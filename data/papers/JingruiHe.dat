2016 IEEE 16th International Conference on Data Mining

Heterogeneous Representation Learning with Structured Sparsity Regularization
Pei Yang

Jingrui He

Arizona State University
Tempe, AZ 85281, USA
Email: cs.pyang@gmail.com

Arizona State University
Tempe, AZ 85281, USA
Email: jingrui.he@gmail.com

Abstract—Motivated by real applications, heterogeneous learning has emerged as an important research area, which aims
to model the co-existence of multiple types of heterogeneity. In
this paper, we propose a HEterogeneous REpresentation learning model with structured Sparsity regularization (HERES) to
learn from multiple types of heterogeneity. HERES aims to
leverage two kinds of information to build a robust learning
system. One is the rich correlations among heterogeneous
data such as task relatedness, view consistency, and label
correlation. The other is the prior knowledge of the data
in the form of, e.g., the soft-clustering of the tasks. HERES
is a generic framework for heterogeneous learning, which
integrates multi-task, multi-view, and multi-label learning into
a principled framework based on representation learning. The
objective of HERES is to minimize the reconstruction loss
of using the factor matrices to recover the input matrix for
heterogeneous data, regularized by the structured sparsity
constraint. The resulting optimization problem is challenging
due to the non-smoothness and non-separability of structured
sparsity. We develop an iterative updating method to solve
the problem. Furthermore, we prove that the reformulation
of structured sparsity is separable, which leads to a family of
efﬁcient and scalable algorithms for solving structured sparsity
penalized problems. The experimental results in comparison
with state-of-the-art methods demonstrate the effectiveness of
the proposed approach.

grouped into clusters with overlap. Here, the goal is to
build a heterogeneous representation learning system to
maximally leverage the correlations among heterogeneous
data, while imposing the structured sparsity regularization
to encode our prior knowledge in the model.
The major challenges arising from these problems are
two-fold. One is how to model the rich correlations among
the heterogeneous data such as task relatedness [5], view
consistency [10], and label correlation [46], in a principled
framework [37]. The other is how to solve the structured
sparsity regularized problem, which is challenging due to
the properties of non-smoothness and non-separability.
In this paper, we propose a HEterogeneous REpresentation learning model with structured Sparsity regularization
(HERES). HERES is a generic approach for heterogeneous
learning from multiple types of heterogeneity, which incorporates the task relatedness, view consistency, and label correlation into a principled framework. Speciﬁcally,
we study the heterogeneous learning problem from matrix
factorization perspective, which decomposes the data matrix
into basis matrix and encoding matrix. HERES models the
task relatedness by requiring different tasks to share a common basis matrix, the view consistency (or label correlation)
by requiring different views (or labels) to share a common
encoding matrix. The objective of HERES is to minimize
the reconstruction loss of using both the basis matrices and
the encoding matrices to recover the heterogeneous data,
penalized by the structured sparsity. The structured sparsity
regularization allows us to encode our prior knowledge of
the data (e.g., the soft-clustering of tasks) into the model.
It requires the similar tasks to behave similarly in selecting
the informative latent features, while truncating the irrelevant ones, which enhances the robustness and improves the
generalization performance of the model.
The main obstacle to solve this problem is the nonsmoothness and non-separability of the structured sparsity.
To tackle this problem, we ﬁrst transform the nonsmooth
objective with structured sparsity into a smooth one by
making use of an auxiliary function. Then, we prove that
the reformulated problem is separable. Thanks to this appealing property, we are able to split the structured sparsity
penalized problem into multiple independent sub-problems,
which can be solved in parallel. The sub-problems enjoy the
nice properties of convexity and having analytical solutions.

1. Introduction
In many data mining applications, heterogeneity is an
intrinsic property of the data, which has fueled the research
on heterogeneous learning [15], [36], [37], [44] in recent
years. In this paper, we focus on the co-existence of triple
types of heterogeneity such as task, view, and label heterogeneity. Take image annotation as an example. The images
collected from different websites or using different devices
follow different feature distributions, corresponding to task
heterogeneity. The images are represented by different types
of features, such as global features, grid-based features,
bag of visual words, corresponding to view heterogeneity.
Also, each image is usually associated with multiple classes,
corresponding to label heterogeneity. On the other hand, the
data may exhibit the soft-clustering property from different perspectives. For example, the tasks may be naturally
2374-8486/16 $31.00 © 2016 IEEE
DOI 10.1109/ICDM.2016.67

539

Also, it is worth mentioning that the proposed structured
sparsity subsumes various sparsity regularizations, such as
task-speciﬁc sparsity, task-common sparsity, their combinations, etc. The main contributions of this paper can be
summarized as follows:
•
We propose a novel heterogeneous representation
learning model with structured sparsity to learn from
complex heterogeneity by leveraging the correlations
and prior knowledge of heterogeneous data.
•
HERES generalizes heterogeneous learning with single or dual heterogeneity by integrating multi-task,
multi-view, and multi-label learning into a principled
framework based on representation learning.
•
We prove that the reformulation of structured sparsity is separable, which leads to a family of efﬁcient
and scalable algorithms for solving the structured
sparsity regularized problems.
•
Experimental results on various data sets show the
effectiveness of the proposed approach.
The rest of the paper is organized as follows. After the
review of the related work in Section 2, we present the
proposed model in Section 3, and discuss some of its special
cases in Section 4. Section 5 shows the experimental results.
Finally, we conclude the paper in Section 6.

gradient method was adopted to solve the overlapping group
Lasso, and a ﬁxed point method was developed to compute the proximal operator. A smoothing proximal gradient
method [7] reformulated the structured sparse regression
problems by using the Nesterov’s smoothing technique, and
solved the approximation problem by proximal gradient
method. The FoGLasso method [42] solved the overlapping
group Lasso penalized problem via the accelerated gradient
descent method using the proximal operator as a key building block. The structural graphical Lasso approach [39] established a bridge between the computation of the proximal
operator associated with a structural regularization and the
derivation of a screening rule for structural graphical Lasso.

2.2. Heterogeneous Learning
Heterogeneous learning aims to leverage different types
of heterogeneity such as task, view, and label heterogeneity,
to improve the learning performance.
Multi-task learning seeks to learn the relatedness among
multiple tasks to improve the learning performance for
each task. Different assumptions on task relatedness lead to
different regularizations imposed on the model. Multi-task
feature learning [1], [23] assumed that multiple related tasks
share a low-dimensional representation. Clustered multi-task
learning [47] assumed that multiple tasks follow a clustered
structure. Trace-norm regularized methods constrained the
models of different tasks to share a low-dimensional subspace [1], [19]. Robust multi-task learning aimed to identify
irrelevant tasks by decomposing the model into a shared
feature structure that captures task relatedness, and a groupsparse structure that detects outliers [11]. Sparsity regularizations are widely used in multi-task learning, such as
2,1 -norm regularized method [1], group Lasso regularized
method [40], sparse group Lasso regularized methods [48],
tree-guided group Lasso regularized method [20], treeguided fused lasso [14], elastic net regularized method [12],
etc.
In multi-label learning, each instance is associated with
a set of labels. The key issue for multi-label learning is how
to exploit the correlations among multiple labels. Multi-label
learning methods can be classiﬁed into three categories [46]:
ﬁrst-order method such as ML-kNN [45], second-order approach such as Rank-SVM [9], and high-order methods.
High-order methods have become the mainstream of multilabel learning due to their strong correlation-modeling capabilities. To name a few, subspace learning approach LSML [18] assumed that a common subspace is shared among
multiple labels; trace-norm regularized method LEML [41]
modeled a multi-label learning framework with rank constraints; multi-label feature learning method [6] applied
2,1 -norm regularization to the objective function to make
the classiﬁer robust for outliers; sparse local embeddings
method SLEEC [3] learned a small ensemble of local distance preserving embeddings, and used 1 regularization
to obtain sparse embeddings. Some other methods such as
TRAM [21] worked in a transductive way by leveraging
the information from unlabeled data to estimate the optimal
label concept compositions.

2. Related Work
In this section, we review the related work on both structured sparsity regularization and heterogeneous learning.

2.1. Structured Sparsity
Imposing sparsity regularizations such as Lasso [32] and
group Lasso [43] on learning model usually leads to better
performance and model interpretability. While Lasso [32]
using the 1 penalty results in sparse models, it can not
leverage any prior information such as the natural grouping
of features. When features are partitioned into groups, group
Lasso [43] leads to the selection of groups of features. However, the non-overlapping group structure in group Lasso
limits its applicability.
Some recent work has studied the structured sparsity
problem. Most of them are based on ﬁrst-order or secondorder optimization algorithms. A straightforward solution is
to duplicate features that belong to more than one group,
and apply forward-backward splitting algorithms on the
expanded space [16]. However, it is limited by its scalability
and the need to maintain the data consistency. A primal-dual
algorithm for overlapping group sparse regularization was
proposed in [26] with no need of data duplication, which is
based on proximal methods. A network ﬂow algorithms for
structured sparsity was introduced in [24]. It shows that the
proximal operator associated with the structured norm can
be computed by solving a quadratic min-cost ﬂow problem.
In [28], an alternation direction method was developed for
structured sparsity penalized problem, which is based on
the augmented Lagrangian method. The Structured-Lasso
(SLasso) presented in [17] applied an active set algorithm
to solve the optimization problem. In [2], the proximal

540

1 ≤ i ≤ T and 1 ≤ j ≤ V . Here, φi ∈ Rp×ni is the
encoding matrix, where p is the dimensionality of the latent
space. Bj ∈ Rdj ×p is the basis matrix for the featureinstance data. U ∈ Rm×p is the basis matrix for labelinstance data.
The main idea of the proposed HERES model is to learn
a robust representation from the heterogeneous data. First,
HERES integrates multi-task, multi-view, and multi-label
learning into a principled framework based on representation
learning. We model the task relatedness by requiring different tasks to share a common basis matrix Bj in the j -view.
The label correlation is encoded into the common basis
matrix U shared across multiple tasks. The view consistency
is captured in the common encoding matrix φi shared across
multiple views for the i-task. Also, the decompositions of
the feature-instance and the label-instance matrices in the itask share the common encoding matrix φi . Second, HERES
leverages the prior knowledge on the soft-clustering of the
tasks to build a robust system by imposing the structured
sparsity regularization on the model. Let G be the number of
task clusters. Denote the set of task index in the k th cluster
by g (k), and the cluster set by Ω = {g(k)|1 ≤ k ≤ G}. Let
φ(k) be the block matrix corresponding to the k th cluster,
which is a concatenated matrix of all the encoding matrices
φi (1 ≤ i ≤ T ) if i ∈ g(k). For example, [φ1 , · · · , φT ]2,1
puts all tasks into one cluster and encourages them to share
a common sparsity structure. The soft-clustering of tasks is
given as the prior knowledge.
The objective of HERES is to minimize the reconstruction loss resulting from using both the basis matrices and
encoding matrices to recover the heterogeneous data, while
imposing the structured sparsity constraints on the groups
of the encoding matrices, i.e.,

The goal of multi-view learning is to leverage the complementary information among different views to improve
the performance [4]. Multi-view learning methods can be
divided into two groups: co-regularization algorithms such
as SVM-2K [10] and CoMR [30], and canonical-correlation
analysis (CCA) based algorithms [31]. Some recent work
aimed to learn the subspaces from multi-view data, such as
the MISL algorithm [35] which discovered a latent intact
representation of the data by using Cauchy loss to measure
the reconstruction cost; the MSL [34] model which tried to
jointly recover the corresponding latent representation and
reconstruction model; the subspace representation learning
method [13] which formulated the unsupervised multi-view
clustering as a joint optimization problem with a common
subspace representation matrix and a group sparsity inducing norm. Both of [13], [34] used 2,1 norm regularization
for the subspace representation learning.
Most recently, heterogeneous learning from multiple
types of heterogeneity became to receive much attentions,
such as multi-task multi-view learning which modeled task
relatedness in the presence of multiple views [15], [36],
[44], multi-view multi-label learning which modeled both
the view consistency and the label correlation [38], and heterogeneous learning from triple types of heterogeneity [37]
including task, view, and label heterogeneity.
In this paper, we focus on heterogeneous learning from
triple types of heterogeneity by leveraging both the correlations among heterogeneous data and the prior knowledge
on the data, which is formulated as a structured sparsity
regularized representation learning problem. These make our
work distinctive from the previous approaches.

3. The Proposed HERES Model

min min min

We ﬁrst introduce the proposed HERES model. Then,
an efﬁcient algorithm is developed to solve the optimization
problem.

U {Bj } {φi }

V
T 


Xij − Bj φi 2F + λ2 Yi − U φi 2F

i=1 j=1

+

G

k=1

3.1. Objective



αk φ(k) 

(1)
2,1

where λ and αk (1 ≤ k ≤ G) are non-negative parameters
to control the importance of the empirical loss and the
structured sparsity, respectively. The l2,1 norm φ(k) 2,1
encourages certain rows of φ(k) to become sparse, hence
reducing the dimensionality of the learned representations
for the k th task cluster.
The intuition behind the HERES model is as follows.
First, φi can be viewed as the new representations of the
instances of i-th task in the latent space, which acts as a
bridge to connect the feature spaces between different views,
as well as to connect the feature space in each view with the
label space. Taking webpage classiﬁcation as an example,
the words (one view) on the webpage, the hyperlinks (another view) pointing to the webpage, and categories (labels) of
webpage could be linked by the latent topics of the webpage.
Second, Bj can be viewed as the new representations of the
features of j -th view in the latent space, which builds the
connection among tasks. Likewise, U can be viewed as the

Suppose we are given multi-task multi-view multi-label
data. T and V are the numbers of tasks and views, respectively. Let Xij ∈ Rdj ×ni be the feature-instance matrix
for the data of i-th task and j -th view, Yi ∈ Rm×ni the
label-instance matrix for the data of i-th task, where ni is
the number of instances in i-th task, dj is the number of
features in j -th view, and m is the number of labels.
The i-th row and j -th column vectors of a matrix W are
represented by Wi: and W:j , respectively. diag(v) returns a
diagonal matrix with elements of vector v on the main diagonal. W F is the Frobenius norm of matrixW . The 2,1
norm
of a matrix W is deﬁned as W 2,1 = i Wi: 2 =
 
2
j Wij .
i
We study the heterogeneous learning problem from
matrix factorization perspective. We try to reconstruct the
feature-instance matrix and label-instance matrix by letting Xij ≈ Bj φi and Yi ≈ U φi simultaneously, where

541

where t is the iteration index, and

new representations of the labels in the latent space, which
correlates the multiple labels of different tasks. Furthermore,
HERES introduces the structured sparsity regularization to
encourage the similar tasks to behave similarly in selecting
the most informative bases, while truncating the irrelevant
ones.
⎡
⎤
⎡ ⎤
Xi1
B1
⎢ .. ⎥
⎢ .. ⎥
⎢ . ⎥
. ⎥
By letting Xi = ⎢
⎣X ⎦ , B = ⎣B ⎦ , φ = {φi }, Eq. 1
iV

⎟
⎜
1
1
(t)

 ⎟

 
D(k) = diag ⎜
⎝ 
 (t)  , · · · ,  (t)   ⎠ .
2 φ(k) 

2
 φ(k) p: 
1: 2

B

φ

T


Proof. We make use of an auxiliary function to derive the
updating rule for φ. Let

V

2

Xi − Bφi F +

i=1

G




αk φ(k) 2,1

F (φ) =

B

φ

T


=

k=1

2

Xi − Bφi F +

i=1

G


k=1

k=1

k=1

p



[φ(k) ]r: 

2

r=1

αk

i=1
p


(t)

[φ(k) ]r: 22 + [φ(k) ]r: 22
(t)

2[φ(k) ]r: 2

r=1

φ



Similar to [27], we can obtain the derivative of J φ, φ(t) :

∂ 
J φ, φ(t)
∂φ
⎡
⎤
p
T
G


[φ(k) ]r: 22
∂ ⎣
2
⎦
=
Xi − Bφi F +
αk
(t)
∂φ i=1
2[φ
]

r:
2
r=1
k=1
(k)
 T

G




∂
(t)
2
=
Xi − Bφi F +
αk tr φT(k) D(k) φ(k)
∂φ i=1
k=1







Since F φ(t) = J φ(t) , φ(t) ≥ min J φ, φ(t) =
φ




J φ(t+1) , φ(t) ≥ F φ(t+1) , the objective function F (φ)
is non-increasing under the above update.

Theorem 1. [Reformulation of Objective] The objective
function in Eq. 3 with respect to φ is non-increasing under
the update

i=1

αk

where
φ(t)

 is the value of φ at iteration t. Note that
of F (φ) due to the facts
J φ, φ(t) is an auxiliary function

that J (φ, φ) = F (φ) and J φ, φ(t) ≥ F (φ). The latter
follows from a2 + b2 ≥ 2ab for any scalars a and b.
Since J φ, φ(t) is an auxiliary function of F (φ), F (φ)
is non-increasing under the update


φ(t+1) = arg min J φ, φ(t) .

Solving the optimization problem in HERES is challenging due to the non-smoothness and non-separability
of structured sparsity. Although the overlapping sparsity
constraints are difﬁcult to separate in its original form, we
ﬁnd that the reformulation of the problem is separable. Next,
we ﬁrst transform the non-smooth problem into a smooth
one by making use of an auxiliary function. Then, we prove
the separability of the new formulation of structured sparsity,
which leads to an efﬁcient and scalable algorithm to solve
the structured sparsity penalized problem.

φ

2

k=1
G


Xi − Bφi F +

G


3.2. Optimization

G


T




αk φ(k) 2,1

T


 
2
J φ, φ(t) =
Xi − Bφi F +



2
αk φ(k) 2,1 + β BF

Xi − Bφi 2F +

G


Then, we deﬁne a new function,

k=1

T


2

Xi − Bφi F +

i=1

(3)
where β is a non-negative parameter to control the smoothness of the model.
The major advantages of the proposed HERES model
are two-fold. First, it is a generic framework for learning complex heterogeneity. HERES is widely applicable
to heterogeneous learning with single or multiple types
of heterogeneity. Second, the introduced structured sparsity
allows for the modeling of soft-clustering of tasks. It accommodates multiple sparsity regularizations. For example,
we can simultaneously impose multiple types of sparsity
constraints on the model, such as task-speciﬁc sparsity, taskcommon sparsity, their combinations, etc. Task-speciﬁc sparsity φi 2,1 is used to capture the task-dependent structures,
while task-common sparsity [φ1 , · · · , φT ]2,1 is used to
capture the task-independent structures. Some case studies
will be introduced in the next section.

φ(t+1) = arg min

T

i=1

(2)

To avoid degeneracy in representation learning, we add the
smoothness regularization on the basis matrix B . Then, the
overall objective of HERES is as follow:
min min

(5)

2

λYi
λU
can be transformed into a compact form:
min min

⎞

⎛

Theorem 2 shows that the reformulation of structured
sparsity is separable. The intuition of separability here is that
the optimization problem with the overlapping structured
sparsity can be split into multiple independent sub-problems,
which could be solved in parallel.



(t)
αk tr φT(k) D(k) φ(k)
(4)

542

Proof. First, ﬁx φ and optimize B . The zero gradient condition of Eq. 7 with respect to B gives

Theorem 2. [Separability of Structured Sparsity] The reformulation of structured sparsity is separable:
G

k=1

=

T



T 
βB +
Bφi φTi − Xi φTi = 0
i=1
 T

−1
T
Xi φTi
βI +
φi φTi
⇒B =



(t)
αk tr φT(k) D(k) φ(k)
⎡
tr

⎛

⎣φTi

⎝

i=1

⎞



⎤

(6)

i=1

(t)
αk D(k) ⎠ φi ⎦

1≤k≤G,i∈g(k)

Proof.

(t)

G

k=1

=
=
=

G

k=1
G

k=1
G


=
=

G



αk tr

r=1

αk

p 

r=1
p 

αk



(t)
D(k)

(t)

(t)

G






αk

· φ(k)

T 
r:

tr

(t)



D(k)

Theorem 4. [Convergence] The proposed HERES algorithm is guaranteed to converge to the local optimum.


2
· [φi ] 
r: 2

rr

(t)

Proof. Since the objective in Eq. 7 is block-wise convex
with respect to B and φi (1 ≤ i ≤ T ), according to the
property of block coordinate descent method (Lemma 3.1
in [33]), the proposed HERES algorithm based on block
coordinate descent will converge to the local optimum.


⎞



⎝

i=1

We summarize the above procedures into the HERES
algorithm as shown in Algorithm 1. We make use of
block coordinate descent method [33] to iteratively solve
the problem. It updates D(k) , B and φi respectively in an
iterative way until convergence. Theorem 4 demonstrates the
convergence of the proposed HERES algorithm.

r:

r: 2

i∈g(k)

tr φTi D(k) φi

⎛

⎣φTi

which completes the proof.

 

[φi ] 2

·

rr

i∈g(k)

⎡

φ(k)






 2
·  φ(k) r: 2

rr

i∈g(k) r=1



rr



p 
 

αk





D(k)
D(k)

r=1

k=1

=

p 


k=1

T


B T Bφi − B T Xi + Di φi = 0

−1
(t)
⇒φi = B T B + Di
B T Xi



(t)
αk tr φT(k) D(k) φ(k)

k=1

⎤

(t)
αk D(k) ⎠ φi ⎦

1≤k≤G,i∈g(k)

Algorithm 1 HERES Algorithm

which completes the proof.

Input:
Feature-instance matrices Xij and label-instance
matrices Yi where 1 ≤ i ≤ T and ≤ j ≤ V , dimension
p, task clusters Ω, parameters αk (1 ≤ k ≤ G) , β, λ.
Output:
Predicted label-instance matrices.
1: Set t = 0;
(t)
2: Initialize φi by using traditional clustering algorithm
such as K -means for each task, where 1 ≤ i ≤ T ;
3: repeat
(t)
4:
Update D(k) by Eq. 5 for each task cluster, where
1 ≤ k ≤ G;
5:
Update B (t+1) by Eq. 9;
(t+1)
6:
Update φi
by Eq. 10 for each task, where 1 ≤
i ≤ T;
7:
Set t ← t + 1;
8: until converged
9: return Predicted label-instance matrices Fi = U φi
where 1 ≤ i ≤ T .

According to Theorem 1 and Theorem 2, the objective
function in Eq. 3 is then transformed into:
min min
B

i=1

Second, ﬁx B and optimize φ. The zero gradient condition
of Eq. 7 with respect to φi gives

φ

T




(t)
Xi − Bφi 2F + tr φTi Di φi + β B2F

(7)

i=1

where

(t)



=

Di

(t)

αk D(k)

(8)

1≤k≤G,i∈g(k)

By now the optimization problem in Eq. 7 with respect to φ
can be split into T independent sub-problems, each of which
is related to φi (1 ≤ i ≤ T ), respectively. This appealing
property makes it possible to design an efﬁcient and scalable
algorithm to solve the problem in parallel.
We reach the ﬁnal solution of HERES. The objective
function in Eq. 7 is an unconstrained quadratic optimization
with respect to B and φi , respectively. Thus, we can obtain
the analytical solutions as shown in Theorem 3.

Regarding the algorithm complexity of HERES, the most
time or space consuming steps are to update B (step 5) and
φi (step 6). According to Eq. 9 and Eq. 10, the size of
the involved matrices in inversion is p × p, where p is the
dimensionality of the latent space. Note that we usually have
p  max(ni , dj ), where ni is the number of instances in
i-th task, and dj is the number of feature in the j -th view.
Therefore, the proposed HERES algorithm is scalable to the
problem size.

Theorem 3. [Optimums] The optimal solutions for the
objective function in Eq. 7 are as follows,
B=

 T
i=1

Xi φTi





βI +
(t)

φ i = B T B + Di

T

−1

i=1

φi φTi

B T Xi

−1
(9)
(10)

where 1 ≤ i ≤ T .

543

4. Case Study

Note that in Corollary 3, each task belongs to two
clusters, i.e., i ∈ {i} and i ∈ {1, · · · , T }. In other words,
the cluster {1, · · · , T } overlaps with each of the remaining
T clusters. It facilitates the joint modeling of task-speciﬁc
sparsity and task-common sparsity.
It is worth pointing out that the scope of the proposed
structured sparsity is beyond these special cases. It allows
for ﬂexible modeling of soft-clustering of tasks, i.e., each
task can belong to any clusters.

In this section, we introduce some special cases of the
proposed model. Based on the prior knowledge of the data,
the structured sparsity can be instantiated as various sparsity
regularizations.
It is well known that Lasso [32] encourages elementwise sparsity; group Lasso [43] encourages group-wise sparsity; while sparse group Lasso [29] encourages both
group-wise and element-wise sparsity. Accordingly, in heterogeneous learning, we may hope to achieve task-level
sparsity, task-cluster-level sparsity, their combinations, etc.
All these sparsity regularizations can be accommodated
in the proposed model. Note that the structured sparsity
introduced here focuses on 2,1 norm, which is different
from Lasso, group Lasso, and sparse group Lasso that are
based on 1 /2 norm. Also, we study the structured sparsity
problem in heterogeneous representation learning, which is
more challenging since we need to simultaneously learn both
the basis matrix and the encoding matrix.
The following corollaries show some special cases of
the proposed model, which are based on the relationships
between the tasks and task clusters. In all the special cases,
the optimal solutions for B (Eq. 9) and φi (1 ≤ i ≤ T )
(Eq. 10) in HERES remain unchanged. The only difference
(t)
is the update of Di in Eq. 8, which can be further reduced
to speciﬁc forms. The proofs of the corollaries are omitted
for brevity.

5. Experiments
We implement the model introduced in Corollary 3,
which employs the structured sparsity to capture both taskdependent and task-independent relatedness.

5.1. Data Sets and Setup
We evaluate the algorithms on three benchmark data sets
including two text data and one image data. All of them are
available online1 .
Reuters Corpus Volume I (RCV1V2) data set [22] is
widely used for the evaluation of heterogeneous learning algorithm. RCV1V2 contains about 800,000 newswire stories.
There are three category sets of data: topics, industry codes,
and regions. Each of these category sets has a hierarchical
structures. It is common to use four subsets of this data,
each containing 6000 instances on average and with a total
number of 101 class labels.
EUR-Lex [25] data set contains nearly 20,000 text documents about European Union ofﬁcial laws, different kinds
of treaties and agreements, parliamentary journals. The documents are organized in a hierarchical structures according
to three different schemas: subject matter, directory codes,
and EUROVOC. There are 412 labels in total.
NUS-WIDE 2 is a real-world web image data set [8].
It consists of more than 269,000 images with over 5,000
user-provided tags, and ground-truth of 81 concepts with a
hierarchical structures. The images are represented by different types of visual features such as 64-D color histogram
in LAB color space, 144-D color correlogram in HSV color
space, 73-D edge distribution histogram, and 500-D bag of
visual words. The light version of NUS-WIDE is used in
our experiments.
In these data sets, the label refers to the multiple categories each instance belongs to. The task refers to classifying the instances belonging to different sub-categories,
which follow different data distributions [15], [37]. For the
NUS-WIDE data, the view refers to different types of visual
feature. For either RCV1V2 or EUR-Lex data set, similar
to [37], the data are represented by two views: one corresponds to the TF-IDF features; and the other corresponds
to the latent topics obtained by applying probabilistic latent
semantic analysis3 on the term frequency.
Table 1 shows the properties of different data sets.
Label cardinality refers to the average number of labels

Corollary 1. (Task-speciﬁc Sparsity): Suppose there are T
task clusters and each task corresponds one cluster, i.e., the
cluster set Ω = {{1}, · · · , {T }}, the objective function in
Eq. 3 is rewritten into

T 
2
2
min
Xi − Bφi F + αi φi 2,1 + β BF
B,φ

i=1

(t)

then, we obtain the diagonal
matrix Di whose (j, j)(1 ≤

(t)
αi 
=  (t)
j ≤ p) element is Di
  .
jj

2
 φi

j:




2

Corollary 2. (Task-common Sparsity): Suppose all the tasks
are in one cluster, i.e., the cluster set Ω = {{1, · · · , T }},
the objective in Eq. 3 is rewritten into
T
2
2
min
Xi − Bφi F + αa φa 2,1 + β BF
B,φ

i=1

where φa = [φ1 , · · · , φT ] and αa is the parameter, then, we
(t)
obtain the diagonal
 matrix Di whose (j, j)(1 ≤ j ≤ p)
(t)
αa 
element is Di
=  (t)
  .
jj

2
 φa

j:




2

Corollary 3. (Task-speciﬁc and Task-common Sparsity):
Suppose cluster set Ω = {{1}, · · · , {T }, {1, · · · , T }} contains T + 1 clusters, the objective in Eq. 3 is rewritten into
T 


2
2
min
Xi − Bφi F + αi φi 2,1 +αa φa 2,1 +β BF
B,φ

i=1

(t)

then, we obtain the diagonal
matrix Di whose (j, j)(1 ≤

(t)
αi 
αa 
=  (t)
j ≤ p) element is Di
  + 
 (t)   .
jj

2
 φi

j:




2

2
 φa

j:




1. http://mulan.sourceforge.net/datasets-mlc.html
2. http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm
3. http://lear.inrialpes.fr/people/verbeek/code

2

544

TABLE 1: Statistics of different data sets.
Data set
RCV1V2 1
RCV1V2 2
RCV1V2 3
RCV1V2 4
EUR-Lex
NUS-WIDE

Instances
6000
6000
6000
6000
19348
55615

Features
47236
47236
47229
47236
5000
708

Labels
101
101
101
101
412
81

per instance. Accordingly, label density normalizes label
cardinality by the the number of labels. Label diversity is
the number of distinct label combinations observed in the
data set [46].

Cardinality
2.880
2.634
2.614
2.484
1.292
1.869

Density
0.029
0.026
0.026
0.025
0.003
0.023

Diversity
1028
954
939
816
1615
18430

we observe that the results are basically consistent across
different metrics, i.e., the larger the F1 -score, the larger the
accuracy, the smaller the Hamming loss.
The results show that both the proposed method HERES
and HiMLS [37] perform better than the other algorithms
in most cases. It demonstrates that learning performance
can be improved by leveraging the rich correlations among
heterogeneous data, such as the task relatedness, view consistency, and label correlation. The other methods including
ML-kNN [45], LS-ML [18], and TRAM [21] only consider the label correlation, while ignoring the other types
of heterogeneity. The results also suggest that treating the
instances in different tasks discriminatively is usually better
than just pooling them into one single task. Analogously,
treating different views in a complementary way is usually
better than just concatenating all the features together.
HERES performs the best among all the algorithms.
Although both HERES and HiMLS [37] take advantage
of triple heterogeneity, the major competency of HERES
over HiMLS lies in the proposed structured sparsity regularization imposed on the model. Structured sparsity helps
pick out the informative latent features, while truncating the
irrelevant ones, which leads to a better representation of the
heterogeneous data in the new latent space. This automatic feature learning procedure improves the generalization
performance of the model. Furthermore, structured sparsity
regularization provides a ﬂexible way to encode the prior
knowledge on the data into the model. In this experiment,
we use task-speciﬁc sparsity to select the latent features
related to each individual task, while using the task-common
sparsity to pick out the latent features shared across multiple
tasks. As a consequence, it gains the performance promotion
by modeling the task relatedness in a more reﬁned way.
In summary, heterogeneous learning could greatly beneﬁt from leveraging both the rich correlations among heterogeneous data including the task relatedness, view consistency, label correlation, as well as the prior knowledge about
the data such as the soft-clustering of tasks.

5.2. Evaluation Metrics and Comparison Methods
We use F1 -score, accuracy and Hamming loss [46] as
the evaluation metrics to examine the performance of all
comparison algorithms on the test data.
F1 -score is the ratio of predicted correct labels to the
mean of the numbers of actual labels and predicted labels,
averaged over all instances. F1 -score is the harmonic mean
of precision and recall. Accuracy refers to the ratio of predicted correct labels to the intersection between actual labels
and predicted labels, averaged over all instances. Hamming
Loss is the sum of the prediction error (an incorrect label
is predicted) and the missing error (a relevant label not
predicted), normalized over total number of labels and total
number of instances. Note that the larger the values of F1 score and accuracy, or the smaller the value of Hamming
loss, the better the performance of the learning algorithm.
In this work, we focus on improving the performance
of multi-label learning by leveraging the multiple types
of heterogeneity. We compare our method with the heterogeneous learning method HiMLS proposed recently in
[37]. Also, HERES is compared with different types of
multi-label learning 4 methods including: graph-based multilabel approach ML-kNN [45], multi-label method based on
subspace learning LS-ML [18], and transductive multi-label
learning approach TRAM [21].
Note that both HERES and HiMLS [37] are capable of
learning from triple types of heterogeneity, while the other
methods are limited to a single type of heterogeneity, i.e.,
label heterogeneity. Therefore, for those methods dealing
with label heterogeneity only, their input is the combined
data, where the instances of all the tasks are pooled together,
and the features from each view are concatenated into one
single view.
We repeat the experiments ten times for each data set and
report the average performance and the standard deviation.
The parameters are tuned for each algorithm using crossvalidation on the training data.

5.4. Inﬂuence of Parameters
It is interesting to study how the dimensionality p of the
latent space inﬂuences the performance of HERES. Taking
RCV1V2 1 data as an example, we vary p from 100 to
8000, and observe the change of performance. The result
is shown in Figure 4. We can see that HERES performs
better when p ≥ 2000 than p < 2000. A larger p indicate
a potential better representation capability of the model.
Then, the sparsity constraint imposed on the model helps
select the most informative latent features, leading to a better
performance.

5.3. Performance Study
Figures 1-3 (in next page) show the performance in
terms of F1 -score, accuracy, and Hamming loss respectively
for the comparison methods on the six data sets. First of all,
4. Due to space limit, we omit the comparison results with multi-task or
multi-view learning, as their performance is not as good as HERES.

545



+(5(6

+L0/6

0/N11

/60/



75$0

)VFRUH





 

UFYYB

UFYYB

UFYYB

UFYYB

HXUOH[GF

QXVZLGH

Figure 1: F1 -score of different algorithms on the six data sets.



+(5(6

+L0/6

0/N11

/60/

75$0



$FFXUDF\





 

UFYYB

UFYYB

UFYYB

UFYYB

HXUOH[GF

QXVZLGH

Figure 2: Accuracy of different algorithms on the six data sets.



+(5(6

+L0/6

0/N11

/60/

75$0

+DPPLQJORVV







UFYYB

UFYYB

UFYYB

UFYYB

HXUOH[GF

QXVZLGH

Figure 3: Hamming loss of different algorithms on the six data sets.

546










)VFRUH

)VFRUH














S







)VFRUH

)VFRUH













,WHUDWLRQ





Figure 7 shows the performance sensitivity with respect
to λ, which is used to balance the contribution from empirical loss. The performance curve is relatively ﬂat when
λ ≤ 1. But a large λ (e.g., λ = 16) may hurt the performance, suggesting that too much weight is placed on the
empirical loss.
We empirically study the convergence of HERES on the
RCV1V2 1 data set. The result is shown in Figure 8. The
F1 -score increases rapidly, and becomes stable after a few
iterations. The results verify the fast convergence property
of the proposed algorithm.







Figure 8: F1 -score varies with each iteration.














D



O



















Next, we study the performance of HERES varying with
the parameter αk , which is used to control the importance
of the structured sparsity. Note that in our experiments, the
cluster set Ω = {{1}, · · · , {T }, {1, · · · , T }} contains T + 1
clusters (please refer to Corollary 3 for details). Therefore,
we empirically set [α1 , · · · , αT , αa ] = [α, · · · , α, T α]. The
performance of HERES with respect to α on RCV1V2 1
data is shown in Figure 5. First of all, the performance is
poor when α = 0. It suggests that the structured sparsity
constraint is indispensable to the proposed model. Then,
the performance increases signiﬁcantly as α increases, and
reaches to the peak at α = 1/16. But a large α (e.g., α > 16)
may hurt the performance.

 



Figure 7: F1 -score varies with λ (log4 scale).

Figure 4: F1 -score varies with dimension p.



Figure 5: F1 -score varies with α (log4 scale).

6. Conclusion

Figure 6 shows the performance of HERES varying with
β on RCV1V2 1 data, which controls the importance of
smoothness regularization. When β = 0, it means that no
smoothness constraint is imposed on the model, resulting in
poor performance. The results show that HERES is robust
over a wide range of β values.

In this paper, we propose a heterogeneous representation learning model with structured sparsity regularization. HERES incorporates multiple types of correlations
among heterogeneous data into a representation learning
framework. The separability of the reformulated problem
leads to an efﬁcient and scalable algorithm to solve the
structured sparsity regularized problem. The effectiveness
of the proposed method is validated on various data sets in
comparison with different heterogeneous learning methods.





)VFRUH













Acknowledgments




This work is supported by the NSF research grant IIS1552654, ONR Research grant N00014-15-1-2821, IBM
Faculty Award, and NSFC research grant 61473123. The
views and conclusions are those of the authors and should
not be interpreted as representing the ofﬁcial policies of the
funding agencies or the governments.


 





E









Figure 6: F1 -score varies with β (log4 scale).

547

References
[1]

A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature learning.
In NIPS, pages 41–48, 2006.

[2]

A. Argyriou, C. A. Micchelli, M. Pontil, L. Shen, and Y. Xu.
Efﬁcient ﬁrst order methods for linear composite regularizers. CoRR,
abs/1104.1436, 2011.

[3]

A. Blum and T. Mitchell. Combining labeled and unlabeled data with
co-training. In COLT, pages 92–100, 1998.

[5]

R. Caruana. Multitask learning. Machine Learning, 28(1):41–75,
1997.

[6]

X. Chang, F. Nie, Y. Yang, and H. Huang. A convex formulation for
semi-supervised multi-label feature selection. In AAAI, pages 1171–
1177, 2014.

[7]

X. Chen, Q. Lin, S. Kim, J. G. Carbonell, and E. P. Xing. Smoothing
proximal gradient method for general structured sparse learning. In
UAI, pages 105–114, 2011.

[9]

[26] S. Mosci, S. Villa, A. Verri, and L. Rosasco. A primal-dual algorithm
for group sparse regularization with overlapping groups. In NIPS,
pages 2604–2612, 2010.
[27] F. Nie, H. Huang, X. Cai, and C. H. Q. Ding. Efﬁcient and robust
feature selection via joint 2,1 -norms minimization. In NIPS, pages
1813–1821, 2010.

K. Bhatia, H. Jain, P. Kar, M. Varma, and P. Jain. Sparse local
embeddings for extreme multi-label classiﬁcation. In NIPS, pages
730–738, 2015.

[4]

[8]

[25] E. L. Mencı́a and J. Fürnkranz. Efﬁcient pairwise multilabel classiﬁcation for large-scale problems in the legal domain. In ECML-PKDD,
pages 126–135, 2008.

[28] Z. T. Qin and D. Goldfarb. Structured sparsity via alternating direction
methods. Journal of Machine Learning Research, 13:1435–1468,
2012.
[29] N. Simon, J. Friedman, T. Hastie, and R. Tibshirani. A sparse-group
Lasso. Journal of Computational and Graphical Statistics, 22(2):231,
2013.
[30] V. Sindhwani and D. S. Rosenberg. An RKHS for multi-view learning
and manifold co-regularization. In ICML, pages 976–983, 2008.
[31] K. Sridharan and S. M. Kakade. An information theoretic framework
for multi-view learning. In COLT, pages 403–414, 2008.
[32] R. Tibshirani. Regression shrinkage and selection via the Lasso.
Journal of the Royal Statistical Society. Series B (Methodological),
58(1):267–288, 1996.

T. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. NUSWIDE: a real-world web image database from national university of
singapore. In CIVR, 2009.

[33] P. Tseng. Convergence of a block coordinate descent method for
nondifferentiable minimization. Journal of Optimization Theory and
Applications, 109(3):475–494, 2001.

A. Elisseeff and J. Weston. A kernel method for multi-labelled
classiﬁcation. In NIPS, pages 681–687, 2001.

[34] M. White, Y. Yu, X. Zhang, and D. Schuurmans. Convex multi-view
subspace learning. In NIPS, pages 1682–1690, 2012.

[10] J. D. R. Farquhar, D. R. Hardoon, H. Meng, J. Shawe-Taylor, and
S. Szedmák. Two view learning: SVM-2K, theory and practice. In
NIPS, 2005.

[35] C. Xu, D. Tao, and C. Xu. Multi-view intact space learning. IEEE
Trans. Pattern Anal. Mach. Intell., 37(12):2531–2544, 2015.

[11] P. Gong, J. Ye, and C. Zhang. Robust multi-task feature learning. In
KDD, pages 895–903, 2012.

[36] H. Yang and J. He. Learning with dual heterogeneity: A nonparametric bayes model. In KDD, pages 582–590, 2014.

[12] P. Gong, J. Zhou, W. Fan, and J. Ye. Efﬁcient multi-task feature
learning with calibration. In KDD, pages 761–770, 2014.

[37] P. Yang and J. He. Model multiple heterogeneity via hierarchical
multi-latent space learning. In KDD, pages 1375–1384, 2015.

[13] Y. Guo. Convex subspace representation learning from multi-view
data. In AAAI, 2013.

[38] P. Yang, J. He, H. Yang, and H. Fu. Learning from label and feature
heterogeneity. In ICDM, pages 1079–1084, 2014.

[14] L. Han and Y. Zhang. Learning tree structure in multi-task learning.
In KDD, pages 397–406, 2015.

[39] S. Yang, Q. Sun, S. Ji, P. Wonka, I. Davidson, and J. Ye. Structural
graphical Lasso for learning mouse brain connectivity. In KDD, pages
1385–1394, 2015.

[15] J. He and R. Lawrence. A graph-based framework for multi-task
multi-view learning. In ICML, pages 25–32, 2011.

[40] X. Yang, S. Kim, and E. P. Xing. Heterogeneous multitask learning
with joint sparsity constraints. In NIPS, pages 2151–2159, 2009.

[16] L. Jacob, G. Obozinski, and J. Vert. Group Lasso with overlap and
graph Lasso. In ICML, pages 433–440, 2009.

[41] H.-F. Yu, P. Jain, P. Kar, and I. S. Dhillon. Large-scale multi-label
learning with missing labels. In ICML, pages 593–601, 2014.

[17] R. Jenatton, J. Audibert, and F. R. Bach. Structured variable selection
with sparsity-inducing norms. Journal of Machine Learning Research,
12:2777–2824, 2011.

[42] L. Yuan, J. Liu, and J. Ye. Efﬁcient methods for overlapping group
Lasso. IEEE Trans. Pattern Anal. Mach. Intell., 35(9):2104–2116,
2013.

[18] S. Ji, L. Tang, S. Yu, and J. Ye. Extracting shared subspace for
multi-label classiﬁcation. In KDD, pages 381–389, 2008.

[43] M. Yuan and Y. Lin. Model selection and estimation in regression
with grouped variables. Journal of the Royal Statistical Society. Series
B (Statistical Methodology), 68(1):49–67, 2006.

[19] S. Ji and J. Ye. An accelerated gradient method for trace norm
minimization. In ICML, pages 457–464, 2009.

[44] J. Zhang and J. Huan. Inductive multi-task learning with multiple
view data. In KDD, pages 543–551, 2012.

[20] S. Kim and E. P. Xing. Tree-guided group Lasso for multi-task
regression with structured sparsity. In ICML, pages 543–550, 2010.

[45] M.-L. Zhang and Z.-H. Zhou. ML-KNN: A lazy learning approach
to multi-label learning. Pattern Recognition, pages 2038–2048, 2007.

[21] X. Kong, M. K. Ng, and Z.-H. Zhou. Transductive multilabel learning
via label set propagation. IEEE Trans. Knowl. Data Eng. (TKDE),
pages 704–719, 2013.

[46] M.-L. Zhang and Z.-H. Zhou. A review on multi-label learning
algorithms. IEEE Transactions on Knowledge and Data Engineering,
26(8):1819–1837, 2014.

[22] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. Rcv1: A new
benchmark collection for text categorization research. Journal of
Machine Learning Research (JMLR), 5:361–397, 2004.

[47] J. Zhou, J. Chen, and J. Ye. Clustered multi-task learning via
alternating structure optimization. In NIPS, pages 702–710, 2011.

[23] Y. Li, X. Tian, T. Liu, and D. Tao. Multi-task model and feature joint
learning. In IJCAI, pages 3643–3649, 2015.

[48] J. Zhou, J. Liu, V. A. Narayan, and J. Ye. Modeling disease
progression via fused sparse group Lasso. In KDD, pages 1095–
1103, 2012.

[24] J. Mairal, R. Jenatton, G. Obozinski, and F. R. Bach. Network ﬂow
algorithms for structured sparsity. In NIPS, pages 1558–1566, 2010.

548

2010 IEEE International Conference on Data Mining

Rare Category Characterization
Jingrui He
Carnegie Mellon University
jingruih@cs.cmu.edu

Hanghang Tong
Carnegie Mellon University
htong@cs.cmu.edu

examples from those classes. In this paper, we refer to this
problem as rare category characterization, i.e., characterizing
the minority classes for the purpose of understanding and
correctly classifying those classes.
In this paper we exploit compactness of rare categories via
a new algorithm we call RACH, which represents minority
classes as hyperballs. Our key observation is as follows:
although the minority classes are non-separable from the
majority classes, they often exhibit compactness. That is,
each minority class often forms a compact cluster. For
example, the fraudulent people often make multiple similar
transactions to maximize their proﬁts [5]. For rare diseases,
the patients with the same type of rare disease often share
similar genes or chromosomal abnormalities [14].
In this paper, we propose RACH by exploring such
compactness for rare category characterization. The core
of RACH is to represent the minority classes with a hyperball. We present the optimization framework as well as
an effective algorithm to solve it. Furthermore, we show
how RACH can be naturally kernelized. We also analyze the
complexity of RACH. Finally, we justify the effectiveness
of the proposed RACH by both theoretical analysis and
empirical evaluations.
The rest of our paper is organized as follows. Related
work is reviewed in Section II. In Section III, we propose the
optimization framework to provide a compact representation
for the minority class with justiﬁcation, followed by the
conversion of this framework to the convex optimization
problem as well as its dual form. Then we introduce the
RACH algorithm to solve the dual problem with performance
guarantee in Section IV, and the kernelized RACH algorithm in Section V. Experimental results are presented in
Section VI. Finally, we conclude the paper in Section VII.

Abstract—Rare categories abound and their characterization
has heretofore received little attention. Fraudulent banking
transactions, network intrusions, and rare diseases are examples of rare classes whose detection and characterization are of
high value. However, accurate characterization is challenging
due to high-skewness and non-separability from majority
classes, e.g., fraudulent transactions masquerade as legitimate
ones.
This paper proposes the RACH algorithm by exploring the
compactness property of the rare categories. It is based on an
optimization framework which encloses the rare examples by a
minimum-radius hyperball. The framework is then converted
into a convex optimization problem, which is in turn effectively
solved in its dual form by the projected subgradient method.
RACH can be naturally kernelized. Experimental results validate the effectiveness of RACH.
Keywords-rare category; minority class; characterization;
compactness; optimization; hyperball; subgradient;

I. I NTRODUCTION
Many real world problems exhibit extremely skewed class
membership. Some classes (the minority classes) are overwhelmed by the others (the majority classes) in terms of
the example numbers. It is often the case that the minority
classes are much more important than the majority classes.
For example, minority classes can represent fraudulent banking transactions or successful network intrusions - either can
represent less than 0.01% of normal transactions or network
trafﬁc - yet detecting them can prove crucial. In medical
diagnoses, some extremely severe diseases may have very
few records; however, misdiagnosis of these diseases may
have fatal consequences.
What is even more challenging is that such rare categories
are often non-separable from the majority classes. For example, the guileful fraudulent people often try to camouﬂage
their transactions within the normal transactions so that they
can bypass the current fraud detection algorithms [5]. For
most types of rare diseases, they have identiﬁed genetic
origins, which involve only one or several genes or chromosomal abnormalities. Yet, the remaining vast number of
genes and chromosomes behave normally [14].
That said, it is therefore a very important challenge to
accurately classify such minority classes given that they are
(1) highly skewed and (2) non-separable from the majority
classes. In addition, if the minority classes can be characterized by a concise representation, we may better understand
the nature of the minority classes, and thus better identify
1550-4786/10 $26.00 © 2010 IEEE
DOI 10.1109/ICDM.2010.154

Jaime Carbonell
Carnegie Mellon University
jgc@cs.cmu.edu

II. R ELATED W ORK
In this section, we review the related work, which can
be categorized into four parts: rare category detection,
imbalanced classiﬁcation, outlier detection and SVM-based
algorithms.
Rare category detection is to ﬁnd at least one example
from each minority class with the help of a labeling oracle,
minimizing the number of label requests. Up until now,
researchers have developed several methods for rare category
detection. For example, in [24], the authors assumed a mixture model to ﬁt the data, and experimented with different
226

and bear no-similarity among themselves. In contrast, our
work uses a hyperball-based representation for the minority
classes, and we assume that the rare examples from the same
class are self-similar. We do not require the support region
of the majority class to be a hyper-ball, i.e., we make no
clustering or compactness assumption for the majority class.
SVM-based algorithms are also related to rare category
characterization. Firstly, our proposed method is motivated
by one-class SVM [26], which is used to estimate a subset
of the input space such that the probability of ﬁnding an
example outside the subset is small, given examples from
a single class. However, it does not apply in our settings
since we deal with data from multiple classes (one majority
class and one minority class); and we have access to a
set of labeled examples from both the majority and the
minority classes. In addition, we will make use of the
unlabeled data to further improve the performance of our
method. Secondly, our method is also related to SVM-Perf,
which is an implementation of the SVM formulation for
optimizing multivariate performance measures [21]. SVMPerf is optimizing an upper bound on the training loss
regularized by the L2 norm of the weight vector [21].
However, the compactness property of the minority classes
is not exploited in SVM-Perf. In addition, with SVM-Perf,
we can not obtain a concise representation for the minority
classes.

hint selection methods, of which Interleaving performs the
best; in [15], the authors studied functions with multiple output values, and used active sampling to identify an example
for each of the possible output values; in [17], the authors
developed a new method for detecting an example of each
minority class via an unsupervised local-density-differential
sampling strategy; in [11], the authors presented an active
learning scheme that exploits the cluster structure in the data,
which was proven to be effective in rare category detection;
and in [28], to identify anomalies at different scales, the
authors created a hierarchy by repeatedly applying mean
shift with an increasing bandwidth on the data. Rare category
detection can be followed by rare category characterization,
i.e., after ﬁnding a few (limited) examples from the minority
classes, the challenge becomes how to identify most or all
rare examples in the unlabeled data.
Imbalanced classiﬁcation has been well studied over the
past decade, and several workshops and special issues have
dedicated to this problem, such as AAAI’2000 workshop
on Learning from Imbalanced Data Sets [19], ICML’2003
workshop on Learning from Imbalanced Data Sets [6], and
ACM SIGKDD special issue on Learning from Imbalanced
Data Sets [8]. Researchers have proposed many methods to
address this problem, such as sampling methods [22][7][10],
ensemble based methods [9][27], to name a few. These
methods can be used for rare category characterization
by returning the unlabeled examples that are classiﬁed as
minority class examples. However, these methods might not
take full advantage of the minority class properties (e.g.,
the compactness property). Notice that in [29], the proposed
method exploits the local clustering within large classes;
whereas our method is based on the compactness of the
minority classes, i.e., small classes. In addition, we might not
be able to obtain a compact representation for the minority
classes with these methods.
Outlier Detection refers to the problem of ﬁnding patterns in data that do not conform to expected behaviors [4].
According to [4], the majority of outlier detection techniques can be categorized into classiﬁcation based [2], nearest neighbor based [25], clustering based [30], information
theoretic [18], spectral [13], and statistical techniques [1].
In general, outlier detection ﬁnds individual and isolated
examples that differ from a given class in an unsupervised
fashion. Typically, there is no way to characterize the outliers
since they are often different from each other. On the other
hand, in rare category characterization, we are given labeled
examples from a certain minority class, and hope to ﬁnd
similar examples from the same minority class by characterizing the distribution of this class. Some work addresses
the case where the outliers are clustered [23]. However,
they still assume that the outliers are separable from the
normal data points. Notice that the work proposed in [16]
uses a hyperball-based representation for the normal class,
or majority class. It assumes that the outliers are scattered

III. O PTIMIZATION F RAMEWORK
In this section, we present our optimization framework,
after we introduce the notation and the pre-processing step.
A. Notation and Assumptions
Notation. For the sake of simplicity, we assume that there
is only one majority class and one minority class in the data
set. (Multiple majority and minority classes can be converted
into several binary problems.) Throughout this paper, we will
use bold lower-case letters to denote vectors, normal letters
(lower-case or upper-case) to denote scalars, and calligraphic
capital letters to denote sets. Let x1 , . . . , xn1 ∈ Rd denote
the labeled examples from the majority class, which correspond to yi = 1, i = 1, . . . , n1 ; let xn1 +1 , . . . , xn1 +n2 ∈ Rd
denote the labeled examples from the minority class, which
correspond to yj = −1, j = n1 + 1, . . . , n1 + n2 ; let
xn1 +n2 +1 , . . . , xn ∈ Rd denote all the unlabeled examples.
Here, n1 , n2 , and n denote the number of labeled examples
from the majority class, the number of labeled examples
from the minority class, and the total number of examples,
both labeled and unlabeled. d is the dimensionality of the
input space. Our goal is to identify a list of unlabeled
examples which are believed to come from the minority class
with high precision and recall.
Assumption. In many imbalanced problems, it is often the
case that the rare examples from the same minority class
are very close to each other, whereas the examples from

227

data. This is to ensure that we do not miss any rare example.
We should point out that the ﬁltering process is orthogonal
to the other parts of the proposed algorithm. In the remainder
of this paper, unlabeled data (unlabeled examples) refer to
the examples output by the ﬁltering process.

the same majority class may be scattered in the feature
space. This assumption is also used in [17][29][24], etc,
when dealing with imbalanced data sets, either explicitly
or implicitly. Furthermore, we also assume that the rare
examples can be enclosed by a minimum-radius hyperball
in the input space without including too many majority
class examples. This seemingly rigorous assumption will
become more ﬂexible when we use the high-dimensional
feature space instead of the input space via the kernel trick
in Section V. With this assumption, we allow the support
regions of the majority and minority classes to overlap with
each other.

C. Problem Formulation
Now, we are ready to give the problem formulations
for rare category characterization. We ﬁrst give its original
formulation and illustrate its intuitions. Then, we present its
convex approximation together with its dual form.
Original Formulation. To ﬁnd the center and radius of
the minimum-radius hyperball, we construct the following
optimization framework, which is inspired by one-class
SVM [26].
Problem 1.

B. Pre-processing: Filtering
Algorithm 1 Filtering Process for Rare Category Characterization
Input: x1 , . . . , xn1 +n2 , xn1 +n2 +1 , . . . , xn
Output: xn1 +n2 +1 , . . . , xn
1: if n2 > 1 then
2:
Estimate the center c of the hyperball by one-class
SVM [26], using all the labeled minority examples
3: else
4:
Set the center c = xn1 +1
5: end if
6: for i = n1 + n2 + 1, . . . , n do
7:
Calculate the distance di = xi − c
8: end for
n2
9: Calculate p = n +n
; set Dthre as the (n −n1 −n2 )×pth
1
2
smallest value among all di (i = n1 + n2 + 1, . . . , n );
10: n = n1 + n2
11: for i = n1 + n2 + 1, . . . , n do
12:
if di ≤ 3 · Dthre then
13:
n = n + 1, xn = xi
14:
end if
15: end for

min
2

R ,c,α,β

R 2 + C1

n1

i=1
2

αi + C2

n−n
1 −n2


βk

k=1

s.t. xi − c ≥ R2 − αi , i = 1, . . . , n1
αi ≥ 0, i = 1, . . . , n1
xj − c2 ≤ R2 , j = n1 + 1, . . . , n1 + n2
xk − c2 ≤ R2 + βk−n1 −n2 , k = n1 + n2 + 1, . . . , n
βk−n1 −n2 ≥ 0, k = n1 + n2 + 1, . . . , n
where R is the radius of the hyperball; c is the center of
the hyperball; C1 and C2 are two positive constants that
balance among the three terms in the objective function; α
and β correspond to the non-negative slack variables for the
labeled examples from the majority class and the unlabeled
examples; αi and βk are the ith and k th component of α and
β respectively.
In Problem 1, we minimize the squared radius of the
hyperball and a weighted combination of the slack variables.
Furthermore, we have three types of constraints with respect
to the training data. The ﬁrst type is for the labeled examples
from the majority class, i.e., they should be outside the
hyperball. Notice that these are not strict constraints, and
the labeled examples from the majority class falling inside
the hyperball correspond to positive slack variables αi . In
this way, we allow the support regions of the majority and
minority classes to overlap with each other. The second type
is for the labeled examples from the minority class, i.e.,
they should be inside the hyperball. In contrast, these are
strict constraints, and the hyperball should be large enough
to enclose all the labeled rare examples. The last type is
for the unlabeled examples, i.e., we want the hyperball to
enclose as many unlabeled examples as possible. Different
from the second type of constraints, these constraints are
not strict, and the examples falling outside the hyperball
correspond to positive slack variables βk . The intuition of
this type of constraints is that after the ﬁltering process,
the unlabeled examples are all in the neighborhood of the

In the unlabeled data, examples far from the hyperball
may be safely classiﬁed as belonging to the majority class
without materially affecting the performance of our classiﬁer. Therefore, we ﬁrst ﬁlter the unlabeled data to exclude
such examples from the following optimization framework,
and only focus on the examples that are close to the
hyperball. The ﬁltering process is described in Alg. 1. It
takes both the labeled and the unlabeled examples as input,
and outputs a set of unlabeled examples which are close to
the hyperball. Here, n − n1 − n2 is the number of unlabeled
examples after the ﬁltering process. The algorithm works
as follows. It ﬁrst estimates the center c of the hyperball
using one-class SVM [26] or a single labeled example; then
it estimates the proportion p of the rare examples in the
unlabeled data using the labeled data; ﬁnally, it calculates the
distance threshold Dthre based on p, which is used to ﬁlter
out the unlabeled examples far away from the hyperball.
Notice that 3 × Dthre is actually used to ﬁlter the unlabeled

228

2, the center c of the hyperball can be calculated as follows.
n
n1
j=n1 +1 λj xj −
i=1 λi (xi − ĉ)
n
c=
(1)
j=n1 +1 λj

minority class. The support region of the minority class
should have a higher density compared with the rest of the
neighborhood. Therefore, we want the hyperball to enclose
as many unlabeled examples as possible.
Convex Approximation of Problem 1. Note that Problem
1 is difﬁcult to solve due to the ﬁrst type of constraints on
the labeled examples from the majority class, which make
this framework non-convex in the center c. To address this
problem, we approximate these constraints based on ﬁrstorder Taylor expansion around the current center ĉ, and have
the following optimization problem, which is convex.
Problem 2. (Convex Approximation of Problem 1)
n1
n−n
1 −n2


2
R
+
C
α
+
C
βi
min
1
i
2
2
R ,c,α,β

i=1

IV. O PTIMIZATION A LGORITHM : RACH
Here, we present the proposed optimization algorithm
to solve Problem 1. The basic idea is as follow: after an
initialization step; we will recursively formulate Problem 2
using the current estimate ĉ for the center of the hyperball;
and then solve Problem 2 in its dual form (Problem 3) by a
projected subgradient method.
A. Initialization Step
First, we need to initialize the center c of the hyperball
and the Lagrange multipliers λ in Problem 3, which is
summarized in Alg. 2. It takes as input both the labeled
and the unlabeled examples (after the ﬁltering process), and
outputs the initial estimates of the center c and the Lagrange
multipliers λ. In Step 1, it initializes the center c and the
radius R of the hyperball using one-class SVM [26] if we
have more than one labeled examples from the minority
class; otherwise, it uses the only labeled rare example as the
center c, and the smallest distance between this example and
the nearest labeled example from the majority class as R. In
Step 2, it initializes the Lagrange multipliers based on the
KKT conditions of Problem 1. For a labeled example from
the majority class, if its distance to the center c is bigger
than R, λi = 0; if the distance is less than R, λi = C1 ;
and if the distance is equal to R, we use C21 as the value
for λi . For a labeled example from the minority class, if its
distance to the center c is less than R, λj = 0; otherwise, we
2
as the value for λj . For an unlabeled example,
use C1 +C
2
if its distance to the center c is less than R, λk = 0; if the
distance is bigger than R, λk = C2 ; and if the distance is
equal to R, we use C22 as the value for λk .

i=1
2

s.t. R2 − αi − xi 2 + ĉ + 2(xi − ĉ)T c ≤ 0,
i = 1, . . . , n1
αi ≥ 0, i = 1, . . . , n1
xj − c2 ≤ R2 , j = n1 + 1, . . . , n1 + n2
xk − c2 ≤ R2 + βk

k
n1 n
−2 , −

= n 1 + n2 + 1 , . . . , n

βk ≥ 0, k = 1, . . . , n − n1 − n2
Based on Problem 2, we ﬁnd the solution to Problem 1
in an iterative way. To be speciﬁc, in each iteration step,
we form Problem 2 based on the current estimate ĉ of the
center, ﬁnd the optimal R2 , c, α and β, and then update
Problem 2 based on the new center c. We stop the iteration
until the solution in two consecutive steps are very close
to each other or the maximum number of iteration steps is
reached.
Dual Problem for Problem 2. It is obvious that Problem
2 satisﬁes Slater’s condition [3]. Therefore, we solve this
problem via the following dual problem.
Problem 3. (Dual Problem for Problem 2)
n1
n1
n



2
2
λj xj  −
λi xi  +
λi ĉ2
max
λ

j=n1 +1

−



s.t. 1 +

i=1

n

j=n1 +1 λj xj −
n

n1

i=1

λi =

n


n1

i=1

B. Projected Subgradient Method for Problem 3

2
i=1 λi (xi − ĉ)

j=n1 +1

Projected subgradient methods minimize a convex function f (λ) subject to the constraint that λ ∈ X , where X is
a convex set, by generating the sequence {λ(t) } via

(λ(t) − τt ∇(t) )
λ(t+1) =

λj

λj

j=n1 +1

0 ≤ λi ≤ C1 , i = 1, . . . , n1
0 ≤ λj , j = n1 + 1, . . . , n1 + n2
0 ≤ λk ≤ C2 , k = n1 + n2 + 1, . . . , n

X
(t)
where ∇(t)
is the (sub)gradient of f at λ , τt is the step
size, and X (x) = arg miny {x − y : y ∈ X } is the
Euclidean projection of x onto X . To solve Problem 3,
will
the gradient descent step is straight-forward.1 Next,
nwe
1
focus
on
the
projection
step,
where
X
=
{λ
:
1+
λ
i =
i=1
n
j=n1 +1 λj , 0 ≤ λi ≤ C1 , i = 1, . . . , n1 ; 0 ≤ λj , j =
n1 +1, . . . , n1 +n2 ; 0 ≤ λk ≤ C2 , k = n1 +n2 +1, . . . , n}.

where λ is the vector of Lagrange multipliers, λi , i =
1, . . . , n1 are associated with the constraints on the labeled
examples from the majority class, λj , j = n1 + 1, . . . , n1 +
n2 are associated with the constraints on the labeled examples from the minority class, and λk , k = n1 +n2 +1, . . . , n
are associated with the constraints on the unlabeled examples. Furthermore, based on the KKT conditions of Problem

1 Note that in our case, we are maximizing a concave function in Problem
3, and gradient ascent is actually used in RACH.

229

where θ is a Lagrange multiplier associated with the equality
constraint; ζ and η are two vectors of Lagrange multipliers
associated with the inequality constraints whose elements
are ζi and ηi respectively. Taking the partial derivative of
L(λ, θ, ζ, η) with respect to λ and set it to 0, we get

Algorithm 2 Initialization for RACH
Input: x1 , . . . , xn
Output: initial estimates of c and λ
1: if n2 > 1 then
2:
initialize the center c and the radius R of the hyperball
using one-class SVM [26]
3: else
4:
set c = xn1 +1 , and set R as the smallest distance
between xn1 +1 and the nearest labeled example from
the majority class
5: end if
6: Initialize λ as follows.
For 1 ≤ i ≤ n1 , if xi − c > R, λi = 0;
if xi − c < R, λi = C1 ; if xi − c = R,
λi = C21
For n1 + 1 ≤ j ≤ n1 + n2 , if xj − c < R,
2
λj = 0; if xj − c = R, λj = C1 +C
2
For n1 +n2 +1 ≤ k ≤ n, if xk −c < R, λk = 0;
if xk − c > R, λk = C2 ; if xk − c = R,
λk = C22

λi = vi − ai θ + ζi − ηi

For the ﬁrst half of Lemma 1, suppose that s, t ∈ S+ . If
λs = 0 and λt > 0, we have ζs ≥ 0, ηs = 0, ζt = 0 and
ηt ≥ 0. Therefore, vs −θ+ζs = 0 and vt −θ−ηt > 0, which
can not be satisﬁed simultaneously since vs > vt . Therefore,
if λs = 0, λt must be zero as well. Similar proof can be
applied when s, t ∈ S− . For the second half of Lemma 1,
suppose that s , t ∈ S+ . If λs = εs and λt < εt , we
have ζs = 0, ηs ≥ 0, ζt ≥ 0 and ηt = 0. Therefore,
λs − εs = vs − εs − θ − ηs = 0 and λt − εt = vt − εt −
θ + ζt < 0, which can not be satisﬁed simultaneously since
vs − εs < vt − εt . Similar proof can be applied when
s, t ∈ S− .
Besides the vector v, deﬁne the vector v such that its
th
i element vi = vi − εi . Based on Lemma 1, for S+ (S− ),
we can keep two lists: the ﬁrst list sorts the elements of v
whose indices are in S+ (S− ) in an ascending order, and
only a top portion of the list corresponds to 0 in λ; the
second list sorts the elements of v whose indices are in
S+ (S− ) in a descending order, and only a top portion of
the list corresponds to the elements of λ that reach their
upper bounds. For the remaining indices in S+ (S− ), their
corresponding elements in λ are between 0 and the upper
bound, and the Lagrange multipliers ζi = ηi = 0. Therefore,
according to Equation 2, λi = vi − θ (λi = vi + θ). Finally,
with respect to the value of θ, we have the following lemma.
Lemma 2: Let λ be the optimal solution to Problem 4.
1
2
3
Let S+
, S+
and S+
denote subsets of S+ which correspond
to the elements in λ that are equal to 0, equal to the upper
bound,
0 and the upper bound respectively.
 2and
 between
1
3
1
2
3
S+ S +
= S+ . Let S−
, S−
and S−
denote subsets
S+
of S− which correspond to the elements in λ that are equal
to 0, equal to the upper bound,
0 and the
 2and
 between
1
3
S− S−
= S− . θ can be
upper bound respectively. S−
calculated as follows.

In the projection step, we consider the following optimization problem.
Problem 4. (Projection Step of Problem 3)
n

1
ai λi = z, 0 ≤ λi ≤ εi
min λ − v22 s.t.
λ
2
i=1
where ai (i = 1, . . . , n) denote a set of constants which are
either 1 or -1; z is a constant; v can be seen as the updated
vector for λ based on gradient descent in each iteration step
of the projected subgradient method, or λ(t) − τt ∇(t) ; and
εi is the upper bound for λi . Without loss of generality,
we assume that εi > 0, i = 1, . . . , n. For this optimization
problem, deﬁne S+ = {i : 1 ≤ i ≤ n, ai = 1}, and S− =
{i : 1 ≤ i ≤ n, ai = −1}.
Before we give our optimization algorithm for Problem 4,
we ﬁrst give the following lemma, which is the key for
solving Problem 4.2
Lemma 1: Let λ be the optimal solution to Problem 4.
Let s and t be two indices such that s, t ∈ S+ or s, t ∈ S− ,
and vs > vt . If λs = 0, then λt must be zero as well. On the
other hand, let s and t be two indices such that s , t ∈ S+
or s , t ∈ S− , and vs − εs < vt − εt . If λs = εs , then
λt must be εt as well.
Proof: The Lagrange function of Problem 4:


θ=

n
n


1
2
ai λi − z) −
ζi λ i
L(λ, θ, ζ, η) = λ − v + θ(
2
i=1
i=1

−

n


(2)

3
k∈S+

vk +



2
j∈S+

εj −



3|+
|S+

3
k∈S−
3|
|S−

vk −



2
j∈S−

εj − z
(3)

1
2
3
Proof: According tothe deﬁnition of S+
, S+
, S+
and
1
2
3
1
1
S−
, S−
,
S−
, ∀i ∈ S+
, λi = 0, ζi ≥ 0, ηi = 0;
S−
2
2
3
3
S−
S−
, λj = εj , ζj = 0, ηj ≥ 0; ∀k ∈ S+
,
∀j ∈ S+
3
0 < λk < εk , ζk = ηk = 0. Furthermore, ∀k ∈ S+ , λk =
3
, λk = vk + θ. Therefore,
vk − θ; ∀k ∈ S−

ηi (εi − λi )

i=1
2 Note that in [12], the authors addressed a much simpler problem where
ai = 1, and εi = ∞, i = 1, . . . , n.

230

z=

n


a i λi =

2
i∈S+

i=1

=



2
j∈S+



εj +



3
k∈S+



λi −
3
S+

(vk − θ) −


2
i∈S−



2
j∈S−



Algorithm 3 Projected Subgradient Method for Problem 3

λi
3
S−

εj −



Input: x1 , . . . , xn ; step size τ ; C1 , C2 ; N2 ; ĉ; initial
estimate of λ
Output: λ
1: Deﬁne S+ = {n1 + 1, . . . , n} and S− = {1, . . . , n1 }
2: for step = 1 to N2 do
3:
Calculate ∇ as follows:

(vk + θ)

3
k∈S−

Solving this equation regarding θ, we get Equation 3.
Based on Lemma 1 and Lemma 2, to solve Problem 4, we
1
2
1
, S+
, S−
gradually increase the number of elements in S+
2
and S− , calculate θ accordingly, and determine the value of
λ which has the smallest value of 12 λ − v22 . Alg. 3 gives
the details for solving Problem 3 in RACH. In Step 3 of
Alg. 3, we calculate the gradient of the objective function
in Problem 3 at the current value of λ and ĉ; then in Step 4,
λ is updated via gradient ascent to obtain v. The remaining
steps (Step 5- 16) are for the projection step (i.e., for solving
Problem 4): in Step 5, we calculate the vector v using both
v and the upper bounds; to calculate the projection of v on
1
2
, S+
,
X , in Step 7 to Step 15, we try different sizes for S+
1
2
S− and S− , calculate θ and λ accordingly, and determine
the projection of v based on the distance between v and
1
2
, S+
,
w, where w is calculated based on the current sets S+
3
1
2
3
S+ , S− , S− and S− .

l = 1, . . . , n1 :
∇l = −xl 2 + ĉ2
n
n1
2( j=n1 +1 λj (xj )T − i=1
λi (xi − ĉ)T )(xl − ĉ)
n
+
j=n1 +1 λj
l = n1 + 1, . . . , n :
n
n1
( j=n1 +1 λj (xj )T − i=1
λi (xi − ĉ)T )
2

·
∇l = xl  −
n
( j=n1 +1 λj )2
n1
n


(
λj (2xl − xj ) +
λi (xi − ĉ))
j=n1 +1

4:
5:

C. RACH for Problem 1
Algorithm. Now, we are ready to present the RACH
algorithm (Alg. 4) to solve Problem 1. It is given the training
data, the step size τ , C1 , C2 , and the numbers of iteration
steps N1 , N2 . (Note that N2 is used in Alg. 3 in Step 3
of RACH.) The output is the unlabeled examples whose
predicted class labels are −1. RACH works as follows. It
ﬁrst initializes the center c and the Lagrange multipliers λ
using Alg. 2; then it repeatedly forms Problem 3 based on the
current estimate of the center c, and applies Alg. 3 to solve
it, which is based on the projected subgradient method; after
solving Problem 3, the center c is updated using Equation 1;
ﬁnally, we classify the unlabeled examples based on their
corresponding Lagrange multipliers λk . The last step can be
justiﬁed as follows. In Problem 1, for the unlabeled instances
xk , k = n1 + n2 + 1, . . . , n, if xk − c < R, λk = 0, then
yk = −1; if xk − c = R, 0 < λk < C2 , then yk = −1; if
xk − c > R, λk = C2 , then yk = 1.
Concise Representation of the Minority Class. From
Alg. 4, we can also compute the radius R of the hyberball, which is the maximum distance from the center c to
xn1 +1 , . . . , xn whose Lagrange multipliers are less than the
corresponding upper bounds. The resulting hyberball (fully
described by the center c and the radius R) provides a concise representation for the minority class. This representation
can help us better understand the minority class. We can
also use it to predict an unlabeled example as follow: if it
is within the hyberball (i.e., its distance to the center c is
less than R), we classify it as a rare example; otherwise, it
belongs to the majority class.

i=1

Update λ via gradient ascent to obtain: v = λ + τ ∇
Calculate v as follows:
vi = vi − C1 , i = 1, . . . , n1
vj = −∞, j = n1 + 1, . . . , n1 + n2

vk = vk − C2 , k = n1 + n2 + 1, . . . , n

6:
7:
8:

9:
10:

11:

12:
13:

14:
15:
16:

231

Set D = ∞
for I1 = 1, I2 = 1, I3 = 1, I4 = 1 to I1 = |S+ | +
1, I2 = |S− | + 1, I3 = |S+ | + 1, I4 = |S− | + 1 do
1
Let S+
⊂ S+ denote the subset of indices in S+
such that the corresponding elements in v are no
2
⊂ S+
larger than the I1th largest element; let S+
denote the subset of indices in S+ such that the
corresponding elements in v are no smaller than
the I3thsmallest element

1
2
2
S+
{n1 +1, . . . ,n1 +n2 } 
= ∅,
If S+

= ∅ or S+
3
1
2
= S+ \(S+
)
continue; otherwise, S+
S+
1
Let S−
⊂ S− denote the subset of indices in S−
such that the corresponding elements in v are no
2
⊂ S−
larger than the I2th largest element; let S−
denote the subset of indices in S− such that the
corresponding elements in v are no smaller than
smallest element
the I4th 
1
2
3
If S−

= ∅, continue; otherwise, S−
=
S−

1
2
S− \(S− S− )

k∈S 3

vk −

k∈S 3

2
2
vk +|S+
|C2 −|S−
|C1 −1

+
−
Calculate θ =
3 |+|S 3 |
|S+
−
 1
1
Calculate w as follows: wi = 0, i ∈ S+
S− ;
2
2
w i = C 2 , i ∈ S+ ; w i = C 1 , i ∈ S− ; w i = v i −
3
3
; wi = vi + θ, i ∈ S−
θ, i ∈ S+
If v − w < D, set λ = w and D = v − w.
end for
end for

Computational Complexity of RACH. It can be shown that
the time complexity of RACH is O(N1 N2 (n − n1 )2 (n1 )2 ).
In practice, we can reduce the running time in the following
three ways. First, we ﬁnd that in our experiments RACH
converges very quickly, often within a few tens of iterations.
Second, in the applications that we are interested in, there
are very few labeled examples from both the majority and
the minority classes. A typical value for n1 is a few tens, and
a typical value for n2 is less than 10. Finally, recall that in
Section III, we have applied Alg. 1 to ﬁlter out the unlabeled
examples which are far away from the minority class. After
this operation, only a small portion of the unlabeled data
(typically less than 10%) is passed on to Alg. 4.
Algorithm 4 RACH: Rare Category Characterization
Input: x1 , . . . , xn ; step size τ ; C1 , C2 ; N1 , N2
Output: unlabeled examples whose predicted class labels
are −1
1: Initialize the hyberball center c and the Lagrange multipliers λ by Alg. 2
2: for step = 1 to N1 do
3:
Update the Lagrange multipliers λ by Alg. 3 based
on the current center c
4:
Update the center c based on Equation 1
5: end for
6: for k = n1 + n2 + 1 to n do
7:
if λk < C2 then
8:
set yk = −1
9:
else
10:
set yk = 1
11:
end if
12: end for

(a) Input data with a few labels

(b) Input data with a few labels
Figure 1. Rare category characterization on the synthetic data set. (Best
viewed in color.)

A. Synthetic Data Set
Fig. 1(a) shows a synthetic data set where the majority
class has 3000 examples drawn from a Gaussian distribution,
and the 4 minority classes correspond to 4 different shapes
with 84, 150, 267, and 280 examples respectively. In this
ﬁgure, the green circles represent labeled examples from
the minority classes, and the red pluses represent labeled
examples from the majority class. Here we construct 4
binary problems (the majority class vs. each minority class).
Fig. 1(b) shows the classiﬁcation result where the green dots
represent the rare examples, and the red dots represent the
majority class examples. From this ﬁgure, we can see that
almost all the rare examples have been correctly identiﬁed
except for a few points on the boundary.

V. K ERNELIZED RACH A LGORITHM
In this section, we brieﬂy introduce how to generalize
RACH to the high-dimensional feature space induced by
kernels. The major beneﬁt of kernelizing the RACH algorithm is that, instead of enclosing the rare examples by a
minimum-radius hyperball, we can now use more complex
shapes, which make our algorithm more ﬂexible and may
lead to more accurate classiﬁcation results.
Compared with the original Alg. 4 which is designed
for the input space, in the kernelized RACH algorithm, we
only need to make the following changes. First, instead of
directly calculating the center c, we keep
n a set of coefﬁcients
γi , i = 1, . . . , n such that c =
i=1 γi xi . Therefore,
Step 1 of Alg. 4 generates a set of initial coefﬁcients
for c, and Step 4 updates the coefﬁcients
of c based on
n
γ
K(xi , x), and
Equation 
1. In 
this way, c · x =
i
i=1
n
n
γ
γ
K(x
,
x
),
where
K(·, ·) is the
c2 =
i
j
i
j
i=1
j=1
kernel function. Next, notice that Alg. 4 and Alg. 3 are dependent on the examples only through the inner products or
distances, which can be replaced by the kernel calculation.
VI. E XPERIMENTAL R ESULTS
In this section, we present some experimental results
showing the effectiveness of RACH.

B. Real Data Sets
We also did experiments on 7 real data sets, which are
summarized in Table I. For each data set, we construct
several binary problems consisting of one majority class
and one minority class, and vary the percentage of labeled
examples. For the sake of comparison, we also tested
the following methods: (1) KNN (K-nearest neighbor); (2)
Manifold-Ranking [31]; (3) Under-Sampling the majority
class until the two classes are balanced and training with
SVM; (4) TSVM [20] with different costs for the examples

232

other hand, the performance of the other methods varies a
lot across the different data sets. For example, in Fig. 2(a),
the performance of KNN is only worse than RACH; whereas
in Fig. 3(b), the performance of KNN is worse than TSVM,
and as the percentage of labeled examples increases, KDD
performs not as good as Under-Sampling.

from different classes; (5) SVM-Perf [21]. We used the
RBF kernel in RACH. All the parameters are tuned by cross
validation. The comparison results in terms of the F-score
(harmonic mean of precision and recall) of the minority class
are shown in Fig. 2 to Fig. 8. Under each ﬁgure, the numbers
outside the brackets are the class indices included in the
binary problem, and the numbers inside the brackets are the
number of examples from each class. Notice that in all the
ﬁgures, the label percentage ranges from 5% to 25%. This
is because in our applications, we are only interested in the
cases where the percentage of labeled examples is small.

1

0.9

F−score

0.8

Table I
S UMMARY OF THE DATA SETS

Data Set
No. of Examples
No. of Features
Data set
No. of Examples
No. of Features

Abalone
4177
7
Page Blocks
5473
10

Ecoli
336
7
Shuttle
4515
9

0.6

0.5

Glass
Yeast
214
1484
9
8
20 Newsgroups
18774
61188

0.4

0.05

0.1

0.15

0.2

0.25

Label Percentage

(a) 1 (143) vs. 2 (77)
1
0.9

1

0.8

0.9

0.7

F−score

0.8
0.7

F−score

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.7

0.6
0.5

0.6
0.5
0.4
KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.3

0.4

0.2

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.3
0.2
0.1
0
0.05

0.1

0.15

0.2

0.1
0
0.05

0.1

0.15

0.2

0.25

Label Percentage
0.25

Label Percentage

(b) 2 (77) vs. 3 (52)
Figure 3. Ecoli data set.

(a) 1 (689) vs. 14 (67)
1

VII. C ONCLUSION
In this paper, we proposed the RACH algorithm to address
the problem of rare category characterization, which is
used for understanding and correctly classifying the rare
categories. We addressed the challenging case where the data
set is highly skewed and the minority class is non-separable
from the majority class. The basic idea is to enclose the rare
examples with a minimum-radius hyperball by exploring the
compactness property of the minority class. We formulate
it as an optimization problem and present the effective
optimization algorithm RACH. In RACH, we repeatedly (1)
convert the original problem into a convex optimization
problem, and (2) solve it in its dual form by a projected
subgradient method. Furthermore, we generalize RACH to
the high-dimensional feature space induced by kernels. In
the majority of our experiments RACH outperformed all
other methods, and in the remaining ones it was virtually
indistinguishable from the top performer.
R EFERENCES

0.98
0.96

F−score

0.94
0.92
0.9
0.88
0.86

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.84
0.82
0.8
0.05

0.1

0.15

0.2

0.25

Label Percentage

(b) 2 (634) vs. 4 (57)
Figure 2. Abalone data set.

From these ﬁgures, we can see that in the majority of
our experiments RACH outperformed all other methods,
and in the remaining ones it was virtually indistinguishable
from the top performer, such as Fig. 3(b) and Fig. 7(a). In
particular, the performance of RACH is better than SVMPerf in most cases, although the latter directly optimizes
the F-score. This might be due to the fact that the objective
function of SVM-Perf is only an upper bound of the training
loss regularized by the L2 norm of the weight vector. And
also, SVM-Perf is designed for the purpose of a general
classiﬁcation problem; and it might ignore the skewness and
the compactness properties of the minority class. On the

[1] C. C. Aggarwal and P. S. Yu. Outlier detection for high
dimensional data. In SIGMOD, pages 37–46, 2001.
[2] D. Barbará, N. Wu, and S. Jajodia. Detecting novel network
intrusions using bayes estimators. In SDM, April 2001.

233

1

0.9

0.95

0.8

0.9

0.7

0.85

F−score

F−score

0.6
0.5
0.4
0.3

0.1
0
0.05

0.1

0.15

0.2

0.7
0.65

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.2

0.8
0.75

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.6
0.55
0.5
0.05

0.25

0.1

0.15

0.2

0.25

Label Percentage

Label Percentage

(a) 1 (463) vs. 6 (44)

(a) 1 (70) vs. 3 (17)
0.9
1
0.8

0.9

0.7

0.8

0.6

F−score

F−score

0.7
KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.6
0.5
0.4

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.5
0.4
0.3

0.3

0.2

0.2
0.1
0.1
0
0.05

0
0.05
0.1

0.15

0.2

0.25

0.1

0.15

0.2

0.25

Label Percentage

Label Percentage

(b) 3 (244) vs. 8 (30)
Figure 5. Yeast data set.

(b) 1 (70) vs. 5 (9)
Figure 4. Glass data set.

[12] J. Duchi, S. Shalev-Shwartz, Y. Singer, and T. Chandra.
Efﬁcient projections onto the l1 -ball for learning in high
dimensions. In ICML, pages 272–279, 2008.

[3] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004.
[4] V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection:
A survey. ACM Computing Surveys, 2009.

[13] H. Dutta, C. Giannella, K. D. Borne, and H. Kargupta.
Distributed top-k outlier detection from astronomy catalogs
using the demac system. In SDM, 2007.

[5] D. H. Chau, S. Pandit, and C. Faloutsos. Detecting fraudulent
personalities in networks of online auctioneers. In PKDD,
pages 103–114, 2006.

[14] EURODIS. Rare diseases: Understanding this public health
priority, 2005.

[6] N. Chawla, N. Japkowicz, and A. Kolcz, editors. Proceedings
of the ICML’2003 Workshop on Learning from Imbalanced
Data Sets, 2003.

[15] S. Fine and Y. Mansour. Active sampling for multiple output
identiﬁcation. In COLT, pages 620–634, 2006.
[16] N. Görnitz, M. Kloft, and U. Brefeld. Active and semisupervised data domain description. In ECML/PKDD (1),
pages 407–422, 2009.

[7] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P.
Kegelmeyer. Smote: Synthetic minority over-sampling technique. J. Artif. Intell. Res. (JAIR), 16:321–357, 2002.

[17] J. He and J. Carbonell. Nearest-neighbor-based active learning for rare category detection. In NIPS. 2007.

[8] N. V. Chawla, N. Japkowicz, and A. Kotcz. Editorial: special
issue on learning from imbalanced data sets. SIGKDD Explor.
Newsl., 6(1):1–6, 2004.

[18] Z. He, X. Xu, and S. Deng. An optimization model for outlier
detection in categorical data. CoRR, abs/cs/0503081, 2005.

[9] N. V. Chawla, A. Lazarevic, L. O. Hall, and K. W. Bowyer.
Smoteboost: Improving prediction of the minority class in
boosting. In PKDD, pages 107–119, 2003.

[19] N. Japkowicz, editor. Proceedings of the AAAI’2000 Workshop on Learning from Imbalanced Data Sets, 2000.

[10] D. A. Cieslak and N. V. Chawla. Start globally, optimize locally, predict globally: Improving performance on imbalanced
data. In ICDM, pages 143–152, 2008.

[20] T. Joachims. Transductive inference for text classiﬁcation
using support vector machines. In ICML, pages 200–209,
1999.

[11] S. Dasgupta and D. Hsu. Hierarchical sampling for active
learning. In ICML, pages 208–215, 2008.

[21] T. Joachims. A support vector method for multivariate
performance measures. In ICML, pages 377–384, 2005.

234

1
0.9

0.8

0.8

0.7

0.7

0.6

0.6

F−score

F−score

1
0.9

0.5
0.4
KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.3
0.2
0.1
0
0.05

0.1

0.15

0.2

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.5
0.4
0.3
0.2
0.1
0
0.05

0.25

0.1

Label Percentage

0.9

0.95

0.8

0.9

0.7

0.85

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.5
0.4

0.25

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.8
0.75
0.7
0.65

0.3
0.2

0.6

0.1

0.55

0
0.05

0.2

(a) 3 (132) vs. 2 (37)
1

F−score

F−score

(a) 2 (329) vs. 4 (88)
1

0.6

0.15

Label Percentage

0.1

0.15

0.2

0.5
0.05

0.25

0.1

0.15

0.2

0.25

Label Percentage

Label Percentage

(b) 2 (37) vs. 7 (11)
Figure 7. Shuttle data set.

(b) 2 (329) vs. 5 (115)
Figure 6. Page blocks data set.

[22] C. X. Ling and C. Li. Data mining for direct marketing:
Problems and solutions. In KDD, pages 73–79, 1998.
0.45

[23] S. Papadimitriou, H. Kitagawa, P. B. Gibbons, and C. Faloutsos. Loci: Fast outlier detection using the local correlation
integral. In ICDE, pages 315–327, 2003.

0.4
0.35

F−score

0.3

[24] D. Pelleg and A. W. Moore. Active learning for anomaly and
rare-category detection. In NIPS. 2004.

0.25
0.2
0.15

[25] S. Ramaswamy, R. Rastogi, and K. Shim. Efﬁcient algorithms
for mining outliers from large data sets. In SIGMOD, pages
427–438. ACM, 2000.

KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.1
0.05
0
0.05

0.1

0.15

0.2

0.25

Label Percentage

[26] B. Schölkopf, J. C. Platt, J. Shawe-Taylor, A. J. Smola,
and R. C. Williamson. Estimating the support of a highdimensional distribution. Neural Computation, 13(7):1443–
1471, 2001.

(a) comp (4852) vs. misc.forsale
(964)
0.45
0.4

[27] Y. Sun, M. S. Kamel, and Y. Wang. Boosting for learning
multiple classes with imbalanced class distribution. In ICDM,
pages 592–602, 2006.

0.35

F−score

0.3

[28] P. Vatturi and W.-K. Wong. Category detection using hierarchical mean shift. In KDD, pages 847–856, 2009.

0.25
0.2
0.15
KNN
Manifold−Ranking
Under−Sampling
TSVM
RACH
SVM−Perf

0.1

[29] J. Wu, H. Xiong, P. Wu, and J. Chen. Local decomposition
for rare class analysis. In KDD, pages 814–823, 2007.

0.05
0
0.05

0.1

0.15

0.2

0.25

Label Percentage

[30] D. Yu, G. Sheikholeslami, and A. Zhang. Findout: ﬁnding
outliers in very large datasets. Knowl. Inf. Syst., 4(4):387–
412, 2002.

(b) rec (3968) vs. comp.os.mswindows.misc (963)
Figure 8. 20 Newsgroups data set.

[31] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and
B. Schölkopf. Ranking on data manifolds. In NIPS, 2003.

235

Graph-Based Semi-Supervised Learning as a Generative Model
Jingrui He

Jaime Carbonell
Yan Liu
Carnegie Mellon University
School of Computer Science
5000 Forbes Avenue, Pittsburgh 15213

jingruih@cs.cmu.edu

jgc@cs.cmu.edu

Abstract
This paper proposes and develops a new
graph-based semi-supervised learning method.
Different from previous graph-based methods that
are based on discriminative models, our method is
essentially a generative model in that the class
conditional probabilities are estimated by graph
propagation and the class priors are estimated by
linear regression. Experimental results on various
datasets show that the proposed method is superior
to existing graph-based semi-supervised learning
methods, especially when the labeled subset alone
proves insufficient to estimate meaningful class
priors.

1

Introduction

In many real world classification tasks, the number of labeled
instances is very few due to the prohibitive cost of manually
labeling every single data point, while the number of unlabeled data can be very large since they are easy to obtain.
Traditional classification algorithms, known as supervised
learning, only make use of the labeled data, therefore prove
insufficient in these situations. To address this problem,
semi-supervised learning has been developed, which makes
use of unlabeled data to boost the performance of supervised
learning. In particular, graph-based semi-supervised learning algorithms have proved to be effective in many applications, such as hand-written digit classification [Zhu et al.,
2003; Zhu et al., 2005], medical image segmentation [Grady
and Funka-Lea, 2004], word sense disambiguation [Niu, Ji
and Tan, 2005], image retrieval [He et al., 2004], etc.
Compared with other semi-supervised learning methods,
such as TSVM [Joachims, 1999], which finds the hyperplane
that separates both the labeled and unlabeled data with the
maximum margin, graph-based semi-supervised learning
methods make better use of the data distribution revealed by
unlabeled data. In graph-based semi-supervised learning, a
weighted graph is first constructed in which both the labeled
and unlabeled data are represented as vertices. Then many of
these methods can be viewed as estimating a function on the
graph [Zhu, 2005]. Based on the assumption that nearby
points in the feature space are likely to have the same label,
the function is defined to be locally smooth and consistent

yanliu@cs.cmu.edu

with the labeled data. Finally, the classification labels are
obtained by comparing the function value and a pre-specified
threshold. For example, in the Gaussian random fields and
harmonic function method, the learning problem is formulated in terms of a Gaussian random field on the graph, and
the mean of the field serves as the function [Zhu et al., 2003].
Another example is the local and global consistency method,
in which the function at each point is iteratively determined
by both the information propagated from its neighbors and its
initial label [Zhou et al., 2004]. Yet another example is the
graph mincut method whose function corresponds to partitioning the graph in a way that roughly minimizes the number
of similar pairs of examples that are given different labels
[Blum and Chawla, 2001]. In the mincut method, the function can only take binary values.
Up till now, graph-based semi-supervised learning methods are generally approached from the discriminative perspective [Zhu, 2005] in that the function on the graph corresponds to posterior probabilities in one way or another. In
the discriminative setting, however, the use of unlabeled data
does not necessarily guarantee better decision boundaries. In
addition, there is no clear explanation why the function on
the graph should correspond to posterior probabilities from
statistics point of view.
In this paper, we propose a new graph-based
semi-supervised learning method from the generative model
perspective. Specifically, the class conditional probabilities
and the class priors are estimated from the weighted graph.
The potential advantages involve several aspects: first, it can
be theoretically justified that in the ideal cases where the two
classes are separable, the output functions in terms of certain
eigenvectors of the graph converge to the class conditional
probabilities as the number of training data goes to infinity.
In non-ideal cases, our functions still provide a good estimate
of the class conditional probabilities. Finally, the estimated
class priors make use of both the labeled and unlabeled data,
which compensate for the lack of label information in many
practical situations. Experimental results show that our approach leads to better performance than other existing
graph-based methods on a variety of datasets. Hence we can
claim both stronger theoretical justification and better empirical results.
The rest of the paper is organized as follows. In Section 2
and Section 3, we introduce how to estimate the class condi-

IJCAI-07
2492

tional probabilities and the class priors respectively. Section
4 deals with the out-of-sample problem, followed by an outline of the algorithm in Section 5. Then the experimental
results are shown in Section 6. Finally, we give conclusion
and hint on future work in Section 7.

2

Estimating Class Conditional Probabilities

2.1 Notation
In a binary classification problem, suppose that we are given
d
a set of n training samples: x1 , xn
. The first nl samples are labeled, including nl1 positive ( yi 1, i 1, , nl1 ) and
nl 0 nl nl1 negative ( yi 0, i nl1 1, , nl ) samples. The
remaining nu n nl samples are unlabeled. Our goal is to
predict the class labels of these nu points by computing the
posterior probability P yi xi .
By Bayes rule, we have
(1)

0.5 . In our genera-

tive model, in order to calculate P yi | xi , we need to estimate both p xi yi and p y . In this section, we focus on
estimating the class conditional probability p xi yi , and the
estimation of p y will be discussed in the next section.
n n
with
We first form an affinity matrix W
Wij
xi , x j , where
xi , x j is a non-negative function

measuring the direct similarity between xi and x j . Then
Dii

the
diagonal
w , i 1, n , and S D 1/ 2WD
1 ij
D

j

D1 1/ 2W1D1 1/ 2
0

0

S1
0

S

S0

0
D0 1/ 2W0 D0 1/ 2

(4)

The following theorem connects the class conditional
probabilities with the diagonal elements of D .
Theorem 1. If xi , x j
xi x j
Vn , where n and
n

sup

following
, lim

u

u

u

,

yi is predicted to be 1 iff P yi 1| xi

n

where W1 and W0 represent the sub-matrices corresponding
to the positive and negative samples respectively, and 0
represents zero matrix. If the total number of positive
(negative) samples in the training set is n1 ( n0 ), W1 ( W0 ) is
an n1 n1 ( n0 n0 ) square matrix. Let D1 and D0 be two
diagonal matrices, the diagonal elements of which are the
row sums of W1 and W0 . Then S can be written as

the

yi ' 0,1

define

(3)

Vn are positive parameters, and the function

p( xi | yi ) P( yi )
p ( xi | yi ') P( yi ')

P yi | xi

W1 0
0 W0

W

as

1/ 2

matrix,
where
. Finally define

and f as two n -dimensional vectors. The element of
( f ) is set to 1 iff the corresponding point is a positive
(negative) labeled one.

conditions:
d

u

u

i 1 i

u

0

0 , lim Vn
n

,

satisfies
u du 1

0 , lim nVn

,

, as

n

the number of examples n goes to infinity, Dii n y coni

verges to p xi yi .
The proof of the theorem is straightforward and therefore
we put it in the appendix. Notice that this theorem is similar
to a result in kernel density estimation. The difference is that
in kernel density estimation, we only have labeled data from
a single class; while in our situation, we have both labeled
and unlabeled data, and we could estimate the class conditional distributions of the two classes at the same time.
Suppose that the labeled data are noise-free. According to
Theorem 1, we can use Dii to approximate the class conditional probability of xi given the observed label yi . However, for the unlabeled points, we do not know if Dii corre-

f

sponds to p xi yi 1 or p xi yi

f

lem, we can make use of the eigenvectors of S .
It is easy to show that the largest eigenvalue of S1 and S0
is 1, and if W1 and W0 form a connected graph respectively,

2.2 The Ideal Case
To start with, let us first consider the ideal case where the two
classes are far apart. In this case, we have the following
equation:
p x

P y 1 p x y 1

P y

0 p xy

0

where y x is the observed class label of data point x .
Based on this assumption, if xi and x j are from two different classes, the corresponding Wij

the corresponding eigenvectors would be v

0 . Therefore if we

knew the labels of all the samples and put together the samples from the same class, the affinity matrix W , and thus the
symmetric matrix S would be block-diagonal. To be specific, let

D11/ 2 1 and

D01/ 2 1 [Chung, 1997].

Based on v and v , we can
construct two eigenvectors of S with eigenvalue 1:
v

(2)

P yx p x yx

0 . To address this prob-

v1

vT

0

T

, v0

0 vT

T

(5)

where 0 is a zero vector. Notice that if we square v1 and v0
by elements to get v12 and v02 , and then add them up, we get
(6)
v12 v02 D1 1 D0 1 D 1
Obviously, v12 and v02 correspond to p xi yi 1 and
p xi yi

0

equal to Dii .

IJCAI-07
2493

respectively, and their non-zero elements are

To get v and v , we perform f
S f
and
f
S f until convergence. Since the initial value of f
is not orthogonal to v1 (the elements of f and v1 are
non-negative), f will converge to v1 . Similarly, f will
2

converge to v0 . Therefore, upon convergence, f i

2

( fi

)

is in proportion to the class conditional probability of the
positive (negative) class. After normalizing f i

2

( fi

2

)

so that it sums to 1, we have an empirical estimation of
p xi yi 1 ( p xi yi 0 ), which converges to its true value
as n goes to infinity.
Figure 1 gives an example of density estimation in the
ideal case. Figure 1(a) shows the training data, where the two
moons represent two classes, and each class has one labeled
example marked as star. Figure 1(b) and 1(c) show the estimated class conditional distributions of the two classes.

S f and
sponds to eigenvalue 1. If we still iterate f
f
S f until convergence, both f and f will converge to the same eigenvector. On the other hand, the opS f and f
S f can be seen as the
eration of f
labeled data gradually spreading their information to nearby
points. If the iteration steps are unlimited, every data point
will be equally influenced by the positive and negative labeled data, leading to the same value of f and f .
To solve this problem, in our algorithm, we have designed
a stopping criterion, and the iteration process is stopped once
the criterion is satisfied. To be more specific, when estimating the class conditional probabilities of the positive class,
we could get an estimate of p xi yi 1 in each iteration step

(by normalizing f i

2
0
-2
-4
-5

0

5

10

(a)

(b)
(c)
Figure 1. Density Estimation in the Ideal Case. (a): training data; (b)
and (c) class conditional distributions

2.3 The General Case
In the general cases, the two classes are not far apart, and we
have the following theorem.
Theorem 2. If xi , x j satisfies the conditions in Theorem 1,
as the number of samples n goes to infinity, Dii n converges to p xi yi 1 P y 1 p xi yi 0 P y 0
The proof to this theorem is quite similar to Theorem 1. So
we omit the details here. It can be seen easily that Theorem 1
is a special case of Theorem 2 when the two classes are far
apart, i.e.
lim Dii n

p xi yi

1 P y 1 , if yi

1

lim Dii n

p xi yi

0 P y

0

n

n

0 , if yi

(7)

Equation (7), together with the fact that lim n1 n P y 1 ,
n
leads to Theorem 1.
In the general cases, W tends to form one connected graph
instead of two, and S only has one eigenvector that corre-

so that it sums to 1). By summing up

this probability for negative labeled samples, we have the
average likelihood of these samples in the positive class:
L

6
4

2

nl
i n

1

p xi yi

1

n . We stop the iteration when the

second derivative of L with respect to the iteration steps
crosses 0. This criterion can be justified as follows: in the
initial iteration steps, only a few negative data get positive
score from their nearby positive labeled points, so the rate at
which L increases is very low; as the iteration proceeds,
those negative data have accumulated high scores and
propagate to the majority of negative points, so the rate
gradually increases; finally, as f begins to converge, its
value at each data point becomes stable, so the rate decreases
until it reaches 0. If we plot the curve of L with respect to
the number of iteration steps, the shape would be convex first,
and then concave until convergence (Figure 2(b)). Notice
that in the initial iteration steps, the positive points, which are
far away from the positive labeled points but connected to
them via some kind of manifold, cannot get positive scores.
If the algorithm stops at this stage, it may not fully explore
the data distribution and cause misclassification on certain
clusters of data. Therefore we choose the transition point
between convex and concave as the stopping point in order to
trade off between prematurity and excessive propagation.
The stopping criterion for the negative class can be derived
similarly, i.e. L

nl 1
i 1

p xi yi

0

nl1 . A key point in our

algorithm is that the estimation of the class conditional
probabilities of the two classes is independent, i.e. the
numbers of iteration steps when the two stopping criterions
are satisfied are not necessarily the same.
Figure 2 gives an example of density estimation in the
general case showing the effectiveness of our criterion. This
example is quite similar to the one shown in Figure 1 except
that the two classes are not far apart. Figure 2(b) shows the
value of L (the upper curve) and L (the lower curve) in
each iteration step. The arrows point to the positions in the
curves where the two criterions are satisfied. Figure 2(c) and
2(d) show the estimated class conditional distributions of the
two classes. Although there are small gaps in the middle of
the distributions, the moon structure is recovered fairly well.

IJCAI-07
2494

3

8

x 10

-3

4

2.5

6
4

d
To classify a data point x
that is not present during the
training stage, we first calculate its class conditional probabilities via kernel regression:

L+

2

L-

1.5

2

n

1

0

4
-5

0

5

10

200

400

600

800

(b)

(d)
(c)
Figure 2. Density Estimation in the Generation Case. (a): training
data; (b): L and L in each iteration; (c) and (d): class conditional
distributions.

Note that the stopping criterion discussed above is based
on simple heuristics. Currently we are trying to design a
stopping criterion in a more principled manner.

3.

Initialize f and f . The element of f ( f ) is set
to 1 if the corresponding point is a positive (negative)
labeled one, and 0 otherwise.
S f , f
S f .
Update f

4.

Assign p xi yi 1

2.

n
i 1

5.

(8)
However, when the number of labeled data is small, the
estimated class conditional probabilities may not be very
accurate, and thus p̂ is not very reliable. To solve this
problem, we use a beta distribution as the prior distribution
for P y 1 , the parameters of which are p̂ and 1 pˆ . Then
the estimate of P y 1 based on the labeled set:
0 1 pˆ , i 1,

pˆ nl1
,P y
1 nl

0

1 P y 1

,n

(9)

which is equivalent to smoothing the proportion of the positive and negative samples in the labeled set. When the
number of labeled data is small, unlabeled data can be fully
exploited to compensate for the proportion in the labeled set
that is not the same as the class priors; when the number of
labeled data is large, labeled data will dominate the estimation of the class priors.

6.

so
0

p xi yi

2

fi

, p xi yi

0

n

that

i 1

( fi ) 2 , and

p xi yi

1

1

,

1.

Calculate the average likelihood of negative (positive)
labeled points in the positive (negative) class:
L

form a linear regression problem, the solution of which is
equal to the least squares estimator of P y 1 .

P y 1

The Algorithm

normalize

In this section, we focus on estimating the class prior P y .
Existing graph-based semi-supervised learning methods only
use the labeled set to estimate the class priors, either explicitly [Zhu et al., 2003] or implicitly [Zhou et al., 2004]. Obviously, in real applications, the proportion of positive and
negative labeled data is often far from the true class priors.
In our algorithm, we use both the labeled and unlabeled
data to estimate the class priors. According to Theorem 2,
once we have estimated the class conditional probability
p xi yi , we can feed them into the following equations and

p xi yi

(10)

x, xi

The procedures for estimating p xi yi and P y are summarized in Table 1 and Table 2 respectively.
n n
1. Form the affinity matrix W
, where
Wij
xi , x j . Calculate D and S .

Estimating Class Priors

1 pˆ

p xi y

Using these class conditional probabilities and the class
priors obtained during the training stage, we can calculate the
posterior probability and make a prediction.

5

p xi yi

n
i 1

0
0

(a)

Dii n

x, xi

i 1

p xy

0.5

2

3

Prediction of New Testing Data

nl
i nl 1 1

p xi yi 1

nl 1

nl 0 ( L

i 1

p xi yi

0

nl1 ).

Go to step 4 unless one of the following conditions is
satisfied:
a. L ( L ) remains at 0, and f ( f ) has converged;
b. L ( L ) does not remain at 0, and the second derivative of L ( L ) with respect to the iteration steps
crosses 0.
Output p xi yi 1 and p xi yi 0 .
Table 1. Description of Estimation for p xi yi

1.

Solve the following linear regression problem for the
least squares estimator p̂ of P y 1 :
pˆ p xi yi

2.

1

1 pˆ

p xi yi

0

Dii n , i 1,

,n

Calculate the class priors as the smoothed proportion of
the positive and negative samples in the labeled set
P y 1

pˆ nl1
,P y
1 nl

0

1 P y 1

Table 2. Description of Estimation for P y

6

Experimental Results

In this section, we present the comparative experimental
results on two datasets: Cedar Buffalo binary digits database
[Hull, 1994], and a document genre-classification dataset
[Liu et al., 2003]. Our algorithm is compared with two other

IJCAI-07
2495

graph-based semi-supervised learning methods: Gaussian
random fields [Zhu et al., 2003] and the local and global
consistency method [Zhou et al., 2004]. We did not compare
with supervised learning methods, such as one nearest
neighbor, since they have been proved to be less effective
than Gaussian random fields based on experimental results
[Zhu et al., 2003].
We have designed two kinds of experiments: balanced and
unbalanced. In the balanced case, the ratio of labeled points
from each class is always the same as the class priors; in the
unbalanced case, if not explained otherwise, we fix the total
number nl of labeled points, and perturb the number of
positive labeled points around nl 2 with a Gaussian distribution of mean 0 and standard deviation nl 10 . In each
experiment, we gradually increase the number of labeled data,
perform 20 trials for each labeled data volume, and average
the accuracy at each volume point.

case, while the performance of our algorithm is comparable
to the balanced case. This is because the class mass normalization procedure adopted in Gaussian random fields
depends on the labeled set only to estimate the class priors;
while our algorithm makes use of both the labeled and the
unlabeled set to estimate the class priors. Therefore, it is
more robust against the perturbation in the proportion of the
positive and negative data in the labeled set.

6.2 Genre Dataset
Genre classification is to classify the documents based on its
writing styles, such as political articles and movie reviews.
The genre dataset that we use consists of documents from 10
genres, including biographies (b), interview scripts (is),
movie reviews (mr), product reviews (pr), product press
releases (ppr), product descriptions on store websites (pd),
political articles on newspapers (pa), editorial papers on
politics (ep), news (n), and search results from multiple
search engines using 10 queries (sr). We randomly select
380 documents from each category to compose the whole
dataset of 3800 documents. Each document is processed into
a “tf.idf” vector, which is generated based on the top 10,000
most frequent words in this dataset after stemming, with the
header
and
stop
words
removed.
Here

6.1 Cedar Buffalo Binary Digits Database
We first perform experiments on Cedar Buffalo binary digits
database [Hull, 1994] including two classification tasks:
classifying digits “1” vs “2”, with 1100 images in each class;
and odd vs even digits, with 2000 images in each class (400
images for each digit). The data we use are the same as those
used
in
[Zhu
et
al.,
2003].
Here
exp

xi

xj

2

2

2

, where

xi , x j

is the

0.85
0.8

0.9

accuracy

accuracy

0.75
0.8

Our Algorithm
Gaussian Random Fields

0.7

0.7
0.65

Local and Global Consistency

0.5
0

Gaussian Random Fields
Local and Global Consistency

0.55
20

40

60

80

1

0.5

0.7

Our Algorithm

0.6

0.6

20

labeled set size

40

60

80

1

labeled set size

0.85

0.9

0.8

Our Algorithm
0.7

Gaussian Random Fields
Local and Global Consistency

0.6

Our Algorithm
Gaussian Random Fields
Local and Global Consistency

0.7
0.65

0.5

1

0.8

0.5

1

20

40

60

80

1

labeled set size

(a)
(b)
Figure 4. Unbalanced Classification. (a): 1 vs 2; (b) odd vs even

Figure 3(a) and 3(b) show the results of the two classification tasks in the balanced case. The performance of our
algorithm is comparable with Gaussian random fields, and
both of them are much better than the local and global consistency method. Figure 4(a) and 4(b) show the results in the
unbalanced case. In this situation, the performance of
Gaussian random fields is much worse than in the balanced

accuracy

0.55
80

Our Algorithm
Gaussian Random Fields
Local and Global Consistency

0.6

0.55

20

40

60

0.5

80

20

40

60

80

labeled set size

(a)
(b)
Figure 5. Classification between Random Partitions. (a): balanced;
(b): unbalanced

0.4
0

60

0.03 , which is bor-

labeled set size

0.5
40

0.65

0.6

0.9

labeled set size

xi x j

Our Algorithm
Gaussian Random Fields
Local and Global Consistency

0.65

0.6

20

xi x j

0.55

0.75

0.8

accuracy

accuracy

(a)
(b)
Figure 3. Balanced Classification. (a): 1 vs 2; (b) odd vs even
1

1

rowed from [Zhu et al., 2003] and roughly measures the
similarity between documents. The only difference is that we
keep all the edges instead of keeping edges for only 10
nearest neighbors. Next we perform experiments to compare
the three algorithms. The results are provided in Figure 5 and
Figure 6 respectively.

average distance between each data point and its 10 nearest
neighbors.
1

exp

accuracy

d 2

0.9

Our Algorithm
Gaussian Random Fields
Local and Global Consistency

0.85
0.8

accuracy

2

2

accuracy

xi , x j

0.7
0.6
0.5

0.75
0.7
0.65

0.4

0.6

0.3

0.55

0.2

50

100

labeled set size

150

Our Algorithm
Gaussian Random Fields
Local and Global Consistency

0.5

50

100

150

labeled set size

(a)
(b)
Figure 6. Unbalanced Classification. (a): pa vs other; (b) b vs other

For Figure 5, we randomly partition the 10 categories into
two classes, i.e. pa, pr, sr, b, and is, vs mr, ppr, pd, ep and n.
Figure 5(a) and 5(b) correspond to the balanced and unbal-

IJCAI-07
2496

anced cases respectively. In the balanced case, Gaussian
random fields is better than our algorithm and the local and
global consistency method. This might be because the
function xi , x j does not have some of the nice properties
required by Theorem 2. However, in the unbalanced case,
Gaussian random fields tends to suffer a lot. On the contrary,
our algorithm is quite robust despite of the perturbation.
In Figure 6, we try to classify pa and b against all the other
categories. In these experiments, the class priors are 0.1 for
the positive class and 0.9 for the negative class. However,
here we provide equal numbers of positive and negative
points in the labeled set. From the figures, we can see that the
performance of our algorithm is rather stable, while the
performance of both Gaussian random fields and the local
and global consistency method is largely affected by the
misleading labeled set, since they only depend on the labeled
set to estimate the class priors, either explicitly or implicitly.

7

Conclusion and Future Work

In this paper, we propose a novel graph-based
semi-supervised learning method to estimate both the class
conditional probabilities and the class priors. It is a generative model, in contrast to existing graph-based methods,
which are essentially discriminative. In the ideal case, the
estimated class conditional probabilities have been proved to
converge to the true value. In the general case, our algorithm
can still output reasonable estimates of the class conditional
probabilities. For data points outside the training set, the
class conditional probabilities are estimated via kernel regression. When estimating the class priors, we effectively
use the unlabeled data to make up for the labeled data with
unrepresentative class prior distributions. Experimental
results on two datasets demonstrate the superiority of our
algorithm over recent existing graph-based semi-supervised
learning methods, especially when the proportion in the
labeled set is not the same as the class priors.
In our experiments, we notice that in some cases, adding
even a single labeled point into the labeled set brings about
significant improvement in classification accuracy; while in
other cases, adding many labeled points into the labeled set
does not help improve the performance. Currently we are
incorporating active learning into our framework. Particularly, we are interested in determining when to invoke active
learning (not just which instances to label) in order to achieve
the biggest gain while minimizing incremental labeling cost.

plications based on graph-theoretic electrical potentials.
ECCV04, workshop on Computer Vision Approaches to
Medical Image Analysis and Mathematical Methods in
Biomedical Image Analysis.
[He et al., 2004] He, J., Li, M., Zhang, H. J., Tong, H., &
Zhang, C. (2004). Manifold-ranking based image retrieval. Proc. 12th ACM International Conf. on Multimedia.
[Hull, 1994] Hull, J. J. (1994). A database for handwritten
text recognition research. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 16.
[Joachims, 1999] Joachims, T. (1999). Tranductive Inference
for text classification using Support Vector Machines.
ICML.
[Liu et al., 2003] Liu, Y., Carbonell, J., & Jin, R. (2003). A
New Pairwise Ensemble Approach for Text Classification. ECML.
[Niu, Ji and Tan, 2005] Niu, Z. Y., Ji, D. H., & Tan, C. L.
(2005). Word sense disambiguation using label propagation based semi-supervised learning. Proc. 43rd Meeting
of the Association for Computational Linguistics.
[Zhou et al., 2004] Zhou, D., bousquet, O., Lal, T., Weston,
J., & Schlkopf, B. (2004). Leaning with local and global
consistency. NIPS.
[Zhu et al., 2003] Zhu, X., Ghahramani, Z., & Lafferty, J.
(2003). Semi-supervised learning using Gaussian fields
and harmonic functions. ICML.
[Zhu et al., 2005] Zhu, X., & Lafferty, J. (2005). Harmonic
mixtures: combining mixture models and graph-based
methods for inductive and scalable semi-supervised
learning. ICML.
[Zhu, 2005] Zhu, X. (2005). Semi-supervised learning with
graphs. Doctoral dissertation, School of Computer Science, Carnegie Mellon University.

Appendix
Proof of Theorem 1: suppose xi is from the positive class:
lim Dii n1

n

lim

n

n1

lim

j 1

n

Ex Y

1

xi

n

Wij n1

j 1

xj

n

(11)

n1Vn

xi , x

xi , x p x y 1 dx
p xi y 1

References
[Blum and Chawla, 2001] Blum, A., & Chawla, S. (2001).
Learning from labeled and unlabeled data using graph
mincuts. ICML.
[Chung, 1997] Chung, F. R. K. (1997). Spectral graph theory, regional conference series in mathematics, no. 92.
American Mathematical Society.
[Grady and Funka-Lea, 2004] Grady, L., & Funka-Lea, G.
(2004). Multi-label image segmentation for medical ap-

Equation (11) reduces the number of terms in the summation from n to n1 since Wij 0 if x j is from the negative
class.

xi , x j

is a delta function at xi

xj .

A corre-

sponding proof applies if xi is from the negative class.

IJCAI-07
2497

W-Boost and Its Application to Web Image Classiﬁcation
Jingrui He1 , Mingjing Li2 , Hong-Jiang Zhang2 , Changshui Zhang3
Automation Department, Tsinghua University, Beijing 100084, China
2
Microsoft Research Asia, 49 Zhichun Road, Beijing 100080, China
1
hejingrui98@mails.tsinghua.edu.cn, 2 {mjli, hjzhang}@microsoft.com, 3 zcs@tsinghua.edu.cn
1,3

Abstract
When training data is not sufﬁcient, boosting algorithms
tend to overﬁt as more weak learners are combined to form
a strong classiﬁer. In this paper, we propose a new variant of RealBoost, called W-Boost, which is based on a
novel weight update scheme and uses changeable bin number to estimate marginal distributions in weak learner design. This new boosting procedure results in both fast convergence rate and small generalization error. Experimental results on synthetic data and web image classiﬁcation
demonstrate the effectiveness of our approach.

1. Introduction
In the ﬁeld of pattern recognition, one fundamental problem is to build reliable classiﬁers which are easily trained
and that generalize well. Nowadays, two dominant methods for building classiﬁers are Support Vector Machines
(SVM) [2] and boosting (e.g., AdaBoost) [10]. The former
is designed to maximize the margins of labeled data, and
boasts good generalization performance. However, when
the decision manifold is complicated, the number of support vectors dramatically increases and the training time becomes unbearable for practical use.
The original idea of AdaBoost is to combine some weak
learners to form a strong classiﬁer. By emphasizing the examples misclassiﬁed by present weak learner and deemphasizing those correctly classiﬁed, Adaboost is able to gradually concentrate on the hard examples. It has been proven
that AdaBoost minimizes an exponential form of the classiﬁcation error [5], and that it tends to increase the margins of
all the examples at the expense of decreasing some already
large margins [8]. In [5], the authors further generalize the
idea of discrete AdaBoost to form RealBoost which uses
class probability estimates to construct real-valued weak
learners. Despite their simplicity and effectiveness, boosting algorithms have been discovered to overﬁt when the
number of training data is small and many weak learners

Proceedings of the 17th International Conference on Pattern Recognition (ICPR’04)
1051-4651/04 $ 20.00 IEEE

are combined.
In this paper, we have proposed a new weight update
scheme which utilizes independence measure in terms of
Kullback-Leibler distance to make up for data insufﬁciency.
Furthermore, when using histograms to approximate class
probabilities as in RealBoost, we gradually change the bin
number to help achieve a small generalization error. The
above techniques are integrated into a new boosting algorithm, called W-Boost.
The rest of the paper is organized as follows. In section
2, we introduce the new weight update scheme and weak
learners with changeable bin number. In section 3, experimental results on both synthetic data and web image classiﬁcation are presented to demonstrate the effectiveness of
W-Boost. Finally, we conclude in section 4.

2. W-Boost classiﬁer
Let’s consider a binary classiﬁcation problem. We have
training data (x1 , y1 ), · · · , (xN , yN ) where x ∈ χ is a vector valued feature and yi = 1 or −1. Without any loss of
generality, suppose the priors for both positive and negative examples are equal. RealBoost initially assigns equal
weights to positive and negative examples. To obtain weak
learner fm (x), it ﬁrst ﬁts the class probability estimate
pm (x) = pw (y = 1|x) ∈ [0, 1] using weights wi on the
pm (x)
training data, then sets fm (x) ← 12 log 1−p
∈ R and
m (x)
updates wi ← wi exp(−yi fm (xi )), i = 1, 2, . . . , N . After
normalization, the samples with updated weights are used to
obtain the next weak learner.The combined classiﬁer can
M
be written as: F (x) = sign[ m=1 fm (x)]. Experimental
results have demonstrated the superiority of RealBoost over
Discrete Adaboost in classiﬁcation tasks [5].

2.1. Weight update scheme
To build the weak learner fm (x), we ﬁrst select one feature component x(m) and build 1D histogram for this feature. The decision made by the weak learner is based on the

weighted posterior probability given that feature, which is
approximated by the histogram, i.e. fm (x) = fm (x(m) ) =
1
2

log

pw (y=1|x(m) )
.
pw (y=−1|x(m) )

In RealBoost, initially positive exam-

ples are assigned a weight w0 = 2N1 + , and negative examples are assigned a weight w0 = 2N1 − , where N+ and N−
are the numbers of positive and negative examples, respectively, and N+ +N− = N . We can think of this as sampling
the feature space uniformly and assigning each example a
weight w0 = 12 p(x|y). Suppose that p(x|y) can be written
in the following form:
p(x|y) = p1 (x1 |y) · · · pD (xD |y)

(1)

where pi (xi |y) is the marginal distribution, D is the dimensionality of feature space χ, i.e. the feature components are
conditionally independent. In the ﬁrst weight update process, we have
w1 = 12 p(x|y) exp(−yf1 (x(1) )) =
1
2



p(1) (x(1) |y = 1)p(1) (x(1) |y = −1) ·
pi (xi |y)
xi =x(1)

(2)
due to the fact that y = 1 or −1 and p(y = 1) = p(y = −1).
Integrate w1 to get marginal distribution of xi = x(1)

w1 dxj = kpi (xi |y)
(3)
j=i

where k is a constant. Since the integration of marginal
distribution must equal 1, k ≡ 1 and the marginal distribution of xi = x1 is still pi (xi |y) after weight update, which
follows from conditional independence. This result can be
easily generalized to succeeding weight update processes.
If two feature components xi and xj are statistically independent, weight update according to one of their marginal
distributions will not affect the marginal distribution of the
other. On the contrary, if they are totally dependent, their
marginal distributions will change simultaneously. For example, if xi ≡ xj , their marginal distributions will always
remain the same. If the dependence extent lies somewhere
in between, how will their marginal distributions affect each
other? Due to the vast variety of pdfs, the relationship can
not be written explicitly. However, it can be approximated
for practical use.
In our algorithm, we keep a set of weights on all examples for each feature component to generate 1D histograms.
Let w(i), w(j) denote the present sets of weights for com

ponents xi and xj , respectively, and w (i), w (j) denote the
sets of weights after weight update according to marginal
distribution of xi . We may update w(i), w(j) in the following way:


p

(y=1|xi )

w(i)
w (i) = w(j) · exp(−y( 21 log pw(i)
(y=−1|xi ) ))

Proceedings of the 17th International Conference on Pattern Recognition (ICPR’04)
1051-4651/04 $ 20.00 IEEE





w (j) = (1 − αij )w (i) + αij w(j)

(4)

where αij ∈ [0, 1] is a parameter indicating the dependence
extent between xi and xj . If they are independent, αij = 1;
if they are totally dependent, αij = 0. Although the relationship between the four marginal distributions is far more
complicated than that expressed in eq4 and possibly cannot be written in an explicit form, we will show in the next
section that this approximation is good enough to prevent
overﬁtting in case of data insufﬁciency to some extent.
As mentioned above, αij is measure of independence.
Traditionally, the measurement of independence is based
on the Kullback-Leibler ”distance” between the joint probability distribution of the feature components and the product of their marginal distributions, i.e. KL(i, j) =

pi,j (s,t)
s,t ps,t (s, t) log pi (s)pj (t) , where pi,j is the weighted sum
of examples whose ith component xi lies in the sth bin
and jth component xj lies in the tth bin. pi (s) and pj (t)
can be explained similarly. If xi and xj are independent,
KL(i, j) = 0; otherwise, KL(i, j) > 0. To normalize this
distance to [0, 1], we set αij = exp(−KL(i, j)l ), where l
is a positive parameter. Generally speaking, more training
data implies a smaller inﬂuence of independence measure
on weight update, i.e. larger l. We are now doing research
on selecting proper l according to the statistical property of
training data. In our preliminary experiments, l ≡ 1. The
main reason for choosing the exponential function for normalization lies in its convex and monotonously decreasing
nature. The smaller KL(i, j) is, the more accurate the approximation in eq4.

2.2. Weak learner design
It is easily understood that estimating a marginal distribution with larger bin numbers will lead to faster convergence rate in training error with a higher probability of overﬁtting, and vice versa. However, if we change the bin number in the training process, we may expect to achieve good
performance on both aspects. To be speciﬁc, the initial bin
number b0 can be set large enough to get a fast convergence
rate; in each of the following rounds, a constant ∆b will be
subtracted from b0 . With the bin number becoming smaller,
the weak classiﬁer will be rougher and not focus on the few
outliers, thus it will help to prevent the ﬁnal classiﬁer from
overﬁtting.
The two parameters b0 and ∆b can be adjusted to ﬁt various kinds of data. If we put more emphasis on convergence
rate, we may increase b0 or decrease ∆b; if we want to prevent the classiﬁer from overﬁtting, we may decrease b0 or
increase ∆b.

2.3. W-Boost algorithm
The proposed algorithm is summarized in Table 1.

1. Start with w0 (xd ) = 2N1 + for all positive examples, and w0 (xd ) = 2N1− for all negative examples, where d = 1, 2, . . . , D; set bin number b0 .
2. Calculate independence measure αij between every pair of feature components with b0 -bin histograms.

slow; when the bin number is large (RealBoost1), the convergence rate is fast, however, as more weak learners are
combined, the testing error ceases to further decrease and
even increases a little. The overﬁtting phenomenon is easily
observed from the large gap between the plots representing
training error and testing error of RealBoost1. Compared
with RealBoost2, the convergence rate of W-Boost is much
faster; compared with RealBoost1, the testing error of WBoost is continuously driven down although it may be a little higher than that of RealBoost1 when only a few weak
learners are combined.

3.2. Application in web image classiﬁcation

3. Repeat for m = 1, 2, . . . , M :
• For each feature xd , calculate histogram with bm−1 bins using the
weights wm−1 (xd ), construct classiﬁer
fm (xd ) =

1
2

pw

log p

d (y=1|x
m−1 (x )

wm−1

d

(y=−1|x
(xd )

)

d)

calculate weighted classiﬁcation
εdm = Ewm−1 [1(yf (xd )<0) ].

, and
error

• Select the feature x(m) with minimum
classiﬁcation error, and set fm (x(m) ) =
1
2

pwm−1 (x(m) ) (y=1|x(m) )

log p

wm−1 (x(m) )

(y=−1|x(m) )

.

• Update wm−1 (xd ), d = 1, 2, . . . , D and
xd = x(m) using eq4, and renormalize the
D sets of weights to get wm (xd ).
• Bin number bm = bm−1 − ∆b, if bm < 2,
bm = 2.

(m)
)].
4. Output the classiﬁer sign[ M
m=1 fm (x
Table 1. W-Boost

3. Experimental results
3.1. Synthetic data
We ﬁrst demonstrate the effectiveness of W-Boost on
an artiﬁcial non-linear separation problem, which is used
in [7]. Despite the complexity of the interleaving spirals
seen in Fig 2(a), we also add some noise, which increases
the difﬁculty for building classiﬁers. For each point, we
project it to 144 directions uniformly distributed in the 2D
plane resulting in a feature space of 144 dimensions. The
training errors and testing errors of both RealBoost and WBoost are illustrated in Fig 2(b).
When the bin number is small (RealBoost2), the convergence rate of both training error and testing error is very

Proceedings of the 17th International Conference on Pattern Recognition (ICPR’04)
1051-4651/04 $ 20.00 IEEE

With the ever growing volume of images on the Web,
organizing the images systematically is a must for efﬁcient
retrieval work. As a preliminary step, distinguishing photographs and graphics (Fig 1) has drawn the attention of
some researchers [3], [4], [1], [9]. In our experiment, we
extract edge intensity histogram, color correlogram [6], and
farthest neighbor histogram [9] features for each image, and
make use of Maximum Marginal Diversity (MMD) [11] to
select the 40 most discriminative features to represent the
images. The training set consists of 1149 graphics and
1001 photographs, while the testing set consists of 10348
graphics and 9014 photographs. The number of testing data
greatly exceeds the number of training data, which increases
the probability for the classiﬁer to overﬁt.
We apply three boosting algorithms to this classiﬁcation
problem: W-Boost with b0 = 200, ∆b = 10 (W-Boost1) to
test the performance of W-Boost, W-Boost with b0 = 200,
∆b = 0 (W-Boost2) to see the effectiveness of the novel
weight update scheme on preventing overﬁtting, and RealBoost with bin number=200 for comparison. The results
are illustrated in Fig 3. Notice that the convergence rate
of W-Boost is much slower than that of RealBoost, however, the testing error of RealBoost is always the largest of
the three methods after four weak learners are combined.
Furthermore, applying the weight update scheme alone can
already improve the generalization performance. When we
decrease the bin number in each round of W-Boost, even
smaller testing error can be obtained. But the decline in testing error is not so obvious as that with constant bin number
during the ﬁrst few iterations.

4. Conclusion
In this paper, we have proposed an improved version
of RealBoost, called W-Boost, which incorporates independence measure between feature components into weight
update scheme and varies the bin number in estimating
marginal distributions. Experimental results on both synthetic data and real data show that W-Boost can indeed im-

prove the generalization performance when training data is
not sufﬁcient compared with testing data. Future work includes: 1) reﬁne the probability model expressed in eq4 to
get a better approximation; 2) explore the relationship between the parameter l which controls the impact of independence measure on weight update and the statistical property
of training data.

References

(a)

[1] S. Dong, and Y. Yang. Hierarchical web image classiﬁcation by multi-level features. Proc. Machine Learning and
Cybernetics, 2:663–668, 2002.
[2] Y. Freund, and R. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting.
Journal of Computer and System Sciences, 55(1):119–139,
1997.
[3] A. Hartmann, and R. Lienhart. Automatic classiﬁcation of
images on the web. SPIE, 2002.
[4] J. Hu, and A. Bagga. Functionality-based web image categorization. Technical report, ALR-2003-014, Avaya Labs
Research.
[5] J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic
regression: a statistical view of boosting. The Annual of
Statistics, 28(2):337–374, 2000.
[6] J. Huang, S.R. Kumar, M. Mitra, W.J. Zhu, and R. Zabih.
Image indexing using color correlograms. CVPR, 762–768,
1997.
[7] C. Liu, and H. Shum. Kullback-Leibler boosting. CVPR,
1:587–594, 2003.
[8] R. Schapire, Y. Freund, P. Barlett, and W.S. Lee. Boosting
the margin: a new explanation for the effectiveness of voting
methods. Proc. 14th International Conference on Machine
Learning, 322–330, 1997.
[9] V. Athitsos, M.J. Swain, and C. Frankel. Distinguishing
photographs and graphics on the world wide web. Proc. of
Content-Based Access of Image and Video Libraries, 10–17,
1997.
[10] V. Vapnik. The Nature of Statistical Learning. Springer,
1995.
[11] N. Vasconcelos. Feature selection by maximum marginal
diversity. CVPR, 1:762–769, 2003.

(a)

(b)

Figure 1. Examples of graphic and photograph images. (a) Graphic. (b) Photograph.

Proceedings of the 17th International Conference on Pattern Recognition (ICPR’04)
1051-4651/04 $ 20.00 IEEE

(b)

Figure 2. Comparison between W-Boost and
RealBoost. (a) Synthetic two-class data. (b)
The training and testing error rate vs. the
number of weak learners. (RealBoost1: bin
number=15; RealBoost2: bin number=150;
W-Boost: b0 = 150, ∆b = 5)

Figure 3. Comparison on web image classiﬁcation. (W-Boost1: b0 = 200, ∆b = 10; WBoost2: b0 = 200, ∆b = 10; RealBoost: bin
number=200)

43

Co-Clustering Structural Temporal Data with Applications
to Semiconductor Manufacturing
YADA ZHU, IBM Research
JINGRUI HE, Arizona State University

Recent years have witnessed data explosion in semiconductor manufacturing due to advances in instrumentation and storage techniques. The large amount of data associated with process variables monitored over
time form a rich reservoir of information, which can be used for a variety of purposes, such as anomaly detection, quality control, and fault diagnostics. In particular, following the same recipe for a certain Integrated
Circuit device, multiple tools and chambers can be deployed for the production of this device, during which
multiple time series can be collected, such as temperature, impedance, gas flow, electric bias, etc. These time
series naturally fit into a two-dimensional array (matrix), i.e., each element in this array corresponds to a
time series for one process variable from one chamber. To leverage the rich structural information in such
temporal data, in this article, we propose a novel framework named C-Struts to simultaneously cluster on
the two dimensions of this array. In this framework, we interpret the structural information as a set of constraints on the cluster membership, introduce an auxiliary probability distribution accordingly, and design
an iterative algorithm to assign each time series to a certain cluster on each dimension. Furthermore, we
establish the equivalence between C-Struts and a generic optimization problem, which is able to accommodate various distance functions. Extensive experiments on synthetic, benchmark, as well as manufacturing
datasets demonstrate the effectiveness of the proposed method.

r

CCS Concepts:
Theory of computation → Structured prediction; Unsupervised learning and
clustering;
Mathematics of computing → Time series analysis;

r

Additional Key Words and Phrases: Co-clustering, semiconductor, structural, temporal
ACM Reference Format:
Yada Zhu and Jingrui He. 2016. Co-clustering structural temporal data with applications to semiconductor
manufacturing. ACM Trans. Knowl. Discov. Data 10, 4, Article 43 (May 2016), 18 pages.
DOI: http://dx.doi.org/10.1145/2875427

1. INTRODUCTION

Semiconductor manufacturing represents one of the most complex manufacturing
processes in the world [Newell et al. 2007]. Here, one key challenge is how to exploit
the large amount of data associated with process variables monitored over time (e.g.,
temperature, impedance, gas flow, electric bias) for a variety of purposes such as
anomaly detection, quality control, and fault diagnostics, which may lead to significant
reduction in the manufacturing cost [Kurz et al. 2013; Johnson and McLoone 2012]. In
particular, to produce a certain Integrated Circuit (IC) device, multiple tools will be deployed following the same recipe process, and each tool has multiple chambers to carry
out the task. Therefore, the time-series data associated with various process variables
This work was supported by IBM Research by providing IBM FACULTY AWARD.
Authors’ addresses: Y. Zhu, IBM T.J. Watson Research Center, 1101 Kitchawan Rd, Yorktown Heights, NY
10598; email: yzhu@us.ibm.com; J. He, Computer Science and Engineering, Arizona State University, 699
S. Mill Ave. Tempe, AZ 85281; email: jingrui.he@asu.edu.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for
components of this work owned by others than ACM must be honored. Abstracting with credit is permitted.
To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this
work in other works requires prior specific permission and/or a fee. Permissions may be requested from
Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212)
869-0481, or permissions@acm.org.
c 2016 ACM 1556-4681/2016/05-ART43 $15.00

DOI: http://dx.doi.org/10.1145/2875427

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:2

Y. Zhu and J. He

measured from all the chambers fit into a two-dimensional array, or matrix. To be
specific, each row of the array corresponds to one chamber, each column corresponds to
one process variable, and each element in this array corresponds to the measurements
of the process variable over time. Such structural temporal data contain rich information about the manufacturing process, and thus, can be exploited to help domain
experts gain more insights into the recipe of the IC device.
In particular, the simultaneous clustering of rows (chambers) and columns (process
variables) helps identify chambers with similar behaviors and process variables with
similar patterns over time. Such information can be further used to detect outlying
chambers as well as process variables for the sake of quality control and fault diagnostics. Although very important, this problem cannot be readily solved using existing
techniques on time-series clustering or multi-way clustering. For time-series clustering, most existing methods are designed for unstructured time-series data [Zakaria
et al. 2012a; Rakthanmanon et al. 2012a, 2012c; Li and Prakash 2011], and thus,
cannot leverage the structural information from the underlying matrix. For multi-way
clustering, existing methods take as input one or more matrices of scalers [He et al.
2009; Chakrabarti et al. 2004; Dhillon et al. 2003], and cannot be applied on matrices
of time series.
In this article, for the first time, we study the co-clustering of such structural temporal
data and propose the C-Struts framework to address this problem. In this framework,
we first interpret the structural information associated with the two-dimensional array as a set of constraints on the cluster membership: the time series in the same
row/column should be assigned to the same row/column cluster. Then, we introduce
an auxiliary probability distribution taking these constraints into consideration, analyze its properties, and build a prototype for each row/ column accordingly. Finally,
we propose an iterative algorithm to repeatedly assign each row/column to the closest
prototype.
The major contributions of this paper can be summarized as follows.
(1) A novel problem of co-clustering structural temporal data, which originates from
semiconductor manufacturing.
(2) A general framework for modeling the relationship between rows/columns and
row/column clusters.
(3) An iterative algorithm for repeatedly updating the row/column cluster membership.
(4) Extensive experiments on synthetic, benchmark, and real datasets.
The rest of the article is organized as follows. In Section 2, we briefly review the
related work. Then, we present the C-Struts framework together with the iterative
algorithm in Section 3. Experiments results are provided in Section 4. Finally, we
conclude the article in Section 5.
2. RELATED WORK

In this section, we review the related work in time-series analysis, multi-way clustering,
and semiconductor device fabrication.
2.1. Time-Series Analysis

Time-series analysis aims at extracting meaningful information from sequences of data
points, measured at successive time stamps.1 For time-series data, researchers have
studied a variety of problems, such as classification [Chen et al. 2013; Hu et al. 2013],
clustering [Zakaria et al. 2012b; Li and Prakash 2011; Li et al. 2010], search and
indexing [Rakthanmanon et al. 2012b; Wei et al. 2008], forecasting [Yi et al. 2000],
outlier detection [Papadimitriou et al. 2005], etc.
1 http://en.wikipedia.org/wiki/Time

series.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

Co-Clustering Structural Temporal Data with Applications to Semiconductor Manufacturing

43:3

For time-series clustering, a key component is the distance function between two
time series. For example, Dynamic Time Warping can be used for this purpose, and
it has been studied in various settings [Xi et al. 2006; Fu et al. 2008]. The distance
function can also be obtained based on various features of time-series data, which can
be extracted using Principal Component Analysis (PCA), Discrete Fourier Transform
(DFT), Kalman filters [Li et al. 2010], Complex-valued Linear Dynamical Systems [Li
and Prakash 2011], etc.
The major difference between existing methods for time-series clustering and our
proposed work is as follows. For the former, the time-series data are typically unstructured, and the clustering results are solely based on the distance between two time
series; whereas for the latter, the time-series data are structured, i.e., they naturally
fit into a two-dimensional array, and the structural information can be exploited to
improve the clustering results.
2.2. Multi-Way Clustering

Different from traditional clustering techniques [Jain and Dubes 1988], which are
designed to group objects so as to maximize within cluster similarity and between
cluster dissimilarity, for sparse relational data, co-clustering or bi-clustering methods [Madeira and Oliveira 2004] aim at simultaneously cluster objects of each type.
These methods typically produce groupings of better quality by leveraging clusters of
other types in the similarity measure [He et al. 2009]. The information-theoretic coclustering method [Dhillon et al. 2003] is among the first to address this problem, which
monotonically increases the preserved mutual information by intertwining the row and
column clusterings. Follow up work includes the MMRC model proposed in Long et al.
[2007], the minimum Bregman information principle proposed in Banerjee et al. [2007],
the general binary clustering model and its variations proposed in Li [2005], minimum
sum-squared residue co-clustering proposed in Cho et al. [2004], etc.
Co-clustering has been generalized to handle more than two object types, i.e., multiway clustering. Examples include Consistent Bipartite Graph Co-partitioning [Gao
et al. 2005], which aims at collectively clustering star-shaped relationships among
different types of objects; spectral relational clustering [Long et al. 2006], which iteratively embeds each type of objects into low-dimensional spaces and benefits from the
interactions among the hidden structures of different types; collective matrix factorization [Singh and Gordon 2008], which assumes shared parameters among factors when
an entity participates in multiple relations; etc. Furthermore, researchers have proposed various techniques to automatically determine the number of clusters for each
object type, such as cross associations [Chakrabarti et al. 2004], AutoPart [Chakrabarti
2004], PaCK [He et al. 2009], etc.
The major difference between existing methods for multi-way clustering and our
proposed work is as follows. The input of multi-way clustering is one or more matrices
of scalars, i.e., each element in the matrices is a scaler; whereas the input of the
proposed work is a matrix of time series, i.e., each element in the matrix is a time
series.
Another related work is GraphScope [Sun et al. 2007], which takes time-evolving
graphs as input, and uses an information-theoretic criterion to segment time into
homogeneous intervals. In particular, it aims at: (1) discovering communities among
objects of the same type; and (2) detecting change points in time. This is different
from our proposed work, where we aim at simultaneously clustering multiple object types (chambers and process variables) based on their time varying properties.
Finally, in Zhu and He [2014], we proposed a co-clustering method for time-series
data. This method can be seen as a special case of our proposed work here by using the Euclidean distance to measure the difference between each time series and
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:4

Y. Zhu and J. He

the row/column cluster prototype. In contrast, in this article, we propose a generic optimization problem to accommodate various types of distance functions, and provide
empirical results demonstrating its robustness with respect to the parameter in the
distance function.
2.3. Semiconductor Device Fabrication

Semiconductor manufacturing is a capital intensive process in which each wafer goes
through hundreds of processes to finally yield IC devices [Zhu et al. 2012]. During
each step, various process variables, such as temperature, pressure, and gas flow, are
collected by sensors and represented as time-series data for detecting process faults,
analyzing tool stability and tool matching, etc. Usually the same step produces wafers
in multiple tools, each of which has multiple chambers. Therefore, the process data are
naturally expressed as a multi-dimensional array. Due to tool variability, the process
conditions of chambers in the same tool are more similar than those from different
tools. In each step, process variables form different categories intuitively based on
physical properties and advanced process control. For instance, uncontrollable process
variables, such as impedance and electric bias, are related to the setting and drift of
the controllable variable, voltage. Similarly, the throttle valve positions change with
pressure, temperature and gas flow over time. Thus structural information is embedded
in the dynamic process data.
For the purpose of process fault/anomaly detection, multivariate statistical methods have been applied successfully in actual applications, such as PCA, Fisher linear
analysis, and partial least square [Chang et al. 2012]. These methods are based on
the summary statistics (e.g. mean and standard deviation) of the time-series data,
which tends to lose the temporal information in the process data. To handle the timevarying characteristic of the process data, the wavelet method analyzes process data in
a frequency space to detect abnormalities [Misra 2007]; recursive PCA detects faulty
processes by updating the PCA model through various processes [Jeng et al. 2007; Li
et al. 2000]; and PCA and k-nearest neighbor are used hierarchically [He and Wang
2010]. However, the structural information embedded in the time-series data cannot be
naturally incorporated into these algorithms. To the best of our knowledge, our work
is the first to leverage the structural temporal information for process fault detection
in semiconductor manufacturing.
3. PROPOSED WORK

In this section, we introduce our proposed framework on co-clustering structural temporal data. In other words, given structural temporal data that fit into a two-dimensional
array, our goal is to simultaneously cluster the rows and the columns. Here, we would
like to point out that the analysis and the proposed algorithm can be naturally extended
to multi-dimensional arrays, which will be discussed in Subsection 3.5.
3.1. Notation

Let zi, j denote the time series in the ith row and the jth column, i = 1, . . . , M,
j = 1, . . . , N, where M (N) is the total number of rows (columns) in the array. Each
i, j
i, j
time series zi, j has T i, j observations, i.e., zi, j = {z1 , . . . , zT i, j }. Notice that the length of
different time series is not necessarily the same. Let R denote the number of row clusters, and C denote the number of column clusters. For example, in device fabrication of
semiconductor manufacturing, the R row clusters are associated with different tools,
which contain various number of chambers; whereas the C column clusters are associated with different types of process variables, e.g., the variables subject to Advance
Process Control, the dependent variables, etc.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

Co-Clustering Structural Temporal Data with Applications to Semiconductor Manufacturing

43:5

Let ẑ r,: denote the rth row cluster for r = 1, . . . , R; ẑ :,c denote the cth column cluster
for c = 1, . . . , C; 1 denote the mapping from {z i, j } to {ẑ r,: } (row cluster); and 2 denote
the mapping from {z i, j } to {ẑ :,c } (column cluster).
3.2. Problem Definition

Given the above structured time-series data, our goal is to simultaneously cluster the
M × N time series into R row clusters and C column clusters, resulting in R × C
clusters in total. In particular, the cluster assignment should satisfy the following two
constraints.
(1) Row Constraint (RC): the time series in the same row should be assigned to the
same row cluster.
(2) Column Constraint (CC): the time series in the same column should be assigned to
the same column cluster.
Based on these constraints ∀i = 1, . . . , R, j = 1, . . . , C, 1 (z i, j ) = 1 (z i,: ), where z i,:
denotes the time series on the ith row, and 2 (z i, j ) = 2 (z:, j ), where z :, j denotes the
time series on the jth column.
Notice that these constraints originate from device fabrication in semiconductor
manufacturing, where the time series collected from chambers in the same tool exhibit
similar patterns due to their physical proximity (constraint (1)), and the time series
associated with process variables of the same type are similar to each other due to their
control pattern (constraint (2)). Therefore, traditional time-series clustering methods
dealing with unstructured temporal data are not best suited for such problems, since
they do not take these constraints into consideration. The problem setting is also
different from existing co-clustering/multi-way clustering methods [Dhillon et al. 2003;
Chakrabarti et al. 2004; Sun et al. 2007; He et al. 2009], where the input is one or more
matrices, i.e., the elements on the two-dimensional array are scalers instead of time
series.
3.3. The Proposed C-Struts Framework

For each time series zi, j , we assume its current value at time stamp t can be regressed
L
i, j
i, j
i, j
i, j
i, j
on the past values up to a maximum lag L: zt = l=1
βl · zt−l + t , where βl are
i, j
the parameters, and t are IID random variables for i = 1, . . . , M, j = 1, . . . , N,
i, j
i, j
and t = 1, . . . T i, j . Let β i, j = [β1 , . . . , β L ]T , where (·)T denotes vector transpose. In
the initialization step, the parameters β i, j can be estimated by solving the following
optimization problem:
β

i, j

= arg min


t


i, j
zt

−

L


2
i, j
βl

·

i, j
zt−l

+ αR(β i, j )

(1)

l=1

where R(·) is a regularizer on the parameters, e.g., p-norm of β i, j , and α is a positive parameter that balances between the mean squared error and the regularizer.
Such optimization problem can be solve using ridge regression if R(β i, j ) = β i, j 2 ,
Lasso [Tibshirani 1996] if R(β i, j ) = |β i, j |, elastic net [Zou and Hastie 2003] if R(·) is a
linear combination of both the two-norm and the one-norm of β i, j , etc.
Based on the two constraints RC and CC, we assume that the joint probability of:
(1) the parameters β, (2) the time series on the ith row zi,: , and (3) the time series
on the jth column z:, j , can be approximated by the following auxiliary probability
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:6

Y. Zhu and J. He

distribution:
p(β, zi,: , z:, j )
≈ q(β, zi,: , z:, j )
.
= μi, j p(ẑr,: , ẑ:,c ) p(zi,: |ẑr,: ) p(z:, j |ẑ:,c ) p(β|zi,: ) p(β|z:, j )

(2)

where 1 (zi,: ) = ẑr,: , 2 (z:, j ) = ẑ:,c , and the value of the coefficient μi, j guarantees that
q(·) is a valid probability distribution, i.e.,
μi, j = 
β

1
.
p(β|zi,: ) p(β|z:, j )

Based on the auxiliary probability distribution q(·), the parameters β can be generated as follows. We first draw the row cluster ẑr,: and the column cluster ẑ:,c from
p(ẑr,: , ẑ:,c ); based on these clusters, we then draw each row zi,: according to p(zi,: |ẑr,: ),
and each column z:, j according to p(z:, j |ẑ:,c ); finally, we draw the parameters β based
on both zi,: and z:, j according to μi, j p(β|zi,: ) p(β|z:, j ).
It can be proven that q(·) has the following property.
LEMMA 3.1 (PROPERTIES OF q(·)).
(1) The marginal probability of ẑr,: (ẑ:,c ) is the same under p (·) and q(·). To be specific,
q(ẑr,: ) = p(ẑr,: )

(3)

q(ẑ:,c ) = p(ẑ:,c ).

(4)

(2) The conditional probability of zi,: (z:, j ) given ẑr,: (ẑ:,c ) is the same under p (·) and
q (·). To be specific,
q(zi,: |ẑr,: ) = p(zi,: |ẑr,: )

(5)

q(z:, j |ẑ:,c ) = p(z:, j |ẑ:,c ).

(6)
:,c

(3) zi,: is conditionally independent of the column cluster ẑ given the row cluster ẑr,: ;
z:, j are conditionally independent of the row cluster ẑr,: given the column cluster
ẑ:,c . To be specific,
q(zi,: |ẑr,: , ẑ:,c ) = q(zi,: |ẑr,: )

(7)

q(z:, j |ẑr,: , ẑ:,c ) = q(z:, j |ẑ:,c ).

(8)

PROOF. For Equation (3) ∀r = 1, . . . , R, we have (Equation (4) can be proven similarly)



μi, j p(ẑr,: , ẑ:,c ) p(zi,: |ẑr,: ) p(z:, j |ẑ:,c ) p(β|zi,: ) p(β|z:, j )
q(ẑr,: ) =
ẑ:,c zi,: :1 (zi,: )=ẑr,:
z:, j :2 (z:, j )=ẑ:,c

=

ẑ

=




:,c



β

p(ẑr,: , ẑ:,c ) p(zi,: |ẑr,: ) p(z:, j |ẑ:,c )
r,:

zi,: :1 (zi,: )=ẑ
z:, j :2 (z:, j )=ẑ:,c

p(ẑr,: , ẑ:,c )

ẑ:,c

= p(ẑr,: ).
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

Co-Clustering Structural Temporal Data with Applications to Semiconductor Manufacturing

43:7

For Equation (5), ∀i = 1, . . . , M, such that 1 (zi,: ) = ẑr,: , we have (Equation (6) can
be proven similarly)
q(zi,: |ẑr,: ) =

q(zi,: , ẑr,: )
q(ẑr,: )
 
ẑ:,c

=



q(β, zi,: , z:, j , ẑr,: , ẑ:,c )

p(ẑr,: )

i,:
:, j
z:, j :2 (z:, j )=ẑ:,c β q(β, z , z )



p(ẑr,: )
r,:
:,c
i,: r,:
:, j :,c
z:, j :2 (z:, j )=ẑ:,c p(ẑ , ẑ ) p(z |ẑ ) p(z |ẑ )

ẑ:,c

=

β


ẑ:,c

=



z:, j :2 (z:, j )=ẑ:,c

p(ẑr,: )

p(z:, j , ẑ:,c )
p(ẑr,: )
= p(zi,: |ẑr,: )
=

where the second equation is based on Equation (1).
For Equation (7), we have (Equation (8) can be proven similarly)
q(zi,: |ẑr,: , ẑ:,c )

=


=

=



z:, j :2 (z:, j )=ẑ:,c

β

q(β, zi,: , z:, j , ẑr,: , ẑ:,c )

q(ẑr,: , ẑ:,c )

i,:
:, j
z:, j :2 (z:, j )=ẑ:,c β q(β, z , z )

β,zi,: :1 (zi,: )=ẑr,:
z:, j :2 (z:, j )=ẑ:,c
z:, j :2 (z:, j )=ẑ:,c

q(β, zi,: , z:, j , ẑr,: , ẑ:,c )

p(ẑr,: , ẑ:,c ) p(zi,: |ẑr,: ) p(z:, j |ẑ:,c )
p(ẑr,: , ẑ:,c )

= p(zi,: |ẑr,: )
= q(zi,: |ẑr,: ).
where the last equality is based in Equation (5).
From the above properties, we can see that the approximation probability q(·) keeps
the marginal probability of the row/column clusters, as well as the conditional probability of each row/column given a row/column cluster. Furthermore, the conditional
independence in Equations (7) and (8) is consistent with both RC and CC.
Therefore, we propose to construct a prototype for each row/column cluster based on
q(·). To this end, ∀r = 1, . . . , R, we first compute the posterior distribution of β given
ẑr,: as follows.
q(β, ẑr,: )
q(β|ẑr,: ) =
q(ẑr,: )
 

zi,: :1 (zi,: )=ẑr,:
z:, j :2 (z:, j )=ẑ:,c
r,:

ẑ:,c

=
=




ẑ

:,c

i,:

i,:

q(β, zi,: , z:, j )

p(ẑ )
μi, j p(ẑ:,c |ẑr,: ) p(zi,: |ẑr,: ) p(z:, j |ẑ:,c ) · p(β|zi,: ) p(β|z:, j ).

r,:

z :1 (z )=ẑ
z:, j :2 (z:, j )=ẑ:,c

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:8

Y. Zhu and J. He

Then, for the rth row cluster, we define its prototype as the expected value of β given
the row cluster, i.e.,
β̂

r,:

= Eq(β|ẑr,: ) (β).

If both p (β|zi,: ) and p(β|z:, j ) follow a Gaussian distribution such that p (β|zi,: ) ∝
exp(− 2σ1 2 (β − β i,: )T (β − β i,: )), and p(β|z:, j ) ∝ exp(− 2σ1 2 (β − β :, j )T (β − β :, j )), where β i,:
R

C

denotes the column average of β i, j , β :, j denotes the row average, σ R and σC are both
positive parameters, i.e.,
β i,: =

N
1  i, j
β
N

(9)

j=1

β

:, j

M
1  i, j
=
β .
M

(10)

i=1

In this case, the row cluster prototype can be derived as follows.


r,:
β̂ =
p (ẑ:,c |ẑr,: ) p (zi,: |ẑr,: ) p (z:, j |ẑ:,c ) · Eμi, j p (β|zi,: ) p (β|z:, j ) (β)
ẑ:,c zi,: :1 (zi,: )=ẑr,:
z:, j :2 (z:, j )=ẑ:,c

=





p (ẑ:,c |ẑr,: ) p (zi,: |ẑr,: ) p (z:, j |ẑ:,c ) ·

ẑ:,c zi,: :1 (zi,: )=ẑr,:
z:, j :2 (z:, j )=ẑ:,c

σC2 β i,: + σ R2 β :, j
σ R2 + σC2

.

(11)

:,c

Similarly the column cluster prototype β̂ can be obtained from the following equation:


σ 2 β i,: + σ R2 β :, j
:,c
β̂ =
p (ẑr,: |ẑ:,c ) p (zi,: |ẑr,: ) p (z:, j |ẑ:,c ) · C 2
.
(12)
2
σ
+
σ
r,:
r,:
i,:
i,:
R
C
ẑ
z :1 (z )=ẑ
z:, j :2 (z:, j )=ẑ:,c

Notice that the row and column cluster prototypes in Equations (9) and (10) are not
centroids. Instead, they are weighted combination of the row and column average of
the parameters, where the weights are obtained via the approximation probability q(·).
For the conditional probability of each row/column given its row/ column cluster, we
propose to estimate its value as follows:

	
1
r,: T
r,:
i,:
i,:
i,: r,:
p(z |ẑ ) ∝ exp −
(β − β̂ ) (β − β̂ )
(13)
2σ R2


	
1
:,c T
:,c
:, j
:, j
(β − β̂ ) (β − β̂ ) .
(14)
p(z |ẑ ) ∝ exp −
2σC2


Together with the fact that zi,: :1 (zi,: )=ẑr,: p(zi,: |ẑr,: ) = 1 and z:, j :1 (z:, j )=ẑ:,c p(z:, j |ẑ:,c ) =
1, we can obtain the exact value of these conditional probabilities.
To estimate the joint probability of each row/column cluster pair, we use the empirical probability mass of the time series that have been mapped to the corresponding
row/column cluster. To be specific,
:, j

:,c

p(ẑr,: , ẑ:,c ) =

|zi, j |1 (zi, j ) = ẑr,: , 2 (zi, j ) = ẑ:,c |
M×N

(15)

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

Co-Clustering Structural Temporal Data with Applications to Semiconductor Manufacturing

43:9

where |zi, j |1 (zi, j ) = ẑr,: , 2 (zi, j ) = ẑ:,c | denotes the number of times series that have
been mapped to the rth row cluster and the cth column cluster.
3.4. The Proposed Algorithm

The proposed algorithm is summarized in Algorithm 1. In Steps 1–5, we compute the
parameters β i, j for each time series in the two-dimensional array; in Steps 6–11, we
compute the row/column average of the parameters β i,: /β :, j ; in Step 12, we randomly
assign the rows to the R row clusters, and assign the columns to the C column clusters;
then, we repeat Steps 14–25 until convergence (not to exceed niter times), where in
r,: :,c
Steps 14–19, we compute the row/column cluster prototype β̂ /β̂ , and in Steps 20–
25, we re-assign each row/column to the closest row/column cluster prototype.
3.5. Discussion

Finally, in this subsection, we discuss alternative features and extensions for the proposed C-Struts algorithm.
3.5.1. Equivalence to Optimization Problem. In order to learn the optimal mapping functions 1 and 2 , a natural optimization problem can be expressed as follows:
⎫
⎧
R
C
⎨



 i,:
 

 :, j
⎬
min Ep
s β , Eq(β|ẑr,: ) (β) +
s β , Eq(β|ẑ:,c ) (β)
(16)
1 ,2
⎭
⎩
r,:
:,c
i,:
:, j
r=1 1 (z )=ẑ

c=1 2 (z )=ẑ

where the outermost expectation is with respect to the true joint probability p(·),
the prototypes for row/column clusters are with respect to the auxiliary probability q (·), and s(·, ·) is a function that measures the distance between two vectors.
The proposed algorithm can be seen as minimizing Equation (16) when s(β, E(β)) =
β − E(β)2 . It can be adapted to alternative choices of the distance function, such as
s(β, E(β)) = β − E(β)d where d > 0, and Mahalanobis distance. In this case, Algorithm 1 can be revised by updating 1 (zi,: ) with arg max ẑr,: s(β i,: , Eq(β|ẑr,: )(β) ) in Step 21,
and updating 2 (z:, j ) with arg max ẑ:,c s(β :, j , Eq(β|ẑ:,c )(β) ) in Step 24 of Algorithm 1. In
the next section, we will provide empirical evaluation regarding different distance
functions.
3.5.2. Computational Complexity. The following lemma provides the computational complexity of the proposed Algorithm 1.

LEMMA 3.2 (COMPUTATIONAL COMPLEXITY OF C-STRUTS). If all the parameters β i, j are
given, the time complexity of C-Struts is O(MNL). The space complexity of C-Struts is
O(MNL).
This lemma indicates that both the time complexity and the space complexity of CStruts are linear with respect to the total number of rows, the total number of columns,
and the length of the parameters β i, j . Therefore, it is scalable to large datasets. Notice
that this result does not include the computation of the parameters β i, j via ridge
regression or Lasso (Steps 1–5 in Algorithm 1), as it is orthogonal to the remaining
co-clustering steps. The time complexity also depends on niter , which is the largest
number of iterations allowed. As we will show in the next section, empirically the
number of iterations required for the co-clustering loop to converge typically does not
exceed 8.
3.5.3. Alternative Features for Time Series. In Algorithm 1, we use the parameters β i, j ,

i = 1, . . . , M, j = 1, . . . , N, to represent the time series in the two-dimensional array,
which is obtained from the Auto-Regressive (AR) model. Alternatively, we could use
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:10

Y. Zhu and J. He

the Auto-Regressive Moving-Average (ARMA) model, i.e.,
i, j
zt

=c

i, j

+

L




i, j
βl

·

i, j
zt−l

+

i, j
t

+

L


i, j

i, j

γl · t−l

l =1

l=1
i, j

where ci, j is the expectation of zi, j and γl are additional parameters. The rest of the
i, j
i, j
algorithm applies on the concatenation of βl and γl . If all the time series in the
two-dimensional array are of the same length, we could also use PCA or DFT to extract
the features, both of which have been used in time-series clustering.
3.5.4. Extension to Multi-Dimensional Arrays. Up until now, we have focused on temporal
data that fit into a two-dimensional array. The proposed C-Struts framework can be naturally extended to multi-dimensional arrays. For example, if the underlying structure
is a three-dimensional array instead of a matrix, the auxiliary probability distribution
can be defined as follows:

q(β, zi,:,: , z:, j,: , z:,:,k)
= μi, j,k p(ẑr,:,: , ẑ:,c,: , ẑ:,:,o ) p(zi,:,: |zr,:,: ) p(z:, j,: |z:,c,: )
· p(z:,:,k|z:,:,o ) p(β|zi,:,: ) p(β|z:, j,: ) p(β|z:,:,k).
It consists of three parts: the first part is the joint probability of clusters on the three
dimensions; the second part is the conditional probability of a single element (e.g., a
row) given the cluster on a certain dimension; and the last part is the conditional probability of the parameters given elements on different dimensions. Based on the above
auxiliary probability distribution, we could modify the prototypes on the three dimensions accordingly, based on which we could repeatedly update the cluster membership
using Algorithm 1.
4. EXPERIMENTAL RESULTS

In this section, we test the performance of the proposed C-Struts algorithm on synthetic, benchmark, and manufacturing datasets. Since C-Struts is the first algorithm
for co-clustering structural temporal data, we compare its performance with existing methods for time-series clustering, including CLDS [Li and Prakash 2011] and
k-Means. Different from C-Struts, neither CLDS nor K-Means take into consideration
the structural information associated with the underlying two-dimensional array. We
also compare C-Struts with a co-clustering algorithm on matrix and scalar data. We
name it “Co-clustering” in this section. The algorithm calculates pairwise similarity
directly from raw time-series data and applies the Information-Theoretic Co-clustering
algorithm on top of the similarity. Notice that all the algorithms are given the same
number of clusters as input, i.e., for C-Struts the number of row/column clusters is
R/C; and for CLDS and K-Means, the number of clusters is R × C.
4.1. Synthetic Data

4.1.1. Co-Clustering Results. In this subsection, we test the performance of C-Struts
on two synthetic datasets. For both datasets, we generate three row clusters, each
with a unique AR model; the time series in the three column clusters correspond to
sampling frequency of 10, 9, and 8, respectively. Figure 1 shows the co-clustering results of C-Struts on the two datasets, respectively, one without noise, and the other
with Gaussian noise of standard deviation 0.01. In this figure, the various colors indicate the ground truth, and the rows/columns are re-arranged so that rows/columns
assigned to the same row/column cluster are grouped together. As we can see, when
the data are noise free, C-Struts perfectly recovers the underlying matrix structure
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

Co-Clustering Structural Temporal Data with Applications to Semiconductor Manufacturing

43:11

Fig. 1. Performance of C-Struts on synthetic datasets.

ALGORITHM 1: C-Struts Algorithm
Require: zi, j , i = 1, . . . , M, j = 1, . . . , N, R, C, niter
Ensure: 1 , 2
1: for i = 1 to M do
2:
for j = 1 to N do
3:
Compute the parameters β i, j by solving Equation (1) using ridge regression, Lasso, etc;
4:
end for
5: end for
6: for i = 1 to M do
7:
Compute the row average β i,: using Equation (9);
8: end for
9: for j = 1 to N do
10:
Compute the column average β :,: using Equation (10);
11: end for
12: Randomly initialize 1 and 2 ;
13: for k = 1 to niter do
14:
for r = 1 to R do
r,:
15:
Compute the row cluster prototype β̂ using Equation (11);
16:
end for
17:
for c = 1 to C do
:,c
18:
Compute the column cluster prototype β̂ using Equation (12);
19:
end for
20:
for i = 1 to M do
r,:
21:
Update 1 (zi,: ) ← arg min ẑr,: β i,: − β̂ 2 ;
22:
end for
23:
for j = 1 to N do
:,c
24:
Update 2 (z:, j ) ← arg min ẑ :,c β :, j − β̂ 2 ;
25:
end for
26: end for

[Figure 1(a)]; when the data are slightly contaminated by noise, C-Struts can still generate reasonable clustering results: only three rows are assigned to the wrong row
cluster [Figure 1(b)].
4.1.2. Distance Functions. In this subsection, we evaluate the performance of C-Struts
with respect to different d values in the distance function s(β, E(β)) = β − E(β)d.
For this experiment, we use the synthetic dataset with Gaussian noise of standard
deviation 0.1. For each given d value, we repeat the experiment for 200 times and
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:12

Y. Zhu and J. He

Fig. 2. The performance of C-Struts, w.r.t., distance functions on synthetic dataset.

Fig. 3. The processing time of C-Struts scales linearly, w.r.t., the number of rows.

report the mean and standard deviation of Jaccard index. Figure 2 presents the error
bar plot where the smallest value of d is 0.2. This figure shows that C-Struts is robust
to a wide range of d values in this distance function when d > 0.5.
4.1.3. Computational Complexity. To empirically evaluate the computational complexity
of C-Struts algorithm, we use the synthetic dataset with Gaussian noise of standard
deviation 0.1 as described above over different number of rows. The experiments have
been performed on a laptop with Intel Core i5-4300U processor and 8 GB of RAM,
equipped with Windows 7 operating system. The code has been executed using 64-bit
MATLAB (R2014a). For each number of rows, we perform the experiments 200 times
and record the mean and standard deviation of CPU time in seconds. We plot the
time in seconds against the number of rows, as shown in Figure 3. As we can see, the
processing time scales linearly with respect to the number of rows, which is consistent
with our analysis in Subsection 3.5.
In addition, we evaluate the impact of niter on the time complexity of the C-Struts
algorithm. We set niter as a sufficiently large number and assume the co-clustering loop
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

Co-Clustering Structural Temporal Data with Applications to Semiconductor Manufacturing

43:13

Fig. 4. Convergence study of C-Struts algorithm: the clustering objective function converges typically within
eight iterations.

Fig. 5. Performance of C-Struts on semiconductor manufacturing dataset.

converges if the co-clustering membership does not change. At each iteration, we report
the value of the co-clustering objective function, Equation (16). As shown in Figure 4,
the co-clustering loop converges quickly, which is typically less than eight iterations.
4.2. Manufacturing Data

In this subsection, we test the performance of C-Struts on a dataset collected from
semiconductor manufacturing. The dataset corresponds to an etching step with 19
process variables that forms three categories based on the process control practice:
“gas and pressure,” “power,” and “others.” The etching step lasts for 133 seconds and
two data points are collected during each second for all the process variables. It is
concurrently running in five tools, each having six chambers. Here, the goal is to identify
similar chamber and process variable behaviors. Figure 5 presents the co-clustering
results, where the various colors indicate the ground truth, and the rows/columns
are re-arranged so that rows/columns assigned to the same row/column cluster are
grouped together. From this figure, we can see that the 30 chambers have been correctly
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:14

Y. Zhu and J. He

Fig. 6. Comparison on all datasets in the “data1” category.

assigned to the row cluster that corresponds to the tool that the chambers belong
to. This is consistent with the assumption that chambers behave similarly in the
same tool and differently across various tools. On the other hand, of the three column
clusters generated by C-Struts, the first cluster corresponds to the “other” category,
and it mistakenly includes process variables from the “gas and pressure” category.
This might be due to the nature of the “other” category, which mixes process variables
of different types and is less well defined as the “gas and pressure” or the “power”
category.
4.3. Benchmark Data

Although the proposed C-Struts algorithm is designed for semiconductor manufacturing, it can also be used in other applications. In this subsection, we test its performance on all datasets in the “data1” category from UCR Time-Series Classification/Clustering Page.2 To be specific, we use the known classes in these datasets to
form the row clusters, and form the column clusters based on various sampling frequencies. The collective comparison results with existing time-series clustering methods and co-clustering method on matrix/scalar data are shown in Figure 6, where
Figure 6(a) compares C-Struts with K-Means in terms of the Jaccard index values,
Figures 6(b) and 6(c) compares C-Struts with CLDS and Co-clustering in terms of
the same metric, respectively. From this figure, we can see that the proposed CStruts algorithm outperforms K-Means, CLDS, and Co-clustering in the majority of the
datasets.
Furthermore, we also compare the Jaccard index values associated with both row and
column clustering at various sampling frequencies, and present the results in Figures 7
and 8, respectively. From these figures, once again we see that the performance of CStruts is better than the competitors in most cases. For some datasets, where C-Struts
is not as good as the other methods, e.g., ChlorineConcentration, the Jaccard index
values are typically small, indicating that the parameters β i, j used to represent each
time series may not be able to fully capture its pattern.
5. CONCLUSION

In this paper, motivated by semiconductor manufacturing, we study a novel problem of co-clustering structural temporal data. In this problem, we are given as input a two-dimensional array consisting of multiple time series, and the goal is to
simultaneously cluster both the rows and the columns. This problem is different
from traditional time-series clustering, which targets unstructured time-series data,
2 http://www.cs.ucr.edu/∼eamonn/time

series data/.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

Co-Clustering Structural Temporal Data with Applications to Semiconductor Manufacturing

43:15

Fig. 7. Comparison on benchmark datasets: part 1.

and multi-way clustering, which assumes the input matrix (matrices) consists of
scalers.
To address this problem, we propose a general framework named C-Struts. It interprets the structural information as constraints on the cluster membership, and uses an
auxiliary probability distribution to obtain prototypes for each row/column cluster. We
also present an iterative algorithm to assign each time series to the closest row/column
cluster based on the distance to the prototypes. Experimental results on synthetic,
benchmark, as well as manufacturing data demonstrate the effectiveness of C-Struts.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:16

Y. Zhu and J. He

Fig. 8. Comparison on benchmark datasets: part 2.

ACKNOWLEDGMENTS
The authors thank the Editor, the Associate Editor, and the referees for comments that helped them improve
the manuscript.

REFERENCES
Arindam Banerjee, Inderjit S. Dhillon, Joydeep Ghosh, Srujana Merugu, and Dharmendra S. Modha. 2007. A
generalized maximum entropy approach to Bregman co-clustering and matrix approximation. J. Mach.
Learn. Res. 8, 1919–1986.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

Co-Clustering Structural Temporal Data with Applications to Semiconductor Manufacturing

43:17

Deepayan Chakrabarti. 2004. AutoPart: parameter-free graph partitioning and outlier detection. In Proceedings of the 8th European Conference on Principles and Practice of Knowledge Discovery in Databases
(PKDD). Springer-Verlag Berlin Heidelberg, 112–124.
Deepayan Chakrabarti, Spiros Papadimitriou, Dharmendra S. Modha, and Christos Faloutsos. 2004. Fully
automatic cross-associations. In Proceedings of the 10th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining. ACM New York, NY, USA, 79–88.
Hyung Jin Chang, Dong Sung, Pyo Jae Kim, and Jin Young Choi. 2012. Spatiotemporal pattern modeling
for fault detection and classification in semiconductor manufacturing. IEEE Trans. Semicond. Manuf.
25, 72–82.
Yanping Chen, Bing Hu, Eamonn J. Keogh, and Gustavo E. A. P. A. Batista. 2013. DTW-D: time series
semi-supervised learning from a single example. In Proceedings of the 19th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining. ACM New York, NY, USA, 383–391.
Hyuk Cho, Inderjit S. Dhillon, Yuqiang Guan, and Suvrit Sra. 2004. Minimum sum-squared residue coclustering of gene expression data. In Proceedings of the SIAM International Conference on Data Mining.
114–125.
Inderjit S. Dhillon, Subramanyam Mallela, and Dharmendra S. Modha. 2003. Information-theoretic coclustering. In Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining. ACM New York, NY, USA, 89–98.
Ada Wai-Chee Fu, Eamonn J. Keogh, Leo Yung Hang Lau, Chotirat (Ann) Ratanamahatana, and Raymond
Chi-Wing Wong. 2008. Scaling and time warping in time series querying. VLDB J. 17, 4, 899–921.
Bin Gao, Tie-Yan Liu, Xin Zheng, QianSheng Cheng, and Wei-Ying Ma. 2005. Consistent bipartite graph copartitioning for star-structured high-order heterogeneous data co-clustering. In Proceedings of the 11th
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM New York, NY,
USA, 41–50.
Jingrui He, Hanghang Tong, Spiros Papadimitriou, Tina Eliassi-Rad, Christos Faloutsos, and Jaime
Carbonell. 2009. PaCK: scalable parameter-free clustering on k-partite graphs. In Proceedings of the
SDM Workshop on Link Analysis, Counterterrorism and Security.
Qinghua Peter He and Jin Wang. 2010. Large-scale semiconductor process fault detection using a fast pattern
recognition-based method. IEEE Trans. Semicond. Manuf. 23, 194–200.
Bing Hu, Yanping Chen, and Eamonn J. Keogh. 2013. Time series classification under more realistic assumptions. In Proceedings of the SIAM International Conference on Data Mining. 578–586.
Anil K. Jain and Richard C. Dubes. 1988. Algorithms for Clustering Data. Prentice-Hall, Inc., Upper Saddle
River, NJ.
Jyh-Cheng Jeng, Cheng-Chih Li, and Hsiao-Ping Huang. 2007. Fault detection and isolation for dynamic
processes using recursive principal component analysis based on filtering of signals. Asia-Pacific J. chem.
Eng. 2, 501–509.
A. B. Johnson and S. F. McLoone. 2012. A dynamic sampling methodology for within product virtual metrology. In Proceedings of the 29th International Manufacturing Conference. University of Ulster, Coleraine,
United Kingdom.
Daniel Kurz, Cristina De Luca, and Jurgen Pilz. 2013. Monitoring virtual metrology reliability in a sampling
decision system. In Proceedings of the Conference on Automation Science and Engineering. IEEE.
Lei Li and B. Aditya Prakash. 2011. Time series clustering: complex is simpler!. In Proceedings of the 28th
International Conference on Machine Learning. 185–192.
Lei Li, B. Aditya Prakash, and Christos Faloutsos. 2010. Parsimonious linear fingerprinting for time series.
Very Large Database Endowment 3, 1, 385–396.
Tao Li. 2005. A general model for clustering binary data. In Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM New York, NY, USA, 188–197.
Weihua Li, H. Henry Yue, Sergio Valle-Cervantes, and S. Joe Qin. 2000. Recursive PCA for adaptive process
monitoring. J. Process Contr. 10, 471–486.
Bo Long, Zhongfei (Mark) Zhang, Xiaoyun Wu, and Philip S. Yu. 2006. Spectral clustering for multi-type
relational data. In Proceedings of the 23rd International Conference on Machine Learning. 585–592.
Bo Long, Zhongfei (Mark) Zhang, and Philip S. Yu. 2007. A probabilistic framework for relational clustering.
In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining. ACM New York, NY, USA, 470–479.
Sara C. Madeira and Arlindo L. Oliveira. 2004. Biclustering algorithms for biological data analysis: a survey.
IEEE/ACM Trans. Comput. Biol. Bioinform. 1, 1, 24–45.
Manish Misra. 2007. Novel techniques for real-time and predictive FDC systems. Future Fab Int. 22.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

43:18

Y. Zhu and J. He

Glenn Newell, Naji Bekhazi, and Ray Morgan. 2007. Optimizing Storage and I/O for Distributed Processing
on Enterprise and High Performance Compute (HPC) Systems for Mask Data Preparation Software
(CATS). Technical Report. Synopsys, Inc.
Spiros Papadimitriou, Jimeng Sun, and Christos Faloutsos. 2005. Streaming pattern discovery in multiple time-series. In Proceedings of the 31st International Conference on Very Large Data Bases. VLDB
Endowment, 697–708.
Thanawin Rakthanmanon, Bilson J. L. Campana, Abdullah Mueen, Gustavo E. A. P. A. Batista, M. Brandon
Westover, Qiang Zhu, Jesin Zakaria, and Eamonn J. Keogh. 2012a. Searching and mining trillions
of time series subsequences under dynamic time warping. In Proceedings of the 18th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining. ACM New York, NY, USA, 262–
270.
Thanawin Rakthanmanon, Bilson J. L. Campana, Abdullah Mueen, Gustavo E. A. P. A. Batista, M. Brandon
Westover, Qiang Zhu, Jesin Zakaria, and Eamonn J. Keogh. 2012b. Searching and mining trillions
of time series subsequences under dynamic time warping. In Proceedings of the 18th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining. ACM New York, NY, USA, 262–
270.
Thanawin Rakthanmanon, Eamonn J. Keogh, Stefano Lonardi, and Scott Evans. 2012c. MDL-based time
series clustering. Knowl. Inf. Syst. 33, 2 (2012), 371–399.
Ajit Paul Singh and Geoffrey J. Gordon. 2008. Relational learning via collective matrix factorization. In
Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining. ACM New York, NY, USA, 650–658.
Jimeng Sun, Christos Faloutsos, Spiros Papadimitriou, and Philip S. Yu. 2007. GraphScope: parameter-free
mining of large time-evolving graphs. In Proceedings of the 13th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining. ACM New York, NY, USA, 687–696.
R. Tibshirani. 1996. Regression shrinkage and selection via the Lasso. J. R. Stat. Soc. Series B Stat. Methodol.
58, 267–288.
Li Wei, Eamonn J. Keogh, Xiaopeng Xi, and Melissa Yoder. 2008. Efficiently finding unusual shapes in large
image databases. Data Min. Knowl. Discov. 17, 3, 343–376.
Xiaopeng Xi, Eamonn J. Keogh, Christian R. Shelton, Li Wei, and Chotirat Ann Ratanamahatana. 2006.
Fast time series classification using numerosity reduction. In Proceedings of the 23rd International
Conference on Machine Learning. 1033–1040.
Byoung-Kee Yi, Nikolaos Sidiropoulos, Theodore Johnson, H. V. Jagadish, Christos Faloutsos, and Alexandros
Biliris. 2000. Online data mining for co-evolving time sequences. In Proceedings of the 16th International
Conference on Data Engineering. IEEE, 13–22.
Jesin Zakaria, Abdullah Mueen, and Eamonn J. Keogh. 2012a. Clustering time series using unsupervisedshapelets. In Proceedings of the IEEE International Conference on Data Mining. IEEE, 785–794.
Jesin Zakaria, Abdullah Mueen, and Eamonn J. Keogh. 2012b. Clustering time series using unsupervisedshapelets. In Proceedings of the IEEE International Conference on Data Mining. IEEE, 785–794.
Yada Zhu and Jingrui He. 2014. Co-clustering structural temporal data with applications to semiconductor
manufacturing. In Proceedings of the IEEE International Conference on Data Mining. IEEE, 1121–1126.
Yada Zhu, Jingrui He, and Rick Lawrence. 2012. Hierarchical modeling with tensor inputs. In Proceedings
of the 26 AAAI Conference on Artificial Intelligence. AAAI.
Hui Zou and Trevor Hastie. 2003. Regularization and variable selection via the elastic net. J. R. Stat. Soc.
Series B Stat. Methodol. 67, 2, 301–320.
Received May 2015; revised December 2015; accepted January 2016

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 43, Publication date: May 2016.

A Graph-based Recommendation across
Heterogeneous Domains
∗

Deqing Yang§ , Jingrui He‡ , Huazheng Qin§ Yanghua Xiao§ , Wei Wang§
§

§

School of Computer Science, Shanghai Key Laboratory of Data Science
§
Fudan University, Shanghai, 200433, China P. R.

{yangdeqing, huazhengqin13, shawyh, weiwang1}@fudan.edu.cn
Arizona State University, AZ, USA, ‡ jingrui.he@gmail.com

ABSTRACT

Keywords

Given the users from a social network site, who have been tagged
with a set of terms, how can we recommend the movies tagged
with a completely different set of terms hosted by another website?
Given the users from a website dedicated to Type I and Type II diabetes, how can we recommend the discussion threads from another
website dedicated to gestational diabetes, where the keywords used
in the two websites might be quite diverse? In other words, how
can we recommend across heterogeneous domains characterized
by barely overlapping feature sets?
Despite the vast amount of existing work devoted to recommendation within homogeneous domains (e.g., with the same set of
features), or collaborative filtering, emerging applications call for
new techniques to address the problem of recommendation across
heterogeneous domains, such as recommending movies hosted by
one website to users from another website with barely overlapping
tags. To this end, in this paper, we propose a graph-based approach
for recommendation across heterogeneous domains. Specifically,
for each domain, we use a bipartite graph to represent the relationships between its entities and features. Furthermore, to bridge
the gap among multiple heterogeneous domains with barely overlapping sets of features, we propose to infer their semantic relatedness through concept-based interpretation distilled from online
encyclopedias, e.g., Wikipedia and Baike. Finally, we propose an
efficient propagation algorithm to obtain the similarity between entities from heterogeneous domains. Experimental results on both
Weibo-Douban data set and Diabetes data set demonstrate the effectiveness and efficiency of our algorithm.

cross-domain recommendation, heterogenous domains, graph propagation, semantic matching

1.

INTRODUCTION

Up until now, recommender systems have been successfully applied to a variety of domains, ranging from movies to research papers, from online friends to social tags. Existing techniques for
recommender systems can be mainly categorized into three different groups: collaborative filtering (CF for short) [15, 16], contentbased filtering [3,6], and hybrid recommender systems [5]. Most of
these techniques focus on a single domain [27, 36]. In other words,
the users and the items come from the same website.
More recently, researchers have studied cross-domain recommendation [19,21,24,32], where the users and the items come from
different websites. The main goal of cross-domain recommendation is to alleviate the cold start problem, such that the matching
between users and items across different domains is satisfactory in
the beginning. Notice that, most, if not all, of existing techniques
for cross-domain recommendation work best if different domains
share a large number of features. In this way, the relevance between
users from one domain and items from another can be naturally obtained based on the common features. Please refer to Section 4 for
a detailed review of related works.

1.1

Applications

Nowadays, with the emergence of various e-commerce websites,
a natural question is: how can we recommend items across heterogeneous domains, i.e., the different domains sharing very few feaCategories and Subject Descriptors
tures? Take Weibo (Chinese version of Twitter, http://www.
H.3.5 [Information Storage and Retrieval]: On-line Information
weibo.com) and Douban (the largest Chinese movie database,
Services-Web-based services; H.2.8 [Database Management]: Database http://www.douban.com) as an example. The tags used by
applications-Data mining; I.2.4 [Artificial Intelligence]: KnowlWeibo users are quite different from those used to specify movies
edge Representation Formalisms and Methods-Semantic networks
on Douban, which is illustrated by the tag clouds in Figure 1. From
this figure, we can see that the common Weibo tags include ‘mu∗Corresponding author.
sic’, ‘movie’, ‘food’, ‘80s’, which generally characterize a Weibo
user’s hobby, age, constellation, etc. In contrast, Douban tags are
generally used to specify a movie’s nation, year and genre, such
Permission to make digital or hard copies of all or part of this work for personal or
as ‘USA’, ‘Japan’, ‘animation’, ‘classic’, etc. For this case, exclassroom use is granted without fee provided that copies are not made or distributed
isting techniques for cross-domain recommendation may not be
for profit or commercial advantage and that copies bear this notice and the full citaable to accurately identify the movies from Douban that may be
tion on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or reof potential interest to Weibo users. Another example is the recpublish, to post on servers or to redistribute to lists, requires prior specific permission
ommendation of articles across different websites. In particular,
and/or a fee. Request permissions from Permissions@acm.org.
among the various social network websites dedicated to diabetes
CIKM’15, October 19-23, 2015, Melbourne, VIC, Australia
patients, some of them might be open to all types of diabetes pac 2015 ACM. ISBN 978-1-4503-3794-6/15/10 ...$15.00.
⃝
tients, such as http://www.tudiabetes.org (denoted by
DOI: http://dx.doi.org/10.1145/2806416.2806523.

463

Figure 1: Tag clouds of Weibo users (a) and Douban movies (b). These tags can be viewed as the features specifying Weibo users and
Douban movies to be used for recommendation. However, seldom tags are shared in these two groups.

users

users

items	
  A

items	
  

users	
  A

domain	
  A	
  	
  	
  	
  	
  	
  	
  	
  	
  domain	
  B

(a)

(b)

users	
  A

items	
  

items	
  B

domain	
  A	
  	
  	
  	
  	
  	
  	
  	
  	
  domain	
  B

users	
  B

domain	
  A	
  	
  	
  	
  	
  	
  	
  	
  	
  domain	
  B

(c)
features	
  B

features	
  A

features

users	
  B

users	
  A

How	
  to	
  recommend?

items	
  B

items	
  B	
  

items	
  A	
  
domain	
  A	
  	
  	
  	
  	
  	
  	
  	
  	
  	
  

	
  

domain	
  A	
  	
  	
  	
  	
  	
  	
  	
  	
  

	
  domain	
  B

(d)

	
  

	
  domain	
  B

(e)

Figure 2: Different settings of cross-domain recommendation. The solid lines between users and items represent user-item interactive
relations such as ratings, reviews and so on. In subfigure (a)∼(c), shared users or items can be found in both two domains. Furthermore, in subfigure (d), common features exist. In subfigure (a)∼(d), user-item relations can be found in both domains. All this
abundant information can be used to discover the relations between the two domains. In this paper, we focus the setting of subfigure
(e) which is more challenging than the formers because neither user-item relations nor common features across the domains can be
obtained.
Diabetes1), which is for patients of Type I, Type II, and prediabetes. And some of them might focus on a specific type of diabetes
patients, such as https://diabetessisters.org (denoted
by Diabetes2), which is for female diabetes patients, especially for
those with gestational diabetes. In this case, due to the different
vocabulary used by the different websites, existing techniques for
cross-domain recommendation may not be able to effectively recommend discussion threads from Diabetes2 to the users of Diabetes1 who are not aware of the other website.

mendation is demonstrated in Figure 2. Previous solutions mainly
focused on two typical cross-domain settings. In the first setting,
either users or items are shared in both domains. For example,
in [24], there is an one-one mapping between the users and items
of the two domains. It indicates that the two domains have the
same groups of users and items as depicted in Figure 2(a). As depicted in Figure 2(b) and (c), the two domains share either users or
items [7, 21]. The second setting is illustrated in Figure 2(d), both
users and items are disjoint, but the relations between the two domains can be derived through the shared features, such as the same
tag space [32,37] or similar user-item interactive patterns [19]. Furthermore, in the preceding four cases, the user-item interactive relations (the solid lines in the figures) such as rating, review or pur-

1.2 Challenges
The main difference between our concern of recommendation
across heterogeneous domains and traditional cross-domain recom-

464

chase exist in each domain. However, all the solutions for these
cases obviously can not be directly used to solve the problem setting as shown in Figure 2(e), where domain A only contains users
and domain B only contains items and no shared features can be
used to establish the links between the users in domain A and the
items in domain B.
However, the heterogenous cross-domain recommendation scenario of Figure 2(e) is a popular and valuable setting in real world.
For example, it will create a lot of business opportunities if we can
accurately recommend products in eBay to a user in Tweet or Facebook. Therefore, in this paper, we focus on the challenging problem of recommendation across heterogeneous domains. In general,
this new problem setting poses two challenges.

down to inferring the similarity between different types of objects
(users and items) from multiple domains. In this section, we present
our graph-based method: we first start with some notations, followed by the introduction of the global similarity and the efficient
computation of the relevance vectors, and finally discuss semantic
matching for inducing cross-domain correlation.

2.1

Notation

Without loss of generality, in this paper, we consider 2 different
domains, although the proposed method can be easily generalized
to multiple domains. Formally, for the ith domain (i=1,2), we use
a bi-partite graph Gi = {Vi , Ei } to represent the relationships between the objects in this domain and their characterizing features,
where Vi is the set of nodes in this graph, and Ei is a set of undirected edges. Let ni denote the number of objects in the ith domain,
and mi denote the number of features. Therefore, Vi consists of
two types of nodes: ni object nodes, and mi feature nodes. Notice
that in Ei , an edge only exists between different types of nodes, i.e.,
between an object node and a feature node, and the edge weights
are set to the feature value of the corresponding object. Let X i ,
ni × mi , denote the connectivity matrix between the two types of
nodes, whose elements are set to be the edge weights.
In cross-domain recommendation where only a small fraction of
features are shared across different domains, a critical question is
how to build the connection between the bi-partite graphs for different domains. To address this problem, in our method, we propose the following matching graph between features from the two
domains. Let G0 = {V0 , E0 } denote such a bi-partite matching
graph, where V0 includes all the feature nodes from the two domains, and E0 denotes the set of edges connecting features from
different domains. Based on this graph, we define connectivity
matrix X 0 , (m1 + m2 ) × (m1 + m2 ), whose elements measure
the similarity between features from different domains. Details of
learning the connectivity matrix X 0 based on semantic matching
will be discussed in Subsec. 2.4.
Putting all above graphs together, we get a multi-partite
∪ graph
G = {V,
as shown in Figure 3, where V = V1 V2 , and
∪E} ∪
E = E1 E2 E0 . Then, we define an affinity matrix X for this
graph. X is an (n1 + n2 + m1 + m2 ) × (n1 + n2 + m1 + m2 )
matrix and is represented as,


0n1 ×n1 0n1 ×n2
X1
0n1 ×m2
 0n2 ×n1 0n2 ×n2 0n2 ×m1

X2

X=
 X T1

0m1 ×n2 0m1 ×m1
X0
0m2 ×n1
X T2
X T0
0m2 ×m2

1. The first challenge is the sparsity of shared features across
heterogeneous domains, which makes the discovery of the
connections among the non-shared features non-trivial. Recall the tags of Weibo users and Douban movies, correlating
different tags across the two domains is critical for recommending Douban movie to Weibo users. However, discovering such connections is not a trivial task.
2. The second challenge is designing an effective and efficient
model for inferring the similarity of entities across heterogeneous domains, especially when the numbers of entities and
features are very large. Recall the setting of Figure 2(e), even
when the connections between the features of the two domains are discovered, inferring the similarity between users
and items is also challenging.

1.3 Basic Idea and Organization
To overcome these challenges, we propose to use bipartite graphs
to represent the relationships between entities and their features,
and build the connection between heterogeneous domains through
semantic matching of features. Based on the composite multipartite graph, we propose an effective and efficient propagation algorithm to infer the global similarity between entities across different domains. The major contributions of this paper can be summarized as follows.
1. We propose a novel recommendation approach based on a
multi-partite graph representation and an efficient propagation algorithm. Furthermore, we justify the optimization of
our algorithm.
2. We conduct extensive experiments on two real applications:
Douban movie recommendation for Weibo users, article recommendation across different diabetes social networks, to
verify the effectiveness of our solution for recommendation
across heterogenous domains.

where (·)T denotes matrix transpose and 0 is a zero matrix. Based
on this graph, our goal is to infer the similarity between object
nodes from different domains.

The rest of this paper is organized as follows. In Section 2, we introduce our graph-based approach for recommendation across heterogeneous domains including the semantic matching between different tags/keywords. In Section 3, we evaluate the performance
of our approach against existing techniques. Finally, we survey the
related works in Section 4 and conclude our paper in Section 5.

2.2

Global Similarity between Objects

In graph G, the direct connections between object nodes from
different domains are absent, e.g., between user nodes and item
nodes in Figure 3. Thus, we will measure their similarity based on
graph propagation. To be specific, we first normalize the affinity
matrix X as follows.

2. GRAPH-BASED APPROACH FOR CROSSDOMAIN RECOMMENDATION
Different from traditional CF-based methods, in this paper, we
target a more challenging problem of cross-domain recommendation, i.e., recommending the items from one domain to the users
from another heterogenous domain. This problem essentially boils

465

1

1

S = D − 2 XD − 2

0n1 ×n1 0n1 ×n2
 0n2 ×n1 0n2 ×n2

=
S T1
0m1 ×n2
0m2 ×n1
S T2

S1
0n2 ×m1
0m1 ×m1
S T0


0n1 ×m2

S2


S0
0m2 ×m2

(1)

domain1
user feature
user

L EMMA 1.

domain2
item feature
item

G0/X0

(3)

Proof. Lemma 1 can proved by applying the Woodbury formula [25]
on Equation 2, and leveraging the block structure of both K −1 and
K.■
Notice that the inverse of both C and BC −1 B T exists. This
is because K 1 is part of K, which is the inverse of the symmetric
positive definite matrix I − αS.
Based on K 1 , if the objects in the first domain are users, and
the objects in the second domain are items, the relevance between
the kth user and all the items can be obtained from the kth row or
column of K, since K 1 is a symmetric matrix. In other words,
the relevance vector can be written as si = K 1 ui , where ui is an
n1 + n2 dimensional vector. The elements of ui are 0 except the
ith one, which is set to 1.

connectivity matrix

G1/X1

(
)−1
K 1 = I − BC −1 B T

G2/X2

2.3

Figure 3: A multi-partite graph across two domains. Red lines
are user-feature edges in domain 1 and blue lines are itemfeature edges in domain 2. The green lines between red rectangles and blue rectangles are the edges between user features
and item features, which can be established by the semantic
similarity of features.

Efficient Computation of Relevance Vector

In this subsection, we focus on the efficient computation of the
relevance vector, which is summarized in Algorithm 1. It takes as
input matrices B and C, the query vector u (with only one nonzero entry), α and the number of iterations niter . The output is
the relevance]vector s with respect to u. Here we define S̃ 0 =
[
0 S0
. In this way, matrix C has the following equivalent
S T0
0
form C = I − αS̃ 0 .
The algorithm works as follows. In Step 1, we initialize the relevance vector to be the query vector u. In the outer loop starting
from Step 2, we set w to be B T s in Step 3, initialize r to be w in
Step 4, and pass both vectors to the inner loop starting from Step 5.
In the inner loop, we update r in Step 6 niter times. Finally, in the
outer loop, we re-scale r in Step 8, based on which we obtain the
current estimate of the relevance vector s.

where D is a diagonal matrix with each element equal to the row
sum of X; S 1 , S 2 , and S 0 are normalized versions of X 1 , X 2 ,
and X 0 , respectively.
In order to compute the global similarity between the ith node
and all the other nodes in the composite multi-partite graph, we use
vi to denote the (n1 + n2 + m1 + m2 ) dimensional vector, whose
ith element is 1 and all the others are 0. Using the manifold ranking
algorithm proposed in [35], the global similarity vector with respect
to the ith node can be written as (I − αS)−1 v i , where I is an
(n1 + n2 + m1 + m2 ) × (n1 + n2 + m1 + m2 ) identity matrix,
and α is a positive scalar whose value is close to 1. Putting all these
vectors together, we have the following (n1 + n2 + m1 + m2 ) ×
(n1 + n2 + m1 + m2 ) global similarity matrix K,

Algorithm 1 Graph-based Recommendation across Heterogeneous
Domains
Input: B, C, u, α, niter
Output: s
1: Initialize s to be u
2: for i = 1 to niter do
3:
w ← BT s
4:
Initialize r to be w
5:
for j = 1 to niter do
6:
r ← αS̃ 0 r + (1 − α)w
7:
end for
1
8:
r ← 1−α
r
9:
s ← Br + (1 − α)u
10: end for

K = (I − αS)−1 [v 1 , . . . , v n1 +n2 +m1 +m2 ] = (I − αS)−1
(2)
Each element in K measures the global similarity between each
pair of nodes. The property of the global similarity matrix
∑ K can
i
be interpreted using Taylor expansion [14], i.e., K = ∞
i=0 (αS) .
th
th
Notice that the i term measures the weighted i -step similarity
on the multi-partite graph, and its impact on the overall similarity
decreases exponentially with respect to i.
It is easy to see that K has the following block structure.
([
])−1 [
]
A B
K1 K2
K=
=
T
T
B
C
K2 K3

The convergence property of Algorithm 1 is presented in the following theorem.

According
to Equation 2, we conclude
that,
[
]
[ A=
]
I − 0n1 ×n1
0n1 ×n2
−αS 1 0n1 ×m2
,B =
,
0n2 ×n1
I − 0n2 ×n2
0n2 ×m1 −αS 2
[
]
I
−αS 0
and C =
. K 1 , K 2 , and K 3 are submatri−αS T0
I
ces of K, which are of the same dimensionality as A, B, and C
respectively. Since we are only interested in the similarity among
objects from different domains, instead of the whole matrix K, we
only compute the submatrix K 1 , (n1 + n2 ) × (n1 + n2 ), which
has the following closed form solution.

T HEOREM 1. As niter goes to infinity, s returned by Algorithm
1 converges to (1 − α)K 1 u.
Proof. We prove Theorem 1 via the following two steps. In the
first step, we analyze the convergence property of the inner loop between Step 5 and Step 7 of Algorithm 1; then in the second step, we
analyze the convergence property of the outer loop between Step 2
and step 10.
First, the following lemma shows the convergence property of
the inner loop.

466

L EMMA 2. Given w, as niter goes to infinity, in the inner loop
of Algorithm 1, r converges to (1 − α)C −1 w.

As we known, an online encyclopedia contains millions of concepts including person, location, organization, hobby and etc. There
exists an article page describing the fact about each concept. As
well, there are many hyper-links linking to other concepts on each
article page to enrich its semantic description. According to the
principle of previous Wikipedia based methods [11,22], two terms,
i.e., two concepts, are considered semantically related if they cooccur as hyper-links in one article page. The more such article
pages can be found, the more semantically related the two terms
are.

Proof. To prove Lemma 2, simply observe that upon convergence,
r = αS̃ 0 r + (1 − α)w. Therefore, (I − αS̃ 0 )r = (1 − α)w.
Together with the fact that C = I − αS̃ 0 , we conclude the proof
for Lemma 2.■
Based on Lemma 2, we can see that the inner loop provides an
efficient way of computing r = (1 − α)C −1 w. Combined with
Step 2 and Step 8 of Algorithm 1, we can see that in Step 9, the vector r is equal to C −1 B T s. Upon convergence, s = BC −1 B T s+
(1 − α)u. Therefore, (I − BC −1 B T )s = (1 − α)u. Together
with the definition of K 1 in Equation (3), we conclude our proof
for Theorem 1. ■
Comparing Algorithm 1 with direct computation of s = (I −
BC −1 B T )−1 u, the major advantage is its time efficiency. In our
applications, it is often the case that both B and S̃ 0 are very sparse.
Let lB and lS̃ 0 denote the number of non-zero elements in B and
S̃ 0 respectively. The time complexity of Algorithm 1 can be shown
as follows.

Concept 1’s article
…Conceptx…concepty…

tagxßàConceptx
tagyßàConcepty
…

tagx’s concept vector
Concept 2’s article
…Conceptz…Conceptx…

→	
  

C x = c1 c2 0 … c6 0…

…
Concept 6’s article
…Conceptx…Conceptu…
Concepty…

L EMMA 3. The time complexity of Algorithm 1 is O(lB + lS̃ 0 ).

C y = c1 0 0 … c6 0…

…

Proof. It is easy to see that the major computation in Algorithm is
matrix vector multiplication. Since both B and S̃ 0 are very sparse,
the computational complexity of S̃ 0 r is O(lS̃ 0 ), and the computational complexity of B is O(lB ), which completes the proof.■
Therefore, Algorithm 1 scales to large data sets since its time
complexity is linear with respect to the number of non-zeros elements in B and S̃ 0 . On the other hand, for direct computation
of s via matrix inversion, the typical time complexity is O((n1 +
n2 )2.373 ) using optimized CW-like algorithms [12], which is prohibitive for large data sets.

tagy’s concept vector
→	
  

Figure 4: The articles in online encyclopedias derive the concept vectors of tags. The left part display some articles in the
online encyclopedia. In this case, tagx and tagy are mapped
into Conceptx and Concepty respectively, and then tagx is semantically related to tagy through some encyclopedia concepts
although they are not represented by the same term.

2.4.2

Interpreting Semantic Reslationships

Then, we formalize the semantic interpretation of a tag. In order
to represent the semantics of a tag through the contexts provided
by the encyclopedia, we should first map a tag into an article entry
(i.e., a concept) of the encyclopedia. Given a tag i and a concept c,
we map i into c if i and c are exactly same or c’s string is a maximal
substring of i’s string. Under this mapping scheme, we can find a
mapped concepts for nearly 90% of tags. As depicted in Figure 4,
tagx and tagy are first mapped into Concpetx and Concpety , respectively. Then, we can find that Conceptx and Concepty cooccur in the article page of Concept 1, indicating their semantic
relatedness. Similarly, we may find another evidence, i.e., Concept
6’s article page. Therefore, although Conceptx and Concepty are
not same, they are still semantically related. Clearly, the indirect
matching through the contexts provided by concepts’ article pages
in online encyclopedia rather than lexical matching, is exactly what
we expect in the semantic matching for two tags.
According to Explicit Semantic Analysis (ESA for short)’s basic idea [11], the semantic interpretation of a tag i can be represented by a concept vector which is formally defined as C⃗i =
[c1 , ..., cC ] ∈ RC . C is the total number of concepts in the encyclopedia and cj (1 ≤ j ≤ C) represents the semantic relevance
of concept j to tag i, i.e., the TF-IDF score of concept i’s occurrence in concept j’s article. Figure 4 describes the compositions
of C⃗x and C⃗y . Thus, the semantic similarity between tag x and tag
y can be represented as the cosine similarity of C⃗x and C⃗y , namely
cos(C⃗x , C⃗y ). To establish the links between user tags and item tags,
i.e., E0 in the bi-partite graph G0 , we can set a threshold λ. Then,
the edge between x and y is created if cos(C⃗x , C⃗y ) ≥ λ. As well,

2.4 Semantic Matching
According to our algorithm, some relationships between features
should be established in order to discover the similarity of objects
in the two domains, i.e., inferring E0 in G0 . In this subsection,
we introduce how to find the relationships between different features from two heterogeneous domains, respectively. For a better
interpretation, we use the case where the features are represented
by tags to illustrate our method.

2.4.1 Basic Idea
As we declared before, most tags coming from heterogenous domains are different, which demands us to correlate two tags on semantic level rather than lexical level. In general, semantic matching
requires more context information of tags. To accomplish it, we try
to discover hyper-links existing among millions of concepts in online encyclopedias.
Most prior works on computing semantic relatedness resorted to
some well-defined lexical resources, such as WordNet [18]. However, lexical resources require lexicographic expertise and only cover
a small fraction of language lexicons. As we observed, the tags
adopted by Weibo users contain many proper names, neologisms,
and etc., which are seldom included in current lexical resources.
The authors in [11, 22] used substantial semantic information of
online encyclopedias, e.g., Wikipedia, to enrich the semantic representation of terms. In this paper, we also utilize online encyclopedias to achieve the semantic matching of tags. Concretely, we
adopt Wikipedia and Baike (http://baike.baidu.com) for
English tags and Chinese tags, respectively.

467

cos(C⃗x , C⃗y ) is set as the element of connectivity matrix X 0 (refer
to Figure 3). Accordingly, λ decides the density of X 0 . In our
experiments, we will display how λ affects on the performance of
our recommendation algorithm.

weights of Ei (i=1,2) as the TF-IDF scores of the keywords for
each user/post.

3.1.2

The Ground Truth of Recommendation

Then, we introduce how to capture the ground truths of the two
cross-domain recommendation tasks in our experiments.

3. EXPERIMENTS
In this section, we evaluate the performance of our proposed
graph-based algorithm through two applications of recommendation across heterogeneous domains.

1. Douban Movie Recommendation.
Unlike some famous movie recommendation data set such as
MovieLens (https://movielens.org.), there are no explicit
rating/review data of Weibo users on Douban movies, it is difficult to directly obtain the ground truth of Weibo users’ preferences on Douban movies. Therefore, we have to rely on human
assessments for generating ground truth of Douban movie recommendation. Specifically, we randomly selected 100 Weibo users
from our data set as volunteers, to whom we recommended some
Douban movies generated by the tested approaches. Then we asked
each volunteer whether to accept the recommended movies or not.
Each volunteer can give one of three answers, i.e., yes, no and
unknown. We only took the move of yes as a hit recommendation. We took their average acceptance rates as the performance
measure of the tested approaches.

3.1 Experiment Setup
We first present some experiment settings including data sets,
baseline methods and performance metrics.

3.1.1 Data sets
To demonstrate the performance of our algorithm, we focus on
the following two different types of data sets in our evaluation experiments.

1. Weibo-Douban Data Set.
The first data set is collected from two Chinese websites: Weibo
and Douban. Weibo is the largest Chinese Twitter which has more
than 0.6 billion accounts and 90 million active users per day. Recommending various products to Weibo users can create plenty of
business opportunities. On the other hand, Douban is a famous
Chinese website of movie reviews. Although both Weibo users and
Douban movies are profiled by a set of tags, the tags in these two
websites are quite different (recall to Figure 1 in Section 1). Thus,
recommending Douban movies to Weibo users is a typical recommendation problem across heterogeneous domains. To construct
the bi-partite graphs for this problem, we define the edge weight
between an object node and a feature node (the weight of Ei , i=1,2)
by a tag score, which quantifies the extent to which a tag can characterize the user/movie. For a Weibo user, the tag score is computed by a local tag propagation algorithm proposed in [33]. For a
Douban movie, the score of a tag is its tagging frequency for this
movie which can be fetched directly from Douban website. From
Douban website, we totally collected 4,028 movies whose average
rating scores are above 7.5 (10 is the best) and review numbers are
greater than 2000. Since most Weibo tags and Douban tags are
both written in Chinese, we used Baike encyclopedia to explore the
semantic similarity of these tags.

2. Diabetes Post Recommendation.
To generate the ground truth of a diabetes patient’s preferred
posts, we first generated a representative vector for each Diabetes1’s
user and Diabetes2’s post. Given a Diabetes1’s user, we collected
all his/her published posts as a corpus from which a set of keywords
were extracted. Each element of the user vector is the TF-IDF
score of one keyword. So does a Diabetes2’s post vector. Then,
we ranked all posts according to the cosine similarity of the user
vector and the post vectors. Finally, we assume that the user will
only accept top 30% of the posts whose cosine similarity is greater
than 0. These posts were considered as recommendation ground
truth of the user. Since all Diabetes keywords are English words,
we used Wikipedia’s concepts to compute the semantic similarity
of keywords.

3.1.3

Baselines

To emphasize the effectiveness of our approach, we also compared the performance of some state-of-the-art baselines.

1. Random Recommendation.

2. Diabetes Data Set.
The second data set is collected from two diabetes social network
websites, i.e., Diabetes1 and Diabetes2 introduced in Section 1. It
can be obtained from our Lab’s website (http://gdm.fudan.
edu.cn/GDMWiki/Wiki.jsp?page=Network%20DataSet).
The former is dedicated to diabetes patients of Type I, Type II,
and pre-diabetes, whereas the latter focuses on female diabetes
patients, especially those with gestational diabetes. Our goal is
to recommend discussion threads from Diabetes2 to the users of
Diabetes1. Due to the different vocabulary used by the different websites, we can also regard this problem as recommendation
across heterogeneous domains. In this data set, we randomly collected 5,000 users from Diabetes1. Each user is profiled by a set
of keywords extracted from his/her historical posts on this website. From Diabetes2, we collected 2,790 posts (threads) each of
which is also characterized by a set of keywords. Furthermore, to
fully demonstrate the effectiveness of our proposed approach, we
removed some tags shared by the two forums as a pre-processing
step. When we constructed the bi-partite graphs, we set the edge

468

It is the most naive method for recommendation. To let this baseline be more competitive, we randomly recommended items from
some filtered candidates. In this naive baseline, for Douban movie
recommendation, we randomly selected movies from those having
more than 15,000 reviews and more than 8.8 rating scores. For
Diabetes recommendation, we randomly recommended the posts
from those having more than 2 keywords shared with the users. We
denote this baseline as RAND.

2. Lexical Matching.
It measures the similarity between a user and an item by computing the cosine similarity of their feature (tag/keyword) vectors.
This recommendation scheme can be further divided into two baselines, i.e., LEXIC1 and LEXIC2. In LEXIC1, the vector’s element
is set as 1 if the user/item has the corresponding feature, otherwise
as 0. In LEXIC2, each element of the vector equals to the corresponding feature’s score to the user/item. Obviously, an item will
not be recommended to a user by this method if they do not share
any common feature.

(a) Precision score

(b) Average Precision score

(c) nDCG score

Figure 5: Human assessment performance of Douban movie recommendation. Each column represents a competitor method. The
X-axis represents the number of recommended movies. It shows that our method (GRAPH) beats all baselines in each top-k cases.

3. ESA Matching.

to the query in IR systems [17]. For a set of top-k recommended
items, the nDCG score can be calculated as:

To highlight the effectiveness of our graph propagation approach,
we adopted ESA scheme [11] as a baseline. Specifically, a user
or an item are characterized by a profile vector that is the sum of
concept vectors of user/item’s features. Then, we measure the similarity between a user and an item by the cosine similarity of their
profile vectors.

nDCG =

Besides ESA, Normalized Google Distance (NGD for short) [9]
is also an effective measure on two terms’ semantic relatedness. For
recommendation, the similarity between a user and an item can be
represented by the NGD of their feature (tag/keyword) sets. Specifically, given a user u and an item v, suppose Tu is the in-neighbor
concept set of u’s features in the encyclopedia hyper-link graph,
so is Tv for v’s features. Then the NGD similarity of u and v is
computed as
max{log|Tu |, log|Tv |} − log|Tu ∩ Tv |
logN − min{log|Tu |, log|Tv |}

(6)

where rel(i) is same as Eq. (5) and Z is a normalized factor. Compared with AP, nDCG is more sensitive to rank position of recommended items. In general, a user pays less attention to the items
listed behind, hence nDCG is better to evaluate recommendation
performance.

4. Google Distance.

GS(u, v) = 1 −

k
1 ∑ 2rel(i) − 1
Z i=1 log2 (i + 1)

3.2

Evaluation Results

Next, we present our experimental results. In particular, we use
Precision, Average Precision and nDCG as evaluation metrics to
quantify the acceptance rate of the users to the top-k recommended
items, i.e., movies and posts. Note that we set the α in Equation (2)
to 0.99 when running our algorithm in the experiments. Small variations of α will not affect the comparative performance of our approach versus the competitors. We also study the impact of the
parameter λ on the overall performance, which is used to construct
the connectivity matrix based on semantic matching.

(4)

where N is the total number of concepts in the encyclopedia. We
denote this baseline as GGLDIST.

3.2.1

3.1.4 Performance Metrics

Douban Movie Recommendation

For Douban movie recommendation task, as mentioned before,
the performance results were evaluated by surveying the 100 volunteers who have Weibo accounts in our data set. In order to highlight
our graph-based approach’s superiority, we compared our approach
with all baselines for this recommendation task. Furthermore, we
selected an optimal value of λ (=0.01) in our algorithm. The parameter study of λ will be introduced in the following subsection.
Figure 5(a)∼(c) display the average scores of all competitors’
performance under the three metrics including the performance of
recommending top-4 to top-8 movies. We only list the results from
top-4 to top-8 due to the space limitation of the figures. The results of other top-k recommendations also highlight our method’s
superiority. In the figures, our graph-based method is denoted as
GRAPH. GRAPH0 is a variation of our method where the weights
of Ei (i = 0, 1, 2) are set to 1 or 0 instead of concrete feature
score (for E1 and E2 ) or semantic similarity value of two terms
(for E0 ). From the results we find that all methods perform best
when recommending top-4 movies. Naturally, good recommendation methods should rank the hit items to priority positions. Compared with other competitors, GRAPH almost always performs the
best. The superiority of GRAPH over GRAPH0 justifies the advantage of fine-grained edge weight in the multi-partite graph. The
superiority of ESA and GRAPH over LEXIC1/2 justifies the effec-

In our experiments, we use the following three metrics to quantify the acceptance rate of the users (Weibo users or diabetes users)
to the top-k recommended items (Douban movies or diabetes posts).
The results of these metrics directly reflect the performance of all
recommendation methods.

Precision at rank k (Pr). It is defined as the proportion of
top-k recommended items that are accepted by the users.

Average Precision at rank k (AP). It is the average precision score of top-k recommended items and is defined as:
∑k
i=1 (P (i) × rel(i))
(5)
AP =
M
where rel(i) is an indicator function. It equals to 1 if the i-th recommended item is accepted, otherwise 0. P (i) is the accepted proportion of top-i items and M is the total number of accepted items
in all top-k items. Compared with Pr, AP is more accurate to measure ranking performance.

Normailzed Discounted Cumulative Gain (nDCG). It is
another popular metric to measure relevance level of search results

469

(a) Precision score

(b) Average Precision score

(c) nDCG score

Figure 6: The performance of all competitors on recommending top-4 diabetes posts. It shows that our method (GRAPH) outperforms the baselines no matter how many shared keywords across domains are removed.

(a) Precision score

(b) Average Precision score

(c) nDCG score

Figure 7: Human assessment performance of graph-based method in different λs. Each line depicts a top-k Douban movie recommendation, showing that 0.01 is the best threshold to decide the sparsity of E0 in the bi-partite graph.
cays evidently as more shared keywords are removed, GRAPH only
decays a bit. Even when 50% of shared keywords are removed, our
method’s performance can still stay above 0.6. It indicates that the
graph-based method is more qualified for recommendation across
heterogenous domains with rarely shared features.

tiveness of concept-based semantic interpretation w.r.t. uncovering
the latent relationships between users and items. The superiority of
GRAPH over LEXIC1/2, GGLDIST and ESA indicates that, our
graph-based method can discover more similarities between users
and items that are originally neglected due to the gap of heterogenous domains. The outperformance of our approach over these
baselines should be mainly attributed to graph propagation principle.

3.2.3

Parameter Study

As mentioned before, the parameter λ in our algorithm decides
the sparsity of E0 in the bi-partite graph G0 . That is, for two feature nodes belonging to two different domains respectively, an edge
linking them is established only when the semantic similarity of the
two features is bigger than λ. Then, how does it affect the performance of our graph-based algorithm? To answer this question, we
tested the performance of our approach when the λ is set to different values.
Figure 7(a)∼(c) show our approach’s performance as the function of λ on Douban movie recommendation. In the figures, each
line corresponds the performance of a top-k recommendation where
k varies from 4 to 8. From the figures we can see the performance
of our proposed approach is robust with respect to small variations
in the value of λ. In particular, our approach gains the best performance in all metrics when λ = 0.01. The results of other k’s
values also agree this point. On one hand, it is obvious that too
sparse edges in G0 (larger λ) are not beneficial to the recommendation performance because fewer connections across two domains
can be derived through them. On the other hand, our experiment
results indicate that more edges in G0 (smaller λ) between user
features and item features will not improve the recommendation
performance either because potential noises will be imported by
the additional edges with lower weights in G0 .

3.2.2 Diabetes Post Recommendation
By statistics, we found that there are many shared keywords
across the two diabetes domains. Specifically, the Jaccard coefficient of the keyword sets of two domains is 0.221. As a result,
we first removed a fraction of shared keywords before running the
algorithms in order to simulate the setting of cross-heterogenousdomain recommendation, i.e., few common keywords can be found
in the two domains. Then, we tested the algorithms under different situations when a specific proportion of shared keywords are
deleted. As introduced in Subsec. 3.1.2, the ground truth of diabetes post recommendation were generated according to the principle of LEXIC2. Consequently, we only compared GRAPH with
RAND, GGLDIST and ESA for this recommendation task. Referring to the results of Douban movie recommendation, we only
list the performance of top-4 diabetes posts since all approaches
perform best when recommending top-4 items. The other top-k results will not affect the comparative performance of our proposed
approach versus the competitors.
Figure 6(a)∼(c) depict performance scores of the competitors as
the function of removed proportion of shared keywords where the
proportion varies from 0% to 50%. From the figures we can find
that, although the performance of all methods except for RAND de-

470

4. RELATED WORK

by using the knowledge of document/image labels in auxiliary domains. In this work, relations between documents and images are
captured by their co-occur tags. B. Cao et al. [7] proposed a nonparametric Bayesian framework for solving the collective link prediction, which allows knowledge to be adaptively transferred across
heterogeneous tasks while taking into account the similarities between tasks. These methods are not suitable to be applied in our
setting, where we aim to build the connections between heterogeneous entities across different domains instead of learning multiple
models.

In this section, we survey the research works related to our work
through the following three categories.

4.1 Social and Cross-domain Recommendation
By now, Social Recommender Systems have become the main
part of recommender systems including content-based and structurebased mechanisms. Hannon et al. [13] proposed content-based user
profiling based on CF for recommending new friends in Twitter.
In [1], users are first represented by a frequency vector of hashtags
and entities in tweets and then are recommended to with the URLs
having similar profile vectors. In [3], consumers are recommended
to based on the analysis of product reviews. For structure-based
mechanism, the authors in [4, 8] emphasized that the structure of
social links is an important clue to recommend new users. The social clues are effective on mitigating cold start problem in CF.
More recently, cross-domain recommendation has been a hot
spot in recommendation field. Ignacio et al. [10] made a survey
of emerged solutions for cross-domain recommendation and emphasized two major tasks. One is to exploit knowledge about the
users and the items in the source domain for improving recommendation quality for the items in the target domain. The second
task is to make joint recommendations for the items belonging to
different domains. Many previous works on cross-domain recommendation focus on improving CF-based scheme. For example, the
authors in [19,32] tried to migrate the rating data from a dense auxiliary domain to alleviate the cold start problem in a sparse target
domain resulting in the improvement of recommendation performance in the target domain. Besides, [2, 29] merged user profiles
distributed in different domains for better recommendation. The
settings in above works are different from our problem setting. The
cross-domain setting of Zhang et al.’s work [34] is similar to ours.
But they correlated Facebook users to eBay products through Facebook’s page categories and eBay taxonomy other than the semantic
similarities between features in the heterogenous domains.

4.3

Semantic Relatedness Measurement

In NLP, measuring semantic relatedness of two terms or entities
is an important task. Many prior works utilized the lexical concepts in WordNet’s taxonomy [18] based on the deepest point in
the taxonomy [31] or information content [26]. To expand concept coverage, many researchers took Wikipedia as the knowledge
base of semantic interpretation. M. Strube et al. [28] and D.Milne
et al. [22] used the taxonomy and the Normalized Google Distance [9] in Wikipedia to compute semantic relatedness, respectively. E.Gabrilovich et al. [11] proposed a widely applied model
of semantic interpretation, i.e., Explicit Semantic Analysis which
is also based on the relations between concepts in online encyclopedia. More recently, T. Mikolov et al. [30] proposed word embedding which learns a distributed representation for a word through
neural network. Then the semantic relatedness of two words can
be computed by the distance of two word vectors. This approach is
effective but costly in computation and depends training corpus.

5.

4.2 Transfer Learning across Heterogenous Domains
Transfer learning has been extensively studied in the past decade.
It aims to improve a learning task in a target domain by using the
knowledge transferred from other domain in which a related task
is known [23]. Recently, transfer learning techniques have been
widely applied to mitigate the sparsity problem of collaborative filtering in cross-domain recommendation.
In [19], Li et al. proposed a transfer learning approach that performs a co-clustering strategy on the rating matrix of an auxiliary
domain with high rating density, and discovers rating patterns at the
cluster level. Assuming that user rating behavior is similar in two
domains, the approach establishes relations between domains based
on the found rating patterns. In their other work [20], Li et al. extended the previous approach by means of a probabilistic model in
which a user or item belonging to a particular cluster is not binary,
but is described in terms of probability density function. In this
case a common model is built from the ratings of all the considered
domains, without requiring a dense source domain. Also addressing the sparsity problem in CF-based recommendation, W. Pan et
al. [24] transferred the rating knowledge from some auxiliary data
source in binary form to a target numerical rating matrix through a
novel framework of transfer by collective factorization. In all above
works, the user-item relations, i.e., users’ ratings on items exist in
both domains which is different to our scenario. Y. Zhu et al. [37]
also applied transfer learning method to learn image classification

CONCLUSION

In this paper, we address a new challenging problem of recommendation across heterogenous domains. That is, recommending
the items in one domain to the users in another domain when the
features of the two domains rarely overlap, as well as no user-item
interactive relations in each domain can be obtained. To this end,
we first capture the semantic relations between user features and
item features (tags/keywords) through ESA-based concept interpretation from online encyclopedias. Then, we propose a novel graphbased algorithm to discover the hidden similarity between two entities (users/items) via propagation principle. We not only exploit our
algorithm with solid proofs, but also justify our approach’s performance superiority over the state-of-the-art competitors through extensive evaluations. The results demonstrate our approach’s merits
to many real world applications of cross-domain recommendation.

6.

ACKNOWLEDGEMENTS

This paper was supported by the National NSFC (No.61472085,
61171132, 61033010), by National Key Basic Research Program
of China under No.2015CB358800, by Basic research project of
Shanghai science and technology innovation action plan under
No.15JC1400900, and by Shanghai Science and Technology Development Funds (13dz2260200, 13511504300). This paper was
also partially supported by an IBM Faculty Award.

7.

REFERENCES

[1] F. Abel, Q. Gao, G.-J. Houben, and K. Tao. Analyzing
temporal dynamics in twitter profiles for personalized
recommendations in the social web. In Proc. of WebSci,
2011.

471

[20] B. Li, Q. Yang, and X. Xue. Transfer learning for
collaborative filtering via a rating-matrix generative model.
In Proc. of ICML, 2009.
[21] Z. Lu, E. Zhong, L. Zhao, E. Xiang, W. Pan, and Q. Yang.
Selective transfer learning for cross domain
recommendation. In Proc. of SDM, 2013.
[22] D. Milne and I. H. Witten. An effective, low-cost measure of
semantic relatedness obtained from wikipedia links. In Proc.
of AAAI, 2008.
[23] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE
TKDE, 22(10):1345 - 1359, 2010.
[24] W. Pan, N. N. Liu, E. W. Xiang, and Q. Yang. Transfer
learning to predict missing ratings via heterogeneous user
feedbacks. In Proc. of IJCAI, 2011.
[25] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P.
Flannery. Numerical Recipes: The Art of Scientific
Computing. Cambridge University Press, 2007.
[26] P. Resnick. Using information content to evaluate semantic
similarity in a taxonomy. In Proc. of IJCAI, 1995.
[27] S. Sen, J. Vig, and J. Riedl. Tagommenders: Connecting
users to items through tags. In Proc. of WWW, 2009.
[28] M. Strube and S. P. Ponzetto. Wikirelate! computing
semantic relatedness using wikipedia. In Proc. of AAAI,
2006.
[29] M. Szomszor, H. Alani, I. Cantador, K. OHara, and
N. Shadbolt. Semantic modelling of user interests based on
cross-folksonomy analysis. In Proc. of ISWC, 2008.
[30] M. Tomas, S. Ilya, C. Kai, C. Greg, and D. Jeffrey.
Distributed representations of words and phrases and their
compositionality. In arXiv:1310.4546, 2013.
[31] Z. Wu and M. Palmer. Verb semantics and lexical selection.
In Proc. of ACL, 1994.
[32] W. C. Wynne, H. Mong, and L. Lee. Making
recommendations from multiple domains. In Proc. of
SIGKDD, 2013.
[33] D. Yang, Y. Xiao, H. Tong, J. Zhang, and W. Wang. An
integrated tag recommendation algorithm towards weibo user
profiling. In Proc. of DASFAA, 2015.
[34] Y. Zhang and M. Pennacchiotti. Predicting purchase
behaviors from social media. In Proc. of WWW, 2013.
[35] D. Zhou, J. Weston, A.Gretton, O.Bousquet, and
B. Scholkopf. Ranking on data manifolds. In Proc. of NIPS,
2003.
[36] T. C. Zhou, H. Ma, M. R. Lyu, and I. King. Userrec: A user
recommendation framework in social tagging systems. In
Proc. of AAAI, 2010.
[37] Y. Zhu, Y. Chen, Z. Lu, S. J. Pan, G.-R. Xue, Y. Yu, and
Q. Yang. Heterogeneous transfer learning for image
classification. In Proc. of AAAI, 2011.

[2] F. Abel, E. Herder, G.-J. Houben, N. Henze, and D. Krause.
Cross-system user modeling and personalization on the
social web. In Proc. of UMUAI, 2013.
[3] S. Aciar, D. Zhang, S. Simoff, and J. Debenham.
Recommender system based on consumer product reviews.
In Proc. of WI, 2006.
[4] M. J. Brzozowski and D. M. Romero. Who should i follow?
recommending people in directed social networks. In Proc.
of CSCW, 2011.
[5] R. Burke. Hybrid web recommender systems. LNCS,
4321:377–408, 2007.
[6] I. Cantador, A. Bellogin, and D. Vallet. Content-based
recommendation in social tagging systems. In Proc. of
Recommender System, 2010.
[7] B. Cao, N. N. Liu, and Q. Yang. Transfer learning for
collective link prediction in multiple heterogenous domains.
In Proc. of ICML, 2010.
[8] J. Chen, W. Geyer, C. Dugan, M. Muller, and I. Guy. Make
new friends but keep the old, recommending people on social
networking sites. In Proc. of CHI, 2009.
[9] R. L. Cilibrasi and P. M. Vitanyi. The google similarity
distance. Knowledge and Data Engineering, IEEE
Transactions on, 19(3):370–383, 2007.
[10] I. Fernandez-Tobias, I. Cantador, M. Kaminskas, and
F. Ricci. Cross-domain recommender systems: A survey of
the state of the art. 2011.
[11] E. Gabrilovich and S. Markovitch. Computing semantic
relatedness using wikipedia-based explicit semantic analysis.
In Proc. of IJCAI, 2007.
[12] L. Gall and François. Powers of tensors and fast matrix
multiplication. In Proc. of ISSAC, 2014.
[13] J. Hannon, M. Bennett, and B. Smyth. Recommending
twitter users to follow using content and collaborative
filtering approaches. In Proc. of RecSys, 2010.
[14] Hazewinkel and Michiel. Taylor series. Encyclopedia of
Mathematics, Springer, 2001.
[15] T. Hofmann. Collaborative filtering via gaussian probabilistic
latent semantic analysis. In Proc. of SIGIR, 2003.
[16] T. Hofmann. Latent semantic models for collaborative
filtering. ACM Transactions on Information Systems, 2:89 115, 2004.
[17] K. Jĺarvelin and J. Kekĺalĺainen. Cumulated gain-based
evaluation of ir techniques. ACM Transactions on
Information Systems, 20:422-446, 2002.
[18] F. L., G. E., and Matias. WordNet: An Electronic Lexical
Database. MIT Press, Cambridge, MA., 1998.
[19] B. Li, Q. Yang, and X. Xue. Can movies and books
collaborate? cross-domain collaborative filtering for sparsity
reduction. In Proc. of IJCAI, 2009.

472

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Adaptive Multi-task Sparse Learning
with an Application to fMRI Study
Xi Chen

∗

Jinghui He

†

Rick Lawrence†

Abstract
In this paper, we consider the multi-task sparse learning problem under the assumption that the dimensionality diverges with the sample size. The traditional
l1 /l2 multi-task lasso does not enjoy the oracle property unless a rather strong condition is enforced. Inspired by adaptive lasso, we propose a multi-stage procedure, adaptive multi-task lasso, to simultaneously
conduct model estimation and variable selection across
diﬀerent tasks. Motivated by adaptive elastic-net, we
further propose the adaptive multi-task elastic-net by
adding another quadratic penalty to address the problem of collinearity. When the number of tasks is ﬁxed,
under weak assumptions, we establish the asymptotic
oracle property for the proposed adaptive multi-task
sparse learning methods including both adaptive multitask lasso and elastic-net. In addition to the desirable asymptotic property, we show by simulations that
adaptive sparse learning methods also achieve much improved ﬁnite sample performance. As a case study, we
apply adaptive multi-task elastic-net to a cognitive science problem, where one wants to discover a compact semantic basis for predicting fMRI images. We show that
adaptive multi-task sparse learning methods achieve superior performance and provide some insights into how
the brain represents meanings of words.

Jaime G. Carbonell∗

cessing [1], computational biology [19] and neuroscience
[11]. In multi-task learning, the basic assumption to be
made is how diﬀerent tasks are related to each other.
Popular ways of modeling the relatedness include assuming that all tasks share a common latent feature representation [2] (e.g., sparsity-pattern); or parameters for
diﬀerent tasks are close to each other [7] or share a common prior [25]. We also note that when diﬀerent tasks
share the same input space but diﬀerent output spaces,
the corresponding learning problem is often referred to
as multi-response learning, which can be viewed as a
special case of multi-task learning.
For high-dimensional data, variable selection is of
great importance to improve both prediction accuracy
and model interpretability. The task of conducting
variable selection can always be achieved via learning
the sparsity pattern of parameters. In the multi-task
learning setting, it is often assumed that parameters for
diﬀerent tasks share the same sparsity pattern [2, 18].
To achieve such an eﬀect, a popular approach is to
adopt a joint sparsity regularization to encourage groupwise sparsity across multiple tasks. In particular, one
can adopt the l1 /lq mixed-norm penalty with q > 1
[26, 19, 16]. Given K tasks, the l1 /lq mixed-norm
penalty is deﬁned as:
(1.1)

1 Introduction
The traditional learning problem can often be cast to
the estimation of a function f : X 7→ Y, where X ∈ Rp
is the input space and Y ∈ R is the output space. For
many applications, the entire learning task can often
be divided into several sub-tasks. When sub-tasks are
related, it can be advantageous to learn all tasks simultaneously instead of learning each task independently.
More formally, given K related tasks, the objective of
multi-task learning [23, 5] is to jointly estimate K functions f (k) : X (k) 7→ Y (k) for 1 ≤ k ≤ K. Multi-task
learning has been applied to many practical problems,
including computer vision [21], natural language pro∗ School
† IBM

of Computer Science, Carnegie Mellon University
T.J. Watson Research Center

176
212

λ1

p
∑

∥β j ∥q ,

j=1
(1)

(2)

(K)

where β j = (βj , βj , . . . , βj ) ∈ RK is the coeﬃcient
vector to be estimated for the j-th variable, λ1 is a
positive regularization parameter and p denotes the
dimensionality of the input space. In this paper, we
focus on the widely used l1 /l2 mixed-norm penalty
which encourages the joint sparsity pattern among
diﬀerent tasks.
The traditional l1 /l2 mixed-norm penalty mainly
suﬀers from two problems: (1) each l2 -norm on the coeﬃcient vector shares the same amount of regularization (i.e., λ1 ). This condition might be too restrictive
for practical applications. A natural way to address
this issue is to use a diﬀerent weight w
j for the j-th
∑
p
variable, i.e., to deﬁne the penalty as λ1 j=1 wj ∥β j ∥2 .

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

When there is a prior on the importance of each variable
(e.g., extracted from biological domain knowledge as in
[10] 1 ), the weight wj can be determined based on the
prior knowledge. However, when the prior knowledge of
the weight is unavailable, a natural question is how to
automatically estimate wj from the data. (2) From a
statistical point-of-view, according to [8, 9], a good estimation procedure for sparse learning should have the
following asymptotical oracle property: model
selection
√
consistency and asymptotic normality ( n-estimation
consistency). When the dimensionality p diverges with
the sample size, one fundamental limitation of the l1 /l2 regularized multi-task lasso is that it does not have oracle property unless the design matrix satisﬁes a rather
strong condition [15, 3].2
To address these problems, inspired by adaptive
single-task lasso and its extensions [27, 24, 3, 29], we
propose a multi-stage adaptive estimation procedure
for multi-task sparse learning. More precisely, we ﬁrst
estimate the initial coeﬃcients from the ordinary multitask lasso. Then, we construct adaptive weights for
each variable from the estimated coeﬃcients. As the
last step, ﬁnal coeﬃcients are estimated by another
l1 /l2 -regularized multi-task lasso with the constructed
adaptive weights. We establish the oracle property for
the proposed adaptive multi-task lasso.
In addition, it is known that when the correlation
between predictors is high, lasso leads to unstable variable selection performance. To address the problem
of collinearity, Zou et al. [28] proposed the so-called
elastic-net penalty by adding another quadratic penalty
on top of the sparsity-inducing l1 penalty. In this paper, we apply the elastic-net penalty to the multi-task
learning setting by adding the quadratic penalty on top
of l1 /l2 mixed-norm penalty. We show that the proposed adaptive multi-task elastic-net, as a generalization of adaptive multi-task lasso, also achieves the oracle property under the assumption that the number
of variables diverges with the sample size. In addition
to the asymptotic property, we demonstrate via simulations that adaptive multi-task elastic-net leads to much
better empirical performance for ﬁnite sample case. We
note that the proof of oracle property for both adap-

tive lasso [27] and adaptive group lasso [24, 3] assumes
that the dimensionality p is ﬁxed and hence cannot be
applied here. Our proof directly follows the proof for
adaptive single-task elastic-net in [29].
As an important application, we apply adaptive
multi-task learning methods to a cognitive neuroscience
problem [14, 11], where we are interested in simultaneously predicting the functional magnetic resonance images (fMRI) from the presented word and selecting the
corresponding semantic knowledge basis. We show that
the proposed adaptive multi-task elastic-net achieves superior results.
The rest of this paper is organized as follows. In
Section 2, we overview multi-task lasso and elasticnet penalty. In Section 3, we propose the adaptive
multi-task learning algorithm. In Section 4, we discuss
computational issues. In Section 5, we establish the
oracle property of the proposed adaptive multi-task
learning methods. In Section 6, we present numerical
results on both simulated and real fMRI datasets. We
conclude the paper in Section 7 with a discussion of
possible future work.
2

Background

In this section, we introduce the background of the
multi-task lasso. Consider a K-task linear regression
model:
(2.2)

y (1)

=

X (1) (β (1) )∗ + ϵ(1)

y (2)

=
..
.

X (2) (β (2) )∗ + ϵ(2)

y (K)

=

X (K) (β (K) )∗ + ϵ(K) ,

where for each task k = 1, . . . , K, let X (k) be the
prescribed n(k) × p design matrix, (β (k) )∗ the true
regression coeﬃcients, y (k) the n(k) -dimensional outputs
and ϵ(1) , . . . , ϵ(K) i.i.d. random noises. We assume
that for each task k and dimension j, predictors are
standardized to mean zero and l2 -norm one:
(2.3)

(k)
n
∑

i=1
1 Although

the work in [10] also follows the name “adaptive
multi-task lasso”, our work distinguishes from [10] in that we
automatically construct the prior weights purely from the data
instead of relying on any prior knowledge. The method in [10]
deﬁnes the weight as a linear combination of the data features
from the prior knowledge and jointly optimizes the regression
parameters and linear combination coeﬃcients.
Hence, the
optimization is not only computationally heavy but also has many
local minima.
2 The ﬁnite sample properties of l /l -regularized multi-task
1 2
lasso have been studied in [13].

177
213

(k)
xij

=0

and

(k)
n
∑

(k)

(xij )2 = 1.

i=1

We further assume that the noise has mean 0 and
(k)
(k)
variance σ 2 , i.e., E(ϵj ) = 0 and Var(ϵj ) = σ 2 .
For the notation simplicity, we re-write Eq. (2.2) in
a more compact form:
(2.4)

y = Xβ ∗ + ϵ,

∑K
where y and ϵ are k=1 n(k) -dimensional random vectors formed by stacking y (1) , . . . , y (K) and ϵ(1) , . . . , ϵ(K) .

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Similarly, β ∗ denotes the vector obtained by stacking
{(β (1) )∗ , . . . , (β (K) )∗ }. The design matrix X is a block
diagonal matrix with X (k) being the k-th block.
(k)
: k ∈
Furthermore, we introduce β j ≡ (βj
{1, . . . , K}) for 1 ≤ j ≤ p, that is, the vector formed
by the regression coeﬃcients corresponding to the jth variable and let β denote the vector obtained by
stacking {(β (1) ), . . . , (β (K) )}. The l1 /l2 mixed-norm of
β is deﬁned as:
∥β∥2,1 =

(2.5)

p
∑

Algorithm 1 Adaptive Multi-task Elastic-Net
Input: Input and response for K tasks {y (k) , X (k) }K
k=1 ,
tuning parameters λ1 , λ∗1 , λ2 , and the predeﬁned positive constant γ for constructing adaptive weights.
1.
(3.8)

p
{
}
∑
b = (1+λ2 ) arg min ∥y−Xβ∥22 +λ1
∥β j ∥2 +λ2 ∥β∥22 .
β
β

2.

∥β j ∥2 ,

j=1

√∑
K

(3.9)

b = arg min
β
β

(2.6)

∑

(k)

(k)

βj Xj ∥22 + λ1

j=1

k=1

∑
p

p

∥y (k) −

b ∥2 )−γ ,
w
bj = (∥β
j

for j = 1, . . . , p

(k)

2
where ∥β j ∥2 ≡
k=1 (βj ) has the eﬀect to enforce
the elements in β j to achieve zeros simultaneously.
The multi-task lasso is formulated by minimizing
the squared loss with the l1 /l2 mixed-norm of β:
K
{∑

j=1

∥β j ∥2

}

3.
(3.10)

p
{
}
∑
b ∗ = (1+λ2 ) arg min ∥y−Xβ∥22 +λ∗1
w
bj ∥β j ∥2 +λ2 ∥β∥22 .
β
β

j=1

b ∗.
Output: The ﬁnal estimated coeﬃcients β

j=1

p
{
}
∑
∥β j ∥2 .
≡ arg min ∥y − Xβ∥22 + λ1
β

j=1

To address the problem of collinearity among variables, similar to single-task elastic-net
[28], one can add
∑p
2
another quadratic penalty
j=1 ∥β j ∥2 on top of the
l1 /l2 -regularization and the corresponding multi-task
elastic-net can be formulated as:
(2.7)

p
{
}
∑
b = (1 + λ2 ) arg min ∥y − Xβ∥22 + λ1
∥β j ∥2 + λ2 ∥β∥22 .
β
β

j=1

The motivation for the (1 + λ2 )-scaling is to correct
the∑extra bias introduced by the quadratic penalty
p
λ2 j=1 ∥β j ∥22 . The readers may refer to [28] for more
details on this scaling parameter.
As we discussed in the introduction part, it is desirable to have diﬀerent regularization weights {wj }pj=1
for diﬀerent variables. When there is no prior knowledge
for constructing such weights, it is impractical to tune
each wj individually. Inspired by the adaptive singletask lasso [28] and adaptive single-task elastic-net [29],
we propose our adaptive multi-task learning methods
in the next section which use a data-driven method to
automatically construct the regularization weights.
3 Adaptive Multi-task Sparse Learning
In this section, we present the proposed adaptive multitask elastic-net in Algorithm 1. The algorithm has three
stages. In the ﬁrst stage, we estimate the initial regresb via the multi-task elastic-net with
sion coeﬃcients β
uniform weight for each variable. Then we construct

178
214

the adaptive weights {w
bj }pj=1 from the initial estimated
b as in Eq. (3.9). As the last step, we obcoeﬃcients β
tain the ﬁnal coeﬃcients via the multi-task elastic-net
with the adaptive weights {w
bj }pj=1 .
We ﬁrst note that if λ2 is set to zero, this procedure
reduces to adaptive multi-task lasso. Therefore, we
can view adaptive multi-task lasso as a special case of
adaptive multi-task elastic-net with λ2 = 0.
We also note that for the ease of tuning parameters, Step 1 (Eq. (3.8)) and Step 3 (Eq. (3.10)) share
the same regularization parameter λ2 for the quadratic
penalty. According to our practical experience, using diﬀerent regularization parameters for the quadratic
penalty has very limited improvement on the performance but makes the tuning process much more timeconsuming. In addition, as we show in the next section, the (asymptotic) oracle property can be established without assuming two diﬀerent λ2 s for Step 1 and
3. But for λ1 and λ∗1 , both of them have to be tuned to
guarantee empirical performance and statistical property. We will discuss the choice of the parameters and
the constant γ in more details in Section 5.
4 Computation
As for the optimization problems in Step 1 and 3, due
to the simple structure of l1 /l2 mixed-norm penalty, the
proximal operator associated with the l1 /l2 penalty can
be solved in a closed-form. Therefore, one can easily adopt the Nesterov’s composite gradient methods
[17] (e.g., fast iterative shrinkage thresholding algorithm

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Algorithm 2 FISTA for solving Multi-task Elastic-Net Let α = vt −
with Adaptive Weights
(k) K
Input: {X (k) }K
}k=1 , {w
bj }pj=1 , λ∗1 , λ2 .
k=1 , {y
0
0
Initialization: θ0 = 1, v = β ,
(k)
L = 2 maxK
) + 2λ2
k=1 σmax (X
Iterate For t = 0, 1, 2, . . ., until convergence of β t :

(4.13)

1. Compute ∇h(vt ) according to (4.11).
2. Solve the proximal operator associated with the
l1 /l2 mixed norm penalty:
β t+1 = arg min⟨β, ∇h(vt )⟩ +
β

+λ∗1

(4.12)

L
∥β − vt ∥22
2
p
∑

w
bj ∥β j ∥2

j=1

3. Set θt+1 =
4. Set v

t+1

1+

=β

√

1+4θt2
.
2

t+1

+

t+1
θt −1
θt+1 (β

β t+1
j

1
t
L ∇h(v ).

=

{
(1 −

Then we have:

λ∗
bj
1w
L∥αj ∥2 )αj

0

if ∥αj ∥2 >

λ∗
bj
1w
L

otherwise.

According to [4], Algorithm 2 has a convergence rate
of O( T12 ), where T is the total number of iterations and
the per-iteration complexity is O (min(p, n) · p · K).
We note that the computational cost for Step 3 is
much cheaper than that for Step 1 since one only needs
to conduct estimation on the variables selected from
b is the initial sparse
Step 1. More specially, recall that β
b ̸= 0}
estimate obtained from Step 1, let Ab = {j : β
j
b For those j ∈ Abc ,
and Abc be the complement set of A.
b ∗ = 0. Therefore,
w
bj = ∞ and hence the ﬁnal estimate β
j
for Step 3, instead of solving the full problem, we can
b ∗bc = 0 and then estimate the remaining
ﬁrst set β
A
coeﬃcients by:
K
{∑
∑ (k) (k)
∗
b
β Ab = (1 + λ2 ) arg min
∥y (k) −
βj Xj ∥22

− β ).
t

β

b ∗ = (1 + λ2 )β t+1 .
Output: β

(4.14)

+λ∗1

∑
b
j∈A

(FISTA) [4] or a variant of FISTA with line-search in
[12]) to solve the corresponding optimization problems.
For the purpose of completeness, we present the specialization of FISTA [4] for solving Step 3 (Step 1 can be
viewed as a special case of Step 3) in Algorithm 2.
Let
h(β) = ∥y − Xβ∥22 + λ2 ∥β∥22

k=1

b
j∈A

w
bj ∥β j ∥2 + λ2

∑

}
∥β j ∥22 .

b
j∈A

When using Algorithm 2 to solve Eq.(4.14),
the(
per-iteration ) complexity
reduces
to
c n) · |A|
b ·K
O min(|A|,
as
compared
to
O (min(p, n) · p · K) for solving the full problem.
b ≪ p, there is only a little extra
Since we often have |A|
computational cost for adaptive methods.

be the smooth part of the objective function in Eq. 5 Statistical Property
In this section, we discuss the statistical property of
(3.10) with gradient:
adaptive multi-task elastic-net and lasso. Using the
(4.11)
∇h(β) = 2XT Xβ − 2XT y + 2λ2 β.
same proof technique for adaptive single-task elastic-net
[29], we show that asymptotically adaptive multi-task
The Lipschitz constant L for ∇h(β) is deﬁned as elastic-net has the oracle property, that is, the estimated
follows: for any β 1 and β 2 , we always have ∥∇h(β 1 ) − b ∗
β satisﬁes model selection consistency and asymptotic
∇h(β 2 )∥2 ≤ L∥β 1 − β 2 ∥2 . The closed form of L can be
normality.
easily derived:
We ﬁrst introduce some necessary notations. We
denote
the Gram matrix of X by Ψ = n1 XT X, which is
L = 2 σmax (X) + 2λ2 ,
a block-diagonal matrix with n1 (X (k) )T (X (k) ) as its kK
= 2 max σmax (X (k) ) + 2λ2
th block. Let A be the set of true relevant variable, i.e.,
k=1
(k)
A = {j : β ∗j ̸= 0} with |A| = p0 < p. Let Xj be the
where σmax (X) is the maximum singular value of X.
(k)
j-th column of X (k) and XA be the sub-matrix of X (k)
The proximal operator in Eq. (4.12) can be solved
with the indices of columns in A. Then we deﬁne Xj to
in a closed form as shown in [6, 12]. More speciﬁcally,
(k)
be the block diagonal matrix with Xj as its k-th block,
rewrite Eq. (4.12):
(k)

β t+1

and XA with XA as its k-th block. And we denote ΣA
1
1
as XT X . In addition, let β ∗A be the p0 K sub-vector of
= arg min ∥β−(vt − ∇h(vt ))∥22 +
w
bj ∥β j ∥2 ∗ A A
(1)
(K)
2
L
L j=1
β
β formed by stacking {(βA )∗ , . . . , (βA )∗ }. For the
λ∗1

p
∑

179
215

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

notation simplicity, we assume that the sample size n
We prove the oracle property by extending the proof
for each task is the same.
for adaptive single-task elastic-net in [29] to the multiTo establish the oracle property under the ﬁxed K task case. The proof of asymptotic normality is based on
scenarios, we make the following assumptions:
Lyapunov central limit theorem as in [29]. The detailed
proof is presented in Appendix.
(A1) λmin (Ψ) ≥ b, where b is a positive constant.
Remark 1. Since the assumptions involving λ2 only
∗
∥
λ2
(A2) p = O(nν ) for some 0 ≤ ν < 1
√ 2 = 0,
= 0 and limn→∞ λ2 ∥β
include limn→∞ √
n
n
adaptive multi-task lasso with λ2 = 0 automatically
(A3)
∑K ∑p
satisﬁes these assumptions. Therefore, as a special case
(k) 2
n
maxi=1 k=1 j=1 (xij )
of adaptive multi-task elastic-net, adaptive multi-task
=0
lim
n→∞
n
lasso also enjoys the oracle property.
(A4) There exists δ > 0 such that for any task k and
6 Experiment
(k)
variable j: E(|ϵj |2+δ ) < ∞
In this section, we demonstrate the performance of
The ﬁrst condition (A1) assumes the positive deﬁ- adaptive multi-task sparse learning methods by both
niteness of the Gram matrix. The second one assumes simulated data and a fMRI case study.
that p can diverge with n while the last two assumptions
6.1 Simulated Study We generate data from multiare used for proving the asymptotic normality.
To establish the oracle property, we choose the ﬁxed task linear model with K tasks as in Eq.(2.2). More spe(k)
2
for 1 ≤ k ≤ K follows a p-dimensional
constant γ > 1−ν
for constructing the adaptive weights. cially, each X
The other parameters should be set according to the standard multivariate Gaussian distribution. The true
∗
coeﬃcients are β ∗ = (β1∗ , . . . , β|A|
, 0, . . . , 0)T where
following conditions:
each βj for 1 ≤ j ≤ |A| is drawn from N (3, 0.12 ). We
(B1)
compare multi-task lasso (lasso), multi-task elastic-net
(enet), adaptive multi-task lasso (ada-lasso) and adap∗
λ1
λ
λ2
lim √ = 0;
lim √1 = 0;
lim √ = 0;
tive multi-task elastic-net (ada-enet). We
√ set the samn→∞
n→∞
n→∞
n
n
n
ple size n for each task n = 200, p = 4⌈ n⌉ − 5 = 55,
p0 ≡ |A| = ⌈p/3⌉ = 19, K = 5 or K = 10 and the noise
(B2) In addition, let η = minj∈A (∥β ∗j ∥2 ), we assume level σ = 2 or σ = 4. Since ν = 1/2, we set γ = 2 = 4
1−ν
that λ∗1 and λ2 satisfy the following conditions:
according to the theory. According to our experience,
the result is not very sensitive to the choice of λ2 as
(
)1
λ2 ∥β ∗ ∥2
n γ
long
as it falls into a certain range. Therefore, for the
√
= 0;
lim
η=∞
lim
n→∞
n→∞ pλ∗
n
ease of tuning parameters, we directly set λ2 = 1 for
1
elastic-net. We tune other parameters λ1 and λ∗1 using
The oracle property which contains model selection the same sized held-out validation data generated in the
consistency and asymptotic normality is stated in the same way as the training data.
next theorem:
For each method, we report the mean squared error
∑K
(k) ∗ T b (k) ∗
b (k) ∗
∗
b be the estimator obtained from (MSE) deﬁned by E[ k=1 ((β ) −(β ) ) ((β ) −
Theorem 5.1. Let β
(k) ∗
adaptive multi-task elastic-net in Algorithm 1, under the (β ) )] and the variable selection performance. The
variable selection performance is measured by precision
assumptions (A1)–(A4) and (B1)–(B2), we have
deﬁned by |Ab∗ ∩ A|/|Ab∗ |, recall deﬁned by |Ab∗ ∩ A|/|A|
∗
b ̸= 0} be the set of estimated and F1-score by 2 · precision · recall/(precision + recall).
1. Let Ab∗ = {j : β
j
In addition, we report the mean and standard deviation
relevant variables, Pr(Ab∗ = A) → 1.
of each measure based on 100 runs in Table 1.
From Table 1, we make following interesting obser2. There exists α with ∥α∥2 = 1, such that
vations:
(
)
1/2 b ∗
∗
αT (I + λ2 Σ−1
β
)Σ
−
β
A
A
A
A
1. For all diﬀerent settings of K and σ, adaptive
methods outperform non-adaptive methods in both
model ﬁtting and selection. When the number
of task K increases, the advantage of adaptive
procedures becomes more apparent.

→d N (0, (1 + λ2 )2 σ 2 ),
where ΣA = XTA XA .

180
216

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

K

σ

5

2

5

4

10

2

10

4

K

σ

5

2

5

4

10

2

10

4

Method
lasso
enet
ada-lasso
ada-enet
lasso
enet
ada-lasso
ada-enet
lasso
enet
ada-lasso
ada-enet
lasso
enet
ada-lasso
ada-enet

Method
lasso
enet
ada-lasso
ada-enet
lasso
enet
ada-lasso
ada-enet
lasso
enet
ada-lasso
ada-enet
lasso
enet
ada-lasso
ada-enet

Table 1: Simulation
MSE
5.895 ( 1.731 )
5.512 ( 1.663 )
2.604 ( 0.647 )
2.580 ( 0.617 )
11.116 ( 2.914 )
10.879 ( 2.787 )
10.554 ( 3.074 )
10.551 ( 3.220 )
7.761 ( 1.403 )
7.583 ( 1.438 )
2.391 ( 0.731 )
2.401 ( 0.727 )
16.923 ( 2.771 )
16.479 ( 2.808 )
13.554 ( 4.142 )
13.374 ( 3.970 )

study for n = 200,
F1-score
0.781 ( 0.154 )
0.738 ( 0.152 )
0.815 ( 0.068 )
0.812 ( 0.072 )
0.577 ( 0.069 )
0.579 ( 0.066 )
0.606 ( 0.079 )
0.613 ( 0.078 )
0.719 ( 0.039 )
0.665 ( 0.035 )
0.902 ( 0.057 )
0.896 ( 0.058 )
0.644 ( 0.051 )
0.632 ( 0.047 )
0.743 ( 0.103 )
0.746 ( 0.103 )

p = 55, p0 = 19.
Precision
0.731 ( 0.216 )
0.658 ( 0.206 )
0.828 ( 0.105 )
0.814 ( 0.105 )
0.524 ( 0.142 )
0.522 ( 0.140 )
0.706 ( 0.100 )
0.705 ( 0.101 )
0.564 ( 0.047 )
0.499 ( 0.040 )
0.865 ( 0.081 )
0.850 ( 0.086 )
0.495 ( 0.050 )
0.477 ( 0.047 )
0.792 ( 0.099 )
0.794 ( 0.101 )

Table 2: Simulation study for n = 200, p = 400, p0 = 134.
MSE
F1-score
Precision
8.991 ( 0.786 )
0.633 ( 0.019 )
0.507 ( 0.018 )
6.571 ( 1.432 )
0.579 ( 0.049 )
0.431 ( 0.095 )
8.515 ( 1.143 )
0.632 ( 0.046 )
0.767 ( 0.048 )
6.895 ( 0.986 )
0.651 ( 0.035 )
0.639 ( 0.073 )
16.078 ( 2.017 )
0.547 ( 0.035 )
0.492 ( 0.064 )
13.765 ( 1.363 )
0.506 ( 0.039 )
0.603 ( 0.047 )
12.270 ( 1.442 )
0.488 ( 0.039 )
0.621 ( 0.048 )
12.392 ( 1.572 )
0.549 ( 0.028 )
0.488 ( 0.075 )
13.261 ( 1.250 )
0.703 ( 0.030 )
0.555 ( 0.033 )
12.637 ( 0.968 )
0.561 ( 0.008 )
0.391 ( 0.008 )
8.614 ( 1.075 )
0.809 ( 0.027 )
0.881 ( 0.024 )
6.790 ( 0.897 )
0.798 ( 0.025 )
0.765 ( 0.046 )
20.924 ( 1.443 )
0.629 ( 0.022 )
0.514 ( 0.024 )
19.082 ( 1.320 )
0.591 ( 0.015 )
0.437 ( 0.013 )
18.776 ( 2.050 )
0.654 ( 0.038 )
0.744 ( 0.036 )
16.306 ( 1.891 )
0.666 ( 0.036 )
0.725 ( 0.039 )

2. When the noise level is low (σ = 2), the performance of adaptive multi-task lasso and adaptive
multi-task elastic-net are similar. For larger noise,
adaptive multi-task elastic-net outperforms adaptive multi-task lasso.
3. In terms of variable selection performance, we
observe that the recall for adaptive procedures
is lower than that for non-adaptive ones but the
precision is much higher, which leads to higher F1score. This observation indicates that non-adaptive
procedures tend to select an overly dense model,
thus leading to high recall but very low precision.

181
217

Recall
0.904 (
0.915 (
0.817 (
0.823 (
0.754 (
0.763 (
0.541 (
0.554 (
0.998 (
0.999 (
0.948 (
0.954 (
0.928 (
0.942 (
0.707 (
0.712 (

0.084
0.091
0.099
0.095
0.222
0.223
0.097
0.098
0.010
0.007
0.058
0.055
0.064
0.053
0.126
0.127

)
)
)
)
)
)
)
)
)
)
)
)
)
)
)
)

Recall
0.843 (
0.934 (
0.543 (
0.681 (
0.656 (
0.437 (
0.404 (
0.676 (
0.960 (
0.990 (
0.749 (
0.838 (
0.810 (
0.912 (
0.584 (
0.618 (

0.030
0.085
0.068
0.085
0.135
0.044
0.039
0.158
0.017
0.009
0.044
0.053
0.039
0.025
0.046
0.042

)
)
)
)
)
)
)
)
)
)
)
)
)
)
)
)

Now we study a more challenging case for p > n.
We set p = 2n = 400 and p0 = |A| = ⌈p/3⌉ = 134
and repeat the above experiments. Although the theory
does not directly apply to the case when p grows faster
than n asymptotically, for this experiment, we still set γ
to 4 as in the previous example. In fact, we tune γ in the
range {1, 2, . . . , 5} and observe that the performance is
insensitive with respect to γ. The results are presented
in Table 2.
From Table 2, we can see that when p > n, adaptive
multi-task elastic-net is still the best for most cases in
terms of both model ﬁtting and selection. When K is
small, adaptive multi-task lasso could be worse than

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Table 3: The 60 stimulus words presented during the
fMRI studies. Each row represents a category.
bear
cat
cow
dog
horse
arm
eye
foot
hand
leg
apartment barn
church
house
igloo
arch
chimney closet
door
window
coat
dress
pants
shirt
skirt
bed
chair
desk
dresser
table
ant
bee
beetle
butterfly fly
bottle
cup
glass
knife
spoon
bell
key
refrigerator telephone watch
chisel
hammer pliers
saw
screwdriver
carrot
celery
corn
lettuce
tomato
airplane bicycle
car
train
truck
Figure 1: Model for predicting fMRI activation given a
stimulus word
category includes the words Chisel, Hammer, Pliers,
Saw, Screwdriver, and a furniture category includes Bed,
Chair,
Dresser, Desk, Table, etc. All the 60 words are
multi-task lasso or multi-task elastic-net. When we
presented
in Table 3.
add another quadratic penalty (i.e., adaptive multi-task
Then
nine participants were presented with 60
elastic-net), the performance will be greatly improved.
diﬀerent
words
and were asked to think about each
For non-adaptive methods, when p > n, it is well
word
for
several
seconds while their neural activities
known that adding the quadratic penalty leads to much
were
recorded.
So
that there are altogether n = 60
better performance [28]. From our experiments, similar
fMRI
images
taken
for each participant4 . A typical
conclusions can also be drawn for adaptive methods.
fMRI image contains activities in over 20,000 voxels.
6.2 Application to fMRI Study In this section, We select the top K = 500 voxel responses using the
we present a case study of adaptive multi-task elastic- stability criterion score as described in [14]. By viewing
activation at each single voxel as a task, the output
net by applying it to an important problem in cogni- the
(k)
y
is the neural activation at the k-th voxel and there
tive neuroscience. Speciﬁcally, we consider the task of
are
in
total 500 tasks.
predicting a person’s neural activity in response to an
As
for the input, for each stimulus word, we adopt
English word as described in [14, 11]. The goal is to
the
semantic
features from 218 questions as in [20]5 .
predict the neural image recorded using functional magnetic resonance imaging (fMRI) when a person stares at These questions are related to the size, color, shape,
and thinks about a given word. The experimental pro- property, usage of an object. Example questions include
tocol is illustrated in Figure 1. In more details, given IS IT BODY PART? or CAN YOU HOLD IT?. Given
a stimulus word w, the ﬁrst step encodes the meaning a stimulus word, each question is rated from 1 to 5 (from
of w in terms of intermediate semantic features. The deﬁnitely not to deﬁnitely yes). In other words, each
second step predicts the neural fMRI activation at each stimulus word is mapped into a vector of length 218
voxel 3 of the brain, as a sum of neural activations con- which corresponds to the answers from 218 questions
tributed by each of the intermediate semantic features. to this word. Therefore, in our problem, the design
The training process uses a small number of words to matrix X has p = 218 columns and is shared across all
learn a multi-task linear model that maps the intermedi- K = 500 tasks. These questions can be viewed as a
ate semantic features to neural activation images where set of sematic basis and the question which we try to
answer in this experiment is: What is the top 10 basis
each task is deﬁned by the activation at each voxel.
meanings of the words from
More speciﬁcally, the dataset contains 60 stimulus to best represent semantic
6
diﬀerent
categories
?
words which are composed of nouns from 12 categories
with 5 exemplars per category. For example, a bodypart
category includes Arm, Eye, Foot, Hand, Leg, a tools

4 Each
5 Our

3A

voxel represents a 1-3 mm3 volume in the brain and is the
basic spatial unit of measurement in fMRI.

182
218

image is actually the average of 6 diﬀerent recordings.
intermediate features are diﬀerent from the ones used in

[11].
6 In addition to the top 10 basis, we also conduct experiments to
select various numbers of basis. We observe that adaptive multi-

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

task elastic-net always performs better than the non-adaptive
methods. However, we omit the results due to space limitations.
7 Similar to what we observe in the simulated study, the
performance is insensitive to λ2 and γ.

183
219

Non−adaptive (seperate)
Adaptive (seperate)
Non−adaptive (combined)
Adaptive (combined)

0.9
0.85

Acc

0.8
0.75
0.7
0.65
0.6
0.55

1

2

3

4
5
6
Participant

7

8

9

0.85

0.8

0.75

Acc

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

To automatically learn the semantic basis, we apply the proposed adaptive multi-task elastic-net on the
fMRI data which can simultaneously predict the fMRI
images and perform the basis selection. More speciﬁcally, our evaluation is based on the leave-two-out testing. For each trial, we select 2 words out of the 60
for testing and other 58 words for training. To evaluate the prediction performance, we convert this regression problem into a classiﬁcation problem using the
method in [14]. More speciﬁcally, let two testing images be y1 and y2 , where each one is a 500 × 1 column vector and the predicted images be yb1 and yb2 . If
cos(y1 , yb1 ) + cos(y2 , yb2 ) > cos(y1 , yb2 ) + cos(y2 , yb1 ), we
say the prediction
( ) task for this trial is successful. We
generate all 60
possible pairs for 60 words (1,770 in
2
total) and count the number of times that the joint labeling is correct. The accuracy is deﬁned as the number
of successes over 1770 trials.
For this experiment, lasso methods are always worse
than the corresponding elastic-net methods. Therefore, we only compare adaptive multi-task elastic-net
and multi-task elastic-net with λ2 and γ set to one7 .
For multi-task elastic-net, we tune the regularization
parameter so that 10 basis are selected. For adaptive
multi-task elastic-net, λ1 is tuned using leave-one-out
cross validation on training set; while λ∗ is tuned so
that top 10 basis are included. In addition, there are
in total 9 participants. Therefore, we have two choices
of learning schemes. We can either treat each participant separately or combine fMRI from all participants
(thereby yielding 500 × 9 = 4500 tasks ). The comparison results are presented in Figure 2.
From Figure 2, we can see that for most participants, adaptive procedure signiﬁcantly outperforms the
non-adaptive procedure. The only exception is for the
3rd participant on the separated data and 4th participant on the combined data. The p-value of paired ttest between the results of adaptive and non-adaptive
methods is 0.03884 < 0.05 for the separated data and
0.008446 < 0.5 for the combined data, which further indicates the adaptive method has the advantages over the
non-adaptive method. From the box plot in Figure 2, we
observe that although the median of the combined data
does not have a notable improvement as compared to
that of the separated data, the variance is much smaller.
This indicates that the results obtained from the com-

0.7

0.65

0.6
Non−Ada (sep)

Ada (sep)

Non−Ada (combined)Ada (combined)

Figure 2: Bar and box plots for accuracies for 9 fMRI
participants
bined data are more stable 8 .
In Table 4, we present one example of top 10
questions learned from adaptive multi-task elastic-net.
As we can see, there is a close relationship between
the selected semantic basis and 60 stimulus words. For
example, IS IT AN ANIMAL? refers to words bear,
cat, cow, dog, horse, ant, bee, beetle, butterfly, fly; IS
IT A BODY PART? refers to arm, eye, foot, hand,
leg; IS IT MADE OF WOOD? is related to the
concept furniture, IS IT MANMADE? is related to
many concepts, including clothing, tools, etc. Other
interesting questions are related to the speciﬁc property
of the objects, e.g., CAN YOU EAT IT? and CAN
8 The reported accuracies are lower than the ones in [20]. This
is mainly because we learn a highly sparse model with only 10
semantic basis selected for the variable selection purpose; while
[20] uses ridge regression, which utilizes all 218 features.

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

as representing the oﬃcial policies, either expressed
Table 4: An example of 10 learned semantic basis or implied, of the U.S. Defense Advanced Research
questions.
Projects Agency or the U.S. Government. The U.S.
IS IT AN ANIMAL?
Government is authorized to reproduce and distribute
IS IT A BODY PART?
reprints for Government purposes notwithstanding any
IS IT A BUILDING?
copyright notation hereon.
IS IT A BUILDING PART?
IS IT A TOOL ?
References
IS IT MANMADE?
CAN YOU EAT IT?
CAN YOU HOLD IT?
[1] R. K. Ando and T. Zhang. A framework for learning
IS IT COLORFUL ?
predictive structures from multiple tasks and unlabeled
DOES IT HAVE PARTS?
data. Journal of Machine Learning Research, 6:1817–

YOU HOLD IT?. We also point out that the correlated
semantic basis IS IT MANMADE? and IS IT A
TOOL? are selected simultaneously. It is mainly due to
the “grouping eﬀect” of the quadratic penalty in elasticnet which can simultaneously select highly correlated
variables for the purpose of better interpretability.
7

Conclusion

In this paper, we propose adaptive multi-task lasso and
elastic-net for multi-task sparse learning. Our methods
can learn the regularization weight for each variable in a
data-dependent manner and enjoy the asymptotic oracle
property. We further apply the proposed method to an
interesting fMRI study problem, which leads to superior
performance in terms of predicting fMRI images from
stimulus words.
As an immediate next step, we would like to apply
the idea of adaptive learning to multi-task classiﬁcation
problems where the output space for each task is
discrete. Theoretically, we would like to study the case
where the number of tasks also goes to inﬁnity with
the sample size. In addition, we would like to explore
another aspect of fMRI application: how to decode
the stimulus word from a large set of possible words
according to the recorded fMRI images.
8

Acknowledgement

We would like to thank Mark Palatucci for providing us
the fMRI data that makes this experiment possible. We
would also like to thank Mu Li and Qihang Lin for very
helpful discussions. We thank anonymous reviewers for
their constructive comments on improving the quality of
the paper. Research was sponsored by the U.S. Defense
Advanced Research Projects Agency (DARPA) under
the Anomaly Detection at Multiple Scales (ADAMS)
program, Agreement Number W911NF-11-C-0200. The
views and conclusions contained in this document are
those of the author(s) and should not be interpreted

184
220

1853, 2005.
[2] A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine Learning,
73(3):243–273, 2008.
[3] F. Bach. Consistency of the group lasso and multiple kernel learning. Journal of Machine Learning Research, 1179–1225:2008, 9.
[4] A. Beck and M. Teboulle. A fast iterative shrinkage
thresholding algorithm for linear inverse problems.
SIAM Journal of Image Science, 2(1):183–202, 2009.
[5] R. Caruana. Multitask learning. Machine Learning
Journal, 28:41–75, 1997.
[6] J. Duchi and Y. Singer. Eﬃcient online and batch
learning using forward backward splitting. Journal of
Machine Learning Research, 10:2899–2934, 2009.
[7] T. Evgeniou and M. Pontil. Regularized multitask
learning. In ACM SIGKDD, 2004.
[8] J. Fan and R. Li. Variable selection via nonconcave
penalized likelihood and its oracle properties. Journal
of the American Statistical Association, 96:1348–1360,
2001.
[9] J. Fan and R. Li. Statistical challenges with high dimensionality: Feature selection in knowledge discovery.
In Proceedings of the Madrid International Congress of
Mathematicians, 2006.
[10] S. Lee, J. Zhu, and E. P. Xing. Adatpive multitask lasso: with applications to eqtl detection. In
Advances in Neural Information Processing Systems
(NIPS), 2010.
[11] H. Liu, M. Palatucci, and J. Zhang. Blockwise coordinate descent procedures for the multi-task lasso, with
applications to neural semantic basis discovery. In International Conference on Machine Learning, 2009.
[12] J. Liu, S. Ji, and J. Ye. Multi-task feature learning
via eﬃcient ℓ2,1 -norm minimization. In Conference on
Uncertainty in Artificial Intelligence (UAI), 2009.
[13] K. Lounici, A. B. Tsybakov, M. Pontil, and S. A.
V. D. Geer. Taking advantage of sparsity in multi-task
learning. In Conference on Learning Theory (COLT),
2009.
[14] T. M. Mitchell, S. V. Shinkareva, A. Carlson, K.-M.
Chang, V. L. Malave, R. A. Mason, and M. A. Just.
Predicting human brain activity associated with the
meanings of nouns. Science, 320:1191, 2008.

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

[15] Y. Nardi and A. Rinaldo. On the asymptotic properties of the group lasso estimator for linear models.
Electronic Journal of Statistics, 2:605–633, 2008.
[16] S. Negahban and M. J. Wainwright. Simultaneous support recovery in high dimensions: Beneﬁts and perils
of block ℓ1 /ℓ∞ -regularization. IEEE Transactions on
Information Theory, 57 (6):3841–3863, 2011.
[17] Y. Nesterov. Gradient methods for minimizing composite objective function. Technical report, Universit
catholique de Louvain, Center for Operations Research
and Econometrics (CORE), 2007.
[18] G. Obozinski, B. Taskar, and M. I. Jordan. Highdimensional union support recovery in multivariate regression. In Advances in Neural Information Processing Systems (NIPS). MIT Press, 2008.
[19] G. Obozinski, B. Taskar, and M. I. Jordan. Joint covariate selection and joint subspace selection for multiple classiﬁcation problems. Statistics and Computing,
20:231–252, 2010.
[20] M. Palatucci, D. Pomerleau, G. Hinton, and
T. Mitchell. Zero-shot learning with semantic output
codes. In Advances in Neural Information Processing
Systems (NIPS), 2009.
[21] A. Quattoni, M. Collins, and D. Trevor. Transfer
learning for image classiﬁcation with sparse prototype
representations. In IEEE Conference on Computer
Vision and Pattern Recognition, 2008.
[22] R. Rockafellar. Convex Analysis. Princeton Univ.
Press, 1996.
[23] S. Thrum and L. Pratt. Learning to Learn. Kluwer
Academic Publishers, 1998.
[24] H. Wang and C. Leng. A note on adaptive group lasso.
Computational Statistics and Data Analysis, 52:5277–
5286, 2008.
[25] K. Yu, V. Tresp, and A. Schwaighofer. Learning gaussian processes from multiple tasks. In International
Conference on Machine Learning (ICML), 2005.
[26] M. Yuan and Y. Lin. Model selection and estimation
in regression with grouped variables. Journal of the
Royal Statistical Society: Series B, 68:49–67, 2006.
[27] H. Zou. The adaptive lasso and its oracle properties. Journal of the American Statistical Association,
101(476):1418–1429, 2006.
[28] H. Zou and T. Hastie. Regularization and variable
selection via the elastic net. Journal of the Royal
Statistical Society: Series B, 67(2):301–320, 2005.
[29] H. Zou and H. Zhang. On the adaptive elastic-net with
a diverging number of parameters. Annals of Statistics,
37(4):1733–1751, 2009.

Before we go into the details of the proof for the
model selection consistency, we ﬁrst show the property
of the estimator obtained by multi-task elastic-net with
uniform weights (without (1 + λ2 )-scaling):
Lemma 9.1. Let

{
b 2 , λ1 ) = arg min ∥y − Xβ∥2
β(λ
2
β

(9.15)

+λ1

p
∑

}
wj ∥β j ∥2 + λ2 ∥β∥22 ,

j=1

then we have:
(9.16)
∑
(
)
λ22 ∥β ∗ ∥22 + pKσ 2 + λ21 pj=1 wj2
∗ 2
b
,
E ∥β(λ2 , λ1 ) − β ∥2 ≤ 4
(bn + λ2 )2

If wj = 1 for all 1 ≤ j ≤ p (i.e., uniform weight), then
we have:
(9.17)
∗ 2
(
)
2
2
2
b 2 , λ1 ) − β ∗ ∥2 ≤ 4 λ2 ∥β ∥2 + pKσ + λ1 p ,
E ∥β(λ
2
2
(bn + λ2 )

Proof. The main idea of the proof follows [29] which
introduces the ridge regression estimator:
b 2) =
β(λ

arg min{∥y − Xβ∥22 + λ2 ∥β∥22 }
β

= (XT X + λ2 I)−1 XT y
b 2 , λ1 )−β ∗ into β(λ
b 2 , λ1 )− β(λ
b 2 ) and
We decompose β(λ
∗
b
β(λ2 ) − β , and we can show that
(9.18)

b 2 , λ1 ) − β(λ
b 2 )∥22 ≤
E∥β(λ

b 2 ) − β ∗ ∥22 ) ≤ 2
(9.19) E(∥β(λ

λ21

∑p
j=1

wj2

(bn + λ2 )2

λ22 ∥β ∗ ∥22

+ pKσ 2
(bn + λ2 )2

By the fact that
b 2 , λ1 ) − β ∗ ∥2 ≤
∥β(λ
2

b 2 , λ1 ) − β(λ
b 2 )∥2
2 ∥β(λ
2
∗ 2
b
+2 ∥β(λ2 ) − β ∥ ,
2

we obtain the result in Eq. (9.17).
9

Appendix

In this section, we present the outline of the proof for
model selection consistency in Theorem 5.1. Our proof
directly follows the proof for adaptive single-task elasticnet [29] and extends it to the multi-task case. The
asymptotic normality can be obtained from Lyapunov
central limit theorem as shown in [29].

185
221

We decompose the proof of the model selection consistency into two parts: (1) for any irrelevant variable
b ∗ = 0 tends to be 1; (2)
j ∈ Ac , the probability that β
j
b ∗ ∥2 > 0 tends to 1.
for all j ∈ A, the probability that ∥β
j
Now we present the ﬁrst part of the model selection
consistency in the following proposition:

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

e be the coeﬃcients estimated
Proposition 9.1. Let β
We ﬁrst analyze the last term Pr(b
η ≤ η/2). Let
b 2 , λ1 )j ∥2 ). The event ηb ≤ η/2
by adaptive multi-task elastic-net without the (1 + λ2 )- b
j = arg minj∈A (∥β(λ
scaling:
implies that
{
b 2 , λ1 ) − β ∗ ∥2 ≥ ∥βb∗ ∥2 − ηb ≥ η − ηb ≥ η/2.
e=
(9.25) ∥β(λ
(9.20) β
arg min ∥y − Xβ∥22
j

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

β

+λ∗1

p
∑

w
bj ∥β j ∥2 +

λ2 ∥β∥22

By Markov inequality and Lemma 9.1, we obtain that:

}
,

Pr(b
η ≤ η/2)

j=1

b ∥2 )−γ are the constructed adaptive
where w
bj = (∥β
j
weights. Then we have
(9.26)

e = 0) → 1,
Pr(∀j ∈ Ac , β
j

(9.21)
as n → ∞.

We note that adaptive multi-task elastic-net with
or without (1 + λ2 )-scaling shares the same sparsity
pattern. The reason why we consider adaptive multitask elastic-net without (1 + λ2 )-scaling here is mainly
due to the simplicity of the notation.
Proof. For any vector u, the subdiﬀerential of ∥u∥2 can
be characterized as follows [22]:
{
{ξ : ∥ξ∥2 ≤ 1} α = 0
(9.22)
∂∥ · ∥2 |u =
u
u ̸= 0
∥u∥2

b 2 , λ1 ) − β ∗ ∥2 ≥ η/2)
≤ Pr(∥β(λ
b 2 , λ1 ) − β ∗ ∥2 )
E(∥β(λ
2
≤
η 2 /4
λ22 ∥β ∗ ∥22 + pKσ 2 + λ21 p 1
· 2 ≡ K3
≤
(bn + λ2 )2
η

Now we analyze the ﬁrst term in Eq. (9.24). In
λ∗ 1
order to bound w
bj , we introduce M = ( n1 ) γ and
b 2 , λ1 )j ∥ ≤ M and
consider two separate events ∥β(λ
b
∥β(λ2 , λ1 )j ∥ > M for j ∈ Ac separately. More
speciﬁcally, using the union bound, we obtain that:
∑
T
∗
e
bj , ηb > η/2)
j∈Ac Pr(∥2Xj (y − XA β A )∥2 > λ1 w
∑
e )∥2 > λ∗ w
b > η/2,
≤ j∈Ac Pr(∥2XjT (y − XA β
A
1 bj , η
(9.27)

+

∑

b 2 , λ1 )j ∥ ≤ M )
∥β(λ
b
j∈Ac Pr(∥β(λ2 , λ1 )j ∥2 > M )

By Markov inequality, the last term in Eq. (9.27)
According to the Karush-Kuhn-Tucker condition of
can be easily bounded using the results from Lemma
convex optimization problem in Eq. (9.20), we have
9.1:
e = 0} is the same as
that the event {∀j ∈ Ac , β
∑
j
b 2 , λ1 )j ∥2 > M )
Pr(∥β(λ
c
e ) + λ∗ w
c
b
α
=
0,
∀j
∈
A
,
(9.23) −2XjT (y − XA β
j∈A
j
j
A
1
)
1 (∑ b
2
where αj ∈ ∂∥β∥2 |β=0 . According to the property
E
∥
β(λ
,
λ
)
∥
≤
2
1
j
2
M2
of the subdiﬀerential of l2 -norm as in Eq. (9.22), the
j∈Ac
(
)
condition in Eq. (9.23) is equivalent to:
b 2 , λ1 ) − β ∗ ∥2
E ∥β(λ
2
e )∥2 ≤ λ∗ w
≤
∥2XjT (y − XA β
∀j ∈ Ac .
A
1 bj ,
M2
∗ 2
2
Therefore, Proposition 9.1 is equivalent to saying that:
λ ∥β ∥2 + pKσ 2 + λ21 p 1
(9.28) ≤ 4 2
· 2 ≡ K2
(bn + λ2 )2
M
e )∥2 ≤ λ∗ w
bj ) → 1,
Pr(∀j ∈ Ac , ∥2X T (y − XA β
A

j

1

As for the ﬁrst term in (9.27), we obtain the
bound also by Markov inequality with some algebraic
derivations:

which is further equivalent to:
e )∥2 > λ∗ w
Pr(∃j ∈ Ac , ∥2XjT (y − XA β
A
1 bj ) → 0,
minj∈A (∥β ∗j ∥2 )

and ηb
=
Let η
=
b 2 , λ1 )∥2 ), where β(λ
b 2 , λ1 ) is obtained
minj∈A (∥β(λ
from Eq. (9.15). By repeatedly using the union bound,
we obtain:
e )∥2 > λ∗ w
(9.24) Pr(∃j ∈ Ac , ∥2XjT (y − XA β
A
1 bj )
∑
T
∗
e )∥2 > λ w
Pr(∥2Xj (y − XA β
≤
A
1 bj )
≤

Pr(∥2XjT (y

e )∥2 >
− XA β
A

λ∗1 w
bj , ηb

j∈Ac

(
e )∥2 > λ∗1 w
Pr ∥2XjT (y − XA β
bj ,
A

)
b 2 , λ1 ) j ∥ ≤ M
ηb > η/2, ∥β(λ
∑
e )∥2 > λ∗1 M −γ , ηb > η/2)
≤
Pr(∥2XjT (y − XA β
A
j∈Ac

4M 2γ
E
≤
(λ∗1 )2

j∈Ac

∑

∑

> η/2)

j∈Ac

+ Pr(b
η ≤ η/2)

186
222

(

∑

)
∥XjT (y

e )∥22 I(b
− XA β
η > η/2
A

j∈Ac

4M ( 2 λ22 ∥β ∗ ∥22 + pKσ 2 + (λ∗1 )2 (η/2)−2γ p
≤
8p K
(λ∗1 )2
(bn + λ2 )2
)
(9.29) +2npKσ 2 ≡ K1
2γ

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Now combining Eq. (9.24) with Eq. (9.26), (9.28)
and (9.29), we have

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

e )∥2 > λ∗ w
Pr(∃j ∈ Ac , ∥2XjT (y−XA β
A
1 bj ) ≤ K1 +K2 +K3 .
Under the assumption (A2) and with the param2
eters satisfying (B1) and (B2) and γ > 1−ν
, we have
that K1 , K2 and K3 all go to zero as n goes to inﬁnity.
e = 0) → 1.
Therefore, we obtain that Pr(∀j ∈ Ac , β
j
Now we show the other half of the model selection
e ̸= 0. We characterize it
consistency: for any j ∈ A, β
j
in the next proposition.
e be obtained from Eq. (9.20),
Proposition 9.2. Let β
then we have:
e ∥2 > 0) → 1
Pr(min ∥β
j
j∈A

We ﬁrst introduce

{
}
∑
e (λ2 ) = arg min ∥y − XA β∥22 + λ2
(9.30) β
∥β j ∥22 .
A
β

j∈A

By the same argument as in Eq. (9.25), we have
e ∥2 > min ∥β
e (λ2 )j ∥2 − ∥β
e −β
e (λ2 )∥2
min ∥β
j
A
A
A
j∈A

j∈A

and
e (λ2 )j ∥2 > min ∥β ∗ ∥2 − ∥β
e (λ2 ) − β ∗ ∥2
min ∥β
A
A
j
A
j∈A

j∈A

According to Eq. (9.18) and (9.19), we have
√∑
√
λ∗1
bj2
j∈A w
λ∗1 p max w
bj
e −β
e (λ2 )∥2 ≤
∥β
≤
A
A
bn + λ2
bn + λ2
√ −γ
λ∗1 pb
η
≤
,
bn + λ2
and
e (λ2 ) − β ∗ ∥2 ) ≤ 2
E(∥β
A
2

λ22 ∥β ∗ ∥22 + pKσ 2
(bn + λ2 )2

e −β
e (λ2 )∥2
Then we can easily show that both ∥β
A
A
∗ 2
e
and E(∥β A (λ2 ) − β ∥2 ) converge to zero in probability,
i.e., op (1). Since η = minj∈A ∥β ∗j ∥2 > 0, we have
e ∥2 > 0) → 1.
Pr(minj∈A ∥β
j

187
223

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

BOOSTING WEB IMAGE SEARCH BY CO-RANKING*
Jingrui He1, Changshui Zhang2, Nanyuan Zhao2, Hanghang Tong3
Department of Automation, Tsinghua University, Beijing 100084, China
{hejingrui98, walkstar98}@mails.tsinghua.edu.cn, 2{zcs, zhaony}@tsinghua.edu.cn
1,2

1

ABSTRACT
To maximally improve the precision among top-ranked
images returned by a web image search engine without
putting extra burden on the user, we propose in this paper
a novel co-ranking framework which will re-rank the
retrieved images to move the irrelevant ones to the tail of
the list. The characteristic of the proposed framework can
be summarized as follows: (1) making use of the decisions
from multi-view of images to boost retrieval performance;
(2) generalizing present multi-view algorithms which
need labeled data for initialization to the unsupervised
case so that no extra interaction is required. To
implement the framework, we use one-class support
vector machines to train the basic learner, and propose
different schemes for combination. Experimental results
demonstrate the effectiveness of the proposed framework.

1. INTRODUCTION
To browse through the huge image resource available on
the World Wide Web both effectively and efficiently,
people have designed several web image search engines,
such as Google Image Search, AltaVista Image Search,
AllTheWeb Picture Search, Lycos Multimedia Search, etc.
Generally speaking, these search engines are all textbased, i.e., the images are described by filename, caption,
surrounding text, and text in the HTML document that
displays the images, etc. Compared with content-based
image search engines, their performance in terms of
precision is relatively satisfactory. However, it is often
observed that some top-ranked images are actually
irrelevant to the user’s query concept. This problem may
be attributed to the following reasons: (1) the multiple
meanings of words or phrases used to characterize the
content of an image; (2) misplacement of images in a
totally irrelevant environment; etc. The removal of these
top-ranked irrelevant images will further boost the
performance of web image search engines, and is highly
desirable from the users’ perspective.
*

The above problem can be reformulated as follows:
given a list of images retrieved by a web image search
engine, how to re-rank them in order to move the
irrelevant ones to the tail of the list, and further improve
the precision among top-ranked images accordingly. In
this paper, we take on this problem as a multi-view
problem, and propose a novel co-ranking framework
which is based on the fact that low level image features
can be partitioned into disjoint subsets (views) which
roughly satisfy the assumptions of compatibility and uncorrelation. On the other hand, since in real applications,
the user might be reluctant to provide relevance feedback,
the framework is implemented in an unsupervised manner
without extra interaction with the user, in contrast to
present multi-view learning algorithms [1, 3, 7], which
make use of labeled data for initialization.
Furthermore, we adopt One-Class SVMs (OCS) [2] to
train the basic learner in each view since it is expected to
perform well in a finite sample size setting [2]. To
combine the decisions from different learners, the outputs
of OCS are converted to probabilities using the method in
[5]. Finally, we propose different combination schemes
which are compared via experimental results.
The rest of the paper is organized as follows. In
Sect.2, we briefly review related work in web image reranking and multi-view learning. The proposed coranking framework is presented in Sect.3, with the
implementation issues discussed in Sect.4. Experimental
results are provided in Sect.5, which demonstrate the
effectiveness of the framework from various aspects.
Finally, we conclude the paper in Sect.6.
2. RELATED WORK
To solve the problem of web image re-ranking,
researchers have proposed different methods.
For
example, Yan et al [9] train SVMs whose positive training
data are from the query examples, while negative training
data are from negative pseudo relevance feedback;
however, in the scenario of query by keyword, positive
training data is hard to obtain. And Lin et al [10] propose
a relevance model to calculate the relevance of each

This work is supported by the project (60475001) of the National Natural Science Foundation of China.

0-7803-8874-7/05/$20.00 ©2005 IEEE

II - 409

ICASSP 2005

image, which evaluates the relevance of the HTML
document linking to the image; however, this model
depends on the documents returned by a text web search
engine, which may be totally irrelevant with the retrieved
images.
In a multi-view problem, the features of the domain
can be partitioned into disjoint subsets (views) that are
sufficient to learn the target concept [3]. Several
algorithms have been proposed to deal with this problem.
For example, based on the assumptions of compatibility
and un-correlation, Blum et al [1] propose co-training
which will gradually add self-labeled examples to the
training set; Nigam et al [7] propose co-EM which differs
from co-training in that unlabeled data obtain probabilistic
labels instead of absolute ones and these labels are
updated in each iteration; furthermore, Muslea et al [3]
propose co-EMT, which combines semi-supervised and
active learning. It is worth noticing that all of the above
algorithms need a labeled set to train the initial basic
classifiers. However, in the context of web image
retrieval, the labeled set must be provided by the user,
which will inevitably put extra burden on the user.

The co-ranking framework is well suited for the
problem of web image re-ranking. Firstly, the ranked set
D of unlabeled examples is provided by a web image
search engine based on text description. Secondly, the
criterion is the relevance between each image and the
query concept. Thirdly, by making use of low level image
features to form the views, the above assumptions can be
considerably satisfied, which guarantees a good
performance from theoretical perspective. To be specific,
present low level features can be categorized into color,
texture, shape, etc. It is reasonable to assume that features
belonging to different categories are independent, since
they describe image contents from different perspectives.
On the other hand, although features from different
categories may not be totally compatible, we can still
assume this assumption since the relevant images returned
by a web image search engine are generally similar
enough to be identified by features from any of the
categories, and the number of irrelevant ones is often
small and can be considered as random noise.
z
Inputs:
- a learning problem with two views V 1 and V 2
- an unsupervised learning algorithm L

3. THE PROPOSED CO-RANKING FRAMEWORK

- the ranked set D of m unlabeled examples
Suppose that in the problem domain, we have two views
V 1 and V 2 , thus any example x can be described as
> x1 , x2 @ , where x1 and x1 belong to the two views
respectively. Thus our co-ranking framework comes in
parallel with co-training, and is summarized in Fig.1.
In essence, co-ranking is proposed to deal with the
kind of problems that given a rough ranking of examples,
how to boost the ranking result such that the examples are
sorted in descending order of a certain criterion. Different
from co-training, co-EM, and co-EMT, the framework is
implemented in an unsupervised manner. To be specific,
firstly, the input examples in D do not have labels, and
they only have an initial ranking order; secondly, L is an
unsupervised learning algorithm. Furthermore, in each
iteration, the examples in D will be re-ranked according
to the present combined learner l , which is different from
co-training, co-EM, and co-EMT. Although presently we
only adopt two views, the co-ranking framework can be
easily extended to the situation of more than two views.
Like in the co-training algorithm, two assumptions
should be approximately satisfied for the co-ranking
algorithm to perform well: (1) the two views should be
compatible, i.e., the optimal ranking result can be
obtained from either of the two views; (2) the two views
should be independent in order to refine the ranking result
from different perspectives.
The analysis on the
convergence of our co-ranking framework based on the
above assumptions should be analogous to that of cotraining, and we leave the rigorous analysis to future work.

- the number k of iterations to be performed
z

Loop for k iterations
- use L and V 1 D  to create a basic learner l1 that
will assign a ranking score to each example x
based on present ranking order
- use L and V 2  D  to create a basic learner l2 that
will assign a ranking score to each example x
based on present ranking order
- combine the ranking scores of l1 and l2 to obtain
the combined learner l
- re-rank the examples in D according to l

z

Outputs:
- the combined learner l
- a ranked list of the examples in D
Fig.1. Co-ranking framework

4. IMPLEMENTATION ISSUES
4.1. The Design of Different View
In our current implementation, we use color histogram
feature [8] which belongs to the color category, and
wavelet feature [6] which belongs to the texture category
to form V 1 and V 2 . Although the two views are
constructed using low-level features, the co-ranking

II - 410

method can still improve the retrieval performance, as is
shown in the next section. One can certainly choose other
low-level features and even textual description to form the
views. However, the selection of the optimal views is
beyond the scope of this paper, and we will further extend
our work in this direction.
4.2. One-Class SVMs as the Basic Learner
A key issue of the co-ranking framework is the design of
the unsupervised learning algorithm L . We adopt OneClass SVMs (OCS) [2] to train basic learners in each view,
since it is expected to perform well in a finite sample size
setting. When training data are corrupted by noise, the
performance of OCS will greatly degrade. Given the
present ranking order of the images in D , precision
among top-ranked images are relatively higher than that
among bottom-ranked ones. Therefore, we use n ( n  m )
top-ranked images as the training data for OCS, and the
obtained basic learner will output ranking scores for all
the images in D .
In the co-ranking framework, the outputs of weak
learners must be integrated to get the combined learner l .
However, OCS outputs uncalibrated values, and we need
to convert them to probabilities. Therefore we adopt the
method proposed in [5], which is different from [4] since
the former uses unlabeled data while the latter uses
labeled data. To be specific, we train the parameters of a
sigmoid function to map the outputs to probabilities:
(1)
P  y 1 f  1 ª¬1  exp  Af  B º¼
f  x  is the uncalibrated output of SVMs for

where f

the observation x , y  ^1,1` is the class label, and
P y 1 f



is the posterior probability that x is a positive

example given the output of SVMs. The determination of
A and B is based on the following optimization problem.

^

`

min ¦ i  ti log  pi   1  ti  log 1  pi  
where pi

(2)

1 ª¬1  exp  Af i  B º¼

where fi is the SVMs output of the ith observation xi ,
and ti is the probability of xi being a positive example,
which is obtained via (3).
1 rxi E

(3)
where rx is the ranking order of xi , and E is a positive
ti

To combine the posterior probabilities obtained from
different views, we propose two schemes: (1) to average
the probabilities, (2) to select the largest one. Let p1 and
p 2 denote the probabilistic outputs for V 1 and V 2 , the
combined learner l using the two schemes can be
expressed as (4) and (5) respectively:
l  x

ª¬ p1  x   p 2  x  º¼ 2

(4)

l  x

max ^ p1  x  , p 2  x `

(5)

5. EXPERIMENTAL RESULTS
5.1. Parameter and Operation Setting
To test the performance of the proposed co-ranking
framework in different circumstances, we first form a
general-purpose image database from which the initial
retrieved images are to be simulated. The database
consists of 5,000 Corel images, which are made up of 50
image categories, each having 100 images of essentially
the same topic. To simulate the dataset D of m ranked
images retrieved by a web image search engine, we first
designate a certain category to contain all the relevant
images, fix the ratio ram of relevant images in the m
images, and randomly select images from the database
according to ram . Then we vary the ratio ran of relevant
images in the first n images, which will be fed into OCS
to train the basic learner. In all our experiments, the
adopted performance measure is precision. Each of the
categories is taken as the target, and the precision is
averaged over all categories.
The parameter settings of the co-ranking framework
are as follows. k 20 iterations are performed as a
tradeoff between processing time and performance. The
dataset D consists of m 100 images, and the first n 10
images are used for training OCS. The adopted kernel
function in OCS is the RBF kernel, i.e.,
2
k  xi , x j  exp  xi  x j  2V 2p  . The value of V p is





empirically set to be 0.1, which achieves the best result
among all the choices.
5.2. Comparison of Combination Strategies

i

parameter that controls the decreasing rate of ti as rx

i

increases. Presently, we set it to 1 for simplicity.
Therefore, top-ranked images have a large ti , while
bottom-ranked images have a small one, which is
consistent with our intuition.
4.3. Combination Scheme

As is mentioned in section 4.3, two schemes are available
for obtaining the combined learner l ((4) and (5)). In this
subsection, we perform experiments to compare their
performance. The results are listed in Fig.2.
From Fig.2, we can see that the first strategy, which
averages the probabilities, performs better than the second
one, which selects the larger probability as the final result.
For example, when ran 0.5 , P10 is 93% using the first

II - 411

scheme, and is 83% using the second one. Based on the
experimental results, we will apply the average strategy in
subsequent experiments.

rigorous analysis on the convergence of the proposed
framework; 2) investigate the optimal views for web
image retrieval.

5.3. Comparison with Single View Algorithm
One characteristic of the co-ranking framework is that it
partitions image features into two subsets (views), and the
two views will take the advantage of each other to
iteratively improve the ranking result. One may naturally
come up with the questions that will this partition be of
any good? Will the performance of an algorithm that runs
without feature partition be even better? To answer these
questions, we design another algorithm named iterative
One-Class SVMs (IOCS) for comparison: it differs from
the co-ranking method in that in each iteration, only one
OCS will be trained on all the features. Comparison
results are presented in Fig.3.
Experimental results demonstrate that our co-ranking
algorithm, which partitions the features into two views,
outperforms its counterpart where only a single view is
assumed. For example, when ran 0.8 , P10 using the coranking method is 97.4%, and is 80.1% using IOCS.

Fig.2. ram

0.5

Fig.3. ram

0.5

(a) Google retrieved images

5.4. Experiments with Google Retrieved Images
We have also performed experiments with Google
retrieved images. Given the query keyword “building”,
we first resort to Google to form the initial ranked set D ,
and the first ten images are shown in Fig.4(a). Obviously,
the fourth image is totally irrelevant with the query, and it
is retrieved due to improper text description. Then we
apply the co-ranking framework to D , and the first ten reranked images are shown in Fig.4(b). From the result, we
can see that all of the top-ranked images are closely
related to the query concept, thus the performance of the
web image search engine is improved.
6. CONCLUSION
In this paper, we propose a novel co-ranking framework
to deal with the problem that some top-ranked images
returned by a web image search engine are actually
irrelevant to the user’s query concept. By partitioning the
image features into disjoint subsets (views), the
framework can iteratively boost the ranking result, using
the basic learners trained in each view. One major
difference between this framework and other multi-view
algorithms is that we do not need labeled data for
initialization, while existing algorithms all depend on
labeled data to construct basic learners. In our current
implementation, we choose OCS as the learning algorithm
and design different schemes for the sake of combination.
The effectiveness of the proposed framework is validated
by systematic experiments. Future work includes: 1)

(b) Re-ranked images
Fig.4. Experiments with Google retrieved images
7. REFERENCES
[1] A. Blum, et al, “Combining Labeled and Unlabeled Data
with Co-Training,” Proc. COLT, pp. 92-100, 1998.
[2] B. Scholkopf, et al, “Estimating the Support of a HighDimensional Distribution,” Neural Computation, pp. 1443-1471,
2001.
[3] I. Muslea, et al, “Active + Semi-Supervised Learning =
Robust Multi-View Learning,” Proc. ICML, pp. 435-442, 2002.
[4] J.C. Platt, “Probabilistic Outputs for Support Vector
Machines and Comparisons to Regularized Likelihood
Methods,” In Advances in Large Margin Classifiers, MIT Press,
1999.
[5] J.R. He, et al, “Probabilistic One-Class SVMs in Web
Image Retrieval,” Proc. PCM, 2004.
[6] J.Z. Wang, et al, “Content-Based Image Indexing and
Searching Using Daubechies’ Wavelets,” Int. Journal of Digital
Libraries, vol. 1, pp. 311-328, 1998.
[7] K. Nigam, et al, “Analyzing the Effectiveness and
Applicability of Co-Training,” Proc. CIKM, pp. 86-93, 2000.
[8] M. Swain, et al, “Color Indexing,” IJCV, pp. 11-32, 1991.
[9] R. Yan, et al, “Multimedia Search with Pseudo-Relevance
Feedback,” Int. Conf. on Image and Video l, pp. 238-247, 2003.
[10] W. Lin, et al, “Web Image Retrieval Re-Ranking with
Relevance Model,” Proc. IEEE/WIC Int. Conf. on Web
Intelligence, pp. 242-248, 2003.

II - 412

GenDeR: A Generic Diversified Ranking Algorithm

Hanghang Tong
IBM T.J. Watson Research
Yorktown Heights, NY 10598
htong@us.ibm.com

Jingrui He
IBM T.J. Watson Research
Yorktown Heights, NY 10598
jingruhe@us.ibm.com

Boleslaw K. Szymanski
Rensselaer Polytechnic Institute
Troy, NY 12180
szymab@rpi.edu

Qiaozhu Mei
University of Michigan
Ann Arbor, MI 48109
qmei@umich.edu

Abstract
Diversified ranking is a fundamental task in machine learning. It is broadly applicable in many real world problems, e.g., information retrieval, team assembling,
product search, etc. In this paper, we consider a generic setting where we aim
to diversify the top-k ranking list based on an arbitrary relevance function and
an arbitrary similarity function among all the examples. We formulate it as an
optimization problem and show that in general it is NP-hard. Then, we show that
for a large volume of the parameter space, the proposed objective function enjoys
the diminishing returns property, which enables us to design a scalable, greedy
algorithm to find the (1 − 1/e) near-optimal solution. Experimental results on
real data sets demonstrate the effectiveness of the proposed algorithm.

1 Introduction
Many real applications can be reduced to a ranking problem. While traditional ranking tasks mainly
focus on relevance, it has been widely recognized that diversity is another highly desirable property.
It is not only a key factor to address the uncertainty and ambiguity in an information need, but also
an effective way to cover the different aspects of the information need [14]. Take team assembling
as an example. Given a task which typically requires a set of skills, we want to form a team of
experts to perform that task. On one hand, each team member should have some relevant skills.
On the other hand, the whole team should somehow be diversified, so that we can cover all the
required skills for the task and different team members can benefit from each other’s diversified,
complementary knowledge and social capital. More recent research discovers that diversity plays
a positive role in improving employees’ performance within big organizations as well as their job
retention rate in face of lay-off [21]; in improving the human-centric sensing results [15, 17]; in the
decision of joining a new social media site (e.g., Facebook) [18], etc.
To date, many diversified ranking algorithms have been proposed. Early works mainly focus on
text data [5, 23] where the goal is to improve the coverage of (sub-)topics in the retrieval result. In
recently years, more attention has been paid to result diversification in web search [2, 20]. For example, if a query bears multiple meanings (such as the key word ‘jaguar’, which could refer to either
cars or cats), we would like to have each meaning (e.g., ‘cars’ and ‘cats’ in the example of ‘jaguar’)
covered by a subset of the top ranked web pages. Another recent trend is to diversify PageRank-type
of algorithms for graph data [24, 11, 16]. It is worth pointing out that almost all the existing diversified ranking algorithms hinge on the specific choice of the relevance function and/or the similarity
function. For example, in [2] and [20], both the relevance function and the similarity function implicitly depend on the categories/subtopics associated with the query and the documents; in [16], the
1

relevance function is obtained via personalized PageRank [8], and the similarity is measured based
on the so-called ‘Google matrix’; etc.
In this paper, we shift the problem to a more generic setting and ask: given an arbitrary relevance
function wrt an implicit or explicit query, and an arbitrary similarity function among all the available
examples, how can we diversify the resulting top-k ranking list? We address this problem from
the optimization viewpoint. First, we propose an objective function that admits any non-negative
relevance function and any non-negative, symmetric similarity function. It naturally captures both
the relevance with regard to the query and the diversity of the ranking list, with a regularization
parameter that balances between them. Then, we show that while such an optimization problem
is NP-hard in general, for a large volume of the parameter space, the objective function exhibits
the diminishing returns property, including submodurality, monotonicity, etc. Finally, we propose a
scalable, greedy algorithm to find provably near-optimal solution.
The rest of the paper is organized as follows. We present our optimization formulation for diversified
ranking in Section 2, followed by the analysis of its hardness and properties. Section 3 presents our
greedy algorithm for solving the optimization problem. The performance of the proposed algorithm
is evaluated in Section 4. In Section 5, we briefly review the related work. Finally, we conclude the
paper in Section 6.

2 The Optimization Formulation
In this section, we present the optimization formulation for diversified ranking. We start by introducing the notation, and then present the objective function, followed by the analysis regarding its
hardness and properties.
2.1 Notation
In this paper: we use normal lower-case letters to denote scalers or functions, bold-face lower-case
letters to denote vectors, bold-face upper-case letters to denote matrices, and calligraphic upper-case
letters to denote sets. To be specific, for a set X of n examples {x1 , x2 , . . . , xn }, let S denote the
n × n similarity matrix, which is both symmetric and non-negative. In other words, S i,j = S j,i
and S i,j ≥ 0, where S i,j is the element of S in the ith row and the j th column (i, j = 1, . . . , n).
For any ranking function r(·), which returns the non-negative relevance score for each example
in X with respect to an implicit or explicit query, our goal is to find a subset T of k examples,
which are relevant to the query and diversified among themselves. Here the positive integer k is the
budget of the ranking list size, and the ranking function r(·) generates an n × 1 vector r, whose ith
element r i = r(xi ). When we describe the objective function as well as the proposed optimization
algorithm, it is convenient to introduce the following n × 1 reference vector q = S · r. Intuitively,
its ith element q i measures the importance of xi . To be specific, if xi is similar to many examples
(high S i,j (j = 1, 2, ...., )) that are relevant to the query (high r j (j = 1, 2, ...), it is more important
than the examples whose neighbors are not relevant. For example, if xi is close to the center of a
big cluster relevant to the query, the value of q i is large.
2.2 Objective Function
With the above notation, our goal is to find a subset T of k examples which are both relevant to
the query and diversified among themselves. To this end, we propose the following optimization
problem.
X
X
arg max g(T ) = w
q i ri −
r i S i,j r j
(1)
|T |=k

i∈T

i,j∈T

where w is a positive regularization parameter that defines the trade-off between the two terms, and
T consists of the indices of the k examples that will be returned in the ranking list.
Intuitively, in the goodness function g(T ), the first term measures the weighted overall relevance
of T with respect to the query, and q i is the weight for xi . It favors relevant examples from big
clusters. In other words, if two examples are equally relevant to the query, one from a big cluster and
the other isolated, by using the weighted relevance, we prefer the former. The second term measures
2

the similarity among the examples within T . That is, it penalizes the selection of multiple relevant
examples that are very similar to each other. By including this term in the objective function, we seek
a set of examples which are relevant to the query, but also dissimilar to each other. For example, in
the human-centric sensing [15, 17], due to the homophily in social networks, reports of two friends
are likely correlated so that they are a lesser corroboration of events than reports of two socially
unrelated witnesses.
2.3 The Hardness of Equation (1)
In the optimization problem in Equation (1), we want to find a subset T of k examples that collectively maximize the goodness function g(T ). Unfortunately, by the following theorem, it is NP-hard
to find the optimal solution.
Theorem 2.1. The optimization problem in Equation (1) is NP-hard.
Proof. We will prove this from the reduction of the Densest k-Subgraph (DkS) problem, which is
known to be NP-hard [7].
To be specific, given an undirected graph G(V, E) with the connectivity matrix W , where V is the
set of vertices, and E is the set of edges. W is a |V| × |V| symmetric matrix with elements being 0 or
1. Let |E| be the total number of the edges in the graph. The DkS problem is defined in Equation (2).
X
Q = arg max
W i,j
(2)
|Q|=k

i,j∈Q

Define another |V| × |V| matrix W̄ as: W̄ i,j = 1 − W i,j . It is easy to see that
P
k 2 − i,j∈Q W̄ i,j . Therefore, Equation (2) is equivalent to
X
Q = arg min
W̄ i,j
|Q|=k

Furthermore, notice that
is equivalent to

P|V|

i,j=1

|Q|=k

arg

i,j∈Q

W i,j =

(3)

i,j∈Q

W̄ i,j = |V|2 − |E| = constant. Let T = V \ Q, then Equation (3)
X

arg max
=

P

i∈Q,j∈T

max

|T |=|V|−k

2

X

W̄ i,j +

W̄ i,j +

i∈T ,j∈Q

X

W̄ i,j +

i∈Q,j∈T

X

X

W̄ i,j

i∈T ,j∈T

W̄ i,j

(4)

i,j∈T

Next, we will show that Equation (4) can be viewed as an instance of the optimization problem in
Equation (1) with the following setting: let the similarity function S be W̄ , the ranking function r
be 1|V|×1 , the budget be |V| − k, and the regularization parameter w be 2. Under such settings, the
objective function in Equation (1) becomes
X
X
g(T ) = 2
q i ri −
ri W̄ i,j r j
i∈T

=

2

|V|
XX

i,j∈T

i∈T j=1

=

2

XX

2

XX
i∈Q j∈T

ri W̄ i,j r j

(dfn. of q)

ri W̄ i,j r j

(symmetry of W̄)

i,j∈T

X

ri W̄ ij r j +

i∈Q j∈T

=

X

ri W̄ ij r j −

W̄ ij +

X

i,j∈T

W̄ i,j

(dfn. of r)

(5)

i,j∈T

which is equivalent to the objective function in Equation (4). This completes the proof.
3



2.4 Diminish Returns Property of g(T )
Given that Equation (1) is NP-hard in general, we seek for a provably near-optimal solution instead
in the next section. Here, let us first answer the following question: under what condition (e.g., in
which range of the regularization parameter w), is it possible to find such a near-optimal solution
for Equation (1)?
To this end, we present the so-called diminishing returns property of the goodness function g(T )
defined in Equation (1), which is summarized in the following theorem. By Theorem 2.2, if we
add more examples into an existing top-k ranking list, the goodness of the overall ranking list is
non-decreasing (P2). However, the marginal benefit of adding additional examples into the ranking
list decreases wrt the size of the existing ranking list (P1).
Theorem 2.2. Diminish Returns Property of g(T ). The goodness function g(T ) defined in Equation (1) has the following properties:
(P1) submodularity. For any w > 0, the objective function g(T ) is submodular wrt T ;
(P2) monotonicity. For any w ≥ 2, The objective function g(T ) is monotonically nondecreasing wrt T .
Proof. We first prove (P1). For any T1 ⊂ T2 and any given example x ∈
/ T2 , we have
g(T1 ∪ x) − g(T1 ) =

(w

X

q i ri −

i∈T1 ∪x

=

wq x r x − (

X

X
i,j∈T1 ∪x

ri S i,x r x +

i∈T1

=

X

ri S i,j r j ) − (w
X

X

qi ri −

i∈T1

r i S i,j rj )

i,j∈T1

rx S x,j rj + rx S x,x rx )

j∈T1

wq x r x − S x,x r 2x − 2rx

X

S x,j rj

(6)

j∈T1

Similarly, we have g(T2 ∪ x) − g(T2 ) = wq x r x − S x,x r2x − 2rx
Therefore, we have
(g(T1 ∪ x) − g(T1 )) − (g(T2 ∪ x) − g(T2 )) =

2rx

X

P

j∈T2

S x,j rj .

2rx

X

S x,j rj

j∈T1

j∈T2

=

X

S x,j rj − 2rx
S x,j rj ≥ 0

(7)

j∈T2 \T1

which completes the proof of (P1).
Next, we prove (P2). Given any T1 ∩ T2 = Φ, where Φ is the empty set, with w ≥ 2, we have
X
X
X
X
g(T2 ∪ T1 ) − g(T2 ) = w
qiri − (
ri S i,j r j +
r i S i,j rj +
r i S i,j rj )
i∈T1

=

w

X

i∈T1 ,j∈T2

ri

i∈T1

≥

2

X

ri

2

X

=

2

X

i∈T1

X

S i,j rj −

X

X

ri S i,j rj )

i,j∈T1

ri S i,j rj +

i∈T1 ,j∈T2

j=1

ri

X

i,j∈T1

ri S i,j rj +

i∈T1 ,j∈T2

S i,j r j − 2(

ri (

i∈T1

i∈T2 ,j∈T1

X

S i,j r j − (2

j=1
n
X

j=1
n
X

i∈T1

=

n
X

X

ri S i,j rj )

i,j∈T1

S i,j r j )

j∈T1 ∪T2

S i,j rj ≥ 0

(8)

j ∈T
/ 1 ∪T2



which completes the proof of (P2).
4

3 The Optimization Algorithm
In this section, we present our algorithm GenDeR for solving Equation (1), and analyze its performance with respect to its near-optimality and complexity.
3.1 Algorithm Description
Based on the diminishing returns property of the goodness function g(T ), we propose the following
greedy algorithm to find a diversified top-k ranking list. In Alg. 1, after we calculate the reference
vector q (Step 1) and initialize the ranking list T (Step 2), we try to expand the ranking list T
one-by-one (Step 4-8). At each iteration, we add one more example with the highest score si into
the current ranking list T (Step 5). Each time we expand the current ranking list, we update the
score vector s based on the newly added example i (Step 7). Notice that in Alg. 1, ‘⊗’ means the
element-wise multiplication, and diag(S) returns an n × 1 vector with the corresponding elements
being the diagonal elements in the similarity matrix S.
Algorithm 1 GenDeR
Input: The similarity matrix S n×n , the relevance vector rn×1 , the weight w ≥ 2, and the budget
k;
Output: A subset T of k nodes.
1: Compute the reference vector q: q = Sr;
2: Initialize T as an empty set;
3: Initialize the score vector s = w × (q ⊗ r) − diag(S) ⊗ r ⊗ r;
4: for iter = 1 : k do
5:
Find i = argmaxj (sj |j = 1, ..., n; j ∈
/ T );
6:
Add i to T ;
7:
Update the score vector s ← s − 2ri S :,i ⊗ r
8: end for
9: Return the subset T as the ranking list (earlier selected examples ranked higher).

3.2 Algorithm Analysis
The accuracy of the proposed GenDeR is summarized in Lemma 3.1, which says that for a large
volume of the parameter space (i.e., w ≥ 2), GenDeR leads to a (1 − 1/e) near-optimal solution.
Lemma 3.1. Near-Optimality of GenDeR. Let T be the subset found by GenDeR, |T | = k, and
T ∗ = argmax|T |=k g(T ). We have that g(T ) ≥ (1 − 1/e)g(T ∗ ), where e is the base of the natural
logarithm.
Proof. The key of the proof is to verify that for any example xj ∈
/ T , sj = g(T ∪ xj ) − g(T ),
where s is the score vector we calculate in Step 3 or update in Step 7, and T is the initial empty
ranking list or the current ranking list in Step 6. The remaining part of the proof directly follows the
diminishing returns property of the goodness function in Theorem 2.2, together with the fact that
g(Φ) = 0 [12]. We omit the detailed proof for brevity.

The complexity of the proposed GenDeR is summarized in Lemma 3.2. Notice that the quadratic
term in the time complexity comes from the matrix-vector multiplication in Step 1 (i.e., q = Sr);
and the quadratic term in the space complexity is the cost to store the similarity matrix S. If the
similarity matrix S is sparse, say we have m non-zero elements in S, we can reduce the time
complexity to O(m + nk); and reduce the space complexity to O(m + n + k).
Lemma 3.2. Complexity of GenDeR. The time complexity of GenDeR is O(n2 + nk); the space
complexity of GenDeR is O(n2 + k).


Proof. Omitted for Brevity.
5

4 Experimental Results
We compare the proposed GenDeR with several most recent diversified ranking algorithms, including DivRank based on reinforced random walks [11] (referred to as ‘DR’), GCD via resistive graph
centers [6] (referred to as ‘GCD’) and manifold ranking with stop points [25] (referred to as ‘MF’).
As all these methods aim to improve the diversity of PageRank-type of algorithms, we also present
the results by PageRank [13] itself as the baseline. We use two real data sets, including an IMDB
actor professional network and an academic citation data set. In [11, 6], the authors provide detailed
experimental comparisons with some earlier methods (e.g., [24, 23, 5], etc) on the same data sets.
We omit the results by these methods for clarity.
4.1 Results on Actor Professional Network
The actor professional network is constructed from the Internet Movie Database (IMDB)1 , where
the nodes are the actors/actresses and the edges are the numbers of the co-stared movies between two
actors/actresses. For the inputs of GenDeR, we use the adjacency matrix of the co-stared network as
the similarity function S; and the ranking results by ‘DR’ as the relevance vector r. Given a top-k
ranking list, we use the density of the induced subgraph of S by the k nodes as the reverse measure
of the diversity (lower density means higher diversity). We also measure the diversity of the ranking
list by the so-called ‘country coverage’ as well as ‘movie coverage’ (higher coverage means higher
diversity), which are defined in [24]. Notice that for a good top-k diversified ranking list, it often
requires the balance between the diversity and the relevance in order to fulfill the user’s information
need. Therefore, we also present the relevance score (measured by PageRank) captured by the entire
top-k ranking list. In this application, such a relevance score measures the overall prestige of the
actors/actresses in the ranking list. Overall, we have 3,452 actors/actresses, 23,460 edges, 1,027
movies and 47 countries.
The results are presented in Fig. 1. First, let us compare GenDeR with the baseline method ‘PageRank’. From Fig. 1(d), we can see that our GenDeR is as good as ‘PageRank’ in terms of capturing
the relevance of the entire top-k ranking list (notice that the two curves almost overlap with each
other). On the other hand, GenDeR outperforms ‘PageRank’ in terms of the diversity by all the
three measures (Fig. 1(a-c)). Since GenDeR uses the ranking results by ‘DR’ as its input, ‘DR’
can be viewed as another baseline method. The two methods perform similarly in terms of density
(Fig. 1(c)). Regarding all the remaining measures, our GenDeR is always better than ‘DR’. For
example, when k ≥ 300, GenDeR returns both higher ‘country-coverage’ (Fig. 1(a)) and higher
‘movie-coverage’ (Fig. 1(b)). In the entire range of the budget k (Fig. 1(d)), our GenDeR captures
higher relevance scores than ‘DR’, indicating the actors/actresses in our ranking list might be more
prestigious than those by ‘DR’. Based on these results, we conclude that our GenDeR indeed improves ‘DR’ in terms of both diversity and relevance. The most competitive method is ‘MF’. We
can see that GenDeR and ‘MF’ perform similarly in terms of both density (Fig. 1(c)) and ‘movie
coverage’ (Fig. 1(b)). In terms of ‘country coverage’ (Fig. 1(a)), ‘MF’ performs slightly better than
our GenDeR when 300 ≤ k ≤ 400; and for the other values of k, the two methods mix with each
other. However, in terms of relevance (Fig. 1(d)), our GenDeR is much better than ‘MF’. Therefore,
we conclude that ‘MF’ performs comparably with or slightly better than our GenDeR in terms of
diversity, at the cost of sacrificing the relevance of the entire ranking list. As for ‘GCD’, although
it leads to the lowest density, it performs poorly in terms of balancing between the diversity and the
relevance (Fig. 1(d)), as well as the coverage of countries/movies (Fig. 1(a-b)).
4.2 Results on Academic Citation Networks
This data set is from ACL Anthology Network2. It consists of a paper citation network and a researcher citation network. Here, the nodes are papers or researchers; and the edges indicate the
citation relationship. Overall, we have 11,609 papers and 54,208 edges in the paper citation network; 9,641 researchers and 229,719 edges in the researcher citation network. For the inputs of
GenDeR, we use the symmetrized adjacency matrix as the similarity function S; and the ranking
results by ‘DR’ as the relevance vector r. We use the same measure as in [11] (referred to as ‘coverage’), which is the total number of unique papers/researchers that cite the top-k papers/researchers in
the ranking list. As pointed out in [11], the ‘coverage’ might provide a better measure of the overall
quality of the top-k ranking list than those traditional measures (e.g., h-index) as they ignore the diversity of the ranking list. The results are presented in Fig. 2. We can see that the proposed GenDeR
1
2

http://www.imdb.com/
http://www.aclweb.org/anthology-new/

6

50

1000
PageRank
900

DR

45

MF
800

GCD
GenDeR

700
movie coverage

country coverage

40

35

30

600
500
400

PageRank

25

DR
300

20

MF
GCD

200

GenDeR
15
50

100

150

200

250

300

350

400

450

100
50

500

100

150

200

250

k

350

400

450

500

k

(a) Country Coverage (Higher is better)

(b) Movie Coverage (Higher is better)

0.09

0.35
PageRank

PageRank
0.08

DR

DR

0.3

MF

MF

0.07

GCD

GCD

0.25

GenDeR

GenDeR
relevance

0.06
density

300

0.05
0.04

0.2

0.15

0.03
0.1
0.02
0.05

0.01
0
50

100

150

200

250

300

350

400

450

0
50

500

100

150

200

250

k

300

350

400

450

500

k

(c) Density (Lower is better)

(d) Relevance (Higher is better)

Figure 1: The evaluations on actor professional network. (a-c) are different diversity measures and
(d) measures the relevance of the entire ranking list.
performs better than all the alternative choices. For example, with k = 50, GenDeR improves the
‘coverage’ of the next best method by 416 and 157 on the two citation networks, respectively.
6000

8000
PageRank
7000

DR
5000

MF
6000

GCD
GenDeR

4000

coverage

coverage

5000
3000

4000
3000

2000

PageRank
DR

2000

MF

1000

GCD

1000

GenDeR
0

0

20

40

60

80

0

100

k

0

20

40

60

80

100

k

(a) Paper Citation Network

(b) Researcher Citation Network

Figure 2: The evaluations on academic citation networks. Higher is better.

5 Related Work
Carbonell et al [5] are among the first to study diversified ranking in the context of text retrieval and
summarization. To this end, they propose to use the Maximal Marginal Relevance (MMR) criterion
to reduce redundancy while maintaining query relevance, which is a linear combination of relevance
and novelty. In [23], Zhai et al address this problem from a different perspective by explicitly modeling the subtopics associated with a query, and proposing a framework to evaluate subtopic retrieval.
Recently, researchers leverage external information sources to help with diversified ranking. For example, in [2], Agrawal et al maximize the probability that the average user finds at least one useful
7

result within the top ranked results with the help of a taxonomy available through Open Directory
Project (ODP); in [4], Capannini et al mine the query log to find specializations of a given query,
and use the search results of the specializations to help evaluate the set of top ranked documents;
in [20], Welch et al model the expected number of hits based on the number of relevant documents
a user will visit, user intent in terms of the probability distribution over subtopics, and document
categorization, which are obtained from the query logs, WordNet or Wikipedia.
With the prevalence of graph data, such as social networks, author/paper citation networks, actor
professional networks, etc, researchers have started to study the problem of diversified ranking in
the presence of relationships among the examples. For instance, in [24], Zhu et al propose the
GRASSHOPPER algorithm by constructing random walks on the input graph, and iteratively turning
the ranked nodes into absorbing states. In [11], Mei et al propose the DivRank algorithm based on
a reinforced random walk defined on the input graph, which automatically balances the prestige
and the diversity among the top ranked nodes due to the fact that adjacent nodes compete for their
ranking scores. In [16], Tong et al propose a scalable algorithm to find the near-optimal solution to
diversify the top-k ranking list for PageRank. Due to the asymmetry in their formulation, it remains
unclear if the optimization problem in [16] is NP-hard. On a higher level, the method in [16]
can be roughly viewed as an instantiation of our proposed formulation with the specific choices
in the optimization problem (e.g, the relevance function, the similarity function, the regularization
parameter, etc). In [25], Zhu et al leverage the stopping points in the manifold ranking algorithms
to diversify the results. All these works aim to diversify the results of one specific type of ranking
function (i.e., PageRank and its variants).
Learning to rank [10, 1, 3] and metric learning [19, 22, 9] have been two very active areas in the
recent years. Most of these methods require some additional information (e.g., label, partial ordering, etc) for training. They are often tailored for other purposes (e.g., improving the F-score in the
ranking task, improving the classification accuracy in metric learning, etc) without the consideration
of diversity. Nonetheless, thanks to the generality of our formulation, the learned ranking functions
and metric functions from most of these works can be naturally admitted into our optimization objective function. In other words, our formulation brings the possibility to take advantage of these
existing research results in the diversified ranking setting.
Remarks. While generality is one of the major contributions of this paper, we do not disregard the
value of the domain-specific knowledge. The generality of our method is orthogonal to domainspecific knowledge. For example, such knowledge can be reflected in the (learnt) ranking function
and/or the (learnt) similarity function, which can in turn serve as the input of our method.

6 Conclusion
In this paper, we study the problem of diversified ranking. The key feature of our formulation lies
in its generality: it admits any non-negative relevance function and any non-negative, symmetric
similarity function as input, and outputs a top-k ranking list that enjoys both relevance and diversity.
Furthermore, we identify the regularization parameter space where our problem can be solved nearoptimally; and we analyze the hardness of the problem, the optimality as well as the complexity of
the proposed algorithm. Finally, we conduct experiments on several real data sets to demonstrate
the effectiveness of this algorithm. Future work includes extending our formulation to the on-line,
dynamic setting.

7 Acknowledgement
Research was sponsored by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-09-2-0053. This work was in part supported by the National
Science Foundation under grant numbers IIS-1054199 and CCF-1048168; and by DAPRA under
SMISC Program Agreement No. W911NF-12-C-0028. The views and conclusions contained in this
document are those of the authors and should not be interpreted as representing the official policies,
either expressed or implied, of the Army Research Laboratory, the National Science Foundation, or
the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for
Government purposes notwithstanding any copyright notation here on.

References
[1] A. Agarwal and S. Chakrabarti. Learning random walks to rank nodes in graphs. In ICML, pages 9–16,
2007.

8

[2] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. Diversifying search results. In WSDM, pages
5–14, 2009.
[3] C. J. C. Burges, K. M. Svore, P. N. Bennett, A. Pastusiak, and Q. Wu. Learning to rank using an ensemble
of lambda-gradient models. Journal of Machine Learning Research - Proceedings Track, 14:25–35, 2011.
[4] G. Capannini, F. M. Nardini, R. Perego, and F. Silvestri. Efficient diversification of search results using
query logs. In WWW (Companion Volume), pages 17–18, 2011.
[5] J. G. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents
and producing summaries. In SIGIR, pages 335–336, 1998.
[6] A. Dubey, S. Chakrabarti, and C. Bhattacharyya. Diversity in ranking via resistive graph centers. In KDD,
pages 78–86, 2011.
[7] U. Feige, G. Kortsarz, and D. Peleg. The dense k-subgraph problem. Algorithmica, 29, 1999.
[8] T. H. Haveliwala. Topic-sensitive pagerank: A context-sensitive ranking algorithm for web search. IEEE
Trans. Knowl. Data Eng., 15(4):784–796, 2003.
[9] P. Jain, B. Kulis, and I. S. Dhillon. Inductive regularized learning of kernel functions. In NIPS, pages
946–954, 2010.
[10] T.-Y. Liu. Learning to rank for information retrieval. In SIGIR, page 904, 2010.
[11] Q. Mei, J. Guo, and D. R. Radev. Divrank: the interplay of prestige and diversity in information networks.
In KDD, pages 1009–1018, 2010.
[12] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An analysis of approximations for maximizing submodular set functionsłi. MATHEMATICAL PROGRAMMING, (1):265–294, 1973.
[13] L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: Bringing order to the
web. Technical report, Stanford Digital Library Technologies Project, 1998. Paper SIDL-WP-1999-0120
(version of 11/11/1999).
[14] F. Radlinski, P. N. Bennett, B. Carterette, and T. Joachims. Redundancy, diversity and interdependent
document relevance. SIGIR Forum, 43(2):46–52, 2009.
[15] M. Srivastava, T. Abdelzaher, and B. Szymanski. Human-centric sensing. Phil. Trans. R. Soc. 370 ser.
A(1958), pages 176–197, 2012.
[16] H. Tong, J. He, Z. Wen, R. Konuru, and C.-Y. Lin. Diversified ranking on large graphs: an optimization
viewpoint. In KDD, pages 1028–1036, 2011.
[17] M. Y. S. Uddin, M. T. A. Amin, H. Le, T. Abdelzaher, B. Szymanski, and T. Nguyen. On diversifying
source selection in social sensing. In INSS, 2012.
[18] J. Ugander, L. Backstrom, C. Marlow, and J. Kleinberg. Structural diversity in social contagion. PNAS,
109(16):596–5966, 2012.
[19] J. Wang, H. Do, A. Woznica, and A. Kalousis. Metric learning with multiple kernels. In NIPS, pages
1170–1178, 2011.
[20] M. J. Welch, J. Cho, and C. Olston. Search result diversity for informational queries. In WWW, pages
237–246, 2011.
[21] L. Wu. Social network effects on performance and layoffs: Evidence from the adoption of a social
networking tool. Job Market Paper, 2011.
[22] E. P. Xing, A. Y. Ng, M. I. Jordan, and S. J. Russell. Distance metric learning with application to clustering
with side-information. In NIPS, pages 505–512, 2002.
[23] C. Zhai, W. W. Cohen, and J. D. Lafferty. Beyond independent relevance: methods and evaluation metrics
for subtopic retrieval. In SIGIR, pages 10–17, 2003.
[24] X. Zhu, A. B. Goldberg, J. V. Gael, and D. Andrzejewski. Improving diversity in ranking using absorbing
random walks. In HLT-NAACL, pages 97–104, 2007.
[25] X. Zhu, J. Guo, X. Cheng, P. Du, and H. Shen. A unified framework for recommending diverse and
relevant queries. In WWW, pages 37–46, 2011.

9

2015 IEEE International Conference on Data Mining

On the Connectivity of Multi-layered Networks:
Models, Measures and Optimal Control
Chen Chen, Jingrui He, Nadya Bliss and Hanghang Tong
Arizona State University
Tempe, Arizona 85287, USA
Email: {chen chen, jingrui.he, nadya.bliss, hanghang.tong}@asu.edu
so does the information network. In this application, the
different layers form a tree-structured dependency graph.
Compared with singlelayered networks, multilayered networks are even
more vulnerable to external
attacks analogous to the
Butterﬂy Effect in the
atmosphere system. That is,
even a small disturbance on
one supporting layer/network
might cause a ripple effect
to
all
the
dependent
layers,
leading
to
a
catastrophic/cascading
failure of the entire system.
In 2012, Hurricane Sandy
Fig. 1. A simpliﬁed example of
disabled several major power
multi-layered network.
generator facilities in the New York area, which not only
put tens of thousands of people in dark for a long time,
but also paralyzed the telecom network and caused a great
interruption on the transportation network. Therefore, it is of
key importance to identify crucial nodes in the supporting
layer/network, whose loss would lead to a catastrophic failure
of the entire system, so that counter measures can be taken
proactively.

Abstract—Networks appear naturally in many high-impact
real-world applications. In an increasingly connected and coupled
world, the networks arising from many application domains
are often collected from different channels, forming the socalled multi-layered networks, such as cyber-physical systems,
organization-level collaboration platforms, critical infrastructure
networks and many more. Compared with single-layered networks, multi-layered networks are more vulnerable as even a
small disturbance on one supporting layer/network might cause
a ripple effect to all the dependent layers, leading to a catastrophic/cascading failure of the entire system. The state-of-theart has been largely focusing on modeling and manipulating the
cascading effect of two-layered interdependent network systems
for some speciﬁc type of network connectivity measure.
This paper generalizes the challenge to multiple dimensions.
First, we propose a new data model for multi-layered networks
(M U L A N), which admits an arbitrary number of layers with a
much more ﬂexible dependency structure among different layers,
beyond the current pair-wise dependency. Second, we unify a wide
range of classic network connectivity measures (S UB L INE). Third,
we show that for any connectivity measure in the S UB L INE family,
it enjoys the diminishing returns property which in turn lends
itself to a family of provable near-optimal control algorithms
with linear complexity. Finally, we conduct extensive empirical
evaluations on real network data, to validate the effectiveness of
the proposed algorithms.
Keywords—multi-layered network; connectivity control;

I. I NTRODUCTION
Networks are ubiquitous and naturally appear in many
high-impact applications. Moreover, in a way reminiscent of the famous quote from Leonardo da Vinci1 , the networks arising from these application domains are often interconnected/interwined with each other, forming the so-called
multi-layered networks [3], [8], [16], [18]. Cyber-physical
systems are a classic example of multi-layered networks,
where the control layer controls the physical layer (e.g.,
power grid) through the communication layer (e.g., computer
networks); and in the meanwhile, the fully functioning of the
communication layers depends on the sufﬁcient power supply
from the physical layer. Here, these three interdependent layers
naturally form a line-structured dependency graph. Another example is the organization-level collaboration platforms
(Fig. 1), where the team network is supported by the social
network, connecting its employee pool, which further interacts
with the information network, linking to its knowledge base.
Furthermore, the social network layer could have an embedded
multi-layered structure (e.g., each of its layers represents a
different collaboration type among different individuals); and
1 “Learn

In response to such an imminent need, a recent trend in
multi-layered networks research community has been focusing
on modeling and manipulating the cascading effect of twolayered interdependent network systems [3], [15], [18], [19],
[8]. Although much progress has been made, several key
challenges have largely remained open. First (modeling), most,
if not all, of these existing work is devoted to two-layered
networks with a pair-wise dependency structure; and thus
it is not clear how to represent and model multiple (more
than two) layers with a more generic dependency structure.
Second (connectivity measures), there does not exist one
single network connectivity measure that is superior to all
other measures; but rather several connectivity measures are
prevalent in the literature (e.g., robustness, vulnerability, triangle counts). Each of the existing controlling algorithms on
multi-layered networks is tailored for one speciﬁc connectivity
measure. It is not clear if an algorithm designed for one speciﬁc
connectivity measure is still applicable to other measures. So
how can we design a generic control strategy that applies to
a variety of prevalent network connectivity measures? Third
(optimal control), an optimal control strategy tailored for twolayered networks might be sub-optimal, or even misleading to

how to see. Realize that everything is connected to everything else.”

1550-4786/15 $31.00 © 2015 IEEE
DOI 10.1109/ICDM.2015.104

715

network G, where G(i, j) = 1 indicates layer j depends
on layer i (or layer i supports layer j), G(i, j) = 0 means
no direct dependency from layer i to layer j; (2) a set of
within-layer adjacency matrices A = {A1 , . . . , Ag }; (3) a
set of inter-layer node-node dependency matrices D, indexed
by pair (i, j), i, j ∈ [1, . . . , g], such that for a pair (i, j),
if G(i, j) = 1, then D(i,j) is an ni × nj matrix; otherwise
D(i,j) = Φ (i.e., an empty set); (4) θ is a one-to-one mapping function that maps each node in layer-layer dependency
network G to the corresponding within-layer adjacency matrix
Ai (i = 1, ..., g); (5) ϕ is another one-to-one mapping function
that maps each edge in G to the corresponding inter-layer
node-node dependency matrix D(i,j) . We deﬁne a multi-layered
network as a quintuple Γ =< G, A, D, θ, ϕ >.
For simplicity, we restrict the within-layer adjacency matrices Ai to be simple (i.e., no self-loops), symmetric and
binary; and the extension to the weighted, asymmetric case
is straight-forward. In this paper, we require inter-layer dependency network G to be an un-weighted directed acyclic graph
(DAG). Notice that compared with the existing pair-wise twolayered model, it allows a much more ﬂexible and complicated
dependency structure among different layers. For the interlayer node-node dependency matrix D(i,j) , D(i,j) (s, t) = 1
indicates that node s in layer i supports node t in layer j.

multi-layered networks, e.g., in case we want to simultaneously
optimize the connectivity of multiple layers by manipulating
one common supporting layer. On the theoretic side, the
optimality of the connectivity control problem of generic
multi-layered networks is largely unknown.
This paper aims to address all these challenges, and the
main contributions can be summarized as
• New Data Models. We propose a novel multi-layered
network model (M U L A N), which admits an arbitrary
number of layers with a much more ﬂexible node-level
dependency structure among different layers, beyond
the current pair-wise dependency (Section II).
• Connectivity Measures. We unify a family of prevalent
network connectivity measures (S UB L INE), in close
relation to a variety of important network parameters
(e.g., epidemic threshold, network robustness, triangle
counting) (Section III).
• Optimal Control. We show that for any network connectivity measure in the S UB L INE family, the optimal
connectivity control problem with the proposed M U L A N model enjoys the diminishing returns property,
which naturally lends itself to a family of provable
near-optimal control algorithms with linear complexity
(Section IV).
• Empirical Evaluations. We perform extensive experiments based on real data sets to validate the effectiveness of the proposed algorithms. (Section V).
II. A N EW M ULTI - LAYERED N ETWORK M ODEL
In this section, we propose our new multi-layered network
model that admits an arbitrary number of layers with a more
generic dependency structure among different layers. We start
with the main symbols used throughout the paper ( Table I). We
use bold upper case letters for matrices (e.g., A, B), bold lower
case letters for column vectors (e.g., a, b) and calligraphic font
for sets (e.g., A, B). The transpose of a matrix is denoted with
a prime, i.e., A is the transpose of matrix A.
TABLE I.

Symbol
A, B
a, b
A, B
A(i, j)
A(i, :)
A(:, j)
A
G
A
D
θ, ψ
Γ
Si , T i , . . .
Si→j
N (Si )
m i , ni
λ<A,j> , u<A,j>
λA , uA
C(A)
IA (Si )
I(Si )

Fig. 2(a) presents an example of a four-layered network. In
this example, Layer 1 (e.g., the control layer) is the supporting
layer (i.e., the root node in the layer-layer dependency network
G). Layer 2 and Layer 3 directly depend on Layer 1 (e.g.,
one represents a communication layer by satellites and the
other represents another communication layer in landlines,
respectively), while Layer 4 (e.g., the physical layer) depends
on both communication layers (Layer 2 and Layer 3). The
abstracted layer-layer dependency network (G) is shown in
Fig. 2(b). A = {A1 , A2 , A3 , A4 } denotes the within-layer
adjacency matrices, each of which describes the network
topology in the corresponding layer. In this example, D is a set
of matrices containing only four non-empty matrices: D(1,2) ,
D(1,3) , D(2,4) , and D(3,4) . For example, D(3,4) describes the
node-node dependency between Layer 3 and Layer 4. The oneto-one mapping function θ maps node 1 (i.e., Layer 1) in G
to the within-layer adjacency matrix of Layer 1 (A1 ); and the
one-to-one mapping function ϕ maps edge < 3, 4 > in G to
the inter-layer node-node dependency matrix D(3,4) as shown
in Fig. 2(b).

M AIN S YMBOLS .

Deﬁnition and Description
the adjacency matrices (bold upper case)
column vectors (bold lower case)
sets (calligraphic)
the element at ith row j th column
in matrix A
the ith row of matrix A
the j th column of matrix A
transpose of matrix A
the layer-layer dependency matrix
networks at each layer of M U L A N
A = {A1 , . . . , Ag }
inter-layer node-node dependency matrices
one to one mapping functions
multi-layered network M U L A N
Γ =< G, A, D, θ, ψ >
node sets in layer Ai (calligraphic)
nodes in Aj that depend on nodes S in Ai
nodes and inter-layer links that depend on Si
number of edges and nodes in layer Ai
j th largest eigenvalue (in module) and its
corresponding eigenvector of network A
ﬁrst eigenvalue and eigenvector of network A
connectivity function of network A
impact of node set Si on network A
overall impact of node set Si to M U L A N

III. U NIFICATION OF C ONNECTIVITY M EASURES
In this section, we present a uniﬁed view for a variety of
prevalent network connectivity measures.
The key of our uniﬁed connectivity measure (referred to as
S UB L INE in this paper) is to view the connectivity of the entire
network as an aggregation over the connectivity measures of
its sub-networks (e.g., subgraphs), that is,

f (π)
(1)
C(A) =
π⊆A

where π is a subgraph of A. The non-negative function f :
π → R+ maps any subgraph in A to a non-negative real
number and f (Φ) = 0 for empty set Φ. In other words, we
view the connectivity of the entire network (C(A)) as the sum
of the connectivity of all the subgraphs (f (π)). Based on such
a connectivity deﬁnition, we further deﬁne the impact function

With the above notation, we introduce a new data model
for multi-layered networks as follows.
Deﬁnition 1. A Multi-layered Network Model (M U L A N).
Given (1) a binary g × g abstract layer-layer dependency
716

(b) The corrsponding layer-layer dependency network G

(a) A four-layered network
Fig. 2.

An illustrative example of M U L A N model

of a given set of nodes S as follows, where A\S is the residual
network after removing the set of nodes S from the original
network A.
I(S) = C(A) − C(A \ S)
(2)

attacked/deleted (e.g., shaded circle nodes), all the nodes from
Layer 2 and Layer 3 that are dependent on S (e.g., shaded
parallelogram and triangle nodes) will be disabled/deleted,
which will in turn cause the disfunction of the nodes in Layer
4 (e.g., shaded diamond nodes) that depend on these affected
nodes in Layer 2 or Layer 3. Our goal is to choose k nodes
from Layer 1 that have the maximal impact on both Layer 2
and Layer 4, i.e., to simultaneously decrease the connectivity
C(A2 ) and C(A4 ) as much as possible.
B. O PERA: Theory
In this subsection, we present the major theoretic results of
the optimal connectivity control problem (O PERA) on multilayered networks deﬁned in Problem 1. It says that for any
connectivity function C(A) in the S UB L INE family (eq. (1)),
for any multi-layered network in the M U L A N family (Deﬁnition 1), the optimal connectivity control problem (O PERA,
Problem 1) bears diminishing returns property.

Based on eq. (2), we can deﬁne the overall impact of node
set Si in Ai on the multi-layered network system as
I(Si ) =

g

j=1

αj I(Si→j ) =

g


αj (C(Aj ) − C(Aj \ Si→j ))

j=1

(3)
where α = [α1 , ..., αg ] is a g × 1 non-negative weight vector
that assigns different weights to different layers in the system.
Si→j denotes the set of nodes in layer-j that depend on nodes
S in layer-i.
It turns out many prevalent network connectivity measures
can be interpreted from this perspective. Examples include
path capacity, loop capacity and triangle capacity. We omit
the detailed discussions due to space limit.
IV. O PTIMAL C ONNECTIVITY C ONTROL
In this section, we ﬁrst deﬁne the optimal connectivity control problem (O PERA) on the proposed multi-layered network
model (M U L A N); then unveil its major theoretic properties;
and ﬁnally propose a generic algorithmic framework to solve
it.

Theorem 1. Diminishing Returns Property of M U L A N.
For any connectivity function C(A) in the S UB L INE family
(eq. (1)), for any multi-layered network in the M U L A N family
(Deﬁnition 1); the
overall impact of node set Sl in the control
g
layer l, I(Sl ) = i=1 αi I(Sl→i ), is (a) monotonically nondecreasing; (b) sub-modular; and (c)normalized.
Proof: Omitted for space.
C. O PERA: Algorithms
In this subsection, we introduce our algorithm to solve
O PERA (Problem 1).

A. O PERA: Problem Statement
We formally deﬁne the optimal connectivity control problem (O PERA) on the proposed M U L A N model for multilayered networks as follows.
Given: (1) a multi-layered network Γ =< G, A, D, θ, ψ > (2)
a control layer Al , (3) an impact function I(.), and (4) an
integer k (budget);

A Generic Solution Framework. Finding out the global
optimal solution for Problem 1 by a brute-force method
would be computationally intractable, due to the exponential
enumeration. Nonetheless, the diminishing returns property of
the impact function I(.) (Theorem 1) immediately lends itself
to a greedy algorithm for solving O PERA with any arbitrary
connectivity function in the S UB L INE family and an arbitrary
member in the M U L A N family, summarized in Algorithm 1.

Output: a set of k nodes Sl from the control layer (Al ) such
that I(Sl ) (the overall impact of Sl ) is maximized.
In the above deﬁnition, the control layer Al indicates the
sources of the ‘attack’; and the g × 1 vector α indicates the
target layer(s) as well as their relative weights. For instance,
in Figure 2(a), we can choose Layer 1 as the control layer
(indicated by the strike sign); and set α = [0 1 0 1 ] , which
means that both Layer 2 and Layer 4 are the target layers
(indicated by the star signs) with equal weights between them.
In this example, once a subset of nodes S in Layer 1 are

In Algorithm 1, Steps 2-4 calculate the impact score
I(v0 ) (v0 = 1, 2, ...) for each node in the control layer Al .
Step 5 selects the node with the maximum impact score.
In each iteration in Steps 7-19, we select one of the remaining (k − 1) nodes, which would make the maximum
marginal increase in terms of the current impact score (Step
12, margin(v0 ) = I(S ∪ {v0 }) − I(S)). In order to further
speed-up the computation, the algorithm admits an optional
lazy evaluation strategy (adopted from [11]) by activating an
optional ‘if’ condition in Step 11.

Problem 1. O PERA on M U L A N

717

nodes in target layer(s), and then trace back to its supporting
layer through the inter-layer dependency links (i.e., D). For
both strategies, we need a node importance measure. In our
evaluations, we compare three such measures, including (1)
node degree; (2) pagerank measure [13]; and (3) Netshield
values [21]. In addition, for comparison purposes, we also
randomly select nodes either from the control layer (for
the forward propagation strategy) or from the target layer(s)
(for the backward propagation strategy). Altogether, we have
eight baseline methods (four for each strategy, respectively),
including (1) ‘Degree-FP’, (2) ‘PageRank-FP’, (3) ‘NetshieldFP’, (4) ‘Rand-FP’, (5) ‘Degree-BP’, (6) ‘PageRank-BP’, (7)
‘Netshield-BP’, (8) ‘Rand-BP’.

We can show that Algorithm 1 leads to a near-optimal
solution with linear complexity, thanks to the diminishing
returns property in Theorem 1. We omit the detailed algorithm
analysis due to space limit.
Algorithm 1 O PERA: A Generic Solution Framework
Input: (1) A multi-layered network Γ, (2) a control layer Al ,
(3) an overall impact function I(Sl ) and (4) an integer k
Output: a set of k nodes S from the control layer Al .
1: initialize S to be empty
2: for each node v0 in layer Al do
3:
calculate margin(v0 ) ← I(v0 )
4: end for
5: ﬁnd v = argmaxv0 margin(v0 ) and add v to S
6: set margin(v) ← −1
7: for i = 2 to k do
8:
set maxMargin ← −1
9:
for each node v0 in layer Al do
10:
/*an optional ‘if’ for lazy eval.*/
11:
if margin(v0 ) > maxMargin then
12:
calculate margin(v0 ) ← I(S ∪ {v0 }) − I(S)
13:
if margin(v0 ) > maxMargin then
14:
set maxMargin ← margin(v0 ) and v ← v0
15:
end if
16:
end if
17:
end for
18:
add v to S and set margin(v) ← −1
19: end for
20: return S
V. E XPERIMENTAL R ESULTS
In this section, we empirically evaluate the proposed
O PERA algorithms. All experiments are designed to show the
effectiveness of the proposed O PERA algorithms at optimizing
the connectivity measures (deﬁned in the proposed S UB L INE
family) of a multi-layered network (from the proposed M U L A N family).

O PERA Algorithms and Variants. We evaluate three prevalent network connectivity measures, including (1) the leading eigenvalue of the (within-layer) adjacency matrix, which
relates to the epidemic threshold of a variety of cascading
models; (2) the loop capacity (LC), which relates to the robustness of the network; and (3) the triangle capacity (TC), which
relates to the local connectivity of the network. As mentioned
in Section III, both the loop capacity and the triangle capacity
are members of the S UB L INE family. Strictly speaking, the
leading eigenvalue does not belong to the S UB L INE family.
Instead, it approximates the path capacity (PC), and the latter
(PC) is a member of the S UB L INE family. Correspondingly,
we have three instances of the proposed O PERA algorithm
(each corresponding to one speciﬁc connectivity measures) including ‘O PERA-PC’, ‘O PERA-LC’, and ‘O PERA-TC’. Recall
that there is an optional lazy evaluation step (Step 11) in the
proposed O PERA algorithm, thanks to the diminishing returns
property of the S UB L INE connectivity measures. When the
leading eigenvalue is chosen as the connectivity function, such
a diminishing returns property does not hold any more. To
address this issue, we introduce a variant of O PERA-PC as
follows. At each iteration, after the algorithm chooses a new
node v (Step 18, Algorithm 1), we (1) update the network by
removing all the nodes that depend on node v, and (2) update
the corresponding leading eigenvalues and eigenvectors. We
refer to this variant as ‘O PERA-PC-Up’. For each of the three
connectivity measures, we run all four O PERA algorithms.

A. Experimental Setup
Data Sets Summary. We perform the evaluations on three
application domains, including (D1) a multi-layered Internet
topology at the autonomous system level (M ULTI AS); and
(D2) critical infrastructure networks (I NFRA N ET). For each
application domain, we use real networks to construct the
within-layer networks (i.e., A in the M U L A N model) and
construct one or more inter-layer dependency based on real
application scenarios (i.e., G and D in the M U L A N model).
A summary of these data sets is shown in Table II. We will
present the detailed description of each application domain in
Subsection V-B.
TABLE II.
Data Sets
D1
D2

Application Domains
M ULTI AS
I NFRA N ET

Machines and Repeatability. All the experiments are performed on a machine with 2 processors Intel Xeon 3.5GHz
with 256GB of RAM. The algorithms are programmed with
MATLAB using single thread. All data sets used in this paper
are publicly available. Due to the space limit, we omit the
actual ﬁgures for some experimental results. We will include
these additional results in an extended technical report.

DATA S ETS S UMMARY.
# of Layers
2∼4
3

# of Nodes
5,929∼24,539
19,235

B. Effectiveness Results
D1 - M ULTI AS. This data set contains the Internet topology
at the autonomous system level. The data set is available at
http://snap.stanford.edu/data/. It has 9 different network snapshots, with 633 ∼ 13, 947 nodes and 1, 086 ∼ 30, 584 edges.
In our evaluations, we treat these snapshots as the withinlayer adjacency matrices A. For a given supporting layer,
we generate the inter-layer node-node dependency matrices
D by randomly choosing 3 nodes from its dependent layer
as the direct dependents for each supporting node. For this
application domain, we have experimented with different layerlayer dependency structures (G), including a two-layered network, a three-layered line-structured network, a three-layered

# of Links
11,183∼50,778
46,926

Baseline Methods. To our best knowledge, there is no
existing method which can be directly applied to the connectivity optimization problem (Problem 1) of the proposed
M U L A N model. We generate the baseline methods using
two complementary strategies, including forward propagation
(‘FP’ for short) and backward propagation (‘BP’ for short).
The key idea behind the forward propagation strategy is that
an important node in control layer might have more impact
on its dependent networks as well. On the other hand, for
the backward propagation strategy, we ﬁrst identify important
718

Fig. 3. Evaluations on the M ULTI AS data set, with a four-layered diamond-shaped dependency network. The connectivity change vs. budget. Larger is better.
All the four instances of the proposed O PERA algorithm (in red) outperform the baseline methods.

and (b) multi-layered network analysis.
Network Connectivity Control. Connectivity is a fundamental property of networks, and has been a core research
theme in graph theory and mining for decades. Depending on
the speciﬁc applications, many network connectivity measures
have been proposed in the past. Examples include the size
of giant connected component (GCC), graph diameter, the
mixing time [9], the vulnerability measure [1], the epidemic
thresholds [4], the natural connectivity [10] and number of
triangles in the network, each of which often has its own,
different mathematical deﬁnitions.

tree-structured network and a four-layered diamond shaped
network. Figure 3 shows the results on the diamond shaped network. All the four instances of the proposed O PERA algorithm
perform better than the baseline methods. Among the baseline
methods, the backward propagation methods are better than
the forward propagation methods. This is because the length of
the back tracking path on the dependency network G (from the
target layer to the control layer) is short. Therefore compared
with other baseline methods, the node set returned from the
BP strategy is able to affect more important nodes in the target
layer. The results on the other dependent networks are similar
and omitted due to the space limit. In all these scenarios, the
proposed O PERA algorithms perform best consistently.
D2 - I NFRA N ET. This data set contains three types of
critical infrastructure networks, including (1) the power grid,
(2) the communication network; and (3) the airport networks. The power grid is an undirected, un-weighted network representing the topology of the Western States Power Grid of the United State [23]. It has 4,941 nodes and
6,594 edges. We use one snapshot from the M ULTI AS data set as the communication network with 11,461 nodes
and 32,730 edges. The airport network represents the internal US air trafﬁc lines between 2,649 airports and has
13,106 links (available at http://www.levmuchnik.net/Content/
Networks/NetworkData.html). We construct a triangle-shaped
layer-layer dependency network G (see the icon of Figure 4)
based on the following observation. The operation of an airport
depends on both the electricity provided by the power grid and
the Internet support provided by the communication network.
In the meanwhile, the full functioning of the communication
network depends on the support of power grid. We use the
similar strategy as M ULTI AS to generate the inter-layer nodenode dependency matrices D. The results are summarized in
Figure 4. Again, the proposed O PERA algorithms outperform
all the baseline methods. Similar to the M ULTI AS network,
the back tracking path from the airport layer to the power grid
layer is also very short. Therefore the backward propagation
strategies perform relatively better than other baseline methods.
In addition, we also change the density of the inter-layer
node-node dependency matrices and evaluate its impact on the
optimization results (detailed results are omitted for space).
We found that (1) across different dependency densities, the
proposed O PERA algorithms still outperform the baseline
methods; and (2) when the dependency density increases, the
algorithms lead to a larger decrease of the corresponding
connectivity measures with the same budget.
VI. R ELATED W ORK
In this section, we review the related work, which can be
categorized into two groups: (a) network connectivity control,

From algorithm’s perspective, network connectivity control
aims to optimize (e.g., maximize or minimize) the corresponding connectivity measure by manipulating the underlying
topology (e.g., add/remove nodes/links). Recent work tries
to solve this problem by collectively ﬁnding a subset of nodes/links with the highest impact on the network connectivity
measure. For example, Tong et al. [21], [20] proposed both
node-level and edge-level manipulation strategies to optimize
the leading eigenvalue of the network, which is the key
network connectivity measure behind a variety of cascading
models. In [5], Chan et al. further generalized these strategies
to manipulate the network robustness measure through the
truncated loop capacity [10]. Another important aspect of
network connectivity control lies in the network dynamics.
Chen et al. in [6] proposed an efﬁcient online algorithm to
track some important network connectivity measures (e.g., the
leading eigenvalue, the robustness measure) on a temporal
dynamic network.
Multi-Layered Network Analysis. Multi-layered networks have been attracting a lot of research attention in recent
years. In [16] and [7], the authors presented an in-depth
introduction on the fundamental concepts of interdependent,
multi-layered networks as well as the key research challenges.
In a multi-layered network, the failure of a small number of
the nodes might lead to catastrophic damages on the entire
system as shown in [3] and [22]. In [3], [15], [19], [18], [8],
different types of two-layered interdependent networks were
thoroughly analyzed. In [7], Gao et al. analyzed the robustness
of multi-layered networks with star- and loop-shaped dependency structures. Similar to the robustness measures in [17],
most of the current works use the size of GCC (giant connected
component) in the network as the evaluation standard [14],
[12], [2]. Nonetheless, the ﬁne-granulated connectivity details
might not be captured by the GCC measure.
VII. C ONCLUSION
In this paper, we study the connectivity control problem
on multi-layered networks (O PERA). Our main contributions
719

Fig. 4. Evaluations on the I NFRA N ET data set, with a three-layered triangle-shaped dependency network. The connectivity change vs. budget. Larger is better.
All the four instances of the proposed O PERA algorithm (in red) outperform the baseline methods.

are as follows. First, we propose a new data model for
multi-layered networks (M U L A N), which admits an arbitrary
number of layers with a much more ﬂexible dependency
structure among different layers, beyond the current pair-wise
dependency. Second, we unify a family of prevalent network
connectivity measures (S UB L INE). Third, we show that for
any network connectivity measure in the S UB L INE family,
the optimal connectivity control problem with the proposed
M U L A N model enjoys the diminishing returns property, which
naturally lends itself to a family of provable near-optimal
control algorithms with linear complexity. Finally, we conduct extensive empirical evaluations on real network data, to
validate the effectiveness of the proposed algorithms. In the
future, we plan to generalize M U L A N to an arbitrary layerlayer dependency network as well as the dynamic setting.
ACKNOWLEDGEMENT
This material is supported by the National Science Foundation under Grant No. IIS1017415, by the Army Research
Laboratory under Cooperative Agreement Number W911NF09-2-0053, by Defense Advanced Research Projects Agency
(DARPA) under Contract Number W911NF-11-C-0200 and
W911NF-12-C-0028, by National Institutes of Health under
the grant number R01LM011986, Region II University Transportation Center under the project number 49997-33 25.

[7]

J. Gao, S. V. Buldyrev, S. Havlin, and H. E. Stanley. Robustness of a
network of networks. Physical Review Letters, 107(19):195701, 2011.
[8] J. Gao, S. V. Buldyrev, H. E. Stanley, and S. Havlin. Networks formed
from interdependent networks. Nature physics, 8(1):40–48, 2012.
[9] M. Jerrum and A. Sinclair. Conductance and the rapid mixing property
for markov chains: the approximation of permanent resolved. In
Proceedings of the twentieth annual ACM symposium on Theory of
computing, pages 235–244. ACM, 1988.
[10] W. Jun, M. Barahona, T. Yue-Jin, and D. Hong-Zhong. Natural connectivity of complex networks. Chinese Physics Letters, 27(7):078902,
2010.
[11] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, J. VanBriesen,
and N. Glance. Cost-effective outbreak detection in networks. In
Proceedings of the 13th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 420–429. ACM, 2007.
[12] D. T. Nguyen, Y. Shen, and M. T. Thai. Detecting critical nodes
in interdependent power networks for vulnerability assessment. IEEE
Trans. Smart Grid, 4(1):151–159, 2013.
[13] L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank
citation ranking: Bringing order to the web. Technical report, Stanford
Digital Library Technologies Project, 1998. Paper SIDL-WP-1999-0120
(version of 11/11/1999).
[14] M. Parandehgheibi and E. Modiano. Robustness of interdependent
networks: The case of communication networks and the power grid. In
Global Communications Conference (GLOBECOM), 2013 IEEE, pages
2164–2169. IEEE, 2013.
[15] R. Parshani, S. V. Buldyrev, and S. Havlin. Interdependent networks:
Reducing the coupling strength leads to a change from a ﬁrst to second
order percolation transition. Physical review letters, 105(4):048701,
2010.
[16] S. M. Rinaldi, J. P. Peerenboom, and T. K. Kelly. Identifying,
understanding, and analyzing critical infrastructure interdependencies.
Control Systems, IEEE, 21(6):11–25, 2001.
[17] C. M. Schneider, A. A. Moreira, J. S. Andrade, S. Havlin, and H. J.
Herrmann. Mitigation of malicious attacks on networks. Proceedings
of the National Academy of Sciences, 108(10):3838–3841, 2011.
[18] A. Sen, A. Mazumder, J. Banerjee, A. Das, and R. Compton. Multilayered network using a new model of interdependency. arXiv preprint
arXiv:1401.1783, 2014.
[19] J. Shao, S. V. Buldyrev, S. Havlin, and H. E. Stanley. Cascade of
failures in coupled network systems with multiple support-dependent
relations. arXiv preprint arXiv:1011.0234, 2010.
[20] H. Tong, B. A. Prakash, T. Eliassi-Rad, M. Faloutsos, and C. Faloutsos.
Gelling, and melting, large graphs by edge manipulation. In Proceedings
of the 21st ACM international conference on Information and knowledge
management, pages 245–254. ACM, 2012.
[21] H. Tong, B. A. Prakash, C. Tsourakakis, T. Eliassi-Rad, C. Faloutsos,
and D. H. Chau. On the vulnerability of large graphs. In Data Mining
(ICDM), 2010 IEEE 10th International Conference on, pages 1091–
1096. IEEE, 2010.
[22] A. Vespignani. Complex networks: The fragility of interdependency.
Nature, 464(7291):984–985, 2010.
[23] D. J. Watts and S. H. Strogatz. Collective dynamics of smallworldnetworks. nature, 393(6684):440–442, 1998.

The content of the information in this document does not
necessarily reﬂect the position or the policy of the Government,
and no ofﬁcial endorsement should be inferred. The U.S. Government is authorized to reproduce and distribute reprints for
Government purposes notwithstanding any copyright notation
here on.
R EFERENCES
[1]
[2]

[3]

[4]

[5]

[6]

R. Albert, H. Jeong, and A.-L. Barabási. Error and attack tolerance of
complex networks. Nature, 406(6794):378–382, 2000.
A. Bernstein, D. Bienstock, D. Hay, M. Uzunoglu, and G. Zussman.
Power grid vulnerability to geographically correlated failuresanalysis
and control implications. In INFOCOM, 2014 Proceedings IEEE, pages
2634–2642. IEEE, 2014.
S. V. Buldyrev, R. Parshani, G. Paul, H. E. Stanley, and S. Havlin.
Catastrophic cascade of failures in interdependent networks. Nature,
464(7291):1025–1028, 2010.
D. Chakrabarti, Y. Wang, C. Wang, J. Leskovec, and C. Faloutsos. Epidemic thresholds in real networks. ACM Transactions on Information
and System Security (TISSEC), 10(4):1, 2008.
H. Chan, L. Akoglu, and H. Tong. Make it or break it: manipulating robustness in large networks. In Proceedings of 2014 SIAM International
Conference on Data Mining, pages 325–333. SIAM, 2014.
C. Chen and H. Tong. Fast eigen-functions tracking on dynamic graphs.
In Proceedings of the 2015 SIAM International Conference on Data
Mining. SIAM, 2015.

720

Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI 2015)

MUVIR: Multi-View Rare Category Detection
Dawei Zhou, Jingrui He, K. Seluk Candan, Hasan Davulcu
Arizona State University
Tempe, Arizona
{dzhou23,jingrui.he,candan,hdavulcu}@asu.edu

Abstract

In many real-world applications, the data consists of multiple views, or features from multiple information sources.
For example, in synthetic ID detection, we aim to distinguish
between the true identities and the fake ones generated for
the purpose of committing fraud. Each identity is associated
with information from various aspects, such as demographic
information, online social behaviors, banking behaviors. Another example is insider threat detection, where the goal is to
detect malicious insiders in a large organization, by collecting various types of information regarding each employee’s
daily behaviors. To detect the rare categories in these applications, simply concatenating all the features from multiple
views may lead to sub-optimal performance in terms of increased number of label requests, as it ignores the relationship
among the multiple views. Furthermore, among the multiple
information sources, some may generate features irrelevant
to the identification of the rare examples, thus deteriorates
the performance of rare category detection.
To address this problem, in this paper, we propose a novel
framework named MUVIR for detecting the initial examples from the minority classes in the presence of multi-view
data. The key idea is to integrate view-specific posterior
probabilities of the example coming from the minority class
given features from each view, in order to obtain the estimate of the overall posterior probability given features from
all the views. In particular, the view-specific posterior probabilities can be inferred from the scores computed using
a variety of existing techniques [He and Carbonell, 2007;
He et al., 2008]. Furthermore, MUVIR can be generalized
to handle problems where the exact priors of the minority
classes are unknown. To the best of our knowledge, this paper is the first principled effort on rare category detection in
the presence of multiple views. Compared with existing techniques, the main advantages of MUVIR can be summarized
as follows.
1. Effectively leveraging the relationship among multiple
views to improve the performance of rare category detection;
2. Robustness to irrelevant views;
3. Flexibility in terms of the base algorithm used for generating view-specific posterior probabilities.
The rest of this paper is organized as follows. After a brief
review of the related work in Section 2, we introduce the pro-

Rare category detection refers to the problem
of identifying the initial examples from underrepresented minority classes in an imbalanced data
set. This problem becomes more challenging in
many real applications where the data comes from
multiple views, and some views may be irrelevant
for distinguishing between majority and minority
classes, such as synthetic ID detection and insider
threat detection. Existing techniques for rare category detection are not best suited for such applications, as they mainly focus on data with a single
view.
To address the problem of multi-view rare category
detection, in this paper, we propose a novel framework named MUVIR. It builds upon existing techniques for rare category detection with each single
view, and exploits the relationship among multiple
views to estimate the overall probability of each example belonging to the minority class. In particular, we study multiple special cases of the framework with respect to their working conditions, and
analyze the performance of MUVIR in the presence
of irrelevant views. For problems where the exact
priors of the minority classes are unknown, we generalize the MUVIR algorithm to work with only an
upper bound on the priors. Experimental results on
both synthetic and real data sets demonstrate the effectiveness of the proposed framework, especially
in the presence of irrelevant views.

1

Introduction

In contrast to the large amount of data being generated and
used everyday in a variety of areas, it is usually the case that
only a small percentage of the data might be of interest to
us, which form the minority class. However, without initial
labeled examples, the minority class might be very difficult
to detect with random sampling due to the imbalance nature
of the data, and the limited budget for requesting labels from
a labeling oracle. Rare category detection has been proposed
to address this problem, so that we are able to identify the
very first examples from the minority class, by issuing a small
number of label requests to the labeling oracle.

4098

Rare Category Detection
Rare category analysis has also been studied for years. Up
to now, many methods have been approached to address this
problem. In this paper, we mainly review the following two
existing works on rare category detection. The first one is
[He and Carbonell, 2007], in which algorithm NNDM is proposed standing on two assumptions: (i) data sets have little
knowledge about labels (ii) there is no separability or nearseparability between majority and minority classes. Both assumptions exactly meet the setting of the problem we want
to figure out. The probability distribution function (pdf) of
the majority class tends to be locally smooth, while the pdf of
minority class tends to be a more compact cluster. In general,
the algorithm measures the changes of local density around
a certain point. NNDM gives a score to each example, and
the score is the maximum difference of local density between
one item and all of its neighboring points. By querying the
examples with the largest score, it is able to hit the region of
minority class with the largest probability.
Another work about rare category detection is [He et al.,
2008], the authors provided an upgraded algorithm GRADE
based on NNDM. In this algorithm, they took the consideration of the manifold structure in minority class. For example,
two examples from the same minority class on the manifold
may be far away in Euclidean distance. In this case, they generate a global similarity matrix embedded all of the examples
from the original feature space. The items of minority class
are made to form a more compact cluster for each minority
class. Based on global similarity matrix, they measure the
changes of local density for each example. The changes of local density, to some extent, has been enlarged, and made the
minority classes easier to be discovered. Furthermore, they
provided an approximating algorithm to manage rare category detection with less information about priors of minority classes. In this paper, our proposed framework MUVIR
is generic in the sense that it can leverage multiple existing
RCD methods, such as GRADE, NNDM and etc., to analyze
the problem in the multi-view version. To the best of our
knowledge, this is the first effort on rare category detection
with multiple views.

posed framework for multi-view rare category detection in
Section 3. In Section 4, we test our model on both synthetic
data sets and real data sets. Finally, we conclude this paper in
Section 5.

2

Related Work

Multi-view Learning
Multi-view learning targets problems where the features naturally come from multiple information sources, or multiple
views. It has been studied extensively in the literature. Cotraining [Blum and Mitchell, 1998] is one of the earliest efforts in this area, where the authors proved that maximizing
the mutual consistency of two independent views could be
used to learn the pattern based on a few labeled and many unlabeled examples. Since then, multi-view learning has been
studied in multiple aspects during these years. A portion of
the researchers focus on the study of independent assumption for co-training, which is essential in the real world application. [Abney, 2002] refined the analysis of co-training
and gave a theoretical justification that their algorithm could
work on a more relax independence scenario rather than cotraining. [Balcan et al., 2004] proposed an independence
expansion and proved that it could guarantee the success of
co-training. Another line of work has been devoted to the
construction of multiple views and how to combine multiple views. In [Ho, 1998], they apply random sampling
algorithm called RSM, which perform bootstrapping in the
feature space to separate the views. [Chen et al., 2011]
transform the feature decomposition task into an optimization problem, which could automatically divide the feature
space into two exclusive subsets. While, in the aspect of how
to combine multiple views and learn models, we can separate
it into the problems of supervised learning, semi-supervised
learning and unsupervised learning. In the category of supervised and semi-supervised learning, [Muslea et al., 2003;
2006] designed a robust semi-supervised algorithm which
combined co-learning with active learning. CoMR [Sindhwani and Rosenberg, 2008] proposed a multi-view learning
algorithm based on a reproducing kernel Hilbert space with a
data-dependent co-regularization norm. In [Yu et al., 2011],
author proposed a co-training Bayesian graph model, which is
more reliable in handling the case of missing views. SMVC
[Günnemann et al., 2014] proposed a Bayesian framework
for modeling multiple clusterings of data by multiple mixture distributions. In the category of unsupervised learning,
[Long et al., 2008] introduced a general model for unsupervised multiple view learning and demonstrate it in various
types of unsupervised learning on various types of multiple
view data. The authors of [Song et al., 2013] developed
a kernel machine for learning in multi-view latent variable
models, which also allows mixture components to be nonparametric and to learn data in an unsupervised fashion.
Different from existing work on multi-view learning, in
this paper, we start de-novo, i.e., we do not have any labeled
examples to start with, but we are able to query the oracle for
the labels of selected examples until at least one example has
been detected from each minority class.

3

The Proposed Framework

In this section, we introduce the proposed framework MUVIR for multi-view rare category detection. Notice that similar as existing techniques designed to address this problem
for single-view data, we target the more challenging setting where the support regions of the majority and minority
classes overlap with each other, which makes MUVIR widely
applicable to a variety of real problems.

3.1

Notation

Suppose that we are given a set of unlabeled examples S =
{x1 , · · · , xn }, which come from m distinct classes, i.e. yi ∈
{1, · · · , m}. Without loss of generality, assume that yi = 1
corresponds to the majority class with prior p1 , and the remaining classes are minority classes with prior pc . Furthermore, each example xi is described by features from V views,
i.e., xi = [(x1i )T , . . . , (xVi )T ]T , where xvi ∈ Rdv , and dv is

4099

the dimensionality of the v th view. In our proposed model, we
repeatedly select examples to be labeled by an oracle, and the
goal is to discover at leaset one example from each minority
class by requesting as few labels as possible.

3.2

Proof. Notice that when the features from multiple views are
conditionally independent given the class label, we have
P (x|y = 2) =

P (xv |y = 2)

v=1

Multi-View Fusion

The rest of the proof follows by changing the inequality in
Equation 2 to equality.

In this section, for the sake of exposition, we focus on the binary case, i.e., m = 2, and the minority class corresponds to
yi = 2, although the analysis can be generalized to multiple
minority classes. As reviewed in Section 2, existing techniques for rare category detection with single-view data essentially compute the score for each example according to the
change in the local density, and select the examples with the
largest scores to be labeled by the oracle. Under mild conditions [He et al., 2008; He and Carbonell, 2007], these scores
reflect P (x, y = 2), thus are in proportion to the conditional
probability P (y = 2|x).
For data with multi-view features, running these algorithms [He et al., 2008; He and Carbonell, 2007] on each
view will generate scores in proportion to P (y = 2|xv ),
v = 1, . . . , V . Next, we establish the relationship between
these probabilities and the overall probability P (y = 2|x).

Based on the above analysis, in MUVIR, we propose to assign the score for each example as follows.
!d
QV
V
v
Y
v
v
v=1 P (x )
s(x) =
(3)
s (x )
P (x)
v=1
where sv (xv ) denotes the score obtained based on the v th
view using existing techniques such as NNDM [He and Carbonell, 2007] or GRADE [He et al., 2008]; and d ≥ 0 is a
parameter that controls the impact of the term related to the
marginal probability of the features. In particular, we would
like to discuss two special cases of Equation 3.
Case 1. If the features from multiple views are conditionally
independent given the class label, and they are marginally inQV
dependent, i.e., P (x) = v=1 P (xv ), then Corollary 1 indicates that d = 0;
Case 2. If the features from multiple views are conditionally
independent given the class label, then Corollary 1 indicates
that d = 1.
In Section 4, we study the impact of the parameter d on
the performance of MUVIR, and show that in general, d ∈
(0, 1.5] will lead to reasonable performance.
Notice that the proposed score in Equation 3 is robust to
irrelevant views in the data, i.e., the views where the examples from the majority and minority classes cannot be effectively distinguished. This is mainly due to the first part
QV
v
v
v=1 s (x ) on the right hand side of Equation 3. For example, assume that view 1 is irrelevant such that the distribution of the majority class (P (x|y = 1)) is the same as
the minority class (P (x|y = 2)). In this case, the viewspecific score s1 (x1 ), which reflects the conditional probability P (y = 2|x), would be the same for all the examples.
Therefore, when integrated with the scores from the other relevant views, view 1 will not impact the relative score of all
the examples, thus it will not degrade the performance of the
proposed framework.

Theorem 1. If the features from multiple views have weak
dependence given the class label yi = 2 [Abney, 2002], i.e.,
QV
P (x|y = 2) ≥ α v=1 P (xv |y = 2), α > 0, then
!
QV
V
v
Y
v
v=1 P (x )
P (y = 2|x) ≥ C(
P (y = 2|x )) ×
P (x)
v=1
(1)
where C = (p2 )αV −1 is a constant.
Proof.
P (y = 2)P (x|y = 2)
P (x)
QV
P (y = 2)α v=1 P (xv |y = 2)
≥
P (x)
QV P (y=2|xv )P (xv )
P (y = 2) v=1
P (y=2)
=α
P (x)
QV
P (y = 2|xv )P (xv )
= α v=1
P (x)(P (y = 2))V −1
QV
V
Y
P (xv )
α
v
= 2 V −1
P (y = 2|x ) v=1
(p )
P (x)
v=1

V
Y

P (y = 2|x) =

(2)

3.3 MUVIR Algorithm
The proposed MUVIR algorithm is described in Algorithm 1.
It takes as input the multi-view data set, the priors of all the
classes (p1 , p2 , . . . , pm ), as well as some parameters, and outputs the set of selected examples together with their labels.
MUVIR works as follows. In Step 2, we compute the viewspecific score for each example, which can be done using
any existing techniques for rare category detection. In Step
3, we estimate the view-specific density using kernel density estimation; whereas in Step 5, we estimate the overall density by pooling the features from all the views together. Finally, Steps 6 to 16 aim to select candidates according to P (y = c|x). To be specific, in Step 7, we skip

As a special case of Theorem 1, when the features from
multiple view are conditionally independent given the class
label, i.e., α = 1, we have the following corollary.
Corollary 1. If the features from multiple views are conditionally independent given the class label, then Inequality 1
becomes equality, and C = (p2 )1V −1 .

4100

class c if examples from this class have already been identified in the previous iterations. Step 10 implements the feedback loop by excluding any examples close to the labeled
ones from being selected in future iterations. Notice that
the threshold  depends on the algorithm used to obtain the
view-specific scores. For example, it is set to the smallest
k-nearest neighbor distance in NNDM [He and Carbonell,
2007], and the largest k-nearest neighbor global similarity in
GRADE [He et al., 2008]. Step 11 updates the view-specific
score for each example with enlarged neighborhood for computing the change in local density [He and Carbonell, 2007;
He et al., 2008]. In Step 13, we compute the overall score
based on Equation 3, and select the example with the maximum overall score to be labeled by the oracle in Step 14. In
Step 15, if the labeled example is from the target class in this
iteration, we proceed to the next class; otherwise, we mark
the class of this examples as labeled.

VIR, MUVIR-LI is more suitable in real world applications.
MUVIR-LI is described in Algorithm 2. It works as follows. Step 2 calculates the specific score sv for each example.
The only difference from MUVIR is that here we use upper
bound p to calculate sv , which is a less accurate measurement of changing local density than in MUVIR. The same as
MUVIR, we estimate the view specific density and the overall
density by applying kernel density estimation in Step 3 and
Step 5. The while loop from Step 6 to Step 16 is the query
processing. We calculate the overall score for each example
and select the examples with the largest overall score to be
labeled by oracle. We end the loop until all the classes has
been discovered.
Algorithm 2 MUVIR-LI Algorithm
Input:
Unlabeled data set S with features from V views, p, d, .
Output:
The set I of selected examples and the set L of their labels.
1: for v = 1 : V do
2:
Compute the view-specific score sv (xvi ) for all the examples using existing techniques for rare category detection, such as GRADE-LI [He et al., 2008];
3:
Estimate P (xvi ) using kernel density estimation;
4: end for;
5: Estimate P (xi ) using kernel density estimation;
6: while not all the classes have been discovered do
7:
for t = 2 : n do
8:
for v = 1 : V do
9:
For each xi that has been labeled by the oracle,
∀i, j = 1, . . . , n, i 6= j,, if kxvi , xvj k2 ≤ , then
sv (xvj ) = −∞;
10:
Update the view-specific score sv (xvi ) using existing techniques such as GRADE-LI [He et al.,
2008];
11:
end for;
12:
Compute the overall score for each example s(xi )
based on Equation 3;
13:
Query the label of the example with the maximum
s(xi )
14:
Mark the class that x belongs to as discovered.
15:
end for;
16: end while

Algorithm 1 MUVIR Algorithm
Input: Unlabeled data set S with features from V views,
p1 , . . . , pm , d, .
Output: The set I of selected examples and the set L of their
labels.
1: for v=1 : V do
2:
Compute the view-specific score sv (xvi ) for all the examples using existing techniques for rare category detection, such as GRADE [He et al., 2008];
3:
Estimate P (xvi ) using kernel density estimation;
4: end for
5: Estimate P (xi ) using kernel density estimation on all the
features combined;
6: for c=2 : m do
7:
If class c has been discovered, continue;
8:
for t = 2 : n do
9:
for v = 1 : V do
10:
For each xi that has been labeled by the oracle,
∀i, j = 1, . . . , n, i 6= j,, if kxvi , xvj k2 ≤ , then
sv (xvj ) = −∞;
11:
Update the view-specific score sv (xvi ) using existing techniques such as GRADE [He et al.,
2008];
12:
end for
13:
Compute the overall score for each example s(xi )
based on Equation 3;
14:
Query the label of the example with the maximum
s(xi )
15:
If the label of xi is from class c, break; otherwise,
mark the class of xi as labeled.
16:
end for
17: end for

4

Experimental Results

In this section, we will present the results of our algorithm on
both synthetic data sets and real data sets in multiple special
scenarios, such as data sets with different number of irrelevant
features, data sets with multiple classes and data sets with
very rare categories, such as class proportion of 0.02%.

3.4 MUVIR with Less Information (MUVIR-LI)
In many real applications, it may be difficult to obtain the priors of all the minority classes. Therefore, In this subsection,
we introduce MUVIR-LI, a modified version of Algorithm 1,
which replaces the requirement for the exact priors with an
upper bound p for all minority classes. Compared with MU-

4.1

Synthetic Data Sets

Binary Class Data Sets
For binary classes, we perform experiment on 3600 synthetic
data sets, and each scenario has independent 100 data sets.

4101

In Majority Class Center

300
250

450

400

# of selected examples

# of selected examples

350

Near Majority Class Center

450

Random Sampling
GRADE
d=0
d=0.5
d=1
d=1.5

400

200
150
100

350
300
250
200
150
100

50

50

0

0

1

2

0

3

Partly Separated from Majority Class

400

# of selected examples

450

350
300
250
200
150
100
50

0

# of irrelevant features

1

2

0

3

0

# of irrelevant features

1

2

3

# of irrelevant features

Figure 1: Prior of minority class is 0.5%
In Majority Class Center

150

100

50

0

0

1

2

250

# of selected examples

200

Near Majority Class Center

250

Random Sampling
GRADE
d=0
d=0.5
d=1
d=1.5

# of selected examples

# of selected examples

250

200

150

100

50

0

3

0

# of irrelevant features

1

2

200

150

100

50

0

3

Partly Separated from Majority Class

0

# of irrelevant features

1

2

3

# of irrelevant features

Figure 2: Prior of minority class is 1%
In Majority Class Center

70
60
50
40
30
20

70
60
50
40
30
20
10

0

0

1

2

# of irrelevant features

3

Partly Separated from Majority Class

90

80

10
0

100

90

# of selected examples

# of selected examples

80

Near Majority Class Center

100

Random Sampling
GRADE
d=0
d=0.5
d=1
d=1.5

90

# of selected examples

100

80
70
60
50
40
30
20
10

0

1

2

0

3

# of irrelevant features

0

1

2

3

# of irrelevant features

Figure 3: Prior of minority class is 2%
We consider the following three special conditions: (i) different number of irrelevant features, i.e. from 0 to 3 irrelevant
features; (ii) different priors for minority class, i.e. 0.5%,
1%, 2%; (iii) different levels of correlation between majority
class and minority class, ie. minority class stays in the center of majority class, minority class stays around the center of
majority class, minority class stays at the boundary of majority class. Besides, as the distribution of majority class tends
to be more scattered and the distribution of minority class is
more compact, we set each data set with 5000 examples and
σmajority : σminority = 40 : 1.
In the experiment, we compare MUVIR with GRADE [He
et al., 2008] and random sampling. Fig. 1 shows the results when the prior of minority class is 0.5%. Using random sampling, we need to label 200 examples on average to
identify the minority class. In most cases, other approaches
outperform random sampling. However, the learning model
generated by GRADE algorithm performs worse with the increasing of irrelevant features. In contrast, MUVIR is more
efficient and stable rather GRADE. The experiment with minority proportions of 1% and 2% are represented in Fig. 2
and Fig. 3. In these two experiment, MUVIR outperforms
GRADE and random sampling in each condition with any
setting of d. Comparing these three figures, we have the following observations for binary class data sets: (i) MUVIR is
more reliable especially when dealing with data sets containing irrelevant features. (ii) In the case of data sets with no
irrelevant features, the performance of MUVIR with different

values of d are roughly the same. (iii) In the case of data
sets with irrelevant features, MUVIR with d = 1 outperforms
other methods.

# of selected examples

Multi-classes Data Sets with Imprecise Prior
300
250
200

Random Sampling
GRADE
GRADE-LI
MUVIR, d=1
MUVIR-LI, d=1

150
100
50
0

0

1

2

3

# of irrelevant features

Figure 4: Multi-class data sets
For multi-class data sets, we compare the performances
among different approaches. In particular, GRADE-LI [He
et al., 2008] and MUVIR-LI are only provided with an upper
bound p on the proportion of all the minority classes. The
multi-class data sets consisting of 9000 examples correspond
to majority class, and the other 1000 examples correspond to
4 minority classes. The proportions of minority classes are
4%, 3%, 2%, 1%. Similar to previous experiments, we will
discuss the scenario data sets contain different number of irrelevant features. Each value we represented in the figure
is the median value of results from 100 same scenario data
sets. From Fig. 4, we can have the following conclusions: (i)
MUVIR outperforms all other algorithms in multi-class data

4102

Views
relevant view 1
relevant view 2
relevant view 3
relevant view 4
irrelevant view 1
irrelevant view 2

sets; (ii) GRADE only performs good when data sets have 1
or 0 irrelevant feature; (iii) MUVIR-LI is more reliable than
GRADE-LI in all scenarios. The reason that our models have
better performance is that both MUVIR and MUVIR-LI are
capable to exploit the relationship among multiple views and
extract useful information to make predictions.

Table 1: Relevant and irrelevant views in Adult Data set.
algorithms, we have preprocessed both data sets in order to
keep each feature component has mean 0 and standard deviation 1. In the following experiments, we will compare MUVIR and MUVIR-LI with the following algorithms: GRADE,
GRADE-LI and random sampling.
70

# of selected examples

# of selected examples

Parameter Analysis
From previous experiments, we found different parameter
settings may result in different outcomes. In this experiment,
we will focus on analyzing the impact from degree d and upper bound prior p. To measure the impact of these parameters,
we generate 400 data sets with minority class proportion 1%.
The number of irrelevant features varies from 0 to 3, and each
case has 100 data sets. In Fig. 5, the X axis represents different values of degree d, and Y axis represents the number of
selected examples on average. From Fig. 5, we can see that
MUVIR performs better when d ∈ (0, 1.5]. In the following
experiments, we will focus on studying the performance of
our algorithm with d in this certain area.
250
200
150

With 0 Irrelevant
With 1 Irrelevant
With 2 Irrelevant
With 3 Irrelevant

Features
Features
Features
Features

Without Irrelevant features
With Irrelevant features

60
50
40
30
20
10
0

GRADE

MUVIR, d=0

MUVIR, d=0.5

MUVIR, d=1

MUVIR, d=1.5

100

Figure 7: Adult

50
0
0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

5.5

6

Value of d

Adult data set contains 48842 instances and 14 features of
each example. It is a binary classes data sets. Considering the
original prior of minority class in data sets is around 24.93%.
To better test the performance of our model, we keep majority class the same and down sample the minority class to 500
examples. In this way, we generate 24 data sets with minority
prior of 1.3%. And we select relevant and irrelevant views
based on correlation analysis. Noticed that all the views are
fed to all the algorithms without information regarding their
relevance. The details about relevant and irrelevant views are
represented in Tab.1. Fig. 7 shows the comparison results on
real data by applying 5 different approaches. In this experiment, we have not included MUVIR-LI, it is because MUVIRLI is mainly developed for multi-class cases and Adult is a
binary class data sets. By using random sampling, the average number of selected examples is 76. With irrelevant views,
GRADE needs 69 requests, MUVIR with d = 0 needs 60 requests, MUVIR with d 6= 0 needs around 30 to 40 requests.
The results totally meet our intuition that when dealing data
sets with irrelevant views, MUVIR with d 6= 0 outperforms
MUVIR with d = 0, and MUVIR with d = 0 outperforms
GRADE. However, when dealing with data sets without irrelevant views, GRADE needs less labeling requests than MUVIR with d = 0, but more labeling requests than MUVIR with
d around 1.
Different from Adult, Statlog contains 58000 examples and
7 classes. Among 7 classes, there are 6 minority classes, with
priors varying from 0.02% to 15%. In this experiment, we
compare the following 4 methods: GRADE, GRADE-LI with
c
upper bound p = maxm
c=2 p , MUVIR with d = 1, MUVIR-LI
m
with d = 1 and p = maxc=2 pc . From Fig. 8, we can see that
MUVIR outperforms all other algorithms for finding all the
minority class. With the same upper bound prior, GRADE-

Figure 5: Learning curves with different degree d

# of selected examples

Features
education, education years, work class
age, hours per week, occupation
martial status, relationship, sex
race, native country
final weight
capital loss, capital gain

500
400

With 1 Irrelevant Features
Without Irrelevant Features
Random Sampling

300
200
100
0

2%

4%

6%

8%

10%

12%

14%

16%

Upper bound p

Figure 6: Learning curves with different prior upper bound
With the same data sets, we studied the learning curves of
labeling requests by applying MUVIR-LI with different upper
bound p. In Fig. 6, the X axis represents different values of
upper bound proportion and Y axis represents the number of
labeling requests. The red line represents the average number of labeling requests by using random sampling. When
data sets without irrelevant features, MUVIR-LI works well
even with upper bound p changing from 1% to 12%. When
data sets with irrelevant features, MUVIR-LI can still outperforms random sampling with upper bound p changing from
1% to 8.5%. However, when the upper bound exceeds a certain level, the algorithm tends to be random sampling. This
might be due to the reason that when the bound is very loose,
e.g. the exact proportion of the minority class is 1% and the
given upper bound is 10%, the performance of our proposed
algorithm may be greatly affected by the introduced noise.

4.2

Real Data Sets

In this subsection, we will demonstrate our algorithm on two
real data sets Statlog and Adult. Noted that, before we run our

4103

Percentage of Classes Discovered

LI needs 272 labeling requests while MUVIR-LI only needs
168 labeling requests to discover all the classes. If we apply random sampling, it may needs around 5000 labeling request to only identify the smallest minority class. Compared
with Adult, we have better results on Statlog. It is because
the distribution of majority class and minority classes are not
meshed together as in Adult. Thus, to identify the minority
classes in Statlog is a much easier case.

Proceedings of the eleventh annual conference on Computational learning theory, pages 92–100. ACM, 1998.
[Chen et al., 2011] Minmin Chen, Yixin Chen, and Kilian Q
Weinberger. Automatic feature decomposition for single
view co-training. In Proceedings of the 28th International
Conference on Machine Learning (ICML-11), pages 953–
960, 2011.
[Günnemann et al., 2014] Stephan Günnemann, Ines Färber,
Matthias Rüdiger, and Thomas Seidl. Smvc: semisupervised multi-view clustering in subspace projections.
In Proceedings of the 20th ACM SIGKDD international
conference on Knowledge discovery and data mining,
pages 253–262. ACM, 2014.

1
GRADE
GRADE-LI
MUVIR
MUVIR-LI

0.8

0.6

0.4

[He and Carbonell, 2007] Jingrui He and Jaime G Carbonell.
Nearest-neighbor-based active learning for rare category
detection. In Advances in neural information processing
systems, pages 633–640, 2007.

0.2

0
0

50

100

150

200

250

300

# of Selected Examples

Figure 8: Statlog

5

[He et al., 2008] Jingrui He, Yan Liu, and Richard
Lawrence. Graph-based rare category detection. In
Data Mining, 2008. ICDM’08. Eighth IEEE International
Conference on, pages 833–838. IEEE, 2008.

Conclusion

In this paper, we have proposed a multi-view based method
for rare category detection named MUVIR. Based on MUVIR,
we also provided a modified version MUVIR-LI for dealing
with real applications with less prior information. Different
from existing methods, our methods exploit the relationship
among multiple views and measure the probability belonging
to target class for all examples. Our algorithm works well
with multiple special cases: data sets with irrelevant features,
data sets with multiple minority class and various correlation
levels between minority class and majority class. The effectiveness of our proposed methods is guaranteed by theoretical
justification and extensive experiments results on both synthetic and real data sets, especially in the presence of irrelevant views.

[Ho, 1998] Tin Kam Ho. The random subspace method for
constructing decision forests. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 20(8):832–844,
1998.
[Long et al., 2008] Bo Long,
S Yu Philip,
and
Zhongfei (Mark) Zhang. A general model for multiple view unsupervised learning. In SDM, pages 822–833.
SIAM, 2008.
[Muslea et al., 2003] Ion Muslea, Steven Minton, and
Craig A Knoblock. Active learning with strong and weak
views: A case study on wrapper induction. In IJCAI, volume 3, pages 415–420, 2003.

Acknowledgment

[Muslea et al., 2006] Ion Muslea, Steven Minton, and
Craig A Knoblock. Active learning with multiple views.
Journal of Artificial Intelligence Research, pages 203–
233, 2006.

The authors gratefully acknowledge the support from the
National Science Foundation under Grant Numbers IIP1430144. Any opinions, findings, and conclusions expressed
in this material are those of the authors and do not necessarily
reflect the views of the National Science Foundation.

[Sindhwani and Rosenberg, 2008] Vikas Sindhwani and
David S Rosenberg. An rkhs for multi-view learning
and manifold co-regularization. In Proceedings of the
25th international conference on Machine learning, pages
976–983. ACM, 2008.

References
[Abney, 2002] Steven P. Abney. Bootstrapping. In Proceedings of the 40th Annual Meeting of the Association for
Computational Linguistics, July 6-12, 2002, Philadelphia,
PA, USA., pages 360–367, 2002.
[Balcan et al., 2004] Maria-Florina Balcan, Avrim Blum,
and Ke Yang. Co-training and expansion: Towards bridging theory and practice. In Advances in neural information
processing systems, pages 89–96, 2004.
[Blum and Mitchell, 1998] Avrim Blum and Tom Mitchell.
Combining labeled and unlabeled data with co-training. In

[Song et al., 2013] Le Song, Animashree Anandkumar,
Bo Dai, and Bo Xie. Nonparametric estimation of
multi-view latent variable models.
arXiv preprint
arXiv:1311.3287, 2013.
[Yu et al., 2011] Shipeng Yu, Balaji Krishnapuram, Rómer
Rosales, and R Bharat Rao. Bayesian co-training. The
Journal of Machine Learning Research, 12:2649–2680,
2011.

4104

3170

IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 15, NO. 10, OCTOBER 2006

Generalized Manifold-Ranking-Based
Image Retrieval
Jingrui He, Mingjing Li, Hong-Jiang Zhang, Hanghang Tong, and Changshui Zhang

Abstract—In this paper, we propose a general transductive
learning framework named generalized manifold-ranking-based
image retrieval (gMRBIR) for image retrieval. Comparing with
an existing transductive learning method named MRBIR [12], our
method could work well whether or not the query image is in the
database; thus, it is more applicable for real applications. Given
a query image, gMRBIR first initializes a pseudo seed vector
based on neighborhood relationship and then spread its scores
via manifold ranking to all the unlabeled images in the database.
Furthermore, in gMRBIR, we also make use of relevance feedback
and active learning to refine the retrieval result so that it converges
to the query concept as fast as possible. Systematic experiments on
a general-purpose image database consisting of 5 000 Corel images
demonstrate the superiority of gMRBIR over state-of-the-art
techniques.
Index Terms—Image retrieval, manifold ranking, outside the
database, relevance feedback.

I. INTRODUCTION
HE history of image retrieval can be traced back to the late
1970s, which aims to provide an effective and efficient tool
for managing large image databases. Up until now, with the advent and popularity of World Wide Web, the number of digital
images available for various purposes has grown tremendously,
and many researchers have put their attention to the development of an image retrieval system, which works well in general
or specific contexts [4], [14], [27], [30].
In the preliminary stage, image retrieval is based on keyword
annotation, which is a natural extension of text retrieval. In this
approach, images in the database are first annotated manually
by keywords, and then retrieved according to their annotations.
However, it suffers from several main difficulties, e.g., the large
amount of labor required to annotate the whole database, and
the inconsistency among different annotators in perceiving the
same image. Therefore, this approach cannot be applied to real
applications, especially when the size of the database is very
large.
To overcome these difficulties, an alternative scheme, content-based image retrieval (CBIR) was proposed in the early
1990s, which makes use of low-level image features instead
of keywords to represent images. Its advantage over keyword-

T

Manuscript received January 9, 2005; revised February 12, 2006. This work
was supported by National High Technology Research and Development Program of China (863 Program) under Contract 2001AA114190. The associate
editor coordinating the review of this manuscript and approving it for publication was Dr. Benoit Macq.
J. He, H. Tong, and C. Zhang are with the Automation Department, Tsinghua
University, Beijing 100084, China (e-mail: hejingrui98@mails.tsinghua.edu.cn;
walkstar98@mails.tsinghua.edu.cn; zcs@tsinghua.edu.cn).
M. Li and H.-J. Zhang are with Microsoft Research Asia, Beijing 100080,
China (e-mail: mjli@microsoft.com; hjzhang@microsoft.com).
Digital Object Identifier 10.1109/TIP.2006.877491

based image retrieval lies in the fact that low-level features can
be extracted automatically without human intervention, and that
the image’s own content is always consistent. Present low-level
features can be categorized into color [10], [13], [22], texture
[3], [9], [11], [15], [23], shape [5], [26], etc. However, despite
the great deal of research work dedicated to the exploration of
an ideal descriptor for image content, the performance of these
low-level features is far from satisfactory due to the well-known
gap between visual features and semantic concepts, i.e., images of dissimilar semantic content may share some common
low-level features, while images of similar semantic content
may be scattered in the feature space.
To narrow or bridge the gap, a great deal of research work
has been performed, which can be categorized into two major
groups: one is to search for appropriate metrics to measure perceptual similarity; and the other is to incorporate relevance feedback (RF) into the retrieval process in order to learn better representation of images as well as the query concept.
In the initial retrieval stage, given the query image, several
distance functions can be used to measure the similarity between
the query and all the images in the database. Traditional dis,
tance functions are based on Minkowski metrics, such as
,
, etc. In [20], the authors compare the performance of
different Minkowski metrics in texture image retrieval and draw
distance performs better than
a conclusion that Manhattan
, Mahalanobis, and Chebychev
distances.
Euclidean
This conclusion is consistent with the experimental results of
[10], [21], where
distance outperforms other distances on
color images. A more systematic study is presented in [25],
where the authors propose a model of image retrieval systems
and deduce a scheme for deriving the best similarity measure
in a set of similarity measures, assuming a parametric model of
the variability of feature vectors within the same class. More recently, to make up for the drawback of static feature weighting
schemes combined with Minkowski metrics, Li et al. [2] propose a perceptual distance function (DPF), which is dynamically
calculated in the subspace where the similarity between two images is maximized. Another example is the Earth Mover’s Distance (EMD) [28], which has a rigorous probabilistic interpretation and has been successfully applied to image retrieval [8].
However, these metrics are based on pairwise distance calculation and oversimplify the relationship among all the images in
the database. Therefore, their effectiveness is quite limited.
On the other hand, relevance feedback is an online learning
technique used to improve the performance of information retrieval systems. With the additional information of the user’s
rating on the relevance of the retrieved images, the system dynamically learns the user’s query concept, and gradually improves the retrieval result. Among others, a key issue in relevance feedback is the learning strategy. Traditional learning

1057-7149/$20.00 © 2006 IEEE

HE et al.: GENERALIZED MANIFOLD-RANKING-BASED IMAGE RETRIEVAL

3171

Fig. 1. Manifold ranking on a simple toy problem.

methods can be categorized into three major groups [16], [17],
[24]: query reweighting [16], [27], [29], query point movement
[17], [30], and query expansion [16], [17]. However, because
these methods do not fully utilize the information embedded in
feedback images, their performance can not reach a satisfactory
level.
More recently, statistical learning methods have been incorporated into relevance feedback, and have been extensively
demonstrated to outperform their traditional counterparts [1],
[18], [19], [24], [31]. According to whether or not unlabeled
data is utilized in the training stage, these methods can be
classified into inductive and transductive ones.
The goal of an inductive method is to create a classifier which
separates the relevant and irrelevant images and generalizes well
on unseen examples. For example, the authors of [18] first compute a large number of highly selective features, and then use
boosting to learn a classification function in this feature space;
similarly, the relevance feedback method proposed in [19] trains
a support vector machine (SVM) from labeled examples, hoping
to obtain a small generalization error by maximizing the margin
between relevant and irrelevant images. Moreover, to speed up
the convergence to the target concept, active learning methods
are also utilized to select the most informative images which
will be presented to and marked by the user. For example, the
support vector machine active learning algorithm
proposed by Tong et al. [24] selects the points near the SVM
boundary so as to maximally shrink the size of the version space.
Another active learning scheme, the maximizing expected generalization algorithm (MEGA) [1], judiciously selects samples
in each round and uses positive examples to learn the target concept, while negative examples to bound the uncertain region.
One major problem with inductive methods is the insufficiency
of labeled examples, which might bring great degradation to the
performance of the trained classifier.
Different from inductive methods, transductive methods aim
to accurately predict the relevance of unlabeled images which
are attainable during the training stage. For example, Discriminant-EM algorithm proposed by Wu et al. [31] makes use of
unlabeled data to construct a generative model, which will be
used to measure relevance between the query and database images. However, as pointed out in [31], if the components of data
distribution are mixed up, which is often the case in CBIR, the
performance of D-EM will be compromised.

In [12], we have proposed a novel transductive learning
framework named manifold-ranking-based image retrieval
(MRBIR). Different from traditional CBIR systems, in MRBIR,
relevance between the query and database images is evaluated
by exploring the relationship of all the data points in the feature
space, which addresses the limitation of present similarity
metrics based on pairwise distance. Comparing with D-EM,
which uses unlabeled data to construct a generative model,
MRBIR takes each unlabeled image as a vertex in a weighted
graph that will propagate the ranking score of labeled examples.
Furthermore, the proposed system can improve the retrieval
result by means of relevance feedback, including feedback
with only positive examples and with both positive and negative examples. More importantly, for the first time, MRBIR
integrates transductive learning and active learning in a natural
way, which results in a better performance than state-of-the-art
techniques.
One major problem with MRBIR is that it can only deal with
the problem where the query image is in the database, since
the weighted graph takes the query point as a vertex. However,
when the query image is not in the database, MRBIR cannot
spread its ranking score to the images in the database. In most
real applications, the query image is provided by the user, and it
is unlikely to be found in the database. Thus, the usefulness of
MRBIR is somewhat limited.
In this paper, we extend MRBIR to form a general framework
named generalized manifold-ranking-based image retrieval
(gMRBIR), which could work well no matter whether or not
the query image is in the database. Its basic concern is how to
effectively initialize the ranking scores of the vertices in the
original graph. Given a query image, gMRBIR performs the
following two-step procedure.
1) Initialization: Spread the ranking score of the query image
to its nearest neighbors in the database.
2) Propagation: Spread the ranking scores of the neighbors to
all the unlabeled images via manifold ranking.
If the query image is in the database, MRBIR and gMRBIR
lead to the same ranking result when
; while, if the query
image is not in the database, the first step of gMRBIR provides
seeds with various ranking scores, and the second step performs manifold ranking based on these seeds.

3172

IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 15, NO. 10, OCTOBER 2006

Taking advantage of the experimental results in [12], we incorporate the best schemes for relevance feedback and active
learning used in MRBIR into gMRBIR in order to refine the
retrieval results. Furthermore, some modifications are made to
accommodate the speciality of gMRBIR.
The organization of the paper is as follows. In Section II, we
briefly review related work. Section III presents the fundamental
idea of gMRBIR. Learning methods for improving the retrieval
result, including relevance feedback and active learning, are introduced in Section IV. In Section V, we provide experimental
results to evaluate the performance of gMRBIR. Finally, we
conclude in Section VI.
II. RELATED WORK
Different from traditional methods, which measure perceptual similarity based on pairwise distance, MRBIR makes use
of a manifold ranking algorithm to measure relevance between
the query and database images, which explores the relationship
of all the data points in the feature space [12]. Fig. 1 presents
a simple toy problem to illustrate the idea of manifold ranking.
We are given a set of points sampled from two concentric circles, and a query in the inner circle [Fig. 1(a)]. The task is to rank
all the data points according to their relevance to the query. Intuitively, the relevance of data points in the inner circle should
decrease along the circle, and so do the data points in the outer
circle; furthermore, all the points in the inner circle should have
a higher relevance than those in the outer circle, as is shown in
Fig. 1(b). However, if the points are ranked simply according to
pairwise Euclidean distance to the query, we will by no means
obtain such a result.
Given a set of points
, the first points are the queries which form the query set,
and the rest are to be ranked according to their relevance to the
denote a metric on which assigns
queries. Let
to each pair of points
and
a distance
, and
denote a ranking function which assigns each point
a ranking score
to form the vector . Finally, we define a
vector
, in which
if is a query, and
, otherwise. Furthermore, we need to set two parameters:
of nearest neighbors between which an edge
the number
should be put, and the width of the kernel for defining the
edge weight.
The procedure of the manifold ranking algorithm used in
MRBIR is presented below. An intuitive description of this algorithm is: a weighted graph is first formed which takes each
data point as a vertex; assign a positive ranking score to each
query while zero to the remaining points; all the data points
then spread their scores to the nearby points via the weighted
graph; the spread process is repeated until a global stable state
is reached, and all the points except the query will have their
own scores according to which they will be ranked. In the context of image retrieval, there is only one query in the query set.
The resultant ranking score of an unlabeled image is in proportion to the probability that it is relevant to the query, with large
ranking score indicating high probability.

Manifold Ranking Algorithm
nearest neighbors for each point;
1) Calculate the
connect two points with an edge if they are neighbors.
defined by
2) Form the affinity matrix
if there is an
edge linking and . Let
.
by
3) Symmetrically normalize
in which is the diagonal matrix with
-element
equal to the sum of the th row of .
4) Let
be a zero vector. Iterate
until convergence, where is a
.
parameter in
denote the th component of the limit of the
5) Let
. Rank each point according to its
sequence
(largest ranked first).
ranking scores
By careful analysis, we have the following theorem [6], [7]:
converges to1
The sequence
(1)
From (1), we can reach the following conclusions.
1) In the context of image retrieval, the matrix
can be calculated offline to facilitate fast
since no iteraonline calculation of the ranking score
tion steps are needed.
of all the unlabeled images are ob2) The ranking scores
tained from . Therefore, we name as the “seed vector”
hereafter.
III. GMRBIR
A. Fundamental Idea
Recall that in MRBIR, the query image should be a vertex in
the weighted graph; otherwise would be a zero vector, and all
the unlabeled images would end up with a zero ranking score.
This condition is satisfied when the query image is in the database. However, in real applications, users tend to select a query
image from outside the database. In these cases, MRBIR cannot
be readily used to perform image retrieval. A natural solution
is to form an enlarged graph which adds the query image as
a vertex into the original graph. However, one major problem
with this solution is that: each time the user provides a query
has to be calculated onimage, the enlarged matrix
line, which will inevitably slower the processing speed of image
retrieval systems.
Next, we will present our method used in gMRBIR for
dealing with the problem of query images outside the database.
The fundamental idea is how to properly initialize the ranking
scores of the vertices in the original graph. Suppose that the
affinity matrix of the enlarged graph with the query image as a
, then we have
vertex is denoted

(2)
1We have omitted a constant coefficient which will not affect the ranking
result.

HE et al.: GENERALIZED MANIFOLD-RANKING-BASED IMAGE RETRIEVAL

3173

where is an -dimensional vector. Its th component
if the th image is among the nearest neighbors of the query
in step 2) of
image, and its value is defined the same way as
the manifold ranking algorithm. We will discuss about the value
of in Section III-B. After normalization [as in step 3) of the
manifold ranking algorithm], we have

Recall that the first dimensions of
of the original graph, i.e.,
score

make up the ranking

(10)
Comparing (1) and (10), the difference is that the latter has
an additional constant coefficient (which will not affect the
ranking result), and that the seed vector is replaced by . For
the sake of discrimination, we will name as the pseudo seed
vector in contrast to the seed vector . Ideally, should be calculated according to (4). In our current implementation, to further
simplify computation, we use the following equation to obtain
this pseudo seed vector

(3)
(11)
where
is a diagonal matrix with
-element equal to the
, and is the normalized vector of ,
sum of the th row of
i.e.,

(4)
where

is the

-element of the diagonal matrix , and
. In (3), the approximation is
can be ignored compared to
.
because that
The th component
of can be seen as the similarity
between the query and database images based on low-level feanearest neighbors
tures, if the database image is within the
since
of the query. It is easily verified that
and
. Thus, we make
, then
, and the
reasonable assumptions that
.
Frobenius norm
(
-dimensional) as the seed vector of
Define
the enlarged graph. Recall that when the query image is not in
the database, the seed vector of the original graph is a zero
(
-dimensional) denote the final ranking
vector. Let
score of the enlarged graph. Then, we have (5)–(9), shown at
are functions of
the bottom of the page, where , , and
a square matrix. The approximation in (9) is because that
can be ignored compared to .

In this way, we do not need to store the matrix . The vector
together with the matrix is enough to calculate . Based on
(10), if the query image is outside the database, gMRBIR will
perform the following two-step procedure.
1) Initialization: Spread the ranking score of the query image
nearest neighbors in the database, and obtain the
to its
pseudo seed vector according to (11).
2) Propagation: Spread the ranking scores of the pseudo seed
vector to all the unlabeled images via manifold ranking.
B. Discussion
Ideally,
(which is used to obtain the affinity matrices
and in step 1) of the manifold ranking algorithm) and
(which is used to obtain the vectors and in gMRBIR)
should be the same, as they are integrated to form the enlarged
. From another point of view,
determines
affinity matrix
the number of nonzero elements in the pseudo seed vector
, which correspond to the images most similar to the query.
Since such images and the associated similarity in terms of
are determined by low-level features, their precision can
may introduce a lot of noise in the
be very low, and a large
.
initialization step. Therefore, we deliberately set
Experimental results in Section V support our supposition.
Although the two-step procedure in gMRBIR is designed to
deal with the problem in which the query image is outside the

(5)
(6)
(7)
(8)
(9)

3174

IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 15, NO. 10, OCTOBER 2006

database, it is well suited to solve the problem in which the query
image is within the database. To be specific, in such a situation,
the query image would be the nearest neighbor of itself, and the
corresponding element in the pseudo seed vector would be
sufficiently large as compared to the other elements. If we set
, obtained from (1) and (10) would be the same except
for a constant coefficient, i.e., MRBIR and gMRBIR would produce the same ranking result. From this point of view, MRBIR
can be viewed as a speciality of gMRBIR.

TABLE I
IMAGE FEATURES USED IN gMRBIR

lated from relevance feedback, (13) becomes almost the same
as (12).

IV. LEARNING METHODS IN GMRBIR
A. Relevance Feedback

B. Active Learning

As noticed by previous research work, in relevance feedback,
relevant and irrelevant images should be processed differently
due to the asymmetry between the two classes. According to
the experimental results in [12], the simplest yet most effective scheme for incorporating feedback images in MRBIR is as
follows.
and . The element of the former
1) Define two vectors
one is set to 1 if the corresponding image is the query or a
positive example; while the element of the latter one is set
if the corresponding image is a negative example.
to
All the other elements of the two vectors are set to 0.
and
denote the ranking scores obtained from
2) Let
positive and negative examples respectively.
,
, where
. The
smaller is, the less impact negative examples will have
on .
3) The final ranking score

Contrary to passive learning, active learning selects unlabeled
images for labeling according to some principle in each round of
relevance feedback, hoping to maximally improve the retrieval
result. In [12], we adopt three active learning methods based
on different principles. The first method selects the most relevant images; the second method selects the most inconsistent
, while the third one seimages which have the smallest
lects the inconsistent images which are also quite similar to the
query. In the context of image retrieval, where the goal is to
identify the user’s query concept using a limited number of labeled images, relevant images are more important than negative
ones. Based on experimental results, the first method performs
the best, which is consistent with theoretical analysis. Therefore,
this method is incorporated into gMRBIR as the active learning
method.

(12)
When the query is within the database, it can always be
marked as a relevant image in the first round of relevance
has at least one nonzero element.
feedback; thus, the vector
However, when the query image is outside the database,
may be a zero vector even after a few rounds of relevance
feedback due to the lack of relevant images. In this case,
will totally depend on irrelevant images to produce the final
ranking score, which may be unreliable. Therefore, we revise
as follows:

(13)
where is calculated through (10) based on low-level features.
controls the contribution of to , and it decreases with the
fedback by the user, i.e.,
total number of relevant images

(14)
, i.e.,
is a zero vector,
, and
is a
When
weighted combination of the ranking scores obtained from lowincreases,
level features and negative feedback images; as
becomes smaller. When sufficient relevant images are accumu-

V. EXPERIMENTAL RESULTS
We have evaluated the performance of gMRBIR using a general-purpose image database consisting of 5 000 Corel images.
The images are categorized into 50 groups, such as beach, bird,
mountain, jewelry, sunset, etc. Each of the categories contains
100 images of essentially the same content, which serve as
the groundtruth. We use each image in the whole database as
a query. The remaining 4 999 images constitute the database,
from which relevant images are to be found, i.e., the query is
outside the database. The results are averaged over the 5 000
queries, and the precision versus scope curve is used to evaluate
the performance of various methods.
Feature selection is a large open problem and might have a
great impact on the results. Besides the traditional global features [9]–[11], [13], [22], [23], recently a lot of research work
has investigated regional features to depict image content [8].
However, regional feature extraction depends on image segmentation, which is far from applicable in real applications. Therefore, in our current implementation, we only adopt global features, which are listed in Table I.2 Note that we have normalized
to eliminate the effect of
each dimension of the features to
different scales.
A. gMRBIR Without Relevance Feedback
distance
As validated by the experimental results in [12],
is more appropriate for defining edge weights in the affinity ma2We have experimented with many features and feature combinations. The
comparison results are consistent with those provided in subsequent sections.

HE et al.: GENERALIZED MANIFOLD-RANKING-BASED IMAGE RETRIEVAL

3175

Fig. 3. One feedback with 20 images.
Fig. 2. Comparison without relevance feedback.

trix
than the commonly used
fine edge weights as follows:

distance. Therefore, we de-

(15)
denotes the
distance between and .
where
Therefore, we need to specify four parameters for gMRBIR to
, , and . Among them, is
perform image retrieval: ,
set to 0.99, which is consistent with [6], [7], [12]. We resort to
and . To be specific, we
MRBIR to determine the values of
include all the 4 999 images in the database, take each image as
a query, and use MRBIR to obtain the retrieval result. We comand and select the one leading to
pare different pairs of
the highest average precision. Ideally, for each testing query, a
different pair of parameters should be selected based on the remaining 4 999 images in the database. However, in our experiments, we observe that the values do not vary a lot with different
and
for simplicity.
queries. So, we fix
As we have discussed in Section III-B, should be smaller
to achieve a relatively high precision in the initialization
than
and , ideally, the value of should be adapted
step. Like
to each query. One way for selecting proper value at runtime
nearest neighbors of the query in the database
is to find the
or
distance, sort them in ascending order of
based on
distance to the query, and set to be the number of neighbors
before the largest discrepancy is observed. In this subsection, for
the sake of simplicity, we only perform experiments with fixed
values for different queries, and compare their performance
and
distances. The comparison results are
with that using
provided in Fig. 2.
.
In our experiments, the best result is achieved at
, the nearest neighbors may
When is very small, e.g.,
not be semantically similar to the query image due to the imprecision of low-level features; thus, the performance of gMRBIR
may not be very stable. When is very big, on the other hand,
, the performance is also inferior to
, but the
e.g.,
difference is not very prominent. The reason can be explained as
follows: although the inclusion of many neighbors to initialize

the pseudo seed vector will introduce noise into the retrieval
process, their effect is not very obvious, since the edge weight
declines very fast with the increase of the distance between
the query and database images ((15)).
Comparing the performance of gMRBIR with that of
and
distances, we can see that our method achieves significant improvement over traditional methods based on pairwise
distances.
B. gMRBIR With Relevance Feedback
In this subsection, we perform experiments to test the performance of the learning methods (including relevance feedback and active learning) used in gMRBIR and compare with
SVM [19]. Users’ feedback processes are simulated as follows.
In each round of relevance feedback, a certain number of images that are most relevant to the query based on the judgment
of the current system are fedback and examined (the most relevant strategy). Images from the same (different) category as
the query are used as new positive (negative) examples. For
distance is utilized in the initial retrieval stage and the
SVM,
adopted kernel is Gaussian kernel. When both positive and negative examples are available, an SVM classifier can be trained to
predict the relevance of unlabeled images. Note that this method
will not be affected no matter whether or not the query image is
in the database. For gMRBIR, the parameter in relevance feedback is set to 0.25, which has been demonstrated to achieve the
best result in [12]. To provide a systematic evaluation, we fix
the total number of images that are labeled in relevance feedback to 20, but vary the times of feedback and the number of
images fedback each time accordingly. The combinations used
in this experiment include: one feedback with 20 images each
time, two feedbacks with ten images each time, and four feedbacks with five images each time. In all these experiments, gMRBIR outperforms SVM by a large margin. In Figs. 3–5, we
present their retrieval results after the first round of relevance
feedback when 20 images, ten images, and five images are fedback, respectively.
Comparing the three figures with Fig. 2, we can see that when
training data is not sufficient, SVM brings degradation to the
distance is utilized to measure relevance
performance when

3176

IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 15, NO. 10, OCTOBER 2006

then further spreads the scores to all the unlabeled images
via manifold ranking. Furthermore, the best learning methods
used in MRBIR are incorporated into gMRBIR with some
modifications to ensure that reasonable retrieval results can be
obtained in all cases. Experimental results on a general-purpose
image database show that, in the intial retrieval stage, gMRBIR
is much better than traditional methods based on pairwise distances; in relevance feedback, gMRBIR consistently improves
the retrieval result and outperforms SVM. Currently, we are
trying to construct multiple graphs based on different features,
and then incorporate information from these graphs to perform
retrieval, which will hopefully make better use of these features
and give even higher precision.
ACKNOWLEDGMENT
Fig. 4. One feedback with ten images.

The authors would like to thank S. Yan, X. Zheng, L. Zhang,
and X. Yi for their valuable discussions and enlightening
comments, as well as the reviewers for their comments and
suggestions.
REFERENCES

Fig. 5. One feedback with five images.

between the query and database images; while gMRBIR consistently improves the initial retrieval result no matter how many
images are fedback by the user. Take P50 (precision within the
distance, we
top 50 retrieved images) as an example. Using
get P50 at 27.5%; when 20 images are fedback by the user,
SVM improves P50 to 32.8%; when ten images are fedback by
the user, P50 using SVM becomes 22.5%; when only five images are fedback by the user, P50 is further decreased to 15.8%.
Using gMRBIR, we get initial P50 at 32.2%; when 20 images
are fedback by the user, gMRBIR improves P50 to 44.7%; when
ten images are fedback by the user, gMRBIR improves P50 to
39.4%; when only five images are fedback by the user, P50 is
still improved to 35.1%.
VI. CONCLUSION AND FUTURE WORK
In this paper, we have proposed a general transductive
learning framework named generalized manifold-ranking-based
image retrieval. If the query image is in the database, it could
produce the same ranking result as MRBIR if the number of
neighbors used to initialize the pseudo seed vector is small,
while, if the query image is outside the database, it first spreads
the ranking score of the query image to its neighbors, and

[1] B. Li, E. Chang, and C. S. Li, “Learning image query concepts via
intelligent sampling,” in Proc. IEEE Int. Conf. Multimedia & Expo,
2001, pp. 961–964.
[2] B. Li, E. Chang, and C. T. Wu, “DPF-a perceptual distance function
for image retrieval,” in Proc. IEEE Int. Conf. Image Processing, 2002,
vol. 2, pp. 597–600.
[3] B. S. Manjunath and W. Y. Ma, “Texture features for browsing and
retrieval of image data,” IEEE Trans. Pattern Anal. Mach. Intell., vol.
18, no. 8, pp. 837–842, Aug. 1996.
[4] C. Faloutsos, R. Barber, M. Flickner, J. Hafner, W. Niblack, D.
Petkovic, and W. Equitz, “Efficient and effective querying by image
content,” J. Intell. Inf. Syst., vol. 3, no. 3–4, pp. 231–262, 1994.
[5] C. Schmid and R. Mohr, “Local grayvalue invariants for image retrieval,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 19, no. 5, pp.
530–535, May 1997.
[6] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Chölkopf,
“Learning with local and global consistency,” presented at the NIPS
2003.
[7] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and B. Chölkopf,
“Ranking on data manifolds,” presented at the NIPS 2003.
[8] F. Jing, M. Li, H. J. Zhang, and B. Zhang, “An effective region-based
image retrieval framework,” presented at the 10th ACM Int. Conf. Multimedia 2002.
[9] F. Liu and R. W. Picard, “Periodicity, directionality, and randomness:
Wold features for image modeling and retrieval,” IEEE Trans. Pattern
Anal. Mach. Intell., vol. 8, no. 7, Jul. 1996.
[10] G. Pass, “Comparing images using color coherence vectors,” in Proc.
4th ACM Int. Conf. Multimedia, 1997, pp. 65–73.
[11] H. Tamura, S. Mori, and T. Yamawaki, “Textural features corresponding to visual perception,” IEEE Trans. Syst., Man, Cybern., vol.
8, no. 6, pp. 460–472, Jun. 1978.
[12] J. He, M. Li, H. J. Zhang, H. Tong, and C. Zhang, “Manifold-ranking
based image retrieval,” in Proc. 12th ACM Int. Conf. Multimedia, 2004,
pp. 9–16.
[13] J. Huang, S. R. Kumar, M. Mitra, W. J. Zhu, and R. Zabih, “Image
indexing using color correlograms,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 1997, pp. 762–768.
[14] J. R. Smith and S. F. Chang, “VisualSEEK: A fully automated contentbased query system,” in Proc. 4th ACM Int. Conf. Multimedia, 1996,
pp. 87–98.
[15] J. Z. Wang, G. Wiederhold, O. Firschein, and X. W. Sha, “Contentbased image indexing and searching using Daubechies’ wavelets,” Int.
J. Digit. Libraries, vol. 1, no. 4, pp. 311–328, 1998.
[16] K. Porkaew, M. Ortega, and S. Mehrota, “Query reformulation for content based multimedia retrieval in MARS,” in Proc. IEEE Int. Conf.
Multimedia Computing and Systems, 1999, vol. 2, pp. 747–751.

HE et al.: GENERALIZED MANIFOLD-RANKING-BASED IMAGE RETRIEVAL

[17] K. Porkaew and K. Chakrabarti, “Query refinement for multimedia
similarity retrieval in MARS,” in Proc. 7th ACM Int. Conf. Multimedia,
1999, pp. 235–238.
[18] K. Tieu and P. Viola, “Boosting image retrieval,” in Proc. IEEE Conf.
Computer Vision and Pattern Recognition, 2000, vol. 1, pp. 228–235.
[19] L. Zhang, F. Lin, and B. Zhang, “Support vector machine learning for
image retrieval,” in Proc. IEEE Int. Conf. Image Processing, 2001, vol.
2, pp. 721–724.
[20] M. Kokare, B. N. Chatterji, and P. K. Biswas, “Comparison of similarity metrics for texture image retrieval,” in IEEE Conf. Convergent
Technologies for Asia-Pacific Region, 2003, vol. 2, pp. 571–575.
[21] M. Stricker and M. Orengo, “Similarity of color images,” in Proc.
SPIE Storage and Retrieval for Image and Video Databases, 1995, pp.
381–392.
[22] M. Swain and D. Ballard, “Color indexing,” Int. J. Comput. Vis., vol.
7, no. 1, pp. 11–32, 1991.
[23] S. G. Mallat, “A theory for multiresolution signal decomposition: The
wavelet representation,” IEEE Trans. Pattern Anal. Mach. Intell., vol.
11, no. 7, pp. 674–693, Jul. 1989.
[24] S. Tong and E. Chang, “Support vector machine active learning for
image retrieval,” presented at the 9th ACM Int. Conf. Multimedia 2001.
[25] J. P. Tarel and S. Boughorbel, “On the choice of similarity measures for
image retrieval by example,” in Proc. 10th ACM Int. Conf. Multimedia,
2002, pp. 446–455.
[26] X. S. Zhou, Y. Rui, and T. Huang, “Water-Filling: A novel way for
image structural feature extraction,” in Proc. IEEE Int. Conf. Image
Processing, 1999, vol. 2, pp. 570–574.
[27] Y. Ishikawa, R. Subramanya, and C. Faloutsos, “MindReader:
Querying databases through multiple examples,” presented at the 24th
Int. Conf. Very Large Data Bases 1998.
[28] Y. Rubner, C. Tomasi, and L. Guibas, “A metric for distributions with
applications to image databases,” in Proc. IEEE Int. Conf. Computer
Vision, 1998, pp. 59–66.
[29] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra, “Relevance feedback: A power tool for interactive content-based image retrieval,” IEEE
Trans. Circuits Syst. Video Technol., vol. 8, no. 5, pp. 644–655, Sep.
1998.
[30] Y. Rui, T. Huang, and S. Mehrotra, “Content-based image retrieval
with relevance feedback in MARS,” in Proc. IEEE Int. Conf. Image
Processing, 1997, pp. 815–818.
[31] Y. Wu, Q. Tian, and T. Huang, “Discriminant-EM algorithm with application to image retrieval,” in Proc. IEEE Conf. Computer Vision and
Pattern Recognition, 2000, vol. 1, pp. 155–162.

Jingrui He received the B.S. and M.S. degrees from
the Automation Department, Tsinghua University,
China, in 2002 and 2005, respectively. She is
currently pursuing the Ph.D. degree at the School
of Computer Science, Carnegie Mellon University,
Pittsburgh, PA.
Her research interests include statistical machine
learning, information retrieval, and multimedia.

3177

Mingjing Li received the B.S. degree in Electrical
Engineering from the University of Science and
Technology of China in 1989 and the Ph.D. degree in
pattern recognition from the Institute of Automation,
Chinese Academy of Sciences, in 1995.
He joined Microsoft Research Asia, Beijing, in
July 1999. His research interests include pattern
recognition and multimedia search.

Hong–Jiang Zhang received the B.S. degree from
Zhengzhou University, China, and the Ph.D. degree from the Technical University of Denmark,
both in electrical engineering, in 1982 and 1991,
respectively.
From 1992 to1995, he was with the Institute of
Systems Science, National University of Singapore,
where he led several projects in video and image
content analysis and retrieval and computer vision.
From 1995 to 1999, he was a Research Manager at
Hewlett-Packard Labs, responsible for research and
technology transfers in the areas of multimedia management, computer vision
and intelligent image processing. In 1999, he joined Microsoft Research Asia,
Beijing, where he is currently the Managing Director of Advanced Technology
Center. He has authored three books, over 300 referred papers, eight special
issues of international journals on image and video processing, content-based
media retrieval, and computer vision, as well as over 50 patents or pending
applications. He currently serves on the editorial boards of five IEEE/ACM
journals and a dozen committees of international conferences.

Hanghang Tong received the B.S. and M.S. degrees
from the Automation Department, Tsinghua University, China, in 2002 and 2005, respectively. He
is currently pursuing the Ph.D. degree at the School
of Computer Science, Carnegie Mellon University,
Pittsburgh, PA.
His research interests include data mining and statistical machine learning.

Changshui Zhang received the B.S. degree in Mathematics from Peking University, China, in 1986, and
the Ph.D. degree from Tsinghua University, Beijing,
China, in 1992.
He is currently a professor with Tsinghua University. His interests include pattern recognition,
machine learning, computer vision, image processing, complex networks, etc.

2016 IEEE 16th International Conference on Data Mining

Bi-level Rare Temporal Pattern Detection
Dawei Zhou, Jingrui He, Yu Cao, Jae-sun Seo
Arizona State University
Tempe, AZ 85281
Email: {dzhou23, jingrui.he, ycao, jaesun.seo}@asu.edu
skewed in the sense that the minority classes (rare temporal patterns) are overwhelmed by the majority classes
(normal temporal patterns); (2) it is usually the case that
identifying the minority classes is more important than
identifying the majority classes in the temporal data; (3) the
minority classes are often non-separable from the majority
classes. For example, most of the ECG signals collected by
wearable devices are normal, generated by healthy people,
and only a small number of them are abnormal, generated
by people with certain heart diseases such as arrhythmia.
Without domain speciﬁc knowledge, it can be very difﬁcult
to distinguish between abnormal ECG signals and normal
ones. In malicious insider identiﬁcation, the daily activities
of most employees are normal, and only a small number of
employees are malicious insiders with abnormal activities.
Since these guileful insiders usually try to camouﬂage as
normal employees, these abnormal activities may be very
similar to the normal ones. Furthermore, within the abnormal
temporal sequences, there may only be a few time segments
exhibiting similar abnormal patterns, forming a rare category
of temporal patterns. For instance, the ECG signal of an
individual with arrhythmia may only show irregular heartbeats in a few time segments; the malicious insiders may
behave abnormally every now and then. Fig. 1 illustrates
such bi-level structure of the temporal data, where abnormal
sequences contain at least one abnormal time segment, and
normal sequences only contain normal time segments. In this
paper, we aim to detect abnormal sequences and abnormal
segments simultaneously, which correspond to the bi-level
rare temporal pattern detection.
To the best of our knowledge, such bi-level structure
(sequence level vs. segment level) is not exploited in existing
works on outlier detection for temporal data, which focus on
either the sequence level, or the segment level. Furthermore,
they fail to explore the similarity among the abnormal time
segments, treating them as isolated outliers. On the other
hand, existing works on rare category analysis are mainly
focused on static data, which are not readily applicable to
temporal data with rare categories of abnormal patterns.
To bridge this gap, in this paper, we study the problem
of rare temporal pattern detection by exploiting the bilevel structure in the data. Our proposed model is based on
an optimization framework that maximizes the likelihood
of observing the data on both the sequence level and the

Abstract—
Nowadays, temporal data is generated at an unprecedented
speed from a variety of applications, such as wearable devices,
sensor networks, wireless networks and etc. In contrast to such
large amount of temporal data, it is usually the case that only
a small portion of them contains information of interest. For
example, for the ECG signals collected by wearable devices,
most of them collected from healthy people are normal, and
only a small number of them collected from people with
certain heart diseases are abnormal. Furthermore, even for
the abnormal temporal sequences, the abnormal patterns may
only be present in a few time segments and are similar among
themselves, forming a rare category of temporal patterns. For
example, the ECG signal collected from an individual with a
certain heart disease may be normal in most time segments,
and abnormal in only a few time segments, exhibiting similar
patterns. What is even more challenging is that such rare
temporal patterns are often non-separable from the normal
ones. Existing works on outlier detection for temporal data
focus on detecting either the abnormal sequences as a whole, or
the abnormal time segments directly, ignoring the relationship
between abnormal sequences and abnormal time segments.
Moreover, the abnormal patterns are typically treated as
isolated outliers instead of a rare category with self-similarity.
In this paper, for the ﬁrst time, we propose a bi-level
(sequence-level/ segment-level) model for rare temporal pattern detection. It is based on an optimization framework
that fully exploits the bi-level structure in the data, i.e., the
relationship between abnormal sequences and abnormal time
segments. Furthermore, it uses sequence-speciﬁc simple hidden
Markov models to obtain segment-level labels, and leverages
the similarity among abnormal time segments to estimate
the model parameters. To solve the optimization framework,
we propose the unsupervised algorithm BIRAD, and also the
semi-supervised version BIRAD-K which learns from a single
labeled example. Experimental results on both synthetic and
real data sets demonstrate the performance of the proposed
algorithms from multiple aspects, outperforming state-of-theart techniques on both temporal outlier detection and rare
category analysis.
Keywords-rare category detection; temporal data mining;
time series; time segments;

I. I NTRODUCTION
In the era of big data, we are exposed to large amount
of temporal data, such as biomedical signals [20], ﬁnancial
transaction records [14], and network trafﬁc [21]. Besides
the large volume of data, we are also facing the following challenges: (1) the class membership is often highly
2374-8486/16 $31.00 © 2016 IEEE
DOI 10.1109/ICDM.2016.16

719

Figure 1: Illustration of the Bi-Level Structure in the Temporal Data.
segment level. Furthermore, it uses sequence-speciﬁc simple
hidden Markov models to generate segment-level labels, and
leverages the similarity among the abnormal time segments
to estimate the model parameters. To solve the optimization problem, we propose an unsupervised algorithm for
detecting rare temporal patterns named BIRAD and its semisupervised version named BIRAD-K. Both algorithms are
based on Block Coordinate Update, which repeatedly update the sequence-level labels, segment-level labels, and the
model parameters. We analyze these algorithms in terms of
convergence and time complexity, and empirically evaluate
their performance on both synthetic and real data sets.
The rest of this paper is organized as follows. After a
brief review of the related work in Section 2, we introduce
the bi-level model, the optimization framework, and the
proposed algorithms with performance analysis in Section
3. In Section 4, we present the experimental results on
both synthetic and real data sets, which demonstrate the
effectiveness and efﬁciency of the proposed framework.
Finally, we conclude this paper in Section 5.

framework named MUVIR, which exploited the relationship
between multiple views and estimated the overall probability
of each example belonging to the minority class. In [34], the
authors proposed a fast method for rare category detection
on time-evolving graphs, which incrementally updated the
detection models based on local updates. In this paper, we
further study the problem of rare category detection on
temporal data and aim to exploit the bi-level structure of
abnormal temporal sequences / time segments.
B. Outlier Detection for Temporal Data
Outlier detection, also called anomaly detection or novelty
detection, refers to the problem of ﬁnding instances that
do not conform to the expected behavior in the data. This
problem has been studied in various domains, such as
heterogenous networks [6, 21, 16], crowdsourcing [31, 35]
and spatiotemporal channels [26, 28]. Prior works mainly
focused on two categories of temporal outliers: outliers in
time series databases and outliers within the given time
series [10]. For the ﬁrst category of outliers, the previous
methods aim to identify a few time series as outliers,
such as clustering methods [22], parametric methods [5],
window-based methods [9]. For the second category of
outliers, the methods aim to ﬁnd particular elements or
subsequences on the given time series. For example, in [13],
the authors presented an autoregressive data-driven model
to identify outliers in environmental data streams; in [3],
the authors studied a more challenging problem that outlier
detection faced with a never-ending data stream. Different
from existing works on outlier detection for temporal data,
our work focuses on the more challenging case where
the abnormal temporal patterns are non-separable from the
normal ones, and we propose to leverage the relationship
between abnormal temporal sequences and abnormal time
segments for the sake of improving the detection accuracy.

II. R ELATED W ORK
In this section, we brieﬂy review the related work on rare
category analysis, outlier detection for temporal data, and
multi-instance learning.
A. Rare Category Analysis
Rare category detection is the problem of identifying
minority classes from the under-represented feature spaces,
while minimizing the number of labeling requests. Up
until now, several techniques have been developed for rare
category detection in different scenarios. [23] introduced the
problem setting of rare category detection and experimented
with different hint selection strategies to detect useful
anomalies. In [11, 12], the authors presented two active
learning schemes to detect rare categories via unsupervised
local-density-differential sampling strategy. More recently,
in [32], the authors studied the problem of rare category
detection on multi-view data and proposed a Bayesian

C. Multi-Instance Learning
Multi-instance learning is a variation of supervised learning, where examples are considered as bags consisting of

720

B. Model Formulation

multiple individual instances. [8] is the earliest literature that introduced and showed the importance of multiinstance learning. In the past decades, various techniques
were proposed targeting multi-instance learning. In [18, 30],
diverse density based frameworks are proposed for solving the multi-instance learning problem, by measuring the
intersection of the positive bags minus the union of the
negative bags. [1] presented an extended version of support
vector machine on multi-instance learning, and developed
a heuristic method to solve the mixed integer quadratic
programs. [36] is the ﬁrst study on the problem of multiinstance learning under the condition that examples are not
independent and identically distributed (i.i.d) by constructing
an undirected graph of each bag and designing a graph
kernel to classify the positive and negative examples. Similar
to multi-instance learning, in our model, the segment-level
labels collectively determine the corresponding sequencelevel label. However, here we assume that the relationship
among adjacent time segments is governed by segmentspeciﬁc simple hidden Markov models, and many existing
works on multi-instance learning can be seen as special cases
of our proposed model.

Our model lies in inference about the bi-level hidden state
process given the observations S, which involves calculating
the following posterior distribution.
P r(y (m) |x(m) ) ∝ P r(y (m) , x(m) )

(1)
= P r(x(m) )P r(y (m) |x(m) )
Thus, we propose the objective of our model as follows.
M

(2)
ln P r(y (m) , x(m) )
argmax
y (1:M ) m=1

As the data could be categorized into normal and abnormal temporal sequences, we can rewrite Eq. 2 as follows.

argmax
ln P r(y (m) , x(m) )
y (1:M )

+



Y (m) =1

ln P r(y (m) , x(m) )

(3)

Y (m) =0

By introducing sequence-level label Y (m) to the preceding
equation, we have
M

ln[P r(y (m) , x(m) |Y (m) = 1)
argmax
y (1:M ) m=1

III. B I -L EVEL M ODEL FOR R ARE
T EMPORAL PATTERN D ETECTION

× P r(Y (m) = 1)]Y

In this section, we propose a bi-level model for detecting
the rare temporal patterns. We start with notation and
problem deﬁnition. Then we present the model formulation,
followed by the optimization techniques. Finally, we introduce both the unsupervised algorithm BIRAD for detecting
the rare temporal patterns and its semi-supervised version
BIRAD-K.

(m)

× P r(Y (m) = 0)](1−Y

+ ln[P r(y (m) , x(m) |Y (m) = 0)
(m)

)

(m)

s.t. Y (m) = max yi
i

m = 1, . . . , M, i = 1, . . . , n(t)
(4)
Let L0 denote ln P r(y (m) , x(m) |Y (m) = 0), and L1
denote ln P r(y (m) , x(m) |Y (m) = 1). We can rewrite Eq. 4
as follows.

A. Notation and Problem Deﬁnition
Suppose that we are given a set of M temporal sequences S = {x(1) , . . . , x(M ) }, and, in temporal sequence
x(m) where m = 1, . . . , M , there are n(m) temporal
(m)
(m)
segments, i.e., x(m) = {x1 , . . . , xn(m) }. Let y (m) =
(m)
(m)
(m)
{y1 , . . . , yn(m) } ∈ {0, 1}1×n
denote the segment-level
labels, or hidden states of temporal segments in x(m) , and
Y (m) ∈ {0, 1} denote the sequence-level label, or hidden
state of x(m) . Without loss of generality, we assume that: (1)
(m)
(m)
yi = 1 corresponds to abnormal segments, and yi = 0
(m)
corresponds to normal segments; (2) Y
= 1 corresponds
to abnormal temporal sequences, and Y (m) = 0 corresponds
to normal sequences. As the bi-level structure illustrated
in Fig. 1, only a small portion of temporal sequences
in S correspond to abnormal sequences, in which only a
small portion of temporal segments are abnormal segments.
Therefore, the abnormal segments would be extremely rare
when considering the whole data set S. Our goal is to
identify anomalies in the sequence level as well as the
segment level. For the sake of clarity, we also introduce
(m)
(m)
the following indicator function I(y (m) ) = maxni=1 yi .

argmax

M


(1 − Y (m) )[L0 (x(m) ) + ln P r(Y (m) = 0)]

y (1:M ) m=1
+ Y (m) [L1 (x(m) )

+ ln P r(Y (m) = 1)]
(m)

s.t. Y (m) = max yi
i

m = 1, . . . , M, i = 1, . . . , n(t)
(5)
In order to model the joint probability of the segment-level
labels y (m) and the temporal data x(m) , we propose to use
simple Hidden Markov Models (HMM) [2]. In particular,
we have the following three assumptions: (1) the Markov
assumption, i.e., the next state is dependent only upon the
current state, where the state corresponds to the segment(m)
level label yi ; (2) the stationarity assumption, i.e., state
transition probabilities are independent of the actual time at
which the transitions take place; (3) the output independence
assumption, i.e., current output (observation) is statistically
independent of the previous outputs (observations). Next
we elaborate on modeling normal and abnormal temporal

721

sequences.
Modeling Normal Temporal Sequences: For the sake
of exposition, we ﬁrst model the normal temporal sequence,
i.e., Y (m) = 0. The log likelihood of any normal temporal
sequence x(m) is deﬁned by
L0 = ln P r(y (m) , x(m) |Y (m) = 0)
= ln[P r(x(m) |y (m) , Y (m) = 0) × P r(y (m) |Y (m) = 0)]
(6)
Based on the Markov assumption and output independence assumption, we have
(m)

P r(y (m) |Y (m) = 0)] = P r(y1
×

(m)
n

j=2

|Y (m) = 0)

(m) (m)
P r(yj |yj−1 , Y (m)

Modeling Abnormal Temporal Sequences: As we
mentioned before, if temporal sequence x(m) contains at
(m)
(m)
with yi
= 1, then
least one abnormal segment xi
(m)
is abnormal, i.e.,
we claim that temporal sequence x
Y (m) = 1. Similar as before, we have the following log
likelihood.
(12)
L1 = ln P r(y (m) , x(m) |Y (m) = 1)
In our model, we assume that the features from abnormal
time segments are generated from the same compact distribution across all abnormal temporal sequences. Similar to
Eq. 9, by taking advantage of the HMM assumptions and
Bayes’ Rule, we can rewrite Eq. 12 as follows.
L1 = ln[

= 0)

(m)
n

(m)

P r(xi

(m)

|yi

, Y (m) = 1)

(i=1)

(7)
By applying the stationarity assumption, we have

×

(m)

P r(x(m) |y (m) , Y (m) = 0) =

n

(m)

P r(xi

i=1

(m)

|yi

i=1

(m)

P r(xi

(m)

|yi

(m)

n

j=2

(m)

P r(yj

For any abnormal temporal sequence x , we deﬁne the corresponding Hidden Markov Model [2] λ =
(N, O, A, B, π) as follows.
1) N , the number of hidden states in the model. In this
paper, N = 2, i.e., normal and abnormal states.
2) O, the number of distinct observations. In our model,
for any temporal sequence x(m) , the number of observations is the length of x(m) .
3) A, N × N , the state transition probability distribution.
A is an N × N matrix. In this paper, we have:

(m)

|yj−1 , Y (m) = 0)]

(9)
On the other hand, we assume that any normal temporal
(m)
is drawn from an unknown Gaussian distrisegment xi
bution, although the proposed model can be generalized to
other parametric distributions:
(m) (m)
P r(xi |yi , Y (m)

= 0) ∼



(m)
N (xi , μ0 , σ0 )

A=

where mean μ0 and variance σ0 are not given. Hence,
(m)
N (xi , μ0 , σ0 ) could be interpreted as the emission prob(m)
ability of xi given hidden state 0.
Then, Eq. 9 can be rewritten as follows.
L0 =

(m)
n


i=1

+

(m)
n


j=2

(m)

ln N (xi

(m)

ln P r(yj

(m)

, μ0 , σ0 ) + ln P r(y1

|Y (m) = 0)

(m)

(10)
For any normal temporal sequences x(m) , there is no
segment-level state transition, i.e., all temporal segments are
normal. Therefore, L0 could be simpliﬁed as follows.
L0 =

i=1

(m)

ln N (xi

, μ0 , σ0 )

a00
a10

a01
a11



where aij denotes the transition probability from state
i to state j. And we have aij ∈ [0, 1] and ai0 +ai1 = 1,
i ∈ {0, 1}.
4) B, the observation emission probability distribution,
which is an N ×O matrix. We assume that normal time
segments meet distribution N (μ0 , σ0 ), while abnormal
time segments meet distribution N (μ1 , σ1 ).
5) π, the initial state probability distribution, of which
the length is N . In our model, for any temporal
(m)
sequence x(m) , we deﬁne a0 as the probability that
(m)
the initial temporal segment x1 is abnormal. Then,
we can write the initial state probability distribution
(m) (m)
of sequence x(m) as [1 − a0 , a0 ].

|yj−1 , Y (m) = 0)

(m)
n


(m)

|yj−1 , Y (m) = 1)]
(13)

, Y (m) = 0)

|Y (m) = 0) ×

(m)

P r(yj

(m)

(m)

× P r(y1

(m)
n

j=2

Plugging Eq. 7 and Eq. 8 into Eq. 6, we have
(m)
n

= 1) ×

, Y (m) = 0)

(8)

L0 = ln[

(m)
P r(y1 |Y (m)

(11)

Based on the HMM model λ = (N, O, A, B, π), Eq. 13

722

Updating State Transition Probability Distribution:
By taking the partial derivative of Eq. 15 with respect to
a11 and a01 , and letting them equal to zero, we have the
following closed form update rules.
M n(m) (m) (m) (m)
yj−1 yj
j=2 Y
m=1
(17)
a11 = M n(m)
(m) y (m)
j−1
j=2 Y
m=1

can be rewritten as follows.
(m)
n
 (m)
(m)
[yi ln N (xi , μ1 , σ1 )
L1 =
i=1

(m)

+ (1 − yi

(m)

+ (1 − y1

(m)

) ln N (xi

(m)

, μ0 , σ0 )] + [y1

) ln(1 − a0 )] +

(m)
n


j=2
(m)

(m)

+ yj−1 (1 − yj

ln a0

(m) (m)

[yj−1 yj

ln a11

(m)

(m)

) ln(1 − a11 ) + (1 − yj−1 )yj

(m)

(m)

+ (1 − yj−1 )(1 − yj

a01 =

) ln(1 − a01 )]

(14)
Overall Objective Function: Plugging Eq. 11 and Eq. 14
into the objective function in Eq. 5, we have
M


argmax
y (1:M ) , a0 , a11 ,
μ 1 , σ1 , μ 0 , σ0

(m)

+ (1 − yi

Y

(m)

(m)
n


{

m=1

i=1
(m)

) ln N (xi

(m)

[yi

(m)

ln N (xi
(m)

, μ0 , σ0 )] + [y1

(m)

) ln(1 − a0 )] +

n


, μ 1 , σ1 )

ln a0

j=2
(m)

(m)

+ yj−1 (1 − yj
+ (1 −

(m)
yj−1 )(1

ln a11

(m)

(m)

) ln(1 − a11 ) + (1 − yj−1 )yj

−

(m)
yj ) ln(1

(m)
n


+ (1 − Y (m) ){

i=1

s.t.

(m) (m)

[yj−1 yj

ln a01

− a01 )] + ln P r(Y (m) = 1)}

(m)

ln N (xi

, μ0 , σ0 ) + ln P r(Y (m) = 0)}

Updating Bi-level Labels: In this part, we give an
easy and fast update strategy for updating bi-level labels.
For updating the sequence-level labels, we ﬁrst score each
temporal sequence by comparing the log likelihood of the
sequence being labeled as abnormal vs. normal in each
iteration. Then, the sequences with higher scores would be
labeled as abnormal and the rests will be labeled as normal.
The details will be illustrated in BIRAD and BIRAD-K. For
updating the segment-level labels, there are the following
two cases. When the sequence-level label Y (m) = 0,
we can directly label each segment in y (m) as 01×n(m) .
When the sequence-level label Y (m) = 1, we apply Viterbi
algorithm [24] to iteratively update the most likely hidden
states, or segment-level labels, y (m) , which maximizes the
objective function in Eq. 15.

a0 , a11 , a01 ∈ [0, 1]
(m)

Y (m) = max yi
i

m = 1, . . . , M, i = 1, . . . , n(t)

(15)

C. Optimization
Given any ﬁnite observation sequence, it is challenging to
maximize the posterior probability by adjusting the HMM
model parameters (A, B, π). In fact, there is not a practical
method to exactly solve this problem. However, a number
of iterative procedures, such as EM based methods [15]
and gradient based methods [15], have been proposed to
obtain a local maximum of this problem. In the following
two subsections, we will introduce two simple and fast
algorithms, i.e., BIRAD and BIRAD-K, targeting the novel
setting of bi-level rare temporal pattern detection. Both
of these two algorithms are built upon Block Coordinate
Update (BCU) method [17, 27, 29], which divides all the
variables into multiple blocks and iteratively updates them.
To be speciﬁc,
Updating Initial State Probability Distribution: By
taking the partial derivative of Eq. 15 with respect to a0 ,
and letting it equal to zero, we have the following closed
form update rule.
(m)

a0

(m)

= y1

(18)

Updating Observation Emission Probability Distribution: By taking the partial derivation of Eq 15 with respect
to μ1 , σ1 , μ0 , σ0 , and letting them equal to zero, we have
the following closed form update rules.
M n(m) (m) (m)
xt
t=1 yt
m=1
(19)
μ1 = 
n(m) (m)
M
t=1 yt
m=1
M n(m) (m) (m)
|xt − μ1 |22
t=1 yt
(20)
σ1 = m=1
M n(m) (m)
y
−
1
t
t=1
m=1
M n(m)
(m) (m)
(1
− yt )xt
t=1
m=1
(21)
μ0 = 

(m)
(m)
M
n
)
t=1 (1 − yt
m=1
M n(m)
(m)
(m)
)|xt − μ0 |22
t=1 (1 − yt
(22)
σ0 = m=1
M n(m)
(m)
)−1
t=1 (1 − yt
m=1

(m)

+ (1 − y1

n(m) (m)
(m) (m)
(1 − yj−1 )yj
j=2 Y
m=1
M n(m) (m)
(m)
(1 − yj−1 )
j=2 Y
m=1

M

ln a01

D. BIRAD Algorithm
Based on the update rules introduced in the previous subsection, we ﬁrst introduce the unsupervised method — Bilevel Rare Temporal Anomaly Detection (BIRAD) algorithm.
It is given an unlabeled temporal sequence data set S and
the proportion of abnormal sequences P as inputs. It outputs
the hidden states of all temporal sequences and temporal
segments in S. The algorithm iteratively updates the HMM
parameters λ = (A, B, π) and the bi-level hidden states
until convergence, or a certain stopping criterion is satisﬁed.
The details of BIRAD are presented in Algorithm 1.

(16)

723

scores for each temporal sequence x(m) , which estimate
the probability of a sequence being abnormal rather than
normal. Step 12 updates the sequence-level/ segment-level
labels based on score(m) . Step 13 to Step 17 checks if
there is any inconsistency between y (m) and Y (m) . If any
inconsistency exists, these temporal sequences are labeled
as normal. At last, in Step 19, BIRAD returns the predicted
bi-level labels.
Next, we analyze the convergence of the proposed BIRAD
algorithm. We ﬁrst derive Lemma 1 and Lemma 2, which
show that the update rules in Algorithm 1 are upperbounded and non-decreasing. Lemma 1 and Lemma 2 lead
to Theorem 1, which shows the convergence of BIRAD.

Algorithm 1 Bi-level Rare Temporal Anomaly Detection
(BIRAD)
Input:
Temporal sequence data set x(1) , . . . , x(M )
Proportion of abnormal sequences P .
Output:
Y (1) , . . . , Y (M ) ; y (1) , . . . , y (M )
1: Initialize sequence-level and segment-level labels.
2: while stopping criterion is not satisﬁed do
3:
Update initial state probability distribution π by
Eq. 16.
4:
Update transition probability distribution A by Eq. 17
to Eq. 18.
5:
Update emission probability distribution B by Eq. 19
to Eq.22.
6:
for m =1: M do
7:
Update hidden states y (m) of x(m) by Viterbi
Algorithm.
8:
Compute L1 (x(m) ) in Eq. 14 based on updated
y (m) .
9:
Compute L0 (x(m) ) in Eq.11 based on updated
y (m) .
10:
Compute score(m) = L1 (x(m) ) + ln P −
L0 (x(m) ) − ln(1 − P )
11:
end for
12:
Label the temporal sequences with positive scores
as abnormal, i.e., Y (m) = 1, and keep the updated
prediction labels y (m) . Label the remaining temporal
sequences as normal, i.e., Y (m) = 0, and label the
segments in these sequences as normal, i.e., y (m) =
01×n(m) .
13:
for m = 1 : M do
14:
if I(y (m) ) = Y (m) then
15:
Let Y (m) = 0 and y (m) = 01×n(m) .
16:
end if
17:
end for
18: end while
19: return Y (1) , . . . , Y (M ) ; y (1) , . . . , y (M ) .

Lemma 1 (Upper-bounded). The overall objective function
in Eq. 15 is upper-bounded.
Proof Sketch: Due to properties of the parametric
distributions of normal and abnormal time segments, as well
as the transition probabilities, it is easy to see that Eq. 15 is
upper-bounded.
Lemma 2 (Non-decreasing). The objective function in
Eq. 15 is non-decreasing in general under the update rules
in Algorithm 1.
Proof: By separately taking second-order derivatives of
Eq. 15 with respect to the variables of initial probability π,
transition probability distribution A and emission probability distribution B, it is easy to see that the three Hessian
matrices we obtain are negative semi-deﬁnite. Thus, when
all but one block are ﬁxed, Eq. 15 is a concave function
with respect to the free block. In other words, the overall
objective function Eq. 15 is non-decreasing when we only
update the blocks of the initial probability, the transition
probability and the emission probability.
The same conclusion could also be reached when we
update the segment-level labels with other blocks ﬁxed,
as the Viterbi algorithm always returns the optimal labels
y (m) for any input sequence x(m) . On the sequence-level,
the BIRAD algorithm ﬁrstly scores each temporal sequence
by comparing the log likelihood of the sequence being
labeled as abnormal vs. normal. Then all the temporal
sequences with positive scores are labeled Y (m) = 1, and
the ones with negative scores are labeled Y (m) = 0. At
last, BIRAD algorithm corrects the inconsistency between
sequence-level and segment-level labels for the following
(m)
two cases: (1)Y (m) = 1 and y (m) = 01×n ; (2)
Y (m) = 0 and y (m) contains at least one segment-level
label as 1. For case 1, it is easy to see Eq. 15 increases
by ln P r(Y (m) = 0) − ln P r(Y (m) = 1) after correction of
Y (m) , where P r(Y (m) = 0)  P r(Y (m) = 1). For case 2,
the overall objective function in Eq. 15 keeps the same value
after correction of y (m) . In this way, the objective function
value with the resulting sequence-level and the associated
segment-level labels is no smaller than any alternative label

BIRAD works as follows. First, Step 1 initializes the
sequence-level/ segment-level labels. Speciﬁcally, one potential way to initialize the bi-level hidden states is to randomly
select M × P temporal sequences and label them as 1,
while the rest are labeled as 0. Then, we can initialize any
hidden states of temporal segments to be identical as the
hidden state of the corresponding temporal sequence. Next,
Step 2 to Step 18 applies the BCU optimization process.
From Step 3 to Step 5, BIRAD updates the initial probability vector π, transition probability distribution A and
emission probability distribution B based on the updated
labels y (1) , . . . , y (M ) . In Step 7 to Step 10, BIRAD updates
the segment-level hidden states of x(m) and calculates the

724

assignments. Therefore, the objective function in Eq. 15 is
non-decreasing under the update rules of Algorithm 1.

Algorithm 2 Bi-level Rare Temporal Anomaly Detection
with K Segments Selected (BIRAD-K)

Theorem 1 (Local Optimum). The proposed BIRAD algorithm converges to the local optimal.

Input:
Temporal sequence data set x(1) , . . . , x(M ) with only
(AQ)
one labeled abnormal segment xAG
Proportion of abnormal sequences P .
Output:
Y (1) , . . . , Y (M ) ; y (1) , . . . , y (M )
1: Initialize sequence-level and segment-level labels.
2: Compute K = m × P
3: while stopping criterion is not satisﬁed do
4:
Update HMM model λ = (π, A, B) as Step 3 to Step
5 in Algorithm 1.
5:
Update the segment-level hidden states and anomaly
score score(m) for each temporal sequence x(m) as
Step 6 to Step 11 in Algorithm 1.
6:
Label the temporal sequences with the top K scores
as abnormal, i.e., Y (m) = 1, and keep the updated
prediction labels y (m) . Label the remaining temporal
sequences as normal, i.e., Y (m) = 0, and label the
segments in these temporal sequences as normal, i.e.,
y (m) = 01×n(m) .
(AQ)
7:
Correct Y (AQ) or yAG , if either of them are updated
as 0.
8:
Check and ﬁx the inconsistency between sequencelevel labels and segment-level labels as Step 13 to
Step 17 in Algorithm 1.
9: end while
10: return Y (1) , . . . , Y (M ) ; y (1) , . . . , y (M ) .

Proof: According to Lemma 1 and Lemma 2, the objective function is non-decreasing and upper-bounded based
on the update rules in Algorithm 1. Therefore, the proposed
BIRAD algorithm converges to a local optimal.
We also analyze the computational complexity of the
BIRAD algorithm in the following theorem.
Theorem 2 (Time Complexity). The time complexity of
Algorithm 1 (with Viterbi algorithm) is O(LM O).
Proof: Let L be the required number of iterations for
Algorithm 1 to converge. The time complexity of Viterbi
Algorithm is O(N 2 O), where N is the number of hidden
states, and O is the length of a given temporal sequence. In
each iteration of Algorithm 1, we call Viterbi Algorithm M
times. Thus, we have the time complexity of Algorithm 1
as O(LM O).
E. BIRAD-K Algorithm
In some cases, we may be able to start with a few labeled
examples, i.e., labeled segments. To accommodate these
cases, we introduce a modiﬁed semi-supervised version of
Algorithm 1 named BIRAD-K in Algorithm 2.
To be speciﬁc, BIRAD-K is given a temporal sequence
(AQ)
data set S with only one labeled abnormal segment XAG ,
where AQ is the sequence-level index and AG is the
(AQ)
segment-level index of XAG , and prior P as input. Compared with BIRAD, BIRAD-K works better with noisy data,
e.g., data with outliers or changing points. The details of
BIRAD-K are described in Algorithm 2. Step 1 initializes
the bi-level hidden states. Step 2 calculates K, which is the
number of abnormal temporal sequences in the data set. Step
3 to Step 9 is the BCU process. Identical to BIRAD, we ﬁrst
update the initial probability vector π, transition probability distribution A and emission probability distribution B
based on the updated labels from the last iteration. Next,
we calculate the scores for identifying abnormal temporal
sequences in Step 5. Different from BIRAD in Step 6,
we label the temporal sequences with the top K scores as
abnormal and the rest as normal. Step 7 ensures Y (AQ) and
(AQ)
yAG are always labeled as 1. Step 8 checks if there is any
inconsistency between sequence-level labels and segmentlevel labels. Finally, in Step 10, BIRAD-K returns all the
consistent prediction labels upon convergence.

DPCA-T 2 [25], DPCA-Q [25], and one semi-supervised
method, i.e., Semi-DTW-D [7]. The RCD methods, i.e.,
NNDB and GRADE, require the exact proportion of abnormal time segments in the entire data set. This is the reason
why the RCD algorithms produce the same precision and
recall rate in the results shown in Fig. 2. For the two PCA
methods, the principal components are associated with 95%
of the total variance explanation. Semi-DTW-D is a semisupervised learning method for time series classiﬁcation. In
the comparison experiments, BIRAD-K and Semi-DTW-D
are given a single labeled abnormal segment as training data.
A. Data Set Description
The synthetic data set is generated from auto-regression
model with 3 different coefﬁcients C1, C2 and C3. It
contains 95 normal temporal sequences and 5 abnormal
sequences, and each temporal sequence consists of 1,000
observations. In normal sequences, all data points ﬁt the
model with coefﬁcients C1. In abnormal sequences, there are
980 normal data points that ﬁt the model with coefﬁcients
C2, and 20 abnormal data points that ﬁt the model with
coefﬁcients C3.

IV. E XPERIMENTS
In this section, we evaluate the performance of our proposed algorithms, i.e., BIRAD and BIRAD-K, on both synthetic and real data sets in comparison with four state-of-theart unsupervised methods, i.e., NNDB [11], GRADE [12],

725

(a) Synthetic Data

(d) Yahoo-web3

(b) Yahoo-web1

(e) Yahoo-web4

(c) Yahoo-web2

(f) ECG

(g) UIWA

Figure 2: Performance Evaluation on Real Data

based on precision, recall and F-score (deﬁned as F-score =
2 · Recall · Precision / (Recall + Precision)). Notice that, in
these experiments, we are able to identify all the abnormal
temporal sequences, and the following results are respect to
y (m) , m = 1, . . . , M .
First, the proposed algorithms are evaluated on the synthetic data set and 4 Yahoo-web data sets, all of which
are temporal data sets with anomalies. From Fig. 2(a) to
Fig. 2(e), we can discover the signiﬁcant advantages of
our proposed methods. The PCA methods always produce
very low recall rate, which indicates that the PCA methods
may not be suitable for capturing anomalies in the subspace
with maximized variance. For NNDB and GRADE, they are
very stable for both precision and recall rates, but perform
unsatisﬁed when facing more complex conditions, such as
changing points. In Fig. 2(d), both NNDB and GRADE
achieve very low precision and recall rates. This is because
they are built upon static methods, thus not effective in
handling the temporal variations. Compared with BIRAD
and BIRAD-K, we ﬁnd that Semi-DTW-D always achieves
good precision scores, while the recall rates are lower.
This is because Semi-DTW-D is designed for time series
classiﬁcation, which only meaures the distance between
temporal segments, but has not considered the hidden state
transition between the adjacent temporal segments. It can
be seen that our proposed methods always outperform the
other methods, especially in the sense of recall rate and Fscore rate. Comparing BIRAD and BIRAD-K, it is shown that
BIRAD-K performs slightly better than BIRAD, especially
in Fig. 2(d) and Fig. 2(e). This implies that BIRAD-K
algorithm may be more suited for applications with outliers
or changing points.
Next, two challenging real world problems are considered
for anomaly detection. In Fig. 2(f), we study the problem
of anomaly pattern detection on ECG signals. It reveals that

In our experiments, we include 4 temporal data sets
from Yahoo! Webscope program 1 . Each data set contains
around 80 temporal sequences, and each sequence contains
around 1,500 observations. The ﬁrst data set contains regular
anomaly points. The second and third data sets contain
periodic outliers. The third and fourth data sets include
anomaly points as well as changing points. To match the
scenario of our studying problem, each data set is modiﬁed
as containing 95% synthetic normal sequences and 5%
abnormal sequences.
ECG data set is a collection of 100 ECG signal records,
which is extracted from a public ECG database 2 . Each
record consists of ∼ 300 segments, where each segment
corresponds to one certain heart beat pulse. In this data
set, 10% signal records are abnormal temporal sequences.
Meanwhile, there are around 2% abnormal segments in these
abnormal sequences. Our goal is to detect noisy and unstable
heart beat pulses, which may be produced due to movements
or changes of the environment conditions.
At last, ADL data set [19] comprises information regarding the sensor logs of users’ daily activities during a 35-day interval. The data set is labeled with 10
different daily behaviors, i.e., “Leaving  , “T oileting  ,
“Showering  , “Sleeping  , “Breakf ast , “Lunch ,
“Dinner , “Snack  , “Spare − T ime , “Grooming  . In
this experiment, we consider “Snack  as the abnormal
behavior, which only comprises around 5% of data, and the
rest as the normal behaviors. In the end, we aim to identify
all the time intervals of “Snack” for each user.
B. Effectiveness Analysis
In this subsection, we evaluate the effectiveness of BIRAD
and BIRAD-K over 1 synthetic data set and 6 real data sets
1 https://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70
2 https://www.physionet.org/physiobank/database/ptbdb/

726

(a) Objective Value over Iterations

the series of synthetic data sets with increasing sequence
length, from 500 to 5,000. The results are shown in Fig. 5.
From the preceding two experiments, we have the following
observations: (1) BIRAD is slightly faster than BIRAD-K;
(2) the running time of both algorithms increases linearly in
general for both cases, i.e., increasing the sequence length
and increasing the number of temporal sequences. we run
the experiments with Matlab 2014a on a workstation with
four 3.5 GHz CPUs, 256 GB memory and 2 TB disk space.

(b) F-score over Iterations

Figure 3: Convergence Analysis

D. Parameter Analysis
In this subsection, we empirically study the parameter
sensitivity of BIRAD and BIRAD-K algorithms on the synthetic data set. Fig. 6 shows our analysis results. Notice
that the exact proportion of abnormal temporal sequences
is 5% in the data set. For BIRAD-K algorithm, we can see
the F-score increases sharply as the prior changes from 1%
to 5%. This is because BIRAD-K discovers more abnormal
sequences with the increase of input prior (P < 5%). As
the prior goes beyond 5%, the F-score of BIRAD-K slightly
diminishes but stabilizes near 0.89. The reason is that several
normal temporal sequences are included in the group of
abnormal sequences, as the input prior exceeds the exact
prior. Thus, the input prior would introduce a bias especially
when we update the transition probability distribution A
and emission probability distribution B. Different from the
previous case, the experiments show that the precision rate
reduces slightly and the recall rate is kept stable when the
input prior (P > 5%) increases. Compared with BIRAD-K,
we can see the F-score rates of BIRAD are more stable. This
implies that BIRAD is more reliable than BIRAD-K in the
cases with unprecise priors.

all the methods perform very well on this data set, however
our BIRAD and BIRAD-K algorithms still outperform the
others. In addition, in Fig. 2(g), we apply our algorithms
on wireless sensor networks data so as to detect all the
abnormal behaviors. Due to the unremovable randomness in
human’s daily behaviors, this problem is more challenging
than the previous 5 data sets. In this experiment, lack
of the ability to extract temporal information is the main
reason why GRADE and NNDB get much lower precision
than the others. Compared with BIRAD and BIRAD-K, the
PCA methods and Semi-DTW-D get a lower recall rates
because it may not be able to precisely catch the rules of
state transition, especially in the occurrence of randomness.
In general, we have the following observations about our
proposed algorithms from these 6 experiments: (1) Both
BIRAD and BIRAD-K outperform our 3 baseline algorithms
in most cases; (2) BIRAD produces comparable results as
BIRAD-K in most cases; (3) BIRAD-K performs modestly
better than BIRAD especially in the presence of outliers and
changing points.
C. Convergence and Efﬁciency Analysis

V. C ONCLUSION AND F UTURE W ORK

In this subsection, we ﬁrst examine the convergence of BIRAD algorithm on the synthetic data set. Fig. 3(a) illustrates
the non-decreasing and upper-bounded characteristics of the
objective function when applying BIRAD. In Fig. 3(b), we
present the changes of F-score among different iterations.
It is shown that the F-score monotonically increases with
objective values and then saturates, implying that the performance improves with increasing objective values.
Then, we examine the running time and parameter sensitivity of BIRAD and BIRAD-K algorithms. First, we perform
our algorithms on a series of synthetic data sets with increasing number of temporal sequences. Let the prior be 5% and
the length of each temporal sequence be 1,000, we generate
a series of synthetic data sets with increasing number of
temporal sequences, from 100 to 1,000. The results are
shown in Fig. 4. After that, we test our algorithms on a series
of data sets with increasing sequence length. Different from
the experiments in Fig. 4, we let each data set contain 100
temporal sequences and the prior be 5%, and we generate

In this paper, we introduce a novel data mining problem bi-level rare temporal pattern detection, which aims to ﬁll the
gap in the literature by conducting rare category analysis on
temporal data. Speciﬁcally, we address the challenging case
where the labels of the temporal data are highly skewed on
both the sequence-level and the segment-level. We formulate
the problem as an optimization problem, which maximizes
the likelihood of observing the data on both the sequencelevel and the segment-level. To solve the optimization problem, we propose an unsupervised algorithm BIRAD and its
semi-supervised version BIRAD-K, which iteratively update
the model parameters based on the block coordinate update
method and return the bi-level labels that are consistent on
the sequence-level and the segment-level. The comparison
experiments with state-of-the-art techniques demonstrate the
effectiveness of our proposed algorithms. In our future work,
we will extend the proposed framework to the cases when
multiple types of rare temporal patterns exist such that the
number of hidden states N > 2.

727

Figure 4: Efﬁciency Analysis on Increas- Figure 5: Efﬁciency Analysis on Increasing Number of Temporal Sequences
ing Length of Temporal Sequences

ACKNOWLEDGMENT
This work is supported by NSF research grant IIS1552654, an IBM Faculty Award, and a research grant by
Samsung Advanced Institute of Technology. The views and
conclusions are those of the authors and should not be
interpreted as representing the ofﬁcial policies of the funding
agencies or the U.S. Government.

[18]
[19]
[20]

R EFERENCES
[1] S. Andrews, I. Tsochantaridis, and T. Hofmann. Support vector
machines for multiple-instance learning. In Advances in neural
information processing systems.
[2] L. E. Baum and T. Petrie. Statistical inference for probabilistic
functions of ﬁnite state markov chains. The annals of mathematical
statistics, 1966.
[3] N. Begum and E. Keogh. Rare time series motif discovery from
unbounded streams. VLDB, 2014.
[4] M. Billinghurst and T. Starner. Wearable devices: new ways to manage
information. Computer, 1999.
[5] V. Chandola, V. Mithal, and V. Kumar. Comparative evaluation of
anomaly detection techniques for sequence data. In ICDM, 2008.
[6] L. Chen, J. Warner, P. L. Yung, D. Zhou, W. Heinzelman, I. Demirkol,
U. Muncuk, K. Chowdhury, and S. Basagni. Reach 2-mote: A rangeextending passive wake-up wireless sensor node. ACM Transactions
on Sensor Networks (TOSN), 2015.
[7] Y. Chen, B. Hu, E. Keogh, and G. E. Batista. Dtw-d: time series
semi-supervised learning from a single example. In SIGKDD, 2013.
[8] T. G. Dietterich, R. H. Lathrop, and T. Lozano-Pérez. Solving the
multiple instance problem with axis-parallel rectangles. Artiﬁcial
intelligence, 1997.
[9] F. A. González and D. Dasgupta. Anomaly detection using real-valued
negative selection. Genetic Programming and Evolvable Machines,
2003.
[10] M. Gupta, J. Gao, C. Aggarwal, and J. Han. Outlier detection for
temporal data. Synthesis Lectures on Data Mining and Knowledge
Discovery, 2014.
[11] J. He and J. G. Carbonell. Nearest-neighbor-based active learning for
rare category detection. In NIPS, 2007.
[12] J. He, Y. Liu, and R. Lawrence. Graph-based rare category detection.
In ICDM, 2008.
[13] D. J. Hill and B. S. Minsker. Anomaly detection in streaming environmental sensor data: A data-driven modeling approach. Environmental
Modelling and Software, 2010.
[14] D. L. Holloway and A. Anderson. Online payment system for
merchants, June 16 2006. US Patent App. 11/922,346.
[15] W. Khreich, E. Granger, A. Miri, and R. Sabourin. A survey of
techniques for incremental learning of hmm parameters. Information
Sciences, 2012.
[16] J. Li, X. Hu, J. Tang, and H. Liu. Unsupervised streaming feature
selection in social media. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,
pages 1041–1050, 2015.
[17] Z.-Q. Luo and P. Tseng. On the convergence of the coordinate

[21]
[22]
[23]
[24]
[25]
[26]

[27]
[28]

[29]

[30]
[31]
[32]
[33]
[34]
[35]
[36]

728

Figure 6: Parameter Analysis

descent method for convex differentiable minimization. Journal of
Optimization Theory and Applications, 1992.
O. Maron and T. Lozano-Pérez. A framework for multiple-instance
learning. Advances in neural information processing systems, 1998.
F. J. Ordónez, P. de Toledo, and A. Sanchis. Activity recognition
using hybrid generative/discriminative models on home environments
using binary sensors. Sensors, 2013.
J. J. Oresko, Z. Jin, J. Cheng, S. Huang, Y. Sun, H. Duschl, and
A. C. Cheng. A wearable smartphone-based platform for real-time
cardiovascular disease detection via electrocardiogram processing.
Information Technology in Biomedicine, IEEE Transactions on, 2010.
S. Pan, Q. Ye, S. Liu, and D. Zhou. Joint resource allocation
for wlan&wcdma integrated networks based on spectral bandwidth
mapping. Journal of Electronics (China), 2011.
X. Pan, J. Tan, S. Kavulya, R. Gandhi, and P. Narasimhan. Ganesha:
blackbox diagnosis of mapreduce systems. ACM SIGMETRICS, 2010.
D. Pelleg and A. W. Moore. Active learning for anomaly and rarecategory detection. In NIPS, 2004.
L. R. Rabiner. A tutorial on hidden markov models and selected
applications in speech recognition. Proceedings of the IEEE, 1989.
E. L. Russell, L. H. Chiang, and R. D. Braatz. Data-driven methods
for fault detection and diagnosis in chemical processes. Springer
Science & Business Media, 2012.
K. Shu, P. Luo, W. Li, P. Yin, and L. Tang. Deal or deceit:
detecting cheating in distribution channels. In Proceedings of the
23rd ACM International Conference on Conference on Information
and Knowledge Management, pages 1419–1428, 2014.
P. Tseng. Convergence of a block coordinate descent method for
nondifferentiable minimization. Journal of optimization theory and
applications, 2001.
Y. Wang, Q. Zhang, and B. Li. Efﬁcient unsupervised abnormal crowd
activity detection based on a spatiotemporal saliency detector. In 2016
IEEE Winter Conference on Applications of Computer Vision (WACV),
pages 1–9, 2016.
Y. Xu and W. Yin. A block coordinate descent method for regularized
multiconvex optimization with applications to nonnegative tensor
factorization and completion. SIAM Journal on imaging sciences,
2013.
Q. Zhang and S. A. Goldman. Em-dd: An improved multiple-instance
learning technique. In Advances in neural information processing
systems, 2001.
X. Zhang, G. Xue, R. Yu, D. Yang, and J. Tang. Truthful incentive mechanisms for crowdsourcing. In 2015 IEEE Conference on
Computer Communications (INFOCOM), pages 2830–2838, 2015.
D. Zhou, J. He, K. Candan, and H. Davulcu. MUVIR: multi-view
rare category detection. In IJCAI, 2015.
D. Zhou, J. Luo, V. M. Silenzio, Y. Zhou, J. Hu, G. Currier, and H. A.
Kautz. Tackling mental health by integrating unobtrusive multimodal
sensing. In AAAI, 2015.
D. Zhou, K. Wang, N. Cao, and J. He. Rare category detection on
time-evolving graphs. In ICDM, 2015.
Y. Zhou and J. He. Crowdsourcing via tensor augmentation and
completion. 2016.
Z.-H. Zhou, Y.-Y. Sun, and Y.-F. Li. Multi-instance learning by
treating instances as non-iid samples. In ICML, 2009.

Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence

Improving Traffic Prediction with Tweet Semantics
Jingrui He*, Wei Shen† , Phani Divakaruni‡ , Laura Wynter‡ , Rick Lawrence‡
* Computer Science Department, Stevens Institute of Technology, jingrui.he@gmail.com
† @Walmartlabs, Walmart eCommerce, wshen@walmartlabs.com
‡ BAMS, IBM Research, {ricklawr, phanid, lwynter}@us.ibm.com

Abstract

tional factors, such as scheduled events [Maze et al., 2006;
Mahmassani et al., 2009].
With the rapid growth of online social media, more and
more people are using Twitter, Facebook, etc to communicate
their mood, activities, plans, as well as to exchange news and
ideas, which creates a huge repository containing information
not accessible from conventional media. In particular, a lot of
people are using their mobile devices to access the social media web sites via web applications, hence generating a large
number of messages on the go. Many of the messages are related to the current traffic conditions, such as ’Traffic jam on
new preedy street, near Parking Plaza Saddar, cars unmoved
for last 20 mins’, ’Big road block intersection of Rondebult
and Commissioner street Boksburg’, etc. It is also common
for people to announce their travel plans in the near future,
such as ’This SUNDAY !!!! We will be playing at Di Piazzas
in Long Beach’, ’good night! getting up early tomorrow to
pack and then off to the airport for our flight @ 5PM’, etc.
Motivated by the uniqueness of the information contained
in online social media, and the close relationship between
traffic and tweets, In this paper, we answer the following
question: can we extract tweet-based semantics to help improve longer-term traffic prediction? To answer this question, we first establish the correlation between traffic measurements and tweet counts at various granularity. Then we
directly extract semantics from tweets via a sparse matrix,
and incorporate the semantics into the auto-regression model
used in traffic prediction. Finally, the sparse matrix is obtained by solving an optimization framework, whose goal is
to minimize the prediction error in the traffic measurements.
The rest of the paper is organized as follows. In Section
2, we briefly review existing work on traffic prediction and
social media aided analysis. Then we study the correlation
between traffic measurements and tweet counts in Section 3.
It leads to the optimization framework for systematically incorporating tweet semantics in traffic prediction and an iterative algorithm for solving it in Section 4. The experimental
results are presented in Section 5. Finally, we conclude the
paper in Section 6.

Road traffic prediction is a critical component in
modern smart transportation systems. It provides
the basis for traffic management agencies to generate proactive traffic operation strategies for alleviating congestion. Existing work on near-term traffic prediction (forecasting horizons in the range of
5 minutes to 1 hour) relies on the past and current
traffic conditions. However, once the forecasting
horizon is beyond 1 hour, i.e., in longer-term traffic
prediction, these techniques do not work well since
additional factors other than the past and current
traffic conditions start to play important roles.
To address this problem, in this paper, for the first
time, we examine whether it is possible to use
the rich information in online social media to improve longer-term traffic prediction. To this end,
we first analyze the correlation between traffic volume and tweet counts with various granularities.
Then we propose an optimization framework to extract traffic indicators based on tweet semantics using a transformation matrix, and incorporate them
into traffic prediction via linear regression. Experimental results using traffic and Twitter data originated from the San Francisco Bay area of California demonstrate the effectiveness of our proposed
framework.

1

Introduction

With the steadily increasing number of motor vehicles in
the United States, road traffic prediction becomes a critical
component in modern smart transportation systems. Accurate prediction of both near-term and longer-term traffic conditions can greatly help traffic management agencies generate proactive strategies to alleviate congestion. It can also
help road users better plan their trips by avoiding road segments expected to be congested soon. Existing work on road
traffic prediction largely focuses on forecasting horizons in
the range of 5 minutes to 1 hour by using past and current
traffic conditions [Al-Deek et al., 2001; Smith et al., 2002;
Kamarianakis and Prastacos, 2003; Min and Wynter, 2011].
The proposed techniques do not generalize well to forecasting horizons beyond 1 hour due to the impact of addi-

2

Related Work

In this section, we review the existing work from two perspectives, namely traffic prediction and social media aided
analysis.

1387

2.1

Traffic Prediction

specific features in addition to the bag-of-word features to
classify tweets into a predefined set of classes; etc.
Furthermore, some researchers are extracting information from tweets which might be useful in another domain.
In [Bollen et al., 2010], the authors try to answer the question: is the public mood correlated or even predictive of economic indicators? To this end, they first derive from large
scale Twitter feeds the collective mood states, and then perform the correlation analysis with the Dow Jones Industrial
Average (DJIA) over time. Finally, they show that the accuracy of DJIA predictions can be significantly improved by the
inclusion of specific public mood dimensions, such as Calm.
In [Eisenstein et al., 2010], based on the geo-tagged social
media, the authors propose a multi-level generative model
that reasons jointly about latent topics and geographical regions. Our proposed work belongs to this direction, and we
try to build the correlation between Twitter and a new domain,
namely traffic prediction. This is motivated by the presence
of a large number of tweets related to traffic conditions.

Road traffic prediction is a critical component in modern
smart transportation systems. With an accurate prediction of
traffic conditions, traffic management agencies can generate
proactive traffic operation strategies to alleviate congestion,
and road users can plan their trips accordingly ahead of time.
The modeling approaches of traffic prediction can be classified into parametric methods and non-parametric methods.
The former category relies primarily on statistical techniques,
including historical average and smoothing techniques [Smith
and Demetsky, 1997; Williams et al., 1998], auto-regressive
moving average models [Ahmed and Cook, 1979; Levin and
Tsao, 1980; Al-Deek et al., 2001; Smith et al., 2002; Kamarianakis and Prastacos, 2003; Min and Wynter, 2011], and
Kalman filter algorithms [Okutani and Stephanedes, 1984;
Guo and Williams, 2010]. The main non-parametric approaches published to date include non-parametric regression [Smith and Demetsky, 1996; Clark, 2003; Huang and
Sadek, 2009] and artificial neural networks (ANN) [Clark et
al., 1993; Vythoulkas, 1993; Yun et al., 1998; van Lint et al.,
2005; Vlahogianni et al., 2005; Khosravi et al., 2011]. These
studies rely primarily on traffic data collected from sensors
such as loop detectors, GPS devices, cell phones, etc., with
forecasting horizons in the range of 5 minutes to 1 hour. Studies on longer-term traffic prediction are rather limited, primarily because additional factors other than the past and current traffic conditions start to play important roles once the
forecasting horizon is beyond 1 hour. Only a few researchers
and private companies have attempted to analyze and utilize
the correlation between traffic data and those external factors such as weather and event schedules [Maze et al., 2006;
Mahmassani et al., 2009].
The main focus in this paper is on investigating how Twitter data can be used as an external data source for improving
near-term traffic prediction beyond the forecasting horizon of
1 hour. To the best of our knowledge, our study is the first
to leverage the rich information in social media to help with
traffic prediction.

2.2

3

Correlation Study

In this section, we study the correlation between traffic measurements and tweet counts by first introducing the data sets
used in this paper, and then presenting the correlation analysis.

3.1

Data Description

To accommodate the correlation analysis, we need two data
sets: one containing traffic measurements, and the other containing tweet information. We generate the traffic data set
by collecting measurements from 943 loop detectors covering the San Francisco Bay area between August 3, 2011 and
September 30, 2011 using the California Performance Measurement System (PeMS, 1 ). This data set contains 1,380,552
entries, each of which records an hourly traffic volume measured at one detector location. We also collected tweet data
for the same area during the same time period. The tweets
were obtained using the Twitter streaming API with a geolocation filter defining the lat/long bounding box of (-122.75,
36.934, -121.75, 38.369). To avoid spam, we filter out tweets
that contain the regular expressions of “http:” or “www.”.
For each tweet, we collect information of user account, time
stamp, content, and the geo-location. This results in a total
number of 212,145 tweets from 19,435 distinct users. Note
that due to an unexpected data center outage, Twitter data
during Sept 2 to Sept 12 were not collected.

Social Media Aided Analysis

As mentioned in the previous section, nowadays, many researchers are trying to exploit the rich information in social
media for various purposes. For example, there is a lot of interest in using social media to detect emerging news or events:
in [Petrovic et al., 2010], the authors address the problem of
detecting new events from a stream of Twitter posts using an
algorithm based on locality-sensitive hashing; in [Sankaranarayanan et al., 2009], the authors propose a news processing system called TwitterStand to capture tweets that correspond to late breaking news; in [Sakaki et al., 2010], the authors investigate the real-time interaction of events such as
earthquakes in Twitter, and propose a probabilistic spatiotemporal model for the target event that can find the center and
the trajectory of the event location, etc.
Another line of research is tweet classification for the purpose of information filtering. For example, in [Go et al.,
2011], the authors test various algorithms for classifying the
sentiment of tweets, such as SVM, Naive Bayes, etc; in [Sriram et al., 2010], the authors use a small set of domain-

3.2

Data Processing

For traffic data, let v ∈ RT denote the time series of regional
level traffic intensity, where T is the total number of time
stamps, and its tth element vt is the traffic volume (the total
number of vehicles passing each detector) averaged over all
943 detectors in time stamp t.
Due to the recurrent nature of traffic, v typically exhibits
periodic fluctuations, as can be seen in Figure 1(a). In traffic prediction, it is common practice to exclude such fluctuations in the prediction models. Therefore, we first estimate
1

1388

http://pems.dot.ca.gov

10
15
20
time stamp (hour)

0

5

−48

10
15
20
time stamp (hour)

0

−48
0

5

−48

10
15
20
time stamp (hour)

−36

−24
−12
Time lag (hour)

(c) 12 hour

(c) De-trended hourly traffic (d) De-trended hourly social
intensity
activity intensity

−36

−24
−12
Time lag (hour)

0

(b) 2 hour

Cross−correlation
−0.4 −0.2 0.0 0.2 0.4

200

10
15
20
time stamp (hour)

# of vehicles/hour
−200 −100
0
100

# of vehicles/hour
−1000 −500 0
500 1000

5

−24
−12
Time lag (hour)

(a) 1 hour

(a) Hourly traffic intensity (b) Hourly social activity intensity

0

−36

Cross−correlation
−0.4 −0.2 0.0 0.2 0.4

5

Cross−correlation
−0.4 −0.2 0.0 0.2 0.4

Cross−correlation
−0.4 −0.2 0.0 0.2 0.4

# of vehicles/hour
100 200 300 400 500
0

# of vehicles/hour
0 1000
3000
5000
0

0

−48

−36

−24
−12
Time lag (hour)

0

(d) 24 hour

Figure 2: Cross correlation between de-trended traffic intensity and de-trended social activity intensity

Figure 1: Data de-trending
the current de-trended traffic intensity δv and the de-trended
social activity intensity δc in the past 48 hours with time resolutions of 1, 2, 12, and 24 hours respectively. The height of
the green bar at time lag −∆t represents the correlation between δvt and δct−∆t . The two blue dashed lines mark the
95% confidence intervals of the correlation values.
As can be seen from this figure, the current de-trended
traffic intensity and the de-trended social activity intensity in
the past 48 hours exhibit statistically significant correlation.
Quite interestingly, the correlation seems to be negative for
all four time resolutions tested, which implies that when the
social activity is less intense than the average level, the traffic
activity on the road network is usually more intense than the
average level in the near future. In terms of correlation levels,
larger time resolutions such as 12 hours and 24 hours tend to
have higher absolute values of correlation than smaller ones
such as 1 hour and 2 hours. For the data with 12-hour resolution, the correlation for only even time lags is statistically
significant.
Furthermore, we test the significance of the correlation between the two time series by adding lagged δc to the original
auto-regression model used for traffic prediction [Smith and
Demetsky, 1997]. To be specific, we predict δv using the
following linear regression model.

the seasonal variation component and then subtract it from
v to get the de-trended version. More specifically, for each
(hour of day, day of week) pair (τ, d) where τ = 0, . . . , 23
and d = 0, . . . , 6, we define the seasonal variation component
τ,d as follows
P
t
{t|g(t)=(τ,d)} v
τ,d =
|{t|g(t) = (τ, d)}|
where g(·) is an operator retrieving both the hour of day and
day of week indices for a given time stamp t, and |{·}| denotes the number of elements in the set.
The de-trended version of regional level traffic intensity is
now defined as δv ∈ RT , where its tth element δvt is set as
follows.
δvt = vt − (τ, d), s.t. g(t) = (τ, d)
For Twitter data, let c ∈ RT denote the time series of social activity intensity measure, whose tth component ct is the
total number of tweets for time stamp t. Similar to the traffic intensity measure v, c also exhibits periodic fluctuations.
Therefore, we define the de-trended version δc in a similar
way as δv.
Figure 1 compares the time series of traffic and social media intensities before and after de-trending. Each line in the
plot corresponds to the data from one day in the studied time
period, and each time stamp corresponds to an hour. The
daily recurrent patterns in both the raw traffic and Twitter data
can be clearly observed.

3.3

δvt = α + β1 δvt−1 + β2 δvt−2 + γ1 δct−1 + γ2 δct−2 (1)
where α is the offset, β1 , β2 , γ1 , and γ2 are coefficients associated with traffic and Twitter data with various lags. We apply this model with time resolutions of 1, 2, 12, and 24 hours
respectively, and identify the covariates that are statistically
significant. The results are summarized in Table 1.
In this table, the second column shows the estimated value
of the coefficients; the third column shows the standard error;
the fourth column is the t statistics; and the last column is
the p-value. For the time resolutions of 1, 2, 12 hours, there
exists at least one lag of δc that is statistically significant.

Correlation Analysis

As a first step towards predicting traffic intensity using Twitter data, we test if social activity intensity measure has any
correlation with the traffic intensity measure in the same region. Figure 2 shows the cross-correlation results between

1389

is the total number of tweets in time stamp t, and d is the
number of stemmed words. Its element Fti,j (i = 1, . . . , nt ,
j = 1, . . . , d) in the ith row and j th column is positive if and
only if the j th word appears in the ith tweet.
Furthermore, let M ∈ R(d+1)×m denote the transformation matrix, where m is the number of traffic indicators
based on tweet semantics. Its element Mj,k (j = 1, . . . , d,
k = 1, . . . , m) in the j th row and k th column corresponds to
the weight of the j th word in the k th traffic indicator, and its elements in the last row correspond to the offsets of each traffic
indicator. For example, suppose that the first traffic indicator
only has a large weight for word today, then it mainly collects information from tweets related to the activities happening today; suppose that the second traffic indicator only has
a large weight for word airport, then it focuses on the conditions around the airport, etc. Various traffic indicators are
used to depict different aspects of traffic, e.g., according to
time, location, etc. Therefore, it is easy to understand that M
is sparse column-wise, which corresponds to each traffic indicator. However, it may not be sparse row-wise, since some
words may have positive weights in many traffic indicators,
e.g., traffic.
Finally, the matrix St ∈ Rn×m that consists of the
semantic-based traffic indicators for all the tweets in time
stamp t is obtained by St = Ft × M. Its element Sti,k in the
ith row and k th column measures the strength of the k th traffic
indicator in the ith tweet. Using the previous example, if a
tweet mentions the activities around the beach today, then the
strength of the first traffic indicator according to the semantics of this tweet is large, whereas the strength of the second
traffic indicator (which is related to the conditions around the
airport) is small.

Furthermore, the coefficients of such covariates are negative,
which is consistent with the cross-correlation results shown in
Figure 2. For the time resolution of 24 hours, the regression
model does not include any statistically significant lags of δc.
Table 1: Results of Multiple Linear Regressions
(a) 1-hour time resolution

Coefficients
α
β1
β2
γ1
γ2

Value
0.341
1.142
-0.235
-0.161
0.046

Std. Err.
1.550
0.029
0.029
0.050
0.057

t
0.220
39.674
-8.227
-3.233
0.804

p-value
0.826
0.000 ∗
0.000 ∗
0.001 ∗
0.421

(b) 2-hour time resolution

Coefficients
α
β1
β2
γ1
γ2

Value
0.529
1.073
-0.246
-0.163
0.069

Std. Err.
2.873
0.041
0.040
0.051
0.055

t
0.184
26.246
-6.097
-3.187
1.244

p-value
0.854
0.000 ∗
0.000 ∗
0.002 ∗
0.214

(c) 12-hour time resolution

Coefficients
α
β1
β2
γ1
γ2

Value
-2.398
0.258
0.538
0.036
-0.109

Std. Err.
8.557
0.086
0.086
0.042
0.041

t
-0.280
2.985
6.231
0.854
-2.633

p-value
0.780
0.004 ∗
0.000 ∗
0.396
0.010 ∗

(d) 24-hour time resolution

Coefficients
α
β1
β2
γ1
γ2

Value
-1.919
0.698
-0.035
-0.048
-0.019

Std. Err.
12.470
0.160
0.164
0.043
0.039

t
-0.154
4.363
-0.215
-1.120
-0.502

p-value
0.878
0.000 ∗
0.831
0.269
0.619

4.2

Optimization Problem

Next, we introduce the optimization problem, which finds the
optimal transformation matrix M that minimizes the traffic
prediction error. To be specific, we solve the following objective function with respect to M.

(Note: ∗ means p-value < 0.05)

M,α,βl ,γl

4

Optimization Framework for Incorporating
Tweet Semantics

(δvt − α −

t=max (r1 ,r2 )+1

−

r2
X
l=1

In the previous section, we established the correlation between de-trended traffic intensity and de-tended social activity intensity. In this section, we propose a general optimization framework, which extends our analysis beyond the social activity intensity, and extracts traffic indicators based on
tweet semantics to better predict traffic conditions.

4.1

T
X

min

γl

m
X
k=1

r1
X

βl δvt−l

l=1

2
11×nt−l St−l
:,k ) + λ

m
X

|M:,k |1

(2)

k=1

where λ is a positive parameter that balances between the
two terms, r1 is the maximum time lag associated with traffic
data, r2 is the maximum time lag associated with traffic indicators based on tweet semantics, 11×nt−l is a row vector of
th
1s, | · |1 is the l1 norm, St−1
:,k and M:,k denotes the k column
t−1
of S
and M respectively.
From Equation 2, we can see that the objective function
consists of two terms: the first term measures the prediction
error of δvt using the linear regression model with lags up to
r1 for traffic data and lags up to r2 for traffic indicators based
on tweet semantics; and the second term imposes sparsity on
each column of M.

Traffic Indicators based on Tweet Semantics

During time stamp t, we first map each tweet to the space
of stemmed words (stop words removed), which generates
a non-negative sparse vector. Putting all such vectors together, and appending an additional column of all 1s, we
nt ×(d+1)
have the sparse feature matrix Ft ∈ R+
, where nt

1390

Furthermore, regarding the number of traffic indicators
based on tweet semantics, i.e., the number of columns of M,
we have the following lemma.
Lemma. ∀m > 1, the optimal solution to Equation 2 is
equivalent to the optimal solution with m = 1.
Proof sketch. For any matrix M with m columns, we can
generate a vector m by adding all the columns of M together.
The value of the objective function in Equation 2 is the same
with M and m.
Based on the above lemma, Equation 2 can be simplified
as follows.
T
X

min

m,α,βl ,γl

(δvt − α −

t=max (r1 ,r2 )+1

−

r2
X

r1
X

3. Model 3: traffic intensity and tweet semantics (based on
the model in Equation 3) using Algorithm 1.
In the third model, we test its performance using two versions of the feature matrix Ft : one with binary values, and
the other with tf-idf values. For both versions, the number
of columns (e.g., the number of stemmed words) is 161,914,
and the number of rows depends on the time stamp.
In Equation 3, ideally, the maximum time lag r1 for traffic data and r2 for Twitter data in each of the three models
should be tuned by cross-validation. Empirical studies in
traffic prediction practice typically suggest optimal values for
r1 ranging from 2 to 6 [Kamarianakis and Prastacos, 2003;
Min and Wynter, 2011]. For r2 , the results in Table 1 suggest
that the most recent or the second most recent covariate associated with social activity tend to be statistically significant
for predicting traffic. Therefore, for the purpose of concept
demonstration, in our experiments, each model incorporates
exactly the two most recent time lags for both traffic data and
Twitter data. In other words, for the first model, δvt−1 and
δvt−2 are used to predict δvt ; for the second model, δvt−1 ,
δvt−2 , δct−1 , and δct−2 are used; for the third model, δvt−1 ,
δvt−2 , Ft−1 , Ft−2 are used.
The entire data set consisting of both traffic data and Twitter data are partitioned into two parts, with the beginning
(s − 1)/s (s = 3, 4, 5, 6, 7) as the training set and the remaining as the test set. Model estimation and prediction are
performed with various time resolutions. For the training data
set, the models are estimated through 5-fold cross-validation.
The prediction performance is evaluated by two measures,
namely Mean Absolute Percentage Error (MAPE) and Root
Mean Square Error (RMSE), which are calculated as follows

βl δvt−l

l=1

γl 11×nt−l Ft−l m)2 + λ|m|1

(3)

l=1

Equation 3 can be solved using the following iterative algorithm. It works as follows. We first initialize m to be a vector
of all zeros, which indicates that no tweet semantics are used.
Then, in each iteration, we solve for α, βl (l = 1, . . . , r1 ), γl
(l = 1, . . . , r2 ), and m in an alternating way.
Algorithm 1 Iterative Algorithm for solving Equation 3
Require: Ft , δvt (t = 1, . . . , T ), r1 , r2 , λ, niter
Ensure: α, βl (l = 1, . . . , r1 ), γl (l = 1, . . . , r2 ), m
1: Initialize m to be a vector of all zeros.
2: for n = 1 to niter do
3:
Fix m, and solve for α, βl (l = 1, . . . , r1 ), and γl (l =
1, . . . , r2 ) via linear regression.
4:
Fix α, βl (l = 1, . . . , r1 ), and γl (l = 1, . . . , r2 ),
and solve for the transformation vector using glmnet [Friedman et al., 2010].
5: end for

T
X
1
|δvt − δv̂t |
(
)
T − max (r1 , r2 ) t=r+1
vt
v
u
T
X
u
1
RMSE = t
(δvt − δv̂t )2
T − max (r1 , r2 ) t=r+1

MAPE =

Furthermore, solving the original traffic prediction model
based on auto-regression and the model in Equation 1 can be
seen as special cases of Equation 3. To see this, if we set
m to be a zero vector, we get the original traffic prediction
model without tweet information; on the other hand, if we set
m to be a zero vector except for the last element, which is set
to 1, and set r1 = r2 = 2, we get the model in Equation 1.
Therefore, the value of the objective function with the optimal
vector m is at least as good as the original traffic prediction
model and the model in Equation 1.

5

where δv̂t denotes the estimated value of δvt .
Figure 3 shows the comparison results of the three models in terms of both MAPE and RMSE for time resolution
of 12 hours. The results for other time resolutions are similar and hence omitted for brevity. From this figure, we can
see that the information in social media indeed helps improve
the performance of traffic prediction. To be specific, by including the tweet counts as the covariates, the second model
performs better than the first one, which is only using traffic information; by leveraging the traffic indicators based on
tweet semantics, the third model further improves the performance in terms of both MAPE and RMSE. Furthermore, the
difference between using binary valued and tf-idf valued feature matrices is not significant in most cases. This might be
explained by the fact that the presence of certain keywords
(instead of the frequency) is enough to characterize the traffic
condition.
For illustration purpose, we also show in Figure 4 the profile of predicted values vs. the true values for a sample partition where the last 1/7 of the data is used as the test data.

Experimental Results

In this section, we test the performance of the proposed
framework, and compare with the models based on traffic intensity only, and both traffic intensity and social activity intensity. To be specific, throughout our experiments, we apply
the following three models:
1. Model 1: traffic intensity only;
2. Model 2: traffic intensity and social activity intensity
(based on the model in Equation 1);

1391

8.00

model 1

7.00
6.02

6.00

model 2

5.87

5.83
5.07

MAPE (%)

5.00

model 3 - binary
7.00

to Berkeley in the Bay Area), Friday, giants, etc. Interestingly, the word giants is the name for San Francisco baseball
team, which indicates that sports-related activities are a key
factor in traffic prediction.

model 3 - "idf

6.81 6.78 6.78

6.23 6.12 6.12 6.16
5.59
5.18

5.18 5.18
4.78

5.00
4.52 4.51

4.00
3.00

6

2.00

In this paper, motivated by the fact that people tend to post
traffic-related content in social media, we answer the following question: can we leverage such information to improve traffic prediction. To this end, we first perform correlation analysis between traffic measurements and tweet counts,
and then propose a general optimization framework to extract
traffic indicators based on tweet semantics. Experimental results on traffic data and Twitter data collected from the San
Francisco Bay area between August 3, 2011 and September 30, 2011 demonstrate the improved performance of our
model over the existing traffic prediction model based on
auto-regression.

1.00
0.00

1/7

1/6

1/5
1/4
Frac!on of test data

1/3

(a) MAPE
250

model 1

RMSE

model 2

model 3 - binary
226

223 221 221

model 3 - "idf

209 207
204 204

200

191

185 183

181

187 183

173 173

171 172

159 157

150
100
50

Conclusion

References

0

1/7

1/6

1/5
Frac!on of test data

1/4

[Ahmed and Cook, 1979] M. S. Ahmed and A. R. Cook.
Analysis of freeway traffic time-series data by using
box-jenkins techniques. Transportation Research Board,
722:1–9, 1979.
[Al-Deek et al., 2001] H. Al-Deek, S. Ishak, and M. Wang.
A new short-term traffic prediction and incident detection system on i-4, vol. i. final research report. Technical report, Transportation Systems Institute(TSI), Department of Civil and Environmental Engineering, University
of Central Florida, 2001.
[Bollen et al., 2010] Johan Bollen, Huina Mao, and XiaoJun Zeng. Twitter mood predicts the stock market. CoRR,
abs/1010.3003, 2010.
[Clark et al., 1993] S. D. Clark, M. S. Dougherty, and H. R.
Kirby. The use of neural networks and time series models for short-term traffic forecasting: a comparative study.
Proceedings of the PTRC 21st Summer Annual Meeting,
1993.
[Clark, 2003] S. Clark. Traffic prediction using multivariate
nonparametric regression. Journal of Transportation Engineering, 129:161–168, 2003.
[Eisenstein et al., 2010] Jacob
Eisenstein,
Brendan
O’Connor, Noah A. Smith, and Eric P. Xing. A latent variable model for geographic lexical variation. In
EMNLP, pages 1277–1287, 2010.
[Friedman et al., 2010] J. H. Friedman, T. Hastie, and
R. Tibshirani. Regularization paths for generalized linear models via coordinate descent. Journal of Statistical
Software, 33(1):1–22, 2 2010.
[Go et al., 2011] Alec Go, Richa Bhayani, and Lei Huang.
Twitter sentiment classification using distant supervision.
Technical report, Stanford University, 2011.
[Guo and Williams, 2010] J. Guo and B. M. Williams. Realtime short-term traffic speed level forecasting and uncertainty quantification using layered kalman fiters. Transportation Research Record, 2175:28–37, 2010.

1/3

(b) RMSE

Figure 3: Comparison of different models
From this figure, we can see that our proposed model (model
3) tracks the fluctuation in the traffic volume better model 1
(using traffic information only) and model 2 (using both traffic information and tweet counts): in the first 3 intervals, the
predicted values using model 3 are closer to the true values
than the other two models; and in the remaining 8 intervals,
the predicted values using model 3 well approximate the true
values.
0
-100
-200

δv

-300
-400
-500
model 3 - !idf
model 1

-600
-700

1

2

3

4
5
6
7
8
Number of 12-hour intervals

model 2
true value
9

10

11

12

Figure 4: Prediction profile of different models (unit time
stamp = 12 hours)
Furthermore, by including the l1 norm in the objective
function, our proposed framework generates a sparse transformation vector m, which helps us understand the way social
media affects traffic. In other words, the non-zero elements in
m correspond to the key words in tweets that indicate traffic
conditions, such as ucberkeley, albany (which is a city close

1392

[Huang and Sadek, 2009] S. Huang and A. W. Sadek. A
novel forecasting approach inspired by human memory:
The example of short-term traffic volume forecasting.
Transportation Research Part C, 17:510–525, 2009.
[Kamarianakis and Prastacos, 2003] Y. Kamarianakis and
P. Prastacos. Forecasting traffic flow conditions in an urban network: comparison of multivariate and univariate
approaches. Transportation Research Record, 1858:74–
84, 2003.
[Khosravi et al., 2011] A. Khosravi, E. Mazloumi, S. Nahavandi, D. Creighton, and J. Van Lint. A genetic algorithmbased method for improving quality of travel time prediction intervals (in press). Transportation Research Part C,
2011.
[Levin and Tsao, 1980] M. Levin and Y.-D. Tsao. On forecasting freeway occupancies and volumes. Transportation
Research Record, 773:47–49, 1980.
[Mahmassani et al., 2009] H. S. Mahmassani, J. Dong,
J. Kim, R. B. Chen, and B. Park. Incorporating weather
impacts in traffic estimation and prediction systems. Technical Report FHWA-JPO-09-065, Northwestern University, 2009.
[Maze et al., 2006] T.H. Maze,
M. Agarwal,
and
G. Burchett. Whether weather matters to traffic demand, traffic safety, and traffic operations and flows.
Transportation Research Record, 1948:170–176, 2006.
[Min and Wynter, 2011] W. Min and L. Wynter. Real-time
road traffic prediction with spatio-temporal correlations.
Transportation Research Part C, 19:606–616, 2011.
[Okutani and Stephanedes, 1984] I. Okutani and Y. J.
Stephanedes.
Dynamic prediction of traffic volume
through kalman filtering theory. Transportation Research
Part B, 18:1–11, 1984.
[Petrovic et al., 2010] Sasa Petrovic, Miles Osborne, and
Victor Lavrenko. Streaming first story detection with application to twitter. In HLT-NAACL, pages 181–189, 2010.
[Sakaki et al., 2010] Takeshi Sakaki, Makoto Okazaki, and
Yutaka Matsuo. Earthquake shakes twitter users: real-time
event detection by social sensors. In WWW, pages 851–
860, 2010.
[Sankaranarayanan et al., 2009] Jagan Sankaranarayanan,
Hanan Samet, Benjamin E. Teitler, Michael D. Lieberman,

and Jon Sperling. Twitterstand: news in tweets. In GIS,
pages 42–51, 2009.
[Smith and Demetsky, 1996] B. L. Smith and M. J. Demetsky. Multiple-interval freeway traffic flow forecasting.
Transportation Research Record, 1554:136–141, 1996.
[Smith and Demetsky, 1997] B. L. Smith and M. J. Demetsky. Traffic flow forecasting: comparison of modelling approaches. Journal of Transportation Engineering,
123(4):261–266, 1997.
[Smith et al., 2002] B. L. Smith, B. M. Williams, and R. K.
Oswalsd. Comparison of parametric and nonparametric
models for traffic flow forecasting. Transportation Research Part C, 10:303–321, 2002.
[Sriram et al., 2010] Bharath Sriram, Dave Fuhry, Engin
Demir, Hakan Ferhatosmanoglu, and Murat Demirbas.
Short text classification in twitter to improve information
filtering. In SIGIR, pages 841–842, 2010.
[van Lint et al., 2005] J. van Lint, S. Hoogendoorn, and
H. van Zuylen. Accurate freeway travel time prediction with state-space neural networks under missing data.
Transportation Research Part C, 13:347–369, 2005.
[Vlahogianni et al., 2005] E. Vlahogianni, M. G. Karlaftis,
and J. C. Golias. Optimized and meta-optimized neural
networks for short-term traffic flow prediction: A genetic
approach. Transportation Research Part C, 13:211–234,
2005.
[Vythoulkas, 1993] P. C. Vythoulkas.
Alternative approaches to short-term traffic forecasting for use in driver
information systems. In Transportation and Traffic Theory, Proceedings of the 12th International Symposium on
Traffic Flow Theory and Transportation, Berkeley, CA,
July 1993.
[Williams et al., 1998] B. M. Williams, P.K. Durvasula, and
D. E. Brown. Urban traffic flow prediction: application
of seasonal autoregressive integrated moving average and
exponential smoothing models. Transportation Research
Record, 1644:132–144, 1998.
[Yun et al., 1998] S.-Y. Yun, S. Namkoong, J.-H. Rho, S.-W.
Shin, and J.-U. Choi. A performance evaluation of neural
network models in traffic volume forecasting. Mathematical Computer Modelling, 27:293–310, 1998.

1393

2015 IEEE 15th International Conference on Data Mining Workshops

Cross-Site Virtual Social Network Construction

∗ School

Chenhao Xie∗ , Deqing Yang∗ , Jingrui He† , Yanghua Xiao∗
of Computer Science, Shanghai Key Laboratory of Data Science, Fudan University, Shanghai, China
∗ Email: {xiechenhao,yangdeqing,shawyh}@fudan.edu.cn, Tel: (86)21-51355555
† Arizona State University, AZ, USA. Email: jingrui.he@gmail.com
introduced in [1], of which the goal is to recommend items
to users in another heterogeneous domain. In particular, in
our system, we build some bipartite graphs to represent the
relationships between users of each site and the keywords
used in their posts. Then, to bridge the gap between different
vocabularies used by different sites, we infer their semantic
relatedness through concept-based interpretation distilled
from online encyclopedias, such as Wikipedia. Finally, the
similarities between users of two different sites are computed as similarity scores via an efﬁcient graph propagation
algorithm. Such similarity scores can be used to construct
a cross-site virtual social network for the sake of forming
support groups for the diabetes patients.
Our techniques are different from: (1) existing work on
cross-domain recommendation [2] in the sense that we target
heterogeneous domains with barely overlapping feature sets
(vocabularies); and (2) transfer learning [3], [4] across
heterogeneous domains as we aim to build the connections
between users across different sites instead of learning
multiple predictive models.
To thoroughly demonstrate our techniques on constructing
cross-site virtual social network, we have implemented a
graphic tool which will be presented in the following section.
The rest of this paper is organized as follows. In Section
II, we introduce the key techniques used in our system,
followed by introducing the user interface and functionality
of our demonstration tool in Section III. And then we present
our paper’s related work in Section IV. Finally, we conclude
the paper in Section V.

Abstract—
Given the plethora of social networking sites, it can be
difﬁcult for users to browse too many sites and discover social
friends. For example, for a new diabetes patient, how can s/he
ﬁnd the users with similar symptoms on different dedicated
sites and form supporting groups with them? Since different
sites may use different vocabularies, this problem is challenging
to match users across different sites. To address it, in this
paper, we present a tool to demonstrate how to construct a
virtual social network across multiple social networking sites.
Speciﬁcally, it uses bipartite graphs to represent the relationships between users and their posts’ keywords in each site;
it bridges the gap between different vocabularies of different
sites based on their semantic relatedness through concept-based
interpretations; and it uses an efﬁcient propagation algorithm
to obtain the similarity between users from different sites,
which can be used to construct the cross-site virtual social
network.
Keywords-cross-site, virtual social network, semantic matching, graph propagation

I. I NTRODUCTION
Social networks have experienced fast growth in the last
decade, such as Twitter and Facebook. They have become
fundamental platforms on which many people maintain
their friendships and share information with others. Besides the generic ones, many dedicated social networking sites have been created to help patients with a speciﬁc type of disease, such as diabetes. Examples include
TuDiabetes (http://www.tudiabetes.org/), Diabetic Connect
(http://www.diabeticconnect.com/), Diabetes Sisters (https://
diabetessisters.org/), etc. On one hand, these dedicated social
networking sites provide diabetes patients rich opportunities
to get exposed to recent developments on this disease and
to form support groups with people suffering from similar
symptoms; on the other hand, once a new user has selected
a social networking site, s/he is likely to stick to the site,
although it could be the case that many users from another
site share a lot of commonalities with this user, thus can
provide many useful tips and suggestions.
To help diabetes patients form support groups across multiple websites, we have developed a graph-based system for
constructing cross-site virtual social network. It is based on
recommendation techniques across heterogeneous domains

II. K EY T ECHNIQUES
In this section, we introduce our graph-based recommendation system based on [1]: we start with some notations,
followed by the introduction of the global similarity and the
efﬁcient computation of the relevance vectors, and ﬁnally
discuss semantic matching for bridging the gap between
different vocabularies used by different social networking
sites.
A. Notation
In this paper, for the sake of clarity, we consider 2
different sites. Formally, for the ith domain (i=1,2), we use a
bipartite graph Gi = {Vi , Ei } to represent the relationships
between the users of one site and the keywords used in
users’ historical posts, where Vi is the set of nodes in this
graph, and Ei is a set of undirected edges. Let ni denote the
number of users in the ith site, and mi denote the number of
keywords. Therefore, Vi consists of two types of nodes: ni
user nodes, and mi keyword nodes. Let X i , ni ×mi , denote

This demo was supported by NSFC (No.61472085, 61171132,
61033010), by National Key Basic Research Program of
China under No.2015CB358800, by Basic research project of
Shanghai science and technology innovation action plan under
No.15JC1400900, and by Shanghai Science and Technology Development Funds (13dz2260200, 13511504300). Corresponding
author is Yanghua Xiao.
978-1-4673-8493-3/15 $31.00 © 2015 IEEE
DOI 10.1109/ICDMW.2015.98

1660

dimensional vector, whose ith element is 1 and all the others
are 0. Thus the global similarity vector with respect to the
ith node can be written as (I − αS)−1 v i , where I is an
(n1 + n2 + m1 + m2 ) × (n1 + n2 + m1 + m2 ) identity
matrix, and α is a positive scalar whose value is close to
1. Putting all these vectors together, we have the following
global similarity matrix K which has (n1 +n2 +m1 +m2 )×
(n1 + n2 + m1 + m2 ) dimensions,

the connectivity matrix between the two types of nodes,
whose elements are set to be the edge weights (e.g., the
TF-IDF value of the keywords to a user). Furthermore, let
G0 = {V0 , E0 } denote the bipartite matching graph, where
V0 includes all the keyword nodes from the two sites, and E0
denotes the set of edges connecting keywords from different
sites. Based on this graph, we deﬁne a connectivity matrix
X 0 , (m1 + m2 ) × (m1 + m2 ), whose elements measure the
similarity between features from different domains. Details
of learning the connectivity matrix X 0 based on semantic
matching will be discussed in Subsec. II-C.
Putting all above graphs together, we get a multi-partite
graph
 G = {V, E} as shown

in Figure 1, where V =
V1 V2 , and E = E1 E2 E0 . Then, we deﬁne an
afﬁnity matrix X for this graph. X is an (n1 + n2 + m1 +
m2 ) × (n1 + n2 + m1 + m2 ) matrix and is represented as,
⎡
⎤
0n1 ×n1 0n1 ×n2
X1
0n1 ×m2
⎢ 0n2 ×n1 0n2 ×n2 0n2 ×m1
⎥
X2
⎥
X=⎢
⎣ X T1
⎦
0m1 ×n2 0m1 ×m1
X0
T
T
0m2 ×n1
X2
X0
0m2 ×m2

K = (I − αS)−1 [v 1 , . . . , v n1 +n2 +m1 +m2 ] = (I − αS)−1
(2)
It is easy to see that K has the following block structure,

−1 

	

K1 K2
A B
=
K=
K T2 K 3
BT C
where K 1 , K 2 , and K 3 are submatrices of K,



0n1 ×n2
I − 0n1 ×n1
,
A=
0n2 ×n1
I − 0n2 ×n2



−αS 1 0n1 ×m2
B=
0n2 ×m1 −αS 2

where (·)T denotes matrix transpose and 0 is a zero matrix.
Based on this graph, our goal is to infer the similarities
between user nodes from different domains.
 site
keywords

site
users

keywords

C=

users

GX0

B. Global Similarity between Objects
In graph G, the direct links between user nodes from
different sites are absent. Thus, to establish such links,
we will measure the similarities between these users based
on a graph propagation algorithm. To be speciﬁc, we ﬁrst
normalize the afﬁnity matrix X as follows.
1

0n2 ×m1
0m1 ×m1
S T0

⎤
0n1 ×m2
⎥
S2
⎥
⎦
S0
0m2 ×m2


.

C. Semantic Matching
According to our algorithm, some relationships between
keywords should be established in order to discover the
similarity of users from the two social networking sites, i.e.,
inferring E0 in G0 . In this subsection, we introduce how to
ﬁnd the relationships between different keywords from two
sites, respectively.
As we known, an online encyclopedia contains millions
of concepts including person, location, organization, hobby
and etc. There exists an article page describing the fact
about each concept. As well, there are many hyper-links
linking to other concepts on each article page to enrich its
semantic description. According to the principle of previous
Wikipedia based methods [5], [6], two terms, i.e., two
concepts, are considered semantically related if they cooccur as hyper-links in one article page. The more such
article pages can be found, the more semantically related

1

S1

−αS 0
I

Based on K 1 , the relevance between the k th user and all
the users from the other site can be obtained from the k th row
or column of K 1 , since K 1 is a symmetric matrix. In other
words, the relevance vector can be written as si = K 1 ui ,
where ui is an n1 + n2 dimensional vector. The elements of
ui are 0 except the ith one, which is set to 1. An efﬁcient
algorithm for computing the relevance vector was introduced
in [1], which is based on an iterative power method.

G2X2

Figure 1. A multi-partite graph across two sites. Red lines and blue lines
are user-keyword edges in site1 and site2, respectively. The green lines
between red rectangles and blue rectangles are the edges between keywords
from different sites, which can be established by the semantic similarities
of keywords.

S = D − 2 XD − 2
⎡
0n1 ×n1 0n1 ×n2
⎢ 0n2 ×n1 0n2 ×n2
=⎢
⎣ S T1
0m1 ×n2
0m2 ×n1
S T2

I
−αS T0

Since we are only interested in the similarities among users
from different sites, instead of the whole matrix K, we only
compute the submatrix K 1 , (n1 + n2 ) × (n1 + n2 ), which
has the following closed form solution.
−1

K 1 = I − BC −1 B T
(3)

connectivity matrix

G1X1




and

(1)

where D is a diagonal matrix with each element equal to
the row sum of X; S 1 , S 2 , and S 0 are normalized versions
of X 1 , X 2 , and X 0 , respectively.
In order to compute the global similarities between the
ith node and all the other nodes in the composite multipartite graph, we use vi to denote an n1 + n2 + m1 + m2

1661

Figure 2. Screenshot of demonstration tool’s user interface. Center main frame displays two social networks including cross-site social links issued by our
algorithm. Left content panel is used to control the display of nodes and edges in main frame. Right panel shows semantic relatedness between keywords
of two users.

was designed not only to display the virtual social links between the users from Diabetes2 and Diabetes1 respectively,
but also to reﬂect the similarities between the users in one
website. In each diabetes website, we use the similarity of
two users’ keyword sets to represent the similarity between
these two users. Speciﬁcally, one user is represented by
a keyword vector in which each element is the TF-IDF
value of one keyword to him/her, i.e, the edge weight in
Gi (i = 1, 2). Then, we compute the cosine similarity of the
two vectors as the two users’ similarity. Such similarity can
be used as the ground to issue the social links between the
users in one site. The similarity between two users from the
two diabetes websites respectively is computed according to
the algorithm in Subsec. II-B.
Our tool’s user interface is shown in Figure 2. The main
frame is in center of the interface where the users from the
two websites are displayed as red nodes and blue nodes,
respectively. The red edges and blue edges are the social
relationships built based on user similarities in each website.
The green edges between the nodes from the two websites
respectively are the virtual social relationships established by
our algorithm. For all the three types of edges, each edge’s
thickness represents its weights, i.e., the similarity between
the two ends (users) of the edge.
In the left content panel, all scroll bars are used to control
different thresholds that adjust the display of nodes and
edges in the main frame. At ﬁrst, in each website, an edge
can be accounted and in turn, be displayed in the main frame
only when its weight is bigger than the threshold ‘Network1/2 Lower Bound’. The threshold ‘Similarity Lower
Bound’ has the same function to control the display of green
edges. For a node in each website, its degree is the number
of the accounted edges between it and other nodes in the
same site. Then, one node is displayed in the main frame
when its degree is bigger than ‘Network1/2 Degree’.

the two terms are. In our scenario, a keyword equals to a
concept if they are represented by the same term.
According to ESA’s (Explicit Semantic Analysis) basic
idea [5], the semantic interpretation of a keyword i can be
represented by a concept vector which is formally deﬁned
as Ci = [c1 , ..., cC ] ∈ RC . C is the total number of concepts
in the encyclopedia and cj (1 ≤ j ≤ C) represents the
semantic relevance of concept j to keyword i, i.e., the TFIDF score of concept i (represented by keyword i) in concept
j’s article. Thus, the semantic similarity between keyword
a and keyword b can be represented as the cosine similarity
of Ca and Cb , namely cos(Ca , Cb ). To establish the links
between keywords from the two sites, i.e., E0 in the bipartite
graph G0 , we can set a threshold λ. Then, the edge between
a and b is created if cos(Ca , Cb ) ≥ λ. As well, cos(Ca , Cb )
is set as the element value of connectivity matrix X 0 (refer
to Figure 1). Accordingly, λ decides the density of X 0 . At
last, we can compute si through the algorithm introduced in
Subsec. II-B when X 0 is inferred.
III. U SER I NTERFACE AND FUNCTIONALITY
In this section, we demonstrate the user interface and
functionality of our graphic tool which can be accessed
through http://218.193.131.244:8000. The tool was coded
in JavaScript and can be viewed in Google Chrome and
Firefox explorer. Currently, our tool is illustrated by using
the datasets of two diabetes social network websites, i.e.,
http://www.tudiabetes.org (denoted by Diabetes1) and https:
//diabetessisters.org (denoted by Diabetes2). The former site
is dedicated to diabetes patients of Type I, Type II, and prediabetes, and the latter focuses on female diabetes patients,
especially those with gestational diabetes.
Our goal is to establish virtual social links between the
users from Diabetes1 and Diabetes2, respectively. Our tool
1662

relations between documents and images are captured by
their co-occur tags. These methods are not suitable to be
applied in our setting, where we aim to build the connections between heterogeneous users (with different keywords)
across different websites instead of learning multiple models.

The right panel displays the details about the semantic
relatedness between two keyword sets, which are used to
infer the similarity between two users from the two websites,
respectively. For example, when we click the green edge
between A0 and B0, the right panel will show A0’s keywords
as left column and B0’s keywords as right column. All
keywords are positioned according to their similarities (TFIDF value) to the user. And the grey lines between the two
columns demonstrate the semantic relatedness between the
keywords belonging to A0 and B0 respectively, which are
computed based the algorithm in Subsec. II-C. Moreover,
the thickness of each line can indicate semantic relatedness
value between the two keywords.

V. C ONCLUSIONS
In this paper, we demonstrate a graphic tool which was
designed to construct virtual social relationships across
different social networking sites. To this end, we not only
propose an algorithm to discover the semantic relatedness
between different vocabularies, but also design an efﬁcient
propagation algorithm to capture the similarities between
users from different sites. Our tool can clearly display the
connections between different entities (users and keywords)
among the networks.

IV. R ELATED W ORK
In this section, we survey the research works related to
the techniques built in our demonstration tool.

R EFERENCES
[1] D. Yang, J. He, H. Qin, Y. Xiao, and W. Wang, “A graphbased recommendation across heterogeneous domains,” in
Proc. of CIKM, 2015.
[2] B. Li, Q. Yang, and X. Xue, “Can movies and books
collaborate? cross-domain collaborative ﬁltering for sparsity
reduction,” in Proc. of IJCAI, 2009.
[3] Z. Lu, E. Zhong, L. Zhao, E. Xiang, W. Pan, and Q. Yang,
“Selective transfer learning for cross domain recommendation,” in Proc. of SDM, 2013.
[4] B. Cao, N. N. Liu, and Q. Yang, “Transfer learning for
collective link prediction in multiple heterogenous domains,”
in Proc. of ICML, 2010.
[5] E. Gabrilovich and S. Markovitch, “Computing semantic
relatedness using wikipedia-based explicit semantic analysis,”
in Proc. of IJCAI, 2007.
[6] D. Milne and I. H. Witten, “An effective, low-cost measure of
semantic relatedness obtained from wikipedia links,” in Proc.
of AAAI, 2008.
[7] I. Fernandez-Tobias, I. Cantador, M. Kaminskas, and F. Ricci,
“Cross-domain recommender systems: A survey of the state
of the art,” 2011.
[8] W. C. Wynne, H. Mong, and L. Lee, “Making recommendations from multiple domains,” in Proc. of SIGKDD, 2013.
[9] M. Szomszor, H. Alani, I. Cantador, K. OHara, and N. Shadbolt, “Semantic modelling of user interests based on crossfolksonomy analysis,” in Proc. of ISWC, 2008.
[10] F. Abel, E. Herder, G.-J. Houben, N. Henze, and D. Krause,
“Cross-system user modeling and personalization on the
social web,” in Proc. of UMUAI, 2013.
[11] S. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE
TKDE, vol. 22, no. 10, pp. 1345 - 1359, 2010.
[12] Y. Zhu, Y. Chen, Z. Lu, S. J. Pan, G.-R. Xue, Y. Yu,
and Q. Yang, “Heterogeneous transfer learning for image
classiﬁcation,” in Proc. of AAAI, 2011.
[13] F. L., G. E., and Matias, WordNet: An Electronic Lexical
Database. Cambridge, MA.: MIT Press, 1998.
[14] Z. Wu and M. Palmer, “Verb semantics and lexical selection,”
in Proc. of ACL, 1994.
[15] P. Resnick, “Using information content to evaluate semantic
similarity in a taxonomy,” in Proc. of IJCAI, 1995.
[16] M. Strube and S. P. Ponzetto, “Wikirelate! computing semantic relatedness using wikipedia,” in Proc. of AAAI, 2006.
[17] R. L. Cilibrasi and P. M. Vitanyi, “The google similarity distance,” Knowledge and Data Engineering, IEEE Transactions
on, vol. 19, no. 3, pp. 370–383, 2007.

A. Semantic Relatedness Measurement
Many prior works on measuring semantic relatedness of
two terms utilized the lexical concepts in WordNet’s taxonomy [13] based on the deepest point in the taxonomy [14] or
information content [15]. To expand concept coverage, many
researchers took Wikipedia as the knowledge base of semantic interpretation. M. Strube et al. [16] and D.Milne et al. [6]
used the taxonomy and the Normalized Google Distance [17]
in Wikipedia to compute semantic relatedness, respectively.
E.Gabrilovich et al. [5] proposed a widely applied model
of semantic interpretation, i.e., Explicit Semantic Analysis
which is also based on the relations between concepts in
online encyclopedia.
B. Cross-domain Recommendation
In fact, constructing virtual social links across different
websites can be viewed as cross-domain friend recommending. Ignacio et al. [7] proposed a survey of emerged
solutions for cross-domain recommendation and emphasized
two major tasks. Many previous works on cross-domain
recommendation focus on improving CF-based scheme. For
example, the authors in [2], [8] tried to migrate the rating
data from a dense auxiliary domain to alleviate the cold
start problem in a sparse target domain resulting in the
improvement of recommendation performance in the target
domain. Besides, [9], [10] merged user proﬁles distributed
in different domains for better recommendation.
C. Transfer Learning
Transfer learning aims to improve a learning task in a
target domain by using the knowledge transferred from other
domain in which a related task is known [11]. Recently,
transfer learning techniques have been widely applied to
mitigate the sparsity problem of collaborative ﬁltering in
cross-domain recommendation. In [2], Li et al. proposed
a transfer learning approach that performs a co-clustering
strategy on the rating matrix of an auxiliary domain with
high rating density, and discovers rating patterns at the
cluster level. Y. Zhu et al. [12] applied transfer learning
method to learn image classiﬁcation by using the knowledge
of document/image labels in auxiliary domains. In this work,

1663

Learning with Dual Heterogeneity:
A Nonparametric Bayes Model
Hongxia Yang

Jingrui He

IBM Watson Research Center
1101 Kitchawan Rd
Yorktown Heights, NY, 10598

School of Computing, Informatics, Decision
Systems Engineering
Arizona State University
699 S Mill Ave, Tempe, AZ 85281

yangho@us.ibm.com

jingrui.he@gmail.com

ABSTRACT

to handle multiple types of data heterogeneity. For example, in social media, we may have micro-blogs coming from
heterogeneous sources, such as Facebook and Twitter, and
each micro-blog may be characterized by heterogeneous features, such as key words, hashtags, number of re-tweets,
number of Facebook likes, etc; in manufacturing, we may
have products from heterogeneous manufacturing lines, and
each product may be characterized by heterogeneous environmental variables, such as temperature, pressure, etc; in
traﬃc analytics, we can collect traﬃc information from heterogeneous geographic locations (e.g., diﬀerent states), and
for each location, we may have heterogeneous traﬃc indicators, such as volume, GPS positions, etc.
Recent years have seen growing interest in addressing problems with multiple types of data heterogeneity [22, 19, 14,
43, 20, 21, 42]. In particular, for problems with dual heterogeneity, i.e., both task and view heterogeneity, researchers
have proposed multi-task multi-view learning, or M 2 T V
learning, to jointly learn in multiple related tasks with overlapping, partially overlapping or completely diﬀerent feature
spaces [22, 43, 21, 42]. Compared with traditional multi-task
learning [12, 46, 11, 38, 30], where the feature space is homogeneous across diﬀerent tasks, i.e., a single view, M 2 T V
learning is able to handle heterogeneous feature spaces; compared with traditional multi-view learning [13, 24, 16, 28, 8],
where the examples come from a homogeneous task, i.e., a
single task, M 2 T V learning is able to leverage heterogeneous
(related) tasks to improve the learning performance in each
task.
A key question in M 2 T V learning is how to model the
relatedness among multiple tasks/views. Existing methods
for M 2 T V learning [22, 43, 21, 42] usually assume that all
the tasks are equally related, and all the views are equally
consistent. Therefore, they mainly focus on exploring various types of task relatedness and view consistency. In this
paper, we go one step further, and study: (1) if all the tasks
are equally related and all the views are equally consistent;
(2) to what extent the multiple tasks are related and the
multiple views are consistent. This is motivated by the fact
that in many real applications, it is often not known a priori
the degree of relatedness among multiple tasks and consistency among multiple views. In the adversarial cases where
some tasks are negatively related to the others and some
views are contaminated by noise, simply applying the existing methods for M 2 T V learning may even hurt the performance. Although in traditional multi-task learning, there
has already been some work accommodating various task

Traditional data mining techniques are designed to model a
single type of heterogeneity, such as multi-task learning for
modeling task heterogeneity, multi-view learning for modeling view heterogeneity, etc. Recently, a variety of real applications emerged, which exhibit dual heterogeneity, namely
both task heterogeneity and view heterogeneity. Examples
include insider threat detection across multiple organizations, web image classiﬁcation in diﬀerent domains, etc. Existing methods for addressing such problems typically assume that multiple tasks are equally related and multiple
views are equally consistent, which limits their application
in complex settings with varying task relatedness and view
consistency. In this paper, we advance state-of-the-art techniques by adaptively modeling task relatedness and view
consistency via a nonparametric Bayes model: we model
task relatedness using normal penalty with sparse covariances, and view consistency using matrix Dirichlet process.
Based on this model, we propose the NOBLE algorithm
using an eﬃcient Gibbs sampler. Experimental results on
multiple real data sets demonstrate the eﬀectiveness of the
proposed algorithm.

Categories and Subject Descriptors
G.3 [Probability and Statistics]: [nonparametric statistics]; I.5.1 [Pattern Recognition]: Models—statistical

Keywords
Nonparametric Bayes modeling; multi-task multi-view; Gibbs
sampler.

1.

INTRODUCTION

Nowadays, we are facing large amount of data in a variety of areas, such as social media, manufacturing, traﬃc
analytics, etc. A common challenge in these areas is how
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD’14, August 24–27, 2014, New York, NY, USA.
Copyright 2014 ACM 978-1-4503-2956-9/14/08 ...$15.00.
http://dx.doi.org/10.1145/2623330.2623727.

582

to jointly learn the domain transforms, and a probit classiﬁer
shared in the common domain; the authors of [42] proposed
a large margin framework to address transfer learning problems1 with the same set of views in the source and target
domains; the authors of [21] proposed a graph-based framework to model the relationship among multiple tasks/views,
and designed an iterative algorithm IteM 2 to ﬁnd the classiﬁcation function. The major diﬀerence between our work
and the existing work is the following. Existing methods
assume that all the tasks are equally related and all the
views are equally consistent. Therefore, they mainly focus
on exploring various kinds of task relatedness and view consistency. In our work, we go one step further, and study:
(1) if all the tasks are equally related and all the views are
equally consistent; and (2) to what extent the multiple tasks
are related and the multiple views are consistent.
The problem of varying task relatedness has been studied in traditional multi-task learning. For example, in [37],
the authors proposed to use bipartite graphs to represent
multi-task learning, and made use of Gaussian process to
model varying task relatedness; in [12], the authors proposed a robust multi-task learning (RMTL) algorithm that
learns multiple tasks simultaneously as well identiﬁes the
irrelevant tasks; in [46], the authors showed the equivalent
relationship between alternating structure optimization and
clustered multi-task learning; etc. However, the above methods and analysis only apply in the multi-task setting, and it
is not straightforward to extend them to M 2 T V learning.
In particular, Bayesian modeling has been widely used
in multi-task learning and multi-view learning over the last
decade. Research work dedicated to Bayesian hierarchical
modeling has demonstrated eﬀectiveness and improvement
in performance [19, 3, 5]. The proposed methods have been
successfully applied to diﬀerent areas, such as information
retrieval [7] and computer vision [30]. Typical approaches
to transfer information among multiple tasks/views include:
sharing hidden nodes in neural networks, placing a common
prior in hierarchical models, sharing a common structure on
the predictor space, and structured regularization in kernel
methods, among others [19, 38, 9, 40, 39].

relatedness [45, 46, 12, 11], to the best of our knowledge,
our work is the ﬁrst to study this problem in the context of
M 2 T V learning.
To this end, motivated by the successful application of
Bayesian hierarchical modeling in multi-task learning and
multi-view learning [19, 3, 5], we propose a nonparametric
Bayes method for M 2 T V learning. In this method, task
relatedness is modeled via a normal penalty that decomposes the full covariance matrix into the Kronecker product,
and view consistency is modeled via a matrix Dirichlet process. Furthermore, we design the NOBLE algorithm, which
stands for NOnparametric Bayes LE arning with dual heterogeneity. It is based on an eﬃcient Gibbs sampler scalable
to relatively high dimensions. The main contributions of this
paper can be summarized as follows.
1. For the ﬁrst time, in the context of M 2 T V learning,
we study problems where multiple tasks may exhibit
diﬀerent degree of relatedness, and multiple views may
exhibit diﬀerent degree of consistency;
2. We propose a nonparametric Bayes method for M 2 T V
learning which adaptively learns various task relatedness and view consistency;
3. We design the NOBLE algorithm based on an eﬃcient
Gibbs sampler scalable to relatively high dimensions;
4. We compare the performance of our proposed NOBLE
algorithm with state-of-the-art techniques on various
real data sets.
The rest of the paper is organized as follows. In Section
2, we brieﬂy review the related work. The nonparametric
Bayes method for M 2 T V learning is proposed in Section 3,
followed by the algorithm description of NOBLE in Section
4. Section 5 compares NOBLE with state-of-the-art methods on real data sets. Finally, we conclude in Section 6.

2.

RELATED WORK

In this section, we brieﬂy review the related work in heterogeneous learning and Dirichlet process mixture models.

2.2 Dirichlet Process Mixture Models

2.1 Heterogeneous Learning

In this paper, we propose to use Dirichlet process (DP)
prior to encourage view clustering in the context of M 2 T V
learning. Before presenting our model, we brieﬂy review DP
mixture models. In a Bayesian mixture model, we assume
that the true density of the response Y can be written as
a mixture of parametric densities, conditioned on a hidden
parameter θ. For example, in a Gaussian mixture, θ corresponds to the mean μ and variance σ 2 . The marginal probability of an observation is given by a continuous mixture,
f (y) = T f (y|θ)P (dθ), where T is the set of all possible
parameters and the prior P is a measure on that space. DP
models uncertainty about the prior density P [17, 2]. If P
is drawn from a Dirichlet process then it can be analytically
integrated out of the conditional distribution of θT given
θ1:(T −1) , where θT denotes the T th parameter for observation yT . Speciﬁcally, the random variable θT has a Polya

The goal of heterogeneous learning is to leverage multiple
types of heterogeneities (e.g., task heterogeneity, view heterogeneity, instance heterogeneity, label heterogeneity, etc)
to improve the performance of predictive modeling. For example, in [22, 23, 33, 43, 19, 21, 42], the authors jointly
modeled the task and view heterogeneities; in [41] the authors jointly modeled the view and instance heterogeneities;
in [26], the authors jointly modeled the instance and label
heterogeneities.
For problems with both task and view heterogeneity, the
authors of [22] focused on multiple tasks with completely
diﬀerent feature spaces, and proposed to construct a single prediction model in the shared induced space; the authors of [23] proposed to learn shared predictive structures
on common views from multiple related tasks, and used the
consistency among diﬀerent views to improve the performance; the authors of [43] used co-regularization in each
task to obtain a linear mapping, and used additional regularization functions across diﬀerent tasks to impose task relatedness; the authors of [19] proposed a latent probit model

1

Transfer learning is very similar to multi-task learning except that in transfer learning, we only care about the learning performance in the target domain.

583

a particular index h∗ , then the corresponding parameters
Θph∗ is likely to be shared among multiple tasks. We also
note that this sharing among tasks is encouraged by large
Uth∗ . Since Uth∗ may be large for multiple diﬀerent tasks t,
this implies that if parameter sharing occurs for one predictor among the multiple tasks, then it is also likely that there
will be sharing for other predictors. We can therefore generalize the following key properties of MSBP: (i) if a given
parameter for predictor p, Θph∗ , is shared among some of
the tasks, it is more likely to be shared among other tasks;
(ii) if sharing occurs between multiple predictors for a subset
of tasks, then it is more encouraged that sharing will occur
between other predictors within these tasks.

urn distribution [6]:
θT |θ1:(T −1) ∼

T
−1

1
α
δθ +
G0 .
α + T − 1 t=1 t
α+T −1

The above equation reveals the clustering property of the
joint distribution of θ1:T , where there is a positive probability that each θt will take on the value of another θt , leading
some of the parameters to share values. This equation also
makes clear the roles of α and G0 . The unique values of
θ1:(T −1) are drawn independently from G0 ; the parameter α
controls how likely θT is to be a newly drawn value from G0
rather than to take one of values from θ1:(T −1) . G0 controls
the distribution of a new component.
In a DP mixture, θ is a latent parameter to an observed
data point y [2]: P ∼ DP(αG0 ), θt ∼ P, yt |θt ∼ f (·|θt ). Examining the posterior distribution of θ1:T given y1:T brings
out its interpretation as an “inﬁnite clustering” model. Because of the clustering property, observations are grouped
by their shared parameters. Unlike ﬁnite clustering models, however, the number of groups is random and unknown.
Moreover, a new data point can be assigned to a new cluster
that was not previously seen in the data.
However, the DP prior does not allow local clustering
of tasks/views with respect to a subset of the feature vector without making independence assumptions. Considering
sample s (s = 1, . . . , nt ) from task (or view) t (t = 1, . . . , T ),
suppose that the response variable is yts and related feature
vector is xts with dimension np by 1. A common strategy for such problem is to use a hierarchical model of the
form yts ∼ p(xts , f t , φ), where p(x, f , φ) is the conditional
distribution of y given feature vector x, parameters f and
φ. φ are global parameters and f = (f 1 , . . . , f T ) is a vector of task-speciﬁc (or view-speciﬁc) coeﬃcients. We could
specify independent DP priors for the coeﬃcients [35, 14]:
iid
ftp ∼ Gt , Gt ∼ DP (αj , G0j ) for p = 1, . . . , np . This approach allows diﬀerential clustering of the coeﬃcients for
diﬀerent feature components, however, independence is assumed across the feature components. This is unappealing,
because ftp = ft p provides information that tasks t and t
are similar, which should intuitively increase the probability
that ftp = ft p , for p = p . Motivated by this desire to
borrow information across related feature components and
tasks simultaneously, [35] propose a matrix stick-breaking
process (MSBP) by assuming
ind

ftp ∼ Gtp ,

3. NONPARAMETRIC BAYES LEARNING
WITH DUAL HETEROGENEITY
3.1 Notation
Suppose that we have T tasks and V views in total. For
the v th view, there are dv features. For the tth task (t =
1, . . . , T ), there are nt examples and each example can be
represented as xts = [(xts1 ) , . . . , (xtsV ) ] with label ŷts
(s = 1, . . . , nt ), where () denotes vector transpose. xtsv ∈
Rdv denotes the features from the v th view (v = 1, . . . , V )
of the sth example in the tth task, and ŷts is either discrete for classiﬁcation problems, or real-valued for regression problems. Notice that if a certain view is missing, the
associated features will all be 0. Therefore, our problem setting is essentially the same as in [21] where some views are
shared by multiple tasks, and some views are task speciﬁc.
Without loss of generality, suppose that we know the output
ŷt1 , . . . , ŷtmt of the ﬁrst mt examples, where mt is usually
much smaller than nt . Our goal is to leverage both the label
information from all the related tasks, as well as the consistency among diﬀerent views of a single task to predict the
output of the remaining nt − mt examples.

3.2 Model Formulation
In our proposed model, we ﬁrst decompose each task into
multiple single-view models. Each of them generates a predictor based on the features in the single view, which can
be used to make predictions on future unseen examples.
Here we relax the common assumption in multi-view learning [8, 29, 34] that diﬀerent views are conditionally independent given the class label. To be speciﬁc, for the tth task
(t = 1, . . . , T ), we use a mixture linear regression model for
the estimated output ŷts (s = 1, . . . , nt ) by averaging the
prediction results from all single-view models as follows:

G ∼ P,

where G = {Gtp , p = 1, . . . , np , t = 1, . . . , T } is a matrix of
random probability measures, and P is a probability measure on (Ω, G), with Ω the space of T × np matrices with the
(t, p)th element a probability measure on (Xt , Bt ). Here, G
is a σ-algebra of subsets of Ω and Bt is a Borel σ-algebra of
subsets of Xt , ftp ∈ Xt . The proposed MSBP allows separate clustering and borrowing of information for the diﬀerent
feature components through
Gtp =

H


{Vtph

h=1

Vtph = Uth Wph ,



Vtpl }δΘph ,

ŷts =

v=1

ind

l<h
iid

(xtsv ) f tv + ts ,

where f tv ∈ Rdv is the coeﬃcient vector, and tsv ∈ R is the
observational error. Based on the above model, we estimate
the task relatedness and the view consistency as follows.

Θph ∼ G0p ,

Uth ∼ Beta(1, α),

V


iid

Wph ∼ Beta(1, β).

To provide an intuitive explanation for the above formulation, we ﬁrst consider the sticks Wph . If Wph is large for

584

1. Task Relatedness: Here we use a Gaussian process deﬁned on ts to model the task relatedness. To be speciﬁc, we assume that s = {ts }t=1,...,T ∼ N(0, K), where
K ∈ RT ×T is the kernel matrix of the Gaussian process, and it is the key to determining the various task
relatedness. Diﬀerent from [37], where only a single information source is used to obtain the kernel function,

We start by assuming for v ≥ v  ≥ 1,

in this paper, we fully leverage the multi-view property
to estimate K in a more reliable way. To be speciﬁc, in
order to estimate K, we deﬁne a task graph as follows:
the graph consists of T nodes with each node representing a single task; let B ∈ RT ×T denote the adjacency
matrix of the graph, whose 
element
in the tth row and
nt nt
tth column is Btt = nt1n 
< xts , xt s >,

s=1
s =1
t
where t, t = 1, . . . , T , and < ·, · > denotes vector inner
product. For this graph, we can compute the Laplacian
Δ = D − B, where D ∈ RT ×T is a diagonal matrix with
each diagonal element equal to the row sum of B. Using
Δ, we obtain K as follows:


K = β(Δ +

1
I)
σ2

−1

ind

Ψvv ∼ Fvv ,

Here F = {Fvv , V ≥ v ≥ v  ≥ 1} is a matrix of random
probability measures. Let Ω be the space of symmetric
V × V matrices and F will be a σ-algebra of subsets of
Ω. P is a probability measure on (Ω, F).
Next, our focus is on the speciﬁcation of P. Assuming
each element in F has a stick-breaking representation,
i.e.,
Fvv =

,

Ψ12
..
.
ΨV 2

···
..
.
···




ind
(1 − Wvv ,l ) δΘh , Θh ∼ G, (1)

l<h

Dependency within dimensions of F will be incorporated
through dependent stick-breaking weights and the common parametric prior G. For the stick-breaking weights,
we decompose them as follows
ind

Wvv ,h = γvh γv h , γvh ∼ Beta(1, α), α ∼ Ga(1, α0 ),
where both γvh and γv h are random variables with the
same Beta distribution, α > 0 is a parameter in the Beta
distribution, and α0 > 0 is the scale parameter in the
Gamma distribution. In this way, we guarantee the symmetric property: Wvv ,h = Wv v,h . Furthermore, according to [15], the deﬁnition of γvh ensures that
∞




(1 − Wvv ,l ) = 1
Wvv ,h
h=1

l<h

Therefore, Equation (1) is a valid probability measure.
We use the following example to show the intuition of the
above formulation. Let V = 4, and V1 , . . . , V4 stand for
the four diﬀerent views. Then the probability that two
covariance matrices ΨV1 V2 and ΨV1 V3 are same can be
computed as follows.

2. View Consistency: To estimate the various view consistency, we jointly model the coeﬃcient vectors f tv (v =
1, . . . , V ) through:
⎞
⎛
⎡
Ψ11
f t1
⎟
⎜
⎢ .
..
. ⎠ ∼ N ⎝ 0 , ⎣ ..
f tV
ΨV 1

Wvv ,h

where W vv = {Wvv ,h , h = 1, . . . , ∞}, for V ≥ v ≥
v  ≥ 1, is an array of random stick-breaking weights.
Θh ∈ Rd+v ×dv stands for the latent covariance matrix2
that is drawn from the base measure G, which usually
takes the Inverse-Wishart (IW) distribution. Notice that
similar to the usual Dirichlet Process, Ψvv equals to Θh
with probability proportional to Wvv ,h l<h (1 − Wvv ,l ).

We would like to point out several important aspects of
the proposed Gaussian process. First, the kernel matrix
K, whose elements indicate the similarity among various
tasks, depends on the inverse of the regularized graph
Laplacian Δ. Therefore, the relatedness between two
tasks is global in the sense that it depends on all the
tasks. Second, if we also have unlabeled data in addition
to the labeled training data, all the unlabeled data can be
used to deﬁne the adjacency matrix B (since it does not
require label information), thus making it more robust to
noise. Finally, the adjacency matrix B depends on the
features from all the views through xts . It tends to be
more reliable if certain views have been contaminated by
noise.

⎜
⎝

∞


h=1

where both β and σ 2 are positive parameters. In particular, β controls the overall sharpness of the distribution: large values of β mean that the distribution is
more peaked around its mean. For more ﬂexibility, we
let β ∼ Ga(a, b), which stands for Gamma distribution
with shape parameter a and scale parameter b. It will
be adapted to the data through adjusting the distribution related parameters a and b. σ 2 controls the amount
of regularization. For this parameter, we could use the
following prior σ 2 ∼ IG(c, d), which stands for InverseGamma distribution with shape parameter c and scale
parameter d.

⎛

F ∼ P,

Pr(ΨV1 V2 = ΨV1 V3 ) =

⎤⎞
Ψ1V
.. ⎥⎟
. ⎦⎠
ΨV V

1
(α + 1)(α + 2) − 1

Furthermore, the conditional probability of these two matrices being the same given that ΨV4 V2 = ΨV4 V3 can be
computed as follows.

d ×d

lim Pr(ΨV1 V2 = ΨV1 V3 |ΨV4 V2 = ΨV4 V3 ) =

where Ψvv ∈ R+v v denotes the covariance matrix between the v th and the v th views. Ψvv = Ψv v .

α→0

1
α+1

From the above equations, we can see that the probability
of ΨV1 V2 and ΨV1 V3 being the same ranges between 0
and 1, depending on the value of the parameter α. Both
converge to 1 in the limit as α → 0 and to 0 as α → ∞.
We can verify that Pr(ΘV1 V2 = ΘV1 V3 ) ≤ Pr(ΘV1 V2 =
ΘV1 V3 |ΘV4 V2 = ΘV4 V3 ). It means given that view 2, 4 and

Furthermore, a Dirichlet Process (DP) prior can be used
here to encourage view cluster. However, without the
conditional independence assumption, the DP prior does
not allow local clustering of views with respect to a subset
of the feature vectors. To address this problem, we extend
the matrix DP prior [15] to deﬁne the covariance matrix
Ψvv , which encourages cross-view sharing of data. To be
speciﬁc, we borrow information by incorporating dependency in the prior distributions for the matrices {Ψvv }.

2

For the sake of explanation, we assume that dv is a constant
for v = 1, . . . , V ; otherwise we ﬁll in 0 values to make the
dimensionality of each view equal.

585

where

view 3, 4 are equally correlated in terms of the covariance
matrices, then there will be an increased probability that
view 1, 2 and view 1, 3 are equally correlated.

⎛

⎞
⎛
y11
x11
⎜ . ⎟
⎜ ..
⎜ .. ⎟
⎜ .
⎜
⎟
⎜
⎜ y1S ⎟
⎜ x1S
⎜
⎟
⎜
⎜ . ⎟
⎜
⎜ . ⎟
⎜
⎜ . ⎟
⎜
⎜
⎟
y = ⎜ y21 ⎟ , X = ⎜
⎜
⎜ . ⎟
⎜
⎜ . ⎟
⎜
⎜ . ⎟
⎜
⎜
⎟
⎜
⎜ y2S ⎟
⎜
⎜
⎟
⎜ .. ⎟
⎝
⎝ . ⎠
yT S
⎛
⎛
⎞
f1
xts1
⎜ .
⎜ . ⎟
with xts = ⎝ .. ⎠ , and f = ⎝ ..
xtsV
fT

Finally, for the base measure G of the view covariance
matrix, we consider the following degenerate distribution:
G = πI0 + (1 − π)G0 , G0 ∼ IW(ν, Ψ0 )
where 0 ≤ π ≤ 1, ν is the degrees of freedom of the
Inverse-Wishart distribution, Ψ0 ∈ Rd+v ×dv is the scale
matrix. When Ψvv falls into the I0 cluster, the corresponding covariance matrix will be a zero matrix, and
the nonsigniﬁcant f tv will be set to 0.
Figure 1 shows the graphical representation of the proposed model. To generalize, for each example s in the task
t (yst ), task relatedness is characterized through K where
β controls the overall sharpness of the distribution and σ 2
controls the amount of regularization. On the other hand,
there is a view-speciﬁc feature xtsv for the s example in
the tth task and we use f tv to characterize v th view eﬀect
in the tth task. We extend the DP to characterize the covariance matrix Ψvv in order to cluster the coeﬃcients f tv .
W and α characterize the stick weights; G characterizes
the base measure for DP, which is a degenerate distribution
with probability π to be the null matrix and with probability
1 − π to be an Inverse-Wishart distribution G0 with degrees
of freedom ν and scale matrix Ψ0 .

⎞

x21
..
.
x2S

⎞

xT 1
..
.
xT S
⎛

⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟,
⎟
⎟
⎟
⎟
⎟
⎟
⎠

⎞
f t1
⎜ . ⎟
⎟
⎠ , f t = ⎝ .. ⎠ .
f tV

The posterior distribution of f tv is proportional to combining the joint likelihood and the prior in Equation (1).
Therefore we can update f tv jointly from the following conjugate mulvariate normal distribution:


−1  −1
p(f | · · · ) ∼ MN X(K −1 ⊗ IS )X + IT ⊗ Ψ
X (K
⊗ IS ŷ),

−1

, (3)
X(K −1 ⊗ IS )X + IT ⊗ Ψ

Similarly, by combining the joint likelihood as in Equation
(2) and the prior Ga(a, b), β is updated directly through the
following Gamma distribution p(β| · · · ):




1
1
1
Ga a + T V, b + (ŷ − Xf ) (Δ + 2 IT ) ⊗ IS (ŷ − Xf ) . (4)
2
2
σ

In each iteration, given the prior IG(c, d), σ 2 is drawn
through:


1
1
p(σ2 | · · · ) ∼ IG c + T V, d + β(ŷ − Xf ) (ŷ − Xf ) .
2
2

Since the DP prior implies that D is almost surely discrete, the prior will automatically group the m coeﬃcientspeciﬁc hyperparameters Ψvv into L clusters Ψ∗l , where
L ≤ 12 V (V − 1). One of these clusters will most likely correspond to Ψ∗l = Idv ×dv , and the other clusters will not be
0. We denote Jvv = l if the (v, v  )th covariance matrix is
clustered in the lth latent cluster. Our proposed prior can
be seen more
 clearly through the equivalent stick breaking
form Jvv ∞
l=1 Wl δl with

for l = 1
πδ0 ,
Ψ∗l ∼
(1 − π)IW(ν, Ψ0 ), for l > 1.

Figure 1: Graphical representation for the proposed
model.

4.

THE PROPOSED ALGORITHM

In this section, we present the NOBLE algorithm, which
stands for NOnparametric Bayes LE arning with dual heterogeneity. It is based on an eﬃcient Gibbs algorithm that
is scalable to relatively high dimensions. For simplicity, we
assume that nt = S in the following. In particular, each
iteration of the Gibbs sampler draws samples through the
following sequence. The joint likelihood of the samples is as
follows:
TS

Extending the exact block Gibbs sampler of [36], the joint
prior distributions of Jvv and a latent variable ζvv can be
written as
f (Jvv , ζvv |W ) =



δl (·) =

l:Wl >ζvv

1

p(y|X, f , K) = (2π)− 2 |IS ⊗ K|− 2


 

−1 
1
y − Xf
· exp − y − Xf IS ⊗ K
2

(5)

∞


1(ζvv < Wl )δl (·).

l=1

We implement the following exact block Gibbs sampler steps:

(1). Sample ζ
vv  ∼ uniform(0, WJvv ), for v ≥ v ≥ 1 with
Wl = γl h<l (1 − γh ).

(2)

586

Sample
 variables γl from γl ∼
 the stick-breaking random
L
beta 1 + ml , α + s=l+1 ms , for l = 1, . . . , L with L

2. SMTL [27]: a Bayesian semi-supervised learning framework for problems with multiple tasks using unlabeled
data based on Markov random walk.

the minimum value satisfying W1 + . . . + WL > 1 −
min{ζvv }. ml is the number of components clustered
into the lth cluster.

3. CASO [10]: a multi-task learning algorithm improving
the ASO algorithm [1] through a novel regularizer.

Sample Ψ∗l for l = 1, . . . , L by
For all 4 algorithms, we repeat the experiments 10 times
(1) For l = 1,Ψ∗1 = 0.
and report the average classiﬁcation error4 . For regMVMT,
 1

(2) For 2 ≤ l ≤ L, since (f tv |f t(−v) ) ∝ exp − 2 f tv Ψvv f tv −the parameters are optimized using cross-validation. For


f tv v∼v Ψvv f tv , Ψ∗l can be drawn directly from:
SMTL and CASO, the parameters are set according to [27]


and [10] respectively. For the proposed NOBLE algorithm,
 
∗
Ψl ∼ IW ml + ν + 1, Ψ0 + t J  =l f tv f tv .
we simply set non-informative hyperparameters as α0 = 1,
vv

(2). Sample Jvv for v ≥ v  ≥ 1 from the multinomial conditional with

exp{−f tv Ψ∗l f tv }.
Pr(Jvv = l|·) ∝ 1(ζvv < πl )
t
ind

After updating γh , with the relationship γvh ∼ beta(1, α), α ∼
Ga(1, α0 ), we sample α through



p(α| · · · ) ∼ E α0 −
log(1 − γvh ) .
(6)
v,h

where E(x; λ) = λ exp(−λx) is the exponential density.
Based on the above discussion, the proposed NOBLE algorithm is summarized in Algorithm 1.
Algorithm 1 NOBLE Algorithm
Require: yts , xtsv , INtsv , K t = 1, . . . , T , s = 1, . . . , S,
v = 1, . . . , V
Ensure: the initial value for f tv , β, σ 2 , Ψvv and α
1: for i = 1 to Total number of iterations do
2:
for t = 1 to T do
3:
for v, v  = 1 to V do
4:
Update f through the multivariate normal distribution in Equation (3);
5:
Update β through the Gamma distribution as in
Equation (4);
6:
Draw σ 2 directly from Inverse Gamma distribution in Equation (5);
7:
Update DP related parameters using exact block
Gibbs sampler as described in the above Step 4;
8:
Update α using truncated exponential distribution as in equation (6).
9:
end for
10:
end for
11: end for

5.

EXPERIMENTS

In this section, we present some experimental results showing the eﬀectiveness of the proposed NOBLE algorithm and
compare against the following algorithms3 :
1. regMVMT [44]: an inductive multi-view learning algorithm for multiple related tasks through a co-regularized
framework.
3
We did not compare with IteM 2 [21] since in our experiments, the features are not guaranteed to be non-negative.
As shown in [43], the performance of IteM 2 is not satisfactory in this case.

π = 1/2, ν = 2np + 1 and Ψ0 = Inp without prior knowledge
about the correlation among the tasks and the relative importance of each view in the predictive model of each task.
We also performed convergence diagnostics, such as trace
plots and Geweke’s convergence diagnostic for randomly selected parameters. No signs of adverse mixing have been
found. All results are based on 3,000 Gibbs sampling iterations after a burn-in period of 2,000.
In our experiments, to generate multiple views from the
original feature space, we adopt a similar strategy as in [25],
and apply diﬀerent linear/nonlinear dimensionality reduction methods, including ICA with diﬀerent functions (pow3
or order 3 polynomial kernel, Tanh, Gaussian, skew) [18],
PCA based (PCA, Prob PCA [31], and kernel PCA), MDS,
diﬀusion maps, Laplacian, and Laplacian Eigenmaps [32],
resulting in 11 views total.
20 newsgroups data set. We ﬁrst consider the 20 newsgroups data set [4]. This data set consists of articles from 20
diﬀerent newsgroups forming a hierarchical structure. Here
we focus on the “comp” and “rec” categories (similar experimental results are observed for the other categories and thus
omitted for brevity), and create 4 tasks from them. To be
speciﬁc, for each task, we pick one subcategory from “comp”
and “rec” respectively and randomly sample 100 articles from
each subcategory to form 2 classes, each described by 53975
features.
To test the capability of our proposed algorithm to recover data sets with diﬀerent sparsity, we experiment on
data sets with various numbers of labeled examples: varying from randomly selecting 20 to 180 observed samples and
use the remaining as test set.
Figure 2 shows the comparison results of the 4 algorithms
with varying training set size. Each subﬁgure shows the average classiﬁcation error for a single task. From these ﬁgures,
we can see that the performance of NOBLE dominates the
other methods, and the margin becomes more signiﬁcant as
the number of labeled examples increases. This is because
NOBLE is able to learn from data: (1) if all the tasks/views
are related, and (2) how much they are related to each other.
Figure 3 shows that by using the DP prior, we are able to
partition the 11 views into 2 groups roughly: one consists of
7 views generated using ICA and PCA based dimensionality
reduction methods, and the other consists of 4 views generated using MDS, diﬀusion maps, Laplacian, and Laplacian
Eigenmaps. In each iteration of the algorithm, there is a
positive probability that ΨVi Vj = ΨVi Vj for every j = j  .
Two views j = j  are said to be clustered in terms of sharing covariance matrices if and only if ΨVi Vj = ΨVi Vj and
Figure 3 is the average over the iterations. The clustering
4

587

For the sake of clarity, we did not display the error bars.

Figure 2: Comparison results on the 20 Newsgroups data.
sive experiments, regMVMT cannot perform well when the
training sample size is small.
We also test the computation time per iteration in NOBLE as we vary the training set size, which is shown in
Figure 6. From this ﬁgure, we can see that NOBLE scales
linearly with respect to the total number of labeled examples, thus it is scalable to relatively large data sets.

of the views encoded by the ties among the covariance matrices will simply be referred to as the “clustering of the
views”, although it should be understood that it is the data
themselves that are clustered. The fact that our model induces ties among the views is the means by which it borrows
strength across objects for estimation.
WebKB data set. Next we test the performance of NOBLE on WebKB data set, where the goal is to classify whether
a web page is course related or not [8]. We also create 4 tasks
from this data set, each including 200 web pages collected
from the same university.

6. CONCLUSION
In this paper, we propose a nonparametric Bayes model
for addressing problems with dual-heterogeneity, i.e., task
heterogeneity (multiple related tasks) and view heterogeneity (multiple views). Compared with state-of-the-art techniques which assume that the tasks are equally related and
the views are equally consistent, we aim at answering the following two questions: (1) Are all the tasks equally related
and all the views equally consistent? (2) To what extent
are the tasks related to each other, and the views consistent
with each other? To this end, we make use of the normal
penalty with sparse inverse covariances and the matrix DP
prior to adaptively learn the task relatedness and the view
consistency. Furthermore, we propose the NOBLE algorithm based on an eﬃcient Gibbs sampler, which constructs
predictors for all the tasks leveraging both the multi-task
and multi-view nature. Experimental results on several real
data sets show that NOBLE outperforms existing methods
in M 2 T V learning.

View Clustering in 20 Newsgroups Data
ICA(pow^3)
ICA(Tanh)

0.9

ICA(Gaussian)

0.8

ICA(skew)

0.7

ProbPCA

0.6

PCA

0.5

KernelPCA
MDS

0.4

diffusion maps

0.3

Laplacian

0.2

Laplacian Eigenmaps
2

4

6

8

10

0.1

Figure 3: NOBLE clustering probability for 11
views of the 20 newsgroups data.

4.5

4

5

Seconds per iteration

Figure 4 shows the comparison results with varying training set size. Similarly as before, we can see that the performance of NOBLE is better than the other 3 competitors in
each of the 4 tasks.
Email spam data set. Finally, we compare on the email
spam data set from ECML 2006 discovery challenge.5 The
goal is to classify if each email is spam or ham. In problem A, There are 3 users with 2,500 emails each, which are
considered as 3 related tasks.
Comparison results are shown in Figure 5. On this data
set, we also see improved performance of NOBLE over the
competitors except for Task 1: when the training set size
is small, NOBLE and CASO are pretty close to each other;
when the training set size is large, the performance of NOBLE is consistently improved whereas the performance of
CASO ﬂuctuates. We notice that throughout the exten-

3.5

3

2.5

2
200

220

240

260
280
300
320
340
Number of Labeled Data in Each Task

360

380

Figure 6: Computation time per iteration of NOBLE ˙

References
[1] R. Ando and T. Zhang. A framework for learning
predictive structures from multiple tasks and
unlabeled data. Journal of Machine Learning
Research, 6:1817–1853, 2005.

http://www.ecmlpkdd2006.org/challenge.html.

588

Figure 4: Comparison results on the WebKB data.

Figure 5: Comparison results on the email spam data.
[2] C. Antoniak. Mixtures of dirichlet processes with
applications to bayeisan nonparametric problems. The
Annals of Statistics, 2:1152–1174, 1974.

[12] J. Chen, J. Zhou, and J. Ye. Integrating low-rank and
group-sparse structures for robust multi-task learning.
In KDD, pages 42–50, 2011.

[3] C. Archambeau, S. Guo, and O. Zoeter. Sparse
bayesian multi-task learning. NIPS, 2011.

[13] C. Christoudias, R. Urtasun, and T. Darrell.
Multi-view learning in the presence of view
disagreement. In UAI, pages 88–96, 2008.

[4] A. Asuncion and D. Newman. UCI machine learning
repository, 2007.

[14] L. Ding, A. Yilmaz, and R. Yan. Interactive image
segmentation using dirichlet process multiple-view
learning. IEEE Transactions on Image Processing,
21(4):2119–2129, 2012.

[5] B. Bakker and T. Hesks. Task clustering and gating
for bayesian multitask learning. JMLR, 4:83–99, 2003.
[6] D. Blackwell and J. MacQueen. Ferguson distributions
via polya urn schemes. The Annals of Statistics,
1:353–355, 1973.

[15] D. Dunson, Y. Xue, and L. Carin. The matrix stickbreaking process: ﬂexible bayes meta analysis. Journal
of the American Statistical Association, 103:317–327,
2008.

[7] D. M. Blei, T. L. Griﬃths, M. I. Jordan, and J. B.
Tenenbaum. Hierarchical topic models and the nested
chinese restaurant process. In NIPS, 2003.

[16] J. Farquhar, D. Hardoon, H. Meng, J. Shawe-Taylor,
and S. Szedmak. Two view learning: Svm-2k, theory
and practice. NIPS, 2005.

[8] A. Blum and T. M. Mitchell. Combining labeled and
unlabeled sata with co-training. In COLT, 1998.

[17] T. Ferguson. A bayesian analysis of some
nonparametric problems. The Annals of Statistics,
1:209–230, 1973.

[9] D. Burr and H. Doss. A bayesian semiparametric
model for random-eﬀects meta-analysis. Journal of the
American Statistical Association, 100(469):242–251,
2005.

[18] H. Gavert, J. Hurri, J. Sarela, and A. Hyvarinen. The
fastica package for matlab.
http: // research. ics. aalto. fi/ ica/ fastica/ ,
2005.

[10] J. Chen, T. Lei, J. Liu, and J. Ye. A convex
formulation for learning shared structures from
multiple tasks. ICML, 2009.

[19] S. Han, X. Liao, and L. Carin. Cross-domain multitask
learning with latent probit models. NIPS, 2012.

[11] J. Chen, J. Liu, and J. Ye. Learning incoherent sparse
and low-rank patterns from multiple tasks. In KDD,
pages 1179–1188, 2010.

[20] M. Harel and S. Mannor. Learning from multiple
outlooks. In ICML, pages 401–408, 2011.

589

[36] C. Yau, O. Papaspiliopoulos, G. Roberts, and
C. Holmes. Nonparametric hidden markov models
with application to the analysis of
copy-number-variation in mammalian genomes.
Journal of Royal Statistical Society: Series B,
73(1):37–57, 2010.

[21] J. He and R. Lawrence. A graphbased framework for
multi-task multi-view learning. In ICML, pages 25–32,
2011.
[22] J. He, Y. Liu, and Q. Yang. Linking heterogeneous
input spaces with pivots for multi-task learning. In
SDM, 2014.

[37] K. Yu and W. Chu. Gaussian process models for link
analysis and transfer learning. In NIPS, 2007.

[23] X. Jin, F. Zhuang, S. Wang, Q. He, and Z. Shi. Shared
structure learning for multiple tasks with multiple
views. In ECML/PKDD (2), pages 353–368, 2013.

[38] K. Yu, A. Schwaighofer, and V. Tresp. Learning
gaussian processes from multiple tasks. ICML, 2005.

[24] S. M. Kakade and D. P. Foster. Multi-view regression
via canonical correlation analysis. In COLT, pages
82–96, 2007.

[39] K. Yu, A. Schwaighofer, V. Tresp, W. Ma, and
H. Zhang. Collaborative ensemble learning:
Combining collaborative and content-based
information ﬁltering via hierarchical bayes. UAI, 2003.

[25] A. Kumar, P. Rai, and H. D. III. Co-regularized
multi-view spectral clustering. In NIPS, pages
1413–1421, 2011.

[40] K. Yu, V. Tresp, and S. Yu. A nonparametric
hierarchical bayesian framework for information
ﬁltering. Proceedings of the 27th Annual International
ACM SIGIR Conference on Research and
Development in Information Retrieval, 2004.

[26] Y.-X. Li, S. Ji, S. Kumar, J. Ye, and Z.-H. Zhou.
Drosophila gene expression pattern annotation
through multi-instance multi-label learning.
IEEE/ACM Trans. Comput. Biology Bioinform.,
9(1):98–112, 2012.

[41] D. Zhang, J. He, and R. D. Lawrence. Mi2ls:
multi-instance learning from multiple
informationsources. In KDD, pages 149–157, 2013.

[27] Q. Liu, X. Liao, and L. Carin. Semi-supervised
multi-task leraning. NIPS, 2007.

[42] D. Zhang, J. He, Y. Liu, L. Si, and R. D. Lawrence.
Multi-view transfer learning with a large margin
approach. In KDD, pages 1208–1216, 2011.

[28] I. Muslea, S. Minton, and C. A. Knoblock. Active +
semi-supervised learning = robust multi-view learning.
In ICML, pages 435–442, 2002.

[43] J. Zhang and J. Huan. Inductive multi-task learning
with multiple view data. In KDD, pages 543–551,
2012.

[29] K. Nigam and R. Ghani. Analyzing the eﬀectiveness
and applicability of co-training. In CIKM, pages
86–93, 2000.

[44] J. Zhang and J. Huan. Inductive multi-task learning
with multiple view data. In KDD, pages 543–551,
2012.

[30] J. O’Sullivan and S. Thrun. Discovering structure in
multiple learning tasks: The tc algorithm. ICML,
pages 489–497, 1996.

[45] Y. Zhang and D.-Y. Yeung. A convex formulation for
learning task relationships in multi-task learning.
CoRR, abs/1203.3536, 2012.

[31] M. Tipping and C. Bishop. Probabilistic principal
component analysis. Journal of the Royal Statistical
Society, Series B, 61:611–622, 1999.

[46] J. Zhou, J. Chen, and J. Ye. Clustered multi-task
learning via alternating structure optimization. In
NIPS, pages 702–710, 2011.

[32] L. van der Maaten, E. Postma, and H. van den Herik.
Dimensionality reduction: A comparative review.
Tilburg University Technical Report, TiCC-TR
2009-005, 2009.
[33] H. Wang, F. Nie, H. Huang, S. L. Risacher, A. J.
Saykin, and L. Shen. Identifying disease sensitive and
quantitative trait-relevant biomarkers from
multidimensional heterogeneous imaging genetics data
via sparse multimodal multitask learning.
Bioinformatics, 28(12):127–136, 2012.
[34] W. Wang and Z.-H. Zhou. A new analysis of
co-training. In ICML, pages 1135–1142, 2010.
[35] Y. Xue, X. Liao, L. Carin, and B. Krishnapuram.
Multi-task learning for classiﬁcation with dirichlet
process priors. Journal of Machine Learning Research,
8:35–63, 2007.

590

2014 IEEE International Conference on Data Mining

Learning from Label and Feature Heterogeneity
Pei Yang

Jingrui He

Hongxia Yang

Haoda Fu

The City College of New York
Arizona State University IBM Thomas J. Watson Research Eli Lilly and Company
South China University of Technology jingrui.he@gmail.com
yangho@us.ibm.com
fu haoda@lilly.com
cs.pyang@gmail.com
labels are similar, and (2) impose the view consistency by requiring that view-based classiﬁers generate similar predictions
on the same examples. To solve the resulting optimization
problem, we propose an iterative algorithm based on block
coordinate descent. It is guaranteed to converge to the global
optimum.

Abstract—Multiple types of heterogeneity, such as label heterogeneity and feature heterogeneity, often co-exist in many realworld data mining applications, such as news article categorization, gene functionality prediction. To effectively leverage
such heterogeneity, in this paper, we propose a novel graphbased framework for Learning with both Label and Feature
heterogeneities, namely L2 F . It models the label correlation by
requiring that any two label-speciﬁc classiﬁers behave similarly on
the same views if the associated labels are similar, and imposes the
view consistency by requiring that view-based classiﬁers generate
similar predictions on the same examples. To solve the resulting
optimization problem, we propose an iterative algorithm, which
is guaranteed to converge to the global optimum. Furthermore,
we analyze its generalization performance based on Rademacher
complexity, which sheds light on the beneﬁts of jointly modeling
the label and feature heterogeneity. Experimental results on
various data sets show the effectiveness of the proposed approach.

Furthermore, we aim to answer the fundamental question
of whether the generalization performance can be improved
by jointly modeling both label and feature heterogeneities.
Our theoretical analysis based on Rademacher complexity
shows that the error bound of the proposed framework could
be improved by utilizing the label correlation and imposing
the view consistency. We also empirically demonstrate the
effectiveness of L2 F on various data sets compared with stateof-the-art techniques. The main contributions of this paper can
be summarized as follows.

Keywords—multi-label learning; multi-view learning; heterogeneity; Rademacher complexity.

I.

A graph-based framework named L2 F for jointly
modeling the label and feature heterogeneity;
• Theoretical analysis of L2 F showing the beneﬁts of
simultaneously leveraging both types of heterogeneity;
• Experimental results on a variety of data sets showing
the effectiveness of L2 F .
The rest of the paper is organized as follows. After a brief
review of the related work in Section 2, we present the proposed L2 F model in Section 3, and analyze its generalization
performance in Section 4. Section 5 shows the experimental
results on various datasets. Finally, we conclude in Section 6.
•

I NTRODUCTION

Many real-world applications exhibit both label and feature
heterogeneities, such as text categorization, medical diagnosis,
image/video annotation, gene functionality prediction, tag recommendation. One one hand, label heterogeneity means that
each example is associated with a set of different class labels.
For example, the FIFA World Cup news about the goal-line
technology belong to both sports and technology categories;
genes may have multiple functionalities which cause them to
be associated with multiple diseases. On the other hand, feature
heterogeneity means that the data is described by features from
multiple views, or information sources. For example, news
articles can be characterized by both the text content in the web
pages, and the anchor text in the hyperlinks; proteins in given
species have features that contain diverse information such
as gene expression, protein-protein interactions, and sequence
similarity, where some features are species-speciﬁc, and the
others are cross-species.

II.

In this section, we survey the related work on heterogeneous learning from label or feature heterogeneity, such as
multi-label learning and multi-view learning.
Multi-label learning studies the problem where each example is associated with a set of labels [17]. One key issue is to
exploit correlations or dependencies among multiple labels.
According to [20], existing strategies for label correlation
exploitation can be grouped into three categories: ﬁrst-order,
second-order, and high-order approaches. First-order methods
assume that labels are independent, and multi-label learning
problem can be transformed into a number of independent
binary classiﬁcation problems, e.g., ML-kNN [21]. Secondorder approaches consider the pairwise relations between labels. Then the multi-label learning problem is transformed
into the label ranking problem which aims at properly ranking
every relevant-irrelevant label pair for each training instance,
e.g., Rank-SVM [4]. Various methods have been proposed for
high-order label correlation learning. For example, LEAD [20]

The major challenge for addressing such problems is how
to jointly model the multiple types of heterogeneity in mutually
beneﬁcial way. To address this problem, we propose a novel
graph-based framework named L2 F to leverage both label
and feature heterogeneities. In particular, L2 F accommodates
multiple relationships, such as instance-instance, label-label,
and view-view correlations. In this way, it is able to: (1) model
the label correlation by requiring that any two label-speciﬁc
classiﬁers behave similarly on the same views if the associated
This work was done when the ﬁrst author conducted the postdoctoral
research in The City College of New York.

1550-4786/14 $31.00 © 2014 IEEE
DOI 10.1109/ICDM.2014.42

R ELATED W ORK

1079

In L2 F , we model the multiple types of relationship including instance-instance, label-label, and view-view correlations
in a graph-based framework. The goal is to maximize the
smoothness consistency of the instances together with label
correlation and view consistency, and simultaneously minimize
the empirical loss on the training data. Thus, the objective is
to minimize,
J (f ) = JC (f ) + αJL (f ) + βJV (f ) + γJemp (f )
(1)
where JC , JL , JV , and Jemp correspond to instance consistency, label correlation, view consistency, and empirical loss,
respectively. The non-negative parameters α, β, and γ balance
the importance of the corresponding terms. Next we will give
a detailed setup of each loss function.

employed Bayesian network to encode the conditional dependencies of the labels as well as the feature set, with the feature
set as the common parent of all labels. The LS-ML algorithm
was proposed for multi-label learning to extract common
subspace shared among multiple labels [7]. A hypergraph
spectral learning formulation was proposed for multi-label
classiﬁcation to exploit the correlation information among
different labels using hypergraph [15]. TRAM [8] studied the
problem of transductive multi-label learning by utilizing the
information from both labeled and unlabeled data. LIFT [19]
constructed features speciﬁc to each label by conducting
clustering analysis on its positive and negative instances, and
then performed training and testing by querying the clustering
results. MAHR [6] aimed to discover the label relationship
via a boosting approach with a hypothesis reuse mechanism.
A generic empirical risk minimization (ERM) framework was
proposed for large-scale multi-label learning [18].

(C)

=
Instance Consistency on the Graph: Let Gj
{Vj , Ej } be the graph for the instances in the j th view, where
Vj is the set of instances, and Ej is the set of edges. For
(j)
(j)
an edge e ∈ Ej connecting the instance pair (xi , xk ),
its weight is determined by the similarity between the two
(j)
(j)
instances denoted by k(xi , xk )(1 ≤ i, k ≤ n), which can
be estimated using the instance-feature correlation in various
ways (e.g., we use Gaussian RBF function). Let Wj ∈ Rn×n
(C)
be the afﬁnity matrix for the instance-instance graph Gj
(j)
(j)
whose (i, k) element is k(xi , xk ). Deﬁne the Laplace matrix
− 12
− 12
Lj = D (D −Wj )D
where D is a diagonal matrix with
n
element Dii = k=1 Wj (i, k).

Multi-view learning has been studied extensively in the
literature. Co-training [1] is one of the earliest multi-view
learning algorithm. SVM-2K [5] combined KCCA with SVM
in an optimization framework. CoMR [13] was proposed for
multi-view learning, which was based on a Reproducing Kernel
Hilbert Space (RKHS) with a data-dependent co-regularization
norm. MMH [2] was a large-margin learning framework for
discovering a predictive latent subspace representation shared
by multiple views. An information-theoretic framework [14]
was proposed for multi-view learning, which showed that
minimizing the incompatibility over unlabeled data helped
reduce expected loss on the test data. The PAC generalization
bound [3] was provided for co-training, which upper-bounded
the error of classiﬁers learned from two views.
III.

Intuitively, similar instances should have similar predictions. Following the random walk model [23], we model the
instance consistency as follows,
 m V
T
fij
Lj fij = f T QC f
(2)
JC (f ) =

T HE P ROPOSED L2 F M ODEL

i=1

j=1

In this section, we will introduce the proposed L2 F model.
The basic idea of L2 F is to encode the label correlation and
view consistency in a graph-based framework.

where QC is a block diagonal matrix with its entry [QC ]ij,ij =
Lj for 1 ≤ i ≤ m, 1 ≤ j ≤ V . Since the Laplace matrix Lj
is positive semi-deﬁnite, QC is also positive semi-deﬁnite.

Let n, m denote the number of examples and labels, respectively. Let X be an example space, and L = {L1 , L2 , · · · , Lm }
be a ﬁnite set of class labels. An example x ∈ X is described
from V views, i.e., x = {x(j) |1 ≤ j ≤ V } where x(j) is
the instance in j th view, which is a feature vector. For the
j th (1 ≤ j ≤ V ) view, the feature dimension is denoted
by dj . Each example x is associated with a subset of labels
L(x) ∈ 2L , which is the set of relevant labels of x. In practice,
the relevant labels L(x) can be denoted by a binary label
vector Y (x) = [Y1 (x), Y2 (x), · · · , Ym (x)] where Yi (x) = 1
if Li ∈ L(x), Yi (x) = −1 otherwise for 1 ≤ i ≤ m. Let
Y = {1, −1}m be the set of all such possible labelings.

Label Correlation: Let G(L) = {V, E} be the graph for
the labels, where V = L is the set of labels, and E is the set of
edges. For an edge e ∈ E connecting the label pair (Li , Lk ),
its weight is determined by the similarity between the two
labels denoted by k(Li , Lk )(1 ≤ i, k ≤ m), which can be
estimated using the example-label correlation in various ways.
Let S ∈ Rm×m be the afﬁnity matrix for the label-label graph
G(L) whose (i, k) element is k(Li , 
Lk ). The degree of a label
m
Li (1 ≤ i ≤ m) is deﬁned as di = j=1 Sij .
Based on the graph G(L) , we model the label correlations
by requiring that any two label-speciﬁc classiﬁers behave
similarly on the same views if the associated labels are similar.
In speciﬁc, if two labels Li and Lk are similar, the labelspeciﬁc classiﬁers fij and fkj should keep close to each other
on the same j th view. Therefore, we model the correlation
among multiple labels as follows,

Given a data set D = {(x, Y (x))|x ∈ X , Y (x) ∈ Y},
consisting of nl labeled examples and nu unlabeled examples
which are i.i.d drawn from some unknown distribution P, our
goal is to build a multi-label classiﬁer h : X → Y as accurately
as possible. Without loss of generality, assume that the labels
of the ﬁrst nl examples are known. For the compactness of
representation, we denote the ith (1 ≤ i ≤ m) label vector
of all the examples by yi = [Yi (x1 ), Yi (x2 ), · · · , Yi (xn )]T ∈
Rn×1 . Let fij ∈ Rn×1 be the prediction vector of all the
examples for the ith (1 ≤ i ≤ m) label and the j th (1 ≤ j ≤
 T
T
T
T
T
V ) view. Denote f = f11
, · · · , f1V
, · · · , fm1
, · · · , fmV
∈
RnmV ×1 . Let AF be the Frobenius norm for the matrix A.

JL (f ) =

V
j=1


2
 fij
fkj 
 = f T QL f
√
√
Sik 
−
 d
i,k=1
dk  F
i

m

(3)

where QL is a block matrix with its entry,

2 (1 − Sik /di√
) In×n , i = k
[QL ]ij,kj =
−2Sik In×n / di dk , i = k
for 1 ≤ i, k ≤ m, 1 ≤ j ≤ V . Since f T QL f ≥ 0, QL is
positive semi-deﬁnite.
1080

View Consistency: In order to maximize the view consistency, we require that for any view pairs, the difference of
predictions resulting from their view-based classiﬁers should
keep small as much as possible. Hence, we model the consistency among multiple views as follows,
JV (f ) =

m V
i=1

j,k=1

fij − fik 2F = f T QV f

By setting the ﬁrst-order derivative of the above equation
with respect to fij (1 ≤ i ≤ m, 1 ≤ j ≤ V ) to zero, we obtain
the analytical solution as follows
−1
∗
fij
= Hij
pij
(7)
	 



where Hij = 2Lj + 4α 1 − Sdiii + 4β (V − 1) + 2γ In×n
m
V
and pij = 4α k=1,k=i √Sdikd fkj + 4β k=1,k=j fik + 2γyi .

(4)

where QV is a block matrix
with its entry,

2 (V − 1) In×n , j = k
[QV ]ij,ik =
−2I
,
j = k

i k

Prediction: For the test example, the ﬁnal prediction
is the expectation of predictions resulting from view-based
classiﬁers. For the example x, the prediction for its ith label
is as follows



n×n

for 1 ≤ i ≤ m, 1 ≤ j, k ≤ V . Since f T QV f ≥ 0, QV is
positive semi-deﬁnite.

hi (x) = sgn

Empirical Loss: Various empirical loss functions, such as
hinge loss, least square loss, logistic loss, and etc., can be used
to measure the consistency with known label information.

(8)

The following theorems show the convergence property and
algorithm complexity of the proposed method.

Overall Objective: In summary, the overall goal is to
minimize the following objective function:
J (f ) = JC (f ) + αJL (f ) + βJV (f ) + γJemp (f )
= f T Qf + γJemp (f )

1 V
∗
fij
(x)
j=1
V

Theorem 3.2 (Convergence): The L2 F method converges
to the global optimum.

(5)

Theorem 3.3 (Time Complexity): The time complexity of
the L2 F method is O(niter V mnc )(2.373 ≤ c ≤ 3)) where
niter is the iteration of the algorthm.

A nice property of the proposed mothed is that its objective
function is joint convex as shown in the following theorem.
Due to space limitation, we omit the proofs for all the
theorems, which will be given in a long version of this paper.

Theorem 3.4 (Space Complexity): The space complexity
of the L2 F method is O(V n2 + m2 ).
IV. T HEORETIC A NALYSIS

Theorem 3.1 (Optimality): When using convex empirical
loss, the objective in Eq. 5 is convex with respect to f .

In this section, we analyze the generalization performance
of the proposed framework, which shows the beneﬁts of
simultaneously modeling label and feature heterogeneity. To be
speciﬁc, we will demonstrate that the upper bound of empirical
Rademacher complexity together with the error bound of the
proposed L2 F model can be reduced by incorporating the label
correlation and enhancing the view consistency.

where Q = QC + αQL + βQV .

When using least square loss as empirical loss function,
the objective function in Eq. 5 can be solved analytically. For
the least square loss, we have
 m V
2
Jemp (f ) =
fij − yi F = f T Qemp f −2f T p+q
i=1

j=1

where Qemp is block diagonal matrix with its entry
[Qemp ]ij,ij = In×n , p is a block vector with its entry
[p]ij = yi , and q is a constant block vector with its entry
[q]ij = yiT yi · 1n×1 for 1 ≤ i ≤ m, 1 ≤ j ≤ V . Obviously,
Qemp is positive semi-deﬁnite. Then, the objective function in
Eq. 5 can be rewritten into
J (f ) = JC (f ) + αJL (f ) + βJV (f ) + γJemp (f )
= f T QA f − 2γf T p + γq

Let H be the space of functions with the norm deﬁned
as f 2H = f T QC f . Based on H, we deﬁne H̃ to be
the space of functions with the norm f 2H̃ = f 2H +
αf T QL f + βf T QV f = f T Qf . Suppose that QC , QL , QV , Q
are invertible 1 . The following theorem will show that both H
and H̃ are RKHS.
Theorem 4.1 (RKHS): Both H and H̃ are RKHS with
= Q−1 =
kernel matrix K = Q−1
C , and K̃
−1
[QC + αQL + βQV ] , respectively.

(6)

where QA = QC + αQL + βQV + γQemp . Obviously, QA
is positive semi-deﬁnite. By taking derivative of Eq. 6 with
respect to f , we have ∇f J (f ) = 0 ⇒ f ∗ = γQ−1
A p.

Hence, based on Theorem 4.1, the overall objective in Eq. 5
can be reduced to standard supervised learning problem:

Optimization using block coordinate descent: Since
QA ∈ RnmV ×nmV
 , the space complexity of the above method
is O n2 m2 V 2 . To reduce the space complexity, we resort
to block coordinate descent (BCD) method [10], [16] to
iteratively solve the optimization problem. We ﬁrst rewrite the
objective in Eq. 6 as follows

Let F := {f ∈ H̃ : f  ≤ r} denote the ball of radius r in
H̃. According to Theorem 4.12 in [12], we can easily obtain
the following theorem regarding the Rademacher complexity
of the proposed method.

J (f ) = JC (f ) + αJL (f ) + βJV (f 
) + γJemp (f )
V
m
m 
V
T



fij
fij
2f T f
T
=
fij Lj fij + α
Sik
− √ij kj +
di
i=1 j=1
m


+β
+γ

j=1 i,k=1

V

 T

T
T
fik + fik
fik
fij fij − 2fij

i=1 j,k=1
V 
m 

i=1 j=1

T
T
fij − 2fij
yi + yiT yi
fij

d i dk

T
fkj
fkj
dk



2

f ∗ = arg minf ∈H̃ f H̃ + γJemp (f )

(9)

Theorem 4.2 (Rademacher complexity): The
empirical
Rademacher complexity of the proposed L2 F method is
upper bounded by:

 


2r
−1
tr [QC + αQL + βQV ]
(10)
R̂ (F) ≤
nmV



1 Otherwise, a pratical approach is to add a small regularization term λI(λ ≥
0) to it.

1081

Note that α and β balance the importance of label correlation and view consistency in the overall objective, respectively.
For simplicity, let R̂ (FC ) and R̂ (FCL ) be the empirical
Rademacher complexities corresponding to α = β = 0, and
β = 0 in Eq. 10, respectively.

The Diabetes dataset was obtained from a big biomedical company. This dataset is a collection of symptom and
treatment information regarding diabetes patients. Each patient
may receive multiple treatments. The data are described with
two views of features measuring the long (e.g., average past
3 month blood glucose) and short (e.g., current fasting blood
glucose) term drug impact, respectively.
B. Performance Evaluation

Theorem 4.3 (Rademacher Complexity Reduction): For
the proposed L2 F method, the upper bound of empirical
Rademacher complexity can be reduced by incorporating the
label correlation and enhancing view consistency, i.e.,
R̂ (F) ≤ R̂ (FCL ) ≤ R̂ (FC )

The proposed L2 F method is compared with a variety of
typical multi-label learning algorithms including: 1) ﬁrst-order
approach ML-kNN [21]; 2) feature-based approach LIFT [19];
3) subspace learning approach LS-ML [7]; 4) transductive
learning approach TRAM [8]. The L2 F method is given the
multi-view data, whereas the other methods are given the
concatenated features from all the views. The parameters are
tuned for each algorithm using cross-validation on the training
data. We repeat the experiments ten times for each dataset and
report the average performance.

(11)

Note that QL encodes the correlation among multiple
labels, while QV encodes the consistency among multiple
views. From Theorem 4.3, we can see that the Rademacher complexity of the proposed L2 F method decreases by
incorporting the label correlation and view consistency into
the overall objective as deﬁned in Eq. 5. An application of
Theorem 4.9 in [12] together with Theorem 4.2 show that:

We use the F1 -score (harmonic mean of precision and
recall) [22] on the test data as the evaluation metric, which
is deﬁned as follows:
1 nl +nu 2 |L(xk ) ∩ Z(xk )|
F1 =
k=nl +1 |L(xk )| + |Z(xk )|
nu
where Z(x) = {Li |hi (x) = 1, 1 ≤ i ≤ m} is the predicted
label set for example x. Note that larger value of F1 -score are
indicating better performance.

Theorem 4.4 (Error Bound): With probability at least 1 −
δ(0 ≤ δ ≤ 1), the generalization error of prediction function
f is upper-bounded as follows:

ln (2/δ)
2r 
(12)
tr (Q−1 )+3
ED [f (x)] ≤ Jemp (f )+
nmV
2nmV
Theorem 4.4 suggests that the error bound of our proposed
method can be improved due to the reduction of Rademacher
complexity.
V.

Figure 1 shows the results on Medical dataset. Figures 2-6
show the results on different subset of Reuters Corpus Volume
(RCV) datasets, respectively. The results on Diabetes dataset
are shown in Figure 7. In each ﬁgure, x-axis represents the
ratio which is used to randomly sample a subset of instances
from the training data, and y-axis denotes the F1 -score. First
of all, a common trend observed from these ﬁgures is that
the performance of all the algorithms usually perform better
when the ratio increases. It is reasonable because more training
instances help build a robust classifer.

E XPERIMENTS

In this section, we aim to empiricallly verify the effectiveness of the proposed algorithm comparing with a variety of
state-of-the-art approaches.
A. Datasets and Setup
We use various multi-label datasets to test the performance
of our proposed algorithm. Table I shows the properties of
different datasets. Label cardinality is the average number
of labels per instance. Accordingly, label density normalizes
label cardinality by the the number of labels. Label diversity
is the number of distinct label combinations observed in the
dataset [22].

The results show that L2 F performs better than the other
algorithms in most cases. ML-kNN [21] performs worst among
all the algorithms. This is likely due to the fact that MLkNN is a ﬁrst-order approach which ignores the correlation
among multiple labels. In constract, all the other algorithms
usually perform better than ML-kNN by leverging the label
correlations. In principle, the classiﬁers induction process of
LIFT [19] is similar to ML-kNN. But LIFT improves upon
ML-kNN by building the classiﬁer on each label with labelspeciﬁc features instead of the original ones. LS-ML [7] learns
a common subspace shared among multiple labels, which
helps improve the learning performance for the multi-label
data. However, since its objective function is non-convex,
the performance of LS-ML would be limited by the local
optimum problem. Different from other approaches, TRAM [8]
is a tranductive multi-label learning method which tries to
exploit the information from both labeled and unlabeled data.
They formulate the transductive multilabel classiﬁcation as an
optimization problem of estimating label concept compositions. The results show that unlabeled data can provide helpful
information to build the multi-label classiﬁer.

The ﬁrst dataset is the Medical dataset [11]. The Computational Medical Center organized Medical NLP Challenge 2
with a rich set of medical text corpus. This dataset is actually a collection of patient symptom histories, diagnosis and
prognoses reported to the insurance companies. The second
dataset is the Reuters Corpus Volume I (RCV I) dataset [9],
which is a collection of over 800,000 newswire stories. The
news are organized into the hierarchical structures. It is usually
common to use ﬁve subsets of this data, each containing 6000
data instances on average and with a total number of 101 class
labels. The above two datasets are available online 3 . We create
the multi-view data as follows. For each dataset, the instances
are described from two views: one corresponds to the TF-IDF
features; another view corresponds to the latent topics obtained
by applying probabilistic latent semantic analysis on the term
counts, where the number of latent topics is set to 100.

In comparison with the other methods, the key advantage
of L2 F is that it models both label and feature heterogeneities

2 http://www.computationalmedicine.org/challenge/index.php
3 http://mulan.sourceforge.net/datasets.html

1082

TABLE I: Statistics of Different Datasets.
Instances (Testing)
978 (645)
6000 (3000)
6000 (3000)
6000 (3000)
6000 (3000)
6000 (3000)
8812 (2644)

Features
1449
47236
47236
47229
47236
47235
16

Labels
45
101
101
101
101
101
30

Cardinality
1.245
2.880
2.634
2.614
2.484
2.642
1.290

Density
0.028
0.029
0.026
0.026
0.025
0.026
0.043

Diversity
94
1028
954
939
816
946
45

/,)7

/6í0/



75$0

/ )



)íVFRUH

Dataset
Medical
RCV1
RCV2
RCV3
RCV4
RCV5
Diabetis

0/íN11









in a principled framework. First, by leveraging the consistency among multiple views, the view-based classiﬁers can
mutually improve each other. On the contrary, all the other
comparison methods do not consider the view consistency,
simply concatenating features from different views cannot gain
much additional improvement. Second, by considering the
correlation among multiple labels, the performance of labelspeciﬁc classiﬁers in L2 F can beneﬁt from each other. In
the next subsection, we will also show how the performances
of L2 F vary with the trade-off parameters, α and β, which
control the weight of label correlation and view consistency,
respectively. Another competency of L2 F is that it is capable
of ﬁnding the global optimum due to the joint convexity of
the objective function.
0/íN11

/,)7

/6í0/







5DWLR









Fig. 4: F1 -score varies with ratio on RCV 3 dataset.
0/íN11

/,)7

/6í0/



75$0

/ )



)íVFRUH
















5DWLR









Fig. 5: F1 -score varies with ratio on RCV 4 dataset.



75$0



/ )


0/íN11












/,)7

/6í0/



75$0

/ )





)íVFRUH

)íVFRUH











5DWLR












Fig. 1: F1 -score varies with ratio on Medical dataset.
0/íN11

/,)7

/6í0/










5DWLR









Fig. 6: F1 -score varies with ratio on RCV 5 dataset.



75$0



/ )








/,)7

/6í0/

/)

75$0





)íVFRUH

)íVFRUH

0/íN11













5DWLR







/,)7






Fig. 2: F1 -score varies with ratio on RCV 1 dataset.
0/íN11



/6í0/










5DWLR







Fig. 7: F1 -score varies with ratio on Diabetes dataset.



75$0



/ )



)íVFRUH
















5DWLR









Fig. 3: F1 -score varies with ratio on RCV 2 dataset.

In addition, we have a few different observations on the
Diabetes dataset. The performance of three algorithms, i.e.,
ML-kNN, LS-ML, and LIFT, are poor, indicating that this
is a more challenging task. In constrast, both TRAM and
L2 F perform better, and their results are comparable on this
dataset. This might due to the fact both TRAM and L2 F take
advantage of the unlabeled data information. TRAM utilizes
the unlabeled data in a tranductive way, while L2 F leverges
the smoothness consistency among the nearest instances.

1083





)íVFRUH

)íVFRUH













ACKNOWLEDGMENT















α






















β











This material is partially supported by the National
Science Foundation under Grant No. IIS1017415, by the
Army Research Laboratory under Cooperative Agreement No. W911NF-09-2-0053, by DARPA under Contract No.
W911NF-11-C-0200 and W911NF-12-C-0028, by Region II
University Transportation Center under the project No. 4999733 25, and by NSFC under Grant No. 61473123.

Fig. 8: F1 -score varies with α and β (log2 scale).



[2]



)íVFRUH

)íVFRUH

[1]









[3]





[4]







R EFERENCES











γ






























,WHUDWLRQ

     

[5]

Fig. 9: F1 -score varies with γ (log2 scale) and iteration.
[6]

C. Parameter Sensitivity and Convergence
We study the parameter sensitivity on the Medical dataset.
α and β are used to balance the importance of label correlation
and view consistency, respectively. We tune α and β on the
grid 2[−4:1:4] . Figure 8 shows the results. Comparing with
α = 0, the algorithm performs better when α increases, and the
best case occurs when α = 1, which indicates that modeling
label correlation could signiﬁcantly improve the multi-label
learning performance. However, if α is very large such as
α = 16, the label correlation part will dominate the entire
objective function, making the model hard to keep certain level
of accuracy. Nevertheless, the performance is robust over a
wide range of values for α. In Figure 8, we observe a similar
trend for β, which suggests that the learner could beneﬁt from
enhancing the consistency among multiple views. γ is used to
control the weight of empirical loss. We tune γ on the grid
2[−4:1:4] . The result is shown in the left panel of Figure 9. As
expected, the performance is poor when γ = 0, and the F1 score ﬁrst increases and then decreases when γ is increased. As
a result, we tune the parameters on each dataset using standard
cross-validation.
We empirically study the convergence property of L2 F
algorithm on the Medical dataset. The result is shown in the
right panel of Figure 9. From this ﬁgure, we can see that L2 F
converges fast and its performance becomes stable after 10
iterations.
VI. C ONCLUSION AND F UTURE W ORK
2

In this paper, we propose a graph-based approach L F
for learning from both label and feature heterogeneities. An
iterative algorithm is presented to solve the convex problem,
which is guaranteed to converge to the global optimum. We
analyze its performance in terms of its generalization error rate.
Both the theoretic analysis and the comparison experiments
with state-of-the-art methods demonstrate the effectiveness of
the proposed method. One of our on-going work is to extend
the proposed framework to the transductive setting. Due to
its label and feature heterogeneity, transductive learning is
particularly challenging in this situation.

[7]
[8]

[9]

[10]

[11]

[12]
[13]
[14]
[15]
[16]

[17]

[18]
[19]
[20]
[21]
[22]

[23]

1084

A. Blum and T. Mitchell. Combining labeled and unlabeled data with
co-training. In COLT, pages 92–100, 1998.
N. Chen, J. Zhu, and E. P. Xing. Predictive subspace learning for
multi-view data: a large margin approach. In NIPS, 2010.
S. Dasgupta, M. L. Littman, and D. A. McAllester. Pac generalization
bounds for co-training. In NIPS, pages 375–382, 2001.
A. Elisseeff and J. Weston. A kernel method for multi-labelled
classiﬁcation. In NIPS, pages 681–687, 2001.
J. D. R. Farquhar, D. R. Hardoon, H. Meng, J. Shawe-Taylor, and
S. Szedmák. Two view learning: Svm-2k, theory and practice. In NIPS,
2005.
S.-J. Huang, Y. Yu, and Z.-H. Zhou. Multi-label hypothesis reuse. In
KDD, pages 525–533, 2012.
S. Ji, L. Tang, S. Yu, and J. Ye. Extracting shared subspace for multilabel classiﬁcation. In KDD, pages 381–389, 2008.
X. Kong, M. K. Ng, and Z.-H. Zhou. Transductive multilabel learning
via label set propagation. IEEE Trans. Knowl. Data Eng. (TKDE), pages
704–719, 2013.
D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. Rcv1: A new benchmark
collection for text categorization research. Journal of Machine Learning
Research (JMLR), 5:361–397, 2004.
Z. Q. Luo and P. Tseng. On the convergence of the coordinate descent
method for convex differentiable minimization. Journal of Optimization
Theory and Applications, 72(1):7–35, 1992.
J. P. Pestian, C. Brew, P. Matykiewicz, D. J. Hovermale, N. Johnson,
K. B. Cohen, and W. Duch. A shared task involving multi-label
classiﬁcation of clinical free text. In Proceedings of the Workshop on
BioNLP, pages 97–104, 2007.
J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern
Analysis. Cambridge University Press, 2004.
V. Sindhwani and D. S. Rosenberg. An rkhs for multi-view learning
and manifold co-regularization. In ICML, pages 976–983, 2008.
K. Sridharan and S. M. Kakade. An information theoretic framework
for multi-view learning. In COLT, pages 403–414, 2008.
L. Sun, S. Ji, and J. Ye. Hypergraph spectral learning for multi-label
classiﬁcation. In KDD, pages 668–676, 2008.
P. Tseng. Convergence of a block coordinate descent method for
nondifferentiable minimization. Journal of Optimization Theory and
Applications, 109(3):475–494, 2001.
G. Tsoumakas and I. Katakis. Multi-label classiﬁcation: An overview.
International Journal of Data Warehousing and Mining, 3(3):1–13,
2007.
H.-F. Yu, P. Jain, P. Kar, and I. S. Dhillon. Large-scale multi-label
learning with missing labels. In ICML, pages 593–601, 2014.
M.-L. Zhang. Lift: Multi-label learning with label-speciﬁc features. In
IJCAI, pages 1609–1614, 2011.
M.-L. Zhang and K. Zhang. Multi-label learning by exploiting label
dependency. In KDD, pages 999–1008, 2010.
M.-L. Zhang and Z.-H. Zhou. Ml-knn: A lazy learning approach to
multi-label learning. Pattern Recognition, pages 2038–2048, 2007.
M.-L. Zhang and Z.-H. Zhou. A review on multi-label learning
algorithms. IEEE Transactions on Knowledge and Data Engineering,
26(8):1819–1837, 2014.
D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Schölkopf. Learning
with local and global consistency. In NIPS, 2004.

2008 Eighth IEEE International Conference on Data Mining

Graph-based Rare Category Detection
Jingrui He
Carnegie Mellon University
jingruih@cs.cmu.edu

Yan Liu
IBM T.J. Watson Research
liuya@us.ibm.com

Abstract

in network intrusion detection, systematically finding new
malicious network activities among huge volume of routine network traffic is a critical unmet challenge [16]; in
astronomy where most objects in sky survey images are explainable by current science, detection of useful anomalies
may lead to new discoveries [12]; in image spam detection,
identifying the small number of near-duplicate spam images
greatly improves the performance of email spam filters [14].

Rare category detection is the task of identifying examples from rare classes in an unlabeled data set. It is an
open challenge in machine learning and plays key roles
in real applications such as financial fraud detection, network intrusion detection, astronomy, spam image detection,
etc. In this paper, we develop a new graph-based method
for rare category detection named GRADE. It makes use
of the global similarity matrix motivated by the manifold
ranking algorithm, which results in more compact clusters
for the minority classes; by selecting examples from the regions where probability density changes the most, it relaxes
the assumption that the majority classes and the minority
classes are separable. Furthermore, when detailed information about the data set is not available, we develop a
modified version of GRADE named GRADE-LI, which only
needs an upper bound on the proportion of each minority
class as input. Besides working with data with structured
features, both GRADE and GRADE-LI can also work with
graph data, which can not be handled by existing rare category detection methods. Experimental results on both synthetic and real data sets demonstrate the effectiveness of the
GRADE and GRADE-LI algorithms.

The most straightforward method for rare category detection is random sampling, i.e. randomly selecting examples to be labeled by the oracle. However, if the data
set is skewed, random sampling is extremely inefficient at
discovering all the classes in the data set, especially rare
classes. Therefore, we need more sophisticated methods
for rare category detection. Up until now, only a few methods have been proposed to address this challenge. For
example, the method based on mixture models proposed
in [12] is among the first attempts in this direction. In [4],
the authors proposed a generic consistency algorithm, and
proved upper bounds and lower bounds for this algorithm
in some specific situations. More recently, in [7], the authors proposed NNDB and NNDM algorithms for rare category detection, which essentially perform local-densitydifferential-sampling. Furthermore, in [8], the authors generalized the theoretical results for the binary case in [7] to
cases with multiple minority classes.

1. Introduction
Traditional supervised learning methods require labeled
examples from each class to construct classifiers, which are
able to predict the class labels of future unseen examples.
This problem has been well studied over the years, for both
balanced data sets [11], and imbalanced ones [9] [13] [15].
However, in real applications, it is often the case that at the
beginning, we do not have any labeled examples from all the
classes, especially those rare categories, or minority classes,
which have only a few examples in the data set. It is of great
importance to identify the rare categories with a few label
requests, i.e. to propose initial candidates of each class to
the labeling oracle, which can provide us with the class label
of any example with a fixed cost.
Rare category detection has a lot of applications. For example, in financial fraud detection where only a small number of transactions are fraudulent, detecting early instances
of the fraud patterns helps us stop such illicit activity [2];
1550-4786/08 $25.00 © 2008 IEEE
DOI 10.1109/ICDM.2008.122

Richard Lawrence
IBM T.J. Watson Research
ricklawr@us.ibm.com

In this paper, we propose a new method for rare category detection: Graph-based Rare Category Detection
(GRADE). The basic idea is to utilize the global similarity
matrix and get more compact clusters for the examples from
the minority classes, which is motivated by the manifold
ranking algorithm [18] and the consistency method [17].
This results in sharper changes in local density near the
boundaries of minority classes and thus makes it easier
to discover those classes. Furthermore, we improve the
GRADE algorithm to get the GRADE-LI algorithm that requires less information, and therefore is more suitable for
real applications. Compared with the methods proposed
in [12] and [4], our algorithms do not depend on the assumption that the majority classes and the minority classes
are separable; compared with the methods proposed in [7]
833

and [8], the GRADE-LI algorithm requires less information
about the data set, and yet can achieve better performance
in most cases. Furthermore, our algorithms can handle both
data with structured feature representation and graph data,
whereas existing rare category detection methods can only
work on structured data.
The rest of the paper is organized as follows. In Section 2, we describe the GRADE algorithm for rare category
detection and analyze its effectiveness. The improved algorithm GRADE-LI is presented in Section 3. In Section 4, we
show some experimental results of GRADE and GRADELI compared with existing methods. Finally, we conclude
the paper in Section 5.

to label the example with the largest score. To be specific,
for each class c, if we have not found any example from this
class, we set the score of xi to be the maximum difference
of nci and that of the neighboring points with similarity bigc
ger than or equal to at , where t is the iteration index. By
querying the label of the example with the largest score, we
are able to focus on the regions where the underlying density changes the most. If this example is not from class c,
we increase t by 1 and repeat; otherwise, we proceed to the
next class. Notice that for a labeled example, any unlabeled
example with global similarity bigger than or equal to the
class specific similarity will not be selected in the future.

2. GRADE Algorithm

2.3.1 Global similarity matrix
∀c = 1, . . . , m, let S c be the subset of S that consists of
all the examples from class c, which are denoted S c =
{xc1 , . . . , xcK c } ⊂ S. Let W c be the associated pair-wise
similarity matrix, K c × Kc , whose elements are defined as
in Equation (1). Notice that by setting σ to be the smallest distance to the K th nearest neighbor, we guarantee that
for any example from a minority class, its pair-wise similarity with at least another example from the same minority
class is reasonably large. Next,
define the diagonal matrix
nc
c
c
=
Dc , K c × K c , where Dii
j=1 Wij . Finally define
c
c −1/2
the normalized matrix W = (D )
W c (Dc )−1/2 . Noc
tice that W is positive semi-definite, so its eigen-values
are non-negative, which are denoted λ c1 ≥ λc2 ≥ . . . ≥
λcK c ≥ 0, and the corresponding eigen-vectors are denoted uc1 , . . . , ucK c , s.t. uci  = 1, i = 1, . . . , K c . Furthermore, the largest eigen-value λ c1 is 1, with eigen-vector
uc1 ∝ (Dc )1/2 1K c ×1 , where 1K c ×1 is a vector of 1s. With
respect to uc1 , we have the following lemma.

2.3

In this section, we introduce the GRADE algorithm for
data with feature representation and discuss its application
to graph data.

2.1

Notation

Given a set of n unlabeled examples S = {x 1 , . . . , xn },
xi ∈ Rd , which come from m distinct classes, i.e. y i ∈
{1, . . . , m}, our goal is to find at least one example from
each class by requesting as few label requests as possible.
For simplicity, we assume that there is only one majority
class, which corresponds to y i = 1, and all the other classes
are minority classes. Let p c denote the prior of the c th class,
c = 1, . . . , m. Notice that the prior p 1 of the majority class
is much larger than the prior of any minority class p c , c =
2, . . . , m.

2.2

Algorithm

The GRADE algorithm for examples with observed features is described in Algorithm 1. Here α is the model parameter with positive values (which is usually very close
to 1). It works as follows. First of all, we calculate the
maximum number of examples K in each minority class.
Then using this number, we pick the parameter σ, which
is the smallest distance to the K th nearest neighbor. Next,
we construct the pair-wise similarity matrix W  , whose elements are calculated using the Gaussian kernel. In Step 4,
we construct the diagonal matrix D, whose elements are the
row sums of W  . Next, we calculate the normalized matrix
W and the global similarity matrix A. The specific form
of the global similarity matrix has been used in the manifold ranking algorithm [18] for ranking data with respect
to a query point and the consistency method [17] for semisupervised learning. The following steps are based on the
similarity measure in A. For each class c, we calculate the
number of examples K c from this class, and find the largest
global similarity to the (K c )th nearest neighbor, which is
the class specific similarity ac . Then, for each example x i ,
we find all of its neighbors with global similarity larger than
or equal to a c , which is referred to as N N (x i , ac ). Let nci
be the number of examples in this set. In Step 12 to Step 19,
we calculate the score for each example and ask the oracle

Justiﬁcation

Lemma 1 If σ changes with the number of examples n such
that limn→∞ σ = 0 and limn→∞ n(σ)d = ∞, then as n
goes to infinity, ∀c = 1, . . . , m, u c1 · (uc1 )T converges in
probability to C c U c , where C c is a constant, U c is a K c ×
K c matrix, its elements at the ith row and j th column Uijc =

f c (xci ) × f c (xcj ), and f c (xci ) is the probability density
function of class c at xci .
If we knew the class labels of all the examples in S, we
can group the examples from the same class, and put the
examples from the majority class at the end. To start with,
suppose that if xi and xj are from different classes, W ij =
0. Then the normalized matrix W is block-diagonal, i.e.
W = diag(W 2 , . . . , W m−1 , W 1 ). Therefore A = (In×n −
αW )−1 is also block-diagonal, and it satisfies the following
lemma.
Lemma 2 If xi and xj both belong to class c, A ij =
K c
1
c
c
k=1 1−αλc uk (i)uk (j); otherwise, Aij = 0.
k

If α is very close to 1, A can be approximated as follows.
1
If xi and xj both belong to class c, A ij ≈ 1−α
uc1 (i)uc1 (j).

834

Compared with the pair-wise similarity matrix W  , the
global similarity matrix A is better suited for rare category
detection. This is because if the minority class has a manifold structure, two examples on this manifold may be far
away from each other in terms of Euclidean distance, so
their pair-wise similarity is very small; whereas their global
similarity is large since it is roughly in proportion to the
density of the minority class at both points. Fig.1a shows
an example where the majority class (blue dots) has a uniform distribution, and the minority class (red ‘x’s) forms
a 1-dimensional manifold. The black dots at both ends of
the manifold have a small pair-wise similarity. However, in
terms of the global similarity, they are quite similar, which
matches our intuition. Furthermore, if we take the global
similarity matrix as the pair-wise similarity matrix, and map
all the points to the original feature space while preserving the pair-wise similarity, the examples from the minority classes tend to form more compact clusters compared
with the original feature representation (Fig.1b), whereas
the probability density function of the majority class is still
quite smooth, which makes the following querying process
more effective. This is particularly beneficial if the manifold structures of the minority classes are elongated, as
shown in Fig.1a.

Algorithm 1 Graph-based Rare Category Detection
(GRADE)
Input: Unlabeled data set S, p 1 , . . . , pm , α
Output: The set I of selected examples and the set L of
their labels
c
1: Let K = maxm
c=2 n × p .
2: For each example, calculate the distance between this
example and its K th nearest neighbor. Set σ to be the
minimum value of all such distances.
3: Construct the pair-wise similarity matrix W  , n × n,
where n is the number of examples, and ∀i, j =
1, . . . , n,
xi − xj 2
Wij = exp(−
)I(i 
= j)
(1)
2σ 2
4:
5:
6:
7:
8:
9:
10:

11:
12:
13:
14:
15:

where I(·) is the indicator function.
Construct the diagonal matrix D, n × n, where D ii =

n

j=1 Wij , i = 1, . . . , n.
Calculate the normalized matrix W
=
D−1/2 W  D−1/2 .
Calculate the global similarity matrix A = (I n×n −
αW )−1 , where In×n is an n × n identity matrix.
for c = 2 : m do
Let K c = npc .
For each row of A, find the (K c )th largest element.
Set ac to be the largest value of all such elements.
∀xi ∈ S, let N N (xi , ac ) = {x|x ∈ S, A(x, xi ) ≥
ac }, and nci = |N N (xi , ac )|, where A(x, xi ) is the
corresponding element in A.
end for
for c = 2 : m do
If class c has been discovered, continue.
for t = 2 : n do
For each xi that has been labeled y i , ∀xj ∈ S,
if A(xi , xj ) ≥ ayi , sj = −∞; for all the other
max c (nci − ncj ).
examples, si =

2

2

1.5

1.5

1

1

0.5

0.5

0

0

−0.5

−0.5

−1

−1

−1.5

−1.5

−2
−2

−1

0

1

2

−2
−2

−1

0

1

2

(a) Original feature space (b) Mapped feature space

Figure 1. Synthetic data set. Blue dots: majority class; red ‘x’s: minority class.

xj ∈N N (xi , at )

2.3.2 Querying process
Step 7 to Step 19 select examples to be labeled by the oracle. According to our previous discussion, if we reconstruct
the features according to the global similarity matrix, the
minority classes will form compact clusters and the probability density function of the majority class will be locally
smooth. Generally speaking, the querying process selects
the examples from regions where the local density changes
the most, and therefore has a high probability of hitting the
minority classes. To be specific, as discussed before, if two
examples are both from a minority class, their global similarity tends to be much larger than that if they are both
from the majority class. So the class specific similarity a c is
likely to be determined by the examples from the minority
classes. Furthermore, as n goes to infinity, A ij is roughly in
proportion to the density of class c at x i and xj if they both
belong to minority class c. Therefore, if f c (xi ) is large, the
global similarity between x i and the other examples from

Select and query the label of x = arg max xi ∈S si .
If the label of x is equal to c, break; otherwise,
mark the class that x belongs to as discovered.
18:
end for
19: end for
16:
17:

According to Lemma
1, as n goes to infinity, A ij converges
Cc
in probability to 1−α
f c (xi )f c (xj ).
Notice that uci = 1, c = 1, . . . , m, i = 1, . . . , K c .
In general, the absolute value of the elements of u c1 for minority classes are much larger than that for majority class
since the majority class has far more examples than minority classes. Therefore, the global similarity between two
examples from minority class tends to be much larger than
that between examples from the majority class.

835

class c tends to be large, and n ci is large accordingly. In
other words, if we take the global similarity as the pair-wise
similarity based on the new feature representation, n ci is the
number of neighbors within a fixed distance. Therefore, n ci
is roughly in proportion to the local density at x i .
For each class c, we calculate the score of each example
xi , which is the maximum difference in the local density
between xi and the other examples with global similarity
c
bigger than or equal to at . By querying the data point with
the largest score, we focus on the regions where the local
density changes the most, so we have a higher probability of
finding examples from the minority classes. Furthermore,
by increasing the value of t, we gradually enlarge the size of
neighborhood. In this way, we are able to select not only the
points on the boundaries of minority classes, but also those
in the interior, which increases our chance of finding the
minority class examples. Finally, we make use of a simple
feedback strategy: if an unlabeled example is quite similar
to a labeled one, we preclude it from being selected in the
future. In this way, we avoid wasting the labeling effort
on the minority classes that have been discovered already.
Notice that the feedback strategy is orthogonal to the other
components of our algorithm. Currently, we are exploring
more effective feedback strategies.
It should be mentioned that we do not make any assumption about the separability between the majority class and
the minority classes, which is different from [4] and [12].
In fact, our algorithm works well when the support regions
of the majority class and the minority classes overlap.
The NNDB algorithm proposed in [7] can be seen as a
special case of our algorithm for the binary case. If we use
the pair-wise similarity matrix W  instead of the global similarity matrix A, and the update of the neighborhood size is
slightly modified in Step 15, our algorithm queries the same
examples as NNDB. In [7], it has been proven that under
certain conditions, with a high probability, after a few iteration steps, NNDB queries at least one example whose
probability of coming from the minority class is at least 13 .
If the new feature representation based on the global similarity matrix satisfies these conditions, our algorithm shares
the same theoretical properties as NNDB. In real applications, our algorithm is better than NNDB or NNDM (the
counterpart of NNDB for multiple classes) since we use the
global similarity, which makes the minority class examples
more tightly clustered.

2.4

wise similarity matrix constructed in Step 3 of Algorithm 1
for data with feature representation. To detect the rare categories using Algorithm 1, we input the graph G, p 1 , . . . , pc
and α. Then, we skip Step 1 to Step 3. All the other steps
are the same as before.
It is worth mentioning that in graph mining, researchers
have developed algorithms for detecting dense subgraphs or
communities [5, 10, 6]. If we want to use these approaches
for rare category detection, it is labor-intensive to have the
oracle label the whole subgraph. Conversely, the problem
of picking representative vertices of the subgraphs for the
oracle to label has not been addressed by existing work.

3. GRADE-LI Algorithm

In the GRADE algorithm, we need to input the proportions of all the classes. In practice it is often difficult to
estimate the number of classes in the data set, not to mention the priors of different classes. However, it may be relatively easier to obtain an upper bound on the proportion of
the minority classes of interest to us. In this section, we relax this requirement to produce the GRADE-LI algorithm,
which only needs an upper bound p on the proportion of all
the minority classes. Compared with GRADE, GRADE-LI
is more suited for real applications.
The GRADE-LI algorithm is summarized in Algorithm
2. It works as follows. Step 1 to Step 3 construct the
pair-wise similarity matrix. The only difference from the
GRADE algorithm is that here we use the upper bound p
to set the value of K. Step 4 to Step 6 calculate the global
similarity matrix, which is the same as in the GRADE algorithm. Step 7 calculates the largest global similarity to the
K th nearest neighbor and assigns it to a. Then in Step 8,
for each example x i , we find the number n i of its neighbors
with global similarity bigger than or equal to a. The while
loop in Step 9 is essentially the same as in the GRADE algorithm except that we are using a single similarity a instead
of a set of class specific similarities.

4. Experimental Results

In this section, we present the experimental results on
both synthetic and real data sets to show the effectiveness
of GRADE and GRADE-LI.

4.1

Synthetic Data Set

Fig.2 shows the result of applying GRADE on the synthetic data set in Fig.1a. There are 1000 examples from
the majority class, and only 20 examples from the minority class. Using random sampling, we need to label 51 examples to discover the minority class on average, whereas
using the GRADE algorithm, we only need to label 1 example, denoted as the black star. Note that in this data set, we
only have one minority class. If we run GRADE-LI with
the prior of the minority class as input, we get exactly the
same result as GRADE.

Application to Graph Data

Algorithm 1 can also be applied to graph data. To be specific, given a graph G = (V, W  ), where V = {v1 , . . . , vn }
consists of all the vertices, and W  is the connectivity matrix, i.e. Wij is the edge weight if vi is connected with
vj , and Wij = 0 otherwise. W  can be either binary or
real-valued (non-negative). Notice that the elements of W 
denote the pair-wise similarity, which is similar to the pair-

4.2

Real Data Set

In this subsection, we perform experiments on 4 real data
sets, which are summarized in Table1. Note that we have

836

Algorithm 2 Graph-based Rare Category Detection with
Less Information (GRADE-LI)
Input: Unlabeled data set S, p, α
Output: The set I of selected examples and the set L of
their labels
1: Let K = n × p.
2: For each example, calculate the distance between this
example and its K th nearest neighbor. Set σ to be the
minimum value of all such distances.
3: Construct the pair-wise similarity matrix W  , n × n,
where n is the number of examples, and ∀i, j =
1, . . . , n,
xi − xj 2
Wij = exp(−
)I(i 
= j)
2σ 2
4:
5:
6:
7:
8:
9:
10:
11:

need 14 label requests; with the Abalone data set, to discover all the classes, Interleave needs 333 label requests on
average, NNDM needs 179 label requests, RS needs 483 label requests on average, GRADE needs 149 label requests,
and GRADE-LI needs 318 label requests; with the Shuttle data set, Interleave needs 140 label requests on average, NNDM needs 87 label requests, RS needs 512 label
requests on average, GRADE needs 33 label requests, and
GRADE-LI needs 36 label requests.
2
1.5
1
0.5
0
−0.5

Construct the diagonal matrix D, n × n, where D ii =

n

j=1 Wij , i = 1, . . . , n.
Calculate the normalized matrix W
=
D−1/2 W  D−1/2 .
Calculate the global similarity matrix A = (I n×n −
αW )−1 .
For each row of A, find the K th largest element. Set a
to be the largest value of all such elements.
∀xi ∈ S, let N N (xi , a) = {x|x ∈ S, A(x, xi ) ≥ a},
and ni = |N N (xi , a)|.
while not all the classes have been discovered do
for t = 2 : n do
For each xi that has been labeled y i , ∀xj ∈ S, if
A(xi , xj ) ≥ a, sj = −∞; for all the other examples, si =
max a (ni − nj ).

−1
−1.5
−2
−2

−1

0

1

2

Figure 2. Synthetic data set: the black star
represents the example selected by GRADE.
Table 1. Properties of the data sets used.
Data Set
n
d m Largest Smallest
Class
Class
Ecoli [1]
336 7 6 42.56%
2.68%
Glass [1]
214 9 6 35.51%
4.21%
Abalone [1] 4177 7 20 16.50%
0.34%
Shuttle [3] 4515 9 7 75.53%
0.13%
From these results, we have the following observations:
first, with all the data sets, GRADE is much better than
NNDM, which is the prior best method for rare category
detection. Notice that both of the two algorithms need
the number of classes as well as the proportions of all the
classes as input. Second, the performance of GRADE-LI is
better than NNDM on all the data sets except the Abalone
data set. The reason might be the following: in the Abalone
data set, the proportion of the majority class is 16.50%, the
proportion of the largest minority class is 15.18%, and the
proportion of the smallest minority class is 0.34%. As we
have shown with the synthetic data set in the last subsection,
if the proportions of different minority classes do not vary
a lot, which is the case for the other 3 data sets, the performance of GRADE-LI is similar to GRADE. On the other
hand, if the proportions of different minority classes vary a
lot, which is the case for the Abalone data set, the performance of GRADE-LI is worse than GRADE. It should be
pointed out that compared with NNDM, GRADE-LI needs
much less information: only an upper bound on the proportion of the minority classes is needed. The reduction in the
prior knowledge about the data set is significant especially
when the number of classes in the data set is large, as with
the Abalone data set.
The GRADE-LI algorithm needs an upper bound on the
proportion of all the minority classes as input. Next we
study the robustness of GRADE-LI with respect to this up-

xj ∈N N (xi , t )

Select and query the label of x = arg max xi ∈S si .
Mark the class that x belongs to as discovered.
14:
end for
15: end while
12:
13:

pre-processed the data so that each feature component has
mean 0 and standard deviation 1. In the following experiments, we have compared GRADE and GRADE-LI with
the following methods: NNDM [7], Interleave (the best
method proposed in [12]) and random sampling (RS). Notice that the results for Interleave and RS are averaged over
100 runs.
Fig.3 to Fig.4 show the comparison results on the 4 data
sets. Note that for GRADE-LI, we use the exact upper
bound as input. With the Ecoli data set, to discover all
the classes, Interleave needs 41 label requests on average,
NNDM needs 36 label requests, RS needs 43 label requests
on average, GRADE needs 6 label requests, and GRADELI needs 32 label requests; with the Glass data set, to discover all the classes, Interleave needs 24 label requests on
average, NNDM needs 18 label requests, RS needs 31 label requests on average, and both GRADE and GRADE-LI

837

1

Percentage of Classes Discovered

Percentage of Classes Discovered

per bound using the 4 real data sets. To this end, we add
and subtract 15% from the exact upper bounds, and provide GRADE-LI the perturbed upper bounds. In Fig.5,
we compare the following 5 methods in terms of the total
number of label requests: NNDM, GRADE, GRADE-LI,
c
GRADE-LI with p = 0.85 × maxm
c=2 p , and GRADE-LI
c
with p = 1.15 × maxm
p
.
c=2
0.8
0.6
Interleave
NNDM
RS
GRADE
GRADE−LI

0.4
0.2
0
0

10
20
30
40
Number of Selected Examples

50

less information about the data set; (3) By using the global
similarity matrix to compensate for the lack of information
about the data set, GRADE-LI outperforms NNDM in most
situations; (4) GRADE-LI is robust to small perturbations
in the upper bound.

References

1

[1] A. Asuncion and D.J. Newman. UCI machine learning
repository, 2007.
[2] S. Bay, K. Kumaraswamy, M.G. Anderle, R. Kumar, and
D.M. Steier. Large scale detection of irregularities in accounting data. In ICDM, pages 75–86, 2006.

0.8
0.6
Interleave
NNDM
RS
GRADE
GRADE−LI

0.4
0.2
0
0

(a) Ecoli

10
20
30
Number of Selected Examples

[3] P. Brazdil and J. Gama.
Statlog repository.
In
http://www.niaad.liacc.up.pt/old/statlog/datasets
/shuttle/shuttle.doc.html, 1991.

40

(b) Glass

1

Percentage of Classes Discovered

Percentage of Classes Discovered

Figure 3. Ecoli and Glass data sets.

0.8
0.6
Interleave
NNDM
RS
GRADE
GRADE−LI

0.4
0.2
0
0

100
200
300
400
Number of Selected Examples

500

(a) Abalone

[4] S. Fine and Y. Mansour. Active sampling for multiple output
identification. In COLT, pages 620–634, 2006.

1

[5] G.W. Flake, S. Lawrence, and C.L Giles. Efficient identification of web communities. In KDD, pages 150–160, 2000.

0.8

[6] D. Gibson, R. Kumar, and A. Tomkins. Discovering large
dense subgraphs in massive graphs. In VLDB, pages 721–
732, 2005.

0.6
Interleave
NNDM
RS
GRADE
GRADE−LI

0.4
0.2
0
0

100
200
300
400
500
Number of Selected Examples

[7] J. He and J. Carbonell. Nearest-neighbor-based active learning for rare category detection. In NIPS, 2007.

600

[8] J. He and J. Carbonell. Rare class discovery based on active
learning. In ISAIM, 2008.

(b) Shuttle

Figure 4. Abalone and Shuttle data sets.
From Fig.5, we can see that GRADE-LI is quite robust
against small perturbations in the upper bounds. For example, with the Glass data set, to find all the classes, using
c
GRADE-LI, if p = maxm
c=2 p , we need 14 label requests;
m
c
if p = 0.85 × maxc=2 p , we need 16 label requests; if
c
p = 1.15 × maxm
c=2 p , we need 18 label requests.

[9] K. Huang, H. Yang, I. King, and K.R. Lyu. Learning classifiers from imbalanced data based on biased minimax probability machine. In CVPR, pages II–558–II–563, 2004.
[10] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins. On the
bursty evolution of blogspace. In WWW, pages 568–576,
2003.
[11] T. Mitchell. Machine Learning. McGraw-Hill Science Engineering, 1997.

Number of Selected Examples

350
300
250
200

NNDM
GRADE
GRADE−LI
−15%
+15%

[12] D. Pelleg and A. Moore. Active learning for anomaly and
rare-category detection. In NIPS, 2004.
[13] Y. Sun, M.S. Karmel, and Y. Wang. Boosting for learning multiple classes with imbalanced class distribution. In
ICDM, pages 592–602, 2006.
[14] Z. Wang, W. Josephson, Q. Lv, M. Charikar, and K. Li. Filtering image spam with near-duplicate detection. In CEAS,
2007.
[15] G. Wu and E.Y. Chang. Aligning boundary in kernel space
for learning imbalanced dataset. In ICDM, pages 265–272,
2004.

150
100
50
0

Ecoli

Glass Abalone Shuttle

Figure 5. Robustness study.

5. Conclusion
In this paper, we propose a graph-based method for
rare category detection named GRADE. Based on GRADE,
we designe a modified version named GRADE-LI, which
requires less information about the data set as input.
Our experimental results indicate that: (1) GRADE and
NNDM [7] (i.e., one of state-of-art algorithms) need the
same amount of information about the data set, and yet
GRADE is better than NNDM; (2) The improved version
GRADE-LI is competitive with GRADE even if it requires

[16] J. Wu, H. Xiong, P. Wu, and J. Chen. Local decomposition
for rare class analysis. In KDD, pages 814–823, 2007.
[17] D. Zhou, O. Bousquet, T.N. Lal, J. Weston, and
B. Scholkopf. Learning with local and global consistency.
In NIPS, 2003.
[18] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and
B. Scholkopf. Ranking on data manifolds. In NIPS, 2003.

838

2015 IEEE International Conference on Data Mining

A Graph-based Hybrid Framework for Modeling
Complex Heterogeneity
Pei Yang

Jingrui He

Arizona State University
Tempe, AZ 85281, USA
Email: cs.pyang@gmail.com

Arizona State University
Tempe, AZ 85281, USA
Email: jingrui.he@gmail.com

Abstract—Data heterogeneity is an intrinsic property of many
high impact applications, such as insider threat detection, trafﬁc
prediction, brain image analysis, quality control in manufacturing
processes, etc. Furthermore, multiple types of heterogeneity (e.g.,
task/view/instance heterogeneity) often co-exist in these applications, thus pose new challenges to existing techniques, most of
which are tailored for a single or dual types of heterogeneity.
To address this problem, in this paper, we propose a novel
graph-based hybrid approach to simultaneously model multiple
types of heterogeneity in a principled framework. The objective
is to maximize the smoothness consistency of the neighboring
nodes, bag-instance correlation together with task relatedness on
the hybrid graphs, and simultaneously minimize the empirical
classiﬁcation loss. Furthermore, we analyze its performance based
on Rademacher complexity, which sheds light on the beneﬁts
of jointly modeling multiple types of heterogeneity. To solve
the resulting non-convex non-smooth problem, we propose an
iterative algorithm named M 3 Learning, which combines block
coordinate descent and the bundle method for optimization.
Experimental results on various data sets show the effectiveness
of the proposed algorithm.

I.

I NTRODUCTION

Many real-world data mining applications exhibit multiple
types of heterogeneity, such as insider threat detection, trafﬁc
prediction, brain image analysis, quality control in manufacturing processes, etc. In this paper, we focus on three
common types of heterogeneity, i.e., task heterogeneity, view
heterogeneity, and instance heterogeneity. For example, in
insider threat detection problems, task heterogeneity refers to
the detection process in multiple target organizations, view
heterogeneity refers to the various types of information being
collected, and instance heterogeneity refers to the dynamic
behaviors of malicious insiders over time. Another example
is about quality control in semiconductor manufacturing. We
may have products from heterogeneous manufacturing lines
(task heterogeneity), each product can be characterized by
heterogeneous environmental variables, such as temperature,
pressure, power, impedance, etc. (view heterogeneity), and
some components of the product are defective (instance heterogeneity). Most existing techniques are designed to model
a subset of the three types of heterogeneity, and are not best
suited to address the more complex setting. To the best of our
knowledge, we are the ﬁrst to jointly model triple types of
heterogeneity including task, view, and instance heterogeneity.
The major challenge for learning with three types of
heterogeneity is how to effectively model the relationships
among various entities, i.e., instances and bags from multiple
1550-4786/15 $31.00 © 2015 IEEE
DOI 10.1109/ICDM.2015.109

tasks, and features from multiple views. Such relationships
should reﬂect the key assumptions underlying each type of
heterogeneity, including the task relatedness assumption [1],
the view consistency assumption [2], as well as the baginstance label assumption [3].
To address this problem, in this paper, we propose a novel
graph-based hybrid framework to learn from the three types
of heterogeneity. In this framework, we model the relationship
between instances and bags using hypergraphs, and the relationship between instances and features using bipartite graphs.
The objective is to maximize the smoothness consistency of
the neighboring nodes in the bipartite graphs, bag-instance
correlation in the hypergraphs together with the relatedness
among multiple tasks, and simultaneously minimize the empirical classiﬁcation loss. Based on the proposed framework,
we introduce an iterative algorithm named M 3 Learning,
which adapts block coordinate descent and non-convex bundle
method to solve the resulting optimization problem. The comparison experiments with state-of-the-art techniques demonstrate the effectiveness of the proposed algorithm.
Furthermore, we aim to answer the fundamental question
of whether the generalization performance can be improved by
jointly modeling the triple types of heterogeneity. We analyze
the generalization performance of the proposed framework
based on Rademacher complexity [4]. The analytical results
show that by jointly modeling triple heterogeneity, the empirical Rademacher complexity of the proposed approach can be
improved, resulting in the decreasing of the error bound for
the proposed model. The main contributions of this paper can
be summarized as follows:
•

A novel learning setting with three types of heterogeneity;
• A graph-based hybrid approach which models task
relatedness, view consistency, and bag-instance correlations in a principled framework;
• Theoretical analysis in terms of Rademacher complexity showing the improvement of generalization
performance by jointly modeling triple heterogeneity;
• Experimental results on various data sets demonstrating the effectiveness of the proposed algorithm.
The rest of the paper is organized as follows. After a brief
review of the related work in Section 2, we present the proposed framework and analyze its generalization performance
in Section 3. Section 4 shows the experimental results. Finally,
we conclude in Section 5.
1081

II.

R ELATED W ORK

bipartite graph with two types of nodes: one type of nodes
associated with the instances from multiple tasks, and another
type of nodes associated with the features from multiple views.
As shown on the right side of Figure 1, G(h) consists of T
hypergraphs constructed for different tasks, where each node
represents an instance, and each hyperedge can connect more
than two nodes. In other words, a hyperedge includes a subset
of instances.

In this section, we review the related work on modeling a
single or dual types of heterogeneity.
In multi-instance learning [3], the examples are considered
bags consisting of multiple instances, whose labels collectively
determine the bag-level label. Various techniques have been
proposed to address this problem, such as Diverse Density algorithm [5] and its extension EM-DD [6], K-nearest
neighbor based method Citation-kNN [7], large-margin based
methods including mi-SVM/MI-SVM [8] and MILEAGE [9],
kernel-based methods [10], [11], etc. In multi-view learning,
the features from multiple sources form natural partitions
(views). Different methods have been proposed to leverage
the view consistency to improve the performance, such as CoTraining [12], large-margin based methods [2], co-regularized
method CoMR [13], kernel spectral algorithm [14], etc. Multitask learning assumes that multiple related tasks share some
common structures. Various approaches have been proposed,
such as alternating structure optimization (ASO) [15], multitask feature learning [16], clustered-based method [17], robust
multi-task learning [18], etc.

Based on the hybrid graphs G, we deﬁne 2 types of
functions on the instance and feature nodes, respectively. To
be speciﬁc, for the tth (t = 1, . . . , T ) task, deﬁne function gt (·)
on the set of instance nodes associated with this task, where
gt (·) > 0 indicates a positive class label for the instance, and
vice versa. For the v th (v = 1, . . . , V ) view, deﬁne function
ftv (·) on the set of feature nodes being connected to the
tth (t = 1, . . . , T ) task, where ftv (·) > 0 indicates that the
feature carries positive label information for this task, and vice
versa.
Label Smoothness on the Bipartite Graph: Note that
the bipartite graphs model the instance-feature correlations.
(b)
Let Gtv = {Ntv , Etv } denote the bipartite subgraph between
instances from the tth task and features from the v th view,
where Ntv includes both the instance and feature nodes. Etv
consists of the edges between instance and feature nodes,
whose weights are determined by the corresponding feature
value of the instance. In this paper, we assume that the feature
values are non-negative. On this bipartite graph, let Wtv denote
the (ct + dv ) × (ct + dv ) afﬁnity matrix as


0ct ×ct
Atv
Wtv =
ATtv
0dv ×dv

More recently, researchers begin to study problems with dual types of heterogeneity. For example, for problems with both
instance and view heterogeneity, the MI2LS method proposed
in [19] imposes view consistency on the instance level; for
problems with both task and view heterogeneity, a variety of
techniques have been proposed to model task relatedness in the
presence of multiple views, e.g., [20], [21], [22]. For the more
complex setting with all three types of heterogeneity, these
techniques cannot be readily applied without disregarding the
useful information from a certain type of heterogeneity.
III.

where Atv is an ct × dv matrix with each row set to
be the feature values in the v th view for each instance in
this task. Furthermore, we normalize Wtv to obtain Utv =
−1/2
−1/2
Dtv Wtv Dtv , where Dtv is a diagonal matrix whose
diagonal elements are equal to the row sum of Wtv . From
the random walk point of view, we aim to maximize the
label smoothness on the bipartite graph, which is equivalent
to minimizing,
T  V 

gt 2 + ftv 2 − 2gtT Ltv ftv
JS =

M3 L EARNING F RAMEWORK

In this section, we will present the graph-based hybrid
model to address problems with complex heterogeneity, and
then analyze its generalization performance.
Suppose we have T related tasks in total. For the tth task,
t = 1, . . . , T , we have
ntnt bags, and bag Bti consists of nti
instances. Let ct = i=1
nti be the total number of instances
for the tth task. Each instance is described by features from V
complementary views1 , where dv is the number of features in
the v th view. Assume that the true label of bag Bti is yti ∈
{−1, 1}. Without loss of generality, assume that in the tth task,
the labels of the ﬁrst mt bags are known, and mt is typically
much smaller than nt . The goal is to leverage the small amount
of label information in order to learn the prediction function
b(Bti ) (t = 1, . . . , T , i = 1, . . . , nt ) for the unknown bags.

t=1

v=1

where Ltv is the off-diagonal block of Utv .
Bag-Instance Correlation on Hypergraphs: Note that the
bipartite graphs model the bag-instance correlations. Next, we
measure the label smoothness of instances on the hypergraphs
from the perspective of random walks.
(h)

Let Gt = (Nt , Et ) be the hypergraph for the tth task,
where Nt is the instance set in the tth task and Et is the
hyperedge set. We ﬁrst deﬁne the similarity metric between
bag Bti and instance xj as

k(x, xj )
s(Bti , xj ) =
x∈Bti
|Bti |

A. Label Propagation on Hybrid Graphs
We ﬁrst construct the hybrid graphs G to represent the
rich heterogeneity. It consists of the bipartite graph denoted
by G(b) and multiple hypergraphs denoted by G(h) , i.e., G =
{G(b) , G(h) }. Figure 1 provides examples of these graphs. As
shown on the left side of Figure 1, G(b) is an instance-feature

where k(x, xj ) is instance-instance similarity which can be
estimated in various ways (e.g., Gaussian kernel, cosine similarity, etc.), and |B| is the number of instance in bag B.
Each hyperedge e ∈ Et corresponds to a bag Bti which
consists of not only the instances in this bag, but also the

1 Notice

that for the ease of explanation, we assume that the same set of
views are shared by all the tasks, although the proposed idea can be applied
to the more general case where different tasks have both shared views and
task-speciﬁc views.

1082

7DVNW
,QVWDQFHV

7DVNW
,QVWDQFHV

9LHZY
)HDWXUHV

9LHZY
)HDWXUHV

7DVNW
,QVWDQFHV

7DVNW
,QVWDQFHV

Fig. 1: Illustration of the graph representation of M 3 Learning. Bags from multiple tasks consist of a set of instances (squares),
which are described by features (circles) from multiple views. The left part is an instance-feature bipartite graph. The right part
is composed of multiple hypergraphs for different tasks, where each hyperedge (dotted ellipse) is a subset of instances.
instances xj ∈ Nt satisfying s(Bti , xj ) >  where  is a
threshold (here we set it to the mean of instance-instance
similarity). For a hyperedge e ∈ Et , its degree is deﬁned
to be δ(e) =
|e|. For a node v ∈ Nt , its degree is deﬁned
by δ(v) =
{e∈Et |v∈e} w(e), where w(e) is the weight
associated with the hyperedge e ∈ Et , and it can be designed
to encode our prior knowledge on the bag. The diagonal
matrices with diagonal elements δ(e), δ(v), w(e) are denoted
De , Dv , We , respectively. The node-edge incidence matrix
C ∈ R|Nt |×|Et | is deﬁned as: C(v, e) = 1 if v ∈ e, and
C(v, e) = 0 otherwise.

Overall Objective: Putting everything together, the overall
objective is to maximize the label smoothness, bag-instance
correlation together with the task relatedness, and simultaneously minimize the empirical loss, which is equivalent to
minimizing,
J(f, g) = JS + βJB + λJR + μJemp

where β, λ, and μ are non-negative parameters that balance
the contribution from different terms.
M3 Learning Algorithm: We combine block coordinate
descent [24] and the bundle method [25] to solve the optimization problem in Eq. 1. Given g, J(g, f ) is a quadratic convex
optimization problem. By taking the derivative of J(g, f ) with
respect to f and setting it to zero, we have
T
LTtv gt + 2λ k=1,k=t fkv
ftv =
(2)
1 + 2λ (T − 1)

Intuitively, if two instances share more common hyperedges, they will be more similar. Likewise, if two hyperedges
share more common instances, they will also be more similar.
Therefore, the hypergraphs capture the bag-instance correlation. For all the tasks, we deﬁne the label smoothness of
instances on the hypergraphs by
T
JB = t=1 gtT Lt gt

where 1 ≤ t ≤ T and ≤ v ≤ V . Given f , J(g, f ) is
a non-smooth and non-convex optimization problem. Since
traditional bundle methods minimize the convex functions,
we adopt the non-convex bundle method [25] to solve g.
Theorem 1 shows the convergence of the proposed algorithm 2 .

where Lt is the normalized hypergraph Laplacian deﬁned as
−1
−1
Lt = I − Dv 2 CWe De−1 C T Dv 2 . This can be interpreted
from the random walk perspective on the hypergraph [23].
Given the current position u ∈ Nt , the walker ﬁrst chooses
a hyperedge e over all hyperedges incident with u with the
probability proportional to w(e), and then chooses a node v ∈
e uniformly at random.

Theorem 1 (Convergence). M 3 learning algorithm converges
to the local optimum.
B. Generalization Performance
It is important to investigate whether the generalization
performance can be improved by jointly modeling the complex
heterogeneity. Hence, in this subsection, we will ﬁrst construct
an RKHS for the proposed method, and then analyze its
empirical Rademacher complexity [4] and error bound.


T
T
T
Denote h = g1T ,f11
, · · · , f1V
, ·
· · , gTT , fTT1 , · · · , fTTV
T
V
and l = |h| = t=1 ct + v=1 dv . The overall objective
in Eq. 1 can be rewritten into

Task Relatedness: Notice that for the v th view, we deﬁned
T functions: f1v , . . . , fT v . Here, we assume that different
tasks are related via the functions deﬁned on the same view.
Intuitively, the related tasks should have similar predicitons
on the same feature. In other words, ft1 v − ft2 v 2 should
be small, where t1 , t2 ∈ {1, . . . , T }. Therefore, the task
relatedness can be measured by
T  T  V
ft1 v − ft2 v 2
JR =
t1 =1

t2 =1

v=1

J(h) = hT QS h + βhT QB h + λhT QR h + μJemp (h)

i=1

(3)

where QS is block diagonal matrix with its t (1 ≤ t ≤ T )
diagonal entry
⎤
⎡ VI
−L
···
−L
th

Consistency with Known Label Information: Various
empirical loss functions, such as hinge loss, squared loss,
and logistic loss, can be used to measure the consistency
with known label information. Here we adopt the hinge loss.
Since all the known label information is on the bag level, the
consistency can be measured by

	
T  m t
max 0, 1 − yti max gt (x)
Jemp =
t=1

(1)

[QS ]t,t

⎢
=⎣

ct ×ct

−LT
t1
.
.
.
−LT
tV

t1

tV

⎥
⎦

Id1 ×d1
..

.
IdV ×dV

2 Due to space limit, we omitted the proofs of all the theorems, which will
be included in an extended version of this paper.

x∈Bti

1083

and QB , QR are block matrices such as

L t = i, v = j = 1
[QB ]htv ,hij = 0 t otherwise

[QR ]htv ,hij =

The intuition is that the upper bound on the generalization
performance of the proposed model depends on the empirical
loss, the trace of Q−1 , as well as the problem size. Theorem 5
together with Theorem 4 suggest that the error bound of our
proposed method can be improved due to the reduction of
Rademacher complexity.

2 (T − 1) Idv ×dj t = i, v = j = 1
t = i, v = j = 1
−2Idv ×dj
0
otherwise

IV.

where 1 ≤ t, i ≤ T and 1 ≤ v, j ≤ V + 1.

E XPERIMENTAL R ESULTS

In this section, we show the experimental results of our
proposed algorithm on various data sets in comparison with
state-of-the-art techniques.

Let H be the space of functions with the norm deﬁned as
h2H = hT QS h. Denote Q = QS + βQB + λQR . Based on
H, we deﬁne H̃ to be the space of functions with the norm

A. Data Sets and Comparison Algorithms

h̃2H̃ = h2H + βhT QB h + λhT QR h = hT Qh

Three real-world benchmark data sets are used to test the
performance of the proposed algorithm. The Spam Email data
set was released by ECML/PKDD 2006 discovery challenge 3 .
In problem A, there are emails from 3 different users (2500 emails per user). The inboxes differ in the distribution of emails.
The goal is to construct a spam ﬁlter for each single user that
correctly classiﬁes its emails as spam or non-spam. We create
different tasks for different users. The Cora data set [26] is
an online archive containing approximately 37,000 computer
science research papers. 5 top categories and 10 sub-categories
were selected from Cora data set for evaluation. Based on this
subset, we created the multi-task learning problems shown
on the top of Table I, where the number in the parenthesis
is the number of instances. Reuters-21578 4 is widely used
for the evaluation of automatic text categorization algorithms.
Reuters-21578 corpus also has a hierarchical structure, which
contains 5 top categories. We use the pre-processed version of
the corpus5 , and create the multi-task learning problems shown
on the bottom of Table I.

Assume that QS , QB , QR , Q are invertible (otherwise one can
add a small regularization term to it). The following theorem
will show that H̃ is an RKHS.
Theorem 2 (RKHS). H̃ is an RKHS whose reproducing kernel
kH̃ (x, z) is equal to
kH (x, z) − KxT (I + βQB K + λQR K)−1 (βQB + λQR )Kz
T
where K = Q−1
S and Kx = [kH (x, x1 ) . . . kH (x, xl )] .

Based on Theorem 2, our proposed framework can be
reduced to standard supervised learning as follows.
h̃∗ = arg minh̃∈H̃ h̃2H̃ + μJemp (h̃)
Let H̃r := {h̃ ∈ H̃ : h̃ ≤ r} denote the ball of radius
r in H̃. Next, we will derive the Rademacher complexity of
the proposed method, and demonstrate the beneﬁt of jointly
modeling the multiple heterogeneity.

These data sets have been commonly used in the previous
work [20], [15] for learning from single or dual heterogeneity. For the latter two data sets, the task corresponds
to classifying the documents from different sub-categories,
drawn from different but related distributions. In these data
sets, the instances correspond to documents or paragraphs
in emails. Similar to [19], the instances are described from
two views: one corresponds to the TF-IDF features from the
original feature space; and the other corresponds to the hidden
topics information from the latent space obtained by applying
probabilistic latent semantic analysis on the term counts, where
the number of topics is set to 200 empirically. Following [11],
we create positive bags by randomly drawing p% instances
from the positive category and the remaining instances (and
all instances in negative bags) from the negative category.

Theorem 3 (Rademacher Complexity). The empirical
Rademacher complexity of H̃r is bounded as follows:

2r
R̂l (H̃r ) ≤
tr(K̃)
(4)
l
where K̃ = Q−1 = (QS + βQB + λQR )−1 .
Theorem 4 (Improvement of Rademacher Complexity). For
the proposed M 3 learning method, the upper bound of its
empirical Rademacher complexity can be improved by incorporating the bag-instance correlations and the task relatedness.
Its upper bound decreases with β and λ in an amount
determined by Δ(β, λ) = tr(K − K̃) ≥ 0.
Note that QB encodes the correlation information between
bags and instances, and QR encodes the task relatedness
among the multiple tasks. From Theorem 4, we can see that
the upper bound of the empirical Rademacher complexity
decreases by incorporating the correlation information between
bags and instances, as well as the relatedness among the
multiple tasks. An application of Theorem 4.17 in [4] shows
that:

In this work, we focus on leveraging the rich heterogeneity
to improve the prediction on the bag level. To the best of
our knowledge, there is no previous work for learning in such
a complex setting. Therefore, in addition to comparing M 3
learning with M I 2 LS [19] for learning with both instance
and view heterogeneity, we also compare M 3 with a variety of
multi-instance learning approaches including: 1) density-based
method EM-DD [6]; 2) large-margin based methods miSVM
and MISVM [8]; 3) KNN based method Citation-kNN (CKNN for short) [7]; 4) kernel-based method miGraph [11].

Theorem 5 (Error Bound). With probability at least 1 − δ, we
have

l
ln (2/δ)
1 
4
−1
ξi +
tr (Q ) + 3
Py=sgn(h(x)) (y) ≤
lγ i=1
lγ
2l

3 http://www.ecmlpkdd2006.org/challenge.html
4 http://www.daviddlewis.com/

where γ > 0 is the desired margin.

5 www.cse.ust.hk/TL/dataset/Reuters.zip

1084

TABLE I: Task description for Cora (top) and Reuters-21578 (bottom) data sets.
TASK

+1

-1

1
2
1
2
1
2
1
2
1
2

/data structures algorithms and theory/computational complexity/ (711)
/data structures algorithms and theory/computational geometry/ (459)
/data structures algorithms and theory/computational complexity/ (711)
/data structures algorithms and theory/computational geometry/ (459)
/data structures algorithms and theory/computational complexity/ (711)
/data structures algorithms and theory/computational geometry/ (459)
/networking/protocols/ (743)
/networking/routing/ (477)
/encryption and compression/encryption/ (534)
/encryption and compression/compression/ (530)

/networking/protocols/ (743)
/networking/routing/ (477)
/operating systems/realtime/ (595)
/operating systems/memory management/ (1102)
/machine learning/probabilistic methods/ (687)
/machine learning/genetic algorithms/ (670)
/machine learning/probabilistic methods/ (687)
/machine learning/genetic algorithms/ (670)
/machine learning/probabilistic methods/ (687)
/machine learning/genetic algorithms/ (670)

1
2
1
2
1
2

OrgsPeople.src +1 (588)
OrgsPeople.tar +1 (587)
OrgsPlaces.src +1 (428)
OrgsPlaces.tar +1 (456)
PeoplePlaces.src +1 (428)
PeoplePlaces.tar +1 (456)

OrgsPeople.src -1 (649)
OrgsPeople.tar -1 (621)
OrgsPlaces.src -1 (588)
OrgsPlaces.tar -1 (587)
PeoplePlaces.src -1 (649)
PeoplePlaces.tar -1 (621)

DA-OS
DA-ML
NT-ML
EC-ML
Orgs-People
Orgs-Places
People-Places







0,/6
0






(0í''
PL690
0,690
&í.11
PL*UDSK



(UURUUDWH

(UURUUDWH



(0í''
PL690
0,690
&í.11
PL*UDSK





0,/6
0






(0í''
PL690
0,690
&í.11
PL*UDSK





0,/6
0




0

























5DWLR




















5DWLR




















5DWLR









0,/6








(0í''
PL690
0,690
&í.11
PL*UDSK



(UURUUDWH

DA-NT

(UURUUDWH

DATA SET












5DWLR









Fig. 2: Results on email spam data sets: a) task 1; b) task 2; c) task 3; d) averaged over all tasks.
The classiﬁcation error rate on test bags is used for comparison, which is deﬁned as ratio of the number of misclassiﬁed
bags to that of total test bags. Both M 3 and M I 2 LS take as
input the multi-view data, and the other methods are given the
concatenated features from all the views. The parameters are
tuned for each algorithm using cross-validation on the training
data. We repeat the experiments 10 times for each data set and
report the average error rates and the standard deviations.
B. Performance Study
Figure 2(a-c) shows the comparison results on email spam
data sets for each task, respectively. The average performance
and standard deviations are shown in Figure 2(d) by aggregating all the tasks. In each ﬁgure, x-axis represents the ratio
p of positive instances in positive bags, and y-axis represents
the error rate. Results on Cora and Reuters-21578 data sets are
shown on Table II. On these data sets, we ﬁx the ratio to 0.3.
First of all, a common trend observed from the ﬁgures is
that most of the algorithms usually perform worse when the
ratio decreases. It is reasonable because smaller ratio means
less positive instances in the positive bags, which makes it
harder for the classiﬁer to identify the characteristic instances
in each bag. One exception is MISVM since we stop it after
100 iterations due to its relative low efﬁciency.
From these ﬁgures, we can see that M 3 and miGraph
perform better than the other methods in most cases. It indicates that graph-based approaches show superiority on these
data sets in comparison with the other algorithms by either
considering the consistency of nearest neighbors on the graph
(as in M 3 ), or modeling the inter-correlation between instances
in the bags via a graph kernel (as in miGraph). Moreover,
the performance superiority of M 3 over the other methods
is more evident when the ratio is less than 0.3 indicating
that the learning task becomes more difﬁcult. It veriﬁes the

effectivenss of simultaneously modeling triple types of heterogeneity, namely task heterogeneity, view heterogeneity, and
instance heterogeneity, in a principled framework. By leveraging the consistency among multiple views, the view-based
classiﬁers can mutually improve each other. By leveraging the
relationship between instances and bags, we are able to better
characterize the positive bags and instances. By considering the
relatedness among tasks, the performance of individual tasks
can beneﬁt from each other by borrowing information from
related tasks.
C. Parameter Sensitivity
The effectiveness of jointly modeling multiple types of
heterogeneity can be also veriﬁed by varying the parameters
in the objective function (see Eq. 1). For example, we study
the parameter sensitivity on the email spam data set. We tune
λ (or β) on the grid 10[−3:1:3] , μ on the grid 2[−1:1:5] .
The result for λ is shown in Figure 3(a). λ is to balance the
importance of task relatedness. The algorithm performs worse
when λ ≤ 0.01, and the worst case occurs when λ = 0, which
suggests that simultaneously modeling the related tasks could
signiﬁcantly improve the multi-instance learning performance.
The optimal performance is achieved at λ = 1. Nevertheless,
the performance is quite robust over a wide range of values
for λ. Figure 3(b) shows a similar trend for β, indicating
that the learner could beneﬁt from leveraging the bag-instance
relationship. μ is used to control the weight of empirical loss.
In Figure 3(c), we could also see that the error rate ﬁrst
decreases and then increases when μ is increased.
D. Computational Efﬁciency and Convergence
We empirically study the convergence of M 3 on the email
spam data set. The result is shown in Figure 3(d). From this
ﬁgure, we can see that M 3 converges fast and its performance
becomes stable after 5 iterations. Also, the computational

1085

TABLE II: Average classiﬁcation error rates and standard deviations on Cora (top) and Reuters-21578 (bottom) data sets.
MISVM
0.540±0.05
0.349±0.13
0.429±0.07
0.469±0.05
0.284±0.06
0.694±0.01
0.500±0.35
0.694±0.08

C-KNN
0.281±0.02
0.350±0.04
0.275±0.02
0.330±0.07
0.392±0.03
0.316±0.12
0.284±0.01
0.295±0.03






























(UURUUDWH


























λ


















β












(UURUUDWH
&38WLPH









M3
0.029±0.01
0.080±0.05
0.093±0.07
0.090±0.08
0.056± 0.01
0.110±0.04
0.180±0.07
0.240±0.11










M I 2 LS
0.185±0.26
0.310±0.17
0.253±0.12
0.192±0.09
0.173±0.10
0.305±0.01
0.397±0.02
0.368±0.01

MI G RAPH
0.055±0.01
0.101±0.06
0.126±0.05
0.119±0.09
0.047±0.03
0.133±0.05
0.206±0.11
0.126±0.06









&38WLPHVHFRQG

MI SVM
0.148±0.03
0.274±0.03
0.235±0.02
0.166±0.06
0.089±0.04
0.188±0.14
0.340±0.06
0.262±0.04

(UURUUDWH

EM-DD
0.155±0.13
0.285±0.10
0.199±0.01
0.125±0.09
0.118±0.13
0.179±0.10
0.295±0.06
0.242±0.02

(UURUUDWH

(UURUUDWH

DATA SET
DA-NT
DA-OS
DA-ML
EC-ML
NT-ML
O RGS -P EOPLE
O RGS -P LACES
P EOPLE -P LACES









μ





















,WHUDWLRQ










Fig. 3: a) Error rate vs. λ (log10 scale); b) Error rate vs. β (log10 scale); c) Error rate vs. μ (log2 scale); d) Error rate and CPU
time vary with each iteration.
cost of the proposed method is empirically studied. The CPU
running time for M 3 learning on the email spam data set is
plotted in Figure 3(d). The result shows that the proposed
algorithm is empirically linearly scalable.
V.

[9]
[10]
[11]

C ONCLUSION

In this paper, we focus on jointly modeling multiple types
of heterogeneity. To this end, we propose a graph-based hybrid
framework for modeling the multiple types of relationships
among instances, bags, tasks, and views. Furthermore, we
analyze its generalization performance in terms of Rademacher
complexity and the error bound, which show the beneﬁt
of jointly modeling multiple heterogeneity. The comparison
experiments with state-of-the-art techniques demonstrate its
effectiveness.
Acknowledgment: This work is partially supported by the NSF
(No. IIS1017415), Region II University Transportation Center (No.
49997-33 25), DARPA (No. W911NF-11-C-0200 and W911NF-12C-0028), and NSFC (No. 61473123).
R EFERENCES
[1] R. Caruana, “Multitask learning,” Machine Learning, vol. 28, no. 1, pp.
41–75, 1997.
[2] J. D. R. Farquhar, D. R. Hardoon, H. Meng, J. Shawe-Taylor, and
S. Szedmák, “Two view learning: Svm-2k, theory and practice,” in
NIPS, 2005.
[3] T. G. Dietterich, R. H. Lathrop, and T. Lozano-Pérez, “Solving the
multiple instance problem with axis-parallel rectangles,” Artiﬁcial Intelligence Journal, vol. 89, no. 1-2, pp. 31–71, 1997.
[4] J. Shawe-Taylor and N. Cristianini, Kernel Methods for Pattern Analysis. Cambridge University Press, 2004.
[5] O. Maron and T. Lozano-Pérez, “A framework for multiple-instance
learning,” in NIPS, 1998, pp. 570–576.
[6] Q. Zhang and S. A. Goldman, “Em-dd: An improved multiple-instance
learning technique,” in NIPS, 2001, pp. 1073–1080.
[7] J. Wang and J.-D. Zucker, “Solving the multiple-instance problem: a
lazy learning approach,” in ICML, 2000, pp. 1119–1126.
[8] S. Andrews, I. Tsochantaridis, and T. Hofmann, “Support vector machines for multiple-instance learning,” in NIPS, 2002, pp. 561–568.

[12]
[13]
[14]
[15]

[16]
[17]
[18]
[19]
[20]
[21]
[22]
[23]

[24]

[25]

[26]

1086

D. Zhang, J. He, L. Si, and R. D. Lawrence, “Mileage: Multiple instance
learning with global embedding,” in ICML, 2013, pp. 82–90.
T. Gärtner, P. A. Flach, A. Kowalczyk, and A. J. Smola, “Multi-instance
kernels,” in ICML, 2002, pp. 179–186.
Z.-H. Zhou, Y.-Y. Sun, and Y.-F. Li, “Multi-instance learning by treating
instances as non-i.i.d. samples,” in ICML, 2009, pp. 157–164.
A. Blum and T. Mitchell, “Combining labeled and unlabeled data with
co-training,” in COLT, 1998, pp. 92–100.
V. Sindhwani and D. S. Rosenberg, “An rkhs for multi-view learning
and manifold co-regularization,” in ICML, 2008, pp. 976–983.
L. Song, A. Anandkumar, B. Dai, and B. Xie, “Nonparametric estimation of multi-view latent variable models,” in ICML, 2014, pp. 640–648.
R. K. Ando and T. Zhang, “A framework for learning predictive
structures from multiple tasks and unlabeled data,” Journal of Machine
Learning Research (JMLR), vol. 6, pp. 1817–1853, 2005.
A. Argyriou, T. Evgeniou, and M. Pontil, “Multi-task feature learning,”
in NIPS, 2006, pp. 41–48.
J. Zhou, J. Chen, and J. Ye, “Clustered multi-task learning via alternating structure optimization,” in NIPS, 2011, pp. 702–710.
P. Gong, J. Ye, and C. Zhang, “Robust multi-task feature learning,” in
KDD, 2012, pp. 895–903.
D. Zhang, J. He, and R. D. Lawrence, “Mi2ls: multi-instance learning
from multiple informationsources,” in KDD, 2013, pp. 149–157.
J. He and R. Lawrence, “A graph-based framework for multi-task multiview learning,” in ICML, 2011, pp. 25–32.
J. Zhang and J. Huan, “Inductive multi-task learning with multiple view
data,” in KDD, 2012, pp. 543–551.
H. Yang and J. He, “Learning with dual heterogeneity: A nonparametric
bayes model,” in KDD, 2014, pp. 582–590.
D. Zhou, J. Huang, and B. Schölkopf, “Learning with hypergraphs:
Clustering, classiﬁcation, and embedding,” in NIPS, 2007, pp. 1601–
1608.
P. Tseng, “Convergence of a block coordinate descent method for
nondifferentiable minimization,” Journal of Optimization Theory and
Applications, vol. 109, no. 3, pp. 475–494, 2001.
C. Bergeron, G. M. Moore, J. Zaretzki, C. M. Breneman, and K. P.
Bennett, “Fast bundle algorithm for multiple-instance learning,” IEEE
Trans. Pattern Anal. Mach. Intell. (PAMI), vol. 34, no. 6, pp. 1068–
1079, 2012.
A. K. McCallum, K. Nigam, J. Rennie, and K. Seymore, “Automating
the construction of internet portals with machine learning,” Information
Retrieval, vol. 3, no. 2, pp. 127–163, 2000.

Nearest-Neighbor-Based Active Learning for Rare
Category Detection

Jingrui He
School of Computer Science
Carnegie Mellon University
jingruih@cs.cmu.edu

Jaime Carbonell
School of Computer Science
Carnegie Mellon University
jgc@cs.cmu.edu

Abstract
Rare category detection is an open challenge for active learning, especially in
the de-novo case (no labeled examples), but of significant practical importance for
data mining - e.g. detecting new financial transaction fraud patterns, where normal
legitimate transactions dominate. This paper develops a new method for detecting
an instance of each minority class via an unsupervised local-density-differential
sampling strategy. Essentially a variable-scale nearest neighbor process is used to
optimize the probability of sampling tightly-grouped minority classes, subject to
a local smoothness assumption of the majority class. Results on both synthetic
and real data sets are very positive, detecting each minority class with only a fraction of the actively sampled points required by random sampling and by Pelleg’s
Interleave method, the prior best technique in the sparse literature on this topic.

1

Introduction

In many real world problems, the proportion of data points in different classes is highly skewed:
some classes dominate the data set (majority classes), and the remaining classes may have only a
few examples (minority classes). However, it is very important to detect examples from the minority
classes via active learning. For example, in fraud detection tasks, most of the records correspond to
normal transactions, and yet once we identify a new type of fraud transaction, we are well on our
way to stopping similar future fraud transactions [2]. Another example is in astronomy. Most of
the objects in sky survey images are explainable by current theories and models. Only 0.001% of
the objects are truly beyond the scope of current science and may lead to new discoveries [8]. Rare
category detection is also a bottleneck in reducing the sampling complexity of active learning [1,
5]. The difference between rare category detection and outlier detection is that: in rare category
detection, the examples from one or more minority classes are often self-similar, potentially forming
compact clusters, while in outlier detection, the outliers are typically scattered.
Currently, only a few methods have been proposed to address this challenge. For example, in [8],
the authors assumed a mixture model to fit the data, and selected examples for labeling according
to different criteria; in [6], the authors proposed a generic consistency algorithm, and proved upper
bounds and lower bounds for this algorithm in some specific situations. Most of the existing methods
require that the majority classes and the minority classes be separable or work best in the separable
case. However, in real applications, the support regions of the majority and minority classes often
overlap, which affects negatively the performance of these methods.
In this paper, we propose a novel method for rare category detection in the context of active learning.
We typically start de-novo, no category labels, though our algorithm makes no such assumption.
Different from existing methods, we aim to solve the hard case, i.e. we do not assume separability or
near-separability of the classes. Intuitively, the method makes use of nearest neighbors to measure
local density around each example. In each iteration, the algorithm selects an example with the
1

maximum change in local density on a certain scale, and asks the oracle for its label. The method
stops once it has found at least one example from each class (given the knowledge of the number
of classes). When the minority classes form compact clusters and the majority class distribution
is locally smooth, the method will select examples both on the boundary and in the interior of the
minority classes, and is proved to be effective theoretically. Experimental results on both synthetic
and real data sets show the superiority of our method over existing methods.
The rest of the paper is organized as follows. In Section 2, we introduce our method and provide
theoretical justification, first for binary classes and then for multiple classes. Section 3 gives experimental results. Finally, we conclude the paper in Section 4.

2
2.1

Rare category detection
Problem definition

Given a set of unlabeled examples S = {x1 , . . . , xn }, xi ∈ Rd , which come from m distinct classes,
i.e. yi ∈ {1, . . . , m}, the goal is to find at least one example from each class by requesting as few
total labels as possible. For the sake of simplicity, assume that there is only one majority class,
which corresponds to yi = 1, and all the other classes are minority classes.
2.2

Rare category detection for the binary case

First let us focus on the simplest case where m = 2, and Pr[yi = 1] À Pr[yi = 2] = p, i.e.
p ¿ 1. Here, we assume that we have an estimate of the value of p a priori. Next, we introduce our
method for rare category detection based on nearest neighbors, which is presented in Algorithm 1.
The basic idea is to find maximum changes in local density, which might indicate the location of a
rare category.
The algorithm works as follows. Given the unlabeled set S and the prior of the minority class p, we
first estimate the number K of minority class examples in S. Then, for each example, we record
its distance from the K th nearest neighbor, which could be realized by kd-trees [7]. The minimum
distance over all the examples is assigned to r0 . Next, we draw a hyper-ball centered at each example
with radius r0 , and count the number of examples enclosed by this hyper-ball, which is denoted as
ni . ni is roughly in proportion to the local density. To measure the change of local density around a
certain point xi , in each iteration of Step 3, we subtract nj of neighboring points from ni , and let the
maximum value be the score of xi . The example with the maximum score is selected for labeling
by the oracle. If the example is from the minority class, stop the iteration; otherwise, enlarge the
neighborhood where the scores of the examples are re-calculated and continue.
Before giving theoretical justification, here, we give an intuitive explanation of why the algorithm
works. Assume that the minority class is concentrated in a small region and the probability distribution function (pdf) of the majority class is locally smooth. Firstly, since the support region of the
minority class is very small, it is important to find its scale. The r0 value obtained in Step 1 will
be used to calculate the local density ni . Since r0 is based on the minimum K th nearest neighbor
distance, it is never too large to smooth out changes of local density, and thus it is a good measure of
the scale. Secondly, the score of a certain point, corresponding to the change in local density, is the
maximum of the difference in local density between this point and all of its neighboring points. In
this way, we are not only able to select points on the boundary of the minority class, but also points
in the interior, given that the region is small. Finally, by gradually enlarging the neighborhood where
the scores are calculated, we can further explore the interior of the support region, and increase our
chance of finding a minority class example.
2.3

Correctness

In this subsection, we prove that if the minority class is concentrated in a small region and the pdf
of the majority class is locally smooth, the proposed algorithm will repeatedly sample in the region
where minority class examples occur with high probability.
Let f1 (x) and f2 (x) denote the pdf of the majority and minority classes respectively, where x ∈ Rd .
To be precise, we make the following assumptions.
2

Algorithm 1 Nearest-Neighbor-Based Rare Category Detection for the Binary Case (NNDB)
Require: S, p
1: Let K = np. For each example, calculate the distance to its K th nearest neighbor. Set r 0 to be
the minimum value among all the examples.
2: ∀xi ∈ S, let N N (xi , r 0 ) = {x|x ∈ S, kx − xi k ≤ r 0 }, and ni = |N N (xi , r 0 )|.
3: for t = 1 : n do
4:
∀xi ∈ S, if xi has not been selected, then si =
max 0 (ni − nj ); otherwise, si = −∞.
xj ∈N N (xi ,tr )

5:
Query x = arg maxxi ∈S si .
6:
If the label of x is 2, break.
7: end for

Assumptions
1. f2 (x) is uniform within a hyper-ball B of radius r centered at b, i.e. f2 (x) = V 1(r) , if
x ∈ B; and 0 otherwise, where V (r) ∝ rd is the volume of B.
c1 p
2. f1 (x) is bounded and positive in B 1 , i.e. f1 (x) ≥ (1−p)V
(r) , ∀x ∈ B and f1 (x) ≤
c2 p
d
(1−p)V (r) , ∀x ∈ R , where c1 , c2 > 0 are two constants.
With the above assumptions, we have the following claim and theorem. Note that variants of the
following proof apply if we assume a different minority class distribution, such as a tight Gaussian.
Claim 1. ∀², δ > 0, if n ≥ max{ 2c21p2 log 3δ , 2(1−21−d )2 p2 log 3δ , ²4 V (1r2 )4 log 3δ }, where r2 =
1
2
r2
r2
r
1 , and V ( 2 ) is the volume of a hyper-ball with radius 2 , then with probability at least 1 − δ,
(1+c2 ) d
r2
0
2 ≤ r

≤ r and | nni − E( nni )| ≤ ²V (r0 ), 1 ≤ i ≤ n, where V (r0 ) is the volume of a hyper-ball
with radius r0 .
Proof. First, notice that the expected proportion of points falling inside B, E( |N Nn(b,r)| ) ≥ (c1 +1)p,
and that the maximum expected proportion of points falling inside any hyper-ball of radius r22 ,
max[E(

x∈Rd

|N N (x,
n

r2
2

)|

)] ≤ 2−d p. Then

ni
ni
r2
or ∃xi ∈ S s.t. | − E( )| > ²V (r0 )]
2
n
n
ni
ni
r2
r2
0
0
0
and ∃xi ∈ S s.t. | − E( )| > ²V (r0 )]
≤ Pr[r > r] + Pr[r < ] + Pr[r ≥
2
2
n
n
ni
ni
r2
r2
≤ Pr[|N N (b, r)| < K] + Pr[max |N N (x, )| > K] + n Pr[| − E( )| > ²V (r0 )|r0 ≥ ]
d
2
n
n
2
x∈R
N N (x, r22 )
ni
N N (b, r)
ni
r
2
| < p] + Pr[max |
| > p] + n Pr[| − E( )| > ²V (r0 )|r0 ≥ ]
= Pr[|
n
n
n
n
2
x∈Rd

Pr[r0 > r or r0 <

2 2

≤ e−2nc1 p + e−2n(1−2

−d 2 2

) p

+ 2ne−2n²

2

V (r 0 )2

where the last inequality is based on Hoeffding bound.
2 2

−d 2 2

2

0

Let e−2nc1 p ≤ 3δ , e−2n(1−2 ) p ≤ 3δ and 2ne−2n² V (r ) ≤ 2ne−2n²
n ≥ 2c21p2 log 3δ , n ≥ 2(1−21−d )2 p2 log 3δ , and n ≥ ²4 V (1r2 )4 log 3δ . ¥
1

2

V(

r2 2
2 )

≤

δ
3,

we obtain

2

Based on Claim 1, we get the following theorem, which shows the effectiveness of the proposed
method.
Main Theorem. If
1. Let B 2 be the hyper-ball centered at b with radius 2r. The minimum distance between
the points inside B and the ones outside B 2 is not too large, i.e. min{kxi − xj k|xi , xj ∈
S, kxi − bk ≤ r, kxj − bk > 2r} ≤ α, where α is a positive parameter.
1

Notice that here we are only dealing with the hard case where f1 (x) is positive within B. In the separable
case where the support regions of the two classes do not overlap, we can use other methods to detect the
minority class, such as the one proposed in [8].

3

p2 OV (

r2

,r)

2
, where β ≤ 2d+1 V (r)
2. f1 (x) is locally smooth, i.e. ∀x, y ∈ Rd , |f1 (x)−f1 (y)| ≤ βkx−yk
2
α
r2
and OV ( 2 , r) is the volume of the overlapping region of two hyper-balls: one is of radius
r, the other one is of radius r22 , and its center is on the sphere of the bigger one.

3. The number of examples is sufficiently large,
i.e. n ≥ max{ 2c21p2 log 3δ , 2(1−21−d )2 p2 log 3δ , (1−p)4 β14 V ( r2 )4 log 3δ }.
1

2

then with probability at least 1 − δ, after d 2α
r2 e iterations, NNDB will query at least one example
whose probability of coming from the minority class is at least 31 , and it will continue querying such
2d
− 2) · αr cth iteration.
examples until the b( p(1−p)
Proof. Based on Claim 1, using condition 3, if the number of examples is sufficiently large, then with
probability at least 1 − δ, r22 ≤ r0 ≤ r and | nni − E( nni )| ≤ (1 − p)βV (r0 ), 1 ≤ i ≤ n. According to
n
condition 2, ∀xi , xj ∈ S s.t. kxi − bk > 2r, kxj − bk > 2r and kxi − xj k ≤ α, E( nni ) and E( nj )
nj
ni
0
will not be affected by the minority class, and |E( n ) − E( n )| ≤ (1 − p)βV (r ) ≤ (1 − p)βV (r).
Note that α is always bigger than r. Based on the above inequalities, we have
nj
ni
nj
nj
ni
nj
ni
ni
| − | ≤ | − E( )| + | − E( )| + |E( ) − E( )| ≤ 3(1 − p)βV (r) (1)
n
n
n
n
n
n
n
n
From inequality (1), it is not hard to see that ∀xi , xj ∈ S, s.t. kxi − bk > 2r and kxi − xj k ≤ α,
nj
ni
0
n − n ≤ 3(1 − p)βV (r), i.e. when tr = α,
si
≤ 3(1 − p)βV (r)
n

(2)

This is because if kxj − bk ≤ 2r, the minority class may also contribute to
may be even smaller.

nj
n ,

and thus the score

On the other hand, based on condition 1, there exist two points xk , xl ∈ S, s.t. kxk − bk ≤ r,
kxl − bk > 2r, and kxk − xl k ≤ α. Since the contribution of the minority class to E( nnk ) is at least
r

p·OV ( 22 ,r)
,
V (r)

p·OV (

r2

,r)

p·OV (

r2

,r)

2
2
− (1 − p)βV (r0 ) ≥
− (1 − p)βV (r). Since
so E( nnk ) − E( nnl ) ≥
V (r)
V (r)
ni
ni
0
for any example xi ∈ S, we have | n − E( n )| ≤ (1 − p)βV (r ) ≤ (1 − p)βV (r), therefore

p · OV ( r22 , r)
p · OV ( r22 , r) 3(1 − p)p2 · OV ( r22 , r)
nl
nk
−
≥
− 3(1 − p)βV (r) ≥
−
n
n
V (r)
V (r)
2d+1 V (r)
Since p is very small, p À

3(1−p)p2
;
2d+1

therefore,

nk
n

−

nl
n

> 3(1 − p)βV (r), i.e. when tr0 = α,

sk
> 3(1 − p)βV (r)
(3)
n
In Step 4 of the proposed method, we gradually enlarge the neighborhood to calculate the change of
local density. When tr0 = α, based on inequalities (2) and (3), ∀xi ∈ S, kxi − bk > 2r, we have
sk > si . Therefore, in this round of iteration, we will pick an example from B 2 . In order for tr0 to
be equal to α, the value of t would be d rα0 e ≤ d 2α
r2 e.
If we further increase t so that tr0 = cα, where c > 1, we have the following conclusion: ∀xi , xj ∈
n
S, s.t. kxi − bk > 2r and kxi − xj k ≤ cα, nni − nj ≤ (c + 2)(1 − p)βV (r), i.e. sni ≤ (c + 2)(1 −
2

d

2
− 2, then ∀xi ∈ S, kxi − bk > 2r, sk > si ,
, i.e. c ≤ p(1−p)
p)βV (r). As long as p ≥ (c+2)(1−p)p
2d
2
0
and we will pick examples from B . Since r ≤ r, the method will continue querying examples in
2d
− 2) · αr cth iteration.
B 2 until the b( p(1−p)

Finally, we show that the probability of picking a minority class example from B 2 is at least 31 .
To this end, we need to calculate the maximum probability mass of the majority class within B 2 .
Consider the case where the maximum value of f1 (x) occurs at b, and this pdf decreases by β every
time x moves away from b in the direction of the radius by α, i.e. the shape of f1 (x) is a cone
1 (b)
= 1, where
in (d + 1) dimensional space. Since f1 (x) must integrate to 1, i.e. V ( αfβ1 (b) ) · fd+1
V ( αfβ1 (b) ) is the volume of a hyper-ball with radius
4

αf1 (b)
β ,

1

d

d+1 β d+1 .
we have f1 (b) = ( Vd+1
(α) )

Therefore, the probability mass of the majority class within B 2 is:
2r
2r β
V (2r)(f1 (b) − β) +
V (2r) < V (2r)f1 (b)
α
α d+1
1
d
d
1
d + 1 d+1
V (r)
d+1 β d+1
)
β d+1 = 2d
= V (2r)(
1 (d + 1)
V (α)
V (α) d+1
p2 · OV ( r22 , r) d
) d+1 < 2p
V (r)
where V (2r) is the volume of a hyper-ball with radius 2r. Therefore, if we select a point at random
p
p
≥ p+2p
= 31 .
from B 2 , the probability that this point is from the minority class is at least p+(1−p)·2p
¥
1

d

1

< (d + 1) d+1 (2d+1 V (r)β) d+1 ≤ (d + 1) d+1 (

2.4

Rare category detection for multiple classes

In subsection 2.2, we have discussed rare category detection for the binary case. In this subsection,
we focus on the case where m > 2. To be specific, let p1 , . . . , pm be the priors of the m classes,
and p1 À pi , i 6= 1. Our goal is to use as few label requests as possible to find at least one example
from each class.
The method proposed in subsection 2.2 can be easily generalized to multiple classes, which is presented in Algorithm 2. In this algorithm, we are given the priors of all the minority classes. Using
each pi , we estimate the number Ki of examples from this class, and calculate the corresponding ri0
value in the same manner as NNDB. Then, we calculate the local density at each example based on
different scales ri0 . In the outer loop of Step 9, we calculate the r0 value which is the minimum of
all the ri0 whose corresponding classes have not been discovered yet and its index. In the inner loop
of Step 11, we gradually enlarge the neighborhood to calculate the score of each example. This is
the same as NNDB, except that we preclude the examples that are within a certain distance of any
selected example from being selected. This heuristic is to avoid repeatedly selecting examples from
the same discovered class. The inner loop stops when we find an example from an undiscovered
class. Then we will update the r0 value and resume the inner loop. If the minority classes form
compact clusters and are far apart from each other, NNDM is able to detect examples from each
minority class with a small number of label requests.
Algorithm 2 Nearest-Neighbor-Based Rare Category Detection for Multiple Classes (NNDM)
Require: S, p2 , . . . , pm
1: for i = 2 : m do
2:
Let Ki = npi .
3:
For each example, calculate the distance between this example and its Kith nearest neighbor.
Set ri0 to be the minimum value among all the examples.
4: end for
0
5: Let r10 = maxm
i=2 ri .
6: for i = 1 : m do
7:
∀xj ∈ S, let N N (xj , ri0 ) = {x|x ∈ S, kx − xj k ≤ ri0 }, and nij = |N N (xj , ri0 )|.
8: end for
9: while not all the classes have been discovered do
10:
Let r0 = min{ri0 |1 ≤ i ≤ m, and class i has not been discovered}, and s be the corresponding index, i.e. r0 = rs0 .
11:
for t = 1 : n do
12:
for each xi that has been selected and labeled yi , ∀x ∈ S, s.t. kx − xi k ≤ ry0 i , si = −∞;
for all the other examples, si =
max 0 (nsi − nsj ).
xj ∈N N (xi ,tr )

13:
Query x = arg maxxi ∈S si .
14:
If x belongs to a class that has not been discovered, break.
15:
end for
16: end while

In NNDB and NNDM, we need the priors of the minority classes as the input. As we will see in the
next section, our algorithms are robust against small perturbations in the priors.
5

3

Experimental results

In this section, we compare our methods (NNDB and NNDM) with the best method proposed in [8]
(Interleave) and random sampling (RS) on both synthetic and real data sets. In Interleave, we use
the number of classes as the number of components in the mixture model. For both Interleave and
RS, we run the experiment multiple times and report the average results.
3.1

Synthetic data sets

Figure 1(a) shows a synthetic data set where the pdf of the majority class is Gaussian and the pdf of
the minority class is uniform within a small hyper-ball. There are 1000 examples from the majority
class and only 10 examples from the minority class. Using Interleave, we need to label 35 examples,
using RS, we need to label 101 examples, and using NNDB, we only need to label 3 examples in
order to sample one from the minority class, which are denoted as ‘x’ in Figure 1(b). Notice that
the first 2 examples that NNDB selects are not from the correct region. This is because the number
of examples from the minority class is very small, and the local density may be affected by the
randomness in the data.

5

5

4

4

3

3

2

2

1

1

0

0

−1

−1
−3

−2

−1

0

1

2

3

−3

4

−2

−1

0

1

2

3

4

(b) Examples Selected by NNDB, denoted as ‘x’

(a) Data Set

Figure 1: Synthetic Data Set 1.
In Figure 2(a), the X-shaped data consisting of 3000 examples correspond to the majority class, and
the four characters ‘NIPS’ correspond to four minority classes, which consist of 138, 79, 118, and
206 examples respectively. Using Interleave, we need to label 1190 examples, using RS, we need
to label 83 examples, and using NNDM, we only need to label 5 examples in order to get one from
each of the minority classes, which are denoted as ‘x’ in Figure 2(b). Notice that in this example,
Interleave is even worse than RS. This might be because some minority classes are located in the
region where the density of the majority class is not negligible, and thus may be ‘explained’ by the
majority-class mixture-model component.
3.2

Real data sets

In this subsection, we compare different methods on two real data sets: Abalone [3] and Shuttle [4].
The first data set consists of 4177 examples, described by 7 dimensional features. The examples
come from 20 classes: the proportion of the largest class is 16.50%, and the proportion of the
smallest class is 0.34%. For the second data set, we sub-sample the original training set to produce
a smaller data set with 4515 examples, described by 9 dimensional features. The examples come
from 7 classes: the proportion of the largest class is 75.53%, and the proportion of the smallest class
is 0.13%.
The comparison results are shown in Figure 3(a) and Figure 3(b) respectively. From these figures,
we can see that NNDM is significantly better than Interleave and RS: with Abalone data set, to find
6

200

200

180

180

160

160

140

140

120

120

100

100

80

80

60

60

40

40

20

20
0

0
0

50

100

150

200

0

250

50

100

150

200

250

(b) Examples Selected by NNDM, denoted as ‘x’

(a) Data Set

Figure 2: Synthetic Data Set 2.
all the classes, Interleave needs 280 label requests, RS needs 483 label requests, and NNDM only
needs 125 label requests; with Shuttle data set, to find all the classes, Interleave needs 140 label
requests, RS needs 512 label requests, and NNDM only needs 87 label requests. This is because
as the number of components becomes larger, the mixture model generated by Interleave is less
reliable due to the lack of labeled examples, thus we need to select more examples. Furthermore,
the majority and minority classes may not be near-separable, which is a disaster for Interleave. On
the other hand, NNDM does not assume a generative model for the data, and only focuses on the
change in local density, which is more effective on the two data sets.

20

7

Classes Discovered

Classes Discovered

6
15

10

NNDM
Interleave
RS

5

5
4

NNDM
Interleave

3

RS
2

0
0

100
200
300
400
Number of Selected Examples

1
0

500

(a) Abalone

100
200
300
400
500
Number of Selected Examples

600

(b) Shuttle

Figure 3: Learning Curves for Real Data Sets

3.3

Imprecise priors

The proposed algorithms need the priors of the minority classes as input. In this subsection, we test
the robustness of NNDM against modest mis-estimations of the class priors. The performance of
NNDB is similar to NNDM, so we omit the results here. In the experiments, we use the same data
sets as in subsection 3.2, and add/subtract 5%, 10%, and 20% from the true priors of the minority
classes. The results are shown in Figure 4. From these figures, we can see that NNDM is very robust
to small perturbations in the priors. For example, with Abalone data set, if we subtract 10% from
the true priors, only one more label request is needed in order to find all the classes.
7

20

7

Classes Discovered

Classes Discovered

6
15
−5%
−10%
−20%
0
+5%
+10%
+20%

10

5

0
0

50
100
150
200
Number of Selected Examples

5
−5%
−10%
−20%
0
+5%
+10%
+20%

4
3
2
1
0

250

20
40
60
80
Number of Selected Examples

(a) Abalone

100

(b) Shuttle

Figure 4: Robustness Study

4

Conclusion

In this paper, we have proposed a novel method for rare category detection, useful for de-novo active
learning in serious applications. Different from existing methods, our method does not rely on the
assumption that the data is near-separable. It works by selecting examples corresponding to regions
with the maximum change in local density, and depending on scaling, it will select class-boundary
or class-internal samples of minority classes. The method could be scaled up using kd-trees [7]. The
effectiveness of the proposed method is guaranteed by theoretical justification, and its superiority
over existing methods is demonstrated by extensive experimental results on both synthetic and real
data sets. Moreover, it is very robust to modest perturbations in estimating true class priors.

Acknowledgments
This paper is based on work in part supported by the Defense Advanced Research Projects Agency
(DARPA) under contract number NBCHD030010.

References
[1] M. Balcan, A. Beygelzimer, and J. Langford. Agnostic active learning. In Proc. of the 23rd Int.
Conf. on Machine Learning, pages 65–72, 2006.
[2] S. Bay, K. Kumaraswamy, M. Anderle, R. Kumar, and D. Steier. Large scale detection of
irregularities in accounting data. In Proc. of the 6th Int. Conf. on Data Mining, pages 75–86,
2006.
[3] C. Blake and C. Merz.
Uci repository of machine learning databases.
http://www.ics.uci.edu/ machine/MLRepository.html, 1998.
[4] P.
Brazdil
and
J.
Gama.
Statlog
repository.
http://www.niaad.liacc.up.pt/old/statlog/datasets/shuttle/shuttle.doc.html, 1991.

In
In

[5] S. Dasgupta. Coarse sample complexity bounds for active learning. In Advances in Neural
Information Processing Systems 19, 2005.
[6] S. Fine and Y. Mansour. Active sampling for multiple output identification. In The 19th Annual
Conf. on Learning Theory, pages 620–634, 2006.
[7] A. Moore. A tutorial on kd-trees. Technical report, University of Cambridge Computer Laboratory, 1991.
[8] D. Pelleg and A. Moore. Active learning for anomaly and rare-category detection. In Advances
in Neural Information Processing Systems 18, 2004.

8

2012 IEEE 12th International Conference on Data Mining

Hierarchical Multi-task Learning with Application to Wafer Quality Prediction
Jingrui He∗ , Yada Zhu∗
T.J. Watson Research Center
Email: {jingruhe, yzhu}@us.ibm.com
∗ IBM

mapping with which the prediction performance can be
improved [2], [5]; and some assume that various tasks share
the relationship among data [22], [23]; etc. Furthermore, in
the case that the relatedness varies among different tasks,
some researchers try to cluster the tasks into groups such
that tasks within the same group are more related than tasks
in different groups [4], [13].
In this paper, we propose and study a novel setting
named Hierarchical MTL where the tasks are partitioned into
multiple groups, and they exhibit hierarchical relatedness. To
be speciﬁc, different tasks within the same group are related
on the task-level, whereas different groups are related on
the group-level. One example is the application of virtual
metrology in semiconductor manufacturing, where the goal
is to predict the wafer quality based on process variables,
such as temperature, pressure and gas ﬂow per unit time. It is
often the case that wafers are produced in multiple chambers,
each of which has multiple sides. Each side can be seen as a
single task with a model that predicts the quality of wafers
produced therein based on the process variables, and each
chamber can be seen as a group of such tasks. Intuitively, the
models for different sides of the same chamber are related on
the side-level (task-level), whereas the models for different
chambers are related on the chamber-level (group-level),
hence the hierarchical task relatedness.
To address the above problem, motivated by wafer quality
prediction, we propose an optimization framework, which
partitions all the process variables into 2 sets based on
their characteristics, independent and dependent, and models the task-level and group-level relatedness by imposing
different constraints on the coefﬁcient vectors of the 2 sets.
Furthermore, we propose the HEAR algorithm (MTL with
HiErarchical tAsk Relatedness) to solve the optimization
problem, and demonstrate its performance on both synthetic
and real data sets for semiconductor manufacturing and
document classiﬁcation.
The main contributions of this paper can be summarized
as follows.
1) Problem deﬁnition: we propose and study a novel
setting in MTL with hierarchical task relatedness;
2) General framework: motivated by wafer quality prediction in semiconductor manufacturing, we solve
the problem of hierarchical MTL by partitioning the
process variables into 2 sets, namely independent and
dependent, and imposing different constraints on their

Abstract—Many real problems of multi-task learning exhibit
hierarchical task relatedness. In other words, the tasks are partitioned into multiple groups. Different tasks within the same
group are related on the task-level, whereas different groups
are related on the group-level. For example, in semiconductor
manufacturing, the problem of wafer quality prediction can
be considered as hierarchical multi-task learning, where each
task corresponds to a single side of a chamber with sidelevel relatedness, and a group of tasks corresponds to a
chamber of multiple sides with chamber-level relatedness.
Motivated by this application, in this paper, we propose an
optimization framework for hierarchical multi-task learning,
which partitions all the input features into 2 sets based on
their characteristics, and models task-level and group-level
relatedness by imposing different constraints on the coefﬁcient
vectors of the 2 sets. This is different from existing work on
task clustering where the goal is to uncover the grouping of
tasks, the tasks do not exhibit group-level relatedness, and the
input features are not discriminated in the prediction model
to model task-level and group-level relatedness. To solve this
framework, we propose the HEAR algorithm based on block
coordinate descent, and demonstrate its effectiveness on both
synthetic and real data sets from domains of semiconductor
manufacturing and document classiﬁcation.
Keywords-hierarchical multi-task learning; wafer quality;
task relatedness;

I. I NTRODUCTION
In multi-task learning (MTL), we are facing multiple
prediction tasks, either classiﬁcation [8], or regression [16],
or a combination of both [27], and we only have a few
labeled examples in each task. Our goal is to leverage the
relatedness among various tasks to compensate for the lack
of label information in a single task, so that we can build a
good model for each task that predicts well on future unseen
examples. The past decade has seen continuous advancement
and growing interest in this area. It has been used in
many real applications such as sentiment classiﬁcation [11],
document categorization [10], landmine detection [19], [25],
image retrieval [26], face recognition [29], etc.
A key component in multi-task learning is taskrelatedness, i.e., what information is shared among the
tasks and how it is shared. Up until now, researchers have
explored various types of task-relatedness. For example,
some assume that re-weighted examples from one task can
be used in another task [11], [28]; some assume that the
model parameters for different tasks are similar [17], [29];
some assume that different tasks share the same feature
1550-4786/12 $26.00 © 2012 IEEE
DOI 10.1109/ICDM.2012.63

500
290

blockwise coordinate descent algorithm; in [30], the authors
proposed MTRL algorithm, where the task covariance matrix
can model positive task correlation, negative task correlation,
and task unrelatedness; in [15], the authors constructed a
task network based on model parameters, and casted the
optimization problem as a second order cone program; etc.
The third case is common feature representation, upon which
models are built for multiple tasks. For example, in [2],
the authors present an algorithm that learns common sparse
feature representations across a pool of related tasks, and
constructs linear models based on the learned features for
each target task; in [5], the authors propose the CASO
algorithm, which improves the ASO algorithm in [1] by
including an additional regularizer in the objective function
and making use of alternating structure optimization to solve
the convex relaxation efﬁciently; in [31], the authors provide
a probabilistic interpretation of the general multi-task feature
selection using the l1,q norm, and develop a probabilistic
model using the noninformative Jeffreys prior; in [9], the
authors use an undirected graph deﬁned on features to learn
a task covariance matrix related to the task parameters
to measure the task relationship; etc. The fourth case is
common relational knowledge, where various tasks share the
relationship among data. For example, in [22], the authors
propose the TAMAR algorithm, which transfers Markov
Logic Networks (MLN) across multiple tasks by mapping
and revising them; in [23], the authors propose the SR2LR
algorithm for a more challenging case in relational domain
transfer where the amount of target data is minimal and
consists of information about just a handful of entities.
More recently, people begin to study MTL problems
where the relatedness varies with different task pairs. For
example, in [4] the authors adopt neural network model for
multi-task learning, and cluster the tasks based on Gaussian
mixture models; in [13], the authors design a spectral
norm over the set of coefﬁcient vectors, which results in
a convex optimization formulation for clustering multiple
tasks; in [6], the authors propose a robust multi-task learning
algorithm that captures the task relationships using a lowrank structure, and simultaneously identiﬁes the outlier tasks
using a group-sparse structure. The major difference between
these techniques and ours is 3-fold. First, one challenge
in these techniques is to uncover the grouping of tasks;
whereas in our setting the grouping of tasks is known, and
the challenge is in modeling the hierarchical task relatedness.
Second, these techniques focus on various amount of tasklevel relatedness, and lack group-level relatedness; whereas
we integrate both the task-level and the group-level relatedness. Third, in these techniques, the input features are
treated equally; whereas in our setting, the input features are
partitioned into 2 sets, and we impose different constraints
on their coefﬁcient vectors to accommodate the task-level
and group-level relatedness, which is motivated by wafer
quality prediction in semiconductor manufacturing.

coefﬁcients in the prediction model;
3) HEAR Algorithm: we propose an effective algorithm
for addressing the above framework, and demonstrate
its effectiveness by experimental results on various
data sets.
The rest of the paper is organized as follows. We ﬁrst
review the related work in Section II, then we propose
the optimization framework in Section III, followed by the
introduction of the HEAR algorithm in Section IV. Section V
shows the effectiveness of HEAR on both synthetic and real
data sets. Finally, we conclude the paper in Section VI.
II. R ELATED W ORK
In this section, we brieﬂy review the related work on
multi-task learning and transfer learning. The goal of both
multi-task learning and transfer learning is to leverage the
relatedness of multiple tasks to compensate for the lack of
labeled data in the target tasks. The major difference between
them is in terms of the target tasks. In multi-task learning, all
the tasks are target tasks with a few labeled examples, and
we aim to build good models for all of them. On the other
hand, in transfer learning, only some of the tasks are target
tasks with no or limited label information, and the remaining
tasks are source tasks with abundant label information. Here
we only aim to build good models for the target tasks and
do not care about the source tasks. Techniques proposed for
one scenario is often readily applied to the other scenario. To
be speciﬁc, transfer learning methods can be used for multitask learning by alternating the source and target tasks, and
multi-task learning methods can be used for transfer learning
by down-weighting the examples from the source tasks.
In both learning scenarios, the key component is task
relatedness, which affects the information shared/transferred
among various tasks. Depending on the type of such information, multi-task learning and transfer learning can
be categorized into four cases [24], i.e., instance-based,
parameter-based, common feature representation, and common relational knowledge.
The ﬁrst case is instance-based, i.e., directly incorporating
data from related tasks to help build the model for the
target task. For example, in [28], [12], the authors measure
the expected classiﬁcation loss in the target task via reweighted labeled examples in the source task; in [8], the
authors use boosting to ﬁlter out the training data in the
source task that are different from the target task data
by adjusting their weights in each iteration, and use the
remaining data in the source task as additional training
data in the target task; etc. The second case is parameterbased, i.e., imposing similarity on the parameters of various
tasks. For example, in [29], the authors penalize the matrix
consisting of model parameters from multiple tasks based
on matrix-variate normal density; in [18], the authors study
multi-task Lasso, which assumes joint sparsity of model
parameters among multiple tasks, and propose a cyclical

291
501

III. O PTIMIZATION F RAMEWORK

often considered to be the same for different sides of the
same chamber. This is because the independent variables
correspond to the controlled parameters in the production
process to achieve a speciﬁc set point, and their values are
set such that the quality of the produced wafers meet certain
standards. For different sides of the same chamber with a
ﬁxed environment, the controlled parameters affect the wafer
quality in the same way. On the other hand, the correlation of
wafer quality with the set of dependent variables is affected
by the independent variables. This is because the dependent
variables correspond to the uncontrolled parameters. Their
effect on the wafer quality is closely related to the environment of the chamber, which is determined by the controlled
parameters.
Put in another way, for different sides of the same
chamber, the corresponding tasks are related via: (1) the
same coefﬁcient vector for the set of independent variables;
and (2) the relatedness between the coefﬁcient vectors for
independent variables and dependent variables. Therefore,
in the following derivation, we replace αt,s with αt since
it only varies with chambers/groups of tasks. On the other
hand, for different chambers/groups of tasks, their coefﬁcient
vectors for the set of independent variables should be similar.
Therefore, the tasks associated with all the sides of all the
chambers exhibit hierarchical relatedness.
Putting everything together, we have the following objective function.

In this section, we present the optimization framework for
hierarchical MTL. We ﬁrst introduce the problem deﬁnition,
followed by the objective function. Then, we discuss some
special cases of the proposed framework, which are closely
connected with some existing work in MTL.
A. Problem Deﬁnition
The framework for hierarchical MTL is motivated by
wafer quality prediction in semiconductor manufacturing,
where the goal is to predict the wafer quality based on
process variables, such as temperature, pressure and gas
ﬂow per unit time. Furthermore, it is often the case that
wafers are produced from multiple chambers, each of which
has multiple sides. Each side of each chamber corresponds
to a task with a unique model that predicts the quality
of wafers produced therein based on the process variables,
and each chamber can be seen as a group of such tasks.
The hierarchical task relatedness is reﬂected in the fact that
the models predicting the quality of wafers produced from
different sides of the same chamber are more similar (tasklevel relatedness) than those from different chambers (grouplevel relatedness).
Suppose that we have C chambers, i.e., groups of tasks,
and the tth chamber, i.e., the tth group, has St sides/tasks.
The process variables measured for each wafer/example can
be partitioned into two sets: independent and dependent.
The set of d1 independent variables include pressure, power,
temperature, gas ﬂows, etc, which are subject to Advance
Process Control (APC); whereas the set of d2 dependent
variables include impedance, electric bias, throttle valve
positions, etc, which are heavily dependent on the set of
independent variables. For the sth side of the tth chamber
(t = 1, . . . , T , s = 1, . . . , St ), let nt,s denote the number of
wafers/examples produced therein; At,s ∈ Rnt,s ×d1 denote
the independent variables for all the wafer/example; B t,s ∈
Rnt,s ×d2 denote the dependent variables; and y t,s ∈ Rnt,s
denote the quality of the wafers in terms of deposition
thickness. Our goal is to leverage the relatedness among
multiple sides/tasks and multiple chambers/groups to better
predict the wafer quality.

Q(αt , β t,s , M )
=

St
T 

{ [L(y t,s , At,s αt , B t,s βt,s )
t=1 s=1

+ λ1 βt,s − M αt p ]} + λ2 R(α1 , . . . , αT )

(1)

where L(·) denotes the loss function that takes as input the
wafer quality in terms of the deposition thickness, the independent and the dependent variables; R(·) is the function
of all the coefﬁcient vectors for the independent variables;
p, λ1 and λ2 are positive parameters; M ∈ Rd2 ×d1 is the
transformation matrix that connects the coefﬁcient vectors
for the independent variables and the dependent variables.
Intuitively, the ﬁrst term of the objective function Q
measures the prediction error; the second term measures
the approximation error of the coefﬁcient vector for the
dependent variables using the transformed coefﬁcient vector
for the independent variables; and the last term imposes
similarity on all the coefﬁcient vectors for the independent
variables. Notice that various tasks are coupled in two
different ways, depending on whether they are in the same
group or not, i.e., sharing the same group index t. If two
tasks come from the same group t, they share the same
coefﬁcient vector αt for the independent variables, and their
coefﬁcient vectors for the dependent variables are both close
to M αt ; on the other hand, if two tasks come from different
groups, they are related only by the coefﬁcient vectors for the

B. Objective Function
To predict the wafer quality y t,s , we make use of a linear
model, which is commonly used in virtual metrology [14],
[21]. To be speciﬁc, ∀t = 1, . . . , T , s = 1, . . . , St ,
ŷ t,s = At,s αt,s + B t,s βt,s
where ŷ t,s is the predicted wafer quality for the sth side
of the tth chamber; αt,s ∈ Rd1 and βt,s ∈ Rd2 are
the coefﬁcient vectors for the independent and dependent
variables respectively.
In the application of virtual metrology, the correlation
of wafer quality with the set of independent variables is

292
502

be close to the common vector α0 ∈ Rd1 , we have the
following optimization problem.

independent variables. By minimizing Eq. (1), we leverage
the hierarchical task relatedness to construct models for all
the tasks.
Notice that our setting is similar to [4], [13], [6] in that
the relatedness varies with different task pairs. However,
there is signiﬁcant difference between these methods and
ours in various aspects. First of all, in [4], [13], [6], the
grouping of the tasks (relevant vs. irrelevant) is not known
a priori, and the goal is to optimize the information transfer
among tasks by identifying the relevant tasks; whereas in our
setting, we already know how the tasks are grouped, and the
goal is to leverage the hierarchical task relatedness to help
build the model for each task. Second, in [4], [13], [6], the
relatedness among different groups of tasks is not taken into
consideration; whereas in our setting, we model both the
task-level and the group-level relatedness in the objective
function. Third, in [4], [13], [6], the input variables are
treated equally; whereas in our setting, the input variables
form 2 sets (independent vs. dependent), and the different
constraints for the 2 coefﬁcient vectors associated with these
sets reﬂect the hierarchical task relatedness.

min Q(αt , β t,s , M , α0 )
= min

St
T 

{ [(y t,s − At,s αt − B t,s βt,s )2
t=1 s=1

+ λ1 βt,s − M αt 2 ]} + λ2

T


(αt − α0 )2

(2)

t=1

Notice that Eq. (2) is not convex in all the parameters.
However, it is easy to see that given αt and β t,s (t =
1, . . . , T , s = 1, . . . , St ), Q is convex with respect to M
and α0 ; on the other hand, given M and α0 , Q is convex
with respect to αt and β t,s (t = 1, . . . , T , s = 1, . . . , St ).
Therefore, we make use of block coordinate descent to ﬁnd
the solution to Eq. (2), i.e., we repeatedly update M and
α0 based on the current αt and βt,s , and vice versa until
convergence.
B. Block Coordinate Descent

C. Special Cases

By taking the partial derivative of Q with respect to M
and α0 , and setting it to 0, we have

Many existing single-task and multi-task learning methods
can be seen as special cases of Eq. (1). For example, if we
only have the dependent variables, and αt is ﬁxed at 0, all
the tasks are decoupled, and Eq. (1) is equivalent to solving
each task individually. If we only have the independent
variables, β t,s is ﬁxed at 0, and M is a 0 matrix, all
the tasks are coupled such that: (1) tasks from the same
group share the same coefﬁcient vector; and (2) tasks from
different groups have similar coefﬁcient vectors. In the case
that each group has only one task, this is consistent with the
formulation in [29], [18].
Eq. (1) is also related to convex multi-task feature learning
proposed in [2]. To see this, assume that we only have a set
of dependent variables B t,s , and let λ1 → ∞. In this way,
tasks within the same group share the same coefﬁcient vector
M αt , and different groups have similar αt . Furthermore,
if St = 1 (t = 1, . . . , T ), and R() is the (2,1)-norm
of the matrix consisting of α1 , . . . , αT , we get the same
optimization problem in [2].

M=
α0 =

St
T 
T


(
βt,s )αt (
St αt αt )−1
t=1 s=1
T


1
T

(3)

t=1

αt

(4)

t=1

where αt denotes the transpose of αt .
From Eq. (3) and (4), we can see that both M and α0 are
used by different groups of tasks, therefore, their estimation
leverages the information from all the tasks.
On the other hand, ∀t = 1, . . . , T , let γ t ∈ Rd1 +St d2
denote [αt , βt,1 , . . . , βt,St ] , γ 0 ∈ Rd1 +St d2 denote
S t
[α0 , 0, . . . , 0] , y t ∈ R s=1 nt,s denote [y t,1 , . . . , y t,St ] ,
St
X t ∈ R( s=1 nt,s )×(d1 +St d2 ) denote
⎤
⎡
At,1 B t,1
0
···
0
⎢ At,2
0
B t,2 · · ·
0 ⎥
⎥
⎢
⎥
⎢
..
..
..
..
.
.
⎦
⎣
.
.
.
.
.
0
···
0 B t,St
At,St

IV. HEAR A LGORITHM
In this section, we study an instantiation of Eq. (1), and
discuss how to make use of block coordinate descent to
ﬁnd its solution. Then we introduce an accelerating scheme
for updating the coefﬁcient vectors, followed by the formal
description of the HEAR algorithm.

I t ∈ R(d1 +St d2 )×(d1 +St d2 ) denote
⎡
I d1 ×d1 0 · · ·
⎢
0
0 ···
⎢
⎢
..
.. . .
⎣
.
.
.
0
0 ···

A. Instantiation of Eq. (1)
In Eq. (1), if we let L(y t,s , At,s αt , B t,s β t,s ) = (y t,s −
At,s αt − B t,s β t,s )2 , p = 2, and R(α1 , . . . , αT ) =
T
minα0 t=1 (αt − α0 )2 , which encourages all the αt to

0
0
..
.

⎤
⎥
⎥
⎥
⎦

0

where I d1 ×d1 denotes d1 × d1 identity matrix, and M t ∈

293
503

R(d1 +St d2 )×(d1 +St d2 ) denote
⎡
M  M −M 
⎢ −M I d2 ×d2
⎢
⎢
..
..
⎣
.
.
−M
0

···
···
..
.

−M 
0
..
.

···

I d2 ×d2

⎤

C 1,j ∈ Rd1 ×d2 , and C i,j ∈ Rd2 ×d2 (i, j = 2, . . . , St ). Then
using Woodbury formula, we have,

⎥
⎥
⎥
⎦

(X t X t + λ1 M t + λ2 I t )−1 = C − CM t1 D−1 M t1 C
(7)
where D can be written as follows.


St +1
M C 1,1 M 
M j=2
C 1,j
St +1 St +1
D = St +1

i=2 C i,1 M
i=2
j=2 C i,j

Given M and α0 , Q can be written as a function of γ t
(t = 1, . . . , T )
Q(γ t ) =

T


In this way, in each iteration, instead of computing the
inverse of a (d1 + St d2 ) × (d1 + St d2 ) matrix, we only
compute the inverse of a (2d2 ) × (2d2 ) matrix, which is
independent of the number of tasks within each group.

{yt − X t γ t 2 + λ1 γ t M t γ t

t=1

+ λ2 (γ t − γ 0 ) I t (γ t − γ 0 )}
Taking the partial derivative of Q with respect to γ t and
setting it to 0, we have
γt =

(X t X t

−1

+ λ1 M t + λ2 I t )

(X t y t

+ λ2 γ 0 )

D. Algorithm Description
The proposed HEAR algorithm is presented in Alg. 1.
It works as follows. In Step 1, we initialize the coefﬁcient
vectors to be vectors of all 1s. In Step 2, we compute matrix
C t , which is the inverse of X t X t + λ2 I t (t = 1, . . . , T ).
It will be used to update the coefﬁcient vectors via Eq.
(7). Next, we repeatedly update M , α0 , as well as all
the coefﬁcient vectors N times. Based on the coefﬁcient
vectors obtained via the proposed HEAR algorithm, given
an unlabeled example from the sth task of the tth group with
independent variables at,s ∈ Rd1 and dependent variables
bt,s ∈ Rd2 , we predict its output using at,s αt + bt,s β t,s .

(5)

where we make use of the fact that I t γ 0 = γ 0 .
From Eq. (5), we can see that if we ﬁx M and α0 ,
different groups of tasks are decoupled. Therefore, the
coefﬁcient vector γ t for the tth task can be individually
estimated. However, the tasks within the same group are still
coupled due to the sharing of the coefﬁcient vector αt for
the independent variables as well as the connection between
the coefﬁcient vectors αt and βt,s for the 2 sets of variables
via the transformation matrix M .

Algorithm 1 HEAR Algorithm
Input: At,s , B t,s , y t,s , (t = 1, . . . , T , s = 1, . . . , St ), λ1 ,
λ2 , maximum number of iterations N
Output: αt , βt,s , (t = 1, . . . , T , s = 1, . . . , St ), M , α0
1: Initialize αt and β t,s (t = 1, . . . , T , s = 1, . . . , St ) to
be vectors of all 1s

2: Compute C t = (X t X t + λ2 I t )−1 (t = 1, . . . , T )
3: for i = 1 to N do
4:
Update M using Eq. (3)
5:
Update α0 using Eq. (4)
6:
Update αt and β t,s using Eq. (5) and Eq. (7)
7: end for

C. Accelerated Update of γ t
As discussed in the previous subsection, we make use of
block coordinate descent to repeatedly update M and α0
based on the current αt and β t,s using Eq. (3) and (4), and
vice versa using Eq. (5), until convergence. As we can see,
Eq. (5) involves computing the inverse of a (d1 + St d2 ) ×
(d1 + St d2 ) matrix, which might be very time consuming,
especially when the number of tasks within each group is
large. To address this problem, we notice that the matrix
inversion involves two parts: X t X + λ2 I t which is ﬁxed
for each task, and λ1 M t which is updated in each iteration.
Furthermore, M t can be rewritten as follows.



I d2 ×d2 −I d2 ×d2
(6)
M t = M t1
M t1
−I d2 ×d2
0
where M t1 is deﬁned as follows.
⎡
M
0
⎢ 0 I d2 ×d2
⎢
M t1 = ⎢ .
..
⎣ ..
.
0

According to [20], the convergence of HEAR to a local
optimum of Eq. (2) is guaranteed since the objective function
is convex with respect to each block (i.e., M , α0 , and γt ).
Notice that in each iteration of HEAR, the processing time is
linear
with respect to the total number of training examples
T 
St
s=1 nt,s , which is a direct result from Eq. (5) and
t=1
Eq. (7).

⎤
⎥
⎥
⎥
⎦

V. E XPERIMENTAL R ESULTS

I d2 ×d2

In this section, we demonstrate the performance of the
proposed HEAR algorithm on both synthetic and real data
sets for semiconductor manufacturing and document classiﬁcation. In particular, we aim to answer the following two
questions.

Let C t ∈ R(d1 +St d2 )×(d1 +St d2 ) denote (X t X t + λ2 I t )−1 .
In the following analysis, when the context is clear, we omit
the subscript of C t , and let C i,j denote its block in the ith
row and j th column, s.t., C 1,1 ∈ Rd1 ×d1 , C i,1 ∈ Rd2 ×d1 ,

294
504

1) How does the performance of HEAR compare with
other multi-task learning algorithms?
2) How does HEAR scale with the number of training
examples?
To answer the ﬁrst question, we compare with the following
algorithms:
1) MTL-FEAT [2], which learns common sparse feature
representations across a pool of related tasks, and
constructs linear models based on the learned features
for each target task;
2) CASO [5], which improves the ASO algorithm [1]
by including an additional regularizer in the objective
function and making use of alternating structure optimization to solve the convex relaxation efﬁciently;
3) RMTL [7], which learns multiple tasks simultaneously
and identiﬁes the irrelevant (outlier) tasks by making
use of both a low-rank structure, as well as a groupsparse structure;
4) GMTL [4], which is based on a neural network model
and uses gating of tasks to make some tasks more
similar than others.
For the proposed HEAR algorithm, MTL-FEAT, RMTL and
GMTL, we choose the parameters by cross-validation; for
CASO, we set the parameters according to [5].

HEAR
MTL−FEAT
CASO
RMTL
GMTL

1.6
1.4

RMSE

1.2
1
0.8
0.6
0.4
0.2
0

50

52

54
56
58
60
62
64
66
Number of Labeled Examples in Each Task

68

70

(a) No noise
HEAR
MTL−FEAT
CASO
RMTL
GMTL

1.8
1.6
1.4

RMSE

1.2
1
0.8
0.6
0.4
0.2

A. Comparison with Different Algorithms
1) Synthetic Data: We ﬁrst compare the algorithms on
a synthetic data set. It consists of 3 groups, each with 3
tasks. For each task, we randomly generate 100 examples,
which are described by 100 independent variables and 50
dependent variables. For each group of tasks, we use a single
coefﬁcient vector αt for the set of independent variables;
and for the tasks within the same group, their coefﬁcient
vectors βt,s for the set of dependent variables are obtained
by perturbing the product of a random matrix M (50 × 100)
with αt . Finally, the output y t,s is obtained by multiplying
the 2 sets of variables with the corresponding coefﬁcient
vectors, plus Gaussian noise with various standard deviation.
The comparison results are shown in Figure 1, where
the x-axis is the number of training examples, and the yaxis is the Root of Mean Squared Error (RMSE) averaged
over all the tasks and 10 runs. The two sub-ﬁgures show
the RMSE for different levels of Gaussian noise. From this
ﬁgure, we can see that HEAR performs much better than all
the competitors for multi-task learning with hierarchical task
relatedness. To be speciﬁc, when there is no noise in the data,
HEAR can perfectly recover the underlying model in terms
of the coefﬁcient vectors; when there is a small amount of
noise, HEAR outperforms the other 4 algorithms in terms of
both the average RMSE and its standard deviation.
2) Semiconductor Data: In this subsection, we show the
comparison results on a data set collected from a semiconductor manufacturing process. This manufacturing process deposits dielectric materials as capping ﬁlm on wafers,

0

50

52

54
56
58
60
62
64
66
Number of Labeled Examples in Each Task

68

70

(b) Gaussian noise with standard deviation 0.2
Figure 1. Comparison on synthetic data set: our proposed HEAR performs
the best for Gaussian noise with various standard deviation.

whose quality is mainly determined by the deposition thickness. For the purpose of our studies, we have collected
wafer data from 4 chambers and 2 sides per chamber. Each
produced wafer is described by 56 independent variables and
31 dependent variables. The drift and variation of both types
of variables can cause wafer quality variation. The set of
independent variables include pressure, power, temperature,
gas ﬂows, etc, which are subject to APC. These variables
determine the environment of the chamber and are shared
by the 2 sides of each chamber. On the other hand, the set of
dependent variables include impedance, electric bias, throttle
valve positions, etc, which are largely affected by the set of
independent variables.
Our data set consists of the measurements of 1651 wafers
together with their deposition thickness in a 5 month period.
After removing some outliers, there are around 200 examples
from each of the 8 chamber sides. As a pre-processing step,
the process variables and the outputs are normalized to have
mean 0 and standard deviation 1.
The test errors averaged over all the sides/tasks for all
three algorithms are shown in Figure 2, where the x-axis is

295
505

0.26

the number of labeled examples in each task, and the y-axis
is the RMSE average over all the tasks and 10 runs. This
ﬁgure shows that the performance of HEAR is consistently
better than the others under each training set size, especially
when the number of labeled examples is small. This is
due to the fact that HEAR leverages the grouping of the
tasks and imposes hierarchical task relatedness accordingly,
which better models the relationship between input process
variables and output wafer quality measurements.

HEAR
MTL−FEAT
CASO
RMTL
GMTL

Average classification error

0.24
0.22
0.2
0.18
0.16
0.14
0.12

HEAR
MTL−FEAT
CASO
RMTL
GMTL

0.46
0.44
0.42

0.1
250 260 270 280 290 300 310 320 330 340 350
Number of Labeled Examples in Each Task

0.4

Figure 3. Comparison on 20 newsgroups data set: our proposed HEAR
performs the best.

RMSE

0.38
0.36
0.34

vocabulary is closely related to the common vocabulary, thus
its coefﬁcient vector β t,s can be approximated based on αt .
Therefore, by leveraging such task relatedness, HEAR is able
to improve the performance of MTL-FEAT, CASO, RMTL
and GMTL.

0.32
0.3
0.28
0.26
80

84

88
92
96
100 104 108 112
Number of Labeled Examples in Each Task

116

120

Table I
G ROUP AND TASK DESCRIPTION FOR 20 NEWSGROUPS DATA SET.

Figure 2. Comparison on semiconductor data set: our proposed HEAR
performs the best.

G1T1

3) Generalization Study: Our proposed framework is
motivated by wafer quality prediction in semiconductor
manufacturing. In this subsection, we study how HEAR
generalizes to other domains, e.g., document classiﬁcation.
20 Newsgroups: We ﬁrst test the performance of HEAR
on 20 newsgroups data set [3]. This data set has a twolevel hierarchy. Each group of tasks corresponds to the
classiﬁcation between two top-level categories, and in each
single task we try to distinguish the documents in two
sub categories. Here the vocabulary common to all the
tasks corresponds to the independent variables, and the taskspeciﬁc vocabulary corresponds to the dependent variables.
Table 1 provides the details of the groups and tasks, where
the number following ‘G’ denotes the group index, the
number following ‘T’ denotes the task index in the group,
and the number in the parenthesis is the number of examples.
Similar experimental results are observed for data sets with
different groups and different tasks, and hence omitted for
brevity.
Figure 3 shows the comparison results on a data set with
2 groups, each having 2 tasks. The x-axis is the number of
labeled examples in each task, and the y-axis is the crossvalidation error averaged over all the tasks.
From this ﬁgure, we can see that HEAR outperforms
the other 4 competitors. This can be explained by the fact
that the common vocabulary shared by tasks in the same
group has the same impact on the output of these tasks,
thus the same coefﬁcient vector αt ; and the task-speciﬁc

G1T2
G2T1
G2T2

+1
-1
+1
-1
+1
-1
+1
-1

comp.graphics (581)
sci.crypt (594)
comp.sys.ibm.pc.hardware (587)
sci.electronics (591)
comp.sys.mac.hardware (575)
sci.med (594)
comp.windows.x (592)
sci.space (593)

ECML Discovery Challenge: We also study the performance of HEAR on the email spam data set from ECML
2006 discovery challenge1. In the second part, we are given
15 different users, and 400 emails per user. The classiﬁcation
of emails for each user corresponds to a single task. For our
studies, we form groups of tasks consisting of emails from
multiple users. Similar as before, the vocabulary common to
all the users corresponds to the independent variables, and
the user-speciﬁc vocabulary corresponds to the dependent
variables.
Figure 4 shows the comparison results on 2 data sets with
2 groups, each group having 2 tasks. The results on other
data sets are similar and hence omitted for brevity. From this
ﬁgure, we can see that the performance of HEAR is always
the best.
B. Time Complexity
Finally, we answer the second question. To this end,
we did experiments using synthetic data with respect to
1 http://www.ecmlpkdd2006.org/challenge.html

296
506

0.5

160
HEAR
MTL−FEAT
CASO
RMTL
GMTL

0.45

140

0.35

Time (second)

Average classification error

0.4

0.3
0.25

120

100

80

0.2
0.15

60
0.1

0

0.05
0

40

44

48
52
56
60
64
68
72
Number of Labeled Examples in Each Task

76

80

Figure 5. Processing time of HEAR scales linearly with the number of
training examples in each task.

(a) Problem 1
HEAR
MTL−FEAT
CASO
RMTL
GMTL

0.24

Average classification error

0.22

sides is considered a group of tasks. In this case, tasks
within the same group are related on the task-level, and
groups are related on the group-level. Furthermore, the input
process variables in the production process are naturally
partitioned into 2 sets according to their characteristics. The
proposed framework models the hierarchical task relatedness
by imposing different constraints on the coefﬁcient vectors
of the 2 sets. To solve this framework, we design the HEAR
algorithm based on block coordinate descent. It outperforms
existing MTL algorithms on both synthetic and real data
sets.

0.2
0.18
0.16
0.14
0.12
0.1
0.08
40

44

48
52
56
60
64
68
72
Number of Labeled Examples in Each Task

0.5
1
1.5
2
2.5
3
3.5
4
4
Number of Labeled Examples in Each Task
x 10

76

80

(b) Problem 2

R EFERENCES

Figure 4. Comparison on ECML Challenge data set: our proposed HEAR
performs the best for both problems.

[1] R. K. Ando and T. Zhang. A framework for learning
predictive structures from multiple tasks and unlabeled data.
Journal of Machine Learning Research, 6:1817–1853, 2005.

the number of training examples in each task. The data is
simulated as in Subsection V-A1. Each scenario consists
of 3 groups, each with 3 tasks. An example in a single
task is described by 100 independent variables and 100
dependent variables. The experiments have been performed
on a laptop with Intel Core i7-2720QM processor and 8
GB of RAM, equipped with Windows 7 operating system.
For each training set size, we perform the experiments 10
times and record the average computational time in seconds.
We plot the time in seconds against the training set size, as
shown in Figure 5. Clearly, the processing time increases
linearly with the number of training examples in each task,
which matches our analysis at the end of Subsection IV-D.

[2] A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task
feature learning. Machine Learning, 73(3):243–272, 2008.
[3] A. Asuncion and D. Newman. UCI machine learning repository, 2007.
[4] B. Bakker and T. Heskes. Task clustering and gating for
bayesian multitask learning. Journal of Machine Learning
Research, 4:83–99, 2003.
[5] J. Chen, L. Tang, J. Liu, and J. Ye. A convex formulation
for learning shared structures from multiple tasks. In ICML,
page 18, 2009.
[6] J. Chen, J. Zhou, and J. Ye. Integrating low-rank and groupsparse structures for robust multi-task learning. In KDD,
pages 42–50, 2011.

VI. C ONCLUSION
In this paper, we study the problem of multi-task learning
with hierarchical task relatedness, and propose an optimization framework that captures both task-level and group-level
relatedness. This is motivated by wafer quality prediction in
semiconductor manufacturing, where each task corresponds
to predicting the quality of wafers produced in a single
side of a chamber, and a chamber consisting of multiple

[7] J. Chen, J. Zhou, and J. Ye. Integrating low-rank and groupsparse structures for robust multi-task learning. In KDD,
pages 42–50, 2011.
[8] W. Dai, Q. Yang, G.-R. Xue, and Y. Yu. Boosting for transfer
learning. In ICML, pages 193–200, 2007.

297
507

[9] H. Fei and J. Huan. Structured feature selection and task
relationship inference for multi-task learning. In ICDM, 2011.

[21] S. Lynn, J. Ringwood, E. Ragnoli, S. McLoone, and
N. MacGearailt. Virtual metrology for plasma etch using
tool variables. In Advanced Semiconductor Manufacturing
Conference, 2009.

[10] J. Gao, W. Fan, J. Jiang, and J. Han. Knowledge transfer
via multiple model local structure mapping. In KDD, pages
283–291, 2008.

[22] L. Mihalkova, T. N. Huynh, and R. J. Mooney. Mapping
and revising markov logic networks for transfer learning. In
AAAI, 2007.

[11] J. He, Y. Liu, and R. D. Lawrence. Graph-based rare category
detection. In ICDM, pages 833–838, 2008.

[23] L. Mihalkova and R. J. Mooney. Transfer learning from
minimal target data by mapping across relational domains.
In IJCAI, pages 1163–1168, 2009.

[12] J. Huang, A. J. Smola, A. Gretton, K. M. Borgwardt, and
B. Schölkopf. Correcting sample selection bias by unlabeled
data. In NIPS, pages 601–608, 2006.

[24] S. J. Pan and Q. Yang. A survey on transfer learning. IEEE
Trans. Knowl. Data Eng., 22(10):1345–1359, 2010.

[13] L. Jacob, F. Bach, and J.-P. Vert. Clustered multi-task
learning: A convex formulation. In NIPS, pages 745–752,
2008.

[25] F. Wang, X. Wang, and T. Li. Semi-supervised multi-task
learning with task regularizations. In ICDM, pages 562–568,
2009.

[14] P. Kang, D. Kim, H.-J. Lee, S. Doh, and S. Cho. Virtual
metrology for run-to-run control in semiconductor manufacturing. Expert Systems with Applications, 38:2508–2522,
2011.

[26] Y. Xue, X. Liao, L. Carin, and B. Krishnapuram. Multitask learning for classiﬁcation with dirichlet process priors.
Journal of Machine Learning Research, 8:35–63, 2007.

[15] T. Kato, H. Kashima, M. Sugiyama, and K. Asai. Multi-task
learning via conic programming. In NIPS, 2007.

[27] X. Yang, S. Kim, and E. P. Xing. Heterogeneous multitask
learning with joint sparsity constraints. In NIPS, pages 2151–
2159, 2009.

[16] S. Kim and E. P. Xing. Tree-guided group lasso for multi-task
regression with structured sparsity. In ICML, pages 543–550,
2010.

[28] D. Zhang, J. He, Y. Liu, L. Si, and R. D. Lawrence. Multiview transfer learning with a large margin approach. In KDD,
pages 1208–1216, 2011.

[17] N. D. Lawrence and J. C. Platt. Learning to learn with the
informative vector machine. In ICML, 2004.

[29] Y. Zhang and J. G. Schneider. Learning multiple tasks with
a sparse matrix-normal penalty. In NIPS, pages 2550–2558,
2010.

[18] H. Liu, M. Palatucci, and J. Zhang. Blockwise coordinate
descent procedures for the multi-task lasso, with applications
to neural semantic basis discovery. In ICML, page 82, 2009.
[19] Q. Liu, X. Liao, and L. Carin. Semi-supervised multitask
learning. In NIPS, 2007.

[30] Y. Zhang and D. Y. Yeung. A convex formulation for learning
task relationships in multi-task learning. In UAI, pages 733–
742, 2010.

[20] D. G. Luenberger. Linear and Nonlinear Programming.
Addison-Wesley, Massachusetts, second edition, 1973.

[31] Y. Zhang, D. Y. Yeung, and Q. Xu. Probabilistic multi-task
feature selection. In NIPS, pages 2559–2567, 2010.

298
508

2010 IEEE International Conference on Data Mining Workshops

Ensemble-based Method for Task 2: Predicting Traffic Jam
Jingrui He, Qing He, Grzegorz Swirszcz, Yiannis Kamarianakis, Rick Lawrence, Wei Shen, Laura Wynter
Business Analytics and Mathematical Science, IBM Research, Yorktown Heights, New York 10598
{jingruhe, qhe, swirszcz, yiannis, ricklawr, wshen, lwynter}@us.ibm.com
test sets consist of 5000 samples (hours) each. Let Ai
(i = 1, . . . , 5000) denote the ith training hour, and Bj
(j = 1, . . . , 5000) denote the j th test hour. The evaluation
metric is based on the concept of Mean Average Precision
(MAP) from the domain of information retrieval adapted to
the specifics of this task. It takes the largest value when
the predicted sequence is exactly the same as the target
sequence and punishes any deviations from the target, such
as different length of the sequence, different order of road
segments, etc. Mistakes on early positions of the sequence
are punished more than later ones. Overall result for the test
set is calculated as an arithmetic average of values computed
for each sample. Each competing team may submit solutions
many times for the whole duration of the challenge. They are
evaluated instantly after submission and the resulting MAP
is visible to all teams. However, this result is only based on
the preliminary set, which comprises 35% of the test data.
And the final evaluation is based on the final set, which
comprises the remaining 65% of the test data.
Our solution has MAP 0.5580 on the preliminary set, and
0.55793 on the final set, which finished in second place
in the contest. Based on our experience, jammed roads in
the remaining 40 minutes are not strongly dependent on the
history, and a dominating effect is the overall frequency of a
road being jammed. This observation is consistent with the
good performance of the baseline, which always predicts the
most frequently jammed roads, as well as the close results
of different teams.
II. E NSEMBLE - BASED M ETHOD
In this section, we introduce our ensemble-based method.
The ensemble fuses information from several base predictors
in order to come up with a better combined predictor. It
consists of the following components.
1) Base predictors;
2) Fusing scheme;
3) Sequence length predictor;
4) Evaluation framework.
By constructing base predictors from various aspects, we
are able to collect useful information from different sources.
By fusing the predictors in different ways, we are able to
make the best out of each base predictor. By adaptively
determining the length of jammed road sequence in the
remaining 40 minutes, we are able to identify most of the
true jammed roads with a few false alarms. And by using
cross validation [2] as our evaluation framework, we are able

Abstract—In this paper, we describe our solution for ICDM
2010 Contest Task 2 (Jams), where the task is to predict future
where the next traffic jams will occur in morning rush hour,
given data gathered during the initial phase of this peak period.
Our solution, which is based on an ensemble approach, finished
Second in the final evaluation.
Keywords-ensemble; nearest-neighbor; cross validation;

I. I NTRODUCTION
ICDM 2010 Contest asks researchers to devise algorithms
that tackle problems of traffic flow prediction, for the
purpose of intelligent driver navigation and improved city
planning [1]. The data sets come from a highly realistic
simulator of vehicular traffic, Traffic Simulation Framework
(TSF), developed at the university of Warsaw. Simulations
employ the map of the city of Warsaw, Poland, taken from
OpenStreetMap project. The contest includes 3 tasks: Traffic,
Jams and GPS. In this paper, we focus on the second task,
which is to predict where the next jams will occur during
main phase of the morning peak, given the data gathered
during the initial phase of the peak. Such prediction could
be used to warn drivers in advance, before the jams actually
occur. In the given data sets, there are 35170 road segments
defined by 18716 different nodes, of which only 8631 road
segments are major roads whose maximum velocity is more
than 60km/h, and the remaining 26539 road segments are
minor roads whose maximum velocity is 60km/h.
The main challenges of this task can be summarized as
follows. First, the data provided are imprecise in terms that
they only contain ordered sequences of jammed streets. In
other words, detailed measurements of speed and number
of cars, as well as the time when the jam first occurs,
are missing. Second, the data cover only major roads that
constitute 25% of the whole road network. However, the
missing information related to minor roads may influence
jams on major roads.
In this task, data samples were generated from independent 1-hour long simulations, starting each time from
an almost empty road network, fed subsequently with cars
according to the selected distributions of start and destination
points. As input, we are given 5 road segments with road
work as well as a sequence of major roads where the
first jams occurred during the initial 20 minutes of the
simulation. The goal is to predict a sequence of major roads
where the next jams will occur in the next 40 minutes. The
sequences are ordered according to time of jam appearance
and their length may vary between samples. Training and
978-0-7695-4257-7/10 $26.00 © 2010 IEEE
DOI 10.1109/ICDMW.2010.54

1363

to pick a set of parameters which at least correspond to a
local optimum and avoid over-fitting. Next, we will elaborate
on each component in the following subsections.

the training set. In our experiments, the following similarity
measurements have been used,
[1] MAP1 : the MAP similarity between the sequence of
jammed roads in the initial 20 minutes of the training
hour and the sequence of jammed roads in the initial
20 minutes of the test hour;
[2] MAP2 : the MAP similarity between the reverse sequence of jammed roads in the initial 20 minutes of
the training hour and the reverse sequence of jammed
roads in the initial 20 minutes of the test hour;
[3] Simple1 : the number of common jammed roads in the
initial 20 minutes of the training hour and the initial 20
minutes of the test hour divided by the longer length
of the two sequences;
[4] Simple2 : the number of common jammed roads in the
remaining 40 minutes of the training hour and the
initial 20 minutes of the test hour divided by the longer
length of the two sequences;
[5] Simple3 : the number of common roads with road work
in the training hour and the test hour divided by 5.

A. Base Predictors
In our ensemble-base method, two types of base predictors
have been employed, namely geographic propagation predictors and nearest neighbor predictors [2]. They calculate the
likelihood of a road segment having jams in the remaining
40 minutes of a test hour, based on geographic information
and jam information from similar training hours.
1) Geographic Propagation Predictors: The intuition of
the geographic propagation predictors is to track where the
jammed traffic will flow based on the connectivity of the
road segments. To construct this type of predictors, we first
build connectivity matrix C, which is 35170 × 35170. Its
element C(i, j) is equal 1 if and only if the end node of
road segment i is the same as the start node of road segment
j; otherwise C(i, j) = 0. For each simulation hour in the
test set, since the drivers know ahead of the time which road
segments have road work, if road segment i has road work,
we would set the ith row and ith column of C to 0. In this
way, no vehicles would enter or exit such road segments.
Furthermore, we construct vector v0 (1×35170) based on the
jammed road segments in the initial 20 minutes. Its element
v0 (i) is set to 1 if and only if the ith road segment is jammed
in the initial 20 minutes and 0 otherwise. By multiplying
v0 with C, we get v1 , i.e., v1 = v0 × C. The nonzero
elements of v1 correspond to the road segments where the
jammed vehicles might flow once they exit the jammed
road segments in the first 20 minutes. Similarly, we define
v2 = v0 × C 2 and v3 = v0 × C 3 , whose nonzero elements
indicate where the jammed vehicles might flow after 2 and
3 hops, respectively. v1 , v2 and v3 are incorporated into the
ensemble as base predictors. Note that,
[1] v0 is NOT used as a base predictor since road segments having jams in the initial 20 minutes cannot be
included in the predicted sequence for the remaining
40 minutes;
[2] Based on our experiments, higher-order propagation
vectors do not improve the performance. Therefore,
they are not used as base predictors.
We also experimented with variants of C, such as the
normalized version of C whose row sums are 1 and the
variant of C whose elements reflect the minimum travel
time from one road segment to another. However, we found
the above binary version works the best based on cross
validation, which will be introduced in Subsection II-D.
2) Nearest Neighbor Predictors: The intuition of the
nearest neighbor predictors is to make use of the information
from similar training hours to help predict the jammed roads
in the remaining 40 minutes of a test hour. To construct this
type of predictors, for each simulation hour in the test set,
we first calculate its similarity to each simulation hour in

The first similarity measurement (MAP1 ) is straight-forward.
The second one (MAP2 ) is based on the assumption that the
road segments having jams later in the initial 20 minutes
may have a bigger influence over the jammed roads in the
remaining 40 minutes. The third similarity measurement
(Simple1 ) is a simplified version of MAP1 in that it ignores
the order of the sequences, and considers two simulation
hours to be similar to each other if they share many common
jammed roads in the initial 20 minutes. The fourth similarity
measurement (Simple2 ) is similar to Simple1 except that for
the training hour, we use the sequence of jammed roads in
the remaining 40 minutes instead of the initial 20 minutes.
This is because if the remaining 40 minutes of the training
hour and the initial 20 minutes of the test hour share many
jammed roads, then the order information hidden in the
initial 20 minutes of the training hour may help rank the
jammed roads in the remaining 40 minutes of the test hour.
The last similarity measurement (Simple3 ) considers two
simulation hours to be similar to each other if they have
common roads with road work. Surprisingly, when using
each similarity measurement alone to predict jammed roads
in the remaining 40 minutes of a test hour, Simple1 performs
the best, and combining all five of them gives even better
performance. We also experimented with other similarity
measurements, such as the MAP similarity between the
sequence of jammed roads in the remaining 40 minutes of
the training hour and the sequence of jammed roads in the
initial 20 minutes of the test hour, but the above combination
gives the best performance based on cross validation.
Once we have calculated the similarity between the j th
test hour Bj and each training hour, we find its k nearest
neighbors which correspond to the k training hours with the
maximum similarity to Bj . Let Aj1 , . . . , Ajk denote these

1364

which actually have jams in the remaining 40 minutes fall
beyond the cutoff point. Therefore, the cutoff point should
be a little larger than the length of true sequence in order to
include as many jammed roads as possible without having
too many false alarms. In our experiments, for each test hour,
we first calculate the average number of jammed roads in
the remaining 40 minutes among its neighbors, and then
multiply it by 1.13 to get the cutoff point. However, if the
length of the true sequence is particularly large, this scheme
tends to underestimate the cutoff point. Therefore, to address
this problem, we make the following modification to the
cutoff point. If the score of the road segment at the cutoff
point is larger than 0.19, which often indicates a long true
sequence, we would extend the predicted sequence until the
score of the road segment is less than 0.19.
D. Evaluation Framework
Our method involves 15 parameters. A simple way to tune
these parameters is to generate output files with different
parameter settings, upload the files, and use the MAP value
returned by the server to determine the optimal setting. There
are two potential problems with this evaluation scheme.
First, each team is only allowed 100 submissions, which is
clearly not enough for such a huge parameter space. Second
and more seriously, the result returned by the server is only
based on the preliminary set, which comprises 35% of the
test data. Therefore, by greedily adjusting the parameters
to fit the preliminary set, we are prone to over-fitting. In
other words, good performance on the preliminary set does
not guarantee good generalization performance on the final
set, which comprises 65% of the test data. To address this
problem, we use 10-fold cross validation on the training set
as the evaluation framework. It is often the case that the
result returned by the server on the preliminary set is very
close to our result from cross validation. For example, our
final solution has MAP 0.5573 based on cross validation in
the training set, 0.5580 based on the preliminary set, and
0.55793 based on the final set. In this way, we effectively
avoid over-fitting.
III. C ONCLUSION
In this paper, we described our ensemble-based method
for Task 2 Jams. It incorporates information from various
base predictors, combines them in two different ways,
adaptively determines the optimal sequence length, and is
evaluated via cross validation on the training set. The good
performance on the final test set proves its effectiveness.
ACKNOWLEDGMENT
We thank Yan Liu for helpful discussions, and we thank
the contest organizers for such a fun competition.
R EFERENCES

neighbors. For each of these neighbors, we assign a score
to the jammed roads in both the initial 20 minutes and the
remaining 40 minutes. Take MAP1 and Aj1 as an example.
Let MAP1 (j, 1) denote the similarity between Bj and Aj1 ,
and lj1 denote the total number of jammed roads in Aj1 .
Then the ith jammed road is assigned the following score
(x +

y(lj1 + 1 − i)
) × MAP1 (j, 1)d , i = 1, . . . , lj1
2lj1

where x, y and d are three parameters to be tuned via
cross validation. Then we add the scores from the k nearest
neighbors together to obtain the base predictor. The base
predictors from the other similarity measurements can be
obtained similarly. Note that k is also tuned via cross validation, and different similarity measurements have different
optimal values for k.
B. Fusing Scheme
To combine the nearest neighbor predictors, we have two
options.
1) Combining the scores obtained from different similarity measurements in a linear fashion;
2) Combining the similarity measurements as a single
one with which to obtain the base predictor.
Based on our experiments, the second option gives better
performance, with MAP almost 1% more than the first
option. Therefore, the second option is used in our method.
The coefficients of different similarity measurements are as
follows: 0.9 for MAP1 , 0.6 for MAP2 , 0.8 for Simple1 , 0.2
for Simple2 , and 1.5 for Simple3 , which are tuned via cross
validation. In this way, we obtain only one base predictor
based on nearest neighbors. For this predictor, we used 36
nearest neighbors, x = 10, y = 1 and d = 4.
Next, we combine the nearest neighbor predictor with
geographic propagation predictors. Notice that for a test
hour, each base predictor essentially assigns a score for
each road segment, with a higher score indicating more
chance of having jams in the remaining 40 minutes. In
our method, we combine them in a linear fashion. The
coefficients of different base predictors are as follows: 1
for nearest neighbor predictor, 0.044 for both v1 and v2 ,
and 0.0011 for v3 . These coefficients are tuned via cross
validation.
C. Sequence Length Predictor
After combining the base predictors, we get a score for
each road segment. Then we rank the road segments with
their scores from large to small. The road segments on the
top of the list are likely to have jams in the remaining 40
minutes of the test hour. Next, we need to pick a cutoff
point before which the road segments will be included in
the predicted sequence. Here, our key observation is that, if
we knew the length of the true sequence and used that as
the cutoff point, the average MAP would be low. The reason
may be explained as follows. In the predicted sequence, we
tend to have some false alarms, and some road segments

[1] IEEE icdm contest: Tomtom traffic prediction for intelligent
gps navigation, 2010.
[2] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of
Statistical Learning: Data Mining, Inference, and Prediction.
Springer, New York, NY 10013, USA, 2001.

1365

Co-Clustering based Dual Prediction for
Cargo Pricing Optimization
Yada Zhu

Hongxia Yang

Jingrui He

IBM Research
Yorktown Heights, NY 10598

Yahoo! Inc
Sunnyvale, California 94089

Arizona State University
Tempe, AZ 85281

yzhu@us.ibm.com

hongxia@yahoo-inc.com

jingrui.he@asu.edu

ABSTRACT

General Terms

This paper targets the problem of cargo pricing optimization
in the air cargo business. Given the features associated with
a pair of origination and destination, how can we simultaneously predict both the optimal price for the bid stage and
the outcome of the transaction (win rate) in the decision
stage? In addition, it is often the case that the matrix representing pairs of originations and destinations has a block
structure, i.e., the originations and destinations can be coclustered such that the predictive models are similar within
the same co-cluster, and exhibit significant variation among
diﬀerent co-clusters. How can we uncover the co-clusters
of originations and destinations while constructing the dual
predictive models for the two stages?
We take the first step at addressing these problems. In
particular, we propose a probabilistic framework to simultaneously construct dual predictive models and uncover the
co-clusters of originations and destinations. It maximizes
the conditional probability of observing the responses from
both the quotation stage and the decision stage, given the
features and the co-clusters. By introducing an auxiliary distribution based on the co-clustering assumption, such conditional probability can be converted into an objective function. To minimize the objective function, we propose the
COCOA algorithm, which will generate both the suite of
predictive models for all the pairs of originations and destinations, as well as the co-clusters consisting of similar pairs.
Experimental results on both synthetic data and real data
from cargo price bidding demonstrate the eﬀectiveness and
eﬃciency of the proposed algorithm.

Algorithms; Performance

Keywords
Co-clustering; dual predictive models

1.

INTRODUCTION

Revenue management in the air cargo business is a fast
growing field. It usually consists of two stages: the bidding
stage where the vendor provides a bidding price with respect
to a pair of origination and destination, or OD pair, and the
decision stage where the customer makes a decision whether
to accept this price or not. Compared to other industries
such as passenger airlines or hotels, this field is more challenging in multiple respects due to the specific characteristics of cargo inventory, cargo business, and cargo booking
behavior. This renders traditional yield management models
ineﬀective or ineﬃcient, thus necessitates the development
of new models.

Categories and Subject Descriptors
I.5.2 [Pattern Recognition]: Design Methodology—classifier design and evaluation; I.5.3 [Pattern Recognition]:
clustering—algorithm; I.5.4 [Pattern Recognition]: Applications

Figure 1: Transaction size of diﬀerent OD pairs.

Here we focus on the following three major challenges.
First, as illustrated in Figure 1, the number of transactions
varies significantly among diﬀerent OD pairs. For those pairs
whose transaction volume is small, the resulting predictive
model tends to be inaccurate due to the lack of training
data. Second, most existing techniques construct predictive models for the two stages separately, thus prevent key
information to be shared by these models. Third, the originations and destinations can be naturally co-clustered such
that the underlying predictive models are similar within each
co-cluster. This property has not been exploited for improv-

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from Permissions@acm.org.
KDD ’15, August 10-13, 2015, Sydney, NSW, Australia
c 2015 ACM. ISBN 978-1-4503-3664-2/15/08 ...$15.00.
⃝
DOI: http://dx.doi.org/10.1145/2783258.2783337.

1583

ing model performance and gaining insights into diﬀerent
OD pairs.
To address these challenges, in this paper, we propose a
novel probabilistic framework to simultaneously construct
dual predictive models for each OD pair, while uncovering
the co-clusters of originations and destinations. It is based
on the conditional probability of observing the two types of
responses from the two stages, given the features with respect to the OD pair, and the mappings for co-clustering.
We approximate this probability using an auxiliary distribution that satisfies the co-clustering assumption, and develop
a special case of the framework based on generalized linear
models. Furthermore, we propose an eﬀective and eﬃcient
algorithm named COCOA for solving the resulting optimization problem, whose computational complexity is linear with
respect to the total number of OD pairs. Finally, we evaluate
the performance of COCOA from various aspects using both
synthetic data and real data on cargo price optimization.
To the best of our knowledge, we are the first to tackle
the problem of cargo price optimization from a holistic perspective. In other words, we encapsulate multiple correlated
models into a single probabilistic framework. The main advantage is that it allows key information to be shared among
the diﬀerent models. For example, the co-clusters provide
regularization for the dual predictive models, and accurate
dual predictive models in turn will improve the performance
of co-clustering. Notice that for the OD pairs with a small
transaction volume, such regularization helps alleviate the
problem of small training set size.
The main contributions of this paper can be summarized
as follows.

First-order methods assume that labels are independent,
and multi-label learning problem can be transformed into a
number of independent binary classification problems, e.g.,
ML-kNN [40]. Second-order approaches consider the pairwise relations between labels. Then the multi-label learning
problem is transformed into the label ranking problem which
aims at properly ranking every relevant-irrelevant label pair
for each training instance, e.g., Rank-SVM [10]. Various
methods have been proposed for high-order label correlation
learning. For example, LEAD [39] employed Bayesian network to encode the conditional dependencies of the labels as
well as the feature set, with the feature set as the common
parent of all labels. The LS-ML algorithm was proposed
for multi-label learning to extract common subspace shared
among multiple labels [18]. A hypergraph spectral learning formulation was proposed for multi-label classification
to exploit the correlation information among diﬀerent labels
using hypergraph [31]. TRAM [20] studied the problem of
transductive multi-label learning by utilizing the information from both labeled and unlabeled data. LIFT [38] constructed features specific to each label by conducting clustering analysis on its positive and negative instances, and then
performed training and testing by querying the clustering
results. MAHR [15] aimed to discover the label relationship
via a boosting approach with a hypothesis reuse mechanism.
A generic empirical risk minimization (ERM) framework was
proposed for large-scale multi-label learning [36]. A theoretical analysis on multi-label consistency was proposed in [12].
The authors proved a necessary and suﬃcient condition for
the consistency of multi-label learning based on surrogate
loss functions. Another related work is MLLOC [16], which
assumed that the label correlation may be shared by only a
subset of instances rather than all the instances.
Our problem setting for cargo pricing optimization is different from multi-label learning. This can be seen from the
fact that the two types of responses are obtained based on
diﬀerent sets of inputs: for the bidding stage, the inputs
include the features for each OD pair; and for the decision
stage, in addition to these features, the inputs also include
the estimated price from the predictive model of the bidding
stage. Furthermore, in our proposed framework, we leverage
the intrinsic co-clusters of originations and destinations to
facilitate information sharing, which is particularly beneficial for those OD pairs with a small transaction volume.

1. A novel probabilistic framework for cargo price optimization, which leverages the intrinsic co-clusters of
originations and destinations to construct dual predictive models for all pairs of originations and destinations;
2. An eﬀective and eﬃcient algorithm named COCOA for
solving the resulting optimization problem;
3. Experimental results on both synthetic and real data
sets demonstrating the performance of COCOA.
The rest of the paper is organized as follows. In Section 2,
we briefly review the related work. The probabilistic framework for simultaneous dual prediction and co-clustering is
proposed in Section 3, where we also present the COCOA
algorithm. Section 4 shows promising results on both the
synthetic data as well as a real data set for air cargo price
optimization. Finally, we conclude in Section 5.

2.2

Multi-Way Clustering

Diﬀerent from traditional clustering techniques [17], which
are designed to group objects so as to maximize within cluster similarity and between cluster dissimilarity, for sparse relational data, co-clustering or bi-clustering methods [24] aim
at simultaneously cluster objects of each type. These methods typically produce groupings of better quality by leveraging clusters of other types in the similarity measure [14]. The
information-theoretic co-clustering method [8] is among the
first to address this problem, which monotonically increases
the preserved mutual information by intertwining the row
and column clustering. Follow up work includes the generative model for evolutionary heterogeneous clusters in dynamic networks [32], the evolutionary co-clustering method
proposed in [19], the MMRC model proposed in [23], the
minimum Bregman information principle proposed in [1],
the general binary clustering model and its variations proposed in [21], minimum sum-squared residue co-clustering

2. RELATED WORK
In this section, we review the related work on multi-label
learning, multi-way clustering, and cargo pricing optimization.

2.1 Multi-Label Learning
Multi-label learning studies the problem where each example is associated with a set of labels [34]. One key issue is to exploit correlations or dependencies among multiple labels. According to [39], existing strategies for label correlation exploitation can be grouped into three categories: first-order, second-order, and high-order approaches.

1584

proposed in [6], etc. The proposed technique is also related to our previous work in [41], where we studied the
co-clustering of multiple time series that fit into a matrix.
Co-clustering has been generalized to handle more than
two object types, i.e., multi-way clustering. Examples include Consistent Bipartite Graph Co-partitioning (CBGC) [11],
which aims at collectively clustering star-shaped relationships among diﬀerent types of objects; spectral relational
clustering [22], which iteratively embeds each type of objects
into low dimensional spaces and benefits from the interactions among the hidden structures of diﬀerent types; collective matrix factorization [29], which assumes shared parameters among factors when an entity participates in multiple
relations; etc. Furthermore, researchers have proposed various techniques to automatically determine the number of
clusters for each object type, such as cross-associations [3],
AutoPart [2], PaCK [14], etc.
The major diﬀerence between existing methods for multiway clustering and our proposed work is as follows. Here
the inputs of co-clustering are the dual predictive models
for both the bidding stage and the decision stage, and our
goal is to jointly infer the mappings for co-clustering as well
as the dual predictive models.

2.3 Pricing Optimization for Revenue Management
The air cargo industry has substantially grown over the
past decades, driving the need of a structured environment
with the explicit goal of maximizing revenues by oﬀering
optimized bidding prices. Air cargo companies use bidding
price to accept/reject incoming bookings: if the rate of the
booking is lower than the bidding price value then the booking is rejected, otherwise it is accepted. Bidding price controls are revenue based and have the advantages of being
simple, having a natural interpretation as the marginal value
of a given resource, and have a very good revenue performance [33, 5].
Optimal bidding price methods were introduced [30], and
extended by [28], and [35]. [4] addressed the issue of origindestination-specific demand, which is common for low fare
passengers cargo, versus the itinerary-specific demand, widely
used in the passenger models. They extend three popular
models to incorporate origin-destination demand and introduce a routing algorithm tailored towards the special structure of the flight networks and their objectives. The simulation results report the superiority of an extended probabilistic model over a first come first serve policy applied to cargo
revenue management. [26] proposed a dual ascent scheme to
solve the Lagrangian of the probabilistic model used in [4].
Our proposed framework is significantly diﬀerent from existing techniques due to the fact that it addresses the problem of pricing optimization from a holistic perspective. In
particular, it bridges the bidding stage and the decision
stage by jointly learning the dual predictive models, and
it leverages the intrinsic co-clusters of originations and destinations to enable information sharing among diﬀerent OD
pairs. Therefore, it is able to improve the performance of
both predictive models, which eventually lead to increased
revenue.

the co-clusters of originations and destinations, followed by
the introduction of the COCOA algorithm for solving the
optimization problem.

3.1

Notation

Suppose that there are O originations and D destinations.
Let xi,j,k ∈ Rd denote the features extracted with respect to
the ith origination and the j th destination for the kth transaction, i = 1, . . . , O, j = 1, . . . , D, k = 1, . . . , Ki,j , where
Ki,j denotes the number of transactions with respect to the
ith origination and the j th destination. For xi,j,k , we aim to
(1)
predict two types of responses: yi,j,k ∈ R+ , which denotes
(2)

the quoted price in the bidding stage, and yi,j,k ∈ {0, 1},
which denotes the outcome of the transaction (successful or
not) in the decision stage. Notice that our problem setting
is diﬀerent from traditional multi-label learning [37] in the
(1)
sense that the estimated ŷi,j,k is a function of xi,j,k , and
(2)

(1)

the estimated ŷi,j,k is a function of both xi,j,k and ŷi,j,k ;
whereas multi-label learning assumes that the prediction of
diﬀerent labels is based on the same set of inputs. Furthermore, in our proposed probabilistic framework, we exploit the 2-dimensional structure formed by combinations of
O originations and D destinations in order to gain deeper
understanding of the groupings of originations and destinations, which in turn help improve the predictive models.

3.2

Probabilistic Framework

We propose to use generalized linear models to predict
(1)
(2)
(1)
both types of responses yi,j,k and yi,j,k . Let β i,j ∈ Rd and
(2)

β i,j ∈ Rd+1 denote the vectors of unknown parameters in
the two models respectively. For example, we could use the
(1)
(1)
identity link function g −1 (x′i,j,k β i,j ) = x′i,j,k β i,j for the
(1)

prediction of real-valued yi,j,k , which leads to the linear regression model; and the logit link function g −1 ([x′i,j,k , ŷi,j,k ]β i,j )
(1)

=

(2)

1
1+exp(−[x′i,j,k ,ŷi,j,k ]β i,j )
(1)

(2)

for the prediction of binary yi,j,k ,

which leads to the logistic regression model.
Notice that for each stage s = 1, 2, we can construct an
(s)
O × D array B (s) such that B i,j , the element in the ith row
(s)

and the j th column, is set to β i,j . We assume that the rows
and columns of B (s) can be re-arranged such that B (s) has
a block structure where the elements within the same block
are similar to each other, and the elements across diﬀerent
blocks are dissimilar. This is equivalent to co-clustering the
O originations to R row clusters, and the D destinations
to C column clusters. Furthermore, in pricing optimization, it is usually the case that the block structure is shared
across the two stages. Let u1 , . . . , uO and v1 , . . . , vD denote
the O originations and D destinations respectively; Let ΦR
denote the mapping from each origination (u1 , . . . , uO ) to
one of the R row clusters (û1 , . . . , ûR ), and ΦC denote the
mapping from each destination (v1 , . . . , vD ) to one of the
C column clusters (v̂1 , . . . , v̂C ). Following [41, 9], given ΦR
and ΦC such that ΦR (ui ) = ûr and ΦC (vj ) = v̂c , we assume
that the probability p(s) (β (s) , ui , vj |ΦR , ΦC ) of having β (s)
for the combination of the ith origination and the j th destination can be approximated with an auxiliary distribution
q (s) (β (s) , ui , vj |ΦR , ΦC ) with the following property.

3. THE PROPOSED FRAMEWORK
In this section, we propose a probabilistic framework to simultaneously construct dual predictive models, and uncover

1585

(2)

3.3

Objective Function

In this subsection, we specify the probabilities used in
Equation 3, which originate from the application of pricing
optimization.
(1)
For predicting yi,j,k , we use linear regression model, and

(s)

p(s) (β (s) , ui , vj |ΦR , ΦC ) = p(s) (β i,j |ΦR , ΦC )
≈ q (s) (β (s) , ui , vj |ΦR , ΦC )
. (s)
= µi,j p(ûr , v̂c )p(s) (ui |ûr )p(s) (vj |v̂c )p(s) (β (s) |ui )p(s) (β (s) |vj )
(1)

log p(yi,j,k |xi,j,k , β i,j ) = − 2σ1 2 ∥yi,j,k −x′i,j,k β i,j ∥2 . For pre(1)

(1)

(1)

(1)

0

(2)

(s)

where µi,j is a normalization parameter such that q (s) (·) is a
valid probability distribution. According to Equation 1, the
auxiliary distribution q (s) (β (s) , ui , vj |ΦR , ΦC ) reflects the coclustering assumption, and it can be decomposed into five
non-constant terms, all of which are derived from p(s) (β (s) , ui , vj ):
p(ûr , v̂c ), which is the joint probability of the rth row cluster
and the cth column cluster; p(s) (ui |ûr ) (p(s) (vj |v̂c )), which is
the probability of having the ith origination ui (the j th destination vj ) in the rth row cluster (the cth column cluster);
and p(s) (β (s) |ui ) (p(s) (β (s) |vj )), which is the probability of
having β (s) given the ith origination (the j th destination).
Notice that p(1) (ûr , v̂c ) = p(2) (ûr , v̂c ) due to the assumption that the block structure is shared by B (1) and B (2) .
Therefore, we omit the superscript of this term for brevity.
Lemma 3.1 in [41] shows that certain probabilities derived
from p(s) (·) are preserved in the auxiliary distribution q (s) (·),
including:
q(ûr,: ) = p(ûr,: ), q(v̂:,c ) = p(v̂:,c ), q(ûr,: , v̂:,c ) = p(ûr,: , v̂:,c )
q (s) (ui,: |ûr,: ) = p(s) (ui,: |ûr,: ), q (s) (v:,j |v̂:,c ) = p(s) (v:,j |v̂:,c )
(2)

k

∑

(1)

(1)

(2)

(1)

(2)

{log p(yi,j,k |xi,j,k , β i,j ) + log p(yi,j,k |xi,j,k , yi,j,k , β i,j )}

i,j,k

∑ ∑
(s)
(
log µi,j p(ûr , v̂c )

r

+

∑
c

(s)
(s)
1
∥β i,j −Ep(s) |ui {β i,j }∥2 ),
(s)
2(σi )2
(s)
(s)
1
exp(− (s)
∥β i,j − Ep(s) |vj {β i,j }∥2 ),
2(σ
)2

(s)

and p(s) (β i,j |vj ) ∝

j

(s)

(s)

where Ep(s) |ui {β i,j } and Ep(s) |vj {β i,j } are the expectation
(s)

of β i,j with respect to p(s) (·) for the ith origination and the
(s)

th

(s)

j destination respectively, σi and σj are two positive
constants. Furthermore, it is straight-forward to see that
the MLE estimate of both expectations can be expressed as
(s)
origination-wise and destination-wise average, i.e., Ep(s) |ui {β i,j } ≈
∑
∑
(s) . 1
(s)
(s)
(s) . 1
(s)
β i,: = D
j β i,j , Ep(s) |vj {β i,j } ≈ β :,j = O
i β i,j .
Before specifying probabilities p(s) (ui |ûr ) and p(s) (vj |v̂c ),
we first compute the expectations of the vector β (s) with
respect to each row/column cluster based on q (s) (·). First
of all, the conditional distribution of the vector β (s) given
the rth row cluster can be expressed as follows.

ΦR (ui )=ûr
ΦC (vj )=v̂c

s

i,j

+

(s)

tributions, i.e., p(s) (β i,j |ui ) ∝ exp(−

· p(s) (β (s) |ui )p(s) (β (s) |vj )

]
∑[
(1)
(1)
(2)
(1)
(2)
+
log p(yi,j,k |xi,j,k , β i,j ) + log p(yi,j,k |xi,j,k , yi,j,k , β i,j ) }

s

(s)

and p(s) (β i,j |vj ), we assume that they follow Gaussian dis-

c

(s)

log p(yi,j,k , β i,j |xi,j,k , ΦR , ΦC )
∑ ∑
(s)
=
{
log p(s) (β i,j |ΦR , ΦC )

∑

(s)

. For p(s) (β i,j |ui )

(s)
(β (s) , ui , vj )
ΦR (ui )=ûr q
c
q(β
,
û
)
Φ
(v
)=v̂
r
c
j
C
q (s) (β (s) |ûr ) =
=
q(ûr )
p(s) (ûr )
∑
∑
(s)
=
µi,j p(v̂c |ûr )p(s) (ui |ûr )p(s) (vj |v̂c )

(s)

+

(2)

(s)

the vectors of parameters β i,j given the features xi,j,k , and
the mappings ΦR , ΦC ) can be expressed as follows.

≈

(1)

|xi,j,k , yi,j,k , β i,j ) =

(2)
(1)
(2)
exp(yi,j,k [x′i,j,k ,yi,j,k ]β i,j )
(1)
(2)
1+exp([x′i,j,k ,yi,j,k ]β i,j )

∑ ∑

Based on the above discussion, the conditional probability
(s)
of observing the data (the two types of responses yi,j,k , and

(s)

(2)

dicting yi,j,k , we use logistic regression model, and log p(yi,j,k

∑
(s) .
β̂ r,: = Eq(s) |ûr {β (s) } =

r,c

∑

log p

(s)

(ui |ûr )p

(s)

where we repeatedly applied Equation 2 to replace the probabilities derived from q (s) (·) with those derived from p(s) (·).
As discussed before, both p(s) (β (s) |ui ) and p(s) (β (s) |vj ) follow Gaussian distributions. Therefore, the expectation of
β (s) given ûr can be derived as follows.

(s)
(β i,j |ui )

c

ΦR (ui )=ûr

∑

(s)

log p(s) (vj |v̂c )p(s) (β i,j |vj ))

∑

(s)

(3)

· p(s) (ui |ûr )p(vj |v̂c ) ·

ΦC (ui )=ûr

In Equation 3, the overall probability is approximated by the
sum of five terms: the first two terms come from the gen(2)
(1)
eralized linear models to predict yi,j,k and yi,j,k ; the third
term is fixed given ΦR and ΦC ; the fourth term measures the
(s)
probability of having β i,j for the ith origination of the rth
row cluster; and the last term measures the probability of
(s)
having β i,j for the j th destination of the cth column cluster.

p(v̂c |ûr )

ΦR (ui )=ûr
ΦC (vj )=v̂c
(s)

σj2 β i,: + σi2 β :,j
σi2 + σj2

(4)

Similarly, the expectation of β (s) given v̂c can be derived as
follows.
∑
(s) .
β̂ :,c = Eq(s) |v̂c {β (s) } =
r

(s)

Finally, both the vectors of parameters β i,j and the mappings ΦR , ΦC can be obtained by maximizing Equation 3
with specific choices of the probabilities.

∑

(s)

· p(s) (ui |ûr )p(vj |v̂c ) ·

1586

p(ûr |v̂c )

ΦR (ui )=ûr
ΦC (vj )=v̂c
(s)

σj2 β i,: + σi2 β :,j
σi2 + σj2

(5)

Using these expectations, p(s) (ui |ûr ) and p(s) (vj |v̂c ) can be
specified as follows.
p(s) (ui |ûr ) ∝ exp(−
p(s) (vi |v̂c ) ∝ exp(−

1
(s)

(σr )2
1
(s)
(σc )2

update both p(s) (ui |ûr ) and p(s) (vj |v̂c ) based on the current
(s)

(s)

(s)

∥β i,: − β̂ r,: ∥2 )
(s)

∥β :,j −

Algorithm 1 COCOA Algorithm
(s)

(s)
β̂ :,c ∥2 )

Input: xi,j,k , y i,j,k , R, C, α1 , α2 , α3 , α4 , α5 , n1 , n2

(6)

Output:

Based on the above specified probabilities, we have the following objective function, which is the negative log probability of observing the data. Minimizing the objective function
(s)
with respect to β i,j , ΦR , ΦC will lead to the dual predictive
models with respect to the bidding price and the outcome
of the transaction, as well as the co-clustering of origination/destination pairs.
(s)

f (β i,j , ΦR , ΦC ) =

∑

(2)
(1)
(2)
(1)
(2)
− α1 yi,j,k ([x′i,j,k , yi,j,k ]β i,j ) + α1 log(1 + exp([x′i,j,k , yi,j,k ]β i,j )} 6:
∑
∑
∑ (s)
∑
(s)
(s)
(s)
∥β i,j − β i,: ∥2 ]
+
{α2
[∥β i,: − β̂ r,: ∥2 + α3

+ α4

r

∑
c

ΦR (ui )=ûr

∑

(s)

(s)

[∥β :,j − β̂ :,c ∥2 + α5

∑

j
(s)

7:

(7)
where α1 , . . . , α5 are constants that depend on
(s)

(s)
σ0 , σi ,

8:
9:

(s)
σj ,

(s)

(s)

(s)

(s)

exp([x′i,j,k , yi,j,k ]β i,j )} + α3 ∥β i,j − β i,: ∥2 + α5 ∥β i,j −
(1)

(2)

(s)

(s)

(s)

β :,j ∥2 , i = 1, . . . , O, j = 1, . . . , D;
∑ (s)
∑ (s)
(s)
(s)
1
1
Update β i,: = O
j β i,j and β :,j = D
i β i,j , s =
1, 2, i = 1, . . . , O, j = 1, . . . , D;
for t′ = 1 to n2 do
(s)
Compute β̂ r,: using Equation 4, r = 1, . . . , R;
(s)

10:
11:
12:
13:
14:
15:
16:
17:
18:
19:

Compute β̂ :,c using Equation 5, c = 1, . . . , C;
for i = 1 to O do
∑
(s)
(s)
Let r̂ ← arg minr 2s=1 ∥β i,: − β̂ r,: ∥2 ;
Update ΦR (ui ) ← ûr̂ ;
end for
for j = 1 to D do
∑
(s)
(s)
Let ĉ ← arg minc 2s=1 ∥β :,j − β̂ :,c ∥2 ;
Update ΦC (vj ) ← v̂ĉ ;
end for
Update p(s) (ui |ûr ) and p(s) (vj |v̂c ) using Equation 6;
20:
end for
21: end for

σr , and σc .

3.4 COCOA Algorithm
To minimize the objective function in Equation 7, we propose the following algorithm named COCOA based on block
coordinate descent, which is described in Algorithm 1.
The COCOA algorithm works as follows. It takes as input
(1)
(2)
the features xi,j,k , two types of responses yi,j,k and yi,j,k ,
the total number of row clusters R, the total number of
column clusters C, parameters α1 , . . . , α5 , and numbers of
iteration steps n1 , n2 . Then it proceeds by alternating the
(s)
optimization with respect to β i,j and ΦR , ΦC . Finally, it
(s)

outputs both the vectors β i,j , as well as the two mappings
ΦR and ΦC that generate the co-clustering of O originations
and D destinations.
(s)
To be specific, in Steps 1 and 2, we initialize both β i,: and

3.5

Discussions

In this subsection, we discuss the proposed COCOA algorithm from various aspects.
(s)
First of all, in COCOA, β i,j is obtained via regularized
risk minimization. In the first iteration of the outer loop,
Steps 5 and 6 are reduced to ridge regression and L2 regularized logistic regression respectively. In the following iterations, both are regularized by the origination-wise and
destination-wise average. Notice that in the training stage,
(2)
for the prediction of yi,j,k , an alternative choice is to use

(s)
β :,j

to be 0 vector, and initialize both ΦR and ΦC by randomly assigning each origination/destination to one of the
row/column clusters. Then we initialize both p(s) (ui |ûr ) and
p(s) (vj |v̂c ) assuming uniform distribution among the originations/destinations within the same row/column cluster.
Next we repeat the following steps n1 times until conver(s)
gence. In Steps 5 and 6, we solve for β i,j via regularized risk
minimization. Notice that here we have two regularization
(s)
(s)
terms using β i,: and β :,j respectively. In Step 7, we update
(s)

x′i,j,k β (1)i,j ∥2 + α3 ∥β i,j − β i,: ∥2 + α5 ∥β i,j − β :,j ∥2 ,
i = 1, . . . , O, j = 1, . . . , D;
(2)
Solve
for
β i,j
by
minimizing
∑
(2)
(1)
(2)
′
+
α1 log(1
+
k −α1 yi,j,k ([xi,j,k , yi,j,k ]β i,j )
(s)

(s)

∥β i,j − β :,j ∥2 ]}

i

Φ2 (vj )=v̂c

ΦR , ΦC
(s)
(s)
β i,: and β :,j

(s)

(1)

i,j,k

s

(s)
β i,j ,

1: Initialize
to be 0 vectors, s = 1, 2, i =
1, . . . , O, j = 1, . . . , D;
2: Randomly initialize ΦR and ΦC ;
3: Initialize p(s) (ui |ûr ) = |ΦR (u1i )=ûr | and p(s) (vj |v̂c ) =
1
, s = 1, 2, i = 1, . . . , O, j = 1, . . . , D,
|ΦR (vj )=v̂c |
r = 1, . . . , R, c = 1, . . . , C;
4: for t = 1 to n1 do
∑
(1)
(1)
5:
Solve for β i,j by minimizing
k ∥yi,j,k −

{∥yi,j,k − x′i,j,k β i,j ∥2
(1)

(s)

expectations β̂ r,: and β̂ :,c .

[x′i,j,k , x′i,j,k β i,j ] instead of [x′i,j,k , yi,j,k ]. In other words,
(1)

(s)

both β i,: and β :,j using origination-wise and destinationwise average. Steps 8 to 20 form an inner loop for updating the mappings ΦR and ΦC . In the inner loop, we first
compute the expectations of β (s) within each row/column
cluster in Steps 9 and 10. Then we update mapping ΦR by
assigning each origination to its closest row cluster (Steps
11 to 14), and mapping ΦC by assigning each destination
to its closest column cluster (Steps 15 to 18). Finally, we

(1)

we could use the estimated price x′i,j,k β i,j to replace the
(1)

(1)

real price yi,j,k . In this way, the ridge regression model in
(1)

Step 5 of COCOA for predicting yi,j,k will have an additional
∑
(1)
(2)
(2)
regularizer k −α1 yi,j,k ([x′i,j,k , x′i,j,k β i,j ]β i,j ) + α1 log(1 +
exp([x′i,j,k , x′i,j,k β i,j ]β i,j )}. The benefit of using the estimated price instead of the real price is that it provides a
(1)

1587

(2)

more accurate model for the test stage, since during the test
stage, the real price will be unknown. However, it comes
(1)
(2)
with the cost of coupling the estimation of β i,j and β i,j ,
which might aﬀect the convergence of the iterative algorithm. Investigating eﬀective and eﬃcient algorithms for
coupled parameters is one of our future research directions.
Second, the computational complexity of COCOA is shown
in the following lemma.

diﬀerent number of “originations” and “destinations” (ranges
from 3 to 5). The specific vectors for ith row, jth column
(s)
yi,j,: (s = 1 for the linear model and s = 2 for the generalized
linear model) are generated as following.
1. For each row and column cluster, generate cluster spe(s)
(s)
cific mean β̂ r,: and β̂ :,c ;
(s)

Lemma 1. The time complexity of COCOA is O[n1 (d2.376 +
2∑
d
i,j Ki,j + n2 (ORd + DCd + OD))], and the space complexity is O[d3 + ODd].

2. Given row cluster mean β̂ r,: and standard deviation

Proof. The time complexity can be proven based on the
fact that the computational cost of COCOA is dominated
by regularized risk minimization in Steps 5 and 6, as well
as the inner loop between Steps 8 and 20. The computational
complexity of regularized risk minimization is d2.376 +
2∑
d
i,j Ki,j , including both ridge regression using CoppersmithWinograd algorithm [7] for matrix inversion, and logistic regression using coordinate ascent, conjugate gradient ascent,
quasi-Newton method, or iterative scaling [25]. Within the
inner loop, the time complexity of Steps 9 and 10 is O(OD),
Steps 11 to 14 is O(ORd), Steps 15 to 18 is O(DCd), and
Step 19 is O(Od + Dd).
On the other hand, the space complexity includes both
the space requirement for d × d matrix inversion, the stor(s)
age of all the vectors of parameters β i,j , the probabili(s)
(s)
ties p (ui |ûr ) and p (vj |v̂c ), as well as the various ex-

3. Given column cluster mean β̂ :,c and standard devia-

(s)

(s)

(s)

(s)

pectations β i,: , β j,: , β̂ r,: , and β̂ :,c , where i = 1, . . . , O,
j = 1, . . . , D, r = 1, . . . , R, c = 1, . . . , C.
Lemma 1 implies that the time complexity of COCOA
scales linearly with respect to the number of originationdestination pairs, and the total number of transactions across
all origination-destination pairs. It also depends on both n1
and n2 . As we will show in the next section, empirically the
number of iterations required for the inner loop n2 and the
outer loop n1 to converge typically does not exceed 8.

4. EXPERIMENTAL RESULTS

(s)

(s)

(s)

(s)

tion σC , generate column vector β :,j through Gaussian distributions;
(s)

(s)

4. β i,j is finalized through the weighted average of β i,:
(s)

and β :,j using respective standard deviations;
5. For each OD pair, generate input features xi,j,: and
(1)
(2)
yi,j,: and yi,j,: are then produced through linear model
(to mimic the price distribution) and a generalized linear model (to mimic the winning probability distribu(s)
tion) through β i,j and xi,j,: with perturbation error
0.01.
(s)

(s)

We set R, C = 3, β i,: and β :,j to be 0 vectors and randomly generate cluster members as starting points. We use
5-fold cross validation to choose α. After the algorithm converges, the estimated winning probability for each OD pair
is shown in Figure 3(b). The red color stands for higher winning probability given all other conditions the same and the
blue color denotes relatively lower wining probability. We
also use the solid lines to illustrate the clustering boundaries.
As we can see, OD pairs in similar colors are grouped together, which implies COCOA recovers all the clusters. The
winning probability for the OD pairs before co-clustering is
also shown in Figure 3(a) for comparison.

4.2

In this section, we demonstrate the eﬀectiveness of the
proposed COCOA algorithm both on synthetic and real data.
To our best knowledge, COCOA is the first algorithm for
co-clustering based dual prediction framework and we compare its performance with an advanced hierarchical clustering and prediction methodology, hglm, which is currently
adopted by a worldwide cargo company. Methodology details are described in 4.2.1. Diﬀerent from COCOA, hglm
performs co-clustering and prediction separately. In addition, this two-step method tends to introduce extra variances by using outputs from the first step model as inputs
for the second model. Also, there is no adaptive feedback
process to improve the performance for both models. COCOA can potentially tackle these challenges by integrating a
regularized linear submodel for the bid price prediction and
a generalized linear submodel for the win-rate prediction in
a consistent framework.

(s)

σR , generate row vector β i,: through Gaussian distributions;

Worldwide Cargo Company Challenge

In this subsection, we test the performance of COCOA
on a real cargo pricing optimization problem. We select 20
originations and 20 destinations with relatively high volume
of transactions. Among the resulting 400 OD pairs, about
25% of them have less than 20 transactions. Such OD pairs
are excluded from training β, which is estimated based on
(s)
(s)
its cluster membership’s average β̂ r,: and β̂ :,c . Each transaction is accompanied with historical bidding prices and bidding stages (win or loss) and several other features, including
number of cargo pieces, cargo weight, cargo volume, lead
time and customer size, etc. Based on domain knowledge
and the initial study, we set R, C = 3. Similarly to the
(s)
(s)
synthetic study, we initialize β i,: and β :,j as 0, randomly
generate cluster members, and use the 5-fold cross validation to choose α. However, we tested with other settings
and found that our algorithm is insensitive to these starting
values. To make a fair comparison, hglm is also given the
same number of row/column clusters R/C.
In the following sub sections, we describe in detail the
evaluation of COCOA in terms of the co-clustering results,
predictive likelihood, improvement of revenue, and convergence rate.

4.1 Synthetic Data
In this subsection, we first test the performance of COCOA on a synthetic data set which mimics the real world
problem. The synthetic data consists of 3 row clusters and
3 column clusters. Each row and column cluster consists of

1588

Figure 2: COCOA performance on real data: the three row clusters present clear diﬀerent in bidding price which can be interpretated
by the diﬀerence in three important features, i.e., lead time, customer size and cargo volume

4.2.1 The Introduction to hglm

correspondence structure (e.g., pattern recognition) for the
most similar eﬀects. The density for each block is given by
[13]:
}
{
1
1
(9)
exp − 2 (uij − µkl )2 ,
fkl (uij ; α) = √
2
2σkl
2πσkl

We first introduce an advanced Hierarchical clustering and
prediction methodology framework currently adopted by a
worldwide cargo company. Notice that this problem has a
natural hierarchical structure, e.g., diﬀerent transactions are
grouped to diﬀerent OD pairs. The first step of the framework is to cluster OD pairs based on the win rate eﬀects
directly coming from the OD pairs and use the following Hierarchical Logistic Regression Model [27] to estimate such
eﬀect.
logit{E(yijk )} = Xijk βij + Zij uij + ϵijk ,

where uij is OD pair eﬀect for ORIG=i and DEST=j and
2
α = (µkl , σkl
) is the cluster-specific mean and variance.
However, this two step method may introduce extra variances from estimating the first framework and using the outputs as inputs for the second modeling. Also, there is no
adaptive feedback process to improve the performance for
both models.
This two step method has been very successful in helping the cargo company to develop an automatic optimized
pricing machinery to increase revenue. However, this two
step method does not bridge the information sharing and
connection among the two modeling.

(8)

where yijk is the kth cargo-price bidding stage (win or loss)
for the ith origination and the jth destination; Xijk be
the corresponding fixed eﬀects which include bidding specific variables and customer market information. Let Zij
stand for the random eﬀects coming from the OD (origination and destination) pair (i, j). βij is the coeﬃcient for
the fixed eﬀects and uij is OD pair (i, j) eﬀect estimation.
In a hierarchical model, observations are grouped into clusters (e.g., origination-destination in this cargo-price bidding
problem), and the distribution of an observation is determined not only by the common structure among all clusters
but also by the specific structure of the cluster where this
observation belongs to. So the random eﬀect component,
diﬀerent for diﬀerent clusters, is introduced into the model.
In the second step, the cargo company would co-cluster
the OD pairs based on the homogeneous eﬀects for the win
rates that are estimated through Model (8) or uij . Each cell
of the matrix is the random eﬀect estimation of a specific
OD pair. The basic idea of co-clustering consists in making
permutations of objects and variables in order to draw a

4.2.2

Co-clustering Result

Figure 4 shows the win probability prediction before and
after co-clustering by COCOA algorithm. Red color stands
for higher win probability given all other conditions the
same, and the solid lines demonstrate the clustering boundaries. After co-clustering, the OD pairs are rearranged and
OD pairs in similar colors are grouped together. The three
row clusters generated from the 20 originations show clear
geographical pattern. To be specific, airports, such as AMS,
BUD, CGN and DUS from European cities are in the same
row cluster; airports, such as ATL, IAH, JFK and ORD
from US cities, and airports, such as BOM, NRT and PVG
from Asian and pacific area belong to the other two row
clusters, respectively. In addition, the three row clusters

1589

(a) OD pair latent winning probability before coclustering

(a) Before clustering

(b) OD pair latent winning probability after coclustering

Figure 4: COCOA performance on real data: co-clustering results
on the winning probability prediction of selected OD pairs.

(b) After clustering
Figure 3: Performance on synthetic data set: COCOA recovers
all the clusters.

hood value but also smaller variation of log likelihood value
than hglm over all training sample fractions. COCOA outperforms hglm because it leverages the block structure in
the prediction stages of both price and win probability.

present strong diﬀerence in average bidding price. For example, the average bidding price corresponding to airports
ATL, AMS and BOM are about 4e4, 2e4 and 5.5e4 unit,
respectively. These three airports are examples from each
of the three row clusters, respectively. The price distinction
can be explained by the diﬀerence in three critical features,
i.e., lead time, customer size, and cargo volume. As shown
in Figure 2, the cargo volume of AMS is about half of that
of ATL and BOM. The customer size of BOM is relatively
large compared to ATL and AMS. This matches our intuition that large customer size and cargo volume lead to high
bidding price and vice versa. The three column clusters
present similar patterns.

4.2.4

Weighted Prediction Objectives

In reality, the objective function can be extended to include a weight (γ) on the price prediction and win probability prediction to reflect one’s preference, i.e. γl(·)(1) +
(1 − γ)l(·)(2) . The impact of γ on the price optimization
is presented in Figure 6, where the x-axis is a range of γ
values and the y-axis is the total log likelihood of price and
win probability on the test data. The log likelihood value
obtains the maximum at γ = 0.2 which corresponds to a
relatively high weight on the win probability. On the other
hand, the variation of the log likelihood increases significantly at very small or large γ values, such as 0.1 and 0.9.
This is because the prediction of undominated objective results in large variation. These findings can help practitioners select appropriate γ values. The total expected revenue
which is given by the summation of predictive price multiple
by predictive win probability of all the transaction on the
test data is compared with actual revenue. As shown in Figure 7, COCOA can improve revenue significantly, although
the variation of revenue prediction increases given relatively
large γ values. This again demonstrates the superer performance of COCOA .

4.2.3 Predictive Likelihood
Figure 5 presents the comparison between COCOA and
hglm based on the real data set in terms of total log likelihood of price and win probability. In Figure 5, the x-axis
is the fraction of transactions per OD pair used for training, and y-axis is the total log likelihood of price and win
probability prediction normalized by test sample size. For
each training sample fraction, we repeat the experiment for
20 times and report the mean and standard deviation of
the normalized log likelihood as an error bar plot. Figure 5
shows that COCOA obtains not only larger mean log likeli-

1590

Figure 5: Performance on real data set: COCOA consistently
outperforms hglm.

Figure 7: Performance on real data set: COCOA leads to higher
expected revenue.

Figure 6: Eﬀect of the weight on the two prediction objective
functions w.r.t. log-likelihood.

Figure 8: Convergence study of COCOA : the clustering objective
function converges typically within 8 iterations

sumption, and generalized linear models for the two types of
responses. We also proposed an iterative algorithm named
COCOA for solving the resulting optimization problem in an
eﬀective and eﬃcient manner. The performance of COCOA
is demonstrated on both synthetic and real data sets.

4.2.5 Convergence Study
We evaluate the time complexity of COCOA based on the
inner loop. We set n2 as a suﬃciently large number and
assume the inner loop converges if the co-clustering membership does not change. At the first iteration of the outer
loop, we report the co-clustering objective function value of
the inner loop at each iteration. As shown in Figure 8, the
inner loop converges quicky, which is typically less than 8
iterations.

6.

REFERENCES

[1] A. Banerjee, I. S. Dhillon, J. Ghosh, S. Merugu, and
D. S. Modha. A generalized maximum entropy
approach to bregman co-clustering and matrix
approximation. Journal of Machine Learning
Research, 8:1919–1986, 2007.
[2] D. Chakrabarti. Autopart: Parameter-free graph
partitioning and outlier detection. In PKDD, pages
112–124, 2004.
[3] D. Chakrabarti, S. Papadimitriou, D. S. Modha, and
C. Faloutsos. Fully automatic cross-associations. In
KDD, pages 79–88, 2004.
[4] V. CHen, D. Guenther, and E. Johnson. Routing
considerations in airline yield management. In
PRoceedings 5th International Conference of the
Decision Science Institute, 1999.
[5] W. Chiang, C. Chen, and X. Xu. An overview of
research on revenue management: current issues and
future research. International Journal of Revenue
Management, pages 97–128, 2006.

5. CONCLUSIONS
In this paper, we studied the problem of cargo pricing optimization, and proposed a probabilistic framework to maximize the conditional probability of observing two types of
responses from the two stages (the bidding stage and the
decision stage) given the features for each OD pair and the
mappings for co-clustering. Compared with existing work,
the main advantage of the proposed framework is three-fold.
First of all, it allows information sharing among all the OD
pairs, which significantly boosts the performance on the OD
pairs with a small transaction volume. Second, it bridges
the two stages by jointly learning the dual predictive models. Finally, it leverages the intrinsic co-clusters of originations and destinations to improve the model performance.
Furthermore, we instantiated the framework with both an
auxiliary distribution designed based on the co-clustering as-

1591

[6] H. Cho, I. S. Dhillon, Y. Guan, and S. Sra. Minimum
sum-squared residue co-clustering of gene expression
data. In SDM, pages 114–125, 2004.
[7] D. Coppersmith and S. Winograd. Matrix
multiplication via arithmetic progressions. J. Symb.
Comput., 9(3):251–280, 1990.
[8] I. S. Dhillon, S. Mallela, and D. S. Modha.
Information-theoretic co-clustering. In Proceedings of
the 9th ACM international Conference on Knowledge
Discovery and Data Mining, pages 89–98, 2003.
[9] I. S. Dhillon, S. Mallela, and D. S. Modha.
Information-theoretic co-clustering. In Proceedings of
the Ninth ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, Washington,
DC, USA, August 24 - 27, 2003, pages 89–98, 2003.
[10] A. Elisseeﬀ and J. Weston. A kernel method for
multi-labelled classification. In NIPS, pages 681–687,
2001.
[11] B. Gao, T.-Y. Liu, X. Zheng, Q. Cheng, and W.-Y.
Ma. Consistent bipartite graph co-partitioning for
star-structured high-order heterogeneous data
co-clustering. In KDD, pages 41–50, 2005.
[12] W. Gao and Z.-H. Zhou. On the consistency of
multi-label learning. Artif. Intell. (AI), pages 22–44,
2013.
[13] G. Govaert and M. Nadif. Clustering with block
mixture models. Pattern Recognition, 36(2):463–473,
2003.
[14] J. He, H. Tong, S. Papadimitriou, T. Eliassi-Rad,
C. Faloutsos, and J. Carbonell. Pack: Scalable
parameter-free clustering on k-partite graphs. In SDM
Workshop on Link Analysis, Counterterrorism and
Security, 2009.
[15] S.-J. Huang, Y. Yu, and Z.-H. Zhou. Multi-label
hypothesis reuse. In KDD, pages 525–533, 2012.
[16] S.-J. Huang and Z.-H. Zhou. Multi-label learning by
exploiting label correlations locally. In AAAI, pages
1–7, 2012.
[17] A. K. Jain and R. C. Dubes. Algorithms for Clustering
Data. Prentice-Hall, Inc., Upper Saddle River, NJ,
USA, 1988.
[18] S. Ji, L. Tang, S. Yu, and J. Ye. Extracting shared
subspace for multi-label classification. In KDD, pages
381–389, 2008.
[19] S. Ji, W. Zhang, and J. Liu. A sparsity-inducing
formulation for evolutionary co-clustering. In KDD,
pages 334–342, 2012.
[20] X. Kong, M. K. Ng, and Z.-H. Zhou. Transductive
multilabel learning via label set propagation. IEEE
Trans. Knowl. Data Eng. (TKDE), pages 704–719,
2013.
[21] T. Li. A general model for clustering binary data. In
KDD, pages 188–197, 2005.
[22] B. Long, Z. M. Zhang, X. Wu, and P. S. Yu. Spectral
clustering for multi-type relational data. In ICML,
pages 585–592, 2006.
[23] B. Long, Z. M. Zhang, and P. S. Yu. A probabilistic
framework for relational clustering. In KDD, pages
470–479, 2007.

[24] S. C. Madeira and A. L. Oliveira. Biclustering
algorithms for biological data analysis: a survey. IEEE
Transactions on Computational Biology and
Bioinformatics, pages 24–45, 2004.
[25] T. P. Minka. A comparison of numerical optimizers for
logistic regression. Technical report, Microsoft
Research, 2007.
[26] B. Rao. A convex programming model for cargo
revenue-mix optimization. Internal Report, Sabre
Holdings, 2000.
[27] L. Ronnegard, X. Shen, and M. Alam. hglm: A
package for fitting hierarchical generalized linear
models. The R Journal, 2(2):20–28, 2010.
[28] R. Simpson. Using network flow techniques to find
shadow prices for market and seat inventory control.
MIT Flight Transportation Laboratory Memorandum
M89-1, Cambridge, MA, 1989.
[29] A. P. Singh and G. J. Gordon. Relational learning via
collective matrix factorization. In KDD, pages
650–658, 2008.
[30] B. Smith and C. Penn. Analysis of alternative
origin-destination control strategies. AGIFORS
Annual Symposium Proceedings, 28.
[31] L. Sun, S. Ji, and J. Ye. Hypergraph spectral learning
for multi-label classification. In KDD, pages 668–676,
2008.
[32] Y. Sun, J. Tang, J. Han, C. Chen, and M. Gupta.
Co-evolution of multi-typed objects in dynamic star
networks. IEEE Trans. on Knowledge and Data
Engineering, 99:1–14, 2013.
[33] K. Talluri and G. Van Ryzin. The Theory and
Practice of Revenue Management, International Series
in Operations Research and Management Science.
Boston/Dordrecht/London: Kluwer Academic
Publishers, 2004.
[34] G. Tsoumakas and I. Katakis. Multi-label
classification: An overview. International Journal of
Data Warehousing and Mining, 3(3):1–13, 2007.
[35] E. Williamson. Airline network seat control. PhD
Thesis, MIT, Cambridge, MA, 1992.
[36] H.-F. Yu, P. Jain, P. Kar, and I. S. Dhillon.
Large-scale multi-label learning with missing labels. In
ICML, pages 593–601, 2014.
[37] M. Zhang and Z. Zhou. A review on multi-label
learning algorithms. IEEE Trans. Knowl. Data Eng.,
26(8):1819–1837, 2014.
[38] M.-L. Zhang. Lift: Multi-label learning with
label-specific features. In IJCAI, pages 1609–1614,
2011.
[39] M.-L. Zhang and K. Zhang. Multi-label learning by
exploiting label dependency. In KDD, pages 999–1008,
2010.
[40] M.-L. Zhang and Z.-H. Zhou. Ml-knn: A lazy learning
approach to multi-label learning. Pattern Recognition,
pages 2038–2048, 2007.
[41] Y. Zhu and J. He. Co-clustering structural temporal
data with applications to semiconductor
manufacturing. In ICDM, 2014.

1592

3154

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,

VOL. 28,

NO. 12,

DECEMBER 2016

A Generalized Hierarchical Multi-Latent Space
Model for Heterogeneous Learning
Pei Yang, Member, IEEE, Hasan Davulcu, Member, IEEE, Yada Zhu, Member, IEEE,
and Jingrui He, Member, IEEE
Abstract—In many real world applications such as image annotation, gene function prediction, and insider threat detection, the data
collected from heterogeneous sources often exhibit multiple types of heterogeneity, such as task heterogeneity, view heterogeneity, and
label heterogeneity. To address this problem, we propose a Hierarchical Multi-Latent Space (HiMLS) learning framework to jointly
model the triple types of heterogeneity. The basic idea is to learn a hierarchical multi-latent space by which we can simultaneously
leverage the task relatedness, view consistency and the label correlations to improve the learning performance. We first propose a
multi-latent space approach to model the complex heterogeneity, which is then used as a building block to stack up a multi-layer
structure in order to learn the hierarchical multi-latent space. In such a way, we can gradually learn the more abstract concepts in the
higher level. We present two instantiated models of the generalized framework using different divergence measures. The two-phase
learning algorithms are used to train the multi-layer models. We drive the multiplicative update rules for pre-training and fine-tuning in
each model, and prove the convergence and correctness of the update methods. The effectiveness of the proposed approach is
verified on various data sets.
Index Terms—Heterogeneous learning, multi-task learning, multi-view learning, multi-label learning, matrix tri-factorization

Ç
1

I

INTRODUCTION

the era of big data, a large amount of information collected from heterogeneous sources are correlated with
each other. It is of great importance to mine such hidden
correlations in the presence of multiple types of heterogeneity for many real world applications, such as web news classification, gene function prediction, insider threat detection,
image annotation, etc. In this paper, we focus on triple types
of heterogeneity, i.e., task heterogeneity, view heterogeneity, and label heterogeneity. For example, for the satellite
image analysis problems, task heterogeneity refers to the
images collected from different satellites following from different distributions; view heterogeneity refers to various
types of features such as color histogram, edge distribution
histogram, and bag of visual words; label heterogeneity
refers to the multiple tags associated with each image.
The major challenge for learning with the triple types of
heterogeneity is how to effectively mine the hidden correlations among the heterogeneous data. Such correlations
should reflect the key assumptions underlying each type of
heterogeneity, including the task relatedness assumption [7],
the view consistency assumption [16], as well as the label
correlation assumption [34]. To the best of our knowledge,
we are the first to jointly model the triple heterogeneity.
N



P. Yang, H. Davulcu, and J. He are with Arizona State University, Tempe,
AZ 85281.
E-mail: {cs.pyang, jingrui.he}@gmail.com, HasanDavulcu@asu.edu.
 Y. Zhu is with IBM Research, Yorktown Heights, NY 10598.
E-mail: yzhu@us.ibm.com.
Manuscript received 22 Dec. 2015; revised 26 July 2016; accepted 5 Sept.
2016. Date of publication 20 Sept. 2016; date of current version 2 Nov. 2016.
Recommended for acceptance by X. Zhu.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identifier below.
Digital Object Identifier no. 10.1109/TKDE.2016.2611514

To tackle this problem, we propose a Hierarchical MultiLatent Space (HiMLS) framework for heterogeneous learning. The goal is to maximally leverage the rich correlations
among heterogeneous data to improve the performance. To
this end, we first present a multi-latent space model, which
characterizes task relatedness, view consistency, and label
correlation in a principled framework. It is formulated as a
regularized non-negative matrix tri-factorization problem,
aiming to simultaneously minimize the reconstruction loss
on the instance-feature data and the classification loss on the
instance-label data, while maximizing the similarity among
the co-latent spaces. Furthermore, the proposed multi-latent
space model is used as a building block to establish a multilayer structure. It aims to build a hierarchical multi-latent
space to gradually learn the more abstract concepts in the
higher layer. The proposed HiMLS approach is motivated
from two streams of work in machine learning. One is multiway clustering (or co-clustering) [3] which improves the
quality of clustering by intertwining both row and column
information that are inter-related. Another is multi-layer
models [19] which obtains better data representations by
automatically extracting the hierarchical concepts from data.
Our multi-latent space model employs multi-way clustering
on the instances, features, and labels to capture the correlations among the heterogeneous data, while the hierarchical
multi-latent space model takes advantage of multi-layer
structure to learn the hierarchical concepts from data. Both of
them help extract the rich correlations among heterogeneous
data, leading to better performance.
Based on this generalized framework, we present two
instantiated models using different distance metrics, i.e.,
least squares loss function and the generalized KullbackLeibler divergence. For each model, we develop an iterative
updating algorithm to solve the optimization problem. The

1041-4347 ß 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

YANG ET AL.: A GENERALIZED HIERARCHICAL MULTI-LATENT SPACE MODEL FOR HETEROGENEOUS LEARNING

proposed algorithms consist of two phases. First, each layer
is pre-trained in a greedy layer-wise way. Then, it fine-tunes
the weights of all the layer to reduce the total reconstruction
loss and the classification loss. It is worth noting that the
proposed approach is a generalized framework to learn
from complex heterogeneity, which subsumes some popular methods on learning from a single heterogeneity.
The main contributions of this paper can be summarized
as:


A novel learning problem which simultaneously
models triple types of heterogeneity;
 A generalized framework to learn the hierarchical
multi-latent space from complex heterogeneity;
 Two alternative models and the corresponding optimization algorithms;
 Generalization of some previous work on learning
from single heterogeneity;
 Experimental results on various data sets showing
the effectiveness of the proposed approach.
The rest of the paper is organized as follows. After a review
of the related work in Section 2, we present the proposed generalized framework in Section 3, and two alternative models
and their corresponding optimization algorithms in Sections 4
and 5, respectively. Some case studies are discussed in
Section 6. Section 7 shows the experimental results. Finally,
we conclude the paper in Section 8.

2

RELATED WORK

Since we make use of matrix factorization techniques to
model the complex heterogeneity, we review the related
work on both heterogeneous learning and non-negative
matrix factorization.

2.1 Heterogeneous Learning
Heterogeneous learning aims to leverage different types of
heterogeneity, such as task heterogeneity, view heterogeneity, and label heterogeneity, to improve the learning performance. Most of the previous work were focused on
modeling a single or dual types of heterogeneity.
In multi-task learning, the goal is to leverage the small
amount of labeled data from multiple related tasks to
improve the learner for each task. Among others, alternating structure optimization [1] decomposed the model into
the task-specific and task-shared feature mapping; multitask feature learning [2] assumed that multiple related tasks
share a low-dimensional representation; clustered multitask learning [47] assumed that multiple tasks follow a clustered structure. Some recent multi-task learning methods
dealt with irrelevant tasks by assuming that the model can
be decomposed into a shared feature structure that captures
task relatedness, and a group-sparse structure that detects
outliers [17].
In multi-view learning, the features from multiple sources form natural views. The goal is to leverage the complementary information among different views to improve the
performance. Co-Training [4] is one of the earliest algorithms for multi-view learning. More recent work includes:
SVM-2K [16] which combined KCCA with SVM in an optimization framework; the information-theoretic framework
for multi-view learning [30]; the CoMR method [29] based

3155

on a data-dependent Reproducing Kernel Hilbert Space
(RKHS); the large-margin framework for multi-view data
based on a latent space Markov network [8]; the convex
multi-view subspace learning method MSL [36] which
enforced conditional independence among the multiple
views while reducing dimensionality, etc.
In multi-label learning, each instance is associated with a
set of labels [34], [46]. The key issue is how to exploit the
correlations or dependencies among multiple labels. To
name a few, ML-kNN [45] converted the multi-label learning into a number of independent binary classification problems; Rank-SVM [15] solved the label ranking problem
under the large margin framework; LEAD [44] employed
Bayesian network to encode the conditional dependencies
of the labels; LS-ML [22] assumed that a common subspace
is shared among multiple labels; HG [31] constructed a
hypergraph to exploit the correlation information among
different labels; LEML [41] learned the latent label space
under a generic empirical risk minimization framework
with trace-norm regularization. In addition, MLLOC [21]
assumed that the label correlation may be shared by a subset of instances only rather than all the instances; the boosting based method MAHR [20] aimed to discover the label
relationship by using a hypothesis reuse mechanism; the
transductive approach TRAM [23] leveraged the information from unlabeled data to estimate the optimal label concept compositions.
More recently, researchers begin to study problems with
dual types of heterogeneity. For problems with both task
and view heterogeneity, a variety of techniques have been
proposed to model task relatedness in the presence of multiple views, e.g., the transductive method IteM 2 [18], the
inductive method regMVMT [43], the Bayesian method
NOBLE [37], and the graph-based method M 2 LID [39]. For
the problems with both label and view heterogeneity, the
L2 F method proposed in [40] modeled both the view consistency and the label correlations in a graph-based framework. For the more complex setting with all three types of
heterogeneity, these techniques cannot be readily applied
without disregarding the useful information from a certain
type of heterogeneity, except for our recent work [38] on
modeling the triple heterogeneity. This paper extends [38]
substantially by providing the generalized learning framework, the alternative optimization algorithms, and the theoretical analysis regarding the optimal solutions, as well as
the comprehensive empirical evaluations.

2.2 Non-Negative Matrix Factorization
Non-negative matrix factorization (NMF) [24] aims to
extract data-dependent non-negative basis functions, which
has been given much attention due to its part-based and
easy interpretable representation. Non-negative matrix factorization [25] has been widely used in data mining, biomedical, chemometrics, signal processing, computer vision,
neuroscience, graph analysis, etc [10]. Incorporating extra
constraints such as sparseness [28], smoothness [5], or
orthogonality [14] was shown to improve the decomposition and provide the better representation. Various extensions and variations of NMF have been proposed, such as
Semi-NMF [12], Convex-NMF [12], multi-layer NMF [10],
[33], weighed NMF [35], Tri-NMF [14], etc.

3156

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,

NMF has connections to many other techniques in data
mining. For example, under some mild conditions, NMF
with the least squares loss function is equivalent to a relaxed
K-means clustering [11], while NMF with the generalized
Kullback-Leibler (KL) divergence loss function is equivalent
to probabilistic latent semantic indexing [13].

3

THE PROPOSED GENERALIZED FRAMEWORK
FOR HETEROGENEOUS LEARNING

We first present the multi-latent space framework to model
the complex heterogeneity, which is then used as a building
block to stack up a multi-layer structure in order to learn
the hierarchical multi-latent space.

3.1 Notations and Problem Statements
Suppose we are given the multi-label data with multiple
views in different tasks. Let T be the number of tasks, V the
number of views, m the number of labels. Each instance is
described from V views, and associated with multiple
labels. For the ith task and jth view, denote the number of
instances and features by ni and dj , respectively. Let


~ ij = X ij
2 Rni dj be the instance-feature matrix for the
X
Xiju
ith task and jth view, where Xij is the training data and Xiju


Yi
~
2 Rni m be the instance-label
is the test data. Let Y i ¼
Yiu
matrix for the ith task, where Yi and Yiu are for training and
test data respectively. The instance-label matrix can be
either a binary or a real matrix, such as the user-item matrix
of either preference or rating scores in a recommender system. The goal is to build a model to predict the instancelabel matrix for the test data by leveraging the rich information among heterogeneous data.
Some math symbols used in this paper are introduced as
follows. For two matrices X and Y , let X  Y , X  Y , and X
Y
be the Hadamard product (or entrywise product), Kronecker product, and Hadamard division, respectively. Let
x ¼ vecðXÞ be the matrix vectorization of X into a vector x.
3.2 Multi-Latent Space Learning
We propose a multi-latent space learning framework to
jointly model the task relatedness, view consistency, and
label correlations in a principled way.
Motivated by the success of multi-way clustering [3] in
leveraging the inter-correlations among data to improve
clustering quality, we do multi-way clustering on heterogeneous data to learn the multi-latent space. It simultaneously
clusters instances, features

and labels into the correspondR
i
~i ¼
2 Rni p be the instance encoding clusters. Let R
Rui
ing matrix where p is the dimensionality of instance latent
space, Ri and Rui are for training and test data, respectively.
Let Cj 2 Rdj q be the feature encoding matrix, C Y 2 Rmq
the label encoding matrix where q is the dimensionality of
~i (or Cj , CY )
feature (or label) latent space. Each row in R
represents the coeffecients of the instance (or feature, label)
associated with the instance (or feature, label) clusters.
Denote M ij 2 Rpq ; M iY 2 Rpq as the co-latent space

VOL. 28,

NO. 12,

DECEMBER 2016

matrices. We try to reconstruct the instance-feature matrix
~ ij  R
~i Mij C T and
and instance-label matrix by letting X
j
Yi  Ri MiY CYT respectively, where 1  i  T and 1  j  V .
Note that Mij models the correlations between instance
clusters and feature clusters, while MiY models the correlations between instance clusters and label clusters.
The multi-latent space model is formulated as a regularized non-negative matrix triple factorization problem, which
simultaneously decomposes the instance-feature and
instance-label matrices, while enforcing the task relatedness,
view consistency, and label correlations on the data. The
objective is to simultaneously minimize the reconstruction
loss on the instance-feature data (1st term) and the classification loss on the instance-label data (2nd term), while maximizing the similarity among the co-latent spaces (3rd term):
min

fR;M;Cg > 0

T X
V


X
~ ij ; R
~i M ij C T
L X
j
i¼1 j¼1

T
T X
V
X
X




þa
L Y i ; Ri M iY CYT þ b
L M ij ; M iY
i¼1

(1)

i¼1 j¼1

where LðX; Y Þ is the distance metric between X and Y . a and
b are the non-negative parameters. The non-negative constraints allow for the multi-way clustering interpretation.
The multi-latent space model can be interpreted from the
perspective of constrained multi-way clustering. By constraining the multi-way clustering procedures, we model
the task relatedness by requiring the features across different
tasks to share the same feature clustering coefficients,
enhance the view consistency by requiring the instances to
share the same instance clustering coefficients across different views, characterize the label correlations by requiring the
labels to share the same label clustering coefficients across
different tasks. Fig. 1a shows an illustrative example about
the proposed multi-latent space model. Specifically, the
multi-latent space model encodes multiple types of correlations among the heterogeneous data as follows:
Task Relatedness. For the jth view, the decompositions of
the instance-feature data Xij ð1  i  T Þ in different tasks
share the same feature encoding matrix C j .
Label Correlation. The labels share the same label encoding matrix C Y across different tasks.
View Consistency. For the ith task, the decompositions of
the instance-feature data Xij ð1  j  V Þ in different views
share the same instance encoding matrix Ri .
Correlations Among Feature-Instance-Label. For the ith task,
the decompositions of instance-feature data X ij and
instance-label data Y i share the same instance encoding
matrix Ri .
Correlations Among Co-Latent Spaces. Since the instances,
features, and labels may share the latent semantic concepts,
we hope the learned co-latent spaces, Mij and MiY , are similar to each other.
The intuition of enhancing the correlations among colatent spaces is as follows. Take webpage classification as an
example. The words (1st view) on the webpage, the hyperlinks (2nd view) pointing to the webpage, and categories
(labels) of webpage could be linked by the latent semantic
topics (bridges) of the webpage. Therefore, we hope that the

YANG ET AL.: A GENERALIZED HIERARCHICAL MULTI-LATENT SPACE MODEL FOR HETEROGENEOUS LEARNING

3157

Fig. 1. An illustrative example about the proposed approach. In (a), without loss of generality, suppose there are two tasks and two views. The view
consistency is modeled by sharing the instance encoding matrix R1 (or R2 ) across different views. The task relatedness is modeled by sharing the
feature encoding matrices C1 (or C2 ) across different tasks. The label correlation is modeled by sharing the label encoding matrix CY across different
ð1Þ
ð1Þ
ð1Þ
ðl1Þ
tasks. In (b), the input data matrix Xij ð1  i  T; 1  j  V Þ is decomposed into three matrices, Ri , Mij , and Cj . Then, the co-latent space Mij
ðlÞ

is further decomposed to learn its own co-latent space Mij where 2  l  L. In such a way, the multi-latent space model can be used as a building
block to stack up a multi-layer architecture in order to learn the hierarchical multi-latent space.

co-latent spaces Mij ð1  j  V Þ learned in the feature spaces
from multiple views are as similar as possible to the colatent space MiY learned from label spaces, which acts as a
bridge to link the labels with the features from multiple
views in the latent spaces. Note that maximizing the correlations between co-latent spaces is equivalent to minimizing
the distance between them.

3.3 Hierarchical Multi-Latent Space Model
Motivated by the success of multi-layer models [19] in automatically extracting the hierarchical concepts from data, we
use the multi-latent space model as a building block to stack
up a multi-layer architecture. It aims to learn the hierarchical multi-latent space from complex heterogeneity.
The co-latent spaces Mij and MiY can be viewed as the
~ ij and
compact representations for the original input data X
Yi . Let L be the number of layers. For the co-latent space
ðl1Þ
ðl1Þ
(or MiY ) where lð2  l  LÞ represents the layer,
Mij
ðlÞ

we hope to further learn its own co-latent space Mij (or
ðlÞ

MiY ) in a higher level, i.e.,
ðl1Þ

 Ri Mij Cj

ðl1Þ

 Ri MiY CY

Mij

MiY

ðlÞ

ðlÞ

ðlÞT

ðlÞ

ðlÞ

ðlÞT

In such a way, we can gradually learn the factor matrices in
ðLÞ
each layer. Based on the learned co-latent spaces Mij and
ðLÞ

MiY in the highest layer L, we hope to recover the original
~ ij and Yi , in the first layer as accurately as posinput data, X
sible. Thus, the objective for the multi-layer architecture is
as follows:
min

fR;M;Cg > 0

XT XV
i¼1



~ ij ;
L X
j¼1

~ð1:LÞ M ðLÞ C ð1:LÞT
R
i
ij
j



ð1:LÞ
ðLÞ ð1:LÞT
L
Y
;
R
M
C
i
i
iY
Y
i¼1


XT XV
ðLÞ
ðLÞ
L
M
;
M
þb
ij
iY
i¼1
j¼1
þa

XT



Q
where Aðs:tÞ ¼ tl¼s AðlÞ if s  t, and Aðs:tÞ ¼ I otherwise for
any matrix A. I is an identity
For the simplicity of
 matrix.

R
ð1:LÞ
ð2:LÞ
i
~
Ri .
notation, we denote R
¼
i
Rui
Fig. 1b shows an illustrative example for the proposed
hierarchical multi-latent space model. Take the webpage
classification or image annotation as the examples. In each
layer, we do multi-way clustering on the instances, features
and labels. Since the instances, features and labels may usually have hierarchical latent structures, they can be clustered
into sub-categories, and further into high-level sub-categories, until the top categories. In such a way, we can gradually learn the more abstract semantic concepts in a higher
layer.

3.4 Prediction
Note that the proposed hierarchical multi-latent space
model works in a transductive fashion since the first term of
Eqs. (1) or (2) involves both training and test data in building the model.
After the model training, we can obtain the instance
encoding matrices Rui for test data, Ri for training data, and
ðlÞ
Ri ð2  l  LÞ shared by both training and test data. Then,
we can use the factor matrices to predict the instances in the
test data. The final prediction is the weighted sum of predicðl1Þ
tions resulting from each layer. We have MiY 
ðlÞ
ðlÞ ðlÞT
Ri MiY CY ð2  l  LÞ, and try to approximate Yiu by using
ð1Þ ð1ÞT
Rui MiY CY . Therefore, the predicted instance-label matrix
for the test data in ith ð1  i  T Þ task can be computed as
follows:
Fi ¼

L
X
l¼1

(2)

ðlÞ

wl Fi ¼

L
X

ð2:lÞ

wl Rui Ri

ðlÞ

ð1:lÞT

MiY CY

;

(3)

l¼1

where wl controls the weight for lth layer. A na€ıve way is to
set the weights based on the reconstruction loss in each
layer. In our experiments, we simply use the equal weight
for each layer.

3158

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,

If the input instance-label matrix is a binary matrix, we
can transform the predicted matrix Fi into a binary one by
using 0.5 as the classification decision threshold.

3.5 Distance Metric
Various distance metric LðX; Y Þ can be used in our proposed model to measure the similarity between X and
Y . In this paper, we focus on two divergence measures
widely used in NMF models. One is the least squares
loss function,
X 
2
X ij  Y ij :
kX  Y k2F ¼
i;j

db ðxjyÞ ¼

 log xy  1
x log xy  x þ y

Lemma 1. For any non-negative matrices M; Xi ; Ri ; Ci ; Pj and
Kj , the objective function,
J ðM Þ ¼ a

J ðM Þ ¼ a
¼ atr

i

F

T 

T X
V 

X
X





Y i  Ri M iY C T 
2 þ b

M ij  M iY 
2 :
a
Y F
F
i¼1

(4)

i¼1 j¼1

The objective function defined in Eq. (2) for hierarchical
multi-latent space can be instantiated as follows,
min

fR;M;Cg > 0

þa


2


ð1:LÞ
ðLÞ ð1:LÞT 


Y i  Ri MiY CY



F

i¼1

þb

 2M RTi X i C i
T



i
Xh
M T MP j PjT  2M T K j PjT þ const:

9
8 T
2
½Ri Ri M ðtÞ CiT C i 	uv 
Muv
>
>
>
>

=
<
ðtÞ
XX
Muv
ðtÞ

	
¼a
G M; M

>
>  T
>
ðtÞ
uv
i u;v >
;
: 2 Ri Xi C i uv Muv
1 þ ln MðtÞ
Muv
h
i
9
8
2
>
>
M ðtÞ P j PjT

Muv
>
>
>
>
uv
=

XX<
ðtÞ
Muv
;
þb

	
i
>
> h
>
j u;v >
>
>
M
ðtÞ
uv
;
: 2 K j PjT Muv
1 þ ln ðtÞ




uv

Muv

is an auxiliary function of J ðM Þ due to the facts:

and
(5)

T X
V 


2
X

 ðLÞ
ðLÞ 


Mij  MiY 
 :
i¼1 j¼1

RTi Ri MCiT C i

GðM; M Þ ¼ J ðM Þ;

F

i¼1 j¼1

M

j
T

Let t be the index of iteration. Similar to [14], we can
show that


2
T X
V 

X

~
~ð1:LÞ M ðLÞ C ð1:LÞT 


Xij  R


i
ij
j

T 

X

i

j

T X
V 


2
X

~
~i M ij C T 


X ij  R
j 
 þ
i¼1 j¼1

X

X






Xi  Ri MC T 
2 þ b

MP j  K j 
2
i F
F

X

þ btr

In this section, we introduce the two-phase optimization
algorithm for HiMLS.
When using least squares loss function, the objective
defined in Eq. (1) for multi-latent space can be instantiated as
follows,

fR;M;Cg > 0

(7)

where a and b are the non-negative parameters.

OPTIMIZATION ALGORITHM FOR HIMLS

min

j

sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P
P
a i RTi Xi C i þ b j K j PjT
P
P
;
M¼M
a i RTi Ri MCiT C i þ b j MP j PjT

Next, we propose the optimization algorithm HiMLS
based on least squares loss function in Section 4, and
HiMLSD based on generalized Kullback-Leibler divergence
in Section 5.

4

X

X






Xi  Ri MC T 
2 þ b

MP j  K j 
2 ;
i F
F

Proof. We make use of auxiliary function approach [25] to
derive the update rules for Eq. (6) and prove its
convergence.
The objective function for M is rewritten into:

b 2 Rnf0; 1g:

bðb1Þ

greedy layer-wise manner, then fine-tune the weights of all
layers to reduce the total reconstruction loss and classification loss.
To derive the multiplicative update rules for pre-training
(in Theorem 3) and fine-tuning (in Theorem 4) in HiMLS,
we first derive Lemma 1. This lemma provides a generic
method to derive the update rules for all of R; M; C in both
pre-training and fine-tuning.

is non-increasing under the update rule:

b¼0
b¼1

>
>
: ðxb þðb1Þyb bxyb1 Þ

DECEMBER 2016

(6)

It
P reducesP to the Kullback-Leibler divergence when
i;j X ij ¼
i;j Y ij ¼ 1.
Note that both the least squares (b ¼ 2) and generalized
KL divergence (b ¼ 1) are the special cases of b-divergence:
x
y

NO. 12,

i

Another is the generalized Kullback-Leibler divergence,
	
X 
Xij
DðXjj Y Þ ¼
X
log

X
þ
Y
ij
ij
ij :
i;j
Y ij

8
>
>
<

VOL. 28,

F

Following the tactics successfully used in deep learning [19], we adopt a two-phase procedure to train the multilayer model. We first pre-train the weights of each layer in a



G M; M ðtÞ  J ðM Þ:
The minimum is obtained by setting the derivative to
zero:

@ 
G M; M ðtÞ ¼ 0:
@M

YANG ET AL.: A GENERALIZED HIERARCHICAL MULTI-LATENT SPACE MODEL FOR HETEROGENEOUS LEARNING

vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
u PT ~ T ~
u
i¼1 Xij Ri M ij
C j ¼ C j  tPT
~T R
~i M ij
CjM T R

Then, we get the update rule as follows:
sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P
P
a i RTi Xi C i þ b j K j PjT
P
P
M¼M
:
a i RTi Ri MCiT C i þ b j MP j PjT






Since
J M ðtÞ ¼ G M ðtÞ ; M ðtÞ  min G M; M ðtÞ




M
¼ G M ðtþ1Þ ; M ðtÞ  J M ðtþ1Þ , the objective function
J ðM Þ is non-increasing under the above update rule. t
u

j

 trðLM Þ;
T

where LðL  0Þ is the Lagrangian multiplies matrix. The
zero gradient condition gives

X
T
T
R
R
MC
C
þ
b
MP j PjT
i
i
i
i
i
j
X
X
A¼a
RT X i C i þ b
K j PjT :
i i
j

:

(15)

Also, the limiting solutions of the update rules satisfy the KKT
condition.

Proof. The convergence of the update follows from
Lemma 1. According to Lemma 2, we can prove that the
limiting solutions satisfy the KKT condition.
u
t
ð1:LÞ
ðLÞ ð1:LÞT
~
, Vij ¼
For simplicity, denote Vij ¼ Ri Mij Cj
ð1:LÞ
ðLÞ ð1:LÞT
ð1:LÞ
ðLÞ ð1:LÞT
~
, ViY ¼ Ri M C
, and FðAÞ ¼
Ri Mij Cj
Y

Theorem 4 (Convergence of Fine-tuning). The objective
function in Eq. (5) is non-increasing under the update rules:

According to the complementary slackness condition, we
have

vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ



ﬃ
u PV
ðLÞT
u j¼1 F Xij Cjð1:LÞ MijðLÞT þ aF Y i CYð1:LÞ MiY
u
ðlÞ




¼ Ri  tP
ð1:LÞ
ðLÞT
ð1:LÞ
ðLÞT
V
þ aF ViY CY MiY
Mij
j¼1 F Vij Cj

ðlÞ

Ri

(8)

Next, we verify that the limiting solution of the update
rule in Eq. (7) satisfies the above equation. When it converges, M ð1Þ ¼ M ðtþ1Þ ¼ M ðtÞ ¼ M where t is the number
of iteration, we have

(16)
vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
u
PV
ðLÞT ð2:LÞT
u
u ð1:LÞ
Mij Ri
u
j¼1 Xij Cj
u
u
Ri ¼ Ri  tP
V
u ð2:LÞ M ðLÞ C ð1:LÞT C ð1:LÞ M ðLÞT Rð2:LÞT
ij
j
j
ij
i
j¼1 Ri Ri

ðM  MÞ  B ¼ ðM  MÞ  A ) ðB  AÞ  ðM  MÞ ¼ 0:
(9)
The equivalence between Eqs. (8) and (9) completes the
proof.
u
t
Theorem 3 shows the multiplicative update rules for the
multi-latent space model defined in Eq. (4), and demonstrates its convergence and correctness.

Theorem 3 (Convergence of Pre-training). The objective
function in Eq. (4) is non-increasing under the update rules:
vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
PV
u
T
T
u
j¼1 X ij C j Mij þ aY i C Y MiY
t
Ri ¼ Ri  PV
T
T
T
T
j¼1 Ri M ij Cj C j Mij þ aRi M iY CY C Y MiY
vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
u PV
u
T
u
j¼1 Xij C j Mij
Rui ¼ Rui  tPV
u
T
T
j¼1 Ri M ij Cj C j Mij

aRTi Ri M iY CYT C Y þ bVM iY

for any matrix A.
Theorem 4 shows the multiplicative update rules for the
hierarchical multi-latent space model defined in Eq. (5), and
demonstrates its convergence and correctness.

X

L  M ¼ 0 ) ðB  AÞ  M ¼ 0:

M iY ¼ M iY 

sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
P
aRTi Y i C Y þ b Vj¼1 M ij

(14)

ð1:l1ÞT
ðlþ1:LÞT
Ri
ARi

where
B¼a

(13)

sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
~T X
~ ij C j +bM iY
R
i
M ij ¼ M ij 
T
~
~
Ri Ri M ij CjT C j +bM ij

iY

@LðMÞ
¼ 0 ) L ¼ B  A;
@M

(12)

i

sﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
PT
Y T Ri M iY
C Y ¼ C Y  PT i¼1 iT T
i¼1 C Y MiY Ri Ri M iY

Lemma 2. The limiting solution of the update rule in Eq. (7) satisfies the KKT condition.

i

ij

i¼1

Lemma 2 shows that the iterative update method in
Lemma 1 will converge to the stationary point.

Proof. For the function JðMÞ in Eq. (6) with non-negative
constraint, we introduce the Lagrangian function
X

X






X i  Ri MC T 
2 þ b

MP j  K j 
2
LðM Þ ¼a
i F
F

3159

(10)
(11)

(17)
ðlÞ

Cj

vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
uPT
~T R
~ð1:LÞ M ðLÞ C ðlþ1:LÞT
u i¼1 Cjð1:l1ÞT X
ij i
ij
j
ðlÞ
¼ Cj  tPT
ð1:l1ÞT ~ T ~ð1:LÞ
ðLÞ ðlþ1:LÞT
V R
C
M C
i¼1

ðlÞ

CY

j

ij

i

ij

vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
u PT
ð1:l1ÞT T ð1:LÞ
ðLÞ ðlþ1:LÞT
u
CY
Yi Ri MiY CY
ðlÞ
¼ CY  tPTi¼1 ð1:l1ÞT
ð1:LÞ
ðLÞ ðlþ1:LÞT
VTiY Ri MiY CY
i¼1 CY

ðLÞ

Mij

vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
u ~ð1:LÞT ~ ð1:LÞ
ðLÞ
uRi
þ bMiY
Xij Cj
ðLÞ
¼ Mij  t ð1:LÞT
~ ij C ð1:LÞ þ bM ðLÞ
~
V
R
i

ðLÞ

ðLÞ

MiY ¼ MiY 

j

ð1:LÞT

ð1:LÞ

ViY CY

(19)

(20)

ij

vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
u ð1:LÞT
P
ð1:LÞ
ðLÞ
uaRi
Y i CY þ b Vj¼1 Mij
t
aRi

(18)

j

ðLÞ

þ bVMiY

;

(21)

where 1  l  L. Also, the limiting solutions of the update
rules satisfy the KKT condition.

3160

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,

ðlÞ

After obtaining Ri

ðlÞ

ðlÞ

and Cj , we can update Mij and

 l < LÞ by using the update rule got in the pretraining phase.
Based on Theorems 3 and 4, we summarize the optimization algorithm for HiMLS in Algorithm 1. There are two
training phases including pre-training and fine-tuning in
Algorithm 1. As shown in Steps 1-9, the pre-training phase
goes forward from the first layer to the highest layer, and
each layer is trained in a greedy layer-wise manner. In contrast, the fine-tuning phase shown in Steps 10-17 moves in
an opposite direction, and the weights of all the layers will
be updated. The convergence of the HiMLS algorithm is
guaranteed by Theorems 3 and 4.

Algorithm 1. HiMLS Algorithm
~ ij ð1  i  T; 1  j  V Þ,
Input: Instance-feature matrices X
instance-label matrices for train data Y i ð1  i  T Þ, a; b,
number of layers L.
Output: Predicted instance-label matrices Fi ð1  i  T Þ for test
data.
1: for l ¼ 1 : L do
~ðlÞ ð1  i  T Þ, C ðlÞ and C ðlÞ ð1  j  V Þ by
2: Initialize R
i
j
Y
clustering instances, labels, and features using
probabilistic latent semantic analysis, respectively;
3:

ðlÞ

ðlÞy

ðl1Þ

ðlÞy

ðlÞ

ðlÞy

ðl1Þ

ðlÞy

Initialize M ij ¼ Ri Mij C j , M iY ¼ Ri M iY CY

1

1
where Ry ¼ RT R RT and C y ¼ C C T C . Note that
ð0Þ
~ ij , and M ð0Þ ¼ Yi ;
M ¼X
ij

iY

4:
5:

repeat
ðlÞ
Update Ri ð1  i  T Þ and Rui by Eq. (10) and Eq. (11);

6:

Update Cj ð1  j  V Þ and CY by Eq. (12) and Eq. (13);

ðlÞ

ðlÞ
Mij

ðlÞ

ðlÞ
MiY

12:
13:

Update
and
where 1  i  T; 1  j  V by
Eq. (14) and Eq. (15);
until converged
end for;
repeat
ðLÞ
ðLÞ
Update Mij and MiY where 1  i  T; 1  j  V by
Eq. (20) and Eq. (21);
for l ¼ L : 1 do
ðlÞ
Update Ri ð1  i  T Þ and Rui by Eq. (16) and Eq. (17);

14:

Update Cj ð1  j  V Þ and CY by Eq. (18) and Eq. (19);

7:
8:
9:
10:
11:

ðlÞ

ðlÞ
Mij

ðlÞ

ðlÞ
MiY

Update
and
where 1  i  T; 1  j  V; l 6¼ L
by Eq. (14) and Eq. (15);
16: end for;
17: until converged
18: return Predictions for the test data using Eq. (3).
15:

Time Complexity. Similar to other matrix factorization
methods based on multiplicative update rules [14], [25], a
nice property of the proposed HiMLS algorithm is that most
of the computations are matrix multiplications and can be
computed efficiently. Lemma 5 shows the complexity of the
algorithm. The proof is omitted for brevity.

Lemma 5 (Complexity). The time complexity for the multiplicative update rules in Theorem 3 are as follows:

NO. 12,

DECEMBER 2016

XV


2
OðRi Þ ¼ OðRui Þ ¼ O
n
N
pq
þ
q
þ
d
q
þ
mq
i
j
j¼1
XT


d N ni p þ pq þ p2
OðCj Þ ¼ O
i¼1 j
XT


2
mN
n
p
þ
pq
þ
p
OðCY Þ ¼ O
i
i¼1
 

OðMij Þ ¼ O pN ni dj þ qdj þ pq þ q2
 

OðMiY Þ ¼ O pN ni m þ qm þ pq þ q2 ;

Proof. According to Lemma 1, we can prove the convergence of the updating. According to Lemma 2, we can
prove that the limiting solutions satisfy the KKT
condition.
u
t
ðlÞ
MiY ð1

VOL. 28,

where 1  i  T; 1  j  V and N is the number of iteration
until convergence.
Note that the dimensions of the latent spaces are usually far smaller than the ones in the original spaces, i.e.,
p  ni and q  dj . Lemma 5 shows that the multiplicative update rules for pre-training are scalable to the
problem sizes. Likewise, we can obtain the time complexity of the update rules for fine-tuning, which are
omitted for brevity.

5

OPTIMIZATION ALGORITHM FOR HIMLSD

In this section, we introduce the optimization algorithm for
HiMLSD, which is the counterpart of HiMLS.
HiMLSD adopts the generalized Kullback-Leibler divergence (see Section 3.5) as loss metric. Therefore, the objective function defined in Eq. (1) for multi-latent space is
instantiated as,
min

fR;M;Cg > 0

þa

T
X

T X
V


X
~ ij jjR
~i M ij C T
D X
j
i¼1 j¼1

T X
V
X




D Y i jjRi M iY CYT þ b
D M ij jjM iY :

i¼1

(22)

i¼1 j¼1

The objective function defined in Eq. (2) for hierarchical
multi-latent space can be instantiated as,
min

fR;M;Cg > 0

þa

T
X

T X
V


X
~ ij jjR
~ð1:LÞ M ðLÞ C ð1:LÞT
D X
i
ij
j
i¼1 j¼1



ð1:LÞ
ðLÞ ð1:LÞT
D Y i jjRi MiY CY

(23)

i¼1

þb

T X
V


X
ðLÞ
ðLÞ
D Mij jjMiY :
i¼1 j¼1

Next, we derive Lemma 6, which is a generic method to
derive the multiplicative update rules for R; M; C in both
pre-training and fine-tuning of HiMLDS.

Lemma 6. For any non-negative matrices H; X; R; C and P , the
function


F ðH Þ ¼ aD XjjRHC T þ bDðHjjP Þ;

(24)

is non-increasing under the update:

H


H  aRT
bE



X
C
RHC T
T
þ aR EC

þ bP

;

(25)

YANG ET AL.: A GENERALIZED HIERARCHICAL MULTI-LATENT SPACE MODEL FOR HETEROGENEOUS LEARNING

where a and b are non-negative parameters. E is a unit matrix
whose dimensions are set wherever appropriate.

Proof. The function F ðHÞ can be rewritten as,

where W ¼ C  R. The key issue is to design an auxiliary
function for F ðhÞ. Denote

X
X


G h; ht ¼ a
xi log xi  xi þ
W
h
ij
j
j
i

W ij htj
W ij htj
P
a
xi P
log
W
h

log
ij
j
t
t
k W ik hk
k W ik hk
i;j
!
X
hj
hj log  hj þ pj :
þb
pj
j

X

W ij hj  

j

X
j

s:t: cj  0;

X

cj log

Setting cj ¼ P

k

log

X
j

W ik htk

W ij hj  

j

W ij hj
cj

cj ¼ 1:

P
W ij htj
W ij hj k W ik htk
P
:
t log
W ij htj
k W ik hk

!


X
xi W ij htj
dG h; ht
hj
P
þ b log
¼ a
¼ 0:
t  W ij
h
W
h
pj
dhj
j
ik
k
k
i
Since log x  1  1=x with x ! 1 [6], the above equation
can be approximated as:
a

i

xi W ij htj
P
 W ij
hj k W ik htk

!


	
pj
þb 1
¼ 0:
hj

u
t
Similar to the proof in Lemma 6, we can derive the
following lemma.
X



ak D X k jjRk HCkT ;

(27)

is non-increasing under the update rule:

	
P
Xk
T
H
k ak Rk Rk HC T C k þ bP
k
P
H
;
bE þ k ak RTk E k C k

(28)

where b and ak are non-negative parameters. E (or Ek ) is a
unit matrix whose dimensions are set wherever appropriate.
Lemma 8 shows that the iterative update method in
Lemma 6 will converge to the stationary point.

Lemma 8. The limiting solution of the update rule in Eq. (25)
satisfies the KKT condition.



From this inequality it follows
that G h; ht  F ðhÞ.


The minimum of G h; ht with respect to h is determined by setting the gradient to zero:

X

aW T 
 1 þ b 
 1
 
  X 
ht  a C T  RT vec RHC
þ bp
T
 T

¼
a 
 vec R EC þ b 
 1


t
X
h  vec aRT RHC
T C þ bvecðP Þ


¼
a 
 vec RT EC þ bvecðE Þ


X
H  aRT RHC
C
þ bP
T
)H
:
T
aR EC þ bE

k

, we obtain,

X

Paxi W ij t þ bpj
W ik h
k
P k
b þ a i W ij


x
þ bp
ht  aW T Wh
i

J ðH Þ ¼ bDðHjjP Þ+

j
W ij htj

P

Lemma 7. The function

!



To show that G h; ht is an auxiliary function ofF ðhÞ,
we need to prove: (1) Gðh; hÞ ¼ F ðhÞ; (2) G h; ht
 F ðhÞ. The first equation is straightforward. To prove
the latter inequality, we use the convexity of log
function:
 log

htj

)h¼

¼ aDðvecðXÞjjðC  RÞvecðH ÞÞ+bDðvecðH ÞjjvecðP ÞÞ
¼ aDðxjjWhÞ+bDðhjjpÞ
!
X
X
xi
¼a
xi log P
 xi þ
W ij hj
j
j W ij hj
i
!
X
hj
hj log  hj þ pj ;
þb
pj
j

X

According to Eq. (26), we have,
hj ¼



F ðhÞ ¼ aD XjjRHC T +bDðHjjP Þ



¼ aD vecðX Þjjvec RHC T þ bDðvecðHÞjjvecðP ÞÞ

3161

(26)

Proof. For the function F ðHÞ in Eq. (24) with non-negative
constraint, we introduce the Lagrangian function
!
X
X
xi
xi log P
 xi þ
W ij hj
LðhÞ ¼a
j
j W ij hj
i
!
X
hj
hj log  hj þ pj  trðLhT Þ;
þb
pj
j
where LðL  0Þ is the Lagrangian multiplies vector. The
zero gradient condition gives

	
X
@LðhÞ
xi
hj
þ b log :
¼ 0 ) Lj ¼ a
Wij 1  P
@hj
W
h
pj
ik k
k
i
According to the complementary slackness condition
Lj  hj ¼ 0, we have
"
#

	
X
xi
hj
þ b log

 hj ¼ 0:
a
Wij 1  P
(29)
pj
k Wik hk
i
Likewise, when x ! 1, log x  1  1=x, the above equation can be approximated as:

3162

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,

"
a

X
i


	

	#
xi
pj
þb 1

 hj ¼ 0:
Wij 1  P
hj
k Wik hk

ðLÞ
Mij

(30)

ðLÞ

Mij

ðtþ1Þ
hj

verges,
¼
iteration, we have
hj b þ a

X

ðtÞ
hj

¼

Wij


ðLÞ
ð1:LÞT
MiY  aRi

ðLÞ

¼ hj

i

MiY

X axi Wij
P
þ bpj :
k Wik hk
i

M iY

Yi
Ri M iY CYT

CY þ b

M ij
j¼1 M iY


ðlÞ
ð1:l1ÞT
Ri  aRi

ð lÞ
Ri

Ri

P
X
T
Ri  a R MY i C T C Y MiY
þ Vj¼1 R M ijC T C j MijT
i iY Y
i ij j
PV
T þ
T
aE i C Y MiY
j¼1 E ij C j Mij

Rui

CjT

CYT

Rui 

PV

u
Xij
j¼1 Ru M ij C T
j
i

ð1:l1ÞT

aRi

T
j¼1 E ij C j Mij

~
P
~T Xij T
CjT  Ti¼1 MijT R
i R
~i M ij C
j
PT
TR
~T E ij
M
ij i
i¼1

P
T
CYT  Ti¼1 MiY
RTi R MY i C T
i iY Y
:
PT
T
T
i¼1 MiY Ri E ij

ðLÞ

ð1:LÞ

þb

ð1:LÞT CY

MiY CY

Yi
T
ViY ð0Þ ViY ðlÞ

E i VTiY ðlÞ þ

Rui 

Rui

P

PV
j¼1

ðLÞ

Mij

	

ðLÞ

MiY

þ bV 
 E

þ
PV

PV

ð1:l1ÞT

j¼1

Ri

ð1:l1ÞT

Ri

j¼1



X ij
T
Vij ð0Þ Vij ðlÞ

E ij VTij ðlÞ

ðlÞT

ðlÞT

Cj



PT
i¼1

PV

QTij ðlÞ

PT

Cj

i¼1

ðlÞT
CY

CY



PT
i¼1

i¼1

(33)

(41)

E ij VTij ð1Þ
~ ij
X

~ð1:LÞ M ðLÞ C ð1:LÞT
R
i
ij
j

ð1:l1Þ

Cj

(42)

ð1:l1Þ

QTij ðlÞE ij Cj

QTiY ðlÞ

PT



u
Xij
V
T
j¼1 Ru Vij ð1Þ Vij ð1Þ
i

j¼1

ðlÞT

ð1:LÞ

Ri

Yi

ðLÞ ð1:LÞT

MiY CY

ð1:l1Þ

QTiY ðlÞE i CY

ð1:l1Þ

CY

;

(43)

where 1  l  L. Also, the limiting solutions of the update
rules satisfy the KKT condition.

	
(34)

C j MijT

PV

ð1:LÞ

Ri

Yi

(40)

	

aRTi E i C Y þ bV 
 E


ðLÞ

þ bMiY

(39)

Theorem 9 (Convergence of Pre-training). The objective
function in Eq. (22) is non-increasing under the update rules:

	
~
~T Xij T C j þ bM iY
M ij  R
i R
~i M ij C
j
(32)
M ij
~T E ij C j þ bE
R
i
M iY  aRTi

ð1:LÞ
C
~ð1:LÞ M ðLÞ C ð1:LÞT j
R
i
ij
j

ð1:LÞT
ð1:LÞ
aRi
E i CY

Next we derive the multiplicative update rules for pretraining and fine-tuning in HiMLDS. Theorem 9 shows the
multiplicative update rules for Eq. (22), and demonstrates
its convergence and correctness.

PV

!

~ ij
X

(31)

The equivalence between Eqs. (30) and (31) completes the
proof.
u
t



DECEMBER 2016

(38)

¼ hj where t is the index of

!

NO. 12,

~ð1:LÞT E ij C ð1:LÞ þ bE
R
i
j

Next, we verify that the limiting solution of the update
rule in Eq. (25) satisfies the above equation. When it conð1Þ
hj



~ð1:LÞT
R
i

VOL. 28,

(35)

Proof. According to Lemma 7, we can prove the convergence of the updating. According to Lemma 8, we can
prove that the limiting solutions satisfy the KKT
condition.
u
t
Likewise, we can obtain the algorithm for HiMLSD and
its time complexity, which are omitted for brevity.

6
(36)

(37)

Proof. According to Lemma 7, we can prove the convergence of the updating. According to Lemma 8, we can
prove that the limiting solutions satisfy the KKT
condition.
u
t
ðlþ1:LÞ
ðLÞ ð1:LÞT
ðlþ1:LÞ
ðLÞ
Mij Cj
, ViY ðlÞ ¼ Ri
MiY
Define Vij ðlÞ ¼ Ri
ð1:LÞT
~ð1:LÞ M ðLÞ C ðlþ1:LÞT , and QiY ðlÞ ¼ Rð1:LÞ M ðLÞ
CY
, Qij ðlÞ ¼ R
i
ij
j
i
iY
ðlþ1:LÞT
CY
.

Theorem 10 shows the multiplicative update rules for
Eq. (23), and demonstrates its convergence and correctness.

Theorem 10 (Convergence of Fine-tuning). The objective
function in Eq. (23) is non-increasing under the update rules:

THE SPECIAL CASES OF HIMLS

The proposed model is a generalized framework for learning complex heterogeneity. It is widely applicable to multiple types of heterogeneous learning problems.
A special case of HiMLS is to learn the common co-latent
space M shared among all the tasks, view, and labels, i.e.,
Mij ¼ MiY ¼ Mð1  i  T; 1  j  V Þ. And by using the
training data only, Eq. (4) can be specialized as
min

R;M;C


2
T X
V 

T 

X
X







Y i  Ri MC T 
2 :

Xij  Ri MCjT 
 þ a
Y F
i¼1 j¼1

F

i¼1

(44)
It is worth noting that Eq. (44) is not a trivial special case.
Theorem 11 shows that some popular methods for learning
from single heterogeneity can be viewed as the special cases
of our proposed model, such as the multi-view learning
method MSL [36] and the multi-label learning method
LS-CCA [32]. Both MSL and LS-CCA are closely related to
canonical correlation analysis (CCA), while MSL is an unsupervised learning method aiming to learn the subspace

YANG ET AL.: A GENERALIZED HIERARCHICAL MULTI-LATENT SPACE MODEL FOR HETEROGENEOUS LEARNING

from multiple views, and LS-CCA is a supervised learning
method for the multi-label problem when one of the views
used in CCA is derived from the labels.

Theorem 11. The multi-view learning method MSL [36] and the
multi-label learning method LS-CCA [32] can be viewed as the
special cases of HiMLS.
Proof. Consider two special cases of HiMLS for learning
from a single heterogeneity as follows:
1) Unsupervised multi-view learning: By letting
T ¼ 1, V ¼ 2, and a ¼ 0, Eq. (44) can be rewritten into:



2 


2
min 
X1  RMC1T 
F þ
X2  RMC2T 
F :

R;M;C

(45)

where Xj ðj ¼ 1; 2Þ is the instance-feature matrix for the
jth view.
2) Supervised multi-label learning: By letting T ¼ 1,
V ¼ 1, and a ¼ 1, Eq. (44) can be rewritten into:



2 


2
min 
X  RMC1T 
F þ
Y  RMC2T 
F ;

R;M;C

(46)

where X and Y are the instance-feature matrix and
instance-label matrix, respectively.
Both Eqs. (45) and (46) have the same form as follows:



2
min 
½X; Y 	  HC T 
F ;

(47)

H;C



where H ¼ RM and C T ¼ C1T ; C2Th . Consider the normali
1

1

ized data matrix defined as Z ¼ ðXX T Þ2 X; ðYY T Þ2 Y .

When imposing the orthogonal constraint C T C ¼ I,
Eq. (47) can be rewritten into:



2
min 
Z  HC T 
F :

H;C T C¼I

(48)

Let f ðH; C Þ denote the objective function for Eq. (48),
which can be transformed into:


f ðH; C Þ ¼ tr Z T Z  2CH T Z þ H T H :
When fixing C, we have:
rH f ðH; C Þ ¼ 2ZC þ 2H ¼ 0 ) H ¼ ZC:
By substituting H ¼ ZC into Eq. (48), we have



2
min 
Z  HC T 
F
T
C C¼I


¼ min tr Z T Z  2CC T Z T Z þ C T Z T XC
T
C C¼I




¼ tr Z T Z  max tr C T Z T ZC :

(49)

C T C¼I

The optimal solution for C is given by the top k eigenvectors of Z T Z. According to [36], Eq. (49) has the same
optimal solution with CCA which aims to optimize:


s:t: U T XXT U ¼ V T YY T V ¼ I:
max tr U T XY T V
U;V

Therefore, the first special case of HiMLS is equivalent to
applying CCA to the instance-feature matrices from multiple views [36]. The second special case of HiMLS is

3163

equivalent to applying CCA to both the instance-feature
matrix and instance-label matrix [32].
u
t

7

EXPERIMENTS

In this section, we demonstrate the effectiveness of the proposed algorithms on various data sets in comparison with
different heterogeneous learning methods.

7.1 Data Sets and Setup
Four real data sets from different domains are used for evaluation, including text, image, and manufacturing data.
The first data set is the Reuters Corpus Volume I
(RCV1V2)1 data set [26], which is a collection of over
800,000 newswire stories. There are three category sets of
data: Topics (i.e., major subject of a story), Industry Codes
(i.e., type of business discussed), and Regions (i.e., geographic locations). Each of these category sets has a hierarchical structures. It is usually common to use several
subsets of this data, each containing 6,000 data instances on
average and with a total number of 101 class labels.
EUR-Lex [27] is a text data set containing European
Union official laws in practice, different kinds of treaties
and agreements, parliamentary journals. This data set contains nearly 20,000 text documents classified according to
three different schemas: i) subject matter (e.g., agriculture),
ii) official classification hierarchy called the directory codes
(e.g., a document belonging to a class also belongs to all its
parent classes), and iii) EUROVOC, a multilingual thesaurus maintained by the Office for Official Publications of the
European Communities. Each of these category sets forms a
hierarchical structures.
NUS-WIDE2 [9] is the a real-world web image data set
comprising over 269,000 images with over 5,000 user-provided tags, and ground-truth of 81 concepts with a hierarchical structures. There are several types of low-level visual
features such as 64-D color histogram in LAB color space,
144-D color correlogram in HSV color space, 73-D edge distribution histogram, and 500-D bag of visual words. We use
the light version of NUS-WIDE.
In these data sets, the label refer to the multiple categories each instance belonging to. For the NUS-WIDE data,
the view refers to different types of low-level visual feature.
For either RCV1V2 or EUR-Lex data sets, similar to [42], the
data are described from two views: one corresponds to the
TF-IDF features; another corresponds to the latent topics
obtained by applying probabilistic latent semantic analysis3
on the term counts. The task refers to classify the instances
belonging to different sub-categories, which follow different
but related distributions [18].
The last data set AL-SMELT is related to manufacturing
process. AL-SMELT is collected from Aluminum smelting
process. This data set corresponds to an electrolytic process
with 174 process variables that forms 4 views based on the
process control practice: power and resistance, noise control, feed control, and chemicals. It is concurrently running
in 245 smelters, which can be classified into 5 groups (tasks)
based on their design and generation. The 174 process
1. http://mulan.sourceforge.net/datasets-mlc.html
2. http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm
3. http://lear.inrialpes.fr/people/verbeek/code

3164

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,

TABLE 1
Statistics of Different Data Sets
Data set
RCV1V2_1
RCV1V2_2
RCV1V2_3
RCV1V2_4
EUR-Lex
NUS-WIDE
AL-SMELT

47,236
47,236
47,229
47,236
5,000
708
174

101
101
101
101
412
81
2

2.880
2.634
2.614
2.484
1.292
1.869
0.986

0.029
0.026
0.026
0.025
0.003
0.023
0.493

1,028
954
939
816
1,615
18,430
4

TABLE 2
Comparison Among HiMLS Variants on RCV1V2_1 Data Set
Algorithm

F1 -score

Accuracy

HiMLS
MLS
MLS-T
MLS-V
MLS-S

.906
.006
.868
.023
.864
.008
.857
.009
.847
.018

.885
.006
.829
.028
.822
.009
.813
.010
.805
.020

NO. 12,

DECEMBER 2016

TABLE 3
Comparison Among HiMLS Variants on RCV1V2_2 Data Set

Instances Features Labels Cardinality Density Diversity
6,000
6,000
6,000
6,000
19,348
55,615
6,468

VOL. 28,

Hamming loss
.064
.003
.102
.018
.106
.006
.107
.005
.116
.011

variables are collected automatically at daily level via sensors. Two other important control variables, temperature
and Alumina Fluoride, are collected every other day manually. Here, the goal is to predict the change direction
(increase or decrease) of these 2 variables (labels) when they
are not collected. The prediction fills in the information gap
and enables feedback control in a finer granularity.
Table 1 shows the properties of different data sets. Label
cardinality is the average number of labels per instance.
Accordingly, label density normalizes label cardinality by
the the number of labels. Label diversity is the number of
distinct label combinations observed in the data set [46].

7.2 Evaluation Metrics
In order to comprehensively investigate the performance of
the proposed method, we use F1 -score, accuracy and Hamming loss on the test data as the evaluation metrics.
F1 -score [46] is the harmonic mean of precision and recall
where precision is the proportion of predicted correct labels
to the total number of actual labels, recall is the proportion
of predicted correct labels to the total number of predicted
labels, averaged over all instances. Note that the larger
value of F1 -score is indicating the better performance.
Accuracy [46] for each instance is defined as the proportion of the predicted correct labels to the total number of
labels for that instance. Overall accuracy is the average
across all instances. Note that the larger value of accuracy is
indicating the better performance.
Hamming Loss [46] reports how many times on average,
the relevance of an instance to a class label is incorrectly predicted. Therefore, hamming loss takes into account the prediction error (an incorrect label is predicted) and the
missing error (a relevant label not predicted), normalized
over total number of classes and total number of instances.
Note that the smaller the value of Hamming loss, the better
the performance of the learning algorithm.
7.3 Effectiveness of HiMLS Components
First of all, we aim to verify the effectiveness of each
component in the proposed model, and demonstrate the

Algorithm
HiMLS
MLS
MLS-T
MLS-V
MLS-S

F1 -score

Accuracy

.903
.006
.880
.006
.872
.003
.856
.026
.842
.011

.872
.006
.846
.008
.828
.005
.818
.030
.814
.014

Hamming loss
.073
.003
.089
.004
.098
.005
.102
.017
.100
.007

TABLE 4
Comparison Among HiMLS Variants on RCV1V2_3 Data Set
Algorithm
HiMLS
MLS
MLS-T
MLS-V
MLS-S

F1 -score

Accuracy

.900
.006
.878
.011
.871
.019
.860
.003
.854
.018

.869
.006
.844
.012
.841
.022
.820
.004
.814
.024

Hamming loss
.076
.003
.096
.007
.091
.012
.103
.001
.106
.013

advantages of simultaneously modeling the multiple heterogeneity in one framework. Therefore, we compare
HiMLS with its four special cases: 1) multi-task multi-view
variant MLS; 2) multi-task single-view variant MLS-T; 3)
multi-view single-task variant MLS-V; 4) single-task singleview variant MLS-S. Each of these four variants has only
one layer.
HiMLS and MLS are input with multi-task and multiview data. For the single-view setting, the features from
all the views are concatenated into one single view. For
the single-task setting, the instances in all the tasks are
pooled into one single task. For HiMLS, we set the number of layers L ¼ 2, and the numbers of latent topics ½p; q	
for the instances and features(or labels) to ½200; 100	,
½40; 20	 in the first and second layer, respectively. For
all the other methods with only one layer, we set
½p; q	 ¼ ½40; 20	.
The classification performances of HiMLS and its variants on RCV1V2 data sets are shown on Tables 2, 3, 4, and
5. Based on these comparison results, we have the following
findings:






Both MLS-T and MLS-V perform better than MLS-S
in most cases by incorporating either task relatedness or view consistency. It suggests that simply
concatenating the features from different views is
not the best way to model the view heterogeneity;
likewise, simply pooling the instances of all tasks
into one single task is not the best way to model the
task heterogeneity.
MLS perform better than either MLS-T or MLS-V in
most cases. It suggests that jointly modeling multiple
types of heterogeneity can gain performance improvement upon single-heterogeneity learning.
HiMLS performs better than MLS. It indicates that the
learned hierarchical multi-latent space helps build a
more robust and discriminative classifier. One possible reason to account for this is that the multi-layer
structure helps find the more accurate local optimum
by gradually learning the abstract concepts. In contrast, the single-layer methods may suffer from the
local optimal solution in lower quality.

YANG ET AL.: A GENERALIZED HIERARCHICAL MULTI-LATENT SPACE MODEL FOR HETEROGENEOUS LEARNING

TABLE 5
Comparison Among HiMLS Variants on RCV1V2_4 Data Set
Algorithm

F1 -score

Accuracy

HiMLS
MLS
MLS-T
MLS-V
MLS-S

.894
.002
.874
.010
.864
.019
.859
.016
.851
.013

.860
.002
.835
.012
.825
.023
.816
.020
.807
.016

Hamming loss
.082
.002
.097
.008
.103
.014
.106
.013
.113
.011

TABLE 8
Classification Performance on RCV1V2_3
Algorithm

F1 -score

Accuracy

HiMLS
HiMLSD
L2 F
ML-kNN
LS-ML
TRAM

.900
.006
.889
.007
.837
.008
.764
.005
.816
.010
.873
.006

.869
.006
.860
.007
.788
.010
.738
.006
.785
.006
.846
.005

TABLE 6
Classification Performance on RCV1V2_1
Algorithm

F1 -score

Accuracy

HiMLS
HiMLSD
L2 F
ML-kNN
LS-ML
TRAM

.906
.006
.889
.007
.847
.011
.803
.092
.821
.021
.888
.003

.885
.006
.858
.007
.802
.015
.775
.094
.789
.019
.857
.004

F1 -score

Accuracy

HiMLS
HiMLSD
L2 F
ML-kNN
LS-ML
TRAM

.903
.006
.911
.004
.884
.005
.772
.009
.828
.019
.874
.004

.872
.006
.881
.004
.850
.005
.751
.008
.799
.016
.848
.004

Hamming loss
.076
.003
.080
.005
.120
.005
.115
.001
.107
.003
.081
.003

TABLE 9
Classification Performance on RCV1V2_4

Hamming loss
.064
.003
.082
.003
.110
.009
.102
.038
.109
.005
.082
.003

Algorithm

F1 -score

Accuracy

HiMLS
HiMLSD
L2 F
ML-kNN
LS-ML
TRAM

.894
.002
.913
.002
.858
.005
.754
.005
.831
.017
.870
.004

.860
.002
.866
.004
.816
.005
.728
.007
.801
.015
.851
.006

TABLE 7
Classification Performance on RCV1V2_2
Algorithm

3165

7.4 Performance Comparison
The second experiment is to compare the proposed method
with various heterogeneous learning algorithms. In this
work, we focus on improving the performance of multilabel learning by leveraging the multiple type of heterogeneity. To the best of our knowledge, there is no previous
work for learning from the triple heterogeneity. Therefore,
we compare our proposed approach with a variety of multilabel learning methods which learn from single or dual heterogeneity. The comparison approaches includes: 1) multiview multi-label learning methods L2 F [40]; 2) graph-based
multi-label approach ML-kNN [45]; 3) multi-label method
based on subspace learning LS-ML [22]; 4) transductive
multi-label learning approach TRAM [23].
In addition, we compare the two alternative algorithms
of our proposed approach, i.e., HiMLS and HiMLSD, to
examine their performance differences. Note that HiMLS is
based on least squares loss function, while HiMLSD is based
on generalized KL divergence. In order to conduct a fair
comparison between them, the same initializations are used
for HiMLS and HiMLSD.
HiMLS (or HiMLSD) is input with multi-task and multiview data. For the other algorithms, the instances of all the
tasks are pooled together. L2 F method is given the multiview features, whereas the other methods are given the
concatenated features from all the views. The parameters
are tuned for each algorithm using cross-validation on the
training data. We repeat the experiments ten times for each
data set and report the average performances and the standard deviations.

.082
.002
.077
.002
.106
.005
.118
.004
.104
.004
.075
.004

TABLE 10
Classification Performance on EUR-Lex

Hamming loss
.073
.003
.071
.002
.083
.003
.103
.001
.100
.004
.079
.002

Hamming loss

Algorithm

F1 -score

Accuracy

HiMLS
HiMLSD
L2 F
ML-kNN
LS-ML
TRAM

.749
.009
.740
.009
.713
.020
.498
.029
.664
.013
.667
.016

.719
.011
.707
.008
.680
.020
.472
.027
.631
.013
.635
.016

Hamming loss
.033
.002
.034
.001
.033
.003
.043
.002
.088
.006
.040
.002

TABLE 11
Classification Performance on NUS-WIDE
Algorithm

F1 -score

Accuracy

HiMLS
HiMLSD
L2 F
ML-kNN
LS-ML
TRAM

.675
.007
.649
.008
.700
.001
.589
.004
.628
.021
.684
.007

.645
.006
.634
.009
.615
.002
.582
.003
.618
.020
.676
.008

Hamming loss
.187
.003
.192
.005
.204
.002
.215
.002
.190
.008
.166
.003

Tables 6, 7, 8, and 9 show the classification performances
of different methods on RCV1V2. The performances on
EUR-Lex, NUS-WIDE, and AL-SMELT are shown in
Tables 10, 11, and 12, respectively.
The results show that both HiMLS and HiMLSD perform
better than the other algorithms in most cases. LS-ML [22]
learns a common subspace shared among multiple labels,
which helps improve the learning performance for the
multi-label data. However, since its objective function is
non-convex, the performance of LS-ML may be limited by
the local optimum problem. TRAM [23] is a transductive
multi-label learning method which tries to exploit the information from unlabeled data to estimate the optimal label
concept compositions. The results show that unlabeled
data can provide helpful information to build the multilabel classifier. For ML-kNN [45], since it ignores the correlation among multiple labels, its performance on these data

3166

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,

TABLE 12
Classification Performance on AL-SMELT
Algorithm

F1 -score

Accuracy

HiMLS
HiMLSD
L2 F
ML-kNN
LS-ML
TRAM

.848
.003
.873
.006
.773
.001
.845
.001
.852
.000
.383
.001

.847
.003
.871
.006
.772
.001
.842
.000
.850
.001
.381
.001

Hamming loss
.140
.003
.115
.006
.214
.000
.139
.001
.131
.001
.605
.000

sets is not comparable with the other methods in most cases.
Different from these methods for learning from single heterogeneity, both HiMLS (or HiMLSD) and L2 F [40] model
the feature and label heterogeneity and gain performance
improvement by enhancing the view consistency. It suggests that treating the features from different views in a discriminative and complementary way is usually better than
just concatenating all the features into one view. Likewise,
treating the instances in different tasks discriminatively is
usually better than just pooling all the instances together.
The performance superiority of the proposed method over
the comparison methods verifies the effectiveness of the
proposed approach to model the complex heterogeneity in
a principled framework. Another important competency of
the proposed method is that its multi-layer structure helps
build a robust classifier by gradually finding the more highlevel concepts in the deep structures.
TRAM performs a little better than HiMLS (or HiMLSD)
on NUS-WIDE data set. It indicates that NUS-WIDE may be
consistent with the smoothness assumption, and TRAM is
able to effectively leverage this assumption. However,
TRAM shows relative poor performance on AL-SMELT
data suggesting that the transductive method may be misled by the unlabeled information.
The results show that the performances of HiMLS and
HiMLSD are comparable. Each of them wins on three out of
seven data sets. It suggests that they adapt to different data
set. Both of them provide the alternative methods to model
the heterogeneous data.

7.5 Parameter Sensitivity
We study the parameter sensitivity on the RCV1V2_1 data
set. a and b are tuned on the grid 10½3:1:3	 . The results are
shown in Figs. 2a, and 2b. a is used to balance the importance of classification loss. The algorithm performs worse as
a approaches 0. When a ¼ 0, it means that no label information is used for training. The optimal performance is
achieved at a ¼ 1. Nevertheless, the performance is quite
robust over a wide range of values of a. b is used to control

VOL. 28,

NO. 12,

DECEMBER 2016

TABLE 13
Performance Varies with Number of Layers
L

F1 -score

Accuracy

1
2
3
4
5

.868
.023
.874
.002
.884
.003
.891
.003
.906
.006

.829
.028
.842
.003
.855
.005
.864
.003
.885
.006

Hamming loss
.102
.018
.092
.001
.083
.002
.079
.002
.064
.003

the importance of regularization. The result shown in
Fig. 2b indicates that setting appropriate weight to the regularization term can lead to better performance. As a result,
we tune the parameters, a and b, for each data set by crossvalidation on the training data.
We empirically study the convergence of HiMLS on the
RCV1V2_1 data set. The result is shown in Fig. 2c. From this
figure, we can see that HiMLS converges fast and its performance becomes stable after a few iterations. Thus, we terminate the algorithm after a maximum of 50 iterations.

7.6 Impact of Layers
It is interesting to investigate how the number of layers L
affects the performance of the proposed approach (e.g.,
HiMLS). We set L ¼ 1; 2; 3; 4; 5, and the numbers of latent
topics in each layer are 40,100,400,1000,4000, respectively.
We set p ¼ q here. Table 13 shows the results on the
RCV1V2_1 data set. We can see that the performances
(F1 -score, accuracy, and Hamming loss) are consistently
improved when the number of layers increased from 1 to 5.
It demonstrates that the multi-layer structure improves the
performance by learning the hierarchical abstract concepts
from data. When L keeps increased from 5, we have not
observed the significant improvement of performance. Our
conjecture is that the algorithm may have approached the
local optimum. Therefore, we empirically set L ¼ 5.

8

CONCLUSION

We propose a multi-layer framework to jointly model triple
heterogeneity. In each layer, it learns a multi-latent space
shared among the heterogeneous data. Then the multi-latent
model is used as a building block to stack up a multi-layer
structure so as to gradually learn the more abstract concepts.
Based on this generalized framework, we present two alternative models using different divergence measures. A deep
learning algorithm is proposed to solve the optimization problem in each model, which first pre-trains each layer and then
fine-tunes the whole multi-layer structure by using the multiplicative update rules. The comparison experiments with various heterogeneous learning methods demonstrate the
effectiveness of the proposed model.

Fig. 2. From left to right: a) F1 -score versus a (log10 scale); b) F1 -score versus b (log10 scale); c) F1 -score versus iteration.

YANG ET AL.: A GENERALIZED HIERARCHICAL MULTI-LATENT SPACE MODEL FOR HETEROGENEOUS LEARNING

ACKNOWLEDGMENTS
This work is supported by the NSF research grant IIS1552654, ONR Research grant N00014-15-1-2821, IBM Faculty Award, and NSFC research grant 61473123. The views
and conclusions are those of the authors and should not be
interpreted as representing the official policies of the funding agencies or the governments.

REFERENCES
[1]
[2]
[3]

[4]
[5]
[6]
[7]
[8]
[9]

[10]

[11]
[12]
[13]

[14]

[15]
[16]
[17]
[18]
[19]
[20]
[21]

R. K. Ando and T. Zhang, “A framework for learning predictive
structures from multiple tasks and unlabeled data,” J. Mach. Learning Res., vol. 6, pp. 1817–1853, 2005.
A. Argyriou, T. Evgeniou, and M. Pontil, “Multi-task feature
learning,” in Proc. Adv. Neural Inf. Process. Syst., 2006, pp. 41–48.
A. Banerjee, I. S. Dhillon, J. Ghosh, S. Merugu, and D. S. Modha,
“A generalized maximum entropy approach to Bregman co-clustering and matrix approximation,” J. Mach. Learning Res., vol. 8,
pp. 1919–1986, 2007.
A. Blum and T. Mitchell, “Combining labeled and unlabeled data
with co-training,” in Proc. 11th Annu. Conf. Comput. Learning Theory, 1998, pp. 92–100.
D. Cai, X. He, J. Han, and T. S. Huang, “Graph regularized nonnegative matrix factorization for data representation,” IEEE Trans.
Pattern Anal. Mach. Intell., vol. 33, no. 8, pp. 1548–1560, Aug. 2011.
D. Cai, X. He, X. Wang, H. Bao, and J. Han, “Locality preserving
nonnegative matrix factorization,” in IJCAI, 2009, pp. 1010–1015.
R. Caruana, “Multitask learning,” Mach. Learning, vol. 28, no. 1,
pp. 41–75, 1997.
N. Chen, J. Zhu, and E. P. Xing, “Predictive subspace learning for
multi-view data: a large margin approach,” in Proc. Advances
Neural Inf. Process. Syst., 2010, pp. 361–369.
T. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng,
“NUS-WIDE: A real-world web image database from national
university of singapore,” in Proc. ACM Int. Conf. Image Video
Retrieval, 2009, Art. no. 48.
A. Cichocki, R. Zdunek, A. H. Phan, and S. ichi Amari, Nonnegative Matrix and Tensor Factorizations - Applications to Exploratory
Multi-Way Data Analysis and Blind Source Separation, Hoboken, NJ,
USA: Wiley, 2009.
C. H. Q. Ding and X. He, “On the equivalence of nonnegative
matrix factorization and spectral clustering,” in Proc. SIAM Int.
Conf. Data Mining, 2005, pp. 606–610.
C. H. Q. Ding, T. Li, and M. I. Jordan, “Convex and seminonnegative matrix factorizations,” IEEE Trans. Pattern Anal.
Mach. Intell., vol. 32, no. 1, pp. 45–55, Jan. 2010.
C. H. Q. Ding, T. Li, and W. Peng, “On the equivalence between
non-negative matrix factorization and probabilistic latent semantic indexing,” Comput. Statistics Data Anal., vol. 52, no. 8, pp. 3913–
3927, 2008.
C. H. Q. Ding, T. Li, W. Peng, and H. Park, “Orthogonal nonnegative matrix t-factorizations for clustering,” in Proc. 12th ACM
SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2006, pp. 126–
135.
A. Elisseeff and J. Weston, “A kernel method for multi-labelled
classification,” in Proc. Adv. Neural Inf. Process. Syst., 2001,
pp. 681–687.
J. D. R. Farquhar, D. R. Hardoon, H. Meng, J. Shawe-Taylor, and S.
Szedm
ak, “Two view learning: SVM-2K, theory and practice,” in
Proc. Adv. Neural Inf. Process. Syst., 2005, pp. 355–362.
P. Gong, J. Ye, and C. Zhang, “Robust multi-task feature
learning,” in Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data
Mining, 2012, pp. 895–903.
J. He and R. Lawrence, “A graph-based framework for multi-task
multi-view learning,” in Proc. 28th Int. Conf. Mach. Learning, 2011,
pp. 25–32.
G. E. Hinton and R. R. Salakhutdinov, “Reducing the dimensionality of data with neural networks,” Science, vol. 313, no. 5786,
pp. 504–507, 2006.
S.-J. Huang, Y. Yu, and Z.-H. Zhou, “Multi-label hypothesis
reuse,” in Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data
Mining, 2012, pp. 525–533.
S.-J. Huang and Z.-H. Zhou, “Multi-label learning by exploiting label
correlations locally,” in Proc. AAAI Conf. Artif. Intell., 2012, pp. 1–7.

3167

[22] S. Ji, L. Tang, S. Yu, and J. Ye, “Extracting shared subspace for
multi-label classification,” in Proc. ACM SIGKDD Int. Conf. Knowl.
Discovery Data Mining, 2008, pp. 381–389.
[23] X. Kong, M. K. Ng, and Z.-H. Zhou, “Transductive multilabel
learning via label set propagation,” IEEE Trans. Knowl. Data Eng.,
vol. 25, no. 3, pp. 704–719, Mar. 2013.
[24] D. D. Lee and H. S. Seung, “Learning the parts of objects by nonnegative matrix factorization,” Nature, vol. 401, pp. 788–791, 1999.
[25] D. D. Lee and H. S. Seung, “Algorithms for non-negative matrix
factorization,” in Proc. Adv. Neural Inf. Process. Syst., pp. 556–562, 2000.
[26] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li, “RCV1: A new benchmark collection for text categorization research,” J. Mach. Learning
Res., vol. 5, pp. 361–397, 2004.
[27] E. L. Mencıa and J. F€
urnkranz, “Efficient pairwise multilabel
classification for large-scale problems in the legal domain,” in
Proc. Eur. Conf. ECML-PKDD, 2008, pp. 126–135.
[28] A. D. Pascual-Montano, J. M. Carazo, K. Kochi, D. Lehmann, and
R. D. Pascual-Marqui, “Nonsmooth nonnegative matrix factorization (nsNMF),” IEEE Trans. Pattern Anal. Mach. Intell., vol. 28,
no. 3, pp. 403–415, Mar. 2006.
[29] V. Sindhwani and D. S. Rosenberg, “An RKHS for multi-view
learning and manifold co-regularization,” in Proc. 25th Int. Conf.
Mach. Learning, 2008, pp. 976–983.
[30] K. Sridharan and S. M. Kakade, “An information theoretic framework for multi-view learning,” in Proc. Annu. Conf. Comput. Learning Theory, 2008, pp. 403–414.
[31] L. Sun, S. Ji, and J. Ye, “Hypergraph spectral learning for multilabel classification,” in Proc. 14th ACM SIGKDD Int. Conf. Knowl.
Discovery Data Mining, 2008, pp. 668–676.
[32] L. Sun, S. Ji, and J. Ye, “Canonical correlation analysis for multilabel classification: A least-squares formulation, extensions, and
analysis,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 33, no. 1,
pp. 194–200, Jan. 2011.
[33] G. Trigeorgis, K. Bousmalis, S. Zafeiriou, and B. W. Schuller, “A
deep semi-NMF model for learning hidden representations,” in
Proc. 31st Int. Conf. Mach. Learning, 2014, pp. 1692–1700.
[34] G. Tsoumakas and I. Katakis, “Multi-label classification: An overview,” Int. J. Data Warehousing Mining, vol. 3, no. 3, pp. 1–13, 2007.
[35] D. Wang, T. Li, and C. H. Q. Ding, “Weighted feature subset non-negative matrix factorization and its applications to document understanding,” in Proc. IEEE 10th Int. Conf. Data Mining, 2010, pp. 541–550.
[36] M. White, Y. Yu, X. Zhang, and D. Schuurmans, “Convex multiview subspace learning,” in Proc. Adv. Neural Inf. Process. Syst.,
2012, pp. 1682–1690.
[37] H. Yang and J. He, “Learning with dual heterogeneity: A nonparametric bayes model,” in Proc. 20th ACM SIGKDD Int. Conf. Knowl.
Discovery Data Mining, 2014, pp. 582–590.
[38] P. Yang and J. He, “Model multiple heterogeneity via hierarchical
multi-latent space learning,” in Proc. 21th ACM SIGKDD Int. Conf.
Knowl. Discovery Data Mining, 2015, pp. 1375–1384.
[39] P. Yang, J. He, and J.-Y. Pan, “Learning complex rare categories
with dual heterogeneity,” in Proc. SIAM Int. Conf. Data Mining,
2015, pp. 523–531.
[40] P. Yang, J. He, H. Yang, and H. Fu, “Learning from label and feature heterogeneity,” in Proc. 14th IEEE Int. Conf. Data Mining,
2014, pp. 1079–1084.
[41] H.-F. Yu, P. Jain, P. Kar, and I. S. Dhillon, “Large-scale multi-label
learning with missing labels,” in Proc. 31st Int. Conf. Mach. Learning, 2014, pp. 593–601.
[42] D. Zhang, J. He, and R. D. Lawrence, “MI2LS: Multi-instance learning from multiple information sources,” in Proc. 19th ACM SIGKDD
Int. Conf. Knowl. Discovery Data Mining, 2013, pp. 149–157.
[43] J. Zhang and J. Huan, “Inductive multi-task learning with multiple view data,” in Proc. 18th ACM SIGKDD Int. Conf. Knowl.
Discovery Data Mining, 2012, pp. 543–551.
[44] M.-L. Zhang and K. Zhang, “Multi-label learning by exploiting
label dependency,” in Proc. 16th ACM SIGKDD Int. Conf. Knowl.
Discovery Data Mining, 2010, pp. 999–1008.
[45] M.-L. Zhang and Z.-H. Zhou, “ML-KNN: A lazy learning
approach to multi-label learning,” Pattern Recognit., 2007,
pp. 2038–2048.
[46] M.-L. Zhang and Z.-H. Zhou, “A review on multi-label learning
algorithms,” IEEE Trans. Knowl. Data Eng., vol. 26, no. 8, pp. 1819–
1837, Aug. 2014.
[47] J. Zhou, J. Chen, and J. Ye, “Clustered multi-task learning via
alternating structure optimization,” in Proc. Adv. Neural Inf.
Process. Syst., 2011, pp. 702–710.

3168

IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,

Pei Yang is a postdoctoral researcher in the Statistical Learning Lab (STAR Lab), Arizona State
University. His research focuses on statistical
machine learning and data mining such as heterogeneous learning, semi-supervised learning,
transfer learning, rare category analysis, and
functional data analysis, with applications in web
mining, big data analytics, bioinformatics, healthcare, etc. He has published more than 20 research
articles on referred journals and conference proceedings. He is a member of the IEEE.
Hasan Davulcu received the PhD degree in computer science from State University of New York,
Stony Brook, New York. He is an associate professor in the School of Computing, Informatics
and Decision Systems Engineering, Arizona
State University. He has done research in data
mining and information assurance. His previous
works in data and services integration were published at prestigious ACM and the IEEE conferences. He is currently the PI for an US National
Science Foundation partnership for Innovation:
Building Innovation Capacity (PFI:BIC) grant focusing on financial fraud
detection via visual analytics. He is a member of the IEEE.

VOL. 28,

NO. 12,

DECEMBER 2016

Yada Zhu is a research staff member with the IBM
T. J. Watson Research Center. Her research interests include big data analytics, survival analysis,
statistical data mining and machine learning with
applications to ecommerce, advanced manufacturing, and energy and utilities. She has published
more than 30 research articles on referred journals,
books, and conference proceedings. Her work has
been acknowledged by IBM innovation awards and
IBM research accomplishment awards. She has
served as an associated editor of the International
Journal QTQM. She is a member of the IEEE.
Jingrui He received the PhD degree in computer
science from Carnegie Mellon University. She is
an assistant professor in the School of Computing, Informatics and Decision Systems Engineering, Arizona State University (ASU). She joined
ASU in 2014 and directs the Statistical Learning
Lab (STAR Lab). Her research focuses on heterogeneous machine learning, rare category
analysis, semi-supervised learning, and active
learning, with applications in healthcare, social
network analysis, semiconductor manufacturing,
etc. She received the NSF CAREER Award in 2016, IBM Faculty Award
in 2015 and 2014, respectively, and has published more than 60 refereed
articles. She has served on the organizing committee/senior program
committee of many conferences, including ICML, KDD, IJCAI, SDM,
ICDM, etc. She is also the author of the book Analysis of Rare Categories (Springer-Verlag, 2012). She is a member of the IEEE.
" For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

Model Multiple Heterogeneity via Hierarchical
Multi-Latent Space Learning
Pei Yang

Jingrui He

Arizona State University
Tempe, AZ 85281, USA

Arizona State University
Tempe, AZ 85281, USA

cs.pyang@gmail.com

jingrui.he@asu.edu

ABSTRACT
In many real world applications such as satellite image analysis, gene function prediction, and insider threat detection,
the data collected from heterogeneous sources often exhibit multiple types of heterogeneity, such as task heterogeneity, view heterogeneity, and label heterogeneity. To address
this problem, we propose a Hierarchical Multi-Latent Space
(HiMLS) learning approach to jointly model the triple types
of heterogeneity. The basic idea is to learn a hierarchical
multi-latent space by which we can simultaneously leverage
the task relatedness, view consistency and the label correlations to improve the learning performance. We ﬁrst propose
a multi-latent space framework to model the complex heterogeneity, which is used as a building block to stack up
a multi-layer structure so as to learn the hierarchical multilatent space. In such a way, we can gradually learn the more
abstract concepts in the higher level. Then, a deep learning algorithm is proposed to solve the optimization problem.
The experimental results on various data sets show the effectiveness of the proposed approach.

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications—
Data Mining; I.5.2 [Computing Methodologies]: Pattern
Recognition—Design Methodology

General Terms
Theory, algorithm, performance, experiment

Keywords
Heterogeneous learning; multi-task learning; multi-view learning; multi-label learning

1.

INTRODUCTION

In the era of big data, a large amount of information collected from heterogeneous sources are correlated with each
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
KDD’15, August 10-13, 2015, Sydney, NSW, Australia.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3664-2/15/08 ...$15.00.
DOI: http://dx.doi.org/10.1145/2783258.2783330.

1375

other. It is of great importance to mine such hidden correlations in the presence of multiple types of heterogeneity for
many real world applications, such as satellite image analysis, gene function prediction, and insider threat detection.
In this paper, we focus on triple types of heterogeneity, i.e.,
task heterogeneity, view heterogeneity, and label heterogeneity. For example, for the satellite image analysis problems,
task heterogeneity refers to the images collected from different satellites following from diﬀerent distributions; view
heterogeneity refers to various types of features such as color histogram, edge distribution histogram, and bag of visual
words; label heterogeneity refers to the multiple labels associated with each image such as sea, plane, and yacht.
The major challenge for learning with the triple types of
heterogeneity is how to eﬀectively mine the hidden correlations among the heterogeneous data. Such correlations
should reﬂect the key assumptions underlying each type of
heterogeneity, including the task relatedness assumption [4],
the view consistency assumption [9], as well as the label correlation assumption [23]. To the best of our knowledge, we
are the ﬁrst to jointly model the triple types of heterogeneity including the task heterogeneity, view heterogeneity and
label heterogeneity.
To address this problem, we propose a Hierarchical MultiLatent Space (HiMLS) learning approach to jointly model
the triple types of heterogeneity. The basic idea is to learn
a hierarchical multi-latent space by which we can accommodate multiple types of relationship among the instances, features and labels including the task relatedness, view consistency and the label correlations. We ﬁrst present the multilatent space framework to model the complex heterogeneity
which is formulated as a regularized non-negative matrix
triple factorization problem. It aims to minimize the reconstruction loss on the instance-feature data, classiﬁcation loss
on the instance-label data, together with the regularization
term. Furthermore, the multi-latent space model is used as
a building block to stack up a multi-layer structure so as to
learn the hierarchical multi-latent space. In such a way, we
can gradually learn the more abstract concepts in a higher
layer. Finally, we will introduce an iterative updating algorithm to solve the resulting optimization problem. The
proposed algorithm consists of two phases. First, each layer
is pre-trained in a greedy layer-wise way. Then, it ﬁne-tunes
the weights of all the layer to reduce the total reconstruction loss and the classiﬁcation loss. It is worth noting that
the proposed model is a generalized framework to learn from
complex heterogeneity. For example, some popular methods

on learning from a single heterogeneity can be viewed as the
special cases of the proposed approach.
The main contributions of this paper can be summarized
as follows:
• A novel learning problem which simultaneously models
triple types of heterogeneity;
• A multi-layer architecture to learn the hierarchical multilatent space from complex heterogeneity;
• A deep learning algorithm to solve the optimization
problem;
• Generalization of some previous work on learning from
single heterogeneity;
• Experimental results on various data sets showing the
eﬀectiveness of the proposed approach.
The rest of the paper is organized as follows. After a
brief review of the related work in Section 2, we present
the proposed model and the optimization algorithm in Section 3, followed by the discussion of some special cases of
the proposed approach in Section 4. Section 5 shows the
experimental results. Finally, we conclude in Section 6.

2.

that a common subspace is shared among multiple labels;
graph-based method HG [21] constructed a hypergraph to
exploit the correlation information among diﬀerent labels;
transductive approach TRAM [15] leveraged the information
from unlabeled data to estimate the optimal label concept
compositions; MLLOC [13] assumed that the label correlation may be shared by only a subset of instances rather than
all the instances; boosting based method MAHR [12] aimed
to discover the label relationship by using a hypothesis reuse
mechanism; a generic empirical risk minimization framework
was proposed for large-scale multi-label learning [28].
More recently, researchers begin to study problems with
dual types of heterogeneity. For problems with both task
and view heterogeneity, a variety of techniques have been
proposed to model task relatedness in the presence of multiple views, e.g., [11, 30, 25, 26]. For the problems with
both label and view heterogeneity, the L2 F method proposed in [27] modeled both the view consistency and the label correlations in a graph-based framework. For the more
complex setting with all three types of heterogeneity, these
techniques cannot be readily applied without disregarding
the useful information from a certain type of heterogeneity.

3.

RELATED WORK

THE PROPOSED HIMLS MODEL

The basic idea of the proposed HiMLS approach is to learn
a hierarchical multi-latent space by which we can take advantage of multiple types of heterogeneity to improve the
performance of the learning system. We ﬁrst present the
multi-latent space framework to model the complex heterogeneity, which is then used as a building block to stack up
a multi-layer structure so as to learn the hierarchical multilatent space. Finally, we will introduce an iterative updating
algorithm to solve the resulting optimization problem.
Before going into the details, the problem statement and
the notations will be introduced. Suppose we are given the
multi-label data with multiple views in diﬀerent tasks. Let
T be the number of tasks, V the number of views, m the
number of labels, respectively. Let X be an instance space,
L = {L1 , L2 , · · · , Lm } a ﬁnite set of class labels. An instance
x ∈ X is described from V views, and associated with a subset of labels L(x) ∈ 2L , which is the set of relevant labels
of x. In practice, the relevant labels L(x) can be denoted
by a binary label vector y(x) = [y1 (x), y2 (x), · · · , ym (x)],
where yk (x) = 1(1 ≤ k ≤ m) if Lk ∈ L(x), and 0 otherwise. For the ith task and j th view, denote the number
of instances

 and features by ni and dj , respectively. Let
Xij
ni ×dj
be the instance-feature matrix for the
X̃ij =
u ∈ R
Xij
u
ith task and j th view, whereXijis the training data and Xij
Yi
is the test data. Let Ỹi =
∈ Rni ×m be the instanceYiu
label matrix for the ith task, where Yi is for the training
data and Yiu is for the test data. The goal is to build a
multi-label classiﬁer f (x) = [f1 (x), f2 (x), · · · , fm (x)], where
fk (x) ∈ {1, 0}(1 ≤ k ≤ m) by using the data given in multiple tasks and described with multiple views.

In this section, we review the related work on modeling a
single or dual types of heterogeneity.
In multi-view learning, the features from multiple sources
form natural partitions (views). Co-Training [3] is one of
the earliest algorithms for multi-view learning. More recent work includes: SVM-2K [9] which combined KCCA
with SVM in an optimization framework; the informationtheoretic framework for multi-view learning [20]; the CoMR
method [19] based on a data-dependent Reproducing Kernel Hilbert Space (RKHS); the large-margin framework for
multi-view data based on a latent space Markov network [5];
the MSL [24] model which is a convex multi-view subspace
learning method that enforced conditional independence among the multiple views while reducing dimensionality.
In multi-task learning, the goal is to leverage the small
amount of labeled data from multiple related tasks to improve the learner for each task. Among others, alternating structure optimization [1] decomposed the model into
the task-speciﬁc and task-shared feature mapping; multitask feature learning [2] assumed that multiple related tasks
share a low-dimensional representation; clustered multi-task
learning [34] assumed that multiple tasks follow a clustered
structure. Some recent multi-task learning methods are able
to deal with irrelevant tasks by assuming that the model can
be decomposed into a shared feature structure that captures
task relatedness, and a group-sparse structure that detects
outliers [10].
In multi-label learning, each instance is associated with a
set of labels [23, 33]. The key issue for multi-label learning
is how to exploit correlations or dependencies among multiple labels. To name a few, ﬁrst-order method such as MLkNN [32] assumed that labels are independent and transformed the multi-label learning into a number of independent binary classiﬁcation problems; second-order approach
such as Rank-SVM [8] transformed the multi-label learning into the label ranking problem; LEAD [31] employed
Bayesian network to encode the conditional dependencies of
the labels; subspace learning approach LS-ML [14] assumed

3.1

Multi-Latent Space Learning

In order to leverage the triple types of heterogeneity, we
propose a multi-latent space learning framework to jointly model the task relatedness, view consistency, and label
correlations in a principled way.

1376

Intuitively, we can do multi-way clustering on the heterogeneous data which simultaneously clusters the instances,
features and labels into the their corresponding clusters, reRi
∈ Rni ×p be the instance-tospectively. Let R̃i =
Riu
cluster matrix where p is the dimensionality of instance latent space, Ri and Riu are for training and test data, respectively. Let Cj ∈ Rdj ×q be the feature-to-cluster matrix,
CY ∈ Rm×q the label-to-cluster matrix where q is the dimensionality of feature (or label) latent space. Each row in
R̃i (or Cj , CY ) represents the coeﬀecients of the instance
(or feature, label) associated with the instance (or feature,
label) clusters. Denote Mij ∈ Rp×q , MiY ∈ Rp×q as the colatent space matrices. Note that Mij models the correlations
between the instance clusters and the feature clusters, while
MiY models the correlations between the instance clusters
and the label clusters.
In the proposed model, we aim to learn the multi-latent spaces from the instances and labels of multiple tasks, and the
features with multiple views. The multi-latent space model is formulated as a regularized non-negative matrix triple
factorization problem, which simultaneously decomposes the
instance-feature and instance-label matrices, while enforcing
the task relatedness, view consistency, and label correlations
on the data. The objective is to minimize the reconstruction
loss on the instance-feature data, classiﬁcation loss on the
instance-label data, together with the regularization term:


min Jrec X̃, R, M, C + αJcl (Y, R, M, C)
(1)
+ βΩ (R, M, C)

Speciﬁcally, Eq. 2 encodes multiple types of correlations among the heterogeneous data as follows:
• Correlations among feature-instance-label: For the ith
task, the decompositions of instance-feature data Xij
and instance-label data Yi share the same instance-tocluster matrix Ri .
• Label correlation: The labels share the same label-tocluster matrix CY across diﬀerent tasks.
• View consistency: For the ith task, the decompositions
of the instance-feature data Xij (1 ≤ j ≤ V ) in diﬀerent views share the same instance-to-cluster matrix Ri .
• Task relatedness: For the j th view, the decompositions
of the instance-feature data Xij (1 ≤ i ≤ T ) in diﬀerent tasks share the same feature-to-cluster matrix Cj .

3.2

where α and β are the non-negative coeﬃcients to control
the importance of classiﬁcation loss and regularization, respectively. Ω (R, M, C) is the regularization of R, C and
M.
Various regularization techniques can be used to encode
our prior knowledge about the task relatedness, view consistency, and the label correlations. Since the instances, features, and labels may share the latent semantic concepts, we
hope the learned co-latent spaces are similar to each other.
In speciﬁc, we hope that the co-latent spaces learned in the
feature spaces from multiple views are as similar as possible
to the ones learned from label spaces, which acts as a bridge
to link the labels with the features from multiple views in
the latent spaces. Therefore, Eq. 1 can be instantiated as,
min

{R,M,C}>0

α

V
T 
2


T
Mij − MiY 2F
Yi − Ri MiY CY  + β

i=1

F

≈ Ri Mij Cj

(l−1)

≈ Ri MiY CY

MiY

(l)

(l)

(l)T

(l)

(l)

(l)T

Suppose L is the number of layers. Similar to Eq. 2, we can
obtain the objective function for the lth (2 ≤ l ≤ L) layer:
min

{R,M,C}>0

+α

T 
V 
2

 (l−1)
(l)
(l) (l)T 
− Ri Mij Cj 
Mij

F

i=1 j=1

T 
2

 (l−1)
(l)
(l) (l)T 
− Ri MiY CY 
MiY

+β

(3)

F

i=1

F

T 


(l−1)

Mij

T 
V 
2


T
X̃ij − R̃i Mij Cj  +
i=1 j=1

Hierarchical Multi-Latent Space Model

The multi-latent space model can be used as a building
block to stack up a multi-layer architecture so as to learn the
hierarchical multi-latent space from complex heterogeneity.
Take the text data as an example. In each layer, we do multiway clustering on the documents, features and labels. Since
all of the documents, features and labels may have hierarchical structures, they can be clustered into sub-categories,
and further into high-level sub-categories, until the top categories. In such a way, we can gradually learn the more
abstract concepts in a higher layer.
The co-latent spaces Mij and MiY can be viewed as the
compact representations for the original input data X̃ij and
(l−1)
(l−1)
(or MiY ) where
Yi . Based on the co-latent space Mij
l represents the layer, we hope to further learn its own co(l)
(l)
latent space Mij (or MiY ) in a higher level, i.e.,

T 
V 
2

 (l)
(l) 
Mij − MiY 
i=1 j=1

(2)

F
(L)

(L)

Based on the learned co-latent spaces Mij and MiY in
the highest layer L, we hope to recover the original input
data, X̃ij and Yi , in the ﬁrst layer as accurately as possible. Thus, the objective for the multi-layer architecture is
as follows:
V 
T 
2


(1:L)
(L) (1:L)T 
Mij Cj
min
X̃ij − R̃i


i=1 j=1

The non-negative constraints R > 0 and C > 0 allow for
the multi-way clustering interpretation. The multi-latent
space model can be interpreted from the perspective of constrained multi-way clustering. By constraining the multiway clustering procedures, we model the task relatedness
by requiring that the features across diﬀerent tasks share
the same feature clustering coeﬃcients, enhance the view
consistency by requiring that the instances share the same
instance clustering coeﬃcients across diﬀerent views, model the label correlations by requiring that the labels share
the same label clustering coeﬃcients across diﬀerent tasks.

{R,M,C}>0

+α

F

i=1 j=1

T 


2

(1:L)
(L) (1:L)T 
MiY CY
Yi − Ri


F

i=1

+β

T 
V 
2

 (L)
(L) 
Mij − MiY 
i=1 j=1

1377

F

(4)

t


where A(s:t) =

The minimum is obtained by setting the derivative to zero:


∂
G M, M (t) = 0
∂Muv

A(l) if s ≤ t, and A(s:t) = I otherwise for

l=s

any matrix A.

Prediction: The ﬁnal prediction is the weighted sum of
predictions resulting from each layer. For ith (1 ≤ i ≤ T )
task, the predicted instance-label matrix is as follows:
Fi =

L


(l)

w l Fi

=

l=1

L


u(1)

w l Ri

(l)

(1:l)T

MiY CY

(5)

i

l=1

where wl controls the weight for l

3.3

(2:l)

Ri

Then, we get the update rule as follows:
	






α RiT Xi Ci + β Kj PjT


i
j
M =M 

 α  RT R M C T C + β  M P P T
i
i
j j
i
i

th







Since J M (t) = G M (t) , M (t) ≥ min G M, M (t) =
M




G M (t+1) , M (t) ≥ J M (t+1) , the objective function J (M )
is non-increasing under the above update rule.

layer.

Optimization Algorithm

Following the tactics successfully used in deep learning, we
adopt a two-phase procedure to train the multi-layer model. We ﬁrst pre-train the weights of each layer in a greedy
layer-wise manner, then ﬁne-tune the weights of all layers to
reduce the total reconstruction loss and classiﬁcation loss.
In speciﬁc, we pre-train the ﬁrst layer by using Eq. 2, and
the following lth (2 ≤ l ≤ L) layer by using Eq. 3. Then,
at the ﬁne-tuning phase, we update the weights for all the
layers by using Eq. 4.
To derive the multiplicative update rules for pre-training
and ﬁne-tuning, we ﬁrst derive Lemma 3.1. The proof of
Lemma 3.1 is a key step to prove Theorem 3.1 and Theorem 3.2.

The following Theorem 3.1 shows the multiplicative update rules for Eq. 2, and demonstrates its convergence and
correctness. The update rules for Eq. 3 can be obtained in
a similar way.
Theorem 3.1 (Convergence of Pre-training). The
objective function in Eq. 2 is non-increasing under the updating rules:


V


T + αY C M T

Xij Cj Mij
i Y

iY
j=1

Ri = Ri  
V

T + αR M
T
T

Ri Mij CjT Cj Mij
i iY CY CY MiY

Lemma 3.1. The objective function,
2



T
M Pj − Kj 2F (6)
J (M ) = α
Xi − Ri M Ci  +β
F

i



V


u C MT

Xij
j
ij

j=1

u
u
Ri = R i  
V

T

Riu Mij CjT Cj Mij

is non-increasing under the updating rule:
	






α RiT Xi Ci + β Kj PjT


i
j
M =M 

 α  RT R M C T C + β  M P P T
i
i
j j
i
i

= αtr

F



j

M T RiT Ri M CiT Ci − 2M T RiT Xi Ci

i

+ βtr



M

T

M Pj PjT

− 2M

T

Kj PjT

j=1

i=1

CY = CY





Mij = Mij

+ const

Let t be the number of iteration. Next we will show that
G

M, M

(t)



MiY = MiY 

⎧	


⎛
⎞⎫
T R M (t) C T C
2
⎪
⎨ Ri
	


  ⎪
Muv ⎬
i
i uv · Muv
i
T
(t)
⎠
− 2 Ri Xi Ci
Muv ⎝1 + ln
= α
⎪
(t)
(t) ⎪
uv
⎭
⎩
u,v
Muv
Muv
i
⎧	


⎞⎫
⎛
2
(t)
T
⎪
⎪
· Muv
Pj P j
	


  ⎨ M
Muv ⎬
T
(t) ⎝
uv
⎠
+β
− 2 Kj Pj
M
1 + ln
⎪
(t)
(t) ⎪
uv uv
⎭
Muv
Muv
j u,v ⎩

Ω̃ij = R̃i

G (M, M ) = J (M )












(10)

i=1

R̃iT X̃ij Cj +βMiY
T
R̃i R̃i Mij CjT Cj +βMij
αRiT Yi CY + β

V

j=1

(11)

Mij

αRiT Ri MiY CYT CY + βV MiY

(12)

Proof. Please see Appendix A.


(1)
Ri
(1:L)
(2:L)
(1:L)
(L) (1:L)T
Denote R̃i
=
, Ωij = Ri
Mij Cj
,
u(1) Ri
Ri
(1:L)

is an auxiliary function of J (M ) due to the facts:

and

(9)



T



YiT Ri MiY

i=1


 T
T RT R M
CY MiY
i iY
i

j


(8)



T


T R̃ M

X̃ij
i ij

i=1
Cj = Cj  

T

T R̃T R̃ M
Cj Mij
i ij
i

j

Proof. We make use of auxiliary function approach [16]
to derive the updating rules and prove its convergence and
correctness.
Similar to [7], we can derive the updating rule for M . The
objective function for M is as follows:
2



T
M Pj − Kj 2F
J (M ) = α
Xi − Ri M Ci  + β
i

(7)

j=1

j

i

j

(L)

(1:L)T

Mij Cj

(1:l−1)T

(1:L)

, ΩiY = Ri

(l+1:L)T

(L)

(1:L)T

MiY CY

, and

Φ (A) = Ri
ARi
for any matrix A.
Theorem 3.2 shows the multiplicative update rules for the
objective function Eq. 4, and demonstrates its convergence
and correctness.



G M, M (t) ≥ J (M ) .

1378

Theorem 3.2 (Convergence of Fine-tuning). The
objective function in Eq. 4 is non-increasing under the updating rules:

(l)

Ri

Algorithm 1 HiMLS Algorithm
Input:
Instance-feature
matrices
instance-label matrices
X̃ij (1 ≤ i ≤ T, 1 ≤ j ≤ V ),
for train data Yi (1 ≤ i ≤ T ), α, β, number of layers L.
Output: Predicted instance-label matrices Fi (1 ≤ i ≤ T )
for test data.
1: for l = 1 : L do
(l)
(l)
(l)
2:
Initialize R̃i (1 ≤ i ≤ T ), CY and Cj (1 ≤ j ≤ V )
by clustering instances, labels, and features using
probabilistic latent semantic analysis, respectively;
(l)
(l)†
(l−1) (l)†
(l)
= Ri Mij Cj , MiY
=
3:
Initialize Mij


−1 T
(l)†
(l−1) (l)†
Ri MiY CY where R† = RT R
R and C † =

−1
(0)
(0)
C CT C
. Note that Mij = X̃ij , and MiY = Yi ;
4:
repeat
(l)
5:
Update R̃i (1 ≤ i ≤ T ) by Eq. 7 and Eq. 8;
(l)
(l)
6:
Update Cj (1 ≤ j ≤ V ) and CY by Eq. 9 and Eq. 10;
(l)
(l)
7:
Update Mij and MiY where 1 ≤ i ≤ T, 1 ≤ j ≤ V
by Eq. 11 and Eq. 12;
8:
until converged
9: end for;
10: repeat
(L)
(L)
11:
Update Mij and MiY where 1 ≤ i ≤ T, 1 ≤ j ≤ V
by Eq. 17 and Eq. 18;
12:
for l = L : 1 do
(l)
13:
Update Ri (1 ≤ i ≤ T ) and Riu by Eq. 13 and Eq. 14;
(l)
(l)
14:
Update Cj (1 ≤ j ≤ V ) and CY by Eq. 15 and Eq. 16;
(l)
(l)
15:
Update Mij and MiY where 1 ≤ i ≤ T, 1 ≤ j ≤
V, l = L by Eq. 11 and Eq. 12;
16:
end for;
17: until converged
18: return Predictions for the test data using Eq. 5.







V
 
(1:L)
(L)T
(1:L)
(L)T

+ αΦ Yi CY
Φ Xij Cj
Mij
MiY

 j=1
(l)
= Ri  




 
V
(1:L)
(L)T
(1:L)
(L)T

+ αΦ ΩiY CY
Φ Ωij Cj
Mij
MiY
j=1

u

Ri

(13)


V


u C (1:L) M (L)T R(2:L)T

Xij
j
ij
i

j=1

u
= Ri  
(14)
 
V
(2:L)
(L) (1:L)T
(1:L)
(L)T (2:L)T

Riu Ri
Mij Cj
Cj
Mij
Ri
j=1

(l)


 T
  (1:l−1)T T (1:L) (L) (l+1:L)T

Mij Cj
X̃ij R̃i
 i=1 Cj
(l)
= Cj  

 T
(1:l−1)T T (1:L)
(L) (l+1:L)T
Cj
Mij Cj
Ω̃ij R̃i

(l)


 T
  (1:l−1)T T (1:L) (L) (l+1:L)T

Y i Ri
MiY CY
 i=1 CY
(l)
= CY  

 T
(1:l−1)T T
(1:L)
(L) (l+1:L)T
CY
ΩiY Ri
MiY CY

Cj

(15)

i=1

CY

(16)

i=1


 (1:L)T
(1:L)
(L)
 R̃
+ βMiY
X̃ij Cj
 i
(L)
(L)
Mij = Mij   (1:L)T
(1:L)
(L)
+ βMij
R̃i
Ω̃ij Cj


V


(1:L)T
(1:L)
(L)
 αRi
Y i CY
+β
Mij

j=1
(L)
(L)

MiY = MiY 
(1:L)T
(1:L)
(L)
αRi
ΩiY CY
+ βV MiY

(17)

(18)

Proof. Please see Appendix B.
(l)

After obtaining Ri
(l)

(l)

(l)

and Cj , we can update Mij and

MiY (1 ≤ l < L) by using the updating rule got in the pretraining phase.
Based on Theorem 3.1 and Theorem 3.2, we summarize
the optimization algorithm for HiMLS in Algorithm 1. There
are two training phases including pre-training and ﬁne-tuning
in Algorithm 1. As shown in Steps 1-9, the pre-training
phase goes forward from the ﬁrst layer to the highest layer,
and each layer is trained in a greedy layer-wise manner. In
contrast, the ﬁne-tuning phase shown in Steps 10-17 moves
in an opposite direction, and the weights of all the layers
will be updated. The convergence of the HiMLS algorithm
is guaranteed by Theorem 3.1 and Theorem 3.2.




O(Mij ) = O pN ni dj + qdj + pq + q 2



O(MiY ) = O pN ni m + qm + pq + q 2
where 1 ≤ i ≤ T, 1 ≤ j ≤ V and N is the number of iteration
until convergence.
Note that the dimensionalities of the latent spaces are
usually far smaller than the ones in the original spaces, i.e.,
p 	 ni and q 	 dj . Theorem 3.3 shows that the multiplicative update rules for pre-training are scalable to the
problem sizes. Likewise, we can obtain the time complexity
of the update rules for ﬁne-tuning, which are omitted due
to space limit.

Time complexity: Similar to other matrix factorization methods based on multiplicative update rules [16, 7], a
nice property of the proposed HiMLS algorithm is that most
of the computations are matrix multiplications and can be
computed eﬃciently. Theorem 3.3 shows the complexity of
the algorithm. The proof is omitted for brevity.

4.

Theorem 3.3 (Complexity). The time complexity for
the multiplicative update rules in Theorem 3.1 are as follows:
 V


ni N pq + q 2 + dj q + mq
O(Ri ) = O(Riu ) = O
j=1

O(Cj ) = O
O(CY ) = O

 T
i=1

 T
i=1

THE SPECIAL CASES OF HIMLS

The proposed model is a generalized framework for learning complex heterogeneity. It is widely applicable to multiple types of heterogeneous learning problems.
A special case of HiMLS is to learn the common co-latent
space M shared among all the tasks, view, and labels, i.e.,
Mij = MiY = M (1 ≤ i ≤ T, 1 ≤ j ≤ V ). And by using the
training data only, Eq. 2 can be specialized as:



dj N ni p + pq + p2

min



mN ni p + pq + p2

R,M,C

1379

V 
T 
T 
2
2






Xij − Ri M CjT  + α
Yi − Ri M CYT 
i=1 j=1

F

i=1

F

(19)

It is worth noting that Eq. 19 is not a trivial special case.
Theorem 4.1 shows that some popular methods for learning from single heterogeneity can be viewed as the special
cases of our proposed model, such as the multi-view learning method MSL [24] and the multi-label learning method
LS-CCA [22]. Both MSL and LS-CCA are closely related
to canonical correlation analysis (CCA), while MSL is a unsupervised learning method aiming to learn the subspace
from multiple views, and LS-CCA is a supervised learning
method for the multi-label problem when one of the views
used in CCA is derived from the labels.

Therefore, the ﬁrst special case of HiMLS is equivalent to applying CCA to the instance-feature matrices from multiple
views, which is equivalent to MSL [24]. The second special
case of HiMLS is equivalent to applying CCA to both the
instance-feature matrix and instance-label matrix, which is
equivalent to LS-CCA [22].

5.

Theorem 4.1. The multi-view learning method MSL [24]
and the multi-label learning method LS-CCA [22] can be
viewed as the special cases of HiMLS.
Proof. Consider two special cases of HiMLS for learning
from a single heterogeneity as follows:
1) Unsupervised multi-view learning: By letting T = 1,
V = 2, and α = 0, Eq. 19 can be rewritten into:


2
2




(20)
min X1 − RM C1T  + X2 − RM C2T 
R,M,C

F

5.1

F

F

F

where X and Y are the instance-feature matrix and instancelabel matrix, respectively.
Mathematically speaking, both Eq. 20 and Eq. 21 have
the same form as follows:

2


(22)
min [X, Y ] − HC T 
H,C

T

=



C1T , C2T




F

. Consider the normal
1
1
ized data matrix deﬁned as Z = (XX T )− 2 X, (Y Y T )− 2 Y .

where H = RM and C

When imposing the orthogonal constraint C T C = I, Eq. 22
can be rewritten into:

2


(23)
min Z − HC T 
T
H,C C=I

F

Let f (H, C) denote the objective function for Eq. 23, which
can be transformed into:


f (H, C) = tr Z T Z − 2CH T Z + H T H
When ﬁxing C, we have:
∇H f (H, C) = −2ZC + 2H = 0 ⇒ H = ZC
By substituting H = ZC into Eq. 23, we have

2


min Z − HC T 
F
C T C=I


T
= min tr Z Z − 2CC T Z T Z + C T Z T XC
C T C=I




= tr Z T Z − max tr C T Z T ZC

Data sets and Setup

Three online benchmark data sets 1 including two text
data sets and one image data set are used for evaluation.
The ﬁrst data set is the Reuters Corpus Volume I (RCV1V2) data set [17], which is a collection of over 800,000
newswire stories. There are three category sets of data: Topics (i.e. major subject of a story), Industry Codes (i.e. type
of business discussed), and Regions (i. e. geographic locations). Each of these category sets has a hierarchical structures. It is usually common to use several subsets of this
data, each containing 6000 data instances on average and
with a total number of 101 class labels.
EUR-Lex [18] is a text data set containing European Union oﬃcial laws in practice, diﬀerent kinds of treaties and
agreements, parliamentary journals. This data set contains nearly 20,000 text documents classiﬁed according to three
diﬀerent schemas: i) subject matter (e.g. agriculture), ii) ofﬁcial classiﬁcation hierarchy called the directory codes (e.g.
a document belonging to a class also belongs to all its parent classes), and iii) EUROVOC, a multilingual thesaurus
maintained by the Oﬃce for Oﬃcial Publications of the European Communities. Each of these category sets forms a
hierarchical structures.
NUS-WIDE 2 [6] is the a real-world web image data set
comprising over 269,000 images with over 5,000 user-provided
tags, and ground-truth of 81 concepts with a hierarchical
structures. There are several types of low-level visual features such as 64-D color histogram in LAB color space, 144D color correlogram in HSV color space, 73-D edge distribution histogram, and 500-D bag of visual words. We use the
light version of NUS-WIDE.
Table 1 shows the properties of diﬀerent data sets. Label cardinality is the average number of labels per instance.
Accordingly, label density normalizes label cardinality by
the the number of labels. Label diversity is the number of
distinct label combinations observed in the data set [33].
In these data sets, the label refer to the multiple categories
each instance belonging to. For the NUS-WIDE data, the
view refers to diﬀerent types of low-level visual feature. For
either RCV1V2 or EUR-Lex data sets, similar to [29], the
data are described from two views: one corresponds to the
TF-IDF features; another corresponds to the latent topics
obtained by applying probabilistic latent semantic analysis3
on the term counts. The task refers to classify the instances
belonging to diﬀerent sub-categories, which follow diﬀerent
but related distributions [11].

where Xj (j = 1, 2) is the instance-feature matrix for the j th
view.
2) Supervised multi-label learning: By letting T = 1, V =
1, and α = 1, Eq. 19 can be rewritten into:


2
2




(21)
min X − RM C1T  + Y − RM C2T 
R,M,C

EXPERIMENTS

In this section, we verify the eﬀectiveness of the proposed
algorithm on various data sets in comparison with the stateof-the-art techniques.

(24)

C T C=I

The optimal solution for C is given by the top k eigenvectors
of Z T Z. According to [24], Eq. 24 has the same optimal
solution with CCA which aims to optimize:


maxtr U T XY T V
s.t. U T XX T U = V T Y Y T V = I

1

http://mulan.sourceforge.net/datasets-mlc.html
http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm
3
http://lear.inrialpes.fr/people/verbeek/code
2

U,V

1380

Table 1: Statistics of Diﬀerent Data sets.
Data set
RCV1V2 1
RCV1V2 2
RCV1V2 3
RCV1V2 4
EUR-Lex
NUS-WIDE

Instances
6000
6000
6000
6000
19348
55615

Features
47236
47236
47229
47236
5000
708

Labels
101
101
101
101
412
81

Table 2: Comparison among HiMLS Variants on RCV1V2 1.
Algorithm
HiMLS
MLS
MLS-T
MLS-V
MLS-S

F1 -score
0.895±0.010
0.868±0.023
0.864±0.008
0.857±0.009
0.847±0.018

Accuracy
0.860±0.012
0.829±0.028
0.822±0.009
0.813±0.010
0.805±0.020

5.2

F1 -score
0.903±0.006
0.880±0.006
0.872±0.003
0.856±0.026
0.842±0.011

Accuracy
0.872±0.006
0.846±0.008
0.828±0.005
0.818±0.030
0.814±0.014

Hamming loss
0.081±0.007
0.102±0.018
0.106±0.006
0.107±0.005
0.116±0.011

Algorithm
HiMLS
MLS
MLS-T
MLS-V
MLS-S

Diversity
1028
954
939
816
1615
18430

F1 -score
0.900±0.006
0.878±0.011
0.871±0.019
0.860±0.003
0.854±0.018

Accuracy
0.869±0.006
0.844±0.012
0.841±0.022
0.820±0.004
0.814±0.024

Hamming loss
0.076±0.003
0.096±0.007
0.091±0.012
0.103±0.001
0.106±0.013

Table 5: Comparison among HiMLS Variants on RCV1V2 4.
Algorithm
HiMLS
MLS
MLS-T
MLS-V
MLS-S

Hamming loss
0.073±0.003
0.089±0.004
0.098±0.005
0.102±0.017
0.100±0.007

F1 -score
0.894±0.002
0.874±0.010
0.864±0.019
0.859±0.016
0.851±0.013

Accuracy
0.860±0.002
0.835±0.012
0.825±0.023
0.816±0.020
0.807±0.016

Hamming loss
0.082±0.002
0.097±0.008
0.103±0.014
0.106±0.013
0.113±0.011

HiMLS and MLS are input with multi-task and multi-view
data. For the single-view setting, the features from all the
views are concatenated into one single view. For the singletask setting, the instances in all the tasks are pooled into
one single task. For HiMLS, we empirically set the number
of layers L = 2, and the numbers of latent topics [p, q] for
the instances and features(or labels) to [200, 100], [40, 20] in
the ﬁrst and second layer, respectively. For all the other
methods with only one layer, we set [p, q] = [40, 20].
The classiﬁcation performances of HiMLS and its variants
on RCV1V2 data sets are shown on Tables 2-5. Based on
these comparison results, we have the following ﬁndings:

Evaluation Metrics

In order to comprehensively investigate the performance
of the proposed method, we use F1 -score, accuracy and
Hamming loss on the test data as the evaluation metrics.
F1 -score [33] is the harmonic mean of precision and recall
where precision is the proportion of predicted correct labels
to the total number of actual labels, recall is the proportion
of predicted correct labels to the total number of predicted
labels, averaged over all instances. Note that the larger value
of F1 -score is indicating the better performance.
Accuracy [33] for each instance is deﬁned as the proportion of the predicted correct labels to the total number of
labels for that instance. Overall accuracy is the average
across all instances. Note that the larger value of accuracy
is indicating the better performance.
Hamming Loss [33] reports how many times on average,
the relevance of an instance to a class label is incorrectly
predicted. Therefore, hamming loss takes into account the
prediction error (an incorrect label is predicted) and the
missing error (a relevant label not predicted), normalized
over total number of classes and total number of instances.
Note that the smaller the value of Hamming loss, the better
the performance of the learning algorithm.

5.3

Density
0.029
0.026
0.026
0.025
0.003
0.023

Table 4: Comparison among HiMLS Variants on RCV1V2 3.

Table 3: Comparison among HiMLS Variants on RCV1V2 2.
Algorithm
HiMLS
MLS
MLS-T
MLS-V
MLS-S

Cardinality
2.880
2.634
2.614
2.484
1.292
1.869

• Both MLS-T and MLS-V perform better than MLS-S
in most cases by incorporating either task relatedness
or view consistency. It suggests that simply concatenating the features from diﬀerent views is not the best
way to model the view heterogeneity; likewise, simply
pooling the instances of all tasks into one single task
is not the best way to model the task heterogeneity.
• MLS perform better than either MLS-T or MLS-V in
most cases. It suggests that jointly modeling multiple
types of heterogeneity can gain performance improvement upon single-heterogeneity learning.

Effectiveness of HiMLS components

• HiMLS performs better than MLS. It indicates that
the learned hierarchical multi-latent space helps build
a more robust and discriminative classiﬁer. One possible reason to account for this is that the multi-layer
structure helps ﬁnd the local optimum in a higher quality by gradually learning the abstract concepts. In
contrast, the single-layer methods may suﬀer from the
local optimal solution in lower quality.

In order to demonstrate the eﬀectiveness of simultaneously modeling the multiple heterogeneity in a multi-layer
framework, we compare HiMLS with its four variants with
only one layer: 1) multi-task multi-view variant MLS; 2)
multi-task single-view variant MLS-T; 3) multi-view singletask variant MLS-V; 4) single-task single-view variant MLSS.

1381

Table 6: Classiﬁcation performance on RCV1V2 1.
Algorithm
HiMLS
L2 F
ML-kNN
LS-ML
TRAM

F1 -score
0.895±0.010
0.847±0.011
0.803±0.092
0.821±0.021
0.888±0.003

Accuracy
0.860±0.012
0.802±0.015
0.775±0.094
0.789±0.019
0.857±0.004

HiMLS is input with multi-task and multi-view data. For
the other algorithms, the instances of all the tasks are pooled
together. L2 F method is given the multi-view features,
whereas the other methods are given the concatenated features from all the views. The parameters are tuned for each
algorithm using cross-validation on the training data. We
repeat the experiments ten times for each data set and report the average performances and the standard deviations.
Tables 6-9 show the classiﬁcation performances of diﬀerent
methods on RCV1V2. The performances on EUR-Lex and
NUS-WIDE are shown in Tables 10-11, respectively.
From these results, we can see that HiMLS performs better than the other algorithms in most cases. For ML-kNN [32],
since it ignores the correlation among multiple labels, its
performance on these data sets is not comparable with the
other methods. In contrast, LS-ML [14] learns a common
subspace shared among multiple labels, which helps improve
the learning performance for the multi-label data. However,
since its objective function is non-convex, the performance
of LS-ML may be limited by the local optimum problem.
TRAM [15] is a tranductive multi-label learning method
which tries to exploit the information from unlabeled data
to estimate the optimal label concept compositions. The results show that unlabeled data can provide helpful information to build the multi-label classiﬁer. Diﬀerent from these
methods for learning from single heterogeneity, both HiMLS and L2 F [27] model the feature and label heterogeneity
and gain performance improvement by enhancing the view
consistency. It suggests that treating the features from different views in a discriminative and complementary way is
usually better than just concatenating all the features into
one view. Likewise, treating the instances in diﬀerent tasks
discriminatively is usually better than just pooling all the
instances together. The performance superiority of HiMLS
over the comparison methods veriﬁes the eﬀectiveness of the
proposed approach to model the complex heterogeneity in
a principled framework. Another important competency of
HiMLS is that its multi-layer structure helps build a robust
classiﬁer by gradually ﬁnding the more high-level concepts
in the deep structures.
TRAM performs a little better than HiMLS on NUSWIDE data set. It indicates that NUS-WIDE may be consistent with the smoothness assumption, and TRAM is able
to eﬀectively leverage this assumption.

Hamming loss
0.081±0.007
0.110±0.009
0.102±0.038
0.109±0.005
0.082±0.003

Table 7: Classiﬁcation performance on RCV1V2 2.
Algorithm
HiMLS
L2 F
ML-kNN
LS-ML
TRAM

F1 -score
0.903±0.006
0.884±0.005
0.772±0.009
0.828±0.019
0.874±0.004

Accuracy
0.872±0.006
0.850±0.005
0.751±0.008
0.799±0.016
0.848±0.004

Hamming loss
0.073±0.003
0.083±0.003
0.103±0.001
0.100±0.004
0.079±0.002

Table 8: Classiﬁcation performance on RCV1V2 3.
Algorithm
HiMLS
L2 F
ML-kNN
LS-ML
TRAM

F1 -score
0.900±0.006
0.837±0.008
0.764±0.005
0.816±0.010
0.873±0.006

Accuracy
0.869±0.006
0.788±0.010
0.738±0.006
0.785±0.006
0.846±0.005

Hamming loss
0.076±0.003
0.120±0.005
0.115±0.001
0.107±0.003
0.081±0.003

Table 9: Classiﬁcation performance on RCV1V2 4.
Algorithm
HiMLS
L2 F
ML-kNN
LS-ML
TRAM

F1 -score
0.894±0.002
0.858±0.005
0.754±0.005
0.831±0.017
0.870±0.004

Accuracy
0.860±0.002
0.816±0.005
0.728±0.007
0.801±0.015
0.851±0.006

Hamming loss
0.082±0.002
0.106±0.005
0.118±0.004
0.104±0.004
0.075±0.004

Table 10: Classiﬁcation performance on EUR-Lex.
Algorithm
HiMLS
L2 F
ML-kNN
LS-ML
TRAM

F1 -score
0.749±0.009
0.713±0.020
0.498±0.029
0.664±0.013
0.667±0.016

Accuracy
0.719±0.011
0.680±0.020
0.472±0.027
0.631±0.013
0.635±0.016

Hamming loss
0.033±0.002
0.033±0.003
0.043±0.002
0.088±0.006
0.040±0.002

Table 11: Classiﬁcation performance on NUS-WIDE.
Algorithm
HiMLS
L2 F
ML-kNN
LS-ML
TRAM

5.4

F1 -score
0.675±0.007
0.700±0.001
0.589±0.004
0.628±0.021
0.684±0.007

Accuracy
0.645±0.006
0.615±0.002
0.582±0.003
0.618±0.020
0.676±0.008

Hamming loss
0.187±0.003
0.204±0.002
0.215±0.002
0.190±0.008
0.166±0.003

5.5

Parameter Sensitivity and Convergence

We study the parameter sensitivity on the RCV1V2 1 data set. α and β are tuned on the grid 10[−3:1:3] . The results
are shown in Figure 1(a-b). α is used to balance the importance of classiﬁcation loss. The algorithm performs worse
as α approaches 0. When α = 0, it means that no label
information is used for training. The optimal performance
is achieved at α = 1. Nevertheless, the performance is quite
robust over a wide range of values of α. β is used to control the importance of regularization. The result shown in
Figure 1(b) indicates that setting appropriate weight to the
regularization term can lead to better performance. As a
result, we tune the parameters, α and β, for each data set
by cross-validation on the training data.
Here, we empirically study the convergence of HiMLS on
the RCV1V2 1 data set. The result is shown in Figure 1(c).
From this ﬁgure, we can see that HiMLS converges fast and
its performance becomes stable after 50 iterations.

Performance Comparison

In this work, we focus on improving the performance of
multi-label learning by leveraging the multiple type of heterogeneity. To the best of our knowledge, there is no previous work for learning from the triple heterogeneity. Therefore, we compare HiMLS with a variety of multi-label learning methods which learn from single or dual heterogeneity.
The comparison approaches includes: 1) multi-view multilabel learning methods L2 F [27]; 2) graph-based multi-label
approach ML-kNN [32]; 3) multi-label method based on subspace learning LS-ML [14]; 4) transductive multi-label learning approach TRAM [15].

1382

0.95

0.95

0.9
0.88

0.85
0.8

F1−score

0.9

F1−score

F1−score

0.9

0.85

0.86
0.84
0.82

0.8
0.8

0.75
0 0.001 0.01 0.1

α

1

10

100 1000

0.75
0

0.001 0.01

0.1

β

1

10

100 1000

0.78
0

10

20

30

Iteration

40

50

60

Figure 1: From left to right: a) F1 -score vs. α (log10 scale); b) F1 -score vs. β (log10 scale); c) F1 -score vs. iteration.

6.

CONCLUSION

[10] P. Gong, J. Ye, and C. Zhang. Robust multi-task
feature learning. In KDD, pages 895–903, 2012.
[11] J. He and R. Lawrence. A graph-based framework for
multi-task multi-view learning. In ICML, pages 25–32,
2011.
[12] S.-J. Huang, Y. Yu, and Z.-H. Zhou. Multi-label
hypothesis reuse. In KDD, pages 525–533, 2012.
[13] S.-J. Huang and Z.-H. Zhou. Multi-label learning by
exploiting label correlations locally. In AAAI, pages
1–7, 2012.
[14] S. Ji, L. Tang, S. Yu, and J. Ye. Extracting shared
subspace for multi-label classiﬁcation. In KDD, pages
381–389, 2008.
[15] X. Kong, M. K. Ng, and Z.-H. Zhou. Transductive
multilabel learning via label set propagation. IEEE
Trans. Knowl. Data Eng. (TKDE), pages 704–719,
2013.
[16] D. D. Lee and H. S. Seung. Algorithms for
non-negative matrix factorization. In NIPS, pages
556–562, 2000.
[17] D. D. Lewis, Y. Yang, T. G. Rose, and F. Li. Rcv1: A
new benchmark collection for text categorization
research. Journal of Machine Learning Research
(JMLR), 5:361–397, 2004.
[18] E. L. Mencı́a and J. Fürnkranz. Eﬃcient pairwise
multilabel classiﬁcation for large-scale problems in the
legal domain. In ECML-PKDD, pages 126–135, 2008.
[19] V. Sindhwani and D. S. Rosenberg. An rkhs for
multi-view learning and manifold co-regularization. In
ICML, pages 976–983, 2008.
[20] K. Sridharan and S. M. Kakade. An information
theoretic framework for multi-view learning. In COLT,
pages 403–414, 2008.
[21] L. Sun, S. Ji, and J. Ye. Hypergraph spectral learning
for multi-label classiﬁcation. In KDD, pages 668–676,
2008.
[22] L. Sun, S. Ji, and J. Ye. Canonical correlation analysis
for multilabel classiﬁcation: A least-squares
formulation, extensions, and analysis. IEEE Trans.
Pattern Anal. Mach. Intell., 33(1):194–200, 2011.
[23] G. Tsoumakas and I. Katakis. Multi-label
classiﬁcation: An overview. International Journal of
Data Warehousing and Mining, 3(3):1–13, 2007.
[24] M. White, Y. Yu, X. Zhang, and D. Schuurmans.
Convex multi-view subspace learning. In NIPS, pages
1682–1690, 2012.

In this paper, we propose a multi-layer framework to jointly model triple heterogeneity. In each layer, we learn a multilatent space shared among the instances and labels from
multiple tasks, and features from multiple views. Then the
multi-latent model is used as a building block to stack up a
multi-layer structure so as to gradually learn the more abstract concepts. A deep learning algorithm is proposed to
solve the optimization problem, which ﬁrst pre-trains each
layer and then ﬁne-tunes the whole multi-layer structure by
using the multiplicative update rules. The comparison experiments with state-of-the-art methods demonstrate the effectiveness of the proposed model.
Acknowledgment This work is partially supported by
the NSF (No. IIS1017415), the Army Research Laboratory
(No. W911NF-09-2-0053), Region II University Transportation Center (No. 49997-33 25), DARPA (No. W911NF-11C-0200 and W911NF-12-C-0028), and NSFC (No. 61473123).

7.

REFERENCES

[1] R. K. Ando and T. Zhang. A framework for learning
predictive structures from multiple tasks and
unlabeled data. Journal of Machine Learning Research
(JMLR), 6:1817–1853, 2005.
[2] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task
feature learning. In NIPS, pages 41–48, 2006.
[3] A. Blum and T. Mitchell. Combining labeled and
unlabeled data with co-training. In COLT, pages
92–100, 1998.
[4] R. Caruana. Multitask learning. Machine Learning,
28(1):41–75, 1997.
[5] N. Chen, J. Zhu, and E. P. Xing. Predictive subspace
learning for multi-view data: a large margin approach.
In NIPS, 2010.
[6] T. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and
Y. Zheng. NUS-WIDE: a real-world web image
database from national university of singapore. In
CIVR, 2009.
[7] C. H. Q. Ding, T. Li, W. Peng, and H. Park.
Orthogonal nonnegative matrix tri-factorizations for
clustering. In KDD, pages 126–135, 2006.
[8] A. Elisseeﬀ and J. Weston. A kernel method for
multi-labelled classiﬁcation. In NIPS, pages 681–687,
2001.
[9] J. D. R. Farquhar, D. R. Hardoon, H. Meng,
J. Shawe-Taylor, and S. Szedmák. Two view learning:
Svm-2k, theory and practice. In NIPS, 2005.

1383

Based on Lemma 3.1, we can derive the updating rule for
Mij as in Eq. 11.
5) Update rule for MiY : The objective function for MiY
is as follows:
V
2




MiY − Mij 2F
J (MiY ) = α Yi − Ri MiY CYT  + β

[25] H. Yang and J. He. Learning with dual heterogeneity:
A nonparametric bayes model. In KDD, pages
582–590, 2014.
[26] P. Yang, J. He, and J.-Y. Pan. Learning complex rare
categories with dual heterogeneity. In SDM, 2015.
[27] P. Yang, J. He, H. Yang, and H. Fu. Learning from
label and feature heterogeneity. In ICDM, 2014.
[28] H.-F. Yu, P. Jain, P. Kar, and I. S. Dhillon.
Large-scale multi-label learning with missing labels. In
ICML, pages 593–601, 2014.
[29] D. Zhang, J. He, and R. D. Lawrence. Mi2ls:
multi-instance learning from multiple
informationsources. In KDD, pages 149–157, 2013.
[30] J. Zhang and J. Huan. Inductive multi-task learning
with multiple view data. In KDD, pages 543–551,
2012.
[31] M.-L. Zhang and K. Zhang. Multi-label learning by
exploiting label dependency. In KDD, pages 999–1008,
2010.
[32] M.-L. Zhang and Z.-H. Zhou. Ml-knn: A lazy learning
approach to multi-label learning. Pattern Recognition,
pages 2038–2048, 2007.
[33] M.-L. Zhang and Z.-H. Zhou. A review on multi-label
learning algorithms. IEEE Transactions on Knowledge
and Data Engineering, 26(8):1819–1837, 2014.
[34] J. Zhou, J. Chen, and J. Ye. Clustered multi-task
learning via alternating structure optimization. In
NIPS, pages 702–710, 2011.

F

B.

F

Based on Lemma 3.1, we can derive the updating rule for
(l)
Ri and Riu as in Eq. 13 and Eq. 14, respectively.
(l)
(l)
2) Update rule for Cj : The objective function for Cj is
as follows:
T 
2
 


(l)
(1:L)
(L) (1:L)T 
Mij Cj
=
J Cj
X̃ij − R̃i

Based on Lemma 3.1, we can derive the updating rule for
(l)
Cj as in Eq. 15.
(l)

(l)

3) Update rule for CY : The objective function for CY is
as follows:
T 
2




(l)
(1:L)
(L) (1:L)T 
MiY CY
J CY = α
Yi − Ri

F

i=1

Based on Lemma 3.1, we can derive the updating rule for
(l)
Cj as in Eq. 16.

F

(L)

(L)

4) Update rule for Mij : The objective function for Mij
is as follows:
2

L
1

 




(L)
(l)
(L)
(l)T 
Cj 
R̃i · Mij ·
= X̃ij −
J Mij


l=1
l=L
F

2
 (L)
(L) 
+ β Mij − MiY 

F

F

Based on Lemma 3.1, we can derive the updating rule for
Cj as Eq. 9.
3) Update rule for CY : The objective function for CY is
as follows:
T 
2


T
J (CY ) = α
Yi − Ri MiY CY 

Based on Lemma 3.1, we can derive the updating rule for
(L)
Mij as in Eq. 17.
(L)

(L)

5) Update rule for MiY : The objective function for MiY
is as follows:
2




(L)
(1:L)
(L)
(1:L)T 
· MiY · CY
J MiY = α Yi − Ri
 +

F

i=1

F

i=1

Based on Lemma 3.1, we can derive the updating rules for
Ri and Riu as in Eq. 7 and Eq. 8, respectively.
2) Update rule for Cj : The objective function for Cj is as
follows:
T 
2


T
J (Cj ) =
X̃ij − R̃i Mij Cj 
i=1

F

j=1


2

(1:L)
(L)
(1:L)T 
+ α Yi − Ri
· MiY · CY


Proof. Based on Lemma 3.1, we can derive the updating rules for the objective function in Eq. 2 and prove the
convergence and correctness. The detailed deduction is as
follows:
1) Update rule for Ri : The objective function for Ri is as
follows:
V 
2
2




T
T
J (Ri ) =
Xij − Ri Mij Cj  + α Yi − Ri MiY CY 
j=1

PROOF OF THEOREM 3.2

Proof. Based on Lemma 3.1, we can derive the updating rules for the objective function in Eq. 4 and prove the
convergence and correctness. The detailed deduction is as
follows:
(l)
(l)
1) Update rule for Ri : The objective function for Ri is
as follows:
V 
2
 


(l)
(1:L)
(L)
(1:L)T 
· Mij · Cj
=
J Ri
Xij − Ri


APPENDIX
A. PROOF OF THEOREM 3.1

F

j=1

Based on Lemma 3.1, we can derive the updating rule for
MiY as in Eq. 12.

V 
2

 (L)
(L) 
β
Mij − MiY 

Based on Lemma 3.1, we can derive the updating rule for
CY as in Eq. 10.
4) Update rule for Mij : The objective function for Mij is
as follows:

2


J (Mij ) = X̃ij − R̃i Mij CjT  + β Mij − MiY 2F

j=1

F

F

Based on Lemma 3.1, we can derive the updating rule for
(L)
MiY as in Eq. 18.

F

1384

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Co-Selection of Features and Instances for Unsupervised Rare
Category Analysis
Jingrui He∗

Jaime Carbonell∗

Abstract
Rare category analysis is of key importance both in theory
and in practice. Previous research work focuses on supervised rare category analysis, such as rare category detection
and rare category classification. In this paper, for the first
time, we address the challenge of unsupervised rare category analysis, including feature selection and rare category
selection. We propose to jointly deal with the two correlated
tasks so that they can benefit from each other. To this end,
we design an optimization framework which is able to coselect the relevant features and the examples from the rare
category (a.k.a. the minority class). It is well justified theoretically. Furthermore, we develop the Partial Augmented
Lagrangian Method (PALM) to solve the optimization problem. Experimental results on both synthetic and real data
sets show the effectiveness of the proposed method.
1 Introduction
Rare category analysis refers to the problem of detecting
and characterizing the minority classes in an unlabeled data
set. It is of key importance both in theory and in practice.
For example, in financial fraud detection, most transactions
are legitimate, which constitute the majority class, and the
fraudulent transactions of the same type correspond to one
minority class. Detecting and analyzing a new type of
fraud transactions help us prevent similar transactions from
happening in the future.
Existing research work on rare category analysis applies
in supervised settings, either having access to a labeling
oracle (rare category detection), or given labeled examples
from all the classes (rare category classification). In this
paper, we focus on unsupervised rare category analysis, i.e.
no label information is available in the learning process,
and address the following two problems: (1) rare category
selection, i.e. selecting a set of examples which are likely
to come from the minority class; (2) feature selection, i.e.
selecting the features that are relevant to identify the minority
class.
The key observation is that the above two tasks are correlated with each other. On one hand, the analysis of the
minority class examples helps us identify the relevant fea∗ Carnegie

Mellon University.

525

tures; on the other hand, the identification of the relevant
features is crucial to the selection of the minority class examples. Therefore, we propose to jointly deal with the two
tasks so that they can benefit from each other. To this end,
we formulate the problem as a well justified optimization
framework, which co-selects the relevant features and the examples from the minority class. Furthermore, we design an
effective search procedure based on augmented Lagrangian
method. The basic idea is to alternatively find the relevant features and the minority class examples. Finally, we
demonstrate the performance of the proposed method by extensive experimental results.
The main contributions of this paper can be summarized
as follows.
Problem Definition. To the best of our knowledge,
we are the first to address the two important tasks in
unsupervised rare category analysis; and we propose to
jointly deal with them;
Problem Formulation. We design an optimization
framework for the co-selection of features and instances, which is well justified theoretically;
Search Procedure. We develop an effective algorithm
to solve the optimization problem which is based on
augmented Lagrangian.
The rest of the paper is organized as follows: in Section
2, we review related work; then in Section 3, we present the
optimization framework with theoretical justification; Section 4 introduces the algorithm for solving the optimization
problem; experimental results are given in Section 5; finally,
we conclude in Section 6.
2 Related Work
In this section, we review related work on supervised rare
category analysis, anomaly detection and unsupervised feature selection. Supervised rare category analysis can be further divided into two major groups, rare category detection
and rare category classification.
Rare Category Detection. Here, the goal is to find at
least one example from each minority class with the help of
a labeling oracle, minimizing the number of label requests.

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Assuming the relevance of all the features, researchers have
developed several methods for rare category detection. For
example, in [25], the authors assumed a mixture model to
fit the data, and experimented with different hint selection
methods, of which Interleaving performs the best; in [12],
the authors studied functions with multiple output values,
and used active sampling to identify an example for each of
the possible output values; in [13], the authors developed
a new method for detecting an instance of each minority
class via an unsupervised local-density-differential sampling
strategy; and in [8], the authors presented an active learning
scheme that exploits cluster structure in the data, which was
proven to be effective in rare category detection. Different
from these methods, in our paper, no labeling oracle is
available for querying, and the goal is to select a set of
examples which are likely to come from the minority class.
Furthermore, we assume only some of the features are
relevant to the minority classes, and hope to identify those
features.
Rare Category Classification (Imbalanced Classification). Here, the goal is to construct an accurate classifier for the minority classes given labeled examples from all
the classes. Existing methods can be roughly categorized
into 3 groups [5], i.e. sampling based methods [21][19][6],
adapting learning algorithms by modifying objective functions or changing decision thresholds [28][16], and ensemble based methods [27][7]. Furthermore, some researchers
have worked on feature selection for imbalanced data to improve the performance of the classifier, such as in [30]. The
major difference between these methods and our method is
that we work in an unsupervised fashion, i.e. no labeled data
is available.
Anomaly Detection. Anomaly detection refers to the
problem of finding patterns in data that do not conform to
expected behavior [4]. According to [4], the majority of
anomaly detection techniques can be categorized into classification based [3], nearest neighbor based [26], clustering
based [29], information theoretic [15], spectral [10], and statistical techniques [1]. Compared with our method, anomaly
detection finds individual and isolated instances that differ
from a given class and from each other. Typically these
are in low-density regions. This is a very different process
than discovering a new compact class, where we are looking
for a local density spike and the minority class instances are
strongly self-similar.
Unsupervised Feature Selection. Generally speaking,
existing methods can be categorized as wrapper models and
filter models. The wrapper models evaluate feature subsets
based on the clustering results, such as the FSSEM algorithm [11], the mixture-based approach which extends to
the unsupervised context the mutual-information based criterion [20], and the ELSA algorithm [17]. The filter models are independent of the clustering algorithm, such as the

526

feature selection algorithm based on maximum information
compression index [23], the feature selection method using
distance-based entropy [9], and the feature selection method
based on Laplacian score [14]. Similar to unsupervised feature selection, in our paper, we also assume that the class
labels are unknown. However, in our settings, the class proportions are extremely skewed, and we are only interested
in the features relevant to the minority classes. In this case,
both wrapper and filter methods select the features primarily relevant to the majority classes. Therefore, we need new
methods that are tailored for our problem.
3 Optimization Framework
In this paper, we focus on the binary case, i.e. one majority
class and one minority class, and our goal is to (1) select a
set of examples which are likely to come from the minority
class, and (2) identify the features relevant to this minority
class. In this section, we formulate this problem as an optimization framework, and provide some theoretical justification.
3.1 Notation Let D = {x1 , . . . , xn }, xi ∈ Rd denote a
set of n unlabeled examples, which come from 2 classes,
i.e. the class labels yi ∈ {1, 2}, i = 1, . . . , n. yi = 1
corresponds to the majority class with prior 1−p, and yi = 2
corresponds to the minority class with prior p, p ¿ 1.
Furthermore, of the d features, only dr features are relevant
to the minority class. In other words, the examples from
the minority class have very similar values on those features,
and their values on the other features may be quite diverse.
For the sake of simplicity, assume that the dr features are
independent to each other. Therefore, the examples from
the minority class are tightly clustered in the dr -dimensional
subspace spanned by the relevant features, which we call the
relevant subspace.
Let Sdr denote the set of all dr -dimensional subspaces
of Rd , and let Smin denote the relevant subspace, Smin ∈
Sdr . Let f (x) denote the probability density function (pdf)
of the data in Rd , i.e. f (x) = (1 − p)fmaj (x) + pfmin (x),
where fmaj (x) and fmin (x) are the pdfs of the majority and
minority classes in Rd respectively. Given feature subspace
S ∈ Sdr and x ∈ Rd , let x(S) denote the projection of x on
(S)
(S)
S, and f (S) (x(S) ), fmaj (x(S) ) and fmin (x(S) ) denote the
projection of f (x), fmaj (x) and fmin (x) on S respectively.
To co-select the minority class examples and the relevant features, we define two vectors: a ∈ Rn and b ∈ Rd .
Let ai and bj denote the ith and j th elements of a and b respectively. ai = 1 if xi is from the minority class, and 0
otherwise; bj = 1 if the j th feature is relevant to the minority
class, and 0 otherwise.
3.2 Objective Function Given the prior p of the minority
class and the number of relevant features dr , we hope to find

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

np data points whose corresponding ai = 1, and dr features
whose corresponding bj = 1. Intuitively, the np points
should form a compact cluster in the relevant subspace, and
due to the characteristic of the minority class, this cluster
should be more compact than any other np data points in
any dr -dimensional subspace. To be more strict, we have the
following optimization problem.
Problem 1
min F (a, b) =
s.t.

n
X

1
np

n X
n
X

d
X

ai ak (

i=1 k=1

bj (xij − xkj )2 )

T HEOREM 3.1. If
1. In Smin , the support region of the minority class is
within hyper-ball B of radius r;

j=1

2. The support region of f
in any dr dimensional
subspace
is
bounded,
i.e.
maxS∈Sdr maxx,y∈Rd ,f (S) (x(S) )>0,f (S) (y(S) )>0 kx(S) −
y (S) k = α < +∞;

ai = np, ai = 0, 1

i=1
d
X

(i)

respect to zx(S) , i = 1, . . . , np.
Based on the above definitions, we have the following
theorem.

bj = dr , bj = 0, 1

j=1

Pd
In the objective function F (a, b), j=1 bj (xij − xkj )2 is
the squared distance between xi and xk in the subspace Sb
3. The density of the majority class in hyper-ball B is non(Smin ) (Smin )
spanned by the features with non-zero bj . This squared
zero, i.e. miny∈Rd ,y(Smin ) ∈B (1−p)fmaj
(y
)=
distance contributes to F (a, b) if and only if both ai and
f0 > 0;
ak are equal to 1. Given a set of np points, define the set
distance of every data point to be the sum of the squared
distances between this point and all the points within this set.
4. The function value of φS is big enough if the projection
Therefore, by solving this optimization problem, we aim to
of the data point in the dr -dimensional subspace S is
find a set of np points and dr features such that the average
S (S)
not within B, i.e. minS∈Sdr ,x∈Rd ,x(S) ∈B
)−
set distance of these points to this set in the corresponding
/ φ (x
2
subspace Sb is the minimum.
4r > β > 0;
Problem 1 can be easily applied to the case where either
a or b is known, and we want to solve for the other vector.
To be specific, if a is known, i.e. we know the examples
5. The number of examples is sufficiently large, i.e. n ≥
that belong to the minority class, and we want to find the
8
2C dr
max{ 2(VB1f0 )2 log 2δ , 4pα2 β 4 log δd }, where VB is the
dr -dimensional subspace where the minority class can be
best characterized, we can use the same objective function
volume of hyper-ball B, and Cddr is the number of d
F (a, b), and solve for b using the minority class examples.
choose dr ;
Similarly, if b is known, i.e. we know which features
are relevant to the minority class, and we want to find the
examples from the minority class, we can also use F (a, b), then with probability at least 1−δ, in the solution to Problem
and solve for a in the subspace Sb spanned by the relevant 1, the subspace Sb spanned by the features with bj = 1 is the
relevant subspace Smin , and the data points with ai = 1 are
features.
within B.
3.3 Justification The optimization problem we introduced in the last subsection is reasonable intuitively. Next,
Proof The basic idea of the proof is to show that if the
we look at it from a theoretical perspective.
selected
feature subspace Sb is NOT Smin , or at least one
S
∀S
∈
Sdr , define function ψ
as folpoint
in
the
set of np points is outside B in Smin , we can
d
S (S)
lows.
∀S ∈ Sdr ,Px ∈ R , let ψ (x ) =
always
use
S
1
(S)
(S) 2
min , and find another set of np points such
− y k
=
minDnp ⊂D,|Dnp |=np np y∈Dnp kx
that
all
the
points
are within B, and its objective function
P
(i)
(i)
np
1
(S)
− zx(S) k2 , where zx(S) denotes the ith near- is smaller than the original set. To do this, first, notice that
i=1 kx
np
(S)
(S)
est neighbor of x(S) within x1 , . . . , xn , i.e. ψ S (x(S) ) is according to condition (3), the expected proportion of data
n
(S)
the average squared distance between x and its np nearest points falling inside B, E( nB ) ≥ p + VB f0 , where nB
S
neighbors. Furthermore, define function φ as follows. denotes the number of points within B. Second, according
(i)
φS (x(S) ) = E(ψ S (x(S) )). Here, the expectation is with to condition (2), ∀x ∈ D, Pr[0 ≤ kx(S) −zx(s) k2 ≤ α2 ] = 1,

527

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

i = 1, . . . , np. Therefore,
nB
< p or ∃x ∈ D, ∃S ∈ Sdr ,
n
s.t. ψ S (x(S) ) < φS (x(S) ) − β]
nB
< p]
≤ Pr[
n
+ Pr[∃x ∈ D, ∃S ∈ Sdr , s.t. ψ S (x(S) ) < φS (x(S) ) − β]
nB
nB
− E(
) < −VB f0 ]
≤ Pr[
n
n
dr
+ nCd Pr[ψ S (x(S) ) < φS (x(S) ) − β]
nB
nB
− E(
) < −VB f0 ]
≤ Pr[
n
n
+ nCddr ·
Z
(np+1)
(np+1)
Pr[ψ S (x(S) ) < φS (x(S) ) − β|zx(S) ]dPr[zx(S) ]

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Pr[

(np+1)
x(S)

z

≤ exp(−2n(VB f0 )2 )
Z
2npβ 2
(np+1)
dr
)dPr[zx(S) ]
+ nCd
exp(−
4
(np+1)
α
z (S)
x

≤ exp(−2n(VB f0 )2 ) + nCddr exp(−

2npβ 2
)
α4

where Cddr is an upper bound on the number of subspaces in
Sdr , and the second last inequality is based on Hoeffding’s
inequality and condition (2)1 .
2
Let exp(−2n(VB f0 )2 ) ≤ 2δ , and nCddr exp(− 2npβ
α4 ) ≤
8

2C dr

we get n ≥ 2(VB1f0 )2 log 2δ , and n ≥ 4pα2 β 4 log δd .
In other words, if the number of examples n is sufficiently
δ
2,

8

2C dr

large, i.e. n ≥ max{ 2(VB1f0 )2 log 2δ , 4pα2 β 4 log δd }, then
with probability at least 1 − δ, there are at least np points
within hyper-ball B, and ∀x ∈ D, ∀S ∈ Sdr , ψ S (x(S) ) ≥
φS (x(S) ) − β. Furthermore, according to condition (4),
∀x ∈ D, ∀S ∈ Sdr , if x(S) ∈
/ B, ψ S (x(S) ) > 4r2 .
P
(S )
Notice that ∀a, ∀b, F (a, b) ≥ i:ai =1 ψ Sb (xi b ). On
the other hand, if Sb = Smin , and the points with ai = 1 are
within B in Smin , then F (a, b) < 4npr2 . This is because the
squared distance between any two points within B in Smin
is no bigger than 4r2 .
Given a and b, if Sb is not Smin , we can design a0
and b0 in such a way that Sb0 is Smin , and the points
that correspond to a0i = 1 are within B in Smin . We
can always find such a vector a0 since we have shown
that there are at least np points within B. Therefore,
P
(Sb )
Sb
F (a, b) ≥
) > 4npr2 > F (a0 , b0 ).
i:ai =1 ψ (xi
On the other hand, if Sb is Smin , but at least one point
with ai = 1 is outside B, we can design a0 and b0 in
such a way that b0 = b, and a0 replaces the points with

ai = 1 that are outside B with some points within B
that are different from existing points in a. For the
sake of simplicity, assume that only xt is outside B.
P P
(Smin )
1
−
Therefore, F (a, b) = np
i6=t
k6=t ai ak kxi
Pn
(Smin )
(Smin ) 2
(Smin ) 2
2
− xt
k
≥
xk
k + np i=1 ai kxi
P P
(Smin )
(Smin ) 2
1
−
xk
k
+
i6=t
k6=t ai ak kxi
np
P P
(Smin )
(Smin )
1
Smin
−
2ψ
(xt
) >
i6=t
k6=t ai ak kxi
np
(S

)

xk min k2 + 8r2 ≥ F (a0 , b0 ). The above derivation can be
easily generalized to the case where more than one point
with ai = 1 are outside B. Therefore, in the solution to
Problem 1, Sb is the relevant subspace Smin , and the data
points with ai = 1 are within B.¥
The conditions of Theorem 3.1 are straight-forward except conditions (3) and (4). The purpose of condition (3) is to
limit our attention to the problems where the support regions
of the majority and the minority classes overlap. According
to condition (4), ∀S ∈ Sdr , if x(S) ∈
/ B and y (Smin ) ∈ B,
S (S)
Smin (Smin )
φ (x ) is bigger than φ
(y
) by at least β when
there are at least np points within B in Smin . Therefore, this
condition can be roughly interpreted as follows. The density
around x(S) is smaller than the density around y (Smin ) such
that the expected average squared distance between x(S) and
its np nearest neighbors is much larger than that between
y (Smin ) and its np neighbors. In this way, assuming the other
conditions in Theorem 3.1 are also satisfied, with high probability, we can identify the relevant subspace and pick the
examples within B according to a.
It should be pointed out that if we want to select np
points from the minority class, picking them from hyperball B is the best we can hope for. In this way, each
selected example has a certain probability of coming from
the minority class. On the other hand, if some selected points
are outside B, their probability of coming from the minority
class is 0.

4 Partial Augmented Lagrangian Method
In this section, we introduce the Partial Augmented Lagrangian Method (PALM) to effectively solve Problem 1. In
our method, we alternate the optimization of a and b, i.e.
given the current estimate of a, we solve for b that leads to
the minimum value of F (a, b); given the current estimate of
b, we solve for a that decreases the value of F (a, b) as much
as possible.
To be specific, F (a, b) can be rewritten as F (a, b) =
Pd
Pn Pn
1
2
j=1 bj
i=1
k=1 np ai ak (xij − xkj ) . Therefore, given
a, we can solve for b as P
follows.
For each feature j,
n Pn
1
2
calculate its score saj = np
i=1
k=1 ai ak (xij − xkj ) .
Then find the dr features with the smallest scores, and set
their corresponding bj = 1. It is easy to show that this
vector b minimizes F (a, b) given a. On the other hand,
1 Note that given z (np+1) , ψ S (x(S) ) can be seen as the average of np
(S)
given b, solving for a is not straight-forward, since F (a, b)
x

independent items.

528

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

is not a convex function of a. Therefore, this problem
can not be solved by general binary integer programming
(BIP) algorithms. Even though BIP algorithms can be
combined with heuristics, the performance largely depends
on the heuristics employed. In this paper, we first relax
the constraints on a: instead of requiring that ai be binary,
we require that ai ∈ [0, 1], i.e. we solve the following
optimization problem of a:
Problem 2
min Fb (a) =

n
n
d
X
1 XX
ai ak (
bj (xij − xkj )2 )
np i=1
j=1
k=1

s.t.

n
X

ai = np, ai ∈ [0, 1]

i=1

Next we use augmented Lagrangian method [24] to
solve Problem 2 in an iterative way. The reason for using
augmented Lagrangian method is the following: it is a
combination of Lagrangian and quadratic penalty methods;
compared with the Lagrangian method, the addition of the
penalty terms to the Lagrangian function does not alter the
stationary point of the Lagrangian function, and can help
damp oscillations and improve convergence. Furthermore,
the penalty parameter does not have to go to infinity in
order to get the optimal solution [22]. Here, we define the
following augmented Lagrangian function
LA (a, λ, σ) =

n
n
d
X
1 XX
ai ak (
bj (xij − xkj )2 )
np i=1
j=1

have the Partial Augmented Lagrangian Method, which is
presented in Algorithm 1.
The algorithm works as follows. Given the initial values
λ0 and σ0 of λ and σ, and the maximum number of iteration
steps stepmax , it will output vectors a and b that correspond
to a local minimum of F (a, b). In Step 1, we initialize a
and b. Next, in Step 2, we assign λ and σ to their initial
values, and calculate Kprev , which is the maximum absolute
value of all the di (a) functions, i = 1, . . . , 2n + 1. Then
Step 4 to Step 16 are repeated stepmax times. In Step 4, we
minimize the augmented Lagrangian function with respect to
a, given the current estimates of λ, σ, and b. To be specific,
we use gradient descent to update a, and gradually decrease
the step size until convergence. Once we have obtained an
updated estimate of a, calculate K, which is the maximum
absolute value of the current di (a) functions. If the value of
K is less than a half of Kprev , then we update the Lagrange
multipliers using the formula in Step 7, which is called the
steepest ascent formula in [22]. Furthermore, we update
Kprev using the smaller value of K and Kprev . Otherwise,
if the value K is bigger than a half of Kprev , we double the
value of σ. Next, we update the value of b based on the
current estimate of a. To be specific, for each feature, we
calculate its score based on the formula in Step 14. Then in
Step 16, we pick dr features with the smallest scores, and set
the corresponding bj to 1, which minimizes F (a, b) given a.
In our experiments, the algorithm always converges around
20 iteration steps, so we set stepmax = 30.

Algorithm 1 Partial Augmented Lagrangian Method
(PALM)
σ
(4.1)
d2i (a)
−
λi di (a) +
Input: Initial values of λ and σ: λ0 and σ0 , stepmax
2 i=1
i=1
Output: a and b
1: Initialize a and b
where λi , i = 1, . . . , 2n + 1 are the Lagrange multipliers, σ
2: λ = λ0 , σ = σ0 , Kprev = kd(a)k∞
is a positive parameter, and di (a), i = 1, . . . , 2n + 1 are a
3: for step = 1 to stepmax do
set of functions defined as follows.
4:
a := arg mina LA (a, λ, σ), K := kd(a)k∞
K
n
then
5:
if K ≤ prev
ci (a) if i ≤ 1 or ci (a) ≤ λσi
2
di (a) =
λi
6:
for
i
=
1
to
2n + 1 do
otherwise
σ
7:
λi := λi − σdi (a)
n
X
8:
end for
c1 (a) =
ai − np = 0
9:
Kprev := min(K, Kprev )
i=1
10:
else
cj+1 (a) = aj ≥ 0, 1 ≤ j ≤ n
11:
σ := 2 × σ
ck+n+1 (a) = 1 − ak ≥ 0, 1 ≤ k ≤ n
12:
end if
13:
for j = 1 to d do
Here ci (a), i = 1, . . . , 2n+1, denote the original constraints
14:
Calculate the score for the j th feature saj =
Pn Pn
on a, both equality and inequality, and di (a) are truncated
1
2
i=1
k=1 ai ak (xij − xkj )
np
versions of ci (a), i.e. di (a) is equal to ci (a) if and only
end for
if the corresponding constraint is active or near-active; it is 15:
16:
Pick
dr features with the smallest scores, and set their
λi
fixed at σ otherwise.
corresponding
bj to 1
We minimize LA (a, λ, σ) based on Algorithm 4.20
17: end for
in [22]. Putting together the optimization of a and b, we
k=1

2n+1
X

2n+1
X

529

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

0.5

Z

Notice that the vectors a and b generated by PALM
correspond to a local minimum of F (a, b). To improve its
performance, we can run PALM with different initializations
of a and b in Step 1 of Algorithm 1, and pick the best values
of a and b that correspond to the smallest F (a, b).
The vectors a and b can be interpreted as follows. For b,
its dr non-zero elements correspond to the relevant features.
For a, ideally the minority class examples should correspond
Y
to ai = 1. However, this may not be the case in practice.
X
Therefore, we rank the elements of a from large to small,
Figure 1: An illustrative example. (Best viewed in color)
and hope to find all the minority class examples from the
top of the ranked list. In other words, the elements of a
that correspond to the top np examples of the ranked list are
Accuracy of feature selection. Next we test the preciconverted to 1; whereas the elements of a that correspond to
sion
of the selected features of PALM using synthetic data
the remaining examples are converted to 0.
sets with different prior p. Figure 2 shows the comparison
results of PALM with Laplacian score method [14], feature
5 Experimental Results
variance method (selecting the features with the largest variIn this section, we demonstrate the performance of PALM ance), CRO [18], and random sampling. The x-axis is the
from the following perspectives: (1) the quality of rare proportion of irrelevant features, and the y-axis is the precategory selection; (2) the quality of feature selection; (3) the cision of the selected features. From these results, we can
benefit of co-selecting features and instances simultaneously. see that PALM is much better than the other 4 methods esIn addition, we also want to (1) test the sensitivity of the pecially when the prior p is small. As for Laplacian score
proposed PALM to small perturbations in p and dr ; and method, although it is comparable with PALM for large p,
(2) compare the performance of PALM with binary integer its performance quickly deteriorates as p decreases (e.g. Figprogramming (BIP).
ure 2a and b), which is the case we are interested in for rare
In our experiments, we retrieve the minority class exam- category analysis.
ples from the ranked list generated by different methods, and
use the following performance measures: (1) the precision- 5.2 Real Data Sets
scope curve, i.e. the percentage of the minority class exam- Methods for comparison and data sets. In this subsection,
ples when a certain number of examples are retrieved, such we test the performance of PALM on rare category selection.
as 10% × np, . . . , 100% × np; (2) the recall-scope curve, i.e. To the best of our knowledge, there are no existing methods
the percentage of the minority class examples when a certain for this task. Therefore, we have designed the following
number of MINORITY class examples are retrieved, such as methods for the sake of comparison.
10% × np, . . . , 100% × np.
1. Random: randomly rank all the examples, and select
the first np points from the ranked list as the minority
5.1 Synthetic Data Sets
class examples.
An illustrative example. To demonstrate the performance
of PALM, we first use a simple synthetic data set shown in
2. NNDB-based: calculate the score of each example usFigure 1. In this figure, there are 1000 examples from the
ing NNDB [13]. Note that no feedback from the labelmajority class, denoted as black dots, which are uniformly
ing oracle is available, so the scores are not updated.
distributed in the feature space, and only 10 examples from
the minority class, denoted as red circles, whose features
3. Interleave-based: calculate the score of each example
on Z are uniformly distributed. Of the 3 features, only 2
using the Interleave principle [25]. Similar as the
features (X and Y ) are relevant to the minority class, i.e. the
NNDB-based method, the scores of the examples are
minority class examples have very similar values on these
not updated in this method.
features; and 1 feature (Z) is irrelevant to the minority class,
4. PALM-full: assume that all the features are relevant to
i.e. the minority class examples spread out on this feature.
the minority class, i.e. bj = 1, j = 1, . . . , d, and run
Using PALM, given the number of minority class examples
PALM with dr = d.
and the number of relevant features, we are able to identify
0

−0.5

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

0.5

0

0.5

−0.5

the relevant features, with the corresponding bj = 1. Of the
10 examples with the largest ai values, 9 examples are from
the minority class, and the remaining minority class example
has the 11th largest ai value.

530

0

−0.5

Note that NNDB-based method and Interleave-based method
are both derived from rare category detection methods. For
PALM, we tune the number of relevant features dr without
any label information.

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

PALM
Laplacian
Variance
CRO
Random

Precision

0.6

0.4

0
0

1
PALM
Laplacian
Variance
CRO
Random

0.8

0.2

0.6

0.8

0.4

0.2

0.2

0.4

0.6

0.8

0
0

1

Proportion of Irrelevant Features

0.6

0.4

0.2

0.2

0.4

0.6

0.8

0
0

1

Proportion of Irrelevant Features

(a) p = 0.01

0.8

0.8

0.8

0.4
PALM
Laplacian
Variance
CRO
Random
0.2

0.6

0.4

0.2

0.4

0.6

0.8

Proportion of Irrelevant Features

(d) p = 0.05

1

Precision

1

0.6

0
0

PALM
Laplacian
Variance
CRO
Random
0.2

0.6

0.8

Proportion of Irrelevant Features

(e) p = 0.1

0.6

0.8

1

0.6

0.4

0.2

0.4

0.4

(c) p = 0.02

1

0
0

0.2

Proportion of Irrelevant Features

1

0.2

PALM
Laplacian
Variance
CRO
Random

(b) p = 0.015

Precision

Precision

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Precision

0.8

1

Precision

1

1

0
0

PALM
Laplacian
Variance
CRO
Random
0.2

0.4

0.6

0.8

1

Proportion of Irrelevant Features

(f) p = 0.2

Figure 2: Precision of selected features on synthetic data.

Here we use 4 real data sets, which are summarized in
Table 1. In this paper, we focus on binary problems, i.e.
there is only one majority class and one minority class in the
data set. Therefore, for each data set, we construct several
subproblems as follows. We combine the examples from
two different classes into a smaller binary data set, using
the larger class as the majority class, the smaller class as the
minority class, and test the different methods on these binary
subproblems. For each data set, we present the results on
2 binary subproblems. On the other subproblems, similar
results are observed and therefore omitted for brevity.
Table 1: Properties of the data sets [2] used.

on different data sets, and none of them is consistently better
than Random. Comparing with Random, Interleave-based,
and NNDB-based, we can see that PALM does a better
job at selecting the minority class examples; comparing
with PALM-full, we can see that the features selected by
PALM indeed help improve the performance of rare category
selection.
Notice that in some figures (Figure 3b, Figure 4b,
Figure 5b, Figure 7b, and Figure 8b), at the end of the recall
curves, the different methods seem to overlap with each
other. This is because with no supervision, it is sometimes
difficult to retrieve all the examples from the minority class,
and the last example from the minority class tends to appear
DATA S ET
n
d L ARGEST S MALLEST
towards the end of the ranked list. Therefore, the recall value
C LASS
C LASS
at 100%np is often close to the prior of the minority class in
E COLI
336
7
42.56%
2.68%
the data set.
G LASS
214
9
35.51%
4.21%
Comparison with BIP. Next, in Figure 11 and FigA BALONE 4177 7
16.50%
0.34%
ure 12, we compare the performance of PALM and Binary
Y EAST
1484 8
31.20%
1.68%
where the vector a is obtained by a BIP algorithm combined
Accuracy of rare category selection. Figure 3 to with heuristics on Abalone data set. To be specific, in BiFigure 10 compare the performance of different methods on nary, we randomly initialize a binary vector a which satisfies
the 4 real data sets. In these figures, the left figure shows all the constraints in Problem 1. Then we pick each pair of
precision vs. scope, and the right figure shows recall vs. elements in a with different values, and swap their values if
2
scope. On all the data sets, PALM performs the best: the this leads to a smaller value of the objective function.
precision and recall sometimes reach 100%, such as Figure 8
2 We tested different heuristics, and only the best performance is reported
and Figure 9. As for the other methods (Interleave-based,
NNDB-based, and PALM-full), their performance depends here.

531

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

1
0.9
0.8
0.7

0.7
0.6
0.5

PALM
PALM−full
Random
NNDB−based
Interleave−based

0.6
0.5
0.4
0.3
0.2

0.4

0.1
0

0.3
0.2

−0.1

20

40

60

80

100

20

40

PALM
PALM−full
Random
NNDB−based
Interleave−based

0.9
0.8
0.7

Recall

Recall

0.7
0.6

PALM
PALM−full
Random
NNDB−based
Interleave−based

0.6
0.5
0.4

0.5

0.3

0.4

0.2

0.3

0.1

0.2

0
20

40

60

80

100

20

40

60

Figure 5: Ecoli data set: class 1 vs. class 4, p = 0.197, 3
features selected by PALM.

1.1

0.8

PALM
PALM−full
Random
NNDB−based
Interleave−based

PALM
PALM−full
Random
NNDB−based
Interleave−based

1

0.8

Precision

0.9

100

(b)

(b)

Figure 3: Abalone data set: class 1 vs. class 7, p = 0.362, 4
features selected by PALM.

1

80

Scope

Scope

Precision

100

1

1

0.8

80

(a)

(a)

0.9

60

Scope

Scope

0.7
0.6
0.5
0.4

0.6

0.4

0.2

0.3
0.2

20

40

60

80

0

100

20

40

Scope

0.8

1
PALM
PALM−full
Random
NNDB−based
Interleave−based

100

PALM
PALM−full
Random
NNDB−based
Interleave−based

0.9
0.8
0.7

Recall

0.9

80

(a)

1.1
1

60

Scope

(a)

Recall

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Precision

0.8

PALM
PALM−full
Random
NNDB−based
Interleave−based

Precision

0.9

0.7
0.6

0.6
0.5
0.4

0.5

0.3

0.4

0.2

0.3
0.2

0.1
20

40

60

80

0

100

Scope

20

40

60

80

100

Scope

(b)

Figure 4: Abalone data set: class 2 vs. class 7, p = 0.381, 4
features selected by PALM.

532

(b)

Figure 6: Ecoli data set: class 2 vs. class 4, p = 0.313, 4
features selected by PALM.

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

1

PALM
PALM−full
Random
NNDB−based
Interleave−based

1

0.8
0.7

Precision

Precision

0.8

0.9

0.6

0.5
0.4
0.3

0.2
0.2

0

0.1

20

40

60

80

100

0

Scope

20

40

60

80

100

Scope

(a)

(a)

PALM
PALM−full
Random
NNDB−based
Interleave−based

1

1
0.9
0.8
0.7

0.6

Recall

Recall

0.8

0.4

0.6
0.5

PALM
PALM−full
Random
NNDB−based
Interleave−based

0.4

0.2

0.3

0

0.2

20

40

60

80

0.1

100

Scope

0

20

40

60

80

100

Scope

(b)

Figure 7: Glass data set: class 1 vs. class 3, p = 0.195, 2
features selected by PALM.

1
PALM
PALM−full
Random
NNDB−based
Interleave−based

0.9
0.8
0.7

Precision

0.8

Precision

(b)

Figure 9: Yeast data set: class 2 vs. class 6, p = 0.093, 2
features selected by PALM.

PALM
PALM−full
Random
NNDB−based
Interleave−based

1

0.6

0.4

0.6
0.5
0.4
0.3

0.2
0.2
0.1

0
20

40

60

80

0

100

20

40

Scope

80

100

(a)

1

1
PALM
PALM−full
Random
NNDB−based
Interleave−based

0.9
0.8
0.7

PALM
PALM−full
Random
NNDB−based
Interleave−based

0.9
0.8
0.7

Recall

0.6
0.5

0.6
0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1
0

60

Scope

(a)

Recall

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

0.4

PALM
PALM−full
Random
NNDB−based
Interleave−based

0.6

0.1
20

40

60

80

0

100

Scope

20

40

60

80

100

Scope

(b)

Figure 8: Glass data set: class 2 vs. class 3, p = 0.183, 3
features selected by PALM.

533

(b)

Figure 10: Yeast data set: class 2 vs. class 9, p = 0.055, 3
features selected by PALM.

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

PALM
Binary

1

Precision

0.8
0.6
0.4
0.2
0
20

40

60

80

100

Scope

(a)

1

PALM
Binary

Recall

0.8
0.6
0.4
0.2
0
20

40

60

80

100

Scope

(b)

Figure 12: Abalone data set: class 2 vs. class 7, p = 0.381.

1

PALM+5%
PALM
PALM−5%

Precision

0.8

PALM
Binary

1

Precision

0.8

0.6

0.4

0.6

0.2
0.4

0
Abalone(2 vs.7)Ecoli(2 vs.4) Glass(1 vs.3) Yeast(2 vs.6)

0.2
0
20

40

60

80

(a)

100

Scope

(a)

1

PALM+5%
PALM
PALM−5%

0.8
PALM
Binary

Recall

1
0.8

Recall

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

The vector b is obtained in the same way as PALM.
From these figures, we can see that the performance of
Binary is consistently worse than PALM in terms of both
precision and recall, showing the effectiveness of PALM in
obtaining the vector a.
Sensitivity of PALM. Finally, we test the performance
of PALM when there are small perturbations in the prior
of the minority class and the number of relevant features.
To this end, we first run PALM with p increased by 5%
(PALM+5%) and decreased by 5% (PALM-5%) respectively, and compare their performance with PALM in Figure 13. From this figure, we can see that PALM is quite robust against small perturbations in p. Then we run PALM
with dr increased by 1 (PALM+1) and decreased by 1
(PALM-1) respectively, and compare their performance with
PALM and PALM-full in Figure 14. From this figure, we can
see that PALM is also robust against small perturbations in
dr in most cases (Abalone, Ecoli, and Glass), and in all the
cases, the performance of PALM+1 and PALM-1 is better
than PALM-full (i.e. PALM without feature selection).

0.6

0.6

0.4

0.4

0.2
0.2
0

0
Abalone(2 vs.7)Ecoli(2 vs.4) Glass(1 vs.3) Yeast(2 vs.6)
20

40

60

80

100

Scope

(b)

(b)

Figure 11: Abalone data set: class 1 vs. class 7, p = 0.362.

534

Figure 13: Perturbations on the prior of the minority class.
(Best viewed in color)

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

1

PALM−1
PALM
PALM+1
PALM−full

0.9
0.8

Precision

0.6
0.5
0.4
0.3
0.2
0.1
0

Abalone(2 vs.7) Ecoli(2 vs.4) Glass(1 vs.3) Yeast(2 vs.6)

(a)

1

PALM−1
PALM
PALM+1
PALM−full

0.8

Recall

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

0.7

0.6

0.4

0.2

0
Abalone(2 vs.7)Ecoli(2 vs.4) Glass(1 vs.3) Yeast(2 vs.6)

(b)

Figure 14: Perturbations on the number of relevant features.
(Best viewed in color)
6 Conclusion
In this paper, we address the problem of unsupervised rare
category analysis. To be specific, our goal is to co-select the
relevant features and the examples from the minority class.
To this end, we proposed an optimization framework, which
is well justified theoretically. To solve this optimization
problem, we designed the Partial Augmented Lagrangian
Method (PALM), which alternatively finds the relevant features and the minority class examples. The effectiveness
of PALM is demonstrated by extensive experimental results.
Future research work includes: (1) extending the optimization framework to multiple classes, which may be addressed
by running PALM with respect to the prior of each minority class, from large to small; (2) generalizing PALM to the
cases where the prior information (i.e. the prior of the minority class p and the number of relevant features dr ) is not
available, which may be addressed by introducing objective
functions to evaluate different values of p and dr .
References
[1] C. C. Aggarwal and P. S. Yu. Outlier detection for high
dimensional data. In SIGMOD, pages 37–46, 2001.
[2] A. Asuncion and D. Newman. UCI machine learning repository, 2007.

535

[3] D. Barbará, N. Wu, and S. Jajodia. Detecting novel network
intrusions using bayes estimators. In Proceedings of the First
SIAM Conference on Data Mining, April 2001.
[4] V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection:
A survey. ACM Computing Surveys, 2009.
[5] N. Chawla. Mining when classes are imbalanced, rare events
matter more, and errors have costs attached. In SDM, 2009.
[6] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P.
Kegelmeyer. Smote: Synthetic minority over-sampling technique. J. Artif. Intell. Res. (JAIR), 16:321–357, 2002.
[7] N. V. Chawla, A. Lazarevic, L. O. Hall, and K. W. Bowyer.
Smoteboost: Improving prediction of the minority class in
boosting. In PKDD, pages 107–119, 2003.
[8] S. Dasgupta and D. Hsu. Hierarchical sampling for active
learning. In ICML, pages 208–215, 2008.
[9] M. Dash, K. Choi, P. Scheuermann, and H. Liu. Feature
selection for clustering - a filter solution. In ICDM, pages
115–122, 2002.
[10] H. Dutta, C. Giannella, K. D. Borne, and H. Kargupta.
Distributed top-k outlier detection from astronomy catalogs
using the demac system. In SDM, 2007.
[11] J. G. Dy and C. E. Brodley. Feature subset selection and order
identification for unsupervised learning. In ICML, pages
247–254, 2000.
[12] S. Fine and Y. Mansour. Active sampling for multiple output
identification. In COLT, 2006.
[13] J. He and J. Carbonell. Nearest-neighbor-based active learning for rare category detection. In NIPS, pages 633–640. MIT
Press, 2007.
[14] X. He, D. Cai, and P. Niyogi. Laplacian score for feature
selection. In NIPS, 2005.
[15] Z. He, X. Xu, and S. Deng. An optimization model for outlier
detection in categorical data. CoRR, abs/cs/0503081, 2005.
[16] K. Huang, H. Yang, I. King, and M. R. Lyu. Learning
classifiers from imbalanced data based on biased minimax
probability machine. In CVPR (2), pages 558–563, 2004.
[17] Y. Kim, W. N. Street, and F. Menczer. Feature selection
in unsupervised learning via evolutionary search. In KDD,
pages 365–369, 2000.
[18] Y.-D. Kim and S. Choi. A method of initialization for
nonnegative matrix factorization. In ICASSP, pages II–537–
II–540, 2007.
[19] M. Kubat and S. Matwin. Addressing the curse of imbalanced
training sets: One-sided selection. In ICML, pages 179–186,
1997.
[20] M. H. C. Law, A. K. Jain, and M. A. T. Figueiredo. Feature
selection in mixture-based clustering. In NIPS, pages 625–
632, 2002.
[21] C. X. Ling and C. Li. Data mining for direct marketing:
Problems and solutions. In KDD, 1998.
[22] K. Madsen, H. B. Nielsen, and O. Tingleff. Optimization with
constraints, 2nd ed., 2004.
[23] P. Mitra, C. A. Murthy, and S. K. Pal. Unsupervised feature
selection using feature similarity. IEEE Trans. Pattern Anal.
Mach. Intell., 24(3):301–312, 2002.
[24] J. Nocedal and S. J. Wright. Numerical Optimization.
Springer, August 1999.
[25] D. Pelleg and A. W. Moore. Active learning for anomaly

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

[26]

[27]

[28]

[29]

[30]

and rare-category detection. In NIPS, pages 1073–1080. MIT
Press, 2004.
S. Ramaswamy, R. Rastogi, and K. Shim. Efficient algorithms for mining outliers from large data sets. In W. Chen,
J. F. Naughton, and P. A. Bernstein, editors, SIGMOD, pages
427–438. ACM, 2000.
Y. Sun, M. S. Kamel, and Y. Wang. Boosting for learning
multiple classes with imbalanced class distribution. In ICDM,
pages 592–602, 2006.
G. Wu and E. Y. Chang. Adaptive feature-space conformal
transformation for imbalanced-data learning. In ICML, pages
816–823, 2003.
D. Yu, G. Sheikholeslami, and A. Zhang. Findout: finding
outliers in very large datasets. Knowl. Inf. Syst., 4(4):387–
412, 2002.
Z. Zheng, X. Wu, and R. K. Srihari. Feature selection for text
categorization on imbalanced data. SIGKDD Explorations,
6(1):80–89, 2004.

536

Copyright © by SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Learning Complex Rare Categories with Dual Heterogeneity
Pei Yang∗

Jingrui He∗

Abstract
In the era of big data, it is often the case that the selfsimilar rare categories in a large data set are of great importance, such as the malicious insiders in big organizations,
and the IC devices with defects in semiconductor manufacturing. Furthermore, such rare categories often exhibit multiple types of heterogeneity, such as the task heterogeneity,
which originates from data collected in multiple domains,
and the view heterogeneity, which originates from multiple
information sources. Existing methods for learning rare categories mainly focus on the homogeneous settings, i.e., a
single task and a single view. In this paper, for the first
time, we study complex rare categories with both task and
view heterogeneity, and propose a novel optimization framework named M 2 LID. It introduces a boundary characterization metric to capture the sharp changes in density near
the boundary of the rare categories in the feature space, and
constructs a graph-based model to leverage both task and
view heterogeneity. Furthermore, M 2 LID integrates them
in a way of mutual benefit. We also present an effective
algorithm to solve this framework, analyze its performance
from various aspects, and demonstrate its effectiveness on
both synthetic and real datasets.

1 Introduction
Many real world applications involve large amount of
data. However, it is often the case that the target examples of great interest to us are both rare and self-similar.
These target examples are collectively called rare categories, such as the malicious insiders in big organizations
consisting of tens of thousands of employees, and the IC
devices with defects in semiconductor manufacturing.
Furthermore, the data in such applications often exhibit
multiple types of heterogeneity. Take malicious insiders
as an example. The data collected from multiple related
organizations (e.g., multiple financial institutes) correspond to the task heterogeneity, and the multiple information sources for characterizing the behaviors of employees (e.g., emails, social networks, website browsing
history) correspond to the view heterogeneity. Existing
methods for analyzing rare categories mainly focus on
the homogeneous settings. In other words, they assume
∗ Arizona
† Google

State University, {pyang33, jingrui.he}@asu.edu
Inc., jiayu.pan@gmail.com

Jia-Yu Pan†

that the data come from a single domain and described
based on a single information source [14, 17, 25, 15].
Therefore, they are not best suited for analyzing the
complex rare categories with multiple types of heterogeneity.
To address this problem, in this paper, for the first
time, we study complex rare categories with both task
and view heterogeneity. Here we are facing two major
challenges. The first one is the rarity challenge: given
the small percentage of examples from the rare categories, how can we effectively detect and characterize
them? The second one is the dual heterogeneity challenge: how can we leverage both task and view heterogeneity to maximally boost the performance of rare
category analysis?
To answer these questions, we propose a novel
framework named M 2 LID for Multi-task Multi-view
Learning on Imbalanced Data. First, to address the rarity challenge, in M 2 LID, we propose to use a novel metric named border-degree to capture the sharp changes
in density near the boundary of rare categories in the
feature space. It is based on the different properties between k-nearest neighbors (KNN) and reverse k-nearest
neighbors (RKNN). Second, to address the dual heterogeneity challenge, in M 2 LID, we construct a graphbased model to leverage both task and view heterogeneity. To be specific, we model task relatedness by
requiring the task-specific learners to behave similarly
on the features, and view consistency by requiring the
view-based learners to behave similarly on the examples. Finally, we integrate them into an optimization
framework in a way of mutual benefit based on the following intuition: dual heterogeneity helps characterize
the boundary of rare categories more accurately, which
in turn helps model the dual heterogeneity and improve
the learning performance of multiple tasks. Based on
this framework, we propose an iterative algorithm using block coordinate descent to repeatedly update the
boundary characteristics of rare categories and multiple
classification functions for different tasks. We also analyze its performance in terms of the convergence property, the error bound, and the algorithm complexity.
The major contributions of this paper can be summarized as follows:

523

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

1. An effective metric for characterizing boundaries of
rare categories;
2. A novel optimization framework M 2 LID for modeling the rarity and dual heterogeneity properties
in a way of mutual benefit;
3. Performance analysis with respect to the convergence property, the error bound, and the algorithm
complexity of the proposed algorithm;
4. Experimental results on a variety of data sets
demonstrating the effectiveness of the proposed
algorithm.
The rest of the paper is organized as follows. After
reviewing the related work in Section 2, we present the
proposed M 2 LID framework in Section 3 and analyze
its performance in Section 4, followed by experimental
results in Section 5. Finally we conclude in Section 6.

CoMR [23] algorithm which is based on a Reproducing
Kernel Hilbert Space (RKHS) with a data-dependent
co-regularization norm.
Multi-task learning assumes that multiple tasks can
benefit from certain common structures. To name a few,
feature selection based methods model the task relatedness by constraining all models to share a common set
of features [2]; clustered-based methods aim to discover
the clustered structure from multiple task [28]; alternating structure optimization [1] decomposes the model
into the task-specific and task-shared feature mapping.
Some recent multi-task learning methods dealt with outlier tasks [8, 13].
Most recently, dual-heterogeneity learning methods
began to receive more attention, such as graph-based
learning approach [16] and inductive method based on
co-regularization [27]. However, most of the existing
2 Related Work
work focus on addressing the heterogeneity challenge
We review the related work on imbalanced classification, but ignoring the rarity issue. To the best of our
rare category analysis, and dual-heterogeneity learning. knowledge, there are no previous work focused on rare
2.1 Imbalanced Classification and Rare Cate- category analysis in the dual-heterogeneity setting.
gory Analysis Imbalanced data correspond to data 3 The Proposed M 2 LID Model
sets exhibiting significant or even extreme imbalances.
We first introduce an effective metric for boundary
Researchers have proposed many methods to address
characterization. Then, a novel M 2 LID framework is
this problem [5], such as sampling methods [20, 6], enproposed to model the rarity and the dual-heterogeneity
semble based methods [30]. However, these methods
properties simultaneously.
might not take advantage of compactness property of
the minority class [17], and multiple types of hetero- 3.1 Boundary Characterization The proposed
metric for boundary characterization is motivated from
geneity.
Outlier detection aims to find patterns that do the different properties between KNN and RKNN. Such
not conform to expected behavior [4]. According to different properties can be used to capture the density
[4], outlier detection techniques can be categorized into change around the boundary points between the minorclassification based, nearest neighbor based, clustering ity and majority classes.
According to [26], reverse k-nearest neighbor
based, information theoretic, spectral, and statistical
techniques. They usually assume that the outliers are (RKNN) is defined as follows:
separable from normal data points.
Definition 1. (RKNN) Given a dataset D, a query
In contrast, in rare category analysis, each rare point p, and a positive integer k, reverse k nearest
category forms a compact cluster in the feature space neighbor of p, denoted as RKN Np (k), is a set of
and is self-similar [17]. Some recent work include: points pi that pi ∈ D and ∀pi , p ∈ KN Npi (k), where
local-density-differential sampling method [15]; active KN Npi (k) are the k-nearest neighbors of point pi .
learning based sampling method [10]; method using Since the nearest neighbor relationship is asymmetric,
hierarchical mean shift [25], and SVM-like method the set of points that are closest to a query point (i.e.,
to exploit the compactness property of the minority nearest neighbors) differs from the set of points that
class [17]. Similar to [17], we assume that the majority have the query point as their nearest neighbors (i.e., reclasses have a smooth distribution, and the minority verse nearest neighbors). A property of RKNN is that it
classes exhibit a compactness property.
examines the neighborhood of an object with the view of
2.2 Dual-heterogeneity
Learning Multi-view entire dataset instead of the object itself. Hence, it can
learning aims to leverage view consistency to improve capture the distribution property of the underlying data
the performance. Co-Training [3] is one of the earliest and facilitate the identification of boundary points [26].
algorithm in multi-view learning. More recent work Thus, we make use of the difference properties between
include: SVM-2K [11] which combines KCCA with KNN and RKNN to capture the sharp changes in denSVM in an optimization framework; the information- sity near the boundary of minority classes. It is based
theoretic framework [24] for multi-view learning; the on the following observation: for the minority class, the

524

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

boundary instance points to a few of instances of minority class, as well as being pointed by a few of instances
in majority class, which is different from the interior instances in minority class. In other words, the difference
between KNN and RKNN of the boundary instances is
more significant than that of interior instances. Such
a distinctive feature help to capture the density change
around the border.
Intuitively, if two instances have more common knearest neighbors, they will have more similar Hub values; if two instances have more common reverse knearest neighbors, they will have more similar Authority
values. Therefore, we use Hub/Authority [19] concepts
to model the difference between KNN/RKNN and measure the density changes quantitatively. Based on the
Hub/Authority values, we define a novel metric called
border-degree to measure the probability of a point near
the border.
Definition 2. (Border-degree) Given an instance
x, its border-degree is defined as:
(3.1)
b(x) = h(x) − σa(x)
where σ is a positive parameter, h(x) and a(x) denote
its Hub and Authority values, respectively.
The larger border-degree value an instance has, the
more probably it is near the boundary. A property
of border-degree metric is that it is skewed around
the border while flat in the regions far from border.
The border-degree encodes the boundary information
between majority and minority and captures the sharp
changes in density near the boundary, which can be used
to improve the prediction performance on imbalanced
data. An illustrating example will be provided in the
experiment section.
3.2 The M 2 LID Framework Based on the new
metric for boundary characterization, we further propose a graph-based framework named M 2 LID to learn
from both rarity and heterogeneity.
Directed and Undirected KNN Graph: Suppose we have T tasks and V views. For the i-th task
and the j-th view, we build a directed KNN graph
Gw
ij = (Xij , Eij ) where the vertex set Xij consists of
two subsets, i.e., instance set and feature set. Let nij
be the number of instances, mij the number of features.
Each directed edge is an ordered pair of nodes (u, v)
representing that v is the k-nearest neighbor of u. Let
Wij be the similarity matrix for the graph Gw
ij . Wij
comprises the instance-feature similarity denoted by the
feature values, the instance-instance and feature-feature
similarities which can be estimated by using the Gaussian similarity function. Similar to [16], we assume that
the feature values are non-negative. Note that we can
also build the directed RKNN graph by reversing the
direction of the edges in the directed KNN graph [26].

We further build an undirected KNN graph Gsij ,
where we connect u and v with an undirected edge if
v is among either the k-nearest or reverse k-nearest
neighbors of u. Let Sij be the similarity matrix for Gsij .
Note that Sij is symmetric, while Wij is asymmetric.
Consistency on Undirected Graphs: From
the random walks point of view, given the undirected
KNN graph Gsij , we hope to observe the smoothness
consistency among the nodes. We assume that each
feature is associated with a label which is analogous to
the instances [16].
For the i-th task and the j-th view, we denote
the true labels by the vector yij . Let fij be a vector
for the predictions whose first nij elements are the
I
predictions for the instances denoted by fij
and the
F
remainders for features denoted by fij , i.e., fij =
I
F
[fij
; fij
]. Denote the concatenated prediction vector by
 T
T
T
f = f11 , · · · , f1V
, · · · , fTT1 , · · · , fTTV , and Hub vector
h, Authority vector a, border-degree vector b, label
vector y, correspondingly.
We first derive the smoothness consistency function
for the prediction f. Define the Laplace matrix L(S) =
1
1
2 , where D is a diagonal matrix whose
D− 2 (D − S)D−P
element Duu = v Suv . The objective is to maximize
the smooth consistency among nearest neighbors of both
instances and features (i.e., the first term), consistency
with the label information from the training instances
(i.e., the second term), view consistency in terms of
instances (i.e., the third term), and task consistency in
terms of features (i.e., the last term), which is equivalent
to minimizing:
T P
V
T P
V
P
P
T
JC (f ) =
fij
Lfij fij + γ
||fij − yij ||2
i=1 j=1
i=1 j=1
(3.2)
T
V
V
T
P
P
P
P
I
I 2
F
F 2
+α
||fij
− fik
|| + β
||fji
− fki
||
i=1 j,k=1

i=1 j,k=1

where the Laplace matrix Lfij = L(Sij ), and γ, α, β are
non-negative parameters.
Consistency on Directed Graphs: Meanwhile,
we hope to observe the smoothness consistency on the
directed KNN graph Gw
ij . According to [19], we have
t+1
T t
hij = Wij Wij hij and at+1
= WijT Wij atij where t is
ij
the iteration. So we can derive the Laplace matrix
Lhij = L(Wij WijT ) and Laij = L(WijT Wij ) for Hub and
Authority respectively.
Likewise, to further take advantage of the dual
heterogeneity, we define the smoothness consistency
functions for the regularized Hub JC (h) as
T
V
T P
V
P
P
P
JC (h) =
hTij Lhij hij + α
||hIij − hIik ||2
i=1 j,k=1
i=1 j=1
(3.3)
V
T
P
P
F 2
+β
||hF
ji − hki ||
i=1 j,k=1

and the regularized Authority JC (a) as

525

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

T P
V
T
V
P
P
P
JC (a) =
aTij Laij aij + α
||aIij − aIik ||2
i=1 j=1
i=1 j,k=1
(3.4)
V
T
P
P
F 2
+β
||aF
ji − aki ||

multi-task regularization framework than in a singleview single-task framework by borrowing strength from
related tasks/views.
A more accurate regularized
i=1 j,k=1
Hub/Authority values help characterize the rarity and
Note that different from JC (f), the term controlling the detect the border more accurately. On the other hand,
consistency with label information does not appear in a refined border-degree values can guide the model to
JC (h) (or JC (a)) because there is no correspondence tackle the imbalanced data and improve the prediction
between the Hub (or Authority) values and the labels. performance of the multi-view multi-task framework.
Consistency between Prediction and Border- Algorithm 1 Algorithm for M 2 LID
degree: Without loss of generality, let y(x) = 1 for
Input:
T-task
data
with
V-view
positive instance (minority), y(x) = −1 for negative in{Xij |1 ≤ i ≤ T, 1 ≤ j ≤ V }, α, β, γ, λ, σ.
stance (majority), and y(x) = 0 for unlabeled instance Output: predicted labels for the test data.
initially. Intuitively, the boundary instance will have 1: Initialize the label vector y;
large border-degree and small absolute value of predic- 2: Initialize the regularized Hub/Authority vectors
tion, while the instance far away from boundary will
h(0) /a(0) , and border-degree b(0) using Eq. 3.1;
do
have small border-degree and large absolute value of pre- 3: for t =n0 : niter o
diction. In other words, the absolute value of prediction 4: Fix h(t) , a(t) and update the predicted labels f (t);
n
o
and border-degree is negatively correlated. Various met5:
Fix a(t) , f (t) and update the Hub h(t+1) ;
rics can be used to model the correlation between the
n
o
(t)
(t+1)
and update the Authority a(t+1) ;
prediction f and border-degree b, such as Pearson corre- 6: Fix f , h
lation coefficient and Kullback-Leibler (KL) divergence. 7: end for
Alternately, we borrow the idea from Pearson correla- 8: return predicted labels for the test data by using
Eq. 3.7.
tion coefficient to model the correlation between prediction and border-degree:
Optimization: The overall objective Eq. 3.6 is
"„
« #T „
«2
−
→
−
f −→
µf 2
an
unconstrained
quadratic optimization, which can
b− µb
JP (f, b) =
(3.5)
be
solved
efficiently.
For example, Eq. 3.2 can be
σf
σb
transformed
into
the
compact
matrix form:
where µf and σf (or µb and σb ) denote the mean and
T
JC (f) = f Hf f − 2pT f
standard deviation of f (or b), respectively, which can
→
−
→
−
be estimated empirically. µ f (or µ b ) is a vector where where p = γy and the block matrix Hf is defined as:

each element is µf (or µb ). For simplicity, denote
Lfij + γInij +mij + 2α(V − 1)A+

2
2
2 T


v = [v1 , · · · , vn ] for any n-by-1 vector v here.

2β(T − 1)B,
i= s∧j = t
−αA,
i = s ∧ j 6= t
Overall Objective: In summary, our overall goal [Hf ](fij ,fst ) =


−βB,
i 6= s ∧ j = t

is to maximize the smoothness consistency objective for

0
,
otherwise
(n
+m
)×(n
+m
)
st
st
ij
ij
all of predictions, Hub, and Authority, i.e., f, h, a, and
simultaneously minimize the correlation between the where 1 ≤ i, s ≤ T , 1 ≤ j, t ≤ V , and




prediction and the border-degree. Hence, the objective
Inij
0nij ×mst
0nij ×nst 0nij ×mij
A= 0
,B= 0
is to minimize,
0mij ×mst
Imij
mij ×nij
mij ×nst
By
setting
the
derivatives
of
Eq.
3.6
with
respect
to
each
(3.6) J(f, h, a) = JC (f) + JC (h) + JC (a) + λJP (f, b)
block of {f, h, a} to zero, we can obtain the analytical
where λ is the trade-off coefficient.
solutions.
M 2 LID tackles the rarity by using border-degree
Intuitively, the smaller the border-degree is, the
for boundary characterization, enhances the view con- more confident the view-based classifier is with its
sistency by requiring the view-based learners to behave prediction. Thus, for an unlabeled instance, its final
similarly on the instances, and models the task relat- prediction takes the weighted sum of the predictions
edness by requiring the task-specific learners to behave resulting from the view-based classifiers:
XV 

similarly on the features. Furthermore, M 2 LID adfi∗ (x) =
1 − bij (x) fij (x)
dresses both the rarity and heterogeneity challenges (3.7)
j=1
in a way of mutual benefit. Intuitively, heterogene- where b̄ij is the normalized border-degree, i.e., b̄ij (x) =
ity helps characterize the rarity and detect the border bij (x)/ PV bik (x).
k=1
more accurately, which in turn helps mine the heteroWe propose an iterative M 2 LID Algorithm as
geneity and improve the learning performance. Specif- shown in Algorithm 1. It is based on block coordiically, it is expected that one can obtain more accu- nate descent algorithm [21], and updates each block of
rate regularized Hub/Authority values in a multi-view {f, h, a} iteratively.

526

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Given the error bound ρ, we have:
XV
In this section, we present the performance analysis
P [y = 1|f = −1] ≥ ρ ⇔
Zj ≥ 0
on the important properties regarding the convergence,
j=1
error bound, and algorithm complexity of the proposed

where Zj = 1 − b̄j [rpj (1 − ρ) − ρ(1 − qj )(1 − r)] is
approach.
a random variable. Denote the expectation of Zj as
4.1 Convergence
E [Zj ] = µ. If
Theorem 4.1. (Convergence) The
proposed


rE pj 1 − b̄j
M 2 LID algorithm converges to the local optimum.




,
ρ≥
rE pj 1 − b̄j + (1 − r) E 1 − b̄j (1 − qj )
Proof. For Eq. 3.6, since the Laplace matrices are positive semi-define, it is easily to prove that Hf is also pos- we have µ ≤ 0. It is easy to see that Z is bounded,
j
itive semi-definite. By taking second-order derivative of which is denoted by [ω , ω ]. The Hoeffding inequality
1
2
JC (f) with respect to f, we have ∇2f JC (f) = 2Hf . [18] shows that when τ ≥ 0:
Since Hf is positive semi-definite, JC (f) is convex with
!
X
X


respect to f. Moreover, we can prove that JP (f, b) is
V
V
−2τ 2
Zj − E
Zj ≥ τ ≤ exp
convex with respect to f. Therefore, given (h, a), Eq. 3.6 P
2
j=1
j=1
V (ω1 − ω2 )
is convex with respect to f. Likewise, we can prove that
Eq. 3.6 is also convex with respect to h and a, respec- By letting τ = −V µ and C = (ω − ω )2 , we have
1
2
tively.
X



V
−2V µ2
Based on the theoretical results from block coordiP
Zj ≥ 0 ≤ exp
j=1
nate descent methods [21], the proposed M 2 LID algoC
rithm in Algorithm 1 converges to local optimum. 
which completes the proof.

4.2 Error Bound Analysis Analogous to [12], we
Theorem 4.2 indicates that the error bound ρ is diderive the error bound for our proposed method. Here,
rectly
related to the probability of errors made by viewwe focus on multi-task learning from imbalanced data
based
classifier
and the border-degree. Furthermore, the
with multi-view, which distinguishes us from [12].
probability
that
the algorithm making a false negative
For the j-th (1 ≤ j ≤ V ) view, denote the conerror
greater
than
a given error bound ρ will be expoditional probabilities P [fj = −1|y = 1] = pj , and
nentially
decreased
when the number of views increases.
P [fj = 1|y = −1] = qj . Denote P [y = 1] = r.
Likewise, we can also derive the false positive error
Theorem 4.2. (False Negative Error Bound)
bound, which is omitted here due to the space limit.
Given the error bound
4.3 Algorithm Complexity The time-consuming


rE pj 1 − b̄j
steps in the algorithm of M 2 LID are the computations




,
ρ≥
of the inverse matrices in Steps 4-6. Denote the
rE pj 1 − b̄j + (1 − r) E 1 − b̄j (1 − qj )
number of rows in the square matrix Hf by N =
the probability of making a false negative error by PT PV
2
i=1
j=1 (nij + mij ). The time complexity of the
M LID can be bounded as follows: 

proposed
algorithm is given in Lemma 4.1.
2
−2V µ
(4.8) P {P [y = 1|f = −1] ≥ ρ} ≤ exp
C
Lemma 4.1. (Time Complexity)
The time complex



where µ = E 1 − b̄j [rpj (1 − ρ) − ρ(1 − qj )(1 − r)] , ity of M 2 LID is O niter N 2.376 .
and C is a constant.
Proof. The time complexity
of computing the inverse

Proof. According to Eq. 3.7, since the final prematrix is O N 2.376 by using Coppersmith-Winograd
diction is the weighted sum of output from viewalgorithm [9]. Since M 2 LID algorithm repeats to run

based classifiers, we have P [f = −1|y = 1]
=
niter times, the total time complexity is O niter N 2.376 .


PV
PV
j=1 1 − b̄j P [fj = −1|y = 1] =
j=1 1 − b̄j pj ,

PV
Likewise, the space-consuming steps in the M 2 LID
and P [f = −1|y = −1] =
j=1 1 − b̄j (1 − qj ) likewise. Then, the probability of making a false negative algorithm are to store the matrix Hf and the corresponding inverse matrix. It is easy to obtain the space
prediction can be estimated by using Bayes theorem:
complexity of the M 2 LID algorithm, which is given in
P [y = 1|f = −1]
Lemma 4.2.
P [f=−1|y=1]P [y=1]
= P [f=−1|y=1]P
[y=1]+P
[f=−1|y=−1]P [y=−1]
Lemma 4.2. (Space Complexity)
The space comP

r V
j=1 (1−b̄j )pj
PV
plexity of M 2 LID is O N 2 .
= r PV 1−b̄ p +(1−r)
j) j
j=1 (1−b̄j )(1−qj )
j=1 (

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

4

Performance Analysis

527

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

350
300
300
300
250
250
200
200
200
150
150

150
100

100

100
50
50

100

150

200

250

300

350

50

100

150

200

250

300

350

50

100

150

200

250

300

350

Figure 1: Boundary characterization on three synthetic datasets: a)Circle; b)Half-moon; c)Plus. The blue (green, yellow)
stars representing the instances with top-10 (20, 40) largest border-degree values are located around the boundary regions.

Table 1: Task description for Cora datasets.
Dataset
DA-NT
DA-ML
NT-ML

Task
1
2
1
2
1
2

+1
/data structures algorithms and theory/computational complexity/ (711)
/data structures algorithms and theory/computational geometry/ (459)
/data structures algorithms and theory/computational complexity/ (711)
/data structures algorithms and theory/computational geometry/ (459)
/networking/protocols/ (743)
/networking/routing/ (477)

5 Experiments
In this section, we present the experimental results on
both synthetic and real-world datasets.

-1
/networking/protocols/ (743)
/networking/routing/ (477)
/machine learning/probabilistic methods/ (687)
/machine learning/genetic algorithms/ (670)
/machine learning/probabilistic methods/ (687)
/machine learning/genetic algorithms/ (670)

1
0.95

F−score

0.9
0.85

5.1 Synthetic Datasets We generate synthetic
datasets and visualize the boundary characterization in
order to verify the effectiveness of the proposed borderdegree metric. Figure 1 shows three 2-dimensional synthetic datasets. In each dataset, the major class has
Ratio
2000 instances (black pluses) with a Gaussian distribuFigure 2: F-score of different heterogeneous learning methtion. The minority class has 100 instances (red circles)
ods on Spam Email (task 1).
with uniform distribution within the regions with different shapes, i.e., ‘circle’, ‘moon’, ‘plus’, respectively.
Then, we also visualize those instances with large
border-degree values. The blue (green, yellow) stars
represent the instances with top-10 (20, 40) largest
border-degree values, respectively. From these figures,
we can see that most boundary instances in either
majority or minority class have large border-degree
value, which verifies our intuition. In this regard,
Ratio
border-degree can be used as an effective metric for
Figure 3: F-score of different heterogeneous learning methboundary characterization.
0.8

0.75

2

IteM
CoEM
CMTL
rMTFL
RMTL
CASO

0.7

0.65

2

M LID

0.6
0.02

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

1

0.95
0.9

F−score

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

250

0.85
0.8

0.75

2

IteM
CoEM
CMTL
rMTFL
RMTL
CASO

0.7

0.65

M2LID

0.6
0.02

5.2 Real Datasets The Spam Email data set was
released by ECML/PKDD 2006 discovery challenge
(www.ecmlpkdd2006.org/challenge.html). The inboxes
differ in the distribution of emails. The goal is to
construct a spam filter for each single user that correctly
classifies its emails as spam or non-spam. In problem A,
there are emails from 3 different users (2500 emails per
user) corresponding to different tasks. The emails are
described from two views: the first view corresponds
to the TF-IDF features; the second view corresponds
to the latent topics obtained by applying Probabilistic
Latent Semantic Analysis on the term counts.
Cora [22] is an online archive which contains approximately 37,000 computer science research papers.

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

ods on Spam Email (task 2).

The documents are categorized into a hierarchical structure. Different sub-categories under the same top category are drawn from different distributions. Table 1
shows the data sets and task description, where the
number in the parenthesis is the number of instances.
We create two views for each dataset as we done for the
Spam Email dataset.
The F-score (harmonic mean of precision and recall)
of minority class is used as the evaluation criterion. We
repeat all the comparison algorithms ten times for each
dataset and report the average F-score. For M 2 LID,
we tune α, β, γ, and λ on the grid 4[−5:1:5] , and σ on
2[−5:1:5] by cross-validation on the training data.

528

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

1

1
0.95

0.9

F−score

F−score

0.8

0.8
0.75

2

IteM
CoEM
CMTL
rMTFL
RMTL
CASO

0.7
0.65

0.7
2

IteM
CoEM
CMTL
rMTFL
RMTL
CASO

0.6

0.5

M2LID

0.6
0.02

0.05

0.1

0.15

0.2

0.25

0.3

0.35

M2LID

0.4
0.02

0.4

0.05

0.1

0.15

Ratio

0.2

0.25

0.3

0.35

0.4

Ratio

Figure 4: F-score of different heterogeneous learning meth- Figure 6: F-score of different heterogeneous learning methods on Spam Email (task 3).

ods on Cora DA-NT (average).

1
1

0.95
0.9

0.9

0.85
0.8
0.8
0.75

F−score

F−score

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

0.9
0.85

2

IteM
CoEM
CMTL
rMTFL
RMTL
CASO

0.7
0.65

0.1

0.15

0.2

0.25

0.3

0.35

M2LID

0.5

2

0.05

0.7

0.6

M LID

0.6
0.02

2

IteM
CoEM
CMTL
rMTFL
RMTL
CASO

0.4

Ratio

0.4
0.02

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

Ratio

Figure 5: Error bar of different heterogeneous learning
methods on Spam Email (average).

Figure 7: F-score of different heterogeneous learning methods on Cora NT-ML (average).

5.2.1 Comparison with Heterogeneous Learning We compare M 2 LID with a variety of heterogeneous learning approaches including: 1)multi-task
multi-view learning algorithm IteM 2 [16]; 2)multi-view
learning method CoEM which is a variant of CoTraining [3]; 3)multi-task algorithms implemented in
MALSAR [29] toolbox including CASO [7], CMTL [28],
rMTFL [13], RMTL [8].
All of M 2 LID, IteM 2 , and CoEM are fed with the
multi-view data, whereas the multi-task approaches are
input with the concatenated features from all the views.
The parameters are tuned for each algorithm by crossvalidation on training data.
For Spam Email datasets, Figures 2-4 show the
comparison results for each task, respectively. The
average performance and standard deviations are shown
in Figure 5 by aggregating all the tasks. In each
figure, x-axis represents the ratio between the number
of instances in minority and majority classes, and y-axis
denotes the F-score for the minority class. We randomly
sample the instances to generate the imbalanced subset
according to the specified ratio value. Each dataset
is randomly splitted into training set (50%) and test
set (50%), where they hold the same ratio between the
number of instances in minority and majority classes.
From these figures, we can observe a common trend
that the performance of all the algorithms usually
become worse significantly when the ratio decreases,
which indicates that the rarity property of data would
greatly influence the learning system. M 2 LID performs

the best among all the algorithms when the ratio is less
than 0.2, which demonstrates the effectiveness of our
proposed model. In comparison with the other methods,
the key competency of M 2 LID is that it takes the rarity
into consideration and models the rarity and task/view
heterogeneity properties in a way of mutual benefit. In
contrast, though IteM 2 makes full advantage of task
and view heterogeneity, its discrimination power on
imbalanced data is limited since it does not consider
the rarity issue. Among all the algorithms CoEM
performs the worst, which shows that the traditional
multi-view learning approaches would not be effective
in the situations where the data in different tasks follow
different distributions. This may due to the fact that
they treat the multiple tasks indiscriminately. On the
contrary, the multi-task learning methods significantly
outperform CoEM by modeling the task relatedness
in different way. It is interesting that both of two
approaches dealing with outlier tasks, i.e., RMTL and
rMTFL, perform better than the other two multi-task
learning methods, i.e., CASO and CMTL. It suggests
that the multi-task learning algorithms dealing with
outlier tasks may be more robust to the imbalanced data
comparing to those assuming that there are no outliers.
Figures 6-8 show the comparison results for Cora
datasets. For each dataset, the results are averaged
by the tasks. From these figures, we have the similar
conclusions with those on Spam Email datasets. Note
that the result for CoEM is not shown due to its
relatively worse performance.

529

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

1

1

0.9
0.9

0.8

F−score

F−score

0.7
IteM
CoEM
CMTL
rMTFL
RMTL
CASO

0.5

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.6

OverSampling
UnderSampling
Smote
HardEnsemble
SoftEnsemble

0.4
0.3

M2LID

M2LID

0.4
0.02

0.7

0.5

2

0.6

0.2
0.02

0.4

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

Ratio

Ratio

Figure 8: F-score of different heterogeneous learning meth- Figure 10: F-score of different imbalanced learning methods
ods on Cora DA-ML (average).

on Cora DA-NT (average).

1

1
0.9

0.9

0.8

F−score

0.8

F−score

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

0.8

0.7

0.7
0.6
0.5

0.6

OverSampling
UnderSampling
Smote
HardEnsemble
SoftEnsemble

0.5

OverSampling
UnderSampling
Smote
HardEnsemble
SoftEnsemble

0.4
0.3

M2LID

0.4
0.02

0.05

0.1

0.15

0.2

0.25

0.3

0.35

M2LID

0.2
0.02

0.4

Ratio

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

Ratio

Figure 9: F-score of different imbalanced learning methods

Figure 11: F-score of different imbalanced learning methods

on Spam Email (average).

on Cora NT-ML (average).

5.2.2 Comparison with Imbalanced Learning
We also compare M 2 LID with various imbalanced
learning methods including: 1)OverSampling; 2)UnderSampling; 3)SMOTE [6]; 4)ensemble learning methods
for imbalanced data, which include HardEnsemble and
SoftEnsemble [30]. An online imbalanced learning package named CSNN (http://lamda.nju.edu.cn/Data.ashx)
which implemented all above algorithms is used for comparison. All the imbalanced learning algorithms are input with the concatenated features from all the views.
The parameters are tuned for each algorithm by using
cross-validation on the training data.
Figure 9 shows the average performance on Spam
Email datasets by aggregating all the tasks, and Figures 10-12 show the results for Cora datasets, respectively. First of all, the performance of all the methods
usually worsen along with the decrease of ratio, which
is similar to the trend we got from the last subsection. It indicates that a higher degree of class imbalance may result in greater difficulty in imbalanced learning. Both OverSampling and SMOTE basically perform better than UnderSampling, which suggests that
it would pay more attention to characterize the minority instances than majority instances on these datasets.
Ensemble methods including HardEnsemble and SoftEnsemble can further improve generalization ability by
combining the predictions from different learners. However, though the above approaches are effective for homogeneous data, they might not be the best choices
for heterogeneous data, which is demonstrated by the

experimental results that all the comparison methods
basically perform worse than M 2 LID. First, it would
due to the fact that traditional imbalanced learning algorithms cannot take advantage of task heterogeneity
and/or view heterogeneity to improve the generalization performance. Second, these methods might not
make use of the the compactness property of minority
class [17].
5.2.3 Parameter Sensitivity and Convergence
We study the performance sensitivity with k, which is
used to select the nearest neighbors and construct the
KNN/RKNN graph. Figure 13 plots the performance
curves varying with different values of k on the DA-NT
training data. It shows that the performance of M 2 LID
is quite robust over a wide range of values for k. As a
result, we set k = 40 in the other experiments.
We empirically study the convergence property of
M 2 LID on the Spam Email dataset. The result is
shown in Figure 14. From this figure, we can see that
the M 2 LID converges fast and its performance becomes
stable after 5 iterations.
6

Conclusion

We propose an effective metric for boundary characterization, and a novel M 2 LID framework to learn
from rarity and heterogeneity. Furthermore, we report
the theoretical results regarding the convergence, error
bound, and algorithm complexity for the proposed approach. Experimental results on synthetic and real data
sets demonstrate the effectiveness of the M 2 LID model.

530

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

0.9

1

0.89

0.87

0.7

0.86

F−score

F−score

0.88

0.8

0.6

0.85
0.84

0.5

0.83

OverSampling
UnderSampling
Smote
HardEnsemble
SoftEnsemble

0.4
0.3

0.82
0.81

2

M LID

0.2
0.02

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.8
1

0.4

2

3

4

5

6

7

8

9

10

Iteration

Ratio

Figure 12: F-score of different imbalanced learning methods

Figure 14: F-score varies with iteration.

on Cora DA-ML (average).
1
0.9
0.8

F−score

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

0.9

0.7
0.6
0.5

k=20
k=30
k=40
k=50
k=60
k=70
k=80

0.4
0.3
0.02

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

Ratio

Figure 13: F-score varies with k.
Acknowledgment This work is partially supported by the
NSF (No. IIS1017415), the Army Research Laboratory (No.
W911NF-09-2-0053), Region II University Transportation
Center (No. 49997-33 25), DARPA (No. W911NF-11-C0200 and W911NF-12-C-0028), and NSFC (No. 61473123).

References
[1] R. K. Ando, T. Zhang. A framework for learning predictive
structures from multiple tasks and unlabeled data. Journal
of Machine Learning Research, 6:1817-1853, 2005.
[2] A. Argyriou, T. Evgeniou, M. Pontil. Multi-task feature
learning. In NIPS, 2007, pages 41-48.
[3] A. Blum and T. Mitchell. Combining Labeled and Unlabeled
Data with Co-Training. In COLT 1998, pages 92-100.
[4] V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection: A survey. ACM Computing Surveys, 2009.
[5] N.V. Chawla. Mining when classes are imbalanced, rare
events matter more, and errors have costs attached. In SDM,
2009.
[6] N.V. Chawla, K.W. Bowyer, L.O. Hall, and W.P.
Kegelmeyer. SMOTE: synthetic minority over-sampling
technique. Journal of Artificial Intelligence Research,
16:321-357, 2002.
[7] J. Chen, L. Tang, J. Liu, J. Ye. A convex formulation for
learning shared structures from multiple tasks. In ICML,
pages 137-144, 2009.
[8] J. Chen, J. Zhou, J. Ye. Integrating low-rank and groupsparse structures for robust multi-task learning. In KDD
2011, pages 42-50.
[9] D. Coppersmith and S. Winograd. Matrix multiplication via arithmetic progressions. J. Symbolic Computation,
9(3):251-280, 1990.
[10] S. Dasgupta and D. Hsu. Hierarchical sampling for active
learning. In ICML, pages 208-215, 2008.
[11] J. D. R. Farquhar, D. R. Hardoon, H. Meng, J. ShaweTaylor, S. Szedmák. Two view learning: SVM-2K, Theory
and Practice. In NIPS, 2005.

531

[12] L. Ge, J. Gao, H. Q. Ngo, K. Li, A. Zhang. On Handling
Negative Transfer and Imbalanced Distributions in Multiple
Source Transfer Learning. In SDM, 2013, pages 261-269.
[13] P. Gong, J. Ye, C. Zhang. Robust multi-task feature learning. In KDD, pages 895-903, 2012.
[14] J. He. Analysis of Rare Categories. Springer, Cognitive
Technologies, pages 1-128, 2012.
[15] J. He and J. G. Carbonell. Nearest-neighbor-based active
learning for rare category detection. In NIPS 2007.
[16] J. He, R. Lawrence. A Graphbased Framework for MultiTask Multi-View Learning. In ICML 2011:25-32.
[17] J. He, H. Tong, J. G. Carbonell. Rare Category Characterization. In ICDM 2010:226-235.
[18] W. Hoeffding. Probability Inequalities for Sums of Bounded
Random Variables. Journal of the American Statistical
Association, 58(301):13-30, 1963.
[19] J. M. Kleinberg. Authoritative Sources in a Hyperlinked
Environment. J. ACM, 46(5):604-632, 1999.
[20] M. Kubat, S. Matwin. Addressing the Curse of Imbalanced
Training Sets One-Sided Selection. In ICML 1997, pages
179-186.
[21] Z. Q. Luo and P. Tseng. On the convergence of the coordinate descent method for convex differentiable minimization.
Journal of Optimization Theory and Applications, 72(1):735, 1992.
[22] A. K. McCallum, K. Nigam, J. Rennie and K. Seymore. Automating the Construction of Internet Portals with Machine
Learning. Information Retrieval, 3(2):127-163, 2000.
[23] V. Sindhwani and D. S. Rosenberg. An RKHS for multi-view
learning and manifold co-regularization. In ICML, pages
976-983, 2008.
[24] K. Sridharan and S. M. Kakade. An Information Theoretic
Framework for Multi-view Learning. In COLT 2008, pages
403-414.
[25] P. Vatturi and W.-K. Wong. Category detection using
hierarchical mean shift. In KDD, pages 847-856, 2009.
[26] C. Xia, W. Hsu, M.-L. Lee, B. C. Ooi. BORDER: Efficient
Computation of Boundary Points. IEEE Transactions on
Knowledge and Data Engineering, 18(2):289-303, 2006.
[27] J. Zhang, J. Huan. Inductive multi-task learning with
multiple view data. In KDD 2012:543-551.
[28] J. Zhou, J. Chen, J. Ye. Clustered multi-task learning via
alternating structure optimization. In NIPS, 2011, pages
702-710.
[29] J. Zhou, J. Chen, J. Ye. MALSAR: Multi-tAsk Learning via
StructurAl Regularization. http://www.MALSAR.org.
[30] Z.-H. Zhou, X.-Y. Liu. Training cost-sensitive neural networks with methods addressing the class imbalance problem. IEEE Transactions on Knowledge and Data Engineering, 2006, 18(1): 63-77.

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

2010 IEEE International Conference on Data Mining Workshops

Traffic Velocity Prediction Using GPS Data: IEEE ICDM Contest Task 3 Report
Wei Shen, Yiannis Kamarianakis, Laura Wynter, Jingrui He, Qing He, Rick Lawrence, Grzegorz Swirszcz
IBM T.J. Watson Research Center, Yorktown Heights, NY 10598
{wshen, yiannis, lwynter, jingruhe, qhe, ricklawr, swirszcz}@us.ibm.com
half. Participants are asked to predict the harmonic-average
speed of vehicles that will be passing the 100 segments in
two time periods: 0 - 6’ and 24 - 30’ of the second half of
each such 1-hour window.
The following four features make task 3 particularly
challenging:

Abstract—This report summarizes the methodologies and
techniques we developed and applied for tackling task 3 of
the IEEE ICDM Contest on predicting traffic velocity based
on GPS data. The major components of our solution include 1)
A pre-processing procedure to map GPS data to the network,
2) A K-nearest neighbor approach for identifying the most
similar training hours for every test hour, and 3) A heuristic
evaluation framework for optimizing parameters and avoiding
over-fitting. Our solution finished Second in the final evaluation.

•

Keywords-map-matching; nearest neighbor; cross validation

•

I. TASK D ESCRIPTION

•

As the planet becomes more instrumented, cities across
the world are able to collect transportation data from numerous sources in real-time. By combining traffic data
collected from different sources with advanced algorithms
for traffic prediction, both traffic management centers and
individual drivers can make smarter choices and real-time
traffic management and trip planning. The IEEE ICDM
Contest 2010, sponsored by TomTom, addresses a critical
issue in transportation systems: How can we predict traffic
congestion by making use of available real-time data?
The contest consists of three prediction tasks, each of
which aims at predicting a different traffic congestion measure (i.e., traffic flow, traffic jams, and link travel speeds) for
the city of Warsaw, Poland, based on traffic data generated
from a vehicular traffic simulator. Task 3 is particularly
focused on the data that comes from GPS devices and
combining that with another source of more aggregate traffic
data providing typical link speeds by time of day and day of
the week. In particular, Task 3 involves traffic reconstruction
and prediction based on simulated real-time information
collected from the simulated GPS devices of individual
drivers. The training data of task 3 consists of two files: one
contains the stream of notifications from 1% of vehicles in
the network about their current GPS locations in the city
road network, sent every 10 seconds, and the other provides
the actual average velocities in corresponding simulation
cycles and time periods, on 100 selected road segments.
Fifty 10-hour long simulation cycles are covered in the
training data set, whereas test data cover another 500 hours
of simulation, split into 1-hour windows. The challenge is
that the stream of GPS notifications for the first half of each
1-hour window in the test data is revealed, but not the second
978-0-7695-4257-7/10 $26.00 © 2010 IEEE
DOI 10.1109/ICDMW.2010.52

•

The size of the data set is huge (several GB uncompressed). An efficient method is needed to map the data
set of GPS coordinates to links of the network.
The sampling rate of vehicles varies from link to link
and is in general very low on the 100 selected road
segments.
Simulation hours during the “warming-up” period of a
simulation cycle exhibit different properties from hours
in the middle of a cycle. However, it is not known in the
test data which hours were extracted from a “warmingup” period versus from the rest of the cycle.
The simulated data set has some distinct features which
make temporal-spatial regression models for traffic prediction fail in this specific context.

Solutions of Task 3 are evaluated by calculating the Root
Mean Squared Error (RMSE) of the inverse of the predictions so as to represent the RMSE of travel times, rather
than of speeds. Predicted speeds are hence transformed through inverting and multiplying by 60 - into predicted
travel time over 1 km of the road segment, expressed in
minutes. These travel times are compared with the simulated
ground truth using RMSE. Our final solution has a RMSE of
7.4556 on the test data set, which resulted in second place
in the contest. The remainder of this report discusses the
major steps we took to achieve this solution.
II. M ATCHING GPS DATA TO THE NETWORK
Each GPS record in both the training and test data
sets contains time, an ID, latitude/longitude coordinates,
and velocity of the probe vehicle, but most importantly is
not associated with the links of the network. Before any
data mining methods can be performed, a pre-processing
procedure is needed to map the GPS records to the map. GPS
data in reality are usually noisy and the reported coordinates
may not fall exactly on any links of the network. The
procedure of deciding which link of the network that a GPS
point is located on is called map-matching in the Geographic
Information System (GIS) community.
1369

50
40
30

speed

20
10
0
0

20

40

60

80

100

time

Figure 2.
Figure 1.

The speed profile of a sample training cycle on a sample link

The Warsaw map and GPS records for one training cycle.

on the 100 links typically involves sudden drops or
sudden rises (Figure 2).
Instead, we devised a completely different approach to
predict the traffic speeds from the GPS points. The approach
works by constructing a K-nearest neighbor model to predict
vehicle velocity. Namely, for each test hour, we pick the
training hours that are most similar to it and use a linear
combination of the corresponding velocities for the first and
last 6-min intervals during the second half of the hours as
its estimate.
The following two criteria are used to construct the
similarity measure.
g
g
: Sij
measures how close the total
1) Global similarity Sij
number of GPS counts in one test hour is to that of a
training hour. The total number of GPS points in the network
reflects the overall congestion level of the entire network,
and hence is a good indicator of whether an hour is during
the “warming-up” period of a cycle or not. To construct
g
, let cti and Cjt be the total number of GPS points
Sij
received during every 1-min interval t = 1, . . . , 30 of test
hour i = 1, . . . , 500 and training hour j = 1, . . . , 500,
respectively. The global similarity between a test hour i and
g
, is measured by the RMSE
a training hour j, denoted as Sij
t
t
of cj and Cj . Namely,

30 t
t 2
t=1 (ci − Cj )
g
Sij =
(1)
30

Over the years, researchers have developed diverse map
matching algorithms (e.g., Greenfeld 2002, Alt et al. 2003,
etc.). In our context, GPS signals come from simulated traffic
data and are therefore less noisy than real GPS signals.
To perform the map-matching, we used the built-in overlay
function of the software package ArcGIS. First, coordinates
of the Warsaw map were loaded into ArcGIS, resulting in a
link layer of the map. Then, GPS data of both the training
and test sets were imported and joined with the link layer
by searching the closest link for each point (Figure 1). Note
that for bidirectional links such a method may map a GPS
point to the wrong direction. Fortunately, our investigation
revealed that bidirectional links in the network are mostly
minor links, whose impact to the overall traffic pattern in the
network is less significant as compared to the major links.
We believe this potential deficiency of the method did not
have a critical impact on the final prediction accuracy.
The map-matching procedure was performed for every
simulation cycle in both the training and test data sets. After
map-matching, each GPS data point then had a link ID
associated with it. The new data set was then loaded to a
PostGreSQL database for further processing.
III. T HE K N EAREST N EIGHBOR M ODEL
An effective approach for real-life road traffic prediction
is through specialized auto-regressive models, in which
measurements of the traffic on the link of interest as well
as on certain neighboring links are used as input (see, e.g.,
Min et al. 2007). Unfortunately, that method does not work
well for this simulated data set, due in a large part to the
following reasons:
• The relatively low GPS sampling rate (1% overall)
makes it impossible to construct reliable historical
speed profiles for all the links. For example, for each
of the selected 100 links of interest, the total number
of GPS points during the first half an hour vary from 0
to 934, with mean = 17 and standard deviation = 53.2.
In fact, 22 links among the 100 selected road segments
have no GPS data points at all.
• The actual average link velocity provided by file 2 of
the training data shows that the simulated speed profile

l1
l2
2) Local similarity Sijk
and Sijk
: Comparing the GPS
records with the actual harmonic average speed provided
in the training data, we found that during a 6-min interval
on a selected road segment, the speed of one probe vehicle
can be significantly different from another. For instance,
one GPS record may show a speed instance of zero while
another one may report speed = 60km/hr. The huge variance
in sample speed is partly due to the discrete feature of
the traffic simulator. As a result, the harmonic average
velocity of probe vehicles does not generally lead to reliable
velocity estimates. In fact, it is often impossible to take the
harmonic mean of the speed of the probe vehicles, as many
probe vehicles report speed values of zero in the GPS data.

1370

Nevertheless, the average link speed and GPS data on the
link do exhibit a strong correlation as follows: typically,
links with low speed have many more GPS records with
zero values, whereas links with high speeds are more likely
to have nonzero GPS records. This observations motivated
us to construct a local similarity measure based on the
total number of GPS records with zero and nonzero values
on any link k of interest. Interestingly, we did not get
improvement from looking more closely at the values of
the non-zero speeds, as one might expect. Hence, the local
l1
l2
and Sijk
measuring the similarity of a test
similarity Sijk
hour i, i = 1, . . . , 500 and a training hour j, j = 1, . . . , 500
on link k, k = 1, . . . , 100, is computed as follows:
l1
l2
= |pi − Pj |, Sijk
= |qi − Qj |
Sijk

(2)

where
pi and Pj are the total number of GPS records with zero
values during the first half of test hour i and training hour
j, respectively;
qi and Qj are the total number of GPS records with nonzero
values during the first half of test hour i and training hour
j, respectivley.
Given link k = 1, . . . , 100 and test hour i = 1, . . . , 500,
the actual similarity measure Sijk for each training hour
j = 1, . . . , 500 is computed as the weighted sum of the ranks
of the global similarity and the local similarities. Namely,
g
l1
l2
) + βk rank(Sijk
) + γk rank(Sijk
) (3)
Sijk = αk rank(Sij

Note that the rank of a training hour is measured by its
position when the corresponding similarity measure for all
training hours is sorted in ascending order.
Finally, the harmonic average speeds of the first and
last 6-min intervals of the second half of each test hour
are estimated as the weighted harmonic average speeds of
the corresponding intervals of the K most similar training
hours. The inverse of the similarity metric of each candidate
training hour is used as the weight. In fact, three potential
estimators, the arithmetic mean, the median, and the harmonic mean, were tested when we construct our solution.
Overall the harmonic mean provided the best result.
One potential problem of using the harmonic mean of the
K nearest neighbors is that if all the candidate hours in the
neighbor list have high speed except for a few small outliers,
the harmonic mean can be very small. The existence of such
cases contributes to quite a significant portion of the error.
To avoid the outlier effect, a conditional trimmed harmonic
mean is used by filtering out the rare small outliers when
most of the neighbors have high velocity values.

2) αk - weight of the global similarity measure;
3) βk - weight of the local congestion similarity measure;
4) γk - weight of the local free flow similarity measure;
5) nk - the total number of high speed neighbors for the
outlier filter to be initiated;
6) hk - the high cut-off value of the outlier filter;
7) lk - the low cut-off value of the outlier filter.
All of the above parameters are optimized heuristically
using a 5-fold cross validation framework. A set of parameters were regarded as optimal if it generated the best average
performance over the five test-training data sets. Finally, the
link-specific optimal parameter settings were applied to the
real test data to obtain the final solution for task 3. We
found that it is often the case that the actual performance
measure (7.4556) on the real test data set is slightly better
than the average best performance measure (7.74) from the
cross validation. This is understandable as cross validation
only uses 4/5 of the training data.
V. C ONCLUSIONS
The simulated link velocity profile involves more dramatic
changes than those typically observed in reality, and hence
is much more difficult to predict. Overall, our K nearest
neighbor model combined with the outlier filter is robust,
scalable, and generates satisfactory results (ranked No. 2 in
the final evaluation). The following key observations lead to
the effectiveness of our model:
1) The total number of GPS records in the network provided
a good indicator of the position of a simulation hour during
simulation cycles;
2) Constructing the velocity estimate based on file 2 of the
training data instead of the GPS stream in file 1 as the latter
is very noisy and scattered;
3) Using the total number of GPS counts with zero velocity
on each link as a major component of local similarity;
4) Taking the harmonic mean of the nearest neighbors
instead of the arithmetic mean or median as the estimate.
Due to time constraints, we were unable to extend the
method to incorporate information from other links in geographic proximity to the 100 test links, an extension which
may serve to increase the quality of the predictions further.
ACKNOWLEDGMENT
We thank the contest organizers and sponsor of the contest
for the interesting and challenging competition.
R EFERENCES
[1] J. Greenfeld. Matching GPS observations to locations on a
digital map. In Proceedings of the 81st Annual Meeting of the
Transportation Research Board, Washington D.C., 2002.

IV. T HE E VALUATION F RAMEWORK
For each link k of interest, our K nearest neighbor method
with the outlier filter has seven parameters in total:
1) K - the total number of neighbors used in constructing
the velocity estimate;

[2] H. Alt, A. Efrat, G. Rote, and C. Wenk. Matching planar maps.
Journal of Algorithms, 49: 262 - 283, 2003.
[3] W. Min, L. Wynter, and Y. Amemiya. Road traffic prediction
with spatial-temporal correlations. IBM Research, 2007.

1371

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Hierarchical Active Transfer Learning
David Kale∗

Marjan Ghazvininejad∗

Anil Ramakrishna∗

Abstract
We describe a unified active transfer learning framework
called Hierarchical Active Transfer Learning (HATL).
HATL exploits cluster structure shared between different data domains to perform transfer learning by imputing labels for unlabeled target data and to generate
effective label queries during active learning. The resulting framework is flexible enough to perform not only
adaptive transfer learning and accelerated active learning but also unsupervised and semi-supervised transfer
learning. We derive an intuitive and useful upper bound
on HATL’s error when used to infer labels for unlabeled
target points. We also present results on synthetic data
that confirm both intuition and our analysis. Finally, we
demonstrate HATL’s empirical effectiveness on a benchmark data set for sentiment classification.
1 Introduction
In the era of big data, one major challenge confronting
us is that typically only a small portion of the vast
data is labeled, since annotation is often both time
consuming and costly. This can limit the performance of
predictive models and their ability to generalize to new
observations. In response to this challenge, researchers
have explored two complementary directions: transfer
learning and active learning.
The goal of transfer learning (and related techniques, such as domain adaptation), is to leverage the
labeled data from a related source domain (or task) to
compensate for lack of (labeled) data in a target domain.
Transfer learning has seen significant success in applications, such as computer vision [16] and natural language
processing [12]. However, it is also notorious for producing negative transfer, where transferring source knowledge hinders learning in the target domain, especially
when zero target labels are available [14].
In some applications, we have access to a label
oracle with limited query budget. In these cases, active
learning can identify a small set of examples that, if
labeled, will help to train effective predictive models.
∗ Computer Science Department, Viterbi School of Engineering, University of Southern California, USA
† School of Computing, Informatics, and Decision Systems
Engineering, Arizona State University, USA

Jingrui He†

Yan Liu∗

A vibrant area of machine learning research over the
past decade, active learning has produced a number
of practical and theoretical breakthroughs, as well as
a wide spectrum of algorithms [17, 5]. Nonetheless,
active learning is not a panacea; in particular, it has
a circular dependency on data. In order to pose good
label queries, we must have a reasonably good classifier;
in order to train a good classifier, we need labeled data.
When starting with no labels (i.e., a cold start), most
active learners must resort to random sampling [5, 10].
In this paper, we develop a new hierarchical
clustering-based framework, named Hierarchical Active
Transfer Learning (HATL), that combines these two
learning schemes. It takes as input a cluster tree built
on source and target data and uses cluster structure
and label information from both domains to impute labels on the full data set (source and target). During
early learning it relies heavily on labeled source points
but gradually incorporates feedback from target label
inquiries to refine both its clustering and its label imputation. This accelerates the learning process and mitigates the cold start problem. We derive an intuitive
and useful upper bound on HATL’s error when used
to infer labels for unlabeled target points and present
results on synthetic data that deliver insight into our
theoretical analysis. We demonstrate HATL’s empirical effectiveness on a benchmark data set for sentiment
classification.
The paper is organized as follows. In Section 2, we
briefly review the related work. The proposed framework is introduced in Section 3, followed by theoretical
analysis in Section 4. Finally, we provide experimental
results in Section 5 and conclude in Section 6.
2 Related Work
There is a growing body of excellent research on combining active learning with transfer learning [15, 13],
but the topic still has many open problems and gaps
to bridge between theory and practice. [15] represents
some of the earliest active transfer learning work and describes a simple but intuitive solution that uses a sourcetrained classifier as a cost-free surrogate for the target
label oracle. The paper analyzes label complexity and
error rates and demonstrates convincing empirical re-

514

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

sults. This approach uses uncertainty region sampling,
which can be susceptible to bias and local optima [5].
[4] proposes an optimization-based framework (JOTAL) for adaptive transfer learning with feedback from
batch target label queries. What makes this framework
unique is its choice of objective function: instead of target classification error, it optimizes the similarity (measured using kernel maximum mean discrepancy [8]) between labeled source and target and remaining unlabeled target data points. Empirical results suggest that
JOTAL is one of the most effective active transfer learning frameworks to date. The algorithm, however, lacks a
rigorous theoretical treatment and uses a quadratic programming formulation that may require modification to
scale up to large data sets.
[19] describes a theoretically rigorous Bayesian
framework for active transfer learning, based on priordependent learning. Assuming a prior distribution over
model parameters can accelerate active learning, but
this requires access to the prior [18]. [19] shows that in
sequential transfer learning settings, the prior is identifiable and places an upper bound on the number of
samples required from each domain. However, there is
no limit on the number of tasks that may be required,
and the paper presents no experimental results.
A recent paper that bridges the gap between
theoretical soundness and empirical effectiveness is
[10], which presents a principled framework called
transfer-accelerated, importance weighted consistent active learning (TIWCAL). The authors combine the agnostic active learning algorithm of [1] with transfer
learning based on minimizing a convex combination of
source and target errors [2]. They provide efficient algorithm and derive an intuitive upper bound on target
classification error. Their empirical results show that
TIWCAL can improve target task performance while
reducing the number of target label queries. This approach, however, suffers from the use of static transfer
learning, based on an a priori choice of domain weights.

a hypothesis h 2 H. Now let T denote the binary
tree representing a hierarchical clustering of the data
points in X . For any node (or cluster) v in T , let Tv
denote the hierarchy of nodes (or subtree) rooted at
v. In particular, T = Troot . If we descend far enough
down Tv , we reach a leaf node x, which is a data point.
Denote the set of points associated with arbitrary v as
X(v). Each v has two child nodes u1 and u2 , such that
X(v) = X(u1 ) [ X(u2 ). Trivially, X(x) = {x} for leaf
nodes. A pruning Pv is a subset of non-overlapping
nodes of S
Tv that contains all points associated with v:
X(v) = u2Pv X(u). P is a pruning of the complete
tree T . A labeling function L(v) is a mapping of a node
v to a label (e.g., L(v) : v 7! ±1).

3.2 A Brief Review of HSAL: The Hierarchical
Sampling for Active Learning (HSAL) [6] algorithm was
introduced in [6] and is described in detail in Appendix
7.1 HSAL begins with a cluster tree T over N points
in X and a label query budget of B. At all times, it
maintains a current P and L for T , with initial values
of P = {root} and L(root) = +1. Each iteration of
HSAL consists of four main steps. First, it queries labels
for a batch of b unlabeled points. Second, it estimates
the label proportions in each v 2 P . Next, it updates
P by replacing any node v with its children if it has
a high label disagreement (i.e., high likelihood that the
label proportions are equal, quantified using confidence
intervals). Finally, it updates L by letting L(v) equal
the estimated majority label for each v. Label queries
are made by choosing first a cluster v from P and then
an unlabeled point x from X(v). [6] suggests choosing
v with probability proportional to both its size and
uncertainty about its majority label.
Upon termination, HSAL produces a fully labeled
data set Y = {(x, ŷ(x)) : 8x 2 X } by assigning
ŷ(x) = L(v) to each x 2 X(v). Y can be used to
train any classifier. This label imputation step may assign some incorrect labels, but it also avoids the sample selection bias suffered by other active learning al3 The Proposed Framework
gorithms [6]. The goal of HSAL, then, is to use B
In this section, we introduce our Hierarchical Active label queries to search for P and L with the minerror ✏(P, L), where
Transfer Learning (HATL) framework. We define no- imum possible label
P imputation
P
✏(P,
L)
=
(1/N
)
(L(v)
6= f (x)). This is
tation in Section 3.1, briefly review Hierarchical Samv2P
x2X(v)
pling for Active Learning (HSAL) [6] in Section 3.2, the error when each point is assigned the label L(v) of
its associated cluster v in P . It can be thought of as
and describe HATL in Section 3.3.
transductive classification error on the clustered data.
3.1 Notation: Let X denote a finite sample of data
points from a distribution D. Let f be a true labeling 3.3 Hierarchical Active Transfer Learning: In
function, so that the label of a point x is f (x). We active transfer learning, we have labeled data XS from
will add subscripts to denote samples and distributions
for different domains (e.g., XT , DT , and fT for the
1 Available
online at http://www-scf.usc.edu/∼dkale/
target domain). We will view learning as searching for publications.html

515

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

the source domain, in addition to unlabeled target data
XT . Our proposed HATL framework can leverage XS
and a limited number of queried target labels to help
impute labels for the full XT , which we can then use to
train an accurate classifier for the target domain. HATL
is summarized in Algorithm 1.
Algorithm 1 Hierarchical Active Transfer Learning
(HATL)
Input: Hierarchical cluster tree T of unlabeled target
data XT and labeled source data XS ; target label
budget B and batch size b; target label oracle
1: P
− {root}, L(root) − +1
2: for each (x, y) where x 2 XS , y = fS (x) do
3:
UpdateNodeStatistics(x, y, root)
4: end for
5: (P, L)
GetPruningAndLabeling(T )
6: if B > 0 then
7:
(P, L)
HSAL(T, {XT , XS }, P, L, B, b, oracle)
8: end if
9: for each v 2 P do
10:
ŷ(x) − L(v) for each x 2 X (v)
11: end for
Output: Labeled source and target data: YS =
{(x, ŷ(x)) : 8x 2 XS }, YT = {(x, ŷ(x)) : 8x 2 XT }.
We begin with cluster tree T over XS [ XT , a label
budget B and batch size b, and target label oracle.
On line 1, we initialize P to the root of T and L to
be an arbitrary label. Then in lines 2-4, we update
the label proportion estimates for all nodes, based on
labeled source points. The UpdateNodeStatistics(x, y, v)
subroutine performs this update for all nodes along the
path from x to v in Tv . On line 5, we update P and
L using the GetPruningAndLabeling(Tv ) subroutine,
which recursively splits nodes in Tv that have high label
disagreement. If the budget B > 0, we run HSAL on the
mixture of source and target data but using the updated
P and L (lines 6-8). Finally, we impute labels for all
source and target points in lines 9-11 and output the
fully labeled data sets. The UpdateNodeStatistics and
GetPruningAndLabeling subroutines are implemented
as in HSAL and are described in Appendix 7.1
Discussion. Consider P and L at line 5, following the initial update and pruning but before any target label queries. Every cluster v in P must have either a clear source majority label L(v) or a proportionally small number of labeled source points (so that L(v)
could not be estimated with high confidence). Otherwise, v would have been replaced with its children. In
the latter case, the source data in v will play a limited
role during subsequent active learning (line 7), and the
number of target queries required to choose L(v) will

be similar to that in plain HSAL. In the first case, the
source-based L(v) provides a strong bias about the majority label in v. If most target labels in v agree with
L(v), then the bias is beneficial, and we can achieve a
low label imputation error with few, if any, target label
queries. If, however, most target labels in v disagree
with L(v), then we must query target labels until we
confirm this and split v.
A natural question to ask is under what conditions
HATL might perform poorly or even worse than plain
HSAL? First, suppose that source and target distributions are quite similar, forming several clear large clusters, but that source and target points within each cluster have the opposite labels. The initial pruning P (line
5) will include large clusters with relatively pure source
labels but high target label imputation error. HATL
may need to query a large number of target labels in
order to find separate source-only and target-only clusters in order to improve its labeling. Meanwhile, HSAL
will discover the large, pure target clusters with a small
number of queries. Thus, HATL requires that the source
and target tasks share reasonably similar labeling functions. We will formalize this intuition in Section 4.
Now suppose that the source and target data share
similar labeling functions but have very different cluster
structures with few overlapping regions. The initial
pruning (line 5) will be pure with respect to source
labels but may not reflect the natural cluster structure
of the target data and may group together source and
target points with different labels. HATL’s initial label
imputation may be superior to that of HSAL, but
HSAL will improve rapidly as it finds the large, pure
target clusters with a small number of queries. HATL,
in contrast, will likely plateau until it queries enough
target labels to discover a pruning that matches the
target cluster structure. Thus, the more similar the
target and source distributions and cluster structure,
the better HATL’s performance. In Section 4 we will
derive an upper bound on the target label imputation
error that incorporates domain similarity.
4 Theoretical Analysis
Here we provide a theoretical analysis of the performance of HATL. We begin by stating our main theoretical result, which places an upper bound on the target
label imputation error, given that HATL has queried a
minimum number of labels required to find a relatively
pure pruning of the cluster tree.
Theorem 4.1. Suppose we have constructed a cluster
tree T on over NS source points drawn from DS and
NT target points drawn DT . Choose δ, ⌘ > 0 and any
pruning P ⇤ of T with label imputation error ✏(P ⇤ )  ⌘.

516

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Now assume that HATL has queried bt labels to discover Ah , maximized over hypotheses h 2 H. Throughout
pruning P . Then with probability at least 1−δ our target this paper, we will use dH with a specific hypothesis
label imputation error ✏T (P ) is
class H that consists of one nearest neighbor (1NN)
classifiers that can be constructed from points in cluster
⇤
e
✏T (P )  O(✏(P
) + ⌘)
✓
◆ tree T that have been relabeled using (P, L).
1
We actually use the more specialized dH∆H distance
+ (1 − ↵)
dH∆H (DS , DT ) + "⇤ST
[2], based on the symmetric difference hypothesis class:
2
s
D log(2NT ) − log δ
Definition 4.2. (H∆H hypothesis class [2])
+2
Define
the symmetric difference hypothesis class as
2NT
⌘
⇣ ∗
d∗
∗
e |P | log( 2 b|P | ) (Theorem 1 from [6])
where bt = O
η
ηδ
, ↵ = NT /(NS + NT ), dH∆H (DS , DT ) is the distance
between the source and target distributions DS and DT
[2], "⇤ST is the combined risk of the ideal hypothesis [2],
t is the number of iterations, b is the batch size (queries
per iteration), D is the VC dimension of the hypothesis
class, and d⇤ and |P ⇤ | are the depth and size of P ⇤ .
This theorem places an upper bound on the target
label imputation error with three intuitive terms. The
first is related to the overall (source and target) label imputation error for optimal P ⇤ . The second is a distance
measure between source and target data distributions,
weighted by the proportion 1− ↵ of the data that comes
from the source domain. This term is small when our
tasks are similar or when NT * NS . The third comes
from an application of Hoeffding’s inequality for bounding the deviation between empirical and true errors and
will be relatively small when NT is large.
The proof, given below, builds upon Theorem 1
from [6] , which provides a guarantee about the number
of label queries bt needed by HSAL to find a P with
label imputation error no worse than ✏(P ⇤ ) + ⌘, where
✏(P ⇤ )  ⌘. The total number of queries, bt, depends
upon the number of clusters in P ⇤ , the maximum depth
d⇤ of a cluster in P ⇤ , and choices of δ and ⌘.
4.1 Proof of Theorem 4.1: To prove our theorem,
we begin by introducing several definitions and lemmas.
First, we will use dH distance [11], a hypothesis classdependent distance between data distributions:

H∆H = {g : g(x) = +1 () h(x) 6= h0 (x), h, h0 2 H}
For each pair of hypotheses h, h0 2 H, there exists a g 2
H∆H such that g(x) = +1 if and only if h(x) 6= h0 (x).
Using H∆H we can define the dH∆H distance, for which
the following inequality holds for all h, h0 2 H [2]:
1
dH∆H (DS , DT )
2
where "S (h, h0 ) = P {h(x) 6= h0 (x) for x ∼ DS } is the
label disagreement between h, h0 2 H on points from
DS . This places an upper bound on the difference
between source and target label disagreement for any
pair of hypotheses in H. "S (h) refers to "S (h, fS ), label
disagreement with the true labeling function fS .
We now consider a convex combination of source
and target errors [2], e.g., "α
ST (h) = (1 − ↵)"S (h) +
↵"T (h) for 0 < ↵ < 1. Lemma 1 from [2] upper
bounds the difference between combined and target risk
for hypothesis h:
✓
◆
1
α
⇤
|"ST (h) − "T (h)|  (1 − ↵)
dH∆H (DS , DT ) + "ST
2
|"S (h, h0 ) − "T (h, h0 )| 

where "⇤ST = min "S (h) + "T (h) is the combined risk
h2H

of the hypothesis in H that simultaneously minimizes
source and target error [2]. This quantifies the excess
risk that is due to the difficulty of the task and the differences between the labeling functions fS and fT . Most
domain adaptation and transfer learning frameworks require that "⇤ST be small in order to succeed [2].
Next we prove a lemma that shows that we can
rewrite the label imputation error as a convex combination of source and target empirical errors:

Definition 4.1. (dH distance [11]) Suppose
we
have source and target data distributions DS and DT
Lemma 4.1. Suppose we have run HATL on source and
and hypothesis class H. We can define a dH distance
target samples XS and XT and discovered pruning P .
[11] between DS and DT as:
The label imputation error ✏(P ) can be rewritten as
dH (DS , DT ) , 2 sup |PDS {Ah } − PDT {Ah }|
✏(P ) = "α
h2H
XST (hP ) = (1 − ↵)"XS (hP ) + ↵"XT (hP )
where Ah = {x : x 2 X where h(x) = +1}, the set of
points classified as positive by h.

where hP is a 1NN classifier induced by P ; "XS , "XT ,
and "α
XST are the source, target, and combined empirical
errors
using XS , XT , and XST = XS [ XT ; and ↵ =
The dH distance is the difference between probability
NT
masses assigned by the source and target domains to NS +NT .

517

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Proof.
✏(P ) =

1
NS + NT

X

Step 3 applies Lemma 1 from [2] to upper bound the
combined error. Step 6 applies Theorem 1 from [6] to
place an upper bound on the label imputation error of
P , assuming that we have queried bt labels.

1{hP (x) 6= fS (x)}

x2XS

+

X

1{hP (x) 6= fT (x)}

x2XT

=

!

Proof.

NS
1 X
1{hP (x) 6= fS (x)}
NS + NT NS

✏T (P ) = "XT (hP )

x2XS

NT
1 X
+
1{hP (x) 6= fT (x)}
NS + NT NT

D log(2NT ) − log δ
2NT
✓
◆
1
α
⇤
 "ST (hP ) + (1 − ↵)
dH∆H (DS , DT ) + "ST
2
s
D log(2NT ) − log δ
+
2NT
◆
✓
1
⇤
d
(D
,
D
)
+
"
 "α
(h
)
+
(1
−
↵)
H∆H
S
T
P
ST
XST
2
s
D log(2NT ) − log δ
+2
2NT
✓
◆
1
⇤
dH∆H (DS , DT ) + "ST
= ✏(P ) + (1 − ↵)
2
s
D log(2NT ) − log δ
+2
2NT

 "T (hP ) +

x2XT

= (1 − ↵)"XS (hP ) + ↵"XT (hP ),

↵=

NT
NS + NT

= "α
XST (hP )
The next lemma, adapted from Lemma 2 of [2] , bounds
the deviation between empirical and true combined risk:
Lemma 4.2. Suppose H has finite VC dimension D
and that we have finite samples XS and XT of NS and
NT source and target points, respectively. Then with
probability 1 − δ we have
s
D log( 2N
α
δ )
|"α
XST (h) − "ST (h)| 
2N
T
where ↵ = NSN+N
, N = NS + NT , and the expectaT
tion is over finite samples from the source and target
distributions DS and DT , respectively.

⇤
e
 O(✏(P
) + ⌘)

This is a standard Hoeffding inequality bound, assuming
finite VC dimension D. Ordinarily, 1NN classifiers
have infinite VC dimension, but our hypothesis class
is a subset of 1NN classifiers that can be created using
prunings of our cluster tree T . There is only a finite
number of such prunings. Thus, H is a finite hypothesis
space with VC dimension D  log2 |H| [9].
Finally, we combine Lemmas 4.1 and 4.2 with
Theorem 1 from [6] to prove Theorem 4.1. In the
following proof, Steps 1 and 5 are by definition. Steps 2
and 4 apply Lemma 4.2, first to the target-only error
(with NT target points), then to the combined error.
Because NT  N , log(2NT )/NT ≥ log(2N )/N , so we
use NT instead of N so that we have only one square
root term. The actual bound (using N ) is tighter.

✓

1
dH∆H (DS , DT ) + "⇤ST
2
s
D log(2NT ) − log δ
+2
2NT

+ (1 − ↵)

Proof. This is a straightforward application of Lemma
2 from [2] , which says that
s
s
2
2
D log( 2N
(1 − ↵)
↵
α
δ )
|"α
+
XST (h) − "ST (h)| 
γ
1−γ
2N
where γ = NT /N . In our case, γ = ↵.

s

◆

4.2 Discussion of Theorem 4.1: This theorem
represents a useful guide to understanding and applying HATL. We can expect it to perform best when the
source and target distributions are similar and when
we have relatively large data sets. However, we should
be careful when interpreting its guarantees, as it makes
strong assumptions. In particular, it assumes that clusters are selected for querying with probability proportional to size (similar to Theorem 1 from [6] ). In transfer learning, we typically begin with m “free” labeled
source points. To apply Theorem 4.1, we must assume that these, too, were sampled at random from a
larger pool of NS / m/(bt − m) source points. This
value will change with each iteration of HATL, but the
source data set is of fixed size. In practice, however,
these assumptions should have minimal impact.

518

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

5 Experimental Results
Now we present experimental results that confirm
our intuition and analysis and deepen our understanding of HATL. All code and data for these experiments (including implementations of HSAL [6],
TIWCAL [10], and JOTAL [4]), may be found at
http://www-bcf.usc.edu/⇠liu32/code.html.
5.1 Synthetic data: We design a series of onedimensional synthetic data sets to examine the behavior of HATL and compare its performance with HSAL
under different conditions. We create a single target
domain and five source domains (S1 − S5) of varying
similarity to the target domain, as visualized in Figure 1a. The target data fall into four distinct clusters
of equal size and extent, while each source domain has
between two and four clusters of different sizes and at
different locations. All domains share the same labeling
function: we divide the real line into four regions with
alternating labels. For our experiments, we sample 25
data sets with 200 points each from each domain.
Measuring domain similarity: We approximate
the dH∆H distance (denoted dˆH∆H ) using a domain
separator hypothesis [15], i.e., a classifier trained to
distinguish source from target points. The accuracy of
this classifier is proportional to the distance between
distributions: the more separable the classes, the more
different their distributions. We use a 1NN classifier
(the type of classifier induced by HATL) as our domain
separator and its mean accuracy (estimated via 10-fold
cross validation) as the dˆH∆H distance.
Label imputation error: Figure 1b shows target label imputation error versus target label queries
for HSAL and HATL using S1, S3, and S5. We report mean performance (with 95% confidence intervals)
across all 25 data samples from each domain. HATL
provides substantial benefit over HSAL, particularly
with few queries. It takes HSAL over 20 queries to
reach a mean error of 0.1. Using S1, HATL reaches 0.1
with 15 queries (a 25% reduction) and dominates HSAL
through all 50 queries. Using S2 HATL outperforms
HSAL through the first 15 queries and is competitive
thereafter. S5 provides an early benefit but increases
HATL’s error in the long run. This is not surprising:
S5 has the highest dˆH∆H distance and minimal cluster
overlap. This is an example of a persistent negative bias
leading to a plateau, as discussed in Section 3.3.
Tightness of Theorem 4.1: We are also interested in exploring the tightness and utility of the bound
in Theorem 4.1. While it is intuitive and delivers insight into the strengths and limitations of HATL, such
bounds are known to be loose in practice. We can
rewrite it as bounding the deviation between the tar-

get and optimal overall label imputation errors:
,
, 1−↵
,
,
⇤
e
dH∆H (DS , DT )
) + ⌘), 
,✏T (P ) − O(✏(P
2
We have dropped the "⇤ST and square root terms from
the theoretical bound. The former will be negligibly
small since we labeled all synthetic data sets using the
same labeling function. The latter is large because
the
p synthetic data sets are very small (for NT = 200,
2 log(2NT )/(2NT ) > 0.25) and will overwhelm the domain similarity term. The remaining righthand term is
the weighted similarity between source and target domains, which we can again approximate using the 1NN
domain separator classifier. We will subsequently denote this as dˆH∆H . We estimate the lefthand term (the
deviation) as follows: first, we set the label imputation
error threshold ⌘ = 0.05 and perform a greedy breadthfirst search for a pruning P ⇤ with error ✏(P ⇤ )  ⌘.
Then we run HATL and identify the first iteration where
✏(P )  ✏(P ⇤ ) + ⌘. We assume that we have enough
queries to satisfy the assumptions of Theorem 4.1. Finally, we compute the target-only error ✏T (P ) and the
deviation term. Figure 1c compares the average deviation with the average dˆH∆H distance for each source
data set. The actual deviation is nearly constant across
data sets, between 0.06 and 0.07. The deviation predicted by dˆH∆H grows faster than the actual deviation.
This is surprising because Theorem 4.1 suggest
that HATL’s performance should improve as dH∆H
distance decreases. We can derive some insight into
why this might not be the case if we consider S2 vs.
S4 (Figure 1d). S2 clearly hurts the performance
of HATL; its initial error is as bad as HSAL, and
it plateaus very early. S4 is nearly perfect from the
beginning. This is because S4 has points lying in all
four regions of the true labeling function and provides a
useful initial bias for HATL. S2 has points concentrated
only in the center two regions. However, S2 has a
lower dˆH∆H distance than S4. This suggests that while
dH∆H is a principled and often useful measure of domain
similarity, it has important limitations. In particular, it
ignores the sometimes complex interaction between the
marginal data and conditional label distributions.
5.2 Sentiment classification: Next, we perform experiments using version 2.0 of the Multi-Domain Sentiment Classification (sentiment) data set [3] of Amazon
product reviews. Each product category is treated as a
domain, and the task is to predict the sentiment (positive or negative) of an individual review based on its
contents. In version 2.0, each category contains 1000
positive and 1000 negative documents, represented as
sparse vector of word and bigram counts from a vocabulary of well over a million unique entries. We reduced

519

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

(b) Target label imputation error.

Tightness of Theorem 1 bound
0.25

0.2

Deviation

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

(a) 1D synthetic data sets.

0.15
|ε (P)−(ε(Q)+η)|
T

(1−α)/2 d

H∆H

0.1

0.05

0

S1 (16.24)

S2 (71.52)

S3 (19.36)

S4 (1.00)

S5 (48.76)

Source data

(d) A higher dˆH∆H outperforms a lower dˆH∆H .

(c) Tightness of the Theorem 4.1 bound.

Figure 1: 1D synthetic data experiments. (a) Sources organized vertically by dˆH∆H . (b,d) Mean target label
imputation error for (b) S1, S3, and S5 and (d) S2 and S4. Shading indicates 95% confidence intervals. (c) Actual
vs. predicted absolute deviation between P ’s target label error and P ⇤ ’s overall label error (average number of
queries in parentheses).
the number of features to just over 2000 unigrams and
converted raw counts to log counts. We used 10-fold
cross-validation to estimate the prediction error on the
test set. For each experiment, we choose one category
as the target domain. We start with zero target data
labels and run active learning until all labels have been
queried. For the active transfer learning algorithms, we
use a second category as our source data, choosing 200
positive and 200 negative examples at random to use as
the labeled sample. HATL also uses the remaining 1600
unlabeled source data points in its clustering but does
not have access to the true labels.
We compare HATL’s performance against standard baselines and competing state-of-the-art algorithms, including HSAL, passive transfer learning (train

on source plus labeled target points chosen at random), and joint transfer and batch-mode active learning
(JOTAL)[4]. The reported accuracies use a linear classifier with squared hinge loss and L2 regularization (from
LIBLINEAR [7]). For HSAL and HATL, the classifier is
trained on all training data (including source for HATL)
with imputed labels. Other algorithms are trained only
on data points for which labels are available or queried.
Figure 2 shows results using kitchen as target and
dvd as source. These are among the least similar categories [3]. The baseline supervised (train on labeled
target data) accuracy for kitchen is 0.8925 ± 0.0121.
The baseline unsupervised transfer learning (train on all
dvd data) accuracy is 0.7850 ± 0.0283. HATL outperforms the competing approaches throughout the entire

520

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Sentiment classification: dvd→kitchen
?/@<7-/@<1=4588737=5<72@A1B:B−CD7<=E/@

?/@<7-/@<1=4588737=5<72@A1B:B−CD7<=E/@

1

!'*

1
!'*
9:/05;/1</8<18/<15==,05=>
Average
test set accuracy

9:/05;/1</8<18/<15==,05=>
Average
test set accuracy

!'%
!')(
!')
?,F/0:78/B14/50@7@;1G7<E1544145./48
H?9I
J5887:/1<05@83/014/50@7@;
KLM9I
HATL
HMI

!'$(
!'$
!'((
!'(1
!

"!

#!

$!

%!

!'%)

!'()1
!

&!!

?,F/0:78/B14/50@7@;1G7<E1544145./48
H?9I
J5887:/1<05@83/014/50@7@;
KLM9I
HATL
HMI

!'%

"!!

#!!

(a) Test set accuracy through 100 queries.

)!!

1

Average no. of clusters in pruning
89./4:.0;+,-./0120<3+7=./706;0>/+;6;:

!'*(
!'*
!'%(
!'%
!')(
!')
G@9H
GIH
HATL

!'((
!'(1
!

"!!

#!!

$!!

%!!

&!!! &"!! &#!! &$!! &%!!

?.;=6,.;=0<3477626<4=61;@0A9A−BC6=<D.;

&

!'$

%!!

(b) Test set accuracy through 1800 queries.

@/?<7-/?<1A4588737A5<72?B1C:C−DE7<AF/?

!'$(

$!!

+,-./0123145./416,/07/8
Number
of label queries

+,-./0123145./416,/07/8
Number
of label queries

Average
target label purity of pruning
9:/05;/1<50;/<145./41=,07<>1231=0,?7?;

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

!'%(

$!!
(!!
#!!
'!!
"!!
&!!
!0
!

&!!! &"!! &#!! &$!! &%!!

0

E?8F
EGF
HATL
T

"!!

#!!

$!!

%!!

&!!! &"!! &#!! &$!! &%!!

*+,-./012034-.305+./6.7
Number
of label queries

+,-./0123145./416,/07/8
Number
of label queries

(c) Target label imputation accuracy.

(d) Number of clusters.

Figure 2: dvd-to-kitchen sentiment classification results. Mean test set accuracy through (a) 100 and (b) the
1800 target label queries. (c) Mean target label imputation accuracy of P . (d) Mean size of P .
label query budget (Figure 2a and Figure 2b). The
initial test set accuracy of both HATL and JOTAL is
equivalent to that of the unsupervised transfer learning
baseline and 7 points better than the passive transfer
learner. This suggests that HATL and JOTAL can both
perform unsupervised transfer learning effectively, using
very different approaches. Figure 2c shows that HATL
can also perform semi-supervised learning; with even a
small number of queries, the accuracy for target points
in the clustering is higher than for the test set.
HATL significantly outperforms HSAL. With zero
target labels, HATL is 30 points better than HSAL in
both label imputation accuracy and test set accuracy.
HSAL improves more rapidly over the first few hundred label queries, but HATL continues to outperform
HSAL by at least a few points in accuracy until the very
end. Further, HATL converges to the fully labeled supervised learning performance, just as HSAL does. This
indicates that it avoids negative transfer, successfully
adapting the initial source-based transfer bias based on
the target label feedback that it receives.

6 Discussion and Conclusion
We have described a unified framework for active transfer learning, called Hierarchical Active Transfer Learning (HATL), which uses the machinery of the wellknown, clustering-based Hierarchical Sampling for Active Learning (HSAL) [6]. HATL exploits source and
target domain similarity in the form of shared cluster
structure to impute labels for unlabeled target data and
gradually adapts this transfer as it active queries target
labels. We formalized the intuition behind HATL by
deriving an upper bound on the target label imputation
error that includes terms related to the imputation error
of an optimal pruning and the similarity and respective
sizes of the source and target data sets. We used synthetic data experiments to deepen our understanding
of the error bound and of when and how HATL works.
On a benchmark domain adaptation data set [3], HATL
outperformed its progenitor algorithm, HSAL, and competed with a state-of-the-art active transfer learning
framework [4]. What is more, our results suggest that
this flexible framework can also be used to perform un-

521

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

supervised transfer learning and semi-supervised learning. For future work, we are exploring ways to enable
HATL to adapt more rapidly to target label queries.
One possibility is to reweight source data (based on
cluster proportions) whenever the pruning changes. We
are also experimenting with alternative measures (e.g.,
two-sample tests) of the within-cluster label agreement
between source and target points.
Acknowledgements
The research was partially supported by NSF research
grants IIS-1134990 and IIS-1254206; by the U.S. Defense Advanced Research Projects Agency (DARPA)
under the Social Media in Strategic Communication
(SMISC) program, Agreement Number W911NF-12-10034; and by an IBM Faculty Award. David Kale is
supported by the Alfred E. Mann Innovation in Engineering Doctoral Fellowship. The views and conclusions
are those of the authors and should not be interpreted as
representing the official policies of the funding agencies
or the U.S. Government. We also would like to thank
Sanjoy Dasgupta and our anonymous reviewers for their
helpful feedback.
References
[1] A. Beygelzimer, J. Langford, D. Hsu, and
T. Zhang. Agnostic Active Learning Without Constraints. In Advances in Neural Information Processing Systems (NIPS) 23, pages 199–207. 2011.
[2] J. Blitzer, K. Crammer, A. Kulesza, F. Pereira,
and J. Wortman. Learning bounds for domain
adaptation. In Advances in Neural Information
Processing Systems (NIPS) 20, pages 129–136,
2007.
[3] J. Blitzer, M. Dredze, and F. Pereira. Biographies,
Bollywood, Boom-boxes and Blenders: Domain
Adaptation for Sentiment Classification. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL), 2007.
[4] R. Chattopadhyay, W. Fan, I. Davidson, S. Panchanathan, and J. Ye. Joint transfer and batchmode active learning.
In Proceedings of the
30th International Conference on Machine Learning (ICML), pages 253–261, 2013.
[5] S. Dasgupta. Two Faces of Active Learning.
Theoretical Computer Science, 412(19):1767–1781,
2011.
[6] S. Dasgupta and D. Hsu. Hierarchical sampling for
active learning. In Proceedings of the 25th International Conference on Machine Learning (ICML),
pages 208–215, 2008.

[7] R. Fan, K. Chang, C. Hsieh, X. Wang, and C. Lin.
LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research,
9:1871–1874, 2008.
[8] A. Gretton, K. Borgwardt, M. Rasch, B. Schölkopf,
and A. Smola. A kernel method for the two-sampleproblem. In Advances in Neural Information Processing Systems (NIPS) 19, pages 513–520. 2007.
[9] D. Haussler. Quantifying inductive bias: AI learning algorithms and Valiant’s learning framework.
Artificial Intelligence, 36(2):177–221, September
1988.
[10] D. Kale and Y. Liu. Accelerating active learning with transfer learning. In Proceedings of the
IEEE 13th International Conference on Data Mining (ICDM), 2013.
[11] D. Kifer, S. Ben-David, and J. Gehrke. Detecting
change in data streams. In Proceedings of the 30th
International Conference on Very Large Databases
(VLDB), pages 180–191. VLDB Endowment, 2004.
[12] A. Kumar, A. Saha, and H. Daumé III. A coregularization based semi-supervised domain adaptation. In Advances in Neural Information Processing Systems (NIPS) 23, 2010.
[13] C. Luo, Y. Ji, X. Dai, and J. Chen. Active learning
with transfer learning. In Proceedings of ACL 2012
Student Research Workshop, pages 13–18, 2012.
[14] S. J. Pan and Q. Yang. A survey on transfer
learning. IEEE Transactions on Knowledge and
Data Engineering, 22(10):1345–1359, Oct 2010.
[15] P. Rai, A. Saha, H. Daumé, and S. Venkatasubramanian. Domain adaptation meets active learning.
In Proceedings of the NAACL HLT 2010 Workshop
on Active Learning for Natural Language Processing, pages 27–32, 2010.
[16] R. Raina, A. Battle, H. Lee, B. Packer, and A. Ng.
Self-taught learning: transfer learning from unlabeled data. In Proceedings of the 24th International Conference on Machine Learning (ICML),
pages 759–766, 2007.
[17] B. Settles. Active Learning, volume 6 of Synthesis
Lectures on Artificial Intelligence and Machine
Learning Series. Morgan & Claypool Publishers,
June 2012.
[18] L. Yang, S. Hanneke, and J. Carbonell. Identifiability of priors from bounded sample sizes with
applications to transfer learning. pages 791–808,
2011.
[19] L. Yang, S. Hanneke, and J. Carbonell. A Theory
of Transfer Learning with Applications to Active
Learning. Machine Learning, 90(2):1–28, 2012.

522

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

A Unified Optimization Based Learning Method for Image Retrieval*
Hanghang Tong1,噛 , Jingrui He1,噛 , Mingjing Li2, Wei-Ying Ma2,
Changshui Zhang3, Hong-Jiang Zhang 2
1,3
Department of Automation, Tsinghua University, Beijing 100084, China
2
Microsoft Research Asia, 49 Zhichun Road, Beijing 100080, China
1
{walkstar98, hejingrui98}@mails.tsinghua.edu.cn, 2{mjli, wyma, hjzhang}@microsoft.com
3
zcs@tsinghua.edu.cn

Abstract
In this paper, an optimization based learning
method is proposed for image retrieval from graph
model point of view. Firstly, image retrieval is
formulated as a regularized optimization problem,
which simultaneously considers the constraints from
low-level feature, online relevance feedback and
offline semantic information. Then, the global optimal
solution is developed in both closed form and iterative
form, providing that the latter converges to the former.
The proposed method is unified in the senses that 1) it
makes use of the information from various aspects in a
global optimization manner so that the retrieval
performance might be maximally improved; 2) it
provides a natural way to support two typical query
scenarios in image retrieval. The proposed method
has a solid mathematical ground.
Systematic
experimental results on a general-purpose image
database demonstrate that it achieves significant
improvements over existing methods.

1. Introduction
Initial image retrieval is based on keyword
annotation, which is a natural extension of text
retrieval [2, 14]. The typical query scenario in such
image retrieval systems is query by keyword (QBK).
However, it suffers from several main difficulties, e.g.,
the large amount of manual labor required to annotate
the whole database, and the inconsistency among
different annotators in perceiving the same image [11].
To overcome these difficulties, an alternative
scheme, content-based image retrieval (CBIR) is
proposed in the early 1990’s. The typical query
scenario in such image retrieval systems is query by

example (QBE). Its advantage over keyword based
image retrieval lies in the fact that feature extraction
can be performed automatically and the image’s own
content is always consistent. Despite the great deal of
research work, its performance is far from satisfactory
due to the well-known gap between low-level feature
and high-level semantic concepts [3].
To narrow or bridge the gap, a great deal of work
has been performed. From a learning point of view,
these works can be categorized into two major groups:
one is to search for appropriate metrics so that
similarity measured from low-level feature can best
approximates that from high-level semantics; the other
is to incorporate high-level semantic information to
learn better representation of images as well as the
query concept.
To pursue an optimal similarity metric for low-level
feature, many distance functions have been used,
including perceptual distance function (DPF) [8], Earth
Mover’s Distance (EMD) [10], Manhattan ( L1 )
distance, Euclidean ( L2 ) [7], etc. However, these
metrics are based on pair-wise distance calculation and
might oversimplify the relationship among all the
images in the database.
In terms of high-level semantic information
incorporation, it makes use of the additional high-level
semantic information provided by users to improve the
performance of retrieval systems. According to the
source of such information and corresponding learning
technology, it can be categorized into online short-term
learning and offline long-term learning.
The semantic information for on line learning
comes from relevance feedback.
State-of-the-art
learning techniques can be classified into inductive and
transductive ones according to whether unlabeled data
is utilized in the training stage or not [3]. The goal of

*This work was performed at Microsoft Research Asia.
†
The first two authors contribute equally to this paper.

Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)
1063-6919/05 $20.00 © 2005 IEEE

an inductive method is to create a classifier which
separates the relevant and irrelevant images and
generalizes well on unseen examples. One of the most
effective inductive learning techniques is support
vector machines (SVM) [16]. However, one major
problem with inductive methods is the insufficiency of
labeled examples, which might bring great degradation
to the performance of the trained classifier. On the
other hand, transductive methods aim to accurately
predict the relevance of unlabeled images which are
attainable during the training stage. A representative
work belonging to this category is D-EM [15].
However, if the components of data distribution are
mixed up, which is often the case in CBIR, the
performance of D-EM will be compromised [15].
Despite the immaturity of transductive methods, we
see with them great potential since they provide a way
to solve the small sample size problem.
In contrast to online learning, fewer efforts have
resolved offline learning issues. In both QBE and
QBK, the semantic information accumulated in the log
can be used for offline learning. Moreover, the initial
manual annotation stage in QBK might also provide
such information. The learning technology differs
according to the specific query scenario.
For QBE, He et al proposed in [4] using singular
value decomposition (SVD) method to infer a hidden
semantic space from the log. They also proposed an
online learning strategy based on SVM. However, in
their method, the information from low-level feature is
ignored. Therefore, the performance might be largely
degraded, especially when the log data is limited.
For QBK, a representative work is based on
classification [1]. Jing et al in [6] further extended this
work by introducing labeling vector to online collect
training samples and offline update the keyword
models. However, the ratio of initial manually labeled
images is relatively high to achieve a satisfactory result
(ten percent in their experiments), which is still a
heavy burden especially when the database is large.
On the other hand, Jing et al also proposed combining
online learning to refine the retrieval result. However,
the combination scheme is somewhat heuristic.
Moreover, their method will not work if only positive
examples are provided in relevance feedback.
To deal with the limitations of existing methods in
terms of similarity measurement and online learning,
we applied a recently developed manifold ranking
algorithm for the scenario of QBE in [3]. The
proposed method evaluates the relevance between two
images by exploring the relationship of all the data
points in the low-level feature space. It also provides a
natural way to perform online learning in a
transductive
manner.
Experimental
results
demonstrated that it outperforms existing methods by a

large margin. However, its application in QBK as well
as incorporation with offline learning is not
investigated.
In order to address all the drawbacks mentioned
above in image retrieval, in this paper, we propose an
optimization based learning method to integrate
similarity measurement, online learning and offline
learning in a unified manner. Different from most of
previous work which is based on vector model, the
proposed method is based on graph model, that is, the
information from various aspects is firstly expressed as
the relevance between two images or between an
image and the query concept. Then, image retrieval is
formulated as a regularized optimization problem
which simultaneously considers the constraints from
low-level feature, online feedback and offline
information. Finally, the global optimal solution is
developed in both closed form and iterative form,
providing that the latter converges to the former. The
proposed learning method is unified in the senses that
1) it makes use of the information from all aspects in a
global optimization manner so that the retrieval
performance might be maximally improved; 2) it
provides a natural way to support both QBE and QBK.
The main contribution of this paper can be
summarized as follows:
1. An optimization based learning method is
proposed. It unifies low-level feature and highlevel semantic concept learning in a global
optimization manner. It supports both QBE and
QBK.
2. Significant improvement in image retrieval
performance is achieved.
The organization of the paper is as follows: the
proposed optimization based learning method is
presented in Section 2, we address the implementation
details in Section 3; systematic experimental results are
provided in Section 4; finally, we conclude in Section
5.

2. Optimization based learning method
2.1. Notation
Suppose we have totally n image in the database:
denotes the query.
The
proposed method is based on graph model, that is, the
information from low-level feature and high-level
semantics is denoted as the relevance between two
images or between an image and the query concept:
Let W low = (Wilow
, j , i , j = 1,2," , n ) be an n × n affinity
{I i , i = 1,2," , n} and q

matrix constructed from low-level feature, where Wilow
,j
denotes the relevance between I i and I j measured

Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)
1063-6919/05 $20.00 © 2005 IEEE

Normalize W low by
S low = ( D low ) −1 2 W low ( D low ) −1 2 , where D low is the
diagonal matrix with ( i, i ) -element equal to the sum of

from

low-level

feature.

the ith row of W low ;
Let W off , D off , and S off be defined similarly as
above, except that they are constructed from offline
high-level semantics;
Let y on = [ yion , i = 1,2,", n ]T be an n × 1 vector,
yion

where
denotes the relevance between I i and q
measured from online relevance feedback;
Let f = [ f i , i = 1,2,", n ]T be an n × 1 ranking vector,
where fi denotes the total relevance between I i and
q measured simultaneously from low-leve feature,
offline high-level semantics and online relevance
feedback.

2.2. Optimization problem formulation

To maximally make use of S low , S off and y on to
improve retrieval performance, a ‘good’ ranking vector
should be as consistent as possible with these
information, that is to say, if two images are measured
as relevant by S low or S off , they should receive similar
ranking scores in f and vice versa. On the other hand,
if an image is marked as highly relevant with the query
by y on , it should receive a high ranking score in f
and vice versa. We consider all these constraints in the
a regularized optimization framework by defining the
following cost function with f :

¦

n

¦

η Wioff
,j
i , j =1

Dioff
,i

(3)

f

2.3. Optimization problem solving
Differentiating Q ( f ) with respect to f leads to the
following optimal ranking score f * in closed form:
f * = (1 − µ − η )( I − µ S low − η S off ) −1 ⋅ y on

(4)

*

Although the closed form for f is achieved, in
some practical cases, the iterative form might be more
preferable. We also develop an iterative solution for
solving the optimization problem defined in Eq.2 and
Eq.3:
f (t + 1) = µ S low f (t ) + η S off f (t ) + (1 − µ − η ) y on
(5)
on
The relationship between the above two versions of
optimal solutions can be given as1:
f * = lim f (t )
t →∞

(6)

3. Image retrieval process: implementation
details
To apply the proposed method to image retrieval,
there are two graphs (one from low-level feature W low ;
and the other from offline high-level semantic
information W off ) and one vector y on from online
semantic information. Once constructed, W low is fixed;
while W off and y on are updated according to the
additional semantic information obtained offline and
online, respectively. We should also determine the
regularized parameters in Eq.2.

2

1
Dilow
,i

⋅ fi −

1
D low
j, j

⋅ fj

2

1

f * = arg min Q ( f )

where f (0) = y

With the above notation, the learning task is to infer
the ranking vector f from W low , W off and y on as
Eq.1. Once f is obtained, it can be used to rank all
the images in the database (largest ranked first).
{(W low , D low , S low ); (W off , D off , S off ); y on } → f
(1)

­ n
°
Q( f ) = ®µ
Wilow
,j
° i , j =1
¯

With the above optimization criterion, the optimal
ranking vector f * is achieved when Q ( f ) is
minimized:

⋅ fi −

1
D off
j, j

⋅ fj

n

+ε

¦
i =1

3.1. Graph construction and update

+
½
2°
fi − y on
¾
i
°
¿

(2)

The first, second and third items on the right hand
of Eq.2 correspond to the constraints from S low , S off
and y on , respectively. The trade-off among these
constraints is captured by the regularization parameters
µ , η and ε , where 0 < µ ,η , ε < 1 and µ + η + ε = 1 .

The construction of W low is similar with that in [3]:
1. Take each image as a vertex; calculate the K
nearest neighbors for each point; and connect two
points with an edge if they are neighbors.
2. Since L1 distance can better approximate the
perceptual difference between two images than
other popular Minkowski distances when using
either color or texture representation or both [3], it
is adopted to define the edge weights in W low :

1
The proof in this subsection is similar with that in [17, 18].
For the limited space, we will not provide details here.

Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)
1063-6919/05 $20.00 © 2005 IEEE

m

(

Wilow
, j = ∏ exp − xil − x jl σ l
l =1

)

(7)

where xil and x jl are the lth dimension of xi and
x j respectively; m is the dimensionality of the

feature space; and σ l is a positive parameter that
reflects the scope of different dimensions; set
Wilow
,i = 0 (i = 1,2," , n ) .
On the other hand, the construction and update of
W
can be performed as follows:
1. Initialize W off as an n × n matrix with Wioff
,j = 0
off

(i, j = 1,2,", n ) ;
2. For every two image I i and I j (i ≠ j ) , if they are

labeled with the same keyword (in the initial
manual annotation stage in QBK) or marked as
relevant simultaneously in the same query session,
off
update Wioff
, j ← Wi , j + 1 .
Note that in the case that there is no log data, or in
QBK, only one image is manually labeled in the initial
manual annotation stage, W off is empty and the
proposed method is simplified into the work in [3].

3.2. yon setup: initial query
In QBE, if the query image is in the database, the
element of y on corresponding to the query image is set
1, while all the other elements are set 0. On the other
hand, if the query image is not in the database, in order
to apply Eq.4 or Eq.5, W low and W off should be firstly
expanded by adding one row and one column
corresponding to the query image. However, it might
be time-consuming. For simplicity, we can only use
low-level feature by L1 distance for the initial retrieval
and all the element of y on is set 0.
In QBK, y on is constructed from the initial manual
annotation stage: if an image is not labeled in this stage,
the corresponding element in y on is set 0. On the
other hand, the labeled images are treated differently: if
the keywords of an image cover the query, it is
considered a relevant image and the corresponding
element in y on is set 1; otherwise, it is considered an
irrelevant one and the corresponding element is set
−γ (0 ≤ γ ≤ 1) . In this way, its influence is suppressed.
The reason can be ascribed to the asymmetry between
relevant and irrelevant images [3]: generally speaking,
relevant images should make more contribution to the
overall ranking score than irrelevant ones. Here the
parameter γ controls the suppression extent: the
smaller γ is; the less impact irrelevant images will

have on the overall ranking score. If γ = 1 , there is no
suppression for irrelevant image; if γ = 0 , the effect of
irrelevant images is ignored.

3.3. yon update: relevance feedback
In relevance feedback, the additional online
semantic information can be used to update y on for
both QBE and QBK: for a positive image, the
corresponding element in y on is set 1; while for a
negative image; the corresponding element is set
−γ (0 ≤ γ ≤ 1) for the same reason as discussed above.
As mentioned in the introduction section, if
negative examples are unavailable or we only consider
the positive examples, the method proposed in [6] will
not work. However, it is not the problem for the
proposed method.
Another important issue in relevance feedback is
how to select unlabeled images for users’ feedback so
that the convergence to the query concept can be
maximally speeded up. In [3], we proposed three
active learning schemes. Namely, 1) to select the most
positive images; 2) to select the most informative
images; and 3) to select the most positive and
inconsistent images. All of these schemes can be
combined into the proposed method. Here, we simply
adopt the first scheme since active learning is not the
main focus of this paper.

3.4. Regularization parameter selection
Since µ + η + ε = 1 , there is actually two
independent parameters needed to be set. Note that in
Eq.4, the final ranking result will not be influenced by
(1 − µ − η ) , therefore it is fixed to be 0.01. Thus, we
only need to determine η ( 0 < η < 0.99 ). η reflects the
trade-off of the constraints between low-level feature
and offline high-level semantic information. Ideally, it
should be adaptively set according to the relative
contribution of W off to the final ranking vector
compared with W low . Currently, it is roughly set
according to the amount of offline data: the more
offline information, the higher η is. We will pursue
the more principled way to determine η in future work.

4. Experimental results
4.1. Experiment design
We have evaluated the performance of the proposed
method using a general-purpose image database
consisting of 5,000 Corel images. The images are

Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)
1063-6919/05 $20.00 © 2005 IEEE

categorized into 50 groups, each having 100 images.
Images belonging to the same group are considered to
be relevant. The precision vs. scope curve is used to
evaluate the performance of various methods.
Low-level feature has an important influence on the
retrieval performance. However, we do not perform
careful feature selection in this paper since what we
want to propose is a general learning method which
can be applied with any kind of feature or feature
combination. In our current implementation, the
features that we use to represent each image include
color histogram [12], color correlogram [5], Tamura
feature [13], and pyramid wavelet texture feature [9].
Besides the regularization parameters discussed in
Section 4, there are four parameters need to be set: K ,
σ l , γ and the iteration steps. The number of iteration
steps is set to be 50 since we observe no improvement
with more iterations.
To determine the other
parameters, a parametric study has been performed and
the final parameters adopted are: K = 100 ; σ l = 0.05
and γ = 0.1 .
Relevance feedback (RF) is simulated as follows.
For a query, 5 iterations of RF are carried out. At each
iteration, the system examines top 5 images.

4.2. Experimental results
For limited space, we only present the result of
QBE in this paper. In this scenario, to generate the log
data, a small portion of the images in the database are
used as queries. In each query session, the system
examines the first top 20 images. After the log is
generated, we use each image in the whole database as
a query, and average the results over the 5,000 queries.
The proposed method is compared with SVD-based
method and ‘SVD+SVM’ [4].
First, the initial retrieval result is evaluated. In
order to perform a systematic evaluation, we vary the
percentage of training data, i.e. images used to generate
the log data, and compare the average precision of top
20 retrieved images (P20) with that by SVD-based
method [4]. The precision vs. the percentage of the
training data curve is shown in Figure 1. From the
figure, it can be seen that the proposed method
outperforms SVD-based method by a large margin.
Then, we fix the percentage of the training data to 5%
and evaluate the effect of simultaneous learning from
W low and W off . To this end, we compare the retrieval
result with that by 1) setting W off empty and using
W low only (LOW); and 2) setting W low empty and
using W off only (OFF). The average precision vs
scope is shown in Figure 2. From the figure, it can be
seen that 1) the proposed method takes the advantage

of both low-level feature and high-level semantic
information so that it achieves a high performance; 2)
even the curve of ‘OFF Only ’ outperforms that of
‘SVD’, indicating that in terms of utilizing the log
data alone, the proposed scheme is more effective.
In relevance feedback, we fix the percentage of
training data to be 5% and evaluate two situations:
both positive and negative examples are available (PN);
only positive examples are considered (OP). The
average precision of top 20 retrieved images (P20) vs.
iteration number is shown in Figure 3. The proposed
method outperforms ‘SVD+SVM’ by a large margin.
The reason might be that, in ‘SVD+SVM’, 1) the lowlevel information is totally ignored; 2) according to [4],
the images which are not in the log will not receive the
hidden semantic feature so that when the amount of the
log is small, there is actually not any high-level
information about many images in the database. On
the other hand, if we compare Figure 1 and Figure 3,
‘SVD+SVM’ actually causes degradation in
performance. Only after the system has accumulated
enough labeled examples, can ‘SVD+SVM’ refine the
retrieval result. This observation is consistent with the
experimental results in [3]. On the other hand, the
proposed method consistently increases the precision
and outperforms ‘SVD+SVM’.

5. Conclusions
In this paper, we have investigated image retrieval
under a regularized optimization framework to make
use of the information from both low-level feature and
high-level semantics in a global optimization manner.
Different from most of the existing methods, the
proposed one is based on graph model in which the
information from various aspects is expressed as the
relevance between two images or between an image
and the query concept. The proposed optimization
criterion as well as optimization objective consider
simultaneously the constraints from low-level feature,
online feedback and offline semantic information. The
global optimal solution is developed in both closed
form and iterative form. Systematic experimental
results demonstrate the effectiveness of the proposed
method.

6. Acknowledgements
This work is supported by the project (60475001) of
the National Natural Science Foundation of China.
The authors would give thanks to Xing Zheng for
valuable discussions.

Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)
1063-6919/05 $20.00 © 2005 IEEE

1
0.9

SVD

0.8

Proposed Method

Precision

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1

5

10

15

20

Percentage of training data (%)

Figure 1. Systematic comparison of P20 under
different size of training data.
0.8
0.7

SVD

LOW+OFF

0.6

LOW Only

OFF Only

0.5
Precision

[1] Chang, E., et al., "CBSA: Content-Based Soft Annotation
for Multimodal Image Retrieval Using Bayes Point
Machines", IEEE Trans on Circuits and Systems for Video
Technology, January 2003, Volume 13, No. 1, pp.26-38.
[2] Chang, S.K. and Hsu, A., "Image Information Systems:
Where do We Go from Here?", IEEE Trans. on Knowledge
and Data Engineering, Oct. 1992, 4(5).
[3] He J., Li M., Zhang H.J., Tong H., and Zhang C.,
"Manifold-Ranking Based Image Retrieval", Proc. ACM
International Multimedia Conference, 2004.
[4] He X., King O., Ma W.Y., Li M., and Zhang H.J.,
"Learning a Sementic Space from User's Relevance
Feedback for Image Retrieval", IEEE Tran. on Circuits and
Systems for Video Technology, January 2003, Vol. 13, No. 1.
[5] Huang, J., et al., "Image Indexing Using Color
Correlograms", Proc. IEEE Conf. on Computer Vision and
Pattern Recognition, 1997, pp. 762-768.
[6] Jing F., Li M., Zhang H.J., and Zhang B., "Keyword
Propagation for Image Retrieval", Proc. IEEE International
Symposium on Circuits and Systems, 2004
[7] Kokare, M., Chatterji, B.N., and Biswas, P.K.,
"Comparison of Similarity Metrics for Texture Image
Retrieval", IEEE Conf. on Convergent Technologies for
Asia-Pacific Region, 2003, vol. 2, pp. 571-575.
[8] Li, B., Chang, E., and Wu, C.T., "DPF-a Perceptual
Distance Function for Image Retrieval", Proc. IEEE Int. Conf.
on Image Processing, 2002, vol. 2, pp. 597-600.
[9] Mallat, S.G., "A Theory for Multiresolution Signal
Decomposition: the Wavelet Representation", IEEE Trans.
on Pattern Analysis and Machine Intelligence, 1989, vol. 11,
pp. 674-693.
[10] Rubner, Y., Tomasi, C., and Guibas, L., "A metric for
distributions with applications to image databases", Proc.
IEEE Int. Conf. on Computer Vision, pp. 59-66, 1998.
[11] Shen, H.T., et al., "Giving meanings to WWW images",
Proc. 4th ACM Int. Conf. on Multimedia, 2000.
[12] Swain, M., and Ballard, D., "Color indexing", Int.
Journal of Computer Vision, 1991, 7(1): 11-32.
[13] Tamura H., Mori S., and Yamawaki T., "Textural
Features Corresponding to Visual Perception", IEEE Trans.
on Systems., Man and Cybernetics, June 1978, 8(6):460-472.
[14] Tamura, H. and Yokoya, N., "Image database systems: a
survey", Pattern Recognition, 1984, Vol. 17, No. 1.
[15] Wu, Y., Tian, Q., and Huang, T., "Discriminant-EM
algorithm with application to image retrieval", Proc. IEEE
Conf. on Computer Vision and Pattern Recognition, vol. 1,
pp. 155-162, 2000.
[16] Zhang, L., Lin, F., and Zhang, B., "Support Vector
Machine learning for image retrieval", Proc. IEEE Int. Conf.
on Image Processing, 2001, vol. 2, pp. 721-724.
[17] Zhou, D., et al., "Learning with local and global
consistency", 18th Annual Conf. on Neural Information
Processing Systems, 2003.

[18] Zhou, D., et al., "Ranking on data manifolds", 18th
Annual Conf. on Neural Information Processing System,
2003.

0.4
0.3
0.2
0.1
0
10

20

30

40

50

60

70

80

90

100

Scope

Figure 2. Evaluation simultaneous learning effect
1
0.9

SVD+SVM

PN

OP

0.8
0.7
Precision

7. References

0.6
0.5
0.4
0.3
0.2
0.1
0
1

2

3

4

Iteration Number

Figure 3. Comparison of relevance feedback

Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)
1063-6919/05 $20.00 © 2005 IEEE

5

2015 IEEE International Conference on Data Mining

Rare Category Detection on Time-Evolving Graphs
Dawei Zhou

Kangyang Wang

Nan Cao

Jingrui He

Arizona State University
davidchouzdw@gmail.com

Arizona State University
wky91916@gmail.com

IBM T.J. Watson Research
nan.cao@gmail.com

Arizona State University
jingrui.he@gmail.com

as daily transactions and real-time online banking activities; in
insider threat detection, the insiders intentionally change their
behavior patterns over time to avoid being caught. For such
applications, straight-forward application of existing RCD
techniques would be very time-consuming by constructing the
models from scratch at each time step. Furthermore, besides
the limited budget on querying the labeling oracle, in these
applications, it is also critical to detect the initial rare examples
as early as possible to avoid further damage.
To address this problem, in this paper, for the ﬁrst time,
we study the problem of incremental RCD. To be speciﬁc, we
ﬁrst propose two incremental algorithms, i.e., SIRD and BIRD,
to detect the initial examples from the minority classes under
different dynamic settings. The key idea is to efﬁciently update
our detection model by local changes instead of reconstructing
it from scratch on the updated data at a new time step, so as to
reduce the time cost of redundant and repeating computations.
Furthermore, we provide a modiﬁed version – BIRD-LI, which
relaxes the requirement of the exact priors with a soft upper
bound for all the minority classes. Finally, we study a unique
problem of query distribution in the dynamic settings, which
distributes allocated labeling budget to different time steps,
and propose ﬁve query distribution strategies.
The rest of our paper is organized as follows. In Section II,
we brieﬂy review the related work on both RCD and timeevolving graph mining. In Section III, we study incremental
RCD and propose three algorithms for addressing different
dynamic settings, i.e., SIRD, BIRD and BIRD-LI. Then, in
Section IV, we introduce the unique problem of query distribution in the dynamic settings, and propose ﬁve strategies
for allocating the labeling budget to different time steps. In
Section V, we demonstrate our models on both synthetic and
real data sets. Finally, we conclude this paper in Section VI.

Abstract—Rare category detection(RCD) is an important topic
in data mining, focusing on identifying the initial examples from
rare classes in imbalanced data sets. This problem becomes more
challenging when the data is presented as time-evolving graphs,
as used in synthetic ID detection and insider threat detection.
Most existing techniques for RCD are designed for static data
sets, thus not suitable for time-evolving RCD applications.
To address this challenge, in this paper, we ﬁrst propose
two incremental RCD algorithms, SIRD and BIRD. They are
built upon existing density-based techniques for RCD, and
incrementally update the detection models, which provide ‘timeﬂexible’ RCD. Furthermore, based on BIRD, we propose a
modiﬁed version named BIRD-LI to deal with the cases where
the exact priors of the minority classes are not available. We
also identify a critical task in RCD named query distribution. It
aims to allocate the limited budget into multiple time steps, such
that the initial examples from the rare classes are detected as
early as possible with the minimum labeling cost. The proposed
incremental RCD algorithms and various query distribution
strategies are evaluated empirically on both synthetic and real
data.
Index Terms—Rare Category Detection, Time-evolving Graph
Mining, Incremental Learning

I. I NTRODUCTION
In the era of big data, tremendous amount of data in a
variety of areas is being generated at an unprecedented speed.
However, it is often the case that, only a small percentage
of the data is of interest to us. For example, in synthetic
ID detection [13], only a very small number of identities are
faked ones generated by mixing the identifying information
from multiple sources. Such identities are created for the sole
purpose of committing ﬁnancial fraud. Another example is
insider threat detection [4], where only a small number of users
in a big organization are malicious insiders, aiming to attack
the organization or its employees via sabotage, espionage, etc.
The small percentage of data of interest to us is called the
minority class, or rare category, since such examples are often
self-similar. Due to their rarity nature and the limited budget on
querying the labeling oracle, who can provide the true label of
any example at a ﬁxed cost, it is difﬁcult to identify examples
from such classes via simple random sampling. To address this
problem, rare category detection has been proposed to identify
the very ﬁrst example from the minority class, by requesting
only a small number of labels from the oracle.
Most, if not all, of existing rare category detection techniques are designed for static data. However, in many realworld applications, the data is evolving over time, so is the
minority classes. For example, in synthetic ID detection, each
identity may keep updating his/her information over time, such
1550-4786/15 $31.00 © 2015 IEEE
DOI 10.1109/ICDM.2015.120

II. R ELATED W ORK
A. Rare Category Detection
Lots of technologies have been developed for the problem
of RCD in the past few years. [12] proposed a mixture
model-based algorithm, which is the ﬁrst attempt in this area.
In [6] [7], the author developed an innovative method to detect rare categories via unsupervised local-density-differential
sampling strategy. [3] presented an active learning scheme via
exploiting the cluster structure in data sets. In [8], RACH was
proposed for rare category characterization by an optimization
framework. More recently, in [11], two prior-free methods
were proposed in order to address the rare category detection
1135

element at ith row and the j th column of matrix M (t) , and
M (t) (:, j) is the j th column of matrix M (t) , etc.

problem without any prior knowledge. In [16], the authors
proposed a framework named MUVIR, which could leverage
multiple existing rare-category-detection methods in the multiview vision. However, few works have been found to address
the dynamic-setting rare category detection. In this paper, we
study the problem of how to efﬁciently and incrementally learn
from time-evolving graph and effectively detect rare categories
over time.

B. Static Rare Category Detection
Static RCD refers to a problem of repeatedly selecting examples to be labeled by oracle until all the minority classes in a
static data set are discovered. One very successful approach for
static RCD is to make use of manifold structure and identify
rare category examples. In [7], authors developed a graphbased RCD method named GRADE. In GRADE algorithm,
they ﬁrst construct a pair-wise similarity matrix W  and its
corresponding diagonal matrix D, whose elements are the row
sum of W  . And then, they calculate the normalized matrix
W as follows:
W = D−1/2 W  D−1/2

B. Time-evolving Graph Mining
In recent years, more and more researches have been conducting on time-evolving graph mining. For example, in [10],
the authors analyzed the properties of the time evolution
of real graphs and proposed a forest ﬁre graph-generative
model; [2] studied the problem of community evolution
and developed a novel method to measure the movement of
individuals among communities; in [15], authors proposed a
fast proximity tracking method for dynamic graphs; in [9], the
authors focused on the difﬁculties of conversation dynamics
and proposed a simple mathematical model in order to generate basic conversation structures; in [5], the authors proposed a
new graph-pattern matching algorithm, which can avoid cubictime computation; [1] raised a divide-and-conquer framework,
which could ﬁnd the k-nearest-neighbors efﬁciently on large
time-evolving graphs; in [14], the authors launched a fast
algorithm which could detect the node relationships for localizing anomalous changes in time-evolving graphs. In this
paper, we propose several fast-updating RCD methods which
could incrementally update the models based on local changes
on time-evolving graphs. The correctness of our algorithms is
demonstrated by both theoretical proof and experiments.

Based on the normalized pair-wise similarity matrix W , they
construct a global similarity matrix A by applying random
walk with restart (RWR), which is shown as follows:
A = (In×n − αW )−1
By constructing the global similarity matrix, the changes of
local density would become sharper near the boundary of
the minority classes. Based on this intuition, GRADE could
identify minority classes with much less queries than random
sampling. However, the time complexity of calculating the
global similarity matrix and ﬁnding each example’s (K)th
nearest neighbor is O(n3 + K · n2 ), which is not efﬁcient
enough for time-evolving RCD applications.
C. Dynamic Rare Category Detection
In this subsection, we introduce two fast-updating incremental RCD algorithms (SIRD and BIRD) for dealing with the
RCD problem on time-evolving graphs. These two methods
greatly reduce the computation cost for both updating global
similarity matrix and ﬁnding each example’s K th nearest
neighbor. To specify this problem, we have the following
assumptions: (i) the number of examples is ﬁxed, and only
edges change over time; (ii) dataset is imbalanced; (iii)
minority classes are not separable from the majority classes.
1) Single Update: We ﬁrst consider the simplest case: only
one self-loop edge (a, a) changes at time step t. In other
words, there is only one non-zero element (a, a) in S (t) .
To address this problem, we ﬁrst introduce Theorem 1 to
update the global similarity matrix A(t) more efﬁciently. Due
to page limitation, all proofs in this paper are omitted.

III. I NCREMENTAL R ARE C ATEGORY D ETECTION
In this section, we introduce the proposed framework for
time-evolving rare category detection.
A. Notation
Time-evolving Graphs

S(1)

+ΔS
+Δ
ΔS(2)

S(2)

+ΔS
+Δ
ΔS(3)

...

.
...

+ΔS
ΔS((T)
S(T-1) +Δ

S(T)

Normalization
M(1)

M(2)

…

1

2

…

M

(T-1)

T-1

M(T)
T

Fig. 1: Time-evolving Graphs
Suppose we are given n unlabeled examples {x1 , · · · , xn },
and observe m(t) updated edges at time step t. We assume
(t)
yi = 1 corresponds to the majority class with prior p1 , and
(t)
the remaining classes are the minority classes with prior pc .
We use capital S (t) to represent the aggregated adjacency
matrix and ΔS (t) to denote the new edges and updated
weights that appear at time step t. Speciﬁcally, we have
ΔS (t) = S (t) −S (t−1) . We use M (t) to denote the normalized
aggregated adjacency matrix, which is calculated from S (t) .
In the following part of this paper, we use the convention
in Matlab to represent matrix elements, e.g., M (t) (i, j) is the

Theorem 1. The global similarity matrix A(t) at time step t
can be exactly updated from global similarity matrix A(t−1)
at last time step t − 1 by the following equation:
A(t) = A(t−1) + α

A(t−1) uv T A(t−1)
I + v T A(t−1) u

where u and v T are the two vectors decomposed from updating
matrix δM (t)
In our methods, we use an approximate method to calculate
two column vectors u and v. The details are described as
follows. We ﬁrstly assume that the updated edges at time step

1136

t have little impact on the row sum of adjacency matrix M t
when the number of updated edges are extremely smaller than
total number of edges. Thus, we have

The ﬁrst K (t) elements in N N (t) (i, :) are the same as
N N (t−1) (i, :), if it satisﬁes the condition that
α
≤ min {Ti }
i=1,...,m
I + V T A(t−1) U

D(t) ∼
= D(t−1)

where Ti = min{

To normalize S (t) and S (t−1) , we have:
M (t) = (D(t) )−1/2 S (t) (D(t) )−1/2
M

(t−1)

= (D

(t) −1/2

)

S

(t−1)

(D

(t−1) −1/2

)

(1)

(t)

T

,

A

(t−1)
δi
(t−1)
φ ai
i,bi

}.

(t)

Input: M (1) , A(1) , ΔS (2) , . . . , ΔS (T ) , pc , α.
Output: The set I of labeled examples
1: Construct the n × n diagonal matrix D, where Dii =
n
(1)
, i = 1, . . . , n.
(j=1) S
2: Sort row i of A(1) and saved into N N (1) (i, :), where i =
1, . . . , n.
3: for t=2:T do
(t)
4:
Let K (t) = maxC
c=2 n × pc .
5:
Let column vector u = D(:, a)−1/2 and column vector
v = ΔS (t) (a, a)D(:, a)−1/2 , where ΔS (t) (a, a) is the
non-zeros element in ΔS (t) .
6:
Update the global similarity matrix as follows:

(3)
−1/2

As ΔM = uv , we could easily assign u = D(:, a)
and v = ΔS (t) (a, b)D(:, b)−1/2 .
Besides, as the time complexity of constructing a new
neighbor information matrix N N (t) is O(K (t) · n2 ). We
introduce the Theorem 2 to efﬁciently update N N (t) .
Theorem 2. Suppose there is only one self loop edge (a, a)
being updated at time step t. If it satisﬁes the condition that
(t−1)
δi
α
≤ (t−1)
, the ﬁrst K (t) elements in N N (t) (i, :)
I+v T A(t−1) u
Ai,a

(t−1)
δi
(t−1)
φbi
i,ai

Algorithm 1 SIRD Algorithm

(2)

Let Eq. 1  Eq. 2, we have
ΔM (t) = (D(t−1) )−1/2 ΔS (t) (D(t−1) )−1/2

A

φa

A(t) = A(t−1) + α

are the same as N N (t−1) (i, :).
The single-update incremental RCD algorithm (SIRD) is
shown in Algorithm 1. In Step 1 to Step2, we ﬁrstly initialize the diagonal matrix D and neighbor information matrix
N N (1) at time step 1. In Step 4, let K (t) represents the number
of examples in the largest minority class at time step t. Then,
from Step 5 to Step 6, we update the global similarity matrix
at each time step. Step 7 to Step 9 updates the rows in N N (t) ,
of which the K (t) largest elements are changed. Step 11 to
20 is the query process. First of all, we calculates the class
speciﬁc ac in Step 13, which is the largest global similarity
(th)
to the kc nearest neighbor. Then, in Step 14, we count the
number of its neighbors whose global similarity larger than or
equal to ac , and let nci denote the counts for each example xi .
In Step 16, we calculate the score of each example xi , which
represents the change of local density. At last, we select the
examples with the largest score and let them be labeled by
oracle. The query process only terminates as long as all the
minority classes are discovered.
The efﬁciency of the updating process for Algorithm 1 is
given by the following lemma.

7:
8:

9:
10:
11:
12:
13:
14:
15:
16:

17:
18:

Lemma 1. The computational cost of updating process at each
time step in Algorithm 1 is O(n2 + l · K (t) · n).

19:
20:

2) Batch Update: In most real world applications, we may
always observe that a batch of edges change at the same
period. Speciﬁcally, the updated aggregated adjacency matrix
ΔM (t) may have more than one non-zero elements. Hence,
ΔM (t) can not be decomposed into two column vectors, and
Theorem 2 could not be applied in this condition. In this part,
we introduce Theorem 3 to helps us to update the neighbor
information matrix N N (t) when batch of edges are changed.

A(t−1) uv T A(t−1)
I + v T A(t−1) u

for i=1:n do
Based on Theorem 2, identify whether the ﬁrst K (t)
elements of N N (t) (i,:) is changed. If true, update
the ﬁrst K (t) element in N N (t) (i, :); otherwise, let
N N (t) (i, :) = N N (t−1) (i, :).
end for
end for
for c = 2:C do
(T )
Let kc = n × pc
Find the ﬁrst kc element in each row of N N (T ) . Set ac
to be the largest value of them.
Let KN N c (xi , ac ) = {x|N N (T ) (i, j) > ac }, and
nci = |KN N c |, where i = 1, . . . , n and j = 1, . . . , n.
for index = 1: n do
For each nodes xi has been labeled yi , if
A(T ) > ayi , scorej = −∞; else, let scorei =
maxA(T ) (i,j)> ac (nci − ncj )
index
Select the examples x with largest score to oracle.
If the label of x is exact class c, break; else, mark
the class that x belongs to as discovered
end for
end for

The Batch-update Incremental Rare Category Detection
(BIRD) is shown in Algorithm 2. Step 1 and Step 2 are the
initialization process. Step 3 to 12 updates the global similarity
matrix A(t) and neighbor information matrix N N (t) . Different
from Algorithm 1, Step 5 to Step 8 iteratively updates the
global similarity matrix A(t) based on m(t) changed edges.
Another difference is that, in Step 10, T is the minimum value
of the thresholds calculated from m(t) updated edges. At last,
Step 13 to Step 20 is the query process, which is the same as
what we have described in Algorithm 1.

Theorem
3. Suppose
there
are
m
edges
{(a1 , b1 ), · · · , (am , bm )} being updated at time step t.

1137

and select the examples with the largest overall score to be
labeled by oracle. BIRD-LI only terminates the loop until all
the classes are discovered.

The efﬁciency of batch-edges updating in Algorithm 2 is
proved by the following lemma.
Lemma 2. In Algorithm 2, the computational cost of the
updating process at each time step is O(m(t) n2 + l · K (t) · n).

IV. Q UERY DYNAMICS
A. Query Locating
First of all, we introduce the query locating problem. In real
world applications, it could be the case that we are given a
series of unlabeled time-evolving graphs S (1) , S (2) , . . . , S (T ) ,
and we need to select an optimal time step Topt for identifying
minority class.
Before talking about our methods, let us introduce the two
main factors that affect the required number of queries in rare
category detection. The ﬁrst factor is P (y = 2|xi ), which is
the probability that example xi belongs to minority class given
the features of xi . Many works have already studied it before,
such as MUVIR [16], GRADE [7] and NNDM [6]. Another
factor is the density Di of xi . Because when the proportions
of minority classes are ﬁxed, the density of minority classes
located area would directly impact the hardness of RCD.
When the density of neighborhood is higher, it means we
need identify rare category examples from a larger set of
candidates. Considering the second factor, we introduce the
following theorem to estimate density Di based on the global
similarity matrix constructed before.

Algorithm 2 BIRD Algorithm
(t)

Input: M (1) , A(1) , ΔS (2) , . . . , ΔS (T ) , pc , α.
Output: The set I of labeled examples
1: Construct the n × n diagonal matrix D, where Dii =
n
(1)
, i = 1, . . . , n.
(j=1) S
2: Sort row i of A(1) and saved into N N (1) (i, :), where i =
1, . . . , n.
3: for t=2:T do
(t)
4:
Let K (t) = maxC
l=c n × pc .
(t)
5:
for m = 1: m do
6:
Let column vector u = D(:, am )−1/2 and column vector v = ΔS (t) (am , bm )D(:, bm )−1/2 , where
ΔS (t) (a, a) is the non-zeros element in ΔS (t) .
7:
Update the global similarity matrix as follows:
A(t) = A(t−1) + α
8:
9:
10:

11:
12:
13:
14:
15:
16:

17:
18:
19:
20:

A(t−1) uv T A(t−1)
I + v T A(t−1) u

end for
for i=1:n do
Based on Theorem 3, identify whether the ﬁrst
K (t) elements of N N (t) (i,:) is changed. If true,
update the K (t) element in N N (t) (i, :); otherwise,
let N N (t) (i, :) = N N (t−1) (i, :).
end for
end for
while not all the classes have been discovered do
Calculate ni for each examples, where i = 1, . . . , n.
for index = 1: n do
For each nodes xi has been labeled yi , if
A(T ) > a, scorej = −∞; else, let scorei =
a
(ni − nj )
maxA(T ) (i,j)> index
Select the examples x with largest score to labeling
oracle.
mark the class that x belongs to as discovered.
end for
end while

Theorem 4. For each example xi , the density of xi is positive
(t)
(t)
(t)
correlated with Di , where Di = Σnj=1 Ai,j , i = 1, · · · , n.
(t)

We let score(t) = P (y = 2|xi ), which could be obtained
using existing techniques such as MUVIR [16] or GRADE [7].
Under this circumstance, we propose to assign the hardness
of identifying minority class at time step t as follows:


(t) −1
scorei
(t)
I = kc max
(4)
(t)
i=1,...,kc
Di
where kc is the number of examples in minority class c.
Let RS (t) denote the number of required queries by ran(1)
(T )
dom sampling at time step t. And, Let C = RS −RS
.
T
Intuitively, we could achieve optimal solution Topt , when the
difference between the “exact” saved number of queries and
estimate saved number of queries C ∗ Topt is maximized. The
formulation is shown as follows:

D. BIRD with less information
In many applications, it may be difﬁcult to obtain the
exact priors of all the minority classes. In this subsection,
we introduce BIRD-LI, a modiﬁed version of BIRD, which
requires only an upper bound pt for all the minority classes
existing at time step t. To be speciﬁc, BIRD-LI ﬁrstly calculates N N (1) and diagonal matrix D at the ﬁrst, which is the
same as BIRD. Then, the global similarity matrix A(T ) and the
neighbor information matrix N N (T ) could be updated from
the ﬁrst time step to the time step T . The only difference
between BIRD and BIRD-LI is the size of minority class K (t)
is calculated based on an estimated upper bound prior instead
of the exact ones for all minority classes. After the updating
process, it calculates an overall score for the minority classes

max

t=1,...,T

I (1) − I (t)
· (RS (1) − RS (T ) ) − C · t
I (1) − I (T )

(5)

B. Query Distribution
In this subsection, we will talk about a more general
problem: Query Distribution. In real world applications, it
could be the case that the updated graphs come as streams, and
we need to allocate our query budget into multiple incoming
time steps. So, is there a method to allocate the queries
properly into different time steps, and enable us to ﬁnd the
minority class examples with both minimum query budget and
minimum time budget?
To further study the query dynamic problem, we propose
5 potential strategies for the query distribution problem: S1

1138

Allocate all the budget at the ﬁrst time step; S2 Allocate all the
budget at the last time step; S3 Allocate all the budget at time
step Topt ; S4 Allocate the query budget evenly into different
time steps; S5 Allocate the query budget into different time
steps following exponential distribution, such as e−αt .
For query distribution problem, we propose Algorithm 3.
Different from the query process of Algorithm 2, in Step 3,
we need to apply a strategy to calculate the certain budget
B (t) for time step t. If we have not found the minority class
within B (t) at time step t, then we go to the next time step.
The overall algorithm stops either when minority classes are
discovered or there is no budget to use.
We compare the performance of these ﬁve strategies with
both synthetic data set and real data set in Section V.

40

250
200

100

1

2

3

4

5

6

0

7

1

2

3

(a) Synthetic Data

5

6

7

(b) Abalone
4500

120

RS
BIRD-LI
BIRD
GRADE

100

80

RS
BIRD-LI
BIRD
GRADE

4000
3500
3000

Queries

Queries

4

Time Step

Time Step

60

40

2500
2000
1500
1000

20

500

1

2

3

4

5

6

7

Time Step

0

1

2

3

4

5

6

7

Time Step

(c) Adult

(d) Statlog

Fig. 2: Effectiveness
is really difﬁcult to ﬁnd proper real datasets satisfying the
scenario setting of both rare category detection and timeevolving graphs. In this case, we ﬁnd 3 real datasets which
meet the scenario of rare category detection. The details of
these 3 real datasets are summarized in Table 1. And then, we
generate additional 6 time-evolving graphs in the latter time
steps. For these time-evolving graphs, we let the proportion of
one certain minority class increase by 1% and simultaneously
let the proportion of the majority class decrease by 1% in
each time step. Fig. 2(a) shows the comparison results of 4
different methods: random sampling(RS), BIRD, BIRD-LI and
GRADE. Notice that BIRD and BIRD-LI perform the query
process upon the approximate aggregated adjacency matrix,
while GRADE is performed on the exact adjacency matrix
at each time step. Besides, we input BIRD-LI with a much
looser prior upper bound, e.g., we input 5% as the upper bound
instead of using the exact prior of 1%. And then, we perform
the same comparison experiments on 3 real data sets, which
is shown in Fig. 2(b), Fig. 2(c) and Fig. 2(d). In general, we
have the following observations: (i) both BIRD and BIRDLi outperform random sampling in any conditions; (ii) all of
these 4 methods perform better when prior of minority class
is getting larger; (iii) BIRD gives a comparable performance
as GRADE; (iv) BIRD-LI is quite robust and requires only a
few more queries than BIRD in most cases.

V. E XPERIMENTS

Largest-Class
56.93%
1.30%
79.16%

300

50

0

A. Effectiveness
m
5
2
6

350

150

Input: S,M (1) ,A(1) ,N N (1) ,ΔS (2) , . . . , ΔS (T ) ,p(t) ,α.
Output: The set I of labeled examples and the L of their
labels
1: for t = 1:T do
(t)
2:
Let K (t) = maxC
l=c n × pl .
(t)
3:
Calculate B as Given Strategy S.
4:
Calculate N N (t) as described in Algorithm 2.
5:
while not all the classes have been discovered do
6:
Find the (K (t) )th element in each row of N N (t) . Set
ac to be the largest value of them.
7:
Let KN N c (xi , ac ) = {x|N N (T ) (i, j) > ac }, and
nci = |KN N c |, where i = 1, . . . , n and j = 1, . . . , n.
8:
for index = 1: B (t) do
9:
For each nodes xi has been labeled yi , if
A(T ) > ayi , scorej = −∞; else, let scorei =
maxA(T ) (i,j)> ac (nci − ncj )
index
10:
Select the examples x with largest score to labeling
oracle.
11:
If the label of x is exact class c, break; else, mark
the class that x belongs to as discovered
12:
end for
13:
end while
14:
If all the minority classes are discovered, break.
15: end for

d
8
14
9

RS
BIRD-LI
BIRD
GRADE

400

Queries

Queries

60

20

Algorithm 3 Query Distribution Algorithm

n
4177
48842
58000

RS
BIRD-LI
BIRD
GRADE

80

0

Name
Abalone
Adult
Statlog

450

100

B. Efﬁciency of Batch Update

Smallest-Class
0.41%
98.70%
0.04%

For both BIRD and GRADE, the most time consuming step
is updating the global similarity matrix A(t) and neighbor information matrix N N (t) in each time step. In this subsection,
we report the running time of updating A(t) and N N (t) from
an initial time step to the second time step. To better visualize
the performance, we run the experiment on an increasing size
of graph, i.e., from 500 examples in graph to 1000 examples
in graph. And for each certain size, we have 100 identicalsetting datasets. Each point in Fig. 3 is computed based on
the average value of the 100 datasets in identical settings. As

TABLE I: Real Datasets
First of all, we demonstrate the effectiveness upon 1000
synthetic datasets and 3 real data sets. For the synthetic
datasets, we generate 1000 synthetic datasets, and each of
them contains 5000 examples, two classes. And, we initialize
the priors of the minority classes as 1% and increase these
priors by 1% in each time step. For the real datasets, it

1139

we talked before, the computation cost of GRADE is O(n3 ),
and our method only costs O(n2 ). From Fig. 3, we can see
the difference of running time is largely increasing over time.
The difference is limited when the number of examples is
500. However, when the size of graph goes to 10000, the
running time of BIRD is 6.227 seconds, while the running
time of GRADE is 41.41 seconds, which is 7 times of BIRD.
Moreover, the difference will be extraordinarily enlarged again
when we run algorithms on a series of time steps. We ran the
experiments with Matlab 2014a on a workstation with CPU
3.5 GHz 4 processors, 256 GB memory and 2 T disk space.

VI. C ONCLUSION AND F UTURE W ORK
In this paper, we mainly focus on the problem of how to
efﬁciently and incrementally identify under-represented rare
category examples from time-evolving graphs. To the best
of our knowledge, we are the ﬁrst attempt on RCD under
these dynamic settings. The major contribution of this paper
could be summarized as follows: (1)A novel problem setting
of rare category detection on time-evolving graphs; (2)Two
fast incremental RCD algorithms in dynamic settings, i.e.,
SIRD and BIRD, and the analysis regarding their efﬁciency
and effectiveness; (3)Fast update algorithm BIRD-LI for the
cases where the exact priors of minority classes are unknown;
(4)Preliminary study on query distribution, which is unique
in the dynamic settings; (5)Extensive experiments on both
synthetic and real data sets. In our future works, we will
continue studying RCD under dynamic settings, especially
the problem of query distribution. A very interesting and
challenging research direction is how to allocate optimal query
budget and detect rare categories in real time settings.

45

Exact Update (GRADE)
Fast-Batch-Update (BIRD)

40

Runing Time

35
30
25
20
15
10
5
0

1000

2000

3000

4000

5000

6000

7000

8000

9000

10000

# of Example in Grapha

Fig. 3: Efﬁciency

R EFERENCES

80

50

150

60

45

100

50

0
0

Queries

200

Queries

Queries

C. Query Dynamics
In this subsection, we perform the results of query locating
and query distribution. In Fig. 4, we apply the query locating
methods on 3 real datasets. As the proportion is increasing over
time, the labeling request is decreasing in general. Besides, we
also observe that Topt is always located at left bottom of each
graph, which meets our ALAP and AEAP intuitions.

40

4

6

0
0

8

Time Step

40

35

20

2

[1] L. Akoglu, R. Khandekar, V. Kumar, S. Parthasarathy, D. Rajan,
and K.-L. Wu. Fast nearest neighbor search on large timeevolving graphs. In ECML PKDD. Springer, 2014.
[2] L. Backstrom, D. Huttenlocher, J. Kleinberg, and X. Lan. Group
formation in large social networks: membership, growth, and
evolution. In ACM SIGKDD, 2006.
[3] S. Dasgupta and D. Hsu. Hierarchical sampling for active
learning. In ICML, 2008.
[4] W. Eberle, J. Graves, and L. Holder. Insider threat detection
using a graph-based approach. Journal of Applied Security
Research, 2010.
[5] W. Fan, X. Wang, and Y. Wu. Incremental graph pattern
matching. TODS, 2013.
[6] J. He and J. G. Carbonell. Nearest-neighbor-based active
learning for rare category detection. In NIPS, 2007.
[7] J. He, Y. Liu, and R. Lawrence. Graph-based rare category
detection. In ICDM, 2008.
[8] J. He, H. Tong, and J. Carbonell. Rare category characterization.
In ICDM, 2010.
[9] R. Kumar, M. Mahdian, and M. McGlohon. Dynamics of
conversations. In ACM SIGKDD, 2010.
[10] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graphs over time:
densiﬁcation laws, shrinking diameters and possible explanations. In ACM SIGKDD, 2005.
[11] Z. Liu, K. Chiew, Q. He, H. Huang, and B. Huang. Prior-free
rare category detection: More effective and efﬁcient solutions.
Expert Systems with Applications, 2014.
[12] D. Pelleg and A. W. Moore. Active learning for anomaly and
rare-category detection. In NIPS, 2004.
[13] C. Phua, V. Lee, K. Smith, and R. Gayler. A comprehensive
survey of data mining-based fraud detection research. ICICTA,
2010.
[14] K. Sricharan and K. Das. Localizing anomalous changes in
time-evolving graphs. In ACM SIGMOD, 2014.
[15] H. Tong, S. Papadimitriou, S. Y. Philip, and C. Faloutsos.
Proximity tracking on time-evolving bipartite graphs. In SIAM
SDM, 2008.
[16] D. Zhou, J. He, K. Candan, and H. Davulcu. Multi-view rare
category detection. In IJCAI, 2015.

2

4

6

30
0

8

2

(a) Abalone

4

6

8

Time Step

Time Step

(b) Adult

(c) Statlog

Fig. 4: Query Locating
Furthermore, by applying Algorithm 3, we perform the
results of 5 different strategies on one binary-class synthetic
dataset and one binary-class real dataset, i.e. Adult. In both
Fig. 5(a) and F.g 5(b), we observe that Strategy S1 is always
located at the left top of the ﬁgure, which hold the time
optimal; Strategy S2 is always located at the right bottom
of the ﬁgure, which hold the budget optimal; Strategy S3 is
always located at the left bottom of the ﬁgure, which leverage
both the time and budget factor. All of these 3 observations
meet our intuitions.
80

40
S1
S2
S3
S4
S5

S1
S2
S3
S4
S5

30

Queries

Queries

60

40

20

20

10

0
0

2

4

6

Time Step

(a) Synthetic Dataset

8

0
0

2

4

6

8

Time Step

(b) Real Dataset(Adult)

Fig. 5: Query Distribution

1140

Learning No-Reference Quality Metric by Examples*
Hanghang Tong1, Mingjing Li2, Hong-Jiang Zhang2, Changshui Zhang3, Jingrui He1, Wei-Ying Ma2
1, 3

Department of Automation, Tsinghua University, Beijing 100084, China
2
Microsoft Research Asia, 49 Zhichun Road, Beijing 100080, China
1
{walkstar98, hejingrui98}@mails.tsinghua.edu.cn, 2{mjli, hjzhang, wyma}@microsoft.com,
3
zcs@tsinghua.edu.cn
Abstract
In this paper, a novel learning based method is
proposed for No-Reference image quality assessment.
Instead of examining the exact prior knowledge for the
given type of distortion and finding a suitable way to
represent it, our method aims to directly get the quality
metric by means of learning. At first, some training
examples are prepared for both high-quality and lowquality classes; then a binary classifier is built on the
training set; finally the quality metric of an un-labeled
example is denoted by the extent to which it belongs to
these two classes. Different schemes to acquire
examples from a given image, to build the binary
classifier and to model the quality metric are proposed
and investigated. While most existing methods are
tailored for some specific distortion type, the proposed
method might provide a general solution for NoReference image quality assessment. Experimental
results on JPEG and JPEG2000 compressed images
validate the effectiveness of the proposed method.

1. Introduction
Image quality assessment aims to automatically
provide an objective measurement for the quality of a
given image which is consistent with the result given by
human observers [2, 12, 16, 18, 20]. With the
prevalence of digital images, automatic image quality
assessment is highly desirable in the following ways
[14, 16, 18]: 1) to monitor and control image quality
for quality control systems; 2) to benchmark image
processing systems; 3) to optimize algorithms and
parameters; 4) to help home users better manage their
digital photos and evaluate their expertise in
photographing.
According to the prior knowledge used in the
assessment, we can categorize existing image quality
*

metrics into three classes [16, 18]: full-reference (FR),
reduce-reference (RR) and no-reference (NR). Both
FR and RR are essentially fidelity assessment since
they need the original un-distorted image as a reference
either fully or partially [14, 16, 18]. However, in many
situations, the original un-distorted image might not
exist or be very hard to obtain [9, 13, 14]. On the other
hand, it is very easy for human observers to assess
image quality without using any reference image. In
recent years, NR image quality assessment has attracted
the attention of more and more researchers [3, 8, 10, 13,
17, 19].
Due to the limited understanding of the human
vision system (HVS), most, if not all, of the existing
NR assessment algorithms focus on distortion
measurement, in which the quality metric is described
by the extent to which the image has probably been
distorted [13, 14]. No matter whether explicitly or
implicitly, the general flow of these algorithms can be
summarized as follows [14]: 1) find some
discriminative local feature; 2) use local feature to
model local distortion metric; 3) average local
distortion metric over the whole image to get a overall
distortion metric Qm ; 4) use Qm to predict image
quality score Ps which is consistent with human
perception.
Finding suitable local feature and
modeling the local distortion metric are two key steps
within the whole algorithm.
Most of existing methods focus on blurring,
blockiness and ringing. For example, the authors in
[17, 19] proposed using blockiness difference and
activity of the image signal as local distortion feature
for blockiness and blurring, and using a nonlinear
combination of them to model the local blurring metric;
the authors in [9, 10] proposed using edge spread as the
local blurring feature which is used directly as the local
distortion metric; the authors in [13] proposed using
wavelet coefficients as the local feature for blurring

This work was performed at Microsoft Research Asia.

Proceedings of the 11th International Multimedia Modelling Conference (MMM’05)
1550-5502/05 $20.00 © 2005 IEEE

and ringing in JPEG2000 compressed images, and the
local distortion metric is simply denoted as
“significant” or “insignificant” by a threshold. The
main drawbacks of the existing methods are [14]: 1)
extracting local distortion feature is quite distortiontype dependent (they need the exact prior knowledge
for the given type of distortion and a suitable way to
represent it); 2) the way they model the local distortion
metric seems to over simplify the relationship between
the local feature and the local distortion metric.
To address the drawbacks of existing NR methods
for JPEG2000 compressed images, by viewing all edge
points as either “distorted” or “un-distorted”, we
proposed in [14] using principal component analysis
(PCA) to extract the local feature of a given edge point,
which indicates both blurring and ringing. We also
proposed using the probabilities of the given edge point
being “distorted” and “un-distorted” to model the local
distortion metric by Bayes rule. However, there are
still some limitations: 1) both the way we select
projection axis and the Gaussian assumption for the
conditional probabilities are somewhat arbitrary; and 2)
the local distortion metric takes the ratio between the
priors of “distorted” and “un-distorted” as a parameter,
which is hard to obtain in practice.
In this paper, we extend our work in [14] and
propose a learning based method to model the quality
metric. In our method, instead of examining the exact
prior knowledge for the given type of distortion and
finding a suitable way to represent it, we aim to directly
get the quality metric by means of learning. The basic
idea of our method is that images of similar quality
should share some common law in their low-level
features and this common law might be learned from a
set of given examples. To achieve this goal, we first
prepare some examples to compose two classes: “high
quality” and “low quality”; then a binary classifier is
built on these two classes so that the two classes will be
separated as far as possible; finally, the quality metric
of an un-labeled example is denoted by the extent to
which it belongs to these two classes. In contrast to the
traditional methods which are tailored for some
specific distortion type, ours might provide a general
solution for NR image quality assessment. Systematic
experiments on JPEG and JPEG2000 compressed
images validate the effectiveness of the proposed
method.
The examples for the training set can be one point
or block within the given image, where the distortion
might occur. To build a binary classifier, we propose
two different schemes: one resorts to boosting to
perform feature selection and classifier training
simultaneously; the other incorporates the label

information into PCA for feature re-extraction and
feature de-correlation; followed by Maximum Marginal
Diversity (MMD) [15] for feature selection and
Bayesian classifier for classification. While the second
scheme is based on our previous work [14] on the
whole, its limitations mentioned above are addressed in
this paper. Furthermore, according to the different
forms of the trained classifiers, we also propose two
schemes to model the quality metric.
The organization of this paper is as follows. Section
2 presents the flowchart of the proposed method. We
address the issues of training set preparation, classifier
building and quality metric modeling in Section 3,
Section 4 and Section 5 respectively. Systematic
experimental results are presented in Section 6. Finally,
we conclude the paper in Section 7.

2. The flowchart of the proposed method
The basic idea of our method is that images of similar
quality should share some common law in their lowlevel features and this common law might be learned
from a set of given examples. The flowchart of the
proposed learning-based method for NR image quality
assessment is summarized in Fig. 1. Its details are
given as follows.

Prepare the Training Set

Build the Binary Classifier

Model the Quality Metric

Predict the Quality Score

Fig. 1. The flowchart of the proposed method
♦ First, we need to prepare some examples E (i ) both
of “high quality” and of “low quality” to compose
the training set, where i = 1,2,, N and N is the
total number of examples. Those “high quality”
examples E + (i ) compose S + (the subset for

Proceedings of the 11th International Multimedia Modelling Conference (MMM’05)
1550-5502/05 $20.00 © 2005 IEEE

positive examples), where i = 1,2,, N + and N + is
the total number of “high quality” examples.
Those “low quality” examples E − (i ) compose S −

(the

subset

for

negative

examples),

where

♦ Next, a binary classifier is built on {F (i ), Y (i )}
(i = 1,2,, N ) , which separates the positive and
negative examples as far as possible, where
Y (i ) = +1 if E (i ) ∈ S + and Y (i ) = −1 otherwise.
♦ Then, the quality metric Qm( j ) for a new example
j can be modeled through its probabilities of
being “positive” and being “negative”:
Qm( j ) = f ( P( S + | F (i )), P( S − | F (i )))
(1)

Opt. 1: detect all edge points of a given image. Every
edge point is viewed as an example E (i ) . For each
edge point E (i ) , assign it to the center of a block and
arrange all the pixels within this block in a vector
which is used as the corresponding initial feature F (i ) .
Let r denote the size of the block and F (i ) is r 2
dimensional.
Opt. 2: divide a given image into small blocks. Every
block is viewed as an example E (i ) . For each block
E (i ) , arrange all the pixels within it in a vector which
is used as the corresponding initial feature F (i ) . Let
r denote the size of the block and F (i ) is r 2
dimensional.

where P ( S + | F (i )) and P ( S − | F (i )) are the
posteriors of the example j being “positive” and
“negative” respectively which can be acquired from
the trained classifier; and f : R 2 → R is some kind
of function which maps the posteriors to a quality
metric. Average Qm( j ) over the whole image I ,
we get an overall distortion metric Qm( I ) for the
given image.
♦ Finally, predict the quality score Ps ( I ) of the
given image so that it will be consistent with the
result given by human observers [9, 10, 14]:
(2)
Ps ( I ) = α + β ⋅ Qm( I )γ

Note that Opt. 1 is designed for blurring and ringing,
while Opt. 2 is mainly designed for blockiness and it
also provides a rough description for blurring and
ringing. Opt. 2 is more efficient than Opt. 1 in terms of
processing time since it does not require edge detection
as a preprocessing step.
Based on the above preparation, the training set can
be set up as follows:
Algorithm 1: Prepare the training set
1. Prepare some original un-distorted images and
their distorted versions. There must be enough
distortion in the distorted image so that every
example in it can be viewed as “low quality”;

i = 1,2,, N − , N − is the total number of “low

quality” examples and N + + N − = N . Here, each
example E (i ) can be one point or block of a given
image and it is denoted as an initial feature vector:
E (i ) → F (i ) (i = 1,2,, N ) .

where α , β and γ are unknown parameters and
can be determined by minimizing the MSE (meansquare-error) between prediction score and mean
human score:
MSE =

1
N aho

N aho

∑ ( Ps( I ) − Mhs( I ))

2

2.

For each image, use Opt. 1 or Opt. 2 to obtain
all examples E (i ) and their corresponding
initial features F (i ) ;

3.

Add E ( i ) to the training set. To be specific, if
E (i ) comes from an original image, add it to

(3)

S + ; else add it to S − .

I =1

where Mhs( I ) is the mean human score of the I th
image; N aho is the number of the images used to
determine the parameters.

3. Prepare the training set
For most existing types of distortion, we can
identify them locally.
For example, blurring is
perceptually apparent around edges; ringing usually
appears near sharp edges [1, 9, 10]; while blockiness
often occurs in JPEG compressed images and is visible
at the boundary of two adjacent blocks (usually 8 × 8 )
used in the compression stage [17, 19]. Based on the
above observation, we propose the following two
operations to acquire examples and form their
corresponding initial features from a given image:

4. Build the binary classifier
It is always a challenge to select a good feature set
for classification. We propose two different schemes
for our task in this paper.

4.1. Boosting based scheme
Recent developments in the field of machine
learning have demonstrated that boosting based
methods may have a satisfactory performance by
combining weak learners [5, 6]. Furthermore, the
boosting procedure can also be viewed as a feature
selection process if the weak learner uses a single
feature in each stage. Benefiting from such cherished

Proceedings of the 11th International Multimedia Modelling Conference (MMM’05)
1550-5502/05 $20.00 © 2005 IEEE

properties, our first scheme is very simple. That is, we
simply use some boosting based method to train on the
initial feature set and in this context, boosting performs
both feature selection and classifier training
simultaneously.

Note that by taking the covariance matrix as Eq. 4.,
we can make use of the label information in PCA to reextract some more discriminative features from the
initial feature vector. Moreover, de-correlation on
different dimensions by PCA also makes the
subsequent feature selection step more reliable.

4.2. Feature re-extraction based scheme
Theoretically, Bayesian classifier can produce the
minimum classification error. However, we can not
directly apply it to our task since the dimensionality of
the initial feature vector is very high, which makes it
very difficult to estimate probability distribution that is
necessary for Bayesian classifier. Therefore, we have
to select a small subset from the initial feature vector,
whose elements are most discriminative.
On the other hand, we find out by experiments that
the discriminative power of each dimension in the
initial feature vector is very weak, which means a small
subset of it might not be adequate for a satisfactory
classification performance.
Based on the above observations, some more
powerful features should be re-extracted and selected
from the initial feature vector. In [14], we have
proposed using PCA to perform feature re-extraction.
However, the way we select the feature (the associated
projection axis) in [14] was somewhat arbitrary. In this
paper, MMD [15] is adopted to perform feature
selection. The detailed scheme is given as follows:
Algorithm 2: Feature re-extraction based scheme
1. Normalize F (i ) (i = 1,2,,( N + + N − )) on each
dimension to [ 0, 1] ;
2.

Calculate covariance matrix ∑ [4, 7]:
∑ = ( N − ⋅ ∑− + N + ⋅ ∑+ )

(N

−

+ N+ )

(4)

where ∑− and ∑+ are covariance
matrix of S − and S + , respectively
3.

Let u j ( j = 1,2,, r 2 )

Perform PCA on ∑ .

5. Model the quality metric
After the binary classifier is built, the quality metric
Qm( j ) for a new example j can be modeled through

its probabilities of being “positive” and being
“negative” as Eq. 1. To be specific, we propose two
schemes according to the different forms of the trained
classifiers. In both cases, the overall quality metric
Qm( I ) for a given image I is obtained by averaging
Qm( j ) over the whole image.

5.1. Quality metric for Boosting
Among the many choices, we favor Real-AdaBoost
[5, 6] here for its relative simplicity and clear physical
meaning: since in Real-AdaBoost, the output of every
weak learner indicates the probability of a given
example j being of “high quality” or being of “low
quality”, by combining the outputs of all the weak
learners obtained in the training stage, we get a
confident coefficient for its quality metric:
T

Qm ( j ) = ∑ ht ( F ( j ) )

where ht (t = 1,2,, T ) denote the t th weak learner of
Real-AdaBoost; T is the total number of weak learners.

5.2. Quality metric for Bayesian classifier
In this case, we get a Bayesian classifier and the
quality metric Qm( j ) can be modeled through its
posterior probabilities:
Q( j) =

denote the j th principle axis;
4.

The

new

feature

set

is

denoted

as

T

F ′ ( i ) =  x1 , x2 ,, xr2  , where x j denotes the

projection of F (i) on u j ;
5.

Use MMD to select the M most
discriminative features Fs' (i) ( s = 1,, M ) ;

6.

Feed Fs' (i) to Bayesian classifier.

(5)

t =1

P( S + | Fs' ( j ))
P( S − | Fs' ( j )) + P( S + | Fs' ( j ))

(6)

where P( S + | Fs' ( j )) and P ( S − | Fs' ( j )) are the posterior
probabilities, respectively.
Using Bayes rule, Eq. 6. can be converted to:
Q( j ) =

P( Fs' (

P( Fs' ( j ) | S + ) ⋅ ratio
j ) | S − ) ⋅ ratio + P( Fs' ( j ) | S + )

where P ( Fs' ( j ) | S − ) and P ( Fs' ( j ) | S + ) are
conditional
probabilities
respectively,
+
−
ratio = P( S ) P( S ) .

Proceedings of the 11th International Multimedia Modelling Conference (MMM’05)
1550-5502/05 $20.00 © 2005 IEEE

(7)
the
and

In [14], ratio is viewed as an additional parameter
and the final quality metric is a function of ratio .
Although we can obtain it by optimizing Eq. 2. together
with α , β and γ theoretically, it is very difficult in
practice. So in this paper, we simply set ratio = N + N − .
Another issue with Eq. 7. is the estimation of the
conditional probabilities. In [14], we simply assume
them as Gaussian distribution, the parameters of which
can be estimated by maximum likelihood (ML) [4, 7].
In this paper, in addition to this simple (and somewhat
arbitrary) strategy, we also propose using multidimensional histogram (MDH) to estimate the
conditional probabilities, since the dimensionality of
Fs' ( j ) is quite low (2 in our experiments).

6. Experimental results
What we try to propose in this paper is a general
solution for NR quality assessment. In this Section, we
will examine the performance of the proposed method
for JPEG and JPEG2000 compressed images.

6.1. Operation and parameter settings
In our experiments, there are two training sets and
one testing set: “training set 1” for training the
classifier, “training set 2” for determining the
parameters ( α , β and γ ) which are necessary to
predict quality scores in Eq. 2., and “testing set” for
examining the performance of the proposed algorithms.
We use the linear correlation value (LCV) and MSE
between the prediction results and mean human score
to evaluate the performance of various methods.
Different schemes to acquire examples from a given
image, to build the binary classifier and to model the
quality metric will be evaluated. Moreover, to estimate
the conditional probabilities for Bayesian classifier,
both ML and MDH will be investigated.
A set of parameters need to be determined:
♦ A larger block size r can provide more
information about the local distortion effect,
however, it also need more processing time. In our
experiment, it is set to 9 for Opt. 1 and 12 for Opt.
2;
♦ Two parameters in Real-AdaBoost (the bin number
nBin and the weak learner number T ) are
determined by cross-validation (5 folds) [4, 7];
♦ The number of selected features in Algorithm 2 M
is set to 2;
♦ In the case that the conditional probabilities are
estimated by MDH, the bin number on each
dimension is 20.

6.2. Assessment results for JPEG images
The image database that we use in this part is from
[11], which consists of 29 original high-resolution 24bits/pixel RGB color images and their JPEG
compressed versions with different compressed ratios.
The total number of the images in the database is 234.
According to [11], about 25 human observers rated
each image as “Bad”, “Poor”, “Fair”, “Good” or
“Excellent”. Mean human scores are acquired after
normalizing the original raw scores and removing
outliers. (For more details of the subjective experiment,
refer to [11, 19].)
In our experiment, the database is randomly divided
into two sets: 15 images together with their compressed
versions compose “training set 2” and 14 images
together with their compressed versions compose
“testing set”. “Training set 1” is set up by 15 original
images from “training set 2” and their compressed
versions with the highest compressed ratio.
The main distortion in JPEG compressed images is
blockiness and blurring [17, 19]. In order to form the
training set, we adopt Opt. 2 to acquire the examples
from a given image for reasons given in Section 3.
LCV and MSE by various methods are listed in
Table 1. In [19], the authors proposed using blockiness
difference and activity of the image signal as local
distortion feature for blockiness and blurring, and using
a nonlinear combination of them to model the local
blurring metric. The result obtained by their algorithm
on the same testing set is also shown in Table 1 for
comparison. It can be seen that all the results by our
methods are comparable with those by [19]. For RealAdaBoost, it even outperforms those by [19]. While
the algorithm in [19] is based on the exact prior
knowledge about what blockiness and blurring are and
how to describe them, such knowledge is not required
in our methods.
Table 1. Assessment results for JPEG images
Result
LCV
MSE
Method
Real-AdaBoost
Bayesian

92.3%

9.1

ML

86.4%

12.4

MDH

88.0%

11.5

90.1

9.8

Algorithm in [19]

The prediction result using Real-AdaBoost versus
mean human score on “testing set” is shown in Fig. 2.
An example of applying Real-AdaBoost to assess the
quality of JPEG compressed images is shown in Fig. 3.

Proceedings of the 11th International Multimedia Modelling Conference (MMM’05)
1550-5502/05 $20.00 © 2005 IEEE

Table 2. Assessment results for JPEG2000 images
Result
LCV
MSE
Method
Opt.1

Opt.2

Real-AdaBoost

86.3%

11.1

ML

85.0%

11.7

MDH

85.3%

11.4

Real-AdaBoost

85.6%

11.8

ML

81.6%

13.0

MDH

80.6%

13.2

74.0%

15.9

Bayesian

Bayesian

Algorithm in [10]
Fig. 2. Quality prediction versus mean human score for
JPEG compressed images

6.3. Assessment results for JPEG2000 images
The image database that we use in this part is also
from [11], which consists of 29 original high-resolution
24-bits/pixel RGB color images and their JPEG2000
compressed versions with different compressed ratios.
The total number of the images in the database is 227.
The subjective experiment is similar with that of JPEG
compressed images.
In our experiment, the database is randomly divided
into two sets: 14 images together with their compressed
versions compose “training set 2” and 15 images
together with their compressed versions compose
“testing set”. “Training set 1” is set up by 14 original
images from “training set 2” and their compressed
versions with the highest compressed ratio.
The main distortion in JPEG2000 compressed
images is blurring and ringing [1, 9, 10, 13]. In order
to form the training set, we adopt both Opt. 1 and Opt.
2 to acquire the examples from a given image.
LCV and MSE by various methods are listed in
Table 2. In [10], the authors proposed using edge
spread as the local blurring feature which is used
directly as the local distortion metric. The result
obtained by their algorithm on the same testing set is
also shown in Table 2 for comparison. In all cases, our
methods outperform the one in [10] by a large margin.
Comparing the different operations to acquire the
examples, it can be seen that Opt. 1 outperforms Opt. 2.
However, it is worth noticing that in Opt. 2, there is no
edge detection step which is time-consuming so that it
can serve as the fast version of Opt. 1 in this context.

The prediction result using Real-AdaBoost versus
mean human score on “testing set” is shown in Fig. 4.
An example of applying Real-AdaBoost to assess the
quality of JPEG2000 compressed images is shown in
Fig. 5.

(a) By Opt. 1

(b) By Opt. 2

Fig. 4. Quality prediction versus mean human score for
JPEG2000 compressed images

Proceedings of the 11th International Multimedia Modelling Conference (MMM’05)
1550-5502/05 $20.00 © 2005 IEEE

7. Conclusion
In this paper, we have extended our previous work
in [14] and proposed a novel learning method for NR
image quality assessment. In our method, we first
prepare some examples to compose two classes: “high
quality” and “low quality”; then a binary classifier is
trained on these two classes; finally, the quality metric
of an un-labeled example is denoted by the extent to
which it belongs to these two classes. Different
schemes to acquire examples from a given image, to
building the binary classifier and to model the quality
metric are proposed and investigated. In contrast to the
traditional methods which are tailored for some
specific distortion type, our method might provide a
general solution for NR image quality assessment.
Systematic subjective experiments on JPEG and
JPEG2000 compressed images demonstrate the
effectiveness of the proposed method. Future work
includes testing on other types of distortion and
integrating prior knowledge with the proposed method.

8. Acknowledgements
This work was supported by National High
Technology Research and Development Program of
China
(863
Program)
under
contract
No.2001AA114190.

9. References
[1] M.D. Adams, “The JPEG-2000 still image compression
standard”, ISO/IEC JTC 1/SC 29/WG 1, Document N2412,
Sep. 2001.
[2] C.J. van den Branden, “Special issue on image and video
quality metrics”, Signal Processing, vol 70, Nov. 1998.
[3] J. Caviedes and S. Gurbuz, “No-reference sharpness
metric based on local edge kurtosis”, International
Conference on Image Processing, vol. 3, pp. 53-56, Sep.
2002.
[4] R.O. Duda, P.E. Hart and D.G. Stork, Pattern
Classification (2nd Edition), Wiley-Interscience, Oct. 2000.
[5] Y. Freund, and R. Schapire, “A decision-theoretic
generalization of on-line learning and an application to
boosting”, Journal of Computer and System Sciences, 55(1):
119-139, 1997.
[6] J. Friedman, T. Hastie, and R. Tibshirani, “Additive
logistic regression: a statistical view of boosting”, The
Annual of Statistics, 28(2): 337-374, 2000.

[7] T. Hastie, R. Tibshirani, and J.H. Friedman, The
Elements of Statistical Learning. Springer Verlag, Aug. 2001.
[8] X. Li, “Blind image quality assessment”, International
Conference on Image Processing, vol. 1, pp. 24-28, Sep.
2002.
[9] P. Marziliano, F. Dufaux, S. Winkler and T. Ebrahimi,
“A no-reference perceptual blur metric”, International
Conference on Image Processing, vol. 3, pp. 57-60, Sep.
2002.
[10] E.P. Ong, W.S. Lin, Z.K. Lu, S.S. Yao, X.K Yang and
L.F. Jiang, “No-reference JPEG-2000 image quality metric”,
International Conference on Multimedia and Expo, vol. 1,
pp. 6-9, July. 2003.
[11] H.R. Sheikh, Z. Wang, L. Cormack and A. C. Bovik,
“LIVE
image
quality
assessment
database”,
http://live.ece.utexas.edu/research/quality.
[12] R. Shaw, “A century of image quality”, IS&T's PICS
Conference, pp. 221-224, Savannah, GA, 1999.
[13] H.R. Sheikh, Z. Wang, L. Cormack and A. C. Bovik,
“Blind quality assessment for JPEG2000 compressed
images”, International Conference on Image Processing, vol.
2, pp. 3-6, Sep. 2002.
[14] H.H. Tong, M.J. Li, H.J. Zhang, and C.S. Zhang, “Noreference quality assessment for JPEG2000 compressed
images”, To appear in International Conference on Image
Processing, 2004.
[15] N. Vasconcelos, “Feature selection by maximum
marginal diversity: optimality and implications for visual
recognition”, Proceeding on Computer Vision and Pattern
Recognition, vol. 1, pp. 762-769, 2003.
[16] VQEG, “Final report from the video quality experts
group on the validation of objective models of video quality
assessment”, http://www.vqeg.org/, Mar. 2000.
[17] Z. Wang, A.C. Bovik, and B.L. Evans, “Blind
measurement of blocking artifacts in images”, International
Conference on Image Processing, pp. 981-984, Sept. 2000.
[18] Z. Wang, A.C. Bovik, H.R. Sheikh, and E.P. Simoncelli,
“Image quality assessment: from error visibility to structural
similarity”, IEEE Transaction on Image Proc., vol. 13, no. 4,
Apr. 2004.
[19] Z. Wang, H.R. Sheikh, and A.C. Bovik, “No-reference
perceptual quality assessment of JPEG compressed images”.
International Conference on Image Processing, vol. 2, pp. 36, Sep. 2002.
[20] S. Winkler, “Issues in vision modeling for perceptual
video quality assessment”, Signal Processing, vol. 78, pp.
231-251, Oct. 1999.

Proceedings of the 11th International Multimedia Modelling Conference (MMM’05)
1550-5502/05 $20.00 © 2005 IEEE

(a) Ps = 78.54 Mhs = 82.33

(a) Ps = 82.73 Mhs = 77.47

(b) Ps = 55.88 Mhs = 51.93

(b) Ps = 50.27 Mhs = 50.19

(c) Ps = 40.12 Mhs = 39.13

(c) Ps = 31.46 Mhs = 31.57

Fig.3. An example of applying Real-AdaBoost to assess the
quality of JPEG compressed images.
(a) the original
uncompressed image; (b) some distortion in the compressed
image; (c) lots of distortion in the compressed image. Ps is the
prediction result; Mhs is the mean human score.

Fig.5. An example of applying Real-AdaBoost to assess
the quality of JPEG2000 compressed images by Opt. 1.
(a) the original uncompressed image; (b) some distortion
in the compressed image; (c) lots of distortion in the
compressed image. Ps is the prediction result; Mhs is the
mean human score.

Proceedings of the 11th International Multimedia Modelling Conference (MMM’05)
1550-5502/05 $20.00 © 2005 IEEE

Rare Class Discovery Based on Active Learning
Jingrui He and Jaime Carbonell
School of Computer Science
Carnegie Mellon University

Abstract
In machine learning, the new-class discovery problem
remains an open challenge, especially for emergent rare
classes. However, the challenge is of crucial importance for applications such as detecting new financial
fraud patterns, new viral mutations and new network
malware, most of which ‘hide’ among vast volumes of
normal data and observations. This paper focuses on
a new approach, based on local-topology density estimation, applicable to discovering examples of the rare
classes rapidly, despite non-separability with the majority class(es). The new method, called ALICE, and
its variant MALICE, are shown effective both theoretically and empirically in outperforming other methods
in the literature, both on challenging synthetic data
and on real data sets.

1

Introduction

Supervised machine learning methods require labeled
training examples for each class (Mitchell 1997). Semisupervised methods such as co-training (Blum &
Mitchell 1998), and active learning (Donmez & Carbonell 2007) share the same requirement, although the
former also utilizes unlabeled examples, and the latter
optimizes sampling strategies to obtain additional labels. However, both assume that at least one or more
instance of each class is given – i.e., they do not address
the new-class discovery challenge.
In many real world problems, we are interested in
rapidly discovering examples of rare classes, which are
known to be existent in the data set a priori. Often
times very small rare classes obfuscated to appear as
members of known majority classes. For instance, the
vast majority of financial transactions are legitimate,
but a small number may be fraudulent; detecting early
instances of new fraud patterns is a major first step
towards systematically finding and stopping such illicit
activity (Bay et al. 2006). Another example is network
intrusion detection; systematically finding the early onset of new malicious network activities among huge vol-

umes of routine network traffic is a critical unmet challenge (Wu et al. 2007). If we sample the data at random, we will need to examine a very large number of
routine majority-class examples before discovering the
emergent rare classes. This problem is also a bottleneck in reducing the sample complexity of active learning (Balcan, Beygelzimer, & Langford 2006) (Dasgupta
2005).
Compared with the rich literature on unbalancedcategory classification, up until now, only a few methods have been proposed to address the rare class discovery challenge. For example, in (Pelleg & Moore 2004),
the authors assumed a mixture model to fit the data,
and selected examples for labeling according to different criteria; in (Fine & Mansour 2006), the authors
proposed a generic consistency algorithm, and proved
upper bounds and lower bounds for this algorithm in
some specific situations. Scalability in new-class discovery was addressed in (Carbonell et al. 2006). Online new-topic assignment for documents in a stream
was proposed in (Blei & Lafferty 2006). Whereas the
above evidence a recent surge of interest in new class
discovery, these methods in general require that the
majority classes and the rare classes be separable or
nearly-separable to work well. However, in real applications, the support regions of the majority classes and
the rare classes often overlap strongly (sometimes due
to intentional obfuscation).
In this paper, we propose a new active learning method
for rapid rare-class discovery, named ALICE. It works
in the cases where we know the existence of some rare
classes, but do not have any labeled examples from
these classes. Different from existing methods on class
exploration, in our method, the rare classes may overlap with the majority classes. However, different rare
classes should be distinct from each other. Intuitively,
for each class, ALICE makes use of the local topology
defined by nearest neighbors to measure local density
around each example based on class-specific radii. Then
it selects an example with the maximum change in local
density on a certain scale, asks an external oracle for
its label, and gradually increases the scale until it finds

an example from that class. The core ALICE is proven
to be effective theoretically. In practice, to avoid repeatedly sampling the same class once discovered, we
have modified ALICE to produce MALICE, which performs much better than existing methods in our set of
experiments, both on synthetic and real data.
The rest of the paper is organized as follows. In Section
2, we introduce ALICE and MALICE with theoretical
justifications. Then we give some experimental results
to demonstrate their effectiveness in Section 3. Finally,
we conclude the paper in Section 4.

2
2.1

Class Exploration Method

Notation

Given a set of unlabeled examples S = {x1 , . . . , xn },
xi ∈ Rd , which come from m distinct classes, i.e.
yi ∈ {1, . . . , m}. For the sake of simplicity, assume
that there is one majority class with prior p1 , which
corresponds to yi = 1, and all the other classes are rare
classes with priors p2 , . . . , pm , p1 À pi , i 6= 1. Without
loss of generality, suppose that we are only interested
in the rare classes, and the goal is to find at least one
example from each rare class by requesting as few total
labels as possible.

2.2

Method

The proposed method ALICE is presented in Algorithm
1. ALICE works as follows: Given the priors for the
rare classes, we first estimate the number Ki of instances from class i in the set S. Then, for class i,
at each example, we record its distance from the Kith
nearest neighbor, which could be realized efficiently by
kd-trees (Moore 1991) for medium or low input-space
dimensionality. The minimum distance over all the examples is the class specific radius, and is assigned to
ri0 . Next, we draw a hyper-ball centered at example xj
with radius ri0 , and count the number of examples enclosed by this hyper-ball, which is denoted as nij . nij
is roughly in proportion to the local density. To find
examples from class i, in each iteration of Step 10, we
subtract the local density of neighboring points from nij ,
and let the maximum value be the score of xj . The example with the maximum score is selected for labeling
by the oracle. If the example is from class i, stop the iteration; otherwise, enlarge the neighborhood where the
scores of the examples are re-calculated and continue.
To intuitively understand ALICE, assume that the rare
classes are concentrated in small regions and the probability density function (pdf) of the majority class is
locally smooth. Firstly, since the support regions of the
rare classes are very small, it is important to find their

scales. The ri0 values obtained in Step 3 will be used to
calculate the local density nij . Since ri0 is based on the
minimum Kith nearest neighbor distance, it is never too
large to smooth out changes of local density, and thus
it is a good measure of the scale to begin with. Secondly, in each iteration of Step 8, the score of a certain
point, corresponding to the change in local density, is
the maximum of the difference in local density between
this point and all of its neighboring points. In this way,
we are not only able to select points on the boundary
of the rare class i, but also points in the interior, given
that the support region of class i is small. Finally, by
gradually enlarging the neighborhood where the scores
are calculated, we can further explore the interior of the
support region, and increase our chance of finding rare
class examples.
Algorithm 1 Active Learning for Initial Class Exploration (ALICE)
Require: S, p2 , . . . , pm
1: Initialize all the rare classes as undiscovered.
2: for i = 2 : m do
3:
Let Ki = npi , where n is the number of examples.
4:
For each example, calculate the distance between
this example and its Kith nearest neighbor. Set ri0
to be the minimum value among all the examples.
5: end for
6: for i = 2 : m do
7:
∀xj ∈ S, let N N (xj , ri0 ) = {x|x ∈ S, kx − xj k ≤
ri0 }, and nij = |N N (xj , ri0 )|.
8: end for
9: for i = 2 : m do
If class i has been discovered, continue.
10:
11:
for t = 2 : n do
12:
For each xj that has been selected, sij =
−∞; for all the other examples, sij =
max 0 (nij − nik ).
xk ∈N N (xj ,tri )

Select and query the label of x
=
arg maxxj ∈S sij .
14:
If the label of x is equal to i, break; otherwise,
mark the class that x belongs to as discovered.
15:
end for
16: end for
13:

2.3

Justification

In this subsection, we prove that if the rare classes are
concentrated in small regions and the pdf of the majority class is locally smooth, ALICE will repeatedly
sample in the regions where rare class examples occur
with high probability.
Let fi (x) denote the pdf of class i, where i = 1, . . . , m
and x ∈ Rd . To be precise, we make the following
assumptions.

1
3m−3
1
m
log 3m−3
δ , maxi=2 2(1−2−d )2 p2i log
δ ,
2c2i1 p2i
1
3m−3
m
maxi=2 ²4 V ( ri2 )4 log δ }, then with probability at
2
ni
ni
least 1 − δ, r2i2 ≤ ri0 ≤ ri and | nj − E( nj )| ≤ ²V (ri0 ),

Assumptions

max{maxm
i=2

1. The pdf fi (x) of rare class i is uniform within a hyperball Bi of radius ri 1 centered at bi , i = 2, . . . , m, i.e.
1
fi (x) = V (r
, if x ∈ Bi ; and 0 otherwise, where
i)
V (ri ) ∝ rid is the volume of Bi .

1 ≤ j ≤ n.

2. f1 (x) is bounded and positive in Bi , i = 2, . . . , m,
pi
pi
i.e. f1 (x) ≥ p1cVi1(r
, ∀x ∈ Bi and f1 (x) ≤ p1cVi2(r
,
i)
i)
d
2
∀x ∈ R , where ci1 , ci2 > 0 are two constants.
Furthermore, for each rare class i, i = 2, . . . , m, let
ri
ri2
ri2 =
1 ; and let OV ( 2 , ri ) be the volume of the
(1+ci2 ) d

overlapping region of two hyper-balls: one is of radius
ri ; the other one is of radius r2i2 , and its center is on
the sphere of the previous one. We have the following
theorem, which proves the effectiveness of ALICE.
Theorem. If

2. The rare classes are far apart, i.e. if xj , xk ∈ S,
kxj − bi k ≤ ri , kxk − bi0 k ≤ ri0 , i, i0 = 2, . . . , m, and
i 6= i0 , then kxj − xk k > α.
3. f1 (x) is locally smooth, i.e.
f1 (y)| ≤

∀x, y ∈ Rd , |f1 (x) −

where β ≤ minm
i=2

1
2(1−2−d )2 p2i
1
m
maxi=2 p4 β 4 V ( ri2 )4
1
2

log

nij
nij
− E( )| > ²V (ri0 )]
n
n
m
m
X
X
ri2
≤
Pr[ri0 > ri ] +
]+
Pr[ri0 <
2
i=2
i=2

log

i1 i

Lemma.
For
each
rare
i
=
2, . . . , m, ∀²i , δi
>
0,

i=2

≤
+

m
X
i=2
m
X

Pr[|N N (bi , ri )| < Ki ]
Pr[max |N N (x,
x∈Rd

i=2

+

+

m
X
i=2
m
X

n Pr[|
Pr[|

m
X

+n

class
if n

i,
≥

This is the actual radius, as opposed to the class specific
radius ri0 .
2
Notice that here we are only dealing with the hard case
where f1 (x) is positive within Bi . In the separable case
where the support regions of the majority class and the rare
classes do not overlap, we can use other methods to detect
the rare classes, such as the one proposed in (Pelleg & Moore
2004).

≤

N N (bi , ri )
| < pi ]
n

x∈Rd

Pr[|

i=2
m
X

N N (x, r2i2 )
| > pi ]
n

nij
nij
ri2
− E( )| > ²V (ri0 )|ri0 ≥
]
n
n
2
2

2

e−2nci1 pi +

i=2

+ 2n

m
X

ri2
)| > Ki ]
2

nij
nij
ri2
− E( )| > ²V (ri0 )|ri0 ≥
]
n
n
2

Pr[max |

i=2
m
X

Proof. To prove the theorem, we need the following
simple lemma.

nij
nij
ri2
AND ∃xj s.t. | − E( )| > ²V (ri0 )]
2
n
n

Pr[ri0 ≥

i=2

3m−3
δ ,
3m−3
δ }.

ri2
2

OR ∃i, ∃xj ∈ S s.t. |

=

then with probability at least 1 − δ, in every iteration of
Step 8, after d r2α
e rounds of Step 10, ALICE will query
i2
at least one example whose probability of coming from
a rare class is at least 13 .

1

Pr[∃i, s.t. ri0 > ri OR ∃i, s.t. ri0 <

r

p2i OV ( 2i2 ,ri )
.
2d+1 V (ri )2

4. The number of examples is sufficiently large,
1
3m−3
i.e. n ≥ max{maxm
i=2 2c2 p2 log
δ ,
maxm
i=2

x∈Rd

m
X

1. For rare class i, i = 2, . . . , m, let Bi2 be the hyper-ball
centered at bi with radius 2ri . The minimum distance
between the points inside Bi and the ones outside Bi2
is not too large, i.e. maxm
i=2 min{kxj − xk k|xj , xk ∈
S, kxj − bi k ≤ ri , kxj − bi k > 2ri } ≤ α.

βkx−yk
,
α

Proof.
First, notice that for each rare class i,
the expected proportion of points falling inside Bi ,
i ,ri )|
E( |N N (b
) ≥ (ci1 + 1)pi , and that the maximum exn
pected proportion of points falling inside any hyper-ball
r
|N N (x, 2i2 )|
of radius r2i2 , max[E(
)] ≤ 2−d pi . Then
n

m
X

e−2n(1−2

−d 2 2
) pi

i=2
2

e−2n²

V (ri0 )2

i=2

where the last inequality is based on Hoeffding bound.
2

2

δ
δ
−2n(1−2−d )2 p2i
≤ 3m−3
and
3m−3 , e
ri2 2
2
0
2
δ
−2n² V (ri )
−2n² V ( 2 )
2ne
≤ 2ne
≤ 3m−3 , we obtain
1
log 3m−3
n ≥ 2c21 p2 log 3m−3
,
n
≥
δ
δ , and
2(1−2−d )2 p2i
i1 i
1
3m−3
n ≥ ²4 V ( ri2 )4 log δ . ¥
2

Let e−2nci1 pi ≤

Based on this lemma, using condition 4, let ² = p1 β, if
the number of examples is sufficiently large, then with
probability at least 1 − δ, for each rare class i, i =

2, . . . , m, r2i2 ≤ ri0 ≤ r and |
1 ≤ j ≤ n.

nij
n

− E(

nij
n )|

≤ p1 βV (ri0 ),

To better prove the theorem, given a point xj ∈ S,
we say that xj is ‘far from all the rare classes’ iff for
every rare class i, kxj − bi k > 2ri , i.e. xj is not within
Bi2 . According to condition 3, ∀xj , xk ∈ S s.t. xj and
xk are far from all the rare classes and kxj − xk k ≤
ni

ni

α, E( nj ) and E( nk ) will not be affected by the rare
classes. Therefore, in iteration i of Step 8 where we aim
ni

ni

to find examples from rare class i, |E( nj ) − E( nk )| ≤
p1 βV (ri0 ) ≤ p1 βV (ri ). Furthermore, since α is always
bigger than ri , we have
|

nij
ni
− k|
n
n
nij
nij
nij
ni
ni
ni
≤ | − E( )| + | k − E( k )| + |E( ) − E( k )|
n
n
n
n
n
n
≤ 3p1 βV (ri )
(1)

From inequality (1), it is not hard to see that ∀xj , xk ∈
S, s.t. xj is far from all the rare classes and kxj −xk k ≤
α,

nij
n

−

nik
n

∀xj ∈ S s.t. xj is far from all the rare classes, we have
siu > sij . Therefore, in this round of iteration, we will
pick an example that is NOT far from one of the rare
classes, i.e. there exists a rare class it s.t. the selected
example is within Bi2t . Note that it is not necessarily
equal to i, which is the rare class that we would like to
discover in Step 8 of the method.
Finally, we show that the probability of picking an example that belongs to rare class it from Bi2t is at least 31 .
To this end, we need to calculate the maximum probability mass of the majority class within Bi2t . Consider
the case where the maximum value of f1 (x) occurs at
bit , and this pdf decreases by β every time x moves
away from bit in the direction of the radius by α, i.e.
the shape of f1 (x) is a cone in (d+1) dimensional space.
αf (b )
f (b )
Since f1 (x) must integrate to 1, i.e. V ( 1β it ) · 1d+1it ,
αf1 (bit )
) is the volume
β
αf1 (bit )
, we have f1 (bit ) =
β

where V (

On the other hand, based on conditions 1 and 2, there
exist two points xu , xv ∈ S, s.t. kxu − bi k ≤ ri , xv
is far from all the rare classes, and kxu − xv k ≤ α.
ni
Since the contribution of rare class i to E( nu ) is at
least
p1 βV

pi ·OV
,ri )
, so E( n
V (ri )
r
p
·OV
( 2i2 ,ri )
i
(ri0 ) ≥
−
V (ri )

ample xj ∈ S, we have
p1 βV (ri ), therefore

) − E(

xjv
n

)≥

r
( 2i2

pi ·OV
,ri )
V (ri )

−

p1 βV (ri ). Since for any ex-

ni
| nj

−

ni
E( nj )|

≤ p1 βV

(ri0 )

≤

( r2i2 , ri )

pi · OV
nu
nv
−
≥
− 3p1 βV (ri )
n
n
V (ri )
pi · OV ( r2i2 , ri ) 3p1 p2i · OV ( r2i2 , ri )
≥
−
V (ri )
2d+1 V (ri )
Since pi is very small, pi À
r

3p1 p2i ·OV ( 2i2 ,ri )
2d+1 V (ri )

6p1 p2i
;
2d+1

therefore,

d

2rit β
2rit
β) +
V (2rit )
α
α d+1
d
1
d + 1 d+1
β d+1
< V (2rit )f1 (bit ) = V (2rit )(
)
V (α)
1
d
V (rit )
d+1 β d+1
= 2d
1 (d + 1)
d+1
(V (α))

V (2rit )(f1 (bit ) −

sij
≤ 3p1 βV (ri )
(2)
n
This is because if xk is not far from any of the rare
ni
classes, the rare classes may also contribute to nk , and
thus the score of xj may be even smaller.

xiu

1

d+1 β d+1 . Theredius
( Vd+1
(α) )
fore, the probability mass of the majority class within
Bi2t is:

≤ 3p1 βV (ri ), i.e. when tri0 = α,

r
( 2i2

of a hyper-ball with ra-

niu
n

−

niv
n

>

≥ 3p1 βV (ri ), i.e. when tri0 = α,

siu
> 3p1 βV (ri )
(3)
n
In Step 10 of the proposed method, we gradually enlarge the neighborhood to calculate the change of local density to continue seeking an example of the rare
class. When tri0 = α, based on inequalities (2) and (3),

1

d

< (d + 1) d+1 (2d+1 V (rit )β) d+1
r

≤ (d + 1)

1
d+1

p2 · OV ( i2t 2 , rit ) d
( it
) d+1 < 2pit
V (rit )

where V (2rit ) is the volume of a hyper-ball with radius
2rit . Therefore, if we select a point at random from
Bi2t , the probability that this point is from rare class it
p
pit
is at least pi +pi1t·2pi ≥ pi +2p
= 31 . ¥
i
t

2.4

t

t

t

Implementational Issues

According to our theorem, in each iteration of Step 8,
with high probability, we may pick examples belonging
to the rare classes after selecting a small number of examples. However, the discovered rare class it may not
be the same as the rare class i that we hope to discover in this iteration of Step 8. Furthermore, we may
repeatedly select examples from class it before finding
one example from class i. To address these issues, we
have modified the original ALICE algorithm to produce
MALICE, which is shown in Algorithm 2.
There are two major differences between MALICE and
ALICE. 1) In Step 12 of MALICE, once we have labeled an example, any unlabeled example within the
class specific radius of this example will be precluded

Algorithm 2 Modified Active Learning for Initial
Class Exploration (MALICE)
Require: S, p2 , . . . , pm
1: Initialize all the rare classes as undiscovered.
2: for i = 2 : m do
3:
Let Ki = npi .
4:
For each example, calculate the distance between
this example and its Kith nearest neighbor. Set ri0
to be the minimum value among all the examples.
5: end for
0
6: Let r10 = maxm
i=2 ri .
7: for i = 2 : m do
8:
∀xj ∈ S, let N N (xj , ri0 ) = {x|x ∈ S, kx − xj k ≤
ri0 }, and nij = |N N (xj , ri0 )|.
9: end for
10: for i = 2 : m do
11:
If class i has been discovered, continue.
for t = 2 : n do
12:
13:
For each xj that has been selected, ∀xk ∈ S,
s.t. kxj −xk k ≤ ry0 j , sik = −∞; for all the other
max 0 (nij − nik ).
examples, sij =
xk ∈N N (xj ,tri )

Select and query the label of x
=
arg maxxj ∈S sij .
15:
If the label of x is equal to i, break; otherwise,
t = t − 1, mark the class that x belongs to as
discovered.
16:
end for
17: end for
14:

(shown in blue dots) is Gaussian and the pdf of the rare
class (shown in red circles) is uniform within a small
hyper-ball. There are 1000 examples from the majority
class and only 10 examples from the rare class. Using
Interleave, we need to label 35 examples on average; using RS, we need to label 101 examples on average; and
using MALICE, we only need to label 3 examples in
order to sample one example from the rare class we are
interested in, which are denoted as ‘x’ in Figure 1(b).
Notice that the first 2 examples that MALICE selects
are not from the correct region. This is because the
number of examples from the rare class is very small,
and the local density may be affected by the randomness in the data.

5

4

3

2

1

0

−1
−3

−2

−1

0

1

2

3

4

2

3

4

(a) Data Set

from selection. Since we have proved that with high
probability, the class specific radius is less than the actual radius, this modification will help prevent examples
of the same class from being selected repeatedly. 2) In
Step 14 of MALICE, if the labeled example belongs to
a rare class other than class i, we will not enlarge the
neighborhood based on which the scores of the examples are re-calculated. This is to increase the chance
that if tri0 is close to α, we will select examples from
Bi2 .

5

4

3

2

1

0

3

Experimental Results

−1
−3

In this section, we compare MALICE with the best
method proposed in (Pelleg & Moore 2004) (Interleave)
and random sampling (RS) on both synthetic and real
data sets. In Interleave, we use the number of classes
as the number of components in the mixture model.
For both Interleave and RS, we run the experiments 10
times and report the average results.

3.1

Synthetic data sets

Figure 1(a) shows a synthetic data set where there is
only one rare class. The pdf of the majority class

−2

−1

0

1

(b) Examples Selected by MALICE, denoted as ‘x’

Figure 1: Synthetic Data Set 1.
In Figure 2(a), the majority class has 3000 examples
(shown in blue dots) with Gaussian distribution. The
4 rare classes (shown in red circles) all have different
shapes, and each has 267, 280, 84 and 150 examples respectively. Using Interleave, we need to label 382 examples on average; using RS, we need to label 68 examples
on average; and using MALICE, we only need to label

4 examples, each of which is in a different rare class.
The examples selected by MALICE are denoted as ‘x’
in Figure 2(b). Notice that with this dataset, Interleave
is even worse than RS. This is because some rare class
is within the dense region of the majority class. Therefore, it may take Interleave a long time to finally find
one example from this rare class.

200

150

100

50

0

−50
−100

−50

0

50

100

150

200

250

(a) Data Set

In Table 1 and 2, we compare the number of labeled
examples for different methods on the two data sets
respectively. From these tables, we can see that MALICE is significantly better than Interleave and RS: with
Shuttle data set, to find all the rare classes, Interleave
needs 132 label requests, RS needs 512 label requests,
and MALICE only needs 84 label requests; with image
data set, to find all the rare classes, Interleave needs
662 label requests, RS needs 112 label requests, and
MALICE only needs 49 label requests. This is because
as the number of components becomes larger, the mixture model generated by Interleave is less reliable due
to the lack of labeled examples, thus we need to select more examples. Furthermore, the majority class
and rare classes may not be nearly-separable, which is
a disaster for Interleave. On the other hand, MALICE
does not assume a generative model for the data, and
only focuses on the change in local density, which is
more effective on the two data sets.
Number of Rare
Classes Discovered
MALICE
Interleave
RS

1

2

3

4

5

6

6
1
7

11
52
9

49
107
13

71
109
63

72
115
100

84
132
512

Table 1: The Number of Labeled Examples for Different
Methods on Shuttle Data Set.

200

150

Number of Rare
Classes Discovered
MALICE
Interleave
RS

100

50

1

2

3

4

5

3
6
10

4
114
22

14
180
39

43
181
61

49
662
112

0

Table 2: The Number of Labeled Examples for Different
Methods on Image Data Set.

−50
−100

−50

0

50

100

150

200

250

(b) Examples Selected by MALICE, denoted as ‘x’

3.3
Figure 2: Synthetic Data Set 2.

3.2

Real data sets

In this subsection, we compare different methods on
two real data sets: Shuttle (Brazdil & Gama 1991) and
image data set. The first data set consists of 4515 examples, described by 9 dimensional features. The examples
come from 7 classes: the proportion of the largest class
(majority class) is 75.53%, and the proportion of the
smallest class is 0.13%. The second data set consists
of 5000 images, described by 244 dimensional features
such as color and texture. The examples come from
6 classes: the proportion of the largest class (majority class) is 90.00%, and the proportion of the smallest
class is 2.00%.

Conclusion

In this paper, we have proposed a new active learning method (ALICE) for rare-class discovery, which is
a very important topic in many real problems, such
as network intrusion detection and financial fraud detection. Different from existing methods, ALICE does
not rely on the assumption that the data is nearlyseparable. It works by selecting examples corresponding to regions with the maximum change in local density, and depending on scaling, it will select classboundary or class-internal examples of the rare classes.
ALICE could be scaled up using kd-trees (Moore 1991).
The effectiveness of ALICE is guaranteed by theoretical
justification, i.e. guarantees on the probability of discovering an example of rare classes, given a sampling
strategy. Furthermore, to avoid repeatedly sampling in
the same class in real applications, we have modified

ALICE accordingly to produce MALICE, which outperforms existing methods on both synthetic and real
data sets. Future work involves studying the robustness
of MALICE when the parameters provided to it (the
number of rare classes, and the priors of each class) are
unknown or just estimates.

References
Balcan, M.; Beygelzimer, A.; and Langford, J. 2006.
Agnostic active learning. In Proc. of the 23rd Int.
Conf. on Machine Learning, 65–72.
Bay, S.; Kumaraswamy, K.; Anderle, M.; Kumar, R.;
and Steier, D. 2006. Large scale detection of irregularities in accounting data. In Proc. of the 6th Int. Conf.
on Data Mining, 75–86.
Blei, D., and Lafferty, J. 2006. Dynamic topic models.
In Proc. of the 23rd Int. Conf. on Machine Learning,
113–120.
Blum, A., and Mitchell, T. 1998. Combining labeled
and unlabeled data with co-training. In Proc. of the
23th Annual Conf. on Computational Learning Theory, 92–100.
Brazdil, P., and Gama, J. 1991. Statlog repository.
In http://www.niaad.liacc.up.pt/old/statlog/datasets
/shuttle/shuttle.doc.html.
Carbonell, J.; Fink, E.; Jin, C.; Gazen, C.; Mathew,
J.; Saxena, A.; Satish, V.; s. Ananthraman; Dietrich,
D.; Mani, G.; Tittle, J.; and Durbin, P. 2006. Scalable data exploration and novelty detection. In NIMD
Workshop.
Dasgupta, S. 2005. Coarse sample complexity bounds
for active learning. In Advances in Neural Information
Processing Systems 19.
Donmez, P., and Carbonell, J. 2007. Dual-strategy
active learning. In Proc. of the 18th European Conf.
on Machine Learning.
Fine, S., and Mansour, Y. 2006. Active sampling for
multiple output identification. In The 19th Annual
Conf. on Learning Theory, 620–634.
Mitchell, T. 1997. Machine Learning. McGraw-Hill
Science Engineering.
Moore, A. 1991. A tutorial on kd-trees. Technical report, University of Cambridge Computer Laboratory.
Pelleg, D., and Moore, A. 2004. Active learning for
anomaly and rare-category detection. In Advances in
Neural Information Processing Systems 18.
Wu, J.; Xiong, H.; Wu, P.; and Chen, J. 2007. Local
decomposition for rare class analysis. In Proc. of the
13th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, 814–823.

Diversified Ranking on Large Graphs:
An Optimization Viewpoint
Hanghang Tong

Jingrui He

Zhen Wen

Ravi Konuru

Ching-Yung Lin

IBM T.J. Watson Research Center
Hawthorne, NY, USA
{htong,

jingruhe, zhenwen, rkonuru, chingyung}@us.ibm.com

ABSTRACT

Diversity is also positively associated with personnel performance
and job retention rate in a large organization [38].
Despite their own success of the previous works (See Section 6
for a review), two important questions remain open in diversified
ranking on large graphs. The first challenge is the measure - for a
given top-k ranking list, how can we quantify its goodness? Intuitively, a good top-k ranking list should capture both the relevance
and the diversity. For example, given a task which typically requires a set of different skills, if we want to form a team of experts,
not only should the people in the team have relevant skills, but
also they should somehow be ‘different’ from each other so that
the whole team can benefit from the diversified, complementary
knowledge and social capital. However, there does not exist such a
goodness measure for the graph data in the literature. Most of the
existing works for diversified ranking on graphs are based on some
heuristics. The only exception is [27], where the authors made an
important step towards this goal by providing some optimization
explanations, which is achieved by defining a time-varying objective function at each iteration. But still, it is not clear what overall
objective function the algorithm tries to optimize.
The second challenge lies in the algorithmic aspect - how can we
find an optimal, or near-optimal, top-k ranking list that maximizes
the goodness measure? Bringing diversity into the design objective
implies that we need to optimize on the set level. In other words, the
objective function for a subset of nodes is usually not equal to the
sum of objective functions of each individual nodes. It is usually
very hard to perform such set-level optimization. For instance, a
straight-forward method would need exponential enumerations to
find the exact optimal solution, which is infeasible even for medium
size graphs. This, together with the fact that real graphs are often of
large size, reaching billions of nodes and edges, poses the challenge
for the optimization algorithm - how can we find a near-optimal
solution in a scalable way?
In this paper, we address these challenges from an optimization
point of view. We propose a goodness measure which intuitively
captures both (a) the relevance between each individual nodes in
the ranking list and the query node; and (b) the diversity among
different nodes in the ranking list. We further propose a scalable
algorithm (linear wrt the size of the graph) that generates a provably near-optimal top-k ranking list. To the best of our knowledge,
this is the first work for diversified ranking on large graphs that
(1) has a clear optimization formulation; (2) finds a provably nearoptimal solution; and (3) enjoys the linearly scalability. The main
contributions of the paper are summarized as follows:

Diversified ranking on graphs is a fundamental mining task and has
a variety of high-impact applications. There are two important open
questions here. The first challenge is the measure - how to quantify the goodness of a given top-k ranking list that captures both
the relevance and the diversity? The second challenge lies in the
algorithmic aspect - how to find an optimal, or near-optimal, top-k
ranking list that maximizes the measure we defined in a scalable
way?
In this paper, we address these challenges from an optimization
point of view. Firstly, we propose a goodness measure for a given
top-k ranking list. The proposed goodness measure intuitively captures both (a) the relevance between each individual node in the
ranking list and the query; and (b) the diversity among different
nodes in the ranking list. Moreover, we propose a scalable algorithm (linear wrt the size of the graph) that generates a provably
near-optimal solution. The experimental evaluations on real graphs
demonstrate its effectiveness and efficiency.

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications – Data
Mining

General Terms
Algorithm, experimentation

Keywords
Diversity, ranking, scalability, graph mining

1.

INTRODUCTION

Given an author-paper network, how to find the top-k most related conferences for a given author? How to diversify the ranking
list so that it captures the whole spectrum of the given author’s research interest? It is now widely realized that diversity is a key factor to address the uncertainty and ambiguity in an information need;
and to cover the different aspects of the information need [32].

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
KDD’11, August 21–24, 2011, San Diego, CA, USA.
Copyright 2011 ACM 978-1-60558-193-4/08/088 ...$5.00.

• A measure to quantify goodness for a top-k ranking list that
captures both relevance and diversity;
• An algorithm to find a diversified top-k ranking list from
large graphs;

1028

Symbol
A, B, . . .
A(i, j)
A(i, :)
A(:, j)
A
a, b, . . .
I, J , . . .
⊗
r
p
I
1
0
n, m
k
c

1) is a damping factor;
 A is the row-normalized adjacency matrix
of the graph (i.e., n
j=1 A(i, j) = 1 (i = 1, ..., n); and r is the n×
1 resulting ranking vector. Note that if p(i) = 1/n(i = 1, ..., n), it
is reduced to the standard PageRank [30]; if p(i) = 1 and p(j) =
0(j = i), the resulting ranking vector r gives the proximity scores
from node i to all the other nodes in the graph [37].
In order to simplify the description of our upcoming method, we
also introduce the so-called ‘Google matrix’ B:

Table 1: Symbols
Definition and Description
matrices (bold upper case)
the element at the ith row and j th column of A
the ith row of matrix A
the j th column of matrix A
transpose of matrix A
vectors
sets (calligraphic)
element-wise Hadamard product
an n × 1 ranking vector

an n × 1 query vector (p(i) ≥ 0, n
i=1 p(i) = 1)
an identity matrix
a vector/matrix with all elements set to 1s
a vector/matrix with all elements set to 0s
the number of the nodes and edges in the graph
the budget (i.e., the length of the ranking list)
the damping factor 0 < c < 1

B = cA + (1 − c)p11×n

where 11×n is a 1 × n row vector with all elements set to 1s. Intuitively, the ‘Google matrix’ B can be viewed as the personalized
adjacency matrix that is biased towards the query vector p. It turns
out that the ranking vector r defined in eq. (1) satisfies r = Br. In
other words, the ranking vector r is the right eigenvector of the B
matrix with the eigenvalue 1. It can be verified that B is a columnwise stochastic matrix (i.e., each column of B sums up to 1). By
Perron-Frobenius theorem [10], it can be shown that 1 is the largest
(in module) simple eigenvalue of the matrix B; and the ranking
vector r is unique with all non-negative elements since the graph is
irreducible.
Our goal is two-fold: (1) we want a goodness measure to quantify the quality of a given top-k ranking list that captures both the
relevance and the diversity; and (2) given the goodness measure, we
want an optimal or near-optimal algorithm to find a top-k ranking
list that maximizes such goodness measure in a scalable way. With
the above notations and assumptions, our problems can be formally
defined as follows:

• Proofs and complexity analysis, showing that our method is
provably near-optimal in terms of optimization quality with
linear scalability;
• Extensive experimental evaluations, demonstrating the effectiveness and efficiency of our method.
The rest of the paper is organized as follows. We introduce notation and formally define the problems in Section 2. We present
and analyze the proposed measure and algorithm in Section 3 and
Section 4, respectively. We provide experimental evaluation in Section 5. We review the related work in Section 6 and conclude in
Section 7.

2.

P ROBLEM 1. (Goodness Measure.)
Given: A large graph An×n , the query vector p, the damping factor c, and a subset of k nodes S;
Output: A goodness score f(S) of the subset of nodes S, which
measures (a) the relevance of each node in S wrt the query
vector p, and (b) the diversity among all the nodes in the
subset S.

PROBLEM DEFINITIONS

Table 1 lists the main symbols we use throughout the paper. In
this paper, we consider the most general case of directed, weighted,
irreducible unipartite graphs. We represent a general graph by its
adjacency matrix1 . Following the standard notation, we use bold
upper-case for matrices (e.g., A), bold lower-case for vectors (e.g.,
a), and calligraphic fonts for sets (e.g., I). We denote the transpose
with a prime (i.e., A is the transpose of A). For a bipartite graph
with adjacency matrix
 W, we can
 convert it to the equivalent uni0 W
partite graph: A =
. We use subscripts to denote the
W 0
size of matrices/vectors (e.g., An×n means a matrix of size n × n).
When the size of matrices/vectors are clear from the context, we
omit such subscripts for brevity. Also, we represent the elements in
a matrix using a convention similar to Matlab, e.g., A(i, j) is the
element at the ith row and j th column of the matrix A, and A(:, j)
is the j th column of A, etc. With this notation, we can represent
a sub-matrix of A as A(I, I), which is a block of matrix A that
corresponds to the rows/columns of A indexed by the set I.
In this paper, we focus on personalized PageRank [30, 11] since
it is one of the most fundamental ranking methods on graphs, and
has shown its success in many different application domains in the
past decade. Formally, it can be defined as follows:


r = cA r + (1 − c)p

n

(2)

P ROBLEM 2. (Diversified Top-k Ranking Algorithm.)
Given: A large graph An×n , the query vector p, the damping factor c, and the budget k;
Find: A subset of k nodes S that maximizes the goodness measure
f(S).
In the next two sections, we present our solutions for these two
problems respectively.

3. THE PROPOSED GOODNESS MEASURE
In this section, we address Problem 1. Our goal is to define a
goodness measure to quantify the quality of a given top-k ranking
list that captures both the relevance and the diversity. We first discuss some design objectives of such a goodness measure; and then
present our solution followed by some theoretical analysis.

3.1 Design Objectives
As said before, a good diversified top-k ranking list should balance between the relevance and the diversity. The notion of relevance is clear for personalized PageRank, - larger value in the
ranking vector r means more relevant wrt the query vector p. On
the other hand, the notion of diversity is more challenging. Intuitively, a diversified subset of nodes should be dis-similar with
each other. Take the query ‘Find the top-k conferences for Philip
Yu from the author-conference network’ as an example. Dr. Philip

(1)

where p is an n × 1 personalized vector (p(i) ≥ 0, i=1 p(i) =
1). Sometimes, we also refer to p as the query vector. c (0 < c <
1
In practice, we store these matrices using an adjacency list representation, since real graphs are often very sparse.

1029

Yu is a professor at University of Illinois at Chicago. His recent major research interest lies in databases and data mining. He also has
broad interests in several related domains, including systems, parallel and distributed processing, web applications, and performance
modeling, etc. A top-k ranking list for this query would have high
relevance if it consists of all the conferences from databases and
data mining community (e.g., SIGMOD, VLDB, KDD, etc) since
all these conferences are closely related to his major research interest. However, such a list has low diversity since these conferences
are too similar with each other (e.g., having a large overlap of contributing authors, etc). Therefore, if we replace a few databases
and data mining conferences by some representative conferences
in his other research domains (e.g., ICDCS for distributed computing systems, WWW for web applications, etc), it would make the
whole ranking list more diverse (e.g., the conferences in the list are
more dis-similar with each other).
Furthermore, if we go through the ranking list from top down,
we would like to see the most relevant conferences to appear first
in the ranking list. For example, a ranking list in the order of ‘SIGMOD’,‘ICDCS’,‘WWW’ is better than ‘ICDCS’,‘WWW’,‘SIGMOD’
since databases (SIGMOD) is a more relevant research interest for
Dr. Philip Yu, compared with distributed computing systems (ICDCS),
or web applications (WWW). In this way, the user can capture Dr.
Philip Yu’s main research interest by just inspecting a few topranked conferences/nodes. This suggests the so-called diminishing
returns property of the goodness measure - it would help the user
to know better about Dr. Philip Yu’s whole research interest if we
return more conferences/nodes in the ranking list; but the marginal
benefit becomes smaller and smaller as we go down the ranking list.
Another implicit design objective lies in the algorithmic aspect.
The proposed goodness measure should also allow us to develop
an effective and scalable algorithm to find an optimal (or at least
near-optimal) top-k ranking list from large graphs. We will discuss
and address this issue in the next section.
To summarize, for a given top-k ranking list, we aim to provide a
single goodness score that (1) measures the relevance between each
individual node in the list and the query vector p; (2) measures the
similarity (or dis-similarity) among all the nodes in the ranking list;
(3) exhibits some diminishing returns property wrt the size of the
ranking list; and (4) enables some effective and scalable algorithm
to find an optimal (or near-optimal) top-k ranking list.

3.2 The Proposed Measure

i,j∈S

Let us analyze how the proposed goodness measure meets our
design objectives in subsection 3.1.
There are two terms in eq (3), the first term is twice the sum
of the ranking scores in the ranking list. For the second term, recall that B can be viewed as the personalized adjacency matrix wrt
the query vector p, where B(i, j) indicates the similarity (i.e., the
strength of the connection) between nodes i and j. In other words,
the second term in eq (3) is the sum of all the similarity scores between any two nodes i, j(i, j ∈ S) in the ranking list (weighted
by r(j)). Therefore, the proposed goodness measure captures both
the relevance and the diversity. The more relevant (higher r(i))
each individual node is, the higher the goodness measure f(S). At
the same time, it encourages the diversity within the ranking list by
penalizing the (weighted) similarity between any two nodes in S.
The proposed measure f(S) also exhibits the diminishing returns
property, which is summarized in Theorem 1. The intuitions of
Theorem 1 are as follows: (1) by P1, it means that the utility of an
empty ranking list is always zero; (2) by P2, if we add more nodes
into the ranking list, the overall utility of the ranking list does not
decrease; and (3) by P3, the marginal utility of adding new nodes
is relatively small if we already have a large ranking list.
T HEOREM 1. Diminishing Returns Property of f(S). Let Φ
be an empty set; I, J , R be three sets s.t., I ⊆ J , and R∩J = Φ.
The following facts hold for f(S):
P1: f(Φ) = 0;
P2: f(S) is monotonically non-decreasing, i.e., f(I) ≤ f(J );
P3: f(S) is submodular, i.e., f(I ∪R)−f(I) ≥ f(J ∪R)−f(J ).
P ROOF of P1. It is obviously held by the definition of f(S). 2
P ROOF of P2. Let T = J \ I. Substituting eq (3) into f(J ) −
f(I) and canceling the common terms, we have
=

f(J ) − f(I)



2
r(i) −
B(i, j)r(j) −
B(i, j)r(j)
i∈T

=

(



+(

i∈I j∈T

r(j) −

i∈T j∈J

B(i, j)r(j))

r(i) −



B(i, j)r(j))

(4)

i∈T j∈J

Recall that the matrix B is a column-wise stochastic matrix (i.e.,
each column of B sums up to 1). The first half of eq (4) satisfies


(
r(j) −
B(i, j)r(j))
j∈T

=

i,j∈S

j∈S




j∈T i∈I

i∈T

We can also represent f(S) by using the matrix A instead:




f(S) = 2
r(i) − c
A(j, i)r(j) − (1 − c)
r(j)
p(i)
i∈S

3.3 Proofs and Analysis

j∈T

Let A be the row-normalized adjacency matrix of the graph, B
be the ‘Google matrix’ defined in eq (2), p be the personalized
vector and r be the ranking vector. For a given ranking list S (i.e.,
S gives the indices of the nodes in the ranking list; and |S| = k.),
the proposed goodness measure is formally defined as follows:
Goodness Measure:


f(S) = 2
r(i) −
B(i, j)r(j)
(3)
i∈S

still output an ordered subset based on the diminishing returns need
when the user is seeking for a diverse top-k ranking list.

i∈S



r(j)(1 −

j∈T

=



j∈T i∈I

r(j)

j∈T





B(i, j))

i∈I

B(i, j) ≥ 0

(5)

i∈I
/

For the second half of eq (4), we have that


r(i) −
B(i, j)r(j))
(

where c is the damping factor in personalized PageRank, and 11×|S|
is a row vector of length |S| with all the elements set to 1s. It can
be shown that it is equivalent to eq. (3).
Notice that the goodness measure in eq (3) is independent on the
ordering of the different nodes in the subset S. If we simply change
the ordering of the nodes for the same subset S, it does not affect
the goodness score. However, as we will show in Section 4, we can

i∈T

=



(r(i) −

i∈T

=



i∈T j ∈J
/

1030

i∈T j∈J



B(i, j)r(j))

j∈J

B(i, j)r(j) ≥ 0

(6)

The last equality in eq (6) is due to the fact that r = Br, and each
element in r is non-negative.
Putting eq (4)-(6) together, we have that f(J ) ≥ f(I), which
completes the proof of P2.
2
P ROOF of P3. Again, let T = J \ I. Substituting eq (4) into
(f(I ∪ R) − f(I)) − (f(J ∪ R) − f(J )) and canceling the common
terms, we have
=

(f(I ∪ R) − f(I)) − (f(J ∪ R) − f(J ))


(
B(i, j)r(j) −
B(i, j)r(j))
i∈J j∈R

+

(

 

i∈I j∈R

B(i, j)r(j) −

i∈R j∈J ∪R

=

complexity in computation. This makes this strategy very slow, or
even infeasible, for a graph with more than a few thousand nodes.
Another possible solution for eq. (7) is to remove the quadratic
term in the objective function as follows. Starting from some initial indicator vector x̂, we iterate between the following two steps:
(1) approximate the objective function in eq. (7) by its first order
Taylor expansion around x̂; and (2) update x̂ by solving a binary
integer programming problem for the approximated objective function, which is linear wrt x. We refer to this strategy as ‘Ite-BIP’.
However, the two main issues still exist: (1) it is not clear how
such approximation will downgrade the overall optimization performance; (2) the binary integer programming itself, again, requires
polynomial time, which does not scale to large graphs.



 

B(i, j)r(j))

i∈R j∈I∪R

B(i, j)r(j) +

j∈R i∈T



B(i, j)r(j) ≥ 0

4.2 The Proposed D RAGON Algorithm

i∈R j∈T

Our proposed D RAGON algorithm is presented in Alg. 1. In step
1, we compute the ranking vector r (e.g., by the power method,
etc). Then after some initializations (steps 2-5), we select k nodes
one-by-one as follows. At each time, we compute the score vector
s in step 7. Then, we select one node with the highest score in the
vector s and add it to the subset S (steps 8-9). After that, we use the
selected node to update the two reference vectors u and v (steps 1011). Note that ‘⊗’ denote the element-wise product between two
matrices/vectors. Intuitively, the score vector s keeps the marginal
contribution of each node for the goodness measure given the current selected subset S. From step 7, it can be seen that at each
iteration, the values of such marginal contribution either keeps unchanged or decreases. This is consistent with P3 of Theorem 1 - as
there are more and more nodes in the subset S, the marginal contribution of each node is monotonically non-increasing. It is worth
pointing out that we use the original normalized adjacency matrix
A, instead of the ‘Google matrix’ B in Alg. 1. This is because for
many real graphs, the matrix A is often very sparse, whereas the
matrix B might not be3 . In the case B is dense, it is not efficient in
either time or space to use B in Alg. 1.
In Alg. 1, although we try to optimize a goodness measure that is
not affected by the ordering of different nodes in the subset, we can
still output an ordered list to the user based on in which iteration
these nodes are selected - earlier selected nodes in Alg. 1 are placed
at the top of the resulting top-k ranking list. This ordering naturally
meets the diminishing returns need when the user is seeking for a
diverse top-k ranking list as we analyzed in subsection 3.1.

Therefore, we have that f(I ∪ R) − f(I) ≥ f(J ∪ R) − f(J ),
which completes the proof of P3.
2

4.

THE PROPOSED ALGORITHM

In this section, we address Problem 2. Here, given the initial
query vector p and the budget k, we want to find a subset of k
nodes that maximizes the goodness measure defined in eq (3). We
first analyze the main challenges in optimizing eq (3); and then
present the proposed algorithm D RAGON, followed by some theoretical analysis and discussion.

4.1 Challenges
Problem 2 is essentially a subset selection problem to find the
optimal k nodes that maximize eq (3). Theorem 1 indicates that it
is not easy to find the exact optimal solution of Problem 2 - it is NPhard to maximize a monotonic submodular function if the function
value is 0 for an empty set [18]. For instance,
 a straight-forward
method would take exponential enumerations nk to find the exact
optimal k nodes, which is not feasible in computation even for a
medium size graph (e.g., with a few hundred nodes).
We can also formulate Problem 2 as a binary quadratic programming problem. Let xn×1 be a binary indicator vector (x(i) = 1
means node i is selected in the subset S, and 0 means it is not
selected). Problem 2 can be expressed as the following binary
quadratic programming problem:
min
Subject to:

x Dx
x(i) ∈ {0, 1}(i = 1, ..., n)
n

x(i) = k

4.3 Proofs and Analysis
Here, we analyze the optimality as well as the complexity of the
proposed algorithm. We show that our D RAGON leads to a nearoptimal solution, and at the same time it enjoys linear scalability
in both time and space.
Optimality. The optimality of the proposed D RAGON is given
in Lemma 1. According to Lemma 1, our D RAGON is near-optimal
- its solution is within a fixed fraction (1 − 1/e ≈ 0.63) from the
global optimal one. Given the hardness of Problem 2, such nearoptimality is acceptable in terms of optimization quality.

(7)

i=1

where D = (B−2In×n )diag(r), In×n is an identity matrix of size
n × n, and diag(r) is a diagonal matrix with r(i, i)(i = 1, ..., n)
being the diagonal elements.
Eq. (7) is still not easy to solve due to (1) the binary constrains on
the variable x and (2) the quadratic term in the objective function.
If we relax the binary constrain on x as 0 ≤ x(i) ≤ 1(i = 1, ..., n),
we can solve the relaxed problem by standard quadratic programming packages. We refer to this strategy as ‘Lin-QP’. However,
there are two major limitations of this method. First of all, we do
not know what the gap is between eq. (7) and its relaxed version.
Therefore, it is not clear how good the final solution is in terms of
maximizing the original goodness measure (eq (3)) even if we can
solve the relaxed problem optimally2 . Second, most, if not all, of
the existing quadratic programming packages require polynomial

L EMMA 1. Near-Optimality of D RAGON. Let S be the subset
found by D RAGON; |S| = k; and S ∗ = argmax|S|=k f(S). We
have that f(S) ≥ (1 − 1/e)f(S ∗ ), where e is the base of the natural
logarithm.
P ROOF. Omitted for Brevity

2

because the matrix D (1) might be asymmetric and (2) is not always semi-positive definite.
3
To see this, notice that B is a full matrix if p is uniform.

2

It is worth pointing out that it is not even easy to find an optimal solution for the relaxed problem by quadratic programming

1031

Algorithm 1 D RAGON for Problem 2
Input: The row-normalized adjacency matrix A of the graph, the
damping factor c, the query vector p, and the budget k;
Output: A subset of k nodes S.
1: Compute the ranking vector r: r = cA r + (1 − c)p;
2: Initialize S as the empty set; set u = v = 0n×1 ;
3: for i = 1 : n do
4:
Initialize ŝ(i) = (2 − cA(i, i) − (1 − c)p(i))r(i);
5: end for
6: for iter = 1 : k do
7:
Compute the score vector s = ŝ − u ⊗ r − v;
8:
Find i = argmaxj s(j)(j = 1, ..., n; j ∈
/ S);
9:
Add node i into S;
10:
Update u ← u + cA(:, i) + (1 − c)p(i)1n×1 ;
11:
Update v ← v + cA (:, i)r(i) + (1 − c)r(i)p;
12: end for
13: Return the subset S

Table 2: Comparison of different methods. Our proposed
D RAGON is the only method that leads to a near-optimal solution with linear scalability.
Measure

Optimality

Scalability

Convergence

ARW [42]
RRW [27]
D RAGON

NA
Partial
Yes

NA
NA
Near-optimal

No
Yes
Yes

Yes
NA
Yes

its optimization solution is. Moreover, RRW [27] introduced some
modifications and approximation techniques to the original vertex
reinforced random walk, and it is not clear how the modified vertex
reinforcement random walk converges4 .

5. EXPERIMENTAL EVALUATIONS

Time Complexity. The time complexity of the proposed D RAGON
is given in Lemma 2. According to Lemma 2, our D RAGON has
linear time complexity wrt the size of the graph. Therefore it is
scalable to large graphs in terms of computational time.
L EMMA 2. Time Complexity of D RAGON. The time complexity of Alg. 1 is O(m + nk).
P ROOF. Omitted for brevity.
2
We would like to point out that the proposed D RAGON can be
further sped up. Firstly, notice that the O(m) term in Lemma 2
comes from computing the ranking vector r (step 1) by the most
commonly used power method. There are a lot of fast methods for
computing r, either by effective approximation (e.g., [37]), or by
parallelism (e.g. [13]). These methods can be naturally plugged in
our D RAGON, which might lead to further computational savings.
Secondly, the O(nk) term in Lemma 2 comes from the greedy selection step in steps 6-12. Thanks to the monotonicity of f(S) as we
show in Theorem 1, we can use the similar lazy evaluation strategy
as [20] to speed up this process, without sacrificing the optimization quality.
Space Complexity. The space complexity of the proposed D RAGON
is given in Lemma 3. According to Lemma 3, our D RAGON has linear space complexity wrt the size of the graph. Therefore it is also
scalable to large graphs in terms of space cost.
L EMMA 3. Space Complexity of D RAGON. The space complexity of Alg. 1 is O(m + n + k).
P ROOF. Omitted for brevity.

Method

2

4.4 Discussion - Comparisons
In literature, there exist two other methods to encourage diversity
in the top-k ranking list for personalized PageRank. Here, we make
a comparison in terms of optimality, convergence, and scalability
of different methods. ARW [42] is based on an intuitive heuristic
by greedily selecting the highest ranked node and setting it as the
absorbing state. From theoretical point of view, it is not clear what
ARW [42] tries to optimize. And also, it requires a matrix inverse
of the same size of the graph, which is not scalable to large graphs.
RRW [27] is based on vertex reinforced random walk [31]. Compared with ARW [42], it makes an important step forward by providing some optimization explanations via defining a time-varying
objective function that changes at each iteration step. However, it is
still not clear what overall metric it tries to measure; and how good

In this section, we provide empirical evaluations for the proposed
D RAGON. Our evaluations mainly focus on (1) the effectiveness
and (2) efficiency of the proposed D RAGON.

5.1 Experimental Setup
Data sets. We use the DBLP publication data5 to construct a
co-authorship network, where each node is an author and the edge
weight is the number of the co-authored papers between the two
corresponding persons. Overall, we have n = 418, 236 nodes
and m = 2, 753, 798 edges. We also construct much smaller
co-authorship networks, using the authors from only one conference (e.g., KDD, SIGIR, SIGMOD, etc.). For example, KDD is the
co-authorship network for the authors in the ‘KDD’ conference.
These smaller co-authorship networks typically have a few thousand nodes and up to a few tens of thousands edges. We also construct the co-authorship networks, using the authors from multiple
conferences (e.g., KDD+SIGIR). For these graphs, we denote them
as Sub(n,m), where n and m are the numbers of nodes and edges in
the graph, respectively.
Machine configurations. For the computational cost and scalability, we report the wall-clock time. All the experiments ran on the
same machine with four 2.4GHz AMD CPUs and 48GB memory,
running Linux (2.6 kernel). For all the quantitative results, we randomly generate a query vector p and feed it into different methods
for a top-k ranking list with the same length. We repeat it 100 times
and report the average.
Evaluation criteria. To the best of our knowledge, there is no
universally accepted measure for diversity. In [27], the authors suggested an intuitive notion based on the density of the induced subgraph from the original graph A by the subset S. The intuition is as
follows: the lower the density (i.e., the less 1-step neighbors) of the
induced subgraph, the more diverse the subset S. Here, we generalize this notion to the t-step graph in order to also take into account
the effect of those in-direct neighbors. Let Sign(.) be a binary function operated element-wise on a matrix, i.e., Y = Sign(X), where
Y is a matrix of the same size as X, Y(i, j) = 1 if X(i, j) > 0,
Y(i, j) = 0 otherwise.
 We define the t-step connectivity matrix
Ct as Ct = Sign( ti=1 Ai ). That is, Ct (i, j) = 1 (0) means
that node i can (cannot) reach node j on the graph A within tsteps/hops. With this Ct matrix, we define the diversity of a given
subset S as eq (8). Here, the value of Div(t) is always between
0.5 and 1 - higher means more diverse. If all the nodes in S are
reachable from each other within t-steps, we say that the subset S
4
Even if it converges, its stationary state might not be unique according to [31].
5
http://www.informatik.uni-trier.de/˜ley/db/

1032

is the least diverse (Div(t) = 0.5). On the other extreme, If all the
nodes in S cannot reach each other within t-steps, the subset S is
the most diverse (Div(t) = 1).
1

Div(t) =
(8)
1 + i,j∈S,i=j Ct (i, j)/(|S| · (|S| − 1))
For the task of top-k ranking, the notion of diversity alone, though
important, might not be enough for the information need. For example, if we simply randomly select k nodes as the top-k ranking
list, these k nodes might not connected with each other at all given
that the length of the ranking list k is usually much smaller than
the number of nodes n in the graph. Therefore, it has a high diversity. However, it is unlikely that such a ranking list can well
fit the user’s information need since each of them might have very
low relevance score. In other words, a diversified top-k ranking list
should also have high relevance. That said, we will mainly focus
on evaluating how different methods balance between the diversity
and the relevance.
Notice that the relevance score for each individual node is often
very small on large graphs (since the L1 norm of the ranking vector
is 1). To make the two quantities (diversity vs. relevance) comparable with each other, we need to normalize the relevance scores.
Let Ŝ be the top-k ranking list by the original personalized PageRank, we define the normalized relevance score for a given subset
S(|S| = k) as eq (9). Since the personalized PageRank always
gives the k most relevant nodes, the Rel defined in eq (9) is always
between 0 and 1 - higher means more relevant.

r(i)
Rel = i∈S
(9)
i∈Ŝ r(i)

Figure 1: An illustrative example of a co-authorship network
with three communities. Given the query node 1 and the budget k = 3, the proposed D RAGON returns three relevant and
diversified nodes (2, 6, and 10, in black). In contrast, personalized PageRank returns nodes 2, 3 and 5 (all from the DM
community).
authors in the ranking list by personalized PageRank is somehow
redundant, in terms of helping the user to understand Prof. Yiming
Yang’s whole collaboration network. For example, Prof. Alex G.
Hauptmann is also from Carnegie Mellon University. Although, he
has a lot of co-authored papers with Yiming Yang, they are also coauthored with Jian Zhang and Rong Jin. Therefore, given that Jian
Zhang and Rong Jin are already in the ranking list, his existence
does not provide much marginal information about Yiming Yang’s
collaboration network. As a quantitative indicator, the average degree of the induced subgraph by D RAGON is only 2.8, which is
much lower (i.e., more diverse) than that by personalized PageRank (4.3). Finally, notice that for some authors, although they show
up in both lists, their positions in the ranking list are different. For
example, Jian-Yun Nie shows at the 4th and the 8th positions in the
two ranking lists, respectively. This is because Jian-Yun Nie makes
the top-4 authors more diverse compared with Thomas Pierce, although its individual relevance score is lower than the latter.

5.2 Effectiveness of

D RAGON: Case Studies
Let us start with an illustrative example to gain some visual intuitions. In Fig. 1, we show a fictitious co-authorship network, where
each node corresponds to an author (e.g., John, Smith, etc), and the
edge weight is the number of the co-authored papers. There are
three communities in this network (e.g., DM, DB and IR). From
Fig. 1, we can see that node 1 has very strong connections to the
DM community. In other words, DM might be his/her major research interest. In addition, s/he also has some connections to the
IR and DB communities. Given the budge k = 3, personalized
PageRank returns all the three nodes (nodes 2, 3 and 5) from DM
community which is consistent with the intuition since personalized PageRank solely focuses on the relevance. In contrast, the
proposed D RAGON returns nodes 2, 6, and 10, each of which is
still relevant enough to the query node 1. At the same time, they
are diversified from each other, covering the whole spectrum of
his/her research interest (DM, DB, and IR).
We also conduct cast studies on real graphs. We construct a
co-authorship networks from SIGIR (the major conference on information retrieval) and ICML (the major conference on machine
learning). We issue a query to find the top-10 co-authors for Prof.
Yiming Yang. The results are shown in Fig. 2. We compare it with
the original personalized PageRank. Yiming Yang is a professor
from Carnegie Mellon University; and she has broad interest in information retrieval and machine learning. From Fig. 2, we have
the following observations. Firstly, both D RAGON and personalized PageRank share the same authors for the top-3 returned authors, indicating that D RAGON also captures those highly relevant
authors wrt the querying author. Secondly, our D RAGON returns
a more diverse list of authors. For example, although ChengXiang
Zhai is not a co-author of Yiming Yang, they shares a lot of research
interest in information retrieval, and has a lot of indirect connections through other IR people. In contrast, the existence of some

5.3 Comparison with Alternative Methods for
Diversified Ranking on Graphs
We compare the proposed D RAGON with ARW [42] and RRW [27],
both of which also aim to improve the diversity of personalized
PageRank. We skip the comparison with MMR [6] for brevity
since [27] shows that its performance is not as good as RRW for
the graph-type data. For RRW [27], it has two variants based on
different approximation methods it actually uses: the one based on
the cumulative estimation (referred to as ‘RRW-a’) and the other
one based on the pointwise estimation (referred to as ‘RRW-b’).
First, let us compare how different methods balance between
the relevance and the diversity. Fig. 3 shows the results on the
NIPS co-authorship network. We test with different budgets (k =
10, 20, 30, 40, 50, 100). In Fig. 3, Div(1) means that we only consider 1-step neighbors to measure the diversity (i.e., setting t = 1
in eq (8)). Div(2) means that we consider both 1-step and 2-step
neighbors (i.e., setting t = 2 in eq (8)). We only present the results by RRW-a since RRW-b gives similar results. From Fig. 3,
we can see that all the three methods are effective to improve the
diversity. The proposed D RAGON achieves a better balance between the relevance and the diversity. For ARW, although it gives
the highest diversity score, its (normalized) relevance score is too
low - only about half of the other two methods. This is because
in ARW, only the first node is selected according to the relevance;

1033

Figure 2: Top-10 authors for Prof. Yiming
Yang. Our D RAGON return a relevant, but
more diverse list of authors. The difference
between the two lists is highlighted in black.

(a) Diversity by 1-step neighbors

(b) Diversity by 1- and 2-step neighbors

Figure 3: Diversity and Relevance trade-off of different methods.

and all the remaining (k-1) are selected by diversity. As for RRWa, both its relevance and diversity scores are lower than the proposed D RAGON. It is interesting to notice from Fig. 3(b) that the
diversity of RRW-a drops a lot when it is measured by within 2step neighbors (i.e., Div(2)). This is consistent with the intuition
of RRW. In RRW (both RRW-a and RRW-b), it achieves the diversity by encouraging 1-step neighboring nodes to compete with each
other. Consequently, the density of its within 1-step induced subgraph might low (i.e., high diversity), it is not necessary the case
for the within t-step (t ≥ 2) induced subgraph.
In order to test how the overall performance of different methods vary across different data sets, we take the average between
relevance and diversity scores. The results are presented in Fig. 4,
using four different co-authorship networks (SIGMOD, NIPS, SIGIR, SIGGRAPH). For the space limitation, we omit the results
when the diversity is measured by within 1-steps neighbors, which
is similar as the results by within 2-steps neighbors. It can be seen
that the proposed D RAGON consistently performs the best.

highest optimization quality (i.e., highest f(S)) with least amount
of wall-clock time. The normalized f(S) for ‘Lin-QP’ is missing
for Sub(24K,114K) because it fails to finish within 100,000 seconds. This indicates that it is not feasible for large graphs. For the
smaller graphs, ‘Lin-QP’ leads to slightly lower f(S) than the proposed D RAGON; but it requires 3-5 orders of magnitude wall-clock
time. For all the other comparative methods, they lead to worse
optimization quality with longer wall-clock time.

5.5 Scalability
We also evaluate the scalability of D RAGON. When we evaluate
the scalability wrt the number of the nodes in the graph, we fix the
number of edges and vice versa. The results in Fig. 7 are consistent with the complexity analysis in subsection 4.3 - the proposed
D RAGON scales linearly wrt both n and m, which means that it is
suitable for large graphs.

100

Here, we evaluate the effectiveness and the efficiency of the proposed D RAGON in terms of maximizing the goodness measure f(S).
We compared it with the two methods we introduced in subsection 4.1. We also compare it with two other heuristics. The first
method (referred to as ‘Heuristic1’) starts with generating a candidate pool (e.g., the top 10 × k most relevant nodes), picks one seed
node, and then repeatedly adds the most dis-similar (measured by
A) node into the ranking list from the candidate pool. The second
method (referred to as ‘Heuristic2’) also starts with generating a
candidate pool, puts all the nodes from candidate pool in the list,
and then repeatedly drops a most similar (measured by A) node
from the list.
First, let us evaluate how the different methods balance between
the optimization quality (measured by f(S)) and the speed (measured by wall-clock time). Fig. 5 shows the results from the coauthorship network of NIPS and KDD conferences with the budget
k = 20, where f(S) is normalized by the highest one among different methods. It can be seen that the proposed D RAGON is the
best - it leads to the highest optimization quality (i.e., highest f(S))
with the least amount of wall-clock time. Notice that the y-axis is
in logarithm scale.
We also conduct experiments on the co-authorship network constructed from multiple conferences. Fig. 6 shows the results on
these data sets with the budget k = 20. Here Sub(n,m) means a
co-authorship network with n nodes and m edges. We stop the
program if it takes more than 100,000 seconds (i.e., more than
10 days). It can be seen from Fig. 6 that the proposed D RAGON
is consistently best across all the different data sets - it leads to

90
80
70

100

K=5
K=20
K=50
K=100
K=200

average wall−clock time (sec)

average wall−clock time (sec.)

5.4 Comparison with Alternative Optimization Methods

60
50
40
30
20
10
1

90
80
70

K=5
K=20
K=50
K=100
K=200

60
50
40
30
20

1.5

2

2.5

3

# of nodes

3.5

10
0

4
5

x 10

(a) Time vs. # of nodes

0.5

1

1.5

# of edges

2

2.5
6

x 10

(b) Time vs. # of edges

Figure 7: Scalability of D RAGON. The proposed D RAGON
scales linearly wrt the size of the graph.

6. RELATED WORK
In this section, we review the related work, which can be categorized into four parts: ranking on graphs, diversity, set-level optimization for data mining and general graph mining.
Ranking on Graphs. Personalized PageRank is one of the most
fundamental and most widely used ranking methods on graphs. It
has been successfully applied to many high-impact applications [30,
11].Many other ranking methods on graphs are built upon, and/or
share the similar ideas as personalized PageRank, such as RalationalRank [9, 3], random walk with restart [37], SimRank [22],
etc. Because of its generality and wide applicability, we choose
Personalized PageRank as the starting point of our method. Other
ranking methods on graphs include HITS [15], electricity-based
methods [17], etc. There also exist a lot of work to speed-up the
computation of personalized PageRank, such as [37, 33, 13]. It
is worth pointing out that all these fast algorithms can be naturally
plugged into the proposed D RAGON to gain further savings in computational time.

1034

0.85
0.8
0.75
0.7

DRAGON
ARW
RRW_a
RRW_b

0.65
0.6
0.55
0.5
10

20

30

40

50

60

70

k

(a) SIGMOD

80

90

100

1

0.9
0.85
0.8
0.75
0.7

DRAGON
ARW
RRW_a
RRW_b

0.65
0.6
0.55
0.5
10

20

30

40

50

60

70

80

90

0.95
0.9
0.85

DRAGON
ARW
RRW_a
RRW_b

0.8
0.75
0.7
0.65
0.6
10

100

1

Ave. of Div(2) and Rel.

0.9

Ave. of Div(2) and Rel.

1
0.95

Ave. of Div(2) and Rel.

Ave. of Div(2) and Rel.

1
0.95

20

30

40

50

k

60

70

80

90

0.95
0.9
0.85
0.8
0.75
0.7

0.6
0.55
0.5
10

100

DRAGON
ARW
RRW_a
RRW_b

0.65

20

30

k

(b) NIPS

40

50

60

70

80

90

100

k

(c) SIGIR

(d) SIGGRAPH

Figure 4: Comparison with alternative methods for diversified ranking on graphs. The average of the relevance and the diversity vs.
the budget k (larger is better). The proposed D RAGON(red star) consistently performs the best.
>=100,000
DRAGON
Heuristic1
Heuristic2
Lin−QP
Ite−BIP

Normalized f(S)

0.8
0.7
0.6
0.5
0.4
0.3
0.2

Log Wall−clock Time (Sec.)

1
0.9

10,000

DRAGON
Heuristic1
Heuristic2
Lin−QP
Ite−BIP

1,000

100

10

1

0.1
0.1
0

Sub(2K,7K) Sub(5K,37K)

Sub(9K,37K)

Sub(11K,45K)

Sub(24K,114K)

0.01

Sub(2K,7K)

Sub(5K,19K)

Sub(9K,37K)

Sub(11K,45K)

Sub(24K,114K)

Figure 5: Wall-clock time vs. quality on the
NIPS+KDD co-authorship Network. The y(a) Comparison on the normalized f(S)
Comparison on wall-clock time
axis is in logarithm scale. The proposed
(higher is better)
(lower is better)
D RAGON is the best. It has the highest f(S)
Figure 6: Comparison of different optimization methods. Our D RAGON(the left most
with the least amount of time.
one) always leads to the highest f(S), with the least amount of time. Best viewed in color.
Diversity. It is now widely recognized that diversity is a highly
desired property in many data mining tasks, such as expertise and
legal search [32], recommendation system [43], blog filtering [7],
document summarization [6], etc. It is a powerful tool to address
the uncertainty and ambiguity; and/or to cover the different aspects
of an information need [32]. For the graph-type data, [42] was
among the first to address the diversified ranking on graphs. [27]
proposed to balance between the relevance and diversity based on
the vertex reinforcement random walk on graphs . However, they
suffer from some important subtle issues as we show in subsection 4.4. There are also a lot of algorithms to improve the diversity
for other types of data (e.g., document, etc), including [6, 41, 21],
etc.
Set-level Optimization for Data Mining. In the recent years,
set-level optimizationhas been playing a very important role in many
data mining tasks. Many set-level optimization problems are NPhard. Therefore, it is difficult, if not impossible, to find the global
optimal solutions. However, if the function is monotonic sub-modular
with 0 function value for the empty set, a greedy strategy can lead
to a provably near-optimal solution [18]. This powerful strategy
has been recurring in many different settings, e.g., immunization,
outbreak detection, blog filtering, sensor placement, influence maximization, structure learning, etc. (See [18] for a comprehensive review). In this paper, we introduce a new type of submodular function tailored for diversified ranking on large graphs.
General Graph Mining. There is a lot of work on graph mining.
Representative works include pattern and law mining [5], frequent
substructure discovery [39], compression [26], fraud and anomaly
detection [29], community mining and graph partition [14, 34, 25,
40], social action tracking [36], user click-through modeling [1, 2],
collaborative filtering [16, 8, 35, 12], term formation [19], network
classification [28], link prediction [23, 24, 4], etc.

1035

7. CONCLUSION
In this paper, we address the diversified ranking on large graphs
from an optimization point of view. To the best of our knowledge,
this is the first work for diversified ranking on large graphs that (1)
has a clear optimization formulation (see eq. (3)); (2) finds provably near-optimal solutions (see Theorem 1 and Lemma 1); and (3)
enjoys the linear scalability (see Lemma 2 and Lemma 3). Our experimental evaluations on real graphs validate that our method is
(1) indeed effective to balance the relevance and the diversity in
top-k ranking; and (2) scalable to large graphs.

8. ACKNOWLEDGEMENT
Research was sponsored by the Army Research Laboratory and
was accomplished under Cooperative Agreement Number W911NF09-2-0053. The views and conclusions contained in this document
are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army
Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.

9. REFERENCES
[1] C. L. 0001, F. Guo, and C. Faloutsos. Bbm: bayesian
browsing model from petabyte-scale data. In KDD, pages
537–546, 2009.
[2] D. Agarwal, A. Z. Broder, D. Chakrabarti, D. Diklic,
V. Josifovski, and M. Sayyadian. Estimating rates of rare
events at multiple resolutions. In KDD, pages 16–25, 2007.
[3] A. Angel, S. Chaudhuri, G. Das, and N. Koudas. Ranking
objects based on relationships and fixed associations. In
EDBT’09, pages 910–921, 2009.

[24] R. Lichtenwalter, J. T. Lussier, and N. V. Chawla. New
perspectives and methods in link prediction. In KDD, pages
243–252, 2010.
[25] A. S. Maiya and T. Y. Berger-Wolf. Sampling community
structure. In WWW, pages 701–710, 2010.
[26] H. Maserrat and J. Pei. Neighbor query friendly compression
of social networks. In KDD, pages 533–542, 2010.
[27] Q. Mei, J. Guo, and D. R. Radev. Divrank: the interplay of
prestige and diversity in information networks. In KDD,
pages 1009–1018, 2010.
[28] J. Neville, B. Gallagher, and T. Eliassi-Rad. Evaluating
statistical tests for within-network classifiers of relational
data. In ICDM, pages 397–406, 2009.
[29] C. C. Noble and D. J. Cook. Graph-based anomaly detection.
In KDD, pages 631–636, 2003.
[30] L. Page, S. Brin, R. Motwani, and T. Winograd. The
PageRank citation ranking: Bringing order to the web.
Technical report, Stanford Digital Library Technologies
Project, 1998. Paper SIDL-WP-1999-0120 (version of
11/11/1999).
[31] R. Pemantle. Vertex reinforced random walk. Prob. Th. and
Rel. Fields, pages 117–136, 1992.
[32] F. Radlinski, P. N. Bennett, B. Carterette, and T. Joachims.
Redundancy, diversity and interdependent document
relevance. SIGIR Forum, 43(2):46–52, 2009.
[33] P. Sarkar and A. W. Moore. Fast nearest-neighbor search in
disk-resident graphs. In KDD, pages 513–522, 2010.
[34] V. Satuluri and S. Parthasarathy. Scalable graph clustering
using stochastic flows: applications to community discovery.
In KDD, pages 737–746, 2009.
[35] H. Shan and A. Banerjee. Generalized probabilistic matrix
factorizations for collaborative filtering. In ICDM, pages
1025–1030, 2010.
[36] C. Tan, J. Tang, J. Sun, Q. Lin, and F. Wang. Social action
tracking via noise tolerant time-varying factor graphs. In
KDD, pages 1049–1058, 2010.
[37] H. Tong, C. Faloutsos, and J.-Y. Pan. Fast random walk with
restart and its applications. In ICDM, pages 613–622, 2006.
[38] L. Wu. Social network effects on performance and layoffs:
Evidence from the adoption of a social networking tool. Job
Market Paper, 2011.
[39] D. Xin, J. Han, X. Yan, and H. Cheng. Mining compressed
frequent-pattern sets. In VLDB, pages 709–720, 2005.
[40] X. Yin, J. Han, and P. S. Yu. Cross-relational clustering with
user’s guidance. In KDD, pages 344–353, 2005.
[41] Y. Yue and T. Joachims. Predicting diverse subsets using
structural svms. In ICML, pages 1224–1231, 2008.
[42] X. Zhu, A. B. Goldberg, J. V. Gael, and D. Andrzejewski.
Improving diversity in ranking using absorbing random
walks. In HLT-NAACL, pages 97–104, 2007.
[43] C.-N. Ziegler, S. M. McNee, J. A. Konstan, and G. Lausen.
Improving recommendation lists through topic
diversification. In WWW, pages 22–32, 2005.

[4] L. Backstrom and J. Leskovec. Supervised random walks:
predicting and recommending links in social networks. In
WSDM, pages 635–644, 2011.
[5] A. Broder, R. Kumar, F. Maghoul1, P. Raghavan,
S. Rajagopalan, R. Stata, A. Tomkins, and J. Wiener. Graph
structure in the web: experiments and models. In WWW
Conf., 2000.
[6] J. G. Carbonell and J. Goldstein. The use of mmr,
diversity-based reranking for reordering documents and
producing summaries. In SIGIR, pages 335–336, 1998.
[7] K. El-Arini, G. Veda, D. Shahaf, and C. Guestrin. Turning
down the noise in the blogosphere. In KDD, pages 289–298,
2009.
[8] Y. Ge, H. Xiong, A. Tuzhilin, K. Xiao, M. Gruteser, and
M. J. Pazzani. An energy-efficient mobile recommender
system. In KDD, pages 899–908, 2010.
[9] F. Geerts, H. Mannila, and E. Terzi. Relational link-based
ranking. In VLDB, pages 552–563, 2004.
[10] G. H. Golub and C. F. V. Loan. Matrix Perturbation Theory.
The Johns Hopkins University Press, 1996.
[11] T. H. Haveliwala. Topic-sensitive pagerank. WWW, pages
517–526, 2002.
[12] D. Heckerman, D. M. Chickering, C. Meek, R. Rounthwaite,
and C. M. Kadie. Dependency networks for collaborative
filtering and data visualization. In UAI, pages 264–273, 2000.
[13] U. Kang, C. E. Tsourakakis, and C. Faloutsos. Pegasus: A
peta-scale graph mining system. In ICDM, pages 229–238,
2009.
[14] G. Karypis and V. Kumar. Multilevel -way hypergraph
partitioning. In DAC, pages 343–348, 1999.
[15] J. M. Kleinberg. Authoritative sources in a hyperlinked
environment. J. ACM, 46(5):604–632, 1999.
[16] Y. Koren. Collaborative filtering with temporal dynamics. In
KDD, pages 447–456, 2009.
[17] Y. Koren, S. C. North, and C. Volinsky. Measuring and
extracting proximity in networks. In KDD, pages 245–255,
2006.
[18] A. Krause and C. Guestrin. Beyond convexity submodularity in machine learning. In ICML, 2008.
[19] T. Lappas, K. Liu, and E. Terzi. Finding a team of experts in
social networks. In KDD, pages 467–476, 2009.
[20] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, J. M.
VanBriesen, and N. S. Glance. Cost-effective outbreak
detection in networks. In KDD, pages 420–429, 2007.
[21] L. Li, K. Zhou, G.-R. Xue, H. Zha, and Y. Yu. Enhancing
diversity, coverage and balance for summarization through
structure learning. In WWW, pages 71–80, 2009.
[22] P. Li, H. Liu, J. X. Yu, J. He, and X. Du. Fast single-pair
simrank computation. In SDM, pages 571–582, 2010.
[23] D. Liben-Nowell and J. Kleinberg. The link prediction
problem for social networks. In Proc. CIKM, 2003.

1036

Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17)

Finding Cut from the Same Cloth: Cross Network Link
Recommendation via Joint Matrix Factorization
Arun Reddy Nelakurthi, Jingrui He
Arizona State University, Tempe, AZ, USA
{anelakur,jingrui.he}@asu.edu

from the other social networks. Motivated by this application, in this paper, we focus on cross network link recommendation, which aims to identify similar actors across multiple heterogeneous social networks. In this way, we will be
able to form support groups consisting of patients from multiple disease-speciﬁc networks, all sharing the same questions and concerns.
The problem setting studied in this paper is similar and
yet signiﬁcantly different from existing work on cross network link prediction. In particular, existing work either links
different accounts belonging to the same user across multiple social networks (Zhang et al. 2015), or links users with
complementary expertise or interest (Tang et al. 2012). In
contrast, we aim to ﬁnd similar users using different social
networks, which enables them to exchange important information regarding their shared questions or concerns.
Based on the observation that different disease-speciﬁc
social networks tend to share the same topics as well as
the interests of user groups in certain topics, we propose to
jointly decompose the user-keyword matrices from these social networks, while requiring them to share the same topics
and user group-topic association matrices. To be speciﬁc,
we form a generic optimization framework, and instantiate
it with variations of the constraints. Then we propose an iterative optimization algorithm and analyze its performance
from multiple perspectives. Finally, we test the performance
of this algorithm on various real-world data sets, which outperforms state-of-the-art techniques.
The rest of the paper is organized as follows, Section 2
discusses the related work in the ﬁeld of link prediction and
non-negative matrix factorization. Section 3 formalizes the
problem of cross network link prediction and describes the
proposed approach as well as the optimization algorithm. In
Section 4, we evaluate the performance of our proposed algorithm and discuss the results on different data sets. Finally, we conclude the paper in Section 5.

Abstract
With the emergence of online forums associated with major
diseases, such as diabetes mellitus, many patients are increasingly dependent on such disease-speciﬁc social networks to
gain access to additional resources. Among these patients, it
is common for them to stick to one disease-speciﬁc social network, although their desired resources might be spread over
multiple social networks, such as patients with similar questions and concerns. Motivated by this application, in this paper, we focus on cross network link recommendation, which
aims to identify similar users across multiple heterogeneous
social networks. The problem setting is different from existing work on cross network link prediction, which either tries
to link accounts of the same user from different social networks, or aims to match users with complementary expertise
or interest.
To approach the problem of cross network link recommendation, we propose to jointly decompose the user-keyword matrices from multiple social networks, while requiring them to
share the same topics and user group-topic association matrices. This constraint comes from the fact that social networks
dedicated to the same disease tend to share the same topics as
well as the interests of users groups in certain topics. Based
on this intuition, we construct a generic optimization framework, provide four instantiations and an iterative optimization
algorithm with performance analysis. In the experiments, we
demonstrate the superiority of the proposed algorithm over
state-of-the-art techniques on various real-world data sets.

1

Introduction

Nowadays, online social networks has become an important portal for patients with major diseases, such as diabetes
mellitus, to connect with physicians as well as other patients. Compared with the generic social networks such as
Twitter and Facebook, the disease-speciﬁc social networks
(e.g., TuDiabetes (2016) and DiabetesSisters (2016)) have a
greater concentration of patients with similar conditions, and
the patients expect to obtain additional resources from these
social networks. However, when it comes to using these social networks, it is often the case that a patient would stick
to a single social network, and rarely look at the other social
networks, thus limiting their access to the online resources,
especially the patients with similar questions and concerns

2

Related Work

In this section, we brieﬂy review the related work on link
prediction and non-negative matrix factorization.
Link prediction is a widely studied problem in the ﬁeld
of Social Network Analysis (Liben-Nowell and Kleinberg
2007; Al Hasan and Zaki 2011; Wang et al. 2014). Link
prediction can be broadly classiﬁed into two types: (1)

c 2017, Association for the Advancement of Artiﬁcial
Copyright 
Intelligence (www.aaai.org). All rights reserved.

1467

Classical link prediction which aims at predicting the missing links in a given social network (Al Hasan et al. 2006;
Fortunato 2010); (2) Cross network link prediction that recommends the links across two or more social networks.
Tang et al. (2012) modeled users as feature vector with indomain and cross-domain topic distributions, and used it to
learn associations between users across source and target
domains. Kong, Zhang, and Yu (2013) suggested a multinetwork anchoring algorithm to discover the correspondence
between accounts of the same user in multiple networks.
Zhang et al. (2015) proposed an energy-based framework
COSNET for cross network link prediction in heterogeneous
networks. Our problem differs with previous cross network
link prediction problems, as we recommend links between
similar actors across social networks.
Non-negative matrix factorization (NMF) is widely used
for co-clustering problems. Li and Ding (2006) demonstrated a NMF framework for document-word co-clustering.
Cai et al. (2011) improved Li and Ding (2006) framework
by adding a graph regularizer which captures geometric information embedded in the data. Gu, Ding, and Han (2011)
proposed an orthogonal framework to ﬁx scaling problem in Cai et al. (2011). Wang, Nie, and Huang (2015)
proposed a NMF based Dual Knowledge Transfer approach for cross-language Web page classiﬁcation. Our
approach differs from previous works as we jointly factor user-keyword matrices from multiple social networks
to learn latent features on the combined set of keywords
from all the social networks and users from each social
network. Chakraborty and Sycara (2015) proposed a constrained NMF framework for community detection in social
networks which is closely related to our work. Our problem
is different from the community detection problem, which
ﬁnds communities of closely related actors inside a single
social network, whereas we ﬁnd closely related actors across
multiple social networks.

3

Figure 1: Cross network link prediction problem: A) Two
social networks with user nodes represented by circles and
user-user associations represented by edges joining two
nodes. Different colors represent different user groups. B)
User-keyword bipartite graph, circles represent users from
different social networks, squares represent keywords from
vocabulary space for different social networks. Dotted lines
link the users to unique keywords in a social network and
solid lines link users to shared keywords. C) Dotted lines
represent the recommended links between similar actors
across social networks.
social networks. The goal of cross network link recommendation is to identify similar actors across multiple social networks. This is different from existing work on cross network
link prediction which focuses on linking different accounts
of the same user, or ﬁnding users with complementary expertise or interest.

Let Gk = VkU , VkW , EkU W  denote the undirected userkeyword bipartite graph for the k th social network, where
VkW is the set of keyword nodes |VkW |= nk and EkU W ⊆
VkU × VkW is the set of edges connecting the user nodes and
the keyword nodes. Let Xk ⊂ Rmk ×nk be the user-keyword

adjacency matrix constructed from the bipartite graph Gk ,
k = 1, . . . , K. Let d be the size of the vocabulary for all the
social networks combined, i.e., |V1W ∪ V2W ∪ .. ∪ VKW |= d.
Figure 1 illustrates the cross network link recommendation problem with two social networks K = 2. Figure 1(A)
shows the user-user connection graphs G1 and G2 . Figure

1(B) represents the user-keyword bipartite graphs G1 and

G2 . Figure 1(C) represents the problem of cross network
link recommendation that recommends links between user
nodes from different social networks G1 and G2 .

Cross Network Link Recommendation

In this section, we formally introduce the cross network
link recommendation problem, followed by the proposed
generic optimization framework and its instantiations. Then
we present the iterative optimization algorithm as well as its
performance analysis.

3.1

Notation and Problem Deﬁnition

Suppose that we have K disease-speciﬁc social networks:
Gk = VkU , EkU , k = 1, . . . , K, where VkU is the set of user
nodes |VkU |= mk and EkU ⊆ VkU × VkU is the set of edges
representing the connection between users in the same social network. Self-connections and multiple links between
two user nodes are not allowed. Let Ak ⊂ {0, 1}mk ×mk
denote the user-user adjacency matrix for the k th social network k = 1, . . . , K, where the edge weight is set to 1
if there is a connection between two users. Notice that
we focus on the more challenging case where: (1) there
are no shared user nodes across the social networks, i.e.,
ViU ∩ VjU = Ø, i = j ∀ i, j = 1, . . . , K, and (2) there are no
cross network links available between the users in different

Problem. Cross network link prediction across multiple social networks.
Input: The input to the problem is a set of user-user
adjacency matrices {A1 , A2 , . . . , AK } constructed from
user relationship graphs Gk , k = 1, . . . , K and a set
of user-keyword adjacency matrices {X1 , X2 , . . . , XK }

constructed from user-keyword bipartite graphs Gk , k =
1, . . . , K.
Output: A set of cross network links E U ⊆ ViU × VjU
connecting similar user nodes ViU from the social network
Gi to user nodes VjU from the social network Gj , where i = j
and i, j = 1, . . . , K.

1468

3.2

In order to identify the similar actors across multiple
disease-speciﬁc social networks, we propose to perform coclustering on user-keyword graphs to learn the representation of users and keywords in a latent feature space, and
then recommend the links between similar actors across the
networks through the respective user latent features learned
from each network. To be speciﬁc, we propose a constrained
non-negative matrix tri-factorization (NMTF) approach with
a graph regularizer obtained from the user-user adjacency
matrices.
We begin by considering existing NMTF approaches
and later introduce our approach for link recommendation.
NMTF as shown in eq (1) involves decomposing a matrix
X ⊂ Rm×n , into three non-negative latent factor matrices
F ⊂ Rm×p
, S ⊂ Rp×o
and G ⊂ Rn×o
that can best ap+
+
+
proximate X. For example, in the context of social network
analysis, given the user-keyword matrix for a social network,
NMTF co-clusters users and keywords into p user groups
and o keyword groups.
X = FSGT





Xk − Fk Sk GTk 2 − αk tr FTk Ak Fk
F


T 
− Gk Ak Gk

min

Matrix Factorization for Cross Network Link
Recommendation

(3)

Fk ≥ 0, Sk ≥ 0, Gk ≥ 0, k = 1, . . . , K

s.t.



FTk Dk Fk = I, GTk Dk Gk = I




where Ak is the keyword-keyword adjacency matrix, Dk =

 ij
j Ak is the degree matrix, I is the identity matrix of the
appropriate size. The main difference between GNMF eq (2)
and IGNMTF eq (3) is the orthogonal constraints, which ﬁx
both the scale transfer and trivial solution problems. Without
the constraints the optimization problem in eq (2) can be
seen as a special case of eq (3) by absorbing Sk into Fk .
Also, as shown in Nie et al. (2010) when orthonormal and
non-negative constraints of Fk and Gk are simultaneously
satisﬁed, then it can be proved that in each row of Fk and
Gk , only one element could be positive and others are zeros,
which can be directly used to assign cluster labels to data
points.

3.3

Proposed Framework

As shown in the last subsection, existing work on NMTF
is designed for a single social network, and cannot be readily applied to model multiple social networks and identify
similar actors. Notice that disease-speciﬁc social networks
often share the same set of topics. For example, for diabetesspeciﬁc social networks, the set of topics usually include
Type I diabetes, Type II diabetes, gestational diabetes, diet
and exercise, etc. Furthermore, the users of these social networks tend to form the same groups with interest in certain
topics. For example, on both TuDiabetes and DiabetesSisters, there are user groups associated with Type I diabetes,
Type II diabetes and gestational diabetes. Based on this observation, in this subsection, we present our proposed optimization framework named CrossNet, which jointly decomposes the user-keyword matrices from multiple social networks, while requiring them to share the same topics as well
as user group-topic association matrices.

(1)

Cai et al. (2011) proposed a co-clustering method called
Graph based non-negative matrix factorization (GNMF) that
adds a graph regularizer to NMF imposing manifold assumptions. The factors for multiple social networks can be
computed individually through K subproblems as follows:


2

min Xk − Fk GTk F + αk tr FTk Lk Fk
(2)
s.t. Fk ≥ 0, Gk ≥ 0, k = 1, . . . , K
where tr(.) is the trace of the matrix, Lk = Dk − Ak
is the graph Laplacian of user-user adjacency matrix Ak ,
 ij
Dk =
j Ak is the degree matrix, αk is the regularization parameter on the user groups and ||.||2F is the Frobenius
norm. The ﬁrst term in the objective function minimizes the
reconstruction error and the second term is a manifold regularizer on user-user relations which incorporates the geometric information of the data.If two users are closely connected
to each other, they belong to the same group.
Gu, Ding, and Han (2011) and Huang et al. (2014)
showed that when regularization parameter αk is set to a
large value GNMF ends up in a trivial solution, associating
all the users to one group. Also GNMF is prone to scale
transfer problems, when the parameters in the objective
function multiplied by any scalar (γ > 1) results in a
solution which is different from the optimal solution. To
ﬁx these two issues, Gu, Ding, and Han (2011) proposed a
graph based NMTF approach (IGNMTF), with three factors
and orthogonal constraints to allow more degrees of freedom between user and keyword latent factors. Huang et al.
(2014) added orthogonal constraints to eq (2) to ﬁx scale
transfer problems. Similar as before, we have the following
K subproblems:

K 





Xk − Fk SGT 2 + αk tr FTk Lsk Fk
F

min

k=1

s.t.

NF (Fk ), NG (G), NS (S)
OF (Fk ), OG (G), k = 1, . . . , K

(4)
= I−
is the symmetric normalwhere
ized Laplacian of the user-user adjacency matrix Ak , NF (·),
NG (·), and NS (·) denote the non-negative constraint on a
certain matrix, OF (·) and OG (·) denote the orthogonal constraint on the input matrix. Notice that we use the symmetric
normalized Laplacian as it provides more robust results as
compared to the one used in eq (2).
Compared with eq (2) and eq (3), the major difference
is that we couple the K subproblems by requiring them to
share the same matrices S and G. This is because multiple
disease-speciﬁc social networks tend to share the same topics (G) as well as the user group-topic matrix S. Depending
Lsk

1469

−1
−1
D k 2 Ak D k 2

The Lagrangian multiplier Λk is calculated as given in the
(Ding et al. 2006) by summing up across i index. That gives

on the speciﬁc form of the non-negative constraint N (·) and
the orthogonal constraint O(·), CrossNet can be instantiated
in four different ways as follows.
CrossNet-I:
Fk ≥ 0, G ≥ 0

(5)
Gi,j = 1, k = 1, . . . , K.
FT Fk = IF ,

Λk = FTk Xk GST − SGT GST − αk FTk Lsk Fk
As Λk has negative components, it can be expressed as a
−
difference of two non-negative components Λk = Λ+
k −Λk ,
|Λk |+Λk
|Λk |−Λk
and Λ−
. Substituting the
where Λ+
k =
k =
2
2
non-negative components in the equation (3.4) we get

k

j

CrossNet-II:
Fk ≥ 0, S ≥ 0, G ≥ 0

FTk Fk = IF ,
Gi,j = 1, k = 1, . . . , K.

(Fk SGT GST + αk Lsk Fk − Xk GST − Dk Fk Λ+
k

ij ij
+Dk Fk Λ−
k ) Fk = 0

(6)

j

CrossNet-III:
Fk ≥ 0, G ≥ 0
FTk DF Fk = IF ,



Gi,j = 1, k = 1, . . . , K.

As the constraint, I − FTk Dk Fk is symmetric, As suggested in (Gu, Ding, and Han 2011) we have tr(Λk (I −
FTk Dk Fk )) = tr((I−FTk Dk Fk )ΛTk ). Therefore only symmetric part of Λk contributes to L. So Λk should be sym
Λ +ΛT
metric, we use Λk = k 2 k instead of Λk . This leads to
the following update rule for calculating Fk :
	

ij





Xk GST + Dk Fk Λk+


ij 

Fij
ij
k ⇐ Fk  

Fk SGT GST + αk Lsk Fk + Dk Fk Λk−

(7)

j

CrossNet-IV:
Fk ≥ 0, S ≥ 0, G ≥ 0

FTk DF Fk = IF ,
Gi,j = 1, k = 1, . . . , K.

(8)

j

Notice that in all four instantiations, the orthogonal constraint on G is designed in such a way that its row sums are
equal to 1. In this way, we allow the keywords to be part of
multiple keyword groups (topics) instead of a single one.

3.4

(10)
Computing G: Fixing S and Fk , setting ∇L(G) = 0 and
following the similar steps in computing Fk we get the following update rule for G:
	
ij

 


T
TF S
X


k
t=1
k
Gij ⇐ Gij 

(11)
ij
  T
T T
t=1 S Fk Fk SG

Optimization Algorithm

In this subsection we provide the optimization algorithm for
CrossNet with the constraint instantiation in eq (8). The algorithm for the other instantiations can be designed in a similar way. The objective function in eq (4) that we minimize
is the following sum of squared residuals:
K  


tr XTk Xk − 2GT XTk Fk S + FTk Fk SGT GST
f=


The orthogonal constraint j Gi,j = 1 on G is enforced by
row normalizing the G factor after every iteration.
Computing S: Fixing G and Fk , setting ∇L(S) = 0 and
following the similar steps in computing Fk we get the following update rule for S:
	
ij


 


K
TX G
F


k
k=1
k
Sij ⇐ Sij 

(12)
ij
 K 
T
T
k=1 Fk Fk SG G

k=1



+ αk tr FTk Lsk Fk
Following the standard theory of constrained optimization, we introduce the following Lagrangian function where
Lagrange multiplier Λk enforce the constraints FTk Dk Fk =
I in eq (8).
L=

K  


tr XTk Xk − 2V T XTk Fk S + FTk Fk SGT GST

Theorem 1. The objective function in eq (5) is lowerbounded, and monotonically decreasing (non-increasing)
with the update rules eq (10), eq (11) and eq (12). Hence
CrossNet converges.

k=1





+ αk tr FTk Lsk Fk + Λk I − FTk Dk Fk

Proof Sketch. First of all, it is easy to see that the objective
function in eq (5) is lower-bounded. Second, it consists of
two terms, and it sufﬁces to show that each of these terms is
monotonically decreasing. As the second term depends on
U only, the update functions are similar between CrossNet
and general NMTF. Following the steps in (Ding et al. 2006;
Gu, Ding, and Han 2011), it can be shown that the ﬁrst term
is monotonically decreasing under the update rules. For the
second term, by introducing an auxiliary function as in (Cai
et al. 2011), it can be shown that the second term is also

(9)
Computing Fk : Fixing S and G, the gradient ∇L(Fk ) is
∇L(Fk ) = 2(Fk SGT GST + αk Lsk Fk − Xk GST − Dk Fk Λk )

By the KKT complementary slackness we have
∇L(Fk )ij Fij
k = 0, so
(Fk SGT GST +αk Lsk Fk −Xk GST −Dk Fk Λk )ij Fij
k =0

1470

Algorithm 1: CrossNet Algorithm
Input: A set of user-user adjacency matrices
{A1 , A2 , . . . , AK } constructed from user
relationship graphs Gk , k = 1, . . . , K and a set
of user-keyword adjacency matrices
{X1 , X2 , . . . , XK } constructed from
user-keyword bipartite graphs

Gk , k = 1, . . . , K. The regularization parameter
αk . Number of iterations t.
Output: The user latent factors Fk for all the
disease-speciﬁc social networks
k = 1, . . . , K.
1 Initialize the factor matrices Fk and G using k-means.
2 for i ← 1 to t do
3
Update S using eq (12)
4
Update G using eq (11)
5
Update Fk using eq (10) ∀ k = 1, . . . , K
6 end
7 Return user latent factors Fk .

Artiﬁcial Intelligence (cs.AI)
Computer Vision (cs.CV)
Databases (cs.DB)
Machine Learning (cs.LG)
Software (cs.SE)

6972
5321
2070
7321
2753

10272
10156
4297
11103
5514

diabetes

# posts

# nodes # edges

Diabetes Sisters
TuDiabetes

2643
3742

750
1032

4

31266
19284
6492
39349
18462

4118
6323

Experimental Results

In this section we compare CrossNet with other state-of-theart approaches on an academic publications data set. We
also demonstrate the effectiveness of CrossNet through a
case study on a diabetes-speciﬁc social network data set.

4.1

Data Sets

The ﬁrst data set is from the online repository of electronic preprints arXiv (2016), which contains scientiﬁc papers related to artiﬁcial intelligence (cs.AI), computer vision
(cs.CV), databases (cs.DB), machine learning (cs.LG) and
software (cs.SE) categories in the ﬁeld of computer science.
Each category represents a social network with user-user
associations based on the co-authorship information. Keywords are extracted from the abstract of each scientiﬁc paper. For each author (user), we combine all the abstracts
from the papers authored or co-authored by the author. The
ground truth for this data set is computed from the existing
cross network links (authors common to different networks).
The neighborhood formation algorithm based on RWR is
used to estimate the cross network link associations.
We also demonstrate the applicability of CrossNet to a
real world setting through a case study on diabetes-speciﬁc
social networks. The user posts from two diabetes-speciﬁc
social networks – TuDiabetes (2016) and DiabetesSisters
(2016) are crawled. The user-user associations in the forums
are missing, so we considered the users who post in any
given thread as related, i.e., there exists an edge between the
users responding to the same thread. Keywords are extracted
from the posts. Several pre-processing steps were taken
before the experiments, including stemming, stop word removal, etc. Each user is represented as a binary feature vector with bag of words with n-grams n = {1, 2, 3}. Table 1
shows the data set statistics.

Link Recommendation

Using NMTF we represent the users in a latent feature space
shared across all the networks. For link prediction we leverage the learned shared user space along with user associations in each social network. We combine user-user associations and user-user latent features space as a graph. We use
neighborhood formation using random walk with restarts
(RWR) (Sun et al. 2005) to learn the cross network useruser relations. As the social networks are dynamic in nature
(users join and leave over time), our approach is more robust and works for new users as we can leverage user-user
associations to predict links between cross network users.

3.6

# papers # nodes # edges

Table 1: Statistics of arXiv and diabetes-speciﬁc social network data sets.

monotonically decreasing. Putting everything together, the
update rules converge to the local optimal solution. Hence
CrossNet converges. Details omitted due to space limit.
With the update rules eq (10), eq (11) and eq (12) the optimization algorithm for link prediction problem is presented
in the Algorithm 1.

3.5

arXiv

Complexity Analysis

The user-keyword matrix X ⊂ Rm×n is typically very
sparse . Using NMTF, X is factorized into three latent factors as shown in eq (1). Updating Fk , S and G using a
multiplicative update algorithm takes O(k 2 (m + n)) in each
iteration for computation. And other O(zk) cost for component wise addition where z << mn is the number of
non-zero elements in X. Using the multiplicative algorithms
for sparse computation, the efﬁciency of our algorithm can
be improved tremendously. As the value of k is very small
(usually < 100), we can consider that the algorithm is linear per computation. Empirically we found that number of
iterations it takes to converge is t < 100. So the total cost of
complexity is O(tk 2 (m + n) + tkz) which is still linear. So
computationally, CrossNet scales to large data sets.

4.2

Experiment Setup

We compare the proposed CrossNet approaches with other
state-of-the-art approaches including: (1) GNMF (Cai et al.
2011); (2) IGNMTF (Gu, Ding, and Han 2011); (3) CoupledLP (Dong et al. 2015) modiﬁed for cross network links;
and (4) COSNET (Zhang et al. 2015).
We have used Precision at K (P@K) as an evaluation metric to compare the performance of different algorithms. It

1471

DB - SE
DB - LG
LG - SE
AI - LG
AI - CV
CV - LG
P@10 P@20 P@10 P@20 P@10 P@20 P@10 P@20 P@10 P@20 P@10 P@20
GNMF
IGNMTF
CoupledLP
COSNET
CrossNet - I
CrossNet - II
CrossNet - III
CrossNet - IV

15.48
26.28
23.4
31.68
35.28
36.12
35.28
35.41

12.84
18.36
20.28
29.88
30.48
30.59
30.36
30.63

12.88
18.92
31.58
35.8
36.71
36.94
36.59
37.05

12.77
16.3
21.77
26.56
32.95
33.29
33.17
33.63

8.64
24.25
24.64
31.99
33.8
34.06
33.93
34.19

8.77
18.96
24.12
28.64
31.48
31.61
31.48
31.73

18.72
33.23
37.86
47.58
44.62
44.77
44.77
45.08

17.47
30.26
40.87
45.86
42.73
42.32
42.54
42.81

15.03
22.08
36.84
41.76
42.83
43.09
42.69
43.23

14.9
19.02
25.4
30.99
38.44
38.84
38.7
39.24

11.73
32.9
33.43
43.4
45.85
46.2
46.03
46.38

11.9
25.73
32.73
38.85
42.7
42.88
42.7
43.05

Table 2: arXiv results
topic-1
healthy eating

topic-2
insurance

topic-3
exercise

topic-4
products

topic-5
diet

topic-6
diagnosis

topic-7
research

food12
medical insurance12 running12
pump12
insulin12
diagnosed12
patients study1
12
12
2
12
12
12
healthy eating
cost information
ginger
cgm
dose
diabetes
levels12
12
12
1
12
12
12
carbs
money
training
minimed
carbs
family doctor
doctor12
2
12
12
1
12
12
protein
insulin supplies
yoga
infusion pumps
low carb
hospital
ADA 1
1
2
12
12
2
12
veggies
strips
gym
insulin use
high day
symptoms
people12
12
12
12
12
12
12
bread
companies
workout
omnipod
bg
months
clinical treatment1
diet12
doctors12
muscle2
pumping set12 basal hours12 told diabetic12 disease research2
Table 3: Diabetes keyword groups (top 7).

1

represents keywords from Diabetes Sisters, 2 from TuDiabetes and 12 from both.
factorization approach clustered similar keywords from different networks into one group. The following is an example of two posts generated by two users from different social
networks, between whom CrossNet recommends a link.

computes the percentage of the relevant links among the topK links predicted by the algorithm. For evaluation we compute P@10 and P@20 for all the algorithms and data set
combinations. Here relevant links refer to the links between
similar actors across the networks.
Regarding the parameters, we use grid-search to set regularization parameters α1 = α2 = 0.01 for CrossNet, the
number of user groups and keyword groups o = p = 40 and
iterations t = 100. From the results in Table 2 CrossNet outperforms all other approaches. Jointly factorizing keywords
across all the networks through G resulted in signiﬁcant improvement over GNMF and IGNMF approaches. CrossNet
outperformed modiﬁed CoupledLP as it uses both the useruser associations and user-keyword bipartite graphs unlike
CoupledLP that relies on user-user network structure only.
COSNET performs closely as it leverages both the user-user
and user-keyword graphs, but it identiﬁes the distinct useruser links across networks to the similar ones. Among the
four constraint instantiations, setting S ≥ 0 and orthogonal
constraint with degree matrix led to a better performance.

4.3

User A: I have been diagnosed with Type 1 for about 5 years.
I had my blood glucose with an A1C over 9. I am worried!
User B: I am a 22 year old female recently diagnosed type 1
diabetic. I found out that my blood glucose was over 400. I
came here looking for support.
As we can see, both users are concerned about their blood
glucose level and have been diagnosed with Type I diabetes.

5

Conclusion

In this paper, motivated by the use of disease-speciﬁc social networks, we studied the problem of cross network link
recommendation, where we aim to identify similar patients
across multiple heterogeneous networks, such that they can
form support groups to exchange information and resources.
This is different from existing work on cross network link
prediction where the goal is to link accounts belonging to
the same user from different social networks or to ﬁnd users
with complementary expertise or interests. To address this
problem, we propose an optimization framework named
CrossNet with four instantiations, which can be solved using an iterative algorithm. The performance of the proposed
algorithm is evaluated both analytically in terms of convergence and computational complexity, and empirically on
various real data sets.

Case Study

We also conduct a case study on diabetes-speciﬁc social networks. Notice that CrossNet has two steps: (1) jointly decomposing the user-keyword matrices from each network
into respective user factors and a combined keyword latent
factor matrix; (2) using RWR on user-user associations and
user factor matrices for each network to recommend links
between similar actors across different networks. Table 3
shows the keyword latent factors from all the networks combined (K = 2, p = 7). It can be observed that our joint

1472

Acknowledgements

Nie, F.; Ding, C.; Luo, D.; and Huang, H. 2010. Improved
minmax cut graph clustering with nonnegative relaxation. In
Proceedings of the 2010 European Conference on Machine
Learning and Knowledge Discovery in Databases: Part II,
ECML PKDD’10, 451–466. Berlin, Heidelberg: SpringerVerlag.
Sun, J.; Qu, H.; Chakrabarti, D.; and Faloutsos, C. 2005.
Neighborhood formation and anomaly detection in bipartite
graphs. In Fifth IEEE International Conference on Data
Mining (ICDM’05), 8 pp.–.
Tang, J.; Wu, S.; Sun, J.; and Su, H. 2012. Crossdomain collaboration recommendation. In Proceedings of
the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’12, 1285–1293.
New York, NY, USA: ACM.
TuDiabetes. 2016. A community of people touched by diabetes, a program of the diabetes hands foundation. [Online;
accessed 29-November-2016].
Wang, P.; Xu, B.; Wu, Y.; and Zhou, X. 2014. Link prediction in social networks: the State-of-the-Art.
Wang, H.; Nie, F.; and Huang, H. 2015. Large-scale
cross-language web page classiﬁcation via dual knowledge
transfer using fast nonnegative matrix trifactorization. ACM
Trans. Knowl. Discov. Data 10(1):1:1–1:29.
Zhang, Y.; Tang, J.; Yang, Z.; Pei, J.; and Yu, P. S.
2015. COSNET: Connecting heterogeneous social networks
with local and global consistency. In Proceedings of the
21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’15, 1485–1494.
New York, NY, USA: ACM.

This work is supported by the NSF research grant IIS1552654, ONR research grant N00014-15-1-2821, and an
IBM Faculty Award. The views and conclusions are those
of the authors and should not be interpreted as representing
the ofﬁcial policies of the funding agencies or the government.

References
Al Hasan, M., and Zaki, M. J. 2011. A survey of link prediction in social networks. In Social Network Data Analytics.
Springer US. 243–275.
Al Hasan, M.; Chaoji, V.; Salem, S.; and Zaki, M. 2006.
Link prediction using supervised learning. In SDM06: workshop on link analysis, counter-terrorism and security.
arXiv. 2016. arxiv.org e-print archive. [Online; accessed
29-November-2016].
Cai, D.; He, X.; Han, J.; and Huang, T. S. 2011. Graph
regularized nonnegative matrix factorization for data representation. Pattern Analysis and Machine Intelligence, IEEE
Transactions on 33(8):1548–1560.
Chakraborty, Y. P. N., and Sycara, K. 2015. Nonnegative
matrix tri-factorization with graph regularization for community detection in social networks.
DiabetesSisters. 2016. Diabetessisters. [Online; accessed
29-November-2016].
Ding, C.; Li, T.; Peng, W.; and Park, H. 2006. Orthogonal nonnegative matrix t-factorizations for clustering. In
Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD
’06, 126–135. New York, NY, USA: ACM.
Dong, Y.; Zhang, J.; Tang, J.; Chawla, N. V.; and Wang, B.
2015. CoupledLP: Link prediction in coupled networks. In
Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD
’15, 199–208. New York, NY, USA: ACM.
Fortunato, S. 2010. Community detection in graphs. Physics
reports 486(3):75–174.
Gu, Q.; Ding, C.; and Han, J. 2011. On trivial solution and
scale transfer problems in graph regularized nmf. In IJCAI
Proceedings-International Joint Conference on Artiﬁcial Intelligence, volume 22, 1288. people.virginia.edu.
Huang, J.; Nie, F.; Huang, H.; and Ding, C. 2014. Robust manifold nonnegative matrix factorization. ACM Trans.
Knowl. Discov. Data 8(3):11:1–11:21.
Kong, X.; Zhang, J.; and Yu, P. S. 2013. Inferring anchor
links across multiple heterogeneous social networks. In Proceedings of the 22nd ACM international conference on Information & Knowledge Management, 179–188. ACM.
Li, T., and Ding, C. 2006. The relationships among various
nonnegative matrix factorization methods for clustering. In
Data Mining, 2006. ICDM’06. Sixth International Conference on, 362–371. IEEE.
Liben-Nowell, D., and Kleinberg, J. 2007. The linkprediction problem for social networks. J. Am. Soc. Inf. Sci.
58(7):1019–1031.

1473

Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI-16)

Crowdsourcing via Tensor
Augmentation and Completion
Yao Zhou, Jingrui He
Arizona State University, Tempe, Arizona
yzhou174@asu.edu, jingrui.he@asu.edu
Abstract

More recently, [Dawid et al., 1979] proposed an iterative
algorithm based on Expectation Maximization (EM) to estimate worker quality and infer the item true label at the
same time. Its performance is further improved by a variety of recent algorithms [Zhou et al., 2012; Liu et al., 2012b;
Zhang et al., 2014; Raykar et al., 2010]. Section 2 provides a
brief review of these algorithms.
In this paper, for the first time, we approach the crowdsourcing problem using tools and concepts from tensor augmentation and completion (TAC). Compared with existing
techniques, we are able to effectively leverage the structured
information in the labeled data. First of all, we represent the
set of labels provided by non-experts (workers) as a threeway tensor, and then augment it with an extra tensor slice
named the ground truth layer. Second, to infer the true labels
in the ground truth layer, we leverage the low rank property of
the augmented tensor, and introduce two optimization problems named PG-TAC (prior guided) and RS-TAC (relaxed
simplex). Finally, we propose various algorithms for solving these problems using block coordinate descent. Empirical results on 6 real data sets demonstrate the effectiveness of
the proposed methods in both binary and multi-class labeling
tasks, outperforming several state-of-the-art methods.
The rest of the paper is organized as follows. In Section
2, we briefly review existing working on crowdsourcing and
tensor completion. Then in Sections 3 and 4, we present our
proposed model and optimization algorithms, followed by experimental results on both synthetic and real data sets in Section 5. Finally, we conclude the paper in Section 6.

Nowadays, the rapid proliferation of data makes it
possible to build complex models for many real applications. Such models, however, usually require
large amount of labeled data, and the labeling process can be both expensive and tedious for domain
experts. To address this problem, researchers have
resorted to crowdsourcing to collect labels from
non-experts with much less cost. The key challenge
here is how to infer the true labels from the large
number of noisy labels provided by non-experts.
Different from most existing work on crowdsourcing, which ignore the structure information in the
labeling data provided by non-experts, in this paper,
we propose a novel structured approach based on
tensor augmentation and completion. It uses tensor
representation for the labeled data, augments it with
a ground truth layer, and explores two methods to
estimate the ground truth layer via low rank tensor
completion. Experimental results on 6 real data sets
demonstrate the superior performance of the proposed approach over state-of-the-art techniques.

1

Introduction

Recent years have seen explosive growth of data being collected from a variety of domains. Such unprecedented
amount of data makes it possible to build complex models
for prediction and inference. On the other hand, building
such models requires accurate label information, the collection of which from domain experts is typically both expensive and tedious. Alternatively, crowdsourcing has been proposed to collect large amount of label information from nonexperts, which is much less expensive [Kittur et al., 2008;
Huberman et al., 2009]. However, due to the noisy nature of
the labels provided by non-experts, a key challenge in crowdsoucing is how to infer the true labels from the large number
of noisy labels.
To address this problem, a variety of techniques have
been proposed in the past decades. Among others, the most
straightforward method is majority voting, which is based
on the assumption that all labels are equally reliable. However, this assumption may not hold in practice, and majority voting has been proven sub-optimal [Karger et al., 2011].

2

Related work

In this section, we briefly review the related work on crowdsourcing and missing value completion.
One of the earliest works on crowdsourcing is [Dawid et
al., 1979], which proposes an iterative algorithm based on Expectation Maximization (EM) to estimate worker quality and
infer the item true label at the same time. They assume each
worker is associated with a probabilistic confusion matrix for
item labeling. Each diagonal entry of the confusion matrix
represents the labeling accuracy in each labeling class and
the off-diagonal entries of each row represent the mislabeling probabilities. However their model implicitly ignores the
item variations in the same class and assumes all items, which

2435

have the same true labels, will have the same degree of difficulties. That assumption does not hold in many real-world
situations, then [Zhou et al., 2012] improved upon their work
by proposing a minimax entropy principle to infer the true label, the labeling difficulty of the item, and the quality of the
worker. Besides the worker quality, their method assumes
that each item has its own intrinsic difficulty of being mislabeled. When the item difficulty is ignored, their model is
reduced to the EM method proposed by [Dawid et al., 1979].
Another flaw of the EM method, proposed by [Dawid et al.,
1979], is that their likelihood function is nonconvex, therefore its performance is initialization sensitive because the EM
iterations can possibly converge at a local optimum. To address this issue, [Zhang et al., 2014] proposed a two-staged
algorithm in which the initial worker confusion matrix is estimated using the spectral method, and then their algorithm
turns to EM iterations. Their model has been proved to be
able to achieve the minimax rates of convergence up to a logarithmic factor. [Liu et al., 2012b] also proposed a graphical
model that performs variational inference method using belief
propagation and mean field (MF) algorithms. Another probabilistic model named GLAD, which can simultaneously estimate the ground truth, item difficulty and worker ability, has
also been proposed by [Whitehill et al., 2009]. However the
GLAD model can only work on binary tasks and it does not
model the worker bias, its performance can get worse when
the bias variation of different workers is high [Welinder et
al., 2010]. Later on, the GLAD model is generalized to work
multi-class labelling tasks by [Mineiro, 2011].
Missing values are commonly seen in many real-world applications, such as recommendation systems, which motivates
the study of missing value completion. This problem is initially proposed by [Candès and Recht, 2009] in order to recover the missing entries in matrices. Theoretically it has already been proved that most low rank matrices can be recovered from a small fraction of entries by formatting a rank minimization problem. However this rank minimization problem
is NP-hard and non-convex, which results in the optimization problem that uses trace norm as the objective. This is
addressed and mentioned in a variety of works [Candès and
Tao, 2010; Recht, 2011]. The advantage is that trace norm
is the tightest convex envelop for matrix rank. In many practical situations, higher dimensional data is more desired and
it requires to generalize the completion methods on tensors.
Similar to matrix completion, it is straightforward to think
of formulating the tensor completion as a rank minimization
problem. However, unlike the matrix rank, there is no direct algorithm that can decide the rank of a tensor [Kolda
and Bader, 2009]. To overcome this issue, similarly, [Liu et
al., 2012a] proposed to approximate the rank minimization
problem as a trace norm minimization problem. They introduce one type of the definition for tensor trace norm, while
there exists many other definitions [Gandy et al., 2011]. [Liu
et al., 2012a] also relaxes the objective function so that the
optimization problem becomes convex. Their final low rank
tensor completion method (LRTC) shows the broad capability to recover data in various format. Meanwhile there are
many other heuristic methods [Xu et al., 2013] that can be
applied to do tensor completions by employing tensor decom-

position and unfolded matrix factorization. However the theoretical guarantee of these heuristic methods is still an open
question and the comparison experiment results from [Liu et
al., 2012a] show that LRTC has a more stable performance
on both synthetic data and real-world data.

3
3.1

Problem formulation
Notation

In this article, we use calligraphic letters, such as X , to denote tensors. We use upper case letters, such as M , to denote
matrices. Vectors and scalars are denoted by the bold lower
case letters and a lower case letters such as x and x. A n-way
tensor is denoted as X 2 IRN1 ⇥N2 ⇥...⇥Nn . The (i, j, k)th
element of a three-way tensor X is represented by Xijk . A
slice of a three-way tensor X is denoted as Xi:: , X:j: or X::k .
A fiber of a three-way tensor is denoted as X:jk , Xi:k or Xij: .
The norm of a tensor
P is analogous to the matrix Frobenius
norm: ||X ||F = ( i,j,k |Xijk |2 )1/2 . The trace norm of a
P
matrix M is defined as: ||M ||⇤ = i i (M ) and i (M ) denotes the ith singular value in descending order. Let ⌦ denote
the index set of a tensor, and |⌦| denote the cardinality of ⌦.
One important operation of a tensor X is called matricization
or unfold, which reorders a n-way tensor into a matrix. We
denote X(k) as the output of unfold operation along the k-th
dimension of a tensor X , i.e., X(k) = unfoldk (X ). Similarly,
the foldk (X(k) ) is the inverse operation of unfold and it returns the tensor X . The details of operations fold and unfold
can be found at [Kolda and Bader, 2009].

3.2

Tensor augmentation and completion

We propose to reorganize the worker labels from crowdsourcing as a three-way label tensor T 0 2 IRNw ⇥Ni ⇥Nc and an
index set ⌦. Here Nw , Ni and Nc are denoted as number of
the workers, number of the items and number of the classes
respectively. Each worker gives each item either exactly one
label or no label, then label tensor T 0 and index set ⌦ are
built as follows: If a worker i has labeled an item j with la0
bel k, the corresponding fiber Tij:
is initialized with an unit
vector, which has value of 1 in kth entry and value of 0’s in
the rest. Meanwhile the corresponding index triplets of fiber
0
Tij:
are added into the index set ⌦. However a worker does
not necessarily have to label all items. If worker i does not
0
label item j, fiber Tij:
is initialized with a zero vector and
⌦ remains unchanged. If that is the case, the label tensor
T 0 will have missing entries. In our approach, we propose
to augment the label tensor with an extra tensor slice of size
Ni ⇥ Nc , called the ground truth layer, on the worker dimension. All entries of the ground truth layer are assumed to be
missing and our objective is to infer the true labels of items.
Recall that the common approach for matrix completion is
to minimize the matrix trace norm by solving the following
convex optimization problem [Candès and Recht, 2009].
min : ||X||⇤ ,
X

s.t. : X⌦ = M⌦

(1)

where X and M are matrices of the same size. ⌦ is the index
set of matrix M , and X is the matrix such that its rank should
be minimized while completing procedure. The entries that

2436

do not belong to ⌦ are missing. For tensor completion, [Liu et
al., 2012a] followed the same formulation with the following
trace norm definition of an n-way tensor X :
||X ||⇤ =
s.t. :

n
X

n
X
l=1

↵l ||X(l) ||⇤

↵l = 1, ↵l

regularization is to updating the item labels by combining the
prior statistics and tensor structure information. The formulation becomes:
n
X
l
min :
↵l ||Ml ||⇤ + ||X(l) Ml ||2F + ||Xig :: S||2F
X ,Ml
2
2
l=1

(2)

s.t. : X⌦ = T⌦

0, l = 1, ..., n

Here S 2 IRNw ⇥Nc represents the item prior statistics matrix
of the tensor T .

l=1

where ↵l , l = 1, ..., n are pre-defined scalars of tensor trace
norm. Analogous to the matrix completion formulation, the
tensor completion problem can be written as follows:
min :
X

n
X
l=1

↵l ||X(l) ||⇤ ,

s.t. : X⌦ = T⌦

Relaxed simplex ground truth inference
The second formulation has regularization terms w.r.t. the
tensor fibers of the ground truth layer. Originally each item
fiber Xig j: is posed to be constraint in a simplex. However
the amount of labels collected for each item is usually limited to a small number in empirical experiment. It is likely
that the labels of these items fluctuate around their expected
values. In order to prevent overfitting, we formulate our objective with relaxed simplex constraint and penalize the large
fluctuations according to the value of parameter :

(3)

In the formulation, X is the target tensor that needs to be
completed. However, the unfolded matrices X(l) , l = 1, ..., n,
are not independent with each other. In order to split them
and solve them independently, same number of intermediate
matrices Ml , l = 1, ..., n are introduced in this problem. Then
this optimization problem can be relaxed and formulated as:
min :

X ,Ml

n
X
l=1

↵l ||Ml ||⇤ +

l

2

||X(l)

Ml ||2F ,

min :

X ,Ml

(4)
s.t. :

s.t. : X⌦ = T⌦

X ,Ml

n
X
l=1

↵l ||Ml ||⇤ +

l

2

||X(l)

Ml ||2F + R(Xig :: )

l=1

Nc
X

↵l ||Ml ||⇤ +
Xijk

l

2

||X(l)

Ml ||2F +

2

Ni
X

⇠j2

j=1

(7)

1 = ⇠j , i = ig , 8j = 1, ..., Ni

X⌦ = T ⌦

4

Algorithm

All the terms in the objective function are convex, therefore
we can employ the block coordinate descent (BCD) for the
optimization problems (6) and (7). BCD is guaranteed to converge [Tseng, 2001] and is computational easier and cheaper
than the batch update. Then we apply the coordinate descent to optimize one target variable while fixing others. In
our case, we have four blocks: X , M1 , M2 and M3 , because
the observed tensor has only three dimensions: the worker,
the item and the label. There are two major iteration steps
in BCD: First iteration updates one intermediate matrix Ml
while fixing the other intermediate matrices and the tensor
X ; Second iteration updates the tensor and fixing all intermediate matrices.

(5)

s.t. : X⌦ = T⌦

Here ig denotes the ground truth layer index on the worker
dimension of the tensor.

3.3

n
X

k=1

We propose to formulate the crowdsourcing problem as
an augmented tensor completion problem with certain regularization on the ground truth layer. Since our task only
requires a three-way tensor, from now on, without other
specifications, all tensors in our equations have an order of
three, namely n = 3. Given the augmented label tensor
T 2 IR(Nw +1)⇥Ni ⇥Nc and index set ⌦, our optimization
problem becomes:
min :

(6)

Two formulations for inferring the ground
truth layer

4.1

Updating Ml

Under certain simplification, the optimization problem of first
BCD iteration becomes:
↵l
1
min : ||Ml ||⇤ + ||X(l) Ml ||2F
(8)
Ml
2
l
The close-form solution of this problem has been given by
[Cai et al., 2010] as D⌧ (X(l) ) = U ⌃⌧ V T . We first compute
singular value decomposition of matrix X(l) = U ⌃V T , then
replace ⌃ with its shrinkage version: ⌃⌧ = diag({ i ⌧ }+ ).
Here a+ = max(a, 0) and ⌧ is the threshold of shrinkage
SVD. No matter under prior guided formulation or relaxed
simplex formulation, both problems will have problem (8) as
the sub-problem in their BCD iterations.

In the formulations, we propose to regularize the ground truth
layer in two different ways: One is to regularize the discrepancy between the ground truth layer of the tensor and a given
prior statistics of the items. Another one is to constraint each
tensor fiber of the ground truth layer in a simplex. Under
these two regularizations, the inferred the ground truth layer
can have distinct interpretations.
Prior guided ground truth inference
The objective function of the first formulation has a regularization term w.r.t. the discrepancy between ground truth layer
and prior statistics matrix, and the regularization is parameterized with a positive value . Our key motivation of this

2437

4.2

Updating X

Similarly, we rewrite the objective element wise, and the
Lagrangian of the optimization problem becomes:

Prior guided formulation:
With intermediate matrices M1 , M2 and M3 fixed in this iteration, the optimization problem becomes:

L=

n
X
l=1

min :
X

n
X
l=1

l

2

Ml ||2F +

||X(l)

2

||Xig ::

S||2F

+

(9)

j=1

s.t. : X⌦ = T⌦
This problem is convex and the objective can be rewritten
in elementary manner and then the Lagrangian of the optimization problem is given as:
L=

n
X
l=1

+

2

l

2

X

S||2F +

(10)

|⌦|
X

ijk (Xijk

(i,j,k)2⌦

Tijk )

+

X

s.t. :

l=1

Nc
X

k=1

l

2

||X(l)

Xijk

Ml ||2F +

2

Ni
X

1

X

⇠j ) +

j=1

ijk (Xijk

(i,j,k)2⌦

Tijk )
(15)

l

⌧j

(17)

Pn

l=1

l

ijk

PNc
oldl (Ml ))ijk )
l=1 l (1 P k=1 (fP
n
n
( Nc + l=1 l ) l=1 l

(19)

Our proposed PG-TAC method is described in Algorithm
1. The algorithm of RS-TAC is omitted due to space limit.

ijk

5

Experiments

In this section, we report the results of our proposed methods
on four groups of synthetic data sets. The purpose of this is
to study the behavior of our methods under various data set
configurations. Moreover, we compare our methods with a
variety of state-of-the-art algorithms on six real data sets.

5.1

Relaxed simplex formulation:
The intermediate matrices M1 , M2 and M3 are fixed, the optimization problem becomes:
n
X

k=1

Xijk

|⌦|

⇠j2

Substituting Equation (18) in Equation (16), we get:
✓ Pn
◆
l=1Pl f oldl (Ml )
Xijk =
n

The elements in set C3 do not appear in the third term of the
Lagrangian. We take the derivative of the Lagrangian w.r.t.
Xijk and set it to 0, then we get:
✓ Pn
◆
✓
◆
f oldl (Ml )
S
l=1
Pn l
Xijk =
+ Pn
l=1 l +
l=1 l +
ijk
jk
(13)

min :

⌧j (

Nc
X

2

Ni
X

Substituting Equations (16) and (17) into the relaxed conPNc
straint k=1
Xijk 1 = ⇠j , we get:
Pn
PNc
1)
l(
k=1 f oldl (Ml ))ijk
Pn
(18)
⌧j = l=1
Nc + 1 l=1 l

(11)

l

i,j,k

⇠j =

The elements in set C2 do not appear in the second and
third terms of the Lagrangian. We take the derivative of the
Lagrangian w.r.t. Xijk and set it to 0, then we get:
✓ Pn
◆
l=1Pl f oldl (Ml )
Xijk =
(12)
n
l=1

(f oldl (Ml ))ijk )2 +

(Xijk

l=1

Elements of tensor X can be divided into three sets. First
set C1 has its elements belong to the index set: (i, j, k) 2 ⌦.
The elements of the second set C2 neither belong to the index
set nor the ground truth layer: (i, j, k) 2
/ ⌦ and i 6= ig ; The
elements of the third set C3 do not belong to the index set but
belong to the ground truth layer: (i, j, k) 2
/ ⌦ and i = ig .
The elements in set C1 do not appear in the second term of
the Lagrangian. Easily we know that the solution is:
Xijk = Tijk

2

X

Similar as the prior guided formulation, here the elements
of tensor X are also divided into three sets C1 , C2 and C3 .
The solutions for the elements in sets C1 , C2 stay the same
as shown in equations (11) and (12). The elements in set C3
do not appear in the third term of Lagrangian. We take the
derivative of the Lagrangian w.r.t. Xijk and ⇠j and set them
to 0, then we get:
Pn
⌧j
l (f oldl (Ml ))ijk
Pn
Xijk = l=1
(16)

(f oldl (Ml ))ijk )2

(Xijk

i,j,k

||Xig ::

Ni
X

l

Synthetic data

Generation of synthetic data sets is based on four parameters: number of worker Nw , number of items Ni , number of
classes Nc and probability of no labels q. Given Nc and Ni ,
the true labels of these items are sampled from a multinomial distribution with probabilities p1 , p2 , ..., pnc . In order to
have balanced data, these probabilities should be the same.
However we add random noise to the probabilities without
breaking the rule of the sum being to 1. Now, the data set is
unbalanced and is more analogous to a real data set. Then for
each worker, we generate a Nc ⇥Nc worker quality confusion
matrix as follows: the diagonal entries are independently and

⇠j2

j=1

(14)

1 = ⇠j , i = ig , 8j = 1, ..., Ni

X⌦ = T ⌦

2438

Error rate

Configuration (b)
0.6

NC-TAC
PG-TAC
RS-TAC

0.4

while ||X T ||F /||T ||F ✏ do
for l = 1:n do
Updating Ml based on equation (8).
end
Updating elements in set C1 based on equation (11);
Updating elements in set C2 based on equation (12);
Updating elements in set C3 based on equation (13);
end

0.3
0.2

NC-TAC
PG-TAC
RS-TAC

0.4

0.2

0.1
0

0
20

40
60
80
Number of workers: N w

2

4
6
8
Number of classes: Nc

Configuration (d)

NC-TAC
PG-TAC
RS-TAC

NC-TAC
PG-TAC
RS-TAC

0.6

Error rate

0.4

Error rate

100

Configuration (c)

0.5

uniformly sampled from a certain probability range. Empirically, the labeling difficulty of each item should rise with the
increasing number of labels Nc , therefore it would be inappropriate to sample the diagonal probability entries in a fixed
range for different Nc values. In order to simulate the realworld situations, we assign each diagonal entry with a probability which is the product of random guess and a scale factor . We empirically draw  from a uniform distribution of
range [1.5, 1.99]. For instance, if the scale factor is drawn as
1.8, then for a 3-labeling task, the diagonal element will have
accuracy value of 0.6. The non-diagonal entries are randomly
assigned with positive probabilities under the constraint that
the sum of each row of the confusion matrix is equal to 1.
Since each worker does not have to label all items, we draw
a labeling decision for each worker from a Bernoulli distribution with the probability of q. In addition to prior guided
tensor augmentation and completion (PG-TAC) and relaxed
simplex tensor augmentation and completion (RS-TAC), we
also use no constraint tensor augmentation and completion
(NC-TAC) as a simple baseline method for comparison. The
evaluation metric is the error rate of label prediction. All the
outcomes of our proposed methods are result of 10 independent runnings and the performance is shown in figure 1. The
initial configuration is Nw = 50, Ni = 400, Nc = 4 and
q = 0.7. Based on this, we report the performance of our
proposed methods on synthetic data sets generated with four
groups of configurations: (a). Nw varies in range of [20, 90]
by a step size of 10. (b). Nc varies in range of [2, 8] by a step
size of 1. (c). Ni varies in range of [50, 1000] by a step size
of 50. (d). q varies in range of [0, 0.95] by a step size of 0.05.
Under each configuration, other data set parameters remain
consistent with the initial configuration.
On all synthetic data sets we generated, the PG-TAC
method achieves the lowest error rate on all configurations.
The RS-TAC method does not necessarily improve the performance. In many configurations, RS-TAC and NC-TAC have
almost the same performance. We also observe when the data
sets are not sufficiently labeled, for instance, if Nw and Ni
are very small or q is relatively large, the performance of our
proposed methods are almost the same. When more data is
used, the PG-TAC and RS-TAC have better performance.

5.2

Configuration (a)

0.5

Error rate

Algorithm 1: PG-TAC
Data: Augmented tensor T , prior statistics S, ↵, , , ✏.
Result: Completed tensor X .

0.3
0.2

0.4
0.2

0.1
0

0
0

200

400
600
800
Number of items: Ni

1000

0

0.2

0.4

0.6

0.8

1

Probability of no labels: q

Figure 1: Comparison results of our proposed methods on
various synthetic data sets configurations.
sets have binary labels and three data sets have multiple labels. The binary labeling data sets include Temp data set
[Snow et al., 2008]), RTE data set [Snow et al., 2008] and
Spam data set [Zhou et al., 2015]. The multi-class labeling
data sets include Dog data set [Zhou et al., 2012], Web data
set [Zhou et al., 2012] and Age data set [Han et al., 2015].
RTE
Temp
Web
Dog
Spam
Age

# classes
2
2
5
4
2
7

# items
800
462
2653
807
149
1002

# workers
164
76
177
109
18
165

# total labels
8000
4620
15567
7354
1901
10020

Table 1: For Dog data set, the unqualified workers, who have
only labeled a small amount of images, are remained. For
web data set, 12 items have been removed due to lack of true
labels. For age data set, data has been discretized into 7 bins:
[0, 9], [10, 19], [20, 29], [30, 39], [40, 49], [50, 59], [60, 100].

5.3

Methods

In our experiment, we employed eight methods for the purpose of comparison: Majority Voting (MV) is the most
straightforward method to implement and we use it as one of
our baseline methods. Dawid-Skene Expectation Maximization (DS-EM), proposed by [Dawid et al., 1979], is a generative model which jointly infers the item true labels and worker
qualities. Dawid-Skene Mean Field (DS-MF) employs variational inference using mean filed method and this model is
proposed by [Liu et al., 2012b]. Generative model of Labels,
Abilities and Difficulties (GLAD), proposed by [Whitehill
et al., 2009], is a probabilistic framework that can simultaneously infer worker quality, item difficulty and item true
labels. Here we use its variant, implemented by [Mineiro,

Real data

We also evaluate our methods with various other methods on
six real world crowdsourcing data sets. There are three data

2439

RTE
Temp
Web
Dog
Spam
Age

MV
10.31
6.39
26.93
17.91
19.80
34.88

DS-EM
7.25
5.84
16.92
15.86
13.42
39.62

DS-MF
6.63
5.84
18.24
15.74
12.75
36.33

GLAD
7.00
5.63
19.30
–
18.12
35.73

MMCE
7.50
5.63
11.12
16.23
12.75
31.14

NC-TAC
7.13
5.84
11.16
15.86
14.10
31.24

PG-TAC
7.00
5.41
10.82
15.74
12.75
32.44

RS-TAC
7.25
5.84
11.23
15.74
13.42
31.14

Table 2: Comparison results of all methods on six real data sets in error rate (in percentage)
2011], which can work on multi-class data. Minimax Conditional Entropy (MMCE) uses the minimax entropy principle
[Zhou et al., 2012] to infer items ground truth from noisy labels. When the item difficult is ignored, the MMCE model is
reduced to DS-EM method. NC-TAC is another simple baseline of our proposed method without the constraint on ground
truth layer. PG-TAC employs an tensor slice as its prior statistics. When regularization parameter is very small, PG-TAC
is approximately equal to NC-TAC; when is sufficiently
large, PG-TAC reduces to its prior statistics. The objective of
RS-TAC has a regularization term, which is parameterized by
, to control the strength of relaxation on ground truth layer.

5.4

recover the unknown ground truth layer with meaningful returning values. This has been verified by initialize ground
truth layer with all 0’s and the final completed values on it
are meaningless. The ground truth layer of RS-TAC method
is initialized with DS-EM. We use ||X T ||F /||T ||F as the
stopping criteria and it is set to 10 5 . The final label prediction is performed as follows: in each fiber Xig j: of the
completed ground truth layer, the entry with larger values are
more likely to be correctly predicted.

5.6

Table 2 summarizes the error rates of various methods on
six real data sets. For fairly comparison, all methods have
been fed with the same format of input data. Our proposed
methods PG-TAC and RS-TAC have consistently lower error rate than other state-of-the-art methods in most data sets.
The RS-TAC method has the best performance on Age data
set, which is the most difficult one we employed. Among all
other data sets, the RS-TAC method has similar performance
as NC-TAC. We observe the PG-TAC has outperformed all
state-of-the-arts methods in most real data sets. The performance shown by PS-TAC is within our anticipation because
PG-TAC combines the prior information and structural information inferred from tensor. From Equation (13), we know
that inferred layer is actually the linear combination of prior
statistics and NC-TAC. The only exception is on Age data
set, which has severely unbalanced label distributions. Interestingly, DS-EM has the worst performance on Age data
set among all methods. Even though the prior statistics is
severely biased, PG-TAC still can achieve competitive results.

Parameter selection

PG-TAC and RS-TAC both have three parameters in objective: ↵l , l and . Here l = 1, ..., 3 and 3 is the mode of
the tensor. The values of ↵l are assigned with value of 1/3
and we let l = ↵ll . Given l , the value of l is also determined. Therefore it is straightforward to verify that we only
need to tune l in BCD iterations no matter it is in the step of
computing Ml or in the step of computing X . For simplicity,
we let all l be the same for all three modes. Eventually we
can apply the grid search on two regularization parameters l
and , and the procedure is described as follows: all data sets
we used are publicly available online and they all come with
ground truth labels. We run our proposed algorithms on a 2D grid parameter space. For each possible parameter pair on
the searching grid, a subset of worker labels is randomly chosen from current data set without replacement. In practice,
we empirically choose 90 percent of worker labels as a subset, run our methods, and evaluate the performance. Then we
repeat the same procedure ten times for each possible parameter pair on the grid. Eventually the regularization parameter
pair is chosen as the one that have lowest average error rate.

5.5

Results

6

Conclusion

In this paper, we propose two novel methods (PG-TAC and
RS-TAC) to infer the true labels of items in both binary and
multi-class crowdsourcing settings. These methods capture
the structure information in the data by representing the noisy
labels provided by workers with tensors. Furthermore, we
propose to augment the data tensor with an extra ground truth
layer, and explore various tensor completion techniques to infer the true labels in the ground truth layer. Our experiment
results on 6 real data set demonstrate that our proposed methods outperform state-of-the-art techniques.

Implementation details

The results of MV, DS-EM and MMCE methods are verified by using the open source implementation provided by
[Zhou et al., 2015]. Our PG-TAC method uses the DS-EM
as prior statistic and the ground truth layer is initialized using histogram of worker labels. In our empirical studies, we
have tried initializing ground truth layer with majority voting of worker labels, mean value of the tensor and normalized histogram of worker labels. Normalized histogram is the
linear combination of label tensor slices, therefore the rank
of the augmented tensor will not increase if the ground truth
layer is initialized using histogram. If we do not have any
information about the ground truth layer, there is no hope to

Acknowledgements
The research was partially supported by NSF research grant
IIS-1552654; and by an IBM Faculty Award. The views and

2440

[Raykar et al., 2010] Vikas C. Raykar, Shipeng Yu, Linda H.
Zhao, Gerardo Hermosillo Valadez, Charles Florin, Luca
Bogoni, and Linda Moy. Learning from crowds. Journal
of Machine Learning Research, 11:1297–1322, 2010.
[Recht, 2011] Benjamin Recht. A simpler approach to matrix completion. Journal of Machine Learning Research.,
12:3413–3430, 2011.
[Snow et al., 2008] Rion Snow, Brendan O’Connor, Daniel
Jurafsky, and Andrew Y. Ng. Cheap and fast—but is it
good?: Evaluating non-expert annotations for natural language tasks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages
254–263, 2008.
[Tseng, 2001] Paul Tseng. Convergence of a block coordinate descent method for nondifferentiable minimization.
Journal of Optimization Theory and Applications, pages
475–494, 2001.
[Welinder et al., 2010] Peter Welinder, Steve Branson, Serge
Belongie, and Pietro Perona. The multidimensional wisdom of crowds. In Advances in Neural Information Processing Systems, 2010.
[Whitehill et al., 2009] Jacob Whitehill, Ting fan Wu, Jacob
Bergsma, Javier R. Movellan, and Paul L. Ruvolo. Whose
vote should count more: Optimal integration of labels
from labelers of unknown expertise. In Advances in Neural Information Processing Systems, 2009.
[Xu et al., 2013] Yangyang Xu, Ruru Hao, Wotao Yin, and
Zhixun Su. Parallel matrix factorization for low-rank tensor completion. CoRR, 2013.
[Zhang et al., 2014] Yuchen Zhang, Xi Chen, Dengyong
Zhou, and Michael I. Jordan. Spectral methods meet EM:
A provably optimal algorithm for crowdsourcing. In Advances in Neural Information Processing Systems, 2014.
[Zhou et al., 2012] Dengyong Zhou, John C. Platt, Sumit
Basu, and Yi Mao. Learning from the wisdom of crowds
by minimax entropy. In Advances in Neural Information
Processing Systems, 2012.
[Zhou et al., 2015] Dengyong Zhou, Qiang Liu, John C.
Platt, Christopher Meek, and Nihar B. Shah. Regularized
minimax conditional entropy for crowdsourcing. CoRR,
abs/1503.07240, 2015.

conclusions are those of the authors and should not be interpreted as representing the official policies of the funding
agencies or the U.S. Government.

References
[Cai et al., 2010] Jian-Feng Cai, Emmanuel J. Candès, and
Zuowei Shen. A singular value thresholding algorithm
for matrix completion. SIAM Journal on Optimization,
20:1956–1982, 2010.
[Candès and Recht, 2009] Emmanuel J. Candès and Benjamin Recht. Exact matrix completion via convex optimization. Foundations of Computational Mathematics,
pages 717–772, 2009.
[Candès and Tao, 2010] Emmanuel J. Candès and Terence
Tao. The power of convex relaxation: Near-optimal matrix completion. IEEE Transaction of Information Theory.,
pages 2053–2080, 2010.
[Dawid et al., 1979] P. Dawid, A. M. Skene, A. P. Dawidt,
and A. M. Skene. Maximum likelihood estimation of observer error-rates using the em algorithm. Applied Statistics, pages 20–28, 1979.
[Gandy et al., 2011] Silvia Gandy, Benjamin Recht, and Isao
Yamada. Tensor completion and low-n-rank tensor recovery via convex optimization. Inverse Problems, 2011.
[Han et al., 2015] Hu Han, Charles Otto, Xiaoming Liu, and
Anil K. Jain. Demographic estimation from face images:
Human vs. machine performance. IEEE Transactions on
Pattern Analysis and Machine Intelligence, pages 1148–
1161, 2015.
[Huberman et al., 2009] Bernardo A. Huberman, Daniel M.
Romero, and Fang Wu. Crowdsourcing, attention and productivity. Journal of Information Science, 35:758–765,
2009.
[Karger et al., 2011] David R. Karger, Sewoong Oh, and Devavrat Shah. Budget-optimal task allocation for reliable
crowdsourcing systems. CoRR, abs/1110.3564, 2011.
[Kittur et al., 2008] Aniket Kittur, Ed H. Chi, and Bongwon
Suh. Crowdsourcing user studies with mechanical turk. In
Proceedings of the SIGCHI Conference on Human Factors
in Computing Systems, 2008.
[Kolda and Bader, 2009] Tamara G. Kolda and Brett W.
Bader. Tensor decompositions and applications. SIAM
Review, 51:455–500, 2009.
[Liu et al., 2012a] Ji Liu, Przemyslaw Musialski, Peter
Wonka, and Jieping Ye. Tensor completion for estimating missing values in visual data. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 35:208–220,
2012.
[Liu et al., 2012b] Qiang Liu, Jian Peng, and Alexander T
Ihler. Variational inference for crowdsourcing. In Advances in Neural Information Processing Systems, 2012.
[Mineiro, 2011] P. Mineiro. http://www.machinedlearnings.
com/2011/08/low-rank-confusion-modeling-of.html,
2011.

2441

Graph-based Transfer Learning
Jingrui He

Yan Liu

Richard Lawrence

School of Computer Science
Carnegie Mellon University

Predictive Modeling Group
IBM Research

Predictive Modeling Group
IBM Research

jingruih@cs.cmu.edu

liuya@us.ibm.com

ABSTRACT

examples in the source domain, whereas very few or no labeled examples in the target domain. Transfer learning is
of key importance in many real applications. For example,
in sentiment analysis, we may have many labeled movie reviews (labels obtained according to the movie ratings), but
we are interested in analyzing the polarity of reviews about
an electronic product [4]; in face recognition, we have many
training images under certain lightening and occlusion conditions based on which a model is trained, but practically
the model will be used under totally diﬀerent conditions [14].
Generally speaking, transfer learning can follow one of the
following three scenarios:

Transfer learning is the task of leveraging the information
from labeled examples in some domains to predict the labels
for examples in another domain. It ﬁnds abundant practical applications, such as sentiment prediction, image classiﬁcation and network intrusion detection. In this paper,
we propose a graph-based transfer learning framework. It
propagates the label information from the source domain to
the target domain via the example-feature-example tripartite graph, and puts more emphasis on the labeled examples from the target domain via the example-example bipartite graph. Our framework is semi-supervised and nonparametric in nature and thus more ﬂexible. We also develop
an iterative algorithm so that our framework is scalable to
large-scale applications. It enjoys the theoretical property
of convergence. Compared with existing transfer learning
methods, the proposed framework propagates the label information to both the features irrelevant to the source domain and the unlabeled examples in the target domain via
the common features in a principled way. Experimental results on 3 real data sets demonstrate the eﬀectiveness of our
algorithm.

1. The source domain and the target domain have the
same feature space and the same feature distribution,
and only the labeling functions are diﬀerent, such as
multi-label text classiﬁcation [24];
2. The source domain and the target domain have the
same feature space, but the feature distribution and
the labeling functions are diﬀerent, such as sentiment
classiﬁcation for diﬀerent purposes [4];
3. The source domain and the target domain have different feature space, feature distribution and labeling
functions, such as verb argument classiﬁcation [10].

Categories and Subject Descriptors

In this paper, we focus on the second scenario, which sometimes is formalized as the problem that the training set and
the test set have diﬀerent feature distribution [7].
The main contribution of this paper is to develop a graphbased transfer learning framework based on separate constructions of a tripartite graph (labeled examples - features
- unlabeled examples) and a bipartite graph (labeled examples - unlabeled examples). By propagating the label information from labeled examples (mostly from the source
domain) to unlabeled examples (from the target domain)
via the features on the tripartite graph, and by imposing
domain related constraints on the bipartite graph, we are
able to learn a classiﬁcation function that takes values on all
the unlabeled examples in the target domain. Finally, these
examples are labeled according to the sign of the function
values. The proposed framework is semi-supervised since it
makes use of unlabeled examples to help propagate the label
information. Furthermore, in the second transfer learning
scenario (which we are interested in), the labeling functions
in diﬀerent domains may be closely related to the feature
distribution; thus unlabeled examples are helpful in constructing the classiﬁers. However, our framework is diﬀerent from traditional semi-supervised learning due to the fact
that labeled examples from diﬀerent domains are treated dif-

H.2.8 [Database Management]: Database Applications –
Data Mining

General Terms
Algorithm, experimentation

Keywords
Transfer learning, graph-based

1.

ricklawr@us.ibm.com

INTRODUCTION

Transfer learning refers to the process of leveraging the
information from a source domain to train a better classiﬁer
for a target domain. Typically there are plenty of labeled

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
CIKM’09, November 2–6, 2009, Hong Kong, China.
Copyright 2009 ACM 978-1-60558-512-3/09/11 ...$10.00.

937

of nodes: the labeled nodes, i.e. the nodes that correspond
to the labeled examples (most of them are from the source
domain); the feature nodes, i.e. the nodes that correspond
to the features; and the unlabeled nodes, i.e. the nodes
that correspond to the unlabeled examples from the target
domain. Both the labeled nodes and the unlabeled nodes
are connected to the feature nodes, but the labeled nodes
are not connected to the unlabeled nodes, and the nodes
of the same type are not connected either. Furthermore,
there is an edge between a labeled (unlabeled) node and a
feature node if and only if the corresponding example has
T
S
T
that feature, i.e. xS
i,j = 0 (xi,j = 0), where xi,j (xi,j ) is
th
S
T
the j feature component of xi (xi ), and the edge weight
T
is set to xS
i,j (xi,j ). Here we assume that the edge weights
are non-negative. This is true in many applications, such
as document analysis where each feature corresponds to a
unique word and the edge weight is binary or equal to the
tﬁdf value. In a general setting, this may not be the case.
However, we could perform a linear transformation to the
features and make them non-negative.
Fig. 1a shows an example of the tripartite graph. The
diamond-shaped nodes correspond to the feature nodes, the
lighter circle nodes correspond to the examples from the
source domain, and the darker circle nodes correspond to
the examples from the target domain. Notice that the labeled nodes are on the left hand side, the feature nodes
are in the middle, and the unlabeled nodes are on the right
hand side. The intuition of the graph can be explained as
follows. Consider sentiment classiﬁcation in diﬀerent domains as an example. Each of the diamond-shaped nodes
in Fig. 1a corresponds to a unique word; the lighter circle
nodes correspond to labeled movie reviews; and the darker
circle nodes correspond to product reviews that we are interested in. The labeled reviews on the left hand side of
Fig. 1a propagate their label information to the unlabeled
product reviews via the feature nodes. Notice that each of
the two domains may have some unique words that never
occur in the other domain. For example, the word ‘actor’
often occurs in a movie review, but may never occur in a
product review; similarly, the word ‘polyethylene’ may occur in a product review, but is never seen in a movie review.
Based on this graph structure, the label information can be
propagated to the domain-speciﬁc words, i.e. the words irrelevant to the movie reviews, which will help classify the
unlabeled product reviews.
Given the tripartite graph, we deﬁne aﬃnity matrix A(3) ,
which is (m + n + d) × (m + n + d). The ﬁrst m + n rows
(columns) correspond to the labeled nodes, the next n − n
rows (columns) correspond to the unlabeled nodes, and the
remaining d rows (columns) correspond to the feature nodes.
Therefore, A(3) has the following block structure
⎡
⎤
0(m+n)×(m+n) 0(m+n)×(n−n) A(3,1)
A(3) = ⎣ 0(n−n)×(m+n) 0(n−n)×(n−n) A(3,2) ⎦
(A(3,1) )T
(A(3,2) )T
0d×d

ferently in order to construct an accurate classiﬁer in the target domain, whereas in traditional semi-supervised learning,
all the labeled examples are treated in the same way. The
framework is also non-parametric in nature, which makes it
more ﬂexible compared with parametric models.
The proposed transfer learning framework is fundamentally diﬀerent from existing graph-based methods. For example, the authors of [9] proposed a locally weighted ensemble framework to combine multiple models for transfer learning, where the weights of diﬀerent models are approximated
using a graph-based approach; the authors of [12] proposed a
semi-supervised multi-task learning framework, where t-step
transition probabilities in a Markov random walk are incorporated into the neighborhood-conditional likelihood function to ﬁnd the optimal parameters. Generally speaking,
none of these methods try to propagate the label information to the features irrelevant to the source domain and the
unlabeled examples in the target domain via the common
features. Some non-graph-based methods try to address this
problem in an ad-hoc way, such as [4], whereas our paper
provides a principled way to do the propagation.
The rest of the paper is organized as follows. Firstly, Section 2 introduces the tripartite graph and a simple iterative
algorithm for transfer learning based on this graph. Then
in Section 3, we present the graph-based transfer learning
framework and associate it with the iterative algorithm from
Section 2. Experimental results are shown in Section 4, followed by some discussion. Section 5 introduces related work.
Finally, we conclude the paper in Section 6.

2.

TRANSFER LEARNING WITH TRIPARTITE GRAPH

In this section, we ﬁrst introduce the tripartite graph that
propagates the label information from the source domain
to the target domain via the features. Using this graph,
we can obtain a classiﬁcation function that takes values on
all the unlabeled examples from the target domain. Then
we present an iterative algorithm to ﬁnd the classiﬁcation
function eﬃciently.

2.1 Notation
Let X S denote the set of examples from the source doS
d
main, i.e. X S = {xS
1 , . . . , xm } ⊂ R , where m is the number
of examples from the source domain, and d is the dimensionality of the feature space. Let Y S denote the labels
S
} ⊂ {−1, 1}m ,
of these examples, i.e. Y S = {y1S , . . . , ym
S
S
where yi is the class label of xi , 1 ≤ i ≤ m. Similarly, for
the target domain, let X T denote the set of examples, i.e.
X T = {xT1 , . . . , xTn } ⊂ Rd , where n is the number of examples from the target domain. Among these examples, only
T
the ﬁrst n examples are labeled, i.e. Y T = {y1T , . . . , yn
}⊂
{−1, 1}n , where yiT is the class label of xTi , 1 ≤ i ≤ n.
Here 0 ≤   1, i.e. only a small fraction of the examples in
the target domain are labeled, and  = 0 corresponds to no
labeled examples in the target domain. Our goal is to ﬁnd a
classiﬁcation function for all the unlabeled examples in X T
with a small error rate.

where 0a×b is an a × b 0 matrix, A(3,1) and A(3,2) are both
sub-matrices of A(3) , and (·)T is the transpose of a matrix.
(3,1)
(3,2)
Let Ai,j (Ai,j ) denote the element in the ith row and the
th
j column of A(3,1) (A(3,2) ). Based on the discussion above,
(3,1)
(3,2)
Ai,j = xS
= xTi,j . Note that the elements of
i,j and Ai,j
(3)
A are non-negative. Furthermore, deﬁne diagonal matrix
D(3) , which is (m + n + d) × (m + n + d). Its diagonal

2.2 Tripartite Graph
Let G(3) = {V (3) , E (3) } denote the undirected tripartite
graph, where V (3) is the set of nodes in the graph, and E (3)
is the set of weighted edges. V (3) consists of three types

938

(3)

element Di

=

 m+n+d
j=1

(3)
Ai,j
(3)

(3)

Ai,j , i = 1, . . . , m + n + d, where
th

ranking algorithm proposed in [25], where each element of
f needs to be optimized. Minimizing Q1 with the above
constraint, we have the following lemma.

th

denote the element in the i row and the j column of
. Similar as A(3) , D(3) has the following block structure
⎡
⎤
0(m+n)×(n−n) 0(m+n)×d
D(3,1)
(3)
D = ⎣ 0(n−n)×(m+n)
D(3,2)
0(n−n)×d ⎦
0d×(m+n)
0d×(n−n)
D(3,3)

A

(3,1)

(3,2)

Lemma 1. If f L = y L , Q1 is minimized at
f U ∗ = (I(n−n)×(n−n) − α2 S (3,2) (S (3,2) )T )−1
((1 − α)y U + α(1 − α)S (3,2) y F + α2 S (3,2) (S (3,1) )T y L )

(3,3)

,D
and D
are diagonal matrices whose
where D
diagonal elements are equal to the row sums of A(3,1) , A(3,2)
and (A(3,1) )T + (A(3,2) )T respectively. Finally, deﬁne the
normalized aﬃnity matrix S (3) = (D(3) )−1/2 A(3) (D(3) )−1/2 ,
which also has the following block structure
⎡
⎤
0(m+n)×(m+n) 0(m+n)×(n−n) S (3,1)
(3)
(3,2)
⎦
S = ⎣ 0(n−n)×(m+n) 0(n−n)×(n−n) S
(S

(3,1) T

)

(S

(3,2) T

1

)

f F ∗ = (Id×d − α2 (S (3,2) )T S (3,2) )−1 ((1 − α)y F
+α(S
where α =

i,j=1

(3)

Aij ( 

1

fi
(3)
Di

= f (I(m+n+d)×(m+n+d) − S
T

−

(3)

fj
(3)
Dj

)2 + μ

(3,2) T

(2)

U

) y )

1
.
1+μ

− 2(f U )T S (3,2) f F + μf U − y U 2 + μf F − y F 2

0d×d

Therefore,
∂Q1
= 2f U − 2S (3,2) f F + 2μ(f U − y U )
∂f U
∂Q1
= 2f F − 2(S (3,1) )T y L − 2(S (3,2) )T f U + 2μ(f F − y F )
∂f F

Given the tripartite graph and the corresponding aﬃnity matrix, we can deﬁne three functions f L , f F and f U ,
which take values on the labeled nodes, the feature nodes,
and the unlabeled nodes respectively. Note that the function
value of f U will be used to classify the unlabeled examples
in the target domain, and the function value of f F can be
used to infer the polarity of the features. Similarly, deﬁne
three vectors y L , y F and y U , whose lengths are equal to
the number of labeled nodes m + n, the number of feature nodes d, and the number of unlabeled nodes n − n
respectively. The elements of y L are set to be the class
label of the corresponding labeled example, whereas the elements of y F and y U could reﬂect our prior knowledge about
the polarity of the features and the unlabeled examples, or
simply 0 if such information is not available. For the sake
of notation simplicity, let f = [(f L )T , (f U )T , (f F )T ]T and
y = [(y L )T , (y U )T , (y F )T ]T .
To ﬁnd the classiﬁcation function with a low error rate, we
propose to minimize the following objective function, which
is motivated by [25].
m+n+d


) y + α(1 − α)(S
L

Q1 = (y L )T y L + (f U )T f U + (f F )T f F − 2(y L )T S (3,1) f F

2.3 Objective Function Q1

1
2

(3,1) T

Proof. Replacing f L with y L , Q1 becomes

where S (3,1) = (D(3,1) )− 2 A(3,1) (D(3,3) )− 2 , and S (3,2) =
1
1
(D(3,2) )− 2 A(3,2) (D(3,3) )− 2 . Similar as A(3) , the elements
(3)
of S are also non-negative.

Q1 (f ) =

(1)

Setting

∂Q1
∂f U

and

∂Q1
∂f F

to 0, we get Equations 1 and 2.

Notice that in Lemma 1, in order to get f U ∗ and f F ∗ ,
we need to solve matrix inversions. This is computationally
expensive especially when the number of unlabeled examples
in X T or the number of features is very large. To address
this problem, we propose the following iteration steps to
obtain the optimal solutions.
f U (t + 1) = αS (3,2) f F (t) + (1 − α)y U

(3)

f F (t + 1) = α(S (3,1) )T y L + α(S (3,2) )T f U (t) + (1 − α)y F (4)

m+n+d


(fi − yi )2

i=1
2

)f + μf − y

where μ is a small positive parameter, Ia×b is an a × b identity matrix, and fi and yi are the ith element of f and y
respectively.
This objective function can be interpreted as follows. The
ﬁrst term of Q1 , f T (I(m+n+d)×(m+n+d) − S (3) )f , measures
the label smoothness of f . In other words, neighboring nodes
on the graph should have similar f values. The second term,
μf −y2 , measures the consistency of f with the label information and the prior knowledge encoded in y. By minimizing Q1 , we hope to obtain a smooth classiﬁcation function
fU with a small error rate.
In our implementation, we ﬁx f L = y L . In this way, we
can make better use of the label information in y L . This
modiﬁcation distinguishes our method from the manifold

where f U (t) and f F (t) denote f U and f F at the tth iteration. The two equations can be interpreted as follows. Based
on Equation 3, if an example has many positive (negative)
features or it is believed to be positive (negative) a priori,
its function value would be large (small), indicating that it
is a positive (negative) example. Based on Equation 4, if
a feature is contained in many positive (negative) labeled
examples, or it is shared by many unlabeled examples with
large (small) function values, or it is believed to be positive
(negative) a priori, its function value would be large (small).
In this way, the label information is gradually propagated
to the unlabeled examples in the target domain and the
features irrelevant to the source domain via the common
features on the tripartite graph.
The following theorem guarantees the convergence of the
iteration steps.
Theorem 1. When t goes to infinity, f U (t) converges to
f
and f F (t) converges to f F ∗ .
Proof. According to Equations 3 and 4
U∗

f U (t) = αS (3,2) f F (t − 1) + (1 − α)y U = (1 − α)y U
+ αS (3,2) (α(S (3,1) )T y L + α(S (3,2) )T f U (t − 2)
+ (1 − α)y F )
= α2 S (3,2) (S (3,2) )T f U (t − 2) + (1 − α)y U
+ α2 S (3,2) (S (3,1) )T y L + α(1 − α)S (3,2) y F

939

For the sake of simplicity, let V = S (3,2) (S (3,2) )T and v =
(1 − α)y U + α2 S (3,2) (S (3,1) )T y L + α(1 − α)S (3,2) y F . First,
we assume that t is an even number. Therefore, the above
equation can be written as follows.

f F (0) are initialized to y U and y F respectively. Next, we
update f U and f F according to Equations 3 and 4. Finally,
we classify all the unlabeled examples in X T according to
the corresponding elements in f U .

t

2

2

t
2

f (t) = α V f (t − 2) + v = (α V ) f (0) + (
U

U

U

−1
2


Algorithm 1 TRITER Algorithm for Transfer Learning

(α2 V )i )v

Input: The set of examples from the source domain X S and
the set of their labels Y S ; the set of examples from the
target domain X T and the set of labels for the ﬁrst n
examples Y T ; the number of iteration steps t; μ.
Output: The labels of all the unlabeled examples in X T .
1: Set y L (f L ) according to the label information; set y U
and y F according to our prior knowledge, or simply 0 if
such information is not available; initialize f U (0) = y U
and f F (0) = y F .
2: for i = 1 : t do
3:
Calculate f U (i) and f F (i) according to Equations 3
and 4.
4: end for
5: for i = (n + 1) : n do
6:
If the function value of f U (t) at xTi is positive, yiT = 1;
otherwise, yiT = −1.
7: end for

i=0
1
,
where f U (0) is the initial value of f U . Since α = 1+μ
0 < α < 1. Therefore, if the eigenvalues of V are in [-1,1],
we have
t

lim (α2 V ) 2 f U (0) = 0(n−n)×1

t→∞
t

lim

t→∞

−1
2

(α2 V )i = (I(n−n)×(n−n) − α2 V )−1
i=0

Hence, if t is an even number,
lim f U (t) = f U ∗

t→∞

With respect to the eigenvalues of V , we have the following
lemma.
Lemma 2. The eigenvalues of V are in [-1,1].
1

Proof. Notice that V = S (3,2) (S (3,2) )T = (D(3,2) )− 2 A(3,2)
1
1
1
(D(3,3) )− 2 (D(3,3) )− 2 (A(3,2) )T (D(3,2) )− 2 is similar to (D(3,2) )−1
A(3,2) (D(3,3) )−1 (A(3,2) )T . Let V (1) = (D(3,2) )−1 A(3,2) and
V (2) = A(3,2) (D(3,3) )−1 . Then V is similar to V (1) (V (2) )T .

(1)
Furthermore, it is easy to see that dj=1 Vi,j = 1, ∀1 ≤ i ≤
n−n (2)
(1)
n − n, and i=1 Vi,j = 1, ∀1 ≤ j ≤ d, where Vi,j and
(2)

Vi,j are the elements of V (1) and V (2) in the ith row and
the j th column. Therefore, for the ith row of V (1) (V (2) )T ,
∀1 ≤ i ≤ n − n, its row sum is
d
n−n
 
j=1 k=1

(1)

(2)

Vi,k Vj,k =

d

k=1

(1)

Vi,k

n−n


(2)

Vj,k = 1

j=1

According to Perron-Frobenius theorem [18], since the elements of V (1) (V (2) )T are non-negative, the spectral radius of V (1) (V (2) )T is 1. Furthermore, since V is similar
to V (1) (V (2) )T , its spectral radius is also 1. Therefore, the
eigenvalues of V are in [-1,1].
Therefore, using Lemma 2, we have shown that if t is an even
number, as t goes to inﬁnity, f U (t) converges to f U ∗ . This
conclusion also holds when t is an odd number. Finally,
applying similar techniques to f F , we can show that as t
goes to inﬁnity, f F (t) converges to f F ∗ .
Comparing the above iterative steps with Equations 1
and 2, we can see that they avoid solving matrix inversions
directly. In our experiments, the number of iteration steps
until convergence is always less than 30. Therefore, these
iterative steps are an eﬃcient alternative to Equations 1
and 2.
Based on Equations 3 and 4, we design the following
TRITER (TRIpartite-graph-based TransfER learning) algorithm to minimize Q1 , which is shown in Algorithm 1. It
works as follows. First, we set y L (f L ), y U and y F according
to the label information or our prior knowledge. f U (0) and

3. GRAPH-BASED TRANSFER LEARNING
FRAMEWORK
In Section 2, we have introduced a tripartite graph that
connects the examples from the source domain and the target domain with the features, and have designed the TRITER
algorithm to minimize the objective function Q1 eﬃciently.
Although simple and straight-forward, Q1 is not best suited
for transfer learning. This is because the label information
from the source domain and the target domain is propagated
in the same way. If the labeled examples from the source
domain dominate the labeled nodes, the label information
of the small number of labeled examples from the target domain would be ﬂooded, and the resulting classiﬁcation function for the target domain may be largely biased. In other
words, since our goal is to construct an accurate classiﬁer in
the target domain, the labeled examples from the same domain should be more important than the labeled examples
from diﬀerent domains.
To address this problem, in this section, we propose the
graph-based transfer learning framework. In this framework,
in addition to the tripartite graph, we also design a bipartite graph to make better use of the labeled examples from
the target domain. Based on the two graphs, we present
objective function Q2 and the optimal solutions. Furthermore, under certain conditions, the solutions to Q2 can be
obtained by minimizing a slightly modiﬁed version of Q1 via
the TRITER algorithm.

3.1 Bipartite Graph
Let G(2) = {V (2) , E (2) } denote the undirected bipartite
graph, where V (2) is the set of nodes in the graph, and E (2)
is the set of weighted edges. V (2) consists of two types of
nodes: the labeled nodes which correspond to the labeled
examples from both the source domain (majority) and the
target domain (minority); the unlabeled nodes which correspond to the unlabeled examples from the target domain.
Each labeled node is connected to each unlabeled node, with

940

nal elements are equal to the row sums and the column sums
of A(2,1) respectively. Finally, let S (2) denote the normalized
aﬃnity matrix S (2) = (D(2) )−1/2 A(2) (D(2) )−1/2 , which also
has the following block structure.

the edge weight indicating the domain related similarity between the two examples, whereas the same type of nodes are
not connected.
Fig. 1b shows an example of the bipartite graph which has
the same labeled and unlabeled nodes as in Fig. 1a. Similarly, the lighter circle nodes correspond to the examples
from the source domain, and the darker circle nodes correspond to the examples from the target domain. The labeled
nodes on the left hand side are connected to each unlabeled
node on the right hand side. Again take sentiment classiﬁcation in diﬀerent domains as an example. The labeled
nodes correspond to all the labeled reviews, most of which
are movie reviews, and the unlabeled nodes correspond to
all the unlabeled product reviews. The edge weights are set
to reﬂect the domain related similarity between two reviews.
Therefore, if two reviews are both product reviews, one labeled and one unlabeled, their edge weight would be large;
whereas if two reviews are from diﬀerent domains, the movie
review labeled and the product review unlabeled, their edge
weight would be small. In this way, we hope to make better
use of the labeled product reviews to construct the classiﬁcation function for the unlabeled product reviews.

S (2) =

0(m+n)×(m+n)
(S (2,1) )T

S (2,1)




0(n−n)×(n−n)

1

1

where S (2,1) = (D(2,1) )− 2 A(2,1) (D(2,2) )− 2 .

3.2 Objective Function Q2
In Subsection 2.2, we introduced a tripartite graph which
propagates the label information from the labeled nodes to
the unlabeled nodes via the feature nodes; and in Subsection 3.1, we introduced a bipartite graph which puts high
weights on the edges connecting examples from the same
domain and low weights on the edges connecting examples
from diﬀerent domains. In this section, we combine the two
graphs to design objective function Q2 . By minimizing Q2 ,
we can obtain a smooth classiﬁcation function for the unlabeled examples in the target domain which relies more on
the labeled examples from the target domain than on those
from the source domain.
For the sake of simplicity, deﬁne g = [(f L )T , (f U )T ]T . It is
easy to see that g = Bf , where B = [I(m+n)×(m+n) , 0(m+n)×d ].
Thus the objective function Q2 can be written as follows.

Q2 (f ) =

+
(a) Tripartite graph

	

(b)
Bipartite
graph

m+n+d

1
fi
fj
(3)
γ
A (
−
)2
2 i,j=1 i,j
(3)
(3)
Dj
Di

m+n
m+n+d

1  (2)
gi
gj
τ
Ai,j ( 
−
)2 + μ
(fi − yi )2
2 i,j=1
(2)
(2)
i=1
Dj
Di

= γf T (I(m+n+d)×(m+n+d) − S (3) )f
+ τ f T B T (I(m+n)×(m+n) − S (2) )Bf + μf − y2

Figure 1: An example of the graphs.
where γ and τ are two positive parameters. Similar as in
Q1 , the ﬁrst term of Q2 , γf T (I(m+n+d)×(m+n+d) − S (3) )f ,
measures the label smoothness of f on the tripartite graph;
the second term, τ f T B T (I(m+n)×(m+n) −S (2) )Bf , measures
the label smoothness of f on the bipartite graph; and the
third term, μf − y2 , measures the consistency of f with
the label information and the prior knowledge. It should
be pointed out that the ﬁrst two terms in Q2 can be combined mathematically; however, the two graphs can not be
combined due to the normalization process.
Based on Q2 , we can claim that our method is diﬀerent from semi-supervised learning, which treats the labeled
examples from diﬀerent domains in the same way. In our
method, by imposing the label smoothness constraint on
the bipartite graph, we can see that the labeled examples
from the target domain have more impact on the unlabeled
examples from the same domain than the labeled examples
from the source domain. In the next section, we will compare our method with a semi-supervised learning method
experimentally.
Similar as before, we ﬁx f L = y L , and minimize Q2 with
respect to f U and f F . The solutions can be obtained by the
following lemma.

Let A(2) denote the aﬃnity matrix for the bipartite graph,
which is (m + n) × (m + n). The ﬁrst m + n rows (columns)
correspond to the labeled nodes, and the remaining n − n
rows (columns) correspond to the unlabeled nodes. According to the structure of the bipartite graph, A(2) has the
following form.
A

(2)

	
=

0(m+n)×(m+n)
(A(2,1) )T

A(2,1)




0(n−n)×(n−n)

(2,1)

where A
is the sub-matrix of A(2) . Note that the ele(2)
ments of A are set to be non-negative. Let D(2) denote the
(m + n) × (m + n) diagonal matrix, the ith diagonal element
m+n (2)
(2)
of which is deﬁned Di =
j=1 Ai,j , i = 1, . . . , m + n,
(2)

where Ai,j is the element of A(2) in the ith row and the
j th column. Similar as A(2) , D(2) has the following block
structure.


	
0(m+n)×(n−n)
D(2,1)
D(2) =
(2,2)
0(n−n)×(m+n)
D
where D(2,1) and D(2,2) are diagonal matrices whose diago-

941

Lemma 3. If f L = y L , Q2 is minimized at
f˜U ∗ = ((γ + τ + μ)I(n−n)×(n−n) −

(μy U +

minimizing Q1 with the following parametrization
γ
α = 
(μ + γ)(μ + γ + τ )

γ2
S (3,2) (S (3,2) )T )−1
γ+μ
(5)

y L = y L
y U =

2

γ
γμ (3,2) F
S (3,2) (S (3,1) )T y L +
S
y
γ +μ
γ+μ

y F = 

+ τ (S (2,1) )T y L )
f˜F ∗ =

F

The most signiﬁcant diﬀerence between the parameter settings in Theorem 2 and the original settings is in the deﬁnition of y U . That is, y U consists of two parts, one from its
own prior information, which is in proportion to μy U , and
the other from the label information of the labeled examples, which is in proportion to τ (S (2,1) )T y L . Note that the
second part is obtained via the bipartite graph, and it encodes the domain information. In other words, incorporating
the bipartite graph into the transfer learning framework is
equivalent to working with the tripartite graph alone, with
a domain speciﬁc prior for the unlabeled examples in the
target domain and slightly modiﬁed versions of α and y F .
Finally, to minimize Q2 , we can simply apply the TRITER
algorithm with the parameter settings speciﬁed in Theorem 2, which usually converges within 30 iteration steps.

Q2 = γ((y L )T y L + (f U )T f U + (f F )T f F
− 2(y L )T S (3,1) f F − 2(f U )T S (3,2) f F )
+ τ ((y L )T y L + (f U )T f U − 2(y L )T S (2,1) f U )
+ μf U − y U 2 + μf F − y F 2
Therefore,
∂Q2
= 2γ(f U − S (3,2) f F ) + 2τ (f U − (S (2,1) )T y L )
∂f U
+ 2μ(f U − y U )

4. EXPERIMENTAL RESULTS

∂Q2
= 2γ(f F − (S (3,1) )T y L − (S (3,2) )T f U )
∂f F

In this section, we present some experimental results, and
compare the proposed graph-based transfer learning framework with state-of-the-art techniques.

+ 2μ(f F − y F )
∂Q2
∂f U

and

∂Q2
∂f F

μ
yF
(μ + γ)(μ + γ + τ ) − γ

Proof. Replacing α, y L , y U and y F with α , y L , y U and
y respectively in Equations 1, we get Equations 5.

γ
μ
((S (3,1) )T y L + (S (3,2) )T f˜U ∗ ) +
y F (6)
γ+μ
γ+μ

Proof. Replacing f L with y L , Q2 becomes

Setting

μy U + τ (S (2,1) )T y L

μ + γ + τ − γ μ+γ+τ
μ+γ

4.1 Experiment Settings

to 0, we get Equations 5 and 6.

To demonstrate the performance of the proposed graphbased transfer learning framework, we perform experiments
in the following 3 areas.

In Equation 5, if we ignore the matrix inversion term in
the front, we can see that f˜U ∗ gets the label information
from the labeled nodes through the following two terms:
γ2
S (3,2) (S (3,1) )T y L and τ (S (2,1) )T y L , which come from
γ+μ
the tripartite graph and the bipartite graph respectively.
Recall that y L is deﬁned on the labeled nodes from both
the source domain and the target domain. In particular, if
a labeled node is from the target domain, its corresponding
row in S 2,1 would have large values, and it will make a big
contribution to f˜U ∗ via τ (S (2,1) )T y L . This is in contrast to
labeled nodes from the source domain, whose corresponding
rows in S 2,1 have small values, and their contribution to f˜U ∗
would be small as well.
Similar to objective function Q1 , we can also design an
iterative algorithm to ﬁnd the solutions of Q2 . However, in
the following, we focus on the relationship between Q1 and
Q2 , and will introduce an iterative algorithm based on the
TRITER algorithm to solve Q2 .
Comparing Equations 1 with 5, we can see that they are
very similar to each other. The following theorem builds a
connection between objective functions Q1 and Q2 .

1. Sentiment classiﬁcation (SC). In this area, we use the
movie and product review data set. The movie reviews come from [15]. Positive labels are assigned to
ratings above 3.5 stars and negative to 2 and fewer
stars. The product reviews are collected from Amazon
for software worth more than 50 dollars. In our experiments, we use the movie reviews as the source domain
and the product reviews as the target domain. After
stemming and stop word removal, the feature space is
34305-dimensional.
2. Document classiﬁcation (DC). In this area, we use the
20 newsgroups data set [16]. The documents within
this data set has a two-level categorical structure. Based
on this structure, we generate 3 transfer learning tasks.
Each task involves distinguishing two higher-level categories. The source domain and the target domain
contains examples from diﬀerent lower-level categories.
For example, one transfer learning task is to distinguish between rec and talk. The source domain contains examples from rec.sport.baseball and talk.politics.
misc; whereas the target domain contains examples
from rec.sport.hockey and talk.religion.misc. The way

Theorem 2. If f L = y L , then f˜U ∗ can be obtained by

942

label information to the unlabeled examples in the
same way.
5. The transfer learning toolkit developed by UC Berkeley (http://multitask.cs.berkeley.edu/). The method
that we use is based on [2], which is denoted BTL.
Note that for document classiﬁcation and sentiment
classiﬁcation, the feature space is too large to be processed by BTL. Therefore, as a preprocessing step,
we perform singular value decomposition (SVD) to
project the data onto the 100-dimensional space spanned
by the ﬁrst 100 singular vectors.
6. The boosting-based transfer learning method [7], which
is denoted TBoost.

that the transfer learning tasks are generated is similar
to [9] and [6]. After stemming and stop word removal,
the feature space is 53975-dimensional.
3. Intrusion detection (ID). In this area, we use the KDD
Cup 99 data set [1]. It consists of both normal connections and attacks of diﬀerent types, including DOS
(denial-of-service), R2L (unauthorized access from a
remote machine), U2R (unauthorized access to local
superuser privileges), and probing (surveillance and
other probing). For this data set, we also generate 3
transfer learning tasks. In each task, both the source
domain and the target domain contain some normal
examples as the positive class, but the negative class
in the two domains corresponds to diﬀerent types of
attacks. Similar as in [9], only the 34 continuous features are used.

4.2 Evaluations
For the graph-based transfer learning framework, we set
μ = 0.01, which is consistent with [25], y F = 0, and y U = 0
in all the experiments. For τ and γ, we test their impact on
the performance using SC, which is shown in Fig. 2. From
this ﬁgure, we can see that the performance of our method
is quite stable within a wide range of τ and γ. Therefore, in
the following experiments, we set τ = 5 and γ = 1.

The details of the transfer learning tasks are summarized
in Table 1. Notice that in SC and DC, we tried both binary
features and tﬁdf features. It turns out that binary features
lead to better performance. Therefore, we only report the
experimental results with the binary features here. Note
that the features in ID are not binary.
In our proposed transfer learning framework, the bipartite
graph is constructed as follows. A(2,1) is a linear combination of two matrices. The ﬁrst matrix is based on domain
information, i.e. its element is set to 1 iﬀ the corresponding
labeled and unlabeled examples are both from the target
domain, and it is set to 0 otherwise. The second matrix
is A(3,1) (A(3,2) )T , i.e. if a labeled example shares a lot of
features with an unlabeled example, the corresponding element in this matrix is large. Note that this is only one way of
constructing the bipartite graph with domain information.
Exploring the optimal bipartite graph for transfer learning
is beyond the scope of this paper.
We compare our method with the following methods.

Test Error on the Target Domain

tau=10
0.55

tau=5
tau=2

0.5

tau=1
tau=0.1

0.45

tau=0.01

0.4
0.35
0.3
0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

1. Learning from the target domain only, which is denoted target only. With this method, we ignore the
source domain, and construct the classiﬁcation function solely based on the labeled examples from the
target domain. In other words, none of the nodes in
the tripartite graph and bipartite graph correspond to
examples from the source domain.
2. Learning from the source domain only, which is denoted source only. With this method, we ignore the
label information from the target domain, and construct the classiﬁcation function solely based on the
labeled examples from the source domain. In other
words, all of the nodes on the left hand side of the
tripartite graph and the bipartite graph correspond to
examples from the source domain, and the nodes that
correspond to the target domain examples are all on
the right hand side of the two graphs.
3. Learning from both the source domain and the target
domain, which is denoted source+target. With this
method, we combine the function f U output by target
only and source only linearly, and predict the class
labels of the unlabeled examples accordingly.
4. Semi-supervised learning, denoted semi-supervised.
It is based on the manifold ranking algorithm [25].
With this method, all the labeled examples are considered from the target domain, and we propagate their

(a) γ = 1

Test Error on the Target Domain

0.46
gamma=10
gamma=5
gamma=2
gamma=1
gamma=0.1
gamma=0.01

0.44
0.42
0.4
0.38
0.36
0.34
0.32
0.3

0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

(b) τ = 5

Figure 2: Impact of τ and γ on the performance of
the proposed method.
Fig. 3 to Fig. 9 compare the proposed graph-based transfer learning framework with the baseline methods on the 7

943

Area
SC

DC

ID

Source Positive
Movie (1000)
comp.os.ms-windows
.misc (572)
rec.sport.baseball
(594)
rec.sport.baseball
(594)
Normal (1000)
Normal (1000)
Normal (1000)

Table 1: Transfer Learning Tasks
Source Negative
Target Positive
Movie (1000)
Product (5680)
comp.windows.x
rec.autos (592)
(592)
rec.sport.hockey
sci.crypt (594)
(598)
rec.sport.hockey
talk.politics.misc (464)
(598)
Probing (1000)
Normal (1000)
DOS (1000)
Normal (1000)
Probing (500) DOS (500)
Normal (1000)

transfer learning tasks. In these ﬁgures, the x-axis is the
number of labeled examples from the target domain, and
the y-axis is the average test error in the target domain over
20 runs (labeled examples from the target domain are randomly picked in each run). The error bars are also shown in
these ﬁgures.

Test Error on the Target Domain

1

Test Error on the Target Domain

0.5

0.4

0.6

Graph−based
Target Only
Source+Target
Semi−supervised
Source Only
BTL
TBoost

0.4

0.2

0
0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

0.3

0.2

0.1

Graph−based
Target Only
Source+Target
Semi−supervised
Source Only
BTL
TBoost

Figure 5: Comparison on the second task of DC.

0.6
Test Error on the Target Domain

0
0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

Figure 3: Comparison on SC.

1
Test Error on the Target Domain

0.8

Target Negative
Product (6047)
rec.motorcycles
(596)
sci.electronics
(591)
talk.religion.misc
(376)
R2L (1000)
R2L (1000)
R2L (1000)

0.8

0.6

Graph−based
Target Only
Source+Target
Semi−supervised
Source Only
BTL
TBoost

0.5
0.4

Graph−based
Target Only
Source+Target
Semi−supervised
Source Only
BTL
TBoost

0.3
0.2
0.1
0
0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

Figure 6: Comparison on the third task of DC.

0.4

0.2

construct the classiﬁcation function. When the number of
labeled examples from the target domain is small, its performance varies a lot depending on the speciﬁc labeled examples. In contrast, the graph-based method considers the
label information from both the source domain and the target domain, therefore, it is not very sensitive to the speciﬁc
labeled examples from the target domain. Third, the performance of semi-supervised is always much worse than our
method. This is because in all our experiments, the number
of labeled examples from the target domain is much smaller
than that from the source domain, which is quite common
in practise. Therefore, with semi-supervised, the labeled
examples from the target domain is ﬂooded by those from
the source domain, and the performance is not satisfactory.
Fourth, in most of the experiments, the average performance

0
0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

Figure 4: Comparison on the first task of DC.
Based on these results, we have the following observations.
First of all, it is easy to see that our graph-based method
is the best of the 7 methods in all the tasks in terms of the
average error rate. Second, the graph-based method is very
stable in terms of the small error bars, especially compared
with target only. This is consistent with our intuition
since target only totally ignores the source domain, and
only uses the label information from the target domain to

944

Test Error on the Target Domain

Test Error on the Target Domain

0.5
0.4
0.3
0.2
0.1
0
−0.1
−0.2

Graph−based
Target Only
Source+Target
Semi−supervised
Source Only
BTL
TBoost

Test Error on the Target Domain

0.5

0.4
0.3

Figure 9: Comparison on the third task of ID.

Graph−based
Target Only
Source+Target
Semi−supervised
Source Only
BTL
TBoost

10]. There are also specialized transfer learning techniques
for certain application areas, such as adapting context-free
grammar [17], speech recognition [13], and sentiment prediction [4].
Transfer learning is closely related to concept drifting in
stream mining, in which the statistical properties of the
target variable change over time. These changing properties might be the class prior P (y), the feature distribution
P (x|y), the decision function P (y|x) or a combination of
all. Multiple approaches have been developed, such as ensemble approaches [20], co-clustering [6], and local structure
map [9]. Transfer learning is also relevant to sample bias
correction, which is mostly concerned with distinct training
distribution P (x|λ) and testing distribution P (x|θ) with unknown parameters λ and θ. Several bias correction methods
have been developed based on estimating the probability
that an example is selected into the sample and using rejection sampling to obtain unbiased samples of the correct
distribution [23, 22, 8].
Our proposed framework is motivated by the graph-based
methods for semi-supervised learning [26, 25]. In the framework, the tripartite graph propagates the label information
from the source domain to the target domain via the features, and the bipartite graph makes better use of the label
information from the target domain. This framework is fundamentally diﬀerent from previous work on transfer learning
and related areas. It propagates the label information in a
principled way, which is in contrast to some ad-hoc methods
based on pivot features [4]; it directly associates the polarity
of features with the class labels of all the examples, which
is in contrast to previous graph-based methods [12, 9] that
do not model this relationship with the graph structure.

0.4
0.3
0.2
0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

Figure 8: Comparison on the second task of ID.
of the graph-based method and target only is getting closer
as we increase the number of labeled examples from the target domain. This is because with the graph-based method,
the labeled examples from the target domain have more impact on the classiﬁcation function than those from the source
domain. As the number of labeled examples from the target
domain increases, their impact tends to dominate. So the
performance of the graph-based method and target only
will get closer. Finally, in some experiments, such as Fig. 4
and Fig. 6, the gap between the graph-based method and
source+target is getter larger. This is reasonable since in
source+target, we are combining the source domain and
the target domain in a naive way. So the performance gain
caused by more labeled examples from the target domain is
not as signiﬁcant as the graph-based method.

5.

0.5

0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

Figure 7: Comparison on the first task of ID.

0.6

0.6

Graph−based
Target Only
Source+Target
Semi−supervised
Source Only
BTL
TBoost

0.2

0
20
40
60
80
100
Number of Labeled Examples from the Target Domain

0.7

0.7

RELATED WORK

There has been signiﬁcant amount of work on transfer
learning in machine learning research. One of the early attempts aims to achieve better generalization performance by
jointly modeling multiple related learning tasks, and transferring information among them, i.e. multi-task learning [3,
5, 19]. It usually tackles the problem where the feature space
and the feature distribution P (x) are identical whereas the
labeling functions are diﬀerent. Further developments in
the area include combining labeled data from the source domain with labeled or unlabeled data from the target domain,
which leads to transfer learning methods for k-nearest neighbor [19], support vector machines [21], and logistic regression [11]. Another line of research focuses on Bayesian logistic regression with a Gaussian prior on the parameters [2,

6. CONCLUSION
In this paper, we proposed a new graph-based framework
for transfer learning. It is based on both a tripartite graph
and a bipartite graph. The tripartite graph consists of three
types of nodes, and it propagates the label information via
the features. The bipartite graph consists of two types of
nodes, and it imposes the domain related smoothness constraint between the labeled examples and the unlabeled examples. Based on the two graphs, we have designed an objective function Q2 , which is a weighted combination of the
label smoothness on the tripartite graph, the label smoothness on the bipartite graph, and the consistency with the
label information and the prior knowledge. Closed form so-

945

[11] X. Liao, Y. Xue, and L. Carin. Logistic regression
with an auxiliary data source. In ICML, pages
505–512, 2005.
[12] Q. Liu, X. Liao, and L. Carin. Semi-supervised
multitask learning. In NIPS, 2007.
[13] J. luc Gauvain and C. hui Lee. Maximum a posteriori
estimation for multivariate gaussian mixture
observations of markov chains. IEEE Transactions on
Speech and Audio Processing, 2:291–298, 1994.
[14] A. M. Martı́nez. Recognition of partially occluded
and/or imprecisely localized faces using a probabilistic
approach. In CVPR, pages 1712–1717, 2000.
[15] B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up?
sentiment classiﬁcation using machine learning
techniques. CoRR, cs.CL/0205070, 2002.
[16] J. Rennie. 20 newsgroups. In
http://people.csail.mit.edu/jrennie/20Newsgroups/,
2007.
[17] B. Roark and M. Bacchiani. Supervised and
unsupervised pcfg adaptation to novel domains. In
NAACL, pages 126–133, 2003.
[18] H. Roger and J. Charles. Matrix Analysis. Cambridge
University Press, 1985.
[19] S. Thrun. Is learning the n-th thing any easier than
learning the ﬁrst? In NIPS, pages 640–646. MIT
Press, 1996.
[20] H. Wang, W. Fan, P. S. Yu, and J. Han. Mining
concept-drifting data streams using ensemble
classiﬁers. In KDD ’03, 2003.
[21] P. Wu and T. G. Dietterich. Improving svm accuracy
by training on auxiliary data sources. In ICML, pages
871–878, 2004.
[22] B. Zadrozny. Learning and evaluating classiﬁers under
sample selection bias. In ICML, page 114, 2004.
[23] B. Zadrozny and C. Elkan. Learning and making
decisions when costs and probabilities are both
unknown. In KDD, pages 204–213, New York, NY,
USA, 2001. ACM.
[24] J. Zhang, Z. Ghahramani, and Y. Yang. Learning
multiple related tasks using latent independent
component analysis. In NIPS, 2005.
[25] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and
B. Schölkopf. Ranking on data manifolds. In NIPS,
2003.
[26] X. Zhu, Z. Ghahramani, and J. Laﬀerty.
Semi-supervised learning using gaussian ﬁelds and
harmonic functions. In ICML, pages 912–919, 2003.

lutions to Q2 have been developed. Furthermore, we have
built the connection between Q2 and the objective function
Q1 , which is solely based on the tripartite graph. Finally,
based on the above connection, we have designed an iterative algorithm to ﬁnd the solutions to Q2 . Diﬀerent from
existing transfer learning methods, the proposed framework
propagates the label information to both the features irrelevant to the source domain and the unlabeled examples from
the target domain via the common features in a principled
way. Experimental results on several transfer learning tasks
demonstrate the superiority of the proposed framework over
state-of-the-art techniques. For future work, we are interested in investigating the theoretical bounds of the performance for graph-based transfer learning algorithms and the
applications to large-scale data sets.

7.

REFERENCES

[1] Kdd cup 99. In http://kdd.ics.uci.edu/databases
/kddcup99/kddcup99.html, 1999.
[2] R. K. Ando and T. Zhang. A framework for learning
predictive structures from multiple tasks and
unlabeled data. Journal of Machine Learning
Research, 6:1817–1853, 2005.
[3] J. Baxter. A bayesian/information theoretic model of
learning to learn viamultiple task sampling. Mach.
Learn., 28(1):7–39, 1997.
[4] J. Blitzer, M. Dredze, and F. Pereira. Biographies,
bollywood, boom-boxes and blenders: Domain
adaptation for sentiment classiﬁcation. In ACL, 2007.
[5] R. Caruana. Multitask learning. In Machine Learning,
pages 41–75, 1997.
[6] W. Dai, G.-R. Xue, Q. Yang, and Y. Yu. Co-clustering
based classiﬁcation for out-of-domain documents. In
KDD, pages 210–219, 2007.
[7] W. Dai, Q. Yang, G.-R. Xue, and Y. Yu. Boosting for
transfer learning. In ICML, pages 193–200, 2007.
[8] W. Fan, I. Davidson, B. Zadrozny, and P. S. Yu. An
improved categorization of classiﬁer’s sensitivity on
sample selection bias. In ICDM, pages 605–608,
Washington, DC, USA, 2005. IEEE Computer Society.
[9] J. Gao, W. Fan, J. Jiang, and J. Han. Knowledge
transfer via multiple model local structure mapping.
In KDD, pages 283–291, 2008.
[10] S.-I. Lee, V. Chatalbashev, D. Vickrey, and D. Koller.
Learning a meta-level prior for feature relevance from
multiple related tasks. In ICML, pages 489–496, 2007.

946

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Linking Heterogeneous Input Spaces with Pivots for
Multi-Task Learning
Jingrui He ∗

Yan Liu†

Abstract
Most existing works on multi-task learning (MTL) assume
the same input space for different tasks. In this paper, we
address a general setting where different tasks have heterogeneous input spaces. This setting has a lot of potential applications, yet it poses new algorithmic challenges - how can
we link seemingly uncorrelated tasks to mutually boost their
learning performance?
Our key observation is that in many real applications,
there might exist some correspondence among the inputs
of different tasks, which is referred to as pivots. For such
applications, we first propose a learning scheme for multiple
tasks and analyze its generalization performance. Then
we focus on the problems where only a limited number of
the pivots are available, and propose a general framework
to leverage the pivot information. The idea is to map
the heterogeneous input spaces to a common space, and
construct a single prediction model in this space for all
the tasks. We further propose an effective optimization
algorithm to find both the mappings and the prediction
model. Experimental results demonstrate its effectiveness,
especially with very limited number of pivots.
1 Introduction
Multi-task learning (MTL) has been proposed to address the
problem of labeled data scarcity in each single task, and
the goal is to leverage the label information from all the
related tasks to build a better model for each task. Multitask learning has been widely applied in many real problems,
such as sentiment classification in different domains [17],
remote sensing [20], cross-lingual classification [23], face
recognition [27], etc. In recent years, multi-task learning
has attracted extensive research attention from both the
application and the algorithm sides (see Section 2 for a brief
review). Most existing works assume that different tasks
share the same input space. In other words, the examples
from different tasks are represented by vectors in the same
space.
Here, we address a general setting where different tasks
∗ Stevens

Institute of Technology
of Southern California
‡ Hong Kong University of Science and Technology
† University

181

Qiang Yang‡

have heterogeneous input spaces. For example, in crosslingual classification [23], the first task might be classifying
a set of English documents whose input space consists of
English vocabulary, and the second task might be classifying
a set of German documents whose input space consists of
German vocabulary. Another example is simultaneous classification of documents and images [29]. Here the first task
is document classification whose input space consists of the
document vocabulary, and the second task is image classification whose input space consists of the ‘image vocabulary’ (e.g., clusters of image features extracted from different regions). Yet another example is cross-domain sentiment
classification [22], where different tasks correspond to the
classification of documents in different domains with different vocabularies. In all these examples, the two tasks have
different input spaces - we refer to this problem setting as
MUSH (Multi-Task Learning with Heterogeneous Input Spaces). Compared with the existing works on MTL in the
same input space, MUSH has received much less attention
up until now. Yet it is of great interest from the application
perspective, since it brings the possibility of jointly learning
multiple arbitrary tasks so that they could benefit from each
other.
MUSH also poses new challenges from the algorithm
perspective since multiple tasks seem to be totally uncorrelated with each other if their examples are in different input spaces. Here our key observation is that in many real
applications, there might exist some correspondence among
certain input dimensions of different tasks. In the example
of cross-lingual classification, there is a natural correspondence between the words from two different languages (e.g.,
‘good’ in English means ‘gut’ in German); in the example of
document-image classification, some words can be naturally
‘translated’ into some image regions, and vice versa [28]; in
the example of cross-domain sentiment classification, some
domain-specific words are linked via the same sentiment polarity. The correspondence across different input spaces provides an important connection among multiple tasks. In this
paper, such correspondence is represented by pivots, which
consist of tuples of input dimensions from multiple tasks
bearing the same correspondence.
The major contributions of this paper are three-fold.
First of all, when all the pivot information is available,

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

we propose the following learning scheme for MTL: we
first map the examples from heterogeneous input spaces of
multiple tasks to the same pivot space, and then construct
a single prediction model in the pivot space for all the
tasks. Second, we analyze this learning scheme in terms
of the generalization error of the prediction model for each
task. Finally, based on this scheme, we propose a general
framework, which, given a limited number of pivots, is
able to learn the mappings from the input spaces to a
common space and the prediction model in this space. In this
framework, to make use of the pivot information, we enforce
the input dimensions mapped to the same pivot be projected
to the common space in a similar way.
The rest of the paper is organized as follows. In Section
2, we briefly review the related work. The learning scheme
for MUSH with pivots is presented and analyzed in Section 3.
Based on this scheme, in Section 4, we introduce the general
framework for MUSH with a limited number of pivots.
Then we discuss a special case of this framework together
with the optimization algorithm in Section 5. In Section
6, we show some experimental results, which demonstrate
the effectiveness of our proposed algorithm. Finally, we
conclude the paper in Section 7.
2 Related Work
In multi-task learning, task relationship is usually modeled
in the following two ways. One is to construct prediction
functions in a common (derived) feature space. Here the
common feature space can be either the latent space [19, 7,
2, 1], or the augmented feature space [18, 4]. The other is to
assume shared function classes in the original feature space
and similar parameters [14, 6, 20, 12]. Our proposed model
is closer to the first way of modeling task relatedness in that
we also map the examples to the common space. However,
there are two major differences. One is that we focus on
the general setting where different tasks have different input
spaces, and the mappings for different tasks in terms of the
transformation matrices are not the same. The other is that,
for the first time, we make use of the pivot information to
guide the calculation of the transformation matrices.
Heterogeneous multi-task learning is one special type
of multi-task learning, where the dimensions of the inputs or
even the input space are different across different tasks [26,
9]. Several models have been proposed to solve the problem,
mostly motivated by cross-lingual applications [8, 25, 23,
29, 15, 16, 10]. For example, the TLRisk algorithm uses
a language model to link the class labels to the inputs in the
source spaces, which in turn is translated to the inputs in
the target spaces [8]; the co-training-based algorithm makes
use of Google translate to generate pivots for each word in
each language, creates multiple language-dependent views,
and then applies the co-training algorithm [5] to construct
the classifiers [25]; the CL-SCL algorithm chooses from

182

a large number of pivots the ones that satisfy the support
condition, and maps the examples from different tasks to a
common space according to the correlation of all the inputs
to the selected pivots [23]; the feature augmentation method
first transforms the data of heterogeneous input space into
a common subspace to measure their similarities and then
develops different feature mapping functions for each task to
augment the transformed data [10].
As we can see, some existing algorithms require a
large number of pivots (or dictionaries) to achieve good
results [25, 23], which might be infeasible to obtain in many
practical applications; on the other hand, if we apply the
multi-view based method [16] in our setting, the common
view would correspond to the pivots, and the task-specific
views would correspond to the remaining input dimensions.
However, the view consistency assumption may not hold if
we only have a limited number of pivots, which will impair
the performance of this method. In this paper we aim to
address these issues and improve the performance in each
task with only a limited number of pivots. As a result, the
major technical challenge is how to effectively explore the
connections between tasks.
3 Learning Scheme for MUSH with Pivots
In this section, we propose the learning scheme for MUSH
with pivots, followed by the analysis regarding its generalization performance.
3.1 Learning scheme Suppose that we have T tasks.
Each task has a set of labeled examples (xti , yit ), (i =
t
1, . . . , nt , t = 1, . . . , T ), where xti ∈ Rd denotes the
ith example in the tth task, dt is the dimensionality of the
input space for the tth task, yit is the output for input xti
(yit ∈ {1, −1} for classification problems, or yit ∈ R for
regression problems), and nt is the number of labeled examples in the tth task, which is usually small in multi-task
learning. Notice that each task has its unique input space,
and the number of input dimensions may be different across
multiple tasks. For example, in cross-lingual classification,
the English documents in Task 1 are described by a set of
English words, which is different from the set of German
words used to describe German documents in Task 2. Furthermore, let Dt denote the probability distribution of xti for
the tth task. Here, our goal is to leverage the labeled examples from all the tasks to build a good prediction model for
each task.
In this paper, we assume that the inputs for different
tasks are connected via P pivots, which span the pivot space
RP . In other words, for a certain task, each input dimension
can be mapped to a single pivot, and the pivots are shared
by multiple tasks. Therefore, in our previous example, the
English word ‘good’ and the German word ‘gut’ map to the
same pivot. On the other hand, multiple input dimensions of
a single task may be mapped to the same pivot. For example,

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

in sentiment classification problems, both the English word
‘good’ and ‘nice’ are mapped to the same pivot. Therefore,
for the tth task, each example xti is mapped to x̃ti ∈ RP
(i = 1, . . . , nt ) such that the value for a pivot is equal to
the sum of all the input dimensions mapped to the same
pivot. To be specific, if the elements in xti that correspond
to ‘good’ and ‘nice’ are 0.7 and 0.4 respectively, then the
element in x̃ti that corresponds to their pivot is 1.1. In this
way, we have the induced distribution D̃t for the tth task with
probability density function fD̃t (x̃) for x̃ ∈ RP . We also
assume that given x̃, the probability distribution of the label
D̃(y) is shared by all the tasks.
Based on the above notation, we propose the following
learning scheme for MUSH with pivots. We first map the
examples from all the tasks to the same pivot space, and
then construct a single prediction model in this space. In
the first step, we use different mappings for different tasks
to accommodate the heterogeneous input spaces; and in the
second step, we pool all the examples in the pivot space
together to build a good prediction model. As we will show
in the next subsection, if all the tasks have similar induced
distribution in the pivot space, the prediction model will have
good generalization performance for each task.
Throughout this paper, we use normal lower-case letters
to denote scalers or functions, normal upper-case letters
to denote constants, bold-face lower-case letters to denote
vectors, and bold-face upper-case letters to denote matrices.
Furthermore, in most cases, the superscript of a letter refers
to the task index, and the subscript refers to the example
index or input dimension index.
3.2 Generalization performance Next, we analyze the
proposed learning scheme in terms of the generalization
performance of the prediction model in the pivot space. To
this end, we first compare two distributions D̃s for the sth
task and D̃t for the tth task (s, t = 1, . . . , T ) in the pivot
space via the L1 distance, which is defined as
dL1 (D̃s , D̃t ) = 2 sup |PrD̃s [B] − PrD̃t [B]|
B∈B

where B denotes the set of measurable subsets under D̃s and
D̃t . In other words, if two tasks are similar, i.e., they have
similar distributions in the pivot space, then their L1 distance
should be small. In particular, dL1 (D̃t , D̃t ) = 0.
In this subsection, we focus on classification problems.
Let H denote a hypothesis space of VC-dimension C in
the pivot space. Given a classifier h ∈ H, we define its
prediction error with respect to the distribution D̃t (x̃) for the
tth task and D̃(y) as follows.
ϵt (h) = Ex̃∼D̃t ,y∼D̃ [I(y ̸= h(x̃))] = Prx̃∼D̃t ,y∼D̃ [y ̸= h(x̃)]

The following theorem builds the connection between
ϵt (h) and ϵ̂(h).
T HEOREM 3.1. For the tth task, with probability at least
1 − δ, for every h ∈ H:
(3.1)
√
T
4
2en
4 ∑ ns
ϵt (h) ≤ ϵ̂(h)+
(C log
+ log )+
dL1 (D̃s , D̃t )
n
C
δ s=1 2n
where n =

∑T
s=1

ns , and e is the Euler number.

Proof. In the pivot space, if we consider all the examples
multiple tasks as coming from a single distribution
∑T from
ns s
, then the prediction error ϵ(h) of h with respect
D̃
s=1 n
∑T
s
to this distribution can be written as ϵ(h) = s=1 nn ϵs (h).
Therefore the prediction error of h with respect to the distribution D̃t for the tth task can be bounded as follows.
ϵt (h) = ϵ(h) +

T
∑
ns
s=1

= ϵ(h) +

∫
T
∑
ns
n

s=1

= ϵ(h) +

T
∑
ns

n

s=1

∫
{

n

fD̃t (x̃) ≥fD̃s (x̃)

x̃

(ϵt (h) − ϵs (h))

Pry∼D̃ [y ̸= h(x̃)](fD̃t (x̃) − fD̃s (x̃))dx̃

·

Pry∼D̃ [y ̸= h(x̃)](fD̃t (x̃) − fD̃s (x̃))dx̃

∫

−
fD̃t (x̃) <fD̃s (x̃)

≤ ϵ(h) +

T
∑
ns
s=1

∫

fD̃t (x̃) ≥fD̃s (x̃)

≤ ϵ(h) +

·

Pry∼D̃ [y ̸= h(x̃)](fD̃t (x̃) − fD̃s (x̃))dx̃

∫
T
∑
ns
s=1

≤ ϵ(h) +

n

Pry∼D̃ [y ̸= h(x̃)](fD̃s (x̃) − fD̃t (x̃))dx̃}

n

fD̃t (x̃) ≥fD̃s (x̃)

(fD̃t (x̃) − fD̃s (x̃))dx̃

T
∑
ns
dL1 (D̃s , D̃t )
2n
s=1

On the other hand, by applying Vapnik-Chervonenkis theory [24], we can bound ϵ(h) by its empirical estimate ϵ̂(h).
Combined with the fact that the VC-dimension of H is C,
we can show that with probability at least 1 − δ,
√
ˆ + 4 (C log 2en + log 4 )
ϵ(h) ≤ ϵ(h)
n
C
δ

where I(·) is the indicator function. We also define the
Putting everything together, we complete the proof.
empirical error in the pivot space as follows.
Notice that in Equation (1), we have three terms on the
t
n
T ∑
T
∑
∑
right
hand side. The first two terms are obtained as if all the
t
t
t
ϵ̂(h) =
I(yi ̸= h(x̃i ))/(
n)
examples come from the same task. The third term is unique
t=1 i=1
t=1

183

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

for multi-task learning, and it measures how related/similar
different tasks are. On one hand, if all the tasks have the
same distribution in the pivot space, then the third term
is equal to 0, and Equation (1) is reduced to the bound
for single task learning; on the other hand, if all the tasks
are completely different in the sense that the L1 distance
between any pair of them reaches the maximum value 1,
then the third term is equal to 1, which means that multi-task
learning does not help in such cases.
According to Theorem 3.1, comparing MTL with
Single-Task Learning (STL), the main advantage of MTL is
in the fact that it leverages all n labeled examples from multiple tasks to build the prediction model, as opposed to only
using nt labeled examples from the tth task. Therefore, MTL
is a effective way to solve the problem of label scarcity.
4 General Framework
The learning scheme proposed in Section 3 is based on the
assumption that we know the mapping from each input space
to the pivot space. Notice that in many real applications, the
mappings may not be available to us or may be expensive to
obtain. For example, in cross-lingual classification, given
documents in several languages, we may only know the
correspondence of a small number of words from different
vocabularies. In this case, our goal is to leverage the limited
pivot information to help us find the mappings from the input
space to a common space (not necessarily the pivot space),
as well as the prediction model in this space.
In this section, we assume that we are given p pivots,
p ≪ P . Each pivot is a T -tuple of input dimensions, one
dimension from each task, although our proposed framework
can be easily generalized to the cases where multiple input
dimensions of a single task map to the same pivot. For the
ease of explanation, we rearrange the inputs in each task so
that the first p dimensions in each task are always contained
in the pivots.
In our framework, we assume that examples from multiple tasks can be mapped into a d-dimensional common space, where a single prediction model can be used to predict
the outputs of examples from all the tasks. Notice that ideally, d should be equal to P , and the common space is the
pivot space. However, due to the lack of the pivot information, we need to learn the mappings from the data. Therefore,
the common space is not necessarily the same as the pivot space. The major difference between this assumption and the
one used in [2] is: in our case, the transformation matrices
for different tasks are different, but the prediction model in
the common space is shared by all the tasks; whereas in [2],
the transformation matrix is the same for all the tasks, but the
prediction models vary among the tasks. In applications such
as cross-lingual classification and document-image classification, our assumption is more appropriate. To see this, simply notice that due to the different input spaces of different

184

tasks, we can not use a single transformation matrix for all
the tasks. Furthermore, we assume that the input dimensions
corresponding to the same pivot have similar prediction power of the output. Therefore, their projection matrices to the
common space should be similar. This is motivated by the
mappings from the input space to the pivot space introduced
in the last section when all P pivots are available: the input
dimensions corresponding to the same pivot are mapped to
this pivot with weight 1.
Based on the above assumptions, we first use the taskt
specific transformation matrix Ut ∈ Rd×d to map the
th
examples in the t task to the d-dimensional common space,
d ≤ dt , (t = 1, . . . , T ). Here, we require that the rows of Ut
be orthonormal. Notice that since the first p input dimensions
in each task are contained in the pivots, Ut (:, 1 : p), the
first p columns of Ut , correspond to the projection matrix of
these dimensions to the common space. Due to the definition
of pivots such that input dimensions contained in the same
pivot have similar contribution to the output, Ut (:, 1 : p)
should all be close to a certain matrix V ∈ Rd×p . In
other words, similar as in [13], the projection matrices for
the dimensions contained in pivots are regularized via their
mean. Then we construct a linear predictor in the common
space with coefficient vector a ∈ Rd based on the labeled
examples from all the tasks. To be specific, we propose the
following objective function in Equation (2).
T
n
∑
1 ∑
( t
L(yit , a′ Ut xti ))
n i=1
t=1
t

min fd (Ut , V, a) =

(4.2)

+

T
∑
(γ t ∥Ut (:, 1 : p) − V∥2F ) + γ∥a∥2
t=1

s.t. U · (Ut )′ = Id×d , (t = 1, . . . , T )
t

where a′ denotes the transpose of a, L(·, ·) denotes the
prediction loss, ∥ · ∥F denotes matrix Frobenius norm, ∥ · ∥
denotes vector L2 norm, Id×d is a d × d identity matrix, γ t
and γ are positive parameters that balance among different
terms in this objective function.
In the objective function of Equation (2), the first term
measures the average prediction loss of all the tasks, the
second term measures the difference between the projection
matrices for the dimensions contained in pivots and the
matrix V, which encourages similar projections for the
dimensions in the same pivot, and the last term penalizes
the L2 norm of the linear classifier in the common space.
When γ t = 0 (t = 1, . . . , T ), Equation (2) imposes weak
relatedness among multiple tasks, since it only requires
the L2 norm of all the coefficient vectors to be the same,
and the pivot information is not used. On the other hand,
when γ t → ∞, (t = 1, . . . , T ), the projection matrices
for the dimensions contained in pivots are all forced to be
V. We will discuss this special case in Section 5. The

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

constraints in Equation (2) require that the transformation
matrices Ut be orthonormal. This is to avoid the nonidentifiability problem. For each task, the matrices that
satisfy this constraint constitute the Stiefel manifold [11].
With respect to the generalization performance of this
prediction model, we have the following lemma.

∑T
p). Let Vi = n1t t=1 Uti (:, 1 : p) (i = 1, 2). It is easy to
see that the first d1 − 1 rows of V1 and V2 are the same, and
1 )V2 (d1 ,:)+a2 (d2 )V2 (d2 ,:)
the last row of V1 is equal to a2 (d√
.
2
2
(a2 (d1 )) +(a2 (d2 ))

Based on the two sets of transformation matrices Ut1 and
Ut2 (t = 1, . . . , T ), V1 , V2 , the coefficient vectors a1 and
a2 , we can compare fd1 (Ut1 , V1 , a1 ) and fd2 (Ut2 , V2 , a2 ).
th
L EMMA 4.1. For the t task, with probability at least 1 − δ, In Equation (2), the first term a′1 Ut1 = a′2 Ut2 (t = 1, . . . , T ),
for every h ∈ H:
and the third term ∥a1 ∥2 = ∥a2 ∥2 . Therefore, we only need
√
to compare the second term. ∀t = 1, . . . , T ,
4
2en
4
((d + 1) log
+ log )
ϵt (h) ≤ϵ̂(h) +
∥Ut2 (:, 1 : p) − V2 ∥2F − ∥Ut1 (:, 1 : p) − V1 ∥2F
n
d+1
δ
=∥Ut2 (d1 : d2 , 1 : p) − V2 (d1 : d2 , :)∥2F
T
∑
ns
s
t
+
dL1 (D̃ , D̃ )
− ∥Ut1 (d1 , 1 : p) − V1 (d1 , :)∥2
2n
s=1
≥∥Ut2 (d1 : d2 , 1 : p) − V2 (d1 : d2 , :)∥2
Proof. Theorem 3.1 combined with the fact that the VCa2 (d2 )
a2 (d1 )
dimension of linear classifiers in the d-dimensional common
√
− ∥[ √
]·
space is d + 1 proves this lemma.
(a2 (d1 ))2 + (a2 (d2 ))2
(a2 (d1 ))2 + (a2 (d2 ))2
The objective function in Equation (2) is not jointly con(Ut2 (d1 : d2 , 1 : p) − V2 (d1 : d2 , :))∥2
vex in Ut , U, and a. However, as long as L(·, ·) is convex
with respect to the second argument, the objective function ≥0
is convex with respect to each of its variables. Therefore, Therefore, the minimum of fd2 (Ut2 , V2 , a2 ) is no smaller
we could apply block coordinate descent to iteratively up- than the minimum of fd1 (Ut1 , V1 , a1 ).
date Ut , U and a, which is guaranteed to converge to a local
optimum [21]. Furthermore, in order to update the orthonor- 5 A Special Case of the Framework
mal transformation matrices, we could apply Newton or con- In this section, we discuss a special case of the general
jugate gradient methods on the Stiefel manifold [11]. For the framework proposed in Section 4 when γ t → ∞, (t =
special case of the optimization framework to be discussed 1, . . . , T ). In this case, Ut (:, 1 : p) = V, (t = 1, . . . , T ).
in the next section, we will introduce a simple solution via That is, the projection matrices for the input dimensions
gradient descent.
contained in pivots are exactly the same across all the tasks.
Before ending this section, we would like to point out ∀t = 1, . . . , T , let Ut = [V Vt ], where Vt ∈ Rd×(dt −p) .
that the minimum of the objective function fd depends on The problem in Equation (2) can be written as follows.
the dimensionality d of the common space. The following (5.3)
T ∑
nt
theorem shows that it is non-decreasing with respect to d.
∑
L(yit , a′ [V Vt ]xti )
t
min gd (V , V, a) =
+ γ∥a∥2
T HEOREM 4.1. For any pair of positive integers d1 and d2 ,
nt
t=1 i=1
such that d2 > d1 , min fd2 ≥ min fd1 .
s.t. V · (V)′ + Vt · (Vt )′ = Id×d , (t = 1, . . . , T )
Proof. Without loss of generality, assume that d2 =
In Theorem 4.1, we have shown that the minimum value
d1 + 1. When the dimensionality of the common space is d2 ,
let Ut2 denote the transformation matrix of size d2 × dt for of the objective function in Equation (2) depends on d, the
the tth task (t = 1, . . . , T ). Therefore, Ut2 · (Ut2 )′ = Id2 ×d2 . dimensionality of the common space. Although Equation
(3) is a special case of Equation (2), the following theorem
Let a2 denote any coefficient vector of length d2 .
On the other hand, when the dimensionality of the shows that under certain conditions, the minimum of gd is
common space is d1 , we construct the set of orthonormal independent of d.
t
transformation matrices Ut1 ∈ d1 × dt (t = 1, . . . , T ) as T HEOREM 5.1. If d < min(p, d − p), then Equation (3) is
t
t
equivalent
to
the
following
optimization
problem.
follows. Let the first d1 − 1 rows of U1 be the same as U2 ,
T
nt
∑
∑
a2 (d1 )Ut2 (d1 ,:)+a2 (d2 )Ut2 (d2 :)
t
1
√
and the last row of U1 be
, where (5.4) min g(ut , c) =
( t
L(yit , (ut )′ xti )) + γc2
(a2 (d1 ))2 +(a2 (d2 ))2
n
t=1
i=1
a2 (d1 ) is the d1 th element in a2 , and Ut2 (d1 , :) denotes the
t
th
t
t
s.t.
u
(1
:
p)
=
v
d1 row in U2 . It is easy to verify that U1 is orthonormal.
The coefficient vector a1 ∈ Rd1 is constructed in a similar
∥ut ∥ = c, (t = 1, . . . , T )
way by setting
a
(i)
=
a
(i)
(i
=
1,
.
.
.
,
d
−
1),
and
1
2
1
√
t
a1 (d1 ) = (a2 (d1 ))2 + (a2 (d2 ))2 .
where ut ∈ Rd , ut (1 : p) denotes the first p elements of ut ,
p
Notice that in Equation (2), the minimum
∑Tvalue tof the and v ∈ R is the common coefficient vector for the input
1
objective function is obtained when V = nt t=1 U (:, 1 : dimensions contained in pivots.

185

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

Proof. First of all, it is easy to see when d = 1, the
coefficient vector a is reduced to a scaler, and Equation (3)
is equivalent to Equation (4). Next, we need to show that the
minimum of gd does not depend on d. According to Theorem
4.2, when d > 1, the minimum of gd is no smaller than the
minimum of g. We will prove that the minimum of g is also
no smaller than the minimum of gd . To this end, next we
show that given any feasible solution to Equation (4), there
always exists a feasible solution to Equation (3) such that
their objective functions have the same value.
Let ut = c[v′ (vt )′ ]′ (t = 1, . . . , T ) denote the set of
feasible coefficient vectors for Equation (4), where vt ∈
t
Rd −p , and ∥v∥2 + ∥vt ∥2 = 1. Let V = [v W′ ]′ and Vt =
[vt (Wt )′ ]′ denote a set of matrices constructed based on v
t
and vt where W ∈ R(d−1)×p and Wt ∈ R(d−1)×(d −p)
(t =, 1 . . . , T ). Next, we prove that W and Wt can be
constructed in such a way that V · (V)′ + Vt · (Vt )′ = Id×d
(t = 1, . . . , T ). In other words,
V · (V)′ + Vt · (Vt )′
]
[ ′ ]
[
]
v
(vt )′ [ t
′
v (Wt )′
=
[v W ] +
W
Wt
[ ′
]
v v + (vt )′ vt v′ W′ + (vt )′ (Wt )′
=
Wv + Wt vt WW′ + Wt (Wt )′
]
[
1
v′ W′ + (vt )′ (Wt )′
= Id×d
=
Wv + Wt vt WW′ + Wt (Wt )′

Therefore, we can construct B and Bt as follows. Let
t ′
)
v′
, and the first row of Bt be − (v
the first row of B be ∥v∥
∥vt ∥ .
Let the remaining rows of B (Bt ) be unit-length row vectors
that are orthogonal to the first row as well as orthogonal
among themselves, which is always achievable since d <
min(p, dt − p). Finally, by setting a(1) = c and a(i) = 0
(i = 2, . . . , d), gd (Vt , V, a) is equal to g(ut , c).
Putting everything together, we have shown that for
any feasible solution to Equation (4), there always exists
a feasible solution to Equation (3) with the same objective
function value. Therefore, the minimum of g is no smaller
than the minimum of gd . Together with Theorem 4.2, we
complete the proof.
Based on Theorem 5.1, we can see that when the
dimensionality of the common space d is smaller than both p
and dt − p, (t = 1, . . . , T ), the value of d will not affect the
optimal solution, and Equation (3) is equivalent to Equation
(4), where we only need to minimize the objective function
with respect to a set of equal-length vectors ut , whereas in
Equation (3), we need to optimize with respect to a set of
orthonormal matrices. Let ut = [v′ , (vt )′ ]′ (t = 1, . . . , T ).
According to the constraints in Equation (4), vt should have
equal lengths.
Similar as before, the optimization problem in Equation
(4) is not jointly convex with respect to v and vt . Here we
propose MUSH-p, a gradient descent based method to find a
local optimum, which is described in Algorithm 1.

Therefore, W and Wt need to satisfy the following
equations.
Algorithm 1 MUSH-p algorithm
t t
Input: (xti , yit ), (i = 1, . . . , nt , t = 1, . . . , T ), L(·, ·), p, γ,
Wv + W v = 0
(5)
the number of iteration steps I
(6)
W(W)′ + Wt (Wt )′ = I(d−1)×(d−1)
Output: ut , (t = 1, . . . , T )
Let AΛA′ denote the eigen-decomposition of WW′ ,
1: Initialize v and vt to be zero vectors
(d−1)×(d−1)
where A ∈ R
is an orthogonal matrix, and Λ ∈
2: for i = 1 to I do
∂g
∂g
R(d−1)×(d−1) is a diagonal matrix whose diagonal elements
3:
Calculate the gradient ∇v = ∂v
and ∇vt = ∂v
t,
are non-negative. From Equation (6), it is easy to see that
(t = 1, . . . , T )
the eigen-decomposition of Wt (Wt )′ is A(I(d−1)×(d−1) −
4:
Perform line search to find the optimal step size ct ,
′
Λ)A , and the diagonal elements of Λ are no greater than
(t = 1, . . . , T ), such that ∥vt − ct ∇vt ∥ is a constant
1. Therefore,
the SVD
across different tasks
√
√ decomposition of W can be written
as A ΛB, where Λ is a diagonal matrix whose diagonal
5:
For t = 1, . . . , T , update vt ← vt − ct ∇vt
elements are square root of Λ, B ∈ R(d−1)×p , and BB′ =
6:
Perform line search to find the optimal step size c0 ,
I(d−1)×(d−1) . Similarly, the SVD decomposition of Wt
and update v ← v − c0 ∇v
√
t
t
7: end for
can be written as A I(d−1)×(d−1) − ΛB , where B ∈
(d−1)×(dt −p)
t
t ′
8: Generate ut = [v′ , (vt )′ ]′ , (t = 1, . . . , T )
R
, and B (B ) = I(d−1)×(d−1) . Therefore,
Equation (5) becomes,
√
√
ΛBv + I(d−1)×(d−1) − ΛBt vt = 0

Algorithm 1 works as follows. In Step 1, we initialize
all the vectors to be zero. Then we iteratively update the
vectors S times. To be specific, in Step 3, we calculate the
Let Λ = ∥vt ∥2 I(d−1)×(d−1) , then I(d−1)×(d−1) − Λ = gradient vectors ∇v and ∇vt ; in Step 4, we perform line
∥v∥2 I(d−1)×(d−1) , and the above equation is equivalent to
search to find the optimal step sizes while maintaining the
t
equal-length constraint, which can be done by varying the
v
v
+ Bt t = 0
B
step size for one task and calculating the step sizes for the
∥v∥
∥v ∥

186

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

6 Experimental Results
In this section we evaluate the performance of the proposed
algorithms. In particular, we would like to answer the following questions: (1) Does the performance of MUSH-p improve as more pivots are given? (2) Given different labeled
set sizes, how does MUSH-p compare with alternative competitors?
6.1 Experimental set-up In this paper, we use the crosslingual sentiment classification data set from [23]. It consists
of 4 million product reviews from Amazon.{de|fr|co.jp},
which are written in three languages: German, French, and
Japanese. Furthermore, the corpus is extended with English
product reviews from [3], and dictionaries between English
and the three languages are available. To assign class labels,
a review with >3 (<3) stars is labeled as positive (negative),
and other reviews are discarded. For each language, the
labeled reviews are grouped into 3 categories: books, dvd,
and music [23]. Based on this data set, we can create multitask learning problems as follows. We pick a category, say
books, and assign reviews from this category in 2 different
languages to 2 tasks, say English and German1 . The goal is
to leverage the labeled reviews from both tasks to classify
the unlabeled reviews.
Due to the scarcity of existing methods for MUSH
which are able to utilize pivot information, we adapt the
CL-SCL algorithm for transfer learning [23] to the multitask learning setting for the sake of comparison. Notice that
our proposed MUSH-p algorithm is supervised, whereas CLSCL is semi-supervised. Therefore, in our experiments, in
addition to the labeled training set, CL-SCL is also given
the unlabeled test set in each task, and its performance on
these test sets is reported for comparison. For this algorithm,
we set the parameters the same way as in [23]. For a
fair comparison, CL-SCL is provided with the same set of
pivots as our proposed algorithms. Besides CL-SCL, we also
compare with two simple baselines. The first one is single
task learning, denoted as STL, where multiple tasks are
learned separately without considering the pivot information.
The second one is to project all the examples to the space
spanned by the pivots, and construct a single classifier in this
space to predict the examples from different tasks, which
is denoted as Pivot-Space. For the proposed MUSH-p we
1 Since we only have dictionaries between English and the other languages, one task always consists of reviews in English.

187

Average Classification Error

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

other tasks; in Step 5, we update vt ; and in Step 6, we update use the negative log-likelihood in logistic regression as the
the common vector v for the input dimensions contained in loss function L(·, ·), and the parameters are chosen by crosspivots. Finally, in Step 8, we obtain the weight vectors ut validation.
by concatenating v and vt . During the test phase, we predict
the output of xt from the tth task using the sign of (ut )′ xt for
0.305
classification problems, or the value of (ut )′ xt for regression
400 labeled examples
0.3
problems.
800 labeled examples
1200 labeled examples

0.295
0.29
0.285
0.28
0.275
0.27
0.265

200

400

600

800

1000

Number of Pivots

Figure 1: Performance study with various number of pivots.

6.2 Pivot study In this subsection, we answer the first
question. To this end, we pick the reviews from the category
of books written the English and German languages, vary
the number of pivots provided to MUSH-p, and report the
average classification error with 400, 800, and 1200 labeled
examples respectively in Figure 1. From this figure, we
can see that all 3 curves follow the same trend: in the
beginning when we only have a small number of pivots,
more pivot information helps improve the performance, and
the performance is stabilized around 400 pivots, beyond
which no improvement is observed with additional pivot
information.
6.3 Comparison with alternative competitors In this
subsection, we answer the second question. Here we show
the comparison results on 9 multi-task learning problems in
Figure 2. In these figures, the x-axis shows the total number
of labeled training examples, and the y-axis is the average
classification error on the test sets of the two tasks over 10
runs. The number of available pivots is fixed at 100. From
these figures, we have the following observations. (1) The
performance of MUSH-p is better than STL in most cases,
which also uses logistic regression in the two tasks, but ignores the pivots. It shows that making use of the pivot information to build the connection among different tasks can
indeed improve the performance. (2) The performance of
MUSH-p is also better than Pivot-Space, which combines the
label information from all the tasks, but ignores the non-pivot
input dimensions. This is because when the number of pivots is small, constructing the classifier solely based on the
pivots tends to lose much information. (3) The performance
of CL-SCL is the worst of all the competitors, which can
be explained as follows. In CL-SCL, the subspace of bilingual classifiers is approximated using the pivot predictors. A
small number of pivots may negatively affect this approximation, which in turn affects its performance.

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

0.5

0.35

0.3

500

1000

1500

0.45

MUSH−p
STL
CL−SCL
Pivot−Space

0.4

0.35

0.3

0.25

2000

0.5

Average Classification Error

Average Classification Error

Average Classification Error

MUSH−p
STL
CL−SCL
Pivot−Space

0.4

0.25

Number of Labeled Training Examples

500

1000

1500

0.4

0.35

0.3

0.25

2000

MUSH−p
STL
CL−SCL
Pivot−Space

0.45

Number of Labeled Training Examples

(a) books: English vs. German

500

1000

1500

2000

Number of Labeled Training Examples

(b) dvd: English vs. German

(c) music: English vs. German

0.5

0.45

0.4

0.35

0.3

0.25

500

1000

1500

0.45

MUSH−p
STL
CL−SCL
Pivot−Space

0.4

0.35

0.3

0.25

2000

Average Classification Error

0.5

MUSH−p
STL
CL−SCL
Pivot−Space

Average Classification Error

Average Classification Error

0.5

500

1000

1500

0.4

0.35

0.3

0.25

2000

(d) books: English vs. France

MUSH−p
STL
CL−SCL
Pivot−Space

0.45

Number of Labeled Training Examples

Number of Labeled Training Examples

500

1000

1500

2000

Number of Labeled Training Examples

(e) dvd: English vs. France

(f) music: English vs. France

0.5

0.4

MUSH−p
STL
CL−SCL
Pivot−Space

0.35

0.3

500

1000

1500

2000

Number of Labeled Training Examples

(g) books: English vs. Japanese

0.5

MUSH−p
STL
CL−SCL
Pivot−Space

0.45

Average Classification Error

Average Classification Error

0.45

Average Classification Error

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

0.5
0.45

0.4

0.35

0.3

0.25

500

1000

1500

Number of Labeled Training Examples

(h) dvd: English vs. Japanese

2000

0.45

MUSH−p
STL
CL−SCL
Pivot−Space

0.4

0.35

0.3

0.25

500

1000

1500

2000

Number of Labeled Training Examples

(i) music: English vs. Japanese

Figure 2: Comparison of average classification error with various labeled set sizes: MUSH-p is consistently better than the
competitors.

References
7 Conclusion
In this paper, we study MUSH, a general setting in MTL
[1] R. K. Ando and T. Zhang. A framework for learning
where different tasks have heterogeneous input spaces. To
predictive structures from multiple tasks and unlabeled
this end, we first propose a learning scheme, which maps
data. Journal of Machine Learning Research, 6:1817–
the examples from all the tasks to the pivot space, and
1853, 2005.
then construct a single prediction model in this space. The
[2] A. Argyriou, T. Evgeniou, and M. Pontil. Conperformance of the prediction model is shown to depend on
vex multi-task feature learning. Machine Learning,
both the total number of examples, as well as the similarity
73(3):243–272, 2008.
among multiple tasks. Based on this scheme, we focus
on the problems where only a limited number of pivots [3] J. Blitzer, M. Dredze, and F. Pereira. Biographies, bolare available, and propose an optimization framework to
lywood, boom-boxes and blenders: Domain adaptation
find both the mappings and the prediction model. Finally,
for sentiment classification. In ACL, 2007.
we propose the MUSH-p algorithm to solve a special case
of this framework. Experimental results demonstrate the [4] J. Blitzer, R. T. McDonald, and F. Pereira. Domain
adaptation with structural correspondence learning. In
effectiveness of MUSH-p.
EMNLP, pages 120–128, 2006.
[5] A. Blum and T. M. Mitchell. Combining labeled and
unlabeled sata with co-training. In COLT, 1998.

188

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

Downloaded 06/22/17 to 149.169.221.96. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php

[6] E. V. Bonilla, K. M. Chai, and C. K. I. Williams. Multi- [18] H. D. III. Frustratingly easy domain adaptation. CoRR,
abs/0907.1815, 2009.
task gaussian process prediction. In NIPS, 2007.
[7] J. Chen, L. Tang, J. Liu, and J. Ye. A convex formula- [19] B. Lin, S. Yang, C. Zhang, J. Ye, and X. He. Multi-task
tion for learning shared structures from multiple tasks.
vector field learning. In NIPS, pages 296–304, 2012.
In ICML, page 18, 2009.
[20] Q. Liu, X. Liao, and L. Carin. Semi-supervised multi[8] W. Dai, Y. Chen, G.-R. Xue, Q. Yang, and Y. Yu.
task learning. In NIPS, 2007.
Translated learning: Transfer learning across different
[21] D. G. Luenberger. Linear and Nonlinear Programming.
feature spaces. In NIPS, pages 353–360, 2008.
Addison-Wesley, Massachusetts, 2nd edition edition,
[9] W. Dai, O. Jin, G.-R. Xue, Q. Yang, and Y. Yu. Eigen1973.
transfer: a unified framework for transfer learning. In
[22] S. J. Pan, X. Ni, J.-T. Sun, Q. Yang, and Z. Chen. CrossICML, page 25, 2009.
domain sentiment classification via spectral feature
[10] L. Duan, D. Xu, and I. W. Tsang. Learning with augalignment. In WWW, pages 751–760, 2010.
mented features for heterogeneous domain adaptation. [23] P. Prettenhofer and B. Stein. Cross-language text
In ICML, 2012.
classification using structural correspondence learning.
In ACL, pages 1118–1127, 2010.
[11] A. Edelman, T. s, A. Arias, Steven, and T. Smith. The
geometry of algorithms with orthogonality constraints. [24] V. Vapnik. Statistical learning theory. Wiley, 1998.
SIAM J. Matrix Anal. Appl, 20:303–353, 1998.
[25] X. Wan. Co-training for cross-lingual sentiment classi[12] T. Evgeniou, C. A. Micchelli, and M. Pontil. Learning
fication. In ACL/AFNLP, pages 235–243, 2009.
multiple tasks with kernel methods. Journal of Machine Learning Research, 6:615–637, 2005.
[26] Q. Yang, Y. Chen, G.-R. Xue, W. Dai, and Y. Yu.
Heterogeneous transfer learning for image clustering
[13] T. Evgeniou and M. Pontil. Regularized multi–task
via the socialweb. In ACL/AFNLP, pages 1–9, Suntec,
learning. In KDD, pages 109–117, 2004.
Singapore, August 2009.
[14] P. Gong, J. Ye, and C. Zhang. Multi-stage multi-task
[27] Y. Zhang and J. Schneider. Learning multiple tasks
feature learning. In NIPS, pages 1997–2005, 2012.
with a sparse matrix-normal penalty. In NIPS, 2010.
[15] M. Harel and S. Mannor. Learning from multiple
[28] X. Zhu, A. B. Goldberg, M. Eldawy, C. R. Dyer,
outlooks. In ICML, pages 401–408, 2011.
and B. Strock. A text-to-picture synthesis system for
augmenting communication. In AAAI, pages 1590–,
[16] J. He and R. Lawrence. A graphbased framework for
2007.
multi-task multi-view learning. In ICML, pages 25–32,
2011.
[29] Y. Zhu, Y. Chen, Z. Lu, S. J. Pan, G.-R. Xue, Y. Yu, and
Q. Yang. Heterogeneous transfer learning for image
[17] H. D. III. Bayesian multitask learning with latent
classification. In AAAI, 2011.
hierarchies. CoRR, abs/0907.0783, 2009.

189

Copyright © SIAM.
Unauthorized reproduction of this article is prohibited.

2004 International Conference on Image Processing (ICIP)

SYMMETRY FEATURE IN CONTENT-BASED IMAGE RETRIEVAL'
Jingnii He', Mingjing Li', Hong-hung Zhang, Changshui Zhany
','Department of Automation, Tsinghua University, Beijing 100084, China
'Microsoft Research Asia, 49 Zhichun Road, Beijing 100080, China
'hejingrui98@mails.tsinghua.edu.cn, {mjli, hjzhang}@microsoft.com, lzCs@tsinghua,edu.cn
ABSTRACT
In this papcr, we first apply thc theory of wallpapcr
groups to natural images and cxtract a novcl feature to
depict thc symmetry propcrty of natural images. The
original proposed algorithm takes autocorrelation and
correlation as a preprocessing stcp, which is very timeconsuming. Through further analysis, wc develop a sct of
schemcs to accelerate this algorithm. Experimental results
demonstrate that in performing content-based imagc retrieval, thc proposed symmctry feature outperforms wavelet feature, which is a widcly accepted descriptor of tcxture, and water-filling featurc. The accelerated version of
the algorithm improves the processing speed by a large
margin while it brings little degradation to retrieval performance.

1. INTRODUCTION
In thc past few decades, content-based image retrieval
(CBIR) has been an active research topic as a result of an
explosively growing volume of digital images. One of the
basic problems in CBIR is to extract proper features to
represent the contents of the original images. Many kinds
of features have been proposed and investigated, including color, texture, shape and structure. All of them contribute to the improvement of performance in CBIR systems. For example, to make use of color information,
Swain and Ballard [IO] proposed using color histograms
as image representation; Markus et a1 [9] first introduced
color moment feature for indexing. By incorporating spatial correlations of colors, correlogram feature proposed
by Huang et a1 [4] tends to achieve better retrieval performance than the above two features. Color coherence
vector proposed by Pass et a1 [7] is another efficient feature which combines color and spatial information. To
depict texture property, Jacobs et al [5] and Wang et a1
[ l l ] applied Haar wavelet and Daubechies wavelet transforms to the original images respectively and compared

their corresponding cocfficicnts as the similarity measurc.
In [13, 141, Zhou et a1 extract structural features through
the water-filling algorithm, hoping to obtain salicnt edges
and structurc information.
As is mentioncd in [6], symmetry is pcrvasivc in both
natural and man-made environments. It also plays a nontrivial role in human recognition. For example, Reisfeld
et al [SI propose a robust facial feature detector based on a
generalized symmctry interest operator; Gauch et al [ I ]
prcsenl a shapc-bascd image segmentation method using
intensity axis of symmetry (IAS). According to the theory
of wallpaper groups [2], the infinite variety of symmetry
patterns can be wcll categorized into seventeen Crystallographic groups. This thcory has already hcen applied in
Chemistry, analyzing molecules and crystal, etc [12].
However, since strictly symmetrical patterns rarely appear
in natural images, there is no research applying this theory
to dcpict natural image contents as far as we know.
Based on the thcory of wallpaper groups, in this paper, we first propose an algorithm to extract symmetry
features on multi-scale for natural images. The original
algorithm takes autocorrelation and correlation as a preprocessing step, thus it is very time-consuming. Through
further analysis, we accelerate the algorithm and make it
suitable for practical use. To demonstrate the effectiveness of the proposed symmetry feature, we compare it
with wavelet and water-filling features on a general purpose image database including 5,000 Corel images. The
experimental results are very promising.
The rest of the paper is organized as follows. In section 2, we propose the symmetry feature for natural images. In section 3, we discuss the acceleration scheme.
Experimental results are presented in section 4. Finally,
we conclude the paper in section 5.

2. T H E SYMMETRY FEATURE FOR NATURAL
IMAGES
2.1. Symmetry feature

This work was performed at Microsoft Research Asia

0-7803-8554-3/04/$20.00 0 2 0 0 4 IEEE.

417

According to thc theory of wallpaper groups [ 2 ] , there are
exactly seventeen different plane symmetry groups, which
are charactcrized by four distinct kinds of planar symmetry, namely translation symmetry, rotation symmetry, reflection symmetry and glide reflection symmetry. The
thcory also guarantees that rotation symmetry can only be
2-fold, 3-fold, 4-fold and 6-fold, where k -fold means
360/k ( t= 2 , 3 , 4 , 6 ) degrees rotation. To determine the
symmetry typc o r a 2D repeated pattern, Liu et al [6] first
apply the symmetry to be tcsted to the entire pattern, thcn
check thc similarity between the original and transformed
images. In [3], we generalize this idca by comparing the
corrclation between the original and transformed imagcs
with thc autocorrelation of the original image in terms or
translation vectors. However, the above two pieces of
work can only deal with man-madc repeated pattcms:
In this paper, for the first timc we try lo extcnd our
idea in [ 3 ]to natural images. To makc symmetry property
explicit for natural images, we first divide the images into
blocks and examine thcir symmctry property. When dealing with natural images, we only focus on rotation symmetry. Thc reason lies in the fact that reflection symmetry
and glide rcflection symmctry cannot be correctly identified if there is no information about the reflection axis,
which is just the case when we deal with natural images.
On the other hand, translation symmetry can only be identified when there are more than four identical repeated
units in thc neighborhood which rarely appears in natural
images.
2.2. Feature extraction algorithm

To fully describe local details, we divide a given image
into small blocks. Neighboring blocks have half of their
area overlapping to avoid unreasonable segmentation.
Like in [ 3 ] , to determine the presence of a certain kind of
rotation symmetry, we fust rotate the original block and
compute its correlation with the transformed block, then
compare the result with the autocorrelation of the original
block. However, the'comparison cannot be done based on
translation vectors due to the lack of repeated units. In
this case, we compare the maximum values of correlation
and autocorrelation instead, which can be interpreted intuitively as follows. If a block has a certain kind of rotation symmetry, the rotated block will exhibit similar appearance as the original one, thus the maximum value of
correlation, which corresponds to a good match between
the two blocks, approximates that of autocorrelation. To
be specific, let am and c. denote the maximum values of
autocorrelation and correlation respectively, i.e.
a, = max,,] a ( i ,j ) , c, = max,,, c(i,j ) , where o(i,j ) and
c(i,j ) denote autocorrelation and correlation values at the
point ( i , j ) . Furthermore, to obviate the influence of different area involved in computing autocorrelation and

corrclation, we normalize a, and cm in the following
way: 3, =a, /area, , Z," = cm/area,, where oreau = h . w is
the size of the original block with hcight h and width w ,
and urea, is the ovcrlapping area bctween the two blocks
with their centers in superposition. Thus the symmetry
measure o r a block can be defined as the ratio between the
two maximum values:
,~

I

-5
-

7

11)

0,"

where B can be 2, 3, 4, or 6 , corresponding to k -fold
rotation symmetry. The larger si is, the more likely this
block has t -fold rotation symmelry.
Once we have obtained all rour symmetry measures
for each block, some statistics can bc computed to represent the whole image. In our work, we only calculate the
first and second order moments fur each kind of rotation
symmetry, thus gct an 8-dimensional featurc for Ihc given
image.
One key [actor of the above feature extraction
schcme is the sizc o f each block, which should balance
between symmetry rormation and locality. It is unwise to
fix this parametcr due to the unpredicted variation in scale.
Therefore, we vary the block size and calculate symmetry
measure on multi-scale. In this paper, we vary the block
sizc in T = 3 levels, i.e. 16x16 , 3 2 x 3 2 and 6 4 x 6 4 ,
where the block size in the higher level is 4 times as large
as that in the lower level. Let v(r) denote the 8dimensional feature at the nh level ( t = 1 , 2 , 3 ) , the symmetry feature used to represent the image can be written
as: v = [ ~ T ( 1 ) . y T ( 2 ) , " T ( 3 ) ]and
r , it has 24 dimensions altogether.

3. ACCELERATION SCHEME
The feature extraction algorithm described in section 2
takes autocorrelation and correlation as a preprocessing
step, which is very time-consuming, especially when the
size of blocks is large. In this section, we have developed
several schemes to accelerate the original algorithm, including: 1) the maximum value of autocorrelation can be
directly calculated using gray values; 2) correlation between the original block and the rotated one can be accelerated by means of Fast Fourier Transform (FFT); 3) the
maximum values of both autocorrelation and correlation
at the higher level can be approximated using those at the
lower level.
Firstly, it is easily understood that the maximum
value of autocorrelation must appear at the central point of
a given block, which can be written in the following form:
a,
=Z(p(i,J)-~l~d
(2)
i.j

where p ( i ,j ) is the gray value at the point ( i , j ) in the
original block. If we stack each column of the points

41 8

Symmetry feature extraction algorithm

within the block into an ( h . w ) -dimensional vector,
o , , ~ ~ ,can
, ~ , he
~ viewed as the inner product between this
vector and itself.

Meanwhilc,

where i # h / 2 or

j # wJ2 can he viewed as the inner product between the

block vector and another one with the same points hut
differcnt arrangement. Note that the two vectors share
equal modulc. Thus o , , ~ ~ =man,,,
, , , / ~ u(i,j ) . Based on this
simple rule, we can obtain o,,~using Eq.2. instead OI" calculating the autocorrelation at every point.
When we calculate r",, there is no such rule that
guarantces its location at thc central point. To speed up
the calculation of correlation, we may take the advantage
of FFT. When we put the pixel gray values in an ( h x U')
matrix, and get two matrices M , . M, reprcsenting thc two
blocks, the correlation hctwccn thcse two blocks is cqual
to the convolution of M , and MI up to a translation factor, where i f ? ( i , j ) =M , ( h - i , w - j ) . Therefore, wc first
perform FFT to an image block and its rotated counterparl
and
to get twv spectral reprcsentations: b ; ( q , q )
F , ( q , q ) . The correlation result can be ohtaincd by
transforming F = Fo. Fr' hack lo space domain, where F,:
is the complex conjugate of 6
Let st' denote k-fold symmetly measure at the nh
scale, with the first scale corresponding to block size of
16x16. Notice that one block B'"(i, j ) in the nh scale is
composed of four neighboring blocks B"-"(Zi+ 1 , 2 j + X) ,
( / , k= 0,Z) in the ( I - I)th scale. Once we have calculated
the maximum values of autocorrelation and correlation for
each block at the (r-l)th scale, we can approximate the
maximum values at the nh scale using those at the
(f-1)th
scale.
Let
u f 1 ' ( 2 i + / , 2 j + k ) and
c:-')(2i+/,2j+k)

( / , k = O , I ) denote the maximum values

of B " - ' ) ( 2 i + / , 2 j + k )

, and

o:)(i,j) and c:l(i,j) denote

those of B(')(i,j ) ,then we have:
Q ( i . j ) = Z ( p ( i , j ) .p ( i , j ) )
i.1

=Xa:-"(Zi+/,2j+ k);
1.k

C t 1 ( i , j )= C (p(i.j ) .9(i,j ) )

(3)

1.;

= xci-'1(2i

+ / , 2j + k )

1.k

where y(i, j ) is the gray scale at point ( i , j ) in the rotated
block; / , k = 0 , 2 . The first equation is strictly satisfied,
while the second one is approximately satisfied due to the
rotational effect.
Based on the above preparation, we can summarize
the algorithm as follows:

1. Divide thc image into 16x16 overlapping blocks; cal-

culate 0: for each block using Eq.2.; calculate
means of FFT;
2. Calculate v(1) using Eq. I .;
3. Repeat for f = 2,3 :

c:

by

Calculate a:,, and c: using Eq.3.;
Calculatc v ( t ) using Eq.1.;
4. Output symmctry featurc for the given imagc:
Y

= ["'(I),

v'(2), J ( 3 ) I T

4. EXPERIMENTAL RESULTS

All our experimcnls are pcrformed on a gcneral purpose
image database. It consists of 5,000 images takcn from
Corcl image databasc, and can he categorized into 50
groups, cach of which contains 100 images. Somc of the
concept groups are: balloon, dog, model, ship, wolf, etc.
Two images belonging' to the samc group arc considered
relevant, and vice versa.
4.1. Processing time

The main operation in the original algorithm is autocorrelation and correlation. By means of the three schemcs
proposed in the prcvious section, the accelerated version
greatly relieves the computation load. To test the effcctivencss of the acceleration scheme, we perform both the
original algorithm and the accelerated version on a
384x256 image, and list their processing time in tahlel.

I

Algorithm
I1 Original I Accelerated
Processing time I 13.92 seconds 1 2.134 seconds
Table 1 . Processing time comparison (Intel(R) 1.79GHz,
512MRAM)
4.2. Systematic retrieval results

We build three kinds of features on our image database,
i.e. symmetry feature, wavelet feature [ I l l and waterfilling feature [13, 141, and use them for image retrieval
respectively. All these features are based on the gray
value of pixels, and no color information is utilized. In
[ I I], Wang et al proposed applying Daubechies wavelet
transform to the images, and using the coefficients as feature vectors. However, the dimensionality of their feature
is very high, especially for large images. 'In our implementation, we first perform 3-level Dauhechies wavelet
transform, and then extract the first and second order
moments of coefficients at each level, thus get an 18dimensional representation. Water-filling feature has 18
dimensions, consisting of MaxFillingTime and the associ-

41 9

I. REFERENCE

ated ForkCount (MFT and FC), MaxForkCount and the
associated FillingTime (MFC and FT), FillingTime Histogram (7 bins),and Forkcount Histogram (7 bins).
Since different components in the same kind of feature usually have different ranges of value, w e normalize
them to [0, 11 to ensure that they have the same impact on
the calculation of similarity between images. Throughout
the experiments, Euclidian distance is used to measure the
similarity. The retrieval results are plotted in Fig.1.
From Fig.I., w e can see that symmetry feature oulperforms wavelet feature, which is a widely accepted descriptor of texture, and water-filling feature. Furthermore,
the symmetq feature obtaincd from the accelerated algorithm performs almost as well as that obtained from the
original one, which demonstrates the effectiveness of our
accelerated algorithm.

J.M. Gauch, and S.M. Pizcr, “Thc intensity axis of symmetry and its application to image segmentation”, IEEE Tran.~.
on Partern Analysis and Machine Inlelligencr, 15:753-770,
1993.

B. Crunbaum, and G.C. Shcphard, Tiling.v and p a n e r s ,
W.H. Frceman and Company, 1987.
J.R. He, M.J. Li, H.J. Zhang, and C.S. Zhang, ”Automatic
peak number detcction in image symmctry analysis”, .submitted to PCM’2004, 2004.
J. Huang, S.R. Kumar, M. Mitra, W.J. Zhu. and R. Zabih,
“Image indexing using color corrclograms”, CYPR, 762-768,
1997.
C.E. Jacobs, A. Pinkelstcin, and D.H. Salesin, “Fast mu1tiresolution image querying”, Proc. SIGGAPH ‘95, 277-286.
1995.

5. CONCUSION
In this paper, we have proposed a novel feature which
depicts the symmetrical property of natural images based
o n the theory of wallpaper groups. When applied in the
field of image retrieval, it outperforms wavelet and waterfilling features. Furthermore, we have also developcd
several schemes to accelerate the algorithm for practical
use, which brings almost no degradation to retrieval performance. Future work includes incorporating color information into the proposed symmetry feature to further
improve its performance.

D. Reisfeld, and Y. Yeshurun, “Robust detection of facial
features by generalized symmetry”, Proc. IEEE Inl. Con/
on Pallern Rrcngnition, 117-120, 1992.

6. ACKNOWLEDGEMENTS

M. Stricker, and M. Orengo, “Similarity of color images”,

Y. Liu, and R. Collins, “A computational modcl for rcpeated pattern perception using Frieze and Wallpapcr
groups”, CVPR, 537.544.2000.
G. Pass, R. Zabih, and J. Miller, ”Comparing images using
color coherence vectors”, ACM Multimedia, 65-73, 1996.

Sloroge and Retrieval for Image and Video Darabases, 381-

This work was supported by National High Technology
Research and Development Program of China (863 Program) under contract No.2001AAI 14190.

392, 1995.
[IO] M.J. Swain, and D.H. Ballard, “Indexing via color histograms”, Proc. Third Inl. Con/ on Computer Visron, 390-

393, 1990.
[Ill J.Z. Wang, G. Wiederhold, 0. Firschein, and S.X. Wei,
‘Content-based image indexing and searching using Daubechies’ wavelets”, Inl. J. on Digitol Libraries, 1:311-328,
1997.

--C---Hater-Filling Fearurc

[I21 H. Zabrodsky, S. Peleg, and D. Avnir, “Continuous symmetry measures”, J American Chem. Soc., 115:8278-8289,
1992.
[I31 X.S. Zhou, and T.S.Huang, “Image retrieval: feature primi-

tives, feature representation, and relevance feedback”,
CBAIVL ‘2000, in conjunction with IEEE CVPR ’2000,2000.
[I41 X.S. Zhou, Y. Rui, and T.S. Huang, “Water-Filling: a novel
way for image SttuCtUrd feature extraction”, IClP’99, 1999.
IQ

20

30

10

50

60

70

80

90

IW

SCOW

Fig.1. Retrieval performance comparison

420

Multi-View Transfer Learning
with a Large Margin Approach
Dan Zhang

Jingrui He

Computer Science
Department
Purdue University
West Lafayette, IN

zhang168@cs.purdue.edu

Machine Learning Group
IBM TJ Watson Research
Center
Yorktown Heights, NY

jingruhe@us.ibm.com

Yan Liu

Computer Science
Department
University of Southern
California
Los Angeles, CA

yanliu.cs@usc.edu
Richard D. Lawrence

Luo Si

Computer Science
Department
Purdue University
West Lafayette, IN

Machine Learning Group
IBM TJ Watson Research
Center
Yorktown Heights, NY

lsi@cs.purdue.edu

ricklawr@us.ibm.com

ABSTRACT

Keywords

Transfer learning has been proposed to address the problem of scarcity of labeled data in the target domain by leveraging the data from
the source domain. In many real world applications, data is often
represented from different perspectives, which correspond to multiple views. For example, a web page can be described by its contents
and its associated links. However, most existing transfer learning
methods fail to capture the multi-view nature, and might not be best
suited for such applications.
To better leverage both the labeled data from the source domain
and the features from different views, this paper proposes a general framework: Multi-View Transfer Learning with a Large Margin Approach (MVTL-LM). On one hand, labeled data from the
source domain is effectively utilized to construct a large margin
classifier; on the other hand, the data from both domains is employed to impose consistencies among multiple views. As an instantiation of this framework, we propose an efficient optimization
method, which is guaranteed to converge to ² precision in O(1/²)
steps. Furthermore, we analyze its error bound, which improves
over existing results of related methods. An extensive set of experiments are conducted to demonstrate the advantages of our proposed
method over state-of-the-art techniques.

Multi-View Learning, Transfer Learning, Large Margin Approach

1.

INTRODUCTION

Transfer learning has been proposed and commonly used to address the problem of scarcity of labeled data in a particular target domain. It builds a model for the target domain by leveraging
the label information from another related domain (source domain),
thus avoids the costly process of generating labels for target domain
examples. In many real world applications, the examples are often
described from different perspectives, which correspond to multiple views. For example, in web mining, a web page can be represented by its contents and in-bound/out-bound links; in image analysis, an image can be described by different types of features, such
as, color, texture, and shape. It has been shown that leveraging the
consistencies between different views can help improve the learning performance. However, most existing transfer learning methods are designed only for single-view problems. In other words,
if applied to problems with multiple views, these methods would
fail to utilize the redundancy incurred by the multi-view property.
Therefore, they are not ideal for such applications.
Despite its importance, the problem of Multi-View Transfer Learning (MVTL) has received limited attention. Most existing methods integrate the multi-view and transfer learning nature by some
heuristics without theoretical analysis, such as the convergence rate
of their algorithms, and how the learned model for the target domain can be improved by integrating the characteristics of multiview features into transfer learning. And researchers tend to put
more emphasis on the multi-view side. For example, in [40], the
proposed algorithm uses the classifier trained on the source domain
to generate the initial seed set, and then applies the co-training [4]
algorithm to construct the classifier for the target domain; in [13],
the authors explicitly model the view consistency in their objective
function without considering the data distribution difference between the source domain and the target domain. Another straightforward method for MVTL is to concatenate the features from multiple views, and apply the transfer learning methods for single-view
problems to build the model for the target domain. However, this
kind of methods disregard the redundancy incurred by different

Categories and Subject Descriptors
I.2.6 [Artificial Intelligence]: Learning—Knowledge acquisition

General Terms
Algorithms, Performance, Experimentation

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
KDD’11, August 21–24, 2011, San Diego, California, USA.
Copyright 2011 ACM 978-1-4503-0813-7/11/08 ...$10.00.

1208

of the adjusted loss function on the source domain examples can be as close to the expectation of the loss function
on the target domain examples as possible. In [23, 24], the
authors utilize the data distribution differences between several source domains and the target domain, and propose a
method to combine the classifiers from these source domains
optimally.

views. As shown in a lot of previous works [37, 44, 47], without
considering the consistencies between different views, the performance of multi-view learning cannot be guaranteed. On the contrary, in MVTL, we utilize the nature of both the transfer learning
and the multi-view learning in an unified way.
To achieve this goal, this paper proposes a general framework:
Multi-View Transfer Learning with a Large Margin Approach (MVTL-LM). In particular, from the transfer learning perspective, we
integrate the nature of the multi-view setting into the transfer learning framework and impose the consistencies among multiple views,
which implicitly limits the capacity of the hypothesis class. This is
significantly different from previous large margin transfer learning
methods [29], which do not consider the problem of multi-view
setting. From multi-view learning perspective, the new formulation explicitly models the data distribution difference between the
source domain and the target domain, applies the technique of importance sampling [1], and uses weighted labeled data from the
source domain to construct a large margin classifier for the target
domain. In particular, we propose a novel optimization method
based on the bundle method [38, 39], which can solve an instantiation of the MVTL-LM framework in a very efficient way. We
further prove that the optimization method can converge to ² precision in O( 1² ) steps (See Theorem 3.1) and each step takes time
O(sn), where s is the average sparsity for features and n is the total
number of source domain examples (See Theorem 3.2). Moreover,
we analyze the generalized error bound of MVTL-LM in the target
domain, which depends on its performance in the source domain
and the empirical Rademacher complexity of a related hypothesis
class (See Theorem 3.3). The empirical Rademacher complexity
is reduced by making use of the multi-view nature. Experimental
results demonstrate the advantages of our proposed method over
state-of-the-art techniques.
The rest of this paper is organized as follows. The related works
are discussed in Section 2. Section 3 introduces the research problem, presents the proposed algorithm and analyzes some properties
of the proposed method. Section 4 presents the experimental results. Section 5 concludes the whole paper.

2.

4. Relation Transfer. In [10, 25, 26], the authors build the
relational map between the source and the target domains,
and relax the independently and identically distributed (i.e.,
iid) assumption in these two domains.
Despite their success on single-view problems, existing transfer
learning methods may not work well on MVTL problems since the
nature of multiple views are not considered in these works. In contrast, besides transferring knowledge from the source domain to
the target domain via instance transfer, our proposed MVTL-LM
approach imposes the consistencies between multiple views by explicitly modeling the differences between the outputs from different
views, which promises to improve the performance.

2.2

RELATED WORKS

This section briefly introduces related works on transfer learning,
multi-view learning, MVTL and the bundle method.

2.1

Multi-View Learning

In many real-world applications, examples are represented by
multiple views. It has been shown extensively in prior research that
leveraging the redundancy among the multiple views can improve
the learning performance [12, 17, 20, 31, 36, 44, 45]. For example,
the authors of [12] construct a classifier on each view and regulate
the consistencies between different views. Furthermore, they show
that the Rademacher complexity of the function class can also be
greatly reduced by regulating the consistencies.
This idea is further exploited in [20], where the authors incorporate the consistency term into multi-view semi-supervised learning
problems, and show a substantial improvement on the classification performance. Similarly, in [44], the authors incorporate this
idea into local learning [41] and propose a novel way to define the
graph Laplacian. Most existing multi-view learning methods are
for the single-domain settings. However, in MVTL problems, the
source domain and the target domain do not have the same data distribution. As we will show in the experiments, disregarding the data
distribution difference may adversely affect the classification performance. In contrast, besides leveraging the consistency between
different views, our proposed MVTL-LM approach also considers
the domain difference by an effective re-weighting scheme, so it
can achieve better performance in MVTL problems.

Transfer Learning

As an important technique to address the problem of scarcity of
labeled data in the target domain, transfer learning has received
much attention recently. A key problem in transfer learning is what
kind of knowledge can be transferred from the source domain to the
target domain. Roughly speaking, the assumptions introduced in
previous transfer learning work can be grouped into four categories:

2.3

Multi-View Transfer Learning

As mentioned in introduction, existing methods for multi-view
transfer learning combine the multi-view learning and transfer learning by some heuristics, and tend to put more emphasis on the multiview side. For example, the co-adaptation algorithm proposed in
[40] uses the labeled examples from the source domain to construct classifiers, which will be used to generate the initial seed
set. It then applies the co-training algorithm [4] to construct the
classifier for the target domain. Note that in the latter stage, labeled examples from the source domain are not utilized, which may
otherwise provide useful insights about consistency between multiple views and the optimal classifier. In [13], the co-regularized
loss function consists of the standard regularized log likelihood on
multiple views based on the labeled data, as well as the expected
Bhattacharyya distance based on the unlabeled data. When applied
in MVTL problems, it may fail to capture the data distribution difference between the source domain and the target domain. In contrast, our proposed MVTL-LM approach integrates the multi-view

1. Feature Representation Transfer. In [2, 7, 9, 11, 28, 30],
the authors assume that there exists a common feature space
shared by both the source domain and the target domain,
which can be used as a bridge to transfer knowledge.
2. Parameter Transfer. In [5, 19], the authors make use of
Gaussian Process (GP) models, and assume that the source
domain and the target domain have shared parameters / hyperparameters.
3. Instance Transfer. Due to the data distribution difference
between the source domain and the target domain, in [8, 42],
the authors select or re-weight the examples from the source
domain for use in the target domain such that the expectation

1209

and transfer learning nature in a principled way, and is tailored for
MVTL problems. Furthermore, we address some important theoretical problems, such as the convergence rate, time complexity
and the generalization error bound, which have not been discussed
in previous works for MVTL.

2.4

ing nature. In this framework, we construct linear classifiers for all
of the views, whose weight vectors are obtained via the following
optimization problem:

w(1) ,...,w(M )

Bundle Method

The proposed formulation is a convex optimization problem. In
this paper, we propose an optimization algorithm based on the bundle method [38, 39], which has shown its superior performances in
both efficiency and effectiveness over state-of-the-art methods, to
solve this proposed formulation. The basic motivation of the bundle method is to approximate the objective function J(w) through
a set of linear functions, where w is the model parameter. In particular, this objective function is lower bounded as follows:

+

1≤i≤t

where wi is a set of points picked by the bundle method, and ai is
the gradient/sub-gradient at point wi . The bundle method monotonically decreases the gap between J(w) and max1≤i≤t {J(wi−1 )+
hw − wi−1 , ai i} such that the minimal point of J(w) can be approximated by that of the line segments max1≤i≤t {J(wi−1 ) +
hw − wi−1 , ai i}.
Some recent developments in bundle method [39] show that if
J(w) contains some regularizers by itself, the bundle method is
guaranteed to converge to the precision ² in O(1/²) steps. In MVTLLM, we adapt the bundle method to solve the proposed problem,
which can also be proven to have an efficient convergence rate.

Cp R(P rT , l(x(p) , y, w(p) ))

p=1
(p,q)

Cp,q Rc (P rT

f (x) =

Problem Statement and Notations

Suppose we are given a set of labeled source domain examples
(p)
(p)
(p)
from M independent views: {(x1 , y1S ), . . . , (xn , ynS )}, xi ∈
Rdp ×1 , yiS ∈ {−1, 1}, p ∈ {1, 2, . . . , M }, where n is the total
number of source domain examples and dp is the dimensionality
(p)
of the p-th view. yiS is the class label of xi . Besides the source
domain examples, a set of unlabeled target domain examples are
(p)
(p)
(p)
(p)
also available, and are denoted as: {z1 , z2 , . . . , zm }, zi ∈
Rdp ×1 , p ∈ {1, 2, . . . , M }.
The goal of MVTL is to construct an accurate classifier for the
target domain by making use of the labeled examples from the
source domain as well as the redundancy incurred by multiple views.
In this paper, similar to [15], we assume that P rT (y|x) = P rS (y|x).
In other words, the conditional probability of the class label given
the features is the same for both the source domain and the target
domain. This particular case can also be referred to as covariate
shift [35]. As claimed in [15], even in some cases when this assumption does not hold, the algorithm, which is based on this assumption, can still perform well.

3.2

p=1

M
X

, lc (x(p) , x(q) , w(p) , w(q) )),

(1)

where Ω(w(p) ) is the regularization term defined on the p-th view
weight vector w(p) ; R(P rT , l(x(p) , y, w(p) )) is the expected classification loss with respect to the data distribution of the target
domain examples (P rT ), which measures the deviations between
the true labels and the predicted labels based on the p-th view;
l(x(p) , y, w(p) ) is the classification loss (such as the hinge loss
(p,q)
[32]); Rc (P rT , lc (x(p) , x(q) , w(p) , w(q) )) measures the expected
consistency between the p-th view and the q-th view with respect to
their joint distribution in the target domain; lc (x(p) , x(q) , w(p) , w(q) )
is the consistency between the p-th view and the q-th view (such as
the squared loss between the predictions on different views); γp ,
Cp , and Cp,q are non-negative parameters that balance the relative
importance of the three terms in the objective function in Eq.(1).
Notice that when Cp,q = 0, Eq.(1) is equivalent to training a
large margin classifier on each view independently. When Cp,q >
0, by minimizing Eq.(1), we can obtain large margin classifiers
which are also consistent across different views. The final classifier
is the average of large margin classifiers on all the views, i.e.,

MULTI-VIEW TRANSFER LEARNING
WITH A LARGE MARGIN APPROACH

In this section, we first introduce the problem statement and
some notations for MVTL. Then, a general framework named MVTLLM is proposed, which integrates the multi-view and transfer learning nature in a principled way. Based on an instantiation of the
framework, we propose an optimization method, which is adapted
from the bundle method [38, 39]. Towards the end of this section,
we analyze some important properties of the proposed method.

3.1

M X
M
X

γp Ω(w(p) ) +

p=1 q=1

J(w) ≥ max {J(wi−1 ) + hw − wi−1 , ai i},

3.

M
X

min

MVTL-LM Framework

In this subsection, we propose a general large margin framework
for MVTL, which fully exploits the multi-view and transfer learn-

1210

M
1 X (p) T (p)
(w ) x ,
M p=1

where x = [(x(1) )T , . . . , (x(M ) )T ]T . Next, we will discuss the
loss term and the consistency term respectively.

3.2.1

Classification Loss

R(P rT , l(x(p) , y, w(p) )) measures the expected classification
loss with respect to the data distribution on the target domain. To be
specific, R(P rT , l(x(p) , y, w(p) )) = E(x,y)∼P rT [l(x(p) , y, w(p) )].
However, in our problem setting, we do not have any labeled examples from the target domain. Therefore, we estimate this term using
labeled examples from the source domain as follows:
E(x,y)∼P rT [l(x(p) , y, w(p) )]
P rT (x, y) (p)
l(x , y, w(p) )]
P rS (x, y)
P rT (y|x)P rT (x) (p)
=E(x,y)∼P rS [
l(x , y, w(p) )]
P rS (y|x)P rS (x)
P rT (x) (p)
l(x , y, w(p) )].
=E(x,y)∼P rS [
P rS (x)
=E(x,y)∼P rS [

=E(x,y)∼P rS [β(x)l(x(p) , y, w(p) )].
n
1X
(p)
βi l(xi , yi , w(p) ),
≈
n i=1

(2)

where P rS is the distribution of the source domain, weight func(x)
tion β(x) := PP rrTS (x)
; and βi = β(xi ). Notice that the value of
β(x) reflects the distribution difference between the source domain
and the target domain. If the two distributions are similar, β(x)
will be close to 1; if the two distributions are dissimilar, underrepresented examples in P rT will receive a higher weight, whereas
over-represented examples will receive a lower weight. In this way,

Algorithm: Multi-View Transfer Learning with a Large Margin Approach (MVTL-LM)
Input:
1. Reweighting Ratios for Source Domain Examples: βi , i =
{1, 2, . . . , n}
2. Optimization Parameters: γ1 and γ2 for regularizers, and
the trade-off parameters C, C1 , C2 in Eq.(5), ² = 0.001.
3. Source Domain Examples:
(i)
(i)
(i)
{(x1 , y1 ), (x2 , y2 ), . . . , (xn , yn )}, i ∈ {1, 2, . . . , M }.
4. Target Domain Examples:
(i)
(i)
(i)
{z1 , z2 , . . . , zm }, i ∈ {1, 2, . . . , M }
Output:
The label assignment l = [l1 , l2 , . . . , lm ] for the target domain examples.
e 0.
1. Initialization t = 0, randomly initialize w
e −, X
e (1) , X
e (2) according to Eq.(5).
2. Construct X
3. Construct the matrix H(β, C).
4. repeat
5. t = t + 1
6.
Compute the gradient for the empirical loss: at =
e t−1 ), and bt = Remp (w
e t−1 )− < w
e t−1 , at >.
∂w
e Remp (w
7. Derive the optimization problem: RtCP = max1≤i≤t <
e ai > +bi
w,
e t = arg minw
e + RtCP
e T H(β, C)w
8. w
e w
e i ) − Jt (w
e t)
9. ²t = min0≤i≤t J(w
10. until ²t ≤ ²
11.Classification Assignment: for target domain example zi ,
(1)
(2)
e T (e
if 0.5 × w
zi + e
zi ) > 0, li equals 1, and otherwise it
equals −1.

we are able to estimate the classification error for the target domain
using labeled examples from the source domain.
There are various ways to estimate βi , such as Gaussian Mixture Model (GMM) [22], Kernel Density Estimation [34], Kernel
Mean Matching [15], etc. In our approach, we concatenate the
features on different views together, and measure the probability
ratios between source and target domains by using GMM. To be
specific, we first estimate the marginal distribution of all the features in the source domain and the target domain using two GMMs
respectively. Then, βi is estimated as the ratio between the two
generative probabilities on xi given by these two GMMs. Notice
that in GMM, we need to specify the number of components. As
will be shown in Section 4, the proposed approach is very robust to
small perturbations in this number.

3.2.2

Consistency
(p,q)

As a consistency term, Rc (P rT , lc (x(p) , x(q) , w(p) , w(q) ))
regulates that the outputs on individual views should be consistent,
and not deviate too much. lc (x(p) , x(q) , w(p) , w(q) )) is the consistency loss function, which penalizes the deviations between the
output of x(p) and x(q) , under the classifiers w(p) and w(q) . Similar to Eq.(2), To estimate this term, we use both the labeled examples from the source domain and the unlabeled examples from the
target domain as follows:
(p,q)

Rc (P rT

, lc (x(p) , x(q) , w(p) , w(q) ))

=E(x(p) ,x(q) )∼P r(p,q) [lc (x(p) , x(q) , w(p) , w(q) ))]
Ã n T
X
1
(p)
(q)
βi lc (xi , xi , w(p) , w(q) )
≈
m + n i=1
!
m
X
(p)
(q)
(p)
(q)
+
lc (zi , zi , w , w ) .

Table 1: Algorithm Description: Multi-View Transfer Learning with a Large Margin Approach (MVTL-LM)

(3)

i=1

This term regulates the consistency on both the source domain and
target domain examples. Combining this constraint with the standard objective functions for each view yields a multi-view learning
algorithm, which was shown to perform better than single view approach on many classification applications.

3.3

(1)T

(1)T
(2)T
e(1)
e(2)
x
= [xi , 0]T , x
= [0, xi ]T ,
i
i

In this section, a concrete form of the above framework will be
studied. Without loss of generality, we focus on the two view formulation, i.e., M equals 2, which can be easily extended to the
case when M is larger than 2. The hinge loss is used to define
l(x(p) , y, w(p) ), and the squared loss is used for lc (x(p) , x(q) , w(p) ,
w(q) )). 2-norm is used as the regularization term Ω(·). Then, the
concrete form of the Eq.(1) turns to:
2
n
2
X
X
X
γp
(p)
kw(p) k2 +
Cp
βi ξ i
2
w(1) ,w(2)
p=1
p=1
i=1

min

(4)

s.t.

(1)

(2)

− w(2)T zi k2 )

(1)

≥ 1 − ξi

(2)

, yi w(2)T xi

(p)

Cp βi ξi

p=1 i=1

(1)
(2)
eTx
e(2)
≥ 1 − ξi , y i w
≥ 1 − ξi ,
i
P
Pm − −T
e−
e−T
where H(β, C) = I(γ1 , γ2 )+C( n
zi e
zi ),
i x
i +
i=1 βi x
i=1 e
and I(γ1 , γ2 ) is a diagonal matrix, with the first d1 elements being
γ1
and the remaining ones being γ22 . It is clear that this problem is
2
convex, since βi is given.
There are several alternatives to solve this problem efficiently.
Here, an efficient way, which is an adaption of the bundle method,
is proposed to solve this optimization problem of the MVTL-LM
approach. The concrete procedure is described in Table 1. Here,
P
P
S T (p)
e = 2p=1 n
e x
ei }, J(w)
e =
Remp (w)
i=1 Cp βi max{0, 1−yi w
P
P
(p)
2
n
T
T
e H(β, C)w+
e
e =w
e H(β, C)w+
e
w
Jt (w)
p=1
i=1 Cp βi ξi

∀i ∈ {1, 2, . . . , n},
(1)

2 X
n
X

∀i ∈ {1, 2, . . . , n}
(1)

i=1

yi w(1)T xi

e T H(β, C)w
e+
w

eTx
ei
yi w

i=1

kw(1)T zi

(5)

(p)

n
X
(1)
(2)
+C(
βi kw(1)T xi − w(2)T xi k2

s.t.

(2)

ei , only the d(p−1) + 1 to dp -th elements (d0 = 0) are
where in x
(p)
nonzero and equals xi . After introducing these notations, Eq.(4)
can be simplified to the following form:

e
w

min

+

(2)T

(1)T
(2)T
e = [w1T , w2T ]T , x
e−T
w
= [xi , −xi ]T
i

Method

m
X

(1)

x
+w
x
(X (1) , X (2) ) 7−→ R can be specified as: f (x) = w
2
To simplify this formulation, several concatenate vectors are further
introduced:

(2)

≥ 1 − ξi .

Here in this proposed method, we have absorbed the scaling com1
into the trade-off parameters Cp and
ponents. i.e., n1 and m+n
C respectively, for simplicity. The final classification function f :

1211

.

e ai > +bi . Since Remp (w)
e is non-smooth,
max1≤i≤t < w,
so, when calculating its gradient, we use the sub-gradient instead,
which can be calculated as
e =−
∂w
e Remp (w)

2 X
n
X

(p)

In summary, the algorithm converges in O(1/²) steps. It is clear
2
that the number of iterations also highly depends on Rmax
, which
can be viewed as the maximum reweighted norm for the source domain examples. Furthermore, it is clear that increasing the parameter values of C1 and C2 will increase the number of iterations.

(p)

ei ,
Cp βi Ii yiS x

3.4.2

p=1 i=1
(p)
Ii

where
is set to be 1, if
otherwise.

3.4

eTx
e(p)
yiS w
i

< 1, and

(p)
Ii

is set to be 0,

Theoretical Analysis

In this section, we deduct the convergence rate, time complexity
as well as the generalized error bound of the proposed method.

3.4.1

Convergence

T HEOREM 3.1. For the convergence rate of the algorithm de(p)
scribed
1, Suppose
= maxp,i (Cp βi )ke
xi k. A =
Pn in Table
Pm Rmax
− −T
− −T
ei x
ei + i=1 e
C( i=1 βi x
zi e
zi ), the corresponding eigenvalues of A are specified as: σ1 (A) ≥ σ2 (A) ≥ . . . ≥ σ(d1 +d2 ) (A) ≥
0. Assume that βi ≤ B. The proposed method converges in
O(1/²). In particular,
2
• If ² > 16Rmax
/(min{γ1 , γ2 } + 2σ(d1 +d2 ) (A)), the proposed method converges to precision ² after at most
nB(C1 +C2 )(min{γ1 ,γ2 }+2σ(d +d ) (A))
1
2
steps.
log2
4R2
2
• If ² ≤ 16Rmax
/(min{γ1 , γ2 } + 2σ(d1 +d2 ) (A)), the proposed method converges to precision ² after at most
nB(C1 +C2 )(min{γ1 ,γ2 }+2σ(d +d ) (A))
2
1
2
+32Rmax
/(²(min
log2
2
4Rmax
{γ1 , γ2 } + 2σ(d1 +d2 ) (A))) − 1 steps.
P
P
e =w
e T H(β, C)w
e + 2p=1 n
P ROOF. We have J(w)
i=1 Cp βi
(p)
e = w
e T H(β, C)w.
e Ω∗ (µ) = µT H−1 (β, C)µ is the
ξi , Ω(w)
P2 Pn
e J(0) = p=1
Fenchel dual of Ω(w).
i=1 Cp βi ≤ nB(C1 +
e
C2 ). k∂w
≤ Rmax . It is clear that k∂µ2 Ω∗ (µ)k ≤
e Remp (w)k
4/(min {γ1 , γ2 } + 2σ(d1 +d2 ) (A)). By integrating these inequalities into Theorem 4 of [39], we can get
¡
¢
²t
2
min 1, ²t (min{γ1 , γ2 } + 2σ(d1 +d2 ) (A))/16Rmax
,
²t − ²t+1 ≥
2
e i ) − Jt (w
e t ). The algorithm will termiwhere ²t = min0≤i≤t J(w
2
nate if ²t < ². So, if ² > 16Rmax
/(min{γ1 , γ2 }+2σ(d1 +d2 ) (A)),
²t − ²t+1 ≥ ²2t , and the algorithm will terminate after at most:

J(0)(min{γ1 , γ2 } + 2σ(d1 +d2 ) (A))
2
4Rmax
nB(C1 + C2 )(min{γ1 , γ2 } + 2σ(d1 +d2 ) (A))
≤log2
2
4Rmax
log2

(6)

This result is similar to the time complexity result per iteration in
[16]. However, the total number of iterations in [16] may be as
worse as O(1/²2 ), as given by the Lemma 2 of [16]. On the contrary, the number of iterations required in this paper is guaranteed
to be in O(1/²). So, solving the proposed problem by the proposed
method is much faster than using the Cutting Plane method [18].

Generalized Error Bound

In this subsection, we assume that ∀x, β(x) ≤ B if the marginal
probabilities in the source domain or in the target domain are greater
(1)
(2)
than 0. Let w∗ and w∗ denote the solution of Eq.(4). Similar to [12], we consider the class of functions FE,D = {f |f :
x → 21 ((w(1) )T x(1) + (w(2) )T x(2) )} such that kw(1) k2 ≤ E 2 ,
kw(2) k2 ≤ E 2 , and with probability at least 1 − δ,
n
1 X
(1)
(2)
βi k(w(1) )T xi − (w(2) )T xi k2
m + n i=1

+

m
1 X
(1)
(2)
k(w(1) )T zi − (w(2) )T zi k2
m + n i=1

≤

n
1 X
(1)
(2)
βi k(w∗(1) )T xi − (w∗(2) )T xi k2
m + n i=1

m
1 X
(1)
(2)
k(w∗(1) )T zi − (w∗(2) )T zi k2
m + n i=1
v
s
u n
m
X
X
ln(2/δ)
EB u
2
2
t
=: D.
kxi k +
kzi k + 3B
+
m + n i=1
2(m
+ n)
i=1

+

Furthermore, define Fβ,E,D to be the following class of functions,

steps.
2
If ² ≤ 16Rmax
/(min{γ1 , γ2 }+2σ(d1 +d2 ) (A)), then, this method
2
needs the above indicated steps to converge to the precision 16Rmax
/(min{γ1 , γ2 }+2σ(d1 +d2 ) (A)), then, we should have ²t −²t+1 ≥
²2
2
t
(min{γ1 , γ2 }+2σ(d1 +d2 ) (A))/16Rmax
. It is clear that it needs
2
2
another 32Rmax /(²( min{γ1 , γ2 } + 2σ(d1 +d2 ) (A))) − 1 steps to

converge to the precision ². So, in total, this algorithm converges
in
log2

T HEOREM 3.2. For each iteration of the proposed method, it
takes time O(sn).
P ROOF. The gradient computation in step 6 takes time O(sn),
where s is the average sparsity on both views. Instead of solving
the primal quadratic program, one can instead solve the optimization problem in step 8 in the dual form. Setting up the dual for
each iteration is dominated by computing the O(t2 ) elements of
the Hessian, which can be done in O(t2 s) steps. Since t2 is normally much smaller than n, it leads to an overall time complexity
of O(sn) per iteration.

3.4.3

max

Time Complexity

Fβ,E,D = {h|h : (x, y) → β(x) · A(−f (x) · y), f ∈ FE,D }
1
if a > 0
1 + a if − 1 ≤ a ≤ 0 . Based on these func0
otherwise
tion classes, we have the following theorem with respect to the generalization error of the classifier obtained via the MVTL algorithm.
n

where A(a) =

T HEOREM 3.3. Fix δ ∈ (0, 1). Then, with probability at least
1 − δ, every f ∈ Fβ,E,D satisfies:

nB(C1 + C2 )(min{γ1 , γ2 } + 2σ(d1 +d2 ) (A))
2
4Rmax

EP rT (sign(f (x)) 6= y)
2
n
X
X
1
(p)
Cp
βi ξi + R̂S,n (Fβ,E,D ) + 3B
≤
n(C1 + C2 ) p=1
i=1

2
+32Rmax
/(²(min{γ1 , γ2 } + 2σ(d1 +d2 ) (A))) − 1

steps.

1212

r

ln(2/δ)
,
2n

Dataset
comp vs rec

where R̂S,n (Fβ,E,D ) is the empirical Rademacher complexity of
Fβ,E,D in the source domain.
P ROOF. Since the conditional probability of y given x is the
same for the source domain and the target domain,

comp vs sci

EP rT (sign(f (x)) 6= y) = EP rS (β(x) · sign(f (x)) 6= y).
Notice that ∀h ∈ Fβ,E,D , h(x, y) ∈ [0, B]. By similar proof as
Theorem 4.17 in [33], we obtain that with probability greater than
1 − δ,

comp vs talk

EP rS (β(x) · sign(f (x)) 6= y) ≤ EP rS (β(x) · A(−f (x) · y))
r
2
n
X
X
ln(2/δ)
1
(p)
Cp
βi ξi + R̂S,n (Fβ,E,D ) + 3B
.
≤
n(C1 + C2 ) p=1
2n
i=1

rec vs sci

rec vs talk

According to Theorem 3.3, the generalization error bound of
any function in Fβ,E,D depends on the weighted sum of all the
slack variables associated with labeled examples in the source domain and the empirical Rademacher complexity of Fβ,E,D in the
source domain (up to a constant). Therefore, from transfer learning perspective, if the data distributions of the source domain and
the target domain are similar (B is relatively small), constructing
the large margin classifier in the source domain helps improve the
generalization error of the classifier in the target domain. More
importantly, from multi-view learning perspective, in Fβ,E,D , by
leveraging the consistencies among different views, we effectively
limit the hypothesis class, thus reduce the empirical Rademacher
complexity. As empirically shown in [12], after imposing the consistency on different views, the Rademacher complexity is significantly reduced compared with the single-view correspondents.
This bound improves some existing theoretical results in transfer learning. For example, compared with the bound in Theorem 1
of [3], we make use of the data-dependent convergence measures,
which can yield more accurate bounds. In Theorem 5 of [6], the authors also proved a bound for classifiers trained on multiple sources
based on empirical Rademacher complexity. However, their bound
can not be estimated from the data. For example, it depends on
the expected difference between the labeling functions of different
domains, which can not be estimated in our case where the target
domain does not have any labeled examples.
Our bound also improves the results in [12], which is a multiview learning algorithm. First, our bound is proposed for the transfer learning setting, whereas SVM-2K [12] is for the single domain setting. Furthermore, Theorem 3 of [12] can be seen as a
special case of our bound when the source domain and the target
domain have the same distribution and we do not use the unlabeled
data from the target domain. Second, compared with SVM-2K, we
make additional use of the unlabeled data from the target domain. If
the number of unlabeled examples from the target domain is much
larger than the number of labeled examples from the source domain, we tend to decrease the value of D, which is the upper bound
on the view consistency. In this way, we reduce the function class,
the corresponding Rademacher complexity, and thus improve the
bound.

4.

sci vs talk

Source Domain
comp.graphics
comp.os.ms-windows.misc
rec.autos
rec.motorcycles
comp.graphics
comp.os.ms-windows.misc
sci.electronics
sci.space
comp.sys.ibm.pc.hardware
comp.sys.mac.hardware
talk.politics.guns
talk.politics.mideast
rec.autos
rec.motorcycles
sci.electronics
sci.space
rec.sport.baseball
rec.sport.hockey
talk.politics.guns
talk.politics.mideast
sci.electronics
sci.space
talk.politics.guns
talk.politics.mideast

Target Domain
comp.sys.ibm.pc.hardware
comp.sys.mac.hardware
rec.sport.baseball
rec.sport.hockey
comp.sys.ibm.pc.hardware
comp.sys.mac.hardware
sci.crypt
sci.med
comp.graphics
comp.os.ms-windows.misc
talk.politics.misc
rec.sport.baseball
rec.sport.hockey
sci.crypt
sci.med
rec.autos
rec.motorcycles
talk.politics.misc
sci.crypt
sci.med
talk.politics.misc

Table 2: Descriptions of Six Sub-datasets from 20Newsgroup

4.1
4.1.1

Datasets
20 Newsgroups

20 Newsgroups dataset1 contains 4 main categories, i.e., ‘comp’,
‘rec’, ‘sci’, ‘talk’, as well as some small categories, such as ‘alt.athe
ism’, ‘misc.forsale’, etc. The number of examples for each of the
four main categories ranges from 3253 to 4881. Each of the four
main categories contains some subcategories, which are assigned
to different domains. Using the 4 main categories, we create 6
sub-datasets. The detailed descriptions of these sub-datasets are
summarized in Table 2. For each sub-dataset, we extract features
from 2 views. One view (View 1) corresponds to the original tfidf content information processed by Principle Component Analysis (PCA), and the other view (View 2) corresponds to the hidden
topic information obtained by Probabilistic Latent Semantic Analysis (PLSA)2 of the binary word features.

4.1.2

Spam Detection

This dataset is from ECML/PKDD Discovery Challenge 20063 ,
which focuses on personalized spam filtering and generalization
across related learning tasks. In particular, in Task A, we aim to
construct spam filters for 3 different users, each of which have 2500
emails. In our experiments, we take the labeled emails from one
user as the source domain, and the unlabeled emails from another
user as the target domain. The two views are generated using the
same way as 20 Newsgroups.

4.1.3

WebKB

This dataset contains web pages from computer science departments of several different universities4 . They are divided into 7
1

EXPERIMENTS

http://people.csail.mit.edu/jrennie/20Newsgroups/
Actually, PLSA [14] can be considered as a dimensionality reduction method, which maps the documents to some fixed number
of hidden topics. The topic distribution for each document can be
used as low dimensional representation.
3
http://www.ecmlpkdd2006.org/challenge.html
4
http://www.cs.cmu.edu/∼webkb/
2

In this section, we present and analyze an extensive set of experimental results, which clearly demonstrate the advantages of the
proposed method.

1213

SVM-View1
SVM-View2
SVM
SVM-2K
CDSC
LLGC
LMTTL
Co-Training
MVTL-LM

comp vs rec
85.4
84.0
86.2
88.5
87.6
77.5
85.8
86.9
92.9

comp vs sci
73.3
70.6
70.9
79.3
72.3
71.1
69.8
72.5
80.1

20 Newsgroups
comp vs talk rec vs sci
95.4
67.2
96.4
63.5
96.7
64.6
97.2
71.0
81.3
71.2
92.6
72.6
96.4
64.5
97.1
66.7
98.3
75.3

rec vs talk
56.8
65.8
53.6
81.6
80.1
73.9
53.7
61.2
83.4

sci vs talk
81.8
78.3
80.1
83.1
80.4
81.2
78.6
81.4
83.0

student
0.595
0.171
0.544
0.725
0.361
0.167
0.546
0.495
0.742

WebKB
course
0.541
0.116
0.562
0.512
0.202
0.277
0.545
0.554
0.565

faculty
0.441
0.236
0.464
0.563
0.291
0.310
0.475
0.444
0.671

Table 3: Classification Results on 20 Newsgroups and WebKB. For 20 Newsgroups, we report the classification accuracy; for WebKB,
we report the F-measure due to the extremely imbalanced nature of this data set. It can be seen that MVTL-LM performs the best
in most cases.
categories (i.e., student, faculty, staff, course, project, department
and other). We generate three sub-datasets out of them, i.e., student,
course and faculty. For each sub-dataset, we pick the corresponding
webpages from the four main universities, i.e., Cornell, Washington, Wisconsin, and Texas as the source domain positive examples,
and the webpages in ’other’ category from these four universities
as the source domain negative examples. In the target domain, a
similar way is used to extract examples from the other universities.
We use the content (View 1) and the link information (View 2) as
the two views of this dataset.

4.2

20Newsgroup

100
95
90

Accracy

85
80
75
comp vs rec
comp vs sci
comp vs talk
rec vs sci
rec vs talk
sci vs talk

70

Methods

We compare the proposed method with the following competitors: Support Vector Machines (SVM), which is a supervised classification method; LLGC [46], which is a semi-supervised learning
method; SVM-2K [12], which is a multi-view learning method;
CDSC [21], LMTTL [29], which are transfer learning methods and
have shown state-of-the-art performances. We also adapt the cotraining [27] algorithm to work for MVTL problems as follows:
we disregard the domain difference, put labeled examples from the
source domain and unlabeled examples from the target domain together, and apply the co-training algorithm to construct a classifier
for each view of the target domain via SVM. This is similar to the
co-adaptation algorithm proposed in [40] except that besides generating the initial seed set, labeled examples from the source domain
are also used to construct classifiers for the target domain. Notice
that besides SVM-2K and the co-training algorithm, the other baseline methods only work in the single-view settings. Therefore, for
the sake of comparison, we first represent each example using a
single set of features by concatenating the features from different
views, and then apply these methods on this single view. Furthermore, to better understand the benefits brought by the multi-view
methods, we also apply SVM on each view and report the performance.
For our proposed method, the re-weighting factors βi , i = 1, . . . , n
are learned by Gaussian Mixture Model, and the numbers of Gaussian components are both set to be 4. We will show later that the
performance of MVTL-LM is very robust against small perturbations in the number of Gaussian components. We set γ1 = γ2 = 1,
and tune the remaining three parameters (C1 , C2 and C) through
five fold cross validation on both the source domain and the target domain. The parameters of SVM-2K are also set in the same
way, except that in SVM-2K we do not need to consider the number of Gaussian components. For LLGC, the RBF kernel is used,
with its Gaussian variance being determined automatically by local
scaling [43]. The parameters of CDSC, SVM, LMTTL and CoTraining are all set through five fold cross validation similarly.

1214

65
60
55
2

3

4

5

6

Numer of Gaussian Mixture Models

7

8

(a)
Figure 1: The impact of changing the number of Gaussian components on the performance of our proposed method. In this
evaluation, we are assuming that the numbers of Gaussian components for both the source domain and the target domain are
the same. The experiments are conducted by fixing the number
of Gaussian components, while tuning the other parameters.

4.3

Results and Analysis

To study the impact of changing the number of Gaussian components on the performance of our proposed method, we vary this
number when estimating βi , and report the classification accuracy
on 20 Newsgroups dataset in Fig.1. From these results, we can see
that the proposed method is very stable with different numbers of
Gaussian components. Similar results have also been observed on
WebKB and Spam datasets.
Next we report the comparison results in Tables 3 and 4 respectively. For 20 Newsgroups and Spam datasets, the classification
accuracy is reported; whereas for WebKB dataset, the F-measure
is reported instead due to the extremely imbalanced nature of this
dataset 5 . From these results, we have the following observations.
1. Our proposed method MVTL-LM performs the best in most
cases. This is because our method models both the consis5
The number of negative examples is around 6 times more than that
of the positive examples.

SVM-View1
SVM-View2
SVM
SVM-2K
CDSC
LLGC
LMTTL
Co-Training
MVTL-LM

user1 vs user2
79.7
94.8
94.6
94.1
84.1
97.1
94.9
92.5
95.2

user1 vs user3
65.7
97.3
96.9
97.6
97.2
96.3
96.2
96.6
97.9

user2 vs user3
83.4
97.4
97.6
97.2
96.6
93.2
97.5
96.6
98.1

user2 vs user1
76.7
91.4
92.1
91.8
90.3
91.7
92.0
92.2
93.7

user3 vs user1
76.0
89.8
88.7
90.8
89.1
91.3
88.9
88.6
92.9

user3 vs user2
80.9
94.2
92.9
94.1
91.7
93.2
93.1
93.9
96.3

Table 4: Classification Results on Spam dataset. The classification accuracy is reported. It can be seen that MVTL-LM performs the
best in most cases.

5.

tency between different views and the domain difference simultaneously, whereas the other methods ignore some useful information (i.e., the data distribution difference between
different domains and the redundancy incurred by multiple
views).

CONCLUSIONS

Transfer learning is an important technique for utilizing data in
a related source domain for building predictive models in a target domain. Much valuable prior research has been conducted for
traditional transfer learning with data from a single view. However, many real world applications often contain data from multiple
views, and there is limited work for transfer learning with data from
different views. This paper proposes a formal learning framework
for Multi-View Transfer Learning with a Large Margin (MVTLLM) approach. In particular, the weighted labeled data from the
source domain is used to construct a large margin classifier for target domain and both the unlabeled data from the target domain and
data from source domain are used to ensure the classification consistency between different views. A novel optimization method
based on bundle method is proposed to learn model parameters
in an efficient manner, which has a theoretical guarantee to generate ²-accurate results in O(1/²) steps. Furthermore, theoretical
analysis is provided for the generalization error bound of the proposed method and shows the improved results of the Rademacher
complexity. An extensive set of results on three different datasets
have been provided to demonstrate the advantages of the proposed
method against several other alternatives.

2. Comparing with multi-view learning methods (SVM-2K and
Co-Training), MVTL-LM performs better because it explicitly models the data distribution difference between the source
domain and the target domain; whereas the multi-view learning methods simply treat the two domains as a single one.
3. Comparing with transfer learning methods (CDSC and LMTTL), in MVTL-LM, we are able to transfer additional information about view consistency from the source domain to the
target domain. We also suspect that these traditional transfer learning methods may not work well in the cases when
different kinds of features are merged together. Therefore,
MVTL-LM could achieve better performance in most cases.
4. The performance of SVM is worse than SVM-2K in most
cases. This is because in SVM, simply concatenating the features from different views together fails to capture the consistency between different views; whereas SVM-2K explicitly
models this consistency, which is able to improve the overall
performance.

6.

5. Comparing with SVM, SVM-View1, and SVM-View2, we
can see that concatenating the features from different views
may not necessarily result in an increase in the classification
performances although SVM uses more information than SVMView1 and SVM-View2.
6. As a graph based semi-supervised method, the performance
of LLGC is not promising because the basic mainfold assumption in semi-supervised learning does not hold in transfer learning, and concatenating multi-view features together
is not well suited in the multi-view learning scenario.

ACKNOWLEDGEMENT

We would like to express our sincere thanks to Dr. Zheng Wang
(Tsinghua University), Prof. S.V.N. Vishwanathan (Purdue University), and the anonymous reviewers for their valuable comments
and suggestions. This research was partially supported by the NSF
research grants IIS-0746830, CNS-1012208, IIS-1017837, CCF0939370.

7.

REFERENCES

[1] E. C. Anderson. Monte Carlo Methods and Importance
Sampling, 1999.
[2] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature
learning. In NIPS, page 41. MIT Press, 2007.
[3] S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira.
Analysis of representations for domain adaptation. In NIPS,
pages 137–144, 2006.
[4] A. Blum and T. M. Mitchell. Combining labeled and
unlabeled sata with co-training. In COLT, pages 92–100,
1998.
[5] E. Bonilla, K. Chai, and C. Williams. Multi-task Gaussian
process prediction. NIPS, 20:153–160, 2008.
[6] K. Crammer, M. Kearns, and J. Wortman. Learning from
multiple sources. Journal of Machine Learning Research,
9:1757–1774, 2008.

7. The traditional transfer learning methods show very poor performances in WebKB. This is because in the subdatasets of
WebKB, the link view contains too much noise as can be seen
from the performance of SVM-View2. Concatenating these
features together may bring more noise for classification, and
therefore could cause a decrease in the classification performance, especially for traditional transfer learning methods.
These observations clearly demonstrate the advantages of the
proposed method over state-of-the-art ones. It validates our claims
and theoretical analysis that by integrating the multi-view learning
and transfer learning together, the classification performance can
be greatly improved.

1215

[29] B. Quanz and J. Huan. Large margin transductive transfer
learning. In CIKM, pages 1327–1336, 2009.
[30] R. Raina, A. Battle, H. Lee, B. Packer, and A. Ng.
Self-taught learning: transfer learning from unlabeled data.
In ICML, pages 766–763, 2007.
[31] D. Rosenberg, V. Sindhwani, P. Bartlett, and P. Niyogi. A
Kernel for Semi-Supervised Learning With Multi-View Point
Cloud Regularization. IEEE Signal Processing Magazine,
2009.
[32] B. Scholkopf and A. Smola. Learning with kernels. MIT
press Cambridge, Mass, 2002.
[33] J. Shawe-Taylor and N. Cristianini. Kernel Methods for
Pattern Analysis. Cambridge University Press, New York,
NY, USA, 2004.
[34] S. Sheather and M. Jones. A reliable data-based bandwidth
selection method for kernel density estimation. Journal of
the Royal Statistical Society. Series B (Methodological),
53(3):683–690, 1991.
[35] H. Shimodaira. Improving predictive inference under
covariate shift by weighting the log-likelihood function.
Journal of Statistical Planning and Inference,
90(2):227–244, 2000.
[36] V. Sindhwani and P. Niyogi. A co-regularized approach to
semi-supervised learning with multiple views. In ICML
Workshop on Learning with Multiple Views, 2005.
[37] V. Sindhwani and D. Rosenberg. An RKHS for multi-view
learning and manifold co-regularization. In ICML, pages
976–983, 2008.
[38] A. Smola, S. Vishwanathan, and Q. Le. Bundle methods for
machine learning. NIPS, 20, 2008.
[39] C. Teo, S. Vishwanthan, A. Smola, and Q. Le. Bundle
methods for regularized risk minimization. The Journal of
Machine Learning Research, 11:311–365, 2010.
[40] G. Tur. Co-adaptation: Adaptive co-training for
semi-supervised learning. In ICASSP, 2009.
[41] M. Wu and B. Schölkopf. A local learning approach for
clustering. In NIPS, pages 1529–1536, 2006.
[42] B. Zadrozny. Learning and evaluating classifiers under
sample selection bias. In ICML, 2004.
[43] L. Zelnik-Manor and P. Perona. Self-tuning spectral
clustering. NIPS, 17:1601–1608, 2004.
[44] D. Zhang, F. Wang, C. Zhang, and T. Li. Multi-view local
learning. In AAAI, pages 752–757, 2008.
[45] T. Zhang, A. Popescul, and B. Dom. Linear prediction
models with graph regularization for web-page
categorization. In SIGKDD, pages 821–826, 2006.
[46] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and
B. Schölkopf. Learning with local and global consistency. In
NIPS, 2003.
[47] S. Zhu, K. Yu, Y. Chi, and Y. Gong. Combining content and
link for classification using matrix factorization. In SIGIR,
pages 487–494, 2007.

[7] W. Dai, G.-R. Xue, Q. Yang, and Y. Yu. Co-clustering based
classification for out-of-domain documents. In KDD, pages
210–219, 2007.
[8] W. Dai, Q. Yang, G. Xue, and Y. Yu. Boosting for transfer
learning. In ICML, pages 200–207, 2007.
[9] W. Dai, Q. Yang, G. Xue, and Y. Yu. Self-taught clustering.
In ICML, pages 200–207, 2008.
[10] J. Davis and P. Domingos. Deep transfer via second-order
Markov logic. In ICML, pages 217–224, 2009.
[11] L. Duan, I. Tsang, D. Xu, and S. Maybank. Domain transfer
svm for video concept detection. CVPR, pages 1375–1381,
2009.
[12] J. Farquhar, D. Hardoon, H. Meng, J. Shawe-Taylor, and
S. Szedmak. Two view learning: SVM-2K, theory and
practice. NIPS, 18:355, 2006.
[13] K. Ganchev, J. Graça, J. Blitzer, and B. Taskar. Multi-view
learning over structured and non-identical outputs. In UAI,
pages 204–211, 2008.
[14] T. Hofmann. Probabilistic latent semantic indexing. In
SIGIR, pages 50–57, 1999.
[15] J. Huang, A. Smola, A. Gretton, K. Borgwardt, and
B. Scholkopf. Correcting sample selection bias by unlabeled
data. NIPS, 19:601, 2007.
[16] T. Joachims. Training linear SVMs in linear time. In KDD,
pages 217–226, 2006.
[17] T. Joachims and N. Cristianini. Composite kernels for
hypertext categorisation. In ICML, pages 250–257, 2001.
[18] J. Kelley. The cutting plane method for solving convex
programs. Journal of the SIAM, 8(4):703–712, 1960.
[19] N. Lawrence and J. Platt. Learning to learn with the
informative vector machine. In ICML, page 65, 2004.
[20] G. Li, S. C. H. Hoi, and K. Chang. Two-view transductive
support vector machines. In SDM, pages 235–244, 2010.
[21] X. Ling, W. Dai, G.-R. Xue, Q. Yang, and Y. Yu. Spectral
domain-transfer learning. In KDD, pages 488–496, 2008.
[22] X. Liu, Y. Gong, W. Xu, and S. Zhu. Document clustering
with cluster refinement and model selection capabilities. In
SIGIR, pages 191–198, 2002.
[23] Y. Mansour, M. Mohri, and A. Rostamizadeh. Domain
adaptation with multiple sources. In NIPS, pages 1041–1048,
2008.
[24] Y. Mansour, M. Mohri, and A. Rostamizadeh. Multiple
source adaptation and the rényi divergence. In UAI, pages
367–374. AUAI Press, 2009.
[25] L. Mihalkova, T. Huynh, and R. Mooney. Mapping and
revising Markov logic networks for transfer learning. In
AAAI, volume 22, pages 608–613, 2007.
[26] L. Mihalkova and R. Mooney. Transfer learning by mapping
with minimal target data. In Proceedings of the AAAI-08
Workshop on Transfer Learning for Complex Tasks, 2008.
[27] K. Nigam and R. Ghani. Analyzing the effectiveness and
applicability of co-training. In CIKM, pages 86–93, 2000.
[28] S. Pan, J. Kwok, and Q. Yang. Transfer learning via
dimensionality reduction. In Proceedings of AAAI, pages
677–682.

1216

Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence

Hierarchical Modeling with Tensor Inputs
Yada Zhu, Jingrui He, Rick Lawrence
IBM T.J. Watson Research Center
1101 Kitchawan Road Route 134
Yorktown Heights, NY 10598

Abstract

either for classification or for regression (Mitchell 1997;
Wasserman 2009). However, by converting tensors into vectors, we tend to lose much information embedded in the
structure of tensors, such as the feature correspondence in
different steps in the example of semiconductor manufacturing, or the neighborhood information of a pixel in the example of computer vision.
To maximally exploit such valuable structural information embedded in the input tensors, in this paper, we address
the problem of predictive modeling with tensor inputs by directly operating on the tensors. To this end, we propose a
general optimization framework, which predicts the output
(or its probability of coming from each class) based on the
inner product between the input tensor and a weight tensor.
The weight tensor is then estimated in a hierarchical way. To
be specific, we assume that the weight tensor has a low-rank
approximation, and the Candecomp/Parafac (CP) decomposition (Kolda and Bader 2009) of the low-rank tensor can be
further approximated based on prior information from various sources, e.g., different domain experts. This framework
is motivated by wafer quality prediction in semiconductor
manufacturing, where the input tensors have two dimensions
(using summary statistics for each process variable in a single step instead of the instantaneous measurements): steps
and features. On one hand, the features in a single step, or
the same feature across different steps, tend to have similar
values in the weight tensor, which leads to the assumption of
low-rank approximation for the weight tensor; on the other
hand, different domain experts may have various opinions
regarding the relative importance of certain steps and certain
features on predicting wafer quality, and we need to leverage
their prior knowledge in order to improve the performance
of the predictor, especially when the labeled set is small.
Our proposed framework combines these two factors with
the prediction loss in the objective function, which leads to
an optimal solution for the weight tensor in the linear model.
Furthermore, we propose an effective algorithm for solving the optimization framework named H-MOTE. It is based
on block coordinate descent, which is guaranteed to converge to a local optimum since the objection function in the
general framework has unique minimum in each coordinate
block. Experimental results on synthetic and semiconductor
manufacturing data sets demonstrate the good performance
of H-MOTE compared with state-of-the-art techniques.

In many real applications, the input data are naturally expressed as tensors, such as virtual metrology
in semiconductor manufacturing, face recognition and
gait recognition in computer vision, etc. In this paper,
we propose a general optimization framework for dealing with tensor inputs. Most existing methods for supervised tensor learning use only rank-one weight tensors in the linear model and cannot readily incorporate
domain knowledge. In our framework, we obtain the
weight tensor in a hierarchical way – we first approximate it by a low-rank tensor, and then estimate the lowrank approximation using the prior knowledge from various sources, e.g., different domain experts. This is motivated by wafer quality prediction in semiconductor
manufacturing. Furthermore, we propose an effective
algorithm named H-MOTE for solving this framework,
which is guaranteed to converge. The time complexity
of H-MOTE is linear with respect to the number of examples as well as the size of the weight tensor. Experimental results show the superiority of H-MOTE over
state-of-the-art techniques on both synthetic and real
data sets.

Introduction
In many real applications, data come in the form of tensors,
or multi-dimensional arrays. For example, in semiconductor manufacturing, each recipe process usually has multiple
steps. During each step, we could observe process variables
such as temperature, pressure and gas flow per unit time.
Therefore, to predict the wafer quality, the input data are
naturally expressed as third-order tensors (the three dimensions or modes are steps, seconds within a step, and observed
process variables, or features) or second-order tensors if
we use the summary statistics for each process variable in
a single step instead of the instantaneous measurements.
Another example is in computer vision, where images can
be modeled as second-order tensors, and image sequences
can be modeled as third-order tensors (Wang, Chen, and
Xu 2011). Much existing work on dealing with tensor data
converts tensors into one-dimensional vectors, and applies
the rich methodology for vector inputs to build the model,
c 2012, Association for the Advancement of Artificial
Copyright 
Intelligence (www.aaai.org). All rights reserved.

1233

has not been as much effort on dealing with tensor inputs.
Existing methods for predictive modeling with tensor inputs
can be roughly categorized into the following 2 groups: dimensionality reduction and supervised tensor learning (classification and regression).
Dimensionality reduction for tensor data is also called
tensor embedding. It aims at finding the intrinsic local geometrical structure of the tensor space by learning a lower
dimensional tensor subspace (with the same order) (He, Cai,
and Niyogi 2005), which has been successfully applied in
computer vision tasks, such as face recognition (He, Cai,
and Niyogi 2005; Dai and Yeung 2006; Tao et al. 2008;
Li et al. 2008) and gait recognition (Tao et al. 2006; 2007;
Li et al. 2008), as well as network anomaly detection and
sensor measurements (Sun et al. 2008). For example, the authors in (He, Cai, and Niyogi 2005) propose the TSA algorithm for structured dimensionality reduction, which explicitly takes into account the manifold structure of the image
space; the authors in (Dai and Yeung 2006) propose several tensor embedding methods, which allow the relationships between dimensions of a tensor representation to be
efficiently characterized; for gait recognition, the authors
in (Tao et al. 2007) first build a set of Gabor based human gait appearance models, and then use GTDA to seamlessly incorporates the object structure information as a natural constraint; the authors in (Tao et al. 2008) generalize
the Bayesian principal component analysis (BPCA) to tensors; the authors in (Li et al. 2008) propose DLLE and its
tensorized version, which generalize LLE (Roweis and Saul
2000) to enforce the separability between different classes;
and the authors in (Sun et al. 2008) introduce a general
framework named ITA, which efficiently computes a compact summary for high-order and high-dimensional data, as
well as reveals the hidden correlations.
On the other hand, in supervised tensor learning, a classifier (or regressor) is directly built based on the tensor inputs
instead of their vectorized version. For example, in (Hochreiter and Obermayer 2004), the authors introduce P-SVM,
which minimizes a scale-invariant capacity measure under
a new set of constraints, and develop a fast optimization algorithm based on SMO (Platt 1998); in (Tao et al. 2005), the
authors establish a supervised tensor learning framework,
within which conventional learning machines such as SVM
and MPM can be generalized to tensors; and in (Cai, He, and
Han 2006), the authors propose STM, which finds a maximum margin classifier in the tensor space, and TLS, which
finds a minimum residual sum-of-squares classifier.
Our proposed method belongs to supervised tensor learning. In our method, the weight tensor of the underlying linear model is built in a hierarchical way: the weight tensor
is first approximated using a low-rank tensor; the Candecomp/Parafac (CP) decomposition (Kolda and Bader 2009)
of the low-rank tensor is then estimated based on prior information from various sources. Compared with the methods proposed in (Tao et al. 2005) and (Cai, He, and Han
2006), they can be seen as special cases of our model in the
sense that they only use rank-one weight tensors, whereas
in our model, the rank of the optimal weight tensor can
be more than one. Compared with P-SVM (Hochreiter and

The main contributions of this paper are as follows:
1. an optimization framework, modeling the predictive task
with tensor inputs in a hierarchical way;
2. an algorithm (H-MOTE), solving the optimization framework;
3. proof and analysis, showing the quality, convergence and
scalability of the proposed algorithm.
The rest of the paper is organized as follows. In Section 2,
we briefly review the related work. The general optimization
framework is presented in Section 3, followed by the introduction of H-MOTE algorithm in Section 4. We show some
experimental results in Section 5 with discussion. Finally,
we conclude the paper in Section 6.

Related Work
In this section, we briefly review related work on wafer quality prediction in semiconductor manufacturing and predictive modeling with tensor inputs.

Wafer Quality Prediction
In semiconductor manufacturing, wafers have to go through
hundreds of processes to become a final IC device. Each
process follows a given recipe that defines detailed fabrication steps and settings of the process variables. In recent
years, virtual metrology (VM) has received a lot of attention in semiconductor industry, which builds models to predict wafer quality based on historical measurements of wafer
quality and corresponding process variables. The predicted
wafer quality can then prompt feedback control in a timely
fashion, detect fault wafers early, and improve productivity
by reducing actual metrology frequency of wafer quality.
For this purpose, researchers have built statistical models such as multiple regression with feature selection (Kang
et al. 2011; Lynn et al. 2009), partial least squares (Khan,
Moyne, and tilbury 2008), SVM regression (Kang et al.
2011), and artificial neural networks (Chang et al. 2006;
Su et al. 2008) based on one-dimensional vectors converted
from the input tensors. However, as discussed in Section ,
this conversion tends to lose useful information embedded
in the structure of input tensors. For example, for a certain
recipe process, it may be the case that the process variables
in Step 12 have key impact on the wafer quality. These types
of prior knowledge cannot be naturally incorporated into the
statistical model based on vectorized tensors. On the other
hand, although the real-time process variables can be represented as multivariate time-series, for VM applications, the
objective is to predict the wafer quality, rather than to forecast the process variables. Therefore, time-series analysis is
not most appropriate for this purpose.
To the best of our knowledge, our work is the first to build
a tensor-based model for wafer quality prediction, which incorporates prior knowledge from various sources in a principled way.

Predictive Modeling with Tensor Inputs
Compared with the rich literature on predictive modeling
with vector inputs (Mitchell 1997; Wasserman 2009), there

1234

Obermayer 2004), we do not need to construct the data matrix, which involves complex interaction between the ‘row’
objects and the ‘column’ objects, and our method can be easily generalized to higher order tensors, whereas P-SVM can
only be applied on second-order tensors (matrices). Furthermore, compared with all the existing methods in this group,
our method is able to incorporate prior information from various sources in a principled way, whereas existing methods
cannot leverage this information.

CP decomposition factorizes a tensor into a sum of component rank-one tensors (Kolda and Bader 2009). For example,
given third-order tensor T ∈ Rd1 ×d2 ×d3 , we would like to
write it by
R
X
T =
ar ◦ br ◦ cr
r=1

where R is a positive integer, ar ∈ Rd1 , br ∈ Rd2 ,
cr ∈ Rd3 , and ‘◦’ denotes vector outer product. For the
ease of future explanation, we refer to ar ◦ br ◦ cr as the
rth component of T , r = 1, . . . , R.

Optimization Framework
In this section, we propose the general optimization framework for hierarchical modeling with tensor inputs. First we
introduce the notation used throughout this paper; then we
provide some background on CP decomposition and tensor
rank; based on the above introduction, we present the objective function; and finally, we interpret the objective function
from different perspectives.

The rank of a tensor T is defined as the smallest number of rank-one tensors that generate T as their sum (Kolda
and Bader 2009). In other words, in the above equation, the
smallest value of R that satisfies the equality is the rank of
T . In particular, when R = 1, for K th -order tensors, we can
decompose them into the outer product of K vectors.

Notation
Objective Function

Suppose that we are given N training examples {Xn , yn },
n = 1, . . . , N , where Xn ∈ Rd1 ×d2 ×···×dK is a Kdimensional array, or K th -order tensor, and yn ∈ R is the
response variable for regression problems, or yn ∈ {−1, 1}
is the class label for classification problems. Notice that for
Xn , K is the dimension of this array or the number of modes
of this tensor, and dk is the number of elements along the
k th dimension, k = 1, . . . , K. Therefore, the total number
QK
of input features is k=1 dk . When K = 1, the input Xn
is a vector, and the problem is reduced to regular regression or classification; when K = 2, Xn is a matrix; when
K > 2, Xn is a K th -order tensor. In this paper, we focus on
the cases where K > 1. For such problems, we can always
convert the input tensor into a vector by concatenating the
fibers along different modes, which are defined by fixing the
indices of all the modes but one.1 Then we can apply the
well-established techniques for dealing with vector inputs to
predict the value of yn . However, in this way, we lose the
rich information embedded in the structure of Xn . Therefore, in this paper, our goal is to predict the value of yn by
making use of the structure of Xn .
For future reference, throughout this paper, we use lowercase letters to denote scalers; boldface lower-case letters to
denote vectors; and calligraphic upper-case letters to denote tensors. Let T1 , T2 ∈ Rd1 ×d2 ×···×dK denote two tensors. Define hT1 , T2 i to be the inner product between T1
and T2 , which is the sum of the products of their correspondingpelements. Furthermore, define the norm of tensor
kT1 k = hT1 , T1 i.

In our proposed framework, we predict the value of yn using a linear model, such as the linear regression model for
regression problems and logistic regression model for classification problems. Therefore, in this linear model, we have a
weight tensor C ∈ Rd1 ×d2 ×···×dK , which is the same size as
Xn . The main idea of this framework is to model the weight
tensor in a hierarchical way, i.e., we first approximate the
weight tensor using a low-rank tensor, whose CP decomposition is in turn estimated based on prior information from
various sources.
To be specific, we minimize a loss function
L(yn , hXn , Ci) summed over all the training examples.
For example, L(·, ·) can be the squared loss in regression,
or the logistic loss in classification. Here we require that
L(·, ·) is convex with respect to the second argument.
Based on the tensor structure, we assume that the weight
tensor C can be approximated by a rank-R tensor with
PR
CP decomposition r=1 a1r ◦ a2r ◦ · · · ◦ aKr , where R
is equal to the number of sources where we could obtain
domain knowledge, e.g., R domain experts, and akr ∈ Rdk
is the weight vector for the k th mode in the rth component.
PR
Therefore, kC − r=1 a1r ◦ a2r ◦ · · · ◦ aKr k2 should
be small. Intuitively, each weight vector akr reflects the
importance of the k th mode of the input tensors in the rth
component, and akr (r = 1, . . . , R) collectively measure
the contribution of the k th mode of Xn to the output yn .
For example, when K = 2 and R = 1, C is a matrix, and
C(i, j) should be close to a11 (i) × a21 (j), where C(i, j)
is the element of C in the ith row and j th column, a11 (i)
is the ith element of a11 , and a21 (j) is the j th element of
a21 . Furthermore, to estimate the weight vector akr , we
need to leverage the domain knowledge from R different
sources, e.g., domain experts. To be specific, for each akr ,
we assume that it is close to vector akr0 ∈ Rdk , which is
given to us a priori from the rth source, r = 1, . . . , R.

CP Decomposition and Tensor Rank
In our framework, the rank-R approximation of the weight
tensor is decomposed into a sum of vector outer products
based on CP decomposition (Kolda and Bader 2009). The
1
Note that the vectorized version of the tensor may not be
unique due to different orderings of the fibers.

1235

fix akr , and minimize f with respect to C, we have
N
X
fakr (C) =
L(yn , hXn , Ci)

Putting everything together, we minimize the following.
f (C, akr , k = 1, . . . , K, r = 1, . . . , R)
=

N
X

L(yn , hXn , Ci) + γ0 kC −

n=1

+

K X
R
X

R
X

(1)

n=1

a1r ◦ a2r ◦ · · · ◦ aKr k2
+ γ0 kC −

r=1

R
X

a1r ◦ a2r ◦ · · · ◦ aKr k2

r=1

γkr kakr − akr0 k2

Notice that the third term on the right hand side of Equation
(1) is not dependent on C. It is easy to see that fakr (C) is
convex in C, given that L(·, ·) is convex with respect to the
second argument, and
N
∂fakr (C) X
=
l(yn , hXn , Ci)Xn
∂C
n=1

k=1 r=1

where γ0 and γkr (k = 1, . . . , K, r = 1, . . . , R) are positive
parameters that balance among different terms. In particular,
the relative values of γ1r , . . . , γKr reflect our confidence in
using prior knowledge to approximate the weight vector in
each mode of the rth component: the bigger the value of γkr ,
the more confident we are about this approximation.

+ 2γ0 (C −

R
X

Interpreting the Objective Function

a1r ◦ a2r ◦ · · · ◦ aKr )

(2)

r=1

In this subsection, we interpret the objective function in
Equation (1) from different perspectives.
If L(yn , hXn , Ci) is the squared loss for regression problems or logistic loss for classification problems, it reflects
the negative log-likelihood of the nth example, and Equation
(1) can be interpreted from a probability perspective. To be
specific, if the prior distribution of C is normal with mean
PR
1
r=1 a1r ◦ a2r ◦ · · · ◦ aKr and variance 2γ0 for each element, and the prior distribution of akr is normal with mean
akr0 and variance 2γ1kr for each element, then Equation (1)
is the posterior probability of C and akr (k = 1, . . . , K, r =
1, . . . , R) given the data (up to a constant). Therefore, by
minimizing Equation (1), we can find the MAP estimates
of the weight tensor C as well as the weight vectors akr
(k = 1, . . . , K, r = 1, . . . , R).
On the other hand, traditional ridge regression and logistic regression for vector inputs can be seen as special cases
of the proposed optimization framework. To see this, simply
fix akr (k = 1, . . . , K, r = 1, . . . , R) to be 0 vectors, and
we have the same objective function as in ridge regression
or logistic regression for vector inputs. In this way, when we
minimize the original objective function with respect to both
the weight tensor and the weight vectors, the second term on
the right hand side of Equation (1) can be seen as a new regularizer which encourages a low-rank approximation of the
weight tensor C instead of shrinking it to 0 as in ridge regression and logistic regression. As we will see in Section , the
use of this new regularizer effectively prevents over-fitting,
especially when the labeled data is very scarce.

where l(·, ·) is the partial derivative of L(·, ·) with respect to
the second argument.
Similarly, if we minimize f with respect to als , keeping C
and akr fixed, k 6= l, r 6= s, we have
R
X
a1r ◦ a2r ◦ · · · ◦ aKr k2
fC,akr ,k6=l,r6=s (als ) = γ0 kC −
r=1

+ γls kals − als0 k2
Notice that the first term on the right hand side of Equation (1) is not dependent on als . It is easy to see that
fC,akr ,k6=l,r6=s (als ) is convex in als , and
∂fC,akr ,k6=l,r6=s (als )
= 2γ0 (αls als − β ls + τ ls )
∂als
+ 2γls (als − als0 )
(3)
where αls = ha1s ◦ · · · ◦ a(l−1)s ◦ a(l+1)s ◦ · · · ◦ aKs , a1s ◦
· · · ◦ a(l−1)s ◦ a(l+1)s ◦ · · · ◦ aKs i, and β ls , τ ls are dl dimensional vectors. For β ls , its ith element β ls (i) =
hCl=i , a1s ◦ · · · ◦ a(l−1)s ◦ a(l+1)s ◦ · · · ◦ aKs i. Here Cl=i ∈
Rd1 ×···×dl−1 ×dl+1 ×···×dK is a (K −1)th -order tensor. Its elements are equal to C with the index of the lth dimension fixed
at i. For τ ls , its ith element τ ls (i) = hTlsi , a1s ◦· · ·◦a(l−1)s ◦
a(l+1)s ◦ · · · ◦ aKs i. Here Tlsi ∈ Rd1 ×···×dl−1 ×dl+1 ×···×dK
P
is a (K − 1)th -order tensor, and Tlsi = r6=s alr (i)(a1r ◦
· · · ◦ a(l−1)r ◦ a(l+1)r ◦ · · · ◦ aKr ).
Therefore, setting Equation (3) to 0, we have the following optimal vector a∗ls that minimizes fC,akr ,k6=l,r6=s (als ).
γ0 β ls − γ0 τ ls + γls als0
a∗ls =
(4)
γ0 αls + γls

H-MOTE Algorithm
In this section, we introduce the H-MOTE algorithm (Hierarchical MOdeling with TEnsor inputs) for calculating
the weight tensor C that minimizes Equation (1), analyze
its performance in terms of quality, convergence, and time
complexity, and elaborate on a special case of H-MOTE for
squared loss in regression problems.

Algorithm Description
Based on the above discussion, in this paper, we make use
of block coordinate descent method to find the optimal solution to Equation (1). The convergence of block coordinate
descent is guaranteed since the objective function has unique
minimum in each coordinate block (Luenberger 1973). The
proposed H-MOTE algorithm is shown in Algorithm 1. It
works as follows. In Step 1, we initialize vector akr to be
akr0 ; between Step 2 and Step 9, we alternatively update

Analysis of Equation (1)
Notice that the function f is not jointly convex with respect
to C and akr , k = 1, . . . , K, r = 1, . . . , R. However, if we

1236

QK
QK
where IQK
denotes the k=1 dk × k=1 dk identity
k=1 dk
matrix, xn denotes the vectorized version of Xn , x0n denotes
the transpose of xn , and br denotes the vectorized version
of a1r ◦ a2r ◦ · · · ◦ aKr . Notice that Equation (5) is very
similar to ridge regression on the vectorized inputs except
PR
for the term γ0 r=1 br , which reflects both the low-rank
nature of the weight tensor as well as prior knowledge. As
can be seen in the next section, it is particularly helpful for
preventing overfitting when the labeled set size is small.
In this case, in Step 3 of H-MOTE, instead of updating
C using gradient descent, we simply apply Equation (5) to
obtain c, which, after rearranging the elements, will give us
the current weight tensor C.

weight tensor C and weight vectors akr (k = 1, . . . , K,
r = 1, . . . , R) for T times.
During the test stage, given a tensor X , we first calculate
its inner product with the weight tensor C, hX , Ci, which
can be used to predict the output for regression problems,
or transformed into probabilities via the logistic function for
classification problems.

Quality and Convergence Analysis
With respect to the convergence of the proposed H-MOTE
algorithm, we have the following lemma.
Lemma 1. If the number of iteration steps T is sufficiently
large, H-MOTE will converge to a local optimum of the objective function in Equation (1).
Proof. Omitted due to lack of space.

Experimental Results
In this section, we demonstrate the performance of the proposed H-MOTE algorithm on both synthetic and real data
sets. In particular, we aim to answer the following questions.
1. How does the performance of H-MOTE compare with the
algorithms dealing with vectorized inputs?
2. How does the performance of H-MOTE compare with
other supervised tensor learning algorithms?
3. How is H-MOTE affected by small perturbations in the
parameters?
4. How fast does H-MOTE converge to a local optimum?
5. Will higher-rank tensors improve the performance?
To answer the first 5 questions, we fix R = 1 in H-MOTE,
and test the following variants of H-MOTE: H-MOTE1 with
ak10 (k = 1, . . . , K) set to zero; H-MOTE2 with ak10 (k =
1, . . . , K) given by a domain expert; H-MOTE3 with ak10
(k = 1, . . . , K) set using the output of H-MOTE2.

Time Complexity
Assuming that the number of iteration steps needed for gradient descent in Step 3 of H-MOTE is upper bounded by T 0 ,
we have the following lemma demonstrating the time complexity of H-MOTE.
Lemma 2. The time complexity of H-MOTE is
QK
O(T ((T 0 (N + KR) + K 2 R2 ) k=1 dk )).
Proof. Omitted due to lack of space.
Notice that in all our experiments, T and T 0 are always
upper bounded by 50. Therefore, according to the above
lemma, H-MOTE scales linearly with respect to the number
of examples and the size of the weight tensor.
Algorithm 1 H-MOTE: Hierarchical Modeling with Tensor
Inputs
Input: Xn , yn , n = 1, . . . , N , γ0 , γkr , akr0 , (k =
1, . . . , K, r = 1, . . . , R), the number of iteration steps
T
Output: Weight tensor C and weight vectors akr (k =
1, . . . , K, r = 1, . . . , R)
1: Initialize akr = akr0 (k = 1, . . . , K, r = 1, . . . , R)
2: for t = 1 to T do
3:
Update the weight tensor C using gradient descent according to Equation (2)
4:
for k = 1 to K do
5:
for r = 1 to R do
6:
Update vector akr according to Equation (4)
7:
end for
8:
end for
9: end for

Synthetic Data
In this subsection, we answer the first question, and compare
the three variants of H-MOTE with ridge regression for vectorized inputs (Ridge) (Wasserman 2009) on synthetic data
sets. The data sets consist of 1000 randomly generated examples represented as second-order tensors. The outputs are
obtained by first calculating the inner product between the
input tensors and a rank-one weight tensor, and then adding
Gaussian noise with increasing variance. The Root Mean
Squared Error (RMSE) of 5-fold cross validation are shown
in Figure 1, which are averaged over 50 runs.

Case Study
In this subsection, we study a special case of H-MOTE,
where the loss function is given by L(yn , hXn , Ci) = (yn −
hXn , Ci)2 . In this way, we have l(yn , hXn , Ci) = −2(yn −
hXn , Ci). By setting Equation (2) to 0, we have a closedform solution for the vectorized version c of the weight tensor C in each iteration step of H-MOTE,
N
R
N
X
X
X
0 −1
c = (γ0 IQK
+
x
x
)
(γ
b
+
yn xn )
n
0
r
n
k=1 dk
n=1

r=1

(a) Training error

(b) Test error

Figure 1: Comparison on synthetic data: H-MOTE methods
perform better than ridge regression and prevent overfitting.

n=1

(5)

1237

(a) Data set 1

(b) Data set 2

(c) Data set 3

Figure 2: Comparison on real data: H-MOTE3 has the lowest average RMSE

are chosen based on cross-validation in the training set only.
Next we answer the first two questions on the real data
sets. The comparison results of the six methods are shown in
Figure 2. For each training set size, we run the experiments
50 times, and report both the mean and the standard deviation. From these figures, we can see that the performance of
H-MOTE methods is consistently better than Ridge, which
takes vectorized inputs, and existing supervised tensor learning methods (PSVM and TLS). Comparing H-MOTE2 and
H-MOTE1, the prior information provided by the domain expert used in H-MOTE2 helps improve the performance; and
in H-MOTE3, by using the output of H-MOTE2 as the prior,
we further reduce the RMSE.

From this figure, we have the following observations.
First, H-MOTE methods for tensor inputs are significantly
better than ridge regression for vectorized inputs in terms
of both the training error and the test error. Second, on the
test set, the standard deviation of RMSE for H-MOTE methods is much smaller compared with ridge regression. Third,
using ridge regression, the difference between the average
RMSE on the training set and on the test set is larger than using H-MOTE methods, showing that H-MOTE methods are
more robust to overfitting. Finally, as we increase the standard deviation of the Gaussian noise, the difference between
H-MOTE methods and ridge regression is getting smaller.

Real Data

Robustness Study In this part, we answer the third question, and use the first data set to test H-MOTE under small
perturbations of the parameters γ0 , γ11 and γ12 . Figure 3
shows the RMSE vs. different values of γ0 , which demonstrates the robustness of H-MOTE. The results of the other
parameters are similar and omitted due to lack of space.

In this subsection, we test the performance of H-MOTE on
three data sets collected from semiconductor manufacturing
processes. The first data set corresponds to a process with a
total of 7 steps, each having 17 process variables. The median of each process variable is obtained, which can be represented as a second-order tensor of size 7 × 17 or a vector
of length 119. The second and third data sets correspond to
a process with 10 steps, each having 15 process variables.
For the second data set, we use the median of each process
variable, which can be represented as a second-order tensor
of size 10 × 15 or a vector of length 150; and for the third
process, we use both the median and the variance, which can
be represented as a second-order tensor of size
10 × 30 or a vector of length 300. Due to the low frequency
of actual metrology, in 9-month time period there are totally
488 and 891 target measurements for the two processes. Before building VM prediction models, data are preprocessed
to eliminate observations with missing values, measurement
errors and outliers. The process variables and the output are
normalized to have mean zero and standard deviation one.

Convergence Rate In this part, we answer the fourth
question using the first data set. We assume that the algorithm converges if the change of the estimated weight
tensor C and estimated weight vectors a11 and a12 is less
than 10−7 . We let the algorithm run sufficiently large
number of iterations to obtain the optimal value C ∗ , a∗11
and a∗12 . Then at iteration t, we calculate the difference
between
the current estimates and their optimal value: δt =
p
k Ct − C ∗ k2 + k a11,t − a∗11 k2 + k a12,t − a∗12 k2 ,
where Ct , a11,t and a12,t are the estimated tensor and
weight vectors at iteration t. In Figure 4, we plot the natural
log of δt versus the iteration number t. We can see that
H-MOTE converges at least exponentially.
Higher Rank Weight Tensors In this part, we answer the
last question. In our framework, the rank R depends on the
number of sources to obtain the domain knowledge. Next
we test the performance of H-MOTE with R = 2, where one
source of prior knowledge is from the domain expert, and the
other is from H-MOTE1 with R = 1. The comparison results
of H-MOTE with R = 1 and R = 2 on the second data set
are shown in Figure 5. We can see that bigger values of R
are able to further improve the performance of H-MOTE in
terms of the average RMSE of cross validation.

Comparison with Different Algorithms On the real data
sets, we compare the three variants of H-MOTE with the following three competitors: Ridge (ridge regression (Wasserman 2009)) for dealing with vectorized inputs; PSVM (Potential Support Vector Machine (Hochreiter and Obermayer
2004)) for supervised tensor learning; and TLS (Tensor
Least Squares (Cai, He, and Han 2006)) for supervised tensor learning. For all these methods, the cross-validation results of RMSE are used for comparison, and the parameters

1238

Kang, P.; Kim, D.; Lee, H.-J.; Doh, S.; and Cho, S. 2011.
Virtual metrology for run-to-run control in semiconductor
manufacturing. Expert Systems with Applications 38:2508–
2522.
Khan, A. A.; Moyne, J. R.; and tilbury, D. M. 2008. Virtual metrology and feedback control for semiconductor manufacturing processes using recursive partial least squares.
Journal of Process Control 18:961–974.
Kolda, T. G., and Bader, B. W. 2009. Tensor decompositions
and applications. SIAM Review 51(3):455–500.
Li, X.; Lin, S.; Yan, S.; and Xu, D. 2008. Discriminant
locally linear embedding with high-order tensor data. IEEE
Trans. on Systems, Man, and Cybernetics 38(2):342–352.
Luenberger, D. G. 1973. Linear and Nonlinear Programming. Massachusetts: Addison-Wesley, second edition.
Lynn, S.; Ringwood, J.; Ragnoli, E.; McLoone, S.; and
MacGearailt, N. 2009. Virtual metrology for plasma etch
using tool variables. In Advanced Semiconductor Manufacturing Conference.
Mitchell, T. M. 1997. Machine Learning. New York:
McGraw-Hill.
Platt, J. C. 1998. Fast training of support vector machines
using sequential minimal optimization. Advances in Kernel
Methods.
Roweis, S. T., and Saul, L. K. 2000. Nonlinear dimensionality reduction by locally linear embedding. SCIENCE
290:2323–2326.
Su, Y.-C.; Lin, T.-H.; Cheng, F.-T.; and Wu, W.-M. 2008.
Accuracy and real-time considerations for implementing
various virtual metrology algorithms. IEEE Trans. on Semiconductor Manufacturing 21(3):426–434.
Sun, J.; Tao, D.; Papadimitriou, S.; Yu, P. S.; and Faloutsos,
C. 2008. Incremental tensor analysis: Theory and applications. TKDD 2(3).
Tao, D.; Li, X.; Hu, W.; Maybank, S.; and Wu, X. 2005.
Supervised tensor learning. In ICDM, 450–457. IEEE Computer Society.
Tao, D.; Li, X.; Maybank, S. J.; and Wu, X. 2006. Human
carrying status in visual surveillance. In CVPR, 1670–1677.
Tao, D.; Li, X.; Wu, X.; and Maybank, S. J. 2007. General tensor discriminant analysis and gabor features for
gait recognition. IEEE Trans. Pattern Anal. Mach. Intell.
29(10):1700–1715.
Tao, D.; Sun, J.; Shen, J.; Wu, X.; Li, X.; Maybank, S. J.;
and Faloutsos, C. 2008. Bayesian tensor analysis. In IJCNN,
1402–1409.
Wang, Q.; Chen, F.; and Xu, W. 2011. Tracking by thirdorder tensor representation. IEEE Trans. on Systems, Man,
and Cybernetics 41:385 – 396.
Wasserman, L. 2009. All of Statistics. New York: SpringerVerlag New York, LLC.

Figure 3: Impact of small Figure 4: Convergence study
perturbations in γ0
of H-MOTE

Figure 5: Comparison of H-MOTE with different ranks

Conclusion
In this paper, we propose a general optimization framework
for hierarchical modeling with tensor inputs, which is motivated by wafer quality prediction in semiconductor manufacturing. This optimization framework directly operates
on the input tensors, and it is able to incorporate domain
knowledge in a principled way. To solve the optimization
framework, we propose an effective algorithm named HMOTE based on block coordinate descent. It converges to
a local optimum, with linear time complexity regarding the
total number of examples and the number of elements in the
weight tensor. Experimental results on both synthetic and
real data sets demonstrate the effectiveness of H-MOTE.

References
Cai, D.; He, X.; and Han, J. 2006. Learning with tensor
representation. Technical report, University of Illinois at
Urbana-Champaign.
Chang, Y.-J.; Kang, Y.; Hsu, C.-L.; Chang, C.-T.; and Chan,
T. Y. 2006. Virtual metrology technique for semiconductor
manufacturing. In IJCNN.
Dai, G., and Yeung, D.-Y. 2006. Tensor embedding methods. In AAAI.
He, X.; Cai, D.; and Niyogi, P. 2005. Tensor subspace analysis. In NIPS. MIT Press.
Hochreiter, S., and Obermayer, K. 2004. Classification, regression, and feature selection on matrix data. Technical
report, Technische Universitat Berlin.

1239

Graph Based Multi-Modality Learning*
Hanghang Tong1, Jingrui He1, Mingjing Li2, Changshui Zhang1, Wei-Ying Ma2
1

Automation Department, Tsinghua University, Beijing 100084, China
+86-10-62782447
{walkstar98, hejingrui98}@mails.tsinghua.edu.cn
zcs@mail.tsinghua.edu.cn
2
Microsoft Research Asia, 49 Zhichun Road, Beijing 100080, China
+86-10-62617711
{mjli, wyma}@microsoft.com
8, 11, 24, 25]. For example, Web page can be represented by its
plain text as well as the anchor text; video can be represented by
visual, audio, and caption track; digital image can be represented
by color feature and texture feature; Web image can be
represented by content feature and its text annotation. A lot of
research demonstrates that by properly fusing the evidence from
each modality, better understanding could be achieved than only
using one modality or simply treating all representation as one
modality.*

ABSTRACT
To better understand the content of multimedia, a lot of research
efforts have been made on how to learn from multi-modal feature.
In this paper, it is studied from a graph point of view: each kind of
feature from one modality is represented as one independent graph;
and the learning task is formulated as inferring from the
constraints in every graph as well as supervision information (if
available). For semi-supervised learning, two different fusion
schemes, namely linear form and sequential form, are proposed.
For each scheme, it is derived from optimization point of view;
and further justified from two sides: similarity propagation and
Bayesian interpretation. By doing so, we reveal the regular
optimization nature, transductive learning nature as well as prior
fusion nature of the proposed schemes, respectively. Moreover,
the proposed method can be easily extended to unsupervised
learning, including clustering and embedding.
Systematic
experimental results validate the effectiveness of the proposed
method.

According to the different learning tasks, existing work in multimodality learning can be classified into three categories:
supervised learning, semi-supervised learning, and un-supervised
learning.
Tradition methods mainly focus on supervised learning task.
According to at which level fusion takes place, they can be further
classified into two categories: fusion at feature level and fusion at
output level [8]. The work in [5] belongs to the first category, in
which textual and visual features are concatenated into one single
index vector for Web image retrieval. On the other hand, it has
been recognized that fusion on output level generally outperforms
the former [6, 8, 11]. Many fusion strategies can be adopted in
this case, including linear combination, min-max aggregation,
voting production combination etc [14, 19]. Among them, one
most widely used strategy is linear combination [11, 14].
However, as pointed out by [25], linear combination has its own
theoretical limitation. To address this issue, by treating the output
of each classifier as a new kind of feature, the authors in [24]
proposed a non-linear fusion method named super-kernel.
However, the unlabelled data is still not explored.

Categories and Subject Descriptors
H.3.1 [INFORMATION STORAGE AND RETRIEVAL]:
Content Analysis and Index.

General Terms: Algorithms, Theory, Experimentation.
Keywords: Multi-modality analysis; graph model; regularized
optimization; similarity propagation; Bayesian interpretation.
1. INTRODUCTION
In multimedia content analysis, much research effort has been
made to utilize the multi-modal feature to better understand the
multimedia content in recent years, which benefits from the
following fact: the representation for the data point can be
naturally split into two or more independent modalities [1, 3, 5, 6,

To leverage the unlabelled data in the training stage, semisupervised learning has been applied into multi-modality learning.
One of the most widely used methods in this category is Co-Train
[3]. The authors in [3] justified Co-Train in the Probably
Approximately Correct (PAC) framework, provided that two
modalities are compatible and un-correlated. The authors in [7]
applied Co-Train in Web image annotation and retrieval.
However, in real applications, the two assumptions of Co-Train
(compatibility and un-correlation) are not always satisfied. An
important variant of Co-Train is Co-EM [9, 17], which uses the
hypothesis in one modality to probabilistically label the sample in
the other modality. The authors in [17] argue that Co-EM is

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
MM’05, November 6–11, 2005, Singapore.
Copyright 2005 ACM 1-59593-044-2/05/0011…$5.00.

*

862

This work was performed at Microsoft Research Asia.

spectral clustering or embedding algorithms, the proposed method
can be naturally extended to un-supervised learning.

closer to theoretical assumptions in [3] than Co-Train. However,
as pointed out by [26], Co-EM is just a technical design and its
convergence is not proved.

The main contribution of this paper is summarized as follows:

To cluster objects with heterogeneous features, some researchers
have extended existing clustering methods to multi-modality
version.
For example, the authors in [23] proposed a
reinforcement clustering algorithm; the authors in [13] extended
existing DBSCAN algorithm to multi-modality; the authors in [2]
extended EM to Multi-View EM based on mixture model.
Compared with supervised learning, unsupervised learning in
multi-modality seems not to be fully explored.
On a more general level, there are two key issues in multimodality learning for any learning task: 1) how to learn within
each modality; 2) how to fuse the evidence across each modality.
It can be seen that most of existing work in multi-modality
learning is based on vector model.

1)

Make a systematic investigation on graph based methods in
terms of their extension in multi-modality learning. Both
semi-supervised and un-supervised learning are investigated;

2)

For semi-supervised learning, propose two different schemes.
For each scheme, it is derived from optimization point of
view and further justified from two sides: similarity
propagation and Bayesian interpretation;

3)

For un-supervised learning, extend a spectral clustering
algorithm to multi-modality; extend a spectral embedding
algorithm to multi-modality.

The organization of this paper is as follows. In Section 2, we
make a short review on the related work. The proposed method for
semi-supervised learning task is presented in Section 3. Its
extension to unsupervised task is provided in Section 4. In
Section 5, we provide systematic experimental results which
demonstrate the effectiveness of our method. Finally, we
conclude the paper in Section 6.

More recently, graph based learning method has attracted more
and more research attention in both learning society and
multimedia community. For unsupervised learning task, spectral
clustering has shown its superiority in many applications. For
example, the authors in [27] proposed Locality Preserving Cluster
(LPC) algorithm for clustering images and demonstrated its
advantage over traditional methods. In [4], the authors applied
Laplacian Eigen-Map [1] to hierarchically cluster Web image
search result. For semi-supervised learning task, the authors in
[10] applied a recent developed manifold ranking algorithm in
content based image retrieval (CBIR) in the scenario of query by
example (QBE). By exploring the relationship among all images
in the database, the authors showed that it outperforms the stateof-art techniques in CBIR. The authors in [20] further extend the
manifold ranking algorithm to image retrieval in the scenario of
query by keyword (QBK).

2. RELATED WORK
2.1 Manifold Ranking Algorithm
The manifold ranking algorithm is a graph based semi-supervised
learning algorithm [30, 31]. It has two versions for different tasks:
to rank data points and to predict the labels of unlabeled points.
For the task of predicting the labels of unlabeled data points, it can
be
formulated
as:
given
a
set
of
points
χ = {x1 , K, xl , xl +1 , K, xn } ⊂ m and a label set

ζ = {1,L,c} , the first l points xi (i ≤ l ) are labeled as yi ∈ ζ ;

Inspired by the success of [4, 10, 20, 27], in this paper, we take a
further step on graph based methods and explore their extensions
in multi-modality learning task. From graph point of view, each
kind of feature from one modality is represented as one
independent graph and the learning task is formulated as inferring
from the constraints in every graph as well as supervision
information (if available).

and the remaining points xu (l + 1 ≤ u ≤ n) are to be labeled.
Define a n × c labeling matrix Y = [Y1 ,L , Yc ] with Yij = 1 if xi is
labeled as yi = j and Yij = 0 otherwise; define a

n×c

matrix F corresponding to a classification on the dataset χ by
labeling each point xi with yi = arg max j ≤ c Fij . The procedure of

For semi-supervised learning, both classification and retrieval in
QBK are considered. Based on different optimization strategies,
two different fusion schemes, namely linear form and sequential
form, are proposed. While in the linear form, all the constraints
are fused simultaneously, they are considered sequentially in the
sequential form. For each scheme, both closed solution and
iterative solution are developed, providing the later converges to
the former. To reveal the transductive nature as well as prior
probability fusion nature, the proposed schemes are further
justified from two sides: similarity propagation and Bayesian
interpretation, respectively. By doing so, we will show that the
difference between linear form and sequential form actually comes
from 1) the different optimization strategy they adopt; 2) the
different manner they spread and fuse similarity through graphs;
and 3) the different way they fuse the prior probability.

predicting labels can be summarized as the follows [30]:

Algorithm 1 Manifold ranking algorithm
1.

Let W = (Wij , i , j = 1,L, n ) an n × n affinity matrix.

2.

Symmetrically normalize W by S = D −1/ 2WD −1/ 2 in
which D is the diagonal matrix with ( i, i ) -element equal
to the sum of the ith row of W.

3.

Iterate F ( t + 1) = α SF ( t ) + (1 − α ) Y until convergence,
where α is a parameter in [ 0,1) and F ( 0 ) = Y .

4.

On the other hand, the proposed method can be viewed as
similarity matrix learning or graph Laplacian learning from multimodality. Thus, by feeding the learnt matrix into some existing

Let F * denote the limit of the sequence {F ( t )} . Label
each point xi with yi = arg max j ≤ c Fij* .

863

(

An intuitive description of the above algorithm is: a weighted
graph is first formed which takes each data point as a vertex; a
positive score is assigned to each label while zero to the remaining
points; all the points then spread their scores to the nearby points
via the weighted graph; the spread process is repeated until a
global stable state is reached, and all the points will have their
own scores according to which they will be labeled.

Let W a = Wija , i, j = 1, 2,L , n

)

be an n × n

affinity matrix

constructed from x (i = 1,2,L, n ) , where Wija denotes the
a
i

similarity between xi and x j measured from modality a .
Normalize W a by S a = ( D a ) −1 2 W a ( D a ) −1 2 , where D a is the
diagonal matrix with ( i , i ) -element equal to the sum of the ith row

2.2 Application in Image Retrieval

of W a ;

In [10, 20], the authors have applied the above algorithm to image
retrieval in the scenario of QBE and QBK, respectively. In both
works, the authors showed that their algorithms outperform the
state-of-art techniques. The key points of [10, 20] are briefly
summarized as follows:

Let W b , D b , and S b be defined similarly as above, except that
they are constructed from modality b ;
Let Y be an n × c labeling matrix with Yij = 1 if xi is labeled as
yi = j and Yij = 0 otherwise; Yi is a 1 × c labeling vector for

♦ In the initial query stage in the scenario of QBE, there is only
one query in the label set (in this case, F is an n × 1 ranking
vector). The resultant ranking score of an unlabeled image is
in proportion to the probability that it is relevant to the query,
with large ranking score indicating high probability. For QBK,
the keyword model, indicating the relevant score of each
image with each keyword, is constructed from the initial labels
and step 4 in algorithms 1 is ignored for soft annotation
purpose. The initial retrieval result is given by sorting the
image in the descending order of its relevant score with
respect to the query.

data i ;
Let F be an n × c vectorial function, where Fij denotes the
relevance of data i belonging to class j , with a larger value
indicating higher relevance. Fi is a 1 × c classification vector for
data i .
With the above notation, the learning task is to infer the vectorial
function F from W a , W b and Y as Eq.1.
{(W a , D a , S a ); (W b , D b , S b ); Y } → F

♦ In relevance feedback (both in QBE and QBK), if the user
only marks relevant examples, the algorithm can be easily
generalized by adding these newly labeled images into the
query set; on the other hand, if examples of both labels are
available, they are treated differently: relevant images are also
added to the query set, while for irrelevant images, the authors
designed three schemes based on the observation that positive
examples should make more contribution to the final ranking
score than negative ones.

Once F is obtained, a classification decision on the dataset χ
can be made by labeling each point xi with yi = arg max j ≤ c Fij .
For retrieval task in the scenario of QBK, the relevance score of
the data point xi with respect to the query q is given by Si = Fiq .
The initial retrieval result is given by sorting the data points in the
decreasing order of their relevance scores.
To best fuse the information of S a , S b and Y to improve
classification or retrieval performance, a ‘good’ vectorial function
F should be as consistent as possible with these information, that
is to say, if two points ( xi and x j ) are measured as similar by S a

♦ To maximally improve the ranking result, the authors also
developed three active learning methods for selecting images
in each round of relevance feedback. Namely, 1) to select the
most positive images; 2) to select the most informative images;
and 3) to select the most positive and inconsistent images.

or S b , they should receive similar classification vectors in F ( Fi
and F j ) and vice versa. On the other hand, if a data point xi is

3. GRAPH BASED SEMI-SUPERVISED
LEARNING IN MULTI-MODALITY

within the initial label set, its classification vector Fi should be as
consistent as possible with the initial labeling vector Yi . In the
following two subsections, we will present two different fusion
schemes based on different optimization strategies, respectively.

First, we address the graph based semi-supervised learning in
multi-modality, including classification and retrieval in the
scenario of QBK. After a brief statement of notation and problem
definition, we will propose two different fusion schemes from
optimization point of view, and further justify them from both
similarity propagation point of view and Bayesian interpretation.

3.2 Linear Fusion Scheme
In this scheme, the constraints from S a , S b and Y are fused
simultaneously by a weighted sum. To meet this end, we
formulate a regularized optimization framework by defining the
following cost function with respect to F , which is a direct
extension of [30]:

3.1 Notation and Problem Definition
We use the same notations as those in Algorithm 1, except that
each data point has more than one kind of feature (one modality
for one kind of feature). Without losing generality, we suppose
each data point
has two kinds of feature:
xi

xi = xia , xib

(1)

(i = 1,2,L, n ) , where xia and xib denote the feature

vector constructed from modality a and b , respectively.

864

 n

Q ( F ) =  µ ∑ Wija
 i , j =1


1

⋅ Fi −

Diia

D ajj

⋅ Fj

2
n

η ∑ Wijb
i , j =1

1
b
ii

D

Solving the optimization problem defined by Eq. 8 and 9 leads to
the following optimal vectorial function F2* (Sequential Form):

2

1

1

⋅ Fi −

D

b
jj

⋅ Fj

n

+ε∑
i =1

+


2
Fi − Yi 



F2* = (1 − µ )(1 − η )( I − η S b ) −1 ( I − µ S a ) −1 ⋅ Y

(2)

Like in linear form, the iterative form for F2* can be given as :

F2 (t + 1) = µ S a F2 (t ) + η S b F2 (t ) − µη S b S a F2 (t ) + (1 − µ )(1 − η )Y
where F2 (0) = Y

The first, second and third items on the right hand side of Eq.2
correspond to the constraints from S a , S b and Y , respectively.
The trade-off among these constraints is captured by the
regularization parameters µ , η and ε , where 0 < µ ,η , ε < 1

(11)

And the relationship between the iterative form and linear form
can be given as:
F2* = lim F2 (t )

and µ + η + ε = 1 .

t →∞

Eq. 2 can be re-written in a more concise form as follows:

Using Taylor expansion and omitting the constant coefficient
(1 − µ − η ) of Eq.5,:

With the above optimization criterion, the optimal vectorial
function F * is achieved when Q ( F ) is minimized:

F * = ( I − µ S a − η S b ) −1 ⋅ Y
∞

= ∑ (η S b + µ S a )iY

(4)

F

= Y + {η S bY + µ S aY } + {η S b (η S bY + µ S aY ) + µ S a (η S bY + µ S aY )} + L

Similarly, the optimal solution for sequential form as Eq. 10 can
be re-written as:

the following optimal vectorial function F * (Linear Form):
(5)

∞

i =0
∞

From the above equations, we can grasp the idea of the proposed
method from a transductive learning point of view. Both F * and
F2* can be regarded as the sum of a series of infinite terms. The
first term is simply the score of initial labels Y , the second term is
to spread the scores of the initial labeled points to their nearby
points by the two graphs; the third term is to further spread and
fuse the scores, and so on. Thus the effect of un-labeled points is
gradually incorporated; and the evidence from two modalities is
fused at each step by weighted sum.

(7)

3.3 Sequential Fusion Scheme
Different from linear scheme, in this scheme, the constraints from
S a , S b and Y are fused sequentially. In this case, we can
formulate the following two-stage optimization problem:
Q1 ( F ) = µ F ( I − S ) F + (1 − µ )( F − Y ) ( F − Y )
T

a

Comparing Eq. 13 and 14, it can be seen that the difference of the
two proposed schemes lies in the ways they propagate and fuse the
similarity by the two graphs. For linear form, the second term in
Eq. 13 is to spread the scores of the initial labeled points to their
nearby points by the two graphs S a and S b respectively, and then
fuse the results by weighted sum; the third term is to further
spread and fuse the scores, and so on. For sequential form, every
item in Eq. 14 denotes 1) spreading initial label Y through S a by
arbitrary steps and then 2) spreading the result through S b by
arbitrary steps.

T

F1* = arg min Q1 ( F )

(8)

F

Q2 ( F ) = η F T ( I − S a ) F + (1 − η )( F − F1* )T ( F − F1* )
F2* = arg min Q2 ( F )

(14)

b i

i =0 j =0

where F (0) = Y
(6)
By a similar analysis as in [30, 31], the relationship between
closed form and iterative form can be given as:
t →∞

j =0

∞

= ∑∑ (η S ) ( µ S a ) j Y

F (t + 1) = µ S a F (t ) + η S b F (t ) + (1 − µ − η )Y

F = lim F (t )

∞

F2* = ∑ (η S b )i ∑ ( µ S a ) jY

Although the closed form is achieved, in some practical cases, the
iterative form might be more preferable. We also develop an
iterative version in Eq. 6:

*

(13)

i =0

Differentiating Q ( F ) defined by Eq. 3 with respect to F leads to
F * = (1 − µ − η )( I − µ S a − η S b ) −1 ⋅ Y

(12)

3.4 Similarity Propagation

Q ( F ) = µ F T ( I − S a ) F + η F T ( I − S b ) F + ε ( F − Y )T ( F − Y ) (3)

F * = arg min Q ( F )

(10)

(9)

F

Eq. 8 (Stage 1) defines an optimal F1* by considering the
constraints from S a and Y ; while Eq. 9 (Stage 2) defines an
optimal F2* by considering the constraints from S b and F1* . The

3.5 Bayesian Interpretation

final classification or retrieval decision can be made based on F2* .

Following [28], we present a Bayesian interpretation for the
proposed schemes. In this way, we will reveal the prior fusion
nature of the proposed schemes. Moreover, we will show that the
difference between linear form and sequential form also comes
from different way they fuse the prior.

a

The trade-off between S and Y is captured by the regularization
parameters µ ; while the trade-off between S b and F1* is captured
by the regularization parameter η , where 0 < µ ,η < 1 .

865

4. GRAPH BASED UN-SUPERVISED
LEARNING IN MULTI-MODALITY

Let P ( F ) denotes the prior probability of F , and P (Y | F ) be
the conditional probability of Y . Then the optimal F estimation
can be given by MAP:

Define S ′ =

*

F = arg max{log( P (Y | F )) + P ( F )}
F

= arg min{− log( P (Y | F )) − P ( F )}

(15)

µSa +ηSb
, and α ′ = µ + η in Eq. 5, the closed form
µ +η

solution for linear form is converted to:

F

F * = (1 − α ′)( I − α ′S ′) −1 Y

As in [28], the conditional probability is assumed as:
P (Y | F ) =

1
2
exp(−ε F − Y )
Z

Similarly,

(16)

we

The prior P ( F ) is also assumed as in [28], except that in multimodality, we have two possible distributions: ( Pa ( F ) from

(17)

∆′ = I −

distribution of P ( F ) .
The first fusion strategy is the same as [8]. (For detailed
discussion for this fusion assumption, refer to [8]):

∆ ′2 = I −

(18)

− ηµ F T ( I − S b )( I − S a ) F + ε F − Y }

= (1 − µ )(1 − η )( I − η S b )( I − µ S a ) −1 Y

µ S a + η S b − µη S b S a
µ + η − µη

(25)

(19)

Algorithm 2 Clustering from multi-modality
(20)

1.

Suppose µ + η − ηµ + ε = 1 , the solution for the above equation is
given as follows:
F * = ε ( I − µ S a − η S b + ηµ S b S a ) −1 Y

(24)

In this paper, the spectral clustering algorithm in [16] is adopted
for clustering task; while Laplacian Eigen-Map in [1] is used for
embedding task. They are briefly summarized in algorithm 2 and
3, respectively.

On the other hand, if we take the following fusion strategy as Eq.
19, and substitute Eq. 16 and Eq. 19 into Eq. 15, we will get the
optimization criteria as Eq 20.

2

µSa +ηSb
µ +η

Note that such similarity learning or Laplacian fusion is actually
independent on the label information Y . Based on this
observation, the proposed algorithm can be further extended to unsupervised learning by feeding the new normalized similarity
matrix or graph Laplacian to some existing spectral methods.

Substituting Eq.16 and Eq. 18 into Eq. 15, will lead to exactly the
same optimization criteria as Eq. 3, based on which linear form as
Eq. 5 can be derived.

F

(23)

and with sequential form as:

P( F ) =

F * = arg min{µ F T ( I − S a ) F + η F T ( I − S b ) F

and

Moreover, in [29], the graph Laplacian is defined as ∆ = I − S .
Thus, the proposed algorithm can be also viewed as graph
Laplacian fusion from multi-modality, with linear form:

By fusing Pa ( F ) and Pb ( F ) properly, we can obtain the final

1 exp{− µ F T ( I − S a ) F − η F T ( I − S b ) F }
Z
exp{− F Tη ( I − S b ) µ ( I − S a ) F }

µ S a + η S b − µη S b S a
µ + η − µη

Both Eq. 22 and 23 have exactly the same form as the original
manifold ranking algorithm [30, 31]. In this way, the proposed
algorithm can be viewed as an extension of manifold ranking
algorithm in terms of new normalized similarity matrix learning.

Pa ( F ) =

1
µ
η
[ Pa ( F )] [ Pb ( F )]
Z
1
= exp{− µ F T ( I − S a ) F − η F T ( I − S b ) F }
Z

S2′ =

F2* = (1 − α 2′ )( I − α 2′ S2′ ) −1 Y

modality a and Pb ( F ) from modality b )

P( F ) =

define

α 2′ = µ + η − µη in Eq. 15, the closed form solution for sequential
form is converted to:

where Z is a normalization constant and ε is a scaling factor.

1
exp{− F T ( I − S a ) F }
Z
1
Pb ( F ) = exp{− F T ( I − S b ) F }
Z

if

(22)

Define
Snew =

µS a + ηS b
µ +η

(linear

form),

µ S a + η S b − µη S b S a
(sequential form);
µ + η − µη

Form the matrix X by staking the k largest eigenvectors of S new : X = [ x1 x2 L xk ] ;

3.

Normalize X so that each row of X has unit length;

4.

Treat each row X of as a data point in R k ; and
cluster them into k clusters using K-means;

5.

Assign the original data point i to class j if and
only if the i th row of X belongs to cluster j

866

or

2.
(21)

Note that this solution is exactly the same as the sequential form
as in Eq. 10. Moreover, Eq. 20 can be viewed as the regularized
optimization criteria for sequential form. In this way, sequential
form actually can be optimized in one stage as linear form.

S new =

can better approximate the perceptual difference between two
images than other popular Minkowski distances when using either
color or texture representation or both [10]:

Algorithm 3 Embedding from multi-modality
new

1.

Define
by Eq. 24 (linear form), or
(sequential form);

Eq. 25

2.

Form the matrix X by staking the k smallest eigenvector of new : X = [ x1 x2 L xk ] ;

3.

Normalize X so that each row of X has unit length;

4.

The embedding of original data point i in Rk is the
i th row of X.

m

l =1

new

xi

xi

}

(i = 1, 2,L , k )

)

(27)

where xil and x jl are the lth dimension of xi and x j respectively;
m is the dimensionality of the feature space; and σ l is a positive
parameter that reflects the scope of different dimensions and is set
to 1 in this paper.

Note that in algorithm 3, we made a modification to the
optimization criteria of the original Eigen-Map algorithm [1] by:
arg min xiT xi =1 { xiT

(

Wij = ∏ exp − xil − x jl σ l

On the other hand, to construct the graph for text modality
(surrounding text for Web image; plain text and in-link anchor
text for Web page), the feature vector is weighted by TF/IDF [7]
and the edge weight is defined by dot product:

(26)

m

Wij = ∑ xil ⋅x jl

5. EXPERIMENTAL RESULTS

(28)

l =1

5.1 Experimental Design

where xil and x jl are the same as in Eq. 27 except that they

Three datasets are used in the experimental evaluation:

represent text feature.

i)

For all learning tasks, the proposed method (LIN for linear form
and SEQ for sequential form) is compared with 1) using modality
a only (AM), 2) using modality b only (BM), 3) using both
modality a and b as one modality (AB-OM).

Web Page. This dataset is a subset of WebKB from [22].
1051 Web pages are classified into two categories: 230
for ‘course’ and 821 for ‘non-course’. Every Web page
is represented by two modalities: plain text (modality a )
and in-link anchor text (modality b ). It has been used
to evaluate the performance of Co-Train [3].

ii)

Corel5000. This dataset consists of 5,000 Corel images.
The images are categorized into 50 groups, each having
100 images. Images belonging to the same group are
considered to be relevant. Every image is represented
by two modalities: pyramid wavelet texture feature [15]
(modality a ) and color histogram [18] (modality b ).

iii)

Web Image. 9046 images are crawled from Web. Every
image is manually annotated by 1 to 3 keywords from a
pre-defined keyword list. There are totally 48 keywords
in the keyword list, including ‘Bear’, ‘Dinosaur’, ‘Orb’,
‘People’, ‘Flower’, ‘Shell’ etc.
Every image is
represented by two modalities: the surrounding text1 of
the given image (modality a ) and a combination of
low-level feature as listed in table 1 (modality b ).

5.2 Experimental Results for Semi-supervised
Learning
Both classification and image retrieval in the scenario of QBK are
evaluated in this part. For both learning tasks, a small portion of
data points are randomly selected from the dataset and manually
labeled. In order to perform a systematic evaluation, we vary the
size of training data, i.e. the number of initial manually labeled
data points, and compare the average classification error or
retrieval accuracy. Considering the randomness of the selection of
initial labels, we run 10 times of labeling and training; and the
average result is recorded.
Note that if sequential form is adopted, we need to determine the
sequence of modality a and modality b (determining using
S b S a or S a S b in Eq. 10). For simplification, we can substitute
1
S b S a in Eq. 10 by ( S b S a + S a S b ) . However, in all of our
2
experiments, we find that this sequence does not change the
comparative results. Since our main concern in this paper is the
comparative performance of the proposed schemas, we simply use
S b S a in Eq. 10 for all the datasets.

Table 1. Feature combination for content modality
Feature Name

Dimension

color histogram [18]

36 Dim.

color correlogram [12]

144 Dim.

Tamura feature [21]

20 Dim.

pyramid wavelet texture feature [15]

24 Dim.

The regularized parameter for label information is fixed at 0.01,
which is the same as in [10]. In this way, there is actually one
remaining regularized parameter µ ( µ + η = 0.99 for linear form
and µ + η − µη = 0.99 for sequential form). A parametric study is
conducted on µ using linear form. The range of µ to achieve
satisfactory performance as well as the final value used in the
experiments for different dataset is listed in table 2. In sequential
form, we use the same value of µ as in linear form for the sake of
simplicity.

To construct the graph from image content modality (low-level
feature for both Corel5000 and Web image), L1 distance is
adopted to define the edge weights in the graph as Eq. 27, since it
1

We use the same method as in [7] to extract the surrounding text
of the given image.

867

Table 2. Parametric study on µ
0.8

Dataset

Satisfactory Range

Final Value
0.7

0.2 ≤ µ ≤ 0.8

µ = 0.5

Corel 5000

0.1 ≤ µ ≤ 0.5

µ = 0.3

0.6

Web Image

0.2 ≤ µ ≤ 0.8

µ = 0.5

0.5

BM

LIN

SER

AB-OM

P20

Web Page

AM

0.4

Dataset i (Web Page) is used to evaluate the classification
performance. The classification error vs. training data curve is
shown in Figure 1. The compared schemes use manifold ranking
algorithm [30] for classification purpose. It can be seen from the
figure that in most cases, using more feature does help to reduce
the classification error. However, when training data size (the
number of initial manually labeled data points) is 5, 65 or 100,
AB-OM can not even beat AM or BM, indicating that using more
feature as one modality actually causes performance deterioration
in these cases. On the other hand, both proposed schemes
outperform the other three in all cases. For example, when using
20 training data, the average classification errors for AB-OM, LIN,
SEQ are 18.6%, 15.3%, 8.1%, respectively. Comparing LIN and
SEQ, it can be seen that sequential form always outperforms linear
form by a large margin.

0.3
0.2
0.1
50

100

200

300

400

500

Number of training data

(a) Corel5000 dataset
0.8
0.7

AM

BM

LIN

SER

AB-OM

0.6
P20

Both Dataset ii and Dataset iii are used to evaluate the retrieval
performance in the scenario of QBK. The average precision of top
20 retrieved images (P20) vs. training data size (the number of
initial manually labeled data points) is shown in Figure 2. The
average precision vs. scope is shown in Figure 3 when training
data size is fixed at 100. The compared schemes use the algorithm
in [20] to build the keyword model. For Corel5000, using two
kinds of feature together always outperforms using only one of
them in all cases. Comparing AB-OM, LIN and SEQ, it can be
seen that treating all feature as two modalities (both LIN and SEQ)
always outperform treating them as one modality (AB-OM), with
SEQ achieving the highest accuracy.

0.5
0.4
0.3
0.2
50

100

200

300

400

500

Number of training data

(b) Web Image dataset

Figure 2 P20 vs. training data size
0.5
0.45

Classification Error

0.4

AM

BM

LIN

SER

For Web Image, it can be seen from Figure 2(b) that treating all
feature as one modality (AB-OM) starts to cause performance
degradation when training dataset size is greater than 200. In all
cases, both the proposed schemes outperform the other three. Unlike in Corel5000, LIN is slightly better than SEQ for Web Image.

AB-OM

0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
5

15

25

35

45

55

65

75

85

95

Training data size

Figure 1. Systematic comparison of classification error
under different sizes of training data

868

(MI) are used for performance evaluation.
discussion of AC and MI, refer to [27].)
0.5

AM

BM

LIN

SER

AB-OM
0.9

0.4

AM

0.8
0.3
Clustering Accuracy

Precision

(For detailed

0.2

0.1

BM

AB-OM

LIN

SER

0.7
0.6
0.5
0.4

0
10

20

30

40

50

60

70

80

90

0.3

100

Scope

0.2
0.1

(a) Corel5000 dataset

0.3

0.5

0.7

0.9

The value of regularized parameter

(a) Accuracy
0.6

AM

BM

LIN

SER

0.016

AB-OM

0.014

AM

BM

AB-OM

LIN

SER

0.5
Clustering Accuracy

Precision

0.012
0.4

0.3

0.2

0.01
0.008
0.006
0.004
0.002

0.1
10

20

30

40

50

60

70

80

90

100

0

Scope

0.1

0.3

0.5

0.7

0.9

The value of regularized parameter

(b) Web Image dataset
(b) Normalized mutual information

Figure 3 Precision vs. scope when training data size is 100

Figure 4. Clustering result vs. regularized parameter µ

5.3 Experimental Results for Un-supervised
Learning

The results vs. the regularized parameter µ are shown in Figure 4.
It can be seen from the figure that using two kinds of feature
together always outperforms using only one of them in all cases.
For accuracy, both LIN and SEQ outperform using two kinds of
feature as one modality (AB-OM) when 0.1 ≤ µ ≤ 0.7 . For
normalized mutual information, while SEQ outperforms AB-OM
when 0.1 ≤ µ ≤ 0.5 , LIN remains best in all situations.

Both clustering and embedding are evaluated in this part. When
sequential form is adopted, the normalized similarity matrix or
graph Laplacian might not be symmetrical. To address this issue,
we add a pre-processing step in Algorithm 2 and 3:
1
S new ← [ S new + ( S new )T ]
2
1 new
new
← [
+( new )T ]
2

Dataset ii is used to evaluate embedding performance. The
regularized parameter µ is set to 0.5 for both LIN and SEQ.
After embedding by Algorithm 3, the image is indexed by its
embedding. Then, we use each image in the database as a query,
and average the results over the 5,000 queries. The precision vs.
scope curve for different schemes when embedding dimension is
set 10 and 100 is shown in Figure 6. Again, the proposed two
schemes outperform the other three. For example, when the
embedding dimension is fixed at 10, using only color feature or
texture feature, P20 is 6.15% (AM) and 11.3% (BM), respectively;
using color feature and texture feature as one modality, P20 is

(29)

2 classes are randomly selected form the Dataset ii dataset and
fed into Algorithm 2. To perform a systematic evaluation, we run
selecting and clustering 20 times and the average result is recorded.
The compared schemes are fed into spectral clustering algorithm
[16]. For all clustering algorithms, the reduced dimension (such
as k in algorithm 2) is empirically set equal to the cluster number.
As in [27], the accuracy (AC) and normalized mutual information

869

13.2% (AB-OM); while P20 is 16.5% and 16.8% for LIN and
SEQ, respectively.

performance with some existing multi-modality
algorithms, such as Co-Train, super-kernel etc.

7. REFERENCES

0.25

Precision

0.2

AM

BM

LIN

SER

[1] Belkin, M., and Niyogi, P. Laplacian Eigenmaps and spectral
techniques for embedding and clustering. Neural
Computation, pp. 1373-1396, 2003.

AB-OM

[2] Bickel, S., and Scheffer, T. Multi-view clustering. Proc. of
Int. Conf. on Data Mining, pp. 19-26, 2004.

0.15

[3] Blum, A., and Mitchell, T. Combining labeled and unlabeled
data with Co-Training. Proc. of the Conf. on Computational
Learning Theory, pp. 92-100, 1998.

0.1

0.05

[4] Cai, D., He, X., Li, Z., Ma, W.Y., and Wen, J.R. Hierarchical
clustering of WWW image search results using visual, textual
and link information. Proc. of the ACM Conf. on Information
Retrieval, pp. 952-959, 2004.

0
10

20

30

40

50

60

70

80

90

100

Scope

[5] Cascia, M.L., Sethi, S., and Sclaroff, S. Combining textural
and visual cues for content-based image retrieval on the
world wide web. IEEE Workshop on Content-based Access of
Image and Video Libaries, pp. 24-28, 1998.

(a) Embedding dimension is set 10
0.25
0.23

AM

BM

0.21

LIN

SER

[6] Dupont, S., and Luettin, J. Audio-visual speech modeling for
continuous speech recognition. IEEE Trans. on Multimedia,
2(3): 141-151, 2000.

AB-OM

0.19
Precision

learning

[7] Feng, H., Shi, R., and Chua, T.S. A bootstrapping framework
for annotating and retrieving WWW images. Proc. of the
ACM Int. Conf. on Multimedia, pp. 960-967, 2004.

0.17
0.15
0.13

[8] Garg, A., Potamianos, G., Neti, C., and Huang, T.S. Framedependent multi-stream reliability indications for audiovisual speech recognition, Proc. of Int. Conf. on Acoustics,
Speech and Signal Processing, vol. 1, pp. 24-27, 2003.

0.11
0.09
0.07

[9] Ghani, R. Combining labeled and unlabeled data multi-class
text categorization. Proc. of the Intl. Conf. on Machine
Learning, pp. 187-194, 2002.

0.05
10

20

30

40

50

60

70

80

90

100

Scope

[10] He, J., Li, M., Zhang, H.J., Tong, H., and Zhang, C. Manifold
ranking based image retrieval. Proc. of the ACM Conf. on
Information Retrieval, pp. 9-16, 2004.

(b) Embedding dimension is set 50

Figure 5. Precision vs. scope for Corel5000 embedding

[11] Heckmann, M., Berthommier, F., and Kroschel, K. Noise
adaptive stream weighting in audio-visual speech recognition,
EURASIP Journal on Applied Signal Process, pp. 1260-1273,
2002.

6. CONCLUSION
In this paper, we have made an investigation on graph-based
learning methods in terms of their extension in multi-modality.
For semi-supervised learning, two different fusion schemes, linear
form and sequential form, are proposed. For each scheme, it is
derived from optimization point of view and further justified from
two sides: similarity propagation and Bayesian interpretation. By
doing so, we reveal the regular optimization nature, transductive
learning nature as well as prior fusion nature of the proposed
schemes, respectively. Also, we show that the difference between
the two schemes actually comes form 1) the different optimization
strategy they adopt; 2) the different manner they spread and fuse
similarity through graphs; and 3) the different way they fuse the
prior probability. Moreover, the proposed method can be easily
extended to unsupervised learning, including clustering and
embedding. The effectiveness of the proposed method is justified
by systematic experiments. In further work, we will 1) explore the
working conditions of the two proposed schemes from a
theoretical point of view; 2) investigate a more principled way to
determine the regularized parameter; and 3) compare its

[12] Huang, J., Kumar, S.R., Mitra, M., Zhu, W.J., and Zabih, R.
Image indexing using color correlograms. Proc. IEEE Conf.
on Computer Vision and Pattern Recognition, pp. 762-768,
1997.
[13] Kailing, K., Kriegel, H., Pryakhin, A., and Schubert, M.
Clustering multi-represented objects with noise. Proc. of the
Pacific-Asia Conf. on Knowledge Discovery and Data
Mining, pp. 394-403, 2004.
[14] Kittler, J., Hatef, M., and Duin, R.P.W. Combining classifiers.
Pattern Recognition, pp. 897-901, 1996.
[15] Mallat, S.G., A theory for multiresolution signal
decomposition: the wavelet representation. IEEE Trans. on
Pattern Analysis and Machine Intelligence, vol. 11, no. 7, pp.
674-693, 1989.
[16] Ng, A.Y., Jordan, M.I., and Weiss, Y. On spectral clustering:

870

analysis and an algorithm. Advances in Neural Information
Processing Systems, 2001.

[25] Yan, R., and Hauptmann, A.G. The combination limit in
multimedia retrieval. Proc. of the ACM Int. Conf. on
Multimedia, pp. 339-342, 2003.

[17] Nigam, K., and Ghani, R. Analyzing the effectiveness and
applicability of Co-Training. Proc. of Information and
Knowledge Management, pp. 86-93, 2000

[26] Yi, X. Zhang, C, and Wang, J. Multi-view EM algorithm and
its application to color image segmentation. IEEE Int. Conf.
on Multimedia and Expo, pp. 351-354, 2004.

[18] Swain, M., and Ballard, D. Color indexing. Int. Journal of
Computer Vision, 7(1): 11-32, 1991.

[27] Zheng, X., Cai, D., He, X., Ma, W.Y., and Lin, X. Locality
preserving clustering for image database. Proc. of the ACM
Conf. on Information Retrieval, pp. 885-891, 2004.

[19] Suen, C.Y., and Lam, L. Multiple classifier combination
methodologies for different output level. Proc. of the First Int.
Workshop on Multiple Classifier, pp. 52-66, 2000.

[28] Zhou, D., and Schölkopf, B. A regularization framework for
learning from graph data. Workshop on Statistical Relational
Learning at Int. Conf. on Machine Learning, pp. 132-137,
2004.

[20] Reference removed for double-blind review
[21] Tamura, H., Mori, S., and Yamawaki, T. Textural features
corresponding to visual perception. IEEE Trans. on Systems.,
Man and Cybernetics, pp. 460-472, 1978.

[29] Zhou, D., and Schölkopf, B. Transductive Inference with
Graphs. MPI Technical Report , 2004.

[22] The WebKB dataset.
http://meganesia.int.gu.edu.au/~phmartin/WebKB/.

[30] Zhou, D., Bousquet, O., Lal, T.N., Weston, J., and
Schölkopf, B. Learning with local and global consistency.
18th Annual Conf. on Neural Information Processing
Systems, pp. 237-244, 2003.

[23] Wang, J., Zeng, H., Chen, Z., Lu, H., Tao, L., and Ma. W.Y.
Recom: reinforcement clustering of multi-type interrelated
data objects. Proc. of the ACM Conf. on Information
Retrieval, pp. 274-281, 2003.

[31] Zhou, D., Bousquet, O., Lal, T.N., Weston, J., and
Schölkopf, B. Ranking on data manifolds. 18th Annual Conf.
on Neural Information Processing System, pp. 169-176,
2003.

[24] Wu, Y., Chang, E.Y., Chang, K.C.C., and Smith, J.R.
Optimal multimodal fusion for multimedia data analysis.
Proc. of the ACM Int. Conf. on Multimedia, pp. 572-579,
2004.

871

Data Min Knowl Disc (2017) 31:400–423
DOI 10.1007/s10618-016-0478-6

Discovering rare categories from graph streams
Dawei Zhou1 · Arun Karthikeyan1 ·
Kangyang Wang1 · Nan Cao2 · Jingrui He1

Received: 6 May 2016 / Accepted: 13 September 2016 / Published online: 28 September 2016
© The Author(s) 2016

Abstract Nowadays, massive graph streams are produced from various real-world
applications, such as financial fraud detection, sensor networks, wireless networks. In
contrast to the high volume of data, it is usually the case that only a small percentage
of nodes within the time-evolving graphs might be of interest to people. Rare category
detection (RCD) is an important topic in data mining, focusing on identifying the
initial examples from the rare classes in imbalanced data sets. However, most existing
techniques for RCD are designed for static data sets, thus not suitable for time-evolving
data. In this paper, we introduce a novel setting of RCD on time-evolving graphs. To
address this problem, we propose two incremental algorithms, SIRD and BIRD, which
are constructed upon existing density-based techniques for RCD. These algorithms
exploit the time-evolving nature of the data by dynamically updating the detection
models enabling a “time-flexible” RCD. Moreover, to deal with the cases where the
exact priors of the minority classes are not available, we further propose a modified
version named BIRD-LI based on BIRD. Besides, we also identify a critical task in
RCD named query distribution, which targets to allocate the limited budget among
multiple time steps, such that the initial examples from the rare classes are detected
as early as possible with the minimum labeling cost. The proposed incremental RCD
algorithms and various query distribution strategies are evaluated empirically on both
synthetic and real data sets.
Keywords Rare category detection · Time-evolving graph · Incremental learning

Responsible editor: Jian Pei.

B

Dawei Zhou
dzhou23@asu.com

1

CIDSE, Arizona State University, Tempe, AZ 85281, USA

2

New York University Shanghai, Shanghai 200122, China

123

Discovering rare categories from graph streams

401

1 Introduction
Compared with the tremendous and rapidly changing data, the examples of interest to
us only hold a very small portion. For instance, in financial synthetic identity detection (Phua et al. 2010), only a tiny proportion of identities are fraudulent, generated by
mixing the identifying information from multiple sources. Such identities are created
with the sole purpose of committing financial fraud. Another example is insider threat
detection (Eberle et al. 2010), where only a small population amongst a big organization are malicious insiders involved in treacherous behaviors, such as sabotage,
espionage, etc. The small percentage of data of interest to us is called the minority
class or rare category, since such examples are often self-similar. Due to the rarity of
the minority classes and the limited budget on querying the labeling oracle who can
provide the true label of any example at a fixed cost, it is difficult to identify examples
from such classes via random sampling. To efficiently deal with this problem, rare
category detection (RCD) has been proposed to identify the very first example from
the minority class, by requesting only a small number of labels from the oracle (Pelleg
and Moore 2004).
Most, if not all, of existing RCD techniques are designed for static data. However,
in many real-world applications, the data is not static but evolves with time, and so
are the minority classes. Examples of such scenarios are listed as follows.
– In financial synthetic identity detection, within the transaction network, each identity could correspond to one specific node, and each transaction activity could
correspond to one edge. Since each identity may keep updating his or her information, such as daily transactions and real-time online banking activities, the data
is evolving over time. Our goal is to identify the identities and transactions, which
have unusual characteristics and significantly differ from the majorities in the
networks.
– In insider threat detection, the insiders intentionally change their behavior patterns
over time to avoid being caught. In other words, the insiders may not be abnormal
all the time when compared with normal employees. Thus, how to distinguish
insiders and normal employees from evolving data is a challenge.
– In event detection in social networks, the snapshots of social networks are evolving
every single second with updated vertex sets and updated edge sets, which means
the event related vertex sets may shrink, expand or shift within the time-evolving
social networks. Hence, how to model, capture and track the changing target events
over evolving social networks would be the main task.
Straight-forward applications of existing RCD techniques in the preceding scenarios would be very time-consuming by constructing the models from scratches at each
time step. Additionally, it is critical to allocate queries among different time steps from
labeling oracle, which may help detect the initial rare examples as early as possible to
avoid further damage.
Addressing this issue, in this paper, for the first time, we study the problem of incremental RCD. Specifically, we first propose two incremental algorithms, i.e., SIRD and
BIRD, to detect the initial examples from the minority classes under different dynamic
settings. The key idea is to efficiently update our detection model by local changes

123

402

D. Zhou et al.

instead of reconstructing it from scratches based on the updated data at a new time
step, so as to reduce the time cost of redundant and repeating computations. Furthermore, we relax the requirement of the exact priors with a soft upper bound for all the
minority classes to provide a modified version—BIRD-LI. Finally, we study a unique
problem of query distribution under the dynamic settings, which distributes allocated
labeling budget among different time steps, and propose five query distribution strategies. This paper is extended from our previous work (Zhou et al. 2015b) in terms of
the detailed algorithm, theoretical justification and the comprehensive experiments on
real time-evolving graph data sets.
The rest of our paper is organized as follows. In Sect. 2, we briefly review the
related work on both RCD and time-evolving graph mining. In Sect. 3, we study
incremental RCD and propose three algorithms, i.e., SIRD, BIRD and BIRD-LI, to
address different dynamic settings. Then, in Sect. 4, we introduce the unique problem of
query distribution under the dynamic settings, and propose five strategies for allocating
the labeling budget among different time steps. In Sect. 5, we demonstrate our models
on both synthetic and real data sets. Finally, we conclude this paper in Sect. 6.

2 Related work
2.1 Rare category analysis
RCD refers to the problem of identifying the initial examples from under-represented
minority classes in an imbalanced data set. Lots of techniques have been developed for
solving the problem of RCD in the past decade. Pelleg and Moore (2004) proposed
a mixture model-based algorithm, which is the first attempt in this area. In He and
Carbonell (2007) and He et al. (2008), the authors developed an innovative method
to detect rare categories via unsupervised local-density-differential sampling strategy.
Dasgupta and Hsu (2008) presented an active learning scheme via exploiting the cluster
structure in data sets. In He et al. (2010), the authors introduced a novel problem called
rare category characterization, which not only detects but also characterizes the rare
categories, and proposed an optimization framework to explore the compactness of rare
categories. More recently, in Liu et al. (2014), two prior-free methods were proposed
in order to address the RCD problem without any prior knowledge. In Zhou et al.
(2015a), the authors proposed a framework named MUVIR, which could leverage
existing RCD models on each single view and estimate the overall probability of each
example belonging to the minority classes. However, all of the preceding works focus
on the static data sets, and few works have been proposed to address the problem of
RCD under dynamic settings.
2.2 Outlier detection on streaming data
With the improvement of hardware technology on data collection, many applications
require efficient mechanisms to process the outlier detection on streaming data (Gupta
et al. 2014). Tons of algorithms have been proposed in the past decade. Yamanishi
and Takeuchi (2002) and Yamanishi et al. (2004) presented an online discounting

123

Discovering rare categories from graph streams

403

learning algorithm to incrementally update a probabilistic mixture model and capture
outliers in data streams. In Aggarwal and Philip (2010), the authors proposed online
clustering methods, which maintained a dynamic clustering model to identify outliers
under dynamic settings. Instead of only updating parameters of the prediction model,
dynamic Bayesian network (Hill et al. 2007), a modifiable model, was proposed to
detect anomalies from environmental sensor data. Different from regular data streams,
distributed data streams are collected from distributed sensors over time. Bettencourt
et al. (2007) and Franke and Gertz (2008) studied the problem of outlier detection
on multiple types of distributed data streams, such as air temperature sensor network
data, water pollution sensor network data and wind sensor network data. Different
from outlier detection, rare category detection assumes that the anomalies belong
to multiple distinct classes, in the sense that the within-class similarities are much
larger than the between-class similarities. In this paper, we aim to discover these rare
categories over a series of time-evolving graphs.

2.3 Graph based anomaly detection
In the literature, there are abundant works focusing on anomaly detection in static
graphs. Basically, all of the existing works study two types of static graphs: plain
static graphs and attributed static graphs. Plain graph assumes the only information
we have is the structure of graph. This category of anomaly detection methods aims to
exploit the structure of graphs and mine the unrepresentative pattern of anomalies, e.g.,
global graph structure methods (Kang et al. 2010; Henderson et al. 2010); local graph
structure methods (Akoglu et al. 2010; Kang et al. 2011; Gupte and Eliassi-Rad 2012).
Attributed graph assumes both the structure and the coherence of attributes are given.
Müller et al. (2013) and Gao et al. (2010) proposed node outlier ranking methods
on static attributed graphs. Yagada Davis et al. (2011) characterized anomalies by
discrediting the numerical attributes into “outlier score”. In Sricharan and Das (2014),
the authors proposed a fast algorithm which could detect the node relationships for
localizing anomalous changes in time-evolving graphs.
More recently, an increasing number of research has been conducted under dynamic
graph settings. For examples, in Leskovec et al. (2005), the authors analyzed the properties of the time evolution of real graphs and proposed a “forest fire” graph-generative
model; Backstrom et al. (2006) studied the problem of community evolution and developed a novel method to measure the movement of individuals among communities;
in Kumar et al. (2010), the authors focused on the difficulties of conversation dynamics
and proposed a simple mathematical model in order to generate basic conversation
structures; in Berlingerio et al. (2012) and Koutra et al. (2011), the authors proposed
several graph similarity measurements to detect the discontinuity in dynamic social
networks. Besides, to reduce the time complexity, in Tong et al. (2008), the authors proposed a fast proximity tracking method for dynamic graphs; in Koutra et al. (2012),
the authors used tensor decomposition techniques to efficiently obtain the “scores”
for anomalies on dynamic graphs; in Fan et al. (2013), the authors proposed a new
graph-pattern matching algorithm, which can avoid cubic-time computation; Akoglu
et al. (2014) raised a divide-and-conquer framework, which could find the k-nearest-

123

404

D. Zhou et al.

Fig. 1 Incremental rare category detection

neighbors efficiently on high volume of time-evolving graphs. BIRD approach (Zhou
et al. 2015b) provided a fast updating method for the challenging problem of RCD on
time-evolving graphs. In this paper, we propose several fast-updating RCD methods
which could incrementally update the models based on local changes on time-evolving
graphs. This paper extends our previous work (Zhou et al. 2015b) substantially by providing the detailed algorithm, theoretical justification and the comprehensive empirical
evaluations on real-world time-evolving graph data sets, which are not presented in
the previous version.

3 Incremental rare category detection
In this section, we introduce the proposed framework of incremental RCD. Our methods exploit the time-evolving nature of dynamic graphs and update the RCD model
incrementally based on the local updates from time to time. To the best of our knowledge, existing RCD methods are all designed for static data sets, while we target a more
challenging setting, in which the data is presented as time-evolving graphs. Notice that
we allow the support regions of the majority and minority classes to overlap with each
other in the feature space, which makes our algorithm widely applicable to a variety
of real-world problems.
3.1 Notation
Suppose we are given a series of time-evolving graphs {S (1) , . . . , S (T ) }, which are
shown in Fig. 1. For any time step t = 1, . . . , T , the vertices in S (t) are identical and
(t)
only edges change over time. We assume yi = 1 corresponds to the majority class
(t)
(t)
with prior p1 , and the remaining classes are the minority classes with priors pc at
time step t. We use S (t) to denote the new edges and updated weights that appear at
time step t. Specifically, we have S (t) = S (t) − S (t−1) .
In the following part of this paper, we use the convention in Matlab to represent
matrix elements, e.g., S (t) (i, j) is the element at ith row and the jth column of matrix
S (t) , and S (t) (:, j) is the jth column of matrix S (t) , etc. The main symbols we used in
this paper are listed in Table 1.

123

Discovering rare categories from graph streams
Table 1 Symbols

Symbol

405
Description

n

Number of nodes

m (t)

Number of updated edges

xi

ith nodes in data set

t

Time step

C

Number of classes

(t)
pc

Proportion of classes c

α

Constraint parameter

I

Identity matrix

S (t)

n × n original aggregated adjacency matrix at time t

S (t)

n × n updating matrix for S (t−1)

M (t)

Normalized n × n aggregated adjacency matrix at time t

M (t)

n × n updating matrix for M (t−1)

N N (t)

n × n neighbor information matrix at time step t

A(t)

n × n global similarity matrix at time step t

3.2 Static rare category detection
In static RCD, we repeatedly select examples to be labeled by the oracle until all the
minority classes in a static data set are discovered. One approach for static RCD is to
make use of the manifold structure for identifying rare category examples. In He et al.
(2008), authors developed a graph-based RCD method named GRADE. In GRADE
algorithm, they first construct a pair-wise similarity matrix W  and its corresponding
diagonal matrix D, whose elements are the row sums of W  . Then, they calculate the
normalized matrix W as follows.
W = D −1/2 W  D −1/2
Based on the normalized pair-wise similarity matrix W , they construct a global similarity matrix A as follows.
A = (In×n − αW )−1

(1)

where α is a small enough positive discounting constant in the range of (0, 1). By
constructing the global similarity matrix, the changes of local density would become
sharper near the boundary of the minority classes. Based on this intuition, GRADE
could identify minority classes with much fewer queries than random sampling. However, the time complexity of calculating the global similarity matrix and finding each
example’s (K )th nearest neighbor is O(n 3 + K · n 2 ), which is not efficient enough
for time-evolving RCD applications.

123

406

D. Zhou et al.

3.3 Dynamic rare category detection
In this subsection, we introduce two fast-updating incremental RCD algorithms (SIRD
and BIRD) to deal with the RCD problem on time-evolving graphs. Both methods
greatly reduce the computation cost for updating the global similarity matrix and
finding each node’s K th nearest neighbor. Similar to static rare category detection,
we target the challenging case where the minority classes are not separable from the
majority classes.
3.3.1 Single update
We first consider the simplest case: only one self-loop edge (a, a) changes at time step
t. In other words, there is only one non-zero element (a, a) in S (t) . Similar to He et al.
(2008), we use M (t) to denote the normalized aggregated adjacency matrix, which is
defined as follows.
M (t) = (D (t) )−1/2 S (t) (D (t) )−1/2

(2)

Besides, let M (t) denote the updating matrix for M (t) , such as M (t) = M (t) −
M (t−1) . Clearly, there is also only one non-zero element existing in M (t) . Hence,
M (t) could be easily decomposed into the product of two column vectors uv T ,
where u and v are two column vectors with only one non-zero element. To address
this problem, we first introduce Theorem 1 to update the global similarity matrix A(t)
more efficiently.
Theorem 1 The global similarity matrix A(t) at time step t can be exactly updated
from global similarity matrix A(t−1) at the previous time step t − 1 by the following
equation:
A(t) = A(t−1) + α

A(t−1) uv T A(t−1)
I + v T A(t−1) u

where u and v T are the two vectors decomposed from updating matrix M (t)
Proof Suppose there is only one edge updated at time step t, and we have M (t) =
uv T . Thus, Eq. (1) could be rewritten as follows.
−1

A(t) = I − α M (t)
−1

= I − α M (t−1) − αM (t)
−1

= I − α M (t−1) − αuv T

(3)

By applying the Sherman–Morrison Lemma (Sherman and Morrison 1950), we have
A(t) = A(t−1) + α

123

A(t−1) uv T A(t−1)
I + v T A(t−1) u

(4)

Discovering rare categories from graph streams

407

Hence, the global similarity matrix A(t) in our Algorithm 1 could be exactly updated
at each time step.


In Theorem 1, we can see column vectors u and v are essential for updating the
global similarity matrix A(t) . To reduce the computational complexity, in Algorithm
1, we use an approximate method to calculate the two column vectors u and v. The
details are described as follows. We first assume that the updated edges at time step t
have little impact on the row sum of adjacency matrix S (t) when the number of updated
edges is extremely smaller than the total number of edges. Thus, we have
D (t) ∼
= D (t−1)
To normalize aggregated adjacency matrix of S (t) and S (t−1) , we have
−1/2

−1/2

S (t) D (t)
M (t) = D (t)
−1/2

−1/2

M (t−1) = D (t)
S (t−1) D (t−1)

(5)
(6)

By Eqs. (5, 6), we have
−1/2

−1/2

M (t) = D (t−1)
S (t) D (t−1)

(7)

As
M (t)
=
uv T ,
we
could
easily
assign
−1/2
(t)
and v = S (a, b)D(:, b)−1/2 .
u = D(:, a)
Besides, as the time complexity of constructing a new neighbor information matrix
N N (t) is O(K (t) · n 2 ), we introduce Theorem 2 to efficiently update N N (t) .
Theorem 2 Suppose there is only one self loop edge (a, a) being updated at time step
t. If it satisfies the condition that

I +v T

α
A(t−1) u

≤

N N (t) (i, :) are the same as N N (t−1) (i, :).

(t−1)

δi

(t−1)
Ai,a φa

, the first K (t) elements in

Proof Based on Theorem 1, we have
A(t−1) uv T A(t−1)
I + v T A(t−1) u
A(t−1) M (t) A(t−1)
= A(t−1) + α
I + v T A(t−1) u

A(t) = A(t−1) + α

(8)

Since u and v are column vectors that contain only one non-zero element, then I +
v T A(t−1) u is a constant value, which means it is just a scalar and will not change the
order of elements in N N (t) .
From Eq. (8) we also have the updating rule for each element (i, j) in A(t)
(t)

(t−1)

Ai, j = Ai, j

(t−1)

+ β Ai,a

(t−1)

Aa, j

(9)

123

408

D. Zhou et al.

α
is also a constant.
I +v T A(t−1) u

(t) 
(t−1)
K
Let δi
= min j=1 N N (t−1) (i, j) − N N (t−1) (i, j + 1) denote the smallest
adjacent difference among the first K (t) elements in the ith row of N N (t−1) , and

where β =

φa = N N t−1 (a, 1) denote the largest element in row a. Intuitively, as long as the
(t−1) (t−1)
Aa, j is smaller than the smallest adjacent gap between any
largest value of β Ai,a
(t)
of the first K nodes in the ith row of N N (t) , we can claim that the order of these
sorted K (t) nodes will not change. Therefore, based on Eq. (9), if the condition satisfies
(t−1)

δi
α
≤ (t−1)
T
(t−1)
I +v A
u
Ai,a φa
we can claim that the first K (t) elements in N N (t) (i, :) will not change.

(10)



Based on Theorem 2, we can identify the rows of N N (t) , in which the order of the
largest elements will not change. Thus, we only need to update the disordered
rows in N N (t) .
The single-updated incremental RCD algorithm (SIRD) is shown in Algorithm 1.
In Step 1 to Step 2, we first initialize the diagonal matrix D and neighbor information
matrix N N (1) at time step 1. In Step 4, let K (t) represent the number of nodes in the
largest minority class at time step t. Then, from Step 5 to Step 6, we update the global
similarity matrix at each time step. Step 7 to Step 9 updates the rows in N N (t) , of
which the K (t) largest elements are changed. Step 11–20 is the query process. First of
all, we calculate the class specific a c at Step 13, which is the largest global similarity
to the kc(th) nearest neighbor. Then, in Step 14, we count the number of its neighbors
whose global similarity is larger than or equal to a c , and let n ic denote the counts for
each node xi . In Step 16, we calculate the score of each node xi , which represents the
change of local density. At last, we select the nodes with the largest score and let them
be labeled by oracle. The query process only terminates as long as all the minority
classes are discovered.
The efficiency of the updating process for Algorithm 1 is given by the following
lemma.
K (t)

Lemma 1 The computational cost of the updating process at each time step in Algorithm 1 is O(n 2 + l · K (t) · n).
Proof As described before, the computational cost for normalization and decomposition process is O(n). Then, in Step 6, compared to the straightforward computation,
i.e., A(t−1) = (I − α M (t) )−1 , we reduce the time complexity from O(n 3 ) to O(n 2 )
by avoiding the matrix inverse computation. Furthermore, from Step 7 to Step 9, we
simplify the resorting process by only updating the rows, in which the top K (t) elements are disordered. Suppose l is the total number of rows in N N (t), which does

not satisfy Eq. (10), then the computational cost is reduced from O K (t) · n 2 to


O l · K (t) · n . By leveraging each part, the computational cost of the updating process




is O n 2 + l · K (t) · n .

123

Discovering rare categories from graph streams

409

ALGORITHM 1: SIRD Algorithm
(t)

Input: M (1) , A(1) , S (2) , . . . , S (T ) , pc , α.
Output: The set I of labeled nodes

1: Construct the n × n diagonal matrix D, where Dii = n( j=1) S (1) , i = 1, . . . , n.

2: Sort row i of A(1) decreasingly and save into N N (1) (i, :), where i = 1, . . . , n.
3: for t=2:T do
(t)
4: Let K (t) = maxC
c=2 n × pc .
5: Let column vector u = D(:, a)−1/2 , and column vector v = S (t) (a, a)D(:, a)−1/2 , where
S (t) (a, a) is the non-zero element in S (t) .
6: Update the global similarity matrix as follows.
A(t) = A(t−1) + α
7:
8:

9:
10:
11:
12:
13:
14:
15:
16:

A(t−1) uv T A(t−1)
I + v T A(t−1) u

for i=1:n do
Based on Theorem 2, identify whether the first K (t) elements of N N (t) (i,:) are changed. If
true, update the first K (t) elements in N N (t) (i, :); otherwise, let N N (t) (i, :) = N N (t−1) (i, :).
end for
end for
for c = 2:C do
(T )
Let kc = n × pc
Find the first kc elements in each row of N N (T ) . Set a c to be the largest value of them.
Let K N N c (xi , a c ) = {x|N N (T ) (i, j) > a c }, and n ic = |K N N c |, where i = 1, . . . , n and
j = 1, . . . , n.
for index = 1: n do
For each node xi has been labeled yi , if A(T ) > a yi , scor e j = −∞; else, let scor ei =
c
c
max (T )
a c (n i − n j )
A

(i, j)> index

17:
Select the nodes x with the largest score to labeling oracle.
18:
If the label of x is exact class c, break; else, mark the class that x belongs to as discovered.
19: end for
20: end for

3.3.2 Batch update
In most real world applications, we always observe that a batch of edges change at
the same period. Specifically, the updated aggregated adjacency matrix M (t) may
have more than one non-zero element. Hence, M (t) cannot be decomposed into two
column vectors, and Theorem 2 could not be applied in this condition. In this part, we
introduce Theorem 3 to help us update the neighbor information matrix N N (t) when
a batch of edges are changed.
Theorem 3 Suppose there are m edges {(a 1 , b1 ), . . . , (a m , bm )} being updated at
time step t. The first K (t) elements in N N (t) (i, :) are the same as N N (t−1) (i, :), if it
satisfies the condition that
I+
	
where Ti = min

(t−1)

δi

A

(t−1)
φbi
i,a i

,

α
≤ min {Ti }
i=1,...,m
A(t−1) U

VT

(t−1)

δi

A

(t−1)
φa i
i,bi



.

123

410

D. Zhou et al.

Proof Since the aggregated adjacency matrix M (t) is a symmetric matrix, then, each
element (a, b), where a 	= b, has a symmetrical element (b, a) in M (t) .
When the two edges (a, b) and (b, a) are updated at time step t, we have M (t) =
(t)
(t)
(t)
(t)
M1 + M2 , where M1 has only one non-zero element (a, b), and M2 has
only one non-zero element (b, a). Similar to Eq. (8), we have an approximate updating
rule as follows.
(t)

A(t−1) M1 A(t−1)
A(t) ∼
= A(t−1) + α
I + (v (1) )T A(t−1) u (1)
+α

A(t−1) M2(t) A(t−1)
I + (u (1) )T A(t−1) v (1)

(11)

where M1(t) = u (1) (v (1) )T , M2(t) = v (1) (u (1) )T and u (1) , v (1) are two column
vectors.
Besides, we also have


(t)
(t)
A(t) = A(t−1) + β A(t−1) M1 A(t−1) + A(t−1) M2 A(t−1)
α
, and β is a constant.
I +(v (1) )T A(t−1) u (1)
(t)
(t−1)
(t−1) (t−1)
(t−1) (t−1)
Therefore, Ai, j = Ai, j + β Ai,a Ab, j + β Ai,b Aa, j .
Based on Theorem 2, we can claim that the largest K (t) elements

where β =

in N N (t) (i, :)

will not change, if it satisfies

	
where T1 = min

(t−1)
δi
(t−1)
A 1 φb1
i,a

α
≤ T1
I + V T A(t−1) U



,

(t−1)
δi
(t−1)
A 1 φa 1
i,b

(12)

.

Similarly, when there are m (t) pairs of edges being updated at time step t, we can
claim that if it satisfies
m (t)
α
min
{Tm }
(13)
≤
m=1
I + V T A(t−1) U

 (t−1)
(t−1)
δi
δi
, then the first K (t) elements in N N (t) (i, :) will
where Tm = min (t−1)
, (t−1)
Ai,a c φbc

not change.

Ai,bc φa c




The Batch-update Incremental RCD (BIRD) algorithm is shown in Algorithm 2.
Step 1 and Step 2 are the initialization step. Step 3 to Step 12 updates the global
similarity matrix A(t) and the neighbor information matrix N N (t) . Different from
Algorithm 1, Step 5 to Step 8 iteratively updates the global similarity matrix A(t)
based on m (t) changed edges. Another difference is that, in Step 10, T is the minimum
value of the thresholds calculated from m (t) updated edges. At last, Step 13 to Step 20
is the query process, which is the same as what we have described in Algorithm 1.
The efficiency of batch-edges updating in Algorithm 2 is proved by the following
lemma.

123

Discovering rare categories from graph streams

411

Lemma 2 In Algorithm 2, the computational cost of the updating process at each
time step is O(m (t) n 2 + l · K (t) · n).
Proof Different from Algorithm 1, in Algorithm 2, we have m (t) updated edges at
time step t. We need to update the global similarity matrix A(t) for m (t) times. Thus,
the computation cost of updating the global similarity matrix is O(m (t) n 2 ). Let l be
the number of rows in N N (t) , which do not satisfy Eq. (13). For updating these rows in
N N (t) , the computational complexity is O(l · K (t) · n). Thus, in total, the computation


cost of updating process at each time step is O(m (t) n 2 + l · K (t) · n).
ALGORITHM 2: BIRD algorithm
(t)

Input: M (1) , A(1) , S (2) , . . . , S (T ) , pc , α.
Output: The set I of labeled nodes

1: Construct the n × n diagonal matrix D, where Dii = n( j=1) S (1) , i = 1, . . . , n.

2: Sort row i of A(1) decreasingly and save into N N (1) (i, :), where i = 1, . . . , n.
3: for t=2:T do
C n × p (t) .
4: Let K (t) = maxl=c
c
(t)
5: for m = 1: m do
6:
Let column vector u = D(:, a m )−1/2 , and column vector v = S (t) (a m , bm )D(:, bm )−1/2 ,
where S (t) (a m , bm ) is the non-zero element in S (t) .
7:
Update the global similarity matrix as follows.
A(t) = A(t−1) + α

A(t−1) uv T A(t−1)
I + v T A(t−1) u

8: end for
9: for i=1:n do
10:
Based on Theorem 3, identify whether the first K (t) elements of N N (t) (i,:) are changed. If
true, update the first K (t) elements in N N (t) (i, :); otherwise, let N N (t) (i, :) = N N (t−1) (i, :).
11: end for
12: end for
13: while not all the classes have been discovered do
14: Calculate n i for each node, where i = 1, . . . , n.
15: for index = 1: n do
16:
For each node xi has been labeled yi , if A(T ) > a, scor e j = −∞; else, let scor ei =
max A(T ) (i, j)> a (n i − n j )
index

17:
Select the nodes x with the largest score to labeling oracle.
18:
Mark the class that x belongs to as discovered.
19: end for
20: end while

3.4 BIRD with less information
In many applications, it may be difficult to obtain the exact priors of all the minority
classes. In this subsection, we introduce BIRD-LI, a modified version of BIRD, which
requires only an upper bound prior p (t) for all the minority classes existing at time
step t. To be specific, BIRD-LI calculates N N (1) and diagonal matrix D at the first
time step, which is the same as BIRD. Then, the global similarity matrix A(t) and the
neighbor information matrix N N (t) could be updated from the first time step to the

123

412

D. Zhou et al.

time step T . The only difference between BIRD and BIRD-LI is that the size of the
minority class K (t) is calculated based on an estimated upper bound prior instead of the
exact ones for all the minority classes. After the updating process, BIRD-LI calculates
an overall score for the minority classes and selects the nodes with the largest overall
score to be labeled by the oracle.
BIRD-LI is described in Algorithm 3. It works as follows: Step 1 to Step 2 is the initial process for calculating N N (1) and the diagonal matrix D at the first time step. Step
3 to Step 12 aims to update the global similarity matrix A(T ) and the neighbor information matrix N N (T ) from time step 1 to time step T , which is the same as BIRD. The
while loop from Step 13 to Step 20 is the query process. We calculate an overall score
for the minority classes and select the nodes with the largest overall score to be labeled
by the oracle. BIRD-LI only terminates the loop until all the classes are discovered.
ALGORITHM 3: BIRD-LI algorithm
Input: M (1) , A(1) , S (2) , . . . , S (T ) , p (t) , α.
Output: The set I of labeled nodes and the L of their labels

1: Construct the n × n diagonal matrix D, where Dii = n( j=1) S (1) , i = 1, . . . , n.

2: Sort row i of A(1) decreasingly and save into N N (t) (i, :), where i = 1, . . . , n.
3: for t = 2:T do
4: Let K (t) = n × p (t) .
5: for m = 1: m (t) do
6:
Let column vector u = D(:, a m )−1/2 , and column vector v = S (t) (a m , bm )D(:, bm )−1/2 ,
where S (t) (a m , bm ) is a non-zero element in S (t) .
7:
Update the global similarity matrix as follows.
A(t) = A(t−1) + α

A(t−1) uv T A(t−1)
I + v T A(t−1) u

where u and v T are the two vectors decomposed from normalized updating matrix M (t) .
8: end for
9: for i=1:n do
10:
Based on Equation 13, identify whether the first K (t) elements of N N (t) (i,:) are changed. If
true, update the first K (t) elements in N N (t) (i, :); otherwise, let N N (t) (i, :) = N N (t−1) (i, :).
11: end for
12: end for
13: while not all the classes have been discovered do
14: Calculate n i for each node, where i = 1, . . . , n
15: for index = 1: n do
16:
For each node xi has been labeled yi , if A(T ) > a, scor e j = −∞; else, let scor ei =
max A(T ) (i, j)> a (n i − n j )
index

17:
Select the nodes x with the largest score to labeling oracle.
18:
Mark the class that x belongs to as discovered.
19: end for
20: end while

4 Query dynamics
In the previous section, we introduce two incremental RCD methods, i.e., BIRD and
SIRD, which are used for identifying rare categories on time-evolving graphs. Taking

123

Discovering rare categories from graph streams

413

the advantage of BIRD and SIRD, we can efficiently update the initial RCD model at
time step 0 to any future time step T . However, in many real word applications, we may
not want to make queries to oracle at each time step or we may only be allowed with
a limited number of queries. In these two cases, we introduce the following two open
problems: (1) query locating (QL): how to find the optimal time step T to discover
rare categories; (2) query distribution (QD): how to allocate limited number of queries
into different time steps.
4.1 Query locating
First of all, we introduce the query locating problem. In real world applications,
it could be the case that we are given a series of unlabeled time-evolving graphs
S (1) , S (2) , . . . , S (T ) , and we need to select an optimal time step Topt , so that we can
identify the minority classes with as less queries as possible (ALAP) and as early as
possible (AEAP).
Before presenting our methods, let us introduce the two main factors that may
affect the required number of queries in rare category detection. The first factor is
P(y = 2|xi ), which is the probability that example xi belongs to the minority class
given the features of xi . A considerable number of works have already studied it
before, such as MUVIR (Zhou et al. 2015a), GRADE (He et al. 2008) and NNDM (He
and Carbonell 2007). Another factor is the density Di at xi , the definition of which
is introduced in Theorem 4. When the density Di at example xi is high, it means
there are many other examples close or similar to example xi . Suppose there are two
nodes xi and x j in graph G, where P(y = 2|xi ) = P(y = 2|x j ) and Di > D j .
Since the density at node xi is larger than the density at node x j , there is a higher
probability that multiple classes are overlapped in the neighborhood of xi . To some
extent, higher density Di implies higher probability of mis-classifying xi . Thus, the
value of P(y = 2|xi ) is negatively correlated with the number of required queries,
and the value of density Di is positively correlated with the number of required labels.
For the second factor, we introduce the following theorem to estimate local density
based on the global similarity matrix constructed before.
(t)

Theorem 4 For each example xi , the density of xi is positively correlated with Di
(t)
(t)
at time step t, where Di = Σ nj=1 Ai, j , i = 1, . . . , n.

Proof Notice that A(t) (i, j) represents the global similarity between xi and x j . Thus,
(t)
(t)
Di = Σ nj=1 Ai, j is the aggregated global similarity between example xi and all the
existing examples on graph. If the density of example xi is high, then it is always true
that there are lots of examples which are similar or close to xi . In other words, the
(t)
(t)
density Di should be large. Similarly, when the density of xi is low, the value of Di
should be small. In conclusion, for any existing example xi in the graph, its density is
(t)
positively correlated with Di .


We let scor e(t) = P(y = 2|xi(t) ), which could be obtained using existing techniques such as MUVIR Zhou et al. (2015a) or GRADE He et al. (2008). Under this
circumstance, we propose to assign the hardness of identifying the minority classes at

123

414

D. Zhou et al.

Fig. 2 Correlation

time step t as follows.

	
I

(t)

= kc max

i=1,...,kc

scor ei(t)


−1

(t)

(14)

Di

where kc is the number of examples in the minority class c. In Fig. 2, the left figure
shows the exact number of queries needed to identify rare categories from a series of
time-evolving graphs. The right figure shows the value of I (t) calculated by Eq. (14).
We can see these two curves are highly correlated.
Let RS (t) denote the number of required queries by random sampling at time step
(1)
S (T )
. Intuitively, we could achieve optimal solut. Simultaneously, let C = R S −R
T
tion Topt , when the difference between the “exact” saved number of queries and the
estimated saved number of queries, i.e., C ∗ Topt , is maximized. The formulation is
shown as follows.
max

t=1,...,T


I (1) − I (t)  (1)
(T )
−C ·t
·
RS
−
RS
I (1) − I (T )

(15)

4.2 Query distribution
In this subsection, we discuss a more general problem: query distribution. In realworld applications, it could be the case that the updated graphs come as streams, and
we need to allocate our query budget among multiple time steps. Hence, we need a
method to allocate the queries properly among different time steps and enable us to
find the minority class examples with the minimum query budget and time.
To further explore this problem, we generate a synthetic data set containing two
classes, in which the initial proportion of the minority class equals to 0.1 %. We
increase the proportion of the minority class by 1 % in each time step. In Fig. 3, each
point (Q; T ) represents the minimum required budget Q for identifying the minority
class by time step T , and the budget is evenly allocated from time step 1 to time step
T . From this figure, we have 3 observations: (i) if we need to finish the task by time
step 1, then the largest number of queries is required; (ii) if we only need to finish the

123

Discovering rare categories from graph streams

415

u

Fig. 3 Query allocation

task by the last time step, the smallest number of queries is required. (iii) the point
at time step 3 is likely to hold a good trade-off, which has a relatively low querying
number and early detection time.
To further study the query dynamics problem, we propose 5 potential strategies for
the query distribution problem:
–
–
–
–
–

S1 Allocate all the budget at the first time step.
S2 Allocate all the budget at the last time step.
S3 Allocate all the budget into time step Topt .
S4 Allocate the query budget evenly among different time steps.
S5 Allocate the query budget into different time steps following exponential distribution, such as e−αt , where α > 0.

For query distribution problem, we propose Algorithm 4. Different from the query
process of Algorithm 2, in Step 3, we need to apply a strategy to calculate the certain
budget B (t) for time step t. If we have not found the minority class within B (t) at time
step t, then we go to the next time step. The overall algorithm stops either when the
minority class is discovered or when there is no budget to use.
We compare the performance of these five strategies with both synthetic data sets
and real data sets in Sect. 5.

5 Experiments
The analysis in Sects. 3 and 4 shows the advantage of our model in RCD on timeevolving graphs. In this section, we aim to empirically verify the effectiveness and the
efficiency of the proposed algorithms on both synthetic data sets and real data sets.
5.1 Data sets and setup
Six time-evolving graph data sets are used for testing our proposed algorithms. Among
these 6 data sets, there is 1 synthetic data set, 3 semi-real data sets and 2 real data sets.
In Table 2, we list several statistics of each data set.

123

416

D. Zhou et al.

ALGORITHM 4: Query distribution algorithm
Input: Strategy S,M (1) ,A(1) ,N N (1) ,S (2) , . . . , S (T ) , p (t) ,α.
Output: The set I of labeled nodes and the L of their labels
1: for t = 1:T do
C n × p (t) .
2: Let K (t) = maxl=c
l
3: Calculate B (t) as given Strategy S.
4: Calculate N N (t) as described in Algorithm 2.
5: while not all the classes have been discovered do
6:
Find the (K (t) )th element in each row of N N (t) . Set a c to be the largest value of them.
7:
Let K N N c (xi , a c ) = {x|N N (T ) (i, j) > a c }, and n ic = |K N N c |, where i = 1, . . . , n and
j = 1, . . . , n.
8:
for index = 1: B (t) do
9:
For each node xi has been labeled yi , if A(T ) > a yi , scor e j = −∞; else, let


n ic − n cj
scor ei = max (T )
ac
A

(i, j)> index

10:
Select the nodes x with the largest score to labeling oracle.
11:
If the label of x is exact class c, break; else, mark the class that x belongs to as discovered.
12:
end for
13: end while
14: If all the minority classes are discovered, break.
15: end for

Table 2 Statistics of different data sets
Name

Instance

Time steps

Number of classes

Synthetic data

5000

6

2

Abalone

4177

6

20

Adult

48,842

6

2

Statlog

58,000

6

6

Epinion

5665

16

24

Twitter

16,149

5

6

The synthetic data set contains 5000 instances, and we assume the proportion of
the minority class is increasing over time. Hence, to generate the time-evolving graphs
in later time steps, we let the proportion of a certain minority class increase by 1 %
and simultaneously let the proportion of the majority class decrease by 1 % at each
time step. Meanwhile, we generate additional 6 time-evolving graphs for 6 more time
steps.
The Abalone data set comes from a biology study. In this data set, we need to
predict the age of abalone based on multiple features. The age varies from 1 to 29,
which roughly forms a normal distribution. Specifically, there are very few examples
lying in the two extreme sides of the distribution. We separate the Abalone data set
into 5 classes, i.e., one majority class and 4 minority classes. The proportion of the
majority class is 56.93 %, and the proportion of the smallest class is 0.4 %. Besides,
we choose the minority class with the smallest prior to evolve over time.
The Adult data set comes from a demographic census, which aims to predict whether
the income of people exceeds $50 K per year or not. In Adult data set, there are 48,842

123

Discovering rare categories from graph streams

417

examples containing one majority class and one minority class. The majority class
is the population of income below $50 K, and the minority class is the population of
income above $50 K. In this data set, around 24 % of examples belong to the minority
class. Since we stand on the problem of the RCD, we keep the majority class the same
and only take 500 examples from the minority class. In this way, we can generate 24
data sets with the minority priors of 1.3 %. Notice that all the experimental results for
the Adult data set are calculated from the average values of the 24 sub-data sets.
The Statlog data set comes from a shuttle schedule database, which consists of
58,000 examples and 7 classes. However, we only include the 6 largest classes in our
evaluation, because the smallest class only contains 13 examples. After this modification, the priors of the 5 minority classes vary from 0.04 to 15 %. Same as before, we
incrementally increase the proportion of the smallest minority class by 1 % in each
time step.
The Epinion data set is a collection of about 5665 instances and 10,382 features over
16 time steps crawled from Epinion.com. Epinions is a product review site, where users
can share their reviews about products. Users themselves can also build trust networks
to seek advice from others. In this data set, each product is an instance, and the features
for each product are formed by the bag-of-words model upon its reviews. In addition,
the smallest class in Epinion only consists 0.03 % vertices while the proportion of the
largest class is 17.56 %.
The Twitter data set is crawled from Twitter streaming API based on a set of terrorism related keywords, such as shoot, kidnap, blast and etc.. We include 16,149
English-speaking twitter users from 6 countries and around 10 millions tweets from
4/25/2015 to 5/5/2015. Then, we extract 209 features based on users’ profiles, sentiments analysis, topic model analysis and users’ ego-network analysis. In this data set,
there are 56 % of users from Turkey, 0.09 % from Syria, 0.3 % from Iraq, 1.3 % from
Iran, 36 % from Saudi Arabia and 5.8 % from Yemen. We separate the users into 6
classes based on their nationalities and generate a time-evolving graph in each 2-day
interval.

5.2 Performance evaluation
First of all, we demonstrate the effectiveness upon 1000 synthetic data sets and 3
semi-synthetic data sets. We generate 1000 synthetic data sets, and each of them
contains 5,000 examples belonging to two classes. Besides, we initialize the priors
of the minority classes as 1 % and increase these priors by 1 % at each time step. We
also make use of 3 real data sets which meet the scenario of RCD. The details of
these 3 real data sets are summarized in Table 2. Then, we synthesize additional 6
time-evolving graphs from time step 2 to time step 7. For these time-evolving graphs,
we let the proportion of a certain minority class increase by 1 % and simultaneously let
the proportion of the majority class decrease by 1 % at each time step. Fig. 4a shows
the comparison results of 4 different methods: random sampling (RS), BIRD, BIRDLI and GRADE. Notice that BIRD and BIRD-LI perform the query process upon the
approximate aggregated adjacency matrix, while GRADE is performed on the exact
adjacency matrix at each time step. Besides, we provide BIRD-LI with a much looser

123

418

D. Zhou et al.

(a)

(b)

(c)

(d)

Fig. 4 Performance on synthetic and semi-synthetic data sets. a Synthetic data. b Abalone. c Adult. d
Statlog

prior upper bound, e.g., we input 5 % as the upper bound instead of using the exact
prior of 1 %. Then, we perform the same comparison experiments on 3 semi-synthetic
data sets, which are shown in Fig. 4b–d. At last, we evaluate our algorithms on two
real data sets in Figs. 5 and 6. Different from the previous cases, the proportions of the
minority classes vary randomly instead of increasing over time. In general, we have
the following observations: (i) both BIRD and BIRD-Li outperform random sampling
in any conditions; (ii) all of these 4 methods perform better when the prior of minority
class is getting larger; (iii) BIRD gives a comparable performance as GRADE does;
(iv) BIRD-LI is quite robust and requires only a few more queries than BIRD does in
most cases.
5.3 Efficiency of batch update
We run the experiments with Matlab 2014a on a workstation with CPU 3.5 GHz 4
processors, 256 GB memory and 2 T disk space. For both BIRD and GRADE, the
most time-consuming step is updating the global similarity matrix A(t) and neighbor
information matrix N N (t) at each time step. In this subsection, we report the running
time of updating A(t) and N N (t) from an initial time step to the second time step.
To better visualize the performance, we run the experiment on an increasing size of
graph, i.e., from 500 examples in graph to 1000 examples in graph. For each certain

123

Discovering rare categories from graph streams

419

Fig. 5 Performance on epinion data set

Fig. 6 Performance on twitter data set

size, we have 100 identical-setting data sets. Each point in Fig. 7 is computed based
on the average value of the 100 data sets under identical settings. As we mentioned
before, the computation cost of GRADE is O(n 3 ), and our method only costs O(n 2 ).
From Fig. 7, we can see the difference of running time is gradually increasing over
time. The difference is limited when the number of examples is 500. However, when
the size of graph goes to 10,000, the running time of BIRD is 6.227 seconds, while
the running time of GRADE is 41.41 seconds, which is 7 times of BIRD. Moreover,
the difference would be even more significant when we run algorithms on a series of
time steps.

123

420

D. Zhou et al.

Fig. 7 Efficiency

(a)

(b)

(c)
Fig. 8 Query locating. a Abalone. b Adult. c Statlog

5.4 Query dynamics
In this subsection, we show the performance of query locating and query distribution.
In Fig. 8, we apply the query locating methods on 3 real data sets. As the proportion

123

Discovering rare categories from graph streams

(a)

421

(b)

Fig. 9 Query distribution. a Synthetic data set. b Real data set (adult)

is increasing over time, the labeling request is decreasing in general. Besides, we also
observe that Topt is always located at the left bottom of each graph, which meets our
ALAP and AEAP intuitions.
Furthermore, by applying Algorithm 4, we perform the results of 5 different strategies on one binary-class synthetic data set and one binary-class real data set, i.e.,
Adult. In both Fig. 9a, b, we observe that Strategy S1 is always located at the left top
of the figure, which holds the time optimal; Strategy S2 is always located at the right
bottom of the figure, which holds the budget optimal; Strategy S3 is always located
at the left bottom of the figure, which considers both the time and the budget factors.
All of these 3 observations are consistent with our intuitions.
Besides, we also find two interesting observations. The first one is that, in Fig. 9a,
Strategy S4 performs slightly better than Strategy S5, while Strategy S5 outperforms
Strategy S4 in Fig. 9b. The reason is as follows. Strategy S5 always allocates most
of the budget at the earliest few time steps, which is why Strategy S5 could identify
minority class examples at time step 1 in Fig. 9b. But, if Strategy S5 cannot discover
the minority class at the beginning, it will finish the task later than Strategy S4, which
is why S5 performs worse than S4 in Fig. 9a. Strategy S4 allocates its budget evenly
among each time steps. However, when the task is relatively tough at the beginning
few time steps and relatively easy at the end, Strategy S4 may fail. This is what is
happening in Fig. 9b. Another interesting observation is that, in Fig. 9b, Strategy
S3 only queries 27 examples at time step 3 for discovering the minority class, while
Strategy S4 needs 39 labeling requests. Since the graph is evolving over time, Strategy
S4 may automatically skip some minority-class examples when these examples are
pretty similar to the previous labeled examples, which is the reason why Strategy S4
requires more queries.

6 Conclusion
In this paper, we mainly focus on the problem of efficiently and incrementally identifying under-represented rare category examples from time-evolving graphs. We propose
two fast incremental updating algorithms, i.e., BIRD and SIRD, as well as a generalized version of BIRD named BIRD-LI to handle the problems where the exact priors

123

422

D. Zhou et al.

of the minority classes are unknown. Furthermore, based on our algorithms, we introduce five strategies to deal with the novel problem—query distribution. To the best
of our knowledge, this is the first attempt in RCD under these dynamic settings. The
comparison experiments with state-of-the-art methods demonstrate the effectiveness
and the efficiency of the proposed algorithms.
Acknowledgements This work is supported by NSF research Grant IIS-1552654, and an IBM Faculty
Award. The views and conclusions are those of the authors and should not be interpreted as representing
the official policies of the funding agencies or the U.S. Government.

References
Aggarwal CC, Philip SY (2010) On clustering massive text and categorical data streams. Knowl Inf Syst
24(2):171–196
Akoglu L, McGlohon M, Faloutsos C (2010) Oddball: spotting anomalies in weighted graphs. In: PacificAsia conference on knowledge discovery and data mining, Springer, New York, pp 410–421
Akoglu L, Khandekar R, Kumar V, Parthasarathy S, Rajan D, Wu KL (2014) Fast nearest neighbor search
on large time-evolving graphs. In: Joint European conference on machine learning and knowledge
discovery in databases, Springer, New York, pp 17–33
Backstrom L, Huttenlocher D, Kleinberg J, Lan X (2006) Group formation in large social networks: membership, growth, and evolution. In: ACM SIGKDD international conference on knowledge discovery
and data mining, ACM, New York, pp 44–54
Berlingerio M, Koutra D, Eliassi-Rad T, Faloutsos C (2012) Netsimile: a scalable approach to sizeindependent network similarity. In: arXiv preprint arXiv:1209.2684
Bettencourt LM, Hagberg AA, Larkey LB (2007) Separating the wheat from the chaff: practical anomaly
detection schemes in ecological applications of distributed sensor networks. In: Distributed computing
in sensor systems, Springer, New York, pp 223–239
Dasgupta S, Hsu D (2008) Hierarchical sampling for active learning. In: International conference on machine
learning, ACM, New York, pp 208–215
Davis M, Liu W, Miller P, Redpath G (2011) Detecting anomalies in graphs with numeric labels. In: ACM
international conference on information and knowledge management, ACM, New York, pp 1197–1202
Eberle W, Graves J, Holder L (2010) Insider threat detection using a graph-based approach. J Appl Secur
Res 6(1):32–81
Fan W, Wang X, Wu Y (2013) Incremental graph pattern matching. ACM Trans Database Syst 38(3):18
Franke C, Gertz M (2008) Detection and exploration of outlier regions in sensor data streams. In: IEEE
international conference on data mining workshops, IEEE, Los Alamitos, pp 375–384
Gao J, Liang F, Fan W, Wang C, Sun Y, Han J (2010) On community outliers and their efficient detection in
information networks. In: ACM SIGKDD international conference on knowledge discovery and data
mining, ACM, New York, pp 813–822
Gupta M, Gao J, Aggarwal C, Han J (2014) Outlier detection for temporal data. Synth Lect Data Min Knowl
Discov 5(1):1–129
Gupte M, Eliassi-Rad T (2012) Measuring tie strength in implicit social networks. In: Annual ACM web
science conference, ACM, New York, pp 109–118
He J, Carbonell JG (2007) Nearest-neighbor-based active learning for rare category detection. In: Advances
in neural information processing systems, pp 633–640
He J, Liu Y, Lawrence R (2008) Graph-based rare category detection. In: IEEE international conference on
data mining, IEEE, pp 833–838
He J, Tong H, Carbonell J (2010) Rare category characterization. In: IEEE international conference on data
mining, IEEE, pp 226–235
Henderson K, Eliassi-Rad T, Faloutsos C, Akoglu L, Li L, Maruhashi K, Prakash BA, Tong H (2010)
Metric forensics: a multi-level approach for mining volatile graphs. In: ACM SIGKDD international
conference on knowledge discovery and data mining, ACM, New York, pp 163–172
Hill DJ, Minsker BS, Amir E (2007) Real-time bayesian anomaly detection for environmental sensor data.
In: Congress-international association for hydraulic research, Citeseer, vol 32, p 503

123

Discovering rare categories from graph streams

423

Kang U, McGlohon M, Akoglu L, Faloutsos C (2010) Patterns on the connected components of terabytescale graphs. In: IEEE international conference on data mining, IEEE, pp 875–880
Kang U, Tsourakakis CE, Appel AP, Faloutsos C, Leskovec J (2011) Hadi: mining radii of large graphs.
ACM Trans Knowl Discov Data 5(2):8
Koutra D, Ke TY, Kang U, Chau DHP, Pao HKK, Faloutsos C (2011) Unifying guilt-by-association
approaches: theorems and fast algorithms. In: Joint European conference on machine learning and
knowledge discovery in databases, Springer, New York, pp 245–260
Koutra D, Papalexakis EE, Faloutsos C (2012) Tensorsplat: spotting latent anomalies in time. In: Panhellenic
conference on informatics, IEEE, pp 144–149
Kumar R, Mahdian M, McGlohon M (2010) Dynamics of conversations. In: ACM SIGKDD international
conference on knowledge discovery and data mining, ACM, pp 553–562
Leskovec J, Kleinberg J, Faloutsos C (2005) Graphs over time: densification laws, shrinking diameters
and possible explanations. In: ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, ACM, pp 177–187
Liu Z, Chiew K, He Q, Huang H, Huang B (2014) Prior-free rare category detection: more effective and
efficient solutions. Expert Syst Appl 41(17):7691–7706
Müller E, Sánchez PI, Mülle Y, Böhm K (2013) Ranking outlier nodes in subspaces of attributed graphs.
In: IEEE international conference on data engineering workshops, IEEE, pp 216–222
Pelleg D, Moore AW (2004) Active learning for anomaly and rare-category detection. In: Advances in
neural information processing systems, pp 1073–1080
Phua C, Lee V, Smith K, Gayler R (2010) A comprehensive survey of data mining-based fraud detection
research. arXiv preprint arXiv:10096119
Sherman J, Morrison WJ (1950) Adjustment of an inverse matrix corresponding to a change in one element
of a given matrix. Annals Math Stat 21(1):124–127
Sricharan K, Das K (2014) Localizing anomalous changes in time-evolving graphs. In: ACM SIGMOD
international conference on management of data, ACM, pp 1347–1358
Tong H, Papadimitriou S, Philip SY, Faloutsos C (2008) Proximity tracking on time-evolving bipartite
graphs. In: SIAM international conference in data mining, pp 704–715
Yamanishi K, Takeuchi Ji (2002) A unifying framework for detecting outliers and change points from nonstationary time series data. In: ACM SIGKDD international conference on knowledge discovery and
data mining, ACM, pp 676–681
Yamanishi K, Takeuchi JI, Williams G, Milne P (2004) On-line unsupervised outlier detection using finite
mixtures with discounting learning algorithms. Data Min Knowl Discov 8(3):275–300
Zhou D, He J, Candan K, Davulcu H (2015a) Muvir: Multi-view rare category detection. In: International
joint conference on artificial intelligence, pp 4098–4104
Zhou D, Wang K, Cao N, He J (2015b) Rare category detection on time-evolving graphs. In: IEEE international conference on data mining, IEEE, pp 1135–1140

123

2016 IEEE 16th International Conference on Data Mining

Functional Regression with Mode-Sparsity Constraint
Pei Yang

Jingrui He

Arizona State University
Tempe, AZ 85281, USA
Email: cs.pyang@gmail.com

Arizona State University
Tempe, AZ 85281, USA
Email: jingrui.he@gmail.com

Abstract—Functional data is ubiquitous in many domains such
as healthcare, social media, manufacturing process, sensor
networks, etc. Functional data analysis involves the analysis
of data which is treated as inﬁnite-dimensional continuous
functions rather than discrete, ﬁnite-dimensional vectors. In
this paper, we propose a novel function-on-function regression
model based on mode-sparsity regularization. The main idea
is to represent the regression coefﬁcient function between predictor and response as the double expansion of basis functions,
and then use mode-sparsity constraint to automatically ﬁlter
out the irrelevant basis functions for both predictors and
responses. The mode-sparsity regularization covers a wide
spectrum of sparse models for function-on-function regression.
The resulting optimization problem is challenging due to the
non-smooth property of the mode-sparsity. We develop an
efﬁcient and convergence-guaranteed algorithm to solve the
problem. The effectiveness of the proposed approach is veriﬁed
on benchmark functional data sets in various domains.

1. Introduction
Functional data analysis (FDA) has been widely used in
many areas such as engineering, biomedicine, meteorology,
economics, etc [15]. In FDA, the ideal units of observation
are functions deﬁned on some continuous domains (e.g.,
time domains, spatial domains, imaging domains, spectral
domains, and genomic locations), and the observed data
consists of a sample of functions taken from some population sampled on a discrete grid [10]. For example, the
mass spectrometry data [7] contains mass spectra from a
study to ﬁnd serum proteomic markers for pancreatic cancer
performed at the University of Texas MD Anderson Cancer
Center. Each spectrum is a spiky function whose peaks
correspond to proteins and peptides with molecular mass.
Another example is neuroimaging, where the activation
levels observed at voxels in the brain are the responses
over the two or three dimensions of space and possibly time
as well [8]. The distinctive characteristic of FDA is that it
treats the inﬁnite-dimensional data as real-valued functions
rather than discrete, ﬁnite-dimensional vectors which are
commonly used by existing data mining techniques.
In this paper, we propose a novel Functional regression
model with Mode-sparsity constraint (FarMost) for functionon-function regression, where both predictors and responses
2374-8486/16 $31.00 © 2016 IEEE
DOI 10.1109/ICDM.2016.68

are functional data. The main idea is to represent the regression coefﬁcient function between the predictor and the
response as the double expansion of basis functions, and
then use mode-sparsity constraint on the regression weight
matrix to truncate irrelevant basis functions. The intuition
behind the proposed model is that we allow the dimensionality of the regression weight matrix to be relatively
large to accommodate more basis functions for a potentially
improved representation capability, while using the modesparsity regularization to automatically select the most informative basis functions. The mode-sparsity constraint enables
the joint multi-way shrinking of basis functions for both
predictors and responses. Meanwhile, it provides a ﬂexible
mechanism to adjust the sparsity of the regression weights,
and covers a broad spectrum of sparse models for functional
regression.
The resulting optimization problem is convex but nonsmooth due to the non-smoothness of the introduced modesparsity. To address this problem, we transform the nonsmooth objective function into a smooth one by making
use of an auxiliary function. Then, a simple and efﬁcient
algorithm is developed to solve the reformulated problem,
which works in an iterative update fashion. The proposed
algorithm is guaranteed to converge to the global optimum.
The effectiveness of the proposed model is evaluated on
the benchmark functional data sets collected from different
domains including the weather data, the electromyographical
data, and the diffusion tensor imaging data. In summary, the
main contributions of this paper are as follows:
•

•

•

We propose a novel function-on-function regression
model FarMost based on mode-sparsity regularization which facilitates the multi-way selection of
basis functions in building the regression model.
We develop an efﬁcient algorithm to solve the optimization problem in an iterative update fashion, and
prove its global convergence.
We demonstrate the effectiveness of the proposed
model on various functional data sets.

The rest of the paper is organized as follows. After a
brief review of the related work in Section 2, we present
the proposed FarMost model in Section 3. Section 4 shows
the experimental results. Finally, we conclude the paper in
Section 5.
1311

2. Related Work
We review the related work on functional data analysis [15]. In particular, we focus on functional regression,
which is one of the most active areas in FDA.
Most of the current functional regression work focus
on scalar-on-function regression, which involves functional
predictor and scalar response [10]. There has been comparatively less work on function-on-function regression, which
involves both functional predictor and functional response.
The basic function-on-function regression model was introduced in [15]. Functional Principal Component Analysis
(FPCA) is a popular technique used in functional regression model. For example, FPCreg [17] is a nonparametric
regression model based on functional principal component
decomposition; the Functional Additive Models (FAM) [11]
utilized functional principal components in an additive way.
Regularization is widely used in the function-on-function
model to avoid overﬁtting. In [2], different regularization
techniques including basis truncation, roughness penalty,
and sparsity penalty were adopted for linear B-spline basis
functions. The Penalized Function-on-Function Regression
(PFFR) [3] accommodated multiple functional predictors
and response observed on dense or sparse grids, and applied
quadratic roughness penalties on the model. The functional
additive mixed model [16] used quadratic penalty to build
the regression model for functional response on both functional and scale predictor. The multi-level functional regression approach [9] incorporated various basis expansions
including principal components, spline-based and waveletbased functional representations into the regression model.
In addition, some nonlinear functional regression models
have been proposed, such as the Triple-Basis Estimator
(3BE) [13] and the functional RKHS approach [4], [5].
In this paper, we focus on building a function-onfunction regression model by using mode-sparsity regularization for multi-way selection of basis functions, which is
distinctive from the existing work on FDA.

3. The Proposed FarMost Approach
We ﬁrst present the FarMost model, and then introduce
an iteratively update algorithm to solve the resulting optimization problem. Some special cases of the proposed
model will be discussed at the end of this section.

3.1. The FarMost Model
Let S and T be two interval domains. Denote the
functional predictor by x (s) ∈ Rn×1 measured at grid point
s ∈ S , and functional response by y (t) ∈ Rn×1 measured
at t ∈ T , where n is the number of curves. Note that we do
not require the predictor and response to be deﬁned on the
same domains. Here, the goal is to build a regression model
of functional response y on functional predictor x.
For two matrices X and Y , let X  Y and X ⊗ Y be
the Hadamard product (or entrywise product) and Kronecker
product, respectively. The vectorization of the matrix X into
a vector x is denoted by x = vec (X). Let W F be the

Frobenius norm of a matrix W . The p,q norm of a matrix

q/p 1/q
 
p
|W
|
. The
W is deﬁned as W p,q =
ij
i
j
i-mode matricization of a tensor W (or matrix W which is
a 2-way tensor) is denoted by W(i) (or W(i) ) [6]. diag(x)
returns a square diagonal matrix with the elements of vector
x on the main diagonal.
The basic functional regression model [15] can be represented as

y (t) =
x (s)β (s, t) ds + ε (t)
(1)
Ωt

where β (s, t) is a bivariate regression coefﬁcient function,
Ωt is a t-dependent interval set, and ε (t) is a residual
function. Intuitively, the regression function β(s, t) for a
ﬁxed value of t can be interpreted as the related weight
placed on x(s) that is required to predict y(t).
We consider the bivariate regression function β (s, t) as
a double expansion in terms of K1 basis functions ϕi (1 ≤
i ≤ K1 ) and K2 basis functions θj (1 ≤ j ≤ K2 ) such that
β (s, t) =

K1 
K2


wij ϕi (s) θj (t) = ϕT (s) W θ (t)

(2)

i=1 j=1

where ϕ (s) ∈ RK1 ×1 , θ (t) ∈ RK2 ×1 , and W is a K1 ×
K2 matrix of regression weight wij . By substituting this
expansion, the basic regression model in Eq. 1 becomes

y (t) =
x (s) ϕT (s) W θ (t) ds + ε (t)
(3)
Ωt
= Xt W θ (t) + ε (t)
	
where Xt = Ωt x (s) ϕT (s) ds.
Next, we introduce the proposed Functional regression
model based on Mode-sparsity regularization (FarMost).
The objective of FarMost is to minimize the reconstruction
loss resulting from the regression of the response on the
predictor, and the mode-sparsity constraint imposed on the
regression weights:




q
2
q
min y (t) − Xt W θ (t)F dt + α1 W 2,q + α2 
W T 
2,q
W

(4)
where α1 and α2 are non-negative parameters to control
the importance of the sparsity regularizations. The sparsity
q
constraint W 2,q encourages certain rows of W to be
sparse in 
order
to ﬁlter out irrelevant basis functions from
q
ϕ, while 
W T 
2,q encourages certain columns of W to be
sparse to truncate irrelevant basis functions from θ. Here, q
controls the degree of sparsity, where 1 ≤ q ≤ 2. A smaller
q could lead to a more sparse W . In particular, q = 2
corresponds to the squared Frobenius norm W 2F , while
q = 1 corresponds to the 2,1 norm W 2,1 which is the
most sparse case. The mode-sparsity regularization provides
a wide spectrum of sparse models for function-on-function
regression by varying the value of q .
The intuition behind the proposed model is that we allow
the dimensionality of W to be relatively large to accommodate more basis functions contained in both ϕ and θ for a

1312

potentially improved representation capability. Meanwhile,
the mode-sparsity regularization is used to automatically and
simultaneously pick the most informative basis functions.
In other words, the mode-sparsity constraint enables the
joint selection of basis functions for both predictors and
responses.

Next, the key issue is to design an auxiliary function for
F (W ). Deﬁne a new function,

 
2
(k)
G W, W
= y (t) − Xt W θ (t)F dt

q−2
2−q  k q q 
tr (Φi ) 2 + tr Φi (Φki ) 2
.
2
2
i=1


Note that G W, W (k) is an auxiliary function

 of F (W
 )
due to the facts: G (W, W ) = F (W ) and G W, W (k) ≥
F (W ) where the latter follows from Lemma 1 since both
Φi and Φki are

 positive deﬁnite matrices.
Since G W, W (k) is an auxiliary function of F (W ),
F (W ) is non-increasing under the update


W (k+1) = arg min G W, W (k) .
+

3.2. Optimization
Note that the objective function in Eq. 4 is convex since
both the loss function and 2,q norm are convex when 1 ≤
q ≤ 2. However, the non-smoothness of 2,q norm (q < 2)
poses a considerable challenge on the optimization method.
We will develop a simple and efﬁcient algorithm to solve
the problem.
We ﬁrst introduce the following inequality [12], which
will be used in the proof of convergence of the proposed
algorithm.

+

i=1

(k)

T
αi tr W(i)
Di W(i)



=

(k)

2



∂
∂ 
(k)
T
αi tr (W(i) W(i)
)  I Di
J(W ) +
∂W
∂W i=1
	


2



∂
(k)
T
=
J(W ) +
αi tr W(i) Di W(i)
∂W
i=1

(k)

Di

where the last equality follows

 (k)  from the

 equivalence
 of
(k)
(k)
the derivatives.
Since
F
W
=
G
W
,
W
≥






min G W, W (k) = G W (k+1) , W (k) ≥ F W (k+1) ,
W
the objective function F (W ) is non-increasing under the
above update.

∈ RKi ×Ki (1 ≤



q  (k)
(k)
=
W(i) (W(i) )T  I
2

q−2
2

.

In particular, for the special cases where q = 2 and
q = 1, we have the following corollary, which can be easily
derived from Theorem 1.

(6)

Corollary 1. If q = 2 which corresponds to the squared
Frobenius norm W 2F , we have

Proof. We make use of an auxiliary function to derive the
update rule. Let I be an identity matrix. Denote


T
Φi = W(i) W(i)
 I,
Φki

=



(k)
(k)
W(i) (W(i) )T



(k)

Di



 I.

2

y (t) − Xt W θ (t)F dt +


=

y (t) −

2
Xt W θ (t)F dt

+

2

i=1
2

i=1




q
αi 
W(i) 
2,q


q
2

αi tr Φi

= I.

(7)

If q = 1 which corresponds to the 2,1 norm W 2,1 , we
have
⎛
⎞
1
1
(k)
⎠ (8)
Di = diag ⎝
,··· ,
(k)
(k)
2[W(i) ]1: 2
2[W(i) ]Ki : 2

The objective function in Eq. 4 is rewritten into
F (W ) =

2


∂
∂ 
(k)
αi tr Φi Di
J(W ) +
∂W
∂W i=1

=

(5)

where k is the iteration index, and Di
i ≤ 2) is a diagonal matrix,

2



∂
G W, W (k)
∂W

2
q−2 
∂
q  k 2
∂ 
=
αi tr Φi
Φi
J(W ) +
∂W
∂W i=1
2

Theorem 1 (Convergence). The objective in Eq. 4 is nonincreasing under the update

2
W (k+1) = arg min y (t) − Xt W θ (t)F dt


W

Denote J(W ) = y (t) − Xt W θ 
(t)F dt for
 simplicity.
Next, we obtain the derivative of G W, W (k) :

In Theorem 1, we transform the non-smooth objective
deﬁned in Eq. 4 into a smooth one by making use of an
auxiliary function, and derive an iteratively update algorithm
to solve the reformulated problem.

W



αi

	

Lemma 1. For any positive deﬁnite matrices A, At ∈
Rm×m , the following inequality holds when 0 < p ≤ 2:
 p p 
 p p 
p−2 
p−2 
≤ tr At2 − tr At At 2 .
tr A 2 − tr AAt 2
2
2

2


2


(k)

(k)

where [W(i) ]j: is the j th (1 ≤ j ≤ Ki ) row vector of W(i) .
Note that Eq. 5 is a quadratic optimization problem. We
derive the closed-form solution for the regression weights
W as shown in Theorem 2.


.

1313

4. Experiments

Theorem 2 (Optimum). The optimal solution for Eq. 5 is
as follows,

We evaluate the proposed method on three benchmark
functional data sets collected from various domains. Table 1
shows the statistics of the data sets, where |S| and |T | are
numbers of points in the corresponding domains.
The Canadian Weather data set1 was introduced in [15]
as one of their main examples of functional data. For 35
weather stations, the daily temperature and precipitation
were averaged over a period of 30 years. The goal is to
predict the log daily precipitation proﬁle of a weather station
from information on the daily temperature proﬁle.
The LipEMG data2 consists of 32 records of the movement acceleration of the lower lip when a subject was repeatedly required to say the syllable ‘Bob’, and the corresponding electromyographical (EMG) activities of the primary
muscle depressing the lower lip [14]. The goal is to predict
the lip acceleration from the EMG activities.
The diffusion tensor imaging (DTI2) data was collected at Johns Hopkins University and the Kennedy-Krieger
Institute [1]. The data set involves 340 DTI scans from
the subjects with multiple sclerosis (MS). From each DTI
scan, fractional anisotropy (FA) proﬁles were obtained along
the corpus callosum (FA-CCA) and right corticospinal (FARCTS) tracts. The goal is to build a functional regression
model to predict FA-CCA from FA-RCTS in order to study
their spatial association.

−1

vec (W ) = [A + D] vec (P )
(9)
 
 T 
	
T
where A =
θ (t) θ (t) ⊗ Xt Xt dt, D = α1 IK2 ⊗
	
(k)
(k)
D1 + α2 D2 ⊗ IK1 , and P = XtT y (t) θT (t) dt.

Proof. The zero gradient condition of Eq. 5 gives


XtT Xt W θ (t) θT (t)dt +


=

2


(k)

αi Di W(i)

i=1

XtT y(t)θT (t)dt.

Based
on  the property of Kronecker product,

vec U HV T
= (V ⊗ U ) vec (H) for any matrices
U, V, and H, we have


2





(k)
vec XtT Xt W θ (t) θT (t) dt +
αi vec Di W(i)





i=1

XtT y(t)θT (t)dt

= vec
 
 
 
⇒
θ (t) θT (t) ⊗ XtT Xt dt vec (W ) +


(k)
(k)
α1 IK2 ⊗ D1 + α2 D2 ⊗ IK1 vec (W ) = vec (P )
⇒ Avec (W ) + Dvec (W ) = vec (P )

which completes the proof.
We summarize the above procedure into FarMost algorithm as shown in Algorithm 1. It iteratively updates the
regression weight matrix W and the diagonal matrix Di
until convergence. Note that since the objective in Eq. 4 is
convex, Theorem 1 demonstrates that the proposed FarMost
algorithm is guaranteed to converge to the global optimum.

TABLE 1: Statistics of different data sets.
Data set
Weather
LipEMG
DTI2

Algorithm 1 FarMost Algorithm

n
35
32
340

x
Temperature
EMG
FA-RCTS

|S|
365
501
55

y
Precipitation
Acceleration
FA-CCA

|T |
365
501
93

We adopt different performance metrics to evaluate the
proposed method. Let f (t) = Xt W θ(t) be the predicted
response function. The predicted and ground-truth regression functions for the cth (c = 1, · · · , m) curve are denoted
by fc (t) and yc (t), respectively, where m is the number
curves in the test data. RSS is the sum of squared residuals
integrated over the domain, and MRSS is the mean of RSS
over testing curves, deﬁned as,

1 m
2
M RSS =
[yc (t) − fc (t)] dt.
c=1
m

Input: Functional predictor x (s) and functional response
y (t), basis functions ϕ and θ, parameters α1 , α2 .
Output:
Regression weight matrix W .
1: Set k = 0;
(k)
2: Initialize Di
as an identity matrix, where i = 1, 2;
3: repeat
4:
Update W (k+1) by Eq. 9;
(k+1)
5:
Update Di
by Eq. 6, where i = 1, 2;
6:
Set k = k + 1;
7: until convergence

MRPE is the mean of the relative prediction errors over
testing curves, which is deﬁned as,
	
2
[yc (t) − fc (t)] dt
1 m
	
M RP E =
.
c=1
m
yc2 (t)dt

The most time or space consuming step in the FarMost
algorithm is to update W in Step 4. According to Eq. 9, the
size of the matrices involved in the computation is K12 K22 ,
where K1 and K2 are the numbers of basis functions. Note
that even though the number of curves n or the number of
points p is large, a far less number of basis functions would
be enough to well represent the data. In other words, we
usually have Ki  max(n, p) (i = 1, 2). Therefore, our
method is scalable to large data sets. Also, the proposed
FarMost algorithm is very simple, and enjoys the nice
property of global convergence.

Note that the smaller the value of either MRSS or MRPE
on the test data, the better the performance of the algorithm.
We compare the proposed FarMost algorithm with
various function-on-function regression methods including
1. http://www.psych.mcgill.ca/misc/fda/
2. http://www.stats.ox.ac.uk/∼silverma/fdacasebook/lipemg.html

1314

)DU0RVW

)GD/0

)3&UHJ

)$0







 







7UDLQLQJ5DWLR






)DU0RVW

)GD/0

)3&UHJ

)$0




053(

0566




7UDLQLQJ5DWLR





)DU0RVW

)GD/0

)3&UHJ

)$0












7UDLQLQJ5DWLR








Figure 3: MRSS varies with training ratio on LipEMG.
)DU0RVW

)GD/0

)3&UHJ






7UDLQLQJ5DWLR





Figure 4: MRPE varies with training ratio on LipEMG.

)$0







)DU0RVW

)GD/0

)3&UHJ

)$0






053(

0566



Figure 2: MRPE varies with training ratio on Weather.






















)$0








)3&UHJ



Figure 1: MRSS varies with training ratio on Weather.


)GD/0





053(

0566



)DU0RVW






7UDLQLQJ5DWLR



 




Figure 5: MRSS varies with training ratio on DTI2.






7UDLQLQJ5DWLR





Figure 6: MRPE varies with training ratio on DTI2.

FdaLM [15] with 2 regularization, FPCreg [17], and
FAM [11]. Both FPCreg and FAM are available online in
the PACE3 package.
We repeat the experiments 5 times and report the mean
and standard deviation of performance. The parameters are
tuned for each algorithm by cross-validation on training
data. The basis functions used in both FarMost and FdaLM
are Fourier series. The numbers of basis functions are empirically set to 150.

each ﬁgure, x-axis represents the training ratio, and y -axis
represents the regression performances on the test data. Note
that since all the methods are deterministic, their deviations
are close to zero.
The results show that the proposed FarMost algorithm
performs the best among all the comparison algorithms.
Both FPCreg and FAM are based on functional principal
component analysis (FPCA) which keeps only the ﬁrst few
principal components explaining the most variability. The
results indicate that the functional principal components
with the largest amount of variability in predictor may
not necessarily be the most discriminative in predicting
response. FdaLM performs worse than the other algorithms,
suggesting that using only the roughness penalty (2 regu-

4.1. Performance Comparison
Figures 1 - 6 show the regression performances in terms
of MRSS and MRPE respectively on the three data sets. In
3. http://www.stat.ucdavis.edu/PACE/

1315

in an iterative update fashion, and converges to the global
optimum. The experiments on multiple benchmark functional data sets demonstrate the effectiveness of the proposed
model.

larization) may not be adequate to build a robust regression model. In contrast, FarMost uses the mode-sparsity
regularization to simultaneously select the informative basis
functions from each mode and truncate the irrelevant ones.
It improves the representation capability of the basis functions and leads to a more robust regression model. As a
consequence, its generalization performance on the unseen
responses can be improved.

Acknowledgments: This work is supported by the NSF
research grant IIS-1552654, ONR Research grant N0001415-1-2821, IBM Faculty Award, and NSFC research grant
61473123. The views and conclusions are those of the
authors and should not be interpreted as representing the
ofﬁcial policies of the funding agencies or the governments.

4.2. Parameter Sensitivity
We study the performance sensitivity of FarMost on
the parameters α1 and α2 , which are used to control the
importance of the mode-sparsity regularization. Figure 7 and
Figure 8 show the similar trends of the performance varying
with the two parameters. For example, the algorithm performs worse as α1 approaches 0 when no sparsity constraint
is imposed on the regression weights. The optimal performance is achieved at α1 = 16. It suggests that imposing
the mode-speciﬁc sparsity regularization on the regression
model could lead to better performance. But a large α1 (e.g.,
α1 ≥ 256) will deteriorate the performance of the FarMost
algorithm, indicating that too much weight is putting on the
sparsity regularization term.

References



[1]

P. J. Basser, S. Pajevic, C. Pierpaoli, J. Duda, and A. Aldroubi. In
vivo ﬁber tractography using DT-MRI data. Magnetic Resonance in
Medicine, 44(4):625–632, 2000.

[2]

J. Harezlak, B. A. Coull, N. M. Laird, S. R. Magari, and D. Christiani.
Penalized solutions to functional regression problems. Computational
Statistics & Data Analysis, 51(10):4911–4925, 2007.

[3]

A. Ivanescu, A.-M. Staicu, F. Scheipl, and S. Greven. Penalized
function-on-function regression. Computational Statistics, 30(2):539–
568, 2015.

[4]

H. Kadri, E. Duﬂos, P. Preux, S. Canu, and M. Davy. Nonlinear
functional regression: a functional RKHS approach. In AISTATS,
pages 374–380, 2010.

[5]

H. Kadri, E. Duﬂos, P. Preux, S. Canu, A. Rakotomamonjy, and
J. Audiffren. Operator-valued kernels for learning from functional
response data. Journal of Machine Learning Research, 2015.

[6]

T. G. Kolda and B. W. Bader. Tensor decompositions and applications.
SIAM Review, 51(3):455–500, 2009.

[7]

J. M. Koomen, L. N. Shih, K. R. Coombes, D. Li, L.-c. Xiao,
I. J. Fidler, J. L. Abbruzzese, and R. Kobayashi. Plasma protein
proﬁling for diagnosis of pancreatic cancer reveals the presence of
host response proteins. Clinical Cancer Research, 11(3):1110–1118,
2005.

[8]

D. J. Levitin, R. L. Nuzzo, B. W. Vines, and J. O. Ramsay. Introduction to functional data analysis. Canadian Psychology, 48(3):135–
155, 2007.

[9]

M. J. Meyer, B. A. Coull, F. Versace, P. Cinciripini, and J. S. Morris.
Bayesian function-on-function regression for multilevel functional
data. Biometrics, 71(3):563–574, 2015.

053(













D









Figure 7: MRPE varies with α1 on DTI2 (log4 scale).


[10] J. S. Morris. Functional regression. Annual Review of Statistics and
Its Application, 2(1):321–359, 2015.

053(




[11] H.-G. Müller and F. Yao. Functional additive models. Journal of the
American Statistical Association, 103(484):1534–1544, 2008.



[12] F. Nie, H. Huang, and C. H. Q. Ding. Low-rank matrix recovery via
efﬁcient Schatten p-norm minimization. In AAAI, 2012.











D







[13] J. B. Oliva, W. Neiswanger, B. Póczos, E. P. Xing, H. Trac, S. Ho,
and J. G. Schneider. Fast function to function regression. In AISTATS,
2015.





[14] J. Ramsay and B. Silverman. Applied Functional Data Analysis. New
York: Springer-Verlag, 1st edition, 2002.

Figure 8: MRPE varies with α2 on DTI2 (log4 scale).

[15] J. Ramsay and B. Silverman. Functional Data Analysis. New York:
Springer-Verlag, 2nd edition, 2005.

5. Conclusions

[16] F. Scheipl, A.-M. Staicu, and S. Greven. Functional additive
mixed models. Journal of Computational and Graphical Statistics,
24(2):477–501, 2015.

In this paper, we propose a novel function-on-function
regression model based on the mode-sparsity constraint to
conduct multi-way selection of basis functions in building
the regression system. A simple and efﬁcient algorithm is
developed to solve the optimization problem, which works

[17] F. Yao, H.-G. Müller, and J.-L. Wang. Functional linear regression
analysis for longitudinal data. The Annals of Statistics, 33(6):2873–
2903, 2005.

1316

2014 IEEE International Conference on Data Mining

Co-clustering Structural Temporal Data
with Applications to Semiconductor Manufacturing
Yada Zhu

Jingrui He

IBM T.J. Watson Research Center
Email: yzhu@us.ibm.com

Arizona State University
Email: jingrui.he@asu.com

quality control and fault diagnostics. Although very important,
this problem cannot be readily solved using existing techniques
on time series clustering or multi-way clustering. For time
series clustering, most existing methods are designed for
unstructured time series data [3, 22, 15], and thus cannot
leverage the structural information from the underlying matrix.
For multi-way clustering, existing methods take as input one
or more matrices of scalers [6, 1, 4], and cannot be applied
on matrices of time series.
In this paper, for the ﬁrst time, we study the co-clustering
of such structural temporal data and propose the C-Struts
framework to address this problem. In this framework, we
ﬁrst interpret the structural information associated with the
two-dimensional array as a set of constraints on the cluster
membership. Then we introduce an auxiliary probability distribution taking these constraints into consideration, analyze
its properties, and build a prototype for each row/ column
accordingly. Finally, we propose an iterative algorithm to
repeatedly assign each row/column to the closest prototype.
The rest of the paper is organized as follows. In Section
2, we brieﬂy review the related work. Then we present the
C-Struts framework together with the iterative algorithm in
Section 3. Experiments results are provided in Section 4.
Finally, we conclude the paper in Section 5.
II. R ELATED W ORK
In this section, we brieﬂy review the related work.
Time Series Analysis. For time series data, researchers have
studied a variety of problems, such as classiﬁcation [3, 7],
clustering [22, 10], search and indexing [16, 20], forecasting [21], outlier detection [14], etc. The major difference
between existing methods for time series clustering and our
proposed work is as follows. For the former, the time series
data are typically unstructured, and the clustering results are
solely based on the distance between two time series; whereas
for the latter, the time series data are structured, i.e., they
naturally ﬁt into a two-dimensional array, and the structural
information can be exploited to improve the clustering results.
Multi-way Clustering. Different from traditional clustering
techniques, which are designed to group objects so as to
maximize within cluster similarity and between cluster dissimilarity, for sparse relational data, co-clustering or bi-clustering
methods [12] aim at simultaneously clustering objects of each
type. It has been generalized to handle more than two object
types, i.e., multi-way clustering [5, 11]. The major difference
between existing methods for multi-way clustering and our

Abstract—
Recent years have witnessed data explosion in semiconductor
manufacturing due to advances in instrumentation and storage
techniques. In particular, following the same recipe for a certain
IC device, multiple tools and chambers can be deployed for the
production of this device, during which multiple time series can
be collected, such as temperature, impedance, gas ﬂow, electric
bias, etc. These time series naturally ﬁt into a two-dimensional
array (matrix), i.e., each element in this array corresponds to
a time series for one process variable from one chamber. To
leverage the rich structural information in such temporal data,
in this paper, we propose a novel framework named C-Struts
to simultaneously cluster on the two dimensions of this array.
In this framework, we interpret the structural information as
a set of constraints on the cluster membership, introduce an
auxiliary probability distribution accordingly, and design an
iterative algorithm to assign each time series to a certain cluster
on each dimension. To the best of our knowledge, we are the ﬁrst
to address this problem. Extensive experiments on benchmark
and manufacturing data sets demonstrate the effectiveness of
the proposed method.
Index Terms—Structural; temporal; co-clustering;

I. I NTRODUCTION
Semiconductor manufacturing represents one of the most
complex manufacturing processes in the world [13]. Here,
one key challenge is how to exploit the large amount of data
associated with process variables monitored over time (e.g.,
temperature, impedance, gas ﬂow, electric bias) for a variety
of purposes such as anomaly detection, quality control, and
fault diagnostics, which may lead to signiﬁcant reduction in
the manufacturing cost [9, 8]. In particular, to produce a certain
IC (Integrated Circuit) device, multiple tools will be deployed
following the same recipe process, and each tool has multiple
chambers to carry out the task. Therefore, the time series data
associated with various process variables measured from all
the chambers ﬁt into a two-dimensional array, or matrix. To
be speciﬁc, each row of the array corresponds to one chamber,
each column corresponds to one process variable, and each
element in this array corresponds to the measurements of
the process variable over time. Such structural temporal data
contain rich information about the manufacturing process,
and thus can be exploited to help domain experts gain more
insights into the recipe of the IC device.
In particular, the simultaneous clustering of rows (chambers)
and columns (process variables) helps identify chambers with
similar behaviors and process variables with similar patterns
over time. Such information can be further used to detect
outlying chambers as well as process variables for the sake of
1550-4786/14 $31.00 © 2014 IEEE
DOI 10.1109/ICDM.2014.17

1121

proposed work is as follows. The input of multi-way clustering
is one or more matrices of scalers; whereas the input of the
proposed work is a matrix of time series.
Semiconductor Device Fabrication. For the purpose of
process fault/anomaly detection, multivariate statistical methods have been applied successfully in semiconductor manufacturing, such as Principal component analysis (PCA), Fisher
linear analysis and partial least square [2]. However, the
structural information embedded in the time-series data cannot
be naturally incorporated into these algorithms. To the best
of our knowledge, our work is the ﬁrst to leverage the
structural temporal information for process fault detection in
semiconductor manufacturing.
III. P ROPOSED W ORK
In this section, we introduce our proposed framework on
co-clustering structural temporal data. In other words, given
structural temporal data that ﬁt into a two-dimensional array, our goal is to simultaneously cluster the rows and the
columns. Here we would like to point out that the analysis
and the proposed algorithm can be naturally extended to multidimensional arrays, which will be discussed in Subsection 3.5.
A. Notation
Let z i,j denote the time series in the ith row and the j th
column, i = 1, . . . , M , j = 1, . . . , N , where M (N ) is
the total number of rows (columns) in the array. Each time
series z i,j has T i,j observations, i.e., z i,j = {z1i,j , . . . , zTi,ji,j }.
Notice that the length of different time series is not necessarily
the same. Let R denote the number of row clusters, and
C denote the number of column clusters. For example, in
device fabrication of semiconductor manufacturing, the R row
clusters are associated with different tools, which contain
various number of chambers; whereas the C column clusters
are associated with different types of process variables, e.g.,
the variables subject to Advance Process Control (APC), the
dependent variables, etc.
Let ẑ r,: denote the rth row cluster for r = 1, . . . , R; ẑ :,c
denote the cth column cluster for c = 1, . . . , C; Φ1 denote the
mapping from {z i,j } to {ẑ r,: } (row cluster); and Φ2 denote
the mapping from {z i,j } to {ẑ :,c } (column cluster).
B. Problem Deﬁnition
Given the above structured time series data, our goal is to
simultaneously cluster the M × N time series into R row
clusters and C column clusters, resulting in R × C clusters in
total. In particular, the cluster assignment should satisfy the
following two constraints.
1) Row Constraint (RC): the time series in the same row
should be assigned to the same row cluster;
2) Column Constraint (CC): the time series in the same
column should be assigned to the same column cluster.
Based on these constraints, ∀i = 1, . . . , R, j = 1, . . . , C,
Φ1 (z i,j ) = Φ1 (z i,: ), where z i,: denotes the time series on the
ith row, and Φ2 (z i,j ) = Φ1 (z i,: ), where z :,j denotes the time
series on the j th column.
Notice that these constraints originate from device fabrication in semiconductor manufacturing, where the time series

collected from chambers in the same tool exhibit similar patterns due to their physical proximity (constraint (1)), and the
time series associated with process variables of the same type
are similar to each other due to their control pattern (constraint
(2)). Therefore, traditional time series clustering methods
dealing with unstructured temporal data are not best suited for
such problems, since they do not take these constraints into
consideration. The problem setting is also different from existing co-clustering/multi-way clustering methods [4, 1, 18, 6],
where the input is one or more matrices, i.e., the elements on
the two-dimensional array are scalers instead of time series.
C. The Proposed C-Struts Framework
For each time series z i,j , we assume its current value
at time stamp t can be regressed
values up to
L oni,jthe past
i,j
· zt−l
+ i,j
a maximum lag L: zti,j =
t , where
l=1 βl
i,j
i,j
βl are the parameters, and t are IID random variables
for i = 1, . . . , M , j = 1, . . . , N , and t = 1, . . . T i,j . Let
β i,j = [β1i,j , . . . , βLi,j ]T , where (·)T denotes vector transpose.
In the initialization step, the parameters β i,j can be estimated
by solving the following optimization problem.
β i,j = arg min


t

(zti,j −

L

l=1

i,j 2
βli,j · zt−l
) + αR(β i,j ) (1)

where R(·) is a regularizer on the parameters, e.g., p-norm
of β i,j , and α is a positive parameter that balances between
the mean squared error and the regularizer. Such optimization
problem can be solve using ridge regression if R(β i,j ) =
β i,j 2 , Lasso [19] if R(β i,j ) = |β i,j |, elastic net [23] if
R(·) is a linear combination of both the 2-norm and the 1norm of β i,j , etc.
Based on the two constraints RC and CC, we assume that
the joint probability of: (1) the parameters β, (2) the time
series on the ith row z i,: , and (3) the time series on the j th
column z :,j , can be approximated by the following auxiliary
probability distribution.
p(β, z i,: , z :,j ) ≈ q(β, z i,: , z :,j )
.
= μi,j p(ẑ r,: , ẑ :,c )p(z i,: |ẑ r,: )p(z :,j |ẑ :,c )p(β|z i,: )p(β|z :,j )
(2)
where Φ1 (z i,: ) = ẑ r,: , Φ2 (z :,j ) = ẑ :,c , and the value of
the coefﬁcient μi,j guarantees that q(·) is a valid probability
distribution, i.e., μi,j =  p(β|zi,:1)p(β|z:,j ) .
β
Based on the auxiliary probability distribution q(·), the
parameters β can be generated as follows. We ﬁrst draw the
row cluster ẑ r,: and the column cluster ẑ :,c from p(ẑ r,: , ẑ :,c );
based on these clusters, we then draw each row z i,: according
to p(z i,: |ẑ r,: ), and each column z :,j according to p(z :,j |ẑ :,c );
ﬁnally, we draw the parameters β based on both z i,: and z :,j
according to μi,j p(β|z i,: )p(β|z :,j ).
It can be proven that q(·) has the following property.
LEMMA 3.1 [Properties of q(·)]
1) The marginal probability of ẑ r,: (ẑ :,c ) is the same under
p(·) and q(·). To be speciﬁc,
q(ẑ r,: ) = p(ẑ r,: ), q(ẑ :,c ) = p(ẑ :,c )
(3)

1122

:,c

2) The conditional probability of z i,: (z :,j ) given ẑ r,: (ẑ :,c )
is the same under p(·) and q(·). To be speciﬁc,
q(z i,: |ẑ r,: ) = p(z i,: |ẑ r,: ), q(z :,j |ẑ :,c ) = p(z :,j |ẑ :,c )
(4)

Similarly the column cluster prototype β̂ can be obtained
from the following equation.


:,c
β̂ =
p(ẑ r,: |ẑ :,c )p(z i,: |ẑ r,: )p(z :,j |ẑ :,c )

3) z i,: is conditionally independent of the column cluster
ẑ :,c given the row cluster ẑ r,: ; z :,j are conditionally
independent of the row cluster ẑ r,: given the column
cluster ẑ :,c . To be speciﬁc,
q(z i,: |ẑ r,: , ẑ :,c ) = q(z i,: |ẑ r,: )
q(z :,j |ẑ r,: , ẑ :,c ) = q(z :,j |ẑ :,c )

·

ẑ :,c

=
=



z i,: :Φ1 (z i,: )=ẑ r,:
z :,j :Φ2 (z :,j )=ẑ :,c
r,:



q(β, z i,: , z :,j )

p(ẑ )

μi,j p(ẑ :,c |ẑ r,: )p(z i,: |ẑ r,: )p(z :,j |ẑ :,c )

p(ẑ r,: , ẑ :,c ) =

ẑ :,c z i,: :Φ1 (z i,: )=ẑ r,:
z :,j :Φ2 (z :,j )=ẑ :,c
i,:
:,j

Then for the rth row cluster, we deﬁne its prototype as
r,:
the expected value of β given the row cluster, i.e., β̂ =
Eq(β|ẑr,: ) (β).
If both p(β|z i,: ) and p(β|z :,j ) follow a Gaussian distribution such that p(β|z i,: ) ∝ exp(− 2σ12 (β − β i,: )T (β − β i,: )),
R

Φ1 ,Φ2

and p(β|z :,j ) ∝ exp(− 2σ12 (β − β :,j )T (β − β :,j )), where
i,:

i,j

N
M
1  i,j
1  i,j
β , β :,j =
β
N j=1
M i=1

+

(6)



β :,j − Eq(β|ẑ:,c ) (β)2 )

(12)

where the outermost expectation is with respect to the true
joint probability p(·), and the prototypes for row/column
clusters are with respect to the auxiliary probability q(·).
D. The Proposed Algorithm
The proposed algorithm is summarized in Algorithm 1. In
Step 1 to 5, we compute the parameters β i,j for each time
series in the two-dimensional array; in Step 6 to 11, we
compute the row/column average of the parameters β i,: /β :,j ;
in Step 12, we randomly assign the rows to the R row clusters,
and assign the columns to the C column clusters; then we
repeat Step 14 to 25 until convergence (not to exceed niter
times), where in Step 14 to 19, we compute the row/column
r,: :,c
cluster prototype β̂ /β̂ , and in Step 20 to 25, we re-assign
each row/column to the closest row/column cluster prototype.

ẑ :,c z i,: :Φ1 (z i,: )=ẑ r,:
z :,j :Φ2 (z :,j )=ẑ :,c

· Eμi,j p(β|zi,: )p(β|z:,j ) (β)


p(ẑ :,c |ẑ r,: )p(z i,: |ẑ r,: )p(z :,j |ẑ :,c )
=

·

C


c=1 Φ2 (z :,j )=ẑ :,c

Then, the row cluster prototype can be derived as follows.


r,:
p(ẑ :,c |ẑ r,: )p(z i,: |ẑ r,: )p(z :,j |ẑ :,c )
β̂ =

ẑ :,c z i,: :Φ1 (z i,: )=ẑ r,:
z :,j :Φ2 (z :,j )=ẑ :,c
2 i,:
2 :,j
β + σR
β
σC
2
2
σR + σC

(11)

r=1 Φ1 (z i,: )=ẑ r,:

:,j

β denotes the column average of β , β denotes the row
average, σR and σC are both positive parameters, i.e.,
β i,: =

|z i,j |Φ1 (z i,j ) = ẑ r,: , Φ2 (z i,j ) = ẑ :,c |
M ×N

where |z i,j |Φ1 (z i,j ) = ẑ r,: , Φ2 (z i,j ) = ẑ :,c | denotes the
number of times series that have been mapped to the rth row
cluster and the cth column cluster.
Based on the above discussion, the optimal mapping functions Φ1 and Φ2 should maximize the following objective,
R


min Ep (
β i,: − Eq(β|ẑr,: ) (β)2

· p(β|z )p(β|z )

C

(8)

Notice that the row and column cluster prototypes in Equations
(7) and (8) are not centroids. Instead, they are weighted
combination of the row and column average of the parameters,
where the weights are obtained via the q(·).
For the conditional probability of each row/column given
its row/ column cluster, we propose to estimate its value as
follows.
r,:
r,:
1
(9)
p(z i,: |ẑ r,: ) ∝ exp(− 2 (β i,: − β̂ )T (β i,: − β̂ ))
2σR
:,c
:,c
1
p(z :,j |ẑ :,c ) ∝ exp(− 2 (β :,j − β̂ )T (β :,j − β̂ )) (10)
2σC

Together with the fact that zi,: :Φ1 (zi,: )=ẑr,: p(z i,: |ẑ r,: ) = 1

:,j :,c
and
z :,j :Φ1 (z :,j )=ẑ :,c p(z |ẑ ) = 1, we can obtain the
exact value of these conditional probabilities.
To estimate the joint probability of each row/column cluster
pair, we use the empirical probability mass of the time series
that have been mapped to the corresponding row/column
cluster. To be speciﬁc,

(5)

Proof. Omitted for brevity.
From the above properties, we can see that the approximation probability q(·) keeps the marginal probability of the
row/column clusters, as well as the conditional probability of
each row/column given a row/column cluster. Furthermore, the
conditional independence in Equation (5) is consistent with
both RC and CC.
Therefore, we propose to construct a prototype for each
row/column cluster based on q(·). To this end, ∀r, we ﬁrst
compute the posterior distribution of β given ẑ r,: as follows.
q(β, ẑ r,: )
q(β|ẑ r,: ) =
q(ẑ r,: )
 

ẑ r,: z i,: :Φ1 (z i,: )=ẑ r,:
z :,j :Φ2 (z :,j )=ẑ :,c
2 i,:
2 :,j
β + σR
β
σC
2
2
σR + σC

(7)

1123

E. Discussion
Finally, in this subsection, we discuss alternative features
and extensions for the proposed C-Struts algorithm.
1) Alternative Features for Time Series: In Algorithm 1,
we use the parameters β i,j , i = 1, . . . , M , j = 1, . . . , N , to
represent the time series in the two-dimensional array, which is
obtained from the Auto-Regressive (AR) model. Alternatively,
we could use the Auto-Regressive Moving-Average (ARMA)
L
L 
i,j
i,j
+ i,j
model, i.e., zti,j = ci,j + l=1 βli,j · zt−l
t +
l =1 γl ·
i,j
i,j
i,j
i,j
is the expectation of z , and γl are
t−l , where c
additional parameters. The rest of the algorithm applies on
the concatenation of βli,j and γli,j
 . If all the time series in the
two-dimensional array are of the same length, we could also
use PCA or DFT to extract the features, both of which have
been used in time series clustering.
Algorithm 1 C-Struts Algorithm
Input: z i,j , i = 1, . . . , M , j = 1, . . . , N , R, C, niter
Output: Φ1 , Φ2
1: for i = 1 to M , j = 1 to N do
2:
Compute the parameters β i,j by solving Equation (1)
using ridge regression, Lasso, etc;
3: end for
4: for i = 1 to M do
5:
Compute the row average β i,: using Equation (6);
6: end for
7: for j = 1 to N do
8:
Compute the column average β :,: using Equation (6);
9: end for
10: Randomly initialize Φ1 and Φ2 ;
11: for k = 1 to niter do
12:
for r = 1 to R do
r,:
13:
Compute the row cluster prototype β̂ using Equation (7);
14:
end for
15:
for c = 1 to C do
:,c
16:
Compute the column cluster prototype β̂ using
Equation (8);
17:
end for
18:
for i = 1 to M do
r,:
19:
Update Φ1 (z i,: ) ← arg minẑr,: β i,: − β̂ 2 ;
20:
end for
21:
for j = 1 to N do
:,c
22:
Update Φ2 (z :,j ) ← arg minẑ:,c β :,j − β̂ 2 ;
23:
end for
24: end for
2) Extension to Multi-dimensional Arrays: The proposed
C-Struts framework can be naturally extended to multidimensional arrays. For example, if the underlying structure
is a three-dimensional array instead of a matrix, the auxiliary
probability distribution can be deﬁned as follows.
q(β, z i,:,: , z :,j,: , z :,:,k )
= μi,j,k p(ẑ r,:,: , ẑ :,c,: , ẑ :,:,o )p(z i,:,: |z r,:,: )p(z :,j,: |z :,c,: )
· p(z :,:,k |z :,:,o )p(β|z i,:,: )p(β|z :,j,: )p(β|z :,:,k )

It consists of three parts: the joint probability of clusters
on the three dimensions; the conditional probability of a
single element (e.g., a row) given the cluster on a certain
dimension; and the conditional probability of the parameters
given elements on different dimensions. Based on the auxiliary
probability distribution, we could modify the prototypes on the
3 dimensions accordingly, based on which we could repeatedly
updated the cluster membership using Algorithm 1.
IV. E XPERIMENTAL R ESULTS
In this section, we test the performance of the proposed CStruts algorithm on benchmark and manufacturing data sets.
Since C-Struts is the ﬁrst algorithm for co-clustering structural
temporal data, we compare its performance with existing
methods for time series clustering, including CLDS [10], KMeans on the vectors β i,j , and Co-clustering based on the
pair-wise similarity between the time series in each row and
each column. Different from C-Struts, neither CLDS nor KMeans take into consideration the structural information associated with the underlying two-dimensional array; although
Co-clustering leverages the structural information, it ignores
the detailed information in each time series since it only uses
the pair-wise similarity. Notice that all the algorithms are given
the same number of clusters as input, i.e., for C-Struts and Coclustering, the number of row/column clusters is R/C; and for
CLDS and K-Means, the number of clusters is R × C.
A. Manufacturing Data
In this subsection, we test the performance of C-Struts on a
data set collected from semiconductor manufacturing. The data
set corresponds to an etching step with 19 process variables
that forms 3 categories based on the process control practice:
‘gas and pressure’, ‘power’, and ‘others’. It is concurrently
running in 5 tools, each having 6 chambers. Here, the goal is
to identify similar chamber and process variable behaviors.
Figure 1 shows the results on this data set. In particular,
Figure 1(a) presents the co-clustering results, where the various colors indicate the ground truth, and the rows/columns
are re-arranged so that rows/columns assigned to the same
row/column cluster are grouped together. From this ﬁgure, we
can see that the 30 chambers have been correctly assigned to
the row cluster that corresponds to the tool that the chambers
belong to. This is consistent with the assumption that chambers
behave similarly in the same tool and differently across various
tools. On the other hand, of the 3 column clusters generated by
C-Struts, the ﬁrst cluster corresponds to the ‘other’ category,
and it mistakenly includes process variables from the ‘gas and
pressure’ category. This might be due to the nature of the
‘other’ category, which mixes process variables of different
types and is less well deﬁned as the ‘gas and pressure’ or the
‘power’ category. Figure 1(b) shows the comparison results
on 10 wafers, which clearly demonstrates the superiority of
C-Struts over the competitors.
B. Benchmark Data
Although the proposed C-Struts algorithm is designed for
semiconductor manufacturing, it can also be used in other
applications. In this subsection, we test its performance on

1124

R EFERENCES

all data sets in the ‘data1’ category from UCR Time Series
Classiﬁcation/Clustering Page1 . To be speciﬁc, we use the
known classes in these data sets to form the row clusters,
and form the column clusters based on various sampling
frequencies. We compare all the methods in terms of the
Jaccard index values associated with both row and column
clustering at various sampling frequencies, and present the
results in Figure 2. From these ﬁgures, we can see that the
performance of C-Struts is better than the others in most cases.

(a) Clustering results using C-Struts.

[1] D. Chakrabarti, S. Papadimitriou, D. S. Modha, and C. Faloutsos. Fully automatic cross-associations. In KDD, pages 79–88,
2004.
[2] H. J. Chang, D. Sung, P. J. Kim, and J. Y. Choi. Spatiotemporal pattern modeling for fault detection and classiﬁcation in
semiconductor manufacturing. IEEE Trans. on Semiconductor
Manufacturing, 25:72–82, 2012.
[3] Y. Chen, B. Hu, E. J. Keogh, and G. E. A. P. A. Batista. Dtw-d:
time series semi-supervised learning from a single example. In
KDD, pages 383–391, 2013.
[4] I. S. Dhillon, S. Mallela, and D. S. Modha. Informationtheoretic co-clustering. In KDD, pages 89–98, 2003.
[5] B. Gao, T.-Y. Liu, X. Zheng, Q. Cheng, and W.-Y. Ma. Consistent bipartite graph co-partitioning for star-structured high-order
heterogeneous data co-clustering. In KDD, pages 41–50, 2005.
[6] J. He, H. Tong, S. Papadimitriou, T. Eliassi-Rad, C. Faloutsos,
and J. Carbonell. Pack: Scalable parameter-free clustering
on k-partite graphs. In SDM Workshop on Link Analysis,
Counterterrorism and Security, 2009.
[7] B. Hu, Y. Chen, and E. J. Keogh. Time series classiﬁcation
under more realistic assumptions. In SDM, pages 578–586,
2013.
[8] A. Johnson and S. McLoone. A dynamic sampling methodology
for within product virtual metrology. In 29th International
Manufacturing Conf., 2012.
[9] D. Kurz, C. D. Luca, and J. Pilz. Monitoring virtual metrology
reliability in a sampling decision system. In Conf. on Automation Science and Engineering, 2013.
[10] L. Li and B. A. Prakash. Time series clustering: Complex is
simpler! In ICML, pages 185–192, 2011.
[11] B. Long, Z. M. Zhang, X. Wu, and P. S. Yu. Spectral clustering
for multi-type relational data. In ICML, pages 585–592, 2006.
[12] S. C. Madeira and A. L. Oliveira. Biclustering algorithms for
biological data analysis: A survey. IEEE/ACM Trans. Comput.
Biology Bioinform., 1(1):24–45, 2004.
[13] G. Newell, N. Bekhazi, and R. Morgan. Optimizing storage
and i/o for distributed processing on enterprise and high performance compute (hpc) systems for mask data preparation
software (cats). Technical report, Synopsys, Inc., 2007.
[14] S. Papadimitriou, J. Sun, and C. Faloutsos. Streaming pattern
discovery in multiple time-series. In VLDB, pages 697–708,
2005.
[15] T. Rakthanmanon, B. J. L. Campana, A. Mueen, G. E. A. P. A.
Batista, M. B. Westover, Q. Zhu, J. Zakaria, and E. J. Keogh.
Searching and mining trillions of time series subsequences
under dynamic time warping. In KDD, pages 262–270, 2012.
[16] T. Rakthanmanon, B. J. L. Campana, A. Mueen, G. E. A. P. A.
Batista, M. B. Westover, Q. Zhu, J. Zakaria, and E. J. Keogh.
Searching and mining trillions of time series subsequences
under dynamic time warping. In KDD, pages 262–270, 2012.
[17] J. Sun, C. Faloutsos, S. Papadimitriou, and P. S. Yu. Graphscope: parameter-free mining of large time-evolving graphs. In
KDD, pages 687–696, 2007.
[18] R. Tibshirani. Regression shrinkage and selection via the lasso.
Journal of the Royal Statistical Society (Series B), 58:267–288,
1996.
[19] L. Wei, E. J. Keogh, X. Xi, and M. Yoder. Efﬁciently ﬁnding
unusual shapes in large image databases. Data Min. Knowl.
Discov., 17(3):343–376, 2008.
[20] B.-K. Yi, N. Sidiropoulos, T. Johnson, H. V. Jagadish, C. Faloutsos, and A. Biliris. Online data mining for co-evolving time
sequences. In ICDE, pages 13–22, 2000.
[21] J. Zakaria, A. Mueen, and E. J. Keogh. Clustering time series
using unsupervised-shapelets. In ICDM, pages 785–794, 2012.
[22] H. Zou and T. Hastie. Regularization and variable selection via
the elastic net. Journal of the Royal Statistical Society: Series
B (Statistical Methodology), 67(2):301–320, 2003.

(b) Comparison results

Fig. 1: Clustering results on semiconductor data set.
Furthermore, we provide the collective comparison results
of C-Struts and CLDS in Figure 3. From this ﬁgure, we can
see that the proposed C-Struts algorithm outperforms CLDS
in the majority of the data sets. The results of K-Means are
omitted due to the similarity with Co-clustering.

Fig. 3: Comparison of C-Struts and CLDS on all data sets in
the ‘data1’ category.
V. C ONCLUSION
In this paper, motivated by semiconductor manufacturing,
we study a novel problem of co-clustering structural temporal
data. In this problem, we are given as input a two-dimensional
array consisting of multiple time series, and the goal is to
simultaneously cluster both the rows and the columns. This
problem is different from traditional time series clustering,
which targets unstructured time series data, and multi-way
clustering, which assumes the input matrix consists of scalers.
To address this problem, we propose a general framework
named C-Struts. It interprets the structural information as
constraints on the cluster membership, and uses an auxiliary probability distribution to obtain prototypes for each
row/column cluster. We also present an iterative algorithm
to assign each time series to the closest row/column cluster
based on the distance to the prototypes. Experimental results
on various data sets demonstrate the effectiveness of C-Struts.
1 http://www.cs.ucr.edu/∼eamonn/time_series_data/

1125

(a) 50words

(b) Two Patterns

(c) Beef

(d) MedicalImages

(e) WordsSynonyms

(f) CinC ECG torso

(g) Symbols

(h) Cricket X

(i) Cricket Y

(j) Cricket Z

(k) DiatomSizeReduction

(l) OSULeaf

(m) SwedishLeaf

(n) FISH

(o) FaceAll

(p) yoga

(q) FacesUCR

(r) Trace

(s) Haptics

(t) InlineSkate

Fig. 2: Comparison on a subset of benchmark data sets.

1126

Mean Version Space: a New Active Learning Method
for Content-Based Image Retrieval*
Jingrui He1, Mingjing Li2, Hong-Jiang Zhang2, Hanghang Tong1, Changshui Zhang3
1,3

1

Department of Automation, Tsinghua University, Beijing 100084, China
2
Microsft Research Asia, 49 Zhichun Road, Beijing 100080, China

{hejingrui98, walkstar98}@mails.tsinghua.edu.cn, 2{mjli, hjzhang}@microsoft.com
3
zcs@tsinghua.edu.cn

ABSTRACT

1. INTRODUCTION

In content-based image retrieval, relevance feedback has been
introduced to narrow the gap between low-level image feature and
high-level semantic concept. Furthermore, to speed up the
convergence to the query concept, several active learning methods
have been proposed instead of random sampling to select images
for labeling by the user. In this paper, we propose a novel active
learning method named mean version space, aiming to select the
optimal image in each round of relevance feedback. Firstly, by
diving into the lemma that motivates support vector machine
active learning method (SVMactive), we come up with a new
criterion which is tailored for each specific learning task and will
lead to the fastest shrinkage of the version space in all cases. The
criterion takes both the size of the version space and the posterior
probabilities into consideration, while existing methods are only
based on one of them. Moreover, although our criterion is
designed for SVM, it can be justified in a general framework.
Secondly, to reduce processing time, we design two schemes to
construct a small candidate set and evaluate the criterion for
images in the set instead of all the unlabeled images. Systematic
experimental results demonstrate the superiority of our method
over existing active learning methods.

The last few decades witnessed an explosion in the volume of
digital images, which necessitates an efficient scheme for
browsing and indexing large image databases. To address this
issue, people have proposed an integrated framework named
content-based image retrieval (CBIR). In the framework, firstly,
each image is mapped to a point in the feature space by extracting
low-level image features, which can be categorized into color [2, 7,
14], texture [3, 4, 19], shape [11, 12, 23], etc; secondly, given a
query in terms of image examples, the framework then retrieves
images based on their features. *
It is widely accepted that the major bottleneck of CBIR systems is
the large gap between low-level image features and high-level
semantic concepts, which prevents the systems from being applied
to real applications [10]. To be specific, images of dissimilar
semantic content may share some common low-level features,
while images of similar semantic content may be scattered in the
feature space. Despite the great deal of research work dedicated to
the exploration of an ideal descriptor for image content, no single
feature or feature combination can achieve satisfactory
performance up till now.
To narrow or bridge the gap, relevance feedback, an efficient
online learning technique borrowed from the field of information
retrieval, has been introduced to CBIR since the 1990’s [10]. In
each round of relevance feedback, the user will judge the
relevance of some database images, and the system will update its
retrieval result according to these newly obtained labeled
examples. Two most important factors in relevance feedback are
the image selection strategy and the learning method [10, 16].

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications – image
databases; H.3.3 [Information Storage and Retrieval]:
Information Search and Retrieval – relevance feedback, search
process.

General Terms

The learning method in relevance feedback has been extensively
studied. Traditional learning methods can be categorized into three
major groups [9]: query reweighting, query point movement, and
query expansion. However, because these methods do not fully
utilize the information embedded in feedback images, their
performance is far from satisfactory. More recently, statistical
learning methods have been applied to relevance feedback.
Among others, some researchers apply inductive methods to the
learning task, aiming to create a classifier that generalizes well on
unseen examples. For example, the authors of [15] first compute a
large number of highly selective features, and then use boosting to
learn a classification function in this feature space; similarly, the
learning method proposed in [22] trains a support vector machine
(SVM) from labeled examples, hoping to obtain a small

Algorithms, Experimentation, and Theory.

Keywords
Content-based image retrieval, relevance feedback, active learning,
version space

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that
copies bear this notice and the full citation on the first page. To copy
otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee.
MIR’04, October 15-16, 2004, New York, New York, USA.
Copyright 2004 ACM 1-58113-940-3/04/0010...$5.00.

*

15

This work was performed at Microsoft Research Asia.

5,000 Corel images validate the superiority of our method over
existing ones.

generalization error by maximizing the margin between the two
classes of images. On the other hand, some researchers consider
image retrieval as a transductive learning problem, aiming to
accurately predict the relevance of unlabeled images attainable
during the training stage. For example, the authors of [21] propose
a discriminant-EM algorithm. It makes use of unlabeled data to
construct a generative model, which will be used to measure
relevance between the query and database images.

The paper is organized as follows. In Section 2, we analyze the
limitation of SVMactive, propose our mean version space criterion
for active learning in detail, and examine it under a general
framework. The two schemes for speeding up the evaluation
process are presented in Section 3. We provide systematic
experimental results to evaluate the proposed active learning
method from various aspects in Section 4. Finally, we conclude
the paper in Section 5.

In contrast, there is not so much work dealing with image
selection strategy. A good strategy should select the most
informative images in each round of relevance feedback, thus the
user only need to label a small number of images before the
system learns the query concept. The simplest selection strategy is
random sampling. However, since the selected images to be
labeled by the user often convey little information for improving
present retrieval result, a large number of images have to be
labeled before the system achieves satisfactory performance,
which runs counter to our original intention [16]. A more
reasonable choice is to select the most relevant images, the
motivation behind which is to ask the user to validate the
judgment of the current system on image relevance. However,
from the classification point of view, these images may not be
sufficient to train an accurate classifier. More recently, the authors
of [16, 17] propose a support vector machine active learning
method as the image selection strategy, and prove that, for a given
number of queries, it minimizes the maximum expected size of the
version space, where the maximum is taken over all conditional
distributions of image label given its low-level feature. However,
in practice, people have found that SVMactive often leads to slow
convergence to the target concept [20], and its performance is
sometimes not as good as that of the most relevant strategy.
Another example is the active learning method using preclustering proposed in [6], which takes into account the prior data
distribution. It makes two assumptions: (1) all the clusters have
the shape of hyper-spheres in the feature space; (2) given the
cluster label, the data and its class label are independent. However,
in the context of image retrieval, both of them may be violated due
to the complex distribution of low-level image features.
Furthermore, the method is restricted to linear logistic regression
to model the distribution of cluster labels, which may not be
powerful enough for image retrieval tasks.

2. MEAN VERSION SPACE ACTIVE
LEARNING
2.1 Notations and Assumptions
In this paper, we adopt SVM [18] as the learning method in
relevance feedback. Given a set of labeled examples
xk , k = 1,K, M , xk ∈ R N
,
and
their
labels
yk , k = 1,K , M , yk ∈ {−1, 1} ( M is the total number of labeled

examples), a Mercer kernel K implicitly defines a mapping
Φ : R N → F . In the feature space F , there are a set of
hyperplanes that separate the examples. These hyperplanes are
called the version space [5], which is formally defined as follows
[17]:

DEFINITION 1. The version space

{

V = w ∈W

w = 1, yk ( w ⋅ Φ ( xk ) ) > 0, k = 1,K, M

}

(1)

where the parameter space W is equal to F .
In the version space, SVM selects the hyperplane that maximizes
the margin in F , i.e. the optimal parameter

{

}

w* = arg max min yk ( w ⋅ Φ ( xk ) )
w∈W

k

(2)

Here we only consider unbiased SVM classifier, i.e., the optimal
separating hyperplane is chosen from the hyperplanes that pass
through the origin. Intuitively, this limitation might bring about
performance degradation since it only covers a small subset of all
possible hyperplanes that separate the examples. We will come
back to this issue in subsection 2.3.

In this paper, we aim to improve SVMactive from a theoretical point
of view. Firstly, by diving into the lemma that motivates SVMactive,
we draw a conclusion that the inferiority of SVMactive may be
attributed to the fact that it considers the supremum of all learning
tasks, while ignoring their specialty. Then we propose a new
criterion for active learning which is tailored for each specific
learning problem. The criterion guarantees that after selecting a
single image, the mean version space will be maximally shrinked.
As we will show in Section 2, the criterion takes both the size of
the version space and the posterior probabilities into consideration,
while SVMactive and the most relevant strategy are only based on
one of them. Our criterion is justified with both unbiased and
biased SVM classifiers. Moreover, although our criterion is
designed for SVM, it can be justified in a general framework.
Secondly, since the evaluation of the proposed criterion over the
entire database may be very time-consuming, and the response
time of a CBIR system is of key importance, we propose two
simple schemes to limit the candidate images. Systematic
experiments on a general-purpose image database consisting of

Let Area (V ) denote the surface area that the version space V
occupies on the hypersphere w = 1 [17]. Given an active learner
l , let Vi denote the version space of l after i queries have been
made, while Vi + ( xk ) and Vi − ( xk ) denote the version space after
the ( i + 1) th query xk is labeled as 1 and -1 respectively.
Note that the version space exists only if the training examples are
linearly separable in the feature space F . Since the number of
labeled examples is usually very small compared with the
dimensionality of F , we make a reasonable assumption that the
relevant and irrelevant images previously marked by the user can
be separated by a hyperplane in F . As in [17], we also require
that the examples have constant modulus in F , i.e. Φ ( xk ) = λ .
This requirement has no effect on radial basis function (RBF)

16

(

kernel K ( u , v ) = exp − u − v

)

2

To obtain the criterion for each unlabeled example, we need to
calculate both the size of version space Vi + ( xk ) , Vi − ( xk ) and the

σ 2 ; while for polynomial kernel

K ( u , v ) = ( u ⋅ v + 1) , it requires that xk be constant.
p

posterior probabilities. It has been pointed out in [17] that it is not
practical to explicitly compute the former term. Since there exists a
duality between the feature space F and the parameter space W ,
and the examples have constant modulus in F (the assumption
mentioned in subsection 2.1), a reasonable way to approximate
Vi + ( xk ) and Vi − ( xk ) is as follows [17]: add xk to the positive

2.2 Mean Version Space
The lemma that motivates SVMactive is as follows [17]:

LEMMA 1. Suppose we have finite dimensional feature space F .
Suppose active learner l * always queries instances whose
corresponding hyperplanes in parameter space W halve the area
of the current version space. Let l be any other active learner.
Denote the version spaces of l * and l after i queries as Vi* and

example set, retrain SVM to obtain its margin m + ( xk ) , which is
used as an indication of the size of Vi + ( xk ) ; add xk to the negative
example set, retrain SVM to obtain its margin m − ( xk ) , which is

Vi respectively. Let Ρ denote the set of all conditional
distributions of y given x . Then

∀i ∈

+

sup EP  Area (Vi* )  ≤ sup EP  Area (Vi ) 
P∈Ρ

used as an indication of the size of Vi − ( xk ) .
On the other hand, the calculation of the posterior probabilities
should be based on SVM trained on present labeled examples, which
provides an estimation of the true probabilities. Since SVM outputs
uncalibrated values, we need to convert the outputs to probabilities.
In [8], the authors describe an intuitive way for such conversion, i.e.

(3)

P∈Ρ

with strict inequality whenever there exists a query j ∈ {1,K , i} by
l that does not halve version space V j −1 .

P( y = 1 f ) =

The lemma implicitly assumes that the criterion for selecting
examples in SVMactive is:
cSVM ( xk ) = Area (Vi + ( xk ) ) − Area (Vi − ( xk ) )

consistent with our intuition. When the number of labeled images
used for fitting this sigmoid function is very small, we may add some
top-ranked (say, the first 20) images to the positive set and some
bottom-ranked (say, the last 20) images to the negative set.
When an example is far from the boundary, i.e., it has a large value
for f , if it is selected and assigned with the label predicted by the
current classifier, the version space will shrink a little; if it is
assigned with the opposite label, the size of the version space will be
greatly reduced. However, since f is large, its posterior probability

Before presenting our own criterion for selecting examples, we
would like to reiterate the goal for designing an active learning
strategy combined with SVM, i.e., to maximally shrink the version
space after each selected example is labeled by the user, since a
small version space will guarantee that the predicted hyperplane
lies close to the optimal one constructed when all the images have
their labels. Quite naturally, we define the criterion as the
expectation of the size of the version space after an unlabeled
example xk has been labeled. To be specific,

Area (Vi

( xk ) ) P ( yk = 1 xk ) +
( xk ) ) P ( yk = −1 xk )

of having the opposite label will be very small, which causes its
criterion value to be large. On the other hand, when an example is
within the margin, if it is selected and marked by the user, no matter
what label it obtains, the version space will be reduced considerably,
and the criterion value tends to be small. However, there is no
guarantee that the examples on or near the separating hyperplane
will be selected with the smallest criterion value, as in SVMactive,
which reflects the difference between the two methods.
At the end of this subsection, we would like to derive the criterion of
the most relevant strategy for theoretical comparison among the
three image selection strategies:

+

−

(6)

where f is the output of SVM, while A and B are real-valued
parameters determined by maximum likelihood estimation. As long
as A < 0 , P ( y = 1 f ) is an increasing function of f , which is

(4)

SVMactive then selects the example with the smallest cSVM in each
round of relevance feedback. Due to practical difficulty in
computing the size of the version space, the method finally takes
on the closest-to-boundary criterion to select examples [16, 17].
Note that according to Lemma 1, SVMactive is optimal in the
supremum sense. However, for a specific learning task where P is
fixed, the above lemma cannot guarantee that SVMactive maximally
shrinks the version space. This may partially explain why
SVMactive often brings about slow convergence to the target
concept, and its performance is sometimes not as good as that of
the most relevant strategy.

cMVS ( xk ) = Area (Vi

1
1 + exp ( Af + B )

(5)

cMR = − f

*

(7)

The example with the smallest cMR will be selected in each round of
relevance feedback. As aforementioned, the posterior probabilities
are determined by f . Therefore, this criterion can be considered as
a function of the posterior probabilities. Note that the criterion of
SVMactive is only based on the size of the version space. Nevertheless,
the mean version space criterion takes both the two factors into
account, thus may obtain a better performance than these two image
selection criterions.

If we select example x which has the smallest cMVS , the version
space will be maximally shrinked with each round of relevance
feedback. Note that our criterion is tailored for each specific
learning task by considering the posterior probabilities
( P ( yk = 1 xk ) and P ( yk = −1 xk ) ), in contrast to SVMactive,
which ignores this information and is optimal only in the
supremum sense.

17

When we use SVM, the generalization error can be evaluated by
means of the margin size: the smaller the margin is, the less possible
the constructed classifier with the newly labeled example will make
a mistake when predicting the label of an unlabeled example. This
argument seems to be contradictory with our common knowledge
that a hyperplane with a large margin tends to have a smaller
generalization error. The difference here is that we compare the
different OPTIMAL hyperplanes obtained using different training
sets. Note that a small margin means that the current hyperplane is
close to the ideal one, thus the generalization error tends to be small
accordingly. This conclusion is consistent with [13] in which a “best
worst-case” model is used to induce the closest-to-boundary
criterion for active learning. By replacing the two generalization
error terms in Equation 12 by m + ( xk ) and m − ( xk ) , we obtain

2.3 Biased SVM Classifier
Up till now, we have focused on unbiased SVM classifier, i.e.,
f ( x) = w ⋅ Φ ( x)

(8)

However, as discussed in subsection 2.1, its performance might not
be as good as that of biased SVM classifier, which can be written as
f ( x ) = w ⋅ Φ ( x ) +b

(9)

Note that its parameter space W ′ has one more dimension than W
incurred by b , the translation factor. Therefore, the duality no
longer exists between the feature space F and the parameter space
W ′ , which adds difficulties to the analysis of the version space.
However, we can still use Equation 5 as the criterion to select
examples in each round of relevance feedback except that the terms
Area (Vi + ( xk ) ) and Area (Vi − ( xk ) ) must be replaced by the

Equation 10.

3. ACCELERATING THE EVALUATION
PROCESS

margins m + ( xk ) and m − ( xk ) respectively, since the concept of the
version space is not considered in this case, i.e.

cMVS ( xk ) = m + ( xk ) P ( yk = 1 xk )

+ m − ( xk ) P ( yk = −1 xk )

One major problem with the proposed mean version space active
learning method is that evaluating each unlabeled example requires
solving two quadratic programming (QP) problems. When there are
a lot of unlabeled examples, say many thousands, the processing
time for selecting even a single one for the user to label is unbearable.
Therefore, we need to design an efficient as well as effective
acceleration scheme.

(10)

The reason for applying the above criterion to biased SVM classifier
can be explained as follows: when the examples are linearly
separable in the feature space F , labeling an example and adding it
to the training set will cause the margin to decrease or to remain the
same; when we finally obtain the ideal separating hyperplane, its
margin will be the smallest in the entire training process. From this
point of view, the most efficient way of selecting examples in each
round of relevance feedback would be to select the ones which will
maximally reduce the margin.

One way to reduce the processing time is to limit the scope of
candidate examples. As has been discovered by the authors of [13], a
point’s location with respect to the labeled examples has a large
effect on how labeling it influences the hyperplane. Here we use a
similar example as in [13] to explain our idea, which is illustrated in
Figure 1. As explained in subsection 2.2, the examples within the
margin tend to have a small criterion value. Here, we assume that
the selected examples lie within the margin for simplicity.

2.4 Mean Version Space Active Learning in a
General Framework
It is widely accepted that active learning should select examples that
minimize the expected future classification error [1]:

∫ E ( yˆ − y )

2

x

x  p ( x ) dx


(11)
(a) Unlabeled example far away from labeled ones

where y is the true label of x , ŷ is the label predicted by the
updated classifier, and E . x  denotes the expectation over

P( y x) .

Equation 11 can be considered as the generalization error of the
updated classifier. In a binary classification problem, given an
unlabeled example xk , the expected generalization error after xk is
labeled by the user can be expressed as follows:

Error ( xk ) = ∫ E ( yˆ + − y )

x
2
+ ∫ E ( yˆ − − y )
x


2

x  p ( x ) dx P ( yk = 1 xk )

x  p ( x ) dx P ( yk = −1 xk )


(b) Unlabeled example near labeled ones

Figure 1. The location of a selected example will largely affect
the change in the separating hyperplane. “+” denotes a
positive example, “-” denotes a negative example, and “o”
denotes the selected unlabeled example. The dashed line is the
old separating hyperplane; the solid line is the new hyperplane
if the unlabeled example is given label -1; the area between the
two dotted lines is the margin.

(12)

where ŷ + and ŷ − denote the predicted label after xk has been
labeled
1
and
-1
respectively.
Accordingly,
2
2
+
−




∫x E ( yˆ − y ) x  p ( x ) dx and ∫x E ( yˆ − y ) x  p ( x ) dx are the
generalization errors in those two cases.

As we can see from Figure 1, an unlabeled example in the near
neighborhood of labeled ones tends to change the separating
hyperplane greatly, while an unlabeled example far away from any
labeled example will bring little change to the placement of the

18

Before the retrieval process, we need to construct a feature vector
to represent each image. Feature selection is a large open problem
and might have a great impact on the results. In our current
implementation, the feature vector is simply made up of color
histogram [14] and wavelet feature [19] since we focus on the
relative performance comparison. Color histogram is obtained by
quantizing the HSV color space into 64 bins. To calculate the
wavelet feature, we first perform 3-level Daubechies wavelet
transform to the image, and then calculate the first and second
order moments of the coefficients in High/High, High/Low, and
Low/High bands at each level, thus obtain an 18-dimensional
feature. We will leave the problem of selecting the optimal feature
combination to future work.

hyperplane. Furthermore, in the context of CBIR, the number of
labeled images is very small in most cases. Thus the estimated
posterior probabilities with respect to the relevance to the user’s
query concept is relatively more accurate for examples in the
neighborhood of labeled ones than those far away from any
labeled example.
Based on the above two observations, we limit the scope of
candidate examples to those nearest to the labeled ones. However,
in practice, it is hard to define the nearest neighbors with respect
to the labeled set, and the nearest neighbor search itself might be
time-consuming. To address this issue, we design two simple
schemes to construct the candidate set:
Using the S most relevant images;

4.2 Evaluation of the Criterion

Using the S images closest to the separating hyperplane.

To compare the proposed mean version space criterion with that of
SVMactive and the most relevant strategy, we design the following
experiment: given the query image, in the first round of relevance
feedback, the system selects 10 images and asks the user for their
labels; while in subsequent rounds of relevance feedback, only one
image will be selected. Note that in the first round of relevance
feedback, since there is only one positive example (the query
image) and no negative one, no classifier is constructed and the
system always presents the most relevant images to the user. We
calculate the average P20 1 of mean version space (MVS),
SVMactive, and the most relevant strategy (MR) after each round of
relevance feedback, and compare their results in Figure 2 and
Figure 3.

The rationality of the two schemes can be explained as follows:
the first scheme selects the examples that are close to the positive
ones, while the second scheme selects the examples that are close
to the support vectors. On the other hand, the two schemes can be
considered as using SVMactive and the most relevant strategy for
rough selection, followed by the mean version space criterion for
further improvement.
To choose a proper value for S , we first sort all the unlabeled
images according to the first/second scheme, and then calculate
CMVS for the images one by one. The evaluation process stops if
one of the following conditions is satisfied:

CMVS of the present image is twice as large as the minimum
value that has ever been reached;

In our experiments, for fair comparison, we adopt the polynomial
kernel with p = 1 in SVM 2 (as in [17]), and construct both
unbiased (Figure 2) and biased SVM (Figure 3) to obtain the
separating hyperplane. The conclusion is the same: our mean
version space criterion outperforms both SVMactive and the most
relevant strategy, which is consistent with the theoretical analysis.
Take Figure 3 as an example, where we use biased SVM to learn
the query concept. After the fifth round of relevance feedback,
P20 using MVS is 0.268, using SVMactive 0.244, and using MR
0.251.

The minimum value of CMVS remains unchanged for 10 images.
Finally, the image with the minimum value of CMVS is selected to
be labeled by the user. In our experiments, the value of S is
always no more than 1% of the whole database when either of the
conditions is satisfied, therefore, the processing time for
evaluating the criterion value is greatly reduced.
To sum up, in each round of relevance feedback, the mean version
space active learning method performs the following operations:

It is interesting to note that in Figure 3, after the second round of
relevance feedback, both SVMactive and MR bring significant
degradation to the performance although more labeled examples
are available. However, when we use MVS to select images, no
significant degradation in performance is observed; after the
second round of relevance feedback, P20 is consistently improved.

1. Construct a candidate set using one of the two schemes, and
select the image with the smallest criterion value in the set to
be labeled by the user;
2. Update the SVM classifier using the newly obtained labeled
example.

4.3 The Candidate Set

4. EXPERIMENTAL RESULTS

The processing time of both SVMactive and MR is very short, since
they only need to construct one classifier in each round of
relevance feedback. However, in the original form of MVS, we
need to construct two classifiers for each unlabeled example,
which results in a very long processing time.

4.1 Parameters and Operation Settings
To test the performance of the proposed mean version space active
learning method, we perform systematic experiments on a generalpurpose image database consisting of 5,000 Corel images. The
database is made up of 50 categories, such as beach, bird,
mountain, jewelry, sunset, etc. Each of the categories contains 100
images of essentially the same content, which serve as the
groundtruth. In our experiments, we use each image in the whole
database as a query, and average the results over the 5,000 queries.
Unless otherwise stated, the precision vs. rounds of feedback
curve is used to evaluate the performance of various methods.

19

1

The reason for using P20 to compare the performance of
different methods is that with many search engines, the first 20
images can be displayed in one page.

2

Lemma 1 requires that the feature space F is finite dimensional.
Polynomial kernel satisfies this requirement, while RBF kernel
does not [17].

In this subsection, we will evaluate MVS with the acceleration
schemes when the next example to be labeled by the user is
chosen from a small candidate set. As in the previous subsection,
the system returns ten images for the user to label in the first
round of relevance feedback, and returns only one image in
subsequent rounds. Again, we use average P20 to compare the two
simple schemes with the original method, and present their results
in Figure 4 and Figure 5. (MVS denotes the original method,
MVS(CB) denotes the scheme that selects the images closest to
the boundary, while MVS(MR) denotes the scheme that selects
the most relevant images)

0.27
MVS
SVM_active
MR

0.26

Precision

0.25
0.24
0.23
0.22
0.21
0.2

Obviously, P50 of MVS(MR) is nearly identical with that of MVS,
while P20 of MVS(CB) is inferior to both of them. The reason
might be explained as follows: positive examples are often
surrounded by negative ones, thus the most relevant images
always lie in the neighborhood of those positive examples. On the
other hand, with MVS(CB), we cannot guarantee that any selected
example is in the neighborhood of labeled ones. Based on
experimental results, we will use MVS(MR) as the acceleration
scheme in subsequent experiments.

1

2

3

4

5

Relevance Feedback

Figure 2. Performance comparison (unbiased SVM).

0.27
MVS
SVM_active
MR

0.26

The advantage of using a small candidate set is a great reduction
in processing time. In Table 1, we compare the average processing
time of SVMactive, MR, MVS and MVS(MR) in the second round
of relevance feedback (Pentium 4 1.80GHz, 512M RAM).
Obviously, when we use the candidate set, the processing time
reduces to the same magnitude as that of SVMactive and MR.
Furthermore, the original method which evaluates the criterion for
all the unlabeled images does not scale well; however, in the
accelerated version, the processing time is mainly determined by
S , which has no direct relationship with the size of the database.

Precision

0.25
0.24
0.23
0.22
0.21
1

2

3

4

5

Relevance Feedback

Table 1. Comparison of processing time
Seconds

SVMactive

MR

MVS

MVS (MR)

0.031

0.031

2.264

0.055

Figure 3. Performance comparison (biased SVM).

0.27

4.4 Feedback with Multiple Images

MVS
MVS (CB)
MVS (MR)

0.26

Although our analysis is for the case where only one example is
labeled by the user in each round of relevance feedback, the mean
version space active learning method also generalizes well when
multiple images are labeled in each round. Figure 6 and Figure 7
compare the precision vs. scope curve of various methods after the
fourth and fifth rounds of relevance feedback respectively, with
ten images labeled by the user in each round. Note that the trained
classifier is biased SVM with polynomial kernel ( p = 5 ).

Precision

0.25
0.24
0.23
0.22
0.21

From the comparison results we can see that when multiple images
are fed back in each round, the performance of SVMactive is much
worse than that of MR, while MVS consistently outperforms both
MR and SVMactive. For example, after the fourth round of
relevance feedback (Figure 6), P20 using MVS is 0.464, using
MR 0.448, and using SVMactive 0.364; while after the fifth round
of relevance feedback (Figure 7), P20 using MVS is 0.537, using
MR 0.515, and using SVMactive 0.420.

1

2

3

4

5

Relevance Feedback

Figure 4. Performance comparison (unbiased SVM, the curve
of MVS is overlapped by that of MVS(MR)).

We have also performed experiments with the RBF kernel. Again
MVS outperforms both SVMactive and MR no matter what value
σ takes.

20

justified with both unbiased and biased SVM classifiers, and can
be fitted in a general active learning framework. Furthermore, to
reduce the processing time, we design two schemes to construct a
candidate set in each round of relevance feedback and select
images from this set. This operation is based on the observation
that the location of the selected unlabeled example will affect the
change in the separating hyperplane and also the accuracy of the
posterior probabilities. We have evaluated the effectiveness of the
mean version space method from various aspects by means of
systematic experiments, which validate the advantage of our
method over existing ones.

0.27
MVS
MVS (CB)
MVS (MR)

0.26

Precision

0.25
0.24
0.23
0.22
0.21
1

2

3

4

6. ACKNOWLEDGMENTS

5

This work was supported by National High Technology Research
and Development Program of China (863 Program) under contract
No.2001AA114190.

Relevance Feedback

Figure 5. Performance comparison (biased SVM, the curve of
MVS is overlapped by that of MVS(MR)).

7. REFERENCE
0.7
MVS
SVM_active
MR

0.6

[1]

Cohn, D.A., Ghahramani, Z., and Jordan, M.I. Active
learning with statistical models. Journal of Artificial
Intelligence Research, vol. 4, pp. 129-145, 1996.

[2]

Huang, J., et al. Image indexing using color correlograms.
Proc. IEEE Conf. on Computer Vision and Pattern
Recognition, pp. 762-768, 1997.

[3]

Liu, F., and Picard, R.W. Periodicity, directionality, and
randomness: Wold features for image modeling and retrieval.
IEEE Trans. on Pattern Analysis and Machine Intelligence,
vol. 8, 1996.

[4]

Manjunath, B.S., and Ma, W.Y. Texture features for
browsing and retrieval of image data. IEEE Trans. on
Pattern Anaysis and Machine Intelligence, vol. 18, pp. 837842, 1996.

[5]

Mitchell, T. Generalization as search. Artificial Intelligence,
vol. 28, pp. 203-226, 1982.

[6]

Nguyen, H.T., Smeulders, A. Active learning using preclustering. Proc. 21th Int. Conf. on Machine Learning, 2004.

[7]

Pass, G. Comparing images using color coherence vectors.
Proc. 4th ACM Int. Conf. on Multimedia, pp. 65-73, 1997.

[8]

Platt, J.C. Probabilistic outputs for support vector machines
and comparisons to regularized likelihood methods.
Advances in Large Margin Classifiers, MIT Press, 1999.

[9]

Porkaew, K., and Chakrabarti, K. Query refinement for
multimedia similarity retrieval in MARS. Proc. 7th ACM Int.
Conf. on Multimedia, pp. 235-238, 1999.

Precision

0.5
0.4
0.3
0.2
0.1
10

20

30

40

50
60
Scope

70

80

90

100

Figure 6. Performance comparison after the fourth round of
relevance feedback.
0.7
MVS
SVM_active
MR

Precision

0.6

0.5

0.4

0.3

0.2
10

20

30

40

50
60
Scope

70

80

90

[10] Rui, Y., et al. Relevance feedback: a power tool for
interactive content-based image retrieval. IEEE trans.
Circuits and Systems for Video Technology, 1998.

100

Figure 7. Performance comparison after the fifth round of
relevance feedback.

[11] Schimid, C. A structured probabilistic model for recognition.
Proc. IEEE Conf. on Computer Vision and Pattern
Recognition, vol. 2, pp. 490, 1999.

5. CONCLUSION

[12] Schmid, C., and Mohr, R. Local grayvalue invariants for
image retrieval. IEEE Trans. on Pattern Analysis and
Machine Intelligence, vol. 19, pp. 530-535, 1997.

In this paper, we have proposed a novel active learning method
named mean version space, which is tailored for each specific
learning task and can maximally shrink the version space. Our
method takes both the size of the version space and the posterior
probabilities into consideration, while SVMactive and the most
relevant strategy are only based on one of them. Our criterion is

[13] Schohn, G., and Cohn, D. Less is more: active learning with
support vector machines. Proc. 17th Int. Conf. on Machine
Learning, pp. 839-846, 2000.

21

[14] Swain, M., and Ballard, D. Color indexing. Int. Journal of
Computer Vision, 7(1): 11-32, 1991.

Daubechies’ wavelets. Int. Journal of Digital Libraries, vol.
1, no. 4, pp. 311-328, 1998.

[15] Tieu, K., and Viola, P. Boosting image retrieval. Proc. IEEE
Conf. on Computer Vision and Pattern Recognition, vol. 1,
pp. 228-235, 2000.

[20] Wang, L., Chan, K.L., and Zhang, Z. Bootstrapping SVM
active learning by incorporating unlabelled images for image
retrieval. Proc. IEEE Conf. on Computer Vision and Pattern
Recognition, vol. 1, pp. 629-634, 2003.

[16] Tong, S., and Chang, E. Support vector machine active
learning for image retrieval. Proc. 9th ACM Int. Conf. on
Multimedia, 2001.

[21] Wu, Y., Tian, Q., and Huang, T. Discriminant-EM
algorithm with application to image retrieval. Proc. IEEE
Conf. on Computer Vision and Pattern Recognition, vol. 1,
pp. 155-162, 2000.

[17] Tong, S., and Koller, Daphne. Support vector machine
active learning with applications to text classification.
Journal of Machine Learning Research, vol. 2, pp. 45-66,
2001.

[22] Zhang, L., Lin, F., and Zhang, B. Support vector machine
learning for image retrieval. Proc. IEEE Int. Conf. on Image
Processing, vol. 2, pp. 721-724, 2001.

[18] Vapnik, V. The Nature of Statistical Learning. Springer,
1995.

[23] Zhou, X.S., Rui, Y., and Huang, T. Water-Filling: a novel
way for image structural feature extraction. Proc. IEEE Int.
Conf. on Image Processing, vol. 2, pp. 570-574, 1999.

[19] Wang, J.Z., Wiederhold, G., Firschein, O., and Sha, X.W.
Content-based image indexing and searching using

22

MI2LS: Multi-Instance Learning from
Multiple Information Sources
Dan Zhang

Jingrui He

Richard D. Lawrence

Facebook Incorporation
Menlo Park, CA

Computer Science
Department
Stevens Institute of
Technology
Hoboken, NJ

Machine Learning Group
IBM T.J. Watson Research
Center
Yorktown Heights, NY

danzhang2008@gmail.com

jingrui.he@gmail.com

ricklawr@us.ibm.com

ABSTRACT

1.

In Multiple Instance Learning (MIL), each entity is normally expressed as a set of instances. Most of the current MIL methods only
deal with the case when each instance is represented by one type of
features. However, in many real world applications, entities are often described from several different information sources/views. For
example, when applying MIL to image categorization, the characteristics of each image can be derived from both its RGB features
and SIFT features. Previous research work has shown that, in traditional learning methods, leveraging the consistencies between different information sources could improve the classification performance drastically.
Out of a similar motivation, to incorporate the consistencies between different information sources into MIL, we propose a novel
research framework – Multi-Instance Learning from Multiple Information Sources (MI2 LS). Based on this framework, an algorithm – Fast MI2 LS (FMI2 LS) is designed, which combines Constraint Concave-Convex Programming (CCCP) method and an adapted Stoachastic Gradient Descent (SGD) method. Some theoretical analysis on the optimality of the adapted SGD method and the
generalized error bound of the formulation are given based on the
proposed method. Experimental results on document classification
and a novel application – Insider Threat Detection (ITD), clearly
demonstrate the superior performance of the proposed method over
state-of-the-art MIL methods.

Traditional learning methods normally treat each example as a
non-separable entity, and represent the example by one feature vector. However, the semantic meanings of each individual example
could vary among its constituent parts, rather than being consistent
throughout the whole content. As one variation of traditional learning methods, Multiple Instance Learning (MIL) [11] has been proposed to solve the label ambiguity problem. In particular, in MIL,
each example/bag is divided into several different parts/instances.
The labels are assigned to the bags, rather than individual instances.
In this way, the features for the desired local object in each example will be less likely affected by its irrelevant parts, and therefore
the learned model can be more accurate. A lot of work has been
done for MIL classification [2, 11, 14, 23, 32, 46] and its variants,
such as outlier detection [44], online learning [3], and ranking [19].
These methods have been widely employed in applications such as
text mining [2], drug design [11], localized content based image
retrieval (LCBIR) [32], human action recognition [1] and market
targeting [46].
Most of the current MIL methods focus merely on solving problems where examples are described by only one set of features.
However, in many real-world applications, examples are often derived from several different information sources/views, and therefore are represented by multiple sets of features. For example, in
webpage classification, each webpage has disparate descriptions
such as in-bound, out-bound links and textual content. In image
retrieval, each image can be described by different kinds of features, such as RGB features, SIFT features [27], and texture features. Different sets of features normally have different statistical
properties. As shown in previous studies in multi-view learning
work [5, 12, 22, 25, 35, 39, 50], by leveraging the consistencies
between different views, the classification performance can be improved. Therefore, designing a MIL algorithm that incorporates
information from multiple sources is also expected to bring in performance improvements.
The existing research in this direction is rare. In [31], the authors did some experiments by using MIL on different views separately and then combined them with equal weights. This method
is straightforward. However, it does not consider the consistencies between different views. On the contrary, in this paper, to
integrate the consistencies into MIL, a novel framework – MultiInstance Learning from Multiple Information Sources (MI2 LS) is
proposed. From the MIL perspective, MI2 LS integrates the nature of the multi-view setting into the MIL framework and impose
the consistencies among multiple views. From multi-view learning perspective, the new formulation explicitly handles the prob-

Categories and Subject Descriptors
I.2.6 [Artificial Intelligence]: Learning – Knowledge acquisition

General Terms
Algorithms, Performance, Experimentation

Keywords
Multi-View Learning, Multi-Instance Learning, Stoachastic Gradient Descent

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD’13, August 11–14, 2013, Chicago, Illinois, USA.
Copyright 2013 ACM 978-1-4503-2174-7/13/08 ...$15.00.

149

INTRODUCTION

lem of label ambiguity through modeling different segments of
examples. More precisely, the new framework aims at designing
classifiers for MIL on individual views and constraining the consistencies between these classifiers simultaneously. Based on the
proposed framework, a concrete optimization formulation is suggested. However, the proposed formulation is non-convex and contains too many constraints derived on both the bag and the instance
levels. Therefore, to solve the resulting optimization problem, we
propose a novel method – Fast MI2 LS (FMI2 LS), which is a combination of Constrained Concave-Convex Procedure (CCCP) and
Stochastic Gradient Descent (SGD). We prove that the proposed
method is guaranteed to converge with some derived convergence
bounds. Furthermore, the generalized error bound of the proposed
method is analyzed. To show the effectiveness and efficiency of the
proposed method, in the experiment part, a series of experiments
are conducted on two benchmark text datasets, Reuters21578, WebKB, as well as a newly introduced application of MIL – Insider
Threat Detection (ITD). In this new application, MIL is employed
to find the potential harmful insiders through analyzing their online
behaviors, where the features during each time period is modeled
as a bag and each bag contains instances derived from daily features. The different views in ITD indicate different types of online
behaviors. Experimental results on this application and the two
text datasets clearly demonstrate the advantages of our proposed
method over state-of-the-art techniques.
The rest of this paper is organized as follows. Section 2 introduces the related work. Section 3 proposes the research problem
and presents the proposed algorithm. Some theoretical analysis are
given in Section 4. Section 5 presents the experimental results.
Section 6 concludes the whole paper.

2.
2.1

and achieved better local solutions [16]. Gärtner et al. [15] put
forward a kernel function directly based on bags. Later, Kwok and
Cheung [24] advanced their work through proposing a marginalized MIL kernel and converting the MIL from an incomplete data
problem to a complete data problem. In [7], the authors revised the
loss functions of single-instance SVM and focus more on the positive bags with smaller sizes. To improve the efficiency of misvm
and MISVM, bundle method is adapted to solve the non-convex
optimization problem [4]. Furthermore, some research work incorporates the MIL constraints into gaussian process [23] and conditional random fields [10]. In [20, 26, 48, 51], the multi-instance
multi-label problem has also attracted a lot of attentions, in which
the labels are not restricted to be binary, but can be a vector. Moreover, some other variants of MIL are also proposed, such as multiinstance outlier detection [44], multi-instance online learning [3]
and multi-instance ranking [19].
The previous research work is reasonable, and solves emerging
MIL problems from different perspectives. However, few of them
considered the case when examples are derived from multiple information sources, while the previous work on traditional single
instance learning methods has demonstrated superior performances
of methods that consider the consistencies between different information sources over the ones that do not. Out of this motivation, the
proposed framework MI2 LS integrates the consistencies between
different sources into a unified framework for MIL, and Fast MI2 LS
is proposed to solve the suggested formulation in an efficient and
effective way.

2.2

Learning with Multiple Information Sources

In a lot of real-world applications, examples are usually extracted
from multiple information sources/views. It has been shown extensively in prior research that utilizing the consistency between
the multiple sources/views could achieve better performance [5,
12, 22, 25, 35, 39, 45, 47, 50]. In particular, one of the earliest
work in multi-view learning is [5], in which the authors propose
the co-training method to solve problems where the examples are
described by two distinct views. In [12], the authors build classifiers on different views and constrain the consistencies between
different classifiers on each individual view. Moreover, they show
that the Rademacher complexity of the function class can also be
greatly reduced by regulating the consistencies.
This idea is further exploited in [25], in which the consistency
term is incorporated into multi-view semi-supervised learning problems, and it has shown a substantial improvement on the classification performance. Likewise, in [47], the authors introduce the consistency into local learning [43] and design a novel way to define
the graph Laplacian. When applied to transfer learning [17, 45],
imposing the consistencies between different views also shows superior performances in transferring the knowledge between different domains. Most existing multi-view learning methods are for the
single instance settings, while MIL problem naturally exists in real
world applications. So, different from the prior work, in this paper,
the view consistency constraint is further applied to MIL problems,
such that the label ambiguity problem in multi-view learning can
be handled in a more principled way.

RELATED WORKS
Multi-Instance Classification

The concept of MIL was first introduced by Dietterich et al.
[11] for predicting musk molecular. Since then, numerous research
work has been done in MIL. Roughly speaking, MIL methods can
be separated into three groups, (1) the group that is specifically designed to solve MIL [11, 29]; (2) the group that converts MIL to
traditional single-instance problems and solve the resulting problem through traditional learning methods [8, 9]. (3) the group that
revises traditional single-instance learning methods by imposing
MIL constraints [2, 7, 15, 16, 23, 24].
For the first group, APR [11], which encloses positive instances
by an axis-parallel rectangle in the feature space, is the first method
to solve MIL problems. Later, Maron and Lozano-Pérez proposed
Diverse Density (DD) [29, 30], which tries to identify the concept point that resembles positive instance most, and classify unlabeled bags according to the distances between the instances in
these bags and this concept point. In [33, 49], the authors accelerated DD method by applying Expectation-Maximization (EM), and
proposed EM-DD.
In the second group, DD-SVM [9] picks a set of prototypes
among the local solutions from DD method returned by different
initializations and then design a large margin classifier based on
the bag level features extracted from these selected prototypes. In
[8], the authors embedded bags into a feature space spanned by
instances, and apply 1-norm SVM to build the bag level classifiers.
Most of the MIL methods fall into the third group. Andrew et
al.[2] proposed two different MIL formulations based on SVM [6],
i.e., misvm for the instance level classification and MISVM for
the bag level classification. Since the MIL formulations are nonconvex, Gehler and Chapelle tried to use deterministic annealing

3.
3.1

THE PROPOSED METHOD
Problem Statement and Notation

Suppose a set of n labeled bags: D = {(Bi , Yi ), i = 1, . . . , n}
are available for training, where Bi represents the i-th bag and
Yi ∈ {1, −1} is its binary label. The bag Bi consists of a set

150

of instances, and each instance is described by different views. In
particular, the p-th view of instances in the i-th bag Bi are denoted
(p)
(p)
(p)
as {Bi1 , . . . , Bini }, p = 1, . . . , M , and Bij ∈ Rdp 1 . dp is
the dimensionality of the p-th view. ni is the number of instances
in the i-th bag and M is the total number of views. The objective of Multi-Instance Learning from Multiple Information Sources
(MI2 LS) is to design a function f : B → {1, −1} by integrating the consistencies between different views into MIL, such that
classification on the unlabeled bags could be accurate.

yond this bound. Then, a concrete formulation can be given as:
min
w(1) ,w(2)

s.t.

2
2
n
n ni
1 X X (p) (p)
1X
C XX
kw(p) k2 +
C ξi +
ηij
2 p=1
n p=1 i=1
N i=1 j=1

∀i ∈ {1, 2, . . . , n}
(1)

(1)

(2)

(2)

Yi max w(1)T Bij ≥ 1 − ξi
j∈ni

Yi max w(2)T Bij ≥ 1 − ξi
j∈ni

∀i ∈ {1, 2, . . . , n}, ∀j ∈ {1, 2, . . . , ni }

3.2

Formulation

(1)

We aim to leverage the instances derived from different information sources (views) and their labels simultaneously. The general
framework of MI2 LS is as follows:

min Ω(w(1) , . . . , w(M ) ) + Lc (D, w(1) , . . . , w(M ) )

w(p)

+ La (D, w(1) , . . . , w(M ) ),

where Ω(w(1) , . . . , w(M ) ) is regularizer that depicts the capacity
of the classifiers on different views, Lc (D, w(1) , . . . , w(M ) ) represents the classification loss on the different views given by the
classifiers, La (D, w(1) , . . . , w(M ) ) measures the consistencies of
the classifiers on different views based on the corresponding classification outputs. Since in MIL the outputs can be measured on both
the instance level and the bag level, La (D, w(1) , . . . , w(M ) ) can
also be defined on the bag level, the instance level or on both of the
two levels. Through incorporating these three components, the proposed framework ensures that the classification on each individual
view should be accurate enough and the output of each individual
instance or bag given by the classifiers on different views should be
consistent.
Following this framework and considering the case when features are derived from two views without the loss of generality
(M = 2), there are multiple ways of formulating the three different terms. For the first part, one of the possible options to define the regularizer, which
P is also the one used in this paper, is
Ω(w(1) , . . . , w(M ) ) = 2p=1 kw(p) k2 . The hinge loss can be applied to Lc (D, w(1) , . . . , w(M ) ) similar to most large marge methods. The -insensitive loss is used to define La (D, w(1) , . . . , w(M ) )2 ,
which requires the inconsistency between different views of each
instance be within  error bound and penalizes the discrepancy be-

(2)

|w(1)T Bij − w(2)T Bij | ≤  + ηij ,
(1)
Pn
where N = i=1 ni , C (1) , C (2) and C are trade-off parameters
tuning the importances on the classification losses on the corresponding views as well as the penalty term that measures the consistencies between different views.
The proposed optimization formulation imposed the view consistency assumption into the framework of MIL in a reasonable
way. However, this is a non-convex optimization problem. So, it
cannot be solved directly. Moreover, in many real world problems,
the numbers of bags and instances are huge, which would result
in a large number of constraints and therefore could drastically increase the computational complexity for solving this problem. To
deal with this optimization problem efficiently and effectively, a
concrete method – Fast MI2 LS (FMI2 LS) is therefore proposed in
the following sections.

3.3

Method

For the convenience of computation, without loss of generality,
we introduce three concatenated vectors as:
e = [w(1)T , w(2)T ]T ,
w
e (2) = [0d1 T , B(2)T ]T ,
e (1) = [B(1)T , 0d2 T ]T , B
B
ij
ij
ij
ij
where 0dp is a 1 × dp zero vector. After this transformation, it
e (p) . Then, problem (1) can be
e (p) = w
eTB
is clear that w(p)T B
ij
ij
converted to the following form:

e
w

2
n
n ni
C XX
1
1 X X (p) (p)
e 2+
kwk
C ξi +
ηij
2
n p=1 i=1
N i=1 j=1

s.t.

∀i ∈ {1, 2, . . . , n}

min

(1)

(1)

(2)

(2)

e
eTB
Yi max w
ij ≥ 1 − ξi
j∈ni

e
eTB
Yi max w
ij ≥ 1 − ξi
j∈ni

∀i ∈ {1, 2, . . . , n}, ∀j ∈ {1, 2, . . . , ni }
1

e (1) − w
e (2) ≤  + ηij
eTB
eTB
w
ij
ij

2

In MI LS, the instances on different views could be derived from
different partition ways and the numbers of instances in the same
bag could be different on different views. Here, we do not consider this case out of simplicity. As we shall see later, the proposed
framework could handle this situation by imposing consistencies
on the bag level.
2
In the proposed method, for simplicity, we only consider the case
when the consistency is defined on the instance level. If the consistency is defined on the bag level, then the last constraint of problem
(1) can be re-written to restrict the differences between the outputs
of each bag on different views in a similar way. The resulting optimization problem can be solved using a similar method as the one
proposed in this paper. If the consistency is defined on both of the
two levels, the constraint can be considered as a combination of the
bag and instance level consistencies.

e (1) − w
e (2) ≥ − − ηij .
eTB
eTB
w
ij
ij

(2)

Compared with problem (1), although this form is simplified, it is
still non-convex and contains too many constraints. There are multiple ways of handling the non-convex optimization problems, such
as Constrained Concave-Convex Procedure (CCCP) [41], adapted
bundle method [13] and deterministic annealing [16]. Due to the
popularity of CCCP, we use this method to decompose this nonconvex problem into a series of convex sub-problems and focus on
the resulting convex subproblems. Furthermore, to reduce the time
complexity on solving these subproblems, Stochastic Gradient Descent (SGD) [37] method is adapted, such that the algorithm can
find a local optimal solution in linear scale.

151

3.4

stances indicated by jp∗ in Eq.(3), and its corresponding label from
the selected bags in As 5 . zi ∈ Bs represents the instances sampled
from all of the instances in selected bags, i.e., As . It is clear that
e As , Bs ) can be calculated as:
the subgradient of f (w,

CCCP with Stochastic Gradient Descent

e (0)3 , CCCP iteratively computes w
e (t)
Given a starting point w
(t−1)
T e (1)
T e (2)
e
e Bij and maxj∈ni w
e Bij
from w
by replacing maxj∈ni w
e (t−1) . More precisely,
with their first order Taylor expansions at w
for the t-th iteration of CCCP, the derived subproblem for solving
problem (2) is:
min
e
w

s.t.

k1
2
e As , Bs )
∂f (w,
1 X X (p) (p)
(p)
e−
=w
C Ii1 yi xi
e
∂w
k1 p=1 i=1

2
n ni
n
1 X X (p) (p)
C XX
1
e 2+
kwk
ηij
C ξi +
2
n p=1 i=1
N i=1 j=1

+

∀i ∈ {1, 2, . . . , n}
(1)

(1)

e ∗ ≥1−ξ
eTB
Yi w
i
ij

(p)

(2)

e ∗ ≥1−ξ
eTB
Yi w
i
ij
2

∀i ∈ {1, 2, . . . , n}, ∀j ∈ {1, 2, . . . , ni }
e (1) − w
e (2) ≤  + ηij
eTB
eTB
w
ij
ij
e (1) − w
e (2) ≥ − − ηij
eTB
eTB
w
ij
ij

(3)

e (p) , and represents the most posie (t−1)T B
where jp∗ = arg maxj w
ij
tive instance for the i-th bag on p-th view. Through solving a series
of subproblems derived from CCCP, the method is guaranteed to
converge to a local optimal solution of problem (2).
The resulting subproblem is convex. However, the cost of directly solving this problem is non-trivial, especially when the numbers of bags, instances, as well as the resulting constraints for the
optimization problem are large. A lot of research work, such as
bundle method [21, 40] and SGD method, has been proposed to
improve the efficiency of similar optimization problems. In this
paper, due to the superior performance, SGD is employed. Different from the traditional SGD method, in problem (3), we have two
different sets of constraints, i.e., the ones on the bags and the ones
on instances. The algorithm receives several parameters, i.e., S the number of SGD iterations to perform; k1 and k2 (k1 << n,
k2 << N ) - the number of bags and instances to use for approximating the sub-gradients. At the beginning of SGD algorithm for
(t−1)S 4
e (t0 ) to be w
eα
the t-th CCCP
, whose norm
√ iteration, we set w
is at most C (1) + C (2) . Here, the subscript α means that the
output of SGD for the t-th CCCP iteration is an averaged result of
the last corresponding αS SGD iterations. The averaged result is
adopted here because of the superior performance as shown in [34].
For the s-th iteration of the SGD algorithm, we randomly pick a set
of bags As ∈ {1, . . . , n}, and another set of instances Bs from all
of the instances (as indicated by As ) in selected bags. By doing so,
the computational cost can be reduced on both the bag level and
the instance level. More precisely, during each SGD iteration, we
replace problem (3) with an approximated convex sub-problem as
follows:
e As , Bs )
min f (w,
e
w

=

(5)

(p)

where Ii1 , Ii2 , Ii3 are indicator functions. Ii1 equals 1, if
e T xi(p) < 1, and otherwise 0; Ii2 equals 1 if w
e T z(1)
e T z(2)
yi w
>
i −w
i
T (2)
T (1)
e zi − w
e zi >  and oth and otherwise 0; Ii3 equals 1 if w
erwise 0. By setting the step length to be ηs = 1s , the updating
e s ,Bs )
e ts − ηs ∂f (w,A
e ts+1 = w
scheme can be written as w
|w=
e w
e ts .
e
∂
√w
ts+1
(1) + C (2) }.
e
e
w
will
then
be
projected
to
the
set
{k
wk
≤
C
√
Here, C (1) + C (2) is radius of the ball that the optimal solution
of (4) should fall into, as shown in the later section. The final output

1

(2)

k2
C X
(1)
(2)
(Ii2 − Ii3 )(zi − zi ),
k2 i=1

t(1−α)S

t

tS
e S
e
+...+w
e t(1−α)S to w
e tS as: w
eα
is averaged from w
= w
αS
for some constant α ∈ (0, 1). Based on the above derivation, the
whole algorithm can be summarized in Table 1.

4.

THEORETICAL ANALYSIS

In this section, some important properties of the proposed method,
such as the optimality and generalized error rate, will be analyzed.

4.1

Optimality

It has already been shown in previous work that the CCCP [41]
will converge asymptotically. During each CCCP iteration, SGD is
used for solving the resulting convex sub-problem. In this section,
we will investigate some important properties of the adapted SGD
method, such as the bound of the optimal solution and the differtS
eα
e t∗ ,
ence between the objective function values of w
and that of w
e t∗ refers to the optimal value for the t-thPiteration.
where w
P 1
e As , Bs ) = k11 2p=1 ki=1
C (p)
Theorem 1: Suppose G(w,
P
(p)
(2)
(1)
2
e T xi } + kC2 ki=1
e T zi −
e T zi − w
max{0, 1 − yi w
max{w
(2)

(1)

e T zi − , 0}. Then, k∂G(w, As , Bs )k2 ≤ H 2 ,
e T zi − w
, w
2
where, H = C (1)2 U (1)2 +C (2)2 U (2)2 + C 2 max{U (1)2 , U (2)2 }+
2C (1) C (2) U (1) U (2) + 2C (1) CU (1)2 + 2C (2) CU (2)2 ,
(1)
(2)
U (1) = maxi,j {kBij k}, U (2) = maxi,j {kBij k}.
Proof: Please check the Appendix.
Theorem 2: The
√ optimal solution of problem (3) should fall
within the ball of C (1) + C (2) .
Proof: Please check the Appendix.
Theorem 2 justifies the reason why during each SGD iteration,
at step
√ 11 of Table 1, the solution will be regulated within the
ball C (1) + C (2) , since the optimal solution is guaranteed to be
falling within this ball.
Theorem 3: For the s-th SGD iteration, the following inequality
holds 6 :

(4)

k1
2
1
1 X X (p)
e 2+
e T x(p)
kwk
C max{0, 1 − yi w
i }
2
k1 p=1 i=1

k2
n
o
C X
e T z(1)
e T z(2)
e T z(2)
e T z(1)
max w
−w
− , w
−w
− , 0 ,
i
i
i
i
S
S
k2 i=1
(H 2 + C (1) + C (2) )(1 + lnS)
1X
1X
e ts ) ≤
e t∗ ) +
f s (w
f s (w
S s=1
S s=1
S
(p)
where, (xi , yi ) represents the instance whose output is the largest
t0
e , i.e., the inin the corresponding bag given by the classifier w
5
To avoid confusion, please note that yi indicates the label for the
3 (t)
e represents the result from the t-th CCCP iteration.
w
i-th selected bag from As , while Yi in the previous formulations
4
refers to the label for the i-th bag in the whole dataset.
Here, the superscript ts means the s-th SGD iteration for the t-th
6
e ts , As , Bs ) in problem (4).
e ts ) here refers to f (w
CCCP iteration.
f s (w

+

152

Table 1: The description of FMI2 LS
Input: 1. Labeled bags: {(Bi , Yi ), i = 1, 2, · · · , n}; 2. parameters: trade-off parameters C (1) , C (2) and C; subsample
sizes k1 for bags and k2 for instances; SGD iterations S; averaging constant α.
tS
eα
Output: The classifier w
.
CCCP Iterations:
e 0 , t = 0.
1. Initialize w
2. repeat
3. Derive problem (3).
Stochastic Gradient Descent Iterations:
4.
for s = 1, . . . , S
5.
Choose As ∈ D, where |As | = k1 .
(p)
e ts−1 , xi(p) i ≤ 1}.
6.
Set A+
s = {(xi , yi ) ∈ As : yi hw
7.
Choose Bs ∈ As , where |Bsn| = k2 .
o
e ts−1 )T z(1)
e ts−1 )T z(2)
e ts−1 )T z(2)
e ts−1 )T z(1)
8.
Set Bs+ = {zi ∈ Bs : max (w
− (w
− , (w
− (w
−  > 0}
i
i
i
i
e s ,Bs )
t
|w=
Calculate ∂f (w,A
e
e w
e s−1 according to Eq.(5).
∂w
e s ,Bs )
e ts = w
e ts−1√− 1s ∂f (w,A
t
Calculate w
|w=
e
e w
e s−1 .
∂w

9.
10.

C (1) +C (2)

e ts = min{1,
e ts .
11.
Update w
}w
e ts k
kw
12.
end for
13. t = t + 1.
(t−1)S
e (t0 ) = w
eα
14. w
.
15.until convergence
tS
eα
e t(1−α)S + . . . + w
e tS )/αS.
16. w
= (w

√
e
(w)
2
2
(1) + C (2) + H)2 . By
e
Proof: k ∂f∂sw
e k ≤ (kwk + H) ≤ ( C
plugging this result to Corollary 1 of [36], we can get:
√
S
S
(H + C (1) + C (2) )2 (1 + lnS)
1X
1X
e ts ) ≤
e t∗ ) +
f s (w
f s (w
S s=1
S s=1
2S
≤

S
(H 2 + C (1) + C (2) )(1 + lnS)
1X
e t∗ ) +
f s (w
S s=1
S

Theorem 4: With probability over the choices of (A1 , . . . , AS )
and (B1 , . . . , BS ), we have that:
√
1
2 + 52 log( 1−α
) ( C (1) + C (2) + H)2
tS
t∗
e α ) − F (w
e )] ≤
E[F (w
,
α
S
where F (∗) is the objective function in problem
(3).
√
e
(w)
2
2
(1) + C (2) + H)2 . By
e
Proof: k ∂f∂sw
C
k
≤
(k
wk
+
H)
≤
(
e
plugging this into Theorem 5 of [34], we can get this conclusion.

4.2

5.

In this section, we consider the class of functions FC (1) +C (2) ,D =
e ∗ 7−→ 1 (maxj w
e (1) + maxj w
e (2) )} such that
eTB
eTB
{g|g : B
∗j
∗j
2
2
(1)
(2)
e ≤ C + C , and with probability of at least 1 − δ,
kwk

5.1
5.1.1

(2)

e −w
e | ≤  + E(ηij ) ≤ D
eTB
eTB
|w
ij
ij
(1)

(2)

(1)

(2)

D2
(1)
minij ((Bij )2

Datasets
Reuters21578

Reuters215787 is a benchmark dataset from Reuters newswire
in 1987. It has 135 categories, with 21578 documents. We pick
documents from 2 sub-categories as the positive examples. The
same amount of documents from the remaining dataset are randomly picked as negative ones. In document classification, if a
document belongs to a specific category, it is highly possible that
not every passage of this document is related to this category. So, it
could be better modeled as a MIL problem. More specifically, similar to [2], we treat each document as a bag and use the different

e −B
e )T (B
e −B
e )w
e T (B
e ≤ D2
⇒w
ij
ij
ij
ij
e 2≤
⇒kwk

EXPERIMENTS

In this section, an extensive set of experiments on document classification and a novel application – insider threat detection is presented to demonstrate the effectiveness and efficiencies of the proposed method.

Generalized Error Bound

(1)

√
min{ C (1) +C (2) ,E}
upper bounded by: P̂n (FC (1) +C (2) ,D ) =
×
n
qP
Pni
(1)
(1)
n
(maxρij ≥0,ρT 1=1
i=1
j=1 ρij K(Bij , Bij )
i
qP
Pni
(2)
(2)
n
+ maxρij ≥0,ρT 1=1
i=1
j=1 ρij K(Bij , Bij )).
i
Proof: Please check the Appendix.
Theorem 6: Fix κ ∈ (0, 1). Then, with probability at least 1−κ,
e ∗ ))) ≤
every g ∈ FC (1) +C (2) ,D satisfies: P (Y∗ 6= sign(g(B
P2 Pn
(p)
(p)
1
e )}
P
max{0, 1 − Yi g(B
(p)
i
p=1
i=1 C
n 2
i=1 C
q
ln(2/κ)
+ P̂n (FC (1) +C (2) ,D ) + 3
.
2n
Proof: This result can be got by applying Theorem 5 to Theorem
4.9 in [38].

(2)

+ (Bij )2 )

e 2 ≤ E2,
⇒kwk
(6)
q
(1)
(2)
where E , D/ minij ((Bij )2 + (Bij )2 ).
Theorem 5: The empirical Rademacher complexity of the functional space FC (1) +C (2) ,D on D = {(Bi , Yi ), i = 1, . . . , n} is

7

153

http://daviddlewis.com/resources/textcollections/reuters21578/.

Reuters 1

Reuters 1

0.8
FMI2LS

0.75

FMI2LS−0
MISVM
misvm
Citation KNN
MILES

0.85

2

FMI LS−0
MISVM
misvm
Citation KNN
MILES

0.7
0.65
0.01

0.2

0.4
0.6
Training Ratio

200

0.8
0.75
0.7

0.01

0.2

(a)

0.4
0.6
Training Ratio

0.8

0.01

500

FMI2LS
FMI2LS−0
MISVM
misvm
Citation KNN
MILES

FMI2LS
FMI2LS−0
MISVM
misvm
Citation KNN
MILES

0.65

0.8

Reuters 2
1000

0.9

Time

400
Time

Accuracy

0.85

Reuters 2

FMI2LS

Accuracy

600
0.9

0.2

(b)

0.4
0.6
Training Ratio

0.8

0.01

0.2

(c)

0.4
0.6
Training Ratio

0.8

(d)

Figure 1: Performances Comparisons on Reuters. Some of the experiment results of MILES cannot be reported due to the time
complexity issue as stated in Experiment section.
course

course

Time

0.9
0.85
FMI2LS
FMI2LS−0
MISVM
misvm
Citation KNN
MILES

0.8
0.75
0.7
0.01

0.2

0.4
0.6
Training Ratio

0.8

0.9

1000

0.85
0.8
0.75

0.65

(a)

0.2

0.4

0.6

0.01

0.8

Training Ratio

500

FMI2LS
FMI2LS−0
MISVM
misvm
Citation KNN
MILES

FMI2LS
FMI2LS−0
MISVM
misvm
Citation KNN
MILES

0.7

500

0.01

faculty
1000

0.95

Accuracy

1500

0.95
Accuracy

faculty

2

FMI LS
2
FMI LS−0
MISVM
misvm
Citation KNN
MILES

Time

1

0.2

(b)

0.4
0.6
Training Ratio

0.8

(c)

0.01

0.2

0.4
0.6
Training Ratio

0.8

(d)

Figure 2: Performances Comparisons on WebKB. Some of the experiment results of MILES cannot be reported due to the time
complexity issue as stated in Experiment section.

5.1.3

fixed-length passages as instances. For each of the sub-dataset, after removing the stop words and stemming, tf-idf [28] features are
extracted and processed by PCA for one information source, and
we use the hidden topics information obtained from Probabilistic
Latent Semantic Analysis (PLSA)8 of the binary word features as
another one. For a detailed description of these two datasets, please
refer to Table 2.

5.1.2

WebKB

WebKB9 is also a benchmark dataset for document classification,
which contains webpages from computer science departments in
around four different universities. There are seven categories in this
dataset, i.e., student, faculty, staff, department, course, project and
other, with 8280 webpages in this dataset. The two most frequently
appeared categories, i.e., course, and faculty, are used for classification, where each sub-dataset contains all of the webpages/bags
from one of the two categories, and the same number of the negative bags randomly sampled from the remaining six categories in
WebKB. We use the same way as we do for Reusters21578 to extract features from different views and model bags and instances.
The detailed description of the two sub-datasets is summarized in
Table 2.
Dataset
Reuters1
Reuters2
Course
Faculty
ITD

# Features View1
528
528
320
320
17

# Features View2
528
528
320
320
12

# Bags
1268
1256
1348
1590
1166

Insider Threat Detection (ITD)

We obtained this real dataset from a big IT company. ITD is
a project that is devoted to identify the potential harmful insiders
through analyzing their online activities, such as sending emails,
login, logout, downloaded files, etc. In this project, some experts
are hired to decide whether during each period (around 30 days),
each person in the database did malicious things or not. Based on
these labelings, each online activity is quantified as a feature value.
However, it is highly possible that a person may not do malicious
things on each single day during the period in which he is marked as
guilty. Out of this motivation, the features for the online behaviors
within one day is considered as an instance and the instances during
each period is treated as a bag. If a person is known to have done
some malicious things in a specific period, then the corresponding
collection of instances (days) is considered as a positive bag. Otherwise, this collection of instances will be considered as negative.
The different activities are quantified into numeric features. These
features are further divided into two groups according to the nature
of the corresponding behaviors i.e, the group that describes his social behaviors such as sending emails and interacting with friends
on social media websites, and the group that depicts things he did
by himself, such as logging in and out of a computer system. The
whole dataset contains 1000 negative bags and 166 positive bags,
where each instance is represented by two different views derived
from the two feature groups as described above. Please refer to
Table 2 for details on the size of the dataset.

#Instances
2367
2145
3528
4248
32235

5.2

Evaluation Metric

In Reuters21578 and WebKB, since the positive and negative
classes are relatively balanced, we use the classification accuracy
as the measurement criteria. But for ITD dataset, the number of
positive bags is far less than that of the negative ones. So, F1 score
for the top 20 returned results is used here for measurement. In
recision×Recall
,
particular, F1 score is defined as F 1@20 = 2 × P
P recision+Recall
where, P recision and Recall are measured for the top 20 results.

Table 2: The detailed description of the datasets
8
Actually, PLSA[18] can be considered as a dimensionality reduction method, which maps the documents into some fixed number
of hidden topics. The topic distribution for each document can be
used as low dimensional features.
9
http://www.cs.cmu.edu/∼webkb/

154

ITD

Comparison Methods

0.5
0.45

We compare the proposed method with several state-of-the-art
methods. MISVM and misvm [2] are MIL methods based on SVM.
The difference between MISVM and midvm is that during each iteration, to update the classifiers, MISVM tries to find a witness for
each bag, while misvm assigns pseudo labels to all of the instances.
MILES [8] tries to use a single vector to represent each bag through
mapping these bags on a learned space. Citation KNN [42] adapts
KNN to multi-instance by considering two different kinds of neighborhood relationships. These baseline methods could not be used
to solve the multiple view problem directly. So, we concatenate the
features in different views together and treat them as from one information source. To demonstrate the benefits of ensuring the consistencies between different views without concatenating the features, we also conduct experiments by setting C to be 0 (FMI2 LS0). It is clear that the formulation of the experiments proposed in
[31] can be considered as a special case of FMI2 LS-0. For the proposed method, k1 is chosen as 10% of the number of bags, while
k2 is 50% of the instances in sampled bags. α is set to be 0.2. The
number of SGD iterations is set to be 30. By using 5 fold cross validation, C (1) and C (2) are searched through the grid 2[−5:1:7] , C is
searched though 2[−3:1:5] . The parameters of the baseline methods
are also tuned similarly.

5.4

0.4
F1@20

ITD
1000

FMILMIS
FMILMIS−0
MISVM
misvm
Citation KNN
MILES

0.35

Time

5.3

0.3

500

FMILMIS
FMILMIS−0
MISVM
misvm
Citation KNN
MILES

0.25
0.2
0.15
0.01

0.2

0.4
0.6
Training Ratio

0.8

(a)

0.01

0.2

0.4
0.6
Training Ratio

0.8

(b)

Figure 3: Performances Comparisons on ITD. F1 score for the
top 20 returned results is used here due to the imbalance of this
dataset. Some of the experiment results of MILES cannot be
reported due to the time complexity issue as stated in Experiment section.

stances in positive bags is large. This drawback could potentially
hinder its uses in practical applications. In our experiments, this
time complexity issue is also very evident. Some experimental
results for MILES cannot be acquired due to the extremely large
amount of training time. The performance of MILES is very competitive, compared with the other baseline methods. However, it is
clear that, from these experiments, its performance cannot exceed
the proposed method either.

Results and Analysis

The experiments are conducted by specifying a specific ratio of
each dataset for training and keeping the rest for testing. The average results of 20 independent experiments on the three datasets
with different training rations are shown in Fig.1, Fig.2 and Fig.3.
From these experimental results, we can see that the proposed
method performs better than the other baseline methods in most
cases. It is clear that considering the consistencies of examples on
different views in MIL could significantly improve the classification performance. The time complexity of the proposed method is
also very low, compared with the baseline methods. This is due to
the fact that SGD could significantly reduce the time complexity.
When compared with FMI2 LS-0, it can be concluded that the time
complexity of FMI2 LS-0 is similar to that of the proposed method.
But the performance of FMI2 LS-0 is inferior. It further demonstrates the advantages of the proposed method by introducing the
consistencies between different views.
For MISVM and misvm, both of these two methods are traditional MIL methods. Their performances are good in terms of
both the classification performance and time complexity. However,
since these two methods do not consider the different characteristics from multiple information sources, and merely concatenate
the different features by using only one feature vector, their performances are inferior to that of the proposed one.
Citation KNN is an adaption of nearest neighbor method. More
specifically, it defines two different types of neighbors when measuring the similarities between two bags. It can be seen from the
experiments that one of the major drawbacks for this method is that
its time complexity is too high because it needs to calculate the
distances between test bags and training bags each time. Since it
does not consider the consistencies between different views either,
contenting the features on different views cannot bring in much additional benefits.
In MILES, during the training phase, the instances in training
bags are mapped to a space spanned by the instances in positive
bags, and then the most relevant examples are selected through
one norm SVM. The method could capture the most important instances in an optimized way. However, the major issue is that its
time complexity could be extremely high when the number of in-

6.

CONCLUSIONS

In this paper, we investigate an interesting but rarely studied
problem – Multi-Instance Learning from Multiple Information Sources (MI2 LS). To solve this problem, a general framework is proposed to incorporate the consistencies between different information sources/views into Multi-Instance Learning (MIL). Based on
the proposed framework, a concrete method, FMI2 LS (Fast MI2 LS) is designed. In particular, the proposed method integrates Constrained Concave-Convex Programming (CCCP) method with an
adapted Stoachastic Gradient Descent (SGD) method to solve the
non-convex optimization problem in an efficient way. Some important properties of the proposed method are analyzed thereafter.
Experimental results on different applications, i.e., document classification and the newly proposed application – Insider Threat Detection (ITD), clearly demonstrate the superior performance of the
proposed method against several other state-of-the-art MIL techniques on both efficiency and effectiveness. Based on the proposed
method, in the future, we plan to extend the current work in the
following ways: (1) In this paper, we didn’t tune the weights of different views in the final classifier for simplicity. However, it is often
the case that the data quality on different views could be different.
We plan to design a method to adaptively tune the weights of different views under the current framework. (2) Due to the nature of
MIL, we can define different kinds of consistencies between views,
i.e., on the instance level, the bag level, and the mixture of bag and
instance level. It is an interesting topic to further investigate which
one works better.

References
[1] S. Ali and M. Shah. Human action recognition in videos using kinematic features and multiple instance learning. IEEE
Trans. Pattern Anal. Mach. Intell., 32(2):288–303, 2010.
[2] S. Andrews, I. Tsochantaridis, and T. Hofmann. Support vector machines for multiple-instance learning. In NIPS, 2003.

155

[3] B. Babenko, M.-H. Yang, and S. Belongie. Robust object
tracking with online multiple instance learning. IEEE Trans.
Pattern Anal. Mach. Intell., 33(8):1619–1632, 2011.

[23] M. Kim and F. D. la Torre. Gaussian processes multiple instance learning. In ICML, pages 535–542, 2010.
[24] J. T. Kwok and P.-M. Cheung. Marginalized multi-instance
kernels. In IJCAI, pages 901–906, 2007.

[4] C. Bergeron, G. M. Moore, J. Zaretzki, C. M. Breneman,
and K. P. Bennett. Fast bundle algorithm for multipleinstance learning. IEEE Trans. Pattern Anal. Mach. Intell.,
34(6):1068–1079, 2012.

[25] G. Li, S. C. H. Hoi, and K. Chang. Two-view transductive
support vector machines. In SDM, pages 235–244, 2010.
[26] Y.-X. Li, S. Ji, S. Kumar, J. Ye, and Z.-H. Zhou. Drosophila
gene expression pattern annotation through multi-instance
multi-label learning. IEEE/ACM Trans. Comput. Biology
Bioinform., 9(1):98–112, 2012.

[5] A. Blum and T. M. Mitchell. Combining labeled and unlabeled sata with co-training. In COLT, pages 92–100, 1998.
[6] B.Scholkopf and A.Smola. Learning with Kernels. MITPress,
Cambridge, MA, 2002.

[27] D. G. Lowe. Object recognition from local scale-invariant
features. In ICCV, pages 1150–1157, 1999.

[7] R. C. Bunescu and R. J. Mooney. Multiple instance learning
for sparse positive bags. In ICML, pages 105–112, 2007.

[28] C. D. Manning, P. Raghavan, and H. Schtze. Introduction to
Information Retrieval. Cambridge University Press, 2008.

[8] Y. Chen, J. Bi, and J. Z. Wang. Miles: Multiple-instance
learning via embedded instance selection. IEEE Trans. Pattern Anal. Mach. Intell., 28(12):1931–1947, 2006.

[29] O. Maron and T. Lozano-Pérez. A framework for multipleinstance learning. In NIPS, 1997.

[9] Y. Chen and J. Z. Wang. Image categorization by learning
and reasoning with regions. Journal of Machine Learning
Research, 5:913–939, 2004.

[30] O. Maron and A. L. Ratan. Multiple-instance learning for
natural scene classification. In ICML, pages 341–349, 1998.
[31] M. Mayo and E. Frank. Experiments with multi-view multiinstance learning for supervised image classification. In Proc
26th International Conference Image and Vision Computing
New Zealand, Auckland, New Zealand, pages 363–369, 2011.

[10] T. Deselaers and V. Ferrari. A conditional random field for
multiple-instance learning. In ICML, pages 287–294, 2010.
[11] T. G. Dietterich, R. H. Lathrop, and T. Lozano-Perez. Solving
the multiple instance problem with axis-parallel rectangles. In
Artificial Intelligence, 1998.

[32] R. Rahmani and S. Goldman. MISSL: Multiple-instance
semi-supervised learning. In ICML, 2006.

[12] J. Farquhar, D. Hardoon, H. Meng, J. Shawe-Taylor, and
S. Szedmak. Two view learning: SVM-2K, theory and practice. NIPS, 18:355, 2006.

[33] R. Rahmani, S. A. Goldman, H. Zhang, S. R. Cholleti, and
J. E. Fritts. Localized content-based image retrieval. IEEE
Trans. Pattern Anal. Mach. Intell., 30(11):1902–1912, 2008.

[13] A. Fuduli, M. Gaudioso, and G. Giallombardo. Minimizing
nonconvex nonsmooth functions via cutting planes and proximity control. SIAM Journal on Optimization, 14(3):743–756,
2004.

[34] A. Rakhlin, O. Shamir, and K. Sridharan. Making gradient
descent optimal for strongly convex stoachastic optimization.
In ICML, 2012.

[14] T. Gärtner, P. Flach, A. Kowalczyk, and A. Smola. Multi–
instance kernels. In ICML, 2002.

[35] D. Rosenberg, V. Sindhwani, P. Bartlett, and P. Niyogi. A
Kernel for Semi-Supervised Learning With Multi-View Point
Cloud Regularization. IEEE Signal Processing Magazine,
2009.

[15] T. Gärtner, P. A. Flach, A. Kowalczyk, and A. J. Smola. Multiinstance kernels. In ICML, pages 179–186, 2002.

[36] S. Shalev-shwartz and Y. Singer. Logarithmic regret algorithms for strongly convex repeated games. In The Hebrew
University, 2007.

[16] P. V. Gehler and O. Chapelle. Deterministic annealing for
multiple-instance learning. Journal of Machine Learning Research - Proceedings Track, 2:123–130, 2007.

[37] S. Shalev-Shwartz, Y. Singer, N. Srebro, and A. Cotter. Pegasos: primal estimated sub-gradient solver for svm. Math.
Program., 127(1):3–30, 2011.

[17] J. He and R. Lawrence. A graphbased framework for multitask multi-view learning. In ICML, pages 25–32, 2011.
[18] T. Hofmann. Probabilistic latent semantic indexing. In SIGIR,
pages 50–57, 1999.

[38] J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. MCambridge University Press, 2004.

[19] Y. Hu, M. Li, and N. Yu. Multiple-instance ranking: Learning
to rank images for image retrieval. In CVPR, 2008.

[39] V. Sindhwani and P. Niyogi. A co-regularized approach to
semi-supervised learning with multiple views. In ICML Workshop on Learning with Multiple Views, 2005.

[20] R. Jin, S. Wang, and Z.-H. Zhou. Learning a distance metric
from multi-instance multi-label data. In CVPR, pages 896–
902, 2009.

[40] C. H. Teo, S. V. N. Vishwanathan, A. J. Smola, and Q. V. Le.
Bundle methods for regularized risk minimization. Journal of
Machine Learning Research, 11:311–365, 2010.

[21] T. Joachims. Training linear svms in linear time. In KDD,
pages 217–226, 2006.

[41] A. S. Vishwanathan, A. J. Smola, and S. V. N. Vishwanathan.
Kernel methods for missing variables. In AISTATS, pages
325–332, 2005.

[22] T. Joachims and N. Cristianini. Composite kernels for hypertext categorisation. In ICML, pages 250–257, 2001.

156

Proof of Theorem 2: Through calculating the dual of problem
(4), it can be concluded that:

[42] J. Wang, et Jean-Daniel Zucker, and J. daniel Zucker. Solving
the multiple-instance problem: A lazy learning approach. In
ICML, pages 1119–1125, 2000.

k1
k1
k2
1
C (1) X (1) C (2) X (2)
C X
e 2+
kwk
ξi +
ξi +
ηi
2
k1 i=1
k1 i=1
k2 i=1

[43] M. Wu and B. Schölkopf. A local learning approach for clustering. In NIPS, pages 1529–1536, 2006.
[44] O. Wu, J. Gao, W. Hu, B. Li, and M. Zhu. Indentifying multiinstance outliers. In SDM, pages 430–441, 2010.

k1
k1
k2
X
X
X
1
(1)
(2)
(3)
(4)
e 2+
kwk
αi +
αi + 
(αi − αi ),
2
i=1
i=1
i=1

≤−

[45] D. Zhang, J. He, Y. Liu, L. Si, and R. D. Lawrence. Multiview transfer learning with a large margin approach. In KDD,
pages 1208–1216, 2011.

s.t.

(1)

0 ≤ αi
(3)

αi

[46] D. Zhang, Y. Liu, L. Si, J. Zhang, and R. D. Lawrence. Multiple instance learning on structured data. In NIPS, pages 145–
153, 2011.

C (1)
,
k1

≤

(4)

≤ 0, αi

(1)

(2)

(2)

0 ≤ αi

≥ 0,

(3)

≤

(4)

0 ≤ αi

C (2)
k1
(3)

− αi

≤

C
,
k2

(4)

where αi , αi , αi , αi are the dual variables corresponding
to the four sets of constraints in problem (3) respectively.
It is clear that,

[47] D. Zhang, F. Wang, C. Zhang, and T. Li. Multi-view local
learning. In AAAI, pages 752–757, 2008.

e 2 ≤ C (1) + C (2)
kwk
e falls within the ball whose radius
So, the optimal solution of w
√
C (1) + C (2) .
2
Proof of Theorem 5: The Rademacher complexity of the functional space FC (1) +C (2) ,D can be upper bounded as follows:

[48] M.-L. Zhang and Z.-H. Zhou. M3miml: A maximum margin method for multi-instance multi-label learning. In ICDM,
pages 688–697, 2008.

is

[49] Q. Zhang and S. A. Goldman. Em-dd: An improved multipleinstance learning technique. In NIPS, pages 1073–1080,
2001.

R̂n (FC (1) +C (2) ,D ) = Eσ [sup |
g∈F

n
2X
e i )|]
σi g(B
n i=1

[50] T. Zhang, A. Popescul, and B. Dom. Linear prediction models with graph regularization for web-page categorization. In
SIGKDD, pages 821–826, 2006.

n
2X 1
e (2) )|]
e (1) + max w
eTB
eTB
=Eσ [sup |
σi (max w
ij
ij
j
j
2
f ∈F n
i=1

[51] Z.-H. Zhou and M.-L. Zhang. Multi-instance multi-label
learning with application to scene classification. In NIPS,
pages 1609–1616, 2006.

=Eσ [sup |
f ∈F

√
n
X
min{ C (1) + C (2) , E}
e (2)∗ )|]
e (1)∗ + B
≤
σ i (B
Eσ [|
ij2
ij1
n
i=1
√
min{ C (1) + C (2) , E}
≤
×
n
v
u n
uX
(2)
(2)
(1)
(1)
t
K(Bij ∗ , Bij ∗ ) + K(Bij ∗ , Bij ∗ )

APPENDIX
Proof of Theorem 1: To prove this theorem, we suppose ιi =
(2)

(1)

e T xi }
e T xi }
∂ max{0,1−yi w
∂ max{0,1−yi w
, κi =
,
e
e
∂w
∂w
(1)
(2)
(2)
(1)
e T z i −w
e T zi −,w
e T zi −w
e T zi −,0}
∂ max{w
υi =
.
e
∂w

1

≤C

U

(1)2

+C

(2)2

U

(2)2

2

+ C max{U

(1)2

,U

(2)2

2

2

√
min{ C (1) + C (2) , E}
≤
×
n
v
uX
ni
u n X
(1)
(1)
t
(
max
ρij K(Bij , Bij )

k1
k1
k2
∂G(w, As , Bs ) 2
C (2) X
C X
C (1) X
ιi +
κi +
υi k2
k =k
e
∂w
k1 i=1
k1 i=1
k2 i=1
(1)2

1

i=1

Then, the fol-

lowing inequality holds:

k

n
1X
e (2)∗ )|]
e (1)∗ + w
eTB
eTB
σ i (w
ij2
ij1
n i=1

ρij ≥0,ρT
i 1=1

}

+ 2C (1) C (2) U (1) U (2) + 2C (1) CU (1)2 + 2C (2) CU (2)2

+
2

max

ρij ≥0,ρT
i 1=1

i=1 j=1

v
uX
ni
u n X
(2)
(2)
t
ρij K(B , B ))
ij

ij

i=1 j=1

2

157

Jointly Modeling Label and Feature Heterogeneity
in Medical Informatics
PEI YANG, Arizona State University
HONGXIA YANG, Yahoo! Inc.
HAODA FU, Eli Lilly and Company
DAWEI ZHOU, Arizona State University
JIEPING YE, University of Michigan
THEODOROS LAPPAS, Stevens Institute of Technology
JINGRUI HE, Arizona State University
Multiple types of heterogeneity including label heterogeneity and feature heterogeneity often co-exist in
many real-world data mining applications, such as diabetes treatment classification, gene functionality
prediction, and brain image analysis. To effectively leverage such heterogeneity, in this article, we propose
a novel graph-based model for Learning with both Label and Feature heterogeneity, namely L2 F. It models
the label correlation by requiring that any two label-specific classifiers behave similarly on the same views if
the associated labels are similar, and imposes the view consistency by requiring that view-based classifiers
generate similar predictions on the same examples. The objective function for L2 F is jointly convex. To
solve the optimization problem, we propose an iterative algorithm, which is guaranteed to converge to the
global optimum. One appealing feature of L2 F is that it is capable of handling data with missing views and
labels. Furthermore, we analyze its generalization performance based on Rademacher complexity, which
sheds light on the benefits of jointly modeling the label and feature heterogeneity. Experimental results on
various biomedical datasets show the effectiveness of the proposed approach.
Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications—Data mining;
I.5.2 [Computing Methodologies]: Pattern Recognition—Design methodology
General Terms: Design, Algorithms, Performance
Additional Key Words and Phrases: Heterogeneous learning, multi-label learning, multi-view learning,
medical informatics
ACM Reference Format:
Pei Yang, Hongxia Yang, Haoda Fu, Dawei Zhou, Jieping Ye, Theodoros Lappas, and Jingrui He. 2016. Jointly
modeling label and feature heterogeneity in medical informatics. ACM Trans. Knowl. Discov. Data 10, 4,
Article 39 (May 2016), 25 pages.
DOI: http://dx.doi.org/10.1145/2768831
This work is partially supported by the NSF (No. IIS1017415), the Army Research Laboratory (No. W911NF09-2-0053), Region II University Transportation Center (No. 49997-33 25), DARPA (No. W911NF-11-C-0200
and W911NF-12-C-0028), and NSFC (No. 61473123).
Authors’ addresses: P. Yang, School of Computing, Informatics and Decision Systems Engineering, Arizona
State University, Tempe, AZ 85281; email: cs.pyang@gmail.com; H. Yang, Yahoo! Inc., Sunnyvale, CA 94089;
email: hongxia@yahoo-inc.com; H. Fu, Lilly Corporate Center, Drop Box 2241, Indianapolis, IN 46285; email:
fu_haoda@lilly.com; D. Zhou, School of Computing, Informatics and Decision Systems Engineering, Arizona
State University, Tempe, AZ 85281; email: davidchouzdw@gmail.com; J. Ye, Department of Computational
Medicine and Bioinformatics and Department of Electrical Engineering and Computer Science, University of
Michigan, Ann Arbor, MI 48103; email: jieping@gmail.com; T. Lappas, School of Business, Stevens Institute
of Technology, Hoboken, NJ 07030; email: tedlappas@gmail.com; J. He, School of Computing, Informatics and
Decision Systems Engineering, Arizona State University, Tempe, AZ 85281; email: jingrui.he@gmail.com.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for
components of this work owned by others than ACM must be honored. Abstracting with credit is permitted.
To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this
work in other works requires prior specific permission and/or a fee. Permissions may be requested from
Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212)
869-0481, or permissions@acm.org.
c 2016 ACM 1556-4681/2016/05-ART39 $15.00

DOI: http://dx.doi.org/10.1145/2768831

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39

39:2

P. Yang et al.

1. INTRODUCTION

Many real-world applications exhibit both label and feature heterogeneity, such as
text categorization, medical diagnosis, image or video annotation, gene functionality
prediction, and tag recommendation. On one hand, label heterogeneity means that
each example is associated with a set of different class labels. For example, the diabetes
patients may receive multiple treatments such as metformin and sulphonylurea, which
refer to multiple labels; genes may have multiple functionalities, which cause them to
be associated with multiple diseases. On the other hand, feature heterogeneity means
that the data are described by features from multiple views, or information sources.
For example, the diabetes patients are characterized by different views of features
measuring the long-term and short-term drug impact; proteins in given species have
features that contain diverse information such as gene expression, protein–protein
interactions, and sequence similarity, where some features are species specific, and the
others are cross species.
The major challenge for addressing such problems is how to jointly model the multiple types of heterogeneity in mutually beneficial way. To address this problem, in this
article, we propose a novel graph-based model named L2 F to leverage both label and
feature heterogeneity. In particular, L2 F accommodates multiple relationships, such
as instance–instance, label–label, and view–view correlations in a principled framework. In this way, it is able to: (1) model the label correlation by requiring that any
two label-specific classifiers behave similarly on the same views if the associated labels are similar, and (2) impose the view consistency by requiring that view-based
classifiers generate similar predictions on the same examples. To solve the resulting
optimization problem, we propose an iterative algorithm based on block coordinate
descent. It is guaranteed to converge to the global optimum. Furthermore, different
from most existing methods for addressing data heterogeneity, which require complete
views and labels, a direct extension of the proposed L2 F model can be used on data with
both missing views and missing labels. Therefore, it is widely applicable to real-world
applications with incomplete views and incomplete labels.
Moreover, we aim to answer the fundamental question of whether the generalization performance can be improved by jointly modeling both label and feature heterogeneity. Our theoretical analysis based on Rademacher complexity [Shawe-Taylor and
Cristianini 2004] shows that the error bound of the proposed model could be improved
by utilizing the label correlation and imposing the view consistency. We also empirically
demonstrate the effectiveness of L2 F on various datasets compared with state-of-theart techniques.
The L2 F model can be further extended to a generalized framework that uses the hypergraph to model the multiple types of relationships among the objects in a principled
manner. By encoding our prior knowledge on the learning task into the structure of the
hypergraph, we could develop various instantiations of the generalized framework for
modeling multiple types of heterogeneity.
The main contributions of this article can be summarized as follows:
(1) a graph-based model named L2 F for jointly learning the label and feature heterogeneity;
(2) a natural extension of L2 F for handling data with missing views and missing labels;
(3) theoretical analysis showing the benefits of simultaneously leveraging both types
of heterogeneity;
(4) experimental results on a variety of biomedical datasets showing the effectiveness
of the proposed approach.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:3

The rest of the article is organized as follows. After a brief review of the related
work in Section 2, we present the proposed L2 F model and its iterative optimization
algorithm in Section 3. The generalization performance of L2 F is analyzed in Section 4.
Section 5 discusses the extension of L2 F to a hypergraph-based framework. The experimental results on various datasets are shown in Section 6. Finally, we conclude in
Section 7.
2. RELATED WORK

In this section, we survey the related work on heterogeneous learning from single or
dual heterogeneity, as well as their applications in biomedical domain.
2.1. General Heterogeneous Learning

Multi-label learning studies the problem where each example is associated with a set of
labels [Tsoumakas and Katakis 2007; Zhang and Zhou 2014]. The key issue for multilabel learning is how to exploit correlations or dependences among multiple labels.
According to Zhang and Zhang [2010], existing strategies for label correlation exploitation can be grouped into three categories: first-order, second-order, and high-order
approaches. First-order methods assume that labels are independent, and multi-label
learning problem can be transformed into a number of independent binary classification problems, for example, ML-kNN [Zhang and Zhou 2007]. Second-order approaches
consider the pairwise relations between labels. Then, the multi-label learning problem
is transformed into the label ranking problem which aims at properly ranking every relevant–irrelevant label pair for each training instance, for example, Rank-SVM
[Elisseeff and Weston 2001]. Various methods have been proposed for high-order label
correlation learning. For example, LEAD [Zhang and Zhang 2010] employed Bayesian
network to encode the conditional dependencies of the labels as well as the feature set,
with the feature set as the common parent of all labels. LS-ML [Ji et al. 2008] aimed to
extract common subspace shared among multiple labels. A hypergraph spectral learning formulation was proposed for multi-label classification, where a hypergraph was
constructed to exploit the correlation information among different labels [Sun et al.
2008]. LIFT [Zhang 2011] constructed features specific to each label by conducting
clustering analysis on its positive and negative instances, and then, performed training and testing by querying the clustering results. MLLOC [Huang and Zhou 2012]
assumed that the label correlation may be shared by only a subset of instances rather
than all the instances. MAHR [Huang et al. 2012] aimed to discover the label relationship via a boosting approach with a hypothesis reuse mechanism. FaIE [Lin et al.
2014] is a feature-aware label space dimension reduction (LSDR) approach that jointly
maximized the recoverability of the original label space from the latent space, and the
predictability of the latent space from the feature space. CFT [Li and Lin 2014] adapted
the filter tree algorithm for cost-sensitive multi-label classification via constructing the
label powerset.
Some multi-label methods work in the semi-supervised setting. CNMF [Liu et al.
2006] exploited unlabeled data as well as label correlations via the constrained nonnegative matrix factorization. TRAM [Kong et al. 2013] studied the problem of transductive multi-label learning by utilizing the information from both labeled and unlabeled data. CSFS [Chang et al. 2014] jointly modeled the sparse feature selection and
semi-supervised learning in an optimization framework. TRANS [Guo and Schuurmans
2012] combined large-margin multi-label classification with unsupervised subspace
learning. TML [Wang et al. 2011] is probabilistic transductive multi-label approach
which simultaneously modeled the labeling consistency between visually similar videos
and the multi-label interdependence for each video. iMLCU [Wu and Zhang 2013]
is an inductive semi-supervised approach that simultaneously considered pairwise
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:4

P. Yang et al.

label correlations over labeled data and imposes maximum-margin regularization over
unlabeled data.
Related theories for multi-label learning have also been studied and developed. The
VC-dimension theory is used to derive the generalization bound for MAHR [Huang
et al. 2012], which showed that the hypothesis reuse in MAHR can utilize the label
relationship to reduce the capacity of the learning system, and thus, lead to a better
generalization ability. A generic empirical risk minimization (ERM) framework was
proposed for large-scale multi-label learning [Yu et al. 2014]. The proposed framework
demonstrated better generalization performance for low-rank promoting trace-norm
regularization when compared to (rank insensitive) Frobenius norm regularization. A
theoretical analysis on multi-label consistency was proposed in Gao and Zhou [2013].
They proved a necessary and sufficient condition for the consistency of multi-label
learning based on surrogate loss functions.
Since multi-label is closely related to multi-task learning, we brief review the related
work on multi-task learning. The goal of multi-task learning is to leverage the small
amount of labeled data from multiple related tasks to improve the learner for each
task. Among others, alternating structure optimization [Ando and Zhang 2005] decomposed the model into the task-specific and task-shared feature mapping; multi-task
feature learning [Argyriou et al. 2006] assumed that multiple related tasks share a
low-dimensional representation; clustered multi-task learning [Zhou et al. 2011] assumed that multiple tasks follow a clustered structure. Some recent multi-task learning methods are able to deal with irrelevant tasks by assuming that the model can
be decomposed into a shared feature structure that captures task relatedness, and a
group-sparse structure that detects outliers [Chen et al. 2011; Gong et al. 2012].
Multi-view learning has been studied extensively in the literature. Co-training [Blum
and Mitchell 1998] is one of the earliest multi-view learning algorithm. It is proved
that the two independent yet consistent views could be used to learn a concept in the
probably approximately correct (PAC) framework based on a few labeled and many
unlabeled examples. SVM-2K [Farquhar et al. 2005] combined KCCA with SVM in
an optimization framework. CoMR [Sindhwani and Rosenberg 2008] is proposed for
multi-view learning, which is based on a Reproducing Kernel Hilbert Space (RKHS)
with a data-dependent co-regularization norm. The large-margin based method MMH
[Chen et al. 2010] aimed to discover a predictive latent subspace representation shared
by multiple views. The kernel spectral algorithm [Song et al. 2014] is a non-parametric
kernel estimation method for learning multi-view latent variable models. An explicit
objective function was introduced to measure the compatibility of learned hypotheses
in multi-view learning [Collins and Singer 1999], and the boosting method was used
to optimize the function. The PAC generalization bound [Dasgupta et al. 2001] was
provided for co-training, which upper bounded the error of classifiers learned from two
views. The view independence assumption is relaxed in Abney [2002], which suggested
that the disagreement rate of two independent hypotheses upper bounded the error rate
of either hypothesis. An information-theoretic framework [Sridharan and Kakade 2008]
was proposed for multi-view learning, which showed how to derive incompatibility
functions for certain loss functions of interest so that minimizing this incompatibility
over unlabeled data helped reduce expected loss on the test data.
More recently, researchers begin to study problems with dual types of heterogeneity. For problems with both task (or domain) and view heterogeneity, a variety of
techniques have been proposed to model task relatedness in the presence of multiple views, for example, He and Lawrence [2011], Zhang and Huan [2012], Yang and
He [2014], Yang et al. [2015], and Yang and Gao [2013]. For the problems with both
label and view heterogeneity, the multi-view 2DAL [Zhang et al. 2009] method integrated the mechanism of multi-view learning and active learning for multi-label image
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:5

classification; MVMVL-MM [Fang and Zhang 2012] is based on the large margin framework, which mapped the multi-view data into low-dimensional feature space and simultaneously maximized the dependence between new feature descriptions and the
labels; the L2 F approach [Yang et al. 2014] modeled both the view consistency and
the label correlations in a graph-based framework. This article extends our previous
work [Yang et al. 2014] substantially by providing the detailed algorithm, theoretical
justification, and model generalization, as well as the comprehensive empirical evaluations on the biomedical data, which were not specifically presented in the preliminary
version.
2.2. Heterogeneous Learning in Biomedical Domain

In biomedical domain, most data collected from different sources are heterogeneous.
Take the prediction of causal disease genes as an example, the data may be in the forms
of sequence, expression, annotation, and so on. According to the survey paper [Piro
and Di Cunto 2012], the evidences available for disease genes can be classified into
the following categories: text-mining of biomedical literature, functional annotations,
pathways and ontologies, phenotype relationships, intrinsic gene properties, sequence
data, protein–protein interactions, regulatory information, orthologous relationships,
and gene expression information. Since different data sources can provide quite complementary disease-relevant information in many cases, they are practically merged
to provide better coverage and generalization than any single data source.
Various methods have been proposed to model the associations between gene
and disease. To name a few, sequence-based approach [Miozzi et al. 2008] used
high-throughput gene-expression data to predict gene function through the “guilt by
association” principle. Network-based approach [Singh-Blom et al. 2013] worked by
determining similarity between candidate gene and disease nodes in heterogeneous
networks composed of different biological networks. Diffusion-based approach [Li and
Patra 2013] conducted the random walk on a heterogeneous network composed of
both the protein–protein interaction network and the weighted phenotype network.
However, most of these methods ignore either the correlations among multiple labels
by treating different labels independently, or the consistency among multiple views by
simply concatenating different types of features into one view.
3. THE PROPOSED L 2 F MODEL

In this section, we will introduce the proposed L2 F model. The basic idea of L2 F is to
encode the label correlation and view consistency in a graph-based model. An iterative
algorithm is presented to solve the resulting optimization problem. Furthermore, a
direct extension of L2 F can deal with missing labels and missing views.
3.1. Notations and Problem Statements

Let n and m denote the number of examples and labels, respectively. Let X be an
example space, and L = {L1 , L2 , . . . , Lm} be a finite set of class labels. An example
x ∈ X is described from V views, that is, x = {x ( j) |1 ≤ j ≤ V }, where x ( j) is the
instance in jth view, which is a feature vector. For the jth(1 ≤ j ≤ V ) view, the feature
dimension is denoted by dj . Each example x is associated with a subset of relevant
labels denoted by L(x) ∈ 2L . In practice, the relevant labels L(x) can be denoted by a
binary label vector Y (x) = [Y1 (x), Y2 (x), . . . , Ym(x)], where Yi (x) ∈ {1, −1}(1 ≤ i ≤ m) is
defined as

1
Li ∈ L(x)
Yi (x ) =
−1 Li ∈
/ L(x).
Let Y = {1, −1}m be the set of all such possible labelings.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:6

P. Yang et al.

Given a dataset D = {(x, Y (x))|x ∈ X , Y (x) ∈ Y}, consisting of nl labeled examples
and nu unlabeled examples, which are i.i.d drawn from some unknown distribution
P, our goal is to build a multi-label classifier h : X → Y that optimizes some specific
evaluation criterion. Without loss of generality, assume that the labels of the first nl
examples are known. We have n = nl + nu.
For the compactness of representation, we denote the ith(1 ≤ i ≤ m) label vector
of all the examples by yi = [Yi (x1 ), Yi (x2 ), . . . , Yi (xn)]T ∈ Rn×1 . Let fi j ∈ Rn×1 be the
prediction vector of all the examples for the ith(1 ≤ i ≤ m) label and the jth(1 ≤ j ≤ V )
T
T
T
T T
view. Denote f = [ f11
, . . . , f1V
, . . . , fm1
, . . . , fmV
] ∈ RnmV ×1 . Let A F be the Frobenius
norm for the matrix A.
3.2. Objective

In L2 F, we model the multiple types of relationship including instance-instance, label–
label, and view–view correlations in a graph-based framework. The goal is to maximize
the smoothness consistency of the instances together with label correlation and view
consistency, and simultaneously, minimize the empirical loss on the training data.
Thus, the objective is to minimize,
J ( f ) = JC ( f ) + α JL( f ) + β JV ( f ) + γ Jemp ( f )

(1)

where JC , JL, JV , and Jemp correspond to instance consistency, label correlation, view
consistency, and empirical classification loss, respectively. The non-negative parameters α, β, and γ balance the importance of the corresponding terms. In the following,
we will give a detailed setup of each loss function.
Instance Consistency on the Graph: Let G(C)
= {V j , E j } be the K-nearest-neighbors
j
graph for the instances in the jth view, where V j is the set of instances, and E j is the set
( j)
( j)
( j)
( j)
of edges. We connect the instance pair (xi , xk ) if xk is the K-nearest neighbor of xi .
The edge weight is determined by the similarity between the two instances denoted by
( j)
( j)
k(xi , xk )(1 ≤ i, k ≤ n), which can be estimated using the instance-feature correlation
in various ways (e.g., we use Gaussian RBF function). Let W j ∈ Rn×n be the affinity
( j)
( j)
whose (i, k) element is k(xi , xk ). Define
matrix for the instance–instance graph G(C)
j
the Laplacian 
matrix L j = D− 2 (D − W j )D− 2 where D is a diagonal matrix whose (i, i)
element Dii = nk=1 W j (i, k).
Intuitively, similar instances should have similar predictions. Following the random
walk model [Zhou et al. 2004], we model the instance consistency as follows:
1

JC ( f ) =

1

m 
V


fiTj L j fi j = f T QC f,

(2)

i=1 j=1

where QC is a block diagonal matrix with its entry [QC ]i j,i j = L j for 1 ≤ i ≤ m, 1 ≤
j ≤ V . Since the Laplacian matrix L j is positive semi-definite, QC is also positive
semi-definite.
Label Correlation: Let G(L) = {V, E} be the K-nearest-neighbors graph for the labels,
where V = L is the set of labels, and E is the set of edges. We connect the label pair
(Li , Lk) if Lk is the K-nearest neighbor of Li . The edge weight is determined by the
similarity between the two labels denoted by k(Li , Lk)(1 ≤ i, k ≤ m), which can be
estimated using the example-label correlation in various ways (e.g., we use Gaussian
(L)
RBF function). Let S ∈ Rm×m be the affinity matrix for the label–label graph G
whose
(i, k) element is k(Li , Lk). The degree of a label Li (1 ≤ i ≤ m) is defined as di = m
j=1 Si j .
Based on the graph G(L) , we model the label correlations by requiring that any two
label-specific classifiers behave similarly on the same views if the associated labels are
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:7

similar. In specific, if two labels Li and Lk are similar, the label-specific classifiers fi j
and fkj should keep close to each other on the same j th view. Therefore, we model the
correlation among multiple labels as follows:

2
 fi j
fkj 
T

Sik  √ − √ 
JL ( f ) =
 = f QL f
d
d
i
k
F
j=1 i,k=1
V 
m


(3)

where QL is a block matrix with its entry,

[QL]i j,kj =

2 (1 − Sik/di ) In×n,
√
−2Sik In×n/ di dk,

i=k
i = k

for 1 ≤ i, k ≤ m, 1 ≤ j ≤ V . Since f T QL f ≥ 0, QL is positive semi-definite.
View Consistency: In order to maximize the view consistency, we require that for
any view pairs, the difference of predictions resulting from their view-based classifiers should keep small as much as possible. Hence, we model the consistency among
multiple views as follows:
JV ( f ) =

m 
V



 fi j − fik2 = f T QV f
F

(4)

i=1 j,k=1

where QV is a block matrix with its entry,

[QV ]i j,ik =

2 (V − 1) In×n,
−2In×n,

j=k
j = k

for 1 ≤ i ≤ m, 1 ≤ j, k ≤ V . Since f T QV f ≥ 0, QV is positive semi-definite.
Empirical Loss: Various empirical loss functions, such as hinge loss, least square
loss, logistic loss, and so on, can be used to measure the consistency with known label
information.
Overall Objective: In summary, the overall goal is to minimize the following objective
function:
J ( f ) = JC ( f ) + α JL( f ) + β JV ( f ) + γ Jemp ( f )
= f T ( QC + α QL + β QV ) f + γ Jemp ( f )
= f T Qf + γ Jemp ( f ) ,

(5)

where Q = QC + α QL + β QV .
A nice property of the proposed method is that its objective function is joint convex
as shown in the following theorem.
THEOREM 3.1 (CONVEXITY). When using convex empirical loss, the objective function in
Equation (5) is convex with respect to f .
PROOF. Since all of QC , QL, and QV are positive semi-definite, Q is also positive
semi-definite. Hence, f T Qf is convex with respect to f . Therefore, when the empirical
loss function Jemp( f ) is convex, the overall objective function in Equation (5) is also
convex.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:8

P. Yang et al.

3.3. Optimization

When using least-square loss as empirical loss function, the objective function in Equation (5) can be solved analytically. For the least square loss, we have
m 
V



 fi j − yi 2 = f T Qemp f − 2 f T p + q
Jemp ( f ) =
F

(6)

i=1 j=1

where Qemp is block diagonal matrix with its entry [Qemp]i j,i j = In×n, p is a block vector
with its entry [ p]i j = yi , and q is a constant block vector with its entry [q]i j = yiT yi · 1n×1
for 1 ≤ i ≤ m, 1 ≤ j ≤ V . Obviously, Qemp is positive semi-definite.
Then, the objective function in Equation (5) can be rewritten into
J ( f ) = JC ( f ) + α JL( f ) + β JV ( f ) + γ Jemp ( f )


= f T QC + α QL + β QV + γ Qemp f − 2γ f T p + γ q

(7)

= f QA f − 2γ f p + γ q,
T

T

where QA = QC + α QL + β QV + γ Qemp. Obviously, QA is positive semi-definite. By taking
derivative of Equation (7) with respect to f , we have
∇ f J ( f ) = 2QA f − 2γ p = 0 ⇒ f ∗ = γ Q−1
A p.

(8)

nmV ×nmV

, the space comOptimization Using Block Coordinate Descent: Since QA ∈ R
plexity of the above method is O(n2 m2 V 2 ). To reduce the space complexity, we resort
to block coordinate descent (BCD) method [Luo and Tseng 1992; Tseng 2001] to iteratively solve the optimization problem. We first rewrite the objective in Equation (7) as
follows:
J ( f ) = JC ( f ) + α JL( f ) + β JV ( f ) + γ Jemp ( f )
	 T


m 
V 
V
m


fi j fi j
2 fiTj fkj
fkjT fkj
T
fi j L j fi j + α
Sik
− √
+
=
di
dk
di dk
i=1 j=1
m


+β

V 


i=1 j,k=1

+γ

m 
V 


j=1 i,k=1

fiTj fi j − 2 fiTj fik + fikT fik



(9)


fiTj fi j − 2 fiTj yi + yiT yi .

i=1 j=1

By setting the first-order derivative
fi j (1 ≤ i ≤ m, 1 ≤ j ≤ V ) to zero, we have,

of

Equation

(9)

with

Hi j fi∗j = pi j ,
where

respect

to
(10)




 
Sii
+ 4β (V − 1) + 2γ In×n
Hi j = 2L j + 4α 1 −
di

and
pi j = 4α

m

k=1,k=i

V

Sik
fkj + 4β
fik + 2γ yi .
√
di dk
k=1,k= j

Prediction: For the test example, the final prediction is the expectation of predictions
resulting from view-based classifiers. For the example x, the prediction for its ith label
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:9

ALGORITHM 1: The L2 F Algorithm Based on BCD
Input:
multi-view multi-label dataset D = {(x, y(x)|x ∈ X , y(x) ∈ Y},
parameters: α, β, γ , niter .
Output:
predicted labels for the test data.
1: Initialize yi (1 ≤ i ≤ m) for each example to its true label for training data, 0 for test data;
2: Compute the instance-instance Laplacian matrices {L j |1 ≤ j ≤ V };
3: Compute the label-label affinity matrix S;
4: for t = 1 : niter do
5:
for i = 1 : m do
6:
for j = 1 : V do
7:
Keep the other block fixed, and update fi j by Eq. (10);
8:
end for;
9:
end for;
10: end for;
11: Return predicted labels for the test data by using Eq. (11).

is as follows:

⎛

⎞
V

1
hi (x ) = sgn ⎝
fi∗j (x )⎠ .
V

(11)

j=1

The L2 F algorithm based on block coordinate descent method is shown in Algorithm 1. Next, we will discuss the convergence property, the time and space complexity
of the proposed algorithm.
THEOREM 3.2 (CONVERGENCE). The L2 F algorithm converges to the global optimum.
PROOF. By taking second-order derivative of Equation (9) with respect to fi j , we have
∇ 2fi j J ( f ) = Hi j . Obviously, the Hessian matrix Hi j is positive semi-definite. Therefore,
the objective J f is block-wise convex with respect to fi j (1 ≤ i ≤ m, 1 ≤ j ≤ V ). According to Luo and Tseng [1992], block coordinate descent method converges to the local
optimum when the objective is block-wise convex.
Based on Theorem 3.1, the overall objective in Equation (5) is joint convex with
respect to f . For a joint convex function, a local minimum is also a global minimum.
Hence, our algorithm based on block coordinate descent method converges to the global
optimum.
The space complexity for instance–instance Laplacian matrix and label–label affinity
matrix are O(n2 ) and O(m2 ), respectively. To sum up, the space complexity of the L2 F
algorithm is O(V n2 + m2 ).
To solve Equation (10), a straightforward way is to compute fi∗j = Hi−1
j pi j . Based on
the selected matrix inversion algorithm [Winograd and Coppersmith 1990], the time
complexity of computing the inverse matrix is O(nc ), where 2.373 ≤ c ≤ 3. Hence,
the time complexity for the whole algorithm is O(niter V mnc ). However, if L j is a largesize matrix, the computation of inverse matrix is inefficient. Note that L j is sparse
since it is the Laplacian matrix based on K-nearest-neighbors graph. Therefore, for the
sparse and large-size matrix L j , it is much more efficient to solve Equation (10) by the
iterative conjugate gradient type algorithms [Sun et al. 2009] such as LSQR [Paige and
Saunders 1982], which can take advantage of the sparsity to accelerate the convergence
procedure.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:10

P. Yang et al.

3.4. Learning from Data with Missing Views and Labels

Many real-world applications often face the challenges of data with missing views or
labels. Generally speaking, missing label means that some labels of the examples are
incomplete, and missing view means that all the features in certain view are missing
for some examples. Given the incomplete views or labels, the learning problem becomes
more challenging. A natural extension of our method can deal with these missing value
problems.
Missing Views: To tackle the missing view problem, we need to change the formulation of the instance–instance affinity matrices {W j |1 ≤ j ≤ V }.
( j)
Suppose that the jth view information is missing for the instance xk , which is
( j)
denoted as xk ∈ ∅. In this case, we compute the instance–instance similarity regarding
( j)
the instance xk by borrowing the strength from other views as follows:
W j (i, k) =

1
Vk

V




k xi(v) , xk(v) ,

v=1,xk(v) ∈∅
/

where Vk is the number of non-missing views for the example xk. Note that we suppose
that each example has at least one non-missing view.
Missing Labels: To tackle the missing label problem, we need to change the computation of the label–label affinity matrix S.
Suppose that, for example, x, its kth label Yk (x ) is missing. In this case, we estimate
its label by borrowing the strength from its nearest neighbors. First, by letting α = β =
0 in Equation (10) and averaging the predictions from view-based classifiers, we can
obtain the predictions as follows:
V
γ 
fk =
(L j + γ I)−1 yk.
V
j=1

Then, the missing label, for example, x can be estimated as max{0, sgn( fk(x))}. Finally,
we can use the smoothed labels to re-compute the affinity matrix S.
Co-existing of Missing Views and Labels: When the missing views and missing labels
co-exist, the learning task becomes more difficult. But our proposed model can handle
this issue by simply combining the above two operations.
4. THEORETIC ANALYSIS

In this section, we analyze the generalization performance of the proposed approach,
which shows the benefits of simultaneously modeling label and feature heterogeneity.
To be specific, we will demonstrate that the upper bound of empirical Rademacher
complexity together with the error bound of the proposed L2 F model can be reduced by
incorporating the label correlation and enhancing the view consistency.
We first construct a Reproducing Kernel Hilbert Space (RKHS) for the proposed
method, and then, analyze its Rademacher complexity and error bound.
4.1. An RKHS

Let H be the space of functions with the norm defined as  f 2H = f T QC f . Based on
H, we define H̃ to be the space of functions with the norm  f 2H̃ =  f 2H + α f T QL f +
β f T QV f = f T Qf . Suppose that QC , QL, QV , and Q are invertible.1 The following theorem will show that both H and H̃ are RKHS.
1 When

it is singular, a practical approach is to add a small regularization term to it such as λI(λ ≥ 0).

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:11

−1
THEOREM 4.1 (RKHS). Both H and H̃ are RKHS with kernel matrix K = QC
, and
−1
−1
K̃ = Q = [QC + α QL + β QV ] , respectively.

PROOF. Since QC is positive semi-definite, according to Theorem 4 in Smola and
Kondor [2003], H is a Reproducing Kernel Hilbert Space with the kernel matrix K =
−1
QC
. Likewise, since Q is positive semi-definite, H̃ is also a Reproducing Kernel Hilbert
Space with the kernel matrix K̃ = Q−1 = [QC + α QL + β QV ]−1 .
Hence, based on Theorem 4.1, the overall objective in Equation (5) can be reduced to
standard supervised learning problem:
f ∗ = arg min  f 2H̃ + γ Jemp ( f )

(12)

f ∈H̃

4.2. Generalization Performance

Let F := { f ∈ H̃ :  f  ≤ r} denote the ball of radius r in H̃. According to Theorem 4.12
in Shawe-Taylor and Cristianini [2004], we can obtain the following theorem regarding
the empirical Rademacher complexity of the proposed method.
THEOREM 4.2 (RADEMACHER COMPLEXITY). The empirical Rademacher complexity of the
proposed L2 F method is upper bounded by
 

−1 
2r
R̂ (F ) ≤
.
(13)
tr QC + α QL + β QV
nmV
Note that α and β balance the importance of label correlation
in

 and view
 consistency

the overall objective, respectively. For simplicity, let R̂ Fα=β=0 and R̂ Fβ=0 correspond
to the empirical Rademacher complexity for α = β = 0, and β = 0 in Equtation (13),
respectively.
THEOREM 4.3 (RADEMACHER COMPLEXITY REDUCTION). For the proposed L2 F method, the
upper bound of empirical Rademacher complexity can be reduced by incorporating the
label correlation and enhancing view consistency, that is,




(14)
R̂ (F ) ≤ R̂ Fβ=0 ≤ R̂ Fα=β=0 .
PROOF. Note that both of QC and QL are positive semi-definite and symmetric.
Suppose QC has eigenvalues
υ1 ≥ · · · ≥ υt ≥ 0
and α QL has eigenvalues
ρ1 ≥ · · · ≥ ρt ≥ 0
and QC + α QL has eigenvalues
μ1 ≥ · · · ≥ μt ≥ 0.
According to Weyl’s inequality, the following inequality holds, for i = 1, . . . , t
υi + ρt ≤ μi .
Then, we have
t
t


1
1
−1
≤
= tr(QC
).
μi
υi

(15)

tr([QC + α QL + β QV ]−1 ) ≤ tr([QC + α QL]−1 ).

(16)

tr([QC + α QL]−1 ) =

i=1

i=1

Likewise, we have

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:12

P. Yang et al.

Fig. 1. A hypergraph model where the nodes represent the instances, and the simple edges (solid line) encode
the instance–instance correlations, and the hyperedges (dotted ellipse) encode the instance-label correlations.
The graphs corresponding two different views are shown in the left and right panels, respectively.

By Equations (15) and (16), we can reach the final conclusion as follows:
R̂ (F ) ≤ R̂(Fβ=0 ) ≤ R̂(Fα=β=0 ).
Note that QL encodes the correlation among multiple labels, while QV encodes the
consistency among multiple views. From Theorem 4.3, we can see that the Rademacher
complexity of the proposed L2 F method decreases by incorporating the label correlation
and view consistency into the overall objective as defined in Equation (5).
An application of Theorem 4.9 in Shawe-Taylor and Cristianini [2004] together with
Theorem 4.2 show that:
THEOREM 4.4 (ERROR BOUND). With probability at least 1 − δ(0 ≤ δ ≤ 1), the generalization error of prediction function f is upper bounded as follows:

ln (2/δ )
2r 
−1
.
(17)
tr(Q ) + 3
ED [ f (x)] ≤ Jemp( f ) +
nmV
2nmV
Theorem 4.4 suggests that the error bound of our proposed method can be improved
due to the reduction of Rademacher complexity.
5. MODEL GENERALIZATION AND DISCUSSION

In this section, we extend the model proposed in Section 3 to a generalized framework, which uses the hypergraph to model multiple types of relationships among the
objects including the instance–instance, instance–label, and view–view correlations.
Some specific instantiations of the generalization framework will also be discussed, as
well as the relationships between them.
Let G = {N, E} be the graph where N is the set of instances, and E is the set of
edges. E consists of two subset of edges, that is, E = Ec ∪ El , where Ec is the set of
simple edges and El is the set of hyperedges. Thus, G can be viewed as the combination
of two subgraphs, that is, G = Gc ∪ Gl , where Gc = {N, Ec } and Gl = {N, El } are the
simple graph and hypergraph, respectively. In comparison with simple graph that can
only represent the pairwise relationship, the hypergraph is capable of representing
more complex relationships among the objects [Zhou et al. 2007]. The illustration of
the hypergraph framework is shown in Figure 1. Note that the simple edges (solid line)
encode the instance–instance correlations, while the hyperedges (dotted ellipse) encode
the instance–label correlations. The graphs corresponding to different views have the
same hyperedge set but different simple edge set.
For an edge e ∈ Ec connecting the instance pair (xi , x j ), its weight is determined by
the similarity between the two instances. The similarity matrix for the subgraph Gc
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:13

is denoted by Wc . The degree matrix for Gc is denoted
by Dc , which is diagonal matrix
containing the degrees of the nodes, that is, Dc (i, i) = j Wc (i, j).
Each hyperedge e ∈ El corresponds to a label and consists of all the instances relevant
to this label. The degree of a hyperedge e, denoted as δ(e), is the number
of nodes in e.

The degree of a node v ∈ N, denoted as δ(v), is defined as δ(v) = {e∈El |v∈e} w(e) where
w(e) is the weight associated with the hyperedge e. The diagonal matrix forms for δ(v),
w(e) are denoted as Dl , Hl , respectively. The node-edge incidence matrix Cl ∈ R|N|×|El |
is defined as Cl (v, e) = 1 if v ∈ e, and Cl (v, e) = 0 otherwise. The similarity matrix for
the subgraph Gl is defined as Wl = Cl Hl ClT .
Based on the graph G, we propose a generalized framework to model both label
and feature heterogeneity. Note that the number of instances, features, and labels are
denoted as n, d, and m, respectively. Let X ∈ Rd×n, Y ∈ Rn×m, and F ∈ Rn×m be matrices
for the instances, labels, and predictions, respectively. The objective is to minimize:
J ( X, Y, F, G) = 	 ( X, Y, F, G) + γ Jemp (Y, F ) ,

(18)

where Jemp (Y, F ) is the empirical classification loss, and 	 ( X, Y, F, G) is the regularization term used to model multiple types of relationships among the objects including
the instance–instance, instance–label, and view–view correlations, which are closely
related to the structure of the graph G.
Next, we will introduce two instantiations of the generalized framework defined in
Eqation (18). For simplicity, we only consider the single-view scenario in the following
discussions.
One instantiation is to model the instance–instance and instance–label correlations
on the subgraphs, Gc and Gl , respectively. Note that the subgraph Gc encodes the
instance–instance correlation. Intuitively, similar instances should have similar predictions. Therefore, we model the instance consistency as Jc ( F ) = tr(F T Lc F), where Lc
is the Laplacian matrix for the graph Gc . For the subgraph Gl , if two instances share
more common hyperedges, they will be more similar. Likewise, if two hyperedges share
more common instances, they will also be more similar. In this regard, the hypergraph
Gl captures the instance–label correlation. Hence, we can model instance–label correlations as Jl ( F ) = tr(F T Ll F), where Ll is the Laplacian matrix for the graph Gl . In
this case, Eq. (18) can be rewritten into
J ( X, Y, F, G) = μtr(F T Lc F) + ωtr(F T Ll F) + γ Jemp (Y, F ) ,

(19)

where μ and ω are non-negative parameters to balance the contributions of different
terms.
Another instantiation is to model both instance–instance and instance–label correlations in the hypergraph G. For the hypergraph G, we can consider putting different
weights on the edges to encode our prior knowledge on relations among the subgraphs.
c 0
For example, we can assign the weights to the edges of the graph G such as [ μH
].
0 ωHl
We propose to model both instance–instance and instance–label correlations encoded
in the graph G as J ( F ) = tr(F T LF), where L is the Laplacian matrix for the graph G.
In this case, Equation (18) can be reformulated into
J ( X, Y, F, G) = tr(F T LF) + γ Jemp (Y, F ) .

(20)

Since the solutions to both Equations (19) and (20) are closely related to the corresponding Laplacian matrices, that is, Lc , Ll , and L. Next, we will discuss some
relationships between these two instantiations in term of their Laplacian matrices.
THEOREM 5.1. For G = Gc ∪ Gl with the diagonal weight matrix for the hypergraph as
c 0
H = [ μH
] , the unnormalized Laplacian matrix of the hypergraph is weighted sum
0 ωHl
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:14

P. Yang et al.

of the unnormalized Laplacian matrices of the subgraphs, that is,
L = μLc + ωLl .

(21)

PROOF. For the subgraph Gl , the unnormalized Laplacian matrix is defined as Ll =
Dl − Wl = Dl − Cl Hl ClT . For the subgraph Gc , the unnormalized Laplacian matrix is
defined as Lc = Dc − Wc . Because simple edge is a special case of hyperedge, Wc can
be rewritten into Wc = Cc Hc CcT in the same form with Wl , where Cc is the node–edge
incidence matrix and Hc is the weight matrix of the edges for graph Gc .
For the hypergraph G, we have
L = D − W = D − C HC T 

 T 
Cc
μHc 0
= μDc + ωDl − [ Cc Cl ]
0 ωHl
ClT


= μDc + ωDl − μCc Hc CcT + ωCl Hl ClT




= μ Dc + Cc Hc CcT + ω Dl + Cl Hl ClT
= μLc + ωLl .
The normalized Laplacian matrix is defined as Lsym = D− 2 LD− 2 = I − D− 2 LD− 2 .
sym
sym
However, the equation Lsym = μLc + ωLl is usually not satisfied. One special case
sym
sym
is when Dc = Dl , we have Lsym = 2(μLc + ωLl ), which follows from
1

sym

μLc

sym

+ ωLl

−1

1 −1
1
D 2 (μLc + ωLl ) D− 2
2
1
= Lsym.
2
=

− 12

= μDc 2 Lc Dc

−1

1

1

1

− 12

+ ωDl 2 Ll Dl
1
1
1
= D− 2 LD− 2
2

The above discussions indicate that if the unnormalized Laplacian matrices are used
in both Equations (19) and (20), they will lead to the equivalent solutions. But such a
conclusion cannot be made for the normalized Laplacian matrices.
It is worth noting that a variety of instantiations of the generalization framework are
possible depending on the structure of the hypergraph, as well as the weights putting
on the hyperedges. The strength of the proposed generalization framework is that it
allows us to model multiple types of correlations, such as instance–instance, label–
label, and view–view correlations in a principled way by encoding our prior knowledge
of the learning task into the hypergraph structure.
6. EXPERIMENTS

The theoretical analysis in Section 4 shows the advantages of modeling label and
feature heterogeneity in our framework. In this section, we aim to empirically verify
the effectiveness of the proposed algorithm in comparison with a variety of state-ofthe-art approaches.
6.1. Datasets and Setup

Four multi-label datasets on the biomedical domain are used to test the performance
of our proposed algorithm.
The first dataset is the Medical dataset [Pestian et al. 2007]. The Computational
Medical Center organized Medical NLP Challenge2 with a rich set of medical text
2 http://www.computationalmedicine.org/challenge/index.php.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:15

Table I. Statistics of Different Datasets
Dataset
Medical
Tudiabetes
Genbase
Diabetes

Instances Features Labels Cardinality Density Diversity Training
978
10,521
662
8,812

1,449
9,064
1,186
16

45
20
27
30

1.245
2.715
1.252
1.290

0.028
0.136
0.046
0.043

94
1,665
32
45

333
7,364
463
6,168

Test
645
3,157
199
2,644

corpus. This dataset is actually a collection of patient symptom histories, diagnosis
and prognoses reported to the insurance companies.
The Tudiabetes dataset is a collection of about 300,000 posts belonging to 21,285
threads crawled from Tudiabetes forum.3 The posts are organized into 20 categories
such as type 1 diabetes, type 2 diabetes, insulin pump, etc. Each forum user may send
the posts in multiple categories. In this dataset, users are instances and categories are
labels. This is a multi-label setting, since the same user can belong to many categories.
The features for each user are characterized by the text of his posts.
Both of the Medical and Tudiabetes datasets are text data. Based on the raw text,
we generate two views of features as follows: one corresponds to the TF-IDF features;
another corresponds to the latent topics obtained by applying probabilistic latent semantic analysis on the term counts, where the number of latent topics is set to 100.
Genbase [Diplaris et al. 2005] is a biomedical dataset for protein function classification. In Genbase, each instance is a protein, and each label is a protein class, which it
belongs to. The function of a protein is directly related to its structure. The proteins
are represented with two views of features, that is, patterns and profiles. Patterns are
short amino acid chains that have a specific order, while profiles are computational representations of multiple sequence alignments using hidden Markov models. Proteins
are grouped into several families according to the functions they perform. All proteins
contained in a family feature a certain structural relation, thus having similar properties. Some proteins belong to more than one class, thus the problem could be defined
as a multi-label classification problem.
The Diabetes dataset was obtained from a big biomedical company. This dataset
is a collection of symptom and treatment information regarding diabetes patients.
Each patient may receive multiple treatments, which can be regarded as the labels.
The patients are described with two views of features measuring the long- and shortterm drug impact, respectively. For example, glycated hemoglobin (A1c or HbA1c) is
a measurement of blood glucose level. A1c measures the average past 3-month blood
glucose value. Comparing with the A1c, fasting blood glucose (FBG) measure the shortterm drug impact. The FBG measures the current fasting blood glucose value. Both
views of measurements are key variables for treating diabetes patients.
Both Medical and Genbase datasets are available online.4 Table I shows the properties of different datasets. Label cardinality is the average number of labels per instance.
Accordingly, label density normalizes label cardinality by the number of labels. Label
diversity is the number of distinct label combinations observed in the dataset [Zhang
and Zhou 2014].
6.2. Evaluation Metric and Comparison Algorithms

We use both F1 -score and accuracy as the evaluation metrics to test the performance
of the proposed method.

3 http://www.tudiabetes.org/forum.
4 http://mulan.sourceforge.net/datasets.html.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:16

P. Yang et al.

Fig. 2. Performance (left: F1 -score, right: accuracy) varies with ratio on Medical.

F1 -score [Godbole and Sarawagi 2004] is the harmonic mean of precision and recall,
which is defined as follows:
F1 =

nl +nu
2|L(xk) ∩ Z(xk)|
1 
,
nu
|L(xk)| + |Z(xk)|
k=nl +1

where Z(x) = {Li |hi (x) = 1, 1 ≤ i ≤ m} is the predicted label set for example x. Note
that the larger value of F1 -score is indicating better performance.
Accuracy [Godbole and Sarawagi 2004] for each instance is defined as the proportion
of the predicted correct labels to the total number of labels for that instance. Overall
accuracy is the average across all test instances, which is defined as follows:
Accuracy =

nl +nu
1 
2|L(xk) ∩ Z(xk)|
.
nu
|L(xk) ∪ Z(xk)|
k=nl +1

Note that the larger value of accuracy is indicating the better performance.
The proposed L2 F method is compared with a variety of multi-label learning algorithms including (1) first-order approach ML-kNN [Zhang and Zhou 2007]; (2) featurebased approach LIFT [Zhang 2011]; (3) subspace learning approach LS-ML [Ji et al.
2008]; (4) transductive learning approach TRAM [Kong et al. 2013]; and (5) semisupervised method CSFS [Chang et al. 2014].
L2 F is given the multi-view data, whereas the other methods are given the concatenated features from all the views. The parameters are tuned for each algorithm using
cross validation on the training data. Then, the models are builded on the training
data with the optimal parameters, and then, evaluated on the test data. We repeat the
experiments ten times for each dataset and report the average performance.
6.3. Performance Evaluation

The comparison results for the datasets are shown in Figures 2–5. In each figure, x-axis
represents the ratio, which is used to randomly sample a subset of instances from the
training data, and y-axis denotes the performance such as F1 -score and accuracy.
First of all, a common trend observed from these figures is that the performance of
all the algorithms usually perform better when the ratio increases. It is reasonable
because more training instances help build a robust classifier.
The results show that L2 F performs better than the other algorithms in most cases.
The performance of ML-kNN [Zhang and Zhou 2007] is somewhat limited due to the
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

Fig. 3. Performance (left: F1 -score, right: accuracy) varies with ratio on TuDiabetes.

Fig. 4. Performance (left: F1 -score, right: accuracy) varies with ratio on Genbase.

Fig. 5. Performance (left: F1 -score, right: accuracy) varies with ratio on Diabetes.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:17

39:18

P. Yang et al.

fact that ML-kNN is a first-order approach, which ignores the correlation among multiple labels. In contrast, all the other algorithms usually perform better than ML-kNN
by leveraging the label correlations. In principle, the classifiers induction process of
LIFT [Zhang 2011] is similar to ML-kNN. But LIFT improves upon ML-kNN by building the classifier on each label with label-specific features instead of the original ones.
LS-ML [Ji et al. 2008] learns a common subspace shared among multiple labels, which
helps improve the learning performance for the multi-label data. However, since its objective function is non-convex, the performance of LS-ML would be limited by the local
optimum problem. Different from other approaches, TRAM [Kong et al. 2013] is a tranductive multi-label learning method, which tries to exploit the information from both
labeled and unlabeled data. They formulate the transductive multi-label classification
as an optimization problem of estimating label concept compositions. CSFS [Chang
et al. 2014] is also a semi-supervised method that conducts the sparse feature selection
by leveraging the unlabeled data. The results show that unlabeled data can provide
helpful information to build the multi-label classifier.
In comparison with the other methods, the key advantage of L2 F is that it models
both label and feature heterogeneity in a principled framework. First, by leveraging
the consistency among multiple views, the view-based classifiers can mutually improve
each other. On the contrary, all the other comparison methods do not consider the
view consistency, simply concatenating features from different views cannot gain much
additional improvement. Second, by considering the correlation among multiple labels,
the performance of label-specific classifiers in L2 F can benefit from each other. In
the next subsection, we will also show how the performances of L2 F vary with the
tradeoff parameters, α and β, which control the weight of label correlation and view
consistency, respectively. Another competency of L2 F is that it is capable of finding the
global optimum due to the joint convexity of the objective function.
In addition, we have a few different observations on the Diabetes dataset. First, we
find that the performance of the proposed algorithm is not very sensitive to different
ratios in the range of 0.2–1.0. Hence, we gradually decrease the ratio from 0.2 to 0.03,
and find that its performance begins to worsen. It suggests that the proposed method
can perform well on this dataset even though very few instances are used for training.
Second, the performance of four algorithms, that is, ML-kNN, LS-ML, LIFT, and CSFS,
are poor, indicating that this is a more challenging task. In contrast, both TRAM and
L2 F perform better than the other methods. This might due to the fact both TRAM
and L2 F take advantage of the unlabeled data. TRAM utilizes the unlabeled data in a
transductive way, while L2 F leverages the smoothness consistency among the nearest
instances. But all things have pros and cons. The result of CSFS suggests that the
performance cannot be guaranteed to improve with the help of unlabeled data.
6.4. Parameter Sensitivity

We study the parameter sensitivity on the Medical dataset. α and β are used to weigh
the importance of label correlation and view consistency, respectively. We tune α and
β on the grid 2[−4:1:4] . The left panel of Figure 6 shows the performance varies with α.
In comparison with α = 0, the algorithm performs better when α increases, and the
best result occurs when α = 1, which indicates that modeling label correlation could
significantly improve the multi-label learning performance. However, if α is very large
such as α = 16, the label correlation part will dominate the entire objective function,
making the model hard to keep certain level of accuracy. Nevertheless, the performance
is robust over a wide range of values for α. The right panel of Figure 6 shows a
similar trend for β, which suggests that the learner could benefit from enhancing the
consistency among multiple views.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:19

Fig. 6. F1 -score varies with α (left) and β (right) (log2 scale).

Fig. 7. F1 -score varies with σx (left) and σ y (right) (log2 scale).

We use the RBF kernel to estimate both the instance–instance
and label–label sim|x −x |2
ilarities, which is defined as k(xi , x j ) = exp(− i2σ 2j ) where σ is the width parameter.
We tune the width for instance kernel denoted by σx and label kernel denoted by σ y
on the grid 2[−5:1:5] . The performance varying with σ is shown in Figure 7. The results
show that the performance is robust over a wide range of σ values.
γ is used to control the weight of empirical loss. We tune γ on the grid 2[−4:1:4] . The
result is shown in the left panel of Figure 8. As expected, the performance is poor when
γ = 0, and the F1 -score first increases and then decreases when γ is increased.
As a result, we tune the parameters on each dataset using standard cross validation.
6.5. Convergence

The L2 F algorithm uses an iterative procedure to solve the optimization problem.
Theorem 3.2 guarantees that L2 F converges to a global optimum. Here, we empirically
study the convergence property of L2 F algorithm on the Medical dataset. The result is
shown in the right panel of Figure 8. From this figure, we can see that L2 F converges
fast and its performance becomes stable after 10 iterations. Thus, we terminate the
algorithm after a maximum of 15 iterations.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:20

P. Yang et al.

Fig. 8. F1 -score varies with γ (log2 scale) (left) and iteration (right).

Fig. 9. Performance (left: F1 -score, right: accuracy) varies with masked rate of labels.

6.6. Learning from Missing Views and Labels

In this subsection, we aim to verify the robustness of the L2 F method to the missing
views and missing labels on the Medical dataset.
Missing Labels: To generate the dataset with missing labels, we first randomly select
a percentage of examples from the training data. The ratio between the number of
selected examples and that of total training examples is denoted by the masked rate
r, which is adjusted in the range r = {0, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3}. Then, for
each example, we randomly select one of its positive labels and mask it as missing
label.
Figure 9 shows the performances of different algorithms vary with masked rate
of labels. A common trend is that all the algorithms usually perform worse when
the masked rate increases in most cases. It is reasonable that as the masked rate
increases, more noise will be introduced into the training data rendering more difficulty
to the learning task. As shown in the figure, L2 F is more robust to the noisy data in
comparison with the other algorithms. Its performance remains stable over a wide
range of masked rates. In contrast, the performance curve of TRAM [Kong et al. 2013]
drops sharply when the labels of a very small percentage of instances are masked as
missing, such as r = 0.025. This result suggests that the transductive learning method
TRAM is sensitive to the missing labels because the noisy label information is likely to
mislead the learning system in the transductive setting.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:21

Fig. 10. Performance (left: F1 -score, right: accuracy) varies with masked rate of views.

Fig. 11. Performance (left: F1 -score, right: accuracy) varies with masked rate of both views and labels.

Missing Views: To generate the dataset with missing views, we first randomly select a
percentage of examples from the training data. Likewise, the masked rate is adjusted
in the range r = {0, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3}. Then, for each example, we
randomly select one of its views and mask it as missing view.
Figure 10 shows the performances of different algorithms vary with masked rate
of views. In this figure, we can see that the performance of all the algorithms is not
very sensitive to the missing values in most cases. Two reasons could account for
this phenomenon. For the comparison algorithms except L2 F, though some views are
missing, the features in other views are concatenated to build the classifiers. For L2 F,
we borrow the strength from other views to reconstruct the instance–instance affinity
matrix, which is then used to build the learning system.
Co-existing of Missing Views and Labels: By combining the above two operations as
we done for the missing labels and views, we can generate the dataset with both missing
labels and missing views. The results are shown in Figure 11. Since the algorithms
are not very sensitive to the missing views in our setting, we can see that the results
shown in this figure are similar to those in Figure 9.
6.7. Visualization of the Hypergraph on Diabetes Dataset

Taking the Diabetes data as an example, we explore the correlations among multiple
labels, as well as the feature distributions in different views.
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:22

P. Yang et al.

Fig. 12. A fraction of hypergraph constructed from the Diabetes data, where the hyperedge in dotted polyline
represents the treatment, which corresponds to a set of patients received this treatment. The average A1C
and FBG values of the patients received the corresponding treatments are shown in the table.

Figure 12 shows a fraction of the hypergraph constructed from the Diabetes data.
In this figure, the hyperedge in dotted polyline represents the label (treatment), which
corresponds to a set of nodes (patients) received this treatment. There are five types of
treatments shown in the figure, that is, insulin, metformin, sulphonylurea, pioglitazone
15mg, and pioglitazone 30mg. Insulin is a hormone that helps to regulate blood sugar.
It is known that insulin is prescribed for patients with type 1 diabetes and for patients
with type 2 diabetes who have not responded so well on oral medication. Metformin
is commonly used as a first line treatment for type 2 diabetes, which is the only
available diabetes medication in the biguanides class of drugs. Sulphonylureas are the
class of antidiabetic drug for type 2 diabetes, which work by increasing the amount
of insulin the pancreas produces and increasing the working effectiveness of insulin.
Pioglitazone is an antidiabetic drug used to increase the insulin sensitivity. From the
figure, we can see that there is no correlations between insulin and either metformin or
sulphonylurea. This is reasonable because insulin is usually used for patients with type
1 diabetes, while both metformin and sulphonylurea are commonly used for patients
with type 2 diabetes. The results suggest that multiple types of labels are locally
correlated in the Diabetes dataset, and learning system can benefit from exploring the
correlations among different labels.
The right panel of the figure further shows the data distributions of features in
different views. In this table, the second column (instance) refers to the total number
of patients received the corresponding treatments; the last two columns (A1C and
FBG) refer to the average A1C and FBG values of these patients, which measure the
long-term and short-term drug impact, respectively.
7. CONCLUSION

In this article, we propose a graph-based approach L2 F for learning from both label and
feature heterogeneity. L2 F is robust to missing value problems, such as missing labels
and missing views. An iterative algorithm is presented to solve the convex problem,
which is guaranteed to converge to the global optimum. We analyze its performance
in terms of its generalization error rate, which shows the benefit of jointly modeling
the dual heterogeneity. Furthermore, a generalized framework based on L2 F allows
us to model multiple types of heterogeneity by incorporating our prior knowledge of
ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:23

the learning task into the hypergraph structure. The comparison experiments with
state-of-the-art methods demonstrate the effectiveness of the proposed algorithm.
One of our on-going work is to extend the proposed framework to the semi-supervised
setting. It is expected that the performance could be improved by picking out the informative examples and rebuilding the learning system, which is particularly challenging
due to both label and feature heterogeneity. Also, we will explore different pathways
to model the multiple types of correlation relationships among different labels, and
investigate how and when the learning performance can be improved by leveraging
multiple types of correlations in the heterogeneous scenarios.

REFERENCES
Steven P. Abney. 2002. Bootstrapping. In ACL. 360–367.
Rie Kubota Ando and Tong Zhang. 2005. A framework for learning predictive structures from multiple tasks
and unlabeled data. J. Mach. Learn. Res. 6, 1817–1853.
Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil. 2006. Multi-task feature learning. In
NIPS. 41–48.
Avrim Blum and Tom Mitchell. 1998. Combining labeled and unlabeled data with co-training. In COLT.
92–100.
Xiaojun Chang, Feiping Nie, Yi Yang, and Heng Huang. 2014. A convex formulation for semi-supervised
multi-label feature selection. In AAAI. 1171–1177.
Jianhui Chen, Jiayu Zhou, and Jieping Ye. 2011. Integrating low-rank and group-sparse structures for robust
multi-task learning. In KDD. 42–50.
Ning Chen, Jun Zhu, and Eric P. Xing. 2010. Predictive subspace learning for multi-view data: a large margin
approach. In NIPS.
Michael Collins and Yoram Singer. 1999. Unsupervised models for named entity classification. In EMNLP.
100–110.
Sanjoy Dasgupta, Michael L. Littman, and David A. McAllester. 2001. PAC generalization bounds for cotraining. In NIPS. 375–382.
Sotiris Diplaris, Grigorios Tsoumakas, Pericles A. Mitkas, and Ioannis P. Vlahavas. 2005. Protein classification with multiple algorithms. In Panhellenic Conference on Informatics. 448–456.
André Elisseeff and Jason Weston. 2001. A kernel method for multi-labelled classification. In NIPS. 681–687.
Zheng Fang and Zhongfei (Mark) Zhang. 2012. Simultaneously combining multi-view multi-label learning
with maximum margin classification. In ICDM. 864–869.
Jason D. R. Farquhar, David R. Hardoon, Hongying Meng, John Shawe-Taylor, and Sándor Szedmák. 2005.
Two view learning: SVM-2K, theory and practice. In NIPS.
Wei Gao and Zhi-Hua Zhou. 2013. On the consistency of multi-label learning. Artif. Intell.199–200, 2–44.
Shantanu Godbole and Sunita Sarawagi. 2004. Discriminative methods for multi-labeled classification. In
PAKDD. 22–30.
Pinghua Gong, Jieping Ye, and Changshui Zhang. 2012. Robust multi-task feature learning. In KDD. 895–
903.
Yuhong Guo and Dale Schuurmans. 2012. Semi-supervised multi-label classification—a simultaneous
large-margin, subspace learning approach. In ECML PKDD. 355–370. DOI:http://dx.doi.org/10.1007/
978-3-642-33486-3_23
Jingrui He and Rick Lawrence. 2011. A graph-based framework for multi-task multi-view learning. In ICML.
25–32.
Sheng-Jun Huang, Yang Yu, and Zhi-Hua Zhou. 2012. Multi-label hypothesis reuse. In KDD. 525–533.
Sheng-Jun Huang and Zhi-Hua Zhou. 2012. Multi-label learning by exploiting label correlations locally. In
AAAI. 1–7.
Shuiwang Ji, Lei Tang, Shipeng Yu, and Jieping Ye. 2008. Extracting shared subspace for multi-label classification. In KDD. 381–389.
Xiangnan Kong, Michael K. Ng, and Zhi-Hua Zhou. 2013. Transductive multilabel learning via label set
propagation. IEEE Trans. Knowl. Data Eng. 25, 3, 704–719.
Chun-Liang Li and Hsuan-Tien Lin. 2014. Condensed filter tree for cost-sensitive multi-label classification.
In ICML. 423–431.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

39:24

P. Yang et al.

Yongjin Li and Jagdish C. Patra. 2013. Genome-wide inferring gene-phenotype relationship by walking on
the heterogeneous network. Bioinformatics 26, 9, 1219–1224.
Zijia Lin, Guiguang Ding, Mingqing Hu, and Jianmin Wang. 2014. Multi-label classification via featureaware implicit label space encoding. In ICML. 325–333.
Yi Liu, Rong Jin, and Liu Yang. 2006. Semi-supervised multi-label learning by constrained non-negative
matrix factorization. In AAAI. 421–426.
Z. Q. Luo and P. Tseng. 1992. On the convergence of the coordinate descent method for convex differentiable
minimization. J. Optimization Theory Appl. 72, 1, 7–35.
Laura Miozzi, Rosario Michael Piro, Fabio Rosa, Ugo Ala, Lorenzo Silengo, Ferdinando Di Cunto, and Paolo
Provero. 2008. Functional annotation and identification of candidate disease genes by computational
analysis of normal tissue gene expression data. PLoS ONE 3, 6, e2439.
Christopher C. Paige and Michael A. Saunders. 1982. LSQR: an algorithm for sparse linear equations and
sparse least squares. ACM Trans. Math. Softw. 8, 1, 43–71. DOI:http://dx.doi.org/10.1145/355984.355989
John P. Pestian, Christopher Brew, Pawel Matykiewicz, D. J. Hovermale, Neil Johnson, K. Bretonnel Cohen,
and Wodzislaw Duch. 2007. A shared task involving multi-label classification of clinical free text. In
Proceedings of the Workshop on BioNLP. 97–104.
R. M. Piro and F. Di Cunto. 2012. Computational approaches to disease-gene prediction: rationale, classification and successes. FEBS J. 279, 678–696.
John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University
Press.
Vikas Sindhwani and David S. Rosenberg. 2008. An RKHS for multi-view learning and manifold coregularization. In ICML. 976–983.
U. Martin Singh-Blom, Nagarajan Natarajan, Ambuj Tewari, John O. Woods, Inderjit S. Dhillon, and Edward
M. Marcotte. 2013. Prediction and validation of gene-disease associations using methods inspired by
social network analyses. PLoS One 8.
Alex J. Smola and Risi Kondor. 2003. Kernels and regularization on graphs. In COLT. 144–158.
Le Song, Animashree Anandkumar, Bo Dai, and Bo Xie. 2014. Nonparametric estimation of multi-view latent
variable models. In ICML. 640–648.
Karthik Sridharan and Sham M. Kakade. 2008. An information theoretic framework for multi-view learning.
In COLT. 403–414.
Liang Sun, Shuiwang Ji, and Jieping Ye. 2008. Hypergraph spectral learning for multi-label classification.
In KDD. 668–676.
Liang Sun, Shuiwang Ji, and Jieping Ye. 2009. A least squares formulation for a class of generalized eigenvalue problems in machine learning. In ICML. 977–984. DOI:http://dx.doi.org/10.1145/1553374.1553499
Paul Tseng. 2001. Convergence of a block coordinate descent method for nondifferentiable minimization. J.
Optimization Theory Appl. 109, 3 , 475–494.
Grigorios Tsoumakas and Ioannis Katakis. 2007. Multi-label classification: An overview. Int. J. Data Warehousing Min. 3, 3 , 1–13.
Shmuel Winograd and Don Coppersmith. 1990. Matrix multiplication via arithmetic progressions. J. Symb.
Comput. 9, 3, 251–280.
Jingdong Wang, Yinghai Zhao, Xiuqing Wu, and Xian-Sheng Hua. 2011. A transductive multi-label learning
approach for video concept detection. Pattern Recognit. 44, 10–11, 2274–2286. DOI:http://dx.doi.org/
10.1016/j.patcog.2010.07.015
Le Wu and Min-Ling Zhang. 2013. Multi-label classification with unlabeled data: An inductive approach. In
ACML. 197–212.
Hongxia Yang and Jingrui He. 2014. Learning with dual heterogeneity: A nonparametric Bayes model. In
KDD. 582–590.
Pei Yang and Wei Gao. 2013. Multi-view discriminant transfer learning. In IJCAI. 1848–1854.
Pei Yang, Jingrui He, and Jia-Yu Pan. 2015. Learning complex rare categories with dual heterogeneity. In
SDM. 523–531.
Pei Yang, Jingrui He, Hongxia Yang, and Haoda Fu. 2014. Learning from label and feature heterogeneity. In
ICDM. 1079–1084.
Hsiang-Fu Yu, Prateek Jain, Purushottam Kar, and Inderjit S. Dhillon. 2014. Large-scale multi-label learning
with missing labels. In ICML. 593–601.
Jintao Zhang and Jun Huan. 2012. Inductive multi-task learning with multiple view data. In KDD. 543–551.
Min-Ling Zhang and Zhi-Hua Zhou. 2014. A review on multi-label learning algorithms. IEEE Trans. Knowl.
Data Eng. 26, 8, 1819–1837.

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Jointly Modeling Label and Feature Heterogeneity in Medical Informatics

39:25

Min-Ling Zhang. 2011. LIFT: multi-label learning with label-specific features. In IJCAI. 1609–1614.
Min-Ling Zhang and Kun Zhang. 2010. Multi-label learning by exploiting label dependency. In KDD. 999–
1008.
Min-Ling Zhang and Zhi-Hua Zhou. 2007. ML-KNN: A lazy learning approach to multi-label learning. Pattern
Recognit., 2038–2048.
Xiaoyu Zhang, Jian Cheng, Changsheng Xu, Hanqing Lu, and Songde Ma. 2009. Multi-view multi-label
active learning for image classification. In ICME. 258–261.
Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal, Jason Weston, and Bernhard Schölkopf. 2004. Learning with local and global consistency. In NIPS.
Dengyong Zhou, Jiayuan Huang, and Bernhard Scholkopf. 2007. Learning with hypergraphs: Clustering,
classification, and embedding. In NIPS. 1601–1608.
Jiayu Zhou, Jianhui Chen, and Jieping Ye. 2011. Clustered multi-task learning via alternating structure
optimization. In NIPS. 702–710.
Received September 2014; revised March 2015; accepted April 2015

ACM Transactions on Knowledge Discovery from Data, Vol. 10, No. 4, Article 39, Publication date: May 2016.

Multiple Random Walk and Its Application
in Content-Based Image Retrieval*
Jingrui He1, Hanghang Tong1, Mingjing Li2, Wei-Ying Ma2, Changshui Zhang3
1,3

Department of Automation, Tsinghua University, Beijing 100084, China
2

1

Microsft Research Asia, 49 Zhichun Road, Beijing 100080, China

{hejingrui98, walkstar98}@mails.tsinghua.edu.cn, 2{mjli, wyma}@microsoft.com
3
zcs@tsinghua.edu.cn

ABSTRACT

1. INTRODUCTION

In this paper, we propose a transductive learning method for
content-based image retrieval: Multiple Random Walk (MRW).
Its basic idea is to construct two generative models by means of
Markov random walks, one for images relevant to the query
concept and the other for the irrelevant ones. The goal is to obtain
the likelihood functions of both classes. Firstly, MRW generates
two random walks with virtual absorbing boundaries, and uses the
absorbing probabilities as the initial estimation of the likelihood
functions. Then it refines the two random walks through an EMlike iterative procedure in order to get more accurate estimation of
the likelihood functions. Class priors are also obtained in this
procedure. Finally, MRW ranks all the unlabeled images in the
database according to their posterior probabilities of being
relevant. By using both labeled and unlabeled data, MRW can be
seen as a transductive learning method, which has been
demonstrated to outperform inductive ones by previous research
work. Systematic experiments on a general-purpose image
database consisting of 5,000 Corel images demonstrate the
superiority of MRW over state-of-the-art techniques.

With the prevalence of World Wide Web, the number of
accessible digital images is growing at an exponential speed. To
make the best use of these resources, people need an efficient and
effective tool to manage them. In such context, Content-Based
Image Retrieval (CBIR) was proposed in the early 1990’s. It
depends on low-level features to find images relevant to the query
concept, which is represented by the query example provided by
the user. Comparing with traditional image retrieval paradigms,
where the images are first annotated manually by keywords, and
then retrieved according to the annotations, CBIR has the
following advantages: 1. feature extraction can be performed fully
automatically without human intervention; 2. the images’ own
content is always consistent.*
The initial research work in CBIR focuses on exploring an ideal
descriptor for image content. Generally speaking, these low-level
features can be categorized into three major groups: color [4, 12,
20], texture [8, 10, 11, 23], and shape [16, 17, 28]. However, their
performance is far from satisfactory due to the well-known gap
between low-level features and high-level semantic concepts. To
be specific, images of dissimilar semantic content may share some
common low-level features, while images of similar semantic
content may be scattered in the feature space [2].

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications – image
databases; H.3.3 [Information Storage and Retrieval]:
Information Search and Retrieval – search process, relevance
feedback.

The first attempt towards bridging this gap is searching for
appropriate metrics to measure perceptual similarity. These
metrics can be classified into pair-wise and global ones. The first
class includes the simplest Minkowski distances (L1 distance, L2
distance, etc), as well as the more complicated ones, such as
Dynamic Partial distance Function (DPF) [7] and Earth Mover’s
Distance (EMD) [14]. A representative example of the second
class is the transductive learning framework named ManifoldRanking Based Image Retrieval (MRBIR) proposed by He et al
[2], which uses the manifold-ranking algorithm to explore the
relationship among all the data points in the feature space, and
then measures relevance between the query and all the images in
the database accordingly. Comparing these two classes of metrics,
the former has the advantage of very fast processing speed, while
the latter is more accurate since it takes into consideration global
relationship. However, this attempt is subject to the limited
information available to describe the query concept, that is, we
only have one query example provided by the user. Therefore, the

General Terms
Algorithms, Experimentation, Theory.

Keywords
Markov random walk, generative model, likelihood function, class
prior, image retrieval, relevance feedback.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
MIR’05, November 10-11, 2005, Singapore.
Copyright 2005 ACM 1-59593-244-5/05/0011…$5.00.

*

151

This work was performed at Microsoft Research Asia.

In MRW, when we design the two generative models, two virtual
absorbing boundaries are added to each random walk: one
positive boundary, and the other non-positive boundary. Only
labeled data are connected with the positive boundary; while the
others are connected with the non-positive boundary. The
transition probabilities between vertices other than the absorbing
boundaries are based on the affinity matrix. After sufficiently
large transition steps, the random walks output the absorbing
probabilities that correspond to each data point, which, after
normalization, would be taken as the initial estimation of the
likelihood functions. Then through an EM-like iterative
procedure, MRW refines the random walks in terms of their
transition matrices, in order to better estimate the likelihood
functions. Class priors are also obtained in this procedure. Finally,
by feeding these likelihood functions and the class priors into the
Bayes’ formula, MRW outputs the posterior probability that each
data point is relevant to the query concept, and ranks the data
points accordingly.

proposed similarity metrics cannot always measure perceptual
similarity accurately, and the retrieval precision is low.
A more promising line of research to bridge the semantic gap is to
incorporate relevance feedback [13] into CBIR. Relevance
feedback is a powerful tool borrowed from the community of
information retrieval [15]. In each round, the CBIR system returns
a certain number of images to the user, and asks for their
relevance degree. In this way the system is able to gradually learn
the user’s query concept, and improve the retrieval result. To
make the best use of this additional information, an effective
learning method should be used to identify the relevant images
from the irrelevant ones. Again, state-of-the-art learning methods
can be classified as inductive and transductive ones, according to
whether unlabeled data is utilized in the training stage or not [2].
Inductive methods include Support Vector Machine (SVM) [25],
boosting [22], etc. These methods essentially construct
discriminative models for the two classes of images (relevant vs.
irrelevant), and rank the images in the database according to the
classification results. However, they all suffer from the smallsample-size problem, which might bring great degradation to the
accuracy of the discriminative models. On the other hand,
transductive methods provide a way to solve this problem by
using unlabeled data, such as Discriminant-EM [24], MRBIR [2],
etc. D-EM proposed by Wu et al [24] makes use of unlabeled data
to construct a generative model, which will be used to measure
relevance between the query and database images. However, if the
components of data distribution are mixed up, its performance
will be compromised. In MRBIR, when both relevant and
irrelevant images are fed back by the user, it discriminately
spreads their ranking scores via the unlabeled data, and then
combines the scores to get the improved retrieval result. One
major problem with MRBIR is that no general guideline has been
given to spread the scores of irrelevant images, that is, how to
determine the coefficient that affects the contribution of negative
ranking scores to the final score. This problem affects the
generalization performance of MRBIR to different databases.

In the initial retrieval stage, where only one query example is
available, the generative model for images relevant to the query
concept can be readily constructed by Markov random walk,
while that for irrelevant images cannot due to the lack of negative
examples. Instead, the likelihood function of the negative class
can be approximated based on pair-wise distance between lowlevel features. In relevance feedback, both relevant and irrelevant
images are provided by the user. They can be used to construct the
two generative models, which will lead to more accurate
estimation of the posterior probabilities, and better retrieval
results accordingly.
The rest of the paper is organized as follows. In Section 2, we
introduce the proposed Multiple Random Walk. Then we
elaborate on the details of its application in CBIR in Section 3,
including the initial retrieval stage and relevance feedback.
Experimental results are given in Section 4, followed by
concluding remarks in Section 5.

2. MULTIPLE RANDOM WALK

In this paper, we propose a novel transductive method for CBIR:
Multiple Random Walk (MRW). It constructs two generative
models for the two classes of images (relevant and irrelevant) by
means of Markov random walks, using both labeled and unlabeled
data. The goal is to estimate the likelihood functions that given
the positive (negative) class, a certain data point is generated. The
difference between D-EM and MRW is the method used to
construct the generative models. The former utilizes Gaussian
distribution to represent both classes, which might be too simple
to depict the complex distribution of image features; while the
latter utilizes the graphical model to achieve this goal, which is
suitable to capture the relationship among data points with various
underlying distributions. On the other hand, when comparing
MRBIR with MRW, we can see that the former is a special
example of the latter where class priors are fixed beforehand (they
correspond to the coefficient that affects the contribution of
negative ranking scores to the final score), and the two generative
models do not fully utilize the label information. By allowing the
class priors to be determined automatically, MRW can be easily
applied to different databases; by making full use of the label
information to characterize the two random walks, we can better
understand the query concept, and achieve higher precision.

From the perspective of probability theory, image retrieval can be
seen as a procedure of ranking images in the database according
to their posterior probabilities of being relevant to the query
concept. To obtain the posterior probabilities, we need to know
the class priors (the prior probabilities of the positive and negative
classes) and the likelihood functions (the probability of generating
a certain data point given the class label). In this section, we
introduce MRW in a general setting. After giving some notations,
we will introduce the way by which MRW calculates the
likelihood functions via Markov random walks, and then present
the EM-like iterative procedure in which both the priors and the
likelihood functions are refined gradually. Finally, we will give
the flowchart of MRW to help illustrate this transductive method.

2.1 Notations
Consider a binary classification problem. Suppose that we have a
set
of
n
data
points:

χ = { x1 ,K, xn , xn +1 ,K, xn
+

+

+

+ n−

}

, xn+ + n− +1 ,K, xn ⊂

m

. The first n+

points are positive examples with yi = 1, i = 1,K , n+ , the next n−
points are negative examples with yi = −1, i = n+ + 1,K , n+ + n− ,
while the remaining n − n+ − n− points are unlabeled examples.

152

Furthermore, we define an undirected graph G = (V , E ) , where

Based on the above discussion, the ( n + 2 ) × ( n + 2 ) transition

V is the vertex set including the n data points, and E
corresponds to the edges connecting two vertices with weights
wij ( i , j = 1,K n ) . Our goal is to predict the class labels of all the

matrix of the enlarged graph G + can be written as follows:

 1

PG + =  0

+
 BG + y

unlabeled points based on their posterior probabilities of being
positive and negative.

2.2 Generative Model in MRW
To begin with, let us come to a brief introduction to Markov
random walk. A random walk is a finite Markov chain that is
time-reversible [9]. To be specific, imagine a particle walking
along the vertices of a graph. From a starting point, it moves to
one of its neighbors with a certain probability in one step; then
from this point, it moves again in subsequent step, etc. It is worth
noticing that Markov random walk satisfies the following Markov
property: P[ X t +1 | X 0 , X 1 ,..., X t ] = P[ X t +1 | X t ] , where X t denotes the
status of the particle at time t . That is, the next move does not
depend on previous status of the particle. Therefore, each random
walk can be uniquely characterized by a transition matrix. Markov
random walk has been applied in many research fields [9]. For
example, by making use of the fact that the distribution of the
particle status tends to the stationary distribution as t → ∞ , it
can be used to design sampling algorithms. In this paper, we apply
Markov random walk to construct generative models for the two
classes.

BG +

)

β 0 K 0 
α 0 K 0 
0 O O M 


, A + = 0 O O M 
=
 M O O 0 G
 M O O 0




0 K 0 β
0 K 0 α 

(1)

(2)

y + is an n -dimensional label vector: yi+ = 1 , for i = 1,K , n+ ;
yi+ = 0 , for i = n+ + 1,K , n . BG + and AG + are n × n diagonal
matrices, with positive parameters α and β satisfying
α + β = 1 . The first (second) row denotes the probabilities of the
particle moving to the n + 2 vertices in one step given that it is
currently at vG+ + ( vG− + ). The other rows denote the transition
probabilities given that the particle is currently at one of the
vertices in V . From PG + , we can see that starting from positive
labeled examples, the particle has a constant probability β of
being absorbed by vG+ + in one step, while starting from all the
other examples, it has a constant probability β of being absorbed
by vG− + in one step. The value of β should be small enough so

matrix, with the ( i, i ) -element equal to the sum of the ith row of

that the particle can visit many vertices in V before being
absorbed by vG+ + or vG− + , thus global information is effectively

W . With these two matrices, we define P = D −1W . To construct
the positive random walk, we add two virtual absorbing
boundaries
to
G
to
get
an
enlarged
graph

}

BG + (1n − y

+

0Tn 

0Tn 

AG + P 

where 1n ( 0 n ) is an n -dimensional vector consisting of 1s (0s).

We first define the positive random walk (the random walk for the
positive class). Let W denote the n × n affinity matrix of graph
G , with its elements being wij . Let D denote the n × n diagonal

({

0
1

utilized.

)

( )

G + = V , vG+ + , vG− + , E + , where vG+ + and vG− + correspond to the

By calculating PG +

positive absorbing boundary and the non-positive absorbing
boundary respectively, and E + includes all the edges in E as
well as those connecting the absorbing boundaries and the
original vertices. To understand the meaning of absorbing
boundaries, again let us consider the particle walking along the
vertices of G + . An absorbing boundary is such a vertex that once
the particle moves to it, it will by no means move to other vertices
thereafter.

(the probabilities that starting from each vertex in V , the particle
is finally absorbed by vG+ + ) in the positive random walk:

(

)

−1

⋅ BG + y +

(3)

Furthermore, we normalize p + to get f + such that 1Tn ⋅ f + = 1 ,
which is used as the likelihood function of the positive class:

P ( xi y = 1) = f i +

(4)

Negative random walk (the random walk for the negative class) is
constructed in a similar way. Again, two virtual absorbing
boundaries are added to G to get the enlarged graph

examples. In other words, starting from vertices corresponding to
positive labeled examples, the particle have certain probabilities
of being absorbed by vG+ + in one step; while starting from other
vertices, the particle cannot reach v

, we can obtain the absorbing probability

p + = I − AG + P

Next we design the connection between absorbing boundaries and
the vertices in V for the positive random walk. It is reasonable to
connect the positive absorbing boundary vG+ + and the n+ positive

+
G+

∞

({

}

)

G − = V , vG+ − , vG− − , E − . The ( n + 2 ) × ( n + 2 ) transition matrix
on this enlarged graph is as follows:

in one step. Likewise, we

can also connect the non-positive absorbing boundary vG− + and

 1

PG − =  0

−
 BG − y

the remaining n − n+ examples. In other words, the particle may
be absorbed by vG− + in one step if and only if it starts from
vertices corresponding to the remaining n − n+ examples.

153

0
1

BG − (1n − y

−

)

0Tn 

0Tn 

AG − P 

(5)

BG −

β 0 K 0 
α 0 K 0 
0 O O M 


, A − = 0 O O M 
=
 M O O 0 G  M O O 0




0 K 0 β
0 K 0 α 

P(
(6)

∞

is equal to the current estimation of the posterior probability that
this example is a positive (negative) one multiplied by β . Note
that in this case, by introducing the posterior probabilities, MRW
can be less affected by noise in the labeled data. Similarly, starting
from all the other examples, the probability that the particle is
absorbed by vG− + ( vG− − ) in one step is equal to the current

probabilities that starting from each vertex in V , the particle is
finally absorbed by vG+ − ) in the negative random walk:

(

)

−1

⋅ BG − y −

(7)

After normalization, we get f − , which is used as the likelihood
function of the negative class:

P ( xi y = −1) = fi −

estimation of the posterior probability that this example is NOT a
positive (negative) one multiplied by β . To be specific, in the
positive random walk, if the ith example is a positive labeled one,

(8)

P
P(
P

(s)

AG( +

s +1)

where BG( +

s +1)

and AG( +

s +1)

s +1)

(s)

( y = −1) P ( xi

(y

i

(x

i

( y = −1) P ( xi

y = −1) + P ( y = 1) P

(x

i

s +1)

1

are the ( i, i ) -element of BG( +

s +1)

( j , j ) = β ⋅ P( s +1) ( y j = −1 x j )

(15)

( j , j ) = 1 − β P( s +1) ( y j = −1 x j )

(16)

( j , j ) = β (1 − P( s +1) ( y j = −1 x j ) )

(17)

( j , j ) = 1 − β (1 − P( s +1) ( y j = −1 x j ) )

(18)

s +1)

AG( −

s +1)

Otherwise,
BG( −

s +1)

y = 1)

With these matrices, the updated likelihood functions can be
obtained with equations (3), (4) and (7), (8). In this way, the label
information is effectively incorporated into the two random walks,
which is expected to improve the estimation of the likelihood
functions.

(9)
(s)

( i, i )

respectively. In the negative random walk, if the jth
BG( −

y = 1)

The E-step and M-step are executed alternatively and iteratively
until a stable state is reached. The estimation of the posterior
probabilities in the last iteration are output and used in image
retrieval. Since the proposed EM-like iterative procedure
essentially works in a hill-climbing manner [1], it is not expected
to reach a global optimal solution in all cases. However,
according to the experimental results in Section 4, it still improves

In M-step, based on the current estimation of the posterior
probabilities, we can refine the class priors as well as the random
walks. To be specific, the class priors are updated as follows:
P(

s +1)

example is a negative labeled one,

= −1 xi ) =
(s)

(14)

and AG( +

s +1)

y = −1) + P ( y = 1) P

P ( s ) ( y = −1) P ( s ) ( xi y = −1)

( i, i )

AG( −
(s)

( i, i ) = 1 − β (1 − P( s +1) ( yi = 1 xi ) )

s +1)

= 1 xi ) =
(s)

(13)

BG( +

In E-step, by feeding the current estimation of the likelihood
functions and the class priors into the Bayes’ formula, we can
obtain the posterior probabilities of each unlabeled example being
positive and negative:

P ( s ) ( y = 1) P ( s ) ( xi y = 1)

( i, i ) = β (1 − P( s +1) ( yi = 1 xi ) )

Otherwise,

Firstly, f and f are used to initialize the likelihood functions
of the positive class and negative class respectively. And the class
priors, P (0) ( y = 1) and P (0) ( y = −1) , are both set to 0.5.

i

(12)

s +1)

−

(y

( i, i ) = 1 − β P( s +1) ( yi = 1 xi )

AG( +

In this section, we will present an EM-like iterative procedure
used in MRW to refine the generative models as well as to obtain
the class priors.

P

(11)

s +1)

When we calculate the likelihood functions, one potential
problem with Equation (2) and Equation (6) is the constant
probability β of the particle being absorbed by the absorbing
boundaries in one step. Intuitively, starting from different data
points, the particle should have different probabilities of being
absorbed. On the other hand, according to the Bayes’ formula, to
obtain the posterior probabilities, besides the likelihood functions,
we also need to know the class priors ( P ( y = 1) and P ( y = −1) ).

( s +1)

( i, i ) = β ⋅ P( s +1) ( yi = 1 xi )

BG( +

2.3 EM-like Iterative Procedure in MRW

+

(10)

To update the positive (negative) random walk, we make the
following assumption: in the positive (negative) random walk,
starting from a positive (negative) labeled example, the
probability that the particle is absorbed by vG+ + ( vG+ − ) in one step

, we can obtain the absorbing probability (the

p − = I − AG − P

n

Here we assume P ( xi ) = 1 n , for i = 1,K , n .

i = n+ + 1,K , n+ + n− ; yi− = 0 , for i = 1,K , n+ , n+ + n− + 1,K , n . By

( )

1

( y = −1) = ∑ P( s +1) ( yi = −1 xi )
n
i =1

where y − is an n -dimensional label vector: yi− = 1 , for
calculating PG −

s +1)

n

( y = 1) = ∑ P( s +1) ( yi = 1 xi )
n
i =1

154

the performance
considerably.

of

state-of-the-art

techniques

in

CBIR

fi − =

Initialization:

(19)

where d ( q, i ) is the distance between the low-level features of

1.

Construct enlarged graph G+ ( G− );

2.

Calculate the absorbing probabilities according to

the query example and the ith image in the database; λ is a small
positive parameter to avoid zero denominator. In this scheme, the
larger d ( q, i ) is, the more probable this image is generated by the

Equation (3) (Equation (7));
3.

d ( q, i ) − d min

λ + d max − d ( q, i )

Normalize p + ( p − ) to get f + ( f − ), the initial

negative class. Based on this underlying principle, the likelihood
function of the negative class can be approximated using more
complex functions. In this paper, Equation (19) is adopted for the
sake of simplicity.

likelihood function of the positive (negative) class.

E-step: calculate the current estimation of the posterior

In the EM-like iterative procedure of MRW, the positive random
walk will not be revised in each iteration. This is to avoid
magnifying the estimation error since the number of labeled
example is very limited (only one positive example). On the other
hand, the likelihood function of the negative class is fixed at
Equation (19) and will not be revised either. Therefore, only the
class priors and the posterior probabilities are updated in each
iteration.

probabilities according to Equation (9);
M-step: update the class priors according to Equation (10);
update the random walks according to equations
(11)-(18), (3), (4), (7), and (8)
No
Stable?

Finally all the unlabeled images in the database are ranked in
descending order of their posterior probabilities of being relevant
to the query concept, which is obtained in the last iteration of the
EM-like iterative procedure.

Yes
Output the posterior probabilities P(s+1) ( yi = 1 xi )

Figure 1. Flowchart of MRW.

3.2 Relevance Feedback

2.4 Flowchart of MRW

In relevance feedback, the user will evaluate the system’s current
judgment on image relevance, and provide the labels for some
unlabeled images, both relevant and irrelevant. With these labeled
examples, we can construct the initial generative models for the
two classes of images following the equations in Subsection 2.2.
Next we can refine these models and the class priors via the EMlike iterative procedure, as in Subsection 2.3. Finally, we can
obtain the posterior probability of each unlabeled image being
relevant to the query concept, and rank the images accordingly.

According to the above discussion, the flowchart of MRW is
summarized in Figure 1.

3. MULTIPLE RANDOM WALK IN CBIR
When applying MRW to CBIR, several aspects have to be well
considered: 1. the initial retrieval stage where only one query
image can be used as the labeled example; 2. relevance feedback
where both relevant and irrelevant images are provided by the
user.

4. EXPERIMENTAL RESULTS

3.1 The Initial Retrieval Stage

We have evaluated the performance of MRW on a generalpurpose image database consisting of 5,000 Corel images. These
images are categorized into 50 groups, such as beach, bird,
mountain, jewelry, sunset, etc. Each of the categories contains 100
images of essentially the same content, which serve as the
groundtruth. We use each image in the database as a query, and
average the results over the 5,000 queries. The precision vs. scope
curve is used to evaluate the performance of various methods.

There are two typical query scenarios in CBIR: query by keyword
(QBK) and query by example (QBE). While the former need
additional information about the annotation of some database
images, the latter can be performed solely based on low-level
features, and it is the focus of this paper.
In the initial retrieval stage, there is only one image provided by
the user to express his or her query concept. With this query
example, the initial generative model of the positive class can be
easily constructed according to Subsection 2.2. However, due to
the lack of irrelevant images, the initial generative model of the
negative class cannot be constructed since the particle will never
be absorbed by the positive absorbing boundary in the negative
random walk, no matter where it starts. As an alternative, we
design the following scheme to define the likelihood function of
the negative class. Let d max and d min denote the maximum and

As is well known, feature selection is a large open problem and
might have a great impact on the retrieval results [2]. Besides the
traditional global features [4, 8, 11, 12, 17], recently a lot of
research work has investigated regional features to depict image
content [5]. However, regional features depend on image
segmentation, the performance of which is far from satisfactory.
Therefore, in our current implementation, we only adopt global
features, which are listed in Table 1. Note that we have
normalized each dimension of the features to [0,1] to eliminate
the effect of different scales.

minimum distances between the low-level features of the query
example and database images. Then the initial likelihood function
of the negative class is defined as follows:

155

Table 1. Features used in the experiments
Name

Description & Dimension

Color Correlogram [4]

HSV space, 144 dimensions

Color Histogram [20]

HSV space, 36 dimensions

Tamura Feature [8]

20 dimensions

Pyramid Wavelet Texture
Feature [10]

24 dimensions

4.2 Relevance Feedback
In relevance feedback, both positive and negative examples are
provided by the user, so the number of labeled examples is much
bigger than that in the initial retrieval stage, and the retrieval
performance is expected to be considerably improved. Note that
the most relevant images judged by the current system are
presented to and labeled by the user in each round of relevance
feedback, which is the so-called most relevant strategy in [3].
Next we compare MRW and MRBIR with respect to their ability
to improve the retrieval performance in relevance feedback. As in
[2], to provide a systematic evaluation, we fix the total number of
images that are marked by the user to 20, but vary the times of
feedback and the number of images fed back each time
accordingly. The combinations include: 1 feedback with 20
images each time; 2 feedbacks with 10 images each time; and 4
feedbacks with 5 images each time. The experimental results are
presented in Figure 3, Figure 4, and Figure 5 respectively.

As we adopt the method in [2] to construct the affinity matrix W ,
two parameters need to be set in MRW. The first one is the
number of neighbors K used to construct the affinity matrix. In
our experiments, it is set to 100 although the performance is not
very sensitive to its specific value. The second parameter is β ,
which is closely related to the probability of the particle being
absorbed by vG+ + ( vG+ − ) in one step, if it starts from a positive
(negative) labeled example. As discussed in Subsection 2.2, it
should be small enough so that the particle can visit many vertices
in V before being absorbed by vG+ + ( vG+ − ). In our experiments,

From the figures, we can see that MRW outperforms MRBIR no
matter which combination is used. Furthermore, as in the initial
retrieval stage, when the scope increases, the advantage of MRW
over MRBIR becomes more obvious. In contrast, the advantage of
MRBIR over the traditional SVM-based method becomes less
obvious with larger scope values [2]. Another interesting
observation is that: as fewer images are fed back in each round of
relevance feedback, the improvement of MRW over MRBIR
becomes less remarkable when equal number of labeled images
has been accumulated. For example, in Figure 3 where 20 images
are fed back by the user in each round, P10 (the precision among
the top 10 retrieved images) using MRBIR is 0.726, and it is
0.769 using MRW. The improvement is 5.92%. In Figure 4 where
10 images are fed back by the user in each round, P10 using
MRBIR is 0.758, and it is 0.794 using MRW. The improvement is
4.75%. In Figure 5 where 5 images are fed back by the user in
each round, P10 using MRBIR is 0.784, and it is 0.805 using
MRW. The improvement is 2.69%. The reason may be explained
as follows: when fewer images are fed back in each round, we
tend to obtain more positive examples in the 20 images that are
finally accumulated. On the one hand, more positive examples
help improve the performance MRBIR considerably [2]; on the
other hand, they may cause the sampling probability of labeled
examples to deviate from the actual distribution, so MRW does
not benefit much from the reduction of feed back images in each
round.

we set β = 0.01 ( α = 0.99 ), which is consistent with [2, 26, 27].
To demonstrate the effectiveness of MRW, we compare MRW
with MRBIR both in the initial retrieval stage and in relevance
feedback. The parameters of MRBIR are the same as in [2] in
order to make a fair comparison. Note that since He et al has
demonstrated the superiority of MRBIR over traditional methods
in [2], we will not include their results in our figures.

4.1 The Initial Retrieval Stage
In this subsection, we compare MRW and MRBIR in the initial
retrieval stage where only one query example is provided by the
user. The comparison results are illustrated in Figure 2. From the
figure, we can see that MRW consistently improves MRBIR no
matter what the scope is. Furthermore, as the scope increases, the
advantage of MRW over MRBIR becomes more obvious. Take
P100 (the precision among the top 100 retrieved images) as an
example, it is 0.254 using MRBIR, and is 0.280 using MRW,
which improves MRBIR by 10.2%. Therefore, we can conclude
that, by making use of the likelihood function of the negative class
(Equation (19)) and by adjusting the class priors in the EM-like
iterative procedure, MRW is able to learn the query concept more
accurately.
MRBIR

4.3 Response Time

MRW

In MRW, the E-step and M-step are repeated until a stable state is
reached. In most cases, the number of iteration steps is no more
than 10. In the initial retrieval stage, we only have to calculate the
absorbing probabilities once since the random walks are not
refined in the EM-like iterative procedure, so the processing speed
is fast (0.532 seconds, Pentium 4 1.80GHz, 512M RAM). In
relevance feedback, although we have to calculate the absorbing
probabilities in each iteration, we have designed an algorithm
similar to that in [26, 27], which helps to reduce the response time
greatly (5.125 seconds). Therefore, MRW meets the need of realtime retrieval tasks.

0.5

Precision

0.45
0.4
0.35
0.3
0.25
10

20

30

40

50

60

70

80

90

100

Scope

Figure 2. Comparison in the initial retrieval stage.

156

MRBIR

models for images that are relevant and irrelevant to the query
concept, we design two Markov random walks with positive and
non-positive virtual absorbing boundaries. After normalization,
the absorbing probabilities can be used as the initial estimation of
the likelihood functions. Furthermore, an EM-like iterative
procedure is designed to refine the random walks as well as to
obtain the class priors. Finally, the estimation of the posterior
probabilities are output by MRW and used in image retrieval.

MRW

0.8
0.75
0.7
Precision

0.65
0.6
0.55
0.5

In the initial retrieval stage where only one query image is
provided by the user, the generative model for relevant images can
be constructed by means of Markov random walk, while that for
irrelevant images is constructed based on pair-wise distance
between low-level features due to the lack of irrelevant images. In
the EM-like iterative procedure, only the class priors are updated.
Finally, all the unlabeled images in the database are ranked in
descending order of their posterior probabilities of being relevant.
In relevance feedback where both relevant and irrelevant images
are provided by the user, we can construct both the positive and
negative random walks using these labeled examples, thus obtain
a more accurate estimation of the posterior probabilities.
Systematic experimental results on a general-purpose image
database consisting of 5,000 Corel images demonstrate the
superiority of MRW over MRBIR.

0.45
0.4
0.35
0.3
10

20

30

40

50

60

70

80

90

100

Scope

Figure 3. Comparison after the first round of relevance
feedback with 20 images labeled by the user in each round.
MRBIR

MRW

0.8
0.75
0.7

Precision

0.65

6. REFERENCES

0.6

[1] Bilmes, J.A. A Gentle Tutorial of the EM Algorithm and Its
Application to Parameter Estimation for Gaussian Mixture
and Hidden Markov Models. Technical Report UMIACSTR-97-021, International Computer Science Institute and
U.C. Berkeley, 1998.

0.55
0.5
0.45
0.4
0.35

[2] He, J., Li, M., Zhang, H.J., Tong, H., and Zhang, C.
Manifold-ranking based image retrieval. Proc. 12th ACM Int.
Conf. on Multimedia, pp. 9-16, 2004.

0.3
10

20

30

40

50 60
Scope

70

80

90

100

[3] He, J., Li, M., Zhang, H.J, Tong, H., and Zhang, C. Mean
version space: a new active learning method for contentbased image retrieval. Proc. 6th ACM SIGMM Int. Workshop
on Multimedia Information Retrieval, pp. 15-22, 2004.

Figure 4. Comparison after the second round of relevance
feedback with 10 images labeled by the user in each round.
MRBIR

MRW

[4] Huang, J., Kumar, S.R., Mitra, M., Zhu, W.J., Zabih, R.
Image indexing using color correlograms. Proc. IEEE Conf.
on Computer Vision and Pattern Recognition, pp. 762-768,
1997.

0.8
0.75
0.7

[5] Jing, F., Li, M., Zhang, H.J., Zhang, B. An effective regionbased image retrieval framework. Proc. 10th ACM Int. Conf.
on Multimedia, pp. 456-465, 2002.

Precision

0.65
0.6
0.55

[6] Kokare, M., Chatterji, B.N., and Biswas, P.K. Comparison of
similarity metrics for texture image retrieval. IEEE Conf. on
Convergent Technologies for Asia-Pacific Region, vol. 2, pp.
571-575, 2003.

0.5
0.45
0.4
0.35

[7] Li, B., Chang, E., and Wu, C.T. DPF-a perceptual distance
function for image retrieval. Proc. IEEE Int. Conf. on Image
Processing, vol. 2, pp. 597-600, 2002.

0.3
10

20

30

40

50 60
Scope

70

80

90

100

[8] Liu, F., and Picard, R.W. Periodicity, directionality, and
randomness: Wold features for image modeling and retrieval.
IEEE Trans. on Pattern Analysis and Machine Intelligence,
vol. 18, pp. 722-733, 1996.

Figure 5. Comparison after the fourth round of relevance
feedback with 5 images labeled by the user in each round.

5. CONCLUSION

[9] Lovasz, L. Random walks on graphs: a survey.
Combinatorics Paul Erdos is Eighty, vol. 2, pp. 1-46, 1993.

In this paper, we have proposed a novel transductive method for
CBIR named Multiple Random Walk. To construct the generative

157

[10] Mallat, S.G. A theory for multiresolution signal
decomposition: the wavelet representation. IEEE Trans. on
Pattern Analysis and Machine Intelligence, vol. 11, pp. 674693, 1989.

[21] Szummer, M., and Jaakkola, T. Partially labeled
classification with Markov random walks. Neural
Information Processing Systems, 2002.
[22] Tieu, K., and Viola, P. Boosting image retrieval. Proc. IEEE
Conf. on Computer Vision and Pattern Recognition, vol. 1,
pp. 228-235, 2000.

[11] Manjunath, B.S., and Ma, W.Y. Texture features for
browsing and retrieval of image data. IEEE Trans. on
Pattern Analysis and Machine Intelligence, vol. 18, pp. 837842, 1996.

[23] Wang, J.Z., Wiederhold, G., Firschein, O., and Sha, X.W.
Content-based image indexing and searching using
Daubechies’ wavelets. Int. Journal of Digital Libraries, vol.
1, no. 4, pp. 311-328, 1998.

[12] Pass, G. Comparing images using color coherence vectors.
Proc. 4th ACM Int. Conf. on Multimedia, pp. 65-73, 1997.

[24] Wu, Y., Tian, Q., and Huang, T. Discriminant-EM algorithm
with application to image retrieval. Proc. IEEE Conf. on
Computer Vision and Pattern Recognition, vol. 1, pp. 155162, 2000.

[13] Rocchio, J.J. Relevance feedback in information retrieval.
The SMART Retrieval System, pp. 313-323, Prentice-Hall,
Englewood Cliffs, NJ, 1971.
[14] Rubner, Y., Tomasi, C., and Guibas, L. A metric for
distributions with applications to image databases. Proc. 6th
IEEE Int. Conf. on Computer Vision, pp. 59-66, 1998.

[25] Zhang, L., Lin, F., and Zhang, B. Support vector machine
learning for image retrieval. Proc. IEEE Int. Conf. on Image
Processing, vol. 2, pp. 721-724, 2001.

[15] Rui, Y., Huang, T.S., Ortega, M., and Mehrotra, S.
Relevance feedback: a power tool for interactive contentbased image retrieval. IEEE Trans. Circuits and Systems for
Video Technology, vol. 8, pp. 644-655, 1998.

[26] Zhou, D., Bousquet, O., Lal, T.N., Weston, J., and Schölkopf,
B. Learning with local and global consistency. Neural
Information Processing Systems, 2003.

[16] Schmid, C. A structured probabilistic model for recognition.
Proc. IEEE Conf. on Computer Vision and Pattern
Recognition, vol. 2, pp. 485-490, 1999.

[27] Zhou, D., Weston, J., Gretton, A., Bousquet, O., and
Schölkopf, B. Ranking on data manifolds. Neural
Information Processing Systems, 2003.

[17] Schmid, C., and Mohr, R. Local grayvalue invariants for
image retrieval. IEEE Trans. on Pattern Analysis and
Machine Intelligence, vol. 19, pp. 530-535, 1997.

[28] Zhou, X.S., Rui, Y., and Huang, T. Water-Filling: a novel
way for image structural feature extraction. Proc. IEEE Int.
Conf. on Image Processing, vol. 2, pp. 570-574, 1999.

[18] Shi, J., and Malik, J. Normalized cuts and image
segmentation. IEEE Trans. on Pattern Analysis and Machine
Intelligence, vol. 22, pp. 888-905, 2000.

[29] Zhu, X., Ghahramani, Z., and Lafferty, J. Semi-supervised
learning using Gaussian Fields and harmonic functions. Proc
12th Int. Conf. on Machine Learning, 2003.

[19] Stricker, M., and Orengo, M. Similarity of color images.
Storage and Retrieval for Image and Video Databases, Proc.
SPIE 2420, pp 381-392, 1995.
[20] Swain, M., and Ballard, D. Color indexing. Int. Journal of
Computer Vision, 7(1): 11-32, 1991.

158

MILEAGE: Multiple Instance LEArning with Global Embedding

Dan Zhang1
danzhang2008@gmail.com
Jingrui He2
jingrui.he@gmail.com
Luo Si3
lsi@cs.purdue.edu
Richard D. Lawrence4
ricklawr@us.ibm.com
1
Facebook Incorporation, Menlo Park, CA 94025
2
Computer Science Department, Stevens Institute of Technology, Hoboken, NJ 07030
3
Computer Science Department, Purdue University, West Lafayette, IN 47907
4
IBM T.J. Watson Research Center, Yorktown Heights, NY 10562

Abstract
Multiple Instance Learning (MIL) generally
represents each example as a collection of instances such that the features for local objects can be better captured, whereas traditional methods typically extract a global
feature vector for each example as an integral part. However, there is limited research work on investigating which of the
two learning scenarios performs better. This
paper proposes a novel framework – Multiple Instance LEArning with Global Embedding (MILEAGE), in which the global feature
vectors for traditional learning methods are
integrated into the MIL setting. Within the
proposed framework, a large margin method
is formulated to adaptively tune the weights
on the two different kinds of feature representations (i.e., global and multiple instance) for
each example and trains the classifier simultaneously. An extensive set of experiments
are conducted to demonstrate the advantages
of the proposed method.

1. Introduction
Traditional learning methods usually consider each
example as one non-separable entity, and represent
the whole content of the example by one feature
vector. However, the semantic meanings of an example sometimes vary among its constituent parts.
Multiple Instance Learning (MIL) has been proposed
to deal with problems whose output information is
Proceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR:
W&CP volume 28. Copyright 2013 by the author(s).

only known for bags of items/instances, as opposed
to for each example. More precisely, in a MIL setting, each example/bag is divided into several different parts/instances. The labels are assigned to bags,
rather than individual instances. A bag is labeled
as positive if it contains more than one positive instance; otherwise it is labeled as negative. In this
paper, for each example, the feature vector extracted
by using the same way as we do for traditional nonMIL methods (i.e., treating each example as an integral entity) is referred to as the global representation of this example, while its local representation is a set of instances extracted for each part of
this example, as in MIL. To some extent, the global
representation for each example can also be considered as its bag level features. Numerous methods have
been developed for MIL classification (Andrews et al.,
2003; Dietterich et al., 1998; Kim & la Torre, 2010)
and its variants, such as outlier detection (Wu et al.,
2010), online learning (Babenko et al., 2011), ranking (Hu et al., 2008), etc.
These methods have
been widely employed in areas such as text mining
(Andrews et al., 2003) and localized content based image retrieval (LCBIR) (Rahmani & Goldman, 2006).
Most previous MIL methods focused on improving
classification performance under local representation.
However, few of them investigated whether the local
representation is always better than the global one.
This problem has posed a big challenge for researchers
to decide what kind of algorithms should be used when
facing real world applications. In (Ray & Craven,
2005), the authors compared the performances of traditional and MIL methods. However, their work is still
based on the local representation, and adapts the traditional learning methods to the local representation.
Although rarely studied, it is intuitive that the true

MILEAGE: Multiple Instance LEArning with Global Embedding

positive rates in positive bags could affect the performances of local and global representations significantly. This is because if the true positive rate in
a positive bag is low, then its global representation
will be dominated by the irrelevant parts of this example, while methods based on local representation
could pick the true positive instances for training. On
the contrary, if an example has few irrelevant parts,
then the global representation tends to be more informative than the local one, since methods based on local representations normally focus on some local parts
of each example. This intuition can also be verified
empirically by the experiments conducted in Section
4.1. When incorporating this intuition into real applications, the major challenge is how to learn for each
training example, whether local representation is better or global one tends to prevail.

ture representation, for each example, its local feature representations, i.e., instances for different parts
of this example, are also available (The notions of
global and local representations are defined in Section 1). The instances in the i-th bag are denoted
as: Bi∗ = {Bi1 , Bi2 , . . . , Bini } ∈ Rd×ni 1 , and ni is
the number of instances in the i-th bag. Throughout
the paper, subscript ∗ means j = 1, . . . , ni . Given an
unlabeled example Bu and its associated local representations, i.e., Bu∗ , the objective of Multiple Instance
LEArning with Global Embedding (MILEAGE) is to
design a function f : (Bu , Bu∗ ) → R, such that the
classification on this unlabeled example is accurate. If
f (Bu , Bu∗ ) > 0, this example is classified as positive
and otherwise negative.

To solve this challenge, a novel research framework
– Multiple Instance LEArning with Global Embedding (MILEAGE) is proposed. MILEAGE leverages
the benefits from both local and global representations
such that in general it can achieve a better performance than both MIL and traditional learning methods. From another perspective, local and global feature representations can be treated as two information
sources, and each of them carries some auxiliary information to improve classification performance, which
is similar to the basic motivation of multi-view learning methods (Joachims et al., 2001). To solve the proposed framework, a novel method is designed by adaptively tuning the importance of the two different representations. It is based on the intuition that local
representation tends to perform better when the positive ratio is small. An iterative method is employed
to solve the derived optimization problem. To accelerate the optimization speed, inspired by (Fuduli et al.,
2004), we adapt the bundle method to solve the resulting non-convex non-smooth problem by explicitly considering the convex regularization and the non-convex
loss terms. Some discussions and theoretical analysis
have been provided on important properties such as
convergence rate and generalized error rate of the proposed method. Experiments on image, text datasets
and a novel application – Insider Threat Detection,
demonstrate the advantages of the proposed method.

For each bag, a weight variable is introduced to balance the importance of the two representations. The
weight is decided by both the prior knowledge from the
positive ratio for each bag and the fitness of the data.
Without loss of generality, given a specific example Bi
and its associated instances Bi∗ , the classifier takes
the following form:

2. Methodology
2.1. Problem Statement and Notation
Suppose a set of examples: D = {(Bi , Bi∗ , Yi ), i =
1, . . . , n} are given, where Bi ∈ Rd×1 denotes the
global representation for the i-th example and Yi ∈
{1, −1} is its binary label. Along with the global fea-

2.2. Method

f (Bi , Bi∗ ) = λi max wT Bij + (1 − λi )wT Bi ,
j

(1)

where 1 ≥ λi ≥ 0 is the convex combination coefficient for the i-th example, w ∈ Rd×1 is the linear
classifier and we assume that the bias has already been
absorbed into feature vectors. maxj wT Bij is the output from the local representation of the i-th example2 ,
whereas wT Bi is the output from its global representation. f (Bi , Bi∗ ) balances these two outputs through
the weight λi . From a Bayesian perspective, given a
dataset, the logarithm of the posterior distribution for
w and λ can be written as follows:
log P (w, λ|D) ∝ log P (D|w, λ)P (w)

n
Y

P (λi ),

(2)

i=1

where λ = [λ1 , . . . , λn ]. Here, we assume that the
examples are i.i.d. generated. P (w) follows the Gaussian distribution N (0, I). P (λi ) follows the Beta distribution with beta(γe−µri , γe−µ(1−ri ) ), where µ and
γ are the hyper-parameters and partially control the
mean and skewness of the distribution. ri ∈ [0, 1] is
the prior knowledge on the positive ratio for the ith bag, and can be obtained through various ways.
For example, ri can be simply set to 0.5 if no prior
knowledge is available. In practice, a preliminary classifier can be trained beforehand by using SVM on
1

We assume that the local and global representations
share the same feature space. But the proposed formulation can be extended to the case when their feature spaces
are different.
2
The output of each example in MIL is normally decided
by the instance that appears to be most positive under a
classifier w (Andrews et al., 2003)

MILEAGE: Multiple Instance LEArning with Global Embedding

{(Bi , Yi ), i = 1, . . . , n}. Then, ri can be estimated by
applying this classifier on the instances in each bag. It
is clear that E(λi ) = e−µri /(e−µri + e−µ(1−ri ) ). Given
w and λ, the probability of generating a dataset D
can be described by the hinge loss as: P (D|w, λ) ∝
Qn
−C max{0,1−Yi (λi maxj wT Bij +(1−λi )wT Bi )}
, where C
i=1 e
is a parameter. Then, maximizing Eq.(2) is equivalent
to solving the following problem:
n
n
X
X
1
kwk2 + C
ξi −
(γe−µri − 1) log λi
w,λ,ξi ≥0 2
i=1
i=1

+(γe−µ(1−ri ) − 1) log(1 − λi )
(3)

min

s.t. ∀i ∈ {1, . . . , n},
Yi (λi max wT Bij + (1 − λi )wT Bi ) ≥ 1 − ξi .
j

This formulation is non-convex and cannot be solved
directly. An iterative method is employed to solve this
problem. In particular, for the k-th iteration, given
w(k−1) , λ1 , . . . , λn can be updated by:
n
X

min C
λ

−

i=1

n
X

((γe

− 1) log λi + (γe

−µ(1−ri )

− 1) log(1 − λi ))

(4)

(k−1)

where ji
= arg maxj w(k−1)T Bij . The convexity
of this objective function cannot be determined, since
the signs of (γe−µri − 1) and (γe−µ(1−ri ) − 1) are not
clear. But some methods, such as the adapted subgradient method, can still be used to find its optimal
or local optimal solution efficiently. Given λ from the
previous step, w(k) can be optimized by:

C

n
X
i=1

2.3. Bundle Method for Non-Convex
Non-Smooth Optimization
The traditional bundle method looks for a set of cut-

i=1

w

It is clear that the proposed formulation is inductive on the classifier but transductive on λi . So, if
we only need to predict the unlabeled instances in
the unlabeled set, then we can directly apply the
learned classifier. If the prediction is made on the
bag level, on an unlabeled example (Bu , Bu∗ ), j =
1, . . . , nu . Its hidden variable λu can be estimated as:
λ∗u = E(λu |Bu , Bu∗ ) = e−µru /(e−µru + e−µ(1−ru ) ),
where ru is the positive instance ratio within this
bag estimated from the learned classifier w. Then,
f (Bu , Bu∗ ) = λ∗u maxj wT Buj + (1 − λ∗u )wT Bu . If
f (Bu , Bu∗ ) > 0, the example is labeled as positive
and otherwise it is labeled as negative.

max{0, 1 − Yi (λi w(k−1)T Bij (k−1) + (1 − λi )w(k−1)T Bi )}
ting planes that could serve as lower bounds of the
i

−µri

min

on these updating schemes, problem (4) and problem
(5) will be conducted iteratively until convergence.

1
kwk2 +
2

(5)

max{0, 1 − Yi (λi max wT Bij + (1 − λi )wT Bi )}
j

original convex objective function. For non-convex
optimization problems, however, these cutting planes
could no longer serve as lower bounds of the objective
functions, as shown in Fig.1. Some research works consider shifting of affine pieces downwards (Noll, 2012;
Schramm & Zowe, 1992). However, the amount of the
shifting appears arbitrary (Fuduli et al., 2004).
In this section, the bundle method, which is based on
first order approximation, is adapted to solve problem
(5). In particular, the intended objective function can
be casted as the following framework:
min
w

F (w) = Ω(w) + Remp (w),

(6)

where Ω(w) is a non-negative convex differentiable regularizer, and Remp (w) is a non-convex non-smooth
It is still a non-convex non-smooth optimization probloss function. In problem (5), Ω(w) = 21 kwk2
lem. But the form is much less complicated than
and Remp (w) = C max{0, 1 − Yi (λi maxj wT Bij + (1 −
that of problem (3). It can be solved through varλi )wT Bi )}.
ious ways, such as constrained concave-convex procedure (CCCP) (Yuille & Rangarajan, 2003). HowThis method handles this non-convex non-smooth
ever, the computational cost for solving this problem
problem in an iterative way and exhibits a kind of both
convex and nonconvex behavior relative to the current
is non-trivial. In several recent works, the bundle
point in the iterative procedure. More precisely, for
method has shown its superior performance in both efthe t-th iteration of bundle method, it maintains two
ficiency and effectiveness over state-of-the-art methods
(t)
sets of cutting planes, i.e., I+ , {j|αj ≥ 0}, I− ,
(Joachims, 2006; Joachims et al., 2009; Smola et al.,
(t)
2007; Teo et al., 2010). However, one major drawback
{j|αj < 0}, where j = 1, . . . , t − 1 and
for this method is that it can only be employed to solve
(t)
(t−1)
) − Remp (w(j) ) − gjT (w(t−1) − w(j) ). (7)
convex optimization problems. In (Fuduli et al., 2004; αj , Remp (w
Hare & Sagastizábal, 2010; Noll, 2012), several heurisHere, gj ∈ ∂w Remp (w(j) )3 . Then, the following two
tics are employed to handle this issue for the bundle method. In this paper, inspired by (Fuduli et al.,
3
For simplification, we abused the superscript. Please
2004), we adapt the bundle method to solve this pronote that in this section, the superscript t denotes the t-th
posed optimization problem in the next section. Based
iteration in the bundle method.

MILEAGE: Multiple Instance LEArning with Global Embedding

solution for the previous step is kept, and the proximity parameter will shrink for a better solution. If
kw(t) − w(t−1) k is less than a predefined threshold θ,
the proximity parameter will also shrink to do a more
thorough search within that region.

Figure 1. Approximation of Remp (w) at w4 . The cutting
planes from other points either over or underestimate the
value at and in the vicinity of w4 , and the sign of αi will
not change in the vicinity of w4 (α1 < 0, α2 > 0, α3 < 0).
Based on this locality characteristic, we adapted the bundle
method in Section 2.3.

sets of affine functions are defined as:
(t)

∆+ (w) , max gjT (w − w(t−1) ) − αj ,
j∈I+

(t)

∆− (w) , min gjT (w − w(t−1) ) − αj .
j∈I−

(t)

(8)

It is clear that ∆+ (w) is an approximation of
Remp (w) − Remp (w(t−1) ), while ∆− (w) is its locally
pessimistic estimation. These approximations are only
locally valid around the local minimal point. Here,
(t)
the meanings of αj and the locality property can
be shown in Fig.1. Therefore, during each iteration, the new optimal point should tradeoff minimizing
∆+ (w) and proximity kw−w(t−1) k with the constraint
∆+ (w) ≤ ∆− (w) as follows:
min
w,ζ

s.t.

P (w, γ (t) ) = γ (t) (ζ + Ω(w)) +

The classic bundle method usually checks whether the
difference between the objective function value and
the cutting plane function value is less than a threshold. If so, the iteration terminates. Here, this strategy cannot be used because the cutting planes of the
non-convex function cannot be considered as the lower
bounds for the original objective function any more.
In the proposed method, during each iteration, two
stopping criteria will be checked. The first stopping
criteria is to check whether γ (t) is smaller than a specified threshold ǫ1 . This is because although we hope
that the new updated point should fall within a small
region of w(t−1) , if γ (t) becomes too small, w(t) is unlikely to deviate too much from w(t−1) , and the results will not be meaningful. An extreme example is
if γ (t) = 0, then w(t) = w(t−1) . The second stopping
criteria is to check whether 0 ∈ ∂F (w(t) ), i.e., whether
w(t) can be considered as a stationary point for F (w).
In practice, we check whether ko∗ k/F (w(t) ) ≤ δ,
where o∗ = mino∈conv{gj |j∈J+ } ko + ∂Ω(w(t) )k and

1
kw − w(t−1) k2 (9)
2

(t)

ζ ≥ gjT (w − w(t−1) ) − αj , j ∈ I+ ,
(t)

ζ ≤ gjT (w − w(t−1) ) − αj , j ∈ I− ,

where γ (t) is the non-negative proximity control parameter for the t-th iteration that balances the objective function value and the proximity of the updated
point. This problem can be solved efficiently through
its dual form, since both of the sets I+ and I− are
small. Suppose w(t) = arg minw P (w, γ (t) ). If not
computationally expensive, a line search can be performed between w(t) and w(t−1) on F (w) such that a
better solution can be found.
If the optimal solution can result in a drastic decrease
in the objective function F (w), it is called a serious
step and the optimal solution for w will be updated.
Otherwise, it is considered as a null step, the optimal

J+ = {i ∈ I+ |αi ≤ ǫ2 }. In particular,
o∗ = Gυ ∗ + ∂Ω(w(t) ),

(10)

where G is a matrix with its columns being the subgradients gj from J+ and υ ∗ can be
optimized by solving υ ∗ = arg min υ T GT Gυ +
2(∂Ω(w(t) ))T Gυ s.t. υ T 1 = 1, υ ≥ 0.

3. Discussions and Theoretical Analysis
The proposed bundle method is summarized in Table
1. It is clear that the major advantage of the proposed
method over (Fuduli et al., 2004) is that the proposed
method better exploits the structure of the objective
function by treating the convex and non-convex parts
separately. It therefore eliminates the unnecessary first
order approximation for the convex part. In this way,
theoretically the cutting plane approximation for the
whole objective function is more accurate than the one
used in (Fuduli et al., 2004).
In (Bergeron et al., 2012), the authors directly applied (Fuduli et al., 2004) to MIL. However, there
are several major differences between these two papers. 1. (Bergeron et al., 2012) only focuses on
the traditional MIL, and can not be used to solve
MILEAGE. 2. By directly employing (Fuduli et al.,
2004), (Bergeron et al., 2012) does not treat the convex and non-convex parts separately either and therefore its first order approximation is less accurate than
the one used in this paper.

MILEAGE: Multiple Instance LEArning with Global Embedding
Input: 1. The objective function: Ω(w) + Remp (w). 2. Parameters: descent coefficient: m = 0.1, initial proximity
control parameter γ (1) = 1, deviation parameters ǫ1 = 0.01, ǫ2 = 0.1 and θ = 0.01, decay coefficient η = 0.9, gradient
precision δ = 0.01. Output: w.
1. Initialize w(1) , t=1
repeat:
2.
t = t + 1.
3.
Get (w(t) , ζ (t) ) by solving the dual of problem (9).
4.
If F (w(t) ) ≤ F (w(t−1) ) + m(ζ (t) + Ω(w(t) ) − Ω(w(t−1) )) and kw(t) − w(t−1) k ≥ θ
5.
γ (t) = γ (t−1)
6.
else
7.
γ (t) = ηγ (t−1)
8.
If γ (t) ≤ ǫ1 , then exit.
9.
If F (w(t) ) > F (w(t−1) ) + m(ζ (t) + Ω(w(t) ) − Ω(w(t−1) )), then, w(t) = w(t−1) .
10.
end if
11.
I+ = φ, I− = φ
12.
for j=1 . . . t
S
S
(t)
(t)
13.
Evaluate αj according to Eq.(7), if αj ≥ 0, then, I+ = I+ j; if αj < 0, then, I− = I− j;
14.
end for
15.
Compute o∗ according to Eq.(10). If ko∗ k/F (w(t) ) ≤ δ, then exit.
until algorithm terminates
16. w = w(t) .

Table 1. The proposed bundle method for non-convex non-smooth optimization

In (Do & Artières, 2009), the non-convex formulation
for hidden markov models is also solved by adapting
the bundle method to the non-convex case, and treating the convex and non-convex parts separately. The
adapted method is reasonable by tuning the cutting
plane at each iteration according to the comparison
with the previous “optimal” cutting plane. However,
even with this tuning, the obtained cutting plane is
still not able to serve as the lower bound of the objective function. On the contrary, the proposed method
does not focus on looking for the lower bound, but
some important local properties around each point.
Furthermore, based on the proposed bundle method,
some important properties are analyzed in Theorem 1
and Theorem 2.
Theorem 1:
Suppose D
= maxt Ω(w(t) )
γ2
and R
=
maxj kgj k,
then − 20 R2
≤
P (w(t) , γ (t) ) ≤ γ0 D.
In solving problem
γ 2C 2
≤
(5),
− 02 max{maxi,j kBij k2 , maxi kBi k2 }
P (w(t) , γ (t) ) ≤ γ0 D.
Proof: Please refer to Supplemental Materials.



Theorem 2: The bundle method terminates after at
0
most log γǫ10 / log(η) + 2Eγ
mθ 2 steps, given min Remp (w) +
Ω(w) is upper bounded by E. In solving problem (5),
the algorithm terminates after at most log γǫ10 / log(η)+
2nCγ0
mθ 2

steps.

Proof: Please refer to Supplemental Materials.



Suppose the class of classifier satisfies kwk ≤ B
and λ are obtained from iterative updates. Since
the proposed method can be easily extended to the
kernel case, FB is defined as: {f |f : (Bi , Bi∗ ) →
λi maxj wT φ(Bij ) + (1 − λi )wT φ(Bi ), kwk ≤ B},

where φ is a nonlinear map with kernel function K(·, ·).
The generalized error bound can be derived by the following theorems:
Theorem 3: The empirical Rademacher complexity of the functional space FB on D =
{(Bi , Bi∗ , Yi ), i = q
1, . . . , n} is upper bounded by:
Pn Pni 2 2
2B
max
T
ϕij ≥0,ϕi 1=1
i=1
j=1 λi ϕij K(Bij , Bij ) +
n
p
P
n
2B
2
i=1 (1 − λi ) K(Bi , Bi ).
n
Proof: Please refer to Supplemental Materials.



Theorem 4: Fix κ ∈ (0, 1). Then, with probability at least 1 − κ, every f P
∈ FB satisfies:
P (y 6= sign(f (Bi , Bi∗ ))) ≤ n1 ni=1 max{0, 1 −
Yi (λi maxj wT Bij q+
(1
−
λi )wT Bi )}
+
Pn Pni 2 2
2B
max
T
λ
ϕ
K(B
,
B
)
ij
ij +
ϕij ≥0,ϕi 1=1
i=1
j=1 i ij
n
q
p
Pn
ln(2/κ)
2B
2
i=1 (1 − λi ) K(Bi , Bi ) + 3
n
2n .
Proof: It can be proved by applying Theorem 3 to
Theorem 4.9 in (Shawe-Taylor & Cristianini, 2004). 
From Theorem 3 and Theorem 4, it can be seen that
the derived Rademacher complexity and generalized
error bound are related to both the local and global
feature representations. Theorem 5 states the case
when the Rademacher Complexity can be improved,
compared with both local and global feature representations.
C2
Theorem 5: Suppose a ≤ λi ≤ max{ C
a, 1 −
1
C2
. . . , n, a ∈ [0, 1], where C1 =
C1 (1 − a)}, i = 1,q
Pn Pni 2
2B
i=1
j=1 ϕij K(Bij , Bij )
n maxϕij ≥0,ϕT
i 1=1
pPn
2B
and
C2
=
K(Bi , Bi ),
then,
qPn P i=1
n
ni
2B
2 2
i=1
j=1 λi ϕij K(Bij , Bij ) +
n maxϕij ≥0,ϕT
i 1=1

MILEAGE: Multiple Instance LEArning with Global Embedding
20

1

20

1

15

0.95

15

0.95

0

5

0.85
0

0.8
−5

−5

0.75

−10

0.7

−15
−10

−5

0

5

10

15

20

Accuracy

Accuracy

5

0.9

10

0.9

10

0.65
0.1 0.2

SVM
MISVM
0.4

0.6

0.8

1

0.8
0.75

−10

0.7

−15

0.65

−20
−15

−10

−5

0

5

10

15

20

0.1

SVM
MISVM
0.5

1

Positive Ratio

Positive Ratio

(a)

0.85

(b)

(c)

(d)

Figure 2. Experiments with different positive ratios. The true positive (marked by red) and negative (marked by blue)
instance distributions are shown in (a) and (c) respectively, with different amount of overlap. The positive bags are
generated by extracting specified ratios of positive instances (as indicted in x-axis of (b) and (d)) and negative instances
from the two instance distributions, while negative bags are composed of negative instances. SVM and its MIL variant
– MISVM (Andrews et al., 2003), are used for comparisons. Here, for SVM, experiments are conducted on the averaged
features in each bag. In (b) and (d), the averaged accuracy of 20 independent runs under different positive ratios are
reported for datasets generated from (a) and (c) respectively.
2B
n

pPn

i=1 (1

− λi )2 K(Bi , Bi ) ≤ max{C1 , C2 }.

Proof: Please refer to Supplemental Materials.



In Theorem 5, C1 indicates the Rademacher Complexity derived from the local representation, while C2
represents the Rademacher Complexity for the global
representation. It can be concluded that, under some
restrictions, the Rademacher Complexity of the proposed method is guaranteed to be less than the maximum one of the Rademacher Complexities for local
and global representations.

4. Experiments
4.1. Synthetic Experiments
The synthetic dataset is designed to verify the intuitions conveyed in this paper, i.e., local representation
works better when the true positive ratios in positive
bags are lower, while global representation works better when the ratios are higher. In particular, we design
two sets of experiments as shown in Fig.2. For each
set of experiments, positive instances are generated
from a Gaussian distribution, and negative ones are
generated from another three Gaussian distributions,
with different amounts of overlap, as shown in Fig.2(a)
and Fig.2(c). Based on these two data distributions,
for each set of experiments, 6 toy datasets are created
with each positive bag containing a certain ratio of
positive and negative instances and each negative bag
containing all negative instances. Each bag contains
10 instances. For each dataset 1000 positive bags and
1000 negative ones are i.i.d. generated. SVM and its
MIL variant – MISVM (Andrews et al., 2003) (We report the comparison results of these two methods, be-

cause their objective functions are the same except for
the local and global representation part) are used for
comparison, where the average feature representation
of each bag is used as its global feature representation
and used by SVM. For each experiment, 50% examples are randomly picked for training, and the rest for
testing. The averaged results of 20 independent runs
under different ratios of positive instances in positive
bags are reported in Fig.2(b) and Fig.2(d) for datasets
generated from Fig.2(a) and Fig.2(c) respectively, with
the parameters tuned by 5-fold cross validation.
It can be partially concluded from the experiments
that: (1) The local representation is not always better
than the global one; (2) The local representation tends
to perform better than the global one when the positive ratio is low; (3) There is no universally “good”
positive ratio below which the local representation is
definitely better than the global one. (4) It seems that
if the amount of overlap between positive and negative
distributions is high, the local representation is likely
to be worse than that of the global representation4 .
4.2. Real Applications
These experiments are conducted on three datasets,
i.e., an image dataset from Corel (Andrews et al.,
2003), a text dataset from Reuters21578 as well as
newly proposed application – Insider Threat Detection. In MIL, MUSK (Dietterich et al., 1998) is also
a commonly used benchmark dataset. But its perfor4
Please note that although the overlap in Fig.2(c) looks
heavy on the instance level, SVM can still attain almost
100% accuracy. This is because their global features are
much better separated, since the average of the instance
features greatly reduce the variance of the distributions.

MILEAGE: Multiple Instance LEArning with Global Embedding

For Reuters21578, documents from 4 sub-categories,
as well as some negative documents, are randomly
picked. For each of the sub-dataset, after removing
the stop words and stemming, tf-idf (Manning et al.,
2008) features are extracted and processed by PCA
(Berry & Castellanos, 2007). The resulting dimensionality is 249. For each document/bag, the global
feature vector is extracted from the whole content;
while the instance features are derived through a sliding window with fixed length (Andrews et al., 2003).
For Reuters1, Reuters2, Reuters3, Reuters4, they contain 1602, 1256, 1100, 502 bags, and 3006, 2181, 2249,
920 instances, respectively.
For Insider Threat Detection (ITD), We obtained this
real dataset from a big IT company. ITD is a project
which is devoted to find the potential harmful insiders through analyzing their online behaviors, such as
sending emails, login, logout, downloaded files. In this
dataset, some experts are hired to decide whether during each period (around 30 days), each person in the
database did malicious things or not. Each online behavior is quantified as a feature value. However, it
is highly possible that if a person did malicious things
during a period, it does not mean that he did malicious
things every day. Out of this motivation, the features
for the online behaviors within one day is considered
as an instance and the instances during each period
is treated as a bag. If a person is known to do some
malicious things in a specific period, then the corresponding collection of instances (days) is considered as
a positive bag. Otherwise, this collection of instances
will be considered as negative. The global feature representation for each bag is extracted from the corresponding period as a whole. The whole dataset contains 1000 negative bags and 166 positive bags, where
each bag contains around 30 instances and each instance is represented by 32 features. On this dataset,
due to the imbalance of the dataset, F1 score for the
top 20 returned results is used here for measurement.

0.92
Accuracy

0.92
0.91
0.9

0.9
0.88
0.86
0.84

0.89
0.88

0.82
20

40

60 C 80

100

0.8
0

120

50

(a)

100

µ

150

200

250

(b)
0.95

Accuracy

The Corel dataset is divided into three sub-datasets,
i.e., Fox, Elephant and Tiger. For a detailed description of these three datasets, please refer to
(Andrews et al., 2003). For each picture/example in
Corel, the global feature vector is the average of the
instances on all dimensions.

0.93

Accuracy

mance is not reported here, because the meaning of
the global representation for MUSK is not clear. In
MUSK, instances represent different conformations of
molecule. For each molecule, a set of conformations
do not convey physical meanings in global representation. But for images and documents, each image or
document itself can be considered a concrete object.

0.9

0.85

20

40

γ

60

80

100

(c)
Figure 3. Parameter Sensitivity Comparisons

4.3. Comparison Results
In the proposed method, parameters C, γ and µ are
set through 5-fold cross validation on the training set
through the grids 2[−5:2:7] , 2[−4:2:8] and [0.1, 1, 10, 100]
respectively. To show the advantages of the proposed large margin method, we compare it with several baseline methods, including traditional large margin methods, SVM-B, SVM-I, and multiple instance
learning methods: Citation KNN (Wang & Zucker,
2000), MISVM (Andrews et al., 2003), miSVM
(Andrews et al., 2003), MILES (Chen et al., 2006),
and ISMIL (Fu & Robles-Kelly, 2009).
For SVM-B, SVM is used on the bag/global features
for training and prediction. For SVM-I, the bag labels are assigned to their corresponding instances, and
SVM is used on these labeled instances. For each unlabeled bag, if at least one of its instances is labeled
as positive by SVM-I, then its bag label is positive.
Otherwise, it is negative. As for MIL methods, Citation KNN is an adaptation of traditional K nearest
neighbor to MIL. MISVM and miSVM are two large
margin multiple instance classification methods, derived from SVM. MILES tries to represent each bag
by using one feature vector, and then design a classifier based on that. For ISMIL, the algorithm maps
bags into a space spanned by some selected instances,
and designs a classifier based on that. The parameters
of the baseline methods are also tuned by 5-fold cross
validation. For the large margin methods, for the fair
of comparison, only linear classifiers are used.
The average accuracy of 20 independent runs are reported in Table 2 and 3. For each experiment, 90%
examples are randomly sampled as training examples,

MILEAGE: Multiple Instance LEArning with Global Embedding

MILEAGE
SVM-B
SVM-I
CitationKNN
MISVM
miSVM
MILES
ISMIL

Fox
64.5
53.8
56.5
60.5
59.0
57.5
62.0
61.6

Image
Elephant
84.5
83.0
71.2
81.5
78.3
81.0
81.9
82.0

Tiger
84.0
76.0
72.5
82.0
81.7
78.3
77.5
78.9

Reuters1
90.3
90.5
88.5
86.5
90.6
88.2
88.9
88.0

Text
Reuters2
Reuters3
92.9
93.2
92.0
91.1
92.4
88.9
86.7
80.9
91.9
91.3
91.7
90.5
91.7
92.2
90.3
91.5

Reuters4
91.6
88.2
89.4
81.4
90.4
86.6
88.4
89.3

Insider Threat Detection
ITD
0.495
0.397
0.401
0.319
0.474
0.444
0.469
0.417

Table 2. Accuracy Comparisons (%) on Image and Text datasets, and F1 Comparisons on Insider Threat Detection. On
ITD dataset, F1 score for the top 20 returned results is used here for measurement due to the imbalance of the dataset.

MILEAGE
SVM-B
SVM-I
CitationKNN
MISVM
miSVM
MILES
ISMIL

Fox
26.2
0.06
0.8
42.7
27.9
25.3
26.6
9.5

Image
Elephant
48.7
0.01
0.5
48.5
13.7
19.3
30.1
11.3

Tiger
58.3
0.02
0.4
36.2
13.5
3.8
23.4
10.0

Reuters1
254.8
0.7
0.9
166.6
242.3
17.3
476.3
210.2

Text
Reuters2
Reuters3
225
74.5
0.7
0.4
1.2
0.8
90.4
80.0
431.2
309.3
10.5
7.5
236.4
201.0
100.3
62.1

Reuters4
53.9
0.2
0.7
14.3
165.5
1.2
17.0
10.8

Insider Threat Detection
ITD
12.6
0.8
0.7
93.8
4.6
5.8
2308
58.4

Table 3. Time Comparisons (in seconds)

while the remaining ones are used for testing. It is
clear that MIL methods are not better than the traditional learning methods on all of these datasets, which
further verifies that the local representation for MIL
may not be always better than the global representation. From these experimental results, in most cases,
MILEAGE shows the best performance. This is because MILEAGE takes advantage of both local and
global representations adaptively. These two different representations can be considered as two different
information sources, and both of them convey some
useful information in improving the performance.
For time comparisons, the proposed method is comparable with most of the other MIL methods. The
efficiency of the proposed bundle method plays an important role. For example, MISVM needs to solve a
non-convex problem similar to problem (5) only once
for each experiment, but the proposed method needs to
solve problems (4) and (5) for around 15 times before
convergence. So, the average amount of time needed
for each independent execution of the bundle method
is small, compared with that of MISVM. On the other
side, traditional learning methods such as SVM-B and
SVM-I tend to be more efficient because they can easily apply convex optimization methods such as Sequential Maximization Optimization to their convex
objective functions once with only one kind of representations. But the proposed MILEAGE framework
generate more accurate results in most cases due to
the more realistic non-convex setting of both global
representations and local representations.
To show the robustness of the proposed method, some
parameter sensitivity experiments are conducted on C,

µ, γ, and shown in Fig.3. The averaged experiments of
20 independent runs on Reuters4 are reported. From
these experiments, it can be seen that the proposed
method is relatively robust with respect to these parameters. We also observed similar patterns from experiments on the other datasets.

5. Conclusions
This paper presents a novel machine learning problem
– Multiple Instance LEArning with Global Embedding
(MILEAGE) for integrating the global feature representations into multiple instance learning. To solve the
proposed problem, a large margin method is proposed,
which adaptively tunes the weights for the two different feature representations imposed on each bag and
trains the classifier. To solve the resulted non-convex
non-smooth problem efficiently, an alternative method
is employed and the bundle method that explicitly
treats the convex and non-convex parts is suggested.
Some theoretical analysis, such as the time complexity and generalized error rate, are provided thereafter.
The experimental results on both the text and image
datasets, as well as the newly proposed application –
Insider Threat Detection, clearly demonstrate the advantages of the proposed method.

Acknowledgments
This work is partially supported by NSF research
grants IIS-0746830, CNS- 1012208 and IIS-1017837.
This work is also partially supported by the Center
for Science of Information (CSoI) under grant agreement CCF-0939370.

MILEAGE: Multiple Instance LEArning with Global Embedding

References
Andrews, S., Tsochantaridis, I., and Hofmann, T. Support
vector machines for multiple-instance learning. In NIPS,
2003.
Babenko, Boris, Yang, Ming-Hsuan, and Belongie, Serge.
Robust object tracking with online multiple instance
learning. IEEE Trans. Pattern Anal. Mach. Intell., 33
(8):1619–1632, 2011.

Noll, Dominikus. Bundle method for non-convex minimization with inexact subgradients and function values.
Computational and Analytical Mathematics, 2012.
Rahmani, R. and Goldman, S.A. MISSL: Multiple-instance
semi-supervised learning. In ICML, 2006.
Ray, Soumya and Craven, Mark. Supervised versus multiple instance learning: an empirical comparison. In
ICML, pp. 697–704, 2005.

Bergeron, Charles, Moore, Gregory M., Zaretzki, Jed,
Breneman, Curt M., and Bennett, Kristin P. Fast bundle
algorithm for multiple-instance learning. IEEE Trans.
Pattern Anal. Mach. Intell., 34(6):1068–1079, 2012.

Schramm, Helga and Zowe, Jochem. A version of the bundle idea for minimizing a nonsmooth function: Conceptual idea, convergence analysis, numerical results. SIAM
Journal on Optimization, 2(1):121, 1992.

Berry, Michael W. and Castellanos, Malu. Survey of Text
Mining: Clustering, Classification, and Retrieval, Second Edition. 2007.

Shawe-Taylor, John and Cristianini, Nello. Kernel Methods for Pattern Analysis. MCambridge University Press,
2004.

Chen, Yixin, Bi, Jinbo, and Wang, James Ze. Miles:
Multiple-instance learning via embedded instance selection. IEEE Trans. Pattern Anal. Mach. Intell., 28(12):
1931–1947, 2006.

Smola, Alex J., Vishwanathan, S. V. N., and Le, Quoc V.
Bundle methods for machine learning. In NIPS, 2007.

Dietterich, T. G., Lathrop, R. H., and Lozano-Perez, T.
Solving the multiple instance problem with axis-parallel
rectangles. In Artificial Intelligence, 1998.
Do, Trinh Minh Tri and Artières, Thierry. Large margin
training for hidden markov models with partially observed states. In ICML, pp. 34, 2009.
Fu, Zhouyu and Robles-Kelly, Antonio. An instance selection approach to multiple instance learning. In CVPR,
pp. 911–918, 2009.
Fuduli, Antonio, Gaudioso, Manlio, and Giallombardo,
Giovanni. Minimizing nonconvex nonsmooth functions
via cutting planes and proximity control. SIAM Journal
on Optimization, 14(3):743–756, 2004.
Hare, Warren and Sagastizábal, Claudia A. A redistributed
proximal bundle method for nonconvex optimization.
SIAM Journal on Optimization, 20(5):2442–2473, 2010.
Hu, Yang, Li, Mingjing, and Yu, Nenghai. Multipleinstance ranking: Learning to rank images for image
retrieval. In CVPR, 2008.
Joachims, Thorsten. Training linear svms in linear time.
In KDD, pp. 217–226, 2006.
Joachims, Thorsten, Cristianini, Nello, and Shawe-Taylor,
John. Composite kernels for hypertext categorisation.
In ICML, pp. 250–257, 2001.
Joachims, Thorsten, Finley, Thomas, and Yu, ChunNam John. Cutting-plane training of structural svms.
Machine Learning, 77(1):27–59, 2009.
Kim, Minyoung and la Torre, Fernando De. Gaussian processes multiple instance learning. In ICML, pp. 535–542,
2010.
Manning, Christopher D., Raghavan, Prabhakar, and
Schtze, Hinrich. Introduction to Information Retrieval.
Cambridge University Press, 2008.

Teo, Choon Hui, Vishwanathan, S. V. N., Smola, Alex J.,
and Le, Quoc V. Bundle methods for regularized risk
minimization. Journal of Machine Learning Research,
11:311–365, 2010.
Wang, Jun and Zucker, Jean-Daniel. Solving multipleinstance problem: A lazy learning approach. In Langley,
Pat (ed.), ICML, pp. 1119–1125, 2000.
Wu, Ou, Gao, Jun, Hu, Weiming, Li, Bing, and Zhu, Mingliang. Indentifying multi-instance outliers. In SDM, pp.
430–441, 2010.
Yuille, A. and Rangarajan, A. The concave-convex procedure. Neural Computation, 2003.

Data Min Knowl Disc (2015) 29:1709–1732
DOI 10.1007/s10618-014-0392-8

A general framework for predictive tensor modeling
with domain knowledge
Yada Zhu · Jingrui He · Richard D. Lawrence

Received: 12 November 2012 / Accepted: 24 October 2014 / Published online: 12 November 2014
© The Author(s) 2014

Abstract In many real applications such as virtual metrology in semiconductor manufacturing, face recognition, and gait recognition in computer vision, the input data is
naturally expressed as tensors or multi-dimensional arrays. Furthermore, in addition
to the known label information, domain knowledge can often be obtained from various
sources, e.g., multiple domain experts. To address such problems, in this paper, we
propose a general optimization framework for dealing with tensor inputs while taking
into consideration domain knowledge. To be specific, our framework is based on a linear model, and we obtain the weight tensor in a hierarchical way—first approximate it
by a low-rank tensor, and then estimate the low-rank approximation using the domain
knowledge from various sources. This is motivated by wafer quality prediction in semiconductor manufacturing. We also propose an effective algorithm named H-MOTE for
solving this framework, which is guaranteed to converge. For each iteration, the time
complexity of H-MOTE is linear with respect to the number of examples as well as
the size of the weight tensor. Therefore, H-MOTE is scalable to large-scale problems.
Experimental results show that H-MOTE outperforms state-of-the-art techniques on
both synthetic and real data sets.
Keywords Classifier design and evaluation · Algorithms · Data mining · Tensor ·
Semiconductor manufacturing · Wafer quality · Virtual metrology

Responsible editor: Chih-Jen Lin.
Y. Zhu (B) · R. D. Lawrence
IBM T.J. Watson Research Center, Yorktown Heights, USA
e-mail: yzhu@us.ibm.com
J. He
CIDSE, Arizona State University, Tempe, AZ, USA

123

1710

Y. Zhu et al.

1 Introduction
In many real applications, data come in the form of tensors, or multi-dimensional
arrays. For example, in semiconductor manufacturing, each recipe process usually
has multiple steps. During each step, we could observe process variables such as
temperature, pressure and gas flow per unit time. Therefore, to predict the wafer quality,
the input data are naturally expressed as third-order tensors (the three dimensions or
modes are steps, seconds within a step, and observed process variables, or features)
or second-order tensors if we use the summary statistics for each process variable
in a single step instead of the instantaneous measurements. Please refer to Sect. 2.1
for a brief overview. Another example is in computer vision, where images can be
modeled as second-order tensors, and image sequences can be modeled as third-order
tensors (Wang et al. 2011). Much existing work on dealing with tensor data converts
tensors into one-dimensional vectors, and applies the rich methodology for vector
inputs to build the model, either for classification or for regression (Mitchell 1997;
Wasserman 2009). However, by converting tensors into vectors, we tend to lose much
information embedded in the structure of tensors, such as the feature correspondence
in different steps in the example of semiconductor manufacturing, or the neighborhood
information of a pixel in the example of computer vision.
To maximally exploit such valuable structural information embedded in the input
tensors, in this paper, we address the problem of predictive modeling with tensor inputs
by directly operating on the tensors. To this end, we propose a general optimization
framework, which predicts the output (or its probability of coming from each class)
based on the inner product between the input tensor and a weight tensor. The weight
tensor is then estimated in a hierarchical way. To be specific, we assume that the weight
tensor has a low-rank approximation, and the Candecomp/Parafac (CP) decomposition (Kolda and Bader 2009) of the low-rank tensor can be further approximated based
on prior information from various sources, e.g., different domain experts.
The proposed framework is motivated by wafer quality prediction in semiconductor
manufacturing, where the input tensors have two dimensions (using summary statistics
for each process variable in a single step instead of the instantaneous measurements):
steps and features. On one hand, the features in a single step, or the same feature
across different steps, tend to have similar values in the weight tensor, which leads to
the assumption of low-rank approximation for the weight tensor; on the other hand,
different domain experts may have various opinions regarding the relative importance
of certain steps and certain features on predicting wafer quality, and we need to leverage
their prior knowledge in order to improve the performance of the predictor, especially
when the labeled set is small. Our proposed framework combines these two factors
with the prediction loss in the objective function, which leads to a locally optimal
solution for the weight tensor in the linear model.
Furthermore, we propose an effective algorithm for solving the optimization framework named H-MOTE. It is based on block coordinate descent. Under certain conditions, H-MOTE is guaranteed to converge to a local optimum. Experimental results on
synthetic data sets and semiconductor manufacturing data sets demonstrate the good
performance of H-MOTE compared with state-of-the-art techniques.
The main contributions of this paper can be summarized as follows:

123

A general framework for predictive tensor

1711

1. An optimization framework, modeling the predictive task with tensor inputs in a
hierarchical way;
2. An algorithm (H-MOTE), solving the optimization framework;
3. Proof and analysis, showing the quality, convergence and scalability of the proposed algorithm.
The rest of the paper is organized as follows. In Sect. 2, we briefly review the related
work. The general optimization framework is presented in Sect. 3, followed by the
introduction of H-MOTE algorithm in Sect. 4. We show some experimental results in
Sect. 5 with discussion. Finally, we conclude the paper in Sect. 6.

2 Related work
In this section, we briefly review related work on wafer quality prediction in semiconductor manufacturing and predictive modeling with tensor inputs.

2.1 Wafer quality prediction
In semiconductor manufacturing, wafers have to go through hundreds of processes
to finally yield Integrated Circuit devices. Each process follows a given recipe that
defines detailed fabrication steps, settings of the process variables in each steps and step
durations. To monitor process performance, modern semiconductor tools are equipped
with in situ sensors that collect real-time processing conditions, such as temperature,
impedance, gas flow, at every step. The sampling frequency ranges from seconds to
milliseconds. The process data can be considered as third-order tensors with respect
to steps, time stamps within a step and observed process variables. This enormous
amount of data is typically used for fault diagnosis based on the summary statistics
(mean, standard deviation, etc.) of process variables in each step. Obviously the summary statistics for each variable in a single step are second-order tensors. Since the
large amount of process data is a direct indicator of the process state, it has prompted
semiconductor industry to develop virtual metrology (VM) application. VM generally
refers to a model based prediction of quality characteristics of wafers in place of, or
in the absence of, actual measurements of those characteristics. Quality characteristics of wafers can be layer thickness, trench structures, reflective index, strength,
etc. depending on the specific process. Given a recipe process, the underlying model
is learned from historical measurements of the wafer quality characteristic (e.g., the
deposition thickness of wafers produced by chemical vapour deposition processes)
and the corresponding process variables that are naturally expressed as third-order
or second-order tensors. The predicted wafer quality (VM) can be used to enhance
run-to-run process control between metrology events. If the models are sufficiently
accurate predictors of process outcomes, VM applications present the opportunity to
prompt process control timely and reduce the number of physical measurements made
to monitor and control a process, while maintaining or even reducing the variability of
process outputs. Such applications are especially attractive for highly complex, capi-

123

1712

Y. Zhu et al.

tal intensive semiconductor manufacturing lines, in which measurements monitoring
processes may add significant processing time and cost.
For this purpose, researchers have built statistical models such as multiple regression
with feature selection (Kang et al. 2011; Lynn et al. 2009), partial least squares (Khan
et al. 2008), SVM regression (Kang et al. 2011), and artificial neural networks (Chang
et al. 2006; Su et al. 2008) based on one-dimensional vectors converted from the
input tensors. However, as discussed in Sect. 1, this conversion tends to lose useful
information embedded in the structure of input tensors. For example, for a given recipe
process, it may be the case that the process variables in a certain step of this process have
key impact on the wafer quality. These types of prior knowledge cannot be naturally
incorporated into the statistical model based on vectorized tensors. On the other hand,
although the real-time process variables can be represented as multivariate time-series,
for VM applications, the objective is to predict the wafer quality, rather than to forecast
the process variables. Therefore, time-series analysis is not most appropriate for this
purpose.
To the best of our knowledge, our work is the first to build a tensor-based model
for wafer quality prediction, which can incorporate the prior knowledge from various
sources in a principled way.

2.2 Predictive modeling with tensor inputs
Compared with the rich literature on predictive modeling with vector inputs (Mitchell
1997; Wasserman 2009), there has not been as much effort on dealing with tensor
inputs. Existing methods for predictive modeling with tensor inputs can be roughly
categorized into the following 2 groups: dimensionality reduction and supervised
tensor learning (classification and regression).
Dimensionality reduction for tensor data is also called tensor embedding. It aims
at finding the intrinsic local geometrical structure of the tensor space by learning a
lower dimensional tensor subspace (with the same order) (He et al. 2005), which has
been successfully applied in computer vision tasks, such as face recognition (He et al.
2005; Dai and Yeung 2006; Tao et al. 2008; Li et al. 2008) and gait recognition (Tao
et al. 2006, 2007; Li et al. 2008), as well as network anomaly detection and sensor
measurements (Sun et al. 2008). For example, the authors in He et al. (2005) propose
the tensor subspace analysis algorithm for structured dimensionality reduction, which
explicitly takes into account the manifold structure of the image space; the authors
in Dai and Yeung (2006) propose several tensor embedding methods, which allow the
relationships between dimensions of a tensor representation to be efficiently characterized; for gait recognition, the authors in Tao et al. (2007) first build a set of Gabor
based human gait appearance models, and then use general tensor discriminant analysis to seamlessly incorporates the object structure information as a natural constraint;
the authors in Tao et al. (2008) generalize the Bayesian principal component analysis
to tensors; the authors in Li et al. (2008) propose discriminant locally linear embedding and its tensorized version, which generalize locally linear embedding (Roweis
and Saul 2000) to enforce the separability between different classes; and the authors
in Sun et al. (2008) introduce a general framework named incremental tensor analysis,

123

A general framework for predictive tensor

1713

which efficiently computes a compact summary for high-order and high-dimensional
data, as well as reveals the hidden correlations.
On the other hand, in supervised tensor learning, a classifier (or regressor) is directly
built based on the tensor inputs instead of their vectorized version. For example,
in Hochreiter and Obermayer (2004), the authors introduce potential support vector machine (PSVM) Hochreiter and Obermayer (2004)), which minimizes a scaleinvariant capacity measure under a new set of constraints, and develop a fast optimization algorithm based on sequential minimal optimization (Platt 1999); in Tao et
al. (2005), the authors establish a supervised tensor learning framework, within which
conventional learning machines such as SVM and minimax probability machines can
be generalized to tensors; and in Cai et al. (2006), the authors propose support tensor
machines, which aims at finding a maximum margin classifier in the tensor space, and
tensor least squares (TLS) (Cai et al. 2006), which aims at finding a minimum residual
sum-of-squares classifier.
Our proposed method belongs to supervised tensor learning. In our method, the
weight tensor of the underlying linear model is built in a hierarchical way: the weight
tensor is first approximated using a low-rank tensor; the CP decomposition (Kolda
and Bader 2009) of the low-rank tensor is then estimated based on prior information
from various sources. Compared with the methods proposed in Tao et al. (2005)
and Cai et al. (2006), they can be seen as special cases of our model in the sense
that they only use rank-one weight tensors, whereas in our model, the rank of the
optimal weight tensor can be more than one. Compared with PSVM (Hochreiter and
Obermayer 2004), we do not need to construct the data matrix, which involves complex
interaction between the ‘row’ objects and the ‘column’ objects, and our method can
be easily generalized to higher order tensors, whereas PSVM can only be applied on
second-order tensors (matrices). Furthermore, compared with all the existing methods
in this group, our method is able to incorporate prior information from various sources
in a principled way, whereas existing methods cannot leverage this information to
improve the performance of the predictor. We also extended the discussion of tensor
decomposition methods, and theoretical and experimental studies on the quality and
convergence of the H-MOTE in Zhu et al. (2012).
3 Optimization framework
In this section, we propose the general optimization framework for hierarchical modeling with tensor inputs. First we introduce the notation used throughout this paper in
Sect. 3.1; then we provide some background on tensor decomposition and tensor rank
in Sect. 3.2; based on the above introduction, in Sect. 3.3, we present the objective
function; and finally, in Sect. 3.4, we interpret the objective function from different
perspectives.
3.1 Notation
Suppose that we are given N training examples {Xn , yn }, n = 1, . . . , N , where
Xn ∈ Rd1 ×d2 ×···×d K is a K -dimensional array, or K th-order tensor, and yn ∈ R is

123

1714

Y. Zhu et al.

the response variable for regression problems, or yn ∈ {0, 1} is the class label for classification problems. Notice that for Xn , K is the dimension of this array or the number
of modes of this tensor, and dk is the number of elements along
 K the kth dimension, k =
dk . When K = 1, the
1, . . . , K . Therefore, the total number of input features is k=1
input Xn is a vector, and the problem is reduced to regular regression or classification;
when K = 2, Xn is a matrix; when K > 2, Xn is a K th-order tensor. In this paper, we
focus on the cases where K > 1. For such problems, we can always convert the input
tensor into a vector by concatenating the fibers along different modes, which are defined
by fixing the indices of all the modes but one.1 Then we can apply the well-established
techniques for dealing with vector inputs to predict the value of yn . However, in this
way, we lose the rich information embedded in the structure of Xn . Therefore, in this
paper, our goal is to predict the value of yn by making use of the structure of Xn .
For future reference, throughout this paper, we use lower-case letters to denote
scalers; boldface lower-case letters to denote vectors; and calligraphic upper-case letters to denote tensors. Let T1 , T2 ∈ Rd1 ×d2 ×···×d K denote two tensors. Define T1 , T2 
to be the inner product between T1 and T2 , which is the sum of the products
√ of their
corresponding elements. Furthermore, define the norm of tensor T1  = T1 , T1 .
3.2 Tensor decomposition and tensor rank
Due to the nature of the problems we are focusing on (e.g., wafer quality prediction
in semiconductor manufacturing), we assume that the weight tensor in the linear
model has a low-rank approximation, which can be decomposed using a variety of
methods, e.g., Tucker decomposition and CP decomposition (Kolda and Bader 2009).
Both of these methods can be seen as higher-order extensions of the matrix singular
value decomposition (Kolda and Bader 2009). For example, given third-order tensor
T ∈ Rd1 ×d2 ×d3 , using Tucker decomposition, we can write it by
T =


r

s

gr st ar ◦ bs ◦ ct

t

where gr st denotes the element of a small third-order tensor core, ar ∈ Rd1 , bs ∈
Rd2 , ct ∈ Rd3 , and ‘◦’ denotes vector outer product. On the other hand, using CP
decomposition, we can write it by
T =

R


ar ◦ br ◦ cr

r =1

where R is a positive integer, br ∈ Rd2 , and cr ∈ Rd3 . For the ease of future explanation, we refer to ar ◦ br ◦ cr as the r th component of T , r = 1, . . . , R. From the above
two equations, it is easy to see that CP decomposition can be seen as a special case
of Tucker decomposition by assuming a superdiagonal tensor core (Kolda and Bader
1 Note that the vectorized version of the tensor may not be unique due to different orderings of the fibers.

123

A general framework for predictive tensor

1715

2009). In our proposed framework, the low-rank approximation of the weight tensor
can be decomposed using either Tucker or CP method. For the sake of clarity, in the
following, we only focus on CP decomposition.
Using CP decomposition, the rank of a tensor T is defined as the smallest number of
rank-one tensors that generate T as their sum (Kolda and Bader 2009). In other words,
in the above equation for CP decomposition, the smallest value of R that satisfies the
equality is the rank of T . In particular, when R = 1, for K th-order tensors, we can
decompose them into the outer product of K vectors.
3.3 Objective function
In our proposed framework, we predict the value of yn using a linear model, such as
the linear regression model for regression problems and logistic regression model for
classification problems. This is consistent with some existing work on quality control
in semi-conductor manufacturing (Kang et al. 2011; Khan et al. 2008; Lynn et al.
2009). Therefore, in this linear model, we have a weight tensor C ∈ Rd1 ×d2 ×···×d K ,
which is the same size as Xn . The main idea of this framework is to model the weight
tensor in a hierarchical way, i.e., we first approximate the weight tensor using a lowrank tensor, whose CP decomposition is in turn estimated based on prior information
from various sources.
To be specific, we minimize a loss function L(yn , Xn , C) summed over all the
training examples. For example, L(·, ·) can be the squared loss in regression, or the
logistic loss in classification. Here we require that L(·, ·) is quasiconvex with respect
to the second argument. Based on the tensor structure, we assume that 
the weight
tensor C can be approximated by a rank-R tensor with CP decomposition rR=1 a1r ◦
a2r ◦ · · · ◦ a K r , where R is equal to the number of sources where we could obtain
domain knowledge, e.g., R domain experts, and akr ∈Rdk is the weight vector for
the kth mode in the r th component. Therefore, C − rR=1 a1r ◦ a2r ◦ · · · ◦ a K r 2
should be small. Intuitively, each weight vector akr reflects the importance of the kth
mode of the input tensors in the r th component, and akr (r = 1, . . . , R) collectively
measure the contribution of the kth mode of Xn to the output yn . For example, when
K = 2 and R = 1, C is a matrix, and C(i, j) should be close to a11 (i) × a21 ( j), where
C(i, j) is the element of C in the ith row and jth column, a11 (i) is the ith element of
a11 , and a21 ( j) is the jth element of a21 . Furthermore, to estimate the weight vector
akr , we need to leverage the domain knowledge from R different sources, e.g., domain
experts. To be specific, for each akr , we assume that it is close to vector akr 0 ∈ Rdk ,
which is given to us a priori from the r th source, r = 1, . . . , R.
Putting everything together, we minimize the following objective function.
f (C, akr , k = 1, . . . , K , r = 1, . . . , R)

2
N
R






L(yn , Xn , C) + γ0 C −
a1r ◦ a2r ◦ · · · ◦ a K r 
=


r =1

n=1

+

K 
R


γkr akr − akr 0 2

(3.1)

k=1 r =1

123

1716

Y. Zhu et al.

where γ0 and γkr (k = 1, . . . , K , r = 1, . . . , R) are positive parameters that balance
among different terms. In particular, the relative values of γ1r , . . . , γ K r reflect our
confidence in using prior knowledge to approximate the weight vector in each mode
of the r th component: the bigger the value of γkr , the more confident we are about
this approximation.

3.4 Interpreting the objective function
In this subsection, we interpret the objective function in Eq. (3.1) from different perspectives.
If L(yn , Xn , C) is the squared loss for regression problems or logistic loss for
classification problems, it reflects the negative log-likelihood of the nth example, and
Eq. (3.1) can be interpreted from a probability
perspective. To be specific, if the prior

distribution of C is normal with mean rR=1 a1r ◦ a2r ◦ · · · ◦ a K r and variance 2γ10
for each element, and the prior distribution of akr is normal with mean akr 0 and
variance 2γ1kr for each element, then Eq. (3.1) is the posterior probability of C and
akr (k = 1, . . . , K , r = 1, . . . , R) given the data (up to a constant). Therefore, by
minimizing Eq. (3.1), we can find the maximum a posteriori estimates of the weight
tensor C as well as the weight vectors akr (k = 1, . . . , K , r = 1, . . . , R).
On the other hand, traditional ridge regression and logistic regression for vector
inputs can be seen as special cases of the proposed optimization framework. To see
this, simply fix akr (k = 1, . . . , K , r = 1, . . . , R) to be 0 vectors, and we have
the same objective function as in ridge regression or logistic regression with Gaussian
prior (Bishop 2006) for vector inputs. In this way, when we try to minimize the original
objective function with respect to both the weight tensor and the weight vectors, the
second term on the right hand side of Eq. (3.1) can be seen as a new regularizer which
encourages a low-rank approximation of the weight tensor C instead of shrinking it to
0 (with rank 0) as in ridge regression and logistic regression. As we will see in Sect. 5,
the use of this new regularizer effectively prevents over-fitting, especially when the
labeled data is very scarce.

4 H-MOTE algorithm
In this section, we introduce the H-MOTE algorithm (Hierarchical MOdeling with
TEnsor inputs) for calculating the weight tensor C that minimizes Eq. (3.1), analyze
its performance in terms of quality, convergence, and time complexity, and elaborate
on a special case of H-MOTE for squared loss in regression problems.

4.1 Analysis of Equation (3.1)
Notice that the function f is not jointly quasiconvex with respect to C and akr , k =
1, . . . , K , r = 1, . . . , R. However, if we fix akr , and minimize f with respect to C,
we have

123

A general framework for predictive tensor

f akr (C) =

N

n=1

1717


2
R





L(yn , Xn , C) + γ0 C −
a1r ◦ a2r ◦ · · · ◦ a K r 



(4.1)

r =1

Notice that the third term on the right hand side of Eq. (3.1) is not dependent on C. It
is easy to see that f akr (C) is quasiconvex in C, given that L(·, ·) and the second term of
Eq. (3.1) on the right hand side are quasiconvex with respect to the second argument,
and


N
R

∂ f akr (C) 
=
l(yn , Xn , C)Xn + 2γ0 C −
a1r ◦ a2r ◦ · · · ◦ a K r
(4.2)
∂C
r =1

n=1

where l(·, ·) is the partial derivative of L(·, ·) with respect to the second argument.
Similarly, if we minimize f with respect to als , keeping C and akr fixed, k = l,
r = s, we have

2
R





f C ,akr ,k=l,r =s (als ) = γ0 C −
a1r ◦ a2r ◦ · · · ◦ a K r  + γls als − als0 2


r =1

Notice that the first term on the right hand side of Eq. (3.1) is not dependent on als . It
is easy to see that f C ,akr ,k=l,r =s (als ) is quasiconvex in als , and
∂ f C ,akr ,k=l,r =s (als )
= 2γ0 (αls als − β ls + τ ls ) + 2γls (als − als0 )
∂als

(4.3)

where αls = a1s ◦· · ·◦a(l−1)s ◦a(l+1)s ◦· · ·◦a K s , a1s ◦· · ·◦a(l−1)s ◦a(l+1)s ◦· · ·◦a K s ,
and β ls , τ ls are dl -dimensional vectors. For β ls , its ith element β ls (i) = Cl=i , a1s ◦
· · · ◦ a(l−1)s ◦ a(l+1)s ◦ · · · ◦ a K s . Here Cl=i ∈ Rd1 ×···×dl−1 ×dl+1 ×···×d K is a (K − 1)thorder tensor. Its elements are equal to C with the index of the lth dimension fixed at i.
For τ ls , its ith element τ ls (i) = Tlsi , a1s ◦· · ·◦a(l−1)s ◦a(l+1)s ◦·
· ·◦a K s . Here Tlsi ∈
Rd1 ×···×dl−1 ×dl+1 ×···×d K is a (K −1)th-order tensor, and Tlsi = r =s alr (i)(a1r ◦· · ·◦
a(l−1)r ◦ a(l+1)r ◦ · · · ◦ a K r ).
∗ that
Therefore, setting Eq. (4.3) to 0, we have the following optimal vector als
minimizes f C ,akr ,k=l,r =s (als ).
∗
als
=

γ0 β ls − γ0 τ ls + γls als0
γ0 αls + γls

(4.4)

4.2 Algorithm description
Based on the above discussion, in this paper, we make use of block coordinate descent
method to find the optimal solution to Eq. (3.1). When the loss function L(yn , Xn , C)
and the second term in Eq. (3.1) are strictly quasiconvex with respect to the weight
tensor C, the convergence of block coordinate descent is guaranteed by Proposition 5
on page 132 of Grippo and Sciandrone (2000). The proposed H-MOTE algorithm is

123

1718

Y. Zhu et al.

shown in Algorithm 1. It works as follows. In Step 1, we initialize vector akr to be
akr 0 ; between Step 2 and Step 9, we alternatively update weight tensor C and weight
vectors akr (k = 1, . . . , K , r = 1, . . . , R) for T times.
Algorithm 1 H-MOTE: Hierarchical Modeling with Tensor Inputs
Require: Xn , yn , n = 1, . . . , N , γ0 , γkr , akr 0 , (k = 1, . . . , K , r = 1, . . . , R), the number of iteration
steps T
Ensure: Weight tensor C and weight vectors akr (k = 1, . . . , K , r = 1, . . . , R)
1: Initialize akr = akr 0 (k = 1, . . . , K , r = 1, . . . , R)
2: for t = 1 to T do
3: Update the weight tensor C using gradient descent method: compute the gradient of C using Equation
(4.2), and use a line search to determine the step size.
4: for k = 1 to K do
5:
for r = 1 to R do
6:
Update vector akr according to Equation (4.4)
7:
end for
8: end for
9: end for

During the test stage, given a tensor X , we first calculate its inner product with
the weight tensor C, X , C, which can be used to predict the output for regression
problems, or transformed into probabilities via the logistic function for classification
problems.
4.3 Quality and convergence analysis
With respect to the convergence of the proposed H-MOTE algorithm, we have the
following lemma.
Lemma 4.1 Assume that the loss function L(yn , Xn , C) is strictly quasiconvex with
respect to the weight tensor C. If the number of iteration steps T is sufficiently large,
the sequence of weight tensors C and the sequence of weight vectors akr generated
by H-MOTE will converge in the limit, and the limit point of the sequences forms a
critical point of the objective function in Eq. (3.1).
Proof H-MOTE is based on block coordinate descent. Since the loss function
L(yn , Xn , C) is strictly quasiconvex, the objective function in Eq. (3.1) is strictly quasiconvex with respect to each block. According to Proposition 5, page 132 of Grippo
and Sciandrone (2000), the sequence of C and the sequence of akr generated by HMOTE will converge in the limit. Furthermore, the limit point of the sequences forms
a critical (i.e., stationary) point of Eq. (3.1).



4.4 Time complexity
Assuming that the number of iteration steps needed for gradient descent in Step 3 of
H-MOTE is upper bounded by T  , we have the following lemma demonstrating the
time complexity of H-MOTE.

123

A general framework for predictive tensor

1719

Lemma
4.2 The time complexity of H-MOTE is O(T ((T  (N + K R) + K 2 R 2 )
K
k=1 dk )).
Proof In Step 3 of H-MOTE, we need to update C for T  times based on gradient
descent. The time complexity of computing the first component of Eq. (4.2) is linear
with respect to the total number of examples as well as the total number of elements
in weight tensor C; whereas the complexity of computing the second component of
Eq. (4.2) is linear with respect to the rank R, the order K , as well as the total number
of elements in C. On the other hand, for updating each weight vector akr , the time
complexity of computing Eq. (4.4) is linear with respect to K R times the total number
of elements in C. Putting everything together, we have the above lemma.



4.5 Case study
In this subsection, we study some special cases of H-MOTE.
4.5.1 Squared loss
For regression problems, i.e., yn ∈ R, the loss function can be defined as
L(yn , Xn , C) = (yn − Xn , C)2 . In this way, we have l(yn , Xn , C) = −2(yn −
Xn , C). By setting Eq. (4.2) to 0, we have a closed-form solution for the vectorized
version c of the weight tensor C in each iteration step of H-MOTE,

c = γ0 I  K

k=1 dk

+

N

n=1

−1 
xn xn

γ0

R


br +

r =1

N



yn xn

(4.5)

n=1

K
K
dk × k=1
dk identity matrix, xn denotes the vecwhere I K dk denotes the k=1
k=1

torized version of Xn , xn denotes the transpose of xn , and br denotes the vectorized
version of a1r ◦ a2r ◦ · · · ◦ a K r . Notice that Eq. (4.5)
is very similar to ridge regression on the vectorized inputs except for the term γ0 rR=1 br , which reflects both the
low-rank nature of the weight tensor as well as prior knowledge. As can be seen in the
next section, it is particularly helpful for preventing overfitting when the labeled set
size is small.
In this case, in Step 3 of H-MOTE, instead of updating C using gradient descent,
we simply apply Eq. (4.5) to obtain c, which, after rearranging the elements, will give
us the current weight tensor C.
4.5.2 Logistic loss
For classification problems, i.e., yn ∈ {0, 1}, the loss function can be defined as
exp(Xn ,C )
L (yn , Xn , C) = yn ln 1+exp(1Xn ,C ) + (1 − yn ) ln 1+exp(
Xn ,C ) . In this way, we have
l(yn , Xn , C) = yn −

exp(Xn ,C )
1+exp(Xn ,C ) ,

and Eq. (4.2) becomes

123

1720

Y. Zhu et al.



	
N 
R

∂ f akr (C) 
exp(Xn , C)
a1r ◦ a2r ◦ · · · ◦ a K r
yn −
=
Xn +2γ0 C−
∂C
1 + exp(Xn , C)
n=1

r =1

(4.6)
This equation will be used in Step 3 of H-MOTE for updating the weight tensor.
 Notice
that it is very similar to the gradient in logistic regression except for 2γ0 (C− rR=1 a1r ◦
a2r ◦ · · · ◦ a K r ). This term also reflects the low-rank nature of the weight tensor used
in the classifier as well as prior knowledge from domain experts.
5 Experimental results
In this section, we demonstrate the performance of the proposed H-MOTE algorithm
on both synthetic and real data sets. In particular, we aim to answer the following
questions.
1. How does the performance of H-MOTE compare with the algorithms dealing with
vectorized inputs?
2. How does the performance of H-MOTE compare with other supervised tensor
learning algorithms?
3. Will additional features describing process variables improve the performance of
H-MOTE in wafer quality prediction?
4. How is the performance of H-MOTE affected by small perturbations in the parameters?
5. How fast does H-MOTE converge to a local optimum?
6. Will higher-rank tensors improve the performance of H-MOTE?
7. How well does H-MOTE perform on other data sets besides semiconductor manufacturing?
To answer these questions, unless otherwise stated, we fix R = 1 in H-MOTE, i.e., we
have inputs from one domain expert, and test the following variants.
• H-MOTE1: H-MOTE algorithm with the prior of ak1 (k = 1, . . . , K ) (the coefficient vector for the kth mode of the weight tensor according to the first oracle) set
to zero, i.e., ak10 = 0
• H-MOTE2: H-MOTE algorithm with the prior of ak1 (k = 1, . . . , K ), i.e., ak10
(k = 1, . . . , K ), given by a domain expert
• H-MOTE3: H-MOTE algorithm with the prior of ak1 (k = 1, . . . , K ) set using ak1
(k = 1, . . . , K ) from the output of H-MOTE2
5.1 Synthetic data
In this subsection, we answer the first question, and compare the three variants of
H-MOTE with existing methods based on vectorized inputs on synthetic data sets. The
data sets consist of 1,000 randomly generated tensors. The outputs are obtained by
first calculating the inner product between the input tensors and a rank-one weight
tensor, and then adding Gaussian noise with increasing variance for different data

123

A general framework for predictive tensor

Ridge
H−MOTE3

1721

H−MOTE1
Low Rank

H−MOTE2
Unregularize

RMSE

0.15

0.1

0.05

0

0.01

0.1

0.2

Standard Deviation of Gaussian Noise

(a) Training error
Ridge
H−MOTE3

H−MOTE1
Low Rank

H−MOTE2
Unregularize

RMSE

0.3

0.2

0.1

0

0.01

0.1

0.2

Standard Deviation of Gaussian Noise

(b) Test error
Fig. 1 Comparison on synthetic data sets consisting of second-order tensors (matrices): H-MOTE methods
perform better than ridge regression and prevent overfitting (Color figure online)

sets. Figures 1 and 2 show the results of 5-fold cross validation for second-order and
third-order tensors, where the x-axis is the standard deviation of the Gaussian noise,
and the y-axis is the Root Mean Squared Error (RMSE) averaged over 50 runs. In
Fig. 1, we compared with ridge regression (Ridge) (Wasserman 2009), un-regularized
linear regression (Unregularize), and H-MOTE with only low-rank approximation
regularization (Low Rank); whereas in Fig. 2, we only showed the results of ridge
regression for the sake of clarity.2
From these figures, we have the following observations. First, H-MOTE methods
with tensor inputs are significantly better than existing methods based on vectorized
inputs in terms of the test error. Second, on the test set, the standard deviation of RMSE
2 The results of the the other two methods are similar as in Fig. 1.

123

1722

Y. Zhu et al.

Ridge
H−MOTE2

H−MOTE1
H−MOTE3

0.1

RMSE

0.08
0.06
0.04
0.02
0

0.01

0.1

0.2

Standard Deviation of Gaussian Noise

(a) Training error
Ridge
H−MOTE2

H−MOTE1
H−MOTE3

1

RMSE

0.8
0.6
0.4
0.2
0

0.01

0.1

0.2

Standard Deviation of Gaussian Noise

(b) Test error
Fig. 2 Comparison on synthetic data sets consisting of third-order tensors: H-MOTE methods perform
better than ridge regression and prevent overfitting (Color figure online)

for H-MOTE methods is much smaller compared with the other methods. Third, using
existing methods based on vectorized inputs, the difference between the average RMSE
on the training set and on the test set is larger than using H-MOTE methods, showing
that H-MOTE methods are more robust to overfitting. This can be attributed to the
new regularizer used in H-MOTE which encourages a low-rank approximation of the
weight tensor instead of shrinking it to 0 as in Ridge. Finally, as we increase the
standard deviation of the Gaussian noise, the difference between H-MOTE methods
and existing methods based on vectorized inputs is getting smaller. This is consistent
with our intuition since in the extreme case where the signal is overwhelmed by the
noise, we cannot expect any model to give us satisfactory results.

123

A general framework for predictive tensor

1723

Table 1 Data sets description
Data set

Number of
examples

Number of
steps

Number of
process variables

Types of summary
statistics

Dimensionality of
equivalent vectors

1

488

7

14

1

98

2

891

10

12

1

120

3

891

10

12

2

240

5.2 Real data
In this subsection, we test the performance of H-MOTE on three data sets collected from
semiconductor manufacturing processes. The processes deposit dielectric material as
capping film on wafers. The key measure of wafer quality is the deposition thickness.
Each process has multiple recipe steps, which have multiple process variables and last
different amount of time. The process variables such as gases and power take different
values at different steps. The process variables and tool conditions can drift at any time
and cause wafer quality variation. At every second, the tool measures each variable
for every wafer in processing. Thus the data can be represented as a third-order tensor
whose three modes are steps, seconds, and process variables. In most existing factory
wide production control systems, summary statistics of each variable at each step are
reported to the trace system for fault detection and wafer quality control partially
due to the different duration of different steps. Therefore, from the trace database we
obtained summary statistics of median or variance for each variable, which can be
represented as second-order tensors.3
The first data set corresponds to a process with a total of 7 steps, each having
17 process variables. The median of each process variable is obtained, which can be
represented as a second-order tensor of size 7 × 17 or a vector of length 119. The
second and third data sets correspond to a process with 10 steps, each having 15
process variables. For the second data set, we use the median of each process variable,
which can be represented as a second-order tensor of size 10 × 15 or a vector of length
150; and for the third process, we use both the median and the variance, which can be
represented as a second-order tensor of size 10 × 30 or a vector of length 300. Due to
the low frequency of actual metrology, in 9-month time period there are totally 488
and 891 target measurements for the two processes. The details of the data sets are
summarized in Table 1.
Notice that it is common practice to predict wafer quality based on the median of
each process variable. The reason for including the variance in the third data set is the
following. Some very critical process variables are usually very well controlled (maybe
through closed-loop control) during production. As a result, the first-order summary
statistics, such as mean or median at certain steps, are sometimes constant over many
wafers. In this case, the first-order statistics may have limited prediction power for
3 Currently we are trying to address the challenge of different duration for different steps, so that the input

tensors contain instantaneous measurements, which may improve the performance of quality prediction.

123

1724

Y. Zhu et al.

both vector-based and tensor-based predictive modeling. However, little departure
of those critical variables from their specification could induce large deviation of
wafer quality from the target. Since the second-order statistics capture exactly such
variation, therefore, we use it to enhance the predictive modeling in the third data set. In
Sect. 5.2.2, we will show some results demonstrating the effectiveness of second-order
statistics.
Before building VM prediction models, data are preprocessed to eliminate observations with missing values, measurement errors and outliers based on the quality
control standard. The variables with identical values for all the wafers as well as some
unnecessary variables according to the domain expert are also removed. The process
variables and the output are normalized to have mean zero and standard deviation one.
5.2.1 Comparison with different algorithms
On the real data sets, we compare the three variants of H-MOTE with the following
three competitors.
• Ridge (ridge regression Wasserman (2009)) for dealing with vectorized inputs. It
has been widely used as a baseline prediction model in VM applications (Su et
al. 2008) for its simplicity and interpretability. Since many process variables are
highly correlated, step-wise feature selection is used to reduce the dimensionality
and select predictive features.
• PSVM for supervised tensor learning. It bears similar ideas as SVM (Vapnik 2000),
and has been successfully applied on various problems, e.g., protein classification,
web page classification, etc. For PSVM, we use the RBF kernel. Note that this
method can only be applied to second-order tensors (matrices).
• TLS for supervised tensor learning. It aims at finding a minimum residual sumof-squares classifier, which can be seen as a special case of H-MOTE where the
rank of the weight tensor is fixed at 1, and no prior knowledge is used.
For all these methods, the cross-validation results of RMSE are used for comparison,
and the parameters are chosen based on cross-validation in the training set only.
Next we answer the first two questions on the real data sets. The comparison results
of the six methods are shown in Figs. 3, 4 and 5. In these figures, the x-axis is the
number of training examples, and the y-axis is average RMSE. For each training set
size, we run the experiments 50 times, and report both the mean and the standard
deviation. From these figures, we have the following observations. First, the performance of H-MOTE methods is consistently better than Ridge, which takes vectorized
inputs. This is because in H-MOTE, we leverage the rich information embedded in
the structure of the input tensors. Second, the performance of H-MOTE methods is
also better than existing supervised tensor learning methods (PSVM and TLS), which
might be due to the special regularizer used in H-MOTE as well as the integration of
prior knowledge. Third, comparing H-MOTE2 and H-MOTE1, the prior information
provided by the domain expert used in H-MOTE2 helps improve the performance.
Finally, in H-MOTE3, by using the output of H-MOTE2 as the prior information, we
can further reduce the RMSE.

123

A general framework for predictive tensor

1725

TLS
H−MOTE1

1

Ridge
H−MOTE2

PSVM
H−MOTE3

0.9

RMSE

0.8
0.7
0.6
0.5
0.4
0.3
200 210 220 230 240 250 260 270 280 290 300

Sample Size
Fig. 3 Comparison on data set 1: H-MOTE3 has the lowest average RMSE (Color figure online)

TLS
H−MOTE1

Ridge
H−MOTE2

PSVM
H−MOTE3

1
0.9

RMSE

0.8
0.7
0.6
0.5
0.4
200

210

220

230

240

250

260

270

280

290

Sample Size
Fig. 4 Comparison on data set 2: H-MOTE3 has the lowest average RMSE (Color figure online)

Furthermore, H-MOTE methods can provide us some useful insights regarding the
manufacturing process, which are difficult (if at all possible) to obtain using vectorbased methods. For example, data sets 2 and 3 contain measurements collected from
Plasma-Enhanced Chemical Vapor Deposition (PECVD). PECVD involves plasma to
create ionization of several key precursors, which enhances the chemical reactions.
Some power related variable4 is one of the best indicators of the plasma. Using HMOTE1 with zero vectors as the prior, the maximum absolute value in a11 exactly
corresponds to this variable. Similarly, the maximum absolute value in a21 corresponds
4 We omit the name of the variable due to confidential issues.

123

1726

Y. Zhu et al.

TLS
H−MOTE1

Ridge
H−MOTE2

PSVM
H−MOTE3

1.2

RMSE

1

0.8

0.6

0.4
200

210

220

230

240

250

260

270

280

290

Sample Size
Fig. 5 Comparison on data set 3: H-MOTE3 has the lowest average RMSE (Color figure online)

nd

Median

Median & 2

order statistics

0.55

RMSE

0.5
0.45
0.4
0.35
0.3

200

210

220

230

240

250

260

270

280

290

Sample Size
Fig. 6 Comparison of H-MOTE3 with different features: using both first-order and second-order statistics
leads to better performance compared with using first-order statistics alone (Color figure online)

to step 10 in this process, which makes sense intuitively since actual deposition is
conducted at step 10. In addition, we could obtain some new insights from H-MOTE
methods. For example, besides step 10, engineers tend to think that step 9 is relatively
more important than the other steps since it is the pre-deposition step. However, using
H-MOTE methods, we discover that steps 2 and 8 are more important than step 9 in
terms of their values in a21 . This can be explained by the facts that (1) two types of
important gas flow are turned on at step 2, and (2) the duration of steps 2 and 8 is
longer than that of step 9.

123

A general framework for predictive tensor

1727

5.2.2 Feature study
In this part, we answer the third question regarding features used in wafer quality
prediction. As we have mentioned at the beginning of Sect. 5.2, the second and third
data sets correspond to the same process with different inputs. Data set 2 only uses
the median of each process variable in a single step, whereas data set 3 uses both the
median and the variance. Here, we compare the performance of H-MOTE3 on the two
data sets in Fig. 6. From this figure, we can see that including second-order statistics
indeed improves the performance in terms of the average RMSE of cross validation.
For example, when the sample size is 300, using median alone, the average RMSE is
0.600, whereas using both median and variance, the average RMSE is 0.572.
5.2.3 Robustness study
In this part, we answer the fourth question. To this end, we use the first data set to
evaluate the robustness of H-MOTE with respect to its parameters γ0 , γ11 and γ12 . To
be specific, we first find the optimal values for γ0 , γ11 and γ12 based on cross-validation
in the training set, then we keep two of them fixed and test the RMSE of H-MOTE
under small perturbations of the remaining parameter.
Figure 7 shows RMSE vs. different values of the parameters. From this figure, we
can see that the performance of H-MOTE is quite stable for all three parameters over
a wide range, which demonstrates the robustness of the proposed algorithm.
5.2.4 Convergence rate
In this part, we answer the fifth question. To evaluate the rate of convergence,
we did experiments using the first data set. We assume that the algorithm converges if the change of the estimated weight tensor C and estimated weight vectors a11 and a12 is less than 10−7 . We let the algorithm run sufficiently large num∗ and a∗ . Then at iteration t,
ber of iterations to obtain the optimal value C ∗ , a11
12
we calculate
the difference between the current estimates and their optimal value:



∗ 2 +  a
∗
2
δt =  Ct − C ∗ 2 +  a11,t − a11
12,t − a12  , where Ct , a11,t and a12,t
are the estimated tensor and weight vectors at iteration t.
In Fig. 8, we plot the natural log of δt versus the iteration number t. It is approximately a straight line when t is small. When t becomes larger, the convergence rate is
even faster. This shows that the algorithm converges at least exponentially.

5.2.5 Time complexity
To evaluate the computational complexity, we use the synthetic data set as described
in Sect. 5.1 with different training set size. The experiments have been performed on a
laptop with Intel Core i7-2720QM processor and 8 GB of RAM, equipped with Windows 7 operating system. The code has been executed using 64-bit Matlab (R2012b).
For each training set size, we perform the experiments 10 times and record the average
processing time in seconds. We plot the time in seconds against the training set size,

123

1728

Y. Zhu et al.

Fig. 7 Impact of the
parameters: H-MOTE is robust
to small perturbations in the
parameters

0.35
0.34
0.33

RMSE

0.32
0.31
0.3
0.29
0.28
0.27
0.26
0.25
0.1

0.2

0.3

0.4

0.5

(a)

0.6

0.7

0.8

0.9

1

0

0.35
0.34
0.33

RMSE

0.32
0.31
0.3
0.29
0.28
0.27
0.26
0.25

0

0.2

0.4

(b)

0.6

0.8

1

0.6

0.8

1

11

0.35
0.34
0.33

RMSE

0.32
0.31
0.3
0.29
0.28
0.27
0.26
0.25

0

0.2

0.4

(c)

123

12

A general framework for predictive tensor

1729

2

10

0

10

log(δt )

−2

10

−4

10

−6

10

−8

10

0

50

100

150

200

t
Fig. 8 Convergence study of H-MOTE: δt decreases at least exponentially
80
70

Time (Second)

60
50
40
30
20
10
0
0

5

10

Number of training examples

15
4

x 10

Fig. 9 Processing time of H-MOTE scales linearly with respect to the training set size

as shown in Fig. 9. Clearly, the processing time scales linearly with respect to the
number of labeled examples.
5.2.6 Higher rank weight tensors
In this part, we answer the last question. In our proposed framework, the rank R
depends on the number of sources where we could obtain the domain knowledge, e.g.,
R domain experts. Next we test the performance of H-MOTE with R = 2 and R = 3.
The comparison results on the second data set are shown in Fig. 10. From this figure,
we can see that bigger values of R are able to further improve the performance of HMOTE in terms of the average RMSE of cross validation. This is consistent with our

123

1730

Y. Zhu et al.

Rank 1 weight tensor
Rank 3 weight tensor

0.55

Rank 2 weight tensor

RMSE

0.5

0.45

0.4

0.35

200

210

220

230

240

250

260

270

280

290

Sample Size
Fig. 10 Comparison of H-MOTE with different ranks (Color figure online)
TSL
H−MOTE1

Classification Error

0.6

Ridge
H−MOTE2

PSVM
H−MOTE3

0.5
0.4
0.3
0.2
0.1
60

65

70

75

80

85

90

95

100

Sample Size
Fig. 11 Comparison on Olivetti Faces data: H-MOTE3 has the lowest average classification error (Color
figure online)

intuition since more domain knowledge often leads to better performance in predictive
modeling. Notice that changing R from 2 to 3 does not improve the performance. It
means that the performance of H-MOTE is stabilized around R = 2, and additional
prior information may not be able to further improve the performance.
5.2.7 Olivetti faces data set
Finally, we would like to test the performance of H-MOTE on a non semiconductor
manufacturing data set: Olivetti Faces data set5 , each image being 32 by 32 pixels
5 http://cs.nyu.edu/~roweis/data.html.

123

A general framework for predictive tensor

1731

grayscale, i.e. a second-order tensor. From this data set, we created multiple binary
classification problems, where we would like to distinguish images from two groups
of people. To solve this problem, we apply our framework as a logistical regression
setting as discussed in the Sect. 4.5.2. We start with H-MOTE1 without any domain
knowledge, train H-MOTE2 with ak10 (k = 1, . . . , K ) set as the output of H-MOTE1
and then train H-MOTE3 with ak10 (k = 1, . . . , K ) set using the estimate of ak1
(k = 1, . . . , K ) from H-MOTE2. The comparison results in terms of the average
classification error are shown in Fig. 11. From this figure, we can see that H-MOTE
methods generalize well to non semiconductor manufacturing data, and outperform
the other competitors in terms of the classification error.
6 Conclusion
In this paper, we propose a general optimization framework for hierarchical modeling
with tensor inputs, which is motivated by wafer quality prediction in semiconductor
manufacturing. This optimization framework directly operates on the input tensors
instead of converting them to vectors, and it is able to incorporate domain knowledge
in a principled way. To solve the optimization framework, we propose an effective
algorithm named H-MOTE based on block coordinate descent. H-MOTE is guaranteed
to converge to a local optimum, and for each iteration it has linear time complexity
with respect to the total number of examples and the number of elements in the weight
tensor. Besides synthetic data sets, we also evaluate our algorithm on three real data
sets collected from semiconductor manufacturing as well as the Olivetti Faces Data
Set. All the results demonstrate consistently better performance than both vector-based
method and tensor-based methods in terms of prediction errors.
References
Bishop CM (2006) Pattern recognition and machine learning (Information Science and Statistics). Springer,
Secaucus
Cai D, He X, Han J (2006) Learning with tensor representation. Technical Report. University of Illinois at
Urbana, Champaign
Chang Y-J, Kang Y, Hsu C-L, Chang C-T, Chan TY (2006) Virtual metrology technique for semiconductor
manufacturing. In: IJCNN
Dai G, Yeung D-Y (2006) Tensor embedding methods. In: AAAI
Grippo L, Sciandrone M (2000) On the convergence of the block nonlinear Gauss–Seidel method under
convex constraints. Oper Res Lett 26(3):127–136
He X, Cai D, Niyogi P (2005) Tensor subspace analysis. MIT Press, In: NIPS
Hochreiter S, Obermayer K (2004) Classification, regression, and feature selection on matrix data. Technical
Report. Technische Universitat, Berlin
Kang P, Kim D, Lee H-J, Doh S, Cho S (2011) Virtual metrology for run-to-run control in semiconductor
manufacturing. Expert Syst Appl 38:2508–2522
Khan AA, Moyne JR, tilbury DM (2008) Virtual metrology and feedback control for semiconductor manufacturing processes using recursive partial least squares. J Process Control 18:961–974
Kolda TG, Bader BW (2009) Tensor decompositions and applications. SIAM Rev 51(3):455–500
Li X, Lin S, Yan S, Xu D (2008) Discriminant locally linear embedding with high-order tensor data. IEEE
Trans Syst Man Cybern 38(2):342–352
Lynn S, Ringwood J, Ragnoli E, McLoone S, MacGearailt N (2009) Virtual metrology for plasma etch
using tool variables. In: Advanced Semiconductor Manufacturing Conference

123

1732

Y. Zhu et al.

Mitchell TM (1997) Machine Learning. McGraw-Hill, New York
Platt JC (1999) Advances in kernel methods. MIT Press, Cambridge, MA.
Roweis ST, Saul LK (2000) Nonlinear dimensionality reduction by locally linear embedding. SCIENCE
290:2323–2326
Su Y-C, Lin T-H, Cheng F-T, Wu W-M (2008) Accuracy and real-time considerations for implementing
various virtual metrology algorithms. IEEE Trans Semicond Manuf 21(3):426–434
Sun J, Tao D, Papadimitriou S, Yu PS, Faloutsos C (2008) Incremental tensor analysis: Theory and applications. TKDD 2(3):11
Tao D, Li X, Hu W, Maybank S, Wu X (2005) Supervised tensor learning. In: ICDM, IEEE Computer
Society, pp. 450–457
Tao D, Li X, Maybank SJ, Wu X (2006) Human carrying status in visual surveillance. In: CVPR, pp.
1670–1677
Tao D, Li X, Wu X, Maybank SJ (2007) General tensor discriminant analysis and gabor features for gait
recognition. IEEE Trans Pattern Anal Mach Intell 29(10):1700–1715
Tao D, Sun J, Shen J, Wu X, Li X, Maybank SJ, Faloutsos C (2008) Bayesian tensor analysis. In: IJCNN,
pp. 1402–1409
Vapnik VN (2000) The nature of statistical learning theory. Springer, New York
Wang Q, Chen F, Xu W (2011) Tracking by third-order tensor representation. IEEE Trans Syst Man Cybern
41:385–396
Wasserman L (2009) All of statistics. Springer, New York
Zhu Y, He J, Lawrence RD (2012) Hierarchical modeling with tensor inputs. In: AAAI Conference on
Artificial Intelligence, pp. 1233–1239

123

Manifold-Ranking Based Image Retrieval*
Jingrui He1, Mingjing Li2, Hong-Jiang Zhang2, Hanghang Tong1, Changshui Zhang3
1,3

Department of Automation, Tsinghua University, Beijing 100084, China
2

1

Microsft Research Asia, 49 Zhichun Road, Beijing 100080, China

{hejingrui98, walkstar98}@mails.tsinghua.edu.cn, 2{mjli, hjzhang}@microsoft.com
3
zcs@tsinghua.edu.cn
accessed and analyzed, this specific technique continually gains
momentum, and has witnessed several major breakthroughs.

ABSTRACT
In this paper, we propose a novel transductive learning framework
named manifold-ranking based image retrieval (MRBIR). Given a
query image, MRBIR first makes use of a manifold ranking
algorithm to explore the relationship among all the data points in
the feature space, and then measures relevance between the query
and all the images in the database accordingly, which is different
from traditional similarity metrics based on pair-wise distance. In
relevance feedback, if only positive examples are available, they
are added to the query set to improve the retrieval result; if
examples of both labels can be obtained, MRBIR discriminately
spreads the ranking scores of positive and negative examples,
considering the asymmetry between these two types of images.
Furthermore, three active learning methods are incorporated into
MRBIR, which select images in each round of relevance feedback
according to different principles, aiming to maximally improve the
ranking result. Experimental results on a general-purpose image
database show that MRBIR attains a significant improvement over
existing systems from all aspects.

The initial image retrieval is based on keyword annotation, which
is a natural extension of text retrieval. In this approach, the
images are first annotated manually by keywords, and then
retrieved by their annotations. However, it suffers from several
main difficulties, e.g., the large amount of manual labor required
to annotate the whole database, and the inconsistency among
different annotators in perceiving the same image.
To overcome these difficulties, an alternative scheme, contentbased image retrieval (CBIR) was proposed in the early 1990’s,
which makes use of low-level image features instead of the
keyword features to represent images, such as color [3, 12, 23],
texture [9, 10, 26], and shape [19, 20, 31]. Its advantage over
keyword based image retrieval lies in the fact that feature
extraction can be performed automatically and the image’s own
content is always consistent. Despite the great deal of research
work dedicated to the exploration of an ideal descriptor for image
content, its performance is far from satisfactory due to the wellknown gap between visual features and semantic concepts, i.e.,
images of dissimilar semantic content may share some common
low-level features, while images of similar semantic content may
be scattered in the feature space.*

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications – image
databases; H.3.3 [Information Storage and Retrieval]:
Information Search and Retrieval – search process, relevance
feedback.

To narrow or bridge the gap, a great deal of work has been
performed, which can be categorized into two major groups: one
is to search for appropriate metrics to measure perceptual
similarity; the other is to incorporate relevance feedback (RF), a
power tool borrowed from the community of information retrieval,
to learn better representation of images as well as the query
concept.

General Terms
Algorithms, Experimentation.

KEYWORDS

In the initial retrieval stage, where only one query example is
available, several distance functions can be used to measure the
similarity between the query and all the images in the database.
For example, to make up for the drawback of traditional static
feature weighting schemes combined with Minkowski metrics, Li
et al [8] propose a perceptual distance function (DPF), which is
dynamically calculated in the subspace where the similarity
between two images is maximized. Another example is the Earth
Mover’s Distance (EMD) [16], which has a rigorous probabilistic
interpretation and has been successfully applied to image retrieval
[4]. In a recent study [6], the authors compare the performance of
different distance functions in texture image retrieval and draw a
conclusion that Manhattan ( L1 ) distance performs better than

Manifold ranking, image retrieval, relevance feedback, active
learning.

1. INTRODUCTION
Image retrieval, initiated in the late 1970’s, aims to provide an
effective and efficient tool for managing large image databases.
With the ever-growing volume of digital images generated, stored,
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that
copies bear this notice and the full citation on the first page. To copy
otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee.
MM’04, October 10–16, 2004, New York, New York, USA.
Copyright 2004 ACM 1-58113-893-8/04/0010...$5.00.

*

9

This work was performed at Microsoft Research Asia.

the query concept, which, to our knowledge, has not attracted
researchers’ attention.

Euclidean ( L2 ), Mahalanobis and Chebychev ( L∞ ) distances.
This conclusion is consistent with the experimental results of [12,
22], where L1 distance outperforms other distances on color
images. However, these metrics are based on pair-wise distance
calculation and oversimplify the relationship among all the images
in the database. Therefore, their effectiveness is quite limited.

In this paper, we propose a novel transductive learning framework
named manifold-ranking based image retrieval (MRBIR), which is
initially inspired by a recently developed manifold-ranking
algorithm [29, 30]. In MRBIR, relevance between the query and
database images is evaluated by exploring the relationship of all
the data points in the feature space, which addresses the limitation
of present similarity metrics based on pair-wise distance.
Different from D-EM, which uses unlabeled data to construct a
generative model, MRBIR takes each unlabeled image as a vertex
in a weighted graph that will propagate the ranking score of
labeled examples. Furthermore, the proposed system can improve
the retrieval result by means of relevance feedback, including
feedback with only positive examples and with both positive and
negative examples. Different schemes will be applied to deal with
these two types of feedback. Finally, we develop three active
learning methods based on different principles, hoping to
maximally improve the ranking result, and discuss their
effectiveness in image retrieval by analyzing their experimental
results.

Relevance feedback, on the other hand, is an online learning
technique used to improve the performance of information
retrieval systems. With the additional information of the user’s
rating on the relevance of the retrieved images, the system
dynamically learns the user’s query concept, and gradually
improves the retrieval result. Among others, a key issue in
relevance feedback is the learning strategy. Traditional learning
methods can be categorized into three major groups [13, 14, 25]:
query reweighting [5, 14, 17], query point movement [13, 18] and
query expansion [13, 14]. However, because these methods do
not fully utilize the information embedded in feedback images,
their performance can not reach a satisfactory level.
More recently, some researchers apply statistical learning methods
to relevance feedback, which have been extensively demonstrated
to outperform traditional ones [7, 24, 25, 27, 28]. According to
whether unlabeled data is utilized in the training stage or not,
these methods can be classified into inductive and transductive
ones.

The manifold ranking algorithm [29, 30] is initially proposed to
rank the data points along their underlying manifold by analyzing
their relationship in Euclidean space. Although such manifold
structure might not exist for images belonging to the same
semantic concept, the way in which the relationship among all the
data points is investigated can be well applied to measuring the
relevance between the query and unlabeled images. The algorithm
first constructs a weighted graph using each data point as a vertex.
Then the positive ranking score of the query is iteratively
propagated to nearby points via the graph. Finally all data points
will be ranked according to their ranking scores, with a larger
score indicating higher relevance. By incorporating unlabeled
data in the learning process and exploring their relationship with
labeled data, we hope that this transductive method will
outperform inductive methods.

The goal of an inductive method is to create a classifier which
separates the relevant and irrelevant images and generalizes well
on unseen examples. For example, the authors of [24] first
compute a large number of highly selective features, and then use
boosting to learn a classification function in this feature space;
similarly, the relevance feedback method proposed in [28] trains a
support vector machine (SVM) from labeled examples, hoping to
obtain a small generalization error by maximizing the margin
between the two classes of images. To speed up the convergence
to the target concept, active learning methods are also utilized to
select the most informative images which will be presented to and
marked by the user. For example, the support vector machine
active learning algorithm (SVMactive) proposed by Tong et al [25]
selects the points near the SVM boundary so as to maximally
shrink the size of the version space. Another active learning
scheme, the maximizing expected generalization algorithm
(MEGA) [7], judiciously selects samples in each round and uses
positive examples to learn the target concept, while negative
examples to bound the uncertain region. One major problem with
inductive methods is the insufficiency of labeled examples, which
might bring great degradation to the performance of the trained
classifier.

In relevance feedback, if the user only marks relevant examples,
the manifold ranking algorithm can be easily generalized by
adding these newly labeled images into the query set; on the other
hand, if examples of both labels are available, they will be treated
differently: relevant images are also added to the query set, while
for irrelevant images, we design three schemes to utilize their
information, and select the best one to incorporate into MRBIR
according to experimental results.
To maximally improve the ranking result, we incorporate three
active learning methods into MRBIR for selecting images in each
round of relevance feedback. The first method is to select the
most relevant images; the second one is to select the most
informative images; while the third one tries to take the advantage
of the first two methods by selecting the inconsistent images
which are also quite similar to the query. We will compare their
performance and discuss their feasibility in image retrieval.

On the other hand, transductive methods aim to accurately predict
the relevance of unlabeled images which are attainable during the
training stage.
For example, Discriminant-EM algorithm
proposed by Wu et al [27] makes use of unlabeled data to
construct a generative model, which will be used to measure
relevance between the query and database images. However, as
pointed out in [27], if the components of data distribution are
mixed up, which is often the case in CBIR, the performance of DEM will be compromised. Despite the immaturity of transductive
methods, we see with them great potential since they provide a
way to solve the small sample size problem by utilizing unlabeled
data to make up for the insufficiency of labeled data. Furthermore,
active learning can be incorporated to speed up the convergence to

The main contribution of this paper can be summarized as follows:

10

1.

Propose a novel transductive learning framework for image
retrieval based on a manifold ranking algorithm;

2.

Design and investigate different schemes for utilizing the
two types of feedback to improve the retrieval result;

3.

Develop three active learning methods to incorporate into
the proposed framework.

proportion to the probability that it is relevant to the query, with
large ranking score indicating high probability.

The organization of the paper is as follows. In Section 2, we
introduce the transductive method used in MRBIR to measure
relevance of database images to the query. Section 3 presents
different schemes for utilizing the two types of feedback to
improve the retrieval result. We propose our active learning
methods in Section 4. Implementation issues are discussed in
Section 5. In Section 6, we provide experimental results to
evaluate the framework from all aspects. Finally, we conclude in
Section 7.

Sort the pair-wise distances among points in ascending
order. Repeat connecting the two points with an edge
according to the order until a connected graph is
obtained.

2.

Form

the

(

affinity

Wij = exp  − d 2 xi , x j

)

matrix

W

defined

by

2σ 2  if there is an edge linking

xi and x j . Let Wii = 0 .
3.

2. THE TRANSDUCTIVE LEARNING
METHOD FOR IMAGE RETRIEVAL

Symmetrically normalize W by S = D −1/ 2WD −1/ 2 in
which D is the diagonal matrix with ( i, i ) -element equal
to the sum of the ith row of W.

Different from traditional methods, which measure perceptual
similarity based on pair-wise distance, in MRBIR, we measure
relevance between the query and database images by exploring the
relationship of all the data points in the feature space. To achieve
this goal, we resort to the manifold ranking algorithm proposed in
[29, 30]. The algorithm is initially used to rank data points along
their underlying manifold, which is revealed by the relationship
among all the data points. Although such manifold structure
might not exist for images belonging to the same semantic concept,
the way in which the relationship among all the data points is
investigated can be well applied to measuring the relevance
between the query and database images. In this section, we will
introduce this algorithm, followed by some analysis of its
application in MRBIR.

4.

Iterate f ( t + 1) = α Sf ( t ) + (1 − α ) y until convergence,
where α is a parameter in [ 0,1) .

5.

Let fi* denote the limit of the sequence

{ fi ( t )} .

Rank

*

each point xi according to its ranking scores fi (largest
ranked first).

Figure 1. Manifold ranking algorithm

2.3 Analysis of the Algorithm
Next we will analyze the algorithm with respect to its transductive
nature. The theorem in [30] guarantees that the sequence { f ( t )}
converges to

2.1 Notation

Given a set of points χ = { x1 , K, xq , xq +1 , K, xn } ⊂

m

f * = β (1 − α S ) y
−1

，

the first q points are the queries which form the query set, and the
rest are to be ranked according to their relevance to the queries.
Let d : χ × χ → denote a metric on χ which assigns each pair
of points xi and x j a distance d ( xi , x j ) , and f : χ →

(1)

where β = 1 − α . Although f * can be expressed in a closed form,
for large scale problems, the iteration algorithm is preferable due
to computational efficiency. Using Taylor expansion, we have

denote

−1

f * = (I −αS ) y

a ranking function which assigns to each point xi a ranking score
f i . Finally, we define a vector y = [ y1 , K ,

1.

(

)

= I + α S + α 2S 2 + K y

yn ] , in which
T

(2)

= y + α Sy + α S (α Sy ) + K

yi = 1 if xi is a query, and yi = 0 otherwise.

Here, we omit the constant coefficient β since it will not affect
the ranking result. From the above equation, we can grasp the
idea of manifold ranking from another point of view. f * can be
regarded as the sum of a series of infinite terms. The first term is
simply the vector y , the second term is to spread the ranking
scores of the query points to their nearby points, the third term is
to further spread the ranking scores, etc. Thus the effect of
unlabeled data is gradually incorporated into the ranking score.

2.2 The Ranking Process
The procedure of the algorithm in [29, 30] is listed in Figure 1.
An intuitive description of this algorithm is: a weighted graph is
first formed which takes each data point as a vertex; assign a
positive ranking score to each query while zero to the remaining
points; all the points then spread their scores to the nearby points
via the weighted graph; the spread process is repeated until a
global stable state is reached, and all the points except the query
will have their own scores according to which they will be ranked.
Note that self-reinforcement is avoided by setting the diagonal
elements of the affinity matrix to 0. The propagation of ranking
score reflects the relationship of all the data points, since in the
feature space, distant points will have different ranking scores
unless they belong to the same cluster consisting of many points
that help to link the distant points, and nearby points will have
similar ranking scores unless they belong to different clusters. In
the context of image retrieval, there is only one query in the query
set. The resultant ranking score of an unlabeled image is in

2.4 Formation of the Weighted Graph
When applied in MRBIR, the first step of the algorithm in Figure
1 is modified as: calculate the K nearest neighbors for each point;
connect two points with an edge if they are neighbors. The reason
for this modification is to ensure enough connection for each point
while preserving the sparse property of the weighted graph.
Notice that in this way, the constructed graph is not necessarily
connected and may consist of several separate clusters, which is
different from the original algorithm. An inevitable consequence
of a disconnected graph is that not all the images will end up with

11

a ranking score. However, since the images without ranking
scores are not connected with the queries whether directly or
indirectly, we can conclude with high confidence that those
images are irrelevant ones. In the context of image retrieval where
we pay much attention to the images ranked first, the order of
images that come last in the ranking list is of minor concern, i.e.
we do not care how the irrelevant images are arranged. So we
simply put the images with no ranking score in the tail of the
ranking list without harming the overall performance.

spread ranking scores independently, and assign large value to
images belonging to their corresponding neighborhood. The
ultimate ranking score is the sum of these individual scores.

3.2 RF with Positive and Negative Examples
Due to the asymmetry between relevant and irrelevant images,
they should be processed differently. For example, in Rocchio
formula [15], the initial query is moved towards positive examples
and away from negative examples by different degrees; in MEGA
[7], positive examples are used to learn the target concept in
k -CNF , while negative examples are used to learn a k -DNF that
bounds the uncertain region; some researchers even come up with
the idea of introducing different penalizing factors for positive and
negative examples into the optimization problem of SVM [11].
A deeper reason for this asymmetry is that relevant images tend to
form certain clusters in the feature space, while irrelevant images
occupy the remaining feature space.

As stated in [1, 21], defining a suitable affinity matrix W is of key
importance. A commonly used distance function d ( xi , x j ) is the

L 2 distance, which results in a Gaussian kernel for defining edge
weights in W. However, based on the experimental results in [6,
12, 22], we can draw a conclusion that L1 distance can better
approximate the perceptual difference between two images than
other popular Minkowski distances when using either color or
texture representation or both. Replacing L 2 distance with L1
distance, we use the Laplace kernel in MRBIR to define the edge
weights in W, which can be written as follows:

(

)

m

k L xi , x j = ∏
l =1

(

1
exp − xil − x jl σ l
2σ l

)

To accommodate this asymmetry, in MRBIR, positive and
negative examples spread their ranking scores differently. To
speak concretely, we first define two vectors y + and y − . The
element of the former one is set to 1 if the corresponding image is
the query or a positive example; while the element of the latter one
is set to -1 if the corresponding image is a negative example. All
the other elements of the two vectors are set to 0. Secondly, let

(3)

where xil and x jl are the lth dimension of xi and x j respectively;

A = β ( I − α S ) , and define two matrices A+ and A− which are
−1

m is the dimensionality of the feature space; and σ l is a positive
parameter that reflects the scope of different dimensions. Thus

(

m

)

(

Wij = k L xi , x j = ∏ exp − xil − x jl σ l
l =1

)

used to propagate the ranking scores of positive and negative
examples, i.e., f + * = A+ y + , f −* = A− y − , where f + * and f −* are
the ranking scores obtained from positive and negative examples
respectively.
The final ranking score can be written as
f * = f + * + f −* . Generally speaking, positive examples should
make more contribution to the final ranking score than negative
examples. The reasons can be explained as follows: for an
unlabeled image, the farther it lies from positive examples in the
feature space, the less possible it is also a positive one. However,
we do not have a similar conclusion for negative examples: if an
unlabeled image lies far from negative examples, the possibility
that it is a positive one is not necessary enhanced, since it may not
get closer to positive examples either.

(4)

Here, we omit the coefficient 1 ( 2σ l ) , since its effect on the
affinity matrix W will be counteracted in the normalization step
S = D −1/ 2WD −1/ 2 and will not contribute to the final ranking
result.

3. RELEVANCE FEEDBACK
3.1 RF with Only Positive Examples
When only positive examples are available from the user’s
feedback or when we consider only the relevant images, several
schemes can be applied, making use of the information to improve
retrieval accuracy. For example, the authors of [14] propose two
query expansion approaches that selectively add relevant objects
to the query, namely similar expansion and distant expansion;
another approach adopted by [2] estimates the distribution of the
target images in the feature space using one-class SVM. In this
specific context, the manifold ranking algorithm can be easily
generalized: add the newly obtained positive examples into the
query set, and rerun the manifold ranking algorithm to refine the
retrieval result. In this way, the vector y will have multiple nonzero components that will spread their ranking scores in the
propagation process. And the sequence { f ( t )} converges to
f * = β (I −αS ) y = β (I −αS )
−1

−1

Based on the above discussion, in MRBIR, we fix A+ , and
explore the following three schemes for designing A− :
In the first scheme, we set A− = γ A+ , which simply impair
the contribution of the negative ranking score to f * by
using a parameter γ ∈ ( 0,1] : the smaller γ is, the less
impact negative examples will have on f * . When γ = 1 ,
there is no de-emphasis on negative examples.
The second scheme is based on equation (2), i.e.,

(

M

≈ β ∑α i S i y −

+

n +1

∑y

i

(

)

f −* = β y − + α Sy − + α S α Sy − + K

)

(6)

i =0

(5)

where the negative score is approximated using only the first

i =1

i

where y is a n-dimensional vector with the ith component equal

M terms.

to 1 and others equal to 0, and n + is the number of positive
examples fed back by the user. Therefore these examples will

M

Thus A− = β ∑ α i S i , this can be directly
i =0

calculated without the iteration steps. In this scheme, the

12

ranking scores of negative examples only spread to nearby
points, and their effect on distant points is negligible.

absolute value of f i −* indicates the irrelevance of an unlabeled
image determined by negative examples, a small value of
fi * = fi + * + fi − * means that the image is judged to be relevant by

In the third scheme, we modify the neighborhood of a
negative example by changing σ l . Recall that σ l denotes a
set of parameters introduced to calculate Wij .

the same degree as it is judged to be irrelevant, therefore, it can be
considered an inconsistent one.
From the perspective of
information theory, such images are most informative.

It also

controls the neighborhood size within which the points will
have a big similarity value to the center point: the bigger σ l
is, the larger the neighborhood size.
Therefore, we
deliberately decrease σ l to obtain σ l′ , and calculate another

The third method tries to take the advantage of the above two
schemes by selecting the inconsistent images which are also quite
similar to the query. To speak concretely, we define a criterion
function

similarity matrix W ′ for propagating negative ranking
scores, using σ l′ . i.e.
m

(

Wij′ = ∏ exp − xil − x jl σ l′
l =1

)

feedback. The criterion can be explained intuitively as follows:
the selected images should not only provoke maximum
disagreement among labeled examples (small fi +* + f i −* ), they

(7)

−1

σ l′ = η ⋅ σ l ( 0 < η < 1)

must also be relatively confidently judged as a relevant one by the
positive examples (large f i + * ). We justify this scheme as follows:
generally speaking, since positive examples occupy a small region
in the feature space and are surrounded by negative examples, to
identify the true boundary separating the two classes of images
with a small number of labeled examples, it is more reasonable to
explore in the inconsistent region near positive examples than in
the entire inconsistent region. If an image is far from all the
labeled examples, it will have a small value for both f i + * and

Thus the neighborhood of negative examples is smaller than
that of positive examples, and the scope of their effect is
decreased.
In Section 6 we give experimental results to compare the three
schemes, and incorporate the best one into MRBIR.

4. ACTIVE LEARNING METHODS
Contrary to passive learning, in which the learner randomly selects
some unlabeled images and asks the user to provide their labels,
active learning selects images according to some principle, hoping
to speed up the convergence to the query concept. This scheme
has been proven to be effective in image retrieval by previous
research work [25, 7]. In MRBIR, we develop three active
learning methods based on different principles, which
intentionally select images in each round of relevance feedback,
aiming to maximally improve the ranking result.
+*

+

+

(8)

Unlabeled images with the largest value of c ( xi ) are selected for

S ′ = D′−1/ 2W ′D′−1/ 2
A− = β ( I − α S ′ )

c ( xi ) = fi + * − f i + * + f i −*

−*

−

f i −* , and a small fi +* + f i −* accordingly, thus it is likely to be
selected by the second scheme although it makes small
contribution to the refinement of the boundary. However, it is not
likely to be selected by the third scheme according to equation (8).
Therefore, this scheme is expected to outperform the second one.

5. IMPLEMENTATION ISSUES
One crucial element in designing an applicable CBIR system is the
response time. It is unimaginable that the user has to wait a long
time before the system is able to return satisfactory retrieval
results. In the manifold ranking algorithm, we have to calculate
the multiplication of large scale matrices in the iteration step.
However, after the graph is simplified by connecting only
neighboring points, we can use a sparse representation for
matrices W and S, which are calculated off-line. In this way, the
processing time can be greatly reduced. Another acceleration
scheme is based on sampling techniques, which reduces the scale
of the weighted graph to form a small graph, and propagates the
scores of labeled images to its vertexes. For images not in the
small graph, their scores can be obtained by exploring their
neighborhood relationship with images in the small graph.

−

As pointed out in Section 3.2, f = A y and f = A y ,
which are the ranking scores obtained from positive and negative
examples respectively. The final ranking score f * = f + * + f −* .
For an unlabeled image xi , f i* is in proportion to the conditional
probability that xi is a positive example given present labeled
images: the larger f i* is, the bigger the probability.
The first method is to select the unlabeled images with the largest
f i* , i.e., the most relevant images, which is widely used in
previous research work [4, 17, 18, 28]. The motivation behind
this simple scheme is to ask the user to validate the judgment of
the current system on image relevance. Since the images
presented to the user are always the ones with the largest
probabilities of being relevant, many of them might be labeled as
positive, which will help the system refine the query concept;
while the negative feedback images will help to eliminate false
positive images.

Another issue is with respect to the query image. Recall that the
weighted graph takes the query point as a vertex. If the query
image is in the database, we can directly use the matrices W and S
which are calculated off-line to rank the unlabeled images. On the
other hand, if the query image is not in the database, we first
project it to a point in the feature space. Next we connect the
query with its K nearest neighbors in the image database, and
calculate the edge weights by equation (4). Thirdly, we add one
row and one column to W, with each element equal to the

The second method is to select the unlabeled images with the
smallest f i* . Since the value of f i + * indicates the relevance of
an unlabeled image determined by positive examples, while the

13

for Scheme 3. We have observed that to achieve satisfactory
results, γ should lie within [0.1, 0.5]; M can be any integer
between 2 and 5; and η should lie within [0.3, 0.7].

corresponding edge weight. All the other operations will be
performed similarly using this enlarged matrix W.

6. EXPERIMENTAL RESULTS

In Figure 3, we have compared the performance of the three
schemes with the following parameter settings: γ = 0.25 ; M = 3 ;
and η = 0.5 . Furthermore, we also present the result when γ = 1
in Scheme 1 (denoted as “Ref”). In this case, positive and
negative examples are treated without difference. Obviously, the
three schemes with proper parameter settings outperform this
naive method, which validates the asymmetry between positive
and negative examples discussed in subsection 3.2. For example,
P10 using Scheme 1 is 0.540, using Scheme 2 is 0.531, using
Scheme 3 is 0.520, and using “Ref” is 0.503. Moreover, Scheme
1 is slightly better than the other two despite of its simplicity.
Therefore, Scheme 1 is incorporated into MRBIR.

We have evaluated the performance of MRBIR using a generalpurpose image database consisting of 5,000 Corel images. The
images are categorized into 50 groups, such as beach, bird,
mountain, jewelry, sunset, etc. Each of the categories contains
100 images of essentially the same content, which serve as the
groundtruth. We use each image in the whole database as a query,
and average the results over the 5,000 queries. The precision vs.
scope curve is used to evaluate the performance of various
methods.
Feature selection is a large open problem and might have a great
impact on the results. In our current implementation, the feature
vector is simply made up of color histogram [23] and wavelet
feature [26] since we focus on the relative performance
comparison1. Color histogram is obtained by quantizing the HSV
color space into 64 bins. To calculate the wavelet feature, we first
perform 3-level Daubechies wavelet transform to the image, and
then calculate the first and second order moments of the
coefficients in High/High, High/Low and Low/High bands at each
level. We will leave the problem of selecting the optimal feature
combination to future work.

L2 distance

MRBIR(Laplace kernel)

MRBIR(Gaussian kernel)

0.35

Precision

0.3

There are four parameters needed to be set in the manifold ranking
algorithm: K, α , σ l and the iteration steps. The algorithm is not
very sensitive to the number of neighbors. In our experiments, we
set K = 200 . α is fixed at 0.99, consistent with the experiments
performed in [29, 30]. The value of σ l is problem-dependent. A

0.25
0.2
0.15
0.1
10

20

30

40

50

60

70

80

90

100

Scope

Figure 2. Comparison without relevance feedback.

principled way for determining σ l is setting it to be the average
value in the lth dimension. In our current implementation, we set
it to be 0.05 for all dimensions for the sake of simplicity. The
number of iteration steps is 50, since we observe no improvement
in performance with more iteration.

Scheme 1
Scheme 3

Scheme 2
Ref

0.55
0.5

Precision

0.45

6.1 MRBIR without Relevance Feedback
As a new scheme of measuring similarity between images in CBIR,
MRBIR is first compared with traditional methods based on pairwise distance when no relevance feedback is performed. The
comparison results are illustrated in Figure 2. From the figure, we
can see that MRBIR using Laplace kernel outperforms all the
other methods, which confirms the method from two aspects: (1)
by considering the relationship among all the data points, our
method can better approximate relevance between the query and
database images than traditional methods; (2) Laplace kernel is
more suitable for defining edge weights than Gaussian kernel.

0.4
0.35
0.3
0.25
0.2
0.15
10

20

30

40

50

60

70

80

90

100

Scope

Figure 3. Comparison of the three schemes.

6.3 Relevance Feedback
When both positive and negative examples are provided by the
user, we apply MRBIR (with three active learning methods), SVM
[28] and SVMactive [25] to refine the retrieval result, and compare
their performance. For SVM and SVMactive, L1 distance is
utilized in the initial retrieval stage and the adopted kernel is
Gaussian kernel. To provide a systematic evaluation, we fix the
total number of images that are marked by the user to 20, but vary
the times of feedback and the number of images fed back each
time accordingly. The combinations used in this experiment
include: 1 feedback with 20 images each time; 2 feedbacks with
10 images each time; and 4 feedbacks with 5 images each time. In
all the experiments, no matter which active learning method is
taken, MRBIR outperforms SVM and SVMactive. In this section,
we only present the results after the first and second rounds of

6.2 Comparison of Schemes for Incorporating
Negative Examples
As discussed in Section 3.2, we have three candidate schemes for
designing A− . In order to select the best one to integrate into
MRBIR, we have performed parametric study for each scheme:
0 < γ ≤ 1 for Scheme 1; 1 ≤ M ≤ 10 for Scheme 2; and 0 < η < 1

1

L1 distance

We have performed experiments with various features, such as
color coherence, color correlogram, etc, and have reached the
same conclusion.

14

relevance feedback with 5 images fed back each time, as in Figure
4.

in Table 1 (Pentium 4 1.80GHz, 512M RAM). Although MRBIR
needs the longest time among all algorithms, it is still acceptable
for both the search session and the feedback session.

In the first round of relevance feedback, the active learning part of
both MRBIR and SVMactive is not provoked, and the most relevant
images are labeled by the user. We did not adopt the scheme
presented in [25], which asks the user to label randomly selected
images in the first round of relevance feedback, since in this
scheme, the information about the query is not utilized in the
initial stage, which will inevitably result in slow convergence to
the query concept.

Table 1. Comparison of Processing Time
Time(second)

MRBIR

L1

SVM

SVMactive

Search

0.859

0.015





Feedback

0.859



0.062

0.062

MRBIR

SVM

0.5

After the first round of relevance feedback (Figure 4(a)), MRBIR
exhibits significant improvement over SVM. Take P10 (the
precision within the first 10 retrieved images) as an example, for
SVM, P10 is 0.260; while for MRBIR, it is 0.401, which exceeds
SVM by about 54%. Similarly, P100 is 0.111 using SVM, and is
0.189 using MRBIR. The latter exceeds the former by about 70%.
The reason lies in the fact that very few training examples may
cause the decision boundary in SVM to distort greatly from the
ideal one, while MRBIR can always relatively accurately predict
the relevance of unlabeled images in the neighborhood of labeled
examples.

Precision

0.4
0.3
0.2

0.1
0
10

20

30

40

50

60

70

80

90

100

Scope

(a)

When the second round of relevance feedback has been performed
(Figure 4(b)), no matter which active learning method is taken,
MRBIR outperforms SVM and SVMactive. Again we take P10 to
demonstrate the advantage of MRBIR. For SVM, P10 is 0.265;
for SVMactive, P10 is 0.239; while for the three active learning
methods used in MRBIR, P10 is 0.478, 0.411, and 0.459
respectively. The best result obtained by MRBIR exceeds SVM
by 80%, and SVMactive by 100%.

MRBIR1

MRBIR2

SVM

Active SVM

MRBIR3

0.6
0.5

Precision

0.4
0.3
0.2

Notice that comparing Figure 2 and Figure 4, SVM and SVMactive
cause degradation in performance. Only after the system has
accumulated enough labeled examples, are they able to refine the
retrieval result; while MRBIR consistently increases the precision
and outperforms SVM and SVMactive. Comparing Figure 4(a) and
Figure 4(b), the improvement in P10 using SVM is only 0.005,
while the improvement of MRBIR using the first active learning
method is 0.077.

0.1
0
10

20

30

40

50
60
Scope

70

80

90

100

(b)

Figure 4. (a) Comparison after the first round of relevance
feedback with 5 feedback images; (b) Comparison after the
second round of relevance feedback (MRBIR1-MRBIR3
denote the three active learning methods).

Comparing the three active learning methods (Figure 4(b)), the
performance of the second one (MRBIR2) is the worst, which
selects the most informative images. The reason may be the lack
of positive examples. When we try to capture a query concept
with a limited number of labeled images, positive examples tend
to be more important than negative ones. Since the second
scheme selects the images which arouse the most disagreement
among labeled images, the positive examples fed back in each
round of relevance feedback is generally smaller than the other
two methods, thus its performance is compromised. Of the
remaining two methods, the first method is slightly better than the
third one, which may lead to the following conclusion: in image
retrieval where the labeled examples are quite limited, selecting
the most relevant images in each round of relevance feedback may
be the best strategy for active learning.

7. CONCLUSION
In this paper, we propose a novel transductive learning framework
named manifold-ranking based image retrieval (MRBIR), which is
inspired by a recently developed manifold-ranking algorithm [29,
30]. The algorithm is initially proposed to rank data along their
underlying manifold. In MRBIR, we use this algorithm to explore
the relationship among all the data points in the feature space, and
measure relevance between the query and database images, thus it
addresses the limitation of present similarity metrics based on
pair-wise distance. MRBIR also enables the user to perform
relevance feedback, and provides different schemes to refine the
retrieval result in case of the two types of feedback. Furthermore,
we incorporate three active learning methods into MRBIR to
speed up the convergence to the query concept. The methods
make use of different principles to select images in each round of
relevance feedback and ask the user for their labels. Experiments
on a general-purpose image database consisting of 5,000 Corel
images demonstrate that MRBIR outperforms existing methods.

In our experiments, MRBIR also greatly outperforms MARS [17,
18] when only positive examples are fed back by the user. Due to
the limited space, we will not present specific results.

6.4 Processing Time
We also compare the average response time of MRBIR using the
first active learning method with existing systems, which is listed

15

MARS. Proc. IEEE Int. Conf. on Multimedia Computing
and Systems, vol. 2, pp. 747-751, 1999.

8. ACKNOWLEDGEMENTS
We would like to thank Shuicheng Yan, Xin Zheng, Lei Zhang
and Xing Yi for their valuable discussions and enlightening
comments.
This work was supported by National High
Technology Research and Development Program of China (863
Program) under contract No.2001AA114190.

[15] Rocchio, J.J. Relevance feedback in information retrieval.
The SMART Retrieval System, pp. 313-323, Prentice-Hall,
Englewood Cliffs, NJ, 1971.
[16] Rubner, Y., Tomasi, C., and Guibas, L. A metric for
distributions with applications to image databases. Proc.
IEEE Int. Conf. on Computer Vision, pp. 59-66, 1998.

9. REFERENCES
[1]

Bengio, Y., Vincent, P., and Paiement, J. Learning
Eigenfunctions of Similarity: Linking Spectral Clustering
and Kernel PCA. Technical Report 1232, University of
Montreal, 2003.

[2]

Chen, Y., Zhou, X., and Huang, T. One-class SVM for
learning in image retrieval. Proc. IEEE Int. Conf. on Image
Processing, vol. 1, pp. 34-37, 2001.

[3]

Huang, J., et al. Image indexing using color correlograms.
Proc. IEEE Conf. on Computer Vision and Pattern
Recognition, pp. 762-768, 1997.

[4]

Jing, F., et al. An effective region-based image retrieval
framework. Proc. 10th ACM Int. Conf. on Multimedia, 2002.

[5]

Ishikawa, Y., Subramanya, R., and Faloutsos, C.
MindReader: querying databases through multiple examples.
Proc. 24th Int. Conf. on Very Large Data Bases, 1998.

[6]

Kokare, M., Chatterji, B.N., and Biswas, P.K. Comparison
of similarity metrics for texture image retrieval. IEEE Conf.
on Convergent Technologies for Asia-Pacific Region, vol. 2,
pp. 571-575, 2003.

[7]

Li, B., Chang, E., and Li, C.S. Learning image query
concepts via intelligent sampling. Proc. IEEE Int. Conf. on
Multimedia & Expo, pp. 961-964, 2001.

[8]

[9]

[17] Rui, Y., et al. Relevance feedback: a power tool for
interactive content-based image retrieval. IEEE Trans.
Circuits and Systems for Video Technology, 1998.
[18] Rui, Y., Huang, T., and Mehrotra, S. Content-based image
retrieval with relevance feedback in MARS. Proc. IEEE Int.
Conf. on Image Processing, pp. 815-818, 1997.
[19] Schmid, C. A structured probabilistic model for recognition.
Proc. IEEE Conf. on Computer Vision and Pattern
Recognition, vol. 2, pp. 490, 1999.
[20] Schmid, C., and Mohr, R. Local grayvalue invariants for
image retrieval. IEEE Trans. on Pattern Analysis and
Machine Intelligence, vol. 19, pp. 530-535, 1997.
[21] Shi, J., and Malik, J. Normalized cuts and image
segmentation. IEEE Trans. on Pattern Analysis and
Machine Intelligence, vol. 22, pp. 888-905, 2000.
[22] Stricker, M., and Orengo, M. Similarity of color images.
Storage and Retrieval for Image and Video Databases, Proc.
SPIE 2420, pp 381-392, 1995.
[23] Swain, M., and Ballard, D. Color indexing. Int. Journal of
Computer Vision, 7(1): 11-32, 1991.
[24] Tieu, K., and Viola, P. Boosting image retrieval. Proc. IEEE
Conf. on Computer Vision and Pattern Recognition, vol. 1,
pp. 228-235, 2000.

Li, B., Chang, E., and Wu, C.T. DPF-a perceptual distance
function for image retrieval. Proc. IEEE Int. Conf. on Image
Processing, vol. 2, pp. 597-600, 2002.

[25] Tong, S. and Chang, E. Support vector machine active
learning for image retrieval. Proc. 9th ACM Int. Conf. on
Multimedia, 2001.

Liu, F., and Picard, R.W. Periodicity, directionality, and
randomness: Wold features for image modeling and retrieval.
IEEE Trans. on Pattern Analysis and Machine Intelligence,
vol. 8, 1996.

[26] Wang, J.Z., Wiederhold, G., Firschein, O., and Sha, X.W.
Content-based image indexing and searching using
Daubechies’ wavelets. Int. Journal of Digital Libraries, vol.
1, no. 4, pp. 311-328, 1998.

[10] Manjunath, B.S., and Ma, W.Y. Texture features for
browsing and retrieval of image data. IEEE Trans. on
Pattern Analysis and Machine Intelligence, vol. 18, pp. 837842, 1996.

[27] Wu, Y., Tian, Q., and Huang, T. Discriminant-EM algorithm
with application to image retrieval. Proc. IEEE Conf. on
Computer Vision and Pattern Recognition, vol. 1, pp. 155162, 2000.

[11] Morik, K., Brockhausen, P., and Joachims, T. Combining
statistical learning with a knowledge-based approach––a
case study in intensive care monitoring. Proc. 16th Int. Conf.
on Machine Learning, 1999.

[28] Zhang, L., Lin, F., and Zhang, B. Support vector machine
learning for image retrieval. Proc. IEEE Int. Conf. on Image
Processing, vol. 2, pp. 721-724, 2001.

[12] Pass, G. Comparing images using color coherence vectors.
Proc. 4th ACM Int. Conf. on Multimedia, pp. 65-73, 1997.

[29] Zhou, D., et al. Learning with local and global consistency.
NIPS, 2003.

[13] Porkaew, K., and Chakrabarti, K. Query refinement for
multimedia similarity retrieval in MARS. Proc. 7th ACM Int.
Conf. on Multimedia, pp. 235-238, 1999.

[30] Zhou, D., et al. Ranking on data manifolds. NIPS, 2003.
[31] Zhou, X.S., Rui, Y., and Huang, T. Water-Filling: a novel
way for image structural feature extraction. Proc. IEEE Int.
Conf. on Image Processing, vol. 2, pp. 570-574, 1999.

[14] Porkaew, K., Ortega, M., and Mehrota, S. Query
reformulation for content based multimedia retrieval in

16

