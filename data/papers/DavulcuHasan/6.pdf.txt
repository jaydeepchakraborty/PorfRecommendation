2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

Co-Clustering Signed 3-Partite Graphs
Sefa Şahin Koç

İsmail Hakkı Toroslu

Hasan Davulcu

Computer Science Department
Computer Engineering Department
Aselsan Rehis
Middle East Technical University, Ankara, Turkey Arizona State University, Tempe, AZ
Ankara, Turkey
Email: hdavulcu@asu.edu
Email: toroslu@ceng.metu.edu.tr
Email: sskoc@aselsan.com.tr

Abstract—In this paper, we propose a new algorithm, called
ST RI C LUSTER, to find tri-clusters from signed 3-partite graphs.
The dataset contains three different types of nodes. Hyperedges
connecting three nodes from three different partitions represent
either positive or negative relations among those nodes. The
aim of our algorithm is to find clusters with strong positive
relations among its nodes. Moreover, negative relations up to
a certain threshold is also allowed. Also, the clusters can have
no overlapping hyperedges. We show the effectiveness of our
algorithm via several experiments.

I. I NTRODUCTION
A hyperedge in a tri-partite graph represents the relationship
among the three nodes it connects. For example, in a social
tagging system, which contains three types of nodes (users,
tags, resources), a hyperedge means that a user annotates a
resource with a tag [1]. A tripartite cluster of these hyperedges
may give many information such as users' attitudes to multiple
resources or users with common interests. As another example,
in a biological analysis system, a level of gene in a sample at
a particular time can be represented as a tripartite hyperedge.
By mining tripartite clusters, genes showing common characteristics in samples at common time slots could be extracted
[2].
Finding biclusters with maximum size from a bipartite graph
is proven to be NP-hard, as well as discovering tripartite
clusters with maximum size [3]. Therefore, works in literature
[2], [4], [1] apply heuristics to determine clusters. As a common strategy, tri-clusters are generated by first constructing
biclusters between each pair of three partitions [4]. Then, each
bicluster is matched with two others in order to construct triclusters. Since this approach is very costly, as an alternative,
first, two partitions are selected, and, then, biclusters of these
bipartite graphs are constructed. After that, by iterating each
one of these biclusters on the third partition, tripartite clusters
can be constructed [2]. However, since the first two partitions
are fixed, this approach has bias against the third partition.
As another approach, tripartite clusters focus on one-to-one
correspondence among the nodes [5], [6]. However, the realworld data is usually more complex. For example, in a social
tagging system, a group of users may tag multiple sources
with the same set of tags, which corresponds to many-to-many
relationship.
In this paper, we present an effective algorithm which
generates tri-clusters from tripartite hyperedges with positive
signs. Our method has the following properties: 1) A minimum

IEEE/ACM ASONAM 2016, August 18-21
2016, San Francisco, CA, USA
978-1-5090-2846-7/16/$31.00 © 2016 IEEE

threshold for positive signed hyperedge density ratio over
all possible hyperedges among tri-partitions of the cluster is
defined, and, it must be satisfied by clusters. 2) A simple
greedy approach is used in order to trim the hyperedges from
tri-clusters with negative signs to increase the positive density
ratio of the cluster. 3) In order to prevent constructing very
small clusters, both negative signed hyperedges and triples
with no connections are also allowed as long as they satisfy
user defined density threshold constraints. 4) Clusters are not
allowed to have overlaps in terms of hyperedges. A simple
heuristic is used to mark hyperedges in order to prevent
hyperedge overlaps among clusters, and fast termination of
the algorithm while searching potentially maximal clusters. 5)
The effectiveness of our approach is shown using a coveragebased metric.
To the best of our knowledge this is the first work that
attempts to find co-clusters with potentially overlapping nodes
from signed tri-partite graphs. In our work, the clusters
are constructed considering the hyperedges, and thus, it is
possible to generate clusters with common nodes from the
same dimension. A typical problems that motivates this work
is finding co-clusters from sentiments of tweets on issues.
The three dimensions of this problems are people who write
tweets, the selected set of issues (or named entities) and the
chosen sentiment words by the users on these issues. The
sign of the sentiment words also sepresent the sign of the
hyperedge between the three nodes of these dimenstions. It is
very likely that same sentiment words are used by people with
different clusters corresponding to different camps. Similarly
more than one camp may have similar sentiments towards the
same issue as well. Therefore, clusters generated on sentiment
words and on issues which corresponds to positive feelings
of different camps may have many common items. Even on
people dimension, it is likely to generate clusters with several
common people, which may be interpreted as these people
being close to more than one different political camps.
The rest of the paper is organized as follows. Section
II introduces ST RI C LUSTER algorithm. Section III presents
experiments and section IV concludes the paper.
II. T HE ST RI C LUSTER A LGORITHM
In this paper, we use the notations given in Table 1.
ST RI C LUSTER algorithm takes a set of hyperedges, Γ as an
input, such that each hyperedge h connects three nodes from
three different types U = (U1 , U2 , U3 ). Figure 1 illustrates

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)
for 1 ≤ i ≤ 3, and this constraint should also be satisfied by
every cluster.

TABLE I
S YMBOL TABLE
Symbol
Γ
Γv/iv
α
p
n
λi
Li
<
h+/−
Ui
Eir
Uir
Si

Meaning
set of hyperedges
set of valid/invalid hyperedges
a tripartite cluster
minimum ratio of h+ in a cluster
maximum ratio of h− in a cluster
minimum size for type i in a cluster
number of nodes for type i in a cluster (size of type i)
set of tripartite clusters
a hyperedge with positive/negative label
set of nodes for type i
affectiveness value for node r of type i
minimum Eir in Ui , which belongs to node r
maximum number of h in which a node from type i can be

hyperedges given as 3D matrix. These hyperedges have either
positive or negative labels which are also represented by green
and red colors respectively in Figure 1. Remaining entries
(white cells) corresponds to node triples without connecting
hyperedges. In the example, nodes are {{A,B}, {a,b,c,d,e},
{1,2,3,4,5}} from types U1 , U2 , U3 respectively.
A

1

a

3

-

b

-

c

+

d
e

2

+

+

4

5

B

+

-

a

+

-

+

2

3

+

-

4

5
+

b

+

+

+

c

+

+

-

-

+

d

-

+

+

+

e

+

+

-

1

+

Algorithm 1 STriCluster Algorithm
1: procedure ST RI C LUSTER (Γ, p , n , λ1 , λ2 , λ3 )
2:
loop
3:
generate α from Γ
4:
β = C LEAN I NVALIDS(Γ, Γiv , α, λ1 , λ2 , λ3 )
5:
if not β then
6:
return <
7:
end if
8:
D ENSITY C HECKING(α, p , n , λ1 , λ2 , λ3 )
9:
if α * f ormula (3) then
. if α satisfies
10:
<←<⊕α
. ⊕ means appending
11:
end if
12:
for each h in α do
. h is a hyperedge in α
13:
Γiv ← Γiv ⊕ h
14:
end for
15:
end loop
16: end procedure
ST RI C LUSTER algorithm (Algorithm 1) starts by generating
a potential cluster α which contains all hyperedges in Γ. For
the example input data in Figure 1, α initially is equal to the
whole graph. If there are invalid hyperedges (used to prevent
hyperedge overlaps), they will be removed from α (Section
2.B). After invalid hyperedges are removed, if α does not
satisfy the condition (3), (i.e., β is FALSE), the algorithm
terminates.

Fig. 1. Input Data

The aim of ST RI C LUSTER is to find tripartite clusters of
hyperedges with highly positive labels. To be a valid tripartite
cluster, it has to satisfy threshold values for both density and
size. The density threshold values are p and n , such that
0 ≤ p , n ≤ 1, (p + n ) ≤ 1. The former one represents the
minimum ratio density of positive hyperedges (h+ ) among all
possible hyperedges (i.e., there may be L1 × L2 × L3 number
of possible hyperedges for a cluster with size (L1 , L2 , L3 ),
where Li is number of nodes with Ui type in the cluster). If
Cp is the number of h+ , then:
Cp
,
(1)
L1 × L2 × L3
If p = 1, generated tripartite clusters become tripartite cliques
as well. n is the value to control the density of negatively
signed hyperedges (h− ). If Cn represnts the number of h− ,
then:
Cn
n ≥
,
(2)
L1 × L2 × L3
shows maximum allowed tolerance of h− in a cluster if n 6=
0.
In order to prevent constructing very small clusters λi is
defined, such that:
Li ≥ λi ,
(3)
p ≤

A

1

a

3

-

b

-

c

+

d
e

2

+

+

4

5

B

+

-

a

+

-

+

2

3

+

-

4

5
+

b

+

+

+

c

+

+

-

-

+

d

-

+

+

+

e

+

+

-

1

+

Fig. 2. Removing Node (3) From a Potential Cluster

After a potential cluster α is generated, density check
operation is applied on α (Section 2.A). This operation aims
to get α to satisfy conditions (1), (2), and (3). There are three
possible cases that can happen: In the first case (case I), if
conditions (1) or (2) are not satisfied, the least useful node is
removed from α (Figure 2) iteratively, until both constraints
are satisfied. For the example in Figure 1, this step will remove
nodes {{a,d,e}, {3,4,5}} from types U2 , U3 respectively from
α. As the second case (case II), if the removal of a node
from α violates the constraint (3), the process stops. In this
case, one h− in α is labeled as invalid. This prevents the
construction of exactly the same potential tripartite cluster
again, because of C LEAN I NVALIDS operation (Line 4) of the
algorithm. As the third case (case III), α satisfies conditions
(1), (2), and (3). Then, D ENSITY C HECKING operation returns

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

α (as a reference parameter). In the example, returned cluster
α contains nodes {{A,B}, {b,c}, {1,2}} shown in Figure 3. In
this case, α is added to the cluster list < (Line 7). After that,
all hyperedges in α are labeled as invalid and added into Γiv
which is the list of invalid hyperedges (Line 13). The following
sub-section describes the details of density checking procedure
which handles these operations.

(Figure 2). Node 3 has the lowest effectiveness value, E33 ,
5 = 0.1 uscompared to others. E33 is obtained as 2+2−1−1−1
2×
ing formula (5). In following iterations, nodes {a, d, e, 3, 4, 5}
will be removed from α. Then, D ENSITY C HECKING will
reach to case III satisfying all three conditions (1), (2), and (3)
and, then returns α which contains nodes {A, B, b, c, 1, 2}.
If α does not satisfy conditions (1) and (2) and if node
removal results the violation of condition (3), it means that
D ENSITY C HECKING is in case II. In this case, the procedure
marks the first h− as invalid.

A

1

2

B

1

2

B. Clean Invalids

b

-

+

b

+

+

c

+

c

+

+

Invalid hyperedges include the hyperedges of all tripartite
clusters previously generated as well as all edges marked
as invalid by D ENSITY C HECKING. In order to remove a
hyperedge one of the nodes from this hyperedge should be
removed. To do this, C LEAN I NVALIDS procedure picks a node
to remove and it repeats the same action until no invalid
hyperedge is left in α. While selecting a node, it uses a
heuristic that reduces the cluster size as minimum as possible.
In order to do this, we first determine the number of invalid
hyperedges connected to each node. If the ratio of this number
to Si is high, that node is more likely to be removed. This ratio,
called as θir for node r from type i. Then, we calculate the
effectiveness for all the valid nodes of α, which is called as
v
Eir
. These two values values are combined with the following
formula:
θir
(7)
γir =
v .
0.9 + Eir

(a) Matrix Representation

(b) Cluster Representation

Fig. 3. A Tripartite Cluster Mined in Given Input

A. Density Checking
If given cluster α does not satisfy conditions (1) and (2),
the density checking algorithm searches for nodes to exclude
until α satisfies these constraints. If a node is connected by
high number of h+ , it should be less likely to be removed.
We define hyperedge’s usefullness as follows:
(
2
if h has positive label
val(h) =
(4)
−1
if h has negative label.
Then, the effectiveness of a node (r) is determined with the
following formula where Si represents the maximum number
of hyperedges which contains that node in Ui :
(
P
val(h)
if r ∈ h
h∈α
0
otherwise
Eir =
.
(5)
Si
Then, for each partition, all nodes are checked to find a node
with minimum effectiveness value:
X
Uir = min(
Eir ).
(6)
r∈Ui

At the end of this stage, there will be three Uir values
which are U1a , U2b , U3c corresponding to partitions U1 , U2 , U3
respectively. Minimum of them will be the effectiveness value
Eix of node x. This node will be the one to be removed from
type i in α in this iteration.
TABLE II
N UMBER OF POSSIBLE HYPEREDGES FOR EACH NODE TYPE
Type
S1
S2
S3

Value
L2 × L3
L1 × L3
L1 × L2

For the input in Figure 1, when D ENSITY C HECKING operation applied on α, node 3 will be removed in the first iteration

Among all nodes, the one which has highest γ value is the
one to be removed.
As a constraint, if removing node x will result violation
of condition (3), C LEAN I NVALIDS procedure returns FALSE.
If there is no invalid hyperedge left in α, C LEAN I NVALIDS
returns TRUE.
For the input data in Figure 1, ST RI C LUSTER algorithm
finds the cluster in Figure 3 in the first iteration. Then,
hyperedges of this newly generated cluster are labeled as
invalid. In the next iteration, new potential cluster α (Figure 4-a) is generated from Γ. But α contains some invalid
hyperedges (colored with blue in Figure 4-a). Therefore, α
is passed to C LEAN I NVALIDS procedure to be cleaned from
invalid hyperedges. First, node c is removed since γ2c is
3 ÷ 0.9 = 3.33, is the maximum among γ values. Then, nodes
2 and 1 are selected and removed respectively (Figure 4-b,
4-c). This will result a clean α (Figure 4-d) and the procedure
terminates.
III. E XPERIMENTS
In order to evaluate our algorithm, we have generated data
sets with varying sizes. We have done all the experiments on
MacBook Pro Mid 2015 (Intel i7 2,5 GHz, 16GB memory).
In the first set of experiments, we have fixed h+ and h−
density ratios while changing input sizes. Other parameters
are also fixed as p = 0.75, n = 0.10, λi = (2,2,2). In this
test, we have generated 6 sample datasets. Each one contains

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

A

1

2

-

+

a
b
c

-

4

5

+

-

+

+

-

+

+

B

1

a
b

+

d
e

3

2

3

+

-

+

+

4

5

A

+

b

+

c

+

+

-

-

+

d

-

+

+

+

e

+

1

3

-

+

a
b

4

5

B

+

-

a

+

d
e

+
+

-

+

1

3

4

-

b

+

d

-

e

e

+

+

3

-

4

5

+

-

+

+

-

+

B

-

+

+

1

a
b

2

3

+

-

+

+

d

-

+

e

+

4

5
+

+
+

+

(b) Removing Second Node

5

A

+

a

+
+

2

-

d

(a) Removing First Node

A

1

a

+

b
+

3

4

5

B

3

+

-

a

-

+

+

-

+

d
e

(c) Removing Third Node

4

+

5
+

b

+

d

+

+

e

(d) A Clean Tripartite Cluster

Fig. 4. A Scenario of C LEAN I NVALIDS Procedure

positive hyperedges with 60%, negative hyperedges with 20%,
and 20% is empty. (L1 × L2 × L3 ) values for these samples
are (31.25K, 62.5K, 125K, 250K, 500K, 1M) respectively.
Figure 5 presents the results.
Time

Cover

IV. C ONCLUSION
300K

5250 sn

225K

3500 sn

150K

1750 sn

75K

31.25K

62.5K

125K

250K

500K

1M

Number of Hyperedges

Time

7000 sn

0 sn

clusters being non-trivial. The results show that we have
achieved very high coverage in that sense, since constructed
clusters include almost as many hyperedges as the half of the
number of positively signed hyperedges.
We have also tested our approach using real data set, which
corresponds to the tweets of users on selected issues. These
tweets are processed in order to determine the sentiments of
users towards these issues. From these tweets, a three dimensional data set is generated. These dimensions are users, issues,
and sentiment words chosen by the users on these issues,
which also represent the sign of the hyperedge connecting
these three items. We have large datasets with 10K users, 45K
sentiment words and 20 different issues. This 3-dimensional
data is very sparse with only 280K non-empty entries. So far,
we have applied our algorithm to a fraction of this dataset
which corresponds to randomly select few percentages of it.
We have obtained fairly large and overlapping clusters in all
three dimensions. Some largest clusters have as many items as
the 10% of the nodes of its corresponding dimensions, even
for user or sentiment words dimensions.

0K

In this paper, we have proposed a new method, called
ST RI C LUSTER, to mine tripartite clusters of positively labeled
hyperedges. The input data is composed of three dimensions.
Each hyperedge connects three nodes from each dimension.
Clusters are generated depending on density ratio of positively
(minimum) and negatively (maximum) labeled hyperedges.
We have showed the effectiveness of our approach using
both syntetic and real data sets.

Input Size

ACKNOWLEDGMENT
Fig. 5. Test Scenario Depending on Input Size

In the second test, we have generated 5 datasets. In this test,
we have fixed the size as (L1 × L2 × L3 ) = 125K and we
have varying density ratios for (h+ , h− ) pairs as {(0.2,0.4),
(0.2,0.2), (0.4,0.2), (0.4,0.4), (0.6,0.2)}. The results are shown
in Figure 6.
Cover
35K

768 sn

26K

512 sn

18K

256 sn

9K

0 sn

0.2-0.4

0.2-0.2

0.4-0.4

0.4-0.2

0.6-0.2

Number of Hyperedges

Time

Time
1024 sn

0K

Density Ratio Values

Fig. 6. Test Scenario Depending on Density Ratios in Input Data

The figures show both execution times and the number of
hyperedges included in the constructed clusters. We prefer
most (positive) hyperedges to be included in clusters while

This research was supported partially by USAF Grant
FA9550-15-1-0004.
R EFERENCES
[1] C. Lu, X. Chen, and E. Park, “Exploit the tripartite network of social
tagging for web clustering,” in Proceedings of the 18th ACM conference
on Information and knowledge management. ACM, 2009, pp. 1545–
1548.
[2] L. Zhao and M. J. Zaki, “Tricluster: an effective algorithm for mining
coherent clusters in 3d microarray data,” in Proceedings of the 2005 ACM
SIGMOD international conference on Management of data. ACM, 2005,
pp. 694–705.
[3] M. Dawande, P. Keskinocak, J. M. Swaminathan, and S. Tayur, “On
bipartite and multipartite clique problems,” Journal of Algorithms, vol. 41,
no. 2, pp. 388–403, 2001.
[4] L. Zhu, A. Galstyan, J. Cheng, and K. Lerman, “Tripartite graph clustering for dynamic sentiment analysis on social media,” in Proceedings
of the 2014 ACM SIGMOD international conference on Management of
data. ACM, 2014, pp. 1531–1542.
[5] X. Liu and T. Murata, “Detecting communities in tripartite hypergraphs,”
arXiv preprint arXiv:1011.1043, 2010.
[6] Y.-R. Lin, J. Sun, P. Castro, R. Konuru, H. Sundaram, and A. Kelliher,
“Metafac: community discovery via relational hypergraph factorization,”
in Proceedings of the 15th ACM SIGKDD international conference on
Knowledge discovery and data mining. ACM, 2009, pp. 527–536.

