2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

Co-Clustering Signed 3-Partite Graphs
Sefa S ¸ ahin Koc ¸  Ismail Hakki Toroslu Hasan Davulcu
Computer Science Department Computer Engineering Department Aselsan Rehis Middle East Technical University, Ankara, Turkey Arizona State University, Tempe, AZ Ankara, Turkey Email: hdavulcu@asu.edu Email: toroslu@ceng.metu.edu.tr Email: sskoc@aselsan.com.tr

Abstract--In this paper, we propose a new algorithm, called ST RI C LUSTER, to find tri-clusters from signed 3-partite graphs. The dataset contains three different types of nodes. Hyperedges connecting three nodes from three different partitions represent either positive or negative relations among those nodes. The aim of our algorithm is to find clusters with strong positive relations among its nodes. Moreover, negative relations up to a certain threshold is also allowed. Also, the clusters can have no overlapping hyperedges. We show the effectiveness of our algorithm via several experiments.

I. I NTRODUCTION A hyperedge in a tri-partite graph represents the relationship among the three nodes it connects. For example, in a social tagging system, which contains three types of nodes (users, tags, resources), a hyperedge means that a user annotates a resource with a tag [1]. A tripartite cluster of these hyperedges may give many information such as users' attitudes to multiple resources or users with common interests. As another example, in a biological analysis system, a level of gene in a sample at a particular time can be represented as a tripartite hyperedge. By mining tripartite clusters, genes showing common characteristics in samples at common time slots could be extracted [2]. Finding biclusters with maximum size from a bipartite graph is proven to be NP-hard, as well as discovering tripartite clusters with maximum size [3]. Therefore, works in literature [2], [4], [1] apply heuristics to determine clusters. As a common strategy, tri-clusters are generated by first constructing biclusters between each pair of three partitions [4]. Then, each bicluster is matched with two others in order to construct triclusters. Since this approach is very costly, as an alternative, first, two partitions are selected, and, then, biclusters of these bipartite graphs are constructed. After that, by iterating each one of these biclusters on the third partition, tripartite clusters can be constructed [2]. However, since the first two partitions are fixed, this approach has bias against the third partition. As another approach, tripartite clusters focus on one-to-one correspondence among the nodes [5], [6]. However, the realworld data is usually more complex. For example, in a social tagging system, a group of users may tag multiple sources with the same set of tags, which corresponds to many-to-many relationship. In this paper, we present an effective algorithm which generates tri-clusters from tripartite hyperedges with positive signs. Our method has the following properties: 1) A minimum

threshold for positive signed hyperedge density ratio over all possible hyperedges among tri-partitions of the cluster is defined, and, it must be satisfied by clusters. 2) A simple greedy approach is used in order to trim the hyperedges from tri-clusters with negative signs to increase the positive density ratio of the cluster. 3) In order to prevent constructing very small clusters, both negative signed hyperedges and triples with no connections are also allowed as long as they satisfy user defined density threshold constraints. 4) Clusters are not allowed to have overlaps in terms of hyperedges. A simple heuristic is used to mark hyperedges in order to prevent hyperedge overlaps among clusters, and fast termination of the algorithm while searching potentially maximal clusters. 5) The effectiveness of our approach is shown using a coveragebased metric. To the best of our knowledge this is the first work that attempts to find co-clusters with potentially overlapping nodes from signed tri-partite graphs. In our work, the clusters are constructed considering the hyperedges, and thus, it is possible to generate clusters with common nodes from the same dimension. A typical problems that motivates this work is finding co-clusters from sentiments of tweets on issues. The three dimensions of this problems are people who write tweets, the selected set of issues (or named entities) and the chosen sentiment words by the users on these issues. The sign of the sentiment words also sepresent the sign of the hyperedge between the three nodes of these dimenstions. It is very likely that same sentiment words are used by people with different clusters corresponding to different camps. Similarly more than one camp may have similar sentiments towards the same issue as well. Therefore, clusters generated on sentiment words and on issues which corresponds to positive feelings of different camps may have many common items. Even on people dimension, it is likely to generate clusters with several common people, which may be interpreted as these people being close to more than one different political camps. The rest of the paper is organized as follows. Section II introduces ST RI C LUSTER algorithm. Section III presents experiments and section IV concludes the paper. II. T HE ST RI C LUSTER A LGORITHM In this paper, we use the notations given in Table 1. ST RI C LUSTER algorithm takes a set of hyperedges,  as an input, such that each hyperedge h connects three nodes from three different types U = (U1 , U2 , U3 ). Figure 1 illustrates

IEEE/ACM ASONAM 2016, August 18-21 2016, San Francisco, CA, USA 978-1-5090-2846-7/16/$31.00 © 2016 IEEE

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM) for 1  i  3, and this constraint should also be satisfied by every cluster. Algorithm 1 STriCluster Algorithm 1: procedure ST RI C LUSTER (, p , n , 1 , 2 , 3 ) 2: loop 3: generate  from  4:  = C LEAN I NVALIDS(, iv , , 1 , 2 , 3 ) 5: if not  then 6: return 7: end if 8: D ENSITY C HECKING(, p , n , 1 , 2 , 3 ) 9: if  f ormula (3) then if  satisfies 10:    means appending 11: end if 12: for each h in  do h is a hyperedge in  13: iv  iv  h 14: end for 15: end loop 16: end procedure ST RI C LUSTER algorithm (Algorithm 1) starts by generating a potential cluster  which contains all hyperedges in . For the example input data in Figure 1,  initially is equal to the whole graph. If there are invalid hyperedges (used to prevent hyperedge overlaps), they will be removed from  (Section 2.B). After invalid hyperedges are removed, if  does not satisfy the condition (3), (i.e.,  is FALSE), the algorithm terminates.
A a b c d e + + + 1 2 + + 3 4 + + + + 5 B a b c d e + + + 1 2 + + + + + 3 + + 4 5 +

TABLE I S YMBOL TABLE Symbol  v/iv 
p n

i Li h+/- Ui Eir Uir Si

Meaning set of hyperedges set of valid/invalid hyperedges a tripartite cluster minimum ratio of h+ in a cluster maximum ratio of h- in a cluster minimum size for type i in a cluster number of nodes for type i in a cluster (size of type i) set of tripartite clusters a hyperedge with positive/negative label set of nodes for type i affectiveness value for node r of type i minimum Eir in Ui , which belongs to node r maximum number of h in which a node from type i can be

hyperedges given as 3D matrix. These hyperedges have either positive or negative labels which are also represented by green and red colors respectively in Figure 1. Remaining entries (white cells) corresponds to node triples without connecting hyperedges. In the example, nodes are {{A,B}, {a,b,c,d,e}, {1,2,3,4,5}} from types U1 , U2 , U3 respectively.
A a b c d e + + + 1 2 + + 3 4 + + + + 5 B a b c d e + + + 1 2 + + + + + 3 + + 4 5 +

Fig. 1. Input Data

The aim of ST RI C LUSTER is to find tripartite clusters of hyperedges with highly positive labels. To be a valid tripartite cluster, it has to satisfy threshold values for both density and size. The density threshold values are p and n , such that 0  p , n  1, ( p + n )  1. The former one represents the minimum ratio density of positive hyperedges (h+ ) among all possible hyperedges (i.e., there may be L1 × L2 × L3 number of possible hyperedges for a cluster with size (L1 , L2 , L3 ), where Li is number of nodes with Ui type in the cluster). If Cp is the number of h+ , then: Cp , (1) L1 × L2 × L3 If p = 1, generated tripartite clusters become tripartite cliques as well. n is the value to control the density of negatively signed hyperedges (h- ). If Cn represnts the number of h- , then: Cn , (2) n  L1 × L2 × L3 shows maximum allowed tolerance of h- in a cluster if n = 0. In order to prevent constructing very small clusters i is defined, such that: Li  i , (3)
p

Fig. 2. Removing Node (3) From a Potential Cluster



After a potential cluster  is generated, density check operation is applied on  (Section 2.A). This operation aims to get  to satisfy conditions (1), (2), and (3). There are three possible cases that can happen: In the first case (case I), if conditions (1) or (2) are not satisfied, the least useful node is removed from  (Figure 2) iteratively, until both constraints are satisfied. For the example in Figure 1, this step will remove nodes {{a,d,e}, {3,4,5}} from types U2 , U3 respectively from . As the second case (case II), if the removal of a node from  violates the constraint (3), the process stops. In this case, one h- in  is labeled as invalid. This prevents the construction of exactly the same potential tripartite cluster again, because of C LEAN I NVALIDS operation (Line 4) of the algorithm. As the third case (case III),  satisfies conditions (1), (2), and (3). Then, D ENSITY C HECKING operation returns

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

 (as a reference parameter). In the example, returned cluster  contains nodes {{A,B}, {b,c}, {1,2}} shown in Figure 3. In this case,  is added to the cluster list (Line 7). After that, all hyperedges in  are labeled as invalid and added into iv which is the list of invalid hyperedges (Line 13). The following sub-section describes the details of density checking procedure which handles these operations.

(Figure 2). Node 3 has the lowest effectiveness value, E33 , 1-1-1 5 = 0.1 uscompared to others. E33 is obtained as 2+2- 2× ing formula (5). In following iterations, nodes {a, d, e, 3, 4, 5} will be removed from . Then, D ENSITY C HECKING will reach to case III satisfying all three conditions (1), (2), and (3) and, then returns  which contains nodes {A, B, b, c, 1, 2}. If  does not satisfy conditions (1) and (2) and if node removal results the violation of condition (3), it means that D ENSITY C HECKING is in case II. In this case, the procedure marks the first h- as invalid. B. Clean Invalids Invalid hyperedges include the hyperedges of all tripartite clusters previously generated as well as all edges marked as invalid by D ENSITY C HECKING. In order to remove a hyperedge one of the nodes from this hyperedge should be removed. To do this, C LEAN I NVALIDS procedure picks a node to remove and it repeats the same action until no invalid hyperedge is left in . While selecting a node, it uses a heuristic that reduces the cluster size as minimum as possible. In order to do this, we first determine the number of invalid hyperedges connected to each node. If the ratio of this number to Si is high, that node is more likely to be removed. This ratio, called as ir for node r from type i. Then, we calculate the effectiveness for all the valid nodes of , which is called as v Eir . These two values values are combined with the following formula: ir (7) ir = v . 0.9 + Eir Among all nodes, the one which has highest  value is the one to be removed. As a constraint, if removing node x will result violation of condition (3), C LEAN I NVALIDS procedure returns FALSE. If there is no invalid hyperedge left in , C LEAN I NVALIDS returns TRUE. For the input data in Figure 1, ST RI C LUSTER algorithm finds the cluster in Figure 3 in the first iteration. Then, hyperedges of this newly generated cluster are labeled as invalid. In the next iteration, new potential cluster  (Figure 4-a) is generated from . But  contains some invalid hyperedges (colored with blue in Figure 4-a). Therefore,  is passed to C LEAN I NVALIDS procedure to be cleaned from invalid hyperedges. First, node c is removed since 2c is 3 ÷ 0.9 = 3.33, is the maximum among  values. Then, nodes 2 and 1 are selected and removed respectively (Figure 4-b, 4-c). This will result a clean  (Figure 4-d) and the procedure terminates. III. E XPERIMENTS In order to evaluate our algorithm, we have generated data sets with varying sizes. We have done all the experiments on MacBook Pro Mid 2015 (Intel i7 2,5 GHz, 16GB memory). In the first set of experiments, we have fixed h+ and h- density ratios while changing input sizes. Other parameters are also fixed as p = 0.75, n = 0.10, i = (2,2,2). In this test, we have generated 6 sample datasets. Each one contains

A b c

1 +

2 +

B b c

1 + +

2 + +

(a) Matrix Representation

(b) Cluster Representation

Fig. 3. A Tripartite Cluster Mined in Given Input

A. Density Checking If given cluster  does not satisfy conditions (1) and (2), the density checking algorithm searches for nodes to exclude until  satisfies these constraints. If a node is connected by high number of h+ , it should be less likely to be removed. We define hyperedge's usefullness as follows: val(h) = 2 -1 if h has positive label if h has negative label. (4)

Then, the effectiveness of a node (r) is determined with the following formula where Si represents the maximum number of hyperedges which contains that node in Ui :
h

. (5) Si Then, for each partition, all nodes are checked to find a node with minimum effectiveness value: Uir = min(
r Ui

Eir =

val(h) 0

if r  h otherwise

Eir ).

(6)

At the end of this stage, there will be three Uir values which are U1a , U2b , U3c corresponding to partitions U1 , U2 , U3 respectively. Minimum of them will be the effectiveness value Eix of node x. This node will be the one to be removed from type i in  in this iteration.
TABLE II N UMBER OF POSSIBLE HYPEREDGES FOR EACH NODE TYPE Type S1 S2 S3 Value L2 × L3 L1 × L3 L1 × L2

For the input in Figure 1, when D ENSITY C HECKING operation applied on , node 3 will be removed in the first iteration

2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)

A a b c d e

1

2 -

3

4 +

5 -

B a b

1

2 +

3 -

4

5 +

A a b

1

2 -

3

4 +

5 -

B a b

1

2 +

3 -

4

5 +

+

+

+

+ +

+ + +

+ + + +

+ +

-

+ -

+

+ +

+ +

+ + +

+ +

c d e

d e +

d e

+ +

+

-

+

(a) Removing First Node

(b) Removing Second Node

A a b d e

1

3

4 +

5 -

B a b

1

3 -

4

5 +

A a b

3

4 +

5 -

B a b

3 -

4

5 +

-

+

+ +

+ + +

+ +

+

+ +

+ + +

d e

d e +

d e

+

-

+

(c) Removing Third Node

(d) A Clean Tripartite Cluster

Fig. 4. A Scenario of C LEAN I NVALIDS Procedure

positive hyperedges with 60%, negative hyperedges with 20%, and 20% is empty. (L1 × L2 × L3 ) values for these samples are (31.25K, 62.5K, 125K, 250K, 500K, 1M) respectively. Figure 5 presents the results.
Time 7000 sn Cover 300K

clusters being non-trivial. The results show that we have achieved very high coverage in that sense, since constructed clusters include almost as many hyperedges as the half of the number of positively signed hyperedges. We have also tested our approach using real data set, which corresponds to the tweets of users on selected issues. These tweets are processed in order to determine the sentiments of users towards these issues. From these tweets, a three dimensional data set is generated. These dimensions are users, issues, and sentiment words chosen by the users on these issues, which also represent the sign of the hyperedge connecting these three items. We have large datasets with 10K users, 45K sentiment words and 20 different issues. This 3-dimensional data is very sparse with only 280K non-empty entries. So far, we have applied our algorithm to a fraction of this dataset which corresponds to randomly select few percentages of it. We have obtained fairly large and overlapping clusters in all three dimensions. Some largest clusters have as many items as the 10% of the nodes of its corresponding dimensions, even for user or sentiment words dimensions. IV. C ONCLUSION In this paper, we have proposed a new method, called ST RI C LUSTER, to mine tripartite clusters of positively labeled hyperedges. The input data is composed of three dimensions. Each hyperedge connects three nodes from each dimension. Clusters are generated depending on density ratio of positively (minimum) and negatively (maximum) labeled hyperedges. We have showed the effectiveness of our approach using both syntetic and real data sets. ACKNOWLEDGMENT This research was supported partially by USAF Grant FA9550-15-1-0004. R EFERENCES
[1] C. Lu, X. Chen, and E. Park, "Exploit the tripartite network of social tagging for web clustering," in Proceedings of the 18th ACM conference on Information and knowledge management. ACM, 2009, pp. 1545­ 1548. [2] L. Zhao and M. J. Zaki, "Tricluster: an effective algorithm for mining coherent clusters in 3d microarray data," in Proceedings of the 2005 ACM SIGMOD international conference on Management of data. ACM, 2005, pp. 694­705. [3] M. Dawande, P. Keskinocak, J. M. Swaminathan, and S. Tayur, "On bipartite and multipartite clique problems," Journal of Algorithms, vol. 41, no. 2, pp. 388­403, 2001. [4] L. Zhu, A. Galstyan, J. Cheng, and K. Lerman, "Tripartite graph clustering for dynamic sentiment analysis on social media," in Proceedings of the 2014 ACM SIGMOD international conference on Management of data. ACM, 2014, pp. 1531­1542. [5] X. Liu and T. Murata, "Detecting communities in tripartite hypergraphs," arXiv preprint arXiv:1011.1043, 2010. [6] Y.-R. Lin, J. Sun, P. Castro, R. Konuru, H. Sundaram, and A. Kelliher, "Metafac: community discovery via relational hypergraph factorization," in Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2009, pp. 527­536.

3500 sn

150K

1750 sn

75K

0 sn

31.25K

62.5K

125K

250K

500K

1M

0K

Input Size

Fig. 5. Test Scenario Depending on Input Size

In the second test, we have generated 5 datasets. In this test, we have fixed the size as (L1 × L2 × L3 ) = 125K and we have varying density ratios for (h+ , h- ) pairs as {(0.2,0.4), (0.2,0.2), (0.4,0.2), (0.4,0.4), (0.6,0.2)}. The results are shown in Figure 6.
Time 1024 sn Cover 35K

512 sn

18K

256 sn

9K

0 sn

0.2-0.4

0.2-0.2

0.4-0.4

0.4-0.2

0.6-0.2

0K

Density Ratio Values

Fig. 6. Test Scenario Depending on Density Ratios in Input Data

The figures show both execution times and the number of hyperedges included in the constructed clusters. We prefer most (positive) hyperedges to be included in clusters while

Number of Hyperedges

768 sn

26K

Time

Number of Hyperedges

5250 sn

225K

Time

