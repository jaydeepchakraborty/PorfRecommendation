The 2009 IEEE/RSJ International Conference on
Intelligent Robots and Systems
October 11-15, 2009 St. Louis, USA

LabRatTM: Miniature Robot for Students,
Researchers, and Hobbyists
Paul Robinette1,2 , Ryan Meuth1,2 , Ryanne Dolan1,3 and Donald Wunsch2
1
Rolla Engineered Solutions, LLC, Rolla, MO USA
2
Applied Computational Intelligence Laboratory,
Missouri University of Science and Technology, Rolla, MO USA
3
University of Missouri, Columbia, MO USA

Abstract—LabRatTM is an autonomous, self-contained mobile
robot kit with batteries, motors, two bumper whisker sensors,
and three infrared proximity sensors that double as channels for
"Rat-to-Rat" communication. The vehicle determines its position
with an optical sensor that detects movement in both lateral
directions. The LabRatTM design is completely open source,
including software examples and libraries. LabRatTM is designed
to fit inside the body of a computer mouse and has applications
in the classroom, the lab and the home. The device has been
successfully used in an undergraduate robotics class.

I. I NTRODUCTION
LabRatTM is a small, open-source robot designed to be
used by students, researchers and hobbyists for a variety of
applications. What distinguishes LabRatTM from other small
robot kits is an optical mouse sensor on the bottom of the
robot, providing high-rate, high-accuracy position information,
as well as the ability for instructors to incorporate machine
vision into their courses, as the optical sensor is effectively a
small CMOS camera.
High school and college educators can use LabRatTM to
teach programming, electronics, and introductory robotics,
while researchers can upgrade LabRatTM with a serial radio
and a very small Linux computer to provide an unprecedented
level of capability in a small package at very low cost.
Hobbyists can change any aspect of the design through the
use of freely available open-source tools and documentation
for both hardware and software.
II. BACKGROUND
Robotics is an inherently interdisciplinary engineering field,
encompassing electrical, computer and mechanical engineering, as well as computer science, mathematics, physics, systems engineering, and in some instances psychology, cognitive
neuroscience, and philosophy. The breadth of the problems
presented by robotics development encourages the integration
of knowledge and problem solving methods from a wide
range of fields. With the advent of autonomous vehicles
in the military and consumer robotics products such as the
iRobot Roomba, the robotics industry is growing rapidly and
is expected to continue to grow as consumer spending on
robotics increases. Study of the discipline of robotics can give
engineers a valuable perspective on systems integration, as
well as experience in a wide range of fields and in real-world

978-1-4244-3804-4/09/$25.00 ©2009 IEEE

problem solving, increasing the flexibility of the engineer in
a rapidly changing world.
Recently, engineering educators have started integrating
robotics into their classes. The 2005 Computing Curricula
recommendations by the Association for Computing Machinery (ACM), Association for Information Systems (AIS), and
the IEEE Computing Society (IEEE-CS) specifically mentions
robotics in its recommendation to Computer Science educators: "Now CS researchers are working with scientists from
other fields to make robots become practical and intelligent
aides" [13]. Robotics can apply to lessons across several
different disciplines in engineering, science, math and business
[17], [19]. Whole institutions are being created to educate
students in the robotics field [18].
While some are discussing the inclusion of robotics into
existing curriculum, others are writing about the changes
required to teach robotics as a major [16]. Dr. McKee describes
three basic divisions robotics education should have: designing
and building robots, programming robots for practical situations, and making robots act more human. He also believes
that education in robotics should start with practice and work
its way to theory instead of the other way around, as most
engineering is taught.
Robotics competitions have been a big factor in interesting
students of all ages in robotics specifically and engineering in
general [12]. In 2000, the Society of Manufacturing Engineers
offered 14 different robotics competitions from pick-andplace machines to remote control vehicles to maze-solvers.
The Association for Unmanned Vehicle Systems International
organized six collegiate level competitions in 2008 [2]. These
competitions have driven students to learn more about robots
through experience. Some schools are developing their own
robotics competitions for freshman introductory courses to
expose new students to engineering immediately [21].
Several instructors have found it necessary to create their
own electronics packages to give their students adequate
experiential learning in electrical and computer engineering.
One such package used two Atmel AVRs, four H-bridges to
control motors, an LCD screen and several general purpose
input and output pins to give students a platform for their
senior capstone course [14]. Several kits are also commercially available, such as Lego Mindstorms, iRobot Create and

1007

Parallax Scribbler [20]. Table I below summarizes several
educational and hobby robotics products. Each of these kits
has a niche that it favors in terms of student age, programming
proficiency, expandability and expense.
Although the LabRat is the only robot listed in Table I
that uses an optical sensor, these sensors have been used for
research into position measurement. In [11], the researchers
found that the optical sensor they were testing aggregated error
at a RMS rate of 0.2 mm over 50 mm. According to their
results, placing the sensor on the perpendicular axis to the
drive train on a differential drive robot provides the ability to
detect lateral motion in both axes as well as arcs in between
these axes.
III. T HE L AB R AT TM
A. Development
Development of the LabRatTM was greatly accelerated by its
open-source design and its use in the Introduction to Robotics
Class at the Missouri University of Science and Technology.
Primary development was accomplished by Rolla Engineered
Solutions, LLC with Cadsoft’s Eagle software to design the
circuit and lay out the board. This allowed for the development
process to go quickly using an inexpensive piece of software.
The engineers collaborated through the use of a Subversion
Repository, which also allowed for mistakes to be reverted
easily. The entire design was then published on Google Pages
so that students in the Robotics class could download design
details and libraries. The schematic is shown in Figure 1, the
top of the LabRatTM board is shown in Figure 2 and the bottom
is shown in Figure 3.
The software libraries were created using the freely available AVR Studio in Windows and open-source avr-gcc in
Linux. This allows for development in most software environments that students and researchers use. Due to the open
source nature of the project, students helped immensely in
fixing errors and adding functionality to the libraries as well
as suggesting changes in LabRatTM hardware.
Initially, two prototype LabRatsTM were made. Some errors
were found in these and corrected before the first production
run of the robots. These robots were delivered to students and
other customers in November of 2008 (see Figure 4). This
gave the designers more feedback and allowed them to perform
further modifications on the case design (see Figure 5).
B. Features
LabratTM has several features that make it attractive to
students, researchers and hobbyists. There are many ways to
communicate between LabRatTM and other devices through
wire and radio methods. Several sensors combine to allow
LabRatTM to accomplish a variety of tasks in the home, the
lab and the classroom.
1) Processing
Power:
The
processor
on
the
LabRatTM board is an Atmel AtMega324p AVR. This
is a simple yet powerful processor used extensively in
industry. The AVR is an 8 bit RISC microprocessor with 32
KB of flash memory running at 8 MHz. The LabRatTM is

Figure 2.

Top of LabRatTM Board

also expandable with an onboard Gumstix running at 600
MHz with 32 MB of RAM.
2) Sensors: LabRatTM comes with ranging, proximity and
position sensors. Three infrared LED/photosensor pairs are
arrayed on the front to allow the detection of objects up to
seven inches away. Just in front of these are two whiskers that
act as tactile proximity sensors so that LabRatTM can detect
when it has run into an obstacle. These whiskers can be bent to
the users preference so that LabRatTM can fit into tight spaces
or have the range to give objects a wide berth. It is possible to
connect an ultrasonic ranging device to the LabRat using the
extra general purpose ports, however this sensor would need
to be positioned carefully to avoid reflections from the ground.
It was determined to be unnecessary as standard equipment on
LabRatTM since the vehicle already has IR and touch sensors.
An optical sensor similar to those used in optical computer
mice is located on the bottom of LabRatTM to acquire position
information. The sensor only provides two dimensional movement information but through on-board software estimates can
be made about the rotation of LabRatTM .
The charge level of the batteries is also monitored through
the use of an on-board voltage sensor.

1008

Robot
PPRK [7]
Create [4]
LabRatTM
LegoMindstorms NXT [5]
Boe-Bot [3]
Scribbler [8]
SumoBot [9]
PicoBotz [6]
3pi [1]
Sumovore [10]

Vendor
Price
Programming Tools Prog. Languages
Hardware
Expandable
Compute Power
Acroname
$325
proprietary
proprietary
proprietary
very
limited
iRobot
$200-300
proprietary*
C, .Net
proprietary
very
expandable
RollaEng
$120-250
open-source
C
open-source
very
expandable
Lego
$200
proprietary
Java
proprietary
limited
limited
Parallax
$160
proprietary
BASIC
proprietary
limited
limited
Parallax
$160
proprietary*
BASIC
proprietary
no
limited
Parallax
$160
proprietary
BASIC
proprietary
limited
limited
iBOTZ
$140
proprietary
proprietary
proprietary
no
very limited
Pololu
$120
open-source
C
proprietary
limited
limited
Solarbotics
$100
open-source
C, BASIC
proprietary
limited
expandable
* Open-source tools are also available for the Create and Scribbler, but are not officially supported by their vendors
Table I
E DUCATIONAL ROBOTICS P LATFORMS

Figure 1.

LabRatTM Schematic

3) Communications: The main communication for programming and debugging LabRatTM is a serial port on the
back of the board. This allows for quick and easy communication but obviously does not work when the robot is
driving around the lab. A second serial port is sent to a port
designed for an XBee communications device. This allows
for communications at a distance of 100 meters to several
kilometers, depending on the XBee device used. The main
serial port is shared with the Gumstix device, which allows the
Gumstix to receive communication from an external computer
and reprogram the AVR in the field. Additionally, the IR
transmitter/receiver pairs on the front of the robot can double
as "Rat-to-Rat" communication channels through the use of
pulsed IR signals.
4) Expansion: Three general-purpose I/O pins are available
to experimenters for expansion. Each of these pins can be
configured through software for analog input or digital I/O.
Two UART ports and one I2C port are available for further
expansion. For research applications, LabRatTM has a port
to attach a Gumstix board. These open-source, Linux-based
embedded systems provide up to an additional 600 MHz of
processing power with 32 MB of RAM as well as a USB

connection and several other features attractive to research
labs.
5) Locomotion : LabRatTM propels itself using two small
Solarbotics motors. These motors are controlled by pulsewidth modulation, are powered by three AAA batteries and
can achieve speeds of up to 42 centimeters per second. At full
speed, standard alkaline batteries will provide functionality for
over 3 hours.
6) Form Factor: LabRatTM was designed to fit in the shell
of most computer mice, providing the entire platform in a
small package.
7) Autonomous Charging Capability: The LabRatTM design
includes a port for the connection of an external charging
circuit. The whiskers of LabRatTM are connected to ground,
providing a means for charging and detecting docking. By attaching a charging "tail" that drags on the operating surface, an
autonomous charging station and program can be constructed
that allows the robot to dock and charge itself.
8) Simulation Environment: The LabRatTM software libraries contain profiles for the open-source Player/Stage Simulation Environment, allowing students and developers to test
software designs without wasting batteries. The LabRatTM ap-

1009

Figure 5.

LabRatTM Modification February 2009

plication programming interface is designed to minimize the
amount of code changes needed to transfer between the
simulated software environment and the real-world hardware
platform.
IV. A PPLICATIONS
A. Education

Figure 3.

Figure 4.

Bottom of LabRatTM Board

LabRatsTM Delivered to Students Fall Semester 2008

The first use of LabRatTM was as an educational tool for the
Introduction to Robotics Class at the Missouri University of
Science and Technology. Students started out by programming
a simulated LabRatTM in Player/Stage. The simulation realistically portrayed the sensors and capabilities of LabRatTM so
that the students would be more familiar with the platform
when they received the robots later in the semester.
LabRatTM is a great platform for robotics students because
it supplements their education with inexpensive practical experience. LabRatTM can be used to teach simple concepts such
as two dimensional Proportional-Integral-Derivative (PID) motion control to keep the robot moving in a straight line at a
constant, controlled speed.
Once the students have mastered simple control they can
move on to more complicated projects, such as a maze solving
robot. A LabRatTM can be placed in a maze and be forced
to find its way through using just the infrared sensors and
whiskers. This can easily be simulated in an environment such
as Player/Stage so that students can prove that their algorithm
works before transitioning to the robot. This also gives students the opportunity to gain exposure to the complications of
moving between simulated and real environments.
Another LabratTM project that can easily be simulated is autonomous waypoint navigation. Since LabRatTM has position
sensors it can make an accurate estimate of its current location
and use that to find waypoints while avoiding obstacles with
its infrared sensors and whiskers.
LabRatTM also has the ability to teach the students about
swarm robotics methods. In order to keep the expense low for
students, the LabRatsTM can communicate with their infrared

1010

LEDs and photosensors so that one robot can act as a leader
and have the others follow in a formation.
In the first offering of the Introduction to Robotics course at
Missouri University of Science and Technology, students utilized the LabRatTM platform in a single semester to complete
many interesting and high-quality semester projects. A few of
these projects are outlined below.
1) Rotation Sensing : The LabRatTM optical sensor was
utilized in a machine-vision project attempting to discern
platform rotation from the image returned by the optical
sensor.
2) Wireless Control: This project utilized a modified
PlayStation game controller and two-way XBee communication to remotely control the physical operation of the
LabRatTM . On-board software was developed that temporarily
interrupts normal LabRatTM program execution and passes
control to a remote operator. When remote operation is complete, the on-board LabRatTM program execution resumes
where it was interrupted.
3) Autonomous Charging Dock : Students developed both
hardware and software to enable autonomous charging on the
LabRatTM . The developed hardware consisted of a charging
station and an IR blaster circuit that was used to signal the
location and direction of the charging station to the LabRatTM .
LabRatTM software included voltage sensing and autonomous
seeking of the charging beacon.
B. Research
Using the XBee (IEEE 802.15.4) radio and Gumstix
with LabRatTM makes it a versitile research platform.
The extra processing power and communications range give
LabRatsTM the ability to perform complex exploration and
searching tasks with several inexpensive robots. Using the
Gumstix, it is feasible to mount a small camera to a
LabRatTM and gather visual information in addition to proximity data about the environment.
The XBee radios allow LabRatTM to communicate over
great distances so that one LabRatTM can travel without
communication relays. Without the Gumstix, this can be a
great benefit as LabRatTM is perfectly capable of accomplishing searches such as particle swarm optimization using
the onboard AVR. Another interesting research project is to
autonomously communicate in an area with many radio obstacles such that LabRatsTM have to navigate to optimal coverage
areas and send messages from one location to another. Using
methods such as in [15], an individual LabRat’s position can
be determined based on known positions of other transmitters.
Without adding a XBee or Gumstix, LabRatTM can function
as an interesting platform for researching distributed behavior
in autonomous vehicles with limited communication ability.
The robots can relay information using their infrared LEDs
across an unknown environment. This has much shorter range,
but could be applicable for research that does not allow for
radio transmissions to be sent, such as within swarms of
autonomous underwater vehicles.

C. Hobby
The low price point allows hobbyists to purchase a
LabRatTM and use it for any interesting project they can imagine. The open source nature of the project allows hobbyists to
understand the inner workings of the robot and extend the
platform to meet their needs. Open source projects tend to be
attractive to hobbyists as they like a project that they can fully
understand and help create.
Using the LabRat’sTM optical sensor, hobbyists can implement simple line-following algorithms without requiring
additional hardware or sensors. Additional LEDs, speakers,
and other devices can be attached to the board and interfaced to
the microcontroller, for example to provide visual or auditory
feedback.
By attaching a XBee radio and a temperature sensor, a
hobbyist could use a LabRatTM as a mobile temperature sensor.
This could help the user by finding hot spots in an area with
sensitive equipment (such as a server room) or by checking
the temperature control in one floor of a building.
V. C ONCLUSION
TM

LabRat
is a small, open-source robot designed to be
ideal for students, researchers, and hobbyists. It has a low price
point so that it is affordable to all of these groups while still
being highly competitive in terms of features. A highly capable
robot, it can accomplish most tasks required in educational and
experimental use of autonomous ground robots.
More information about the LabRatTM can be found at
www.labratrobot.com.
ACKNOWLEDGMENTS
The authors would like to thank Paul Drews and Michael
Chrisco for their hard work contributing to the hardware and
software of LabRatTM . The authors would also like to thank
the Fall Semester 2008 Introduction to Robotics Class at the
Missouri University of Science and Technology for their help
in the LabRatTM development process.
R EFERENCES
[1] 3pi. http://www.pololu.com/catalog/product/747, Accessed February 28,
2009.
[2] Auvsi student competitions. http://www.auvsi.org/competitions/. Accessed Jan 29, 2009.
[3] Boe-bot.
http://www.parallax.com/Store/Robots/RollingRobots/tabid/128/CategoryID/3/List/0/SortField/0/Level/a/ProductID/296/Default.aspx, Accessed February 28, 2009.
[4] irobot
create.
http://store.irobot.com/product/index.jsp?productId=2591900, Accessed February 28, 2009.
[5] Legomindstorms nxt.
http://www.robotstore.com/store/product.asp?pid=1928&catid=1637, Accessed February 28, 2009.
[6] Picobotz.
http://www.robotstore.com/store/product.asp?pid=766&catid=1554, Accessed February 28, 2009.
[7] Pprk.
http://www.acroname.com/robotics/parts/R277PPRKBS2BLACK.html, Accessed February 28, 2009.
[8] Scribbler.
http://www.parallax.com/Store/Robots/RollingRobots/tabid/128/CategoryID/3/List/0/SortField/0/catpageindex/2/Level/a/ProductID/323/Default.aspx, Accessed February 28, 2009.
[9] Sumobot.
http://www.parallax.com/Store/Robots/RollingRobots/tabid/128/CategoryID/3/List/0/SortField/0/catpageindex/2/Level/a/ProductID/316/ Default.aspx, Accessed February 28, 2009.
[10] Sumovore. http://www.solarbotics.com/products/k_sv/, Accessed February 28, 2009.

1011

[11] The optical mouse for indoor mobile robot odometry measurement.
Sensors and Actuators A: Physical, 126(1):141 – 147, 2006.
[12] Carol Anderson. Student robotic challenges. Tech Directions, 60(3),
October 2000.
[13] The Joint Task Force for Computing Curricula 2005. Computing curricula 2005. http://www.acm.org/education/education/curric_vols/CC2005March06Final.pdf, Accessed January 28, 2009.
[14] David Livingston. A controller for robotics and microcontroller applications instruction. In 2007 ASEE Annual Conference and Exposition,
2007.
[15] D. Marinakis and G. Dudek. Probabilistic self localization for sensor
networks. In 2006 AAAI National Conference on Artificial Intelligence,
2006.
[16] G. T. McKee. The robotics body of knowledge (education). Robotics
and Automation Magazine, IEEE, 14(1):18–19, March 2007.
[17] Afsaneh Minaie and Reza Sanati. An international study of robotics
courses in the computer science/engineering curriculum. In 2006 ASEE
Annual Conference and Exposition, 2006.
[18] K Nagai. Learning while doing: practical robotics education. Robotics
and Automation Magazine, IEEE, 8(2):39–43, June 2001.
[19] Terri Varnado. Robotics across the curriculum. Tech Directions, 60(4),
November 2000.
[20] Richard Weiss and Isaac Overcast. Finding your bot-mate: Criteria
for evaluating robot kits for use in undergraduate computer science
education. Journal of Computing Sciences in Colleges, 24(2):43–49,
Dec 2008.
[21] Jason Yao, Gene Dixon, William Howard, Rick Williams, Keith
Williamson, Geoffrey Dieck, and Steve McLawhorn. "who is the biggest
pirate?" design, implementation, and result of a robotics competition for
general engineering freshman. In 2006 ASEE Annual Exposition and
Conference, 2006.

1012

Divide and Conquer Evolutionary TSP Solution for Vehicle Path
Planning
Ryan J. Meuth, and Donald C. Wunsch II

Abstract— The problem of robotic area coverage is
applicable to many domains, such as search, agriculture,
cleaning, and machine tooling. The robotic area coverage task
is concerned with moving a vehicle with an effector, or sensor,
through the task space such that the sensor passes over every
point in the space. For covering complex areas, back and forth
paths are inadequate. This paper presents a real-time path
planning architecture consisting of layers of a clustering method
to divide and conquer the problem combined with a twolayered, global and local optimization method. This architecture
is able to optimize the execution of a series of waypoints for a
restricted mobility vehicle, a fixed wing airplane.
I.

INTRODUCTION

F

or large continuous tasks, such as area coverage, it is
desirable to decompose the problem space to reduce the
complexity of the problem. Several methods have been
devised to accomplish this, including grid division methods
of various geometries, and Voronoi divisions [1]. These
methods work well for uniform environments and simple
sensing apparatus’, but they often do not account for the
intersection of the agent’s sensor with the environment.
Introducing environmental effects and sensor characteristics
increases the complexity of area coverage
A vehicle assigned to search area coverage must plan an
optimal path through the allocated search space. This
optimal path is considered as the shortest route through the
set of points that allows the vehicle’s sensing apparatus to
visit all points in the search space. The path between these
points can be optimized using many different algorithms,
including graph search, and TSP solution methods. At this
level, the vehicle dynamics, vehicle sensing characteristics,
and environmental effects can all be included to affect the
optimal solution. With the inclusion of vehicle dynamics, the
true value of a path is not only dependant on the distance
between its points, but also the vehicle capabilities and
characteristics of the vehicle’s control system.
The traveling salesman problem is focused on finding the
shortest tour through a fixed set of points. This has been
Manuscript received October 9, 2007. This work was supported in part
by The Boeing Company.
Ryan Meuth is with the Applied Computational Intelligence Laboratory,
Missouri University of Science and Technology, Rolla, MO, 65401 USA
(e-mail: rmeuth@mst.edu).
Donald C. Wunsch II is with the Department of Electrical and Computer
Engineering at the Missouri University of Science and Technology, Rolla,
MO, 65401, USA. (e-mail: dwunsch@mst.edu).

deeply researched in literature, as efficient solutions have
wide ranging applications in domains such as vehicle routing
and job-scheduling. As an NP-hard problem, it is extremely
difficult to solve large instances of the TSP exactly, so
heuristic methods must be used. One of the most powerful
heuristic algorithms is the Lin-Kernighan method, which is
an iterative method that begins with a random tour, and
performs pair-wise optimization by steps to arrive at local
minima, and then repeats with a new random tour, always
saving the best tour encountered [2]. While not an exact
method, it has been shown that the method can find near
optimal solutions in a reasonable amount of time.
Supplemented by an intersection removal step, as found in
the chained LK method, the performance and quality of the
LK algorithm is increased.
Unfortunately, the time
complexity of this algorithm is still unsuitable for real-time
operation under problem sets larger than a few thousand
points [3].
It has been shown that the time complexity of the LK method
can be somewhat linearized at the cost of optimality by first
clustering the point set, using the LK method to find a subtour, then merging the cluster sub-tours into a final tour [46]. The operation of the algorithm becomes very fast, in
exchange for a reasonable drop in tour quality.
The LK method has also been supplemented by genetic
algorithms that perform a global search, while the LK
method performs a local search. By evolving initial tours
instead of randomly generating them, the global search
becomes more directed, and is able to converge on higher
quality tours faster. This topic of research is still young, and
much work remains [7, 8].
Including the vehicle dynamics adds computational
complexity to any algorithm, so a new TSP solution method,
Clustered Evolutionary Lin-Kernighan or CELK, is
presented as a method to bring TSP solution into the realtime domain.
Given a region to be searched and an agent with associated
characteristics and capabilities, the task of planning a path
through the region is extremely complex if all points in the
region are to be considered as part of a possible coverage
path for an agent. In light of this, many methods have been
developed for dividing the search space based on the agent’s
sensing characteristics to provide a set of points that, if all
points in the set are included in the agent’s final path,

676
c
978-1-4244-1823-7/08/$25.002008
IEEE

guarantee that complete coverage is achieved [9, 10]. This
set of points can then be used as an instance of the Traveling
Salesmen Problem to find a tour through all points, thus
covering the search space.
II. THE CLUSTERED EVOLUTIONARY LK ALGORITHM
Once a complete coverage point set has been constructed, the
problem becomes one of finding the shortest tour through the
set of points, which is an instance of the Traveling Salesman
Problem, or TSP.
A three-tiered method has been developed, combining
clustering, genetic algorithms, and the LK method to find
good quality tours with a near linear time complexity. Given
a point set, the set is clustered, by way of the Adaptive
Resonance Theory method, into a maximum of M clusters,
where M is chosen to be the number of points in the set
divided by a fixed scalar, in order to maintain an average
cluster size[11]. Sub-tours are then planned within each
cluster, using a genetic algorithm-based LK method, called
Evolutionary Lin-Kernighan, or ELK. This algorithm is used
to recoup some of the tour quality lost through clustering,
and analysis has shown that there is also a speed benefit to
using the algorithm. Once sub-tours are found, they are
merged back into a final tour using the method described in
[4].
Utilizing the clustering method to maintain an average
cluster size keeps the time complexity of each instance of the
ELK method constant, giving the overall algorithm a linear
time complexity, while maintaining good tour quality. Also,
it allows for many levels of parallelism, as each sub-tour can
be computed individually, and each trial tour within the subtour optimization can also be optimized independently.
In order to improve the ratio of tour quality to computational
expense, an Evolutionary Lin-Kernighan method was
developed. This method uses a genetic algorithm to generate
trial tours, which are then optimized to local minima using
the LK method. This scheme is not a new idea, and the
development of useful genetic operators under similar
architectures has been explored [12].
The ELK algorithm begins by generating P random
individuals, where each individual is a trial tour. Each
individual is then evaluated, which consists of applying the
LK algorithm with intersection removal until a local
minimum is achieved, and the total tour length is assigned to
the individual’s fitness. Roulette-wheel parent selection is
then used to generate P children, where the probability of
individuals being selected as parents is proportional to their
rank in the population. Reproduction is achieved through
Cost Preserving Crossover and a Mutation Operator. The
cost preserving operator has been shown to have good
performance at low computational expense [reference for
recombination operators].

A fixed number of ‘Strangers’ or random individuals are
introduced to the population at each generation. The new
individuals are evaluated, and Roulette-wheel survival is
used to keep P individuals with an individual’s probability of
survival being proportional to their rank in the population.
This process is repeated until an evaluation limit is exceeded.
Mutation is achieved by swapping edges with probability
PgMut .
III. ALGORITHM RESULTS
The tour quality of the ELK algorithm was compared to that
of the LK algorithm alone, over 100 randomly generated
points, averaged over 30 runs, each run consisting of 1000
evaluations. As can be seen in Fig. 1, the amount of tour
improvement per evaluation is significantly greater using the
ELK algorithm.
Additionally, trial tours generated by the ELK algorithm
were evaluated significantly faster, as LK needed to make
fewer changes due to pre-optimized sections of their tours
being inherited from the previous generation. To study this
effect, the two algorithms were compared by executing them
for 1000 path evaluations on randomly generated tours of
varying length. An average was taken over 11 runs for each
tour length. The number of optimization iterations per path
was recorded, as well as execution times for each run. Fig. 2
shows the average execution times of the methods on various
tour sizes. Fig. 3 shows the average number of optimization
iterations performed on each tour size under the two
algorithms.
Fig. 4 shows the average optimizations
performed on each trial path under the two algorithms.
These Fig.s show that the ELK method has a significant
quality and performance advantage over the LK method
alone. Fig. 1 shows that the ELK method produces higher
quality paths in fewer iterations. Fig. 2 shows the LK and
ELK algorithms operating on Tours of increasing length,
showing that the ELK algorithm has increasing benefits with
path size. Fig. 3 shows the average optimization iterations
necessary to converge to a local minimum for increasing tour
sizes under the LK and ELK algorithms. Note that the LK
method increases iterations with tour size, while the ELK
method holds relatively constant.
Fig.s 4 and 5 show the number of optimization iterations that
were executed on each path evaluated. For the LK
algorithm, this is relatively constant, as each path is
randomly generated. The ELK algorithm starts high at
values corresponding to the LK method, and then reduces
sharply, slowly decreasing as a global search is performed.

2008 IEEE Congress on Evolutionary Computation (CEC 2008)

677

LK, ELK Algorithm Performance (100 Pts, 30 Runs)

LK Optimization Iterations Per Path

4900

8

4700

7

Optimization Iterations

4800

Avg LK
Avg ELK

4500

4

Log. (Avg LK)
Log. (Avg ELK)

4400
y = -72.173Ln(x) + 4724.2

4300

5

3
2

4200

1

4100

960

900

840

780

720

660

600

540

480

Path Evaluation

Iteration

Fig. 1 - LK vs. ELK Tour Quality.

420

1000

360

800

300

600

240

400

60

200

1

0

180

0

y = -109.24Ln(x) + 4815.5

4000

120

Path Value

LK
50
LK
100
LK
150
LK
200
LK
250

6

4600

Fig. 4 - LK Optimization Iterations.

LK vs. ELK Performance Times
ELK Optimization Iterations Per Path Evaluation

1000
900
7

700
LK Avg. Time

500

ELK Avg. Time

400
300
200
100
0
250

300

ELK 150
ELK 200

3

ELK 250
ELK 300

2
1

Tour Size

1000

950

900

850

800

750

700

650

600

550

500

450

400

350

1

Fig. 2 - Performance Times of LK vs. ELK.

300

0

250

200

ELK 100

200

150

ELK 50

4

150

100

5

100

50

Optimization Iterations

6

600

50

Optimization Time (s)

800

Path Evaluation

Fig. 5 - ELK Optimization Iterations.
Average Optimization Iterations vs. Tour Size

Clustering the point sets and performing optimization on
sub-tours, then merging the sub-tours into a final tour has
been shown to linearize the run-time complexity of the ELK
method, as shown in Fig. 6.

7

5
4

LK

Compute Time vs. Path Size

ELK

3

8000
2
1
0
50

100

150

200

250

300

Tour size

Fig. 3 - LK vs. ELK Average Optimization Iterations.

Compute Time (seconds)

Optimization Iterations

6

7000
6000
5000
Clustering

4000

No Clustering

3000
2000
1000
0
0

2000

4000

6000

8000

10000 12000

14000

Path Size (points)

Fig. 6 - Time Performance of Clustered ELK and ELK on
Various Path Sizes.
IV. TSP FOR PHYSICAL VEHICLES
When planning for real-world vehicles, it may be desirable
to substitute the Euclidean distance objective function for a
cost function that models the mobility of the vehicle. In this
way the total behavior of the vehicle can be optimized.

678

2008 IEEE Congress on Evolutionary Computation (CEC 2008)

Since the LK method is the underlying algorithm, only
metrics should be used as the objective function [2]. As
such, we must show that any valid objective function has the
properties of symmetry, positivity, reflexivity and triangle
inequality.

To adapt the vehicle heuristic to the LK optimization
method, the set of possible edges becomes all combinations
of three points in the problem set. In this way the algorithm
can be directly applied to this instance of the TSP.
V. PHYSICAL VEHICLE HEURISTIC RESULTS

For heterogeneous vehicles, a simple heuristic metric is
proposed, estimating the time to cross the edge, given in
equation 1.
The guidance speed is a positive scalar
representing the average % of the vehicle’s maximum
velocity that the vehicle travels under guidance. The agility
of the vehicle is also a positive scalar, representing a
measure of the ability of the vehicles’ guidance system to
execute turns without incurring extra time, as compared to a
straight path.
The use of this heuristic allows the
optimization of the path based on the vehicle’s kinematics.

t ( ei ) =

§ c g v max
d ( a ei , bei )
+c a ¨¨
c g v max
© a

·
¸¸ 1 − cos(θ aei ,bei ,cei )
¹

(

Fig. 8 shows the optimized path on a triangular grid of points
using only Euclidean distance. Fig. 9 shows the optimized
path on the same grid using the physical vehicle cost
heuristic detailed in equation 1. Note the resulting straight
path sections, which minimizes the coverage time for those
point sequences through the conservation of momentum.

)

Equation 1. – Physical vehicle heuristic.
Given a possible edge ei, consisting of three points, aei, bei,
and cei .
Where
• d(a,b) is the Euclidean distance between points a, b.
• vmax is the maximum vehicle speed.
• a is the vehicles acceleration capability
• șa,b,c is the angle between points a, b and c.
• cg is a scalar representing the guidance speed.
• ca is a scalar representing the vehicle agility.

Fig. 8 - Optimized path using Euclidean Distance.

This heuristic has the property that the degenerate case of the
heuristic simplifies to Euclidean distance. Also, symmetry,
positivity and reflexivity properties are trivial to
demonstrate. However, the property of triangle inequality
should be shown.
The distance component dominates the physical vehicle
heuristic equation and since the angle between edges only
adds time, the triangle inequality holds.

Fig. 9 - Optimized Path using a Physical Vehicle Heuristic.
Fig. 7 – The triangle inequality holds for 3-edges.

To evaluate the effectiveness of the vehicle mobility
heuristic, a simulation was developed to model the behavior
of a fixed wing air vehicle. The mobility of such vehicles

2008 IEEE Congress on Evolutionary Computation (CEC 2008)

679

are well known and easy to model. The path planning
algorithm was tested over 30 runs each over the same
environment using the vehicle heuristic and Euclidean
distance as the cost. The results are shown in the table below.

t-Test: Two-Sample Assuming Equal Variances
Euclid.

3207.889

3400.667

Mean

Time

Time

Variance

3761.861

2273.25

3104

3381

Observations

9

9

3158

3323
3408

4

3179

3388

Pooled Variance
Hypothesized Mean
Difference

3017.556

3293

0

5

3209

3390

df

16

t Stat

-7.4445

6

3167

3396

P(T<=t) one-tail

6.96E-07

7

3223

3492

t Critical one-tail

1.745884

8

3106

3402

P(T<=t) two-tail

1.39E-06

9

3265

3362

10

3271

3445

PVH

1
2
3

Mean
3197.5
3398.7
Table 1. Time to complete for two cost structures over 10
runs, physical vehicle heuristic and Euclidean distance.

Mean

t Critical two-tail
2.119905
Table 3. t-Test assuming equal variances showing that the
samples are significantly different at Į=0.05

VII. REFERENCES
[1]

F-Test Two-Sample for Variances
PVH

Euclid.

3207.889

3400.667

Variance

3761.861

2273.25

Observations

9

9

df

8

8

F

1.654838

P(F<=f) one-tail

0.246041

[2]

[3]

[4]

F Critical one-tail
3.438101
Table 2. F-Test showing Equal Variance at Į=0.05
The results show that optimization utilizing the mobility
characteristics is able to significantly improve the time of
completion for a mobility-restricted vehicle.
The
environmental and mobility characteristics of the vehicle
greatly determine the time to complete, so there is great
potential to optimize the path using this cost method.

[5]

[6]

VI. CONCLUSION
For scenarios where a mobility limited vehicle must plan an
efficient path through a large, complex environment in realtime, traditional path planning methods are inadequate. A
three component path planning architecture, combining
divide and conquer, local and global optimization methods.
It has been shown that this architecture has the advantage of
both speed and accuracy, being able to plan an efficient path
for a mobility restricted vehicle in real-time.

680

PVH
Euclidean

Run

[7]

[8]

K. Nagatani and H. Choset, "Toward robust sensor
based exploration by constructing reduced
generalized Voronoi graph," in Intelligent Robots
and Systems, 1999, pp. 1687 - 1692.
S. Lin and B. W. Kernighan, "An Effective
Heuristic Algorithm for the Traveling Salesman
Problem," Operations Research, vol. 21, pp. 498516, March-April 1973 1973.
D. Applegate, W. Cook, and A. Rohe, "Chained
Lin-Kernighan for Large Traveling Salesman
Problems," 2000.
S. Mulder and D. C. Wunsch, "Million City
Traveling Salesman Problem Solution by Divide
and Conquer Clustering with Adaptive Resonance
Neural Networks," Neural Networks, July 2003.
D. C. Wunsch and S. Mulder, "Using Adaptive
Resonance Theory and Local optimization to divide
and conquer large scale traveling salesman
problems," in International Joint Conference on
Neural Networks, 2003, pp. 1408-1411.
D. C. Wunsch and S. Mulder, "Evolutionary
Algorithms, Markov Decision Processes, Adaptive
Critic Designs, and Clustering: Commonalities,
Hybridization and Performance," in International
Conference on Intelligent Sensing and Information
Processing, 2004, pp. 477-482.
H.-K. Tsai, J.-M. Yang, and C.-Y. Kao, "Solving
traveling salesman problems by combining global
and local search mechanisms," in Conference on
Evolutionary Computation, 2002, pp. 12-17.
H.-K. Tsai, J.-M. Yang, and C.-Y. Kao, "An
evolutionary algorithm for large traveling salesman

2008 IEEE Congress on Evolutionary Computation (CEC 2008)

[9]

[10]

[11]

[12]

problems," IEEE Transactions on Systems, Man
and Cybernetics Part B, vol. 34, pp. 1718-1729,
August 2004.
E. Gonzalez, A. Suarez, C. Moreno, and F. Artigue,
"Complementary regions: a surface filling
algorithm," in Robotics and Automation, 1996.
Proceedings., 1996 IEEE International Conference
on, 1996, pp. 909-914 vol.1.
R. N. De Carvalho, H. A. Vidal, P. Vieira, and M. I.
Ribeiro, "Complete coverage path planning and
guidance for cleaning robots," in Industrial
Electronics, 1997. ISIE '97., Proceedings of the
IEEE International Symposium on, 1997, pp. 677682 vol.2.
G. A. Carpenter, S. Grossberg, and D. B. Rosen,
"ART 2-A: An adaptive resonance algorithm for
rapid category learning and recognition," Neural
Networks, pp. 493-504.
P. Merz and B. Freisleben, "Genetic Local Search
for the TSP: new results," in IEEE Conference on
Evoluationary Computation, 1997, pp. 159-164.

2008 IEEE Congress on Evolutionary Computation (CEC 2008)

681

22nd IEEE International Symposium on Intelligent Control
Part of IEEE Multi-conference on Systems and Control
Singapore, 1-3 October 2007

TuC08.1

A SURVEY OF NEURAL COMPUTATION ON GRAPHICS PROCESSING HARDWARE
Ryan J. Meuth, Donald C. Wunsch II
University of Missouri- Rolla
Dept. of Electrical & Computer Engineering
1870 Miner Circle,
Rolla, MO, 65401
Abstract - Modern graphics processing units (GPU) are used
for much more than simply 3D graphics applications. From
machine vision to finite element analysis, GPU’s are being
used in diverse applications, collectively called General
Purpose Graphics Processor Utilization. This paper explores
the capabilities and limitations of modern GPU’s and surveys
the neural computation technologies that have been applied
to these devices.
I. INTRODUCTION
In recent years consumer graphics processing units have
experienced significant increases in performance, driven
by increasingly realistic game simulations and popular
multimedia demands. As a result, the graphics industry
has leveraged a parallel processing model to provide a
doubling of graphics computing capability every six
months, as opposed to the 18 month doubling rate general
computing processors, a trend that is illustrated in Figure
1. As these graphics processors become more capable and
flexible, they have become desirable platforms for general
computation.
Owens [1] provides a comprehensive
overview of the industry of general purpose computation
on GPU’s. However, Owens neglects to mention neural
network applications on graphics processing units. Here,
we provide an overview of these techniques, with
associated challenges and limitations.

Fig 1. The exponential increase in performance of graphics processing
units compared to the performance of Intel processors over the last 4
years. Figure Courtesy of Owens [1].

Figure 2 shows an overview of the graphics processing
pipeline. On the host system side, the application
generates a data structure to be rendered, consisting of a
set of verticies and their corresponding colors that define a
polygon.
Manuscript received January 30, 2007. This work was supported in part
by The Boeing Company, M. K. Finley Endowment, and the National
Science Foundation.
Ryan Meuth is with the Department of Electrical and Computer
Engineering at the University of Missouri – Rolla, Rolla MO, 65401,
USA. (phone: 573-341-4521; e-mail: rmeuth@umr.edu).
Donald C. Wunsch II is with the Department of Electrical and Computer
Engineering at the University of Missouri Rolla, Rolla, MO, 65401,
USA. (e-mail: dwunsch@umr.edu).

1-4244-0441-X/07/$20.00 ©2007 IEEE.

Fig 2. The graphics processing pipeline. Modern GPU’s combine the
vertex and fragment processor into a unified shader unit that is able to
perform either of these functions. Currently, GPU’s can include up to
128 unified shader units. Figure Courtesy of Goodnight [2].

524

TuC08.1

This data structure is passed to the vertex processor, which
is the first programmable unit in the graphics pipeline,
which typically applies transformations to the vertices.
The rasterizer then maps these coordinates to pixel
locations, generating a set of fragments. These fragments
are then passed to the fragment processor, the second
programmable unit in the pipeline.
The Fragment
processor determines which fragments are to be drawn to
the frame buffer, and then fills pixels with color
information based on a program called a shader. Shader
programs allow complex lighting and texture information
to be mapped onto pixels. The frame buffer holds the
completed image for output to a display.
To maintain high frame rates under increasingly
graphically intensive applications the vertex and fragment
processors have been implemented as a single-instruction,
multiple-data parallel processing architecture. Modern
graphics processors combine vertex and fragment
processors into a generalized unified shader unit. At this
writing, GPU’s can include up to 128 unified shader units,
operating at up to 1.3Ghz. As the entire pipeline is based
on the 32-bit floating point data type, this yields a
significant processing capability on the order of hundreds
of GFLOPS in a single desktop frame. Additionally, bus
enhancements now allow multiple graphics cards to work
together in the same system [3].
For general purpose computing, the GPU architecture
lends itself well to applications where the same
calculations are repeatedly performed on large blocks of
data [4]. In this way, particle systems, finite element
analysis, image processing, and other numerical
computation are well suited to utilize the GPU. However,
the shader units of GPU’s do not yet include efficient
branching hardware, so algorithms utilizing datadependant operations are difficult to implement
effectively. Also, the data bus that hosts the GPU is often
inefficient for small data transfers, so to achieve a
reasonable speedup data must be operated on in batches
[5]. Many of these difficulties have been overcome by
creative algorithm design and implementation on the target
systems. The widespread availability of these devices has
allowed inexpensive high performance computing
environments to be constructed that leverage both CPU
and GPU capability to create a ‘cluster of clusters’ [6].

II. GAME CONSOLES
Driven by increasingly complex video games and graphics
as well as new entertainment media demands such as
internet, digital photography and video playback,
consumer video game consoles have become powerful
general purpose machines. At the same time, these
systems must be brought to the public at an affordable
price point. Figure 3 compares the ratio of Floating Point
Operations per Second (FLOPS) per dollar of several
game consoles and Intel Pentium based systems. Here we
can see that the cost-effectiveness of the latest generation
of game consoles is an order of magnitude higher than that
of any Intel-based system. These features make gaming
consoles a highly desirable platform for inexpensive high
performance computing systems.
Though the performance per dollar ratio of these systems
is attractive, they are not without limitations, most notably
in their interconnect ability. Only the last two generations
of consoles have included networking capabilities, and
then only one port is provided, limiting the efficiency of
interconnects architectures in console-based clusters.
Until the latest generation of game consoles, the
technology embedded in these products have often lagged
behind the capability of personal computers at the time of
release. However, the selling price of these devices makes
them very competitive. In the previous generation of
game consoles, this was recognized, and several attempts
were made to utilize inexpensive game consoles as nodes
in a super computing cluster. Very little success was made
with the original Xbox [7], but researchers at the
University of Illinois – Urbana Champaign succeeded in
developing a 65-node computing cluster based off of the
popular Playstation 2 video game console. This cluster
was used for chemical simulations, and with a price point
of $15,000 for the entire cluster, the system provided a
high level of performance per dollar [8].

GPU shader programs are written in a language similar to
assembly, and can be developed through a graphics
programming interface, such as OpenGL or DirectX.
High-level languages such as Brook, Sh, and RapidMind
allow developers to use C-based languages to write shader
programs, providing data abstraction and useful functions,
reducing the learning curve of these devices.

525

TuC08.1

is to be built for the Department of Energy at Los Alamos
National Laboratory in New Mexico. [12]

FLOPS/Dollar
4.50E+08
4.00E+08
3.50E+08
3.00E+08
2.50E+08
2.00E+08
1.50E+08
1.00E+08
5.00E+07
0.00E+00
PS3

Xbox 360

Pentium 4
Dual

PS2

Pentium 4

Xbox

Pentium 4
Quad

Pentium 3

II. UNSUPERVISED LEARNING

Fig. 3. Shows the FLOPS per dollar ratio of the past two generations of
game consoles and Intel Processor-based systems. We can see that the
latest generation of game consoles is several orders of magnitude more
cost efficient than the latest Pentium-based systems.

The latest generation of game consoles differs from the
former in that Microsoft’s Xbox 360 and Sony’s
Playstation 3 both include new technologies that greatly
surpass what is available in the home PC market. The
Xbox 360 includes a tri-core Power PC processor
operating at 3.2Ghz, theoretically providing a peak
processing capability of 115.2 GFLOPS. The Xbox 360
surpasses PC-based computing capability by an order of
magnitude, at a quarter of the cost [9]. Additionally, the
Playstation 3 is capable of 205 GFLOPS provided by a
nine-core processor called the Cell Broadband Engine
cooperatively developed by Sony, IBM and Toshiba. The
Cell consists of a single Power PC (PPE) based processor
that manages 8 Synergistic Processing Elements (SPE)
connected by an extremely high speed interconnect bus
and shared memory. The PPE controls the SPEs like a
cluster master node, implementing job queue, shared
memory, and bus management. The Cell is unique in that
the device is capable of managing 8 independent threads at
full processor speed, with full branching and floating point
operations available on each SPE [10, 11].
The Cell is also interesting in that it can be programmed
using existing tools for graphics processing units, making
much existing GPGPU work directly portable to these
platforms.
Currently, no projects have been undertaken to develop
high performance computing clusters based on the current
generation game consoles. However, IBM will be using
the Cell Processor in its next generation super computer,
codenamed “RoadRunner.” The machine will consist of
16,000 AMD Opteron cores matched with 16,000 Cell
Broadband Engines, collectively rated at over 1 petaFLOP/s. This will make it the most powerful super
computer in the world by several orders of magnitude. It

The repetitive operations of self-similar data clustering
methods have allowed many of these algorithms to be
ported to the GPU, but the iterative and data-dependant
nature of the algorithms have prevented large performance
gains. Bohn implements Kohonen feature maps on GPU
hardware. Even in ’98 performance was improved by 5
times on large data sets using the GPU’s of the time [13].
Hall uses a combination of the GPU and CPU to
implement K-means clustering, using the GPU to perform
distance computations and the CPU to perform template
updates. Using this method, Hall was able to triple the
performance of the algorithm over the CPU alone [14].
Similarly, Harris implements the Fuzzy C-Means
algorithm, doubling its performance [15].
III. SUPERVISED NEURAL NETWORKS
Artificial neural networks attempt to capture the
adaptability of biological neurons in a mathematical model
for information processing. ANNs are very powerful tools
that are highly parallelizable but also computationally
expensive and match well with the GPU computing
architecture. As a workhorse of the computational
intelligence field, there exists a high demand for this
acceleration. As a highly analytic structure, neural
networks can be reduced to a series of matrix operations,
and thus are easily parallelized, as the GPU is highly
optimized to perform these kinds of operations.
Zhongwen achieves a massive 200 times increase in
performance of a multilayer perceptron implemented on
graphics hardware over a typical CPU, enabling real-time
soccer ball tracking on commodity hardware. Zhongwen
uses the GPU to first extract a set of characteristics from
image data, then applies a pre-trained MLP to these
characteristics for classification. Zhongwen also provides
several tips for ensuring efficient implementation of
algorithms on GPU’s. These tips include minimizing the
pass count (or number of times a program must be applied
to data), and minimizing data transfers between CPU and
GPU sides [16].
Bernhard takes a different approach, implementing
spiking neural networks for image segmentation, which
achieves up to a 20 times increase in performance.
Bernhard utilized a special counter on the GPU called the
Occlusion Query, which tracks how many times a memory
location has been modified by a shader program. Using
this counter, he was able to efficiently compile the
activations of neurons in a spiking neural network [17].

526

TuC08.1

IV. CONCLUSIONS
It can be easily seen from this review that significant
performance gains can be elicited from implementing
neural network algorithms on graphics processing units.
However, there is an amount of art to these
implementations. In some cases the performance gains
can be as high at 200 times, but as low as 2 times or
actually less than CPU operation. Thus it is necessary to
understand the limitations of the graphics processing
hardware, and to take these limitations into account when
developing algorithms targeted at the GPU. It should also
be noted that all the reviewed papers in this document
were operating on last-generation hardware. As of the end
of 2006, the next generation graphics hardware has been
released, which include an order of magnitude more
shader units per processor, as well as improved branching
capabilities. One can envision the possible capability of
256 programmable shader units working in parallel at 1.3
GHz each, in a single desktop box. Unfortunately none of
the previous work has analyzed the performance of their
algorithms relative to the number of computational units
involved, which makes it uncertain exactly how new
hardware will effect the performance of these algorithms.
Additionally, efficient implementations of several neural
network techniques have yet to be realized, including
Adaptive Resonance Theory, making this an open and
exciting area of research.
ACKNOWLEDGMENT
The authors are grateful to Rui Xu for helpful discussions.
REFERENCES

[8] “65 Node PS2 Linux Cluster,”
http://arrakis.ncsa.uiuc.edu/ps2/cluster.php accessed January 19, 2007.
University of Illinois, Urbana-Champaign.
[9] “Comparison of Seventh Generation Game Consoles”,
www.wikipedia.com,
http://en.wikipedia.org/wiki/Comparison_of_seventhgeneration_game_consoles, Retrieved January 19, 2007.
[9] Pham D., Asano S., Bolliger M., Day M. N., Hofstee H. P., Johns
C., Kahle J., Kameyama., Keaty J., Masubichi Y., Riley M., Shippy D.,
Stasiak D., Wang M., Warnock J., Weitzel S., Wendel D., Yamazaki T.,
Yazawa K.: “The design and implementation of a first-generation CELL
processor.” Proceedings of the International Solid-State Circuits
Conference (Feb. 2005), pp. 184–186.
[10] Brown, Jeffry (2005-12-06). “Application-customized CPU
design.” IBM. http://www128.ibm.com/developerworks/power/library/pa-fpfxbox/?ca=dgrlnxw07XBoxDesign Retrieved on 2006-09-30.
[11] "Introduction to the Cell multiprocessor", IBM Journal of Research
and Development,
http://researchweb.watson.ibm.com/journal/rd/494/kahle.html,
September 7, 2005.
[12] “IBM to Build World's First Cell Broadband Engine Based
Supercomputer.” IBM http://www03.ibm.com/press/us/en/pressrelease/20210.wss (2006-09-06). Retrieved
on 2006-09-11.
[13] Bohn C.A.: “Kohonen feature mapping through graphics
hardware.” In Proceedings of the Joint Conference on Information
Sciences (1998), vol. II, pp. 64–67.
[14] Jesse D. Hall, John C. Hart: “GPU Acceleration of Iterative
Clustering” Manuscript accompanying poster at GP^2: The ACM
Workshop on General Purpose Computing on Graphics Processors,
and SIGGRAPH 2004 poster, Aug. 2004
[15] Harris, C.; Haines, K.; “Iterative Solutions using Programmable
Graphics Processing Units.” The 14th IEEE International Conference
on Fuzzy Systems, 2005. FUZZ '05. May 22-25, 2005 Page(s):12 – 18
[16] Zhongwen Luo; Hongzhi Liu; Xincai Wu: “Artificial neural
network computation on graphic process units,” IEEE International
Joint Conference on Neural Networks, 2005. IJCNN '05. Proceedings.
Volume 1, 31 July-4 Aug. 2005 Page(s):622 - 626 vol. 1
[17] F. Bernhard and R. Keriven. “Spiking neurons on GPUs.” In
International Conference on Computational Science. Workshop
General purpose computation on graphics hardware (GPGPU):
Methods, algorithms and applications, Reading, UK, May 2006.

[1] John D. Owens, David Luebke, Naga Govindaraju, Mark Harris,
Jens Krüger, Aaron E. Lefohn, Timothy, “A Survey of General-Purpose
Computation on Graphics Hardware,” J. Purcell Computer Graphics
Forum, Volume 26
[2] Goodnight, N., Wang, R., Humphreys, G., “Computation on
programmable graphics hardware” IEEE Computer Graphics and
Applications, Volume 25, Issue 5, Sept.-Oct. 2005 Page(s):12 – 15
[3] “GeForce 8800 specifications,”
http://www.nvidia.com/page/geforce_8800.html, accessed November 9,
2006.
[4] Ekman M., Warg F., Nilsson J., “An in-depth look at computer
performance growth.” ACM SIGARCH Computer Architecture News 33,
1 (Mar. 2005), 144–147.
[5] Trancoso, P.; Charalambous, M.; “Exploring graphics processor
performance for general purpose applications” 8th Euromicro
Conference on Digital System Design, 2005. Proceedings. 30 Aug.-3
Sept. 2005 Page(s):306 – 313
[6] Zhe Fan; Feng Qiu; Kaufman, A.; Yoakum-Stover, S. “GPU Cluster
for High Performance Computing Supercomputing,” Proceedings of the
ACM/IEEE SC2004 Conference 2004 Page(s):47 – 47
[7] “12 Node Xbox Linux Cluster,”
http://www.xl-cluster.org/index.php accessed January 19, 2007.

527

Meta-Learning Genetic Programming
Ryan J. Meuth
University of Advancing Technology
2625 W Baseline Rd.
Tempe, AZ, 85283
1-(636)-578-4171

rmeuth@ieee.org
and gained through human experience.
This random
initialization property is useful for comparing different
computational intelligence methods and in some cases,
particularly when computation time is not an issue, is desirable as
it allows the search to be more focused, thus leading to solutions
that would not otherwise have been found efficiently. It is also
worth noting that many real-world problem domains are
composed of sub-problems that can be solved individually, and
combined (often in a non-trivial way) to provide a solution for the
larger problem [1, 2].

ABSTRACT
In computational intelligence, the term ‘memetic algorithm’ has
come to be associated with the algorithmic pairing of a global
search method with a local search method. In a sociological
context, a ‘meme’ has been loosely defined as a unit of cultural
information, the social analog of genes for individuals. Both of
these definitions are inadequate, as ‘memetic algorithm’ is too
specific, and ultimately a misnomer, as much as a ‘meme’ is
defined too generally to be of scientific use. In this paper, we
extend the notion of memes from a computational viewpoint and
explore the purpose, definitions, design guidelines and
architecture for effective memetic computing. Utilizing two
genetic programming test-beds (the even-parity problem and the
Pac-Man video game), we demonstrate the power of high-order
meme-based learning, known as meta-learning. With applications
ranging from cognitive science to machine learning, metalearning has the potential to provide much-needed stimulation to
the field of computational intelligence by providing a framework
for higher order learning.

In some problem instances, such as large instances of the even
parity problem, it is nearly impossible to stochastically arrive at a
complete solution without utilizing generalized solutions for small
instances of the problem [3]. It is simple to evolve a function that
performs even parity on 2 bits using only the logical functions
AND, OR and NOT as primitives, but extremely difficult to
evolve a 10-bit even parity function without any a priori
information as the space of all possible solutions is immensely
larger, and even the best known solution is complex. By simply
defining the general 2-bit XOR function (the even parity
computation for 2 bits), the optimization method has a higher
probability of combining instances of XOR to arrive at an n-bit
even-parity function, greatly accelerating the optimization
process.

Categories and Subject Descriptors
I.2.2 [Artificial Intelligence]: Automatic Programming –
program synthesis, program verification.

Both Darwinian evolution and memetics have been sources of
inspiration for classes of algorithms for problem-solving
techniques with memetic algorithms being the most prominent
and direct manifestation of the inspiration. In recent years, there
has been a marked increase in research interests and activities in
the field of Memetic Algorithms (MA). The first generation of
MA refers to hybrid algorithms, the combination of populationbased global search (often in the form of an evolutionary
algorithm) with a cultural evolutionary stage. The first generation
of MA, though it encompasses characteristics of cultural
evolution (in the form of local refinement) in the search cycle,
may not qualify as a true evolving system according to Universal
Darwinism, since all the core principles of inheritance/memetic
transmission, variation and selection are missing [4, 5]. This
suggests why the term MA stirred up criticisms and controversies
among researchers when first introduced [6].

General Terms
Algorithms, Design, Theory.

Keywords
Genetic Programming, even parity, pac-man, meta-learning,
memetic algorithms, late breaking abstract.

1. INTRODUCTION
One of the major drawbacks of evolutionary algorithms and
computational intelligence methods in general is that the solvers
employed usually start from zero information, or utilize random
initial states, independent of how similar the problem instance is
to other instances the method has been applied to in the past. In
effect, the optimization methods typically do not incorporate any
mechanisms to establish inter-instance memory.

2. META-LEARNING GENETIC
PROGRAMMING

In effect, the optimization methods typically do not incorporate
any mechanisms to establish inter-instance memory. Parameter
recommendations
and
user-seeded
known-good initial
evolutionary algorithm populations provide some inter-instance
information, though this knowledge is provided by the operator,

A meta-learning system should be composed of four primary
components – an optimizer, a memory, a selection mechanism,
and a generalization mechanism, shown in Figure 1. The
selection mechanism takes the features of a given problem as
input, and performs a mapping to solutions in the memory that

Copyright is held by the author/owner(s).
GECCO’10, July 7-11, 2010, Portland, Oregon, USA.
ACM 978-1-4503-0073-5/10/07.

2101

bias the use of functions in the initial generation of the GP
process. By seeding the population with genetic information that
has been useful in similar situations in the past, it is expected that
the GP will be able to more quickly find a high-quality solution.
If a high-quality solution is not found, the exploration/exploitation
feedback mechanism will drive the system towards new solutions,
which will be incorporated into the function library at the end of
training.

have an expected high quality. The memory stores previous or
generalized solutions encountered by the system, and passes
selected solution(s) on to the optimizer. The optimizer performs
specialization and modification of solutions to optimize a given
specific problem instance, while the generalization mechanism
compares the resultant solution with existing solutions in
memory, and either adds a new solution or modifies an existing
solution. In memetic computation terms, the optimizer generates
schema or modifies memes into schema, and then the
generalization mechanism converts the schema back into memes
for storage in memory. The selection mechanism provides a
mapping on memes, providing recognition from a problem
specification to a likely useful general solution, effectively
utilizing internally represented meta-memes.

To demonstrate the principles and advantages of meta-learning,
its application to the even and odd parity problems, standard
benchmarks for GP and automatic function definition methods [8]
are examined. Additionally the meta-learning architecture is
evaluated on the game of Pac-Man. The game of Pac-Man is a
standard benchmark for the study of evolution of autonomous
agents in changing environments. The Pac-Man scenario allows
the demonstration of behaviors such as task-prioritization (eating
dots vs. avoiding ghosts), adaptability, and robustness[9].

With these components, the architecture should be capable of
exploiting information gained in previous problem sessions
towards the solution of problems of increasing complexity.
Integrating a cross-instance memory and a selection mechanism
with an optimization method allows the recognition of a situation
and the selection of previously utilized schema as likely high
quality solution candidates. The optimization process then
combines and refines these solution candidates to provide a good
solution much faster than if the method had only random initial
solutions. Once the solution is deployed, the selection method is
trained to associate the situation (stimulus) with the solution
(behavior) utilizing the fitness (reward) of the solution[7].

The results show that the addition of memory, and the training
and integration of separately learned skills can significantly
increase the fitness of evolved individuals for even-parity
function approximation, and playing the game of PAC-MAN.

3. REFERENCES
[1] D. Shahaf and E. Amir, "Towards a Theory of AI
Completeness," 8th Interational Symposium on Logic
Formalizations of Commonsense Reasoning, 2007.
[2] D. Lenat and R. V. Guha, Building Large Knowledge-Based
Systems: Addison-Wesley, 1989.
[3] J. R. Koza, "Hierarchical genetic algorithms operating on
populations of computer programs," in International Joint
Conference on Artificial Intelligence, 1989, pp. 768-774.
[4] D. Dennett, Darwin's Dangerous Idea. New York:
Touchstone Press, 2005.
[5] Y. S. Ong and A. J. Keane, "Meta-Lamarckian learning in
memetic algorithms," IEEE Transactions on Evolutionary
Computation, vol. 8, pp. 99--110, 2004.
[6] P. Moscato, "On evolution, search, optimization, genetic
algorithms and martial arts: Towards memetic algorithms,"
Caltech Concurrent Computation Program, C3P Report, 826.
1989.

Figure 1. Meta-Learning Architecture
This architecture is implemented using Gram-ART, a new
Adaptive Resonance Theory variant, which is capable of
clustering variable dimension semantic inputs by creating
templates that store a non-parametric distribution over the
symbols and structure of a given grammar. This method serves as
generalization and memory mechanism for a geneticprogramming optimizer.

[7] R. J. Meuth, M.-H. Lim, Y.-S. Ong, and D. C. Wunsch, "A
Proposition on Memes and Meta-Memes in Computing for
Higher-Order Learning," Journal of Memetic Computing,
vol. 1, 2009.

A GP Meta-Learning system is constructed by augmenting the
Automatic Function Definition GP with a neural network method
that is trained to map between a parametric description of a given
task and the function-categories created by the Gram-ART
method. The output of this mapping is used to probabilistically

[9] J. R. Koza, "Evolution and co-evolution of computer
programs to control independent-acting agents," in From
Animals to Animats: Proceedings of the First International
Conference on Simulation of Adaptive Behavior, 1991.

[8] J. R. Koza, "Hierarchical Automatic Function Definition in
Genetic Programming," in Foundations of Genetic
Algorithms 2: Morgan Kaufmann, 1992, pp. 297-318.

2102

Memetic Comp. (2009) 1:85–100
DOI 10.1007/s12293-009-0011-1

REGULAR RESEARCH PAPER

A proposition on memes and meta-memes in computing
for higher-order learning
Ryan Meuth · Meng-Hiot Lim · Yew-Soon Ong ·
Donald C. Wunsch II

Received: 26 September 2008 / Accepted: 7 April 2009 / Published online: 29 April 2009
© Springer-Verlag 2009

Abstract In computational intelligence, the term ‘memetic
algorithm’ has come to be associated with the algorithmic
pairing of a global search method with a local search method.
In a sociological context, a ‘meme’ has been loosely defined
as a unit of cultural information, the social analog of genes
for individuals. Both of these definitions are inadequate, as
‘memetic algorithm’ is too specific, and ultimately a misnomer, as much as a ‘meme’ is defined too generally to be of
scientific use. In this paper, we extend the notion of memes
from a computational viewpoint and explore the purpose,
definitions, design guidelines and architecture for effective
memetic computing. Utilizing two conceptual case studies,
we illustrate the power of high-order meme-based learning.
With applications ranging from cognitive science to machine
learning, memetic computing has the potential to provide
much-needed stimulation to the field of computational intelligence by providing a framework for higher order learning.
Keywords Machine learning · Memetic computing ·
Meta-learning · Computational intelligence architectures

R. Meuth (B) · D. C. Wunsch II
Applied Computational Intelligence Laboratory,
Department of Electrical and Computer Engineering,
Missouri University of Science and Technology, Rolla, MO, USA
e-mail: rmeuth@mst.edu
M.-H. Lim
School of Electrical and Electronic Engineering,
Nanyang Technological University, Singapore 639798, Singapore
Y.-S. Ong
School of Computer Engineering, Nanyang Technological University,
Singapore 639798, Singapore

1 Introduction
Over the past several years many hundreds of papers have
been published on the modification and application of only
a handful of core computational intelligence techniques—
namely dynamic programming, evolutionary algorithms,
neural networks, fuzzy logic, and data clustering methods.
Algorithmically, there have been refinements and crossovers
in these categories, such as heuristic dynamic programming,
particle swarm optimization, evolutionary-trained fuzzy neural networks, and hybrid genetic algorithms, resulting in significant but relatively modest quality and performance gains.
Beyond these modifications the pace of new algorithm design
has been stagnant for a period of time, while the complexity of
machine learning and optimization problems has grown ever
larger with the maturity of the internet, digital media, and the
proliferation of data sources in all aspects of human life.
Meanwhile, advancement in hardware technology has
brought about affordable and powerful computing platforms
which are more easily accessible. However, it is clear that
increase in computational capacity cannot even come close
to addressing the challenges posed by the complexity of problems, many of which are typical of real-world scenarios [14].
More advanced and novel computational paradigms, particularly from the algorithms front have to be championed. The
general perception on how algorithms have managed to keep
pace with increasing problem complexity over the years is
depicted in Fig. 1. Initially, algorithms by and large were able
to keep up with the demands of increasing problem complexity. To a certain extent, the algorithms which typically
belong to the category of conventional or exact enumerative
procedures were able to surpass the complexity of problems
that were typical of what people were trying to solve. Subsequently, as the complexity of problems pushes the capability
limits of algorithms, it became evident that the complexity

123

86

Complexit
y index

Memetic Comp. (2009) 1:85–100
Current
state-of-art

Problem
Learning Enhanced
Algorithms

Any two [optimization] algorithms are equivalent when
their performance is averaged across all possible
problems.

Algorithms

Time

Fig. 1 An abstract comparison on state of optimization from the
perspectives of problems and algorithms complexity

of problems being addressed began to overwhelm the algorithms available. We view the region corresponding to the
convergence and divergence of the curves as being synonymous to the era of computational intelligence techniques. It
can be envisaged that in time, the spread between complexity of problems and algorithms will widen if computational
intelligence remains at status quo. There are clear signs that
these issues are in the early stages of being addressed. In
particular, the phase of research should be putting emphasis
not just on learning per se, but rather on issues pertaining to
higher order learning. This is a natural tendency in order to
address the demands and challenges of problems that surface.
The era of computational intelligence to a certain extent
managed to contain the gap between algorithms and problem.
In time, it will become clear that the divergence between
the two curves will continue, as shown in Fig. 1. A more
promising outlook as shown by the broken line curve can
be achieved and modern day optimization techniques can
rise to this challenge by incorporating not just mechanisms
for adaptation during the process of solving an instance of a
difficult problem, but rather mechanisms of adaptation or
more appropriately learning spanning across instances of
problems encountered during the course of optimization.
While a certain degree of similarity may be drawn when
compared to case-based reasoning (CBR), such perceived
‘experiential’ trait similarity in the sense that both encompass mechanisms to draw on ‘experience’ from previously
encountered problem instances is superficial. Unlike CBR
methods which rely on the need for explicit examples and
ranking procedures, optimization problems are usually not
amenable to such explicit case by case assessment to yield
information that is potentially useful to a search algorithm
[23,70]. Rather, a more likely emphasis should be the building up of a body of knowledge, more specifically memes and
meta-memes that collectively offer capability with a much
broader problem-solving scope in order to deal with the class
of problems being addressed.
In 1997, Wolpert and Macready formalized the ‘No Free
Lunch Theorem’ stating simply:

123

Additionally, Wolpert and Macready made the observation that in order to reduce the average cost across a set of
problems and optimizers, one must methodically utilize prior
or acquired information about the matching of problems to
procedures, given a priori knowledge gained from experience
[71]. The realizations brought by the No Free Lunch Theorem
changed the research focus of the field of computational intelligence from the design of individual algorithms to the design
of architectures of algorithms and parameters optimization.
It is in this spirit that the development of memetic algorithms
has been motivated [13,21,31,32,34,36,41,53,54,73].
Taken alone, current methods tend to be overwhelmed by
large datasets and suffer from the curse of dimensionality. A
new class of higher order learning algorithms are needed that
can autonomously discern patterns in data that exist on multiple temporal and spatial scales, and across multiple modes
of input. These new algorithms can be architectures utilizing
existing methods as elements, but to design these architectures effectively, some design principles should be explored.
Ultimately, the curse of complexity cannot be wholly
avoided. As the size or dimension of the problems increases,
a greater amount of computation becomes necessary to find
high quality solutions. However, such computation need not
be done on the fly, meaning at the exact time that a problem
is presented. If a memory mechanism is provided that can
store and retrieve previously used or generalized solutions,
then computation can be shifted into the past, greatly reducing the amount of computation necessary to arrive at a high
quality solution at the time of problem presentation.
One of the major drawbacks of evolutionary algorithms
and computational intelligence methods in general is the solvers employed usually start from zero information, independent of how similar the problem instance is to other instances
the method has been applied to in the past. In effect, the optimization methods typically do not incorporate any mechanisms to establish inter-instance memory. This property is
useful for comparing different computational intelligence
methods and in some cases, particularly when computation
time is not an issue, the capacity to draw on memory of past
instances solved is desirable as it allows the search to be more
focused, thus leading to solutions that would not otherwise
have been found efficiently. It is also worth noting that many
real-world problem domains are composed of sub-problems
that can be solved individually, and combined (often in a
non-trivial way) to provide a solution for the larger problem
[35,60].
In some problem instances, such as large instances of the
even parity problem, it is nearly impossible to stochastically
arrive at a complete solution without utilizing generalized

Memetic Comp. (2009) 1:85–100

solutions for small instances of the problem [24]. It is simple
to evolve a function that performs even parity on 2 bits using
only the logical functions AND, OR and NOT as primitives,
but extremely difficult to evolve a 10-bit even parity function
without any a priori information as the space of all possible solutions is immensely larger, and even the best known
solution is complex. By simply defining the general 2-bit
XOR function (the even parity computation for 2 bits), the
optimization method has a higher probability of combining
instances of XOR to arrive at an n-bit even-parity function,
greatly accelerating the optimization process.
In the game of chess, humans start at the top, and solve a
successive sequence of smaller, tractable problems to arrive
at a move. However, the learning process is bottom-up—a
human player of chess first learns the legal moves of every
piece, and then combines those general move capabilities
into strategies, strategies into tactics and those tactics combine with the tactics of the opposing player to form a highlevel view of the game as a whole. At each level optimization
and generalization are performed to pass information up and
down the play hierarchy. However, this natural progression
is not reflected in the methods that we utilize to computationally approach problems of this scale. The typical approach is
combinatorial optimization, where a sequence of low-level
moves is statistically analyzed in order to arrive at a plan
of play. As a whole, this is a computationally intractable
problem, and it does not even come close to resembling the
way humans play chess. Additionally, the skills learned in
chess may translate across several domains as general problem solving skills. The ability to translate knowledge from
one domain to another implies the necessity of meta-learning
or learning about how or what to learn—in order to recognize similar problem features in disparate environments and
scenarios.
The remaining of this paper is organized as follows.
Section 2 gives a brief outline of the classes of brain inspired
memetic computing. In Sect. 3 we discuss and compare
between schema and memes, in particular their roles in learning. Section 1 gives an architectural framework for computing with memes and meta-memes, exposing some important
issues in the design of systems with higher order learning
capability. Two examples, the even parity in Sect. 5 and travelling salesman problem in Sect. 6 are studied to illustrate the
concept of learning that spans across instances of problems.
In Sect. 7, we conclude this paper.

2 Brain inspired memetic computing
While Darwinian evolution has been a source of inspiration
for a class of algorithms for problem-solving, memetics has
served as a motivation for problem-solving techniques with
memetic algorithms being the most prominent and direct

87

manifestation of the inspiration. In recent years, there has
been a marked increase in research interests and activities
in the field of Memetic Algorithms. The first generation
of MA refers to hybrid algorithms, a marriage between a
population-based global search (often in the form of an
evolutionary algorithm) coupled with a cultural evolutionary stage. The first generation of MA though it encompasses
characteristics of cultural evolution (in the form of local
refinement) in the search cycle, may not qualify as a true
evolving system according to Universal Darwinism, since all
the core principles of inheritance/memetic transmission, variation and selection are missing. This suggests why the term
MA stirs up criticisms and controversies among researchers
when first introduced in [43]. The typical design issues [49]
include (i) how often should individual learning be applied,
(ii) on which solutions should individual learning be used,
(iii) how long should individual learning be run, (iv) what
maximum computational budget to allocate for individual
learning, and (v) what individual learning method or meme
should be used for a particular problem, sub-problem or
individual.
Multi-meme [28], hyper-heuristic [22] and metaLamarckian MA [53,54] are referred to as second generation MA exhibiting the principles of memetic transmission
and selection in their design [48]. In multi-meme MA, the
memetic material is encoded as part of the genotype. Subsequently, the decoded meme of each respective individual
is then used to perform a local refinement. The memetic
material is then transmitted through a simple inheritance
mechanism from parent to offspring. On the other hand, in
hyper-heuristic and meta-Lamarckian MA, the pool of candidate memes considered will compete, based on their past
merits in generating local improvements through a reward
mechanism, deciding on which meme to be selected to proceed for future local refinements. A meme having higher
rewards will have greater chances of being replicated or copied subsequently. For a review on second generation MA,
i.e., MA considering multiple individual learning methods
within an evolutionary system, the reader is referred to [53].
Co-evolution and self-generation MAs introduced in [34] and
[62] are described in [48] as third generation MA where all
three principles satisfying the definitions of a basic evolving
system has been considered. In contrast to second generation MA which assumes the pool of memes to be used being
known a priori, a rule-based representation of local search
is co-adapted alongside candidate solutions within the evolutionary system, thus capturing regular repeated features or
patterns in the problem space.
From the three classes of MA outlined, memes can be
seen as mechanisms that capture the essence of knowledge in
the form of procedures that affect the transition of solutions
during a search. The level of participation or activation of
memes is typically dictated by certain indicative performance

123

88

Memetic Comp. (2009) 1:85–100

Table 1 Generational descriptions of memetic algorithms
Classes

Characteristics

Example systems

First Generation

Global search paired with local search

(i) A canonical MA [43,50]
(ii) Adaptive global/local search [16]
(iii) MA for combinatorial optimization [33]
(iv) Handling computationally expensive problems [55]
(v) Multiobjective permutation flowshop scheduling [19]
(vi) Fitness landscape analysis of MA [38]
(vii) Robust aerodynamic design [56]
(viii) Evolutionary gradient search (Arnold and Salomon [6])
(ix) Large-scale quadratic assignment problem [63]
(x) Evolutionary Lin–Kernighan for traveling salesman
problem [40]
(xi) Dynamic optimization problem [68]
and many others

Second Generation

Global search with multiple local optimizers. Memetic
information (Choice of optimizer) Passed to offspring
(Lamarckian evolution)

(i) Nurse rostering problem [9]
(ii) Hyper-heuristic MA [15,22]
(iii) Structure prediction and structure comparison of
proteins [29]
(iv) Meta-Lamarckian MA [54]
(v) Multimeme MA [31]
(vi) Adaptive multi-meme MA [53]
(vii) Multimeme algorithm for designing HIV multidrug
therapies [10,45]
(viii) Agent-based memetic algorithm [17,67]
(ix) Diffusion memetic algorithm [48]
and several others

Third Generation

4th Generation

Global search with multiple local optimizers. Memetic
information (Choice of local optimizer) passed to
offspring (Lamarckian Evolution). A mapping between
evolutionary trajectory and choice of local
optimizer is learned

(i) Co-evolution MA [62]

Mechanisms of recognition, Generalization,
optimization, and memory are utilized

Unknown

metrics, the objective being to achieve a healthy balance
between local and global search. Memes instead of being
performance-driven should be extended to include capacity to evolve based on the snapshots of problem instances.
In the process of solving a repertoire of problem instances,
memes can culminate based on the recurrence of patterns
or structures. From basic patterns or structures, more complex higher level structures can arise. In this regard, a brain
inspired meta-learning memetic computational system, consisting of an optimizer, a memory, a selection mechanism,
and a generalization mechanism that conceptualizes memes
not just within the scope of a problem instance, but rather in
a more generic contextual scope is appropriate. Such traits
which are lacking in the third generation MA can serve as the
basis of 4th generation class of MAs. The reader is referred to
Table 1 for a summary of generational description of Memetic

123

(ii) Self-generation MA [30]

Algorithms. The summary although by no means exhaustive
should serve as a useful guide on the classifications of the
various traits of existing MA research.
The mammalian brain exhibits hierarchical self-similarity, where neurons, groups of neurons, regions of the brain,
and even whole lobes of the brain are connected laterally and
hierarchically. Biological neurons are particularly well suited
to this architecture; a single neuron serves as both a selection
and learning mechanism. A neuron only fires when it receives
significant input from one or more sources, and thus serves
as a correlation detector. Additionally, it learns by modifying the weights of its inputs based on local information from
firing rate, as well as global information from the chemical environment. Thus neurons activate when they encounter
patterns that have made them fire before, and are able to adapt
in delayed-reward situations due to global signals.

Memetic Comp. (2009) 1:85–100

In laterally connected architectures, neuron groups can
provide the function of clustering, as active neurons suppress
the activity of their neighbors to pass their information down
the processing chain, providing both selection and routing of
information. The effect of this selectivity is that biological
neural architectures route a spreading front of activation to
different down-stream networks based on the similarity of
the features present in the pattern of activation to previously
presented patterns. As the activation front passes each neuron, the synaptic weights are changed based on local information—the firing rate of the neuron, the chemical environment,
and the features present in the signal that activated the neuron, slightly changing how an individual neuron will respond
at the next presentation of patterns [8].
Connected in loops, neurons provide short-term memory,
process control and create temporally-delayed clustering.
Combining loops and lateral connections at several levels
of neuron groups (groups of neurons, groups of groups, etc)
the neural architecture is able to exhibit increasing levels
of selection, memory, and control. This is exactly the architecture that we see in the human cortex—a single cortical
column contains recursion and lateral inhibition, and these
cortical columns are arranged in a similar way, progressing in a fractal learning architecture up to the level of lobes,
where sections of the brain are physically separated [20]. This
fractal architecture is similar to the N th-order meta-learning
architecture described later in Sect. 4.
The brain inspired meta-learning memetic computational
system is thus regarded here as a 4th generation memetic
computational system. The novelty of the proposed metalearning memetic system is highlighted below.
(i) In contrast to the second generation memetic algorithms, there is no need to pre-define a pool of memes
that will be used to refine the search. Instead memes
are learned automatically—they are generalized information that passed between problem instances.
(ii) Since it satisfies all the three basic principles of an
evolving system, it also qualifies as a third generation memetic computational system. Unlike simple
rule-based representation of meme used in co-evolution and self-generation MAs, the brain inspired metalearning memetic computational system models the
human brain that encodes each meme as hierarchies
of cortical neurons [20]. With a self-organizing cortical architecture, meaningful information from recurring real-world patterns can be captured automatically
and expressed in hierarchical nested relationships. A
human brain stimulated by the recurrence of patterns,
builds bidirectional hierarchical structures upward.
The structure starts from the sensory neurons, through
levels of cortical nodes and back down towards muscle
activating neurons.

89

(iii) There exists a memory component to store the system’s generalized patterns or structures of previously
encountered problems—these elements could be
thought of as memes.
(iv) Selection mechanisms are provided to perform association between problem features and previously generalized patterns that are likely to yield high-quality
results.
(v) Meta-learning about the characteristics of the problem is introduced to construct meta-memes which are
stored in the selection mechanism, allowing higherorder learning to occur automatically.
(vi) Memes and meta-memes in computing are conceptualized for higher-order learning as opposed to the
typical definition of local search method used in all
the works in memetic algorithm.

3 Schema–meme relationship
A genetic algorithm learns by passing schema (the genetic
information of individuals) from generation to generation.
Through natural selection and reproduction, useful schemata
proliferate and are refined through genetic operators. The
central concept of learning is that of the schema—a unit
of information that is developed through a learning process [18,57,59]. The typical ‘memetic algorithm’ uses an
additional mechanism to modify schemata during an individual’s ‘lifetime’, taken as the period of evaluation from
the point of view of a genetic algorithm, and that refinement is able to be passed on to an individual’s descendants.
The concept of schemata being passable just as behaviors
or thoughts are passed on is what we term as memes—a
meme being a unit of cultural information [53,54,61,64].
Thus, memes can be thought of as an extension of schemata—schemata that are modified and passed on over a learning process. However, this distinction is a matter of scale.
In a learning method, the current content of the representation could be called a schema, but when that information is
passed between methods, it is more appropriately regarded
as a meme.
This is analogous to the sociological definition of a meme
[12]. In this form, a meme may contain certain food preparation practices, or how to build a home or which side of
the road to drive on. Within the individuals of a generation, they are relatively fixed, but they are the result of a
great deal of optimization, capturing the adaptations resulting from the history of a society. These cultural memes are
passed from generation to generation of the population, being
slightly refined at each step—new ingredients are added to
the cooking methods, new building materials influence construction, traffic rules change, etc. The mechanism that allows
this transformation is that of generalization [51,52,58].

123

90

To communicate an internal schema from one individual to
another, it must be generalized into a common representation—that of language in the case of human society. The
specifics of the schema are of no great importance, as they
would mean very little to an individual other than the originator due to the inherent differences between individuals. For
instance, a description of the precise movements necessary
to create a salad, such as the technique used to slice tomatoes and wash lettuce, is less important than the ingredients
and general process of preparing the salad. Thus the salad
recipe is a meme, a generalized representation of the salad,
but the recipe alone is insufficient to produce the salad. The
salad recipe is expressed only when it is put through the process of preparation, of acquiring and preparing the individual ingredients, and combining them according to the salad
meme.
A meme may be thought of as generalized schema. Schemata are refined for an instance; memes are generalized to
the extent of being transmissible between problem instances.
To resolve the potential confusion that may arise, we put
forth a loose definition of the term ‘Memetic Computation’—
a paradigm of computational problem-solving that encompasses the construction of a comprehensive set of memes thus
extending the capability of an optimizer to quickly derive a
solution to a specific problem by refining existing general
solutions, rather than needing to rediscover solutions in every
situation.

4 A framework for higher order learning
A meta-learning system should be composed of four primary
components—an optimizer, a memory, a selection mechanism, and a generalization mechanism, shown in Fig. 2. The
selection mechanism takes the features of a given problem
as input, and performs a mapping to solutions in the memory that have an expected high quality. The memory stores
previous or generalized solutions encountered by the system, and passes selected solution(s) on to the optimizer. The
optimizer performs specialization and modification of solutions to optimize a given specific problem instance, while
the generalization mechanism compares the resultant solution with existing solutions in memory, and either adds a new
solution or modifies an existing solution. In memetic computation terms, the optimizer generates or modifies memes into
schema, and then the generalization mechanism converts the
schema back into memes for storage in memory. The selection mechanism provides a mapping about memes, providing
recognition from a problem specification to a likely useful
general solution, effectively utilizing internally represented
meta-memes.
With these components, the architecture should be capable of exploiting information gained in previous problem

123

Memetic Comp. (2009) 1:85–100

Fig. 2 Meta-learning architecture

sessions towards the solution of problems of increasing complexity. Integrating a cross-instance memory and a selection
mechanism with an optimization method allows the recognition of a situation and the selection of previously utilized
schema as likely high quality solution candidates. The optimization process then combines and refines these solution
candidates to provide a good solution much faster than if the
method had only random initial solutions. Once the solution
is deployed, the selection method is trained to associate the
situation (stimulus) with the solution (behavior) utilizing the
fitness (reward) of the solution.
The process described above is itself a learning process,
and thus could be augmented with increasingly higher level
memory and selection methods, to allow complex, high-order
solutions to be found. A sort of fractal meta-learning architecture of this type may be capable of virtually unlimited
problem-solving capacity across a wide variety of problem
domains.
The sequence of learning sessions matters greatly to the
expression of complex behavior. By starting with simple
problem instances and presenting successively more complex
scenarios, the problem is decomposed, allowing solutions
from sub-problems to be exploited, increasing the likelihood
that higher level solutions will occur. Additionally, by training these simple solution components, a wider variety of
high-level solutions can be trained more rapidly. For example, when training a dog, teaching him to ‘sit’ decreases the
amount of training necessary for both ‘stay’ and ‘beg’ behaviors. This is analogous to the automatic construction of a
‘Society of Mind’ as described by [42].
When constructing optimization architectures, an issue of
particular relevance is that of representation—how the schemata are stored. In population based algorithms schemata
are stored as parameter strings, in neural networks, schemata are implicitly represented as interconnection weights,
clustering methods store templates for categories, etc. How
these schemata are expressed (and thereby their meaning) is
dependent on the expression structure. In genetic algorithms
a string is decoded into a trial problem solution, the weights

Memetic Comp. (2009) 1:85–100

91

Fig. 3 Meta-meta learning
Fig. 4 N th-order meta learning

in neural networks are utilized through weighted summation
and passing through a transfer function. This division of representation prevents the simple utilization of schema across
solution methods. To get disparate methods to work together,
great care must be taken to modify both methods to utilize
the same schema, which has been the subject of a great deal
of research [1,2,4,7,11,25,39,44,46,54].
First order learning methods consist of a single algorithm
that modifies schema to optimize a system. Individually, all
classical machine learning methods fall into this category.
Meta-learning or second-order methods learn about the process of learning, and modify the learning method, which in
turn modifies schema. A simple illustration of a meta-learning architecture is presented in Fig. 2. In this figure, schemata
are represented as ‘procedures’, which are stored in memory.
A problem is presented to the architecture, and a selection
mechanism chooses likely valuable schema from memory,
which are then modified to the particular problem instance.
High-value schema are then generalized and saved back into
memory, and the selection mechanism then learns an association between characteristics of the problem instance and
schema that yielded positive results.
These second order methods should be able to be combined with other methods or layers to produce third-order
methods and so on to order N , as illustrated in Figs. 3 and 4.
To produce higher order methods, information gained in one
problem instance should be utilized to provide a partial solution to another similar problem instance allowing the system
as a whole to take advantage of previous learning episodes.

problems, standard benchmarks for genetic programming
and automatic function definition methods [26,27]. We propose a hypothetical genetic programming system utilizing
a set of Boolean operators to construct individuals implementing the even or odd parity functions (XOR and XNOR,
respectively). We analyze two cases of the evolution of the
three-input XOR function, both starting with populations
implementing the two-input XOR function, with and without the abstraction that is inherent in a meta-learning system.
A third case is presented illustrating the functionality of a
simple selection mechanism on the odd-parity function.
5.1 Problem overview
Koza described the even parity problem below.
The Boolean even-parity function of k Boolean arguments returns T (True) if an odd number of its arguments are T , and otherwise returns NIL (False). The
concatenation of this returned bit to the original string
making the total string even, hence even-parity.
In applying genetic programming to the even-parity
function of k arguments, the terminal set T consists of
the k Boolean arguments D0, D1, D2, . . . involved in
the problem, so that
T = {D0, D1, D2, . . .}.
The function set F for all the examples herein consists
of the following computationally complete set of four
two-argument primitive Boolean functions:
F = {AND, OR, NAND, NOR, NOT}.

5 Even-parity example
To demonstrate the principles and advantages of meta-learning, we examine its application to the even and odd parity

The Boolean even-parity functions appear to be the
most difficult Boolean functions to find via a blind random generative search of expressions using the above
function set F and the terminal set T . For example,

123

92

Memetic Comp. (2009) 1:85–100

Fig. 6 XOR tree representation

Fig. 5 Illustration of function representation as tree structure

even though there are only 256 different Boolean functions with three arguments and one output, the Boolean
even-3-parity function is so difficult to find via a blind
random generative search that we did not encounter it at
all after randomly generating 10,000,000 expressions
using this function set F and terminal set T . In addition, the even-parity function appears to be the most
difficult to learn using genetic programming using this
function set F and terminal set T [26,27].
The odd-parity function is similarly constructed, returning true if an even number of its arguments are true, and
otherwise returning false.
In genetic programming (GP), the genome of an individual is represented as a tree structure, where operations are
applied at branches, and the leaves are constants and problem parameters. An illustration of a functional represented as
tree strurture is shown in Fig. 5 [24,26,27]. One advantage
of GP is that the results can be easily human interpretable
and formally verifiable, a quality that is not present in many
other computational intelligence methods [58].
The even-2-parity function is simply the XOR function,
which is itself a composition of the terminal set functions in
one simple possible configuration:
a XOR b = (a OR b) AND (a NAND b)
Using a tree representation, the XOR function is shown in
Fig. 6.
Constructing the even-3-parity function using only these
primitives is more difficult, but follows a similar pattern,
illustrated below and in Fig. 7:
XOR (a, b, c) = (((a OR b) AND (a NAND b)) OR c)
AND (((a OR b) AND (a NAND b)) NAND c)

123

Note that the three-input XOR structure relies on the recursive use of the two-input XOR function, replacing the ‘a’
nodes with XOR nodes, and re-assigning the top-level ‘b’
nodes to be the ‘c’ variable.
Note that if a 2-bit XOR function is defined explicitly as in
Fig. 8, the even-3-parity function becomes greatly simplified,
as written below and shown in Fig. 9.
XOR (a, b, c) = (a XOR b) XOR c
5.2 Case 1: Non-meta XOR3 evolution
Taking a genetic programming system as an example, in a
non-meta learning system, evolution of the XOR3 function
must proceed through at least two generations. To further
expand on our illustration, we consider the best case scenario
whereby all the individuals in the population incorporate the
simplified XOR function, as shown in Fig. 10.
As there are four leaf nodes out of seven total nodes, the
probability of selecting a leaf node for crossover (PL1 ) is 4/7.
Assuming a uniform population of individuals implementing
XOR2 (translating to a 100% probability of choosing another
XOR2 individual for crossover) the probability of selecting
the root node of another individual to replace the selected
leaf node is (PF1 ) 1/7.
Then, the evolutionary process must select one of the two
top-level ‘b’ nodes for mutation from the tree which has a
total of 13 nodes, thus the probability of selecting one correct
leaf for mutation (PM1 ) is 2/13. Choosing from the eight possible node types (the combination of terminal set and functional set), the probability of selecting the correct ‘c’ variable
(PV 1 ) is 1/8.
At this point the evolutionary reproduction steps are completed, and the individual shown in Fig. 11 is evaluated. This
partial XOR3 function is not yet complete, but it correctly
completes one test case more than the XOR2 function, which
may give it an evolutionary advantage. Assuming that the
individual survives to the next generation and is again
selected as a parent with 100% probability, an additional

Memetic Comp. (2009) 1:85–100

93

Fig. 7 Three-input XOR tree
representation

Fig. 8 Simplified two-input XOR

Fig. 10 Initial non-meta learning XOR2 individual

the correct variable from the total set of node types (PV 2 ) is
1/8. The completed three-input XOR function is illustrated
earlier in Fig. 9.
Ignoring changes in the population and evolutionary survivability, the probability of transitioning from XOR2 to
XOR3 in two generations without meta-learning is calculated below.
Fig. 9 Simplified three-input XOR

reproduction step must be completed to yield an XOR3
function.
Now the correct leaf node must be selected for crossover,
but this time there is only one node, the ‘a’ node at a depth
of three, from the 13 possible nodes, so the probability of
selecting the correct leaf node for crossover (PL2 ) is 1/13.
Once again, assuming all other individuals in the population
still implement the XOR2 function in Fig. 8, the probability
of selecting the root of another XOR2 individual to replace
the leaf (PF2 ) is 1/7. At the completion of crossover, the total
number of nodes in the tree becomes 18. At the mutation step,
the remaining ‘b’ node at depth three must be selected, and
the probability of selecting correct leaf for mutation (PM2 )
is 1/18. Completing the XOR3, the probability of selecting

Pxor3_nonmeta = PL1 ∗ PF1 ∗ PM1 ∗ PV 1 ∗ PL2 ∗ PF2
∗PM2 ∗ PV 2
= 1.19 × 10−7
where,
PL1 the probability of a leaf node selection for crossover
during the first generation,
PF1 the probability of functional root selection for crossover during the first generation,
PM1 the probability of proper leaf selection for mutation
during the first generation,
PV 1 the probability of proper variable selection for mutation during the first generation,
PL2 the probability of a leaf node selection for crossover
during the second generation,

123

94

Memetic Comp. (2009) 1:85–100

Fig. 11 Intermediate step in
development of 3-bit XOR
function after a single
generation

PF2 the probability of functional root selection for crossover during the second generation,
PM2 the probability of proper leaf selection for mutation
during the second generation,
PV 2 the probability of proper variable selection for mutation during the second generation.
Note that this ignores the significant influence of relative fitness, generational selection, parent selection, probability of
application of crossover/mutation operators and population
influence and may be interpreted as a kind of upper-bound on
the probability that a two-input XOR individual will develop
into a three-input XOR without the abstraction capability of
meta-learning.
5.3 Case 2: Meta-learning XOR3 evolution
In this case we assume a meta-learning system that has
already learned a two-input XOR function, performed generalization and added this to the function set (F = AND, OR,
NAND, NOR, NOT, XOR2). The probability that the system will transition from XOR2 to XOR3 is calculated using
only the mutation step.
With a population uniformly initialized with the two-input
XOR and an individual selected from this population, illustrated in Fig. 8, the probability of selecting a leaf node for
mutation (PL ) is 2/3 as the simplified XOR tree has only three
nodes, and two of them are terminals. Having selected a terminal, the probability of selecting the XOR2 function from
the node set of six functions and three terminals to replace the
leaf node (PF ) is 1/9. Assuming a recursive mutation process,
two new leaf nodes must be selected, and they must contain
variables not yet used by the tree to produce a three-input
XOR. The probability of selecting the correct terminal node
is 1/9, and this process must be repeated twice, so the probability of selecting two correct terminal nodes (PV ) is (1/9)2
or 1/81. Using only one generation the three-input XOR can

123

be developed in a meta-learning system.
Probability of XOR3 from XOR2 : Pxor3_meta
= PL ∗ PF ∗ PV = 0.000914
where,
PL the probability of a leaf node selection for mutation,
PF the probability of XOR2 function selection for mutation,
PV the probability of proper leaf selection for mutation.
Note that using meta-learning, the three-input XOR can
also occur with a crossover and a mutation, where the nonmeta learning system must utilize two full generations. Also
note that though the size of the functional set has increased,
the number of changes necessary to place an upper-bound
on the probability of a three-input XOR occurring has been
substantially decreased, allowing the evolutionary process to
focus on high-level changes.
Thus in a large population, the XOR3 function may occur
in a single generation with a meta-learning system, where a
non-meta learning system must take at least two generation
and probably many thousands of evaluations to evolve an
XOR3.
5.4 Case 3: Selection and odd-parity evolution
To demonstrate the advantages of the complete meta-learning
procedure, we first present the 2-bit even-parity problem to
a theoretical meta-learning system, then the 2-bit odd-parity
problem, and finally the 3-bit even-parity problem. The selection mechanism shall have 2 inputs—the first is activated only
when the system is operating on the even-parity problem, the
second is activated only when operating on the odd-parity
problem. Initially, the memory is empty, so the optimizer is
initialized with random solutions.

Memetic Comp. (2009) 1:85–100

Presented with the even-2-parity problem, the optimizer
outputs a resulting solution that performs the XOR function—‘D0 XOR D1’, where D0 and D1 are the Boolean
arguments of the input. This function is passed to the generalization mechanism, which removes the absolute references
to the Boolean arguments, replacing them with dummy variables ‘A’ and ‘B’, resulting in the function ‘A XOR B’. This
generalized XOR function is then added to the memory, making the function available as a primitive. The functional set
becomes:
F = {AND, OR, NAND, NOR, NOT, XOR}.
The selection mechanism is updated to learn an association between the active ‘even-parity’ input and the new memory element. At this point the procedure and difference in
optimization would be no different than if the optimizer were
operating without the rest of the meta-learning architecture.
Next, the odd-2-parity problem is presented, the ‘odd-parity’ input is activated on the selector mechanism, and having
no other elements to select, the sole item in memory (the generalized ‘A XOR B’ function) is selected to initialize the state
of the optimizer. The optimizer replaces the dummy variables
with references to the Boolean arguments and begins optimization. As only a small modification is necessary, the addition of the NOT primitive function at a high-level to create
an XNOR function, the optimizer has a high probability of
quickly finding a perfect solution to the odd-2-parity problem. This differs from a randomly initialized optimizer as
there would be a lower probability of finding a good solution due to the need to explore more modifications. Once the
meta-learning optimizer finds the solution, the generalization, memory insert, and selection training steps are repeated
for the XNOR function:
F = {AND, OR, NAND, NOR, NOT, XOR, XNOR}.
Finally, the even-3-parity problem is presented to the metalearning architecture. The selection ‘even-parity’ input is
activated, and the associated XOR memory element is used
to initialize the optimizer state. The optimizer replaces the
XOR dummy variables with argument references, and begins
the optimization process. The optimizer need only make the
relatively small change of cascading the XOR function to
produce a 3-input XOR function, where a raw optimization
function without a memory or selection method would need
to evaluate and modify many combinations of the original five
functional primitives to arrive at a good solution. Thus the
meta-learning architecture should be able to arrive at highvalue solutions rapidly by exploiting previously generated
solution to construct high-level solutions.
In this example the memory component stores generalized solutions to previously encountered problems—these
elements could be thought of as memes, as they are solutions
that are passed between problem instances. The selection

95

mechanism performs association between problem features
and solutions that are likely to yield high-value results. By
not only providing the input data to the problem, but additional meta-data about the characteristics of the problem, the
meta-learning architecture can construct meta-memes which
are stored in the selection mechanism, allowing higher-order
learning to occur automatically.

6 Traveling salesman problem
The Traveling Salesman Problem (TSP) is a standard combinatorial optimization problem used for the design and evaluation of optimization methods [3,5,7,11,37,44,46,47,65,66,
69,72,74]. TSP optimization algorithms have a wide range
of applications including job scheduling, DNA sequencing,
traffic management, and robotic path planning. To further
illustrate the capabilities of the meta-learning design paradigm, an example is presented using instances of the TSP.
To apply meta-learning to the TSP problem, the schema
of the problem must be identified. Here the schema takes the
form of the ordering of points in a tour. The addition of a
clustering method to divide and conquer the TSP has been
shown to greatly accelerate the solution of the TSP [40]. With
this addition, the overall schema for the optimizer consists
of the combination of cluster templates, tour point ordering,
and the locations of points. This schema must be generalized
to create a meme, which is trivial for the cluster templates,
but more challenging for the tour ordering and points’ locations. The problem is further complicated by the necessity to
generalize tours to be applicable over multiple scales.
For this application, a meme consists of a small ordered
tour, containing small, limited number of points. To generalize the meme, the centroid of the group is calculated and
subtracted from each point, making the centroid the origin
of the group. The coordinates of each point are then normalized by distance from the origin. This projects the points into
unit-space, and allows comparisons across multiple scales.
Each TSP-meme serves as a pre-optimized tour template.
Each point in the TSP-meme can represent a real point in the
problem instance, or the centroid of a group of points, itself
represented by a meme.
Given an instance of the TSP, the meta-TSP algorithm utilizes a clustering method to divide the problem into sub-problems, and divides those sub-problems into sub-sub problems
and so on, until a threshold for sub-problem size is reached.
The relationships between sub-problems are recorded in a
tree-representation. Each of these sub-problems is generalized, and compared against the recorded memes for existing
solutions.
The recognition mechanism must be able to detect structurally similar sub-problems. For this experiment the matching mechanism compares two normalized sub-problems by

123

96

Fig. 12 Small TSP instance of approximately 30 points

finding the nearest corresponding points between the memes,
and calculating the mean squared error between these points.
If a match is found in memory, the existing meme-solution
(a point ordering) is copied to the current sub-problem, and
the sub-problem updates the meme by refining template point
positions. If no match exists in memory, the sub-problem is
solved as accurately as possible. With a small enough problem threshold, exact solutions to sub-problems can be found,
depending on computational resources available. The subproblem is then stored in memory as a new meme. After all
the sub-problems are solved, they are combined into a global
tour by collapsing the problem-tree, and utilizing a simple
O(n) merge algorithm as detailed in Mulder and Wunsch
[44].
To illustrate this process, an example is given utilizing a
simple instance of the TSP, shown in Fig. 12. A first pass
of clustering is shown in Fig. 13. Note that cluster M3 contains many points, and that a single point has been left out of
the clusters for illustrative purposes. A second pass further
divides cluster M3 into clusters M5, M6, and M7, as shown
in Fig. 14. The final clustering pass assigns all clusters to
a global cluster, M8, in Fig. 15. The hierarchy of clusters,
and thereby sub-problems, is denoted by the cluster tree in
Fig. 16.
At this stage, each sub-problem is optimized independently, as shown in Fig. 17. Note that some of the sub-problems contain references to other sub-problems, particularly
M3 and M8. The centroids of sub-problems are utilized for
optimization and solution, representing sub-problems as a
whole. During the course of optimization, each sub-problem is normalized, and compared with previously computed,
normalized solutions in the memory. These memes can be
stored across instances, building a large library of pre-computed solutions that can be deployed to yield high quality
solutions rapidly. Sub-problems of a global problem instance

123

Memetic Comp. (2009) 1:85–100

Fig. 13 TSP Instance after first clustering pass. Each cluster initializes
a meme, labeled with ‘M#’ and a ‘+’ denoting the centroid

Fig. 14 Second clustering pass. Note the new clusters, M5, M6, and
M7

Fig. 15 Final clustering pass, with global cluster M8

Memetic Comp. (2009) 1:85–100

Fig. 16 Tree of sub-problems (clusters)

can be thought of as new problem instances, and pre-computed solutions that are generated during the calculation of a
global instance can be applied across sub-problems.
For example, the normalized versions of M2 and M4 would
be very similar in structure, and once M2 is computed, the
structural similarity of the sub-problems would be recognized, and the ordering of points for M4 need not to be computed, only copied from M2 to M4. The same process applies
across scales and global problem instances.
When all sub-problems are completed, the problem
hierarchy is collapsed by de-referencing sub-problems and
incrementally merging them with higher level tours. This is
accomplished by choosing the closest set of two vertices in
the sub-problem to any two vertices in the higher level tour.

97

To avoid an O(n 2 ) operation, a small neighborhood of vertices from the super-tour is chosen based on proximity to
the centroid of the sub-tour. This neighborhood of super-tour
vertices is compared to each vertex in the sub-tour to find
the best match. A result of this merge operation is illustrated
in Figs. 18 and 19. Figure 19 shows the final merge of all
complete sub-tours into a final tour. The completed tour is
shown in Fig. 20.
The computational complexity of the proposed method
is expected to be very efficient at O(n log(n)) improving
with linearly decreasing complexity as the library of preoptimized solutions grows, decreasing the amount of optimization to be performed on a given TSP instance.
The qualitative performance of this method is the subject
of future development. The algorithm presented here serves
as an example of meta-learning driven design, incorporating
mechanisms of memory, selection, optimization, and generalization.

7 Conclusion
The desire for a new and robust computational intelligence
paradigm spans many problem domains, including real time
robotic systems which must deal with increasing complexity on a daily basis, deep data mining such as natural language processing with applications in information retrieval
and machine understanding, human–computer interaction,

Fig. 17 Completed memes,
M1 through M8. Super-clusters
reference the centroids of
sub-clusters. Note that memes
M2 and M4 are similar in
structure, but not scale

123

98

Fig. 18 Memes M5, M6, and M7 are merged into M3

Memetic Comp. (2009) 1:85–100

The primary difficulty of designing meta-learning systems
lies in the construction of valid scale-invariant representations which enable the simple construction of selection,
generalization, and memory mechanisms. By providing
generalization, memory, optimization, and selection mechanisms, a meta-learning architecture can operate on highlevel features of a problem instance, selecting generalized
solutions that have been used previously with high utility
in the problem context. Utilizing these features, a system
should be able to learn not only the solution to a problem,
but learn about solving problems. Such a system may enable a
quantum leap in the performance of real-world adaptive systems as they provide the central components of meta-adaptive
systems to be constructed.

References

Fig. 19 Memes M1, M2, M3, M4 are merged into M8

Fig. 20 Completed tour

and long-term optimization. These new, complex frontiers
of machine learning and optimization could all benefit from
the higher order memetic computing methods described here.
We have presented an overview of important definitions
and architectures in memetic computing and have attempted
to illustrate the power of next-generation memetic algorithms.

123

1. Abramson M, Wechsler H (2001) Competitive reinforcement learning for combinatorial problems. In: International joint conference
on neural networks proceedings. IJCNN ’01
2. Agarwal A, Lim M-H, Er M-J, Chew C-Y (2005) ACO for a new
TSP in region coverage. IEEE/RSJ Int Conf Intel Robot Syst
3. Agarwal A, Lim M-H, Er MJ, Nguyen TN (2007) Rectilinear workspace partitioning for parallel coverage using multiple UAVs. Adv
Robot 21(1)
4. Angeline PJ (1993) Evolutionary algorithms and emergent intelligence. Doctoral thesis, Ohio State University, Columbus
5. Applegate D, Cook W, Rohe A (2003) Chained Lin-Kernighan for
large traveling salesman problems. INFORMS J Comput 15(1):82–
92
6. Arnold DV, Salomon R (2007) Evolutionary gradient search revisited. IEEE Trans Evol Comput 11(4):480–495
7. Baraglia R, Hidalgo JI, Perego R (2001) A hybrid heuristic for the
traveling salesman problem. IEEE Trans Evol Comput 5(6):613–
622
8. Beinenstock EL, Cooper L, Munro P (1982) Theory for the development of neuron selectivity: orientation specifity and binocular
interaction in the visual cortex. J Neurosci 2(1):32–48
9. Burke E, Cowling P, Causmaecker PD, Berghe G (2001) A
memetic approach to the nurse rostering problem. Appl Int
15(3):199–214
10. Caponio A, Cascella GL, Neri F, Salvatore N, Sumner M (2007) A
fast memetic algorithm for off-line and on-line control design of
PMSM drives. IEEE Trans Syst Man Cybern Part B Spec Issue
Memetic Algorithms 37(1):28–41
11. Dang J, Zhang Z (2005) A polynomial time evolutionary algorithm
for the traveling salesman problem. Int Conf Neural Netw Brain
12. Dawkins R (1989) The selfish gene. Oxford University Press, USA
13. Francois O, Lavergne C (2001) Design of evolutionary algorithmsA statistical perspective. Evol Comput IEEE Trans on 5(2):129–
148
14. Gaudiot J-L, Kang J-Y, Ro WW (2005) Techniques to improve
performance beyond pipelining: superpipelining, superscalar, and
VLIW. Adv Comput (63)
15. Gutin G, Karapetyan D (2009) A selection of useful theoretical tools for the design and analysis of optimization heuristics.
Memetic Comput 1(1)
16. Hart WE (1994) Adaptive global optimization with local search.
University of California, California

Memetic Comp. (2009) 1:85–100
17. Hasan SMK, Sarker R, Essam D, Cornforth D (2008) Memetic
algorithms for solving job-shop scheduling problems. Memetic
Comput J
18. Holland JH (1975) Adaptation in natural and artificial systems.
University of Michigan Press, Ann Arbor
19. Ishibuchi H, Yoshida T, Murata T (2003) Balance between genetic
search and local search in memetic algorithms for multiobjective permutation flowshop scheduling. IEEE Trans Evol Comput
7(2):204–223
20. Johansson C, Lansner A (2007) Towards cortex sized artificial
neural systems. Neural Netw 20(1):48–61
21. Kazarlis SA, Papadakis SE, Theocharis JB, Petridis V (2001)
Microgenetic algorithms as generalized hill-climbing operators
for GA optimization. Evol Comput IEEE Trans on 5(3):204–
217
22. Kendall G, Soubeiga E, Cowling P (2002) Choice function and
random hyperheuristics. In: 4th Asia Pac Conf Simul Evol Learn,
pp 667–671
23. Kolodner J (1993) Case-based reasoning. Morgan Kaufmann
Publishers Inc., San Francisco
24. Koza JR (1989) Hierarchical genetic algorithms operating on populations of computer programs. In: International joint conference
on artificial intelligence. Morgan Kaufman Publishers
25. Koza JR (1991) Evolution and co-evolution of computer programs
to control independent-acting agents. In: From animals to animats:
proceedings of the first international conference on simulation of
adaptive behavior
26. Koza JR (1992) The genetic programming paradigm: genetically breeding populations of computer programs to solve problems. Dynamic, genetic and chaotic programming. Wiley, London,
pp 201–321
27. Koza JR (1992) Hierarchical automatic function definition in
genetic programming. Foundations of genetic algorithms, vol 2.
Morgan Kaufmann, San Francisco, pp 297–318
28. Krasnogor N (2002) Studies on the theory and design space of memetic algorithms. PhD, Faculty Comput Math Eng Bristol, UK,
University West of England
29. Krasnogor N, Blackburne B, Hirst JD, Burke EK (2002) Multimeme algorithms for the structure prediction and structure comparison of proteins. In: Proc. parallel problem solving from nature.
Lecture notes in computer science. Springer, Heidelberg
30. Krasnogor N, Gustafson S (2004) A study on the use of self-generation in memetic algorithms. Nat Comput 3(1):53–76
31. Krasnogor N, Smith J (2005) A tutorial for competent memetic
algorithms: model, taxonomy, and design issues. Evol Comput
IEEE Trans 9(5):474–488
32. Kuncheva LI, Jain LC (2000) Designing classifier fusion systems
by genetic algorithms. Evol Comput IEEE Trans 4(4):327–336
33. Land MWS (1998) Evolutionary algorithms with local search for
combinatorial optimization. University of California, California
34. Lee JT, Lau E, Yu-Chi H (2001) The Witsenhausen counterexample: a hierarchical search approach for nonconvex optimization
problems. Automat Control IEEE Trans 46(3):382–397
35. Lenat D, Guha RV (1989) Building large knowledge-based systems. Addison-Wesley, Reading
36. Lim M-H, Gustafson S, Krasnogor N, Ong Y-S (2009) Editorial to
the first issue. Memetic Comput 1(1)
37. Lin S, Kernighan BW (1973) An effective heuristic algorithm for
the traveling salesman problem. Oper Res 21(2):498–516
38. Merz P (2004) Advanced fitness landscape analysis and the
performance of memetic algorithms. Evol Comput 12(3):303–325
39. Merz P, Freisleben B (1997) Genetic local search for the TSP: new
results. IEEE Conf Evol Comput
40. Meuth RJ, Wunsch DC II (2008) Divide and conquer evolutionary
Tsp solution for vehicle path planning. In: Congress on evolutionary computation (WCCI’08)

99
41. Milano M, Roli A (2004) MAGMA: a multiagent architecture for
metaheuristics. Syst Man Cybern Part B IEEE Trans 34(2):925–
941
42. Minsky M (1986) The society of mind. Simon & Schuster Inc,
New York
43. Moscato P (1989) On evolution, search, optimization, genetic algorithms and martial arts: towards memetic algorithms, caltech concurrent computation program, C3P Report, 826
44. Mulder S, Wunsch DC (2003) Million city traveling salesman problem solution by divide and conquer clustering with adaptive resonance neural networks. Neural Netw
45. Neri F, Toivanen J, Cascella GL, Ong Y (2007) An adaptive multimeme algorithm for designing HIV multidrug therapies. IEEE
ACM Trans Comput Biol Bioinform 4(2):264
46. Nguyen HD, Yoshihara I, Yamamori K, Yasunaga M (2000) Modified edge recombination operators of genetic algorithms for the
traveling salesman problem. In: 26th Annual conference of the
IEEE industrial electronics society
47. Nguyen HD, Yoshihara I, Yamamori K, Yasunaga M (2007) Implementation of an effective hybrid GA for large scale traveling salesman problems. IEEE Trans Syst Man Cybern Part B 37(1):92–99
48. Nguyen Q-H, Ong Y-S, Lim M-H (2008) Non-genetic transmission
of memes by diffusion. In: 10th Annual conference on genetic and
evolutionary computation (GECCO’08), Atlanta, GA
49. Nguyen QH, Ong YS, Krasnogor N (2007) A study on the design
issues of memetic algorithm IEEE congress on evolutionary computation singapore. IEEE 2390–2397
50. Norman MG, Moscato P (1989) A competitive and cooperative
approach to comple combinatorial search, caltech concurrent computation program, C3P Report 790
51. O’Neill M, Ryan C (1999) Automatic generation of high level functions using evolutionary algorithms. In: 1st International workshop
on soft computing applied to software engineering. Limerick University Press, Limerick
52. O’Neill M, Ryan C (2001) Grammatical evolution. IEEE Trans
Evol Comput 5(4):349–358
53. Ong Y-S, Lim M-H, Zhu N, Wong K-W (2006) Classification of
adaptive memetic algorithms: a comparative study. IEEE Trans
Syst Man Cybern Part B 36(1)
54. Ong YS, Keane AJ (2004) Meta-Lamarckian learning in memetic
algorithms. IEEE Trans Evol Comput 8(2):99–110
55. Ong YS, Nair PB, Keane AJ (2003) Evolutionary optimization
of computationally expensive problems via surrogate modeling.
AIAA J 41(4):687–696
56. Ong YS, Nair PB, Lum KY (2006) Max-Min surrogate-assisted
evolutionary algorithm for robust aerodynamic design. IEEE Trans
Evol Comput 10(4):392–404
57. Poli R (2001) Exact schema theory for genetic programming and
variable-length genetic algorithms with one-point crossover. Genet
Program Evolvable Mach 2(2):123–163
58. Rosca JP (1995) Genetic programming exploratory power and the
discovery of functions. Conference on Evolutionary Programming.
MIT Press, Cambridge
59. Rumelhart DE (1980) Schemata: the building blocks of cognition.
Theoretical issues in reading and comprehension. B. B. R.J. Sprio,
& W.F. Brewer, Erlbaum
60. Shahaf D, Amir E (2007) Towards a theory of AI completeness.
In: 8th Interational symposium on logic formalizations of commonsense reasoning
61. Smart W, Zhang M (2004) Applying online gradient descent
search to genetic programming for object recognition. In: Second
workshop on Australasian information security, data mining
and web intelligence, and software internationalisation, Dunedin,
New Zealand
62. Smith JE (2007) Coevolving memetic algorithms: a review and
progress report. IEEE Trans Syst Man Cybern Part B 37(1):6–17

123

100
63. Tang J, Lim MH, Ong YS (2007) Diversity-adaptive parallel memetic algorithm for solving large scale combinatorial optimization
problems. Soft Comput 11(9):873–888
64. Topchy A, Punsch WF (2001) Faster genetic programming based
on local gradient search of numeric leaf values. Genet Evol Comput
Conf
65. Tsai H-K, Yang J-M, Kao C-Y (2002) Solving traveling salesman
problems by combining global and local search mechanisms. Conf
Evol Comput
66. Tsai H-K, Yang J-M, Kao C-Y (2004) An evolutionary algorithm
for large traveling salesman problems. IEEE Trans Syst Man
Cybern Part B 34(4):1718–1729
67. Ullah ASSMB, Sarker RA, Cornforth D, Lokan C (2007) An agentbased memetic algorithm (AMA) for solving constrained optimazation problems. In: IEEE congress on evolutionary computation,
Singapore
68. Wang H, Wang D, Yang S (2009) A memetic algorithm with adaptive hill climbing strategy for dynamic optimization problems. Soft
Comput

123

Memetic Comp. (2009) 1:85–100
69. Wang L, Maciejewski AA, Seigel HJ, Roychowdhury VP (1998) A
comparitive study of five parallel genetic algorithms using the traveling salesman problem. In: First merged international conference
and symposium on parallel and distributed processing
70. Wills LM, Kolodner J (1994) Towards more creative case-based
design systems. In: Proceedings of the twelfth annual national conference on artificial intelligence (AAAI-94):50–55
71. Woldpert DH, Macready WG (1997) No free lunch theorms for
optimization. IEEE Trans Evol Comput 1(1):67–82
72. Wunsch DC, Mulder S (2003) Using adaptive resonance theory
and local optimization to divide and conquer large scale traveling
salesman problems. Int Joint Conf Neural Netw
73. Xin Y (1999) Evolving artificial neural networks. Proc IEEE
87(9):1423–1447
74. Xu R, Wunsch DII (2005) Survey of clustering algorithms. Neural
Netw IEEE Trans 16(3):645–678

Computational Intelligence Meets the NetFlix Prize
Ryan J. Meuth, Paul Robinette, Donald C. Wunsch II

Abstract— The NetFlix Prize is a research contest that will
award $1 Million to the first group to improve NetFlix’s movie
recommendation system by 10%. Contestants are given a
dataset containing the movie rating histories of customers for
movies. From this data, a processing scheme must be developed
that can predict how a customer will rate a given movie on a
scale of 1 to 5. An architecture is presented that utilizes the
Fuzzy-Adaptive Resonance Theory clustering method to create
an interesting set of data attributes that are input to a neural
network for mapping to a classification.
I.

INTRODUCTION

I

n the media industry, the ability to suggest products to
customers is critical to remain competitive. The accurate
suggestion of products can lead to greatly improved
customer satisfaction as well as expanded sales and customer
retention. To online video rental, suggestion is crucial to the
continued operation of a company, as these suggestions drive
the growth of sales, as customers are exposed to new and
interesting media that they would have never otherwise
selected.
The NetFlix Prize is an open competition awarding a $1
million prize to the first team able to develop a rating
prediction system that beats the existing CINEMATCH
rating system by 10%. Over 2700 teams have participated in
the competition in the first year, with the top team only
achieving a 8.5% improvement[1].

test set where the ratings have been removed from the
triplets.
Since the dataset is so large, initial development has been
performed on a small subset of the data, containing the
ratings of 1000 users over the top 100 movies. This dataset
is still significant, containing over 28,000 records. This
allows rapid development of the data mining scheme while
providing a benchmark to the total dataset.
The primary data table contains 28,181 entries, and each
entry represents a single rating of one movie by one
customer. Each entry includes the attributes movie_id,
customer_id, rank, and rank_date. movie_id uniquely
identfies one of 100 movies covered by this data.
customer_id uniquely identifies one of 1,000 customers as
the source of the rating. rank is a value in [1,5], with 5 being
the most positive rating, and rank_date gives the time the
rating was submitted.
The second table has 100 entries over three attributes,
movie_id, title, and release_date, one entry for each unique
movie. The title is a free text attribute.
The data has the following properties:

Many of the top teams utilize a collective filtering approach,
combining the weighted output of several, even hundreds of
models, in the case of the top rated team, to produce their
predictions[2].
II. DATA ANALYSIS
The full Netflix dataset consists of 100 million anonymous
ratings of 480 thousand customers over nearly 18 thousand
movie titles. The data set consists of customer id, movie id
and rating triplets. The ratings are on a scale of 1 to 5,
where 1 is extremely poor, and 5 is excellent. Several test
sets are provided, as well as a 2.8 million record qualifying

Figure 1. Distribution of the number of rankings for each
movie. This shows there is a wide distribution about the
mean of 281 rankings per movie.

Manuscript received December, 2007.
Ryan Meuth, Paul Robinette and Donald C. Wunsch II are with the
Applied Computational Intelligence Laboratory, Missouri University of
Science and Technology, Rolla, MO, 65401 USA (e-mail:
rmeuth@mst.edu, pmrmq3@mst.edu and dwunsch@mst.edu, respectively).

686
c
978-1-4244-1821-3/08/$25.002008
IEEE

Figure 2. Distribution of Rank Average by Movie. Note that
most ranks are very close to the average of 3.7.
There are 28,181 total rankings across all movies and
customers, with an average of 281 ranks per movie, at a
standard deviation of 96 ranks. The average movie rank
value is 3.7, with a standard deviation of 1.

900
800
700
600
500
400
300
200
100
0

III. ADDITIONAL DATA SOURCES
Additional data has been collected from the Internet Movie
Database utilizing a web-crawler, for each of the 100
movies.
This additional data contains detailed information on each
movie of interest. This data includes, for each film, MPAA
rating, directors, actors, genres, and box office gross. The
goal is to focus on individual Netflix user behavior, and it is
possible that several Netflix users give a particular movie a
variety of ratings.
IV. DATA TRANSFORMATION

36 36
63 52
0
36 .00 5
73 59
36 5.01 9
84 19
36 0.0 8
94 17
5 9
37 .02 6
05 39
37 0.02 5
15 99
5
37 .03 4
26 59
0.
3
37 041
36 92
37 5.
47 04
0 7
37 .05 9
57 38
5
37 .05 9
68 98
0
37 .06 8
78 58
37 5.0 7
89 71
0 8
37 .07 6
99 78
5
38 .08 4
10 38
38 0.08 3
20 98
5
2
38 .095
3
8
38 10. 1
41 10
1
38 5.10 8
52 77
0
38 .11 8
62 37
5.
11 7
97
6

Frequency

Movie Rank Properties

Figure 5. Distribution of Rank Average by Customer. Again,
note that most customers rank movies very close to the
average of 3.7.

Date of Rating

Figure 3. Distribution of Rankings by Date.
The clear majority of rankings were submitted in the latest
two years of the time span covered by the data.

For the MPAA ratings, a scale was assigned to map from a
rating to a number. The scale is as follows: 1=G, 2=PG,
3=PG-13, 4=R. This allows the analysis method to directly
handle the MPAA ratings.
The data was formatted so that string-based data was re-cast
as numerical data. This aids in the ability for our analysis
methods to process the data. For example, instead of a list of
actors for each movie, the top 20 most popular actors are
selected, and 1 attribute was added for each movie that
correspond to whether or not an actor in the top 20 starred in
a given movie. For genre, 12 attributes were added to each
movie, indicating whether or not a movie belonged in that
genre. Attributes on average and standard deviation of
ratings for each movie were also added. These attributes
were also collected for how each user rated movies.
V. MODELING ARCHITECTURE

Figure 4. Distribution of Customer Ranks. Customers
ranked 28 movies on average, with a standard deviation of
14.

The modeling technique that has been implemented is a
combination of the Fuzzy ART Clustering Method,
parameter optimization, and Back-propagation neural
networks.

2008 International Joint Conference on Neural Networks (IJCNN 2008)

687

Figure 6 – Overview of Modeling Architecture
The modeling architecture consists of a Fuzzy-ART unit
providing input to a back-propagation trained neural
network. The input data set is divided into two groups – user
data and movie data. The movie data is clustered utilizing
the Fuzzy-ART unit into categories based on the movie’s
genre, MPAA rating, Box office grosses and other
parameters. For each movie in the database, rather than
using only the category that the movie best matches, a fuzzy
category membership vector is produced. For example, the
movie “The Terminator” may be most strongly associated
with other action movies, but it will hold some similarity
with science fiction movies. This additional information is
useful, and can be used to paint a more detailed picture of
the customer preferences
.
For each customer, a movie category frequency is calculated
based on the customer’s viewing history. This frequency is
calculated by accumulating the fuzzy membership vectors of
the movies in a viewer’s rating history, weighted by the
user’s rating of that movie. Then the accumulated history is
normalized to the 1-0 domain using min-max scaling. The
weighting of the membership vectors is intended to model
the customer’s selection criteria, so that characteristics of
movies that have historically appealed to the customer are
emphasized in the frequency, and vice versa for movies that
the customer did not like.
The modeling method assumes that both a large and diverse
body of movies, customers, and customer histories exist.
Though this is the case for both the number of customers and
the number of movies, the customer rating histories are not
always extensive. New customers with small viewing
histories may be misclassified by the system, so a separate
method may be needed to handle these cases. Fortunately,
all customers in the training set have a viewing history of 10
movies or greater, with an average of 25 movies.
VI. MODELING ARCHITECTURE PSEUDO-CODE
'ŝǀĞŶ͕ƚŚĞƐĞƚŽĨĂůůƵƐƚŽŵĞƌƐĂŶĚĐŝƐĂŶĞůĞŵĞŶƚŽĨ͘

'ŝǀĞŶ ,;ĐͿ͕ ƚŚĞ ^Ğƚ ŽĨ DŽǀŝĞͲZĂƚŝŶŐ WĂŝƌƐ ĨŽƌ ĐƵƐƚŽŵĞƌ Đ͕
ǁŚĞƌĞ Ś;ĐͿ ŝƐ ĂŶ ĞůĞŵĞŶƚ ŽĨ ,;ĐͿ͘  ĂĐŚ Ś;ĐͿ ĐŽŶƚĂŝŶƐ ƚǁŽ
ĞůĞŵĞŶƚƐ͕ Ă ŵŽǀŝĞ / ũ͕ ĂŶĚ ĂŶ ŝŶƚĞŐĞƌ ƌĂƚŝŶŐ ƌ͕ ǀĂůƵĞĚ
ďĞƚǁĞĞŶϭĂŶĚϱ͘

688

'ŝǀĞŶ W͕ ƚŚĞ ƐĞƚ ŽĨ Ăůů ŵŽǀŝĞ ƉƌŽƉĞƌƚŝĞƐ͕ ǁŚĞƌĞ Ɖ ŝƐ ĂŶ
ĞůĞŵĞŶƚŽĨW͘

'ŝǀĞŶ ĨƵŶĐƚŝŽŶ ŵ с &ƵǌǌZd;Ɖ;ũͿͿ ǁŚŝĐŚ ƌĞƚƵƌŶƐ ƚŚĞ ĨƵǌǌǇ
ŵĞŵďĞƌƐŚŝƉǀĞĐƚŽƌŽĨƚŚĞŵŽǀŝĞǁŝƚŚ/ũ͘

>Ğƚ D ďĞ ƚŚĞ ƐĞƚ ŽĨ ĨƵǌǌǇ ŵĞŵďĞƌƐŚŝƉ ǀĞĐƚŽƌƐ ǁŝƚŚ ŵ ĂŶ
ĞůĞŵĞŶƚŽĨD͘

>Ğƚ & ďĞ ƚŚĞ ƐĞƚ ŽĨ ǀŝĞǁŝŶŐ ĨƌĞƋƵĞŶĐŝĞƐ ƚŽ ďĞ ĐĂůĐƵůĂƚĞĚ͕
ǁŝƚŚƐŝǌĞͮͮĂŶĚůĞƚĨďĞĂŶĞůĞŵĞŶƚŽĨ&͘

>ĞƚsďĞƚŚĞƐĞƚŽĨƚƌĂŝŶŝŶŐǀĞĐƚŽƌƐ͕ǁŝƚŚdƚĂƌŐĞƚǀĂůƵĞƐ͘>Ğƚ
ǀďĞĂŶĞůĞŵĞŶƚŝŶs͕ĂŶĚƚĂŶĞůĞŵĞŶƚŝŶd͘

&Žƌ ĞĂĐŚ Đ ŝŶ ͕ ĨŝŶĚ ǀĞƌĂŐĞ ĂŶĚ ^ƚĂŶĚĂƌĚ ĚĞǀŝĂƚŝŽŶ ŽĨ
ZĂƚŝŶŐƐ͕^Đ͘

&Žƌ ĞĂĐŚ Ɖ ŝŶ W͕ ĨŝŶĚ ǀĞƌĂŐĞ ĂŶĚ ^ƚĂŶĚĂƌĚ ĚĞǀŝĂƚŝŽŶ ŽĨ
ZĂƚŝŶŐƐ͕^Ɖ͘

&ŽƌĂĐŚƉŝŶWĂƚƐŽŵĞǀŝŐŝůĂŶĐĞȜ΂
 ŵ;ƉͿс&ƵǌǌZd;ƉͿ
΃


&ŽƌĂĐŚĐŝŶ͕΂
 Ĩ;ĐͿсϬ͖ͬͬ/ŶƚŝĂůŝǌĞsŝĞǁŝŶŐ&ƌĞƋƵĞŶĐǇ
 &ŽƌĂĐŚŚ;ĐͿŝŶ,;ĐͿ΂
  ŵ;Ɖ;Ś;ĐͿ͘ũͿс&ƵǌǌZd;Ɖ;Ś;ĐͿ͘ũͿͿ͖
  Ĩ;ĐͿсĨ;ĐͿнŚ;ĐͿ͘ƌΎŵ͖ͬͬhƉĚĂƚĞsŝĞǁŝŶŐ&ƌĞƋƵĞŶĐǇ
 ΃
 Ĩ;ĐͿсͮͮĨ;ĐͿ͖ͮͮͬͬEŽƌŵĂůŝǌĞ
΃

&ŽƌĂĐŚĐŝŶ΂
&ŽƌĞĂĐŚŚ;ĐͿŝŶ,;ĐͿ΂
ŽŶƐƚƌƵĐƚ ǀ;Ś;ĐͿͿ ďǇ ĐŽŶĐĂƚĞŶĂƚŝŶŐ ƚŚĞ ĨŽůůŽǁŝŶŐ
ĞůĞŵĞŶƚƐ͗
 Ĩ;ĐͿ͕ŵ;Ɖ;Ś;ĐͿ͘ũͿͿ͕^Đ;ĐͿ͕^Ɖ;Ś;ĐͿ͘ũͿͿ͖
/ĨdƌĂŝŶŝŶŐ
   ƚсŚ;ĐͿ͘ƌ͖
 ΃
΃

/ĨƚƌĂŝŶŝŶŐƵƐĞsĂŶĚdƚŽƚƌĂŝŶƚŚĞŶĞƚǁŽƌŬ͕ŽƚŚĞƌǁŝƐĞĂƉƉůǇ
sƚŽƚŚĞŶĞƚǁŽƌŬŽďƚĂŝŶĂƐĞƚŽĨƉƌĞĚŝĐƚŝŽŶƐ͘
VII. FUZZY ADAPTIVE RESONANCE THEORY
Adaptive resonance theory (ART) was developed by
Carpenter and Grossberg as a solution to the plasticity and
stability dilemma, i.e., how adaptable (plastic) should a
learning system be so that it does not suffer from
catastrophic forgetting of previously-learned rules[3-5]. ART
can learn arbitrary input patterns in a stable, fast, and self-

2008 International Joint Conference on Neural Networks (IJCNN 2008)

organizing way, thus overcoming the effect of learning
instability that plagues many other competitive networks.
ART is not, as is popularly imagined, a neural network
architecture. It is a learning theory hypothesizing that
resonance in neural circuits can trigger fast learning.

Layer F2

Reset

…
W

Layer F1

…

ȡ
Orienting Subsystem

Input Pattern I

Figure 7. Topological structure of Fuzzy ART. Layers F1
and F2 are connected via adaptive weights W. The
orienting subsystem is controlled by the vigilance
parameter ȡ.
Fuzzy ART (FA) incorporates fuzzy set theory into ART and
extends the ART family by being capable of learning stable
recognition clusters in response to both binary and realvalued input patterns with either fast or slow learning. The
basic FA architecture consists of two-layer nodes or neurons,
the feature representation field F1, and the category
representation field F2, as shown in Fig. 1. The neurons in
layer F1 are activated by the input pattern, while the
prototypes of the formed clusters are stored in layer F2. The
neurons in layer F2 that are already being used as
representations of input patterns are said to be committed.
Correspondingly, the uncommitted neuron encodes no input
patterns. The two layers are connected via adaptive weights,
Wj, emanating from node j in layer F2. After layer F2 is
activated according to the winner-take-all competition, which
occurs between a certain number of committed neurons and
one uncommitted neuron, an expectation is reflected in layer
F1 and compared with the input pattern. The orienting
subsystem with the pre-specified vigilance parameter ȡ
(0ȡ1) determines whether the expectation and the input
pattern are closely matched. If the match meets the vigilance
criterion, weight adaptation occurs, where learning starts and
the weights are updated. This procedure is called resonance,
which suggests the name of ART. On the other hand, if the
vigilance criterion is not met, a reset signal is sent back to
layer F2 to shut off the current winning neuron, which will
remain disabled for the entire duration of the presentation of
this input pattern, and a new competition is performed
among the remaining neurons. This new expectation is then
projected into layer F1, and this process repeats until the
vigilance criterion is met. In the case that an uncommitted
neuron is selected for coding, a new uncommitted neuron is
created to represent a potential new cluster.

FA exhibits fast, stable, and transparent learning and atypical
pattern detection. The Fuzzy-ART method has the benefit of
being a highly efficient clustering method, with a linear
runtime complexity.

VIII. ARTIFICIAL NEURAL NETWORKS
Artificial neural networks (ANN) attempt to capture the
adaptability of biological neurons in a mathematical model
for information processing.
Artificial Neural networks
consist of a series of layers of nodes, known as artificial
neurons, connected by weights. Each node in a layer is
connected to every node in the previous layer by a series of
weights. The network operates by applying a vector to the
input of the network. At each node in the first layer, the
input vector is multiplied by the node’s set of weights, and
these values are summed together and a transfer function is
applied to get an activation level for the node. Typically the
transfer function is a logarithmic sigmoid or linear function.
This process of accumulating weighted values and
computing activations is repeated through the layers of the
network until the output layer is reached.
Neural networks are not programmed; rather they are trained
using one of several kinds of algorithms. The typical
structure of a training algorithm starts at the output of the
network, calculating an error between the actual network
output and a target output for a given input vector. This
error is used to adjust the weights of the network based on
the amount of influence that a given weight had on the
output. This process repeats from the output side to the
input side, and is thus known as error back-propagation.
There are many methods for how to make these weight
adjustments.

IX. PARAMETER SELECTION
The parameters of the Fuzzy-ART unit and the neural
network are found empirically. For the Fuzzy-ART unit, this
is a simple procedure, where a range of vigilances are
applied, and the resulting number of categories is plotted.
Ranges of vigilance values where the number of categories
remains constant indicate a natural divide in the data at that
sensitivity level.

2008 International Joint Conference on Neural Networks (IJCNN 2008)

689

X. RESULTS

100
90

The modeling architecture is trained using 50% of all
customer records, but using all available movie data. 25% of
the data is used to determine when to stop training iterations
on the neural network. The remainder of the data is used to
evaluate the performance of the model.

80

Number of Categories

70
60
50
40

Training
Validation
Test

30

RMS Error

20
10
0

0

0.1

0.2

0.3

0.4

0.5
0.6
Vigilance

0.7

0.8

0.9

1

Figure 8. Movie Data Clustering Profile. The largest
category plateau falls within the vigilance range of 0.5 to
0.55.

0

10

0

10

20

30
Epoch

40

50

60

Figure 10. An example training session.
The vigilance of 0.55 is chosen to produce approximately 15
clusters.

Due to the models non-deterministic properties, the model
was tested over 30 runs, using randomly selected sub-sets
from the given body of data. Evaluated against the test datasets, the average RMS Error of the Model is 0.8769, with a
standard deviation of 0.005. The minimum RMS Error of
the runs was 0.8663. It is expected that the deployed
performance of the system would be comparable.

XI. CONCLUSION

Figure 9. Movie Category Distribution
For the neural network, however, few methods exist for
quickly determining optimal parameters, so the architecture
and learning parameters are found by trial and error. The
architecture was chosen to be a three layer design, with
sigmoid activation function for the hidden layer, and a linear
output layer. The hidden layer size was chosen to be twice
the input layer size, and the output layer is a single node.
This is a typical design for function approximation. The
default training values of MATLAB neural network toolbox
were used.
The Resilient Back-propagation training
algorithm was used for a balance of speed and accuracy.
The validation data set was used to detect when to stop
training. When the mean-squared error of the validation set
stays the same or rises over 3 epochs, training is terminated.

690

The NetFlix prize is a highly challenging competition, with
such a large dataset and highly non-linear relationship
between a user’s rating history and their future ratings that
traditional data analysis methods often fall far short.
An architecture is presented that combines several
computational intelligence techniques, as well as novel
attribute creation that is able to improve on the accuracy of
the existing system with only a linear complexity to the size
of the dataset.
With an expected performance of 0.8769 RMS Error, the
system only achieves a 7.8% improvement over the Netflix’s
CINEMATCH system. This does not satisfy the competition
objective of 10% improvement, but it is a significant step
towards this goal. Placed on the Netflix Prized leader-board,
this system would fall within the Top 10.
Future development of the system can include the
development of new attributes, particularly related to movie
content and plot development. Additional information about
customers may be useful, such as the region of residence, i.e.

2008 International Joint Conference on Neural Networks (IJCNN 2008)

rural, suburban, urban, etc. Also, marketing information on
a movies’ target demographic may be helpful, as well as the
utilization of more sophisticated modeling techniques such
as time-series prediction.
Many other groups have utilized the weighted output of
several, sometimes hundreds of models to achieve higher
accuracy. Development in this direction may prove useful.
Members of our group will be registering as a development
team for the full Netflix Prize challenge.

REFERENCES
[1]
[2]

[3]

[4]

[5]

"NetFlix Prize Website." vol. 2007.
R. Bell, Y. Koren, and A. C. Volinsky, "Modeling
relationships at multiple scales to improve accuracy
of large recommender systems " in Proceedings of
the 13th ACM SIGKDD international conference
on Knowledge discovery and data mining, 2007.
G. A. Carpenter and S. Grossberg, "Fuzzy ART:
Fast Stable Learning and Categorization of analog
patters by an adaptive resonance system," Neural
Networks, vol. 4, pp. 759-771, 1991.
G. A. Carpenter, S. Grossberg, and D. B. Rosen,
"ART 2-A: An adaptive resonance algorithm for
rapid category learning and recognition," Neural
Networks, pp. 493-504.
S. Grossberg and G. A. Carpenter, "A massively
parallel architecture for a self-organizing neural
pattern recognition machine," Computer Vision,
Graphics, and Image Processing, vol. 37, pp. 54115, 1987.

2008 International Joint Conference on Neural Networks (IJCNN 2008)

691

Proceedings of International Joint Conference on Neural Networks, Atlanta, Georgia, USA, June 14-19, 2009

An Agent-Based Computational Model of a
Self-Organizing Project Management Paradigm for
Research Teams
Paul Robinette, John Seiffertt, Ryan Meuth, Ryanne Dolan, Donald Wunsch
Abstract-We propose a new research organization management paradigm to increase throughput of projects by allowing researchers to choose their own projects through self-organization.
Our methods draw upon the field of Agent-Based computational
social science where Artificial Life and simulated societies have
been used to study complex systems including economies and
financial markets. Modeling the researchers as individual agents,
we simulate our new management structure against a more
traditional organization where the researchers are broken into
departments based on their skills and assigned projects by
management. Our results, measuring the amount of time it takes
a research organization to serve a given number of contracts,
show promise in the less hierarchical approach.
I. INTRODUCTION

T

RADITIONAL business organizations assign employees
to tasks with a management-heavy top-down approach.
A direction will be identified by an executive, turned into
a high-level set of deliverables by a department head, and
then refined into work packages by several layers of middle
management. The last middle manager typically assigns some
of his employees to the project and picks one of them to be a
project manager. This process requires considerable overhead
in the form of managers and administrators and requires managers several layers removed from the actual project to make
implementation decisions that affect employees not directly
under their control.
Some attempts have been made to break these traditional
practices by giving project managers and employees more
control. These efforts have mostly concentrated on applying
agile software development practices to project management.
Agile practices focus on individuals, customers and adapting to
change [1]. Typical methods give developers more control by
allowing them to pick functions they would like to implement
rather than relying on managers to decide which programmer
is best for which job. These practices were created by software
developers who decided software development is considerably
different from other forms of engineering and thus requires a
considerable change in management structure [2].
Research organizations are considerably different from both
software development and traditional engineering organizations. Researchers are typically comprised of engineers and
Paul Robinette, John Seiffertt, Ryan Meuth, and Donald Wunsch are with
the Applied Computational Intelligence Laboratory, Missouri University of
Science and Technology, Rolla, MO USA (email: {pmrmq3, jesOb4, rmeuth,
dwunsch} @mst.edu
Ryanne Dolan is with the Computer Science Department, University of
Missouri, Columbia, MO USA (email: rtdmr6@missouri.edu)

978-1-4244-3553-1/09/$25.00 ©2009 IEEE

scientists who are much more self-directed than typical engineers in a production-driven environment. Unfortunately,
most research organizations are run by large corporations that
attempt to use the same management systems which prove
successful for production-driven departments to organize the
work of the research departments. This management approach
results in researchers being assigned to projects where they
have little interest or little skill and on which their performance
suffers in comparison to their potential productivity level
working on a project better suited to their abilities.
We propose a new paradigm for organizing researchers that
involves self-organization principles from adaptive systems.
Each researcher is assumed to be an intelligent individual who
knows his or her own skills and has enough motivation to find
projects of personal interest. Projects are identified by senior
management and customers. These projects are posted as a list
of deliverables with a reward value for completing the project,
much like a bounty on a freelance contract. Researchers scan
the available projects and sign up for the one that they feel
fits them the best in terms of skills required and individual
interest in the subject. One researcher is required to volunteer
to be the project manager. He or she, with input from the other
researchers on the team, will put together a project plan and
submit it to senior management for review and approval. This
process completely eliminates the need for layers of middle
management for project creation and review.
II. PREVIOUS WORK

A. Agile Software Development Practices Applied to Project
Management

Agile software development methods encourage a collaborative development environment in which each worker is seen
as an intelligent agent capable of making decisions and communicating important information [3]. Each worker follows a
set of rules (depending on the particular strategy employed)
that operate at various timescales: immediate peer-review of
code, continuous testing of software modules, daily meetings, and bi-weekly deadlines, for example. These rules are
designed to increase feedback among workers, management,
and customers, promoting continuous adaptation at every level
of the continuously evolving project. Rather than requiring
a global re-design of the software and reorganization of the
team each time a new feature or requirement is presented
by a customer, agile methods are designed to accommodate

2693

changing requirements quickly by isolating the effects to small
teams making local and immediate decisions.
Agile methods are regarded as radically different than
traditional top-down design and management methods . This
was a significant hurdle preventing their early adoption by
skeptical managers whose experience and training generally
suggested that progress requires order and strict centralized
control[4] . However, software development is itself radically
different than other fields and requires a nontraditional approach in general. Early software development failures led to
the exploration of alternative approaches, and agile methods
today are widely adopted. In particular, the inability of topdown management and traditional engineering design methods
to cope with changing software requirements and fast-paced
development cycles signaled a need for something new. These
problems arise naturally due to the intrinsic complexity of
modern software systems and the difficulty of designing them
beforehand.
By adopting adaptive rules and encouraging feedback, agile
methods alleviate the burden of an exhaustive initial design and
subsequent re-designs. This paper introduces a similar strategy
for the management of research teams which is designed to
increase productivity when management might not know the
optimal allocation of researchers. In both cases, the top-down
management approach is rejected in favor of self-organizing
teams of intelligent workers making local strategic decisions .
B. Adaptive Resonance Theory

Adaptive Resonance Theory (ART) was developed by
Grossberg[5] as a solution to the plasticity and stability
dilemma which asks how adaptable (plastic) should a learning
system be so that it does not suffer from catastrophic forgetting of previously-learned rules (stability). Computational
implementations of ART can learn arbitrary input patterns
in a stable, fast, and self-organizing way, thus overcoming
the effect of learning instability that plagues many other
competitive networks [6][7][8][9].
The basic ART unsupervised neural network architecture
consists of two-layers of nodes, the feature representation field
Fl, and the category representation field F2, as shown in
Figure I. The nodes in layer FI are activated by the input
pattern, while the prototypes of the formed clusters are stored
in layer F2. The nodes in layer F2 that are already being used
as representations of input patterns are said to be committed.
Correspondingly, the uncommitted node encodes no input
patterns. The two layers are connected via adaptive weights,
Wj, emanating from node j in layer F2. After layer F2 is
activated according to the winner-take-all competition among
a certain number of committed nodes and one uncommitted
node, an expectation is reflected in layer FI and compared
with the input pattern. The orienting subsystem with the prespecified vigilance parameter p (0 ::::: p ::::: 1) determines
whether the expectation and the input pattern are closely
matched. If the match meets the vigilance criterion , then
learning occurs and the weights are updated. This procedure
is called resonance, which suggests the name of ART. On

the other hand, if the vigilance criterion is not met, a reset
signal is sent back to layer F2 to shut off the current winning
neuron, which will remain disabled for the entire duration of
the presentation of this input pattern, and a new competition is
performed among the remaining nodes. This new expectation
is then projected into layer FI, and this process repeats until
the vigilance criterion is met. In the case that an uncommitted
node is selected for coding, a new uncommitted node is created
to represent a potential new cluster.

Layer F2

I!¥tPaI:lemI

Figure I. Topological structure of ART. Layers FI and F2 are connected via
adaptive weights W. The orienting subsystem is controlled by the vigilance
parameter p.

T( .)
J
p 2:

= Ix 1\ wi l

Iwil

IX l\ w il

[z]

(I)
(2)

In Equations I and 2, the norm being taken is the L1
norm and the meet operation represents the Fuzzy AND logic
operator and is implemented by taking the element-by-element
minimum of the two vectors. In simpler terms, the category
match phase of the ART process measures the proportion of
the input vector that is captured by the template, known as the
"bottom-up" activation. Similarly, the vigilance match stage
is a measure of how well the template is captured by the
input vector, known as "top-down" activation. A best match,
or "resonance," is said to occur when the top-down activation
satisfies the vigilance criterion .
This bottom-up / top-down resonance property allows ART
to exhibit fast, stable, and transparent learning and atypical
pattern detection. This property can be applied to project
management by representing the projects as templates and the
employees as input vectors. Instead of measuring percentage
match, the system would measure probability of success and
begin contracts with the highest probabilities. For management
to perform an ART-like process, they have to post contracts ,
much like in the self-organizing organization idea above, and
rely on employees to pick projects in a bottom-up fashion.
Management also assigns employees in a top-down fashion,
much like in a traditional organization. Resonance occurs
when management agrees that an employee has the intersection of skills and desire to successfully execute a project
from the business point of view. Only projects that have

2694

sufficient manpower are pursued. This idea is something of a
combination of the self-organizing research organization idea
and a traditional organization.

c.

Computational Social Science

While traditional methods in the study of complex systems
rely on mathematics to analyze governing dynamics, the
emerging field of computational social science [10] is based
on a generative multi-agent modeling framework capable of
demonstrating emergent phenomena which are difficult or
impossible to capture using the classical differential equation
approaches [11]. The approach we take in this paper to
investigate project management techniques falls under the
purview of this new school.
Agent-based computational economics [12] pioneered the
use of computer simulations in the social sciences, and it is
to this field that we mostly look for inspiration in our project
management analysis. Computational economists have studied
financial markets [13], international exchange [14][15], and
can analyze systems which are particularly difficult to model
mathematically, such as those with heterogeneous agents [16].
Also, these artificial societies have been used in modeling the
sustainable development of metropolitan systems [17].
It is a natural step to apply computational intelligence
methods, such as those from self-organizing neural networks
and approximate dynamic programming [18], which has itself
also found application in the modeling of socio-economic
systems [19], to this field of computational social science.
Our construction of a self-organizing managerial structure is
a contribution to this area of research and builds upon the
foundation laid by the field of agent-based computational
modeling of organizations [20].
III. METHODOLOGY
As our management model is designed to optnruze the
productivity of a research organization, we design our agents
to be the researchers themselves. Each agent is represented as a
vector of several values, each corresponding to the researcher's
skill in a category of impact for the organization, such
as software, electrical, computer, mechanical and aerospace
engineering. For simulation purposes, we used 5 such skill
values. These skill measurements can be thought of as weights
towards a particular category like in the ART algorithm. We
will investigate the organization of these agents in two business
structures: a traditional hierarchy and an office built on a
philosophy of self-organization.
Productivity is measured by the successful completion of
research contracts. A contract is represented as a vector of
five "requirements" and one duration value. Each requirement
value corresponds to a skill category. The duration value
measures the duration or difficulty of the project. In order for
a team of researchers to make progress on a contract, the sum
of the skills possessed by the agents must cross the threshold
indicated in the contract's requirement vector.
We initialize a population of researchers with skill levels
distributed uniformly from a low value of 0 to a high value

of 10. In the traditional office, the researchers are divided
into departments based on specialty. The highest-rated agents
in each skill are assigned to the appropriate department as
equitably as possible, with an even amount of researchers in
each department. Notice that some departments will have staff
with non-ideal ratings in the desired skill, just as in real life.
Contracts are assigned to departments based on the highest
skill requirement in a winner-take-all fashion. For example,
a contract with the highest rating in electrical engineering
would be assigned to the electrical engineering department.
The departmental managers, represented in our model by a
greedy optimization algorithm instead of as individual agents,
will select researchers for a project team to service the contract
in a way that accounts for the contract's skill requirements.
The manager selects which researcher to place on the contract
by finding the researcher who reduces the total amount of
missing skill points by the largest amount. This is accomplished by taking the sum of the differences between the
contract's needed skills and the researcher's provided skills.
If, for example, a contract is generated with requirements of
(15, 20, 10, 25, 5) then the manager will pick a researcher
with the skills (10, 8, 2, 9, 2) over a researcher with the
skills (5, 2, 4, 3, 10). As a result of dividing the researchers
into departments and not permitting the departments to work
together, the number of researchers assigned to a team will
be relatively high since reaching the required levels for the
skills not specialized in by the department may require a large
number of low-skilled individuals. We will show that in the
self-organizing management structure this inefficiency is not
as likely to be necessary.

Algorithm 1 Pseudo-code for Traditional Company Simulation
researchers = generateResearchers(number=300,
skills=5)
contracts = generateContracts(number=100,
skills=5)
while(contractsNotComplete(contracts)) :
needWork = []
for d in departments:
needWork[d] = idleResearchers(researchers, d)
contract = getNextContract(dept=d)
assignBestEmployees(contract, needWork(d))

Algorithm 2 Pseudo-code for assignBestEmployees
while(contract.needMoreSkills()) :
contract.addResearcher(
contract.findMinResearcher(fitnessFunction,
researchers))

Algorithm 3 Pseudo-code for fitnessFunction
for i in len (skills) :
totalSkills += contract.skills[i]
-researcher.skills[i]
return totalSkills

2695

For the self-organizing office, the manager algorithm is
not used. Instead, each agent chooses which of the available
contracts to pursue . This decision is based on a compari son
of the contr act's requirements with the agent' s skill levels,
the idea being that an agent will desire to work on a contract
which is best suited for the researcher's own skill set. Available
contract s are posted on a bulletin board and the most senior
agents pick first. If all of the contracts on the board are filled
and there are still more researche rs in need of jobs, then
another contract is posted on the board. In the beginning ,
this gives little choice to junior researchers. For example , if
an available contract with the profile (15, 20, 10, 25, 5) is
presented to an agent with skill set (5, 10, 8, 7, 3), then the
agent would desire that project since the most import ant skill
for it is the one in which the researcher excels . A contract
requiring different skills, such as (20, 2, 10, 10, 20), would
be less attractive to that particular agent. The agent decides
which contr act to select by taking the sum of the differences
between his skills and the skills the contract still needs. This
was inspired by how input patterns are matched with their best
neuron s in ART. A contract cannot proceed until it has all of
the required skills.

Algorithm 4 Pseudo-code for Self Organizing Comp any Simulator

T RA DI TI ONAL

VA RYI NG N UMB ERS OF R ESEA RC HE RS

Num ber of
Researchers

Traditional
Average

Traditional
Standard
Deviation

SelfOrgan izing
Average

SelfOrganizing
Standard
Deviation

300
350
400
450
500
550
600
650
700
750
800
850
900
950
1000

67.10
68.90
65.40
62.30
63.50
54.20
6 1.00
59.30
53.00
54.50
55.30
54.00
53.10
53.30
54.70

9.81
15.71
16.24
10.15
11.96
7.05
11.42
8.06
5.23
6.19
11.87
5.23
3.75
4.14
6.99

39.90
40 .60
40 .90
40 .30
39.90
39.60
40 .70
39.40
40 .00
40 .30
40 .20
39.30
39.80
39.10
40 .10

2.38
1.58
2.08
2.50
1.85
1.51
1.77
1.17
1.41
1.83
1.40
1.57
1.23
1.20
1.52

Traditional

100

Algorithm 5 Pseudo-code for findBestContract
contracts = nonFilledContracts (b b )
return r . f i n dMax Co n t r a c t (
fitnessFunction , c o n t r a c t s)

The performance of each management organization-the
traditional and the self-organizing-is measured by the amount
of time it takes to complete a specified number of contr acts.
IV.

R E S ULTS

vs Self Organizing Research Organization with V arying Number of Researchers

rr----,------,---,-------.--,-------,--,-------n
Traditional

Self Organizing

+

x

80

+

60

~

40

~

~

0

researchers = generateResearchers( n umb e r = 3 0 0,
s kills=5)
contracts = generateContracts (n umb e r = 1 0 0 ,
s kills=5 )
while (contractsNotComplete (c o nt r a c t s ) ) :
bb = getNext25Contracts (c o nt r a c t s )
for r in researchers :
r .contract = r . f i n dBe s t Co nt r a c t (bb )

Table I
vs S EL F O RGA NIZIN G R ESEA RC H O RGANI ZATI O N WI TH

t
I

20

o LL-_
300

--'-_ _-'-_---'-_ _.l..-_--'--_ _' - - _-l..J
400

500

600

700

800

900

1000

Numbe r of Researchers

Figure 2.

Results of varying the number of researchers in simulation

B. Varying Number of Departments
The second simulation held the number of researchers at 300
and the number of contracts at 100, but it varied the number
of skills measured (and thus the numbe r of department s for
the traditional organization) from one to five. The number
of contracts on the bulletin board at one time for the selforganizing organization was 25. The results can be seen in
Table II and Figure 3.
T RA DI TIO NAL

Table \I
vs S ELF O RGA NIZIN G R ESEAR C H O RGA NI ZATI O N WI TH
VARYI NG NU MBERS OF D EPARTM EN TS

A. Varying Number of Researchers

For the first simulation, the number of researchers was
varied to determine if the self-organizing algorithm was better
than the tradition al algorithm and to ensure that the algorithm
was appropriate for several different sized organizations. The
numbe r of contracts was set as one third the number of researchers in each case to give the same time range to complete
each contract. The number of contracts on the bulletin board at
one time for the self-organizing company was 25. The results
can be seen in Table I and Figure 2.

Number of
Departments

Traditional
Average

Traditional
Standard
Deviation

SelfOrganizin g
Average

SelfOrganizing
Standard
Deviation

I
2
3
4
5

26.70
39.70
52.40
54.60
63.00

1.70
4.40
10.60
13.12
39.80

26.30
3 1.40
36.30
37.30
10.82

1.25
2.41
2.26
2.4 1
2.44

2696

Traditional vs Self Organizing Research Organization wit h v arying Numbe r of Departments

100,----,-----,------,-------,------,------,
Traditional
Self Organizing

+
x

80

60

~
o
40

paves the way for more in-depth simulations in the future. We
also see much promise in using agent-b ased computational
models in the analysis of project management techniques
and organizational structures in gener al. Future work includes
more attributes for each agent in order to better simulate
human s and a full implementation of ART as the selection
mechanism.
VII . ACK NOWL EDGM E NTS

20

0"----'-------'--------'--------'--------'-------'
o

Number of Departments

Figure 3.

Results of varying the number of departments in simulation

V. DISCUSSION
In general , the self-organizing research organization performed much better than the traditional organization . When the
number of researchers was changed the average of the results
was approximately 25% to 41% better, depending on which
category was checked. The self-organizing company was very
stable through this test, which was to be expected since the
number of contracts was directly related to the number of
researchers. There is a slight trend in the traditional research
organization results that led to faster completion times as the
number of researchers increased. This is likely due to a greater
mix of skills available in each department.
There is a clear relationship between number of departments and time required for the tradition al organization. When
there was only one department the traditional organization
performed as well as the self-organizing one, but as the
number of departments increased , the time for the traditional
organization to complete the task increased . When only one
skill was required the decision processe s for the traditional
and self-organi zing organizations are remarkably similar-only
the order of execution is different. The traditional organization
tries to find the best person for the next available contract out
of the whole group of researchers while the self-organi zing
organization tries to find the best contract for the next person
in the list. The gap between the two organizations widened
considerably as the tradition al organiz ation was divided into
more departm ents. It is interesting to note that the selforganizing organization performed slightly worse on average
as the number of skills required increased. This was because
it is easy to find the exact skills required when only one skill
is being measured but much harder as more combinations of
skills are required .
VI. CO NCL USIO NS
In simulation, the self-organizing research organization performed as well as or better than the traditional organization.
This lead increased as more skills caused more departments
to be created in the traditional organization. The results show
good promise for the idea that researche rs are more productive
when allowed to choose their own contract. This research

Support from the National Science Foundation, the Missouri University of Science & Technology Intellig ent System s
Center, the Missouri University of Science and Technology
Chancellor's Fellowship, and the M.K. Finley Missouri Endowment , are gratefully acknowledged.
R EFER ENC ES
[I] Beck et aI, "Manifesto for agile software development ," Dec 2008.
http: / /agilemanifesto.org/ .
[2] R. Morien and P. Wongthongtham, "Supporting agility in software development projects - defining a project ontology," Digital Ecosystems and
Technologies. 2008. DEST 2008. 2nd IEEE International Confe rence on,
pp. 229-234, Feb. 2008.
[3] P. Abrahamsson, J. Warsta, M. Siponen, and J. Ronkainen, "New
directions on agile methods: A comparative analysis," in International
Conference on Software Engineering: Proceedings of the 25 th International Conference on Software Engineering: Portland. Oregon , vol. 3,
pp. 244-254, 2003.
[4] D. Karlstrom and P. Runeson, "Combining agile methods with stage-gate
project management," IEEE SOF7WARE, pp. 43--49, 2005.
[5] S. Grossberg, "Adaptive pattern classification and universal recoding, ii:
Feedback, expectation, olfaction, and illusions," Biological Cybernetics,
vol. 23, pp. 187-202, 1976.
[6] G. A. Carpenter and S. Grossberg, "Fuzzy art: Fast stable learning
and categorization of analog patters by an adaptive resonance system,"
Neural Network s, vol. 4, pp. 759-771 , 1991.
[7] G. A. Carpenter, S. Grossberg, and D. B. Rosen, "Art 2-a: An adaptive
resonance algorithm for rapid category learning and recognition," Neural
Networks , pp. 493-504.
[8] G. A. Carpenter and N. Markuzon, "Artmap-ic and medical diagnosis:
Instance counting and inconsistent cases," Neural Netwo rks, vol. II ,
pp. 323- 336, 1998.
[9] S. Grossberg and G. A. Carpenter, "A massively parallel architecture for
a self-organizing neural pattern recognition machine," Computer Vision.
Graphics. and Image Processing, vol. 37, pp. 54-115, 1987.
[10] J. Miller and S. Page, Complex Adaptive Systems: An Introduction to
Computational Models of Social Life. Princeton Studies in Complexity,
Princeton University Press, 2007.
[II] J. Epstein, Generative Social Science: Studies in Agent-Based Computational Modeling. Princeton University Press, 2007.
[12] L. Testafasion and K. Judd, Handbook of Computational Economics:
Agent Based Computational Economics. North-Holland. Amsterdam,
The Netherlands, 2006.
[13] C. Chiarella, M. Gallegati, R. Leombruni, and A. Palestrini, "Asset
price dynamics among heterogeneous interacting agents," Computat ional
Economics, vol. 22, pp. 213-223, Oct-Dec 2003.
[14] R. Ahrens and S. Reitz, "Heterogeneous expectations in the foreign
exchange market: Evidence from daily dmlus dollar exchange rates,"
Journal of Evolutionary Economics, vol. 15, pp. 65- 82, 2005.
[15] J. Arifovic, "The behavior of the exchange rate in the genetic algorithm
and experimental economies," Journal of Political Economy, vol. 104,
pp. 510-541 ,1996.
[16] D. Meyer, A. Karatzoglou, F. Leisch, C. Buchta, and K. Hornik,
"A simulation framework for heterogeneous agents," Computat ional
Economics, vol. 22, Oct-Dec 2003.
[17] F. Wang and S. Tang, "Artificial societies for integrated and sustainable
development of metropolitan systems," IEEE Intelligent Systems, vol. 19,
no. 4, pp. 82-87 .

2697

[18] J. Si, A. Barto, W. Powell, and D. Wunsch, eds., Handbook of Learning and Approximate Dynamic Programming. IEEE Press Series on
Computational Intelligence, 2004.
[19] Y. Aviv and A. Pazgal, "A partially observable markov decision process
for dynamic pricing," Management Science, vol. 51, no. 9, pp. 14001416, 2005.
[20] R. Levitt, "Computational modeling of organizations comes of age,"
Computational and Mathematical Organization Theory, vol. 10, no. 2,
pp. 127-145, 2004.

2698

Application
Notes

Ryan J. Meuth and Donald C. Wunsch II,
Missouri University of Science and Technology, USA
Emad W. Saad and John Vian, The Boeing Company, USA

Memetic Mission Management

M

I. Introduction

any operations require an area
search function, including
search-and-rescue, surveillance,
hazard detection, structure or site
inspection and agricultural spraying.
Furthermore, these area search applications often involve varying vehicle and
environmental conditions. This article
explores using memetic computing to
optimize the behavior of a swarm
of heterogeneous robotic
vehicles executing a
search area coverage
task. Each vehicle is
equipped with a sensing apparatus, and the
swarm must collectively explore an occluded
environment to achieve
a required probability of
detection for each location in the
search area. The problem is further
complicated with the introduction of
dynamic vehicle and environmental
properties, making adaptability a necessary requirement in order to achieve a
high level of mission assurance using
unmanned vehicles. Memetic computing is well suited for this type of application, as it can provide rapid,
high-quality solutions for complex
problems. New memetic methods for
search area decomposition, task allocation and path planning are presented,
with simulated and real-world results
utilizing the Boeing Vehicle Swarm
Technology Laboratory.
Digital Object Identifier 10.1109/MCI.2010.936310

32

The search coverage problem for
multiple heterogeneous vehicles is
unique in that the task is defined in a
general way and must be divided into
sub-tasks, which are then allocated to
each vehicle. The space of these possible
assignments is continuous and increases
exponentially with the size and complexity of the region, as well as with the
quantity and amount of var iation
among vehicles, making the problem
extremely difficult to solve optimally. In the real world,
applications such as automated surveillance and
search-and-rescue, vehicle
and environmental characteristics may be dynamic
due to vehicle failures and
changing weather conditions, so the optimization
methods must be adaptable in real
time in order to maintain the required
probability of detection.
In recent years, there has been a
marked increase in research interests and
activities in the field of memetic computing (MC). One common instantiation of MC refers to hybrid algorithms,
a marriage between population-based
global search (often in the form of an
evolutionary algorithm) coupled with a
cultural evolutionary stage. These
memetic methods have displayed greatly
increased performance in both execution time and quality across many different problem domains [1–8].
The memetic computing algorithms
presented here for task allocation and
path optimization are uniquely designed

IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2010

to operate in real time, enabling adaptation to changing vehicle and environmental characteristics, while balancing
the task load amongst available resources.
These methods leverage the speed and
efficiencies of memetic computing to
seamlessly control and optimize swarms
of heterogeneous vehicles.
These algorithms have been tested in
Boeing’s indoor rapid prototyping testbed that provides a low-cost means for
technology integration, maturation and
demonstration. The test-bed includes
over 20 fully autonomous air and
ground vehicles and utilizes a motion
capture system for indoor localization.
The adaptive area coverage task allocation software was integrated with the
defined test-bed Ethernet interface,
allowing it to exchange waypoint commands and condition and capability data
with the vehicles.
II. Background

As a highly complex problem, multi-vehicle search coverage has been greatly
explored in the literature [9–14]. Additionally, many of the problem sub-components have been analyzed, including
area decomposition, task allocation, and
path optimization. The more general
problem of collective robotics has also
been greatly researched, but continuous
environmental effects have rarely been
considered [15–20].
Several mission-planning architectures have been devised, typically consisting of a mission interpreter, which
reads a standardized representation of
the mission tasks, a task allocation unit,

1556-603X/10/$26.00©2010IEEE

and a planner. These mission-planner
architectures, such as GRAMMPS,
ALLIANCE, MARTHA, M+, and
MURDOCH, have rarely handled heterogeneous vehicles, and they approach
adaptability through continuous
re-planning [15, 21–24]. Also, the task
of search area coverage is largely
unexplored by end-to-end missionplanning architectures.
For large continuous tasks, such as
search area coverage, it is desirable to
decompose the problem space to reduce
the complexity of the problem. Several
methods have been devised to accomplish this, including grid division methods of various geometries and Voronoi
divisions [14, 25, 26]. These methods
work well for uniform environments
and simple sensing apparatuses, but they
do not account for the interaction of the
vehicle’s sensor with the environment.
Task allocation is concerned with
finding the optimal matching of tasks to
vehicles based on vehicle characteristics,
task requirements, and a vehicle’s current
load. Gerkey provides a good overview
of several multi-robot task allocation
architectures and analyzes their run-time
complexity and optimality [25]. Many of
these architectures utilize market-based
methods where vehicles ‘bid’ on available
tasks, and the vehicle with the lowest bid
wins. These methods are distributed and
robust but are often non-optimal as they
are greedy methods operating only on
local information [27, 28].
III. Mission-Planning Architecture

The problem of optimal search coverage
using multiple heterogeneous vehicles
can be decomposed into two coupled
problems, that of high-level task allocation for each vehicle, and low-level route
optimization for the allocated task. At
the highest level, vehicles must be coordinated to ensure that the total search
space is covered in minimal time. This
coordination takes the form of task allocation for each vehicle in the search
space. Here, the task of occluded searcharea coverage is explored for multiple
heterogeneous vehicles. In scenarios
where environments and vehicle capabilities are variable, the task allocation

Memetic computing …can provide rapid, high-quality
solutions for complex problems.
must be adaptable and efficient to handle
these changing situations in real time.
Given a region to be searched and a
vehicle with associated characteristics
and capabilities, the task of planning a
path through the region is extremely
complex if all points in the region are
to be considered as part of a possible
coverage path for a vehicle. In light of
this, a method called probabilistic
decomposition has been developed for
dividing the search space based on the
vehicle’s sensing characteristics to provide a set of points that, if all points in
the set are included in the vehicle’s final
path, guarantee that complete coverage
is achieved, with an efficient set size.
This set of points can then be used as
an instance of the Traveling Salesman
Problem to find a tour through all
points, thus covering the search space.
At the lowest level, a single vehicle
must plan an optimal path through an
allocated search space, which is a sub-region of the total search space. This optimal path is considered the shortest route
through the set of points that allows the
vehicle’s sensing apparatus to visit all
points in the search space. The path
between these points can be optimized
using many different algorithms, including graph search and TSP solution
methods. At this level, the vehicle
dynamics, vehicle sensing characteristics,
and environmental effects all can affect
the optimal solution. With the inclusion
of vehicle dynamics, the true value of a
path is not only dependant on the distance between its points, but also on the
vehicle capabilities and characteristics of
the vehicle’s control system.
The traveling salesman problem is
focused on finding the shortest tour
through a fixed set of points. This has
been deeply researched, as efficient
solutions have wide-ranging applications in domains such as vehicle routing and job scheduling. As an NP-hard
problem, it is extremely difficult to
solve large instances of the TSP exactly,

so heuristic methods must be used. One
of the most powerful heuristic algor ithms is the Lin-Kernighan (LK)
method, an iterative method that begins
with a random tour, performs pair-wise
optimization by steps to arrive at local
minima, and then repeats with a new
random tour, always saving the best
tour encountered [29]. Unfortunately,
the time complexity of this algorithm
is still unsuitable for real-time operation
under problem sets larger than a few
hundred points [30].
It has been shown that the time complexity of the LK method can be somewhat linearized at the cost of optimality
by first clustering the point set, using the
LK method to find a sub-tour, and then
merging the cluster sub-tours into a final
tour [31–33]. The operation of the algorithm becomes very fast in exchange for
a reasonable drop in tour quality.
One class of memetic computing is
the combination of a genetic algorithm
performing a global search while the
LK method performs a local search. By
evolving initial tours instead of randomly generating them, the global
search becomes more directed and is
able to converge on higher quality
tours more quickly. This was the seed
for a young and exciting topic of
research [34, 35].
By including the vehicle dynamics, it
adds computational complexity to any
algorithm, so a new memetic TSP solution method, Clustered Evolutionary
Lin-Kernighan, or CELK, is presented as
a method to bring the TSP solution into
the real-time domain [36, 37].
In environments and scenarios where
vehicle capabilities and the environment
may be variable, an arbitrator is used to
detect changes in the vehicles and
environment and then to decide if a replan should be executed. These four
components—decomposition, task allocation, path planning, and arbitrator—
are combined into a mission-planning
architecture shown in Figure 1.

MAY 2010 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE

33

Task Specification
Agents

Tasks

Change

Environment

Priorities
Scenario Level

Task Allocation

Arbitrator

Path Optimization

System Level

Execution

Agent Level

FIGURE 1 Adaptive mission-planner architecture.

(a)

(b)

(c)

(d)

FIGURE 2 Constrained division.

IV. Probabilistic Decomposition

In order to decompose the search space,
we introduce the probabilistic decomposition algorithm, which iteratively
divides a plane into a set of non-overlapping regions, or facets, that cover the
whole plane, based on the characteristics of the facet vertexes. The subdivision is constructed from a set of 2D
points, or facet anchors, that lie at the

FIGURE 3 Triangular grid initialized division
under distance and observability constraints.

34

center of each facet. The borders of
each facet lie equidistant from adjacent
anchor points. The set of facet vertexes
are known as the Voronoi diagram of a
point set.
The probabilistic decomposition
algorithm begins by initializing the point
set with the vertexes of the bounding
region, as well as a point within the
bounding region. The Voronoi diagram
for the point set is then calculated, and
the vertexes of each facet are examined,
relative to the facet anchor, under a set
of constraints. If the facet vertex does
not meet the constraint criteria, then the
vertex is added as to the anchor point
set, adding a new facet, and halving the
size of the 3 (or 4, in the case of square
facets) adjacent facets along the line
between their anchors and the vertex, as
shown in Figure 2. This process is
repeated for all vertexes of all facets until
no facets remain unconstrained and the
point set is complete. This method has
many desirable properties, most notably
that the constraints can be arbitrarily

IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2010

related to the contents of the facet under
examination.
Figure 2 illustrates the constrained
division algorithm. Cells are outlined as
hexagons, sensor footprints are circular,
and anchor points are located at the
center of each cell and sensor footprint.
Figure 2a shows the divisions using a
simple triangular grid before further
constraints are imposed. The gray line
in 2a shows a vertex under examination. Figure 2b shows the division after
the vertex from 2a was added as a new
anchor point, creating a new cell. Figure 2c shows the division resulting
from an additional anchor point being
added. Figure 2d shows the final division, with the area of highest sensor
overlap shaded.
Additional infor mation can be
included in the constraint set, such as
the probability of observing the true
state of points in the facet. Given the
probability that a vehicle’s sensor will
detect the state of a point if it is fully
visible, and given the probability of
points being visible in the search space
(which can correspond to various
environmental phenomena, such as
vegetation, weather conditions, etc.), a
constraint can be constructed that
ensures that the vehicle passing through
the point set achieves an upper bound
on the observability of points in the
search space.
The probability of observing the state
of a given location is given by Equation 1.
Pobs 5 1 2 3 1 2 1 PdetPvis 24 n.

(1)

Pobs represents the probability of
observing the state of a location over
the entire search sequence, also known
as observability. Pdet is a value that is
related to the sensing capabilities of
the vehicle, representing the probability of detecting the true state of a location if it is completely visible during a
single pass. Pvis is the probability that a
location will be visible. Finally, n represents the number of times that the
vehicle’s sensor visits the given location. The probability of observing the
state of a given location increases with
each pass of the sensor, so to bound

providing a deterministic, precise method
PATH EVAL. – NO ANGLE
PATH EVAL. – ANGLE
HEURISTIC
for assignment evaluation that has only O 1 n 2
COVER TIME
WASTAGE
COVER TIME
WASTAGE
COVER TIME
WASTAGE
complexity. This heuAVERAGE
2517.28
532.20
2410.85
332.18
2407.35
352.13
ristic method is comSTD. DEV.
188.09
269.52
124.36
183.96
47.84
72.24
pared to a single-pass
path optimization,
TABLE 2 Cover time of two agents, differing in sensor footprint.
where a random path
is generated and optiPATH EVAL. - NO ANGLE
PATH EVAL. - ANGLE
HEURISTIC
mized to a local miniCOVER TIME
WASTAGE
COVER TIME
WASTAGE
COVER TIME
WASTAGE
mum. The resulting
AVERAGE
3490.53
1099.83
2780.50
264.53
2727.10
158.38
cost of this path is used
STD. DEV.
306.67
415.68
98.61
160.56
57.17
77.16
as the assignment value
estimate. Below, the
the observability of each point, the
two assignment estimation methods are
is achieved, vehicles are swapped
appropr iate number of passes that
compared in Tables 1 and 2. Wastage is
between regions, and the algorithm
result in the observability falling below
taken as the amount of time agents
repeats until no more swaps are possithe desired threshold must be found.
become idle after having completed
ble, at which point a new random
This could be accomplished by simply
their assigned tasks.
assignment is generated, always keeping
passing a vehicle over the same point
In both situations, the heuristic
the best assignment. In this way, the
repeatedly, or more efficiently, the conmethod provides consistent results,
total area search time is minimized, as
strained subdivision method can be
while simultaneously providing good
the amount of time that vehicles are
used to decrease the size of facets so
estimates of cover time and minimizing
idle is minimized.
that the sensor footprint of a vehicle
wastage. Computationally, the heuristic
The load balancing method uses a
passing through a facet’s anchor overmethod is also significantly faster.
gradient-descent based method to
laps the interior of neighboring facets,
equalize the loads between vehicles
VII. Equilibrium Task
thus increasing the pass count and
allocated to a region. Since the relaAllocation Efficiency
increasing the observability of points
tionship between the size of a vehicle’s
The efficiency of the equilibrium task
in that cell without backtracking. In
allocation and a vehicle’s loading may
allocation method was evaluated in six
application, a maximum pass number
not be differentiable, equilibrium error
scenarios, detailed in Table 3. The enviis implemented to prevent large numis used, as calculated by finding the
ronment size was held constant in each
bers of passes over areas of high occludeviation of a vehicle’s loading from
scenario.
sion. Cells that meet the maximum
the swarm’s average load. The load balTable 4 displays the results of these
pass count but still do not satisfy the
ancing method is described in [38].
experiments. For simple scenarios, the
observability constraint can be flagged
VI. Task Allocation Results
efficiency of the equilibrium task allocaas likely locations for targets.
The method for estimating the loads
tion algorithm is high, nearly 90% in
V. Equilibrium Task Allocation
of the agents principally determines
some cases. In more complex scenarios
The task allocator allocates regions of
the result of the equilibrium task alloconsisting of heterogeneous agents, the
the search area to each vehicle accordcation method. Estimation methods
efficiency is necessarily lower. The introing to each vehicle’s condition and
can range in accuracy from heuristics
duction of variant terrain does not
capabilities. This is accomplished
to high-fidelity simulation of the vehigreatly impact the quality of the task
through an iterative process called equicles. Here, two estimation methods are
allocation, suggesting that the algorithm
librium task allocation and also through
compared, a simple heuristic based on
approaches the maximum efficiency for
a hybrid particle swarm optimization
the standard deviation of the points in
the scenario.
method that is applied to high-level
an agent’s allocation, and a
assignments. An initial assignment is
simple path optimization
TABLE 3 Task allocation evaluation scenarios.
produced by randomly assigning vehimethod. The heur istic
SCENARIO
AGENTS
ENVIRONMENT
cles to a region. If more than one vehimethod first calculates the
1
2, IDENTICAL
UNIFORM
cle is assigned to a region, the region is
centroid of an agent’s
2
2, DIFFERENT
UNIFORM
divided among the vehicles using a
assigned path points and
3
2, DIFFERENT
VARIANT
gradient-descent based method towards
then sums the travel times
4
4, IDENTICAL
UNIFORM
the equalization of the time-loading
between the centroid and
5
4, DIFFERENT
UNIFORM
6
4, DIFFERENT
VARIANT
between all vehicles. Once equilibrium
every point in the path, thus
TABLE 1 Cover time of two agents, differing in mobility.

MAY 2010 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE

35

TABLE 4 Equilibrium task allocation performance.
SCENARIO

# AGENTS

SINGLE

MULTIPLE

SPEEDUP

EFFICIENCY

1
2
3
4
5
6

2
2
2
4
4
4

3598.625
3598.625
3656
3598.625
3598.625
3656

2013
2694
2799
1072.5
2005.5
2114

1.787692
1.335793
1.306181
3.355361
1.794378
1.729423

0.893846
0.667896
0.65309
0.83884
0.448594
0.432356

VIII. Clustered Evolutionary
LK Algorithm

Path Value

algorithm a linear time complexity while
maintaining good tour quality.Also, it allows
A three-tiered memetic method has
for many levels of parallelism, as each subbeen developed that combines clustertour can be computed individually, and
ing, genetic algorithms, and the LK
each trial tour within the sub-tour optimimethod to find good quality tours with
zation can also be optimized independently.
a near linear time complexity. Given a
In order to improve the ratio of tour
point set, the set is clustered, by way of
quality to computational expense, an
the adaptive resonance theory method,
Evolutionary Lin-Kernighan method was
into a maximum of M clusters, where
developed. This method uses a genetic
M is chosen to be the number of points
algorithm to generate trial tours, which
in the set divided by a fixed scalar, in
are then optimized to a local minimum
order to maintain an average cluster
using the LK method. This scheme is not
size[39]. Sub-tours are then planned
a new idea, and the development of usewithin each cluster, using a genetic
ful genetic operators under similar archialgorithm-based LK method, called
tectures has been explored [40].
Evolutionary Lin-Kernighan, or ELK.
The ELK algorithm begins by generThis algorithm is used to recoup some
ating P random individuals, where each
of the tour quality lost through clusterindividual is a trial tour. Each individual
ing, and analysis has shown that there is
is then evaluated, which consists of
also a speed benefit to using the algoapplying the LK algorithm with interrithm. Once sub-tours are found, they
section removal until a local minimum is
are merged back into a final tour using
achieved, and the total tour length is
the method described in [31].
assigned to the individual’s fitness. RouUtilizing the clustering method to
lette-wheel parent selection is then used
maintain an average cluster size keeps the
to generate P children, where the probatime complexity of each instance of the
bility of individuals being selected as parELK method constant, giving the overall
ents is proportional to their rank in the
population.
Reproduction is
LK, ELK Algorithm Performance (100 Points, 30 Runs)
achieved through
4900
cost-preserving
4800
Avg LK
crossover and a
Avg ELK
4700
mutation operator.
Log. (Avg LK)
4600
The cost-preservLog. (Avg ELK)
ing operator has
4500
been shown to
4400
y = –72.173ln(x) + 4724.2
have good perfor4300
mance at low
4200
computational
4100
y = –109.24ln(x) + 4815.5
expense [41].
4000
A fixed num0
200
400
600
800
1,000
ber
of ‘strangers,’
Iteration
or random individuals, are introFIGURE 4 LK versus ELK Tour quality.

36

IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2010

duced to the population at each
generation. The new individuals are
evaluated, and Roulette-wheel survival
is used to keep P individuals with an
individual’s probability of survival being
proportional to their rank in the population. This process is repeated until an
evaluation limit is exceeded. Mutation
is achieved by swapping edges with
probability PgMut.
IX. ELK and Divide and
Conquer ELK Results

As the use of clustering algorithms for
divide-and-conquer optimization is well
studied in the literature [31], this section
highlights the results of ELK with a brief
mention of the total CELK algorithm.
For further discussion and evaluation of
the CELK algorithm, the interested
reader is directed to [37].
The tour quality of the ELK algorithm was compared to that of the LK
algorithm alone, over 100 randomly
generated points, averaged over 30
runs, each run consisting of 1000 evaluations. As can be seen in Figure 4, the
amount of tour improvement per evaluation is significantly greater using the
ELK algorithm.
Additionally, trial tours generated by
the ELK algorithm were evaluated significantly faster, as LK needed to make
fewer changes due to pre-optimized
sections of their tours being inherited
from the previous generation. To study
this effect, the two algorithms were
compared by executing them for 1000
path evaluations on randomly generated
tours of varying length. An average was
taken over 11 runs for each tour length.
The evaluations were performed in
turn on the same hardware platform,
with similar levels of code optimization.
The number of optimization iterations

per path was recorded, as well as execution times for each run.
Figure 5 shows the average execution
times of the methods on various tour
sizes. Figure 6 shows the average number
of optimization iterations performed on
each tour size under the two algorithms.
These figures show that the ELK method
has a significant quality and performance
advantage over the LK method alone. Figure 4 shows that the ELK method produces higher quality paths in fewer
iterations. Figure 5 shows the LK and
ELK algorithms operating on tours of
increasing length, showing that the ELK
algorithm has increasing benefits with
path size. Figure 6 shows the average
optimization iterations necessary to converge to a local minimum for increasing
tour sizes under the LK and ELK algorithms. Note that the LK method increases iterations with tour size, while the ELK
method holds relatively constant.
Clustering the point sets and performing optimization on sub-tours, then merging the sub-tours into a final tour, has
been shown to linearize the run-time
complexity of the ELK method, as shown
in Figure 7.

Memetic methods have displayed greatly increased
performance in both execution time and quality across
many different problem domains.

should be used as the objective function
[29]. As such, we must show that any
valid objective function has the properties of symmetry, positivity, reflexivity
and triangle inequality.
For heterogeneous vehicles, a simple
heuristic is proposed which estimates
the time to cross the edge, given in
Equation 2. The guidance speed is a
positive scalar representing the average
percent of the vehicle’s maximum velocity that the vehicle travels under guidance. The agility of the vehicle is a
positive scalar representing a measure of
the ability of the vehicle’s guidance system to execute turns without incurring
extra time as compared to a straight
path. The use of this heuristic allows the
optimization of the path based on the
vehicle’s kinematics.
t 1 ei 2 5

X. TSP For Physical Vehicles

When planning for real-world vehicles,
it may be desirable to substitute the
Euclidean distance objective function for
a cost function that models the mobility
of the vehicle. In this way, the total
behavior of the vehicle can be optimized. Since the LK method is the
underlying algorithm, only metrics

cgvmax
d 1 aei, bei 2
1 ca a
b
cgvmax
a
3 1 1 2 cos 1 u aei, bei, cei 2 .

Equation 2—Physical vehicle heuristic.
Given a possible edge, ei, consisting
of three points, aei, bei, and cei .
Where d(a, b) is the Euclidean distance between points a, b; vmax is the
maximum vehicle speed; a is the vehi-

XI. Physical Vehicle
Heuristic Results

Fig. 8 shows the optimized path on a triangular grid of points using only Euclidean distance on the left and the physical
vehicle cost heuristic (right) detailed in
Equation 2. Note the resulting straight
path sections, which minimize the coverage time for those point sequences
through the conservation of momentum.

Average Optimization Iterations Versus Tour Size
7

LK Avg. Time

Optimization Iterations

Optimization Time (s)

LK Versus ELK Performance Times
1,000
900
800
700
600
500
400
300
200
100
0

cle’s acceleration capability, u a,b,c is the
angle between points a, b and c; cg is a
scalar representing the guidance speed,
and ca is a scalar representing the vehicle’s agility.
This heuristic has the property that
the degenerate case of the heuristic simplifies to Euclidean distance. Also, symmetry, positivity and reflexivity properties
are trivial to demonstrate. The triangle
inequality does not hold for 3-point
edges, though the effect of an edge
change is localized to a small neighborhood of down-stream edges, allowing the
effective use of LK optimization. To adapt
the vehicle heuristic to the LK optimization method, the set of possible edges
becomes all combinations of three points
in the problem set. In this way, the algorithm can be directly applied to this
instance of the TSP.

ELK Avg. Time

50

100

150

200

Tour Size
FIGURE 5 Performance times of LK versus ELK.

250

350

6
5

LK
ELK

4
3
2
1
0
50

100

150
200
Tour Size

250

300

FIGURE 6 LK vs. ELK average optimization iterations.

MAY 2010 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE

37

Boeing’s indoor rapid prototyping test-bed that
provides a low-cost means for technology integration,
maturation and demonstration.

the physical vehicle heuristic were
executed in
8,000
3197.5 seconds on
Clustering
7,000
average.
6,000
No Clustering
Analysis of
5,000
variance on these
4,000
results shows that
3,000
optimization uti2,000
1,000
lizing the mobility
0
characteristics is
0 2,000 4,000 6,000 8,000 10,000 14,000 16,000
able to significantPath Size (points)
ly improve the
time of compleFIGURE 7 Time performance of clustered ELK and ELK on various
tion for a mobilipath sizes.
ty-restr icted
vehicle. The enviTo evaluate the effectiveness of the
ronmental and mobility characteristics
vehicle mobility heuristic, a simulation
of the vehicle greatly determine the
was developed to model the behavior of
time to completion, so there is great
a fixed wing air vehicle. The mobility of
potential to optimize the path using this
such vehicles is well known and easy to
cost method.
model. The path planning algorithm was
XII. Boeing SWARMS Vehicle
tested over 30 runs, each over the same
Swarm Technology Lab
environment using the vehicle heuristic
The above algor ithms have been
and Euclidean distance as the cost. The
tested in Boeing’s Vehicle Swar m
evaluations were performed in turn on
Technology Lab (VSTL) [42] on air
the same hardware platform with similar
and g round vehicles. VSTL is a
levels of code optimization. Under this
100350320 ft indoor rapid prototypexperimental configuration, the paths
ing test-bed that provides a low cost
generated using the Euclidean distance
means for technology integration,
metric were executed in 3398.7 seconds
maturation and demonstration.
on average, while paths generated using
Compute Time (s)

Compute Time Versus Path Size

(a)

(b)

FIGURE 8 Path optimization comparison using euclidean distance
(a) and (b) physical vehicle heuristic.

38

Architecture—The overall VSTL
test-bed architecture comprises hardware and software elements. Hardware
elements include a high-accuracy, lowlatency, vision-based, motion capture
position reference system and a number of hardware vehicles under test.
Each vehicle under test is equipped
with its own on-board controller,
health-monitoring, and communication sensor payload. Communication
between the various software elements
occurs via either of the two data buses.
One bus is used for transmitting timecritical vehicle position and attitude
data. The second bus is used for transmitting health, condition, and capability data as well as vehicle commands.
The interaction between these applications is through UDP Ether net
packets. The architecture also supports
TCP for less time-critical data when
accurate data delivery is required.
The adaptive area coverage task allocation software was integrated with the
defined test-bed Ethernet interface,
allowing it to exchange waypoint
commands and condition and capability
data with the vehicles.
Vehicles—VSTL uses common RC
vehicles equipped with Boeing’s custom common electronic hardware. The
common hardware is a modular electronic board that allows easy integration of new types of vehicles and easy
interoperability with other test-bed
components. The tests below have been
conducted using quad-rotors as air
vehicles and tanks as ground vehicles, as
shown in Figure 10.

IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2010

FIGURE 9 Boeing vehicle swarm technology lab.

A. VSTL Test Results

The following two scenarios have been
tested with the above algorithms to
demonstrate some of the algorithm
capabilities. Both tests used the Equilibrium Task Allocation method.The search
area size was 836 meters and flight
height was 1.5 m.
B. Two Air Vehicles
Test with Different Speeds

(a)

The first test included two air vehicles
with different speeds in order to show
the load balancing capability of the equilibrium task allocation.The vehicle’s sensor radius was set to 0.8 m, and vehicle
speed was 0.6 m/s for one and 0.3 m/s
for the other.
Figure 11 shows the flight test results.
Vehicles 1 and 2 completed the search in
91.44 sec and 85.75 sec respectively.
Thus, although the speed of vehicle 1 is
double that of vehicle 2, their search
time standard deviation is only 4%. The
deviation of the actual flight path of
vehicle 1 from the planned path in segments close to vehicle 2’s path due to
collision avoidance between the vehicles
was also noticed. The vehicle, however,
was still able to achieve its waypoints
and guarantee the coverage.

(b)

FIGURE 10 Quadrotor (a) and (b) tank test vehicles use Boeing common hardware.

C. Heterogeneous Vehicles Test

Vehicle 1 Waypoints

Vehicle 2 Waypoints

Vehicle 1 Actual Flight

Vehicle 2 Actual Flight

–3

–2

–1

0

1

2

3

XIII. Conclusion

This paper presents novel area coverage algorithms that have been validated using Boeing VSTL hardware. Even
though the multi-vehicle search area
coverage problem is large and complex, several new memetic computing

Quadrotor 1 Waypoints
Tank 1 Waypoints

–1
–4

radius to 0.6 m, which triggered a
replan. Figure 12 shows planned and
actual paths as well as the occlusion
map. Vehicles were assigned new paths
after the replan, which is indicated by
the circle for every vehicle. The vehicles
adaptively completed the coverage of
the whole area despite the sensor radius
reduction of quadrotor 1.

This test was designed to demonstrate
advanced features of the adaptive task
allocation algor ithm by including
heterogeneous vehicles, a non-uniform
occlusion map, and dynamic vehicle
capabilities. The test included two air
vehicles (quadrotors) and two ground
vehicles (tanks) with different capabilities. The quadrotors’ sensor radius was
1.2 m, and their speed was 0.6 m/s. The
tanks’ sensor radius was 0.6 m, and their
speed was 0.4 m/s. The maximum
number of passes ‘was set to three for
all vehicles. At 58.32 seconds from the
beginning of the search, quadrotor 1
changed altitude to 0.75 m and sensor

Vehicles Actual Paths

4

–2

–2
–3

–2

–1

0

–3

–3

–4

–4

–6
–7

Y (m)

Y (m)

–4

–5

Quadrotor 2 Waypoints
Tank 2 Waypoints

1

2

3

4

–5
–6
–7

–8
–9
X (m)
Quadrotor Initial Position
FIGURE 11 Planned waypoints and actual paths for vehicles. The task
allocation algorithm assigned a longer path to Vehicle 1 due to its
higher speed in order to achieve equilibrium.

–8
X (m)
Quadrotor Initial Position

Tank Initial Position

FIGURE 12 Planned and actual paths and the occlusion map. Brighter
regions indicate higher occlusion. The planner waypoints are denser
over occluded areas. Quadrotor 1 waypoints are denser after the
replan due to its sensor reduction.

MAY 2010 | IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE

39

Quadrotors

Tanks

Search Area
Mission Planner
FIGURE 13 Heterogeneous area coverage
test in VSTL using two air and two ground
vehicles. Area that has been covered is
painted in black in the mission planner. The
adaptive mission planner is able to complete the full area coverage in spite of a
change in sensor radius of one of the air
vehicles during execution.

methods have been presented that
decompose, allocate and optimize the
exploration of a search area for multiple heterogeneous vehicles. These
new methods were shown to have
good performance and quality, and as
they are defined in a general way,
these methods are applicable to many
other problem domains. The methods
have been combined into a missionplanner architecture that is able to
adaptively control the behavior of
multiple vehicles with dynamic vehicle capabilities and environments for
mission assurance.
The topic of mission-planning architectures and optimization of swarms of
autonomous vehicles is a young and
exciting field with many opportunities
for research. More computationally efficient methods for decomposition may
be useful, as well as the application of
next-generation meta-learning architectures for path planning [43]. In addition
to the existing collision avoidance, path
de-confliction during planning can
improve safety and efficiency.
References
[1] T. Back, M. Emmerich, and O. M. Shir, “Evolutionary algorithms for real world applications [Application
Notes],” IEEE Comput. Intell. Mag., vol. 3, no. 1, pp.
64–67, 2008.
[2] W. Jatmiko, K. Sekiyama, and T. Fukuda, “A psobased mobile robot for odor source localization in dynamic advection-diffusion with obstacles environment:
Theory, simulation and measurement,” IEEE Comput.
Intell. Mag., vol. 2, no. 2, pp. 37–51, 2007.
[3] J. Shinkyu, S. Hasegawa, K. Shimoyama, and S.
Obayashi, “Development and investigation of efficient
GA/PSO-HYBRID algorithm applicable to real-world
design optimization,” IEEE Comput. Intell. Mag., vol. 4,
no. 3, pp. 36–44, 2009.

40

[4] H. Ishibuchi, T. Yoshida, and T. Murata, “Balance
between genetic search and local search in memetic
algorithms for multiobjective permutation flowshop
scheduling,” IEEE Trans. Evol. Comput., vol. 7, no. 2, pp.
204–223, 2003.
[5] Y. S. Ong and A. J. Keane, “Meta-Lamarckian learning in memetic algorithms,” IEEE Trans. Evol. Comput.,
vol. 8, no. 2, pp. 99–110, 2004.
[6] D. V. Arnold and R. Salomon, “Evolutionary gradient
search revisited,” IEEE Trans. Evol. Comput., vol. 11, no.
4, pp. 480–495, 2007.
[7] M. W. S. Land, “Evolutionary algorithms with local
search for combinatorial optimization,” Univ. California,
1998.
[8] Y. S. Ong, P. B. Nair, and A. J. Keane, “Evolutionary optimization of computationally expensive problems
via surrogate modeling,” AIAA J., vol. 41, pp. 687–696,
2003.
[9] E. U. Acar, H. Choset, and L. J. Yeong, “Sensor-based
coverage with extended range detectors,” IEEE Trans.
Robot., vol. 22, no. 1, pp. 189–198, 2006.
[10] R. N. De Carvalho, H. A. Vidal, P. Vieira, and
M. I. Ribeiro, “Complete coverage path planning
and guidance for cleaning robots,” in Proc. IEEE Int.
Symp. Industrial Electronics 1997, ISIE ’97, vol. 2, pp.
677–682.
[11] N. Hazon and G. A. Kaminka, “Redundancy,
efficiency, and robustness in multi-robot coverage,” in
Proc. IEEE Int. Conf. Robotics and Automation, 2005, pp.
735–741.
[12] D. I. Latimer, S. Srinivasa,V. Lee-Shue, S. Sonne, H. Choset, and A. Hurst, “Towards sensor based coverage with robot
teams,” in Proc. IEEE Int. Conf. Robotics and Automation 2002,
ICRA ’02, vol. 1, pp. 961–967.
[13] M. Moors, T. Rohling, and D. Schulz, “A probabilistic approach to coordinated multi-robot indoor
surveillance,” Dept. Comput. Sci. III, Univ. Bonn,
Germany.
[14] J. S. Oh, Y. H. Choi, J. B. Park, and Y. F. Zheng,
“Complete Coverage navigation of cleaning robots using
triangular-cell-based map,” IEEE Trans. Ind. Electron.,
vol. 51, pp. 718–726, June 2004.
[15] R. Alami, “A general framework for multi-robot cooperation and its implementation on a set of three hilare
robots,” in Experimental Robotics IV, 1995.
[16] I. Dutta, A. D. Bogobowicz, and J. J. Gu, “Collective robotics—A survey of control and communication
techniques,” in Proc. Int. Conf. Intelligent Mechatronics and
Automation, 2004, pp. 505–510.
[17] A. Farinelli, L. Iocchi, and D. Nardi, “An analysis of coordination in multi-robot systems,” in Proc.
IEEE Int. Conf. Systems, Man, and Cybernetics, 2003, pp.
1487–1492.
[18] H. Li, F. Karray, O. Basir, and I. Song, “An optimization algorithm for the coordinated hybrid agent framework,” in Proc. IEEE Conf. Systems, Man, and Cybernetics,
2005, pp. 1730–1735.
[19] L. Lin and Z. Zheng, “Combinatorial bids
based multi-robot task allocation method,” in Proc.
IEEE Int. Conf. Robotics and Automation, 2005,
pp. 1145–1150.
[20] N. Zhang and D. C. Wunsch, II, “A comparison of
dual heuristic progamming (DHP) and neural network
based stochastic optimization approach on collective
robotic search problem,” in Proc. Int. Joint Conf. Neural
Networks, 2003, pp. 248–253.
[21] S. Botelho and R. Alami, “M+: A scheme for multirobot cooperation through negotiated task allocation and
achievement,” in Proc. IEEE Int. Conf. Robotics and Automation, Detroit, MI, 1999, pp. 1234–1239.
[22] B. L. Brumitt and A. Stentz, “GRAMMPS: A generalized mission planner for multiple mobile robots in
unstructured environments,” in Proc. IEEE Int. Conf.
Robotics and Automation, 1998.
[23] B. P. Gerkey and M. J. Mataric, “Sold!: Auction
methods for multi-robot coordination,” IEEE Trans. Robot. Automat., vol. 18, no. 5, pp. 758–768, 2002.

IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | MAY 2010

[24] L. E. Parker, “L-ALLIANCE: A mechanism for
adaptive action selection in heterogeneous multi-robot
teams,” Oak Ridge Nat. Lab., Oct. 1995.
[25] B. P. Gerkey and M. J. Mataric, “Multi-robot task
allocation: Analyzing the complexity and optimality of
key architectures,” in Proc. IEEE Int. Conf. Robotics and
Automation, 2003, pp. 3862–3868.
[26] K. Nagatani and H. Choset, “Toward robust sensor based exploration by constructing reduced generalized Voronoi graph,” in Proc. Intelligent Robots and Systems,
1999, pp. 1687–1692.
[27] H. Hanna, “Decentralized approach for multi-robot
task allocation problem with uncertain task execution,”
in Proc. Int. Conf. Intelligent Robots and Systems, 2005, pp.
535–540.
[28] E. H. Ostergaard, M. J. Mataric, and G. S. Sukhatme,
“Multi-robot task allocation in the light of uncertainty,”
in Proc. IEEE Int. Conf. Robotics and Automation, 2002,
pp. 3002–3007.
[29] S. Lin and B. W. Kernighan, “An effective heuristic algorithm for the traveling salesman problem,” Oper.
Res., vol. 21, pp. 498–516, Mar.–Apr. 1973.
[30] D. Applegate, W. Cook, and A. Rohe, “Chained
Lin-Kernighan for large traveling salesman problems,”
2000.
[31] S. Mulder and D. C. Wunsch, “Million city traveling
salesman problem solution by divide and conquer clustering with adaptive resonance neural networks,” Neural
Netw., July 2003.
[32] D. C. Wunsch and S. Mulder, “Using adaptive
resonance theory and local optimization to divide and
conquer large scale traveling salesman problems,” in
Proc. Int. Joint Conf. Neural Networks, 2003, pp. 1408–
1411.
[33] D. C. Wunsch and S. Mulder, “Evolutionary algorithms, Markov decision processes, adaptive critic designs, and clustering: commonalities, hybridization and
performance,” in Proc. Int. Conf. Intelligent Sensing and
Information Processing, 2004, pp. 477–482.
[34] H.-K. Tsai, J.-M. Yang, and C.-Y. Kao, “Solving
traveling salesman problems by combining global and local search mechanisms,” in Proc. Conf. Evolutionary Computation, 2002, pp. 12–17.
[35] H.-K. Tsai, J.-M. Yang, and C.-Y. Kao, “An evolutionary algorithm for large traveling salesman problems,”
IEEE Trans. Syst., Man Cybern. B, vol. 34, pp. 1718–1729,
Aug. 2004.
[36] R. J. Meuth, “Adaptive multi-vehicle mission
planning for search area coverage,” Master’s thesis,
Missouri Univ. Sci. Technol., 2007.
[37] R. J. Meuth and D. C. Wunsch, II, “Divide and
conquer evolutionary TSP solution for vehicle path
planning,” in Proc. Congr. Evolutionary Computation (WCCI’08), 2008.
[38] R. J. Meuth, E. W. Saad, D. C. Wunsch, and J. Vian,
“Adaptive task allocation for search area coverage,” in
Proc. IEEE Int. Conf. Technologies for Practical Robot Applications, Woburn, MA, 2009.
[39] G. A. Carpenter, S. Grossberg, and D. B. Rosen,
“ART 2-A: An adaptive resonance algorithm for rapid
category learning and recognition,” Neural Netw., pp.
493–504, 1991.
[40] P. Merz and B. Freisleben, “Genetic local search for
the TSP: New results,” in Proc. IEEE Conf. Evoluationary
Computation, 1997, pp. 159–164.
[41] A. Schoneveld, J. F. deRonde, and P. M. A. Sloot,
“Preserving locality for optimal parallelism in task allocation,” in Lecture Notes in Computer Science, vol.
1225/1997. 1997.
[42] Y. Shi and R. Eberhart, “Parameter selection in
particle swarm optimization,” in Proc. Conf. Evolutionary
Computation, 1998.
[43] R. J. Meuth, M.-H. Lim, Y.-S. Ong, and D. C.
Wunsch, “A proposition on memes and meta-memes in
computing for higher-order learning,” J. Memetic Comput., vol. 1, 2009.

Proceedings of International Joint Conference on Neural Networks, Orlando, Florida, USA, August 12-17, 2007

APPROXIMATE DYNAMIC PROGRAMMING AND NEURAL NETWORKS ON GAME HARDWARE
Ryan J. Meuth, Donald C. Wunsch II
University of Missouri- Rolla
Dept. of Electrical & Computer Engineering
1870 Miner Circle,
Rolla, MO, 65401
Abstract - Modern graphics processing units (GPU) and game
consoles are used for much more than simply 3D graphics
applications and video games. From machine vision to finite
element analysis, GPU’s are being used in
diverse
applications, collectively called General Purpose computation
onf Graphics Processor Units (GPGPU). Additionally, game
consoles are entering the market of high performance
computing as inexpensive nodes in computing clusters. This
paper explores the capabilities and limitations of modern
GPU’s and game consoles, surveying the ADP and neural
network technologies that can be applied to these devices.

On the host system side, the application generates a data
structure to be rendered, consisting of a set of verticies and
their corresponding colors that define a polygon. This
data structure is passed to the vertex processor, which is
the first programmable unit in the graphics pipeline, which
typically applies transformations to the vertices. The
rasterizer then maps these coordinates to pixel locations,
generating a set of fragments. These fragments are then
passed to the fragment processor, the second
programmable unit in the pipeline.

I. INTRODUCTION
In recent years consumer graphics processing hardware
has experienced significant growth in performance driven
by increasingly realistic game simulations and popular
multimedia demands. As a result, the gaming industry has
leveraged a parallel processing model to provide a
doubling of graphics computing capability every six
months, as opposed to the 18 month doubling rate of
general computing processors, leading to a “SuperMoore’s Law” trend that is illustrated in Figure 1. As
these graphics processors become more capable and
flexible, they have become desirable platforms for general
computation. Owens [1] provides a extensive overview of
the industry of general purpose computation on GPU’s.
However, Owens neglects to mention neural network and
approximate dynamic programming applications on
graphics processing units. Here, we provide an overview
of these techniques, with associated challenges and
limitations.
Figure 2 shows an overview of the graphics processing
pipeline.
Manuscript received January 30, 2007. This work was supported in part
by The Boeing Company, M. K. Finley Endowment, and the National
Science Foundation.
Ryan Meuth is with the Department of Electrical and Computer
Engineering at the University of Missouri – Rolla, Rolla MO, 65401,
USA. (phone: 573-341-4521; e-mail: rmeuth@umr.edu).
Donald C. Wunsch II is with the Department of Electrical and Computer
Engineering at the University of Missouri Rolla, Rolla, MO, 65401,
USA. (e-mail: dwunsch@umr.edu).

1-4244-1380-X/07/$25.00 ©2007 IEEE

Fig. 1. The exponential increase in performance of graphics processing
units compared to the performance of Intel processors over the last 4
years. Figure courtesy of Owens [1].

The fragment processor determines which fragments are to
be drawn to the frame buffer, and then fills pixels with
color information based on a program called a shader.
Shader programs allow complex lighting and texture
information to be mapped onto pixels. The frame buffer
holds the completed image for output to a display device.
To maintain high frame rates under increasingly
graphically intensive applications the vertex and fragment
processors have been implemented as a single-instruction,
multiple-data (SIMD) parallel processing architecture.
Modern graphics processors combine vertex and fragment
processors into a generalized unified shader unit.

the processing elements. Additionally, array sizes are
fixed at compile-time, placing an upper bound on
algorithms that require dynamic data sizes.
The lack of primitive looping and branching capability on
GPUs decreases the efficiency of data dependant
operations. Due to this limitation, each branch of an IF
statement is evaluated, and only the result of the desired
branch is retained, thus no computation can be saved using
branching instructions. Additionally, the lack of explicit
looping capability requires the un-rolling of algorithms
into array or matrix form for efficient operation.

Fig. 2. The graphics processing pipeline. Modern GPU’s combine the
vertex and fragment processor into a unified shader unit that is able to
perform either of these functions. Currently, GPU’s can include up to
128 unified shader units. Figure courtesy of Goodnight [2].

At this writing, GPU’s can include up to 128 unified
shader units, operating at up to 1.3Ghz. As the entire
pipeline is based on the 32-bit floating point data type, this
yields a significant processing capability on the order of
hundreds of GFLOPS in a single desktop chassis.
Additionally, bus enhancements now allow multiple
graphics cards to work together in the same system [3].
The widespread availability of these devices has allowed
inexpensive high performance computing environments to
be constructed that leverage both CPU and GPU capability
to create a ‘cluster of clusters’ [4].
For general purpose computing, the GPU architecture
lends itself well to applications where calculations are
repeatedly performed on large blocks of data [5]. In this
way, particle systems, finite element analysis, image
processing, and other numerical computation are well
suited to utilize the GPU. However, the shader units of
GPU’s do not yet include efficient looping or branching
hardware, so algorithms utilizing data-dependant
operations are difficult to implement effectively. Also, the
data bus that hosts the GPU is often inefficient for small
data transfers, so to achieve a reasonable speedup data
must be operated on in batches [6].
Graphics processing units gain their computational power
from their ability to apply a program to an array of vectors
in parallel. Graphics processing units typically include
processing pipelines that number in powers of two, thus
the highest efficiency is achieved utilizing arrays that are
similarly dimensioned. However, these calculations are
limited to the data currently being operated on, meaning
that there is no direct communication capability between

Many of these difficulties have been overcome by creative
algorithm design and implementation on the target
systems. Iterative, calculation intensive algorithms gain
the most benefit from being ported to GPUs. Typically
most of the porting difficulty involves mapping the
algorithmic data structures into GPU video memory such
that the data can be operated on efficiently, given the GPU
limitations and capabilities.
GPU shader programs are written in a language similar to
assembly, and can be developed through a graphics
programming interface, such as the open-source OpenGL
or Microsoft’s DirectX. High-level languages such as
Brook, Sh, and RapidMind allow developers to use Cbased language extensions to create shader programs,
providing data abstraction, reducing the learning curve of
these devices. Some of these high level languages include
library functions such as ‘Reduce’ which can perform a
given operation on an array resulting in a single vector
using an algorithm that operates with complexity of order
log2(N).
II. GAME CONSOLES
Driven by increasingly complex video games and graphics
as well as new entertainment media demands such as
internet, digital photography and video playback,
consumer video game consoles have become powerful
general purpose machines. At the same time, these
systems must be brought to the public at an affordable
price point. Figure 3 compares the ratio of Floating Point
Operations per Second (FLOPS) per dollar of several
game consoles and Intel Pentium Based Systems. Here we
can see that the cost-effectiveness of the latest generation
of game consoles is an order of magnitude higher than that
of any Intel-based system. These features make gaming
consoles a highly desirable platform for inexpensive high
performance computing systems.
Though the performance per dollar ratio of these systems
is attractive, they are not without limitations, most notably

in their interconnect ability. Only the last two generations
of consoles have included networking capabilities, and
then only one port is provided, limiting the efficiency of
interconnects architectures in console-based clusters.
Until the latest generation of game consoles, the
technology embedded in consoles has often lagged behind
the capability of personal computers at the time.
However, the selling price of these devices makes them
very competitive. In the previous generation of game
consoles, this was recognized, and several attempts were
made to utilize inexpensive game consoles as nodes in a
super computing cluster. Very little success was made
with the original Xbox [7], but researchers at the
University of Illinois – Urbana Champaign succeeded in
developing a 65-node computing cluster based off of the
popular Playstation 2 video game console. This cluster
was used for chemical simulations, and with a price point
of $15,000 for the entire cluster, the system provided a
high level of performance per dollar [8].
FLOPS/Dollar
4.50E+08
4.00E+08
3.50E+08
3.00E+08
2.50E+08
2.00E+08
1.50E+08
1.00E+08
5.00E+07
0.00E+00

and shared memory. The PPE controls the SPEs like a
cluster master node, implementing job queue, shared
memory, and bus management. The Cell is unique in that
the device is capable of managing 8 independent threads at
full processor speed, with full branching and floating point
operations available on each SPE [10, 11].
The Cell is also interesting in that it can be programmed
using existing tools for graphics processing units, making
much existing GPGPU work directly portable to these
platforms.
Currently, no projects have been undertaken to develop
high performance computing clusters based on the current
generation game consoles. However, IBM will be using
the Cell Processor in its next generation super computer,
codenamed “RoadRunner.” The machine will consist of
16,000 AMD Opteron cores matched with 16,000 Cell
Broadband Engines, collectively rated at over 1 petaFLOP/s. This will make it the most powerful super
computer in the world by several orders of magnitude. It
is to be built for the Department of Energy at Los Alamos
National Laboratory in New Mexico. [12]

PS3

Xbox 360

Pentium 4
Dual

PS2

Pentium 4

Xbox

Pentium 4
Quad

Pentium 3

III. DYNAMIC PROGRAMMING

Fig. 3. Shows the FLOPS per dollar ratio of the past two generations of
game consoles and Intel Processor-based systems. We can see that the
latest generation of game consoles is several orders of magnitude more
cost efficient than the latest Pentium-based systems.

The latest generation of game consoles differs from the
former in that Microsoft’s Xbox 360 and Sony’s
Playstation 3 both include new technologies that greatly
surpass what is available in the home PC market. The
Xbox 360 includes a tri-core Power PC processor
operating at 3.2Ghz, theoretically providing a peak
processing capability of 115.2 GFLOPS. The Xbox 360
surpasses PC-based computing capability by an order of
magnitude, at a quarter of the cost [9]. Additionally, the
Playstation 3 is capable of 205 GFLOPS provided by a
nine-core processor called the Cell Broadband Engine
cooperatively developed by Sony, IBM and Toshiba. The
Cell consists of a single Power PC (PPE) based processor
that manages 8 Synergistic Processing Elements (SPE)
connected by an extremely high speed interconnect bus

Iterative search methods have been applied to GPU’s,
illustrating their usefulness in game AI methods, motion
planning, and DNA sequence alignment. Lengyel details
an algorithm for motion planning that is actually the
slowest possible on a serial machine, and achieves optimal
real time operation utilizing a GPU’s parallel hardware on
the uniform Piano Mover Problem [13]. Lengyel’s
algorithm first finds the action that should be taken at each
location in the configuration space using a dynamic
programming method to find the shortest path. This
dynamic programming method has the characteristic of an
expanding front of solutions, starting from the goal
location, and proceeding through the search space. Once
this action policy is found for every location in the space,
the path is found from the starting position, and the system
kinematics are modeled. This method operates optimally
in real-time on reasonably sized problems utilizing the
parallel computation properties of the GPU.
Most methods for finding the provably optimal policy of
MDP’s have an exponential time complexity as each state
transition sequence must be evaluated. For large MDP
formulations, it is often necessary to approximate the
Bellman Equation. However, Todorov explores a subclass of MDP’s and details a method he calls Z-Learning
for finding the optimal policy in linear time [14].
Similarly, Wunsch shows a closed-form solution to
cellular simultaneous recurrent network adaptive critic

design for the generalized maze problem [15]. For large
problems, these algorithms can benefit significantly from
the acceleration that GPU’s can provide.
IV. NEURAL NETWORKS
Neural networks are highly parallelizable and repetitious
processes which should match well with the GPU
computing architecture. As a workhorse of Approximate
Dynamic Programming methods HDP, DHP, GDHP, etc.,
there exists a high demand for this acceleration.
Zhongwen achieves a massive 200 times increase in
performance of an MLP implementation on graphics
hardware over a typical cpu, enabling real-time soccer ball
tracking on commodity hardware [16]. Zhongwen uses
the GPU to first extract a set of characteristics from image
data, then applies a pre-trained MLP to these
characteristics for classification. Zhongwen also provides
several tips for ensuring efficient implementation of
algorithms on GPU’s. These tips include minimizing the
pass count (or number of times a program must be applied
to data), and minimizing data transfers between CPU and
GPU sides.
Steinkraus implements a fully functional 2 layer artificial
neural network on the GPU, resulting in a 3X speedup for
both training and testing phases [17]. Steinkraus’ method
stores input data, training data, and weights in texture
memory on the GPU. Then a batch training method is
used to update the network weights. Steinkaus identifies 4
functions that he uses to compute the weight update, the
least efficient of which is the Inner Product function. This
function could be accelerated using the Reduce
functionality of modern graphics processing units for
additional efficiency.
Similarly, Chellapilla ports a convolutional neural network
to the GPU, resulting in a 4x speedup [18].
Bernhard takes a different approach, implementing spiking
neural networks for image segmentation, which achieves
up to a 20 times increase in performance [19]. Bernhard
utilized a special counter on the GPU called the Occlusion
Query, which tracks how many times a pixel has been
modified by a shader program. Using this counter, he was
able to efficiently compile the activations of pre-synaptic
neurons in a spiking neural network.
V. CONCLUSIONS
It can be easily seen from this review that significant
performance gains can be elicited from implementing
Approximate Dynamic Programming algorithms on
graphics processing units. However, there is an amount of

art to these implementations.
In some cases the
performance gains can be as high as 200 times, but as low
as 2 times or actually less than CPU operation. Thus it is
necessary to understand the limitations of the graphics
processing hardware, and to take these limitations into
account when developing algorithms targeted at the GPU.
It should also be noted that all the reviewed papers in this
document were operating on last-generation hardware. As
of the end of 2006, the next generation graphics hardware
has been released, which include an order of magnitude
more shader units per processor, as well as improved
branching capabilities. One can envision the possible
capability of 256 programmable shader units working in
parallel at 1.3 GHz each, in a single desktop box.
Unfortunately none of the previous work has analyzed the
performance of their algorithms relative to the number of
computational units involved, which makes it unclear how
new hardware will effect the performance of these
methods.
Additionally, utilization of the latest generation game
consoles can be a cost-effective method for accelerating
ADP and neural network methods, and this application
remains a topic of open exploration.
VI. REFERENCES
[1]

John D. Owens, David Luebke, Naga Govindaraju, Mark Harris,
Jens Krüger, Aaron E. Lefohn, Timothy, “A Survey of GeneralPurpose Computation on Graphics Hardware,” Computer
Graphics Forum, Volume 26
[2] Goodnight, N., Wang, R., Humphreys, G., “Computation on
programmable graphics hardware” Computer Graphics and
Applications, IEEE Volume 25, Issue 5, Sept.-Oct. 2005
Page(s):12 – 15
[3] “GeForce 8800 specifications,”
http://www.nvidia.com/page/geforce_8800.html, accessed
November 9, 2006.
[4] Zhe Fan; Feng Qiu; Kaufman, A.; Yoakum-Stover, S., “GPU
Cluster for High Performance Computing” Supercomputing, 2004.
Proceedings of the ACM/IEEE SC2004 Conference 2004
Page(s):47 – 47
[5] Ekman M., Warg F., Nilsson J., “An in-depth look at computer
performance growth.” ACM SIGARCH Computer Architecture
News 33, 1 (Mar. 2005), 144–147.
[6] Tranoso, P.; Charalambous, M.; “Exploring graphics processor
performance for general purpose applications,” Digital System
Design, 2005. Proceedings. 8th Euromicro Conference on 30 Aug.3 Sept. 2005 Page(s):306 – 313
[7] “12 Node Xbox Linux Cluster,”
http://www.xl-cluster.org/index.php accessed January 19, 2007.
[8] “65 Node PS2 Linux Cluster,”
http://arrakis.ncsa.uiuc.edu/ps2/cluster.php accessed January 19,
2007. University of Illinois, Urbana-Champaign.
[9] “Comparison of Seventh Generation Game Consoles”,
www.wikipedia.com,
http://en.wikipedia.org/wiki/Comparison_of_seventhgeneration_game_consoles, Retrieved January 19, 2007.
[9] Pham D., Asano S., Bolliger M., Day M. N., Hofstee H. P., Johns
C., Kahle J., Kameyama., Keaty J., Masubichi Y., Riley M.,

Shippy D., Stasiak D., Wang M., Warnock J., Weitzel S., Wendel
D., Yamazaki T., Yazawa K.: “The design and implementation of a
first-generation CELL processor.” Proceedings of the
International Solid-State Circuits Conference (Feb. 2005), pp.
184–186.
[10] Brown, Jeffry (2005-12-06). “Application-customized CPU
design.” IBM. http://www128.ibm.com/developerworks/power/library/pa-fpfxbox/?ca=dgrlnxw07XBoxDesign Retrieved on 2006-09-30.

[11] "Introduction to the Cell multiprocessor", IBM Journal of
Research and Development,
http://researchweb.watson.ibm.com/journal/rd/494/kahle.html,
September 7, 2005.
[12] “IBM to Build World's First Cell Broadband Engine Based
Supercomputer.” IBM http://www03.ibm.com/press/us/en/pressrelease/20210.wss (2006-09-06).
Retrieved on 2006-09-11.
[13] Lengyel, J., Reichert, M., Donald, B. R., Greenberg, D. P., “Realtime robot motion planning using rasterizing computer graphics
hardware.” Computer Graphics (Proceedings of ACM SIGGRAPH
90) (Aug. 1990), vol. 24, pp. 327–335.
[14] Todorov, Emanuel, “Linearly Solvable Markov Decision
Problems,” Advances in Neural Information Processing Systems,
2006. To Appear.
[15] Wunsch, D., “The cellular simultaneous recurrent network adaptive
critic design for the generalized maze problem has a simple closedform solution.” IJCNN 2000, Proceedings of the IEEE-INNSENNS International Joint Conference on Neural Networks, 2000.
Volume 3, 24-27 July 2000 Page(s):79 - 82 vol.3
[15] Zhongwen Luo; Hongzhi Liu; Xincai Wu, “Artificial neural
network computation on graphic process unit,” IEEE International
Joint Conference on Neural Networks, 2005. IJCNN '05.
Proceedings. Volume 1, 31 July-4 Aug. 2005 Page(s):622 - 626
vol. 1
[17] Steinkraus, D.; Buck, I.; Simard, P.Y., “Using GPUs for machine
learning algorithms,” Proceedings of Eighth International
Conference on Document Analysis and Recognition, 2005. 29
Aug.-1 Sept. 2005 Page(s):1115 - 1120 Vol. 2
[18] Chellapilla K, Puri S, Simard P, “High Performance Convolutional
Neural Networks for Document Processing,” 10th International
Workshop on Frontiers in Handwriting Recognition
(IWFHR’2006) will be held in La Baule, France on October 23-26,
2006.
[19] F. Bernhard and R. Keriven. “Spiking neurons on GPUs,”
International Conference on Computational Science. Workshop
General purpose computation on graphics hardware (GPGPU):
Methods, algorithms and applications, Reading, UK, May 2006.
Acknowledgement: The authors are grateful to Rui Xu for helpful
discussions. This work was partially supported by the National Science
Foundation and the M.K. Finley Missouri endowment.

