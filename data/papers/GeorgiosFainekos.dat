Model-Based Falsification of an
Artificial Pancreas Control System
Sriram Sankaranarayanan1 , Suhas Akshar Kumar1 , Faye Cameron2 , B. Wayne
Bequette2 , Georgios Fainekos3 and David M. Maahs4
1
University of Colorado, Boulder, CO, USA
Rensselaer Polytechnic Institute, Troy, NY, USA
3
Arizona State University, Tempe, AZ, USA
4
Barbara Davis Center for Childhood Diabetes, University of Colorado, Denver, CO, USA
2

ABSTRACT

ing number of instances of medical device failures due to
software errors. Continuous post-market testing and monitoring over hundreds of thousands of users will be necessary
to obtain information about rare, and potentially dangerous
defects [28]. Unfortunately, defects found at this late stage
are quite expensive to fix. As a result, a lot of emphasis has
been placed on in-silico simulation of closed-loop devices
with increasingly sophisticated models of human physiology
and the device’s operating environment.
The in silico study in this paper focuses on a predictive
hypo/hyperglycemia minimizer device for treating patients
with type-1 diabetes by regulating insulin delivery. The device employs a Kalman filter to predict the future values
of blood glucose from past noisy samples. A series of rules
are applied on the predicted future glucose values to decide
whether to turn off the pump, continue normal delivery, or
increase the normal basal rate. Additionally, the device includes rules to detect conditions such as sensor dropouts,
and pressure induced sensor attenuation. Phase I and II
clinical trials have been successfully carried out on an earlier prototype of the system being studied [10, 39]. These
trials have demonstrated the effectiveness of the devices, and
in particular, an increased time in euglycemic range for the
participants on the closed loop system.
Our approach to verification first builds a closed loop simulator in Matlab(tm) to simulate meal and insulin bolus patterns against closed loop and open loop control. The Dalla
Man et al. model is used to capture the effect of meal and
insulin inputs on the patient’s blood glucose levels [20, 41].
We formulate interesting properties about the closed loop
system behavior use simulation-based falsification approach
in the tool S-Taliro to drive the simulations [3]. S-Taliro uses
a metric called the robustness of a simulation to predict a
distance between a given simulation output and a property
of interest [26, 27]. In general, as the robustness value becomes smaller, the simulation output approaches a property
falsification. This principle is used inside a stochastic optimization solver to select a sequence of inputs that result in
decreasing values of the robustness metric, possibly leading
to a violation of the property.
For the closed loop system under study, we formulate ten
properties of interest that concern the behavior of the closed
loop system when the patient’s blood glucose levels are low,
the behavior under high blood glucose levels and comparisons between closed and open loop performance. We use
S-Taliro to search for violations that can represent corner

We present a model-based falsification scheme for artificial
pancreas controllers. Our approach performs a closed-loop
simulation of the control software using models of the human insulin-glucose regulatory system. Our work focuses on
testing properties of an overnight control system for hypoglycemia/hyperglycemia minimization in patients with type1 diabetes. This control system is currently the subject of
extensive phase II clinical trials.
We describe how the overall closed loop simulator is constructed, and formulate properties to be tested. Significantly, the closed loop simulation incorporates the control
software, as is, without any abstractions. Next, we demonstrate the use of a simulation-based falsification approach
to find potential property violations in the resulting control
system. We formulate a series of properties about the controller behavior and examine the violations obtained. Using
these violations, we propose modifications to the controller
software to improve its performance under these adverse
(corner-case) scenarios. We also illustrate the effectiveness
of robustness as a metric for identifying interesting property
violations. Finally, we identify important open problems for
future work.

1.

INTRODUCTION

This paper presents a case-study on the use of robustnessguided falsification techniques for analyzing properties of a
closed-loop artificial pancreas system. The systematic testing of closed-loop medical devices is an important step towards ensuring the safety of their users. To this end, staged
clinical trials have served as the gold standard for evaluating the safety and efficacy of medical devices. However, as
closed loop devices become more complicated with increasing reliance on software-based control, it is clear that clinical
trials can be inadequate for testing the safety and reliability
of the closed loop system. This is evidenced by the grow-

Copyright retained by the authors.

SIGBED Review

24

Vol. 14, Num. 2, March 2017

case behaviors of interest to the designers and clinical experts. S-Taliro provides violations for 8 out of the 10 properties formulated. It also provides the output that approaches
“closest” to violation for the remaining properties.
We conclude by identifying two potentially important directions for future work: (a) assign likelihood scores to violations to enable designers to decide if a design should be
modified in response to such a violation and (b) improve
physiological models by incorporating features that are commonly seen in actual patient data.

1.1

Table 1: Pathway to the artificial pancreas project
with representative papers showing technological
feasibility.
Source: Juvenile Diabetes Research
Foundation (JDRF). See [37] for a recently proposed
revised pathway.
ID
1
2

Related Work

3

A growing body of work focuses on modeling and analysis
of closed loop medical devices, including pacemaker and implantable cardiac defibrillators (ICDs). This has included a
range of ideas from using specification formalisms for physiological models [49], formal verification techniques to verify
closed loop models and the use of physiological models to
test control software [47, 35, 34]. Our work here focuses on
the analysis of an artificial pancreas control system using
models of human insulin-glucose regulatory systems.
The development of detailed mathematical models for the
human insulin-glucose regulation system has led to a number
of widely used models. These include the Bergman minimal
model [8, 7], Dalla Man et al [41, 20, 42] and Hovorka et
al models [33, 54]. The success of these modeling efforts
has led to the concept of in silico clinical trials that use
these models to test control algorithms [40, 48]. These approaches use a virtual clinical protocol to specify the external
inputs (meal timing, amount and bolus) to the simulation.
The simulation is performed for varying patient parameter
sets and predictions on the performance measures of interest
(eg., time in euglycemic range) are obtained. Our approach
deploys more exhaustive search techniques that search over
a large space of possible inputs to the simulation. Also, we
search for worst case scenarios with respect to given property
of interest, formulated by the user and expressed in a specification language such as Metric Temporal Logic (MTL) [38].
This paper also builds on our previous work [11] that performs an exhaustive analysis of a PID control algorithm [52].
However, the study described in this paper involves the use
of the software implementation in the loop rather than a
model constructed from descriptions in the published literature. Working with the software implementation raises
some challenges for closed loop simulation that includes the
need to construct interfaces between the plant model and
the control software. Furthermore, we focus on a wider set
of properties that are more specific to the control system
under analysis.
Our work is also related to that of Chen et al, wherein
symbolic decision procedures are applied to find patient parameter ranges for which a PID controller can be shown to
be safe [16]. Beyond the choice of a different verification
approach, Chen et al focus on capturing a range of variations of patient parameters whereas our approach captures
variations in the inputs (meals, bolus, CGM noise). Furthermore, our approach works with the actual software-inthe-loop setup rather than using a model of the controller.

2.

4

5
6

Refs.
[44]
[13]
[4, 46, 29]

[33, 32, 31]

[9, 10, 12, 18, 40, 36, 21]
[24, 23]

tails [19, 30, 53]. Our previous work on this topic also provides background on artificial pancreas control systems [11].

2.1

Background: Artificial Pancreas

Patients with type-1 diabetes (T1D) rely on external administration of insulin to manage their blood glucose levels.
The ideal range of blood glucose levels (euglycemic range) is
taken to be [70, 180]mg/dl. Hypoglycemia, caused by glucose
values that fall below 70mg/dl, can lead to coma or even
death. Similarly, glucose values that persist above 180mg/dl
is considered hyperglycemia. The short term risks of hyperglycemia above 300mg/dl include diabetic ketacidosis. The
longer term risks of hyperglycemia above 180mg/dl include
damage to eye, kidneys, heart and blood vessels. The overall goal of treating T1D is to maintain the blood glucose
levels in the euglycemic range, avoiding hypoglycemia and
minimizing the time under hyperglycemia.
Artificial Pancreas (AP) refers to a series of increasingly
sophisticated devices used to treat patients with type-1 diabetes through the external administration of insulin (and
other hormones). An AP system’s core function is to continuously adjust the insulin infusion into the patient through
an insulin infusion pump. Typical AP systems use continuous glucose monitors (CGMs) to measure the blood glucose levels in the patients. Additionally, some AP systems
may use inputs from the patients such as impending meals
and physical activity. AP systems may also output warnings/alarms to patients to announce hypoglycemia and suggest using glucagon or rescue carbohydrates. Table 1 summarizes the existing approaches to realizing the AP concept.
The low glucose pump shutoff product has been incorporated in some commercially available pumps [44]. Other
stages are undergoing various phases of clinical trials. It
must be noted that all stages have been shown to be technologically feasible. Note that the more recent road map
by Kowalski [37] emphasizes “automated insulin delivery”
and “multihormonal” approaches as parallel pathways rather
than successive stages.
Figure 1 presents the structure of a closed loop artificial
pancreas at a high level. As mentioned earlier, the closed
loop involves the action of a software-based controller that
decides on the insulin delivery rate. The high level goal of

BACKGROUND & MOTIVATION

We provide a brief background on artificial pancreas controllers that motivates the need for verification [28]. We
refer the reader to monographs on this topic for further de-

SIGBED Review

Description
Low Glucose Pump Shutoff
Pump shutoff during hypo.
Hypoglycemia Minimizer
Pump shutoff for predicted hypo.
Hypo./Hyper. Minimizer
#2 + additional insulin when
glucose above threshold
Hybrid Closed Loop
Closed loop insulin delivery
with manual bolus
Fully Automated Closed Loop
#4 with no manual boluses
Multi-hormone Closed Loop
Use glucagon and insulin

25

Vol. 14, Num. 2, March 2017

Shutoff
Exercise Meals

b(t)

+

u(t)

G(t)
Patient

n(t)

Gs (t)

CGM

Kalman Ĝ(t + 30) Rule-Based
Filter
Decision

Add Insulin
Normal

Gs (t)
uc (t)
Controller

PISA

+

Figure 2: Schematic diagram of the hypo/hyper
minimizing controller.

Figure 1: Closed loop schematic diagram of the overall artificial pancreas system.

can be incomplete or erroneous leading the controller
to make a wrong decision.

the system is to maximize the time for which the patient’s
blood glucose level G(t) remains in the euglycemic range
of [70, 180]mg/dl. Furthermore, the system seeks to avoid
hypoglycemia G(t) < 70mg/dl and minimize time under hyperglycemia G(t) > 180mg/dl.
As shown in Fig. 1, the patient’s glucose regulatory system is subject to external disturbances such as meals and
exercise. The value of the blood glucose level is estimated by
the continuous glucose monitor (CGM) to yield a sensed glucose level Gs (t). Note that the CGM is subject to external
disturbances n(t). The controller is run in a time-triggered
fashion with time period ∆. Typically ∆ is in the order of
minutes (1 − 5 minutes). The controller periodically senses
the value of Gs (t) from the CGM at t = j∆ and computes
an insulin level uc (t), which is held constant in the time interval t ∈ [j∆, (j + 1)∆). Furthermore, in many systems,
the user can provide an external bolus b(t). Typically this
bolus is provided before meals. The overall insulin infusion
u(t) = uc (t)+b(t) is the sum of the controller and externally
administered insulin.
The key challenges that make artificial pancreas control
hard include:

(e) The system is subject to various delays including sensor
delays and actuation delays caused by the delayed action
profile of insulin.
Need for Verification:
As mentioned earlier, external control of blood glucose levels is a challenging problem.
Controller malfunctions that lead to excessive insulin infusion can risk severe consequences to the patient. Typically,
software systems often carry the risk of malfunctions due
to typical programming errors such as buffer overflow, numeric overflow, and divide by zero. Software verification
techniques and better programming language design have
focused on eliminating these errors. However, a larger set of
functional correctness properties of the overall closed loop
remain quite important. The easiest functional correctness
property is that the blood glucose levels remain in the euglycemic range [70, 180]mg/dl. However, due to the significant disturbances present, it is always possible for the unanticipated user actions to cause the blood glucose levels to go
out of range.
Nevertheless, verification approaches are needed to answer
many functional correctness questions: (a) Will the insulin
infusion always be turned off when the sensor glucose value
is below 70mg/dl, the limit for hypoglycemia? (b) Can the
controller infuse extra insulin when the patient’s blood glucose level is low? If yes, what is the lowest blood glucose
level for which the controller may decide to infuse extra insulin? (c) Can the patient remain in hypoglycemia longer
than 3 hours? (d) Can the patient remain in hyperglycemia
longer than 5 hours? A larger list of such properties will be
examined in Section 6.
In this paper, we present a combination of mathematical modeling of the various components of the closed loop,
including disturbances. We perform in-silico simulations of
these models driven by simulation-based property falsification tools to find potential violations that can inform the
designers of these systems about possible worst case behaviors that can result.

(a) Excessive insulin can cause dangerously low blood glucose levels leading to coma or even death. On the other
hand, too little insulin can cause prolonged high glucose
levels leading to short term consequences such as ketacidosis and longer term damage to eye, kidneys, heart and
blood vessels.
(b) Insulin is (typically) the only available control. However, many AP systems cannot directly counteract insulin under normal circumstances. As a result, the insulin already administered persists in the system with an
onset of action 20 minutes after administration, a peak
effect around 90 minutes after administration and persists until 4-6 hours after administration. Furthermore,
the insulin action profile can differ by person.
(c) The system must counteract significant disturbances in
the form of meals and physical activities, without advance knowledge of these disturbances. Other disturbances include short term changes in patient’s physiology due to illnesses, prescription drugs, and alcohol
consumption.

3.

(d) CGMs provide an estimate of the blood glucose levels.
However, they are subject to noise, calibration errors,
dropouts and pressure induced sensor attenuation [25,
14]. As a result, the available sensor measurements

SIGBED Review

CONTROLLER

Figure 2 shows the overall schematic for the control algorithm, which is an advanced version of a predictive pump
shutoff algorithm, originally described by Cameron et al. [13].
The original system uses Kalman filter-based prediction algorithm to shutoff the pump when a hypoglycemia is predicted. The extended system studied here also commands

26

Vol. 14, Num. 2, March 2017

Table 2: Rules for pump shutoff, additional insulin
and resumption of basal insulin delivery. Note that
G(t) refers to current CGM value, Gp (t) refers to the
Kalman filter prediction at time t, Tshutof f (t) is the
total amount of time the pump has been turned off
until time t.
Condition
Gp (t + 30) ≤ 80mg/dl and
Tshutof f (t) < 180 and Tshut (t − 150) < 120

Mode
Shutoff

not Shutoff and Gp (t + 30) ≥ 150
and Tshut (t) < 180

Add Insulin

Shutoff and

Tshut

Gp (t + 30) ≥ 70 or
≥ 180 or Tshut (t − 150) ≥ 120

Insulin

Liver

meal

Digestive
System

Glucose

Insulin
Dependent

G(t)
Nervous
System

Normal

Gs (t)



Subcutaneous

Figure 3: Structure of a physiological insulin-glucose
regulatory model.
the insulin glucose regulatory system in patients with type-1
diabetes.
Physiological Models: The area of physiological modeling of insulin-glucose regulation has received considerable
attention, following seminal work by Bergman, Cobelli and
Others [7, 15]. Recently, physiological models have been
proposed, mainly by Dalla Man et al. [20, 41, 43], and Hovorka et al. [54, 33]. Figure 3 shows the schematic of these
physiological models. The main idea is to (a) write balance equations that account for the entry, storage, uptake
and excretion of glucose and insulin and (b) the effect that
plasma insulin levels have on the uptake of glucose and endogenous production by liver. The resulting model is an ordinary differential equation (ODE). This ODE is often nonlinear due to the nonlinear action profile of plasma insulin
levels on endogenous glucose production, and insulin dependent glucose uptake. Also, the gut absorption model used is
nonlinear [20]. Finally, the model can exhibit hybrid mode
switches due to the action of renal clearance that is typically
turned on only when G(t) ≥ Gr , a renal clearance threshold
parameter (typically 180mg/dl).
For our study, we use the Dalla-Man et al. model, ibid.
This model is a nonlinear ordinary differential equation (ODE)
with 10 state variables. The model and corresponding parameters are available as part of the FDA approved T1DM
simulator that can now be used as an alternative to animal
testing [42]. The model has been increasingly popular inside
a simulation environment for “in-silico” or “virtual” clinical
trials [48, 40].
Closed Loop Simulation: Closed loop simulation is performed by simulating the patient physiological model in composition with the controller. The overall closed loop model
follows the schematic in Figure 1. The inputs to the closed
loop simulation include: (a) the initial state of the patient
physiological model, (b) the timing of meals and their carbohydrate content, (c) the noise in CGM readings and (d) a
set of parameters for the physiological model that are representative of a particular patient’s insulin-glucose regulation.
Factors such as exercise are not supported by the Dalla Man
et al. model used in our simulation. However, a more re-

MODELING HUMAN PHYSIOLOGY

In this section, we briefly describe the process of modeling

SIGBED Review

Insulin
transport

Renal

extra insulin by temporarily increasing the basal insulin delivery rate to mitigate hyperglycemia, as well. Clinical trials
of the predictive pump shutoff system include the inpatient
clinical trials described by Cameron et al [13], and a more
recent trial that studied 45 patients over a total of 42 nights,
described by Maahs et al [39]. These trials reported promising results, including a longer time in the euglycemic range
for the participants.
As mentioned earlier, the system is based on a Kalman filter that analyzes the CGM glucose readings and estimates
the first and second derivatives of the blood glucose level
G(t). Based on the estimated derivatives, it predicts the
value Gp (t + 30) of the blood glucose levels 30 minutes into
the future. This prediction is used by a rule-based decision
support system to command possible pump actions that include (a) shutoff: shut the pump down for a given time
interval, (b) Add Insulin: infuse extra insulin, (c) Normal: continue the current basal rate, and (d) PISA: Alert
the user of faulty CGM values caused by pressure induced
sensor attenuation.
Table 2 briefly describes the major rules that are used by
the system to control insulin delivery. However, many of
the finer details such as the handling of CGM dropouts and
sensor attenuation have been omitted from this discussion.
These details will be provided upon request. A shutoff is
commanded when the predicted glucose level at t + 30mins
is below 80mg/dl, the total shutoff time is less than 180mins,
and total shutoff time in the previous 150mins is less than
120mins. Likewise, additional insulin maybe commanded if
the pump is not currently shutoff, and the predicted glucose
value is above 150mg/dl. Furthermore, additional insulin
may only be commanded if there is time remaining for pump
shutoff.
The full set of rules that govern the control algorithm
considers numerous other factors such as pressure induced
sensor attenuation, the possibility of loss in sensor signal
(dropout), large changes in the sensor value and the time
to next sensor calibration. These rules constitute about 900
lines of code written in MATLAB(tm).

4.

insulin

27

Vol. 14, Num. 2, March 2017

Meal# 1

ϕ

Bolus #1

Model

Simulator
Simulink/Stateflow(tm)

x

Robustness
Calculator

Bolus #2
Closed Loop On

Time

Figure 5: Timeline of simulated events for the closed
loop simulation.

Global
Optimization

optimization engine that seeks to minimize this value. The
global optimizer, in turn, decides on future test inputs to the
simulator based on the past inputs and the robustness values
of the resulting traces. Currently, the tool supports many
optimization engines including uniform random exploration,
simulated annealing search, ant-colony optimization, crossentropy method and genetic algorithms. Since no single optimization engine can guarantee finding a global minimum,
the typical practice of using the tool consists of using multiple optimization engines, repeatedly and in parallel. If the
tool fails to discover a violation, one of the key advantages of
robustness metrics is that the least robust trace can provide
a relaxed property that can be violated by S-Taliro. S-Taliro
is available as an open source tool 2 , and is built to be extensible through the addition of new solvers and alternative
robustness computation techniques. The latest version uses
multiple cores to perform numerous simulations in parallel.
It also supports features such as property-directed parameter tuning for models and requirements. These features will
be enhanced in future releases of the tool.

Figure 4: Illustration of the overall robustnessguided falsification setup.
cently proposed model incorporates exercise and the action
of glucagon (counter-regulation) [42].

ROBUSTNESS-GUIDED TESTING

In this section, we briefly describe robustness guided falsification approach to testing properties of closed-loop control
systems. Numerous details that are skipped here are available elsewhere [1, 11]. The presentation of robustness-guided
falsification below has been excerpted from our previous survey on this topic [11].
Given a mathematical model M and a property P over
its outputs, are there inputs to the model whose outputs
can violate P ? To answer this problem, model checking approaches search over the space of all possible inputs, stopping when a violation is found [5, 17]. However, in many
cases, the models are infinite state making the process of
exhaustively simulating all inputs quite expensive, if not impossible. As a result, many approaches have been proposed
to examine inputs that are “promising” while avoiding inputs
that are “unlikely” to yield violations.
Robustness-guided falsification approaches are based on
two main ideas: (a) A distance metric from an output trace
to a property violation [26, 50, 22]. Such a metric is referred to as the “trace robustness”. Intuitively, a trace with
a smaller robustness is therefore “closer” to a violation when
compared to a trace that has a larger robustness. (b) The
robustness metric is used as an objective function to guide
the system towards property violations in a systematic manner by seeking trajectories of ever decreasing robustness [45,
1, 3]. This is typically solved using heuristic global optimization algorithms such as simulated annealing [45, 1], antcolony optimization [2], genetic algorithms and the crossentropy method [51]. If these techniques discover a negative robustness trace, then a property violation is concluded.
Otherwise, the least robust trace often provides valuable information to the designer, as to how close we get towards
violating the property.

5.1

End of Simulation

ρ(x, ϕ)

Inputs

5.

Meal# 2

6.

PROPERTIES

We now describe the overall setup for our closed-loop in
silico study. We describe the use of S-Taliro to search for
violations of key properties. We report the results of S-Taliro
alongside each property.
Study Setup: The overall timeline of events for the simulation is shown in Figure 5. The simulation setup models a
common usage scenario, wherein the user is assumed to eat
a meal (dinner) and a snack. The meal timings and amount
of carbohydrates (CHO) vary over a range, as specified in
Table 3. The simulation also models the user’s open loop
bolusing behavior by selecting a bolus time which can be
anywhere between 20 min before the meal or up to 20 min
after the meal. The insulin to CHO ratio used to calculate
the insulin bolus amount is also varied in a range. Finally,
we assume a fixed controller starting time when the closed
loop is switched on and include a range of values for the
sensor noise, also shown in Table 3. In particular, we also
perform an open loop simulation wherein the controller is
never turned on, in contrast with a closed loop simulation,
wherein the controller is turned on at t = 50min.

S-Taliro Tool

Figure 4 shows a schematic diagram for S-Taliro 1 , a robustness guided falsification tool that supports MTL properties [3]. S-Taliro has been implemented inside the Matlab
(tm) environment, and can support models described inside
Simulink/Stateflow (tm). The tool uses the inbuilt simulator and computes the robustness for a trace. The resulting robustness is used as an objective function by a global

S-Taliro Setup:
S-Taliro takes the overall closed loop
model and searches over the space of inputs from Table 3
for property violations. The tool formulates a total of 127
inputs that includes 120 sensor noise values. Rather than
find a single violation, we repeatedly ran the tool up to 7
times for each property, stopping each run when a violation
is discovered. This allows us to discover multiple violations.
We simply used the uniform random search heuristic that

1

2

S-Taliro stands for System TemporAl LogIc RObustness

SIGBED Review

28

Cf. https://sites.google.com/a/asu.edu/s-taliro/s-taliro

Vol. 14, Num. 2, March 2017

Table 3: Inputs to the closed-loop simulator.
Inputs
Range
Meal #1 Time
[20, 40]min
Meal # CHO
[60, 150]gms
Meal #2 Time
[180, 300]min
Meal #2 CHO
[0, 60]gms
Insulin Bolus Delta
[−20, 20]min
Insulin-CHO Ratio
[0.05, 0.2]U/gm
Open Loop Basal
[0.01, 0.1]U/hr
Controller Start Time
{50min}
Sensor noise (∼ 120 inputs) [−20, 20]mg/dl

Figure 7: Least robust trace showing a “near violation” of property P1.2. Extra insulin is commanded,
for 5 minutes at G(t) ∼ 90mg/dl.

P1.1: Is it possible for basal insulin to be resumed when
G(t) ≤ 70mg/dl while the total shutoff time and the
shutoff time within the current time window are still
below their upper limits?
It is important to specify that the shutoff times so far
are under the maximum permitted limit since the pump will
resume automatically when these limits have been exceeded.
S-Taliro ran for nearly 2 hours and 5 minutes and found
5 violations. Figure 6 shows the glucose and insulin for the
violation. The circled region shows the violation wherein
insulin delivery is resumed even under hypoglycemia. The
noise pattern in the CGM affects the future glucose prediction (shown in magenta in Fig. 6) and causes the delivery
to resume. Such a scenario can be potentially addressed by
either (a) adjusting the gains for the Kalman filter to be
more robust to noise and/or (b) requiring glucose levels to
cross a minimal threshold before resuming insulin delivery.

Figure 6: Least robust trace showing violation of
property P1.1. The basal insulin is resumed when
G(t) ≤ 70mg/dl. The solid (blue) curve on bottom
plot the insulin delivered to the patient as sum of the
original basal insulin plus the controller commands
that can infuse the basal insulin, add extra insulin
over the basal rate, or shutoff delivery. The red
dotted line shows the extra insulin commanded by
the controller. Pump shutoff occurs whenever the
total insulin infusion is zero.
blindly samples from the set of violations. We observed that
simulated annealing was less effective for this benchmark.
The relative large search space is one possible reason for
this.

6.1

P1.2: Is it possible for additional insulin to be commanded when G(t) ≤ 80mg/dl.
S-Taliro ran for nearly 7.5 hours, performing 750 simulations. It could not violate this property. Nevertheless,
we find an interesting near violation, shown in Fig. 7. It
demonstrates the infusion of extra above basal insulin commanded by the controller. However, this happens around
G(t) ∼ 90mg/dl. Also, the command is for a very short
time period. Also, note that the brief rise in CGM values
due to the added disturbances coincides with the additional
insulin commanded.

Properties and S-Taliro Results

We will now describe the classes of properties that we wish
to test for the overall closed loop. Note that the properties
are meant to expose and understand corner case behaviors
of the closed loop. In other words, we currently lack information as to the likelihood of the violations in realistic usage
scenarios. However, once understood, it will be essential to
find fixes/mitigations for the likely violations described in
this section.

P1.3: Is it possible for additional insulin input to be
commanded and subsequently the pump shutoff within
30 minutes?

Control during Low Glucose Levels: An important
objective of the control algorithm is to reliably turn off insulin delivery in advance of an impending hypoglycemia. As
a result, important questions include whether the controller
will resume basal insulin delivery or even infuse additional
insulin when the patient is already under hypoglycemia?

SIGBED Review

Whereas, a violation of this property is not a safety violation, it provides us insights into how the process of deciding
on extra insulin can interact with the pump shutoff. S-Taliro

29

Vol. 14, Num. 2, March 2017

Figure 10: A single trace that violates properties
P2.1, P2.2 and P2.3. The pump shuts down for a
short interval of 5 minutes when G ∼ 400mg/dl, the
blood glucose levels are in hyperglycemia for almost
95% of the total simulation time and the time above
300mg/dl exceeds 3 hours.

Figure 8: Least robust trace showing a “violation”
of property P1.3. Extra insulin is commanded at
the point of impending hypoglycemia and the pump
shutdown almost immediately.

blood glucose levels under hyperglycemia (G ≥ 180mg/dl)
and extreme hyperglycemia (G ≥ 300mg/dl).
P2.1: Can the pump be shutoff when G ≥ 300mg/dl?

P2.2: Can the total time under hyperglycemia G ≥
180mg/dl exceed 70% of the total simulation time?

P2.3: Can the total time under hyperglycemia G ≥
300mg/dl exceed 3hrs?
S-Taliro ran for nearly 1 hour and 6 minutes to discover
5 violations for property P2.1 The least robust violation
is shown in Fig 10. Note that the pump is shutoff for a
small duration of 5 minutes while the blood glucose G(t) ∼
400mg/dl. Interestingly, we found that all three properties
are violated by this single trace! The pump shutdown results
due to sensor noise that causes it to shutdown. However, the
extended time under hyperglycemia is a result of inadequate
meal bolus. The controller does not infuse enough extra insulin to rectify this situation for this simulation.

Figure 9: Least robust trace showing a violation
of property P1.4. The user enters hypoglycemia
around T = 400 minutes. The pump is shutoff for
less than 50% of this time.
ran for nearly 2.2 hours, finding nearly 4 violations of this
property. Figure 8 shows the least robust violation. Interestingly, we notice that a temporary glitch caused by the
CGM noise causes the controller to briefly command a small
amount of extra insulin above basal and shut off the pump
immediately. The scenario can be potentially addressed by
(a) adding an additional rule that would require a minimal
threshold for CGM value before additional insulin is commanded and/or (b) adjusting the Kalman filter gain values.

Comparing Closed and Open Loop Performance: A
key class of properties involve questions about open vs. closed
loop performance for identical meals, insulin bolus, basal insulin levels and starting patient physiological state. Such a
comparison is hard, if not impossible, in a clinical setting,
but possible in silico, due to mathematical models.

P1.4: Let γ be the ratio of total pump shutoff time
divided by the total time under hypoglycemia. Can γ ≤
0.7? In other words, will the pump be shutoff for less
than 70% of the time under hypoglycemia?

P3.1: Is it possible for the closed loop hypoglycemia
whereas the open loop blood glucose value remains
above 80mg/dl?

S-Taliro ran for nearly 3 hours and 20 minutes, finding 5
violations. The least robust violation is shown in Fig 9.
Control during High Glucose Levels: We now examine a list of questions about the controller behavior under

SIGBED Review

S-Taliro ran on this property for nearly 4.5 hours, yielding 2 violations. The least robust violation is shown in Figure 11.

30

Vol. 14, Num. 2, March 2017

for each CGM readings, allowing S-Taliro to choose any error
value in this range. Our future work will use existing clinical
data that contrasts CGM data with gold standard blood
glucose data from instruments such as YSI glucose meters.
Incorporating more realistic constraints on the CGM noise
patterns introduced by S-Taliro is one way to ensure that
the results are valid.
Next, we note that the lack of modeling for counter-regulatory
processes makes the physiological model potentially less accurate for hypoglycemia. Incorporating more recently proposed models that incorporate counter-regulation is an important next step.
Finally, we note that simulations carried out by S-Taliro
are quite expensive. We are investigating the process of
parallelizing the simulations to gain efficiency and perform
much larger number of simulations.

Figure 11: Violation of property P3.1 showing the
closed loop simulation under hypoglycemia whereas
the open loop stays well above the hypoglycemic
limit.

7.

Figure 12: Violation of property P3.3 showing the
open loop simulation having a longer time in range.
Note that starting from t ∼ 450 mins, the closed loop
simulation enters a prolonged hypoglycemia with
G(t) ∼ 70mg/dl.

P3.2: Is it possible for the closed loop hyperglycemia
above 300mg/dl whereas the open loop blood glucose
level remains below 180mg/dl? In practice, it is necessary to check for ketones when G ≥ 300mg/dl, making
it an important limit.

8.

P3.3: Let ρ represent the ratio of time in range for the
closed loop vs. time in range for the open loop. Is it
possible for ρ < 0.7?
After running for 8 hours, S-Taliro discovers 8 violations,
the least robust of which is shown in Figure 12.

Discussion

At a high level, we find violations to 8 of the 10 properties
and a near violation for one more. It must be noted that the
CGM noise pattern seems to be the single most important
cause of these violations. However, our simulation currently
uses a coarse range of [−20, 20]mg/dl as bounds on the error

SIGBED Review

REFERENCES

[1] H. Abbas, G. Fainekos, S. Sankaranarayanan,
F. Ivancic, and A. Gupta. Probabilistic temporal logic
falsification of cyber-physical systems. Trans. on
Embedded Computing Systems (TECS), 12:95–, 2013.
[2] Y. S. R. Annapureddy and G. E. Fainekos. Ant
colonies for temporal logic falsification of hybrid
systems. In Proceedings of the 36th Annual Conference
of IEEE Industrial Electronics, pages 91 – 96, 2010.
[3] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and
S. Sankaranarayanan. S-taliro: A tool for temporal
logic falsification for hybrid systems. In Tools and
algorithms for the construction and analysis of
systems, volume 6605 of LNCS, pages 254–257.
Springer, 2011.
[4] E. Atlas, R. Nimri, S. Miller, E. A. Grunberg, and
M. Phillip. MD-Logic artificial pancreas system: A
pilot study in adults with type 1 diabetes. Diabetes
Care, 33(5):1072–1076, May 2010.
[5] C. Baier and J.-P. Katoen. Principles of Model
Checking. MIT Press, 2008.

S-Taliro could not obtain a violation for this property even
after running S-Taliro for 10 hours during which about 700
simulations were performed.

6.2

CONCLUSIONS

In conclusion, we have shown a case-study of a hypo/hyper
mitigating controller using S-Taliro to identify corner case
property violations. In doing so, we formulated 10 properties, discovering 8 violations and one scenario that comes
close to a violation. We also identify possible solutions to
mitigating some of these violations by modifying the algorithm. However, before we do so, it is essential to assign
likelihood scores to these violations. Such scores will allow
us to better triage these violations and prioritize the fixes.
Building such scores will require us to design approaches to
precisely identify the “root causes” and use data to estimate
their likelihood. Another important advance involves the automatic tuning of system parameters to fix these violations.
Promising approaches that use sensitivity analysis [22] and
robustness of temporal properties have been proposed for
this problem [6].
Acknowledgments:
We thank the anonymous reviewers for their valuable suggestions. This material is based
upon work supported by the US National Science Foundation (NSF) under grant numbers CPS-1446900, CNS-1319457,
CPS-1446751, and CNS-1319560. All opinions expressed are
those of the authors, and not necessarily of the NSF.

31

Vol. 14, Num. 2, March 2017

[6] E. Bartocci, L. Bortolussi, L. Nenzi, and
G. Sanguinetti. Systematic design of stochastic models
using robustness of temporal properties. Theoretical
Computer Science, 587:3 – 25, 2015.
[7] R. N. Bergman. Minimal model: Perspective from
2005. Hormone Research, pages 8–15, 2005.
[8] R. N. Bergman and J. Urquhart. The pilot gland
approach to the study of insulin secretory dynamics.
Recent Progress in Hormone Research, 27:583–605,
1971.
[9] F. Cameron. Explicitly Minimizing Clinical Risk
through Closed-loop Control of Blood Glucose in
Patients with Type 1 Diabetes Mellitus. PhD thesis,
Stanford University, 2010.
[10] F. Cameron, B. W. Bequette, D. Wilson,
B. Buckingham, H. Lee, and G. Niemeyer. Closed-loop
artificial pancreas based on risk management. J.
Diabetes Sci Technol., 5(2):368–79, 2011.
[11] F. Cameron, G. Fainekos, D. M. Maahs, and
S. Sankaranarayanan. Towards a verified artificial
pancreas: Challenges and solutions for runtime
verification. In Proceedings of Runtime Verification
(RV’15), volume 9333 of Lecture Notes in Computer
Science, pages 3–17, 2015.
[12] F. Cameron, G. Niemeyer, and B. W. Bequette.
Extended multiple model prediction with application
to blood glucose regulation. Journal of Process
Control, 22(8):1422–1432, Sep 2012.
[13] F. Cameron, D. M. Wilson, B. A. Buckingham,
H. Arzumanyan, P. Clinton, H. P. Chase, J. Lum,
D. M. Maahs, P. M. Calhoun, and B. W. Bequette.
Inpatient studies of a kalman-filter-based predictive
pump shutoff algorithm. J. Diabetes Science and
Technology, 6(5):1142–1147, 2012.
[14] J. Castle and K. Ward. Amperometric glucose sensors:
Sources of error and potential benefit of redundancy.
J. Diabetes Sci. and Tech., 4(1), January 2010.
[15] F. Chee and T. Fernando. Closed-Loop Control of
Blood Glucose. Springer, 2007.
[16] S. Chen, M. O’Kelly, J. Weimer, O. Sokolsky, and
I. Lee. An intraoperative glucose control benchmark
for formal verification. In 5th IFAC conference on
Analysis and Design of Hybrid Systems (ADHS), Oct
2015.
[17] E. M. Clarke, O. Grumberg, and D. A. Peled. Model
Checking. MIT Press, 1999.
[18] Claudio Cobelli et al. and AP@Home Consortium.
First use of model predictive control in outpatient
wearable artificial pancreas. Diabetes Care,
37(5):1212–1215, May 2014.
[19] C. Cobelli, C. D. Man, G. Sparacino, L. Magni, G. D.
Nicolao, and B. P. Kovatchev. Diabetes: Models,
signals and control (methodological review). IEEE
reviews in biomedical engineering, 2:54–95, 2009.
[20] C. Dalla Man, R. A. Rizza, and C. Cobelli. Meal
simulation model of the glucose-insulin system. IEEE
Transactions on Biomedical Engineering,
1(10):1740–1749, 2006.
[21] E. Dassau, H. Zisser, H. R.A., P. M.W., B. Grosman,
W. Bevier, E. Atlas, S. Miller, R. Nimri, L. Jovanovic,
and D. F.J. Clinical evaluation of a personalized
artificial pancreas. Diabetes Care, 36(4):801–9, 2013.

SIGBED Review

[22] A. Donzé and O. Maler. Robust satisfaction of
temporal logic over real-valued signals. In FORMATS,
volume 6246 of Lecture Notes in Computer Science,
pages 92–106. Springer, 2010.
[23] F. El-Khatib, J. Jiang, and E. R. Damiano. Adaptive
closed-loop control provides blood-glucose regulation
using dual subcutaneous insulin and glucagon infusion
in diabetic swine. J Diabetes Sci Technol.,
1(2):181–92, 2007.
[24] F. H. El-Khatib, S. J. Russell, D. M. Nathan, R. G.
Sutherlin, and E. R. Damiano. A bihormonal
closed-loop artificial panceras for type 1 diabetes. Sci.
Transl. Med., 2, April 2010.
[25] A. Facchinetti, G. Sparacino, and C. Cobelli. Modeling
the error of continuous glucose monitoring sensor data:
Critical aspects discussed through simulation studies.
J. Diabetes Sci. and Tech., 4(1), January 2010.
[26] G. Fainekos and G. J. Pappas. Robustness of temporal
logic specifications for continuous-time signals.
Theoretical Computer Science, 410:4262–4291, 2009.
[27] G. E. Fainekos. Robustness of Temporal Logic
Specifications. PhD thesis, Department of Computer
and Information Science, University of Pennsylvania,
2008.
[28] G. P. Forlenza, S. Sankaranarayanan, and D. M.
Maahs. Refining the closed loop in the data age:
Research-to-practice transitions in diabetes
technology. Diabetes Technology & Therapeutics,
17(5), 2015.
[29] B. Grosman, E. Dassau, H. Zisser, L. Jovanovic, and
D. F.J. Zone model predictive control: A strategy to
minimize hyper- and hypoglycemic events. J Diabetes
Sci Technol., 4(4):961–75, 2010.
[30] R. Hovorka. Continuous glucose monitoring and
closed-loop systems. Diabetic Medicine, 23(1):1–12,
2005.
[31] R. Hovorka, J. M. Allen, D. Elleri, L. J. Chassin,
J. Harris, D. Xing, C. Kollman, T. Hovorka, A. M.
Larsen, M. Nodale, A. D. Palma, M. Wilinska,
C. Acerini, and D. Dunger. Manual closed-loop
delivery in children and adoloscents with type 1
diabetes: a phase 2 randomised crossover trial. Lancet,
375:743–751, February 2010.
[32] R. Hovorka, V. Canonico, L. Chassin, U. Haueter,
M. Massi-Benedetti, M. Frederici, T. Pieber,
H. Shaller, L. Schaupp, T. Vering, and M. Wilinska.
Nonlinear model predictive control of glucose
concentration in subjects with type 1 diabetes.
Physiological Measurement, 25:905–920, 2004.
[33] R. Hovorka, F. Shojaee-Moradie, P. Carroll,
L. Chassin, I. Gowrie, N. Jackson, R. Tudor,
A. Umpleby, and R. Hones. Partitioning glucose
distribution/transport, disposal and endogenous
production during IVGTT. Am. J. Physiol.
Endocrinol. Metab., 282:992–1007, 2002.
[34] Z. Jiang, M. Pajic, R. Alur, and R. Mangharam.
Closed-loop verification of medical devices with model
abstraction and refinement. International Journal on
Software Tools for Technology Transfer, pages 1–23,
2013.
[35] Z. Jiang, M. Pajic, S. Moarref, R. Alur, and
R. Mangharam. Modeling and verification of a dual

32

Vol. 14, Num. 2, March 2017

[36]

[37]

[38]

[39]

[40]

[41]

[42]

[43]

[44]

[45]

chamber implantable pacemaker. In Tools and
Algorithms for the Construction and Analysis of
Systems (TACAS), volume 7214 of Lecture Notes in
Computer Science, pages 188–203. 2012.
B. Kovatchev, C. Cobelli, E. Renard, S. Anderson,
M. Breton, S. Patek, W. Clarke, D. Bruttomesso,
A. Maran, S. Costa, A. Avogaro, C. Dalla Man,
A. Facchinetti, L. Magni, G. De Nicolao, J. Place, and
A. Farret. Multinational study of subcutaneous
model-predictive closed-loop control in type 1 diabetes
mellitus: summary of the results. J Diabetes Sci
Technol., 4(6):1374–81, 2010.
A. Kowalski. Pathway to artificial pancreas revisited:
Moving downstream. Diabetes Care, 38:1036–1043,
June 2015.
R. Koymans. Specifying real-time properties with
metric temporal logic. Real-Time Systems,
2(4):255–299, 1990.
D. M. Maahs, P. Calhoun, B. A. Buckingham, and
Others. A randomized trial of a home system to
reduce nocturnal hypoglycemia in type 1 diabetes.
Diabetes Care, 37(7):1885–1891, July 2014.
L. Magni, D. Raimondo, L. Bossi, C. D. Man, G. D.
Nicolao, B. Kovatchev, and C. Cobelli. Model
predictive control of type 1 diabetes: an in silico trial.
J. Diabetes Science and Technology, 1(6):804–12, 2007.
C. D. Man, M. Camilleri, and C. Cobelli. A system
model of oral glucose absorption: Validation on gold
standard data. Biomedical Engineering, IEEE
Transactions on, 53(12):2472 –2478, dec. 2006.
C. D. Man, F. Micheletto, D. Lv, M. Breton,
B. Kovatchev, and C. Cobelli. The UVA/PADOVA
type 1 diabetes simulator: New features. J. Diabetes
Science and Technology, 8(1), January 2014.
C. D. Man, D. M. Raimondo, R. A. Rizza, and
C. Cobelli. GIM, simulation software of meal
glucose-insulin model. J. Diabetes Sci. and Tech., 1(3),
May 2007.
Medtronic Inc. “paradigm” insulin pump with low
glucose suspend system, 2012. Cf. http://www.
medtronicdiabetes.ca/en/paradigm veo glucose.html.
T. Nghiem, S. Sankaranarayanan, G. E. Fainekos,
F. Ivančić, A. Gupta, and G. J. Pappas. Monte-carlo
techniques for falsification of temporal properties of
non-linear hybrid systems. In Hybrid Systems:
Computation and Control, pages 211–220. ACM Press,
2010.

SIGBED Review

[46] R. Nimri, I. Muller, E. Atlas, S. Miller, O. Kordonouri,
N. Bratina, C. Tsioli, M. Stefanija, T. Danne,
T. Battelino, and P. M. Night glucose control with
md-logic artificial pancreas in home setting: a single
blind, randomized crossover trial-interim analysis.
Pediatric Diabetes, 15(2):91–100, March 2014.
[47] M. Pajic, R. Mangharam, O. Sokolsky, D. Arney,
J. Goldman, and I. Lee. Model-driven safety analysis
of closed-loop medical systems. Industrial Informatics,
IEEE Transactions on, 10(1):3–16, Feb 2014.
[48] S. Patek, B. Bequette, M. Breton, B. Buckingham,
E. Dassau, F. Doyle III, J. Lum, L. Magni, and
H. Zisser. In silico preclinical trials: methodology and
engineering guide to closed-loop control in type 1
diabetes mellitus. J Diabetes Sci Technol.,
3(2):269–82, 2009.
[49] Y. Pei, E. Entcheva, R. Grosu, and S. Smolka.
Efficient modeling of excitable cells using hybrid
automata. In Proc. Computational Methods in
Systems Biology, pages 216–227, 2005.
[50] A. Rizk, G. Batt, F. Fages, and S. Soliman. On a
continuous degree of satisfaction of temporal logic
formulae with applications to systems biology. In 6th
International Conference on Computational Methods
in Systems Biology, number 5307 in LNCS, pages
251–268. Springer, 2008.
[51] S. Sankaranarayanan and G. E. Fainekos. Falsification
of temporal properties of hybrid systems using the
cross-entropy method. In HSCC, pages 125–134.
ACM, 2012.
[52] G. M. Steil. Algorithms for a closed-loop artificial
pancreas: The case for proportional-integral-derivative
control. J. Diabetes Sci. Technol., 7:1621–1631,
November 2013.
[53] R. E. Teixeira and S. Malin. The next generation of
artificial pancreas control algorithms. J. Diabetes Sci.
and Tech., 2:105–112, Jan 2008.
[54] M. Wilinska, L. Chassin, C. L. Acerini, J. M. Allen,
D. Dunber, and R. Hovorka. Simulation environment
to evaluate closed-loop insulin delivery systems in type
1 diabetes. J. Diabetes Science and Technology, 4,
January 2010.

33

Vol. 14, Num. 2, March 2017

On-Line Monitoring for Temporal Logic Robustness
Adel Dokhanchi, Bardh Hoxha, and Georgios Fainekos

arXiv:1408.0045v1 [cs.SY] 31 Jul 2014

School of Computing, Informatics and Decision Systems Engineering
Arizona State University
{adokhanc,bhoxha,fainekos}@asu.edu

Abstract. In this paper, we provide a Dynamic Programming algorithm for online monitoring of the state robustness of Metric Temporal Logic specifications
with past time operators. We compute the robustness of MTL with unbounded
past and bounded future temporal operators (MTL<+∞
+pt ) over sampled traces of
Cyber-Physical Systems. We implemented our tool in Matlab as a Simulink block
that can be used in any Simulink model. We experimentally demonstrate that the
<+∞
overhead of the MTL+pt
robustness monitoring is acceptable for certain classes
of practical specifications.

1

Introduction

Modern airplanes, automobiles and medical devices are prime examples of safety critical Cyber-Physical Systems (CPS). Nowadays, the majority of safety critical functions
in such systems is controlled by embedded computers. Due to the critical nature of these
components, it is of paramount importance to verify the functional correctness of the
embedded software. However, as the number of computer controlled components increases so does the complexity of the verification of functional correctness. Moreover,
the verification problem of most classes of CPS is even an undecidable problem [1].
As an alternative to verification and off-line testing, runtime monitoring has been
proposed. The underlying idea is that given a set of formal requirements, these requirements are analyzed at runtime by an independent monitor and if a violation is detected,
it is reported to a supervisor. The supervisor can then decide on remedial actions to
fix the problem or reduce its impact to the system. The monitoring problem has been
extensively studied [2–14] for the cases where the formal requirements are expressed
in Linear Temporal Logic (LTL) [15] or in Metric Temporal Logic (MTL) [16].
In this paper, we revisit the MTL runtime monitoring problem when targeted to
CPS. In particular, we claim that the classical Boolean semantics (or even three valued semantics) are not sufficiently informative for CPS behaviors. For instance, consider the specification “After a takeoff command is received, then reach altitude of 600ft
within 5 minutes” for an autonomous Unmanned Aerial Vehicle (UAV) as introduced
in [8]. Clearly, knowing that the specification failed or passed at runtime is important.
However, more useful information from the perspective of the supervisor would be the
knowledge of how far is the aircraft from satisfying the requirement. More specifically,
-10ft from the requirement of 600ft at 1 min away from the 5 min threshold should
potentially be less alarming than -100ft at exactly the same time. A supervisor that has
a model of the dynamics of the aircraft can determine whether the UAV can climb 100ft

2

within 1 min or not. We remark that the determination of the climb rate can only occur at runtime since this depends on the atmospheric parameters, the payload of the
UAV, etc. Hence, the climb rate cannot be a precomputed parameter unless it is very
conservatively set.
Our goal is to construct MTL monitors for estimating the robustness of satisfaction
[17–19]. Temporal logic robustness gives a quantitative interpretation of satisfaction of
an MTL formula. In detail, if an MTL formula valuates to positive robustness ε, then
the specification is true and, moreover, the state sequences can tolerate perturbations
up to ε and still satisfy the specification. Similarly, if the robustness is negative, then
the specification is false and, moreover, the state sequences under ε perturbations still
do not satisfy the specification. Thus, robust semantics can be used to give quantitative
values to the satisfaction of MTL formulas when the target is CPS.
The challenge here is that automata based monitors [13, 14] cannot be synthesized
for computing the robustness valuations. Therefore, formula rewriting methods [11] or
dynamic programming [9] methods must be used. Here, we take the latter approach for
combined unbounded past time and bounded future time MTL specifications. Since we
are working with CPS, we assume that it is possible - if desired - to have a model predictive component in the system [20] which will provide a finite horizon prediction of
the system behavior. That finite horizon prediction could be appended with the observed
system behavior to provide a robustness estimate of a likely system behavior. Hence,
it becomes possible to monitor specifications such as “If at anytime in the past a takeoff command is issued, then within 5 min the altitude of 600ft is reached”. Thus, such
requirements can now be monitored using only the actual observed system behavior or
the observed system behavior with the predicted system behavior.
Our contributions in this paper are as follows: We provide a dynamic programming algorithm for on-line monitoring of the robustness metric of MTL formulas with
bounded future and unbounded past. In addition, we provide a Matlab/Simulink toolbox that can be used in any Simulink model for runtime monitoring of MTL robustness.
The memory usage of our method is bounded and its runtime overhead is negligible for
practical applications. Additional benefits in utilizing an on-line monitor are that it can
be used in temporal logic testing algorithms [21, 22], where it may be desirable that the
simulation stops as soon as the property is violated, as well as in feedback control for
MTL specifications. Although temporal logic robustness has been considered in previous works [17–19], the solutions were provided for off-line testing. To the best of
our knowledge, this is the first attempt to solve the on-line MTL robustness monitoring
problem efficiently.

2

Problem Formulation

In the following, we represent the set of natural numbers including zero by N and the
finite interval of N up to m by Nm = {0, 1, . . . , m}. In this work, we consider monitoring
of Cyber-Physical Systems (CPS). We assume that we have access to some discrete time
execution or simulation traces of the CPS. We view (execution or simulation) traces as
timed state sequences T = T0 T1 T2 . . . Tm = (τ0 , s0 ) (τ1 , s1 ) (τ2 , s2 ) . . . (τm , sm ) where
for each k ∈ Nm , τk ∈ R≥0 is a time stamp and sk ∈ S is a vector containing the

3

Simulink model or Deployed System

CPS

‫ݏ‬௜ ‫ݏ‬௜ାଵ …‫ݏ‬௜ାு௥௭

On-Line
Robustness
Monitor for φ

Plot
Robustness

Feedback loop (future work)
Fig. 1. Overview of the solution of the MTL<+∞
+pt on-line monitoring problem. The monitored
robustness values could be used as feedback to the CPS or it could be plotted to be observed by a
human supervisor if needed.

values of the state variables of the system at each sampling instance k. For example,
for m = 2, the trace T = (0, (2, 0.34))(0.1, (3, 0.356))(0.2, (2, 0.36)) captures the finite
time execution of a CPS with two state variables in the vector sk : one ranging over the
natural numbers N and the other over the reals R. That is, for k = 1, the state of the
system at time τ1 = 0.1 was s1 = (3, 0.356) ∈ N × R. We further assume that S = (S , d)
is a generalized quasi-metric space [23]. The existence of metrics is necessary so that
distances can be defined for quantitative valuations of the atomic propositions [18, 21].
Throughout the paper, the variable i, which ranges over N, is used to represent the
current simulation step or the current index of the sampling process. We assume a
fixed sampling period for the monitored system. Thus, there exists a fixed time period
between consecutive time stamps. For the fixed time period ∆t > 0, for all i ≥ 0, we
have τi+1 − τi = ∆t (or equivalently τi = i∆t). As a result, we can simply compute each
time stamp τi knowing the trace index (or simulation step) i by multiplication (τi = i∆t).
Therefore, we use the trace index (simulation step i) as the reference of time.
The property of interest is stated in Metric Temporal Logic (MTL) with bounded future and unbounded past (MTL<+∞
+pt ) for timed state sequences [11]. More specifically,
at each time i, we would like to monitor safety requirements represented as MTL<+∞
+pt
formulas. These formulas capture safety properties of the system, such as bounded reactivity, which can be periodically analyzed for violation. In our formulation, we use the
robust (quantitative) semantics [18] that quantify the distance between a given execution trace of a CPS and all the execution traces that violate the property. The robustness
of a formula JϕK with respect to a trace T at time i is a value that measures how far is
the trace from the satisfaction/falsification. This measure is an extension of boolean values representing satisfaction or falsification which is used in conventional monitoring.
A positive robustness value means that the trace satisfies the property and a negative
robustness means that the specification is not satisfied.
Our goal in this paper is to provide monitoring tools for temporal logic robustness.
We assume that at each time i, the CPS outputs its current state si along with a finite
prediction si+1 , si+2 , . . ., si+Hrz of horizon length Hrz ∈ N (see Fig. 1). The horizon
length Hrz will be formally defined in Sec. 4; however, informally, it is the required
number of samples after time i so that any future requirements in the MTL specification
φ are resolved, i.e., the horizon depends on the structure of the formula φ, Hrz = hrz(φ).

4

When dealing with CPS, there exist numerous methods by which such a prediction
horizon (forecasting) can be computed [24–26].
Next, we formally define the main problem presented in this paper.
<+∞
Problem 1 (MTL<+∞
+pt Robustness Monitoring) Given an MTL+pt specification ϕ, a
sampling instance i and an execution trace T = T0 T1 . . . Tm such that m = i + hrz(ϕ),
compute the current robustness estimate [[ϕ]](T , i) at time τi .

Intuitively, ϕ represents a system invariant that must hold at every point in the
system execution. This can also be viewed as testing for the specification robustness
[[ϕ]](T , 0), where  is the operator for “always in the future” and ϕ is an arbitrary
MTL<+∞
+pt specification. However, instead of caring about the satisfaction of the formula
at the beginning of the time, we care about the potential of violating ϕ for which we
design an on-line monitor.
Overview of solution and summary of contributions: We provide an on-line monitoring approach for computing the robustness of an MTL<+∞
+pt formula with respect to
execution traces of a CPS. An overview of the solution for the MTL<+∞
+pt on-line monitoring problem appears in Fig. 1. Our method monitors the behavior of a CPS as it
executes. Our toolbox is also useful for applications where Simulink models are actually used for process monitoring (and not simulation). In addition, it can also be used
for code generation for general MTL<+∞
+pt monitors for deployment on actual systems.
Our method computes the robustness of invariants [[ϕ]](T , i) by storing previous specification robustness values – if needed – and by only utilizing a bounded number of pairs
of the execution trace THst , . . . , THrz where Hst ∈ Ni and it will be formally defined in
Sec. 4. Our monitor uses bounded memory and, in the worst case, it has quadratic time
complexity that depends on the magnitude of Hrz − Hst. In principle, our solution for
robustness monitoring is inspired by the boolean temporal logic monitoring algorithm
in [2].

3

Robustness of Metric Temporal Logic Specifications

In digital control and monitoring of CPS, it is inevitable that physical quantities are
measured through a sampling process. As mentioned in the Problem Formulation section, when we mention time, we are actually referring to the corresponding sampling
index i. With a slight abuse of notation and under the assumption of constant sampling
rate, an execution trace T can also be represented by a function s : Ni+Hrz → S . The
view of the sequence s0 s1 . . . si+Hrz as a function s simplifies the presentation of the
robust semantics for MTL.
Using a metric d [23], we can define a distance function that captures how far away
a point x ∈ X is from a set S ⊆ X. Intuitively, the distance function assigns positive
values when x is in the set S and negative values when x is outside the set S . The metric
d must be at least a generalized quasi-metric as described in [21] which also includes
the case where d is a metric as it was introduced in [18].

5

Definition 1 (Signed Distance). Let x ∈ X be a point, S ⊆ X be a set and d be a metric.
Then, we define the Signed Distance from x to S to be
(
Distd (x, S ) :=

− inf{d(x, y) | y ∈ S } if x < S
inf{d(x, y) | y ∈ X\S } if x ∈ S

where inf is the infimum.

Metric Temporal Logic (MTL) was introduced by Koymans [16] to reason about
the quantitative timing properties of boolean signals. In this paper, we use the standard
fragment of MTL with bounded future, but also we allow the use of past time operators.

Definition 2 (MTL<+∞
+pt Syntax). Let AP be the set of atomic propositions and I be
any non-empty interval of N, and I be any non-empty interval of N ∪ {+∞}. The set
MTL<+∞
+pt formulas is inductively defined as ϕ ::= > | p | ¬ϕ | ψ ∨ ϕ | ψUI ϕ | ψSI ϕ
where p ∈ AP and > stands for true.

Note that we use the number of samples to represent the time interval constraints of
temporal operators. For example assume that ∆t = 0.1, then the MTL formula ^[0,0.5] a
where the timing constraints are over time is instead represented by ^[0,5] a in MTL<+∞
+pt .
The propositional operators conjunction (∧) and implication (→) are defined the
usual way. All other bounded future temporal operators can be syntactically defined
using Until (UI ), where  (Next), ^ (Eventually), and  (Always) are defined as ϕ ≡
>U[1,1] ϕ, ^I ϕ ≡ >UI ϕ, and I ϕ ≡ ¬^I ¬ϕ respectively. The intuitive meaning of
the ψU[a,b] ϕ operator at sampling time i is a follows: ψ has to hold at least until ϕ
becomes true within the time interval of [i + a, i + b] in the future. Similarly, all other
bounded/unbounded past temporal operators can be defined using Since (SI ), where
 (Previous),  (Eventually in the past), and  (Always in the past) are defined as
ϕ ≡ >S[1,1] ϕ, I ϕ ≡ >SI ϕ, and I ϕ ≡ ¬I ¬ϕ respectively. The intuitive meaning
of the ψS[a,b] ϕ operator at sampling time i is as follows: since ϕ becomes true within
the interval [i − b, i − a] in the past, ψ must hold till now (current time i).
MTL<+∞
+pt can state requirements over the observable trajectories of a CPS. In order
to capture these requirements, each predicate p ∈ AP is mapped to a subset of the
metric space X. We use an observation map O to interpret each predicate p ∈ AP. In
other words, the observation map is defined as O : AP → P(X) such that for each
p ∈ AP the corresponding set is O(p). Here, P(S ) denotes the powerset of a set S . We
define the robust valuation of an MTL<+∞
+pt formula ϕ over a trace s as follows [17].
Definition 3 (MTL<+∞
+pt Robustness Semantics). Let s be a trace s : N → X, and O
be an observation map O : AP → P(X), then the robust semantics of any formula ϕ ∈

6

MTL<+∞
+pt with respect to s is recursively defined as:
[[>]](s, i) := +∞
[[p]](s, i) := Distd (s(i), O(p))
J¬ϕK(s, i) := −JϕK(s, i)

Jψ ∨ ϕK(s, i) := JψK(s, i) t JϕK(s, i)

Gi+u 
l j−1
JψU[l,u] ϕK(s, i) :=
JϕK(s, j) u
JψK(s, k)
j=i+l
k=i


Gi−l0
li
JψS[l0 ,u0 i ϕK(s, i) :=
JϕK(s,
j)
u
JψK(s,
k)
0
j=max{0,i−u }

k= j+1

where t stands for max, u stands for min, p ∈ AP, l, u, l0 ∈ N and u0 ∈ N ∪ {∞}.
Furthermore, the symbol i in S[l0 ,u0 i will be ) when u0 = +∞ and ] when u0 , +∞.
We should point out that we use the extended definition of maximum (t) and minimum (u), with slight abuse of notation, we let max(∅) = −∞ and min(∅) = +∞. i.e.,
over empty sets we treat min and max as infimum and supremum, respectively. For
exact definition of infimum and supremum see [27].

4
4.1

Robustness Monitoring of MTL+<+∞
pt
Finite horizon and history of MTL<+∞
+ pt

For each MTL<+∞
+pt formula ψ we define the finite horizon hrz(ψ) as the number of
samples we need to consider in the future. In MTL, the satisfaction of the formula
depends on what will happen in the future. In bounded MTL, the finite horizon hrz(ψ)
is the number of steps (samples) which we need to consider in the future in order to
evaluate the formula ψ at the current time i. In other words, hrz(ψ) is the number of
steps into the future for which the truth value of the sub-formula ψ depends on [2].
Similarly, we define the finite history hst(ψ) of ψ as the number of samples we need
to look into the past. That is, the number of steps in the past for which the truth value
of the sub-formula ψ depends on. Intuitively, the hst(ψ) is the size of the history we
need to consider in order to keep track of what happened in the past to evaluate the
formula ψ at present time. The finite horizon and the history can be defined recursively.
We define hrz(ψ) (similar to h(ψ) in [2]) and we add the recursive definition of hst(ψ)
in the following:
hrz(p) = 0
hrz(¬ψ) = hrz(ψ)
hrz(ψ OP ϕ) = max{hrz(ψ), hrz(ϕ)}
hrz(ψU[l,u] ϕ) = max{hrz(ψ) + u − 1, hrz(ϕ) + u}
hrz(ψS[l0 ,u0 i ϕ) = max{hrz(ψ), hrz(ϕ)}
(
max{hst(ψ) + u0 − 1, hst(ϕ) + u0 }
hst(ψS[l0 ,u0 i ϕ) =
max{hst(ψ) + l0 − 1, hst(ϕ) + l0 }

hst(p) = 0
hst(¬ψ) = hst(ψ)
hst(ψ OP ϕ) = max{hst(ψ), hst(ϕ)}
hst(ψU[l,u] ϕ) = max{hst(ψ), hst(ϕ)}
if u0 , +∞
if u0 = +∞

7
Table 1. Pre Vector and Robustness Table
Pre[k]

T k, j

row k ⇓
ψ1 = ϕ
ψ2
Jψ3 K(s, i − 3)
ψ3
ψ4
ψ5

column j ⇒
Time(i)
ψ2 ∧ ψ3
[1,2] q
[0,+∞) p
p
q

-2

-1

0

1

2

i−2

i−1

i

i+1

i+2

JϕK(s, i − 2)
Jψ2 K(s, i − 2)
Jψ3 K(s, i − 2)
Jψ4 K(s, i − 2)
Jψ5 K(s, i − 2)

JϕK(s, i − 1)
Jψ2 K(s, i − 1)
Jψ3 K(s, i − 1)
Jψ4 K(s, i − 1)
Jψ5 K(s, i − 1)

JϕK(s, i)
Jψ2 K(s, i)
Jψ3 K(s, i)
Jψ4 K(s, i)
Jψ5 K(s, i)

JϕK(s, i + 1)
Jψ2 K(s, i + 1)
Jψ3 K(s, i + 1)
Jψ4 K(s, i + 1)
Jψ5 K(s, i + 1)

JϕK(s, i + 2)
Jψ2 K(s, i + 2)
Jψ3 K(s, i + 2)
Jψ4 K(s, i + 2)
Jψ5 K(s, i + 2)

where p ∈ AP. Here, OP is any binary operator in propositional logic, and ψ, ϕ are
MTL<+∞
+pt formulas. For the unbounded S[0,+∞) operator, the computation of finite history is more involved and needs more explanation. Namely, we need to restate the dynamic programming algorithm for monitoring a sub-formula ψS[0,+∞) ϕ based on the following works [9, 5]. According to the robustness semantics, the robustness of ψS[0,+∞) ϕ
at time i is as follows:

Gi 
li
JψS[0,+∞) ϕK(s, i) =
JϕK(s, j) u
JψK(s, k)
j=0

k= j+1

also robustness of ψS[0,+∞) ϕ at time i − 1 is
JψS[0,+∞) ϕK(s, i − 1) =


Gi−1 
li−1
JϕK(s, j) u
JψK(s, k)
j=0

k= j+1

Thus, we can rewrite JψS[0,+∞) ϕK(s, i) as
JψS[0,+∞) ϕK(s, i) = JϕK(s, i) t JψK(s, i) u

 Gi−1 
li−1
!
JϕK(s, j) u
JψK(s, k) =
j=0

k= j+1


!
= JϕK(s, i) t JψK(s, i) u JψS[0,+∞) ϕK(s, i − 1)
Therefore, similar to [5] we recursively update the robustness of ψS[0,+∞) ϕ at the
current time i and save it in a variable called “Pre” to reuse it for the computation of the
next time step (see [5] for more details). As a result, when we have an unbounded past
time operator, we do not need the full history table. However, if the formula contains a
nested future time operator, we need to extend the history to be long enough to contain
the actual values. In other words, although for unbounded past time operators we do not
need the whole history table, we should still extend the history to be able to store the
actual simulation values (not the predicted values) in “Pre”.
4.2

Robustness Computation Algorithm

For each MTL<+∞
+pt formula ϕ we construct a table called Robustness Table with width
of Hst + 1 + Hrz, where Hrz = hrz(ϕ) is the finite horizon of the specification formula
ϕ, and, Hst = Hrz + hst(ϕ), where hst(ϕ) is the finite history of the specification ϕ. Hst
is extended conservatively due to the fact that “Pre” value can only store the robustness

8

Algorithm 1 On-Line Monitor
Input: ϕ, s0i = si si+1 . . . si+Hrz , d, O; Global variables: T , Pre; Output: T 1,0 (robustness value).

procedure Monitor(ϕ, s0i , d, O)
for k ← 1 to |ϕ| do
Pre(k) ← T k,(−Hst+hst(ϕk ))
end for
for j ← 1 − Hst to Hrz do
for k ← 1 to |ϕ| do
if ϕk = p ∈ AP then
T k, j−1 ← T k, j
end if
end for
end for
for k ← |ϕ| down to 1 do
if ϕk = ϕm S[l0 ,u0 i ϕn then

13:
14:
15:
16:
17:

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:

for j ← −Hst + hst(ϕk ) to Hrz do
T k, j ← CR(ϕk , j, s0i , d, O)
end for
else

for j ← Hrz down to − Hst +
hst(ϕk ) do
18:
T k, j ← CR(ϕk , j, s0i , d, O)
19:
end for
20:
end if
21: end for
22: return T 1,0
end procedure

values corresponding to the actual simulation. The height of the robustness table is the
size of the formula ϕ (|ϕ|), where |ϕ| is the number of sub-formulas of ϕ including itself.
For example, assume we have a formula ϕ = [0,+∞) p∧[1,2] q and we intend to compute
[[ϕ]](T , i) at each time i. In formula ϕ, Hst = 2 and Hrz = 2. Since ϕ has unbounded
past-time operators, it needs the Pre vector as well as the Robustness Table. The Pre
vector appended to the Robustness Table is presented in Table 1. In particular, the Pre
vector contains the value of past sub-formulas from the beginning of the time up to the
current time.
In the following, we explain how the values of Table 2, the robustness table, are
computed using Algorithms 1 and 2. In order to make our algorithms more readable,
we used a vector to show the CPS output si , si+1 , . . ., si+Hrz to the monitoring (see Fig.
1). We define a vector s0i = si si+1 . . . si+Hrz which appends current state si with predictions si+1 , si+2 , . . ., si+Hrz . In Table 1, i is the current simulation step which corresponds
to column 0. At each simulation step i, for each unbounded past time sub-formula φ, we
first save the values of the column −Hst + hst(φ) in the Pre vector (Algorithm 1 lines
1-3) since the column −Hst + hst(φ) contains the robustness value of φ from the beginning of the simulation. We need the Pre vector to compute the robustness of φ at the
next sampling time using the dynamic programming method. In the above example, for
Table 2. Robustness Computation of each table entries (Gray cells are unused)
T k, j
k ⇓, j ⇒

i−2
j = −2

i−1
j = −1

i
j=0

i+1
j=1

i+2
j=2

Pre[1]
T 2,−2 u T 3,−2
T 2,−1 u T 3,−1
T 2,0 u T 3,0
T 2,1 u T 3,1
T 2,2 u T 3,2
Pre[2]
T 5,−1 u T 5,0
T 5,0 u T 5,1
T 5,1 u T 5,2
T 5,2
+∞
Pre[3]
Pre[3]uT 4,−2
T 3,−2 u T 4,−1
T 3,−1 u T 4,0
T 3,0 u T 4,1
T 3,1 u T 4,2
Pre[4] Distd (si−2 , O(p)) Distd (si−1 , O(p)) Distd (si , O(p)) Distd (si+1 , O(p)) Distd (si+2 , O(p))
Pre[5] Distd (si−2 , O(q)) Distd (si−1 , O(q)) Distd (si , O(q)) Distd (si+1 , O(q)) Distd (si+2 , O(q))

9

Algorithm 2 Robustness Computation (CR)
Input: ϕk , j, s0i = si si+1 . . . si+Hrz , d, O; Global variables: T , Pre; Output: T k, j .
procedure CR(ϕk , j, s0i , d, O)
if ϕk = > then T k, j ← +∞
else if ϕk = p ∈ AP then
if j >= 0 then
T k, j ← Distd (si+ j , O(p))
end if
else if ϕk = ¬ϕm then
T k, j ← −T m, j
else if ϕk = ϕm ∨ ϕn then
T k, j ← T m, j t T n, j
else if ϕm U[l,u] ϕn then
if j + l ≤ Hrz then
d
tmpmin ← j≤ j0 < j+l T m, j0
T k, j = −∞
for j0 ← j + l to min{Hrz, j + u} do
T k, j ← T k, j t (tmpmin u T n, j0 )
tmpmin = tmpmin u T m, j0
end for
else
T k, j = −∞

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:

20:
end if
21: else if ϕm S[l0 ,u0 i ϕn then
d
22:
tmpmin ← j−l0 < j0 ≤ j T m, j0
0
23:
if u , +∞ then
24:
T k, j = −∞
25:
for j0 ← j − l0 down to j − u0 do
26:
T k, j ← T k, j t (tmpmin u T n, j0 )
27:
tmpmin = tmpmin u T m, j0
28:
end for
29:
else
30:
if j = −Hst + hst(ϕk ) then
31:
tmpS ← Pre[k] u T m, j
32:
else
33:
tmpS ← T k, j−1 u T m, j
34:
end if
35:
T k, j ← (T n, j−l0 u tmpmin ) t tmpS
36:
end if
37: end if
38: return T k, j
end procedure

[0,+∞) p the value at column −2 is saved in Pre to be used during robustness computation. Then, we shift all the robustness table entries of the predicates by one position to
the left (Algorithm 1, lines 4-10). Then the loop (Algorithm 1, lines 11-21) recursively
calls Algorithm 2 to fill the robustness table for each sub-formula from bottom to top.
Each call of Algorithm 2 (CR) computes each table entry T k, j (see tables 1,2) where
column j is the horizon/history index and row k is the sub-formula index. For past subformulas the table entries are computed from left to right (Algorithm 1, lines 13-15),
and for future sub-formulas the table entries are computed from right to left (Algorithm
1, lines 17-19). New values for predicates (according to execution traces) will be placed
in column 0 and the predicted values of the predicates will be saved in columns 1 to Hrz
(Algorithm 2, lines 2-5). Table 2 shows the updates of predicate values in rows 4, and 5
which correspond to Algorithm 2, line 4.
In the following, we explain how the CR Algorithm 2 computes the MTL robustness values for three different cases of MTL:
Case 1 (Lines 10-20): The robustness of bounded future temporal sub-formulas with
interval [l, u] at each column j is computed given the values of its operands for columns
j up-to min{ j + u, Hrz} (Line 14). For example, this case is used in Table 2 to compute
the robustness of sub-formula ψ2 = [1,2] q from right to left. Case 1 in CR Algorithm
is similar to the DP-TALIRO algorithm [28].
Case 2 (Lines 23-28): The robustness of bounded past temporal sub-formulas with interval [l0 , u0 ] at each column j is computed given the values of its operands for columns
j down-to j − u0 (Line 25).

10

Case 3 (Lines 30-36): The robustness of unbounded past temporal sub-formulas with
interval [l0 , +∞) for column j is computed using the stored value in column j − 1 in
dynamic programming fashion (Line 33) and using the Pre vector (Line 31). For example, Case 3 is used to compute the robustness of ψ3 = [0,+∞] p using Pre[3] from left
to right in Table 2.
Finally, we update table entries for the top row which corresponds to ψ1 = ϕ. Since
its corresponding operator ∧ is propositional (Algorithm 2 Lines 6-9), we can update
its value from any direction. The high level explanation of Algorithm 1 is described as
follows:
1. Store values of column −Hst + hst(φk ) for each unbounded past sub-formula φk in
Pre[k] and shift the table entries of predicates one to the left (Lines 1-10).
2. For each row i from |ϕ| to 1 compute the robustness values according to:
(a) If ϕi is a future temporal operator, for each column j from Hrz down to −Hst +
hst(ϕi ), update table entry T i, j using Algorithm 2.
(b) If ϕi is a past temporal operator, for each column j from −Hst + hst(ϕi ) up to
Hrz update table entry T i, j using Algorithm 2.
3. Return the robustness (T 1,0 ).
We provided the proof of this section in Appendix.

5

Experimental Analysis and Case Studies

5.1

Runtime Overhead

First, we measure the overhead of the proposed monitoring framework on a slightly
modified version of the Automatic Transmission (AT) model provided by Mathworks
as a Simulink demo1 . The experiments were conducted on a Windows 7, Intel Core2
Quad (2.99 GHz) with 8 GB RAM.
The physical model of the AT system has two continuous (real-valued) state variables which are also its monitored outputs: the speed of the engine ω and the speed
of the vehicle v. The model includes an automatic transmission controller that exhibits
both continuous and discrete behavior. It is a typical CPS model and specifications over
both boolean and continuous variables can be formalized. However, since the valuation
of the robustness of predicates over continuous state variables is computationally more
expensive than a boolean valuation, we consider only specifications over continuous
state variables for the impact analysis.
We introduce our MTL<+∞
+pt monitoring block in the AT model and test the performance over a set of specifications. In order to test the runtime overhead of our work,
we artificially generate 30 different MTL<+∞
+pt formulas based on typical critical safety
formulas to show that the runtime overhead depends on both of the size of the formula
and the horizon/history. We test our method for 100 runs of monitoring algorithm for
each specification (formula), and for each run we use 100 simulation steps. Then, we
compute the mean and variance of the overhead for each simulation step which is the
1

Available
at:
http://www.mathworks.com/help/simulink/examples/
modeling-an-automatic-transmission-controller.html

11
Table 3. The overhead on each simulation step on the Automatic Transmission model with specifications of increasing length. Table entries are in milliseconds.
#

H=1,000

φ1 (H)
φ3 (H)
φ5 (H)
φ7 (H)
φ9 (H)

E
Mean Var.
2.39 0.00
4.24 0.00
4.66 0.00
4.95 0.00
5.23 0.00

U
Mean Var.
4.83 0.00
7.5 0.001
8.36 0.001
8.94 0.00
9.46 0.001

H=2,000
E
Mean Var.
8.03 0.00
12.7 0.00
14.01 0.00
14.83 0.00
15.4 0.001

U
Mean Var.
15.8 0.001
25.09 0.005
27.8 0.005
29.33 0.006
30.56 0.007

H=10,000
E
Mean Var.
188.8 0.001
314.4 0.01
309.2 0.077
311 0.013
317.5 0.011

U
Mean Var.
358.5 0.036
599 0.665
650 0.014
674.2 0.033
683.5 0.698

execution time of Algorithm 1 in Table 3. In this table, the overhead is measured on
specifications that contain either nested Until operators (U columns) or nested Eventually operators (E columns).
We generate 30 formulas according to the following templates:
– E formulas: φn (H) = p j −→ ψn (H/n)
where H ∈ N is the finite horizon of the formula. In Table 3, we used 1,000, 2,000
and 10,000 for the size of the horizon. Here, p j is an arbitrary predicate and ψn (H/n)
is defined recursively as follows:
ψ1 (h) = ^[0,h] pk and ψn (h) = ^[0,h] (pl ∧ ψn−1 (h)), for 1 < n ≤ 9
where h = H/n, i.e., the finite horizon H divided by the number of nested subformulas n and pk , pl are arbitrary predicates.
– U formulas: φn (H) = p j −→ ψn (H/n)
where H ∈ N is the finite horizon of the formula. In Table 3, we used 1,000, 2,000
and 10,000 for the size of the horizon of H. Here, p j is an arbitrary predicate and
ψn (H/n) is defined recursively as follows:
ψ1 (h) = pk U[0,h] pl and ψn (h) = pm U[0,h] (pn ∧ ψn−1 (Y)), for 1 < n ≤ 9
where h = H/n and pk , pl , pm , pm are arbitrary predicates.
As illustrated in Table 3, the computational complexity of the monitoring algorithm
is closely related to the horizon and history size. Since the algorithm’s complexity is of
order O(n2 ) where n is the horizon/history, the added overhead (in worst case execution)
is quadratic in terms of the size of the horizon for some formulas in Table 3 (like φ1 (H)).
Moreover, in most cases, the impact of the number of nested temporal operators is
not significant compared to the size of horizon/history windows. From Table 3, we
notice that when the horizon and history size is less than 2,000, the overhead for each
simulation step is negligible with our prototype implementation. Furthermore, for most
practical reactivity requirements, it is quite unlikely that even a window size of 2,000
sampling points is necessary. Therefore, the method could be utilized in real world
monitoring applications.
5.2

Case Study

In the following, we utilize the monitoring method on an industrial size high-fidelity engine model. The model is part of the SimuQuest Enginuity [29] Matlab/Simulink tool

12

package. The Enginuity tool package includes a library of modules for engine component blocks. It also includes pre-assembled models for standard engine configurations.
In this work, we use the Port Fuel Injected (PFI) spark ignition, 4 cylinder inline engine configuration. It models the effects of combustion from first physics principles on a
cylinder-by-cylinder basis, while also including regression models for particularly complex physical phenomena. The model includes a tire-model, brake system model, and a
drive train model (including final drive, torque converter and transmission). The input
to the system is the throttle schedule. The output is the normalized air-to-fuel(A/F) ratio. Simulink reports that this is a 56 state model. Note that this number represents only
the visible states. It is possible that more states are present in the blackbox s-functions
which are not accessible. This is a high dimensional non-linear system for which reachability analysis is very difficult. It also includes lookup tables, non-linear components,
and inputs that affect the switching guards.
Enginuity High-Fidelity Engine Model with On-Line Monitoring
engine_torque

[torque]

[torque]

engine_speed

[engine_speed]

[engine_speed]

manifold_pressure

[manifold_press]

[manifold_press]

mass_air_flow

[mass_air_flow]

[mass_air_flow]

[lambda_exhaust]

[lambda_exhaust]

[o2_sensor_voltage]

[vehicle_speed]

lambda
o2_sensor_voltage
gear
vehicle_speed

[gear_active]

[gear_active]

[vehicle_speed]

[o2_sensor_voltage]

torque [Nm]
engine speed [rpm]
manifold pressure [Pa]
mass air flow [kg/s]
lambda exhaust [-]
vehicle speed [mph]
active gear [-]
O2 sensor voltage [V]

input throttle

input throttle
lambda

robustness

robustness

on_line monitoring

Fig. 2. SimuQuest [29] Enginuity Matlab Simulink engine model with the on-line monitoring
block.

A specification of practical interest for an engine is the settling time for the A/F
ratio, which is the quotient between the air mass and fuel mass flow. Ideally, the normalized A/F ratio λ should always be 1, indicating that the ratio of the air and fuel
flow is the same as the stoichiometric ratio. Under engine operating conditions, this
output fluctuates ±%10. We add the on-line monitoring block to the Simulink model as
presented in Fig. 2.
Our goal is to monitor the engine while allowing temporary fluctuations to λ. We
formally define the specification as follows:
φ pt = (λ out of bounds) → [0,1] [0,1] ¬(λ out of bounds)
Here, the formal specification states that if the A/F ratio exceeds the allowed bounds,
then the ratio should have been settled for at least one second within the last two seconds.
Notice that an alternative presentation of the formula would be to use the future
eventually and always operators, i.e. the formula would be defined as follows:

13
Normalized stoichiometric ratio

1.1

0.1

1

0

0.9

−0.1

0.8

0

5

10

15

20

25

30

35

Robustness with the specification φft

0.2

−0.2

0.1

0

0

−0.1

−0.1

0

5

10

15

20

25

0

30

35

−0.2

5

10

15

20

25

30

35

Robustness with the specification φptft

0.2

0.1

−0.2

Robustness with the specification φpt

0.2

0

5

10

15

20

25

30

35

Fig. 3. Runtime monitoring of specifications φ pt , φ f t and φ pt f t on the high-fidelity engine model.
The figure presents a normalized stoichiometric ratio, and the corresponding robustness values for
specifications φ pt , φ f t and φ pt f t . Note that no predictor is utilized when computing the robustness
values.

φ f t = (λ out of bounds) → ^[0,1] [0,1] ¬(λ out of bounds)
In this case, the specification states that always, if the A/F ratio output exceeds the
allowed bounds, then within one second it should settle inside the bounds and stay there
for a second.
Clearly, both φ pt and φ f t are equivalent in terms of the set of traces that satisfy/falsify
each specification2 . However, in real-time robustness monitoring, there is an important
distinction between the two. When the specification requires future information, either
a predictor is put in place or the semantics will handle only the current information.
In this case, without a predictor, the future time formula reduces to the propositional
formula φ f t = (λ out of bounds) → ¬(λ out of bounds) ≡ (λ out of bounds). Therefore,
past time operators should be used. Recall that when monitoring robustness, our goal
is to provide early warning on when the specification may fail by approaching dangerously an undesired threshold. In other words, the past formula allows us to reason
about the robustness of the actual system observations, while the future formula in collaboration with a forecast model would allow us to estimate the likely robustness. This
is in contrast to many boolean monitoring algorithms which issue an “undecided until
further notice” verdict that does not provide any actionable information.
A third alternative monitoring specification is the following formula:
2

Formally, this is the case if we ignore the first 2 seconds of the execution trace as well as the
last 2 seconds – if the execution trace is finite.

14

φ pt f t = [0,2] ((λ out of bounds) → ^[0,1] [0,1] ¬(λ out of bounds))
This specification states that at some point in the last two seconds, when λ is out
of bounds then within the next second, λ will not be out of bounds and stay there for
one second. This alternative seems to be the balance between the φ pt and φ f t formulas.
Where φ pt purely relies on past information, and φ f t relies on information from a predictor, φ pt f t has the advantage that it utilizes both the information from the past but also
it could include information from the predictor.
An example of real-time monitoring on the high-fidelity engine model is presented
in Fig. 3. The figure illustrates the significance of using past time operators when defining specifications. Due to the lack of predictor information, the φ f t monitor falsely
returns falsification at about 4 seconds whereas the φ pt monitor does not.
In the following, we analyze the overhead of the monitoring algorithm for this case
study. Since the runtime is influenced by numerous sources of nondeterminism, we apply the central limit theorem to form confidence intervals for the mean simulation runtime when running the simulations with and without the monitor. To generate the results
in Table 4, we collected 30 samples with 100 simulation runtimes in each sample. We
note that the difference between the estimated mean simulation runtime when adding
the monitor is 0.97%. The experimental results were generated on an Intel Xeon X5647
(2.993GHz, 8 CPUs) machine with 12 GB RAM, Windows 7, and Matlab 2012a.
Table 4. Simulation runtime statistics for the high-fidelity engine model running for 35 seconds
with simulation stepsize of 0.01s. The results include the confidence intervals for the mean simulation runtime.
Simulation runtime(sec.)

6

Est. Mean

95%

Est. Std. Dev

99%

LB

UB

LB

UB

Without monitor

10.811

0.090

10.778

10.844

10.766

10.857

With monitor

10.987

0.086

10.955

11.019

10.944

11.030

Conclusions and Future Work

We have presented an algorithm for monitoring the robustness of combined past and
future MTL specifications. Our framework can incorporate predicted or estimated data
as provided by a model predictive component. We have created a Simulink toolbox
for MTL robustness monitoring which is distributed with the S-Taliro tools [30]. Our
experiments indicate that the toolbox adds minimal overhead to the simulation time of
Simulink models and it can be used for both runtime analysis of the models and for
off-line testing. Our future work will concentrate on several aspects. First, the current
version of the tool allows reasoning over timed state sequences generated under a constant sampling rate. We would like to relax this constraint so that we allow arbitrary
sampling functions. Second, we would like to investigate the possibility of porting our
monitor on FPGA platforms similar to [2, 8]. Finally, we envision that utilizing information about the system through the form of a model will permit us to move to an
event based monitoring framework while still sufficiently approximating the robustness
estimate.

15

Acknowledgments This work was partially supported by NSF awards CNS 1116136
and CNS 1319560. The authors would also like to thank the anonymous reviewers for
the very detailed comments.

References
1. Alur, R., Courcoubetis, C., Halbwachs, N., Henzinger, T.A., Ho, P.H., Nicollin, X., Olivero,
A., Sifakis, J., Yovine, S.: The algorithmic analysis of hybrid systems. Theoretical Computer
Science 138 (1995) 3–34
2. Finkbeiner, B., Kuhtz, L.: Monitor circuits for ltl with bounded and unbounded future. In:
Runtime Verification. Volume 5779 of LNCS., Springer (2009) 60–75
3. Havelund, K., Rosu, G.: Monitoring programs using rewriting. In: Proceedings of the 16th
IEEE international conference on Automated software engineering. (2001)
4. Havelund, K., Rosu, G.: Synthesizing monitors for safety properties. In: Tools and Algorithms for the Construction and Analysis of Systems. Number 2280 in LNCS, Springer
(2002) 342–356
5. Havelund, K., Rosu, G.: Efficient monitoring of safety properties. STTT 6 (2004) 158–173
6. Kristoffersen, K.J., Pedersen, C., Andersen, H.R.: Runtime verification of timed LTL using
disjunctive normalized equation systems. In: Proceedings of the 3rd Workshop on Run-time
Verification. Volume 89 of ENTCS. (2003) 1–16
7. Maler, O., Nickovic, D.: Monitoring temporal properties of continuous signals. In: Proceedings of FORMATS-FTRTFT. Volume 3253 of LNCS. (2004) 152–166
8. Reinbacher, T., Rozier, K.Y., Schumann, J.: Temporal-logic based runtime observer pairs for
system health management of real-time systems. In: Proceedings of the 20th International
Conference on Tools and Algorithms for the Construction and Analysis of Systems. Volume
8413 of LNCS., Springer (2014) 357–372
9. Rosu, G., Havelund, K.: Synthesizing dynamic programming algorithms from linear temporal logic formulae. Technical report, Research Institute for Advanced Computer Science
(RIACS) (2001)
10. Tan, L., Kim, J., Sokolsky, O., Lee, I.: Model-based testing and monitoring for hybrid embedded systems. In: Proceedings of the 2004 IEEE International Conference on Information
Reuse and Integration. (2004) 487–492
11. Thati, P., Rosu, G.: Monitoring algorithms for metric temporal logic specifications. In:
Runtime Verification. Volume 113 of ENTCS., Elsevier (2005) 145–162
12. Basin, D.A., Klaedtke, F., Zalinescu, E.: Algorithms for monitoring real-time properties. In:
Runtime Verification. Volume 7186 of LNCS., Springer (2011) 260–275
13. Geilen, M.: On the construction of monitors for temporal logic properties. In: Proceedings
of the 1st Workshop on Runtime Verification. Volume 55 of ENTCS. (2001) 181–199
14. Maler, O., Nickovic, D., Pnueli, A.: From MITL to Timed Automata. In: Proceedings of
FORMATS. Volume 4202 of LNCS., Springer (2006) 274–289
15. Pnueli, A.: The temporal logic of programs. In: Proceedings of the 18th IEEE Symposium
Foundations of Computer Science. (1977) 46–57
16. Koymans, R.: Specifying real-time properties with metric temporal logic. Real-Time Systems 2 (1990) 255–299
17. Fainekos, G., Pappas, G.J.: Robustness of temporal logic specifications. In: Formal Approaches to Testing and Runtime Verification. Volume 4262 of LNCS., Springer (2006) 178–
192
18. Fainekos, G., Pappas, G.J.: Robustness of temporal logic specifications for continuous-time
signals. Theor. Comput. Sci. 410 (2009) 4262–4291

16
19. Donze, A., Ferrre, T., Maler, O.: Efficient robust monitoring for stl. In: Proceedings of the
25th International Conference on Computer Aided Verification. CAV, Berlin, Heidelberg,
Springer-Verlag (2013) 264–279
20. Garcia, C.E., Prett, D.M., Morari, M.: Model predictive control: Theory and practice - a
survey. Automatica 25 (1989) 335348
21. Abbas, H., Fainekos, G.E., Sankaranarayanan, S., Ivancic, F., Gupta, A.: Probabilistic temporal logic falsification of cyber-physical systems. ACM Trans. Embedded Comput. Syst.
12 (2013) 95
22. Jin, X., Donze, A., Deshmukh, J., Seshia, S.: Mining requirements from closed-loop control
models. In: Hybrid Systems: Computation and Control, ACM Press (2013)
23. Seda, A.K., Hitzler, P.: Generalized distance functions in the theory of computation. The
Computer Journal 53 (2008) bxm108443–464
24. Eklund, J.M., Sprinkle, J., Sastry, S.: Implementing and testing a nonlinear model predictive
tracking controller for aerial pursuit/evasion games on a fixed wing aircraft. In: American
Control Conference. (2005)
25. Bakirtzis, A., Petridis, V., Kiartzis, S., Alexiadis, M., Maissis, A.: A neural network short
term load forecasting model for the greek power system. IEEE Transactions on Power Systems 11 (1996) 858–863
26. Monteiro, C., Bessa, R., Miranda, V., Botterud, A., Wang, J., Conzelmann, G.: Wind power
forecasting: State-of-the-art 2009. Technical Report ANL/DIS-10-1, Argonne National Laboratory (2009)
27. Davey, B.A., Priestley, H.A.: Introduction to Lattices and Order (2. ed.). Cambridge University Press (2002)
28. Fainekos, G., Sankaranarayanan, S., Ueda, K., Yazarel, H.: Verification of automotive control
applications using s-taliro. In: Proceedings of the American Control Conference. (2012)
29. Simuquest: Enginuity. http://www.simuquest.com/products/enginuity (2013) Accessed: 2013-10-14.
30. Annapureddy, Y.S.R., Liu, C., Fainekos, G.E., Sankaranarayanan, S.: S-taliro: A tool for
temporal logic falsification for hybrid systems. In: Tools and algorithms for the construction
and analysis of systems. Volume 6605 of LNCS., Springer (2011) 254–257

17

Appendix: Proof of Section 4.2
We prove by induction the correctness of Algorithms 1 and 2. We need to prove that
at each simulation step i, the returning value of the CR algorithm is the same as the
robustness value. Without loss of generality, assume i ≥ Hst; therefore, the values in the
table columns −Hst to 0 contain the robustness values based on the actual simulation.
When i < Hst then the proof is immediate by the semantics of temporal logic. We must
show that, for each sub-formula ϕk the value stored in column j of robustness table T k, j
should be correctly computed according to the semantics
Jϕk K(s, i + j) = T k, j = CR(ϕk , j, s0i , d, O)
given matrix T and vector Pre
Base case:
We will show that for each MTL<+∞
+pt sub-formula in the form of a predicate, the value
which is returned by the CR algorithm (Algorithm 2) is equal to the semantics of the
sub-formula. Assume the sub-formula is a predicate p = ϕk , for each simulation time
i + j, the corresponding robustness value is stored in the column j of robustness table
as follows:
∀ j, −Hst ≤ j ≤ Hrz, JpK(s, i + j) = Distd (s(i + j), O(p)) = Distd (si+ j , O(p)) =
T k, j = CR(p, j, s0i , d, O)

Therefore, for each predicate the algorithm “CR” computes the correct robustness value.
Induction Hypothesis:
For each temporal sub-formulas ϕk , Hst − hst(ϕk ) ≥ Hrz because of the fact that
Hst = Hrz + hst(ϕ) ≥ Hrz + hst(ϕk ); therefore −Hst + hst(ϕk ) ≤ −Hrz.
As a result, the values at the columns from −Hst up to −Hst + hst(ϕk ) will only depend
on the actual simulation values, i.e., the predicates from column −Hst up to column 0
which will not change in next simulation steps. These values are shown in gray color
cells of Table 5. As a result, all the table entries from −Hst up to −Hst + hst(ϕk ) will
not change (in next run) and the re-computation is not needed. Therefore, we shift
all the values of predicates one column to the left and we ignore columns −Hst to
−Hst + hst(ϕk ) − 1 in our current run of Algorithm1 (Lines 13 and 17). Therefore, it is
not necessary to include the columns −Hst to −Hst + hst(ϕk ) − 1 in proof and Induction
Hypothesis.
For Induction Hypothesis, we assume that the value stored in the robustness table is the
semantically correct robustness value for each sub-formula ϕk :
∀ j, −Hst + hst(ϕk ) ≤ j ≤ Hrz, Jϕk K(s, i + j) = T k, j = CR(ϕk , j, s0i , d, O)

And if there exists unbounded past operator sub-formula like ϕk = ψS[l0 ,+∞) ϕ, we assume the Pre(k) = JψS[l0 ,+∞) ϕK(s, i − 1 − Hst + hst(ϕk ))) because it belongs to the
previous run of i − 1, i.e we store the value T k,(−Hst+hst(ϕk )) in Pre(k) before processing
the current run (i) (see Algorithm 1 line 2).
Induction Step:

18

• Negation:
∀ j, −Hst + hst(ϕk ) ≤ j ≤ Hrz : Jϕk K(s, i + j) = J¬ϕm K(s, i + j) =
−Jϕm K(s, i + j) = −T m, j = CR(¬ϕm , j, s0i , d, O)
• Disjunction:
∀ j, −Hst + hst(ϕk ) ≤ j ≤ Hrz : Jϕk K(s, i + j) = Jϕm ∨ ϕn K(s, i + j) =
Jϕm K(s, i + j) t Jϕn K(s, i + j) = T m, j t T n, j = CR(ϕm ∨ ϕn , j, s0i , d, O)
• Until:
For sub-formulas of the form ϕk = ϕm U[l,u] ϕn , either the corresponding robustness
values are correctly saved in robustness matrix for ϕm , ϕn or the semantics will
satisfy the correctness if the corresponding values belong to columns beyond the
Hrz:
∀ j, −Hst + hst(ϕk ) ≤ j ≤ Hrz : Jϕk K = Jϕm U[l,u] ϕn K(s, i + j) =
Gi+ j+u
lh−1
(Jϕn K(s, h) u
Jϕm K(s, r)) =
h=i+ j+l
r=i+ j
G
lh−1
(T n,h u
T m,r ) = CR(ϕm U[l,u] ϕn , j, s0i , d, O)
h∈[ j+l, j+u]∩[−Hst,Hrz]

r= j

• Bounded Since:
For bounded sub-formula ϕk = ϕm S[l,u] ϕn , the robustness is defined as follows:
Gi+ j−l
li+ j
Jϕk K(s, i + j) = Jϕm S[l,u] ϕn K(s, i + j) =
(Jϕn K(s, h) u
Jϕm K(s, r))
h=i+ j−u
r=h+1
Based on IH we know that j ≥ −Hst + hst(ϕk ). We must show that the values of
T n,p for j − u ≤ p ≤ j − l satisfy T n,p = Jϕn K(s, i + p) i.e. −Hst + hst(ϕn ) ≤ j − u
and also we need to show that the values of T m,q for j − u + 1 ≤ q ≤ j satisfy
T m,q = Jϕm K(s, i + q) i.e. −Hst + hst(ϕm ) ≤ j − u + 1.
We have two cases for hst(ϕk ):
Case 1: hst(ϕk ) = hst(ϕn ) + u = max{hst(ϕn ) + u, hst(ϕm ) + u − 1}
According to IH, j ≥ −Hst + hst(ϕk ), then j ≥ −Hst + hst(ϕn ) + u. Thus j − u ≥
−Hst + hst(ϕn ) which satisfies the fact that T n,p = Jϕn K(s, i + p) for j − u ≤ p ≤ j − l.
On the other hand, in this case: hst(ϕn ) + u ≥ hst(ϕm ) + u − 1
According to IH, j + Hst ≥ hst(ϕk ) ≥ hst(ϕm ) + u − 1, i.e., j + Hst ≥ hst(ϕm ) + u − 1.
Thus j − u + 1 ≥ −Hst + hst(ϕm ), which satisfies the fact that T m,q = Jϕm K(s, i + q)
for j − u + 1 ≤ q ≤ j.
Table 5. Robustness Table (Unchangeable values in next runs are in gray color)
column( j) ⇒
index(time) ⇒

Pre[1]
Pre[...]
Pre[k]
Pre[...]
Pre[|ϕ|](predicate)

−Hst ... −Hst + hst(ϕk ) ... −Hrz = −Hst + hst(ϕ) ... −1 0 1 ... Hrz
i − Hst ... i − Hst + hst(ϕk ) ...
i − Hrz
... i − 1 i i + 1 ... i + Hrz

19

Case 2: hst(ϕk ) = hst(ϕm ) + u − 1 = max{hst(ϕn ) + u, hst(ϕm ) + u − 1}
According to IH, j ≥ −Hst + hst(ϕk ) then j ≥ −Hst + hst(ϕm ) + u − 1. Thus
j − u + 1 ≥ −Hst + hst(ϕm ) which satisfies the fact that T m,q = Jϕm K(s, i + q) for
j − u + 1 ≤ q ≤ j. On the other hand, in this case: hst(ϕm ) + u − 1 ≥ hst(ϕn ) + u.
According to IH, j + Hst ≥ hst(ϕk ) ≥ hst(ϕn ) + u i.e j + Hst ≥ hst(ϕn ) + u.
Thus j − u ≥ −Hst + hst(ϕn ) which satisfies the fact that T n,p = Jϕn K(s, i + p) for
j − u ≤ p ≤ j − l.
As a result:
∀ j, −Hst + hst(ϕk ) ≤ j ≤ Hrz : Jϕk K(s, i + j) = Jϕm S[l,u] ϕn K(s, i + j) =
Gi+ j−l
li+ j
(Jϕn K(s, h) u
Jϕm K(s, r)) =
j−u
r=h+1
Gh=i+
lj
j−l
(T n,h u
T m,r ) = CR(ϕm S[l,u] ϕn , j, s0i , d, O)
h= j−u

r=h+1

• Unbounded Since:
For unbounded sub-formula ϕk = ϕm S[l,+∞) ϕn , according to Induction Hypothesis:
Pre(k) = Jϕm S[l,+∞) ϕn K(s, i − 1 − Hst + hst(ϕk ))
In dynamic programming we recursively update the value
Jϕm S[l,+∞) ϕn K(s, i − Hst + hst(ϕk ) + x)
given the previous robustness value in the table
Jϕm S[l,+∞) ϕn K(s, i − Hst + hst(ϕk ) + x − 1)
(where x = 0 when we use the Pre(k))
According to Def. 3 the robustness
semantics at time i + j:

Gi+ j−l 
li+ j
Jϕm S[l,+∞) ϕn K(s, i + j) =
Jϕn K(s, h) u
Jϕm K(s, r)
h=0

r=h+1

and robustness for previous time i + j − 1:

Gi+ j−l−1
li+ j−1
Jϕn K(s, h) u
Jϕm K(s, r)
Jϕm S[l,+∞) ϕn K(s, i + j − 1) =
h=0

r=h+1

We can define robustness value at time i + j given the value at time i + j − 1:

Gi+ j−l 
li+ j
Jϕm S[l,+∞) ϕn K(s, i + j) =
Jϕn K(s, h) u
Jϕm K(s, r) =
h=0
r=h+1
 Gi+ j−l−1 
F
li+ j−1

=
Jϕn K(s, h) u
Jϕm K(s, r) u Jϕm K(s, i + j)
h=0
r=h+1
li+ j


Jϕn K(s, i + j − l) u
Jϕm K(s, r) =
r=i+ j−l+1

F
= Jϕm S[l,+∞) ϕn K(s, i + j − 1) u Jϕm K(s, i + j)
li+ j


Jϕn K(s, i + j − l) u
Jϕm K(s, r)
r=i+ j−l+1

Based on IH, we know that j ≥ −Hst + hst(ϕk ). We must show that the value
of T n, j−l = Jϕn K(s, i + j − l), i.e., −Hst + hst(ϕn ) ≤ j − l and also the values of T m,q
for j − l + 1 ≤ q ≤ j satisfy T m,q = Jϕm K(s, i + q), i.e., −Hst + hst(ϕm ) ≤ j − l + 1.

20

We have two cases for hst(ϕk ):
Case 1: hst(ϕk ) = hst(ϕn ) + l = max{hst(ϕn ) + l, hst(ϕm ) + l − 1}
According to IH, j ≥ −Hst + hst(ϕk ); therefore, j ≥ −Hst + hst(ϕn ) + l and
j − l ≥ −Hst + hst(ϕn ) which satisfies T n, j−l = Jϕn K(s, i + j − l). On the other
hand in this case: hst(ϕn ) + l ≥ hst(ϕm ) + l − 1.
According to IH, j + Hst ≥ hst(ϕk ) ≥ hst(ϕm ) + l − 1, i.e., j + Hst ≥ hst(ϕm ) + l − 1.
Thus j − l + 1 ≥ −Hst + hst(ϕm ) which satisfies the fact that T m,q = Jϕm K(s, i + q)
for j − l + 1 ≤ q ≤ j.
Case 2: hst(ϕk ) = hst(ϕm ) + l − 1 = max{hst(ϕn ) + l, hst(ϕm ) + l − 1}
According to IH, j ≥ −Hst + hst(ϕk ); therefore, j ≥ −Hst + hst(ϕm ) + l − 1 where
j − l + 1 ≥ −Hst + hst(ϕm ) which satisfies the fact that T m,q = Jϕm K(s, i + q) for
j − l + 1 ≤ q ≤ j. On the other hand in this case: hst(ϕm ) + l − 1 ≥ hst(ϕn ) + l.
According to IH, j + Hst ≥ hst(ϕk ) ≥ hst(ϕn ) + l i.e. j + Hst ≥ hst(ϕn ) + l.
thus j − l ≥ −Hst + hst(ϕn ) which satisfies T n, j−l = Jϕn K(s, i + j − l)
As a result:
∀ j, −Hst + hst(ϕk ) ≤ j ≤ Hrz : Jϕk K(s, i + j) = Jϕm S[l,+∞) ϕn K(s, i + j) =
F
= Jϕm S[l,+∞) ϕn K(s, i + j − 1) u Jϕm K(s, i + j)
li+ j


Jϕn K(s, i + j − l) u
Jϕm K(s, r) =
r=i+ j−l+1
)
(
F
lj

T k, j−1 if j > −Hst + hst(ϕk )
=
u T m, j
T n, j−l u
T m,r =
r= j−l+1
Pre[k] if j = −Hst + hst(ϕk )

F

tmpS
T n, j−l u tmpmin = CR(ϕm S[l,+∞) ϕn , j, s0i , d, O).

Conformance Testing as Falsification for Cyber-Physical
Systems
Houssam Abbas, Bardh Hoxha, and Georgios Fainekos
CPS Lab, Arizona State University, Tempe, AZ, USA

{hyabbas, fainekos, bhoxha}@asu.edu
Jyotirmoy V. Deshmukh, James Kapinski, and Koichi Ueda,
Toyota Technical Center, Gardena, CA, USA

arXiv:1401.5200v2 [cs.SY] 31 May 2014

{jyotirmoy.deshmukh, jim.kapinski, koichi.ueda}@tema.toyota.com
ABSTRACT
In Model-Based Design of Cyber-Physical Systems (CPS),
it is often desirable to develop several models of varying
fidelity. Models of different fidelity levels can enable mathematical analysis of the model, control synthesis, faster simulation etc. Furthermore, when (automatically or manually)
transitioning from a model to its implementation on an actual computational platform, then again two different versions of the same system are being developed. In all previous
cases, it is necessary to define a rigorous notion of conformance between different models and between models and
their implementations. This paper argues that conformance
should be a measure of distance between systems. Albeit a
range of theoretical distance notions exists, a way to compute such distances for industrial size systems and models
has not been proposed yet. This paper addresses exactly
this problem. A universal notion of conformance as closeness between systems is rigorously defined, and evidence is
presented that this implies a number of other applicationdependent conformance notions. An algorithm for detecting that two systems are not conformant is then proposed,
which uses existing proven tools. A method is also proposed
to measure the degree of conformance between two systems.
The results are demonstrated on a range of models.

1.

INTRODUCTION

In a typical Model-Based Design (MBD) process for CyberPhysical Systems (see Fig. 1), a series of models and implementations are iteratively developed such that the end product satisfies a set of functional requirements Φ. Ideally, the
initial (simpler) model MS developed should have structural
properties that make it amenable to formal synthesis and
verification methods [40, 28] (cycle 1 in Fig. 1) through software tools like [17, 35, 44, 22, 41, 34]. Then, the fidelity of
the models is increased by modeling more complex physical
phenomena ignored initially and by introducing inaccuracies

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00.

Requirements /
Specifications Φ

Calibration and
Deployment (SD)

4

1
Simple
Model (‫ܯ‬ௌ )

3

2
Complex
Model (‫ܯ‬஼ )

3

Implementation (SI)
(HIL or Prototype)

Autocode
Generation

Figure 1: Typical V process in MBD. (1) Verifying that the
simple model satisfies the functional requirements; (2) Establishing a relationship between the simple and complex
model; (3) Verifying conformance of implementation to the
model; (4) Verifying that the end product satisfies the functional requirements.
due to the computational platforms such as look-up-tables,
time delays, 3rd party black-box components, etc.
The development of a higher fidelity model raises the obvious question of what is the relationship between the “simple”
MS and “complex” MC models developed (cycle 2 in Fig.
1). If the simpler model developed was a nondeterministic
model and the structure of MC was fully known, then the
answer to the question could be established through behavioral inclusions [40], i.e., is it true that every behavior of MC
can be exhibited by MS , in response to the same stimulus?
However, in practice, non-deterministic models are rarely
utilized and supported by industry tools for MBD such as
LabViewT M or Simulink/StateflowT M . Instead, a hierarchy of deterministic models is developed each capturing a
more accurate representation of the final system, and it is
important to know how ‘close’ two successive models are
to each other. While the higher fidelity model introduces
new, more realistic behavior, it should still follow, roughly,
the behavior of MS . Thus, in lieu of behavioral inclusion,
an appropriate notion of distance between the models is required, i.e., dist(MC , MS ). This we call conformance between the simple and complex models. Such distance1 notions have been developed for various classes of systems [40,
18, 7, 32, 21] over the years. Even though works such as [18,
1
Note we don’t use the word ‘distance’ in the mathematical
sense.

32] treat systems with hybrid dynamics directly, they apply
only to certain classes of hybrid systems and, most importantly, they rely on the full knowledge of the mathematical
model of both MS and MC . For industrial size CPS models,
such knowledge is not always available. Another limitation
is that existing distance measures for systems either consider
only distances in time, e.g., [21], or in space [18, 7, 32]. For
CPS, both are extremely important especially if the end goal
is to verify that the deployed system (SD ) satisfies formal
specifications that involve timing requirements [26, 31].
The same observations hold for the important problem
of verifying whether a system SI , which is an implementation of a model MC , behaves approximately similar to its
model MC (arrows labeled with 3 in Fig. 1). Irrespective of
whether the automatic code generation process has formal
guarantees, rarely does the model MC capture accurately
all physical phenomena. Thus, the prototype system SI will
be manually modified and calibrated into a final deployment
SD . Then, the deployment SD should have a bounded, computable distance from the model MC under an appropriate
metric, i.e., dist(MC , SD ) ≤ ε, and, SD should satisfy the
set of specifications.
In this paper, a framework is provided to address the
aforementioned gaps in MBD for CPS, i.e., arrows 2 and 3
in the V process in Fig. 1. The framework is agnostic about
whether the systems studied are both models or a model
and its implementation, thus we will generically refer to one
system as the Model and to the other as its Implementation.
More specifically, we utilize hybrid distance measures similar to [30, 37, 12] in order to define distances between system
behaviors. Given two system behaviors (or trajectories), we
compute a (τ, ε) distance between them that captures both
their distances in time and in space. Then, given a bound
(τ̄ , ε̄), we consider the problem of whether the Implementation conforms to its Model with degree (τ̄ , ε̄). We pose the
aforementioned problem as an optimization problem which
we solve using our tool S-Taliro [6, 14]. Our solution is a
best effort framework and the guarantees provided are of a
probabilistic nature as described for instance in [3, 5, 27].

Conformance testing versus specification checking.
One question naturally arises at this point: why not just
verify that the Implementation satisfies the same specification that the Model has been verified to satisfy? The reasoning behind the question is that if Φ is all that matters,
it should be sufficient that the Implementation also satisfies
it. We may answer this question as follows:
1. It is not always possible to verify formally that the
Implementation satisfies the formal specification: for
example, a component purchased from a third party
might allow only limited observability and not lend
itself to formal methods.
2. Parts of the specification are not formally expressed.
For example, because the available formal tools can not
handle the size of the design (e.g. reachability tools for
nonlinear systems). Rather, the specification exists in
plain language Test Plan documents [23] or implicitly
in test suites.2
3. For a real-life CPS, much of the behavior is de facto
left unspecified because of the complexity. Once trig2

Note the release of industrial tools that induce requirements from simulation traces, such as [8], in an effort to
formalize requirements currently implicit in tests.

gered, a particular behavior may exhibit unspecified
but undesired characteristics, even though it possesses
the specified, desired, characteristics (and none of the
specified, undesired characteristics).
Therefore, once we have an Implementation, it is not sufficient to check that it too conforms to the specification (if
that is even possible). It is important to make sure that
behaviors exhibited by Model and Implementation are close
(in a sense to be defined). This then is conformance testing.
This way, both Model and Implementation display similar
unspecified characteristics, and our level of confidence in the
Implementation derives from our confidence in the Model.

1.1

Summary of contributions

In the previous sections, we have argued that current ways
of thinking about the relation between a Model and its Implementation are not sufficient for the verification of complex
CPS. In the remainder of this paper,
1. We propose a universal definition of conformance between CPSs as a quantifiable closeness measure between the output behaviors of the two systems.
2. We argue that this universal notion implies most custom conformance notions which depend on the application.
3. We pose conformance testing as a logic property falsification problem. We then apply existing tools to this
problem and show that they successsfully find nonconformant behavior.
4. We show that conformance satisfies a monotonicity
property which allows us to search efficiently for the
best conformance degree between two systems.

2.

PROBLEM FORMULATION

In Section 1, it was argued that the verification of a CPS
implementation in an MBD process requires conformance
testing. The latter was described as checking that Model
and Implementation display ‘similar’ behaviors, where ‘similar’ will be made precise. Because the objective is to detect
bugs caused by the implementation process, Model and Implementation should be tested with the same inputs, and
starting from the same initial conditions. Our high level
goal is then to determine whether there exists a pair of (initial conditions, input signal) that causes the Model and its
Implementation to produce significantly different outputs;
and if such a pair exists, to find it and present it to the user
as a debug guide.
To make this goal precise, this section starts by presenting
the class of systems that we study. This class is illustrated
with a running example of a fuel control system for an automotive application. Then, the conformance testing problem
is formally stated as a search problem over the set of initial
conditions and input signals. Finally, the constraints under
which we seek to solve this problem are presented. This lays
the groundwork for Section 3, where we will mathematically
define what it means for two CPSs to be conformant.
Notation. Given two sets A and B, B A denotes the set of
all functions from A to B. That is, for any f ∈ B A we have
f : A → B. Given a cartesian set product A × B, prA is the
projection onto A, i.e. for all (a, b) ∈ A × B, prA ((a, b)) = a.

2.1

System model and running example

At its most general, a CPS H may be thought of as an
input-output map. Specifically, let N = {1, 2, . . . , |N |} ⊂ N
be a finite set of integers, T > 0 be a positive real, H0 ⊂
Rnh be a set of initial operating conditions of the system,
U ⊂ Rnu be a compact set of input values, and let Y ⊂ Rny
be a set of output values.
Definition 2.1. A real-timed state sequence (real-TSS)
is a pair (y, σ) where y ∈ Y |N | and σ ∈ [0, T ]|N | .
A hybrid-timed state sequence (hybrid-TSS) is a pair
(y, σ) where y ∈ Y |N | and σ ∈ ([0, T ] × N)|N | .
When a statement applies to both real-timed and hybridtimed state sequences, we will simply say ‘timed state sequence’ (TSS). A TSS can be the result of a sampling process
or a numerical integration. Then the vector of ‘timestamps’
σ represents the sequence of sampling times, or times at
which a numerical solution is computed. A timed state sequence will also be referred to as a signal, and a Y -valued
timed state sequence will also be referred to as a trajectory. The latter is standard dynamical systems theory terminology. Note that a real-TSS may be viewed as a special
hybrid-TSS (y, σ) such that σ ∈ ([0, T ] × {1})|N | .
A CPS is modeled as a map between initial conditions
h0 ∈ H0 and input timed state sequences (u, µu ) ∈ U |N | ×
T|N | := U to output timed state sequences (y, µy ) ∈ Y |N | ×
T|N | , where T is either [0, T ] (for real-timed) or [0, T ] × N
(for hybrid-timed). Note that input and output signals must
either both be real-timed, or both be hybrid-timed. We
model discrete states as integers, so H, U and Y could be
hybrid spaces of the form X × L with X ⊂ Rn and L finite.
The system H can then be viewed as a map:
H : (h0 , u) ∈ H0 × U 7→ (y, σ) ∈ Y |N | × T|N |

(1)

We impose the following restrictions on the systems that
we consider:
1. The output space Y must be equipped with a generalized metric d. See [5] for implications.
2. For every initial condition η0 ∈ H0 and input signal
u ∈ U, the system H produces an output signal. This
is imposed to avoid modeling issues where the Model’s
and/or Implementation’s equations have no solutions.
Further details on the necessity and implications of the aforementioned assumptions can be found in [5].
As it is standard in systems theory, the system’s output
can be expressed as a function of its internal state η ∈ H ⊃
H0 :
η ∈ H 7→ y = g(η) ∈ Y
Here, H is the state-space of the system. We do not always assume that the internal state is observable. Given
a real-timed state sequence (y, µ), its ith element is denoted (y, µ)i = (yi , µi ) ∈ Y × T. Similarly, given a hybridtimed state sequence (y, σ), the ith element (y, σ)i is denoted (yi , σi ), with σi = (t, j) ∈ [0, T ] × N.
Example 1. We consider a fuel control (FC) system for
an automotive application. Environmental concerns and government legislation require that the fuel economy be maximized and the rate of emissions (e.g., hydrocarbons, carbon

monoxide, and nitrogen oxides) be minimized. Control of automobile engine air-to-fuel (A/F) ratio is crucial to optimize
fuel economy and to minimize emissions. Ideal A/F levels
are given by the stoichiometric value, which is the optimal
A/F ratio to minimize both fuel consumption and emission
of pollutants. The purpose of the FC system is to maintain
the ratio of air-to-fuel (A/F) within a given range of the
stoichiometric value.
The scenario that we model involves an engine connected
to a dynamometer, which is a device that can control the
speed of the engine and measure the output torque. For our
experiment, the dynamometer maintains the engine at a constant rotational velocity, as the engine is tested. There is
only one input to the model: the throttle position command
from the driver.
The conformance testing scenario for this example is unique,
in that the Model was derived from the Implementation, for
reasons on which we will now elaborate. The Implementation was derived from a textbook model of an engine control
system [20], and contains implementation details such as
look-up-tables (LUTs). The Model was then abstracted from
this Implementation for the purposes of formal analysis [24].
Despite the counter-intuitive relationship between the Model
and Implementation for this case, the conformance task remains: to verify that these two versions satisfy some similarity criterion.
4
The discussion and results in this paper apply to this
input-output map model of a CPS. To define some of the
conformance notions in this paper, it will be useful to sometimes work with the more specialized hybrid automaton model
of a CPS [30]: broadly speaking, a hybrid automaton has
countably many modes {`1 , `2 , . . .} := L, with possibly different dynamics F` active in each mode: η̇ = F` (η, u). The
automaton switches (or ‘jumps’) between modes whenever
the internal state η enters specific subsets G ⊂ H of the
state space, called switching guards. In general, a switching
guard might depend on time and on the current state; different jumps ` → `0 will have different guards: G = G(e, t, η),
e = (`, `0 ). Finally, when the system switches modes, the internal state might be reset to a switch-specific value: η + =
Re(η, e) if η ∈ G(e, t, η). If we explicitly model the system
mode as part of the internal state η = (x, `) ∈ X × L, we
may write the automaton’s equations as [36]

˙
 (ẋ, `)
= (F` (x, u), 0)
(x, u) ∈ C × U
H
(2)
(x+ , `+ ) = Re(e, x)
(x, u) ∈ D × U

y
= g(η)
where C ⊂ X is the ‘flow set’ of continuous evolution, and
D is the jump set, which equals the union of all guard sets.
Apart from the requirement that the dynamics have at least
one solution for every (η0 , u), they are arbitrary.
Remark 2.1. The notion of a system mode applies to the
general input-output model of a system, so in what follows
we will often be referring to the ‘mode’ of the CPS without
necessarily requiring that it be modeled as a hybrid automaton. For example, a powertrain Implementation might be
outputting the current gear, or the mode of operation e.g.
Economy vs. Sport.
The trajectories (or ‘solutions’) of purely continuous dynamical systems (with only one mode) are parameterized by
the time variable t, and those of purely discrete dynamical

systems (with no continuous evolutions) are parametrized by
the number of discrete jumps j. Following Goebel and Teel
[19], the trajectories to hybrid automata are parametrized
by both t and j, to reflect that both evolution mechanisms
are present. So we write η(t, j) for the state and y(t, j) for
the output of the automaton at time t and after j jumps,
or mode switches. Because jumps take 0 time, it is possible
to have the automaton go through several states in 0 time:
η(t, j) → η(t, j + 1) → η(t, j + 2) . . .. This can’t happen
in a physical Implementation, but it may be allowed in the
Model. We refer the reader to [19] for exact definitions of
discrete and hybrid time domains, arcs and trajectories.
We now introduce the behavior of a system which is applicable to both input-output maps and hybrid automata.
Definition 2.2 (Behavior). Take a system H, an initial point h0 ∈ H and input signal u. The behavior of the
CPS H from h0 and u, denoted BH (h0 , u), consists of
• h0 = (x0 , `0 )
• the output trajectory yH (h0 , u) generated by H in response to (h0 , u)
The behavior of H is then
BH = {(h, yH (h, u)) | h ∈ H0 , u ∈ U}
Example 2 (Example 1 Continued). For the FC, the
outputs consist of the normalized air-to-fuel ratio λ and the
fuel commanded into the Cylinder-and-Exhaust. Thus Y =
R2+ . The presence of a switch in the Throttle block, and an
LUT in the Cylinder-and-Exhaust block, induces 8 modes so
L = {1, . . . , 8}. The outputs of the FC are sampled at a fixed
rate. The output signals can be modeled as real-TSS. If we
could observe the mode changes during a simulation, then we
can use a counter j to count the mode switches, or ‘jumps’,
and model the output as a hybrid-TSS. E.g. the following
sequence of sampled (λ, mode)
(1, `1 ), (0.99, `1 ), (0.98, `2 ), (0.87, `2 ), (0.88, `1 )
is interpreted as the following hybrid-TSS
(y, σ) = ((1, 0.99, 0.98, 0.87, 0.88),
((0, 0), (T /|N |, 0), (2T /|N |, 1), (3T /|N |, 1), (3T /|N |, 2))
Note that j counts the jumps so far, but does not indicate
what mode the system is in.

2.2

Conformance testing

Based on the preceding discussion, we adopt the premise
that conformance is a relation of similarity between the behaviors of two systems when subjected to the same stimulus. The behavior is defined in Def. 2.2. So we may speak of
conformant (i.e., similar) behaviors, or conformant output
trajectories. Conformance testing can then be formulated
as a search problem: find a pair of trajectories, generated
by the two CPSs in response to the same initial condition
and input, that are not conformant. The search for a nonconformant pair of trajectories is called falsification.
Problem 1 (Conformance testing). Let HM and HI
be a Model and Implementation of a CPS, respectively. Find
a pair θ = (η, u) ∈ H × U such that yHM (θ) and yHI (θ) are
non-conformant.

Because Implementations typically have limited observability, we assume testing happens under the following restriction:
Assumption 2.1 (Black box testing). The behaviors
of Model and Implementation are observable: i.e. it is always possible, for either system, to obtain an element of the
behavior by executing the system. Only the behavior of the
Implementation is observable - i.e. we know nothing else
about it.
In particular, the sequence of modes that Model and Implementation go through can be an important variable to
track to decide whether the two systems conform. As an
example, a silicon microchip has ‘scan chains’, which are
chains of buffers that pass to the outside world the values
of internal registers. These are only used during testing,
and are burnt before customer delivery. In control systems,
mode estimation [10] could be used when applicable. While
we leave it possible that more is known about the Model,
we won’t need to know more to apply the methods of this
paper. More knowledge of the Model will make applicable
grey box testing methods such as [4, 2].

3.

DEFINING CONFORMANCE

In general, conformance is an application-dependent notion to help determine that the implementation process does
not use components or methods that alter the functionality
(or safety or performance) of the final product in any significant manner. What ‘significant’ means will, naturally,
depend on the application. This makes conformance testing
itself application-dependent. Our first contribution is made
in this section: we present a notion of distance between output trajectories, called (T, J, (τ, ε))-closeness, and argue that
this is an appropriate universal notion of conformance; that
is, it is generally applicable regardless of the underlying application. The price we pay for this universality is that this
notion is stronger than the application-dependent ones: two
systems may not be conformant according to (T, J, (τ, ε))closeness, but they may be conformant according to a weaker
custom notion which is sufficient for the task at hand. In
the second part of this section, we give real-life examples
where the application-dependent conformance turns out to
be implied by (T, J, (τ, ε))-closeness.
Thus we may develop a general theory of conformance
based on (T, J, (τ, ε))-closeness, and ‘generic’ algorithms that
decide conformance which do not depend on the application. This is advantageous for two reasons: one of the challenges today for testing of hybrid systems (and CPS in general) is to define conformance in a rigorous manner, and
(T, J, (τ, ε))-closeness provides an answer. Secondly, generic
conformance tools can be used early in the design cycle, before the instrumentation is all there for a deeper analysis of
the difference between Model and Implementation. Moreover, a feature of the universal notion is that it uses only
the outputs of the system (and possibly the mode sequence
if available). Thus, the analysis and methods herein are applicable to potentially complicated systems with very general system models, including the input-output map model
in Section 2.1.

3.1

A universal conformance notion

The proposed universal notion of conformance is (T, J, (τ, ε))closeness. (T, J, (τ, ε))-closeness expresses proximity between

the outputs, their time sequences (real-TSS and hybridTSS), and their modes if applicable. It is derived from [19].
Definition 3.1 ((T, J, (τ, ε))-closeness). Take a test
duration T > 0, a maximum number of jumps J ∈ N, and
parameters τ, ε > 0. Two timed state sequences, or trajectories, (y, σ) and (y0 , σ 0 ) are (T, J, (τ, ε))-close if
(a) for all i ∈ N such that σi = (t, j) satisfies t ≤ T, j ≤ J,
there exists k ∈ N such that σk0 = (s, j), |t − s| < τ , and
kyi − yk0 k < ε
(b) for all i ∈ N such that σi0 = (t, j) satisfies t ≤ T, j ≤ J,
there exists k ∈ N such that σk = (s, j), |t − s| < τ , and
kyi0 − yk k < ε
We will also say that y1 and y2 are conformant with degree
(T, J, (τ, ε)).
When T and J are clear from the context, we simply say
(τ, ε)-close. Because a real-TSS is a special case of a hybridTSS, the above definition applies to both.
(T, J, (τ, ε))-closeness may be tought of as giving a proximity measure between the two hybrid arcs, both in time
and space. The definition says that within any time window of size 2τ , there must be a time when the trajectories
are within ε or less of each other. Allowing some ‘wiggle
room’ in both time and space is important for conformance
testing: when implementing a Model, there are inevitable
errors. These are due to differences in computation precision, clock drift in the implementation, the use of inexpensive components, unmodeled environmental conditions, etc,
leading to the Implementation’s output to differ in value
from the Model’s output, and to have different timing characteristics. Thus (T, J, (τ, ε))-closeness captures nicely the
intuitive notion that ‘the outputs should still look alike’.
Our definition of (T, J, (τ, ε))-closeness differs slightly from
the original definition in [19] in that we use two ‘precision’
parameters τ and ε instead of one. In practice, using only
one precision parameter is too restrictive, since the outputs
can have a different order of magnitude from the time variable. It can be verified that the hioco relation of Van Osch
[33] is an exact version of (T, J, (τ, ε))-closeness (τ = ε = 0),
with the role of inputs and outputs explicitly differentiated.
Remark 3.1. If it is not possible to observe the number
of jumps j, then we simplify the above definition by assuming
that j is always equal to 1. In other words, we interpret the
definition over real-TSS and assume the system only has one
mode.
Definition 3.2. Take a test duration T > 0, a maximum number of jumps J ∈ N, and parameters τ, ε > 0.
Two CPSs HM and HI are said to be (T, J, (τ, ε))-close if
for any initial condition h0 ∈ H0 and input signal u ∈ U,
the trajectories yHM (h0 , u) and yHI (h0 , u) are (T, J, (τ, ε))close. The two systems are also said to be conformant with
degree (T, J, (τ, ε)).
Remark 3.2. A Model and Implementation generally won’t
have the same state-space, and so won’t accept the same initial conditions. So when we provide the same initial condition h0 to both, one of them might use a projection of h0

or a more general mapping f (h0 ) to obtain its appropriate
initial conditions.
From a conformance perspective, it is preferable to have
a smaller ε and a smaller τ . We use this to define a partial
order on the (τ, ε) pairs.
Definition 3.3. The partial order relation  over (τ, ε)
pairs is given by (τ, ε)  (τ 0 , ε0 ) if and only if τ ≤ τ 0 and
ε ≤ ε0 . The inequality is strict if and only if at least one of
the component-wise inequalities is strict.
Remark 3.3. (T, J, (τ, ε))-closeness has the valuable advantage of being monotonic: if two trajectories are (T, J, (τ, ε))close, then they are (T, J, (τ 0 , ε0 ))-close for any (τ 0 , ε0 ) 
(τ, ε). This allows us to use a simple binary search for a
smallest (τ, ε) pair such that the trajectories, and the systems, are (T, J, (τ, ε))-close. We make use of this property
in the experiments.

3.2

Examples

We conclude this section with examples where applicationspecific notions of conformance are implied by (T, J, (τ, ε))closeness. Thus if we find trajectory pairs (ηHM , ηHI ) that
violate the latter, they automatically violate the former.
Example 3 (Example 1 continued). Because the lookup-tables (LUTs) in the Implementation HI are replaced by
polynomials in the Model HM , some error is expected between the outputs of the two systems. The designer hopes,
however, that the error at the output of the Implementation,
is in the same order of magnitude as the error between the
outputs of the LUTs and the outputs of the corresponding
polynomials. If not, then more entries are needed in the
LUT. Moreover because LUT look-ups are typically faster
than polynomial computations, some delay between the two
outputs is expected to be observed. The designer has a prespecified maximum acceptable delay. In this case, conformance imposes upper bounds on the spatial and temporal
differences between the outputs of Model and Implemenation.
Conformance testing is applicable to application domain
areas other than the automotive industry. E.g. in the microchip design cycle, as shown in the following example.
Example 4 (State retention). HM is an RTL description of an electrical circuit, and HI is equal to HM
with power gating and state retention added to some of its
subsystems. With state retention, the contents of certain
critical memory elements of the power-gated subsystem are
retained in ‘shadow’ registers prior to power-down, and restored after power-up. This creates a temporary difference
between the state of the non-state retained circuit (HM ) and
the state-retained circuit (HI ). This difference lasts until
the reset sequence is completed. Thus in this case, conformance means that a temporary difference in modes between
the two systems is allowed, but they must re-converge after
a pre-defined amount of time.

4.

SOLUTION APPROACH

In this section, we present a general method for determining whether two systems are conformant or not. We
also provide a way to quantify the degree of conformance
between them.

𝐌
(h0 , u)
𝐈

𝒚𝑀
𝜎𝑀
𝒚𝐼
𝜎𝐼

𝒚𝑀
𝜎𝑀
𝒚𝐼
𝜎𝐼

Sk (yM , µM ) := (Sk yM , Sk µM ), with
Sk y

=

(yk+1 , yk+2 , . . . , y|N | , y|N | , . . . , y|N | )
|
{z
}

(3)

k times

Sk µ =

(µk+1 , µk+2 , . . . , µ|N | , µ|N | +

kT
T
, . . . , µ|N | +
)
|N |
|N |

when k > 0, and
Figure 2: Parallel interconnection of Model and Implementation.

Sk y

=

(y1 , . . . , y1 , y1 , yk+2 , . . . , y|N |−k )
| {z }

(4)

k times

Sk µ = µ

4.1

Conformance as falsification

Our approach is based on the observation that (T, J, (τ, ε))closeness can be expressed as a formal logical property defined over the output timed state sequences of the parallel
interconnection of systems HM and HI . See Fig. 2. A
TSS of the interconnection system H|| is just the concatenation of the TSS of the component systems: (y|| , σ|| ) =
((yM , σM ), (yI , σI )). If we can find a (parallel) TSS (or ‘trajectory’) (y|| , σ|| ) which falsifies the (T, J, (τ, ε))-closeness property, then by definition, the component trajectories are nonconformant, and by extension, the systems HM and HI are
non-conformant. In what follows, we will use the terms
‘falsifying trajectory pairs’ and ‘non-conformant trajectory
pairs’ interchangeably.
The logic we use to express (T, J, (τ, ε))-closeness is Metric
Temporal Logic (MTL) [26] (see Appendix for a review of
MTL). We first present the following construction for realTSS, then generalize it to hybrid-TSS.
Real-TSS: Fix τ > 0, ε > 0. Our goal is to express (τ, ε)closeness as an MTL formula. Let (yM , µM ) and (yI , µI )
be the outputs of Model and Implementation CPSs, respectively, in response to the same initial conditions and input
signal. Because (τ, ε)-closeness requires comparing the current value of yM to current, past and future values of yI
(over a window of width 2τ ), we will create shifted versions
of yI . Given the symmetry of (τ, ε)-closeness, we will also
define shifted versions of yM . The amount of the shift will
depend on τ : how many samples of yI (yM ) fit within a
window of width 2τ ?
The shifted versions are now defined. Recall that yM,i
is the ith sample in the TSS yM , and similarly for yI,i .
Consider the Model’s output: for each i ∈ N , compute
the largest k ≥ i such that |µM,i − µM,k | < τ . Define
m(τ, i) = k − i: this is the number of samples in the largest
window of duration less than τ starting at µi . Similarly, we
compute n(τ, i) for the Implementation TSS for every i ∈ N .
The numbers n and m could in general vary with i due to an
adaptive sampling period. Define m(τ ) = min{m(τ, i), i ∈
N }. m(τ ) is the smallest number of samples in a window of size less than τ anywhere in (yM , µM ). Assuming that |µM | > 1, it comes that m(τ ) < ∞.3 This constitues the size of the shift (forward and backward) to apply to (yM , µM ). Similarly, define n(τ ) for the Implementation. We may now define shifted versions of the output trajectories via the discrete shift operator: for k ∈ Z,
3

The case where m(τ ) = ∞ occurs when the Model trajectory yM is Zeno: i.e., when it contains an infinite number
of samples without advancing time. This can result from a
modeling artifact [25]. The condition |µM | > 1 effectively
says we have at least two different timesteps, and so the
trajectory is not initially Zeno.

when k < 0. Note that the filler values at both ends of
the shifted sequences Sk y (3),(4) are obtained by constant
interpolation.
Recall Def. 3.1(a). This condition can be captured by
saying that at all i, there exists a k ∈ {−n(τ ), . . . , n(τ )}
such that kyM,i −(Sk yI )i k < ε. Analogously for Def. 3.1(b).
Now (T, J, (τ, ε))-closeness may be expressed as the following MTL formula ϕ(τ,ε) (∨ is the logical OR operator, ∧
is the logical AND operator, and I is the temporal ‘Always
over the time interval I’ operator - see Appendix)
n(τ )

p1 (τ, ε)

=

_

kyM,i − (Sk yI )i k < ε

(5)

kyI,i − (Sk yM )i k < ε

(6)

k=−n(τ )
m(τ )

p2 (τ, ε)

=

_
k=−m(τ )

ϕ(τ,ε)

:= [0,T ] (p1 (τ, ε) ∧ p2 (τ, ε))

(7)

Because (T, J, (τ, ε))-closeness only requires that the two
signals be within ε of each other at least once in a window
of size 2τ , p1 and p2 use disjunction: it is sufficient for one
shifted comparison to be less than ε.
Hybrid-TSS: To define the MTL formula over hybrid-TSS,
we must break up each trajectory into segments, such that
there are no jumps within a segment. Specifically, consider
the hybrid-TSS (y, σ), with
σ = ((t1 , j1 ), (t2 , j2 ), . . . , (t|N | , j|N | ))
Assume that there are only G unique values of j that appear
in σ, corresponding to G − 1 jumps. We divide the hybridTSS into G segments g1 , . . . , gG , such that j is constant over
a segment. Each segment can be viewed as a real-TSS. If we
apply this procedure to (yM , σM ) and (yI , σI ), we get GM
M
Model segments {giM }G
i=1 and GI Implementation segments
I GI
{gi }i=1 . Let G = max{GM , GI }. We can now apply the
above procedure to every pair (giM , giI ), with the important
difference that the shifted sequences Sk y (3),(4) are filled
with an arbitrarily large value (or +∞), and not by constant
interpolation. This is to reflect that a comparison past the
jump point is not valid. This results in G formulae ϕi(τ,ε)
obtained via (7). The complete formula can now be written
^ i
Φ(τ,ε) =
ϕ(τ,ε)
(8)
i

Note there are other ways of defining the MTL formula
for hybrid-TSS that directly incorporate the jump counter
in the formula. Comparing these different methods is outside the scope of this paper. Unless otherwise indicated, all
the discussion that follows applies equally to the formula
obtained via (7) (for real-TSS) or (8) (for hybrid-TSS).

We can now use existing tools, like S-TaLiRo [6, 14],
to find a pair of trajectories (equivalently, a trajectory of
the parallel interconnection) which falsify ϕ(τ,ε) . S-TaLiRo
uses, among others, Simulated Annealing (SA) to find falsifying trajectories. If such a trajectory is not found, convergence properties of SA imply that with probability approaching 1, the property is satisfied by the systems; equivalently, that the two systems are indeed conformant.
We should stress at this point that the proposed method is
not specific to (T, J, (τ, ε))-closeness. It is more widely applicable to any application-dependent conformance notion
that can be expressed as an MTL formula, including those
from the examples in Section 3. For example, for the case
when mode sequences are allowed to diverge for at most a
pre-defined duration D (Example 4), the conformance relation is expressed as: “For every initial condition h0 ∈ H0 and
every input signal u ∈ U, whenever the two systems are in
different modes, they will be back in the same mode within
D sec”. This can now be written as the MTL formula:
ϕP W C := [0,T −D] (`(t) 6= `0 (t) ⇒ 3[0,D] `(t) = `0 (t))

(9)

We conclude this section with a word on how to practically falsify ϕ(τ,ε) (or any of the other application-dependent
notions). A method that has proved efficient is to minimize
the robustness of the trajectories w.r.t the MTL property. In
this work, we use spatial robustness [5, 15] and time robustness [13]. Spatial robustness measures how far in the output
space a given trajectory is from the nearest trajectory with
opposite truth value for ϕ.4 The spatial robustness of trajectory (y, µ) starting at time t w.r.t. formula ϕ is denoted
as follows
[[ϕ]]((y, µ), t) = r ∈ R ∪ {±∞}
Computing r is done on the output trajectory without any
reference to the system that generated it.
Time robustness measures by how much to shift the given
trajectory in time, to change its truth value w.r.t. ϕ. Two
time robustness values may be measured for each trajectory: the future robustness θ+ and the past robustness θ− ,
depending on whether the signal is shifted left (so future values are introduced) or right (so past values are introduced).
In this work we explicitly denote time robustness by
[[ϕ]]θ ((y, µ), t) = min{θ− , θ+ } ∈ R ∪ {±∞}
The spatial [15] and temporal [13] robust semantics of MTL
formulae are reviewed in the appendix.
Both types of robustness (spatial and temporal) satisfy
the fundamental theorem that a negative robustness value
indicates falsification, a positive value indicates satisfaction,
and a value of 0 indicates that an infinitesimal change in the
trajectory (in space or in time) will change its truth value.
Therefore, the search for a falsifying trajectory y|| can be recast as the problem of minimizing [[ϕ]](y|| , 0) over H0 × U|N | .
To make this a finite-dimensional optimization, the input
signals are parameterized with a finite number of parameters. (This parametrization effectively limits the search
space, and the global minimum returned by falsification is a
minimum over this limited space. But the parametrization
can typically be made as precise as desired, e.g. to within
4

If the mode is observable, spatial robustness also computes
the (quasi-) distance between the modes of the two trajectories [5], but we don’t make use of this here.

the approximation error of the minimization algorithm). As
our objective is to find falsifying trajectories, we stop the
search as soon as it encounters a trajectory with negative
robustness.
Now it is possible to create an example which displays a
(graphically) convergent sequence of trajectories (y||,i , µ||,i ) →
(y|| , µ|| ) such that [[ϕ(τ,ε) ]]((y||,i , µ||,i ), 0) does not converge
to [[ϕ(τ,ε) ]]((y|| , µ|| ), 0). This holds true for both spatial and
temporal robustness. So even if Model and Implementation
are not conformant (for a given value of (T, J, (τ, ε))), local optimization algorithms can get trapped in local minima with positive robustness. On the other hand, nonconformant trajectory pairs will necessarily have negative
robustness, so that if a Model/Implementation pair is nonconformant, all global minima of the robustness are negative, and correspond to non-conformant pairs of trajectories. Thus we need to use global optimizers, like Simulated
Annealing, Cross-Entropy [38] or other methods supported
by [6].

4.2

Degree of conformance

In addition to verifying whether two systems are (τ, ε)close for a given (τ, ε), we may find a smallest such pair
with the order defined in Def.3.3. Recall now that ϕ(τ,ε)
is monotonic in (τ, ε) (remark 3.3). The following theorem
shows that the robustness values are also monotonic in the
parameters τ, ε. The proof is in Appendix B.
Theorem 4.1. Take two TSS (y, σ) and (y0 , σ 0 ), a test
duration T , a number of jumps J, and a time t ≤ T . Consider the parallel concatenation
(y|| , σ|| ) = ((y, σ), (y0 , σ 0 ))
(i) Fix τ > 0. If 0 < ε1 ≤ ε2 , then
[[ϕ(τ,ε1 ) ]]((y|| , σ|| ), t) ≤ [[ϕ(τ,ε2 ) ]]((y|| , σ|| ), t)
(ii) Now fix ε > 0. If 0 < τ1 ≤ τ2 , then
[[ϕ(τ1 ,ε) ]]θ ((y|| , σ|| ), t) ≤ [[ϕ(τ2 ,ε) ]]θ ((y|| , σ|| ), t)
Therefore, we can combine S-TaLiRo with a binary search
over the values of τ and ε to find a smallest pair such that
ϕ(τ,ε) is satisfied. Because the order on (τ, ε) pairs is only
partial, binary search is applied to each component while
fixing the other, thus exploring the Pareto-optimal front
(e.g. [29]). Algorithm 1 shows the binary search for the
smallest ε given a τ . A search over τ can be done similarly
with obvious modifications. The initial εh can be found by
using an initial binary search that doubles some ε0 until
[[ϕ(τ,ε) ]] > 0.
The value (τ̄ , ε̄) returned by this procedure gives a quantitative measure of conformance between the two systems, and
allows the designer to make informed trade-offs between,
say, output accuracy of the Implementation, and its timing
characteristics.
Remark 4.1. For a given τ , the smallest ε such that two
trajectories (y, σ) and (y0 , σ 0 ) are (τ, ε)-close can be calculated as
εM (τ )

=

min

max

kyi − yk0 k

(10)

εI (τ )

=

min

max

kyk − yi0 k

(11)

ε(τ )

=

max{εM (τ ), εI (τ )}

i∈N |σ 0 −σi |<τ
k
i∈N |σ 0 −σi |<τ
k

(12)

1
0.8

Require: Number of iterations K, parameter τ > 0, low
value εl = 0, high value εh > 0 such that [[ϕ(τ,εh ) ]] > 0.
for i = 0 to K − 1 do
ε = 0.5 ∗ (εh + εl )
Run S-TaLiRo to falsify ϕ(τ,ε) .
if ([[ϕ(τ,ε) ]] < 0) then
εl = ε
else
εh = ε;
end if
end for
return [εl , εh ]

0.6

Implementation
Model

λ

Algorithm 1 Searching for a smallest ε given τ .

0.4

0.2

0

1

2

3

4

5

6

7

8

9

t

Implementation
Model

1.1

Fuel

1

0.9

0.8

0.7
0

1

2

3

4

5

6

7

8

9

t

Figure 5: Example 5. Close-up on the trajectories.
Speed
150

50
0

EXPERIMENTS

We illustrate the proposed approach on three systems,
including a commercial high fidelity engine model. In all experiments, we didn’t restrict the maximum number of jumps
J in a given trajectory; rather, the simulation ended only
when simulation time reached T . So below, we set J equal
to some appropriately large JM .

0

10

20

30

40

50

60

70

80

90

100

70

80

90

100

70

80

90

100

Engine Speed
6000
rpm

5.

SimuQuest
Automatic Transmission

100
mph

Similar definitions hold for the smallest τ given an ε. We
can minimize ε(τ ) over the space of TSS to determine a
smallest (τ, ε∗ (τ )) such that the two systems are (T, J, (τ, ε))closeness. The approach in Algorithm 1 has the advantage
of working not just for (T, J, (τ, ε))-closeness, but any other,
application-dependent, notion of conformance.

4000
2000
0

0

10

20

30

40

50

60

Input Signal
50
40
deg

Example 5 (Example 1 continued). We use the FC
Model and Implementation from Example 1 to illustrate the
application of Algorithm 1 to find the tightest values of τ
and ε such that (T, J, (τ, ε))-closeness is true. Because the
(τ, ε) pairs are partially ordered, we are looking for the Paretooptimal front. We decided to fix τ at 0.01, and do a search
over ε. To determine which value of ε to start the search
from, we computed the maximum relative error between the
outputs of the LUTs and the outputs of the corresponding
polynomials over a window of 85 seconds, using randomly
generated inputs. The maximum relative error was 0.4091.
Obviously, because the LUTs are deep in the system, we do
not expect the same relative error at their outputs as that
at the output of the entire system. However, this duplicates
the typical procedure for deciding how many entries to have
in an LUT: fewer levels consumes less memory and makes
for a faster computation, but causes greater error. So the
designer starts from a few entries and observes the output
of the system. If the error in the oputput is not acceptable,
entries are added to the LUT to provide a better approximation. And so on.
Figure 5 shows a close-up of the the output trajectories
from System and Implementation. Note that, as shown in
Fig. 4 for the Fuel output, the two trajectories don’t simply diverge and maintain one distance from each other, but
rather, they diverge for a period only to meet up again.
This interplay between time difference and space difference
is well-captured by (T, J, (τ, ε))-closeness.
S-TaLiRo [6] was run at each iteration of the binary
search to falsify ϕ(0.01,ε) . Algorithm 1 found an interval
ε ∈ [0.71752, 0.71832] over which the robustness varies between between −0.0029 and 0.027. That is, The two systems
are (85, JM , (0.01, ε))-close with ε ∈ [0.71752, 0.71832].

30
20
10
0

0

10

20

30

40

50
sec

60

Figure 6: Example 6. The output trajectories for the
SimuQuest and Automatic Transmission Engine models that
fail the (τ, ε)-closeness specification.

Example 6 (High fidelity engine model). Our second experiment was performed on a Model and Implementation of an automatic transmission. The transmission has
one input (throttle angle), and two outputs: the speed of the
engine ω (RPM) and the speed of the vehicle v (MPH), i.e.,
y = [ω v]T . Here too, the goal is to find a smallest (τ, ε)
such that the two are systems are (τ, ε)-close. The Model
is a slightly modified version of the Automatic Transmission
model provided by Mathworks as a Simulink demo5 . The
model is shown in Figure 3 right. It contains 69 blocks including 2 integrators, 3 look-up tables, 3 2D look-up tables
and a Stateflow chart. The Stateflow chart contains two
concurrently executing Finite State Machines with 4 and 3
states, respectively.
The Implementation is the Enginuity model of a Port Fuel
Injected spark ignition engine from Simuquest [39] with 56
states and a large number of black box components. A overview
of the components of the model is shown in Figure 3 left.
It is significantly more complex than the Model, as it mod5
Available at:
http://www.mathworks.com/products/
simulink/demos.html

Modeling an Automatic Transmission Controller

ImprellerTorque

2
RPM

Ti
Ne

1
In1

Throttle

EngineRPM
Ne

Engine

Ti

speed
gear

gear

Vehicle

up_th
CALC_TH

down_th

Tout
Nout

ShiftLogic
Transmission
down_th
up_th

OutputTorque

0
Brake

run()

gear
throttle

ThresholdCalculation

TransmissionRPM
VehicleSpeed

1
speed

Figure 3: Example 6. Left: SimuQuest Enginuity model components. Used with permission, ©SimuQuest[39]. Right:
Automatic Transmission Model.

Figure 4: Example 5. The Fuel output trajectories periodically separate from each other and converge again.
els the effects of combustion from first physics principles on
a cylinder-by-cylinder basis, while also including regression
models for particularly complex physical phenomena.
The initial conditions x0 are the initial RPM and the
initial vehicle speed, both of which must be 0. Therefore,
X0 = {[0 0]T }. This means the output trajectories depend
only on the input signal u. The throttle at each point in time
can take any value between 0 (fully closed) and 100 (fully
open). We remark that the system is deterministic, i.e., under the same input u, we will always observe the same output
y. Test duration is set to T = 104secs.
In 31 iterations, binary search found an interval of [4.8833,
4.8834], over which the spatial robustness varies between 0.00013 and 0.03. Thus the Model and Implementation are
(104, JM , (5e − 4, ε))-close with ε ∈ [4.8833, 4.8834]. In Figure 6 we present two output trajectories that fail the (τ, ε)closeness specification given the same input sequence.
Example 7. To illustrate the falsification of applicationdependent notions, we choose ϕP W C given by (9), and apply
it to the navigation benchmark Nav0 from [2]. Nav0 is a 4D
hybrid automaton with 16 modes. Its guard sets are categorized as either ‘horizontal’ or ‘vertical’. Fifteen implementations are generated by varying the continuous dynamics in
each mode (resulting in Implementations Dyn1 -Dyn9 ), and
varying the horizontal guards (resulting in Implementations
HG1 -HG3 ) and vertical guards (resulting in Implementations
VG1 -VG3 ). The variations are such that the difference between Nav0 and Dynk is smaller than the difference between
Nav0 and Dynk+1 . Similarly, the difference between Nav0
and HGk is smaller than the difference between Nav0 and
HGk+1 , and comparable to that between Nav0 and VGk .

We ran S-TaLiRo to minimize [[ϕP W C ]]θ , the temporal robustness of ϕP W C . Simulated Annealing (SA) was used as
optimizer. Since it is a stochastic algorithm, to collect statistics, we ran 20 runs of 500 tests each, and each test lasts for
T = 20 seconds. D was set to 0.5. The results are presented
in Table 1. 12 out of the 15 implementations were falsified,
i.e. found to be non-conformant to the Model. Implementations HG1−3 are robustly conformant to the Model, as their
robustness was infinite: this means that modifying the horizontal guards within the amounts prescribed by HG3 can
not affect PWC conformance. On the other hand, only one
test was sufficient to falsify ϕP W C with the vertical guard
modifications. This shows great sensitivity of the system to
the vertical guard conditions. This is useful design input, as
it tells the designers that they can trade-off horizontal guard
implementation accuracy for greater accuracy in implementing the vertical guards.

6.

RELATED WORK

Tretmans [42] defined Input-Output conformance (ioco)
as requiring that the Implementation never produces an output that can not be produced by the specification, and it is
never the case that the Implementation fails to produce an
output when the specification requires one. Both Implementation and specification are modeled as (discrete) labeled
transition systems. Van Osch [33] later extended ioco to hybrid transition systems (HTS) by incorporating continuoustime inputs. This hybrid ioco is not testable in practice
because the state space and transition relations of an HTS
are uncountable, and the test generation algorithm proposed
in [33] doesn’t contain a mechanism for judiciously choosing

Implementations
Dyn1
Dyn2
Dyn3
Dyn4
Dyn5
Dyn6
Dyn7
Dyn8
Dyn9
HG1
HG2
HG3
VG1
VG2
VG3

Nb falsifying runs
(out of 20)
17
13
18
20
20
20
20
20
20
0
0
0
20
20
20

Avg nb of tests
required for falsification
181.47
119.3
141.77
41,45
31.65
27.55
11.6
2.15
1.15
N/A
N/A
N/A
1
1
1

Avg robustness

Avg falsification time

−∞
−∞
−∞
−∞
−∞
−∞
−∞
-0.081
−∞
+∞
+∞
+∞
−∞
−∞
−∞

153.12
98.08,
117.71
33.12
24.82
21.71
8.60
1.59
0.90
N/A
N/A
N/A
0.46
0.47
0.48

Table 1: Results of minimizing [[ϕP W C ]]θ using S-TaLiRo. For each Implementation, are given the number of runs that
showed it to be non-conforming to the Model (second column), the average number of tests (or trajectories) needed before
a falsifying trajectory is found (third column), the average robustness, and the average runtime until falsification. Average
quantities are taken over the 20 runs.

tests from the infinite set of possible tests.
Later work [43] also extends [42] by treating the Implementation as a black box that generates timed traces, and
representing the specification as a timed automaton. The
objective is to verify, for each trace generated by the Implementation, whether it satisfies the invariants of the specification automaton. As such, this conformance notion does does
not address this paper’s goal of verifying ‘similarity’ between
an Implementation and its Model, which is a more comprehensive problem. The work by Brandl et al. [11] utilizes
(discrete) action systems [9] to provide a discrete view of
hybrid systems (a modeling formalism for CPS). Thus Tretmans’ ioco can be applied to the now-discrete system. This
method requires knowledge of the internal system structure,
which we do not assume in our work.
In [1], a distance between systems is also defined via a distance between trajectories. The closeness notion used there
can be shown to be weaker than (T, J, (τ, ε))-closeness, so
that proving two systems to be (T, J, (τ, ε))-close implies
they are close in the sense of [1]. In fact, (T, J, (τ, ε))closeness provides a continuum of closeness degrees between
the two extremes presented in [1].

7.

CONCLUSIONS

In this paper, we have defined conformance between a
Model and its Implementation as a degree of closeness between the outputs of the two systems. This notion is quantifiable, thus allowing us to speak of degrees of conformance,
giving a richer picture of the relation between the two systems. It is also applicable to very general system models, which allows us to study the conformance of Models
to complex Implementations. This conformance was then
expressed as an MTL formula, allowing us to use existing
falsification tools to find non-conformant behavior of Model
and Implementation, if it exists.
Because a CPS will usually have several operating modes
with different dynamics, it will be interesting in future work
to explicitly incorporate the mode switching into the MTL

formulae. Finally, a more complete theory of conformance
should also account for different time domains between the
Model’s trajectories and the Implementation’s trajectories.

8.

ACKNOWLEDGMENTS

The work presented here benefited from the input of Raymond Turin, Founder and CTO at SimuQuest, who provided
assistance in working with the SimuQuest Enginuity model.
This work was partially funded under NSF awards CNS
1116136, CNS 1319560, IIP-0856090 and the NSF I/UCRC
Center for Embedded Systems.

APPENDIX
A. MTL ROBUSTNESS
In this section, we review the robust semantics of MTL
formulas. Details on the theory and algorithms are available
in our previous work [15, 16].
Definition A.1 (MTL Syntax). Let AP be the set of
atomic propositions and I be any non-empty interval of R+ .
The set M T L of all well-formed MTL formulas is inductively
defined as ϕ ::= T | p | ¬ϕ | ϕ ∨ ϕ | ϕUI ϕ, where p ∈ AP
and T is true.
We provide semantics that map an MTL formula ϕ and
an output trajectory (y, µ) of H to a value drawn from R ∪
{±∞}. For an atomic proposition p ∈ AP , the semantics
evaluated for (yi , µi ) consists of the distance between yi and
the set O(p) labeling p. Intuitively, this distance represents
how robustly the point yi lies within (or is outside) the set
O(p). If this distance is zero, then the smallest perturbation
of the point yi can affect the outcome of yi ∈ O(p). We
denote the spatial robust valuation of the formula ϕ over the
trajectory (y, µ) at time t by [[ϕ, O]]((y, µ), t). Here t is such
that t = µi for some i ∈ N . The solution y always starts
from time µ1 = 0. Formally, [[·, ·]] : (M T L × P(H)AP ) →
(Y [0,T ] × [0, T ] → R ∪ {±∞}).

Definition A.2 (Robust Semantics). Let π = (y, µ)
be a real-TSS output of (1) and O ∈ P(H)AP , and let I be a
non-empty interval on the real line. Then the robust semantics of any formula ϕ ∈ M T L with respect to π is defined
as:
[[T, O]](π, t) := + ∞
[[p, O]](π, t) :=Dist(π(t), O(p))
[[¬ϕ1 , O]](π, t) := − [[ϕ1 , O]](π, t)
[[ϕ1 ∨ ϕ2 , O]](π, t) :=[[ϕ1 , O]](π, t) t [[ϕ2 , O]](π, t)
G
[[ϕ1 UI ϕ2 , O]](π, t) :=
([[ϕ2 , O]](π, t0 )u
t0 ∈(t+[0,T ] I)

Similarly, we can show [[p2 (τ, ε1 )]](π, t) ≤ [[p2 (τ, ε2 )]](π, t).
Thus
[[ϕ(τ,ε1 ) ]] = min{[[p1 (τ, ε1 )]](π, t), [[p2 (τ, ε1 )]](π, t)}
≤ min{[[p1 (τ, ε2 )]](π, t), [[p2 (τ, ε2 )]](π, t)} = [[ϕ(τ,ε2 ) ]]
(ii) The time parameter τ controls the numbers n(τ ) and
m(τ ), i.e. the number of shifted versions of the signals that
must be created. See (5),(6). An increase in τ can only lead
to an increase in the number of shifted versions, i.e. m(τ )
and n(τ ) are both non-decreasing in τ . Therefore m(τ1 ) ≤
m(τ2 ) and n(τ1 ) ≤ n(τ2 ). Then by the robust semantics,
[[p1 (τ1 , ε)]]θ (π, t)

ut≤t00 <t0 [[ϕ1 , O]](π, t00 )
where Dist(z, S) is the signed distance of z ∈ X from a set
S⊆X

− inf{kz − z 0 k | z 0 ∈ S}
if z 6∈ S
Dist(z, S) :=
inf{kz − z 0 k | z 0 ∈ X\S} if z ∈ S
where t +[0,T ] I = {t00 ∈ [0, T ] | ∃t0 ∈ I . t00 = t + t0 }, t
and u stand for the supremum and infimum, respectively,
and sup ∅ := −∞ and inf ∅ := +∞. The semantics of the
other operators can be defined using the above basic operators. E.g., 3I φ ≡ TUI φ and 2I φ ≡ ¬3I ¬φ.
It can be shown [15] that if the signal satisfies the property,
then its robustness is non-negative, and if the signal does not
satisfy the property, then its robustness is non-positive.
The time robust semantics differ from the above only in
the definition of the base case. Take t such that µi = t for
some i ∈ N . If we let p[t] denote the truth value of πi |= ϕ,
then
θ− (p, π, t) := p[t] · max{d ≥ 0 | d = µi − µk and
∀k ≤ q ≤ i, p[µq ] = p[t]}
θ+ (p, π, t) := p[t] · max{d ≥ 0 | d = µk − µi and
∀k ≥ q ≥ i, p[µq ] = p[t]}
[[p]]θ (π, t) = min{θ− , θ+ }
The rest of the equations above follows through unchanged.

B.

PROOF OF THEOREM 4.1

We start by proving the result for real-TSS. The extension to hybrid-TSS will then follow immediately. So start
by considering that (y, µ) and (y0 , µ0 ) are real-TSS, and for
convenience, we will use π to denote their parallel concatenation (y|| , σ|| ). Recall (5),(6), and the robust semantics of
MTL from Appendix A.
(i) Define dk = kyM,i − (Sk yI )i k, and the atomic proposition akε := dk < ε. Equation (5) can be written as
n(τ )

p1 (τ, ε) = ∨k=−n(τ ) akε
So it holds that
[[akε ]](π, t) = Dist(dk , (−ε, +ε)) = ε − dk
Thus with ε1 ≤ ε2 , [[akε1 ]](π, t) ≤ [[akε2 ]](π, t). By the robust
semantics,
[[p1 (τ, ε1 )]](π, t) = max{[[akε1 ]](π, t)}
k

≤ max{[[akε2 ]](π, t)} = [[p1 (τ, ε2 )]](π, t)
k

=

max{[[akε ]]θ (π, t) | − n(τ1 ) ≤ k ≤ n(τ1 )}

≤ max{[[akε ]]θ (π, t) | − n(τ2 ) ≤ k ≤ n(τ2 )}
=

[[p1 (τ2 , ε)]]θ (π, t)

since the maximization for τ2 is happening over a larger
set. Similarly, [[p2 (τ1 , ε)]]θ (π, t) ≤ [[p2 (τ2 , ε)]]θ (π, t). Finally,
[[ϕ(τ1 ,ε) ]]θ (π, t) ≤ [[ϕ(τ2 ,ε) ]]θ (π, t).
The extension to hybrid-TSS is straighforward: by (8),
[[Φ(τ,ε1 ) ]](π, t) = min[[ϕi(τ,ε1 ) ]](π, t)
i

≤ min[[ϕi(τ,ε2 ) ]](π, t) = [[Φ(τ,ε1 ) ]](π, t)
i

and similarly
[[Φ(τ1 ,ε) ]]θ (π, t) ≤ [[Φ(τ2 ,ε) ]]θ (π, t)

C.

REFERENCES

[1] A. Abate and M. Prandini. Approximate abstractions
of stochastic systems: A randomized method. In
Decision and Control and European Control
Conference (CDC-ECC), 2011 50th IEEE Conference
on, pages 4861–4866, 2011.
[2] H. Abbas and G. Fainekos. Linear hybrid system
falsification through local search. In Automated
Technology for Verification and Analysis, volume 6996
of LNCS, pages 503–510. Springer, 2011.
[3] H. Abbas and G. Fainekos. Convergence proofs for
simulated annealing falsification of safety properties.
In Proc. of 50th Annual Allerton Conference on
Communication, Control, and Computing. IEEE
Press, 2012.
[4] H. Abbas and G. Fainekos. Computing descent
direction of mtl robustness for non-linear systems. In
American Control Conference (ACC), pages
4411–4416, 2013.
[5] H. Abbas, G. E. Fainekos, S. Sankaranarayanan,
F. Ivancic, and A. Gupta. Probabilistic temporal logic
falsification of cyber-physical systems. ACM
Transactions on Embedded Computing Systems,
12(s2), May 2013.
[6] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and
S. Sankaranarayanan. S-taliro: A tool for temporal
logic falsification for hybrid systems. In Tools and
algorithms for the construction and analysis of
systems, volume 6605 of LNCS, pages 254–257.
Springer, 2011.
[7] A. C. Antoulas, D. C. Sorensen, and S. Gugercin. A
survey of model reduction methods for large-scale
systems. Contemporary Mathematics, 280:193–219,
2000.

[8] Atrenta. Bugscope T M . [Online at:
http://www.atrenta.com/solutions/bugscope.htm5].
[9] R. Back and K. Sere. Stepwise refinement of parallel
algorithms. Science of Computer Programming,
13(2):133–180, 1990.
[10] L. Bako, V. L. Le, F. Lauer, and G. Bloch.
Identification of MIMO switched state-space models.
In American Control Conference (ACC), 2013, pages
71–76, 2013.
[11] H. Brandl, M. Weiglhofer, and B. K. Aichernig.
Automated conformance verification of hybrid
systems. In Quality Software (QSIC), 10th
International Conference on, pages 3–12. IEEE, 2010.
[12] P. Caspi and A. Benveniste. Toward an approximation
theory for computerized control. In Embedded
Software, volume 2491 of LNCS, pages 294–304.
Springer, 2002.
[13] A. Donze and O. Maler. Robust satisfaction of
temporal logic over real-valued signals. In Formal
Modeling and Analysis of Timed Systems, volume 6246
of LNCS, pages 92–106. Springer Berlin Heidelberg,
2010.
[14] G. Fainekos. S-TaLiRo. [Online at:
https://sites.google.com/a/asu.edu/s-taliro/s-taliro].
[15] G. Fainekos and G. Pappas. Robustness of temporal
logic specifications for continuous-time signals.
Theoretical Computer Science, 410(42):4262–4291,
September 2009.
[16] G. Fainekos, S. Sankaranarayanan, K. Ueda, and
H. Yazarel. Verification of automotive control
applications using s-taliro. In Proceedings of the
American Control Conference, 2012.
[17] G. Frehse, C. L. Guernic, A. Donze, S. Cotton,
R. Ray, O. Lebeltel, R. Ripado, A. Girard, T. Dang,
and O. Maler. SpaceEx: Scalable verification of hybrid
systems. In Proceedings of the 23d CAV, 2011.
[18] A. Girard, A. Julius, and G. Pappas. Approximate
simulation relations for hybrid systems. Discrete Event
Dynamic Systems, 18(2):163–179, 2008.
[19] R. Goebel and A. Teel. Solutions to hybrid inclusions
via set and graphical convergence with stability theory
applications. Automatica, 42(4):573 – 587, 2006.
[20] L. Guzzella and C. Onder. Introduction to Modeling
and Control of Internal Combustion Engine Systems.
Springer-Verlag, 2nd edition, 2010.
[21] T. A. Henzinger, R. Majumdar, and V. S. Prabhu.
Quantifying similarities between timed systems. In
FORMATS, volume 3829 of LNCS, pages 226–241.
Springer, 2005.
[22] Z. Huang and S. Mitra. Computing bounded reach
sets from sampled simulation traces. In The 15th
International Conference on Hybrid Systems:
Computation and Control. ACM, 2012.
[23] P. James. Verification Plans: The Five-Day
Verification Strategy for Modern Hardware Verification
Languages. Kluwer Academic Publishers, 2004.
[24] X. Jin, J. Kapinski, J. V. Deshmukh, K. Ueda, and
K. Butts. Fuel control system verification benchmark
problems. In Submitted to: Hybrid Systems:
Computation and Control, 2014.
[25] K. H. Johansson, J. Lygeros, S. Sastry, and

[26]

[27]

[28]

[29]

[30]

[31]

[32]

[33]

[34]

[35]

[36]

[37]

[38]

[39]

[40]

M. Egerstedt. Simulation of hybrid zeno automata. In
Conference on Decision and Control, volume 4, pages
3538–3543, December 1999.
R. Koymans. Specifying real-time properties with
metric temporal logic. Real-Time Systems,
2(4):255–299, 1990.
A. Lecchini-Visintini, J. Lygeros, and J. Maciejowski.
Stochastic optimization on continuous domains with
finite-time guarantees by markov chain monte carlo
methods. Automatic Control, IEEE Transactions on,
55(12):2858 –2863, dec. 2010.
E. A. Lee and S. A. Seshia. Introduction to Embedded
Systems: A Cyber-Physical Systems Approach. Online
http://leeseshia.org/, 2011.
J. Legriel, C. Guernic, S. Cotton, and O. Maler.
Approximating the pareto front of multi-criteria
optimization problems. In J. Esparza and
R. Majumdar, editors, Tools and Algorithms for the
Construction and Analysis of Systems, volume 6015 of
Lecture Notes in Computer Science, pages 69–83.
Springer Berlin Heidelberg, 2010.
J. Lygeros, K. H. Johansson, S. N. Simic, J. Zhang,
and S. Sastry. Dynamical properties of hybrid
automata. IEEE Transactions on Automatic Control,
48:2–17, 2003.
O. Maler and D. Nickovic. Monitoring temporal
properties of continuous signals. In Proceedings of
FORMATS-FTRTFT, volume 3253 of LNCS, pages
152–166, 2004.
E. Mazzi, A.-S. Vincentelli, A. Balluchi, and A. Bicchi.
Hybrid system reduction. In 47th IEEE Conference on
Decision and Control, pages 227–232, 2008.
M. Osch. Hybrid input-output conformance and test
generation. In Formal Approaches to Software Testing
and Runtime Verification, volume 4262 of LNCS,
pages 70–84. Springer Berlin Heidelberg, 2006.
A. Platzer and J.-D. Quesel. KeYmaera: A hybrid
theorem prover for hybrid systems. In International
Joint Conference on Automated Reasoning, volume
5195 of LNCS, pages 171–178. Springer, 2008.
P. Roy, P. Tabuada, and R. Majumdar. Pessoa 2.0: a
controller synthesis tool for cyber-physical systems. In
Proceedings of the 14th international conference on
Hybrid systems: computation and control, pages
315–316, New York, NY, USA, 2011. ACM.
R. G. Sanfelice. Interconnections of hybrid systems:
Some challenges and recent results. Journal of
Nonlinear Systems and Applications, 2(1-2):111–121,
2011.
R. G. Sanfelice and A. R. Teel. Dynamical properties
of hybrid systems simulators. Automatica,
46(2):239–248, 2010.
S. Sankaranarayanan and G. Fainekos. Falsification of
temporal properties of hybrid systems using the
cross-entropy method. In ACM International
Conference on Hybrid Systems: Computation and
Control, 2012.
Simuquest. Enginuity.
http://www.simuquest.com/products/enginuity.
Accessed: 2013-10-04.
P. Tabuada. Verification and Control of Hybrid
Systems: A Symbolic Approach. Springer, 2009.

[41] A. Tiwari. HybridSAL relational abstracter. In
Computer Aided Verification, volume 7358 of LNCS,
pages 725–731. Springer, 2012.
[42] J. Tretmans. Testing concurrent systems: A formal
approach. In CONCUR 1999 Concurrency Theory,
pages 46–65. Springer, 1999.
[43] M. Woehrle, K. Lampka, and L. Thiele. Conformance
testing for cyber-physical systems. ACM Trans.
Embed. Comput. Syst., 11(4):84:1–84:23, Jan. 2013.
[44] T. Wongpiromsarn, U. Topcu, N. Ozay, H. Xu, and
R. M. Murray. Tulip: a software toolbox for receding
horizon temporal logic planning. In Proceedings of the
14th international conference on Hybrid systems:
computation and control, pages 313–314. ACM, 2011.

Modeling Concurrency and Reconfiguration in Vehicular
Systems: A π-calculus Approach
Joseph Campbell

Cumhur Erkan Tuncali

Theodore P. Pavlic

Georgios Fainekos

arXiv:1604.02122v1 [cs.RO] 7 Apr 2016

School of Computing, Informatics, and Decision Systems Engineering
Arizona State University, Tempe, AZ 85281, USA
{jacampb1, etuncali, tpavlic, fainekos}@asu.edu ∗

As autonomous or semi-autonomous vehicles are deployed on the roads, they will have to eventually
start communicating with each other in order to achieve increased efficiency and safety. Current approaches in the control of collaborative vehicles primarily consider homogeneous simplified vehicle
dynamics and usually ignore any communication issues. This raises an important question of how
systems without the aforementioned limiting assumptions can be modeled, analyzed and certified for
safe operation by both industry and governmental agencies. In this work, we propose a modeling
framework where communication and system reconfiguration is modeled through π-calculus expressions while the closed-loop control systems are modeled through hybrid automata. We demonstrate
how the framework can be utilized for modeling and simulation of platooning behaviors of heterogeneous vehicles.

1

Introduction

The DARPA Grand Challenges and, in particular, the Urban Challenge, demonstrated the feasibility of
fully autonomous vehicles driving in urban and rural areas. Since then, multiple well-established companies, research labs, and startups are competing towards becoming the first to sell fully autonomous
vehicles capable of driving on the same roads as human-operated vehicles. One important question that
has not yet been addressed with current research and development activities is how to enable collaboration and cooperation among the autonomous (and even semi-autonomous) vehicles.
Cooperation is essential in many practical applications of autonomous vehicles, such as platooning.
A vehicle platoon is a formation in which several vehicles closely follow each other in order to reduce
aerodynamic drag, yielding both reduced fuel consumption [25] and increased road capacity [22]. Another typical application where vehicle cooperation is required is collision avoidance at intersections [8].
In this application, when two or more vehicles approach an intersection from different directions, they
communicate directly or indirectly in order to cross the intersection without (usually) coming to a full
stop.
Prior work has tackled the challenge of vehicle cooperation by focusing on the development of control and scheduling algorithms for homogeneous vehicles with simplified dynamics. Another common
assumption in the current literature is to ignore any potential issues in the communication protocols of the
vehicular systems. Both assumptions can be very limiting when trying to utilize such control algorithms
on real networks of heterogeneous vehicles operating at high speeds.
In this paper, we develop a modeling framework for collaborating vehicular systems where both the
high-level communication protocols and the low-level complex vehicle dynamics can be modeled in the
same framework. For modeling the communication and reconfiguration layer of the system we have
∗ This

work has been partially supported by award NSF CPS 1446730.

2

Modeling Concurrency and Reconfiguration in Vehicular Systems: A π-calculus Approach

chosen the formalism of π-calculus, which was specifically developed for modeling and reasoning over
mobile communicating processes where the network structure can be modified dynamically [19]. For
closed-loop system dynamics of each vehicle, we use the modeling framework of hybrid automata [2].
The two layers communicate and synchronize through message passing.
The primary and immediate benefit of such a framework is its flexibility. Different communication
protocols can be modeled quickly in a hierarchical fashion where at the highest level we can verify correctness of the protocols. At the same time, executable code can be automatically generated for the lower
levels. For example, the proposed framework can easily incorporate verifiable privacy protocols [10] or
broadcasting protocols [23]. Similarly, different vehicles and control algorithms can be easily modeled
and simulated because hybrid automata model both the control and continuous dynamics of the vehicles
as well as any other discrete modes of operation for these vehicles (e.g., emergency braking, economy
versus sport driving mode). The main benefit of utilizing hybrid automata as a modeling framework is
that reachability analysis [12] and automated test generation [3] can be performed efficiently and effectively.
Because autonomous vehicles are safety-critical systems, the ultimate goal of this project is the requirements-based analysis of the whole system rather than of specific components (e.g., [23]) or behaviors (e.g., [1]). Namely, we envision a verification framework for heterogeneous, high-fidelity models
of collaborating vehicular systems similar to what was proposed by Damm et al. [9] for the Automatic
Train Protection system. In particular, stable and safe vehicle controllers for simplified models can be
utilized in high-fidelity vehicle models in order to be further analyzed using automated test generation
tools such as S-TA L I RO [3].
In summary, our contribution in this paper is the development of a modeling framework that can
represent complex vehicular networks. The complexity enters both in terms of vehicle dynamics and
in terms of complex communication and decision-making protocols. We show that our framework can
effectively model heterogeneous vehicular networks running a variety of control algorithms. Finally,
the proposed framework lays the groundwork in making verification of these systems both tractable and
practical.

2

Related Work

A great deal of effort has gone into proving the safety of autonomous vehicle systems. Due to the large
and diverse literature, we will present a few works that have inspired our own approach. The reader can
find further references in the literature discussed below.
Some methods, such as those by Asplund et al. [4], use formal methods to verify cooperation among
autonomous vehicles. In particular, the authors formalize a distributed coordination protocol using finite state machines, and they consider an over-approximation of the vehicles’ dynamics based on the
maximum acceleration of the vehicles. Then, they utilize Satisfiability Modulo Theory (SMT) solvers to
prove safety of an intersection collision avoidance protocol. The results cannot be generalized since they
apply only to scenarios where the intersection is a shared resource where only one vehicle has access at
each time.
Lygeros et al. [18] model platooning as a hybrid automaton, and they automatically design control
laws for provably safe merge and split vehicle operations. However, their work does not look into the
formalization of the coordination layer for the vehicles and instead treats it rather informally. Our work
can be thought of as enabling the modeling of more complicated communication and control algorithms
on top of or as an extension of the hybrid automaton models proposed by Lygeros et al. Beyond more

J. Campbell, C.E. Tuncali, T.P. Pavlic & G. Fainekos

3

complex coordination protocols that include privacy and security, we can study for example the behavior
of the platoons when there is an unexpected obstacle on the road.
More recently, Loos et al. [17] apply theorem proving methods to verify the safety of adaptive cruise
controllers. In particular, they model the case of vehicles with known bounds on important characteristics
(i.e., maximum braking deceleration, maximum acceleration, and worst-case response-time) with cruisecontrol implementations which pick an acceleration subject to a special safety condition. Under that
condition, they show that the resulting arbitrarily large group of vehicles will be collision free. A similar
result is shown by Platzer [21] for the case of vehicles entering a highway from an on-ramp, where collision-free safety can be proved under the assumption that vehicles entering the highway meet a condition
based on their position, speed, and acceleration relative to vehicles on the highway. Although it is hinted
that this framework can capture the effect of a communication-mediated reconfiguration of the vehicle
platoon, neither case explicitly models any communication nor coordination protocols between vehicles.
Platzer [21] clarifies that communication can be modeled within their framework, but shared variables
with access delays must be used as opposed to explicitly modeling communication channels that are
opened, maintained, and closed by vehicles. Furthermore, despite the expressiveness of the framework,
direct and automated synthesis of controllers that meet required specifications remains elusive.
Along another direction to this problem, Franzle et al. [11] present an extension to the Multi-Lane
Spatial Logic (MLSL) [14] by introducing a local scope for the observations of each vehicle. MLSL has
been proposed as a logical framework for reasoning about decision-making algorithms for automated
driving.
Finally, a number of works consider the verification and synthesis problem for cooperative vehicle
behaviors exclusively at the supervisory or communication level only. That is, no continuous vehicle
dynamics are explicitly considered. For example, Bochmann et al. [7] present a discrete-event controller
synthesis algorithm for lane-changing maneuvers. Bengtsson et al. [6] present a communication protocol
for enabling two platoons to merge together. The work of Kamali et al. [15] is very similar to our
proposed architecture in the sense that they also enable simulation of collaborative vehicles by utilizing
high-fidelity models at the physical level. However, the vehicle coordination protocol is modeled through
timed automata instead of mobile process calculi.

3

Preliminaries

In this paper, we model concurrent high-level behavior of autonomous vehicles with a process algebra
known as π-calculus. This section provides a brief overview of the algebra along with an extension that
is necessary to fully represent a distributed autonomous system.

3.1

Process Algebra

Process algebras, or process calculi as they are also known [5], are a way to algebraically model the interaction between concurrent systems. They are exceedingly useful for reasoning about parallel systems
and as such allow for the verification of these systems to determine whether certain properties hold. For
example, if we are considering a system of autonomous vehicles that are traveling together in a platoon,
then we would like to reason about such a system and establish that merging behavior protocols never
produce a deadlock.
To this end, we must first establish the notion of a process. Informally speaking, a process is simply
the behavior of a system [5]. Process algebra puts forward the idea that these behaviors can be modeled

4

Modeling Concurrency and Reconfiguration in Vehicular Systems: A π-calculus Approach

as a sequence of actions over time which can be manipulated with algebraic rules. As a simple example, consider an abstracted model of a process for a vehicle that is changing lanes. Given the actions,
enable signal, disable signal, change lane, and the sequential operator (.) this process can be modeled
as enable signal.change lane.disable signal. This expression means that the observed behavior is to
enable the turn signal, change lanes, and finally disable the turn signal. However, as we describe in more
detail in the following section, the real power of process algebra comes from its ability to describe the
interaction between concurrent systems.

3.2

π-Calculus

In this work, we employ a specific variant of process algebra known as π-calculus [20, 19]. In its most
basic form, π-calculus defines an expression for a process P ∈ P as a sequence atomic actions π. The
syntax of a process expression can be described by the following grammar.
P ::= π.P | 0

(1a)

Semantically, this means the process P is empty (0) and thus terminating or is composed of one or
more atomic actions π that execute in sequence and yield another process expression. Atomic actions in
π-calculus are made up of primitives known as names, which may be variables, silent actions, communication channels, or simply data values; there is no distinction between them. Given an infinite set of
names N and w, x, y, z ∈ N , three types of actions are defined. Namely,
• Unobservable actions occur when the effect of execution is unknown to the π-calculus process.
For example, P = w.x.P0 defines P as executing w and x sequentially and in order, which results in
the process P0 . Note that this resulting process can also be P itself for recursion, as in P = w.x.P.
Alternatively, if the process terminates after the execution of w and x then it will be defined as
P = w.x.0. For the sake of brevity, a terminating process typically excludes the .0 postfix.
• Outgoing communication occurs when a name is sent along out over a channel. The expression P =
x<y> defines P as sending the name y out over x. In this example, x represents a communication
channel to another process, and P is sending the message y over that channel.
• Incoming communication occurs when a name is received along a channel. The expression P =
x(z) defines P as receiving the name z from x. Similar to the previous example, x represents a
communication channel to another process, and P receives a message on that channel which gets
bound to the name z.
In addition, process expressions may take a parametric form. For example, P(x) = x<y> is a parametric
definition of process P. When P is referenced, it must be passed a name. If we have the expression
w(z).P(z), a message is received over channel w that gets bound to z and is then passed to P. In this
context, z must be another communication channel itself because P immediately uses it to send message
y. This ability to transmit and receive communication channels is an important concept in π-calculus and
is referred to as mobility.
We now introduce more complex constructs into the syntax, as summarized by the following grammar.
P ::= P | P||P0 | P + P0 | !P0

(1b)
0

P ::= P | (νx)P | x : [y ⇒ P, z ⇒ P ]
These constructs support the modeling of multiple processes. In particular,

(1c)

J. Campbell, C.E. Tuncali, T.P. Pavlic & G. Fainekos

5

• P = P||P0 defines the process P as concurrently executing P and P0 .
• P = P + P0 defines the process P as non-deterministically executing either P or P0 .
• P =!P0 indicates that there are (potentially) an infinite number of copies of P0 executing concurrently. This is equivalent to P = P0 ||P. For an actual system, an infinite number of copies is not
possible, and so this represents as many concurrently executing copies as desired.
• (νx)P indicates the name x is unique to P.
• P = x : [y ⇒ P, z ⇒ P0 ] defines the process P as resulting in P if the name x is equal to y, or resulting
in P0 if x is equal to z. Names can also be constants, and so it is possible define P = x : [True ⇒
P, False ⇒ P0 ] for evaluating against True and False.
Now that the syntax and an informal explanation of the semantics for concurrent processes have been
introduced, the concept of reaction must be discussed. Just as there are unobservable actions, there are
also observable actions. Consider two processes, P = w.P0 and Q = w.Q0 , and suppose they are running
concurrently, P||Q. The names w and w are considered complementary, and the actions are linked; if w
is executed, then w will also be executed. This is why we say the actions are observable: the effect of
executing w is observed by the π-calculus rules as it causes w to also execute. The similarity in syntax
between observable actions and communication actions is no coincidence, as communication actions are
observable actions. For a formal analysis of reactions, refer to Milner [19].
This highlights the importance of the scope restriction operator, ν. Let P(x) = x<y>, Q(x) = x(z),
and R(x) = x(w). If the processes run concurrently as in P(x)||Q(x)||R(x) then there are two outcomes:
either Q receives the message sent by P or R does. This is a consequence of all three processes sharing
the same x channel. However, if x is now restricted as in (νx)(P(x)||Q(x))||R(x) then there is only one
outcome: Q receives the message sent by P along their shared (and unique) channel x, and R will receive
another message on a different channel x from an unobserved process.

3.3 ω-Calculus
This work also makes use of ω-calculus, an extension to π-calculus that introduces semantics for reasoning about mobile ad hoc wireless networks [23]. It is a particularly useful extension when dealing with
distributed robotic systems that must form ad hoc networks in order to establish communication. In this
work, two particular operations from ω-calculus are important:
• b<x> broadcasts the message x to any recipient in transmission range.
• r(y) receives a message that has been broadcasted and binds it to y.

4

Methodology

As previously discussed, autonomous vehicle platoons are a tantalizing goal due to the inherent benefits
they bring in the form of increased road capacity and reduced energy usage [25, 22]. However, designing
such a system is not a simple endeavor. In order to scale effectively over a large number of vehicles, this
distributed platoon system should have decentralized control. Additionally, the benefits and stability of a
platoon are increased if the vehicles remain in communication with each other [18]. As autonomous vehicles are safety-critical systems, the behavior that governs any such vehicle platoon must be verified to
ensure no unforeseen dangerous scenarios can arise. Further complicating matters, autonomous vehicles
are not homogeneous systems; each vehicle will have varying physical characteristics. Our work tackles

6

Modeling Concurrency and Reconfiguration in Vehicular Systems: A π-calculus Approach

Supervisor A
(π-calculus)

Supervisor B
(π-calculus)

Interface

Interface

Comm

Control

Comm

Plant

Control

Plant

Figure 1: Organization of two concurrent vehicle processes.

A

A
C

d

B

(a) Initial A–B spacing

l C

2d+l
B

(b) After space is created for C

Figure 2: Expected spacing behavior of vehicle convoy.
these issues by dividing the problem into two non-overlapping parts: a high-level discrete-logic layer
that describes the overall behavior of the autonomous vehicles, and a low-level physical layer that describes the closed-loop dynamics of the underlying system. Interaction occurs in the form of an interface
provided by the low-level layer through which the high-level layer can send signals. This organization is
shown in Fig. 1. The following sections describe these layers in more detail.

4.1

High-level Layer

The high-level layer must be capable of satisfying three conditions: it must be able to model the protocols
of a distributed multi-vehicle system, it must be able to model communication between vehicles, and it
must be amenable to verification processes for safety-critical systems. As it turns out, π-calculus meets
these three conditions and is used to model the high-level behavior in this work. First, however, we must
establish the expected platoon behavior.
Figure 2a depicts a simple platoon of two vehicles. The vehicle labeled A is the leader of this platoon
and the vehicle labeled B is following A at a minimum safe distance d. A third vehicle, C, is outside of
the platoon in a separate lane. Suppose C wishes to join the platoon and that the optimal place to do so
is between A and B. Before C is permitted to join, the distance between A and B must be increased to

J. Campbell, C.E. Tuncali, T.P. Pavlic & G. Fainekos

7

2d + l, where l is the length of C as shown in Fig. 2b. This action ensures that the minimum safe distance
is always respected. This behavior can be further simplified by letting C follow A at distance of d while
B also follows C at a distance of d, making explicit knowledge of l unnecessary.
In this work, we define separate behaviors for three different scenarios: a leader of a platoon (Leader),
a follower in a platoon (Follower), and a vehicle joining a platoon (Joiner). These are the behaviors
exhibited by vehicles A, B, and C, respectively, in Fig. 2. It is also possible for vehicles to transition
between behaviors. For example, a vehicle joining a platoon will become a Follower once it has fully
merged. At the highest level, the system modeled in Fig. 2 can be represented as a π-calculus expression.
Let A = Leader, B = Follower, and C = Joiner. This system is then described by A||B||C. Each of these
behaviors will now be described in terms of a π-calculus expression.
In Section 4, it was stated that an interface layer is utilized by the behaviors to exert control over
the underlying continuous system. The interface layer represents the unobservable actions that can be
called by a π-calculus process expression. Although these actions are considered atomic to π-calculus
expressions, this will not be the case with respect to the low-level continuous layer. In particular, some
actions take considerable time to execute and may wait until certain conditions unknown to the highlevel layer are satisfied. The following unobservable actions are provided in the interface layer.
• get id gets the identification of the vehicle. If B in Fig. 2a calls get id, it will return B.
• get ldr gets the leader of the vehicle. As an example, if B in Fig. 2a calls get ldr, it will return A.
• set ldr sets the leader of the vehicle to the vehicle with the given identification.
• drive tells the vehicle to drive forward with respect to the road geometry.
• keep dist maintains a safe following distance d from the current leader.
• check join checks whether the vehicle with the given identification occupies the position where
this vehicle wants to join. For example, if C in Fig. 2a invokes check join on B, it will return
positive.
• align start causes the interface to trigger the align done event action when the vehicle is d distance
from the current leader.
• merge start causes the interface to trigger the merge done event action when the vehicle has finished merging into the current leader’s lane.
Additionally, recursive expressions are only allowed to execute at most once per sampling period.
The behavior descriptions that follow refer to the system depicted in Fig. 3. A, B, and C are initially
in a platoon of which A is the Leader and B and C are Followers. D is a Joiner external to the platoon.
4.1.1

Leader

The behavior of a platoon Leader is straightforward in this scenario: it simply drives forward indefinitely.
The associated process expression in Algorithm 1 invokes the atomic action drive and repeats this action
indefinitely.
Algorithm 1 Leader
1:

Leader= drive.Leader

8

Modeling Concurrency and Reconfiguration in Vehicular Systems: A π-calculus Approach

A
d

D

A

A
d

B

d

C

d

d
D

d

B

B
d

A

C

B

d

d

D

D
d

d

C
(a) Initial state

(b) Joiner D in position

(c) Distance created

C
(d) Merge complete

Figure 3: Expected merge behavior of vehicle platoon.
4.1.2

Follower

The behavior of a Follower in a platoon is much more involved as it must simultaneously follow its
leader while cooperating with vehicles who wish to join the platoon. This is modeled by the concurrent
execution of Follow and Cooperate in the Follower state in Algorithm 2, which corresponds with the
initial state in Fig. 3a. Just as Leader in Algorithm 1 is an infinitely repeating call to the atomic action
drive, Follow is an indefinitely repeating call to the atomic action keep dist.
Algorithm 2 Follower
1:
2:
3:
4:
5:
6:
7:
8:
9:

Wait(y) = y.merge done
Align(y) = align start.align done.y.Wait
Rcv Ldr(y, ldr) = y(nldr).set ldr<nldr>.Align(y)
Send Ldr(y) = get ldr(ldr).y<ldr>.Rcv Ldr(y, ldr)
Respond(y, f lag) = f lag : [True ⇒ Send Ldr(y)]
Ident(y) = get id(id).y<id>.y( f lag).Respond(y, f lag)
Cooperate=!r(x).(νy)(x<y>.Ident(y))
Follow= keep dist.Follow
Follower= Follow||Cooperate

Cooperate (Line 7 in Algorithm 2) makes use of π-calculus’s special notion of mobility, which allows
us to reconfigure the communication network between vehicles and reason about it. When a vehicle
wishes to join a platoon, it creates a communication channel x and broadcasts it to every vehicle within
range in Line 8 of Algorithm 3. This establishes a communication channel between the Joiner and every
Follower as shown in Fig. 4a. However, a unique communication channel is desired between the Joiner
and each Follower, so the first thing a Follower does upon receiving channel x is to create a new unique
channel y and send that to the Joiner in Line 7 of Algorithm 2. This results in a reconfiguration of
the network as shown in Fig. 4b. Eventually, the Joiner will decide where to merge in the platoon and
will drop all communication channels except to the vehicle that will follow the Joiner, resulting in the
final network shown in Fig. 4c. It is possible to expand these interactions and establish a multi-hop
communication network between a vehicle and its immediate peers when it joins the platoon, however,

J. Campbell, C.E. Tuncali, T.P. Pavlic & G. Fainekos

9

A

D

x

B

A

D

y1

B

y2

x
C
(a) During Cooperate

A

D

B
y2

C
(b) After Cooperate

C
(c) After Respond

Figure 4: Process graph depicting communication network during various points of execution. Cooperate
and Respond refer to Lines 7 and 5 of Algorithm 2 respectively. A, B, C, and D correspond to the vehicles
in Fig. 3.
this is not examined in this work.
Once a unique communication channel is established between the joining vehicle and each Follower
as in Fig. 4b, it is used to synchronize the joining process. In Line 6 of Algorithm 2, the Follower transmits its own identifier to the joining vehicle via y so that it can decide whether to join at the Follower’s
position. Once a reply is received and bound to f lag, the Respond state (Line 5) will either continue to
Send Ldr if f lag is True or terminate otherwise. If f lag is True, the joining vehicle intends to join the
platoon at the Follower’s location. Before this can happen, the joining vehicle must position itself next to
the Follower so that it is ready to merge over as shown in Fig. 3b. In order to facilitate this, the Follower
transmits its current leader, ldr, to the joining vehicle.
When the joining vehicle is in position, it responds to the Follower with its own identifier, nldr, so
that the Follower can set the joining vehicle as its new leader in the Rcv Ldr state. After setting the
joining vehicle as its new leader, the Follower increases its distance to d from the joining vehicle due to
the concurrently executing Follow state. In the Wait state, the Follower waits until the distance between
it and the joining vehicle reaches d with the atomic action wait dist. This is depicted in Fig. 3c. Lastly,
the joining vehicle is signaled to merge, which results in Fig. 3d.
4.1.3

Joiner

The behavior of a Joiner is given in Algorithm 3. Until a decision to join is made by the high-level layer,
the joining vehicle drives forward with respect to the road geometry just like a Leader. The one novel
detail beyond the previous description is that the Joiner behavior transitions to a Follower as the last
action in the Merge state.

4.2

Low-level Layer

The low-level layer can be modeled as a series of hybrid automata [2] in order to describe the behavior of
the controller and plant from Fig. 1. Each behavior – Leader, Follower, and Joiner – has its own hybrid

10

Modeling Concurrency and Reconfiguration in Vehicular Systems: A π-calculus Approach

Algorithm 3 Joiner
1:
2:
3:
4:
5:
6:
7:
8:

Merge(y) = merge start.merge done.y.Follower
Wait(y) = get id(id).y<id>.y.Merge
Align(y) = align start.align done.Wait(y)
Rcv Ldr(y) = y(ldr).set ldr(ldr).Align(y)
Ans(y, ok) = y<ok>.ok : [T ⇒ Rcv Ldr(y)]
Check(y, id) = (νz)( join ok<z, id>.z(ok).Ans(y, ok))
Listen(x) = x(y).y(id).Check(y, id)
Joiner= (νx)(b<x>||!Listen(x))

Follow
L := ldr

ẏ = fx (x, distx (t, L))
ẏ = fy (y, disty (t, L))
align start/L0 := ldr, L := nldr

merge done/

Drive

MergeStart

ẋ = gx (x)
ẏ = gy (y)

ẋ = fx (x, distx (t, L))
ẏ = fy (y, disty (t, L0 ))

|distx (t, L) − dx | < εx /align done

(a) Leader HA

ẋ = fx (x, distx (t, L))
ẏ = fy (y, disty (t, L0 ))

(b) Follower HA

Drive

InitiateJoin
align start/L := ldr

ẋ = gx (x)
ẏ = gy (y)

MakeSpace

|distx (t, L) − dx | < εx /align done

ẋ = fx (x, distx (t, L))
ẏ = gy (y)

WaitForSpace
ẋ = fx (x, distx (t, L))
ẏ = gy (y)

merge start/

|disty (t, L) − dy | < εy /merge done
Follower

Merge
ẋ = fx (x, distx (t, L))
ẏ = fy (y, disty (t, L))

(c) Joiner HA

Figure 5: Hybrid automata for the low-level layer. Each automata receives input signals from the highlevel layer and sends output signals. (a) No inputs/outputs. (b) Inputs: align start, merge done Outputs:
align done (c) Inputs: align start, merge start Outputs: align done, merge done

J. Campbell, C.E. Tuncali, T.P. Pavlic & G. Fainekos

11

automata as shown in Fig. 5. Interaction with the high-level layer takes place in the form of input and
output signals that directly correspond to unobservable actions provided by the interface in Section 4.
We now formally define these signals with respect to the hybrid automata. Let N denote the set of natural
numbers, then we define:
S1 : {align start, align done} → {absent, present}
S2 : {merge start, merge done} → {absent, present}
S3 : {L, L0 } → N
Additionally, the following functions are defined. Let the x-axis lie parallel to the front of the vehicle
and the y-axis lie perpendicular to that.
• gy (y)/gx (x) computes ẏ/ẋ given the current y/x position while taking into account road geometry.
In most cases, this is equivalent to driving forward at a constant velocity.
• fy (y, α)/ fx (x, α) computes ẏ/ẋ given the current y/x position and a distance α with the objective
of reducing α to the minimum safe following distance d.
• distx (t, L) returns the distance along the x-axis to vehicle L at time t.
• disty (t, L) returns the distance along the y-axis to the center of the lane currently occupied by
vehicle L at time t. Currently platoons are not allowed to switch lanes so that discontinuities in
this distance are avoided.
With these signals and functions, we can define each of the vehicle behaviors.
4.2.1

Leader

The Leader automata simply remains in a drive state. No transitions are supported and no input or output
signals are accepted.
4.2.2

Follower

The Follower automata requires the input signal align start to create longitudinal space in front of the
vehicle when a merge has been requested. This is accomplished by a change in leader L, which coincides
with a set ldr call in the high-level layer. However, only fy respects the change in leader; fx continues
to be a function of the previous leader, L0 . This is so the vehicle does not sway in its lane attempting to
position itself laterally behind a vehicle that is changing lanes. When the merge done signal is received,
L is respected on both axes.
4.2.3

Joiner

Similarly, the Joiner automata requires the input signal align start to position itself behind the vehicle it
will be following once the merge is completed. However, the x-axis does not respect its new leader, L,
until the merge start signal is received – indicating that the Follower vehicle is finished aligning itself to
this vehicle.
In practice, these automata are implemented as digital controllers that receive input signals from
the high-level layer via an interface as described in Section 4.1. The advantage of this setup is that
the controllers and vehicle dynamics can be swapped out for any implementation as long as it fulfills
the required interface. As an illustrative example, consider a scenario in which the high-level behavior

12

Modeling Concurrency and Reconfiguration in Vehicular Systems: A π-calculus Approach

(a) Initial state

(b) Joiner in position

(c) Distance created

(d) Merge complete

Figure 6: Actual merge behavior of vehicle platoon.
described in the previous section has been adopted as an automobile industry standard. Each vehicle
manufacturer can then supply a low-level layer for controlling its vehicle without having to re-verify the
behavior protocol.

5

Experiments

Simulation is an important step in the analysis and verification of autonomous vehicle platoons, as the
closed-loop dynamics are a fundamental part of the system. Without simulation, the dynamics are not
validated, and much of the problem is left unsolved. To that end, we have developed a simulation
framework which ties together the high-level and low-level layers discussed in this paper and places them
in control of automobiles in the Webots 8.3 robotics simulator [24]. Two types of instances were tested:
a homogeneous platoon consisting of vehicles with identical physical characteristics and controllers, and
a heterogeneous platoon with varying physical characteristics and differing controllers. The behavior of
vehicles in these simulations is shown in Fig. 6.

5.1

Homogeneous Platoon

In the first experimental simulation scenario, four independent vehicles attempted to join a five-vehicle
platoon. All automobiles were modeled after the Toyota Prius (model included in Webots) with identical
physical characteristics and identical manually tuned PID controllers. The controllers generate throttle
and brake inputs for the plant (simulated vehicle) and track a target following distance from the vehicle
which is being followed. The controllers are not meant to be robust nor optimal, rather they are a simple
example of how this framework can be used to control continuous systems. Localization is achieved by
means of each vehicle broadcasting out its current position at every simulation step. While not practical
in the real world, this is adequate for this simulation as accurately identifying other vehicles and their
positions is a challenging task. The distance functions, distx and disty , make use of these broadcasted
positions in addition to a forward-facing laser sensor for redundancy. All vehicles eventually successfully
merge into the platoon in a distributed and decentralized manner.

5.2

Heterogeneous Platoon

The second experimental scenario again consisted of four independent vehicles attempting to join a fivevehicle platoon; however, this time the vehicles were of varying models (included in Webots). Four auto-

J. Campbell, C.E. Tuncali, T.P. Pavlic & G. Fainekos

13

mobiles were modeled after the BMW X5, three after the Citroen C-Zero, and two after the Toyota Prius.
Additionally, three of the vehicles used the PID controller from the homogeneous platoon experiment
while the remaining six used a model predictive controller designed for such scenarios with some minor
modifications [16]. We vary the reference velocity based on the current tracking error, which is similar
to previous work [13]. In addition we modify the cost parameters, Q and R of the controller, so that the
weight given to the reference velocity and distance varies based on the error. Once again, all vehicles
successfully merged into the platoon without incident.
However, similar to the PID controller in the first experimental simulation, this model predictive
controller is not meant to be optimal nor even provide guarantees of stability. Rather its primary purpose
is to show that our framework can not only effectively represent interactions between heterogeneous
vehicles, but that those vehicles can use dramatically different control schemes.

6

Conclusions

In this paper, we have introduced a new framework which utilizes π-calculus to model complex vehicular
networks. This framework allows for the effective modeling of both high-level decision-making protocols and low-level vehicle dynamics, laying the groundwork for future verification of these systems. In
order to demonstrate the utility of this framework, we have modeled a decentralized platooning protocol
with heterogeneous vehicles and controllers. In future work, we will formally verify complex systems
modeled with this framework.

References
[1] Matthias Althoff, Daniel Althoff, Dirk Wollherr & Martin Buss (2010): Safety Verification of Autonomous
Vehicles for Coordinated Evasive Maneuvers. In: IEEE Intelligent Vehicles Symposium.
[2] Rajeev Alur (2015): Principles of Cyber-Physical Systems. MIT Press.
[3] Yashwanth Singh Rahul Annapureddy, Che Liu, Georgios E. Fainekos & Sriram Sankaranarayanan (2011):
S-TaLiRo: A Tool for Temporal Logic Falsification for Hybrid Systems. In: Tools and Algorithms for the
Construction and Analysis of Systems, LNCS 6605, Springer, pp. 254–257.
[4] Mikael Asplund, Atif Manzoor, Mélanie Bouroche, Siobhan Clarke & Vinny Cahill (2012): A formal approach to autonomous vehicle coordination. In: FM 2012: Formal Methods, Springer, pp. 52–67.
[5] Jos CM Baeten (2005): A brief history of process algebra. Theoretical Computer Science 335(2), pp. 131–
146.
[6] Hoai Hoang Bengtsson, Lei Chen, Alexey Voronov & Cristofer Englund (2015): Interaction Protocol for
Highway Platoon Merge. In: Proceedings of the 2015 IEEE 18th International Conference on Intelligent
Transportation Systems, IEEE, pp. 1971–1976.
[7] Gregor v Bochmann, Martin Hilscher, Sven Linker & Ernst-Rüdiger Olderog (2015): Synthesizing Controllers for Multi-lane Traffic Maneuvers. In: Dependable Software Engineering: Theories, Tools, and Applications, Springer, pp. 71–86.
[8] A. Colombo & D. Del Vecchio (2012): Efficient algorithms for collision avoidance at intersections. In:
Proceedings of the 15th ACM International Conference on Hybrid Systems: Computation and Control.
[9] Werner Damm, Alfred Mikschl, Jens Oehlerking, Ernst-Rüdiger Olderog, Jun Pang, André Platzer, Marc
Segelken & Boris Wirtz (2007): Automating Verification of Cooperation, Control, and Design in Traffic
Applications. In Cliff B. Jones, Zhiming Liu & Jim Woodcock, editors: Formal Methods and Hybrid RealTime Systems, LNCS 4700, Springer, pp. 115–169.

14

Modeling Concurrency and Reconfiguration in Vehicular Systems: A π-calculus Approach

[10] Stéphanie Delaune, Mark Ryan & Ben Smyth (2008): Automatic Verification of Privacy Properties in the
Applied pi Calculus. In Yücel Karabulut, John Mitchell, Peter Herrmann & Christian Damsgaard Jensen,
editors: Trust Management II, IFIP 263, Springer, pp. 263–278.
[11] Martin Fränzle, Michael R Hansen & Heinrich Ody (2015): No Need Knowing Numerous Neighbours. In:
Correct System Design, Springer, pp. 152–171.
[12] Goran Frehse, Colas Le Guernic, Alexandre Donz, Scott Cotton, Rajarshi Ray, Olivier Lebeltel, Rodolfo Ripado, Antoine Girard, Thao Dang & Oded Maler (2011): SpaceEx: Scalable Verification of Hybrid Systems.
In: Proceedings of the 23rd International Conference on Computer Aided Verification.
[13] Datta N Godbole & John Lygeros (1994): Longitudinal control of the lead car of a platoon. Vehicular
Technology, IEEE Transactions on 43(4), pp. 1125–1135.
[14] Martin Hilscher, Sven Linker, Ernst-Rüdiger Olderog & Anders P Ravn (2011): An abstract model for proving safety of multi-lane traffic manoeuvres. In: Formal Methods and Software Engineering, Springer, pp.
404–419.
[15] Maryam Kamali, Louise A Dennis, Owen McAree, Michael Fisher & Sandor M Veres (2016): Formal Verification of Autonomous Vehicle Platooning. arXiv preprint arXiv:1602.01718.
[16] Peng Liu & Umit Ozguner (2015): Predictive control of a vehicle convoy considering lane change behavior
of the preceding vehicle. In: Proceedings of the 2015 American Control Conference, IEEE, pp. 4374–4379.
[17] Sarah M Loos, André Platzer & Ligia Nistor (2011): Adaptive cruise control: Hybrid, distributed, and now
formally verified. In: FM 2011: Formal Methods, Springer, pp. 42–56.
[18] John Lygeros, Datta N Godbole & Shankar Sastry (1998): Verified hybrid controllers for automated vehicles.
IEEE Transactions on Automatic Control 43(4), pp. 522–539.
[19] Robin Milner (1999): Communicating and Mobile Systems: the π Calculus. Cambridge University Press.
[20] Robin Milner, Joachim Parrow & David Walker (1992): A calculus of mobile processes, I. Information and
Computation 100(1), pp. 1–40.
[21] André Platzer (2012): A Complete Axiomatization of Quantified Differential Dynamic Logic for Distributed
Hybrid Systems. Logical Methods in Computer Science 8(4):17, doi:10.2168/LMCS-8(4:17)2012.
[22] BSY Rao & Pravin Varaiya (1993): Flow benefits of autonomous intelligent cruise control in mixed manual
and automated traffic. In: Intelligent Vehicle Highway Systems, 1408, National Academy Press, pp. 36–43.
[23] Anu Singh, CR Ramakrishnan & Scott A Smolka (2010): A process calculus for mobile ad hoc networks.
Science of Computer Programming 75(6), pp. 440–469.
[24] Webots: http://www.cyberbotics.com. Available at http://www.cyberbotics.com. Commercial Mobile
Robot Simulation Software.
[25] Michael Zabat, Nick Stabile, Stefano Farascaroli & Frederick Browand (1995): The Aerodynamic Performance of Platoons: A Final Report. Technical Report UCB-ITS-PRR-95-35, California Partners for Advanced Transit and Highways (PATH).

The Workshops of the Thirtieth AAAI Conference on Artificial Intelligence
Planning for Hybrid Systems: Technical Report WS-16-12

Planning in Dynamic Environments
Through Temporal Logic Monitoring
Bardh Hoxha and Georgios Fainekos
Arizona State University
660 W 6th St, STE 203
Tempe, AZ 85281
{bhoxha, fainekos}@asu.edu
Abstract

2009; Kloetzer and Belta 2007), the authors convert Linear Temporal Logic (LTL) specifications to Büchi automata
and create abstraction models for the dynamical systems.
Then they utilize automata-based methods to synthesize
controllers. One of the main challenges with this approach
are the increasing computational costs due to both the length
of the specification and the level of abstraction of the dynamical system. Other varieties of Temporal Logic such as MTL
have been also utilized in planning. In (Kabanza 1995), the
author uses MTL to create synchronized plans for teams of
agents. In (Karaman and Frazzoli 2008b), the authors consider the vehicle routing problem with MTL specifications.
In (Ding, Lazar, and Belta 2014), for online planning, the
authors present an approach for receding horizon control for
finite deterministic systems subject to LTL formulas. In (Raman et al. 2014), the authors present a method for developing model predictive controllers for systems that can be represented as a mixed integer-linear program. The controller
is developed subject to Signal Temporal Logic (Maler and
Nickovic 2004) specifications.
In this work, we consider the online planning problem for
dynamic environments where both the environment and mission may change. Furthermore, MTL enables the specification of time bounds for temporal operators and thus the definition of more elaborate specifications. Our planning framework utilizes the notion of robustness of MTL specifications
(Fainekos and Pappas 2006; 2009), with a bounded-time
monitoring algorithm (Dokhanchi, Hoxha, and Fainekos
2014), to enable online planning for dynamic environments.
Finally, we illustrate our framework with Matlab Simulink
using a car-like model from the Robotics toolbox (Corke
2011) with various MTL specifications.
Summary of Contributions: We present an online planning problem for robotic systems where the environment
is dynamically changing and mission compliance specifications may be updated. To the authors knowledge, this is
the first attempt to include specification updates in an online
planning problem for dynamically changing environments.
In the following, we provide an overview of our solution
and the planning framework. We illustrate the approach using an example of a car-like model with a number of MTL
specifications.
Acknowledgments: This work has been partially supported by award NSF CNS 1446730.

We present a framework that enables online planning for
robotic systems in dynamic environments. The PLANrm
framework presented in this work utilizes the theory of robustness and monitoring of Metric Temporal Logic (MTL)
specifications to inspect and modify available plans to both
avoid obstacles and satisfy specifications in a dynamic environment. The use of MTL allows the practitioner to set complex event and timing based specifications that need to be
satisfied in the execution of the plan. The monitoring algorithm inspects the possible paths in a bounded window and
selects and adjusts a path to satisfy the specifications. In this
paper, we present initial results on the framework and an extended summary of the algorithmic results. The approach is
illustrated using a running example of a car-like model with
a number of MTL specifications.

Introduction
The problem of motion planning has been researched extensively in the past few decades. As a result, robotic systems
have been successfully deployed in a variety of fields, from
disaster response and recovery to autonomous warehouse
systems, autonomous driving and industrial manufacturing.
In general, the operating environment is dynamic, where
new obstacles may appear, or the mission may change.
To support planning for such environments, we propose
the PLANrm framework that incorporates a Metric Temporal Logic (MTL) (Koymans 1990) monitoring algorithm
(Dokhanchi, Hoxha, and Fainekos 2014) that inspects possible plans in a bounded time window and selects a path that
satisfies changing MTL specifications.
MTL is a formal language which enables practitioners to
express complex specifications that take into account both
the occurrence and timing of events through time. It enables
the definition of specifications such as ”if you pass through
region A within a five second period, then visit region B
while avoiding region C” or ”always visit the refueling region R before visiting region B”.
Temporal Logic has been previously utilized to synthesize controllers for motion-planning of dynamical systems.
In (Fainekos, Kress-Gazit, and Pappas 2005; Fainekos et al.
c 2016, Association for the Advancement of Artificial
Copyright 
Intelligence (www.aaai.org). All rights reserved.

601

Preliminaries

falsified) for a particular system output trajectory. In the following, we use the notation [[ϕ]] to denote the robustness estimate with which µ satisfies the specification ϕ. In addition
to the boolean semantics, the robustness measure ρ defines
how robustly µ satisfies or falsifies ϕ.
Formally, we define the robust semantics of MTL<+∞
+pt as
follows. Using a metric d (Seda and Hitzler 2008), we can
define a distance function that captures how far away a point
x ∈ X is from a set S ⊆ X.

Metric Temporal Logic
Metric Temporal Logic (Koymans 1990) enables reasoning
over quantitative timing properties of boolean signals. In this
paper, we use the standard fragment of MTL with bounded
future, but also we allow the use of past time operators. In
the following, we assume we a constant sampling rate for
the robot and thus any specification on time reduces to a
specification on sampling points.
Definition 1 (MTL<+∞
+pt Syntax) Let AP be the set of atomic
propositions and I be any non-empty interval of N, and I
be any non-empty interval of N ∪ {+∞}. The set MTL<+∞
+pt
formulas is inductively defined as

Definition 2 (Signed Distance) Let x ∈ X be a point, S ⊆
X be a set and d be a metric. Then, we define the Signed
Distance from x to S to be
(

ϕ ::= > | p | ¬ϕ | ψ ∨ ϕ | ψUI ϕ | ψSI ϕ

Distd (x, S ) :=

where p ∈ AP and > stands for true.

Using Definition 2, we provide the formal definition for
the robustness semantics.
Definition 3 (MTL<+∞
+pt Robustness Semantics) Let s be a
trace s : N → X, and O be an observation map O : AP →
P(X), then the robust semantics of any formula ϕ ∈ MTL<+∞
+pt
with respect to s is recursively defined as:

 (Next) as ϕ ≡ >U[1,1] ϕ
^ (Eventually) as ^I ϕ ≡ >UI ϕ
 (Always) as I ϕ ≡ ¬^I ¬ϕ
The intuitive meaning of the ψU[a,b] ϕ operator at sampling
time i is a follows: ψ has to hold at least until ϕ becomes true
within the time interval of [i + a, i + b] in the future.
Past operators:

[[>]](s, i) := +∞
[[p]](s, i) := Distd (s(i), O(p))
~¬ϕ(s, i) := −~ϕ(s, i)
~ψ ∨ ϕ(s, i) := ~ψ(s, i) t ~ϕ(s, i)

 j−1
Gi+u 
~ψU[l,u] ϕ(s, i) :=
~ϕ(s, j) u
~ψ(s, k)

 (Previous) as ϕ ≡ >S[1,1] ϕ
 (Eventually in the past) as I ϕ ≡ >SI ϕ
Iϕ

if x < S
if x ∈ S

where inf is the infimum.

The propositional operators conjunction (∧) and implication (→) are defined the usual way. Other temporal operators
are defined as follows.
Future operators:

(Always in the past) as

− inf{d(x, y) | y ∈ S }
inf{d(x, y) | y ∈ X\S }

j=i+l

≡ ¬I ¬ϕ

~ψS[l0 ,u0 i ϕ(s, i) :=
Gi−l0

The intuitive meaning of the ψS[a,b] ϕ operator at sampling
time i is as follows: since ϕ became true in the past interval
[i − b, i − a], ψ must hold till now (current time i).
The atomic propositions in our case label subsets of the
output space Y. Each atomic proposition is a shorthand for
an arithmetic expression of the form p ≡ g(y) ≤ c, where
g : Y → R and c ∈ R. We define an observation map O :
AP → P(Y) such that for each p ∈ AP the corresponding
set is O(p) = {y | g(y) ≤ c} ⊆ Y.

j=max{0,i−u0 }

k=i


~ϕ(s, j) u

i
k= j+1


~ψ(s, k)

where t stands for max, u stands for min, p ∈ AP, l, u, l0 ∈ N
and u0 ∈ N ∪ {∞}. Furthermore, the symbol i in S[l0 ,u0 i will
be ) when u0 = +∞ and ] when u0 , +∞.

Monitoring of MTL<+∞
+pt Formulas

Robustness of MTL<+∞
+pt Formulas

The monitoring algorithm, formally presented in
(Dokhanchi, Hoxha, and Fainekos 2014), enables the
online robustness estimation of MTL<+∞
+pt formulas during
system execution or simulation. Given a MTL<+∞
+pt formula
ϕ and a current time state sequence step i, the algorithm
determines the number of time steps needed in the future
(resp. past) needed to compute the robustness of ϕ. We refer
to the number of time steps as the window size. Next, a
dynamic algorithm is utilized to calculate the robustness estimate. The future (resp. past) window size for specification
ϕ is called the horizon (resp. history) and denoted by hrz(ϕ)
(resp. hst(p)). The finite horizon and the history are defined
recursively as follows:

The robustness estimate, formally presented in (Fainekos
and Pappas 2009; Abbas et al. 2013), is used to indicate how
well a signal satisfies (or falsifies) MTL specifications. In
the rest of the paper, we will use the terms time state sequence and (execution or simulation) trace interchangeably.
We define a timed state sequence as µ = µ0 µ1 µ2 . . . µm where
µi = (τi , si ) represents a tuple of the time stamp and the vector containing the values of the state variables at sampling
instance i. Given a timed state sequence µ of a system output trajectory and a MTL specification ϕ, the robustness estimate returns a value ρ ∈ R ∪ {−∞, ∞}. A positive (resp.
negative) robustness means that the system is satisfied (resp.

602

inputs

offline/rarely called
global planner

online/runtime
state

Local MTL
Specification
Local RRT
Planner (2)

local
paths

Global
Planner (1)

Global LTL
Specification

global
map

Environment
Map

Finite Horizon
Local MTL Planner

MTL
Monitoring
(3)
feasible
paths
Path
Evaluation
Metric (4)

Robotic
System
vehicle
inputs

local sensing/update map

Figure 1: The planning process using the PLANrm framework.
Horizon:
hrz(p) = 0
hrz(¬ψ) = hrz(ψ)
hrz(ψ OP ϕ) = max{hrz(ψ), hrz(ϕ)}
hrz(ψU[l,u] ϕ) = max{hrz(ψ) + u − 1, hrz(ϕ) + u}
hrz(ψS[l0 ,u0 i ϕ) = max{hrz(ψ), hrz(ϕ)}
History:
hst(¬ψ) = hst(ψ)
hst(ψU[l,u] ϕ) = max{hst(ψ), hst(ϕ)}
hst(ψ OP ϕ) = max{hst(ψ), hst(ϕ)}
hst(ψS[l0 ,u0 i ϕ) =
(
max{hst(ψ) + u0 − 1, hst(ϕ) + u0 }
max{hst(ψ) + l0 − 1, hst(ϕ) + l0 }

However, at this point, we must make sure that the future
obligations from the local MTL requirements are preserved.
In the following, we review motion planning over LTL
specifications and then we provide an overview of our online planning framework for solving Problem 1 through an
example.

Review of LTL Planning
Motion planning over LTL specifications has a long history (Loizou and Kyriakopoulos 2004; Fainekos, KressGazit, and Pappas 2005; Kloetzer and Belta 2007; Karaman and Frazzoli 2008a; Bhatia, Kavraki, and Vardi 2010;
Plaku and McMahon 2013). One of the earliest works in LTL
planning in robotics appears in (Lamine and Kabanza 2002).
There, the authors use LTL runtime monitoring to check for
violations of LTL specifications while the robot executes its
plan. Also, the framework includes a simulation based planner with LTL goals in order to choose a behavior that would
best satisfy the LTL goals.
A general approach to the high-level planning problem
with LTL is as follows. First, a discretized abstraction M
of the workspace using decomposition techniques is generated (Fainekos, Kress-Gazit, and Pappas 2005). Then, the
LTL specification is converted into a Büchi automaton B.
Next, a search algorithm over the product automaton M × B
is utilized to find a feasible plan. In the LTL planning framework, partially known environments can be handled as well.
For example, see the recent work in (Guo, Johansson, and
Dimarogonas 2013), where the authors present an approach
to locally update the product automaton when the environment changes. Closer in spirit to our work are the works by
(Plaku, Kavraki, and Vardi 2009; Bhatia, Kavraki, and Vardi
2010), where the authors present an approach that combines
high-level planners with sampling-based low-level planners
to explore for feasible paths that satisfy LTL specifications.
In general, finding a tractable method for motion planning over MTL requirements is still an open problem. The
approach utilized for LTL formulas is not feasible for MTL.
MTL formulas can be represented by timed automata (Alur

if u0 , +∞
if u0 = +∞

where p ∈ AP. Here, OP is any binary operator in propositional logic, and ψ, ϕ are MTL<+∞
+pt formulas.

Problem Formulation
Our high level goal is to provide an online planning framework for dynamic environments where part of the mission
specifications may be updated. We aim to do so by utilizing
the notion of robustness and monitoring of MTL specifications. Formally, we aim to solve the following problem:
Problem 1 Given a model of a robotic system Σ and a path
p that satisfies an LTL formula ϕ, design an online controller which computes local paths which still satisfy ϕ and,
moreover, they satisfy a set {ψi } of potentially dynamically
changing local MTL mission requirements in a dynamically
changing environment.
The planning framework is presented in Fig. 1. Given a
global LTL specification ϕ, a global planner is utilized to
generate a path from the initial position to the goal position that satisfies ϕ. Then, the online, finite horizon local
MTL planner generates plans that take into account potentially changing MTL specifications until the destination is
reached. In certain conditions, the local planner may not
find a valid local path that satisfies the specification. In those
cases, an updated plan from the global planner is requested.

603

100

100

100

90

90

90

80

80

70

70

60

60

50

50

80
70

y

y

60
50
40

40

30

30

20

20

10

10

40
30
20
10
0

0
0

0
0

10

20

30

40

50

60

70

80

90

10

20

30

40

50

60

70

80

90

100

0

10

20

30

40

50

x

100

60

70

80

90

100

x

Figure 2: Left: Environment map with the initial position for the robot (yellow) at xinit = (10, 10, π) and the goal position for
the robot (green) at xgoal = (90, 90, 0). Middle: RRT generated on the configuration space considering the vehicle dynamics.
Right: Best path based on the RRT from xinit to xgoal .
T = 60s

T = 90s

90

90

90

90

80

80

80

80

70

70

70

70

60

60

60

60

50

50

50

50

y

100

y

100

40

40

40

40

30

30

30

30

20

20

20

20

10

10

10

0

0
0

10

20

30

40

50

60

70

80

90

100

10

0
0

10

20

30

40

x

50

60

70

80

90

100

0
0

10

20

30

40

x

T = 120s

50

60

70

80

90

100

0

T = 150s

80

80

80

80

70

70

70

70

60

60

60

60

50

50

50

50

y

90

y

100

90

40

40

40

40

30

30

30

30

20

20

20

20

10

10

10

0
20

30

40

50

x

60

70

80

90

100

10

20

30

40

50

60

70

80

90

100

60

70

80

90

100

70

80

90

100

0
0

x

50

10

0
0

40

T = 240s

100

90

10

30

T = 180s

100

0

20

x

90

0

10

x

100

y

y

T = 75s

100

y

y

T = 15s
100

10

20

30

40

50

x

60

70

80

90

100

0

10

20

30

40

50

60

x

Figure 3: Vehicle progression from xinit = (10, 10, π) to xgoal = (90, 90, 0) at various times in the path traversal. The blue path
represents the shortest path obtained by the global planner. The green path represents the path traversed by the vehicle. The red
regions represent areas where the vehicle should not go through. Also, every time the vehicle is in the yellow set then within
the next 20s the vehicle should enter set blue set.
and Dill 1994) and currently algorithms exist only for fragments of MTL (Maler, Nickovic, and Pnueli 2006). Therefore, in this work, we utilize LTL for the global specification.

Fig. 1. First, a global planner (1) is utilized to generate paths
considering the environment and system dynamics. For example, using the framework presented in (Bhatia, Kavraki,
and Vardi 2010). Then, the global plan is executed. If there
are any local MTL formulas that must be satisfied, then a local RRT planning framework is executed. The Local Planner
(2) generates paths from the current system location, while
considering a dynamically changing environment and specification. The set of paths generated are then classified as
feasible and infeasible through MTL Monitoring (3). Out of
the feasible local plans, in the Path Evaluation Metric (4)
stage, the framework choses the one that most closely corresponds to the global established path. Here, we can utilize
a weighted average of the robustness metric, in conjunction
with a similarity measure, such as the euclidean distance,
to chose one path from the set of feasible paths. It is important to note that the local plan needs to stay close to
the global plan, either in terms of path distance, regions or

Planning in Dynamic
Environments and Specifications
In real world applications of robotic systems, both the environment and the mission can change dynamically as the
system is running. In the latter case, we assume that such
changes are defined as MTL specifications. We aim to utilize
history and horizon window sizes for MTL specifications to
determine the timespan for the local plan generator in order
to generate specification compliant plans. For the local planner, we utilize MTL since it can capture specifications that
include timing intervals for temporal operators. In many applications it is often necessary to capture timing properties.
We present an overview of the planing framework in

604

P
control points such that H = ni=1 ti . This method is aimed to
improve the smoothness of the trajectories generated as opposed to general RRT methods. This local planning method
is illustrated in Figure 4. To generate the RRT, we utilize a
slightly modified version of the algorithm provided in the
Robotics Toolbox (Corke 2011). The spread-based method
utilized is inspired by the works presented in (Von Hundelshausen et al. 2008; Yu et al. 2012) which may be used to
generate smooth vehicle motion plans.
The set of trajectories generated from the local planner
are then tested over the specifications using the MTL Monitoring (3) algorithm. We use S-TaLiRo (Annapureddy et al.
2011; Hoxha et al. 2014) to conduct the robustness computation over MTL formulas. In Figure 4, we illustrate this
process with the specification ϕ = (a → ^[0,2] b) where a is
the set [10, 12] × [9, 11] and b is the set [13, 15] × [12, 14].
Once the set of feasible trajectories is provided, we utilize the Path Evaluation Metic (4) to choose the best path.
Here, we can utilize the robustness metric, in conjunction
with a trajectory similarity measure, to choose a path that
corresponds closely to the global path provided by the global
planner. We refer to this as the selection criterion. In our example, we utilize a weighted average of the robustness metric and the similarity measure. For a similarity measure, we
utilize a Euclidean distance
P measure, i.e. for two trajectories
T 1 and T 2 , Ed (T 1 , T 2 ) = ni=1 k(T 1 (i), T 2 (i))k /n, where T (i)
represents the vehicle position at time i.
Determining the best selection criterion is a challenging
problem, since non-optimal choices may lead to livelock situations where the vehicle moves but does not make overall
progress towards the goal. If a livelock does happen, it is
important to detect it and mitigate the issue by possibly requesting a new plan from the global planner. This topic will
be covered in future work.

some other high-level abstraction. In case no feasible paths
are found, the Local Planer (2) requests an update from the
global planner (1) and the process repeats until the destination is reached.
To illustrate the approach we utilize the car-like model
from the Robotics Toolbox (Corke 2011). A rear wheel is
fixed to the body, and a front wheel which rotates to steer
the vehicle. We assume that the vehicle only moves forward.
The configuration of the vehicle is represented by generalized coordinates q = (x, y, θ) ∈ C ⊂ S E(2). The kinematic
model of the vehicle is presented with the following equations of motion:
ẋ = v cos θ
ẏ = v sin θ
v
θ̇ = tan γ
L
where (x, y, θ) represent the (x, y) position and θ orientation of the robot, v represents the forward speed, L represents the length of the vehicle and γ is the steering angle. In
our study, the only input to the system is the steering angle
with a constant velocity. For more details on the model see
(Corke 2011). The Matlab Simulink model is also provided
in the toolbox. In Fig. 2 we present the environment along
with the initial and goal positions. We also present the global
plan generated using an RRT algorithm.
In Figure 3, we illustrate vehicle progression in a dynamically changing environment and mission specification. The
mission goal is to go from initial position xinit = (10, 10, π)
to xgoal = (90, 90, 0). At T = 15s, a specification φ = ¬a
is introduced where a is the set [30, 40] × [40, 60]. The
specification states that set a should never be visited. At
T = 60s and T = 75s, the local planner generates a path
that avoids set a. At T = 90s, the specification is updated to
φ = (¬a ∧ ¬b), where b is the set [70, 80] × [40, 60]. At
T = 120s, the local planner fails to find a path towards xgoal
and therefore requests an updated global plan. The global
planner then presents a new route to xgoal . At T = 150s,
the specification is updated to φ = (¬a ∧ ¬b) ∧ (c →
^[0,20] d), where c is the set [40, 50] × [60, 70] and d is the set
[30, 40] × [70, 80]. In addition to the previous specification,
the updated specification states that every time the vehicle
is in set c then within the next 20s the vehicle should enter
set d. At T = 120s, the local planner provides a plan that
satisfies the specification. It should be noted that it strays
away from the plan provided by the global planner in order
to satisfy the updated specification. At T = 240s, the vehicle
reaches the destination.
In practice, when an updated local MTL specification is
received, we should verify that it does not contradict the
global LTL specification. In certain scenarios, we can utilize
the work presented in (Fainekos 2011; Dokhanchi, Hoxha,
and Fainekos 2015) to detect and debug contradictory or inconsistent specifications.
The Local Planner (2) used in this framework generates
a set of trajectories by slightly modifying the steering angle
at a number of control points within the specification horizon/history window. Namely, given a horizon/history window size H, the steering angle is modified at ti equidistant

Conclusion and Future Work
In this work, we presented an overview of the framework
that enables online planning for robotic systems in dynamic
environments where the mission specification may change
during system operation. We illustrated the framework on a
car-like model from the Robotics Toolbox (Corke 2011).
As future work, we will consider the challenges presented
in the previous section. In certain situations, when no feasible paths are presented by the local planner, an updated
global path is requested by the global planner. However, in
those cases, the future obligations from the local MTL specification should be maintained. Also, we will investigate candidates for the selection criterion and conduct experimental results to evaluate them. We will also investigate methods for determining livestock conditions and how to resolve
them. Finally, we plan to utilize the PLANrm framework on
a more complex hybrid system and evaluate the performance
and computational overhead during this process.

References
Abbas, H.; Fainekos, G. E.; Sankaranarayanan, S.; Ivancic,
F.; and Gupta, A. 2013. Probabilistic temporal logic falsi-

605

RRT-Based Local Planner
14

13

13

12

12

11

11

10

10

y

y

Spread-Based Local Planner
14

9

9

8

8

7

7

6

6
9

10

11

12

13

14

15

16

17

9

10

11

12

x

13

14

15

16

17

14

15

16

17

x

14

14

13

13

12

12

11

11

10

10

y

y

Fainekos, G.; Girard, A.; Kress-Gazit, H.; and Pappas, G. J.
2009. Temporal logic motion planning for dynamic robots.
Automatica 45(2):343–352.
Fainekos, G. E.; Kress-Gazit, H.; and Pappas, G. J. 2005.
Temporal logic motion planning for mobile robots. In
Robotics and Automation, 2005. ICRA 2005. Proceedings
of the 2005 IEEE International Conference on, 2020–2025.
IEEE.
Fainekos, G. E. 2011. Revising temporal logic specifications
for motion planning. In Robotics and Automation (ICRA),
2011 IEEE International Conference on, 40–45. IEEE.
Guo, M.; Johansson, K. H.; and Dimarogonas, D. V. 2013.
Revising motion planning under linear temporal logic specifications in partially known workspaces. In Robotics and Automation (ICRA), 2013 IEEE International Conference on,
5025–5032. IEEE.
Hoxha, B.; Bach, H.; Abbas, H.; Dokhanchi, A.; Kobayashi,
Y.; and Fainekos, G. 2014. Towards formal specification
visualization for testing and monitoring of cyber-physical
systems. In Int. Workshop on Design and Implementation
of Formal Tools and Systems.
Kabanza, F. 1995. Synchronizing multiagent plans using
temporal logic specifications. In Lesser, V., ed., Proceedings of the First International Conference on Multi–Agent
Systems, 217–224. San Francisco, CA: MIT Press.
Karaman, S., and Frazzoli, E. 2008a. Complex mission
optimization for multiple-uavs using linear temporal logic.
In American Control Conference, 2008, 2003–2009. IEEE.
Karaman, S., and Frazzoli, E. 2008b. Vehicle routing problem with metric temporal logic specifications. In Decision
and Control, 2008. CDC 2008. 47th IEEE Conference on,
3953–3958. IEEE.
Kloetzer, M., and Belta, C. 2007. Temporal logic planning
and control of robotic swarms by hierarchical abstractions.
Robotics, IEEE Transactions on 23(2):320–330.
Koymans, R. 1990. Specifying real-time properties with
metric temporal logic. Real-Time Systems 2(4):255–299.
Lamine, K. B., and Kabanza, F. 2002. Reasoning about
robot actions: A model checking approach. In Advances
in Plan-Based Control of Robotic Agents, volume 2466 of
LNCS, 123–139. Springer.
Loizou, S. G., and Kyriakopoulos, K. J. 2004. Automatic
synthesis of multi-agent motion tasks based on LTL specifications. In Proceedings of the 43rd IEEE Conference on
Decision and Control.
Maler, O., and Nickovic, D. 2004. Monitoring temporal properties of continuous signals. In Proceedings of
FORMATS-FTRTFT, volume 3253 of LNCS, 152–166.
Maler, O.; Nickovic, D.; and Pnueli, A. 2006. From MITL
to Timed Automata. In Proceedings of FORMATS, volume
4202 of LNCS, 274–289. Springer.
Plaku, E., and McMahon, J. 2013. Combined mission and
motion planning to enhance autonomy of underwater vehicles operating in the littoral zone. In Workshop on Combining Task and Motion Planning at IEEE International Conference on Robotics and Automation (ICRA13).

9

9

8

8

7

7

6

6
9

10

11

12

13

x

14

15

16

17

9

10

11

12

13

x

Figure 4: Top: Left: Local planner used in the bicycle model
example for generating smooth and evenly distributed trajectories. Right: An additional method for generating local
plans through RRTs. Bottom: Trajectories that satisfy (resp.
falsify) specification ϕ = (a → ^[0,2] b) represented in blue
(resp. red) where a is the set [10, 12] × [9, 11] and b is the
set [13, 15] × [12, 14].
fication of cyber-physical systems. ACM Trans. Embedded
Comput. Syst. 12(2s):95.
Alur, R., and Dill, D. L. 1994. Theory of timed automata.
Theoretical Computer Science 126(2):183–235.
Annapureddy, Y. S. R.; Liu, C.; Fainekos, G. E.; and
Sankaranarayanan, S. 2011. S-taliro: A tool for temporal
logic falsification for hybrid systems. In Tools and algorithms for the construction and analysis of systems, volume
6605 of LNCS, 254–257. Springer.
Bhatia, A.; Kavraki, L. E.; and Vardi, M. Y. 2010. Samplingbased motion planning with temporal goals. In International
Conference on Robotics and Automation, 2689–2696. IEEE.
Corke, P. I. 2011. Robotics, Vision & Control: Fundamental
Algorithms in Matlab. Springer.
Ding, X.; Lazar, M.; and Belta, C. 2014. Ltl receding
horizon control for finite deterministic systems. Automatica 50(2):399–408.
Dokhanchi, A.; Hoxha, B.; and Fainekos, G. 2014. Online monitoring for temporal logic robustness. In Runtime
Verification, 231–246. Springer.
Dokhanchi, A.; Hoxha, B.; and Fainekos, G. 2015. Metric
interval temporal logic specification elicitation and debugging. MEMOCODE.
Fainekos, G., and Pappas, G. J. 2006. Robustness of temporal logic specifications. In Formal Approaches to Testing
and Runtime Verification, volume 4262 of LNCS, 178–192.
Springer.
Fainekos, G., and Pappas, G. J. 2009. Robustness of temporal logic specifications for continuous-time signals. Theor.
Comput. Sci. 410(42):4262–4291.

606

Plaku, E.; Kavraki, L. E.; and Vardi, M. Y. 2009. Falsification of ltl safety properties in hybrid systems. In Proc. of
the Conf. on Tools and Algorithms for the Construction and
Analysis of Systems (TACAS), volume 5505 of LNCS, 368 –
382.
Raman, V.; Donzé, A.; Maasoumy, M.; Murray, R. M.;
Sangiovanni-Vincentelli, A.; Seshia, S.; et al. 2014. Model
predictive control with signal temporal logic specifications.
In Decision and Control (CDC), 2014 IEEE 53rd Annual
Conference on, 81–87. IEEE.
Seda, A. K., and Hitzler, P. 2008. Generalized distance functions in the theory of computation. The Computer Journal
53(4):bxm108443–464.
Von Hundelshausen, F.; Himmelsbach, M.; Hecker, F.;
Mueller, A.; and Wuensche, H.-J. 2008. Driving with tentacles: Integral structures for sensing and motion. Journal of
Field Robotics 25(9):640–673.
Yu, H.; Gong, J.; Iagnemma, K.; Jiang, Y.; and Duan, J.
2012. Robotic wheeled vehicle ripple tentacles motion planning method. In Intelligent Vehicles Symposium (IV), 2012
IEEE, 1156–1161. IEEE.

607

2016 IEEE International Conference on Systems, Man, and Cybernetics • SMC 2016 | October 9-12, 2016 • Budapest, Hungary

Extended LTLvis Motion Planning Interface
Wei Wei, Kangjin Kim and Georgios Fainekos
The School of Computing, Informatics and Decision Systems Engineering
Arizona State University
Tempe, AZ, USA
Email: {wwei17,Kangjin.Kim,fainekos}@asu.edu

Abstract—This paper introduces a graphical interface for
Linear Temporal Logic (LTL) specifications for mobile robots. It
is a sketch based interface built on the Android platform which
makes the LTL control interface more friendly to non-expert
users. By predefining a set of areas of interest, this interface can
quickly and efficiently create plans that satisfy extended plan
goals in LTL. The interface can also allow users to customize the
paths for this plan by sketching a set of reference trajectories.
Given the custom paths by the user, the LTL specification and
the environment, the interface generates a plan balancing the
customized paths and the LTL specifications. We also show
experimental results with the implemented interface.

I. I NTRODUCTION
As the robots become more capable, so does the need to
specify and monitor complex motion and mission plans. Temporal logics have been proposed as an effective specification
language for complex missions for single [1] and multiple
[2] robots. However, temporal logic specifications are not
easy to write for people without extensive training in formal
logic. Therefore, in [3], we developed a graphical interface
for Linear Temporal Logic (LTL) specifications. In LTLvis,
the user creates a graph structure in the workspace of the
robot which is then translated into an LTL formula which is
forwarded to the planner.
In this paper, we extend our work by allowing the user to
incorporate specific path recommendations for certain parts
of the mission. In particular, we enable the user to sketch
path segments on the user interface which are then taken
into account by the planner. Since we focus on supervised
autonomy, the sketched paths are not trajectories to be tracked
by the robot but rather additional constraints for the LTL
planner. Two challenges arise when adding such path constraints. First, how to identify which path on the roadmap is
the closest to the one sketched by the user. Second, how to
guarantee that the sketched path does not violate any other
requirements provided as part of the LTL requirement. In
this paper, we provide algorithmic answers to both problems.
Furthermore, we demonstrate our framework using an iRobot
Create (TurtleBot) and the LTL planning framework by [4].
Related Work: Graphical control interfaces appear to be an
effective way to control mobile robots [5]. With a graphical
interface, users can control multiple robots more conveniently
[6] by clicking a predefined button instead of writing a robot
control program. The proposed work from [6] is similar to our
approach. However, instead of commanding a robot to follow
a path, they assign a start position for the robot and the robot

978-1-5090-1897-0/16/$31.00 ©2016 IEEE

will explore the given map to find its path by searching Rapidly
exploring Random Trees (RRT).
In [7], the authors propose a methodology to extract spatial
information about the sketched map and path. This information
including qualitative path movement, the key turning point of
the path and high level path description is helpful to model the
human-like robot navigation. In [8], the authors had shown that
planning using sketch based interfaces can be improved using
path correction. Once users draw a path bypassing an invalid
region (collisions), this interface will auto-correct the invalid
sub-path to a valid Bézier curve. Sakamoto et al. proposed
a robot control interface especially for home robots [9]. The
authors define a set of gesture commands for a set of actions.
They include move with an open curve, vacuum with a closed
curve, stop with a cross mark, etc.
In terms of LTL planning, in [2], the authors proposed
a solution to generate the optimal plan under a temporal
logic specification. LTL is the high level specification for the
planning task which is required to be repeatedly satisfied. To
let the robot complete the mission in a dynamic environment,
Ulusoy et al. proposed a solution in [4]. As the robot sensors
have limited ability to scan the whole environment, they define
a limited region as the local environment.
Summary of Contributions: The main contribution in our
research is to combine an easy-to-use sketch-based interface
with the expressive power of LTL and to improve the LTL
path planner provided by [4] for this hybrid interface1 . A
secondary contribution, which is important on its own, is that
we provide a greedy algorithm to identify the closest path on a
directed topologically grounded graph to a hand drawn curve.
We remark that our algorithm allows the path to be cyclic.
II. P RELIMINARY
In this section, we will first cover the graphical language
for LTL. Then, we will review LTL path planning.
A. Graphical Language for LTL
Temporal logic is a logic that describes events in time.
Linear Temporal Logic (LTL) is a modal temporal logic
reasoning over an infinite sequence of states. This section
mainly introduces the research work by Srinivas, et al on
defining a graphical language [3]. In particular, [3] provides a
graphical representation of an LTL formula in a 2D space. The
1 The authors in [4] provide software package RHTL which includes LTL
planner (LOMAP). Our implementation is based on their software package.

SMC_2016 004194

2016 IEEE International Conference on Systems, Man, and Cybernetics • SMC 2016 | October 9-12, 2016 • Budapest, Hungary

Qinit is a set of initial states; δBA ⊆ QBA × Σ × QBA is a
transition relation; Σ is the input alphabet; FBA is a set of
accepting states.

Fig. 1: The allowed combination of Boolean and temporal operators over an
edge (Reproduced from [3])

graph G is a tuple (V, E, v0 , c, L, Λ, x): where V is the set of
nodes; E ⊆ V ×V is the set of edges; v0 ∈ V is the start node;
c : V → {green, red} is a function that colors each node
either green or red, which corresponds to visiting or avoiding
a node2 ; L : V → ΠB (τ ) labels each node with an LTL
formula over the set of propositions Π; Λ : E → BO1 ×BO2 ×
T O2 × T O1 is a function that labels each edge on the graph
with one or more Boolean or temporal operators (in detail,
BO1 = {AN D, OR}; BO2 = BO1 ∪ {3 , IM P LIES};
T O1 = {, F U T U RE, ALW AY S}; T O2 = T O1 ∪
{N EXT, U N T IL}); x : V → R2 is the position of the node
on the map or on the image.
As BO1 is always implicitly used to connect consecutive
propositions, it is not included when forming the graph. Figure
1 is the flowchart of possible values of Λ.
B. LTL Path Planning
Path planning is the problem of finding a path between
a start position and an end position. Temporal logic path
planning is the path planning problem whose result, i.e., path
must satisfy a temporal logic requirement. The basic theory
on temporal logic planning is described in [1], [2]. First we
need to represent an environment as a discrete graph.
Definition 1. (TS) A transition system is a tuple T :=
(QT S , qinit , δT S , Π, h, wT S ), where QT S is a set of states.
It represents the accessible area in the graph; qinit ∈ QT S is
the starting state; δT S ⊆ QT S × QT S denotes the transition
relation between two states; Π is a finite set of atomic
propositions; h : QT S → 2Π is a function labeling areas
in the environment with atomic propositions; wT S : δ → N is
the weight assigned to each transition.
We denote a finite path on the transition system as p =
q0 , q1 , . . . , qn , where q0 = qinit and for 0 ≤ k < n, qk ∈ QT S
and (qk , qk+1 ) ∈ δ. The result generated from running this
path is a word v0 v1 . . . , where vk = h(qk ) is the set of atomic
propositions satisfied at qk .
After transferring a given environment into a discretized
transition system TS, we also need to convert a given LTL
specification. Thanks to the tool provided by [10], we can
easily convert any LTL formula into a Büchi automaton. We
introduce the definition of a Büchi automaton.
Definition 2. (BA) A Büchi automaton is a tuple B :=
(QBA , Qinit , δBA , Σ, FBA ), where QBA is a set of states;
2 Icons
3

can be added to help people with color blindness.
denotes an empty symbol.

For a run of input word W = ω0 ω1 . . . on the Büchi
automaton where ωi ∈ Σ, the resulting sequence would be
r = s0 s1 . . . , where si ∈ QBA and (si , ωi , si+1 ) ∈ δBA .
Now we have both TS and BA in a graph format. The goal is
to find a resulting sequence r = c0 c1 . . . where ci := (qj , sk ),
qj ∈ QT S and sk ∈ QBA . The resulting sequence should be
valid in TS and ending at one accepting state in BA4 . Hence,
we need to construct a product automaton P := T S × BA.
Definition 3. (PA) The product automaton P = T S × BA
between the transition system T :=(QT S ,qinit ,δT S ,Π,h,wT S )
and Büchi automaton B:=(QBA ,Qinit ,δBA ,Σ,FBA ) is a tuple P :=(SP ,SP O ,δP ,wP ,FP ), where SP =QT S ×QBA is a
finite set of states; SP O = qinit × Qinit is the set of
initial states; δP ⊆ δT S × δBA is a transition relation and
((qi , si ), (qj , sj )) ∈ δP if and only if (qi , qj ) ∈ δT S and
(si , ωi , sj ) ∈ δBA ; wP ((qi , si ), (qj , sj ))=wT S (qi , qj ) is a
weight function; FP =QT S ×FBA is a set of accepting states.
The set of final states FP of the product automaton represents the ultimate goal of the planning path. Then we can
reduce the problem of LTL path planning into finding the
optimal path on a graph given a starting position. At this level,
many methods can be utilized such as A∗ , DFS, Dijkstra etc.
For example, if the resulting path is (q0 , s0 ), (q1 , s1 ), . . . ,
(qn , sn ), then the actual path on the transition system (robot
workspace) will be q0 , q1 , . . . , qn .
III. P ROBLEM D ESCRIPTION
A. Problem Overview
This research mainly focuses on the problems of solving
the path planning under a given LTL specification. Given an
environment, a graphical LTL specification, and the user’s
preferred paths sketched on the environment, find the optimal
path satisfying the LTL specification and maximally following
the user’s path sketches. Once there exist conflicts between
the user sketch path and the LTL specification, the interface
should be able to regard the LTL specification as a higher
priority requirement and find an alternative path minimizing
the distance from the user sketch path. The rationale behind
this choice is that the user may not be explicitly aware of
important safety requirements and event dependencies when
drawing the desired path. An alternative approach would be
to recommended revisions to the mission requirements based
on the path drawn by the user. We have contacted similar
research in the past in the context of LTL planning under user
preferences [11].
B. Solution Overview
The interface starts with an empty screen asking the user
to input a map image. Then, the user can sketch on the map
4 For an infinite word, the word should contain at least one accepting state
in BA infinitely often.

SMC_2016 004195

2016 IEEE International Conference on Systems, Man, and Cybernetics • SMC 2016 | October 9-12, 2016 • Budapest, Hungary

Fig. 3: Black nodes and edges: the roadmap of a simple environment. Green
path: pu . Blue nodes: p0

Fig. 2: The procedure of manually creating a roadmap. Upper left: the user is
asked to load a map. Upper right: when a node is selected, it will be colored
green. Lower left: the red nodes are denoted as neighbors of the green node.
Lower right: a complete roadmap.

using the interface. There are three different editing modes for
planning, roadmap editing, and LTL editing.
• Sketching Mode (Fig. 5): Create nodes; Move nodes;
Draw a path from one node to another; Calculate the
most suitable path according to the user drawing; Clear
current drawing and planning path.
• Roadmap Mode (Fig. 2): Create nodes; Add or remove
undirected edges between nodes; Automatically save once
switching to another mode.
• LTL Mode (Fig. 6): Create nodes; Add or remove edges
with LTL attributes; Edit LTL attributes.
After loading the map, the interface enters the roadmap
mode. A roadmap, which is editable and serializable through
the interface, represents the TS. For example, the roadmap in
Fig. 2 is a topological graph which represents the workspace
of the robot. The roadmap should be stored locally as roadmap
data. If the roadmap data exists, it will be loaded and then the
sketching mode will be entered; otherwise, the interface will
enter the roadmap mode and automatically create an empty
roadmap data for editing. When a user is done editing a
roadmap, the interface will switch to sketching mode. The
last step is to create an LTL specification. However, there is
no restriction for the accessing order of each mode. A user
can access any mode at any time.
IV. E XTENDED -LTLVIS
E-LTLvis enables several drawing features and different
interface layouts from the original LTLvis [3].
A. Load Map and Create Roadmap
Roadmaps can be automatically generated using grid decomposition or a polyhedral decomposition of the environment
[12]. In our interface, we require user to manually create their
own roadmap. First, the interface requires the user to load the
roadmap image when the interface starts (Fig. 2 top left). After
the image is loaded, the interface will search the corresponding
roadmap file (.spc) which stores roadmap data. If it exists, the
data is loaded. If it does not exist, the interface will switch
to roadmap mode and automatically create an empty roadmap
data to allow the user to edit. When finishing editing the map,

the roadmap file will be created to store these nodes and edges
locally. Next time, when the same map image is selected, this
roadmap file will be loaded automatically. We also provide a
video demo in [13] to show in more detail the procedure for
creating a roadmap. Figure 2 contains some screen shots of
this demo.
B. Sketch Path
Sketch mode allows users to customize the path between
any two nodes. In sketching mode, users can add a node by
long pressing on the screen. When customizing the path, you
can first select the starting node, drag the path along the map,
and end the path at another node. This path is denoted as user
sketched path pu . Then, we find the node in the environment
closest to the first node of pu , and denote it as qstart . Also,
we find the node in the environment closest to the last node
of pu , and denote it as qend . Because the user sketched path
may be drawn by curves which consist of too many nodes,
to reduce the computation workload, the path is sampled by
distance dm and angle θm into a list of (blue in the Fig. 3)
nodes (n1, n2, . . . ). After appending qstart to the beginning
of the list and qend to the end of the list, we get a new list of
nodes. This list of nodes is denoted as sampled user sketched
path p0 . For example, in Fig. 3, the green curve is the user
sketched path.
Then, the touch up event will be triggered and the computed
best matching path will be displayed. Since q u may stretch to
areas undefined in the roadmap, this path may not be the same
as q u (Fig. 5). As we need to compare the similarity of two
paths, the best approach is to calculate the volume between
two paths. However, this approach has heavy workload. Thus,
we define a new heuristic, CWPD, to compare two paths.
Definition 4. (CWPD) Component-Wise Path Distance is a
distance between two paths p0 = (n00 , n01 , . . . , n0N −1 ) and
px = (nx0 , nx1 , . . . , nxN −1 ). It is defined as:
CW P D(p0 , px ) =

N
−1
X

dist(n0i , e(nxj ,nxi ) )),

(1)

i=0

where N = size(p0 ), n0i ∈ p0 , nxi , nxj ∈ px , and nxj is previous
node which differs from nxi . If nxi is the first node, nxj equals
to nxi .
We remark that a path can have repetition of nodes.
We use distance to line segment (e(nxj ,nxi ) ) instead of
line to avoid the situation where n0i is very far from
e(nxj ,nxi ) but close to the line(nxj , nxi ). From Eq. (1), we

can also derive the following equation. Let CW P D (n00 ,

SMC_2016 004196

2016 IEEE International Conference on Systems, Man, and Cybernetics • SMC 2016 | October 9-12, 2016 • Budapest, Hungary

Algorithm 1 F IND BMP(p0 , T S)

Fig. 4: The CWPDs of p1 , p2 , p3


n01 , . . . , n0N −1 ), (nx0 , nx1 , . . . , nxN −1 )
denote A and


CW P D (n00 , n01 , . . . , n0N −2 ), (nx0 , nx1 , . . . , nxN −2 )
+
0
dist(NN −1 , e(nxj−1 ,nxN −1 ) ) denote B. Then,
A=

N
−1
X

dist(n0i , e(nxj ,nxi ) )

i=1

=

−2
 NX


dist(n0i , e(nxj ,nxi ) ) + dist(n0N −1 , e(nxj−1 ,nxN −1 ) )

i=1

=B
(2)
Then, we definite the best match path in order to compare
it in terms of distance.
Definition 5. (BMP) Best Matching Path pbmp is a feasible
path on the transition system TS with the same starting qinit
and ending position qend as P 0 . It also has the properties:
length(pbmp ) = length(p0 ); pbmp can be cyclic on TS; The
component-wise path distance between pbmp and p0 should
be minimal.
We can reduce the sample distance dm and angle θm to
increase N . Thus, p0 can always have more nodes than pbmp
so that the size of pbmp can be extended to N by adding copies
of nodes in between. For the example in Fig. 4, some possible
BMP candidates are listed in Table I for the candidate path
set (p1 , p2 , p3 ):
p1
p2
p3
p0

A
A
A
A

B
C
B
n1

B
C
B
n2

B
D
B
n3

B
D
B
n4

E
E
B
n5

E
E
E
n6

E
E
E
E

TABLE I: path p0 and its possible BMP candidates. As p0 has more nodes
than px , we can extend the path (A, B, C) to path (A, B, B, . . . , C) or (A, B,
C, . . . , C) to make their number of nodes equal to N . To achieve the minimum
CWPD, we need to compare the CWPDs (shown in Fig. 4) between p0 and
each px . In this example, the path p3 minimizes the CWPD.

As the number of candidate in the worst case is N M , where
M is the number of nodes in TS, it is impractical to list all
of them before searching the minimum CWPD. Instead, we
create a matrix to store a BMP ending at nxi for each node in
the roadmap. When looping through each node in p0 , the path
stored in the matrix will be updated. The pseudo code of this
greedy algorithm is provided in Alg. 1.

Input: a path p0 and T S := (QT S , qinit , δT S , Π, h, wT S )
Output: a path pbmp
1: M ← |QT S |
. the number of elements in QT S
2: N ← |p0 |
. the number of nodes in p0
3: cwpd[:, :] ← ∞
. for N × M matrix
4: bmp[:, :] ← ∅ 

. for N ×
 M matrix
5: hstart, endi ← index(p0 [1]), index(p0 [N ])
6:
. get indices for start and end

 from nodes
 in QT S
7: hcwpd[1, start], bmp[1, start]i ← 0, {p0 [1]}
8: for i = 2 to N do
for j = 1 to M do
9:
10:
U PDATE(cwpd, bmp, i, j, p0 , T S)
11: pbmp ← bmp[N, end]
12: return pbmp
Because the user sketched path may contain cycles intentionally, standard shortest path algorithms [14] cannot be used.
Algorithm 1 solves the problem also with cycles on the graph.
It takes p0 and T S as input. It proceeds sequentially through
all nodes in p0 (line 8). In each iteration of this outer loop, it
calculates M BMPs for each qj (line 9) according to current
user input path (n00 , n01 , . . . , n0i−1 ). These BMPs start from
qstart and end at qj .
Algorithm 2 U PDATE(cwpd, bmp, i, j, p0 , T S)
Input: two matrix cwpd and bmp, two variables i and j, a
path p0 and T S := (QT S , qinit , δT S , Π, h, wT S )
Output:
1: if bmp[i − 1, j] 6= ∅ then . prev. bmp ending at this node
qj ← index−1 (j, QT S )
. returns a node of QT S
2:
3:
n0i ← index−1 (i, p0 )
. returns a node of p0
4:
eprev ← G ET L AST E DGE(bmp[i − 1, j])
5:
cwpdcandi ← cwpd[i − 1, j]+dist(n0i , eself ) . Eq. (2)
6:
if cwpdcandi < cwpd[i, j] then
7:
cwpd[i, j] ← cwpdcandi
bmp[i, j] ← bmp[i − 1, j] + qj
8:
9:
. concatenates qj to the end of bmp[i − 1, j]
10:
for qk in N eighbors(qj ) do
11:
ecurr ← hqj , qk i
k ← index(qk )
. index of nodes in QT S
12:
13:
if ecurr 6= eprev then
14:
cwpdcandi ← cwpd[i − 1, k] + dist(n0i , ecurr )
if cwpdcandi < cwpd[i, k] then
15:
16:
cwpd[i, k] ← cwpdcandi
17:
bmp[i, k] ← bmp[i − 1, k] + qk
•

At line 4, G ET L AST E DGE() returns the last edge of a given path or an edge with
the same two nodes if there is no last edge e.g., G ET L AST E DGE([ABCDE])
returns [AB] and G ET L AST E DGE([A]) returns [AA].

Algorithm 2 calculates the new CWPD and BMP by utilizing the results from the previous BMPs and CWPDs using
Eq. (2). For each node qj in QT S , it first checks if qj ’s
previous BMP bmp[i – 1, j] for (p0 [1], . . . , p0 [i – 1]) exists.
If it exists, it calculates the distance between p0 [i] and the
last edge of the path (bmp[i – 1, j], qj ). Then, it stores the

SMC_2016 004197

2016 IEEE International Conference on Systems, Man, and Cybernetics • SMC 2016 | October 9-12, 2016 • Budapest, Hungary

in the traditional LTL planner, the resulting path generated
from the new planner will attempt both the LTL specification
and the user input requirement.
Roadmap Mode
Sketching Mode
LTL Mode
Redo
Undo
Send

q0

q1

Fig. 5: The user sketched path (arc with dots) and its BMP (solid line in the
middle of lane). Since the user sketches in areas undefined in the roadmap,
the resulting BMP is much different from the sketched path. The textboxes
are added to improve the readability due to the size of the screenshot.

V. P LANNING U SING -E-LTLVIS
In this section, we will explain an extended planner (Alg.
3) which is modified from a RHTL package [4]. It takes the
product automaton A, the local transition system T S and the
preferred path set D as inputs. In this algorithm, A will be a
tuple A := (Ψ, qinit , δ, W, F ). We denote a preferred path set
as D, where D := {πuv | πuv = (qu , na1 , na2 , . . . , nam , qv ),
qu , qv ∈ Ψ , na1 , na2 , . . . , nam ∈ QT S }.
Algorithm 3 E XTENDED P LANNER(A, T S, D)

IMPLY

NEXT

Fig. 6: The basic LTL specification that corresponds to the sketched path in
Fig. 5

result in bmp[i, j] and cwpd[i, j] if the new cwpd[i, j] is
smaller than the existing value. Then, it repeats the process
for all paths (bmp[i – 1, j], qk ), where qk ∈ N eighbors(qj ).
Note that we can get qj ’s previous BMP and CWPD directly
from bmp[i – 1, j] and cwpd[i – 1, j], respectively, without
recomputing the results. The process will repeat at most M
times; thus, the run time of Alg. 2 is O(M ). In each step, the
minimum CWPD ending at each node in TS will be stored.
Thus, this algorithm finds the BMP with the minimum CWPD
eventually. The step by step run of Alg. 1 over the example
of Table I can be found in [15]. The algorithm only creates
two global matrices of size NM. Thus, the space complexity
of this algorithm is O(N M ) and the runtime complexity is
O(N M M ). Hence, this algorithm can be implemented on a
mobile device. After applying the algorithm to the scenario in
Fig. 2, we can get the result in Fig. 5.
Usually, users may need to specify the paths between
multiple pairs of nodes. Our algorithm will generate multiple
best matching paths for all user sketched paths. This set of
best matching paths is called the preferred path set.

Input: a product automaton A := (Ψ, qinit , δ, W, F ), a local
transition system T S := (QT S , qinit , δT S , Π, h, wT S ) and
a preferred path set D := {πuv | πuv = (qu , na1 , na2 ,
. . . , nam , qv ), qu , qv ∈ Ψ , na1 , na2 , . . . , nam ∈ QT S }
Output: an extended path πltl
1: Create an empty list πltl
2: for each πij in D do
. set all the preferred paths to
highest priority to be chosen
hqi , qj i ← hπij [1], πij [|πij |]i
3:
4:
if hqi , qj i ∈ δ then
5:
Change the weight w(qi , qj ) to α
6: Find the shortest path πA0 with minimum sum of edge
weight from qinit to qaccept in A
. based on the
modified priorities above
7: for k = 1 to |πA0 | − 1 do
8:
hqh , qm i ← hπA0 [k], πA0 [k + 1]i
9:
f ound ← ⊥
for πD in D do . πD is a sequence of nodes in QT S
10:
if πD [1]=qh ∧ πD [|πD |]=qm ∧VALID(πD , A) then
11:
12:
Append πD to πltl
13:
f ound ← >
14:
if ¬f ound then
0
from qh to qm in T S
15:
Find the shortest path πD
0
16:
Append πD to πltl
17: Append πA0 [|πA0 |] to πltl
. this is for qaccept
18: return πltl
•
•
•

C. Edit Specifications
After a path is customized in the Sketching mode, there
should be a default LTL specification displayed in the LTL
Mode (for an example see Fig. 6).
Users can also skip the Sketching mode to directly edit
the LTL specification. In this mode, the editing gestures are
identical to LTLvis [3].
D. Send Data
When all the data is ready, users can send the data to the
LTL planner. The LTL planner used in this work is modified
from the RHTL package [4]. By adding path preference logic

At line 5, α is infinitesimal and α ∈ R+ . It is much smaller than the smallest
weight in W .
At line 11, VALID(πD , A) means that this path πD never visits any avoiding
states in A.
At line 12, 16, 17, each Append operation to πltl adds the element to the tail
of the list.

Algorithm 3 works as follows. Assume πij ∈ D, the
algorithm first checks if there is transition (qi , qj ) ∈ δ at line
4. If such transition exists, it changes its weight to α. Here,
α ∈ R+ denotes an infinitesimal value. This can increase the
priority of the preferred path set when calculating the shortest
path πA0 from qinit to qaccept in line 6. After finding πA0 ,
we need to replace each transition (qi , qj ) ∈ πA0 with a
corresponding transition from either the preferred path set D
or the transition system T S. As the preferred path set D has
higher priority, if πD exists in the preferred set, we add it to
0
the path πltl . Otherwise, we find a shortest alternative πD
in

SMC_2016 004198

2016 IEEE International Conference on Systems, Man, and Cybernetics • SMC 2016 | October 9-12, 2016 • Budapest, Hungary

VII. C ONCLUSIONS

Fig. 7: The experiment environment and its scanned map

Fig. 8: Experiment 1: LTL specification, sketched path and resulting trajectory.
The LTL specification is (q0 → Xq1) ∧ (q0 ∧ Fq2).

T S and add it to πltl . After qaccept is visited, πltl is completed.
For detail, see [16] and [15].
VI. E XPERIMENTS
In this section, we are going to test our interface and
planner on a real robot - TurtleBot. TurtleBot is a Robot
Operating System (ROS) based project. It contains two major
hardware devices: Kinect and iRobot base. The TurtleBot
project also contains many useful packages. For example,
turtlebot_navigation is one of the most popular packages used to localize the robot by itself. Then, we use
turtlebot_rviz to visualize the environment. The final goal
of this experiment is to use the proposed interface to send an
LTL specification and a preferred path set to the planner. The
planner should generate a path plan and order the TurtleBot
to execute the plan. The real environment (185cm × 430cm)
and its scanned map are shown in Fig. 7.
We performed two experiments 10 times each. We measured
the time needed to compute BMPs from p0 . The number of
nodes in QT S for both scenarios was 6 and the number of
nodes in q 0 in average were 11.3 and 29, respectively. Figure
8 shows the first experiment. The task of the TurtleBot is to
execute the specification (q0 → Xq1)∧(q0∧Fq2) (see [1], [2]
for a description of the temporal logic operators). In natural
language, it means “the TurtleBot is required to start from q0
and head for q1. Then it will reach q2 eventually”. It took 1.7
milliseconds in average, having M=6 and N=11.3.
Figure 9 shows the second experiment. The task of the
TurtleBot is to follow the specification (q0 ∧ GF(q1 ∧ Fq2)).
In natural language, it means “the TurtleBot is required to start
from q0 and head for q1 then q2 and loop between q1 and
q2”. It took 4 milliseconds in average, having M=6 and N=29.
In both experiments, the TurtleBot succeeded in finding
the correct path and followed the plan. More details on the
experiment can be found in [13].

Our current research aims to solve the path planning problem with a path requirement under an LTL specification for
a single robot. We combined the ease of use of a sketch
interface and LTLvis [3] into a hybrid interface to allow users
input customized paths. We conducted two experiments. The
interface can express user demands and the planner can realize
these demands correctly in the experiments. In terms of future
research, the interface can be extended to multiple robots by
adding a cooperation module. Second, we can add a realtime feedback module to the planner so that the users will
know how the robots are running. Third, we plan to perform
a usability study to test its ease of use.
ACKNOWLEDGMENT
This work was partially supported by NSF CPS 1446730.
R EFERENCES
[1] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, 2009.
[2] S. L. Smith, J. Tumova, C. Belta, and D. Rus, “Optimal path planning
under temporal logic constraints,” in Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, 2010.
[3] S. Srinivas, R. Kermani, K. Kim, Y. Kobayashi, and G. Fainekos,
“A graphical language for LTL motion and mission planning,” in
Proceedings of the IEEE International Conference on Robotics and
Biomimetics, 2013.
[4] A. Ulusoy, M. Marrazzo, and C. Belta, “Receding horizon control in
dynamic environments from temporal logic specifications,” in Robotics:
Science and Systems, 2013.
[5] D. C. Shah, J. Schneider, and M. E. Campbell, “A robust sketch interface
for natural robot control,” in IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS), 2010.
[6] Y. Ochiai, K. Takemura, A. Ikeda, J. Takamatsu, and T. Ogasawara,
“Remote control system for multiple mobile robots using touch panel
interface and autonomous mobility,” in Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, 2014.
[7] M. Skubic, S. Blisard, C. Bailey, J. A. Adams, and P. Matsakis,
“Qualitative analysis of sketched route maps: Translating a sketch
into linguistic descriptions,” IEEE Transactions on Systems, Man and
Cybernetics, 2004.
[8] J. A. Frank and V. Kapila, “Path bending: Interactive human-robot interfaces with collision-free correction of user-drawn paths,” in Proceedings
of the International Conference on Intelligent User Interfaces, 2015.
[9] D. Sakamoto, K. Honda, M. Inami, and T. Igarashi, Sketch and run: A
stroke-based interface for home robots. 27th International Conference
on Human Factors in Computing Systems, 2009, pp. 197–200.
[10] P. Gastin and D. Oddoux, “Fast LTL to buchi automata translation,” in
Proceedings of the 13th CAV, 2001.
[11] K. Kim and G. Fainekos, “Revision of specification automata under
quantitative preferences,” in IEEE International Conference on Robotics
and Automation, 2014.
[12] S. LaValle, Planning Algorithms, 2006.
[13] “[Online],” https://app.assembla.com/spaces/ltlvis/wiki/E-LTLvis.
[14] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction
to Algorithms. MIT Press, 2009.
[15] W. Wei, “Extended LTLvis motion planning interface,” Master’s thesis,
Arizona State University, 2016.
[16] W. Wei, K. Kim, and G. Fainekos, “Extended LTLvis motion
planning interactive,” arXiv.org, Tech. Rep., 2016. [Online]. Available:
http://arxiv.org/abs/1607.01419

Fig. 9: Experiment 2: LTL specification, sketched path and resulting trajectory.
The LTL specification is (q0 ∧ GF(q1 ∧ Fq2)).

SMC_2016 004199

2012 American Control Conference
Fairmont Queen Elizabeth, Montréal, Canada
June 27-June 29, 2012

Verification of Automotive Control Applications using S-TaLiRo
Georgios E. Fainekos, Sriram Sankaranarayanan, Koichi Ueda and Hakan Yazarel

Abstract— S-TA L I RO is a software toolbox that performs
stochastic search for system trajectories that falsify realtime temporal logic specifications. S-TA L I RO is founded on
the notion of robustness of temporal logic specifications. In
this paper, we present a dynamic programming algorithm
for computing the robustness of temporal logic specifications
with respect to system trajectories. We also demonstrate that
typical automotive functional requirements can be captured and
falsified using temporal logics and S-TA L I RO.

I. I NTRODUCTION
Models of automotive control systems can be fairly complex. Such models are usually developed in a modeling
environment that supports a block diagram graphical user
interface for modeling the continuous plant and control
components, enhanced with finite state machines. Examples
of commonly used modeling and simulation environments
include Simulink/Stateflow (TM), Scade (TM), LabVIEW
(TM) and Ptolemy [1]. A typical system model may contain
thousands of blocks organized in hierarchical subsystems that
go several levels deep. The complexity is further exacerbated
by discrete switches in the form of switching blocks, lookup
tables, communication of subsystems through shared global
variables and so on. Therefore, capturing such an overall
model in an analytical form amenable to traditional control
theoretic analysis (and possibly design) is not a feasible task.
Testing is a commonly used approach to check that the
model satisfies the correctness properties stated in the requirements. However, the success of testing depends primarily on the ability to write test cases that exhaustively cover all
the possible corner cases under which a property can possibly
fail. For the case of control systems, the space of behaviors
is (uncountably) infinite. As a result, the process of testing
often fails to expose potential failures in the model. This has
lead to work on uniform random testing or “guided” random
testing, where the choice of inputs is stochastic, based on
some guidance criteria [2]–[5].
Yet, the problem of systematically guiding the search for
an input that falsifies a given property has not been wellunderstood. At its heart, the problem lies in defining mathematically sound notions of “how far away” a given execution
This work was partially supported by a grant from the NSF Industry/University Cooperative Research Center (I/UCRC) on Embedded Systems at Arizona State University and NSF awards CNS-1017074, CNS1116136 and CNS-1016994.
G. Fainekos is with the School of Computing, Informatics and
Decision Systems Engineering at Arizona State University. E-mail:
fainekos@asu.edu.
S. Sankaranarayanan is with the Department of Computer Science,
University of Colorado, Boulder. E-mail: srirams@colorado.edu
K. Ueda and H. Yazarel are with the Toyota Technical Center. E-mail:
{koichi.ueda,hakan.yazarel}@tema.toyota.com

978-1-4577-1096-4/12/$26.00 ©2012 AACC

of the system is from violating a property. If such a notion of
distance were available – and at the same time easy to compute – it could be used as an objective function in a global
optimization setting. The goal would be to choose inputs that
minimize the distance between the resulting execution trace
and a violation of the property of interest. Recently, we have
made progress towards obtaining mathematical notions of
robustness metrics [6]–[8] that quantify the distance between
the execution trace of a given hybrid system combining
continuous evolution of state variables with discrete mode
switches and a property stated in a commonly used logic
for real-time trace properties called Metric Temporal Logic
(MTL) [9]. The overall framework has been implemented
in a Matlab toolbox called S-TA L I RO [10]. This framework allows us to use robustness computations over traces
guided by a large class of global optimization techniques
including genetic algorithms, ant-colony optimization [11]
and stochastic optimization techniques using Monte-Carlo
simulations [6], [7] and the Cross-Entropy Method [12].
Frameworks such as S-TA L I RO can be used to systematically test a given model by searching for an input that
falsifies the given property of interest. Even if a falsification cannot be found by this process, the traces with least
robustness discovered by the search are often useful to the
developers in showing examples where the simulation comes
“closest” to violating the property.
The goal of this paper is to demonstrate how S-TA L I RO
can be applied to problems in the automotive domain. To this
end, we identified as one of the major challenges to applying
S-TA L I RO to industrial applications the computation time of
the robustness metric.
Contributions: We present an improved algorithm for the
computation of the robustness value based on the dynamic
programming principle [13]. The new algorithm has linear
worst case execution time with respect to the size of the
formula, the number of samples of the system trajectory and
the bounds of the temporal operators. We compare the new
algorithm with the algorithm of our earlier work [8]. Finally,
we present two case studies on automotive applications.
Related Research: The applicability of metaheuristics for
test generation on industrial size problems has been established by Zhao et al. [14]. The authors utilize genetic
algorithms to generate tests for Simulink/Stateflow models.
The cost function is the number of regions and states
that have been covered. The work in [15] utilizes rapidly
exploring random trees guided by automata that recognize all
the prefixes that violate a syntactically safe Linear Temporal
Logic (LTL) formula. A different algorithm for computing
the robustness of MTL formulas as defined in [8] is presented

3567

output signal

in [16]. In [17], a different notion of robustness for temporal
logic specifications is developed, which is also used as a
fitness function for optimization problems.

System
initial
conditions $0 &
input signal u

II. T HE MTL FALSIFICATION P ROBLEM
In this work, we target directly executable models of automotive control applications. As such, we will assume that the
system will be tested for a range of initial conditions, system
parameters and input signals. In particular, we will assume
that the system under study is modeled in Simulink/Stateflow.
However, what we propose here can be readily applied to any
other model based design environment such as Ptolemy [1]
or LabVIEW.
Formally, we view a system Σ as a mapping from initial
conditions X0 , system parameters P and input signals U R
to output signals Y R . Here, R is an abstract time domain,
U is the set of input values (input space) and Y is the set of
output values (output space). Thus, a system Σ is a function
∆Σ : X0 × P × U R → Y R which takes as input an initial
condition χ0 ∈ X0 , a parameter vector p ∈ P and a signal
u : R → U and produces as output a signal η : R → Y.
Since our analysis is based on performing system simulations, we will assume the existence of a sampling function
τ : N → R that returns for each sample i its time stamp
τ (i). In practice, τ is a partial function τ : N → R with
N ⊂ N and |N | < ∞. We will abuse notation and denote
by |τ | the cardinality of the domain of τ , i.e., |τ | = |N |. A
timed state sequence or trace is the pair µ = (η ◦ τ, τ ). We
will also denote η ◦ τ by σ.
Our goal – in the line of work that we initiated in [7]
– is to infer the correctness of the system Σ by observing
its response (output signals) to particular input signals,
initial conditions and parameter values. In particular, we are
interested in finding witnesses, i.e., output signals, which
prove that a requirement or specification is not satisfied by
the system. The process of discovering such witnesses is
usually referred to as falsification.
The next question that needs to be answered is how do
we formally capture informal specifications regarding the
correct or expected behavior of the system. We observe
that Metric Temporal Logic (MTL) [9] is an appropriate
mathematical formalism that can capture such requirements
for automotive control systems. MTL formulas are built over
a set of propositions using combinations of the traditional and
temporal operators. In our case, the set of atomic propositions
AP label subsets of the output space Y. In other words,
we define an observation map O : AP → P(Y) such that
for each π ∈ AP the corresponding set is O(π) ⊆ Y.
Here, P(S) denotes the powerset of a set S. Traditional
logic operators are the conjunction (∧), disjunction (∨),
negation (¬), implication (→) and equivalence (↔). Some
of the temporal operators, which we will be using here, are
eventually (✸I ), always (✷I ) and until (UI ). The subscript
I imposes timing constraints on the temporal operators.
The interval I can be open, half-open or closed, bounded
or unbounded, but it must be non-empty (I 6= ∅). For
example, MTL can capture the requirement that “all the

Temporal Logic
Robustness

Optimization
Algorithm

Minimum
Robustness
Falsifying
Trajectory

robustness 0

Fig. 1. Overview of the solution to the MTL falsification problem posed
as an optimization problem.

observable trajectories y(t) ∈ R attain a value in the set
[10, +∞)” (✸p1 with O(p1 ) = [10, +∞)) or that “whenever
the value of y drops below 10, then it should go above
10 within 5 sec and remain above 10 for at least 10 sec”
(✷(¬p1 → ✸[0,5] ✷[0,10] p1 )).
The MTL falsification problem can be stated as follows.
Problem 2.1 (MTL Falsification): For an MTL specification ϕ, the MTL falsification problem consists of finding
an output signal η of the system Σ starting from some valid
initial state χ0 under a parameter vector p and an input signal
u such that η does not satisfy specification ϕ.
The challenges in solving the MTL falsification problem
are multiple. The main problem is essentially how to guide
the search for such a falsifying trajectory. We remark that
the system dynamics of Σ are not known to us in some
analytical form because most of industrial size models will
contain look-up tables and black-box blocks (object code)
from various suppliers.
In our previous work, we utilized the notion of robustness
of temporal logic formulas [8] in order to convert the
falsification problem into an optimization problem [6], [7],
[10]–[12]. Briefly, temporal logic robustness provides a measure of how robustly a trajectory satisfies a temporal logic
specification. Positive robustness implies that the trajectory
satisfies the specification and, moreover, that there exists a
neighborhood of trajectories (or signals) that also satisfy the
specification. Negative robustness implies that the trajectory
does not satisfy the specification. Thus, in order to falsify
the specification, we can use the temporal logic robustness
as a cost function which we attempt to minimize.
The general overview of the solution of the MTL falsification problem as an optimization problem appears in
Fig. 1. Based on that principle, we have developed the
Matlab toolbox S-TA L I RO [10]. Given a system and its
specification, S-TA L I RO searches for a system trajectory that
minimizes the robustness value of the specification.
III. MTL ROBUSTNESS
In this section, we review the robust semantics of MTL
formulas. Details are available in our previous work [6], [8].
Definition 3.1 (MTL Syntax): Let AP be the set of atomic
propositions and I be any non-empty interval of R+ . The
set M T L of all well-formed MTL formulas is inductively
defined as ϕ ::= T | p | ¬ϕ | ϕ ∨ ϕ | ϕ UI ϕ, where
p ∈ AP and T is true. If there are no timing constraints on
the operators, then the formula is in LTL.
We provide semantics that maps an MTL formula ϕ and
a trace µ to a value drawn from a partially ordered set V.

3568

The semantics for the atomic propositions evaluated for µ(i)
consists of the distance between σ(i) and the set O(p) labeling atomic proposition p. Intuitively, this distance represents
how robustly the point σ(i) lies within (or is outside) the set
O(p). If this distance is zero, then the smallest perturbation
of the point σ(i) can affect the outcome of σ(i) ∈ O(p).
We denote the robust valuation of the formula ϕ over the
trace µ at sampling instance i by [[ϕ, O]]d (µ, i). Formally,
[[·, ·]]d : (M T L × P(Y)AP ) → (L(H) × N → V), where
N = τ −1 (R) = {i ∈ N | τ (i) ∈ R}.
Definition 3.2 (Discrete-Time Robust Semantics):
Consider an extended generalized quasi metric space (Y, d)
(see [6] for a definition). Let µ be a trace of Σ, v ∈ V and
O ∈ P(Y)AP , then the robust semantics of any formula
ϕ ∈ M T L with respect to µ is recursively defined as:
G
[[T, O]]d (µ, i) := V := ⊤
[[p, O]]d (µ, i) :=Distd (σ(i), O(p))
[[¬ϕ1 , O]]d (µ, i) := − [[ϕ1 , O]]d (µ, i)
[[ϕ1 ∨ ϕ2 , O]]d (µ, i) :=[[ϕ1 , O]]d (µ, i) ⊔ [[ϕ2 , O]]d (µ, i)
G
[[ϕ1 UI ϕ2 , O]]d (µ, i) :=
([[ϕ2 , O]]d (µ, i′ )⊓
i′ ∈τ −1 (τ (i)+R I)

⊓i≤i′′ <i′ [[ϕ1 , O]]d (µ, i′′ )
where Distd (σ(i), O(p)) is the signed distance of σ(i)
from O(p) under the metric d (see [8] for a definition),
− is an unary operator for complement over V, t +R I =
{t′′ ∈ R | ∃t′ ∈ I . t′′ = t + t′ } and ⊔ and ⊓ stand for
the supremum and infimum, respectively. The semantics of
the other operators can be defined using the above basic
operators. E.g., ✸I φ ≡ T UI φ and ✷I φ ≡ ¬✸I ¬φ.
For the purposes of the following discussion, let
(µ, i, O) |= ϕ denote the standard Boolean MTL satisfiability. For clarity in the presentation, we define the satisfiability
relation for the base case, i.e., for atomic propositions:
p ∈ AP , (µ, i, O) |= ϕ if σ(i) ∈ O(p). It is easy to show
that if the signal satisfies the property, then its robustness is
non-negative and, similarly, if the signal does not satisfy the
property, then its robustness is non-positive.
In our previous work [8], we had implemented the MTL
robustness computation algorithm using a forward progression algorithm. The precise complexity of the computation of
MTL robustness using formula rewriting procedures is still
an open problem [8]. However, the time complexity is at least
as hard the time complexity of the Boolean version of the
same algorithm [18], which is in the worst case exponential
in the size of the formula.

Algorithm 1 Temporal Logic Robustness Computation
Input: The MTL formula φ, the trace µ = (σ, τ ), the metric
d and the observation map O
Output: Return the value stored in r[1, 1]
1: procedure DP-TA L I RO (φ, O, µ, d)
2:
for j ← |τ | to 1; for i ← |φ| to 1 do
3:
if ψi = T then r[i, j] = ⊤
⊲ ⊤ := ⊔V
4:
else if ψi = p then r[i, j] ← Distd (σ(j), O(p))
5:
else if ψi = ¬ψk then r[i, j] ← −r[k, j]
6:
else if ψi = ψk1 ∨ ψk2 then
7:
r[i, j] ← r[k1 , j] ⊔ r[k2 , j]
8:
else if ψi = ψk1 UI ψk2 then
9:
if j = |τ | then r[i, j] ← K∈ (0, I) ⊓ r[k2 , j]
10:
else if I = [0, +∞) then
11:
r[i, j] ← r[k2 , j] ⊔ (r[k1 , j] ⊓ r[i, j + 1])
12:
else
13:
bl ← min J(j, I); bu ← max J(j, I);
14:
rmin ← ⊓j≤j ′ <bl r[k1 , j ′ ];
15:
r[i, j] ← ⊥;
⊲ ⊥ := ⊓V
16:
for j ′ ← bl to bu do
17:
r[i, j] ← r[i, j] ⊔ (r[k2 , j ′ ] ⊓ rmin );
18:
rmin ← rmin ⊓ r[k1 , j ′ ];
19:
end for
20:
if sup I = +∞ then
21:
r[i, j] ← r[i, j] ⊔ (r[k1 , j] ⊓ r[i, j + 1])
22:
end if
23:
end if
24:
end if
25:
end for
26: end procedure
where k, k1 , k2 > i; K∈ (a, A) = ⊤ if a ∈ A and ⊥
otherwise; and J(j, I) = τ −1 ((τ (j)+R I)∩(τ (j +1)+R I))
if sup I = +∞ and J(j, I) = τ −1 (τ (j) +R I) otherwise.

temporal logic robustness of the subformulas of a formula
φ at the current and future points in time. In brief, the
algorithm starts by constructing the parse tree of the temporal
logic formula φ. Each subformula ψi of φ is uniquely
identified starting from the leafs and represents a row i in
the dynamic programming table. The columns j of the table
represent the different timing instants of the trace. Then, the
algorithm starts by filling the values of each φi at the last
signal sampled and, then, proceeds backwards until the initial
sampling time is reached. The pseudocode for the dynamic
programming algorithm appears in Algorithm 1.
Theorem 4.1: Given an MTL formula φ, a trace µ =
(σ, τ ), a metric d and an observation map O, then

IV. DYNAMIC P ROGRAMMING A LGORITHM FOR
T EMPORAL L OGIC ROBUSTNESS

[[φ, O]]d (µ, 0) = DP-TA L I RO(φ, O, µ, d)

In this section, we present a dynamic programming algorithm for computing the robustness of temporal logic
formulas with respect to a timed state sequence.
The basic principle of the dynamic programming algorithm is that it can reuse previously computed results [13].
Here, the results which are going to be reused are the

Moreover, Algorithm 1 has worst case running time
O(|φ||τ |c), where c = max0≤j≤|τ |,I∈T (φ) |[j, max J(j, I)]|
and T (φ) contains all the timing constraints I of the temporal
operators that appear in φ.
The proof of Theorem 4.1 is based on rewriting the robustness semantics of Def. 3.2. Similar proofs have appeared in

3569

TABLE I
C OMPARISON OF DP-TA L I RO VS FW-TA L I RO ON THE SPECIFICATIONS
OF E XAMPLE 5.2. T HE SIMULATION TRAJECTORY HAS 1673 SAMPLES .
Spec.
φe1
φe2
φe2.1
φe2.2
φe3

DP-TA L I RO (sec)
0.0183
0.0171
0.0175
0.0274
0.0127

gear_state

UP

second
2 entry:
gear = 2;
DOWN

first
entry:
gear = 1;

FW-TA L I RO (sec)
60 <
1.0984
60 <
60 <
0.0069

UP
1

third
entry:
2 gear = 3;

UP

fourth
entry:
gear = 4;

1
DOWN

DOWN

selection_state
during: CALC_TH ;

2

[speed < down_th]

steady_state
2

A. Experimental Comparison of two Robustness Computation Algorithms
In [8], we presented an algorithm for computing temporal
logic robustness which is based on rewriting techniques.
Even though the exact computational complexity is still an
open problem, it is as hard as the Boolean version of the
algorithm [18], which is at least linear in size of the input
trajectory and exponential in the size of the formula and the
timing constraints on the operators.
We have implemented both algorithms in ANSI C and
both can be executed within the Matlab environment. The
dynamic programming version of the algorithm is referred to
as DP-TA L I RO while the rewriting version of the algorithm
is referred to as FW-TA L I RO. Both are available at [19].
In order to compare the two algorithms on realistic specifications and signals, we use the formulas and trajectories
generated for the examples in Section V. The results are
presented in Table IV-A. We observe that the experimental
running time of FW-TA L I RO is highly dependent on the
structure of the formula. On the other hand, DP-TA L I RO
essentially has constant running time with respect to the
length of the simulation trajectory. Thus, DP-TA L I RO is
better suited for our falsification framework.
V. S-TA L I RO A PPLICATION TO AUTOMOTIVE E XAMPLES
In this section, we present the application of S-TA L I RO
to two automotive applications available in the literature.
First, we demonstrate S-TA L I RO on the illustrative example
from [14]. We establish that S-TA L I RO can capture and

downshifting

2 upshifting
1

2
1
after (TWAIT,tick)
[speed <= down_th]
{gear_state.DOWN }

Fig. 2.

[speed > up_th]
1

[speed < up_th]

[speed > down_th]

[8]. The running time of the algorithm for an LTL formulae ϕ
is O(|ϕ||τ |), i.e., it is linear in the size of the formula and the
number of samples in the simulation trajectory. This is easy
to verify since all the entries r[i, j] of the table in Algorithm
1 require at most 3 inf or sup operations. On the other hand,
when an MTL formula is considered, then at most c inf
and/or sup operations are required for the until operator. c is
the maximum number of samples that can appear from any
sampling point j up to the maximum sampling point allowed
bu by the timing constraints of the operator. In detail, c is
the sum of ⊓ operations in line 14 of Alg. 1 plus the number
of iterations in the for loop in lines 16-19.
The hidden cost in the above analysis is the running time
of the distance computation function. The computational
complexity of the distance computations depends on the type
of the sets used for modeling the regions of interest in the
state-space. Details for the Euclidean distance metric are
presented in [8].

1

after (TWAIT,tick)
[speed >= up_th]
{gear_state.UP }

The switching logic for the automatic drivetrain in Example 5.1.

TABLE II
T HE STATE MAPPING OF THE COMPOSITION OF THE TWO FSM.
steady state
upshifting
downshifting

First
q1
q5
q9

Second
q2
q6
q10

Third
q3
q7
q11

Fourth
q4
q8
q12

falsify the requirements posed in [14] on the same problem.
Therefore, S-TA L I RO can be thought as a generalization
of the approach proposed in [14]. Second, we demonstrate
that S-TA L I RO can not only solve the challenge problem
posed in [20], but help the designer easily explore other
properties of the system. All the case studies presented here
are included with the S-TA L I RO distribution [19].
Example 5.1: The illustrative example that is presented in
[14] is the Automatic Transmission model provided by Mathworks as a Simulink demo (http://www.mathworks.
com/products/simulink/demos.html). This is a
model of an automatic transmission controller. According
to the report generated by sldiagnostics (a Matlab
function), the model contains 69 blocks out of which there
are 2 integrators (i.e., 2 continuous state variables: wheel
speed and engine speed (RPM)), 3 look-up tables, 3 look-up
2D tables and a Stateflow chart. The Stateflow chart (see Fig.
2) contains two concurrently executing Finite State Machines
(FSM) with 4 and 3 states, respectively, and non-constant
switching guard conditions. Even though this is a small size
model, it already exhibits all the complexities that prevent
formal modeling and analysis.
For comparing our results with [14], we made the same
modifications to the model in terms of inputs-outputs. That
is, the only input to the system is the throttle schedule, while
the break schedule is set simply to 0 for the duration of
30 sec. Also, we modified the model to output the state of
the synchronous composition of the two FSM (see Table 5.1).
The method proposed in [14] generates tests such that
certain regions of the hybrid state space of the system are
visited (coverage requirement). In particular, the requirement
is to generate tests such that: (i) the vehicle speed v exceeds
120km/h, (ii) the engine speed ω exceeds 4500RPM, and,
(iii) all states are reached in the switching logic. Assuming
that the state vector is [v ω]T and that the states in the

3570

FSM are Q = {q1 , . . . , q12 } (see Table 5.1), then the
coverage requirement above can be captured by the LTL
formula φe0 = ¬(∧9i=1 pi ), where each atomic proposition
pi is mapped to: O(p1 ) = Q × [120, +∞) × R, O(p2 ) =
Q × R × [4500, +∞), and p3 to p9 are mapped to a column
or a row in Table 5.1, e.g., O(p3 ) = {q1 , q5 , q9 } × R2 . Note
that we add the negation in φe0 because we are trying to
falsify the requirement.
The outcome of the S-TA L I RO appears in Fig. 3. The
Simulink model was simulated 41 times for this particular
test. As evident from the figure, the vehicle indeed reaches
the specified thresholds. Running the Simulink toolbox for
Model Coverage of Stateflow charts, we can also verify that
all the states were indeed visited.
△
Example 5.2: The second example concerns a more complex model of a powertrain system [20]. The system is modeled in Checkmate [21]. It has 6 continuous state variables
and 2 Stateflow charts with 4 and 6 states, respectively. The
Stateflow chart for the shift scheduler appears in Fig. 4.
The system dynamics and switching conditions are linear.
However, some switching conditions depend on the initial
conditions of the system. The latter makes the application
of standard hybrid system verification tools not a straightforward task.
The system is operating under constant road grade and
throttle position, which are the initial parameters for the
system. The challenge problem posed in [20] is to find values
for the initial parameters such that starting from 0 speed, the
gear transitions from second to first to second.
The LTL specification that captures the requirement for
switching between gears is: φe1 = ¬✸(g2 ∧ ✸(g1 ∧ ✸g2 ))
where g1 and g2 are the atomic propositions indicating that
the system operates in first and second gears, respectively.
That is, O(g1 ) = {1}×R6 and O(g2 ) = {3}×R6 . Note that
in this example, the atomic propositions do not constrain the
continuous state space. However, the information regarding
the switching conditions that enable a transition is utilized
in the hybrid distance metric for the robustness computation
of the specification (see [6]). Again, we are looking for
a trajectory that satisfies ¬φe1 . Since S-TA L I RO performs
falsification, the user must provide φe1 .
Throttle
100
50
0

0

5

10

15

20

25

30

RPM
5000

first_gear
entry: schedule = 1;
STaliro_StateVar = 1;

shift_speed12

to_first

shift_speed21
1

transition21_shifting
entry:schedule = 4;
STaliro_StateVar = 4;

2

2

transition12_shifting
entry : schedule = 2;
STaliro_StateVar = 2;

shift_speed12

1

shift_speed21

to_second
second_gear
entry: schedule = 3;
STaliro_StateVar = 3;

Fig. 4.

The shift scheduler of Example 5.2.

Applying S-TA L I RO to the above problem returns several
different initial parameters that generate trajectories that
falsify φ. Figure 5 displays the shifting schedule for initial
conditions throttle ≈ 18.8 and road grade ≈ 0.0663. Thus,
it is possible indeed to have a non-required change of gears.
However, note that specification φe does not pose any
restrictions between the timing of events. A more useful
property is that the gear change from second to first to
second should not happen within 2.5 sec, for example. The
requirement φe2.1 = ¬✸(g2 ∧ ✸(g1 ∧ ✸[0,2.5] g2 )) would not
work because we have to measure time since the first time
that event g1 happened. The subformula ✸(g1 ∧✸[0,2.5] g2 ) is
allowed to measure time from the last time that g1 occurred.
If we attempt to use the specification φe2.2 = ✷(g1 →
✸[2.5,+∞) g2 ), then φe2.2 would also not work since there
exist initial parameters that will force the vehicle to go
downhill and, thus, never switch to gear 2. That is, the
falsification is achieved simply because we do not switch
to gear 2. This implies that in terms of falsification we must
also require the system to switch to gear 2, i.e., φe2.2 =
✷(¬g2 ∨ ✷(g1 → ✸[2.5,+∞) g2 ). But, again the property may
be falsified simply because the duration of the simulation
time is short enough that g2 does not occur for a second
time. This requirement might also fail simply because the
last occurrence of g1 happens too close to the end of the
simulation that even though g2 occurs for the second time
the operator ✸[2.5,+∞) trivially evaluates to F because the
timing bounds are outside the time domain of the simulation.
If we were to restate the requirement that we are trying to
impose on the system, then we would specify that “whenever
the system enters state first gear, then it should not enter
4

0

0

5

10

15

20

25

30

3

Speed
200

2
100
0

1
0

Fig. 3.

5

10

15

20

25

30

The falsifying inputs/outputs of Example 5.1.

Fig. 5.

3571

0

10

20

30

40

50

60

The shift schedule falsifying requirement φe1 in Example 5.2.

4

off between the exhaustiveness of model-checking and the
scalability of techniques based on simulations.
Acknowledgments: The authors would like to thank
Hengyi Yang for his help with implementing DP-TA L I RO.

3

2

R EFERENCES
1

Fig. 6.

0

10

20

30

40

50

60

The shift schedule that falsifies requirement φe2 of Example 5.2.
Torque

3000
2000
1000
0

0

10

20

30

40

50

60

40

50

60

Shift Schedule
4
3
2
1

Fig. 7.

0

10

20

30

The torque signal that falsifies requirement φe3 of Example 5.2.

the state second gear within 2.5 sec”. This requirement is
formally captured by: φe2 = ✷((¬g1 ∧Xg1 ) → ✷[0,2.5] ¬g2 ).
Figure 6 presents a shift schedule that falsifies formula φe2 .
For this specification, the initial conditions were throttle
≈ 93.9 and road grade ≈ 0.2453 and S-TA L I RO used
742 simulations. We remark that on an Intel Core Duo at
3.33GHz with 4.00 GB RAM and Windows Vista 64-bit each
execution of the model takes about 3 sec and each robustness
computation about 0.02 sec.
Another property of interest for powertrain systems is
to verify that the jitter is within acceptable limits. This
specification can be captured by requiring that whenever
the system is in transition from gear 2 to gear 1, then the
derivative of the torque is within certain bounds, or formally,
φe3 = ✷(g21 → b) where O(g21 ) = {4} × R7 and O(b) =
{x ∈ R7 | x7 ≤ 450}. In this case, the approximation of
the derivative is outputted from the Simulink model and it
is appended to the output signals. A falsifying trajectory
that corresponds to initial parameters 91.86 and 0.2478 is
presented in Fig. 7 and it was derived after 245 tests.
△
VI. C ONCLUSIONS
In this paper, we presented how S-TA L I RO [10] – a
tool for the falsification of temporal logic properties of
hybrid systems – can be utilized for the verification of automotive applications. S-TA L I RO can be used for analyzing
Simulink/Stateflow models and it is publicly available [19].
We also demonstrated how improvements in the techniques
used to compute robustness using dynamic programming
techniques are key towards enhancing the performance of
the falsification technique, as a whole. We believe that
approaches along the lines of S-TA L I RO offer a good trade-

[1] J. Eker, J. Janneck, E. A. Lee, J. Liu, X. Liu, J. Ludvig, S. Sachs, and
Y. Xiong, “Taming heterogeneity - the ptolemy approach,” Proceedings of the IEEE, vol. 91, no. 1, pp. 127–144, Jan. 2003.
[2] J. Kapinski, B. H. Krogh, O. Maler, and O. Stursberg, “On systematic
simulation of open continuous systems.” in Hybrid Systems: Computation and Control, ser. LNCS, vol. 2623. Springer, 2003, pp. 283–297.
[3] M. Branicky, M. Curtiss, J. Levine, and S. Morgan, “Sampling-based
planning, control and verification of hybrid systems,” IEE Proc.Control Theory Appl., vol. 153, no. 5, pp. 575–590, 2006.
[4] A. Bhatia and E. Frazzoli, “Incremental search methods for reachability analysis of continuous and hybrid systems,” in Hybrid Systems:
Computation and Control, ser. LNCS, vol. 2993. Springer, 2004, pp.
142–156.
[5] T. Nahhal and T. Dang, “Test coverage for continuous and hybrid
systems,” in CAV, ser. LNCS, vol. 4590. Springer, 2007, pp. 449–
462.
[6] H. Abbas, G. E. Fainekos, S. Sankaranarayanan, F. Ivancic, and
A. Gupta, “Probabilistic temporal logic falsification of cyber-physical
systems,” ACM Transactions on Embedded Computing Systems, vol.
(In Press), 2011.
[7] T. Nghiem, S. Sankaranarayanan, G. E. Fainekos, F. Ivancic, A. Gupta,
and G. J. Pappas, “Monte-carlo techniques for falsification of temporal
properties of non-linear hybrid systems,” in Proceedings of the 13th
ACM International Conference on Hybrid Systems: Computation and
Control. ACM Press, 2010, pp. 211–220.
[8] G. E. Fainekos and G. J. Pappas, “Robustness of temporal logic specifications for continuous-time signals,” Theoretical Computer Science,
vol. 410, no. 42, pp. 4262–4291, 2009.
[9] R. Koymans, “Specifying real-time properties with metric temporal
logic.” Real-Time Systems, vol. 2, no. 4, pp. 255–299, 1990.
[10] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan, “S-taliro: A tool for temporal logic falsification for hybrid
systems,” in Tools and algorithms for the construction and analysis
of systems, ser. LNCS, vol. 6605. Springer, 2011, pp. 254–257.
[11] Y. S. R. Annapureddy and G. E. Fainekos, “Ant colonies for temporal
logic falsification of hybrid systems,” in Proceedings of the 36th
Annual Conference of IEEE Industrial Electronics, 2010, pp. 91–96.
[12] S. Sankaranarayanan and G. Fainekos, “Falsification of temporal
properties of hybrid systems using the cross-entropy method,” in
ACM International Conference on Hybrid Systems: Computation and
Control, 2012.
[13] G. Rosu and K. Havelund, “Synthesizing dynamic programming
algorithms from linear temporal logic formulae,” RIACS, Tech. Rep.,
2001.
[14] Q. Zhao, B. H. Krogh, and P. Hubbard, “Generating test inputs for
embedded control systems,” IEEE Control Systems Magazine, vol.
Aug., pp. 49–57, 2003.
[15] E. Plaku, L. E. Kavraki, and M. Y. Vardi, “Falsification of ltl safety
properties in hybrid systems,” in Proc. of the Conf. on Tools and
Algorithms for the Construction and Analysis of Systems (TACAS),
ser. LNCS, vol. 5505. Springer, 2009, pp. 368 – 382.
[16] A. Donze and O. Maler, “Robust satisfaction of temporal logic over
real-valued signals,” in Formal Modelling and Analysis of Timed
Systems, ser. LNCS, vol. 6246. Springer, 2010.
[17] A. Rizk, G. Batt, F. Fages, and S. Soliman, “On a continuous degree
of satisfaction of temporal logic formulae with applications to systems
biology,” in International Conference on Computational Methods in
Systems Biology, ser. LNCS, vol. 5307. Springer, 2008, pp. 251–268.
[18] P. Thati and G. Rosu, “Monitoring algorithms for metric temporal
logic specifications,” in Runtime Verification, ser. ENTCS, vol. 113.
Elsevier, 2005, pp. 145–162.
[19] TaLiRo Tools. [Online]. Available: https://sites.google.com/a/asu.edu/
s-taliro/
[20] A. Chutinan and K. R. Butts, “Dynamic analysis of hybrid system
models for design validation,” Ford Motor Company, Tech. Rep., 2002.
[21] B. I. Silva and B. H. Krogh, “Formal verification of hybrid systems
using CheckMate: a case study,” in Proceedings of the American
Control Conference, vol. 3, Jun. 2000, pp. 1679 – 1683.

3572

2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)
Windsor Oceanico Hotel, Rio de Janeiro, Brazil, November 1-4, 2016

Utilizing S-TaLiRo as an Automatic Test Generation Framework for
Autonomous Vehicles
Cumhur Erkan Tuncali, Theodore P. Pavlic and Georgios Fainekos
Abstract— This paper proposes an approach to automatically generating test cases for testing motion controllers of
autonomous vehicular systems. Test scenarios may consist of
single or multiple vehicles under test at the same time. Tests
are performed in simulation environments. The approach is
based on using a robustness metric for evaluating simulation
outcomes as a cost function. Initial states and inputs are
updated by stochastic optimization methods between the tests
for achieving smaller robustness values. The test generation
framework has been implemented in the toolbox S-TaLiRo.
The proposed framework’s ability to generate interesting test
cases is demonstrated by a case study.

I. I NTRODUCTION
Driver Assistance Systems (DAS) like lane keeping, adaptive cruise control, pedestrian/obstacle collision avoidance,
automatic lane change, emergency braking systems and many
more are being used in high-end modern automotive systems.
Prototype autonomous vehicles have already driven more
than a million miles on the roads. However, ensuring safe
operation of these vehicles will require intensive testing
in various scenarios, which will be a major challenge. As
addressed by Bengler et al. [1], testing autonomous vehicles
is a challenging problem which can not be efficiently handled
with conventional approaches. According to Maurer and
Winner [2], considering the pace of functional growth in
DAS, lack of efficient testing can affect time-to-market for
more advanced systems like fully autonomous vehicles.
Because tests involving autonomous vehicles would comprise test cases which may lead to collisions or near collisions, performing many tests with actual vehicles ending
with collisions would not be economically efficient and
practical. An alternative for testing these systems is using
computer simulations for the vehicles and their surroundings.
However, manually creating test scenarios with large number
of different environmental settings and road conditions would
be difficult and highly time consuming. Furthermore, in
order to extract the limits of the systems under design,
engineering teams would like to discover the behaviors on
the boundary between safe and unsafe operations. Creating
test cases manually for detecting the boundary conditions
which barely cause collisions like fender-benders may be a
challenging job. We believe that automatic test generation
frameworks utilizing simulations are crucial for the future of
This work has been partially supported by awards NSF CNS 1446730
and NSF CNS 1350420
C.E. Tuncali, T.P. Pavlic, and G. Fainekos are with School of Computing,
Informatics and Decision Systems, Arizona State University, Tempe, AZ
85281, USA
(e-mail:{etuncali, tpavlic, fainekos}@asu.edu)

978-1-5090-1889-5/16/$31.00 ©2016 IEEE

autonomous vehicle testing. Such frameworks would produce
large number of tests generated in an intelligent way and
help engineering teams to discover unforeseen scenarios that
could lead to failure.
Although discovering potential problems by testing in the
simulation environments would be beneficial, due to the
inevitable differences in the simulation environments and the
real-world, some test cases that do not fail in simulations may
fail in the real-world or vice versa. So, instead of getting
pass/fail results from the tests, using a metric that indicates
how close each test result is to a failure case, similar to phase
and gain margins in control theory [3], would be more useful.
With availability of such a metric, engineering teams can run
large number of tests in faster simulation environments and
after (automatic) analysis of the test results, they can repeat
some scenarios in the real world using the methods described
in [4] or in much more accurate simulators that require more
computation power/execution time.
In this paper, we address the problem of creating an
automatic test generation framework for autonomous vehicle systems with a focus on collisions. Because of the
dynamics and possible physical limitations on the motion,
an autonomous vehicle cannot be expected to be collision
free for every possible situation. For instance, it may not be
possible to avoid a collision with a vehicle cutting in front at
a very short distance or with a vehicle approaching very fast
from a side. Our main focus is to find the conditions on the
boundary between safe scenarios and collision scenarios. Our
approach is based on running simulations, using simulation
results to compute a robustness value that shows how close a
system trajectory gets to an unsafe set of states and utilizing
optimization methods to seek smaller robustness values by
changing initial states and inputs for the system for the next
test case.
II. R ELATED W ORK
State of the art in testing advanced DAS is discussed by
Stellet et al. [5]. They categorize the main principles for
a testing framework as: (i) derivation of test criteria and
metrics, (ii) establishing a reference system as the ground
truth information and (iii) generation of test scenarios. The
use of robustness metric in our approach falls into the category (i) per their taxonomy. Simulation environment itself
can be considered as the category (ii), and the optimization
engine for S-TaLiRo that is used to create test trajectories can
be considered as the category (iii) based on the discussions
in that work. Our robustness metric definition can be a
candidate to quantitatively measure safety of autonomous

1470

vehicles against collisions. S-TaLiRo provides methods for
automatic, high throughput testing of fully autonomous vehicles inside simulations that can cover complex real-world
traffic situations.
A vehicle in the loop (VIL) test setup is presented by Bock
et al. [6]. They discuss the advantages of using simulators
for testing DAS. Their approach is based on having a human
driver in a simulator and using conventional methods for
generation of test cases.
Althoff et al. [7] propose an online formal verification
approach for autonomous vehicles. The approach proposed
in that work is based on reachability analysis for the ego
vehicle, i.e., the vehicle under control, and other participants
on the road. They compute the reachable sets and occupancy
of the ego vehicle for reference trajectories and claim that
the reference trajectory is safe if occupancy of the ego
vehicle does not exit drivable area nor intersect with the other
participants on the road. They assume that other participants
obey the traffic rules. However, in [7], they are only considering verification of planned trajectories and executing the
trajectories that are deduced to be safe. In contrast, the test
results with our approach give an idea on how the mistakes
of other vehicles in the traffic are handled by the ego vehicle
which is a valid concern for traffic environments consisting
of both autonomous and non-autonomous vehicles.
Our approach is complementary to the VIL testing, online
verification and testing with real vehicles [4], as it will
suggest important and challenging test-cases for existing
methods.
III. P ROBLEM D EFINITION
We denote the set of autonomous Vehicles Under
Test (VUT) by V = {v1 , . . . , vp }, surroundings for the
VUT by S = {s1 , . . . , sq }, and the set of dummy actors
by D = {d1 , . . . , dr }. In more detail, the vehicles in the set
V are simply Cyber-Physical Systems (CPS) which are to
be tested either partially, e.g., controller only, or as a whole.
The surroundings S consist of the environmental settings
like road network, weather and road conditions, traffic rules
and special zones. The set D of dummy actors, i.e., the
mobile or immobile objects in the surroundings, may contain
dummy vehicles, pedestrians, obstacles, etc., optionally with
controllers that can give them mobility. The dummy actors
physically interact with the VUT and they are typically used
to trick the VUT in various test scenarios.
The initial state vectors for the VUT in V, the surroundings S and dummy actors D are respectively denoted
by x0,V , x0,S , and x0,D . The range of initial values for
the ith state of the k th entity in a set V, S, or D,
is denoted by Rvki , Rsik , Rdik , respectively. These ranges
define the domains for the initial state vectors. For instance,
|V|
Q
Q
and × denote
x0,V ∈
(Rvk1 × . . . × Rvσk ), where
k=1

k

Cartesian product, |V| is the number of elements in V and
σk is the number of states for vk ∈ V. We denote the
concatenation of the initial state vectors x0,V , x0,S , and
x0,D , i.e., the initial state for the overall setup, by x0 .

Abbas et al. [8] parameterize input signals u(t) over a
bounded time domain R, by the parameter vectors λ =
[λ1 . . . λm ]T ∈ Λ, τ = [τ1 . . . τm ]T ∈ Rm , where Λ is a
compact set, τi < τj for i < j, such that for all t ∈ R,
u(t) = U(λ, τ )(t) ∈ R. The function U(λ, τ ) returns a
function which is parameterized by λ and τ . For instance, U
could represent the space of functions parameterized using
splines [9]. We slightly modify the notation used in that work
to allow inputs to be functions of the states of the system,
not only signals over time. Hence, we allow the set R in the
above notation to be the bounded domain of any variable
which can be a state of the system or time. We use the
notation uV , uS , uD for the vectors of input functions for
the entities in V, S, D, respectively. Each entry of these input
vectors is a tuple (λ, τ, U), i.e., parameterization vectors and
a choice of interpolation function, corresponding to an input
for an entity of V, S, or D. We denote the input functions
for the overall simulation setup by u.
We define a simulation over V, S and D as a function ΣV,S,D : X̄0 × Λ̄ × R̄ 7→ Rn×k where X̄0 defines the
domain for the initial states, Λ̄ and R̄ define the domain for
the λ and τ parameters of all the input functions respectively,
k is the number of simulation steps and n is the total number
of outputs generated by the elements of V, S and D.
The problem we target is to compute:

R ΣV,S,D x0 , ū(λ̄, τ̄ )
(1)
(x∗0 , ū∗ ) =
arg min
x0 ∈X̄0 ,λ̄∈Λ̄,τ̄ ∈R̄

where R : Rn×k 7→ R is defined as a robustness (cost)
function, λ̄ is the vector of λ parameters and τ̄ is the vector
of τ parameters for all the inputs. The vector ū contains all
input functions, and it is obtained by applying the interpolation function U(λ, τ ) for each input to the corresponding
parameter vectors λ, τ from the selected vectors λ̄, τ̄ .
In other words, for a given simulation function, a set of
vehicles under test, a set of dummy objects, surroundings
information and constraints on state space and input space,
we are seeking the particular inputs and initial states for the
simulation that would minimize a robustness function.
Careful selection of a robustness function is important
for (quickly) finding initial states and input signals which
lead to critical operating points of the system under test like
boundaries between safe and unsafe behavior.
IV. S OLUTION OVERVIEW
A simplified overview of the architecture of our approach
is illustrated in Fig. 1. The main components of the vehicular
systems testing framework that we propose are the optimization engine of S-TaLiRo, a simulation engine, a robustness
evaluation function and a simulation configuration.
A. S-TaLiRo
S-TaLiRo [10] is a M ATLAB [11] toolbox for systematic
testing of hybrid systems, i.e., the systems that exhibit continuous and discrete dynamics. It uses a robustness metric that
represents how far a system trajectory is from falsifying formal system requirements. In particular, negative robustness

1471

S-TaLiRo
(optimization engine, stochastic sampler, input generator )
Initial conditions
& Inputs

Configuration

Simulation
configuration
Fig. 1.

Configuration

Simulation
engine

Output trace

Robustness
measure

Robustness
evaluation
function

An Overview of the Framework Architecture

values mean a requirement is falsified, i.e., conditions have
been found under which the system does not satisfy a requirement. S-TaLiRo uses one of various global optimization
methods for minimizing the robustness function [10] and,
thus, for seeking a falsifying system trajectory. We utilize
S-TaLiRo for solving the problem defined in Section III,
basically for intelligently sampling initial states and input
functions that will be applied to the simulations.
First, a sample space is created from the user defined input
and/or initial state configuration. Then, an initial states vector
and an input functions vector are sampled from the generated
sample space. The simulation of the vehicular systems is executed for a predefined amount of time with the selected initial
states and inputs. As illustrated in Fig. 1, the simulation
engine returns the simulation output trajectory which consists
of states and/or outputs of the simulated system(s) for each
time step of the simulation. The output trajectory obtained
from the simulation is supplied to the robustness evaluation
function that returns a real-valued robustness measure as
an evaluation of how close the simulation results are to
an unsafe set of states. The obtained robustness measure is
used by the optimization engine and the stochastic sampler
in S-TaLiRo for generation of the inputs and initial states
for the next simulation with an attempt to obtain smaller
robustness values. This cycle of input generation, simulation
and robustness evaluation continues until either a negative
robustness value is achieved or the maximum number of
simulations is reached which we use as the termination
conditions for the optimization problem given in (1).
B. Simulation Configuration
Simulation configuration is used to parameterize a wide
range of classes of systems and scenarios. The automated
test generation proceeds by sampling points from this parameterized space as explained above. A test scenario can
be described in a simulation configuration with a focus on a
function with different types of systems and environments.
Referring to the definitions given in Section III, a simulation configuration is basically a structure describing the
sets V, D, S, and the initial state and input spaces X̄0 and
Ū = Λ̄ × R̄. The space for the initial states is described
by supplying the ranges for each initial state, e.g., Rvσk ,
i
and the space for the inputs is described by supplying the
parameterization, i.e., (λ, τ, U) as detailed in Section III. The
simulation configuration can further constraint the relations
between the initial states and inputs.

A typical configuration contains environmental parameters, the number of vehicles in the simulation and parameters
for each vehicle. Some examples to the environmental parameters could be wind, road incline, lane width, number of
lanes, inputs and states of the environment. Vehicle-related
parameters can be mass, tire-friction, ranges of initial states
and inputs, function handles that describe dynamics of these
vehicles or controllers for the vehicles. These are only some
examples and the actual parameters must be completely
defined by the user in accordance with the user supplied
simulation engine and the robustness evaluation function.
C. Simulation Engine
The simulation engine can be a M ATLAB function,
a S IMULINK [11] model or any external simulator like
W EBOTS [12] or C AR S IM [13] that can be wrapped by a
M ATLAB function. The simulation engine must be able to
accept inputs described in the configuration, and it must
return the computed states and/or outputs for each time
step of the simulation. Because the simulation configuration
is available to the simulation engine, the user can freely
parameterize the simulation engine in the desired level of
detail in accordance with the testing purposes.
Here, we recall the definition of a simulation function
given in Section III as ΣV,S,D : X̄0 × Ū 7→ Rn×k . In summary, the simulation engine first initializes the models and/or
controller functions of the VUT in the set V, surroundings S
and the dummy actors D with given initial states. Then, it
executes these models/controllers with respect to the given
inputs while considering the interactions of the entities in the
above sets with each other.
D. Robustness Evaluation Function
The robustness evaluation function is used as a cost
function in the optimization engine of S-TaLiRo. It can either
be supplied by the user or used from robustness computation
implementations with respect to temporal logic specifications
available in S-TaLiRo [14].
In a simulation setup, as the number of variable parameters
increase, the space created by these parameters can be very
large. Testing every combination over such a large space
and finding falsifying behaviors is infeasible in most cases.
Because S-TaLiRo is based on optimization over robustness,
the obtained robustness values from different simulations are
expected to guide the search towards a failure as opposed to
completely random selection of test cases. It should be noted
that the choice of the robustness evaluation function plays an
important role for better guidance.
A robustness evaluation function must return smaller robustness values as we approach to the most interesting failing
system behavior that we seek for. If a negative robustness
value is obtained, S-TaLiRo immediately stops and returns
the related trajectory as a falsifying trajectory. Otherwise,
the search for smaller robustness value over trajectories
continues until a given maximum test count is reached.
In this work, we mainly focus on testing autonomous
vehicles against collisions in an environment where some

1472

vehicles may follow trajectories that can lead to dangerous
situations. Furthermore, we seek the conditions, i.e., initial
states and input signals, that lead to near collisions. Hence,
we design a robustness evaluation function so that the
boundaries between safe and unsafe behavior can be reached
by minimizing the robustness function. Here, we will propose
a robustness evaluation function that can be applicable to a
wide range of setups for testing autonomous vehicles with
a purpose of detecting collisions and/or the situations where
vehicles exit a predefined drivable area.
For a collision instance between two vehicles with velocities ~v1 and ~v2 at the time of collision, we compute
the severity of the collision as k~v1 − ~v2 k, where k · k is
the Euclidean norm. When a collision involving a VUT is
detected in a simulation output trajectory y, we compute
vcoll,y as the collision severity at the moment of the first
collision experienced in y.
If there is no collision involving a VUT in a simulation
output trajectory, we use a safety measure called Time-ToCollision (TTC) [15]. The TTC is the time required for two
vehicles to collide when they are on a collision path. Being
on a collision path for two vehicles means that they will
collide if they continue their current motion. In particular,
the TTC for two vehicles that are not on a collision path is
infinite. We use the looming points approach described by
Ward et al. [16] for collision path and TTC computations.
The minimum TTC experienced between any two vehicles
during a simulation trace y is denoted by ttcmin,y .
Note that we can use collision severity and TTC metrics
for testing against a vehicle exiting the drivable area. Considering the boundaries of drivable areas as stationary objects,
e.g., a wall, TTC or collision severity with these objects can
be computed in a similar manner by taking the velocity of
the objects as a zero vector.
Because we search for the boundary between safe and
unsafe operations, we can consider a collision where vehicles
barely touch each other with zero difference in velocities
as the boundary case that we seek. Hence, a collision with
high relative velocity between the vehicles must have a larger
robustness value compared to a collision with low relative
velocity. In addition, a simulation trace with no collision
must have larger robustness value compared to a simulation
result involving a collision. Our proposed robustness function
R(y) for a simulation trace y is given below:
(
R(y) =

vcoll,y − v
ttcmin,y + vcoll,max

, collision detected in y
, otherwise.
(2)

where vcoll,max is the maximum possible relative collision
velocity and v is a user defined nonnegative real-valued
number representing the minimum collision severity of concern. Whenever the framework achieves a collision with
a severity smaller than v , the robustness value will be
negative and the search will be terminated. In particular,
setting v to zero means that we are seeking the collisions
with the vehicles barely touching each other. However, in this

case, the search will continue until the maximum number of
simulations is reached and the detected minimum robustness
value will be returned.
We assume that we know maximum possible velocity for
all the objects in the simulation which is denoted by vmax .
The maximum collision velocity in a simulation can be
experienced between two vehicles traveling at the maximum
speed in opposite directions. Hence, vcoll,max = 2vmax .
V. C ASE S TUDY
As a case study, we use the simulation engine with the
simulation configuration described below and the robustness
function in (2). S-TaLiRo is configured to use the simulated
annealing method [17].
A. Simulation Configuration for the Case Study
Our case study consists of two VUT in the set V and
a dummy vehicle in the set D on a straight two-lane road
that is described in S. The inputs to the simulation are the
target speed functions for the VUT and target speed and
lateral position functions for the dummy vehicles. Target
speed functions are defined over time, and the target lateral
position function is defined over the longitudinal position
state of the dummy vehicle.
One of the VUT is following the other on a straight
target trajectory on the right lane of a two-lane road. The
dummy vehicle has a trajectory which starts on the left lane
of the road and changes to the right lane after a distance
chosen by the testing algorithm. The target position of the
dummy vehicle inside a lane is varying over the course of
the simulation and the lane change position is also sampled
from a predefined longitudinal position range.
The shape and dimensions of the vehicles are described in
the configuration as the critical points, e.g., corners, of the
vehicles. These points are used to detect collisions and also
used in the looming points method [16] to check collision
paths and to compute the TTC values.
B. Simulation Engine for the Case Study
For the simulation of the VUT, we use a vehicle dynamics
model from the literature [18], [19]. To accurately represent
the dynamics of the VUT, we use relatively complex dynamical models that are costly to compute during simulation.
However, it is not computationally practical to use dynamical
models of similar complexity for the dummy vehicles that
are merely meant to generate reasonable test trajectories to
challenge the VUT. Furthermore, the actual controllers on
the dummy vehicles will be out of the control of the tester,
and so all that is necessary for the dummy vehicles is to
capture the salient features of realistic vehicles in simulation.
Consequently, for the dummy vehicles, we use simpler
kinematic models and controllers. The kinematic model we
use for the dummy vehicle in our case study is described by
Walsh [20]. We have implemented our simulation engine for
the case study as a M ATLAB function.

1473

C. Sensor Setup
We describe the sensors on the vehicles by their orientation, range, maximum sensing angle and position with
respect to the center of mass of the vehicle. In our case
study, we use a sensor setup for side collision avoidance. The
vehicles under test have one distance sensor in front with a
range of 40 m and 10◦ sensing angle and one distance sensor
on the left side with a range of 3 m and 45◦ sensing angle.
The sensor placement and orientation is illustrated in Fig. 2.
The rectangle in the figure represents the top view of the
vehicle where the tip of the arrow on the rectangle is towards
the front of the vehicle. This sensor configuration is used
to test the framework’s ability to detect possible collisions
resulting from the corresponding blind spots.
D. Vehicle Controller with Collision Avoidance
We have implemented a controller with basic forward
and side collision avoidance capabilities by merging two
controllers from the literature. For steering control, we used
the Stanford’s Racing Team’s approach [21] for the DARPA
Grand Challenge 2005. For the longitudinal control, we
used the model predictive convoy controller from Liu and
Ozguner [22]. A reactive planner generates a target path
based on the input target speed and the forward and side
distance sensor data. The generated target path and the input
target speed are supplied to the controller, which generates
force and steering inputs. We use this controller and the
simulation setup only for demonstrating our framework, and
we do not claim any performance or accuracy guarantees for
the controller or the simulator.
We describe the target speed for the VUT as an input
signal chosen by the testing algorithm in a predetermined
range [5, 15] m/s over the simulation time. The target lateral
position for the VUT is the midpoint of the right lane.
However, because the VUT controller has collision avoidance
capabilities, the target lateral positions for the vehicles are
updated during run-time based on the sensor data.
E. Motion Controller for the Dummy Vehicle
The target trajectory for the dummy vehicle is described
by two input functions for S-TaLiRo. One input function
is the target speed for the vehicle. We define the target
speed as a signal with a predefined number of control
points, i.e., the parameter τ described in Section III, equally
distributed over the simulation time. We set the lower and
upper limits, i.e., the domain for the parameter λ described
in Section III, for the target speed at each control point.
Piecewise cubic Hermite interpolating polynomial (pchip)
interpolation [23] function that is available in M ATLAB [11]
is used for interpolation between the control points, i.e., the
U described in Section III. Thus, the target speed for the
dummy vehicle is a signal interpolated between the values
chosen by the test algorithm from a given range.
The other input function for the dummy vehicle describes
its target lateral position. We describe this input with respect
to the vehicle’s longitudinal position state instead of the
simulation time. We use 4 control points for this function

where the first and the last
control points are located at
positions 0 m and 300 m in
the longitudinal axis. The locations for second and third
Fig. 2. Sensor Placement
control points are chosen by
the test algorithm between these positions with a constraint
for the distance between two consecutive control points to
be at least 5 m. The value ranges for the control points are
the limits of the left lane for the first two control points
and the limits of right lane for the remaining control points.
This describes a trajectory that starts at the left lane and then
changes to the right lane. The lateral position inside the lanes
varies between the selected values by the test algorithm.
For the dummy vehicle, as opposed to the VUT, we have
implemented a PID controller for tracking the target speed instead of the costly model predictive controller. As discussed
in subsection V-B, the controller for the dummy vehicle is
only used for roughly following the trajectory proposed by
the tester that will be used to challenge the VUT.
F. Experimental Results
As stated in subsection V-C, we intentionally created a
blind spot in the sensor setup for the VUT. During our
experiments, the framework successfully detected failure
cases caused by this weakness. Fig. 3 illustrates a near
collision where the VUT (at the bottom-right of the figure)
avoids a side collision in the first place and then collides with
the dummy vehicle when returning back to its lane. In this
case, the VUT first avoids the side collision by changing its
lateral position and slowing down. However, after avoiding
the side collision it loses track of the dummy vehicle because
of the blind spot. Hence, the VUT does not continue slowing
down although it should have. Furthermore, it starts making
the maneuver to return to its lane. As a consequence, it
barely touches the dummy vehicle at its rear-right corner.
The final parts of the vehicle trajectories are displayed as
traces behind the vehicles in Fig. 3. The second VUT, i.e.,
the one on bottom-left of the figure, is following the VUT
that had a collision. This VUT is far from the collision
scene, and it is not affected by the collision. There are
additional collisions detected by the framework, and all of
them are returned to the user for further analysis; however,
this was the collision with the minimum robustness value
returned by S-TaLiRo, which makes it an interesting case at
a boundary between safe and unsafe operation. The sampled
input parameters and the generated input function as the
target lateral position of the dummy vehicle leading to the
collision is given in Fig. 4. The τ parameters are defined

1474

Fig. 3.

History of the Vehicles Before a Collision Instance

Fig. 4.

The Input for Target Lateral Position of the Dummy Vehicle

over the longitudinal position state of the dummy vehicle,
and the λ parameters are the target lateral positions for the
corresponding τ parameters. For this case study, the (τ, λ)
samples that led to the collision of concern are (0.0, 1.95),
(121.2, 1.83), (148.2, −1.15), (300.0, −1.11).
R
We have run our experiments on a Windows
PC with an
R

TM
Intel Core i7-4790 CPU and 16GB RAM. A simulation
of 32 s of the described test setup takes 18 s physical time
on our setup. The above failure condition was detected in
100 simulations. Even though the convergence to the global
minimum robustness value is guaranteed with simulated annealing [17], our stochastic approach provides no guarantee
on the number of simulations required to achieve the global
minimum. In general, the execution time of one simulation
in the proposed framework depends on the complexity of
the vehicle ODEs and controllers. The overall worst case
execution time for the framework grows linearly with the
maximum number of simulations chosen by the user.
VI. C ONCLUSIONS
We proposed an approach for automatic simulation based
testing of autonomous vehicle controllers that is guided by
a robustness metric. We believe that the optimization over
robustness for test guidance is a promising approach for
testing cyber physical systems in general [24].
As a future work, we plan to extend the capabilities of
our framework by extracting the conditions leading to unsafe
behavior from the simulations and use them for training a
model for estimating the probability of future collisions.
The trajectory generation for dummy vehicles in our
framework is based on the boundaries described by the
user. The generated trajectories are then tracked by the usersupplied controllers. Nagy et al. [25] propose a method for
generating trajectories for mobile robots that can be easily
tracked by a real vehicle. Although the final trajectories
followed by the controllers are realistic in our framework,
utilizing the approach described in that work can allow using
the trajectories directly without the need for a controller to
track them. As another future work, we plan to incorporate
such a method for trajectory generation.
R EFERENCES
[1] K. Bengler, K. Dietmayer, B. Farber, M. Maurer, C. Stiller, and
H. Winner, “Three decades of driver assistance systems: Review
and future perspectives,” Intelligent Transportation Systems Magazine,
IEEE, vol. 6, no. 4, pp. 6–22, 2014.
[2] M. Maurer and H. Winner, Automotive systems engineering. Springer,
2013.

[3] K.-W. Han and C.-H. Chang, “Gain margins and phase margins for
control systems with adjustable parameters,” Journal of guidance,
control, and dynamics, vol. 13, no. 3, pp. 404–408, 1990.
[4] H. Winner, S. Hakuli, F. Lotz, and C. Singer, Handbook of Driver
Assistance Systems: Basic Information, Components and Systems for
Active Safety and Comfort. Springer, 2015.
[5] J. E. Stellet, M. R. Zofka, J. Schumacher, T. Schamm, F. Niewels,
and J. M. Zollner, “Testing of advanced driver assistance towards
automated driving: A survey and taxonomy on existing approaches and
open questions,” in Intelligent Transportation Systems (ITSC), 2015
IEEE 18th International Conference on. IEEE, 2015, pp. 1455–1462.
[6] T. Bock, M. Maurer, and G. Farber, “Validation of the vehicle in
the loop (VIL); a milestone for the simulation of driver assistance
systems,” in Intelligent Vehicles Symposium, 2007 IEEE. IEEE, 2007,
pp. 612–617.
[7] M. Althoff and J. M. Dolan, “Online verification of automated road
vehicles using reachability analysis,” Robotics, IEEE Transactions on,
vol. 30, no. 4, pp. 903–918, 2014.
[8] H. Abbas, G. Fainekos, S. Sankaranarayanan, F. Ivančić, and A. Gupta,
“Probabilistic temporal logic falsification of cyber-physical systems,”
ACM Transactions on Embedded Computing Systems (TECS), vol. 12,
no. 2s, p. 95, 2013.
[9] M. Egerstedt and C. Martin, Control Theoretic Splines: Optimal
Control, Statistics, and Path Planning. Princeton University Press,
2009.
[10] Y. Annpureddy, C. Liu, G. Fainekos, and S. Sankaranarayanan, “Staliro: A tool for temporal logic falsification for hybrid systems,” in
International Conference on Tools and Algorithms for the Construction
and Analysis of Systems. Springer, 2011, pp. 254–257.
[11] MATLAB, version 9.0.0 (R2016a).
Natick, Massachusetts: The
MathWorks Inc., 2016.
[12] O. Michel, “WebotsTM : Professional mobile robot simulation,” arXiv
preprint cs/0412052, 2004.
[13] Mechanical Simulation, “CarSim,” 2016. [Online]. Available:
http://www.carsim.com/
[14] G. E. Fainekos and G. J. Pappas, “Robustness of temporal logic specifications for continuous-time signals,” Theoretical Computer Science,
vol. 410, no. 42, pp. 4262–4291, 2009.
[15] J. C. Hayward, “Near-miss determination through use of a scale of
danger,” Highway Research Record, no. 384, 1972.
[16] J. Ward, G. Agamennoni, S. Worrall, and E. Nebot, “Vehicle collision
probability calculation for general traffic scenarios under uncertainty,”
in Intelligent Vehicles Symposium Proceedings, 2014 IEEE. IEEE,
2014, pp. 986–992.
[17] H. Abbas and G. Fainekos, “Convergence proofs for simulated annealing falsification of safety properties,” in Communication, Control,
and Computing (Allerton), 2012 50th Annual Allerton Conference on.
IEEE, 2012, pp. 1594–1601.
[18] K. Zhang, J. Sprinkle, and R. G. Sanfelice, “A hybrid model predictive
controller for path planning and path following,” in Proceedings of the
ACM/IEEE Sixth International Conference on Cyber-Physical Systems.
ACM, 2015, pp. 139–148.
[19] E. Narby, “Modeling and estimation of dynamic tire properties,”
Master’s thesis, Linkopings Universitet, Linkoping, 2006.
[20] G. Walsh, D. Tilbury, S. Sastry, R. Murray, and J.-P. Laumond, “Stabilization of trajectories for systems with nonholonomic constraints,”
Automatic Control, IEEE Transactions on, vol. 39, no. 1, pp. 216–222,
1994.
[21] G. M. Hoffmann, C. J. Tomlin, M. Montemerlo, and S. Thrun,
“Autonomous automobile trajectory tracking for off-road driving:
Controller design, experimental validation and racing,” in American
Control Conference, 2007, pp. 2296–2301.
[22] P. Liu and U. Ozguner, “Predictive control of a vehicle convoy considering lane change behavior of the preceding vehicle,” in American
Control Conference (ACC), 2015. IEEE, 2015, pp. 4374–4379.
[23] F. N. Fritsch and R. E. Carlson, “Monotone piecewise cubic interpolation,” SIAM Journal on Numerical Analysis, vol. 17, no. 2, pp.
238–246, 1980.
[24] J. Kapinski, J. Deshmukh, X. Jin, H. Ito, and K. Butts, “Simulationguided approaches for verification of automotive powertrain control
systems,” in 2015 American Control Conference (ACC). IEEE, 2015,
pp. 4086–4095.
[25] B. Nagy and A. Kelly, “Trajectory generation for car-like robots using
cubic curvature polynomials,” Field and Service Robots, vol. 11, 2001.

1475

Math.Comput.Sci. (2011) 5:357–358
DOI 10.1007/s11786-011-0105-2

Mathematics in Computer Science

Foreword
Georgios Fainekos · Eric Goubault ·
Sylvie Putot · Stefan Ratschan

Published online: 4 December 2011
© Springer Basel AG 2011

1 Overview and Scientific Context of this Special Issue
For us, the subject of numerical software verification is the application of logical and mathematical techniques to
reasoning about numerical aspects of software. Which numerical aspects can software have? On the one hand, the
core numerical aspect of software is its usage of numerical data types, especially in the computation with floatingpoint numbers. On the other hand, models (i.e., abstract mathematical descriptions of a given system) play a more
and more important role in the development of software, and those models often have essential numerical aspects.
Those numerical aspects may model the software itself (e.g., control engineers often design controllers based on
ordinary differential equations, but then implement those controllers in digital software) or its physical environment
(e.g., timing constraints, energy consumption, physical laws governing the environment in a control loop).
The first four papers of this volume belong to the first category, and the final two papers to the second category.
The first two papers deal with the verification of the accuracy of computations achieved by numerical programs
that use finite precision date-types (floating-point numbers) to approximate computations in real numbers. Both
papers propose software tools to assess this accuracy. The diversity in the approaches indicates the difficulty of the
problem tackled.
The paper by Graillat and co-authors relies on stochastic arithmetic: the tool runs automatically, but can only
give some probabilistic estimation of the accuracy of the result. The paper by Boldo and Marché presents a tool
G. Fainekos
Arizona State University, Tempe, USA
e-mail: fainekos@asu.edu
E. Goubault · S. Putot
CEA LIST, Gif-sur-Yvette Cedex, France
e-mail: Eric.Goubault@cea.fr
S. Putot
e-mail: Sylvie.PUTOT@cea.fr
S. Ratschan (B)
Institute of Computer Science,
Academy of Sciences of the Czech Republic,
Prague, Czech Republic
e-mail: stefan.ratschan@cs.cas.cz

358

G. Fainekos et al.

chain that gives a formal proof of the accuracy: although some emphasis has been put on the mechanisation of this
proof, its use requires some expertise by the user. But the results are guaranteed.
An area where numerical computation plays a central role is high-performance scientific computing. In this
context, programs usually undergo various transformations with the purpose of optimization and parallelization. It
is important to know whether the outcome of such transformations is equivalent to the original program.
The two papers by Siegel and Zirkel push the boundaries along this line of research. Their first paper presents a
tool (Toolkit for Accurate Scientific Software—TASS) for verifying that a user-provided program that has undergone such transformations, is equivalent to the initial version of this program. One important feature of TASS is that
it can handle parallel programs that have been built using the Message Passing Interface (MPI). The second paper
by the same authors presents in detail a library of numerical programs in C. Each benchmark problem in the library
includes a sequential version of the numerical program and two parallel versions of the same code—one that has
known bugs and another which is a correct implementation. Such a library of benchmark problems can hopefully
facilitate research on the verification of scientific computation software.
A basic data type used by models in software development is the notion of a real function (i.e., a function whose
domain/codomain ranges over the real numbers): for example, certain quantities may evolve in time, and hence, for
modeling them, one uses functions in time. Classical numerical mathematics introduces round-off and discretization
errors when computing with functions, and then analyzes algorithms manually to study the propagation of those
errors. The resulting analysis may depend on unknown quantities (condition numbers), and hence, if not applied
carefully, may have unexpected and—in certain contexts—even catastrophic consequences.
An alternative approach is to enclose the correct computation result into sets, and to ensure that the set computed
in every step of an algorithm always includes the correct result. The paper by Collins and co-authors takes this
alternative approach, and develops a general framework and a library for correctly over-approximating computation
with real functions.
The topic of the final paper of this volume is the verification of hybrid automata. Such hybrid automata are an
important formalism for modeling software in some physical environment. Here, the numerical aspect is formed by
ordinary differential equations or inequalities, that can be used for both modeling controllers that will—in their final
form—be implemented in software, or the continuous behavior of some physical environment. While most verification problems for hybrid automata are undecidable, the paper identifies various classes of verification problems
that are decidable in polynomial, nondeterministic-polynomial, or exponential time.

2 Organizational Context
This journal volume represents a follow-up special issue to the Third International Workshop on Numerical Software
Verification (NSV-3) that took place as part of the Federated Logic Conference FLoC in 2010 in Edinburgh. The
predecessor instances of this workshop took place in St. Francisco (part of CPSWeek, 2009), and Princeton (held
with CAV 2008), and a further instance as part of CAV 2011 in Snowbird, Utah. The first NSV workshop resulted in
a special issue of the journal Formal Methods in System Design (volume 35, number 3), while the second one has
an accompanying special issue titled “Verification of Cyber-Physical Software Systems” that is currently in press,
and will appear in the ACM Transactions of Embedded Computing Systems.

2011 IEEE International Conference on Robotics and Automation
Shanghai International Conference Center
May 9-13, 2011, Shanghai, China

Revising Temporal Logic Specifications for Motion Planning
Georgios E. Fainekos

due to unreachable parts of the environment? Was it due to
some logical inconsistencies in the specification? Was it due
to the system dynamics?
In order to develop a truly user friendly temporal logic
planning system, we need to provide feedback to the user
when the planning stage fails. Or even better, we need to
recommend to the user specifications that are satisfiable
on our particular system and environment. Of course, such
recommendations cannot be arbitrary formulas which happen
to be satisfiable on our particular model (i.e., environment
and system). For example, it is easy to see that the specification “always true” is a valid formula which is true
on every possible model. Hence, these new specification
recommendations must be as close as possible to the original
intentions of the user.
In this paper, we provide a solution to exactly this problem.
That is, our foundational contribution is the definition of
the Linear Temporal Logic (LTL) formula revision problem.
For the solution of this problem, we define a partial order
over LTL specifications and we try to choose a formula that
relaxes the initial specification such that it is satisfiable on
the model and, at the same time, it is a minimal element in
the set of all satisfiable formulas on the model.
To the authors’ best knowledge, this problem has not been
discussed before in the literature. The closest related research
problem is query checking [11], [12]. In query checking,
given a model of the system and a temporal logic formula φ,
some subformulas in φ are replaced with placeholders. Then,
the problem is to determine a set of Boolean formulas such
that if these formulas are placed into the placeholders, then φ
holds on the model. The problem of LTL revision as defined
here is substantially different from query checking. For one,
the user does not know where to position the placeholders
in the formula when the planning fails.
Another related problem is the problem of revising a system model such that it satisfies a temporal logic specification
[13], [14]. Note that in this paper, we are trying solve the
opposite problem, i.e., we are trying to relax the temporal
logic specification such that it can be realized on the system.
The main motivation for our work is that the model of
the system, i.e., the environment and the system dynamics,
cannot be modified and, therefore, we need to understand
what we can be achieved with the current constraints.

Abstract— In this paper, we introduce the problem of automatic formula revision for Linear Temporal Logic (LTL) motion
planning specifications. Namely, if a specification cannot be
satisfied on a particular environment, our framework returns
information to the user regarding (i) why the specification
cannot be satisfied and (ii) how the specification can be modified
so it can become satisfiable. This work contributes towards
rendering temporal logic motion planning frameworks more
user friendly by providing feedback to the user when the LTL
planning phase fails.

I. I NTRODUCTION
During the last several years, there has been an explosion
of research that tries to bridge high level planning frameworks based on temporal logics with low level continuous
control primitives for autonomous robotics applications (see
[1]–[8] and the references therein). Temporal logics and, in
general, formal languages provide a mathematical framework
that facilitates reasoning about the correctness of synthesis
of hybrid systems such that complex system requirements
can be met. Essentially such complex specifications extend
well beyond traditional control requirements into a holistic
system design. The popularity of temporal logics over other
formalisms, e.g., regular languages, can be attributed mainly
to their resemblance to natural language. That property alone
makes temporal logics good candidates for expressing complex system requirements. Along these lines, one can even
develop computational interfaces between natural language
and temporal logics [9], [10]. Therefore, temporal logics
appear to be a suitable medium for our daily discourse with
future autonomous robots.
Nevertheless, one issue that has not been addressed so
far in the automata theoretic temporal logic planning frameworks is what happens when the high-level planning phase
fails. That is, when the temporal logic specification cannot
be realized in the current environment under the current
system dynamics, then the high-level synthesis framework
simply reports a failure. In detail, in temporal logic motion
planning frameworks such as in [1]–[3], the motion planning
problem is divided into two subproblems. First, the high
level planning problem is solved and, then, local feedback
controllers are composed. In detail, the high-level planning
phase can be reduced to a double nested Depth or BreadthFirst Search on a graph. If a goal state in the graph is not
reachable from the start state, then a plan that satisfies the
specification does not exist. Unfortunately, the user is left in
the dark as of why the specification failed. Was the failure

II. P ROBLEM F ORMULATION
In this work, we model the motion of the mobile robot
within its workspace using Finite State Machines (FSM)
[15]. This is a common practice in approaches that hierarchically decompose the motion planning problem into high

This work has been supported by an ASU startup fund.
G. Fainekos is with the School of Computing, Informatics and Decision
Systems Engineering, Arizona State University, Tempe, AZ 85281, USA

fainekos@asu.edu
978-1-61284-385-8/11/$26.00 ©2011 IEEE

40

In order to use discrete logics to reason about continuous
systems, we need to construct a finite partition of the robot’s
workspace1. For that purpose, we can use many efficient cell
decomposition methods for polygonal environments [19].
This results in a topological graph G = (Q, E) which
describes which cells are topologically adjacent, i.e., each
node q ∈ Q in the graph represents a cell and each edge
e = (q, q ′ ) ∈ E in the graph implies topological adjacency
of the cells. Each such cell will be a state in the FTS which
will be labeled by one or more atomic propositions from Π.
Next, we formally define the FTS that can be constructed
from the graph G.
Definition 1 (FTS): A Finite Transition System is a tuple
T = (Q, Q0 , →T , hT , Π) where: Q is a set of states; Q0 ⊆
Q is the set of possible initial states; →T = E ⊆ Q × Q is
the transition relation; and, hT : Q → P(Π) maps each state
q to the set of atomic propositions that are true on q.
We define a path on the FTS to be a sequence of states
and a trace to be the corresponding sequence of sets of
propositions. Formally, a path is a function p : N → Q
such that for each i ∈ N we have p(i) →T p(i + 1)
and the corresponding trace is the function composition
p̄ = hT ◦ p : N → P(Π). The language L(T ) of T consists
of all possible traces.
We now formally introduce LTL without the next time
operator as a specification language for defining the desired
robot behavior. We assume that we use only formulas in
Negation Normal Form (NNF) and that each negated atomic
proposition ¬π has been replaced by a new symbol, e.g. π,
which is added to Π. The details on why LTL in NNF is
equivalent to full LTL can be found in [1]. The use of LTL
in NNF greatly simplifies the technical results. However, in
general, formulae examples are easier to understand in full
LTL. Thus, in the following examples we will freely use the
negation operator.
Definition 2 (LTL Syntax): The set LT L(Π) of all LTL
formulas built over a set of atomic propositions Π is defined
recursively as φ ::= π | φ1 ∨ φ2 | φ1 ∧ φ2 | 3φ1 | φ1 Uφ2 |
2φ1 | φ1 Rφ2 for π ∈ Π and φ1 , φ2 ∈ LT L(Π).
In the following, we let (p̄, i) |= φ denote the satisfiability
of an LTL formula φ over a trace p̄ starting at time i. We
define the language L(φ) to be the set of all traces that satisfy
φ at time 0, i.e., L(φ) = {p̄ ∈ P(Π)ω | (p̄, 0) |= φ}.
Definition 3 (LTL Semantics): The semantics of any LTL
formula φ ∈ LT L(Π) is defined as (for i, j ∈ N):

level discrete planning synthesis and low level continuous
feedback controller composition [1], [3], [7]. Each state of
the FSM T is labeled by a symbol from a set Π = {π0 , π1 ,
. . . , πn } that represents a region in the robot’s workspace.
The user requirements or specifications are expressed
as Linear Temporal Logic (LTL) formulas [15]. In order
to make apparent the use of LTL for the composition of
temporal specifications, we first give an informal description
of the traditional and temporal operators. LTL formulas are
built over a set of atoms, the set Π in our case, using
combinations of the traditional and temporal operators. Traditional logic operators are the conjunction (∧), disjunction
(∨) and negation (¬). Some of the temporal operators are
eventually (3), always (2), until (U) and release (R).
LTL can describe the usual properties of interest for control
problems, i.e. reachability (3π) and safety: (2π or 2¬π).
Beyond the usual properties, LTL can capture sequences
of events and certain infinite behaviors. For example, for
repeatedly visiting regions π1 , π2 and π3 in that order, we can
write 23(π1 ∧3(π2 ∧3π3 )). Examples of more complicated
specifications can be found in [1], [3].
When a specification φ is not satisfiable on a particular
system T , then the current LTL motion planning [1], [3]
and control synthesis methods [16], [17] based on automata
theoretic concepts simply return that the specification is not
satisfiable without any other user feedback. The goal of this
paper is to develop methods for user feedback when the
automata theoretic LTL planning phase fails to return a plan.
Problem 1 (LTL Debugging and Revision): Given a system T and an LTL formula φ, if the specification φ cannot
be satisfied on T , then return to the user:
1) [Debugging] information on how the planning fails;
2) [Revision] a formula ψ which can be satisfied on T ;
3) [Minimal Revision] if possible, the closest formula ψ
to φ which can be satisfied on T .
Debugging has a straightforward solution and we are
simply going to make some remarks on our proposed solution
in the following discussion. However, the revision problem
is substantially more involved. In this paper, we make the
following fundamental contributions:
• First, we provide a formal definition of what it means
for two specifications to be close.
• Then, based on this definition, we provide algorithms
that automatically modify the initial specification φ and
provide as feedback to the user a new specification ψ
which can be realized on the system.
• We prove that ψ is a minimal formula when the planning
phase fails due to unreachable states in T .
• Finally, we pose an open problem regarding the efficient
computation of minimal revision in the general case.

(p̄, i) |= ⊤, (p̄, i) 6|= ⊥, (p̄, i) |= π iff π ∈ p̄(i)
(p̄, i) |= φ1 ∧ φ2 if (p̄, i) |= φ1 and (p̄, i) |= φ2
(p̄, i) |= φ1 ∨ φ2 if (p̄, i) |= φ1 or (p̄, i) |= φ2
(p̄, i) |= φ1 Uφ2 if there exists j ≥ i such that (p̄, j) |= φ2
and for all k with i ≤ k < j we have (p̄, k) |= φ1

III. T EMPORAL L OGIC M OTION P LANNING
In this section, we provide a brief review of the automata
based Linear Temporal Logic (LTL) [15] motion planning.
This is required in order to understand the new contributions
of this paper. Further details on automata based LTL planning
can be found in [1], [17], [18].

(p̄, i) |= φ1 Rφ2 if for all j ≥ i we have (p̄, j) |= φ2
or there exists k ∈ [i, j) such that (p̄, k) |= φ1
1 Similarly, such a finite partition can be constructed on the state space
of the system rather than the workspace. However, this only affects the
resulting FTS and, hence, the results in this paper still apply.

41

In this work, we are interested in the construction of
automata that only accept the traces of T which satisfy the
LTL formula φ. Such automata (which are referred to as
Büchi automata [15]) differ from the classic finite automata
in that they accept infinite strings (traces of T in our case).
Definition 4 (Automaton): A Büchi automaton is a tuple
B = (SB , s0B , Ω, λB , FB ) where: SB is a finite set of states;
s0B is the initial state; Ω is an input alphabet; λB : SB ×Ω →
P(SB ) is a transition relation; and FB ⊆ SB is a set of final
states.
A run r of B is a sequence of states r : N → SB that
occurs under an input trace p̄ taking values in Ω. That is,
for i = 0 we have r(0) = s0B and for all i ≥ 0 we have
r(i + 1) ∈ λB (r(i), p̄(i)). Let lim(·) be the function that
returns the set of states that are encountered infinitely often
in the run r of B. Then, a run r of a Büchi automaton B over
an infinite trace p̄ is accepting if and only if lim(r)∩FB 6= ∅.
Finally, we define the language L(B) of B to be the set of
all traces p̄ that have a run that is accepted by B.
For each LTL formula φ, we can construct a Büchi
automaton Bφ = (SBφ , s0Bφ , P(Π), λBφ , FBφ ) that accepts
the infinite traces which satisfy the specification φ, i.e.,
L(Bφ ) = L(φ). The translation from an LTL formula φ to
a Büchi automaton Bφ is a well studied problem and, thus,
we refer the reader to [15] and the references therein for the
theoretical details behind this translation.
Now that all the related terminology is defined, we can
give an overview of the basic steps involved in the temporal
logic planning [18]. In brief, our goal is to generate paths
on T that satisfy the specification φ. In automata theoretic
terms, we want to find the subset of the language L(T ) which
also belongs to the language L(Bφ ). This subset is simply the
intersection of the two languages L(T )∩L(Bφ ) and it can be
constructed by taking the product T × Bφ of the FTS T and
the Büchi automaton Bφ . Informally, the Büchi automaton
Bφ restricts the behavior of the system T by permitting only
certain acceptable transitions. Then, given an initial state in
the FTS T , we can choose a particular trace from L(T ) ∩
L(Bφ ) according to a preferred criterion.
Definition 5: The product automaton A = T × Bφ is the
automaton A = (SA , s0A , P(Π), λA , FA ) where:
• SA = Q × SB φ ,
• s0A = {(q0 , s0Bφ ) | q0 ∈ Q0 },
• λA : SA ×P(Π) → P(SA ) s.t. (qj , sj ) ∈ λA ((qi , si ), l)
iff qi →T qj and sj ∈ λBφ (si , l) with l ⊆ hT (qj ),
• FA = Q × F is the set of accepting states.
By construction, the following lemma is satisfied.
Lemma 1 (Adapted from [18]): A trace p̄ of T that satisfies the specification φ exists iff the language of A is nonempty, i.e., L(A) = L(T ) ∩ L(Bφ ) 6= ∅.
We say that φ is satisfiable on T if L(A) 6= ∅. Moreover,
finding a satisfying path on T × Bφ is an easy algorithmic
problem [15]. First, we convert automaton T × Bφ to a
directed graph and, then, we find the strongly connected
components (SCC) in that graph. If at least one SCC that
contains a final state is reachable from an initial state, then
there exist accepting (infinite) runs on T × Bφ that have a

finite representation. Each such run consists of two parts: a
part that is executed only once (from an initial state to a
final state) and a part that is repeated infinitely (from a final
state back to itself). Note that if no final state is reachable
from the initial or if no final state is within an SCC, then
the language L(T × Bφ ) is empty and, hence, the temporal
logic planning problem does not have a solution. Namely,
the planning phase has failed and we cannot find a system
behavior that satisfies the specification.
IV. R EVISING LTL S PECIFICATIONS
In many cases, it is possible that the specification φ cannot
be satisfied on the system T . Then, the question that is raised
is, if the specification φ is not satisfiable on our system, what
is the “closest” related specification φ′ that can be satisfied?
Being close to our initial specification φ is very important.
If we relax our specification too much, for example, if we
set φ′ = ⊤, then the specification becomes satisfiable on
our system no matter what. On the other hand, if we choose
an unrelated specification to φ which is satisfiable on our
system, then we do not really achieve our initial design
requirement. Therefore, we need first to define an ordering
relation between specifications and, then, try to choose one
that is as close as possible to the initial specification.
A. Closeness of LTL formulas
As a natural ordering relation between LTL formulas,
we choose the set inclusion on the set of traces that they
characterize. This is a natural choice since if a formula is
not satisfiable over a system T , then we should look for a
specification that imposes less constraints on the system.
Definition 6: Let φ, ψ ∈ LT L(Π), then we define φ  ψ
if and only if L(φ) ⊆ L(ψ).
It is easy to see that  is a partial order on LT L(Π).
However, (LT L(Π), ) is not a lattice [20] since any two
LTL formulas have several upper or lower bounds without a
greatest or a least element. For example, the upper bound of
{π0 , 3π1 } contains π0 ∨ 3π1 and ⊥ ∧ (π0 ∨ 3π1 ). However,
if we consider the quotient [LT L(Π)]/= of LT L(Π) under
the language equivalence relation =, then ([LT L(Π)]/= , )
becomes a lattice. E.g., since L(π0 ∨ 3π1 ) = L(⊥ ∧ (π0 ∨
3π1 )), π0 ∨ 3π1 and ⊥ ∧ (π0 ∨ 3π1 ) belong to the same
equivalence class.
Remark 1: In the following, in order to reduce clutter
in the notation, we will use LT L(Π) to also refer to the
quotient [LT L(Π)]/= and we will use φ to also refer to the
equivalence class [φ]/= . The exact meaning will be clear
from the context.
Therefore, abusing the notation, the top element in the
lattice is the formula φ = ⊤, while the bottom element is
the formula φ = ⊥. If two formulas cannot be compared,
i.e., we have φ1 6 φ2 and φ1 6 φ2 , then we write φ1 k φ2 .
Now that we have defined an ordering between formulas,
we can formally define what we are searching for. Essentially, we are looking for a new specification φ′ that can
be satisfied on T such that it is higher in the order than the
initial specification φ and, at the same time, remains as close
42

⊤

⊤

π2

⊤

π2

1

π0
π1

3

π1

π1 ∧ π2
π1

2

{π0 , π2 }

⊤

π0

0

4
π0

π2

π1

1
π1

π0 ∧ π2 π2

2

⊤
π1

3

⊤
π0 ∧ π1

⊤

Fig. 1. The automaton of the environment T1 of example 1 and the Büchi
automaton for the specification φ1 = 3π1 ∧ 3π2 .

Fig. 2. The automaton of the environment T2 of Example 1 and the Büchi
automaton for the specification φ2 = π0 ∧ 3(π1 ∨ (π2 ∧ 3π1 )).

to φ as possible. In other words, we try to minimally relax
φ such that it can be satisfied on T .
Example 1: Let us consider the specification φ1 = 3π1 ∧
3π2 and the environment T1 of Fig. 1. It is apparent that
there does not exist a plan that would make the specification
satisfied on this particular environment since if you reach
either the state π1 or the state π2 , then you cannot go back
and visit the other state also. In this case, the specification
φ′1 = (3π1 ∧ 3π2 ) ∨ π0 is a minimally relaxed specification
of φ1 , i.e., φ1  φ′1 , which can be satisfied on T1 . Similarly,
3π1 and 3π2 are minimally modified formulas of φ which
are satisfiable on T .
Several observations are in order. First, note that the
formulas π0 ∧ 3π1 and 32π1 are also satisfiable on T1
and, furthermore, π0 ∧ 3π1  3π1 and 32π1  3π1 .
Nevertheless, φ1 6 π0 ∧ 3π1 and φ1 6 32π1 , which means
that these specifications are not a relaxation of the initial
requirement. Similarly, even though φ1  φ′1 , φ′1 should not
be included in our recommended possible formula revisions
since it does not seem to be related to the initial intention of
the user (due to the arbitrary disjunction with π0 ). Second,
notice that 3π1 k 3π2 . This implies that there can be
several minimal solutions to consider from. Finally, it might
be beneficial for the user to have the option to choose any
possibility among the proposed solutions. In other words, the
revised formula could be 3π1 ∨ 3π2 .
2
Next, we formalize the intuition behind the preceding
example. Let FT be the set of all formulas that can be
satisfied on T , that is,

a valid formula relaxation is one that recursively relaxes each
atomic proposition π of the initial specification φ.
Definition 7 (Valid Relaxation): Let φ ∈ LT L(Π), the set
R(φ) of all valid formula relaxations of φ can be constructed
using the recursive operator rel(φ) as follows:
rel(π) ∈ {π}u ∩ LT L({π}) for π ∈ Π
rel(φ1 OP φ2 ) = rel(φ1 ) OP rel(φ2 )
where OP is any Boolean or temporal operator.
Then, the following result is immediate.
Theorem 1: For any φ ∈ LT L(Π) and φ′ ∈ rel(φ), we
have φ  φ′ .
In our problem, given a formula φ such that L(T × Bφ ) =
∅, we are looking for a specification in the set FφT = FT ∩
{φ}u ∩ LT L(AP (φ)) or in the set RFφT = FφT ∩ rel(φ).
Ideally, we would like to pick the smallest element in FφT
(or RFφT ) under the order . As we pointed in Example
1, the set FφT (or RFφT ) does not necessarily have a least
element. Therefore, we will focus our attention to minimal
elements instead.
B. Formula Revision due to Unreachable States
An LTL plan generation might fail due to the existence
of unreachable states in the discrete abstraction of the
environment. Namely, the specification asks for a particular
part of the environment to be reached; however, that part
of the environment is disconnected from current position of
the system. In this case, the formula can be easily revised
using only syntactic modifications. However, minimality of
the revised specification cannot always be achieved. It is
better to describe the procedure through a simple example.
Example 2: Consider the specification φ2 = π0 ∧ 3(π1 ∨
(π2 ∧ 3π1 )) and the environment T2 in Fig. 2. By simply
running a reachability algorithm on T2 , we can determine
the set of atomic propositions that may become true on T2 ,
i.e., {π0 , π2 }. Therefore, we can syntactically replace the 2nd
occurrence of π1 in φ2 with ⊤ and derive the specification
φ′2 = π0 ∧ 3(π1 ∨ π2 ) that becomes satisfiable on T2 . Note,
however, that φ′2 is not minimal in FφT22 . For example, φ′′2 =
π0 ∧ 3(π1 ∨ (π2 ∧ (3π1 ∨ π0 )) is satisfiable on T2 and, also,
φ′′2  φ′2 .
2
Formally, assume that we have a set U of unreachable
atomic propositions. This can be easily computed by finding
the set of reachable atomic propositions on the graph of
the discrete abstraction of the environment. Consider the

FT = {φ ∈ LT L(Π) | L(T × Bφ ) 6= ∅}.
For a subset Φ of LT L(Π), the upper bound of Φ is
{Φ}u = {ψ ∈ LT L(Π) | ∀φ ∈ Φ.φ  ψ}.
Namely, {Φ}u contains all the LTL formulas which are
“larger” than all the formulas in Φ. As Example 1 indicated,
we would like to avoid entering unrelated atomic propositions in our revised specification. Therefore, given an LTL
formula φ, we might want to restrict our search for a new
LTL formula over the set LT L(AP (φ)), where AP (φ) is
the set of atomic propositions that appear in φ.
However, simply restricting the search for a new specification over the set of LTL formulas that are built over the
atomic propositions that appear in the initial specification
might not be enough (as Example 2 will indicate). Therefore,
we also introduce the notion of valid relaxations. Informally,
43

Algorithm 1 DFSModify
Input: System T and automaton Bφ of specification φ.
Output: An automaton B such that L(T × B) 6= ∅.
1: procedure DFSM ODIFY (T , Bφ )
2:
w0 .color ← gray
⊲ w0 = (q0 , s0 )
3:
List ← ∅, w ← w0 , B ← Bφ
4:
while Final state has not been reached do
5:
if List is not empty then
6:
(s, s′ ) ← last entry in List
7:
Remove all pairs (s, :) from the List
8:
Relax one of the predicates on s → s′ of B
9:
w ← arg min{w′ .time | w′ = (q, s), q ∈ Q}
10:
∀w′ s.t. w′ .time ≥ w.time, w′ .color ← white

following recursive function remU : LT L(Π) → LT L(Π)
that operates on an LTL formula φ and removes all the
(positive) occurrences of atomic propositions in U that appear
in conjunctions (recall that no negation operator appears in
our formulas):
remU (π) = π ∈ Π
remU (NTO(π1 ) ∧ NTO(π2 )) = ⊤ if π1 , π2 ∈ U
remU (φ1 ∧ NTO(π)) = remU (φ1 ) if π ∈ U
remU (φ1 OP φ2 ) = remU (φ1 ) OP remU (φ2 )
where OP is any Boolean or temporal operator, i.e., U or
R, and NTO(π) is any nested temporal operator of zero
depth and higher such that the right operant is only π, e.g.,
ψ1 U(ψ2 Rπ) or, simply, π. Then, the following result is
immediate.
Theorem 2: Let φ ∈ LT L(Π) be not satisfiable on FTS
T and ∅ 6= U ⊆ Π be an unreachable set of labels in T .
Set φ′ = remU (φ). Then, we have φ  φ′ . Moreover, φ′ is
minimal in RFφT , i.e., if for any ψ ∈ RFφT , we have ψ  φ′ ,
then L(ψ) = L(φ′ ).

11:
12:
13:
14:

end if
[Final State, List] ← DFSVisit(w)
end while
end procedure

but no final state on A has been reached, then we return to
the latest visited state with forbidden transitions. We modify
Bφ so that it permits one of the forbidden transitions, and
we continue the graph exploration. The process is repeated
until we reach a final state sf ∈ FA . Then, the same DFS
algorithm is called starting from sf and setting as a goal
state sf itself.
The LTL formula revision algorithm is presented in Algorithm 1. The DFSVisit in line 12 is the standard nested DFS
algorithm [21] with the following modifications. First, the
adjacency graph is randomly built on-the-fly since the user
might be interested in generating different relaxations of the
initial specification. Second, we check if we have reached a
final state in A and, if so, we terminate and return. Finally,
we maintain a List with the pairs of states (s, s′ ) of B for
which a transition on T is not allowed.
The new part in Algorithm 1 over the standard DFS is in
the lines 6-10. Heuristically, we pick the last state of B in the
List that had a forbidden transition on T . This corresponds
to a particular transition s′ ∈ λB (s, l) for some set of atomic
propositions l ∈ P(Π). We randomly pick some π ∈ l and
we either remove it if |l| > 1 or we replace it with ⊤ if
|l| = 1. In the latter case, we allow any possible transition
on T . In line 9, we find the first state of A visited that
had as component the state s of B under revision. This is
required since revising a transition from s will affect the
product construction of T with B. Therefore, we need to reinitialize our search from the earliest such state. The need
for using DFS over BFS becomes evident at this stage. DFS
maintains the entry times to all the reachable vertices in the
graph. Finally, in line 10, we make sure that all the states
that were descendants of w are marked as not visited.
Theorem 3: Given a system T and specification automaton Bφ , Algorithm 1 always terminates and returns an
automaton B such that L(Bφ ) ⊆ L(B). The running time
of DFSModify is O(|SBφ |2|Π| (|SA | + |λA |)).

C. Formula Revision due to Specification Inconsistencies
As opposed to unreachable states, logical inconsistencies
cannot be efficiently resolved syntactically. Essentially, a
syntactic modification algorithm would work by relaxing
each subformula in the specification and, then, running
the planning algorithm. It is evident that in order to find
a minimal revision of the initial specification, we would
need to consider all possible combinations of relaxing the
subformulas. In the simplest case, we might need to run
at least O(2|AP (φ)| ) times the planning algorithm assuming
that we are looking for a valid formula relaxation and that
we maximally relax each atomic proposition, i.e., we set
the atomic proposition to ⊤. Note that the above approach
does not necessarily return a minimal formula even in the
set RFφT . When a state with label π is reachable, then
there could be several candidates in {π}u for relaxing the
requirement π.
Here, we provide an algorithm to relax the initial specification φ by using the synchronous product of the environment
T with the specification Bφ . The intuition behind the algorithm is as follows. In Section III, we have already discussed
that L(T × Bφ ) = ∅ if and only if there is no path from an
initial state to a final state or from a final state back to itself.
Our algorithm tries to permit more transitions on Bφ such
that a final state on T × Bφ becomes reachable.
We first consider the finite part of the plan. Similarly to the
planning case, we start a Depth First Search (DFS) from the
initial state of A = T × Bφ , but now we built the product
automaton on-the-fly (similar to the nested DFS algorithm
presented in [21]). Modifying the basic version of DFS for
such an on-the-fly graph exploration only requires minor
modifications and some additional book-keeping. As the
algorithm explores the graph of A, we mark the nodes which
have transitions that are not allowed by the specification.
When the algorithm has marked all the states as explored,
44

¬π0
¬π0 ∧ π2

0

1

¬π0
¬π0 ∧ π1

¬π0 ∧ π1 ∧ π2

¬π0

¬π0 ∧ π2

2

0

¬π0

1

ACKNOWLEDGEMENTS
The author would like to thank the anonymous reviewers
for their detailed comments and suggestions.

¬π0 ∧ π1

¬π0 ∧ π1

⊤

2

R EFERENCES

¬π0

[1] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, Feb. 2009.
[2] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Temporal logic
based reactive mission and motion planning,” IEEE Transactions on
Robotics, vol. 25, no. 6, pp. 1370 – 1381, 2009.
[3] M. Kloetzer and C. Belta, “Automatic deployment of distributed teams
of robots from temporal logic specifications,” IEEE Transactions on
Robotics, vol. 26, no. 1, pp. 48–61, 2010.
[4] C. Belta, A. Bicchi, M. Egerstedt, E. Frazzoli, E. Klavins, and G. J.
Pappas, “Symbolic planning and control of robot motion,” IEEE
Robotics and Automation Magazine, vol. 14, no. 1, pp. 61–71, 2007.
[5] S. G. Loizou and K. J. Kyriakopoulos, “Automatic synthesis of multiagent motion tasks based on LTL specifications,” in Proceedings of
the 43rd IEEE Conference on Decision and Control, Dec. 2004.
[6] T. Wongpiromsarn, U. Topcu, and R. M. Murray, “Receding horizon
control for temporal logic specifications,” in Proceedings of the 13th
ACM international conference on Hybrid systems: computation and
control. New York, NY, USA: ACM, 2010, pp. 101–110.
[7] A. Bhatia, L. E. Kavraki, and M. Y. Vardi, “Sampling-based motion planning with temporal goals,” in International Conference on
Robotics and Automation. IEEE, 2010, pp. 2689–2696.
[8] S. Karaman, R. Sanfelice, and E. Frazzoli, “Optimal control of mixed
logical dynamical systems with linear temporal logic specifications,”
in IEEE Conf. on Decision and Control, 2008.
[9] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Translating
structured english to robot controllers,” Advanced Robotics Special
Issue on Selected Papers from IROS 2007, vol. 22, no. 12, pp. 1343–
1359, 2008.
[10] J. Dzifcak, M. Scheutz, C. Baral, and P. Schermerhorn, “What to do
and how to do it: Translating natural language directives into temporal
and dynamic logic representation for goal management and action
execution,” in Proceedings of the IEEE international conference on
robotics and automation, 2009.
[11] M. Chechik and A. Gurfinkel, “Tlqsolver: A temporal logic query
checker,” in Proceedings of the 15th International Conference on
Computer Aided Verification, vol. 2725. Springer, 2003, pp. 210–
214.
[12] G. Bruns and P. Godefroid, “Temporal logic query checking,” in Proceedings of the 16th Annual IEEE Symposium on Logic in Computer
Science. IEEE Computer Society, 2001, pp. 409 – 417.
[13] Y. Ding and Y. Zhang, “A logic approach for ltl system modification,” in 15th International Symposium on Foundations of Intelligent
Systems, ser. LNCS, vol. 3488. Springer, 2005, pp. 435–444.
[14] M. Finger and R. Wassermann, “Revising specifications with CTL
properties using bounded model checking,” in Brazilian Symposium
on Artificial Intelligence, ser. LNAI, vol. 5249, 2008, p. 157166.
[15] E. M. Clarke, O. Grumberg, and D. A. Peled, Model Checking.
Cambridge, Massachusetts: MIT Press, 1999.
[16] G. E. Fainekos, S. G. Loizou, and G. J. Pappas, “Translating temporal
logic to controller specifications,” in Proceedings of the 45th IEEE
Conference on Decision and Control, Dec. 2006, pp. 899–904.
[17] M. Kloetzer and C. Belta, “A fully automated framework for control of
linear systems from temporal logic specifications,” IEEE Transactions
on Automatic Control, vol. 53, no. 1, pp. 287–297, 2008.
[18] G. D. Giacomo and M. Y. Vardi, “Automata-theoretic approach to
planning for temporally extended goals,” in European Conference on
Planning, ser. LNCS, vol. 1809. Springer, 1999, pp. 226–238.
[19] S. M. LaValle, Planning Algorithms. Cambridge University Press,
2006. [Online]. Available: http://msl.cs.uiuc.edu/planning/
[20] G. E. Fainekos, “An introduction to multi-valued model checking,”
Dept. of CIS, Univ. of Pennsylvania, Tech. Rep. MS-CIS-05-16,
September 2005.
[21] G. J. Holzmann, D. Peled, and M. Yannakakis, “On nested depth
first search,” in Proceedings of the Second Workshop on the SPIN
Verification System, ser. DIMACS, vol. 32. American Mathematical
Society, 1997.
[22] J. Strejcek, “Linear temporal logic: Expressiveness and model checking,” Ph.D. dissertation, Masaryk University Brno, 2004.

Fig. 3. Left: The Büchi automaton Bφ3 from Example 3; Right: The
automaton B3 that is returned by DFSModify.

Note that in practice the worst case running time is
too pessimistic. First, it is highly unlikely that in practical
specifications we will encounter outgoing transitions from
each state labeled by all the subsets of Π. Second, it is
also highly unlikely that each transition is labeled by the
conjunction of all the atomic propositions in Π. Finally, we
can safely assume that the desired initial specification φ is
close to what can be achieved by the system. That is, a
small number of changes should be sufficient to generate
a specification that is satisfiable on the system. If this is
not the case, then this implies that the initial specification is
entirely irrelevant to what can be achieved by the system.
Example 3: Consider the system T1 in Fig. 1 and the
specification φ3 = 3(π2 ∧ 3π1 ) ∧ 2¬π0 . The Büchi automaton Bφ3 that corresponds to φ3 appears in Fig. 3. The
automaton B3 that is returned by DFSModify also appears
in Fig. 3. Note that the formula that corresponds to B3 is
φ′3 = 3(π2 ∧ 3π1 ∧ 2¬π0 ) ∨ 3(π1 ∧ 2¬π0 ). Finally, φ3 is
satisfiable on T1 .
Problem 2 (Open): Up to this point, we have not addressed two issues. First, how do we translate the resulting
automaton back to an LTL formula automatically? And
second, are the formulas that correspond to the automata
which are returned by DFSModify minimal?
It is known that alternating 1-weak Büchi automata (A1W)
have the same expressive power with LTL [22]. Along these
lines, Strejcek in his thesis [22] provides such an automatic
translation from A1W to LTL. In the future, we plan to utilize
such constructions in order to provide a completely automatic
formula revision framework.
Regarding minimality, DFSModify performs a random
search on the automaton graph. Therefore, the resulting
specification automaton is not going to correspond to a
minimal specification in the set FφT , in general. Nevertheless,
minimality might be achieved for certain fragments of LTL.
In the future, we plan to explore such possibilities.
V. C ONCLUSIONS

AND

F UTURE W ORK

We have presented the first steps toward a fully automatic Linear Temporal Logic (LTL) formula debugging and
revision framework. This work contributes toward making
temporal logics more user friendly for robotic applications.
In the immediate future, we will be developing the theoretical
framework of formula revision and debugging even further
by addressing the open problems in Section IV-C as well as
by exploring extensions to LTL games [2] and multi-robot
scenarios [3].
45

Monte-Carlo Techniques for Falsification of Temporal
Properties of Non-Linear Hybrid Systems
Truong Nghiem1 , Sriram Sankaranarayanan2 , Georgios Fainekos3 , Franjo Ivančić4 , Aarti Gupta4
and George J. Pappas1 .
1. Dept. of Electrical Eng., University of Pennsylvania, Philadelphia, PA.
2. Dept. of Computer Science, University of Colorado, Boulder, CO.
3. School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ.
4. NEC Laboratories America, Princeton, NJ.

{nghiem,pappas}@grasp.upenn.edu, srirams@colorado.edu, fainekos@asu.edu,
{ivancic,agupta}@nec-labs.com

ABSTRACT

sign of the metric for a given trajectory s and formula ϕ indicates
whether s satisfies ϕ (written as s |= ϕ). Furthermore, “nearby”
trajectories, defined using a metric over trajectories, whose distances from s are smaller than its robustness also have the same
outcome for the property ϕ as s. Robustness metrics have been previously studied by some of the authors for robust testing of hybrid
systems [12, 11, 18]. However, for the most part, they have been
described over continuous or switched systems trajectories and for
properties over the continuous state variables. We provide a definition for hybrid trajectories in this work.
Given a robustness metric, finding a counterexample to a given
property ϕ reduces to finding a trajectory s that minimizes the
robustness score w.r.t ϕ. This can be viewed as an optimization
problem over the space of inputs of the system. However, in practice, this optimization problem is not necessarily guaranteed to be
tractable [1]. In almost all cases, the optimization problem (objective function and constraints) cannot be written down in a closed
functional form. Nevertheless, such optimization problems can often be solved satisfactorily using Monte-Carlo techniques, that perform a random walk in order to sample from a probability distribution defined implicitly by the robustness metric [31]. Over the long
run, the random walk converges to a stationary distribution over
the input space such that the neighborhood of inputs with smaller
values of robustness are sampled more frequently than inputs with
larger values. Furthermore, Monte-Carlo techniques do not require
the distribution itself to be known in a closed form. Instead, these
techniques simply require the ability to compare the values (ratio)
of the probability density function at two given points in the search
space. In practice, this reduces to simulating the system using the
sampled inputs. The contributions of this paper can be summarized
as follows:

We present a Monte-Carlo optimization technique for finding inputs to a system that falsify a given Metric Temporal Logic (MTL)
property. Our approach performs a random walk over the space of
inputs guided by a robustness metric defined by the MTL property.
Robustness can be used to guide our search for a falsifying trajectory by exploring trajectories with smaller robustness values. We
show that the notion of robustness can be generalized to consider
hybrid system trajectories. The resulting testing framework can be
applied to non-linear hybrid systems with external inputs. We show
through numerous experiments on complex systems that using our
framework can help automatically falsify properties with more consistency as compared to other means such as uniform sampling.

Categories and Subject Descriptors
G.3 [Mathematics of Computing]: Probability and Statistics—
Probabilistic algorithms (including Monte Carlo)

General Terms
Verification

Keywords
Hybrid Systems, Testing, Robustness, Metric Temporal Logic

1.

INTRODUCTION

We propose a technique for finding counterexamples to Metric
Temporal Logic (MTL) properties for non-linear hybrid systems
through global minimization of a robustness metric. Global optimization is carried out using a Monte-Carlo technique that performs a random walk over the space of inputs consisting of initial
states, controls and disturbances. The robustness metric defines the
satisfaction of an MTL property over a given trajectory as a real
number, as opposed to the Boolean 0 − 1 notion used in Logic. The

1. We show that metrics used for robust testing naturally define
objective functions that enable us to cast the problem of falsifying MTL properties into a global optimization problem.
2. We demonstrate the use of hit-and-run Monte-Carlo samplers
to carry out this optimization in the presence of (possibly
non-convex) constraints over the inputs.
3. We extend our notions to hybrid systems, using quasi-metrics
over discrete state-spaces to provide a notion of robustness
for hybrid trajectories w.r.t properties that can involve discrete as well as the continuous state variables.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
HSCC’10, April 12–15, 2010, Stockholm, Sweden.
Copyright 2010 ACM 978-1-60558-955-8/10/04 ...$10.00.

Our approach is applicable even if the property has been proven
using a verification technique. In such cases, our technique obtains system trajectories that have low robustness values w.r.t the

211

requirements. In practice, finding non-robust trajectories may imply designs with smaller safety margins. Traditional testing or verification techniques do not consider such trajectories using Boolean
notions of temporal satisfaction. Our approach is readily applicable
to Simulink/StateflowTM (S/S) models, since simulating the system
is the only primitive needed. We have implemented our approach
inside Matlab (TM) and use it to discover counterexamples to MTL
properties. We establish that random walks guided by robustness
metrics can often falsify MTL properties that cannot be falsified
using blind (uniform random) search.

to guide the search for a falsifying trajectory [12]. We now present
a brief discussion on metrics and the robustness of MTL formulas.

2.

Def. 2.2 (Metric). A metric function d, defined over a statespace X is a function d : X × X 7→ R+ , where R+ = [0, +∞].
The metric d maps pairs of states to non-negative extended real
numbers, satisfying the following properties:

2.2 Metrics
We first consider state-spaces equipped with a metric function
that provides a rigorous notion of “distance” between states. For
continuous state spaces, a suitable norm such as Lp norm (p ≥ 1)
provides such a notion. One of our contributions here is an extension of these notions to structural (directed-) metrics for hybrid
systems. This is described in Section 4.1.

PRELIMINARIES

2.1 Problem Definition
In this section, we briefly present the autonomous hybrid automaton model [1]. Non-autonomous systems are considered in
Section 3.3. We then present metrics and use them to provide continuous semantics for Metric Temporal Logic (MTL) over continuous time trajectories. This is based on our previous work [12].

Identity: d(x1 , x2 ) = 0 iff x1 = x2 ,
Symmetry: d(x1 , x2 ) = d(x2 , x1 ), and
Triangle Inequality: d(x1 , x3 ) ≤ d(x1 , x2 ) + d(x2 , x3 ).

Def. 2.1 (Hybrid Automaton). A hybrid automaton Ψ consists of components hV, L, T , Θ, D, I, ℓ0 i, wherein, V = {x1 , . . .,
xn } is the set of continuous variables; L is a finite set of locations (modes); T is a set of (discrete) transitions such that for each
τ : hℓ1 → ℓ2 , gτ i ∈ T , we move from ℓ1 ∈ L to ℓ2 ∈ L and the
relation gτ over V ∪ V ′ is satisfied; H0 = {ℓ0 } × Θ is the set
of initial conditions with ℓ0 ∈ L and Θ ⊆ Rn ; D is a mapping
of each ℓ ∈ L to a vector field D(ℓ); and, I is a mapping of each
ℓ ∈ L to a location invariant set I(ℓ) ⊆ Rn .

If the Symmetry condition is dropped from the definition, then d is
termed a quasi-metric.
Given a metric d, a radius ε > 0 and a point x ∈ X, the open εball centered at x is defined as Bd (x, ε) = {y ∈ X | d(x, y) < ε}.
Finally, if s and s′ are two system trajectories that take values in a
metric space with metric d, we will use ρd to denote the metric
ρd (s, s′ ) = supt∈R {d(s(t), s′ (t))}.

The product of the locations L with the continuous state-space defines the hybrid state space H = L × Rn . A (timed) trajectory of a
hybrid automaton is an infinite sequence of states hl, ~
x i ∈ L × Rn
of the form hl0 , ~x0 i, hl1 , ~
x1 i, hl2 , ~
x2 i, . . ., such that initially l0 =
ℓ0 and ~
x0 ∈ Θ, and for each consecutive state pair hli , ~
xi i, we either make discrete transition from li to li+1 or we evolve under the
continuous dynamics D(li ) from ~
xi to ~
xi+1 . A hybrid automaton
Ψ is deterministic iff starting from some initial state hℓ0 , ~
x0 i there
exists a unique trajectory h : R+ → H of the automaton (R+ is
the set of non-negative reals). Unless otherwise stated, we consider
deterministic hybrid systems throughout this paper. We will also be
using the notation l : R+ → L to denote the location trajectory and
s : R+ → Rn to denote the continuous trajectory of the system. In
other words, for t ∈ R+ , h(t) = hl(t), s(t)i.

2.3 Robustness of Trajectories
We briefly present the robust interpretation (semantics) of MTL
formulas. Details are available from our previous work [12]. In this
section, we will refer to system trajectories as signals.
Def. 2.3 (MTL Syntax). Let AP be the set of atomic propositions and I be any non-empty interval of R+ . The set M T L
of all well-formed MTL formulas is inductively defined as ϕ ::=
⊤ | p | ¬ϕ | ϕ ∨ ϕ | ϕ UI ϕ, where p ∈ AP and ⊤ is true.
For real-time/hybrid systems, the atomic propositions
label subn
sets of Rn . An observation map O : AP → 2R maps each proposition p ∈ AP to a set O(p) ⊆ Rn . Without loss of generality, each
O(p) ⊆ Rn is assumed Lebesgue measurable. In Section 4.1, we
will demonstrate how to formulate specifications over the hybrid
state-space H instead of the continuous state-space Rn .
We provide semantics that maps an MTL formula ϕ and a trajectory s(t) to a value drawn from the linearly ordered set R. The
semantics for the atomic propositions evaluated for s(t) consists of
the distance between s(t) and the set O(p) labeling atomic proposition p. Intuitively, this distance represents how robustly the point
s(t) lies within (or outside) the set O(p).

MTL Falsification. It is well known that safety properties in themselves do not suffice to specify all system behaviors in practice.
This is especially true for real-time embedded systems wherein
richer properties such as timing requirements, stability and so on
are equally important. Metric Temporal Logic (MTL) introduced
by Koymans [20] is a popular formalism for expressing such properties. The problem of verifying a general MTL specification is undecidable for hybrid systems. Consequently, the bounded-time verification or falsification of such properties has been studied [27, 29,
11]. Our goal in this work is the efficient falsification of bounded
time MTL properties for non-linear hybrid systems.

Def. 2.4 (Signed Distance). Let x ∈ X be a point, S ⊆ X be
a set and d be a metric on X. We define the signed distance from x
to S to be

− inf{d(x, y) | y ∈ S}
if x 6∈ S
Distd (x, S) :=
inf{d(x, y) | y ∈ X\S} if x ∈ S

P ROBLEM 2.1. For an MTL specification ϕ, the MTL falsification problem consists of finding a trajectory of the system Ψ starting
from some valid initial state hℓ0 , ~
x0 i such that the resulting hybrid
trajectory h or the corresponding continuous trajectory s falsifies
specification ϕ, i.e., h 6|= ϕ or s 6|= ϕ, respectively.

If this distance is zero, then the smallest perturbation of the point
x can affect the outcome of x ∈ O(p). We denote the robust valuation of the formula ϕ over the signal s at time t by [[ϕ, O]]d (s, t).
Formally, [[·, ·]]d : (M T L × P(X)AP ) → (X R+ × R+ → R).

Our proposed solution for Problem 2.1 quantifies the robustness
of satisfaction of an MTL formula over a system trajectory in order

212

Def. 2.5 (Continuous-Time Robust Semantics). Let s ∈ X R+ ,
c ∈ R and O ∈ P(X)AP , then the continuous-time robust semantics of any formula ϕ ∈ M T L with respect to s is recursively
defined as follows
[[⊤, O]]d (s, t) := + ∞
[[p, O]]d (s, t) :=Distd (s(t), O(p))
[[¬ϕ1 , O]]d (s, t) := − [[ϕ1 , O]]d (s, t)
[[ϕ1 ∨ ϕ2 , O]]d (s, t) := max([[ϕ1 , O]]d (s, t), [[ϕ2 , O]]d (s, t))
[[ϕ1 UI ϕ2 , O]]d (s, t) :=

sup

Lifting Dϕ to Inputs: The robustness metric Dϕ maps each trajectory s to a real number r. The sign of r indicates whether s |= ϕ
and its magnitude |r| measures its robustness. Our goal is to find
inputs ~
x0 ∈ Θ such that the resulting trajectory s 6|= ϕ, or equivalently Dϕ (s) ≤ 0. This can be expressed as the optimization of the
objective Dϕ over the space of all system trajectories:

min [[ϕ2 , O]]d (s, t′ ),

t′ ∈(t+I)

inf [[ϕ1 , O]]d (s, t′′ )

t<t′′ <t′



where t ∈ R+ and t + I = {τ | ∃τ ′ ∈ I . τ = t + τ ′ }.

min
Dϕ (s) s.t. initial state of s : ~
x0 ∈ Θ
trajectorys

For the purposes of the following discussion, let (s, t, O) |= ϕ
denote the standard Boolean MTL satisfiability. Note that Boolean
MTL satisfiability reduces to an application of Def. 2.5 wherein
the range of the valuation function is the Boolean set B = {T, F}
instead of R. It is easy to show that if the trajectory satisfies the
property, then its robustness is non-negative and, similarly, it the
trajectory does not satisfy the property, then its robustness is nonpositive. The following result holds [12].

However, the trajectories are not the true decision variables for this
problem. For instance, it is hard to explore the space of trajectories
directly while guaranteeing that each trajectory considered is valid.
Fortunately, for deterministic systems, we may associate each input ~x0 ∈ Θ with a unique trajectory s and vice-versa. Let σ(~x0 )
denote the trajectory obtained starting from the initial state ~x0 . Let
Fϕ (~
x0 ) = Dϕ (σ(~
x0 )) denote the robustness of the trajectory obtained corresponding to the initial state ~
x0 ∈ Θ. Therefore, the
optimization can be expressed over the space of inputs as follows:

Theorem 2.1. Given a formula ϕ ∈ M T L, an observation
map O ∈ P(X)AP and a continuous-time signal s ∈ X R+ , the
following hold: (1) If (s, t, O) |= ϕ, then [[ϕ, O]]d (s, t) ≥ 0. In
other words, s satisfies the formula ϕ at time instant t ≥ 0 if its distance valuation is non-negative. Conversely, if [[ϕ, O]]d (s, t) > 0,
then (s, t, O) |= ϕ. (2) If for some t ∈ R+ , ε = [[ϕ, O]]d (s, t) 6= 0,
then for all s′ ∈ Bρd (s, |ε|), we have (s, t, O) |= ϕ if and only if
(s′ , t, O) |= ϕ. I.e, ε defines a robustness tube around the trajectory such that other “nearby” trajectories lying inside this tube
also satisfy ϕ.

minimize~x0 ∈Θ Fϕ (~
x0 ) .
The inputs ~
x0 are the true decision variables of the problem and the
optimization is carried out subject to the constraints in Θ.
Non-deterministic Systems: For non-deterministic and stochastic
systems, a single input can be associated with multiple (possibly
infinitely many) behaviors. For stochastic systems, we may evaluate Fϕ (~
x) as an expectation obtained by sampling a large but
finite set of trajectories. Non-deterministic systems can often be
determinized by adding new input variables to represent the nondeterministic choice. For the most part, we consider deterministic systems in this paper. For instance, systems modeled in formalisms such as Simulink/Stateflow diagrams (TM) are deterministic, at least in theory.
The resulting optimization problem can be quite complex, unlikely to be convex for all but the simplest of cases. Furthermore,
the objective function F though computable for any given input
through simulation, is not expressible in a closed form. Directly
obtaining gradients, Hessians and so on is infeasible for all but the
simplest of cases. We now present Monte-Carlo techniques that
can solve such global optimization problems through a randomized
technique that mimics gradient descent in many cases.

Theorem 2.1 establishes the robust semantics of MTL as a natural measure of trajectory robustness. Namely, a trajectory is ε
robust with respect to an MTL specification ϕ, if it can tolerate perturbations up to size ε and still maintain its current Boolean truth
value. Alternatively, a trajectory with the opposite outcome for ϕ,
if it exists, has a distance of at least ε away.
The precise complexity of the computation of MTL robustness
using formula rewriting procedures is still an open problem [12].
However, for LTL formulae ϕ, a dynamic programming style algorithm can compute the robustness value using O(mn) comparisons, where m = |ϕ| is the size of the formula and n is the length
of the simulation trajectory. Similarly, if we assume that all the
simulation trajectory is sampled at integer time instants and that the
MTL formula involves integer time constants, then the robustness
value of an MTL formula can be computed with O(mnc) comparisons, where c is the largest time value that appears in ϕ. Note
that in either case, we also need kn distance computations, where
k is the number of atomic propositions that appear in ϕ. In turn, the
computational complexity of the distance computations depends on
the type of the sets used for modeling the regions of interest in the
state-space. Details are presented elsewhere [12].

3.

Let Ψ be a given (deterministic) system whose initial states lie
inside the set H0 . Let ϕ be a given MTL property that we wish to
falsify. Given a trajectory s, we have defined a robustness metric
[[ϕ, O]]d (s, t) that denotes how robustly s satisfies (or falsifies) ϕ at
time t. For the following discussion, we assume a fixed label map
O and always interpret the truth (and robustness) of MTL formulas
evaluated at the starting time t = 0. Let Dϕ (s) = [[ϕ, O]]d (s, 0)
denote the robustness metric for s under these assumptions.

3.1 Monte-Carlo Sampling
The Monte-Carlo techniques presented here are based on acceptance-rejection sampling [5, 2]. These techniques were first introduced in statistical physics wherein they were employed to simulate the behavior of particles in various potentials [15]. Variations
of Monte-Carlo techniques are also widely used for solving global
optimization problems [31].
We first present the basic sampling algorithm for drawing samples from a probability distribution and then the technique of hitand-run sampling that respects the (convex) constraints on the input
space due to Θ.
Let f (~
x) = Fϕ (~
x) be a computable robustness function, given
a property ϕ . We seek to minimize f over the inputs in the set

FALSIFYING CONTINUOUS SYSTEMS

In this section, we provide the basic formulation of falsification
in terms of global optimization of a robustness metric defined in
Section 2 and describe a Monte-Carlo technique to solve this global
optimization.

213

Θ. We wish to sample Θ such that any two points a, b ∈ Θ with
robustness values f (a) and f (b) are sampled with probability pro−βfϕ (a)
portional to e −βfϕ (b) , where β > 0 is a “temperature” parameter,
e
whose significance will be made clear momentarily.
Algorithm 1: Monte-Carlo sampling algorithm.
Input: Θ: Input Space, f (·): Robustness Function,
ProposalScheme(·): Proposal Scheme
Result: Samples ⊆ Θ
begin
Choose some initial input ~
x ∈ Θ.
while (¬Target) do
/* Select ~
x′ using ProposalScheme
1
~
x′ ← ProposalScheme(~
x)
2
α ← exp(−β(f (~
x′ ) − f (~
x)))
3
r ← UniformRandomReal(0, 1)
4
if (r ≤ α) then /* Accept proposal?
5
~
x←~
x′
6
if (f (~
x) ≤ 0) then reachTarget := true
7
else
8
/* Reject & seek new proposal

As a direct consequence, one may conclude, for instance, that
an input ~
x1 with f (~
x1 ) = −100 is more likely to be sampled as
compared to some other input ~
x2 with f (~
x2 ) = 100 in the long run.
A similar result holds
R for the continuous case assuming a suitable
measure such that Θ f (~
x)dΘ is well defined [31].

*/

*/

*/

end
Algorithm 1 shows the schematic implementation of the algorithm. Each iteration of the sampler generates a new proposal
~x′ ∈ Θ from the current sample ~
x using some proposal scheme defined by the user (Line 1). The objective f (~
x′ ) is computed for this
′
proposal. Subsequently, we compute the ratio α = e−β(f (~x )−f (~x))
(Line 2) and accept the proposal randomly, with probability α (Line 3).
Note that if α ≥ 1 (i.e, f (~
x′ ) ≤ f (~
x) ), then the proposal is accepted with certainty. Even if f (~
x′ ) > f (~
x) the proposal may still
be accepted with some non-zero probability. If the proposal is accepted then ~
x′ becomes a new sample. Failing this, ~
x remains the
current sample.
A proposal scheme is generally defined by a probability distribution P (~
x′ |~
x) that specifies the probability of proposing a new
sample input ~
x′ given the current sample ~
x. For a technical reason
(known as detailed balance, see [5]), our version of the algorithm
requires that P (~
x′ |~
x) = P (~
x|~
x′ ). Furthermore, given any two in′
puts ~
x, ~
x ∈ Θ, it should be possible with nonzero probability to
generate a series of proposals ~
x, ~
x1 , . . . , ~
x′ that takes us from input
′
~x to ~
x . This is necessary in order to guarantee that the entire input
state space is covered.
For simplicity, let Θ be bounded and discrete with a large but
finite number of points (e.g., consider Θ as a set of finite precision floating point numbers). The robustness function f (~
x) over Θ
induces a probability distribution:

Importance of β: The overall algorithm itself can be seen as a
randomized gradient descent, wherein at each step a new point ~x′
in the search space is compared against the current sample. The
probability of moving the search to the new point follows an exponential distribution on the difference in their robustness values:
′
p ∼ e−β(f (~x )−f (~x)) . In particular, if fϕ (~
x′ ) ≤ fϕ (~x), the new
sample is accepted with certainty. Otherwise, it is accepted with
′
probability e−β(f (~x )−f (~x)) . Informally, larger values of β ensure
that only reductions to f (~
x) are accepted whereas smaller values
correspondingly increase the probability of accepting an increase in
f (~
x). As a result, points with lower values of f are sampled with
an exponentially higher probability as compared to points with a
higher value of the function f .
It is possible, in theory, to prove assertions about the number N
of samples required for the sampled distribution to converge within
some distance to the desired distribution governed by e−βfϕ (~x) .
The acceptance rejection sampling method implicitly defines a (continuous time) Markov chain on Θ, whose invariant distribution is
)
the distribution p(~
x) = R fd(~fx(~
we wish to sample from. For the
y)
Θ
case of discrete input spaces, the convergence is governed by the
mixing time of the Markov chain defined by the proposal scheme.
This time is invariably large (polynomial in the number of input
points), and depends on the proposal scheme used.
Adapting β. One of the main drawbacks of Algorithm 1 is that,
based on nature of the distribution, the sampling may get “trapped”
in local minima. This typically results in numerous proposals getting rejected and few being accepted. Even though we are guaranteed eventual convergence, the presence of local minima slows
down this process, in practice. We therefore periodically adjust the
values of β (and also the proposal scheme) to ensure that the ratio
of accepted samples vs. rejected samples remains close to a fixed
value (1 in our experiments). This is achieved by monitoring the acceptance ratio during the sampling process and adjusting β based
on the acceptance ratio. A high acceptance ratio indicates that β
needs to be reduced, while a low acceptance rate indicates that β
needs to be increased.

where M is the normalizing factor added to ensure that the probabilities add up to one. Suppose Algorithm 1 were run to generate
a large number of samples N . Let η denote the frequency function
mapping subsets of the input space to the P
number of times sample was drawn from the set. Let P (S) = ~x∈S p(~
x) denote the
volume of the probability function for a set S ⊆ Θ.

Proposal Schemes. It is relatively simple to arrive at viable schemes
for generating new proposals. However, designing a scheme that
works well for the underlying problem requires a process of experimentation. For instance, it suffices to simply choose an input
~
x′ uniformly at random from the inputs, regardless of the current
sample. However, such a scheme does not provide many advantages over uniform random sampling. In principle, given a current
sample ~
x, the choice of the next sample ~x′ must depend upon ~x.
A typical proposal scheme samples from a normal distribution
centered at ~
x with a suitably adjusted standard deviation (using
some covariance matrix H). The covariance can be adjusted periodically based, once again, on the observed samples as well as
the acceptance ratio. A smaller standard deviation around ~x yields
samples whose robustness values differ very little from f (~x), thus
increasing the acceptance ratio. However, it is hard to respect the
constraint ~
x′ ∈ Θ using such a proposal scheme.

Theorem 3.1. In the limit, the acceptance rejection sampling
technique (almost surely) generates samples according to the distribution p, P (S) = limN→∞ η(S)
N

Hit-and-run proposal scheme. Hit-and-run schemes are useful in
the presence of input domains such as Θ. For simplicity, we assume
that Θ is convex. Therefore, any line segment in some direction ~v

p(~
x) =

1 −βf (~x)
e
,
M

214

3.2 Computing Robustness
We briefly discuss the computation of the robustness metric for
trajectories. Continuous trajectories are hard to compute precisely,
even when the analytical form of the solution of the system is
known. Thus, trajectories have to be approximated numerically.
An approximate simulation function G that supports robust evaluation of the given property ϕ should guarantee that for some bounded
time horizon [0, T ), ||G(~
x0 , t) − F(~
x0 , t)|| ≤ ǫ, for all t ∈ [0, T )
and for a sufficiently small ǫ > 0. Such a robust simulation function suffices, in practice, to resolve properties that may be of interest to the system designers. An appropriate simulation function
can be obtained for a large class of ODEs using numerical simulation techniques of an appropriate order such as Runge-Kutta
or Taylor-series methods with adaptive step sizes [28]. Numerical integration schemes can also be adapted to provide reliable
bounds ǫ on the distance between the actual and the numerical solution. Given a simulation scheme G for a time interval of interest
[0, T ), we obtain a trace GT (~
x0 ) as a finite set of sample points
{G(~
x0 , t) | t ∈ [0, T )}. The robustness Dϕ can be approximated
using this set of sample points obtained by a numerical integrator.
Unfortunately, for a trajectory σ obtained as the output of a numerical integrator with known error bounds, the trace distance function may no longer satisfy Dϕ (σ) ≥ 0 whenever σ |= ϕ. Instead, we may conclude the existence of some interval [−ǫ2 , ǫ1 ] for
some ǫ1 , ǫ2 ≥ 0, such that if Dϕ (σ) ≤ −ǫ2 , then σ 6|= ϕ and if
Dϕ (σ) ≥ ǫ1 then σ |= ϕ. In general, we may not draw any conclusions if −ǫ1 ≤ Dϕ (σ) ≤ ǫ2 . Furthermore, the bounds ǫ1 , ǫ2 are often unknown for a given system. Nevertheless, the presence of such
a bound implies that it still makes sense to perform the optimization
using a numerically simulated trajectory function G(~
x0 , t).

Figure 1: Hit-and-run proposal scheme.
starting from ~x has a maximum offset u such that the entire segment
between ~
x and ~
x + u~v lies inside Θ.
At each step, we propose a new sample ~
x′ based on the current
sample ~
x. This is done in two steps:
1. Choose a random unit vector ~v uniformly (or using a Gaussian distribution) (Cf. Fig. 1). In practice, one may choose a
~
h
.
random vector ~h and generate a unit vector using ~v = |~h|
2

2. Discover the interval [l, u], such that
∀λ ∈ [l, u], ~
x + λ~v ∈ Θ .
In other words, ~v yields a line segment containing the point
x along the directions ±~v and [l, u] represent the minimum
and maximum offsets possible along the direction ~v starting
from ~x. If Θ is a polyhedron, bounds [l, u] may be obtained
efficiently by using a variant of the minimum ratio test. For a
more complex convex set Θ, value of l (resp. u) may be obtained by solving the one dimensional optimization problem
min(max) λ s.t. ~
x + λ~v ∈ Θ, by using a bisection procedure
given an initial guess on [l, u].

min. fP (~
x0 ) s.t. ~
x0 ∈ Θ .
In practice, such a minimally “robust” simulated trajectories will
often be of great interest to system designers even if mathematically
speaking they do not violate the property under consideration.

3. Finally, we choose a value λ ∈ [l, u] based on some probability distribution with a mean around 0. The variance of
this distribution is an important parameter that can be used
to control the acceptance ratio (along with β) to accelerate
convergence.

Example 3.1. Consider the time variant system
dx
dt
dy
dt

= x − y + 0.1t
= y cos(2πy) − x sin(2πx) + 0.1t

with the initial condition (x, y) ∈ [−1, 1] × [−1, 1]. We wish
to falsify the property 2[0,2] a, wherein O(a) = [−1.6, −1.4] ×
[−.9, −1.1]. Our simulation uses a numerical ODE solver with a
fixed time step over the time interval t ∈ [0, 2]. Figure 2(A) shows
the trajectory the falsifies our safety property using the hit-and-run
sampler and the scatter plot consisting of the samples generated by
the Monte-Carlo sampler. Figure 2(B) plots the robustness of the
sampled trajectory at each simulation step.

Hit-and-run samplers can also be used for non-convex input domains such as unions of polytopes and so on. A detailed description
of the theory behind such sampling techniques is available elsewhere [34, 31].
However, care must be taken to ensure that the input space Θ
is not skewed along some direction ~r. In the worst case, we may
imagine Θ as a straight line segment. In such cases, the hit-and-run
proposal scheme fails to generate new samples. This is remedied by
adjusting the scheme for selecting unit directions to take the skew
of Θ, embedding of Θ inside a subspace spanned by the independent variables and, finally, applying a suitable transformation to Θ
that aids in sampling.
In practice, hit and run samplers can work over non-convex, disconnected domains. Theoretical results on these samplers are very
promising. Smith [33] proves the asymptotic convergence of hit
and run sampling over arbitrary open subsets of Rn . Lovasz [22,
23] has further demonstrated convergence in time O(n3 ) for hit
and run sampling of uniform distribution over a convex body in
n dimensions. Algorithms for global optimization such as hideand-seek [30] and improving hit-and-run [36] have combined hitand-run sampling with Monte-Carlo techniques to generate useful
global optimization techniques.

Remark 3.1. If the user is willing to tolerate additional computational cost, then it is possible to bound the inaccuracies of the
numerical simulation even under the presence of floating-point errors [13]. Then, these bounds can be used to provide bounds on the
robustness of the actual continuous-time trajectory [12].

3.3 Non-autonomous Systems
We now consider extensions to non-autonomous control systems
of the form ~
x˙ = f (~
x, ~
u), with time-varying inputs ~
u : [0, T ] 7→
Rm constrained to belong to a (measurable) set of functions U.
Our goal is to recast the search for control inputs ~
u ∈ U in terms of
a search for a set of parameters ~λu ∈ Rk that lie in some domain
Γ. Valuations to the parameters ~λ ∈ Γ, result in a set of appropriate
control inputs ~
u(~λ) ∈ U. Such a parameterization helps us reduce

215

Scatter plot of sampled inputs along with the discovered violation
1

5
4.5

0.5

4

Fitness Function Value

3.5

y

0

−0.5

3
2.5
2
1.5

−1

1
0.5

−1.5
−2.5

−2

−1.5

−1

−0.5

0

0.5

0

1

x

(A)

0

200

400

600

800
1000
1200
Simulation Step#

1400

1600

1800

2000

(B)

Figure 2: (A) Time trajectory violating the property 2[0,2] ([−1.6, −1.4] × [−.9, −1.1]) along with the scatter plot of sampled inputs
and (B) robustness shown in the y-axis as a function of the simulation step number.
with state-space variables x1 describing the aircraft speed, x2 describing its flight path angle and x3 describing its altitude. The
control input u1 represents the thrust and u2 the angle of attack.
Numerical values for the parameters are as described by Lygeros [24].
The initial value ~
x0 belongs to the box [200, 260] × [−10, 10] ×
[120, 150]. The control inputs are within the range (u1 (t), u2 (t)) ∈
[34386, 53973] × [0, 16]. We wish to find initial values and control
inputs that falsify the MTL formula

the search in terms of a standard global optimization over the space
of real-valued decision variables as opposed to functional valued
variables. However, such a reduction may not necessarily capture
all the control inputs possible in the set U, and therefore restrict our
search to a (proper) subset of inputs.
Given a space of inputs ~
u ∈ U, there are numerous ways to
parameterize the space of control inputs. We discuss a few such
parameterizations below:
Piece-wise Constant Control. We
Spartition the overall time interval [0, T ] into a set of intervals m
i=1 [ti−1 , ti ), wherein t0 = 0
and tm = T . For each interval [ti−1 , ti ), i ≥ 1, the control u(t)
is restricted to be a constant value λi−1 . The control is therefore
parameterized by the tuple hλ0 , . . . , λm i, chosen so that the constraints in U are respected.

ϕ = 2[1,1.5] (x1 ∈ [250, 260]) ⇒ 2[3,4] (x1 6∈ [230, 240]) ,
which claims that if the aircraft speed lies in range [250, 260] during the time interval t ∈ [1, 1.5], then it cannot be within the range
[230, 240] within the time interval t ∈ [3, 4]. The time interval of
interest is taken to be [0, 4.0]. This is divided into 10 sub-intervals
and the control inputs were parameterized to be piece-wise constant within each sub-interval, yielding 20 parameters. Overall,
the search space has 24 parameters. We wish to find a control input so that the resulting trajectory falsifies ϕ.
A hit and run sampler was used for 2500 steps. The samples
along a falsifying trajectory found are shown in Fig. 3(a,b). Figure 3(c) shows how the robustness score varies with the number of
simulation steps. We note that our implementation assigns a score
zero to all falsifying traces. This is performed in order to explore
the space of falsifying traces uniformly.

Piece-wise Linear Control. Piece-wise constant control may be
extended to piecewise linear controls and beyond. Once again, we
partition [0, T ] into m disjoint intervals. For each interval [ti−1 , ti ],
we restrict the form of each control input to be piece-wise linear:
u(ti−1 + δ) = u(ti−1 ) + λi−1 δ. This effectively yields the parameters hu(0), λ0 , . . . , λm i that define the control inputs. These
parameters are chosen so that that the resulting controls respect the
constraints in U. Extensions to this scheme can introduce higherorder parameters of the form u(ti−1 + δ) = u(ti−1 ) + δλ1i−1 +
δ 2 λ2i−1 and so on.

4. FALSIFYING HYBRID SYSTEMS

Spline Functions. We choose a family of splines functions υ(~
x, ~λ)
over a set of parameters ~λ and seek to express each control input
u(~
x) = υ(~
x, ~λ0 ) for some instantiation of the parameters ~λ = ~λ0 .
The splines could be varied at definite time instances and continuity/differentiability conditions imposed at such instances.

In this section, we consider the case of falsifying MTL properties for (potentially non-autonomous) hybrid systems. In general,
the testing framework, which was presented in Section 3.3, can be
applied to switched systems with discrete modes and transitions between them as long as the property ϕ does not involve the system’s
discrete modes.
Given a deterministic hybrid system Ψ and an initial condition
h0 , let G(h0 , t) represent a simulation function for a set of time
instances T such that G approximates the trajectories of the hybrid
system. We assume that G approximates the time trajectories with
some given tolerance bound ǫ by adjusting the integration method.
In practice, this may be harder to achieve for hybrid systems than
for purely continuous systems due to the problem of robust event
detection [10]. However, assuming that such a simulator is available, we may translate the trace fitness function defined for continuous simulations to hybrid simulations with discrete transitions.

Example 3.2 (Aircraft Model). We consider a simple aircraft
model describing the movement of an aircraft as a particle in the
vertical plane, taken directly from previous work of Lygeros [24].
The equations of motion can be described by the ODE:
 SρB0 2

− 2m ~
x1 − g sin(~
x2 )
x2 )
0

~
x˙ =  SρC
~
x1 − g cos(~
2m
~
x1
x1 sin(~

 u ~
x2 ) Sρ 2
1
− 2m ~
x1 (B1 u2 + B2 u22 )
m
SρC
1

+ 0  + 
~
x1 u2
2m
0
0

216

260

20

210

18

200

255
16

190

14

180

250
12

160
x1

x3

170

245

10

150
8

140
240

130

6

120
10

4
235
5

2
0
x2

−5

235

245

240

250

255

260
230

0

0.5

x1

(a)

1

1.5

2
Time

2.5

3

3.5

0

4

0

500

1000

(b)

1500

2000

2500

(c)

Figure 3: (a) Scatter plot of the samples, (b) the trajectory falsifying MTL formula ψ : 2[1,1.5] (x1 ∈ [250, 260]) ⇒ 2[3,4] (x1 6∈
[230, 240]) and (c) the variation of robustness of samples for the aircraft model over the simulation steps.
order relation ≺ as

Specifications for hybrid automata involve a sequence of locations of the discrete subsystem. The simplest such property being
the (un)reachability of a given “error” location. As a result, continuous state distance based on a norm (or a metric distance) does not,
in general, provide a true notion of distance between the specification and the trace. This is especially true in the presence of discrete
transitions with reset maps.




hk, ri ≺ k′ , r ′ iff

For the case of hybrid systems with reset maps, the robustness
metric used thus far cannot be used to compare the hybrid states
(ℓ, ~
x) and (m, ~
y ) in terms of some norm distance between ~
x and
y . Therefore, structural considerations based on the graph that con~
nects the different modes of the hybrid automata have to be considered while designing fitness functions. We now consider metrics
for hybrid systems.
First, we have to define what is the distance between two modes
of the hybrid automaton. We claim that a reasonable metric is the
shortest path distance between two locations. Intuitively, the shortest path distance provides us with a measure of how close we are to
a desirable or undesirable operating mode of the automaton. Such
information is especially useful in the class of falsification algorithms that we consider in this paper.
In the following, given hybrid automaton Ψ, we let Γ(Ψ) =
(L, →) represent the directed graph formed by its discrete modes
and transitions. The shortest path distance from node u to node v in
the graph Γ(Ψ) will be denoted by π(u, v). Note that π(u, v) = ∞
iff there is no path from u to v in the graph Γ(Ψ). It is easy to
verify that the shortest path distance satisfies all the criteria for a
quasi-metric. The shortest path metric can be computed by running
a Breadth First Search (BFS) algorithm on the graph. It is well
known that BFS runs in linear time on the size of the input graph.
In order to reason about trajectories h in the hybrid state space
H, we introduce a generalized distance δ : H × H → B+ , where
B+ = ({0} × R+ ) ∪ (N∞ × {+∞}) and N∞ = N ∪ {∞}, with
definition for h = hl, xi ∈ H and h′ = hl′ , x′ i ∈ H,
δ(h, h′ ) =

h0, d(x, x′ )i
hπ(l, l′ ), +∞i

k < k′
r < r′

if k =
6 k′
if k = k′

Hence, B+ has a smallest element, namely h0, 0i, and an absorbing
element, namely h+∞, +∞i, which is also the least upper bound.
Finally, the addition (and the negation in the case of robust semantics) is defined component-wise. It is easy to verify that the
generalized distance δ satisfies the identity and triangle inequality
properties. In other words, δ is a generalized quasi-metric on H.
The only requirement in the definition of the robust semantics
of MTL formulas (Section 2.3) is that both the trajectory under
study and the specifications take values from the same space. A
straightforward induction on the structure of formula ϕ will indicate that Theorem 2.1 also holds in the case where the metric d is
replaced by a quasi-metric, e.g., δ, in the signed distance function
and the metric ρd . In the following, we will be using the notation
Γ(Ψ)
[[·, ·]]δ
to indicate that now the graph of the hybrid automaton
is required in the robustness computation. Formally, we have that
Γ(Ψ)
[[·, ·]]δ
: (M T L × P(H)AP ) → (HR+ × R+ → B), where
<0
B = ((Z ∪ {−∞}) × {−∞}) ∪ ({0} × R− ) ∪ B+ .

4.1 Robustness of Hybrid Trajectories





Theorem 4.1. Given a formula ϕ ∈ M T L, an observation
map O ∈ P(H)AP , a hybrid automaton graph Γ(Ψ) and a hybrid trajectory h ∈ HR+ , the following holds. If for some t ∈ R+ ,
Γ(Ψ)
we have hε1 , ε2 i = [[ϕ, O]]δ (h, t) 6= h0, 0i, then for all h′ ∈
Bρδ (h, h|ε1 |, |ε2 |i), we have (h, t, O, Γ(Ψ)) |= ϕ if and only if
(h′ , t, O, Γ(Ψ)) |= ϕ.
Therefore, we are in position to reason about hybrid trajectories without changing our definition of MTL robustness. Now the
atomic propositions can map to subsets of H placing, thus, requirements not only on the continuous state-space, but also on the mode
of the hybrid system. Informally, a robustness value of hk, ri will
mean the following:
• If k = 0 and r 6= 0, then we can place a tube of radius
|r| around the continuous part of the trajectory which will
guarantee equivalence under the MTL formula. Moreover, it
is required that at each point in time t, the locations are the
same for all such trajectories.

if l = l′
otherwise

where π is the shortest path metric and d is a metric on Rn . In order
for our generalized distance to behave like a metric, the range B+
must be an additive Abelian semigroup with identity and absorbing
elements and, also, it must be linearly ordered. We order the set
using the dictionary order. Given hk, ri, hk′ , r ′ i ∈ Z∞ × R+ ,
where Z is the set of integers and Z∞ = Z ∪ {±∞}, we define the

• If k > 0, then the specification is satisfied and, moreover, the
trajectory is k discrete transitions away from being falsified.
• If k < 0, then the specification is falsified and, moreover, the
trajectory is k discrete transitions away from being satisfied.

217

in each location are the edges and the vertices that are common
among the neighboring locations.
Each location has affine constant dynamics with drift. In detail,
in each location (i, j) of the hybrid automaton, the system evolves
under the differential equation ~
x˙ = A~
x − Bu(i, j) where

4

13

14

15

16

9

10

11

12

5

6

7

8

x2

3

u(i, j) = [sin(πC(i, j)/4) cos(πC(i, j)/4)]T and
0 0 1

 0

4 2 3 4
0
0
0 0 0
1
0
0
A = 0 0 −1.2 0.1
B = −1.2 0.1
C = 31 62 53 66

2

0 0 0.1 −1.2

1
0

2

0

1

3
2
x1

4
3

4

Figure 4: The environment of the vehicle benchmark example
(Example 4.1). The arrows indicate the direction of the vector
field in each location and the numbers the id of each location.
The green box indicates the set of initial conditions projected
on the position plane.

2 2 1 1

5. EXPERIMENTS

4

We have implemented our techniques inside the Matlab(TM) environment. Our implementation is general enough to interact with
various means for describing hybrid systems including Simulink /
Stateflow models. We currently support full time bounded MTL for
continuous as well as hybrid time trajectories.
We perform a comparison of our implementation (MC) against a
simple uniform random (UR) exploration of the state-space. Both
MC and UR are each run for a set maximum number of iterations,
terminating early if a falsifying trajectory is found. Since these
techniques are randomized, each experiment was repeated numerous times under different seeds in order to obtain statistically significant results. Uniform random exploration provides an ideal measure of the difficulty of falsifying a property over a given input.
Its rate of success empirically quantifies the difficulty of falsifying
a given property. Finally, we have already argued about the importance of obtaining the least robust trajectory where falsification
cannot be achieved. To this end, we compare the set of minima
found using MC as well as that using UR. Table 1 reports on the
results of our comparison using different MTL properties for the
benchmark systems considered thus far. We find that the performance varies depending on the ease with which the property can be
violated by means of uniformly sampling the input space. In almost
all the cases, MC technique performs better than uniform random
sampling, especially when a falsification is hard to find through UR
sampling. We also note, that while MC technique finds the least robust trajectory in almost all cases, the least robust trajectory suffers
from large outlying values in some cases. We believe that these
values represent local minima that the MC sampling is unable to
get away from within the limited number of iterations. In practice, we may periodically reset the MC simulation using random
restarts. However, such restarts were not used in our experimental
comparison.

3.5

3

2.5

2

1.5

1

0.5

0

0.1 −1.2

Our goal is to find an initial state in the set H0 = {13} ×
[0.2, 0.8] × [3.2, 3.8] × [−0.4, 0.4] × [−0.4, 0.4] that will falsify
the formula ϕ = (¬ b) U[0,25.0] c, wherein atomic proposition
b refers to the shaded rectangle (bottom right) in Fig. 5 and c
to the unshaded rectangle above in Fig. 5. In detail, O(b) =
{4} × [3.2, 3.8] × [0.2, 0.8] × R2 and O(c) = {8} × [3.2, 3.8] ×
[1.2, 1.8] × R2 . Informally, ϕ says that the system should reach
c within 25 time units without passing through b. The least robust
(≈ 0) trajectory hl found by our algorithm is shown in Fig. 5 along
with the scatter plot for the samples. Note that it could be the case
that the system is correct with the respect to the specification, but it
is definitely not robustly correct.

1

0

0.5

1

1.5

2

2.5

3

3.5

4

Figure 5: The scatter plot of the sampled initial positions projected on the position plane, along with the least robust trajectory of the vehicle benchmark example (Example 4.1).
This new hybrid notion of MTL robustness is useful in the context of testing for hybrid systems. Namely, our original definition
of MTL robustness places requirements only on the observable
continuous-time trajectories of the system while ignoring the underlying discrete dynamics. The new robustness notion can structurally distinguish system trajectories that might have similar robustness values otherwise. Thus, it can be used to guide our search
algorithms towards less robust system modes. Moreover, we can
now impose different requirements at different operating modes of
the system. This was not possible before.
Example 4.1. Consider a complex instance of the vehicle benchmark [14] shown in Fig. 4. The benchmark studies a hybrid automaton Ψ with 4×4 discrete locations and 4 continuous variables
x1 , x2 , x3 , x4 that form the state vector ~
x = [x1 x2 x3 x4 ]T . We
refer to the vectors [x1 x2 ]T and [x3 x4 ]T as the position and the
velocity of the system, respectively. The structure of the hybrid automaton can be better visualized in Fig. 4. The invariant set of
every (i, j) location is an 1 × 1 box that constraints the position of
the system, while the velocity can flow unconstrained. The guards

6. RELATED WORK
Due to the known undecidability results in the analysis of hybrid systems [1] and the state explosion problem of the reachability
computation algorithms (see [18] for some related references), a lot
of recent research activity has concentrated on testing approaches
to the verification of continuous and hybrid systems [19].

218

Table 1: Experimental Comparison of Monte-Carlo vs. Uniform Random falsification. Legend: ψ: MTL formula number, #Fals.:
number of instances falsified, #MinRob.: best robustness scores, Time: Avg. time in seconds.
ψ

#Run
P(MC ≤ UR)

Aircraft Example 3.2
2[.5,1.5] a ∧ 3[3,4] b
2[0,4] c ∧ 3[3.5,4] d
3[1,3] e
3[.5,1] f ∧ 2[3,4] g
2[0,.5] h
2[2,2.5] i
Vehicle Benchmark 4.1
(¬ b) U[0,25.0] c

#Iter.

#Fals.

MinRob.

per
run

MC

UR

100
100
100
100
100
100

500
1000
2000
2500
2500
2500

88
100
81
0
100
99

100
66
16
0
100
51

h0, 1.2, 18.6i
h0, 0, 0i
h0, .9, 40i
h9.5, 9.7, 10.1i
h0, 0, 0i
h0, 0, 1.0i

35

1000

11

8

h0, .02, .04i

The use of Monte Carlo techniques for model checking has been
considered previously by Grosu and Smolka [17]. Whereas Grosu
and Smolka consider random walks over the automaton defined by
the system itself, our technique defines random walks over the input state space. These are, in general, distinct approaches to the
problem. In practice, our approach does not have the limitation
of being restricted by the topology of the system’s state transition
graph. Depending on this topology, the probability of visiting states
deeper in the graph can sometimes be quite small in pathological
cases. On the other hand, Grosu et al.’s technique can be extended
readily to the case of systems with control inputs without requiring
a finite parameterization of the control. We are currently investigating the possibility of combining both types of random walks in
a single framework. Previous work by some of the authors in this
work considered Monte-Carlo techniques for finding bugs in programs [32]. However, our previous efforts were restricted to safety
properties and did not have a systematic definition of robustness
that we employ here.
There exist two main approaches to the testing problem of hybrid
systems. The first approach is focused on choosing inputs and/or
parameters in a systematic fashion so as to cover the state-space of
the system [9, 3, 4, 25, 26]. These approaches are mainly based
on the theory of rapidly exploring random trees (RRTs). The other
approach is based on the notion of robust simulation trajectory [8,
16, 18, 21]. In robust testing, a simulation trajectory can represent a neighborhood of trajectories achieving, thus, better coverage
guarantees. Recently, the authors in [7] have made the first steps in
bridging these two aforementioned approaches.
On the research front of falsification/verification of temporal logic
properties through testing, the results are limited [27, 29, 11]. The
work that is the closest to ours appears in [29]. The authors of that
work develop a different notion of robustness for temporal logic
specifications, which is also used as a fitness function for optimization problems. Besides the differences in the application domain,
i.e., [29] focuses on parameter estimation for biological systems,
whereas our paper deals with the falsification of hybrid systems,
the two works have also several differences at the theoretical and
computational levels. At the theoretical level, we have introduced a
new metric for hybrid spaces which enables reasoning over hybrid
trajectories, while at the computational level our approach avoids
set operations, e.g., union, complementation etc, which, in general,
increase the computational load.
Younes and Simmons, and more recently, Clarke et al. have pro-

MC
UR
hmin, avg, maxi

Time
MC
avg

UR
avg

h0, 0, 0i
h0, .02, .2i
h0, .5, 1.3i
h9.7, 10.7, 12.4i
h0, 0, 0i
h0, .2, 1.4i

5.6
10.2
20.3
55.5
3
11.9

.8
28
34.0
55.4
.5
26.9

h0, .02, .04i

747

804

posed the technique of Statistical Model Checking (SMC) [35, 6],
which generates uniform random inputs to a system subject to some
constraints, thus converting a given system into a stochastic system.
A probabilistic model checker can be used to prove assertions on
the probability that the system satisfies a given temporal property
ϕ. This probability can be safely approximated using Wald’s probabilistic ratio test. Statistical model checking, like our technique,
requires a simulator to be available for the system but not a transition relation representation. In contrast to SMC, our approach is
guided by a robustness metric towards less robust trajectories. On
the other hand, the complex nature of the system and the robustness metrics imply that we cannot yet provide guarantees on the
probability of satisfaction of the formula.

7. CONCLUSIONS
Embedded systems require the verification of elaborate specifications such as those that can be expressed in MTL. The undecidability of the MTL verification problem over such complex continuous systems mandates the use of lightweight formal methods
that usually involve testing. In this paper, we have presented a
testing framework for the Metric Temporal Logic (MTL) falsification of non-linear hybrid systems using Monte-Carlo optimization
techniques. The use of hit-and-run Monte-Carlo optimization is required in order to overcome the difficulties in handling the complex
system dynamics as well as the nonlinearities in the objective function. Moreover, in order to enable more efficient search in hybrid
state-spaces, a generalized distance function was introduced.
Experimental results indicate the superiority of our testing framework over random search in most of the benchmark examples. The
advantages of our approach are not limited only to the fact that
we can falsify arbitrary systems, but also that we can provide robustness guarantees even to systems that have been proven correct. Even though our results are preliminary, the experiments are
promising enough to indicate that this might be a practical alternative to hybrid system verification methods.

8. ACKNOWLEDGEMENTS
This research was partially supported by NSF CSR-EHS 0720518.

9. REFERENCES
[1] A LUR , R., C OURCOUBETIS , C., H ALBWACHS , N.,
H ENZINGER , T. A., H O , P.-H., N ICOLLIN , X., O LIVERO ,

219

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]

[15]

[16]

[17]

[18]

A., S IFAKIS , J., AND YOVINE , S. The algorithmic analysis
of hybrid systems. Theoretical Computer Science 138, 1
(1995), 3–34.
A NDRIEU , C., F REITAS , N. D., D OUCET, A., AND
J ORDAN , M. I. An introduction to MCMC for machine
learning. Machine Learning 50 (2003), 5–43.
B HATIA , A., AND F RAZZOLI , E. Incremental search
methods for reachability analysis of continuous and hybrid
systems. In HSCC (2004), vol. 2993 of LNCS, Springer,
pp. 142–156.
B RANICKY, M., C URTISS , M., L EVINE , J., AND
M ORGAN , S. Sampling-based planning, control and
verification of hybrid systems. IEE Proc.-Control Theory
Appl. 153, 5 (2006), 575–590.
C HIB , S., AND G REENBERG , E. Understanding the
Metropolis-Hastings algorithm. The American Statistician
49, 4 (Nov 1995), 327–335.
C LARKE , E., D ONZE , A., AND L EGAY, A. Statistical model
checking of analog mixed-signal circuits with an application
to a third order δ − σ modulator. In Hardware and Software:
Verification and Testing (2009), vol. 5394/2009 of Lecture
Notes in Computer Science, pp. 149–163.
DANG , T., D ONZE , A., M ALER , O., AND S HALEV, N.
Sensitive state-space exploration. In Proc. of the 47th IEEE
CDC (Dec. 2008), pp. 4049–4054.
D ONZE , A., AND M ALER , O. Systematic simulation using
sensitivity analysis. In HSCC (2007), vol. 4416 of LNCS,
Springer, pp. 174–189.
E SPOSITO , J. M., K IM , J., AND K UMAR , V. Adaptive
RRTs for validating hybrid robotic control systems. In
Proceedings of the International Workshop on the
Algorithmic Foundations of Robotics (2004).
E SPOSITO , J. M., AND K UMAR , V. An asynchronous
integration and event detection algorithm for simulating
multi-agent hybrid systems. ACM Trans. Model. Comput.
Simul. 14, 4 (2004), 363–388.
FAINEKOS , G. E., G IRARD , A., AND PAPPAS , G. J.
Temporal logic verification using simulation. In FORMATS
(2006), vol. 4202 of LNCS, Springer, pp. 171–186.
FAINEKOS , G. E., AND PAPPAS , G. J. Robustness of
temporal logic specifications for continuous-time signals.
Theoretical Computer Science 410, 42 (2009), 4262–4291.
FAINEKOS , G. E., S ANKARANARAYANAN , S., I VAN ČI Ć ,
F., AND G UPTA , A. Robustness of model-based simulations.
In IEEE Real-Time Systems Symposium (2009).
F EHNKER , A., AND I VAN ČI Ć , F. Benchmarks for hybrid
systems verification. In HSCC (2004), vol. 2993 of LNCS,
springer, pp. 326–341.
F RENKEL , D., AND S MIT, B. Understanding Molecular
Simulation: From Algorithms to Applications. Academic
Press, 1996.
G IRARD , A., AND PAPPAS , G. J. Verification using
simulation. In HSCC (2006), vol. 3927 of LNCS, Springer,
pp. 272 – 286.
G ROSU , R., AND S MOLKA , S. Monte Carlo model
checking. In TACAS (2005), vol. 3440 of Lecture Notes in
Computer Science, pp. 271–286.
J ULIUS , A. A., FAINEKOS , G. E., A NAND , M., L EE , I.,
AND PAPPAS , G. J. Robust test generation and coverage for
hybrid systems. In HSCC (2007), no. 4416 in LNCS,
Springer, pp. 329–342.

[19] K APINSKI , J., K ROGH , B. H., M ALER , O., AND
S TURSBERG , O. On systematic simulation of open
continuous systems. In HSCC (2003), vol. 2623 of LNCS,
Springer, pp. 283–297.
[20] KOYMANS , R. Specifying real-time properties with metric
temporal logic. Real-Time Systems 2, 4 (1990), 255–299.
[21] L ERDA , F., K APINSKI , J., C LARKE , E. M., AND K ROGH ,
B. H. Verification of supervisory control software using state
proximity and merging. In HSCC (2008), vol. 4981 of LNCS,
Springer, pp. 344–357.
[22] L OVASZ , L. Hit-and-run mixes fast. Mathematical
Programming 86 (1999), 443–461.
[23] L OVASZ , L., AND V EMPALA , S. S. Hit-and-run from a
corner. SIAM Journal on Computing 35, 4 (2006), 985–1005.
[24] LYGEROS , J. On reachability and minimum cost optimal
control. Automatica 40 (2004), 917–927.
[25] NAHHAL , T., AND DANG , T. Test coverage for continuous
and hybrid systems. In CAV (2007), vol. 4590 of LNCS,
Springer, pp. 449–462.
[26] P LAKU , E., K AVRAKI , L. E., AND VARDI , M. Y. Hybrid
systems: From verification to falsification. In CAV (2007),
vol. 4590 of LNCS, Springer, pp. 463–476.
[27] P LAKU , E., K AVRAKI , L. E., AND VARDI , M. Y.
Falsification of LTL safety properties in hybrid systems. In
TACAS (2009), vol. 5505 of LNCS, pp. 368 – 382.
[28] P RESS , W. H., F LANNERY, B. P., T EUKOLSKY, S. A., AND
V ETTERLING , W. T. Numerical Recipes: The Art of
Scientific Computing, 2nd ed. Cambridge University Press,
Cambridge (UK) and New York, 1992.
[29] R IZK , A., BATT, G., FAGES , F., AND S OLIMAN , S. On a
continuous degree of satisfaction of temporal logic formulae
with applications to systems biology. In 6th International
Conference on Computational Methods in Systems Biology
(2008), no. 5307 in LNCS, Springer, pp. 251–268.
[30] ROMEIGN , H., AND S MITH , R. Simulated annealing for
constrained global optimization. Journal of Global
Optimization 5 (1994), 101–126.
[31] RUBINSTEIN , R. Y., AND K ROESE , D. P. Simulation and
the Monte Carlo Method. Wiley Series in Probability and
Mathematical Statistics, 2008.
[32] S ANKARANARAYANAN , S., C HANG , R. M., J IANG , G.,
AND I VAN ČI Ć , F. State space exploration using feedback
constraint generation and Monte Carlo sampling. In
ESEC/SIGSOFT FSE (2007), ACM, pp. 321–330.
[33] S MITH , R. Monte Carlo procedures for generating points
uniformly distributed over bounded regions. Operations
Research 38, 3 (1984), 1296–1308.
[34] S MITH , R. L. The hit-and-run sampler: a globally reaching
Markov chain sampler for generating arbitrary multivariate
distributions. In Proceedings of the 28th conference on
Winter simulation (1996), IEEE Computer Society,
pp. 260–264.
[35] YOUNES , H. L. S., AND S IMMONS , R. G. Statistical
probabilistic model checking with a focus on time-bounded
properties. Information & Computation 204, 9 (2006),
1368–1409.
[36] Z ABINSKY, A., S MITH , R., M AC D ONALD , J., ROMEIJN ,
H., AND K AUFMAN , D. Improving hit-and-run for global
optimization. Journal of Global Optimization 3 (1993),
171–192.

220

2015 American Control Conference
Palmer House Hilton
July 1-3, 2015. Chicago, IL, USA

Beyond Single Shooting: Iterative Approaches to Falsification
Jyotirmoy Deshmukh1 , Georgios Fainekos2 , James Kapinski1
Sriram Sankaranarayanan3 , Aditya Zutshi3 , Xiaoqing Jin1

Abstract— Simulation-based falsification techniques using
robustness-guided stochastic search have been successful in
finding property violations in systems that are otherwise not
amenable to formal analysis. A central problem, however, lies in
the phenomenon of simulation-explosion: wherein the number
of simulations required to find violations increases with the size
of the system, along with the time taken for each simulation.
Another problem arises due to corner case phenomenon for
hybrid systems wherein violations are found due to particular
initial conditions, input and switching sequences, that are very
hard to find using stochastic search. In this talk, we demonstrate
techniques that leverage fewer and/or shorter simulation traces
by modifying the system and the properties to iteratively
converge towards a falsification of the original property for the
original system. We present the idea of trajectory splicing, that
explores and incrementally refines multiple, short trajectory
segments to yield a falsification of the original system. Next,
we present the notion of source/target enlargement that makes
corner case bugs easier to find by expanding the set of initial
conditions, the target set and the systems switching conditions
to make the process of finding falsifications easier. We will
briefly address requirements in simulation technologies for large
systems that can make the algorithms presented work faster and
more effectively for model-based designs.

Zutshi and Sankaranarayanan were supported, in part, by the US National
Science Foundation(NSF) under award numbers CNS-1319457 and CNS0953941 and in part by Toyota Engineering and Manufacturing North
America(TEMA). All opinions are those of the authors and not necessarily
of the NSF or TEMA.
1 Toyota Technical Center
2 Arizona State University
3 University of Colorado, Boulder

978-1-4799-8684-2/$31.00 ©2015 AACC

4098

Revision of Specification Automata under Quantitative Preferences

arXiv:1402.3611v1 [cs.FL] 14 Feb 2014

Kangjin Kim and Georgios Fainekos

Abstract— We study the problem of revising specifications
with preferences for automata based control synthesis problems.
In this class of revision problems, the user provides a numerical
ranking of the desirability of the subgoals in their specifications.
When the specification cannot be satisfied on the system, then
our algorithms automatically revise the specification so that the
least desirable user goals are removed from the specification.
We propose two different versions of the revision problem
with preferences. In the first version, the algorithm returns
an exact solution while in the second version the algorithm is
an approximation algorithm with non-constant approximation
ratio. Finally, we demonstrate the scalability of our algorithms
and we experimentally study the approximation ratio of the
approximation algorithm on random problem instances.

I. I NTRODUCTION
Linear Temporal Logic (LTL) has been widely adopted
as a high-level specification language for robotic behaviors
(see [1] for a recent overview). The wide spread adoption
of LTL can be attributed to the tractable algorithms that can
solve automation problems related to robotics (see [1]) and
the connections to natural language [2] and other intuitive
user interfaces [3]. In order for LTL-based control synthesis
methods to move outside research labs and be widely adopted
by the robotics community as a specification language of
choice, specification debugging tools must be developed as
well. In [4], [5], we studied the theoretical foundations of
the specification automata revision problem and we proposed
heuristic algorithms for its solution. In [6], we presented
a version of the revision problem for weighted transition
systems. In the last formulation, the debugging and revision
problem becomes harder to solve since the specification
could fail due to not satisfying certain cost constraints, such
as, the battery capacity, certain time limit, etc.
Here, we revisit the problem posed in [4]. When automatically revising specifications, we are often faced with the
challenge that not all goals have the same value for the user.
In particular, we assume that the user has certain utility or
preference value for each of the subgoals. Thus, an automatic
specification revision should recommend removing the least
desirable goals. In detail, we assume that the specification
is provided as an ω-automaton, i.e., a finite automaton with
Büchi acceptance conditions, and that each symbol labeling
the transitions has a quantitative preference value (i.e., a
positive number).
We formulate two different revision problems. The first
problem concerns removing a set of symbols such that
This work has been partially supported by award NSF CNS 1116136.
K. Kim and G. Fainekos are with the School of Computing, Informatics
and Decision Systems Engineering, Arizona State University, Tempe, AZ
85281, USA {Kangjin.Kim,fainekos}@asu.edu

the synthesis problem has now a solution and the sum
of the preference levels of the set of removed symbols is
minimized. The second problem again seeks to remove a
set of symbols such that the synthesis problem has now a
solution; but now the largest preference level of the symbols
in the removal set must be minimized.
Not surprisingly the former problem is intractable. However, interestingly, the latter problem can be solved in polynomial time. We show how the algorithm that we presented
in [5] can be modified to provide an exact or approximate
solution (depending on the cost function) to the revision
problem with preferences in polynomial time. A practical
implication of the results in this paper is that the user can
now get an exact solution if the goal is to satisfy as many
high preference goals as possible.
Contributions: We define two new versions of the problem of revision under quantitative preferences. We show that
one version can be solved optimally in polynomial time while
the other version of the problem is in general intractable.
We provide an exact and an approximate, respectively,
polynomial time algorithm based on Dijkstra’s algorithm.
Finally, we present some examples and we demonstrate the
computational savings of our approximate algorithm over
the Brute-Force Search Algorithm that solves the intractable
version of the problem exactly.
Related Research: The problem of revising or resolving
conflicting LTL specifications has received considerable attention recently. The closest work to ours is presented in
[7]. The authors consider a number of high-level requirements in LTL which not all can be satisfied on the system.
Each formula that is satisfied gains some reward. The goal
of their algorithm is to maximize the rewards and, thus,
maximize the number of requirements that can be satisfied
on the system. Our problem definition is similar in spirit,
but the problem goals are substantially different and the
two approaches can be viewed as complementary. In [7],
if a whole sub-specification cannot be realized, then it is
aborted. In our case, we try to minimally revise the subspecification so that it can be partially satisfied. Another
substantial difference is that our proposed solutions can be
incorporated directly within the control synthesis algorithm.
Namely, as the algorithm searches for a satisfiable plan, it
also creates the graph where the search for the revision will
take place. In [7], the graph to be used for the revision must
be constructed as a separate step.
The problem of LTL planning with qualitative preferences
has been studied in [8], [9] (see also the references therein
for more research in this direction). As opposed to revision
problem, planning with preferences is based on the fact

that there are many satisfiable plans and, thus, the most
preferable one should be selected. For LTL games, LTLMop
[10] was developed to debug unrealizable LTL specifications
in reactive planning for robotic applications. The problem of
revising LTL specifications on-the-fly as the robot explores
its environment is studied in [11].
In the context of general planners, the problem of finding
good excuses on why the planning failed has been studied in
[12]. Over-Subscription Planning (OSP) [13] and Partial Satisfaction Planning (PSP) [14] are also very related problems.
The aforementioned approaches do not consider extended
goals in LTL.
II. P RELIMINARIES
In this paper, we work with discrete abstractions (Finite
State Machines) of the continuous robotic control system
[15]. Each state of the Finite State Machine (FSM) T is
labeled by a number of symbols from a set Π = {π0 , π1 ,
. . . , πn } that represent regions in the configuration space of
the robot or, more generally, actions that can be performed
by the robot.
Definition 1 (FSM): A Finite State Machine is a tuple
T = (Q, Q0 , →T , hT , Π) where: Q is a set of states;
Q0 ⊆ Q is the set of possible initial states; →T = E ⊆ Q×Q
is the transition relation; and, hT : Q → P(Π) maps each
state q to the set of atomic propositions that are true on q.
We define a path p : N → Q on the FSM to be a sequence
of states and a trace to be the corresponding sequence of sets
of propositions. Formally, a path is a function p : N → Q
such that for each i ∈ N we have p(i) →T p(i + 1) and the
trace is the function composition p̄ = hT ◦ p : N → P(Π).
The language L(T ) of T consists of all possible traces.
Assumption 1: All the states on T are reachable.
In this work, we are interested in the specification automata that impose certain requirements on the traces of T .
In the following, P(Π) denotes the powerset of a set Π.
Definition 2: A specification automaton is a tuple Bs =
s
(SBs , sB
0 , P(Π), δBs , FBs , θ) where:
• SBs is a finite set of states;
B
• s0 s is the initial state;
• P(Π) is the input alphabet;
• δBs : SBs × P(Π) → P(SBs ) is a transition function;
• FBs ⊆ SBs is a set of final states; and
2
• θ : Π × SB → R≥0 is a preference function.
s
l
When s′ ∈ δBs (s, l), we also write s →Bs s′ or
(s, l, s′ ) ∈→Bs . A run r of Bs is a sequence of states
r : N → SBs that occurs under an input trace p̄ taking
s
values in P(Π). That is, for i = 0 we have r(0) = sB
0 and
p̄(i)

for all i ≥ 0 we have r(i) → Bs r(i + 1). Let lim(·) be the
function that returns the set of states that are encountered
infinitely often in the run r of Bs . Then, a run r of an
automaton Bs over an infinite trace p̄ is accepting if and
only if lim(r) ∩ FBs 6= ∅. This is called a Büchi acceptance
condition. Finally, we define the language L(Bs ) of Bs to be
the set of all traces p̄ that have a run that is accepted by Bs .
In order to simplify the discussion in Section III, we will
make the following assumption without loss of generality.

Assumption 2: Between any two states of the specification
automaton there exists at most one transition.
We will also be using the following notations.
2
′
• we define the set EBs ⊆ SB , such that (s, s ) ∈ EBs
s
l

iff ∃l ∈ P(Π) , s →Bs s′ ; and,
2
• we define the function λBs : SB → P(Π) which maps a
s
pair of states to the label of the corresponding transition,
l
i.e., if s →Bs s′ , then λBs (s, s′ ) = l.
In brief, our goal is to generate paths on T that satisfy
the specification Bs [15]. This can be achived by finding
accepting runs on the product automaton A = T × Bs .
Definition 3: The product automaton A = T × Bs is the
automaton A = (SA , sA
0 , P(Π), δA , FA ) where:
• SA = Q × SBs ,
B
A
• s0 = {(q0 , s0 s ) | q0 ∈ Q0 },
• δA : SA × P(Π) → P(SA ) s.t. (qj , sj ) ∈ δA ((qi , si ), l)
iff qi →T qj and sj ∈ δBs (si , l) with l ⊆ hT (qj ),
• FA = Q × F is the set of accepting states.
We say that Bs is satisfiable on T if L(A) 6= ∅. Moreover,
finding a satisfying path on T × Bs is an easy algorithmic
problem [15]. Each accepting (infinite) run consists of two
parts: prefix: a part that is executed only once (from an
initial state to a final state) and, lasso: a part that is repeated
infinitely (from a final state back to itself). Note that if the
prefix or the lasso do not contain a final state, then the
language L(A) is empty. Namely, the synthesis phase has
failed and we cannot find a system behavior that satisfies
the specification.
When a specification B is not satisfiable on a particular
system T , the current motion planning and control synthesis
methods based on automata theoretic concepts [15]–[17] simply return that the specification is not satisfiable without any
other user feedback. In such cases, our previous algorithms
[4], [5] can provide as feedback to the user the closest
revision under equal preference for all goals. Formally, a
revision R is a subset of P(Π) × EBs . Each (π, s, s′ ) ∈ R
indicates that π must be removed from λBs (s, s′ ).
III. R EVISION U NDER P REFERENCES
When choosing an alternative plan, each user can have
different preferences. Suppose that users can assign some
preference level to each proposition labeling the specification automaton through the preference function θ. When
preference level is 0, it is least preferred, and the greater
preference level is, the more preferred it is. However, preference level cannot be ∞. We remark that each occurrence
of an atomic proposition over different transitions can have
different preference levels. Therefore, taking transitions on
the cross-product automaton A, we can get as a reward
preference levels of elements in Π on the transitions.
A revised specification is one that can be satisfied on the
discrete abstraction of the workspace or the configuration
space of the robot. In order to search for a minimal revision,
we need first to define an ordering relation on automata
as well as a distance function between automata. We do
not want to consider the “space” of all possible automata,

but rather the “space” of specification automata which are
semantically close to the initial specification automaton Bs .
The later will imply that we remain close to the initial
intention of the designer. We propose that this space consists of all the automata that can be derived from Bs by
removing symbols from the transitions. Our definition of the
ordering relation between automata relies upon the previous
assumption.
1
Definition 4 (Relaxation): Let B1 = (SB1 , sB
0 , P(Π),
B2
→B1 , FB1 , θB1 ) and B2 = (SB2 , s0 , P(Π), →B2 , FB2 , θB2 )
be two specification automata having the same preference
levels for P(Π). Then, we say that B2 is a relaxation of
B1 and we write B1  B2 if and only if SB1 = SB2 = S,
B2
1
sB
0 = s0 , FB1 = FB2 , θB1 = θB2 and
1) ∀(s, l, s′ ) ∈→B1 − →B2 . ∃l′ .
(s, l′ , s′ ) ∈→B2 − →B1 and l′ ⊆ l.
2) ∀(s, l, s′ ) ∈→B2 − →B1 . ∃l′ .
(s, l′ , s′ ) ∈→B1 − →B2 and l ⊆ l′ .
We remark that if B1  B2 , then L(B1 ) ⊆ L(B2 ) since
the relaxed automaton allows more behaviors to occur.
We can now define the set of automata over which we will
search for a revision.
Definition 5: Given a system T and and a specification
automaton Bs , the set of valid relaxations of Bs is defined
as R(Bs , T ) = {B | Bs  B and L(T × B) 6= ∅}.
We can now search for a solution in the set R(Bs , T ).
Different solutions can be compared from their revision sets.
Definition 6 (Revision Set): Given a specification automaton Bs and a B ∈ R(Bs , T ), the revision set is defined as
R(Bs , B) = {(π, s, s′ ) | π ∈ (λBs (s, s′ ) − λB (s, s′ ))}.
We define two different revision problems.
Problem 1 (Min-Sum Revision): Given a system T and
a specification automaton Bs , if the specification Bs is
not satisfiable on T , then find a revision set R such that
P
ρ∈R θ(ρ) is minimized.
Problem 2 (Min-Max Revision): Given a system T and
a specification automaton Bs , if the specification Bs is
not satisfiable on T , then find a revision set R such that
maxρ∈R θ(ρ) is minimized.
The edges of GA are labeled by the set of symbols which
if removed from the corresponding transition on Bs , they
will enable the transition on A. The overall problem then
becomes one of finding the least number of symbols to be
removed in order for the product graph to have an accepting
run.
Definition 7: Given a system T and a specification automaton Bs , we define the graph GA =
(V, E, vs , Vf , Π, Λ, p), which corresponds to the product
A = T × Bs as follows
• V = S is the set of nodes
• E = EA ∪ ED ⊆ S × S, where EA is the set
of edges that correspond to transitions on A, i.e.,
l
((q, s), (q ′ , s′ )) ∈ EA iff ∃l ∈ P(Π) . (q, s) →A
(q ′ , s′ ); and ED is the set of edges that correspond
to disabled transitions, i.e., ((q, s), (q ′ , s′ )) ∈ ED iff
l
q →T q ′ and s →Bs s′ with l ∩ (Π − hT (q ′ )) 6= ∅

a∧b

⊤
a

s0
b
a∧b

a

s1

a∧b
b

c

⊤

a∧b
a

s2

⊤

s3

b
⊤

Fig. 1: The system T and the specification Bs of Example
1. The LTL formula of Bs is GF (a ∧ F b).
{b}

{a}

{a, b}

{a}

t0 , s 0
{b}
{b}

{a}

{a}

{b}

{a}
{a}

{a, b}

{b}

t1 , s 2

{a, b}

{b}

{a, b}
{a, b}

t2 , s 2
{a}

{a} {a}

{a}

t2 , s 1

{a, b}

{a}

{a}

t2 , s 0

{a}

{a}

t1 , s 1

t0 , s 2
{b}

t1 , s 0
{a}

t0 , s 1
{b}

{a, b}

{a}

{b}

{a, b}

t0 , s 3

t1 , s 3

{b}

t2 , s 3

Fig. 2: The cross-product automaton T ×Bs with relaxations.
Solid transition are for valid transitions and dotted transitions
are for relaxed transitions.

•
•
•
•

vs = sA
0 is the source node
Vf = FA is the set of sinks
Π = {hπ, (s, s′ )i | π ∈ Π, (s, s′ ) ∈ EBs }
Λ : E → P(Π) is the edge labeling function such that
if e = ((q, s), (q ′ , s′ )), then
Λ(e) = {hπ, (s, s′ )i | π ∈ (λBs (s, s′ ) − hT (q ′ ))}.

θ : Π → R≥0 is the preference function of Bs restricted
on Π.
If Λ(e) 6= ∅, then it specifies those atomic propositions
in λBs (s, s′ ) that need to be removed in order to enable the
edge in A. Again, note that the labels of the edges of GA are
subsets of Π rather than Π. This is due to the fact that we
are looking into removing an atomic proposition π from a
specific transition (s, l, s′ ) of Bs rather than all occurrences
of π in Bs .
Consider now a path that reaches an accept state and then
can loop back to the same accept state. The set of labels
of the path is a revision set R that corresponds to some
B ∈ R(Bs , T ). This is immediate by the definition of the
graph GA . Thus, our goal is to solve the Min-Sum and MinMax revision problems on this graph.
Example 1: Let us consider the system T in Fig 1.
The LTL formula of the specification Bs in Fig. 1 is
GF (a ∧ F b)1 . Informally, the specification is ‘Infinitely
•

1 For LTL semantics please see [15]. In this paper, we use LTL formulas
only as notational convenience to represent larger automata.

often visit a and then visit b’. Fig. 2 is the crossproduct automaton T × Bs . The initial state of the
cross-product automaton is (t0 , s0 ). The final states are
(t0 , s0 ), (t1 , s0 ), (t2 , s0 ), (t0 , s3 ), (t1 , s3 ), (t2 , s3 ). Bs is not
satisfiable on T so that there is no reachable path from the
state (t0 , s0 ) to one of the finals and from one of the final
states to back to itself. In this example, the set of atomic
propositions is Π = {a, b, c}. Suppose that the preference
levels of the atomic propositions are θ((si , sj ), {a}) = 3,
θ((si , sj ), {b}) = 5, θ((si , sj ), {c}) = 4 where ∀si , sj ∈ SB .
Then from valid relaxations of Bs , we can find acceptable
paths as follows: p1 = h((t0 , s0 ), {b}, (t0 , s0 )) ((t0 , s0 ),
{b}, (t0 , s0 )) . . .i, p2 = h((t0 , s0 ), ∅, (t0 , s1 )) ((t0 , s1 ),
{b}, (t0 , s0 )) ((t0 , s0 ), ∅, (t0 , s1 )) . . .i, p3 = h((t0 , s0 ), {a},
(t1 , s0 )) ((t1 , s0 ), {a}, (t1 , s0 )) ((t1 , s0 ), {a}, (t1 , s0 )) . . .i,
p4 = h((t0 , s0 ), {a}, (t1 , s0 )) ((t1 , s0 ), {a}, (t1 , s0 ))
((t1 , s0 ), {a, b}, (t2 , s0 )) ((t2 , s0 ), {a, b}, (t2 , s0 )) . . .i, etc.
The sum of preference levels of each path are 5, 5, 3, 8,
respectively. The max of preference levels of each path are
5, 5, 3, 5. Therefore, among the above paths, the path having
atomic propositions that minimize the sum of preference
levels is p3 . It has only {a} on the transitions, so the sum of
preference level of the path is 3 and the max of preference
level of the path is also 3.
△
First, we study the computational complexity of the two
problems by restricting the search problem only to paths from
source (initial state) to sink (accept state). Let P aths(GA )
denote all such paths on GA . We indicate that the graph
search equivalent problem of Problem 2 is in P. Given a
path p = vs v1 v2 . . . vf on GA with vf ∈ Vf , we define the
max-preference level of the path to be:
θmax (p) =

max

(vi ,vi+1 )∈p

θ(Λ(vi , vi+1 ))

Note that this is the same as the original cost function
in Problem 2 since clearly max(vi ,vi+1 )∈p θ(Λ(vi , vi+1 )) =
maxρ∈R θ(ρ) where R = ∪(vi ,vi+1 )∈p Λ(vi , vi+1 ). Thus,
Problem 2 is converted into the following optimization
problem:
p∗ = arg
min
θ(p)
(1)
p∈P aths(GA )
And, thus, the revision will be R = ∪(vi ,vi+1 )∈p∗ Λ(vi , vi+1 ).
Now, we recall the weak optimality principle [18].
Definition 8 (Weak optimality principle): There is an optimal path formed by optimal subpaths.
Proposition 1: The graph search equivalent of Problem 2
satisfies the weak optimality principle.
Proof: Let p∗ be an optimal path under the cost
function θmax , that is, for any other path p, we have
θmax (p) ≥ θmax (p∗). We assume that p∗ is a loopless
path. Notice if a loop exists, then it can be removed without affecting the cost of the path. Let p∗ have a subpath
ps = v1 v2 . . . vi−1 vi which is not optimal, that is p∗ =
p1 ◦ ps ◦ p2 . We use here the notation p1 ◦ p2 to indicate
that the last vertex of p1 and the first vertex of p2 are
the same and are going to be merged. Now assume that
′
there is another subpath p′s = v1 v2′ . . . vj−1
vi such that

θmax (ps ) > θmax (p′s ). Note that θmax (ps ) ≤ θmax (p1 ) and
θmax (ps ) ≤ θmax (p2 ) otherwise p∗ would not be optimal.
We have θmax (ps ) = max(θmax (p1 ), θmax (ps ), θmax (p2 )) =
max(θmax (p1 ), θmax (p′s ), θmax (p2 )) = θmax (p1 ◦ p′s ◦ p2 ).
Hence, the path p1 ◦ p′s ◦ p2 is also optimal. If this process is
repeated, we can construct an optimal path p∗∗ that contains
only optimal subpaths.
The importance of the weak optimality principle being
satisfied is that label correcting and label setting algorithms
can be applied to such problems [18]. Dijkstra’s algorithm
is such an algorithm [19] and, thus, it can provide an exact
solution to the problem.
Now, we proceed to the Min-Sum preference problem.
Given a path p = vs v1 v2 . . . vf on GA with vf ∈ Vf , we
define the sum-preference level of the path to be:
X
θ+ (p) =
{θ(ρ) | ρ ∈ ∪(vi ,vi+1 )∈p Λ(vi , vi+1 )}
and if we are directly provided with a revision set R, then
X
θ+ (R) =
θ(ρ)
ρ∈R

Problem 3: Labeled Path under Additive Preferences
(LPAP). I NPUTS : A graph GA = (V, E, vs , Vf , Π, Λ, θ), and
a preference bound K ∈ N. O UTPUT: a set R ⊆ Π such that
removing all elements in R from edges in E enables a path
from vs to some final vertex vf ∈ Vf and θ+ (R) ≤ K.
We can show that the corresponding decision problem is
NP-Complete.
Theorem 1: Given an instance of the LPAP (GA , K), the
decision problem of whether there exists a path p such that
θ+ (p) ≤ K is NP-Complete.
Proof: [Sketch] Clearly, the problem is in NP since
given a sequence of nodes p, we can verify in polynomial
time that p is a path on GA and θ+ (p) ≤ K.
The problem is NP-hard since we can easily reduce the
revision problem without preferences (see [4]) to this one
by setting the preference levels of all atomic propositions
equal to 1. Then, since all atomic propositions have the same
preference level which is 1, it becomes the problem to find
the minimal number of atomic propositions of the graph.
IV. A LGORITHMS

FOR THE R EVISION
P REFERENCES

P ROBLEM

WITH

In this section, we present Algorithms for the Revision
Problem with Preferable (ARPP). It is based on the Approximation Algorithm of the Minimal Revision Problem
(AAMRP) [5] which is in turn based on Dijkstra’s shortest
path algorithm [19]. The main difference from AAMRP
is that instead of finding the minimum number of atomic
propositions that must be removed from each edge on the
paths of the graph GA , ARPP tracks paths having atomic
propositions that minimize the preferable level from each
edge on the paths of the graph GA .
Here, we present the pseudocode for ARPP. ARPP is
similar to AAMRP in [5]. The difference from [5] is that
AARP uses P REF function instead of using cardinality of the
set. For Min-Sum Revision, the function P REF : Π → R≥0

is defined as following: given a set of label R ⊆ Π and the
preference function θ+ : Π → R≥0 ,
P REF(R) = θ+ (R).
The Min-Sum ARPP is denoted by ARP P+ .
For Min-Max Revision, the function P REF : Π → R≥0 is
defined as following: given a set of label R ⊆ Π and the
preference function θ : Π → R≥0 ,
P REF (R) = max θ(ρ).
ρ∈R

The Min-Max ARPP is denoted by ARP Pmax .
The main algorithm (Alg. 1) divides the problem into
two tasks. First, in line 6, it finds an approximation to the
minimum preference level of atomic propositions from Π
that must be removed to have a prefix path to each reachable
sink (see Section II). Then, in line 11, it repeats the process
from each reachable final state to find an approximation to
the minimum preference level of atomic propositions from
Π that must be removed so that a lasso path is enabled. The
combination of prefix/lasso that removes the least preferable
atomic propositions is returned to the user.
Algorithm 2 follows closely Dijkstra’s shortest path algorithm [20]. It maintains a list of visited nodes V and a
table M indexed by the graph vertices which stores the
set of atomic propositions that must be removed in order
to reach a particular node on the graph. Given a node v, the
preference level of the set M[v, 1] is an upper bound on the
minimum preference level of atomic propositions that must
be removed. That is, if we remove all π ∈ M[v, 1] from Bs ,
then we enable a simple path (i.e., with no cycles) from a
starting state to the state v. The preference level of |M[v, 1]|
is stored in M[v, 2] which also indicates that the node v is
reachable when M[v, 2] < ∞.
The algorithm works by maintaining a queue with the
unvisited nodes on the graph. Each node v in the queue has
as key the summed preference level of atomic propositions
that must be removed so that v becomes reachable on A. The
algorithm proceeds by choosing the node with the minimally
summed preference level of atomic propositions discovered
so far (line 19). Then, this node is used in order to updated
the estimates for the minimum preference level of atomic
propositions needed in order to reach its neighbors (line 23).
A notable difference of Alg. 2 from Dijkstra’s shortest path
algorithm is the check for lasso paths in lines 8-16. After
the source node is used for updating the estimates of its
neighbors, its own estimate for the minimum preference level
of atomic propositions is updated either to the value indicated
by the self loop or the maximum possible preference level
of atomic propositions. This is required in order to compare
the different paths that reach a node from itself.
Correctness: The correctness of the algorithm ARPP is
based upon the fact that a node v ∈ V is reachable on GA
if and only if M[v, 2] < ∞. The argument for this claim is
similar to the proof of correctness of Dijkstra’s shortest path
algorithm in [20]. If this algorithm returns a set of atomic
propositions L which removed from Bs , then the language

Algorithm 1 ARPP
Inputs: a graph GA = (V, E, vs , Vf , Π, Λ, p).
Outputs: the list L of atomic propositions form Π that must
be removed Bs .
1: procedure ARPP(GA )
2:
L←Π
3:
⊲ Each row of M is set to (Π, ∞)
4:
M[:, :] ← (Π, ∞)
5:
M[vs , :] ← (∅, 0)
⊲ Initialize the source node
6:
hM, P, Vi ← F IND M IN PATH (GA , M, 0)
7:
if V ∩ Vf = ∅ then
8:
L←∅
9:
else
10:
for vf ∈ V ∩ Vf do
11:
Lp ← G ETAPF ROM PATH (vs , vf , M, P)
12:
M′ [:, :] ← (Π, ∞)
13:
M′ [vf , :] ← M[vf , :]
14:
G′A ← (V, E, vf , {vf }, Π, L)
15:
hM′ , P′ , V ′ i ← F IND M IN PATH (G′A , M′ , 1)
16:
if vf ∈ V ′ then
17:
Ll ← G ETAPF ROM PATH (vf , vf , M′ , P′ )
18:
if P REF(Lp ∪ Ll ) ≤ P REF(L) then
19:
L ← Lp ∪ Ll
20:
end if
21:
end if
22:
end for
23:
end if
24:
return L
25: end procedure
The function G ETAPF ROM PATH ((vs , vf , M, P)) returns the
atomic propositions that must be removed from Bs in order
to enable a path on A from a starting state vs to a final state
vf given the tables M and P.

L(A) is non-empty. This is immediate by the construction
of the graph GA (Def. 7).
Running time: The analysis of the algorithm ARPP
follows closely the analysis of AAMRP in [5]. The only
difference in the time complexity is that ARPP uses P REF
function in order to compute preference levels of all elements
in Π. Both Min-Sum Revision and Min-Max Revision take
O(Π) since at most they compute preference levels of all
elements in Π. Hence, the running time of F IND M IN PATH
2
is O(E(Π log Π + log V )). Therefore, the running time
2
of ARPP is O(Vf (V Π log Π + E(Π log Π + log V ))) =
2
O(Vf E(Π log Π + log V )) which is polynomial in the size
of the input graph.
V. E XAMPLE

AND

E XPERIMENTS

In this section, we present an example scenario and
experimental results using our prototype implementation of
algorithms and brute-force search.
In the following example, we will be using LTL as a specification language. We remark that the results presented here
can be easily extended to LTL formulas by renaming repeated

Algorithm 2 F IND M IN PATH
Inputs: a graph GA = (V, E, vs , Vf , Π, Λ, p), a table M and
a flag lasso on whether this is a lasso path search.
Variables: a queue Q, a set V of visited nodes and a table
P indicating the parent of each node on a path.
Output: the tables M and P and the visited nodes V
1: procedure F IND M IN PATH (GA ,M,lasso)
2:
V ← {vs }
3:
P[:] ← ∅
⊲ Each entry of P is set to ∅
4:
Q ← V − {vs }
5:
for v ∈ V such that (vs , v) ∈ E and v 6= vs do
6:
hM, Pi ← R ELAX((vs , v), M, P, Λ)
7:
end for
8:
if lasso = 1 then
9:
if (vs , vs ) ∈ E then
10:
M[vs , 1] ← M[vs , 1] ∪ Λ(vs , vs )
11:
M[vs , 2] ← P REF(M[vs , 1] ∪ Λ(vs , vs ))
12:
P[vs ] = vs
13:
else
14:
M[vs , :] ← (Π, ∞)
15:
end if
16:
end if
17:
while Q =
6 ∅ do
18:
⊲ Get node u with minimum M[u, 2]
19:
u ← E XTRACT MIN(Q)
20:
if M[u, 2] < ∞ then
21:
V ← V ∪ {u}
22:
for v ∈ V such that (u, v) ∈ E do
23:
hM, Pi ← R ELAX((u, v), M, P, Λ)
24:
end for
25:
end if
26:
end while
27:
return M, P, V
28: end procedure

occurrences of atomic propositions in the specification and
adding them on the transition system (for details, see [21]).
The following example scenario was inspired by [16], [22],
and we will be using LTL as a specification language.
Example 2 (Single Robot Data Gathering Task): In this
example, we use a simplified road network having three
gathering locations and two upload locations with four
intersections of the road. In Fig. 3, the data gather locations,
which are labeled g1 , g2 , and g3 , are dark gray, the data
upload locations, which are labeled u1 and u2 , are light
gray, and the intersections are labeled i1 through i4 . In order
to gather data and upload the gather-data persistently, the
following LTL formula may be considered: φA := GF(ϕ) ∧
GF(π), where ϕ := g1 ∨ g2 ∨ g3 and π := u1 ∨ u2 . The
following formula can make the robot move from gather
locations to upload locations after gathering data: φG :=
G(ϕ → X(¬ϕ Uπ)). In order for the robot to move to gather
location after uploading, the following formula is needed:
φU := G(π → X(¬π Uϕ)).
Let us consider that some parts of road are not recom-

Algorithm 3 R ELAX
Inputs: an edge (u, v), the tables M and P and the edge
labeling function Λ
Output: the tables M and P
1: procedure R ELAX ((u, v),M,P,Λ)
2:
if P REF (M[u, 1] ∪ Λ(u, v)) < M[v, 2] then
3:
M[v, 1] ← M[u, 1] ∪ Λ(u, v)
4:
M[v, 2] ← P REF(M[u, 1] ∪ Λ(u, v))
5:
P[v] ← u
6:
end if
7:
return M, P
8: end procedure

i2

u1

i2

i4

i4
u1
g2

i1

g2

g3

i1

g3

g1

g1

u2

u2

i3
i3

Fig. 3: Illustration of the simple road network environment
of Example 2. The robot is required to drive right-side of
the road.

mended to drive from gather locations, such as from i4 to
i2 and from i1 to i2 . We can describe those constraints as
follows: ψ1 := G(g1 → ¬(i4 ∧ Xi2 ) Uu1 ) and ψ2 := G(g2 →
¬(i1 ∧ Xi2 ) Uu2 ). If the gathering task should have an order
such as g3 , g1 , g2 , g3 , g1 , g2 , . . ., then the following formula
could be considered: φO := ((¬g1 ∧ ¬g2 ) Ug3 ) ∧ G(g3 →
X((¬g2 ∧ ¬g3 ) Ug1 )) ∧ G(g1 → X((¬g1 ∧ ¬g3 ) Ug2 )) ∧
G(g2 → X((¬g1 ∧ ¬g2 ) Ug3 )). Now, we can informally
describe the mission. The mission is “Always gather data
from g3 , g1 , g2 in this order and upload the collected data
to u1 and u2 . Once data gathering is finished, do not visit
gather locations until the data is uploaded. Once uploading
is finished, do not visit upload locations until gathering data.
You should always avoid the road from i4 to i2 when you
head to u1 from g1 and from i1 to i2 when you head to u2
from g2 ”. The following formula represents this mission:
φsingle := φO ∧ φG ∧ φU ∧ ψ1 ∧ ψ2 ∧ GF(π).
Assume that initially, the robot is in i3 and final nodes
are u1 and u2 . When we made a cross product with the
road and the specification, we could get 36824 states, 350114
transitions and 100 final states. Not removing some atomic
propositions, the specification was not satisfiable.
We tested two different preference levels. For clarity in
presentation, we omit for presenting preference levels on
each transition since we set for all the occurances of the same
symbols the same preference level, we abuse notation and
write θ(π) instead of θ(π, (si , sj )). However, the revision

is for specification transitions. First, the preference level of
the symbols are as follows: for g1 , g2 , g3 , u1 , u2 , i1 , i2 ,
i3 , i4 , the preference levels are 3, 4, 5, 20, 20, 1, 1, 1, 1,
respectively, and for ¬g1 , ¬g2 , ¬g3 , ¬u1 , ¬u2 , ¬i1 , ¬i2 ,
¬i3 , ¬i4 , the preference levels are 3, 4, 5, 20, 20, 1, 1, 1,
1, respectively. ARPP for Min-Sum Revision took 210.979
seconds, and suggested removing ¬g1 and ¬i4 . The total
returned preference was 4 since θ(¬g1 ) = 3 and θ(¬i4 ) =
1. The sequence of the locations suggested by ARPP
is i3 g3 i2 u1 (i1 g1 i3 u2 i1 i2 i4 g2 i3 u2 i1 g1 i3 g3 i4 i2 u1 )+ . We can
check that ¬g1 is from G(g2 → X((¬g1 ∧ ¬g2 ) Ug3 ))
of the formula φO and from ¬ϕ = ¬(g1 ∨ g2 ∨ g3 ) of
the formula φG = G(ϕ → (¬ϕ Uπ)), and ¬i4 is from
G(g1 → ¬(i4 ∧ Xi2 ) Uu1 ) of the formula ψ1 . AARP for
Min-Max Revision took 239 seconds, and returned g1 , ¬g1 ,
¬i1 , and ¬i4 . The maximum returned preference was 3 since
θ(g1 ) = 3 and θ(¬g1 ) = 3.
In the second case, the preference level of the positive atomic propositions are same as the first test, and
the preference level of the negative atomic propositions
are as follow: for ¬g1 , ¬g2 , ¬g3 , ¬u1 , ¬u2 , ¬i1 , ¬i2 ,
¬i3 , ¬i4 , the preference levels are 3, 4, 5, 20, 20, 10,
10, 10, 10, respectively. In this case, ARPP for Min-Sum
Revision took 207.885 seconds, and suggested removing
g3 . The total returned preference was 5 since θ(g3 ) =
5. The sequence of the locations suggested by ARPP
is i3 g3 i4 i2 u1 (i1 g1 i3 u2 i1 i2 i4 g2 i3 u2 i1 i2 u1 )+ . We can check
that g3 is from G(g3 → X((¬g2 ∧¬g3 ) Ug1)) of the formula
φO and from ϕ = (g1 ∨ g2 ∨ g3 ) of the formula φU =
G(φ → X(¬φ Uϕ). ARPP for Min-Max Revision took
214.322 seconds, and returned g1 and ¬g1 . The maximum
preference was 3 since θ(g1 ) = 3 and θ(¬g1 ) = 3.
△
Now, we present experimental results. The propotype
implementation is written in Python.
For the experiments, we utilized the ASU super computing
center which consists of clusters of Dual 4-core processors,
16 GB Intel(R) Xeon(R) CPU X5355 @2.66 Ghz. Our
implementation does not utilize the parallel architecture. The
clusters were used to run the many different test cases in
parallel on a single core. The operating system is CentOS
release 5.9.
In order to assess the experimental approximation ratio of
the heuristic (Min-Sum Revision), we compared the solutions
returned by the heuristic with the Brute-force search. The
Brute-force search is guaranteed to return a minimal solution
to the Min-Sum Revision problem.
We performed a large number of experimental comparisons on random benchmark instances of various sizes. Each
test case consisted of two randomly generated DAGs which
represented an environment and a specification. Both graphs
have self-loops on their leaf nodes so that a feasible lasso
path can be found. The number of atomic propositions in
each instance was equal to four times the number of nodes
in each acyclic graph. For example, in the benchmark where
the graph had 9 nodes, each DAG had 3 nodes, and the
number of atomic propositions was 12. The final nodes are
chosen randomly and they represent 5%-40% of the nodes.

Nodes
9
100
196

Min-Sum
avg
1.305
1.95
2.305

Min-Max
avg
1.785
3.215
3.84

min
0.66
1
1

RATIO
avg
1.423
1.8056
1.7793

max
5
6
8

TABLE III: Numerical Experiments: Number of nodes versus
the results of ARPP for Min-Sum Revision (ARP P+ ) and
ARPP for Min-Max Revision (ARP Pmax ).

The number of edges in most instances were 2-3 times more
than the number of nodes.
Table I compares the results of the Brute-Force Search
Algorithm with the results of ARPP for Min-Sum Revision
on test cases of different sizes (total number of nodes).
For each graph size, we performed 200 tests and we report
minimum, average, and maximum computation times in sec.
Both algorithms were able to finish the computation and
return a minimal revision for instances having 9 nodes and
100 nodes. However, for instances having 196 nodes, the
Brute-Force Search Algorithm had one failed instance which
exceeded the 2 hrs window limit. In the large problem
instances, ARPP for Min-Sum Revision achieved a 600 time
speed-up on the average running time.
In Table II, we present two ratios. RATIO1 captures
the ratios between the sum of preference levels of the set
returned by ARP Pmax over the sum of preference levels of
the set returned by ARP P+ . On the other hand, RATIO2
captures the ratios between the max of preference levels of
the set returned by ARP P+ over the max of preference
levels of the set returned by ARP Pmax . If the ARP P+ was
always returning the optimal solution, then RATIO1 should
always be greater than 1. We observe on the random graph
instances that the result also holds for this particular class
of random graphs. Moreover, there were graph instances
where ARP P+ returned much smaller total preference sum
then ARP Pmax . Importantly, when received the results for
RATIO2, we observe that there exist graph instances where
ARP Pmax returned a revision set with maximum much
less then the maximum preference in the set returned by
ARP P+ . Thus, depending on the user application it could
be desirable to utilize either revision criterion.
Table III shows the comparison between the number of
atomic propositions of the set returned from ARPP for
Min-Sum Revision (ARP P+ ) and the number of atomic
propositions of the set returned from ARPP for Min-Max
Revision (ARP Pmax ). The columns under the avg columns
of Min-Sum and Min-Max indicate the average number of
atomic propositions of the set returned from ARP P+ and
ARP Pmax for graph instances having 9 nodes, 100 nodes,
and 196 nodes. The RATIO captures the ratios between
the number of atomic propositions of the set returned by
ARP Pmax over the number of atomic propositions of the
set returned by ARP P+ . Even though Min-Sum Revision
and Min-Max Revision do not count the number of atomic
propositions while relaxing, this result shows readers how
many atomic propositions each algorithm returns. From the

Nodes
9
100
196

min
0.033
0.065
0.278

Brute-Force
avg
max
0.0921
0.945
0.3707
3.997
303.55
11974

succ
200/200
200/200
199/200

min
0.019
0.065
0.137

Min-Sum Revision
avg
max
succ
0.183
0.874
200/200
0.1598
2.66
200/200
0.4927
12.057
200/200

min
1
1
1

RATIO
avg
max
1
1
1.003
1.619
1.0014
1.1475

TABLE I: Numerical Experiments: Number of nodes versus the results of Brute-Force Search Algorithm and ARPP for
Min-Sum Revision. Under the Brute-Force and Min-Sum Revision columns the numbers indicate computation times in sec.
RATIO indicates the experimentally observed approximation ratio to the optimal solution.
Nodes
9
100
196

Min-Sum Revision (ARP P+ )
min
avg
max
succ
0.019
0.183
0.874
200/200
0.065
0.1598
2.66
200/200
0.137
0.4927
12.057
200/200

Min-Max Revision (ARP Pmax )
min
avg
max
succ
0.02
0.0508
0.66
200/200
0.061
0.1258
0.471
200/200
0.139
0.29824
0.74
200/200

min
1
1
1

RATIO1
avg
max
1.2677
3.4
1.441
5.97
1.4876
5.634

min
1
1
1

RATIO2
avg
max
1.0007
1.1428
1.0264
1.3928
1.0389
2.1904

TABLE II: Numerical Experiments: For each graph GA , Number of nodes versus the results of ARPP for Min-Sum Revision
(ARP P+ ) and ARPP for Min-Max Revision (ARP Pmax ). UnderPthe Min-Sum Revision and
P Min-Max Revision columns
the numbers indicate computation times in sec. RATIO1 indicates (θ(ARRPmax (GA )))/ (θ(ARP P+ (GA ))). RATIO2
indicates max(θ(ARRP+ (GA ))/max(θ(ARP Pmax (GA ))).

fact that the avg of the RATIO for all random graph instances
is greater than 1, we observe that the set returned from
Min-Max Revision in general has more number of atomic
propositions than the set returned from Min-Sum Revision.
VI. C ONCLUSIONS
This paper discusses the problem of specification revision
with user preferences. We have demonstrated that adding
preference levels to the goals in the specification can render
the revision problem easier to solve under the appropriate
cost function. We view the automatic debugging and specification revision problems as foundational for formal methods
to receive wider adoption in the robotics community and
beyond. With the current paper and the predecessors [4]–[6],
[23], we have studied the theoretical foundations of different
versions of the problem. Our algorithms and tools can be
used as add-ons to control synthesis methods developed by
our and other groups [15]–[17], [24], [25]. Our goal for
the future is to incorporate all the specification revision
methods in a comprehensive user-friendly tool that can run
on different platforms.
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers
for their detailed comments.
R EFERENCES
[1] H. Kress-Gazit, “Robot challenges: Toward development of verification and synthesis techniques [errata],” IEEE Robotics Automation
Magazine, vol. 18, no. 4, pp. 108–109, Dec. 2011.
[2] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Translating
structured english to robot controllers,” Advanced Robotics, vol. 22,
no. 12, pp. 1343–1359, 2008.
[3] S. Srinivas, R. Kermani, K. Kim, Y. Kobayashi, and G. Fainekos,
“A graphical language for LTL motion and mission planning,” in
Proceedings of the IEEE International Conference on Robotics and
Biomimetics, 2013.
[4] K. Kim, G. Fainekos, and S. Sankaranarayanan, “On the revision
problem of specification automata,” in Proceedings of the IEEE
Conference on Robotics and Automation, May 2012.

[5] K. Kim and G. Fainekos, “Approximate solutions for the minimal
revision problem of specification automata,” in Proceedings of the
IEEE/RSJ International Conference on Intelligent Robots and Systems,
2012.
[6] ——, “Minimal specification revision for weighted transition systems,”
in Proceedings of the IEEE Conference on Robotics and Automation,
May 2013.
[7] J. Tumova, L. I. R. Castro, S. Karaman, E. Frazzoli, and D. Rus,
“Minimum-violating planning with conflicting specifications,” in
American Control Conference, 2013.
[8] T. C. Son, E. Pontelli, and C. Baral, “A non-monotonic goal specification language for planning with preferences,” in 6th Multidisciplinary
Workshop on Advances in Preference Handling, 2012.
[9] M. Bienvenu, C. Fritz, and S. McIlraith, “Planning with qualitative
temporal preferences,” in International Conference on Principles of
Knowledge Representation and Reasoning, 2006.
[10] V. Raman and H. Kress-Gazit, “Analyzing unsynthesizable specifications for high-level robot behavior using LTLMoP,” in 23rd International Conference on Computer Aided Verification, ser. LNCS, vol.
6806. Springer, 2011, pp. 663–668.
[11] M. Guo, K. H. Johansson, and D. V. Dimarogonas, “Revising motion
planning under linear temporal logic specifications in partially known
workspaces,” in Proceedings of the IEEE Conference on Robotics and
Automation, 2013.
[12] M. Göbelbecker, T. Keller, P. Eyerich, M. Brenner, and B. Nebel,
“Coming up with good excuses: What to do when no plan can
be found,” in Proceedings of the 20th International Conference on
Automated Planning and Scheduling. AAAI, 2010, pp. 81–88.
[13] D. E. Smith, “Choosing objectives in over-subscription planning,”
in Proceedings of the 14th International Conference on Automated
Planning and Scheduling, 2004, p. 393401.
[14] M. van den Briel, R. Sanchez, M. B. Do, and S. Kambhampati, “Effective approaches for partial satisfaction (over-subscription) planning,” in
Proceedings of the 19th national conference on Artifical intelligence.
AAAI Press, 2004, p. 562569.
[15] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, Feb. 2009.
[16] A. Ulusoy, S. L. Smith, X. C. Ding, C. Belta, and D. Rus, “Optimal multi-robot path planning with temporal logic constraints,” in
IEEE/RSJ International Conference on Intelligent Robots and Systems,, 2011, pp. 3087 –3092.
[17] A. LaViers, M. Egerstedt, Y. Chen, and C. Belta, “Automatic generation of balletic motions,” IEEE/ACM International Conference on
Cyber-Physical Systems, vol. 0, pp. 13–21, 2011.
[18] E. Martins, M. Pascoal, D. Rasteiro, and J. Dos Santos, “The optimal
path problem,” Investigacão Operacional, vol. 19, pp. 43–60, 1999.
[19] S. M. LaValle, Planning Algorithms. Cambridge University Press,
2006. [Online]. Available: http://msl.cs.uiuc.edu/planning/

[20] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction
to Algorithms, 2nd ed. MIT Press/McGraw-Hill, Sep. 2001.
[21] LTL2BA
modification.
[Online].
Available:
https://www.assembla.com/code/ltl2ba cpslab/git/nodes
[22] A. Ulusoy, S. L. Smith, X. C. Ding, and C. Belta, “Robust multi-robot
optimal path planning with temporal logic constraints,” in 2012 IEEE
International Conference on Robotics and Automation (ICRA), 2012.
[23] G. E. Fainekos, “Revising temporal logic specifications for motion
planning,” in Proceedings of the IEEE Conference on Robotics and
Automation, May 2011.
[24] L. Bobadilla, O. Sanchez, J. Czarnowski, K. Gossman, and S. LaValle,
“Controlling wild bodies using linear temporal logic,” in Proceedings
of Robotics: Science and Systems, Los Angeles, CA, USA, June 2011.
[25] E. M. Wolff, U. Topcu, and R. M. Murray, “Automaton-guided
controller synthesis for nonlinear systems with temporal logic,” in
International Conference on Intelligent Robots and Systems, 2013.

Extended LTLvis Motion Planning Interface
(Extended Technical Report)
Wei Wei, Kangjin Kim and Georgios Fainekos

arXiv:1607.01419v2 [cs.RO] 24 Jul 2016

The School of Computing, Informatics and Decision Systems Engineering
Arizona State University
Tempe, AZ, USA
Email: {wwei17,Kangjin.Kim,fainekos}@asu.edu

Abstract—This paper introduces a graphical interface for
Linear Temporal Logic (LTL) specifications for mobile robots. It
is a sketch based interface built on the Android platform which
makes the LTL control interface more friendly to non-expert
users. By predefining a set of areas of interest, this interface can
quickly and efficiently create plans that satisfy extended plan
goals in LTL. The interface can also allow users to customize the
paths for this plan by sketching a set of reference trajectories.
Given the custom paths by the user, the LTL specification and
the environment, the interface generates a plan balancing the
customized paths and the LTL specifications. We also show
experimental results with the implemented interface.

I. I NTRODUCTION
As the robots become more capable, so does the need to
specify and monitor complex motion and mission plans. Temporal logics have been proposed as an effective specification
language for complex missions for single [1] and multiple
[2] robots. However, temporal logic specifications are not
easy to write for people without extensive training in formal
logic. Therefore, in [3], we developed a graphical interface
for Linear Temporal Logic (LTL) specifications. In LTLvis,
the user creates a graph structure in the workspace of the
robot which is then translated into an LTL formula which is
forwarded to the planner.
In this paper, we extend our work by allowing the user to
incorporate specific path recommendations for certain parts
of the mission. In particular, we enable the user to sketch
path segments on the user interface which are then taken
into account by the planner. Since we focus on supervised
autonomy, the sketched paths are not trajectories to be tracked
by the robot but rather additional constraints for the LTL
planner. Two challenges arise when adding such path constraints. First, how to identify which path on the roadmap is
the closest to the one sketched by the user. Second, how to
guarantee that the sketched path does not violate any other
requirements provided as part of the LTL requirement. In
this paper, we provide algorithmic answers to both problems.
Furthermore, we demonstrate our framework using an iRobot
Create (TurtleBot) and the LTL planning framework by [4].
Related Work: Graphical control interfaces appear to be
an effective way to control mobile robots [5]. With a graphical
interface, users can control multiple robots more conveniently
[6] by clicking a predefined button instead of writing a robot
control program. The proposed work from [6] is similar to our
approach. However, instead of commanding a robot to follow

a path, they assign a start position for the robot and the robot
will explore the given map to find its path by searching Rapidly
exploring Random Trees (RRT).
In [7], the authors propose a methodology to extract spatial
information about the sketched map and path. This information
including qualitative path movement, the key turning point of
the path and high level path description is helpful to model the
human-like robot navigation. In [8], the authors had shown that
planning using sketch based interfaces can be improved using
path correction. Once users draw a path bypassing an invalid
region (collisions), this interface will auto-correct the invalid
sub-path to a valid Bézier curve. Sakamoto et al. proposed
a robot control interface especially for home robots [9]. The
authors define a set of gesture commands for a set of actions.
They include move with an open curve, vacuum with a closed
curve, stop with a cross mark, etc.
In terms of LTL planning, in [2], the authors proposed
a solution to generate the optimal plan under a temporal
logic specification. LTL is the high level specification for the
planning task which is required to be repeatedly satisfied. To
let the robot complete the mission in a dynamic environment,
Ulusoy et al. proposed a solution in [4]. As the robot sensors
have limited ability to scan the whole environment, they define
a limited region as the local environment.
Summary of Contributions: The main contribution in our
research is to combine an easy-to-use sketch-based interface
with the expressive power of LTL and to improve the LTL
path planner provided by [4] for this hybrid interface1 . A
secondary contribution, which is important on its own, is that
we provide a greedy algorithm to identify the closest path on a
directed topologically grounded graph to a hand drawn curve.
We remark that our algorithm allows the path to be cyclic.
II. P RELIMINARY
In this section, we will first cover the graphical language
for LTL. Then, we will review LTL path planning.
A. Graphical Language for LTL
Temporal logic is a logic that describes events in time.
Linear Temporal Logic (LTL) is a modal temporal logic
reasoning over an infinite sequence of states. This section
mainly introduces the research work by Srinivas, et al on
1 The authors in [4] provide software package RHTL which includes LTL
planner (LOMAP). Our implementation is based on their software package.

Fig. 1: The allowed combination of Boolean and temporal operators over an
edge (Reproduced from [3])

defining a graphical language [3]. In particular, [3] provides
a graphical representation of an LTL formula in a 2D space.
The graph G is a tuple (V, E, v0 , c, L, Λ, x):
• V is the set of nodes;
• E ⊆ V × V is the set of edges;
• v0 ∈ V is the start node;
• c : V → {green, red} is a function that colors each
node either green or red, which corresponds to visiting
or avoiding a node2 ;
• L : V → ΠB (τ ) labels each node with an LTL formula
over the set of propositions Π;
• Λ : E → BO1 × BO2 × T O2 × T O1 is a function that
labels each edge on the graph with one or more Boolean
or temporal operators:
– BO1 = {AN D, OR};
– BO2 = BO1 ∪ {3 , IM P LIES};
– T O1 = {, F U T U RE, ALW AY S};
– T O2 = T O1 ∪ {N EXT, U N T IL}
2
• x : V → R is the position of the node on the map or
on the image
As BO1 is always implicitly used to connect consecutive
propositions, it is not included when forming the graph. Figure
1 is the flowchart of possible values of Λ.
B. LTL Path Planning
Path planning is the problem of finding a path between
a start position and an end position. Temporal logic path
planning is the path planning problem whose result, i.e., path
must satisfy a temporal logic requirement. The basic theory
on temporal logic planning is described in [1], [2]. First we
need to represent an environment as a discrete graph.
Definition 1. (TS) A transition system is a tuple T :=
(QT S , qinit , δT S , Π, h, wT S ), where QT S is a set of states.
It represents the accessible area in the graph;
• qinit ∈ QT S is the starting state;
• δT S ⊆ QT S × QT S denotes the transition relation
between two states;
• Π is a finite set of atomic propositions;
Π
• h : QT S → 2
is a function labeling areas in the
environment with atomic propositions;
• wT S : δ → N is the weight assigned to each transition.
We denote a finite path on the transition system as p =
q0 , q1 , . . . , qn , where q0 = qinit and for 0 ≤ k < n, qk ∈ QT S
2 Icons
3

can be added to help people with color blindness.
denotes an empty symbol.

and (qk , qk+1 ) ∈ δ. The result generated from running this
path is a word v0 v1 . . . , where vk = h(qk ) is the set of atomic
propositions satisfied at qk .
After transferring a given environment into a discretized
transition system TS, we also need to convert a given LTL
specification. Thanks to the tool provided by [10], we can
easily convert any LTL formula into a Büchi automaton. We
introduce the definition of a Büchi automaton.
Definition 2. (BA) A Büchi automaton is a tuple B :=
(QBA , Qinit , δBA , Σ, FBA ), where QBA is a set of states;
• Qinit is a set of initial states;
• δBA ⊆ QBA × Σ × QBA is a transition relation;
• Σ is the input alphabet;
• FBA is a set of accepting states.
For a run of input word W = ω0 ω1 . . . on the Büchi
automaton where ωi ∈ Σ, the resulting sequence would be
r = s0 s1 . . . , where si ∈ QBA and (si , ωi , si+1 ) ∈ δBA .
Now we have both TS and BA in a graph format. The goal is
to find a resulting sequence r = c0 c1 . . . where ci := (qj , sk ),
qj ∈ QT S and sk ∈ QBA . The resulting sequence should be
valid in TS and ending at one accepting state in BA4 . Hence,
we need to construct a product automaton P := T S × BA.
Definition 3. (PA) The product automaton P = T S × BA
between the transition system T :=(QT S ,qinit ,δT S ,Π,h,wT S )
and Büchi automaton B:=(QBA ,Qinit ,δBA ,Σ,FBA ) is a tuple
P :=(SP ,SP O ,δP ,wP ,FP ), where SP =QT S ×QBA is a finite
set of states;
• SP O = qinit × Qinit is the set of initial states;
• δP
⊆ δT S × δBA is a transition relation and
((qi , si ), (qj , sj )) ∈ δP if and only if (qi , qj ) ∈ δT S and
(si , ωi , sj ) ∈ δBA ;
• wP ((qi , si ), (qj , sj ))=wT S (qi , qj ) is a weight function;
• FP =QT S ×FBA is a set of accepting states.
The set of final states FP of the product automaton represents the ultimate goal of the planning path. Then we can
reduce the problem of LTL path planning into finding the
optimal path on a graph given a starting position. At this level,
many methods can be utilized such as A∗ , DFS, Dijkstra etc.
For example, if the resulting path is (q0 , s0 ), (q1 , s1 ), . . . ,
(qn , sn ), then the actual path on the transition system (robot
workspace) will be q0 , q1 , . . . , qn .
III. P ROBLEM D ESCRIPTION
A. Problem Overview
This research mainly focuses on the problems of solving
the path planning under a given LTL specification. Given an
environment, a graphical LTL specification, and the user’s
preferred paths sketched on the environment, find the optimal
path satisfying the LTL specification and maximally following
the user’s path sketches. Once there exist conflicts between
the user sketch path and the LTL specification, the interface
4 For an infinite word, the word should contain at least one accepting state
in BA infinitely often.

Fig. 3: Black nodes and edges: the roadmap of a simple environment. Green
path: pu . Blue nodes: p0

IV. E XTENDED -LTLVIS
E-LTLvis enables several drawing features and different
interface layouts from the original LTLvis [3].
A. Load Map and Create Roadmap
Fig. 2: The procedure of manually creating a roadmap. Upper left: the user is
asked to load a map. Upper right: when a node is selected, it will be colored
green. Lower left: the red nodes are denoted as neighbors of the green node.
Lower right: a complete roadmap.

should be able to regard the LTL specification as a higher
priority requirement and find an alternative path minimizing
the distance from the user sketch path. The rationale behind
this choice is that the user may not be explicitly aware of
important safety requirements and event dependencies when
drawing the desired path. An alternative approach would be
to recommended revisions to the mission requirements based
on the path drawn by the user. We have contacted similar
research in the past in the context of LTL planning under user
preferences [11].
B. Solution Overview
The interface starts with an empty screen asking the user
to input a map image. Then, the user can sketch on the map
using the interface. There are three different editing modes for
planning, roadmap editing, and LTL editing.
• Sketching Mode (Fig. 5): Create nodes; Move nodes;
Draw a path from one node to another; Calculate the
most suitable path according to the user drawing; Clear
current drawing and planning path.
• Roadmap Mode (Fig. 2): Create nodes; Add or remove
undirected edges between nodes; Automatically save once
switching to another mode.
• LTL Mode (Fig. 6): Create nodes; Add or remove edges
with LTL attributes; Edit LTL attributes.
After loading the map, the interface enters the roadmap
mode. A roadmap, which is editable and serializable through
the interface, represents the TS. For example, the roadmap in
Fig. 2 is a topological graph which represents the workspace
of the robot. The roadmap should be stored locally as roadmap
data. If the roadmap data exists, it will be loaded and then the
sketching mode will be entered; otherwise, the interface will
enter the roadmap mode and automatically create an empty
roadmap data for editing. When a user is done editing a
roadmap, the interface will switch to sketching mode. The
last step is to create an LTL specification. However, there is
no restriction for the accessing order of each mode. A user
can access any mode at any time.

Roadmaps can be automatically generated using grid decomposition or a polyhedral decomposition of the environment
[12]. In our interface, we require user to manually create their
own roadmap. First, the interface requires the user to load the
roadmap image when the interface starts (Fig. 2 top left). After
the image is loaded, the interface will search the corresponding
roadmap file (.spc) which stores roadmap data. If it exists, the
data is loaded. If it does not exist, the interface will switch
to roadmap mode and automatically create an empty roadmap
data to allow the user to edit. When finishing editing the map,
the roadmap file will be created to store these nodes and edges
locally. Next time, when the same map image is selected, this
roadmap file will be loaded automatically. We also provide a
video demo in [13] to show in more detail the procedure for
creating a roadmap. Figure 2 contains some screen shots of
this demo.
B. Sketch Path
Sketch mode allows users to customize the path between
any two nodes. In sketching mode, users can add a node by
long pressing on the screen. When customizing the path, you
can first select the starting node, drag the path along the map,
and end the path at another node. This path is denoted as user
sketched path pu . Then, we find the node in the environment
closest to the first node of pu , and denote it as qstart . Also,
we find the node in the environment closest to the last node
of pu , and denote it as qend . Because the user sketched path
may be drawn by curves which consist of too many nodes,
to reduce the computation workload, the path is sampled by
distance dm and angle θm into a list of (blue in the Fig. 3)
nodes (n1, n2, . . . ). After appending qstart to the beginning
of the list and qend to the end of the list, we get a new list of
nodes. This list of nodes is denoted as sampled user sketched
path p0 . For example, in Fig. 3, the green curve is the user
sketched path.
Then, the touch up event will be triggered and the computed
best matching path will be displayed. Since q u may stretch to
areas undefined in the roadmap, this path may not be the same
as q u (Fig. 5). As we need to compare the similarity of two
paths, the best approach is to calculate the volume between
two paths. However, this approach has heavy workload. Thus,
we define a new heuristic, CWPD, to compare two paths.

Definition 4. (CWPD) Component-Wise Path Distance is a
distance between two paths p0 = (n00 , n01 , . . . , n0N −1 ) and
px = (nx0 , nx1 , . . . , nxN −1 ). It is defined as:
CW P D(p0 , px ) =

N
−1
X

dist(n0i , e(nxj ,nxi ) )),

(1)

i=0

where N = size(p0 ), n0i ∈ p0 , nxi , nxj ∈ px , and nxj is previous
node which differs from nxi . If nxi is the first node, nxj equals
to nxi .
We remark that a path can have repetition of nodes.
We use distance to line segment (e(nxj ,nxi ) ) instead of
line to avoid the situation where n0i is very far from
e(nxj ,nxi ) but close to the line(nxj , nxi ). From Eq. (1), we

can also derive the following equation. Let CW P D (n00 ,

n01 , . . . , n0N −1 ), (nx0 , nx1 , . . . , nxN −1 )
denote A and


CW P D (n00 , n01 , . . . , n0N −2 ), (nx0 , nx1 , . . . , nxN −2 )
+
0
x
x
dist(NN −1 , e(nj−1 ,nN −1 ) ) denote B. Then,
A=

N
−1
X

dist(n0i , e(nxj ,nxi ) )

i=1

=

−2
 NX


dist(n0i , e(nxj ,nxi ) ) + dist(n0N −1 , e(nxj−1 ,nxN −1 ) )

i=1

=B
(2)
Then, we definite the best match path in order to compare
it in terms of distance.
Definition 5. (BMP) Best Matching Path pbmp is a feasible
path on the transition system TS with the same starting qinit
and ending position qend as P 0 . It also has the properties:
length(pbmp ) = length(p0 ); pbmp can be cyclic on TS; The
component-wise path distance between pbmp and p0 should
be minimal.
We can reduce the sample distance dm and angle θm to
increase N . Thus, p0 can always have more nodes than pbmp
so that the size of pbmp can be extended to N by adding copies
of nodes in between. For the example in Fig. 4, some possible
BMP candidates are listed in Table I for the candidate path
set (p1 , p2 , p3 ):
p1
p2
p3
p0

A
A
A
A

B
C
B
n1

B
C
B
n2

B
D
B
n3

B
D
B
n4

E
E
B
n5

E
E
E
n6

E
E
E
E

TABLE I: path p0 and its possible BMP candidates. As p0 has more nodes
than px , we can extend the path (A, B, C) to path (A, B, B, . . . , C) or (A, B,
C, . . . , C) to make their number of nodes equal to N . To achieve the minimum
CWPD, we need to compare the CWPDs (shown in Fig. 4) between p0 and
each px . In this example, the path p3 minimizes the CWPD.

As the number of candidate in the worst case is N M , where
M is the number of nodes in TS, it is impractical to list all
of them before searching the minimum CWPD. Instead, we

Fig. 4: The CWPDs of p1 , p2 , p3

create a matrix to store a BMP ending at nxi for each node in
the roadmap. When looping through each node in p0 , the path
stored in the matrix will be updated. The pseudo code of this
greedy algorithm is provided in Alg. 1.
Algorithm 1 F IND BMP(p0 , T S)
Input: a path p0 and T S := (QT S , qinit , δT S , Π, h, wT S )
Output: a path pbmp
1: M ← |QT S |
. the number of elements in QT S
2: N ← |p0 |
. the number of nodes in p0
3: cwpd[:, :] ← ∞
. for N × M matrix
4: bmp[:, :] ← ∅ 

. for N ×
 M matrix
5: hstart, endi ← index(p0 [1]), index(p0 [N ])
6:
. get indices for start and end

 from nodes
 in QT S
7: hcwpd[1, start], bmp[1, start]i ← 0, {p0 [1]}
8: for i = 2 to N do
for j = 1 to M do
9:
10:
U PDATE(cwpd, bmp, i, j, p0 , T S)
11: pbmp ← bmp[N, end]
12: return pbmp
Because the user sketched path may contain cycles intentionally, standard shortest path algorithms [14] cannot be used.
Algorithm 1 solves the problem also with cycles on the graph.
It takes p0 and T S as input. It proceeds sequentially through
all nodes in p0 (line 8). In each iteration of this outer loop, it
calculates M BMPs for each qj (line 9) according to current
user input path (n00 , n01 , . . . , n0i−1 ). These BMPs start from
qstart and end at qj .
Algorithm 2 calculates the new CWPD and BMP by utilizing the results from the previous BMPs and CWPDs using
Eq. (2). For each node qj in QT S , it first checks if qj ’s
previous BMP bmp[i – 1, j] for (p0 [1], . . . , p0 [i – 1]) exists.
If it exists, it calculates the distance between p0 [i] and the
last edge of the path (bmp[i – 1, j], qj ). Then, it stores the
result in bmp[i, j] and cwpd[i, j] if the new cwpd[i, j] is
smaller than the existing value. Then, it repeats the process
for all paths (bmp[i – 1, j], qk ), where qk ∈ N eighbors(qj ).
Note that we can get qj ’s previous BMP and CWPD directly
from bmp[i – 1, j] and cwpd[i – 1, j], respectively, without
recomputing the results. The process will repeat at most M
times; thus, the run time of Alg. 2 is O(M ). In each step, the

Algorithm 2 U PDATE(cwpd, bmp, i, j, p0 , T S)
Input: two matrix cwpd and bmp, two variables i and j, a
path p0 and T S := (QT S , qinit , δT S , Π, h, wT S )
Output:
1: if bmp[i − 1, j] 6= ∅ then . prev. bmp ending at this node
qj ← index−1 (j, QT S )
. returns a node of QT S
2:
. returns a node of p0
n0i ← index−1 (i, p0 )
3:
4:
eprev ← G ET L AST E DGE(bmp[i − 1, j])
cwpdcandi ← cwpd[i − 1, j]+dist(n0i , eself ) . Eq. (2)
5:
6:
if cwpdcandi < cwpd[i, j] then
7:
cwpd[i, j] ← cwpdcandi
8:
bmp[i, j] ← bmp[i − 1, j] + qj
9:
. concatenates qj to the end of bmp[i − 1, j]
for qk in N eighbors(qj ) do
10:
11:
ecurr ← hqj , qk i
k ← index(qk )
. index of nodes in QT S
12:
13:
if ecurr 6= eprev then
cwpdcandi ← cwpd[i − 1, k] + dist(n0i , ecurr )
14:
15:
if cwpdcandi < cwpd[i, k] then
16:
cwpd[i, k] ← cwpdcandi
17:
bmp[i, k] ← bmp[i − 1, k] + qk
•

At line 4, G ET L AST E DGE() returns the last edge of a given path or an edge with
the same two nodes if there is no last edge e.g., G ET L AST E DGE([ABCDE])
returns [AB] and G ET L AST E DGE([A]) returns [AA].

IMPLY

NEXT

Fig. 6: The basic LTL specification that corresponds to the sketched path in
Fig. 5

Mode (for an example see Fig. 6).
Users can also skip the Sketching mode to directly edit
the LTL specification. In this mode, the editing gestures are
identical to LTLvis [3].
D. Send Data
When all the data is ready, users can send the data to the
LTL planner. The LTL planner used in this work is modified
from the RHTL package [4]. By adding path preference logic
in the traditional LTL planner, the resulting path generated
from the new planner will attempt both the LTL specification
and the user input requirement.
V. P LANNING U SING -E-LTLVIS

Roadmap Mode
Sketching Mode
LTL Mode
Redo
Undo
Send

q0

q1

Fig. 5: The user sketched path (arc with dots) and its BMP (solid line in the
middle of lane). Since the user sketches in areas undefined in the roadmap,
the resulting BMP is much different from the sketched path. The textboxes
are added to improve the readability due to the size of the screenshot.

minimum CWPD ending at each node in TS will be stored.
Thus, this algorithm finds the BMP with the minimum CWPD
eventually. The step by step run of Alg. 1 over the example
of Table I can be found in [15]. The algorithm only creates
two global matrices of size NM. Thus, the space complexity
of this algorithm is O(N M ) and the runtime complexity is
O(N M M ). Hence, this algorithm can be implemented on a
mobile device. After applying the algorithm to the scenario in
Fig. 2, we can get the result in Fig. 5.
Usually, users may need to specify the paths between
multiple pairs of nodes. Our algorithm will generate multiple
best matching paths for all user sketched paths. This set of
best matching paths is called the preferred path set.
C. Edit Specifications
After a path is customized in the Sketching mode, there
should be a default LTL specification displayed in the LTL

In this section, we will explain an extended planner (Alg.
3) which is modified from a RHTL package [4]. It takes the
product automaton A, the local transition system T S and the
preferred path set D as inputs. In this algorithm, A will be a
tuple A := (Ψ, qinit , δ, W, F ). We denote a preferred path set
as D, where D := {πuv | πuv = (qu , na1 , na2 , . . . , nam , qv ),
qu , qv ∈ Ψ , na1 , na2 , . . . , nam ∈ QT S }.
Algorithm 3 works as follows. Assume πij ∈ D, the
algorithm first checks if there is transition (qi , qj ) ∈ δ at line
4. If such transition exists, it changes its weight to α. Here,
α ∈ R+ denotes an infinitesimal value. This can increase the
priority of the preferred path set when calculating the shortest
path πA0 from qinit to qaccept in line 6. After finding πA0 ,
we need to replace each transition (qi , qj ) ∈ πA0 with a
corresponding transition from either the preferred path set D
or the transition system T S. As the preferred path set D has
higher priority, if πD exists in the preferred set, we add it to
0
the path πltl . Otherwise, we find a shortest alternative πD
in
T S and add it to πltl . After qaccept is visited, πltl is completed.
For detail, see [15].
VI. E XPERIMENTS
In this section, we are going to test our interface and
planner on a real robot - TurtleBot. TurtleBot is a Robot
Operating System (ROS) based project. It contains two major
hardware devices: Kinect and iRobot base. The TurtleBot
project also contains many useful packages. For example,
turtlebot_navigation is one of the most popular packages used to localize the robot by itself. Then, we use

Algorithm 3 E XTENDED P LANNER(A, T S, D)
Input: a product automaton A := (Ψ, qinit , δ, W, F ), a local
transition system T S := (QT S , qinit , δT S , Π, h, wT S ) and
a preferred path set D := {πuv | πuv = (qu , na1 , na2 ,
. . . , nam , qv ), qu , qv ∈ Ψ , na1 , na2 , . . . , nam ∈ QT S }
Output: an extended path πltl
1: Create an empty list πltl
2: for each πij in D do
. set all the preferred paths to
highest priority to be chosen
hqi , qj i ← hπij [1], πij [|πij |]i
3:
4:
if hqi , qj i ∈ δ then
Change the weight w(qi , qj ) to α
5:
6: Find the shortest path πA0 with minimum sum of edge
weight from qinit to qaccept in A
. based on the
modified priorities above
7: for k = 1 to |πA0 | − 1 do
hqh , qm i ← hπA0 [k], πA0 [k + 1]i
8:
9:
f ound ← ⊥
for πD in D do . πD is a sequence of nodes in QT S
10:
11:
if πD [1]=qh ∧ πD [|πD |]=qm ∧VALID(πD , A) then
12:
Append πD to πltl
f ound ← >
13:
14: if ¬f ound then
0
15:
from qh to qm in T S
Find the shortest path πD
0
16:
Append πD to πltl
17: Append πA0 [|πA0 |] to πltl
. this is for qaccept
18: return πltl
•
•
•

At line 5, α is infinitesimal and α ∈ R+ . It is much smaller than the smallest
weight in W .
At line 11, VALID(πD , A) means that this path πD never visits any avoiding
states in A.
At line 12, 16, 17, each Append operation to πltl adds the element to the tail
of the list.

Fig. 8: Experiment 1: LTL specification, sketched path and resulting trajectory.
The LTL specification is (q0 → Xq1) ∧ (q0 ∧ Fq2).

language, it means “the TurtleBot is required to start from q0
and head for q1. Then it will reach q2 eventually”. It took 1.7
milliseconds in average, having M=6 and N=11.3.
Figure 9 shows the second experiment. The task of the
TurtleBot is to follow the specification (q0 ∧ GF(q1 ∧ Fq2)).
In natural language, it means “the TurtleBot is required to start
from q0 and head for q1 then q2 and loop between q1 and
q2”. It took 4 milliseconds in average, having M=6 and N=29.
In both experiments, the TurtleBot succeeded in finding
the correct path and followed the plan. More details on the
experiment can be found in [13].
VII. C ONCLUSIONS

Fig. 7: The experiment environment and its scanned map

to visualize the environment. The final goal
of this experiment is to use the proposed interface to send an
LTL specification and a preferred path set to the planner. The
planner should generate a path plan and order the TurtleBot
to execute the plan. The real environment (185cm × 430cm)
and its scanned map are shown in Fig. 7.
We performed two experiments 10 times each. We measured
the time needed to compute BMPs from p0 . The number of
nodes in QT S for both scenarios was 6 and the number of
nodes in q 0 in average were 11.3 and 29, respectively. Figure
8 shows the first experiment. The task of the TurtleBot is to
execute the specification (q0 → Xq1)∧(q0∧Fq2) (see [1], [2]
for a description of the temporal logic operators). In natural
turtlebot_rivz

Our current research aims to solve the path planning problem with a path requirement under an LTL specification for
a single robot. We combined the ease of use of a sketch
interface and LTLvis [3] into a hybrid interface to allow users
input customized paths. We conducted two experiments. The
interface can express user demands and the planner can realize
these demands correctly in the experiments. In terms of future
research, the interface can be extended to multiple robots by
adding a cooperation module. Second, we can add a realtime feedback module to the planner so that the users will
know how the robots are running. Third, we plan to perform
a usability study to test its ease of use.
ACKNOWLEDGMENT
This work was partially supported by NSF CPS 1446730.

[12] S. LaValle, Planning Algorithms, 2006.
[13] “[Online],” https://app.assembla.com/spaces/ltlvis/wiki/E-LTLvis.
[14] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction
to Algorithms. MIT Press, 2009.
[15] W. Wei, “Extended LTLvis motion planning interface,” Master’s thesis,
Arizona State University, 2016.

Fig. 9: Experiment 2: LTL specification, sketched path and resulting trajectory.
The LTL specification is (q0 ∧ GF(q1 ∧ Fq2)).

R EFERENCES
[1] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, 2009.
[2] S. L. Smith, J. Tumova, C. Belta, and D. Rus, “Optimal path planning
under temporal logic constraints,” in Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, 2010.
[3] S. Srinivas, R. Kermani, K. Kim, Y. Kobayashi, and G. Fainekos,
“A graphical language for LTL motion and mission planning,” in
Proceedings of the IEEE International Conference on Robotics and
Biomimetics, 2013.
[4] A. Ulusoy, M. Marrazzo, and C. Belta, “Receding horizon control in
dynamic environments from temporal logic specifications,” in Robotics:
Science and Systems, 2013.
[5] D. C. Shah, J. Schneider, and M. E. Campbell, “A robust sketch interface
for natural robot control,” in IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS), 2010.
[6] Y. Ochiai, K. Takemura, A. Ikeda, J. Takamatsu, and T. Ogasawara,
“Remote control system for multiple mobile robots using touch panel
interface and autonomous mobility,” in Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, 2014.
[7] M. Skubic, S. Blisard, C. Bailey, J. A. Adams, and P. Matsakis,
“Qualitative analysis of sketched route maps: Translating a sketch
into linguistic descriptions,” IEEE Transactions on Systems, Man and
Cybernetics, 2004.
[8] J. A. Frank and V. Kapila, “Path bending: Interactive human-robot interfaces with collision-free correction of user-drawn paths,” in Proceedings
of the International Conference on Intelligent User Interfaces, 2015.
[9] D. Sakamoto, K. Honda, M. Inami, and T. Igarashi, Sketch and run: A
stroke-based interface for home robots. 27th International Conference
on Human Factors in Computing Systems, 2009, pp. 197–200.
[10] P. Gastin and D. Oddoux, “Fast LTL to buchi automata translation,” in
Proceedings of the 13th CAV, 2001.
[11] K. Kim and G. Fainekos, “Revision of specification automata under
quantitative preferences,” in IEEE International Conference on Robotics
and Automation, 2014.

V I S PEC: A graphical tool for elicitation of MTL requirements

arXiv:1508.00618v1 [cs.SE] 3 Aug 2015

Bardh Hoxha1 , Nikolaos Mavridis2 and Georgios Fainekos1

Abstract— One of the main barriers preventing widespread
use of formal methods is the elicitation of formal specifications.
Formal specifications facilitate the testing and verification process for safety critical robotic systems. However, handling the
intricacies of formal languages is difficult and requires a high
level of expertise in formal logics that many system developers
do not have. In this work, we present a graphical tool designed
for the development and visualization of formal specifications by
people that do not have training in formal logic. The tool enables
users to develop specifications using a graphical formalism
which is then automatically translated to Metric Temporal
Logic (MTL). In order to evaluate the effectiveness of our tool,
we have also designed and conducted a usability study with
cohorts from the academic student community and industry.
Our results indicate that both groups were able to define formal
requirements with high levels of accuracy. Finally, we present
applications of our tool for defining specifications for operation
of robotic surgery and autonomous quadcopter safe operation.

I. I NTRODUCTION
As robots become commercially available, their correct
operation is of paramount importance. Especially for safety
critical systems, safety must be guaranteed. As for example
in autonomous vehicles [24] and medical robots [17], [13].
Safety requirements are usually expressed in natural language, which is inherently ambiguous, in general. When it is
used for defining system specifications, this ambiguity may
lead to misunderstandings between development teams that
may result in increased costs and delays in development. If
the misunderstandings are not detected, then a product that
does not meet the intended specifications will be developed.
Ideally, specifications should be defined in a mathematical
language, using formal logics. This not only removes ambiguity, but also allows system developers to utilize a vast set
of methods [22] that have been developed by the academic
community for testing and verification of systems. The academic community has also developed automatic tools such as
S-TA L I RO [2], [11], FAPAS [25], SpaceEx [9], CheckMate
[19], F LOW [4], Breach [6], C2E2 [7], KeYmaera [18] and
S TRONG [5] that enable developers to conduct system testing
and verification.
Even though it has been shown, that utilizing formal
specifications can lead to improved testing and verification
[8], the industry still utilizes natural language as the premier
approach in defining specifications. One may conjecture
that the most important reason for doing so is because the
development of specifications through a formal logic requires
1 Bardh Hoxha and Georgios Fainekos are with the School of Computing,
Informatics and Decision Systems Engineering, Arizona State University

{bhoxha,fainekos}@asu.edu
2 Nikolaos Mavridis is with the Interactive Robots and Media Lab and
NCSR Demokritos nmav@alum.mit.edu

a level of mathematical training that many users may not
have [23]. Furthermore, even for expert users, writing formal
specifications is an error prone task [10]. As a result, the
industry has been less willing to utilize formal specifications
in their processes.
In this work, we present a graphical formalism that enables
non-expert users to develop formal specifications for control
systems. The formalism enables the visualization of a large
fragment of MTL. The main challenge in the development
of the formalism lies in finding the right balance between
expressive power and ease-of-use. It is designed for use with
systems and signals and enables both event and time based
specifications. This is the first time that a visual formal
language representation is developed for specifications for
Cyber-Physical Systems (CPS). Here by CPS we define
any system that has discontinuous nonlinear dynamics and
complex safety critical requirements. Prime examples are
medical robotics and autonomous vehicles. A specification
visualization tool has been developed based on the graphical
formalism presented in this work. To evaluate the usefulness
of the tool in terms of usability and ease-of-use, we have
conducted a usability study.
S UMMARY OF C ONTRIBUTIONS :
•
•
•
•

•

We present a graphical formalism that enables the
development of formal specifications.
We present the visual specification tool based on the
graphical formalism.
We conducted a usability study to evaluate the tool.
Through the usability study we proved that both nonexpert users and expert users are able to define formal
requirements accurately using the tool, and derived
suggestions for improvement of the tool.
We present applications of the tool for real-world robots.

R ELATED WORKS : In order to help address the formal
specification challenge, various graphical formalisms have
been studied in the past [20], [1], [15], [3], [26], [21]. The
most relevant works appear in [3] and [26]. In [3], the authors
extend Message Sequence Charts and UML 2.0 Interaction
Sequence Diagrams to propose a scenario based formalism
called Property Sequence Chart (PSC). The formalism is
mainly developed for specifications on concurrent systems.
In [26], PSC is extended to Timed PSC which enables the
addition of timing constructs to specifications.
In terms of usability studies for formal requirements very
few works exist. In [23], the authors study the ability
of expert users to develop requirements in Z. A related
usability study for requirement representation is presented
in [16], where the authors present and evaluate a system

Fig. 1: Overview of the graphical user interface of the MTL specification tool. The example shown represents the MTL
specification φ = 2[0,40] ((speed < 80) → 2[0,40] (rpm < 4000)).

for generating, troubleshooting and executing controllers for
robots using natural language.
II. V ISUAL S PECIFICATION T OOL
The Visual Specification Tool (V I S PEC)1 enables the
development of formal specifications for CPS. Users can
develop requirements in a graphical formalism which is then
translated to Metric Temporal Logic (MTL) [14].
The topic of capturing requirements through graphical
formalisms has been studied in the past [20], [1], [15], [3],
[26]. However, to the best of the authors knowledge, the work
presented here is the first attempt to do so specifically aimed
for the development of specifications for CPS. The initial
idea for the graphical formalism was first presented in [11]
while the tool was still in the early stages of development.
However, in this work we present an updated version of the
tool along with its usability study. The improvements over
the previous version include: a more streamlined interface;
an updated representetion of signals in the interface; and an
updated template definition process.
For CPS specifications, it is often needed to account for
both timing and event sequence occurrence. Both of these are
necessary for reasoning over systems and signals. Consider
the specification 2[0,5] ((speed > 100) → 2[0,5] (rpm >
4000)). It states that whenever within the first 5 seconds,
the vehicle speed goes over 100, then from that moment
on, the engine speed (rpm), for the next 5 seconds, should
always be over 4000. Here both the sequence and timing of
the events are of critical importance.
To ensure that the tool can be utilized by non-expert users,
the following goals for the tool are defined: 1) The user
interface is intuitive to use, i.e, it does no have a high learning
curve; 2) The visual representation of the requirements is
visualy distinct and unambiguous; 3) There is a one-to-one
1 Available
at
https://sites.google.com/a/asu.edu/
s-taliro/vispec

mapping from the visual representation of the requirement
and the corresponding requirement in MTL.
The set of specifications that can be generated from this
graphical formalism is a proper subset of the set of MTL
specifications. Formally, the following grammar produces
the set of formulas that can be expressed by the proposed
graphical formalism:
S
T
A
B
C
D
P

−→
−→
−→
−→
−→
−→
−→

¬T | T
A | B | C
P | ( P∧A) | ( P⇒A)
2I D | 3I D
2I 3I D | 3I 2I D
p | ( p→A) | ( p∧A) | ( p→B ) | ( p∧B )
p | 2I p | 3I p

where p is an atomic proposition. In practice, the atomic
propositions are automatically derived from the templates.
Throughout the development process of the formalism,
it was noticed that the more expressive the formalism, the
more challenging to use it became. Therefore, we focused
on several widely used classes of specifications which are
described in Table I. Examples of the classes of specifications
are presented in the rest of this section.
To make the tool easier to use, we placed several constraints on the types of signals used. Specifically, the signals
and requirements are one dimensional. This enables clear and
structured visualization on a two dimensional user interface.
In Fig. 1, the user interface of the tool is presented
along with its most critical components. The user interface
is composed of a menu, horizontal timeline, rectangular
blocks called templates, and a zoom scroll. While the passage
of time is represented horizontally, the sequence of events
is presented vertically. The formulas are generated from
templates as well as the connections between them.
The main building blocks of the formalism are templates.
These are used for defining temporal logic operators, their
timing intervals, and the expected signal shape. The user

TABLE I: Classes of specifications expressible with the graphical formalism
Specification Class

Explanation

Safety
Reachability
Stabilization

Specifications of the form 2φ used to define specifications where φ should always be true.
Specifications of the form 3φ used to define specifications where φ should be true at least once in the future (on now).
Specifications of the form 32φ used to define specifications that, at least once, φ should be true and from that point
on, stay true.
Specifications of the form 23φ used to define specifications that, it is always the case, that at some point in the future,
φ is true.
Specifications of the form φ → ψ requires the ψ should hold when φ is true.
Specifications of the form N (φ → M ψ), where N and M are temporal operators, used to define an implicative
response between two specifications where the timing of M is relative to timing of N .
Specifications of the form φ ∧ ψ used to define the conjunction of two sub-specifications
Specifications of the form N (φ ∧ M ψ), where N and M are temporal operators, used to define a conjunction between
two specifications where the timing of M is relative to timing of N .

Recurrence
Implication
Reactive Response
Conjunction
Non-strict Sequencing

starts with an empty template and a setup assistant presents
the user with a sequence of dialog boxes that aid in the development of the template. The process is context dependent
where each option selection leads to a potentially different
set of options for the next step.
The first step in the template definition process is to
define the temporal operator. Among the choices (and their
corresponding MTL symbols) are: Always (2), At Least
Once (3), Eventually Always (32), Repeatedly Often and
Finally (23), and now. The options available enable users to
define a wide range of specifications. The following sections
will present examples of a subset of formulas that can be
generated using this graphical formalism.
After the temporal operator is selected, the user sets
the timing bounds for it. Many users might have difficulty
defining timing bounds, especially for specifications with
temporal operators such as Eventually Always (32) and
Repeatedly Often and Finally (23). To illustrate the process,
the tool provides a fill-in-the-blanks sentence format to
the user. For example, if the operator Eventually Always
is selected, the user will have to complete the following
sentence with the timing bounds: “Eventually, between
and
seconds, the signal will become true, and from that
point on, will stay true in the next
to
seconds”.
The set of timing intervals are visualized with color shaded
regions in the template.
The next step in the process is in defining whether the
predicate will evaluate to true when the signal is above
or below a set threshold. For example, for the Always (2)
operator, a signal is selected that is either always above or
below a specified threshold. Once either option is selected,
various signals that fit the requirement are automatically
generated and presented visually. Instead of drawing the
signal, the user will select from one of the generated options.
Consider the following example:
Example 1 A specification from the fragment of MTL formulas called Safety MTL specifications is presented. Specifically, the specification φ1 = 2[0,36] (rpm < 4000). The
formula states that in the next 36 seconds, engine speed
should always be less than 4000. The corresponding graphical formalism for this formula is presented in Fig. 2. Note
that, in regards to the specification, the signal can be of any

shape as long as it is always below the 4000 threshold.
Consider the following example for the At Least Once (3)
temporal operator:
Example 2 A specification from the fragment of MTL formulas called Reachability MTL specifications is presented.
Specifically, the specification φ2 = 3[0,39] (speed > 100).
The formula states that eventually, within the next 39 seconds, the vehicle speed will go over 100. The corresponding
graphical formalism for this formula is presented in Fig. 3.
Again, in regards to the specification, the signal can be of
any shape as long as at one point, within the timing bounds
of the temporal operator, it is above the 100 threshold.

Fig. 2: Example 1: The graphical formalism for the Safety
MTL specification φ1 = 2[0,36] (rpm < 4000).

Fig. 3: Example 2: The graphical formalism for the Reachability MTL specification φ2 = 3[0,39] (speed > 100).
For the Eventually Always (32) operator, at least once
in the timing interval of the eventually operator, the signal
should go above the threshold and stay there for the entire
timing interval of the always operator. Two types of shading
will indicate the timing bounds of the MTL operators.

states that if, within 40 seconds, the vehicle speed is above
100 then within 30 seconds from time 0, the engine speed
should be over 3000. The corresponding graphical formalism
for this formula is presented in Fig. 6.

Fig. 4: Example 3: The graphical formalism for the MTL
specification φ3 = 3[0,30] 2[0,10] (speed > 100).

Example 3 Consider
the
specification
φ3
=
3[0,30] 2[0,10] (speed > 100). The formula states that
at some point in the first 30 seconds, the vehicle speed
will go over 100 and stay above for 10 seconds. The
corresponding graphical formalism for this formula is
presented in Fig. 4.
For the Repeatedly Often and Finally (23) operator, an
oscillating signal is presented where two types of shading
indicate the timing intervals for each MTL operator. Consider
the following example:
Example 4 The specification φ4 = 2[0,30] 3[0,10] (speed >
100) is presented. The formula states that at every timestep
of the simulation in the first 30 seconds, the speed will go
over 100 within the next 10 seconds. The corresponding
graphical formalism for this formula is presented in Fig.
5. No matter how far to the left or right the green shaded
region is moved, contained within the orange region, there
is always a point where the signal is above the threshold.
Recall that the signal is automatically generated so that it
satisfies the options previously selected.

Fig. 6: Example 5: The graphical formalism for the
MTL specification φ5 = (3[0,40] (speed > 100)) →
(3[0,30] (rpm > 3000)).
A second type of relationship enables the user to establish
conjunction between two events. To achieve this, templates
can be grouped. This is indicated by a bold black box. Doing
so requires that both templates evaluate to true. Consider the
following example:
Example 6 Specification φ6 = (2[0,40] (speed < 100)) ∧
(2[0,40] (rpm < 4000)). The formula states that, within 40
seconds, the vehicle speed should be less than 100 and
the engine speed should be under 4000. The corresponding
graphical formalism for this formula is presented in Fig. 7.
The third type of template relationship enables the user
to establish relative timing between two templates. Consider
the following example:

Fig. 5: Example 4: The graphical formalism for the MTL
specification φ4 = 2[0,30] 3[0,10] (speed > 100).
The next important concept in this graphical formalism is
the relationship between templates.
First, the sequence relationship between two templates is
presented. Assume that the first template is already created.
If another template is added below it, then an order in the
execution of the events is defined. The second template is
only considered if the first template is evaluated to true.
Formally, there is an implication relationship from the first
template to the second. Consider the following example:
Example 5 The specification φ5 = (3[0,40] (speed >
100)) → (3[0,30] (rpm > 3000)) is presented. The formula

Example 7 Specification φ7 = 2[0,40] ((speed < 80) →
2[0,40] (rpm < 4000)). Here, the nested specification
2[0,40] (rpm < 4000) is evaluated every time (speed < 80)
is true. This formula is represented in the formalism with
nested templates, otherwise referred to as parent and child
templates. The second template is tabbed and connected to
the first template using a green indicator. In the GUI, such
a nested template is initiated by clicking on the signal of the
parent template. The corresponding graphical formalism is
presented in Fig. 8.
The variety of templates and the connections between
them allow users to express a wide variety of specifications.
III. G RAPHICAL F ORMALISM
The specification development process in V I S PEC is divided in two sub processes. First, given a user input in the
V I S PEC tool, it is translated to a tree structure where the
nodes contain template information such as temporal operators, their corresponding timing parameters, group and the

value threshold for the predicates. Secondly, the generated
tree structure is traversed by a recursive algorithm to generate
the MTL formula. There is a bijection between the visual
representation of a specification and the MTL formula. An
overview of the process is provided in Fig. 10.
An example of the tree structure for MTL formula φ =
2(a ∧ 3b) → (2c ∧ 3(d → (a ∧ 2b))) is shown in Fig.
11. The recursive algorithm for traversing the tree structure
and generating the MTL formula is presented in Alg. 1.
Note that the functions ADD PAREN C ONN{A,B,C,D} add
the parenthesis and connectives between predicates.
IV. U SABILITY S TUDY
A. Hypotheses
The aim of the study is to evaluate whether V I S PEC
enables users to develop formal specifications. Two groups
were considered:
1) Non-expert users: These are users who declared that
they have no experience in working with requirements.
2) Expert users: These are users who declared that they
have experience working with system requirements.
Note that they do not necessarily have experience in
writing requirements using formal logics.
Some of the interesting questions we wanted to investigate,
which are also presented as hypotheses in Tab. II, are:
•
•
•

Whether the graphical formalism enables non-experts
and experts to formalize requirements accurately.
How well the expert cohort performs in comparison to
the non-expert cohort.
How user friendly and easy-to-use V I S PEC is.

Writing formal requirements is a challenging task that
requires a significant amount of training. Therefore, it is safe
to assume that we can reject Hypothesis 1a as supported by
our informal experience. Hypothesis 2a will be tested in a
future work. In addition, we analyze user interaction and
behavior to measure the ease-of-use of the tool.

Fig. 7: Example 6: The graphical formalism for the MTL
specification φ6 = (2[0,40] (speed < 100)) ∧ (2[0,40] (rpm <
4000)).

Algorithm 1 WriteMTL - Algorithm for generating the MTL
formula given a tree structure of the graphical formalism
Input: Tree Structure T = hV, Ei where v ∈ V and v =
hG, Op, Si where G is the group, Op is the temporal
operator and S is the predicate string; string φ
Output: φ
1: function WRITE MTL(T, φ)
2:
C ← T.getChildren.
3:
sC ← size(C)
4:
for node i in C do
5:
φ ← CONC(φ, i.Op)
6:
if i.isParent then
7:
if not(i.S.isEmpty) then
8:
subC ← t.getChildren(i)
9:
if i.G == subC(1).G then
10:
φ ← CONC(φ, ’(’, i.S, ’∧’)
11:
else
12:
if i.isP arent then
13:
φ ← CONC(φ, ’(’, i.S,’→ (’)
14:
else
15:
φ ← CONC(φ, ’(’, i.S,’→’)
16:
end if
17:
end if
18:
φ ← WRITE MTL(i.subtree,φ)
19:
if i.isP arent then
20:
if i.G == subC.G then
21:
φ ← CONC(φ,’)’)
22:
else
23:
φ ← CONC(φ,’))’)
24:
end if
25:
else
26:
if sC > 1 and i 6= sC then
27:
φ ← CONC(φ,’) →’)
28:
else
29:
φ ← CONC(φ,’)’)
30:
end if
31:
end if
32:
else
33:
φ ← CONC(φ,’(’)
34:
φ ← WRITE MTL(i.subtree,φ)
35:
if i 6= sC then
36:
φ ← CONC(φ,’) →’)
37:
else
38:
φ ← CONC(φ,’)’)
39:
end if
40:
end if
41:
else
42:
φ ← CONC(φ,i.S)
43:
if i 6= sC then
44:
φ ← CONC(φ,’∧’)
45:
else
46:
φ ← CONC(φ,’→’)
47:
end if
48:
end if
49:
end for
50: end function

TABLE II: Hypotheses and test results with level of significance α = 0.05. User groups as defined in section IV.A.
Reject null hypothesis

Hypothesis
1a
1b
2a
2b
3alt
T xalt

Non-expert users are able to define formal requirements accurately using formal logics such as MTL.
Non-expert users are able to define formal requirements accurately using the Visual Specification Tool.
Expert users from the industry are able to define formal requirements accurately using formal logics such as MTL.
Expert users from the industry are able to define formal requirements accurately using the Visual Specification Tool.
The mean grade per user for expert users is greater the mean grade per user for non-expert users.
The mean grade per task x for industry users is greater than to the mean grade per task x for non-expert users.

Yes
Yes
Yes
Partially

and actions were logged for each session. The subjects also
completed a demographic and post-completion questionnaire.
D. Metrics

Fig. 8: Example 7: The graphical formalism for the MTL
specification φ7 = 2[0,40] ((speed < 80) → 2[0,40] (rpm <
4000)).
B. Demographics
The non-expert cohort was comprised of twenty subjects
from the student community of Arizona State University.
Most of the subjects are from an engineering background
with little to no experience working with requirements. The
student demographics are presented in Tab. III.
The expert subject cohort was comprised of ten subjects
from the industry in the Phoenix area. The subjects have
experience working with specifications and come from an
engineering background.
TABLE III: Hypothesis 1b Subject Demographics
Freshman
Sophomore
Junior
Senior
Masters
PhD

2
2
5
5
4
2

Computer Science
Software Engineering
Electrical Engineering
Mechanical Engineering
Engineering, other

5
3
3
6
3

Male
Female

12
8

C. Experimental Design
Each subject received a task list to complete. The task
list contained ten tasks related to automotive system specifications. Each task asked the subject to formalize a natural
language specification through V I S PEC and generate an
MTL formula. The list of tasks is presented in Table VI.
The tasks become more complex throughout the session.
The higher the number of the task, the more steps necessary
to complete the task successfully.
Each session is at most 45 minutes long. Subjects received
a one minute and thirty second tutorial on using V I S PEC to
develop specifications. The computer screen was recorded

Two metrics are used for performance evaluation:
Task completion: this is a binary measure, which indicates
whether users were able to finish the task within the set time.
Measure of Accuracy: a value from one to five which is
used to quantify the accuracy of subject generated formulas.
The formulas are graded by formal specification experts
which were given the following two suggested criteria: a)
How accurate the meaning of the natural language specification is captured, and b) Whether the inaccuracies in the user
submitted formula can be easily debugged and corrected in
the testing and verification process. Furthermore, in order to
decrease subjectivity, the following instructions were given
to the expert graders in order to anchor the meanings of
the five different grades of the scale used: A grade of one
indicates that the generated formula is totally inaccurate. A
grade of two indicates that the formula is mostly inaccurate.
A grade of three indicates an inaccurate formula which can
be easily debugged and corrected to the proper formal logic
specification by formal specification experts and thus this is
the minimum acceptable satisfactory result. A grade of four
indicates that the formula is inaccurate but can be debugged
and improved by automated specification debugging tools.
A grade of five indicates that the generated formula is
completely accurate. The group of expert graders consisted
of experts in formal methods and logic.
V. R ESULTS
1) Average grade per task: For both cohorts, the task
performance is presented in Fig. 9. It can be observed that
overall, the mean grade per task for both cohorts is high.
Consider the mean grade per task as a random variable X̄.
Specifically, X̄ : Ω → R, where Ω ∈ {y : 1 ≤ y ≤ 5}.
In Figure 12, we present the survival function SX̄ (x) =
1 − FX̄ (x) = 1 − P (X̄ ≤ x) = P (X̄ > x) based on sample
data. Note that x is the threshold of mean grade accuracy.
2) Hypothesis 1b: To test Hypothesis 1b, we need to
establish what is an acceptable threshold for accuracy in
order to test the hypothesis. As discussed in the metrics
section, we claim that a mean grade higher than three
is an acceptable threshold for non-expert users. Therefore,
hypothesis 1b is reduced to the null hypothesis: the mean
grade per user is less than or equal to three for non-experts.
Let us define the average grade per user as a random
variable Ȳ . Specifically, Ȳ : Ω → R, where Ω ∈ {y :

Grade

Bar plot of mean grade and std. dev. over tasks for non−expert users
6
5
4
3
2
1
T1

T2

T3

T4

T5

T6

T7

T8

Bar plot of mean grade and std. dev. over tasks for expert users
6
5
4
3
2
1

T9 T10

T1

Grade

Box plot of grades over tasks for non−expert users
6
5
4
3
2
1

T2

T3

T4

T5

T6

T7

T8

T9 T10

Box plot of grades over tasks for expert users
6
5
4
3
2
1

T1

T2

T3

T4

T5 T6
Task

T7

T8

T9 T10

T1 T2 T3 T4 T5 T6 T7 T8 T9 T10
Task

Fig. 9: Subject accuracy grades over tasks for both the expert and non-expert cohorts.
V I S PEC
Tool

Tree
Structure

1
Empirical probability

User
Input

MTL

Graphical
Formalism

Fig. 10: The specification development process using
V I S PEC

0.5
non−expert
expert
0

3

3.2

3.4

3.6

3.8

4

4.2

4.4

4.6

4.8

5

4
4.2
x threshold

4.4

4.6

4.8

5

Empirical probability

1

Root

N12 , 1, 3, b

N3 ,2,,
N31 , 2, 2, c
N321 , 3, , a

N322 , 3, 2, b

Fig. 11: The corresponding tree structure for formula φ =
2(a ∧ 3b) → (2c ∧ 3(d → (a ∧ 2b))) where a,b,c and
d are predicates. Each node is composed of a node name,
group number, temporal operator, and predicate. The symbol
 indicates empty parameters.
1 ≤ y ≤ 5}. The sample data from 20 subjects has a mean
grade of 4.43 and standard deviation of 0.41. We test for
normality with the Kolmogorov-Smirnov test, the Chi-square
g.o.f test, and the Anderson-Darling test and all three fail to
reject the null hypothesis that the data follows the normal
distribution. In figure 14, we plot the non-expert data against
a fitted normal distribution and the corresponding Q-Q plot.
If we assume that the data constitute a random sample from
a normal distribution, i.e. Ȳ ∼ N , we can use the t-statistic
to test the hypothesis. We reject the null hypothesis with a
p-value very close to 0.
3) Hypothesis 2b: Similarly, we test Hypothesis 2b for
the expert cohort. Hypothesis 2b is reduced to the null
hypothesis: the mean grade per user is less than or equal to
three for expert users. We test for normality as in the previous
case and all three test fail to reject the null hypothesis that
the data follows the normal distribution.
Consider the average grade per user as a random variable
Z̄. Specifically, Z̄ : Ω → R, where Ω ∈ {y : 1 ≤ y ≤ 5}.
The sample data from 10 subjects has a mean grade of 4.76
and standard deviation of 0.26. In figure 14, we plot the
non-expert data against a fitted normal distribution and the
corresponding Q-Q plot. If we assume that the data constitute
a random sample from a normal distribution, i.e. Z̄ ∼ N we

0.5
non−expert
expert
0

N32 , 2, 3, d

3

3.2

3.4

3.6

3.8

Fig. 12: Top: The empirical probability that the mean grade
per user is greater than threshold x for the non-expert and
expert subjects, i.e., P (Ȳ > x).
Bottom: The empirical probability that the mean grade per
task is greater than threshold x for the non-expert and expert
subjects, i.e., P (X̄ > x).
can use the t-statistic to test the hypothesis.We reject the null
hypothesis with a p-value very close to 0.
Task completion time for non−expert and expert cohorts
250
non−expert
expert

200
Time(sec.)

N1 , 1, 2, a

150
100
50
0

T1

T2

T3

T4

T5

T6

T7

T8

T9

T10

Fig. 13: Example 2: The graphical formalism for the Reachability MTL specification φ2 = 3[0,39] (speed > 100).
4) Hypothesis 3alt : To test Hypothesis 3alt , we conduct
a two sample t-test. The p-value returned from the test is
0.0024 and for a significance level of 0.01, we reject the
null hypothesis. Therefore we claim that the mean grade per
user for expert users is greater than the mean grade per user
for non-experts.
5) Hypothesis T x: Next, we compare the mean grade of
both cohorts in regards to each task. A two sample t-test
is conducted for each task. The results for the tests are

TABLE IV: V I S PEC improvements
# Improve...

Prime Indicators

1.
2.

misclicks; user feedback
task accuracy grade

3.

the process of creating child templates
the tutorial by placing more emphasis
on the difference between implication
and conjunction between templates
the visual representation of grouped
templates

task accuracy
user feedback

grade;

presented in Tab. V. Task 9 is the most difficult task when
it comes to the number of errors generated, and this is the
only task where there is a clear difference in performance
between the expert and non-expert cohorts.
TABLE V: Hypothesis testing of T xnull with α = 0.05
x

Rej. T xnull

p-val.

Conclusion

4
5
6
7
8
9
10

No
No
No
No
No
Yes
No

0.065
0.165
0.074
0.100
0.424
0.016
0.063

potentially
false
potentially
potentially
false
true
potentially

true with more investigation
true with more investigation
true with more investigation
true with more investigation

We observe that the only null hypothesis rejected is for
task nine indicating that the mean grade for expert users is
greater than the mean grade for non-expert users. The subject
accuracy grades over tasks for is shown in Fig. 9.
6) Ease-of-use analysis: One indicator for the ease-of-use
of the application is the total time spent per task. As can be
observed in Fig. 13, the mean time spent per task on average
is at most 167 seconds. For easier identification of points of
difficulty, we divided each task into subtasks. It was observed
that there is no correlation between the length of time spent
in a subtask and correctness. This potentially indicates, as
also verified by correlation testing between times and grades,
that the subjects were unaware of mistakes in the process.
From these and other observations, such as misclicks, and
subject feedback, we have developed a set of refinements
on the tool to improve the user experience. A partial list of
improvements is presented in Table IV.
VI. A PPLICATIONS
A. Robotic Surgery
In the last few decades, there has been a significant
increase in the number of robotics systems, especially in the
health care system. They have been successfully introduced
in multiple areas such as rehabilitation, telesurgery, physical
therapy, elderly care, and remote physician care. In the
following, we will focus on autonomous robotic systems for
surgery where of paramount importance is the safety of these
systems [13]. Specifically, we will consider a model of a
robotic serial link manipulator as presented in [17].
One of the main tasks in surgery is the puncturing action.
The high precision and repeatability of the process, make
robot systems ideal for this task. Also, the trauma induced
around the region is much lower and therefore the recovery
process for the patient is quicker. To complete the puncturing
action, the robot has to move towards the puncturing location.

Test the tissue for various indicators to calibrate for optimal
puncture, bring the puncturing needle to a perpendicular
position and, finally, puncture with correct force and angle. If
the force or angle is miscalculated, it might pose unintended
harm to the patient. Consider the specifications from [17]
that should hold on a serial manipulator for puncturing:
1) From [17]: The force applied to the patient by the end
effector is always less than a given threshold, except
for the puncturing subtask. Formally, assuming that
the operation time is 30 seconds, we have: φs1 =
2[0,30] (¬puncturing → f ≤ fmax ).
2) From [17]: The task is feasible, and the position of
the needle once it stops is inside the target region
R. Formally, assuming that the operation time is 40
seconds, we have: φs2 = 3[0,40] (Stop ∧ needle ∈ R)).
3) Also, other requirements can be expressed for such a
system. For example, the end effector speed should not
be less than vmin and should not be greater than vmax .
Formally: φs3 = 2[0,40] (vmin < vef f < vmax )
The V I S PEC tool is utilized to develop the specifications
for the robotic manipulator. For φs1 , the specification is
presented in Fig. 15. We assume that fmax = 10. For φs2 ,
the specification is presented in Fig. 17. We assume that
needle ∈ R ⇐⇒ 5 < nx < 10 ∧ 5 < ny < 10, where
nx , ny are the x and y coordinates for the needle. For φs3 ,
the specification is presented in Fig. 18. We assume that
vmin = 10 and vmax = 20.
B. Quadcopter
In recent years, quadcopters and other unmanned aerial
vehicles (UAVs) have become a major focus for research both
in the academic community and industry. Among others, they
are used in military operations, nuclear disaster assessment,
firefighting and entertainment. The challenges faced in developing these devices and their control algorithms come from
the flight dynamics and the highly dynamical environment
that they operate in. Also, as the complexity of these devices
increases, so do the performance and reliability requirements.
Consider the following specifications for a quadrotor:
1) The absolute value of the pitch and roll angle should
always be bellow certain thresholds. Formally, assuming
that the operation time is 40 seconds, we have: φq1 =
2[0,40] (|α| < αmax ) ∧ 2[0,40] (|β| < βmax ).
2) If distance to the target region is smaller than a certain threshold d, then for then next 20 seconds, the
speed should not exceed vmax . Formally, assuming that
the operation time is 40 seconds, we have: φq1 =
2[0,40] (dist < d → 2[0,20] (v < vmax )).
The V I S PEC tool is utilized to develop the specifications
for the quadrotor. For φq1 , the specification is presented in
Fig. 16. We assume that αmax = 45 deg, βmax = 45 deg
and γmax = 60 deg. For φq2 , the specification is presented
in Fig. 19. We assume that d = 5 and vmax = 10. For φs3 ,
the specification is presented in Fig. 18. We assume that
vmin = 10 and vmax = 20.

TABLE VI: Task list with automotive system specifications presented in natural language
Task

Natural Language Specification

1.
2.
3.
4.
5.
6.
7.

In the first 40 seconds, vehicle speed should always be less than 160.
In the first 30 seconds, vehicle speed should go over 120.
At some point in time in the first 30 seconds, vehicle speed will go over 100 and stay above for 20 seconds.
At every point in time in the first 40 seconds, vehicle speed will go over 100 in the next 10 seconds.
It is not the case that, for up to 40 seconds, the vehicle speed will go over 100 in every 10 second period.
If, within 40 seconds, vehicle speed is above 100 then within 30 seconds from time 0, engine speed should be over 3000.
If, at some point in time in the first 40 seconds, vehicle speed goes over 80 then from that point on, for the next 30
seconds, engine speed should be over 4000.
In the first 40 seconds, vehicle speed should be less than 100 and engine speed should be under 4000.
At some point in time in the first 40 seconds, vehicle speed should go over 80 and then from that point on, for the next
30 seconds, engine speed should be over 4000.
If, at some point in time in the first 40 seconds, vehicle speed goes over 80 then from that point on, if within the next 20
seconds the engine speed goes over 4000, then, for the next 30 seconds, the vehicle speed should be over 100.

Safety
Reachability
Stabilization
Recurrence
Recurrence
Implication
Reactive Response

8. Conjunction
9. Non-strict sequencing
10. Long sequence

Non−expert data fit with Normal distribution

Expert data fit with Normal distribution

4

4

3

3

2

2

1

1

0

3

3.5

4

4.5

5

5.5

0
3.8

6

4

Quantiles of Input Sample

Quantiles of Input Sample

5.5
5
4.5
4
3.5
−2

−1.5

−1

−0.5
0
0.5
Standard Normal Quantiles

1

4.2

4.4

4.6

4.8

5

5.2

5.4

5.6

5.8

QQ Plot of Sample Data versus Standard Normal

QQ Plot of Sample Data versus Standard Normal

1.5

2

5.5

5

4.5

4
−2

−1.5

−1

−0.5
0
0.5
Standard Normal Quantiles

1

1.5

2

Fig. 14: Subject data fit with a normal distribution and the corresponding Q-Q plot.

Fig. 15: The graphical formalism for φs1 .
VII. C ONCLUSION AND F UTURE W ORK

Fig. 16: The graphical formalism for φq1 .

As robots and other cyber-physical systems become more
complex and ubiquitous, so does the need for better testing
and verification. A set of formal methods that improve
this process require some formal representation of system
specifications. In this work, a graphical formalism and a tool
that enables users to easily develop formal specifications are
presented. The V I S PEC tool enables users who have little to
no mathematical training in formal logics to develop formal
specifications, as was verified by a usability study that was
conducted in order to evaluate the usefulness of the tool
and to get insights on potential improvements. The tool was
utilized to formalize specifications for two robots.
Last but not least, we would like to investigate if the potential inaccuracies of the specifications that users generate with

the tool can be attributed mainly to the inherent ambiguity
of the natural language descriptions which were given, or if
not, which other factors contribute and to what extent. Thus,
in an improved usability study, we aim towards exploring
alternative methods of generation of requirements from engineers for a system, that do not involve the administration of a
natural language description by the experimenter. This would
enable us to study to what extent inherent natural language
ambiguity causes the observed less-than-perfect accuracy that
is sometimes, even if rarely, exhibited.
ACKNOWLEDGMENT: Partial support under NSF awards
CNS-1319560, CNS-1116136, IIP-1454143, IIP-1361926
and the NSF I/UCRC Center for Embedded Systems. We
thank all the participants in the usability study and the

Fig. 19: The graphical formalism for φq2 .

Fig. 17: The graphical formalism for φs2 .

Fig. 18: The graphical formalism for φs3 .
reviewers for the detailed reviews.
R EFERENCES
[1] A. Alfonso, V. Braberman, N. Kicillof, and A. Olivero. Visual timed
event scenarios. In Proceedings of the 26th Int. Conference on
Software Engineering, pages 168–177. IEEE Computer Society, 2004.
[2] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan. S-taliro: A tool for temporal logic falsification for hybrid
systems. In Tools and algorithms for the construction and analysis of
systems, volume 6605 of LNCS, pages 254–257. Springer, 2011.
[3] M. Autili, P. Inverardi, and P. Pelliccione. Graphical scenarios for
specifying temporal properties: an automated approach. Automated
Software Engineering, 14(3):293–340, 2007.
[4] X. Chen, E. Abraham, and S. Sankaranarayanan. Flow*: An analyzer
for non-linear hybrid systems. In Computer-Aided Verification (CAV),
volume 8044 of LNCS, pages 258–263. Springer-Verlag, 2013.
[5] Y. Deng, A. Rajhans, and A. A. Julius. Strong: A trajectory-based
verification toolbox for hybrid systems. In Quantitative Evaluation of
Systems, pages 165–168. Springer, 2013.
[6] A. Donze. Breach, a toolbox for verification and parameter synthesis
of hybrid systems. In Computer Aided Verification, volume 6174 of
LNCS, pages 167–170. Springer, 2010.
[7] P. S. Duggirala, S. Mitra, and M. Viswanathan. Verification of
annotated models from executions. In Proc. of the Eleventh ACM
Int. Conf. on Embedded Software, page 26. IEEE Press, 2013.
[8] G. Fainekos, S. Sankaranarayanan, K. Ueda, and H. Yazarel. Verification of automotive control applications using s-taliro. In Proceedings
of the American Control Conference, 2012.

[9] G. Frehse, C. L. Guernic, A. Donz, S. Cotton, R. Ray, O. Lebeltel,
R. Ripado, A. Girard, T. Dang, and O. Maler. Spaceex: Scalable
verification of hybrid systems. In Proceedings of the 23d CAV, 2011.
[10] G. J. Holzmann. The logic of bugs. In Proc. of the 10th ACM SIGSOFT
symp. on Foundations of soft. eng., pages 81–87. ACM, 2002.
[11] B. Hoxha, H. Bach, H. Abbas, A. Dokhanchi, Y. Kobayashi, and
G. Fainekos. Towards formal specification visualization for testing
and monitoring of cyber-physical systems. In Int. Workshop on Design
and Implementation of Formal Tools and Systems. October 2014.
[12] B. Hoxha, N. Mavridis, and G. Fainekos.
V I S PEC: a graphical tool for elicitation of MTL requirements.
Available at
https://sites.google.com/a/asu.edu/s-taliro/ViSpecTechRpt15.pdf.
[13] Y. Kouskoulas, D. W. Renshaw, A. Platzer, and P. Kazanzides. Certifying the safe design of a virtual fixture control algorithm for a surgical
robot. In C. Belta and F. Ivancic, editors, Hybrid Systems: Computation and Control (part of CPS Week 2013), HSCC’13, Philadelphia,
PA, USA, April 8-13, 2013, pages 263–272. ACM, 2013.
[14] R. Koymans. Specifying real-time properties with metric temporal
logic. Real-Time Systems, 2(4):255–299, 1990.
[15] H. Kugler, D. Harel, A. Pnueli, Y. Lu, and Y. Bontemps. Temporal
logic for scenario-based specifications. In Tools and Alg. for the
Construction and Analysis of Systems, pages 445–460. Springer, 2005.
[16] C. Lignos, V. Raman, C. Finucane, M. Marcus, and H. Kress-Gazit.
Provably correct reactive control from natural language. Autonomous
Robots, 38(1):89–105, 2015.
[17] R. Muradore, D. Bresolin, L. Geretti, P. Fiorini, and T. Villa. Robotic
surgery. Robotics & Automation Magazine, IEEE, 18(3):24–32, 2011.
[18] A. Platzer and J.-D. Quesel. KeYmaera: A hybrid theorem prover for
hybrid systems. In A. Armando, P. Baumgartner, and G. Dowek,
editors, International Joint Conference on Automated Reasoning,
volume 5195 of LNCS, pages 171–178. Springer, 2008.
[19] B. I. Silva and B. H. Krogh. Formal verification of hybrid systems
using CheckMate: a case study. In Proceedings of the American
Control Conference, volume 3, pages 1679 – 1683, June 2000.
[20] M. H. Smith, G. J. Holzmann, and K. Etessami. Events and constraints:
A graphical editor for capturing logic requirements of programs. In Requirements Engineering, 2001. Proceedings. Fifth IEEE International
Symposium on, pages 14–22. IEEE, 2001.
[21] S. Srinivas, R. Kermani, K. Kim, Y. Kobayashi, and G. Fainekos. A
graphical language for LTL motion and mission planning. In Robotics
and Biomimetics (ROBIO), 2013 IEEE International Conference on,
pages 704–709. IEEE, 2013.
[22] S. Tripakis and T. Dang. Model-Based Design for Embedded Systems,
chapter Modeling, Verification and Testing using Timed and Hybrid
Automata, pages 383–436. CRC Press, 2009.
[23] R. Vinter, M. Loomes, and D. Kornbrot. Applying software metrics
to formal specifications: A cognitive approach. In Software Metrics
Symposium, 1998. Metrics 1998. Proceedings. Fifth International,
pages 216–223. IEEE, 1998.
[24] T. Wongpiromsarn, S. Mitra, A. Lamperski, and R. M. Murray. Verification of periodically controlled hybrid systems: Application to an
autonomous vehicle. ACM Trans. Embed. Comput. Syst., 11(S2):53:1–
53:24, Aug. 2012.
[25] B. Yordanov, J. Tmov, I. ern, J. Barnat, and C. Belta. Formal analysis of piecewise affine systems through formula-guided refinement.
Automatica, 49(1):261 – 266, 2013.
[26] P. Zhang, B. Li, and L. Grunske. Timed property sequence chart.
Journal of Systems and Software, 83(3):371–390, 2010.

Article

On the minimal revision problem of
specification automata

The International Journal of
Robotics Research
2015, Vol. 34(12) 1515–1535
Ó The Author(s) 2015
Reprints and permissions:
sagepub.co.uk/journalsPermissions.nav
DOI: 10.1177/0278364915587034
ijr.sagepub.com

Kangjin Kim1, Georgios Fainekos1 and Sriram Sankaranarayanan2

Abstract
As robots are being integrated into our daily lives, it becomes necessary to provide guarantees on their safe and provably
correct operation. Such guarantees can be provided using automata theoretic task and mission planning where the
requirements are expressed as temporal logic specifications. However, in real-life scenarios, it is to be expected that not
all user task requirements can be realized by the robot. In such cases, the robot must provide feedback to the user on why
it cannot accomplish a given task. Moreover, the robot should indicate what tasks it can accomplish which are as ‘‘close’’
as possible to the initial user intent. This paper establishes that the latter problem, which is referred to as the minimal specification revision problem, is NP-complete. A heuristic algorithm is presented that can compute good approximations to
the Minimal Revision Problem (MRP) in polynomial time. The experimental study of the algorithm demonstrates that in
most problem instances the heuristic algorithm actually returns the optimal solution. Finally, some cases where the algorithm does not return the optimal solution are presented.
Keywords
Motion planning, temporal logics, specification revision, hybrid control.

1. Introduction
As robots become mechanically more capable, they are
going to be more and more integrated into our daily lives.
Non-expert users will have to communicate with the robots
in a natural language setting and request a robot or a team
of robots to accomplish complicated tasks. Therefore, we
need methods that can capture the high-level user requirements, solve the planning problem and map the solution to
low-level continuous control actions. In addition, such frameworks must come with mathematical guarantees of safe
and correct operation for the whole system and not just the
high-level planning or the low-level continuous control.
Linear temporal logic (LTL; see Clarke et al., 1999) can
provide the mathematical framework that can bridge the
gap between:
1.

2.

natural language and high-level planning algorithms
(e.g. Dzifcak et al., 2009; Kress-Gazit et al., 2008);
and
high-level planning algorithms and control (e.g. Bhatia
et al., 2010; Fainekos et al., 2009; Karaman et al.,
2008; Roy et al., 2011; Wongpiromsarn et al., 2010).

LTL has been utilized as a specification language in a
wide range of robotics applications. For a good coverage of

the current research directions, the reader is referred to
Fainekos et al. (2009), Kress-Gazit et al. (2009), Karaman
et al. (2008), Kloetzer and Belta (2010), Bhatia et al.
(2010), Wongpiromsarn et al. (2010), Roy et al. (2011),
Bobadilla et al. (2011), Ulusoy et al. (2011), Lacerda and
Lima (2011), LaViers et al. (2011), Filippidis et al. (2012)
and the references therein.
For instance, Fainekos et al. (2009) present a framework
for motion planning of a single mobile robot with secondorder dynamics. The problem of reactive planning and distributed controller synthesis for multiple robots is presented
in Kress-Gazit et al. (2009) for a fragment of LTL
(Generalized Reactivity 1 (GR1)). Wongpiromsarn et al.
(2010) present a method for incremental planning when the
specifications are provided in the GR1 fragment of LTL.
Kloetzer and Belta (2010) and Ulusoy et al. (2011) address
1

School of Computing, Informatics and Decision Systems Engineering,
Arizona State University, Tempe, AZ, USA
2
Department of Computer Science, University of Colorado, Boulder, CO,
USA
Corresponding author:
Kangjin Kim, School of Computing, Informatics and Decision Systems
Engineering, Arizona State University, 660 West 6th Street, Tempe, AZ
85281, USA.
Email: kangjin.kim@asu.edu

1516

the problem of centralized control of multiple robots where
the specifications are provided as LTL formulas. An application of LTL planning methods to humanoid robot dancing
is presented in LaViers et al. (2011). Karaman et al. (2008)
convert the LTL planning problem into Mixed Integer
Linear Programming (MILP) or Mixed Integer Quadratic
Programming (MIQP) problems. The use of samplingbased methods for solving the LTL motion planning problem is explored by Bhatia et al. (2010). All of the previous
applications assume that the robots are autonomous agents
with full control over their actions. An interesting different
approach is taken in Bobadilla et al. (2011) where the
agents move uncontrollably in the environment and the controller opens and closes gates in the environment.
All of the previous methods are based on the assumption
that the LTL planning problem has a feasible solution.
However, in real-life scenarios, it is to be expected that not
all complex task requirements can be realized by a robot or
a team of robots. In such failure cases, the robot needs to
provide feedback to the non-expert user on why the specification failed. Furthermore, it would be desirable that the
robot proposes a number of plans that can be realized by
the robot and which are as ‘‘close’’ as possible to the initial
user intent. Then, the user would be able to understand what
are the limitations of the robot and, also, he/she would be
able to choose among a number of possible feasible plans.
In Fainekos (2011), we made the first steps towards solving the debugging (i.e. why the planning failed) and revision (i.e. what the robot can actually do) problems for
automata theoretic LTL planning (Giacomo and Vardi,
1999). We remark that a large number of robotic applications (e.g. Bhatia et al., 2010; Bobadilla et al., 2011;
Fainekos et al., 2009; Kloetzer and Belta, 2010; LaViers
et al., 2011; Ulusoy et al., 2011) utilize this particular LTL
planning method.
In the follow-up paper (Kim et al., 2012), we studied
the theoretical foundations of the specification revision
problem when both the system and the specification can be
represented by v-automata (Buchi, 1960). In particular, we
focused on the Minimal Revision Problem (MRP), i.e.
finding the ‘‘closest’’ satisfiable specification to the initial
specification, and we proved that the problem is NP-complete even when severely restricting the search space.
Furthermore, we presented an encoding of MRP as a
satisfiability problem and we demonstrated experimentally
that we can quickly get the exact solution to MRP for small
problem instances.
In Kim and Fainekos (2012), we revisited MRP and we
presented a heuristic algorithm that can approximately
solve MRP in polynomial time. We experimentally established that the heuristic algorithm almost always returns the
optimal solution on random problem instances and on LTL
planning scenarios from our previous work. Furthermore,
we demonstrated that we can quickly return a solution to
the MRP problem on large problem instances. Finally, we
provided examples where the algorithm is guaranteed not
to return the optimal solution.

The International Journal of Robotics Research 34(12)

This paper is an extension of the preliminary work in
Kim et al. (2012) and Kim and Fainekos (2012). In this
extended journal version, we present a unified view of the
theory alongside with the proofs that were omitted in the
aforementioned papers. The class of specifications that can
be handled by our framework has been extended as well.
The framework that was presented in Kim et al. (2012) was
geared towards robotic motion planning specifications as
presented in Fainekos et al. (2009). In addition, we prove
that the heuristic algorithm that we presented in Kim and
Fainekos (2012) has a constant approximation ratio only on
a specific class of graphs. Furthermore, we have included
several running examples to enhance the readability of the
paper as well as more case studies to demonstrate the feasibility of the framework. On the other hand, we have
excluded some details on the satisfiability encoding of the
MRP problem which can be found in Kim et al. (2012).

2. Problem formulation
In this paper, we work with discrete abstractions (finite
state machines (FSMs)) of the continuous robotic control
system (Fainekos et al., 2009). This is a common practice
in approaches that hierarchically decompose the control
synthesis problem into high-level discrete planning synthesis and low-level continuous feedback controller composition (e.g. Fainekos et al., 2009; Kloetzer and Belta, 2010;
Kress-Gazit et al., 2009; LaViers et al., 2011; Ulusoy et al.,
2011). Each state of the FSM T is labeled by a number of
symbols from a set P = {p0, p1, ., pn} that represent
regions in the configuration space (see Choset et al., 2005;
LaValle, 2006) of the robot or, more generally, actions that
can be performed by the robot. The control requirements
for such a system can be posed using specification automata B with Büchi acceptance conditions (see Buchi,
1960) also known as v-automata.
The following example presents a scenario for motion
planning of a mobile robot.
Example 1. (Robot motion planning). We consider a
mobile robot which operates in a planar environment. The
continuous state variable x(t) models the internal dynamics
of the robot whereas only its position y(t) is observed. In
this paper, we will consider a second-order model of the
motion of a planar robot (dynamic model):
x_ 1 (t) = x2 (t),
x_ 2 (t) = u(t),

x1 (t) 2 R2 , x1 (0) 2 X1, 0
x2 (t) 2 R2 , x2 (0) = 0, u(t) 2 U

y(t) = x1 (t)
The robot is moving in a convex polygonal environment p0
with four areas of interest denoted by p1, p2, p3, p4 (see
Figure 1). Initially, the robot is placed somewhere in the
region labeled by p1. The robot must accomplish the task:
‘‘Always stay in p0 and visit area p2, then area p3, then
area p4 and, finally, return to and stay in region p1 while

Kim et al.

1517

π

π

π

π
π

Fig. 1. The simple environment of Example 1 along with a lowspeed mobile robot trajectory that satisfies the specification.

π0 ∧ π2 ∧ π3
π0 π0 ∧ π3

π0

s0

π0

π0 ∧ π2

s1

s2

Fig. 3. The modified environment of Figure 1 under large
bounds on the permissible acceleration U. The red regions
indicate areas that should be avoided in order to satisfy :pi
while the yellow regions indicate areas that should be visited in
order to satisfy pi.

π0 ∧ π1 ∧ π4
π0 ∧ ¬π2 ∧ π4

π0 ∧ ¬π2 ∧ π3 ∧ π4

s3

π0 ∧ π1

π0 ∧ ¬π2
π0 ∧ π1 ∧ π3 ∧ π4

s4
π0 ∧ π1

∧4i=0 πi

hTi (qi1 ) = {πi1 }

hTi (qi2 ) = {πi2 }

hTi (qi3 ) = {πi3 }

qi1

qi2

qi3

Fig. 4. Simple FSM model T i of an autonomous agent. Each
state j of the FSM i is labeled by an atomic proposition pij.

Fig. 2. The specification automaton Bm of Example 1.

avoiding area p2,’’ which is captured by the specification
automaton in Figure 2.
In Fainekos et al. (2009), we developed a hierarchical
framework for motion planning for dynamic models of
robots. The hierarchy consists of a high-level logic planner
that solves the motion planning problem for a kinematic
model of the robot, e.g.
z_ (t) = u(t),

z(t) 2 R2 , z(0) 2 Z0

y0 (t) = z(t)
Then, the resulting hybrid controller is utilized for the
design of an approximate tracking controller for the
dynamic model. Since the tracking is approximate, the sets
p need to be modified (see Figure 3 for an example)
depending on the maximum speed of the robot so that the
controller has a guaranteed tracking performance. For
example, in Figure 3, the regions that now must be visited
are the contracted yellow regions, while the regions to be
avoided are the expanded red regions. However, the set
modification might make the specification unrealizable,
e.g. in Figure 3 the robot cannot move from p4 to p1 while
avoiding p2, even though the specification can be realized
on the workspace of the robot that the user perceives. In
this case, the user is entirely left in the dark as of why the
specification failed and, more importantly, on what actually the system can achieve under these new constraints.
This is especially important since the low-level controller
synthesis details should be hidden from the end user.
D

The next example presents a typical scenario for task
planning with two agents.
Example 2. (Multi-agent planning). We consider two
autonomous agents whose independent actions can be
modeled using a FSM as in Figure 4. In this example, each
state qi represents a location i. In order to construct a simple example, we assume that at each discrete time instance
only one agent can move. Alternatively, we can think of
these agents as being objects moved around by a mobile
manipulator and that the manipulator can move only one
object at a time. This means that the state of both objects
can be described by the asynchronous composition of the
two state machines T 1 and T 2 . The asynchronous composition results in a FSM T with nine states where each state
(q1i, q2j) is labeled by hT (q1i , q2j ) = hT 1 (q1i ) [ hT 2 (q2j ).
The system must accomplish the task: ‘‘Object 2 should
be placed in Location 3 after Object 1 is placed in Location
3’’. Note that this requirement could be used to enforce that
Object 2 is going to be positioned on top of Object 1 at the
end of the system execution. However, the requirement permits temporary placing Object 2 in Location 3 before
Object 1 is placed in Location 3. This should be allowed
for problems where a temporary reposition of the objects is
necessary. Now, let us assume that the aforementioned task
is just a part from a long list or requirements which also
include the task: ‘‘Always, Object 1 should not be in
Location 3 until Object 2 moves in Location 3’’.
These are informal requirements and in order to give
them mathematical meaning we will have to use a formal

1518

The International Journal of Robotics Research 34(12)

¬π 13

s2
¬π13

π13 ∧ π23

¬π13

s3

π23

s1

π23

π13 ∧ π23

¬π13

s4
π23

π23

Fig. 5. The specification automaton of Example 2.

language. In LTL (see Clarke et al., 1999), the requirements
1
become F(p13 ^ Fp23) and G(( :p13 )Up23 ). We remark
that the conjunction of these two requirements is actually a
satisfiable specification (even though the requirements
appear conflicting) and the corresponding specification
automaton is presented in Figure 5. The specification
remains satisfiable because the semantics of the logic permit both objects to be placed in Location 3 at the same time
(see transitions on label p13^p23from states s1and s2to
state s3).
However, there is no trajectory of the FSM T that will
satisfy the specification. Recall that the model does not
allow for simultaneous transitions of the two objects.
Again, the user does not know why the specification failed
and, more importantly, on what actually the system can
achieve that is ‘‘close’’ to the initial user intent.
D
When a specification B is not satisfiable on a particular
system T , then the current motion planning and control
synthesis methods (e.g. Fainekos et al., 2009; Kloetzer and
Belta, 2010; LaViers et al., 2011) based on automata theoretic concepts (see Giacomo and Vardi, 1999) simply return
that the specification is not satisfiable without any other
user feedback. In such cases, we would like to be able to
solve the following problem and provide feedback to the
user.
Problem 1. (Minimal revision problem (MRP)). Given a
system T and a specification automaton B, if the specification B cannot be satisfied on T , then find the ‘‘closest’’
specification B0 to B which can be satisfied on T .
Problem 1 was first introduced in Fainekos (2011) for
LTL specifications. In Fainekos (2011), we provided solutions to the debugging and (not minimal) revision problems
and we demonstrated that we can easily get a minimal revision of the specification when the discrete controller synthesis phase fails due to unreachable states in the system.
Assumption 1. All of the states on T are reachable.
In Kim et al. (2012), we introduced a notion of distance
on a restricted space of specification automata and, then,
we were able to demonstrate that MRP is in NP-complete
even on that restricted search space of possible solutions.
Since brute force search is prohibitive for any reasonably
sized problem, we presented an encoding of MRP as a
satisfiability problem. Nevertheless, even when utilizing
state-of-the-art satisfiability solvers, the size of the systems
that we could handle remained small (single robot scenarios in medium complexity environments).

In Kim and Fainekos (2012), we provided an approximation algorithm for MRP. The algorithm is based on
Dijkstra’s single-source shortest path algorithm (Cormen
et al., 2001, see), which can be regarded both as a greedy
and a dynamic programming algorithm (see Sniedovich,
2006). We demonstrated through numerical experiments
that not only the algorithm returns an optimal solution in
various scenarios, but also that it outperforms in computation time our satisfiability based solution. Then, we presented some scenarios where the algorithm is guaranteed
not to return the optimal solution.
Contributions. In this paper, we define the MRP problem
and we provide the proof that MRP is NP-complete even
when restricting the search space (e.g. Problem 2). Then,
we provide an approximation algorithm for MRP and theoretically establish the upper bound of the algorithm for a
special case. Furthermore, we show that for our heuristic
algorithm a constant approximation ratio cannot be established, in general. We also present experimental results of the
scalability of our framework and establish some experimental
approximation bounds on random problem instances. Finally,
in order to improve the paper presentation, we also provide
multiple examples that have not been published before.

3. Preliminaries
In this section, we review some basic results on the automata theoretic planning and the specification revision problem from Fainekos et al. (2009) and Fainekos (2011).
Throughout the paper, we will use the notation P(A) for
representing the powerset of a set A, i.e. P(A) =
fBjB  Ag. Clearly, it includes ; and A itself. We also
define the set difference as A \ B = {x 2 A j x;B}.

3.1. Constructing discrete controllers
We assume that the combined actions of the robot/team of
robots and their operating environment can be represented
using a FSM.
Definition 1. (Finite state machine). A FSM is a tuple
T = (Q, Q0 , !T , hT , P) where





Q is a set of states;
Q0 4 Q is the set of possible initial states;
!T  Q × Q is the transition relation; and
hT : Q ! P(P) maps each state q to the set of atomic
propositions that are true on q.

We define a path on the FSM to be a sequence of states
and a trace to be the corresponding sequence of sets of propositions. Formally, a path is a function p : N ! Q such
that for each i 2 N we have p(i) !T p(i + 1) and the corresponding
trace
is
the
function
composition
p = hT 8 p : N ! P(P). The language L(T ) of T consists
of all possible traces.

Kim et al.

1519

Example 3. For the two agent system in Example 2, a path
would be (q11, q21)(q11, q22)(q12, q22) . and the corresponding trace would be {p11, p21}{p11, p22}{p12, p22} .. D
In this work, we are interested in the v-automata that
will impose certain requirements on the traces of T . Omega
automata differ from the classic finite automata in that they
accept infinite strings (traces of T in our case).
Definition 2. A automaton is a tuple B = (SB , sB0 ,
O, !B , FB ) where:






SB is a finite set of states;
sB0 is the initial state;
O is an input alphabet;
!B  SB × O × SB is a transition relation; and
FB  SB is a set of final states.
l

We also write s ! B s0 instead of (s, l, s0 ) 2!B . A specification automaton is an automaton with Büchi acceptance
condition where the input alphabet is the powerset of the
labels of the system T , i.e. O = P(P).
A run r of a specification automaton B is a sequence of
states r : N ! SB that occurs under an input trace p taking
values in O = P(P). That is, for i = 0 we have r(0) = sB0

p(i)

and for all i  0 we have r(i) ! B r(i + 1). Let lim() be the
function that returns the set of states that are encountered
infinitely often in the run r of B. Then, a run r of an automaton B over an infinite trace p is accepting if and only if
lim (r) \ FB 6¼ ;. This is called a Büchi acceptance condition. Finally, we define the language L(B) of B to be the
set of all traces 
p that have a run that is accepted by B.
Even though the definition of specification automata
(Definition 2) only uses sets of atomic propositions for
labeling transitions, it is convenient for the user to read and
write specification automata with propositional formulas on
the transitions. The popular translation tools from LTL to
automata (e.g. Gastin and Oddoux, 2001) label the transitions with propositional formulas in disjunctive normal
form (DNF). A DNF formula on a transition of a specification automaton can represent multiple transitions between
two states. In the subsequent sections, we will be making
the following simplifying assumption on the structure of the
specification automata that we consider.
Assumption 2. All the propositional formulas that appear
on the transitions of a specification automaton are in DNF.
That is, for any two states s1, s2 of an automaton B, we
represent the propositional formula W
that labels
V the corresponding transition by FB (s1 , s2 ) = i2Ds s j2Csi s cij for
1 2

the scope of this work. Any propositional formula can be
converted in DNF where any negation symbol appears in
front of an atomic proposition. In the case when a translation
tool from LTL to automata does not return transitions labeled
in DNF, then there can be two possible cases. First, the transitions are labeled with sets of atomic propositions (representing a conjunctive clause). In this case, we can easily convert
this set to a propositional formula in DNF by only adding
conjunctions between the atomic propositions. Second, the
transitions are labeled with arbitrary propositional formulas
(possibly in a normal form, e.g. conjunctive normal form
(CNF) or DNF). As we mention above, any arbitrary propositional formula can be converted into DNF. Even though in
theory the length of the resulting DNF formula can grow
exponentially in the worst case, in practice, this is not an issue
since the propositional formulas labeling translations will not
be long. Hence, in general, it is not difficult to computationally transform any transition label in DNF.
Example 4. Let us consider the specification automaton in
Figure 5. The propositional formulas over the set of atomic
propositions P are shorthands for the subsets of P that
would label the corresponding transitions. For example, the
label p13^p23 over the edge (s2, s3) succinctly represents
all the transitions (s2, l, s3) such that {p13, p23} 4 l 4 P.
On the other hand, the label :p13over the edge (s1, s2) succinctly represents all the transitions (s1, l, s2) such that l 4
P and p13;l. On input trace {p11, p21}{p11, p22}{p12,
p22}.the corresponding run would be s1s2s2s2..
D
In brief, our goal is to generate paths on T that satisfy
the specification Bs . In automata theoretic terms, we want
to find the subset of the language L(T ) which also belongs
to the language L(Bs ). This subset is simply the intersection of the two languages L(T ) \ L(Bs ) and it can be constructed by taking the product T × Bs of the FSM T and
the specification automaton Bs . Informally, the automaton
Bs restricts the behavior of the system T by permitting
only certain acceptable transitions. Then, given an initial
state in the FSM T , we can choose a particular trace from
L(T ) \ L(Bs ) according to a preferred criterion.
Definition 3. The product automaton A = T × Bs is the
automaton A = (SA , sA
0 , P(P), !A , FA ) where:





S A = Q × SBs ;
Bs
sA
0 = f(q0 , s0 )jq0 2 Q0 g;
l
!A  SA × P(P) × SA subject to (qi , si ) ! A (qj , sj ) iff
l
qi !T qj and si ! Bs sj with l = hT (qj ) ; and
FA = Q × FB is the set of accepting states.

1 2

some appropriate set of indices Ds1 s2 and Csi 1 s2 . Here, cij is
a literal which is p or :p for some p 2 P. Finally, we
assume that when any sub-formula in FB (s1 , s2 ) is a tautology or a contradiction, then it is replaced by > (true) or
’ (false), respectively.
The last assumption is necessary in order to avoid converting a contradiction like p^:p into a satisfiable formula (see
Section 4). We remark that the Assumption 2 does not restrict

Note that L(A) = L(T ) \ L(Bs ). We say that Bs is satisfiable on T if L(A) 6¼ ;. Moreover, finding a satisfying
path on T × Bs is an easy algorithmic problem (see Clarke
et al., 1999). First, we convert automaton T × Bs to a
directed graph and, then, we find the strongly connected
components (SCCs) in that graph.
If at least one SCC that contains a final state is reachable from an initial state, then there exist accepting

1520

The International Journal of Robotics Research 34(12)

(infinite) runs on T × Bs that have a finite representation.
Each such run consists of two parts: prefix, a part that is
executed only once (from an initial state to a final state);
and lasso, a part that is repeated infinitely (from a final
state back to itself). Note that if no final state is reachable
from the initial or if no final state is within an SCC, then
the language L(A) is empty and, hence, the high-level
synthesis problem does not have a solution. Namely, the
synthesis phase has failed and we cannot find a system
behavior that satisfies the specification.

π0−

1

π0− ∧ π1

0

π0− ∧ π2

π0− ∧ π1 ∧ π2

π0−

Bs

π0− ∧ π1

2

0

π0−

π0−

0

Example 5. The product automaton of Example 2 has 36
states and 240 number of transitions. However, no final
state is reachable from the initial state.
D

B2

2
π0−

B1
π0−

π0− ∧ π2

π0− ∧ π1 ∧ π2

π0−

π0− ∧ π2

π2

π0−

1

1

π0− ∧ π1

2

0

π0−

π0−

1

π0− ∧ π2

π0− ∧ π1 ∧ π2
π2

B3

2
π0−

Fig. 6. Example 7. Bs : the initial specification automaton, here
p
0 [:p0 ; Bs B 1 ; Bs kB 2 ; B s kB3 .

4. The specification revision problem
Intuitively, a revised specification is one that can be satisfied on the discrete abstraction of the workspace or the
:p0

!Bs =

:p0 ^p1

p2

0 ! Bs 0
0 ! Bs 0
0 ! Bs 1
zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{
f(0, l, 0)jl  P and p0 62 lg [ f(0, l, 0)jfp2 g  l  Pg [ f(0, fp1 g, 1), (0, fp1 , p2 g, 1)g [
:p0

:p0 ^p1 ^p2

0 ! 2

:p0 ^p2

1 ! Bs 1

1 ! Bs 2

Bs

zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{
[ f(1, l, 1)jl  P and p0 62 lg [ f(1, fp2 g, 2), (1, fp1 , p2 g, 2)g [ f(0, fp1 , p2 g, 2)g [
:p0

2 ! Bs 2

zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{
[ f(2, l, 2)jl  P and p0 62 lg
>

0 ! B1 0

!B 1 =

:p0 ^p1

0 ! B1 1

>

1 ! B1 1

1

:p0 ^p2

!
B1

2

zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{
f(0, l, 0)jl  Pg [ f(0, fp1 g, 1), (0, fp1 , p2 g, 1)g [ f(1, l, 1)jl  Pg [ f(1, fp2 g, 2), (1, fp1 , p2 g, 2)g [
:p0
p2
0 ! B1 2
2 ! B1 2
zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{ zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{
[ f(0, l, 2)jfp2 g  l  Pg [ f(2, l, 2)jl  P and p0 62 lg

configuration space of the robot. In order to search for a
minimal revision, we need first to define an ordering relation on automata as well as a distance function between
automata. Similar to the case of LTL formulas in Fainekos
(2011), we do not want to consider the ‘‘space’’ of all possible automata, but rather the ‘‘space’’ of specification automata which are semantically close to the initial
specification automaton Bs . The later will imply that we
remain close to the initial intention of the designer. We propose that this space consists of all the automata that can be
derived from Bs by relaxing the restrictions for transitioning from one state to another. In other words, we introduce
possible transitions between two states of the specification
automaton.
Example 6. Consider the specification automaton Bs and
the automaton B1 in Figure 6. The transition relations of
the two automata are defined as

and, hence, !Bs !B1 . In other words, any transition
allowed by Bs is also allowed by B1 and, thus, any trace
accepted by Bs is also accepted B1 . If we view this from the
perspective of the specification, then this means that the
specification imposes less restrictions or that the specification automaton B1 is a relaxed specification with respect to
Bs .
D
As the previous example indicated, specification relaxation could be defined as the subset relation between the
transition relations of the specification automata. However,
this is not sufficient from the perspective of user requirements. For instance, consider again Example 6. The transi:p0 ^p2

(:p0 ^p2 )_p3

Bs

Bs

tion ﬃ ! ﬄ could be relaxed as ﬃ ! ﬄ. A
relevant relaxation from the user perspective should be
removing either of the constraints :p0 or p2 rather than
introducing a new requirement p3. Introducing p3 may
implicitly relax both constraints :p0 and p2 in certain

Kim et al.

1521

contexts. However, our goal in this paper is to find a minimal relaxation.
In Section 3, we indicated that a transition relation could
be compactlyW represented
using a proposition formula
V
FB (s1 , s2 ) = i2Ds s j2Csi s cij in DNF. Given a pair of
1 2
1 2
states (s1, s2) and a set of indices Ds1 s2 , Csi 1 s2 , we define a
substitution u as

u(s1 , s2 , cij ) =

>
cij

if i 2 Ds1 s2 and j 2 Csi 1 s2
otherwise

That is, a substitution only relaxes the constraints on the
possible transitions between two automaton states.
Definition 4. (Relaxation). Let B1 = (SB1 , sB0 1 , O, !B1 , FB1 )
and B2 = (SB2 , sB0 2 , O, !B2 , FB2 ) be two Büchi automata.
Then, we say that B2 is a relaxation of B1 and we write
B1 B2 if and only if (1) SB1 = SB2 = S, (2) sB0 1 = sB0 2 , (3)
FB1 = FB2 and (4) there exists a substitution u such that
W for
all (s, s0 ) 2 S × S, we have FB2 (s, s0 )[ i2Dss0
V
V
W
0
0
j2C i 0 u(s, s , cij ) when FB1 (s, s ) =
i2Dss0
j2C i 0 cij .
ss

ss

In Definition 4, when defining FB2 (s, s0 ), we use the
equivalence relation [ rather then equality = in order to
highlight that in the resulting DNF formula no constant >
appears in a sub-formula. The only case where > can
appear is when FB2 (s, s0 )[>. We remark that if B1 B2 ,
then L(B1 )  L(B2 ) since the relaxed automaton allows
2
more behaviors to occur. If two automata B1 and B2 cannot be compared under relation , then we write B1 k B2 .
The intuition behind the ordering relation in Definition 4 is
better explained by an example.
Example 7. (Continuing from Example 6). Consider the
specification automaton Bs and the automata B1 - B3 in
Figure 6. Definition 4 specifies that the two automata must
have
transitions
between
exactly
the
same
3
states. Moreover, if the propositional formula that labels a
transition between the same pair of states on the two automata differs, then the propositional formula on the relaxed
automaton must be derived by the corresponding label of
the original automaton by removing literals. The latter
means that we have relaxed the constraints that permit a
transition on the specification automaton.
By visual inspection of Bs and B1 in Figure 6, we see
p2

that Bs B1 . For example, the transition ﬀ ! ﬄ is derived
B1

:p0 ^p1 ^p2

from ﬀ ! ﬄ by replacing the literals :p0and
Bs

Similarly,
we
have
Bs jjB2
since
p1with>.
FBs (0, 1) = :p0 ^ p1 and FB2 (0, 1) = ?, i.e. we have
removed a transition between two states. We also have
Bs jjB3 since FBs (2, 0) = ? and FB3 (2, 0) = p2, i.e. we
have added a transition between two states.
D
We remark that we restrict the space of relaxed specification automata to all automata that have the same number of
states, the same initial state, and the same set of final states
for computational reasons. Namely, under these restrictions,

we can convert the specification revision problem into a
graph search problem. Otherwise, the graph would have to
be mutated by adding and/or removing states.
We can now define the set of automata over which we
will search for a minimal solution that has nonempty intersection with the system.
Definition 5. Given a system T and a specification automaton Bs , the set of valid relaxations of Bs is defined as
<(Bs , T ) = fBjBs B and L(T × B) 6¼ ;g.
We can now search for a minimal solution in the set
<(Bs , T ). That is, we can search for some B 2 <(Bs , T )
such that if for any other B0 2 <(Bs , T ), we have B0 B,
then L(B) = L(B0 ). However, this does not imply that a
minimal solution semantically is minimal structurally as
well. In other words, it could be the case that B1 and B2
are minimal relaxations of some Bs , but B1 k B2 and,
moreover, B1 requires the modification of only one transition while B2 requires the modification of two transitions.
Therefore, we must define a metric on the set <(Bs , T ),
which accounts for the number of changes from the initial
specification automaton Bs .
Definition 6. (Distance). Given a system T and a specification automaton Bs , we define the distance of any
from Bs under
B 2 <(Bs , T ) that
 substitution u to
P results P
be distBs (B) = (s, s0 )2EBs i2Dss0 Cssi 0  where jjis the cardinality of the set.
We remark that given two relaxations B1 and B2 of
some Bs where B1 B2 , but B2  B1 , then
distBs (B1 ) 	 distBs (B2 ).
Therefore, Problem 1 can be restated as follows.
Problem 2. Given a system T and a specification automasuch
that
L(T × Bs ) = ;,
find
ton
Bs
B 2 arg minfdistBs (B0 )jB0 2 <(Bs , T )g.

4.1. Minimal revision as a graph search problem
In order to solve Problem 2, we construct a directed labeled
graph GA from the product automaton A = T × Bs . The
edges of GA are labeled by a set of atomic propositions
which if removed from the corresponding transition on Bs ,
they will enable the transition on A. The overall problem
then becomes one of finding the least number of atomic
propositions to be removed in order for the product graph
to have an accepting run. Next, we provide the formal definition of the graph GA which corresponds to a product
automaton A while considering the effect of revisions.
To formally define the graph search problem, we will
need some additional notation. We first create two new sets
of symbols from the set of atomic propositions P:



P2 = {p2jp 2 P};
~ = fl + [ l jl +  P and l  jS (P n l + )g.
P

Given a transition between two states s1 and s2 of some
B and a formula in DNF on the transition, we denote:

1522



The International Journal of Robotics Research 34(12)

jl(c) = p if c = p, and p2 if c = :p;
jS(l) = {p2jp 2 l} where l4P.

Now, we can introduce the following notation. We
define:



the set EB  SB2 , such that (s, s0 ) 2 EB iff 9l 2 P(P),
l
s ! B s0 ; and
the function lB (s1 , s2 ) = ffjl (cij )jj 2 Csi 1 s2 gji 2 Ds1 s2 g
as a transition function that maps a pair of states to the
set of symbols that represent conjunctive clause.
l

That is, if (s, s0 ) 2 EB , then 9l 2 P(P). Here s ! B s0 ;
and if (s, s0 ) 62 EB , then lB (s, s0 ) = ;. Also, if lB (s, s0 ) 6¼ ;,
~
then 8l 2 lB (s, s0 ), l  P(P).
Example 8. Consider a set P = {p0, p1}. Then,
~ =f;,fp0 g, fp g,fp1 g, fp g,fp0 ,p g,fp ,p1 g, P,
P
0
1
1
0
P g. Given a transition (s1, s2) of B and same P, consider
on
that
transition.
Then,
FB (s1 , s2 ) = :p0 _ p1
lB (s1 ,s2 ) =ffp
0 g, fp1 gg. If FB (s1 ,s2 )= :p0 ^ p1 , then
D
lB (s1 ,s2 ) =ffp
0 ,p1 gg:
Definition 7. Given a system T and a specification auto LS ),
maton Bs , we define the graph GA = (V , E, vs , Vf , P,
which corresponds to the product A = T × Bs as follows:








V = SZ is the set of nodes;
E = EA [ ED  S × S, where EA is the set of edges
that correspond to transitions on A, i.e.
l
((q, s), (q0 , s0 )) 2 EA iff 9l 2 P(P). Here (q, s) ! A
(q0 , s0 ) ; and ED is the set of edges that correspond to
disabled transitions, i.e., ((q, s), (q0 , s0 )) 2 ED iff
q !T q0 and (s, s0 ) 2 EBs , but there does not exist
(s, l, s0 ) 2!Bs such that l = hT (q0 ));
v s = sA
0 is the source node;
Vf =nFA is the set of sinks;
o
~ (s, s0 ) 2 EB
 = hp, (s, s0 )ijp 2 P,
P
s

is the edge labeling function such
LS : E ! P(P)Z
that if e = ((q, s),(q0 , s0 )), then LS (e) = fhl0 , (s, s0 )ijl 2
lBs (s, s0 ), l + = (l \ P) n hT (q0 ), l = (l \ P ) n jS
(P n hT (q0 )) and l0 = l + [ l g

Example 9. (Continuing Example 8). We will derive LS(e)
for an edge e = ((q, s1), (q0 , s2)). Assume FB (s1 , s2 )
0
= :p0 _ p1 , then lB (s1 , s2 ) = ffp
0 g, fp 1 gg. If hT (q ) =
+



fp0 g, then for l = fp0 g, l = ;, l = fp0 g and
+
2
0
l0 = fp
1}, l ={p
1}, l = ; and l = {p1}.
0 g, and for
 l={p

g,
(s
,
s
)
,
fp
g,
(s
,
s
)
Thus, LS (e) = f fp
h
ig.
1 2
1
1 2
0
Now assume F(s1,s2) = :p0^p1, then lB (s1 , s2 )
+
0

= ffp
0 , p1 gg. If hT (q ) = fp2 g, then l = fp0 , p1 g, l



0
= {p1}\{p2} = {p1}, l = fp
0 g n fp0 , p1 g = ;, and l
= {p1}. Thus, LS(e) = {h{p1}, (s1, s2)i}.
D
In order to determine which atomic propositions
we must remove from a transition of the specification
automaton, we need to make sure that we can uniquely
identify them. Recall that
LS returns a set, e.g.

0
0
LS (e) = f fp
0 , p1 g, (s, s ) , hfp1 g, (s, s )ig. Saying that
we need to remove p1 from the label of (s, s0 ), it may not
be clear which element of the set LS that p1 refers to. This
affects both the theoretical connection of the graph GA as a
tool for solving Problem 2 and the practical implementation of any graph search algorithm (e.g. see line 22 of
Algorithm 2 in Section 5).
Thus, in the following, we assume that GA uses a func instead of LS. Now, L maps each edge e to
tion L : E ! P
just a single tuple hl,(s, s0 )i instead of a set as in Definition
7. This can be easily achieved by adding some dummy
states in the graph with incoming edges labeled by the
tuples in the original set LS(e). We can easily convert the
original graph GA to the modified one. First, for each edge
e = ((q, s),(q0 , s0 )) 2 ED, we add jLS((q, s),(q0 , s0 ))j new
nodes ~vei , i = 1,.,jLS((q, s),(q0 , s0 ))j. Second, we add the
edge ((q, s), ~vei ) to E and set each label L((q, s), ~vei ) with
exactly one hl,(s, s0 )i 2 LS((q, s),(q0 , s0 )). Then, we add the
edges (~vei , (q0 , s0 )) to E and set L(~vei , (q0 , s0 )) = h;, (s, s0 )i.
Finally, we repeat until all of the edges are labeled by tuples
rather than sets.
We remark that every time we add a new node vei for an
edge that corresponds to the same transition (s, s0 ) of the
specification automaton, then we use the same index i for
each member of LS(e). This is so that later we can map
each edge of the modified graph GA to the correct clause
in the DNF formula of the specification automaton. The
total number of new nodes that we need to add depends on
the number of disjunctions on each label of the specification automaton and the structure of the FSM.
Now, if for some edge e, L(e) 6¼;, then L(e) specifies
those atomic propositions in lBs (s, s0 ) that need to be
removed in order to enable the edge in the product state of
A. Note that the labels of the edges of GA are elements of
 rather than subsets of P. This is due to the fact that we
P
are looking into removing an atomic proposition p from a
specific transition (s, l, s0 ) of Bs rather than all occurrences
of p in Bs .
In the following, we assume that vs;Vf, otherwise, we
would not have to revise the specification. Furthermore, we
define jhl,(s, s0 ), iij = jlj, i.e. the size of a tuple
~ × EB × N is defined to be the size of the
hl, (s, s0 ), ii 2 P
s
set l.

Definition 8. (Path cost). For some n . 0, let m =
e1e2.en be a finite path on the graph GA that consists of
edges of GA . Let

(
(


i
0
0
~
L(m) = hl, (s, s ), k ijl = [j2J lj , J  f1 . . . ng, 8j 2 J , L(ej ) = lj , (s, s ) , k =
0

0

0

if ej = ((q, s), ~vi((q, s), (q , s )) )
otherwise

)

Kim et al.

1523

hT (q1 ) = {π1 , π3 } hT (q2 ) = {π1 , π2 }

q0

q1

q2

s1

next section provides an algorithmic solution to this
problem.

π0 ∧ π1 ∧ π2 ∧ π3

T

q3

Λ(e1 ) = {π0 , π2 }
L(e1 ) = {y((s1 , s1 ), π0 ),
y((s1 , s1 ), π2 )}

q0 , s1

Λ(e2 ) = {π0 , π3 }
L(e2 ) = {y((s1 , s1 ), π0 ),
y((s1 , s1 ), π3 )}

q1 , s1

Λ(e3 ) = {π0 , π2 }

GA

Bs

hT (q3 ) = {π1 , π3 }

q2 , s1

L(e3 ) = {y((s1 , s1 ), π0 ),
y((s1 , s1 ), π2 )}

q3 , s1

Fig. 7. Example 10: T , part of the system; Bs , part of the
specification automaton; GA , part of the graph that corresponds
to the product automaton.

We define the cost of the path m to be
Cost(m) =

X

jlj

~
l2L(m)

~
In the above definition, L(m)
collects in the same tuple
all the atomic propositions that must be relaxed in the same
transition of the specification automaton. It is easy to see
~
that given some set L(m),
then we can construct a substitution um for the corresponding relaxed specification automaton since all the required information is contained in the
~
members of L(m).
Example 10. Consider the Example in Figure 7. In the figure, we provide a partial description of an FSM T , a specification automaton Bs and the corresponding product
automaton A. The dashed edges indicate disabled edges
which are labeled by the atomic propositions that must be
removed from the specification in order to enable the transition on the system. In this example, we do not have to
add any new nodes since we have only one conjunctive
clause on the transition of the specification automaton.
It is easy to see now that in order to enable the path (q0,
s1), (q1, s1), (q3, s1) on the product automaton, we need to
replace p0 and p2 with > in FBs (s1 , s1 ) = p0 ^ p1 ^
p2 ^ p3 . On the graph GA , this path corresponds to
~ 1 e3 ) = fhfp0 , p2 g, (s1 , s1 ), 0ig. Similarly, in order to
L(e
enable the path (q0, s1), (q1, s1), (q2, s1) on the product
automaton, we need to replace p0, p2and p3with>in
FBs (s1 , s1 ). On the graph GA , this path corresponds to
~ 1 e2 ) = fhfp0 , p2 p3 g, (s1 , s1 ), 0ig.
L(e
Therefore, the path defined by edges e1 and e3 is preferable over the path defined by edges e1 and e2. In the first
case, we have cost C(e1e3) = 2 which corresponds to relaxing two requirements, i.e. p0 and p2, while in the latter
case, we have cost C(e1e2) = 3 which corresponds to relaxing three requirements, i.e. p0, p2 and p3.
D
A valid relaxation B should produce a reachable vf 2 Vf
with prefix and lasso path such that L(T × B) 6¼ ;. The

5. A heuristic algorithm for MRP
In this section, we present an approximation algorithm for
the minimal revision problem (AAMRP). It is based on
Dijkstra’s shortest path algorithm (Cormen et al., 2001).
The main difference from Dijkstra’s algorithm is that
instead of finding the minimum weight path to reach each
node, AAMRP tracks the number of atomic propositions
that must be removed from each edge on the paths of the
graph GA .
The pseudocode for the AAMRP is presented in
Algorithms 1 and 2. The main algorithm (Algorithm 1)
divides the problem into two tasks. First, in line 5, it finds
an approximation to the minimum number of atomic pro that must be removed to have a prefix
positions from P
path to each reachable sink (see Section 3.1). Then, in Line
8, it repeats the process from each reachable final state to
find an approximation to the minimum number of atomic
propositions that must be removed so that a lasso path is
enabled. The combination of prefix/lasso that removes the
minimal number of atomic propositions is returned to the
user. We remark that from line 10, a set of atomic propositions found from prefix part is used when it starts searching
for lasso path of every reachable vf 2 V \ Vf .
Algorithm 2 follows closely Dijkstra’s shortest path
algorithm (Cormen et al., 2001). It maintains a list of visited nodes V and a table M indexed by the graph vertices
which stores the set of atomic propositions that must be
removed in order to reach a particular node on the graph.
Given a node v, the size of the set jM½v, 1
j is an upper
bound on the minimum number of atomic propositions that
must be removed. That is, if we remove all p
 2 M½v, 1

from Bs , then we enable a simple path (i.e. with no cycles)
from a starting state to the state v. The size of jM½v, 1
j is
stored in M½v, 2
 which also indicates that the node v is
reachable when M½v, 2
\‘.
The algorithm works by maintaining a queue with the
unvisited nodes on the graph. Each node v in the queue has
as key the number of atomic propositions that must be
removed so that v becomes reachable on A. The algorithm
proceeds by choosing the node with the minimum number
of atomic propositions discovered so far (line 18). Then,
this node is used in order to updated the estimates for the
minimum number of atomic propositions needed in order
to reach its neighbors (line 22). A notable difference of
Algorithm 2 from Dijkstra’s shortest path algorithm is the
check for lasso paths in lines 8–16. After the source node
is used for updating the estimates of its neighbors, its own
estimate for the minimum number of atomic propositions
is updated either to the value indicated by the self loop or
the maximum possible number of atomic propositions.
This is required in order to compare the different paths that
reach a node from itself.

1524

The International Journal of Robotics Research 34(12)

Algorithm 1. AAMRP.
 L).
Inputs: a graph GA = (V , E, vs , Vf , P,
 that must be removed Bs .
Outputs: the list L of atomic propositions form P
1: Procedure AAMRP ðGA Þ

2:
L
P
 ‘)
3:
M½: , :

(P,
(;, 0)
x Initialize the source node
4:
M½vs , :

5:
hM, P, V i
FindMinPath(GA , M, 0)
6:
ACCEPTABLE False
7:
for vf 2 V \ Vf do
GetAPFromPath(vs , vf , M, P)
8:
Lp
 ‘)
(P,
9:
M0 ½: , :

(Lp , jLp j)
x Store APs from prefix path vs , vf to M0 ½vf , :

10:
M0 ½vf , :

0
 L)
(V , E, vf , fvf g, P,
11:
GA
0
FindMinPath(GA
, M0 , 1)
12:
hM0 , P0 , V 0 i
13:
if vf 2 V 0 then
GetAPFromPath(vf , vf , M0 , P0 )
x Get APs of prefix vs , vf and lasso vf , vf from M0 ½vf , :

14:
L0
15:
if |L0 | 	 |L| then
16:
L L0
17:
end if
18:
ACCEPTABLE True
19:
end if
20:
end for
21:
if : ACCEPTABLE then
22:
L ;
23:
end if
24:
return L
25: end procedure
The function GETAPFROMPATH((vs , vf , M, P)) returns the atomic propositions that must be removed from Bs in order to enable a path
on A from a starting state vs to a final state vf given the tables M and P.

Algorithm 2. FINDMINPATH.
 L), a table M and a flag lasso on whether this is a lasso path search.
Inputs: a graph GA = (V , E, vs , Vf , P,
Variables: a queue Q, a set V of visited nodes and a table P indicating the parent of each node on a path.
Output: the tables M and P and the visited nodes V
1: Procedure FINDMINPATH(GA , M,lasso)
2:
V
fvs g
3:
P[:] ;
x Each entry of P is set to ;
4:
Q
V n fvs g
5:
for v2V such that (vs, v) 2 E and v6¼vsdo
6:
RELAX((vs , v), M, P, L)
hM, Pi
7:
end for
8:
if lasso = 1 then
9:
if (vs, vs) 2Ethen
M½vs , 1
 [ L(vs , vs )
10:
M½vs , 1

jM½vs , 1
 [ L(vs , vs )j
11:
M½vs , 2

12:
P[vs] = vs
13:
else
 ‘)
(P,
14:
M½vs , :

15:
end if
16:
end if
17:
while Q 6¼ ; do
x Get node u with minimum M½u, 2

18:
u EXTRACTMIN(Q)
19:
if M½u, 2
\‘ then
20:
V
V [ fug
21:
for v2V such that (u, v) 2 E do
22:
RELAX((u, v), M, P, L)
hM, Pi
23:
end for
24:
end if
25:
end while
26:
return M, P, V
27: end Procedure

Kim et al.

1525

Algorithm 3. RELAX.
Inputs: an edge (u, v), the tables M and P and the edge labeling
function L
Output: the tables M and P
1: Procedure RELAX (u, v),M,P,L)
2:
if jM½u, 1
 [ L(u, v)j\M½v, 2
 then
3:
M½v, 1

M½u, 1
 [ L(u, v)
4:
M½v, 2

jM½u, 1
 [ L(u, v)j
5:
P[v] u
6:
end if
7:
return M, P
8: end orocedure

Correctness. The correctness of the algorithm AAMRP is
based upon the fact that a node v 2 V is reachable on GA if
and only if M½v, 2
\‘. The argument for this claim is similar to the proof of correctness of Dijkstra’s shortest path
algorithm in Cormen et al. (2001). If this algorithm returns
a set of atomic propositions L which removed from Bs , then
the language L(A) is non-empty. This is immediate by the
construction of the graph GA (Definition 7).
We remark that AAMRP does not solve Problem 2
exactly since MRP is NP-complete. However, AAMRP
guarantees that it returns a valid relaxation B where Bs B.
Theorem 1. If a valid relaxation exists, then AAMRP
always returns a valid relaxation B of some initial Bs such
that L(T × B) 6¼ ;.

{π1 }

v1
{π 1 , π 3 }

v3

{π 1 }

v2

{π 3 }

v5

{π 2 }
{π 1 , π 4 }

v4

{π 4 }

v6
{π 4 }

Fig. 8. The graph of Example 11. The source vs = v1 is denoted
by an arrow and the sink v6 by double circle (Vf = {v6}).

The following example demonstrates how the algorithm
works and indicates the structural conditions on the graph
that make the algorithm non-optimal.
Example 11. Let us consider the graph in Figure 8. The
source node of this graph is vs = v1 and the set of sink
 set of this graph is
nodes is Vf = {v6}. The P
 4 g. Consider the first call of FINDMINPATH(line
f
p1 , . . . , p
5 of Algorithm 1).






Before the first execution of the while loop (line 17):
the queue contains Q = fv2 , . . . , v6 g. The table M
has the following entries: M½v1 , :
 = h;, 0i,
p1 g, 1i,
M½v
p1 , p
 3 g, 2i,
M½v2 , :
 = hf
 3 , :
 = hf
 ‘ .
M½v4 , :
 = . . . = M½v6 , :
 = P,
Before the second execution of the while loop (line
17): the node v2 was popped from the queue since it
had M½v2 , 2
 = 1. The queue now contains
Q = fv3 , . . . , v6 g. The table M has the following
M½v2 , :
 = hf
p1 g, 1i,
rows:
M½v1 , :
 = h;, 1i,
p1 , p
 3 g, 2i,
M½v


=
f
p
,
p
M½v3 , :
 = hf
h
4
1  2 g, 2i,

 ‘ .
M½v5 , :
 = M½v6 , :
 = P,
At the end of FINDMINPATH(line 27): The queue now is
empty. The table M has the following rows:
p1 g, 1i, M½v3 , :
 =
M½v1 , :
 = h;, 0i, M½v2 , :
 = hf
 3 g, 2i, M½v4 , :
 = hf
p1, p
 2 g, 2i, M½v5 , :
 =
p1 , p
hf
 4 , which corre 2, p
 4 g, 3i, M½v6 , :
 = P,
p1 , p
hf
sponds to the path v1, v2, v4, v5, v6.

Note that algorithm returns a set of atomic propositions
 which is not optimal jL0 j = 4). The path v1, v3, v4,
L0 = P
p1 , p
 3, p
 4 g with jL0 j = 3.
D
v5, v6would return L0 = f

Proof. First, we will show that if AAMRP returns ;, then
there is no valid relaxation of Bs . AAMRP returns ; when
there is no reachable vf 2 Vf with prefix and lasso path or
GETAPFROMPATH returns ;. If there is no reachable vf, then
either the accepting state is not reachable on Bs or on T .
Recall that the Definition 7 constructs a graph where all of
the transitions of T and B are possible. If it returns ; as a
valid solution, then there is a path on the graph that does not
utilize any labeled edge by L. Thus, L(T × Bs ) 6¼ ;. Since
we assume that Bs is unsatisfiable on T , this is contradiction.
Second, without loss of generality, suppose that
~
~
AAMRP returns L(m).
Using this L(m),
we can build a
relax specification automaton B. Using each
~
and for each p 2 l, we add the indices
hl, (s, s0 ), k i 2 L(m)
of the literal fij in FBs (s, s0 ) that corresponds to p to the sets
Dss0 and Cssi 0 . The resulting substitution u produces a
relaxation. Moreover, it is a valid relaxation, because by
removing the atomic propositions in u from Bs , we get a
path that satisfies the prefix and lasso components on the
product automaton.
u
Running time. The running time analysis of the AAMRP
is similar to that of Dijkstra’s shortest path algorithm. In the
following, we will abuse notation when we use the O notation and treat each set symbol S as its cardinality jS j.
First, we will consider FINDMINPATH. The fundamental
difference of AAMRP over Dijkstra’s algorithm is that we
have set theoretic operations. We will assume that we are
using a data structure for sets that supports O(1) set cardinality quarries, O(log n) membership quarries and element
insertions (Cormen et al., 2001) and O(n) set up time.
Under the assumption that Q is implemented in such a data
structure, each EXTRACTMIN takes O(log V) time.
Furthermore, we have O(V) such operations (actually jV j
2 1) for a total of O(V log V).
Setting up the data structure for Q will take O(V) time.
Furthermore, in the worst case, we have a set L(e) for each

edge e 2 E with set-up
 time
 O(EP). Note that the initiali ‘ does not have to be implemenzation of M½v, :
 to P,
ted since we can have indicator variables indicating when a
set is supposed to contain all of the (known in advance)
elements.

1526

Assuming that E is stored in an adjacency list, the total
number of calls to RELAX at lines 2 and 2 of Algorithm 2
will be O(E) times. Each call to RELAX will have to perform
a union of two sets (M½u, 1
and L(u, v)). Assuming that
 elements, each union
both sets have in the worst case jPj
 log P)
 time. Finally, each set size quarry
will take O(P
takes O(1) time and updating the keys in Q takes O(log V)
time. Therefore, the running time of FINDMINPATH is
 + V log V + E(P
 log P
 + log V )).
O(V + EP
Note that even if under Assumption 1 all nodes of T are
reachable (jV j \ jE j), the same property does not hold
for the product automaton. (e.g, think of an environment T
and a specification automaton whose graphs are Directed
Acyclic Graphs (DAG). However, even in this case, we
have (jV j \ jE j). The running time of FINDMINPATH is
 log P
 + log V )). Therefore, we observe that the
O(E(P

running time also depends on the size of the set P.
However, such a bound is very pessimistic since not all the
edges will be disabled on A and, moreover, most edges will
 as candidates for removal.
not have the whole set P
Finally, we consider AAMRP. The loop at line 7 is
going to be called O(Vf) times. At each iteration,
FINDMINPATH is called. Furthermore, each call to
 log P)
 time (in
GETAPFROMPATH is going to take O(V P
the worst case we are going to have jV j unions of sets
of atomic propositions). Therefore, the running time of
 log P
 + E(P
 log P
 + log V ))) =
AAMRP is O(Vf (V P
 log P
 + log V )) which is polynomial in the size
O(Vf E(P
of the input graph.
Approximation bound. AAMRP does not have a constant
approximation ratio on arbitrary graphs.
Example 12. (Unbounded approximation). The graph in
Figure 9 is the product of a specification automaton with a
single state and a self transition with label
 1, . . . , p
 m, p
 H, p
 | g and an environment automaton
f
p0 , p
with the same structure as the graph in Figure 9 but with
appropriately defined state labels. In this graph, AAMRP
will choose the path v1, v$1, v2, v$2, v3, ., vf. The corresponding revision will be the set of atomic propositions
p0 , p
 1, p
 2, . . . , p
 m g with jLpj = m + 1. This is
Lp = f
because in v2, AAMRP will choose the path through
v$1rather than v0 1since the latter will produce a revision
 H, p
 | gj = 3 while the former a revision
set of size jf
p0 , p
set of size jf
p0 , p
 1 gj = 2. Similarly at the next junction
p0 , p
 1, p
 H, p
 |g
node v3, the two candidate revision sets f
 1, p
 2 g have sizes 4 and 3, respectively.
and f
p0 , p
Therefore, the algorithm will always choose the path
through the nodes vi$rather than vi0 producing, thus, a
solution of size m + 1. However, in this graph, the
p0 , p
 H, p
 | g with
optimal revision would have been Lp = f
jLpj = 3. Hence, we can see that in this example for m . 2
AAMRP returns a solution which is m 2 2 times bigger
than the optimal solution.
D
There is also a special case where AAMRP returns a
solution whose size is at most twice the size of the optimal
solution.

The International Journal of Robotics Research 34(12)

{π , π ♣ }

v1
{π0 }

v1
{π1 }

{π0 }

v1

{π , π ♣ }

v2
{π0 }

v2
{π2 }

{π0 }

v2

{π , π ♣ }

v3

{π0 }
{π0 }
{π0 }

vf

{π3 }

Fig. 9. The graph of Example 12. The source vs = v1 is denoted
by an arrow and the sink vf by double circle (Vf = {vf}).

Fig. 10. The simple environment of Example 13 along with a
low-speed mobile robot trajectory that satisfies the specification.

Theorem 2. AAMRP on planar directed acyclic graphs
(DAGs) where all of the paths merge on the same node is a
2-approximation algorithm.
The proof is provided in the Appendix B.

6. Examples and benchmark evaluations
In this section, we present experimental results using our
prototype implementation of AAMRP. The prototype
implementation is in Python (see Kim, 2014b). Therefore,
we expect the running times to substantially improve with
a C implementation using state-of-the-art data structure
implementations.
We first present some examples and expand few more
example scenarios.
Example 13. We revisit Example 1. The product automaton
of this example has 85 states, 910 transitions and 17
reachable final states. It takes 0.095 seconds by AAMRP.
AAMRP returns the set of atomic propositions {hp4, (s2,
s4)i} as a minimal revision to the problem, which is revision (3) among the three minimal revisions of the example:
one of the blue trajectories in Figure 10. Thus, it is an optimal solution.
Example 14. We revisit Example 2. The graph of this
example has 36 states, 240 transitions and 9 reachable
sinks. AAMRP returns the set of atomic propositions
{hp13, (s2, s3)i} as minimal revision to the problem. It
takes 0.038 seconds by AAMRP. Intuitively, AAMRP

Kim et al.

1527

uploaded. Once uploading is finished, do not visit upload
locations until gathering data. You should always avoid
the road from i4to i2when you head to u1from g1and the
road from i1to i2when you head to u2from g2’’. The following formula represents this mission:
fsingle :¼ fO ^ fG ^ fU ^ c1 ^ c2 ^ GF(p)

Fig. 11. Schematic illustration of the simple road network
environment of Example 15. The robot is required to drive on the
right-hand side of the road.

recommends dropping the requirement that p13should be
reached from the specification. Therefore, Object 1 will
remain where it is, while Object 2 will follow the path q1,
q2, q3, q2, q3, ..
With our prototype implementation, we could expand
our experiment to few more example scenarios introduced
in Ulusoy et al. (2012, 2011).
Example 15. (Single-robot data-gathering task). In this
example, we use a simplified road network having three
gathering locations and two upload locations with four
intersections of the road. In Figure 11, the data gather
locations, which are labeled g1, g2, and g3, are dark gray,
the data upload locations, which are labeled u1and u2, are
light gray, and the intersections are labeled i1through i4. In
order to gather data and upload the gather-data persistently, the following LTL formula may be considered: fA
:= GF(ug)^GF(p), where ug := g1_g2_g3 and p :=
u1_u2. The following formula can make the robot move
from gather locations
to upload 	locations
after gathering

	
data: fG :¼ G ug ! X :ug Up . In order for the robot
to move to gather location after uploading,
the

		 following
formula is needed: fU :¼ G p ! X :pUug .
Let us consider that some parts of road are not recommended to drive from gather locations, such as from i4 to
i2and from i1 to i2. We can describe those constraints as
following: c1 := G(g1!:(i4^Xi2)Uu1 ) and c2 :=
G(g2!:(i1^Xi2) Uu2 ). If the gathering task should have
an order such as g3, g1, g2, g3, g1, g2, ., then the
following formula could be considered: fO :¼
((:g1 ^ :g2 ) Ug3 ) ^ G(g3 ! X ((:g2 ^ :g3 ) Ug1 )) ^ G(g1
! X ((:g1 ^ :g3 ) Ug2 )) ^ G(g2 ! X ((:g1 ^ :g2 ) Ug3 )).
Now, we can informally describe the mission. The mission
is ‘‘Always gather data from g3, g1, g2 in this order and
upload the collected data to u1and u2. Once data gathering
is finished, do not visit gather locations until the data is

Assume that initially, the robot is in i3and all nodes are
final nodes. When we made a cross product with the road
and the specification, we could get 36,824 states, 350,114
edges, and 450 final states. Not removing some atomic propositions, the specification was not satisfiable. AAMRP
took 15 min 34.572 seconds, and suggested removing g3.
Since the original specification has many g3in it, we had to
trace which g3from the specification should be removed.
Hence, we revised the LTL2BA (Gastin and Oddoux, 2001),
indexing each atomic proposition on the transitions and
states (see Kim, 2014a). Two g3are mapped to the same
transition on the specification automaton in (:g1^:g2)
Ug3 of uO and in fg := g1_g2_g3in fU.
D
The last example shows somewhat different missions
with multiple robots. If the robots execute the gather and
upload mission, persistently, we could assume that the battery in the robots should be recharged.
Example 16. (Charging while uploading). In this example,
we assume that robots can recharge their battery in upload
locations so that robots are required to stay at the upload
locations as much as possible. We also assume that each
gathering location has a dedicated upload location such
that g1has u1as an upload location, and g2has u2as an
upload location. For this example, we revised the road network so that we remove the gather location g3and the
intersection i4to make the network simpler for this mission.
We also positioned the upload locations next to each other.
We assume that the power source is shared and it has just
two charging stations (see Figure 12). We can describe the
mission as follows: ‘‘Once robot1finishes gathering data at
g1, robot1should not visit the gather locations until the
data is uploaded at u1. Once robot2finishes gathering data
at g2, robot2should not visit the gather locations until the
data is uploaded at u2. Once the data is uploaded at u1or
u2, robot1or robot2should stay there until a gather location
is not occupied. Persistently, gather data from g1and g2,
avoiding the road from g2to i2’’. The following formula
represents this mission:
fcharging :¼ G(g11 ! X (:g11 ^ :g21 )Uu11 ) ^
G(g22 ! X (:g22 ^ :g12 ) Uu22 ) ^
G(u11 ! u11 U:g22 ) ^
G(u22 ! u22 U:g11 ) ^
GFg11 ^ GFg22 ^
G:(g21 ^ Xi21 ) ^
G:(g22 ^ Xi22 )

1528

The International Journal of Robotics Research 34(12)

i2

u1

g2

i1

u2

g1
i3

Fig. 12. Schematic illustration of the simple road network
environment of Example 16. The robots can stay upload
locations u1 and u2 to recharge the battery.

Assume that initially, robot1is in i1, robot2is in i2, and all
nodes are final nodes. From the cross product with the road
and the specification, there were 65,966 states, 253,882
transitions, and 504 final nodes. For this example, we computed a synchronized environment for two robots, and in
this environment, atomic propositions were duplicated for
each robot. For example, a gather location g1is duplicated
to g11for robot1and g12for robot2. With this synchronized
environment, we could avoid robots to be colliding and to
be in the same location at the same time. However, not
removing some atomic propositions, the specification was
unsatisfiable. AAMRP took 24 min 22.578 seconds, and
suggested removing u22from robot2. The two occurrences of
u22were in G(g22!X(:g22^:g12) Uu22 ) and in the second
u22of G(u22 ! u22 U:g11 ) as indicated by our modified
LTL2BA toolbox. The suggested path from AAMRP for each
robot is as follows:
pathrobot1 = i11 i21 u11 u11 i11
(i21 g21 i31 g11 i11 i21 u11 u11 u11 u11 u11 u11 u11 u11 u11 i11 ) +
pathrobot2 = i22 u12 i12 u22 u22
(u22 u22 u22 u22 u22 u22 u22 i32 g12 i12 i22 g22 i32 g12 i12 u22 ) +

D

We remark that although two equivalent specifications
represent the same mission, the corresponding Büchi automata may actually be different due to the translation algorithm. The theory in this paper as well as AAMRP depend
on the structure of the Büchi automaton. Therefore,
AAMRP may return different results.
For the evaluations, we utilized the ASU supercomputing center which consists of clusters of dual 4-core processors, 16 GB Intel(R) Xeon(R) CPU X5355 @2.66 Ghz.
Our implementation does not utilize the parallel

architecture. The clusters were used to run the many different test cases in parallel on a single core. The operating
system is CentOS release 5.5.
In order to assess the experimental approximation ratio
of AAMRP, we compared the solutions returned by
AAMRP with the brute-force search. The brute-force
search is guaranteed to return a minimal solution to the
MRP problem.
We performed a large number of experimental comparisons on random benchmark instances of various sizes. We
used the same instances which were presented in Kim and
Fainekos (2012); Kim et al. (2012). The first experiment
involved randomly generated DAGs. Each test case consisted of two randomly generated DAGs which represented
an environment and a specification. Both graphs have selfloops on their leaves so that a feasible lasso path can be
found. The number of atomic propositions in each instance
was equal to four times the number of nodes in each acyclic
graph. For example, in the benchmark where the graph had
9 nodes, each DAG had 3 nodes, and the number of atomic
propositions was 12. The final nodes are chosen randomly
and they represent 5–40% of the nodes. The number of
edges in most instances were 2–3 times more than the number of nodes.
Table 1 compares the results of the brute-force search
with the results of AAMRP on test cases of different sizes
(total number of nodes). For each graph size, we performed
200 tests and we report minimum, average and maximum
computation times in seconds and minutes, average and
maximum numbers of atomic propositions for each instance
solution. AAMRP was able to finish the computation and
returned a minimal revision for all of the test cases, but
brute-force search was not able to finish all of the computation within an 8-hour window.
Our brute-force search checks all of the combinations of
atomic propositions. For example, given n atomic propositions, it checks at most 2n cases. It uses breadth-first search
to check the reachability for the prefix and the lasso part. If
it is reachable with the chosen atomic propositions, then it
is finished. If it is not reachable, then it chooses another
combination until it is reachable. Since brute-force search
checks all of the combinations of atomic propositions, the
success mostly depends on the time limit of the test. We
remark that the brute-force search was not able to provide
an answer to all the test cases within an 8-hour window.
The comparison for the approximation ratio was possible
only for the test cases where brute-force search successfully
completed the computation. Note that in the case of 529
nodes, even though the maximum ratio is 1, the maximum
solution from brute-force does not match with the maximum solution from AAMRP. One is 5 and another is 30.
This is because the number of success from brute-force
search is 137/200 and only comparing this success with the
ones from AAMRP, the maximum ratio is still 1.
An interesting observation is that the maximum approximation ratio is experimentally determined to be less than 2.
For the randomly generated graphs that we have

max

1.333
1.125
1
1.2
1
1

avg

1.0016
1.0006
1
1
1
1

1529

Table 2. Benchmark evaluations: number of nodes versus the
results of AAMRP. Under the TIMES columns the numbers
indicate computation times in seconds.
Nodes

AAMRP

min

avg

max

succ

0.125
15.723
50.325
425.362
6734.133

0.23
76.164
570.737
1993.449
6917.094

0.325
128.471
1009.675
4013.717
7100.055

9/10
9/10
8/10
3/10
2/10

1
1
1
1
1
1
200/200
200/200
200/200
200/200
200/200
200/200
5
15
17
20
24
30
1.17
0.179
0.333
1.591
1.591
4.705
0.061
0.076
0.188
0.669
0.669
1.88

1
1
1
1
1
1

1.975
3.395
4.285
4.155
5
5.115

succ
max
avg
min
min
min

max
Times (s)
Solutions (size)
Times (s)

avg
AAMRP
Brute-force search

1024
10,000
20,164
50,176
60,025

constructed the bound appears to be 1.333. However, as we
showed in Example 12, it is not easy to construct random
examples that produce higher approximation ratios. Such
example scenarios must be carefully constructed in
advance.
In the second benchmark evaluation, we attempted to
determine the problem sizes that our prototype implementation of AAMRP in Python can handle. The results are presented in Table 2. We observe that approximately 60,025
nodes would be the limit of the AAMRP implementation in
Python.

0.022
0.038
0.007
0.129
0.15
0.382
200/200
198/200
171/200
158/200
143/200
137/200
5
13
8
6
6
5
1.97
3.277
3.076
2.379
2.692
2.591
1
1
1
1
1
1
1.91
20786
25271
25437
17685
26895
0.104
510.18
1025.44
992.68
1110.05
2153.90
0.037
0.069
0.066
0.103
0.087
0.14

avg

max

avg

max

succ

min

7. Related work

9
100
196
324
400
529

Solutions (size)

min

Ratio

Times

Nodes

Table 1. Benchmark evaluations: number of nodes versus the results of brute-force search and AAMRP. Under the brute-force search and AAMRP columns the numbers indicate computation
times in sec. RATIO indicates the experimentally observed approximation ratio to the optimal solution.

Kim et al.

The automatic specification revision problem for automata
based planning techniques is a relatively new problem.
A related research problem is query checking (Chechik
and Gurfinkel, 2003; Gurfinkel et al., 2002). In query
checking, given a model of the system and a temporal logic
formula f, some sub-formulas in f are replaced with placeholders. Then, the problem is to determine a set of Boolean
formulas such that if these formulas are placed into the placeholders, then f holds on the model. The problem of revision as defined here is substantially different from query
checking. For one, the user does not know where to position the placeholders in the formula when the planning
fails.
Ding and Zhang (2005) and Finger and Wassermann
(2008) also present a related problem. It is the problem of
revising a system model such that it satisfies a temporal
logic specification. Along the same lines, one can study the
problem of maximally permissive controllers for automata
specification (Thistle and Wonham, 1994). Note that in our
work, we are trying to solve the opposite problem, i.e. we
are trying to relax the specification such that it can be realized on the system. The main motivation for our work is
that the model of the system, i.e. the environment and the
system dynamics, cannot be modified and, therefore, we
need to understand what we can be achieved with the current constraints.
Finding out why a specification is not satisfiable on a
model is a problem that is very related to the problems of

1530

vacuity and coverage in model checking (Kupferman et al.,
2008). Another related problem is the detection of the
causes of unrealizability in LTL games. In this case, a number of heuristics have been developed in order to localize
the error and provide meaningful information to the user
for debugging (Cimatti et al., 2008; Konighofer et al.,
2009). Along these lines, LTLMop by Raman and KressGazit (2011) was developed to debug unrealizable LTL
specifications in reactive planning for robotic applications.
Raman et al. (2013) also provided an integrated system for
non-expert users to control robots for high-level, reactive
tasks through natural language. This system gives the user
natural language feedback when the original intention is
unsatisfiable. Raman and Kress-Gazit (2013) introduced an
approach to analyze unrealizable robot specifications due
to environment limitations. They provide methods to find
the minimal unsatisfiable cores, such as deadlock.
Over-Subscription Planning (OSP) by Smith (2004) and
Partial Satisfaction Planning (PSP) by van den Briel et al.
(2004) are also very closely related problems. OSP finds
an appropriate subset of an over-subscribed, conjunctive
goal to meet the limitation of time and energy consumption. PSP describes the planning problem where the goals
are regarded as soft constraints and the planner tries to find
a good quality plan for a subset of the goals. OSP and PSP
have almost the same definition, but there is also a difference. OSP regards the resource limitations as an important
factor of partial goals to be satisfied, while PSP chooses a
trade-off between the total action costs and the goal
utilities.
Göbelbecker et al. (2010) investigated situations in
which a planner-based agent cannot find a solution for a
given planning task. They provided a formalization of coming up with excuses for not being able to find a plan and
determined the computational complexity of finding
excuses. On the practical side, they presented a method that
is able to find good excuses on robotic application
domains.
Another related problem is the Minimum Constraint
Removal Problem (MCR) by Hauser (2012). MCR concentrates on finding the least set of violating geometric constraints so that satisfaction in the specification can be
achieved.
Cizelj and Belta (2013) introduced another related problem which is the automatic formula revision for
Probabilistic Computational Tree Logic (PCTL) specifications for systems with noisy sensors and actuators. Their
proposed approach uses some specification update rules in
order to revise the specification formula until the supervisor is satisfied. The work by Tumova et al. (2013) is also
closely related to our work. It takes as input a transition
system, and a set of sub-specifications in LTL each with a
reward, and constructs a strategy maximizing the total
reward of satisfiable sub-specifications. If a whole subspecification is not feasible, then it is discarded. In our
case, we try to minimally revise a sub-specification (even a
literal) if it is infeasible. In Kim and Fainekos (2014), we

The International Journal of Robotics Research 34(12)

also extended our approach with quantitative preferences.
While revising a sub-specification, instead of finding the
minimum number of atomic propositions to remove, we
attempt to minimize various cost functions on the preference levels of the atomic propositions.
Guo and Dimarogonas (2013) also studied a version of
the specification revision problem. In particular, they focus
on finding a feasible plan that can least violate the given
specification under some user-defined cost function that
depends on the mission. Guo et al. (2013) studied the same
problem under the assumption that the environment is partially known. In their continuing work, Guo and
Dimarogonas (2014) present a framework for minimally
violating planning for multi-robot systems where knowledge about the environment is updated through sensors and
communication between agents. They also set up hard
tasks and soft tasks. Hard tasks should be satisfied as
safety rules meanwhile soft tasks may be violated.
Lahijanian et al. (2015) introduced a specification revision
framework for co-safe LTL formulas with quantitative preferences over a weighted transition system. They show that
their framework works for both fully observable environments and partially observable environments.

8. Conclusions
In this paper, we have proved that the MRP for specification automata is NP-complete. We have also provided a
polynomial time heuristic algorithm for the problem of minimal revision of specification automata and established its
upper bound for a special case. Furthermore, we provided
examples to demonstrate that an approximation ratio cannot
be established for this algorithm.
The MRP is useful when automata theoretic planning
fails and the modification of the environment is not possible. In such cases, it is desirable that the user receives feedback from the system on what the system can actually
achieve. The challenge in proposing a new specification
automaton is that the new specification should be as close
as possible to the initial intent of the user. Our proposed
algorithm experimentally achieves approximation ratio very
close to 1. Furthermore, the running time of our prototype
implementation is reasonable enough to be able to handle
realistic scenarios.
Future research will proceed in the following direction.
Since the initial specification is ultimately provided in some
form of natural language, we would like the feedback that
we provide to be in a natural language setting as well.
Acknowledgements
The authors would like to thank the anonymous reviewers for their
detailed comments and suggestions.

Funding
This work has been partially supported by the NSF (award CNS
1116136).

Kim et al.

Notes
1. Here, F stands for eventually in the future, U for until and G
for always. Further introduction of LTL is out of the scope of
this paper and the interested reader can explore the logic in
Fainekos et al. (2009). We use LTL in the following for succinctness in the presentation.
2. Note that B1 B2 implies that B2 simulates B1 under the usual
notion of simulation relation (Clarke et al., 1999). However,
clearly, if B2 simulates B1 , then we cannot infer that B2 is a
relaxation of B1 as defined in Definition 4.
3. To keep the presentation simple, we do not extend the definition of the ordering relation to isomorphic automata. Also,
this is not required in our technical results since we are actually going to construct automata which are relaxations of a
specification automaton. The same holds for bisimilar automata (e.g. Park, 1981).

References
Bhatia A, Kavraki LE and Vardi MY (2010) Sampling-based
motion planning with temporal goals. In: International
conference on robotics and automation. IEEE, pp. 2689–2696.
Bobadilla L, Sanchez O, Czarnowski J, Gossman K and LaValle
S (2011) Controlling wild bodies using linear temporal logic.
In: Proceedings of robotics: science and systems, Los Angeles,
CA, USA.
Buchi JR (1960) Weak second order arithmetic and finite automata. Zeitschrift für mathematische, Logik und Grundlagen
Mathematik 6: 66–92.
Chechik M and Gurfinkel A (2003) TLQSolver: A temporal
logic query checker. In: Proceedings of the 15th international
conference on computer aided verification (Lecture Notes in
Computer Science, vol. 2725). New York: Springer, pp.
210–214.
Choset H, Lynch KM, Hutchinson S, Kantor G, Burgard W, Kavraki LE and Thrun S (2005) Principles of Robot Motion: Theory, Algorithms and Implementations. Cambridge, MA: MIT
Press.
Cimatti A, Roveri M, Schuppan V and Tchaltsev A (2008) Diagnostic information for realizability. In: Logozzo F, Peled D and
Zuck L (eds.) Verification, Model Checking, and Abstract
Interpretation (Lecture Notes in Computer Science, vol. 4905).
New York: Springer, pp. 52–67.
Cizelj I and Belta C (2013) Negotiating the probabilistic satisfaction of temporal logic motion specifications. In: IEEE/RSJ
international conference on intelligent robots and systems.
Clarke EM, Grumberg O and Peled DA (1999) Model Checking.
Cambridge, MA: MIT Press.
Cormen TH, Leiserson CE, Rivest RL and Stein C (2001) Introduction to Algorithms, 2nd edn. Cambridge, MA: MIT Press/
McGraw-Hill.
Ding Y and Zhang Y (2005) A logic approach for ltl system modification. In: 15th international symposium on foundations of
intelligent systems (Lecture Notes in Computer Science, vol.
3488). New York: Springer, pp. 435–444.
Dzifcak J, Scheutz M, Baral C and Schermerhorn P (2009) What
to do and how to do it: Translating natural language directives
into temporal and dynamic logic representation for goal management and action execution. In: Proceedings of the IEEE
international conference on robotics and automation.

1531

Fainekos GE (2011) Revising temporal logic specifications for
motion planning. In: Proceedings of the IEEE conference on
robotics and automation.
Fainekos GE, Girard A, Kress-Gazit H and Pappas GJ (2009)
Temporal logic motion planning for dynamic robots. Automatica 45: 343–352.
Filippidis I, Dimarogonas DV and Kyriakopoulos KJ (2012)
Decentralized multi-agent control from local LTL specifications. In: 51st IEEE conference on decision and control, pp.
6235–6240.
Finger M and Wassermann R (2008) Revising specifications with
CTL properties using bounded model checking. In: Brazilian
symposium on artificial intelligence (Lecture Notes in Artificial Intelligence, vol. 5249). New York: Springer, pp. 157–166.
Gastin P and Oddoux D (2001) Fast LTL to Büchi automata translation. In: G Berry, H Comon and A Finkel (eds.) Proceedings
of the 13th CAV (Lecture Notes in Computer Science, vol.
2102). New York: Springer, pp. 53–65.
Giacomo GD and Vardi MY (1999) Automata-theoretic approach
to planning for temporally extended goals. In: European conference on planning (Lecture Notes in Computer Science, vol.
1809). New York: Springer, pp. 226–238.
Göbelbecker M, Keller T, Eyerich P, Brenner M and Nebel B
(2010) Coming up with good excuses: What to do when no
plan can be found. In: Proceedings of the 20th international
conference on automated planning and scheduling (ICAPS).
AAAI Press.
Guo M and Dimarogonas DV (2013) Reconfiguration in motion
planning of single- and multi-agent systems under infeasible
local LTL specifications. In: IEEE conference on decision and
control.
Guo M and Dimarogonas DV (2014) Distributed plan reconfiguration via knowledge transfer in multi-agent systems under
local LTL specifications. In: IEEE international conference on
robotics and automation.
Guo M, Johansson KH and Dimarogonas DV (2013) Revising
motion planning under Linear Temporal Logic Specifications
in partially known workspaces. In: IEEE international conference on robotics and automation.
Gurfinkel A, Devereux B and Chechik M (2002) Model exploration with temporal logic query checking. SIGSOFT Software
Engineering Notes 27(6): 139–148.
Hauser K (2012) The minimum constraint removal problem with
three robotics applications. In: Proceedings of the international
workshop on the algorithmic foundations of robotics (WAFR).
Karaman S, Sanfelice R and Frazzoli E (2008) Optimal control of
mixed logical dynamical systems with linear temporal logic
specifications. In: IEEE conference on decision and control.
Kim K (2014a) LTL2BA modification for indexing. Available at:
https://git.assembla.com/ltl2ba_cpslab.git.
Kim K (2014b) Temporal logic specification revision and planning toolbox. Available at: https://subversion.assembla.com/
svn/temporal-logic-specification-revision-and-planning-toolbox/.
Kim K and Fainekos G (2012) Approximate solutions for the minimal revision problem of specification automata. In: Proceedings of the IEEE/RSJ international conference on intelligent
robots and systems.
Kim K and Fainekos G (2014) Revision of specification automata
under quantitative preferences. In: Proceedings of the IEEE
conference on robotics and automation.

1532

Kim K, Fainekos G and Sankaranarayanan S (2012) On the revision problem of specification automata. In: Proceedings of the
IEEE conference on robotics and automation.
Kloetzer M and Belta C (2010) Automatic deployment of distributed teams of robots from temporal logic specifications. IEEE
Transactions on Robotics 26(1): 48–61.
Konighofer R, Hofferek G and Bloem R (2009) Debugging formal
specifications using simple counterstrategies. In: Formal Methods in Computer-Aided Design. IEEE, pp. 152–159.
Kress-Gazit H, Fainekos GE and Pappas GJ (2008) Translating
structured English to robot controllers. Advanced Robotics 22:
1343–1359.
Kress-Gazit H, Fainekos GE and Pappas GJ (2009) Temporal logic
based reactive mission and motion planning. IEEE Transactions on Robotics 25: 1370–1381.
Kupferman O, Li W and Seshia SA (2008) A theory of mutations
with applications to vacuity, coverage, and fault tolerance. In:
Proceedings of the international conference on formal methods
in computer-aided design. Piscataway, NJ: IEEE Press, pp. 25:
1–25:9.
Lacerda B and Lima P (2011) Designing Petri net supervisors
from LTL specifications. In: Proceedings of robotics: science
and systems, Los Angeles, CA, USA.
Lahijanian M, Almagor S, Fried D, Kavraki LE and Vardi MY
(2015) This time the robot settles for a cost: A quantitative
approach to temporal logic planning with partial satisfaction.
In: The twenty-ninth AAAI conference (AAAI-15).
LaValle SM (2006) Planning Algorithms. Cambridge: Cambridge
University Press.
LaViers A, Egerstedt M, Chen Y and Belta C (2011) Automatic
generation of balletic motions. IEEE/ACM international conference on cyber-physical systems, pp. 13–21.
Park D (1981) Concurrency and automata on infinite sequences.
In: Proceedings of the 5th GI-conference on theoretical computer science. Berlin: Springer-Verlag, pp. 167–183.
Raman V and Kress-Gazit H (2011) Analyzing unsynthesizable
specifications for high-level robot behavior using LTLMoP. In:
23rd international conference on computer aided verification
(Lecture Notes in Computer Science, vol. 6806). New York:
Springer, pp. 663–668.
Raman V and Kress-Gazit H (2013) Towards minimal explanations of unsynthesizability for high-level robot behaviors. In:
2013 IEEE/RSJ international conference on intelligent robots
and systems, Tokyo, Japan, 3–7 November 2013, pp. 757–762.
DOI:10.1109/IROS.2013.6696436.
Raman V, Lignos C, Finucane C, Lee KCT, Marcus MP and
Kress-Gazit H (2013) Sorry dave, i’m afraid I can’t do that:
Explaining unachievable robot tasks using natural language.
In: Robotics: Science and Systems IX, Technische Universität
Berlin, Berlin, Germany, 24–28 June 2013.
Roy P, Tabuada P and Majumdar R (2011) Pessoa 2.0: a controller
synthesis tool for cyber-physical systems. In: Proceedings of
the 14th international conference on hybrid systems: computation and control (HSCC’11). New York, NY: ACM Press, pp.
315–316.
Smith DE (2004) Choosing objectives in over-subscription planning. In: Proceedings of the 14th international conference on
automated planning and scheduling (ICAPS-04), pp. 393–401.
Sniedovich M (2006) Dijkstra’s algorithm revisited: the dynamic
programming connexion. Control and Cybernetics 35:
599–620.

The International Journal of Robotics Research 34(12)

Thistle JG and Wonham WM (1994) Supervision of infinite behavior of discrete-event systems. SIAM Journal of Control Optimization 32(4): 1098–1113.
Tumova J, Castro LIR, Karaman S, Frazzoli E and Rus D (2013)
Minimum-violating planning with conflicting specifications.
In: American control conference.
Ulusoy A, Smith SL, Ding XC and Belta C (2012) Robust multirobot optimal path planning with temporal logic constraints.
In: 2012 IEEE international conference on robotics and automation (ICRA).
Ulusoy A, Smith SL, Ding XC, Belta C and Rus D (2011) Optimal multi-robot path planning with temporal logic constraints.
In: IEEE/RSJ international conference on intelligent robots
and systems, pp. 3087–3092.
van den Briel M, Sanchez R, Do MB and Kambhampati S (2004)
Effective approaches for partial satisfaction (over-subscription)
planning. In: Proceedings of the 19th national conference on
artifical intelligence (AAAI’04). AAAI Press, pp. 562–569.
Wongpiromsarn T, Topcu U and Murray RM (2010) Receding
horizon control for temporal logic specifications. In: Proceedings of the 13th ACM international conference on hybrid systems: computation and control. New York, NY: ACM Press,
pp. 101–110.

Appendix A: NP-completeness of the Minimal
Connecting Edge problem
We will prove the Minimal Connecting Edge (MCE) problem is NP-Complete. MCE is a slightly simpler version of
the Minimal Accepting Path (MAP) problem and, thus,
MAP is NP-Complete as well.
In MCE, we consider a directed graph G = (E, V) with a
source s and a sink t where there is no path from s to t. We
^ to be added to E such
also have a set of candidate edges E
that the graph becomes connected and there is a path from
^ have no dependencies
s to t. Note that if the edges in E
between them, then there exists an algorithm that can solve
the problem in polynomial time. For instance, Dijkstra’s
algorithm (Cormen et al., 2001) applied on the weighted
^ w) where the edges in E
^ are
directed graph G = (V , E [ E,
assigned weight 1 and the edges in E are assigned weight 0
solves the problem efficiently.
^ is partitioned in a number
However, in MCE, the set E
^
^
of classes E1 , . . . , En such that if an edge ei is added from
^ i are added as well to G.
^ i , then all the other edges in E
E
This corresponds to the fact that if we remove a predicate
from a transition in Bs , then a number of transitions on GA

q0 , s1

e0

e1

q1 , s1

e2

e3

q2 , s1

e4
e5
q3 , s1
Fig. 13. The MCE instance that corresponds to GA from Figure
^
7. The dashed edges denote candidate edges in E.

Kim et al.

1533

uti

∈ Pi

ui

vi
ufi

∈ Ni

vif

Fig. 14. A single variable gadget. Solid edges are present in the
original graph G that will be constructed. Dashed edges (uti , vti )
^
or between (ufi , vfi ) will be supplied by one of the edge sets in E.

are affected. Let us consider the GA in Figure 7 as an
example. Here, e0, e2 and e4 correspond to y((s1, s1),p0), e1
and e5 to y((s1,s1),p2) and e3 to y((s1,s1),p3). Thus,
^ and there exist three classes E
^i,
fe0 , e1 , e2 , e3 , e4 , e5 g 2 E
^ j in the partition such that fe0 , e2 , e4 g  E
^i,
^ j and E
E
^ j and e3 2 E
^k .
fe1 , e5 g  E
Problem 3. (Minimal Connecting Edge (MCE)). INPUT: Let
G = (V, E) be a directed graph with a source s and a distinguished sink node t. We assume that there is no path in
^  V × V be a set such that E
^ \ E = ;.
G from s to t. Let E
^
^
^
^
We partition E into E = fE1 , . . . , Em g. Each edge e 2 E
has a weight W(e)  0.
OUTPUT: Given a weight limit W, determine whether there
^ such that:
is a selection of edges R  E
1.
2.
3.

there is a path from s to t in the graph with all edges
E[R;
P
e2[R W (e) 	 W ; and
^ i \ R 6¼ ; then E
^ i  R.
^ i 2 E, if E
for each E

Theorem 3. MCE is NP-complete.
Proof. The problem is trivially in NP. Given a selection of
^ we can indeed verify that the source and
edges from E,
sinks are connected, the weight limit is respected and that
the selection is made up of a union of sets from the
partition.
We now claim that the problem is NP-Complete. We
will reduce from 3-CNF-SAT. Consider an instance of 3CNF-SAT with variables X = {x1, ., xn} and clauses C1,
., Cm. Each clause is a disjunction of three literals. We
will construct graph G and family of edges E. The graph G
has edges E made up of variable and clause ‘‘gadgets’’.

A.1 Variable gadgets
For each variable xi, we create six nodes ui, uti , vti , ufi , vfi ,
and vi. The gadget is shown in Figure 14. The node ui is
called the entrance to the gadget and vi is called the exit.
The idea is that if the variable is assigned true, we will take
the path
ui ! uti ! vti ! vi

∈ P1

a1j

vit
aj

∈ N2

a2j

∈ N3

a3j

b1j
b2j

bj

b3j

Fig. 15. The clause gadget for a clause with three literals. The
clause shown here is (x1 _ x2 _ x3 ). The corresponding
missing edges will be added to the set P1, N2, N3, respectively.

x1

xn

C1

Cm

Fig. 16. Connection between gadgets for variables and clauses.

to traverse through the gadget from its entrance to exit. The
missing edge uti ! vti will be supplied by one of the edge
sets. If we assign the variable to false, we will instead
traverse
ui ! ufi ! vfi ! vi
Variable gadgets are connected to each other in G by
adding edges from v1 to u2, v2 to u3 and so on until
vn21!un. The node u1 is the source node.

A.2 Clause gadgets
For each clause Cj of the form (‘j1_‘j2_‘j3), we add a clause
gadget consisting of eight nodes: entry node aj, exit node bj
and nodes aj1,bj1, aj2,bj2 and aj3,bj3 corresponding to each
of the three literals in the clause. The idea is that a path
from the entry node aj to exit node bj will exist if the clause
Cj will be satisfied. Figure 15 shows how the nodes in a
clause gadget are connected.

A.3 Structure
We connect vn the exit of the last variable gadget for variable xn to a1, the entrance for first clause gadget. The sink
node is bm, the exit for the last clause gadget. Figure 16
shows the overall high-level structure of the graph G with
variable and clause gadgets.

A.4 Edge sets
We design a family E = fP1 , . . . , Pn , N1 , . . . , Nn g. The set
Pi will correspond to a truth assignment of true to variable
xi and Ni correspond to a truth assignment of false to xi.
Pi has the edge (uti , vti ) of weight 1 and for each clause
Cj containing the literal xi, we add the missing edge (aij , bij )

1534

corresponding to this literal in the clause gadget for Cj to
the set Pi with weight 0.
Similarly, Ni has the edge from (ufi , vfi ) of weight 1 and
for each clause Cj containing the literal xi it has the missing
edge in the clause gadget for Cj with weight 0. We ask
whether there is a way to connect the source u1 with the
sink bm with weight limit 	 n, where n is the number of
variables.
We verify that the sets P1, ., Pn, N1, ., Nn partition
the set of missing edges.
Claim 1. If there is a satisfying solution to the problem,
then u1can be connected to bm by a choice of edge sets with
total edge weight 	 n.
Proof. Take a satisfying solution. If it assigns true to xi,
then choose all edges in Pi else choose all edges Ni if it
assigns false. We claim that this will connect u1 to bm. First
it is clear that since all variables are assigned, it will connect u1 to vn by connecting one of the two missing links in
each variable gadget. Corresponding to each clause, Cj
there will be a path from aj to bj in the clause gadget for
Cj. This is because, at least one of the literals in the clause
is satisfied and the corresponding set Pi or Ni will supply
the missing edge. Furthermore, the weight of the selection
will be precisely n, since we add exactly one edge in each
variable gadget.
u
Claim 2. If there is a way to connect source to sink with
weight 	 n, then a satisfying assignment exists.
Proof. First of all, the total weight for any edge connection
from source to sink is  n since we need to connect u1 to
vn there are n edges missing in any shortest path. The edges
that will connect have weight 1, each. Therefore, if there is a
way to connect source to sink with weight 	 n, the total
weight must in fact be n. This allows us to conclude that for
every variable gadget precisely one of the missing edges is
present. As a result, we can now form a truth assignment
setting xi to true if Pi is chosen and false if Ni is. Therefore,
the truth assignment will assign either true to xi or false and
not both thanks to the weight limit of n.
u
Next, we prove that each aj will be connected to bj in
each clause gadget corresponding to clause Cj. Let us
assume that this was using the edge (aij , bij ) 2 Ni . Then, by
construction have that xi was in the clause Cj which is now
satisfied since Ni is chosen, assigning xi to false. Similar reasoning can be used if (aj, bj) 2 Pi. Combining, we conclude
that all clauses are satisfied by our truth assignment.
u

The International Journal of Robotics Research 34(12)

Proof. We have already seen that the AAMRP runs in
polynomial time.
Let Y = {y1, ., ym} be a set of Boolean variables and
G: (V, E) be a graph with a labeling function L : E ! P(Y ),
wherein each edge e 2 E is labeled with a set of Boolean
variables L(e) 4Y. The label on an edge indicates that the
edge is enabled iff all the Boolean variables on the edge are
set to true. Let v0 2 V be a marked initial state and F4V
be a set of marked final vertices.
Consider two functions w0 : E ! P(Y ), and
w : E ! N where E* represents the set of all finite
sequences of edges of the graph G. Hence, w0 (P) for a path
P = hv0,.,vki is a set of Boolean variables of its constituent edges which makes them enabled on the path P:
w0 (P) =

Theorem 4. AAMRP on planar DAGs where all the paths
merge on the same node is a polynomial-time 2-approximation algorithm for the MRP.

L(vi1 , vi )

i=1

while w(P) is the number of the Boolean variables of


k
[



w(P) =  L(vi1 , vi ) = jw0 (P)j
i = 1

Given a initial vertex v0, two vertices vi, vj, and a final
vertex vk, let Popt denote the path that produces an optimal
revision for the given graph. Let Pa denote a general revision by AAMRP. Suppose that Popt consists of sub-paths
P0i, Pij, Pjk, and Pa consists of sub-paths P0i, P0 ij, Pjk.
We will discuss the cases when P0i and Pjk are empty
later. The former case can occur when Popt and Pa do not
have any common edges from v0 to vi in the sense that each
path takes a different neighbor out of v0. This case can also
occur when 0 \ i if from v0 to vi there are no Boolean variables to be enabled to make the path activated. Likewise,
the latter case can occur when i \ j \ k or when i 	 j =
k. We do not take i = j unless j = k. Considering both
cases together, we can get the possibility that Popt and Pa
are entirely different from v0 to vk.
In vj, the AAMRP should relax the weight of the path
from v0 to vj, comparing between two paths Pij and P0 ij.
Thus, we can denote
w0 (Pm ) = w0 (P0i ) [ w0 (P0ij ) [ w0 (Pjk )
w0 (P ) = w0 (P0i ) [ w0 (Pij ) [ w0 (Pjk )
Let w0 (P0i) [w0 (P0 ij) = La, w0 (P0i) [w0 (Pij) = Lopt, and
w (Pjk) = L. Then, we can denote
0

Appendix B: Upper bound of the
approximation ratio of AAMRP
We shall show the upper bound of the approximation algorithm (AAMRP) for a special case.

k
[

w0 (Pa ) = La [ L
w0 (Popt ) = Lopt [ L
Recall that
w(Pa ) = jLa [ Lj


w(Popt ) = Lopt [ L

Kim et al.

1535

We will show that w(Pa) 	 2w(Popt).
Note that w(Popt)  1, so that jLopt [ Lj  1. This is
because if w(Popt) = 0, then it is reachable from v0 to vf
without enabling any boolean variables which are atomic
propositions of the specification.
Remark 1. We have jLopt [ Lj  1.
Note that jLaj 	 jLoptj. This is because the AAMRP
only relaxes the path when it has fewer Boolean variables.
Remark 2. We have jLaj 	 jLoptj.
Note that if jLaj = 0, then jLopt [ Lj = jLa [ Lj 	 2
jLopt [ Lj. In this case, La is the optimal path if La = 0
since L is common for the two paths. That is,
w(Pa) 	 2w(Popt).
Consider the case jLaj  1. We will prove the claim by
contradiction. Assume that 2w(Popt) \ w(Pa) so that 2jLopt
[ Lj \ jLa [ Lj. Let jLaj = m, jLoptj = h and jLj = t.
There are four cases.
Case 1. If Lopt \ L = ; and La \ L = ;, then


2Lopt [ L\jLa [ Lj ) 2(h + t)\m + t
2h + 2t\m + t ) 2h + t\m
However, m 	 h by Remark 2. Thus, h + t \ 0
which is not possible and it contradicts our assumption.
Case 2. If Lopt \ L 6¼ ; and La \ L = ;, then let jLopt
\ Lj = z, where 1 	 z 	 min(h, t).


2Lopt [ L\jLa [ Lj ) 2(h + t  z)\m + t
2h + 2t  2z\m + t ) 2h  2z + t\m
If h 	 t, then z 	 h and h = z + a, for some
a0

However, m 	 h by Remark 2. Thus, 2a + b \ 0
which is not possible and it contradicts our assumption.
Case 3. If Lopt \ L = ;, La \ L 6¼ ;, then let jLa \
Lj = u, where 1 	 u 	 min(m, t)


2Lopt [ L\jLa [ Lj ) 2(h + t)\m + t  u
2h + t\m  u ) 2h + t\m
However, m 	 h by Remark 2. Thus, h + t \ 0
which is not possible and it contradicts our assumption.
Case 4. If Lopt \ L6¼;, La \ L 6¼ ;, then let jLopt \ Lj =
z, where 1 	 z 	 min(h, t), and jLa \ Lj = u, where
1 	 u 	 min(m, t)


2Lopt [ L\jL [ Lj ) 2(h + t  z)\m + t  u
2h + 2t  2z\m + t  u ) 2h + t  2z\m  u\m
If h 	 t, z 	 h and h = z + a, for some a  0,
then
2(z + a) + t  2z\m ) 2a + t\m
However, m 	 h and h 	 t by Remark 2. Thus, 2a
\ 0 which is not possible and it contradicts our
assumption.
If h . t, h = t + b, for some b . 0, z 	 t and t =
z + a, for some a  0, then
2h + t  2z\m ) h + (t + b) + t  2z\m
h + (z + a) + b + (z + b)  2z\m
) h + 2z + a + 2b  2z\m
h + a + 2b\m

2(z + a)  2z + t\m ) 2a + t\m
However, h 	 t and m 	 h by Remark 2. Thus, 2a
\ 0 which is not possible and it contradicts our
assumption.
If h . t and h = t + b, for some b . 0, then z 	 t
and t = z + a, for some a  0
2(t + b)  2z + t\m ) 2t  2z + 2b + t\m
2(z + a)  2z + 2b + t\m ) 2z + 2a  2z + 2b + t\m
2a + 2b + t\m ) 2a + 2b + h  b\m
2a + b + h\m

However, m 	 h by Remark 2. Thus, a + 2b \ 0
which is not possible and it contradicts our assumption.
Therefore, jLa [ Lj 	 2jLopt [ Lj, and we can conclude that w(Pa) 	 2w(Popt).

2015 IEEE 17th International Conference on High Performance Computing and Communications (HPCC), 2015 IEEE 7th
International Symposium on Cyberspace Safety and Security (CSS), and 2015 IEEE 12th International Conf on Embedded Software
and Systems (ICESS)

Automatic Parallelization of Simulink Models for
Multi-core Architectures
Cumhur Erkan Tuncali, Georgios Fainekos, Yann-Hang Lee
School of Computing, Informatics and Decision Systems
Arizona State University
Tempe, AZ, USA
{etuncali, fainekos, yhlee}@asu.edu
of an embedded control algorithm, the worst case execution
times of the blocks and a computation budget (deadline), can
we automatically partition the blocks onto the different cores
so that the real-time constraints are satisﬁed?

Abstract— This paper addresses the problem of parallelizing
existing single-rate Simulink models for embedded control applications on multi-core architectures considering communication
cost between blocks on different CPU cores. Utilizing the block
diagram of the Simulink model, we derive the dependency graph
between the different blocks. In order to solve the scheduling
problem, we describe a Mixed Integer Linear Programming
(MILP) formulation for optimally mapping the Simulink blocks
to different CPU cores. Since the number of variables and
constraints for MILP solver grows exponentially when model
size increases, solving this problem in a reasonable time becomes
harder. For addressing this issue, we introduce a set of techniques
for reducing the number of constraints in the MILP formulation.
By using the proposed techniques, the MILP solver ﬁnds solutions
that are closer to the optimal solution within a given time
bound. We study the scalability and efﬁciency of our consisting
approach with synthetic benchmarks of randomly generated directed acyclic graphs. We also use the Fault-Tolerant Fuel Control
System demo from Simulink and a Diesel engine controller from
Toyota as case studies for demonstrating applicability of our
approach to real world problems.

In particular, we focus on control models built in the
Simulink [2] MBD environment. Our goal is to produce a
framework where non-determinism in the control algorithm
is reduced or minimized to the extent possible. Especially
in safety-critical systems, scheduling in a predictable and
deterministic manner is highly important for veriﬁcation and
satisfying the certiﬁcation requirements that are mandated by
regulatory authorities. For example, multi-core architectures
are classiﬁed as highly complex in the 2011/6 ﬁnal report
of European Aviation Safety Agency (EASA) [3] and in the
Certiﬁcation Authorities Software Team position paper CAST32 Multi-core processors [4]. These classiﬁcations highlight
the difﬁculty of certifying safety-critical systems that are based
on multi-core architectures.
Our approach is based on keeping timing properties of
parallelized software as simple as possible. For this purpose,
we are aiming at having separate executables for each core
while Simulink blocks are allocated in each core and executed
in a predetermined order. In other words, we set the priorities
of each block inside each core.

Keywords—Multiprocessing, embedded systems, optimization,
model based development, Simulink, task allocation.

I.

I NTRODUCTION

Model Based Development (MBD) has gained a lot of
traction in the industries that develop safety critical systems.
This is particularly true for industries that develop CyberPhysical Systems (CPS) where the software implements control algorithms for the physical system. Using MBD, system
developers and control engineers can design the control algorithms on high-ﬁdelity models. Most importantly, they can
test and verify the system properties before having a prototype
of the system. The autocode generation facility of MBD tools
provides additional concrete beneﬁt which helps in eliminating
programming errors.

The contributions of this paper are,

However, currently, the autocode generation process of
commercial tools focuses on single-core systems. Namely, at
the model level, there is no automatic support for producing
code that runs on a multi-core system. This is problematic
since advanced control algorithms, e.g., Model Predictive
Control algorithms [1], are computationally demanding and
may not be executed within the limited computation budget of
a single-core embedded system. In this paper, we address this
problem at the model level. Namely, given a data ﬂow diagram

providing a practical solution to the Simulink model
parallelization problem,

•

improving available Mixed Integer Linear Program
(MILP) formulations in the literature for ﬁnding better
solutions within a ﬁxed and practically feasible time
for industrial size models,

•

solving the multi-core mapping problem while considering the timing predictability of the parallelized
application for ease of veriﬁcation and certiﬁcation,
and

•

developing a toolbox for automating parallelization of
Simulink models to multi-core architectures.
II.

R ELATED W ORK

There is a large amount of research being done on the
optimization of scheduling multiple tasks on multi-core processors or multiple processors in the literature. In [5] Anderson

This research was partly funded by the NSF awards CNS-1446730 and
IIP-1361926, and the NSF I/UCRC Center for Embedded Systems.

978-1-4799-8937-9/15 $31.00 © 2015 IEEE
DOI 10.1109/HPCC-CSS-ICESS.2015.232

•

964

et al. propose a Pfair [6] based scheduling method for realtime scheduling on multi-core platforms where the system
has multiple tasks and task migration is allowed. For optimal
mapping of tasks to CPU cores, Yi et al. [7], Bender [8] and
Ostler et al. [9] discuss integer linear programming techniques
which constitute a base for our optimization formulation.
Cotton et al. discuss the use of mapping programs to multi
processors in [10]. Tendulkar et al. discuss the application
of SMT solvers in many-core scheduling for data parallel
applications in [11]. In [12], Feljan et al. propose heuristics
for ﬁnding a good solution for task allocation problems in a
short time instead of searching for an optimal solution.

III.

P ROBLEM D ESCRIPTION

We are addressing the problem of automatically parallelizing existing Simulink models for embedded control applications on multi-core architectures in an optimal way and in a
reasonable time.
We are focusing on single-rate, single-task embedded
control applications which are modeled in Simulink and in
which the execution order of blocks is determined only by
dependencies coming from connections between blocks. Our
target models cannot start execution of next iteration before
ﬁnishing the execution of the current iteration.

There are studies focusing on parallelization of Simulink
models. In [13], Kumura et al. propose methods to ﬂatten
Simulink models for parallelization without giving a detailed
description of the optimization formulation. In that work,
Simulink blocks are considered as tasks. To achieve thread
level parallelism in multi-core, Canedo et al. introduce the
concepts of strands for breaking the data dependencies in
the model. A strand is deﬁned as a chain of blocks that are
driven by Mealy blocks [14]. The proposed method searches
for available strand split points in Simulink models and it is
heavily relying on strand characteristics in target models. In
[15], Cha et al. is focusing on automating code generation for
multi-core systems where the parallel blocks are grouped by
user-deﬁned parallelization start and end S-functions into the
model.

Our target platform is Qorivva MPC5675K-based evaluation board [19]. The processor is a dual-core 32-bit MCU
from Freescale targeting automotive applications. The μC/OSII from Micrium [20] is ported on the target and a library to
support Simulink code generation is devised for the platform
[21]. We handle inter-core data communications by utilizing
available shared memory and inter-core semaphores which
are used for synchronization between tasks across cores and
protecting global critical sections as described by Bulusu in
[21]. For the purpose of utilizing this approach in Simulink,
we model transmission and reception of data between different cores with two separate S-function blocks which implement inter-core transmission and reception using inter-core
semaphores and shared memory. We will refer to these Sfunction blocks as inter-core communication blocks.

There are studies on task parallelization as [9], [7], [8].
However, to apply the similar approaches, Simulink blocks
must be considered as tasks. Given that most realistic models
may consist of a signiﬁcant number of blocks, either these
methods fail to ﬁnd an optimal solution in a reasonable
amount of time or they rely on available loop level parallelism
or functional pipelining as described in [9]. Deng et al.
study model-based synthesis ﬂow from Simulink models to
AUTOSAR runnables [16] and runnables to tasks on multicore architectures in [17]. The authors extend the Firing
Time Automation (FTA) [18] model to specify activations
and requested execution time at activation points. They deﬁne
modularity as a measure of number of generated runnables and
reusability as a measure of false dependencies introduced by
runnable generation. The authors use modularity, reusability
and schedulability metrics for evaluation of runnable generations. They also propose different heuristics and compare
their results with the results obtained by utilizing a simulated
annealing algorithm. Although this work is targeting a similar
problem to our target problem, they are providing experiment
results for systems with less than 50 blocks and they are not
considering inter-core communication and memory overhead.

A. Solution Overview
We approach the problem in ﬁve steps which are illustrated
in Fig. 1. First, creating a directed acyclic graph which
represents dependencies between blocks. Task-data graphs are
discussed in [9]. We use a similar approach using blocks
instead of tasks, worst case execution times of blocks instead
of amount of work associated with tasks and using size
of data communication between blocks. Here we will refer
to this kind of graphs as “block dependency graphs”. Our
second step in approaching the problem is ﬁnding an optimal
or near optimal mapping of blocks to different CPU cores
by formulating a Mixed-Integer Linear Program (MILP) and
solving the resulting optimization problem with off-the-shelf
MILP solvers. The third step is automatically updating the
original Simulink model by adding inter-core communication
blocks where necessary in accordance with the most optimal
solution. The next step is generating separate code for each
target core by automatically commenting out the blocks that
are not mapped to the core for which code is being generated.
Finally, we compile the generated code and deploy it on the
target platform.

Our work mainly differs from the other works in literature
by
1.

providing a complete ﬂow for automatically parallelizing a single-rate Simulink model,

2.

incorporating the communication cost in the optimization problem,

3.

having total available shared memory constraints, and

4.

being able to handle large models with more than 100
blocks in a reasonably short time.

IV.

M ILP F ORMULATION

In this section we present our MILP formulation for the
parallelization problem. Our MILP formulation for optimal
solution is based on the formulations proposed by [5], [6]
and [7]. We introduce an extension to these formulations by
dividing the cost of communication to the transmission and
reception parts. In Subsection D, we describe our techniques
for reducing the number of constraints for allowing the MILP
solvers to ﬁnd better solutions within a feasible time.

965


	





is used in the program formulation to dominate other terms
allowing constraints to be ignored under certain conditions.

 	
	
	
 	
		

 			
		 	
!	"				

B. Variables
bip : A Boolean variable indicating whether block Bi is
mapped to core Pp or not. It is deﬁned for all Bi ∈ B and for
all Pp ∈ P . If Bi is mapped to core Pp , then bip takes value
1. If Bi is mapped to another core, then bip will takes value
0.

 #	$						
				"	
 !	

 $					

dik : A Boolean variable indicating whether block Bi
executes before or after Bk when both blocks are mapped to
same core. It is deﬁned for all Bi , Bk ∈ B with i < k. If Bi
executes before Bk , then dik takes value 1 and if Bi executes
after Bk , then dik takes value 0.

 					

si : The start time for the execution of block Bi . It is deﬁned
for all Bi ∈ B. The lower bound for the variable si (best case
start time) is denoted by bsi . It is determined by the best case
completion time for all of the blocks from which there is a
path to Bi in G. In the best case, all of this workload before
Bi is distributed equally on all of
 The best case
 the cores.
start time of Bi is calculated as
k∈Ki wk /m where Ki =
{Bk : Bk ∈ B ∧ there exists a path f rom Bk to Bi in G}.
The upper bound for the variable si (worst case start time)
is denoted by wsi . It is determined by the best case completion time for all of the blocks to which there is a path
from Bi in G and the block Bi itself, subtracted from the
deadline. The
 worstcase start
 time of Bi is calculated as
deadline − wi + k∈Yi wk /m where Yi = {Bk : Bk ∈
B ∧ there exists a path f rom Bi to Bk in G}. For all i, k
such that Bi , Bk ∈ B and for all p such that Pp ∈ P .

Fig. 1. Steps of going from a single-core Simulink model to multi-core target

A. Notation and Constants
The number of CPU cores available at the target architecture is denoted by m. The set of CPU cores is deﬁned as P =
{Pp : p ∈ [1, m]}. The number of nodes in the dependency
graph is denoted by n where each node corresponds to a block
in the ﬂattened and merged Simulink model. Merging of blocks
is done on the ﬂattened model as described in subsection D.
We describe the dependencies between blocks with the block
dependency graph. This is a directed acyclic graph G = (B,
E), where B = {B1 , B2 , , Bn } is the set of nodes and E is the
set of edges in G. Each node Bi corresponds to a Simulink
block with a worst case execution time wi and each edge Eik
represents a data dependency from block Bi to block Bk . The
set of leaf nodes in B, i.e., set of blocks which do not have
any output ports is denoted by L and the set of start blocks,
i.e., the set of blocks which do not have any input ports is
denoted by S. We use Z for the set of deleted connections from
the blocks that introduce delays (e.g., Unit Delay, Memory,
Integrator, etc) to successor blocks. These connections exist
in the original model, but they are deleted when forming the
directed acyclic graph for removing cycles from the model.
Such a connection is represented by Zik ∈ Z.

f : The completion time after executing all blocks. The
lower bound for variable f is 0 and the upper bound is the
deadline.
C. Objective Function and Constraints
The objective function for the optimization problem is minimizing f while the constraints for the optimization problem
are deﬁned as follows:

The size of the data transfer from block Bi to Bk in bytes
is deﬁned as cik . When Bi and Bk are mapped on different
cores there will be a communication cost for transferring cik
bytes of data between the cores. The communication cost is
divided into transmission and receiving parts where tik denotes
the transmission part of the communication time for sending
cik bytes of data from block Bi to block Bk when they are
mapped on different cores and rik denotes the receiving part
of the communication time for sending cik bytes of data from
block Bi to block Bk when they are on different cores.

1) Every block shall be assigned to a single core:

∀i : Bi ∈ B,
bip = 1

(1)

Pp ∈P

2) Delay introducing blocks and their ﬁrst successor blocks
shall be assigned to the same core:
∀i, k : Zik ∈ Z and ∀p : Pp ∈ P, bip − bkp = 0

The maximum allowed execution time for one iteration of
the model on the target multi-core architecture is given by the
deadline. It is either taken as a user input or calculated as the
overall worst case execution time on a single-core architecture.
The size of a global semaphore structure in bytes is denoted
by sSize and the size of total available shared memory in
bytes is deﬁned as totMem. Data alignment size in bytes
(word size) is denoted by aSize. A very large value (MAX)

(2)

3) The ﬁnishing time of each leaf block shall be less than
or equal to the completion time for executing all blocks: This
constraint is serving for the purpose of being able to formulate
the objective function minimize(maxBi ∈L (si + wi ))) as
minimize(f ).
∀i : Bi ∈ L, si + wi ≤ f

966

(3)

1) Partially ordering independent blocks: In order to reduce the execution time of a model by parallelization, the
model must preferably have a large number of blocks that
are independent to each other. If all blocks are dependent to
each other, then there can be no multi-core mapping that will
improve the execution time and, thus, the best solution will be
mapping all blocks to the same core.

4) If there is a dependency from block Bi to Bk , block Bk
shall not start execution until (i) Bi ﬁnishes execution and
transmission of its output data to its successor blocks that are
mapped on other cores (which we temporarily deﬁne as fi
below) and (ii) Bk ﬁnishes receiving all of its input data that
are sent by the blocks on other cores: Considering that Bi is
mapped to core Pp and Bk is mapped to core Pq where p can
be equal to q:
∀i, k : Bi , Bk ∈ B, Eik ∈ E, ∀p, q : Pp , Pq ∈ P,

[rlk (1 − blq )] + (2 − bip − bkq )M AX
f i ≤ sk −
Bl ∈B

where fi = si + wi +



Bl ∈B [til (1

Typically, in an industrial size model with a large number
of blocks, both the number of blocks that are independent to
each other and the number of blocks that are dependent to each
other becomes large. In this case, when we consider all possible combinations of execution orders (priorities) between these
independent blocks, the number of constraints introduced by
inequalities (5) and (6) becomes very large. As a consequence,
ﬁnding an optimal solution within a feasible time becomes
harder.

(4)

− blp )].

5) Execution of independent blocks that are mapped to
same core cannot overlap: Considering Bi and Bk are mapped
to core Pp , we have two different constraints for this requirement.

We address this problem by deciding the execution order
between certain independent blocks in advance. That is, before
formulating the optimization problem, we decide the values of
the dik variables for these block pairs. Since our execution
order decision is valid only when these blocks are mapped
onto the same core, this should not prevent these blocks to
be mapped on different cores and, hence, be executed in a
different order than what we specify.

∀i, k : i < k, Bi , Bk ∈ B, Eik ∈ E, ∀p : Pp ∈ P,
f i ≤ sk −



[rlk (1 − blp )] + (3 − bip − bkp − dik )M AX

Bl ∈B

f k ≤ si −



(5)

Our partially ordering heuristic is based on comparing
the execution start time frames of independent blocks. The
execution start time frame of a block is deﬁned as the time
frame between its best and worst case start time values.
The best and the worst case start time values of a block
Bi ∈ B are deﬁned in the subsection IV-B as bsi and wsi
respectively. For all independent block pairs B
i ∈
 B and
Bk ∈ B, if (bs(i) ≤ bs(k))∧ (ws(i) < ws(k)) ∨ (bs(i) <
bs(k)) ∧ (ws(i) ≤ ws(k)) then we decide Bi to execute
before B
>
 k and set dik to 1. Else if (bs(i) ≥ bs(k))∧(ws(i)

ws(k)) ∨ (bs(i) > bs(k))∧(ws(i) ≥ ws(k)) then we decide
Bi to execute after Bk and set dik to 0.

[rli (1 − blp )] + (2 − bip − bkp + dik )M AX

Bl ∈B

Where, fi = si + wi +

(6)


and fk = sk + wk +

Bl ∈B

[til (1 − blp )]

Bl ∈B

[tkl (1 − blp )]

Since M AX is a very large constant, (5) will be valid when
block Bi executes before Bk i.e., when dik = 1 and (6) will
be valid when block Bi executes after Bk i.e., when dik = 0.

2) Fully ordering independent blocks: Even though ordering independent blocks using the partially ordering heuristic
improves the performance, this is not enough for models with
very large number of blocks. For example we could not ﬁnd
a feasible solution to models with more than 100 blocks with
this approach. For dealing with those large models we propose
deciding the execution order of all the independent blocks
when they are mapped on the same core. The logic in fully
ordering heuristic is based on comparing the midpoints of the
execution start time frames for these blocks. For independent
blocks Bi ∈ B and Bk ∈ B we decide Bi to be executed
before Bk if the average of bsi and wsi is smaller than the
average of bsk and wsk . With this approach, dik variables of
MILP formulation change to constant values. Our discussion
on the case when these blocks are mapped to different cores
in previous subsection is still valid.

6) Total memory needed for semaphores and communication buffers shall be less than or equal to total amount of
available shared memory:
∀i, k : Bi , Bk ∈ B, Eik ∈ E, ∀p : Pp ∈ P




 C 	

ik
·aSize ·|bip −bkp | < totM em
sSize+
aSize
Bi ,Bk ∈B
(7)
D. Improving Solver Time
The number of variables and constraints in the MILP
formulation grows exponentially as the number of blocks in the
model increase. Consequently, the MILP solver starts failing
in ﬁnding optimal or near optimal solutions for the problem in
a reasonable time. In this section, we introduce our techniques
for addressing this issue.

3) Merging highly coupled blocks: In this heuristic we
merge blocks Bi and Bk when block Bk is the only block
connected to the output port(s) of block Bi and block Bi is
the only block connected to the input port(s) of block Bk . The
merging operation copies all incoming and outgoing edges of
Bk to Bi except the edge Eik . Then it updates wi with wi +wk
and ﬁnally deletes Bk .

We say two blocks are dependent to each other if there
exists a directed path between corresponding nodes in the DAG
representation of the model and we say that two blocks are
independent if there is no directed path between these nodes.

967

merged together without introducing cycles between blocks.
An exception to this is a subsystem including a delay introducing block. In this case, the blocks inside such a subsystem
are not merged into a single block since this can cause a cycle
in the dependency graph. In such a subsystem, predecessor
blocks of a delay introducing block are only merged with other
predecessor blocks and successor blocks are only merged with
other successor blocks. In other words, a predecessor and a
successor of a delay introducing block are never merged. The
ﬂow of the process up to this point is illustrated in the simple
model in Fig. 2. In the next step, the block dependency graph is
annotated with estimates of WCET. Fig. 4 gives an illustration
of a simple block dependency graph.

4) Merging small blocks with large blocks: In this heuristic
we merge blocks Bi and Bk based on their ratio of execution
times. If block Bk is the only block connected to the output
port(s) of block Bi and the WCET of block Bi is very small
when compared to the WCET of block Bk , then block Bi is
merged into block Bk . If block Bi is the only block connected
to the output port(s) of block Bk and the WCET of block
Bk is very small when compared to the WCET of block
Bi , then block Bk is merged into block Bi . We ﬁnd this
technique useful for reducing the number of blocks of concern
in a way that parallelization will be focused on blocks with
higher impact on execution time. The ratio between the worst
case execution times of the blocks for determining a merge
operation can be deﬁned depending on how much reduction is
needed in the number of blocks.

The block dependency graph and the number of CPU cores
on the target architecture are used in generating the MILP
formulation presented in Section IV. The MILP solver returns
the best solution found for mapping blocks to the available
CPU cores and the execution order between these blocks.

The merging methods described above can be used for
decreasing the number of nodes in very large models where
the MILP solver can no more ﬁnd a good solution. These two
techniques are also dependent on the structure of the model.
Although, in general, they assist in ﬁnding better solutions,
there can be cases where the number of nodes cannot be
reduced to an acceptable level.
V.

The solution from the MILP solver is used to add inter-core
communication blocks between the blocks which are mapped
on different CPU cores. The relevant outputs of a block which
are sending data to a block on a different core are connected
to inter-core data transmitting S-function blocks. Similarly,
corresponding inter-core data receiving S-function blocks for
each transmitter are connected to the relevant inputs of the
block which is receiving data on a different core. The intercore communication blocks are added by setting unique IDs
that set each pair of transmitting and receiving blocks to use a
dedicated inter-core semaphore and a dedicated shared memory
location.

I MPLEMENTATION

In this section we describe the details of the implementation
of our tool in MATLAB.
Our tool accepts as an input a Simulink model that is
ready to compile as well as the desired depth of blocks
to be parallelized. It loads the model, reads speciﬁc block
information, e.g., block type, parents, etc., and all the relations
between blocks along with the width and size of the data on
the ports. For data types that are not built-in, the user input is
required to deﬁne the data size in bytes. Using this information
the model is ﬂattened by taking blocks inside sub-systems
out of their parent blocks. The remaining blocks like input
and output ports of subsystems, emptied subsystem container
blocks and ‘Goto’ - ‘From’ pairs, which are converted to line
connections, are discarded from the set of blocks.

An example of the transformation is given in Fig. 3. The
output of B1 is connected to the input of B2 in the original
model. This connection is then replaced by inter-core communication blocks. After adding all needed communication
blocks, we set the priority attributes of the blocks using the
execution start time values obtained from the optimization
solution.
As the last step, a copy of the model is created for every
CPU core. Each copy of the model corresponds to a CPU
core and the blocks which are mapped on other cores are
commented out. Code generated from each of these models
can be compiled to create separate executables for each core.

We represent all these dependencies in a directed graph
where a directed edge represents a data communication from
its source to its destination. Since determining Worst Case
Execution Times (WCET) is not in scope of this paper, we
assume that the WCET values for each of the blocks are
already determined. If there exists a cycle in the directed
graph, this means that there is a corresponding block in
the cycle which creates a data dependency from a previous
iteration of model execution. We will refer to these blocks
as delay introducing blocks. In these cases we break the
connection from delay introducing blocks to their successors
for transforming a directed graph to a directed acyclic graph.
Since the connection from delay introducing blocks to their
successor blocks are deleted, our MILP solution can never
introduce inter-core communication mechanism between these
blocks even if they are mapped on different cores. For dealing
with this issue we force the delay introducing blocks and their
successor blocks to be mapped on the same core in the MILP
formulation.

VI.

E XPERIMENTS

For studying the scalability and efﬁciency of our approach,
we utilize randomly generated directed acyclic graphs with
different number of nodes. We present results of these experiments in subsection VI-A and results of our case studies in subsections VI-B and VI-C. We use SCIP [22] from Achterberg
as MILP solver which is interfaced with MATLAB through
the Opti Toolbox [23] by Currie and Wilson. Experiments are
run on a 64-bit Windows 7 PC with Intel Xeon E5-2670 CPU
and 64 GB RAM.
A. Randomly Generated DAGs
For evaluating performance of our approach, we generate
DAGs in which the WCET, communication costs and connections between blocks are assigned randomly. Then we solve

After all of the cycles are cleared, the blocks that are
originally inside subsystems up to the desired model depth are

968



!




"



























	
















	




















#






	















	
















	









Fig. 4.








ordering heuristics (respectively denoted as basic, partial and
full) and corresponding solver run-time values are presented in
the table for different problem sizes. We also present the ratio
of the solutions found over all the experiments. For a problem
size, the lines corresponding to the approaches which could
not return any solutions are discarded in the table. As it can
be seen from the results presented in Table I, as the number
of blocks in a model increases, any heuristic that (partially)
sets the execution order performs better both in terms of
solver run-time and optimality of solutions. According to our
observations, for ﬁnding an optimal mapping, the basic MILP
formulation performs best when there are less than 30 blocks.
The partially ordering heuristic performs best when there are
30 to 50 blocks. For more than 50 blocks in the model, the
fully ordering heuristic outperforms other approaches in terms
of the achieved speed-up and the ability to return a solution.
The basic MILP formulation fails to return any solution for
models with 70 or more blocks. The partially ordering heuristic
fails to return any solution for models with more than 110
blocks. Although this detail is not illustrated in Table I because
of averaging, according to our experimental results, the fully
ordering heuristic can occasionally achieve very low speedup values compared to the other approaches when there are
less than 20 blocks in the model. However, this issue is
not observed when there are large number of blocks. This
behavior is parallel to our expectations since optimization
can signiﬁcantly reduce the effect of possible non-optimal
execution order decisions by trying large number of different
mapping of blocks to different cores.






!



	



"















#





















Fig. 2.



Flattening models and merging blocks

the problem for a dual-core system with the basic MILP
formulation which is given in Section IV and with the partially
and fully ordering heuristics for deciding the execution order
of independent blocks. We set ﬁve hours (18,000 sec) as an
acceptable upper time limit for the solver run time. Here,
we present a comparison of the performance of these three
approaches in terms of the average speed-up achieved, the
average solver time and the ability to ﬁnd a solution in the
given time limit. The speed-up is computed as the overall
single-core worst case execution time of the model divided
by the overall worst case execution time of the parallelized
model.
Given inﬁnite solver time, the basic MILP formulation
is expected to ﬁnd more optimal solutions than the other
approaches do for any problem size. However, when the solver
time is limited (5 hours in our experiments), it fails to ﬁnd satisfactory solutions for large problems. Table I gives a comparison of the performance of the used approaches. Average speedup achieved by basic MILP formulation, partially and fully












	





In Fig. 5, we illustrate the comparison between the two
heuristics and the basic MILP formulation in terms of the
achieved speed-up over the number of nodes. The solid lines in
the plot represent how much average speed-up is achieved by
each approach. The dashed lines represent the corresponding
minimum and maximum speed-up for each approach. For very
small number of nodes, the basic MILP formulation is better
than the other approaches. However, when the number of nodes
increases, ﬁrst, the partially ordering heuristic and, then, the
fully ordering heuristic perform best.






	















	










Fig. 3.

Block dependency graph for a simple model






	

In Fig. 6, we illustrate the comparison between the two
heuristics and the basic MILP formulation in terms of the
average solver time over the number of nodes. Each line in
the graph represents the average solver time spent for each

Inter-core communication blocks

969

# Nodes

Average
speed-up
1.48
1.47
1.46
1.68
1.71
1.46
1.48
1.62
1.55
1.2
1.66
1.67
1.09
1.55
1.59
1.54
1.75
1.39
1.7
1.38
1.61
1.08
1.64
1.04
1.67
1.56
1.62
1.61

Approach
Basic
Partial
Full
Basic
Partial
Full
Basic
Partial
Full
Basic
Partial
Full
Basic
Partial
Full
Partial
Full
Partial
Full
Partial
Full
Partial
Full
Partial
Full
Full
Full
Full

10-15

30

40

50

60
70
80
90
100
110
130
150
170




C OMPARISON OF DIFFERENT APPROACHES

Average
solver time
2
1
0.5
2620
1558
26
9256
2091
606
18000
12481
5174
18000
17400
11685
18000
18000
18000
18000
18000
18000
18000
18000
18000
18000
18000
18000
18000



% found
Solutions
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
64%
100%
100%
100%
100%
100%
100%
60%
100%
50%
100%
30%
100%
100%
100%
100%


")$ 

TABLE I.






 



 



 





 
 









	














	

&'($ )* &)%$

Fig. 6.

Comparison of solver time between different approaches

model has 1 input port, 1 output port and 53 blocks after
discarding the trivial blocks as described in Section V.
We performed parallelization on a completely ﬂattened
graph. The obtained block dependency graph from this model
is presented in Fig. 7 where the blocks mapped to core 1 and
core 2 are illustrated as the nodes colored with red and blue,
respectively.
We achieved a speed-up value of 1.78 with the partially
ordering heuristic within 5 hours of solver time. A speed-up
value of 1.92 was achieved with the fully ordering heuristic.
The basic MILP solution could only achieve a speed-up value
1.19 because it was unable to ﬁnd the optimum solution within
the given time limit of 5 hours. This result is parallel with the
outcomes of the experiments carried on randomly generated
DAGs.

approach. As it is expected, due to the time limit given to the
solver, as the number of nodes increases, the solution times for
all approaches converge. However, the experiments on models
with less number of nodes suggests that the proposed heuristics
can improve the solver time. In the graph it can be observed
that the average solver time for proposed heuristics (as a
function of node count) is smaller than the basic formulation.
Combining the data in Fig. 5 and Fig. 6, we can see that the
fully ordering heuristic returns better solutions within shorter
solver run-time compared to the other approaches.

C. Case Study: Toyota Diesel Engine Controller
We used the Diesel engine controller model from [1] as
a case study from industry. The original model contains both
controller and plant parts. The controller part of model has
1004 blocks when ﬂattened as described in Section V, it has
7 inputs that are merged into a single input bus signal and 6
outputs that are merged into a single output bus signal. Since
the model has cycles inside the subsystems, our tool ﬂattens
the model by searching all blocks inside subsystems, breaks

B. Case Study: Fault-Tolerant Fuel Control System
As a case study, we used the fuel rate control subsystem of
the Simulink Fault-Tolerant Fuel Control System demo. This

 





 





 


 	



 	

 

 




 

 

 







 









 

 







 
	












 




 

 




 	



 	



 


 	

 
 





 
 !

	



&'($ )* &)%$

 
 !



 
 !







	

 


 	





 

 




 



 

 

 





 




 



  	













 

 







 		



 

 


 





 




 






 




 







 
 

 	






 












 



 











	
"#$$%
#







 





Fig. 5.

 	








 	




 






 	

 




 	




 	

 

Fig. 7. The block dependency graph and its partition onto two cores for the
fuel control system case study

Comparison of speed-up values between different approaches

970

the cycles as described in Section V and merges blocks inside
subsystems (when possible) without introducing new cycles.
For parallelizing this model we set the target model depth as
2. After merging deep blocks of each subsystem, the block
dependency graph is generated from the model with merged
blocks. The generated block dependency graph contains 153
nodes and a total of 184 connections between these nodes. Our
target platform for this case study is the dual-core architecture
from Freescale which is described in Section III. In our target
hardware setup we have a total of 3.8 KB shared memory
available.

[4] Certiﬁcation Authorities Software Team, “Position paper CAST-32
multi-core processors,” Federal Aviation Administration, Tech. Rep.,
2014.
[5] J. H. Anderson, J. M. Calandrino, and U. C. Devi, “Real-time scheduling on multicore platforms,” in Real-Time and Embedded Technology
and Applications Symposium, 2006. Proceedings of the 12th IEEE.
IEEE, 2006, pp. 179–190.
[6] S. K. Baruah, N. K. Cohen, C. G. Plaxton, and D. A. Varvel,
“Proportionate progress: A notion of fairness in resource allocation,”
Algorithmica, vol. 15, no. 6, pp. 600–625, 1996.
[7] Y. Yi, W. Han, X. Zhao, A. T. Erdogan, and T. Arslan, “An ILP formulation for task mapping and scheduling on multi-core architectures,” in
Design, Automation & Test in Europe Conference & Exhibition, 2009.
DATE’09. IEEE, 2009, pp. 33–38.
[8] A. Bender, “Design of an optimal loosely coupled heterogeneous
multiprocessor system,” in European Design and Test Conference, 1996.
ED&TC 96. Proceedings. IEEE, 1996, pp. 275–281.
[9] C. Ostler and K. S. Chatha, “An ILP formulation for system-level application mapping on network processor architectures,” in Proceedings
of the conference on Design, automation and test in Europe. EDA
Consortium, 2007, pp. 99–104.
[10] S. Cotton, O. Maler, J. Legriel, and S. Saidi, “Multi-criteria optimization
for mapping programs to multi-processors,” in Industrial Embedded
Systems (SIES), 2011 6th IEEE International Symposium on. IEEE,
2011, pp. 9–17.
[11] P. Tendulkar, P. Poplavko, I. Galanommatis, and O. Maler, “Many-core
scheduling of data parallel applications using SMT solvers,” in Digital
System Design (DSD), 2014 17th Euromicro Conference on. IEEE,
2014, pp. 615–622.
[12] J. Feljan and J. Carlson, “Task allocation optimization for multicore
embedded systems,” in Software Engineering and Advanced Applications (SEAA), 2014 40th EUROMICRO Conference on. IEEE, 2014,
pp. 237–244.
[13] T. Kumura, Y. Nakamura, N. Ishiura, Y. Takeuchi, and M. Imai, “Model
based parallelization from the simulink models and their sequential C
code,” in Proceedings of the 17th Workshop on Synthesis And System
Integration of Mixed Information Technologies (SASIMI 2012), 2012,
pp. 186–191.
[14] A. Canedo, T. Yoshizawa, and H. Komatsu, “Automatic parallelization
of simulink applications,” in Proceedings of the 8th annual IEEE/ACM
international symposium on Code generation and optimization. ACM,
2010, pp. 151–159.
[15] M. Cha, K. H. Kim, C. J. Lee, D. Ha, and B. S. Kim, “Deriving highperformance real-time multicore systems based on simulink applications,” in Dependable, Autonomic and Secure Computing (DASC), 2011
IEEE Ninth International Conference on. IEEE, 2011, pp. 267–274.
[16] AUTOSAR. (2015) AUTOSAR speciﬁcation. [Online]. Available:
http://www.autosar.org
[17] P. Deng, F. Cremona, Q. Zhu, M. Di Natale, and H. Zeng, “A modelbased synthesis ﬂow for automotive CPS,” in Proceedings of the
ACM/IEEE Sixth International Conference on Cyber-Physical Systems.
ACM, 2015, pp. 198–207.
[18] R. Lublinerman and S. Tripakis, “Modular code generation from
triggered and timed block diagrams,” in Real-Time and Embedded
Technology and Applications Symposium, 2008. RTAS’08. IEEE. IEEE,
2008, pp. 147–158.
[19] Freescale Semiconductor Inc. (2015) Qorivva MPC5675K. [Online].
Available: http://www.freescale.com/
[20] Micrium
Inc.
(2015)
μC/OS-II.
[Online].
Available:
http://micrium.com/rtos/ucosii/
[21] G. R. Bulusu, “Asymmetric multiprocessing real time operating system
on multicore platforms,” Ph.D. dissertation, Arizona State University,
2014.
[22] T. Achterberg, “SCIP: solving constraint integer programs,” Mathematical Programming Computation, vol. 1, no. 1, pp. 1–41, 2009.
[23] J. Currie and D. I. Wilson, “OPTI: lowering the barrier between open
source optimizers and the industrial MATLAB user,” Foundations of
computer-aided process operations, Savannah, Georgia, USA, pp. 8–
11, 2012.

For a model of this size, both the basic MILP formulation
and the partially ordering heuristic fail in ﬁnding a solution in
10 hours. However, by merging blocks of subsystems with
depth more than 2 and with our fully ordering heuristic,
our tool returned a solution to the given problem within
an average of 1.2 hours of solver time. Here the average
is taken over different sets of worst case execution time
assignments. The suggested multi-core mapping by the tool
achieves 1.44x speed-up on average. This result is parallel with
our expectations based on experiments carried on randomly
generated DAGs and illustrates applicability of our approach
to reasonably large problems in industry.
VII.

C ONCLUSION

In this paper we presented our approach for parallelizing
a single-rate Simulink model on a multi-core architecture. We
proposed a heuristic for partially deciding execution order of
independent blocks when they are mapped to the same core.
According to the experimental results with randomly generated
DAGs and our case study with the fuel system controller, this
proposed heuristic improves optimality of found solutions in
a reasonable time for a realistic size of models with around
50 to 60 blocks in our experimental environment. For models
with larger number of blocks, we proposed another heuristic
in which the execution order of all the independent blocks is
decided in advance. With this approach our tool could handle
models with larger than 150 blocks. We also presented this
heuristic together with block merging methods on a case study
from the industry where our tool reduced 1004 blocks to 153
nodes on the dependency graph by merging blocks deeper than
a speciﬁed value and solved the problem on this 153 nodes.
The results from the case study illustrate how our approach
can handle models which can contain more than 1000 blocks.
For the future work, we consider extending this work
by introducing heuristic methods for solving the optimization problem, studying multi-rate models and models with
blocks that have priority assignments. Furthermore, we plan
to incorporate worst case execution time (WCET) tools in our
framework.
R EFERENCES
[1]

[2]
[3]

M. Huang, H. Nakada, S. Polavarapu, R. Choroszucha, K. Butts, and
I. Kolmanovsky, “Towards combining nonlinear and predictive control
of diesel engines,” in American Control Conference (ACC), 2013.
IEEE, 2013, pp. 2846–2853.
Simulink, version 8.5 (R2015a). Natick, Massachusetts: The MathWorks Inc., 2015.
“EASA/2011/6 ﬁnal report,” European Aviation Safety Agency, Tech.
Rep., 2012.

971

Mining Parametric Temporal Logic Properties
in Model Based Design for Cyber-Physical Systems
Extended Version

arXiv:1512.07956v4 [cs.LO] 24 Aug 2016

Bardh Hoxha, Adel Dokhanchi, Georgios Fainekos
Arizona State University
e-mail: {bhoxha,adokhanc,fainekos}@asu.edu
Received: date / Revised version: date

Abstract. One of the advantages of adopting a Model
Based Development (MBD) process is that it enables
testing and verification at early stages of development.
However, it is often desirable to not only verify/falsify
certain formal system specifications, but also to automatically explore the properties that the system satisfies.
In this work, we present a framework that enables property exploration for Cyber-Physical Systems. Namely,
given a parametric specification with multiple parameters, our solution can automatically infer the ranges
of parameters for which the property does not hold on
the system. In this paper, we consider parametric specifications in Metric or Signal Temporal Logic (MTL or
STL). Using robust semantics for MTL, the parameter
mining problem can be converted into a Pareto optimization problem for which we can provide an approximate
solution by utilizing stochastic optimization methods.
We include algorithms for the exploration and visualization of multi-parametric specifications. The framework is
demonstrated on an industrial size, high-fidelity engine
model as well as examples from related literature.

Key words: Metric Temporal Logic, Signal Temporal
Logic, Verification, Testing, Robustness, Multiple Parametric Specification Mining, Cyber-Physical Systems

1 Introduction
Testing, verification and validation of Cyber-Physical
Systems (CPS) is a challenging problem. Prime examples
of such systems are aircraft, cars and medical devices
which are also safety-critical systems. The complexity
in these systems arises mostly from the complex interactions between the numerous components (e.g. software enabled controllers) and the physical environment

(plant). Many accidents [1, 2] and recalls in the industry
have reinforced the need for better methodologies in this
area. In addition, general trends indicate that software
complexity in CPS is going to increase in the future [3].
A recent shift in system development, aimed to alleviate some of the challenges, is the Model Based Design
(MBD) paradigm. One of the benefits of MBD is that a
significant amount of testing and verification of the system can be conducted in various stages of model development. This is different from the traditional approach,
where most of the analysis is conducted on a prototype
of the system. Due to the importance of the problem,
there has been a substantial level of research on testing and verification of models of embedded and hybrid
systems (see [4, 5] for an overview).
In [6, 7], the authors propose an approach to support
the testing and verification process in MBD. The papers
provide a new method for testing embedded and hybrid
systems against formal requirements which are defined
in Metric Temporal Logic (MTL) [8]. MTL formulas are
interpreted over trajectories/behaviors of the system. In
this context, MTL specifications are equivalent to Signal
Temporal Logic (STL) [9] specifications. Given a system
and an MTL specification, the method searches for operating conditions such that the MTL specification is
not satisfied or, in other words, falsified. The authors
utilize the concept of system robustness of MTL specifications [10, 11] to turn the falsification problem into
an optimization problem. The notion of the robustness
metric enables system developers to measure by how far
a system behavior is from failing to satisfy a requirement. This allows for the development of an automatic
test case generator, which uses a stochastic optimization
engine to find operating conditions that falsify the system in terms of the MTL specifications. The resulting
optimization problem may be both non-linear and nonconvex. To solve the problem, in [12, 13, 6], the authors
present stochastic optimization techniques that solve the

2

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

falsification problem with very good performance in both
accuracy and number of simulations required.
In [14], the authors utilize this notion of robustness
to explore and determine system properties. In more detail, given a parameterized MTL specification [15], where
there is an unknown state and/or timing parameter, the
authors find the range of values for the parameter such
that the system is not satisfied.
In this work, we extend and generalize the work in
[14] to enable multiple parameter mining and analysis
of parametric MTL specifications. We improve the efficiency of the previous algorithm in [14] and present a
parameter mining framework for MBD. Such an exploration framework would be of great value to the practitioner. The benefits are twofold. One, it allows for the
analysis and development of specifications. In many cases,
system requirements are not well formalized by the initial system design stages. Two, it allows for the analysis and exploration of system behavior. If a specification
can be falsified, then it is natural to inquire for the range
of parameter values that cause falsification. That is, in
many cases, the system design may not be modified, but
the guarantees provided should be updated.
The extension to multiple parameter mining of MTL
specifications allows practitioners to use this method
with more complex specifications. However, as the number of parameters in the specification increases, so does
the complexity of the resulting optimization problem.
In the case of single parameter mining, the solution of
the problem is a one dimensional range. On the other
hand, with multiple parameters, finding a solution to
the problem becomes more challenging since the optimization problem is converted to a multi-objective optimization problem where the goal is to determine the
Pareto front [16]. To solve this problem, we present a
method for effective one-sided exploration of the Pareto
front and provide a visualization method for the analysis
of parameters. The algorithms presented in this work are
incorporated in the testing and verification toolbox STaLiRo [17, 18]. For an overview of the toolbox see [19].
Finally, we demonstrate our framework on a challenge
problem from the industry on an industrial scale model
and present experimental results on several benchmark
problems. Even though our examples and case study
are from the automotive domain, our results can be applied to any application domain where Model Based Design (MBD) and temporal logic requirements are utilized, e.g., medical devices [20, 21, 22, 23].
Summary of Contributions:
– We extend and generalize the parameter mining problem presented in [14].
– We provide an efficient solution to the problem of
multiple parameter mining.
– We present two algorithms to explore the Pareto front
of parametric MTL with multiple parameters.
– We illustrate our method with an industrial size case
study of a high-fidelity engine model.

– The algorithms presented in this work are publicly
available through our toolbox S-TaLiRo [18].

2 Problem Formulation
2.1 Preliminaries
In the rest of the paper, we take a general approach to
modeling real-time embedded systems that interact with
physical systems that have non-trivial dynamics. A major source of complexity in the analysis of these systems
arises from the interaction between the embedded system and the physical world.
We fix N ⊆ N, where N is the set of natural numbers,
to be a finite set of indexes for the finite representation
of a system behavior. In the following, given two sets
A and B, B A denotes the set of all functions from A
to B. That is, for any f ∈ B A we have f : A → B.
We consider a system Σ as a mapping from a compact
set of initial operating conditions X0 and input signals
U ⊆ U N to output signals Y N and timing (or sampling)
functions T ⊆ RN
+ . Here, U is a compact set of possible
input values at each point in time (input space), Y is
the set of output values (output space), R is the set of
real numbers and R+ the set of positive reals.
We impose three assumptions/restrictions on the systems that we consider:
1. The input signals (if any) must be parameterizable
using a finite number of parameters. That is, there
exists a function U such that for any u ∈ U, there
exist two parameter vectors λ = [λ1 . . . λm ]| ∈ Λ,
where Λ is a compact set, and t = [t1 . . . tm ]| ∈
Rm
+ such that m is typically much smaller than the
maximum number of indices in N and for all i ∈ N ,
u(i) = U(λ, t)(i).
2. The output space Y must be equipped with a generalized metric d which contains a subspace Z equipped
with a metric d [7].
3. For a specific initial condition x0 and input signal
u, there must exist a unique output signal y defined
over the time domain R. That is, the system Σ is
deterministic.
Further details on the necessity and implications of the
aforementioned assumptions can be found in [7]. Assumption 3 can also be relaxed as shown in [24].
Under Assumption 3, a system Σ can be viewed as
a function ∆Σ : X0 × U → Y N × T which takes as an
input an initial condition x0 ∈ X0 and an input signal
u ∈ U and it produces as output a signal y : N → Y
(also referred to as trajectory) and a timing function
τ : N → R+ . The only restriction on the timing function τ is that it must be a monotonic function, i.e.,
τ (i) < τ (j) for i < j. The pair µ = (y, τ ) is usually
referred to as a timed state sequence, which is a widely

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

3

Throttle
100

1.5

50

1

0

0

5

10

15
RPM

20

25

0.5

30

0
x2

5000

0

-0.5
-1

0

5

10

15
Speed

20

25

30

-1.5

200

-2
100

-2.5
0

0

5

10

15

20

25

30

-1.5

-1

-0.5

0

0.5

1

1.5

2

2.5

3

3.5

x1

Fig. 1. Left: Example 1 (AT): Throttle: A piecewise constant input signal u parameterized with Λ ∈ [0, 100]6 and t = [0, 5, 10, 15, 20, 25].
RPM, Speed: The corresponding output signals that falsify the specification “The vehicle speed v is always under 120km/h or the engine
speed ω is always below 4500RPM.” Right: Example 2 (HS): Simulated trajectories of the hybrid system containing a trajectory that
falsifies the specification “A trajectory should never pass set [−1.6, −1.4]2 or set [3.4, 3.6] × [−1.6, −1.4]”. The green square indicates
the set of possible initial conditions and the red squares indicate the bad regions which the system should not enter. The yellow region
indicates the set of initial conditions where the location on the hybrid system changes.

accepted model for reasoning about real time systems
[25]. A timed state sequence can represent a computer
simulated trajectory of a CPS or the sampling process
that takes place when we digitally monitor physical systems. We remark that a timed state sequence can represent both the internal state of the software/hardware
(usually through an abstraction) and the state of the
physical system. The set of all timed state sequences of
a system Σ will be denoted by L(Σ). That is,
L(Σ) = {(y, τ ) | ∃x0 ∈ X0 . ∃u ∈ U . (y, τ ) = ∆Σ (x0 , u)}.
Our high-level goal is to explore and infer properties
that the system Σ satisfies. We do so by observing the
system response (output signals) to particular input signals and initial conditions. We assume that the system
designer has partial understanding about the properties
that the system satisfies (or does not satisfy) and would
like to be able to precisely determine these properties. In
particular, we assume that the system developer can formalize the system properties in Metric Temporal Logic
(MTL) [8], where some parameters are unknown. Such
parameters could be unknown threshold values for the
continuous state variables of the hybrid system or some
unknown real time constraints.
MTL enables the formalization of complex requirements with respect to both state and time. In addition
to propositional logic operators such as conjunction (∧),
disjunction(∨) and negation(¬), MTL supports temporal operators such as next(X), until (U), release (R), always (2) and eventually (3). Among others, MTL can
be utilized to express specifications such as:
– Safety (2φ) : φ should always hold from this moment
on.
– Liveness (3φ): φ should hold at some point in the
future (or now).

– Coverage (3φ1 ∧3φ2 ...∧3φn ): φ1 through φn should
hold at some point in the future (or now), not necessarily in order or at the same time.
– Stabilization (32φ): At some point in the future (or
now), φ should always hold.
– Recurrence (23φ) : At every point time, φ should
hold at some point in the future (or now).
Another popular formalism for the definition of formal requirements is Signal Temporal Logic (STL) [9].
Since MTL formulas are interpreted over behaviors of
the CPS, the results provided in this paper can be directly applied over STL formulas as well. To enable of
elicitation of formal requirements for CPS, tools such as
ViSpec [26] may be utilized.
Throughout the paper, we will consider two running
examples. The first example consists of an automatic
transmission model, and the second, consists of a hybrid
non-linear time varying system.
Example 1 (AT) We consider a slightly modified version of the Automatic Transmission model provided by
Mathworks as a Simulink demo1 . Further details on this
example can be found in [27, 7]. The only input u to the
system is the throttle schedule, while the brake schedule is
set simply to 0 for the duration of the simulation which is
T = 30 sec. The physical system has two continuous-time
state variables which are also its outputs: the speed of
the engine ω (RPM) and the speed of the vehicle v, i.e.,
Y = R2 and y(t) = [ω(t) v(t)]| for all t ∈ [0, 30]. Initially, the vehicle is at rest at time 0, i.e., X0 = {[0 0]| }
and x0 = y(0) = [0 0]| . Therefore, the output trajectories depend only on the input signal u which models the
throttle, i.e., (y, τ ) = ∆Σ (u). The throttle at each point
1 Available
at: http://www.mathworks.com/help/simulink/
examples/modeling-an-automatic-transmission-controller.
html

4

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS
x0 ∈ [−1, 1]2 \X U

S0
x˙1 =
x˙2 =

x1 (t) − x2 (t) + 0.1t
−x1 (t) sin(2πx1 (t))+
x2 cos(2πx2 (t)) + 0.1t

x ∈ XU

inputs:

x0 ∈ X U

S1

output signal y

System
Simulator

x˙1 = x1 (t)
x˙2 = −x1 (t) + x2 (t)

Fig. 2. Example 2: Hybid non-linear system with X U
[0.85, 0.95]2 and initial condition x0 ∈ [−1, 1] × [−1, 1].

PMTL
Specification

System Σ

=

in time can take any value between 0 (fully closed) to 100
(fully open). Namely, u(i) ∈ U = [0, 100] for each i ∈ N .
The model also contains a Stateflow chart with two concurrently executing Finite State Machines (FSM) with 4
and 3 states, respectively. The FSM models the logic that
controls the switching between the gears in the transmission system. We remark that the system is deterministic,
i.e., under the same input u, we will observe the same
output y. In our previous work [7, 17, 12], on such models, we demonstrated how to falsify requirements like:
“The vehicle speed v is always under 120km/h or the
engine speed ω is always below 4500RPM.” A falsifying
system trajectory appears in Fig. 1. A falsifying system
trajectory appears in Fig. 1 (Left).
Example 2 (HS) We consider the hybid time-varying
non-linear system presented in Fig. 2. The output of the
system is the state of the system, i.e. y(t) = x(t). Interesting requirements on this system would be “A trajectory of the system should never pass through the sets
[−1.6, −1.4]2 or [3.4, 3.6] × [−1.6, −1.4]”. A falsifying
system trajectory appears in Fig. 1 (Right).
N
2.2 Parameter Mining
In this work, we provide answers to queries like “What
is the shortest time that ω can exceed 3250 RPM” or
“For how long can ω be below 4500 RPM”. We can also
answer queries about the relationships between parameters with regard to system falsification. For example, for
the specification “Always the vehicle speed v and engine
speed ω need to be less than parameters θ1 , θ2 , respectively” we could ask “If I increase/decrease θ1 by a specific amount, how much do I have to increase/decrease
θ2 so that I satisfy the specification?”.
Formally, we extend and generalize the problem of
single parameter mining presented in [14]. There the
problem is defined as follows.
Problem 1 (MTL 1-Parameter Mining) Given an
MTL formula φ[θ] with a single unknown parameter θ ∈
Θ = [θm , θM ] and a system Σ, find an optimal range
∗
∗
Θ∗ = [θm
, θM
] such that for any ζ ∈ Θ∗ , φ[ζ] does not
hold on Σ, i.e., Σ 6|= φ[ζ].
The extension in the present work is in regards to
the number of parameters that can appear in the specification. Formally, it is defined as follows:

initial
conditions x0 &
input signal u

est.
parameters

Stochastic
Optimization

Temporal Logic
Robustness

robustness ε

Cost
Function

PMTL
Monotonicity

output: parameter
falsification domain Ψ

Fig. 3. Overview of the solution to Problem 2, the PMTL parameter mining problem for CPS.

Problem 2 (MTL m-Parameter Mining) Given an
MTL formula φ[θ] with a vector of m unknown parameters θ ∈ Θ = [θ, θ] and a system Σ, find the set Ψ =
{θ ∗ ∈ Θ | Σ 6|= φ[θ ∗ ]}.
That is, the solution to Problem 2 is the set Ψ such
that for any parameter θ ∗ in Ψ the specification φ[θ ∗ ]
does not hold on system Σ. In the rest of the paper,
we refer to Ψ as the parameter falsification domain. An
approximate solution for Problem 1 was presented in
[14] for the case where θ is a scalar. In [14], the solution
to the problem returned a parameter with which the
falsifying set can be inferred since the parameter range is
one dimensional. Here, we provide a solution to Problem
2. In the multiple parameter setting, we have a set of
possible solutions which we need to explore. That is, the
solution to the multi-parameter mining problem is in the
form of a Pareto front [16].
We note that the original observation that the falsification domain problem over a single system output trace
has the structure of a Pareto front is made in [15]. In this
work, we observe that the falsification domain problem
over all system output traces also has the structure of a
Pareto front. Other methods for Pareto front computation have been studied in [28, 29]. However, the nature
of the problem is significantly different in our case. Here,
due to the undecidability of the problem [30], we can only
guarantee that a parameter falsifies the specification. It
is not the case that we can guarantee that a parameter
value satisfies the specification. Therefore, the parameter falsification domain is generated strictly by utilizing
falsifying behavior.
Ideally, by solving Problem 2, we would also like to
have the property that for any ζ ∈ Θ − Ψ , φ[ζ] holds
on Σ, i.e., Σ |= φ[ζ]. However, even for a given ζ, the
problem of algorithmically computing whether Σ |= φ[ζ]
is undecidable for the classes of systems that we consider
in this work [30].
An overview of our proposed solution to Problem 2
appears in Fig. 3. Given a model and a MTL specifica-

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

tion with one or more parameters, the sampler produces
a point x0 from the set of initial conditions, input signal
u and vector of mined parameters θ for the Parametric
MTL specification. The initial conditions and input signal are passed to the system simulator which returns an
execution trace (output trajectory and timing function).
The trace, in conjunction with the mined parameters, is
then analyzed by the MTL robustness analyzer which returns a robustness value. The robustness score computed
is used by the stochastic sampler to decide on next initial
conditions, inputs, and estimated parameters to utilize.
The process terminates after a maximum number of tests
or when no improvement on the mined parameters has
been made after a number of tests. As the number of
parameters increases, so does the computational complexity of the problem. For formulas with more than one
parameter, we present an efficient approach in Section 6
to explore the parameter falsification domain.
3 Robustness of Metric Temporal Logic
Formulas
Metric Temporal Logic [8] enables reasoning over quantitative temporal properties of boolean signals. In the
following, we present MTL in Negation Normal Form
(NNF) since this is needed for the presentation of the
new results in Section 5. We denote the extended real
number line by R = R ∪ {±∞}.
Definition 1 (Syntax of MTL in NNF) Let R be the
set of truth degree constants, AP be the set of atomic
propositions and I be a non-empty non-singular interval
of R≥0 . The set M T L of all well-formed formulas (wff )
is inductively defined using the following rules:
– Terms: True (>), false (⊥), all constants r ∈ R and
atomic propositions p, ¬p for p ∈ AP are terms.
– Formulas: if φ1 and φ2 are terms or formulas, then
φ1 ∨ φ2 , φ1 ∧ φ2 , φ1 UI φ2 and φ1 RI φ2 are formulas.
The atomic propositions in our case label subsets of
the output space Y . Each atomic proposition is a shorthand for an arithmetic expression of the form p ≡ g(y) ≤
c, where g : Y → R and c ∈ R. We define an observation
map O : AP → P(Y ) such that for each p ∈ AP the
corresponding set is O(p) = {y | g(y) ≤ c} ⊆ Y .
In the above definition, UI is the timed until operator and RI the timed release operator. The subscript
I imposes timing constraints on the temporal operators.
The interval I can be open, half-open or closed, bounded
or unbounded, but it must be non-empty (I 6= ∅) (and,
practically speaking, non-singular (I =
6 {t})). In the case
where I = [0, +∞), we remove the subscript I from the
temporal operators, i.e., we just write U and R. Also,
we can define eventually (3I φ ≡ > UI φ) and always
(2I φ ≡ ⊥RI φ).
Before proceeding to the actual definition of the robust semantics, we introduce some auxiliary notation. A

5

metric space is a pair (X, d) such that the topology of
the set X is induced by a metric d. Using a metric d,
we can define the distance of a point x ∈ X from a set
S ⊆ X. Intuitively, this distance is the shortest distance
from x to all the points in S. In a similar way, the depth
of a point x in a set S is defined to be the shortest distance of x from the boundary of S. Both the notions of
distance and depth play a fundamental role in the definition of the robustness degree. The metrics and distances
utilized in this work are covered in more detail in [11, 7].
Definition 2 (Signed Distance) Let x ∈ X be a point,
S ⊆ X be a set and d be a metric on X. Then, we define
the Signed Distance from x to S to be

−distd (x, S) := − inf{d(x, y) | y ∈ S}



if x 6∈ S
Distd (x, S) :=
depth
(x,
S)
:= distd (x, X\S)

d


if x ∈ S
We utilize the extended definition of the supremum and
infimum, i.e., sup ∅ := −∞ and inf ∅ := +∞.
We define the binary relation  on parameter vectors
θ, θ 0 such that θ  θ 0 ⇐⇒ ∀i, θi ≤ θi0 , where i is the ith
entry of the vector. MTL formulas are interpreted over
timed state sequences µ. In the past [10, 11], we proposed
multi-valued semantics for the MTL where the valuation
function on the predicates takes values over the totally
ordered set R according to a metric d operating on the
output space Y . We let the valuation function be the
depth (or the distance) of the current point of the signal
y(i) in a set O(p) labeled by the atomic proposition p.
Intuitively, this distance represents how robust is the
point y(i) within set O(p). While positive values indicate
satisfaction, negative values indicate that the trajectory
falsifies the MTL specification. If this metric is zero, then
even the smallest perturbation of the point can drive
it inside or outside the set O(p), dramatically affecting
membership.This is called a robustness estimate and is
formally defined in Definition 3.
For the purposes of the following discussion, we use
the notation [[φ]] to denote the robustness estimate with
which the timed state sequence µ satisfies the specification φ. Formally, the valuation function for a given
formula φ is [[φ]] : Y N × T × N → R. In the definition
below, we also use the following notation : for Q ⊆ R,
the preimage of Q under τ is defined as : τ −1 (Q) := {i ∈
N | τ (i) ∈ Q}.
Definition 3 (Robustness Estimate [11]) Let µ =
(y, τ ) ∈ L(Σ), r ∈ R and i, j, k ∈ N , then the robustness estimate of any formula MTL φ with respect to µ
is recursively defined as follows
[[>]](µ, i) := +∞

[[⊥]](µ, i) := −∞

6

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

3.5

20

3

10

2.5

0

2
Robustenss

Robustness

30

-10
-20

1.5
1
0.5

-30
-40

0

-50

-0.5

60
-60
50

40
40

30

20

20
10

0

0
u1

u2

-1
1

1
0.5

0

0

-0.5

-1

-1

x2

x1

Fig. 4. Robustness estimate landscape for system specifications. Left: Example 1 (AT): φAT = ¬(3[0,30] (v > 100) ∧ 2(ω ≤ 4500)) ∧
¬3[10,40] 2[0,5] (60 < v ≤ 80) ∧ ¬3[50,60] 2[0,3] (v ≤ 60). The input signal to the system is generated by linearly interpolating control
t
points u1 , u2 at time 0 and 60, respectively, for the throttle input u. That is, u(t) = 60−t
u1 + 60
u2 .; Right: Example 2 (HS):
60
φHS = 2[0,2] ¬a ∧ 2[0,2] ¬b, where O(a) = [−1.6, −1.4]2 and O(b) = [3.4, 3.6] × [−1.6, −1.4]. Here x1 and x2 are initial conditions for the
hybrid system.

[[p]](µ, i) := Distd (y(i), O(p))

Definition 4 (Syntax of Parametric MTL) Let θ be
a vector of parameters. The set of all well formed Parametric MTL (PMTL) formulas is the set of all well formed
MTL formulas where for all i, θi either appears in an
arithmetic expression, i.e., p[θi ] ≡ g(y) ≤ θi , or in the
timing constraint of a temporal operator, i.e., I[θi ].

[[¬p]](µ, i) := −Distd (y(i), O(p))
[[φ1 ∨ φ2 ]](µ, i) := max([[φ1 ]](µ, i), [[φ2 ]](µ, i))
[[φ1 ∧ φ2 ]](µ, i) := min([[φ1 ]](µ, i), [[φ2 ]](µ, i))
[[φ1 UI φ2 ]](µ, i) :=
sup
j∈τ −1 (τ (i)+I)

min([[φ2 ]](µ, j), inf [[φ1 ]](µ, k))



i≤k<j

[[φ1 RI φ2 ]](µ, i) :=
j∈τ

inf
−1

(τ (i)+I)


max([[φ2 ]](µ, j), sup [[φ1 ]](µ, k))
i≤k<j

Recall that we use the extended definition of supremum
and infimum. When i = 0, then we write [[φ]](µ).
The robustness of an MTL formula with respect to
a timed state sequence can be computed using several
existing algorithms [11, 31, 32].
If we consider the robustness estimate over systems,
the resulting robustness landscape can be both non-linear
and non-convex. In Fig. 4 we present the robustness
landscape for the two running examples, namely Examples 1 (AT) and 2 (HS), on two specifications.
4 Parametric Metric Temporal Logic over
Signals
In many cases, it is important to be able to describe an
MTL specification with unknown parameters and then,
infer the parameters that make the specification false.
In [15], Asarin et al. introduced Parametric Signal Temporal Logic (PSTL) and presented two algorithms for
computing approximations for parameters over a given
signal. Here, we review some of the results in [15] while
adapting them in the notation and formalism that we
use in this paper.

We will denote a PMTL formula φ with parameters
θ by φ[θ]. Given a vector of parameters θ ∈ Θ, then the
formula φ[θ] is an MTL formula. There is an implicit
mapping from the vector of parameters θ to the corresponding arithmetic expressions and temporal operators
in the MTL formula.
Since the valuation function of an MTL formula is
a composition of minimum and maximum operations
quantified over time intervals, a formula φ[θ], when θ
is a scalar, is always monotonic with respect to θ under certain conditions. Similarly, when θ is a vector,
then the valuation function is monotonic with respect
to a priority function f (θ). In general, determining the
monotonicity of PMTL formulas is undecidable [33]. The
priority function will enable the system engineer to prioritize the optimization of some parameters over others
by defining specific weights, or setting an optimization
strategy such as optimizing the minimum, maximum, or
norm of all parameters. The priority function will be
defined in detail in the next section.
In the following, we present monotonicity results for
single and multiple parameter PMTL formulas. We note
that the monotonicity results apply to a subset of PMTL.

4.1 Single parameter PMTL formulas
The first example presented shows how monotonicity appears in the timing requirements of PMTL formulas.

3500

3000

3000

2000
Robustenss

ω(t)

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

2500
2000

1000
0

1500
1000
0

7

5

10

15
t

20

25

30

−1000

0

5

10

15
θ

20

25

30

Fig. 5. Example 3. Left: Engine speed ω(t) for constant throttle u(t) = 50. Right: The robustness estimate of the specification 2[0,θ] (ω ≤
3250) with respect to θ.

Example 3 (AT) Consider the PMTL formula φ[θ] =
2[0,θ] p where p ≡ (ω ≤ 3250). Given a timed state sequence µ = (y, τ ) with τ (0) = 0, for θ1 ≤ θ2 , we have:

the monotonicity of the max and min operators. We remark that the max and min operators preserve monotonicity. Let θ1 ≤ θ2 , then we want to show that:

[0, θ1 ] ⊆ [0, θ2 ] =⇒ τ −1 ([0, θ1 ]) ⊆ τ −1 ([0, θ2 ]).

[[φ1 Uhα,θ1 i φ2 ]](µ, i) ≤ [[φ1 Uhα,θ2 i φ2 ]](µ, i)

Therefore, by Definitions (2) and (3) we have
[[φ[θ1 ]]](µ) =
≥

inf

i∈τ −1 ([0,θ2 ])

inf

To show that (1) holds, we utilize the robust semantics for MTL given in Definition 3 and observe that:

(−Distd (y(i), O(p)))

[[φ1 Uhα,θ2 i φ2 ]](µ, i) =

i∈τ −1 ([0,θ1 ])

(−Distd (y(i), O(p))) = [[φ[θ2 ]]](µ).

That is, the function [[φ[θ]]](µ) is non-increasing with θ.
Intuitively, this relationship holds since by extending the
value of θ in φ[θ], it becomes just as or more difficult to
satisfy the specification. See Fig. 5 for an example using
an output trajectory from the system in Example 1. N
The aforementioned example is formalized by the following monotonicity results.
Lemma 1 (Extended from [14]) Consider a PMTL
formula φ[θ] such that it contains one or more subformulas φ1 OpI[θ] φ2 where Op ∈ {U, R}. Then, given a
timed state sequence µ = (y, τ ), for θ1 , θ2 ∈ R≥0 , such
that θ1 ≤ θ2 , and for i ∈ N , we have:
1. if for all such subformulas, we have (i) Op = U and
sup I(θ) = θ or (ii) Op = R and inf I(θ) = θ,
then [[φ[θ1 ]]](µ, i) ≤ [[φ[θ2 ]]](µ, i), i.e., the function
[[φ[θ]]](µ, i) is non-decreasing with respect to θ.
2. if for all such subformulas, we have (i) Op = R and
sup I(θ) = θ or (ii) Op = U and inf I(θ) = θ,
then [[φ[θ1 ]]](µ, i) ≥ [[φ[θ2 ]]](µ, i), i.e., the function
[[φ[θ]]](µ, i) is non-increasing with respect to θ.

Proof (sketch). Without loss of generality, we will prove
only case (i) of Lemma 1.1. Case (ii) is symmetric with
respect to the temporal operator and Lemma 1.2 is symmetric in terms of monotonicity. The proof is by induction on the structure of the formula and it is similar to
the proofs that appeared in [11].
For completeness of the presentation, we consider the
case [[φ1 Uhα,θi φ2 ]](µ, i), where h∈ {[, (} and i ∈ {], )}.
The other cases are either similar or they are based on

(1)


min([[φ2 ]](µ, j), inf [[φ1 ]](µ, k)) =

sup

i≤k<j

j∈τ −1 (τ (i)+hα,θ2 i)

max


min([[φ2 ]](µ, j), inf [[φ1 ]](µ, k)) ,

sup

i≤k<j

j∈τ −1 (τ (i)+hα,θ1 i)

!
sup
j∈τ −1 (τ (i)+hθ1 ,θ2 i)

min([[φ2 ]](µ, j), inf [[φ1 ]](µ, k))



i≤k<j

=



max [[φ1 Uhα,θ1 i φ2 ]](µ, i), [[φ1 Uhθ1 ,θ2 i φ2 ]](µ, i) ≥
[[φ1 Uhα,θ1 i φ2 ]](µ, i)
where h ∈ {[, (} such that hα, θ1 i ∩ hθ1 , θ2 i = ∅ and
hα, θ1 i ∪ hθ1 , θ2 i = hα, θ2 i.
t
u
Note that Lemma 1 allows for the repetition of a parameter in a PMTL formula. For example, consider the
specification φ = 2[θ,5] a ∧ 3[0,θ] b ≡ ⊥R[θ,5] a ∧ >U[0,θ] b.
In this case, φ satisfies the conditions in Lemma 1. Thus,
from Lemma 1 we know that for two values θ1 and θ2
where θ1 ≤ θ2 :
[[2[θ1 ,5] a ∧ 3[0,θ1 ] b]](µ, i) ≤ [[2[θ2 ,5] a ∧ 3[0,θ2 ] b]](µ, i)
In the following, we derive similar results for the case
where the parameter appears in the numerical expression
of the atomic proposition.
Lemma 2 (Extended from [14]) Consider a PMTL
formula φ[θ] with a single parameter θ such that it contains parametric atomic propositions p1 [θ]...pn [θ] in one
or more subformulas. Then, given a timed state sequence
µ = (y, τ ), for θ1 , θ2 ∈ R≥0 , such that θ1 ≤ θ2 , and for
i ∈ N , we have:
– if ∀j.pj [θ] ≡ gj (x) ≤ θ, then [[φ[θ1 ]]](µ, i) ≤ [[φ[θ2 ]]](µ, i),
i.e., the function [[φ[θ]]](µ, i) is non-decreasing with
respect to θ, and

8

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS
500

4000
0
−500
Robustness Value

Robustness Value

3000

2000

1000

−1000
−1500
−2000
−2500
−3000

0

(28s, 3360rpm)

(101mph, 3350rpm)

−3500
−4000
200

−1000
60
40
20
Timing Parameter

0

0

7000
5000 6000
3000 4000
1000 2000
Engine Speed Parameter

100
Vehicle Speed Parameter 0

0

1000

2000

3000

4000

5000

6000

7000

Engine Speed Parameter

Fig. 6. Left: Example 4: Robustness estimate landscape for varying parameters for engine and vehicle speed for constant throttle
u(t) = 50. Right: Example 5: Robustness landscape for varying parameters for timing parameter and engine speed for constant throttle
u(t) = 50. In both figures, the contour line shows the intersection of the robustness landscape with the zero level set.

– if ∀j.pj [θ] ≡ gj (x) ≥ θ, then [[φ[θ1 ]]](µ, i) ≥ [[φ[θ2 ]]](µ, i), Example 5 (AT) Consider the PMTL formula φ[θ] =
i.e., the function [[φ[θ]]](µ, i) is non-increasing with
(p[θ1 ] ∧q[θ2 ]) where p[θ1 ] ≡ (v ≤ θ1 ) and q[θ2 ] ≡ (ω ≤
respect to θ.
θ2 ). Given a timed state sequence µ = (y, τ ) with τ (0) =
0, for two vectors of parameters θ, θ 0 where θ  θ 0 , we
Proof (sketch). The proof is by induction on the struchave:
O(p[θ1 ]) ⊆ O(p[θ10 ]) =⇒
ture of the formula and it is similar to the proofs that
appeared in [11]. For completeness of the presentation,
Distd (O(p[θ1 ])) ≤ Distd (O(p[θ10 ])) =⇒
we consider the base case [[p[θ]]](µ, i). Let θ1 ≤ θ2 , then
[[p[θ1 ]]](µ, i) ≤ [[p[θ10 ]]](µ, i)
O(p[θ1 ]) ⊆ O(p[θ2 ]). We will only present the case for
and
which y(i) 6∈ O(p[θ2 ]). We have:
O(q[θ2 ]) ⊆ O(q[θ20 ]) =⇒
O(pj [θ1 ]) ⊆ O(pj [θ2 ]) =⇒
Distd (O(p[θ2 ])) ≤ Distd (O(p[θ20 ])) =⇒
distd (y(i), O(pj [θ1 ])) ≥ distd (y(i), O(pj [θ2 ])) =⇒
[[q[θ2 ]]](µ, i) ≤ [[q[θ20 ]]](µ, i)
Distd (y(i), O(pj [θ1 ])) ≤ Distd (y(i), O(pj [θ2 ])) =⇒
Therefore, [[φ[θ]]](µ) ≤ [[φ[θ 0 ]]](µ). That is, the function
[[pj [θ1 ]]](µ, i) ≤ [[pj [θ2 ]]](µ, i)
t
u
[[φ[θ]]](µ) is non-decreasing for all θ for which the rela4.2 Multiple parameter PMTL formulas
tion  holds. Figure 6 presents the robustness landscape
of two parameters over constant input.
N
Next, we extend the result for multiple parameters.
Now we may state the main monotonicity theorem
Example 4 (AT) Consider the PMTL formula φ[θ] =
for multiple parameters. We remark that for convenience
¬(3[0,θ1 ] q ∧ 2p[θ2 ]) where θ = [θ1 , θ2 ]| , p[θ2 ] ≡ (ω ≤
we define the parametric subformulas over all the possiθ2 ) and q ≡ (v ≥ 100). Given a timed state sequence
ble parameters even though only some of them are used
µ = (y, τ ) with τ (0) = 0, for two vectors of parameters
in each subformula.
θ, θ 0 ∈ R2 where θ  θ 0 , we have: for all i,
Theorem 1. Consider a PMTL formula ψ[θ], where θ
θ2 ≤ θ20 =⇒ O(p[θ2 ]) ⊆ O(p[θ20 ]) =⇒
is a vector of parameters, such that ψ[θ] contains tempoDistd (y(i), O(p[θ2 ])) ≤ Distd (y(i), O(p[θ20 ])) =⇒
ral subformulas φ[θ] = φ1 [θ]OpI[θs ] φ2 [θ], Op ∈ {U, R},
or propositional subformulas φ[θ] = p[θ]. Then, given a
−Distd (y(i), O(p[θ2 ])) ≥ −Distd (y(i), O(p[θ20 ])) (2)
n
timed state sequence µ = (y, τ ), for θ, θ 0 ∈ R≥0 , such
that θ  θ 0 , where 1 ≤ j ≤ n, and for i ∈ N , we have:
θ1 ≤ θ10 =⇒ [0, θ1 ] ⊆ [0, θ10 ] =⇒
τ −1 ([0, θ1 ]) ⊆ τ −1 ([0, θ10 ])

(3)

Therefore, by (2) and (3) we obtain:
[[φ[θ]]](µ) =

inf

(2)

≥

inf

i∈τ −1 ([0,θ1 ])

(3)

≥

inf

(−Distd (y(i), O(p[θ2 ])))

i∈τ −1 ([0,θ1 ])

i∈τ −1 ([0,θ10 ])

(−Distd (y(i), O(p[θ20 ])))

(−Distd (y(i), O(p[θ20 ]))) = [[φ[θ 0 ]]](µ)

That is, the function [[φ[θ]]](µ) is non-increasing for all
θ for which the relation  holds.
N

– if for all such subformulas (i) Op = U and sup I(θs ) =
θs or (ii) Op = R and inf I(θs ) = θs or (iii) p[θ] ≡
g(x) ≤ θ, then [[φ[θ]]](µ, i) ≤ [[φ[θ 0 ]]](µ, i), i.e., function [[φ[θ]]](µ, i) is non-decreasing with respect to θ,
– if for all such subformulas (i) Op = R and sup I(θs ) =
θs or (ii) Op = U and inf I(θs ) = θs or (iii) p[θ] ≡
g(x) ≥ θ, then [[φ[θ]]](µ, i) ≥ [[φ[θ 0 ]]](µ, i), i.e., function [[φ[θ]]](µ, i) is non-increasing with respect to θ.
Proof (sketch). The proof is by induction on the structure of the formula. The base case is given by Lemmas
1 and 2.

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

min([[φ2 [θ]]](µ, j)) ≤ min([[φ2 [θ 0 ]]](µ, j))
For all k, by the induction hypothesis we have:


inf ([[φ1 [θ]]](µ, k)) ≤ inf ([[φ1 [θ 0 ]]](µ, k))
i≤k<j

i≤k<j

(4)

4000
3000
Robustenss

Consider the first case where φ[θ] = φ1 [θ] UI[θs ] φ2 [θ].
n
Let θ, θ 0 ∈ R≥0 , where θ  θ 0 . Let i, j, k ∈ N . Then
I[θs ] ⊆ I[θs0 ] and, for all j, by the induction hypothesis
we have

2000
1000
0
−1000
0

(5)

20

0
40

10

60

80

20
100

30

u

[[φ[θ]]](µ, i) = [[φ1 [θ] UI[θs ] φ2 [θ]]](µ, i) =

min([[φ2 [θ]]](µ, j), inf [[φ1 [θ]]](µ, k))
i≤k<j

j∈τ −1 (τ (i)+I[θs ])

≤
sup
j∈τ −1 (τ (i)+I[θs0 ])




min([[φ2 [θ 0 ]]](µ, j), inf [[φ1 [θ 0 ]]](µ, k)) =
i≤k<j

[[φ1 [θ 0 ] UI[θs0 ] φ2 [θ 0 ]]](µ, i) = [[φ[θ 0 ]]](µ, i)

[[φ[θ]]](Σ) ≤ 0. The approximate value of θ∗ is an estimate based on the granularity of the grid that we used to
plot the surface.
N
In summary, in order to solve Problem 2, we would
have to solve the following optimization problem:
optimize

Therefore,
[[φ[θ]]](µ, i) ≤ [[φ[θ 0 ]]](µ, i)

2.8
θ

Fig. 7. Example 6: Specification robustness estimate as a function
of parameter θ and input u for specification φ[θ] = 2[0,θ] (ω ≤
4500).

Then by (4) and (5) we have

sup

9

subject to
t
u

In this section, we have presented several cases where
we can syntactically determine the monotonicity of the
PMTL formula with respect to its parameters. However,
we remark that in general, determining the monotonicity
of PMTL formulas is undecidable [33].
5 Temporal Logic Parameter Bound
Computation
The notion of robustness of temporal logics will enable
us to pose the parameter mining problem as an optimization problem. In order to solve the resulting optimization
problem, falsification methods and S-TaLiRo [18] can
be utilized to estimate the solution for Problem 2.
As described in the previous section, the parametric
robustness functions that we are considering are monotonic with respect to the search parameters. Therefore,
if we are searching for a parameter vector over an interval Θ = [θ, θ], where Θ is a hypercube and θ =
[θ1 , θ2 , ..., θn ]| and θ = [θ1 , θ2 , ..., θn ]| , we are either trying to minimize or maximize a function f of θ such that
for all θ ∈ Θ∗ , we have [[φ[θ]]](Σ) ≤ 0.
Example 6 (AT) Let us consider again the automotive
transmission example and the specification φ[θ] = 2[0,θ] p
where p ≡ (ω ≤ 4500). The specification robustness
[[φ[θ]]](∆Σ (u)) as a function of θ and the input u appears in Fig. 7 for constant input signals. The creation
of the graph required 100 × 30 = 3, 000 simulations. The
contour under the surface indicates the zero level set of
the robustness surface, i.e., the θ and u values for which
we get [[φ[θ]]](∆Σ (u)) = 0. From the graph, we can infer that θ∗ ≈ 2.8 and that for any θ ∈ [2.8, 30], we have

f (θ)

(6)

θ ∈ Θ and
[[φ[θ]]](Σ) =

min [[φ[θ]]](µ) ≤ 0
µ∈Lτ (Σ)

Where f : Rn → R is a either a non-increasing (≥) or
a non-decreasing (≤) function. For two vector parameter
values θ, θ 0 , if θ  θ 0 and θ ≥ 0 then f (θ) ./ f (θ 0 ),
where ./ ∈ {≥, ≤} depending on the monotonicity.
The function [[φ[θ]]](Σ) can not be computed using
reachability analysis algorithms nor is known in closed
form for the systems we are considering. Therefore, we
will have to compute an under-approximation of Θ∗ . Our
focus will be to formulate an optimization problem that
can be solved using stochastic search methods. In particular, we will reformulate the optimization problem (6)
into a new one where the constraints due to the specification are incorporated into the cost function:



 γ ± [[φ[θ]]](Σ)
if [[φ[θ]]](Σ) ≥ 0  (7)
optimizeθ∈Θ f (θ) +

0 otherwise
where the sign (±) and the parameter γ depend on
whether the problem is a maximization or a minimization problem. The parameter γ must be properly chosen
so that the solution of problem (7) is in Θ if and only
if [[φ[θ]]](Σ) ≤ 0. Therefore, if the problem in Eq. (6) is
feasible, then the optimal points of equations (6) and (7)
are the same.
5.1 Non-increasing Robustness Functions
In the case of non-increasing robustness functions [[φ[θ]]](Σ)
with respect to the search vector variable θ, the optimization problem is a minimization problem. Without
loss of generality, let us consider the case for single parameter specifications. Assume that [[φ[θ]]](Σ) ≤ 0. Since

10

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS


𝜃2 𝜃2
𝜃′

𝜃
𝜃′

𝜃

𝜃∗ 𝜃∗
𝜃 𝜃
𝜃 𝜃



𝜃2

𝜃



𝜃′
𝜃



𝜃∗



𝜃
𝜃1 𝜃1



𝜃1





Fig. 8. Illustration of the arrangement of parameters for nonincreasing (Left) and non-decreasing (Right) robustness functions for a two parameter specification. The green (red) region
represents parameter valuations for which we have a positive (negative) robustness value over all system behaviors.

θ ≤ θ, we have [[φ[θ]]](Σ) ≥ [[φ[θ]]](Σ), we need to find the
minimum θ such that we still have [[φ[θ]]](Σ) ≤ 0. That
θ value will be the desired θ∗ since for all θ0 ∈ [θ∗ , θ], we
will have [[φ[θ0 ]]](Σ) ≤ 0.
We will reformulate the problem of Eq. (7) so that we
do not have to solve two separate optimization problems.
From (7), we have:



 γ + minµ∈Lτ (Σ) [[φ[θ]]](µ)
if minµ∈Lτ (Σ) [[φ[θ]]](µ) ≥ 0  =
min f (θ) +

θ∈Θ
0 otherwise



 γ + [[φ[θ]]](µ)
if [[φ[θ]]](µ) ≥ 0  =
= min f (θ) + min
θ∈Θ
µ∈Lτ (Σ) 
0 otherwise



 γ + [[φ[θ]]](µ)
if [[φ[θ]]](µ) ≥ 0  (8)
= min min f (θ) +

θ∈Θ µ∈Lτ (Σ)
0 otherwise
The previous discussion is formalized as follows.
Proposition 1 Let θ ∗ be a set of parameters and µ∗
be the system trajectory returned by an optimization algorithm that is applied to the problem in Eq. (8). If
[[φ[θ ∗ ]]](µ∗ ) ≤ 0, then for all θ  θ ∗ , [[φ[θ]]](Σ) ≤ 0.
Proof. If [[φ[θ ∗ ]]](µ∗ ) ≤ 0, then [[φ[θ ∗ ]]](Σ) ≤ 0. Since
[[φ[θ]]](Σ) is non-increasing with respect to θ, then for
all θ  θ ∗ , we also have [[φ[θ]]](Σ) ≤ 0.
t
u
Proposition 2 If f (θ) = kθk, and the robustness function is non-increasing, then γ = kθk is a valid choice for
parameter γ. Here, k · k denotes the euclidean norm.
Proof. The interesting case to prove here is when we
have θ such that [[φ[θ]]](Σ) ≥ 0 and we have θ 0 such
that [[φ[θ 0 ]]](Σ) < 0. See Fig. 8 (Left) for an illustration
of the arrangement of parameter valuations for a two
parameter specification.
In this case
γ = kθk ≥ kθ 0 k ≥ kθk
and
[[φ[θ]]](Σ) ≥ 0 =⇒
kθk + γ + [[φ[θ]]](Σ) ≥ kθ 0 k
Therefore, if the problem in Eq. (6) is feasible, then the
optimum of equations (6) and (7) is the same.
t
u


























Fig. 9. Example 2: Specification falsification for φ[θ] = 2[0,θ1 ] ¬a
where O(a) = [1.5, θ2 ] × [1, θ3 ] with mined parameters θ1 = 3.417,
θ2 = 1.7, and θ3 = 1.078.

Example 7 (AT) Using Eq. (8) as a cost function, we
can now compute a parameter for Example 6 using STaLiRo [17, 18]. In particular, using Simulated Annealing as a stochastic optimization function, S-TaLiRo returns θ∗ ≈ 2.45 as optimal parameter for constant input
u(t) = 99.81. The corresponding temporal logic robustness for the specification 2[0,2.45] (ω ≤ 4500) is −0.0445.
The number of tests performed for this example was 500
and, potentially, the accuracy of estimating θ∗ can be
improved if we increase the maximum number of tests.
However, based on 100 tests the algorithm converges to
a good solution within 200 tests.
N
Example 8 (HS) Let us consider the specification φ[θ]
= 2[0,θ1 ] ¬a where O(a) = [1.5, θ2 ] × [1, θ3 ] on our hybrid system running example. Here, the bounds for the
timing parameter are θ1 ∈ [0, 5] and the bounds for the
state parameters are θ2 ∈ [1.5, 2.1] and θ3 ∈ [1.1, 1.6].
The ranges for the parameters are chosen based on prior
knowledge and experience about the system. The parameter mining algorithm from S-TaLiRo returns θ1∗ =
3.417, θ2∗ = 1.7, and θ3∗ = 1.078 after running 1000
tests on the system. The generated trajectories by the parameter mining algorithm are presented in Fig. 9. The
returned parameters guarantee that the system does not
satisfy the specification for all parameters θ where θ ∗ 
θ.
N
5.2 Non-decreasing Robustness Functions
The case of non-decreasing robustness functions is symmetric to the case of non-increasing robustness functions.
In particular, the optimization problem is a maximization problem. We will reformulate the problem of Eq. (7)
so that we do not have to solve two separate optimization
problems. From (7), we have:



 γ − maxµ∈Lτ (Σ) [[φ[θ]]](µ)
if maxµ∈Lτ (Σ) [[φ[θ]]](µ) ≥ 0  =
max f (θ) +

θ∈Θ
0 otherwise



 γ − [[φ[θ]]](µ)
if − [[φ[θ]]](µ) ≤ 0  =
= max f (θ) + max
θ∈Θ
µ∈Lτ (Σ) 
0 otherwise

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

11

4000
3500

4000

3000
2500

2000

Robustenss

Robustenss

3000

1000
0
−1000
0

2000
1500
1000

0
20

40

10
60

80

100

30

u

θ

500
0

20

13.8

−500
0

10

20

30

40

50
u

60

70

80

90

100

Fig. 10. Example 9. Left: Specification robustness as a function of the parameter θ and the input u. Right: The robustness function
[[2[12.59,30] (ω ≤ 4500)]](∆Σ (u)).



 γ − [[φ[θ]]](µ)
if [[φ[θ]]](µ) ≥ 0  (9)
= max max f (θ) +

θ∈Θ µ∈Lτ (Σ)
0 otherwise


The previous discussion is formalized in the following
result.
Proposition 3 Let θ ∗ be a set of parameters and µ∗
be the system trajectory returned by an optimization algorithm that is applied to the problem in Eq. (9). If
[[φ[θ ∗ ](µ∗ ) ≤ 0, then for all θ  θ ∗ , we have [[φ[θ]]](Σ) ≤
0.
∗

∗

[[φ[θ]]](Σ) ≤ 0. Again, the approximate value of θ∗ is a
rough estimate based on the granularity of the grid.
Using Eq. (9) as a cost function, we can now compute a parameter for Example 9 using our toolbox STaLiRo [17, 18]. S-TaLiRo returns θ∗ ≈ 12.59 as optimal parameter for constant input u(t) = 90.88 within
250 tests. The temporal logic robustness for the specification 2[12.59,30] (ω ≤ 4500) with respect to the input u
appears in Fig. 10 (Right).
N
6 Parameter Falsification Domain

∗

Proof. If [[φ[θ ]]](µ ) ≤ 0, then [[φ[θ ]]](Σ) ≤ 0. Since
[[φ[θ]]](Σ) is non-decreasing with respect to θ, then for
all θ  θ ∗ , we also have [[φ[θ]]](Σ) ≤ 0.
t
u
Proposition 4 If f (θ) = kθk and the robustness function is non-decreasing, then γ = −kθk is a valid choice
for parameter γ.
Proof. The interesting case to prove here is when we
have θ such that [[φ[θ]]](Σ) < 0 and we have θ 0 such
that [[φ[θ 0 ]]](Σ) ≥ 0. See Fig. 8 (Right) for an illustration
of the arrangement of parameter valuations for a two
parameter specification. In this case
γ = −kθk, [[φ[θ 0 ]]](Σ) ≥ 0 and
kθk ≥ kθ 0 k ≥ kθk =⇒
kθk ≥ kθ 0 k + γ − [[φ[θ 0 ]]](Σ)
Therefore, if the problem in Eq. (6) is feasible, then the
optimum of equations (6) and (7) is the same.
t
u
Example 9 (AT) Let us consider the specification φ[θ]
= 2[θ,30] (ω ≤ 4500) on our running example. The specification robustness [[φ[θ]]](∆Σ (u)) as a function of θ and
the input u appears in Fig. 10 for constant input signals. The creation of the graph required 100×30 = 3, 000
tests. The contour under the surface indicates the zero
level set of the robustness surface, i.e., the θ and u values
for which we get [[φ[θ]]](∆Σ (u)) = 0. We remark that the
contour is actually an approximation of the zero level set
computed by a linear interpolation using the neighboring
points on the grid. From the graph, we could infer that
θ∗ ≈ 13.8 and that for any θ ∈ [0, 13.8], we would have

We utilize the solution of Problem 2 and exploit the robustness landscape of a specific class of temporal logic
formulas to present two algorithms to estimate Ψ =
{θ ∗ ∈ Θ | Σ 6|= φ[θ ∗ ]} for Problem 2. In fact, we can
reduce this problem to finding the set Θbd = Ψ ∩ {θ ∗ ∈
Θ | [[φ[θ ∗ ]]](Σ) = 0} since the robustness landscape is
monotonic. Here, Θbd represents the intersection of the
robustness function with the zero level set. As a preprocessing step, the PMTL parameters are normalized
in the range [0, 1] to avoid bias during the optimization
process. It is important to note, that due to the undecidable nature of the problem, we cannot determine
satisfying parameter values. Therefore, we generate the
parameter falsification domain by finding only falsifying
parameter values.
The first method approximates Θbd by modifying the
priority function f and thereby slightly shifting the minimum or maximum of the objective function in Eq. 8 or
Eq. 9, respectively. The magnitude of the shift depends
on the shape of the robustness landscape of the model
and specification.
As shown in Algorithm 1, the set Ψ is explored iteratively. For every iteration, we draw a random vector ω
with dimension equal to the dimension of Θ. The random vector is used as parameterPweights for the priority
function f (θ). Namely, f (θ) =
wi θi . We run parameter mining, which returns an approximation for Eq. (7).
In case φ[θ] is non-decreasing (or non-increasing), the
optimization algorithm opt is a maximization (or minimization) algorithm. We utilize the values mined and the
corresponding robustness value to expand Ψ and reduce

12

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS
n=2

n=1

n=50

n=100

8000

8000

8000

8000

7000

7000

7000

7000

6000

6000

6000

6000

5000

5000

5000

5000

4000

4000

4000

4000

3000
0

3000

3000

20

40

60

0

20

40

60

0

20

40

3000

60

0

20

40

60

Fig. 11. Illustration of the iterative process for Algorithm 1. Specification: φ[θ] = ¬(3[0,θ1 ] q ∧ 2p[θ2 ]) where p[θ2 ] ≡ (ω ≤ θ2 ) and
q ≡ (v ≥ 100). Model: Automatic Transmission as described in Example 1. The red colored set represents set Ψ = {θ ∈ Θ | Σ 6|= φ[θ]} i.e.
the set of parameter values such that the system does not satisfy the specification. In each iteration of the algorithm, set Ψ gets expanded
by the optimal falsifying parameter which is guided by the robustness landscape and the random weight in the priority function.

the unknown parameter range for the next iteration. We
present the iterative process in Fig. 11.
We define a PMTL specification monotonicity function M : PMTL → {−1, 0, 1} where

lem:
maximize
subject to

c

(10)

c ∗ b + p ∈ Θ and
Σ 6|= φ[ c ∗ b + p ]


 1 if φ[θ] is non-decreasing;
M(φ[θ]) = −1 if φ[θ] is non-increasing;

0 otherwise.
A monotonicity computation algorithm is presented
in [15] and generalized in [33].

Algorithm 1 Robustness Guided Parameter Falsification Domain Algorithm RGDA(opt, Γ , Θ, φ, Σ, n, t)
Input: Stochastic optimization algorithm opt, search space
Γ , parameter range Θ, specification φ, system Σ, number of
iterations n and tests t
Output: Parameter falsification domain Ψ
Internal Variables: Parameter weights ω, parameters
mined θ ∗ and robustness value γ
1: hΨ , ω, θ ∗ , γi ← h∅, ∅, ∅, ∅i
2: for i = 0 to n do
3:
ω ← RandomVector([0, 1], dimension(Θ))
4:
[θ ∗ , γ] ← opt(Γ, Θ, φ, Σ, t, ω, M(φ[θ ∗ ]))
. run
parameter mining and robustness computation
5:
if (γ ≤ 0) then
6:
if (M(φ[θ ∗ ]) = 1) then
7:
Ψ ← Ψ ∪ {θ ∈ Θ | ∀i (0 ≤ θi ≤ θi∗ )} . expand
the falsification domain Ψ
8:
else if (M(φ[θ ∗ ]) = −1) then
9:
Ψ ← Ψ ∪ {θ ∈ Θ | ∀i (θi ≥ θi∗ ≥ 0)}
10:
end if
11:
end if
12: end for
13: return Ψ

Algorithm 2 explores the set Θbd by iteratively expanding the set of falsifying parameters, namely, the set
Ψ . However in this case, the search is finely structured
and does not depend on randomized weights. For presentation purposes, let us consider the case for specifications
with non-decreasing monotonicity. Given a normalized
parameter range with dimension η, in each iteration of
the algorithm, we solve the following optimization prob-

where p is the starting point of the optimization problem
in each iteration and b is the bias vector which enables
to prioritize specific parameters in the search. Namely,
the choice of b directs the expansion of the parameter
falsification domain along a specific direction. We refer to
the solution of Eq. 10 in the ith iteration of the algorithm
as marker(i). Initially, for the first iteration, the value
of p is set to 0 or 1 depending on the monotonicity
of the specification. The returned marker(1) from Eq.
10 is then utilized to update Ψ , the set of parameters
for which the system does not satisfy the specification.
Next, we generate at most 2η − 2 initial position vectors
induced by the returned marker(1).
Consider the example presented in Fig. 12 where we
have marker(1) = [136; 7268]. That value is utilized to
update Ψ and generate two new initial position vectors
at [0; 7268] and [136; 0]. In the next iteration of the algorithm, the search is initialized in one of the newly generated initial position vectors. Namely, the search starts
in [0; 7268] or [136; 0] (see Fig. 12, Left). The initial position vector not utilized is stored in a list and used in
future iterations. In the second iteration, [136; 0] is used
as the initial position vector. We return the solution to
Eq. 10 with marker(2) = [143; 4425] which generates
the initial position vectors [143; 0] and [136; 4425] (Fig.
12, Middle). Similarly, marker(3) is generated in Fig.
12 (Right). In this example, the directional vector b, in
each iteration, directs towards the bounds of the parameter range, namely (160, 8000). The algorithm terminates
when one of the following conditions is met: 1) The distance between markers is less than some value , or
2) no new markers are generated from the current set
of initial position vectors, or 3) a maximum number of
iterations is exceeded.
7 Experiments and a Case Study
The algorithms and examples presented in this work are
implemented and publicly available through the Matlab
toolbox S-TaLiRo [17, 18].

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS
i =1

8000

3

7000

5000

b

4000

1
0

3

7000

6000

3000

i =2

8000

θ* = [136;7268]

2
20

40

60

80

100

120

160

6000

5000

5000

4000

4000

2
20

40

60

80

100

3

7000

θ*= [143;4425]

6000

0

i =3

8000

3000

140

13

120

θ* = [114;7779]

3000
140

160

0

20

40

60

80

100

120

140

160

Fig. 12. Illustration of the iterative process for Algorithm 2. Specification: φ[θ] = 2(p[θ1 ]∧q[θ2 ]) where p[θ1 ] ≡ (v ≤ θ1 ) and q ≡ (ω ≤ θ2 ).
Model: Automatic Transmission as described in Example 1. The parameter range for the specification is Θ = [0 160; 3000 8000]. In each
plot, the search is conducted in a specific direction b. The plots from left to right represent three iterations of Algorithm 2. The yellow
circles and green marks represent sample points of the search optimizer in the process of solving Eq. 10. Specifically, the yellow circles
represent parameter values for which we have found system inputs and initial conditions that falsify the specification. The green marks
represent parameter values for which falsification is not found. The largest yellow circle found by the stochastic optimizer is returned as
the current marker. The orange squares represent the initial position of the search in the current iteration. The blue squares represent the
initial positions generated by the current marker that will be considered in future iterations. The black squares represent initial positions
that will be considered in future iterations. The red colored set represents set Ψ = {θ ∈ Θ | Σ 6|= φ[θ]} i.e. the set of parameter values
such that the system does not satisfy the specification.

Algorithm 2 Structured Parameter Falsification Domain Algorithm SDA(opt, Γ , Θ, φ, Σ, t, , b, n)
Input: Stochastic optimization algorithm opt, search space
Γ , parameter range Θ, specification φ, system Σ, number of
tests t, minimum distance between markers , bias vector b,
maximum number of iterations n
Output: Parameter falsification domain Ψ
Internal Variables: List of initial positions ML, termination condition T C, initial positions generated in the current
iteration T L, iteration i
1: hΨ , p, T C, ML, T L, ii ← h∅, ∅, ⊥, {}, {}, 0i
2: if (M(φ[θ]) = 1) then
3:
ML.Add(0(dimension(Θ)))
4: else if (M(φ[θ]) = −1) then
5:
ML.Add(1(dimension(Θ)))
6: end if
7: while T C = ⊥ do
8:
T L ← {}
9:
for v in ML do
10:
i←i+1
11:
[θ ∗ , γ] ← opt(Γ, Θ, φ, Σ, t, ω, M(φ[θ]), b, v)
.
run parameter mining starting at v and search along the
directional vector b
12:
if (γ ≤ 0) then
13:
T L.Add(GenerateMarkers(θ∗ , M(φ[θ])))
14:
if (M(φ[θ ∗ ]) = 1) then
15:
Ψ ← Ψ ∪ {θ ∈ Θ | ∀i (0 ≤ θi ≤ θi∗ }
16:
Θ ←Θ\Ψ
17:
else if (M(φ[θ ∗ ]) = −1) then
18:
Ψ ← Ψ ∪ {θ ∈ Θ | ∀i (θi ≥ θi∗ ≥ 0)}
19:
Θ ←Θ\Ψ
20:
end if
21:
end if
22:
end for
23:
ML ← T L
24:
if ML.IsEmpty() or DistanceBetweenMarkers(ML) <  or i > n then T C ← >
25:
end if
26: end while
27: return Ψ

The parametric MTL exploration of CPS is motivated by a challenge problem published by Ford in 2002
[34]. In particular, the report provided a simple – but
still realistic – model of a powertrain system (both the
physical system and the embedded control logic) and
posed the question whether there are constant operating conditions that can cause a transition from gear two
to gear one and then back to gear two. That behavior
would imply that the gear transition from 1 to 2 was not
necessary in the first place.
The system is modeled in Checkmate [35]. It has 6
continuous state variables and 2 Stateflow charts with
4 and 6 states, respectively. The Stateflow chart for the
shift scheduler appears in Fig. 13. The system dynamics and switching conditions are linear. However, some
switching conditions depend on the initial conditions of
the system. The latter makes the application of standard
system verification tools not a straightforward task.
In [31], we demonstrated that S-TaLiRo [17, 18] can
successfully solve the challenge problem (see Fig. 13)
by formalizing the requirement as an MTL specification
φP
e1 = ¬3(g2 ∧ 3(g1 ∧ 3g2 )), where gi is a proposition
that is true when the system is in gear i. Stochastic
search methods can be applied to solve the resulting optimization problem where the cost function is the robustness of the specification. Moreover, inspired by the
success of S-TaLiRo on the challenge problem, we tried
to ask a more complex question. Specifically, does a transition exist from gear two to gear one and back to gear
two in less than 2.5 sec? An MTL specification that
can capture this requirement is φP
e2 = 2((¬g1 ∧ Xg1 ) →
2(0,2.5] ¬g2 ). The natural question that arises is what
would be the smallest time for which such a transition can occur? We can formulate a parametric MTL
formula to query the model of the powertrain system:
φP
e3 [θ] = 2((¬g1 ∧Xg1 ) → 2(0,θ] ¬g2 ). We have extended
S-TaLiRo to be able to handle parametric MTL specifi-

14

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS
4

3

first_gear
entry: schedule = 1;
STaliro_StateVar = 1;

shift_speed12

to_first

shift_speed21

2

1

1

transition21_shifting
entry:schedule = 4;
STaliro_StateVar = 4;

transition12_shifting
2 entry : schedule = 2;
STaliro_StateVar = 2;

2

shift_speed12

0

10

20

30

40

50

60

0

10

20

30

40

50

60

4

1

3
shift_speed21

to_second
second_gear
entry: schedule = 3;
STaliro_StateVar = 3;

2

1

Fig. 13. Left: The shift scheduler of the powertrain challenge problem. Right: Shift schedules. The numbers correspond to the variables
in the states of the shift scheduler. Right Top: The shift schedule falsifying requirement φP
e1 . Right Bottom: The shift schedule falsifying
requirement φP
e3 [0.4273].

cations. The total simulation time of the model is set to
60 sec and the search interval is Θ = [0, 60]. S-TaLiRo
returned θ∗ ≈ 0.4273 as the minimum parameter found
(See Fig. 13) using about 300 tests of the system.
The challenge problem is extended to an industrial
size high-fidelity engine model. The model is part of the
SimuQuest Enginuity [36] Matlab/Simulink tool package. The Enginuity tool package includes a library of
modules for engine component blocks. It also includes
pre-assembled models for standard engine configurations,
see Fig. 15. In this work, we will use the Port Fuel Injected (PFI) spark ignition, 4 cylinder inline engine configuration. It models the effects of combustion from first
physics principles on a cylinder-by-cylinder basis, while
also including regression models for particularly complex physical phenomena. Simulink reports that this is a
56 state model. The model includes a tire-model, brake
system model, and a drive train model (including final
drive, torque converter and transmission). The model is
based on a zero-dimensional modeling approach so that
the model components can all be expressed in terms of
ordinary differential equations. The inputs to the system
are the throttle and brake schedules, and the road grade,
which represents the incline of the road. The outputs
are the vehicle and engine speed, the current gear and a
timer that indicates the time spent on a gear. We search
for a particular input for the throttle schedule, brake
schedule, and grade level. The inputs are parametrized
using 12 search variables, where 7 are used to model
the throttle schedule, 3 for the brake schedule, and 2
for the grade level. The search variables for each input
are interpolated with the Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) function provided as a
Matlab function by Mathworks. The simulation time is
60s. We demonstrate the parameter mining method for
two specifications:
1. The specification φS1 [θ] = 2[0,60] ((g2 ∧ Xg1) →
2[0,θ] ((τ ≤ θ) → g1), where τ is the time spent in a gear.
The specification states that after shifting into gear one
from gear two, there should be no shift from gear one to

2.5
2

1.28s
1.5
1
0.5
0

0

10

20

30

40

50

60

Fig. 14. A shift schedule which falsifies the specification φS
1 [θ =
1.29] = 2[0,60] ((g2 ∧ Xg1 ) → 2[0,1.29] ((τ ≤ 1.29) → g1 ) on the
Simuquest high-fidelity engine model for specification.

any other gear within θ seconds. Clearly, the property
defined is equivalent to the property defined in the challenge problem in the sense that the set of trajectories
that satisfy/falsify the property is the same. The reason
for the change made is the improved performance of the
hybrid distance metric [37] with the modified specification. The mined parameter for the specification returned
is 1.29s. Figure 14 presents a shift schedule for which a
transition out of gear one occurs in 1.28 seconds.
2. The specification φS2 [θ] = 2((v < θ1 ) ∧ (ω < θ2 )),
where θ1 , θ2 represent the vehicle and engine speed parameters, respectively. The specification states that the
vehicle and engine speed is always less than θ1 and θ2 ,
respectively. The mined parameters for the specification
returned are 137.1mph and 4870rpm.
In Table 1, we present experimental results for specifications on the Powertrain, Automotive Transmission,
and Simuquest Enginuity high-fidelity engine models. A
detailed description of the benchmark problems can be
found in [7, 12] and the benchmarks can be downloaded
with the S-TaLiRo distribution [18].

8 Related Work
The topic of testing embedded software and, in particular, embedded control software is a well studied problem that involves many subtopics well beyond the scope
of this paper. We refer the reader to specialized book

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

15

Table 1. Experimental results of Parameter Mining with S-TaLiRo. The parameters were mined by running 1000 tests. Legend: f (θ) : the
priority function used, φAT
: Specifications tested on the Automotive Transmission Model, φP : Specification tested on the Powertrain
i
Model, φS : Specification tested on the Simuquest Enginuity high-fidelity Engine Model. The gray colored rows are first presented in [14]
and are included for completeness.

Specification
φAT
[θ]
=
¬3((v
≥ 120) ∧ 3[0,θ] (ω ≥ 4500))
1
φAT
2 [θ] = ¬3((v ≥ 120) ∧ 3[0,θ] (v ≥ 125))
φAT
3 [θ] = ¬3((v ≥ 120) ∧ 3[0,θ] (ω ≥ 4500))
φAT
4 [θ] = ¬3((v ≥ 120) ∧ 3[0,θ] (ω ≥ 4500))
φAT
5 [θ] = 2((v ≤ θ1 ) ∧ (ω ≤ θ2 ))

φAT
6 [θ] = ¬(3[0,θ1 ] (v ≥ 100) ∧ 2(ω ≤ θ2 ))

φAT
7 [θ] = 2((v ≤ θ1 ) ∧ (ω ≤ θ2 )) ∧ 3[0,θ3 ] (v ≥
150) ∧ 3[0,θ4 ] (ω ≥ 4500)
φAT
8 [θ] = 2((v ≤ θ1 ) ∧ (ω ≤ θ2 )) ∧ 3[0,θ3 ] (v ≥
150) ∧ 3[0,θ4 ] (ω ≥ 4500) ∧ 2[θ5 ,60] (v ≥
170) ∧ 2[θ6 ,60] (ω ≥ 4750)
φP
e3 [θ] = 2((¬g1 ∧ Xg1 ) → 2(0,θ] ¬g2 )
φS
1 [θ] = 2[0,60] ((g2 ∧ Xg1 ) → 2[0,θ] ((t ≤ θ) → g1 )

f (θ)
θ
θ
θ
θ
kθk
θ1
θ2
max(θ)
min(θ)
kθk
θ1
θ2
max(θ)
min(θ)
kθk
max(θ)
min(θ)
kθk
max(θ)
min(θ)
θ
θ

Time
135s
138s
137s
132s
139s
137s
138s
138s
138s
144s
142s
138s
140s
142s
145s
143s
142s
146s
145s
143s
2600s
21803s

S-TaLiRo
Parameters Mined
7.7s
10.00s
7.57s
7.56s
h138mph, 5981rpmi
h57mph, 6000rpmi
h180mph, 2910rpmi
h109mph, 6000rpmi
h154mph, 5300rpmi
h15.7s, 4820rpmi
h44.6s, 3598rpmi
h12.2s, 6000rpmi
h37.3s, 3742rpmi
h12.3s, 5677rpmi
h198mph, 4932rpm, 59.5s, 55si
h129mph, 6000rpm, 48.9s, 28.3si
h190mph, 5575rpm, 55.1s, 54.8si
h159mph, 5700rpm, 48.3s, 36.2s, 54.2s, 53.9si
h85.9mph, 6000rpm, 3.8s, 38.8s, 44.5s, 51.5si
h191mph, 4958rpm, 43s, 55.3s, 42s, 47.1si
0.1s
1.29s

Table 2. Experimental Comparison of the method presented in this paper (A) and the parameter synthesis method presented in [33],
(B). Legend: #Sim.: the number of system simulations, #Rob: the number of robustness computations.

Specification
φS
2 [θ]

= 2((v ≤ θ1 ) ∧ (ω ≤ θ2 ))

φAT
5 [θ] = 2((v ≤ θ1 ) ∧ (ω ≤ θ2 ))
φAT
6 [θ] = ¬(3[0,θ1 ] (v ≥ 100) ∧ 2(ω ≤ θ2 )

Method
A
B
A
B
A
B

chapters and textbooks for further information [38, 39].
Similarly, a lot of research has been invested on testing
methods for Model Based Development (MBD) of embedded systems [4]. However, the temporal logic testing
of embedded and hybrid systems has not received much
attention [40, 41, 6, 42].
Parametric temporal logics were first defined over
traces of finite state machines [43]. In parametric temporal logics, some of the timing constraints of the temporal
operators are replaced by parameters. Then, the goal is
to develop algorithms that will compute the values of
the parameters that make the specification true under
some optimality criteria. That line of work has been extended to real-time systems and in particular to timed
automata [44] and continuous-time signals [15]. The authors in [45, 46] define a parametric temporal logic called
quantifier free Linear Temporal Logic over real valued

Parameters Mined
137.1 mph
4870 rpm
149.8 mph
4883 rpm
100.2 mph 5987.6 rpm
137.5 mph
6000 rpm
21s
3580 rpm
59.06s
3296 rpm

Time
20170s
50017s
106s
253s
110s
397s

#Sim
1000
2386
1000
2176
1000
3443

#Rob
1000
5130
1000
11485
1000
9718

signals. However, they focus on the problem of determining system parameters such that the system satisfies
a given property rather than on the problem of exploring
the properties of a given system.
Another related problem is specification mining or
model exploration for finite state machines. The problem
was initially introduced by William Chan in [47] under
the term Temporal Logic Queries. The goal of model
exploration is to help the designer achieve a better understanding and explore the properties of a model of the
system. Namely, the user can pose a number of questions
in temporal logic where the atomic propositions are replaced by a placeholder and the algorithm will try to
find the set of atomic propositions for which the temporal logic formula evaluates to true. Since the first paper
[47], several authors have studied the problem and proposed different versions and approaches [48, 49, 50, 51].

16

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

tems, in general, is undecidable and, therefore the failure
to find a falsifying trajectory does not imply that one
does not exist. Third, in A, through the priority function, we enable the system engineer to have flexibility
when assigning weights and priorities to parameters. In
B, parameter synthesis through binary search implicitly
prioritizes one parameter over others.

Fig. 15. SimuQuest Enginuity model components. Used with perc
mission, 
SimuQuest
[36].

A related approach is based on specification mining over
temporal logic templates [52] rather than special placeholders in a specific formula. In [53], the authors present
an inference algorithm that finds temporal logic properties of a system from data. The authors introduce a reactive parameter signal temporal logic and define a partial
order over it to aid the property definition process.
In [33], the authors provide a parameter synthesis algorithm for Parametric Signal Temporal Logic (PSTL),
a similar formalism to MTL. To conduct parameter synthesis for multiple parameters, a binary search is utilized
to set the parameter value for each parameter in sequence. After a set of parameters is proposed, a stochastic optimization algorithm is utilized to search for trajectories that falsify the specification. If it fails to do
so, the algorithm stops, otherwise this two step process
continues until the termination condition is met.
In the following, we present three main differences
between the method proposed here (A) and the method
proposed in [33] (B). First, A is a best effort algorithm
for which the termination condition is the number of
tests the system engineer is interested to conduct. Clearly,
the more tests, the better the search space is explored.
Since the parameter mining problem is presented as a
single optimization problem, runtime is not directly affected by the number of parameters in the specification.
In contrast, in B, the runtime of the algorithm through
binary search is affected by the number of parameters
in the PSTL formula. For each iteration of the binary
search, multiple robustness computations have to be conducted, which for systems that output a large trace and
contain complex specifications, could become costly. The
second step in B is the falsification of the parameters
proposed. This algorithm needs to be performed on every iteration, until a falsification is found. If a falsifying
trajectory is not found, the stopping condition is met
and the parameters are returned. Second, in A, the parameters returned are the “best” parameters for which a
falsifying trajectory is found. In B, the proposed parameters are parameters for which no falsifying trajectory is
found. Proving that a specification holds for hybrid sys-

We compare the two methods using the Simuquest
Enginuity high-fidelity Engine model and the Automotive Transmission model. To enable the comparison of
the two methods, we have implemented the B method
in S-TaLiRo. Note that the simulation time is 60s. The
experimental results are presented in Table 2. For the A
method, the number of simulations and robustness computations is predefined. On the other hand, for the B
method, these numbers vary following the reasons presented in the previous paragraph. As a result, the difference in computation time between the two methods
is significant. Due to the significant differences between
the two algorithms, in terms of guarantees provided, it
is not possible to compare the quality of the solutions.
While the mined parameters with method A guarantee
falsification of the specification, the mined parameters
with method B do not.
The results for the Automotive Transmission model
can be reproduced by running the experiments in the
S-TaLiRo distribution [18].

9 Conclusion

An important stage in Model Based Development (MBD)
of software for CPS is the formalization of system requirements. We advocate that Metric Temporal Logic
(MTL) is an excellent candidate for formalizing interesting design requirements. In this paper, we have presented a solution on how we can explore system properties using Parametric MTL (PMTL) [15]. Based on the
notion of robustness of MTL [11], we have converted the
parameter mining problem into an optimization problem which we approximate using S-TaLiRo [17, 18]. We
have presented a method for mining multiple parameters as long as the robustness function has the same
monotonicity with respect to all the parameters. Finally,
we have demonstrated that our method can provide interesting insights to the powertrain challenge problem
[34].We demonstrated the method on an industrial size
engine model and examples from related works.
Acknowledgements. This work has been partially supported
by award NSF CNS 1116136 and CNS 1350420. Also, we
thank the Toyota Technical Center for donating a license for
the Simuquest Enginuity tool package.

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

References
1. Lions, J.L., Lbeck, L., Fauquembergue, J.L., Kahn,
G., Kubbat, W., Levedag, S., Mazzini, L., Merle, D.,
O’Halloran, C.: Ariane 5, flight 501 failure, report by
the inquiry board. Technical report, CNES (1996)
2. Hoffman, E.J., Ebert, W.L., Femiano, M.D., Freeman,
H.R., Gay, C.J., Jones, C.P., Luers, P.J., Palmer, J.G.:
The near rendezvous burn anomaly of december 1998.
Technical report, Applied Physics Laboratory, Johns
Hopkins University (1999)
3. Oss, D.G.V.: Computer software in civil aircraft. In: Digital Avionics Systems Conference, 1991. Proceedings.,
IEEE/AIAA 10th, IEEE (1991) 324–330
4. Tripakis, S., Dang, T.: Modeling, Verification and Testing using Timed and Hybrid Automata. In: Model-Based
Design for Embedded Systems. CRC Press (2009) 383–
436
5. Kapinski, J., Deshmukh, J., Jin, X., Ito, H., Butts, K.:
Simulation-guided approaches for verification of automotive powertrain control systems. In: American Control
Conference (ACC), 2015, IEEE (2015) 4086–4095
6. Nghiem, T., Sankaranarayanan, S., Fainekos, G.E., Ivancic, F., Gupta, A., Pappas, G.J.: Monte-carlo techniques
for falsification of temporal properties of non-linear hybrid systems. In: Proceedings of the 13th ACM International Conference on Hybrid Systems: Computation and
Control, ACM Press (2010) 211–220
7. Abbas, H., Fainekos, G., Sankaranarayanan, S., Ivančić,
F., Gupta, A.: Probabilistic temporal logic falsification
of cyber-physical systems. ACM Transactions on Embedded Computing Systems (TECS) 12 (2013) 95
8. Koymans, R.: Specifying real-time properties with metric
temporal logic. Real-Time Systems 2 (1990) 255–299
9. Maler, O., Nickovic, D.: Monitoring temporal properties
of continuous signals. In: Proceedings of FORMATSFTRTFT. Volume 3253 of LNCS. (2004) 152–166
10. Fainekos, G.E., Pappas, G.J.: Robustness of temporal logic specifications. In: Formal Approaches to Testing and Runtime Verification. Volume 4262 of LNCS.,
Springer (2006) 178–192
11. Fainekos, G.E., Pappas, G.J.: Robustness of temporal
logic specifications for continuous-time signals. Theoretical Computer Science 410 (2009) 4262–4291
12. Sankaranarayanan, S., Fainekos, G.: Falsification of
temporal properties of hybrid systems using the crossentropy method. In: ACM International Conference on
Hybrid Systems: Computation and Control. (2012)
13. Annapureddy, Y.S.R., Fainekos, G.E.: Ant colonies for
temporal logic falsification of hybrid systems. In: Proceedings of the 36th Annual Conference of IEEE Industrial Electronics. (2010) 91–96
14. Yang, H., Hoxha, B., Fainekos, G.: Querying parametric
temporal logic properties on embedded systems. In: Int.
Conference on Testing Software and Systems. (2012)
15. Asarin, E., Donzé, A., Maler, O., Nickovic, D.: Parametric identification of temporal properties. In: Runtime
Verification. Volume 7186 of LNCS., Springer (2012)
147–160
16. Myers, R.H., Montgomery, D.C., Anderson-Cook, C.M.:
Response surface methodology: process and product optimization using designed experiments. John Wiley &
Sons (2016)

17

17. Annapureddy, Y.S.R., Liu, C., Fainekos, G.E., Sankaranarayanan, S.: S-taliro: A tool for temporal logic falsification for hybrid systems. In: Tools and algorithms for
the construction and analysis of systems. Volume 6605
of LNCS., Springer (2011) 254–257
18. S-TaLiRo: Temporal Logic Falsification Of CyberPhysical Systems. https://sites.google.com/a/asu.
edu/s-taliro/s-taliro (2015)
19. Hoxha, B., Bach, H., Abbas, H., Dokhanchi, A.,
Kobayashi, Y., Fainekos, G.: Towards formal specification visualization for testing and monitoring of cyberphysical systems. In: International Workshop on Design
and Implementation of Formal Tools and Systems. (2014)
20. Sankaranarayanan, S., Homaei, H., Lewis, C.: Modelbased dependability analysis of programmable drug infusion pumps. In: Formal modeling and analysis of timed
systems. Springer (2011) 317–334
21. Sankaranarayanan, S., Fainekos, G.: Simulating insulin
infusion pump risks by in-silico modeling of the insulinglucose regulatory system. In: International Conference
on Computational Methods in Systems Biology. (2012)
22. Jiang, Z., Pajic, M., Mangharam, R.: Cyber-physical
modeling of implantable cardiac medical devices. Proceedings of the IEEE 100 (2012) 122–137
23. Chen, T., Diciolla, M., Kwiatkowska, M.Z., Mereacre,
A.: A simulink hybrid heart model for quantitative verification of cardiac pacemakers. In: Proceedings of the
16th international conference on Hybrid systems: computation and control, ACM (2013) 131–136
24. Abbas, H., Hoxha, B., Fainekos, G., Ueda, K.:
Robustness-guided temporal logic testing and verification for stochastic cyber-physical systems. In: Cyber
Technology in Automation, Control, and Intelligent Systems (CYBER), 2014 IEEE 4th Annual International
Conference on, IEEE (2014) 1–6
25. Alur, R., Henzinger, T.A.: Real-Time Logics: Complexity
and Expressiveness. In: Fifth Annual IEEE Symposium
on Logic in Computer Science, Washington, D.C., IEEE
Computer Society Press (1990) 390–401
26. Hoxha, B., Mavridis, N., Fainekos, G.: Vispec : A graphical tool for elicitation of mtl requirements. In: Proceedings of the 2015 IEEE/RSJ International Conference on
Intelligent Robots and Systems. (2015)
27. Zhao, Q., Krogh, B.H., Hubbard, P.: Generating test inputs for embedded control systems. IEEE Control Systems Magazine August (2003) 49–57
28. Legriel, J., Le Guernic, C., Cotton, S., Maler, O.: Approximating the pareto front of multi-criteria optimization problems. In: TACAS, Springer (2010) 69–83
29. Deb, K.: Multi-objective optimization using evolutionary
algorithms. Volume 16. John Wiley & Sons (2001)
30. Alur, R., Courcoubetis, C., Halbwachs, N., Henzinger,
T.A., Ho, P.H., Nicollin, X., Olivero, A., Sifakis, J.,
Yovine, S.: The algorithmic analysis of hybrid systems.
Theoretical computer science 138 (1995) 3–34
31. Fainekos, G., Sankaranarayanan, S., Ueda, K., Yazarel,
H.: Verification of automotive control applications using
s-taliro. In: Proceedings of the American Control Conference. (2012)
32. Donze, A., Maler, O.: Robust satisfaction of temporal logic over real-valued signals. In: Formal Modelling
and Analysis of Timed Systems. Volume 6246 of LNCS.,
Springer (2010)

18

Hoxha et al.:: Mining Parametric Temporal Logic Properties in MBD for CPS

33. Jin, X., Donzé, A., Deshmukh, J.V., Seshia, S.A.: Mining
requirements from closed-loop control models. In: Proceedings of the 16th international conference on Hybrid
systems: computation and control, ACM (2013) 43–52
34. Chutinan, A., Butts, K.R.: Dynamic analysis of hybrid
system models for design validation. Technical report,
Ford Motor Company (2002)
35. Silva, B.I., Krogh, B.H.: Formal verification of hybrid
systems using CheckMate: a case study. In: Proceedings
of the American Control Conference. Volume 3. (2000)
1679 – 1683
36. Simuquest: Enginuity. (http://www.simuquest.com/
products/enginuity) Accessed: 2013-10-14.
37. Abbas, H., Fainekos, G.: Linear hybrid system falsification through local search. In: Automated Technology
for Verification and Analysis. Volume 6996 of LNCS.,
Springer (2011) 503–510
38. Conrad, M., Fey, I.: Testing automotive control software. In: Automotive Embedded Systems Handbook.
CRC Press (2008)
39. Koopman, P.:
Better Embedded System Software.
Drumnadrochit Education LLC (2010)
40. Tan, L., Kim, J., Sokolsky, O., Lee, I.: Model-based testing and monitoring for hybrid embedded systems. In:
Proceedings of the 2004 IEEE International Conference
on Information Reuse and Integration. (2004) 487–492
41. Plaku, E., Kavraki, L.E., Vardi, M.Y.: Falsification of
ltl safety properties in hybrid systems. In: Proc. of the
Conf. on Tools and Algorithms for the Construction and
Analysis of Systems (TACAS). Volume 5505 of LNCS.,
Springer (2009) 368 – 382
42. Zuliani, P., Platzer, A., Clarke, E.M.: Bayesian statistical
model checking with application to simulink/stateflow
verification. In: Proceedings of the 13th ACM International Conference on Hybrid Systems: Computation and
Control. (2010) 243–252
43. Alur, R., Etessami, K., La Torre, S., Peled, D.: Parametric temporal logic for model measuring. ACM Trans.
Comput. Logic 2 (2001) 388–407
44. Di Giampaolo, B., La Torre, S., Napoli, M.: Parametric
metric interval temporal logic. In Dediu, A.H., Fernau,
H., Martin-Vide, C., eds.: Language and Automata Theory and Applications. Volume 6031 of LNCS. Springer
(2010) 249–260
45. Fages, F., Rizk, A.: On temporal logic constraint solving
for analyzing numerical data time series. Theor. Comput.
Sci. 408 (2008) 55–65
46. Rizk, A., Batt, G., Fages, F., Soliman, S.: On a continuous degree of satisfaction of temporal logic formulae with
applications to systems biology. In: International Conference on Computational Methods in Systems Biology.
Volume 5307 of LNCS., Springer (2008) 251–268
47. Chan, W.: Temporal-logic queries. In: Proceedings of the
12th International Conference on Computer Aided Verification. Volume 1855 of LNCS., London, UK, Springer
(2000) 450–463
48. Bruns, G., Godefroid, P.: Temporal logic query checking.
In: Proceedings of the 16th Annual IEEE Symposium
on Logic in Computer Science, IEEE Computer Society
(2001) 409 – 417
49. Chechik, M., Gurfinkel, A.: Tlqsolver: A temporal logic
query checker. In: Proceedings of the 15th Interna-

50.

51.

52.

53.

tional Conference on Computer Aided Verification. Volume 2725., Springer (2003) 210–214
Gurfinkel, A., Devereux, B., Chechik, M.: Model exploration with temporal logic query checking. SIGSOFT
Softw. Eng. Notes 27 (2002) 139–148
Singh, A., Ramakrishnan, C., Smolka, S.A.: Query-based
model checking of ad hoc network protocols. In: CONCUR 2009-Concurrency Theory. Springer (2009) 603–
619
Wasylkowski, A., Zeller, A.: Mining temporal specifications from object usage. In: 24th IEEE/ACM International Conference on Automated Software Engineering.
(2009)
Kong, Z., Jones, A., Medina Ayala, A., Aydin Gol, E.,
Belta, C.: Temporal logic inference for classification and
prediction from data. In: Proceedings of the 17th international conference on Hybrid systems: computation and
control, ACM (2014) 273–282

DisCoF+ : Asynchronous DisCoF with Flexible Decoupling for
Cooperative Pathfinding in Distributed Systems

arXiv:1506.03540v1 [cs.RO] 11 Jun 2015

Kangjin Kim, Joe Campbell, William Duong, Yu Zhang and Georgios Fainekos
Abstract— In our prior work, we outlined an approach,
named DisCoF, for cooperative pathfinding in distributed systems with limited sensing and communication range. Contrasting to prior works on cooperative pathfinding with completeness
guarantees, which often assume the access to global information, DisCoF does not make this assumption. The implication
is that at any given time in DisCoF, the robots may not all
be aware of each other, which is often the case in distributed
systems. As a result, DisCoF represents an inherently online
approach since coordination can only be realized in an opportunistic manner between robots that are within each other’s
sensing and communication range. However, there are a few
assumptions made in DisCoF to facilitate a formal analysis,
which must be removed to work with distributed multi-robot
platforms. In this paper, we present DisCoF+ , which extends
DisCoF by enabling an asynchronous solution, as well as
providing flexible decoupling between robots for performance
improvement. We also extend the formal results of DisCoF
to DisCoF+ . Furthermore, we evaluate our implementation
of DisCoF+ and demonstrate a simulation of it running in
a distributed multi-robot environment. Finally, we compare
DisCoF+ with DisCoF in terms of plan quality and planning
performance.

I. INTRODUCTION
While cooperative pathfinding in multi-robot systems has
many applications, it is also fundamentally hard to solve
(i.e., PSPACE-hard [6]). The difficulty lies in the potential coupling between robots: when robots are completely
decoupled (e.g., when robots do not impose constraints
on each other’s plan to the goal), cooperative pathfinding
becomes polynomial-time solvable.1 As a result, most recent
approaches (e.g., [14], [15], [16], [17]) for pathfinding concentrate on how to identify the dependencies between robots,
in order to couple robots only when necessary to achieve
computational efficiency for many problem instances.
In these approaches, the solution is constructed for a
subset of robots (i.e., robots that must be coupled) at any
time, which are assumed to be decoupled with the remaining
robots. The computational complexity is exponential only in
the maximum number of robots in these subsets. While optimistic decoupling can lose optimality and even completeness
(e.g., [15]), pessimistic decoupling can only handle situations
in which robots are loosely coupled (e.g., [16]).
This work has been partially supported by award NSF CNS 1116136,
the ARO grant W911NF-13-1-0023, the ONR grants N00014-13-1- 0176,
N00014-13-1-0519 and N00014-15-1-2027.
K. Kim, J. Campbell, W. Duong, Y. Zhang and G. Fainekos
are with the School of Computing, Informatics and Decision
Systems Engineering, Arizona State University, Tempe, AZ
85281,
USA
{Kangjin.Kim, jacampb1, tbduong,

Yu.Zhang.442, fainekos}@asu.edu
1

A single robot pathfinding problem is polynomial-time solvable.

Meanwhile, to ensure completeness, these approaches often assume access to global information, which includes
knowledge about the current positions of the robots, and the
robots’ individual plans to their respective goals. With this
information, any robot can consider all other robots when
creating its own plan. While this assumption can be made
in many common applications of cooperative pathfinding
where planning can be centralized and performed offline
(e.g., cooperative pathfinding in computer games), it does
not hold in distributed systems due to limited sensing and
communication range.
In our prior work [21], we introduced a window-based
approach, called DisCoF, for cooperative pathfinding in
distributed systems with limited sensing and communication
range. In DisCoF, the window size corresponds to the sensing
range of the robots. Robots can communicate with each other
either directly or indirectly. If they are within sensing range,
then robots may communicate directly. However, if the robots
are out of sensing range it is still possible to communicate
indirectly through other robots using a communication relay
protocol. This allows for coordination beyond a single robot’s
sensor range.
To ensure completeness, DisCoF uses a flexible approach
to decoupling robots such that they can transition from
optimistic to pessimistic decoupling when necessary. Robots
are assumed to be fully decoupled initially. During the online
pathfinding process, robots only couple together when necessary (i.e., when there are predictable conflicts [21]). Since
access to global information is not assumed, the creation of
local couplings (i.e., subsets of robots) may not be sufficient
due to the danger of live-locks. In such cases, a mechanism
(called push and pull) is introduced in which robots in a
local coupling can form a coupling group [21] in order to
coordinate more closely. Robots in a coupling group move
to their goals sequentially in a certain order while keeping
others (i.e., those that have not yet reached their goals) within
communication range. Coupling groups may increase in size
(e.g., when previously undetected robots come within sensing
range of a robot in the coupling group) and decrease in size
(e.g., when robots reach their goals). This mechanism can
potentially lead to a global coupling.
Contributions: In this paper, we introduce an asynchronous variant of DisCoF, refereed to as DisCoF+ , in
order to remove DisCoF’s required assumption that time
steps are synchronized. The Major difference of DisCoF+
from DisCoF is that this one runs on the individual robot,
but the previous one runs on a group of robots, depending
on the synchronized time step for the entire robots. In order

to make it work, we provide an asynchronous algorithm
with its communication strategy. Then, we introduce a new
decoupling strategy in DisCoF+ that allows robots to transition between optimistic and pessimistic decoupling with the
goal of improving efficiency. Furthermore, we demonstrate a
simulation of DisCoF+ in a distributed multirobot environment modelled in Webots in addition to providing the results
of numerical experiments with which the performance of
DisCoF and DisCoF+ are compared in terms of computation
time and length of plans.
II. RELATED WORK
To address the cooperative pathfinding problem, researchers have used a compilation approach [8], [1], [5],
[20], in which the problem is first transformed into other
related problems, and then the existing solutions or algorithms for these problems can be applied. Abstraction
methods to reduce the search space have also been used
[18], [13]. However, due to the inherent complexity of the
problem, these approaches are unscalable. While approaches
that constrain the topologies of the environment [19], [11],
[12] can significantly reduce the complexity, they cannot be
applied to general problem instances.
Given that pathfinding for a single robot is polynomialtime solvable, it is clear that the complexity is a result of
coupling between robots. As a result, researchers have concentrated on various ways to decouple robots. For approaches
that perform optimistic decoupling, robots are considered
as coupled only when necessary. One of the representative
approaches is hierarchical cooperative A∗ (HCA∗ [15]), in
which robots plan one at a time while respecting plans
that have already been calculated. To limit the influence of
the previous robots on the following robots, a windowed
HCA∗ is introduced to restrict this influence based on a
pre-specified window size [15]. Recently, an extension of
WHCA∗ (CO-WHCA∗ [2]) is introduced to further reduce
this influence based on the notion of conflicts. Although
many problem instances can be solved efficiently, optimistic
decoupling in these approaches leads to the loss of optimality
and completeness.
One of the earlier approaches that performs decoupling
while maintaining optimality and completeness relies on
pessimistic decoupling [16], which couples robots when
any conflicts are detected in their entire individual plans.
As a result, this approach tends to over-couple and hence
remains intractable for many problem instances. More recent
approaches relax optimality to achieve better efficiency [9],
[4], [17]. However, to maintain completeness, these approaches assume access to global information and therefore
are inapplicable to distributed systems in which robots have
limited sensing and communication range.
While there are extensible approaches to distributed systems (e.g., [7]) and approaches that are designed for distributed systems (e.g., [10], [3]), they do not provide completeness guarantees. The difficulty lies in planning without
access to global information, which is addressed in [21].

III. D IS C O F
In this section, we provide the problem formulation and
review DisCoF [21]. Extensions to DisCoF (i.e., DisCoF+ )
are discussed in Section IV.
A. Problem Formulation
Given an undirected graph G(V, E), and a set of robots R,
the initial locations of the robots are I ⊆ V , and the goals
are G ⊆ V . Any robot can move to any adjacent vertex in
one time step or remain where they are. A plan P is a set
of individual plans of robots, and P[i] denotes the individual
plan for robot i ∈ R. Each individual plan is composed of a
sequence of actions. For simplicity, in this paper each action
is represented by the next vertex to be visited. For example,
Pk [i] (k ≥ 1) denotes the action to be taken at time step
k − 1 (or the vertex to be visited at k) for robot i. Pk,l [i]
(k ≤ l) denotes the subplan that contains the actions from
Pk [i] to Pl [i]. The goal of cooperative pathfinding is to find
a plan P, such that robots start in I and end in G without any
conflicts (defined below). The location of robots at time step
k is denoted by Sk , and the location of robots after executing
plan P from location S is denoted by S(P). Hence, S0 = I,
S0 (P) = G, and Sk = S0 (P1,k ). A conflict happens at time
step k, if the following is satisfied:
Sk [i] = Sk [j] ∨ (Sk [i] = Sk−1 [j] ∧ Sk−1 [i] = Sk [j]) (1)
in which i ∈ R, j ∈ R and i 6= j. If two robots move to
the same place at time k, the first condition holds. If two
robots switch their locations in two consecutive time steps
from k − 1 to k, the second condition holds. Figure 1 shows
the first condition.
Each robot has a planner that can compute a shortest path,
P (u, v), that moves a robot from vertex u to v. The length of
P (u, v) is denoted as C(u, v), i.e., C(u, v) = |P (u, v)|. The
following simplifying assumptions are also made in DisCoF:
1) Robots are homogeneous and equipped with a communication protocol for message relay.
2) Robots know G and are synchronized at every time step.
Initially, for each robot i, the individual plan is constructed
as P[i] = P (I[i], G[i]). Robots then start executing their
individual plans until conflicts can be predicted (i.e., predictable conflicts in [21]) at time step k. In such cases, the
individual plans of robots that are involved are updated from
Pk+1 to avoid these conflicts.
B. Optimistic Decoupling
In DisCoF, the window size corresponds to the sensing
range of the robot. To reduce communication, a robot is
allowed to communicate with other robots when it can sense
them. However, robots that cannot sense each other can
communicate using the message relay protocol through other
robots. A closure of the set of robots that can communicate
(directly or via message relay) in order to coordinate is called
an outer closure (OC). In an OC, there can be multiple
predictable conflicts. A closure that contains agents with

r1
r2
r2

r2,r3

r2

r2,r3

r2

r2,r3,
r4

r2,r3

r3

r3,r4

r3,r4

r1

r1

r1

r1
r1

r2
r3,r4

r4

r4

r4

Fig. 1. [21]: Scenario that illustrates OC and IC. Two OCs are present {r1 }
and {r2 , r3 , r4 }, out of which one has an IC {r3 , r4 } with a predictable
conflict. The sensing ranges of the robots are shown in gray. The arrows
show the next few steps in the individual plans.

potential conflicts is the inner closure (IC) of the OC. Figure
1 shows an example of OC and IC. For details, refer to [21].
In DisCoF, decoupling is optimistic initially, and gradually
becomes more pessimistic during the online planing process
when necessary. Given an OC with predictable conflicts, in
optimistic decoupling DisCoF updates the individual plans of
robots to proactively resolve these conflicts, while avoiding
introducing new conflicts within a finite horizon (which is
specified by a parameter in DisCoF). The finite horizon is key
to efficiency since the resolution for conflicts in the far future
is likely to waste computation efforts given the incomplete
information (e.g., other robots in the environment). Note that
the window size (i.e., sensing range) in DisCoF represents a
horizon for detecting conflicts.
To ensure that robots are jointly making progress towards
their goals, DisCoF uses the notion of contribution value.
In order to resolve conflicts, plans are updated in a process
known as conflict resolution. In this process, each robot is
associated with a contribution value when using optimistic
decoupling. If this process is successful, robots continue
as fully decoupled. The contribution value is also used to
determine cases when optimistic decoupling is insufficient,
in which the resolution process would fail due to potential
live-locks. When there are no potential live-locks, it is shown
that optimistic decoupling is sufficient for robots to converge
to their goals. Otherwise, robots within the OC use the
following pessimistic decoupling process.
C. Pessimistic Decoupling
In DisCoF, when there are potential live-locks, robots
within an OC transition to pessimistic decoupling by remaining within each other’s communication range (whether direct
or indirect). These robots are referred to as a coupling group,
and this coupling group executes a process known as push
and pull, which allows it to merge with other groups and
robots. Thus, the level of coupling gradually increases. In
this way, DisCoF can naturally transition robots to be fully
coupled when necessary.
In push and pull, robots move to goals one at a time
according to the priorities of subproblems (first introduced

in [4]). However, due to the incompleteness of information
in distributed systems, the priorities will not be fully known.
As a result, DisCoF employs the following process. At time
step k, for each coupling group that has been formed, DisCoF
will:
1) Maintain robots in the group within each other’s communication range;
2) Move robots to goals one at a time based on a relaxed
version of the priority ordering, which is consistent to
that in [4];
3) Add other robots or merge with other groups that
introduce potential conflicts with robots in the current
group as they move to their goals.
Unless there are potential conflicts, each coupling group
progresses independently of other robots and coupling
groups. These processes are described in Alg. 1:
Algorithm 1 Pessimistic Decoupling in DisCoF for a coupling group ω, given the current time step k, the environment
G, current locations S and goal locations G
1: r ← ⊥
. Initialize the leader robot r
2: while ∃i ∈ ω s.t. Sk [i] 6= G[i] do
3:
hψ, φi ← S ENSE C ONFLICT (P , ω, S , k, W )
4:
if ψ = ∅ then
5:
k ←k+1
. Increase the time step by 1
6:
G0 ← hG, ω, S, Gi
7:
hS, P, Wi ← P ROCEED O NE S TEP(G0 , P, k)
8:
else
9:
ω ←ω∪ψ
. Merge conflict robots with ω
10:
hf, Di ← A SSIGNAGENTS T O S UB P(G, ω, S, G)
11:
H ← COMPUTE P RIORITY (G, ω, f , D, S, G)
12:
r←⊥
13:
if r = ⊥ ∨ Sk [r] = G[r] then
14:
r ← R EMOVE F ROM Q UEUE (H )
0
15:
G ← hG, ω, S, Gi
16:
P 0 ← P USH A ND P ULL (G0 , r)
17:
P ← P [0 : k] + P 0 [:] . Update a set of plans for ω
Alg. 1 continues until all members in a coupling group ω
reach their final goals. The termination condition is checked
in line 2. As long as there exists a robot that has not reached
its goal, the algorithm will continue with push and pull. In
Alg. 1, r represents the leader of the group ω. We remark that
there can be cases in which a robot that has already reached
its goal may block the path of the leader r. In this case, push
and pull will swap or rotate (similar to the operators in [4])
robots that have not reached their goals with this blocking
robot in order to progress. Push and pull also ensures that
this blocking robot moves back to its goal afterwards.
In [21], we proved that the combination of optimistic and
pessimistic decoupling in DisCoF guarantees completeness2 .
2 DisCoF is complete for the class of cooperative pathfinding problems
in which there are two or more unoccupied vertices in each connected
component, which is an extension of results in [4].

IV. D IS C O F+
In this section, we discuss the extensions to DisCoF that
are made in a new approach named DisCoF+ . First, we relax
the assumption that robots synchronize at every time step
(or plan step). Note that even though robots in different OCs
cannot communicate in DisCoF, it is assumed that robots
act in synchronized time steps (i.e., robots are given a fixed
amount of time to finish planning and execute a single action
at every time step). The relaxation of this synchronization is
necessary for implementation with real distributed systems,
since we cannot always assume the existence of a global
clock and a fixed amount of time for each time step (e.g., the
time required for planning for each robot may be arbitrarily
different). We remark that each robot can still access the
entire map. We can assume that this information is static such
that it is initially given and does not change at all. However,
each robot cannot recognize where other robots are if they
are out of (indirect) communication and sensing range. This
information is dynamic such that it changes arbitrarily.
Furthermore, we introduce a new decoupling strategy
such that robots are also allowed to decouple after they
form a coupling group (i.e., executing push and pull), thus
transitioning back to optimistic decoupling from pessimistic
decoupling. This strategy is expected to make DisCoF+
more computationally efficient while achieving higher quality plans that require fewer steps.
A. Asynchronous Time Steps
Unlike DisCoF, DisCoF+ allows robots in different OCs to
proceed in dependently and asynchronously. However, robots
within the same OC are assumed to still have synchronized
plan steps. This is a reasonable assumption because these
robots communicate to coordinate with each other. As a
result of this assumption, robots who finish their current plan
step must wait until all others in the OC also finish theirs.
Afterwards, all members of the group start the next plan
step at the same time in order to avoid unnecessary conflicts.
We remark that since we assume homogeneous robots, the
waiting time at each time step is not significant 3 .
We will explain the difference between DisCoF+ algorithm described in Alg. 2 and DisCoF. In DisCoF+ , each
robot i ∈ R runs the algorithm in Alg. 2. In line 6, if
there is no conflict sensed in the current location S[i] and
local window W (i.e., a fixed region around S[i]) of robot
i, such that the IC ψ is empty, robot i can proceed one
step (P ROCEED O NE S TEP) forward in its plan P . Afterwards,
robot i continues to the next iteration. On the other hand, if a
conflict is sensed such that the IC ψ is not empty, robot i tries
to resolve the conflict after checking if it is already involved
in any conflicts at line 14. If it is not involved in any conflict
(i.e., it was executing its plan independently),4 it forms a
local coupling ω. It first tries to decouple optimistically
3 Heterogeneous robots may have difference in speed, sensing & communication range and each robot’s size, etc. Considering these issues and
resolving them are beyond this paper.
4 The process when robot i is already involved in a conflict is more
involved. Refer to Alg. 2 for details.

Algorithm 2 DisCoF+ with asynchronous time steps for a
robot i ∈ R, given the environment G, its initial location I,
final destination F and initial plan P from I to F ; γ denotes
the contributions values
1: hψ, φ, ω, S[:], G[:], γ[:], ki ← h∅, ∅, ∅, ∅, ∅, 0, 0i
2: hS[i], G[i]i ← hI, F i
3: G0 ← hG, ω, S, Gi
4: hS, P, Wi ← P ROCEED O NE S TEP (G0 , P, i, k)
5: while True do
6:
hψ, φi ← S ENSE C ONFLICT(P, i, S, k, W)
7:
if ψ = ∅ then
8:
k ←k+1
. Increase the time step k by 1
9:
G0 ← hG, ω, S, Gi
10:
hS, P, Wi ← P ROCEED O NE S TEP(G0 , P, i, k)
11:
G0 ← hG, ω, S, Gi
. Update G0 with new S
12:
hγ, ω, P i ← R ECOMPUTE C ONT(G0 , P, i, k, γ)
13:
else
14:
if ω 6= ∅ then
15:
ω ←ω∪φ
. Merge ω with OC φ
16:
G0 ← hG, ω, S, Gi
17:
P 0 ← P USH A ND P ULL(G0 , i, γ)
18:
else
19:
ω←ψ
. Set ω to IC ψ
20:
G0 ← hG, ω, S, Gi
21:
P 0 ← C ONVERGENCE(G0 , i, k, φ, P, W, γ)
22:
if |P 0 | = 0 then
23:
ω←φ
. Set ω to OC φ
24:
G0 ← hG, ω, S, Gi
25:
P 0 ← P USH A ND P ULL(G0 , i, γ)
26:
P ← P [0 : k] + P 0 [:]

through C ONVERGENCE. If it cannot find a plan P 0 , then
it decouples pessimistically through P USH A ND P ULL. After
finding a plan P 0 , it continues to the next iteration to sense
if there are new conflicts. We remark that our description of
P USH A ND P ULL in Alg. 2 is simplified to show the overall
process. Once P USH A ND P ULL returns a new plan P 0 in Alg.
2, it contains the individual plan for robot i to move from
its location at the time step k to its goal.
Correctness: For Alg. 2, we need to show that whenever
there is a conflict, it always returns a valid plan. If there is
a conflict, in line 14, robot i checks if it is already involved
in a conflict (with ω). If ω 6= ∅ (i.e., it is already involved
in a conflict), we merge the OC (i.e., φ in Alg. 2) with ω,
and then call P USH A ND P ULL for i. In line 22, if P 0 is not
empty, it means that C ONVERGENCE returns a new plan P 0 .
If P 0 is empty, then robot i calls P USH A ND P ULL. In both
cases, the returned plan P 0 is either from C ONVERGENCE
or P USH A ND P ULL. We have shown that C ONVERGENCE or
P USH A ND P ULL always returns a valid plan in [21].
We remark that P ROCEED O NE S TEP always results in the
robot proceeding one step forward in its plan. If robot i has
already reached its final goal (while there are robots that still
need to reach their goals), proceeding one step in this case
simply adds a step for robot i to stay. However, note that

when robot i blocks other robots after reaching its goal, its
plan can be updated by these other robots (i.e., forcing robot
i to move off its goal temporarily).
B. Communication and Leader Selection
There are two major cases in which robots communicate
with each other in DisCoF+ . One is to detect predictable
conflicts, and another is to synchronize planning and plan
execution within the same OC. Given a robot i ∈ R, detecting predictable conflicts, performed by S ENSE C ONFLICT,
requires the following steps:
1) Check nearby environment (i.e., W) through a sensor
for other robots (e.g., a laser sensor);
2) Compute the OC φ of robot i;
3) Communicate with robots in φ to obtain their plans,
then check if predictable conflicts exist among them;
In the above process, the first step does not require any
communication between robots; it only depends on sensors.
Since robots know the environment (i.e., G), they can easily
detect when there are moving robots nearby using range
sensors. The second step requires to use the message relay
protocol to compute the OC φ. In the third step, once robot i
obtains all the plans of robots in φ, it can check these plans
against its own plan for predictable conflicts (from its current
time step to the next β steps [21]). If conflicts are found with
robot i’s plan, it forms a IC ψ with the conflicting robots,
and then it communicates this back to the robots in the IC
ψ. Furthermore, while creating a new plan for robots in IC
ψ (i.e., C ONVERGENCE), this plan must respect the plans
of other robots in the OC φ of this IC. When such a plan
cannot be found, the set of conflicting robots (ψ initially) is
expanded to include other robots in φ (which are not initially
in ψ).
Example 1 (Sensing Conflicts): Consider the scenario in
Fig. 1. In this scenario, assume that robot r4 is robot i
in the above procedure, so r4 tries to sense a predictable
conflict. r4 first senses its nearby environment for other
robots. In Fig. 1, the local window or the sensing range
of r4 (denoted by W) is shown as the gray region marked
with r4 , and r4 will detect r3 . r4 then computes the OC
φ as {r4 , r3 , r2 }. Since r2 is not r4 ’s local window, r3 will
relay the communication between r2 and r4 . Once r4 obtains
both r2 and r3 ’s plans, it will check their plans against
its owns plan for predictable conflicts. In this scenario, r4
will recognize a predictable conflict with r3 , which can be
addressed using C ONVERGENCE.
4
In the above procedure, the leader who computes the
new plan is the robot who first detects the conflict. Next,
the leader tries to resolve the conflict in the IC ψ with
C ONVERGENCE. If it cannot find a new set of plan (i.e., P 0
in Alg. 2) through C ONVERGENCE, it will continue through
P USH A ND P ULL with the OC φ for the IC ψ. In such cases,
we need to choose a new leader (i.e., the robot that moves to
its goal first), which is based on the priorities of subproblems.
The second major case for communication is for synchronized planning and plan execution in an OC. This is achieved
by P ROCEED O NE S TEP. Note that robots in different OCs

proceed independently and asynchronously. Since planning
and plan execution are synchronized within an OC, it guarantees that no collision can occur among robots in the OC.
In P ROCEED O NE S TEP, each robot asks if other robots have
finished the execution of their current plan step. Once every
robot has finished its current plan step, robots can proceed to
the next step. This requires robots to delay executing the next
step until they receive responses from other robots. However,
When robots move out of the communication range, they do
not synchronize their plan steps anymore.
C. Flexible Decoupling
Flexible decoupling is achieved with the help of contribution values. Contribution values are assigned in DisCoF
to each robot in the C ONVERGENCE process (in optimistic
decoupling), in which the robots must compute an update
to the current plan to avoid potential conflicts. Contribution
values are introduced in DisCoF to ensure that robots are
jointly making progress to their goals. In DisCoF, when the
C ONVERGENCE process fails, robots should be in a coupling
group, running on the plan computed by P USH A ND P ULL
until they reach their goals. In DisCoF+ , however, robots
that are executing P USH A ND P ULL can again decouple by
checking whether certain conditions involving the contribution values hold.
Next, we discuss the new decoupling strategy in DisCoF+ ,
which is illustrated in the following example. Suppose that
a conflict is predicted between two robots. Then, an IC ψ
(initially including only the two robots) can be formed and
there is an associated OC φ for ψ. During the C ONVER GENCE process, when the leader of ψ makes a new plan,
the set of conflicting robots can gradually expand (until
becoming φ) if the leader cannot find a new plan that avoids
the conflict with the current set of conflicting robots, which
is initially ψ. When a new plan is found, DisCoF+ associates
each robot with a contribution value γ, which captures the
individual contribution of the robot to the summation of
shortest distances from all robots’ current locations to their
goal locations.
At the very beginning of a problem instance, the contribution value γ is initialized to be 0 for all robots. Given a
predictable conflict at time step k, a set of conflicting robots
φ and a set of current locations Sk for φ, a set of goal
locations G, the new plan Q (where |Q| < β ∈ N) should
satisfy the followings:
X
X
C(Sk [i], G[i]) + γk− [i] >
C(Sk [i](Q[i]), G[i]) (2)
i∈φ

i∈φ

∀i ∈ φ, ¬∆ik

(3)

where γk− [i] is the contribution value that is associated
with robot i at the time step k, ∆ik is a Boolean variable
representing whether there is a conflict which is computed
based on the updated individual plans and Sk [i](Q[i]) is the
local goal for i ∈ φ.
We remark that while k in Eq. (3) is a constant in DisCoF,
in DisCoF+ , k represents the synchronized current time step

for the group of robots within φ, which can be different
from different OCs. However, note that planning and plan
execution are synchronized within φ until one of robots
reaches its goal location. If it reaches its goal location, then
it is removed from the group, not being maintained within
the communication range anymore.
An interesting point of Eq. (3) is that the new plan Q may
not satisfy Eq. (2) during the execution of Q, as long as Eq.
(2) is satisfied after Q has completed. Q basically specifies a
local goal for the robots to reach prior to resuming following
their original shortest-path plans again. Then, the potential
conflicts are avoided in the process. Given a predictable
conflict at the current time step and a computed Q, the
contribution value γ while executing the actions in Q is
updated for robot i in φ as follows:
γk+δ [i] = C(Sk [i](Q[i]), G[i]) − C(Sk+δ [i], G[i])

g3

g1

I2

r1

r3

r2

I1

g2

Fig. 2. Yellow circles are robots and red circles are their goal locations.
Blue dashed square represents a coupling group of robot r1 and r3 . This
group meets another robot r2 moving in the opposite direction. Gray cells
represent the intersections of corridors.

(4)

where 0 ≤ δ ≤ |Q|. We remark that δ is a relative time
step after the robots have formed an OC. For all robots in a
group, δ is the same. This update continues until the robot
become involved in other conflicts or the value becomes 0.
In DisCoF [21], the contribution value γ is only used
for the C ONVERGENCE process, and robots do not update
their contribution values when a coupling group is formed
and robots start P USH A ND P ULL. This can lead to inefficient
behaviors, e.g., when the leader’s goal location is located
opposite to where the others’ goals are located. This
situation is illustrated in the following example.
Example 2 (Narrow Corridor): Figure 2 shows an example of robot r2 in a narrow corridor meeting with a coupling
group {r1 , r3 } (executing P USH A ND P ULL) moving in the
opposite direction. The coupling group {r1 , r3 } started in
the middle corridor, and then r1 became the leader. While
r1 pushes r3 to clear away of its path to its goal location
g1 , it meets r2 . In this case, they will be merged together.
Suppose that r1 is chosen to be the leader of the new group
{r1 , r2 , r3 }. Until r1 reaches its goal location g1 , r2 and r3
will be pushed to the end of the middle corridor and then
they will be pulled after the intersection i1 .
4
In DisCoF, the only way to reduce the size of a coupling
group is to have the current leader reach its goal. Then, a
new leader will be selected and the remaining robots will
follow the new leader to its goal. This is clearly an inefficient
solution. In DisCoF+ , we use the contribution values γ
also in P USH A ND P ULL, such that robots can decouple even
before the leader reaches its goal.
Next, we discuss how the contribution values can be used
in the P USH A ND P ULL process. More specifically, we provide a decoupling condition for a coupling group to check,
which determines when the robots in the group can decouple
while executing the P USH A ND P ULL process. Suppose that
there is a coupling group ω. After ω computes a new plan
P 0 (in P USH A ND P ULL), each robot in ω will progress using
the plan. During this execution, robots continue recomputing
their contribution values γ as in Eq. (4). At any step, if the

following condition holds, then the group can be decoupled:
X
X
C(Sk [i], G[i]) + γk− [i] >
C(Sk+δ [i], G[i])
(5)
i∈ω

i∈ω

where k is the time step when P USH A ND P ULL starts planning and k + δ is the current time step such that 0 < δ ∈ N.
C(Sk [i], G[i]) is the length of the shortest-path from location
Sk [i] (where conflicts were predicted) to the goal location
G[i] for each robot i ∈ ω. γk− [i] is the contribution value
that robot i ∈ ω had before the conflicts were predicted.
C(Sk+δ [i], G[i]) is the length of the shortest-path from the
current location Sk+δ [i] to the goal location G[i] for each
robot i ∈ ω.
Intuitively, Eq. (5) is the condition when the summation of
the length of the shortest-path from robots’ current locations
to their goal locations is less than the summation of the
length of the shortest-path from their original coupling
locations to their goal locations plus their contribution values
just before forming the coupling group.
In Alg. 2, Eq. (5) is checked inside of R ECOMPUTE C ONT.
If the condition holds, then the algorithm returns a new plan
P (i.e., a shorted-path plan) with an empty coupling group ω.
Otherwise, the algorithm returns the current plan P without
changing the coupling group ω.
Example 3 (Decoupling): In Fig. 2, when the coupling
group {r1 , r3 } is merged with r2 , then conflict locations
for {r1 , r2 , r3 } and the contribution values (i.e., γ) are saved.
For a simple illustration, assume that γ = 0. Then, whenever
the merged group of robots {r1 , r2 , r3 } proceed one time
step in their plan (which is returned by P USH A ND P ULL),
they also check the decoupling condition in Eq.(5) in R E COMPUTE C ONT . However, until the leader r1 reaches its
goal location g1 , they cannot be decoupled. This is because
the summation of the distance between robots’ locations to
their goal locations keeps increasing. When r1 reaches its
goal location g1 , r1 is removed from the group. Assume that
r2 is elected as a new leader of the group. Then, r3 will
be pulled until they reach the conflict location where they
met previously. (See the place where they are placed in the

Fig. 2) After passing the conflict location, r3 and r2 can
be decoupled since Eq. (5) holds. Consequently, from the
intersection I2 , r2 and r3 can move independently to their
goal locations.
4
When a coupling group is decoupled and it immediately
predicts a conflict in the next iteration, it uses the conflict
resolution process through C ONVERGENCE, just as when
fully decoupled robots have predicted conflicts. Even though
we discussed the correctness of DisCoF+ (Alg. 2), we also
need to show that this new decoupling strategy is not subject
to live-locks (i.e., robots are always making joint progress
to the goals).
Theorem 4.1: The decoupling condition in Eq.(5) ensures
that robots in the group gradually progress to their final goals.
Proof: From Eq. (2) and Eq. (4), we know that each
robot in the group gradually moves towards its final goal.
Here, we show that Eq. (5) does not prevent any group
member from reaching its goal. Given that we use the
contribution value γk− when a coupling group is formed,
in order to satisfy Eq. (2) when decoupling, either robots
can all execute their original plans or C ONVERGENCE must
return a new plan which progresses robots to their local
goals. First, their original plans definitelly make progress.
Second, consider the case when it takes the new plan from
C ONVERGENCE. After progressing through the new plan,
all the robots in the group will reach their local goals.
Then, the summation of the distance from their current
locations (which are their local goals) to their final goals
is smaller than the summation of the distance from their
locations (where they predicted the conflicts) to their final
goals plus their contribution values γ before forming the
coupling group. Hence, we can conclude that robots would be
making joint progress to their goals. Hence, the decoupling
condition Eq. (5) does not prevent the group members from
progressing to their final goals.
V. RESULTS
In this section, we will show experimental results. First,
we will show a simulation result. Second, we will provide a
result of numerical experiments.
A. Simulation Result
The simulation shown in Fig. 3 was created using Webots 7.3.0 and the included iRobot Create models. A grid
environment was modelled which contained 30 iRobots and
40 obstacles placed at random (but solvable) locations. Each
iRobot was running with a controller which implemented
DisCoF+, however, one exception was made. Rather than
being completely distributed and simulating ad hoc networks
and localization, the robots communicated with a central
supervisor which provided this information as well as synchronization for robots involved in a conflict. Robots in
different outer closures acted completely asynchronously, but
robots in the same outer closure were synchronized if a
conflict was detected between any of the member robots.
Ultimately, this concession will be replaced with simulated

Fig. 3. Simulation environment represents a 20 × 20 grid world with
10% wooden box obstacles. In this environment, there are 30 iRobot Create
finding their path to their goal positions.

sensors and a fully distributed environment, but for now it
still provides valuable results.
The target computer for the simulation was a MacBook
Pro running Mac OS X 10.10.2 with a 2.3GHz i7 and
16GB of RAM. The simulation was run two times: once
with decoupling enabled and once with decoupling disabled.
Decoupling enabled yielded a total simulation duration of
3 minutes and 23 seconds. Out of all robots, the maximum
number of steps required to reach its destination was 40.
Decoupling disabled yielded a total simulation duration of
5 minutes and 1 second. Out of all robots, the maximum
number of steps required to reach its destination was 54.
These results are interesting for two reasons: one is that
decoupling enabled performs significantly better, another
is the ratio of decoupling enabled vs decoupling disabled
simulation time compared to that of maximum steps. With
decoupling the simulation took 67% of the time and 74% of
the steps that decoupling disabled did. The reason for this
discrepancy is that with decoupling enabled there are more
stay actions in which a robots action is to stay where it is at.
Since robots are asynchronous except for when they are in
a conflict, this means robots will take less time to complete
a plan with stay actions compared to one that doesn’t. It
is expected that environments requiring more complex plans
will benefit from this fact even more.
We provide the demo video for this simulation. Refer the
videos to the following url: https://www.assembla.
com/spaces/discof/wiki/DisCoF_Plus.
B. Numerical Experiments
In order to evaluate the improvement of DisCoF+ over
DisCoF, we execute a number of numerical experiments.
For these experiments, we used a Core i7 CPU 3.2 Ghz
with 8GB memory and 240 GB SSD in Cygwin environment
which runs on Windows 8.1. Our prototype implementation
is written in Python 2.7.2.
Since we only want to get the total concurrent steps
and the computation time for these experiments, instead of
using Webots simulator, we used a simple discrete time
simulator which does not simulate the phisics of the robots
or any communication between the robots. Hence, we are
comparing the total number of steps and the computation
times between DisCoF and DisCoF+ .
As a result of this implementation, we compute an approximate running time by assuming that each robot move takes 5
seconds. Then, for each problem instance, the running time is

OBSTACLES
5%
10%
15%
20%

COMP.
AVG
10.064
13.19
17.6318
26.39

TIME
STD
8.405
10.372
13.296
14.009

DisCoF
STEPS
AVG
STD
352.35
356.207
521.1
521.24
653.67
580.01
954.46
620.08

APPROX. RUN TIME
AVG
STD
1771.815
1788.861
2618.69
2615.82
3285.982
2911.463
4798.691
3111.208

COMP. TIME
AVG
STD
10.733 (1.0086) 22.068 (0.931)
14.37 (1.061)
36.52 (1.538)
23.92 (1.217)
49.768 (1.3)
52.391 (1.942)
75.8 (2.3989)

DisCoF+ (DisCoF+ /DisCoF)
STEPS
AVG
STD
63.95 (0.4266)
80.632 (0.356)
73.51 (0.344)
108.93 (0.346)
99.18 (0.294)
157.356 (0.312)
175.9192 (0.2427) 218.859 (0.3132)

APPROX. RUN TIME
AVG
STD
330.483 (0.43)
423.885 (0.3555)
381.92 (0.348)
579.065 (0.348)
519.82 (0.3)
831.07 (0.314)
931.987 (0.2535)
1161.61 (0.3242)

TABLE I
N UMERICAL E XPERIMENTS : C OMP. T IME REPRESENTS THE TOTAL COMPUTATION TIME IN SECOND , S TEPS REPRESENT CONCURRENT TIME STEPS
FOR ENTIRE ROBOTS ’ PLAN , AND A PPROX . RUN T IME REPRESENTS APPROXIMATE RUNNING TIME IN SECOND . F OR C OMP. T IME , S TEPS AND
A PPROX . RUN T IME , D IS C O F AND D IS C O F+ HAVE AVERAGE AND STANDARD DEVIATION .

equal to the sum of the computation time and the maximum
number of moving steps for a robot times 5.
We show that the decoupling approach improves upon
the previous approach (DisCoF) in. In order to perform the
experimental analysis, instead of scaling up the number of
robots, we increase the density of the environment. That
is, we increase obstacle rates in the environment. Given
30 robots and 20 x 20 grid environment with their goal
locations and obstacles, the Table I shows the result. The
obstacle rates changed from 5% to 20%. For this test, we
randomly generated 100 instances for each obstacle rate.
Obstacle locations were also randomly chosen.
The time ratio in Table I indicates that if the environment
is less populated, then decoupling makes better quality plans
in terms of the total number of concurrent steps and the total
computation time of plans.
However, this result also shows an interesting property of
DisCoF+ . When the environment gets denser, the decoupling
method does not always reduce the total computation times.
This is because in dense environments groups that decouple
may have to recouple with a higher frequency. When it is
re-coupled, a group should make a new plan which requires
extra computation time. On average, DisCoF+ needed 34.4%
steps less than DisCoF’s result.
VI. CONCLUSIONS
In this paper, we introduced DisCoF+ which is an asynchronous extension of our previous work. We also introduced
a strategy of decoupling in DisCoF+ . Through simulations,
we showed how DisCoF+ works in a simulated grid environment to resolve predictable conflicts in a distributed fashion.
We also provided numerical experiments to compare DisCoF
with DisCoF+ . In moderately populated environments, the
decoupling approach shows bettered results than DisCoF.
In future work, we plan to devise different approaches for
the decoupling such as more strict decoupling conditions
and also a heuristic for ordering robots while performing
P USH A ND P ULL so that when at any point time a decoupling
occurs, the conflicts are minimized.
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers
for their detailed comments and suggestions.

R EFERENCES
[1] N. Ayanian, D. Rus, and V. Kumar. Decentralized multirobot control in
partially known environments with dynamic task reassignment. In 3rd
IFAC Workshop on Distributed Estimation and Control in Networked
Systems, 2012.
[2] Z. Bnaya and A. Felner. Conflict-oriented windowed hierarchical
cooperative A∗ . In Proceedings of the 2014 IEEE International
Conference on Robotics and Automation, 2014.
[3] C. Clark, S. Rock, and J.-C. Latombe. Motion planning for multiple
mobile robots using dynamic networks. In Proceedings of the IEEE
International Conference on Robotics and Automation, volume 3,
pages 4222–4227, Sep. 2003.
[4] B. de Wilde, A. W. ter Mors, and C. Witteveen. Push and rotate: Cooperative multi-agent path planning. In 12th International Conference
on Autonomous Agents and Multiagent Systems, 2013.
[5] V. R. Desaraju and J. P. How. Decentralized path planning for multiagent teams with complex constraints. Autonomous Robots, 32(4):385–
403, 2012.
[6] J. Hopcroft, J. Schwartz, and M. Sharir. On the complexity of motion
planning for multiple independent objects; pspace- hardness of the
”warehouseman’s problem”. The International Journal of Robotics
Research, 3(4):76–88, 1984.
[7] R. Jansen and N. Sturtevant. A new approach to cooperative pathfinding. In Proceedings of the 7th International Joint Conference on
Autonomous Agents and Multiagent Systems, AAMAS, pages 1401–
1404, Richland, SC, 2008. International Foundation for Autonomous
Agents and Multiagent Systems.
[8] L. Liu and D. A. Shell. Physically routing robots in a multi-robot
network: Flexibility through a three-dimensional matching graph. The
International Journal of Robotics Research, 32(12):1475–1494, 2013.
[9] R. Luna and K. Bekris. Efficient and complete centralized multirobot
path planning. In IEEE/RSJ Int. Conf. on Intelligent Robots and
Systems, 2011.
[10] M. Otte, J. Bialkowski, and E. Frazzoli. Any-com collision checking:
Sharing certificates in decentralized multi-robot teams. In Proceedings
of the 2014 IEEE International Conference on Robotics and Automation, 2014.
[11] L. E. Parker. Encyclopedia of Complexity and System Science, chapter
Path Planning and Motion Coordination in Multiple Mobile Robot
Teams. Springer, 2009.
[12] M. Peasgood, C. Clark, and J. McPhee. A complete and scalable
strategy for coordinating multiple robots within roadmaps. IEEE
Transactions on Robotics, 24(2):283–292, April 2008.
[13] M. Ryan. Graph decomposition for efficient multi-robot path planning.
In Proceedings of the 20th International Joint Conference on Artifical Intelligence, pages 2003–2008, San Francisco, CA, USA, 2007.
Morgan Kaufmann Publishers Inc.
[14] G. Sharon, R. Stern, A. Felner, and N. R. Sturtevant. Conflict-based
search for optimal multi-agent pathfinding. Artificial Intelligence,
219(0):40 – 66, 2015.
[15] D. Silver. Cooperative pathfinding. In Conference on Artificial
Intelligence and Interactive Digital Entertainment, 2005.
[16] T. Standley. Finding optimal solutions to cooperative pathfinding
problems. In AAAI Conference on Artificial Intelligence, 2010.
[17] T. Standley and R. Korf. Complete algorithms for cooperative
pathfinding problems. In Proceedings of the 22nd International Joint
Conference on Artifical Intelligence, 2011.
[18] N. Sturtevant and M. Buro. Improving collaborative pathfinding using
map abstraction. In Artificial Intelligence and Interactive Digital
Entertainment (AIIDE), pages 80–85, 2006.

[19] K. C. Wang and A. Botea. Fast and memory-efficient multi-agent
pathfinding. In International Conference on Automated Planning and
Scheduling, pages 380–387, 2008.
[20] J. Yu and S. M. LaValle. Multi-agent path planning and network flow.
In Algorithmic Foundations of Robotics X, volume 86, pages 157–173.
Springer, 2013.
[21] Y. Zhang, K. Kim, and G. Fainekos. Discof: Cooperative pathfinding
in distributed systems with limited sensing and communication range.
In to appear in International Symposium on Distributed Autonomous
Robotic Systems, 2014.

2007 IEEE International Conference on
Robotics and Automation
Roma, Italy, 10-14 April 2007

ThDll.5

Where's Waldo?
Sensor-Based Temporal Logic Motion Planning *
Hadas Kress-Gazit, Georgios E. Fainekos and George J. Pappas
GRASP Laboratory, University of Pennsylvania
Philadelphia, PA 19104, USA
{hadaskg,fainekos,pappasg} @grasp.upenn.edu

Abstract- Given a robot model and a class of admissible
environments, this paper provides a framework for automatically and verifiably composing controllers that satisfy high
level task specifications expressed in suitable temporal logics.
The desired task specifications can express complex robot
behaviors such as search and rescue, coverage, and collision
avoidance. In addition, our framework explicitly captures
sensor specifications that depend on the environment with
which the robot is interacting, resulting in a novel paradigm
for sensor-based temporal logic motion planning. As one robot
is part of the environment of another robot, our sensor-based
framework very naturally captures multi-robot specifications.
Our computational approach is based on first creating discrete
controllers satisfying so-called General Reactivity(1) formulas.
If feasible, the discrete controller is then used in order to guide
the sensor-based composition of continuous controllers resulting in a hybrid controller satisfying the high level specification,
but only if the environment is admissible.
Index Terms- Motion planning, temporal logics, sensorbased planning, controller synthesis, hybrid control.
I. INTRODUCTION

Motion planning and task planning are two fundamental
problems in robotics that have been addressed from differen
perspectives. Bottom-up motion planning techniques concentrate on creating control inputs or closed loop controllers for
detailed robot models that steer it from one configuration to
another [1], [2]. Such controllers can either assume perfect
knowledge of the environment [3] or receive information
about the environment through the use of sensors [4]. On the
other hand, top-down task planning approaches are usually
focused on finding coarse, typically discrete, robot actions
in order to achieve more complex tasks [5]. Such goals
may include final goals for multiple robots [6] or temporal
ordering or sequencing of goals [7].
The natural hierarchical decomposition of task planning
layers residing higher than motion planning layers has resulted in a lack of approaches that address the integrated
system, until very recently. The modern paradigm of hybrid systems, coupling continuous and discrete systems,
has enabled the formal integration of high level discrete
actions with low level controllers in a unified framework.
This has inspired a variety of approaches that translate high
level, discrete tasks to low level, continuous controllers in
a verifiable and computationally efficient manner [8]-[10]
*This work is partially supported by National Science Foundation EHS
0311123, National Science Foundation ITR 0324977, and Army Research
Office MURI DAAD 19-02-01-0383.

1-4244-0602-1/07/$20.00 ©2007 IEEE.

or compose local controllers in order to construct global
plans [11]-[13].
This paper follows the spirit of our previous work [8],
[9] where complex task specifications are expressed as
linear temporal logic formulas [14]. However, this paper
contributes in two very significant and novel directions. The
first novelty is that the temporal logic we consider explicitly
models sensor inputs. This enables our task descriptions to
depend on possibly dynamic environment, capturing multirobot search and rescue style missions. In a multi-robot
setting, one robot is part of the environment of another robot,
hence it is very natural to consider a variety of other multirobot missions as well. The interpretation or execution of
such tasks has a very natural game-theoretic flavor between
the robot and the environment (or other robots). Depending
on the the environment, the execution of the task may be
different, but it will satisfy the task if the environment is
admissible.
The second novelty in this paper is the use of a very recent
fragment of linear temporal logic which is called General
Reactivity (1) (GR(1)) [15]. By restricting to GR(1) formulas, the complexity of translating a formula to an automaton
becomes polynomial (from double exponential in the size
of the formula). This dramatic acceleration in computation
does not come at a major expense of expressivity, as a large
number of (but not all) tasks specified in practice is naturally
captured in the fragment of interest.
As in [8], [9], the solution of the discrete synthesis algorithm is integrated with the controllers in [11] resulting in an
overall hybrid controller that is orchestrating the composition
of low level controllers based on the sensorial interaction
with the environment. The overall closed loop system is
guaranteed, by construction, to satisfy the desired specification but only if the robot operates in an environment that
satisfies whatever assumptions that were explicitly modeled,
as another temporal logic formula, in the synthesis process.
This leads to a very natural assume-guarantee decomposition
between the robot and its environment.
II. PROBLEM FORMULATION
The goal of this paper is to construct controllers for
mobile robots that generate continuous trajectories satisfying
given specifications. Furthermore, we would like to achieve
such specifications while interacting, using sensors, with a
variety of environments. To achieve this, we need to specify

3116

ThDll.5

a robot model, assumptions on admissible environments, and
the desired system specification.
Robot Model: We will assume that a mobile robot (or
possibly several mobile robots) is operating in a polygonal
workspace P. The motion of the robot is expressed as

III. TEMPORAL LOGICS
Loosely speaking, Linear Temporal Logic (LTL) [14] consists of the standard propositional logic with some temporal
operators that allow us to express requirements on sequences

p(t) = u(t) p(t) C P C R2 u(t) C U C R2

A. LTL Syntax and Semantics
Syntax: Let AP be a set of atomic propositions. In our
setting AP = X U Y, including both sensor and system
propositions. LTL formulas are constructed from atomic
propositions 7 C AP according to the following grammar:

(1)

where p(t) is the position of the robot at time t, and u(t) is
the control input. We will also assume that the workspace
P is partitioned using a finite number of cells P,, . . . , P,
where P = U =Pi and Pi n Pj 0 if i t j. Furthermore,
we will also assume that each cell is a convex polygon.
The partition naturally creates boolean propositions Y =
{rl r2 .. ., rn} which are true if the robot is located in Pi,
for example rl is true iff p C P1. Since {Pi} is a partition
of P, exactly one ri can be true at any time.
Admissible environments: The robot interacts with its
environment using sensors, which in this paper are assumed to be binary. The m binary sensor variables X =
{Xl, X2, . * X*m} have their own (discrete) dynamics which
we do not model explicitly. Instead, we place high level
assumptions on the possible behavior of the sensor variables,
defining a class of admissible environments. These environmental assumptions will be captured (in Section III) by a
suitable temporal logic formula Se Our goal is to construct
controllers that achieve their desired specification not for any
arbitrary environment, but rather for all possible admissible

environments satisfying Y5e,
System Specification: The desired system specification for
the robot will be expressed as a suitable formula fo in the
so-called linear temporal logic (LTL) [14]. Informally, LTL
will be used (in Section III) to specify a variety of robot
tasks that are linguistically expressed as:
* Coverage: "Go to rooms P1,P2,P3,P4 in any order".
* Sequencing: "First go to room P5, then to room P2".
* Conditions: "If you see Mika, go to room P3, otherwise
stay where you are".
* Avoidance: "Don't go to corridor P7 ".
Furthermore, LTL is compositional, enabling the construction of complicated robot task specifications from simple
ones. Putting everything together, we can describe the problem that will be addressed in this paper.
Problem 1: [Sensor-based temporal logic motion planning] Given robot model (1), initial position p(U), and suitable temporal logic formula (,e modeling our assumptions on
admissible environments, construct (if possible) a controller
so that the robot's resulting trajectories p(t) satisfy the
system specification fo in any admissible environment.
The approach presented in the paper can be easily generalized to the case where the initial position of the robot is not
specified, but may belong in a number of cells.
In order to make Problem 1 formal, we need to precisely
define the syntax, semantics, and class of temporal logic
formulas that are considered in this paper.

of propositions.

0
V
0
lp ::=
0
As usual, the boolean constants True and False are defined
as True = o V -if and False = True respectively. Given
negation (-i) and disjunction (V), we can define conjunction
(A), implication (=>), and equivalence (X). Furthermore,
we can also derive additional temporal operators such as
"Eventually" O =Tr=ue L and "Always" Eo = O
Semantics: The semantics of an LTL formula o is defined
on an infinite sequence or of truth assignments to the atomic
propositions 7 C AP. For a formal definition of the
semantics we refer the reader to [14]. Informally, the formula
Ofo expresses that o is true in the next "step" (the next
position in the sequence) and the formula 901 U 02 expresses
the property that 9ol is true until 02 becomes true. The
sequence or satisfies formula E 9 if o is true in every position
of the sequence, and satisfies the formula Of if o is true
at some position of the sequence. Sequence or satisfies the
formula of if o is true infinitely often.
-

B. Special class of LTL formulas
Following [15], we consider a special class of temporal logic formulas. We first recall that we have divided
our atomic propositions into sensor propositions X =
X
and system propositions Y3 {r= , .. .., r} .
{x1 ...*m},
These special formulas are LTL formulas of the form
0 = ((pe ==>- (s). (Pe is an assumption about the sensor
propositions, and thus about the behavior of the environment,
and os represents the desired behavior of the system. Both
(Fe and os have the following structure

3117

o
(e= (7oi A (7o eA (7g

(a

=

fos A fos A (7os

where
* OeI, s - Non-temporal boolean formulas constraining
(if at all) the initial value(s) for the sensor propositions
X and system propositions Y respectively.
* ~e - represents the possible evolution of the state of the
environment. It consists of a conjunction of formulas
of the form EiBi where each Bi is a boolean formula
constructed from subformulas in X U Y U OX, where

OX

{x1*,... , QOx}. Intuitively, formula, fo'

constrains the next sensor values OX based on the
current sensor X and system Y values.
* s - represents the possible evolution of the state of
the system. It consists of a conjunction of formulas of

ThDll.5

generation of these formulas is easily automated. The final
subformula is part of the desired specification and states that
if the robot is in region P2 (or P4) and it sees Waldo when
he senses' it should remain in region P2 (respectively P4)
in the next step as well.

AD(rl X (Orl v Or2 V or4))
AD(r2 (Orl V Or2 V or3))
AD(r3 X (Or2 V Or3 V or4))
AD(r4 4 (Orl v Or3 v or4))

Fig. 1: The workspace of Example 1. The initial position
of the robot is marked with a star.

the form FIBi where each Bi is a boolean formula in

AE( (Or, A-Or2 A Or3 A Or4)

xuyuOxOy.

V(-Q
Orl A Or2 A Or3 A Q r4)
V(- Orl A -Or2 A Or3 A Q r4)

g,

og - represent goal assumptions for the environment
and desired goal specifications for the system. Both
formulas consist of a conjunction of formulas of the
form LOBi where each Bi is a boolean formula.
The formula Xq= (y =>4 y) which will be discussed in
section IV, is a Generalized Reactivity(]) (GR(1)) formula.

Despite the structural restrictions of this class of LTL
formulas, there does not seem to be a significant loss in
expressivity. Furthermore, the structure of the formula very
naturally reflects the structure of most sensor-based robotic
tasks. We illustrate this with a relatively simple example.
Example 1: Consider a robot that is moving in the
workspace shown in Fig. 1 consisting of four areas labelled P1,..., P4 (which define the system propositions Y =
{ .l... r4}). Initially, the robot is placed somewhere in
region P1. In natural language, the desired specification for
the robot is: Look for Waldo in regions P2 and P4, if you
find him, stay where you are, and if not, keep looking.
Since Waldo is part of the environment, we consider one
sensor proposition X {sWaldo} which becomes true if our
sensor has detected Waldo. Our assumptions about Waldo are
captured by C,pe = f` A fo` A yg. The robot initially does not
see Waldo, thus /p` (-IWasdo). Since we can only sense
Waldo in regions P2 and P4, we encode the requirement
that in other regions the value of sWaldo cannot change.
Furthermore, we assume (for simplicity) that once the robot
detects Waldo, Waldo doesn't move. These requirements are
captured by the formula
e

#
=> (OsWaldo >Waldo
A-r4)XoWaldo)
2(Waldo
(t =F AD((-r2

We place no further assumptions on the environment propo= -OTrue, completing the
sitions which means that Do
modeling of our environment assumptions. Notice that the
environment is admissible whether Waldo is there or not.
We now turn to modeling the robot and the desired
specification, captured by os = fos A fos A yo. Initially,
the robot starts somewhere in region rl, hence f s = (ri A
-1r2 A -r3 A -r4). fos models the possible changes in in the
robot state. The first four subformulas represent the possible
transitions between regions, for example, from region P1
the robot can move to adjacent regions P2, P4, or stay in
P1. The next four subformulas capture the mutual exclusion
constraint, that is at any step, exactly one of r1, r2, r3, and
r4 is true. For a given decomposition of workspace P, the

V(-QOrA-QOr2A-QOr3AOr4)
Aie{2.4} Lil( (ri A OsWaldo) = Qri )

k
Finally, the requirement that the robot keeps looking in
regions P2, P4 unless it has found Waldo is captured by

1,s = °F D(r2 V SWaldo) A ° (r4 V sWaldo)
This completes our modeling of the robot specification as
well. Combining everything together, we get the required
formula o= ((F,e 4=> s).
Having modelled a scenario using o, our goal is now
to synthesize a controller generating trajectories that will
satisfy the formula if the scenario is possible (if the formula
is realizable). This is the goal of the next two sections.
IV. DISCRETE SYNTHESIS
Given an LTL formula, the realization or synthesis problem consists of constructing an automaton whose behaviors
satisfy the formula if such an automaton exists. In general,
creating such an automaton is proven to be doubly exponential in the size of the formula [16]. However, by restricting
ourselves to the special class of LTL formulas, we can use
the efficient algorithm recently introduced in [15] which is
polynomial 0(n3) time, where n is the number of valuations
of the sensor and state variables. We present the algorithm
informally, and refer the reader to [15] for a full description.
The synthesis process is viewed as a game played between
the system (robot) and the environment (as the adversary).
Starting from some initial state, both the robot and the
environment make transition to the state of the system. The
winning condition for the game is given as a GR(1) formula
Q. The way the game is played is that at each step, first the
environment makes a transition according to its transition
relation and then the system makes its own transition. If the
system can satisfy X no matter what the environment does,
we say that the system is winning and we can extract an
automaton for our robot. However, if the environment can
falsify X we say that the environment is winning and the
desired behavior is unrealizable.
Relating the formulas of section Ill-B to the game mentioned above, the initial states of the players are given by fo'

'As explained in Section IV, at each step the robot first senses the
environment and then moves, therefore we need to refer to the truth value
of

3118

OsWaldo

ThDll.5

and yo'. The possible transitions the players can make are
given by ft and ft, and the winning condition is given
by the GR(1) formula X= (yo =#> y). Note that the
system is winning, i.e. X is satisfied if fo is true, which
means that the desired robot behavior is satisfied, or fo
is false, which means that the environment did not reach
its goals (either because the environment was faulty or the
system prevented it from reaching its goals). This implies
that when the environment does not satisfy fo there is no
guarantee about the behavior of the system. Furthermore, if
the environment does not "play fair", i.e. violates its assumed
behavior <o' A ft, the automaton is no longer valid.
The synthesis algorithm [15] takes the GR(1) formula o
and first checks whether it is realizable. If it is, the algorithm
extracts a possible (but not necessarily unique) automaton
which implements a strategy that the robot should follow in
order to satisfy the desired behaviour. The automaton that
is generated by the algorithm can be modeled as a tuple
A (X,Y,Q,qo,d,6>) where:
. X is the set of input (environment) propositions
Y3 is the set of output (system) propositions
Q c N is the set of states
* qo e Q is the initial state
. d: Q x 2- > 2Q is the transition relation, i.e.
6(q,X) = Q' C Q where q C Q is a state and X C X
is the subset of sensor propositions that are true.
* y: Q -> 2Y is the state labeling function where -y(q)
y and y C 2Y is the set of state propositions that are
true in state q. Note that in our case, since the only
outputs are the regions, and there is only one output
proposition that is true at every state, -y(q) = y C y.
Note that this automaton can be nondeterministic2. An admissible input sequence is a sequence X1, X2,. ,Xj C 2x
that satisfies Se A run of this automaton under an admissible
input sequence is a sequence of states or = qo,.ql,----This
sequence starts at the initial state and follows the transition
relation d and the truth values of the input propositions,
i.e. for all j > 0, qj+l C 6(qj, Xj). An interpretation of
a run or is a sequence yo, yi, ... where yi =Y(qi) is the
label of the jth state in the run. We use this sequence of
labels to construct the discrete path the robot must follow.
As mentioned before, when given a non-admissible input
sequence, i.e. an input sequence that violates any part of
(oe. the automaton is no longer relevant and we will not be
able to construct a correct path for the robot.
Example 2: Revisiting Example 1, Fig. 2 represents the
synthesized automaton that realizes the desired behavior.
The number at the top of each circle is the state and the
proposition that is written inside each circle is the state's
label, i.e. the output proposition that is true in that state.
We can see that the robot will first search P2 and then,
if it doesn't find Waldo, continue to search P4. If Waldo
is nowhere to be found, the robot will continue to look for
him forever. Note that this plan is not unique, since the robot
2By making a small change in the algorithm, the automaton may become
deterministic, i.e. for every input there will be a unique next state

could have started searching in P4. Furthermore, it is also
nondeterministic since the robot can go from state 2 to state
6 through either state 3 or 4.

Fig. 2: The synthesized automaton of Example 2
From the interpretation of a run of the automaton, we
extract a discrete path for the robot. What is left to do, is to
transform this discrete path to a continuous trajectory, as is
explained in the next section.
V. CONTROLLER COMPOSITION
In order to continuously implement the discrete solution
of the previous section, we construct a hybrid controller that
takes a set of simple controllers and composes them sequentially according to the discrete execution of the automaton.
Initially, the robot is placed in region io such that -4(qo) =
rio. During the execution, at step j > 1 the robot first
senses its environment3 and determines Xj. Then the next
automaton state is selected qj C 6(qj-1,Xj) and the next
region ij the robot must go to is extracted by ri3 = -Y(qj).
When the robot reaches region ij, step j + 1 is performed.
By continuing this procedure, the discrete path rio, ri,..
is extracted, and by combining the simple controllers, the
continuous path is achieved.
Following the work in [8], we utilize atomic controllers
that satisfy the so-called bisimulation property [17]. Such
controllers are guaranteed to drive the robot from one region
to another regardless of the initial state in the region.
There are several recent approaches for generating such
simple controllers, such as [11], [18].We use the framework
developed in [I I] due to its computational properties and the
variety of regions it can be applied to. In this approach, the
control input is the gradient of a harmonic potential function.
We would like to emphasize that this method can employ
different and more realistic types of controllers, dealing with
convex bodied robots and nonholonomic constraints [19], as
long as they satisfy the bisimulation property.
VI. CASE STUDIES
In this section we give several examples of desired behaviors, the automata that implement them and the trajectories
which they induce. The polygonal environment we use for
the examples is shown in Fig. 3. In the following we refer
to region Pi as region i.
3An implicit assumption is that the sensing is performed only when
entering a region. Another approach would be to check the sensor values
every computation cycle and allow the controller to change before exiting
the current region.

3119

ThDll.5

A. Single robot - Nursery scenario
The desired behaviour is: "Starting in region 1, keep
checking whether a baby is crying in regions 2 or 4. If you
find a crying baby, go look for an adult in regions 6, 7 and
8. Keep looking until you find him. After finding the adult,
go back to monitoring the babies and so on..."
We can define two environment propositions here, one indicating a crying baby was sensed and another indicating an
adult was found. In order to reduce the number of variables,
the computation time and the size of the automaton, we use
one environment proposition, CkBby, indicating whether the
robot should check on the babies (when the proposition is
true) or go look for an adult (when the proposition is false).
Initially CkBby is true. We assume that the proposition
becomes false in regions 2 and 4 if the robot senses a baby
crying and once it becomes false it stays false as long as it
is in 2 or 4 (a baby does not stop crying on her own and she
cannot be ignored). Furthermore, we assume that CkBby
becomes true in regions 6, 7 and 8 only if the robot sensed
an adult. Once it becomes true it stays true in these regions
(once the adult was found, the robot must return to check
on the babies). In all other regions, the truth value of the
proposition may not change.
Following these assumptions, we can construct We.:
CkBby

(((r2 V r4) A-CkBby) (- C CkBby)))
AE(((r6 V r7 V r8)A CkB by) - (CkBby)))
A (-(r2 Vr4Vr6Vr7Vr8)
VrVCkBbyr CkBby))
A g True
A

_o
=

As for the robot, we have ten system propositions

o,...,r, one for each region. Constructing y<:
rlr

(-1Ai=2r...10-1i
(Ps

ATransitions A Mutual Exclusion
AiC {2,4} °1(ri V --CkBby)

tAiEf6,788} g(riV CkBby)
The first and second lines encode the initial condition,
possible transitions and mutual exclusion requirement as in
Example 1. The rest of the formula describes the desired
behaviour, for example, the third line requires the robot to
infinitely often either visit region i, i {2, 4} or look for
an adult.
Runniing this example through the synthesis algorithm, the
computation time was 2 seconds and we got an automaton
with 41 states that realizes this specification. Sample simulations are shown in Fig. 4.

Fig. 3: The environment used

in section

VI.

X

8

I
L

=

18

(a) Babies are not crying

(b) A baby in region 4 cries and
the adult is in region 8

Fig. 4: Nursery Example

B. Multi robot- Search and Rescue
Our framework captures very naturally multi-robot scenarios where one robot becomes part of the environment
of another robot. In a natural decentrallized model, each
robot is tasked by it's own formula yi resulting in it's own
synthesized automaton. The coordination between robots can
be done using the input (sensor) propositions, as shown in
the following scenario.
In this search and rescue scenario, we employ two UAV's
that continuously search regions 1, 3, 7 and 8 for injured
people. Once an injured person was found, a ground vehicle
(ambulance) goes to the person's location and helps out.
If there are no reports of people needing help, the ground
vehicle does not move. If the ground vehicle is in any of
the search regions, the UAV's may skip it. We assume, for
simplicity, that the two UAV's fly at different altitudes so
there can be no collisions between the agents.
The two UAV's will be named robot 1 and 2 and initially
they are in regions 4 and 6 respectively. Other than the initial
region, the two formulas 01i, p2 will be the same therefore
we describe 91i only. Since the behavior of these robots
depend only on the location of the ground vehicle (denoted
as robot 3), we define four environment propositions r3i c
{1, 3, 7, 8} indicating whether robot 3 is in either of these
regions.
'Pi

=

fA-r3A 3r3A-r3A-r3

AMutual Exclusion between

tAD 0True

r3i

i

{1, 3, 7, 8}

Robot 3 does not start in regions 1, 3, 7 or 8, and it cannot
be in two regions at the same time.

1r4 A11 2,3,5,...,

0

_ { A Transitions/ AI Mutual Exclusion

91-A~AiC,3,7,81
~~~1: ((rV
v\ r3)

The robot has to infinitely often visit region i, unless robot
3 is there This formula took I 1 seconds to realize and the
automaton has 129 states
Robot 3 (the ground vehicle) is initially in region 10.
The behavior of robot 3 depends on the sensing done by
robots I and 2 that is transmitted to it. For 103 we define
four input propositions: helpi, C { 1,3,
3, 8} indicating
people needing help in the respective regions. To make the
automaton smaller, we assume that once the robot reaches
region i the proposition helpi becomnes false and if helpj

3120

ThDll.5

is true, it stays true until the robot reaches region j.

direction we are working on is experimenting with different
controllers and various robots, simulated and real.

Aic 1{ ,3,7,8}-helpi
3

=

{

AiF13,,8 (,r3-> -I Chelpi )
AiE 1,3,7,8}D((-r i A helpi) --> Ohelpi)
AD oTrue

ACKNOWLEDGEMENTS

We would like to thank David Conner for allowing us to
his code for the potential field controllers. We would also
like to thank Nir Piterman, Amir Pnueli and Yaniv Sa'ar for
allowing us to use their code for the synthesis algorithm.

use

Robot 3 stays in place unless there is a need for help.

rio Ai=l...,9 -ir

A Transitions A Mutual Exclusion
A LI((Aic 13,78}- Q helpi)
=> (Aj ..,o}
i 0 rj3 <+- rj3))
A {l
D7g(r3 V -ihelpi)
This formula took 60 seconds to realize and the automaton
has 282 states. Fig. 5 depicts four snapshots of a sample
simulation. In this simulation, robot 1 detects a person
(indicated by an X) in region 1, causing robot 3 to move to
region 1. Then, later on, robot 2 detects a person in region
3 and subsequently, robot 3 moves to region 3.

(a) Robot 1 found someone in 1

(b) Robot 3 arrived at 1

(c) Robot 2 found someone in 3

(d) Robot 3 arrived at 3

Fig. 5: Search and Rescue
VII. CONCLUSIONS - FUTURE WORK
In this paper, we have described a method of creating
controllers which are guaranteed to satisfy a user specified
behavior expressed in temporal logic. Furthermore, these
controllers behave in a reactive manner, i.e. the behavior of
the robot can depend on the local information it senses from
the environment in which it is operating. We have shown
that many complex robot behaviors can be expressed and
computed, both for a single robot and for multiple robots.
Writing LTL formulas requires some experience, and
might lead to unintended behaviors. Therefore, we plan to
examine how natural language can be automatically translated into logic, thus enabling "non-expert" users to take
advantage of this method. Furthermore, we would like to
create some feedback to the user that will help him figure out
what went wrong if the specification is unrealizable. Another

REFERENCES
[1] H. Choset, K. M. Lynch, L. Kavraki, W. Burgard, S. A. Hutchinson,
G. Kantor, and S. Thrun. Principles of Robot Motion: Theory,
Algorithms, and Implementations. MIT Press, Boston, USA, 2005.
[2] S. M. LaValle. Planning Algorithms. Cambridge University Press,
Cambridge, U.K., 2006.
[3] Elon Rimon and Daniel E. Kodischek. Exact robot navigation using
artificial potential functions. IEEE Transactions on Robotics and
Automation, 8(5):501-518, October 1992.
[4] H. Choset and J. Burdick. Sensor-based exploration: The hierarchical
generalized voronoi graph. The International Journal of Robotics
Research, 19:96-125, February 2000.
[5] S. Russell and P. Norvig. Artificial Intelligence, A Modern Approach.
Prentice Hall, second edition, 2003.
[6] R.M. Jensen and M. M. Veloso. OBDD-based universal planning
for synchronized agents in non-deterministic domains. Journal oj
Artificial Intelligence Research, 13:189-226, 2000.
[7] P. Bertoli, A. Cimatti, M. Pistore, M. Roveri, , and P. Traverso. MBP
A model based planner. In In Proc. IJCAI'01 Workshop on Planning
under Uncertainty and Incomplete Information, 2001.
[8] Georgios E. Fainekos, Hadas Kress-Gazit, and George J. Pappas. Temporal logic motion planning for mobile robots. In IEEE International
Conference on Robotics and Automation, pages 2020-2025, 2005.
[9] Georgios E. Fainekos, Hadas Kress-Gazit, and George J. Pappas.
Hybrid controllers for path planning: A temporal logic approach. In
IEEE Conference on Decision and Control, Seville, Spain, 2005.
[10] M. Kloetzer and C. Belta. A fully automated framework for control
of linear systems from ltl specifications. In 9th International Workshop on Hybrid Systems: Computation and Control, Santa Barbara,
California, 2006.
[11] David C. Conner, Alfred A. Rizzi, and Howie Choset. Composition of
Local Potential Functions for Global Robot Control and Navigation.
In IEEE/RSJ Int'l. Conf on Intelligent Robots and Systems, pages
3546 - 3551, Las Vegas, NV, October 2003.
[12] D. Conner, H. Choset, and A. Rizzi. Integrated planning and
control for convex-bodied nonholonomic systems using local feedback
control policies. In Proceedings of Robotics: Science and Systems,
Cambridge, USA, June 2006.
[13] S. Lindemann and S. LaValle. Computing smooth feedback plans over
cylindrical algebraic decompositions. In Proceedings of Robotics:
Science and Systems, Cambridge, USA, June 2006.
[14] E. Allen Emerson. Temporal and modal logic. In Handbook oj
theoretical computer science (vol. B): formal models and semantics,
pages 995-1072. MIT Press, Cambridge, MA, USA, 1990.
[15] Nir Piterman, Amir Pnueli, and Yaniv Sa'ar. Synthesis of Reactive(l)
Designs. In VMCAI, pages 364-380, Charleston, SC, Jenuary 2006.
[16] A. Pnueli and R. Rosner. On the synthesis of a reactive module.
In POPL '89: Proceedings of the 16th ACM SIGPLAN-SIGACI
symposium on Principles of programming languages, pages 179-190.
ACM Press, 1989.
[17] R. Alur, T.A. Henzinger, G. Lafferriere, and G.J. Pappas. Discrete
abstractions of hybrid systems. Proceedings of the IEEE, 88:971984, 2000.
[18] Calin Belta and L.C.G.J.M. Habets. Constructing decidable hybrid
systems with velocity bounds. In IEEE Conference on Decision and
Control, Bahamas, 2004.
[19] David C. Conner, Howie Choset, and Alfred Rizzi. Towards provable navigation and control of nonholonomically constrained convexbodied systems. In Proceedings of the 2006 IEEE International
Conference on Robotics and Automation (ICRA '06), May 2006.

3121

Proceeding of the IEEE
International Conference on Robotics and Biomimetics (ROBIO)
Shenzhen, China, December 2013

A Graphical Language for LTL Motion and Mission Planning
Shashank Srinivas, Ramtin Kermani, Kangjin Kim, Yoshihiro Kobayashi and Georgios Fainekos

Abstract— Linear Temporal Logic (LTL) has recently become
a popular high-level specification language for robotic applications. One of the main reasons for the adoption of LTL is that
LTL control synthesis algorithms are scalable while providing
sufficient expressive power for a range of applications. However,
despite the recent progress, one challenge remains. How can a
non-expert robot user, who is not a logician, provide mission
and motion plans for multiple robots in LTL? In this paper, we
propose a graphical specification environment for LTL specifications that utilizes touchscreen technologies. We demonstrate
that the graphical interface can express all the properties of
interest that have appeared in the literature.

I. I NTRODUCTION
More often than not, emergency personnel and armed
forces personnel encounter situations where the use of autonomous robotic vehicles can reduce the risks to human life.
A typical such scenario is when firefighters respond to a fire
emergency in a big office building. Ideally, on the way to
the fire site, the firefighters receive the building blueprints on
their tablets and identify the areas of interest. Upon arrival to
the site, a number of autonomous Unmanned Aerial Vehicles
(UAV) are deployed, detect the fire areas, search for trapped
humans and relay the information to the firefighters. The
situation awareness will permit the firefighters to efficiently
perform their tasks and minimize human casualties. The
same scenario almost identically applies to urban counterterrorism operations or nuclear disaster assessment and recovery operations or, even, to more everyday situations such
as robots assisting medical personnel in hospitals.
Linear Temporal Logic (LTL) can capture such mission
requirements as well as more complex ones [1]–[6] (for a
recent survey see the special issue [7] in the IEEE Robotics
and Automation Magazine). LTL has become a popular
specification language due its expressive power and scalable
control synthesis algorithms which can be tailored to specific
applications. Moreover, recently, a number of issues relating
to specification debugging and revision [8]–[10], on-line plan
revision [3] and partial satisfaction of goals [4] are being
studied. The latest developments build upon the LTL control
synthesis and planning work to provide a complete set of
tools for enabling Human-Robot Interaction (HRI).
However, LTL is a mathematical formalism that requires
experts in order to successfully specify the desired goals in
This work was partially supported under NSF awards CNS 1116136,
IIP-0856090 and the NSF I/UCRC Center for Embedded Systems.
S. Srinivas, R. Kermani, K. Kim, Y. Kobayashi and G. Fainekos are
with the School of Computing, Informatics and Decision Systems
Engineering, Arizona State University, Tempe, AZ 85281, USA

{ssrini37,ramtin,kkim59,ykobaya,fainekos}@asu
.edu

978-1-4799-2744-9/13/$31.00 ©2013 IEEE

704

the logic. Therefore, we need intuitive human-robot interfaces to utilize for mission planning which can be interfaced
with LTL control synthesis methods. In the past, structured
or natural human languages have served as possible humanrobot interfaces (see for example [11]–[14] and the references therein). Unfortunately, automatic speech recognition
algorithms are not yet at the development level that could
be deployed in emergency scenarios or where the robot
needs additional human guidance. Moreover, natural language interfaces may not be the best way to instruct and
receive information from a robot. That is, with the current
technology in natural language understanding, it appears that
touchscreen interfaces and visual programming tools [15]–
[19] offer a better alternative for HRI [20].
The challenge in developing a touchscreen interface is
not only on how to create a user-friendly interface, but
also on how to capture the full expressivity of the specification language. In this paper, we develop a graphical
representation language for LTL called LTLV IS . Our goal
is twofold. First, we provide visual templates for commonly
occurring specifications. The reasoning behind this is that
certain specifications are hard to formalize in LTL even for
expert logicians. Second, we design our framework to allow
representation of arbitrary LTL specifications. The challenge
in accomplishing the two aforementioned goals is that LTL
specifications need to capture both topological and timing
requirements. We demonstrate that all LTL properties of
interest which are published in the literature can be captured
by our graphical representation tool.
Related work: The need for software tools that can visualize complex temporal specifications was recognized early
in the software verification community. In brief, it was found
that the adoption of model checking methods by the industry
was hurdled by the inability of the software engineers to
understand, write and debug formal requirements in temporal
logics. The authors in [21] provide an excellent recent
overview of the past research on the topic. In brief, the prior
work can be categorized in two main approaches: (1) visual
representation of formulas and (2) visual representation of
the desired and/or undesired sequences of events and their
timing. The closest work to LTLV IS appeared in [22] and
[23]. The work in [22] uses acyclic directed graphs to
represent formulas of a variant of µ-calculus. In [23], the
authors construct a time-line representation of events which
is then translated directly into automata. Our work here is
fundamentally different from all the previous works because
our graphical representation must both capture topological
information and, also, it must be tailored to robotic applications for technologically inept users.

II. P ROBLEM D ESCRIPTION

AND

S OLUTION OVERVIEW

In this paper, we are concerned with the problem of
developing a visual specification language for human-robot
interaction. Our main objectives are two. First and foremost, the visual specifications must be translated into Linear
Temporal Logic (LTL) [2] in order to utilize the wealth of
domain specific LTL control synthesis methods that have
been recently developed. Second, the visual specification
language has to be succinct and easy to be understood by
non-expert LTL users, i.e., anyone who has not spent 1-2
years studying the subtleties of writing formal specifications
in temporal logics.
In the following, we mainly focus the discussion to motion
planning applications. We assume that we are given a finite
set of labels Q = {q1 , q2 , . . . , qnQ } in the workspace of the
robot. The labels may represent locations (points-of-interest),
static or dynamic obstacles, objects to be manipulated, actions to be performed at a specific location etc. We remark
that the framework could be easily extended to support
separate atomic propositions for the set of actions and
Boolean sensors at the expense of more complex translation
algorithms.
The following example briefly introduces the main setting
of the targeted applications.

Fig. 1. The user interface, the simple road network and the mission of
Example 1. The areas q1 − q5 are covered parking lots while the areas
q6 − q9 are other points-of-interest (PoI).

Example 1: We consider a search-and-rescue scenario
over a simple road network as in Fig. 1. In this scenario, an
earthquake has hit an apartment complex. The rescue team on
its way to the scene dispatches an autonomous aerial vehicle
(UAV) to verify whether the garage structures have collapsed.
A member of the team uses a tablet device to download a
map of the affected area and he/she provides the mission
plan for the UAV. The goal is to visit parking lots q5 , q3 , q4
and q1 in order and in addition: (1) at the end of the mission
the UAV should stay in parking lot q1 and (2) PoI q8 should
always be avoided (it is the main entrance to the complex).
Such scenarios can be easily captured using Linear Temporal Logic (LTL). LTL formulas are built over a set of
atoms, the set Π = Q in our case, using combinations
of the traditional and temporal operators. Traditional logic

705

operators are the conjunction ∧, disjunction ∨, negation ¬
and implication ⇒. Some of the temporal operators are next
X, eventually F , always G and until U. LTL can describe
the usual properties of interest for control problems, i.e.
reachability (F π) and safety: (Gπ or G¬π). Beyond the
usual properties, LTL can capture sequences of events and
certain infinite behaviors. For example:
• Reachability while avoiding regions: The formula
¬(π1 ∨ π2 ∨ · · · ∨ πn ) Uπn+1 expresses the property that
eventually πn+1 will be true, and until πn+1 is reached,
we must avoid all unsafe sets πi , i = 1, . . . , n.
• Sequencing: The requirement that we must visit π1 , π2
and π3 in that order is naturally captured by the formula
F (π1 ∧ F (π2 ∧ F π3 )).
• Recurrent coverage: The formula G(F π1 ∧ F π2 ∧ · · · ∧
F πm ) requires that the robot repeatedly visits all the
regions π1 , π2 , ..., πm without any particular order.
More complicated specifications can be composed from the
basic specifications using the logic operators (for examples
see Sec. V).
The model checking community has identified as a major
hurdle writing formal specifications that actually capture the
intended specification provided in natural language [21]. It is
to be expected that in robotic applications the problem will
be exaggerated since most of the users will not even have
basic programming skills.
Problem 1: Develop a visual specification language for
robotic applications. The visual specification language
should provide automatic translation to LTL so that existing
control synthesis algorithms can be utilized. The visual
language should provide templates for commonly occurring
LTL specifications so that specification errors are minimized.
Solution overview and Contributions: To address the
problem of creating LTL formulas in a way that is intuitive
to the user and, most importantly, in a way that the resulting
specification indeed captures the desired user intention, we
developed an Android App that provides a touchscreen
interface as in Fig. 1.
The user can enter a number of waypoints on the screen
and move them around as desired. The arrows express
temporal relationship between desired or undesired events
while undirected edges describe Boolean combinations of
events or goals. The color of the node indicates desired or undesired events or locations. However, arbitrary combination
of directed and undirected edges and desired and undesired
locations is not allowed. Furthermore, touching a node for
a time interval of 2 sec a menu pops-up that provides a
number of options as [24], [25]. For example, the user can
provide whether something should be sensed in that location
or whether an action should be performed.
Example 2: The graph in Fig. 1 is automatically translated
in the LTL specification
G(¬q8 ) ∧ F (q5 ∧ F (q3 ∧ F (q4 ∧ F Gq1 ))).

(1)

Additional requirements can be added on different screens
to reduce overloading with too many symbols a single scene
of the operational environment.

III. S YNTAX

AND

S EMANTICS

OF

LTLV IS

When designing a graphical representation language for
arbitrary temporal logic formulas the main question is
whether the visual formalism should retain the full expressivity of the targeted temporal logic. Clearly, a visual
representation that is as expressive as the underlying logic
can be developed using as basis the inductive definition of
the semantics of the logic [26]. However, as noted in [21],
such an approach does not help the non-expert users define
correctly the desired specifications.
LTLV IS is a graphical representation language that can
capture spatio-temporal specifications for robot motion and
mission planning or, more general, for reactive supervisory
control synthesis. It is a combination and extension of
two previous approaches [22] and [23]. Namely, LTLV IS
utilizes a graphical representation of the structure of the
formulas as in [22], but at the same time achieves a time-line
representation of events similar to [23].
Formally, an LTLV IS specification G is a directed graph
embedded in a geometric space. Namely, G is a tuple
(V, E, v0 , c, L, Lα , Lσ , Λ, x) where
• V is a set of nodes;
• E ⊆ V × V is the set of edges;
• v0 ∈ V is a start node;
• c : V → {green, red} is a function that colors each node
either green or red;
• L : V → ΦB (Q) labels each node with an LTL formula
over the set of proposition Π;
• Λ : E → BO1 × BO2 × T O2 × T O1 is a function that
labels each edge on the graph with one or more Boolean
or temporal operators. In detail,
– BO1 = {AND, OR}
– BO2 = BO1 ∪ {ε, IMPLIES}
– T O1 = {ε, FUTURE, ALWAYS}
– T O2 = T O1 ∪ {NEXT, UNTIL}
where ε is the empty string, which is not displayed on
the edge of the specification graph; and
2
• x : V → R is the position of the node on the map or,
in general, on the image.
In our current implementation, we restrict the space to be
2D, but there is no theoretical restriction in developing an
embedding of the specification graph in a 3D space.

b2

t1

t2

The aforementioned graph definition is quite general and
we impose some further restrictions to help the user formulate the desired requirements. The following are some
syntactic restrictions on the graph G. Such restrictions are
enforced on-the-fly as the user builds the specification graph.
Let (b1 , b2 , t1 , t2 ) be a triplet that Λ(u, v) maps to, then
• The combinations of Boolean and temporal operators
which are allowed are presented in Fig. 2. There are
some additional requirements:
– b2 = AND or b2 = OR only if t1 6= ε.
– t2 = ALWAYS or t2 = FUTURE only if t1 6= ε.
• Bidirectional edges appear only in Strongly Connected
Components (SCC) [27] and the label of each edge of an
SCC does not have any temporal operators, i.e., t1 = ε,
t2 = ε.
• If the out-degree of node u is greater than 1, then all
the outgoing edges (u, v) must have the same label b1 .
That is, an LTLV IS graph resembles an and-or tree.
• If the label of the start node v0 is not modified by the
user, then L(v0 ) = true.
The semantics of an LTLV IS specification are given
through the translation algorithm to LTL formulas. The
algorithm is presented in [24]. In the following, we give the
intuition behind the syntax and semantics of specification
graphs. Table I presents the main visual elements of the
graph.
Example 3: Consider the following subgraph with labels
L(1) = q1 and L(2) = q2 .

1

Intuitively, the left node must not hold now since it is
red while the right node must hold in the future since it is
green and it is preceded by a FUTURE label. The AND label
combines the two aforementioned requirements to form the
specification: ¬q1 ∧ F q2 .
Example 4: Consider the following subgraph with labels
L(1) = q1 , L(2) = q2 and L(3) = q3 .

3

706

1

2

The right subgraph converts to the LTL formula as in
Example 3. The left subgraph on the other hand translates to
(¬q1 )U q3 . Since the outgoing edges from node 1 are dashed,
the two subformulas are connected through a disjunction.
Thus, the resulting specification is: (¬q1 ∧ F q2 ) ∨ (¬q1 )U q3 .
Example 5: Consider the following subgraph with labels
L(1) = q1 and L(2) = q2 .
v0

Fig. 2. The allowed combinations of Boolean and temporal operators over
an edge.

2

1

2

The subgraph that includes nodes 1 and 2 translates to
q1 =⇒ X((¬q1 )U q2 ) according to the template. Thus, the
resulting specification is: G(q1 =⇒ X((¬q1 )U q2 )).
Remark 1: An LTLV IS graph can actually represent any
arbitrary LTL formula since the labels of any node u on the
graph can be any well formed LTL formula. This strikes a
balance between the needs of expert users and the needs of

TABLE I

TABLE II

G RAPHICAL ELEMENTS OF LTL V IS .

T EMPLATE SYMBOLS OF LTL V IS .
This indicates a special template that represents properties of the form q1 =⇒ X((¬q1 )U q2 ). It is activated
by enabling the labels IMPLIES and NEXT over an edge
when the template mode is active.

The green node indicates a location that must be visited.
More generally, a green node indicates a Boolean sensor
event that must be true or an action to be performed.
The red node indicates a location that must be avoided.
More generally, a red node indicates a Boolean sensor
event that must be false or an action to be stopped.

A. The User Interface
The User interface (see Fig. 1) consists of buttons to select
a Map, to add Missions, to delete Missions and to Upload
the motion plan to Dropbox on the top row. It contains
checkboxes to select waypoints, which may also include
actions and sensors, for the current mission. A waypoint
represents a location on a map and each location contains an
atomic propositions used to construct the LTL specification.
The waypoint represents a location by the virtue of its ID and
not by its current coordinates on the map. Future versions
of the toolbox will have tighter integration with the map by
also designing the regions that the waypoints correspond to.
The UI consists of a text view on the left side thats shows
relevant context which include the missions that are currently
added and changes to the final specification that is uploaded
when the upload button is pressed. Next to, it is main area
for creating and editing missions graphically. On the right
side, the user will find a list of robots that can be selected
to upload the plan to a specific robot. A preview of the LTL
specification is shown at the bottom of the interface. The
interface also pops up a context menu (see [24]) on a log
press touch event on waypoints which allows the user to
select more options for creating the motion plan.

Solid edges between nodes indicate conjunctive requirements among the nodes that the edges connect.
Dashed edges between nodes indicate disjunctive requirements among the nodes that the edges connect.
When the AND label appears over an edge, it indicates
a conjunctive requirement between the previous node on
the graph and the specification that corresponds to the
subgraph where the edge points to.
When the OR label appears over an edge, it indicates
a disjunctive requirement between the previous node on
the graph and the specification that corresponds to the
subgraph where the edge points to.
When the IMPLIES label appears over an edge, it indicates that satisfaction of the SCC on the originating node
of the edge implies satisfaction of the subgraph where the
edge points to.
When the NEXT label appears over an edge, it indicates
that the subgraph that the edge points to should be
satisfied at the next step (when discrete time semantics
are considered).
When the FUTURE label appears over an edge, it indicates that the subgraph that the edge points to should be
satisfied some time in the future.

B. Creating a motion plan
When the ALWAYS label appears over an edge, it indicates that the subgraph that the edge points to should
always be satisfied in the future.
When the UNTIL label appears over an edge, it indicates
that the SCC on the originating node should be satisfied
until the point in time when the subgraph that the edge
points to is satisfied.

non-expert users. The latter class of users can use only the
graph specifications while the former can mix arbitrary graph
and textual specifications.
IV. I MPLEMENTATION AND U SER I NTERFACE
The software application is built on the Android platform
using Java programming language and it can be downloaded
from [25]. It has been tested on the Samsung galaxy tab 10.1
which runs Android Honeycomb 3.1. It has also been tested
on an Android emulator based on JellyBean 4.1 with WXGA
screen resolution. It uses the built-in AndroidGestureListener
API to check for touch events like tap, doubletap, long press
and scroll actions. It implements the DropBox Sync API to
upload/update the LTL specification to a Dropbox folder on
the cloud.

707

The first thing to do is to load a map by pressing the
Select Map button (top left on the user interface Fig. 1).
This redirects the user to the gallery application present
on Android allowing the user to select the desired map.
The maps are generic images with waypoint information
representing each location integrated into the map. The next
step is to start building the motion plan by selecting the
waypoints required for the current mission. The waypoints
appear on the top of the draw area in the ascending order
of their IDs. The user is now free to drag the waypoints
around to their respective locations on the map. It has to
be noted that this step is not a requirement and only helps
the user visualize the motion plan better. In this prototype
version, the position of the nodes is not forwarded to the
LTL planner, but rather it is assumed that the positions of
the points-of-interest are prespecified. The main reason for
this choice is that there is no common format for all the
planners being developed by the different research groups.
One of the future implementation goals will be to develop
such a format by reviewing toolboxes like [1], [13]
There are a number of gestures and options to create a
motion plan which the users should be able to familiarize
themselves with little or no effort. Each of the gestures
available in the UI is explained below:

TABLE III
E XPLANATION OF SOME OF THE ICONS IN THE POP - UP MENU IN [24]
SET LABEL
VISIT/AVOID
ALWAYS/ONCE

TOGGLE GF/FG
TOGGLE
IMPLIES
TOGGLE
FUTURE
TOGGLE
UNTIL
TOGGLE
UNTIL
PICKUP
OBJECT
DROP OBJECT

Change the label of a node on the graph.
This option tells the robot whether to visit the
location or to avoid it.
It specifies whether the robot should perform
the specified action once or always (or infinitely
often depending on the subgraph).
Toggle between ALWAYS EVENTUALLY and
EVENTUALLY ALWAYS.
Change between IMPLIES, AND and OR of an
edge.
Enable of disable a FUTURE label on the edge.
Enable of disable an UNTIL label on the edge.

Fig. 3.

Periodically visit data upload locations and data gather locations.

Enable of disable a NEXT label on the edge.
This option tells the robot to pick up an object
at the waypoint specified (application specific).
This option tells the robot to drop the object at
the waypoint specifies (application specific).

1) Each circle (green/red) is a waypoint and represents a
particular location on a map regardless of where it is
placed on the map.
2) By default, enabling a location puts a waypoint on the
map indicating that the robot should eventually visit
the location.
3) Enabling multiple waypoints tells the robot to go to
each location with no particular order.
4) The interface supports the following gestures:
a) Single tap: a single tap on two consecutive waypoints changes the predicate from AND to an OR
(E.g. Visit A AND B now becomes visit A OR
B)
b) Double tap: Double tapping two consecutive waypoints produces sequential ordering from the first
point to the next.
c) Long press: Long pressing a waypoint results in
a menu being displayed (see [24]) which gives
further options as indicated in Table III.
5) There are several other buttons to select a Map, to
add/delete missions and to upload the missions created,
to a server that computes the trajectory for the robot
from the uploaded LTL specification.
V. E XAMPLES
The following section describes a few cases based on the
work by Smith et. al. [28]. The work in [28] was selected
due to complex requirements that it includes. The scenario
considered is a collect, transfer and upload mission. In brief,
one or more robots need to visit a number of data collect (q1 ,
q2 , q3 ) and data upload locations (q4 , q5 ) on a road network.
Further details on the examples can be found in [28].
Case A: Repeatedly visit data collect locations (q1 , q2 ,
q3 ) and repeatedly visit data upload locations (q4 , q5 ). The
requirements can be specified using the LTLV IS graph in
Fig. 3. Note that graph nodes 1, 2 and 3 and nodes 4 and 5
are connected with undirected dashed edges which indicate

708

Fig. 4.

Visit an upload location only after data has been gathered.

disjunction between the labels of the nodes. The resulting
formula is:
GF (q1 ∨ q2 ∨ q3 ) ∧ GF (q4 ∨ q5 )

(2)

Case B: To avoid visiting two upload locations consecutively, a robot must visit an upload location only if it has
just gathered data. In order to graphically represent this
requirement with the algorithm presented in [24], two graph
specifications are required; one for
ψ1 = X(¬(q4 ∨ q5 )U (q1 ∨ q2 ∨ q3 ))

(3)

G((q3 ∨ q4 ) =⇒ ψ1 )

(4)

and one for
To enable the user enter such specifications on a single screen
we can use the template as in Fig. 4. In order to use the
template the edge must be labeled with IMPLIES and NEXT
and the template mode must be activated. Thus, the graph as
it appears in Fig. 4 captures the requirement:
G((q3 ∨ q4 ) =⇒ X(¬(q3 ∨ q4 )U (q1 ∨ q2 ∨ q3 )))

(5)

Case C: In order to specify that the data gather locations
q1 , q2 and q3 must be visited periodically, we can visualize
the specification with the graph as given in Fig. 5 resulting
in the LTL formula:
GF q1 ∧ GF q2 ∧ GF q3 ∧ GF (q4 ∨ q5 )

(6)

Remark 2: The experienced LTL user may notice that
taking the conjunction of many different requirements, as

Fig. 5.

Data gather locations q1 , q2 , q3 must be visited periodically.

in the above example, could result in an unsatisfiable or an
unrealizable specification. In such cases, the interface must
provide visual feedback to the user of what needs to be
modified [8]–[10].
VI. C ONCLUSIONS
We have presented LTLV IS which is a graphical representation tool for specifying Linear Temporal Logic (LTL)
formulas. LTLV IS can represent arbitrary LTL formulas for
expert users who do not need guidance in building the desired
specifications. Moreover, with LTLV IS the technologically
inept user can now utilize specific spatio-temporal graphs and
templates in order to construct the desired specification. Even
though in this paper we present the basic toolbox with a basic
functionality, the extensions of this work can be numerous.
First and foremost, LTLV IS can immediately be utilized
over live video feed using kinect and, thus, allowing for
entering high-level plans in the immediate workspace of the
robot. Furthermore, LTLV IS can be extended with geometric
primitives and shapes for capturing locations, objects etc,
as well as with sketches for more immediate robot control.
Finally, in the future, we plan to contact usability studies to
determine possible improvements to the user interface.
ACKNOWLEDGEMENTS
The authors would like to thank Parth Pandya for his help
with the experiments.
R EFERENCES
[1] A. Ulusoy, S. L. Smith, X. C. Ding, C. Belta, and D. Rus, “Optimal multi-robot path planning with temporal logic constraints,” in
IEEE/RSJ International Conference on Intelligent Robots and Systems,, 2011, pp. 3087 –3092.
[2] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, Feb. 2009.
[3] M. Guo, K. H. Johansson, and D. V. Dimarogonas, “Revising motion
planning under linear temporal logic specifications in partially known
workspaces,” in Proceedings of the IEEE Conference on Robotics and
Automation, 2013.
[4] J. Tumova, L. I. R. Castro, S. Karaman, E. Frazzoli, and D. Rus,
“Minimum-violating planning with conflicting specifications,” in
American Control Conference, 2013.
[5] E. M. Wolff, U. Topcu, and R. M. Murray, “Automaton-guided
controller synthesis for nonlinear systems with temporal logic,” in
International Conference on Intelligent Robots and Systems, 2013.

709

[6] L. Bobadilla, O. Sanchez, J. Czarnowski, K. Gossman, and S. LaValle,
“Controlling wild bodies using linear temporal logic,” in Proceedings
of Robotics: Science and Systems, Los Angeles, CA, USA, June 2011.
[7] H. Kress-Gazit, “Robot challenges: Toward development of verication
and synthesis techniques [errata],” IEEE Robotics Automation Magazine, vol. 18, no. 4, pp. 108–109, Dec. 2011.
[8] G. E. Fainekos, “Revising temporal logic specifications for motion
planning,” in Proceedings of the IEEE Conference on Robotics and
Automation, May 2011.
[9] K. Kim, G. Fainekos, and S. Sankaranarayanan, “On the revision
problem of specification automata,” in Proceedings of the IEEE
Conference on Robotics and Automation, May 2012.
[10] V. Raman and H. Kress-Gazit, “Automated feedback for unachievable
high-level robot behaviors,” in Proceedings of the IEEE Conference
on Robotics and Automation, 2012.
[11] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Translating
structured english to robot controllers,” Advanced Robotics, vol. 22,
no. 12, pp. 1343–1359, 2008.
[12] R. Cantrell, K. Talamadupula, P. Schermerhorn, J. Benton, S. Kambhampati, and M. Scheutz, “Tell me when and why to do it!: Runtime planner model updates via natural language instruction,” in 7th
ACM/IEEE International Conference on Human-Robot Interaction,
2012.
[13] C. Finucane, G. Jing, and H. Kress-Gazit, “LTLMoP: Experimenting
with language, temporal logic and robot control,” in IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2010,
pp. 1988–1993.
[14] J. Dzifcak, M. Scheutz, C. Baral, and P. Schermerhorn, “What to do
and how to do it: Translating natural language directives into temporal
and dynamic logic representation for goal management and action
execution,” in Proceedings of the IEEE international conference on
robotics and automation, 2009.
[15] D. Sakamoto, K. Honda, M. Inami, and T. Igarashi, “Sketch and run:
A stroke-based interface for home robots,” in Proceeding of the 27th
Annual SIGCHI Conference on Human Factors in Computing Systems,
2009.
[16] C. Barber, R. Shucksmith, B. MacDonald, and B. Wunsche, “Sketchbased robot programming,” in 25th International Conference of Image
and Vision Computing New Zealand, Nov. 2010, pp. 1 –8.
[17] M. Skubic, D. Anderson, S. Blisard, D. Perzanowski, W. Adams,
J. G. Trafton, and A. C. Schultz, “Using a sketch pad interface for
interacting with a robot team,” in Proceedings of the 20th national
conference on Artificial intelligence - Volume 4. AAAI Press, 2005,
pp. 1739–1740.
[18] D. Shah, J. Schneider, and M. Campbell, “A robust sletch interface
for natural robot control,” in IEEE Intl. Conf. on Intelligent Robots
and Systems, 2010.
[19] R. Fung, S. Hashimoto, M. Inami, and T. Igarashi, “An augmented
reality system for teaching sequential tasks to a household robot,” in
20th IEEE International Symposium on Robot and Human Interactive
Communication, 2011.
[20] M. W. Kadous, R. K.-M. Sheh, and C. Sammut, “Effective user
interface design for rescue robotics,” in Proceedings of the 1st ACM
SIGCHI/SIGART conference on Human-robot interaction, 2006.
[21] M. Autili, P. Inverardi, and P. Pelliccione, “Graphical scenarios for
specifying temporal properties: an automated approach,” Automated
Software Engineering, vol. 14, pp. 293–340, 2007.
[22] I. Lee and O. Sokolsky, “A graphical property specification language,”
in Proceedings of the High-Assurance Systems Engineering Workshop,
1997, pp. 42–47.
[23] M. Smith, G. Holzmann, and K. Etessami, “Events and constraints:
a graphical editor for capturing logic properties of programs,” in 5th
International Symposium on Requirements Engineering, 2001.
[24] S. Srinivas, “A graphical language for ltl motion and mission planning,” Master’s thesis, Arizona State University, 2013.
[25] “LTLvis.” [Online]. Available: https://subversion.assembla.com/svn/
ltlvis/
[26] A. D. Bimbo, L. Rella, and E. Vicario, “Visual specification of branching time temporal logic,” in Proceedings of the 11th International
IEEE Symposium on Visual Languages, 1995, pp. 61–68.
[27] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction
to Algorithms, 2nd ed. MIT Press/McGraw-Hill, Sep. 2001.
[28] S. L. Smith, J. Tumova, C. Belta, and D. Rus, “Optimal path planning
for surveillance with temporal-logic constraints,” The International
Journal of Robotics Research, vol. 30, pp. 1695–1708, 2011.

arXiv:1607.02549v3 [cs.SY] 18 May 2017

Formal Requirement Debugging for Testing
and Verification of Cyber-Physical Systems
Adel Dokhanchi, Bardh Hoxha, and Georgios Fainekos
School of Computing, Informatics and Decision Systems
Arizona State University, Tempe, AZ, U.S.A.
Email: {adokhanc,bhoxha,fainekos}@asu.edu
Abstract
A framework for the elicitation and debugging of formal specifications for Cyber-Physical Systems is presented.
The elicitation of specifications is handled through a graphical interface. Two debugging algorithms are presented.
The first checks for erroneous or incomplete temporal logic specifications without considering the system. The second
can be utilized for the analysis of reactive requirements with respect to system test traces. The specification debugging
framework is applied on a number of formal specifications collected through a user study. The user study establishes
that requirement errors are common and that the debugging framework can resolve many insidious specification errors.

I.

I NTRODUCTION

Testing and verification of Cyber-Physical Systems (CPS) is important due to the safety critical applications of
CPS such as medical devices and transportation systems. It has been shown that utilizing formal specifications can
lead to improved testing and verification [22], [30], [44], [31]. However, developing formal specifications using
logics is a challenging and error prone task even for experts who have formal mathematical training. Therefore, in
practice, system engineers usually define specifications in natural language. Natural language is convenient to use
in many stages of system development, but its inherent ambiguity, inaccuracy and inconsistency make it unsuitable
for use in defining specifications.
To assist in the elicitation of formal specifications, in [28], [29], we presented a graphical formalism and tool
V I S PEC that can be utilized by users in both the academia and the industry. Namely, a user-developed graphical
input is translated to a Metric Interval Temporal Logic (MITL) formula. The formal specifications in MITL can be
used for testing and verification with tools such as S-TA L I RO [5] and Breach [19].
In [29], the tool was evaluated through a usability study which showed that V I S PEC users were able to use
the tool to elicit formal specifications. The usability study results also indicated that in a few cases the developed
specifications were incorrect. This raised two questions. First, are these issues artifacts of the graphical user interface?
Second, can we automatically detect and report issues with the requirements themselves?
We have created an on-line survey1 to answer the first question. Namely, we conducted a usability study on
MITL by targeting users with working knowledge in temporal logics. In our on-line survey, we tested how well
formal method users can translate natural requirements to MITL. That is, given a set of requirements in natural
language, users were asked to formalize the requirements in MITL. The study is ongoing but preliminary results
indicate that even users with working knowledge of MITL can make errors in their specifications.
For example, for the natural language specification “At some time in the first 30 seconds, the vehicle speed (v)
will go over 100 and stay above 100 for 20 seconds”, the specification ϕ = 3[0,30] ((v > 100) ⇒ 2[0,20] (v > 100))
was provided as an answer by a user with formal logic background. Here, 3[0,30] stands for “eventually within 30
time units” and 2[0,20] for “always from 0 to 20 time units”. However, the specification ϕ is a tautology!, i.e. it
evaluates to true no matter what the system behavior is and, thus, the requirement ϕ is invalid. This is because, if
at some time t between 0 and 30 seconds the predicate (v > 100) is false, then the implication (⇒) will trivially
evaluate to true at time t and, thus, ϕ will evaluate to true as well. On the other hand, if the predicate (v > 100) is
true for all time between 0 and 30 seconds, then the subformula 2[0,20] (v > 100) will be true at all time between
0 and 10 seconds. This means that the subformula (v > 100) ⇒ 2[0,20] (v > 100) is true at all time between 0 and
10 seconds. Thus, again, ϕ evaluates to true, which means that ϕ is a tautology.
1 The

on-line anonymous survey is available through: http://goo.gl/forms/YW0reiDtgi

This implies that specification issues are not necessarily artifacts of the graphical user interface and that they
can happen even for users who are familiar with temporal logics. Hence, specification elicitation can potentially
become an issue as formal and semi-formal testing and verification is being adopted by the industry. This is because
specification elicitation can be practiced by untrained users. Therefore, effort can be wasted in checking incorrect
requirements, or even worse, the system can pass the incorrect requirements. Clearly, this can lead to a false sense of
system correctness, which leads us to the second question: What can be done automatically to prevent specification
errors in CPS ?
In this work, we have developed a specification debugging framework to assist in the elicitation of formal
requirements. The specification debugging algorithm identifies some of the logical issues in the specifications, but
not all of them. Namely, it performs the following:
1) Validity detection: the specification is unsatisfiable or a tautology.
2) Redundancy detection: the formula has redundant conjuncts.
3) Vacuity detection: some subformulas do not affect the satisfiability of the formula.
Redundancy and vacuity issues usually indicate some misunderstanding in the requirements. As a result, a wide
class of specification errors in the elicitation process can be corrected before any test and verification process is
initiated. However, some specification issues cannot be detected unless we consider the system, and test the system
behaviors with respect to the specification. We provide algorithms to detect specification vacuity with respect to
system traces in order to help the CPS developer find more vacuity issues during system testing. Our framework
can help developers correct their specifications as well as finding more subtle errors during testing.
This paper is an extended version of the conference paper that appeared in MEMOCODE 2015 [18].
Summary of Contributions:
1) We present a specification debugging algorithm for a fragment of MITL [3] specifications.
2) Using (1) we provide a debugging algorithm for Signal Temporal Logic Specifications [38].
3) We extend Linear Temporal Logic (LTL) [16] vacuity detection algorithms [14] to real-time specifications in
MITL.
4) We formally define signal vacuity and we provide an algorithm to detect the system traces that vacuously
satisfy the real-time specifications in MITL.
5) We present experimental results on specifications that typically appear in requirements for CPS.
The above contributions can help us address and solve some of the logical issues which may be encountered when
writing MITL specifications. In particular, we believe that our framework will primarily help users with minimal
training in formal requirements who use graphical specification formalisms like V I S PEC [29]. The users of V I S PEC
can benefit from our feedback and fix any reported issues. In addition, we can detect potential system-level issues
using algorithms to determine specification vacuity with respect to system traces during testing.
In this paper, the new results over the conference version of the paper [18] concern item (4) in the list above
and are presented in Sections VI, VII-C, VII-D, and Appendix X. In addition, we have expanded some examples
and added further experimental results which did not appear in [18]. Furthermore, we added new algorithms in
Section 4.
II.

R ELATED WORKS

The challenge of developing formal specifications has been studied in the past. The most relevant works appear
in [6] and [45]. In [6], the authors extend Message Sequence Charts and UML 2.0 Interaction Sequence Diagrams
to propose a scenario based formalism called Property Sequence Chart (PSC). The formalism is mainly developed
for specifications on concurrent systems. In [45], PSC is extended to Timed PSC which enables the addition of
timing constructs to specifications. Another non-graphical approach to the specification elicitation problem utilizes
specification patterns [20]. The patterns provided include commonly used abstractions for different logics including
LTL, Computation Tree Logic (CTL), or Quantified Regular Expressions (QRE). This work was extended to the
real-time domain, [34].
Specification debugging can also be considered in areas such as system synthesis [41] and software verification
[4]. In system synthesis, realizability is an important factor, which checks whether the system is implementable given
the constraints (environment) and requirements (specification) [21], [33], [15], [41]. Specification debugging can
also be considered with respect to the environment for robot motion planning. In [23], [32], the authors considered
the problem where the original specification is unsatisfiable with the given environment and robot actions. Then,
they relax the specification in order to render it satisfiable in the given domain.

One of the most powerful verification methods is model checking [16] where a finite state model of the system
is evaluated with respect to a specification. For example, let us consider model checking with respect to the LTL
formula ϕ = 2(req ⇒ 3ack) which represents the following request-response requirement “if at any time in the
future a request happens, then from that moment on an acknowledge must eventually happen”. Here, ϕ can be
trivially satisfied in all systems in which a request never happens. In other words, if the request never happens in
the model of the system (let’s say due to the modeling error), our goal for checking the reaction of the system
(issuing the acknowledge) is not achieved. Thus, the model satisfies the specification but not in the intended way.
This may hide actual problems in the model.
Such satisfactions are called vacuous satisfactions. Antecedent failure was the first problem that raised vacuity
as a serious issue in verification [8], [10]. Vacuity can be addressed with respect to a model [9], [36] or without a
model [24], [14]. A formula which has a subformula that does not affect the overall satisfaction of the formula is a
vacuous formula. It has been proven in [24] that a specification ϕ is satisfied vacuously in all systems that satisfy it
iff ϕ is equivalent to some mutations of it. In [14], they provide an algorithmic approach to detecting vacuity and
redundancy in LTL specifications. Vacuity with respect to testing was considered in [7]. The authors in [7] defined
weak vacuity for test suites that vacuously pass LTL monitors, e.g., [25]. The main idea behind the work in [7]
is that some transitions are removed from the LTL specification automata in order to find vacuous passes during
testing. The authors in [7] renamed the vacuity in model checking as strong vacuity. The authors in [40] consider
the problem of vacuity detection in the set of requirements formalized in Duration Calculus [39].
Our work extends [14] and it is applied to a fragment of MITL. We provide a new definition of vacuity with
respect to Boolean or real-valued signals. To the best of our knowledge, vacuity of real-time properties such as
MITL has not been addressed yet. Although this problem is computationally hard, in practice, the computation
problem is manageable, due to the small size of the formulas.
III.

P RELIMINARIES

In this work, we take a general approach in modeling Cyber-Physical Systems (CPS). In the following, R is the
set of real numbers, R+ is the set of non-negative real numbers, Q is the set of rational numbers, Q+ is the set of
non-negative rational numbers. Given two sets A and B, B A is the set of all functions from A to B, i.e., for any
f ∈ B A we have f : A → B. We define 2A to be the power set of set A. Since we primarily deal with bounded
time signals, we fix the variable T ∈ R+ to denote the maximum time of a signal.
A. Metric Interval Temporal Logic
Metric Temporal Logic (MTL) was introduced in [35] in order to reason about the quantitative timing properties
of boolean signals. Metric Interval Temporal Logic (MITL) is MTL where the timing constraints are not allowed
to be singleton sets [3]. In the rest of the paper, we restrict our focus to a fragment of MITL called BoundedMITL(3,2) where the only temporal operators allowed are Eventually (3) and Always (2) operators with timing
intervals. Formally, the syntax of Bounded-MITL(3,2) is defined by the following grammar:
Definition 1 (Bounded-MITL(3,2) syntax):
φ ::= > | ⊥ | a | ¬a | φ1 ∧ φ2 | φ1 ∨ φ2 | 3I φ1 | 2I φ1
where a ∈ AP , AP is the set of atomic propositions, > is True, ⊥ is False. Also, I is a nonsingular interval
over Q+ with defined end-points. The interval I is right-closed. We interpret MITL semantics over timed traces. A
timed trace is a mapping from the bounded real line to sets of atomic propositions (µ : [0, T ] → 2AP ). We assume
that the traces satisfy the finite variability condition (non-Zeno condition)2 .
Definition 2 (Bounded-MITL(3,2) semantics in Negation Normal Form (NNF)): Given a timed trace µ : [0, T ] →
2AP and t, t0 ∈ [0, T ], and an MITL formula φ, the satisfaction relation (µ, t)  φ is inductively defined as:
(µ, t)  >
(µ, t)  a iff a ∈ µ(t)
(µ, t)  ¬a iff a 6∈ µ(t)
(µ, t)  ϕ1 ∧ ϕ2 iff (µ, t)  ϕ1 and (µ, t)  ϕ2
(µ, t)  ϕ1 ∨ ϕ2 iff (µ, t)  ϕ1 or (µ, t)  ϕ2
(µ, t)  3I ϕ1 iff ∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  ϕ1 .
2 The

satisfiability tools for MITL that we use in Section VII-A, assumes that the traces satisfy the finite variability condition [12].

S −→ ¬T | T
T −→ A | B | C
A −→ P | (P∧A) | (P⇒A)
B −→ 2I D | 3I D
C −→ 2I 3I D | 3I 2I D
D −→ p | (p⇒A) | (p∧A) | (p⇒B) | (p∧B)
P −→ p | 2I p | 3I p
Fig. 1. Graphical representation of φcps = 2[0,30] ((speed > 100) ⇒
2[0,40] (rpm > 4000))

Fig. 2.

V I S PEC grammar to generate MITL

(µ, t)  2I ϕ1 iff ∀t0 ∈ (t + I) ∩ [0, T ], (µ, t0 )  ϕ1 .
Given an interval I = [l, u], (t + I) creates a new interval I 0 where I 0 = [l + t, u + t]. A timed trace µ satisfies
a Bounded-MITL(3,2) formula φ (denoted by µ  φ), iff (µ, 0)  φ. False is defined as ⊥ ≡ ¬>. In this paper,
we assume that Bounded-MITL(3,2) formula is in Negation Normal Form (NNF)3 where the negation operation
is only applied on atomic propositions. NNF is easily obtainable by applying DeMorgan’s Law, i.e ¬3I ϕ ≡ 2I ¬ϕ
and ¬2I ϕ ≡ 3I ¬ϕ. Any Implication operation (⇒) will be rewritten as ψ ⇒ ϕ ≡ ψ 0 ∨ ϕ, where ψ 0 ≡ ¬ψ and
also ψ 0 is in NNF, and NNF formulas, only contain the following boolean operators of (∧, ∨). For simplifying the
presentation, when we mention MITL, we mean Bounded-MITL(3,2). Given MITL formulas ϕ and ψ, ϕ satisfies
ψ, denoted by ϕ |= ψ iff ∀µ.µ |= ϕ =⇒ µ |= ψ. Throughout this paper, we use ϕ ∈ ψ to denote that ϕ is a
subformula of ψ.
B. Signal Temporal Logic
The logic and semantics of MITL can be extended to real-valued signals through Signal Temporal Logic (STL)
[38].
Definition 3 (Signal Temporal Logic [38]): Let s : [0, T ] → Rm be a real-valued signal, and Π = {π1 , ..., πn }
be a collection of predicates or boolean functions of the form πi : Rm → B where B = {>, ⊥} is a boolean value.
For any STL formula ΦST L over predicates Π, we can define a corresponding MITL formula ΦM IT L over some
atomic propositions AP as follows:
1) Define a set AP such that for each π ∈ Π, there exist some aπ ∈ AP
2) For each real-valued signal s we define a µ such that ∀t.aπ ∈ µ(t) iff π(s(t)) = >
3) ∀t.(s, t)  ΦST L iff (µ, t)  ΦM IT L
The traces resulting from abstractions through predicates of signals from physical systems satisfy the finite variability
assumption. For practical applications, the finite variability assumption is satisfied. Since our paper focuses on CPS,
with the abuse of terminology, we may use signal to refer to both timed traces and signals.
C. Visual Specification Tool
The Visual Specification Tool (V I S PEC) [29] enables the development of formal specifications for CPS. The
graphical formalism enables reasoning on both timing and event sequence occurrence. Consider the specification
φcps = 2[0,30] ((speed > 100) ⇒ 2[0,40] (rpm > 4000)). It states that whenever within the first 30 seconds, vehicle
speed goes over 100, then from that moment on, the engine speed (rpm), for the next 40 seconds, should always be
above 4000. Here, both the sequence and timing of the events are of critical importance. See Fig. 1 for the visual
representation of φcps .
Users develop specifications using a visual formalism which can be translated to an MITL formula. The set
of specifications that can be generated from this graphical formalism is a proper subset of the set of MITL
specifications. Fig. 2 represents the grammar that produces the set of formulas that can be expressed by the V I S PEC
graphical formalism. In Fig. 2, p is an atomic proposition. In the tool, the atomic propositions are automatically
derived from graphical templates. For example the formula 2I 3I p can be generated using the following parse
tree S−→T−→C−→ 2I 3I D−→ 2I 3I p. V I S PEC provides a variety of templates and the connections between
them, which allow the users to express a wide collection of specifications as presented in Table I. For more detailed
description of V I S PEC, refer to [29].
3 We

relax this assumption for addressing the Request-Response specifications (see Section VI-A1).

TABLE I.

C LASSES OF SPECIFICATIONS EXPRESSIBLE WITH THE GRAPHICAL FORMALISM

Specification
Class

Explanation

Safety
Reachability

Specifications of the form 2φ used to define specifications where φ should always be true.
Specifications of the form 3φ used to define specifications where φ should be true at least once in the future
(or now).
Specifications of the form 32φ used to define specifications that, at least once, φ should be true and from
that point on, stay true.
Specifications of the form 23φ used to define specifications that, it is always the case, that at some point in
the future, φ repeatedly will become true.
Specifications of the form φ ⇒ ψ requires that ψ should hold when φ is true.
Specifications of the form 2(φ ⇒ M ψ), where M is temporal operator, used to define an implicative
response between two specifications where the timing of M is relative to timing of 2.
Specifications of the form φ ∧ ψ used to define the conjunction of two sub-specifications.
Specifications of the form N (φ∧M ψ), where N and M are temporal operators, used to define a conjunction
between two specifications where the timing of M is relative to timing of N .

Stabilization
Oscillation
Implication
RequestResponse
Conjunction
Non-strict
Sequencing

User Input

V I S PEC
Tool

MITL

Debugging

Specification

Revision Necessary

Fig. 3.

Specification Elicitation Framework

IV.

MITL E LICITATION F RAMEWORK

Our framework for elicitation of MITL specifications is presented in Fig. 3. Once a specification is developed
using V I S PEC, it is translated to STL. Then, we create the corresponding MITL formula from STL. Next, the
MITL specification is analyzed by the debugging algorithm which returns an alert to the user if the specification
has inconsistency or correctness issues. The debugging process is explained in detail in the next section.
To enable the debugging of specifications, we must first project the STL predicate expressions (functions) into
atomic propositions with independent truth valuations. This is very important because the atomic propositions
(a ∈ AP ) in MITL are assumed to be independent of each other. However, when we project predicates to the
atomic propositions, the dependency between the predicates restricts the possible combinations of truth valuations
of the atomic propositions. This notion of predicate dependency is illustrated using the following example. Consider
the real-valued signal Speed in Fig. 4. The boolean abstraction a (resp. b) over the Speed signal is true when the
Speed is above 100 (resp. 80). The predicates a and b are related to each other because it is always the case that
if Speed > 100 then also Speed > 80. In Fig. 4, the boolean signals for predicates a and b are represented in
black solid and dotted lines, respectively. It can be seen that solid and dotted lines are overlapping which shows
the dependency between them. However, this dependency is not captured if we naively substitute each predicate
with a unique atomic proposition. If we lose information about the intrinsic logical dependency between a and b,
then the debugging algorithm will not find possible specification issues.
For analysis of STL formulas within our MITL debugging process, we must replace the original predicate
with non-overlapping (mutual exclusive) predicates. For the example illustrated in Fig. 4, we create a new atomic
proposition c which corresponds to 100 ≥ speed > 80 and the corresponding boolean signal is represented in gray.
In addition, we replace the atomic proposition b with the propositional formula a ∨ c since speed > 80 ≡ (speed >
100 ∨ 100 ≥ speed > 80). Now, the dependency between Speed > 100 and Speed > 80 can be preserved because
it is always the case that if a (Speed > 100), then a ∨ c (Speed > 80). It can be seen in Fig. 4 that the signal b
(dotted line) is the disjunction of the solid black (a) and gray (c) signals, where a and c cannot be simultaneously
true.
The projection of STL to MITL with independent atomic propositions is conducted using a brute-force approach
that runs through all the combinations of predicate expressions to find overlapping parts. The high level overview
of Algorithm 1 is as follows: given the set of predicates Π = {π1 , ..., πn }, the algorithm iteratively calls Algorithm
2 (DEC P RED) in order to identify predicates whose corresponding sets have non-empty intersections. For each
predicate πi , we assume there exists a corresponding set Si such that Si = {x | x ∈ Rm , πi (x) = >}. The set Si
represents part of space Rm where predicate function πi evaluates to >. When no non-empty intersection is found,
the Algorithm 1 terminates.
Algorithm 1 creates a temporary copy of Π in a new set ∆. Then in a while loop Algorithm 2 is called in
Line 3 to find overlapping predicates. Algorithm DEC P RED checks all the combination of predicates in ∆ until it

Speed

a
b

100
80

t

time

Boolean
abstraction

a ≡ Speed >100
time
b ≡ Speed >80

time

c ≡ 100 ≥ Speed >80

time

Fig. 4. The real-valued Speed signal and its three boolean abstractions: a ≡ speed > 100 (solid black line), b ≡ speed > 80 (dotted line),
and c ≡ 100 ≥ Speed > 80 (gray line).
Algorithm 1 Generate Mutually Exclusive Predicates
Algorithm 2 DEC P RED: Decompose Two Predicates

Input: Set of predicates Π = {π1 , ..., πn }
Output: Mutually exclusive predicates Ψ
Update Π with Disjunction of predicates Ψ
1: termCond ← 0;∆ ← Π
2: while termCond = 0 do
3:
Ψ ← DEC P RED(∆)
4:
if Ψ 6= ∅ then
5:
∆←Ψ
6:
else
7:
termCond ← 1
8:
Ψ←∆
9:
end if
10: end while
11: Π ←CreateDisjunction(Π, Ψ)
12: return Π,Ψ

Input: Set of predicates Π = {π1 , ..., πn }
Output: Set of updated predicates Π
1: for i = 1 to size of Π do
2:
for j = i + 1 to size of Π do
3:
if Si ∩ Sj 6= ∅ then
π ij1 ← Si ∩ Sj
4:
5:
π ij2 ← Si \ Sj
6:
π ij3 ← Sj \ Si
7:
REMOVE (Π, {πi , πj })
8:
APPEND (Π, {π ij1 , π ij2 , π ij3 })
9:
return Π
10:
end if
11:
end for
12: end for
13: return ∅

finds overlapping sets (see Line 3). The DEC P RED partitions two overlapping predicates πi , πj into three mutually
exclusive predicates π ij1 , π ij2 , π ij3 in Lines 4-6. Then πi , πj are removed from ∆ in Line 7 and new predicates
π ij1 , π ij2 , π ij3 are appended to ∆ (Line 8). If no overlapping predicates are found, then DEC P RED returns ∅ in
Line 13 and termCond gets value 1 in Line 7 of Algorithm 1. Now the while loop will terminate and Ψ contains all
non-overlapping predicates. We must rewrite the predicates in Π with a disjunction operation on the new predicates
in Ψ. This operation takes place in Line 11 of Algorithm 1. Since CreateDisjunction function is trivial, we omit
its pseudo code. The runtime overhead of Algorithm 1 and the size of the resulting set Ψ can be exponential to
|Π| = n, because we can have 2n possible combinations of predicate evaluations.
V.

MITL S PECIFICATION D EBUGGING

In the following, we present algorithms that can detect inconsistency and correctness issues in specifications.
This will help the user in the elicitation of correct specifications. Our specification debugging process conducts the
following checks in this order: 1) Validity, 2) Redundancy, and 3) Vacuity. In brief, validity checking determines
whether the specification is unsatisfiable or a tautology. Namely, if the specification is unsatisfiable no system can
satisfy it and if it is a tautology every system can trivially satisfy it. For example, p ∨ ¬p is a tautology. If an MITL
formula passes the validity checking, this means that the MITL is satisfiable but not a tautology.
Redundancy checking determines whether the specification has any redundant conjunct. For example, in the
specification p∧2[0,10] p, the first conjunct is redundant. Sometimes redundancy is related to incomplete or erroneous
requirements where the user may have wanted to specify something else. Therefore, the user should be notified.
Vacuity checking determines whether the specification has a subformula that does not affect on the satisfaction of
the specification. For example, ϕ = p ∨ 3[0,10] p is vacuous since the first occurrence of p does not affect on the
satisfaction of ϕ. This is a logical issue because a part of the specification is overshadowed by the other components.
The debugging process is presented in Fig. 5. The feedback (Revision Necessary) to the user is a textual

MITL
Specification

Validity

Redundancy

Vacuity

Specification passed
debugging checks

V I S PEC
Tool
Revision Necessary

Fig. 5.

Specification Debugging

description about the detail of each issue. First, given a specification, a validity check is conducted. If a formula
does not pass the validity check then it means that there is a major problem in the specification and the formula
is returned for revision. Therefore, redundancy and vacuity checks are not relevant at that point and the user is
notified that the specification is either unsatisfiable or is a tautology. Similarly, if the specification is redundant it
means that it has a conjunct that does not have any effect on the satisfaction of the specification and we return the
redundant conjunct to the user for revision. Lastly, if the specification is vacuous it is returned with the issue for
revision by the user. When vacuity is detected, we return to the user the simplified formula which is equivalent to
the original MITL.
A. Redundancy Checking
Recall that a specification has a redundancy issue if one of its conjuncts can be removed without affecting the
models of the specification. Before we formally present what redundant requirements are, we have to introduce
some notation. We consider specification Φ as a conjunction of MITL subformulas (ϕj ):
^k
Φ=
ϕj
(1)
j=1

To simplify discussion, we will abuse notation and we will associate a conjunctive formula with the set of its
conjuncts. That is:
Φ = {ϕj | j = 1, ..., k} ≡ ϕ1 ∪ ϕ2 ∪ · · · ∪ ϕk
(2)
Similarly, {Φ\ϕi } represents the specification Φ where the conjunct ϕi is removed:
^i−1
^k
{Φ\ϕi } = {ϕj | j = 1, ..., i − 1, i + 1, ..., k} =
ϕj ∧
j=1

j=i+1

ϕj

(3)

Therefore {Φ\ϕi } represents a conjunctive formula. Redundancy in specifications is fairly common in practice due
to the incremental additive approach that system engineers take in the development of specifications. Redundancy
should be avoided in formal specification because it increases the overhead of the testing and verification processes.
In addition, redundancy can be the result of incorrect translation from natural language requirement. In the following,
we consider the redundancy removal algorithm provided in [14] for LTL formulas and we extend it to support MITL
formulas.
Definition 4 (Redundancy of Specification): A conjunct ϕi is redundant with respect to Φ if
^
ψ |= ϕi
ψ∈{Φ\ϕi }

To reformulate, ϕi is redundant with respect to Φ if {Φ\ϕi } |= ϕi . For example, in Φ = 3[0,10] (p∧q)∧3[0,10] p∧
2[0,10] q, the conjunct 3[0,10] (p ∧ q) is redundant with respect to 3[0,10] p ∧ 2[0,10] q since 3[0,10] p ∧ 2[0,10] q |=
3[0,10] (p∧q). In addition, 3[0,10] p is redundant with respect to 3[0,10] (p∧q)∧2[0,10] q since 3[0,10] (p∧q)∧2[0,10] q |=
3[0,10] p. This method can catch both the issues and report them to the user. Algorithm 3 finds redundant conjuncts
in the conjunction operation of the following levels:
1) Conjunction as the root formula (top level).
2) Conjunction in the nested subformulas (lower levels).
In the top level, it provides the list of subformulas that are redundant with respect to the original MITL Φ. In the
lower levels, if a specification has nested conjunctive subformulas (φi ∈ Φ), it will return the conjunctive subformula
φi as well as its redundant conjunct ψj ∈ φi . For example, if Φ = 3[0,10] (p ∧ 2[0,10] p) is checked by Algorithm
3, then it will return the pair of (p, p ∧ 2[0,10] p) to represent that p is redundant in p ∧ 2[0,10] p. In Line 5, the pair
of (ψj , φi ) is interpreted as follows: ψj is redundant in φi .

Algorithm 3 Redundancy Checking
Input: Φ (M IT L Specification)
Output: Rϕ (redundant conjuncts w.r.t.
conjunctions)
1:
2:
3:
4:
5:
6:
7:
8:
9:

Algorithm 4 Vacuity Checking
Input: Φ (M IT L Specification)
Output: Vϕ (vacuous formulas)

Rϕ ← ∅
for each conjunctive subformula φi ∈ Φ do
for each conjunct ψj ∈ φi do
if {φi \ψj } |= ψj then
Rϕ ← Rϕ ∪ (ψj , φi )
end if
end for
end for
return Rϕ

1:
2:
3:
4:
5:
6:
7:
8:
9:

Vϕ ← ∅
for each formula ϕi ∈ Φ do
for each l ∈ litOccur(ϕi ) do
if Φ |= ϕi [l ←⊥] then
Vϕ ← Vϕ ∪ {Φ\ϕi } ∧ ϕi [l ←⊥]
end if
end for
end for
return Vϕ

B. Specification Vacuity Checking
Vacuity detection is used to ensure that all the subformulas of the specification contribute to the satisfaction of
the specification. In other words, vacuity check enables the detection of irrelevant subformulas in the specifications
[14]. For example, consider the STL specification φstl = 3[0,10] ((speed > 100) ∨ 3[0,10] (speed > 80)). In
this case, the subformula (speed > 100) does not affect the satisfaction of the specification. This indicates that
φstl is a vacuous specification. We need to create correct atomic propositions for the predicate expressions of
φstl to be able to detect such vacuity issues in MITL formulas. If we naively replace the predicate expressions
speed > 100 and speed > 80 with the atomic propositions a and b, respectively, then the resulting MITL formula
will be φmitl = 3[0,10] (a ∨ 3[0,10] b). However, φmitl is not vacuous. Therefore, we must extract non-overlapping
predicates as explained in Section IV. The new specification φ0mitl = 3[0,10] (a∨3[0,10] (a∨c)) where a corresponds
to speed > 100 and c corresponds to 100 ≥ speed > 80 is the correct MITL formula corresponding to φstl , and
it is vacuous. In the following, we provide the definition of MITL vacuity with respect to a signal:
Definition 5 (MITL Vacuity with respect to timed trace): Given a timed trace µ and an MITL formula ϕ, a
subformula ψ of ϕ does not affect the satisfiability of ϕ with respect to µ if and only if ψ can be replaced with any
subformula θ without changing the satisfiability of ϕ on µ. A specification ϕ is satisfied vacuously by µ, denoted
by µ |=V ϕ, if there exists a subformula ψ which does not affect the satisfiability of ϕ on µ.
In the following, we extend the framework presented in [14] to support MITL specifications. Let ϕ be a formula
in NNF where only predicates can be in the negated form. A literal is defined as a predicate or its negation. For a
formula ϕ, the set of literals of ϕ is denoted by literal(ϕ) and contains all the literals appearing in ϕ. For example,
if ϕ = (¬p ∧ q) ∨ 3[0,10] p ∨ 2[0,10] q, then literal(ϕ) = {¬p, q, p}. Literal occurrences, denoted by litOccur(ϕ),
is a multi-set of literals appearing in some order in ϕ, e.g., by traversal of the parse tree. For the given example
litOccur(ϕ) = {¬p, q, p, q}. For each l ∈ litOccur(ϕ), we create the mutation of ϕ by substituting the occurrence
of l with ⊥. We denote the mutated formula as ϕ[l ←⊥].
Definition 6 (M IT L Vacuity w.r.t. literal occurrence): Given a timed trace µ and an M IT L formula ϕ in NNF,
specification ϕ is vacuously satisfied by µ if there exists a literal occurrence l ∈ litOccur(ϕ) such that µ satisfies
the mutated formula ϕ[l ←⊥]. Formally, µ |=V ϕ if ∃l ∈ litOccur(ϕ) s.t. µ |= ϕ[l ←⊥].
Theorem 1 (M IT L Inherent Vacuity): Assume that the specification Φ is a conjunction of MITL formulas. If
∃ϕi ∈ Φ and ∃l ∈ litOccur(ϕi ), such that Φ |= ϕi [l ←⊥], then Φ is inherently vacuous.
The proof of T HEOREM 1 is straightforward modification of the proofs given in [14], [36]. For completeness
in the presentation, we provide the proof in Appendix IX. When we do not have a root-level conjunction in the
specification (Φ = ϕ4 ), we check the vacuity of the formula with respect to itself. In other words, we check whether
the specification satisfies its mutation (ϕ |= ϕ[l ←⊥]). Technically, Algorithm 4 as presented, returns a list of all
the mutated formulas that are equivalent to the original MITL.
VI.

S IGNAL VACUITY C HECKING

In the previous section, we addressed specification vacuity without considering the system. However, in many
cases specification vacuity depends on the system. For example, consider the LTL specification ϕ = 2(req ⇒
3ack). The specification ϕ does not have an inherent vacuity issue [24]. However, if req never happens in any of
the behaviors of the system, then the specification ϕ is vacuously satisfied on this specific system. As a result, it
4 In

this case, we assume {Φ\ϕ} ≡ > in Line 5 of the Algorithm 4.

has been argued that it is important to add vacuity detection in the model checking process [9], [36]. We encounter
the same issue when we test signals and systems with respect to Request-Response STL/MITL specifications.
A. Vacuous Signals
Consider the MITL specification ϕ = 2[0,5] (req ⇒ 3[0,10] ack). This formula will pass the MITL Specification
Debugging method presented in Section V. However, any timed trace µ that does not satisfy req at any point in time
during the test will vacuously satisfy ϕ. We refer to timed traces that do not satisfy the antecedent (precondition)
of the subformula as vacuous timed traces. Similarly, these issues follow for STL formulas over signals as well.
Consider Task 6 in Table II with the specification ψ = 3[0,40] (speed > 100) ⇒ 2[0,30] (rpm > 3000). Any realvalued signal s that does not satisfy 3[0,40] (speed > 100) will vacuously satisfy ψ. Finding such signals is important
in testing and monitoring, since if a signal s does not satisfy the precondition of an STL/MITL specification, then
there is no point in considering s as a useful test.
Definition 7 (Vacuous Timed Trace (Signal)): Given an MITL (STL) formula ϕ, a timed trace µ (signal s) is
vacuous if it satisfies at least one of the following types of ϕ’s mutations: 1) Antecedent failure mutation. 2) Literal
occurrence removal mutation5 .
1) Antecedent Failure: One of the main sources of vacuity is the antecedent failure in a Request-Response
specification such as ϕRR = 2[0,5] (req ⇒ 3[0,10] ack). We provide a formula mutation that can detect signal
vacuity in Request-Response specifications [26]:
Definition 8 (Request-Response MITL): A Request-Response MITL formula ϕRR is an MITL formula that has
one or more implication (⇒) operations in positive polarity (without any negation). In addition, for each implication
operation the consequent should be a subformula of another temporal operator.
In the Request-Response (RR) specifications, we define sequential events in a specific order (by using the
implication operator). Many practical specification patterns based on the Request-Response format are provided for
system properties [20], [34]. Therefore, we can define a chain of events that the system must respond/react to. In
an RR-specification such as ϕRR = 2[0,5] (req ⇒ 3[0,10] ack), the temporal operator for the consequent 3[0,10] ack
is necessary, unless the system does not have any time to acknowledge the req. For any trace µ in which req
never happens, we can substitute ack by any formula and the specification is still satisfied by µ. Therefore, if the
antecedent is failed by a trace µ, then ϕRR is vacuously satisfied by µ.
For each implication subformula (ϕ ⇒ ψ), the left operand (ϕ) is the precondition (antecedent) of the implication.
An antecedent failure mutation is a new formula that is created with the assertion that the precondition (ϕ) never
happens. Note that RR-specifications should not be translated into NNF. For each precondition ϕ, we create an
antecedent failure mutation 2Iϕ (¬ϕ) where Iϕ is called the effective interval of ϕ.
Definition 9 (Effective Interval): The effective interval of a subformula is the time interval when the subformula
can have an impact on the truth value of the whole MITL (STL) specification.
Each subformula is evaluated only in the time window that is provided by the effective interval. For example, for
MITL specification ϕ ∧ ψ, the effective interval for both ϕ and ψ is [0,0], because ϕ and ψ can change the value
of ϕ ∧ ψ only within the interval [0,0]. Similarly, for the MITL specification 2[0,10] ϕ, the effective interval of ϕ
is [0,10], since the truth value of ϕ is observed in the time window of [0,10] for evaluating 2[0,10] ϕ. The effective
interval is important for the creation of an accurate antecedent failure mutation. This is because the antecedent can
affect the truth value of the MITL formula only if it is evaluated in the effective interval. The effective interval
is like a timing window to make the antecedent observable for an outside observer the way it is observed by the
MITL specification. The effective interval of MITL formulas can be computed recursively using Algorithm 5. To
run Algorithm 5, we must process the MITL formula parse tree6 . The algorithm must be initialized with the interval
of [0,0] for the top node of the MITL formula, namely, EIU(ϕ,[0,0]). This is because, according to the semantics of
MITL, the value of the whole MITL formula is only important at time zero. In Line 8 of Algorithm 5, the operator
⊕ is used to add two intervals as follows:
Definition 10 (⊕): Given intervals I = [l, u] and I 0 = [l0 , u0 ], we define I 00 ← I ⊕ I 0 where I 00 = [l00 , u00 ] such
that l00 = l + l0 and u00 = u + u0 .
5 In Section VI-A2, we discuss that literal occurrence removal mutation does not guarantee the existence of vacuity issue, but it has application
for the falsification purposes.
6 We assume that the MITL specification is saved in a binary tree data structure where each node is a formula with the left/right child as the
left/right corresponding subformula. of ϕ. In addition, we assume that the nodes of ϕ’s tree contain a field called EI where we annotate the
effective interval of ϕ in EI, namely, ϕ.EI ← Iϕ .

Algorithm 5 Effective Interval Update EIU(ϕ,I)
Input: ϕ (Parse Tree of the MITL formula), I (Effective Interval)
Output: ϕ (Updated formula with subformulas annotated with effective intervals)
1: ϕ.EI ← I
2: if ϕ ≡ ¬ϕm then
3:
EIU(ϕm ,I)
4: else if ϕ ≡ ϕm ∨ ϕn OR ϕ ≡ ϕm ∧ ϕn OR ϕ ≡ ϕm ⇒ ϕn then
5:
EIU(ϕm ,I)
6:
EIU(ϕn ,I)
7: else if ϕ ≡ 2I 0 ϕm OR ϕ ≡ 3I 0 ϕm then
8:
I 00 ← I 0 ⊕ I
9:
EIU(ϕm ,I 00 )
10: end if
11: return ϕ
Algorithm 6 Antecedent Failure
Input: ϕRR ,s (RR-Specification, Signal)
Output: AFϕ a list of failed antecedents
1: AFϕ ← ∅
2: EIU(ϕ,[0,0])
3: for each implication (ϕi ⇒ ψi ) ∈ ϕRR do
4:
Iϕi ← ϕi .EI
5:
if s |= 2Iϕi (¬ϕi ) then
6:
AFϕ ← AFϕ ∪ (ϕi ⇒ ψi )
7:
end if
8: end for
9: return AFϕ

Algorithm 7 Literal Occurrence Removal
Input: Φ,s (Specification, Signal)
Output: M Fϕ a list of mutated formulas
1: M Fϕ ← ∅
2: for each formula ϕi ∈ Φ do
3:
for each l ∈ litOccur(ϕi ) do
4:
if s |= ϕi [l ←⊥] then
5:
M Fϕ ← M Fϕ ∪ {ϕi [l ←⊥]}
6:
end if
7:
end for
8: end for
9: return M Fϕ

If either I or I 0 is left open (resp. right open), then I 00 will be left open (resp. right open)7 . In Line 1 of Algorithm
5, the input interval I is assigned to the effective interval of ϕ, namely ϕ.EI. If the top operation of ϕ is a
propositional operation (¬, ∨, ∧, ⇒) then the I will be propagated to subformulas of ϕ (see Lines 2-6). If the top
operation of ϕ is a temporal operator (2I 0 , 3I 0 ), then the effective interval is modified according to Definition 10
and the interval I 00 ← I ⊕ I 0 is propagated to the subformulas of ϕ.
For example, assume that the MITL specification is ϕRR = 2[1,2] (3[3,5] b ⇒ (2[4,6] (c ⇒ 3[0,2] d))). The
specification ϕ has two antecedents, α1 = 3[3,5] b and α2 = c. The effective intervals of α1 and α2 are Iα1 =
[0, 0] ⊕ [1, 2] = [1, 2] and Iα2 = [0, 0] ⊕ [1, 2] ⊕ [4, 6] = [5, 8], respectively. As a result, the corresponding antecedent
failure mutations are 2[1,2] (¬3[3,5] b) and 2[5,8] (¬c), respectively. Algorithm 6 returns the list of antecedent failures
AFϕ , namely all the implication subformulas that are vacuously satisfied by s. If the AFϕ list is empty, then the
signal s is not vacuous.
2) Literal Occurrence Removal: When the specification is in NNF, we consider this mutation. This mutation type
is generated by repeatedly substituting the occurrences of literals with ⊥ denoted by ϕ[l ←⊥] (see the Definition
6). In Algorithm 7, we check whether the signal will satisfy the mutated specification (ϕi [l ←⊥]). Finally, all
the mutated formulas will be returned to the user (M Fϕ ). To check whether signal s satisfies ϕ’s mutations in
Algorithm 6 (Line 3) and Algorithm 7 (Line 4), we should use an off-line monitor such as [22]. In Appendix X,
we prove that for any MITL (STL) specification ϕ, which contains one or more disjunction operators (∨) in its
NNF, any timed trace (signal) that satisfies ϕ will also satisfy a mutation ϕ[l ←⊥] for some literal occurrence l.
Theorem 2: For all MITL formula ϕ ∈ Φ in NNF, if there exists a disjunction subformula in ϕ, then for all µ
such that µ |= ϕ it is always the case that µ |= ϕ[l ←⊥].
Further, any specification which lacks a disjunction operator (∨) in its NNF will not satisfy ϕ[l ←⊥] for any
literal occurrence l. That is, for formulas without any disjunction operator in NNF, we have ϕ[l ←⊥] ≡⊥ since
for any MITL formula ϕ, we have ϕ∧ ⊥≡⊥. Therefore, Algorithm 7 should not be used for formulas without
disjunction in NNF. Antecedent failure is the most critical issue in vacuity analysis. Therefore, when the specification
has implication operators, we should only utilize Algorithm 6. It should be noted that Algorithm 7 cannot find the
antecedent failure issue.
7 Although

we assume in Definition 1 that intervals are right-closed, Algorithm 5 can be applied to right-open intervals as well.

1

Signal Vacuity
Checking

Is signal
Vacuous?

ϕ

System under
Test
initial
conditions &
input signal

output signals

QTL Solver

MITL Monitor
Falsified/Satisfied

Zot
Validity
Redundancy
Vacuity

Z3
MITL CLTLoc SMT
SAT
SAT

Input
Generator

Fig. 7. The MITL SAT solver from [12] is used for
Testing Framework
M. Bersani and M. Rossi and P. San Pietro, A tool for deciding the satisﬁability of continuous-time metric
debugging
specifications.
temporal logic. Acta Informatica,
pages 1–36,
2015.
Fig. 6. Using signal vacuity checking to improve the confidence of an automatic test
generation framework.

CPS Lab

However, Algorithm 7 has two applications for the falsification purposes. In Section VII-D, we explain the
importance and practicality of the falsification methodology and the counter example generation for testing and
verification of CPS. First, Algorithm 7 can find which (how many) disjuncts are satisfied by the signal. This
information can be used by falsification technique to target the disjuncts/predicates that cause the signal satisfaction.
As a result, Algorithm 7 can be used to improve falsification method. Second, Algorithm 7 can be used for
specification coverage analysis when falsification occurs. This is because with a slight modification, the dual of
Algorithm 7 can help us to find the source of the falsification. According to Corollary 1, for any ϕ in NNF, where
ϕ has a conjunctive subformula of ψ = ψ1 ∧ ψ2 , if µ 6|= ϕ then ∃l ∈ litOccur(ψ) s.t µ 6|= ϕ[l ← >]. Now,
we can identify which conjunct of ψ contributes towards the falsification by substituting it by iteratively applying
ϕ[l ← >]. This can be better explained in the following example:
Example 1: Assume ϕ = 3I1 (a ∧ 3I2 b) and a falsifying trace µ 6|= ϕ exists. Formula ϕ contains conjunction
of ψ = a ∧ 3I2 b and litOccur(ψ) = {a, b}. We can substitute a and b to find the source of falsification of ϕ as
follows:
• If µ |= ϕ[a ← >] then µ |= 3I1 (3I2 b), so a is the source of the problem.
• If µ |= ϕ[b ← >] then µ |= 3I1 (a), so b is the source of the problem.
As a result, the dual of Algorithm 7 can be used to debug a trace when the counter example is created using
falsification methodologies [1].
B. Vacuity Detection in Testing
Detecting vacuous satisfaction of specifications is usually applied on top of model checking tools for finite state
systems [9], [36]. However, in general, the verification problem for hybrid automata (a mathematical model of CPS)
is undecidable [2]. Therefore, a formal guarantee about the correctness of CPS modeling and design is impossible,
in general. CPS are usually safety critical systems and the verification and validation of these systems is necessary.
One approach is to use Model Based Design (MBD) with a mathematical model of the CPS to facilitate the system
analysis and implementation [1]. Thus, semi-formal verification methods are gaining popularity [31]. Although we
cannot solve the correctness problem with testing and monitoring, we can detect possible errors with respect to
STL requirements. Vacuity detection in testing is important because vacuous signals satisfy the specification for
reasons other than what was probably intended.
In Fig. 6, a testing approach for signal vacuity detection is presented. The input generator creates initial conditions
and inputs to the system under test. The system under test can be a Model, Process in the Loop, Hardware in the
Loop or a real system. An example of a test generation technology that implements the architecture in Fig. 6 is
presented in [1]. The system under test is simulated to generate an output trace. Then, a monitor checks the trace
with respect to the specification and reports to the user whether the system trace satisfies or falsifies the specification
(for example [43], [38]). For each falsification we will report to the user the falsifying trajectory to investigate the
system for this error. In addition, signal vacuity checking is conducted using Algorithms 6 or 7, and vacuous traces
are reported to the user for more inspection. It should be noted that signal vacuity checking in the S-TA L I RO tool
is computationally efficient (PTIME). The time complexity is proportional to the number of implication operations,
the size of the formula and to the size of the signal [22].
VII.

E XPERIMENTAL A NALYSIS

All the 3-level correctness analysis of MITL specifications need satisfiability checking as the underlying tool
[13]. In validity checking, we simply check whether the specification and its negation are satisfiable. In general, in

order to check whether ϕ |= ψ, we should check whether ϕ ⇒ ψ is a tautology, that is ∀µ, µ |= ϕ ⇒ ψ. This can
be verified by checking whether ¬(ϕ ⇒ ψ) is unsatisfiable. Recall that ϕ ⇒ ψ is equivalent to ¬ϕ ∨ ψ. So we
have to check whether ϕ ∧ ¬ψ is unsatisfiable to conclude that ϕ |= ψ. We use the above reasoning for redundancy
checking as well as for vacuity checking. For redundancy checking of conjunction at the root level, {Φ\ϕi } ∧ ¬ϕi
should be unsatisfiable, in order to conclude that {Φ\ϕi } |= ϕi . For vacuity checking, Φ ∧ ¬(ϕi [l ←⊥]) should be
unsatisfiable, in order to prove that Φ |= ϕi [l ←⊥].
A. MITL Satisfiability
The satisfiability problem of MITL is EXPSPACE-Complete [3]. In order to check whether an MITL formula
is satisfiable we use two publicly available tools: qtlsolver8 and zot9 . The qtlsolver that we used translates MITL
formulas into CLTL-over-clocks [12], [13]. Constraint LTL (CLTL) is an extension of LTL where predicates are
allowed to be the assertions on the values of non-Boolean variables [17]. That is, in CLTL, we are allowed to define
predicates using relational operators for variables over domains like N and Z. Although satisfiability of CLTL in
general is not decidable, some variants of it are decidable [17].
CLTLoc (CLTL-over-clocks) is a variant of CLTL where the clock variables are the only arithmetic variables
that are considered in the atomic constraints. It has been proven in [11] that CLTLoc is equivalent to timed automata
[16]. Moreover, it can be polynomially reduced to decidable Satisfiability Modulo Theories which are solvable by
many SMT solvers such as Z310 . The satisfiability of CLTLoc is PSPACE-complete [13] and the translation from
MITL to CLTLoc in the worst case can be exponential [12]. Some restrictions must be imposed on the MITL
formulas in order to use the qtlsolver [12]. That is, the lower bound and upper bound for the intervals of MITL
formulas should be integer values and the intervals are left/right closed. Therefore, we expect the values to be
integer when we analyse MITL formulas. The high level architecture of the MITL SAT solver, which we use to
check the three issues, is provided in Fig. 7.
B. Specification Debugging Results
We utilize the debugging algorithm on a set of specifications developed as part of a usability study for the
evaluation of the V I S PEC tool [29]. The usability study was conducted on two groups:
1) Group A: These are users who declared that they have little to no experience in working with requirements.
Group A cohort consists of twenty subjects from the academic community at Arizona State University. Most
of the subjects have an engineering background.
2) Group B: These are users who declared that they have experience working with system requirements. Note that
they do not necessarily have experience in writing requirements using formal logics. Group B subject cohort
was comprised of ten subjects from the industry in the Phoenix metro area.
Each subject received a task list to complete. The list contained ten tasks related to automotive system specifications. Each task asked the subject to formalize a natural language specification through V I S PEC and generate an STL
specification. The task list is presented in Table II. A detailed report on the accuracy of the users response to each
natural language requirement is provided in [29]. Note that the specifications were preprocessed and transformed
from the original STL formulas to MITL in order to run the debugging algorithm. For example, specification φ3 in
Table III originally in STL was φ3ST L = 3[0,40] (((speed > 80) ⇒ 3[0,20] (rpm > 4000)) ∧ 2[0,30] (speed > 100)).
The STL predicate expressions (speed > 80), (rpm > 4000), (speed > 100) are mapped into atomic propositions
with non-overlapping predicates (Boolean functions) p1 , p2 , p3 . The predicates p1 , p2 , p3 correspond to the following
STL representations: p1 ≡ speed > 100, p2 ≡ rpm > 4000, and p3 ≡ 100 ≥ speed > 80. In Table III, we
present the common issues with the elicited specifications that our debugging algorithm detects. Note that validity,
redundancy and vacuity issues are present in the specifications listed. It should be noted that for specification φ3 ,
although finding the error takes a significant amount of time, our algorithm can be used off-line.
In Fig. 8, we present the runtime overhead of the three stage debugging algorithm over specifications collected
in the usability study. In the first stage, 87 specifications go through validity checking. Five specifications fail the
test and therefore they are immediately returned to the user. As a result, 82 specifications go through redundancy
checking of conjunction in the root level 11 , where 9 fail the test. Lastly, 73 specifications go through vacuity
checking where 5 specification have vacuity issues. The remaining 68 specifications passed the tests. Note that in
8 qtlsolver: A solver for checking satisfiability of Quantitative / Metric Interval Temporal Logic (MITL/QTL) over Reals. Available from
https://code.google.com/p/qtlsolver/
9 The zot bounded model/satisfiability checker. Available from https://code.google.com/p/zot/
10 Microsoft Research, Z3: An efficient SMT solver. Available from http://research.microsoft.com/en-us/um/redmond/projects/z3/
11 In these experiments, we did not consider conjunctions in the lower level subformulas for redundancy checking.

TABLE II.

TASK LIST WITH AUTOMOTIVE SYSTEM SPECIFICATIONS PRESENTED IN NATURAL LANGUAGE

Task

Natural Language Specification

1. Safety
2. Reachability
3. Stabilization

In the first 40 seconds, vehicle speed should always be less than 160.
In the first 30 seconds, vehicle speed should go over 120.
At some point in time in the first 30 seconds, vehicle speed will go over 100 and stay above for 20
seconds.
At every point in time in the first 40 seconds, vehicle speed will go over 100 in the next 10 seconds.
It is not the case that, for up to 40 seconds, the vehicle speed will go over 100 in every 10 second
period.
If, within 40 seconds, vehicle speed is above 100 then within 30 seconds from time 0, engine speed
should be over 3000.
If, at some point in time in the first 40 seconds, vehicle speed goes over 80 then from that point
on, for the next 30 seconds, engine speed should be over 4000.
In the first 40 seconds, vehicle speed should be less than 100 and engine speed should be under
4000.
At some point in time in the first 40 seconds, vehicle speed should go over 80 and then from that
point on, for the next 30 seconds, engine speed should be over 4000.
If, at some point in time in the first 40 seconds, vehicle speed goes over 80 then from that point
on, if within the next 20 seconds the engine speed goes over 4000, then, for the next 30 seconds,
the vehicle speed should be over 100.

4. Oscillation
5. Oscillation
6. Implication
7. Request-Response
8. Conjunction
9. Non-strict sequencing
10. Long sequence

TABLE III.

I NCORRECT SPECIFICATIONS FROM THE USABILITY STUDY IN [29], ERROR REPORTED TO THE USER BY THE DEBUGGING
ALGORITHM , AND ALGORITHM RUNTIME . F ORMULAS HAVE BEEN TRANSLATED FROM STL TO MITL.
φ

Task #

MITL Specification created by V I S PEC users

Reporting the errors

Sec.

φ1
φ2
φ3
φ4
φ5

3
3
10
4
10

3[0,30] p1 ∧ 3[0,20] p1
3[0,30] (p1 ⇒ 2[0,20] p1 )
3[0,40] (((p1 ∨ p3 ) ⇒ 3[0,20] p2 ) ∧ 2[0,30] p1 )
2[0,40] p1 ∧ 2[0,40] 3[0,10] p1
3[0,40] (p1 ∨ p3 ) ∧ 3[0,40] p2 ∧ 3[0,40] 2[0,30] p1

3[0,30] p1 is redundant
ϕ is a tautology
ϕ is vacuous: ϕ |= ϕ[p3 ←⊥]
2[0,40] 3[0,10] p1 is redundant
3[0,40] (p1 ∨ p3 ) is redundant

14
7
39645
29
126

the figure, two outlier data points are omitted from the vacuity sub-figure for presentation purposes. The two cases
were timed at 39,618sec and 17,421sec. In both cases, the runtime overhead was mainly because the zot software
took hours to determine that the modified specification is unsatisfiable (both specifications were vacuous). The
overall runtime of φ3 in Table III is 39,645sec which includes the runtime of validity and redundancy checking.
The runtime overhead of vacuity checking of φ3 can be reduced by half because, originally, in vacuity checking
we run MITL satisfiability checking for all literal occurrences. In particular, φ3 has four literal occurrences where
for two cases zot took more than 19,500sec to determine that the modified specification is unsatisfiable. We can
provide an option for early detection: stop and report as soon as an issue is found (the first unsatisfiability).
The circles in Fig. 8 represent the timing performance in each test categorized by the number of literal
occurrences and temporal operators. The asterisks represent the mean values and the dashed line is the linear
interpolation between them. In general, we observe an increase in the average computation time as the number of
literal occurrences and temporal operators increases. All the experimental results in Section VII were performed on
an Intel Xeon X5647 (2.993GHz) with 12 GB RAM.
C. LTL Satisfiability
In the previous section, we mentioned that MITL satisfiability problem is a computationally hard problem.
However, in practice, we know that LTL satisfiability is solvable faster than the MITL satisfiability [37]. In this
section, we consider how we can use the satisfiability of LTL formulas to decide about the satisfiability of MITL
formulas. Consider the following fragments of MITL and LTL in NNF:
MITL(2): ϕ ::= > | ⊥ | p | ¬p | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 2I ϕ1
MITL(3): ϕ ::= > | ⊥ | p | ¬p | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 3I ϕ1
LTL(2): ϕ ::= > | ⊥ | p | ¬p | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 2ϕ1
LTL(3): ϕ ::= > | ⊥ | p | ¬p | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 3ϕ1
In Appendix XI, we prove that the satisfaction of a formula φM ∈ MITL(3) in NNF is related to the satisfaction
of an LTL version of φM called φL ∈ LTL(3) where φL is identical to φM except that every interval I in φM is
removed. For example, if φM = 3[0,10] (p ∧ q) ∧ 3[0,10] p then φL = 3(p ∧ q) ∧ 3p. In essence, if φM is satisfiable,
then φL is also satisfiable. Therefore, if φL is unsatisfiable, then φM is also unsatisfiable.
For the always (2) operator, satisfiability is the dual of the eventually operator (3). Assume that φ0M ∈ MITL(2)
contains only the 2 operator and φ0L ∈ LTL(2) is the LTL version of φ0M . If φ0L is satisfiable, then φ0M will also
be satisfiable.

Validity
200
Time (sec)

Time (sec)

200
100

0

1

2

3
Literal Occurence

4

100

0

5

1

2
3
4
No. of Temporal Operators

5

1

2
3
4
No. of Temporal Operators

5

2
3
4
No. of Temporal Operators

5

Redundancy
150
Time (sec)

Time (sec)

150
100
50
0

1

2

3
Literal Occurence

4

100
50
0

5

Vacuity
1500
Time (sec)

Time (sec)

1500
1000
500
0

1

2

3
Literal Occurence

4

5

1000
500
0

1

Fig. 8. Runtime overhead of the three stages of the debugging algorithm over user-submitted specifications. Timing results are presented over
the number of literal occurrences and the number of temporal operators.

Based on the above discussion, if the specification that we intend to test/debug belongs to either category
(fragment), MITL(3) or MITL(2), then we can check the satisfiability of its LTL version (φL ) and decide according
to the following:
Theorem 3: For any formula φM ∈ MITL(3) and φ0M ∈ MITL(2) then
If φL ∈ LTL(3) is unsatisfiable, then φM is unsatisfiable.
If φ0L ∈ LTL(2) is satisfiable, then φ0M is satisfiable.
In these two cases, we do not need to run MITL SAT, if otherwise, we must apply MITL SAT which means that
we wasted effort by checking LTL SAT. However, since the runtime of LTL SAT is negligible, it will not drastically
reduce the performance. As a result LTL satisfiability checking is useful for validity testing. For redundancy checks,
it may also be useful. For example, if we have a formula φ = 3[0,10] p ∧ 2[0,20] p we should check the satisfiability
of φ0 = 2[0,10] ¬p ∧ 2[0,20] p and φ00 = 3[0,10] p ∧ 3[0,20] ¬p for redundancy. Although the original formula φ does
not belong to either MITL(3) or MITL(2), its modified NNF version will fit in these fragments and we may benefit
by the usually faster LTL satisfiability for φ0 and/or φ00 . For vacuity checking, we can use LTL satisfiability if after
manipulating/simplifying the original specification and creating the NNF version, we can categorize the resulting
formula into the MITL(3) or the MITL(2) fragments (see Table IV).
We can check LTL satisfiability of the modified MITL specifications using existing methods and tools [42]. In
our case, we used the NuSMV12 tool with a similar encoding of LTL formulas as in [42]. In Table IV, we compare
the runtime overhead of MITL and LTL satisfiability checking. For the results of the usability study in [29], we
conduct validity and vacuity checking with the LTL satisfiability solver. We remark that in our results in Table IV,
all the formulas belong to the MITL(2) fragment. Since we did not find any MITL(3) formula in our experiments
where its LTL version is not satisfiable, we did not provide MITL(3) formulas in Table IV.
The first column of Table IV provides the debugging test phase where we used the satisfiability checkers. The
second column represents the MITL formulas that we tested using the SAT solver. We omit the LTL formulas
from Table IV, since they are identical to MITL but do not contain timing intervals. The atomic propositions
p1 , p2 , p3 , p4 , p5 of the MITL formulas in Table IV correspond to the following STL predicates: p1 ≡ speed > 100,
p2 ≡ rpm > 4000, p3 ≡ 100 ≥ speed > 80, p4 ≡ rpm > 3000, and p5 ≡ speed > 80. The third and fourth
columns represent the runtime overhead of satisfiability checking for MITL specifications and their corresponding
12

NuSMV Version 2.6.0. Available from http://nusmv.fbk.eu/

TABLE IV.

C OMPARING THE RUNTIME OVERHEAD OF MITL SATISFIABILITY AND LTL SATISFIABILITY ( IN S ECONDS ) FOR SOME OF
THE SPECIFICATIONS FROM V I S PEC ’ S USABILITY STUDY.

TABLE V.
Req.
φAT
1
φAT
2
φAT
3
φAT
4

Test
Phase

MITL Specification

MITL
SAT

LTL
SAT

MITL
LTL

Validity
Validity
Validity
Validity
Vacuity
Vacuity
Vacuity
Vacuity

2[0,40] (p1 ⇒ 2[0,10] (p1 ))
2[0,30] (¬p1 ) ∨ 2[0,20] (¬p1 )
2[0,40] ((¬p1 ∧ ¬p3 ) ∨ 2[0,20] ¬p2 ∨ 2[0,30] p1 ))
2[0,40] ((p1 ∨ p3 ) ⇒ 2[0,20] (p2 ⇒ 2[0,30] p1 ))
2[0,40] (p1 )
2[0,40] (p1 ∧ 2[0,10] (p1 ))
2[0,40] p1 ∧ 2[0,30] (p4 )
2[0,40] p5 ∧ 2[0,70] (p5 )

4.154
3.418
10.85
15.406
1.71
3.727
5.77
8.599

0.047
0.0538
0.045
0.0463
0.0473
0.044
0.0456
0.044

88
63
240
333
36
84
126
194

AUTOMATIC T RANSMISSION R EQUIREMENTS EXPRESSED IN NATUAL LANGUAGE AND MITL FROM [27]
Natural Language
There should be no transition from gear two to gear
one and back to gear two in less than 2.5 sec.
After shifting into gear one, there should be no shift
from gear one to any other gear within 2.5 sec.
If the ω is always less than 4500, then the v can not
exceed 85 in less than 10 sec.
Within 10 sec. v is less than 80 and from that point
on, ω is always less than 4500.

MITL Formula
2[0,27.5] ((g2 ∧ 3(0,0.04] g1 ) ⇒ 2[0,2.5] ¬g2 )
2[0,27.5] ((¬g1 ∧ 3(0,0.04] g1 ) ⇒ 2[0,2.5] g1 )
2[0,30] (ω ≤ 4500) ⇒ 2[0,10] (v ≤ 85)
3[0,10] ((v ≤ 80) ⇒ 2[0,30] (ω ≤ 4500))

LTL version. The last column represents the speedup of the LTL approach over the MITL approach. It can be seen
that the LTL SAT solver (NuSMV) is about 30-300 times faster than the MITL SAT solver (zot). These results
confirm that, when applicable, LTL SAT solvers outperform MITL SAT solvers in checking vacuity and validity
issues in specifications. As a result, it worths to run LTL SAT before MITL SAT when it is possible.
D. Antecedent Failure Detection
To apply signal vacuity checking we use the S-TA L I RO testing framework [1], [28]. S-TA L I RO is a MatLab
toolbox that uses stochastic optimization techniques to search for system inputs for Simulink models which falsify
the safety requirements presented in MTL [1]. Falsification based approaches for CPS can help us find subtle bugs
in industrial size control systems [30]. If after using stochastic-based testing and numerical analysis we could not
find those bugs, then we are more confident that the system works correctly. However, it will be concerning if
the numerical analysis is mostly based on vacuous signals. If we report vacuous signals to S-TA L I RO users, then
they will be aware of the vacuity issue. This will help them to focus on the part of the system that causes the
generation of vacuous signals. For example, users should find the system inputs that activate the antecedent in case
of antecedent failure.
In the following, we illustrate the vacuous signal detection process by using the Automatic Transmission (AT)
model provided by Mathworks as a Simulink demo13 . We introduced a few modifications to the model to make it
compatible with the S-TA L I RO framework. Further details can be found in [27]. S-TA L I RO calls the AT Simulink
model in order to generate the output trajectories. The outputs contain two continuous-time real-valued signals: the
speed of the engine ω (RPM) and the speed of the vehicle v. In addition, the outputs contain one continuous-time
discrete-valued signal gear with four possible values (gear = 1, ..., gear = 4) which indicates the current gear in the
auto-transmission controller. S-TA L I RO then monitors system trajectories with respect to the requirements provided
in Table V. There, in the MITL formulas, we use the shorthand gi to indicate the gear value, i.e. (gear = i) ≡ gi .
The simulation time for the system is set to 30 seconds; therefore, we can use bounded MITL formulas for the
requirements.
After testing the AT with S-TA L I RO, we collected all the system trajectories. Then, we utilized the antecedent
failure mutation on the specification to check signal vacuity (Algorithm 6) for each of the formulas that are provided
in Table V. We provide the antecedent failure specifications and the signals that satisfy them in Table VI. It can
be seen in Table VI that most of the system traces are vacuous signals where the antecedent is not satisfied. This
helps the users to consider these issues and identify interesting test cases that can be used to initialize the system
tester so that the antecedent is always satisfied.
VIII.

C ONCLUSION AND F UTURE W ORK

We have presented a specification elicitation and debugging framework that can assist V I S PEC users to produce
correct formal specifications. In particular, the debugging algorithm enables the detection of logical inconsistencies
13 Available

at: http://www.mathworks.com/help/simulink/examples/modeling-an-automatic-transmission-controller.html

TABLE VI.

R EPORTING SIGNAL VACUITY ISSUE FOR EACH MUTATED FORMULA

Requirement
φAT
1
φAT
2
φAT
3
φAT
4

Antecedent Failure Mutation
2[0,27.5] ¬(g2 ∧ 3(0,0.04] g1 )
2[0,27.5] ¬(¬g1 ∧ 3(0,0.04] g1 )
¬2[0,30] (ω ≤ 4500)
2[0,10] ¬(v ≤ 80)

Vacuous Signals / All Signals
1989 / 2000
1994 / 2000
60 / 214
1996 / 2000

in MITL and STL specifications. Our algorithm improves the elicitation process by providing feedback to the users
on validity, redundancy and vacuity issues. In the future, the specification elicitation and debugging framework will
be integrated in the V I S PEC tool to simplify MITL and STL specification development for verification of CPS. In
addition, we considered vacuity detection with respect to signals. This enables improved analysis since some issues
can only be detected when considering both the system and the specification. In the future, we will consider the
feasibility of using vacuous signals to improve the counter example generation process and system debugging using
signal vacuity.
ACKNOWLEDGMENT
This work was partially supported by NSF awards CNS 1350420 and CNS 1319560.
R EFERENCES
[1]
[2]
[3]
[4]

[5]
[6]
[7]
[8]
[9]
[10]
[11]

[12]
[13]
[14]
[15]

[16]
[17]
[18]

[19]
[20]
[21]

H. Abbas, G. Fainekos, S. Sankaranarayanan, F. Ivančić, and A. Gupta. Probabilistic temporal logic falsification of cyber-physical systems.
ACM Trans. Embed. Comput. Syst., 12(2s):95:1–95:30, May 2013.
R. Alur, C. Courcoubetis, N. Halbwachs, T. A. Henzinger, P.-H. Ho, X. Nicollin, A. Olivero, J. Sifakis, and S. Yovine. The algorithmic
analysis of hybrid systems. Theoretical Computer Science, 138(1):3–34, 1995.
R. Alur, T. Feder, and T. A. Henzinger. The benefits of relaxing punctuality. J. ACM, 43(1):116–146, 1996.
G. Ammons, D. Mandelin, R. Bodı́k, and J. R. Larus. Debugging temporal specifications with concept analysis. In Proceedings of the
ACM SIGPLAN 2003 Conference on Programming Language Design and Implementation 2003, San Diego, California, USA, June 9-11,
2003, pages 182–195, 2003.
Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan. S-taliro: A tool for temporal logic falsification for hybrid
systems. In Tools and algorithms for the construction and analysis of systems, volume 6605 of LNCS, pages 254–257. Springer, 2011.
M. Autili, P. Inverardi, and P. Pelliccione. Graphical scenarios for specifying temporal properties: an automated approach. Automated
Software Engineering, 14(3):293–340, 2007.
T. Ball and O. Kupferman. Vacuity in testing. In Tests and Proofs, Second International Conference, TAP 2008, Prato, Italy, April 9-11,
2008. Proceedings, pages 4–17, 2008.
D. L. Beatty and R. E. Bryant. Formally verifying a microprocessor using a simulation methodology. In DAC, pages 596–602, 1994.
I. Beer, S. Ben-David, C. Eisner, and Y. Rodeh. Efficient detection of vacuity in temporal model checking. Formal Methods in System
Design, 18(2):141–163, 2001.
S. Ben-David, F. Copty, D. Fisman, and S. Ruah. Vacuity in practice: temporal antecedent failure. Formal Methods in System Design,
46(1):81–104, 2015.
M. M. Bersani, M. Rossi, and P. S. Pietro. A logical characterization of timed (non-)regular languages. In Mathematical Foundations
of Computer Science 2014 - 39th International Symposium, MFCS 2014, Budapest, Hungary, August 25-29, 2014. Proceedings, Part I,
pages 75–86, 2014.
M. M. Bersani, M. Rossi, and P. S. Pietro. A tool for deciding the satisfiability of continuous-time metric temporal logic. Acta Inf.,
53(2):171–206, 2016.
M. M. Bersani, M. Rossi, and P. San Pietro. Deciding the satisfiability of mitl specifications. In Fourth International Symposium on
Games, Automata, Logics and Formal Verification,, volume 119 of EPTCS, pages 64–78. Open Publishing Association, 2013.
H. Chockler and O. Strichman. Before and after vacuity. Form. Methods Syst. Des., 34(1):37–58, Feb. 2009.
A. Cimatti, M. Roveri, V. Schuppan, and A. Tchaltsev. Diagnostic information for realizability. In Verification, Model Checking, and
Abstract Interpretation, 9th International Conference, VMCAI 2008, San Francisco, USA, January 7-9, 2008, Proceedings, pages 52–67,
2008.
E. M. Clarke, O. Grumberg, and D. A. Peled. Model Checking. MIT Press, Cambridge, Massachusetts, 1999.
S. Demri and D. D’Souza. An automata-theoretic approach to constraint LTL. Inf. Comput., 205(3):380–415, 2007.
A. Dokhanchi, B. Hoxha, and G. E. Fainekos. Metric interval temporal logic specification elicitation and debugging. In 13. ACM/IEEE
International Conference on Formal Methods and Models for Codesign, MEMOCODE 2015, Austin, TX, USA, September 21-23, 2015,
pages 70–79, 2015.
A. Donze. Breach, a toolbox for verification and parameter synthesis of hybrid systems. In Computer Aided Verification, volume 6174
of LNCS, pages 167–170. Springer, 2010.
M. B. Dwyer, G. S. Avrunin, and J. C. Corbett. Property specification patterns for finite-state verification. In Proceedings of the Second
Workshop on Formal Methods in Software Practice, FMSP ’98, pages 7–15. ACM, 1998.
R. Ehlers and V. Raman. Low-effort specification debugging and analysis. In Proceedings 3rd Workshop on Synthesis, SYNT 2014,
Vienna, Austria, July 23-24, 2014., pages 117–133, 2014.

[22]
[23]
[24]

[25]
[26]
[27]
[28]
[29]
[30]
[31]
[32]
[33]
[34]
[35]
[36]
[37]
[38]
[39]
[40]
[41]
[42]
[43]
[44]
[45]

G. Fainekos, S. Sankaranarayanan, K. Ueda, and H. Yazarel. Verification of automotive control applications using s-taliro. In Proceedings
of the American Control Conference, 2012.
G. E. Fainekos. Revising temporal logic specifications for motion planning. In IEEE International Conference on Robotics and Automation,
ICRA 2011, Shanghai, China, 9-13 May 2011, pages 40–45, 2011.
D. Fisman, O. Kupferman, S. Sheinvald-Faragy, and M. Y. Vardi. A framework for inherent vacuity. In Hardware and Software: Verification
and Testing, 4th International Haifa Verification Conference, HVC 2008, Haifa, Israel, October 27-30, 2008. Proceedings, pages 7–22,
2008.
K. Havelund and G. Rosu. Efficient monitoring of safety properties. STTT, 6(2):158–173, 2004.
F. Horn, W. Thomas, N. Wallmeier, and M. Zimmermann. Optimal strategy synthesis for request-response games. RAIRO - Theor. Inf.
and Applic., 49(3):179–203, 2015.
B. Hoxha, H. Abbas, and G. Fainekos. Benchmarks for temporal logic requirements for automotive systems. In Proc. of Applied
Verification for Continuous and Hybrid Systems, 2014.
B. Hoxha, H. Bach, H. Abbas, A. Dokhanchi, Y. Kobayashi, and G. Fainekos. Towards formal specification visualization for testing and
monitoring of cyber-physical systems. In Int. Workshop on Design and Implementation of Formal Tools and Systems. October 2014.
B. Hoxha, N. Mavridis, and G. Fainekos. V I S PEC: a graphical tool for easy elicitation of MTL requirements. In Proceedings of the
IEEE/RSJ International Conference on Intelligent Robots and Systems, Hamburg, Germany, September 2015.
X. Jin, A. Donze, J. Deshmukh, and S. Seshia. Mining requirements from closed-loop control models. In Hybrid Systems: Computation
and Control. ACM Press, 2013.
J. Kapinski, J. V. Deshmukh, X. Jin, H. Ito, and K. R. Butts. Simulation-guided approaches for verification of automotive powertrain
control systems. In American Control Conference, ACC 2015, Chicago, IL, USA, July 1-3, 2015, pages 4086–4095, 2015.
K. Kim, G. E. Fainekos, and S. Sankaranarayanan. On the revision problem of specification automata. In IEEE International Conference
on Robotics and Automation, ICRA 2012, 14-18 May, 2012, St. Paul, Minnesota, USA, pages 5171–5176, 2012.
R. Könighofer, G. Hofferek, and R. Bloem. Debugging formal specifications: a practical approach using model-based diagnosis and
counterstrategies. STTT, 15(5-6):563–583, 2013.
S. Konrad and B. H. C. Cheng. Real-time specification patterns. In Proceedings of the 27th International Conference on Software
Engineering, ICSE ’05, pages 372–381. ACM, 2005.
R. Koymans. Specifying real-time properties with metric temporal logic. Real-Time Systems, 2(4):255–299, 1990.
O. Kupferman and M. Y. Vardi. Vacuity detection in temporal model checking. STTT, 4(2):224–233, 2003.
J. Li, L. Zhang, G. Pu, M. Y. Vardi, and J. He. LTL satisfiability checking revisited. In 2013 20th International Symposium on Temporal
Representation and Reasoning, Pensacola, FL, USA, September 26-28, 2013, pages 91–98, 2013.
O. Maler and D. Nickovic. Monitoring temporal properties of continuous signals. In Proceedings of FORMATS-FTRTFT, volume 3253
of LNCS, pages 152–166, 2004.
R. Meyer, J. Faber, J. Hoenicke, and A. Rybalchenko. Model checking duration calculus: a practical approach. Formal Aspects of
Computing, 20(4):481–505, 2008.
A. Post, J. Hoenicke, and A. Podelski. Vacuous real-time requirements. In RE 2011, 19th IEEE International Requirements Engineering
Conference, Trento, Italy, August 29 2011 - September 2, 2011, pages 153–162, 2011.
V. Raman and H. Kress-Gazit. Analyzing unsynthesizable specifications for high-level robot behavior using ltlmop. In Computer Aided
Verification - 23rd International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings, pages 663–668, 2011.
K. Y. Rozier and M. Y. Vardi. LTL satisfiability checking. STTT, 12(2):123–137, 2010.
P. Thati and G. Rosu. Monitoring algorithms for metric temporal logic specifications. In Runtime Verification, volume 113 of ENTCS,
pages 145–162. Elsevier, 2005.
H. Yang, B. Hoxha, and G. Fainekos. Querying parametric temporal logic properties on embedded systems. In Testing Software and
Systems, pages 136–151. Springer, 2012.
P. Zhang, B. Li, and L. Grunske. Timed property sequence chart. Journal of Systems and Software, 83(3):371–390, 2010.

APPENDIX
IX.

P ROOF OF T HEOREM 1

In order to show that Φ is inherently vacuous, we must show that if Φ |= ϕi [l ←⊥], then the mutated specification
is equivalent to the original specification. In other words, we should show that if Φ |= ϕi [l ←⊥], then ({Φ\ϕi } ∪
ϕi [l ←⊥]) ≡ Φ . If the mutated specification is equivalent to the original specification, then the original specification
is vacuously satisfiable in any system. That is, the specification is inherently vacuous [24], [14]. We already know
that if Φ |= ϕi [l ←⊥], then Φ =⇒ ϕi [l ←⊥] and trivially Φ =⇒ ϕi [l ←⊥] ∪ {Φ\ϕi }. Now we just need to prove
the other direction. We need to prove that when ϕi is in the negation normal form, then ϕi [l ←⊥] =⇒ ϕi . Since
we replace only one specific literal occurrence of ϕ with ⊥, the rest of the formula remains the same. Therefore,
it should be noted that ϕi [l ←⊥] does not modify any l0 ∈ litOccur(ϕi ) where l0 6= l.
Proof: We use structural induction to prove that ϕi [l ←⊥] =⇒ ϕi
Base Case: ϕi = l or ϕi = l0 6= l
We know that ⊥ =⇒ l and l0 =⇒ l0 . Therefore ϕi [l ←⊥] =⇒ ϕi .
Induction Hypothesis: For any MITL ϕj in NNF we have ϕj [l ←⊥] =⇒ ϕj (or ∀ϕj , ϕj [l ←⊥] =⇒ ϕj )
Induction Step: We will separate the case into unary and binary operators.

Before providing the cases we should review the positively monotonic operators [36]. According to MITL semantics,
f ∈ {2I , 3I } and g ∈ {∧, ∨} are positively monotonic, i.e. for every MITL formulas ϕ1 and ϕ2 in NNF with
ϕ1 =⇒ ϕ2 , we have f (ϕ1 ) =⇒ f (ϕ2 ). Also, for all MITL formulas ϕ0 in NNF, we have g(ϕ1 , ϕ0 ) =⇒ g(ϕ2 , ϕ0 )
and g(ϕ0 , ϕ1 ) =⇒ g(ϕ0 , ϕ2 ).
Case 1: ϕi = f (ϕj ) where f ∈ {2I , 3I }. Since f is positively monotonic, we have that ϕj [l ←⊥] =⇒ ϕj
implies f (ϕj [l ←⊥]) =⇒ f (ϕj ). Thus,
f (ϕj )[l ←⊥] = f (ϕj [l ←⊥]) =⇒ f (ϕj ) = ϕi . As a result ϕi [l ←⊥] =⇒ ϕi .
Case 2: ϕi = g(ϕj1 , ϕj2 ) where g ∈ {∧, ∨} Since g is positively monotonic, we have that ϕj1 [l ←⊥] =⇒ ϕj1 ,
and ϕj2 [l ←⊥] =⇒ ϕj2 implies
g(ϕj1 [l ←⊥], ϕj2 [l ←⊥]) =⇒ g(ϕj1 , ϕj2 ) . Thus, g(ϕj1 , ϕj2 )[l ←⊥] = g(ϕj1 [l ←⊥], ϕj2 [l ←⊥]) =⇒
g(ϕj1 , ϕj2 ) = ϕi . As a result ϕi [l ←⊥] =⇒ ϕi .
Since ϕi [l ←⊥] =⇒ ϕi we can have:
{Φ\ϕi } ∪ ϕi [l ←⊥] =⇒ {Φ\ϕi } ∪ ϕi which is equivalent to
{Φ\ϕi } ∪ ϕi [l ←⊥] =⇒ Φ
X.

P ROOF OF T HEOREM 2

In this section, we will prove that any MITL (STL) ϕ ∈ Φ, which contains a disjunction operation (∨) in NNF
can be vacuously satisfied. In other words, we will prove that any timed trace (signal) which satisfies ϕ will be
considered as a vacuous timed trace (signal) according to Algorithm 7. Without loss of generality we assume that
both operands of disjunction are not constant. This is because if one of the operands is equivalent to > or ⊥, then
the disjunction can be semantically removed as follows ψ ∨ > ≡ > or ψ∨ ⊥≡ ψ for any MITL (STL) ψ.
Let us consider a the vacuous timed trace (signal) returned by Algorithm 7. If there exist ϕi ∈ Φ and l ∈
litOccur(ϕi ) such that the timed trace µ satisfies ϕi [l ←⊥], then µ will be reported as a vacuous timed trace
(signal). Recall that we assume that Φ is a conjunction of MITL specifications according to Equation (1). We also
assume that the conjunct ϕi ∈ Φ is the MITL subformula that contains the disjunction operation. Namely, that
ψ = ψ1 ∨ ψ2 is a subformula of ϕi .
Theorem 4: Any timed trace µ that satisfies ϕi will satisfy ϕi [l ←⊥] for some l ∈ litOccur(ϕi ).
Proof: We have two cases for µ |= ϕi and ψ ∈ ϕi where ψ = ψ1 ∨ ψ2 :
1) ∀t, (µ, t) 6|= ψ: In this case ψ does not affect the satisfaction of µ |= ϕi . If we choose l0 ∈ litOccur(ψ), then
ψ[l0 ←⊥] also does not affect the satisfaction of ϕi .
2) ∃t, s.t. (µ, t) |= ψ: In this case ψ affects the satisfaction of ϕi . So either (µ, t) |= ψ1 or (µ, t) |= ψ2 . If
(µ, t) |= ψ1 then we can choose l0 ∈ litOccur(ψ2 ) and we have (µ, t) |= ψ1 ∨ ψ2 [l0 ←⊥]. Similarly, if
(µ, t) |= ψ2 then we can choose l00 ∈ litOccur(ψ1 ) and we have (µ, t) |= ψ1 [l00 ←⊥] ∨ ψ2 . As a result, there
exists some l ∈ litOccur(ψ) where (µ, t) |= ψ[l ←⊥] and accordingly µ |= ϕi [l ←⊥].
Finally, ∀µ, µ |= ϕi ∃l ∈ litOccur(ϕi ) s.t. µ |= ϕi [l ←⊥]. Which means that µ is a vacuous timed trace
(signal).
Corollary 1: Assume that the conjunct ϕj ∈ Φ is the subformula that contains the conjunction operation in
NNF. Namely, that ψ = ψ1 ∧ ψ2 is a subformula of ϕj . Any timed trace µ that falsifies ϕj will falsify ϕj [l ← >]
for some l ∈ litOccur(ϕj ).
XI.

P ROOFS OF T HEOREM 3

We consider two MITL(3,2) fragments, denoted MITL(2), and MITL(3). In this proof we assume that all
formulas are in NNF. We also consider LTL(3,2) as the set of LTL formulas (with continuous semantics) that
contains only 3 and 2 as temporal operators. In the following we provide the continuous semantics of LTL(3,2)
over traces with bounded duration. Semantics of LTL(3,2) over bounded timed traces can be defined as follows:
Definition 11 (LTL(3,2) continuous semantics): Given a timed trace µ : [0, T ] → 2AP and t, t0 ∈ R, and an
LTL(3,2) formula φ, the satisfaction relation (µ, t)  φ for temporal operators is inductively defined:
(µ, t)  3φ1 iff ∃t0 ∈ [t, T ] s.t (µ, t0 )  φ1 .
(µ, t)  2φ1 iff ∀t0 ∈ [t, T ], (µ, t0 )  φ1 .
We will consider two LTL(3,2) fragments denoted LTL(2), and LTL(3). The syntax of MITL and LTL fragments
are as presented in Section VII-C. We define the operator [φ]LT L which can be applied to any MITL(3,2) formula

and removes its interval constraints to create a new formula in LTL(3,2). For example if φ = 3[0,10] (p ∧ q) ∧
3[0,10] p ∧ 2[0,10] q, then [φ]LT L = 3(p ∧ q) ∧ 3p ∧ 2q. As a result, for any φ ∈ MITL(3, 2) there exists a ψ ∈
LTL(3, 2) where ψ = [φ]LT L . For each MITL(3, 2) formula φ, the language of φ denoted L(φ) is the set of
all timed traces that satisfy φ: µ  φ iff µ ∈ L(φ). Similarly, for any ψ ∈ LTL(3, 2), the language of ψ denoted
L(ψ) is the set of all timed traces that satisfy ψ: µ0  ψ iff µ0 ∈ L(ψ). Based on set theory, it is trivial to prove
that A ⊆ B and C ⊆ D implies A ∪ C ⊆ B ∪ D and A ∩ C ⊆ B ∩ D.
Theorem 5: For any formula ϕ ∈ MITL(3), and t ∈ [0, T ] we have Lt (ϕ) ⊆ Lt ([ϕ]LT L ) where Lt (ϕ) =
{µ | (µ, t)  ϕ}. In other words for all timed trace µ we have (µ, t)  ϕ implies (µ, t)  [ϕ]LT L .
Proof: We use structural induction to prove that Lt (ϕ) ⊆ Lt ([ϕ]LT L )
Base Case: if ϕ = >, ⊥, p, ¬p, then [ϕ]LT L = ϕ and Lt (ϕ) ⊆ Lt ([ϕ]LT L )
Induction Hypothesis: We assume that there exist ϕ1 , ϕ2 ∈ MITL(3) where for all t ∈ [0, T ], Lt (ϕ1 ) ⊆
Lt ([ϕ1 ]LT L ) and Lt (ϕ2 ) ⊆ Lt ([ϕ2 ]LT L )
Case 1: For Binary operators ∧, ∨ we can use the union and intersection properties. In essence, for all formulas
ϕ1 , ϕ2 we have Lt (ϕ1 ∨ ϕ2 ) = Lt (ϕ1 ) ∪ Lt (ϕ2 ) and Lt (ϕ1 ∧ ϕ2 ) = Lt (ϕ1 ) ∩ Lt (ϕ2 ). According to the IH
Lt (ϕ1 ) ⊆ Lt ([ϕ1 ]LT L ) and Lt (ϕ2 ) ⊆ Lt ([ϕ2 ]LT L ); therefore, Lt (ϕ1 ) ∩ Lt (ϕ2 ) ⊆ Lt ([ϕ1 ]LT L ) ∩ Lt ([ϕ2 ]LT L )
and Lt (ϕ1 ) ∪ Lt (ϕ2 ) ⊆ Lt ([ϕ1 ]LT L ) ∪ Lt ([ϕ2 ]LT L ). As a result, Lt (ϕ1 ∧ ϕ2 ) ⊆ Lt ([ϕ1 ]LT L ∧ [ϕ2 ]LT L ) =
Lt ([ϕ1 ∧ ϕ2 ]LT L ), and Lt (ϕ1 ∨ ϕ2 ) ⊆ Lt ([ϕ1 ]LT L ∨ [ϕ2 ]LT L ) = Lt ([ϕ1 ∨ ϕ2 ]LT L ).
Case 2: For the temporal operator 3, we need to compare the semantics of MITL(3) and LTL(3). Recall that
(µ, t)  3I ϕ1 iff ∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  ϕ1 .
(µ, t)  3ϕ1 iff ∃t0 ∈ [t, T ] s.t (µ, t0 )  ϕ1 .
Recall that t00 ∈ (t + I) ∩ [0, T ] implies t00 ∈ [t, T ] since the left bound of I is nonnegative.
According to the semantics, ∀µ.(µ, t)  3I ϕ1 implies
∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  ϕ1 implies
∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  [ϕ1 ]LT L according to IH (Lt0 (ϕ1 ) ⊆ Lt0 ([ϕ1 ]LT L )).
If ∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  [ϕ1 ]LT L then
∃t0 ∈ [t, T ] s.t (µ, t0 )  [ϕ1 ]LT L since t0 ∈ (t + I) ∩ [0, T ] implies t0 ∈ [t, T ].
Moreover, (µ, t0 )  [ϕ1 ]LT L implies that (µ, t)  3[ϕ1 ]LT L ≡ [3ϕ1 ]LT L .
As a result, ∀µ. (µ, t)  3I ϕ1 =⇒ (µ, t)  [3ϕ1 ]LT L so Lt (3I ϕ1 ) ⊆ Lt ([3ϕ1 ]LT L ).
If ϕ ∈ MITL(3) then Lt ([ϕ]LT L ) ⊆ Lt (ϕ) (immediate from set theory). Thus, for all timed traces µ, µ 6 [ϕ]LT L
implies that µ 6 ϕ.
Corollary 2: For any ϕ ∈ MITL(3), if [ϕ]LT L ∈ LTL(3) is unsatisfiable, then ϕ is unsatisfiable.
Theorem 6: For any formula ϕ ∈ MITL(2), and t ∈ [0, T ], we have Lt ([ϕ]LT L ) ⊆ Lt (ϕ), where Lt (ϕ) =
{µ|(µ, t)  ϕ}. In other words ∀µ(µ, t)  [ϕ]LT L =⇒ (µ, t)  ϕ
Proof: Similar to Theorem 5, we can apply structural induction for the proof of Theorem 6.

An Efficient Algorithm for Monitoring Practical
TPTL Specifications

arXiv:1612.03140v1 [cs.LO] 9 Dec 2016

Adel Dokhanchi, Bardh Hoxha, Cumhur Erkan Tuncali, and Georgios Fainekos
Arizona State University, Tempe, AZ, U.S.A.
Email: {adokhanc,bhoxha,etuncali,fainekos}@asu.edu
Abstract—We provide a dynamic programming algorithm for
the monitoring of a fragment of Timed Propositional Temporal
Logic (TPTL) specifications. This fragment of TPTL, which is
more expressive than Metric Temporal Logic, is characterized
by independent time variables which enable the elicitation of
complex real-time requirements. For this fragment, we provide
an efficient polynomial time algorithm for off-line monitoring
of finite traces. Finally, we provide experimental results on a
prototype implementation of our tool in order to demonstrate
the feasibility of using our tool in practical applications.

I.

Introduction

In Cyber-Physical Systems (CPS), many safety critical
components of the system are controlled by embedded computers which interact with the physical environment. Due to
the safety-critical nature of these applications, it is important
to verify their correctness during system development stages.
However, the verification problem for CPS with respect to
safety requirements is undecidable, in general [1]. An alternative to formal verification is semi-formal model-based testing
and monitoring of CPS. We utilize formal logic, in order to
formally specify real-time requirements.
Metric Temporal Logic (MTL) was introduced to provide
the formalization of real-time specifications [16]. Since its
introduction, MTL and its variants have been used in the
verification of real-time systems [20]. Several tools, such as
S-TaLiRo [3] and Breach [7], have been developed by the
academic community for the purpose of semi-formal verification of MTL specifications. These tools use off-line and
on-line monitoring algorithms to check whether the execution
trace of a CPS satisfies/falsifies an MTL formula. In offline monitoring, the execution trace is finite and generated by
running the system for a bounded amount of time. Then, the
off-line monitor checks whether the execution trace satisfies
the specification. On the other hand, an on-line monitor runs
simultaneously with the system. In this paper, we consider offline monitoring of TPTL specifications.
The time complexity of off-line monitoring for MTL is
linear to the size of a finite system trace and linear to the size of
MTL formula. Several algorithms using dynamic programming
[10] or sliding windows [8] have been proposed for MTL
monitoring of CPS. In this paper, we consider TPTL specifications which are more expressive than MTL specifications
[4]. TPTL is an extension of Linear Temporal Logic (LTL)
with freeze quantifiers represented as “x.”. A freeze quantifier
x. assigns to time variable x the “current” time stamp when
the corresponding subformula x.ϕ(x) is evaluated [2]. Then, the
time value (stored in x) can be evaluated inside time constraints
which are linear inequalities over the time variables.

Since its introduction, two semantics where considered for
TPTL [2], [4]. Alur’s semantics [2] allows two time variables
in time constraints (for example x + 1 ≤ y + 4). In contrast,
Raskin’s semantics allows only one time variable in the time
constraint (x ≤ 4) and implicitly considers the current time as
the second time variable [4], [21]. Since the latter semantics
was first considered by Jean-Franois Raskin in [21], we will
refer to it as “Raskin’s TPTL semantics” in this paper. Raskin’s
TPTL semantics was mentioned with alternative terms such
as “Timed LTL” in [17]. In another line of work, in [6], the
authors augmented Alur’s time constraints with more complex
temporal-special predicates to define the closeness property of
two different CPS trajectories. However, the authors in [6] did
not provide a TPTL monitoring algorithm.
Since TPTL subsumes MTL, it is expected that the monitoring problem of TPTL is computationally more complex
[11]. It has been proven that monitoring of a finite trace with
respect to Alur’s TPTL specification is PSPACE-hard [18].
In [18], the authors transform a Quantified Boolean Formula
(QBF), which is PSPACE-hard, into a TPTL formula with real
value time variables. A similar complexity result (PSPACEhard) for Raskin’s TPTL semantics is obtained for integer
time variables in [11]. It is mentioned in [11] that in order
to obtain a polynomial time algorithm for TPTL monitoring
(path checking), we need to fix the number of time variables.
In other words, if the number of time variables is bounded
then the finite trace monitoring will be polynomial to the size
of the TPTL formula. However, in [11], the authors did not
provide any applicable algorithm for TPTL monitoring and
they focused only on the complexity class.
In this work, we move one step further from [11], and allow
the number of time variables to be arbitrary, but they must
be independent to each other1 . For this fragment of TPTL,
we provide an efficient TPTL monitoring algorithm which has
time complexity quadratic in the length of the finite trace. In
addition, the runtime of the algorithm is proportional to the
number of time variables in TPTL.
In terms of related work, a rewriting based algorithm for
TPTL has been provided in [5]. In [5], the authors did not
evaluate the time complexity of their proposed algorithm.
The rewriting technique was used for on-line monitoring of
TPTL specifications in [13]. The authors used the relativization
of TPTL formula with respect to the sequence of observed
states [13], and it was reported that the time complexity is
exponential to the size of TPTL formula [13]. To the best of
our knowledge, our paper is the first work where an efficient
1 In

Section II-B, Definition 5, we introduce independent time variables.

and practical TPTL off-line monitoring algorithm is provided.
II.

Preliminaries

We assume a sampled representation of system behavior
with a discrete trace as the input to the monitoring algorithm.
We utilize the notion of Timed State Sequences (TSS) [2] to
represent the sampled behavior of a system using a digital
clock. We interpret TPTL formulas over TSS. Assume AP =
{a, b, · · · } is a set of atomic propositions, R+ is the set of nonnegative real numbers, and N denotes non-negative integers.
Definition 1 (State and Time Sequences [2]): A state sequence σ = σ0 σ1 σ2 · · · is an infinite sequence of states σi ⊆
AP, where i ∈ N. A (sampled) time sequence τ = τ0 τ1 τ2 . . .
is an infinite sequence of time stamps τi ∈ R+ , where i ∈ N.
We assume that the time sequence τ is:
1)
2)
3)

Initialized, which means that the start up time is zero
(τ0 = 0).
Monotonic, which means that τi ≤ τi+1 for all i ∈ N.
Progressive, which means that for all t ∈ R+ there is
some i ∈ N such that τi > t.

Definition 2 (Timed State Sequence (TSS) [2]): A
timed state sequence ρ = (σ, τ) is a pair consisting
of a state sequence σ and a time sequence τ where
ρ0 ρ1 ρ2 · · · = (σ0 , τ0 )(σ1 , τ1 )(σ2 , τ2 ) · · · .
Given an infinite TSS ρ, we consider a finite prefix of ρ as a
finite TSS. The symbol ρ̂ = (σ̂, τ̂) is used to denote a finite
TSS with the size of |ρ̂| = |σ̂| = |τ̂|. In this paper, we consider
the monitoring of finite TSS with the size of |ρ̂| which is equal
to the number of simulation/execution samples.
A. TPTL Syntax and Semantics
To prevent any confusion in the presentation, we consider
Raskin’s TPTL semantics [21], [4]2 . TPTL is an extension of
LTL that enables the formalization of real-time properties by
including time variables and a freeze time quantifier [2].
Definition 3 (Syntax for T PT L): The set of TPTL formulas ϕ over a finite set of atomic propositions (AP) and a finite
set of time variables (V) is inductively defined according to
the following grammar:
ϕ ::= > | a | x ∼ r | ¬ϕ | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 
 ϕ | ϕ1 Uϕ2 | x.ϕ
where x ∈ V, r ∈ R+ , a ∈ AP, and ∼ ∈ {≤, <, =, >, ≥}, and >
is the symbol for “True”.
The time constraints of TPTL are represented in the form of
x ∼ r. The freeze quantifier x. assigns the current time of
the formula’s evaluation (at each sampled time τi ) to the time
variable x. A TPTL formula is closed if every occurrence of
a time variable is within the scope of a freeze quantifier [2].
In TPTL specifications, we always deal with closed formulas.
We note that “False” is represented as ⊥ ≡ ¬> and
“Implication” is represented as ϕ1 → ϕ2 ≡ ¬ϕ1 ∨ ϕ2 . For
all formulas ψ, φ, ^ψ ≡ >Uψ (Eventually ψ), ψ ≡ ¬^¬ψ
(Always ψ), and ψRφ ≡ ¬(¬ψU¬φ) (ψ Releases φ) are defined
2 We

will explain in Section II-B why we chose Raskin’s semantics.

in the conventional way. Since we focus on off-line monitoring,
we only consider the TPTL semantics for finite traces.
Definition 4 (Discrete-Time Semantics for T PT L): Let
ρ̂ = (σ̂, τ̂) be a finite TSS and i ∈ N where i < |ρ̂| is the index
of the current sample, a ∈ AP, ϕ ∈ T PT L, and an environment
ε : V → R+ . The satisfaction relation (ρ̂, i, ε) |= ϕ is defined
recursively as follows:
(ρ̂, i, ε) |= >
(ρ̂, i, ε) |= a iff a ∈ σi
(ρ̂, i, ε) |= ¬ϕ iff (ρ̂, i, ε) 6|= ϕ
(ρ̂, i, ε) |= ϕ1 ∧ ϕ2 iff (ρ̂, i, ε) |= ϕ1 and (ρ̂, i, ε) |= ϕ2
(ρ̂, i, ε) |= ϕ1 ∨ ϕ2 iff (ρ̂, i, ε) |= ϕ1 or (ρ̂, i, ε) |= ϕ2
(ρ̂, i, ε) |= 
ϕ iff (ρ̂, i + 1, ε) |= ϕ and i < (|ρ̂| − 1)
(ρ̂, i, ε) |= ϕ1 Uϕ2 iff ∃ j, i ≤ j < |ρ̂| s.t. (ρ̂, j, ε) |= ϕ2
and ∀k, i ≤ k < j it holds that (ρ̂, k, ε) |= ϕ1
(ρ̂, i, ε) |= x ∼ r iff (τi − ε(x)) ∼ r i.e.
(current time stamp) − ε(x) ∼ r
(ρ̂, i, ε) |= x.ϕ iff (ρ̂, i, ε[x := τi ]) |= ϕ
The semantics of TPTL are defined over an evaluation
function ε : V → R+ which is an environment for the time
variables. Assume x = r where x ∈ V, and r ∈ R+ , then we have
ε(x) = r. Given a variable x ∈ V and a real number q ∈ R+ , we
denote the environment with ε0 = ε[x := q] which is equivalent
to the environment ε on all time variables in V except variable
x. The assignment operation x := q changes the environment ε
to the new environment ε0 . Formally, ε0 (y) = ε(y) for all y , x
and ε0 (x) = q. We write 0 for the (zero) environment such that
0(x) = 0 for all x ∈ V. We say that ρ̂ satisfies ϕ (ρ̂ |= ϕ) iff
(ρ̂, 0,0) |= ϕ. A variable “x” that is bounded by a corresponding
freeze quantifier “x.” saves the local temporal context τi (now)
in “x”. Assume ϕ(x) is a formula with a free variable x. The
TSS ρ̂ satisfies x.ϕ(x) if it satisfies ϕ(τ0 = 0), where ϕ(0) is
obtained from ϕ(x) by replacing all the free occurrences of the
variable x with constant 0 [2].
B. TPTL Fragments
In this section, we introduce a TPTL fragment for which
we have developed a monitoring algorithm. This restriction is
crucial for obtaining the polynomial runtime of the algorithm.
Definition 5 (Independent Time Variable): A time variable
x is independent if it is in the scope of only one freeze
quantifier x. and no other time variable is in the scope of the
corresponding freeze quantifier (x.).
For example in x.(ψ(x) ∨ ^y.ϕ(x, y)), neither x nor y is
independent. This is because x is within the scope of the freeze
time quantifiers x. in x.(ψ(x) ∨ ^y.ϕ(x, y)) and y. in y.ϕ(x, y).
Similarly, y is not the only time variable that is within the scope
of y. in y.ϕ(x, y). However, both x and y are independent in
x.(ψ(x) ∨ ^y.ϕ(y)).
Now we explain why we focus on Raskin’s semantics in
our monitoring algorithm. In Raskin’s semantics, each time
constraint contains a single time variable (see Definition 3).
However, in Alur’s semantics each time constraint contains
two time variables [2]. In Alur’s semantics, time variables in
the same constraint are dependent to each other. As a result,
in order to benefit from independent time variables, we should
consider Raskin’s semantics.

=

Definition 6 (Encapsulated TPTL formula): Encapsulated
TPTL formulas are TPTL formulas where all the time
variables are independent.

=
=

☐
x.

.

◇

.

In other words, an encapsulated formula is a closed formula
in which every sub-formula has at most one free time variable.

∧
→

Definition 7 (Frozen Subformula): Given an encapsulated
TPTL formula Φ, a frozen subformula φ of Φ is a subformula
which is bounded by a freeze quantifier corresponding to (an
independent) time variable.
In encapsulated formulas, all the closed subformulas are
frozen. For example the formula x.(ψ(x) ∨ ^y.ϕ(x, y)) is not an
“encapsulated” formula because y.ϕ(x, y) is not frozen since
x, y are not independent. Here are two TPTL formulas ϕ1 ,ϕ2
that look similar but only one of them is encapsulated.
•

ϕ1 = x.^(a ∧ x ≤ 10 ∧ y.(y ≤ 2 ∧ y ≥ 1 ∧ b))

•

ϕ2 = x.^(a ∧ x ≤ 10 ∧ y.(x ≤ 2 ∧ y ≥ 1 ∧ b))

In the above, ϕ1 is encapsulated, but ϕ2 is not encapsulated
since y.(x ≤ 2 ∧ y ≥ 1 ∧ b) where x ≤ 2 is inside the scope
of “y.”.
Lemma 1: Any MTL formula can be represented by an
“encapsulated” TPTL formula.
Proof: Each time interval of an MTL temporal operator can be represented with a unique time variable which
is independent of the rest of time variables. The syntactic
modification works as follows: every MTL formula of the form
ϕ = ψU[l,u] φ can be recursively represented as the following
TPTL formula ϕ = x.(ψU(x ≥ l ∧ x ≤ u ∧ φ)). The resulting
TPTL formula is encapsulated.
Lemma 2: MTL is less expressive than “encapsulated”
TPTL formulas.
Proof: It is proven in [4] that the following TPTL formula,
which is evidently encapsulated, cannot be expressed by any
MTL formula [4]: ψ = x.^(a ∧ x ≤ 1 ∧ (x ≤ 1 → ¬b))
In the rest of the paper, we focus on the following problem:
Problem 1: Given a finite TSS ρ̂ and an “encapsulated”
TPTL formula ϕ, check whether ρ̂ satisfies ϕ (ρ̂ |= ϕ).
III.

Monitoring Encapsulated TPTL Formulas

A. TPTL Representation
In the following, we will describe the data structure that
will be utilized to capture the solution for the TPTL monitoring
problem. We store each TPTL formula in a binary tree data
structure. Consider the following example:
Example 1: Assume AP = {a, b} and let
φ = x.^((x ≤ 1 → a) ∧ y.^(y ≤ 1 → ¬b))
φ ≡ x.^((x ≤ 1 → a) ∧ y.ψ1 (y)) ≡ x.ψ2 (x)
where we use ψ1 and ψ2 to simplify the presentation:
ψ1 (y) ≡ ^(y ≤ 1 → ¬b)
ψ2 (x) ≡ ^((x ≤ 1 → a) ∧ y.ψ1 (y))
In this example, we have two independent time variables x and
y. The binary tree of Example 1 is depicted in Fig. 1. There,
the thirteen nodes correspond to thirteen subformulas.

x≤1

a

y.

=

.

◇

=

.

→
y≤1

¬
b

Fig. 1. Binary tree of Example 1 (φ) with three subtrees corresponding to
sets of subformulas θ1 , θ2 , θ3 .

In Fig. 1, each subformula ϕi has a node corresponding to
the highest operator for ϕi . In addition, for each subformula
ϕi we assign an index i. The order of indexes is generated
according to a topological sort where parents have lower index
values than children. Therefore, the original subformula φ
obtains the index 1 because it is the first visited. To evaluate
each node’s >/⊥ value we need to evaluate its children’s >/⊥
value before, this is because of the TPTL recursive semantics
(see Definition 4). If we evaluate the nodes in the decreasing
order of indexes, we would be able to evaluate all the children
before their parents.
Now, we must partition the formula tree into subtrees
rooted by the freeze time operators. Since in Example 1, we
have two independent time variables, we created 2+1 subtrees
(two for time variables and one for the original formula). Each
subtree contains a set of subformulas. These subformulas and
their corresponding subtrees θ1 , θ2 , θ3 are shown in Fig. 1 with
different colors:
The set θ1 contains subformulas rooted at node ϕ9 represented in the light-gray subtree. The set θ1 contains the
subformulas of y.ψ1 (y) as follows θ1 = {^(y ≤ 1 → ¬b), y ≤
1 → ¬b, y ≤ 1, ¬b, b} = {ϕ9 , ϕ10 , ϕ11 , ϕ12 , ϕ13 }.
The set θ2 contains subformulas rooted at node ϕ3 represented in the white subtree. The set θ2 contains the subformulas of x.ψ2 (x) as follows θ2 = {^((x ≤ 1 → a) ∧
y.ψ1 (y)), (x ≤ 1 → a) ∧ y.ψ1 (y), (x ≤ 1 → a), y.ψ1 (y), x ≤
1, a} = {ϕ3 , ϕ4 , ϕ5 , ϕ6 , ϕ7 , ϕ8 }.
The set θ3 contains subformulas rooted at node ϕ1 represented in dark-gray subtree. The set θ3 contains the subformulas of θ3 = {x.ψ2 (x) , x.ψ2 (x)} = {ϕ1 , ϕ2 }.
Each of the subtrees θ1 and θ2 have distinguished fields
referencing to (the index of) parent and root nodes which are
represented in Fig. 1 as follows:
1) θ1 .parent = 6 and θ1 .root = 9.
2) θ2 .parent = 2 and θ2 .root = 3.
Note that θ1 is subformula of θ2 , and θ2 is subformula
of θ3 . This ordering is very important for our algorithm.
We created these subtrees because each frozen subformula
can be separately evaluated. Therefore, we can guarantee the
polynomial runtime. The method will be described in details
in Section IV.

TABLE I.

B. Monitoring Table
We assume that the sampled system output is mapped
(projected) on a finite TSS ρ̂; therefore, we can evaluate the
system output using our off-line monitor. If the specification
does not have a freeze time operator, then the formula is an
LTL formula for which the existing monitoring algorithms will
be utilized [22]. If the specification has a freeze time operator,
we first “instantiate” the time variable with the time label of the
current sample before formula evaluation. Then, we compute
⊥/> values of the corresponding time constraints. When time
constraints are evaluated, they will be resolved to ⊥/>, and
then, the frozen subformula (x.ϕ(x)) is converted into an LTL
formula. Hence, we can apply dynamic programming method
[22] to compute the Boolean value of the frozen subformula.
For each frozen subformula (x.ϕ(x)) at each time instance
τi , we must first precompute the Boolean (⊥/>) value of the
corresponding time constraints to transform this frozen subformula into an LTL. A two-dimensional matrix M|φ|×|ρ̂| with
height (number of rows) |φ| , and width (number of columns)
|ρ̂| is created. Here |φ| denotes the number of subformulas in
φ, and |ρ̂| is the number of samples. Note that row indexing
starts from 1 (φ ≡ ϕ1 ) up to |φ| and column indexing starts
from 0 (ρ0 ) up to |ρ̂| − 1.
The monitoring table of Example 1 is presented in Table I.
At the beginning, the system outputs corresponding to atomic
propositions (AP = {a, b}) are stored in the rows which belong
to the propositions a (row ϕ8 ) and b (row ϕ13 ) in Table I.
In Fig. 1, the subformula ψ2 (x) is depicted inside the white
subtree and ψ1 (y) is depicted inside the light-gray subtree. In
the following, we explain the other rows of Table I and provide
a high level overview of the monitoring of φ:
1st Run) We first instantiate time variable y at each sample
i with the corresponding timed instance τi to evaluate the
Boolean values for the corresponding time constraint y ≤ 1
(row ϕ11 ). The instantiation transforms y.ψ1 (y) into an LTL
formula. Then we compute the Boolean values of ψ1 (τ0 ),
ψ1 (τ1 ), ψ1 (τ2 ), . . . , ψ1 (τ6 ) from left to right. Now the Boolean
value of y.ψ1 (y) for each time stamp τi is available for the
higher level subtree of the Table I. Therefore, the Boolean
values should be copied from row ϕ9 to row ϕ6 .
2nd Run) Given the ⊥/> values of y.ψ1 (y), we can
instantiate x at each time stamp τi and modify formula x.ψ2 (x)
into an LTL formula. Then we compute the Boolean values of
ψ2 (τ0 ), ψ2 (τ1 ), ψ2 (τ2 ), . . . , ψ2 (τ6 ) from left to right. Now the
Boolean values of x.ψ2 (x) are available for each time stamp τi
for the higher subtree. As a result, the ⊥/> values should be
copied from row ϕ3 to row ϕ2 .
3rd Run) The Boolean value of x.ψ2 (x) is computed
given the Boolean values of ψ2 (τi ) according to the semantics
of Always () operator:
^6
φ≡
ψ2 (τi )
i=0

IV.

TPTL Monitoring Algorithm

The algorithms has the main following steps.

The Monitoring Table of formula φ of Example 1 (Fig. 1)

ϕi (OP)
ϕ1 ()
ϕ2 (x.)

τ0
{⊥/>}
ψ2 (0)

τ1

τ2

τ3

τ4

τ5

τ6

ψ2 (τ1 )

ψ2 (τ2 )

ψ2 (τ3 )

ψ2 (τ4 )

ψ2 (τ5 )

ψ2 (τ6 )

ϕ3 (^)
ϕ4 (∧)
ϕ5 (→)
ϕ6 (y.)
ϕ7 (x ≤ 1)
ϕ8 (a)

ψ2 (0)

ψ2 (τ1 )

ψ2 (τ2 )

ψ2 (τ3 )

ψ2 (τ4 )

ψ2 (τ5 )

ψ2 (τ6 )

ψ1 (0)

ψ1 (τ1 )

ψ1 (τ2 )

ψ1 (τ3 )

ψ1 (τ4 )

ψ1 (τ5 )

ψ1 (τ6 )

ϕ9 (^)
ϕ10 (→)
ϕ11 (y ≤ 1)
ϕ12 (¬)
ϕ13 (b)

ψ1 (0)

ψ1 (τ1 )

ψ1 (τ2 )

ψ1 (τ3 )

ψ1 (τ4 )

ψ1 (τ5 )

ψ1 (τ6 )

1)
2)
3)
4)

For each time variable (frozen subformula) and for
each time stamp.
Resolve the time constraints into ⊥/> values (This
step converts the corresponding frozen subformula
into an LTL formula).
Compute ⊥/> value of the resulting LTL formula
using the dynamic programming algorithm.
These ⊥/> values of frozen subformula are used to
evaluate the higher level subformulas.

In the following, a detailed description and pseudo code of the
proposed algorithm for TPTL monitoring will be explained.
A. TPTL to LTL Transformation
The pseudo code of the monitoring algorithm is provided
in Algorithm 1 and its main loop has |V| + 1 iterations
where |V| is the number of freeze time variables. Algorithm
1 calls Algorithm 2 for computing the Boolean value of LTL
subformulas. The first line of Algorithm 1 sets the monitoring
table entries of the corresponding atomic propositions, namely
the Boolean value of each p ∈ AP is extracted from the finite
state sequence σ̂. In addition, Line 1 sets the monitoring table
entries for constant boolean values ⊥/>. For each time variable
vk (in Line 2), we need to compute the ⊥/> value of the
subtree θk . The order of k is in such away that the inner most
subtree (θ1 ) is evaluated first then θ2 , and finally, θ3 (See Fig
1 for Example 1). This order is crucial for the correctness of
the algorithm, because higher level subformulas consider the
lower level frozen subformulas as ⊥/>.
To transform the frozen formula into LTL for each sample
time t between 0 to |ρ̂| − 1 (see Line 3), we must first
instantiate the time variable vk to the corresponding time
stamp τt , then compute the Boolean value of the corresponding
time constraint vk ∼ r. The instantiation evaluates the whole
constraint row into ⊥/> in Lines 4-13 of Algorithm 1. The
environment is updated based on the time stamp τt and
the formula translated into an LTL formula. Now we use a
dynamic programming algorithm based on [22] to compute the
⊥/> value of the frozen subformula in Lines 14-18. In Line 15
of Algorithm 1, θk .max (θk .min) is the maximum (minimum)
index of subformulas in the subtree θk . In Example 1:
1) θ1 .min = 9 and θ1 .max = 13
2) θ2 .min = 3 and θ2 .max = 8
When the Boolean value of the frozen subformula of
vk .ψ(vk ) (θk .root) at time stamp vk = τt is resolved, this
Boolean value is copied to the parent of θk (θk .parent) to be
used by higher level subformulas (see Line 19 of Algorithm

1). The loop of Line 3-20 continues for the other time
stamps (τ1 . . . τ|ρ̂|−1 ) and computes the ⊥/> value of the frozen
subformula for each instantiation of vk to the time stamps
τ1 . . . τ|ρ̂|−1 in this order. Now we resolved the ⊥/> value of the
frozen subformula of vk .ψ(vk ) for all time stamps. We continue
this process for other time variables (Lines 2-21).
When the Boolean values of the frozen subformulas are
resolved for each time variable v1 . . . vk . . . v|V| in this order, we
have an LTL formula for the highest level subformula where it
corresponds to subtree θ|V|+1 . To compute the ⊥/> value of the
highest set of subformulas we run Lines 22-26 of Algorithm
1. Note that Lines 22-26 are almost identical to Lines 1418 because the highest set of subformulas is in LTL. The final
value that corresponds to the monitoring trace is stored in table
entry M[1, 0] and it will be returned to the user. The table entry
M[1, 0] contains the Boolean value of the TPTL specification
(ϕ1 ) at sampled index 0.
B. LTL Monitoring
Now we explain how to compute the Boolean values of
the LTL subtree. Algorithm 2 is based on [22], and follows
Definition 4. Algorithm 1 calls Algorithm 2 at each sample u.
Algorithm 2 has the following 5 cases to compute the Boolean
values of the corresponding LTL operators:
1)
2)
3)
4)
5)

Lines
Lines
Lines
Lines
Lines

1-2 for the NOT operation (¬).
3-4 for the AND operation (∧).
5-6 for the OR operation (∨).
7-12 for the NEXT operation (
).
13-19 for the UNTIL operation (U).

Note that Algorithm 2 (ComputeLTL) is O(1) complexity. Since we can evaluate each frozen subformula (x.ϕ(x))
separately because of independent time variables, the time
complexity of the algorithm is proportional to the number of
time variables and the size of the subformula. On the other
hand, for each time sample we instantiate each time variable
to convert the TPTL subformula into an LTL subformula in
O(|ρ̂|) then run the LTL monitoring algorithm in O(|ρ̂|). As a
result, the upper bound on the time complexity of Algorithm 1
is O(|V| × |ϕ| × |ρ̂|2 ), where |V| is the number of time variables,
|ϕ| is the number of subformulas, and |ρ̂| is the number of TSS
samples. Both algorithms’ correctness proofs are provided in
Section VII.
C. Running example
In this section, we utilize our monitoring algorithm to
compute the solution for Example 1. First step of the algorithm
is the >/⊥ computation of the frozen subformula y.ψ1 (y) which
corresponds to subtree θ1 and is represented in light-gray rows
of Tables I and II. In Table II, when the time value of y is
instantiated to 0, then the value of the time constraint y ≤ 1 will
be resolved for all the samples of i between 0 to 6 according to
the following inequality τi − 0 ≤ 1. Now ψ1 (0) is transformed
into LTL and ψ1 (0) is evaluated, i.e., ψ1 (0) ≡ > (see row ϕ9
column τ0 ). Then, the time value of y is instantiated to τ1 = 0.3
and the value of the time constraint y ≤ 1 will be resolved for
all the samples of i between 1 to 6 according to the following
inequality τi − 0.3 ≤ 1. Similarly, ψ1 (0.3) is transformed into
LTL and ψ1 (0.3) can be computed, i.e., ψ1 (0.3) ≡ > (see row

Algorithm 1 TPTL Monitor
Input: ϕ, ρ̂ = (σ0 , τ0 )(σ1 , τ1 ) · · · (σT , τT ); Global variables:
M|ϕ|×|ρ̂| ; Output: M[1, 0].
procedure TPTLMonitor(ϕ, ρ̂)
1: Initialize all rows in M|ϕ|×|ρ̂| corresponding to predicates
ϕ j ≡ p ∈ AP with >/⊥ value according to σ̂.
2: for k ← 1 to |V| do
3:
for t ← 0 to |ρ̂| − 1 do
4:
for u ← t to |ρ̂| − 1 do
5:
for each ϕ j ≡ vk ∼ r ∈ θk where
6:
j is the index of vk ∼ r in M do
7:
if (τu − τt ) ∼ r then
8:
M[ j, u] ← >
9:
else
10:
M[ j, u] ← ⊥
11:
end if
12:
end for
13:
end for
14:
for u ← |ρ̂| − 1 down to t do
15:
for j ← θk .max down to θk .min do
16:
M[ j, u] ← ComputeLT L(ϕ j , u, M|ϕ|×|ρ̂| )
17:
end for
18:
end for
19:
M[θk .parent, t] ← M[θk .root, t]
20:
end for
21: end for
22: for u ← |ρ̂| − 1 down to 0 do
23:
for j ← θ|V|+1 .max down to θ|V|+1 .min do
24:
M[ j, u] ← ComputeLT L(ϕ j , u, M|ϕ|×|ρ̂| )
25:
end for
26: end for
27: return M[1, 0] // Return the value of the first cell/row in
M|ϕ|×|ρ̂| table
end procedure

ϕ9 column τ1 ). We continue the computation of ψ1 (τi ) with
the following instantiation τ2 = 0.7, . . . , τ6 = 1.9 similar to τ0 .
Now ⊥/> values of the frozen subformula y.ψ1 (y) for each
time stamp τi are available in row ϕ9 of Table II.
The Boolean values of subtree θ1 should be available
for higher level subformulas. Therefore, the row ϕ9 will be
copied to row ϕ6 (in Table II both rows have the same color).
Now we can continue the second run of the algorithm. The
>/⊥ computation of the frozen subformula x.ψ2 (x) which
corresponds to subtree θ2 is represented in white rows of Table
I and II. In Table II, the time value of x is instantiated to 0, then
the value of ψ2 (0) is computed, i.e., ψ2 (0) ≡ > (see row ϕ3
column τ0 ). Now, the time value of x is instantiated to τ1 = 0.3
and the value of ψ2 (0.3) is computed ψ2 (0.3) ≡ > (see row ϕ3
column τ1 ). We continue the computation of ψ2 (τi ) similarly
with τ2 = 0.7 . . . τ6 = 1.9. Now the ⊥/> values of the frozen
subformula x.ψ2 (x) for each time stamp τi are available in
row ϕ3 of Table II. Since the Boolean values of subtree θ2
should be available for higher level subformulas, the row ϕ3
is copied to row ϕ2 . Finally, we compute φ = x.ψ2 (x) using
Lines^
22-26 of Algorithm 1 which corresponds to following:
6
φ=
ψ2 (τi ) ≡ ⊥
i=0

TABLE II.
ϕi
ϕ1
ϕ2
ϕ3
ϕ4
ϕ5
ϕ6
ϕ7
ϕ8
ϕ9
ϕ10
ϕ11
ϕ12
ϕ13

Computing the Boolean values for φ = x.ψ2 (x). Boolean values correspond to the final snapshot of Monitoring Table.
subformula

φ = x.ψ2 (x)
x.ψ2 (x) ≡ x.^((x ≤ 1 → a) ∧ y.ψ1 (y))
^((x ≤ 1 → a) ∧ y.ψ1 (y))
(x ≤ 1 → a) ∧ y.ψ1 (y)
x≤1→a
y.ψ1 (y) ≡ y.^(y ≤ 1 → ¬b)
x≤1
a
^(y ≤ 1 → ¬b)
y ≤ 1 → ¬b
y≤1
¬b
b

τ0 = 0
⊥
ψ2 (0) ≡ >
>
⊥
⊥
ψ1 (0) ≡ >
>
⊥
>
>
>
>
⊥

τ1 = 0.3
⊥
ψ2 (τ1 ) ≡ >
>
⊥
⊥
ψ1 (τ1 ) ≡ >
>
⊥
>
>
>
>
⊥

Algorithm 2 LTL Monitor
Input: ϕ j , u, M|ϕ|×|ρ̂| ; Output: M[ j, u].
procedure ComputeLTL(ϕ j , u, M|ϕ|×|ρ̂| )
1: if ϕ j ≡ ¬ϕm then
2:
return ¬M[m, u]
3: else if ϕ j ≡ ϕm ∧ ϕn then
4:
return M[m, u] ∧ M[n, u]
5: else if ϕ j ≡ ϕm ∨ ϕn then
6:
return M[m, u] ∨ M[n, u]
7: else if ϕ j ≡ 
ϕm then
8:
if u = |ρ̂| − 1 then
9:
return ⊥
10:
else
11:
return M[m, u + 1]
12:
end if
13: else if ϕ j ≡ ϕm Uϕn then
14:
if u = |ρ̂| − 1 then
15:
return M[n, u]
16:
else
17:
return M[n, u] ∨ (M[m, u] ∧ M[ j, u + 1])
18:
end if
19: end if
end procedure
V.

Experiments

An implementation of our TPTL monitoring algorithm is
provided in the S-TaLiRo testing framework [15]. S-TaLiRo
is a Matlab toolbox that uses stochastic techniques to find
initial states and inputs to Simulink models which result in
trajectories that falsify MTL formulas. With our TPTL off-line
monitoring algorithm, S-TaLiRo can evaluate specifications
that are more expressive than MTL.
A. Runtime Analysis
We measured the runtime of our TPTL monitoring algorithm using the S-TaLiRo toolbox. The system under test
was the Automatic Transmission (AT) model provided by
Mathworks as a Simulink demo [19]. We introduced a few
modifications to the model to make it compatible with the STaLiRo framework, which are explained in [14]. AT has two
inputs of Throttle and Brake. The outputs contain two realvalued traces: the rotational speed of the engine ω and the
speed of the vehicle v. In addition, the outputs contain one
discrete-valued trace gear with four possible values.
To provide TPTL specifications, we defined four atomic
propositions corresponding to the following predicates:

τ2 = 0.7
⊥
ψ2 (τ2 ) ≡ >
>
>
>
ψ1 (τ2 ) ≡ >
>
>
>
⊥
>
⊥
>

τ3 = 1.0
⊥
ψ2 (τ3 ) ≡ >
>
>
>
ψ1 (τ3 ) ≡ >
>
>
>
>
>
>
⊥

τ4 = 1.1
⊥
ψ2 (τ4 ) ≡ ⊥
⊥
⊥
>
ψ1 (τ4 ) ≡ ⊥
>
>
⊥
⊥
>
⊥
>

τ5 = 1.5
⊥
ψ2 (τ5 ) ≡ ⊥
⊥
⊥
⊥
ψ1 (τ5 ) ≡ ⊥
>
⊥
⊥
⊥
>
⊥
>

τ6 = 1.9
⊥
ψ2 (τ6 ) ≡ ⊥
⊥
⊥
⊥
ψ1 (τ6 ) ≡ ⊥
>
⊥
⊥
⊥
>
⊥
>

1) a1 ≡ (ω ≥ 4500): “rotational speed of the engine ≥ 4500”
2) a2 ≡ (ω ≤ 1500): “rotational speed of the engine ≤ 1500”
3) a3 ≡ (v ≥ 40): “speed of the vehicle ≥ 40”
4) a4 ≡ (v ≤ 120): “speed of the vehicle ≤ 120”
Note that these predicates are chosen to be non-trivial and have
meaning in the CPS context. The TPTL formulas are generated
based on typical safety reactive response specifications. We
generated these TPTL formula patterns to check the runtime
with respect to: 1) Size of system trace 2) Number of temporal
operators 3) Number of time variables.
We created 18 TPTL formulas that cannot be expressed in
MTL. All the specifications have the reactive response pattern:
(a1 → ψ) where ψ is categorized in two groups:
1)
2)

EA group (ψEA ): contains Eventually/Always specifications with 2, 4 and 8 temporal operators.
UR group (ψUR ): contains Until/Release specifications with 2, 4 and 8 temporal operators.

We first chose a ψ specification in LTL from Table III column
(LTL template). In Table III, column (#) represents the number
of temporal operators for each LTL template. Then, we added
time variables to create a TPTL specification. The last column
in Table III represents the number of TPTL formulas that we
created by adding time constraints on ψ. The time variables
that we add to ψ correspond to individual temporal operators.
In this case, for ψEA2 we create two TPTL formulas with one
and two time variables respectively given as φ1 and φ2 :
EA
EA

φ1 = (a1 → x.^(a2 ∧ (a3 ∨ a4 ∧ C x )))
φ2 = (a1 → x.^(a2 ∧ C x ∧ y.(a3 ∨ a4 ∧ Cy )))

where C x and Cy are the corresponding time constraints for x
and y. Similarly for ψUR2 we created two TPTL formulas with
one and two time variables respectively given as φ1 and φ2 :
UR
UR

φ1 = (a1 → x.(a2 U(a3 R(a4 ∧ C x ))))
φ2 = (a1 → x.(a2 Ua4 ∧ C x ∧ y.(a3 R(a4 ∧ Cy )))

We used a similar method to generate φ3 with one time
variable, φ4 with two time variables, and φ5 with four time
variables based on ψEA4 and ψUR4 with the total number of six
TPTL formulas. Finally, we create eight TPTL formulas based
on ψEA8 and ψUR8 . These formulas are φ6 , φ7 , φ8 , φ9 and they
are represented in Table IV. Our experiments were conducted
on a 64-bit Intel Xeon CPU (2.5GHz) with 64-GB RAM and
Windows Server 2012. We used Matlab 2015a and Microsoft
Visual C++ 2013 Professional to compile our algorithms’ code
(in C) using the Matlab mex compiler.

TABLE III.
LTL
ψEA2
ψEA4
ψEA8
ψUR2
ψUR4
ψUR8

#
2
4
8
2
4
8

Specifications of ψ before adding time variables.
LTL template
^(a2 ∧ (a3 ∨ a4 )
^(a2 ∧ (a3 ∨ a4 ∧ ψEA2 )
^(a2 ∧ (a3 ∨ a4 ∧ ^(a2 ∧ (a3 ∨ a4 ∧ ψEA4 ))))
a2 U(a3 Ra4 )
a2 U(a3 R(a4 ∧ ψUR2 ))
a2 U(a3 R(a4 ∧ (a2 U(a3 R(a4 ∧ ψUR4 )))))

TPTLs
2
3
4
2
3
4

The runtime is provided in Table IV. Each row considers
two TPTL formulas in EA or UR configuration. For example,
the first column φ1 represents (a1 → x.^(a2 ∧(a3 ∨a4 ∧C x )))
and (a1 → x.(a2 U(a3 R(a4 ∧ C x )))) in EA and UR configurations, respectively. In Table IV the second column (#)
represents the number of temporal operators in the corresponding frozen subformula, namely, the number of of temporal
operators in ψEA# or ψUR# . The third column (|V|) in Table
IV represents the number of time variables in ψEA# or ψUR# .
We tested our algorithm with the execution traces of
the length 1000, 2000, and 10000. For each TPTL formula,
we tested our algorithm 100 times where the AT’s throttle
input is provided by random signal generator (without brake).
We reported the mean value (in Bold) and variance of the
algorithm’s runtime in Table IV. It can be seen that when
the length of the trace doubles from |ρ̂|=1,000 to |ρ̂|=2,000
, the runtime quadruples (see Mean values in Table IV).
Similarly, when the length of trace increases ten times from
|ρ̂|=1,000 to |ρ̂|=10,000 the runtime increased 100 times (see
Mean values in Table IV). Now, consider the mean values
of φ1 and φ2 . The number of time variables in φ1 is one
and in φ2 is two. It can be seen that mean values of φ2 are
twice as those of φ1 . Similarly, comparing φ3 and φ4 and φ5
shows that the runtime is proportional to the number of time
variables. Finally, comparing rows φ1 and φ3 and φ6 shows
that the runtime relates to the number of temporal operators.
The experimental results indicate that the runtime behaves as
expected, considering that our algorithm is in O(|V| × |ϕ| × |ρ̂|2 ).
B. Case Study
In this section, we consider CPS requirements which are
impossible to formalize in MTL [4], but we formalize them
in TPTL, very easily. The ultimate goal is to run the testing
algorithm on these requirements. Our TPTL monitoring algorithm is provided as add-on to the S-TaLiRo testing framework.
S-TaLiRo searches for counterexamples to MTL properties
through global minimization of a robustness metric [9]. The
robustness of an MTL formula ϕ is a value that measures
how far is the trace from the satisfaction/falsification of ϕ.
This measure is an extension of Boolean values (>/⊥) for
representing satisfaction or falsification. A positive robustness
value means that the trace satisfies the property and a negative
value means that the property is not satisfied. The stochastic
search then returns the simulation trace with the smallest
robustness value that was found.
To falsify safety requirements in TPTL which are more
expressive than MTL, we should use our proposed TPTL
monitor that can handle those specifications. Now let us
consider the Automatic Transmission (AT) system. It contains
the discrete output gear signal with four possible values
(gear = 1, ..., gear = 4) which indicate the current gear
in the auto-transmission controller. We use four atomic
propositions g1 , g2 , g3 , g4 for each possible gear value, where

Throttle

100
50
0
0

5

10

15

20

25

30

20

25

30

20

25

30

Break

500

0
0

5

10

15

Gear

4
2

6.68
0
0

5

10

15

Fig. 2. Falsification of Φ1 using S-TaLiRo. The duration between e1 and e3
is less than 8 seconds.

(gear = i) ≡ gi .
follows:
1) e1 = g1 ∧ 
g2
2) e2 = g2 ∧ 
g3
3) e2 = g3 ∧ 
g4

Then we define three up-shifting events as
means shift from gear one to gear two.
means shift from gear two to gear three.
means shift from gear three to gear four.

In CPS, it is possible that we need to specify the safety
requirement about three or more events in sequence,
but the time difference between the first and last event
happening should be of importance. In general, these types of
specification are impossible to represent in MTL. We provide
two very succinct TPTL specifications that can formalize
these challenging requirements.
The first requirement is as follows:
“Always if e1 happens, then if e2 happens in future and if e3
happens in future after e2 , then the duration between e1 and
e3 should be equal or more than 8.”
This specification is formalized in the following formula:
Φ1 = z.(e1 → (e2 → (e3 → z ≥ 8)))
S-TaLiRo successfully falsified Φ1 which is represented in Fig.
2. In Fig. 2 the Throttle, Break, and Gear trajectory of the
corresponding falsification is presented. It can be seen that the
duration between e1 and e3 is less that 8. Its actual value is
8.4 − 1.72 = 6.68 < 8.
The second requirement is as follows:
“Always if e1 happens, then e2 should happen in future, and
e3 should happen in future after e2 , and the duration between
e1 and e3 should be equal or less than 12.”
This specification is formalized by the following formula:
Φ2 = z.(e1 → ^(e2 ∧ ^(e3 ∧ z ≤ 12)))
In Fig. 3 the Throttle, Break, and Gear trajectories of the
falsification of Φ2 are represented. It can be seen that the
duration between e1 and e3 is more than 12, its actual value is
19.2−1.32 = 17.88 > 12. This case study shows that S-TaLiRo
can be used for the falsification problem of challenging TPTL
requirements. The method we propose in this work opens
the possibility for CPS off-line monitoring of very complex
specifications in TPTL using an efficient algorithm.

TABLE IV.

The runtime of Monitoring Algorithm for 18 TPTL formulas. All the values are in seconds.

φ

#

|V|

|ρ̂|=1,000
EA (ψEA# )
UR (ψUR# )
Mean
Var.
Mean
Var.

|ρ̂|=2,000
EA (ψEA# )
UR (ψUR# )
Mean
Var.
Mean
Var.

|ρ̂|=10,000
EA (ψEA# )
UR (ψUR# )
Mean
Var.
Mean
Var.

φ1

2

1

0.077

0.0002

0.064

0.000

0.326

0.001

0.250

0.0013

8.512

0.066

6.427

0.068

φ2

2

2

0.151

0.0005

0.137

0.0003

0.5887

0.0018

0.551

0.002

14.31

0.191

13.67

0.175

φ3

4

1

0.142

0.0003

0.097

0.0001

0.5885

0.002

0.382

0.002

15.33

0.232

10.46

0.154

φ4

4

2

0.205

0.0003

0.15

0.0002

0.871

0.0032

0.604

0.002

22.9

0.344

16.35

0.24

φ5

4

4

0.417

0.0012

0.38

0.0004

1.721

0.0058

1.558

0.007

46.25

7.08

41.2

1.077

φ6

8

1

0.227

0.0001

0.154

0.0002

0.948

0.005

0.552

0.0046

30.27

9.708

17.01

2.184

φ7

8

2

0.367

0.025

0.235

0.0011

1.474

0.0078

1.023

0.0137

41.59

2.17

26.95

2.204

φ8

8

4

0.533

0.0042

0.437

0.0013

2.26

0.024

1.751

0.0115

66.13

34.36

48.95

8.857

φ9

8

8

1.145

0.025

1.093

0.0066

4.9

0.0391

4.346

0.1413

137

220

124.6

184

Throttle

100

[6]

50
0
0

5

10

15

20

25

30

20

25

30

Break

500

[7]

[8]
0
0

5

10

15

Gear

4

[9]

2

17.88
0
0

5

10

15

20

25

30

[10]
Fig. 3. Falsification of Φ2 using S-TaLiRo. The duration between e1 and e3
is more than 12 seconds.

VI.

Conclusions and Future works

In this paper, we provide an efficient polynomial time
algorithm for a practical subset of TPTL specifications. We
show that very complex specifications can be succinctly represented in this TPTL subset. In addition, we can combine
full TPTL with a bounded number of time variables with
our suggested algorithm to test the specifications that have an
arbitrary number of independent time variables and full TPTL
with limited number of time variables. Finally, our method
can help CPS developers to efficiently test requirements that
cannot be expressed in MTL.

[11]

[12]

[13]
[14]

[15]

Acknowledgments: This research was partially funded
by NSF awards CNS-1350420 and CNS-1319560.
[16]

References
[1]

R. Alur, C. Courcoubetis, N. Halbwachs, T. A. Henzinger, P.-H. Ho,
X. Nicollin, A. Olivero, J. Sifakis, and S. Yovine. The algorithmic
analysis of hybrid systems. Theoretical Computer Science, 138(1):3–
34, 1995.

[17]

[18]

[2]

R. Alur and T. A. Henzinger. A really temporal logic. Journal of the
ACM, 41(1):181–204, 1994.

[19]

[3]

Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan.
S-TaLiRo: A tool for temporal logic falsification for hybrid systems.
In Tools and algorithms for the construction and analysis of systems,
volume 6605 of LNCS, pages 254–257. Springer, 2011.

[20]

[4]

P. Bouyer, F. Chevalier, and N. Markey. On the expressiveness of TPTL
and MTL. Inf. Comput., 208(2):97–116, 2010.

[5]

M. Chai and H. Schlingloff. A rewriting based monitoring algorithm
for TPTL. In Proceedings of the 22nd International Workshop on
Concurrency, Specification and Programming, Warsaw, Poland, pages
61–72, 2013.

[21]
[22]

J. V. Deshmukh, R. Majumdar, and V. S. Prabhu. Quantifying conformance using the skorokhod metric. In Computer Aided Verification
- 27th International Conference, CAV 2015, San Francisco, CA, USA,
July 18-24, 2015, Proceedings, Part II, pages 234–250, 2015.
A. Donze. Breach, a toolbox for verification and parameter synthesis
of hybrid systems. In Computer Aided Verification, volume 6174 of
LNCS, pages 167–170. Springer, 2010.
A. Donze, T. Ferrre, and O. Maler. Efficient robust monitoring for STL.
In Proceedings of the 25th International Conference on Computer Aided
Verification, CAV, pages 264–279, Berlin, Heidelberg, 2013. SpringerVerlag.
G. Fainekos and G. J. Pappas. Robustness of temporal logic specifications for continuous-time signals. Theor. Comput. Sci., 410(42):4262–
4291, 2009.
G. Fainekos, S. Sankaranarayanan, K. Ueda, and H. Yazarel. Verification of automotive control applications using S-TaLiRo. In Proceedings
of the American Control Conference, 2012.
S. Feng, M. Lohrey, and K. Quaas. Path checking for MTL and
TPTL over data words. In Developments in Language Theory - 19th
International Conference, DLT 2015, Liverpool, UK, July 27-30, 2015,
Proceedings., pages 326–339, 2015.
R. Gerth, D. Peled, M. Y. Vardi, and P. Wolper. Simple on-thefly automatic verification of linear temporal logic. In Proceedings
of the Fifteenth IFIP WG6.1 International Symposium on Protocol
Specification, Testing and Verification XV, pages 3–18, London, UK,
UK, 1996.
J. Håkansson, B. Jonsson, and O. Lundqvist. Generating online test
oracles from temporal logic specifications. STTT, 4(4):456–471, 2003.
B. Hoxha, H. Abbas, and G. Fainekos. Benchmarks for temporal logic
requirements for automotive systems. In Proc. of Applied Verification
for Continuous and Hybrid Systems, 2014.
B. Hoxha, H. Bach, H. Abbas, A. Dokhanchi, Y. Kobayashi, and
G. Fainekos. Towards formal specification visualization for testing and
monitoring of cyber-physical systems. In Int. Workshop on Design and
Implementation of Formal Tools and Systems. October 2014.
R. Koymans. Specifying real-time properties with metric temporal logic.
Real-Time Systems, 2(4):255–299, 1990.
K. J. Kristoffersen, C. Pedersen, and H. R. Andersen. Runtime verification of timed LTL using disjunctive normalized equation systems. In
Proceedings of the 3rd Workshop on Run-time Verification, volume 89
of ENTCS, pages 1–16, 2003.
N. Markey and J.-F. Raskin. Model checking restricted sets of timed
paths. Theor. Comput. Sci., 358(2):273–292, Aug. 2006.
MathWorks.
Modeling an automatic transmission controller,
available
at:
http://www.mathworks.com/help/simulink/examples/
modeling-an-automatic-transmission-controller.html.
J. Ouaknine and J. Worrell. Some recent results in metric temporal logic.
In Formal Modeling and Analysis of Timed Systems, 6th International
Conference, FORMATS 2008, Saint Malo, France, September 15-17,
2008. Proceedings, pages 1–13, 2008.
J.-F. Raskin. Logics, automata and classical theories for deciding realtime. Ph.D. Thesis, University of Namur, Belgium, 1999.
G. Rosu and K. Havelund. Synthesizing dynamic programming algorithms from linear temporal logic formulae. Technical report, Research
Institute for Advanced Computer Science (RIACS), 2001.

VII.

Appendix

In this section, we will prove the correctness of Algorithms
1 and 2. Our method first transforms the TPTL formula into
LTL formula using Algorithm 1. Then it uses the dynamic
programming method for monitoring LTL using Algorithm 2.
A. Proof of the correctness of Algorithm 1
Theorem 1: Given an encapsulated TPTL formula ϕ, and
a finite TSS ρ̂, after the execution of Algorithm 1 the returned
value is:
M[1, 0] = > iff (ρ̂, 0, 0) |= ϕ
To prove this theorem, we must show that the Boolean value
of the subformulas that are computed using Algorithm 1,
follows the TPTL semantics in Definition 4. Since Algorithm
1 does not evaluate propositional and temporal operators, their
corresponding proof will be provided in Section VII-B.
According to the TPTL semantics in Definition 4, for each
freeze time operation x.ϕ(x), and for each time stamp τi we
must instantiate the time variable x with the value of τi .
This instantiation enables us to evaluate time constraints and
transform TPTL to LTL. The loop of Lines 2-21 is the main
loop of Algorithm 1 which instantiates each variable vk with
each time sample τt in Line 3.
Lemma 3: The loop invariant of Algorithm 1 is as follows:

variable assignment (vk := τt ), we first update the environment
variables (Algorithm 1, Line 3), and then copy the ϕi ’s >/⊥
value into vk .ϕi ’s corresponding row (Algorithm 1, Line 19).
Since each time variable vk is independent, we create
the subtree (set) θk corresponding to the subformulas of
vk .ϕi (vk ) (see Section III-A). To evaluate vk .ϕi (vk ), we must
first instantiate variable vk for each time stamp τ0 . . . τ|ρ̂|−1 .
This instantiation is considered in Line 2 of Algorithm 1 for
time variable vk and for each sample of time 0 . . . (|ρ̂| − 1) in
Line 3 of Algorithm 1. Now we must copy the resulting >/⊥
value from ϕi back to vk .ϕi . The row corresponding to θk .root
contains the >/⊥ value of ϕi which is the root of θk subtree.
This values must be copied to the row θk .parent which is the
parent of subtree θk and it corresponds to ϕ j (Algorithm 1,
Line 19).
Case of vk ∼ r:
Consider the semantics of time constraints in Definition 4:
(ρ̂, u, ε) |= vk ∼ r iff (τu − ε(vk )) ∼ r
In the above semantics, ε(vk ) corresponds to the frozen value
of the time variable vk (environment of vk ). In the previous
case for vk .ϕi , we mentioned that we should instantiate vk
at each time stamp τ0 . . . τ|ρ̂|−1 . According to semantics in
Definition 4, each freeze operator assigns the environment
variable for the current and future samples of time t:

∀ j, k, t where ϕ j ≡ vk .ϕi , 0 ≤ t < |ρ̂| :

(ρ̂, t, ε) |= vk .ϕi iff (ρ̂, t, ε[vk := τt ]) |= ϕi

M[ j, t] = > iff (ρ̂, t, ε) |= vk .ϕi

Which means that the environment updates ε[x := τt ] are
observable for the current and the future samples (t ≤ u).
Therefore, after we instantiated variable vk at each time stamp
τt , the environment update will affect all the samples u between
t ≤ u ≤ |ρ̂| − 1. As a result, the time constraint vk ∼ r must be
updated for all future samples of t ≤ u ≤ |ρ̂| − 1 for ε[vk := τt ]
instantiation.

We use induction to prove the loop invariant of Algorithm 1.
Base: If |V| = 0, then formula is in LTL and algorithm
does not enter the to loop of Lines 2-21 (only executes Lines
22-26). The proof of LTL is provided in Section VII-B.
Induction Hypothesis: We assume for all vl , where l < k
the invariant holds. In other words
∀ j, l < k, t where ϕ j ≡ vl .ϕi , 0 ≤ t < |ρ̂| :
M[ j, t] = M[θl .parent, t] = > iff (ρ̂, t, ε) |= vl .ϕi
Induction Step: To show the correctness for the case of
vk , we prove that Algorithm 1 correctly transform TPTL into
LTL. Then we apply the correctness of LTL (See Section
VII-B) to establish the correctness of invariant considering vk .
Thus, we consider two cases that instantiate and evaluate vk
and show that Algorithm 1 follows the semantics in Definition
4. According to I.H. and since time variables are independent,
we can correctly consider frozen subformulas of ϕi as >/⊥.
As a result, we will conclude that ϕi is in LTL.
Case of vk .ϕi :
Consider the semantics of the freeze operator in Definition 4:
(ρ̂, t, ε) |= vk .ϕi iff (ρ̂, t, ε[vk := τt ]) |= ϕi
According to this semantics, the freeze operation “vk .” first
assigns a new value to the variable (vk := τt ). Then the >/⊥
value of vk .ϕi ≡ ϕ j will be resolved to the same >/⊥ value
of ϕi (with the new environment update). Therefore, for each

Lines 4-13 of Algorithm 1 follow the above discussion.
Namely, for time variable vk , we instantiate each time stamp
τt (Line 3), the time constraints of current/future samples
are evaluated according to the frozen time stamp τt . Actual
evaluation happens in the Line 7 of Algorithm 1, where
(τu − τt ) ∼ r follows the semantic (τu − ε(vk )) ∼ r for
each environment assignment of ε[vk := τt ]. Lines 14-18 of
Algorithm 1 will evaluate the LTL formula ϕi (τt ).
So far, we transformed TPTL vk .ϕi (vk ) into LTL ϕi (τt ) for
each time stamp τt . Now we can prove that the loop invariant
of Algorithm 1 holds for vk .
Proof: We will prove the Induction Step by assuming the
correctness of LTL formula ϕi according to Section VII-B:
∀i, t, ε where ϕi ⊂ LT L, 0 ≤ t < |ρ̂|
M[i, t] = > iff (ρ̂, t, ε) |= ϕi
Since for each θk , i = θk .root is the index of the highest LTL,
M[θk .root, t] will also contain the correct >/⊥ value, therefore
M[i, t] = M[θk .root, t] = > iff (ρ̂, t, ε) |= ϕi (vk = τt ) iff
(ρ̂, t, ε[vk := τt ]) |= ϕi
Since in Line 19 M[θk .parent, t] ← M[θk .root, t]
and j = θk .parent we have

M[ j, t] ← M[i, t], as a result
M[ j, t] = M[θk .parent, t] = > iff (ρ̂, t, ε) |= vk .ϕi ≡ ϕ j

B. Proof of the correctness of Algorithm 2
LTL formulas consider only propositional and temporal
operators; therefore, the time variables’ environment (ε) is not
affected by Algorithm 2. Since time variables do not change
during Algorithm 2, we assume that Algorithm 2 considers
time constraints as >/⊥ values since they are already evaluated
in Algorithm 1. In this section, we prove that the output of
Algorithm 2 corresponds to the correct evaluation of the LTL
subformula ϕ j at sample instance u based on Definition 4.
In essence, we will prove M[ j, u] = > if (ρ̂, u, ε) |= ϕ j
and similarly M[ j, u] = ⊥ if (ρ̂, u, ε) 6|= ϕ j . For the proof of
Algorithm 2, we use induction:
Base: In Section IV, we mentioned that in Line 1 of
Algorithm 1 the corresponding values for atomic propositions
are stored in the monitoring table. In essence, for each a ∈ AP,
and for each time stamp τu , we save the following values in the
monitoring table entry M[aindex , u], where aindex is the index
of atomic proposition a in the monitoring table M|ϕ|×|ρ̂| :
1)
2)

M[aindex , u] ← > if a ∈ σu if (ρ̂, u, ε) |= a
M[aindex , u] ← ⊥ if a < σu if (ρ̂, u, ε) 6|= a

Since evaluation of predicates is independent of the time
variables’ environment (ε) the above cases are always satisfied
for all sample instances u and all environments ε. As a
result, every table entry corresponding to a predicate, correctly
reflects the satisfaction of the predicate with respect to the state
trace σ̂ and the environment ε. Similarly, the table entries for
constant Boolean values (>/⊥) are trivially correct.
Induction Hypothesis: Algorithm 1 updates the values
of Table from right to left, i.e., for the samples with indexes
|ρ̂| − 1 down to 0. This is because we resolve temporal
operators looking into the future. Namely, if the Boolean
value in the next samples of time are resolved, then we can
resolve the Boolean evaluation for the current sample of time.
For the Induction Hypothesis, we assume the table entries for
the proper subformulas of ϕ j at the same or future samples
contain the correct >/⊥, i.e, we assume that
∀ϕk ⊂ ϕ j , ∀v ≥ u, M[k, v] = > iff (ρ̂, v, ε) |= ϕk
And also for the same subformula (ϕ j ), we assume the table
entries for all the future samples contain the correct >/⊥
values as follows:
∀v > u, M[ j, v] = > iff (ρ̂, v, ε) |= ϕ j
Induction Step: For the induction step we consider five
cases of ϕ j :
Case 1: ϕ j ≡ ¬ϕm :
Consider M[ j, u] ← ¬M[m, u] (Algorithm 2, Line 2).
According to Definition 4: (ρ̂, u, ε) |= ¬ϕm iff (ρ̂, u, ε) 6|= ϕm
Based on IH: M[m, u] = ⊥ iff (ρ̂, u, ε) 6|= ϕm iff (based on Def.
4) (ρ̂, u, ε) |= ¬ϕm ≡ ϕ j

Therefore, M[ j, u] = ¬M[m, u] = ¬⊥ iff (ρ̂, u, ε) 6|= ϕm iff
(ρ̂, u, ε) |= ¬ϕm ≡ ϕ j
As a result M[ j, u] = > iff (ρ̂, u, ε) |= ϕ j
Case 2: ϕ j ≡ ϕm ∧ ϕn :
Consider M[ j, u] ← M[m, u] ∧ M[n, u] (Algorithm 2, Line 4).
According to Definition 4: (ρ̂, u, ε) |= ϕm ∧ ϕn iff (ρ̂, u, ε) |= ϕm
and (ρ̂, u, ε) |= ϕn
Based on IH: M[m, u] = > iff (ρ̂, u, ε) |= ϕm and M[n, u] = >
iff (ρ̂, u, ε) |= ϕn
We know that, M[m, u] ∧ M[n, u] = > iff M[m, u] = > and
M[n, u] = >
Thus, M[m, u]∧M[n, u] = > iff (ρ̂, u, ε) |= ϕm and (ρ̂, u, ε) |= ϕn
Therefore, M[m, u] ∧ M[n, u] = > iff (ρ̂, u, ε) |= ϕm ∧ ϕn ≡ ϕ j
As a result M[ j, u] = > iff (ρ̂, u, ε) |= ϕ j
Case 3: ϕ j ≡ ϕm ∨ ϕn :
Consider M[ j, u] ← M[m, u] ∨ M[n, u] (Algorithm 2, Line 6).
According to Definition 4: (ρ̂, u, ε) |= ϕm ∨ ϕn iff (ρ̂, u, ε) |= ϕm
or (ρ̂, u, ε) |= ϕn
Based on IH: M[m, u] = > iff (ρ̂, u, ε) |= ϕm and M[n, u] = >
iff (ρ̂, u, ε) |= ϕn
We know that, M[m, u] ∨ M[n, u] = > iff M[m, u] = > or
M[n, u] = >
Thus, M[m, u] ∨ M[n, u] = > iff (ρ̂, u, ε) |= ϕm or (ρ̂, u, ε) |= ϕn
Therefore, M[m, u] ∨ M[n, u] = > iff (ρ̂, u, ε) |= ϕm ∨ ϕn ≡ ϕ j
As a result M[ j, u] = > iff (ρ̂, u, ε) |= ϕ j
Case 4: ϕ j ≡ 
ϕm
Consider M[ j, u] ← M[m, u + 1] if u < |ρ̂| − 1 (Line 11) and
M[ j, u] ← ⊥ otherwise (Line 9 of Algorithm 2).
According to Definition 4 we have two cases:
Case 4.1) u < (|ρ̂| − 1):
(ρ̂, u, ε) |= 
ϕm iff (ρ̂, u + 1, ε) |= ϕm
Based on IH: M[m, u + 1] = > iff (ρ̂, u + 1, ε) |= ϕm iff
(ρ̂, u, ε) |= 
ϕm ≡ ϕ j
As a result M[ j, u] = M[m, u + 1] = > iff (ρ̂, u, ε) |= ϕ j
Case 4.2) u = |ρ̂| − 1:
by Definition 4, (ρ̂, u, ε) 6|= ⊥
Line 9 of Algorithm 2 similarly assigns M[ j, u] ← ⊥
Case 5: ϕ j ≡ ϕm Uϕn
According to [12], Until operation can be simplified according
to following equivalence relation:
φUψ ≡ ψ ∨ (φ ∧ 
(φUψ))
In other words, we need to consider current value of 
(φUψ)
(future value of φUψ at the next sample) and use the current
values of φ and ψ to resolve and evaluate φUψ at the current
sample using equation ψ∨(φ∧
(φUψ)). Algorithm 2 considers
two case for ϕ j ≡ ϕm Uϕn ≡ ϕn ∨ (ϕm ∧ 
(ϕm Uϕn )):
Case 5.1) u < (|ρ̂| − 1):
Now consider the update of M[ j, u] ← M[n, u] ∨ (M[m, u] ∧
M[ j, u + 1]) according to Line 17 of Algorithm 2.
Based on IH: M[n, u] = > iff (ρ̂, u, ε) |= ϕn and M[m, u] = >
iff (ρ̂, u, ε) |= ϕm and
M[ j, u + 1] = > iff (ρ̂, u + 1, ε) |= ϕ j iff (ρ̂, u, ε) |= 
ϕ j
According to Case 2 (Conjunction) M[m, u] ∧ M[ j, u + 1] = >
iff (ρ̂, u, ε) |= ϕm and (ρ̂, u, ε) |= 
ϕ j
Therefore, M[m, u] ∧ M[ j, u + 1] = > iff (ρ̂, u, ε) |= ϕm ∧ 
ϕ j
We know that, M[ j, u] = > iff M[n, u] = > or M[m, u] ∧
M[ j, u + 1] = >

According to Case 3 (Disjunction) M[ j, u] = > iff (ρ̂, u, ε) |= ϕn
or (ρ̂, u, ε) |= ϕm ∧ 
ϕ j
As a result, M[ j, u] = > iff (ρ̂, u, ε) |= ϕn ∨ (ϕm ∧ 
ϕ j )
Case 5.2) u = |ρ̂| − 1:
According to Case 4.2 for Next operator: (ρ̂, u, ε) 6|= ⊥
This implies that ϕ j ≡ ϕn ∨ (ϕm ∧ ⊥) ≡ ϕn ∨ ⊥ ≡ ϕn
Now consider the update of M[ j, u] ← M[n, u] according to
Line 15 of Algorithm 2.
Based on IH: M[n, u] = > iff (ρ̂, u, ε) |= ϕn
Therefore after the assignment, M[ j, u] = > iff (ρ̂, u, ε) |= ϕ j

2014 American Control Conference (ACC)
June 4-6, 2014. Portland, Oregon, USA

Functional Gradient Descent Method for Metric Temporal Logic
Specifications
Houssam Abbas, Andrew Winn, Georgios Fainekos and A. Agung Julius
Abstract— Metric Temporal Logic (MTL) specifications can
capture complex state and timing requirements. Given a nonlinear dynamical system and an MTL specification for that system,
our goal is to find a trajectory that violates or satisfies the
specification. This trajectory can be used as a concrete feedback
to the system designer in the case of violation or as a trajectory
to be tracked in the case of satisfaction. The search for such
a trajectory is conducted over the space of initial conditions,
system parameters and input signals. We convert the trajectory
search problem into an optimization problem through MTL
robust semantics. Robustness quantifies how close the trajectory
is to violating or satisfying a specification. Starting from some
arbitrary initial condition and parameter and given an input
signal, we compute a descent direction in the search space,
which leads to a trajectory that optimizes the MTL robustness.
This process can be iterated to reach local optima (min or max).
We demonstrate the method on examples from the literature.

I. I NTRODUCTION
The development of control laws for nonlinear systems
still remains a formidable challenge despite the wealth of results on nonlinear control. Many practitioners and researchers
still prefer to use classic optimal control [1] and ProportionalIntegral-Derivative (PID) control [2]. There are a number
of reasons for such a choice. The most important one is
that such methods are automatic or almost automatic and,
especially in industry, the control engineers might desire
to avoid complex mathematical derivations. In other cases,
PID control is sufficient to achieve the desired results [3] or
accurate mathematical models might not be available.
Usually, Model-Based Development (MBD) software
tools, like Simulink Design OptimizationTM , can search over
system parameters so that the system output satisfies certain
time and frequency domain specifications. S-TALIRO [4]
and BREACH [5] can be used for both falsification and
open loop control design for temporal logic specifications.
In particular, Metric Temporal Logic (MTL) [6] can capture
requirements on the correct sequencing of events, conditional
reachability, safety requirements and real-time constraints
between various events. In the MTL falsification problem
you are given a formal requirement in MTL and the goal
is to find system operating conditions and parameters that
generate behaviors which do not satisfy the requirements. In
[7], the robustness value of an MTL formula [8] with respect
This work was partially supported by the NSF awards CNS-1116136,
CNS-1218109, CNS-1319560 and by the Department of Defense SMART
Scholarship.
H. Abbas and G. Fainekos are with the Schools of Engineering at Arizona
State University, Tempe, AZ, E-mail: {hyabbas,fainekos}@asu.edu
A. Winn and A. A. Julius are with the Department of Electrical,
Computer, and Systems Engineering at Rensselaer Polytechnic Institute,
Troy, NY, E-mail: winna@rpi.edu, agung@ecse.rpi.edu

978-1-4799-3274-0/$31.00 ©2014 AACC

to a system simulation is considered as the cost function
for an optimization problem. By minimizing the robustness
value over the system simulations one can discover incorrect
or non-robust system behaviors, and by maximizing the
robustness value one can synthesize robust optimal control
trajectories with respect to the MTL specification, all within
the same framework.
All the aforementioned tools treat the system as a blackbox in order to handle systems of arbitrary complexity. They
need an accurate system simulator and, usually, as the fidelity
of the model increases so does the simulation time. Thus, the
total number of simulations needed before simulation-based
tools can provide an answer becomes critical.
In [9], the first steps were taken towards addressing the
problem of reducing the number of simulations for the MTL
falsification problem. That work dealt with deterministic
autonomous nonlinear systems where the search space was
the set of initial conditions (and any parameters) x0 of
the system. If f (x0 ) denotes the MTL robustness value of
the trajectory starting from x0 , then the goal of [9] was
to compute a vector d such that f (x0 + d) < f (x0 ). In
this paper, the search space consists of the set of initial
conditions x0 in RN and the set of square-integrable input
signals of duration T > 0. If a trajectory is computed starting
from an initial condition x0 and under a given input signal
u(·) yields property robustness f (x0 , u), then a descent
element (dx0 , du ) should be computed so that starting from
x0 +dx0 and under input u+du , the trajectory has robustness
f (x0 + dx0 , u + du ) < f (x0 , u).
Our solution combines the previous works in [9], [10]. In
brief, the work in [10] deals with the problem of optimizing
a differentiable integral cost function over the output trajectories of the system starting from a given input signal. The
method is based on the calculus of variations, but it uses a
gradient descent based approach to solve the optimization
problem without formulating the optimality conditions given
by the Minimum Principle.
Contributions: In this paper, we present a method for the
computation of descent directions for reducing specification
robustness for nonlinear dynamical systems. In particular,
given an arbitrary MTL specification, we determine a critical point on the system trajectory which if changed, then
the MTL robustness will be changed as well. We derive
the equations which, given (x, u), will give a descent direction (dx , du ) that provably reduces robustness. Finally,
we demonstrate the applicability of our approach on some
nonlinear models from the literature.

2312

II. P ROBLEM F ORMULATION
We consider a dynamical system with state x ∈ X ⊂ R
ẋ = F (t, x, u)

n

(1)

for a C 1 flow F : R×Rn ×Rm → Rn with initial conditions
x0 ∈ X0 , and control input signal u ∈ L2 [0, T ] which takes
values in a bounded subset U of Rm : u(t) ∈ U ∀t. T is
the trajectory duration, and is fixed throughout this paper, so
we may write L2 without ambiguity. As explained earlier,
x0 can include any system parameters (which are assumed
constant throughout a simulation). The letter w will denote
an element w = (x0 , u) of X0 × L2 . Standard assumptions
apply - see [9], [10].
Assumption 2.1: For every w = (x, u) ∈ X0 × L2 , there
exists a unique solution sw (·) :7→ Rn to the ODE (1). The
solution sw is absolutely continuous. The flow F is locally
bounded, that is, for all compact subsets S ⊂ [0, T ]×X0 ×U ,
there exists m > 0 such that F (S) ⊂ mB, where B is the
unit ball centered at 0.
We formally capture specifications regarding the correct
system behavior using Metric Temporal Logic (MTL) formulae [6]. An MTL formula is a formal logical statement
expressing some property that the system must satisfy. It is
built by combining atomic propositions using logical and
temporal operators. Logical operators are the conjunction
(∧), disjunction (∨), negation (¬), and implication (→).
The temporal operators include eventually (3I ), always
(2I ) and until (UI ). For example, MTL can capture the
requirement that “all the trajectories sw attain a value in the
set [10, +∞)” (3[0,∞) sw (t) ≥ 10), or that “whenever the
value of sw exceeds 10, then it should go below 7 within
5 sec and remain there for at least 10 sec” (2(sw (t) ≥ 10 →
3[0,5] 2[0,10] sw (t) ≤ 7)).
If we associate a set O(p) with each atomic proposition
p ∈ AP such that p is true of the states in O(p), then the
above properties can be written as 3[0,∞) p1 with O(p1 ) =
[10, +∞), and 2(¬p1 → 3[0,5] 2[0,10] p2 ) with O(p2 ) =
(−∞, 7]. We can quantify how robustly a system trajectory
sx satisfies a specification φ in MTL [8]. Namely, we define
a function of the trajectory, ρφ (sw ), which takes positive
values if sw satisfies φ and negative values otherwise.
Its magnitude |ρφ | quantifies how well the specification is
satisfied or falsified. The process of falsifying a specification
φ, i.e. detecting a system behavior that does not satisfy φ,
can thus be re-cast as the problem of finding trajectories
with negative ρφ -values. On the other hand, the optimal
control can be posed as the problem of maximizing the
positive robustness. Since the solutions to (1) are assumed
unique, the search can be performed over the initial states
x ∈ X0 (including any system parameters) and control
signals u ∈ L2 , and can be improved by computing local
descent directions for ρφ .
Problem 1: Given x ∈ X0 , u ∈ L2 , and a formula φ, find
a vector dx ∈ Rn and signal du ∈ L2 such that there exists
an h > 0 for which

A general MTL formula will involve multiple propositions
pi and their sets O(pi ). The following proposition simplifies
our task:
Proposition 2.1: Consider an MTL formula φ and a trajectory sw of (1) such that [[φ, O]](sw , 0) > 0. If assumption
2.1 holds, and for each p ∈ AP , O(p) is a closed halfspace, then there exist a critical time tr ∈ [0, T ] and a
critical proposition p ∈ AP which appears in φ such that
ρφ (w) = inf z∈O(p) ksw (tr ) − zk.
In this paper, we derive the descent vector relative to only one
O(p) at a time; this is the content of Problem 2. The choice of
which O(p) to descend towards at any given time is decided
by the following heuristic: the current target set is always
the set O(p) where p is the critical proposition defined in
Proposition 2.1. Other heuristics are possible. By focusing
on one O(p), the problem is reduced to falsification of a
safety formula, of the form: φ = (¬p) where O(p) = U is
the set of ‘unsafe’ system states.
The robustness then reduces to:
ρφ (x, u) = f (x, u) , min dU (s(x,u) (t))
0≤t≤T

(2)

where dU (y) , inf z∈U ky − zk is the distance of a point y
from U.
The function f is non-differentiable, and generally nonconvex. The special problem is then:
Problem 2: Given x ∈ X0 , u ∈ L2 , U ⊂ Rn , and f
defined in (2), find dx ∈ Rn and du ∈ L2 such that there
exists an h > 0 for which
f (x + h · dx, u + h · du) < f (x, u) ∀ h ∈ (0, h)
If we treat H , X × L2 as a Hilbert space, then it can be
seen that dw = (dx, du) ∈ H is a descent direction in H.
III. C OMPUTING A D ESCENT D IRECTION
Recall that H = X0 × L2 is the Hilbert search space, and
let w ∈ H be an element of that space. For convenience we
define sw (t) = sx0 (t; u).
Before continuing we will prove a result that will allow
us to calculate our descent direction using a convex differentiable manifold.
Theorem 3.1: Let w1 ∈ H with critical time tr,1 as
defined in Proposition 2.1. Define
z(t; w) = argminz∈U ks̄(t; w) − zk,

(3)

J(w) = ks̄(tr,1 ; w) − z(tr,1 ; w1 )k.

(4)

and

Suppose that there exists w2 ∈ H with critical time tr,2 such
that J(w2 ) < J(w1 ). Then the robustness of the trajectory
sw2 (·) is smaller than that of sw1 (·): f (w2 ) < f (w1 ).
Proof: By (2) we see that

ρφ (x + h · dx, u + h · du) < ρφ (x, u) ∀ h ∈ (0, h)
2313

f (w2 ) = min inf ksw2 (t) − zk,
0≤t≤T z∈U

≤ J(w2 ) < J(w1 ) = f (w1 )

Our goal is to minimize the robustness. To do so we
generate a sequence (wi ) ∈ H such that f (wi+1 ) < f (wi )
as follows: first, w0 is given. Then, we iteratively generate
wi+1 from wi by identifying a critical time tr,i and the
corresponding closest unsafe point z(tr,i , wi ). We define the
function
Ji (w) , G(sw (tr,i )) , kz(tr,i , wi ) − sw (tr,i )k

∂F (t)
d
pu (·, τ ) =
pu (t, τ ),
dt
∂x
∂F (t)
d
px0 =
px0 (t),
dt
∂x
∂F (τ )
,
pu (τ, τ ) =
∂u
px0 (0) = In×n

(5)

We then calculate a descent direction ŵ ∈ H and set
wi+1 = wi + hŵ, where h is the step-size. The step-size
is adapted on-line: increased if a descent is obtained, and
reduced if no descent is achieved. Note that with respect to
sw (tr,i ) (5) is differentiable everywhere except for the origin,
at which point the trajectory has reached the unsafe set and
falsification has been shown.
We now adapt the results presented in [10] to find an
update direction ŵ for w that locally decreases Ji (w), which
in turn will decrease the robustness, as per Thm.3.1.
Let dJi (w; ŵ) be the Fréchet derivative of Ji (w) in the
direction ŵ, and let x̂0 and û be the projections of ŵ onto
X0 and L2 . This derivative can be written as a scalar valued
linear functional of ŵ as follows:
Z T
qu (τ )û(τ ) dτ + qxT0 x̂0 ,
dJi (w; ŵ) , hq, ŵi ,
(6)
0

where qx0 and qu are the projections of q ∈ H onto X0 and
U . For brevity we shall use the following notations

∂G 
∂G
,
∈ R1×n ,
∂x
∂x s(tr,i ;x0 ,u)

∂F (t)
∂F 
∈ Rn×n ,
,
∂x
∂x (t,s(t;x0 ,u),u)

∂F 
∂F (t)
∈ Rn×m .
,
∂u
∂u (t,s(t;x0 ,u),u)
Let dsw (t; ŵ) represent the functional derivative of sw (t)
in the direction ŵ. Using the Taylor series based approach
in [10] we see that
∂G
dJi (w, ŵ) =
sw (tr,i ; ŵ),
(7)
∂x
dsw (t; ŵ) =

Z t
∂F (τ )
∂F (τ )
dsw (τ ; ŵ) +
û(τ ) dτ (8)
∂x
∂u
0
Now suppose that
dsw (t; ŵ) = hp(t), ŵi
Z t
pu (t, τ )û(τ )dτ + px0 (t)T x̂0 .
=

We can solve for pu (t, τ ) and px0 (t) by solving the initial
value problem
(10)

By combining (7) with (9) and comparing to (6), we find
that
∂G
pu (tr,i , τ )
∂x
∂G
px (tr,i )
=
∂x 0

qu (τ ) =
qx0

Thus, to find a dJi (w; ŵ) that is negative, we can set ŵ in
the inner product (6) to be −q, that is
∂G
pu (tr,i , τ ),
∂x
∂G
px (tr,i ).
x̂0 = −
∂x 0

û(τ ) = −

(11)
(12)

In order to calculate the update direction for a continuous
input on a digital computer, we represent the input function
by a linear combination of finitely many basis functions. In
each example presented in Section IV, we consider a basis of
either rectangular or triangular pulses that are evenly spaced
through time. Then we can calculate an exact update to the
input parameters using, for example, the sensitivity analysis
tools provided by SundialsTB toolbox [11].
Our approach is a local descent optimization; it can
easily be used within a multi-start scheme (where a local
optimization is performed from several initial points in the
search space), as illustrated in Example 3.
IV. E XPERIMENTS
Example 1: Our first example is a linear 81-dimensional
RLC circuit. The equations are given by
ẋ(t) = Ax(t) + bu(t)
where A and b have appropriate dimensions. The sensitivity
ODE is then itself linear [9]. The safety specification requires
the output voltage to always be less than 1.5V:
φRLC = (x41 ≤ 1.5)

(9)

0

Plugging this equation into the right hand side of (8),
rearranging terms and swapping the order of integration and
equating terms with (9) yields
Z t
∂F (ξ)
∂F (τ )
pu (t, τ ) =
pu (ξ, τ )dξ +
∂x
∂u
τ
Z t
∂F (τ )
px0 (τ )dτ
px0 (t) =
∂x
0

Starting from x0 = [0, 0] and a constant input of 0, the
descent converges to a falsifying trajectory with a near-step
input.
4
Example 2: This example is adapted from [7], given by


x1 (t) − x2 (t) + u(t)
ẋ(t) =
x2 (t) cos(2πx2 (t)) − x1 (t) sin(2πx1 (t)) + u(t)
with initial condition x0 ∈ X0 = [−1, 1] × [−1, 1], and specification 2¬p2 with O(p2 ) = [−1.6, −1.4] × [−0.9, −1.1].

2314

1

0.104

0

ufinal

−1

0.102

−2
−3

u(t)

0.1

−4
−5

0.098

−6
−7

0.096

−8
−9
0

50

100

0

200

250

Fig. 2: Example 3 (Insulin). Final input u(t) found by descent
algorithm, scaled to highlight the initial impulse.

0.092

0.09

150
t

0.094

0.5

1

1.5

2

2.5
3

t

2.5

Fig. 1: Example 2. Final input found by descent.

2
1.5
1

Starting from x0 = [0, 0] and a constant input of 0.1,
the descent converges to a falsifying trajectory.The falsifying
input is shown in Fig.1.
4
Example 3: The following example is 3-dimensional system modeling the variation of glucose and insulin levels
in the blood, following a meal intake [12]. The model
was developed to help design insulin infusion schedules for
diabetes patients, e.g. as done in [13]. It is given by


−p1 x1 (t) − x2 (t)(x1 (t) + Gb ) + Be−kt

−p2 x2 (t) + p3 x3 (t)
ẋ(t) = 
1000
u(t)
−n(x3 (t) + Ib ) + 60V
I
State x1 represents the level of glucose in the blood
plasma above a given basal value Gb , x2 is proportional
to the level of insulin that is effective in controlling blood
glucose level, and x3 represents the level of insulin above
a given basal value Ib . The search space for [x1 , x2 , x3 ] is
[6, 10] × [0.05, 0.1] × [−0.1, 0.1]. The input u(t) represents a
direct infusion of insulin meant to control the glucose level.
u(t) is therefore also referred to as an ‘infusion schedule’.
The pi , n, B and k are model parameters. We fix duration
T = 200. Consider first the following specification:
φ1 = [0,20] x1 ∈ [−2, 10] ∧ [20,200] x1 ∈ [−1, 1]
φ1 specifies that glucose level should remain in the range
[−2, 10] for the first 20 seconds, and should remain in the
range [−1, 1] for the last 180 seconds. Our goal is to design
an infusion schedule such that the glucose level satisfies φ1 .
This can be posed as the problem of falsifying ¬φ1 . We
decided to search over the initial values of the ODE (1), the
input u, and the parameter p3 : p3 varies between diabetes
patients, and its estimated value for normal subjects is 1.3e5 [12]. Larger p3 values imply that the insulin injection u(t)
will have a greater effect on the plasma glucose level x1 (t).
The search range for p3 is therefore fixed to [1e-5,1e-3]. Thus
the outcome of the optimization is a set of initial conditions
(patient’s state at meal time), a continuous infusion schedule,
and a class of patients (as described by the parameter p3 ) for
which the schedule is appropriate.
Starting from a constant input signal at 0.1, and
[x0 , p3 ] =[8, 0.08, 0, 1.3e-5], the initial robustness is 1.5399.

0.5
0

0

20

40

60

80

100
t

120

140

160

180

200

(a) Final input obtained by descent.
10

5

0

−5
0

20

40

60

80

100
t

120

140

160

180

200

(b) Final trajectory returned by descent.

Fig. 3: Example 3 (Insulin). A profile obtained by multi-start.

The optimization returned a decision w with robustness 0.678
in 12 iterations. The final p3 value is 2.03e-5. It is interesting
to note that the final input shows an injection at the beginning
of time, followed by a constant infusion (Fig. 2). This is
the type of infusion schedule advocated as being optimal in
[12, Section III], Runder the nominal p3 value and the cost
T
function C(u) = 0 x21 (t)dt. Our descent method produced
this schedule with relatively little computational effort, and
provides more information on the classes of patients for
which it is appropriate.
Consider next the following specification
φ2 = (phg ∧ X ¬phg → 3[0,10] ([0,20] ¬phg ))
with O(phg ) = {x | x1 ≥ 9.44}. φ2 expresses that if
the glucose level rises above 9.44 mmol/L (meaning hyperglycemia), it should dip below 9.44 within 10secs and stay
there for at least 20secs. Starting from [6, 0.05, 0.1, 0.0001],
the descent keeps the initial value of x1 , since one way to
satisfy φ2 is to never go above the dangerous level of 9.44. To
see how the schedule might need to be adapted for different
values of p3 , we ran a random multi-start simulation, were
we uniformly sample the search space (we used 50 samples),
and from each sample we run a local descent. Fig.3a shows
a falsifying input profile significantly different from the one
in Fig.2, with p3 =8e-4. Whether the shown input schedule
is practicable with today’s technology is not assessed, but
the point is that different classes of patients (and different

2315

initial states) might require different schedules. The resulting
glucose trajectory is shown in Fig.3b, demonstrating a quick
decrease towards safer levels of glucose.
4
Example 4: This example is a 6-dimensional system that
models a quadrotor moving through a vertical plane [10].
The system dynamics are given by:
u1
sin θ
m
u1
Ÿ = µ(wY − Ẏ ) − g +
cos θ
m
θ̈ = u2

Ẍ = µ(wX − Ẋ) −

Here m denotes the object’s mass, g denotes gravitational
acceleration, µ is the coefficient of friction with the air, w·
is the wind velocity along each axis, and ui is the control
input. We define the XY coordinate of the object’s center of
mass as the system’s output.
For this example, we consider the task of verifying the
safety of controllers that drive the quadrotor from one side
of a hill over to the other side without hitting the hill or the
ground. On the other side is a desired goal region, which
the quadrotor must reach within 12 seconds and stay there
afterwards. This requirement can be represented by the MTL
specification,
φ = [12,∞] p1 ∧ [0,12] ¬p2 ∧ [0,12] ¬p3 ,
Here, p1 represents the goal set, p2 represents the ground,
and p3 represents the hill. The sets O(p1 ), O(p2 ), O(p3 ) used
in our experiments are shown graphically in Figure 4.
First, we designed a reference tracking feedback controller
by linearizing the system around a hovering operating point.
The system is assumed to be initially hovering at location
[x, y] = [−8, 2] and that there is no wind during the simulation. Although this controller works well in the nominal
case, it is prudent to consider what happens if the system
does not begin at the expected initial state, or if there is any
wind disturbance. To this end, we treat the wind velocity
as an input to the system bounded by ±2 m/s. We use the
algorithm presented in this paper to search over bounded sets
of initial conditions and horizonal wind profiles.
When the optimization was first run, the system was
falsified mainly by shifting the intial x position to the left
and by having the wind blow the quadrotor to the left. The
updated initial condition and wind disturbance thus caused
the quadrotor to fly into the ground in a way that is not
expected for the nominal performance. This algorithm was
able to quickly find this major design flaw, as shown in
Figure 4.
After fixing the reference signal to maintain a height
of 2 for all points to the left of the starting location, the
optimization was rerun. After running for 7 iterations, the
algorithm found that the initial conditions [x, y, θ, ẋ, ẏ, θ̇] =
[0, 0, 0.005, 0, 0, 0.098] and the wind profile shown in Figure 5 was able to falsify φ, specifically by slowing the
horizontal progression of the quadrotor so that it was not
in the goal set at time t = 12.

V. R ELATED W ORK
The work that appears in [14], [15] is the closest to the
results that we present here in terms of methods utilized. In
[15], sensitivity analysis is used to compute neighborhoods
of trajectories that always remain close enough and, thus,
perform coverage of the initial conditions. These results were
later extended in [14] to estimating parameter ranges and
initial conditions for the satisfaction of STL properties. Even
though our solution leads to sensitivity calculations, our objective is very different from the work in [14]. Our goal is to
develop the local search tools needed in order to improve the
performance of stochastic MTL falsification/optimal control
methods [7], [16]. Moreover, we can search simultaneously
over the initial conditions, parameters and the input signals. Finally, stochastic falsification methods avoid the stateexplosion problems that occur when attempting to cover a
high-dimensional set of parameters.
Different versions of the optimal control problem under
Linear Temporal Logic (LTL) specifications are presented
in [17], [18]. The authors in [17] take a mathematical
programming approach, while [18] develops an automata
based approach. Unlike MTL, LTL does not allow the specification of timing intervals for the Until operator UI (and by
extension, the Always and Eventually operators). This timing
interval is necessary for expressing real-time constraints on
the succession of events, which is important in many control
applications. The problem of optimal control for vehicle
routing for MTL specifications is addressed in [19]. However,
the results in [19] apply to specifications without nested
temporal operators and finite transition systems.
Our work in this paper can also be viewed as an optimal
control problem over hybrid systems. Since in our implementation we parameterize the input signals with a finite
number of parameters at specific points in time, we can
view the system as a parametric hybrid automaton where the
mode switches occur at specific time instants. Then the goal
is to compute the system parameters and initial conditions
such that the MTL robustness is minimized. However, we

Fig. 4: Falsification of Quadrotor with poor reference signal

2316

Fig. 5: Falsifying Wind Profile for Quadrotor System

remark that our theoretical results do not require the finite
parameterization of the input function space.
In terms of optimal control over hybrid systems, [20]
calculates numerically a descent direction for a class of
switched systems. First, we remark that our original cost
function is non-differentiable so it does not satisfy the
assumptions in [20]. In our current numerical implementation
each subproblem that we solve, i.e., descent to a specific set,
satisfies the assumptions in [20]. Thus, our solution could be
utilizing the results in [20] to solve more general problems
in the future. Similar remarks hold for the optimal control
problem formulated in [21]. Finally, in [22], we demonstrated
that in the case of linear hybrid systems improvements in
the convergence rate of stochastic search algorithms can be
achieved by adding a local search step.
VI. C ONCLUSIONS
We have presented the derivation of the equations that
can be used for the computation of Metric Temporal Logic
(MTL) robustness descent vectors in the set of initial conditions, parameter space and input function space for nonlinear
dynamical systems. These results are necessary for enabling
“gray box” MTL falsification and open loop control methods
for dynamical systems. One important advantage of the
proposed approach is that our framework can be readily used
for MTL falsification and/or optimal control methods within
any Model Based Development (MBD) tool that supports
sensitivity analysis. For instance, Simulink can provide such
functionality [23]. In the future, we will focus on extending
our new approach to hybrid systems using, for instance, the
decomposition method proposed in [24]. Also of interest is
the interplay between stochastic search methods [22] and
local gradient descent [25].
R EFERENCES
[1] D. P. Bertsekas, Dynamic Programming and Optimal Control, Two
Volume Set, 2nd ed. Athena Scientific, 2000.
[2] K. Ogata, Modern Control Engineering, 4th ed. Prentice Hall, 2001.

[3] N. Michael, D. Mellinger, Q. Lindsey, and V. Kumar, “The GRASP
multiple micro uav testbed,” IEEE Robotics and Automation Magazine,
vol. 17, no. 3, pp. 56–65, 2010.
[4] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan, “S-taliro: A tool for temporal logic falsification for hybrid
systems,” in Tools and algorithms for the construction and analysis
of systems, ser. LNCS, vol. 6605. Springer, 2011, pp. 254–257.
[5] A. Donze, “Breach, a toolbox for verification and parameter synthesis
of hybrid systems,” in Computer Aided Verification, ser. LNCS.
Springer, 2010, vol. 6174, pp. 167–170.
[6] R. Koymans, “Specifying real-time properties with metric temporal
logic.” Real-Time Systems, vol. 2, no. 4, pp. 255–299, 1990.
[7] H. Abbas, G. E. Fainekos, S. Sankaranarayanan, F. Ivancic, and
A. Gupta, “Probabilistic temporal logic falsification of cyber-physical
systems,” ACM Transactions on Embedded Computing Systems,
vol. 12, no. s2, May 2013.
[8] G. Fainekos and G. Pappas, “Robustness of temporal logic specifications for continuous-time signals,” Theoretical Computer Science, vol.
410, no. 42, pp. 4262–4291, September 2009.
[9] H. Abbas and G. Fainekos, “Computing descent direction of mtl
robustness for non-linear systems,” in American Control Conference,
2013.
[10] A. K. Winn and A. Julius, “Optimization of human generated trajectories for safety controller synthesis,” in American Control Conference
(ACC), 2013, 2013, pp. 4374–4379.
[11] R. Serban and A. Hindmarsh, “Cvodes: the sensitivity-enabled ode
solver in sundials,” in Proceedings of IDETC/CIE, 2005.
[12] M. Fisher, “A semiclosed-loop algorithm for the control of blood glucose levels in diabetics,” Biomedical Engineering, IEEE Transactions
on, vol. 38, no. 1, pp. 57–61, 1991.
[13] S. Sankaranarayanan and G. Fainekos, “Falsification of temporal
properties of hybrid systems using the cross-entropy method,” in
ACM International Conference on Hybrid Systems: Computation and
Control, 2012.
[14] A. Donze, E. Fanchon, L. M. Gattepaille, O. Maler, and P. Tracqui,
“Robustness analysis and behavior discrimination in enzymatic reaction networks,” PLoS ONE, vol. 6, no. 9, p. e24246, 09 2011.
[15] A. Donze and O. Maler, “Systematic simulation using sensitivity
analysis,” in Hybrid Systems: Computation and Control, ser. LNCS,
vol. 4416. Springer, 2007, pp. 174–189.
[16] T. Nghiem, S. Sankaranarayanan, G. Fainekos, F. Ivancic, A. Gupta,
and G. Pappas, “Monte-carlo techniques for falsification of temporal
properties of non-linear hybrid systems,” in Hybrid Systems: Computation and Control, 2010.
[17] S. Karaman, R. Sanfelice, and E. Frazzoli, “Optimal control of mixed
logical dynamical systems with linear temporal logic specifications,”
in IEEE Conf. on Decision and Control, 2008.
[18] E. A. Gol and C. Belta, “Time-constrained temporal logic control of
multi-affine systems,” Nonlinear Analysis: Hybrid Systems, vol. 10,
pp. 21–33, 2013.
[19] S. Karaman and E. Frazzoli, “Vehicle routing problem with metric
temporal logic specifications,” in IEEE Conference on Decision and
Control, Dec. 2008, pp. 3953 –3958.
[20] H. Gonzalez, R. Vasudevan, M. Kamgarpour, S. S. Sastry, R. Bajcsy,
and C. J. Tomlin, “A descent algorithm for the optimal control of constrained nonlinear switched dynamical systems,” in Proceedings of the
13th ACM international conference on Hybrid systems: computation
and control, ser. HSCC ’10. ACM, 2010, pp. 51–60.
[21] H. Axelsson, Y. Wardi, M. Egerstedt, and E. Verriest, “Gradient
descent approach to optimal mode scheduling in hybrid dynamical
systems,” Journal of Optimization Theory and Applications, vol. 136,
no. 2, pp. 167–186, 2008.
[22] H. Abbas and G. Fainekos, “Linear hybrid system falsification through
local search,” in Automated Technology for Verification and Analysis,
ser. LNCS, vol. 6996. Springer, 2011, pp. 503–510.
[23] Z. Han and P. J. Mosterman, “Towards sensitivity analysis of hybrid
systems using simulink,” in Proceedings of the 16th international
conference on Hybrid systems: computation and control. ACM, 2013,
pp. 95–100.
[24] A. Zutshi, S. Sankaranarayanan, J. V. Deshmukh, and J. Kapinski,
“A trajectory splicing approach to concretizing counterexamples for
hybrid systems,” in IEEE Conference on Decision and Control, 2013.
[25] D. Hristu and K. Morgansen, “Limited communication control,” Systems & Control Letters, vol. 37, pp. 193–205, 1999.

2317

2016 IEEE International Conference on Automation Science and Engineering (CASE)
Fort Worth, TX, USA, August 21-24, 2016

Modeling Concurrency and Reconfiguration in Vehicular Systems: A
π -calculus Approach
Joseph Campbell, Cumhur Erkan Tuncali, Peng Liu, Theodore P. Pavlic, Umit Ozguner and Georgios Fainekos

dynamics. Another common assumption in the current literature is to ignore any potential issues in the communication
protocols of the vehicular systems. Both assumptions can be
very limiting when trying to utilize such control algorithms
on real networks of heterogeneous vehicles operating at high
speeds.
In this paper, we develop a modeling framework for
collaborating vehicular systems where both the high-level
communication protocols and the low-level complex vehicle
dynamics can be modeled in the same framework. For
modeling the communication and reconfiguration layer of
the system we have chosen the formalism of π-calculus,
which was specifically developed for modeling and reasoning
over mobile communicating processes where the network
structure can be modified dynamically [4]. For the closedloop system dynamics of each vehicle, we use the modeling
framework of hybrid automata [5]. The two layers communicate and synchronize through message passing.
The primary and immediate benefit of such a framework
is its flexibility. Different communication protocols can be
modeled quickly in a hierarchical fashion where at the
highest level we can potentially verify correctness of the
protocols. For example, the proposed framework can easily
incorporate verifiable privacy protocols [6] or broadcasting
protocols [7]. Furthermore, different vehicles and control
algorithms can be easily modeled and simulated because
hybrid automata model both the control and continuous
dynamics of the vehicles as well as any other discrete modes
of operation for these vehicles (e.g., emergency braking,
economy versus sport driving mode). The main benefit of
utilizing hybrid automata as a modeling framework is that
reachability analysis [8] and automated test generation [9]
can be performed efficiently and effectively. At the same
time, executable code can be automatically generated for the
lower levels [10].
Because autonomous vehicles are safety-critical systems,
there needs to be a requirements-based analysis of the whole
system rather than of specific components (e.g., [7]) or
behaviors (e.g., [11]). Ultimately, there should be a verification framework for heterogeneous, high-fidelity models of
collaborating vehicular systems similar to what was proposed
by Damm et al. [12] for the Automatic Train Protection
system. In particular, stable and safe vehicle controllers for
simplified models can be tested for safety violations using
high-fidelity vehicle models in automated test generation
tools such as S-TA L I RO [9]. This work is the first step

Abstract— As autonomous or semi-autonomous vehicles are
deployed on the roads, they will have to eventually start communicating with each other in order to achieve increased efficiency
and safety. Current approaches in the control of collaborative
vehicles primarily consider homogeneous simplified vehicle
dynamics and usually ignore any communication issues. This
raises an important question of how systems without the aforementioned limiting assumptions can be modeled, analyzed and
certified for safe operation by both industry and governmental
agencies. In this work, we propose a modeling framework where
communication and system reconfiguration is modeled through
π-calculus expressions while the closed-loop control systems
are modeled through hybrid automata. We demonstrate how
the framework can be utilized for modeling and simulation of
platooning behaviors of heterogeneous vehicles.

I. I NTRODUCTION
The DARPA Grand Challenges and, in particular, the
Urban Challenge, demonstrated the feasibility of fully autonomous vehicles driving in urban and rural areas. Since
then, multiple well-established companies, research labs,
and startups are competing towards becoming the first to
sell fully autonomous vehicles capable of driving on the
same roads as human-operated vehicles. One important question that has not yet been addressed with current research
and development activities is how to enable collaboration
and cooperation among the autonomous (and even semiautonomous) vehicles.
Cooperation is essential in many practical applications of
autonomous vehicles, such as platooning. A vehicle platoon
is a formation in which several vehicles closely follow each
other in order to reduce aerodynamic drag, yielding both
reduced fuel consumption [1] and increased road capacity [2]. Another typical application where vehicle cooperation
is required is collision avoidance at intersections [3]. In this
application, when two or more vehicles approach an intersection from different directions, they communicate directly or
indirectly in order to cross the intersection without (usually)
coming to a full stop.
Prior work has tackled the challenge of vehicle cooperation by focusing on the development of control and scheduling algorithms for homogeneous vehicles with simplified
J. Campbell, C.E. Tuncali, T.P. Pavlic, and G. Fainekos are with SCIDSE,
Arizona State University, Tempe, AZ 85281, USA. {jacampb1,

etuncali, tpavlic, fainekos}@asu.edu
P. Liu and U. Ozguner are with ECE, Ohio State University, Columbus,
OH 43212, USA. {liu.3193, ozguner.1}@osu.edu
This work has been partially supported by award NSF CPS 1446730 and
NSF 1446735.

978-1-5090-2409-4/16/$31.00 ©2016 IEEE

523

towards that goal.
In summary, our contribution in this paper is the development of a modeling framework that can represent complex
vehicular networks. The complexity enters both in terms of
vehicle dynamics and in terms of complex communication
and decision-making protocols. We show that our framework
can effectively model heterogeneous vehicular networks running a variety of control algorithms. Finally, the proposed
framework lays the groundwork in making verification (at
least in terms of automatic test generation) of these systems
both tractable and practical.

platoon, neither case explicitly models any communication
nor coordination protocols between vehicles. Platzer [16]
clarifies that communication can be modeled within their
framework, but shared variables with access delays must
be used as opposed to explicitly modeling communication
channels that are opened, maintained, and closed by vehicles.
Furthermore, despite the expressiveness of the framework,
direct and automated synthesis of controllers that meet
required specifications remains elusive.
Along another direction to this problem, Franzle
et al. [17] present an extension to the Multi-Lane Spatial
Logic (MLSL) [18] by introducing a local scope for the
observations of each vehicle. MLSL has been proposed as
a logical framework for reasoning about decision-making
algorithms for automated driving.
A number of works consider the verification and synthesis
problem for cooperative vehicle behaviors exclusively at
the supervisory or communication level only. That is, no
continuous vehicle dynamics are explicitly considered. For
example, Bochmann et al. [19] present a discrete-event
controller synthesis algorithm for lane-changing maneuvers.
Bengtsson et al. [20] present a communication protocol for
enabling two platoons to merge together. The work of Kamali
et al. [21] is very similar to our proposed architecture in
the sense that they also enable simulation of collaborative
vehicles by utilizing high-fidelity models at the physical
level. However, the vehicle coordination protocol is modeled
through timed automata instead of mobile process calculi.
Finally, we remark that some preliminary results of our
work were presented in a news brief [22]. The news brief
primarily argued on the benefits of utilizing π-calculus in
the modeling of collaborative vehicular systems. Here, we
extend upon that announcement by presenting details on the
π-calculus formalism, the low-level control layer, the interaction of high- and low-level layers, and the experimental
results.

II. RELATED WORK
A great deal of effort has gone into proving the safety of
autonomous vehicle systems. Due to the large and diverse
literature, we will present a few works that have inspired
our own approach. The reader can find further references in
the literature discussed below.
Some methods, such as those by Asplund et al. [13], use
formal methods to verify cooperation among autonomous
vehicles. In particular, the authors formalize a distributed
coordination protocol using finite state machines, and they
consider an over-approximation of the vehicles’ dynamics
based on the maximum acceleration of the vehicles. Then,
they utilize Satisfiability Modulo Theory (SMT) solvers to
prove safety of an intersection collision avoidance protocol.
The results cannot be generalized since they apply only to
scenarios where the intersection is a shared resource where
only one vehicle has access at each time.
Lygeros et al. [14] model platooning as a hybrid automaton, and they automatically design control laws for provably
safe merge and split vehicle operations. However, their work
does not look into the formalization of the coordination
layer for the vehicles and instead treats it rather informally.
Our work can be thought of as enabling the modeling of
more complicated communication and control algorithms
on top of or as an extension of the hybrid automaton
models proposed by Lygeros et al. Beyond more complex
coordination protocols that include privacy and security, we
can study for example the behavior of the platoons when
there is an unexpected obstacle on the road.
More recently, Loos et al. [15] apply theorem proving
methods to verify the safety of adaptive cruise controllers.
In particular, they model the case of vehicles with known
bounds on important characteristics (i.e., maximum braking deceleration, maximum acceleration, and worst-case response-time) with cruise-control implementations which pick
an acceleration subject to a special safety condition. Under
that condition, they show that the resulting arbitrarily large
group of vehicles will be collision free. A similar result is
shown by Platzer [16] for the case of vehicles entering a
highway from an on-ramp, where collision-free safety can
be proved under the assumption that vehicles entering the
highway meet a condition based on their position, speed, and
acceleration relative to vehicles on the highway. Although
it is hinted that this framework can capture the effect of
a communication-mediated reconfiguration of the vehicle

III. PRELIMINARIES
In this paper, we model concurrent high-level behavior
of autonomous vehicles with a process algebra known as
π-calculus. This section provides a brief overview of the
algebra along with an extension that is necessary to fully
represent a distributed autonomous system.
A. Process Algebra
Process algebras, or process calculi as they are also
known [23], are a way to algebraically model the interaction
between concurrent systems. They are exceedingly useful
for reasoning about parallel systems and as such allow
for the verification of these systems to determine whether
certain properties hold. For example, if we are considering a
system of autonomous vehicles that are traveling together in
a platoon, then we would like to reason about such a system
and establish that merging behavior protocols never produce
a deadlock.
To this end, we must first establish the notion of a process.
Informally speaking, a process is simply the behavior of
524

a system [23]. Process algebra puts forward the idea that
these behaviors can be modeled as a sequence of actions
over time which can be manipulated with algebraic rules.
As a simple example, consider an abstracted model of a
process for a vehicle that is changing lanes. Given the
actions, enable signal, disable signal, change lane, and
the sequential operator (.) this process can be modeled
as enable signal.change lane.disable signal. This expression means that the observed behavior is to enable the turn
signal, change lanes, and finally disable the turn signal. However, as we describe in more detail in the following section,
the real power of process algebra comes from its ability to
describe the interaction between concurrent systems.

We now introduce more complex constructs into the
syntax, as summarized by the following grammar.
P ::= P | P ||P 0 | P + P 0 | !P 0
P ::= P | (νx)P | x : [y ⇒ P, z ⇒ P ]

In this work, we employ a specific variant of process
algebra known as π-calculus [24], [4]. In its most basic
form, π-calculus defines an expression for a process P ∈ P
as a sequence atomic actions π. The syntax of a process
expression can be described by the following grammar.
(1a)

Semantically, this means that the process P is empty (0)
and thus terminating or is composed of one or more atomic
actions π that execute in sequence and yield another process
expression. Atomic actions in π-calculus are made up of
primitives known as names. As defined in [24], these may
be variables, unobservable actions, communication channels,
or simply data values; there is no distinction between them.
In this work, we make use of communication channels. In
particular, given an infinite set of names N and w, x, y, z ∈
N,
•

•

(1c)

These constructs support the modeling of multiple processes.
In particular,
0
• P = P ||P defines the process P as concurrently
executing P and P 0 .
0
• P = P + P defines the process P as non-deterministically executing either P or P 0 .
0
• P =!P indicates that there are as many concurrently
executing copies of P 0 as desired [4].
• (νx)P indicates the name x is unique to P .
0
• P = x : [y ⇒ P, z ⇒ P ] defines the process P as
resulting in P if the name x is equal to y, or resulting
in P 0 if x is equal to z. Names can also be constants, and
so it is possible define P = x : [True ⇒ P, False ⇒ P 0 ]
for evaluating against True and False.
Now that the syntax and an informal explanation of the
semantics for concurrent processes have been introduced, the
concept of reaction [4] must be discussed. Consider two
processes, P = x(y).P 0 and Q = x<z>.Q0 , and suppose
they are running concurrently, P ||Q. The names x and x are
considered complementary, and the actions are linked; if z
is sent over x by Q, then it will be received by P and bound
to y.
This highlights the importance of the scope restriction
operator, ν. Drawing on an example from Milner [25], let
P (x) = x<y>, Q(x) = x(z), and R(x) = x(w). If the
processes run concurrently as in P (x)||Q(x)||R(x), then
there are two outcomes: either Q receives the message
sent by P , or R does. This is a consequence of all three
processes sharing the same x channel. However, if x is now
restricted as in (νx)(P (x)||Q(x))||R(x) then there is only
one outcome: Q receives the message sent by P along their
shared (and unique) channel x.

B. π-Calculus

P ::= π.P | 0

(1b)
0

Outgoing communication occurs when a name is sent
along out over a channel. The expression P = x<y>
defines P as sending the name y out over x. In this
example, x represents a communication channel to
another process, and P is sending the message y over
that channel.
Incoming communication occurs when a name is received along a channel. The expression P = x(z)
defines P as receiving the name z from x. Similar to
the previous example, x represents a communication
channel to another process, and P receives a message
on that channel which gets bound to the name z.

C. ω-Calculus
This work also makes use of ω-calculus [7], an extension
to π-calculus that introduced semantics for reasoning about
mobile ad hoc wireless networks. It is a particularly useful
extension when dealing with distributed robotic systems that
must form ad hoc networks in order to establish communication. We draw from two operations that have been previously
introduced in ω-calculus:
• b<x> broadcasts the message x to any recipient in
transmission range.
• r(y) receives a message that has been broadcasted and
binds it to y.

In addition, process expressions may take a parametric form.
For example, P (x) = x<y> is a parametric definition of
process P . When P is referenced, it must be passed a name.
If we have the expression w(z).P (z), a message is received
over channel w that gets bound to z and is then passed to P .
In this context, z must be another communication channel
itself because P immediately uses it to send message y. This
ability to transmit and receive communication channels is an
important concept in π-calculus and is referred to as mobility.
Furthermore, π-calculus may be extended to accommodate
multiple parameters; this is known as polyadic π-calculus [4].

IV. METHODOLOGY
As previously discussed, autonomous vehicle platoons are
a tantalizing goal due to the inherent benefits they bring
in the form of increased road capacity and reduced energy
usage [1], [2]. However, designing such a system is not a
525

Supervisor A
(π-calculus)

Supervisor B
(π-calculus)

A

A
Interface
Comm

Control

Interface
Comm

C

d

B

Control

(a) Initial A–B spacing

Plant

Plant

l C

2d+l
B

(b) After space is created for C

Fig. 2: Expected spacing behavior of vehicle convoy.

Fig. 1: Organization of two concurrent vehicle processes.
distance of d, making explicit knowledge of l unnecessary.
In this work, we define separate behaviors for three different scenarios: a leader of a platoon (Leader), a follower in a
platoon (Follower), and a vehicle joining a platoon (Joiner).
These are the behaviors exhibited by vehicles A, B, and
C, respectively, in Fig. 2. It is also possible for vehicles to
transition between behaviors. For example, a vehicle joining
a platoon will become a Follower once it has fully merged.
At the highest level, the system modeled in Fig. 2 can be
represented as a π-calculus expression. Let A = Leader,
B = F ollower, and C = Joiner. This system is then
described by A||B||C. Each of these behaviors will now be
described in terms of a π-calculus expression.
At the beginning of this section, it was stated that an
interface layer is utilized by the behaviors to exert control
over the underlying continuous system. The interface layer
is defined as a concurrently executing π-calculus process.
This process listens for messages over a predetermined set of
communication channels, performs low-level processing, and
in some cases replies with a message. Although this communication is considered atomic to π-calculus expressions, this
will not be the case with respect to the low-level continuous
layer. In particular, some actions take considerable time to
execute and may wait until certain conditions unknown to the
high-level layer are satisfied. The following communication
channels are provided in the interface layer.
• get id gets the identification of the vehicle. If B in
Fig. 2a calls get id, it will return B.
• get ldr gets the leader of the vehicle. As an example,
if B in Fig. 2a calls get ldr, it will return A.
• set ldr sets the leader of the vehicle to the vehicle with
the given identification.
• drive tells the vehicle to drive forward with respect to
the road geometry.
• keep dist maintains a safe following distance d from
the current leader.
• check join checks whether the vehicle with the given
identification occupies the position where this vehicle
wants to join. For example, if C in Fig. 2a invokes
check join on B, it will return positive. In this case
study, the positions at which vehicles join are predetermined for demonstration purposes. In future work, this

simple endeavor. In order to scale effectively over a large
number of vehicles, this distributed platoon system should
have decentralized control. Additionally, the benefits and
stability of a platoon are increased if the vehicles remain
in communication with each other [14]. As autonomous
vehicles are safety-critical systems, the behavior that governs
any such vehicle platoon must be verified to ensure no unforeseen dangerous scenarios can arise. Further complicating
matters, autonomous vehicles are not homogeneous systems;
each vehicle will have varying physical characteristics. Our
work tackles these issues by dividing the problem into two
non-overlapping parts: a high-level discrete-logic layer that
describes the overall behavior of the autonomous vehicles,
and a low-level physical layer that describes the closed-loop
dynamics of the underlying system. Interaction occurs in the
form of an interface provided by the low-level layer through
which the high-level layer can send signals. This organization
is shown in Fig. 1. The following sections describe these
layers in more detail.
A. High-level Layer
The high-level layer must be capable of satisfying three
conditions: it must be able to model the protocols of a
distributed multi-vehicle system, it must be able to model
communication between vehicles, and it must be amenable to
verification processes for safety-critical systems. As it turns
out, π-calculus meets these three conditions and is used to
model the high-level behavior in this work. First, however,
we must establish the expected platoon behavior.
Figure 2a depicts a simple platoon of two vehicles. The
vehicle labeled A is the leader of this platoon and the vehicle
labeled B is following A at a minimum safe distance d. A
third vehicle, C, is outside of the platoon in a separate lane.
Suppose C wishes to join the platoon and that the optimal
place to do so is between A and B. Before C is permitted
to join, the distance between A and B must be increased
to 2d + l, where l is the length of C as shown in Fig. 2b.
This action ensures that the minimum safe distance is always
respected. This behavior can be further simplified by letting
C follow A at distance of d while B also follows C at a
526

A
d

D

A

A

B
d

D

x

B

C

D

y1

B

y2

x

d

d
D

C

A

A

B

C

d
D
d
(c) Distance created

d

Process 2 Follower

C
(d) Merge complete

1:
2:
3:

Fig. 3: Expected merge behavior of vehicle platoon.

4:
5:
6:
7:
8:
9:

will be replaced by an algorithm which decides where
each vehicle should join.
• align start causes the interface to trigger the
align done event action when the vehicle is d distance
from the current leader.
• merge start causes the interface to trigger the
merge done event action when the vehicle has finished
merging into the current leader’s lane.
Additionally, recursive expressions are only allowed to execute at most once per sampling period.
The behavior descriptions that follow refer to the system
depicted in Fig. 3. A, B, and C are initially in a platoon of
which A is the Leader and B and C are Followers. D is a
Joiner external to the platoon.
1) Leader (from [22]): The behavior of a platoon Leader
is straightforward in this scenario: it simply drives forward
indefinitely. The associated process expression in Proc. 1
invokes the interface action drive and repeats this action
indefinitely. For the purposes of this paper, only straight
roads are considered. However, this is easily extended to
curved roads if lane-keeping is incorporated into the Leader.

Wait(y) = y.merge done
Align(y) = align start.align done.y.Wait(y)
Rcv Ldr(y, ldr) = y(nldr).set ldr<nldr>.Align(y)
Send Ldr(y) = get ldr(ldr).y<ldr>.Rcv Ldr(y, ldr)
Respond(y, f lag) = f lag : [T rue ⇒ Send Ldr(y)]
Ident(y) = get id(id).y<id>.y(f lag).Respond(y, f lag)
Cooperate=!r(x).(νy)(x<y>.Ident(y))
Follow= keep dist.Follow
Follower= Follow||Cooperate

The Cooperate expression demonstrates π-calculus’s ability to dynamically reconfigure itself, which is an example
of the mobility property. When a vehicle wishes to join a
platoon, it creates a communication channel x and broadcasts
it to every vehicle within range in Line 8 of Proc. 3. This
establishes a common communication channel connecting
the Joiner and every Follower. However, this is not a unique
channel; any message sent on x can be received by every
Follower. This is not ideal, so unique channels are created
in Line 7 of Proc. 2, resulting in a reconfiguration of the
network as shown in Fig. 4.
These communication channels are then used to synchronize the joining process. In Line 6 of Proc. 2, the Follower
transmits its own identifier to the joining vehicle so that it
can decide whether to join at the Follower’s position. If this
is the case, the Respond expression (Line 5) will continue to
Send Ldr and transmit the vehicle preceding the Follower to
the Joiner. This enables the joining vehicle to position itself
next to the Follower so that it is ready to merge over as
shown in Fig. 3b. When the joining vehicle is in position,

Process 1 Leader
1:

(c) After Respond

2) Follower (from [22]): The behavior of a Follower in
a platoon is much more involved as it must simultaneously
follow its leader while cooperating with vehicles who wish to
join the platoon. This is modeled by the concurrent execution
of Follow and Cooperate in the Follower state in Proc. 2,
which corresponds with the initial state in Fig. 3a.

d

C

C

d
B

D

B

Fig. 4: Process graph depicting communication network
during various points of execution. Cooperate and Respond
refer to Lines 7 and 5 of Proc. 2 respectively. A, B, C, and
D correspond to the vehicles in Fig. 3.

(b) Joiner D in position

d

D
y2

(a) During Cooperate (b) After Cooperate
(a) Initial state

A

d

B

C

A

Leader= drive.Leader

527

the Follower sets the Joiner as its new preceding vehicle in
Line 3 of Proc. 2. This causes the Follower to increase its
distance to d from the joining vehicle due to the concurrently
executing Follow expression. This is depicted in Fig. 3c.
Lastly, the joining vehicle is signaled to merge, which results
in Fig. 3d.
3) Joiner: The behavior of a Joiner is given in Proc. 3.
Until a decision to join is made by the high-level layer,
the joining vehicle drives forward with respect to the road
geometry. Following this, the Joiner broadcasts its intention
to join the platoon in Line 8 of Proc. 3. The interaction
with Followers during the joining process has already been
described; however, the decision of where to join in a platoon
is handled by communication with the interface layer’s
check join channel in the Check expression (Line 6). Once
the Joiner has merged into the platoon, it transitions to a
Follower as the last action in the Merge expression (Line 1).

•
•

distx (t, L) returns the distance along the x-axis to
vehicle L at time t.
disty (t, L) returns the distance along the y-axis to the
center of the lane currently occupied by vehicle L at
time t. Currently platoons are not allowed to switch
lanes so that discontinuities in this distance are avoided.

With these signals and functions, we can define each of the
vehicle behaviors.
1) Leader: The Leader automaton simply remains in a
drive state. No transitions are supported and no input or
output signals are accepted.
2) Follower: The Follower automaton requires the input
signal align start to create longitudinal space in front of
the vehicle when a merge has been requested. This is
accomplished by a change in leader L, which coincides
with a set ldr call in the high-level layer. However, only fy
respects the change in leader; fx continues to be a function
of the previous leader, L0 . This is so the vehicle does not
sway in its lane attempting to position itself laterally behind a
Process 3 Joiner
vehicle that is changing lanes. When the merge done signal
1: Merge(y) = merge start.merge done.y.Follower
is received, L is respected on both axes.
2: Wait(y) = get id(id).y<id>.y.Merge(y)
3) Joiner: Similarly, the Joiner automaton requires the
3: Align(y) = align start.align done.Wait(y)
input signal align start to position itself behind the vehicle
4: Rcv Ldr(y) = y(ldr).set ldr < ldr > .Align(y)
it will be following once the merge is completed. However,
5: Ans(y, ok) = y<ok>.ok : [T rue ⇒ Rcv Ldr(y)]
the x-axis does not respect its new leader, L, until the
6: Check(y, id) = (νz)(check join<z, id>.z(ok).Ans(y, ok))merge start signal is received – indicating that the Follower
7: Listen(x) = x(y).y(id).Check(y, id)
vehicle is finished aligning itself to this vehicle.
8: Joiner= (νx)(b<x>||!Listen(x))
In practice, these automata are implemented as digital
controllers that receive input signals from the high-level layer
via an interface as described in Section IV-A. The advantage
of this setup is that the controllers and vehicle dynamics can
B. Low-level Layer
The low-level layer can be modeled as a series of hybrid be swapped out for any implementation as long as it fulfills
automata [5] in order to describe the behavior of the con- the required interface. As an illustrative example, consider
troller and plant from Fig. 1. Each behavior – Leader, Fol- a scenario in which the high-level behavior described in the
lower, and Joiner – has its own hybrid automaton as shown in previous section has been adopted as an automobile industry
Fig. 5. Interaction with the high-level layer takes place in the standard. Each vehicle manufacturer can then supply a lowform of input and output messages that directly correspond level layer for controlling its vehicle without having to reto communication channels provided by the interface. We verify the behavior protocol.
now formally define these signals with respect to the hybrid
automata. Let N denote the set of natural numbers, then we
define:

V. EXPERIMENTS
Simulation is an important step in the analysis and verification of autonomous vehicle platoons, as the closed-loop
dynamics are a fundamental part of the system. Without
simulation, the dynamics are not validated, and much of the
problem is left unsolved. To that end, we have developed a
simulation framework which ties together the high-level and
low-level layers discussed in this paper and places them in
control of automobiles in the Webots 8.3 robotics simulator [26]. A simulation environment, π-calculus behaviors,
and vehicle control models are provided as inputs. The
framework parses the behaviors and generates executable
code which handles all necessary communication and interaction as defined by the π-calculus expressions. Two types of
environments were tested: a homogeneous platoon consisting
of vehicles with identical physical characteristics and controllers, and a heterogeneous platoon with varying physical

S1 : {align start, align done} → {absent, present}
S2 : {merge start, merge done} → {absent, present}
S3 : {L, L0 } → N
Additionally, the following functions are defined. Let the xaxis lie parallel to the front of the vehicle and the y-axis lie
perpendicular to that.
• gy (y)/gx (x) computes ẏ/ẋ given the current y/x position while taking into account road geometry. In most
cases, this is equivalent to driving forward at a constant
velocity.
• fy (y, α)/fx (x, α) computes ẏ/ẋ given the current y/x
position and a distance α with the objective of reducing
α to the minimum safe following distance d.
528

Follow
L := ldr

ẋ = fx (x, distx (t, L))
ẏ = fy (y, disty (t, L))
align start/L0 := ldr, L := nldr

merge done/

Drive

MergeStart

ẋ = gx (x)
ẏ = gy (y)

ẋ = fx (x, distx (t, L))
ẏ = fy (y, disty (t, L0 ))

|distx (t, L) − dx | < x /align done

ẋ = fx (x, distx (t, L))
ẏ = fy (y, disty (t, L0 ))

(a) Leader HA
Drive
ẋ = gx (x)
ẏ = gy (y)

MakeSpace

(b) Follower HA
align start/L := ldr

InitiateJoin

WaitForSpace

|distx (t, L) − dx | < x /align done

ẋ = fx (x, distx (t, L))
ẏ = gy (y)

ẋ = fx (x, distx (t, L))
ẏ = gy (y)

merge start/

Merge

|disty (t, L) − dy | < y /merge done
Follower

ẋ = fx (x, distx (t, L))
ẏ = fy (y, disty (t, L))

(c) Joiner HA

Fig. 5: Hybrid automata for the low-level layer. Each automaton receives input signals from the high-level layer and sends
output signals. (a) No inputs/outputs. (b) Inputs: align start, merge done Outputs: align done (c) Inputs: align start,
merge start Outputs: align done, merge done
characteristics and differing controllers. The behavior of
vehicles in these simulations is shown in Fig. 6.

toon; however, this time the vehicles were of varying models
(included in Webots). Four automobiles were modeled after
the BMW X5, three after the Citroen C-Zero, and two
after the Toyota Prius. Additionally, three of the vehicles
used the PID controller from the homogeneous platoon
experiment while the remaining six used a model predictive
controller designed for such scenarios with some minor
modifications [27]. We vary the reference velocity based
on the current tracking error, which is similar to previous
work [28]. In addition we modify the cost parameters, Q and
R of the controller, so that the weight given to the reference
velocity and distance varies based on the error. Once again,
all vehicles successfully merged into the platoon without
incident.
However, similar to the PID controller in the first experimental simulation, this model predictive controller is
not meant to be optimal nor even provide guarantees of
stability. Rather its primary purpose is to show that our
framework can not only effectively represent interactions
between heterogeneous vehicles, but that those vehicles can
use dramatically different control schemes.

A. Homogeneous Platoon
In the first experimental simulation scenario, four independent vehicles attempted to join a five-vehicle platoon.
All automobiles were modeled after the Toyota Prius (model
included in Webots) with identical physical characteristics
and identical manually tuned PID controllers. The controllers
generate throttle and brake inputs for the plant (simulated
vehicle) and track a target following distance from the vehicle which is being followed. The controllers are not meant
to be robust nor optimal, rather they are a simple example
of how this framework can be used to control continuous
systems. Localization is achieved by means of each vehicle
broadcasting out its current position at every simulation step.
While not practical in the real world, this is adequate for
this simulation as accurately identifying other vehicles and
their positions is a challenging task. The distance functions,
distx and disty , make use of these broadcasted positions in
addition to a forward-facing laser sensor for redundancy. All
vehicles eventually successfully merge into the platoon in a
distributed and decentralized manner.

VI. CONCLUSIONS

B. Heterogeneous Platoon

In this paper, we have introduced a new framework which
utilizes π-calculus to model complex vehicular networks.
This framework allows for the effective modeling of both

The second experimental scenario again consisted of four
independent vehicles attempting to join a five-vehicle pla529

(a) Initial state

(b) Joiner in position

(c) Distance created

(d) Merge complete

[9] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan, “S-TaLiRo: A tool for temporal logic falsification for
hybrid systems,” in Tools and Algorithms for the Construction and
Analysis of Systems, ser. LNCS, vol. 6605. Springer, 2011, pp. 254–
257.
[10] J. Kim and I. Lee, “Modular code generation from hybrid automata
based on data dependency,” in Real-Time and Embedded Technology
and Applications Symposium, 2003. Proceedings. The 9th IEEE.
IEEE, 2003, pp. 160–168.
[11] M. Althoff, D. Althoff, D. Wollherr, and M. Buss, “Safety verification
of autonomous vehicles for coordinated evasive maneuvers,” in IEEE
Intelligent Vehicles Symposium, 2010.
[12] W. Damm, A. Mikschl, J. Oehlerking, E.-R. Olderog, J. Pang,
A. Platzer, M. Segelken, and B. Wirtz, “Automating verification of
cooperation, control, and design in traffic applications,” in Formal
Methods and Hybrid Real-Time Systems, ser. LNCS, C. B. Jones,
Z. Liu, and J. Woodcock, Eds. Springer, 2007, vol. 4700, pp. 115–
169.
[13] M. Asplund, A. Manzoor, M. Bouroche, S. Clarke, and V. Cahill, “A
formal approach to autonomous vehicle coordination,” in FM 2012:
Formal Methods. Springer, 2012, pp. 52–67.
[14] J. Lygeros, D. N. Godbole, and S. Sastry, “Verified hybrid controllers
for automated vehicles,” IEEE Transactions on Automatic Control,
vol. 43, no. 4, pp. 522–539, 1998.
[15] S. M. Loos, A. Platzer, and L. Nistor, “Adaptive cruise control: Hybrid,
distributed, and now formally verified,” in FM 2011: Formal Methods.
Springer, 2011, pp. 42–56.
[16] A. Platzer, “A complete axiomatization of quantified differential
dynamic logic for distributed hybrid systems,” Logical Methods in
Computer Science, vol. 8, no. 4, 2012.
[17] M. Fränzle, M. R. Hansen, and H. Ody, “No need knowing numerous
neighbours,” in Correct System Design. Springer, 2015, pp. 152–171.
[18] M. Hilscher, S. Linker, E.-R. Olderog, and A. P. Ravn, “An abstract
model for proving safety of multi-lane traffic manoeuvres,” in Formal
Methods and Software Engineering. Springer, 2011, pp. 404–419.
[19] G. v. Bochmann, M. Hilscher, S. Linker, and E.-R. Olderog, “Synthesizing controllers for multi-lane traffic maneuvers,” in Dependable
Software Engineering: Theories, Tools, and Applications. Springer,
2015, pp. 71–86.
[20] H. H. Bengtsson, L. Chen, A. Voronov, and C. Englund, “Interaction
protocol for highway platoon merge,” in Proceedings of the 2015 IEEE
18th International Conference on Intelligent Transportation Systems.
IEEE, 2015, pp. 1971–1976.
[21] M. Kamali, L. A. Dennis, O. McAree, M. Fisher, and S. M.
Veres, “Formal verification of autonomous vehicle platooning,” arXiv
preprint arXiv:1602.01718, 2016.
[22] J. Campbell, C. E. Tuncali, T. P. Pavlic, and G. Fainekos, “Toward
modeling concurrency and reconfiguration in vehicular systems,” in
9th Interaction and Concurrency Experience, Satellite Workshop of
DisCoTec 2016, 2016.
[23] J. C. Baeten, “A brief history of process algebra,” Theoretical Computer Science, vol. 335, no. 2, pp. 131–146, 2005.
[24] R. Milner, J. Parrow, and D. Walker, “A calculus of mobile processes,
I,” Information and Computation, vol. 100, no. 1, pp. 1–40, 1992.
[25] R. Milner, “The polyadic π-calculus: a tutorial,” in Logic and Algebra
of Specification, ser. NATO ASI Series, F. L. Bauer, W. Brauer, and
H. Schwichtenberg, Eds. Springer, 1993, vol. 94, pp. 203–246.
[26] Webots, “http://www.cyberbotics.com,” commercial Mobile Robot
Simulation Software. [Online]. Available: http://www.cyberbotics.com
[27] P. Liu and U. Ozguner, “Predictive control of a vehicle convoy considering lane change behavior of the preceding vehicle,” in Proceedings
of the 2015 American Control Conference. IEEE, 2015, pp. 4374–
4379.
[28] D. N. Godbole and J. Lygeros, “Longitudinal control of the lead car
of a platoon,” Vehicular Technology, IEEE Transactions on, vol. 43,
no. 4, pp. 1125–1135, 1994.

Fig. 6: Actual merge behavior of vehicle platoon.

high-level decision-making protocols and low-level vehicle
dynamics, laying the groundwork for future verification of
these systems. In order to demonstrate the utility of this
framework, we have modeled a decentralized platooning protocol with heterogeneous vehicles and controllers. In future
work, we will formally verify complex systems modeled with
this framework.
R EFERENCES
[1] M. Zabat, N. Stabile, S. Farascaroli, and F. Browand, “The aerodynamic performance of platoons: A final report,” California Partners for
Advanced Transit and Highways (PATH), Tech. Rep. UCB-ITS-PRR95-35, 1995.
[2] B. Rao and P. Varaiya, “Flow benefits of autonomous intelligent cruise
control in mixed manual and automated traffic,” in Intelligent Vehicle
Highway Systems. National Academy Press, 1993, no. 1408, pp.
36–43.
[3] A. Colombo and D. Del Vecchio, “Efficient algorithms for collision
avoidance at intersections,” in Proceedings of the 15th ACM International Conference on Hybrid Systems: Computation and Control,
2012.
[4] R. Milner, Communicating and Mobile Systems: the π Calculus.
Cambridge University Press, 1999.
[5] R. Alur, Principles of Cyber-Physical Systems. MIT Press, 2015.
[6] S. Delaune, M. Ryan, and B. Smyth, “Automatic verification of privacy
properties in the applied pi calculus,” in Trust Management II, ser. IFIP,
Y. Karabulut, J. Mitchell, P. Herrmann, and C. D. Jensen, Eds., vol.
263. Springer, 2008, pp. 263–278.
[7] A. Singh, C. Ramakrishnan, and S. A. Smolka, “A process calculus for
mobile ad hoc networks,” Science of Computer Programming, vol. 75,
no. 6, pp. 440–469, 2010.
[8] G. Frehse, C. L. Guernic, A. Donz, S. Cotton, R. Ray, O. Lebeltel,
R. Ripado, A. Girard, T. Dang, and O. Maler, “Spaceex: Scalable verification of hybrid systems,” in Proceedings of the 23rd International
Conference on Computer Aided Verification, 2011.

530

Fiftieth Annual Allerton Conference
Allerton House, UIUC, Illinois, USA
October 1 - 5, 2012

Convergence Proofs for Simulated Annealing Falsification of Safety
Properties*
Houssam Abbas1 and Georgios Fainekos2
Abstract— The problem of falsifying temporal logic properties of hybrid automata can be posed as a minimization problem
by utilizing quantitative semantics for temporal logics. Previous
work has used a variation of Simulated Annealing (SA) to solve
the problem. While SA is known to converge to the global
minimum of a continuous objective function over a closed and
bounded search space, or when the search space is discrete,
there do not exist convergence proofs for the cases addressed
in that previous work. Namely, when the objective function
is discontinuous, and when the objective is a vector-valued
function. In this paper, we derive conditions and we prove
convergence of SA to a global minimum in both scenarios.
We also consider matters affecting the practical performance
of SA.

I. I NTRODUCTION
One of the major challenges in the model-based development of Cyber-Physical Systems (CPS) is how to automatically verify the correctness of a CPS model with respect to
some formal specification. The proliferation of embedded
computers in a multitude of safety critical systems and
the well documented cases of CPS system failures due to
software-physical system interactions [1], [2] demonstrate
the urgency and the importance of the problem. However,
it is well known [3] that the verification problem of CPS is
undecidable, in general. Therefore, a lot of research effort
has been focused on testing-based methodologies [4]–[13].
In previous work [14]–[16], a notion of robustness of
temporal logics [17] is utilized as a cost function in order to
convert the temporal logic falsification problem of CPS into
an optimization problem. In detail, the robust semantics of
a temporal logic formula over a CPS trajectory evaluate to
a positive value if the trajectory satisfies the specification
and to a negative value otherwise. Thus, we can convert
the falsification problem into a minimization problem of the
specification robustness over the set of all system trajectories.
In general, the resulting optimization problem is non-convex
and non-linear and the search space is uncountable. Thus, in
[14]–[16], a number of stochastic heuristic search techniques
were employed in order to solve the minimization problem
with very promising results. In particular, in [14], a version
of Simulated Annealing (SA) [18], [19] was utilized and a
new SA heuristic for the minimization of a particular class
*This work was partially supported by NSF awards CNS-1017074 and
CNS-1116136.
1 H. Abbas is with the Department of Electrical, Computer and Energy
Engineering, Arizona State University, Tempe, AZ, USA hyabbas at

asu.edu
2 G. Fainekos is with the Department of Computing, Informatics and
Decision Systems Engineering, Arizona State University, Tempe, AZ, USA

fainekos at asu.edu

978-1-4673-4539-2/12/$31.00 ©2012 IEEE

of vector functions was also proposed. For the former, it was
claimed that under the assumption of a finite search space1
we can guarantee convergence of SA to the global minimum
and, thus, guarantee the solution of the original falsification
problem. The convergence of the SA algorithm for vector
functions was left as an open problem.
In this paper, we lift the assumption of the finite search
space and we answer the question of what classes of CPS
and under what conditions we can guarantee the convergence
of SA to the global minimum. Furthermore, we derive
conditions so that the SA algorithm over vector functions
converges to the global minimum, as well. In brief, we prove
that if a CPS is simulatable [20], then the SA algorithms are
guaranteed to converge to the global minimum if the global
minimum does not belong to an equivalence class of measure
zero. The results in this paper are important because they
help us understand the practical and theoretical limitations
of the application of SA to the falsification problem of CPS.
While they are presented for safety requirements due to space
constraints, they can easily be extended to general temporal
logic formulae.
Notation. µ(·) denotes the Lebesgue measure. k · k is the
Euclidean distance, and B (x) = {y ∈ Rd | ky − xk < }.
R≥0 = [0, ∞) and N≥0 = R≥0 ∩ N. ‘Discrete set’ will mean
a finite or countably infinite set. For a set X, P(X) is the
set of all subsets of X.
II. P ROBLEM FORMULATION
A. Falsification of safety properties of hybrid automata
We now introduce the practical setting in which the above
two algorithms are applied, and all theorems are proven. We
stress that we prove the correctness of the SA algorithms
when applied to this practical problem. We consider a
deterministic, non-Zeno2 hybrid automaton [21]
H = (L, X, F low, Init, Inv, E, G, Re)
where L = {`0 , `1 , . . .} ⊂ N is a countable set of ‘locations’,
X ⊂ Rd is the continuous state space, F low : L × X → X
is a vector field describing the continuous evolution of a
trajectory at (`, x), Init ⊂ X is the set of initial continuous
conditions, Inv : L → P(X) associates an invariant set
of F low(`, ·) to each location `, E ⊂ L × L describes the
possible jumps between locations (i.e. (`i , `j ) ∈ E iff there
1 Any compact set of initial conditions and/or other search parameters is
going to be discretized to a finite set of floating-point numbers.
2 An automaton is Zeno if it has trajectories that perform an infinite
number of discrete jumps in a finite amount of time. This is an artifact
of the modeling, and can not happen in reality.

1594

exists a trajectory of the system that visits `i then `j without
visiting any other location in-between), G : E → P(X)
defines guard conditions that cause jumps, and Re : E×X →
X is the reset map which resets the continuous state with
every jump. H = L × X is the ‘state-space’ of H. In this
paper we consider automata for which Init ⊂ Inv(`0 ) so
the initial set H0 = {`0 } × Init.
Given an initial state h = (`0 , x) ∈ H0 , the hybrid
trajectory that starts there is a vector function ηh : [0, ∞) →
H which associates a pair (location, continuous state) to each
point in time: ηh (t) = (`(t), s(x, t)) where s(x, t) is the
continuous state at time t and `(t) is the location of s(x, t).
loc(h) = (`0 , `1 , . . .) is the list of locations visited by ηh ,
with no repetitions. At the time of the j th jump time tj ,
say between locations i and k, ηh (tj ) is actually set-valued:
ηh (tj ) = {(i, tj ), (k, tj )}. Because there is no ambiguity
about `0 , η(`0 ,x) and loc(`0 , x) will also be denoted by ηx
and loc(x) respectively.
We are given a safety property φ of the automaton, and
the set U ⊆ X of states that violate φ. To falsify φ means to
find an initial state h0 ∈ H0 such that the trajectory ηh0 that
starts there enters the unsafe set U. Here we only consider
trajectories of finite duration D < ∞. With non-Zenoness,
this implies that loc(x) is always finite, even if L is countably
infinite. L models the discrete variables of the automaton so
the range of each xi is not a discrete set3 . We will need the
following definitions [14]:
Definition 1 (Discrete distances): lU is the location of the
unsafe set U. Let G = (L, E) be the graph with vertex set L
and edge set E. The discrete distance π(`, `0 ) between the
two locations ` and `0 is the length of the shortest path in
G between the locations. Given x ∈ Init and the trajectory
ηx , `(x) is the location visited by ηx that is closest to `U ,
and k(x) the corresponding distance:
`(x) = argmin`∈loc(x) π(`, `U )
k(x) = min`∈loc(x) π(`, `U ) = π(`(x), `U )
Definition 2 (Continuous distances): For x
∈
X,
dU (x) = inf y∈U kx − yk is the distance between x and the
set U. Given (`, x) ∈ H, r(x) = mint≤D dZ (s(x, t)), where
Z is either U if `U ∈ loc(x) (trajectory enters the location
of U), otherwise it is the guard leading to `0 , where `0 is
the next location in a shortest path in G from ` to `U .
Definition 3 (Robustness): Given a trajectory ηx , its robustness is V (x) , (k(x), r(x)). This is the smallest
‘distance’ between the trajectory and the unsafe set U (note
this isn’t a distance in the mathematical sense of the word).
The robustness time t(x) is the time when trajectory ηx is
closest to U: `(x) = `(t(x)) and r(x) = dZ (s(x, t(x)).
Finding an x0 that produces an unsafe trajectory (one that
enters U) can be achieved by finding the automaton’s trajectory with smallest robustness. Because only one initial
location is possible (namely, `0 ), the search for a minimum
3 If x is a discrete state variable taking values in Q ⊂ Z, then L can
i
i
be augmented to L0 = L × Qi : every jump in the value of xi can then be
modeled as a change of locations in the extended set L0 . The continuous
dynamics are unaffected.

robustness-trajectory is to be carried over the initial set Init.
The minimization problems treated in this paper are then:
Problem 1: For a dynamical system (with only one location, L = {`0 })
D = Init, R = R
V (x) = min dU (s(t; x))
t≤D

(1)

min V (x)
x∈D

Problem 2: For a hybrid automaton:
D = Init, R = Z × R
V (x) = (k(x), r(x))

(2)

min V (x)
x∈D

B. Simulators of hybrid automata
Simulated Annealing (which will be formally defined in
the next section) requires the ability to evaluate V at any
point of the search space: this evaluation requires the simulation of a system trajectory starting at that point. A hybrid
system simulator Hs , which is necessarily a discretization
of the real system H, must be accurate, in the sense that
for every simulated trajectory (generated by the simulator)
starting at some xs ∈ Inits , there is an arbitrarily close
real system trajectory (generated by H) starting at x ∈ Init
(Inits is the discretization of Init).
Not every hybrid system admits an accurate simulator.
In [20] sufficient conditions are given on H and Hs for
Hs to be an accurate simulator of H. The details of these
conditions are given in the appendix. The following is a
direct consequence of [20, Theorem 3.4]:
Proposition 1: Let H be a hybrid automaton, and let P
be the partition of Init induced by the equivalence relation
x ≡ x0 iff loc(x) = loc(x0 ). Let S ∈ P be a part such
that µ(S) 6= 0. If H satisfies the conditions for accurate
simulation over S, then for any x0 ∈ S and every  > 0, there
exists δ > 0 with the following property: for every trajectory
ηx (·) with initial point x in Bδ (x0 ) ∩ S, and every t < D,
there exists t0 such that |t − t0 | < , s(x, t0 ) and s(x0 , t) are
in the same location, and ks(x, t0 ) − s(x0 , t)k < .
III. S IMULATED A NNEALING
Simulated Annealing (SA) is a well-known iterative
stochastic algorithm for global optimization. We are given
an objective function V with domain D ⊂ Rd and range R.
D is known as the state space. The objective is to minimize
V.
We are given a Markov kernel R(·, ·) on (D, B) where B
is the Borel sigma field on D. This is called the transition
Markov kernel. Thus for each x in D, R(x, ·) is a probability
measure on (D, B), and for each B ∈ B, R(·, B) is a
measurable function. We are also given a cooling schedule
(τ0 , τ1 , . . .) on (D, B): this is a sequence of (possibly random) positive numbers.

1595

A. Traditional SA
d

In traditional SA, D ⊂ R and R ⊂ R. SA constructs
iteratively a sequence of states (xi ) ∈ D, a sequence of
candidate points (yi ) ∈ D, and a sequence of temperatures
(τi ) ∈ R>0 , as follows: an initial state x0 and an initial
temperature τ0 are given. Having constructed the sequences
(x1 , x2 , . . . , xk ), (y1 , y2 , . . . , yk ), and (τ1 , τ2 , . . . , τk ), a next
candidate point yk+1 is selected according to the probability
distribution R(xk , ·). The next state xk+1 is set
(
yk+1 with probability p(xk , yk+1 , τk )
xk+1 =
xk
with probability 1 − p(xk , yk+1 , τk )
where
V (y) − V (x)
]}
(3)
τ
p(x, y, t) is referred to as the acceptance probability. Note
that if V (y) < V (x) (so the candidate improves the value
of the objective function), the candidate is accepted with
certainty.
The following conditions are used in [18] to prove convergence:
• C0. The objective function V is continuous on D.
• C1. The state space D is a bounded closed subset of
Rd .
• C2. There exists an x∗ ∈ D such that V achieves its
minimum at x∗
• C3. Let x∗ be as in C2. For every  > 0, the set {x ∈
D | kx − x∗ k < } = B (x∗ ) ∩ D has positive Lebesgue
measure.
• C4. The selection Markov kernel R is absolutely continuous (with respect to the Lebesgue measure on Rd )
and it has a density which is uniformly bounded away
from 0. That is, R is of the form
Z
R(x, B) =
r(x, y)dy with inf r(x, y) > 0
p(x, y, τ ) = min{1, exp[−

B

x,y∈D

This implies that all of D is reachable from any x ∈ D.
C5. For every open subset B in D, R(x, B) is continuous in x.
• C6. For every choice of initial state x0 and initial
temperature τ0 , the sequence of temperatures (τk )k≥0
converges in probability to 0.
The following theorem is proven in [18]:
Theorem 1: Let x1 , x2 , x3 , . . . be the sequence of states
generated by the SA algorithm with selection Markov kernel
R and with cooling schedule τ . Assume that conditions
C0-C6 hold. Let V∗ denote the global minimum of V on
D. Then, for every choice of initial conditions (x0 , τ0 ),
the sequence of function values (V (xk ))k≥0 converges in
probability to V∗ . That is, ∀ > 0, P r[|V (xk )−V∗ | > ] → 0
as k → ∞.
We now discuss the applicability of conditions C0-C6 to our
hybrid automata:
C0: C0 does not hold for Problem 2, and one contribution of
this paper is to show convergence in the absence of global
continuity. Another contribution is to show that it holds for
•

Problem 1.
C1: The initial state x0 ∈ Init typically models starting
physical parameters of the system, and these are always finite
in magnitude, whence Init is bounded. Closure of Init will
have to be assumed (this is a standard assumption, in both
practice and theory [4], [20], [22], [23]).
C2: It is shown in Section IV that C0 and C1 imply C2, so
it holds for Problem 1. We assume it holds for Problem 2.
C3: We first generalize C3 to hybrid automata in condition
C7:
• C7. Let x∗ be as in C2, and let S∗ ∈ P be the part to
which it belongs. Then µ(Bδ (x∗ ) ∩ S∗ ) > 0 ∀δ > 0.
It is immediate to see that the probability of converging to a
minimum that does not satisfy C7 (such as an isolated point)
is 0. Therefore our results can only claim convergence to
minima that belong to sets of non-zero measure, and this is
captured in C7.
C4-C6: these are properties of the optimization algorithm
rather than of the system. The Hit-and-Run sampler may be
used to satisfy C4 and C5 [14], and the cooling schedule can
be chosen to satisfy C6.
We introduce one more condition on the automaton:
• C8. The hybrid automaton admits an accurate simulator
over Init.
Without this condition, it is not guaranteed that we can draw
conclusions about the real system, based on simulations.
B. SA for minimizing a vector function
We now consider the case R = Z × R, so V (x) =
(V1 (x), V2 (x)) is a vector function. The range of V is
lexicographically ordered: (k, r) ≤ (k 0 , r0 ) iff (k < k 0 )
OR (k = k 0 and r ≤ r0 ). This is a total order, so the
issue of non-dominance [24] does not arise. The resulting
vector SA algorithm, introduced in [14], constructs a sequence of states (xi ) ∈ D, a sequence of candidate points
(yi ) ∈ D, and a sequence of temperatures (τi ) ∈ R>0 ,
as follows: an initial state x0 ∈ D and an initial temperature τ0 > 0 are given. Having constructed the sequences
(x1 , x2 , . . . , xk ), (y1 , y2 , . . . , yk ), and (τ1 , τ2 , . . . , τk ), a next
candidate point yk+1 is selected according to the probability
distribution R(xk , ·). It then computes


Vi (yk+1 ) − Vi (xk )
, i = 1, 2
αi = exp −
τk
u = UniformRandomReal(0, 1)
The next state xk+1 is determined as
• xk+1 = yk+1 if the event A =
(V1 (xk ) = V1 (yk+1 )∧u ≤ α2 )∨(V1 (xk ) 6= V1 (yk+1 )∧
u ≤ α1 ) is true
• and xk+1 = xk otherwise.
The two events on either side of the disjunctive are disjoint.
It comes that the update rule for vector SA is:
(
yk+1 with probability pa (xk , yk+1 , τk )
xk+1 =
xk
with probability 1 − pa (xk , yk+1 , τk )

1596

where
pa (x, y, τ ) = min{1,
2
X

Pr[Vi (yk+1 ) 6= Vi (xk )|u ≤ α3−i ] · α3−i }

i=1

We conclude with a Lemma, used in the later proofs,
which will allow us to forego continuity of V over Init.
It is proved for vector V , which subsumes scalar V as a
special case. The global minimum of V∗ = (k∗ , r∗ ) of V
will be characterized by
k∗ ≤ k(x) ∀x ∈ D
r∗ ≤ r(x) ∀x ∈ {y ∈ D|V1 (y) = k∗ }

special case of Thm.3 presented in the next section. But it is
presented here as a separate result, as a first simple extension
of SA convergence, and to hihglight the role played by the
condition that µ(D ) > 0 for all  > 0.
Theorem 2: Assume that conditions C1,C2,C4-C8 are satisfied. Then SA will converge in probability to the global
minimum of Problem 1.
Proof: The proof proceeds along identical lines to
Belisle’s original proof in [18] and so is not repeated. The
main difference is that V is not continuous over its domain
Init in the present paper. However, Lemma 1 removes the
need for this ’global’ continuity of the objective function,
and may be invoked when proving [18, Lemma 1].

Given  = (1 , 2 ) ∈ N>0 × R>0 , define
V. V ECTOR OBJECTIVE FUNCTION

D = {x ∈ D|V1 (x) ≤ k∗ + 1 and V2 (x) ≤ r∗ + 2 }
= {x ∈ D|V (x) ≤ V∗ + }
Lemma 1: Assume C7, C8. Then it holds that ∀ =
(1 , 2 ) > 0, 0 < µ(D ).
Proof: Fix  = (1 , 2 ) > 0, and consider the optimum
x∗ and its robustness time t∗ = t(x∗ ). By C8 and Prop.1,
∃δ2 > 0 s.t. the image of Bδ2 (x∗ ) ∩ S∗ , Bδ2 under
the hybrid dynamics at time t∗ is a set of points that are
at least 2 -close to s(x∗ , t∗ ). Moreover, all trajectories ηy
starting in Bδ2 follow the same sequence of locations as ηx∗ ;
in particular, they all visit the location l(x∗ ) and therefore
have k(y) = k(x∗ ). So |k(y) − k(x∗ )| < 1 . We know that
µ(Bδ2 ) > 0 by condition C7. Recognizing that Bδ2 ⊂ D
proves the lemma.
Optimizing a vector function. One popular way to optimize
a vector objective function is to map its output V (x) = (k, r)
to scalars in R (e.g. [25]), e.g. using the inverse logit function
with a > 0
Ya : (k, r) 7→ k + 2 [2 exp(r/a)/(1 + exp(r/a)) − 1]
Ya maps Z × R to {z + b | z ∈ Z, b ∈ (−1, 1)}. It is strictly
increasing, so the global minima of Ya ◦ V are the same as
the global minima of V . However, it faces the ‘saturation’
effect for large absolute values of r (and fixed k): differences
between Ya values become insignificant at these extremes,
thus not providing the optimizer with enough guidance. This
problem is exacerbated in a practical implementation, which
will discretize Ya , because the the discretized inverse logit is
no longer strictly increasing. This means the global minima
of Y˜a ◦ V are no longer the same as those of V .
In section IV, it is shown that traditional SA converges
when solving Problem 1. In section V, it is shown that
vector SA converges when solving Problem 2. Throughout,
any mention of a global minimum refers to a minimum that
satisfies all needed conditions, which will be explicated.
IV. T RADITIONAL SA FOR A DYNAMICAL SYSTEM
Our first result states that traditional SA converges to
the global minimum V∗ when solving Problem 1. Recall
that Problem 1 deals with automata with one location, so
there are no guards or resets. This result may be seen as a

In this section we prove the convergence of vector SA
when solving Problem 2. The novelty is that this SA algorithm deals with a multi-objective function V (x) = (k, r) ∈
N × R, and the objective is no longer continuous on D.
The proof is a variation on Belisle’s proof [18]. Some of
the definitions need to be appropriately modified to account
for the new objective function. The following theorem is
proven next.
Theorem 3: Let x1 , x2 , . . . be the sequence of states generated by vector SA when solving Problem 2. Assume that
conditions C1,C2,C4-C8 hold. Let V∗ denote the global
minimum of V on D. Then, for any pair of initial conditions
(x0 , τ0 ), the sequence of function values (V (xk )), k ≥ 0,
converges in probability to V∗ .
Since V is a vector function, all expressions are understood to apply in a component-wise fashion, e.g. |V (x)| > 0
iff |V1 (x)| > 0 and |V2 (x)| > 0.
We will show that for every x0 ∈ D, t0 > 0,  > 0 and
δ > 0 there exists an integer n1 such that
P r[Xn ∈
/ D |(X0 , T0 ) = (x0 , τ0 )] ≤ δ ∀n ≥ n1

(4)

This will prove the theorem. If  is such that Init ⊆ D
then Eq.(4) is trivially satisfied. Therefore, fix  > 0 such
that D ⊂ Init, x0 ∈ D, τ0 > 0 and δ > 0. Let m
and n be positive integers, ζ ∈ N>0 × R>0 , and Xnm =
(Xn , Xn+1 , . . . , Xm ) be the random sequence generated by
m
the random process {Xn }. xm
n will be a realization of Xn .
Define the following events:
A = A(m, n) = the event that none of the states (Xi )n+m
i=n
is in D
B = B(ζ, m, n) = the event that at least one of the
transitions Xn+(k−1) → Xn+k , k = 0, 1, . . . , m, is a move
from D to H,ζ , {x ∈ D|V∗ +  < V (x) ≤ V∗ +  + ζ}.
C = C(ζ, m, n) = the event that at least one of the
transitions Xn+(k−1) → Xn+k , k = 0, 1, . . . , m, is a move
from D to H̃,ζ , {x ∈ D|V∗ + ζ +  < V (x)}.
D = the event that Xn+m ∈
/ D .
Observe that D ⊂ A ∪ B ∪ C. Thus for every ζ, m and n

1597

we have

{R(x, H,ζ (i) )}i is a monotonically decreasing sequence of functions.
• The sequence {R(x, H,ζ (i) )} converges pointwise to
the 0 function.
Dini’s theorem allows us to conclude that R(x, H,ζ ) → 0
as ζ → 0 uniformly in x. Thus ∃ζ0 = (ζ1,0 , ζ2,0 ) s.t.
supx∈D R(x, H,ζ0 ) < δ/3m0 . Combined with (6), this
proves the lemma.
•

Pr[Xn+m ∈
/ D |(x0 , τ0 )]
= Pr[D | (x0 , τ0 )]
≤ Pr[A | (x0 , τ0 )] + Pr[B | (x0 , τ0 )]

(5)

+ Pr[D | (x0 , τ0 )]
In the next three sections we prove the following three
lemmata, which show that the ‘escape’ probabilities on
the right hand side of (5) can be made arbitrarily small,
regardless of initial conditions (x0 , τ0 ).
Lemma 2: There exists an integer m0 (which does not
depend on (x0 , τ0 )), such that Pr[A(m0 , n) | (x0 , τ0 )] <
δ/3 ∀n ≥ 0
Lemma 3: Let m0 be as in Lemma 2. There exists a ζ0 =
(ζ0,1 , ζ0,2 ), independent of (x0 , τ0 ), such that

B. Proof of Lemma 4
Let m0 and ζ0 be as in Lemma 1 and Lemma 2 respectively. Fix τ∗ > 0.
Pr[C(ζ0 , m0 , n)|(x0 , τ0 )]
≤

j=0

Pr[B(ζ0 , m0 , n) | (x0 , τ0 )] < δ/3 ∀n ≥ 0
Lemma 4: Let m0 and ζ0 be as in Lemma 2 and Lemma
3 resp. There exists an integer n0 , independent of (x0 , τ0 ),
such that
Pr[C(ζ0 , m0 , n) | (x0 , τ0 )] < δ/3 ∀n ≥ n0
Thus we may conclude that Pr[Xn+m ∈
/ D |(x0 , τ0 )] <
δ∀n ≥ n0 . Therefore, Eq.(4) holds with n1 = n0 + m0 .
The proof of Lemma 2 is almost identical to the original
proof in [18] with some minor obvious modifications, and
again, uses Lemma 1 instead of continuity of V . Therefore
it is omitted.

+ Pr[Cj (ζ0 , m0 , n) ∩ τn+j > τ∗ |(x0 , τ0 )]
The first summand is upper bounded by
pa (x, y, τ ), x ∈ D , y ∈ H̃,ζ0 , τ ≤ τ∗
≤α1 + α2




V1 (y) − V1 (x)
V2 (y) − V2 (x)
+ exp −
= exp −
τ
τ


−V∗ − 1 − ζ1,0 + V∗ + 1
≤ exp
τ


−V∗ − 2 − ζ2,0 + V∗ + 2
+ exp
τ




−ζ2,0
−ζ1,0
+ exp
≤ exp
τ
τ

Pr[B(ζ, m0 , n) | (x0 , τ0 )]

j=0

So there exists a τ∗ s.t. Pr[C(ζ0 , m0 , n)|(x0 , τ0 )] ≤ δ/6
when τ ≤ τ∗ . Condition C6 guarantees the existence of an
n2 such that τn ≤ τ∗ for all n ≥ n2 . The second summand
can be made arbitrarily small by C6: in particular, let n3 be
such that it is smaller than δ/6. Letting n0 ≥ max{n2 , n3}
proves Lemma 4.

Pr[Xn+j ∈ D → Xn+j+1 ∈ H,ζ |(x0 , τ0 )]
{z
}
|
Bj (ζ,m0 ,n)

Pr[Bj (ζ, m0 , n) | (x0 , τ0 )] ≤ sup R(x, H,ζ )
x∈D

Thus
Pr[B(ζ, m0 , n) | (x0 , τ0 )] ≤ m0 sup R(x, H,ζ )

Cj (ζ0 ,m0 ,n)

= Pr[Cj (ζ0 , m0 , n) ∩ τn+j ≤ τ∗ |(x0 , τ0 )]

Let Xi → Xi+1 denote a transition from state Xi to state
Xi+1 , and ζ ∈ N+ × R+ .

≤

Pr[Xn+j ∈ D → Xn+j+1 ∈ H̃,ζ0 |(x0 , τ0 )].
{z
}
|

Pr[Cj (ζ0 , m0 , n)|(x0 , τ0 )]

A. Proof of Lemma 3

m−1
X

m−1
X

(6)

x∈D

Now we may write
H,ζ = {x ∈ D | V1∗ + 1 < V1 (x) ≤ V1∗ + 1 + ζ1 }
∩ {x ∈ D | V2∗ + 2 < V2 (x) ≤ V2∗ + 2 + ζ2 }
1
2
, H,ζ
∩ H,ζ

Consider a sequence {ζ (i) } s.t. ζ (i) → 0 as i → ∞. Then
1
1
1
D ⊇ H,ζ
(1) ⊇ H,ζ (2) ⊇ . . .: since D is bounded (C1), H,ζ
is bounded and therefore has finite Lebesgue measure. Next,
2
µ(H,ζ
) → 0 as ζ2 → 0 (Lemma 2 in [18] with ζ2 = 1/`).
1
2
Thus µ(H,ζ
∩ H,ζ
) = µ(H,ζ ) →
R 0 as ζ → 0. Therefore,
for every x ∈ D, R(x, H,ζ ) = x∈H,ζ r(x, y)dy → 0 as
ζ → 0. Thus:
• R(x, H,ζ (i) ) is a real-valued continuous function over
a compact space D ∀i.

VI. P RACTICAL C ONSIDERATIONS
The previous sections have demonstrated that SA is a
consistent optimization algorithm for the falsification of
temporal logical properties of hybrid automata; that is, the
sequence of samples it produces converges (in probability)
to the set of global optima, regardless of the initial sample.
This is an important property since it guarantees that longer
runs of SA will produce better minima. From a practical
standpoint, previous work [14] has demonstrated that in
practice, SA performs well, both in terms of speed and
quality of obtained minimum. Rather than replicate those
experiments here, we focus instead on the factors that affect
finite-time performance 4 , and how they affect it.
4 Finite-time performance tells us how close is the current minimum,
after N samples generated, to the global minimum. The answer is naturally
affected by the likelihood of SA to spend many samples near non-global
minima for this system and specification.

1598

It is well-known that the practical performance of SA depends on the specific objective function being optimized, the
particular cooling schedule, and the neighborhood selection;
see [26] for a good review of these issues. In our case,
the neighborhood is all of Init as per condition C4, and
the cooling schedule is adaptively modified to maintain an
acceptance-to-rejection ratio close to 1. This is permitted by
condition C6, and has been shown experimentally to help
avoid local minima traps [14]. The objective function is
directly related to the system and property being falsified,
and we now briefly illustrate how its graph can affect
convergence. We select two benchmark hybrid automata and
corresponding unsafe sets, and study the following three
issues for each:
- Generate the partition P of its Init set. This allows us to
assess whether it satisfies condition C7.
- Plot the graph of the objective function, which can indicate
the difficulty of this problem instance.
- See if vector SA generates samples with different sequences
of locations (`i ) for our system. If a run of vector SA
generates very few different (`i ), this might indicate a
local minimum trap, which should not be confused with
having converged (indeed, Lemma 2 asserts that the tail of
the generated sequence consists of samples with the same
sequence of locations with increasing probability).
Our first system, Sys1, is a 2D, 5-location hybrid automaton with linear dynamics in each location:
 −1 10 
 −1 100 
F low(1, x) = 0.1 −100
−1 x, F low(2, x) = 0.1 −10 −1 x
 −1 100 
F low(3, x) = F low(4, x) = 0.1 −10
−1 x
 1 −10 
F low(5, x) = 0.1 10 1 x

Fig. 1: Init partition for Sys1. Parts correspond to the
sequences si

We then ran SA on Sys1 with a sample size of 1000 initial
points, and a trajectory duration of 2sec. All 4 parts were
visited, with the vast majority of the points chosen from
the Part3. This is in accordance with the observations made
above about the partition of Init and shape of the graph.
It is notable that the minimum found by SA (down to two
significant figures) is [1.35, 1.74], almost at the boundary of
parts 3 and 4. These points are harder to find for SA because
of the different sequences on either side of the boundary.
The corresponding robustness value is 0.5 (compare to global
minimum robustness value of 0.49, found on above grid, at
[1.58, 1.79]).
We also re-use the Nav0 benchmark from [27], which
we will argue is a harder instance for SA. Nav0 is a 4dimensional automaton with 16 locations, and it is unknown
whether it is falsifiable or not. For the purposes of presenting
results graphically, we fix the last 2 dimensions of the state
Guard(1, 2) = {x1 > 0}, Guard(2, 3) = {x2 < 0 ∧ x1 < 4.5} vector to [x , x ] = [0.1, 0.2], and let SA vary the first two
3
4
Guard(3, 4) = {x1 < 0}, Guard(2, 5) = {x2 < 0 ∧ x1 > 4.5} dimensions. The graph of the robustness function is given
in Fig.2. The graph was obtained by sampling the initial set
Guard(4, 1) = {x2 > 0}, Guard(5, 3) = {x1 < 4.5}
with a step size of 0.01 (for a total of 3600 points), and
U = {3 < x1 < 4, 3 < x2 < 4}
computing a trajectory of duration 10sec. We can observe
To generate the graph of the robustness function, we sampled a large number of minima with varying depths, increasing
the initial set with a step size of 0.01 in both dimensions, the odds of SA spending a large number of samples in these
leading to a grid with 3600 points. The graph (not shown here minima before jumping back out.
for lack of space) displays several near-flat ‘valleys’ (regions
of small function values) surrounded by ‘peaks’ (regions of
large function values): if SA samples from a given valley, it
will continue sampling from it for a long time because the
probability of accepting an increase in function value will
be small, following Eq.(3). Thus we expect that once SA
samples from a valley that contains a global minimum, then
there’s a high probability it will get arbirarily close to that
minimum.
Using the same grid, the partition P of the initial set was
obtained. A coarser partition (with step size = 0.02) is shown
in Fig.1 for clarity. A total of 4 parts were obtained, each
corresponding to a sequence of locations. It can be seen that
Parts 1 and 3 cover much of Init (see Fig.1), so it is to be
Fig. 2: Graph of the robustness function for Nav0.
expected that at least initially, SA will sample from these 2
parts overwhelmingly. If the global minimum is in a different
Using the same grid, the partition P of the initial set
part, longer runs of SA are required.

1599

was computed. The partition has 189 parts, with the largest
part containing only 15.3% of the points, and the 4 largest
parts together have 53.3% of the points. Fig.3 shows how
the initial set of conditions is highly fragmented. While we
haven’t established a precise relation between the measure of
the parts and SA convergence, condition C7 and the proof
of Prop.1 drive us to conjecture that a larger measure for
the parts leads to a faster convergence. The small size of all
partitions in Nav0 then suggests this is a hard instance for
SA.

provides a number of samples after which we are guaranteed
that the minimum so far is within the desired precision of the
global minimum. The strength of this result is that it requires
very little of the objective function, namely only that it be
well-defined pointwise, measurable, and bounded between 0
and 1. In traditional SA, g ◦ V (x) satisfies these conditions,
with V given in Problem 1 and g is any monotone increasing
function that maps [0, ∞] to [0, 1]. No such result exists yet
for a vector objective function, like the one in Problem 2;
this is the subject of future research.
VII. C ONCLUSIONS

Fig. 3: Zoom on Init partition for Nav0. Different symbols
and colors correspond to different sequences of locations.
Note the fragmentation on the right side.

The problem of falsifying safety properties of hybrid
automata was formulated as optimization problems in [14].
In this paper, we provided conditions on the system under
which Simulated Annealing will converge in probability to
the global minimum, and thus return a system trajectory
of mimimal robustness. Research can proceed along three
directions: the first is to establish convergence conditions for
discrete implementations of the continuous models studied in
this paper. A second direction is to broaden the class of systems for which SA converges, e.g. to systems with more than
one starting location, and to automata with state- and timedependent guard sets, as well as to non-autonomous systems.
A third direction of research is to develop computable criteria
that establish whether a given system is, a priori, suitable
for efficient SA falsification or not. As part of this direction,
there is obvious interest in establishing finite-time guarantees
for the vector SA algorithm.
ACKNOWLEDGMENT
The authors wish to thank Tolga Duman for many helpful
discussions.

SA was run on Nav0 with a sample size of 1000 initial
points, and a test duration of 10sec. It selected points from 62
parts, with the largest 2 containing 70% of the 1000 points,
and the smallest containing 0.01% of the points. These parts
were not the largest parts in P , which is expected since SA
is driven by the objective function as well as the measure
of the parts. SA found a global minimum value of 0.09 at
[0.61, 3.40], compared to the global (grid) minimum of 0.08
at [0.67, 3.52].
On the theoretical side, the probabilistic convergence of
the sequence of initial states generated by SA to a global
optimum, can be informally divided into two parts: the first
part is the convergence of the Markov Chain to its zerotemperature stationary distribution, π∞ , in an appropriate
sense. The stationary distribution favors minima of the objective function. The second part is then the sampling from the
stationary distribution. Thus a bound on SA’s convergence
involves bounding these two components. The second part
depends on the shape of the stationary distribution. In our
1 −βV (x)
case, it is exponential of the form π∞ (x) = M
e
[14],
where M is the (unknown) normalization constant. For the
first part, recently, a result on finite-time guarantees for SA
optimization over continuous domains was obtained in [28].
Informally, given a desired precision of the optimization, it

1600

R EFERENCES
[1] M. Blair, S. Obenski, and P. Bridickas, “Patriot missile software
problem,” United States General Accounting Office, Tech. Rep.
GAO/IMTEC-92-26, 1992.
[2] E. J. Hoffman, W. L. Ebert, M. D. Femiano, H. R. Freeman, C. J.
Gay, C. P. Jones, P. J. Luers, and J. G. Palmer, “The near rendezvous
burn anomaly of december 1998,” Applied Physics Laboratory, Johns
Hopkins University, Tech. Rep., Nov. 1999.
[3] T. A. Henzinger, P. W. Kopke, A. Puri, and P. Varaiya, “What’s
decidable about hybrid automata?” J. Comput. Syst. Sci., vol. 57, no. 1,
pp. 94–124, 1998.
[4] S. Ratschan and J.-G. Smaus, “Finding errors of hybrid systems by
optimizing an abstraction-based quality estimate,” in Proceedings of
the Third Int’l Conf. on Tests and Proofs, Zurich, Switzerland, July
2009, pp. 153–168.
[5] Q. Zhao, B. H. Krogh, and P. Hubbard, “Generating test inputs for
embedded control systems,” IEEE Control Systems Magazine, vol.
Aug., pp. 49–57, 2003.
[6] M. Branicky, M. Curtiss, J. Levine, and S. Morgan, “Sampling-based
planning, control and verification of hybrid systems,” IEE Proc.Control Theory Appl., vol. 153, no. 5, pp. 575–590, 2006.
[7] T. Nahhal and T. Dang, “Test coverage for continuous and hybrid
systems,” in CAV, ser. LNCS, vol. 4590. Springer, 2007, pp. 449–
462.
[8] E. Plaku, L. E. Kavraki, and M. Y. Vardi, “Hybrid systems: From
verification to falsification,” in Proceedings of the 19th International
Conference on Computer Aided Verification, ser. LNCS, W. Damm
and H. Hermanns, Eds., vol. 4590. Springer, 2007, pp. 463–476.
[9] ——, “Falsification of ltl safety properties in hybrid systems,” in Proc.
of the Conf. on Tools and Algorithms for the Construction and Analysis
of Systems (TACAS), ser. LNCS, vol. 5505, 2009, pp. 368 – 382.

[10] A. Rizk, G. Batt, F. Fages, and S. Soliman, “On a continuous degree
of satisfaction of temporal logic formulae with applications to systems
biology,” in International Conference on Computational Methods in
Systems Biology, ser. LNCS, no. 5307. Springer, 2008, pp. 251–268.
[11] P. Zuliani, A. Platzer, and E. M. Clarke, “Bayesian statistical model
checking with application to simulink/stateflow verification,” in Proceedings of the 13th ACM International Conference on Hybrid Systems: Computation and Control, 2010, pp. 243–252.
[12] A. Donze and O. Maler, “Systematic simulation using sensitivity
analysis,” in Hybrid Systems: Computation and Control, ser. LNCS,
vol. 4416. Springer, 2007, pp. 174–189.
[13] F. Lerda, J. Kapinski, E. M. Clarke, and B. H. Krogh, “Verification
of supervisory control software using state proximity and merging,”
in Hybrid Systems: Computation and Control, ser. LNCS, vol. 4981.
Springer, 2008, pp. 344–357.
[14] H. Abbas, G. E. Fainekos, S. Sankaranarayanan, F. Ivancic, A. Gupta,
and G. J. Pappas, “Probabilistic temporal logic falsification of cyberphysical systems,” ACM Transactions on Embedded Computing Systems, vol. (Accepted), 2011.
[15] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan, “S-taliro: A tool for temporal logic falsification for hybrid
systems,” in Tools and algorithms for the construction and analysis
of systems, ser. LNCS, vol. 6605. Springer, 2011, pp. 254–257.
[16] T. Nghiem, S. Sankaranarayanan, G. Fainekos, F. Ivancic, A. Gupta,
and G. Pappas, “Monte-carlo techniques for falsification of temporal
properties of non-linear hybrid systems,” in Hybrid Systems: Computation and Control, 2010.
[17] G. Fainekos and G. Pappas, “Robustness of temporal logic specifications for continuous-time signals,” Theoretical Computer Science, vol.
410, no. 42, pp. 4262–4291, September 2009.
[18] C. J. P. Belisle, “Convergence theorems for a class of simulated
annealing algorithms on Rd ,” Journal of Applied Probability, vol. 29,
no. 4, pp. 885–895, Dec. 1992.
[19] B. Hajek, “Cooling schedules for optimal annealing,” Mathematics of
operation research, vol. 13, no. 2, pp. 311–329, 1988.
[20] R. G. Sanfelice and A. R. Teel, “Dynamical properties of hybrid
systems simulators,” Automatica, vol. 46, no. 2, pp. 239–248, 2010.
[21] P. Tabuada, Verification and Control of Hybrid Systems: A Symbolic
Approach. Springer, 2009.
[22] A. Girard and G. J. Pappas, “Approximation metrics for discrete and
continuous systems,” IEEE Trans. Auto. Cont., vol. 52, no. 5, pp. 782–
798, 2007.
[23] J. Lygeros, K. H. Johansson, S. N. Simic, J. Zhang, and S. Sastry,
“Dynamical properties of hybrid automata,” IEEE Transactions on
Automatic Control, vol. 48, pp. 2–17, 2003.
[24] K. I. Smith, R. M. Everson, J. E. Fieldsend, C. Murphy, and R. Misra,
“Dominance-based multiobjective simulated annealing,” IEEE Transactions on Evolutionary computation, vol. 12, no. 3, pp. 323–342,
2008.
[25] P. Czyzak and A. Jaszkiewicz, “Pareto simulated annealing - a metaheuristic technique for multiple-objective combinatorial optimization,”
J. Multi-Criteria Decision Analysis, vol. 7, pp. 34–47, 1998.
[26] D. Henderson, S. H. Jacobson, and A. W. Johnson, “The theory
and practice of simulated annealing,” in Handbook of metaheuristics.
Springer, 2003.
[27] H. Abbas and G. Fainekos, “Linear hybrid system falsification through
local search,” in Automated Technology for Verification and Analysis,
ser. LNCS, vol. 6996. Springer, 2011, pp. 503–510.
[28] A. Lecchini-Visintini, J. Lygeros, and J. M. Maciejowski, “Stochastic
optimization on continuous domains with finite-time guarantees by
markov chain monte carlo methods,” IEEE Transactions on Automatic
Control, vol. 55, no. 12, pp. 2858–2863, Dec. 2010.
[29] R. Goebel, R. G. Sanfelice, and A. R. Teel, “Hybrid dynamical
systems,” IEEE Control Systems Magazine, pp. 28–93, 2009.

A set C ⊆ Rd called the flow set
n
n
• A set-valued map F : R → P(R ) called the flow
map
n
• A set D ⊆ R called the jump set
n
n
• A set-valued map G : R → P(R ) called the jump
map
We write H = (C, F, D, G). The dynamics of the system
are given by
(
˙
n ξ ∈ F (ξ), ξ ∈ C
ξ∈R
ξ + ∈ G(ξ), ξ ∈ D
Hybrid automata, defined in section II-A, can be modeled
using Def. 4 as follows [29]: let n = d + 1 and ξ = [`, x]T ∈
L × Rd ⊂ Rd+1 be the state of the system. Then we take:
C` = Inv(`), D` = ∪`0 :(`,`0 )∈E Guard(`, `0 ), F` (x) =
F low(`, x), ∀x ∈ C` , and
G` (x) = {[`0 , Re(`, `0 , x)]T | x ∈ Guard(`, `0 )}, ∀x ∈ D` .
For a deterministic automaton, for any x, there is a unique
location `0 such that x ∈ Guard(`, `0 ) (otherwise, two jumps
(`, `0 ) and (`, `00 ) are possible). Thus G` (x) is a singleton.
The dynamics of H are then given by:
(
T
˙
T
d ξ ∈ F (ξ) = {[0, F` (x)] }, x ∈ C`
[`, x] ∈ L×R
+
0
ξ ∈ G(ξ) = {[` , Re(`, `0 , x)]T }, x ∈ D`
•

Conditions for accurate simulation [20, Assumption 2.5].
The data of the hybrid system H = (C, F, D, G), satisfies:
A1. C and D are closed sets.
A2. F : Rd → P(Rd ) is outer semicontinuous (o.s.c.)5 and
locally bounded, and F (ξ) is nonempty and convex for all
ξ ∈ C.
A3. G : Rd → P(Rd ) is o.s.c. and locally bounded, and
G(ξ) is nonempty for all ξ ∈ D.
Proposition 1 is an application of the following theorem.
A ‘maximal’ trajectory is one which can not be extended.
Recall that D is the time-limit of all trajectories we compute.
Theorem 4: [20, Thm. 3.4] Assume that H satisfies the
above conditions. Let K ⊂ Rn be a compact set such that H
is pre-complete from K (i.e. each maximal trajectory starting
from K is either bounded or has infinite length). Then, for
every  > 0 there exists δ ∗ > 0 with the following property:
for any δ ∈ (0, δ ∗ ] and any solution ηx with x ∈ K +δB1 (0)
there exists a solution ηx0 with x0 ∈ K such that the two
trajectories have the same number of location transitions, and
their continuous parts are -close at all times t < D at which
they’re in the same location.

VIII. A PPENDIX
This section details the ‘hybrid basic conditions’ that are
required of a hybrid automaton H for it to have an accurate
simulator. The conditions are framed in the formalism of
differential and difference inclusions [29], which generalizes
the formalism used in this paper.
Definition 4: [20] A hybrid system H on a state space
Rn is defined by

5 A set-valued map F : Rn → P(Rn ) is o.s.c. iff for all sequences
(ξi ) ∈ Rn converging to ξ and all sequences (ωi ) ∈ F (ξi ) converging to
ω, it holds that ω ∈ F (ξ).

1601

1370

IEEE TRANSACTIONS ON ROBOTICS, VOL. 25, NO. 6, DECEMBER 2009

Temporal-Logic-Based Reactive Mission and
Motion Planning
Hadas Kress-Gazit, Member, IEEE, Georgios E. Fainekos, Member, IEEE, and George J. Pappas, Fellow, IEEE

Abstract—This paper provides a framework to automatically
generate a hybrid controller that guarantees that the robot can
achieve its task when a robot model, a class of admissible environments, and a high-level task or behavior for the robot are provided.
The desired task specifications, which are expressed in a fragment
of linear temporal logic (LTL), can capture complex robot behaviors such as search and rescue, coverage, and collision avoidance. In
addition, our framework explicitly captures sensor specifications
that depend on the environment with which the robot is interacting,
which results in a novel paradigm for sensor-based temporal-logicmotion planning. As one robot is part of the environment of another robot, our sensor-based framework very naturally captures
multirobot specifications in a decentralized manner. Our computational approach is based on first creating discrete controllers
satisfying specific LTL formulas. If feasible, the discrete controller
is then used to guide the sensor-based composition of continuous
controllers, which results in a hybrid controller satisfying the highlevel specification but only if the environment is admissible.
Index Terms—Controller synthesis, hybrid control, motion planning, sensor-based planning, temporal logic.

I. INTRODUCTION
OTION planning and task planning are two fundamental problems in robotics that have been addressed from
different perspectives. Bottom-up motion-planning techniques
concentrate on creating control inputs or closed-loop controllers
that steer a robot from one configuration to another [1], [2] while
taking into account different dynamics and motion constraints.
On the other hand, top-down task-planning approaches are usually focused on finding coarse, which are typically discrete,
robot actions in order to achieve more complex tasks [2], [3].
The traditional hierarchical decomposition of planning problems into task-planning layers that reside higher in the hierarchy than motion-planning layers has resulted in a lack of

M

Manuscript received November 6, 2008; revised April 3, 2009. First published
September 15, 2009; current version published December 8, 2009. This paper
was recommended for publication by Associate Editor O. Brock and Editor
L. Parker upon evaluation of the reviewers’ comments. This work was supported in part by the National Science Foundation under Grant EHS 0311123,
in part by the National Science Foundation under Grant ITR 0324977, and in
part by the Army Research Office under Grant MURI DAAD 19-02-01-0383.
H. Kress-Gazit is with the Mechanical and Aerospace Engineering, Cornell
University, Ithaca, NY 14853 USA (e-mail: hadaskg@cornell.edu).
G. E. Fainekos was with the General Robotics, Automation, Sensing, and Perception Laboratory, University of Pennsylvania, Philadelphia, PA 19104 USA.
He is now with the School of Computing, Informatics, and Decision Systems
Engineering, Arizona State University, Tempe, AZ 85287-0112 USA (e-mail:
fainekos@grasp.upenn.edu).
G. J. Pappas is with the General Robotics, Automation, Sensing, and Perception Laboratory, University of Pennsylvania, Philadelphia, PA 19104 USA
(e-mail: pappasg@grasp.upenn.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TRO.2009.2030225

approaches that address the integrated system, until very recently. The modern paradigm of hybrid systems, which couples
continuous and discrete systems, has enabled the formal integration of high-level discrete actions with low-level controllers
in a unified framework [4]. This has inspired a variety of approaches that translate high-level, discrete tasks to low-level,
continuous controllers in a verifiable and computationally efficient manner [5]–[7] or compose local controllers in order to
construct global plans [8]–[10].
This paper, which expands on the work presented in [11],
describes a framework that automatically translates high-level
tasks given as linear temporal-logic (LTL) formulas [12] of specific structure into correct-by-construction hybrid controllers.
One of the strengths of this framework is that it allows for reactive tasks, i.e., tasks in which the behavior of the robot depends
on the information it gathers at runtime. Thus, the trajectories
and actions of a robot in one environment may be totally different in another environment, while both satisfy the same task.
Another strength is that the generated hybrid controllers drive
a robot or a group of robots such that they are guaranteed to
achieve the desired task if it is feasible. If the task cannot be
guaranteed, because of various reasons discussed in Section VI,
no controller will be generated, which indicates that there is a
problem in the task description.
To translate a task to a controller, we first lift the problem
into the discrete world by partitioning the workspace of the
robot and writing its desired behavior as a formula belonging
to a fragment of LTL (see Section III). The basic propositions
of this formula include propositions whose truth value depends
on the robot’s sensor readings; hence, the robot’s behavior can
be influenced by the environment. In order to create a discrete
plan, a synthesis algorithm [13] generates an automaton that
satisfies the given formula (see Section IV). Then, the discrete
automaton is integrated with the controllers in [8] and results in
an overall hybrid controller that orchestrates the composition of
low-level controllers based on the information gathered about
the environment at runtime (see Section V). The overall closedloop system is guaranteed (see Section VI) by construction to
satisfy the desired specification, but only if the robot operates in
an environment that satisfies the assumptions that were explicitly
modeled, as another formula, in the synthesis process. This leads
to a natural assume-guarantee decomposition between the robot
and its environment.
In a multirobot task (see Section VIII), as long as there are
no timing constraints or a need for joint-decision making, each
robot can be seen as a part of the environment of all other robots.
Hence, one can consider a variety of multirobot missions, such
as search and rescue and surveillance, that can be addressed in
a decentralized manner.

1552-3098/$26.00 © 2009 IEEE

KRESS-GAZIT et al.: TEMPORAL-LOGIC-BASED REACTIVE MISSION AND MOTION PLANNING

This paper expands on the work outlined in [11] in several
directions. First, here, we allow the task to include specification
that relate to different robot actions in addition to the motion,
thus accommodating a larger set of tasks. Second, the continuous execution of the discrete automaton has been modified in
order to allow immediate reaction to changes in the state of the
environment. Finally, this paper includes a discussion (see Section VI) regarding the strengths, weaknesses, and extensions
of the framework, as well as the examples that demonstrate
complex tasks.
A. Related Work
The work presented in this paper draws on results from automata theory, control, and hybrid systems. Combining these
disciplines is a recurring theme in the area of symbolic control [4].
Motion description languages (MDLs and MDLe) [14]–[17]
provide a formal basis for the control of continuous systems
(robots) using sets of behaviors (atoms), timers, and events.
This formalism captures naturally reactive behaviors in which
the robot reacts to environmental events, as well as composition
of behaviors. The work presented here is similar in spirit in that
we compose basic controllers in order to achieve a task; however,
the main differences are the scope of allowable tasks (temporal
behaviors as opposed to final goals) and the automation and
guarantees provided by the proposed framework.
Maneuver automata [18], which can be seen as a subset of
MDLs, are an example for the use of a regular language to solve
the motion task of driving a complex system from an initial
state to a final state. Here, each symbol is a motion primitive that
belongs to a finite library of basic motions, and each string in the
language corresponds to a dynamically feasible motion behavior
of the system. Our paper, while sharing the idea of an automaton
that composes basic motions, is geared toward specifying and
guaranteeing higher level and reactive behaviors (sequencing of
goals, reaction to environmental events, and infinite behaviors).
Ideas, such as the ones presented in [18], could be incorporated
in the future into the framework proposed in this paper to allow
for complex nonlinear robot dynamics.
The work in [19] describes a symbolic approach to the task
of navigating under sensor errors and noise in a partially known
environment. In this paper, we allow a richer set of specifications, but perfect sensors and a fully known environment are
assumed. Exploring the ideas regarding the use of Markov decision processes (MDPs) and languages to deal with uncertainty
is a topic for future research.
This paper assumes that a discrete abstraction of the robot
behavior (motion and actions) can be generated. For simple dynamics, such as the kinematic model considered in this paper,
there is considerable work supporting this assumption ( [8]–
[21], etc.); however, such an assumption is harder to satisfy
when complex nonlinear dynamics are considered. Results, such
as the work reported in [22] and [23], where nonlinear dynamical systems are abstracted into symbolic models, could
be used in the future to enhance the work presented in this
paper.

1371

The use of temporal logic for the specification and verification
of robot controllers was advocated way back in 1995 [24], where
computation tree logic (CTL) [12] was used to generate and
verify a supervisory controller for a walking robot. In the hybrid
systems community, several researchers have explored the use
of temporal and modal logic for the design of controllers. Moor
and Davoren [25] and Davoren and Moor [26] use modal logic
to design switching control that is robust to uncertainty in the
differential equations. There, the system is controlled such that it
achieves several requirements, such as safety, event sequencing,
and liveness, and is assumed to be closed, i.e., the controller
does not need to take into account external events from the
environment, whereas, here, we assume an open system in which
the robot reacts to its environment.
From the discrete systems point of view, [27] describes fixpoint iteration schemes to solve LTL games. The decidability of
the synthesis problem for metric temporal logic (MTL), which is
a linear time logic that includes timing constraints, is discussed
in [28].
This paper is based on ideas presented in [7], [29], and our
previous work [5], [6], and [30], such as the use of bisimulations [31], [32] to lift a continuous problem into a discrete
domain while preserving important properties, as well as the
use of LTL as the formalism to capture high-level tasks. These
approaches provide a correct-by-construction controller, whenever one can be found, which is similar to the work presented
in this paper. The main difference between these papers and the
work presented here is that in [5]– [7] the behavior is nonreactive in the sense that the behavior is required to be the same,
no matter what happens in the environment at runtime, for example, visiting different rooms in some complex order. In these
papers, other than localization, the robot does not need to sense
its surroundings, and does not react to its environment. Here,
in contrast, the robot is operating in a possibly adversarial environment to which it is reacting, and the task specification can
capture this reactivity. Such behaviors could include, for example, searching rooms for an object and, once an object is found,
returning to a base station. The behavior of the robot will be different in each execution since the environment may be different
(the object might be in different locations in each execution). As
such, this framework provides a plan of action for the robot so
that it achieves its task under any allowable circumstance. Furthermore, this framework can handle nonlinear dynamics and
motion constraints as long as a suitable discrete abstraction of
the motion and a set of low-level controllers can be defined (see
Section VI).

II. PROBLEM FORMULATION
The goal of this paper is to construct controllers for mobile
robots that generate continuous trajectories that satisfy the given
high-level specifications. Furthermore, we would like to achieve
such specifications while interacting, by using sensors, with a
variety of environments. The problem that we want to solve is
graphically illustrated in Fig. 1.

1372

Fig. 1.

IEEE TRANSACTIONS ON ROBOTICS, VOL. 25, NO. 6, DECEMBER 2009

Problem description.

To achieve this, we need to specify a robot model, assumptions on admissible environments, and the desired system
specification.
1) Robot Model: We will assume that a mobile robot (or,
possibly, several mobile robots) is operating in a polygonal
workspace P . The motion of the robot is expressed as
ṗ(t) = u(t),

p(t) ∈ P ⊆ R2 ,

u(t) ∈ U ⊆ R2

(1)

where p(t) is the position of the robot at time t, and u(t) is
the control input. We will also assume that the workspace P
is partitioned using a finite number of cells P1 , . . . , Pn , where
P = ∪ni=1 Pi , and Pi ∩ Pj = ∅, if i = j. Furthermore, we will
also assume that each cell is a convex polygon. The partition
naturally induces Boolean propositions {r1 , r2 , . . . , rn }, which
are true if the robot is located in Pi

True, if p ∈ Pi
ri =
False, if p ∈ Pi .
Since {Pi } is a partition of P , exactly one ri can be true at any
time.
The robot may have actions that it can perform, such as making sounds, operating a camera, transmitting messages to a base
station, etc. In this paper, we allow actions that can be turned on
and off at any time, and we encode these actions as propositions
A = {a1 , a2 , . . . , ak }

True, if action i is being executed
ai =
False, if action i is not being executed.

below a certain threshold, but this is also a reasonable abstraction when considering more complex sensors, such as vision
systems, where one can utilize decision-making frameworks or
computer-vision techniques. Furthermore, in this paper, we assume that the sensors are perfect, i.e., they always provide the
correct and accurate state of the world. Relaxing this assumption
is a topic for future research.
The m binary sensor variables X = {x1 , x2 , . . . , xm } have
their own (discrete) dynamics that we do not model explicitly.
Instead, we place high-level assumptions on the possible behavior of the sensor variables, thus defining a class of admissible
environments. These environmental assumptions will be captured (in Section III) by a temporal-logic formula ϕe . Our goal
is to construct controllers that achieve their desired specification not for any arbitrary environment, but rather for all possible
admissible environments satisfying ϕe .
3) System Specification: The desired system specification
for the robot will be expressed as a suitable formula ϕs in a
fragment of LTL [12]. Informally, LTL will be used (see Section III) to specify a variety of robot tasks that are linguistically
expressed as
1) coverage: “go to rooms P1 , P2 , P3 , P4 in any order”;
2) sequencing: “first go to room P5 , then to room P2 ”;
3) conditions: “If you see Mika, go to room P3 , otherwise
stay where you are”;
4) avoidance: “Do not go to corridor P7 .”
Furthermore, LTL is compositional, which enables the construction of complicated robot-task specifications from simple
ones.
Putting everything together, we can describe the problem that
will be addressed in this paper.
Problem 1 [Sensor-based temporal-logic-motion planning]:
Given a robot model (1) and a suitable temporal-logic formula
ϕe modeling our assumptions on admissible environments, construct (if possible) a controller so that the robot’s resulting trajectories p(t) and actions act(t) satisfy the system specification ϕs
in any admissible environment, from any possible initial state.
In order to make Problem 1 formal, we need to precisely define the syntax, semantics, and class of temporal-logic formulas
that are considered in this paper.

We define act(t) ⊆ A as the set of actions that are active (true)
at time t as
ai ∈ act(t),

III. TEMPORAL LOGICS
iff ai is true at time t.

Combining these propositions together with the location propositions, we can define the set of robot propositions as Y =
{r1 , r2 , . . . , rn , a1 , a2 , . . . , ak }. Note that if two actions cannot be active at the same time, then such a requirement must
be added to the system specification either by the user (if it is
task-dependent) or automatically from the robot model (when
the actions for a specific robot are defined).
2) Admissible Environments: The robot interacts with its environment using sensors, which, in this paper, are assumed to be
binary. This is a natural assumption when considering simple
sensors, such as temperature sensors or noise-level detectors,
which can indicate whether the sensed quantity is above or

Generally speaking, temporal logic [12] consists of propositions, the standard Boolean operators, and some temporal operators. They have been used in several communities to represent
properties and requirements of systems, which range from computer programs to robot-motion control. There are several different temporal logics, such as CTL, CTL∗ , real-time logics, etc.
In this paper, we use a fragment of LTL for two reasons. First, it
can capture many interesting and complex robot behaviors, and
second, such formulas can be synthesized into controllers in a
tractable way (see Section IV).
We first give the syntax and semantics of the full LTL and
then describe, by following [13], the specific structure of the
LTL formulas that will be used in this paper.

KRESS-GAZIT et al.: TEMPORAL-LOGIC-BASED REACTIVE MISSION AND MOTION PLANNING

1373

A. LTL Syntax and Semantics
Syntax: Let AP be a set of atomic propositions. In our setting,
AP = X ∪ Y, which includes both sensor and robot propositions. LTL formulas are constructed from atomic propositions
π ∈ AP according to the following grammar:
ϕ ::= π | ¬ϕ | ϕ ∨ ϕ | 	 ϕ | ϕ U ϕ.
As usual, the Boolean constants True and False are defined as
True = ϕ ∨ ¬ϕ and False = ¬True, respectively. Given negation (¬) and disjunction (∨), we can define conjunction (∧),
implication (⇒), and equivalence (⇔). Furthermore, given
the temporal operators “next” (	) and “until” (U), we can
also derive additional temporal operators such as “Eventually”
♦ϕ = True U ϕ and “Always” ϕ = ¬♦¬ϕ.
Semantics: The semantics of an LTL formula ϕ is defined
over an infinite sequence σ of truth assignments to the atomic
propositions π ∈ AP . We denote the set of atomic propositions
that are true at position i by σ(i) . We recursively define whether
sequence σ satisfies LTL formula ϕ at position i (denoted σ, i |=
ϕ) by
σ, i |= π,

iff π ∈ σ(i)

σ, i |= ¬ϕ,
σ, i |= ϕ1 ∨ ϕ2 ,
σ, i |= 	ϕ,
σ, i |= ϕ1 U ϕ2 ,

iff σ, i |= ϕ
iff σ, i |= ϕ1 or σ, i |= ϕ2
iff σ, i + 1 |= ϕ
there exists k ≥ i such that σ, k |= ϕ2
and for all i ≤ j < k, we have σ, j |= ϕ1 .

Intuitively, the formula 	ϕ expresses that ϕ is true in the
next “step” (the next position in the sequence), and the formula
ϕ1 U ϕ2 expresses the property that ϕ1 is true until ϕ2 becomes
true. The sequence σ satisfies formula ϕ if σ, 0 |= ϕ. The sequence σ satisfies formula ϕ if ϕ is true in every position of
the sequence, and satisfies the formula ♦ϕ if ϕ is true at some
position of the sequence. Sequence σ satisfies the formula ♦ϕ
if at any position ϕ will eventually become true, i.e., ϕ is true
infinitely often.
B. Special Class of LTL Formulas
Due to computational considerations mentioned in
Section IV, we consider a special class of temporal-logic formulas [13]. We first recall that we have divided our atomic
propositions into sensor propositions X = {x1 , . . . , xm } and
robot propositions Y = {r1 , . . . , rn , a1 , . . . , ak }.
These special formulas are LTL formulas of the form ϕ =
(ϕe ⇒ ϕs ), where ϕe is an assumption about the sensor propositions, and, thus, about the behavior of the environment, and
ϕs represents the desired behavior of the robot. The formula ϕ
is true if ϕs is true, i.e., the desired robot behavior is satisfied,
or ϕe is false, i.e., the environment did not behave as expected.
This means that when the environment does not satisfy ϕe , and
is thus not admissible, there is no guarantee about the behavior
of the system. Both ϕe and ϕs have the following structure:
ϕe = ϕei ∧ ϕet ∧ ϕeg ; ϕs = ϕsi ∧ ϕst ∧ ϕsg

Fig. 2.

Workspace of Example 1.

where ϕei and ϕsi are nontemporal Boolean formulas constraining (if at all) the initial value(s) for the sensor propositions
X and robot propositions Y, respectively, ϕet represents the
possible evolution of the state of the environment and consists of a conjunction of formulas of the form Bi , where
each Bi is a Boolean formula constructed from subformulas
in X ∪ Y ∪ 	X and where 	X = {	x1 , . . . , 	xn }. Intuitively, formula ϕet constrains the next sensor values 	X based
on the current sensor X and robot Y values, ϕst represents the
possible evolution of the state of the robot and consists of a
conjunction of formulas of the form Bi , where each Bi is a
Boolean formula in X ∪ Y ∪ 	X ∪ 	Y. Intuitively, this formula constrains the next robot values 	Y based on the current
robot Y values and on the current and next sensor X ∪ 	X values. The next robot values can depend on the next sensor values
because we assume that the robot first senses, and then acts, as
explained in Section IV, and ϕeg and ϕsg represent goal assumptions for the environment and desired goal specifications for the
robot. Both formulas consist of a conjunction of formulas of the
form ♦Bi , where each Bi is a Boolean formula in X ∪ Y.
The formula φ = (ϕeg ⇒ ϕsg ), which will be discussed in
Section IV, is a generalized reactivity(1) [GR(1)] formula.
This class of LTL imposes additional restrictions on the structure of allowable formulas. Therefore, some LTL formulas cannot be expressed, for example, ♦φ, which is true if at some
unknown point in the future, φ becomes true and stays true
forever.1 However, according to our experience, there does not
seem to be a significant loss in expressivity as most specifications that we encountered can be either directly expressed or
translated to this format. More formally, any behavior that can
be captured by an implication between conjunctions of deterministic Buchi automata can be specified in this framework [13].
Furthermore, the structure of the formula very naturally reflects
the structure of most sensor-based robotic tasks. We illustrate
this with a relatively simple example.
Example 1: Consider a robot that is moving in the workspace
shown in Fig. 2 consisting of 12 regions labeled 1, . . . , 12 (which
relate to the robot propositions {r1 , . . . , r12 }). Initially, the robot
is placed either in region 1, 2, or 3. In natural language, the
desired specification for the robot is as follows: Look for Nemo
in regions 1, 3, 5, and 8. If you find him, turn your video camera
ON, and stay where you are. If he disappears again, turn the
camera OFF, and resume the search.
1 The restricted class of LTL can capture a formula that states that right after
something happens, φ becomes true and stays true forever, but it cannot capture
that φ must become true at some arbitrary point in time.

1374

Since Nemo is part of the environment, the set of sensor propositions contains only one proposition X = {sNem o },
which becomes True if our sensor has detected Nemo. Our
assumptions about Nemo are captured by ϕe = ϕei ∧ ϕet ∧
ϕeg . The robot initially does not see Nemo, and thus, ϕei =
(¬sNem o ). Since we can only sense Nemo in regions 1, 3, 5,
and 8, we encode the requirement that in other regions the value
of sNem o cannot change. This requirement is captured by the
formula

IEEE TRANSACTIONS ON ROBOTICS, VOL. 25, NO. 6, DECEMBER 2009

This completes our modeling of the robot specification as well.
Combining everything together, we get the required formula
ϕ = (ϕe ⇒ ϕs ).
Having modeled a scenario using ϕ, our goal is now to synthesize a controller-generating trajectories that will satisfy the
formula if the scenario is possible (if the formula is realizable).
Section IV describes the automatic generation of a discrete automaton satisfying the formula, while Section V explains how
to continuously execute the synthesized automaton.

ϕet = ((¬r1 ∧ ¬r3 ∧ ¬r5 ∧ ¬r8 ) ⇒ (	sNem o ⇔ sNem o )).
We place no further assumptions on the environment propositions, which means that ϕeg = ♦(True), completing the modeling of our environment assumptions. Note that the environment
is admissible whether Nemo is there or not.
We now turn to modeling the robot and the desired specification, which are captured by ϕs = ϕsi ∧ ϕst ∧ ϕsg . We define 13
robot propositions Y = {r1 , . . . , r12 , aCam eraON }.
Initially, the robot starts somewhere in region 1, 2, or 3 with
the camera; hence

(r ∧
¬r ∧ ¬aCam eraON )

 1 i∈{2,···,12} i
(r2 ∧i∈{1,3,···,12} ¬ri ∧ ¬aCam eraON )
ϕsi =



(r3 ∧i∈{1,2,4,···,12} ¬ri ∧ ¬aCam eraON ).
The formula ϕst models the possible changes in the robot state.
The first block of subformulas represent the possible transitions
between regions, for example, from region 1, the robot can move
to adjacent region 9 or stay in 1. The next subformula captures
the mutual exclusion constraint, i.e., at any step, exactly one of
r1 , . . ., r12 is true. For a given decomposition of workspace P ,
the generation of these formulas is easily automated. The final
block of subformulas is a part of the desired specification and
states that if the robot sees Nemo, it should remain in the same
region in the next step, and the camera should be ON. It also
states that if the robot does not see Nemo, the camera should be
OFF

   (r ⇒ (	r ∨ 	r ))
1
1
9










(r
⇒
(	r
∨
	r

2
2
12 ))



  ..


.







(r12 ⇒ (	r2 ∨ 	r9 ∨ 	r11 ∨ 	r12 ))





 ( (	r1 ∧i= 1 ¬ 	 ri )


s
∨(	r2 ∧i= 2 ¬ 	 ri )
ϕt =



..


.





∨(	r12 ∧i= 12 ¬ 	 ri )




Nem o

⇒


 ( 	s




(∧
	
ri ⇔ ri ) ∧ 	aCam eraON )

i∈{1,···,12}




( ¬ 	 sNem o ⇒ ¬ 	 aCam eraON ).

Finally, the requirement that the robot keeps looking in regions
1, 3, 5, and 8, unless it has found Nemo, is captured by


♦(r1 ∨ sNem o ) ♦(r3 ∨ sNem o )
s
ϕg = 

♦(r5 ∨ sNem o ) ♦(r8 ∨ sNem o ).

IV. DISCRETE SYNTHESIS
Given an LTL formula, the realization or synthesis problem
consists of constructing an automaton whose behaviors satisfy
the formula, if such an automaton exists. In general, creating
such an automaton is proven to be doubly exponential in the
size of the formula [33]. However, by restricting ourselves to the
special class of LTL formulas, we can use the efficient algorithm
that was recently introduced in [13], which is polynomial O(n3 )
time, where n is the size of the state space. Each state in this
framework corresponds to an allowable truth assignment for the
set of sensor and robot propositions. In Example 1, an allowable
state is one in which, for example, the proposition r1 is true,
and all of the other propositions are false. However, a state in
which both r1 and r2 are true is not allowed (violates the mutual
exclusion formula) as is a state in which sNem o and r2 are true
(the environment assumptions state that Nemo cannot be seen
in region 2). Section IX discusses further problem sizes and
computability.
In the following, the synthesis algorithm is informally introduced, see [13] for a full description.
The synthesis process is viewed as a game played between
the robot and the environment (as the adversary). Starting from
some initial state, both the robot and the environment make decisions that determine the next state of the system. The winning
condition for the game is given as a GR(1) formula φ. The way in
which this game is played is that at each step, first, the environment makes a transition according to its transition relation, and
then, the robot makes its own transition. If the robot can satisfy
φ, no matter what the environment does, we say that the robot is
winning, and therefore, we can extract an automaton. However,
if the environment can falsify φ, we say that the environment is
winning and the desired behavior is unrealizable.
Relating the formulas of Section III-B to the game mentioned
previously, the initial states of the players are given by ϕei and
ϕsi . The possible transitions that the players can make are given
by ϕet and ϕst , and the winning condition is given by the GR(1)
formula φ = (ϕeg ⇒ ϕsg ). Note that the system is winning, i.e.,
φ is satisfied if ϕsg is true, which means that the desired robot
behavior is satisfied, or ϕeg is false, which means that the environment did not reach its goals (either because the environment
was faulty or the robot prevented it from reaching its goals). This
implies that when the environment does not satisfy ϕeg , there is
no guarantee about the behavior of the robot. Furthermore, if
the environment does not “play fair,” i.e., violates its assumed
behavior ϕei ∧ ϕet , the automaton is no longer valid.

KRESS-GAZIT et al.: TEMPORAL-LOGIC-BASED REACTIVE MISSION AND MOTION PLANNING

The synthesis algorithm [13] takes the formula ϕ and first
checks whether it is realizable. If it is, then the algorithm extracts a possible (but not necessarily unique) automaton, which
implements a strategy that the robot should follow in order to
satisfy the desired task. The automaton that is generated by the
algorithm is modeled as a tuple A = (X , Y, Q, Q0 , δ, γ).
1) X is the set of input (environment) propositions.
2) Y is the set of output (robot) propositions.
3) Q ⊂ N is the set of states.
4) Q0 ∈ Q is the set of initial states.
5) δ : Q × 2X → 2Q is the transition relation, i.e.,
δ(q, X) = Q ⊆ Q, where q ∈ Q is a state and X ⊆ X
is the subset of sensor propositions that are true.
6) γ : Q → 2Y is the state labeling function, where γ(q) =
y, and y ⊆ Y is the set of robot propositions that are true
in state q.
An admissible input sequence is a sequence X1 ,
X2 , . . . , Xj ∈ 2X that satisfies ϕe . A run of this automaton
under an admissible input sequence is a sequence of states
σ = q0 , q1 , . . .. This sequence starts at some initial state q0 ∈ Q0
and follows the transition relation δ under the truth values of the
input propositions, i.e., for all j ≥ 0, we have qj +1 ∈ δ(qj , Xj ).
An interpretation of a run σ is a sequence y0 , y1 , . . ., where
yi = γ(qi ) is the label of the ith state in the run. We use this
sequence of labels to construct the discrete path that the robot
must follow and to activate/deactivate the different robot actions. As mentioned before, when given a nonadmissible input
sequence, i.e., an input sequence that violates any part of ϕe ,
the automaton is no longer relevant, and we will not be able to
construct a correct path for the robot.
Using this synthesis algorithm, there are several ways to extract an automaton that satisfies the LTL formula. It can either
be made to be deterministic, i.e., for every input, there will be
a unique next state, or nondeterministic, as is the case in this
paper. Furthermore, the automaton can be one that always takes
the “fastest route” toward the goals, i.e., reaches the goals in
the minimum number of transitions, as in this paper, or one that
allows all possible routes, even longer ones, as long as they
eventually satisfy the task.
Example 2: Revisiting Example 1, Fig. 3 represents the synthesized automaton that realizes the desired behavior. The circles represent the states of the automaton, and the propositions
that are written inside each circle are the state’s label, i.e., the
output propositions that are true in that state. The possible initial
states are shown as filled circles. The edges are labeled with the
sensor propositions that must be true in order for the transition
to be made. Edges with no labels are thus labeled with ¬sNem o .
As can be seen, the automaton causes the robot to stay where
it is and turn the camera ON if it senses Nemo; otherwise, the
robot will keep searching for Nemo, with the camera OFF, forever. Note that this automaton is not unique and is nondeterministic. Furthermore, this automaton can only be executed if
the environment (Nemo) is behaving according to the assumptions. Thus, if the robot suddenly senses Nemo in region 9, the
automaton will not have a suitable transition.
From the interpretation of a run of the automaton, we extract
a discrete path for the robot based on the location propositions.

Fig. 3.

1375

Synthesized automaton of Example 2.

What is left to do is to transform this discrete path into a continuous trajectory, as is explained in the next section.
V. CONTINUOUS EXECUTION
In order to continuously implement the discrete solution of the
previous section, we construct a hybrid controller that takes a set
of simple controllers and composes them sequentially according
to the discrete execution of the automaton.
Following the work in [5], we utilize atomic controllers that
satisfy the so-called bisimulation property [31], [32], [34]. Such
controllers are guaranteed to drive the robot from one region to
another, regardless of the initial state in the region. There are
several recent approaches for generating such simple controllers,
such as [8], [10], [20], [35], and [36]. We use the framework
developed in [8] due to its computational properties and the
variety of regions it can be applied to. In this approach, a convex
polygon is mapped to the unit disk, then Laplace’s equation
is solved (in closed form) on the disk, obtaining the potential
function, and finally, the solution is mapped back to the polygon.
This approach resembles the navigation functions introduced
in [37].
The algorithm for executing the discrete automaton is shown
in Algorithm 1. Initially, the robot is placed at position p0 in
region i such that ri ∈ γ(q0 ), where q0 is the initial automaton state satisfying q0 ∈ Q0 . Furthermore, based on all other

1376

IEEE TRANSACTIONS ON ROBOTICS, VOL. 25, NO. 6, DECEMBER 2009

Fig. 4. Possible run of the automaton of Example 2. (a) Nemo is sensed in
region 5. (b) Nemo disappeared; therefore, the robot continues the search. (c)
Robot continues to search regions 1, 3, 5, and 8.

region 5, and therefore, it stays there and turns on its camera,
which is indicated by the magenta squares. Then, as depicted in
Fig. 4(b), Nemo disappears, and the robot resumes the search.
It then continues to search all the regions of interest, as seen in
Fig. 4(c).
propositions γ(q0 ), the appropriate robot actions are activated.
At each step, the robot senses its environment and determines
the values of the binary inputs X . Based on these inputs and its
current state, it chooses a successor state N xtState and extracts
the next region N xtReg, where it should go from γ(N xtState).
Then, it invokes an atomic controller that drives it toward the
next region. If the robot enters the next region in this step, then
the execution changes the current automaton state, extracts the
appropriate actions, and activates/deactivates them. If the robot
is neither in the current region nor in the next region, which
could happen only if the environment violated its assumptions,
then the execution is stopped with an error.
This continuous execution is bisimilar to the discrete execution of the automaton that resembles the continuous execution
of a sequence of discrete states that was presented in [5] and [7].
Note that in the type of automaton that is extracted in this paper,
i.e., in which the next state is the one that advances the robot
the most toward its goals, an action might not be turned on/off
simultaneously with the sensor input change. In other words,
the change in the action might occur only when the robot enters
a new region. This may be avoided by extracting an automaton
that does not have to make progress at each step, but this is not
within the scope of this paper.
This kind of execution allows the robot to react in real time
to changing environment conditions as opposed to the approach
taken in [11], where it is assumed that the robot senses only when
it makes a transition in the automaton (enters a new region).
Example 3: Fig. 4 depicts a possible execution of the automaton synthesized in Example 2. Here, the robot starts in region
3 and searches for Nemo. In Fig. 4(a), the robot finds Nemo in

VI. GUARANTEES AND GENERALIZATIONS
The method presented in this paper is guaranteed, under some
conditions, to generate correct robot behavior. These conditions
can be divided into two groups. The first group refers to tasks,
or formulas, that are unrealizable. These formulas cannot be
synthesized into an automaton either because they are logically
inconsistent, for example, “Go to region 1 and never leave region 4,” or they are topologically impossible, for example, a
task that requires the robot to move between two unconnected
regions in the workspace, or the environment, has a strategy that
prevents the robot from achieving its goals.2 If the formula is
unrealizable, the synthesis algorithm will inform the user that it
is impossible to satisfy such a task.
The second group refers to tasks that are realizable, i.e., there
exists an automaton that realizes them; however, the execution
of this automaton is not correct. This can happen only if the environment behaves “badly” or if it either violates the assumptions
encoded in ϕe , for example, a sensor proposition becomes true
when the formula states it cannot, or it causes the robot to violate
its possible transitions, for example, if someone picks the robot
up and moves it to a different region. In these cases, it is most
likely that the automaton will not have any valid transitions left,
and the execution will halt. Note that while the satisfaction of the
assumptions on the environment is crucial for correct behavior,
these assumptions can be very general and nonrestrictive.
The introduced framework can be extended very easily to
handle different robot models. By choosing controllers that are
2 The

synthesis of the controller is done in a worst-case approach.

KRESS-GAZIT et al.: TEMPORAL-LOGIC-BASED REACTIVE MISSION AND MOTION PLANNING

1377

Fig. 5. Animal herding. (a) Cat is found. (b) Robot herds the cat to its meeting region, without going through the NoCats regions, by trailing yarn. It ignores
dogs sensed along the way. (c) Dog is sensed immediately after leaving the cats meeting region. It is then herded to the dogs region. A mouse is sensed along the
way. (d) Robot herds both the dog and the mouse to the dogs meeting region. (e) Mouse is herded to its meeting region. A dog is sensed. (f) Mouse stays at its
meeting region and the dog is being herded.

guaranteed to drive a robot with a more complex model from one
region to an adjacent one without going through any other region, we obtain the same guarantees of correctness, for example,
we can handle robots with car-like nonholonomic constraints by
employing the controllers in [36]. Note that we can only guarantee correctness and completeness if there exists a discrete
abstraction of the workspace and a set of bisimilar controllers
corresponding to the robot dynamics and the abstraction.
Furthermore, some of the assumptions made in this paper,
e.g., the partition of the workspace, can be relaxed. For this approach, we need to encode possible motion of the robot using
binary propositions that correspond to the activation of different controllers. Whether such controllers correspond to moving
between two regions in a partition of the workspace or moving
between overlapping regions does not change the synthesis and
execution of the automaton. The only difference would be that
one would have to be careful when specifying that areas that
may now belong to the domain of several controllers should
not be reached. Relaxing the partition requirement allows us to
use controllers for convex-bodied nonholonomic robots, such as
in [9], as we have done in [38].
VII. SINGLE-ROBOT SCENARIO—ANIMAL HERDING
One of the strengths of this approach is the ability to generate a complex behavior from a large set of simple instructions
or rules. The automatically generated controller is guaranteed
to obey all given rules, as long as they are consistent, as opposed to the handwritten code that may contain functional,
structural, and design-software bugs. Furthermore, if the set

of rules is inconsistent, the algorithm will stop without creating
the controller, which indicates that the desired rule set cannot be
implemented.
This scenario, which is presented as an example for a complex
task, includes a robot that is moving in a workspace that has 35
connected regions, as shown in Fig. 5. The robot’s goal is to herd
dogs, cats, and mice to their respective meeting points, which
are denoted in the figure by Dogs, Cats, and Mice. In order to
do that, the robot can show a bone to the dogs, trail a piece
of yarn for the cats, and play a flute for the mice. The animals
can appear anywhere in the workspace other than the meeting
places, and while an animal is being herded, it might choose
not to follow the robot and, thus, may no longer be sensed by
the robot. We impose further restrictions on the behavior of the
robot, which are as follows.
1) The robot cannot herd a dog and a cat simultaneously.
2) The robot cannot herd a cat and a mouse simultaneously.
3) Unless there are no animals, the robot must herd at least
one animal at any given time.
4) The robot cannot herd a cat through “NoCats” regions.
5) The robot cannot herd a mouse through “NoMice.”
6) The robot must start herding a dog when it senses one,
unless it is already herding a cat.
7) When sensing a dog and a cat, the dog is to be herded.
8) When sensing a cat and a mouse, the cat is to be herded.
9) The robot must start herding a cat when it senses one,
unless it is already herding a mouse or it senses a dog.
10) The robot should continue herding an animal until it
reaches its meeting region or it disappears and should
not switch between animals randomly.

1378

IEEE TRANSACTIONS ON ROBOTICS, VOL. 25, NO. 6, DECEMBER 2009

In the original set of rules, restriction 9 stated that “the robot
must start herding a cat unless it is already herding a mouse”
without any mention of a dog that may be spotted at the same
time as the cat. This is inconsistent with requirements 1 and 6,
and therefore, no automaton was generated.
In order to encode this behavior, the set of sensor propositions
was X = {sdog , scat , sm ouse }, and the set of robot propositions
was Y = {r1 , . . . , r35 , ab one , ayarn , aﬂute }.3 For lack of space,
we omit the full LTL formula, and only demonstrate how some
of the requirements were encoded.
All the aforementioned restriction are encoded as part of ϕst ,
and here, we show restrictions 1, 3, 5, and 6 as

(¬(	ab one ∧ 	ayarn ))




dog

∨ 	scat ∨ 	sm ouse )

 ((	s
⇒ (	ab one ∨ 	ayarn ∨ 	aﬂute ))




(	aﬂute ⇒ ¬ 	 r20 ))



((	sdog ∧ (¬(ayarn ∧ 	scat ))) ⇒ 	ab one )
where region 20 is the “NoMice” region.
The robot must search the space for animals, and once it
encounters one, it must herd it to its meeting region. This requirement is encoded as part of ϕsg , where the search of each
region is encoded as
♦(ri ∨ sdog ∨ scat ∨ sm ouse )
which means that region i should be searched unless an animal
is sensed, and the herding is encoded as


♦(r1 ∨ ¬ab one ) ♦(r32 ∨ ¬ayarn ) ♦(r36 ∨ ¬aﬂute )
which means that the robot should go to the dogs’ (cats’ or
mice’s) meeting region if the robot is showing a bone (trailing
yarn or playing the flute), i.e., herding a dog (cat or mouse).
Fig. 5 shows a sample run of the generated automaton. The
robot starts by searching the space. It encounters a cat (a) and
proceeds to trail yarn, indicated by the large (blue) dots. It herds
the cat to its meeting region (b), while ignoring dogs that are
present along the way. Furthermore, the robot causes the cat to
reach its meeting region without going through the “NoCats”
regions. Immediately after leaving the cats’ meeting region, the
robot encounters a dog and proceeds to herd it to its meeting
region by showing it a bone, indicated by small (red) dots.
Along the way, it finds a mouse (c) and starts playing the flute
as well, which is indicated by the light (red) stars. The robot,
now herding both a dog and a mouse, first goes to the dogs’
meeting region (d), drops the dog there, and continues, with
the mouse, to the mice’s meeting region. Along the way, it sees
another dog (e), and after dropping the mouse off, it takes the
dog to its meeting place (f).
VIII. MULTIROBOT SCENARIOS
This section illustrates that our framework naturally captures
multirobot scenarios where one robot becomes part of the environment of another robot. In a natural decentralized model,
3 When coding this example, the regions are encoded as binary vectors instead
of separate proposition. Here, we continue with this notation for clarity.

each robot (or subgroup of robots) is tasked by its own formula
ϕi , resulting in its own synthesized automaton. In this case, the
coordination between robots (groups) can be done using sensor
propositions.
We illustrate this approach with the following example. In the
workspace shown in Fig. 2, two robots are placed in regions 1,
2, or 3, independently. The desired behavior is “First, Robot 1
goes looking for Nemo in regions 1, 3, 5, and 8, while Robot
2 stays in place. Once Robot 1 finds him, it stays in place and
turns on its camera. Robot 2 then comes and joins them, and
turns on its light. If Nemo disappears again, Robot 1 resumes
the search with the camera OFF, and Robot 2 stays where it is,
but turns OFF its light.”
Example 4: We write one formula for each robot, thus
creating a separate automaton for each robot. Note that
the behavior of Robot 1 is identical to the behavior of the
robot in Example 1. Following that example, we define one
environment proposition sNem o and 13 robot propositions
{r1 , . . . , r12 , aCam eraON }, which refers to the robot’s location
and action. In order to allow communication between the
robots (allowing Robot 1 to inform Robot 2 whether Nemo
was found and where), we add four more robot propositions:
{aSendNem oIn1 , aSendNem oIn3 , aSendNem oIn5 , aSendNem oIn8 }.
These propositions encode the action of transmitting a message
saying that Nemo was found in a certain region. Since the
motion of Robot 1 and activation of the camera is the same as
the behavior of the robot in Example 1, formula ϕ1 encoding
Robot 1’s behavior is ϕ in this example, with additional
subformulas that take care of the new robot propositions.
The requirement that proposition aSendNem oIni is true, i.e.,
the robot sends a message that Nemo is in region i, if and only
if Robot 1 is in region i and it senses Nemo, is encoded as part
of ϕs1 as
 s
ϕi , (from Example 1)


 s

ϕ , (from Example 1)


 t

Nem o

) ⇔

  ((r1 ∧ 	s
s
ϕ1 =
((r3 ∧ 	sNem o ) ⇔



 ((r5 ∧ 	sNem o ) ⇔






((r8 ∧ 	sNem o ) ⇔


 s
ϕg , (from Example 1).

	aSendNem oIn1 )
	aSendNem oIn3 )
	aSendNem oIn5 )
	aSendNem oIn8 )

For the formula ϕ2 , which describes the desired behavior of Robot 2, we define four environment propositions
{sNem oIn1 , sNem oIn3 , sNem oIn5 , sNem oIn8 }, which indicate that
Nemo was found in regions 1, 3, 5, and 8, respectively.
Similar to Example 1, we define 13 robot propositions
{r1 , . . . , r12 , aLightON } that refer to the robot’s location and
action. For ϕe2 , we make the following assumptions about the
environment: Initially, Nemo is not sensed; hence, initially, all
environment propositions are set to False; furthermore, since
Nemo can only be in one place at a time, at most, one environment proposition can be True at any time. These assumptions

KRESS-GAZIT et al.: TEMPORAL-LOGIC-BASED REACTIVE MISSION AND MOTION PLANNING

1379

are encoded in ϕe2 as

(¬sNem oIn1 ∧ ¬sNem oIn3 ∧ ¬sNem oIn5 ∧ ¬sNem oIn8 )



  ((¬ 	 sNem oIn1 ∧ ¬ 	 sNem oIn3






∧¬ 	 sNem oIn5 ∧ ¬ 	 sNem oIn8 ) ∨





(	sNem oIn1 ∧ ¬ 	 sNem oIn3





∧¬ 	 sNem oIn5 ∧ ¬ 	 sNem oIn8 ) ∨




(¬ 	 sNem oIn1 ∧ 	sNem oIn3
ϕe2 =

∧¬ 	 sNem oIn5 ∧ ¬ 	 sNem oIn8 ) ∨





(¬ 	 sNem oIn1 ∧ ¬ 	 sNem oIn3





∧ 	 sNem oIn5 ∧ ¬ 	 sNem oIn8 ) ∨





(¬ 	 sNem oIn1 ∧ ¬ 	 sNem oIn3





∧¬ 	 sNem oIn5 ∧ 	sNem oIn8 ))



♦(True).
The desired robot behavior is encoded in ϕs2 . Initially, Robot
2 starts somewhere in region 1, 2, or 3 with the light OFF, and
hence

(r ∧
¬r ∧ ¬aLightON )

 1 i∈{2,···,12} i
(r2 ∧i∈{1,3,···,12} ¬ri ∧ ¬aLightON )
ϕsi2 =


(r3 ∧i∈{1,2,4,···,12} ¬ri ∧ ¬aLightON ).
The first two lines of ϕst2 describe the transitions and mutual exclusion, as discussed before. Line 3 states that whenever
Robot 2 is in region i ∈ {1, 3, 5, 8} and Nemo is sensed there,
it should stay where it is. Line 4 forces Robot 2 to have the light
ON whenever it is region i and Nemo is sensed there. Line 5
requires the light to be OFFwhenever Robot 2 is not in the same
region as Nemo. The last subformula requires Robot 2 to stay
where it is whenever Nemo is not sensed by Robot 1.

Possible Transitions Between Regions






Mutual Exclusion of Regions





Nem oIni

) ⇒ 	ri )

i∈{1,3,5,8} ((ri ∧ 	s




Nem oIni

) ⇒ 	aLightON )
i∈{1,3,5,8} ((	ri ∧ 	s
ϕst2 = 

 ((¬(∨i∈{1,3,5,8} (	ri ∧ 	sNem oIni ))) ⇒





¬ 	 aLightON )






( (∧i∈{1,3,5,8} ¬ 	 sNem oIni ) ⇒



(∧i∈{1,...,12} (ri ⇔ 	ri ))).
The final part of the formula ϕsg 2 requires Robot 2 to visit
region i ∈ {1, 3, 5, 8} infinitely often if Nemo is sensed in that
region

♦(sNem oIni ⇒ ri ).
ϕsg 2 =
i∈{1,3,5,8}

The synthesized automaton for Robot 1 has the same number
of states and the same transitions as the automaton in Example
2. The only difference is that in this example, the robot propositions aSendNem oIn5 , i ∈ {1, 3, 5, 8} are added as labels to the
relevant states. The synthesized automata for Robot 2 satisfying
ϕ2 contains 55 states and is omitted here.
A possible execution of these automata is depicted in Fig. 6,
where the robots start in regions 3 and 2, respectively. Robot 1

Fig. 6. Possible run of the multirobot scenario of Example 4. (a) Robot 1 is
searching for Nemo, and Robot 2 stays in region 2. (b) Robot 1 finds Nemo in
region 5, and Robot 2 goes to join him. (c) Robot 2 joins Robot 1 in region 5
and turns the light ON. (d) Nemo disappears, and therefore, Robot 1 resumes the
search, and Robot 2 stays where it is.

begins by searching for Nemo, while Robot 2 stays in region 2,
as seen in Fig. 6(a). In Fig. 6(b), Robot 1 finds Nemo in region
5 and, therefore, stays there and turns on its camera, which is
indicated by the magenta squares. Finding Nemo in region 5
causes Robot 2 to move to that region as well. When Robot 2
arrives in region 5, as depicted in Fig. 6(c), it turns on its light,
which is indicated by the black triangles. Finally, in Fig. 6(d),
Nemo disappears. This causes Robot 1 to turn camera OFF and
resume the search, while Robot 2 turns off the light and stays in
place.
When considering multirobot behaviors, here, we assume that
there are no timing or concurrency constraints, such as two
robots that must reach a room at the exact same time. Such
constraints are difficult to guarantee in a purely decentralized
framework and might require a different approach.
IX. DISCUSSION
In this paper, we have described a method of creating controllers that drive a robot, or a group of robots, such that it
satisfies a high-level user-specified behavior. These behaviors
are expressed in a subset of LTL, and can capture reactive tasks
in which the robot’s behavior depends on the local information
sensed from the environment during runtime. These behaviors
are guaranteed to be satisfied by the robots if the environment
in which they are operating behaves “well,” i.e., it adheres to
the assumptions made about it. We have shown that many complex robot behaviors can be expressed and computed, both for
a single robot and for multiple robots.
Writing LTL formulas, especially ones that conform to
the structure presented in Section III-B, requires some experience and is not always intuitive. Therefore, we plan to
explore more user-friendly interfaces, as well as linguistic

1380

IEEE TRANSACTIONS ON ROBOTICS, VOL. 25, NO. 6, DECEMBER 2009

formalisms, that can be easily translated to the required logic
representation.
Another issue that we wish to address is that of computability.
As mentioned in Section IV, the synthesis algorithm is polynomial in the state space, but this space may be exponential in the
number of inputs and outputs. Currently, we can generate an
explicit representation of an automaton that has 50 000 states
in about an hour (an automaton with a few hundred states takes
a few seconds to compute) on a regular desktop; however, by
moving to a symbolic representation and examining hierarchical
approaches, we believe that we can tackle problems of a larger
scale.
Finally, we intend to experiment with different controllers
and various robots in order to gain a good intuition regarding the variety of tasks and the interplay between the
robot dynamics, its behavior, and the appropriate discrete
abstractions.
ACKNOWLEDGMENT
The authors would like to thank D. Conner, for sharing with
the code for the potential field controllers, and N. Piterman, A.
Pnueli, and Y. Sa’ar for fruitful discussions and for sharing their
code for the synthesis algorithm.
REFERENCES
[1] H. Choset, K. M. Lynch, L. Kavraki, W. Burgard, S. A. Hutchinson,
G. Kantor, and S. Thrun, Principles of Robot Motion: Theory, Algorithms,
and Implementations. Boston, MA: MIT Press, 2005.
[2] S. M. LaValle, Planning Algorithms. Cambridge, U.K.: Cambridge
Univ. Press, 2006.
[3] S. Russell and P. Norvig, Artificial Intelligence, A Modern Approach, 2nd
ed. Englewood Cliffs, NJ: Prentice-Hall, 2003.
[4] C. Belta, A. Bicchi, M. Egerstedt, E. Frazzoli, E. Klavins, and G. J. Pappas, “Symbolic planning and control of robot motion: State of the art
and grand challenges,” Robot. Autom. Mag., vol. 14, no. 1, pp. 61–70,
2007.
[5] G. E. Fainekos, H. Kress-Gazit, and G. J. Pappas, “Temporal logic motion
planning for mobile robots,” in Proc. IEEE Int. Conf. Robot. Autom.,
Barcelona, Spain, 2005, pp. 2020–2025.
[6] G. E. Fainekos, H. Kress-Gazit, and G. J. Pappas, “Hybrid controllers
for path planning: A temporal logic approach,” in Proc. 44th IEEE Conf.
Decis. Control, Dec. 2005, pp. 4885–4890.
[7] M. Kloetzer and C. Belta, “A fully automated framework for control of
linear systems from temporal logic specifications,” IEEE Trans. Autom.
Control, vol. 53, no. 1, pp. 287–297, Feb. 2008.
[8] D. C. Conner, A. A. Rizzi, and H. Choset, “Composition of local potential
functions for global robot control and navigation,” in Proc. IEEE/RSJ
Int. Conf. Intell. Robots Syst., Las Vegas, NV, Oct. 2003, pp. 3546–
3551.
[9] D. Conner, H. Choset, and A. Rizzi, “Integrated planning and control for convex-bodied nonholonomic systems using local feedback control policies,” presented at the Robot.: Sci. Syst., Cambridge, MA, Jun.
2006.
[10] S. Lindemann and S. LaValle, “Computing smooth feedback plans over
cylindrical algebraic decompositions,” presented at the Robot.: Sci. Syst.,
Cambridge, MA, Jun. 2006.
[11] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Where’s Waldo?
Sensor-based temporal logic motion planning,” in Proc. IEEE Int. Conf.
Robot. Autom., Rome, Italy, 2007, pp. 3116–3121.
[12] E. A. Emerson, “Temporal and modal logic,” in Handbook of Theoretical
Computer Science (vol. B): Formal Models and Semantics, Cambridge,
MA: MIT Press, 1990, pp. 995–1072
[13] N. Piterman, A. Pnueli, and Y. Sa’ar, “Synthesis of reactive(1) designs,”
in Proc. VMCAI, Jan. 2006, pp. 364–380.
[14] R. W. Brockett, “On the computer control of movement,” in Proc. IEEE
Int. Conf. Robot. Autom., Apr. 1998, vol. 1, pp. 534–540.

[15] V. Manikonda, P. S. Krishnaprasad, and J. Hendler, Languages, Behaviors,
Hybrid Architectures, and Motion Control. New York: Springer-Verlag,
1999.
[16] D. Hristu-Varsakelis, M. Egerstedt, and P. S. Krishnaprasad, “On the
structural complexity of the motion description language MDLe,” in
Proc. 42nd IEEE Conf. Decis. Control, Dec. 2003, vol. 4, pp. 3360–
3365.
[17] F. Delmotte, T. R. Mehta, and M. Egerstedt, “Modebox a software tool
for obtaining hybrid control strategies from data,” Robot. Autom. Mag.,
vol. 15, no. 1, pp. 87–95, 2008.
[18] E. Frazzoli, M. A. Dahleh, and E. Feron, “Maneuver-based motion planning for nonlinear systems with symmetries,” IEEE Trans. Robot., vol. 21,
no. 6, pp. 1077–1091, Dec. 2005.
[19] S. B. Andersson and D. Hristu, “Symbolic feedback control for navigation,” IEEE Trans. Autom. Control, vol. 51, no. 6, pp. 926–937, Jun.
2006.
[20] C. Belta and L. C. G. J. M. Habets, “Constructing decidable hybrid systems
with velocity bounds,” in Proc. IEEE Conf. Decis. Control, 2004, pp. 467–
472.
[21] S. R. Lindemann and S. M. LaValle, “Smoothly blending vector fields
for global robot navigation,” in Proc. IEEE Conf. Decis. Control, Seville,
Spain, 2005, pp. 207–214.
[22] S. Ramamoorthy and B. Kuipers. (2004). Controller synthesis using qualitative models and simulation, in Proc. International Workshop on Qualitative Reasoning (QR-2004), J. de Kleer and K. Forbus, Eds. [Online].
Available: http://www.qrg.cs.northwestern.edu/qr04/papers.html.
[23] G. Pola, A. Girard, and P. Tabuada, “Approximately bisimilar symbolic
models for nonlinear control systems,” Automatica, vol. 44, no. 10,
pp. 2508–2516, 2008.
[24] M. Antoniotti and B. Mishra, “Discrete event models + temporal logic =
supervisory controller: Automatic synthesis of locomotion controllers,”
in Proc. IEEE Int. Conf. Robot. Autom., 1995, pp. 1441–1446.
[25] T. Moor and J. M. Davoren, “Robust controller synthesis for hybrid systems using modal logic,” in Hybrid Systems: Computation and Control,
(Lecture Notes in Computer Science 2034). New York: Springer-Verlag,
2001, pp. 433–446
[26] J. M. Davoren and T. Moor, “Logic-based design and synthesis of controllers for hybrid systems,” Dept. Syst. Eng, Aust. Nat. Univ., Canberra,
A.C.T., Australia, Tech. Rep., 2000.
[27] L. de Alfaro, T. A. Henzinger, and R. Majumdar, “From verification to
control: Dynamic programs for omega-regular objectives,” in Proc. 16th
Annu. Symp. Logic Comput. Sci., Los Alamitos, CA: IEEE Comput. Soc.
Press, Jun. 2001, pp. 279–290.
[28] P. Bouyer, L. Bozzelli, and F. Chevalier, “Controller synthesis for MTL
specifications,” in CONCUR (Lecture Notes in Computer Science 4137),
C. Baier and H. Hermanns, Eds. New York: Springer-Verlag, 2006,
pp. 450–464.
[29] P. Tabuada and G. J. Pappas, “Linear time logic control of discrete-time
linear systems,” IEEE Trans. Autom. Control, vol. 51, no. 12, pp. 1862–
1877, Dec. 2006.
[30] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, 2009.
[31] R. Milner, Communication and Concurrency. Upper Saddle River, NJ:
Prentice-Hall, 1989.
[32] E. M. Clarke, O. Grumberg, and D. A. Peled, Model Checking.
Cambridge, MA: MIT Press, 1999.
[33] A. Pnueli and R. Rosner, “On the synthesis of a reactive module,” in Proc.
16th ACM SIGPLAN-SIGACT Symp. Principles Program. Languages,
Toronto, ON, Canada: ACM Press, 1989, pp. 179–190
[34] R. Alur, T. A. Henzinger, G. Lafferriere, and G. J. Pappas, “Discrete
abstractions of hybrid systems,” Proc. IEEE, vol. 88, no. 7, pp. 971–984,
Jul. 2000.
[35] L. C. G. J. M. Habets and J. H. van Schuppen, “A control problem for
affine dynamical systems on a full-dimensional polytope,” Automatica,
vol. 40, no. 1, pp. 21–35, 2004.
[36] S. R. Lindemann and S. M. LaValle, “Smooth feedback for car-like vehicles in polygonal environments,” in Proc. IEEE Conf. Robot. Autom.,
2007, pp. 3104–3109.
[37] E. Rimon and D. E. Kodischek, “Exact robot navigation using artificial
potential functions,” IEEE Trans. Robot. Autom., vol. 8, no. 5, pp. 501–
518, Oct. 1992.
[38] D. C. Conner, H. Kress-Gazit, H. Choset, A. A. Rizzi, and G. J. Pappas,
“Valet parking without a valet,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots
Syst., San Diego, CA, Oct. 2007, pp. 572–577.

KRESS-GAZIT et al.: TEMPORAL-LOGIC-BASED REACTIVE MISSION AND MOTION PLANNING

Hadas Kress-Gazit (S’06–M’09) received the
Ph.D.degree in electrical and systems engineering
from the University of Pennsylvania, Philadelphia,
in 2008.
She is currently an Assistant Professor with Sibley
School of Mechanical and Aerospace Engineering,
Cornell University, Ithaca, NY. Her current research
interests include creating verifiable robot controllers
for complex high-level tasks using logic, verification
methods, synthesis, hybrid systems theory, and computational linguistics.
Dr. Kress-Gazit was a finalist for the Best Student Paper Award at the 2007
IEEE International Conference on Robotics and Automation and a finalist for
the 2007 Best Paper Award at the International Conference on Intelligent Robots
and Systems.

Georgios E. Fainekos (S’04–M’08) received the
Ph.D. degree in computer and information science
from the University of Pennsylvania, Philadelphia, in
2008.
He was a Postdoctoral Researcher with the the System Analysis and Verification Group, NEC Laboratories America, Inc., where he was engaged in cyberphysical systems. Since August 2009, he has been an
Assistant Professor with the School of Computing,
Informatics, and Decision Systems Engineering, Arizona State University, Tempe. His current research
interests include formal methods and logic, control theory and hybrid, and embedded and real-time systems with applications to robotics and unmanned aerial
vehicles.
Dr. Fainekos was a finalist for the Best Student Paper Award at the 2007
IEEE International Conference on Robotics and Automation and a recipient of
the 2008 Frank Anger Memorial Association for Computing Machinery Special Interest Group on Embedded Systems/Special Interest Group on Software
Engineering Student Award.

1381

George J. Pappas (S’90–M’91–SM’04–F’09) received the Ph.D. degree in electrical engineering and
computer sciences from the University of California,
Berkeley, in 1998.
He was the former Director of the General Robotics, Automation, Sensing and Perception
(GRASP) Laboratory, University of Pennsylvania,
Philadelphia, where he is currently a Member of
GRASP, the Deputy Dean with the School of Engineering and Applied Science and is the Joseph Moore
Professor with the Department of Electrical and Systems Engineering. He is also with the Department of Computer and Information
Sciences and the Department of Mechanical Engineering and Applied Mechanics. His current research interests include hybrid and embedded systems,
hierarchical control systems, distributed control systems, nonlinear control systems, and geometric control theory, with applications to robotics, unmanned
aerial vehicles, and biomolecular networks.
Prof. Pappas has received numerous awards, including the National Science
Foundation (NSF) CAREER Award in 2002, the NSF Presidential Early Career
Award for Scientists and Engineers in 2002, and the Eliahu Jury Award for
Excellence in Systems Research from the Department of Electrical Engineering
and Computer Sciences, University of California at Berkeley, in 1999.

2015 IEEE International Conference on
Automation Science and Engineering (CASE)
Aug 24-28, 2015. Gothenburg, Sweden

DisCoF+ : Asynchronous DisCoF with Flexible Decoupling for
Cooperative Pathfinding in Distributed Systems
Kangjin Kim, Joe Campbell, William Duong, Yu Zhang and Georgios Fainekos
which implies that all robots have access to the current
positions of the other robots, their individual plans and
goals. With this information, any robot can consider all other
robots when creating its own plan. While this assumption
can be made in many common applications of cooperative
pathfinding where planning can be centralized and performed
offline (e.g., cooperative pathfinding in computer games), it
does not hold in distributed systems with limited sensing and
communication range.
In our prior work [23], we introduced a window-based
approach, called DisCoF, for cooperative pathfinding in
distributed systems with limited sensing and communication
range. In DisCoF, the window size corresponds to the sensing
range of the robots. Robots can communicate with each other
either directly if in range or indirectly if out of range. In
the latter case, it is still possible to communicate indirectly
through other robots using a communication relay protocol.
This allows for coordination beyond a single robot’s sensor
range.
To ensure completeness, DisCoF uses a flexible approach
to decoupling robots such that they can transition from
optimistic to pessimistic decoupling when necessary. Robots
are assumed to be fully decoupled initially. During the
online pathfinding process, robots only couple together when
necessary (i.e., when there are predictable conflicts [23]).
Since access to global communication and coordination is
not assumed, the creation of local couplings (i.e., subsets
of robots) may not be sufficient to avoid live-locks. In such
cases, a mechanism (called push and pull) is introduced in
which robots in a local coupling can form a coupling group
[23] in order to coordinate more closely. Robots in a coupling
group move to their goals sequentially in a certain order
while keeping others (i.e., those that have not yet reached
their goals) within communication range. Coupling groups
may increase in size (e.g., when previously undetected robots
come within sensing range of a robot in the coupling group)
and decrease in size (e.g., when robots reach their goals).
This mechanism can potentially lead to a global coupling.
Contributions: In this paper, first, we introduce an asynchronous variant of DisCoF, refereed to as DisCoF+ , in
order to remove DisCoF’s assumption that time steps are
synchronized.2 That is, we provide an asynchronous algorithm and its communication strategy. Then, we introduce
a new decoupling strategy in DisCoF+ with the goal of

Abstract— In our prior work, we outlined an approach,
named DisCoF, for cooperative pathfinding in distributed systems with limited sensing and communication range. Contrasting to prior works on cooperative pathfinding with completeness
guarantees which assume access to global communication and
coordination, DisCoF does not make this assumption. The
implication is that at any given time in DisCoF, the robots
may not all be aware of each other which is often the
case in distributed systems. As a result, DisCoF represents
an inherently online approach since coordination can only
be realized in an opportunistic manner between robots that
are within each other’s sensing and communication range.
However, there are a few assumptions made in DisCoF to
facilitate a formal analysis which must be removed to work
with distributed multi-robot platforms. In this paper, we present
DisCoF+ which extends DisCoF by enabling an asynchronous
solution, as well as providing flexible decoupling between robots
for performance improvement. Furthermore, we evaluate our
implementation of DisCoF+ by implementing our distributed
multi-robot algorithm in the Webots simulator. Finally, we
compare DisCoF+ with DisCoF in terms of plan quality and
planning performance.

I. INTRODUCTION
While cooperative pathfinding in multi-robot systems has
many applications, it is also fundamentally hard to solve
(i.e., PSPACE-hard [6]). The difficulty lies in the potential coupling between robots: when robots are completely
decoupled (e.g., when robots do not impose constraints
on each other’s plan to the goal), cooperative pathfinding
becomes polynomial-time solvable.1 As a result, most recent
approaches (e.g., [15], [16], [17], [18]) for pathfinding concentrate on how to identify the dependencies between robots
in order to couple robots only when necessary.
In these approaches, the solution is constructed for a subset
of the robots which are coupled to each other and which
are decoupled from the remaining robots. The computational
complexity is exponential only in the maximum number of
robots in these subsets. While optimistic decoupling can lose
optimality and even completeness (e.g., [16]), pessimistic
decoupling can only handle situations in which robots are
loosely coupled (e.g., [17]).
Meanwhile, to ensure completeness, these approaches often assume access to global communication and coordination
This work has been partially supported by NSF award CNS-1116136
and CNS-1446730, the ARO grant W911NF-13-1-0023, the ONR grants
N00014-13-1- 0176, N00014-13-1-0519 and N00014-15-1-2027.
K. Kim, J. Campbell, W. Duong, Y. Zhang and G. Fainekos
are with the School of Computing, Informatics and Decision
Systems Engineering, Arizona State University, Tempe, AZ
85281,
USA
{Kangjin.Kim, jacampb1, tbduong,

2 This is achieved in DisCoF for all robots by 1) maintaining a
synchronized clock at the beginning of the task and 2) limiting each robot
to have the same planning and execution time at each step. However, this
is generally too strong an assumption to make in a distributed system.

Yu.Zhang.442, fainekos}@asu.edu
1

A single robot pathfinding problem is polynomial-time solvable.

978-1-4673-8183-3/15/$31.00 ©2015 IEEE

369

improving efficiency. In DisCoF, only a directional transition
from optimistic to pessimistic decoupling is allowed. On
the other hand, DisCoF+ allows bi-directional transitions
between optimistic and pessimistic decoupling.
Furthermore, for evaluation, we first demonstrate a simulation of DisCoF+ in a distributed multirobot environment
modeled in Webots. Then, we compare the performance of
DisCoF and DisCoF+ in terms of computation time and
length of plans on randomly generated environments.

III. D IS C O F
In this section, we provide the problem formulation and
we review DisCoF [23]. Extensions to DisCoF, DisCoF+ ,
are discussed in Section IV.
A. Problem Formulation
We assume that the workspace is represented by a undirected graph G(V, E). We assume the existence of a set of
robots R with initial positions I ⊆ V and goal positions
G ⊆ V . Any robot can move to any adjacent vertex in
one time step or remain where it is. A plan P is a set of
individual plans of robots, and P[i] denotes the individual
plan for robot i ∈ R. Each individual plan is composed of a
finite sequence of actions. For simplicity, in this paper, each
action is represented by the next vertex to be visited. For
example, Pk [i] (k ≥ 1) denotes the action to be taken at
time step k − 1 (or the vertex to be visited at k) for robot i.
Pk,l [i] (k ≤ l) denotes the subplan that contains the actions
from Pk [i] to Pl [i].
The goal of cooperative pathfinding is to find a plan
P, such that robots start in I and end in G without any
collisions.
A set of locations of robots R at time step k is denoted
by Sk and a location of each robot i ∈ R at time step k is
denoted by Sk [i] for convenience. If robots R execute plan
P from a set of locations S to another set of locations S 0 , it
P
is denoted by S ; S 0 . Likewise, if a robot i ∈ R executes
its plan P[i] from a location S[i] to another location S 0 [i],

II. RELATED WORK
To address the cooperative pathfinding problem, researchers have used a complilation approach [9], [1], [5],
[22], in which the problem is first transformed into other
related problems, and then the existing solutions or algorithms for these problems can be applied. Abstraction
methods to reduce the search space have also been used
[19], [14]. However, due to the inherent complexity of the
problem, these approaches do not scale. While approaches
that constrain the topologies of the environment [21], [12],
[13] can significantly reduce the complexity, they cannot be
applied to general problem instances.
Given that pathfinding for a single robot is polynomialtime solvable, the complexity of multi-robot pathfinding is
a result of coupling between robots. Then, researchers have
studied on various ways to decouple robots. For approaches
that perform optimistic decoupling, robots are considered
as coupled only when necessary. One of the representative
approaches is hierarchical cooperative A∗ (HCA∗ [16]) in
which robots plan one at a time while respecting plans that
have already been computed. To limit the influence of the
previous robots on the following robots, a windowed HCA∗
is introduced to restrict this influence based on a pre-specified
window size [16]. Recently, an extension of WHCA∗ (COWHCA∗ [2]) was introduced to further reduce this influence
based on the notion of conflicts. Although many problem
instances can be solved efficiently, optimistic decoupling
leads to loss of optimality and completeness.
One of the earlier approaches that performs decoupling
while maintaining optimality and completeness relies on
pessimistic decoupling [17] and [20]. That work couples
robots when conflicts are detected in the individual robot
plans. As a result, the approach tends to over-couple and,
hence, remains intractable for many problem instances. More
recent approaches relax optimality to achieve better efficiency [10], [4], [18]. However, to maintain completeness,
these approaches assume access to global communication
and coordination and therefore are inapplicable to distributed
systems in which robots have limited sensing and communication range.
While there are extensible approaches to distributed systems (e.g., [7]) and approaches that are designed for distributed systems (e.g., [11], [3]), they do not provide completeness guarantees. The difficulty lies in planning without
access to global communication and coordination. This is
further discussed in [23].

P[i]

P

it is denoted by S[i] ; S 0 [i]. In addition, given S ; S 0 ,
P[i]

we denote S 0 as S(P), and given S[i] ; S 0 [i], we denote
P
S 0 [i] as S[i](P[i]). Hence, S0 = I, S0 ; G, G = S0 (P),
P1,k

S0 ; Sk and Sk = S0 (P1,k ), and for some robot i ∈ R,
P[i]

P1,k [i]

S0 [i] = I[i], S0 [i] ; G[i], G[i] = S0 [i](P[i]), S0 [i] ;
Sk [i] and Sk [i] = S0 [i](P1,k [i]).
A conflict happens at time step k, if the following is
satisfied:
Sk [i] = Sk [j] ∨ (Sk [i] = Sk−1 [j] ∧ Sk−1 [i] = Sk [j]) (1)
in which i, j ∈ R and i 6= j. In other words, if two robots
move to the same place at time k or two robots switch their
locations in one consecutive time step (from k − 1 to k),
then we have a conflict. This definition of conflict can be
generalized to capture other conditions.
Each robot has a planner that can compute a shortest path,
P (u, v) that moves a robot from vertex u to v. The length of
P (u, v) is denoted as C(u, v), i.e., C(u, v) = |P (u, v)|. The
following simplifying assumptions are also made in DisCoF:
1) Robots are homogeneous and equipped with a communication protocol for message relay.
2) Robots know G and are synchronized at every time step.
Initially, for each robot i, the individual plan is constructed
as P[i] = P (I[i], G[i]). Robots then start executing their
individual plans until conflicts can be predicted (i.e., predictable conflicts in [23]) at time step k. In such cases, the
individual plans of the robots which will lead to conflicts are
updated in Pk+1 to avoid these conflicts.
370

r1
r2
r2

r2,r3

r2

r2,r3

r2

r2,r3,
r4

r2,r3

r3

r3,r4

r3,r4

r1

r1

r1

r1

C. Pessimistic Decoupling
In DisCoF, when there are potential live-locks, robots
within an OC transition to pessimistic decoupling by remaining within each other’s communication range (whether direct
or indirect). These robots are referred to as a coupling group,
and this coupling group executes a process known as push
and pull which allows it to merge with other groups and
robots. Thus, the level of coupling gradually increases. In
this way, DisCoF can naturally transition robots to be fully
coupled when necessary.
In push and pull, robots move to goals one at a time
according to the priorities of subproblems (first introduced
in [4]). However, due to the incompleteness of information
in distributed systems, the priorities will not be fully known.
As a result, DisCoF employs the following process. At time
step k, for each coupling group that has been formed, DisCoF
will:
1) Maintain robots in the group within each other’s communication range.
2) Move robots to goals one at a time based on a relaxed
version of the priority ordering which is consistent to
that in [4].
3) Add other robots or merge with other groups that
introduce potential conflicts with robots in the current
group as they move to their goals.
Unless there are potential conflicts, each coupling group
progresses independently of other robots and coupling
groups.
In [23], we proved that the combination of optimistic and
pessimistic decoupling in DisCoF guarantees completeness.3

r1
r2
r3,r4

r4

r4

r4

Fig. 1. [23]: Scenario that illustrates OC and IC. Two OCs are present {r1 }
and {r2 , r3 , r4 }, out of which one has an IC {r3 , r4 } with a predictable
conflict. The sensing ranges of the robots are shown in gray. The arrows
show the next few steps in the individual plans.

B. Optimistic Decoupling
In DisCoF, the window size corresponds to the sensing
range of the robot. To reduce communication overhead, a
robot is only allowed to communicate with other robots when
it can sense them. However, robots that cannot sense each
other can communicate using the message relay protocol
through other robots. A closure of the set of robots that
can communicate (directly or via message relay) in order to
coordinate is called an outer closure (OC). In an OC, there
can be multiple predictable conflicts. A closure that contains
agents with potential conflicts is the inner closure (IC) of the
OC. Figure 1 shows an example of OC and IC. For details,
refer to [23].

IV. D IS C O F+

In DisCoF, decoupling is optimistic initially, and gradually
becomes more pessimistic when necessary. Given an OC
with predicted conflicts, in optimistic decoupling DisCoF
updates the individual plans of robots to proactively resolve
these conflicts, while avoiding introducing new conflicts
within a finite horizon (which is specified by a parameter
in DisCoF). The finite horizon is key to efficiency since the
resolution for conflicts in the far future is likely to waste
computation efforts given the incomplete information (e.g.,
the positions of other robots in the environment). Note that
the window size, i.e., sensing range, in DisCoF represents a
horizon for detecting conflicts.

In this section, we discuss the extensions to DisCoF that
are made in the new approach named DisCoF+ . First, we
relax the assumption that robots synchronize at every time
step (or plan step). Note that even though robots in different
OCs cannot communicate in DisCoF, it is assumed that
robots act in synchronized time steps. That is, robots are
given a fixed amount of time to finish planning and execute
a single action at every time step. The relaxation of this
synchronization is necessary for implementation in a real
distributed system because we cannot always assume the
existence of a global clock and a fixed amount of time for
each time step (e.g., the time required for planning for each
robot may be arbitrarily different).
We remark that each robot can still access the entire
map. We can assume that this information is static such
that it is initially given and does not change.4 However,
each robot cannot recognize where other robots are if they
are out of (indirect) communication and sensing range. This
information is dynamic such that it changes arbitrarily.

To ensure that robots are jointly making progress towards
their goals, DisCoF uses the notion of contribution value.
In order to resolve conflicts, plans are updated in a process
known as conflict resolution. In this process, each robot is
associated with a contribution value when using optimistic
decoupling. If this process is successful, robots continue
as fully decoupled. The contribution value is also used to
determine cases when optimistic decoupling is insufficient.
That is, when the resolution process would fail due to
potential live-locks. When there are no potential live-locks,
it is shown that optimistic decoupling is sufficient for robots
to converge to their goals. Otherwise, robots within the OC
use the following pessimistic decoupling process.

3 DisCoF is complete for the class of cooperative pathfinding problems
in which there are two or more unoccupied vertices in each connected
component which is an extension of results in [4].
4 Our replanning framework can be extended to partially known environments with unknown static obstacles.

371

Algorithm 1 DisCoF+ with asynchronous time steps
for a robot i ∈ R, given the environment G =
(V, E, {i}, I[i], G[i]), its initial location I[i], final destination
G[i] and initial plan P[i] from I[i] to G[i] and local window
W; γ denotes the contribution values.
1: hψ, φ, ω, S[:], W, γ[:], ki ← h∅, ∅, ∅, ∅, ∅, 0, 0i
2: S[i] ← I[i]
. Update the current location to I[i]
3: G[: i − 1] ∪ G[i + 1 :] ← ∅ . Initialize goals for others
4: P[: i − 1] ∪ P[i + 1 :] ← ∅ . Initizliae plans for others
5: G0 ← (V, E, ∅, S, G)
6: hS, Wi ← P ROCEED O NE S TEP (G0 , P, i, k)
7: while True do
8:
hψ, φi ← S ENSE C ONFLICT(P, i, S, k, W)
9:
if ψ = ∅ then
10:
k ←k+1
. Increase the time step k by 1
11:
G0 ← (V, E, ω, S, G)
12:
hS, Wi ← P ROCEED O NE S TEP(G0 , P, i, k)
13:
G0 ← (V, E, ω, S, G) . Update G0 with new S
14:
hγ, ω, Pi ← R ECOMPUTE C ONT(G0 , P, i, k, γ)
15:
else
16:
if ω 6= ∅ then
. It meets another group.
17:
ω ←ω∪φ
. Merge ω with OC φ
18:
G0 ← (V, E, ω, S, G)
19:
P 0 ← P USH A ND P ULL(G0 , i, γ)
20:
else
21:
ω←ψ
. Set ω to IC ψ
22:
G0 ← (V, E, ω, S, G)
23:
P 0 ← C ONVERGENCE(G0 , i, k, φ, P, W, γ)
24:
if |P 0 | = 0 then
25:
ω←φ
. Set ω to OC φ
26:
G0 ← (V, E, ω, S, G)
27:
P 0 ← P USH A ND P ULL(G0 , i, γ)
28:
if P 0 = ∅ then
29:
return False
30:
P[ω] ← P1,k [ω] + P 0 [ω]
31: return True

Furthermore, we introduce a new decoupling strategy
such that robots are also allowed to decouple after they
form a coupling group (i.e., executing push and pull); thus,
transitioning back to optimistic decoupling from pessimistic
decoupling. This strategy makes DisCoF+ more computationally efficient while achieving higher quality plans that
require fewer steps.5

A. Asynchronous Time Steps
Unlike DisCoF, DisCoF+ allows robots in different OCs to
proceed independently and asynchronously. However, robots
within the same OC are assumed to still have synchronized
plan steps. This is a reasonable assumption because these
robots communicate to coordinate with each other. As a
result of this assumption, robots who finish their current plan
step must wait until all others in the OC also finish theirs.
Afterwards, all members of the group start the next plan
step at the same time in order to avoid unnecessary conflicts.
We remark that since we assume homogeneous robots, the
waiting time at each time step is not significant.6
We now explain Alg. 1. First, all variables including a set
of current locations S and a set of current local window
W are initialized and updated until line 6. Then, while
progressing its own plan P, it senses a conflict at line 8.
If a conflict is not detected, then it progresses the next step
at line 12. If a conflict is detected, then it resolves the conflict
and updates the current plan P with the new plan P 0 from
line 16 to line 30. If a conflict is detected such that the IC
ψ is not empty, robot i tries to resolve the conflict after
checking if it is already involved in any conflicts at line
16. If ω is not empty at line 16, it means that from the
previous iterations, ω has been already assigned. Then, at
the current iteration, another conflict is detected. That is, a
coupling group meets another coupling group while resolving
its conflict. Then, it merges the ω with an current OC φ
and begins P USH A ND P ULL in order to resolve it through
pessimistic decoupling process.7 If ω is empty, then it means
that it hasn’t involved any conflict yet. That is, robot i ∈ R
was executing its plan independently. Then, it forms a local
coupling ω. It first tries to decouple optimistically through
C ONVERGENCE. If it cannot find a plan P 0 , then it decouples
pessimistically through P USH A ND P ULL. After finding a plan
P 0 , it continues to the next iteration to sense if there are new
conflicts. In this way, the above process continues until it

reaches its goal.8
We need to explain some codes and procedures in details.
First, in order to simplify each procedure, at line 5, 11, 13,
18, 22 and 26, we use G0 as a tuple of V , E, ω, S and
G. Here, V and E are from the workspace G = (V, E) , ω
is a set of robots which represents a coupling group, S is
a set of current locations, and G is a set of goal locations.
Second, given a tuple G0 , a set of plans P, a robot i ∈ R,
and i’s local time step k, P ROCEED O NE S TEP returns a set
of current locations S and a current location window W.
We remark that P ROCEED O NE S TEP does not increase the
time step variable k. If k is not increased before calling
P ROCEED O NE S TEP, like line 6, then it does not update the

5 How efficient this strategy is depends on the problem instance. Robots
in a denser environment may need frequent coupling and decoupling, thus
increasing the computation overhead. This is discussed in Sec. V through
simulation experiments.
6 Heterogeneous robots may have different speed, sensing & communication range, size and etc. Considering these issues and resolving them are
beyond the scope of this paper.
7 We remark that our description of P USH A ND P ULL in Alg. 1 is
simplified to show the overall process. Once P USH A ND P ULL returns a new
plan P 0 in Alg. 1, it contains the individual plans for the coupling group
ω to move from their locations at the time step k to their goals.

8 Due to lack of global communication and coordination, our algorithm
(running on each robot) would not be able to determine whether all other
robots have reached their goals, thus we cannot compute a termination
condition. In our simulation, we stop the programs (on all robots) when
they have reached their goals.

372

current locations S with the set of plan P. However, it is
required to be called because the current local window W
should be updated before sensing a predictable conflict at
line 8. Third, given a set of plans P, a robot i ∈ R, a
current set of locations S, i’s local time step k and the
current local window W, S ENSE C ONFLICT returns a tuple
of an IC ψ and an OC φ. If no conflict is detected, the
IC ψ is empty. Regardless of the existence of conflicts,
S ENSE C ONFLICT also returns an OC φ. This may require
to communicate with other agents (we will explain in the
next subsection). Fourth, the contribution value γ is used in
R ECOMPUTE C ONT, C ONVERGENCE and C ONVERGENCE.
In the next subsection, we will explain the details about how
to update the contribution value γ and how the contribution
value γ affects the set of plans P.
Correctness: For Alg. 1, we need to show two conditions.
First, if a given problem instance is valid (solvable), robot
i ∈ R eventually reaches its goal location. If there is no
conflict from the initial location I[i] to its goal location G[i],
it can progress through its plan while sensing conflicts at
line 8 and proceeding one step at line 12 until it reaches
its goal. Whenever there is a conflict, it always computes a
valid plan. At line 16, robot i checks if it is already involved
in a conflict (with ω). If ω 6= ∅ (i.e., it is already involved
in a conflict), it merges the OC (i.e., φ in Alg. 1) with ω,
and then call P USH A ND P ULL for i. In line 24, if P 0 is not
empty, it means that C ONVERGENCE returns a new plan P 0 .
If P 0 is empty, then robot i calls P USH A ND P ULL. In both
cases, the returned plan P 0 is either from C ONVERGENCE
or P USH A ND P ULL. We have shown that C ONVERGENCE or
P USH A ND P ULL always returns a valid plan in [23] if a valid
solution exists.
Second, if a given problem instance is invalid (unsolvable), Alg. 1 returns False. In order to resolve a conflict,
Alg. 1 first calls C ONVERGENCE at line 23 which is for
optimistic decoupling in DisCoF. Then, if it cannot compute
its new plan, it calls P USH A ND P ULL at line 27 which
is for pessimistic decoupling. In [23], we showed DisCoF
guarantees the completeness, and DisCoF uses these two
conflict resolution processes in order to resolve its conflict.
Hence, if a solution exists, the combination of these two
processes returns a solution. However, if a solution does not
exists, it returns False. At line 28, it can check whether it
returns a solution or not. If not, it returns false.
We remark that P ROCEED O NE S TEP in line 12 always
results in the robot proceeding one step forward in its plan.
If robot i has already reached its final goal (while there are
robots that still need to reach their goals), proceeding one
step in this case simply adds a step for robot i to stay.

2) Compute the OC φ of robot i.
3) Communicate with robots in φ to obtain their plans,
then check if predictable conflicts exist among them.
In the above process, the first step does not require any
communication between robots; it only depends on sensors.
Since robots know the environment (i.e., G), they can easily
detect when there are moving robots nearby using range
sensors.
The second step requires the use of a message relay
protocol to compute the OC φ. This is because OC φ includes
robots which cannot directly communicate with the robot i
which originally tried to determine its OC φ. Even though
it computed an OC φ in its previous time step, the OC φ
can be changed whenever S ENSE C ONFLICT is called. This
is because each robot in the OC has its own asynchronous
time if it is not involved in any conflicts and it can update
its OC without considering other members. In this way, if
one of the members in the OC moves out of its neighbors’
sensing range before communicating with its neighbors,
other members cannot update their own OC. In addition,
if each member in an OC is involved in a conflict, all the
members have a synchronized time step until reaching their
local goals. In this case, computing a new OC is still required
because each member of the OC can meet another group
and each member can update their own OC propagating new
information to each other. Hence, whenever each agent calls
S ENSE C ONFLICT, it should communicate with others so that
it can update its OC.
In the third step, once robot i obtains all the plans of
the robots in φ, it can check these plans against its own
plan for predictable conflicts (from its current time step to
the next β steps [23]). In this case, after electing a leader
of the IC ψ, the leader computes the new plan for the IC
ψ and communicates the new plan back to the others in
the IC.9 In order to compute a new plan, the leader tries
C ONVERGENCE. If C ONVERGENCE returns a valid set of
plans P 0 , then the leader can pass P 0 to others. If not, the
leader begins P USH A ND P ULL. However, in P USH A ND P ULL
a new leader is selected which is based on the priorities of
subproblems. Then, the new leader will send the new plan
P 0 (which is computed from P USH A ND P ULL) back to others
in the OC φ.
The second case in which robots communicate is to
synchronize planning and execution among robots in an OC.
Note that robots in different OCs proceed independently and
asynchronously. Since planning and plan execution are synchronized within an OC, it is guaranteed that no collision can
occur among robots in the OC. In P ROCEED O NE S TEP, each
robot in the OC executes a single plan step, communicates
this to the rest of the robots in the OC (through broadcasting
to the local network), and then it halts. Only after all robots in
the OC have completed a plan step are they free to execute

B. Communication and Leader Selection
There are two major cases in which robots communicate
with each other in DisCoF+ . The first case is to detect
predictable conflicts. For detecting conflicts, given a robot
i ∈ R, S ENSE C ONFLICT requires the following steps:
1) Check nearby environment (i.e., W) through a sensor
for other robots (e.g., a laser sensor).

9 The simplest voting mechanism is to elect the robot with the smallest
ID in the group.

373

another, thus achieving synchronization.10 However, when
robots move out of the communication range, they do not
synchronize their plan steps anymore.

An interesting point of Eq. (2) is that the new plan Q may
not satisfy Eq. (2) during the execution of Q, as long as Eq.
(2) is satisfied after Q has completed. After executing the
new local plan Q, each agent reaches its local goal. In this
way, they avoid the predicted conflict. Then, each robot i ∈ φ
can decouple, following its individual plan from the local
goal Sk [i](Q[i]) to its goal G[i]. Given a predicted conflict
at the current time step and a computed Q, the contribution
value γ while executing the actions in Q is updated for robot
i in φ as follows:

C. Flexible Decoupling
Flexible decoupling is achieved with the help of contribution values. Contribution values are assigned in DisCoF
to each robot in the C ONVERGENCE process (in optimistic
decoupling) in which the robots must compute an update
to the current plan to avoid potential conflicts. Contribution
values are introduced in DisCoF to ensure that robots are
jointly making progress to their goals. In DisCoF, when the
C ONVERGENCE process fails, robots are in a coupling group,
running on the plan computed by P USH A ND P ULL until they
reach their goals. In DisCoF+ , however, robots that are
executing P USH A ND P ULL can also decouple by checking
whether certain conditions involving the contribution values
hold.
Next, we discuss the new decoupling strategy in DisCoF+
which is illustrated in the following example. Suppose that
a conflict is predicted between two robots. Then, an IC ψ
(initially including only the two robots) is formed and there
is an associated OC φ for ψ. When the leader of ψ makes a
new plan in the C ONVERGENCE process, if the leader cannot
find a new plan that avoids the conflict with the current set
of conflicting robots ψ, then the set of conflicting robots
gradually expends (until becoming φ). When a new plan is
found, DisCoF+ associates each robot with a contribution
value γ which captures the individual contribution of the
robot to the summation of shortest distances from all robots’
current locations to their goal locations.
For the remaining part of this section, we will use the
cost relation C : V × V → N. For example, C(v1 , v2 ) is the
distance of the shortest path from node v1 to node v2 .
At the very beginning of a problem instance, the contribution value γ is initialized to be 0 for all robots. Given a
predictable conflict at time step k, a set of conflicting robots
φ, the set of current locations Sk for φ and the set of goal
locations G, the new plan Q (where |Q| < β ∈ N)11 must
avoid collisions and satisfy the following:
X
X
C(Sk [i], G[i]) + γk− [i] >
C(Sk [i](Q[i]), G[i]) (2)
i∈φ

γk+δ [i] = C(Sk [i](Q[i]), G[i]) − C(Sk+δ [i], G[i])

(3)

where 0 ≤ δ ≤ |Q| and Sk+δ [i] = Sk [i](Q1,1+δ [i]). We
remark that δ is a relative time step after the robots have
formed an OC. For all robots in a group, δ is the same. This
update continues until the robot become involved in other
conflicts or the value becomes 0.
In DisCoF [23], the contribution value γ is only used
for the C ONVERGENCE process, and robots do not update
their contribution values when a coupling group is formed
and robots start P USH A ND P ULL. This can lead to inefficient
behaviors, e.g., when the leader’s goal location is located
opposite to where the others’ goals are located.
In DisCoF, the only way to reduce the size of a coupling
group is to have the current leader reach its goal. Then, a
new leader will be selected and the remaining robots will
follow the new leader to its goal. This is clearly an inefficient
solution. In DisCoF+ , we use the contribution values γ
also in P USH A ND P ULL, such that robots can decouple even
before the leader reaches its goal.
Next, we discuss how the contribution values can be
used in the P USH A ND P ULL process. More specifically, we
provide a decoupling condition for a coupling group to check
which determines when the robots in the group can decouple
while executing the P USH A ND P ULL process. Suppose that
there is a coupling group ω. After ω computes a new plan
P 0 (in P USH A ND P ULL), each robot in ω will progress using
the plan. During this execution, robots continue recomputing
their contribution values γ as in Eq. (3). At any step, if the
following condition holds, then the group can be decoupled:
X
X
C(Sk [i], G[i]) + γk− [i] >
C(Sk+δ [i], G[i]) (4)
i∈ω

i∈φ

i∈ω

where k is the time step when P USH A ND P ULL starts planning and k + δ is the current time step such that 0 < δ ∈ N.
γk− [i] is the contribution value that robot i ∈ ω had before
the P USH A ND P ULL returned its plan.
Intuitively, Eq. (4) is the condition when the summation of
the length of the shortest-path from robots’ current locations
to their goal locations is less than the summation of the
length of the shortest-path from their original coupling
locations to their goal locations plus their contribution values
just before forming the coupling group.
In Alg. 1, Eq. (4) is checked inside of R ECOMPUTE C ONT
at line 14. Given a set of current locations S, a set of
goal locations G, and contribution values γ, if the condition
holds, then R ECOMPUTE C ONT returns an updated plan P

where γk− [i] is the contribution value that is associated with
robot i at the time step k and Sk [i](Q[i]) is a local goal for
each i ∈ φ, i.e., the position reached by each robot i after
executing plan Q[i].
We remark that while k in Eq. (2) is a constant in DisCoF,
in DisCoF+ , k represents the synchronized current time step
for the group of robots within φ which may differ between
OCs.
10 We assume that in a fixed amount time, each robot can complete its
own movement and within the communication range there is no problem to
communicate with each other.
11 We assume that the length of the plan Q is bigger than β. If the
length of some agent i’s plan Q[i] has shorter than β, then the last state
Sk [i](Q[i]) should be appended at the end of Q[i] until |Q[i]| ≥ β.

374

(i.e., the shortest-path plan from S[i] to G[i]) with an empty
coupling group ω. Then, the coupling group ω becomes
decoupled and each robot follows their individual plan.
Otherwise, R ECOMPUTE C ONT returns the current plan P
without changing the coupling group ω. Then, the coupling
group ω follows the current plan P which was computed
from P USH A ND P ULL.
When a coupling group is decoupled and it immediately
predicts a conflict in the next iteration, it uses the conflict
resolution process through C ONVERGENCE, just as when
fully decoupled robots have predicted conflicts. Even though
we discussed the correctness of DisCoF+ (Alg. 1), we also
need to show that this new decoupling strategy is not subject
to live-locks (i.e., robots are always making joint progress
to the goals).
Theorem 4.1: The decoupling condition in Eq.(4) ensures
that robots in the group gradually progress to their final goals.
Proof: For detail, see [8].

Fig. 2. A simulation environment in Webots modeling a 20 × 20 grid
world with a 10% wooden boxes as obstacles. In this environment, there
are 30 iRobot Create finding their path to their goal positions.

terms of the maximum steps, enabling decoupling took only
74% of the steps than without decoupling. The reason for this
discrepancy is that with decoupling enabled there are more
stay actions in which a robot’s action is to stay where it is.
Since robots are asynchronous except for when they are in
a conflict, this means robots will take less time to complete
a plan with stay actions compared to one that doesn’t. It
is expected that environments which remains more complex
plans will benefit from this fact even more.
We provide the demo video for this simulation
(which is also submitted as an attachment to this paper). In addition, you may refer to the videos at the
following URL: https://www.assembla.com/spaces/
discof/wiki/DisCoF_Plus.

V. RESULTS
In this section, we present some experimental results.
First, we will show a simulation result on a physics based
simulator. Second, we will provide results from numerical
experiments on artificial benchmarks.
A. Simulation in Webots

B. Simulation Experiments on benchmarks

The simulation shown in Fig. 2 was created using Webots 7.3.0 and the included iRobot Create models. A grid
environment was modeled which contained 30 iRobots and
40 obstacles placed at random locations. This instance is
solvable, i.e., each robot can reach its goal position. Each
iRobot was running with a controller which implemented
DisCoF+. However, one exception was made: rather than
being completely distributed and simulating ad hoc networks
and localization, the robots communicated with a central
supervisor which provided this information as well as synchronization for robots involved in a conflict, i.e., in the
same OC. Robots in different outer closures acted completely
asynchronously, but robots in the same outer closure were
synchronized if a conflict was detected between any of the
member robots.
The target computer for the simulation was a MacBook
Pro running Mac OS X 10.10.2 with a 2.3GHz i7 and
16GB of RAM. The simulation was run two times: once
with decoupling enabled and once with decoupling disabled.
Decoupling enabled yielded a total simulation duration of
3 minutes and 23 seconds. Out of all robots, the maximum
number of steps required to reach their destination was 40.
When decoupling was disabled, it yielded a total simulation
duration of 5 minutes and 1 second. Out of all robots, the
maximum number of steps required to reach their destination
was 54.
These results are interesting in two aspects: the total
running time and the number of maximum steps. First, in
terms of the total running time, enabling decoupling performs
significantly better than without decoupling. The simulation
took only 67% of the time that the other did. Second, in

In order to evaluate the improvement of DisCoF+ over
DisCoF, we execute a number of numerical experiments. For
these experiments, we used a 3.2GHz i7 and 8GB of RAM
in Cygwin environment which runs on Windows 8.1. Our
prototype implementation is written in Python 2.7.2.
Since we only want to get the total number of concurrent
steps and the computation time for these experiments, instead
of using the Webots simulator, we used a simple discrete
time simulator which does not simulate the physics of the
robots. In addition, we have not computed the overhead
of any communication between the robots. Hence, we are
comparing the total number of steps and the computation
times between DisCoF and DisCoF+ .
As a result of this implementation, an approximate running
time is calculated for each problem instance by summing
the computation time and the movement time, where the
movement time is the amount of time required to execute
all steps assuming 5 seconds per step.
In order to perform the experimental analysis, instead of
scaling up the number of robots, we increase the density of
the environment. That is, we increase obstacle rates in the
environment. The experiment was performed on a 20 × 20
grid environment with 30 robots. Obstacles were randomly
generated according to their rate which is defined as the
percentage of the grid environment that is considered to be
an obstacle. Table I shows the results for 100 instances of
DisCoF and DisCoF+ as the obstacle rate was varied from
5% to 20%.
In all cases, DisCoF+ needed 24% to 42% less steps than
DisCoF’s result and DisCoF+ took 25% to 43% less than
375

OBSTACLES
5%
10%
15%
20%

COMP.
AVG
10.064
13.19
17.6318
26.39

TIME
STD
8.405
10.372
13.296
14.009

DisCoF
STEPS
AVG
STD
352.35 356.207
521.1
521.24
653.67
580.01
954.46
620.08

APPROX. RUN TIME
AVG
STD
1771.815
1788.861
2618.69
2615.82
3285.982
2911.463
4798.691
3111.208

COMP. TIME
AVG
STD
10.733 (1.0086) 22.068 (0.931)
14.37 (1.061)
36.52 (1.538)
23.92 (1.217)
49.768 (1.3)
52.391 (1.942)
75.8 (2.3989)

DisCoF+ (DisCoF+ /DisCoF)
STEPS
AVG
STD
63.95 (0.4266)
80.632 (0.356)
73.51 (0.344)
108.93 (0.346)
99.18 (0.294)
157.356 (0.312)
175.9192 (0.2427) 218.859 (0.3132)

APPROX. RUN TIME
AVG
STD
330.483 (0.43)
423.885 (0.3555)
381.92 (0.348)
579.065 (0.348)
519.82 (0.3)
831.07 (0.314)
931.987 (0.2535) 1161.61 (0.3242)

TABLE I
S IMULATION E XPERIMENTS : C OMP. T IME REPRESENTS THE TOTAL COMPUTATION TIME IN SEC , S TEPS REPRESENTS CONCURRENT TIME STEPS FOR
ENTIRE ROBOTS ’ PLAN , AND A PPROX . RUN T IME REPRESENTS APPROXIMATE RUNNING TIME IN SEC . AVG STANDS FOR AVERAGE AND STD FOR
STANDARD DEVIATION . T HE RATIO INSIDE THE PARENTHESIS IS D IS C O F + /D IS C O F.

DisCoF’s approximate run time.
The time ratio in Table I indicates that if the environment
is less populated, then decoupling makes better quality plans
in terms of the total number of concurrent steps and the total
computation time of plans.
Despite the fact that DisCoF+ consistently outperforms
DisCoF in the approximate run time, it is important to
comment on the computation time. When the environment
is dense, it takes more computation time. This is because in
dense environments groups that decouple may have to recouple with a higher frequency. That is, when it recouples,
a group should make a new plan which requires extra
computation time.

[7] R. Jansen and N. Sturtevant. A new approach to cooperative pathfinding. In Proceedings of the 7th International Joint Conference on
Autonomous Agents and Multiagent Systems, AAMAS, pages 1401–
1404, Richland, SC, 2008. International Foundation for Autonomous
Agents and Multiagent Systems.
[8] K. Kim, J. Campbell, W. Duong, Y. Zhang, and G. Fainekos.
DisCoF+ : Asynchronous DisCoF with flexible decoupling for cooperative pathfinding in distributed systems.
Technical report,
http://arxiv.org/abs/1506.03540.
[9] L. Liu and D. A. Shell. Physically routing robots in a multi-robot
network: Flexibility through a three-dimensional matching graph. The
International Journal of Robotics Research, 32(12):1475–1494, 2013.
[10] R. Luna and K. Bekris. Efficient and complete centralized multirobot
path planning. In IEEE/RSJ Int. Conf. on IROS, 2011.
[11] M. Otte, J. Bialkowski, and E. Frazzoli. Any-com collision checking:
Sharing certificates in decentralized multi-robot teams. In Proceedings
of the 2014 IEEE ICRA.
[12] L. E. Parker. Encyclopedia of Complexity and System Science, chapter
Path Planning and Motion Coordination in Multiple Mobile Robot
Teams. Springer, 2009.
[13] M. Peasgood, C. Clark, and J. McPhee. A complete and scalable
strategy for coordinating multiple robots within roadmaps. IEEE
Transactions on Robotics, 24(2):283–292, April 2008.
[14] M. Ryan. Graph decomposition for efficient multi-robot path planning.
In Proceedings of the 20th International Joint Conference on Artifical Intelligence, pages 2003–2008, San Francisco, CA, USA, 2007.
Morgan Kaufmann Publishers Inc.
[15] G. Sharon, R. Stern, A. Felner, and N. R. Sturtevant. Conflict-based
search for optimal multi-agent pathfinding. Artificial Intelligence,
219(0):40 – 66, 2015.
[16] D. Silver. Cooperative pathfinding. In Conference on Artificial
Intelligence and Interactive Digital Entertainment, 2005.
[17] T. Standley. Finding optimal solutions to cooperative pathfinding
problems. In AAAI Conference on Artificial Intelligence, 2010.
[18] T. Standley and R. Korf. Complete algorithms for cooperative
pathfinding problems. In Proceedings of the 22nd International Joint
Conference on Artifical Intelligence, 2011.
[19] N. Sturtevant and M. Buro. Improving collaborative pathfinding using
map abstraction. In Artificial Intelligence and Interactive Digital
Entertainment (AIIDE), pages 80–85, 2006.
[20] G. Wagner, M. Kang, and H. Choset. Probabilistic path planning for
multiple robots with subdimensional expansion. In IEEE International
Conference on Robotics and Automation, ICRA, 2012.
[21] K. C. Wang and A. Botea. Fast and memory-efficient multi-agent
pathfinding. In International Conference on Automated Planning and
Scheduling, pages 380–387, 2008.
[22] J. Yu and S. M. LaValle. Multi-agent path planning and network flow.
In Algorithmic Foundations of Robotics X, volume 86, pages 157–173.
Springer, 2013.
[23] Y. Zhang, K. Kim, and G. Fainekos. Discof: Cooperative pathfinding
in distributed systems with limited sensing and communication range.
In to appear in International Symposium on Distributed Autonomous
Robotic Systems, 2014.

VI. CONCLUSIONS
In this paper, we introduced DisCoF+ which is an asynchronous extension of our previous work. We also introduced
a strategy of decoupling in DisCoF+ . Through simulations,
we showed how DisCoF+ works in a simulated grid environment to resolve predictable conflicts in a distributed fashion.
We also provided simulation experiments to compare DisCoF
with DisCoF+ . In moderately populated environments, the
decoupling approach shows better results than DisCoF. In
future work, we plan to devise different approaches for
decoupling and, also, heuristics for ordering robots while
performing P USH A ND P ULL so that when at any point in
time a decoupling occurs, the conflicts are minimized.
R EFERENCES
[1] N. Ayanian, D. Rus, and V. Kumar. Decentralized multirobot control in
partially known environments with dynamic task reassignment. In 3rd
IFAC Workshop on Distributed Estimation and Control in Networked
Systems, 2012.
[2] Z. Bnaya and A. Felner. Conflict-oriented windowed hierarchical
cooperative A∗ . In Proceedings of the 2014 IEEE International
Conference on Robotics and Automation, 2014.
[3] C. Clark, S. Rock, and J.-C. Latombe. Motion planning for multiple
mobile robots using dynamic networks. In Proceedings of the IEEE
International Conference on Robotics and Automation, volume 3,
pages 4222–4227, Sep. 2003.
[4] B. de Wilde, A. W. ter Mors, and C. Witteveen. Push and rotate: Cooperative multi-agent path planning. In 12th International Conference
on Autonomous Agents and Multiagent Systems, 2013.
[5] V. R. Desaraju and J. P. How. Decentralized path planning for multiagent teams with complex constraints. Autonomous Robots, 32(4):385–
403, 2012.
[6] J. Hopcroft, J. Schwartz, and M. Sharir. On the complexity of motion
planning for multiple independent objects; pspace- hardness of the
”warehouseman’s problem”. The International Journal of Robotics
Research, 3(4):76–88, 1984.

376

2013 IEEE International Conference on Robotics and Automation (ICRA)
Karlsruhe, Germany, May 6-10, 2013

Minimal Specification Revision for Weighted Transition Systems
Kangjin Kim and Georgios Fainekos

Abstract— In this paper, we study the problem of revising
Linear Temporal Logic (LTL) formulas that capture specifications for optimal planning over weighted transition systems.
Namely, it is assumed that the model of the system is a
weighted finite state transition system. The LTL specification
captures the system requirements which must be satisfied by
a plan which costs less than a certain cost budget. If the cost
bounds cannot be satisfied with the initial specification, then
it is desirable to return to the user a specification that can
be satisfied on the system within the desired cost budget. We
prove that the specification revision problem for automatabased optimal planning is NP-complete. In order to provide
exact solutions to the problem, we present an Integer Linear
Program (ILP) and a Mixed-Integer Linear Program (MILP)
formulation for different versions of the problem. Finally, we
indicate that a Linear Program (LP) relaxation can compute
fast approximations to the problem.

I. I NTRODUCTION
Temporal logics have become a popular formalism for
capturing high level specifications for both single robots
and teams of robots. The advantage of temporal logics is
twofold. First, they provide a good interface with natural
languages [1], [2]. Second, they provide a mathematical
formal framework for combining high-level reasoning with
low-level controllers with provable results and guaranteed
performance of the final control system. In particular, Linear
Temporal Logic (LTL) has been utilized as a specification
language in a range of robotics applications (see [3]–[13]).
In order for temporal logic planning to become a viable
framework for robot control several aspects of human-robot
interaction must be resolved. Besides the human instructing
the robot, the robot must be able to provide feedback to
the user if it cannot execute some user commands. Along
these lines, in our previous work [14], we introduced the
specification revision problem for Linear Temporal Logic
(LTL). When the LTL planning phase fails, the specification
revision problem attempts to determine a new specification
which is close to the initial user intent and, moreover, it
is satisfiable by the system within its environment. In the
follow-up paper [15], we studied the problem when the
specifications are provided as ω-automata and we proved
that the problem is computationally hard. In view of this
negative result, we developed a polynomial-time heuristic
approximation algorithm with a guaranteed approximation
ratio in some special cases [16].
In this paper, we investigate the problem of specification
revision for optimal planning with LTL specifications. For
This work has been partially supported by award NSF CNS 1116136.
K. Kim and G. Fainekos are with the School of Computing, Informatics
and Decision Systems Engineering, Arizona State University, Tempe, AZ
85281, USA {Kangjin.Kim,fainekos}@asu.edu

978-1-4673-5643-5/13/$31.00 ©2013 IEEE

instance, in optimal LTL planning [11], [17], each action of
the system incurs some cost and the goal is to compute a
plan that satisfies the LTL specification with minimal cost.
Here, we pose the question what happens if we impose
some cost constraints for our plan and the minimal cost plan
that we compute does not satisfy these constraints. Since
the environment and system cannot be modified, we must
compute an alternative specification that remains as close as
possible to the initial user intent. In other words, we attempt
to compute the largest sub-specification that can be satisfied
on the system and the resulting plan is satisfiable with total
cost less than our cost constraints. We prove that the problem
is computationally hard and we provide a formulation of
the problem as a (mixed-) integer linear program (M)ILP.
Also, we provide heuristics in order to provide a linear
programming relaxation that can provide fast approximations
to the optimal solution.
Related research: A related problem is the detection of
the causes of unrealizability in LTL games. In this case, a
number of heuristics have been developed in order to localize
the error and provide meaningful information to the user
for debugging [18], [19]. Along these lines, LTLMop [20]
was developed to debug unrealizable LTL specifications in
reactive planning for robotic applications. In the context of
general planners, the problem of finding good excuses on
why the planning failed has been studied in [21]. OverSubscription Planning (OSP) [22] and Partial Satisfaction
Planning (PSP) [23] are also very related problems. OSP
determines a proper subset of a well-defined, but oversubscribed, conjunctive goal to meet time and energy limitations.
PSP is the problem where each goal is a soft constraint and
the planner attempts to find a good quality plan for a subset
of the goals. In terms of MILP formulation, the specification
revision problem bares some similarities with the vehicle
routing problem with refueling constraints [24].
II. P ROBLEM F ORMULATION
In this paper, we work with discrete abstractions (Finite
State Machines) of the continuous robotic control system
[3]. This is a common practice in approaches that hierarchically decompose the control synthesis problem into highlevel discrete planning synthesis and low level continuous
feedback controller composition [3], [6]. Each state of the
Finite State Machine (FSM) T is labeled by a number of
symbols from a set Π = {π0 , π1 , . . . , πn } that represent
regions in the workspace or the configuration space of the
robot, or more generally, actions that can be performed by
the robot. Moreover, each state of the FSM has an associated
weight. The weights can represent the worst case energy or

4068

60
50

π4
π0

x2

40

π2

30

π1

π

3

20
10
0
0

10

20

30

40

50
x1

60

70

80

90

100

Fig. 1. Example 1: The environment and a trajectory of system (1) that
satisfies the specification φe1 .

time needed for traversing a region. In general, the weights
on the FSM capture some quantitative values on the cost of
performing some action.
The control requirements for such a system can be posed
in propositional Linear Temporal Logic (LTL) [25] or, more
generally, using specification automata B with Büchi acceptance conditions [26] also known as ω-automata. LTL
formulas are built over a set of atoms, the set Π in our
case, using combinations of the traditional and temporal
operators. Traditional logic operators are the conjunction (∧),
disjunction (∨), negation (¬). Some of the temporal operators are eventually (✸), always (✷) and until (U). LTL can
describe the usual properties of interest for control problems,
i.e. reachability (✸π) and safety: (✷π or ✷¬π). Beyond
the usual properties, LTL can capture sequences of events
and certain infinite behaviors. For example, sequencing: The
requirement that we must visit π1 , π2 and π3 in that order
is naturally captured by the formula ✸(π1 ∧ ✸(π2 ∧ ✸π3 )).
More complicated specifications can be composed from the
basic specifications using the logic operators (e.g., [3], [6]).
We assume that we use only formulas in Negation Normal
Form (NNF) and that each negated atomic proposition ¬π
has been replaced by a new symbol, e.g. π, which is added
to Π. The details on why LTL in NNF is equivalent to full
LTL can be found in [3]. Any LTL formula can be converted
into an ω-automaton [27].
The following example, which is the running example
of the paper, presents such a typical scenario for motion
planning of a mobile robot.
Example 1 (Robot Motion Planning): We consider a mobile robot which operates in a planar environment. The
continuous state variable x(t) models the internal dynamics
of the robot whereas only its position y(t) is observed. In this
example, we will consider a 2nd order model of the motion
of a planar robot (dynamic model):
ẋ1 (t) = x2 (t),

ẋ2 (t) = u(t),

y(t) = x1 (t)

(1)

where x1 (t) ∈ R2 , x1 (0) ∈ X1,0 , x2 (t) ∈ R2 , x2 (0) = 0,
u(t) ∈ U . The robot is moving in a convex polygonal environment with four areas of interest denoted by π1 , π2 , π3 , π4
(see Fig. 1). Initially, the robot is placed somewhere in the
region labeled by π1 . The robot must accomplish the task:

“Periodically visit areas π2 , π3 and π4 with the additional
requirement that at least one π4 should be followed by at
least one π2 ”. The informal constraint is captured by the
LTL specification φe1 = ✷(✸π3 ∧ ✸(π4 ∧ ✸π2 )).
The LTL planning is performed on a discrete abstraction
of the environment (FSM) which results from a cell decomposition. The weights that label the transitions of the
FSM are proportional to the area of the cell at the source
of the edge. The weights capture the worst case energy
or time needed to traverse the cell. Figure 1 presents a
trajectory that satisfies the specification φe1 . The trajectory
was created using the hierarchical control framework from
[3]. The trajectory consists of a transient behavior (prefix)
that starts in π1 and visits first π3 and then π4 and π2 and a
limit cycle (loop) that continuously visits π4 , π3 and π2 . △
A challenging problem arises when there is a hard constraint on the total cost for either the transient part or the
stable part of the discrete trajectory. Such constraints could
be imposed if for example there is a total budget on the
energy storage and one of the atomic propositions represents
a recharging station. In other words, even though the specification is satisfiable on the system if the cost constraint is
ignored, it becomes unsatisfiable when considering the hard
cost constraints. If the environment or the robot capabilities
cannot be modified, then the goal is to detect the largest
sub-specification that can be actually realized by the robot.
Problem 1 (Weighted Minimal Revision Prob. (WMRP)):
Given a weighted FTS T , an LTL formula φ and a cost
budget C ∈ R≥0 , if the specification φ cannot be satisfied
on T under cost C, then find the “closest” specification φ′
to φ which is satisfied on T with cost less than C.
The unweighted version of Problem 1 was introduced and
studied in [14], [15]. As indicated in [14], the specification
revision problem is easy when the discrete controller synthesis phase fails due to unreachable states in the system.
Thus, in this paper, we concentrate on the harder problem of
minimal revision when all the states on T are reachable.
Assumption 1: All the states on T are reachable.
Contributions: In this paper, we formally define WMRP
and we show that the problem is NP-complete if we assume
that input is provided as a specification automaton. Also,
we provide an Integer Linear Program (ILP) and a MixedInteger Linear Program (MILP) formulation for two different
versions of WMRP. An LP relaxation is considered and some
examples are presented.
III. O PTIMAL D ISCRETE C ONTROLLERS
In this section, we provide a brief review of automata
based optimal planning over weighted transition systems.
First, we will present how the cost of a periodic discrete
plan can be optimized and, then, we will briefly comment
on the more challenging optimal control problem with LTL
constraints presented in [11], [17].
In order to use temporal logics to specify requirements for
continuous systems, we need to construct a finite partition
of the robot’s workspace (or configuration space). We can

4069

use many efficient cell decomposition methods for polygonal environments [28]. This results in a topological graph
G = (Q, E) which describes which cells are topologically
adjacent, i.e., each node q ∈ Q in the graph represents a
cell and each edge e = (q, q ′ ) ∈ E in the graph implies
topological adjacency of the cells. Each such cell will be a
state in the FSM which will be labeled by a weight and by
one or more atomic propositions from Π. Next, we formally
define the FSM that can be constructed from the graph G.
Definition 1 (FSM): A Finite State Machine is a tuple
T = (Q, Q0 , →T , hT , w, Π) where: Q is a set of states;
Q0 ⊆ Q is the set of possible initial states; →T = E ⊆ Q×Q
is the transition relation; hT : Q → P(Π) maps each state
q to the set of atomic propositions that are true on q; and,
w : Q → R≥0 returns the weight in each state.
We define a path on the FSM to be a sequence of states
and a trace to be the corresponding sequence of sets of
propositions. Formally, a path is a function p : N → Q
such that for each i ∈ N we have p(i) →T p(i + 1)
and the corresponding trace is the function composition
p̄ = hT ◦ p : N → P(Π). The language L(T ) of T consists
of all possible traces.
In this work, we are interested in the construction of
automata that only accept the traces of T which satisfy the
LTL formula φ. Such automata (which we will refer to as
specification or Büchi automata [29]) differ from the classic
finite automata in that they accept infinite strings (traces of
T in our case).
Definition 2 (Automaton): An automaton is a tuple B =
B
(SB , sB
0 , Ω, δB , FB ) where: SB is a finite set of states; s0 is
the initial state; Ω is an input alphabet; δB : SB ×Ω → P(SB )
is a transition function; and FB ⊆ SB is a set of final states.
l
When s′ ∈ δB (s, l), we also write s →B s′ or
(s, l, s′ ) ∈→B . A run r of B is a sequence of states r :
N → SB that occurs under an input trace p̄ taking values in
Ω. That is, for i = 0 we have r(0) = sB
0 and for all i ≥ 0
p̄(i)

we have r(i) → B r(i + 1). Let lim(·) be the function that
returns the set of states that are encountered infinitely often
in the run r of B. Then, a run r of a Büchi automaton B over
an infinite trace p̄ is accepting if and only if lim(r)∩FB 6= ∅.
Finally, we define the language L(B) of B to be the set of
all traces p̄ that have a run that is accepted by B.
A specification automaton is a Büchi automaton where the
input alphabet is the powerset of the labels of the system T ,
i.e., Ω = P(Π). In order to simplify the discussion in Section
IV, we will be using the following assumptions and notation
′
• we define the set EB ⊆ SB × SB , such that (s, s ) ∈ EB
l
iff ∃l ∈ Ω . s →B s′ ; and,
• we define the function λB : SB ×SB → Ω which maps a
pair of states to the label of the corresponding transition,
l
i.e., if s →B s′ , then λB (s, s′ ) = l; and if (s, s′ ) 6∈ EB ,
then λB (s, s′ ) = ∅.
In brief, our goal is to generate paths on T that satisfy the
specification Bφ . In automata theoretic terms, we want to find
the subset of the language L(T ) which also belongs to the
language L(Bφ ). This subset is simply the intersection of the

two languages L(T ) ∩ L(Bφ ) and it can be constructed by
taking the product T ×Bφ of the FSM T and the specification
automaton Bφ . Then, given an initial state in the FSM T , we
can choose a particular trace from L(A) = L(T × Bφ ) =
L(T ) ∩ L(Bφ ) according to a preferred criterion.
Definition 3: The product automaton A = T × Bφ is the
automaton A = (SA , sA
0 , P(Π), δA , FA ) where:
• SA = Q × SBφ ,
Bφ
A
• s0 = {(q0 , s0 ) | q0 ∈ Q0 },
• δA : SA × P(Π) → P(SA ) s.t. (qj , sj ) ∈ δA ((qi , si ), l)
iff qi →T qj and sj ∈ δBφ (si , l) with l ⊆ hT (qj ),
• FA = Q × FB is the set of accepting states.
We say that Bφ is satisfiable on T if L(A) 6= ∅.
The class of languages accepted by Büchi automata can be
fully characterized by ultimately periodic traces [30]. That
is traces of the form: there exist constants m, n ∈ N s.t. for
all k ≥ 0, we have p̄(m + k) = p̄(m + mod (k, n)), where
mod is the modulo operation. In other words, an ultimately
periodic trace consists of a finite (or transient or prefix) part
p̄(0)p̄(1) . . . p̄(m − 1) and a loop (or lasso or steady state
or suffix) part p̄(m)p̄(m + 1) . . . p̄(m + n − 1) repeated ad
infinitum. Based on that observation, we can heuristically
construct a cost function that will help us compute a plan
that satisfies our overall cost bound C:
)
(m
n
X
X
(w(p(m + i))) .
(w(p(1 + i))),
C1 (p) = max
i=1

i=1

The first quantity is the cost of the path to get to the state
p(m), while the second is the cost of the steady state.
Based on the previous cost function, it is easy to compute
the optimal path on T that satisfies φ. We define a weight
function wA on the edges of A as follows: ∀ (qj , sj )
∈ δA ((qi , si ), l), wA ((qi , si ), (qj , sj )) = w(qi ). Then we
run Dijkstra’s shortest path algorithm [31] to compute the
shortest path from the initial state to any accepting state in
FA . Then, starting from each reachable accepting state, we
compute the shortest path to get back to that state. Finally,
we can select a path that minimizes C1 (p).
Example 2: In Example 1, T has 44 states and the Büchi
automaton has 6 states. The product automaton A has 270
states. The minimal cost planning method proposed above
took 0.63sec on an i7 at 2.93GHz with 8GB on a prototype
Matlab implementation. Both the transient and the stable
trajectories are generated such that total weight of the paths
on the discrete abstraction is minimal. The costs of the prefix
and loop are 855 and 1015, respectively.
△
The procedure described above is meaningful only in certain motion planning scenarios. For example, such a planning
framework can be useful in cases where the vehicle can
continuously recharge, e.g., using solar panels, or regenerate
energy while operating. In these cases, it is desirable that the
cost of the periodic part of the plan as well as the transient
behavior have cost less than cost budget C which could
indicate depleted power sources.
A different LTL optimal planning framework has been
developed in [11], [17]. In [17], the authors solve the optimal

4070

planning problem for specifications of the form
φ := ϕ ∧ ✷✸ψ,

(2)

where ψ is a Boolean combination of atomic propositions
that must be satisfied infinitely often. For instance, we could
set ψ = π ⋆ where π ⋆ is an atomic proposition indicating a
recharging or time reseting operation in a particular location
in the environment. Then, the optimal control framework
attempts to compute paths that when passing through spi
have cost less than C.
In the following, we will assume that ψ is a single atomic
proposition, i.e., ψ = π ⋆ . The discussion can be generalized
to Boolean combinations of atomic propositions. Formally,
⋆
given a path p, the function απp : N → N returns the i-th
⋆
appearance of π in p̄. The cost C(p) of a path is defined as
α(i+1)

C2 (p) = lim sup
i→+∞

X

w(p(j))

j=α(i)

⋆

C2 (p) is finite only if π occurs periodically in the trajectory.
The main results from [17] can be summarized as follows.
Theorem 1: There exists p̄ ∈ L(A) s.t. p̄ is ultimately
periodic and the corresponding path p minimizes the cost
function C2 (p).
The computation of a path that minimizes C2 is similar to
the algorithm that produces plans that minimize C1 , but with
a major difference. There is a set of nodes R – potentially
different from FA – that are labeled by π ⋆ and when visited
they reset the cost of a path. A detailed description of the
algorithm appears in [17].
The paths computed with the above process are guaranteed
to be the minimum cost paths. In realistic scenarios, it is to
be expected to have hard constraints on the allowable worst
case costs. As an example consider a scenario where the costs
represent worst case energy consumption in order to traverse
a region and the special atomic proposition indicates the
location of a charging unit. In such scenarios, it is necessary
to revise the mission plan requirements in order to identify
a feasible plan which satisfies the hard cost constraints.
IV. T HE LTL R EVISION P ROBLEM
The specification revision problem concerns the search for
one or more specifications which are related to the initial
user requirement and, which, furthermore, can be satisfied
on the weighted transition system under some hard cost
constraints. One of the fundamental questions regards the
form of the search space of the specifications. Since the
initial user specification allows only system behaviors with
higher cost than the constraint, it is natural to relax some
of the requirements in order to permit more behaviors and,
hopefully, find a behavior with lower cost.
The unconstrained LTL formula search space for a revised
specification is

the problem, FC
T also contains specifications that from the
user perspective cannot be considered valid specification
revisions. Thus, we must impose some constraints on the
search space. First, we define an ordering relation over the
set of LTL formulas.
Definition 4: Let φ, ψ ∈ LT L(Π), then we define φ  ψ
if and only if L(φ) ⊆ L(ψ).
We define the set of ultra relaxations as follows.
Definition 5 (Ultra Relaxation): Let φ ∈ LT L(Π), the
set UR(φ) of all valid formula relaxations of φ can be
constructed using the recursive operator rel(φ) as follows:
rel(π) ∈ {π, ⊤},
OP1 φ = OP1 rel(φ)
rel(φ1 OP2 φ2 ) = rel(φ1 ) OP2 rel(φ2 )
where OP1 is any unary and OP2 is any binary operator.
Informally, a valid formula relaxation is one that recursively relaxes each atomic proposition π of the initial
specification φ.
Example 3: Let us consider the specification φe1 of Example 1. Then, |UR(φe1 )| = 23 = 8. As an example,
we have ϕ = ✷(✸π3 ∧ ✸(π4 ∧ ✸⊤)) ∈ UR(φe1 ). Note
though that ϕ is equivalent to ✷(✸π3 ∧ ✸π4 ). For clarity
in the presentation, we will be using equivalent formulas
interchangeably to refer to formulas in UR(·).
The following result is immediate from Theorem 1 in [14].
Corollary 1: For any φ ∈ LT L(Π) and φ′ ∈ UR(φ), we
have φ  φ′ .
Therefore, a restricted version of Problem 1 can be formally restated as:
Problem 2: Given a system T , a specification φ and a cost
C
C ∈ R≥0 such that φ 6∈ FC
T , find ϕ ∈ FT ∩ UR(φ) such that
C
for any other ψ ∈ FT ∩ UR(φ), we have ψ 6 ϕ.
Remark 1: A restricted search space and, thus, a restricted
version of Problem 1 are necessary for two reasons. First, the
revised specification must be related to the initial user intent
rather than include arbitrary requirements (see [14]). Second,
as we will demonstrate in the next section, the restricted
version of the problem is already computationally hard.
Obviously, with the aforementioned restrictions the
WMRP is decidable. For a formula φ, there is a finite number
of revisions in UR(φ) that we must consider. For each
φ′ ∈ UR(φ), we can solve the optimal path planning problem
and, then, choose the revised specification with the least
modifications that produces optimal paths with cost less than
the bound C. Nevertheless, typical examples of LTL specifications can have 10-30 occurrences of atomic propositions in
a formula (see [17] for an interesting collection). This means
that the optimal LTL planning problem (which includes the
Büchi automaton synthesis for each new formula) must be
solved anywhere from 1,000 times to 1 billion times. Next,
we study the question whether the problem really requires
exploring all the combinations for the optimal solution.

FC
T = {φ ∈ LT L(Π) | ∃p̄.p̄ ∈ L(T × Bφ ) ∧ C(p) ≤ C},

V. LTL R EVISION

where C is C1 or C2 . However, as we have demonstrated
through examples in [14] for the unweighted version of

AS A

S HORTEST PATH P ROBLEM

In this section, we present how Problem 2 can be posed
as a shortest path problem on a weighted labeled graph.

4071

Without loss of generality, we will assume that for any
given specification φ, each atomic proposition π in φ appears
only once in φ. If this is not the case, then for each additional
occurrence of π in φ, we can replace it with a new atomic
proposition, add the proposition to Π and modify the map hT
accordingly. This change is necessary in order to uniquely
identify in φ which propositions need to be replaced by ⊤.
Given a specification φ, we can construct the corresponding specification automaton Bφ . Using the weighted labeled
transition system T and the specification automaton Bφ , we
can construct a graph GA which corresponds to the product
automaton A while considering the effect of revisions and
the weights.
Definition 6: Given a system T and a specification automaton Bφ , we define the graph GA =
(V, E, vs , Vf , W, L, R), which corresponds to the product
A = T × Bφ as
• V = SA is the set of nodes
• E = EA ∪ ED ⊆ SA × SA , where
– EA is the set of edges that correspond to transitions
on A, i.e., ((q, s), (q ′ , s′ )) ∈ EA iff ∃l ∈ P(Π) .
l
(q, s) →A (q ′ , s′ ); and
– ED is the set of edges that correspond to disabled
transitions, i.e., ((q, s), (q ′ , s′ )) ∈ ED iff q →T q ′
l
and s →Bφ s′ with l ∩ (Π − hT (q ′ )) 6= ∅.
A
• vs = s0 is the source node,
• Vf = FA is the set of sinks,
• W : E → R≥0 assigns a weight to each edge in E. If
e = ((q, s), (q ′ , s′ )) ∈ E, then w(e) = w(q).
• L : E → P(Π) maps each edge of the graph to the
set of symbols that need to be removed in order to
enable the edge in the product automaton A. If e =
((q, s), (q ′ , s′ )) ∈ E, then L(e) = λBφ (s, s′ ) − hT (q ′ ).
⋆
• R = {(q, s) ∈ V | π ∈ hT (q)} is the set of “cost
reset” nodes.
We remark that the graph GA is essentially the same graph
as the graph of A with the addition of the disabled edges
due to the specification constraints. Therefore, any path on
the graph of A appears as a path on GA .
A path η = v0 v1 v2 . . . vn on GA is a sequence of nodes
that start from the source v0 = vs , follow the edges from
E, i.e., for 0 ≤ i < n, (vi , vi+1 ) ∈ E, and end in
one of the sinks vn ∈ Vf . The cost of the corresponding
path is defined as CGA (η) = h|L(η)|, W (η)i. L(η) =
S|η|−1
i=0 L(vi , vi+1 ) is the set of symbols that need to be
removed for theP
path to become enabled on A. W (η) =
rj+1
W (vi , vi+1 ) is the weight of the path
maxj=0,1,...,k−1 i=r
j
after k − 1 cost resets by visiting a node in R. Here,
r0 r1 . . . rk with ri ∈ {0, 1, . . . , |η| − 1} is the sequence of
indices such that vri ∈ R, r0 = 0 and rk = |η| − 1. In
the special casePwhere there are no cost resets, i.e., k = 1,
|η|−1
then W (η) =
i=0 W (vi , vi+1 ). Then, by construction,
Problem 2 is reduced to solving a number of the following
problems.
Problem 3: Given a weighted labeled graph GA as in Def.
6 and a cost bound K ∈ R≥0 , find a path η on the graph

such that |L(η)| is minimum over all paths in GA while
W (η) ≤ K.
We refer to the last problem as Constrained Minimally Labeled Path (CMLP). It is easy to show that the corresponding
decision problem is NP-complete.
Theorem 2: Given an instance of the CMLP (GA , K) and
a bound Λ, the decision problem of whether there exists a
path η such that |L(η)| ≤ Λ is NP-Complete.
In other words, even for this simplified version of the
specification revision problem, it is unlikely that there exists
a polynomial time algorithm that can solve the problem. The
best we can hope for is a polynomial time approximation
algorithm as the one that we have presented in [16] for
the unweighted version of the problem. This is currently an
ongoing research effort.
A. (Mixed)-Integer Linear Program Formulation for WMRP
We first present an Integer Linear Program (ILP) formulation that solves CMLP for R = ∅. Our goal is to compute
the least number of labels to remove from the edges of GA
while the path has weight less than K. In the following all
the variables are Boolean, in(v) ⊆ E denotes the incoming
edges to node v ∈ V and out(v) ⊆ E denotes the outgoing
edges from a node v ∈ V . We use one Boolean variable xπ
for each atomic proposition π ∈ Π and one Boolean variable
xe to model each edge of the graph GA . Hence, we formulate
the following ILP problem.
X
min
xπ
(3)
π∈Π
X
X
xeo (4)
xei =
s.t. ∀v ∈ V \(Vf ∪ {vs }) .
eo ∈out(v)

ei ∈in(v)

X

X

eo ∈out(vs )

X

xeo = 1

(5)

xe = 1
X
∀e ∈ E . |L(e)|xe ≤
v∈Vf

(6)

e∈in(v)

π∈L(e)

xπ

(7)

The cost function (3) minimizes the number of atomic
propositions that must be enabled. Constraint (4) captures
the requirement that the incoming “flow” to a node should
be equal to the outgoing “flow”. However, no loops through
the initial node are allowed. Constraint (5) captures the fact
that one outgoing edge from the source node should be on the
path. Similarly, there should be one incoming edge enabled
to a sink node (constraint (6)). Finally, inequality (7) imposes
the constraint that if an edge e is part of the path, i.e., xe = 1,
then the atomic propositions on the edge must be removed.
When R = ∅, then the cost constraint, i.e., that the enabled
path has total weight less than K, is simply
X
W (e)xe ≤ K
(8)
e∈E

The ILP above solves the CMLP, but not the WMRP. In
order to compute the optimal solution for WMRP, we need
to add the requirement for a loop from a sink node back to
itself. In order to enable a loop, we need to create a copy of
the graph for each sink node. The constraint (6) is relaxed to

4072

60

at least one incoming node since a path might visit multiple
sink nodes. For the same reason, we need
X
X
∀v ∈ Vf .
xei ≥
(9)
xeo
ei ∈in(v)

50

π4
40

x2

eo ∈out(v)

Also, we must add the constraint that if an incoming edge to
a sink node is part of the path, then an outgoing edge from
the sink node in the copy of the graph may be part of the
path as well. Let v ′ be the copy of a node v ∈ Vf , then
X
X
xe ≥
xe
(10)
′
e∈in(v)

30

−Wub (1 − xe ) ≤ dv′ − dv − W (e) ≤ Wub (1 − xe ) (11)
and if v ∈ R
−Wub (1 − xe ) ≤ dv′ − W (e) ≤ Wub (1 − xe )

(12)

where Wub is a large enough constant. In our implementation, it is set to Wub = C + maxe∈E W (e). Furthermore, at
least one cost reset node must be visited
X
X
xe ≥ 1
(13)
e∈in(v)

The resulting optimization problem is a Mixed-Integer Linear
Program (MILP).
Remark 2: If there is some ordering in the importance of
achieving certain goals as expressed by the atomic propositions in the specification, then these could be incorporated
in the cost function (3) as weights to the variables xπ .
B. Linear Program Relaxation for WMRP
A simple MILP solver in Matlab which uses a branchand-bound algorithm cannot handle problems of the size
of Example 1 (8484 variables, 8480 inequalities and 539
equalities). Therefore, we directly solve the Linear Program
(LP) relaxation for WMRP in order to get an approximate
solution. The LP relaxation is derived by simply replacing
the constraints that xe , xπ ∈ {0, 1} with 0 ≤ xe ≤ 1 and

π2
π1

π3

20

10

0
0

e∈out(v )

Each copy of the graph has only one accepting node. Furthermore, we need to add the constraint that only one accepting
node is visited in all copies of graphs. This increase in the
complexity of the problem formulation is needed because an
edge that has been enabled in the finite part of the path does
not necessarily have to be part of the loop. Finally, constraint
(8) must be replicated for the copies of the graph.
The above ILP formulation for WMRP might be too difficult to solve if there are many accepting nodes. Alternatively,
we can solve a sequence of ILP problems one for each
accepting node in Vf . In this case, we solve the optimization
problem (3) under constraints (4)-(8) and (10) where now
Vf is a singleton and constraints (4), (6)-(8) are added to the
copy of the graph as well.
However, if the cost function C2 is considered, i.e., R 6= ∅,
then the ILP formulation above is not sufficient. In this case,
for each node v, we need a variable dv ∈ R≥0 that keeps
track of the cost of the path that arrives at node v. We replace
constraint (8) with the following constraints, but only in the
copy of the graph since the cost function ignores the transient
behavior. For all e = (v, v ′ ) ∈ E, if v 6∈ R

v∈R

π0

Fig. 2.

10

20

30

40

50
x1

60

70

80

90

100

Example 4: The resulting trajectory for the revision φe2 .

0 ≤ xπ ≤ 1 for all edges e and atomic propositions π. If
there is a feasible solution to the LP relaxation, we will get
a vector of fractional numbers xπ1 , . . . , xπn , where n is the
number of atomic propositions in the specification.
However, the returned solution might be too conservative
in the sense that most of the variables xπ could have some
small non-zero value. Therefore, we employ 2 heuristics.
First, we force the LP solver to look for feasible solutions
around the minimal path found originally which does not
satisfy the cost constraint. Second, we either randomly round
the values of the variables xπ by assigning probabilities
based on the value of the variables or we set a threshold, e.g.,
relative difference between variables, which depends
on the
P
problem. Finally, we also add the constraint π∈Π xπ ≥ 1
since the variables can take very small values.
Example 4: The LP relaxation of WMRP using cost C1
on Example 1 is solved by Matlab linprog in less than 6sec
on an i7 at 2.93GHz with 8GB. When we set as cost bound
C = 950, we get as specification revision the set {π2 }. That
is, the revised specification derived by replacing π2 with ⊤
in φe1 which is equivalent to φe2 = ✷(✸π3 ∧ ✸π4 ). The
resulting trajectory appears in Fig. 2 with cost 855 for the
prefix and 622 for the lasso part. The trajectory first visits
π3 , then π4 and then oscillates between π3 and π4 .
However, when the cost bound is reduced to C = 800,
then the revision returned is {π2 , π3 }. Thus, the equivalent
LTL specification is φe3 = ✷(✸π4 ), i.e., the robot arrives
and stays in π4 . The resulting trajectory is presented in Fig.
3 with cost 597 for the prefix and 0 for the lasso part.
Under cost function C1 , the LP relaxation is faster than
exhaustive search.
Finally, if we set π ⋆ = π2 , which is allowed in our
framework, and set the cost bound to 800, then the revision
computed removes π4 . The cost of the resulting path, which
repeatedly visits π2 and π3 , is 722. However, this revision
under cost function C2 took 19 min on the same computer.
Future investigations will be focused on whether this is faster
or slower than exhaustive search by repeatedly calling the
optimal control algorithm from [17].
△
VI. C ONCLUSIONS
Linear temporal logic can be viewed as a high level
programming language for robots. In order for LTL control

4073

60

50

π4

x2

40

π0

30

π

2

π1

π3

20

10

0
0

Fig. 3.

10

20

30

40

50
x1

60

70

80

90

100

Example 4: The resulting trajectory for the revision φe3 .

methods to be adopted by a larger number of users, specification debugging and revision methods must be developed.
In this paper, we introduced the problem of minimal revision
of specification automata for linear temporal logic planning
over weighted transition systems (WMRP). We proved that
WMRP in a restricted form is NP-complete. For computing
the exact solution to the problem, we provided a MixedInteger Linear Program (MILP) formulation of the WMRP.
Since the low-end MILP solvers cannot solve realistic problem instances, we provided heuristics for a Linear Program
(LP) relaxation albeit without any approximation guarantees.
Future research will be targeted on developing heuristics
and approximation algorithms with guaranteed bounds. We
believe that a polynomial-time heuristic algorithm similar to
[16] is necessary for implementing the algorithms to be run
on embedded computing devices.
Acknowledgments: The authors would like to thank A.
Agung Julius for recommending taking a linear programming approach. The authors would also like to thank the
anonymous reviewers for their detailed comments and, in
particular, reviewer 6 for suggesting considering the general
case in specification (2).
R EFERENCES
[1] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Translating
structured english to robot controllers,” Advanced Robotics, vol. 22,
no. 12, pp. 1343–1359, 2008.
[2] J. Dzifcak, M. Scheutz, C. Baral, and P. Schermerhorn, “What to do
and how to do it: Translating natural language directives into temporal
and dynamic logic representation for goal management and action
execution,” in Proceedings of the IEEE international conference on
robotics and automation, 2009.
[3] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, Feb. 2009.
[4] I. Filippidis, D. V. Dimarogonas, and K. J. Kyriakopoulos, “Decentralized multi-agent control from local LTL specifications,” in 51st IEEE
Conference on Decision and Control, 2012, pp. pp. 6235–6240.
[5] S. Karaman, R. Sanfelice, and E. Frazzoli, “Optimal control of mixed
logical dynamical systems with linear temporal logic specifications,”
in IEEE Conf. on Decision and Control, 2008.
[6] M. Kloetzer and C. Belta, “Automatic deployment of distributed teams
of robots from temporal logic specifications,” IEEE Transactions on
Robotics, vol. 26, no. 1, pp. 48–61, 2010.
[7] A. Bhatia, L. E. Kavraki, and M. Y. Vardi, “Sampling-based motion planning with temporal goals,” in International Conference on
Robotics and Automation. IEEE, 2010, pp. 2689–2696.
[8] T. Wongpiromsarn, U. Topcu, and R. M. Murray, “Receding horizon
control for temporal logic specifications,” in Proceedings of the 13th
ACM international conference on Hybrid systems: computation and
control. New York, NY, USA: ACM, 2010, pp. 101–110.

[9] P. Roy, P. Tabuada, and R. Majumdar, “Pessoa 2.0: a controller
synthesis tool for cyber-physical systems,” in Proceedings of the 14th
international conference on Hybrid systems: computation and control,
ser. HSCC ’11. New York, NY, USA: ACM, 2011, pp. 315–316.
[10] L. Bobadilla, O. Sanchez, J. Czarnowski, K. Gossman, and S. LaValle,
“Controlling wild bodies using linear temporal logic,” in Proceedings
of Robotics: Science and Systems, Los Angeles, CA, USA, June 2011.
[11] A. Ulusoy, S. L. Smith, X. C. Ding, C. Belta, and D. Rus, “Optimal multi-robot path planning with temporal logic constraints,” in
IEEE/RSJ International Conference on Intelligent Robots and Systems,, 2011, pp. 3087 –3092.
[12] B. Lacerda and P. Lima, “Designing petri net supervisors from ltl
specifications,” in Proceedings of Robotics: Science and Systems, Los
Angeles, CA, USA, June 2011.
[13] A. LaViers, M. Egerstedt, Y. Chen, and C. Belta, “Automatic generation of balletic motions,” IEEE/ACM International Conference on
Cyber-Physical Systems, vol. 0, pp. 13–21, 2011.
[14] G. E. Fainekos, “Revising temporal logic specifications for motion
planning,” in Proceedings of the IEEE Conference on Robotics and
Automation, May 2011.
[15] K. Kim, G. Fainekos, and S. Sankaranarayanan, “On the revision
problem of specification automata,” in Proceedings of the IEEE
Conference on Robotics and Automation, May 2012.
[16] K. Kim and G. Fainekos, “Approximate solutions for the minimal
revision problem of specification automata,” in Proceedings of the
IEEE/RSJ International Conference on Intelligent Robots and Systems,
Oct. 2012.
[17] S. L. Smith, J. Tumova, C. Belta, and D. Rus, “Optimal path planning
for surveillance with temporal-logic constraints,” The International
Journal of Robotics Research, vol. 30, pp. 1695–1708, 2011.
[18] A. Cimatti, M. Roveri, V. Schuppan, and A. Tchaltsev, “Diagnostic
information for realizability,” in Verification, Model Checking, and
Abstract Interpretation, ser. LNCS, F. Logozzo, D. Peled, and L. Zuck,
Eds. Springer, 2008, vol. 4905, pp. 52–67.
[19] R. Konighofer, G. Hofferek, and R. Bloem, “Debugging formal
specifications using simple counterstrategies,” in Formal Methods in
Computer-Aided Design. IEEE, Nov. 2009, pp. 152 –159.
[20] V. Raman and H. Kress-Gazit, “Analyzing unsynthesizable specifications for high-level robot behavior using LTLMoP,” in 23rd International Conference on Computer Aided Verification, ser. LNCS, vol.
6806. Springer, 2011, pp. 663–668.
[21] M. Göbelbecker, T. Keller, P. Eyerich, M. Brenner, and B. Nebel,
“Coming up with good excuses: What to do when no plan can
be found,” in Proceedings of the 20th International Conference on
Automated Planning and Scheduling. AAAI, 2010, pp. 81–88.
[22] D. E. Smith, “Choosing objectives in over-subscription planning,”
in Proceedings of the 14th International Conference on Automated
Planning and Scheduling, 2004, p. 393401.
[23] M. van den Briel, R. Sanchez, M. B. Do, and S. Kambhampati, “Effective approaches for partial satisfaction (over-subscription) planning,” in
Proceedings of the 19th national conference on Artifical intelligence.
AAAI Press, 2004, p. 562569.
[24] K. Sundar and S. Rathinam, “Route planning algorithms for unmanned
aerial vehicles with refueling constraints,” in American Control Conference, june 2012, pp. 3266 –3271.
[25] A. Pnueli, “The temporal logic of programs,” in Proceedings of the
18th IEEE Symposium Foundations of Computer Science, 1977, pp.
46–57.
[26] J. R. Buchi, “Weak second order arithmetic and finite automata,”
Zeitschrift für Math. Logik und Grundlagen Math., vol. 6, pp. 66–
92, 1960.
[27] P. Wolper, “Constructing automata from temporal logic formulas: a tutorial,” in Lectures on formal methods and performance analysis: first
EEF/Euro summer school on trends in computer science. Springer,
2002, pp. 261–277.
[28] S. M. LaValle, Planning Algorithms. Cambridge University Press,
2006. [Online]. Available: http://msl.cs.uiuc.edu/planning/
[29] P. Gastin and D. Oddoux, “Fast LTL to Büchi automata translation,”
in Proceedings of the 13th CAV, ser. LNCS, G. Berry, H. Comon, and
A. Finkel, Eds., vol. 2102. Springer, 2001, pp. 53–65.
[30] J. R. Buchi, “On a decision method in restricted second-order arithmetic,” in Proceedings of the 1960 International Congress on Logic,
Methodology and Philosophy of Science, 1962, pp. 1–11.
[31] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction
to Algorithms, 2nd ed. MIT Press/McGraw-Hill, Sep. 2001.

4074

Editorial: Special Section VCPSS’09
This special section on Numerical Verification of Cyber-Physical Software Systems
comes as a follow-up to a successful series of workshops and special issues on Numerical Software Verification. At the time this editorial was written, the International
Workshop on Numerical Software Verification (NSV) had already reached its third
successful instantiation. In detail, NSV-I was held in July 2008 along with the
Computer-Aided Verification (CAV) conference at Princeton, NJ. NSV-II was held in
April 2009 as part of the CPSWeek in San Francisco, CA, and it was affiliated with the
International Conference on Hybrid Systems: Computation and Control. The latest
in the series, NSV-III was held in July 2010 in Edinburgh, Scotland, and it was part
of the Federated Logic Conference (FLoC 2010) and affiliated with CAV 2010 and
the Symposium on Logic in Computer Science (LICS) 2010. Finally, NSV-I spurred a
special issue on Formal Methods in System Design.
The goal of the NSV series of workshops and special issues is to spark interest in and
focus attention on research problems that relate to numerical issues of general purpose
software. Even though numerical issues relating to computation have been extensively
studied within the scientific computing community, the proof of correctness of general
or specific purpose software under such issues is still in its infancy. The special section
at hand focuses even further on issues relating to software for Cyber-Physical Systems
(CPS). The issue contains 6 articles that cover a wide range of applications within the
verification of software and models of CPS.
The article by Tichakorn Wongpiromsarn, Sayan Mitra, Andrew Lamperski and
Richard Murray studies the problem of verifying embedded control software for autonomous ground vehicles. In this work, the authors introduce a new modeling formalism for hybrid systems that particularly targets periodically controlled embedded
systems. Empirically, most real-life implementations of hybrid systems could be described using that modeling formalism. Then, the authors derive sufficient conditions
for proving safety properties of hybrid systems that fall within the class of Periodically
Controlled Hybrid Automata (PCHA). For certain classes of PCHA such invariance
verification can be performed automatically. One of the highlights of the article is the
application of the proposed method to the manual verification of the controller of Alice,
the California Institute of Technology autonomous ground vehicle entry to the 2007
DARPA Urban Challenge. Using their new framework, the authors determined that
the failure that Alice exhibited during the Urban Challenge was due to an unfortunate
choice of certain system parameters rather than some algorithmic or logic failure in
the design.
The article by Antoine Girard and Gang Zheng presents their work on verifying
safety and liveness properties of metric transition systems. The basic idea behind
their approach consists of using model-checking for infinite state systems wherein a
metric bisimulation is used to capture the currently explored behavior by considering
“nearby” behaviors that also have the same outcome with respect to the property being
verified. Metric bisimulations are natural for cyber-physical systems since they make
essential use of the continuity in the state-space of the system to make deductions
about system properties. The authors demonstrate the practical aspects of their work
on the verification problem of an embedded control system. One of the advantages
of the work by Girard and Zheng is that it can be applied to synthesis problems
as well.

c 2012 ACM 1539-9087/2012/08-ART52 $15.00

DOI 10.1145/2331147.2331162 http://doi.acm.org/10.1145/2331147.2331162

ACM Transactions on Embedded Computing Systems, Vol. 11, No. S2, Article 52, Publication date: August 2012.

52

52:2

G. Fainekos et al.

The article by Sanjit Seshia and Alexander Rakhlin analyzes quantitative properties of systems using game-theoretic learning. The authors introduce a framework to
estimate with high probability a numerical property of a system using measurements
from tests. In detail, the system is assumed to be modeled by a weighted directed
acyclic graph, whose weights might be altered by the environment, where the numerical quantity depends on the particular path chosen on the graph. The authors
take a game-theoretic approach where they try to learn a model of the system by
playing a game between the environment, which chooses the disturbances, and the
system, which chooses the inputs. The goal of the article is to try to estimate the
worst-case and average-case value of the quantity. The relevance of the article to
this special section is through the application of the proposed method, namely, the
authors demonstrate their approach on the estimation of the Worst-Case Execution
Time (WCET) problem for embedded software. WCET estimation is a very important
problem for verifying that the software can be scheduled for execution on a platform
without missing any deadlines. Toward that goal, the authors have implemented a
WCET estimation toolbox called GameTime. Among the benefits of GameTime are
its portability and its application to the actual platform rather than a model of the
system. The results of the article demonstrate that this is a very promising approach
of WCET estimation for soft real-time as well as for hard real-time computing
applications.
The article by Lan Wu and Wei Zhang presents one of the first applications of model
checking to estimating the WCET of multicore processors. In detail, the authors focus
on the WCET problem of independent threads running on multicore processors with a
shared L2 instruction cache. They model each concurrent process and their potential
interferences in the shared cache within SPIN. Then, they bound the WCET by performing a binary search, and they propose a number of modeling simplifications that
improve the running time of their framework, but at the same time guarantee the conservativeness of their results. Finally, the authors present a number of experiments on
a large number of benchmarks, which indicate that their approach gives better bounds
than a static analysis method.
The article by Quinghui Tang, Sandeep Gupta and Georgios Varsamopoulos
presents their work on proposing a general methodology to address thermal effects
and constraints in the scheduling of distributed cyber-physical systems. It presents an
abstract heat-flow model and shows how to identify and characterize possible thermal
interference. The article argues that the energy-related interaction of the distributed
cyber-physical system with the environment can be manipulated through the scheduling of the operational tasks of the distributed system. Thus, the article presents how
to formulate a scheduling problem based on the thermal interference. This can be
utilized to produce an operational schedule that is within some specified thermal constraints. Finally, the article shows how this methodology can be utilized on two very
different application domains, namely, an implanted biosensor network and a data
center.
The work of Truong Nghiem, George Pappas, Rajeev Alur and Antoine Girard focuses on the implementation of time-triggered controllers for linear systems. In this
work, they show techniques for synthesizing code from model-based designs of PID
controllers so that the gap between the model and the implementation that arises
from errors such as quantization, arithmetic errors, and time delays can be accurately
bounded. They demonstrate an application of their techniques to compare different implementations of a controller. Synthesizing code for CPS from models is an important
problem. This article makes a significant contribution on this front by directly dealing

ACM Transactions on Embedded Computing Systems, Vol. 11, No. S2, Article 52, Publication date: August 2012.

Editorial: Special Section VCPSS’09

52:3

with factors such as time delays in invoking a control task due to scheduling policy,
quantization, and arithmetic errors.
—Georgios Fainekos
Arizona State University

Eric Goubault
CEA LIST

Franjo Ivančić
Nec Laboratories America

Sriram Sankaranarayanan
University of Colorado Boulder

Guest Editors

ACM Transactions on Embedded Computing Systems, Vol. 11, No. S2, Article 52, Publication date: August 2012.

1

On the Minimal Revision Problem of Specification Automata
Kangjin Kim, Georgios Fainekos and Sriram Sankaranarayanan

arXiv:1404.2289v2 [cs.SY] 26 Nov 2014

Abstract
As robots are being integrated into our daily lives, it becomes necessary to provide guarantees on the safe and provably
correct operation. Such guarantees can be provided using automata theoretic task and mission planning where the requirements
are expressed as temporal logic specifications. However, in real-life scenarios, it is to be expected that not all user task requirements
can be realized by the robot. In such cases, the robot must provide feedback to the user on why it cannot accomplish a given
task. Moreover, the robot should indicate what tasks it can accomplish which are as “close” as possible to the initial user intent.
This paper establishes that the latter problem, which is referred to as the minimal specification revision problem, is NP complete.
A heuristic algorithm is presented that can compute good approximations to the Minimal Revision Problem (MRP) in polynomial
time. The experimental study of the algorithm demonstrates that in most problem instances the heuristic algorithm actually returns
the optimal solution. Finally, some cases where the algorithm does not return the optimal solution are presented.
Index Terms
Motion planning, temporal logics, specification revision, hybrid control.

I. I NTRODUCTION
As robots become mechanically more capable, they are going to be more and more integrated into our daily lives. Nonexpert users will have to communicate with the robots in a natural language setting and request a robot or a team of robots
to accomplish complicated tasks. Therefore, we need methods that can capture the high-level user requirements, solve the
planning problem and map the solution to low level continuous control actions. In addition, such frameworks must come with
mathematical guarantees of safe and correct operation for the whole system and not just the high level planning or the low
level continuous control.
Linear Temporal Logic (LTL) (see Clarke et al. 1999) can provide the mathematical framework that can bridge the gap
between
1) natural language and high-level planning algorithms (e.g., Kress-Gazit et al. 2008, Dzifcak et al. 2009), and
2) high-level planning algorithms and control (e.g., Fainekos et al. 2009, Karaman et al. 2008, Bhatia et al. 2010, Wongpiromsarn et al. 2010, Roy et al. 2011).
LTL has been utilized as a specification language in a wide range of robotics applications. For a good coverage of the current
research directions, the reader is referred to Fainekos et al. 2009, Kress-Gazit et al. 2009, Karaman et al. 2008, Kloetzer and
Belta 2010, Bhatia et al. 2010, Wongpiromsarn et al. 2010, Roy et al. 2011, Bobadilla et al. 2011, Ulusoy et al. 2011, Lacerda
and Lima 2011, LaViers et al. 2011, Filippidis et al. 2012 and the references therein.
For instance, in Fainekos et al. 2009, the authors present a framework for motion planning of a single mobile robot with
second order dynamics. The problem of reactive planning and distributed controller synthesis for multiple robots is presented
in Kress-Gazit et al. 2009 for a fragment of LTL (Generalized Reactivity 1 (GR1)). The authors in Wongpiromsarn et al.
2010 present a method for incremental planning when the specifications are provided in the GR1 fragment of LTL. The
papers Kloetzer and Belta 2010, Ulusoy et al. 2011 address the problem of centralized control of multiple robots where the
specifications are provided as LTL formulas. An application of LTL planning methods to humanoid robot dancing is presented
in LaViers et al. 2011. In Karaman et al. 2008, the authors convert the LTL planning problem into Mixed Integer Linear
Programming (MILP) or Mixed Integer Quadratic Programming (MIQP) problems. The use of sampling-based methods for
solving the LTL motion planning problem is explored in Bhatia et al. 2010. All the previous applications assume that the
robots are autonomous agents with full control over their actions. An interesting different approach is taken in Bobadilla et al.
2011 where the agents move uncontrollably in the environment and the controller opens and closes gates in the environment.
All the previous methods are based on the assumption that the LTL planning problem has a feasible solution. However, in
real-life scenarios, it is to be expected that not all complex task requirements can be realized by a robot or a team of robots.
In such failure cases, the robot needs to provide feedback to the non-expert user on why the specification failed. Furthermore,
it would be desirable that the robot proposes a number of plans that can be realized by the robot and which are as “close” as
possible to the initial user intent. Then, the user would be able to understand what are the limitations of the robot and, also,
he/she would be able to choose among a number of possible feasible plans.
In Fainekos 2011, we made the first steps towards solving the debugging (i.e., why the planning failed) and revision (i.e.,
what the robot can actually do) problems for automata theoretic LTL planning (Giacomo and Vardi 1999). We remark that a
This work has been partially supported by award NSF CNS 1116136.
K. Kim and G. Fainekos are with the School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ 85281,
USA {Kangjin.Kim,fainekos}@asu.edu
S. Sankaranarayanan is with the Department of Computer Science, University of Colorado, Boulder, CO srirams@colorado.edu

2

60
50

π

4

y2

40

π

30

π1

2

π3

20

π0

10
0

Fig. 1.

0

10

20

30

40

50
y1

60

70

80

90

100

The simple environment of Example 1 along with a low speed mobile robot trajectory that satisfies the specification.
π0 ∧ π2 ∧ π3
π0

s0

π0 ∧ π2

π0

π0 π0 ∧ π3

s1

s2

π0 ∧ π1 ∧ π4

π0 ∧ ¬π2 ∧ π4

π0 ∧ ¬π2 ∧ π3 ∧ π4

s3
π0 ∧ ¬π2

π0 ∧ π1 ∧ π3 ∧ π4

π0 ∧ π1

s4
π0 ∧ π1

∧4i=0 πi

Fig. 2.

Fig. 2. The speciﬁcation automaton of Example 1.
The specification automaton Bm of Example 1.

large number of robotic applications, e.g., Fainekos et al. 2009, Kloetzer and Belta 2010, Bhatia et al. 2010, Bobadilla et al.
2011, Ulusoy et al. 2011 and LaViers et al. 2011, are utilizing this particular LTL planning method.
In the follow-up paper Kim et al. 2012, we studied the theoretical foundations of the specification revision problem when
both the system and the specification can be represented by ω-automata (Buchi 1960). In particular, we focused on the Minimal
Revision Problem (MRP), i.e., finding the “closest” satisfiable specification to the initial specification, and we proved that the
problem is NP-complete even when severely restricting the search space. Furthermore, we presented an encoding of MRP
as a satisfiability problem and we demonstrated experimentally that we can quickly get the exact solution to MRP for small
problem instances.
In Kim and Fainekos 2012, we revisited MRP and we presented a heuristic algorithm that can approximately solve MRP
in polynomial time. We experimentally established that the heuristic algorithm almost always returns the optimal solution on
random problem instances and on LTL planning scenarios from our previous work. Furthermore, we demonstrated that we can
quickly return a solution to the MRP problem on large problem instances. Finally, we provided examples where the algorithm
is guaranteed not to return the optimal solution.
This paper is an extension of the preliminary work by Kim et al. 2012 and Kim and Fainekos 2012. In this extended journal
version, we present a unified view of the theory alongside with the proofs that were omitted in the aforementioned papers. The
class of specifications that can be handled by our framework has been extended as well. The framework that was presented in
Kim et al. 2012 was geared towards robotic motion planning specifications as presented in Fainekos et al. 2009. In addition,
we prove that the heuristic algorithm that we presented in Kim and Fainekos 2012 has a constant approximation ratio only on
a specific class of graphs. Furthermore, we have included several running examples to enhance the readability of the paper as
well as more case studies to demonstrate the feasibility of the framework. On the other hand, we have excluded some details
on the satisfiability encoding of the MRP problem which can be found in Kim et al. 2012.
II. P ROBLEM F ORMULATION
In this paper, we work with discrete abstractions (Finite State Machines) of the continuous robotic control system (Fainekos
et al. 2009). This is a common practice in approaches that hierarchically decompose the control synthesis problem into high
level discrete planning synthesis and low level continuous feedback controller composition (e.g., Fainekos et al. 2009, KressGazit et al. 2009, LaViers et al. 2011, Kloetzer and Belta 2010, Ulusoy et al. 2011). Each state of the Finite State Machine
(FSM) T is labeled by a number of symbols from a set Π = {π0 , π1 , . . . , πn } that represent regions in the configuration
space (see LaValle 2006 or Choset et al. 2005) of the robot or, more generally, actions that can be performed by the robot.
The control requirements for such a system can be posed using specification automata B with Büchi acceptance conditions
(see Buchi 1960) also known as ω-automata.
The following example presents a scenario for motion planning of a mobile robot.

3
60
50

z2

40
30
20
10
0

0

10

20

30

40

50
z

60

70

80

90

100

1

Fig. 3. The modified environment of Fig. 1 under large bounds on the permissible acceleration U . The red regions indicate areas that should be avoided in
order to satisfy ¬πi while the yellow regions indicate areas that should be visited in order to satisfy πi .

Fig. 4.

hTi (qi1 ) = {πi1 }

hTi (qi2 ) = {πi2 }

hTi (qi3 ) = {πi3 }

qi1

qi2

qi3

Fig. 4. Simple FSM model
of an object or an autonomous agent. Each
Simple FSM model Ti of an autonomous agent. Each state j of the FSM i is labeled by an atomic proposition πij .

Example 1 (Robot Motion Planning). We consider a mobile robot which operates in a planar environment. The continuous
state variable x(t) models the internal dynamics of the robot whereas only its position y(t) is observed. In this paper, we will
consider a 2nd order model of the motion of a planar robot (dynamic model):
ẋ1 (t) = x2 (t),
ẋ2 (t) = u(t),
y(t) = x1 (t).

x1 (t) ∈ R2 , x1 (0) ∈ X1,0

x2 (t) ∈ R2 , x2 (0) = 0, u(t) ∈ U

The robot is moving in a convex polygonal environment π0 with four areas of interest denoted by π1 , π2 , π3 , π4 (see Fig. 1).
Initially, the robot is placed somewhere in the region labeled by π1 . The robot must accomplish the task: “Stay always in π0
and visit area π2 , then area π3 , then area π4 and, finally, return to and stay in region π1 while avoiding area π2 ,” which is
captured by the specification automaton in Fig. 2.
In Fainekos et al. 2009, we developed a hierarchical framework for motion planning for dynamic models of robots. The
hierarchy consists of a high level logic planner that solves the motion planning problem for a kinematic model of the robot,
e.g.,
ż(t) = u(t),
y 0 (t) = z(t).

z(t) ∈ R2 , z(0) ∈ Z0

Then, the resulting hybrid controller is utilized for the design of an approximate tracking controller for the dynamic model.
Since the tracking is approximate, the sets π need to be modified (see Fig. 3 for an example) depending on the maximum
speed of the robot so that the controller has a guaranteed tracking performance. For example, in Fig. 3, the regions that now
must be visited are the contracted yellow regions, while the regions to be avoided are the expanded red regions. However, the
set modification might make the specification unrealizable, e.g., in Fig. 3 the robot cannot move from π4 to π1 while avoiding
π2 , even though the specification can be realized on the workspace of the robot that the user perceives. In this case, the user
is entirely left in the dark as of why the specification failed and, more importantly, on what actually the system can achieve
under these new constraints. This is especially important since the low level controller synthesis details should be hidden from
the end user.
4
The next example presents a typical scenario for task planning with two agents.
Example 2 (Multi-Agent Planning). We consider two autonomous agents whose independent actions can be modeled using
an FSM as in Fig. 4. In this example, each state qi represents a location i. In order to construct a simple example, we assume
that at each discrete time instance only one agent can move. Alternatively, we can think of these agents as being objects moved
around by a mobile manipulator and that the manipulator can move only one object at a time. This means that the state
of both objects can be described by the asynchronous composition of the two state machines T1 and T2 . The asynchronous
composition results in a FSM T with 9 states where each state (q1i , q2j ) is labeled by hT (q1i , q2j ) = hT1 (q1i ) ∪ hT2 (q2j ).
The system must accomplish the task: “Object 2 should be placed in Location 3 after Object 1 is placed in Location 3”.
Note that this requirement could be used to enforce that Object 2 is going to be positioned on top of Object 1 at the end of
the system execution. However, the requirement permits temporary placing Object 2 in Location 3 before Object 1 is placed in

4

state

of the FSM

is labeled by an atomic proposition

.

¬π 13

s2
¬π13

π13 ∧ π23

¬π13

s3

π23

s1

π23

π13 ∧ π23

¬π13

s4
π23

π23

Fig. 5.

The specification automaton of Example 2.Fig. 2.

The speciﬁcation automaton of Example 1.

Location 3. This should be allowed for problems where a temporary reposition of the objects is necessary. Now, let’s assume
that the aforementioned task is just a part from a long list or requirements which also include the task: “Always, Object 1
should not be in Location 3 until Object 2 moves in Location 3”.
These are informal requirements and in order to give them mathematical meaning we will have to use a formal language.
In Linear Temporal Logic (LTL) (see Clarke et al. 1999), the requirements become1 : F(π13 ∧ Fπ23 ) and G((¬π13 ) Uπ23 ).
We remark that the conjunction of these two requirements is actually a satisfiable specification (even though the requirements
appear conflicting) and the corresponding specification automaton is presented in Fig. 5. The specification remains satisfiable
because the semantics of the logic permit both objects to be place in Location 3 at the same time (see transitions on label
π13 ∧ π23 from states s1 and s2 to state s3 ).
However, there is no trajectory of the FSM T that will satisfy the specification. Recall that the model does not allow for
simultaneous transitions of the two objects. Again, the user does not know why the specification failed and, more importantly,
on what actually the system can achieve that is “close” to the initial user intent.
4
When a specification B is not satisfiable on a particular system T , then the current motion planning and control synthesis
methods (e.g., Fainekos et al. 2009, Kloetzer and Belta 2010, LaViers et al. 2011) based on automata theoretic concepts (see
Giacomo and Vardi 1999) simply return that the specification is not satisfiable without any other user feedback. In such cases,
we would like to be able to solve the following problem and provide feedback to the user.
Problem 1 (Minimal Revision Problem (MRP)). Given a system T and a specification automaton B, if the specification B
cannot be satisfied on T , then find the “closest” specification B 0 to B which can be satisfied on T .
Problem 1 was first introduced in Fainekos 2011 for Linear Temporal Logic (LTL) specifications. In Fainekos 2011, we
provided solutions to the debugging and (not minimal) revision problems and we demonstrated that we can easily get a minimal
revision of the specification when the discrete controller synthesis phase fails due to unreachable states in the system.
Assumption 1. All the states on T are reachable.
In Kim et al. 2012, we introduced a notion of distance on a restricted space of specification automata and, then, we were able
to demonstrate that MRP is in NP-complete even on that restricted search space of possible solutions. Since brute force search
is prohibitive for any reasonably sized problem, we presented an encoding of MRP as a satisfiability problem. Nevertheless,
even when utilizing state of the art satisfiability solvers, the size of the systems that we could handle remained small (single
robot scenarios in medium complexity environments).
In Kim and Fainekos 2012, we provided an approximation algorithm for MRP. The algorithm is based on Dijkstra’s singlesource shortest path algorithm (see Cormen et al. 2001), which can be regarded both as a greedy and a dynamic programming
algorithm (see Sniedovich 2006). We demonstrated through numerical experiments that not only the algorithm returns an
optimal solution in various scenarios, but also that it outperforms in computation time our satisfiability based solution. Then,
we presented some scenarios where the algorithm is guaranteed not to return the optimal solution.
Contributions: In this paper, we define the MRP problem and we provide the proof that MRP is NP-complete even
when restricting the search space (e.g., Problem 2). Then, we provide an approximation algorithm for MRP and theoretically
establish the upper bound of the algorithm for a special case. Furthermore, we show that for our heuristic algorithm a constant
approximation ratio cannot be established, in general. We also present experimental results of the scalability of our framework
and establish some experimental approximation bounds on random problem instances. Finally, in order to improve the paper
presentation, we also provide multiple examples that have not been published before.
III. P RELIMINARIES
In this section, we review some basic results on the automata theoretic planning and the specification revision problem from
Fainekos et al. 2009, Fainekos 2011.
1 Here, F stands for eventually in the future, U for until and G for always. Further introduction of LTL is out of the scope of this paper and the interested
reader can explore the logic in Fainekos et al. 2009. We use LTL in the following for succinctness in the presentation.

5

Throughout the paper, we will use the notation P(A) for representing the powerset of a set A, i.e., P(A) = {B | B ⊆ A}.
Clearly, it includes ∅ and A itself. We also define the set difference as A \ B = {x ∈ A | x ∈
/ B}.
A. Constructing Discrete Controllers
We assume that the combined actions of the robot/team of robots and their operating environment can be represented using
an FSM.
Definition 1 (FSM). A Finite State Machine is a tuple T = (Q, Q0 , →T , hT , Π) where:
• Q is a set of states;
• Q0 ⊆ Q is the set of possible initial states;
• →T ⊆ Q × Q is the transition relation; and,
• hT : Q → P(Π) maps each state q to the set of atomic propositions that are true on q.
We define a path on the FSM to be a sequence of states and a trace to be the corresponding sequence of sets of propositions.
Formally, a path is a function p : N → Q such that for each i ∈ N we have p(i) →T p(i + 1) and the corresponding trace is
the function composition p̄ = hT ◦ p : N → P(Π). The language L(T ) of T consists of all possible traces.
Example 3. For the two agent system in Example 2, a path would be (q11 , q21 )(q11 , q22 )(q12 , q22 ) . . . and the corresponding
trace would be {π11 , π21 }{π11 , π22 }{π12 , π22 } . . ..
In this work, we are interested in the ω-automata that will impose certain requirements on the traces of T . Omega automata
differ from the classic finite automata in that they accept infinite strings (traces of T in our case).

Definition 2. A automaton is a tuple B = (SB , sB
0 , Ω, →B , FB ) where:
• SB is a finite set of states;
B
• s0 is the initial state;
• Ω is an input alphabet;
• →B ⊆ SB × Ω × SB is a transition relation; and
• FB ⊆ SB is a set of final states.
l

We also write s →B s0 instead of (s, l, s0 ) ∈→B . A specification automaton is an automaton with Büchi acceptance condition
where the input alphabet is the powerset of the labels of the system T , i.e., Ω = P(Π).
A run r of a specification automaton B is a sequence of states r : N → SB that occurs under an input trace p̄ taking values
p̄(i)
in Ω = P(Π). That is, for i = 0 we have r(0) = sB
0 and for all i ≥ 0 we have r(i) → B r(i + 1). Let lim(·) be the function
that returns the set of states that are encountered infinitely often in the run r of B. Then, a run r of an automaton B over an
infinite trace p̄ is accepting if and only if lim(r) ∩ FB 6= ∅. This is called a Büchi acceptance condition. Finally, we define the
language L(B) of B to be the set of all traces p̄ that have a run that is accepted by B.
Even though the definition of specification automata (Def. 2) only uses sets of atomic propositions for labeling transitions, it
is convenient for the user to read and write specification automata with propositional formulas on the transitions. The popular
translation tools from LTL to automata, e.g., Gastin and Oddoux [2001], label the transitions with propositional formulas in
Disjunctive Normal Form (DNF). A DNF formula on a transition of a specification automaton can represent multiple transitions
between two states. In the subsequent sections, we will be making the following simplifying assumption on the structure of
the specification automata that we consider.
Assumption 2. All the propositional formulas that appear on the transitions of a specification automaton are in Disjunctive
Normal Form (DNF). That is, for any two statesWs1 , s2 ofVan automaton B, we represent the propositional formula that labels
the corresponding transition by ΦB (s1 , s2 ) = i∈Ds s j∈C i ψij for some appropriate set of indices Ds1 s2 and Csi1 s2 .
s1 s2
1 2
Here, ψij is a literal which is π or ¬π for some π ∈ Π. Finally, we assume that when any subformula in ΦB (s1 , s2 ) is a
tautology or a contradiction, then it is replaced by > (true) or ⊥ (false), respectively.
The last assumption is necessary in order to avoid converting a contradiciton like π ∧ ¬π into a satisfiable formula (see Sec.
IV). We remark that the Assumption 2 does not restrict the scope of this work. Any propositional formula can be converted
in DNF where any negation symbol appears in front of an atomic proposition.
Example 4. Let us consider the specification automaton in Fig. 5. The propositional formulas over the set of atomic propositions
Π are shorthands for the subsets of Π that would label the corresponding transitions. For example, the label π13 ∧ π23 over
the edge (s2 , s3 ) succinctly represents all the transitions (s2 , l, s3 ) such that {π13 , π23 } ⊆ l ⊆ Π. On the other hand, the label
¬π13 over the edge (s1 , s2 ) succinctly represents all the transitions (s1 , l, s2 ) such that l ⊆ Π and π13 6∈ l. On input trace
{π11 , π21 }{π11 , π22 }{π12 , π22 } . . . the corresponding run would be s1 s2 s2 s2 . . ..
4
In brief, our goal is to generate paths on T that satisfy the specification Bs . In automata theoretic terms, we want to find
the subset of the language L(T ) which also belongs to the language L(Bs ). This subset is simply the intersection of the two

6

languages L(T ) ∩ L(Bs ) and it can be constructed by taking the product T × Bs of the FSM T and the specification automaton
Bs . Informally, the automaton Bs restricts the behavior of the system T by permitting only certain acceptable transitions. Then,
given an initial state in the FSM T , we can choose a particular trace from L(T ) ∩ L(Bs ) according to a preferred criterion.
Definition 3. The product automaton A = T × Bs is the automaton A = (SA , sA
0 , P(Π), →A , FA ) where:
• SA = Q × SBs ,
B
A
• s0 = {(q0 , s0 s ) | q0 ∈ Q0 },
l
l
• →A ⊆ SA × P(Π) × SA s.t. (qi , si ) →A (qj , sj ) iff qi →T qj and si →Bs sj with l = hT (qj ), and
• FA = Q × FB is the set of accepting states.

Note that L(A) = L(T ) ∩ L(Bs ). We say that Bs is satisfiable on T if L(A) 6= ∅. Moreover, finding a satisfying path on
T × Bs is an easy algorithmic problem (see Clarke et al. 1999). First, we convert automaton T × Bs to a directed graph and,
then, we find the strongly connected components (SCC) in that graph.
If at least one SCC that contains a final state is reachable from an initial state, then there exist accepting (infinite) runs on
T × Bs that have a finite representation. Each such run consists of two parts: prefix: a part that is executed only once (from
an initial state to a final state) and, lasso: a part that is repeated infinitely (from a final state back to itself). Note that if no
final state is reachable from the initial or if no final state is within an SCC, then the language L(A) is empty and, hence, the
high level synthesis problem does not have a solution. Namely, the synthesis phase has failed and we cannot find a system
behavior that satisfies the specification.
Example 5. The product automaton of Example 2 has 36 states and 240 number of transitions. However, no final state is
reachable from the initial state.
4
IV. T HE S PECIFICATION R EVISION P ROBLEM
Intuitively, a revised specification is one that can be satisfied on the discrete abstraction of the workspace or the configuration
space of the robot. In order to search for a minimal revision, we need first to define an ordering relation on automata as well
as a distance function between automata. Similar to the case of LTL formulas in Fainekos 2011, we do not want to consider
the “space” of all possible automata, but rather the “space” of specification automata which are semantically close to the initial
specification automaton Bs . The later will imply that we remain close to the initial intention of the designer. We propose that
this space consists of all the automata that can be derived from Bs by relaxing the restrictions for transitioning from one state
to another. In other words, we introduce possible transitions between two states of the specification automaton.
Example 6. Consider the specification automaton Bs and the automaton B1 in Fig. 6. The transition relations of the two
automata are defined as:
¬π

¬π ∧π

π

2
1
0
0−→Bs 0
0−
−−0−−→
0−−→Bs 0
Bs 1
}|
{ z
}|
{ z
}|
{
z
→Bs = {(0, l, 0) | l ⊆ Π and π0 6∈ l} ∪ {(0, l, 0) | {π2 } ⊆ l ⊆ Π} ∪ {(0, {π1 }, 1), (0, {π1 , π2 }, 1)} ∪
¬π

¬π ∧π

¬π ∧π ∧π

0
2
0
1
2
1−−→Bs 1
1−
0−−−−−−−→Bs 2
−−0−−→
Bs 2
}|
{ z
}|
{ z
}|
{
z
∪ {(1, l, 1) | l ⊆ Π and π0 6∈ l} ∪ {(1, {π2 }, 2), (1, {π1 , π2 }, 2)} ∪ {(0, {π1 , π2 }, 2)} ∪
¬π0

2−−→Bs 2

}|
{
z
∪ {(2, l, 2) | l ⊆ Π and π0 6∈ l}

¬π0 ∧π1

>

0−
→B1 0

>

0−
−−−−→B1 1

1−
→B1 1

¬π0 ∧π2

1−
−−−−→B1 2

z
}|
{ z
}|
{ z
}|
{ z
}|
{
→B1 = {(0, l, 0) | l ⊆ Π} ∪ {(0, {π1 }, 1), (0, {π1 , π2 }, 1)} ∪ {(1, l, 1) | l ⊆ Π} ∪ {(1, {π2 }, 2), (1, {π1 , π2 }, 2)} ∪
π

¬π

2
0
1−→B1 2
2−−→B1 2
z
}|
{ z
}|
{
∪ {(1, l, 2) | {π2 } ⊆ l ⊆ Π} ∪ {(2, l, 2) | l ⊆ Π and π0 6∈ l}

and, hence, →Bs ⊂→B1 . In other words, any transition allowed by Bs is also allowed by B1 and, thus, any trace accepted by
Bs is also accepted B1 . If we view this from the perspective of the specification, then this means that the specification imposes
less restrictions or that the specification automaton B1 is a relaxed specification with respect to Bs .
As the previous example indicated, specification relaxation could be defined as the subset relation between the transition
relations of the specification automata. However, this is not sufficient from the perspective of user requirements. For instance,
(¬π0 ∧π2 )∨π3
¬π ∧π2
2 could be relaxed as 1 −
consider again Example 6. The transition 1 −−−0−−→
−−−−−−−−→Bs 2 . A relevant relaxation
Bs
from the user perspective should be removing either of the constraints ¬π0 or π2 rather than introducing a new requirement

7
π0−

1

π0− ∧ π1

0
π0−

∨ π2

π0− ∧ π2

π0− ∧ π1 ∧ π2

π0− ∧ π1

2

0

π0−

⊤

(Bs )

0
π0− ∨ π2

Fig. 6.

π0−

π0− ∧ π2

2
π0−

π0−

π0−

∧ π1

0
π0− ∨ π2

π0−

π0− ∧ π1 ∧ π2
π2

(B3 )

q1

q

(T )

q3

hT (q3 ) = {π1 , π

2

(B1 )

1

q0

π0− ∧ π2

π0−

∧ π1 ∧ π2

(B2 )

1
π2

π0−

1

hT (q1 ) = {π1 , π3 } hT (q2 ) =

⊤

∧ π2

Λ(e1 ) = {π0 , π2 }
L(e1 ) = {y((s1 , s1 ), π0 ),
y((s1 , s1 ), π2 )}

q0 , s1

2
π0−

−
¬π0 ;specification
Bs  B1 ; Bautomaton,
k B3π.− ≡ ¬π0 ;
Example 7. Bs : the initial specification
here
s k B2 ; Bshere
0 ≡
Fig. 6. automaton,
(Example 7)
Bs π
: the
initial
0
Bs  B1 ; Bs k B2 ; Bs k B3 .

q1 , s1

Λ(e3 ) = {π0 , π2 }

(G A )

Λ(e2 )
L(e2 ) = {
y((s1

L(e3 ) = {
y((s1

q3 , s1

Fig. 7. Example 8. T : part of the system; B
automaton; GA : part of the graph that correspond

π3 . Introducing π3 may implicitly relaxe both constraints ¬π0 and π2 in certain contexts. However, our goal in this paper is
→Bs − →B1 = {(0, {π0− }, 0), (0, {π2 }, 0), (1, {π0− }, 1),
to find a minimal relaxation.
A. Minimal Revision as a Graph Searc
III, we indicated that a transition
(0,relation
{π0− , π1could
, π2 },be
2)}compactly represented using a proposition formula ΦB (s1 , s2 ) =
W In Sec. V
In order
to solve Problem
states (s1 , s2 ) and a set of indices D̂s1 s2 , Ĉsi1 s2 , we define
a substitution
θ as 2, we cons
i∈Ds1 s2
j∈Csi s ψij in DNF. Given
→B1 a−pair
→Bof
1 2
s = {(0, ∅, 0), (1, ∅, 1), (0, {π2}, 2)}
graph
G
from
the
product
automato
A

i
−
−
edges
of
G
are
labeled
by
a set o
> 2 }, {π
if 2i}∈⊆D̂{π
∈ Ĉs1 s2
A
and
∅ ⊆ {π
π1 , πj2 }.
s1 s02 , and
θ(s∅1 ,⊆s2{π
, ψ0ij},
)=
which
if
removed
from
the
correspon
ψij Bs otherwise
Similarly, we have
k B2 since →Bs − →B2 =
−
they will enable the transition on A.
{(0,
{π
,
π
},
1)}
while
→
− →Bs = between
∅, i.e., two
we have
1
B
2
0
That is, a substitution only relaxes the constraints
on the possible
transitions
automaton states.
removed aB transition between two states. We
have Bs k B3 then becomes one of finding the lea
B2
Definition 4 (Relaxation). Let B1 =
(SB→
, s 1 , Ω, → 1 , F
) and→
BB2 =−(S→
, Ω, →
, F0)},
two Büchi automata.
Then, in order fo
to be removed
Bwhile
B2B, s=
B2 ) bepropositions
1 B0 − →B B=
1
since
∅
{(2,
{πB22},
0
s
3
3
s
B1
B2
we say that B2 is a relaxation of i.e.,
B1 and
we
write
B

B
if
and
only
if
(1)
S
=
S
=
S,
(2)
s
=
s
,
(3)
F
=
F
have
an accepting
Next,
we provid
1 a transition
2
B2 Recall
Brun.
B2
1
0
0
we have added
between twoB1 states.
W
V
0
0
0
and (4) there exists a substitutionthat
θ such
that
for
all
(s,
s
)
∈
S
×
S,
we
have
Φ
(s,
s
)
≡
θ(s,
s
,
ψ
)
when
i
of
the
graph
G
which
corresponds
to
B2one transition.
ij
A
between
any
two
states
we
may
have
only
i∈D
j∈C
0
0
ss
ss
W
V
A while considering the effect of revis
ΦB1 (s, s0 ) = i∈D 0 j∈C i ψij .△
ss

ss0

Definition
7. Given
can
the setrelation
of automata
over
which
we will
In Def. 4, when defining ΦB2 (s, s0We
), we
usenow
the define
equivalence
≡ rather
then
equality
= in order
to highlight
thatainsystem
the T and a s
0
B
,
we
define
the
graph
s
for a inminimal
solutionThe
thatonly
hascase
nonempty
intersection
resulting DNF formula no constantsearch
> appears
a subformula.
where >
can appear is when
ΦB2 (s, s ) ≡ >. WeGA = (V, E
2
corresponds
theautomata
product A = T × B
remark that if B1  B2 , then L(Bwith
L(Bsystem.
two
1 ) ⊆ the
2 ) since the relaxed automaton allows more behaviors to occur . If to
B1 and B2 cannot be compared under relation , then we write B1 k B2 . The intuition behind the ordering
4
• V = relation
S is theinsetDef.
of nodes
Definition 5. Given a system T and a specification automaton
is better explained by an example.
• E = EA ∪ED ⊆ S ×S, where EA
Bs , the set of valid relaxations of Bs is defined as R(Bs , T ) =
correspond to transitions on A,
Example 7 (Continuing from Example
Consider
{B | 6).
Bs 
B and the
L(Tspecification
× B) 6= ∅}.automaton Bs and the automata B1 -B3 in Fig. 6. Definition
l
3
. (q, s) →A (
A iff ∃l ∈ P(Π)
4 specifies that the two automata must have transitions between exactly the same states . Moreover, if theEpropositional
formula
We can now search for a minimal solution in the set
set of edges
thatoncorrespond
to dis
that labels a transition between the same pair of states on the two automata differs, then the propositional
formula
the
R(Bs , T ). That is, we can search for some B ∈ R(Bs , T )
′ ′
((q, s),
(q latter
, s )) means
∈ ED iff q →T q
relaxed automaton must be derived by the corresponding label of
the original automaton by removing literals.
The
such that if for any other B ′ ∈ R(Bs , T ), we have B ′  B,
′
l
∩
(Π
−
h
(q
))
6= ∅
that we have relaxed the constraints that permit a transition
on
the
specification
automaton.
T
then L(B) = L(B ′ ). However, this does not imply that a
π
2 v =2sA is the source node
•→
s
is
derived
from
By visual inspection of Bs and B1 in Fig. 6, we see that Bs  B1 . For example, the transition 0 −
0
B1
minimal solution semantically is minimal structurally as well.
¬π0 ∧π1 ∧π2
• Vf = FA is the set of sinks
0 −
−−−−−−→Bs 2 by replacingInthe
literals
¬π
and
π
with
>.
Similarly,
we
have
B
k
B
since
Φ
∧ π1
0
1
s
2
Bs (0, 1) = ¬π
other words, it could be the case that B1 and B2 are
′ 0
′
• Π = {hπ, (s, s )i | π ∈ Π, (s, s ) ∈
and ΦB2 (0, 1) = ⊥, i.e., we haveminimal
removedrelaxations
a transitionofbetween
two
states.
We
also
have
B
k
B
since
Φ
(2,
0)
=
⊥
and
s
3
B
s
some Bs , but B1 k B2 and, moreover,
• Λ : E → P(Π) is the edge labelin
ΦB3 (2, 0) = π2 , i.e., we have added
transition
two states.
4
B1 arequires
thebetween
modification
of only one transition while B2
e = ((q, s), (q ′ , s′ )), then
requires
the modification
of automata
two transitions.
Therefore,
We remark that we restrict the space
of relaxed
specification
to all automata
thatwe
have the same number of states,
mustsetdefine
a metric
set R(Bs , T ),reasons.
which accounts
Λ(e) = {hπ,we
(s,can
s′ )i | π ∈ (λBs
the same initial state, and the same
of final
stateson
forthecomputational
Namely, for
under these restrictions,
number
of achanges
from the
initial specification
automaton
convert the specification revision the
problem
into
graph search
problem.
Otherwise, the
graph would have to me mutated by
adding and/or removing states. Bs .
If for some edge e, Λ(e) 6= ∅, then
We can now define the set of automata
whichawe
will Tsearch
a minimalautomaton
solution that atomic
has nonempty
intersection
propositions
in λBs (s, s′ ) that n
Definitionover
6. Given
system
and afor
specification
with the system.
Bs , we define thePdistance of any B ∈ R(Bs , T ) from Bs to order to enable the edge in the product
′
′
of the edges of GA are subsets of
be dist
(s, sset
)−
)| where | ·of
| Blabels
B (s, srelaxations
Bs (B) = automaton
Definition 5. Given a system T and
a specification
BsB,sthe
ofλvalid
s is defined as R(Bs , T ) =
(s,s′ )∈EBs |λ
is
due
to the fact that we are looking in
is
the
cardinality
of
the
set.
{B | Bs  B and L(T × B) 6= ∅}.
proposition π from a specific transition
Therefore,
Problem
can be
2 Note that B  B implies that B simulates
all clearly,
occurrences
of π in Bs .
B1 under
the usual1 notion
of restated
simulation as:
relation Clarke et al. [1999]. than
However,
if B2 simulates
1
2
2
B1 , then we cannot infer that B2 is a relaxation of B1 as defined in Def. 4.
2. Given a system T and a specification au- Example
3 To keep the presentation simple, we doProblem
8. Consider
the Example in
not extend the definition of the ordering relation to isomorphic automata. Also, this
is not required
in our technical
tomaton
Bs which
sucharethat
L(T of×a specification
Bs ) = automaton.
∅, find The
B same
∈ holds
results since we are actually going to construct
automata
relaxations
for bisimilar
automata
(e.g.,
we provide
a partial
description
of an
Park 1981.)
arg min{distB (B ′ ) | B ′ ∈ R(Bs , T )}.
s

automaton Bs and the corresponding

F
F

8

We can now search for a minimal solution in the set R(Bs , T ). That is, we can search for some B ∈ R(Bs , T ) such that
if for any other B 0 ∈ R(Bs , T ), we have B 0  B, then L(B) = L(B 0 ). However, this does not imply that a minimal solution
semantically is minimal structurally as well. In other words, it could be the case that B1 and B2 are minimal relaxations of
some Bs , but B1 k B2 and, moreover, B1 requires the modification of only one transition while B2 requires the modification
of two transitions. Therefore, we must define a metric on the set R(Bs , T ), which accounts for the number of changes from
the initial specification automaton Bs .
Definition 6. (Distance) Given a system T and a specification
the distance of any B ∈ R(Bs , T )
P automaton
P Bs , we define
i
that results from Bs under substitution θ to be distBs (B) = (s,s0 )∈EB
|
Ĉ
|
where
| · | is the cardinality of the set.
0
ss
i∈D̂ 0
s

ss

We remark that given two relaxations B1 and B2 of some Bs where B1  B2 , but B2  B1 , then distBs (B1 ) ≤ distBs (B2 ).
Therefore, Problem 1 can be restated as:
Problem 2. Given a system T and a specification automaton Bs such that L(T ×Bs ) = ∅, find B ∈ arg min{distBs (B 0 ) | B 0 ∈
R(Bs , T )}.
A. Minimal Revision as a Graph Search Problem
In order to solve Problem 2, we construct a directed labeled graph GA from the product automaton A = T × Bs . The
edges of GA are labeled by a set of atomic propositions which if removed from the corresponding transition on Bs , they will
enable the transition on A. The overall problem then becomes one of finding the least number of atomic propositions to be
removed in order for the product graph to have an accepting run. Next, we provide the formal definition of the graph GA
which corresponds to a product automaton A while considering the effect of revisions.
To formally define the graph search problem, we will need some additional notation. We first create two new sets of symbols
from the set of atomic propositions Π:
−
−
• Π = {π | π ∈ Π}.
+
−
+
−
+
e
• Π = {l ∪ l | l ⊆ Π and l ⊆ ξS (Π \ l )}.
Given a transition between two states s1 and s2 of some B and a formula in DNF on the transition, we denote:
−
• ξl (ψ) = π if ψ = π, and π
if ψ = ¬π.
−
• ξS (l) = {π | π ∈ l} where l ⊆ Π.
Now, we can introduce the following notation. We define
•

•

l

the set EB ⊆ SB2 , such that (s, s0 ) ∈ EB iff ∃l ∈ P(Π) , s →B s0 ; and,
the function λB (s1 , s2 ) = {{ξl (ψij ) | j ∈ Csi1 s2 } | i ∈ Ds1 s2 } as a transition function that maps a pair of states to the
set of symbols that represent conjunctive clause.
l

That is, if (s, s0 ) ∈ EB , then ∃l ∈ P(Π). s →B s0 ; and if (s, s0 ) 6∈ EB , then λB (s, s0 ) = ∅. Also, if λB (s, s0 ) 6= ∅, then
e
∀l ∈ λB (s, s0 ) . l ⊆ P(Π).

e = {∅, {π0 }, {π − }, {π1 }, {π − }, {π0 , π − }, {π − , π1 }, Π, Π− }. Given a
Example 8. Consider a set Π = {π0 , π1 }. Then, Π
0
1
1
0
transition (s1 , s2 ) of B and same Π, consider ΦB (s1 , s2 ) = ¬π0 ∨ π1 on that transition. Then, λB (s1 , s2 ) = {{π0− }, {π1 }}. If
ΦB (s1 , s2 ) = ¬π0 ∧ π1 , then λB (s1 , s2 ) = {{π0− , π1 }}.

Definition 7. Given a system T and a specification automaton Bs , we define the graph GA = (V, E, vs , Vf , Π, ΛS ), which
corresponds to the product A = T × Bs as follows
• V = S is the set of nodes;
0 0
• E = EA ∪ ED ⊆ S × S, where EA is the set of edges that correspond to transitions on A, i.e., ((q, s), (q , s )) ∈ EA iff
l
∃l ∈ P(Π) . (q, s) →A (q 0 , s0 ); and ED is the set of edges that correspond to disabled transitions, i.e., ((q, s), (q 0 , s0 )) ∈
ED iff q →T q 0 and (s, s0 ) ∈ EBs , but there does not exist (s, l, s0 ) ∈→Bs such that l = hT (q 0 ));
A
• vs = s0 is the source node;
• Vf = FA is the set of sinks;
0
e , (s, s0 ) ∈ EB }
• Π = {hπ, (s, s )i | π ∈ Π
s
0 0
• ΛS : E → P(Π) is the edge labeling function such that if e = ((q, s), (q , s )), then
ΛS (e) = {hl0 , (s, s0 )i | l ∈ λBs (s, s0 ), l+ = (l ∩ Π) \ hT (q 0 ), l− = (l ∩ Π− ) \ ξS (Π \ hT (q 0 )) and l0 = l+ ∪ l− }.

Example 9 (Continuing Example 8). We will derive ΛS (e) for an edge e = ((q, s1 ), (q 0 , s2 )). Assume ΦB (s1 , s2 ) = ¬π0 ∨ π1 ,
then λB (s1 , s2 ) = {{π0− }, {π1 }}. If hT (q 0 ) = {π0 }, 
then for l = {π0− }, l+ = ∅, l− = {π0− } and l0 = {π0− }, and for l = {π1 },
l+ = {π1 }, l− = ∅ and l0 = {π1 }. Thus, ΛS (e) = { {π0− }, (s1 , s2 ) , h{π1 }, (s1 , s2 )i}.
Now assume Φ(s1 , s2 ) = ¬π0 ∧π1 , then λB (s1 , s2 ) = {{π0− , π1 }}. If hT (q 0 ) = {π2 }, then l = {π0− , π1 }, l+ = {π1 }\{π2 } =
{π1 }, l− = {π0− } \ {π0− , π1− } = ∅, and l0 = {π1 }. Thus, ΛS (e) = {h{π1 }, (s1 , s2 )i}.

9

In order to determine which atomic propositions we must remove from a transition of the 
specification automaton,
we need to

make sure that we can uniquely identify them. Recall that ΛS returns a set, e.g., ΛS (e) = { {π0− , π1 }, (s, s0 ) , h{π1 }, (s, s0 )i}.
Saying that we need to remove π1 from the label of (s, s0 ), it may not be clear which element of the set ΛS π1 refers to. This
affects both the theoretical connection of the graph GA as a tool for solving Problem 2 and the practical implementation of
any graph search algorithm (e.g., see line 22 of Alg. 2 in Sec. V).
Thus, in the following, we assume that GA uses a function Λ : E → Π instead of ΛS . Now, Λ maps each edge e to just a
single tuple hl, (s, s0 )i instead of a set as in Def. 7. This can be easily achieved by adding some dummy states in the graph with
incoming edges labeled by the tuples in the original set ΛS (e). We can easily convert the original graph GA to the modified
one. First, for each edge e = ((q, s), (q 0 , s0 )) ∈ ED , we add |ΛS ((q, s), (q 0 , s0 ))| new nodes ṽie , i = 1, . . . , |ΛS ((q, s), (q 0 , s0 ))|.
Second, we add the edge ((q, s), ṽie ) to E and set each label Λ((q, s), ṽie ) with exactly one hl, (s, s0 )i ∈ ΛS ((q, s), (q 0 , s0 )).
Then, we add the edges (ṽie , (q 0 , s0 )) to E and set Λ(ṽie , (q 0 , s0 )) = h∅, (s, s0 )i. Finally, we repeat until all the edges are labeled
by tuples rather than sets.
We remark that every time we add a new node vie for an edge that corresponds to the same transition (s, s0 ) of the specification
automaton, then we use the same index i for each member of ΛS (e). This is so that later we can map each edge of the modified
graph GA to the correct clause in the DNF formula of the specification automaton. The total number of new nodes that we
need to add depends on the number of disjunctions on each label of the specification automaton and the structure of the FSM.
Now, if for some edge e, Λ(e) 6= ∅, then Λ(e) specifies those atomic propositions in λBs (s, s0 ) that need to be removed
in order to enable the edge in the product state of A. Note that the labels of the edges of GA are elements of Π rather than
subsets of Π. This is due to the fact that we are looking into removing an atomic proposition π from a specific transition
(s, l, s0 ) of Bs rather than all occurrences of π in Bs .
In the following, we assume that vs 6∈ Vf , otherwise, we would not have to revise the specification. Furthermore, we define
e × EB × N is defined to be the size of the set l.
| hl, (s, s0 ), ii | = |l|, i.e., the size of a tuple hl, (s, s0 ), ii ∈ Π
s
Definition 8. (Path Cost) For some n > 0, let µ = e1 e2 . . . en be a finite path on the graph GA that consists of edges of
GA . Let



((q,s),(q 0 ,s0 ))
i if ej = ((q, s), ṽi
)
e
Λ(µ)
= hl, (s, s0 ), ki | l = ∪j∈J lj , J ⊆ {1 . . . n}, ∀j ∈ J, Λ(ej ) = hlj , (s, s0 )i , k =
.
0 otherwise
We define the cost of the path µ to be

Cost(µ) =

X

e
λ∈Λ(µ)

|λ|.

e
In the above definition, Λ(µ)
collects in the same tuple all the atomic propositions that must be relaxed in the same transition
e
of the specification automaton. It is easy to see that given some set Λ(µ),
then we can construct a substitution θµ for the
e
corresponding relaxed specification automaton since all the required information is contained in the members of Λ(µ).
Example 10. Consider the Example in Fig. 7. In the figure, we provide a partial description of an FSM T , a specification
automaton Bs and the corresponding product automaton A. The dashed edges indicate disabled edges which are labeled by
the atomic propositions that must be removed from the specification in order to enable the transition on the system. In this
example, we do not have to add any new nodes since we have only one conjunctive clause on the transition of the specification
automaton.
It is easy to see now that in order to enable the path (q0 , s1 ), (q1 , s1 ), (q3 , s1 ) on the product automaton, we need to replace π0
e 1 e3 ) = {h{π0 , π2 }, (s1 , s1 ), 0i}.
and π2 with > in ΦBs (s1 , s1 ) = π0 ∧π1 ∧π2 ∧π3 . On the graph GA , this path corresponds to Λ(e
Similarly, in order to enable the path (q0 , s1 ), (q1 , s1 ), (q2 , s1 ) on the product automaton, we need to replace π0 , π2 and π3
e 1 e2 ) = {h{π0 , π2 π3 }, (s1 , s1 ), 0i}.
with > in ΦBs (s1 , s1 ). On the graph GA , this path corresponds to Λ(e
Therefore, the path defined by edges e1 and e3 is preferable over the path defined by edges e1 and e2 . In the first case, we
have cost C(e1 e3 ) = 2 which corresponds to relaxing 2 requirements, i.e., π0 and π2 , while in the latter case, we have cost
C(e1 e2 ) = 3 which corresponds to relaxing 3 requirements, i.e., π0 , π2 and π3 .
4
A valid relaxation B should produce a reachable vf ∈ Vf with prefix and lasso path such that L(T × B) 6= ∅. The next
section provides an algorithmic solution to this problem.
V. A H EURISTIC A LGORITHM FOR MRP
In this section, we present an approximation algorithm (AAMRP) for the Minimal Revision Problem (MRP). It is based
on Dijkstra’s shortest path algorithm (Cormen et al. 2001). The main difference from Dijkstra’s algorithm is that instead of
finding the minimum weight path to reach each node, AAMRP tracks the number of atomic propositions that must be removed
from each edge on the paths of the graph GA .
The pseudocode for the AAMRP is presented in Algorithms 1 and 2. The main algorithm (Alg. 1) divides the problem into
two tasks. First, in Line 5, it finds an approximation to the minimum number of atomic propositions from Π that must be

10

hT (q1 ) = {π1 , π3 } hT (q2 ) = {π1 , π2 }

q0

q1

q2

s1
π0 ∧ π1 ∧ π2 ∧ π3

(T )

q3

hT (q3 ) = {π1 , π3 }

Λ(e1 ) = h{π0 , π2 }, (s1 , s1 )i

q0 , s1

(Bs )

Λ(e2 ) = h{π0 , π3 }, (s1 , s1 )i

q1 , s1

q2 , s1

Λ(e3 ) = h{π0 , π2 }, (s1 , s1 )i

(G A )
Fig. 7.

q3 , s1

Example 10. T : part of the system; Bs : part of the specification automaton; GA : part of the graph that corresponds to the product automaton.

Algorithm 1 AAMRP
Inputs: a graph GA = (V, E, vs , Vf , Π, Λ).
Outputs: the list L of atomic propositions form Π that must be removed Bs .
1: procedure AAMRP(GA )
2:
L←Π
3:
M[:, :] ← (Π, ∞)
4:
M[vs , :] ← (∅, 0)
. Initialize the source node
5:
hM, P, Vi ← F IND M IN PATH(GA , M, 0)
6:
ACCEPTABLE ← F alse
7:
for vf ∈ V ∩ Vf do
8:
Lp ← G ETAPF ROM PATH(vs , vf , M, P)
9:
M0 [:, :] ← (Π, ∞)
10:
M0 [vf , :] ← (Lp , |Lp |)
. Store APs from prefix path vs ; vf to M0 [vf , :]
0
11:
GA ← (V, E, vf , {vf }, Π, Λ)
12:
hM0 , P0 , V 0 i ← F IND M IN PATH(G0A , M0 , 1)
13:
if vf ∈ V 0 then
14:
L0 ← G ETAPF ROM PATH(vf , vf , M0 , P0 )
. Get APs of prefix vs ; vf and lasso vf ; vf from M0 [vf , :]
0
15:
if |L | ≤ |L| then
16:
L ← L0
17:
end if
18:
ACCEPTABLE ← T rue
19:
end if
20:
end for
21:
if ¬ACCEPTABLE then
22:
L←∅
23:
end if
24:
return L
25: end procedure
The function G ETAPF ROM PATH((vs , vf , M, P)) returns the atomic propositions that must be removed from Bs in order to
enable a path on A from a starting state vs to a final state vf given the tables M and P.
removed to have a prefix path to each reachable sink (see Section III-A). Then, in Line 8, it repeats the process from each
reachable final state to find an approximation to the minimum number of atomic propositions that must be removed so that a
lasso path is enabled. The combination of prefix/lasso that removes the minimal number of atomic propositions is returned to
the user. We remark that from line 10, a set of atomic propositions found from prefix part is used when it starts searching for
lasso path of every reachable vf ∈ V ∩ Vf .
Algorithm 2 follows closely Dijkstra’s shortest path algorithm (Cormen et al. 2001). It maintains a list of visited nodes V
and a table M indexed by the graph vertices which stores the set of atomic propositions that must be removed in order to
reach a particular node on the graph. Given a node v, the size of the set |M[v, 1]| is an upper bound on the minimum number
of atomic propositions that must be removed. That is, if we remove all π ∈ M[v, 1] from Bs , then we enable a simple path
(i.e., with no cycles) from a starting state to the state v. The size of |M[v, 1]| is stored in M[v, 2] which also indicates that

11

Algorithm 2 F IND M IN PATH
Inputs: a graph GA = (V, E, vs , Vf , Π, Λ), a table M and a flag lasso on whether this is a lasso path search.
Variables: a queue Q, a set V of visited nodes and a table P indicating the parent of each node on a path.
Output: the tables M and P and the visited nodes V
1: procedure F IND M IN PATH (GA ,M,lasso)
2:
V ← {vs }
3:
P[:] ← ∅
. Each entry of P is set to ∅
4:
Q ← V − {vs }
5:
for v ∈ V such that (vs , v) ∈ E and v 6= vs do
6:
hM, Pi ← R ELAX((vs , v), M, P, Λ)
7:
end for
8:
if lasso = 1 then
9:
if (vs , vs ) ∈ E then
10:
M[vs , 1] ← M[vs , 1] ∪ Λ(vs , vs )
11:
M[vs , 2] ← |M[vs , 1] ∪ Λ(vs , vs )|
12:
P[vs ] = vs
13:
else
14:
M[vs , :] ← (Π, ∞)
15:
end if
16:
end if
17:
while Q =
6 ∅ do
18:
u ← E XTRACT MIN(Q)
. Get node u with minimum M[u, 2]
19:
if M[u, 2] < ∞ then
20:
V ← V ∪ {u}
21:
for v ∈ V such that (u, v) ∈ E do
22:
hM, Pi ← R ELAX((u, v), M, P, Λ)
23:
end for
24:
end if
25:
end while
26:
return M, P, V
27: end procedure
Algorithm 3 R ELAX
Inputs: an edge (u, v), the tables M and P and the edge labeling function Λ
Output: the tables M and P
1: procedure R ELAX ((u, v),M,P,Λ)
2:
if |M[u, 1] ∪ Λ(u, v)| < M[v, 2] then
3:
M[v, 1] ← M[u, 1] ∪ Λ(u, v)
4:
M[v, 2] ← |M[u, 1] ∪ Λ(u, v)|
5:
P[v] ← u
6:
end if
7:
return M, P
8: end procedure

the node v is reachable when M[v, 2] < ∞.
The algorithm works by maintaining a queue with the unvisited nodes on the graph. Each node v in the queue has as key the
number of atomic propositions that must be removed so that v becomes reachable on A. The algorithm proceeds by choosing
the node with the minimum number of atomic propositions discovered so far (line 18). Then, this node is used in order to
updated the estimates for the minimum number of atomic propositions needed in order to reach its neighbors (line 22). A
notable difference of Alg. 2 from Dijkstra’s shortest path algorithm is the check for lasso paths in lines 8-16. After the source
node is used for updating the estimates of its neighbors, its own estimate for the minimum number of atomic propositions is
updated either to the value indicated by the self loop or the maximum possible number of atomic propositions. This is required
in order to compare the different paths that reach a node from itself.
The following example demonstrates how the algorithm works and indicates the structural conditions on the graph that make
the algorithm non-optimal.

12

{π 1 }

v1
{π 1 , π 3 }

v3
Fig. 8.

{π 1 }

v2

{π 3 }

v5

{π 2 }
{π 1 , π 4 }

v4

{π 4 }

v6
{π 4 }

The graph of Example 11. The
vs =graph
v1 is denoted
by an arrow
andsource
the sink v6 by double
circle (Vfby
= {v
Fig.source
5. The
of Example
4. The
is denoted
an6 }).

Example 11. Let us consider the graph in Fig. 8. The source node of this graph is vs = v1 and the set of sink nodes is
Vf = {v6 }. The Π set of this graph is {π 1 , . . . , π 4 }. Consider the first call of F IND M IN PATH (line 5 of Alg. 1).
• Before the first execution of the while loop (line 17): The queue contains Q = {v2 , . . . , v6 }. The table M has the following



entries: M[v1 , :] = h∅, 0i, M[v2 , :] = h{π 1 }, 1i, M[v3 , :] = h{π 1 , π 3 }, 2i, M[v4 , :] = . . . = M[v6 , :] = Π, ∞ .
• Before the second execution of the while loop (line 17): The node v2 was popped from the queue since it had M[v2 , 2] = 1.
The queue now contains Q = {v3 , . . . , v6 }. The table M has the following
 rows: M[v1 , :] = h∅, 1i, M[v2 , :] = h{π 1 }, 1i,
M[v3 , :] = h{π 1 , π 3 }, 2i, M[v4 ] = h{π 1 , π 2 }, 2i, M[v5 , :] = M[v6 , :] = Π, ∞ .
• At the end of F IND M IN PATH (line 27): The queue now is empty. The table M has the following rows: M[v1 , :] = h∅, 0i,
M[v

 2, :] = h{π 1 }, 1i, M[v3 , :] = h{π 1 , π 3 }, 2i, M[v4 , :] = h{π 1 , π 2 }, 2i, M[v5 , :] = h{π 1 , π 2 , π 4 }, 3i, M[v6 , :] =
Π, 4 , which corresponds to the path v1 , v2 , v4 , v5 , v6 .
Note that algorithm returns a set of atomic propositions L0 = Π which is not optimal |L0 | = 4. The path v1 , v3 , v4 , v5 , v6
4
would return L0 = {π 1 , π 3 , π 4 } with |L0 | = 3.
Correctness: The correctness of the algorithm AAMRP is based upon the fact that a node v ∈ V is reachable on GA if and
only if M[v, 2] < ∞. The argument for this claim is similar to the proof of correctness of Dijkstra’s shortest path algorithm
in Cormen et al. 2001. If this algorithm returns a set of atomic propositions L which removed from Bs , then the language
L(A) is non-empty. This is immediate by the construction of the graph GA (Def. 7).
We remark that AAMRP does not solve Problem 2 exactly since MRP is NP-Complete. However, AAMRP guarantees that
it returns a valid relaxation B where Bs  B.
Theorem 1. If a valid relaxation exists, then AAMRP always returns a valid relaxation B of some initial Bs such that
L(T × B) 6= ∅.
Proof: First, we will show that if AAMRP returns ∅, then there is no valid relaxation of Bs . AAMRP returns ∅ when
there is no reachable vf ∈ Vf with prefix and lasso path or G ETAPF ROM PATH returns ∅. If there is no reachable vf , then
either the accepting state is not reachable on Bs or on T . Recall that the Def. 7 constructs a graph where all the transitions
of T and B are possible. If it returns ∅ as a valid solution, then there is a path on the graph that does not utilize any labeled
edge by Λ. Thus, L(T × Bs ) 6= ∅. Since we assume that Bs is unsatisfiable on T , this is contradiction.
e
e
Second, without loss of generality, suppose that AAMRP returns Λ(µ).
Using this Λ(µ),
we can build a relax specification
e
automaton B. Using each hl, (s, s0 ), ki ∈ Λ(µ)
and for each π ∈ l, we add the indices of the literal φij in ΦBs (s,s0 ) that
i
corresponds to π to the sets D̂ss0 and Ĉss
0 . The resulting substitution θ produces a relaxation. Moreover, it is a valid relaxation,
because by removing the atomic propositions in θ from Bs , we get a path that satisfies the prefix and lasso components on
the product automaton.
Running time: The running time analysis of the AAMRP is similar to that of Dijkstra’s shortest path algorithm. In the
following, we will abuse notation when we use the O notation and treat each set symbol S as its cardinality |S|.
First, we will consider F IND M IN PATH. The fundamental difference of AAMRP over Dijkstra’s algorithm is that we have
set theoretic operations. We will assume that we are using a data structure for sets that supports O(1) set cardinality quarries,
O(log n) membership quarries and element insertions (Cormen et al. 2001) and O(n) set up time. Under the assumption
that Q is implemented in such a data structure, each E XTRACT MIN takes O(log V ) time. Furthermore, we have O(V ) such
operations (actually |V | − 1) for a total of O(V log V ).
Setting up the data structure for Q will take O(V ) time. Furthermore, in
case, we have a set Λ(e) for each edge

 the worst

e ∈ E with set-up time O(EΠ). Note that the initialization of M[v, :] to Π, ∞ does not have to be implemented since we
can have indicator variables indicating when a set is supposed to contain all the (known in advance) elements.
Assuming that E is stored in an adjacency list, the total number of calls to R ELAX at lines 5 and 21 of Alg. 2 will be O(E)
times. Each call to R ELAX will have to perform a union of two sets (M[u, 1] and Λ(u, v)). Assuming that both sets have in the
worst case |Π| elements, each union will take O(Π log Π) time. Finally, each set size quarry takes O(1) time and updating the
keys in Q takes O(log V ) time. Therefore, the running time of F IND M IN PATH is O(V + EΠ + V log V + E(Π log Π + log V )).
Note that even if under Assumption 1 all nodes of T are reachable (|V | < |E|), the same property does not hold for the
product automaton. (e.g, think of an environment T and a specification automaton whose graphs are Directed Acyclic Graphs

13

roof of correctness of Dijkstra’s shortest path
rmen et al. 2001. If this algorithm returns a
, then
is non-empty. This is immediate by the

{π ⋆ , π ♣ }

v1′

{π ⋆ , π ♣ }

{π0 }

v1

{π0 }

{π1 }

v2′

v2

{π0 }

{π2 }

v1′′

{π ⋆ , π ♣ }

{π0 }

{π0 }
{π0 }

v3

vf

{π0 }

{π3 }

v2′′

is denoted by an arrow
The running time analysis of the AAMRP Fig. 9. The graph of Example 7. The source
and thevsink
by double circle (
).
9. Thepath
graphalgorithm.
of ExampleIn12.the
The source
t of Dijkstra’sFig.
shortest
s = v1 is denoted by an arrow and the sink vf by double circle (Vf = {vf }).
60
50

y2

40
30
20
10
0

Fig. 10.

0

10

20

30

40

50
y1

60

70

80

90

100

The simple environment of Example 13 along with a low speed mobile robot trajectory that satisfies the specification.

(DAG). However, even in this case, we have (|V | < |E|). The running time of F IND M IN PATH is O(E(Π log Π + log V )).
Therefore, we observe that the running time also depends on the size of the set Π. However, such a bound is very pessimistic
since not all the edges will be disabled on A and, moreover, most edges will not have the whole set Π as candidates for
removal.
Finally, we consider AAMRP. The loop at line 7 is going to be called O(Vf ) times. At each iteration, F IND M IN PATH is
called. Furthermore, each call to G ETAPF ROM PATH is going to take O(V Π log Π) time (in the worst case we are going to have
|V | unions of sets of atomic propositions). Therefore, the running time of AAMRP is O(Vf (V Π log Π+E(Π log Π+log V ))) =
O(Vf E(Π log Π + log V )) which is polynomial in the size of the input graph.
Approximation bound: AAMRP does not have a constant approximation ratio on arbitrary graphs.
Example 12 (Unbounded Approximation). The graph in Fig. 9 is the product of a specification automaton with a single
state and a self transition with label {π 0 , π 1 , . . . , π m , π F , π ♣ } and an environment automaton with the same structure as the
graph in Fig. 9 but with appropriately defined state labels. In this graph, AAMRP will choose the path v1 ,v100 , v2 , v200 , v3 ,
. . ., vf . The corresponding revision will be the set of atomic propositions Lp = {π 0 , π 1 , π 2 , . . . , π m } with |Lp | = m + 1.
This is because in v2 , AAMRP will choose the path through v100 rather than v10 since the latter will produce a revision set of
size |{π 0 , π F , π ♣ }| = 3 while the former a revision set of size |{π 0 , π 1 }| = 2. Similarly at the next junction node v3 , the
two candidate revision sets {π 0 , π 1 , π F , π ♣ } and {π 0 , π 1 , π 2 } have sizes 4 and 3, respectively. Therefore, the algorithm will
always choose the path through the nodes vi00 rather than vi0 producing, thus, a solution of size m + 1. However, in this graph,
the optimal revision would have been Lp = {π 0 , π F , π ♣ } with |Lp | = 3. Hence, we can see that in this example for m > 2
AAMRP returns a solution which is m − 2 times bigger than the optimal solution.
4
There is also a special case where AAMRP returns a solution whose size is at most twice the size of the optimal solution.
Theorem 2. AAMRP on planar Directed Acyclic Graphs (DAG) where all the paths merge on the same node is a 2approximation algorithm.
The proof is provided in the Appendix X.
VI. E XAMPLES AND N UMERICAL E XPERIMENTS
In this section, we present experimental results using our prototype implementation of AAMRP. The prototype implementation
is in Python (see Kim 2014b). Therefore, we expect the running times to substantially improve with a C implementation using
state-of-the-art data structure implementations.
We first present some examples and expand few more example scenarios.
Example 13. We revisit Example 1. The product automaton of this example has 85 states, 910 transitions and 17 reachable
final states. It takes 0.095 sec by AAMRP. AAMRP returns the set of atomic propositions {hπ4 , (s2 , s4 )i} as a minimal revision
to the problem, which is revision (3) among the three minimal revisions of the example: one of the blue trajectories in Fig.
10. Thus, it is an optimal solution.
4

14

i2

i4

u1
g2

g3

i1

g1

u2
i3

Fig. 11.

Schematic illustration of the simple road network environment of Example 15. The robot is required to drive right-side of the road.

Example 14. We revisit Example 2. The graph of this example has 36 states, 240 transitions and 9 reachable sinks. AAMRP
returns the set of atomic propositions {hπ13 , (s2 , s3 )i} as minimal revision to the problem. It takes 0.038 sec by AAMRP.
Intuitively, AAMRP recommends dropping the requirement that π13 should be reached from the specification. Therefore, Object
1 will remain where it is, while Object 2 will follow the path q1 , q2 , q3 , q2 , q3 , . . . .
4
With our prototype implementation, we could expand our experiment to few more example scenarios introduced in Ulusoy
et al. 2011, 2012.
Example 15 (Single Robot Data Gathering Task). In this example, we use a simplified road network having three gathering
locations and two upload locations with four intersections of the road. In Fig. 11, the data gather locations, which are labeled
g1 , g2 , and g3 , are dark gray, the data upload locations, which are labeled u1 and u2 , are light gray, and the intersections
are labeled i1 through i4 . In order to gather data and upload the gather-data persistently, the following LTL formula may be
considered: φA := GF(ϕg ) ∧ GF(π), where ϕg := g1 ∨ g2 ∨ g3 and π := u1 ∨ u2 . The following formula can make the robot
move from gather locations to upload locations after gathering data: φG := G(ϕg → X(¬ϕg Uπ). In order for the robot to
move to gather location after uploading, the following formula is needed: φU := G(π → X(¬π Uϕg ).
Let us consider that some parts of road are not recommended to drive from gather locations, such as from i4 to i2 and
from i1 to i2 . We can describe those constraints as following: ψ1 := G(g1 → ¬(i4 ∧ Xi2 ) Uu1 ) and ψ2 := G(g2 → ¬(i1 ∧
Xi2 ) Uu2 ). If the gathering task should have an order such as g3 , g1 , g2 , g3 , g1 , g2 , . . ., then the following formula could be
considered: φO := ((¬g1 ∧ ¬g2 ) Ug3 ) ∧ G(g3 → X((¬g2 ∧ ¬g3 ) Ug1 )) ∧ G(g1 → X((¬g1 ∧ ¬g3 ) Ug2 )) ∧ G(g2 → X((¬g1 ∧
¬g2 ) Ug3 )). Now, we can informally describe the mission. The mission is “Always gather data from g3, g1, g2 in this order
and upload the collected data to u1 and u2 . Once data gathering is finished, do not visit gather locations until the data is
uploaded. Once uploading is finished, do not visit upload locations until gathering data. You should always avoid the road
from i4 to i2 when you head to u1 from g1 and the road from i1 to i2 when you head to u2 from g2 ”. The following formula
represents this mission:
φsingle := φO ∧ φG ∧ φU ∧ ψ1 ∧ ψ2 ∧ GF(π).
Assume that initially, the robot is in i3 and all nodes are final nodes. When we made a cross product with the road and
the specification, we could get 36824 states, 350114 edges, and 450 final states. Not removing some atomic propositions,
the specification was not satisfiable. AAMRP took 15 min 34.572 seconds, and suggested removing g3 . Since the original
specification has many g3 in it, we had to trace which g3 from the specification should be removed. Hence, we revised the
LTL2BA (Gastin and Oddoux [2001]), indexing each atomic proposition on the transitions and states (see Kim 2014a).Two g3
are mappped to the same transition on the specification automaton in (¬g1 ∧ ¬g2 ) Ug3 of φO and in ϕg := g1 ∨ g2 ∨ g3 in
φU .
4
The last example shows somewhat different missions with multiple robots. If the robots execute the gather and upload
mission, persistently, we could assume that the battery in the robots should be recharged.
Example 16 (Charging while Uploading). In this exaple, we assume that robots can recharge their battery in upload locations
so that robots are reqired to stay at the upload locations as much as possible. We also assume that each gathering localtion has
a dedicated upload location such that g1 has u1 as an upload location, and g2 has u2 as an upload location. For this example,
we revised the road network so that we remove the gather location g3 and the intersection i4 to make the network simpler
for this mission. We also positioned the upload locations next to each other. We assume that the power source is shared and

15

i2

u1
g2

i1

u2

g1
i3

Fig. 12.
battery.

Schematic illustration of the simple road network environment of Example 16. The robots can stay upload locations u1 and u2 to recharge the

it has just two charging statations (see in Fig. 12). We can describe the mission as follows: “Once robot1 finishes gathering
data at g1 , robot1 should not visit the gather locations until the data is uploaded at u1 . Once robot2 fisniehs gathering data
at g2 , robot2 shoud not visit the gather locations until the data is uploaded at u2 . Once the data is uploaded at u1 or u2 ,
robot1 or robot2 should stay there until a gather locaiton is not occupied. Persistently, gather data from g1 and g2 , avoiding
the road from g2 to i2 .” The following formula represents this mission:
φcharging := G(g11 → X(¬g11 ∧ ¬g21 ) Uu11 ) ∧
G(g22 → X(¬g22 ∧ ¬g12 ) Uu22 ) ∧
G(u11 → u11 U ¬g22 ) ∧
G(u22 → u22 U ¬g11 ) ∧
GFg11 ∧ GFg22 ∧
G¬(g21 ∧ Xi21 ) ∧
G¬(g22 ∧ Xi22 ).
Assume that initially, robot1 is in i1 , robot2 is in i2 , and all nodes are final nodes. From the cross product with the road
and the specification, there was 65966 states, 253882 transitions, and 504 final nodes. For this example, we computed a
synchronized environtment for two robots, and in this environment, atomic propositions were duplicationed for each robot. For
example, a gather location g1 is duplicated to g11 for robot1 and g12 for robot2 . With this synchronized environment, we could
avoid robots to be colliding and to be in the same location at the same time. However, not removing some atomic propositions,
the specification was unsatisfiable. AAMRP took 24 min 22.578 seconds, and suggested removing u22 from robot2 . The two
occurances of u22 were in G(g22 → X(¬g22 ∧ ¬g12 ) Uu22 ) and in the second u22 of G(u22 → u22 U ¬g11 ) as indicated by
our modified LTL2BA toolbox. The suggested path from AAMRP for each robot is as followings:
pathrobot1 = i11 i21 u11 u11 i11 (i21 g21 i31 g11 i11 i21 u11 u11 u11 u11 u11 u11 u11 u11 u11 i11 )+
pathrobot2 = i22 u12 i12 u22 u22 (u22 u22 u22 u22 u22 u22 u22 i32 g12 i12 i22 g22 i32 g12 i12 u22 )+
4
For the experiments, we utilized the ASU super computing center which consists of clusters of Dual 4-core processors, 16
GB Intel(R) Xeon(R) CPU X5355 @2.66 Ghz. Our implementation does not utilize the parallel architecture. The clusters were
used to run the many different test cases in parallel on a single core. The operating system is CentOS release 5.5.
In order to assess the experimental approximation ratio of AAMRP, we compared the solutions returned by AAMRP with
the brute-force search. The brute-force search is guaranteed to return a minimal solution to the MRP problem.
We performed a large number of experimental comparisons on random benchmark instances of various sizes. We used the
same instances which were presented in Kim et al. 2012, Kim and Fainekos 2012. The first experiment involved randomly
generated DAGs. Each test case consisted of two randomly generated DAGs which represented an environment and a specification. Both graphs have self-loops on their leaves so that a feasible lasso path can be found. The number of atomic propositions
in each instance was equal to four times the number of nodes in each acyclic graph. For example, in the benchmark where
the graph had 9 nodes, each DAG had 3 nodes, and the number of atomic propositions was 12. The final nodes are chosen
randomly and they represent 5%-40% of the nodes. The number of edges in most instances were 2-3 times more than the

16

Nodes

9
100
196
324
400
529

min
0.037
0.069
0.066
0.103
0.087
0.14

BRUTE-FORCE SEARCH
TIMES (SEC)
SOLUTIONS (SIZE)
avg
max
min
avg
max
0.104
1.91
1
1.97
5
510.18
20786
1
3.277
13
1025.44 25271
1
3.076
8
992.68
25437
1
2.379
6
1110.05 17685
1
2.692
6
2153.90 26895
1
2.591
5

succ
200/200
198/200
171/200
158/200
143/200
137/200

TIMES (SEC)
min
avg
max
0.022 0.061
1.17
0.038 0.076
0.179
0.007 0.188
0.333
0.129 0.669
1.591
0.15
0.669 1.591
0.382
1.88
4.705

AAMRP
SOLUTIONS (SIZE)
min
avg
max
1
1.975
5
1
3.395
15
1
4.285
17
1
4.155
20
1
5
24
1
5.115
30

RATIO
succ
200/200
200/200
200/200
200/200
200/200
200/200

min
1
1
1
1
1
1

avg
1.0016
1.0006
1
1
1
1

max
1.333
1.125
1
1.2
1
1

TABLE I
N UMERICAL E XPERIMENTS : N UMBER OF NODES VERSUS THE RESULTS OF BRUTE - FORCE SEARCH AND AAMRP. U NDER THE BRUTE - FORCE SEARCH
AND AAMRP COLUMNS THE NUMBERS INDICATE COMPUTATION TIMES IN sec. RATIO INDICATES THE EXPERIMENTALLY OBSERVED APPROXIMATION
RATIO TO THE OPTIMAL SOLUTION .

Nodes

1024
10000
20164
50176
60025

min
0.125
15.723
50.325
425.362
6734.133

AAMRP
TIMES
avg
max
0.23
0.325
76.164
128.471
570.737
1009.675
1993.449
4013.717
6917.094
7100.055

succ
9/10
9/10
8/10
3/10
2/10

TABLE II
N UMERICAL E XPERIMENTS : N UMBER OF NODES VERSUS THE RESULTS OF AAMRP. U NDER THE TIMES COLUMNS THE NUMBERS INDICATE
COMPUTATION TIMES IN sec.

number of nodes.
Table I compares the results of the brute-force search with the results of AAMRP on test cases of different sizes (total
number of nodes). For each graph size, we performed 200 tests and we report minimum, average and maximum computation
times in second and minimum, average and maximum numbers of atomic propositions for each instance solution. AAMRP
was able to finish the computation and returned a minimal revision for all the test cases, but brute-force search was not able
to finish all the computation within a 8 hours window.
Our brute-force search checks all the combinations of atomic propositions. For example, given n atomic propositions, it
checks at most 2n cases. It uses breath first search to check the reachability for the prefix and the lasso part. If it is reachable
with the chosen atomic propositions, then it is finished. If it is not reachable, then it chooses another combination until it is
reachable. Since brute-force search checks all the combinations of atomic propositions, the success mostly depends on the time
limit of the test. We remark that the brute-force search was not able to provide an answer to all the test cases within a 8 hours
window. The comparison for the approximation ratio was possible only for the test cases where brute-force search successfully
completed the computation. Note that in the case of 529 Nodes, even though the maximum RATIO is 1, the maximum solution
from brute-force does not match with the maximum solution from AAMRP. One is 5 and another is 30. This is because the
number of success from brute-force search is 137 / 200 and only comparing this success with the ones from AAMRP, the
maximum RATIO is still 1.
An interesting observation is that the maximum approximation ratio is experimentally determined to be less than 2. For the
randomly generated graphs that we have constructed the bound apppears to be 1.333. However, as we showed in the example
12, it is not easy to construct random examples that produce higher approximation ratios. Such example scenarios must be
carefully constructed in advance.
In the second numerical experiment, we attempted to determine the problem sizes that our prototype implementation of
AAMRP in Python can handle. The results are presented in Table II. We observe that approximately 60,025 nodes would be
the limit of the AAMRP implementation in Python.
VII. R ELATED WORK
The automatic specification revision problem for automata based planning techniques is a relatively new problem.
A related research problem is query checking Chechik and Gurfinkel 2003, Gurfinkel et al. 2002. In query checking, given a
model of the system and a temporal logic formula φ, some subformulas in φ are replaced with placeholders. Then, the problem
is to determine a set of Boolean formulas such that if these formulas are placed into the placeholders. Then, the problem is to
determine a set of Boolean formulas such that if these formulas are placed into the placeholders, then φ holds on the model.
The problem of revision as defined here is substantially different from query checking. For one, the user does not know where
to position the placeholders in the formula when the planning fails.
The papers Ding and Zhang 2005, Finger and Wassermann 2008 present an also related problem. It is the problem of
revising a system model such that it satisfies a temporal logic specification. Along the same lines, one can study the problem

17

of maximally permissive controllers for automata specification Thistle and Wonham 1994. Note that in this paper, we are trying
to solve the opposite problem, i.e., we are trying to relax the specification such that it can be realized on the system. The main
motivation for our work is that the model of the system, i.e., the environment and the system dynamics, cannot be modified
and, therefore, we need to understand what we can be achieved with the current constraints.
Finding out why a specification is not satisfiable on a model is a problem that is very related to the problems of vacuity and
coverage in model checking Kupferman et al. 2008. Another related problem is the detection of the causes of unrealizability
in LTL games. In this case, a number of heuristics have been developed in order to localize the error and provide meaningful
information to the user for debugging Cimatti et al. 2008, Konighofer et al. 2009. Along these lines, LTLMop Raman and
Kress-Gazit 2011 was developed to debug unrealizable LTL specifications in reactive planning for robotic applications. Raman
et al. 2013 also provided an integrated system for non-expert users to control robots for high-level, reactive tasks through
natural language. This system gives the user natural language feedback when the original intention is unsatisfiable. Raman and
Kress-Gazit 2013 introduced an approach to analyze unrealizable robot specifications due to environment’s limitation. They
provide how to find the minimal unsatisfiable cores, such as deadlock and livelock, for propositional encodings, searching for
some sequence of states in the environment.
Over-Subscription Planning (OSP) Smith 2004 and Partial Satisfaction Planning (PSP) van den Briel et al. 2004 are also
very related problems. OSP finds an appropriate subset of an over-subscribed, conjunctive goal to meet the limitation of time
and energy consumption. PSP explains the planning problem where the goal is regarded as soft constraints and trying to find
a good quality plan for a subset of the goals. OSP and PSP have almost same definition, but there is also a difference. OSP
regards the resource limitations as an important factor of partial goal to be satisfied, while PSP chooses a trade-off between
the total action costs and the goal utilities where handling the plan quality.
In Göbelbecker et al. 2010, the authors investigated situations in which a planner-based agent cannot find a solution for a
given planning task. They provided a formalization of coming up with excuses for not being able to find a plan and determined
the computational complexity of finding excuses. On the practical side, they presented a method that is able to find good
excuses on robotic application domains.
Another related problem is the Minimum Constraint Removal Problem (MCR) Hauser 2012. MCR concentrates on finding
the least set of violating geometric constraints so that satisfaction in the specification can be achieved.
In Cizelj and Belta 2013, authors introduced a related problem which is of automatic formula revision for Probabilistic
Computational Tree Logic (PCTL) with noisy sensor and actuator. Their proposed approach uses some specification update
rules in order to revise the specification formula until the supervisor is satisfied. Tumova et al. 2013 is closely related with our
work. It takes as input a transition system, and a set of sub-specifications in LTL with each reward, and constructs a strategy
maximizing the total reward of satisfiable sub-specifications. If a whole sub-specification is not feasible, then it is discarded. In
our case, we try to minimize revising the sub-specification if it is infeasible. In Kim and Fainekos 2014, we also expended our
approach with quantitative preference. While revising the sub-specification, it has two approaches to get revision. Instead of
finding minimum number of atomic propositions, it tries to minimize the sum of preference levels of the atomic propositions
and to minimize the maximum preference level of the atomic propositions.
VIII. C ONCLUSIONS
In this paper, we proved that the minimal revision problem for specification automata is NP-complete. We also provided
a polynomial time approximation algorithm for the problem of minimal revision of specification automata and established its
upper bound for a special case. Furthermore, we provided examples to demonstrate that an approximation ratio cannot be
established for this algorithm.
The minimal revision problem is useful when automata theoretic planning fails and the modification of the environment is
not possible. In such cases, it is desirable that the user receives feedback from the system on what the system can actually
achieve. The challenge in proposing a new specification automaton is that the new specification should be as close as possible to
the initial intent of the user. Our proposed algorithm experimentally achieves approximation ratio very close to 1. Furthermore,
the running time of our prototype implementation is reasonable enough to be able to handle realistic scenarios.
Future research will proceed along several directions. Since the initial specification is ultimately provided in some form of
natural language, we would like the feedback that we provide to be in a natural language setting as well. Second, we plan on
developing a robust and efficient publicly available implementation of our approximation algorithm.
IX. A PPENDIX : NP- COMPLETENESS OF THE M INIMAL C ONNECTING E DGE P ROBLEM
We will prove the Minimal Connecting Edge (MCE) problem is NP-Complete. MCE is a slightly simpler version of the
Minimal Accepting Path (MAP) problem and, thus, MAP is NP-Complete as well.
In MCE, we consider a directed graph G = (E, V ) with a source s and a sink t where there is no path from s to t. We
also have a set of candidate edges Ê to be added to E such that the graph becomes connected and there is a path from
s to t. Note that if the edges in Ê have no dependencies between them, then there exists an algorithm that can solve the
problem in polynomial time. For instance, Dijkstra’s algorithm Cormen et al. 2001 applied on the weighted directed graph

18

G = (V, E ∪ Ê, w) where the edges in Ê are assigned weight 1 and the edges in E are assigned weight 0 solves the problem
efficiently.
However, in MCE, the set Ê is partitioned in a number of classes Ê1 , ..., Ên such that if an edge ei is added from Êi , then
all the other edges in Êi are added as well to G. This corresponds to the fact that if we remove a predicate from a transition
in Bs , then a number of transitions on GA are affected. Let us consider the GA in Fig. 7 as an example. Here, e0 , e2 and e4
correspond to y((s1 , s1 ), π0 ), e1 and e5 to y((s1 , s1 ), π2 ) and e3 to y((s1 , s1 ), π3 ). Thus, {e0 , e1 , e2 , e3 , e4 , e5 } ∈ Ê and there
exist three classes Êi , Êj and Êj in the partition such that {e0 , e2 , e4 } ⊆ Êi , {e1 , e5 } ⊆ Êj and e3 ∈ Êk .
{
}⊆
∈
q0 , s1

e0

e1

q1 , s1

e2

e3

q2 , s1

e4
e5
q3 , s1
Fig. 13.

Fig. 7. The MCE instance that corresponds to
from Fig. IV-A. The
The MCE instance that corresponds to GA from Fig. 7. The dashed edges denote candidate edges in Ê.

Problem 3 (Minimal Connecting Edge (MCE)). I NPUT: Let G = (V, E) be a directed graph with a source s and a distinguished
sink node t. We assume that there is no path in G from s to t. Let Ê ⊆ V × V be a set such that Ê ∩ E = ∅. We partition Ê
into E = {Ê1 , . . . , Êm }. Each edge e ∈ Ê has a weight W (e) ≥ 0.
O UTPUT: Given a weight limit W , determine if there is a selection of edges R ⊆ Ê such that
1) there
P is a path from s to t in the graph with all edges E ∪ R,
2)
e∈∪R W (e) ≤ W and
3) For each Êi ∈ E, if Êi ∩ R 6= ∅ then Êi ⊆ R.
Theorem 3. MCE is NP-complete.
Proof: The problem is trivially in NP. Given a selection of edges from Ê, we can indeed verify that the source and sinks
are connected, the weight limit is respected and that the selection is made up of a union of sets from the partition.
We now claim that the problem is NP-Complete. We will reduce from 3-CNF-SAT. Consider an instance of 3-CNF-SAT
with variables X = {x1 , . . . , xn } and clauses C1 , . . . , Cm . Each clause is a disjunction of three literals. We will construct
graph G and family of edges E. The graph G has edges E made up of variable and clause “gadgets”.
a) Variable Gadgets: For each variable xi , we create 6 nodes ui , uti , vit , ufi , vif , and vi . The gadget is shown in Fig. 14.
The node ui is called the entrance to the gadget and vi is called the exit. The idea is that if the variable is assigned true, we
will take the path
ui → uti → vit → vi

to traverse through the gadget from its entrance to exit. The missing edge uti → vit will be supplied by one of the edge sets.
If we assign the variable to false, we will instead traverse
ui → ufi → vif → vi
Variable gadgets are connected to each other in G by adding edges from v1 to u2 , v2 to u3 and so on until vn−1 → un .
The node u1 is the source node.
uti

∈ Pi

vit

ufi

∈ Ni

vif

ui

vi

Fig. 8. A single variable gadget. Solid edges are present in the original
Fig. 14. A single variable gadget. Solid edges are present in the original graph G that will be constructed. Dashed edges (uti , vit ) or between (ufi , vif ) will
be supplied by one of the edge sets in Ê.

b) Clause Gadgets: For each clause Cj of the form (`j1 ∨ `j2 ∨ `j3 ), we add a clause gadget consisting of eight nodes:
entry node aj , exit node bj and nodes aj1 , bj1 , aj2 , bj2 and aj3 , bj3 corresponding to each of the three literals in the clause.
The idea is that a path from the entry node aj to exit node bj will exist if the clause Cj will be satisfied. Figure 15 shows
how the nodes in a clause gadget are connected.
c) Structure: We connect vn the exit of the last variable gadget for variable xn to a1 , the entrance for first clause gadget.
The sink node is bm , the exit for the last clause gadget. Figure 16 shows the overall high level structure of the graph G with
variable and clause gadgets.

19

aj

a1j

∈ P1

b1j

a2j

∈ N2

b2j

a3j

∈ N3

b3j

bj

Fig. 9. The clause gadget for a clause with three literals. The clause shown
Fig. 15. The clause gadget for a clause with three literals. The clause shown here is (x1 ∨ x2 ∨ x3 ). The corresponding missing edges will be added to
the set P1 , N2 , N3 , respectively, as shown in figure.

x1

xn

C1

Cm

Fig. 10. Connection between gadgets for variables and clauses.
the gadget Fig.
from
entrance
to exit.
16. its
Connection
between
gadgets for variables and clauses.

d) Edge Sets: We design a family E = {P1 , . . . , Pn , N1 , . . . , Nn }. The set Pi will correspond to a truth assignment of
true to variable xi and Ni correspond to a truth assignment of false to xi .
Pi has the edge (uti , vit ) of weight 1 and for each clause Cj containing the literal xi , we add the missing edge (aij , bij )
corresponding to this literal in the clause gadget for Cj to the set Pi with weight 0.
Similarly, Ni has the edge from (ufi , vif ) of weight 1 and for each clause Cj containing the literal xi it has the missing edge
in the clause gadget for Cj with weight 0. We ask if there is a way to connect the source u1 with the sink bm with weight
limit ≤ n, where n is the number of variables.
We verify that the sets P1 , . . . , Pn , N1 , . . . , Nn partition the set of missing edges.
Claim 1. If there is a satisfying solution to the problem, then u1 can be connected to bm by a choice of edge sets with total
edge weight ≤ n.
Proof: Take a satisfying solution. If it assigns true to xi , then choose all edges in Pi else choose all edges Ni if it assigns
false. We claim that this will connect u1 to bm . First it is clear that since all variables are assigned, it will connect u1 to vn by
connecting one of the two missing links in each variable gadget. Corresponding to each clause, Cj there will be a path from
aj to bj in the clause gadget for Cj . This is because, at least one of the literals in the clause is satisfied and the corresponding
set Pi or Ni will supply the missing edge. Furthermore, the weight of the selection will be precisely n, since we add exactly
one edge in each variable gadget.
Claim 2. If there is a way to connect source to sink with weight ≤ n then a satisfying assignment exists.
Proof: First of all, the total weight for any edge connection from source to sink is ≥ n since we need to connect u1 to
vn there are n edges missing in any shortest path. The edges that will connect have weight 1, each. Therefore, if there is a
way to connect source to sink with weight ≤ n, the total weight must in fact be n. This allows us to conclude that for every
variable gadget precisely one of the missing edges is present. As a result, we can now form a truth assignment setting xi to
true if Pi is chosen and false if Ni is. Therefore, the truth assignment will assign either true to xi or false and not both thanks
to the weight limit of n.
Next, we prove that each aj will be connected to bj in each clause gadget corr. to clause Cj . Let us assume that this was
using the edge (aij , bij ) ∈ Ni . Then, by construction have that xi was in the clause Cj which is now satisfied since Ni is
chosen, assigning xi to false. Similar reasoning can be used if (aj , bj ) ∈ Pi . Combining, we conclude that all clauses are
satisfied by our truth assignment.
X. A PPENDIX : U PPER B OUND OF THE A PPROXIMATION R ATIO OF AAMRP
We shall show the upper bound of the approximation algorithm (AAMRP) for a special case.
Theorem 4. AAMRP on planar Directed Acyclic Graphs (DAG) where all the paths merge on the same node is a polynomialtime 2-approximation algorithm for the Minimal Revision Problem (MRP).
Proof:
We have already seen that the AAMRP runs in polynomial time.
Let Y = {y1 , . . . , ym } be a set of Boolean variables and G : (V, E) be a graph with a labeling function L : E → P(Y ),
wherein each edge e ∈ E is labeled with a set of Boolean variables L(e) ⊆ Y . The label on an edge indicates that the edge
is enabled iff all the Boolean variables on the edge are set to true. Let v0 ∈ V be a marked initial state and F ⊆ V be a set
of marked final vertices.
Consider two functions w0 : E ∗ → P(Y ), and w : E ∗ → N where E ∗ represents the set of all finite sequences of edges
of the graph G. Hence, w0 (P ) for a path P = hv0 , . . . , vk i is a set of boolean variables of its constituent edges which makes

20

them enabled on the path P :
w0 (P ) =

k
[

L(vi−1 , vi )

i=1

while w(P ) is the number of the boolean variables of

k

[
 


 
w(P ) =  L(vi−1 , vi ) = w0 (P )
i=1

Given a initial vertex v0 , two vertices vi , vj , and a final vertex vk , let Popt denote the path that produces an optimal revision
for the given graph. Let Pa denote a general revision by AAMRP. Suppose that Popt consists of subpaths P0i , Pij , Pjk , and
Pa consists of subpaths P0i , Pij0 , Pjk .
We will discuss the cases when P0i and Pjk are empty later. The former case can occur when Popt and Pa do not have
any common edges from v0 to vi in the sense that each path takes a different neighbor out of v0 . This case can also occur
when 0 < i if from v0 to vi there is no boolean variables to be enabled to make the path activated. Likewise, the latter case
can occur when i < j < k or when i ≤ j = k. We do not take i = j unless j = k. Considering both cases together, we can
get the possibility that Popt and Pa are entirely different from v0 to vk .
In vj , the AAMRP should relax the weight of the path from v0 to vj , comparing between two paths Pij and Pij0 . Thus, we
can denote:
w0 (Pm ) = w0 (P0i ) ∪ w0 (Pij0 ) ∪ w0 (Pjk ),
w0 (P ∗ ) = w0 (P0i ) ∪ w0 (Pij ) ∪ w0 (Pjk ).

Let w0 (P0i ) ∪ w0 (Pij0 ) = Λa , w0 (P0i ) ∪ w0 (Pij ) = Λopt , and w0 (Pjk ) = Λ. Then, we can denote:
w0 (Pa ) = Λa ∪ Λ,

w0 (Popt ) = Λopt ∪ Λ.
Recall that
w(Pa ) = |Λa ∪ Λ|,
w(Popt ) = |Λopt ∪ Λ|.
We will show that w(Pa ) ≤ 2w(Popt ).
Note that w(Popt ) ≥ 1, so that |Λopt ∪ Λ| ≥ 1. This is because if w(Popt ) = 0, then it is reachable from v0 to vf without
enabling any boolean variables which are atomic propositions of the specification.
Remark 1. |Λopt ∪ Λ| ≥ 1.
Note that |Λa | ≤ |Λopt |. This is because the AAMRP only relaxes the path when it has less number of boolean variables.
Remark 2. |Λa | ≤ |Λopt |.
Note that if |Λa | = 0, then |Λopt ∪ Λ| = |Λa ∪ Λ| ≤ 2|Λopt ∪ Λ|. In this case, Λa is the optimal path if Λa = 0 since Λ is
common for the two paths. I.e., w(Pa ) ≤ 2w(Popt ).
Consider the case |Λa | ≥ 1. We will prove the claim by contradiction. Assume that 2w(Popt ) < w(Pa ) so that 2|Λopt ∪ Λ| <
|Λa ∪ Λ|. Let |Λa | = µ, |Λopt | = η and |Λ| = τ . There are four cases.
Case 1: if Λopt ∩ Λ = ∅ and Λa ∩ Λ = ∅, then
2|Λopt ∪ Λ| < |Λa ∪ Λ| ⇒ 2(η + τ ) < µ + τ
2η + 2τ < µ + τ ⇒ 2η + τ < µ
However, µ ≤ η by Remark 2. Thus, η + τ < 0 which is not possible and it contradicts our assumption.
Case 2: if Λopt ∩ Λ 6= ∅ and Λa ∩ Λ = ∅, then let |Λopt ∩ Λ| = ζ, where 1 ≤ ζ ≤ min(η, τ ).
2|Λopt ∪ Λ| < |Λa ∪ Λ| ⇒ 2(η + τ − ζ) < µ + τ
2η + 2τ − 2ζ < µ + τ ⇒ 2η − 2ζ + τ < µ
If η ≤ τ , then ζ ≤ η and η = ζ + α, for some α ≥ 0.
2(ζ + α) − 2ζ + τ < µ ⇒ 2α + τ < µ
However, η ≤ τ and µ ≤ η by Remark 2. Thus, 2α < 0 which is not possible and it contradicts our assumption.

21

If η > τ and η = τ + β, for some β > 0, then ζ ≤ τ and τ = ζ + α, for some α ≥ 0.
2(τ + β) − 2ζ + τ < µ ⇒ 2τ − 2ζ + 2β + τ < µ
2(ζ + α) − 2ζ + 2β + τ < µ ⇒ 2ζ + 2α − 2ζ + 2β + τ < µ
2α + 2β + τ < µ ⇒ 2α + 2β + η − β < µ
2α + β + η < µ
However, µ ≤ η by Remark 2. Thus, 2α + β < 0 which is not possible and it contradicts our assumption.
Case 3: if Λopt ∩ Λ = ∅, Λa ∩ Λ 6= ∅, then let |Λa ∩ Λ| = θ, where 1 ≤ θ ≤ min(µ, τ ).
2|Λopt ∪ Λ| < |Λa ∪ Λ| ⇒ 2(η + τ ) < µ + τ − θ
2η + τ < µ − θ ⇒ 2η + τ < µ
However, µ ≤ η by Remark 2. Thus, η + τ < 0 which is not possible and it contradicts our assumption.
Finally the last case: if Λopt ∩ Λ 6= ∅, Λa ∩ Λ 6= ∅, then let |Λopt ∩ Λ| = ζ, where 1 ≤ ζ ≤ min(η, τ ), and |Λa ∩ Λ| = θ,
where 1 ≤ θ ≤ min(µ, τ ).
2|Λopt ∪ Λ| < |Λ ∪ Λ| ⇒ 2(η + τ − ζ) < µ + τ − θ
2η + 2τ − 2ζ < µ + τ − θ ⇒ 2η + τ − 2ζ < µ − θ < µ
If η ≤ τ , ζ ≤ η and η = ζ + α, for some α ≥ 0, then
2(ζ + α) + τ − 2ζ < µ ⇒ 2α + τ < µ
However, µ ≤ η and η ≤ τ by Remark 2. Thus, 2α < 0 which is not possible and it contradicts our assumption.
If η > τ , η = τ + β, for some β > 0, ζ ≤ τ and τ = ζ + α, for some α ≥ 0, then
2η + τ − 2ζ < µ ⇒ η + (τ + β) + τ − 2ζ < µ
η + (ζ + α) + β + (ζ + β) − 2ζ < µ ⇒ η + 2ζ + α + 2β − 2ζ < µ
η + α + 2β < µ
However, µ ≤ η by Remark 2. Thus, α + 2β < 0 which is not possible and it contradicts our assumption.
Therefore, |Λa ∪ Λ| ≤ 2|Λopt ∪ Λ|, and we can conclude that w(Pa ) ≤ 2w(Popt ).
R EFERENCES
A. Bhatia, L. E. Kavraki, and M. Y. Vardi. Sampling-based motion planning with temporal goals. In International Conference
on Robotics and Automation, pages 2689–2696. IEEE, 2010.
Leonardo Bobadilla, Oscar Sanchez, Justin Czarnowski, Katrina Gossman, and Steven LaValle. Controlling wild bodies using
linear temporal logic. In Proceedings of Robotics: Science and Systems, Los Angeles, CA, USA, June 2011.
J. R. Buchi. Weak second order arithmetic and finite automata. Zeitschrift für Math. Logik und Grundlagen Math., 6:66–92,
1960.
Marsha Chechik and Arie Gurfinkel. Tlqsolver: A temporal logic query checker. In Proceedings of the 15th International
Conference on Computer Aided Verification, volume 2725, pages 210–214. Springer, 2003.
Howie Choset, Kevin M. Lynch, Seth Hutchinson, George Kantor, Wolfram Burgard, Lydia E. Kavraki, and Sebastian Thrun.
Principles of Robot Motion: Theory, Algorithms and Implementations. MIT Press, March 2005.
A. Cimatti, M. Roveri, V. Schuppan, and A. Tchaltsev. Diagnostic information for realizability. In Francesco Logozzo, Doron
Peled, and Lenore Zuck, editors, Verification, Model Checking, and Abstract Interpretation, volume 4905 of LNCS, pages
52–67. Springer, 2008.
Igor Cizelj and Calin Belta. Negotiating the probabilistic satisfaction of temporal logic motion specifications. In IEEE/RSJ
International Conference on Intelligent Robots and Systems, 2013.
Edmund M. Clarke, Orna Grumberg, and Doron A. Peled. Model Checking. MIT Press, Cambridge, Massachusetts, 1999.
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Cliff Stein. Introduction to Algorithms. MIT Press/McGrawHill, second edition, September 2001.
Yulin Ding and Yan Zhang. A logic approach for ltl system modification. In 15th International Symposium on Foundations of
Intelligent Systems, volume 3488 of LNCS, pages 435–444. Springer, 2005. ISBN 3-540-25878-7.
Juraj Dzifcak, Matthias Scheutz, Chitta Baral, and Paul Schermerhorn. What to do and how to do it: Translating natural language
directives into temporal and dynamic logic representation for goal management and action execution. In Proceedings of the
IEEE international conference on robotics and automation, 2009.

22

Georgios E. Fainekos. Revising temporal logic specifications for motion planning. In Proceedings of the IEEE Conference on
Robotics and Automation, May 2011.
Georgios E. Fainekos, Antoine Girard, Hadas Kress-Gazit, and George J. Pappas. Temporal logic motion planning for dynamic
robots. Automatica, 45(2):343–352, February 2009.
Ioannis Filippidis, Dimos V. Dimarogonas, and Kostas J. Kyriakopoulos. Decentralized multi-agent control from local LTL
specifications. In 51st IEEE Conference on Decision and Control, pages pp. 6235–6240, 2012.
Marcelo Finger and Renata Wassermann. Revising specifications with CTL properties using bounded model checking. In
Brazilian Symposium on Artificial Intelligence, volume 5249 of LNAI, page 157166, 2008.
P. Gastin and D. Oddoux. Fast LTL to Büchi automata translation. In G. Berry, H. Comon, and A. Finkel, editors, Proceedings
of the 13th CAV, volume 2102 of LNCS, pages 53–65. Springer, 2001.
Giuseppe De Giacomo and Moshe Y. Vardi. Automata-theoretic approach to planning for temporally extended goals. In
European Conference on Planning, volume 1809 of LNCS, pages 226–238. Springer, 1999.
Moritz Göbelbecker, Thomas Keller, Patrick Eyerich, Michael Brenner, and Bernhard Nebel. Coming up with good excuses:
What to do when no plan can be found. In Proceedings of the 20th International Conference on Automated Planning and
Scheduling (ICAPS). AAAI Press, may 2010.
Arie Gurfinkel, Benet Devereux, and Marsha Chechik. Model exploration with temporal logic query checking. SIGSOFT Softw.
Eng. Notes, 27(6):139–148, 2002.
Kris Hauser. The minimum constraint removal problem with three robotics applications. In In Proceedings of the International
Workshop on the Algorithmic Foundations of Robotics (WAFR), 2012.
S. Karaman, R. Sanfelice, and E. Frazzoli. Optimal control of mixed logical dynamical systems with linear temporal logic
specifications. In IEEE Conf. on Decision and Control, 2008.
K. Kim and G. Fainekos. Approximate solutions for the minimal revision problem of specification automata. In Proceedings
of the IEEE/RSJ International Conference on Intelligent Robots and Systems, 2012.
Kangjin Kim. LTL2BA modification for indexing, 2014a. URL https://git.assembla.com/ltl2ba cpslab.git.
Kangjin Kim. Temporal logic specification revision and planning toolbox, 2014b. URL https://subversion.assembla.com/svn/
temporal-logic-specification-revision-and-planning-toolbox/.
Kangjin Kim and Georgios Fainekos. Revision of specification automata under quantitative preferences. In Proceedings of the
IEEE Conference on Robotics and Automation, 2014.
Kangjin Kim, Georgios Fainekos, and Sriram Sankaranarayanan. On the revision problem of specification automata. In
Proceedings of the IEEE Conference on Robotics and Automation, May 2012.
M. Kloetzer and C. Belta. Automatic deployment of distributed teams of robots from temporal logic specifications. IEEE
Transactions on Robotics, 26(1):48–61, 2010.
R. Konighofer, G. Hofferek, and R. Bloem. Debugging formal specifications using simple counterstrategies. In Formal Methods
in Computer-Aided Design, pages 152 –159. IEEE, November 2009.
Hadas Kress-Gazit, Georgios E. Fainekos, and George J. Pappas. Translating structured english to robot controllers. Advanced
Robotics, 22(12):1343–1359, 2008.
Hadas Kress-Gazit, Gerogios E. Fainekos, and George J. Pappas. Temporal logic based reactive mission and motion planning.
IEEE Transactions on Robotics, 25(6):1370 – 1381, 2009.
Orna Kupferman, Wenchao Li, and Sanjit A. Seshia. A theory of mutations with applications to vacuity, coverage, and fault
tolerance. In Proceedings of the International Conference on Formal Methods in Computer-Aided Design, pages 25:1–25:9,
Piscataway, NJ, USA, 2008. IEEE Press.
Bruno Lacerda and Pedro Lima. Designing petri net supervisors from ltl specifications. In Proceedings of Robotics: Science
and Systems, Los Angeles, CA, USA, June 2011.
Steven M. LaValle. Planning Algorithms. Cambridge University Press, 2006. URL http://msl.cs.uiuc.edu/planning/.
Amy LaViers, Magnus Egerstedt, Yushan Chen, and Calin Belta. Automatic generation of balletic motions. IEEE/ACM
International Conference on Cyber-Physical Systems, 0:13–21, 2011.
David Park. Concurrency and automata on infinite sequences. In Proceedings of the 5th GI-Conference on Theoretical Computer
Science, pages 167–183. Springer-Verlag, 1981.
Vasumathi Raman and Hadas Kress-Gazit. Analyzing unsynthesizable specifications for high-level robot behavior using
LTLMoP. In 23rd International Conference on Computer Aided Verification, volume 6806 of LNCS, pages 663–668. Springer,
2011.
Vasumathi Raman and Hadas Kress-Gazit. Towards minimal explanations of unsynthesizability for high-level robot behaviors.
In 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, Tokyo, Japan, November 3-7, 2013, pages
757–762, 2013. doi: 10.1109/IROS.2013.6696436. URL http://dx.doi.org/10.1109/IROS.2013.6696436.
Vasumathi Raman, Constantine Lignos, Cameron Finucane, Kenton C. T. Lee, Mitchell P. Marcus, and Hadas Kress-Gazit. Sorry
dave, i’m afraid I can’t do that: Explaining unachievable robot tasks using natural language. In Robotics: Science and Systems
IX, Technische Universität Berlin, Berlin, Germany, June 24 - June 28, 2013, 2013. URL http://www.roboticsproceedings.
org/rss09/p23.html.

23

Pritam Roy, Paulo Tabuada, and Rupak Majumdar. Pessoa 2.0: a controller synthesis tool for cyber-physical systems. In
Proceedings of the 14th international conference on Hybrid systems: computation and control, HSCC ’11, pages 315–316,
New York, NY, USA, 2011. ACM.
David E. Smith. Choosing objectives in over-subscription planning. In Proceedings of the 14th International Conference on
Automated Planning and Scheduling (ICAPS-04), pages 393–401, 2004.
Moshe Sniedovich. Dijkstras algorithm revisited: the dynamic programming connexion. Control and Cybernetics, 35(3):
599–620, 2006.
J. G. Thistle and W. M. Wonham. Supervision of infinite behavior of discrete-event systems. SIAM J. Control Optim., 32(4):
1098–1113, 1994. ISSN 0363-0129.
J. Tumova, L. I. Reyes Castro, S. Karaman, E. Frazzoli, and D. Rus. Minimum-violating planning with conflicting specifications.
In American Control Conference, 2013.
Alphan Ulusoy, Stephen L. Smith, Xu Chu Ding, Calin Belta, and Daniela Rus. Optimal multi-robot path planning with
temporal logic constraints. In IEEE/RSJ International Conference on Intelligent Robots and Systems,, pages 3087 –3092,
2011.
Alphan Ulusoy, Stephen L. Smith, Xu Chu Ding, and Calin Belta. Robust multi-robot optimal path planning with temporal
logic constraints. In 2012 IEEE International Conference on Robotics and Automation (ICRA), 2012.
Menkes van den Briel, Romeo Sanchez, Minh B. Do, and Subbarao Kambhampati. Effective approaches for partial satisfaction
(over-subscription) planning. In Proceedings of the 19th national conference on Artifical intelligence, AAAI’04, pages
562–569. AAAI Press, 2004. ISBN 0-262-51183-5.
Tichakorn Wongpiromsarn, Ufuk Topcu, and Richard M. Murray. Receding horizon control for temporal logic specifications.
In Proceedings of the 13th ACM international conference on Hybrid systems: computation and control, pages 101–110, New
York, NY, USA, 2010. ACM. ISBN 978-1-60558-955-8.

2012 IEEE International Conference on Robotics and Automation
RiverCentre, Saint Paul, Minnesota, USA
May 14-18, 2012

On the Revision Problem of Specification Automata
Kangjin Kim, Georgios E. Fainekos and Sriram Sankaranarayanan

Abstract— One of the important challenges in robotics is
the automatic synthesis of provably correct controllers from
high level specifications. One class of such algorithms operates
in two steps: (i) high level discrete controller synthesis and
(ii) low level continuous controller synthesis. In this class of
algorithms, when phase (i) fails, then it is desirable to provide
feedback to the designer in the form of revised specifications
that can be achieved by the system. In this paper, we address
the minimal revision problem for specification automata. That
is, we construct automata specifications that are as “close” as
possible to the initial user intent, by removing the minimum
number of constraints from the specification that cannot be
satisfied. We prove that the problem is computationally hard
and we encode it as a satisfiability problem. Then, the minimal
revision problem can be solved by utilizing efficient SAT solvers.

I. I NTRODUCTION
One of the fundamental challenges in robotics is how
to achieve fully automatic correct-by-design synthesis of
control software. Scalable methods and techniques for synthesizing correct by construction controllers can potentially
revolutionize the design process, yielding huge benefits in
terms of improved safety, reliability and time to market.
Moreover, governmental agencies will have the tools to
certify in short time medical robotic devices, autonomous
automobiles and airplanes etc.
Currently, the automatic synthesis problem for complex
dynamical systems is broken into two levels. First, high level
synthesis of the discrete controller and, subsequently, low
level composition of simple control laws. A variety of such
theories and methodologies exist which are usually classified based on the high level specification framework. For
example, a very general and well developed framework for
high-level programming is the extended Motion Description
Language (MDLe) [1] which has interesting composition
properties [2]. A more recent attempt to use Context Free
Languages (CFL) for robotic control appears in [3]. Finite
automata are used as a specification language in [4]. Another
very popular formal specification language is temporal logics
with multiple applications in robotics [5]–[12].
Nevertheless, one issue that has not been adequately
addressed so far in such combined high-low level controller
synthesis frameworks is what happens when the high-level
synthesis phase fails. That is, when the specification cannot be realized in the current environment under the curThis work has been partially supported by award NSF CNS 1116136.
K. Kim and G. Fainekos are with the School of Computing, Informatics
and Decision Systems Engineering, Arizona State University, Tempe, AZ
85281, USA {Kangjin.Kim,fainekos}@asu.edu
S. Sankaranarayanan is with the Department of Computer Science,
University of Colorado, Boulder, CO srirams@colorado.edu

978-1-4673-1405-3/12/$31.00 ©2012 IEEE

rent system dynamics, then the current high-level synthesis
frameworks simply report a failure. Thus, the user is usually
left in the dark as of why the specification failed and, most
importantly, on what the system can actually achieve that is
close to the initial intentions of the user.
In this paper, we study the theoretical foundations of the
specification revision problem when both the system and
the specification can be represented by ω-automata [13].
In particular, we focus on the Minimal Revision Problem
(MRP), i.e., finding the closest satisfiable specification to the
initial specification, and we prove that the problem is NPcomplete. In view of this negative result, we study whether
encoding MRP as a satisfiability problem and utilizing stateof-the-art satisfiability solvers provides an efficient solution
to the problem.
The specification revision problem for automata based
planning techniques is a relatively new problem. In our
previous work [14], we introduced the specification revision problem for Linear Temporal Logic (LTL). There, we
identified conditions such that the minimal revision can be
efficiently solved and we provided a randomized algorithm
to return some specification revision (but not necessarily the
minimal). Finding out why a specification is not satisfiable
on a model is a problem that is very related to the problems
of vacuity and coverage in model checking [15]. Another
related problem is the detection of the causes of unrealizability in LTL games. In this case, a number of heuristics
have been developed in order to localize the error and
provide meaningful information to the user for debugging
[16], [17]. Along these lines, LTLMop [18] was developed
to debug unrealizable LTL specifications in reactive planning
for robotic applications.
II. P ROBLEM F ORMULATION
In this paper, we work with discrete abstractions (Finite
State Machines) of the continuous robotic control system [5].
This is a common practice in approaches that hierarchically
decompose the control synthesis problem into high level discrete planning synthesis and low level continuous feedback
controller composition [5], [6], [11]. Each state of the Finite
State Machine (FSM) T is labeled by a number of symbols
from a set Π = {π0 , π1 , . . . , πn } that represent regions in the
workspace of the robot or, more generally, in its configuration
space (see [19] for precise definitions of workspace and
configuration spaces). The control requirements for such a
system can be posed using specification automata B with
Büchi acceptance conditions [13] also known as ω-automata.
The following example, which is the running example
of this paper, presents such a typical scenario for motion

5171

60

60

50

50
40

π

4

y2

z

2

40
30

30

π

2

π

1

20

π

3

20

10

π

0

10
0
0

0
0

10

20

30

40

50
y1

60

70

80

90

Fig. 1. The simple environment of Example 1 along with a low speed
mobile robot trajectory that satisfies the specification.
π0 ∧ π2 ∧ π3
π0 π0 ∧ π3

π0

s0

π0

π0 ∧ π2

s1

s2

π0 ∧ ¬π2 ∧ π3 ∧ π4

s3

π0 ∧ π1 ∧ π3 ∧ π4

π0 ∧ π1

s4
π0 ∧ π1

The specification automaton of Example 1.

planning of a mobile robot.
Example 1 (Robot Motion Planning): We consider a mobile robot which operates in a planar environment. The
continuous state variable x(t) models the internal dynamics
of the robot whereas only its position y(t) is observed. In
this paper, we will consider a 2nd order model of the motion
a planar robot (dynamic model):
ẋ2 (t) = u(t),

30

40

50
z

60

70

80

90

100

Fig. 3. The modified environment of Fig. 1 under large bounds on the
permissible acceleration U . The dark gray regions indicate areas that should
be avoided in order to satisfy ¬πi while the light gray regions indicate areas
that should be visited in order to satisfy πi .

π0 ∧ π1 ∧ π4

∧4i=0 πi

ẋ1 (t) = x2 (t),

20

π0 ∧ ¬π2 ∧ π4

π0 ∧ ¬π2

Fig. 2.

10

1

100

x1 (t) ∈ R2 , x1 (0) ∈ X1,0
x2 (t) ∈ R2 , x2 (0) = 0, u(t) ∈ U

y(t) = x1 (t).
The robot is moving in a convex polygonal environment π0
with four areas of interest denoted by π1 , π2 , π3 , π4 (see
Fig. 1). The robot is placed somewhere in the region labeled
by π1 . The robot must accomplish the task: “Stay always in
π0 and visit area π2 , then area π3 , then area π4 and, finally,
return to and stay in region π1 while avoiding area π2 ,” which
is captured by the specification automaton in Fig. 2.
In [5], we developed a hierarchical framework for motion planning for dynamic models of robots. The hierarchy
consists of a high level logic planner that solves the motion
planning problem for a kinematic model of the robot, e.g.,
ż(t) = u(t), y ′ (t) = z(t), z(t) ∈ R2 , z(0) ∈ Z0 .

set modification might make the specification unrealizable.
E.g., in Fig. 3, the robot cannot move from π4 to π1 while
avoiding π2 , even though the specification can be realized
on the workspace of the robot that the user perceives. In
this case, the user is entirely left in the dark as of why the
specification failed and, more importantly, on what actually
the system can achieve under these new constraints.
△
When a specification B is not satisfiable on a particular
system T , then the current motion planning and control
synthesis methods [5], [6] based on automata theoretic
concepts simply return that the specification is not satisfiable
without any other user feedback. The goal of this paper is to
study specification feedback mechanisms when the automata
theoretic planning phase fails to return a plan.
Problem 1 (Minimal Revision Problem (MRP)): Given a
system T and a specification automaton B, if the specification B cannot be satisfied on T , then find the “closest”
specification B ′ to B which can be satisfied on T .
Problem 1 was first introduced in [14] for Linear Temporal
Logic (LTL) specifications. In [14], we provided solutions
to the debugging and (not minimal) revision problems and
we demonstrated that we can easily get a minimal revision
of the specification when the discrete controller synthesis
phase fails due to unreachable states in the system. Thus, in
this paper, we concentrate on the harder problem of minimal
revision when all the states on T are reachable.
Assumption 1: All the states on T are reachable.
In this paper, we prove that if the specification is provided
as an arbitrary ω-automaton, then a restricted version of the
minimal revision problem is NP-complete. This theoretical
result has profound implications on two fronts.
•

Then, the resulting hybrid controller is utilized for the
design of an approximate tracking controller for the dynamic
model. Since the tracking is approximate, the sets that the
atomic propositions map to need to be modified (see Fig. 3)
depending on the maximum speed of the robot so the that
the controller has a guaranteed tracking performance. For
example, in Fig. 3, the regions that now must be visited are
the contracted light gray regions, while the regions to be
avoided are the expanded dark gray regions. However, the
5172

•

First, the LTL MRP is most likely NP-complete as well.
The ω-automata that correspond to LTL formulas are a
restricted subset of all possible ω-automata. However,
the structural properties that cause the NP-completeness
of the problem exist in this restricted class of automata
as well.
Second, we now know that in order to find polynomial
time solutions to Problem 1, we will either have to
develop randomized algorithms (as we did in [14]) or
develop approximation algorithms.

l

i.e., if s →B s′ , then λB (s, s′ ) = l; and if (s, s′ ) 6∈ EB ,
then λB (s, s′ ) = ∅.

III. C ONSTRUCTING D ISCRETE C ONTROLLERS
In this section, we provide a brief review of the automata
based motion planning. This is required in order to understand the new contributions of this paper. In order to use ωautomata to specify requirements for continuous systems, we
need to construct a finite partition of the robot’s workspace
[19]. For that purpose, we can use many efficient cell
decomposition methods for polygonal environments [19].
This results in a topological graph G = (Q, E) which
describes which cells are topologically adjacent, i.e., each
node q ∈ Q in the graph represents a cell and each edge
e = (q, q ′ ) ∈ E in the graph implies topological adjacency
of the cells. Each such cell will be a state in the FSM which
will be labeled by one or more atomic propositions from Π.
Next, we formally define the FSM that can be constructed
from the graph G.
Definition 1 (FSM): A Finite State Machine is a tuple
T = (Q, Q0 , →T , hT , Π) where: Q is a set of states;
Q0 ⊆ Q is the set of possible initial states; →T = E ⊆ Q×Q
is the transition relation; and, hT : Q → P(Π) maps each
state q to the set of atomic propositions that are true on q.
We define a path on the FSM to be a sequence of states
and a trace to be the corresponding sequence of sets of
propositions. Formally, a path is a function p : N → Q
such that for each i ∈ N we have p(i) →T p(i + 1)
and the corresponding trace is the function composition
p̄ = hT ◦ p : N → P(Π). The language L(T ) of T consists
of all possible traces.
In this work, we are interested in the ω-automata that will
impose certain requirements on the traces of T . ω-automata
differ from the classic finite automata in that they accept
infinite strings (traces of T in our case).
Definition 2: A automaton is a tuple B
=
B
,
Ω,
δ
,
F
)
where:
S
is
a
finite
set
of
states;
s
(SB , sB
B
B
B
0 is
0
the initial state; Ω is an input alphabet; δB : SB ×Ω → P(SB )
is a transition function; and FB ⊆ SB is a set of final states.
l
When s′ ∈ δB (s, l), we also write s →B s′ or
(s, l, s′ ) ∈→B . A run r of B is a sequence of states r :
N → SB that occurs under an input trace p̄ taking values in
Ω. That is, for i = 0 we have r(0) = sB
0 and for all i ≥ 0 we
p̄(i)

have r(i) → B r(i+1). Let lim(·) be the function that returns
the set of states that are encountered infinitely often in the
run r of B. Then, a run r of an automaton B over an infinite
trace p̄ is accepting if and only if lim(r) ∩ FB 6= ∅. This is
called a Büchi acceptance condition. Finally, we define the
language L(B) of B to be the set of all traces p̄ that have a
run that is accepted by B.
A specification automaton is an automaton with Büchi acceptance condition where the input alphabet is the powerset
of the labels of the system T , i.e., Ω = P(Π). In order to
simplify the discussion in Section IV, we will be using the
following assumptions and notation
′
2
• we define the set EB ⊆ SB , such that (s, s ) ∈ EB iff
l
′
∃l ∈ Ω , s →B s ; and,
2
• we define the function λB : SB → Ω which maps a pair
of states to the label of the corresponding transition,

In brief, our goal is to generate paths on T that satisfy
the specification Bs . In automata theoretic terms, we want to
find the subset of the language L(T ) which also belongs to
the language L(Bs ). This subset is simply the intersection of
the two languages L(T ) ∩ L(Bs ) and it can be constructed
by taking the product T × Bs of the FSM T and the
specification automaton Bs . Informally, the automaton Bs
restricts the behavior of the system T by permitting only
certain acceptable transitions. Then, given an initial state
in the FSM T , we can choose a particular trace from
L(T ) ∩ L(Bs ) according to a preferred criterion.
Definition 3: The product automaton A = T × Bs is the
automaton A = (SA , sA
0 , P(Π), δA , FA ) where:
• SA = Q × SBs ,
B
A
• s0 = {(q0 , s0 s ) | q0 ∈ Q0 },
• δA : SA × P(Π) → P(SA ) s.t. (qj , sj ) ∈ δA ((qi , si ), l)
iff qi →T qj and sj ∈ δBs (si , l) with l ⊆ hT (qj ),
• FA = Q × F is the set of accepting states.
Note that L(A) = L(T ) ∩ L(Bs ). We say that Bs is
satisfiable on T if L(A) 6= ∅. Moreover, finding a satisfying
path on T ×Bs is an easy algorithmic problem [20]. First, we
convert automaton T × Bs to a directed graph and, then, we
find the strongly connected components (SCC) in that graph.
If at least one SCC that contains a final state is reachable
from an initial state, then there exist accepting (infinite) runs
on T × Bs that have a finite representation. Each such run
consists of two parts: a part that is executed only once (from
an initial state to a final state) and a part that is repeated
infinitely (from a final state back to itself). Note that if no
final state is reachable from the initial or if no final state is
within an SCC, then the language L(A) is empty and, hence,
the high level synthesis problem does not have a solution.
Namely, the synthesis phase has failed and we cannot find a
system behavior that satisfies the specification Bs .
IV. T HE S PECIFICATION R EVISION P ROBLEM
Intuitively, a revised specification is one that can be
satisfied on the discrete abstraction of the workspace or the
configuration space of the robot. In order to search for a
minimal revision, we need first to define an ordering relation
on automata as well as a distance function between automata.
Similar to the case of LTL formulas in [14], we do not want
to consider the “space” of all possible automata, but rather
the “space” of specification automata which are semantically
close to the initial specification automaton Bs . The later
will imply that we remain close to the initial intention of
the designer. We propose that this space consists of all the
automata that can be derived from Bs by removing atomic
propositions from the transition input. Our definition of the
ordering relation between automata relies upon the previous
assumption.
1
Definition 4 (Relaxation): Let B1 = (SB1 , sB
0 , P(Π),
2
,
F
,
P(Π),
→
→B1 , FB1 ) and B2 = (SB2 , sB
B2 ) be two
B2
0
specification automata. Then, we say that B2 is a relaxation

5173

of B1 and we write B1  B2 if and only if SB1 = SB2 = S,
B2
1
sB
0 = s0 , FB1 = FB2 and
1) ∀(s, l, s′ ) ∈→B1 − →B2 . ∃l′ .
(s, l′ , s′ ) ∈→B2 − →B1 and l′ ⊆ l.
2) ∀(s, l, s′ ) ∈→B2 − →B1 . ∃l′ .
(s, l′ , s′ ) ∈→B1 − →B2 and l′ ⊇ l.
We remark that  is a partial order over specification
automata. Also, if B1  B2 , then L(B1 ) ⊆ L(B2 ) since
the relaxed automaton allows more behaviors to occur. It is
possible that two automata B1 and B2 cannot be compared
under relation . We can now define the set of automata
over which we will search for a minimal solution that has
nonempty intersection with the system.
Definition 5: Given a system T and a specification automaton Bs , the set of valid relaxations of Bs is defined as
R(Bs , T ) = {B | Bs  B and L(T × B) 6= ∅}.
We can now search for a minimal solution in the set
R(Bs , T ). That is, we can search for some B ∈ R(Bs , T )
such that if for any other B ′ ∈ R(Bs , T ), we have B ′  B,
then L(B) = L(B ′ ). However, this does not imply that
a minimal solution semantically is minimal structurally as
well. In other words, it could be the case that B1 and B2 are
minimal relaxations of some Bs , and moreover, B1 requires
the modification of only one transition while B2 requires the
modification of two transitions. Therefore, we must define a
distance on the set R(Bs , T ), which accounts for the number
of changes from the initial specification automaton Bs .
Definition 6: Given a system T and a specification automaton Bs , we define the distance
P of any B ∈ R(Bs′, T )
from Bs to be distBs (B) =
(s,s′ )∈EBs |λBs (s, s ) −
′
λB (s, s )| where | · | is the cardinality of the set.
Therefore, Problem 1 can be restated as:
Problem 2: Given a system T and a specification automaton Bs such that L(T × Bs ) = ∅, find B ∈
arg min{distBs (B ′ ) | B ′ ∈ R(Bs , T )}.
A. Minimal Revision as a Graph Problem
We will solve Problem 2 by introducing Boolean variables
that represent various possible revisions of the specification
automaton Bs . Consequently, we extend the existing product
automaton T × Bs by adding edges labeled by a conjunction
of Boolean revision variables that can enable the edges.
The overall problem then becomes one of finding the least
number of Boolean revision variables that need to be set to
true so that the product graph has an accepting run.
Revision Variables: We first add Boolean revision variables y(ei , πj ) for each edge ei ∈ EBs and each atomic
proposition πj ∈ λBs (ei ) that labels the ei transition on
Bs . The revision variable proposes to relax the edge ei
by removing πj from its set of atomic propositions. Let
R EV VARS represent the set of all revision variables.
Graphs labeled with Revision Variables: We provide the
formal definition of GA which corresponds to a product
automaton A while considering the effect of revisions.
Definition 7: Given a system T and a specification automaton Bs , we define the graph GA = (V, E, vs , Vf , L),
which corresponds to the product A = T × Bs as follows

V = S is the set of nodes
E = EA ∪ ED ⊆ S × S, where EA is the set
of edges that correspond to transitions on A, i.e.,
l
((q, s), (q ′ , s′ )) ∈ EA iff ∃l ∈ P(Π) . (q, s) →A
′ ′
(q , s ); and ED is the set of edges that correspond
to disabled transitions, i.e., ((q, s), (q ′ , s′ )) ∈ ED iff
l
q →T q ′ and s →Bs s′ with l ∩ (Π − hT (q ′ )) 6= ∅.
A
• vs = s0 is the source node,
• Vf = FA is the set of sinks,
• L : E → P(R EV VARS ) maps each edge of the graph
with a set of revision variables that need to be set to true
in order to enable it. The construction of the labeling
function will be described subsequently.
We describe the construction of the labeling function
L : E → P(R EV VARS ) for the product graph A. Let
e = ((q, s), (q ′ , s′ )) be an edge in A corresponding to edge
ei = (s, s′ ) in Bs and edge (q, q ′ ) in T . Consider the set of
atomic propositions given by Λ(e) = λBs (s, s′ ) − hT (q ′ ) .
If Λ(e) 6= ∅, then it specifies those atomic propositions
in λBs (s, s′ ) that need to be removed in order to enable
the edge in the product state. The label for the edge e =
((q, s), (q ′ , s′ )) is defined as: L(e) = {y((s, s′ ), πj ) | πj ∈
Λ(e)}
•

•

B. Paths on Graphs labeled with Boolean Variables
We now present the problem of finding accepting paths on
Boolean labeled graphs. Let Y = {y1 , . . . , ym } be a set of
Boolean variables and G : (V, E) be a graph with a labeling
function L : E → P(Y ), wherein each edge e ∈ E is labeled
with a set of Boolean variables L(e) ⊆ Y . The label on an
edge indicates that the edge is enabled iff all the Boolean
variables on the edge are set to true. Let v0 ∈ V be a marked
initial state and F ⊆ V be a set of marked final vertices.
Problem 3 (Minimal Accepting Path (MAP)): I NPUTS : A
set of Boolean variables Y , graph G with edge labeling
function L, initial vertex v0 and final vertices F ⊆ V .
O UTPUT: A set Z ⊆ Y of minimal cardinality such that
setting all variables in Z to true and Y − Z to false enables
a path from v0 to some final vertex vf ∈ F along with a
cycle from vf back to itself.
Theorem 1: Given an instance of the minimal accepting
path problem (Y, G, L, v0 , F ) and a bound W , the decision
of problem of whether there exists a truth assignment Z ⊆ Y
such that |Z| ≤ W is NP-Complete.
C. MAP Encoding Into SAT
We discuss a SAT-based encoding of the minimal accepting path. Our encoding converts the search for a minimal
truth assignment to a pseudo-Boolean optimization problem.
Let (Y, G, L, v0 , F ) be a given instance of the minimal
accepting path problem, wherein the graph G has vertices
V and edges E ⊆ V × V . Our goal is to first produce a
Boolean formula Ψ[Y, R] over the Boolean variables in Y
and auxiliary variables in R (described below), such that
for any truth assignment to the variables in Y , there is an
accepting path iff (∃R)Ψ[Y, R].

5174

(u,v)∈E

y∈L(u,v)

V

3) If (vf , v) ∈ E, then REACH (vf , v) ⇔
4) If (vf , v) 6∈ E, then

_
REACH (vf , u) ∧
REACH (vf , v) ⇔
(u,v)∈E

y∈L(vf ,v)

^

y∈L(u,v)

y.



y .

b) “Lasso” condition: Finally, we assert the existence
of a final state which is reachable from itself:
_
(REACH (v0 , vf ) ∧ REACH (vf , vf ))
vf ∈F

SMT solvers such as Yices (http://yices.csl.sri.com) and
Z3 (http://research.microsoft.com/projects/z3) allow us to
search for a minimum weight satisfiable by specifying
weights for setting a variable y to true.
V. N UMERICAL E XPERIMENTS
In this section, we demonstrate the application of our
framework on our motivating example and, then, we assess
the feasibility of posing MRP as a satisfiability problem. For
the experiments, we utilized the ASU supercomputing center
which consists of clusters of Dual 4-core processors, 16GB
Intel(R) Xeon(R) CPU X5355 @2.66 GHz. Our implementations do not utilize the parallel architecture. The clusters
were used to run the many different test cases in parallel on
a single core. The operating system is CentOS release 5.5.
Example 2: First, we revisit our motivating Example 1.
For this example, we used MiniSat [21] for solving the
SAT encoding of MAP. The environment of Fig. 1 was
abstracted into a state machine with 17 states. Thus, the
graph GA had 85 states and 140 atomic propositions: 10 on
the specification automaton (5 positive + 5 negative) times 14
transitions on the specification automaton. The real running
time was 11.7 sec and our implementation returned the 13
revisions. The minimal 3 revisions were: (1) y((s3 , s3 ), ¬π2 ),
(2) y((s2 , s3 ), π4 ), (3) y((s2 , s4 ), π4 ).

60
50
40
y2

The variables in R are of the form REACH (v0 , v) and
REACH (vf , v) for every vertex v ∈ V and vf ∈ F . The
proposition REACH (v0 , v) denotes that vertex v is reachable
from v0 . Similarly for vf ∈ F , the proposition REACH (vf , v)
denotes that vertex v is reachable from vf . We will discuss
the encoding of reachability in terms of a Boolean formula.
The encoding consists of many parts that are conjoined
together (using the AND operator) to create the final formula
involving variables in Y along with variables in R.
a) Reachability from v0 and from vf ∈ F : A node
is reachable iff one of its predecessors is reachable and the
Boolean condition on the edge holds. We assert the following
clauses (assuming that v0 6= vf , otherwise only either the
clauses (v0 , v) or the clauses (vf , v) need to be considered):
V
1) If (v0 , v) ∈ E, then REACH (v0 , v) ⇔ y∈L(v0 ,v) y.
2) If (v0 , v) 6∈ E, then


^
_
REACH (v0 , u) ∧
y .
REACH (v0 , v) ⇔

30
20
10
0
0

10

20

30

40

50
y1

60

70

80

90

100

Fig. 4. The simple environment of Example 1 along with two trajectories
generated using the revised specifications.

Revision (1) is the one that conforms the most with the
human intuition of what a revision to the requirement “Stay
always in π0 and visit area π2 , then area π3 , then area π4
and, finally, return to and stay in region π1 while avoiding
area π2 ,” should be. Namely, if there cannot be a solution
that avoids π2 , then go through π2 . The motion generated
under Revision (1) appears in Fig. 4 in light gray.
Revisions (2) and (3) actually generate the same behavior
(see dark gray trajectory in Fig. 4). Namely, the resulting
trajectory does not visit π4 and does not avoid π2 . To see why
this occurs, let us first consider revision (3). After visiting
π3 the specification automaton is in state s2 . Thus, now, we
have the option to take transition (s2 , s4 ) to get to region
π1 without having to avoid region π2 . On the other hand,
Revision (2) permits the specification automaton to stay in
state s3 until the robot passes over region π2 at which point
the transition (s2 , s3 ) can be taken.
We see that there are several minimal revisions some of
which generate different behaviors. Thus, a feedback system
to the user must supply many such different revisions and
let the user select one of them.
We remark that our alternative implementation of the SAT
encoding of MAP using Answer Set Programming (ASP) and
ClaspD 1.1 [22] returned Revision (2) (along with 3 more
non-minimal revisions) in less than 1 sec.
△
To evaluate if the solution to the SAT encoding of the
minimal revision problem can be solved efficiently we run a
number of experiments. The SAT encoding implementation
was performed using Answer Set Programming (ASP) [22]
under ClaspD 1.1. We repeated each experiment many times
and we report the minimum, maximum and average real
running time. Since in some cases the computation time
exceeded the 2hr hard bound that we had set, we also report
the number of tests that succeeded out of the total number
of trials. Note that the average value is reported for the test
cases that succeeded in computing a minimal revision.
Table I compares the total number of nodes vs the total
number of edges in a graph. For each pair of values we
generated a random graph where about 20% of nodes are
final and the number of atomic propositions is fixed. Each
experiment was executed for a number of nodes and for
a sparse graph, a medium connected graph and a dense
graph. Each graph is generated randomly by providing the
number of nodes, the number of edges, the number of atomic

5175

Edges →
Nodes n ↓
10
100
200
300
400
500

min
0.0
0.3
1.8
5.9
14.7
33.2

Sparse: 2n − 2
avg
max
0.1
0.2
0.6
1.5
4.7
24.1
15.4
76.3
58.2
244.9
125.7
473.0

succ
100/100
100/100
100/100
100/100
100/100
100/100

min
0.0
0.9
9.5
34.8
87.1
176.8

Medium: 3n
avg
max
0.0
0.1
41.5
1934.2
273.4
6400.8
536.5
5624.3
1218.8
4175.3
1800.8
6939.2

succ
100/100
100/100
77/100
71/100
50/100
48/100

min
0.0
1425.1

Dense: n2
avg
max
0.1
0.9
2541.5
5970.4

succ
100/100
67/100
0/100
0/100
0/100
0/100

TABLE I
N UMERICAL E XPERIMENTS : N UMBER OF NODES VERSUS NUMBER OF EDGES . T HE REPORTED NUMBERS ARE MINIMUM , AVERAGE AND MAXIMUM
RUNNING TIME IN SECONDS AND THE NUMBER OF TRIALS THAT SUCCESSFULLY COMPLETED WITHIN 2 HR . F OR EACH RANDOMLY GENERATED
GRAPH , THERE WERE

propositions and the number of final states.
The experimental results indicate that a specification feedback and revision framework based on satisfiability solvers
will be efficient only for small sized problems. The class of
mission and motion planning problems that would generate
graph sizes that can be solved efficiently within our framework is task planning for a single mobile robot within small
- but complicated - environments such as an office building.
VI. C ONCLUSIONS
In this paper, we introduced the problem of minimal revision of specification automata. Namely, if the specification
for a task of a robot is provided as an ω-automaton and
the specification cannot be satisfied on the model of the
system, then propose a new specification automaton which
defines requirements that can be satisfied on the system.
The challenge in proposing a new specification automaton
is that the new automaton should be as close as possible
to the initial intent of the user. We proved that actually the
minimal revision problem for specification automata is NPcomplete. We also provided an encoding of the problem
as a satisfiability problem which can be solved by the
state-of-art satisfiability solvers. Even though our current
solution is efficient for single robot scenarios, we expect that
polynomial-time approximation or randomized algorithms
will provide efficient solutions for multi-robot scenarios. This
is the topic of our on-going research.
ACKNOWLEDGEMENTS
The authors would like to thank the anonymous reviewers
for their detailed comments and suggestions.
R EFERENCES
[1] D. Hristu-Varsakelis, M. Egerstedt, and P. S. Krishnaprasad, “On the
complexity of the motion description language MDLe,” in Proceedings
of the 42nd IEEE CDC, December 2003, pp. 3360–3365.
[2] W. Zhang and H. G. Tanner, “Composition of motion description
languages,” in Hybrid Systems: Computation and Control, ser. LNCS,
vol. 4981. Springer, 2008, pp. 570–583.
[3] N. Dantam and M. Stilman, “The motion grammar: Linguistic perception, planning, and control.” in Robotics: Science and Systems, 2011.
[4] M. Karimadini and H. Lin, “Decomposability of global tasks for multiagent systems,” in in Proc. of the 49th IEEE CDC, 2010.
[5] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, Feb. 2009.

n ATOMIC PROPOSITIONS .

[6] M. Kloetzer and C. Belta, “Automatic deployment of distributed teams
of robots from temporal logic specifications,” IEEE Transactions on
Robotics, vol. 26, no. 1, pp. 48–61, 2010.
[7] S. G. Loizou and K. J. Kyriakopoulos, “Automatic synthesis of multiagent motion tasks based on LTL specifications,” in Proceedings of
the 43rd IEEE Conference on Decision and Control, Dec. 2004.
[8] A. Bhatia, L. E. Kavraki, and M. Y. Vardi, “Sampling-based motion planning with temporal goals,” in International Conference on
Robotics and Automation. IEEE, 2010, pp. 2689–2696.
[9] S. Karaman, R. Sanfelice, and E. Frazzoli, “Optimal control of mixed
logical dynamical systems with linear temporal logic specifications,”
in IEEE CDC, 2008.
[10] P. Roy, P. Tabuada, and R. Majumdar, “Pessoa 2.0: a controller
synthesis tool for cyber-physical systems,” in Proceedings of the 14th
international conference on Hybrid systems: computation and control,
ser. HSCC ’11. New York, NY, USA: ACM, 2011, pp. 315–316.
[11] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Temporal logic
based reactive mission and motion planning,” IEEE Transactions on
Robotics, vol. 25, no. 6, pp. 1370 – 1381, 2009.
[12] T. Wongpiromsarn, U. Topcu, and R. M. Murray, “Receding horizon
control for temporal logic specifications,” in Proceedings of the 13th
ACM international conference on Hybrid systems: computation and
control. New York, NY, USA: ACM, 2010, pp. 101–110.
[13] J. R. Buchi, “Weak second order arithmetic and finite automata,”
Zeitschrift für Math. Logik und Grundlagen Math., vol. 6, 1960.
[14] G. E. Fainekos, “Revising temporal logic specifications for motion
planning,” in Proceedings of the IEEE Conference on Robotics and
Automation, May 2011.
[15] O. Kupferman, W. Li, and S. A. Seshia, “A theory of mutations with
applications to vacuity, coverage, and fault tolerance,” in Proceedings
of the International Conference on Formal Methods in ComputerAided Design. IEEE Press, 2008, pp. 25:1–25:9.
[16] A. Cimatti, M. Roveri, V. Schuppan, and A. Tchaltsev, “Diagnostic
information for realizability,” in Verification, Model Checking, and
Abstract Interpretation, ser. LNCS, F. Logozzo, D. Peled, and L. Zuck,
Eds. Springer, 2008, vol. 4905, pp. 52–67.
[17] R. Konighofer, G. Hofferek, and R. Bloem, “Debugging formal
specifications using simple counterstrategies,” in Formal Methods in
Computer-Aided Design. IEEE, Nov. 2009, pp. 152 –159.
[18] V. Raman and H. Kress-Gazit, “Analyzing unsynthesizable specifications for high-level robot behavior using LTLMoP,” in 23rd International Conference on Computer Aided Verification, ser. LNCS, vol.
6806. Springer, 2011, pp. 663–668.
[19] S. M. LaValle, Planning Algorithms. Cambridge University Press,
2006. [Online]. Available: http://msl.cs.uiuc.edu/planning/
[20] E. M. Clarke, O. Grumberg, and D. A. Peled, Model Checking.
Cambridge, Massachusetts: MIT Press, 1999.
[21] N. Sorensson and N. Een, “Minisat v1.13: A sat solver with conflictclause minimization,” in In Proc. of SAT Competition: Solver Description, 2005.
[22] C. Drescher, M. Gebser, T. Grote, B. Kaufmann, A. König, M. Ostrowski, and T. Schaub, “Conflict-driven disjunctive answer set solving,” in Proceedings of the 11th International Conference on PKRR,
G. Brewka and J. Lang, Eds. AAAI Press, 2008, pp. 422–432.

5176

2013 American Control Conference (ACC)
Washington, DC, USA, June 17-19, 2013

Computing Descent Direction of MTL Robustness for Non-Linear Systems
Houssam Abbas and Georgios Fainekos

Abstract— The automatic analysis of transient properties of
nonlinear dynamical systems is a challenging problem. The
problem is even more challenging when complex state-space
and timing requirements must be satisfied by the system. Such
complex requirements can be captured by Metric Temporal
Logic (MTL) specifications. The problem of finding system
behaviors that do not satisfy an MTL specification is referred
to as MTL falsification. This paper presents an approach for
improving stochastic MTL falsification methods by performing
local search in the set of initial conditions. In particular,
MTL robustness quantifies how correct or wrong is a system
trajectory with respect to an MTL specification. Positive values
indicate satisfaction of the property while negative values
indicate falsification. A stochastic falsification method attempts
to minimize the system’s robustness with respect to the MTL
property. Given some arbitrary initial state, this paper presents
a method to compute a descent direction in the set of initial
conditions, such that the new system trajectory gets closer to the
unsafe set of behaviors. This technique can be iterated in order
to converge to a local minimum of the robustness landscape.
The paper demonstrates the applicability of the method on
some challenging nonlinear systems from the literature.

I. I NTRODUCTION
A number of applications can only be accurately modeled
using nonlinear dynamical models. Typical such applications
include analog circuits [1]–[3] and biological and medical
systems [4]–[7]. A common theme of all the aforementioned
applications is the need to verify transient or periodic properties of the system. Such properties might involve sequencing
of events, conditional reachability and invariants and realtime constraints and can be formally captured using temporal
logics [4], [8].
Unfortunately, for complex nonlinear systems, these types
of properties are hard – if not impossible – to verify algorithmically. Therefore, recent research efforts have been invested
in property falsification methods [9]–[12]. In falsification,
the space of operating conditions and/or inputs is searched
in order to find an initial condition and/or parameter that
will force the system to exhibit an unsafe behavior with
respect to the formal requirement. In turn, the unsafe system
trajectory can be used in order to manually or automatically
modify the system to achieve the desired system behavior
and performance [13], [14].
In [10], [15], the temporal logic falsification problem
is converted into an optimization (minimization) problem
based on the notion of robustness of temporal logics [16].
Essentially, a system trajectory with negative robustness is
one that proves the existence of unsafe system behaviors.
This work was partially supported by the NSF awards CNS-1017074 and
CNS-1116136.
H. Abbas and G. Fainekos are with the Schools of Engineering at Arizona
State University, Tempe, AZ, E-mail: {hyabbas,fainekos}@asu.edu

978-1-4799-0178-4/$31.00 ©2013 AACC

Then, a number of stochastic optimization methods can be
utilized in order to solve the optimization problem and
find a system trajectory that minimizes the temporal logic
robustness metric.
However, in [10], [15], the system is treated as a blackbox. In order, to improve the rate of convergence of stochastic search methods, it is desirable to have techniques that
can compute local descent directions in the search space.
In particular, if a test is performed starting from an initial
condition x with property robustness f (x), then a descent
vector d must be computed so that starting from x + d the
system has robustness f (x + d) < f (x). Such a process
has the potential to speed up the stochastic search method
by enabling gradient descent in the search space. In [17],
we demonstrated that in the case of linear hybrid systems
improvements in the convergence rate can be achieved.
Contributions: In this paper, we present a method for the
computation of descent vectors for reducing specification
robustness for continuous nonlinear dynamical systems. In
particular, given an arbitrary Metric Temporal Logic (MTL)
specification [18], we determine a critical point on the system
trajectory which if changed, then the MTL robustness will
be changed as well. We utilize nonsmooth optimization
theory [19] in order to derive the equations that compute
a descent vector in the set of initial conditions that will
result in reduced MTL robustness. Finally, we demonstrate
the applicability of our approach on some nonlinear models
from the literature. We envision that our results can be
extended to handle arbitrary temporal logic specifications
over trajectories of hybrid systems.
Related Work: Combined state-space and real-time temporal logic properties have been studied in a number of
different settings. MTL properties of nonlinear systems have
been studied in [12] through abstractions to Linear Parameter Varying (LPV) systems. The work in [11] studies
the applicability of statistical model checking methods on
stochastic hybrid systems. The temporal logic falsification
problem can be viewed as a dual problem to the optimal
control problem under temporal logic requirements. In [20],
the optimal control problem under Linear Temporal Logic
(LTL) specifications is studied for mixed-logical discretetime linear dynamical systems. However, there do not exist any optimal control problem formulations for nonlinear
systems under MTL specifications.
The work that appears in [4] and [21] is the closest to the
results that we present here. In particular, in [21], the authors
use sensitivity analysis in order to quantify neighborhoods
of trajectories with the same qualitative behavior. Then, the
results of [21] are extended in [4] to estimating parameter

4405

ranges and initial conditions for which the system satisfies
some real-time temporal logic specification. Even though we
are also using sensitivity analysis in our problem solution,
our objective is very different from the work in [4]. Our
goal is to develop the local search tools needed in order
to improve the performance of stochastic MTL falsification
methods [10], [15]. Stochastic falsification methods avoid
the state-explosion problems that occur when attempting to
cover a high-dimensional set of parameters.
II. P ROBLEM F ORMULATION
We consider a dynamical system with state x ∈ X
ẋ = F (t, x)

(1)

for a C 1 flow F : Rn → Rn with initial conditions x0 ∈ X0 .
Assumption 2.1: For every x ∈ X0 and finite time T > 0,
there exists a unique solution s(·, x) : [0, T ] 7→ Rn to the
differential equation (1). Also, the solution sx (·) is absolutely
continuous. Finally, the flow F is locally bounded, that is,
for all compact sets [0, t] × C ⊂ [0, T ] × X0 , there exists
m > 0 such that F ([0, T ] × C) ⊂ mB, where B is the unit
ball centered at 0.
We formally capture specifications regarding the correct
system behavior using Metric Temporal Logic (MTL) [18].
MTL formulas are built over a set of propositions using
combinations of the traditional and temporal operators. In
this work, the set of atomic propositions AP label subsets of
the state space X. In other words, we define an observation
map O : AP → P(X) such that for each π ∈ AP the
corresponding set is O(π) ⊆ X. Here, P(S) denotes the
powerset of a set S. Traditional logic operators are the conjunction (∧), disjunction (∨), negation (¬), implication (→)
and equivalence (↔). Some of the temporal operators are
eventually (✸I ), always (✷I ) and until (UI ). The subscript
I imposes timing constraints on the temporal operators.
The interval I must be non-empty (I =
6 ∅). For example,
MTL can capture the requirement that “all the trajectories
x(t) ∈ R attain a value in the set [10, +∞)” (✸p1 with
O(p1 ) = [10, +∞)) or that “whenever the value of x drops
below 10, then it should go above 10 within 5 sec and remain
above 10 for at least 10 sec” (✷(¬p1 → ✸[0,5] ✷[0,10] p1 )).
We can quantify how robustly a system trajectory sx (t) =
s(t, x) satisfies a specification φ in MTL [16]. Namely, we
define a function fφ (x) that returns the radius of the largest
neighborhood we can fit around sx such that any trajectory in
that neighborhood satisfies the same MTL specification φ as
sx . Moreover, fφ (x) takes positive values if sx satisfies φ and
negative values otherwise. The falsification of specification
φ, i.e. detecting a system behavior that does not satisfy φ, can
thus be re-cast as the problem of finding initial states x ∈ X0
with negative fφ -values. This can be done using stochastic
search techniques [10], [15]. These can be improved by
computing local descent directions for fφ .
In this paper, our objective is to solve the following subproblem: Let U ⊂ X be a set of ‘unsafe’ system states - in
the next section we see exactly what such a U looks like.

There may be many such sets. We define the robustness of
a trajectory relative to U :
Definition 2.1 (Robustness): Let x ∈ X0 , T > 0 and sx (·)
be the unique solution of (1) starting from time 0, then the
robustness of the solution sx with respect to U is
f (x) = min dU (s(t; x))
0≤t≤T

(2)

where dU (x) = inf u∈U kx − uk is the distance function of a
point x from U .
The function f is non-differentiable, and generally nonconvex. Then, our problem is:
Problem 1: Given x ∈ X0 , T > 0 and the unsafe set U ,
find a vector d(x) ∈ Rn such that
f (x + hd(x)) < f (x) for all 0 < h < h
for some h > 0.
Although Problem 1 was defined for a single unsafe set,
Prop. 3.1 below shows that robustness w.r.t. a general MTL
formula (with several sets) equals the robustness w.r.t. one
of the formula’s atomic propositions (one of the sets).
Some proofs are omitted due to space constraints.
III. MTL ROBUSTNESS
In this section, we provide an informal review of the robust
semantics of MTL formulas. Formal details are available in
our previous work [16].
Definition 3.1 (MTL Syntax): Let AP be the set of atomic
propositions and I be any non-empty interval of R≥0 . The
set M T L of all well-formed MTL formulas is inductively
defined as ϕ ::= T | p | ¬ϕ | ϕ ∨ ϕ | ϕ UI ϕ, where
p ∈ AP and T is true.
The robust semantics maps an MTL formula ϕ and a
trajectory sx to a value drawn from R ∪ {±∞}. The semantics for the atomic propositions evaluated for sx (t) consists
of the distance between sx (t) and the set O(p) labeling
atomic proposition p. Intuitively, this distance represents how
robustly the point sx (t) lies within (or is outside) the set
O(p). If this distance is zero, then the smallest perturbation
of the point sx (t) can affect the outcome of sx (t) ∈ O(p).
The semantics for a formula are naturally defined from the
semantics for the atomic propositions. We denote the robust
valuation of the formula ϕ over the trajectory sx at time
t starting at initial condition x by [[ϕ, O]](sx , t). It is easy
to show [16] that if the signal satisfies the property, then
its robustness is non-negative, and if the signal does not
satisfy the property, then its robustness is non-positive. In [8],
we presented algorithms for efficiently computing the MTL
robustness of a discrete-time trajectory. The analysis can be
extended to continuous-time signals under some assumptions
on the system [16].
For computational reasons, we must impose additional
assumptions on the sets O(p):
Assumption 3.1: For each p ∈ AP , we have O(p) =
∩i {x ∈ Rn | ai · x ≤ bi } where ai ∈ Rn and bi ∈ R.
Under the assumption that (1) is well-behaved, there exist
at least one point in time t and an atomic proposition p such

4406

that the MTL robustness is equal to the distance of sx (t) from
O(p). The proof of the following proposition is based on the
assumption that the trajectory is continuous and bounded for
all time in [0, T ].
Proposition 3.1: Consider an MTL formula φ and a trajectory sx of (1) starting from some x ∈ X0 such that
[[φ, O]](sx , 0) > 0. If (1) satisfies Assumption 2.1, then there
exist tr ∈ [0, T ] and p ∈ AP such that
[[φ, O]](sx , 0) = Dist(sx (tr ), O(p))
where the signed distance Dist(z, S) = dS (z) if z ∈ S, and
−dS (z) otherwise. We remark that given a trajectory of (1),
then the sample of the trajectory that represents the critical
distance can be easily computed by modifying the algorithm
in [8].
In order to detect a bad system behavior with respect to
an MTL specification, our goal is to reduce such critical distances. Therefore, in the following, we focus on a particular
set O(p) or one of its defining half-spaces which we refer
to as the unsafe set U .
In general, φ may have several predicates p and corresponding sets O(p). To falsify φ will require finding a
trajectory that visits these O(p) in some order and under
some timing constraints. In this paper, we derive the descent
vector relative to only one O(p) at a time. Different unsafe
sets O(p) are chosen by the stochastic falsification algorithm,
which calls the local descent algorithm on the chosen unsafe
set.
IV. C OMPUTING A D ESCENT DIRECTION
In this section we compute a descent direction using
tools from nonsmooth analysis. We start by solving the
unconstrained problem X0 = Rn in sub-section IV-A. The
constrained problem is later addressed in sub-section IV-B.

where f o is the generalized directional derivative of f at x
f (y + hd) − f (y)
h
y→x,hց0
Theorem 4.3 ( 2.1.3(i) in [19]): Let g : Rn → be a
convex function with a Lipschitz constant K at x. Then,
the directional derivative in each direction v ∈ Rn exists
and satisfies
g(x + hv) − g(x)
g ′ (x; v) = inf
h>0
h
f o (x; d) = lim sup

In this section we will work from the definition of generalized derivative to derive a descent d such that f o (x; d) < 0.
By definition of robustness (2), we have
f (y + hd) − f (y)
h
y→x,hց0

= lim sup
min dU (s(t; y + hd))−
y→x,hց0 0≤t≤T

− min dU (s(t; y)) /h

f o (x; d) = lim sup

0≤t≤T

By definition of limit, there exists sequences (yi ) → x ∈
Rn and (hi ) → 0 ∈ R+ and i0 ∈ N such that, for i > i0 ,

f o (x; d) ≤ min dU (s(t; yi + hi d))
0≤t≤T


1
− min dU (s(t; yi )) hi +
0≤t≤T
i
It is easily seen that for positive functions g(t) and k(t),
mint g(t) − mint k(t) ≤ − mint [k(t) − g(t)]. Identifying
g(t) = dU (t; yi + hi d) and k(t) = dU (t; yi ), we have
f o (x; d) ≤
− min0≤t≤T [dU (s(t; yi )) − dU (s(t; yi + hi d))] 1
+
≤
hi
i
[dU (s(t; yi )) − dU (s(t; yi + hi d))] 1
= − min
+
0≤t≤T
hi
i

A. Descent vector
In general, two trajectories starting arbitrarily close may
achieve very different robustness values, at very different
points in time. The following theorem shows that for some
systems that are themselves ‘Lipschitz’ (in the sense below),
the objective function is Lipshitz:
Theorem 4.1 (Lipschitz objective): If for every x ∈ X0 ,
there exist b > 0 and Kx > 0 s.t. ks(t; x1 ) − s(t; x2 )k ≤
Kx kx1 − x2 k for all x1 , x2 ∈ Bb (x) and all 0 ≤ t ≤ T , then
the objective function f is Lipschitz.
The condition of the theorem can be shown to hold if we
assume F to be Lipschitz in x on [0, T ] × X, and X is open
connected. Moreover, the constant Kx is then independent
of x.
Nonsmooth analysis [19] provides us with the tools to
compute descent directions.
Theorem 4.2 (Thm. 5.2.5 in [19]): Let f : Rn → be
locally Lipschitz at x. The direction d ∈ Rn is a descent
direction at x if
f o (x; d) < 0

As i → ∞, 1/i → 0, hi → 0, yi → x and s(t; yi +hi d) →
s(t; yi ) in norm by Assumption 2.1. So
f o (x; d)


[dU (s(t; yi )) − dU (s(t; yi + hi d))]
− min
i→∞
0≤t≤T
hi
[dU (s(t; yi )) − dU (s(t; yi + hi d))] 1
= − min lim
+
0≤t≤T i→∞
hi
i
dU (s(t; yi + hi d)) − dU (s(t; yi ))]
= − min
lim
−
0≤t≤T yi →x,hi ց0
hi

≤ lim

(We can show that the interchange of limit and min above
is valid). Linearizing s(t; yi + hi d) in the second argument,
and ignoring higher-order terms o(hi ):
s(t; yi + hi d) ≈ s(t; yi ) + hi

∂s(t; yi )
d
∂y

(3)

Assumption 4.1: We assume that the sensitivity matrix
exists, is invertible, and that it is spectral
A(t; y) , ∂s(t;y)
∂y
norm-continuous in y.

4407

We remark that A(t; y) is the sensitivity of the trajectory
with respect to the initial conditions and can be computed
as indicated in [22], [23]. Then,
f o (x; d) ≤
≤ − min [−
0≤t≤T

lim

yi →x,hi ց0

(dU (s(t; yi ) + hi A(t; yi )d)−

− dU (s(t; yi )))/hi ]
If the limit in brackets does not exist, i.e., it is +∞, then
f o (x; d) < 0 and we are done. Otherwise, it can be shown
that the limit in brackets equals d′U (s(t; A(t; x)d): that is, the
directional derivative of dU at s(t; x) ∈ Rn , in the direction
A(t; x)d. Thus,
f o (x; d) ≤ − min[−d′U (s(t; x); A(t; x)d)]
= max d′U (s(t; x); A(t; x)d)
0≤t≤T

Recall that we want f o (x; d) < 0, so we seek to upperbound the RHS, that is,
max d′U (s(t; x); A(t; x)d) < 0,

0≤t≤T

which is equivalent to
d′U (s(t; x); A(t; x)d) < 0 ∀ t ∈ [0, T ]
Fix t for now. For ease of notation, we’ll just write s and
A for s(t; x) and A(t; x), respectively. By Theorem 4.3,
dU (s + h · Ad) − dU (s)
d′U (s; Ad) = inf
h>0
h
Thus, it is necessary that there exist an h > 0 s.t.

B. Constrained problem
We now remove Assumption (A3) and we consider the
constrained problem where X0 6= Rn . In other words, what
if x + d ∈
/ X0 ?
If we use µd, µ < 1, then
d′U (s(tr ; x); µ · ns(x) (tr )) =
dU (s(tr ; x) + hµ · ds(x) (t)) − dU (s(tr ; x))
<0
= inf
h>0
h
by Eq. (4). So we can shrink d to fit x + d in X0 , and still
have a descent. This simple approach circumvents the need
to calculate or approximate the subdifferential of f subject
to the constraints, which is a non-trivial task given the form
of f .
This brings up the issue of step-size: in principle, any
method for computing a step-size, that does not require differentiability, can be used, once we have a descent direction
(and indeed we use backtracking in our experiments); see
e.g. [19], [24], [25]. In practice, a method that does not
use a line-search is preferable, since line searches require
additional evaluations of the objective function, and this
implies simulating the system. Such simulations might prove
too costly. We will simply highlight two requirements on
any step-size that transpire from above arguments: that it
be “small enough” for the o(h) terms in (3) to be safely
ignored, and that it be smaller than the robustness dU (s(t; x))
as per (4). Additional, generic, conditions can be reviewed
in standard texts, such as [19, Section II.2.1.2].

dU (s + h · Ad) − dU (s) < 0

V. E XPERIMENTS

Let ns(x) (t) ∈ Rn be the vector that gives the direction of
the shortest distance between s(t; x) and U . We’ll write n
for short, and call it an approach vector. Then

Example 1: Our first example is 2-dimensional system
taken from [12] (Example 4), given by


0.05x1 (t) sin2 (x2 (t)) − 2.5x2 (t)
ẋ(t) =
0.5x1 (t) − x2 (t)

dU (s + hn) < dU (s) ∀ 0 < h ≤ dU (s) ⇒
(4)
dU (s + hn) − dU (s)
dU (s + hn) − dU (s)
<
<0
inf
h>0
h
h
So set A(t; x)d(t) = ns(x) (t) ⇒ d(t) = A(t; x)−1 ns(x) (t),
where we made explicit the dependence of the descent vector
on time (different points on the trajectory will have different
descent vectors). Thus, d(t) = A(t; x)−1 ns(x) (t) satisfies
d′U (s(t; x); A(t; x)d(t)) < 0 at every t. In particular at
t∗ , argmax0≤t≤T d′U (s(t; x); A(t; x)d(t)),
we still have
d′U (s(t∗ ; x); A(t∗ ; x)d(t∗ ) < 0
Finally,
d = A(t∗ ; x)−1 ns(x) (t∗ )

(5)

is a descent direction for f at x, subject to the foregoing
assumptions.
It remains to compute t∗ . We can show that t∗ =
argmin0≤t≤T dU (s(t; x)), and the proof is omitted.
We conclude this section by noting that Eq.(5) can be
generalized by choosing a different approach vector than
n, conditioned on satisfying (4). The particular choice will
depend on the geometry of the problem.

We present two representative experiments with this system, both using a trajectory duration of 10 time units,
the specification is ✷¬p1 with O(p1 ) = [−0.11, −0.08] ×
[0, 0.01] and x0 = (0.5, −0.2)T . First, we consider h = 1.
Fig.1 shows a sequence of starting points, and corresponding trajectories, generated by computing successive descent
vectors according to Eq. (5). Descents of different directions
are generated, and successive trajectories get closer to the
unsafe set as can be seen in Fig.2. Ten descent vectors reduce
robustness from 0.016097 to 0.011181.
Starting with h = 0.1, the iterations reach a local minimum after 4 descents - the d computed by Eq.(5) no longer
decreases the objective function value for any step-size. A
small ball around the current x0 was sampled to verify it is
indeed a local minimum.
△
Example 2: Our second example is taken from [15], given
by


x1 (t) − x2 (t) + 0.1t
ẋ(t) =
x2 (t) cos(2πx2 (t)) − x1 (t) sin(2πx1 (t)) + 0.1t
with initial condition x(0) = x0 ∈ X0 = [−1, 1] × [−1, 1],
and specification ✷¬p2 with O(p2 ) = [−1.6, −1.4] ×

4408

0.2

mally, the specification requires that if the system trajectory
is in O(p3 ) at time t1 , then O(p4 ) should be avoided for all
time in [t1 , t1 + 1]. For the specification to be falsified distances to both sets O(p3 ) and O(p4 ) must become zero. Note
that in Fig. 6, our algorithm attempts to minimize both distances. To rigorously assess the efficiency of SA+DESCENT
compared to pure SA, a thorough statistical study will be
conducted in future research.
△

0.15
0.1
0.05

x2

0
−0.05
−0.1
−0.15
−0.2

1

−0.25
4

−0.3
−0.2

0

0.2

0.4

0.6

1

0.5

0.8

3

x1

5
2
0
x2

Fig. 1. Inital set (bottom right), unsafe set (red (black) box in top left)
and trajectories for Example 1.

−0.5

0.02
−1

0.018

0.016

x2

−1.5
−2

−1.5

−1

−0.5

0

0.5

1

1.5

x1

0.014

Fig. 3. Transient trajectories of Example 2. Note the qualitative change in
the trajectories, from 1 to 5, as a result of descending towards the unsafe
set. Circles mark the initial points, and long black arrows are u∗ − s(t; x).

0.012

0.01

0.008
−0.13

−0.125

−0.12

−0.115

−0.11

−0.105

x1

Fig. 2.

0.8
0.75

Successive Example 1 trajectories descending towards unsafe set.

0.7

φ3 = ✷(p3 =⇒ ✷[0,1] ¬p4 )
where O(p3 ) and O(p4 ) are the dark boxes in Fig.6. Infor-

0.65

1.2

0.6
1.4
x2

[−0.9, −1.1]. If the trajectory duration is 6 units, allowing
the trajectories to settle, and starting from (0, 0)T , a local
minimum is reached in only 2 iterations. Inspection of the
descent direction lead us to try a start point x0 = (0.5, 0.5)T :
from here, robustness was reduced from 1.9 to 1.19 in
10 iterations, decreasing at every iteration. If the trajectory
duration is only 2 units, thus remaining in the transient mode,
we can see more clearly the effect of choosing a descent
direction: Fig.3 shows the unsafe set relative to the initial
set, and the trajectories chosen by descent.
To verify that this change in trajectory was not ‘accidental’
(e.g. as a result of the step-size leading to an entirely different
local min), but rather was driven by a genuine descent, we
plot the contour curves of the objective function (obtained by
sampling it on a grid of 500 points). Fig.4 shows a consistent
descent towards levels of decreasing robustness. As further
verification, we moved the unsafe set to [1.251.75]×[−1.1−
0.9]. Fig.5 shows the resulting trajectories chosen by descent.
In order to demonstrate the potential of the proposed
approach to the MTL falsification problem, we incorporated
the descent method with the Simulated Annealing (SA)
falsification method of [15]. We falsified the specification

0.55
2.4

0.5
0.45
0.4
1.6

2.2

0.35

2.0

1.8
0.3
0.15

0.2

0.25

0.3

0.35
x1

0.4

0.45

0.5

0.55

Fig. 4. Contour plot of f in Example 2, with initial points chosen by
descent.

Example 3: Our third example is the quorum sensing
system of the luminescent marine bacterium Vibrio Fischeri
(VF) [5]. This is modeled as a 9-dimensional non-linear
system. A simplified hybrid model of a mutant VF bacterium
has 2 equilibrium points (one luminescent, the other nonluminescent) [5]. We choose the unsafe set to be disjoint
from neighborhoods around these 2 equilibria. Namely, we
consider the specification ✷¬p2 with O(p5 ) = {x ∈
R9 | 13625 ≤ x3 ≤ 13626, 36330 ≤ x7 ≤ 36331, 17968 ≤
x8 ≤ 17969}. Starting from x0 = (1e5, 1, . . . , 1)T , and

4409

1

0.5

x2

0

−0.5

−1

−1.5
−1

−0.5

0

0.5

1

1.5

2

2.5

x1

Fig. 5.

Example 2 with a different unsafe set.

2

x2

1

0

−1

−2
−4

−2

0

2

4

6

8

10

x1

Fig. 6. Example 2 with φ3 . O(p3 ) is the left dark square, O(p4 ) is the
right dark square, X0 is the white rectangle.

computing trajectories of duration 5 units, 10 computations
of a descent vector with step size h = 0.1 reduce robustness
from 36327 to 14099, with robustness decreasing at each
iteration.
△
VI. C ONCLUSIONS
We have presented the derivation of the equations that can
be used for the computation of robustness descent vectors in
the set of initial conditions for nonlinear dynamical systems.
These results are necessary for enabling “gray box” MTL
falsification methods for dynamical systems. In the future, we
will focus on extending our new approach to hybrid systems
and non-autonomous systems.
R EFERENCES
[1] S. Steinhorst and L. Hedrich, “Model checking of analog systems using an analog specification language,” in Proceedings of the conference
on Design, automation and test in Europe, ser. DATE ’08. New York,
NY, USA: ACM, 2008, pp. 324–329.
[2] M. H. Zaki, S. Tahar, and G. Bois, “Formal verification of analog and
mixed-signal designs: A survey,” Microelectronics Journal, vol. 39, p.
13951404, 2008.
[3] S. Little, D. Walter, K. Jones, and C. J. Myers, “Analog/mixed-signal
circuit verification using models generated from simulation traces,”
in Proceedings of the 5th International Symposium on Automated
Technology for Verification and Analysis (ATVA), ser. LNCS, vol. 4762.
Springer, 2007, pp. 114–128.
[4] A. Donze, E. Fanchon, L. M. Gattepaille, O. Maler, and P. Tracqui,
“Robustness analysis and behavior discrimination in enzymatic reaction networks,” PLoS ONE, vol. 6, no. 9, p. e24246, 09 2011.
[5] C. Belta, J. Schug, T. Dang, V. Kumar, G. Pappas, and H. Rubin,
“Stability and rechability analysis of a hybrid model of luminescence
in the marine bacterium vibrio fischeri,” in Proceedings of the 40th
IEEE Conference on Decision and Control, December 2001.

[6] A. A. Julius, Á. M. Halász, M. S. Sakar, H. Rubin, V. Kumar, and G. J.
Pappas, “Stochastic modeling and control of biological systems: The
lactose regulation system of escherichia coli,” IEEE Trans. Automat.
Contr., vol. 53, pp. 51–65, 2008.
[7] S. Sankaranarayanan and G. Fainekos, “Simulating insulin infusion
pump risks by in-silico modeling of the insulin-glucose regulatory
system,” in International Conference on Computational Methods in
Systems Biology, 2012, [To Appear].
[8] G. Fainekos, S. Sankaranarayanan, K. Ueda, and H. Yazarel, “Verification of automotive control applications using s-taliro,” in Proceedings
of the American Control Conference, 2012.
[9] E. Plaku, L. E. Kavraki, and M. Y. Vardi, “Falsification of ltl safety
properties in hybrid systems,” in Proc. of the Conf. on Tools and
Algorithms for the Construction and Analysis of Systems (TACAS),
ser. LNCS, vol. 5505, 2009, pp. 368 – 382.
[10] T. Nghiem, S. Sankaranarayanan, G. Fainekos, F. Ivancic, A. Gupta,
and G. Pappas, “Monte-carlo techniques for falsification of temporal
properties of non-linear hybrid systems,” in Hybrid Systems: Computation and Control, 2010.
[11] P. Zuliani, A. Platzer, and E. M. Clarke, “Bayesian statistical model
checking with application to simulink/stateflow verification,” in Proceedings of the 13th ACM International Conference on Hybrid Systems: Computation and Control, 2010, pp. 243–252.
[12] G. E. Fainekos and G. J. Pappas, “Mtl robust testing and verification
for lpv systems,” in Proceedings of the American Control Conference,
2009, pp. 3748–3753.
[13] A. Rizk, G. Batt, F. Fages, and S. Soliman, “Continuous valuations of
temporal logic specifications with applications to parameter optimization and robustness measures,” Theor. Comput. Sci., vol. 412, no. 26,
pp. 2827–2839, 2011.
[14] A. Donze, G. Clermont, and C. J. Langmead, “Parameter synthesis in
nonlinear dynamical systems: Application to systems biology,” Journal
of Computational Biology, vol. 17, no. 3, pp. 325–336, 2010.
[15] H. Abbas, G. E. Fainekos, S. Sankaranarayanan, F. Ivancic, A. Gupta,
and G. J. Pappas, “Probabilistic temporal logic falsification of cyberphysical systems,” ACM Transactions on Embedded Computing Systems, vol. (Accepted), 2011.
[16] G. Fainekos and G. Pappas, “Robustness of temporal logic specifications for continuous-time signals,” Theoretical Computer Science, vol.
410, no. 42, pp. 4262–4291, September 2009.
[17] H. Abbas and G. Fainekos, “Linear hybrid system falsification through
local search,” in Automated Technology for Verification and Analysis,
ser. LNCS, vol. 6996. Springer, 2011, pp. 503–510.
[18] R. Koymans, “Specifying real-time properties with metric temporal
logic.” Real-Time Systems, vol. 2, no. 4, pp. 255–299, 1990.
[19] M. M. Makela and P. Neittaanmaki, Nonsmooth optimization. World
Scientific, 1992.
[20] S. Karaman, R. Sanfelice, and E. Frazzoli, “Optimal control of mixed
logical dynamical systems with linear temporal logic specifications,”
in IEEE Conf. on Decision and Control, 2008.
[21] A. Donze and O. Maler, “Systematic simulation using sensitivity
analysis,” in Hybrid Systems: Computation and Control, ser. LNCS,
vol. 4416. Springer, 2007, pp. 174–189.
[22] R. Serban and A. Hindmarsh, “Cvodes: the sensitivity-enabled ode
solver in sundials,” in Proceedings of IDETC/CIE, 2005.
[23] I. Hiskens and M. Pai, “Trajectory sensitivity analysis of hybrid systems,” Circuits and Systems I: Fundamental Theory and Applications,
IEEE Transactions on, vol. 47, no. 2, pp. 204 –220, feb 2000.
[24] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge
University Press, 2004.
[25] J. Goffin, “On convergence rates of subgradient optimization methods,”
Mathematical Programming, no. 13, pp. 329–347, 1977.

4410

Formal property verification in a conformance
testing framework
Houssam Abbas

Hans Mittelmann

Georgios Fainekos

School of Electrical, Energy and
Computer Engineering
Arizona State University
Tempe, AZ, U.S.A.
Email: hyabbas@asu.edu

School of Mathematical and
Statistical Sciences
Arizona State University
Tempe, AZ, U.S.A.
Email: mittelmann@asu.edu

School of Computing, Informatics and
Decision Systems
Arizona State University
Tempe, AZ, U.S.A.
Email: fainekos@asu.edu

Abstract—In model-based design of cyber-physical systems,
such as switched mixed-signal circuits or software-controlled
physical systems, it is common to develop a sequence of system
models of different fidelity and complexity, each appropriate for
a particular design or verification task. In such a sequence,
one model is often derived from the other by a process of
simplification or implementation. E.g. a Simulink model might
be implemented on an embedded processor via automatic code
generation. Three questions naturally present themselves: how
do we quantify closeness between the two systems? How can
we measure such closeness? If the original system satisfies some
formal property, can we automatically infer what properties are
then satisfied by the derived model? This paper addresses all
three questions: we quantify the closeness between original and
derived model via a distance measure between their outputs. We
then propose two computational methods for approximating this
closeness measure. Finally, we derive syntactical re-writing rules
which, when applied to a Metric Temporal Logic specification
satisfied by the original model, produce a formula satisfied by
the derived model. We demonstrate the soundness of the theory
with several experiments.

I.

I NTRODUCTION

In the last decade, systems which use embedded software to
control continuously changing physical phenomena have come
to be seen as ‘Cyber-Physical Systems’ (CPS), a category of
systems whose main characteristic is the interaction of continuous and discrete dynamics, possibly with communication
between remote components. This comes as a recognition that
verifying hardware separately from software, or the physical
separately from the cyber, is becoming less satisfactory as
the interactions between the two become richer and more
complicated, and as the design process needs to guarantee
extra-functional requirements [7], [31]. For example, the 2014
Toyota recall of 700,000 Prius vehicles was partly blamed
on the interaction between the controller software and the
transistors of the control board [36]. In a typical Model-Based
Design (MBD) process of CPS (see Fig. 1), a series of models
and implementations are iteratively developed such that the end
product satisfies a set of formal functional requirements Φ [11].
Ideally, the initial (simpler) model MS developed should be
amenable to formal synthesis and verification methods (cycle
1 in Fig. 1) through tools like [17], [34]. Then, the fidelity of
the models is increased by modeling more complex physical
phenomena ignored initially, by taking into account nonfunctional requirements like power consumption, and by mod-

978-1-4799-5338-7/14/$31.00 ©2014 IEEE

155

eling inaccuracies introduced by the real-time computational
platforms such as look-up-tables, time delays, clock drift, a
different computation precision, etc. This yields successively
more complex models MC (cycle 2 in Fig. 1). Afterwards,
the model MC is implemented on a computational platform
to yield the prototype Si ; Si is then manually modified and
calibrated into a final deployment system Sd . Finally, if the
system is deployed over a communication network, the network will introduce a whole range of issues related to random
transmission quality and delayed actuation and sensing. A
similar process in the Model-Based Design of Systems-on-aChip (SoCs) is outlined in [40].
Each of these transformations and calibrations introduces
discrepancies between the behavior of the original system,
which we generically refer to as the nominal system M,
and the behavior of the derived system that is produced,
which we generically refer to as the derived system I. These
discrepancies are spatial (e.g. slightly different signal values
in response to same stimulus, dropped samples, out-of-order
samples) and temporal (e.g. different timing characteristics
of the outputs, delayed responses due to unmodeled physical
phenomena like transport delay), and their magnitude can
vary as time progresses. The same situation arises when I
is derived from M by a process of simplification: e.g. in
Model Order Reduction (MOR), modeling from first physics
principles yields a high-dimensional dynamical system M,
which takes a long time to simulate. This is then reduced to
a lower-dimensional (‘lower order’) system I, which is used
to perform fast simulations where appropriate. Along the V
process in Fig. 1, a simplifying derivation process can be seen
as traversing the left branch of the V in the reverse direction
from bottom to top. This raises two questions:
•

First, what is the relationship between the behaviors
of the “nominal” model M and “derived” model I
(e.g. cycles 2 and 3 in Fig. 1)? Can it be quantified?

•

Second, if the simpler of the two systems M and
I has been formally verified to satisfy some specification, can anything be said automatically about the
specifications satisfied by the more complicated one?

If the simpler model, say M, was nondeterministic and
the structure of I was fully known, then the answer to
both questions could be established through behavioral inclusions, i.e., is it true that every behavior of I can be

Simple Model
Ms

1

2

Complex Model
Mc

derived I, given the formal specification satisfied by the
nominal M.
3) We argue that conformance testing can significantly alleviate the verification burden by allowing us to re-use
previous testing results when the specification changes.
4) We explore the use of alternative algorithms for approximating the conformance degree between two systems in
Section IV. Specifically, we explore the use of Rapidlyexploring Random Trees for arbitrary controllable systems, and the use of state-of-the-art commercial solvers
for the restricted class of switched linear systems.

Calibration and
Deployment Sd

4

Specifications

3

3

Implementation
Si (HIL)

Automatic Code
Generation

Fig. 1: Typical V process in MBD. (1) Verifying that the simple
model satisfies the functional requirements; (2) Establishing
a relationship between the simple and complex model; (3)
Verifying conformance of implementation to the model; (4)
Checking that the end product satisfies the functional requirements. Most of these steps are iterative.
exhibited by M, in response to the same stimulus? However,
in practice, non-deterministic models are rarely utilized and
supported by industry tools for MBD such as LabViewT M ,
Simulink/StateflowT M , or SpiceT M . Moroever, irrespective of
whether the derivation process has formal guarantees (such as
automatic code generation in [5]), rarely do the models capture
accurately all physical phenomena, so that inclusion is unlikely
to hold in a realistic scenario. Similar difficulties with formal
methods arising from having multiple models were outlined
by [8]. Thus, in lieu of behavioral inclusion, an appropriate
quantifiable notion of closeness between the systems behaviors
is required, and this is introduced in Section II-B. If system
I lent itself to formal methods, then the second question
could also be answered by formal verification. For example in
[30], a method for checking formal equivalence of a Simulink
model to its generated C code is presented. However, it is not
always possible to verify formally that I satisfies the formal
specification: for example, a component purchased from a third
party might allow only limited observability and not lend itself
to formal methods. Or, system I might be too large to handle
by today’s formal tools. By evaluating closeness between the
systems’ behaviors, on the other hand, it is possible to draw
conclusions about one from studying the behavior of the other:
this is presented in Section III.
In previous work [2], [3], closeness between two output
signals of two systems was mathematically formalized via
the notion of (T, J, (τ, ε))-closeness (Def. 2.2). This closeness
measure quantitatively captures distances between two signals
in both space and time, while allowing for samples from
either signal to be dropped, and for signal values to be locally
re-ordered. The conformance degree between two systems
M and I was then defined via the closeness between their
output signals, and conformance testing is then the process of
calculating the conformance degree between the two systems,
which was done by Simulated Annealing. In this paper, using
the formalism of hybrid dynamical systems, we extend that
work in four directions:
1) We refine the definition of conformance degree in Section
II-B to reflect the two broad categories of derivation
processes: simplification and implementation.
2) We give an automatic procedure in Section III for deriving
a formal specification (over hybrid time) satisfied by the

156

Experiments (Section V) and a review of related work in the
literature (Section VI) conclude the paper. All proofs are in
the online technical report [4].
Notation. Given an n-tuple α = (a1 , a2 , . . . an ), we denote
by pri (α) the i-th element of the tuple, i.e., pri (α) = ai .
Similarly, we let pri,j (α) = (ai , aj ). Given a relation R ⊂
A × B, and b ∈ B, we also define prb (R) = {a ∈ A : (a, b) ∈
R}. The set of integers is Z, of non-negative integers is N,
N>0 = N \ {0}, and the set of non-negative reals is R+ . For
N ∈ N, [N ] is the set {0, . . . , N }. For reals a and b, we write
a ∨ b = max{a, b} and a ∧ b = min{a, b}. For x ∈ Rn , kxk
is the Euclidian norm (though any norm will do). Finally, #S
is the cardinality of set S.
II.

C ONFORMANCE OF SYSTEMS

A. System Model
In this paper, we deal with embedded control systems.
Such systems typically have certain ‘modes’ of operation, and
the dynamics are generally different between the modes. For
example, a switched power converter is a common electronic
component with one switch. Depending on the switch’s position, the circuit can be in one of two modes, with different
dynamics depending on the active circuit elements [32]. Jumps
between modes are modeled to be instantaneous. To model
such systems, we adopt the hybrid systems formalism. Hybrid systems include as special cases Extended FSMs [16],
switched, impulsive and classical nonlinear and linear dynamical systems, and have been used extensively to model
embedded control systems. Specifically, let H ⊂ Rn be the
state space, C and D be subsets of H, U be a set of input
values, and F , G, and h be functions defined over H. The
hybrid dynamical system H with data C, F, D, G, h, internal
state η ∈ H and output y ∈ Y is governed by (η̇ is the time
derivative of η) [21]
(
η̇
= F (η, u)
(η, u) ∈ C
(η, u) ∈ D
(1)
H η + = G(η, u)
y
= h(η)
η∈H
The discrete mode can be part of the state variable η, e.g.
η = [x, `], where ` takes values in a finite set L, and x is
the real-valued state of the system (e.g. voltage). In this case,
`˙ = 0. The ‘jump’ map G models the change in system state
at a mode change, or ‘jump’, and the jump set D captures
the conditions causing a jump. The ‘flow’ map F models
state evolution away from jumps, while (η, u) is in the flow
set C. System trajectories start from a specified set of initial
conditions H0 ⊂ H. Finally, the output of the system y ∈ Y
is given as a function h of its internal state, and its input is

1

20
15

Implementation
Model

0.9

10
5

0.8

x1

0

0.7

−5
−10

0.6

−15

λ

−20
8

0.5

7

0.4

6
5
4

0.3
3
2
1

j

0
0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

−3

0.2
0.1

x 10
t

Fig. 2: Hybrid-TS for a 2-mode DC-to-DC buck-boost converter [32]. The red circles show hybrid time evolution
pr2,3 (µ) (each circle corresponds to a value (t(i), j(i)), while
the crosses show the value of pr1 (µ) (each cross corresponds
to y(i)). Perspective distortion causes the circles to be misaligned along the j-axis. With every mode switch (‘jump’),
the j parameter increments by 1. Between jumps, the system
evolves along the t axis as time progresses.

given by u which takes values in a set U . This is common
hybrid systems terminology.
The trajectories (or ‘solutions’ or ‘traces’) of purely
continuous-time dynamical systems (with only one mode) are
parameterized by the time variable t, and those of purely
discrete-time dynamical systems (with no continuous evolutions) are parametrized by the number of discrete jumps j.
Following Goebel and Teel [22], the trajectories of hybrid
systems are parameterized by both t and j, to reflect that both
evolution mechanisms are present. (For example, this describes
the view of time for SoC verification in [18]). The resulting
time structure is referred to as ‘hybrid time’. Hybrid time is
better suited to capture phenomena unique to the modeling
of hybrid systems, like Zeno executions [25], and to study
issues related to composition of hybrid systems [37]. See
also [21, Ch. 2] and references therein. We further consider
that the outputs of a dynamical system are first sampled (or, in
simulation, a numerical integrator generates a solution) before
being fed to a controller. Thus, we model the outputs of
a hybrid system as hybrid-timed sequences. Specifically, let
N ∈ N>0 be a positive integer and T ∈ R+ be a positive real.
Definition 2.1: Given a set Y , a Y -valued hybrid-timed
sequence (hybrid-TS or simply TS) is a function µ :
{0, 1, . . . , N } → Y × [0, T ] × N, such that for all i ∈
{0, 1, . . . , N }, pr2,3 (µ(i)) = (t(i), j(i)) with t(0) = j(0) =
0, t(i) ≤ t(i + 1) and j(i) ≤ j(i + 1), t(i) = t(i + 1) =⇒
j(i) < j(i + 1) and j(i) = j(i + 1) =⇒ t(i) < t(i + 1). The
domain of µ is dom(µ) = {0, 1, . . . , N } = [N ].

0

0

0.5

1

1.5

2

2.5
t

3

3.5

4

4.5

5

Fig. 3: The 1st component pr1 (µ) of an output TS of a fuel
control system model M and its implementation I. For each
i ∈ dom(µ), pr1 (µ(i)) is a 2D vector (λ, F uel).
TS µ, which we note as µ = H(η, u). The TS µ can be the
result of a sampling process or a numerical integration. Then
the sequence of ‘timestamps’ pr2,3 (µ) represents the sequence
of (hybrid) sampling times, or times at which a numerical
solution is computed: pr1 (µ(i)) is the value of the output at
(hybrid) time pr2,3 (µ(i)). We do not assume, in general, that
the sampling period (or integration step) is constant. Note that
two output TS of the same system may have different domains.
We refer the reader to [22] for exact definitions of discrete and
hybrid time domains, arcs and trajectories.
Assumption 2.1: We assume that when system I is derived
(by some application-dependent process) from M, there exists
a surjective and left-total relation R ⊂ H0,M × H0,I relating
the initial states of the two systems. This is commonly true in
practice to enable testing; we will say ‘I is derived from M
with relation R’. The output space Y is assumed equipped
with a metric d. Finally, for every initial condition η0 ∈ H0
and input TS u, the system H produces at least one output
TS. This is imposed to avoid modeling issues where either
system’s equations have no solutions.
B. Conformance via (T, J, (τ, ε))-closeness
In this section, we introduce the (T, J, (τ, ε))-closeness
measure between the output TS of hybrid systems in time and
space. It is derived from [22].

For a TS µ, the first component, i.e., pr1 (µ) = y captures
the output of the system, while the second and third components, i.e., pr2,3 (µ) = (t, j), capture the absolute time t and
the number of jumps j that led to the state y. See Fig. 2.
Together, (t, j) are referred to as ‘hybrid time’. Most of the
time, the set Y will be clear from the context.

Definition 2.2 ((T, J, (τ, ε))-closeness): Take a test duration T ∈ R+ , a maximum number of jumps J ∈ N, and
parameters τ, ε > 0. Two timed sequences µ = (y, t, j) and
µ0 = (y 0 , t0 , j 0 ) with domains [N ] and [N 0 ], respectively, are
(T, J, (τ, ε))-close, which we write µ ≈(τ,ε) µ0 , if
(a) for all i ∈ [N ] such that t(i) ≤ T, j(i) ≤ J, there exists
k ∈ [N 0 ] such that j(i) = j 0 (k), |t(i) − t0 (k)| < τ , and
ky(i) − y 0 (k)k < ε
(b) for all i ∈ [N 0 ] such that t0 (i) ≤ T, j 0 (i) ≤ J, there
exists k ∈ [N ] such that j 0 (i) = j(k), |t0 (i) − t(k)| < τ , and
ky 0 (i) − y(k)k < ε
The infimum of all ε such that µ and µ0 are (T, J, (τ, ε))-close
is called the achievable closeness degree given τ .

Given an initial state η ∈ H0 and an input TS u (which is
a U -valued TS), the system H produces an output Y -valued

(T, J, (τ, ε))-closeness may be thought of as giving a proximity measure between the two hybrid-timed sequences, both

157

in time and space. Allowing some ‘wiggle room’ in both
time and space is important for conformance testing: e.g. in
Fig. 3, intuitively, the two output signals are very similar,
yet the sup norm would give a large value to the distance
between them. Thus (T, J, (τ, ε))-closeness captures nicely
the intuitive notion that ‘the outputs should still look alike’.
The two values T and J limit our testing horizon, and will
typically be set based on application domain considerations.
When they are clear from the context, we will drop them to
simplify the language.
Finally, Def. 2.2 requires equality in the number of jumps
j between the two TS, but the results of this paper can be
extended in a straightforward manner to allow some wiggle in
the numbers of jumps, i.e. |j(i) − j 0 (k)| < δ.
Definition 2.3: Let H1 and H2 be two hybrid systems,
such that H2 is derived from H1 with relation R ⊂ H0,1 ×
H0,2 . Take a test duration T ∈ R+ , a maximum number
of jumps J ∈ N, and parameters τ, ε > 0. We say that
system H2 simulates H1 with precision (τ, ε), which is
written H1 τ,ε H2 , if for all (η1 , u) ∈ H0,1 × U, and for
all µ1 = H1 (η1 , u), there exists η2 ∈ H0,2 s.t. (η1 , η2 ) ∈ R
and for some µ2 = H2 (η2 , u), µ1 ≈(τ,ε) µ2 .
This definition is near-identical to that of approximate simulation given in [26, Def. 2.6]. The subtle but important
differences due to our setting are that : 1) the relation R
between initial sets does not arise here as a result of the
approximation by (τ, ε)-closeness, rather it is dictated by the
derivation process from M to I. This bounds the quality of
the approximation. 2) Whereas in [26], R is required to be lefttotal only, here we require R to be surjective as well. This again
is dictated by the derivation process. Modulo this distinction,
our work fits within the approximate bisimulation framework
presented in [26]. Therefore, we use the same terminology
(‘simulation’) and notation.
From a conformance perspective, it is preferable to have
a smaller ε and a smaller τ . Since only a partial order exists
on the (τ, ε) pairs, we define ‘partial’ conformance degrees
between systems.
Definition 2.4: Let H1 and H2 be two hybrid systems. The
conformance degree of H1 to H2 given τ is defined as the
smallest ε such that H1 τ,ε H2 :
CDτ (H1 , H2 ) := inf{ε : H1 τ,ε H2 }
An obvious analogous definition holds for conformance degree
given ε. Thereafter, we will always be referring to the conformance degree given τ and drop ‘given τ ’ from the terminology.
Note that because the conformance degree is defined using
the output behaviors of the systems, and not their internal
structures, observability limitations on either I or M do not
affect our ability to compute it.
Example 1 (Power converters): Power converters are common electronic components, used in many safety-critical systems. A DC-to-DC converter accepts an input DC voltage Vs
and converts it to a reference Vref . It has two modes, and
the switch between them is software-controlled [32]. We use
a simplified model of a power converter as a hybrid system in
Section V, and use this model to compute the (τ, ε)-closeness
between a model and its implementation.


158

Example 2 (Implementation process): A controller is developed for an automatic transmission model in Simulink.
Controller code is then automatically generated by Simulink,
targeting a given computational platform, like an embedded
board. Because the board has different computation precision
than the general-purpose host on which the model was verified,
and because Hardware-In-the-Loop testing introduces delays
and unmodeled interrupts, the generated code+automatic transmission closed-loop system (I) will produce outputs that are
different from the Simulink model+automatic transmission
(M). Conformance testing is needed to quantify the discrepancy between the two systems, and to derive what specification
is satisfied by I, given that M satisfies its specification. 
In all the above scenarios, we wish to test the simplified
system, say, I, rather than the costly system, say, M. In
particular, if we check that I satisfies some property ϕ (which
we can do relatively cheaply), we wish to automatically derive
a corresponding formula satisfied by M, without checking it
explicitly (which might not be possible). The result from the
next section allows us to do so, if we know the conformance
degree of I to M.
C. Local disorder in (T, J, (τ, ε))-close signals
A distinguishing feature of (T, J, (τ, ε))-closeness as a
measure of closeness between TS is that it allows for local
disorder in the signal values: i.e. given two TS µ = (y, t, j)
and µ0 = (y 0 , t0 , j 0 ) define the relation ρ ⊂ [N ] × [N 0 ] by
(i, i0 ) ∈ ρ iff ky(i) − y 0 (i0 )k < ε, |t(i) − t0 (i0 )| < τ and
j(i) = j 0 (i0 ). Then there may exist (i, i0 ) ∈ ρ and (k, k 0 ) ∈ ρ
with i < k and i0 > k 0 . Figure 4 (top) gives a generic
illustration of such a case.
We should note that all four points i, i0 , k, k 0 must occur
within a window of size τ , which is why we call this local disorder. The pattern of Fig. 4 (top) can not repeat in consecutive
windows of width τ : as shown in Fig. 4 (bottom), consecutive
repetitions (indicated by the brackets) actually yield two TS
whose values (pr1 (µ)) are merely shifted with respect to each
other, as indicated by the arrows relating ρ-related samples.
Local disorder could arise in any situation where the output
signal pr1 (µ) of the system is distorted by noise. E.g. if the
model M of an electric circuit produces a noise-free µ, its
implentation I will in general suffer from parasitics and other
noise sources. More generally, recall that signal values (i.e.
pr1 (µ)) are real-valued outputs of the system, and not simply
discrete ‘events’ whose order must be preserved. A priori, and
without further defining the derivation process, there is no
reason to assume that a valid derivation will preserve signal
values order locally, even if globally, the nominal and derived
system have similar outputs. A notion of closeness between
real-valued outputs, therefore, should a priori account for (and
quantify) local disorder. Thus, by allowing local disorder,
(T, J, (τ, ε))-closeness is well-adapted to a wider class of
implementations and distortions than the measures surveyed
in the literature (Section VI).
The above discussion has a consequence for the design
process where M is implemented as I, and I is deployed:
if we calculate the conformance degree CDτ (H1 , H2 ) given
some τ > 0, we are effectively saying that local disorder within
a τ window is permissible, and should be quantified, rather

A. MTL for Hybrid Timed State Sequences

0.15
y
y’

ε

0.1

0.05

0

−0.05

ε

−0.1

−0.15

−0.2

τ
0

1

2

3
t

4

5

6

0.15
y
y’

In order to introduce the MTL-based design framework
in Section III, we now briefly go over the definition of
Metric Temporal Logic (MTL) [29]. MTL is a temporal logic
for expressing real-time properties of embedded and cyberphysical systems, and allows the specification of constraints on
the timing of events. In this section, we present an extension
of MTL over hybrid time. In a hybrid time domain, the time
variable takes values in T = [0, T ]×{0, . . . , J}. This extension
naturally subsumes the case of real-valued time. A hybrid time
set is a non-empty set of the form I = Ec × Ed ⊂ R × N,
where Ec is an interval in R and Ed is a set of successive
integers. Given the hybrid time (s, j) ∈ R × N, (s, j) ⊕ I :=
{(s0 , j 0 ) | ∃(s̄, j̄) ∈ I . s0 = s + s̄ and j 0 = j + j̄}. This is
itself a hybrid time set.
Definition 3.1 (MTL+ Syntax): Let AP be a set of atomic
propositions and I be a hybrid time set. The set M T L+ of
all well-formed MTL formulas in negation normal form is
inductively defined as ϕ := > | ⊥ | p | ¬p | ϕ ∨ ϕ | ϕ ∧
ϕ | ϕ UI ϕ | ϕRI ϕ, where p ∈ AP , > is true and ⊥ is false.

0.1

0.05

0

−0.05

−0.1

−0.15

−0.2

0

2

4

6

8

10

12

t

Fig. 4: Top: local disorder. The squares indicate elements of the
(τ, ε)-close TS, the continuous plots are only there to show the
subtending sampled signals. Samples related by ρ are related
graphically by arrows. Bottom: local disorder only lasts for an
interval of τ .
than flagged as an error. This makes design sense only if the
temporal logic specification according to which M is designed
contains timing intervals of width at least τ . In the next section,
we further quantify the relation between satisfied properties
and conformance degree.
III.

T RANSFER OF PROPERTIES

In Model-Based Design (MBD), the model M is designed
in an iterative fashion to satisfy a certain specification ϕ. In
this work our focus is exclusively on formal specifications expressed in Metric Temporal Logic (MTL) (see Section III-A).
When moving from Model testing to Implementation testing,
the main question is: despite the inaccuracies introduced by
the implementation process, does my Implementation I still
satisfy the specification ϕ?
As mentioned in the Introduction, often, it might not be
possible to formally verify ϕ on the more complex of the two
systems, say M. For all these reasons, our confidence in the
more complex system must derive from two things: the fact
that I satisfies ϕ; and that the two systems M and I have
‘close’ behaviors. In this section, we formalize the relation
between closeness of behaviors and formula satisfiability by
deriving, automatically, which formulae are satsified by a TS µ0
which is (τ, ε)-close to a TS µ, given that the latter satisfies ϕ.
Note that this does not require any testing of µ0 : the formulae
are derived automatically via syntactic manipulations.

159

We instantiate the definitions of the semantics over abstractions of the output TS of the hybrid system H with respect to
the sets O(p) ⊆ Y for all p ∈ AP . Let (µ, i) |=O ϕ denote
the satisfaction of the MTL formula ϕ over a TS µ starting
at sample i with respect to the atomic proposition-mapping
O. If µ does not satisfy ϕ under the map O, then we write
(µ, i) 6|=O ϕ.
Definition 3.2 (MTL+ Semantics): Let µ be a TS and O :
AP → P(Y ). For i, k, l ∈ N, the semantics of any M T L+
formula ϕ can be recursively defined as:
(µ, i) |=O > and (µ, i) 6|=O ⊥
(µ, i) |=O p iff pr1 (µ(i)) ∈ O(p)
(µ, i) |=O ¬p iff pr1 (µ(i)) 6∈ O(p)
(µ, i) |=O ϕ1 ∨ ϕ2 iff (µ, i) |=O ϕ1 or (µ, i) |=O ϕ2
(µ, i) |=O ϕ1 ∧ ϕ2 iff (µ, i) |=O ϕ1 and (µ, i) |=O ϕ2
(µ, i) |=O ϕ1 UI ϕ2 iff ∃k ≥ i such that
pr2,3 (µ(k)) ∈ pr2,3 (µ(i)) ⊕ I and (µ, k) |=O ϕ2
and ∀l with i ≤ l < k we have (µ, l) |=O ϕ1
(µ, i) |=O ϕ1 RI ϕ2 iff ∀k ≥ i,
pr2,3 (µ(k)) ∈ pr2,3 (µ(i)) ⊕ I implies (µ, k) |=O ϕ2
or ∃l with i ≤ l < k such that (µ, l) |=O ϕ1
Other operators can be defined using the above, e.g. the
Eventually operator 3I ϕ := >UI ϕ and the Always operator
I ϕ := ⊥RI ϕ. The usual MTL+ logic over real time is
recovered by choosing all hybrid time sets to be I = Ec × N.
B. Property transfer
Given a set S ⊂ Rn equipped with a metric d, P(S) is the
set of subsets of S. Its δ-expansion E(S, δ) and δ-contraction
C(S, δ) are defined by: E(S, δ) = {x ∈ Rn | inf s∈S d(x, s) ≤
δ} and C(S, δ) = Rn \ E(Rn \ S, δ). Finally, for a hybrid time
set I = Ec × Ed and reals a, b, define Iha,bi := (inf Ec +
a, sup Ec + b) × Ed , where inf and sup are the greatest lower
bound, and least upper bound, operators, respectively.

Theorem 1: Let ϕ be an M T L+ formula with atomic
propositions in AP and O : AP → P(Y ). Let µ = (y, t, j),
µ0 = (y 0 , t0 , j 0 ) be two TS such that µ ≈(τ,ε) µ0 . If (µ, i) |=O ϕ
then for all i0 ∈ dom(µ0 ) s.t. |t0 (i0 ) − t(i)| ≤ τ , j(i) = j 0 (i0 ),
and ky(i) − y 0 (i0 )k ≤ ε,
(µ0 , i0 ) |=Oε [ϕ]τ

M, and whether it equals ϕs . Thus in this case, we identify
H1 = M and H2 = I in Thm. 2. If, as often happens, a
new specification becomes relevant, then instead of testing
the expensive M, we may simply test I, and use Thm. 2 to
conclude the specification satisfied by M. Thus conformance
testing is a one-time cost (as long as M isn’t modified), which
reduces the testing effort when specifications change.

where the operator [·]τ : M T L+ → M T L+ obeys the
following rules:
[>]τ = > ,
[p]τ = p+ ,
[ϕ1 ∨ ϕ2 ]τ =
[ϕ1 ∧ ϕ2 ]τ =
[ϕ1 UI ϕ2 ]τ =
[ϕ1 RI ϕ2 ]τ

[⊥]τ = ⊥
[¬p]τ = p−
[ϕ1 ]τ ∨ [ϕ2 ]τ
[ϕ1 ]τ ∧ [ϕ2 ]τ
(3(−2τ,0]×{0} [ϕ1 ]τ )
UIh−2τ,2τ i (3[0,2τ )×{0} [ϕ2 ]τ )
= (3(−2τ,0]×{0} [ϕ1 ]τ )
RIh2τ,−2τ i (3[0,2τ )×{0} [ϕ2 ]τ )

where I = Ec × Ed is a hybrid time set. Also, Oε (p+ ) =
E(O(p), ε) and Oε (p− ) = C(O(p), ε).
The proof is in the technical report [4]. The results of [24]
and [35] can now be recovered as special cases of the above
theorem. The result of [24] is a special case of Thm. 1 where
only time is allowed to deviate (ε = 0). The result of [35]
requires an order-preserving notion of closeness (which it calls
“order-preserving ε-retiming”). Both operate over real time,
rather than hybrid time, which is more suitable for the study
of hybrid systems. To illustrate the content of Thm. 1, we give
two examples:
[[3,6]×{1,2} p]τ

[3I ϕ]τ

=
=
=
=
=

[⊥RI p]τ
3(−2τ,0] ⊥R[3+2τ,6−2τ ]×{1,2} 3[0,2τ ) p+
⊥R[3+2τ,6−2τ ]×{1,2} 3[0,2τ ) p+
Ih−2τ,2τ i (3[0,2τ ) [p]τ )
3Ih−2τ,4τ i [ϕ]τ

The main result of this section now follows from the definitions
and Thm. 1, and its proof is in [4]. For a hybrid system H and
a map O : AP → P(H), we write Hτ |=O ϕ, if for all output
TS µ of H, there exists i ∈ dom(µ) s.t. pr2 (µ(i)) ≤ τ and
(µ, i) |=O ϕ. We simply write H |=O ϕ if H0 |=O ϕ.
Theorem 2: Let H1 and H2 be two hybrid systems, and ϕ
be an M T L+ formula. If H1 τ,ε H2 and H2 |=O ϕ, then
H1τ |=Oε [ϕ]τ .
The theorem may be interpreted informally as saying that
system H1 needs an ‘initialization phase’, of duration at most
τ , before it satisfies [ϕ]τ . The role played by the Eventually
operators with negative time intervals appearing in [ϕ1 UI ϕ2 ]τ
and [ϕ1 RI ϕ2 ]τ of Thm. 1 also becomes clear: they serve to
cover this initialization phase.
If, say, M is what ultimately gets deployed (or is input
to the next phase of the design cycle), and I is derived from
M by a simplification for testing purposes (e.g. model order
reduction), then we care about M verifying the specification
ϕs , but we want to do the testing on I since it is simpler. We
then use Thm. 2 to derive the specification [ϕp ]τ satsisfied by

160

IV.

C OMPUTING THE CONFORMANCE DEGREE

In this section we treat the problem of computing the
conformance degree given in Def. 2.4. Conformance testing
is the process of finding two trajectories µ1 and µ2 , of H1
and H2 respectively, such that they achieve (τ, CDτ (H1 , H2 ))closeness. The result can be used in two ways: first, the
conformance degree is needed to apply the property transfer
results of the previous section. Secondly, µ1 and µ2 can be
used to debug a derivation process: suppose M and I were
designed to achieve a certain (τ, ε). If conformance testing
yields an achievable degree (τ, ε0 ) with ε0 > ε, i.e. the
true distance is greater than what was designed for, then the
‘witness’ TS µ1 and µ2 act as debugging traces to detect where
the behavior was erroneous, and therefore what needs to be
fixed in the derivation process. The details of such debugging
are naturally application-dependent.
The value CDτ (H1 , H2 ) is computed in stages. For two
TS µ = (y, t, j) and µ0 = (y 0 , t0 , j 0 ), define
cd(µ, µ0 ) := max{cd1 (µ, µ0 ), cd1 (µ0 , µ)}
where
cd1 (µ, µ0 ) =

max

min

i∈dom(µ) i0 ∈dom(µ0 ):
j(i)=j 0 (i0 )
|t(i)−t0 (i0 )|<τ

ky(i) − y 0 (i0 )k

Note that cd is symmetric. Then, given two hybrid systems
related by R, CDτ (H1 , H2 ) is calculated as
CDτ (H1 , H2 )

=

sup{cd(H1 (η1 , u), H2 (η2 , u)) :
η1 ∈ H0,1 , u ∈ U, η2 ∈ H0,2 ∩ prη1 (R)}

This dynamically-constrained optimization can be seen to be
nonsmooth, nonlinear and indeed in general nonconvex. Its
format does not satisfy the principle of optimality because of
the max operators and so it does not lend itself to dynamic
programming. It doesn’t take the form of an integrated or
final cost, and so is not readily amenable to optimal control
methods. In our previous work [3], due to these complexities,
we adopted Simulated Annealing (SA) as a general-purpose,
derivative-free, stochastic global optimizer. We will next develop the computation of CDτ (H1 , H2 ) in two directions:
by the use of an adapted Rapidly-exploring Random Trees
(RRTs) [13], and by computing an upper bound in the case of
switched linear systems, which we derive now.
Let z be a symbol denoting a pair of TS: z = (µ1 , µ2 ) ∈ Z,
Z

=

{(µ1 , µ2 ) : µ2 = H2 (η2 , u), µ1 = H1 (η1 , u)
s.t. (η1 , u) ∈ H0,1 × U, η2 ∈ H0,2 ∩ prη1 (R)}

Noting that CDτ (H1 , H2 ) = supz∈Z cd1 (µ1 , µ2 ) ∨
supz∈Z cd1 (µ2 , µ1 ), we compute supz∈Z cd1 (µ1 , µ2 ) := ε∗1
and supz∈Z cd1 (µ2 , µ1 ) separately. These two optimizations

can be done in parallel and are symmetric in their structure,
so in the remainder we focus on ε∗1 .

qs

Proposition 4.1: For each z = (µ1 , µ2 ) ∈ Z, with
µ1 = (y1 , t1 , j1 ), µ2 = (y2 , t2 , j2 ), i ∈ dom(µ1 ), define
the set S(i, z) := {k ∈ Z | i + k ∈ dom(µ2 )}. If
S := ∩z=(µ1 ,µ2 )∈Z,i∈dom(µ1 ) S(i, z) 6= ∅, define for each
2
k ∈ S, gk (z)
p = maxi∈dom(µ1 ) ky1 (i) − y2 (i + k)k . Then
∗
ε1 ≤ K := mink∈S supz∈Z gk (z)
The proof is in [4]. The set S contains indices for which gk
is a well-defined function of z, and thus needs to be nonempty. While in general, the non-emptiness hypothesis might
be unrealistic, it holds in the important case of switched linear
systems treated in Section IV-B.
A. Rapidly-exploring Random Trees
RRT is a very popular and efficient method of robot motion
planning (see [13] and references therein). Its strength lies in
its ability to explore the robot space quickly to reach a target
from a given starting point. In this section we present an adaptation of RRTs to the problem of computing CDτ (H1 , H2 ).
The workspace Q of the RRT is the product of the two output
spaces Y1 and Y2 of nominal system H1 and derived H2 :
Q = Y1 × Y2 . Let distQ : Q × Q → R+ be a distance
function over Q.
RRT builds a tree to explore the workspace. The root of the
tree is chosen to be a pre-determined couple of initial outputs,
namely q0 = [h1 (η1 ), h2 (η2 )], with (η1 , η2 ) ∈ R. Suppose
the tree currently has i ≥ 1 nodes. A probability distribution
with support Q is used to select a sample qs = [y1 , y2 ] in
the workspace. The nearest distQ -neighbor to qs on the tree
is found, say qnear = [y1near , y2near ]. See Fig. 5. A local
controller is then applied to H2 to synthesize an input TS
ui , of duration Dplan , which drives H2 from y2near to y2 . This
input is applied for a pre-determined duration Dhor , called
the control horizon, which may be different from Dplan . This
leads H2 to output y20 (which is not necessarily equal to y2 ).
The same input is then applied to H1 which then reaches
output y10 . The new configuration qi+1 = [y10 , y20 ] is then
added to the tree, and the process repeats until the tree has
a pre-determined size, or some measure of coverage exceeds
a specified threshold [14]. Once the tree is constructed, every
branch from root to leaf represents an evolution of the two
systems, starting from (η1 , η2 ), and under a series of common
input TS. So we can associate a pair of TS µ = H1 (η1 , u)
and µ0 = H2 (η2 , u) to each branch, and compute cd(µ, µ0 )
along that branch. The largest computed cd-value among all
the branches constitutes an estimate of CDτ (H1 , H2 ) (more
accurately, it is an under-approximation).
Guarantees of this method derive from the guarantees
provided by the underlying RRT algorithm - see for example [28]. This modified RRT only assumes that the systems
have controllers: no other assumption is made concerning their
structure or properties.
B. Switched linear systems
In this section we show how the upper bound of Prop. 4.1
can be computed when both systems are switched linear
systems driven by an external switching signal.

161

qi+1
ui

qnear
q0

Fig. 5: RRT for computing the conformance degree.
Assumption 4.1: Both M and I are switched linear systems (defined below); these models arise frequently in supervisory control of linear systems. The integration step or sampling
period is constant: t(i+1)−t(i) = t0 (i+1)−t0 (i) = δt > 0 ∀i.
E.g. the output may be measured via a sample-and-hold circuit.
The initial sets H0,M and H0,I and the state spaces HM and
HI are bounded boxes in Rn1 and Rn2 , respectively. There
exists a linear transformation VR between the initial state ηI
of HI and that ηM of HM : ηI = VR · ηM . E.g. this is true
whenever I is obtained by MOR from a switched linear M.
A switched linear system H is a hybrid system (1) where
the flow and output functions are linear with respect to the
state and the input, and there are no resets of the state (i.e.
G is the identity). It can be seen as a collection of L linear
sub-systems (A` , B` , C` , D` ), ` ∈ [L], L ∈ N>0 , described by
the discrete-time equations:

∈ H0 ⊂ Rn
 η(0)
η(s + 1) = Aa(s) η(s) + Ba(s) u(s)
H:
(2)
 y(s)
= Ca(s) η(s) + Da(s) u(s)
where a : [0, T ] → [L] is the piece-wise constant rightcontinuous external switching signal with left limits, and
finitely many discontinuities in any bounded interval. When
a(s) changes value, the system starts obeying the dynamics
of the new mode, and hybrid time advances by increasing j. An output TS of H is µ = (y, t, j) s.t. t(i) =
i · δt, y(i) = h(η(t(i))), and j(i) = #{s ∈ [0, i ·
δt] | a is discontinuous at s}. Both M and I are described by
(2) with common switching signal, input TS, mode set [L], output set Y , and (naturally) different matrices (A` , B` , C` , D` ).
In particular, this implies that their output TS have the same
domain, and that pr2,3 (µM ) = pr2,3 (µI ) = (t, j), with t and
j given above. Therefore in this sub-section, we identify η of
(2) with the first component of the TS (η, t, j), and similarly
a ≡ pr1 ((a, t, j)), where (t, j) is the common domain of all
the TS.
We now present the elements of the formal ODEconstrained optimization problem we seek to solve. The search
variable of the optimization is simply the two output TS of the
two systems, ‘unrolled’ over N + 1 time steps, starting from
corresponding initial conditions, and subject to the same input
signal u. Formally, the search variable z can now be written
as a vector of samples:
z = [η1 (0), η1 (1), . . . , η1 (N ), η2 (0), η2 (1), . . . , η2 (N )] ∈ Z

Note that the initial states of the two systems are part of the
search variable. If we wish to make the input TS u part of
the search, we may similarly unroll it and append its sampled
values to the search vector z.

yM
−6.6

yI

−6.8

−7

−7.2

−7.4

Putting it all together, our optimization problem is:

−7.6

−7.8

max
z

gk (z) =

max
i∈dom(µ1 )

ky1 (i) − y2 (i + k)k2

(3)

−8

−8.2
0

s.t.

(Space Constraint) ∀ i = 0, . . . , N
lbi,1 ≤ η1 (i) ≤ ubi,1 , lbi,2 ≤ η2 (i) ≤ ubi,2
(Output constraint) ∀ i = 0, . . . , N
y1 (i) = C1,a(i) η1 (i) + D1,a(i) u(i)
y2 (i) = C2,a(i) η2 (i) + D2,a(i) u(i)
(Dynamical constraint) ∀ i = 0, . . . , N − 1
η1 (i + 1) = A2,a(i) η1 (i) + B1,a(i) u(i)
η2 (i + 1) = A1,a(i) η2 (i) + B2,a(i) u(i)
(Implementation constraint)
η1 (0) = VR · η2 (0)

0.04

0.06

0.08

0.1

0.12

0.14

0.16

0.18

t

Fig. 6: Trajectories that maximize the upper bound for
RLC600, zoomed in to show differences on the order of K.

Proposition 4.2: If Assumption 4.1 holds, then dom(µ) =
dom(µ0 ) = [N ] for all (µ, µ0 ) ∈ Z, and for all k ∈ [N ], the
function z 7→ gk (z) is convex.
The proof is in [4]. Thus, because we are maximizing a convex
function over a convex domain, it suffices to restrict the search
to the feasible set’s boundary. We conclude by noting that for
the solution of (3) to be acceptable as valid output TS, we set
the error tolerance to be less than the integration error incurred
when simulating the system by numerical integration.
V.

0.02

E XPERIMENTS

In this section, we illustrate the preceding theory and
algorithms on benchmark examples. For the first two systems,
we used the state-of-the-art optimization solver KNITRO [43].
KNITRO can handle very large-scale mixed integer nonlinear
programs. While not designed for nonsmooth optimization,
it can still provide a number of local maxima, so we can
approximate the global maximum via multi-start. To illustrate
Thm. 2, we use two tools for property verification: the first is
SpaceEx, a reachability analysis tool which over-approximates
the reachable set of a hybrid linear system, and thus can be
used to rigorously verify safety properties [17]. The second
tool is S-TA L I RO, which searches the set of initial conditions
and input TS (if any) for a falsifier, i.e. an output TS which
does not satisfy the property [6]. S-TA L I RO can handle
arbitrary MTL specifications (not just safety/reachability). Its
guarantees are probabilistic: i.e. if S-TA L I RO does not find
a falsifier, then we know with high probability that one does
not exist. The exact probability depends on the tool’s runtime
and certain other parameters. Other verification methods exist
like coverage-based testing, which can cover the set of initial
conditions with a finite number of tests [27]. In this section, to
avoid overloading the notation, a hybrid time set of the form
I = Ec × {0} will be written simply as Ec .
RLC circuits: The first system, RLC200, is a 200D RLC
circuit obtained from [23]. We take RLC200 to be the nominal
model M. We obtain I from M by balanced model order reduction (MOR), which produces a 14D linear system. Because
it satisfies Assumption 4.1, we formulate the optimization as

162

given in (3), for a given pre-determined input TS. This yields
a K upper bound value (Prop. 4.2) of 0.5453. We computed
the achievable closeness degree ε between the two trajectories
that maximize K (i.e. the solution of (3)), and the obtained
value was also 0.5453. So for this maximum, the bound K is
tight. We also ran the same procedure on a 600-dimensional
scaling up of RLC200 with similar results. See Fig. 6. For
both systems, it took KNITRO an average of 30mins to reach
a maximum.
As an example specification for RLC200, consider the
following progressive settling time formula expressed in MTL:
ϕ = ([0,0.8] |y1 − y2 | ≤ 1) ∧ ([0.8,2.5] |y1 − y2 | ≤ 0.5).
This formula says that in the initial 0.8 secs, the output of
the reduced order system I must not differ from that of M
by more than 1 Volt. Then, and up to time 2.5 secs, it must
differ by even less, namely 0.5V. This reflects the gradual disappearance of transients in the circuits and settling to steadystate operation. We ran S-TA L I RO on I, to test whether it
satisfied ϕ. S-TA L I RO found no falsifiers, indicating that with
high probability, I satisfies the property. The corresponding
transformed formula is ([0.06,0.74] 3[0,0.06] |y1 −y2 | ≤ 1.54)∧
([0.86,2.44] 3[0,0.06] |y1 − y2 | ≤ 1.04) S-TA L I RO returned no

falsifiers of [ϕ]τ by M.
Buck converter [32]: A DC-to-DC buck converter accepts
an input DC voltage Vs and converts it down to a lower
Vref . It has two modes. Given a switching period P and a
duty cycle f , it is in mode 1 for f · P units of time and
mode 2 for (1 − f )P units. For this example’s purposes,
we adopt a simple open-loop strategy where the duty cycle
is a function of the reference voltage: f = Vref /Vs . When
implemented, the circuit’s R, L, C parameters will typically
deviate from their nominal values, and the switching period P
computed by the software will drift from its nominal value.
Thus to study worst-case behavior, the nominal system M
and derived I are taken to correspond to the two extremes
of the valid ranges of R, L, C, P . This is now an example of
a switched system, so we ran KNITRO to find the conformance degree given τ = 3e − 5 secs. It returned ε = 2.24
in under 4 secs. We then ran SpaceEx to verify a safety
property ϕ := [0.001,0.0147]×A |y − 5| ≤ 1 of M, with
A = [d(0.0147 − 0.001)/P e]. The corresponding transformed
formula
[ϕ]3e−5 = [0.001+2τ,0.0147−2τ ]×A 3[0,6e−5) |y − 5| ≤ 3.24
is implied by the following safety formula: ϕs =
[0.001+2τ,0.0147−2τ ]×A |y − 5| ≤ 3.24, so that verifying that
I satisfies ϕs implies it also satisfies [ϕ]3e−5 . We again used
SpaceEx, confirming that I satisfies ϕs .


Hybrid nonlinear: This is a 3D hybrid nonlinear system,
with three modes and a 1D input signal. It is modified from
[20]. In each mode, the dynamics of the nominal model M
are given by:

 " # 
−(1 + γx22 )x1 + 0.1u
x˙1


 x˙2 = 


−0.5(1 − γx21 )x2 + 2x3

 x˙
−(1 − γx1 )2x2 − 0.5x3 + 0.4u
3
(4)
M


  




 y1 = γx1 + x2
y2
x3
where γ is a mode-specific constant. The derived model I is
obtained from M by linearizing the mode dynamics around
the 0 equilibrium. In [20] it was established that with 0 input,
the two systems’ location-specific dynamics are approximately
bisimilar. We ran the RRT method of Section IV-A on the
two systems, using a uniform sampling distribution, Euclidian
distance function, and a Model Predictive Controller for local
motion planning to generate a tree with 1000 nodes. We
computed the largest ε along all branches of the tree, which
yielded a value of 7.157 for τ = 0.06. To illustrate Thm. 2 for
this case, we used S-TA L I RO to check that I satisfies ϕ:
ϕ = 3[0,4]×[JM AX ] ([0,0.4] |y1 − y2 | ≤ 8)
where JM AX is an upper bound on the number of jumps in
[0,4]. S-TA L I RO reports no falsifying trajectories when trying
to falsify the corresponding [ϕ]τ for M.

VI.

R ELATED W ORK

In this paper we understand conformance as a notion that
relates systems, as done in [38], rather than a system and
its specification as in [14], [41]. The work in [38] studies
conformance of embedded software using type systems and
a notion of conformance that only relaxes time, whereas we
are interested in hybrid system models of embedded cyberphysical systems with real-valued outputs and a relaxation of
space as well time distances. The work in [30] provides an
approximate method for verifying formal equivalence between
a Simulink model and its corresponding C code; however it
requires equality of outputs between the two (an extension is
alluded to in the Conclusion), and does not account for timing
differences. The approach to conformance of hybrid systems
in [33] (building on [39]) results in untestable definitions, and
falls in the domain of nondeterministic abstractions. Other
approaches, like [9], require knowledge of the internal system
structure, which is not necessary, in our case, for Def. 2.3.
We defined conformance via the (T, J, (τ, ε))-closeness
between hybrid trajectories, based on the work of Goebel and
Teel [22]. A number of closeness measures between hybrid
trajectories and systems exist. Measures based on bisimulation [19] and supnorms [10] only consider the differences
in signal values at the same moment in time, which is
not appropriate here since TS may have different domains.
Other closeness measures, on the other hand, consider only
differences in trajectories’ timing, e.g., [24]. It can be shown
that (T, J, (τ, ε))-closeness provides a continuum of closeness
degrees between the two extremes presented in [1]. The Skorokhod distance between trajectories used in [12] is related to
(T, J, (τ, ε)), but its use of bijective retimings is too restrictive
in our context. More on the limitations of bijective retimings

163

in the hybrid systems context can be read in [15, Section 5]. In
the latter work, a generalization of (T, J, (τ, ε))-closeness is
presented as a pseudo-metric, but no computational procedure
is given for computing this more general pseudo-metric.
The works closest to ours are [26] and [35]. In [26], (τ, ε)bisimulation relations between metric transition systems are
defined. The goal is to define robust approximate synchronization between systems (rather than conformance testing).
(T, J, (τ, ε))-closeness extends (τ, ε)-bisimulation relations in
a straighforward manner to hybrid time domains, and we place
it in a computational framework where the objective is to
estimate the conformance degree. Later, Quesel [35] defined
the notion of (τ, ε)-similar traces, and proved a property
transfer result between (τ, ε)-similar traces, which is a special
case of our Thm. 1. The main differences with our work are
three. First, unlike (τ, ε)-closeness, (τ, ε)-similarity requires
the retiming relation to be order-preserving [35, Def. 17].
Whether this is important depends on the intended application.
Allowing local ‘disorder’ might be necessary to deal with
noisy signals as shown in Section II-C. Second, multiple jumps
within the same time step are ‘deleted’ [35, Section 3.1] and
not captured in (τ, ε)-similarity: this can be problematic in a
number of applications where such events are indicative of
bugs (e.g. race conditions in mixed-signal circuit verification,
gear slippage in automotive applications, Zeno behavior arising
out of high-level modeling [42], or code generation scenarios
like [5]). Finally, our Thm. 1 generalizes the result in [35] to
hybrid time domains, which allows us to explicitly take into
account discrete events that are of interest to the designer,
whereas they are ignored in [35]. It is also a generalization to
non-order preserving retimings.
VII.

C ONCLUSIONS

In this paper, we have defined conformance between a
system model and a system derived from it, by a process
of simplification or implementation, as a degree of closeness
between the outputs of the two systems. We then demonstrated
two methods to approximate this degree of conformance. In
future work, we plan on conducting a systematic comparison
of the three optimization methods: Simulated Annealing, RRTs
and multi-start KNITRO. We will consider coverage-based
methods for guiding the RRT optimization and the choice of
sampling distribution [14], and how to ‘pre-design’ a model
such that the derived implementation satisfies certain desired
properties. Finally we will apply this framework to concrete
examples of derivation processes such as code generation, and
illustrate how it helps debugging the derivation process.
ACKNOWLEDGMENT
This work was partially supported by NSF grant CNS
1350420.
R EFERENCES
[1]

[2]

A. Abate and M. Prandini. Approximate abstractions of stochastic
systems: A randomized method. In Decision and Control and European
Control Conference (CDC-ECC), 2011 50th IEEE Conference on, pages
4861–4866, 2011.
H. Abbas, B. Hoxha, G. Fainekos, J. V. Deshmukh, J. Kapinski,
and K. Ueda. Conformance testing as falsification for cyber-physical
systems. Technical Report arXiv:1401.5200, January 2014.

[3]

[4]

[5]

[6]

H. Abbas, B. Hoxha, G. Fainekos, J. V. Deshmukh, J. Kapinski, and
K. Ueda. Work in progress: Conformance testing as falsification for
cyber-physical systems. In Cyber-Physical Systems, 2014 IEEE Intl.
Conference on, April 2014.

[25]

H. Abbas, H. Mittelmann, and G. Fainekos. Formal property verification
in a conformance testing framework. [Online at: http://www.public.asu.
edu/∼hyabbas/techreports/MEMOCODE14TechRpt.pdf], 2014.

[26]

M. Anand, S. Fischmeister, Y. Hur, J. Kim, and I. Lee. Generating reliable code from hybrid-systems models. Computers, IEEE Transactions
on, 59(9):1281–1294, Sept 2010.

[27]

Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan.
S-taliro: A tool for temporal logic falsification for hybrid systems. In
Tools and algorithms for the construction and analysis of systems,
volume 6605 of LNCS, pages 254–257. Springer, 2011.

[28]

[7]

S. Bensalem, A. Legay, and M. Bozga. Rigorous embedded design:
challenges and perspectives. STTT, 15(3):149–154, 2013.

[29]

[8]

N. Bombieri, F. Fummi, G. Pravadelli, and J. Marques-Silva. Towards
equivalence checking between TLM and RTL models. In Proceedings
of the 5th IEEE/ACM MEMOCODE, pages 113–122, Washington, DC,
USA, 2007.

[30]

[9]

H. Brandl, M. Weiglhofer, and B. K. Aichernig. Automated conformance verification of hybrid systems. In Quality Software (QSIC), 10th
International Conference on, pages 3–12. IEEE, 2010.

[31]
[32]

[10]

S. Burden, H. Gonzales, R. Vasudevan, R. Bajcsy, and S. S. Sastry.
Metrization and simulation of controlled hybrid systems. Technical
Report arXiv:1302.4402, February 2013.

[33]

[11]

K. Butts.
Presentation: Toyota’s direction.
[Online at:
http://cmacs.cs.cmu.edu/presentations/verif csystems/06 KenButts.pdf],
2010.

[12]

P. Caspi and A. Benveniste. Toward an approximation theory for
computerized control. In Embedded Software, volume 2491 of LNCS,
pages 294–304. Springer, 2002.

[13]

H. Choset, K. M. Lynch, S. Hutchinson, G. A. Kantor, W. Burgard,
L. E. Kavraki, and S. Thrun. Principles of Robot Motion: Theory,
Algorithms, and Implementation. MIT Press, 2005.

[14]

[15]

[34]

[35]

T. Dang and T. Nahhal. Coverage-guided test generation for continuous
and hybrid systems. Formal Methods in System Design, 34(2):183–213,
2009.

[36]

J. Davoren. Epsilon-tubes and generalized skorokhod metrics for hybrid
paths spaces. In R. Majumdar and P. Tabuada, editors, Hybrid Systems:
Computation and Control, volume 5469 of Lecture Notes in Computer
Science, pages 135–149. Springer Berlin Heidelberg, 2009.

[37]

[16]

G. Di Guglielmo, M. Fujita, F. Fummi, G. Pravadelli, and S. Soffia.
EFSM-based model-driven approach to concolic testing of system-level
design. In 9th IEEE/ACM MEMOCODE, pages 201–209, July 2011.

[17]

G. Frehse, C. L. Guernic, A. Donz, S. Cotton, R. Ray, O. Lebeltel,
R. Ripado, A. Girard, T. Dang, and O. Maler. Spaceex: Scalable
verification of hybrid systems. In Proceedings of the 23d CAV, 2011.

[38]

[39]

[18]

G. Funchal and M. Moy. Modeling of time in discrete-event simulation
of systems-on-chip. In 9th IEEE/ACM MEMOCODE, pages 171–180,
July 2011.

[40]

[19]

A. Girard, A. Julius, and G. Pappas. Approximate simulation relations
for hybrid systems. Discrete Event Dynamic Systems, 18(2):163–179,
2008.

[41]

[20]

A. Girard and G. J. Pappas. Approximate bisimulations for nonlinear
dynamical systems. In Proceedings of 44th IEEE Conference on
Decision and Control and European Control Conference, pages 684–
689, 2005.

[42]

[21]

R. Goebel, R. G. SanFelice, and A. R. Teel. Hybrid Dynamical Systems:
modeling, stability and robustness. Princeton University Press, 2012.

[43]

[22]

R. Goebel and A. Teel. Solutions to hybrid inclusions via set and
graphical convergence with stability theory applications. Automatica,
42(4):573 – 587, 2006.

[23]

R. J. Hanson and D. C. Sorensen. Model reduction of dynamical
systems for real time control. [Online at: http://www.caam.rice.edu/
∼modelreduction/mission.html].

[24]

J. Huang, J. Voeten, and M. Geilen. Real-time property preservation
in approximations of timed systems. In Formal Methods and Models

164

for Co-Design, 2003. MEMOCODE ’03. Proceedings. First ACM and
IEEE International Conference on, pages 163–171, June 2003.
K. H. Johansson, J. Lygeros, S. Sastry, and M. Egerstedt. Simulation
of hybrid zeno automata. In Conference on Decision and Control,
volume 4, pages 3538–3543, December 1999.
A. Julius and G. Pappas. Approximate equivalence and approximate
synchronization of metric transition systems. In Decision and Control,
2006 45th IEEE Conference on, pages 905–910, Dec 2006.
A. A. Julius, G. Fainekos, M. Anand, I. Lee, and G. Pappas. Robust
test generation and coverage for hybrid systems. In Hybrid Systems:
Computation and Control, volume 4416 of LNCS, pages 329–342.
Springer-Verlag Berlin Heidelberg, 2007.
S. Karaman and E. Frazzoli. Sampling-based algorithms for optimal
motion planning. I. J. Robotic Res., 30(7):846–894, 2011.
R. Koymans. Specifying real-time properties with metric temporal logic.
Real-Time Systems, 2(4):255–299, 1990.
R. Majumdar, I. Saha, K. Ueda, and H. Yazarel. Compositional
equivalence checking for models and code of control systems. In
Decision and Control (CDC), 2013 IEEE 52nd Annual Conference on,
pages 1564–1571, Dec 2013.
R. Majumdar, I. Saha, and Z. Wang. Systematic testing for control
applications. In 8th IEEE/ACM MEMOCODE, pages 1–10, July 2010.
L. V. Nguyen and T. J. Johnson. Benchmark: DC-to-DC switchedmode power converters (buck converters, boost converters and buckboost converters). In ARCH 2014. 2014.
M. Osch. Hybrid input-output conformance and test generation. In
K. Havelund, M. Nez, G. Rou, and B. Wolff, editors, Formal Approaches to Software Testing and Runtime Verification, volume 4262
of Lecture Notes in Computer Science, pages 70–84. Springer Berlin
Heidelberg, 2006.
A. Platzer and J.-D. Quesel. KeYmaera: A hybrid theorem prover for
hybrid systems. In A. Armando, P. Baumgartner, and G. Dowek, editors,
International Joint Conference on Automated Reasoning, volume 5195
of LNCS, pages 171–178. Springer, 2008.
J.-D. Quesel. Similarity, Logic, and Games: Bridging Modeling Layers
of Hybrid Systems. PhD thesis, Carl Von Ossietzky Universitat Oldenburg, July 2013.
A. Saadat. Defect information report. [Online at: http://wwwodi.nhtsa.dot.gov/acms/cs/jaxrs/download/doc/UCM450071/RCDNN14V053-0945.PDF], 2014.
R. G. Sanfelice. Interconnections of hybrid systems: Some challenges
and recent results. Journal of Nonlinear Systems and Applications,
2(1-2):111–121, 2011.
J.-P. Talpin, P. Guernic, S. Shukla, and R. Gupta. A compositional
behavioral modeling framework for embedded system design and conformance checking. International Journal of Parallel Programming,
33(6):613–643, 2005.
J. Tretmans. Testing concurrent systems: A formal approach. In
CONCUR 1999 Concurrency Theory, pages 46–65. Springer, 1999.
Y. Watanabe and S. Swan. Clearing the clutter: Unified modeling and
verification methodology for system level hardware design. In 10th
IEEE/ACM MEMOCODE, pages 21–23, July 2012.
M. Woehrle, K. Lampka, and L. Thiele. Conformance testing for cyberphysical systems. ACM Trans. Embed. Comput. Syst., 11(4):84:1–84:23,
Jan. 2013.
J. Zhang, K. Johansson, J. Lygeros, and S. Sastry. Dynamical systems
revisited: Hybrid systems with zeno executions. In N. Lynch and
B. Krogh, editors, HSCC, volume 1790 of Lecture Notes in Computer
Science, pages 451–464. Springer Berlin Heidelberg, 2000.
Ziena. KNITRO. [Online at: http://www.ziena.com].

2014 IEEE International Conference on Robotics & Automation (ICRA)
Hong Kong Convention and Exhibition Center
May 31 - June 7, 2014. Hong Kong, China

Revision of Specification Automata under Quantitative Preferences
Kangjin Kim and Georgios Fainekos

Abstract— We study the problem of revising specifications
with preferences for automata based control synthesis problems.
In this class of revision problems, the user provides a numerical
ranking of the desirability of the subgoals in their specifications.
When the specification cannot be satisfied on the system, then
our algorithms automatically revise the specification so that the
least desirable user goals are removed from the specification.
We propose two different versions of the revision problem
with preferences. In the first version, the algorithm returns
an exact solution while in the second version the algorithm is
an approximation algorithm with non-constant approximation
ratio. Finally, we demonstrate the scalability of our algorithms
and we experimentally study the approximation ratio of the
approximation algorithm on random problem instances.

I. I NTRODUCTION
Linear Temporal Logic (LTL) has been widely adopted
as a high-level specification language for robotic behaviors
(see [1] for a recent overview). The wide spread adoption
of LTL can be attributed to the tractable algorithms that can
solve automation problems related to robotics (see [1]) and
the connections to natural language [2] and other intuitive
user interfaces [3]. In order for LTL-based control synthesis
methods to move outside research labs and be widely adopted
by the robotics community as a specification language of
choice, specification debugging tools must be developed as
well. In [4], [5], we studied the theoretical foundations of
the specification automata revision problem and we proposed
heuristic algorithms for its solution. In [6], we presented
a version of the revision problem for weighted transition
systems. In the last formulation, the debugging and revision
problem becomes harder to solve since the specification
could fail due to not satisfying certain cost constraints, such
as, the battery capacity, certain time limit, etc.
Here, we revisit the problem posed in [4]. When automatically revising specifications, we are often faced with the
challenge that not all goals have the same value for the user.
In particular, we assume that the user has certain utility or
preference value for each of the subgoals. Thus, an automatic
specification revision should recommend removing the least
desirable goals. In detail, we assume that the specification
is provided as an ω-automaton, i.e., a finite automaton with
Büchi acceptance conditions, and that each symbol labeling
the transitions has a quantitative preference value (i.e., a
positive number).
We formulate two different revision problems. The first
problem concerns removing a set of symbols such that
This work has been partially supported by award NSF CNS 1116136.
K. Kim and G. Fainekos are with the School of Computing, Informatics
and Decision Systems Engineering, Arizona State University, Tempe, AZ
85281, USA {Kangjin.Kim,fainekos}@asu.edu

978-1-4799-3685-4/14/$31.00 ©2014 IEEE

the synthesis problem has now a solution and the sum
of the preference levels of the set of removed symbols is
minimized. The second problem again seeks to remove a
set of symbols such that the synthesis problem has now a
solution; but now the largest preference level of the symbols
in the removal set must be minimized.
Not surprisingly the former problem is intractable. However, interestingly, the latter problem can be solved in polynomial time. We show how the algorithm that we presented
in [5] can be modified to provide an exact or approximate
solution (depending on the cost function) to the revision
problem with preferences in polynomial time. A practical
implication of the results in this paper is that the user can
now get an exact solution if the goal is to satisfy as many
high preference goals as possible.
Contributions: We define two new versions of the problem of revision under quantitative preferences. We show that
one version can be solved optimally in polynomial time while
the other version of the problem is in general intractable.
We provide an exact and an approximate, respectively,
polynomial time algorithm based on Dijkstra’s algorithm.
Finally, we present some examples and we demonstrate the
computational savings of our approximate algorithm over
the Brute-Force Search Algorithm that solves the intractable
version of the problem exactly.
Related Research: The problem of revising or resolving
conflicting LTL specifications has received considerable attention recently. The closest work to ours is presented in
[7]. The authors consider a number of high-level requirements in LTL which not all can be satisfied on the system.
Each formula that is satisfied gains some reward. The goal
of their algorithm is to maximize the rewards and, thus,
maximize the number of requirements that can be satisfied
on the system. Our problem definition is similar in spirit,
but the problem goals are substantially different and the
two approaches can be viewed as complementary. In [7],
if a whole sub-specification cannot be realized, then it is
aborted. In our case, we try to minimally revise the subspecification so that it can be partially satisfied. Another
substantial difference is that our proposed solutions can be
incorporated directly within the control synthesis algorithm.
Namely, as the algorithm searches for a satisfiable plan, it
also creates the graph where the search for the revision will
take place. In [7], the graph to be used for the revision must
be constructed as a separate step.
The problem of LTL planning with qualitative preferences
has been studied in [8], [9] (see also the references therein
for more research in this direction). As opposed to revision
problem, planning with preferences is based on the fact

5339

that there are many satisfiable plans and, thus, the most
preferable one should be selected. For LTL games, LTLMop
[10] was developed to debug unrealizable LTL specifications
in reactive planning for robotic applications. The problem of
revising LTL specifications on-the-fly as the robot explores
its environment is studied in [11].
In the context of general planners, the problem of finding
good excuses on why the planning failed has been studied in
[12]. Over-Subscription Planning (OSP) [13] and Partial Satisfaction Planning (PSP) [14] are also very related problems.
The aforementioned approaches do not consider extended
goals in LTL.
II. P RELIMINARIES
In this paper, we work with discrete abstractions (Finite
State Machines) of the continuous robotic control system
[15]. Each state of the Finite State Machine (FSM) T is
labeled by a number of symbols from a set Π = {π0 , π1 ,
. . . , πn } that represent regions in the configuration space of
the robot or, more generally, actions that can be performed
by the robot.
Definition 1 (FSM): A Finite State Machine is a tuple
T = (Q, Q0 , →T , hT , Π) where: Q is a set of states;
Q0 ⊆ Q is the set of possible initial states; →T = E ⊆ Q×Q
is the transition relation; and, hT : Q → P(Π) maps each
state q to the set of atomic propositions that are true on q.
We define a path p : N → Q on the FSM to be a sequence
of states and a trace to be the corresponding sequence of sets
of propositions. Formally, a path is a function p : N → Q
such that for each i ∈ N we have p(i) →T p(i + 1) and the
trace is the function composition p̄ = hT ◦ p : N → P(Π).
The language L(T ) of T consists of all possible traces.
Assumption 1: All the states on T are reachable.
In this work, we are interested in the specification automata that impose certain requirements on the traces of T .
In the following, P(Π) denotes the powerset of a set Π.
Definition 2: A specification automaton is a tuple Bs =
s
(SBs , sB
0 , P(Π), δBs , FBs , θ) where: SBs is a finite set of
s
states; sB
0 is the initial state; P(Π) is the input alphabet;
δBs : SBs × P(Π) → P(SBs ) is a transition function; FBs ⊆
SBs is a set of final states; and θ : Π × SB2 s → R≥0 is a
preference function.
l
When s′ ∈ δBs (s, l), we also write s →Bs s′ or
(s, l, s′ ) ∈→Bs . A run r of Bs is a sequence of states
r : N → SBs that occurs under an input trace p̄ taking
s
values in P(Π). That is, for i = 0 we have r(0) = sB
0 and
p̄(i)

for all i ≥ 0 we have r(i) → Bs r(i + 1). Let lim(·) be the
function that returns the set of states that are encountered
infinitely often in the run r of Bs . Then, a run r of an
automaton Bs over an infinite trace p̄ is accepting if and
only if lim(r) ∩ FBs 6= ∅. This is called a Büchi acceptance
condition. Finally, we define the language L(Bs ) of Bs to be
the set of all traces p̄ that have a run that is accepted by Bs .
In order to simplify the discussion in Section III, we will
make the following assumption without loss of generality.
Assumption 2: Between any two states of the specification
automaton there exists at most one transition.

We will also be using the following notations.
2
′
• we define the set EBs ⊆ SB , such that (s, s ) ∈ EBs
s
l

iff ∃l ∈ P(Π) , s →Bs s′ ; and,
2
• we define the function λBs : SB → P(Π) which maps a
s
pair of states to the label of the corresponding transition,
l
i.e., if s →Bs s′ , then λBs (s, s′ ) = l.
In brief, our goal is to generate paths on T that satisfy
the specification Bs [15]. This can be achived by finding
accepting runs on the product automaton A = T × Bs .
Definition 3: The product automaton A = T × Bs is the
automaton A = (SA , sA
0 , P(Π), δA , FA ) where:
• SA = Q × S B s ,
B
A
• s0 = {(q0 , s0 s ) | q0 ∈ Q0 },
• δA : SA × P(Π) → P(SA ) s.t. (qj , sj ) ∈ δA ((qi , si ), l)
iff qi →T qj and sj ∈ δBs (si , l) with l ⊆ hT (qj ),
• FA = Q × F is the set of accepting states.
We say that Bs is satisfiable on T if L(A) 6= ∅. Moreover,
finding a satisfying path on T × Bs is an easy algorithmic
problem [15]. Each accepting (infinite) run consists of two
parts: prefix: a part that is executed only once (from an
initial state to a final state) and, lasso: a part that is repeated
infinitely (from a final state back to itself). Note that if the
prefix or the lasso do not contain a final state, then the
language L(A) is empty. Namely, the synthesis phase has
failed and we cannot find a system behavior that satisfies
the specification.
When a specification B is not satisfiable on a particular
system T , the current motion planning and control synthesis
methods based on automata theoretic concepts [15]–[17] simply return that the specification is not satisfiable without any
other user feedback. In such cases, our previous algorithms
[4], [5] can provide as feedback to the user the closest
revision under equal preference for all goals. Formally, a
revision R is a subset of P(Π) × EBs . Each (π, s, s′ ) ∈ R
indicates that π must be removed from λBs (s, s′ ).
III. R EVISION U NDER P REFERENCES
When choosing an alternative plan, each user can have
different preferences. Suppose that users can assign some
preference level to each proposition labeling the specification automaton through the preference function θ. When
preference level is 0, it is least preferred, and the greater
preference level is, the more preferred it is. However, preference level cannot be ∞. We remark that each occurrence
of an atomic proposition over different transitions can have
different preference levels. Therefore, taking transitions on
the cross-product automaton A, we can get as a reward
preference levels of elements in Π on the transitions.
A revised specification is one that can be satisfied on the
discrete abstraction of the workspace or the configuration
space of the robot. In order to search for a minimal revision,
we need first to define an ordering relation on automata
as well as a distance function between automata. We do
not want to consider the “space” of all possible automata,
but rather the “space” of specification automata which are
semantically close to the initial specification automaton Bs .

5340

The later will imply that we remain close to the initial
intention of the designer. We propose that this space consists of all the automata that can be derived from Bs by
removing symbols from the transitions. Our definition of the
ordering relation between automata relies upon the previous
assumption.
1
Definition 4 (Relaxation): Let B1 = (SB1 , sB
0 , P(Π),
B2
→B1 , FB1 , θB1 ) and B2 = (SB2 , s0 , P(Π), →B2 , FB2 , θB2 )
be two specification automata having the same preference
levels for P(Π). Then, we say that B2 is a relaxation of
B1 and we write B1  B2 if and only if SB1 = SB2 = S,
B2
1
sB
0 = s0 , FB1 = FB2 , θB1 = θB2 and
1) ∀(s, l, s′ ) ∈→B1 − →B2 . ∃l′ .
(s, l′ , s′ ) ∈→B2 − →B1 and l′ ⊆ l.
2) ∀(s, l, s′ ) ∈→B2 − →B1 . ∃l′ .
(s, l′ , s′ ) ∈→B1 − →B2 and l ⊆ l′ .
We remark that if B1  B2 , then L(B1 ) ⊆ L(B2 ) since
the relaxed automaton allows more behaviors to occur.
We can now define the set of automata over which we will
search for a revision.
Definition 5: Given a system T and and a specification
automaton Bs , the set of valid relaxations of Bs is defined
as R(Bs , T ) = {B | Bs  B and L(T × B) 6= ∅}.
We can now search for a solution in the set R(Bs , T ).
Different solutions can be compared from their revision sets.
Definition 6 (Revision Set): Given a specification automaton Bs and a B ∈ R(Bs , T ), the revision set is defined as
R(Bs , B) = {(π, s, s′ ) | π ∈ (λBs (s, s′ ) − λB (s, s′ ))}.
We define two different revision problems.
Problem 1 (Min-Sum Revision): Given a system T and
a specification automaton Bs , if the specification Bs is
not
P satisfiable on T , then find a revision set R such that
ρ∈R θ(ρ) is minimized.
Problem 2 (Min-Max Revision): Given a system T and
a specification automaton Bs , if the specification Bs is
not satisfiable on T , then find a revision set R such that
maxρ∈R θ(ρ) is minimized.
The edges of GA are labeled by the set of symbols which
if removed from the corresponding transition on Bs , they
will enable the transition on A. The overall problem then
becomes one of finding the least number of symbols to be
removed in order for the product graph to have an accepting
run.
Definition 7: Given a system T and a specification automaton Bs , we define the graph GA =
(V, E, vs , Vf , Π, Λ, p), which corresponds to the product
A = T × Bs as follows
• V = S is the set of nodes
• E = EA ∪ ED ⊆ S × S, where EA is the set
of edges that correspond to transitions on A, i.e.,
l
((q, s), (q ′ , s′ )) ∈ EA iff ∃l ∈ P(Π) . (q, s) →A
(q ′ , s′ ); and ED is the set of edges that correspond
to disabled transitions, i.e., ((q, s), (q ′ , s′ )) ∈ ED iff
l
q →T q ′ and s →Bs s′ with l ∩ (Π − hT (q ′ )) 6= ∅
A
• vs = s0 is the source node
• Vf = FA is the set of sinks

•
•

Π = {hπ, (s, s′ )i | π ∈ Π, (s, s′ ) ∈ EBs }
Λ : E → P(Π) is the edge labeling function such that
if e = ((q, s), (q ′ , s′ )), then
Λ(e) = {hπ, (s, s′ )i | π ∈ (λBs (s, s′ ) − hT (q ′ ))}.

θ : Π → R≥0 is the preference function of Bs restricted
on Π.
If Λ(e) 6= ∅, then it specifies those atomic propositions
in λBs (s, s′ ) that need to be removed in order to enable the
edge in A. Again, note that the labels of the edges of GA are
subsets of Π rather than Π. This is due to the fact that we
are looking into removing an atomic proposition π from a
specific transition (s, l, s′ ) of Bs rather than all occurrences
of π in Bs .
Consider now a path that reaches an accept state and then
can loop back to the same accept state. The set of labels
of the path is a revision set R that corresponds to some
B ∈ R(Bs , T ). This is immediate by the definition of the
graph GA . Thus, our goal is to solve the Min-Sum and MinMax revision problems on this graph.
First, we study the computational complexity of the two
problems by restricting the search problem only to paths from
source (initial state) to sink (accept state). Let P aths(GA )
denote all such paths on GA . We indicate that the graph
search equivalent problem of Problem 2 is in P. Given a
path p = vs v1 v2 . . . vf on GA with vf ∈ Vf , we define the
max-preference level of the path to be:
•

θmax (p) =

max

(vi ,vi+1 )∈p

θ(Λ(vi , vi+1 ))

Note that this is the same as the original cost function
in Problem 2 since clearly max(vi ,vi+1 )∈p θ(Λ(vi , vi+1 )) =
maxρ∈R θ(ρ) where R = ∪(vi ,vi+1 )∈p Λ(vi , vi+1 ). Thus,
Problem 2 is converted into the following optimization
problem:
p∗ = arg
min
θ(p)
(1)
p∈P aths(GA )
And, thus, the revision will be R = ∪(vi ,vi+1 )∈p∗ Λ(vi , vi+1 ).
Now, we recall the weak optimality principle [18].
Definition 8 (Weak optimality principle): There is an optimal path formed by optimal subpaths.
Proposition 1: The graph search equivalent of Problem 2
satisfies the weak optimality principle.
The importance of the weak optimality principle being
satisfied is that label correcting and label setting algorithms
can be applied to such problems [18]. Dijkstra’s algorithm
is such an algorithm [19] and, thus, it can provide an exact
solution to the problem.
Now, we proceed to the Min-Sum preference problem.
Given a path p = vs v1 v2 . . . vf on GA with vf ∈ Vf , we
define the sum-preference level of the path to be:
X
θ+ (p) =
{θ(ρ) | ρ ∈ ∪(vi ,vi+1 )∈p Λ(vi , vi+1 )}
and if we are directly provided with a revision set R, then
X
θ+ (R) =
θ(ρ)

5341

ρ∈R

Problem 3: Labeled Path under Additive Preferences
(LPAP). I NPUTS : A graph GA = (V, E, vs , Vf , Π, Λ, θ), and
a preference bound K ∈ N. O UTPUT: a set R ⊆ Π such that
removing all elements in R from edges in E enables a path
from vs to some final vertex vf ∈ Vf and θ+ (R) ≤ K.
We can show that the corresponding decision problem is
NP-Complete.
Theorem 1: Given an instance of the LPAP (GA , K), the
decision problem of whether there exists a path p such that
θ+ (p) ≤ K is NP-Complete.
IV. A LGORITHMS FOR THE R EVISION P ROBLEM WITH
P REFERENCES
In this section, we present Algorithms for the Revision
Problem with Preferences (ARPP). It is based on the Approximation Algorithm of the Minimal Revision Problem
(AAMRP) [5] which is in turn based on Dijkstra’s shortest
path algorithm [19]. The main difference from AAMRP
is that instead of finding the minimum number of atomic
propositions that must be removed from each edge on the
paths of the graph GA , ARPP tracks paths having atomic
propositions that minimize the preference level from each
edge on the paths of the graph GA .
Here, we present the pseudocode for ARPP. ARPP is
similar to AAMRP in [5]. The difference from [5] is that
AARP uses P REF function instead of using cardinality of the
set. For Min-Sum Revision, the function P REF: Π → R≥0
is defined as following: given a set of label R ⊆ Π and the
preference function θ+ : Π → R≥0 , P REF(R) = θ+ (R).
The Min-Sum ARPP is denoted by ARP P+ . For MinMax Revision, the function P REF: Π → R≥0 is defined as
following: given a set of label R ⊆ Π and the preference
function θ : Π → R≥0 , P REF(R) = maxρ∈R θ(ρ). The MinMax ARPP is denoted by ARP Pmax .
The main algorithm (Alg. 1) divides the problem into
two tasks. First, in line 5, it finds an approximation to the
minimum preference level of atomic propositions from Π
that must be removed to have a prefix path to each reachable
sink (see Section II). Then, in line 9, it repeats the process
from each reachable final state to find an approximation to
the minimum preference level of atomic propositions from
Π that must be removed so that a lasso path is enabled. The
combination of prefix/lasso that removes the least preferable
atomic propositions is returned to the user. Due to space limitations, we omit Algorithm 2 F IND M IN PATH and Algorithm
3 R ELAX (for details, see [20]).
The analysis of the algorithm ARPP follows closely
the analysis of AAMRP in [5]. The only difference in
the time complexity is that ARPP uses P REF function
in order to compute preference levels of all elements in
Π. Both Min-Sum Revision and Min-Max Revision take
O(Π) since at most they compute preference levels of all
elements in Π. Hence, the running time of F IND M IN PATH
2
is O(E(Π log Π + log V )). Therefore, the running time
2
of ARPP is O(Vf (V Π log Π + E(Π log Π + log V ))) =
2
O(Vf E(Π log Π + log V )) which is polynomial in the size
of the input graph.

Algorithm 1 ARPP
Inputs: a graph GA = (V, E, vs , Vf , Π, Λ, θ).
Outputs: the list L of symbols from Π that must be removed
from Bs .
1: procedure ARPP(GA )
2:
L←Π
⊲ Each row is set to (Π, ∞)
3:
M[:, :] ← (Π, ∞)
4:
M[vs , :] ← (∅, 0)
⊲ Initialize the source node
5:
hM, P, Vi ← F IND M IN PATH(GA , M, 0)
6:
if V ∩ Vf = ∅ then L ← ∅
7:
else
8:
for vf ∈ V ∩ Vf do
9:
Lp ← G ETAPF ROM PATH(vs , vf , M, P)
10:
M′ [:, :] ← (Π, ∞)
11:
M′ [vf , :] ← M[vf , :]
12:
G′A ← (V, E, vf , {vf }, Π, L)
13:
hM′ , P′ , V ′ i ← F IND M IN PATH(G′A , M′ , 1)
14:
if vf ∈ V ′ then
15:
Ll ← G ETAPF ROM PATH(vf , vf , M′ , P′ )
16:
if P REF(Lp ∪ Ll ) ≤ P REF(L) then
17:
L ← Lp ∪ Ll
18:
end if
19:
end if
20:
end for
21:
end if
22:
return L
23: end procedure
The function G ETAPF ROM PATH((vs , vf , M, P)) returns the
atomic propositions that must be removed from Bs in order
to enable a path on A from a starting state vs to a final state
vf given the tables M and P.

V. E XAMPLE AND E XPERIMENTS
In this section, we present an example scenario and
experimental results using our prototype implementation of
algorithms and brute-force search.
In the following example, we will be using LTL as a specification language. We remark that the results presented here
can be easily extended to LTL formulas by renaming repeated
occurrences of atomic propositions in the specification and
adding them on the transition system (for details, see [21]).
The following example scenario was inspired by [16], [22],
and we will be using LTL as a specification language.
Example 1 (Single Robot Data Gathering Task): In this
example, we use a simplified road network having three
gathering locations and two upload locations with four
intersections of the road. In Fig. 1, the data gather locations,
which are labeled g1 , g2 , and g3 , are dark gray, the data
upload locations, which are labeled u1 and u2 , are light
gray, and the intersections are labeled i1 through i4 . In order
to gather data and upload the gather-data persistently, the
following LTL formula may be considered: φA := GF(ϕ) ∧
GF(π), where ϕ := g1 ∨ g2 ∨ g3 and π := u1 ∨ u2 . The
following formula can make the robot move from gather
locations to upload locations after gathering data: φG :=

5342

i2

u1

i2

i4

i4
u1
g2

i1

g2

g3

i1

g3

g1

g1

u2

u2

i3
i3

Fig. 1: Illustration of the simple road network environment
of Example 1. The robot is required to drive right-side of
the road.

G(ϕ → X(¬ϕ U π)). In order for the robot to move to gather
location after uploading, the following formula is needed:
φU := G(π → X(¬π U ϕ)).
Let us consider that some parts of road are not recommended to drive from gather locations, such as from i4 to
i2 and from i1 to i2 . We can describe those constraints as
follows: ψ1 := G(g1 → ¬(i4 ∧ Xi2 ) U u1 ) and ψ2 := G(g2 →
¬(i1 ∧ Xi2 ) U u2 ). If the gathering task should have an order
such as g3 , g1 , g2 , g3 , g1 , g2 , . . ., then the following formula
could be considered: φO := ((¬g1 ∧ ¬g2 ) U g3 ) ∧ G(g3 →
X((¬g2 ∧ ¬g3 ) U g1 )) ∧ G(g1 → X((¬g1 ∧ ¬g3 ) U g2 )) ∧
G(g2 → X((¬g1 ∧ ¬g2 ) U g3 )). Now, we can informally
describe the mission. The mission is “Always gather data
from g3 , g1 , g2 in this order and upload the collected data
to u1 and u2 . Once data gathering is finished, do not visit
gather locations until the data is uploaded. Once uploading
is finished, do not visit upload locations until gathering data.
You should always avoid the road from i4 to i2 when you
head to u1 from g1 and from i1 to i2 when you head to u2
from g2 ”. The following formula represents this mission:
φsingle := φO ∧ φG ∧ φU ∧ ψ1 ∧ ψ2 ∧ GF(π).
Assume that initially, the robot is in i3 and final nodes
are u1 and u2 . When we made a cross product with the
road and the specification, we could get 36824 states, 350114
transitions and 100 final states. Not removing some atomic
propositions, the specification was not satisfiable.
We tested two different preference levels. For clarity in
presentation, we omit for presenting preference levels on
each transition since we set for all the occurances of the same
symbols the same preference level, we abuse notation and
write θ(π) instead of θ(π, (si , sj )). However, the revision
is for specification transitions. First, the preference level of
the symbols are as follows: for g1 , g2 , g3 , u1 , u2 , i1 , i2 ,
i3 , i4 , the preference levels are 3, 4, 5, 20, 20, 1, 1, 1, 1,
respectively, and for ¬g1 , ¬g2 , ¬g3 , ¬u1 , ¬u2 , ¬i1 , ¬i2 ,
¬i3 , ¬i4 , the preference levels are 3, 4, 5, 20, 20, 1, 1, 1,
1, respectively. ARPP for Min-Sum Revision took 210.979
seconds, and suggested removing ¬g1 and ¬i4 . The total
returned preference was 4 since θ(¬g1 ) = 3 and θ(¬i4 ) =
1. The sequence of the locations suggested by ARPP
is i3 g3 i2 u1 (i1 g1 i3 u2 i1 i2 i4 g2 i3 u2 i1 g1 i3 g3 i4 i2 u1 )+ . We can

check that ¬g1 is from G(g2 → X((¬g1 ∧ ¬g2 ) U g3 ))
of the formula φO and from ¬ϕ = ¬(g1 ∨ g2 ∨ g3 ) of
the formula φG = G(ϕ → (¬ϕ U π)), and ¬i4 is from
G(g1 → ¬(i4 ∧ Xi2 ) U u1 ) of the formula ψ1 . AARP for
Min-Max Revision took 239 seconds, and returned g1 , ¬g1 ,
¬i1 , and ¬i4 . The maximum returned preference was 3 since
θ(g1 ) = 3 and θ(¬g1 ) = 3.
In the second case, the preference level of the positive atomic propositions are same as the first test, and
the preference level of the negative atomic propositions
are as follow: for ¬g1 , ¬g2 , ¬g3 , ¬u1 , ¬u2 , ¬i1 , ¬i2 ,
¬i3 , ¬i4 , the preference levels are 3, 4, 5, 20, 20, 10,
10, 10, 10, respectively. In this case, ARPP for Min-Sum
Revision took 207.885 seconds, and suggested removing
g3 . The total returned preference was 5 since θ(g3 ) =
5. The sequence of the locations suggested by ARPP
is i3 g3 i4 i2 u1 (i1 g1 i3 u2 i1 i2 i4 g2 i3 u2 i1 i2 u1 )+ . We can check
that g3 is from G(g3 → X((¬g2 ∧¬g3 ) U g1)) of the formula
φO and from ϕ = (g1 ∨ g2 ∨ g3 ) of the formula φU =
G(φ → X(¬φ U ϕ). ARPP for Min-Max Revision took
214.322 seconds, and returned g1 and ¬g1 . The maximum
preference was 3 since θ(g1 ) = 3 and θ(¬g1 ) = 3.
△
Now, we present some experimental results. The propotype
implementation is written in Python. For the experiments, we
utilized the ASU super computing center which consists of
clusters of Dual 4-core processors, 16 GB Intel(R) Xeon(R)
CPU X5355 @2.66 Ghz. The operating system is CentOS
release 5.9. The clusters were used to run each test case on
each single core in parallel.
In order to assess the experimental approximation ratio of
the heuristic (Min-Sum Revision), we compared the solutions
returned by the heuristic with Brute-force search algorithm.
The Brute-force search is guaranteed to return a minimal
solution to the Min-Sum Revision problem. We omit the
explanation of the each test case and full experiment results
(for details, see [20]).
Table I compares the results of the Brute-Force Search
Algorithm with the results of ARPP for Min-Sum Revision
(ARP P+ ) on test cases of different sizes (total number of
nodes). For each graph size, we performed 200 tests and
we report minimum, average, and maximum computation
times in sec. The “avg # nodes” column shows the average
number of nodes returned from ARP P+ . Both algorithms
were able to finish the computation and return a minimal
revision for instances having 9 nodes and 100 nodes. However, for instances having 196 nodes, the Brute-Force Search
Algorithm had one failed instance which exceeded the 2 hrs
window limit. In the large problem instances, ARPP for MinSum Revision achieved a 600 time speed-up on the average
running time.
Table II shows the results of ARPP for Min-Max Revision
(ARP Pmax ) on test cases of different sizes (total number of
nodes). This test results also used same test cases as the ones
for Table I. We report minimum, average, and maximum
computation times in sec. The “avg # nodes” shows the
average number of nodes returned from ARP Pmax .

5343

Nodes
9
100
196

min
0.033
0.065
0.278

Brute-Force
avg
max
0.0921
0.945
0.3707
3.997
303.55 11974

succ
200/200
200/200
199/200

min
0.019
0.065
0.137

Min-Sum Revision (ARP P+ )
avg
max
succ
avg # nodes
0.183
0.874
200/200
1.305
0.1598
2.66
200/200
1.95
0.4927 12.057 200/200
2.305

min
1
1
1

RATIO
avg
max
1
1
1.003
1.619
1.0014 1.1475

TABLE I: Numerical Experiments: Number of nodes versus the results of Brute-Force Search Algorithm and ARPP for
Min-Sum Revision. Under the Brute-Force and Min-Sum Revision columns the numbers indicate computation times in sec.
RATIO indicates the experimentally observed approximation ratio to the optimal solution.
Nodes
9
100
196

min
0.02
0.061
0.139

Min-Max
avg
0.0508
0.1258
0.29824

Revision
max
0.66
0.471
0.74

(ARP Pmax )
succ
avg # nodes
200/200
1.785
200/200
3.215
200/200
3.84

TABLE II: Numerical Experiments: For each graph GA ,
Number of nodes versus the result of ARPP for Min-Max
Revision (ARP Pmax ). Under the min, avg, max columns
the numbers indicate computation times in sec.

VI. C ONCLUSIONS
This paper discusses the problem of specification revision
with user preferences. We have demonstrated that adding
preference levels to the goals in the specification can render
the revision problem easier to solve under the appropriate
cost function. We view the automatic debugging and specification revision problems as foundational for formal methods
to receive wider adoption in the robotics community and
beyond. With the current paper and the predecessors [4]–[6],
[23], we have studied the theoretical foundations of different
versions of the problem. Our algorithms and tools can be
used as add-ons to control synthesis methods developed by
our and other groups [15]–[17], [24], [25]. Our goal for
the future is to incorporate all the specification revision
methods in a comprehensive user-friendly tool that can run
on different platforms.
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers
for their detailed comments.
R EFERENCES
[1] H. Kress-Gazit, “Robot challenges: Toward development of verification and synthesis techniques [errata],” IEEE Robotics Automation
Magazine, vol. 18, no. 4, pp. 108–109, Dec. 2011.
[2] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Translating
structured english to robot controllers,” Advanced Robotics, vol. 22,
no. 12, pp. 1343–1359, 2008.
[3] S. Srinivas, R. Kermani, K. Kim, Y. Kobayashi, and G. Fainekos,
“A graphical language for LTL motion and mission planning,” in
Proceedings of the IEEE International Conference on Robotics and
Biomimetics, 2013.
[4] K. Kim, G. Fainekos, and S. Sankaranarayanan, “On the revision
problem of specification automata,” in Proceedings of the IEEE
Conference on Robotics and Automation, May 2012.
[5] K. Kim and G. Fainekos, “Approximate solutions for the minimal
revision problem of specification automata,” in Proceedings of the
IEEE/RSJ International Conference on Intelligent Robots and Systems,
2012.

[6] ——, “Minimal specification revision for weighted transition systems,”
in Proceedings of the IEEE Conference on Robotics and Automation,
May 2013.
[7] J. Tumova, L. I. R. Castro, S. Karaman, E. Frazzoli, and D. Rus,
“Minimum-violating planning with conflicting specifications,” in
American Control Conference, 2013.
[8] T. C. Son, E. Pontelli, and C. Baral, “A non-monotonic goal specification language for planning with preferences,” in 6th Multidisciplinary
Workshop on Advances in Preference Handling, 2012.
[9] M. Bienvenu, C. Fritz, and S. McIlraith, “Planning with qualitative
temporal preferences,” in International Conference on Principles of
Knowledge Representation and Reasoning, 2006.
[10] V. Raman and H. Kress-Gazit, “Analyzing unsynthesizable specifications for high-level robot behavior using LTLMoP,” in 23rd International Conference on Computer Aided Verification, ser. LNCS, vol.
6806. Springer, 2011, pp. 663–668.
[11] M. Guo, K. H. Johansson, and D. V. Dimarogonas, “Revising motion
planning under linear temporal logic specifications in partially known
workspaces,” in Proceedings of the IEEE Conference on Robotics and
Automation, 2013.
[12] M. Göbelbecker, T. Keller, P. Eyerich, M. Brenner, and B. Nebel,
“Coming up with good excuses: What to do when no plan can
be found,” in Proceedings of the 20th International Conference on
Automated Planning and Scheduling. AAAI, 2010, pp. 81–88.
[13] D. E. Smith, “Choosing objectives in over-subscription planning,”
in Proceedings of the 14th International Conference on Automated
Planning and Scheduling, 2004, p. 393401.
[14] M. van den Briel, R. Sanchez, M. B. Do, and S. Kambhampati, “Effective approaches for partial satisfaction (over-subscription) planning,” in
Proceedings of the 19th national conference on Artifical intelligence.
AAAI Press, 2004, p. 562569.
[15] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, Feb. 2009.
[16] A. Ulusoy, S. L. Smith, X. C. Ding, C. Belta, and D. Rus, “Optimal multi-robot path planning with temporal logic constraints,” in
IEEE/RSJ International Conference on Intelligent Robots and Systems,, 2011, pp. 3087 –3092.
[17] A. LaViers, M. Egerstedt, Y. Chen, and C. Belta, “Automatic generation of balletic motions,” IEEE/ACM International Conference on
Cyber-Physical Systems, vol. 0, pp. 13–21, 2011.
[18] E. Martins, M. Pascoal, D. Rasteiro, and J. Dos Santos, “The optimal
path problem,” Investigacão Operacional, vol. 19, pp. 43–60, 1999.
[19] S. M. LaValle, Planning Algorithms. Cambridge University Press,
2006. [Online]. Available: http://msl.cs.uiuc.edu/planning/
[20] K. Kim and G. Fainekos, “Revision of specification automata under
quantitative preferences,” Cornell University Library arXiv.org, Tech.
Rep., 2014.
[21] LTL2BA modification. [Online]. Available: https://www.assembla.
com/code/ltl2ba cpslab/git/nodes
[22] A. Ulusoy, S. L. Smith, X. C. Ding, and C. Belta, “Robust multi-robot
optimal path planning with temporal logic constraints,” in 2012 IEEE
International Conference on Robotics and Automation (ICRA), 2012.
[23] G. E. Fainekos, “Revising temporal logic specifications for motion
planning,” in Proceedings of the IEEE Conference on Robotics and
Automation, May 2011.
[24] L. Bobadilla, O. Sanchez, J. Czarnowski, K. Gossman, and S. LaValle,
“Controlling wild bodies using linear temporal logic,” in Proceedings
of Robotics: Science and Systems, Los Angeles, CA, USA, June 2011.
[25] E. M. Wolff, U. Topcu, and R. M. Murray, “Automaton-guided
controller synthesis for nonlinear systems with temporal logic,” in
International Conference on Intelligent Robots and Systems, 2013.

5344

2015 American Control Conference
Palmer House Hilton
July 1-3, 2015. Chicago, IL, USA

Automotive control design bug-finding with the S-TaLiRo tool
Georgios Fainekos

E XTENDED A BSTRACT
One of the important challenges in the Model Based
Development (MBD) of automotive systems is the problem
of verifying functional system properties. In its general form,
the verification problem is undecidable due to the interplay
between continuous and discrete system dynamics [1]. In this
tutorial, we present the bounded-time temporal logic testing
and verification problem for Cyber-Physical Systems (CPS)
[2]. Temporal logics [3] can formally capture both state-space
and real-time system requirements. For example, temporal
logics can mathematically state requirements like “whenever
the system switches to first gear, then it should not switch to
second gear within 2.5 sec”. Our approach in tackling this
challenging problem is to convert the verification problem
into an optimization problem through a notion of robustness
for temporal logics [4]. The robust interpretation of a temporal logic specification over a system trajectory quantifies
“how much” the system trajectory satisfies or does not
satisfy the specification. In general, the resulting optimization
problem is non-convex and non-linear, the utility function
is not known in closed-form and the search space is uncountable. Thus, stochastic search techniques are employed
in order to solve the resulting optimization problem. We
have implemented our testing and verification framework
into a MATLAB (TM) toolbox called S-TaLiRo (System’s
TemporAl LogIc Robustness) [5], [6]. In this tutorial, we will
demonstrate how S-TaLiRo can provide answers to challenge
problems from the automotive industry [7]–[10].

[7] G. Fainekos, S. Sankaranarayanan, K. Ueda, and H. Yazarel, “Verification of automotive control applications using s-taliro,” in Proceedings
of the American Control Conference, 2012.
[8] H. Abbas, B. Hoxha, G. Fainekos, and K. Ueda, “Robustness-guided
temporal logic testing and verification for stochastic cyber-physical
systems,” in Proc. of IEEE International Conference on CYBER
Technology in Automation, Control, and Intelligent Systems, 2014.
[9] B. Hoxha, H. Abbas, and G. Fainekos, “Using s-taliro on industrial size
automotive models,” in Proc. of Applied Verification for Continuous
and Hybrid Systems, 2014.
[10] H. Yang, B. Hoxha, and G. Fainekos, “Querying parametric temporal
logic properties on embedded systems,” in Int. Conference on Testing
Software and Systems, vol. 7641. Springer, 2012, pp. 136–151.

R EFERENCES
[1] T. A. Henzinger, P. W. Kopke, A. Puri, and P. Varaiya, “What’s
decidable about hybrid automata?” J. Comput. Syst. Sci., vol. 57, no. 1,
pp. 94–124, 1998.
[2] H. Abbas, G. E. Fainekos, S. Sankaranarayanan, F. Ivancic, and
A. Gupta, “Probabilistic temporal logic falsification of cyber-physical
systems,” ACM Transactions on Embedded Computing Systems,
vol. 12, no. s2, May 2013.
[3] R. Alur and T. A. Henzinger, “Logics and Models of Real-Time: A
Survey,” in Real Time: Theory in Practice, vol. 600. Springer-Verlag,
1991, pp. 74–106.
[4] G. E. Fainekos and G. J. Pappas, “Robustness of temporal logic specifications for continuous-time signals,” Theoretical Computer Science,
vol. 410, no. 42, pp. 4262–4291, 2009.
[5] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan, “S-taliro: A tool for temporal logic falsification for hybrid
systems,” in Tools and algorithms for the construction and analysis
of systems, ser. LNCS, vol. 6605. Springer, 2011, pp. 254–257.
[6] TaLiRo
Tools.
[Online].
Available:
https://sites.google.com/a/asu.edu/s-taliro/
This work was partially supported by the NSF awards CNS-1116136 and
CNS-1319560.
G. Fainekos is with the School of Computing, Informatics and Decision
Systems Engineering at Arizona State University, Tempe, AZ, E-mail:
fainekos@asu.edu

978-1-4799-8684-2/$31.00 ©2015 AACC

4096

Metric Interval Temporal Logic Specification
Elicitation and Debugging
Adel Dokhanchi, Bardh Hoxha, and Georgios Fainekos
School of Computing, Informatics and Decision Systems
Arizona State University, Tempe, AZ, U.S.A.
Email: {adokhanc,bhoxha,fainekos}@asu.edu
Abstract—In general, system testing and verification should
be conducted with respect to formal specifications. However,
the development of formal specifications is a challenging and
error prone task, even for experts. This is especially true when
considering complex spatio-temporal requirements in real-time
embedded systems, mixed-signal circuits, or more generally,
software-controlled physical systems. In this work, we present
a framework for the elicitation and debugging of formal specifications. The elicitation of formal specifications is handled
through a graphical user interface. The debugging algorithm
checks inconsistent and wrong specifications. Namely, it detects
validity, redundancy and vacuity issues in formal specifications
developed in a fragment of Metric Interval Temporal Logic
(MITL). The algorithm informs system engineers on any issues
in their specifications. This improves the specification elicitation
process and, ultimately, the testing and verification process.
Finally, we present experimental results on specifications that
typically appear in Cyber Physical Systems (CPS) applications.
Application of our specification debugging tool on user derived
requirements shows that the aforementioned issues are common.
Therefore, the algorithm can help developers to correct their
specifications and avoid wasted effort on checking incorrect
requirements.

I.

I NTRODUCTION

In formal verification of Cyber-Physical Systems (CPS),
a system is verified with respect to formal specifications.
It has been shown that utilizing formal specifications can
lead to improved testing and verification [16], [22], [31].
However, developing formal specifications using logics is a
challenging and error prone task even for experts who have
formal mathematical training. Therefore, in practice, system
engineers usually define specifications in natural language.
Natural language is convenient to use in many stages of system
development, but its inherent ambiguity, inaccuracy and inconsistency make it unsuitable for use in defining specifications.
To assist in the elicitation of formal specifications, in [20],
[21], we presented a graphical formalism and tool V I S PEC that
can be utilized by both expert and non-expert users. Namely,
a user-developed graphical input is translated to a Metric
Temporal Logic (MTL) formula. The formal specifications in
MTL can be used for testing and verification with tools such
as S-TA L I RO [2] and Breach [14].
In [21], the tool was evaluated through a usability study
which showed that both expert and non-expert users were able
to use the tool to elicit formal specifications. The usability
study results also indicated that in many cases the developed
specifications were incorrect. Namely, the specifications con-

978-1-5090-0237-5/15/$31.00 ©2015 IEEE

70

tained logical inconsistencies or they were (partially) wrong1 .
This raised two questions. First, are these issues artifacts of the
graphical user interface? Second, can we automatically detect
and report issues with the requirements themselves?
We have created an on-line survey2 to answer the first
question. Namely, we conducted a usability study on Metric Interval Temporal Logic (MITL) by targeting experts in
temporal logics. In our on-line survey, we tested how well
formal method experts can translate natural requirements to
MITL. That is, given a set of requirements in natural language,
experts were asked to formalize the requirements in MITL.
The study is ongoing but preliminary results indicate that
even experts can make errors in their specifications. For
example, for the natural language specification “At some time
in the first 30 seconds, the vehicle speed (v) will go over
100 and stay above 100 for 20 seconds”, the specification
ϕ = 3[0,30] ((v > 100) ⇒ 2[0,20] (v > 100)) was provided.
Here, 3[0,30] stands for “eventually within 30 time units” and
2[0,20] for “always from 0 to 20 time units”.
However, specification ϕ is invalid. This is because, if at
any point in time between 0 and 30 seconds the predicate
(v > 100) is false, then the specification evaluates to true. On
the other hand, if the predicate (v > 100) is true for all time
between 0 and 30 seconds, then the subformula 2[0,20] (v >
100) will be true at any time between 0 and 10 seconds. This
means that the subformula (v > 100) ⇒ 2[0,20] (v > 100)
is true between 0 and 10 seconds. Thus, again, ϕ evaluates
to true, which means that ϕ is a tautology! This implies that
specification issues are not necessarily artifacts of the graphical
user interface and that they can happen even for the people who
are familiar with temporal logics.
This indicates that the specification elicitation can be a
major issue in testing and verification since effort can be
wasted in checking incorrect requirements, or even worse, the
system can pass the incorrect requirements. Clearly, this can
lead to a false sense of system correctness, which leads us
to the second question: What can be done automatically to
prevent specification errors in CPS?
In this work, we have developed a specification development framework that would enable the elicitation and debugging of specifications. The specification debugging algorithm
identifies invalid and wrong specifications. Namely, it performs
the following in order:
1 In

section V, we will define what we mean by wrong specifications.
on-line survey is available through: http://goo.gl/forms/YW0reiDtgi

2 The

1) Validity detection: the specification is unsatisfiable or a
tautology.
2) Redundancy detection: the formula has redundant conjuncts.
3) Vacuity detection: some subformulas do not affect the
satisfiability of the formula. This usually indicates some
misunderstanding in the requirements.
Summary of Contributions:
1) We present a debugging algorithm for a fragment of MITL
specifications.
2) We extend Linear Temporal Logic (LTL) [12] vacuity
detection algorithms [10] to real-time specifications in
MITL.
3) We present experimental results on specifications that
typically appear in CPS specifications.
The above contributions solve the specification correctness
problem for V I S PEC [21] requirements. The user of V I S PEC
can benefit from our feed-back and fix any reported issues.
II.

R ELATED WORKS

of it. In [10], they provide an algorithmic approach to detecting
vacuity and redundancy in LTL specifications.
Our work extends [10] and it is applied to a fragment of
MITL. We provide a new definition of vacuity with respect
to Boolean or real-value signals. To the best of our knowledge, vacuity of real-time properties such as MITL has not
been addressed yet. Although this problem is computationally
hard, due to the small size of the formulas, in practice the
computation problem is manageable.
III.

P RELIMINARIES

In this work, we take a general approach in modeling Cyber
Physical Systems (CPS). In the following, R is the set of real
numbers, R+ is the set of non-negative real numbers, Q is
the set of rational numbers, Q+ is the set of non-negative
rational numbers. Given two sets A and B, B A is the set of
all functions from A to B, i.e., for any f ∈ B A we have
f : A → B. We define 2A to be the power set of set A. We
fix T ∈ R+ to be the maximum time of a signal.
A. Metric Interval Temporal Logic

The challenge of developing formal specifications has been
studied in the past. The most relevant works appear in [4] and
[32]. In [4], the authors extend Message Sequence Charts and
UML 2.0 Interaction Sequence Diagrams to propose a scenario
based formalism called Property Sequence Chart (PSC). The
formalism is mainly developed for specifications on concurrent
systems. In [32], PSC is extended to Timed PSC which enables
the addition of timing constructs to specifications.
Specification debugging can also be considered in areas
such as system synthesis [30] and software verification [1].
In system synthesis, realizability is an important factor, which
checks whether the system is implementable given the constraints (environment) and requirements (specification) [15],
[24], [11], [30]. Specification debugging can also be considered
with respect to the environment for robot motion planing. In
[17], [23], the authors considered the problem where the original specification is unsatisfiable with the given environment
and robot actions. Then, they relax the specification in order
to render it satisfiable in the given domain.
One of the most powerful verification methods is model
checking [12] where the model of the system is evaluated
with respect to a specification. For example, let us consider
model checking with respect to LTL formulas. It is possible
that the model satisfies the specification but not in the intended
way. This may hide actual problems in the model. These satisfactions are called vacuous satisfactions. Antecedent failure
was the first problem that raised the vacuity as a serious
issue in verification [5], [6]. For example, ϕ = 2[0,5] (req ⇒
3[0,10] ack) is interpreted as “if at any time within the first 5
seconds, a request happens, then from that moment on within
the next 10 seconds, an acknowledge must happen”. Here, ϕ
can be vacuously satisfiable since it can be satisfied in all
systems in which a request never happens. Vacuity can be
addressed with respect to a model [3], [27], [19], [26] or
without a model [18], [10]. A formula is vacuous when it
can be simplified to a smaller equivalent formula. It has been
proven in [18] that a specification ϕ is satisfied vacuously in
all systems that satisfy it iff ϕ is equivalent to some mutations

71

Metric Temporal Logic (MTL) was introduced in [25]
in order to reason about the quantitative timing properties
of boolean signals. Metric Interval Temporal Logic (MITL)
is MTL where the timing constraints are not allowed to be
singleton sets. In the rest of the paper, we restrict our focus to a
fragment of MITL called Bounded-MITL(3,2) where the only
temporal operators allowed are Eventually (3) and Always
(2) operators with timing intervals. Formally, the syntax of
Bounded-MITL(3,2) is presented by the following grammar:
Definition 1 (Bounded-MITL(3,2) syntax):
φ ::= > | ⊥ | a | ¬a | φ1 ∧ φ2 | φ1 ∨ φ2 | 3I φ1 | 2I φ1
where AP is the set of atomic propositions and a ∈ AP , >
is True, ⊥ is False. Also, I is a nonsingular interval over Q+
with defined end-points. The interval I is right-closed.
Definition 2 (Bounded-MITL(3,2) semantics): Given a
time trace µ : [0, T ] → 2AP and t, t0 ∈ R, and an MITL
formula φ, the satisfaction relation (µ, t)  φ is inductively
defined:
(µ, t)  >
(µ, t)  a iff a ∈ µ(t)
(µ, t)  ¬a iff a 6∈ µ(t)
(µ, t)  ϕ1 ∧ ϕ2 iff (µ, t)  ϕ1 and (µ, t)  ϕ2
(µ, t)  ϕ1 ∨ ϕ2 iff (µ, t)  ϕ1 or (µ, t)  ϕ2
(µ, t)  3I ϕ1 iff ∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  ϕ1 .
(µ, t)  2I ϕ1 iff ∀t0 ∈ (t + I) ∩ [0, T ], (µ, t0 )  ϕ1 .
Where (t + I) creates a new interval I 0 where if I = [l, u]
then I 0 = [l + t, u + t].
A boolean signal µ satisfies a Bounded-MITL(3,2) formula
φ (denoted by µ  φ), iff (µ, 0)  φ.
The Implication (⇒) is defined as ψ ⇒ ϕ ≡ ¬ψ ∨ ϕ, and also
⊥ ≡ ¬>. In this paper, we assume that Bounded-MITL(3,2)

formula is in Negation Normal Form (NNF) where the negation
operation is only applied on atomic propositions. NNF is easily
obtainable by applying DeMorgan’s Law, i.e ¬3I ϕ ≡ 2I ¬ϕ
and ¬2I ϕ ≡ 3I ¬ϕ. For simplifying the presentation, when
we mention MITL we mean Bounded-MITL(3,2). Given
MITL formulas ϕ and ψ, ϕ satisfies ψ, denoted by ϕ |= ψ
iff ∀µ.µ |= ϕ ⇒ µ |= ψ.
B. Signal Temporal Logic
The logic and semantics can be extended to real-valued
signals through Signal Temporal Logic (STL) [29].
Definition 3 (Signal Temporal Logic [29]): Let
s : [0, T ] → Rm be a real-time signal, and P = {p1 , ..., pn }
be a collection of predicates or boolean functions of the form
pi : Rm → B where B = {>, ⊥} is a boolean value.
We define the STL formula ΦST L over predicates P using
MITL formula ΦM IT L over the atomic propositions AP . The
semantics of STL can be defined using MITL as follows:
1) Define a set of AP such that for each p ∈ P , there exist
some ap ∈ AP
2) For each signal s we define a µ such that ap ∈ µ(t) iff
p(s(t)) = >
3) ∀t (s, t)  ΦST L iff (µ, t)  ΦM IT L
C. Visual Specification Tool
The Visual Specification Tool (V I S PEC) [21] enables the
development of formal specifications for CPS. The graphical formalism enables reasoning on both timing and event
sequence occurrence. Consider the specification φcps =
2[0,30] ((speed > 100) ⇒ 2[0,40] (rpm > 4000)). It states that
whenever within the first 30 seconds, vehicle speed goes over
100, then from that moment on, the engine speed (rpm), for the
next 40 seconds, should always be above 4000. Here both the
sequence and timing of the events are of critical importance.
See Fig. 1 for the visual representation of φcps .

set of formulas that can be expressed by the proposed graphical
formalism:
S −→ ¬T | T
T −→ A | B | C
A −→ P | (P∧A) | (P⇒A)
B −→ 2I D | 3I D
C −→ 2I 3I D | 3I 2I D
D −→ p | (p⇒A) | (p∧A) | (p⇒B) | (p∧B)
P −→ p | 2I p | 3I p
where p is an atomic proposition. In the tool, the atomic
propositions are automatically derived from the templates.
For example the formula 2I 3I p can be generated using the
following parse tree S−→T−→C−→ 2I 3I D−→ 2I 3I p.
The graphical formalism was developed with the following
goals: a) The user interface is easy to use, i.e, it does not
have a high learning curve; b) The visual representation of the
requirements is clear and unambiguous; c) There is a one-toone mapping from the visual representation of the requirement
and the corresponding requirement in MTL. The graphical
formalism is mainly composed of the following: 1) Templates;
2) Relationships between templates.
Templates are used to define temporal logic operators,
their timing intervals, and the expected signal shape. A template configuration wizard guides the user in the development
process. The process is context dependent where each option
selection leads to a potentially different set of options for the
next step.
After the selection of the temporal operator, the user will
define the timing bounds for it. For specifications with temporal operators such as Eventually Always (32) and Repeatedly
Often and Finally (23), setting the timing bounds may be
a challenging task. To clarify this issue, the tool provides a
fill-in-the-blanks sentence format to the user. For example, if
the operator Eventually Always is selected, the user will have
to complete the following sentence with the timing bounds:
and
seconds, the signal will
“Eventually, between
become true, and from that point on, will stay true in the next
to
seconds”. The set timing intervals are visualized
with color shaded regions in the template.
The next step in the process is in defining whether the
predicate will evaluate to true when the signal is above
or below a set threshold. For example, for the Always (2)
operator, a signal is selected that is either always above or
below a specified threshold. Once either option is selected, a
signal that fits the requirement is automatically generated and
presented visually (See Fig. 1).

Fig. 1. Graphical representation of φcps = 2[0,30] ((speed > 100) ⇒
2[0,40] (rpm > 4000)).

Users develop specifications using a visual formalism
which can be translated to a Metric Temporal Logic formula.
The set of specifications that can be generated from this
graphical formalism is a proper subset of the set of MTL
specifications. Formally, the following grammar produces the

72

Relationships between templates enable the development
of more complex specifications. The three main relationships
between templates are the following: 1) Templates can be
placed in a sequence, where the last template is only considered if the previous templates are evaluated to true. Formally, it enables the definition of an implication relationship
between templates of the form φ ⇒ ψ. 2) Templates can be
grouped to establish a conjunction relationship of the form
φ ∧ ψ. This is indicated visually by a black box around the
templates. 3) Finally, the relative timing relationship enables
the definition of: a) Reactive response specifications of the
form 2(φ ⇒ M ψ) ; b) Non-strict sequencing specifications of

the form N (φ∧M ψ), where N and M are temporal operators.
This relationship is visually distinct in that the nested template
is tabbed in relation to the main template.
The variety of templates and the connections between them
allow users to express a wide variety of specifications as
presented in Table I.
IV.

E LICITATION F RAMEWORK FOR MITL

To enable the debugging of specifications, we must project
the STL predicate expressions into atomic propositions with
independent truth valuations. For example, consider the STL
specification φstl = 3[0,10] ((speed > 100) ∧ 3[0,10] (speed >
80)). In this case, the subformula 3[0,10] (speed > 80) does
not affect the satisfaction of the specification. This indicates
that there is an issue with the specification.
However, if we simply replace the predicate expressions
speed > 100 and speed > 80 with the atomic propositions
a and b, respectively, then the resulting MITL formula will
be φmitl = 3[0,10] (a ∧ 3[0,10] b). Thus, we lose information
about the intrinsic dependency between a and b and debugging
will not find the issue. In order to enable the logical analysis
of such formulas in our debugging process, we replace the
original predicate expressions with atomic propositions with
non-overlapping corresponding predicates (Boolean functions).
For this example, the resulting MITL specification should be
φmitl = 3[0,10] (q1 ∧ 3[0,10] (q1 ∨ q2 )) where q1 corresponds to
speed > 100 and q2 corresponds to 100 ≥ speed > 80. The
projection in the current implementation is conducted using a
brute-force algorithm that runs through all the combinations
of predicate expressions to find overlapping areas.
V I S PEC
Tool

MITL

Debugging

Specification

Revision Necessary

Fig. 2.

Specification Elicitation Framework

Validity

Redundancy

Vacuity

Specification
passed
debugging
checks

V I S PEC
Tool
Revision Necessary

Fig. 3.

Our framework for elicitation of MITL specifications is
presented in Fig. 2. Once a specification is developed using V I S PEC, it is translated into STL. Then, we create the
corresponding MITL formula from STL. Next, the MITL
specification is analyzed by the debugging algorithm which
returns an alert to the user in case the specification has
inconsistency or correctness issues. The debugging process is
explained in detail in the next section.

User Input

MITL
Specification

Specification Debugging

Vacuity. In brief, validity checking determines whether the
specification is satisfiable but not a tautology. Namely, if the
specification is unsatisfiable no system can satisfy it and if it is
a tautology every system can trivially satisfy it. For example,
p ∨ ¬p is a tautology.
Redundancy checking determines whether the specification
has no redundant conjunct when the specification is a conjunction of MITL formulas. For example, in the specification
p ∧ 2[0,10] p, the first conjunct is redundant. Sometimes redundancy is related to incomplete or erroneous requrements
where the user may have wanted to specify something else.
Therefore, the user should be notified.
Vacuity checking determines whether the specification has
a subformula that does not have any affect on the satisfaction
of the specification. For example ϕ = p ∨ 3[0,10] p is vacuous
since the first occurrence of p does not have any affect on the
satisfaction of ϕ.
Definition 4 (Wrong Specification): A specification which
is redundant or vacuous is called wrong.
The reason that we choose the term “wrong” is that
although this specification is logically valid, the specification
in its current representation does not reflect the intention of
the requirement in its natural language form. This is because
part of the specification is over-shadowed with the other
components.
The debugging process is presented in Fig. 3. First, given
a specification, a validity check is conducted. If a formula
does not pass a validity check then it means that there is a
major problem in the specification and the formula is returned
for revision. Therefore, redundancy and vacuity checks are not
relevant at that point. Similarly, if the specification is redundant
it means that it has a conjunct that does not have any affect on
the satisfaction of the specification and we return the redundant
conjunct for revision. Lastly, if the specification is vacuous it
is returned with the issue for revision by the user.
A. Redundancy Checking

Clearly, verifying a system with respect to incorrect specifications is pointless. Therefore, any inconsistencies or other
issues with the specification should be resolved. In the following, we present algorithms that can detect inconsistency and
correctness issues in specifications. This will help the user in
the elicitation of correct specifications.

Recall that a specification has a redundancy issue if one of
its conjuncts can be removed without affecting the models of
the specification. Before we formally present what redundant
requirements are, we have to introduce some notation. We
consider specification Φ as a conjunction of MITL subformulas
(ϕj ):
^k
ϕj
(1)
Φ=

Our specification debugging process conducts the following
checks in this order: 1) Validity, 2) Redundancy, and 3)

To simplify discussion, we will abuse notation and we will
associate a conjunctive formula with the set of its conjuncts.

V.

S PECIFICATION D EBUGGING FOR MITL

73

j=1

TABLE I.

C LASSES OF SPECIFICATIONS EXPRESSIBLE WITH THE GRAPHICAL FORMALISM

Specification Class

Explanation

Safety
Reachability
Stabilization
Oscillation

Specifications of the form 2φ used to define specifications where φ should always be true.
Specifications of the form 3φ used to define specifications where φ should be true at least once in the future (or now).
Specifications of the form 32φ used to define specifications that, at least once, φ should be true and from that point on, stay true.
Specifications of the form 23φ used to define specifications that, it is always the case, that at some point in the future, φ repeatedly
will become true.
Specifications of the form φ ⇒ ψ requires that ψ should hold when φ is true.
Specifications of the form 2(φ ⇒ M ψ), where M is temporal operator, used to define an implicative response between two
specifications where the timing of M is relative to timing of 2.
Specifications of the form φ ∧ ψ used to define the conjunction of two sub-specifications.
Specifications of the form N (φ ∧ M ψ), where N and M are temporal operators, used to define a conjunction between two
specifications where the timing of M is relative to timing of N .

Implication
Reactive Response
Conjunction
Non-strict Sequencing

That is:
Φ = {ϕj | j = 1, ..., k}

(2)

Similarly, {Φ\ϕi } represents the specification Φ where the
conjunct ϕi is removed:
{Φ\ϕi } = {ϕj | j = 1, ..., i − 1, i + 1, ..., k} =
^k
^i−1
ϕj ∧
j=1

j=i+1

ϕj

(3)

Whether {Φ\ϕi } represents a set or a conjunctive formula
will be clear from the context. Redundancy in specifications
is fairly common in practice due to the incremental additive
approach that system engineers take in the development of
specifications. In the following, we consider the redundancy
removal algorithm provided in [10] for LTL formulas and we
extend it to support MITL formulas.
Definition 5 (Redundancy of Specification): A
ϕi is redundant with respect to Φ if
^
ψ |= ϕi

conjunct

ψ∈{Φ\ϕi }

To reformulate, ϕi is redundant with respect to Φ if
{Φ\ϕi } |= ϕi . For example, in Φ = 3[0,10] (p ∧ q) ∧ 3[0,10] p ∧
2[0,10] q, the conjunct 3[0,10] (p ∧ q) is redundant with respect
to 3[0,10] p ∧ 2[0,10] q since 3[0,10] p ∧ 2[0,10] q |= 3[0,10] (p ∧ q).
In addition, 3[0,10] p is redundant with respect to 3[0,10] (p ∧
q) ∧ 2[0,10] q since 3[0,10] (p ∧ q) ∧ 2[0,10] q |= 3[0,10] p. This
method can catch both the issues and report them to the user.
Algorithm 1 finds redundant subformulas, if they exist and
it provides the list of subformulas that are redundant with
respect to Φ as the feedback to the user. It should be noted that
if a specification has nested subformulas in the conjunctive
form, then redundancy checking can be used to find the
redundant conjuncts. For example, ϕ = 3[0,10] (p ∧ 2[0,10] p)
can be checked by Algorithm 1 if p ∧ 2[0,10] p is given as input
to the algorithm instead of ϕ.
B. Vacuity Checking
Vacuity detection is used to ensure that all the subformulas of the specification contribute to the satisfaction of the
specification. In other words, the vacuity check enables the
detection of irrelevant subformulas in the specifications [10].
In the following, we provide the definition of MITL vacuity
with respect to signal.
Definition 6 (MITL Vacuity with respect to signal):
Given a signal T and an MITL formula ϕ. A subformula ψ

74

Algorithm 1 Redundancy Checking
Input: Φ (M IT L Specification)
Output: RLϕ a list of redundant formulas
1: RLϕ ← ∅
2: for each formula ϕi ∈ Φ do
3:
if (Φ\ϕi ) |= ϕi then
4:
RLϕ ← ϕi
5:
end if
6: end for

of ϕ does not affect the satisfiability of ϕ with respect to T if
and only if ψ can be replaced with any subformula θ without
changing the satisfiability of ϕ on T . A specification ϕ is
satisfied vacuously by T , denoted by T |=V ϕ, if there exists
ψ which does not affect the satisfiability of ϕ on T .
In the following, we extend the framework presented in
[10] to support MITL specifications. Let ϕ be a formula
in NNF where only predicates can be in the negated form.
A literal is defined as a predicate or its negation. For
formula ϕ the set of literals of ϕ is denoted by literal(ϕ)
and contains all the literals appearing in ϕ. For example if
ϕ = (¬p∧q)∨3[0,10] p∨2[0,10] q then literal(ϕ) = {¬p, q, p}.
Literal occurrences, denoted by litOccur(ϕ), is a multiset of
literals appearing in some order in ϕ, e.g., by traversal of the
parse tree. For the given example litOccur(ϕ) = {¬p, q, p, q}.
For each l ∈ litOccur(ϕ) we create the mutation of ϕ by
substituting the occurrence of l with ⊥. We denote the mutated
formula as ϕ[l ←⊥].
Definition 7 (M IT L Vacuity w.r.t. literal occurrence):
Given a signal T and an M IT L formula ϕ. Specification ϕ
is vacuously satisfied by T if there exists a literal occurrence
l ∈ litOccur(ϕ) such that T satisfies the mutated formula
ϕ[l ←⊥]. Formally, T |=V ϕ if ∃l ∈ litOccur(ϕ) s.t.
T |= ϕ[l ←⊥].
Theorem 1 (M IT L Vacuity with respect to Specification):
Assume that the specification Φ is a conjunction of MITL
formulas. If ∃ϕi ∈ Φ and ∃l ∈ litOccur(ϕi ), such that
Φ |= ϕi [l ←⊥], then Φ satisfies ϕi vacuously (Φ |=V ϕi ).
The proof is straightforward modification of the proofs
given in [10], [27]. We have added the proof in Appendix
(Section IX-A) for completeness. When we do not have the
conjunction in the specification (Φ = ϕ), we check the vacuity
of the formula with respect to itself. In other words, we check
whether the specification satisfies its mutation (ϕ |= ϕ[l ←⊥]
or ϕ |=V ϕ). Algorithm 2 finds the vacuous subformulas of
the specification similar to [10].

Algorithm 2 Vacuity Checking
Input: Φ (M IT L Specification)
Output: V Lϕ a list of vacuous formulas

the qtlsolver [7]. Therefore, we expect the values to be integer
when we analyse MITL formulas.
B. Specification Debugging Results

1: V Lϕ ← ∅
2: for each formula ϕi ∈ Φ do
3:
for each l ∈ litOccur(ϕi ) do
4:
if Φ |= ϕi [l ←⊥] then
5:
V Lϕ ← ϕi [l ←⊥]
6:
end if
7:
end for
8: end for

VI.

We utilize the debugging algorithm on a set of specifications developed as part of a usability study for the evaluation
of the V I S PEC tool [21]. The usability study was conducted
on two groups:

E XPERIMENTAL A NALYSIS

All the 3-level correctness analysis of MITL specifications
need satisfiability checking as the underlying tool [9]. In
validity checking we simply check whether the specification
and its negation are satisfiable. In general, in order to check
whether ϕ |= ψ, we should check whether ϕ =⇒ ψ is a
tautology, that is ∀µ, µ |= ϕ =⇒ ψ. This can be verified by
checking whether ¬(ϕ =⇒ ψ) is unsatisfiable.
Recall that ϕ =⇒ ψ is equivalent to ¬ϕ∨ψ. So we have to
check whether ϕ ∧ ¬ψ is unsatisfiable to conclude that ϕ |= ψ.
We use the above reasoning for redundancy checking as well as
for vacuity checking. For redundancy checking, {Φ\ϕi } ∧ ¬ϕi
should be unsatisfiable, in order to reason that {Φ\ϕi } |= ϕi .
For vacuity checking, Φ∧¬(ϕi [l ←⊥]) should be unsatisfiable,
in order to prove that Φ |= ϕi [l ←⊥].
A. MITL Satisfiability
As mentioned earlier, we can check all evaluations of a
specification using a satisfiability checker. In order to check
whether an MITL formula is satisfiable we use two publicly
available tools: qtlsolver3 and zot4 . The qtlsolver that we
used, translates MITL formulas into CLTL-over-clocks [7],
[9]. Constraint LTL (CLTL) is an extension of LTL where
predicates are allowed to be the assertions on the values of
non-Boolean variables [13]. That is, in CLTL, we are allowed
to define predicates using relational operators for variable over
domains like N and Z. Although satisfiability of CLTL in
general is not decidable, some variant of it is decidable [13].
CLTLoc (CLTL-over-clocks) is a variant of CLTL where
the clock variables are the only arithmetic variables that are
considered in the atomic constraints. It has been proved in [8]
that CLTLoc is equivalent to timed automata [12]. Moreover, it
can be polynomially reduced to decidable Satisfiable Modulo
Theories which are solvable by many SMT solvers such as
Z35 . The satisfiability of CLTLoc is PSPACE-complete [9] and
the translation from MITL to CLTLoc in the worst case can
be exponential [7]. One additional restriction over the MITL
formulas is that the lower bound and upper bound for the
intervals of MITL formulas should be integer in order to use
3 qtlsolver: A solver for checking satisfiability of Quantitative / Metric
Interval Temporal Logic (MITL/QTL) over Reals. Available from https:
//code.google.com/p/qtlsolver/
4 The zot bounded model/satisfiability checker. Available from https://code.
google.com/p/zot/
5 Microsoft Research, Z3: An efficient SMT solver. Available from http:
//research.microsoft.com/en-us/um/redmond/projects/z3/

75

1) Non-expert users: These are users who declared that they
have little to no experience in working with requirements.
The non-expert cohort consists of twenty subjects from
the academic community at Arizona State University.
Most of the subjects have an engineering background.
2) Expert users: These are users who declared that they
have experience working with system requirements. Note
that they do not necessarily have experience in writing
requirements using formal logics. The expert subject
cohort was comprised of ten subjects from the industry
in the Phoenix area.
Each subject received a task list to complete. The task
list contained ten tasks related to automotive system specifications. Each task asked the subject to formalize a natural
language specification through V I S PEC and generate an STL
specification. The task list is presented in Table II. Note
that the specifications were preprocessed and transformed
from the original STL formulas to MITL in order to run
the debugging algorithm. For example, specification φ3 in
Table III originally in STL was φ3ST L = 3[0,40] (((speed >
80) ⇒ 3[0,20] (rpm > 4000)) ∧ 2[0,30] (speed > 100)).
The STL predicate expressions (speed > 80), (rpm >
4000), (speed > 100) are mapped into atomic propositions
with non-overlapping predicates (Boolean functions) p1 , p2 , p3 .
The predicates p1 , p2 , p3 correspond to the following STL
representations: p1 ≡ speed > 100, p2 ≡ rpm > 4000, and
p3 ≡ 100 ≥ speed > 80.
In Table III, we present common issues with the developed specifications that our debugging algorithm would have
detected and alerted each subject if the tool were available
at the time of the study. Note that validity, redundancy and
vacuity issues are present in the specifications listed. It should
be noted that for specification φ3 , although finding the error
takes a significant amount of time, our algorithm can be used
off-line.
In Fig. 4, we present the runtime overhead of the three
stage debugging algorithm over specifications collected in
the usability study. In the first stage, 87 specifications go
through validity checking. Five specifications fail the test
and therefore they are immediately returned to the user. As
a result, 82 specifications go through redundancy checking,
where 9 fail the test. Lastly, 73 specifications go through
vacuity checking where 5 specification have vacuity issue.
The rest 68 specifications passed the tests. Note that in the
figure, two outlier data points are omitted from the vacuity
sub-figure for presentation purposes. The two cases were
timed at 39,618sec and 17,421sec. In both cases, the runtime
overhead was mainly because the zot software took hours to
determine that the modified specification is unsatisfiable (both
specifications where vacuous). The overall runtime of φ3 in
Table III is 39,645sec which includes the runtime of validity

and redundancy checking. The runtime overhead of vacuity
checking of φ3 (39,618sec) can be reduced by half because in
vacuity checking we run MITL satisfiability checking for all
literal occurrences. In particular, φ3 has four literal occurrences
where for two cases the zot took more than 19,500sec to
determine that the modified specification is unsatisfiable. We
can provide an option for early detection: as soon as an issue
is found (just one unsatisfiable detection) the software should
return the result which in φ3 case can lead to half of the
computation time of the original vacuity detection.
The blue circles in Fig. 4 represent the timing performance
in each test categorized by literal occurrence and number
of temporal operators. The red asterisks represent the mean
values and the dashed line is the linear interpolation between
them. In general, we observe an increase on the average
computation time as the literal occurrence and number of
temporal operators increases. Ideally, the performance analysis
should be conducted over a large set of artificially generated
benchmarks, i.e., specification formulas. However, developing
such benchmarks is a challenging problem on itself and thus
further research is required. The experimental results were
extracted from an Intel Xeon X5647 (2.993GHz) machine with
12 GB RAM.
VII.

D ISCUSSION

In the previous section, we mentioned that MITL satisfiability problem is a computationally hard problem. However,
we know that LTL satisfiability is in practice solvable faster
than MITL satisfiability [28]. We consider how we can use the
satisfiability of LTL formulas to decide about the satisfiability
of MITL formulas. Consider the following fragments of MITL
and LTL in NNF:
MITL(2): ϕ ::= > | ⊥ | p | ¬p | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 2I ϕ1
MITL(3): ϕ ::= > | ⊥ | p | ¬p | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 3I ϕ1
LTL(2): ϕ ::= > | ⊥ | p | ¬p | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 2ϕ1
LTL(3): ϕ ::= > | ⊥ | p | ¬p | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 3ϕ1
In the Appendix (Section IX-B), we prove that the satisfaction of a formula φM ∈ MITL(3) in NNF is related to
the satisfaction of an LTL version of φM called φL ∈ LTL(3)
where φL is identical to φM except that the every interval I in
φM is removed. For example, if φM = 3[0,10] (p∧q)∧3[0,10] p
then φL = 3(p ∧ q) ∧ 3p. In essence, if φM is satisfiable, then
φL is also satisfiable. Therefore, if φL is unsatisfiable then φM
is also unsatisfiable.
For 2 operator, satisfiability is dual of 3. Assume φ0M ∈
MITL(2) contains only 2 operator and φ0L ∈ LTL(2) is the
LTL version of φ0M . If φ0L is satisfiable, φ0M will also be
satisfiable.
Based on the above discussion, if the specification φM that
we intend to test/debug belongs to either category (Fragment)
of MITL(3) or MITL(2), then we can check the satisfiability
of its LTL version (φL ) and decide accordingly:

For example, if we have a formula φ = 3[0,10] p ∧ 2[0,20] p
we should check the satisfiability of φ0 = 2[0,10] ¬p ∧ 2[0,20] p
and φ00 = 3[0,10] p ∧ 3[0,20] ¬p for redundancy. Although in
φ the original formula does not belong to either MITL(3) or
MITL(2), its modified NNF version will fit in these categories
and we may benefit by the LTL satisfiability for φ0 and φ00 .
For vacuity checking, in rare occasions we may be able to
use LTL satisfiability if after manipulating/simplifying the
original specification and creating the NNF version, we can
categorize the resulting formula into MITL(3) or MITL(2)
fragments. We have currently not run any experiments using
LTL satisfiability, but we plan to run feasibility studies in the
future.
VIII.

We have presented a specification elicitation and debugging
framework that helps expert and non-expert users to produce
correct formal specifications. The debugging algorithm enables
the detection of logical inconsistencies in MITL specifications.
Our algorithm improves the elicitation process by providing
feedback to the users on validity, redundancy and vacuity
issues. The specification elicitation and debugging framework
will be integrated in the V I S PEC tool to simplify MITL
specification development for verification of CPS. As future
work, we will consider vacuity detection with respect to signals
and systems. This will enable improved analysis since some
issues can only be detected when considering both system and
specification.
ACKNOWLEDGMENT
This work was partially supported by NSF awards IIP1454143, CNS-1116136 and CNS-1350420.
R EFERENCES
[1]

[2]

[3]

[4]

[5]
[6]

[7]

- If φL ∈ LTL(3) is unsatisfiable, then φM is unsatisfiable.
- If φL ∈ LTL(2) is satisfiable, then φM is satisfiable.

[8]

In these two cases, we do not need to run MITL satisfiability. As a result LTL satisfiability checking is useful for
validity testing. For redundancy check it may also be useful.

76

C ONCLUSION AND F UTURE W ORK

G. Ammons, D. Mandelin, R. Bodı́k, and J. R. Larus. Debugging
temporal specifications with concept analysis. In Proceedings of the
ACM SIGPLAN 2003 Conference on Programming Language Design
and Implementation 2003, San Diego, California, USA, June 9-11, 2003,
pages 182–195, 2003.
Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan.
S-taliro: A tool for temporal logic falsification for hybrid systems. In
Tools and algorithms for the construction and analysis of systems,
volume 6605 of LNCS, pages 254–257. Springer, 2011.
R. Armoni, L. Fix, A. Flaisher, O. Grumberg, N. Piterman, A. Tiemeyer,
and M. Y. Vardi. Enhanced vacuity detection in linear temporal logic. In
Computer Aided Verification, 15th International Conference, CAV 2003,
Boulder, CO, USA, July 8-12, 2003, Proceedings, pages 368–380, 2003.
M. Autili, P. Inverardi, and P. Pelliccione. Graphical scenarios for
specifying temporal properties: an automated approach. Automated
Software Engineering, 14(3):293–340, 2007.
D. L. Beatty and R. E. Bryant. Formally verifying a microprocessor
using a simulation methodology. In DAC, pages 596–602, 1994.
S. Ben-David, D. Fisman, and S. Ruah. Temporal antecedent failure:
Refining vacuity. In CONCUR 2007 - Concurrency Theory, 18th
International Conference, CONCUR 2007, Lisbon, Portugal, September
3-8, 2007, Proceedings, pages 492–506, 2007.
M. Bersani, M. Rossi, and P. San Pietro. A tool for deciding the satisfiability of continuous-time metric temporal logic. Acta Informatica,
pages 1–36, 2015.
M. M. Bersani, M. Rossi, and P. S. Pietro. A logical characterization
of timed (non-)regular languages. In Mathematical Foundations of
Computer Science 2014 - 39th International Symposium, MFCS 2014,
Budapest, Hungary, August 25-29, 2014. Proceedings, Part I, pages
75–86, 2014.

TABLE II.
Task

Natural Language Specification

1.
2.
3.
4.
5.
6.
7.

In the first 40 seconds, vehicle speed should always be less than 160.
In the first 30 seconds, vehicle speed should go over 120.
At some point in time in the first 30 seconds, vehicle speed will go over 100 and stay above for 20 seconds.
At every point in time in the first 40 seconds, vehicle speed will go over 100 in the next 10 seconds.
It is not the case that, for up to 40 seconds, the vehicle speed will go over 100 in every 10 second period.
If, within 40 seconds, vehicle speed is above 100 then within 30 seconds from time 0, engine speed should be over 3000.
If, at some point in time in the first 40 seconds, vehicle speed goes over 80 then from that point on, for the next 30 seconds, engine speed
should be over 4000.
In the first 40 seconds, vehicle speed should be less than 100 and engine speed should be under 4000.
At some point in time in the first 40 seconds, vehicle speed should go over 80 and then from that point on, for the next 30 seconds, engine
speed should be over 4000.
If, at some point in time in the first 40 seconds, vehicle speed goes over 80 then from that point on, if within the next 20 seconds the
engine speed goes over 4000, then, for the next 30 seconds, the vehicle speed should be over 100.

Safety
Reachability
Stabilization
Oscillation
Oscillation
Implication
Reactive Response

8. Conjunction
9. Non-strict sequencing
10. Long sequence

TABLE III.

I NCORRECT SPECIFICATIONS FROM THE USABILITY STUDY IN [21], ERROR REPORTED TO THE USER BY THE DEBUGGING ALGORITHM , AND
ALGORITHM RUNTIME . F ORMULAS HAVE BEEN TRANSLATED FROM STL TO MITL.
φ
φ1
φ2
φ3
φ4
φ5

[9]

[10]
[11]

[12]
[13]
[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

TASK LIST WITH AUTOMOTIVE SYSTEM SPECIFICATIONS PRESENTED IN NATURAL LANGUAGE

Task (#) from Table II
Stabilization (3)
Stabilization (3)
Long sequence (10)
Oscillation (4)
Long sequence (10)

MITL Specification
3[0,30] p1 ∧ 3[0,20] p1
3[0,30] (p1 ⇒ 2[0,20] p1 )
3[0,40] (((p1 ∨ p3 ) ⇒ 3[0,20] p2 ) ∧ 2[0,30] p1 )
2[0,40] p1 ∧ 2[0,40] 3[0,10] p1
3[0,40] (p1 ∨ p3 ) ∧ 3[0,40] p2 ∧ 3[0,40] 2[0,30] p1

M. M. Bersani, M. Rossi, and P. San Pietro. Deciding the satisfiability
of mitl specifications. In Fourth International Symposium on Games,
Automata, Logics and Formal Verification,, volume 119 of EPTCS,
pages 64–78. Open Publishing Association, 2013.
H. Chockler and O. Strichman. Before and after vacuity. Form. Methods
Syst. Des., 34(1):37–58, Feb. 2009.
A. Cimatti, M. Roveri, V. Schuppan, and A. Tchaltsev. Diagnostic
information for realizability. In Verification, Model Checking, and
Abstract Interpretation, 9th International Conference, VMCAI 2008,
San Francisco, USA, January 7-9, 2008, Proceedings, pages 52–67,
2008.
E. M. Clarke, O. Grumberg, and D. A. Peled. Model Checking. MIT
Press, Cambridge, Massachusetts, 1999.
S. Demri and D. D’Souza. An automata-theoretic approach to constraint
LTL. Inf. Comput., 205(3):380–415, 2007.
A. Donze. Breach, a toolbox for verification and parameter synthesis
of hybrid systems. In Computer Aided Verification, volume 6174 of
LNCS, pages 167–170. Springer, 2010.
R. Ehlers and V. Raman. Low-effort specification debugging and
analysis. In Proceedings 3rd Workshop on Synthesis, SYNT 2014,
Vienna, Austria, July 23-24, 2014., pages 117–133, 2014.
G. Fainekos, S. Sankaranarayanan, K. Ueda, and H. Yazarel. Verification of automotive control applications using s-taliro. In Proceedings
of the American Control Conference, 2012.
G. E. Fainekos. Revising temporal logic specifications for motion planning. In IEEE International Conference on Robotics and Automation,
ICRA 2011, Shanghai, China, 9-13 May 2011, pages 40–45, 2011.
D. Fisman, O. Kupferman, S. Sheinvald-Faragy, and M. Y. Vardi. A
framework for inherent vacuity. In Hardware and Software: Verification
and Testing, 4th International Haifa Verification Conference, HVC 2008,
Haifa, Israel, October 27-30, 2008. Proceedings, pages 7–22, 2008.
A. Gurfinkel and M. Chechik. How vacuous is vacuous? In Tools
and Algorithms for the Construction and Analysis of Systems, 10th
International Conference, TACAS 2004, Held as Part of the Joint
European Conferences on Theory and Practice of Software, ETAPS
2004, Barcelona, Spain, March 29 - April 2, 2004, Proceedings, pages
451–466, 2004.
B. Hoxha, H. Bach, H. Abbas, A. Dokhanchi, Y. Kobayashi, and
G. Fainekos. Towards formal specification visualization for testing and
monitoring of cyber-physical systems. In Int. Workshop on Design and
Implementation of Formal Tools and Systems. October 2014.
B. Hoxha, N. Mavridis, and G. Fainekos. V I S PEC: a graphical tool for
easy elicitation of MTL requirements. In Proceedings of the IEEE/RSJ
International Conference on Intelligent Robots and Systems, Hamburg,
Germany, September 2015.

77

[22]

[23]

[24]

[25]
[26]

[27]
[28]

[29]

[30]

[31]

[32]

Reporting the errors
3[0,30] p1 is redundant
ϕ is a tautology
ϕ is vacuous: ϕ |= ϕ[p3 ←⊥]
2[0,40] 3[0,10] p1 is redundant
3[0,40] (p1 ∨ p3 ) is redundant

Runtime (Sec.)
14
7
39645
29
126

X. Jin, A. Donzé, J. Deshmukh, and S. A. Seshia. Mining requirements
from closed-loop control models. In Proceedings of the International
Conference on Hybrid Systems: Computation and Control (HSCC),
April 2013.
K. Kim, G. E. Fainekos, and S. Sankaranarayanan. On the revision
problem of specification automata. In IEEE International Conference
on Robotics and Automation, ICRA 2012, 14-18 May, 2012, St. Paul,
Minnesota, USA, pages 5171–5176, 2012.
R. Könighofer, G. Hofferek, and R. Bloem. Debugging formal
specifications: a practical approach using model-based diagnosis and
counterstrategies. STTT, 15(5-6):563–583, 2013.
R. Koymans. Specifying real-time properties with metric temporal logic.
Real-Time Systems, 2(4):255–299, 1990.
O. Kupferman, W. Li, and S. A. Seshia. A theory of mutations with
applications to vacuity, coverage, and fault tolerance. In Proceedings
of the 2008 International Conference on Formal Methods in ComputerAided Design, FMCAD ’08, pages 25:1–25:9, Piscataway, NJ, USA,
2008. IEEE Press.
O. Kupferman and M. Y. Vardi. Vacuity detection in temporal model
checking. STTT, 4(2):224–233, 2003.
J. Li, L. Zhang, G. Pu, M. Y. Vardi, and J. He. LTL satisfiability
checking revisited. In 2013 20th International Symposium on Temporal
Representation and Reasoning, Pensacola, FL, USA, September 26-28,
2013, pages 91–98, 2013.
O. Maler and D. Nickovic. Monitoring temporal properties of continuous signals. In Proceedings of FORMATS-FTRTFT, volume 3253 of
LNCS, pages 152–166, 2004.
V. Raman and H. Kress-Gazit. Analyzing unsynthesizable specifications for high-level robot behavior using ltlmop. In Computer Aided
Verification - 23rd International Conference, CAV 2011, Snowbird, UT,
USA, July 14-20, 2011. Proceedings, pages 663–668, 2011.
H. Yang, B. Hoxha, and G. Fainekos. Querying parametric temporal
logic properties on embedded systems. In Testing Software and Systems,
pages 136–151. Springer, 2012.
P. Zhang, B. Li, and L. Grunske. Timed property sequence chart.
Journal of Systems and Software, 83(3):371–390, 2010.

IX.

A PPENDIX

A. Proof of Theorem 1
Proof: In order to show that ϕi is satisfied vacuously with
respect to Φ, we must show that if Φ |= ϕi [l ←⊥], then the
mutated specification is equivalent to the original specification.
In other words, we should show that if Φ |= ϕi [l ←⊥], then

Validity
200
Time (sec)

Time (sec)

200
100

0

1

2

3
Literal Occurence

4

100

0

5

1

2
3
4
No. of Temporal Operators

5

1

2
3
4
No. of Temporal Operators

5

2
3
4
No. of Temporal Operators

5

Redundancy
150
Time (sec)

Time (sec)

150
100
50
0

1

2

3
Literal Occurence

4

100
50
0

5

Vacuity
1500
Time (sec)

Time (sec)

1500
1000
500
0

1

2

3
Literal Occurence

4

1000
500
0

5

1

Fig. 4. Runtime overhead of the three stages of the debugging algorithm over user-submitted specifications. Timing results are presented over literal occurrence
and number of temporal operators.

({Φ\ϕi } ∪ ϕi [l ←⊥]) ≡ Φ . If the mutated specification
is equivalent to the original specification, then the original
specification is vacuously satisfiable in any system. That is,
the specification is inherently vacuous [18], [10]. We already
know that if Φ |= ϕi [l ←⊥], then Φ =⇒ ϕi [l ←⊥] and
trivially Φ =⇒ ϕi [l ←⊥] ∪ {Φ\ϕi }. Now we just need to
prove the other direction. We need to prove that when ϕi is in
the negation normal form, then ϕi [l ←⊥] =⇒ ϕi . Since we
replace only one specific literal occurrence of ϕ with ⊥, the
rest of the formula remains the same. Therefore, it should be
noted that ϕi [l ←⊥] does not modify any l0 ∈ litOccur(ϕi )
where l0 6= l.
Base: Case ϕi = l or ϕi = l0 6= l
We know that ⊥ =⇒ l and l0 =⇒ l0 . Therefore
ϕi [l ←⊥] =⇒ ϕi .
Induction Hypothesis: ∀ϕj , ϕj [l ←⊥] =⇒ ϕj
Induction Step: We will separate the case into unary and
binary operators.
Before providing the cases we should review the positively
monotonic operators [27]. According to MITL semantics,
f ∈ {2I , 3I } and g ∈ {∧, ∨} are positively monotonic, i.e.
for every MITL formulas ϕ1 and ϕ2 in NNF with ϕ1 =⇒ ϕ2 ,
we have f (ϕ1 ) =⇒ f (ϕ2 ). Also, for all MITL formulas ϕ0
in NNF, we have g(ϕ1 , ϕ0 ) =⇒ g(ϕ2 , ϕ0 ) and g(ϕ0 , ϕ1 ) =⇒
g(ϕ0 , ϕ2 ).
Case 1: ϕi = f (ϕj ) where f ∈ {2I , 3I }. Since f is
positively monotonic, we have that ϕj [l ←⊥] =⇒ ϕj implies

78

f (ϕj [l ←⊥]) =⇒ f (ϕj ). Thus,
f (ϕj )[l ←⊥] = f (ϕj [l ←⊥]) =⇒ f (ϕj ) = ϕi . As a result
ϕi [l ←⊥] =⇒ ϕi .
Case 2: ϕi = g(ϕj1 , ϕj2 ) where g ∈ {∧, ∨} Since g is
positively monotonic, we have that ϕj1 [l ←⊥] =⇒ ϕj1 ,
and ϕj2 [l ←⊥] =⇒ ϕj2 implies
g(ϕj1 [l ←⊥], ϕj2 [l ←⊥])
=⇒
g(ϕj1 , ϕj2 ) . Thus,
g(ϕj1 , ϕj2 )[l ←⊥] = g(ϕj1 [l ←⊥], ϕj2 [l ←⊥])
=⇒
g(ϕj1 , ϕj2 ) = ϕi . As a result ϕi [l ←⊥] =⇒ ϕi .
Since ϕi [l ←⊥] =⇒ ϕi we can have:
{Φ\ϕi } ∪ ϕi [l ←⊥] =⇒ {Φ\ϕi } ∪ ϕi which is equivalent to
{Φ\ϕi } ∪ ϕi [l ←⊥] =⇒ Φ
B. Proofs of MITL fragments
We consider two MITL(3,2) fragments, denoted
MITL(2), and MITL(3). In this proof we assume that all
formulas are in NNF. We also consider LTL(3,2) as the set
of LTL formulas (with continuous semantics) that contains
only 3 and 2 as temporal operators. In the following we
provide the continuous semantics of LTL(3,2) over traces
with bounded duration. Semantics of LTL(3,2) over bounded
time traces can be defined as follows:
Definition 8 (LTL(3,2) continuous semantics): Given a
timed trace µ : [0, T ] → 2AP and t, t0 ∈ R, and an LTL(3,2)
formula φ, the satisfaction relation (µ, t)  φ for temporal
operators is inductively defined:

(µ, t)  3φ1 iff ∃t0 ∈ [t, T ] s.t (µ, t0 )  φ1 .

If ϕ ∈ MITL(3) then Lt ([ϕ]LT L ) ⊆ Lt (ϕ) (immediate from
set theory). Thus, for all timed traces µ, µ 6 [ϕ]LT L implies
that µ 6 ϕ.

(µ, t)  2φ1 iff ∀t ∈ [t, T ], (µ, t )  φ1 .
0

0

We will consider two LTL(3,2) fragments denoted LTL(2),
and LTL(3). The syntax of MITL and LTL fragments are as
presented in Section VII.
We define the operator [φ]LT L which can be applied to
any MITL(3,2) formula and removes its interval constraints
to create a new formula in LTL(3,2). For example if φ =
3[0,10] (p ∧ q) ∧ 3[0,10] p ∧ 2[0,10] q, then [φ]LT L = 3(p ∧ q) ∧
3p ∧ 2q. As a result, for any φ ∈ MITL(3, 2) there exists
a ψ ∈ LTL(3, 2) where ψ = [φ]LT L . For each MITL(3, 2)
formula φ, the language of φ denoted L(φ) is the set of all
timed traces that satisfy φ: µ  φ iff µ ∈ L(φ). Similarly, for
any ψ ∈ LTL(3, 2), the language of ψ denoted L(ψ) is the
set of all timed traces that satisfy ψ: µ0  ψ iff µ0 ∈ L(ψ).
Based on set theory, it is trivial to prove that A ⊆ B and
C ⊆ D implies A ∪ C ⊆ B ∪ D and A ∩ C ⊆ B ∩ D.
Theorem 2: For any formula ϕ ∈ MITL(3), and t ∈ [0, T ]
we have Lt (ϕ) ⊆ Lt ([ϕ]LT L ) where Lt (ϕ) = {µ | (µ, t) 
ϕ}. In other words for all timed trace µ we have (µ, t)  ϕ
implies (µ, t)  [ϕ]LT L .
Proof: We use structural induction to prove that Lt (ϕ) ⊆
Lt ([ϕ]LT L )
Base: if ϕ = >, ⊥, p, ¬p, then [ϕ]LT L = ϕ and Lt (ϕ) ⊆
Lt ([ϕ]LT L )
Induction Hypothesis: We assume that there exist ϕ1 , ϕ2 ∈
MITL(3) where for all t ∈ [0, T ], Lt (ϕ1 ) ⊆ Lt ([ϕ1 ]LT L ) and
Lt (ϕ2 ) ⊆ Lt ([ϕ2 ]LT L )
Case 1: For Binary operators ∧, ∨ we can use the
union and intersection properties. In essence, for all formulas ϕ1 , ϕ2 we have Lt (ϕ1 ∨ ϕ2 ) = Lt (ϕ1 ) ∪ Lt (ϕ2 )
and Lt (ϕ1 ∧ ϕ2 ) = Lt (ϕ1 ) ∩ Lt (ϕ2 ). According to the
IH Lt (ϕ1 ) ⊆ Lt ([ϕ1 ]LT L ) and Lt (ϕ2 ) ⊆ Lt ([ϕ2 ]LT L );
therefore, Lt (ϕ1 ) ∩ Lt (ϕ2 ) ⊆ Lt ([ϕ1 ]LT L ) ∩ Lt ([ϕ2 ]LT L ) and
Lt (ϕ1 ) ∪ Lt (ϕ2 ) ⊆ Lt ([ϕ1 ]LT L ) ∪ Lt ([ϕ2 ]LT L ). As a result,
Lt (ϕ1 ∧ ϕ2 ) ⊆ Lt ([ϕ1 ]LT L ∧ [ϕ2 ]LT L ) = Lt ([ϕ1 ∧ ϕ2 ]LT L ),
and Lt (ϕ1 ∨ ϕ2 ) ⊆ Lt ([ϕ1 ]LT L ∨ [ϕ2 ]LT L ) = Lt ([ϕ1 ∨
ϕ2 ]LT L ).
Case 2: For the temporal operator 3, we need to compare
the semantics of MITL(3) and LTL(3). Recall that
(µ, t)  3I ϕ1 iff ∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  ϕ1 .
(µ, t)  3ϕ1 iff ∃t0 ∈ [t, T ] s.t (µ, t0 )  ϕ1 .
Recall that t00 ∈ (t + I) ∩ [0, T ] implies t00 ∈ [t, T ] since the
left bound of I is nonnegative.
According to the semantics, ∀µ.(µ, t)  3I ϕ1 implies
∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  ϕ1 implies
∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  [ϕ1 ]LT L according to IH
(Lt0 (ϕ1 ) ⊆ Lt0 ([ϕ1 ]LT L )).
If ∃t0 ∈ (t + I) ∩ [0, T ] s.t (µ, t0 )  [ϕ1 ]LT L then
∃t0 ∈ [t, T ] s.t (µ, t0 )  [ϕ1 ]LT L since t0 ∈ (t + I) ∩ [0, T ]
implies t0 ∈ [t, T ].
Moreover, (µ, t0 )  [ϕ1 ]LT L implies that (µ, t) 
3[ϕ1 ]LT L ≡ [3ϕ1 ]LT L .
As a result, ∀µ. (µ, t)  3I ϕ1 =⇒ (µ, t)  [3ϕ1 ]LT L so
Lt (3I ϕ1 ) ⊆ Lt ([3ϕ1 ]LT L ).

79

Corollary 1: For any ϕ ∈ MITL(3), if [ϕ]LT L ∈ LTL(3)
is unsatisfiable, then ϕ is unsatisfiable.
Theorem 3: For any formula ϕ ∈ MITL(2), and t ∈ [0, T ],
we have Lt ([ϕ]LT L ) ⊆ Lt (ϕ), where Lt (ϕ) = {µ|(µ, t)  ϕ}.
In other words ∀µ(µ, t)  [ϕ]LT L =⇒ (µ, t)  ϕ
Proof: Similar to Theorem 2, we can apply structural
induction for the proof of Theorem 3.

2009 30th IEEE Real-Time Systems Symposium

Robustness of Model-based Simulations
Georgios E. Fainekos, Sriram Sankaranarayanan, Franjo Ivančić, and Aarti Gupta
NEC Laboratories America, 4 Independence Way, Princeton, NJ 08540, USA
Email: {fainekos, srirams, ivancic, agupta}@nec-labs.com
register. As a result, the accumulated errors caused a drift
in the computed times when the system was operational for
many hours. Ultimately, this led to a failure to track and
intercept incoming missiles.
Another – more subtle – example, is provided by Loh
et al. [23] and earlier by Rump [29]. Consider the function
f (a, b) = (333.75−a2)b6 +a2 (11a2 b2 −121b4 −2)+5.5b8 +
a
2b with a = 77617 and b = 33096. Using round-to-nearest
IEEE-754 arithmetic [31], the f function evaluates to (under
different precision)

Abstract—This paper proposes a framework for determining
the correctness and robustness of simulations of hybrid systems.
The focus is on simulations generated from model-based design
environments and, in particular, Simulink. The correctness and
robustness of the simulation is guaranteed against floatingpoint rounding errors and system modeling uncertainties.
Toward that goal, self-validated arithmetics, such as interval
and affine arithmetic, are employed for guaranteed simulation
of discrete-time hybrid systems. In the case of continuous-time
hybrid systems, self-validated arithmetics are utilized for overapproximations of reachability computations.
Keywords-Robustness; Simulation; Hybrid systems; Model
Validation and Analysis; Floating-point arithmetic;

1.172604
(32-bit)
1.1726039400531786
(64-bit)
1.1726039400531786318588349045201838 (128-bit)

I. I NTRODUCTION
Model-based design has vastly simplified the development of embedded systems. Design tools such as Matlab/Simulink, MapleSim and Scade have improved the process of system design. Tools for automatically generating
source code from these designs have vastly shorten the time
to market. However, verification of these models remains
just as complex and costly. Currently, extensive testing under
different operating conditions is performed until the design
team is satisfied that their design adheres to some coverage
requirements.
In practice, however, testing does not explore all critical
inputs. In addition, differentiating between an interesting
and a non-interesting test-case is not straightforward. This
paper considers the problem of evaluating tests in order to
showcase failures of the robustness property. That is, we
determine test trajectories that under some small perturbation
– usually due to uncertainty or internal computation errors
– could cause the system to diverge significantly from the
expected behavior, and potentially lead to failures. Note
that computational errors due to floating/fixed-points are
frequently ignored by many verification techniques for realtime and hybrid systems. Furthermore, our approach ensures
that the test cases that exhibit non-robust behavior will be
of interest to the system designer.
The Patriot missile defense system failure [5] is a wellknown example of the type of bugs that we target in this
paper. Therein, the software, which estimated the future
position of the incoming missile based on the velocity and
the last position as returned by the radar, modeled time
in increments of 0.1 sec. However, 0.1 itself could not be
accurately represented in the underlying 24-bit fixed-point
1052-8725/09 $26.00 © 2009 IEEE
DOI 10.1109/RTSS.2009.26

By increasing the precision, we seem to derive more accurate
results. However, this is deceiving since not even the sign is
correct in the above computations. The actual result, within
one unit of the last digit, is
f (a, b) = −0.827396059946821368141165095479816
These two examples demonstrate that our simulations could
very well have undetected functional errors without the
existence of any correctness errors (bugs) in the model.
For such computation errors and, also, for model uncertainties, our contribution in this paper is a framework for
detecting the robustness of Simulink simulations. In detail,
we developed a suit of tools called RobSim in Matlab
for testing the robustness of discrete and continuous-time
Simulink models. The advantage of our approach is that
we do not have to translate the Simulink model into some
other equivalent formalism, but we operate directly on the
Simulink model itself. Thus, we remain faithful to Simulink
semantics. Towards this objective, we have also produced
the following results and implementations. First, we have
built AALab (Affine Arithmetic Laboratory). AALab is an
Affine Arithmetic (AA) [10] toolbox in Matlab that allows
AA object manipulation with floating-point rounding control
in a transparent way to the user. Second, we have refined the
theory of linear system reachability in order to guarantee the
correctness of Simulink numerical simulations under model
uncertainties and, most importantly, under floating-point
rounding uncertainties. The next section provides further
details on the exact problem that we address in this paper.
345

II. P ROBLEM D EFINITION
Our focus is on the investigation of the robustness of
Simulink model simulations with respect to numerical and
floating-point rounding errors under possible parametric
uncertainties. Before proceeding on giving details on the
problem itself and the proposed solutions, we need to define
what we mean by robustness. The notion of robustness can
have different meanings under different contexts.
Intuitively, in the context of system simulation and testing,
a robust trajectory would be one that under small perturbations would exhibit the same qualitative behavior [17]. In
certain cases, such questions can be answered by control
theory even under the presence of floating-point rounding or
quantization errors [27]. However in general, this problem
cannot be addressed analytically in systems where the lowlevel system dynamics are governed by complex high-level
logic such as in hybrid automata [17].
Thus, we approach the problem from a testing perspective. That is, given a model of a system and some initial
conditions and parameter values, we would like to detect
points in time where the simulation trajectory of the system
does not capture the intended behavior. In particular, we first
study the following problem.
Problem 1: Given a discrete-time Simulink model D with
uncertain initial conditions X0 and parameters P , determine
points in time when the Simulink simulation trajectory is
not robust.
In this problem, the Simulink model D already contains
the initial conditions x0 and parameter values p as well as
the initial t0 and final tn simulation times and sampling step.
Formally speaking, system D can be captured by a system
of difference equations fjd , j ∈ Jd such that
x(k + 1) = fjd (x(k), u(k), p, k)

Figure 1.

A continuous-time Simulink model.

the system dynamics fjd for all the possible parameter values
and, moreover, take into account computation errors.
Now, we can formalize our proposed notion of robustness.
Definition 1: A trajectory x of a Simulink model is robust
if all the trajectories x under internal (model parameters)
and external (input) uncertainties and computation errors
have the same trajectory of indices as x, that is, dx = dx .
Informally, the above definition states that the system
should exhibit the same high-level behavior under all given
conditions and computation errors. Our goal is to ascertain
points in the system trajectory which are not robust. The following example, which is the running example of this paper,
presents the basic idea behind simulation non-robustness.
Example 1: As an example consider the discretized system of the continuous-time model in Fig. 1. The model
contains a switch block which determines which gain is
going to be used in the feedback loop. If the switch signal
(signal s in figure) is larger than 0.4, then “Gain” is selected
otherwise “Gain1” is selected. In this simple case, we want
to detect situations where the numerical simulation computes
a signal with value greater or equal to 4, e.g., for some k,
s(k) = 4.2, but the guaranteed simulation gives bounds on s
which include 4, e.g., [s(k)] = [3.9, 4.5]. This means that it
could be the case that at that point in time the system could
exhibit different dynamical behavior from the one used in
the numerical simulation. Such cases are reported to the user.

(1)

where k ∈ N is the current point in time, x : N → Rn is
the solution of system (1) (we assume that a unique solution
exists), u : N → Rq is an input to the system and p ∈ P ⊆
Rr is a vector modeling the parameters of the system. Here,
N denotes the set of the natural numbers and R the set of
reals. In system (1), at each point in time k, the system
dynamics are governed by a unique difference equation fjd ,
i.e., the system is deterministic. Without going into details,
the system dynamics fjd are chosen according to a relation
Gdj on x(k), x(k+1) and u(k). Each solution x(·) of system
(1) has a corresponding trajectory of indices dx : N → Jd
indicating which system dynamics were active at the current
point in time.
Assume that the set of initial conditions as well as the
parameters and the inputs to the system are not precisely
known, that is, x0 ⊆ Rn , p ⊆ P and u ⊆ Rq respectively.
Then, theoretically for some k0 ≤ kf ∈ N and a fixed j ∈
Jd , we could compute a set of trajectories x : [k0 , kf ] →
P(Rn ), which represent the evolution of the system under

The solution of Problem 1 is presented in Section IV-A. In
this paper, we also present some results toward the solution
of the above problem for continuous-time Simulink models.
Problem 2: Given a continuous-time Simulink model C
with piece-wise continuous dynamics and a set of uncertain
initial conditions X0 and parameters P , determine points in
time when the Simulink simulation trajectory is not robust.
Similar to the discrete-time case, system C can be captured
by a system of linear ordinary differential equations (ODEs):
ẋ(t) = Aj (p(t))x(t) + Bj (p(t))u(t) + hj (p(t))

(2)

where j ∈ Jc is a set of indices, t ∈ R+ (non-negative
reals) is the current point in time, x : R+ → Rn is the
solution of system (2) (again, we assume that a unique
solution exists), u : R+ → Rq is an input to the system,
p : R+ → P ⊆ Rr is a continuous function modeling the
parameters of the system and Aj , Bj , hj are appropriately
346

In IA every quantity [x] is essentially an interval [x] =
[x, x], where the bounds x = inf [x] and x = sup [x] range
over a particular field and x ≤ x. In this paper, we will
consider the fields of the real numbers R and an “abstract”
field of floating point numbers F. The corresponding sets
of intervals will be denoted by IR and IF, respectively. The
purpose of each such interval is to model potential uncertainties in the quantities and to capture internal computation
errors such as rounding errors.
All the standard arithmetic operations have a corresponding operation in IA.
 For example, if x, y ∈ IR, then we
have [x, x] + y, y = [x + y, x + y] and [x, x] y, y =
[min({xy, xy, xy, xy}), max({xy, xy, xy, xy})]. Whenever
we perform an operation of an interval with a real number
a, we implicitly assume that the real number is a degenerate
interval, i.e., [a] = [a, a].
In this paper, we will also be using interval vectors
and interval matrices. For example, an n-ordered tuple of
intervals [[x1 , x1 ], . . . , [xn , xn ]]T is an interval vector [x].
In the following, we will also be using the notation x
to denote the interval vector [−x, x]n for some n ≥ 1.
Similarly, we define m × n interval matrices as members of
IRm×n or IFm×n . The IA operations on vectors and matrices
are the natural extensions over the real arithmetic operations.
The concept of norm plays an important role in the
analysis of properties of vectors and matrices. In order
to define the infinity norm for interval matrices, we need
to first define the absolute value of an interval number:
| [x] | := max({|x|, |x|}). Note that the properties of the
absolute value are preserved, i.e., for x, y ∈ IR, we have
| [x] + [y] | ≤ | [x] | + | [y] | and | [x] [y] | = | [x] || [y] |. Recall
that in the case of matrices, the induced norm
nfor an m × n
matrix A is defined as A∞ = max1≤i≤m j=1 |aij |. The
extension of the definition of the infinity norm to interval
matrices is simply  [A] ∞ =  max({|A|, |A|})∞ , where
the absolute value and the maximum are considered elementwise. Finally, we should remark that both the absolute value
and the norm are not interval numbers.
In this work, we are particularly interested in using IA in
order to capture floating-point rounding errors. For example,
consider the number 0.1 which is not exactly representable in
machine arithmetic. IA allows us to capture this number by
defining an interval [↓(0.1) , ↑(0.1)], where ↓(·) and ↑(·) are
the rounding-down and up operations respectively as defined
in IEEE Floating-Point Standard [31]. In the following, we
will also be using the notation 
(x) = [↓(x) , ↑(x)] in order
to bound the real value of a number. In a slight abuse of
notation, we will also use 
(exp) to imply that the operations
in the expression exp are performed using IA even though
the operands are floating-point numbers. Moreover, when we
perform IA operations over floating-point numbers, we have
to control the rounding mode accordingly in order to enclose
the real value of the operation.
if x, y ∈ IF,


For example,
then we have [x, x] + y, y = [↓ x + y , ↑(x + y)]. For IA

sized matrices (which are continuous with respect to the
parameter vector p). At each point in time t, the system
dynamics are governed by a unique differential equation
ẋ = Aj (p(t))x(t) + Bj (p(t))u(t) + hj (p(t)). As before,
the system dynamics are chosen according to whether a
relation Gcj on x(t), ẋ(t) and u(t) is true. Each solution
x(·) of system (2) has a corresponding trajectory of indices
dx : R+ → Jc indicating which system dynamics were
active at each point in time.
Analogous to the discrete-time case, we might want to
study the behavior of the continuous-time model under
uncertain initial conditions x0 ⊆ Rn , parameters p(t) ⊆ P
and/or inputs u(t) ⊆ Rq . Then, theoretically for some
t0 ≤ tf and a fixed j ∈ Jc , we could compute a set
of trajectories x : [t0 , tf ] → P(Rn ), which represent the
evolution of the system under the system dynamics (2) for
all the possible parameter values and, moreover, take into
account computation errors.
Definition 1 also holds for continuous-time systems.
However, one additional issue that appears in the case of
continuous-time systems is the correctness of the computed
simulation trajectory. In detail, the algorithm employed for
the numerical solution of the ODEs affects the quality of
the resulting simulation and, in some cases, the solution
might even diverge from the real solution. Therefore, in the
continuous-time case, we also report such cases. The details
of the proposed approach appear in Section IV-B.
The solutions to Problems 1 and 2 enable also the robust
simulation of mixed-signal Simulink models. Such models
contain both continuous and discrete-time components. In
Section IV-C, we present some preliminary results toward
the solution of the following problem.
Problem 3: Given a mixed-signal Simulink model M
with discrete and continuous-time components that satisfy
the assumptions of Problems 1 and 2, respectively, and a
set of uncertain initial conditions X0 and parameters P ,
determine points in time when the Simulink simulation
trajectory is not robust.
As a by-product of the solution to the above problem,
we obtain a reachability algorithm for mixed-signal systems
under input, parameter and computation uncertainties. To the
best of our knowledge, this is the first time that this problem
is addressed.
III. T HEORETICAL BACKGROUND
In this section, we review some basic results and notation
that are necessary for presenting the results in this paper.
A. Interval Arithmetic
Interval arithmetic (IA) [25] is one of the first computation models that enabled in an efficient way self-validating
computations. IA has proven to be a valuable tool in a variety
of engineering applications [16]. More related to our work
is the application of IA to reachability problems [14], [28].

347

computations, we use the IntLab library [30] in Matlab.
IA exhibits some of the usual properties, i.e., it is associative and commutative. Moreover, it is inclusion monotone.
Namely, if [x ] ⊆ [x] and [y  ] ⊆ [y], then [x ] ◦ [y  ] ⊆
[x] ◦ [y] where ◦ ∈ {+, −, ×, ÷}. However, IA has some
important deficiencies. In detail, it is sub-distributive, i.e.,
[x] ([y] + [z]) ⊆ [x] [y] + [x] [z] and, also, it has no additive
and no multiplicative inverse. In general, in IA, there is
no information maintained concerning the relationship of
two symbolic values. Consider for example the interval
[x] = [−0.1, 0.1], then [x] − [x] = [−0.2, 0.2]. Obviously,
this is too coarse an overapproximation. The tightest possible
bound is the interval [0, 0]. In feedback systems, such
overapproximations will result in a quick divergence of
the solution enclosure. Fortunately, symbolic computations
using affine arithmetic can resolve this issue.

mention that whenever we mix interval and affine quantities
in an expression we implicitly assume that the interval
variable is converted into an affine variable (see [9]).
Similar to IA, we can define affine vectors and matrices as
elements of ARn (AFn ) and ARm×n (AFm×n ), respectively.
Furthermore, the infinity norm of an affine matrix is simply
the infinity norm of the corresponding interval matrix, i.e.,
 A
 ∞ := [A
]∞ .
Since one of our goals is to account for computation
errors, we must take into account floating-point rounding errors. As opposed to IA, considering floating-point rounding
errors in AA is a little bit more involved. We could just round
outward each of the coefficients in a new affine quantity, but
then the dependencies of the affine quantity on the rounding
errors would be lost. In order to maintain as much information as possible, we can instead compute the rounding errors
for each affine term separately and, then, we can accumulate
the errors into a new affine term. For
kexample, for x, y ∈ AR,
we have x
 + y
 = (x0 + y0 ) + i=1 (xi + yi )εi + zεk+1 ,
where εk+1 is a new affine term and z captures all the
floating-point rounding errors.
In other words, we can associate an affine term with the
computation error that occurs at each operation. These errors
and, also, the affine terms which model uncertain parameters
in the system can be tracked along a computation sequence.
Therefore, at each point in time, we can be cognizant on
how each uncertainty affects the current state of the system.
But more importantly, the propagation of the affine terms
helps to avoid the problems of IA due to lost dependencies
between the variables. Note, however, that it is not always
the case that AA computes better bounds than IA.
Since there is no publicly available affine arithmetic
toolbox for Matlab, we developed our own package AALab
(Affine Arithmetic Laboratory). AALab provides a class for
AA quantities and overloads most of the standard functions
and operators in Matlab in order to provide AA in a transparent way to the user. In addition, AALab provides the option
to take into account or ignore floating-point rounding errors.
It also offers various levels of approximations for nonlinear functions (e.g., trigonometric functions) and, finally,
it implements several ways of aggregating affine terms when
their number becomes too large. We should remark that even
though [32] also studies an implementation of AA in Matlab,
that work does not support the aforementioned features.

B. Affine Arithmetic
Affine Arithmetic (AA) [10] is also a self-validated computation model that permits reasoning over ranges. AA maintains linear dependencies between AA quantities in order to
reduce some of the overapproximation issues that are present
in IA. Linear operations on AA quantities preserve such
linear dependencies. However, when nonlinear operations
are encountered, for example multiplication, then some small
overapproximation of the actual range is introduced.
In detail, AA quantities represent ranges over some field.
In the following, we will be using angular brackets to denote
symbolic variables that represent ranges in AA. Each AA
variable x
 is the summation of a central value x0 ∈ R
and a number of affine terms xi εi , where xi ∈ R is a
coefficient and εi is a variable
k that ranges over [−1, 1].
Formally, we write x
 = x0 + i=1 xi εi . The interpretation
of x
 is that for any x ∈ x
, for all i =1, . . . , k,
k
there exist ε̃i ∈ [−1, 1] such that x = x0 + i=1 xi ε̃i .
Finally,the interval represented
by x
 is simply [x
] :=
k
k
[x0 − i=1 |xi |, x0 + i=1 |xi |] (we should appropriately
control the rounding mode in the case of floating-point
numbers). For convenience, we will denote the set of all AA
quantities over the reals by AR and over the floating-point
numbers by AF.
As mentioned earlier, linear operations, such as addition,
are
e.g., for x,
 to define,
 y ∈ AR, we have
 straightforward
k
k
x0 + i=1 xi εi + y0 + i=1 yi εi = (x0 + y0 ) +
k
i=1 (xi + yi )εi . On the other hand, nonlinear operations,
such as multiplication, must be defined in such a way that
they maintain as many linear terms as possible and, in
addition, overapproximate the nonlinear terms by generating
a new affine term.
For example, for x, y ∈ AR,

 we have
k
k
(x
y
)
+
(x
y
)
εi + zεk+1 ,
x
 y
 = x0 y0 +
0
i
i
0
i=1
	 i=1  
	
	
	
k
k
where z is such that |z| ≥ 	
i=1 xi εi
i=1 yi εi 	.
One of the interesting problems in AA is how to compute
good bounds on the nonlinear terms [9]. Finally, we should

IV. D ETECTING N ON -ROBUSTNESS IN S IMULATIONS
In the previous sections, we provided a short overview
on how self-validated computations can be realized within
Matlab. In this section, we use these tools in order to present
a framework for detecting non-robustness in discrete-time,
continuous-time and mixed-signal Simulink models.
A. Discrete-Time Simulink Models
The main challenge in trying to perform self-validated
computations within the Simulink environment is that

348

1.2

of 0.1 sec. We would like to determine the robustness of the
simulation with initial conditions [−0.1, 0.1]3 and variation
of %1 in the parameter values. The Simulink simulation is
performed with initial conditions [0 0 0]T and the parameter
values as appear in Fig. 1. The result of the computation for
the signal y appears in Fig. 2. RobSimDt detected 5 points
where the simulation is non-robust. Below, we present how
RobSimDt displays one of the warnings of possible nonrobustness (recall that the threshold is 0.4):
Warning 5: In the block ’Switch’ at
time 3.6, the value of the input signal
to the block was 0.3537 while the range
of the input signal computed by RobSim
is [ 0.2948, 0.4126].
Next, we demonstrate how self-validated computations
and robustness checks are performed. Due to space limitations, we are only going to discuss briefly the procedures
of two blocks of our running example: the discrete-time
integrator and the switch. Also, the following presentation
focuses on the use of affine arithmetic as the underlying
computation model which is the default option in RobSimDt.
However, the application of other self-validating computation models is immediate.
Discrete-Time Integrator. In the current version, RobSimDt supports only the forward Euler integration (or accumulation) method (see the on-line Simulink help documentation). When a discrete-time integrator is accessed through
an “update” event, it returns the value of the expression
x
 (k) + K
 
(dt) u
 (k) which is evaluated using selfvalidated arithmetics. Here, x
 (k) is the (guaranteed) state
of the integrator at time k, u
 (k) is the (guaranteed) input
to the block at time k, K is the gain parameter of the block
and dt is the sample step size. Note that we enclose the real
value of dt using interval arithmetic. This is important since
the exact value of dt might not be representable in machine
arithmetic and, thus, if floating-point rounding errors are
not accounted for, they could cause major inaccuracies in
the subsequent computations (recall the case of the Patriot
missile incident in the introduction). The same holds for
the gain K. However, we also allow for the case that the
value of the gain K is uncertain and, moreover, it might be
dependent on other system parameters. Such dependencies
can be modeled by letting K
 share affine terms with other
system parameters. Finally, in the case where an “output”
event is received, the discrete-time integrator simply returns
the current state x
 (k).
Switch Block. The switch block can only be accessed
through an “output” event. Let us assume that the threshold
option in the block has been set to the option “u2 >=
Threshold”. This option means that the input signal u2
should be greater or equal to the threshold and that if this
is true, then the upper input signal “u1” is allowed to pass
through, otherwise the lower input signal “u3” is allowed
to pass through. Now, if the formula φs (k) = (u2
 (k) ≥

1
0.8
0.6
0.4
0.2
0
−0.2

0

5

10

15

20

Figure 2. Guaranteed simulation of Example 2. The bars indicate the
bounds on the guaranteed simulation for each time step of 0.1 sec, while
the line inside is the result of the Simulink simulation.

Simulink accepts only its built-in data types, e.g., double,
signal, int8, fixed-point etc. One way to overcome this
restriction is by monitoring Simulink during a simulation.
Namely, we first instrument Simulink with callback functions (listeners) using Simulink’s Application Programming
Interface (API). Then, we record the sequence of accesses
and the corresponding events (such as “update” or “output”)
sent to the blocks during one Simulation step. Also, we
maintain information about the input signals to the blocks. In
the following, we refer to such sequences as block execution
traces. The advantage of inserting callbacks is that the execution order semantics of Simulink is enforced. Finally, we
follow the block execution trace, but now each mathematical
operation and all the relation checks are performed using
self-validating computation theories such as IA or AA.
We have implemented the above procedure into the software toolbox RobSimDt (ROBust SIMulations in DiscreteTime) within the Matlab programming environment. RobSimDt takes as input a discrete-time Simulink model D and
can perform guaranteed discrete-time simulation using the
parameters provided in D. Since AA provides in general
better bounds on the validated solution than IA, the AA
computation theory is chosen by default. If the user wants
to use uncertain initial conditions, parameters and/or inputs,
then she or he can do so by providing them to RobSimDt.
In this case, the self-validated computation model employed
is the one that corresponds to the data-type of the initial
conditions. The output of RobSimDt is the guaranteed
simulation trace and a structure which holds information on
which Simulink blocks, time and input signal values the
computation might be non-robust. The following result is
immediate from the properties of self-validated arithmetics.
Theorem 1: Let D be a discrete-time Simulink model as
in Problem 1. Let x̃(k) be the state vector of the Simulink
simulation and x
 (k) be the state vector enclosure returned
by RobSimDt at sample k. Then, for all samples k of the
Simulink simulation, we have x̃(k) ∈ x
 (k).
Example 2: Let us consider the continuous-time model of
Fig. 1. The model is discretized with the Simulink Model
Discretizer using zero-order hold (zoh) and a sample step
349

Threshold) ∨ (u2
 (k) < Threshold) evaluates to false
(note that this is not a tautology since the comparisons are
in IA or AA), then a robustness violation has occurred. This
is a violation since either input signal u1
 (k) or u3(k)
could have been chosen by the switch as output. Thus, in this
case, we record the time, block and signal values. Moreover,
since we are trying to study the robustness of a particular
Simulink simulation, we let the switch chose the output
signal according to the value of the non-guaranteed input
signal u2(k). On the other hand, if either subformula of
φs is true at time k, then the corresponding input signal is
allowed to pass through.

model. Then, it executes the Simulink simulation with the
default parameters of the model in order to produce a block
execution trace. Note that for the simulation itself, Simulink
can use any built-in numerical integration method. This is
important since we don’t have to restrict our analysis only
to fixed-step algorithms.
For every time step Δti = ti+1 − ti in the simulation, we
pass the corresponding part of the block execution trace to
SL-Trace. In turn, SL-Trace returns the symbolic derivatives
of the linear (or affine) system for that particular time step
and, also, the constraints on the state space of the model that
must be satisfied (see [18] for a related approach on deriving
symbolic traces). Using the symbolic derivatives, we can
compute an enclosure of the state vector for all time between
the two sampling points. Then, the enclosure is compared
with the constraints to detect possible non-robustness points
in the simulation.
Now, let us assume that the system dynamics as returned
by SL-Trace are given by the interval matrices [A], [B] and
[h]. The interpretation of these matrices is that there exists
a parameter function p : [ti , ti+1 ] → P such that for all
t ∈ [ti , ti+1 ], we have A∗ (t) = A(p(t)) ∈ [A], B ∗ (t) =
B(p(t)) ∈ [B] and h∗ (t) = h(p(t)) ∈ [h]. Then, for any
u : [ti , ti+1 ] → U , the behavior of the system for the time
interval [ti , ti+1 ] is defined by the solution of the equation

B. Continuous-Time Simulink Models
Problem 2 is substantially more challenging then Problem 1. The main obstacle is that replacing the floatingpoint arithmetic with self-validating methods is not enough.
Namely, the model of the system does not consist any more
of ordinary difference equations, but of ordinary differential
equations which are solved using a numerical integration
algorithm. Numerical integration algorithms can only solve
the system of equations approximately and, moreover, they
are also themselves bound to the problem of floating-point
round errors. One way to address this problem is by resorting
to a guaranteed integration method [24], [6]. However, these
integration methods require in turn the explicit representation of the underlying differential equations of the system.
In general, such a system of mathematical equations
cannot be derived automatically due to the complex nature
of the Simulink models, e.g., switch and saturation blocks,
nonlinearities etc. Moreover, linearization methods do not
always extract an exact representation of the linear system
even if such an exact representation exists. In order to
circumvent the deficiencies of any linearization method,
we symbolically compute the derivatives of a Simulink
model whose dynamics are affine for a given operating point
and time. For that purpose, we use our toolbox SL-Trace,
which was initially developed for the symbolic execution
and systematic testing of Simulink models.
Another problem that prevents us from directly employing
guaranteed integrators for the solution of Problem 2 is the
fact that these methods only apply to state vectors represented in interval arithmetic. However, in feedback systems
it is paramount to use state vectors with symbolic numbers
in affine arithmetic. Thus, in general, the dependencies
between the different variables during computation are preserved and, in turn, we reduce overapproximations through
cancellations. We addressed the problem of integration by
developing RobSimCt.
RobSimCt (Robustness of Simulations in Continuoustime) is a toolbox built in Matlab programming environment
which addresses Problem 2. Similar to RobSimDt, it instruments the input Simulink model with listeners in order to
record the sequence of accesses to Simulink blocks in the

ẋ(t) = A∗ (t)x(t) + B ∗ (t)u(t) + h∗ (t)

(3)

Recall that our goal in this section is twofold. First,
we need to verify that the Simulink simulation at time
ti+1 starting from time ti is not false. Second, we have
to check that between time ti and time ti+1 there was
no potential violation of the current model invariants. The
former requires a method that computes an inclusion of the
state of system (3) at any time t for all possible system
parameters and inputs.
Correctness of Integration. Let us first consider the case
where there are no external inputs to the system, i.e., the
state-space representation of the system reduces to ẋ(t) =
A∗ (t)x(t). Then, the solution is x(t) = Φ(t, ti )x(ti ), where

 t

 t

 s1
A∗ (s1 )ds1 +
A∗ (s1 )
A∗ (s2 )ds2 ds1 +. . .
Φ(t, ti ) = I+
ti

ti

ti

is the Peano-Baker series for the transition matrix. Here, I is
the identity matrix. Since each entry in A∗ is continuous with
respect to t and the interval [ti , t] is compact, by repeated
applications of the mean value theorem for integrals, there
exist matrices A∗1 , A∗21 , A∗22 , . . . ∈ [A] such that
(t − ti )2
+ ...
2
Note that the mean value theorem cannot be applied to A∗ ,
but to each of its entries. Hence, by the properties of IA, we
derive the inclusion
(t − ti )2
2
[A] + . . . . (4)
Φ(t, ti ) ∈ I + (t − ti ) [A] +
2
Φ(t, ti ) = I + A∗1 (t − ti ) + A∗21 A∗22

350

For any s ∈ [ti , t], we have B ∗ (s) ∈ [B], h∗ (s) ∈
[h], u(s) ∈ [u] and, also, from (6) and (7) by ig
noring rounding control, we have Φ(t, s) ∈ e[A](t−s) .
By a change of variables, σ = t − s, we get
t
dσ = −ds and ti Φ(t, s)(B ∗ (s)u(s) + h∗ (s))ds ∈
 t−ti  [A]σ 
e
dσ([B] [u]+[h]). From (7), we also get (again,
0
no rounding control)


 t−ti 
m

1
k k
[A] σ + E([A] σ) dσ =
I+
k!
0
k=1

 t−ti
m

(t − ti )k+1
k
[A] +
E([A] σ)dσ
= I(t − ti ) +
(k + 1)!
0

Moreover, in Section IV in [26], it was proven that the above
series converges to the exponential of the interval matrix:
e[A](t−ti )  I + (t − ti ) [A] +
Thus, we have

(t − ti )2
2
[A] + . . . . (5)
2

Φ(t, ti ) ∈ e[A](t−ti ) .

(6)

Of course, we are now faced with the computation of the
exponential of an interval matrix. Unfortunately, the exponential of an interval matrix cannot be computed exactly.
In order to overapproximate the range of the exponential of
a matrix, we use the Taylor expansion in a way similar to
[1] and [26] such that it also takes into account floatingpoint rounding errors. Let A ∈ IRn×n , then the exponential
can be obtained by the Taylor series e[A] = I + [A] +
2
1
1
2 [A] + 3 [A] + . . .. In order to compute a bound on the
solution of e[A] , we must first compute a number m of Taylor
terms and then conservatively bound the remainder term. In
this work, we bound the reminder term using the relation
provided in [21] (which was also employed in [1] and [26]).
The next theorem, which is immediate from the properties
of IA, provides an overapproximation of the exponential of
the interval matrix.
Theorem 2: Given A ∈ IRn×n , an overapproximation of
the matrix exponential e[A] of order m can be obtained by:

m 



1
k
e[A] = I +


[A] +  sup 
(E([A])) (7)
k!

k=1

As it was indicated in [1], E([A] σ) is monotone (increasing)
t−t
with respect to σ. Thus, 0 i E([A] σ)dσ ⊆ E([A] (t−
 t−ti
ti )) 0
dσ = E([A] (t − ti ))(t − ti ). Therefore, we
can compute a conservative enclosure for the effect of the
external input uand the affine term h: [Γ]m (Δti ) = I 


Δtk+1
k
i
(Δti ) + m
k=1 
 (k+1)! [A] + E([A] 
(Δti )) 
(Δti ).
Constraint Violation. Next, we need to address the problem of possible violation of the location invariant constraints.
This step is straightforward. Along with the symbolic derivatives, SL-Trace also returns the invariant constraints that
hold at each point in time in the simulation. More formally,
for each time step [ti , ti+1 ], we have a set of constraints
Πi = {αj x + βj u + γj ≤ 0}j∈J , which is indexed by the
block id where the relation check took place. All we need
to do then is to check that for all t ∈ [ti , ti+1 ] and for all
j ∈ J, the relation αj x(t) + βj u(t) + γj ≤ 0 is satisfied.
From the computation of x
 (ti+1 ), it is obvious that we
cannot perform these checks analytically. Therefore, once
more we must conservatively bound the state of the system
between times ti and ti+1 , that is, we have to compute a set
R such that x
 (t) ⊆ R for all t ∈ [ti , ti+1 ].
Toward that goal, we consider an initial state x(ti ) ∈
x
 (ti ) and the final value of the trajectory at time ti+1 ,
i.e., x(ti+1 ) = Φ(ti+1 , ti )x(ti ). Similar to [11], for any t ∈
[ti , ti+1 ], we consider the approximation of Φ(t, ti )x(ti ) by
t−ti
the linear approximation x(ti ) + ti+1
−ti (Φ(ti+1 , ti )x(ti ) −
x(ti )). Let as denote the difference between the actual value
and its approximation by δ(t), that is,

k=1

[A]m+1

[A]∞
1
∞
where E([A]) = (m+1)!
1− and  = m+2 < 1.
Remark 1: The condition that  < 1 is an important one.
If it is not satisfied, then we should increase the order of
the Taylor terms m. Since we are actually concerned with
the product of the system dynamics [A] with the integration
step Δti , we can alternatively decrease the size of Δti .
Thus, a safe inclusion of the unforced propagation of the
state under rounding errors can be computed as:


(8)
x
 (t) = e[A](t−ti ) x
 (ti )

If the state vector x̃ computed by the numerical integration
algorithm at time ti+1 is not contained in x
 (ti+1 ), i.e.,
x̃(ti+1 ) ∈ x
 (ti+1 ), then we know that an integration error
occurred. On the other hand, if x̃(ti+1 ) ∈ x
 (ti+1 ), then
we cannot be sure whether the integration is correct or not.
Remark 2: Both numbers ti and ti+1 are machine representable floating-point numbers since they are computed
during the Simulink simulation. Nevertheless, their difference Δti = ti+1 − ti might not be representable in machine
arithmetic, hence in (8) we bound t − ti using IA.
Next, we have to take into account the influence of
potential inputs or noise to the system, i.e., the case where
B ∗ , h∗ = 0:

 t
x(t) = Φ(t, ti )x(ti ) +
Φ(t, s)(B ∗ (s)u(s) + h∗ (s))ds

t−ti
δ(t) = Φ(t, ti )x(ti )−x(ti )− ti+1
−ti (Φ(ti+1 , ti )x(ti )−x(ti ))

Using relation (6), the fact that x(ti ) ∈ x
 (ti ) and the
properties of AA, we get


t−ti
[A](ti+1 −ti )
δ(t) ∈ e[A](t−ti ) − I − ti+1
(e
−
I)
x
 (ti )
−ti
=

∞

(t−t

i )((t−ti )

k−1

−(ti+1 −ti )k−1 )
k!

k

[A] x
 (ti )

k=2

Now, we are in position to adapt Theorem 3 from [1] in order
to conservatively enclose δ(t) in the set [Δ]m (Δti ) x
 (ti ),

ti

351

m
k
where [Δ]m (Δti ) = k=2 [λ(k,


i ), 0] [A] + E([A]

 Δt
−k
−1
Δtk
(Δti )) and λ(k, Δti ) = inf 
 (k k−1 − k k−1 ) k!i .
Up to now, we saw how to compute a bound on the
divergence of x(t) from the line that connects x(ti ) and
x(ti+1 ). In order to account for all such trajectories between
x
 (ti ) and x
 (ti+1 ), we simply have to compute the
convex hull of the sets x
 (ti ) and x
 (ti+1 ). Such a
set cannot be computed, thus previous authors [11], [1],
who have worked with zonotope representations of the state
vector, have over-approximated the convex hull with a new
zonotope (for details see [11]). In our work, we instead
compute the interval convex hull (CH) of the two symbolic
sets. This gives us a quick, but conservative, enclosure of the
convex hull. Thus, the resulting set enclosure for the state
vector between times ti and ti+1 is

1
0.8
0.6
0.4
0.2
0

0

0.5

1

1.5

2

2.5

Figure 3. Guaranteed simulation of Example 4. The bars indicate the
bounds on the guaranteed simulation at each time step, while the line with
the circles is the result of the Simulink simulation.

C. Mixed-Signal Simulink Models

[R] = CH([x
 (ti )], [x
 (ti+1 )]) + [Δ]m (Δti )[x
 (ti )],
(9)
where for some x, y ∈ IR, we have CH([x] , [y]) =
[min(x, y), max(x, y)]. Now that we have an overapproximation of the reachable set between samples ti and
ti+1 , we can perform the check for guard violation by simply
checking whether αj [R] + βj [u] + γj ≤ 0 for all j ∈ J.
As mentioned before, if any of these checks fails, then we
keep the corresponding information.
Summary. The above discussion can be summarized in
the following theorem where internal computation errors are
also taken into account.
Theorem 3: Consider the time interval Ti = [ti , ti+1 ]
and a continuous parameter function p : Ti → P such
that for all t ∈ Ti the matrices A∗ (t) = A(p(t)) ∈ [A]
and B ∗ (t) = B(p(t)) ∈ [B] and the vector h∗ (t) =
h(p(t)) ∈ [h] are continuous in each of their entries with
respect to t. Moreover, let Δti = ti+1 − ti and m be the
order of the Taylor terms. Then, for any continuous input
function u : Ti → U such that for all t ∈ Ti we have
u(t) ∈ [u], the system (3) with initial conditions in x
 (ti )
has a solution at time
 is guaranteed to lie in affine
 ti+1 which
set x
 (ti+1 ) = e[A](Δti ) x
 (ti ) + [Γ]m (Δti ) under
floating-point arithmetic. Moreover, for any t ∈ Ti , from
(9), we have x
 (t) ∈ [R] under floating-point arithmetic.
Example 3: Consider the model of Fig. 1 with parameter
values as in Example 2. For the numerical integration, we
use the stiff ODE 15 solver with variable step size with maximum step size 0.05 sec. The constraint on the step size is
necessary in order to compute a better approximation on the
reachable set. The order for the Taylor approximation used
was 40. RobSimCt reported 317 possible constraint violation
warnings and 0 integration errors. Out of the warnings, 17
were at the Switch block. The warnings generated at the
Abs block can be safely ignored since the output of the Abs
block in all these cases is always less than 0.4. Thus, it does
not affect the behavior of the Switch.

In this section, we present our recent progresses in solving
Problem 3. That is, we briefly review the integration of
RobSimDt and RobSimCt into a single toolbox, RobSim,
which can test the robustness of mixed-signal models.
Currently, RobSim accepts models which have continuous and discrete-time components separated by ZeroOrder Hold blocks. This is necessary both theoretically and
implementation-wise. Zero-Order Hold blocks enforce the
requirement that the discrete-time signals have a constant
continuous value for the duration of the respective sample,
while at the same time they act as translators between
symbolic and self-validated computations.
As before, RobSim starts by first computing the block
execution sequence of the given Simulink model. Then, the
symbolic derivatives are derived or the discrete-time blocks
are processed using self-validated arithmetics depending on
which part of the model is updated. The process is repeated
for each time step in the simulation.
Example 4 (Example 10-13 from [19]): Consider
a discrete-time controller connected to the process
50
. The transfer function of the controller
Gp (s) = s(s+10)
2

and the sampling rate is 10 Hz.
is D(z) = 5z −6z+2
z2
Note that the model has 4 states: 2 continuous-time and 2
discrete-time state variables. We would like to study the
correctness of the numerical integration. For the Simulink
simulation, we use the ODE45 solver with no constraints
on the step size. The resulting trajectory has 63 points (see
Fig. 3). RobSim reports that the integration is not correct
at 57 points. Note, though, that the graph (Fig. 3) indicates
that the qualitative behavior of the simulation is correct.
Therefore, the user might want to further relax the bounds
in order to tolerate some of the integration errors as long
as the qualitative behavior is correct.
V. R ELATED R ESEARCH AND D ISCUSSION
Our work spans and adapts results from several (distinct)
research areas. In the previous sections, we have cited

352

several papers which are related to the discussion in each
section. Here, we summarize and discuss some works which
are directly related to our proposed framework.
Affine arithmetic (AA) [10] has been a popular computation model for capturing floating-point rounding errors. In
[13], the authors present a framework for the analysis of
floating-point rounding errors in embedded control software
and the corresponding toolbox FLUCTUAT. In brief, the
underlying theory in [13] is based on abstract interpretation
and on AA. Our work has different scope and goals from
[13]. Besides the apparent differences in the systems that
can be handled (e.g., discrete-time vs continuous-time), our
aim is to study the robustness of a particular simulation
with respect to internal and external uncertainties in the
system, whereas FLUCTUAT computes system invariants
and demonstrates how rounding errors propagate through
the computation.
Another related research area is the reachability analysis
[28] and verification [4] of dynamical systems with uncertain
system parameters. Along this line of research, the works
which are the closest related to ours appear in [15], [11]
and [2]. In [15], the authors present a framework for
performing simulation of discrete-time dynamical systems
with uncertain parameters using semi-symbolic simulations.
The systems are given in SystemC-AMS and the underlying
computation model for the symbolic simulations is AA. The
main difference between [15] and RobSimDt is that in [15]
the authors compute the reachable set of a dynamical system
without switching dynamics while RobSimDt determines the
robustness of a trajectory of a discrete-time hybrid system.
Moreover, RobSimDt can account for computation errors.
The papers [11] and [2] deal with the reachability analysis
of continuous-time hybrid systems based on zonotope representations of the state vector. Zonotopes can be regarded
as a special case of symbolic quantities in AA. In detail,
[11] presents a reachability algorithm for linear (and hybrid)
systems which do not have any uncertain system parameters. On the other hand, in [2], the authors extend their
previous work in [1] to address the reachability problem
of continuous-time hybrid systems with uncertain system
parameters. Even though, our work in this paper subsumes
the existence of a solution for the reachability problem of
continuous-time uncertain hybrid systems, our results differ
in two subtle points. That is, we have to take into account
the possible numerical drift in the computation of time and,
also, to model and capture computation errors. Finally, the
goal of our work is different when compared to [2] and
[1]. RobSimCt studies the robustness and correctness of a
particular simulation.
Reachability analysis of mixed-signal circuits is addressed
in [22] and [7]. However, these approaches do not handle
uncertain parameters or computation errors. Finally, similar
in spirit – but different in underlying theory – are the robust
testing methods [12], [17], [20], [8]. In this line of work, a

numerical simulation is performed which is representative of
a neighborhood of trajectories of the system. Nonetheless,
all the above approaches ignore computation errors.
VI. C ONCLUSIONS
In this paper, we have presented a framework for reporting
points where a simulation might not be robust. Our solution
can model and capture both uncertainties in the model
and internal computation errors. In addition, in the case
of continuous-time Simulink models with piecewise affine
dynamics, we can also detect points where the numerical
integration is not correct.
One of the main advantages of our approach is that it is a
non-intrusive, i.e, we let the simulation execute and, then, we
analyze the resulting trajectories (both the Simulink trajectory and the block execution trace). Therefore, we overcome
the key challenge of deciphering Simulink semantics and,
moreover, we avoid translating the model into a formalism
such as a hybrid automaton. To the best of our knowledge,
this is the first time that robust simulations under many
different sources of uncertainty are considered in Simulink
and, most probably, in any model based development suite.
Even though our framework could be extended to perform
bounded-time reachability computations for hybrid systems
in Simulink, our goal is different. The RobSim suite is
meant to be used as an analysis tool on top of a Simulink
simulation and provide guarantees that the computation itself
is correct against modeling uncertainties and floating-point
rounding errors. Especially, the latter types of errors can be
quite stealthy as we have indicated in the introduction. In
addition, possible points of non-robustness in the simulation
can be further explored by some lightweight method such
as Monte-Carlo simulations. Beyond testing and verification,
our framework could have other applications, too. For example, an efficient implementation could be used for detecting
non-robust points for code generation frameworks as in [3].
Future research is targeting three problems. First, we
are working on extending the framework to non-linear
continuous models. This essentially requires a method to
compute symbolically the derivatives of the system at each
point in time. Second, we are going to provide full support
for mixed-signal systems in RobSim and port our prototype
Matlab implementation into C for more efficient computation. Currently, Matlab speed is a bottleneck for scaling the
RobSim framework into larger systems. Finally, we plan to
add methods for exploring the points of non-robustness in
the simulations.
R EFERENCES
[1] M. Althoff, O. Stursberg, and M. Buss. Reachability analysis
of linear systems with uncertain parameters and inputs. In
46th IEEE Conference on Decision and Control, pages 726–
732, Dec. 2007.

353

[2] M. Althoff, O. Stursberg, and M. Buss. Verification of
uncertain embedded systems by computing reachable sets
based on zonotopes. In Proc. of the 17th IFAC World
Congress, 2008.

[17] A. A. Julius, G. E. Fainekos, M. Anand, I. Lee, and G. J.
Pappas. Robust test generation and coverage for hybrid
systems. In Hybrid Systems: Computation and Control,
number 4416 in LNCS, pages 329–342. Springer, 2007.

[3] M. Anand, S. Fischmeister, J. Kim, and I. Lee. Generating
sound and resource-aware code from hybrid systems models.
In Model-Driven Development of Reliable Automotive Services,, volume 4922 of LNCS, pages 48–66. Springer, 2008.

[18] A. Kanade, R. Alur, F. Ivančić, S. Ramesh, S. Sankaranarayanan, and K. C. Shashidhar. Generating and Analyzing
Symbolic Traces of Simulink/Stateflow Models. In CAV,
pages 430–445. Springer, 2009.

[4] G. Batt, C. Belta, and R. Weiss. Temporal logic analysis of
gene networks under parameter uncertainty. IEEE Transactions on Automatic Control, 53:215–229, Jan. 2008.

[19] B. C. Kuo. Digital Control Systems. Oxford University Press,
Inc., New York, NY, USA, 1992.

[5] M. Blair, S. Obenski, and P. Bridickas. Patriot missile
software problem. Technical Report GAO/IMTEC-92-26,
United States General Accounting Office, 1992.

[20] F. Lerda, J. Kapinski, E. M. Clarke, and B. H. Krogh. Verification of supervisory control software using state proximity
and merging. In Hybrid Systems: Computation and Control,
volume 4981 of LNCS, pages 344–357. Springer, 2008.

[6] O. Bouissou and M. Martel. Grklib: a guaranteed runge
kutta library. In Scientific Computing, Computer Arithmetic
and Validated Numerics, International Symposium on, Los
Alamitos, CA, USA, 2006. IEEE Computer Society.

[21] M. Liou. A novel method of evaluating transient response.
Proceedings of the IEEE, 54(1):20–23, Jan. 1966.
[22] S. Little, N. Seegmiller, D. Walter, C. Myers, and T. Yoneda.
Verification of analog/mixed-signal circuits using labeled hybrid petri nets. In Proceedings of the 2006 IEEE/ACM CAD,
pages 275–282. ACM, 2006.

[7] T. Dang, A. Donzé, and O. Maler. Verification of analog
and mixed-signal circuits using hybrid system techniques. In
Formal Methods in Computer-Aided Design, volume 3312 of
LNCS, pages 21–36. Springer, 2004.

[23] E. Loh and G. W. Walster. Rumps example revisited. Reliable
Computing, 8:245248, 2002.

[8] T. Dang, A. Donze, O. Maler, and N. Shalev. Sensitive statespace exploration. In Proc. of the 47th IEEE Conference on
Decision and Control, pages 4049–4054, Dec. 2008.

[24] K. Makino and M. Berz. Cosy infinity version 9. Nuclear
Instruments and Methods in Physics Research Section A:
Accelerators, Spectrometers, Detectors and Associated Equipment, 558(1):346 – 350, 2006.

[9] L. H. de Figueiredo and J. Stolfi. Self-Validated Numerical
Methods and Applications. Brazilian Mathematics Colloquium monographs. IMPA/CNPq, Brazil, 1997.

[25] R. E. Moore, R. B. Kearfott, and M. J. Cloud. Introduction
to Interval Analysis. SIAM, 2009.

[10] L. H. de Figueiredo and J. Stolfi. Affine arithmetic: Concepts
and applications. Numerical Algorithms, 37(1-4):147–158,
Dec. 2004.

[26] E. P. Oppenheimer and A. N. Michel. Application of interval
analysis techniques to linear systems. ii. the interval matrix
exponential function. IEEE Transactions on Circuits and
Systems, 35(10):1230–1242, Oct 1988.

[11] A. Girard. Reachability of uncertain linear systems using
zonotopes. In Hybrid Systems: Computation and Control,
volume 3414 of LNCS, pages 291–305, 2005.

[27] C. Phillips. Instabilities caused by floating-point arithmetic
quantization. IEEE Transactions on Automatic Control,,
17(2):242–243, Apr 1972.

[12] A. Girard and G. J. Pappas. Verification using simulation. In
Hybrid Systems: Computation and Control (HSCC), volume
3927 of LNCS, pages 272 – 286. Springer, 2006.

[28] N. Ramdani, N. Meslem, and Y. Candau. Reachability of
uncertain nonlinear systems using a nonlinear hybridization.
In Proceedings of the 11th international workshop on Hybrid
Systems, pages 415–428, 2008. Springer.

[13] E. Goubault, S. Putot, P. Baufreton, and J. Gassino. Static
analysis of the accuracy in control systems: Principles and
experiments. In FMICS, volume 4916 of LNCS, pages 3–20.
Springer, 2007.

[29] S. Rump. Algorithms for verified inclusions: Theory and
practice. In R. E. Moore, editor, Reliability in Computing: The
Role of Interval Methods in Scientific Computing, chapter 1,
pages 109–126. Academic Press, 1988.

[14] T. A. Henzinger, B. Horowitz, R. Majumdar, and H. WongToi. Beyond hytech: Hybrid systems analysis using interval
numerical methods. In Hybrid Systems: Computation and
Control, pages 130–144, London, UK, 2000. Springer-Verlag.

[30] S. Rump. INTLAB - INTerval LABoratory. In T. Csendes,
editor, Developments in Reliable Computing, pages 77–104.
Kluwer Academic Publishers, Dordrecht, 1999.

[15] W. Heupke, C. Grimm, and K. Waldschmidt. Applications
of Specification and Design Languages for SoCs, chapter
Modeling Uncertainty in Nonlinear Analog Systems with
Affine Arithmetic, pages 155–169. Springer, 2006.

[31] D. Stevenson. IEEE standard for binary floating-point arithmetic. Technical report, IEEE, August 1985.

[16] E. P. Hofer and A. Rauh. Applications of interval algorithms
in engineering. In Proceedings of the 12th International Symposium on Scientific Computing, Computer Arithmetic and
Validated Numerics, page 1, 2006. IEEE Computer Society.

[32] T. Yokozeki. An implementation of affine arithmetic on
Matlab. Master’s thesis, Waseda University, 2004.

354

Requirements driven falsification with coverage metrics
Adel Dokhanchi

Aditya Zutshi

Rahul T. Sriniva

Arizona State University

University of Colorado,
Boulder

Arizona State University

adokhanc@asu.edu

rthekkal@asu.edu
aditya.zutshi@colorado.edu
Sriram Sankaranarayanan
Georgios Fainekos
University of Colorado, Boulder

Arizona State University

srirams@colorado.edu

fainekos@asu.edu

ABSTRACT

have been developed ranging from reachability computation
techniques [16, 28] to theorem provers [44]. Despite the successful application of these methods in specific applications,
e.g., [34], or on very large linear hybrid systems [28], these
methods cannot, in general, be applied in an automatic way
to problems of industrial size. The reasons are similar - if
not identical - to the reasons that limit the applicability of
control synthesis methods.

Specification guided falsification methods for hybrid systems
have recently demonstrated their value in detecting design
errors in models of safety critical systems. In specification
guided falsification, the correctness problem, i.e., does the
system satisfy the specification, is converted into an optimization problem where local negative minima indicate design errors. Due to the complexity of the resulting optimization problem, the problem is solved iteratively by performing a number of simulations on the system. Even though
it is theoretically guaranteed that falsification methods will
eventually find the bugs in the system, in practice, the performance of these methods, i.e., how many tests/simulations
are executed before a bug is detected, depends on the specification, on the system and on the optimization method.
In this paper, we define and utilize coverage metrics on the
state space of hybrid systems in order to improve the performance of the falsification methods.

1.

Another approach to verifying properties of hybrid systems
relies on testing or simulation guided-methodologies [37].
Such approaches have been found to provide valuable insights and detect errors in problems of industrial size and
complexity [35, 26, 31]. One specific class of such methods
is referred to as specification robustness guided falsification
[5, 42]. As the name implies, such methods search for behaviors that violate a formal specification by executing a
number of judiciously chosen tests.
The formal specifications can be stated in Metric Temporal
Logic (MTL) [39] if the real-valued signals are abstracted
into Boolean-valued signals, or more explicitly in Signal Temporal Logic (STL) [41] if not. The important component of
robustness guided falsification methods is that formal specifications do not valuate using Boolean semantics, but quantitative multi-valued semantics [25, 24, 22, 10]. Namely,
given a system trajectory (behavior), the robust semantics
evaluate to positive values if the trajectory satisfies the specification and to negative values if the trajectory violates the
specification. Moreover, the magnitude of the robust evaluation indicates how robustly the behavior satisfies or violates
the specification. Thus, a falsification algorithm should try
to generate tests that reduce the robustness of the system
behavior with respect to the specification and, eventually,
become negative. This is essentially the application of a
range of stochastic or deterministic optimization algorithms
such as Simulated Annealing [5], Cross-entropy [45], Ant
Colony Optimization [13], and Nelder-Mead [20] to the falsification problem.

INTRODUCTION

Despite the significant progress in control synthesis for hybrid systems [47], the problem still remains challenging in
practice. Among the reasons for the difficulty of the synthesis problem are the large number of continuous state variables, the highly non-linear system dynamics and the interconnected components, many of which are not available
in a form amenable to symbolic analysis. Thus, currently,
control synthesis methods are utilized for specific operating
modes of the system and the different operating modes are
combined in an ad-hoc way based on rule tables and engineering experience. However, such a process is error prone
as the large number of recalls in safety critical applications
indicates.
Therefore, hybrid system verification has been proposed as
an alternative. In verification, the user defines a set of bad
behaviors of the system and the goal is to prove that no bad
behavior is possible. Along these lines, a number of methods

As mentioned earlier, the aforementioned techniques have
shown their value in a number of applications. Moreover,
theoretically speaking, they are guarantee to eventually detect system errors as long as these are not of measure zero in
the search space, e.g., see [3, 7]. In the falsification problem,
the search space consists of initial conditions, input signals
and other system parameters. However, the algorithm performance, i.e., how many tests are required before a bad

978-1-4673-8079-9/15/$31.00 ©2015 IEEE

31

behavior is detected, depends on the landscape induced by
the specification robustness over the search space of the hybrid system. In particular, these methods apply more effectively to continuous (non-hybrid) dynamical systems. Even
though continuous systems may still have a large number
of local minima, their basin of attraction is usually large.
The latter fact helps algorithms to locate faster regions of
interest in the search space.

technical issues that do not contribute to the results in this
paper. In the following, [0, T ] can be thought as the dense
physical time domain for the testing or the simulation. Also,
U is the set of input values (input space) and Y is the set of
output values (output space).

However, the same does not hold for hybrid systems. Local
minima can now appear anywhere in the search space with
very small or non-smooth basins of attraction. Therefore,
the probability that these regions will be detected becomes
very small. In addition, gradient descent algorithms [4, 9, 2]
will not work in such cases. However, if we can extract information about potential discontinuities in the hybrid system,
then we can narrow our search to such regions which otherwise would have been rather improbable to sample from.

1. The input signals u ∈ U [0,T ] (if any) must be piecewise
continuous defined over a finite number of intervals
over [0, T ]. This assumption is necessary in order to be
able to parameterize the input signal space over a finite
set of parameters. Thus, in the following we assume
that any u ∈ U [0,T ] of interest can be represented by
a vector of parameter variables p taking values from a
set PU .

The following three restrictions on the system are critical in
order to be algorithmically searchable over an infinite space:

2. The output space Y must be equipped with a nontrivial metric. For example, the discrete metric does
not provide any useful quantitative information. Concrete examples will be provided later in Section 3.

In this paper, we make several contributions. First, we show
how we can instrument Simulink/Stateflow models in order
to guide the falsification search toward promising regions.
Second, we define coverage metrics not on the continuous
state space of the hybrid system, but on its components that
introduce discontinuities. In this way, we let the stochastic algorithms search over locally continuous spaces while
we implicitly guide the search towards promising operating modes of the hybrid system. This is important because
computing coverage for systems with many real-valued state
variables becomes an intractable task. Furthermore, our
methods may still be utilized in testing actual implementations or testing models which contain black-box components.
Finally, we have modified our robustness computation engine TaLiRo [24, 26] to handle this additional information
and we have implemented everything within our S-TaLiRo
toolbox [1, 14].

2.

3. The system Σ must be deterministic1 . That is, for a
specific initial condition x0 and input signal u, there
must exist a unique output signal y.
The previous restrictions render the system Σ to be a function ∆Σ : X0 × P × PU → Y [0,T ] which takes as input an
initial condition vector x0 ∈ X0 and two parameter vectors p ∈ P and p0 ∈ PU , and produces as output a signal y : [0, T ] → Y . Since we consider testing and/or simulation, we assume that there exists a sampling function
τ : N → [0, T ] that returns for each sample i its time stamp
τ (i). In practice, τ is a partial function τ : N → [0, T ] with
N ⊂ N and |N | < ∞. A timed state sequence or trace is
the pair µ = (y ◦ τ, τ ). We will also denote y ◦ τ by ỹ.
The set of all timed state sequences of Σ that correspond to
any sampling function τ will be denoted by L(Σ). That is,
L(Σ) = {(y ◦ τ, τ ) | ∃τ ∈ [0, T ]N . ∃x0 ∈ X0 . ∃p ∈ P . ∃p0 ∈
PU . y = ∆Σ (x0 , p, p0 )}.

PROBLEM FORMULATION

In this work, we consider models of hybrid systems or, more
generally, of Cyber Physical Systems (CPS) as models developed within a Model Based Development (MBD) language
such as Ptolemy [23] or Simulink/Stateflow. We want to test
models with respect to requirements (specifications) presented in Metric Temporal Logic (MTL) [39]. MTL is a
well know formalism for stating real-time properties.

2.2

In this paper, we assume that R is the set of real numbers,
R+ is the set of non-negative real numbers, and R = R ∪
{±∞}. Also, N is the set of natural numbers including 0
and Z the integers. Given two sets A and B, B A is the set
of all functions from A to B, i.e., for any f ∈ B A we have
f : A → B. We define P(A) to be the power set of the
set A. Since we are considering testing or simulation-guided
methods, we fix T ∈ R+ to be the maximum simulation
time.

2.1

The Falsification Problem

The falsification problem is the process of finding a witness
output signal y0 of the system Σ which does not satisfy a
requirement represented in MTL. MTL can capture many
system requirements by defining a set of atomic propositions
AP which labels subsets of the output space Y . We define
those subsets through an observation map O : AP → P(Y )
where each π ∈ AP is mapped to a set O(π) ⊂ Y . MTL formulas are built over the set of atomic propositions AP , with
combinations of the propositional and temporal logic operators. Propositional logic operators are the conjunction (∧),
disjunction (∨), negation (¬), implication (→) and equivalence (↔). Some of the temporal operators, which we will be
using here, are eventually (3I ), always (2I ) and until (UI ).
The subscript I imposes timing constraints on the temporal
operators.

System Representation

Formally, we view a system Σ as a mapping from initial
conditions X0 , system parameters P and input signals U R
to output signals Y R . Here, R represents an abstract time
domain. For example, R = N×R when we want to talk about
solutions to trajectories of hybrid systems [40]. However,
here we will just assume that R = [0, T ] to avoid many

Problem 1 (MTL Falsification). For an MTL specification ϕ, the MTL falsification problem consists of finding
1

32

We remark that this assumption can also be relaxed [7].

= (0) ∈ −1,1 \

an output signal y of the system Σ starting from some valid
initial state x0 under a parameter vector p and an input signal u such that y does not satisfy specification ϕ.

= (0) ∈
( )∈

l2

l1
= − + 0.1
=
2
−
2
+0.1

The challenging problem here is how to guide the search
for such a falsifying trajectory. Previously, we utilized the
notion of robustness of temporal logic formulas [25, 24] in
order to convert the falsification problem into an optimization problem [13, 42, 45]. Briefly, temporal logic robustness provides a metric of how much a trajectory satisfies
a specification. Positive robustness implies that the trajectory satisfies the specification and, moreover, that there
exists a neighborhood of trajectories (or signals) that also
satisfy the specification. Negative robustness implies that
the trajectory does not satisfy the specification. Therefore,
in order to falsify the specification, we can use the temporal logic robustness as a cost function which we attempt to
minimize.

=
=−

+

Figure 1: The simple hybrid automaton Σ1 of Example 1. In this example, S = [0.85, 0.95]2 and t is the
time variable.
2
1.5
1

x2

0.5

Example 1. Consider the hybrid automaton Σ1 given in
Fig. 1. For a review of the syntax and semantics of hybrid
automata please refer to [11, 47]. Briefly, if the initial state
x0 = (x01 , x02 ) is in the set S (yellow box in Fig. 2), then
Σ1 follows the dynamics in location l2 , while if the initial
system state x0 is in [1, 1]2 \S (green box in Fig. 2), then Σ1
follows the dynamics in location l1 . Moreover, if the system
is operating under the dynamics in location l1 and the state
of the system enters the set S, then the system switches to
location l2 . Sample trajectories with initial conditions over
a grid of 0.05 intervals in each dimension over the set of
initial conditions [−1, 1]2 are presented in Fig. 2.

0
−0.5
−1
−1.5
−2
−2

−1

0

1
x1

2

3

4

Figure 2: The trajectories of the hybrid automaton
from Fig. 1.
S-TaLiRo [14]. Given a system and its specification, STaLiRo searches for a system trajectory that minimizes the
robustness value of the specification.

In this example, the specification is ϕ(a, b) where ϕ(π1 , π2 ) =
2[0,2] ¬π1 ∧ 2[0,2] ¬π2 ≡ 2[0,2] (¬π1 ∧ ¬π2 ), and the atomic
propositions a and b map to the following sets
O(a) = [−1.8, −1.4] × [−1.6, −1.4]

Example 2. [Cont. Example 1] When S-TaLiRo was
run on the system of Fig. 1 using Simulated Annealing for
500 tests for 100 times, then it detected a falsifying behavior
only 32 out of 100 times with an average number of 274
tests. The algorithm usually gets trapped in the large region
of the local minimizers along x2 = −1. Thus, we need to
derive methods and heuristics to guide the search towards
potentially more promising regions.

and
O(b) = [3.7, 4.1] × [−1.6, −1.4].
The atomic propositions a and b correspond to the red boxes
in Fig. 1. The specification reads always in the time interval
[0,2] the system trajectories should not enter either of the
two red boxes.

2.3

The specification robustness landscape is presented in Fig. 3.
In brief, the falsification problem reduces to finding negative
values over the robustness landscape. Some example trajectories that do not satisfy the specification and start from the
set S = [0.85, 0.95]2 are presented in Fig. 2.

Coverage Guarantees

The purpose of this work is twofold. First, it aims in achieving faster falsification with respect to the number of tests/simulations. Second, it aims to provide coverage guarantees after the falsification algorithm has concluded. In
other words, if a falsification algorithm [13, 42, 45] could
not provide a falsifying witness, at least it will be able to
list every “mode” of the system that was accessed and, potentially, for how long. The latter is especially important
in hybrid systems since falsifying trajectories can very well
depend on the sequence of “modes” as well as the time the
system remained in each mode. In a sense, part of what
we are trying to achieve relates to the branch and condition
coverage criteria of software testing [12].

The general overview of the solution of the MTL falsification problem as an optimization problem appears in Fig. 4.
The search/optimization algorithm proposes initial conditions, parameters and input signals. Then, the simulator or
hardware in the loop system produces the system behavior
over which the specification robustness is evaluated. The
process is repeated until a maximum number of test/simulations is reached or a falsifying behavior is detected. Based
on this framework, we have developed the Matlab toolbox

We will formalize the coverage problem for hybrid systems

33

Our main approach to solving the problem will utilize the
hybrid distance metrics that were introduced in [42, 5].
4

3.
Robustenss

MTL AND ROBUST SEMANTICS

In this section, briefly review MTL and its robust semantics.
We also present some extensions necessary for this work.

3

2

Definition 1 (MTL Syntax). Let AP be the set of
atomic propositions and I be any non-empty interval of R+ .
The set M T L of all well-formed MTL formulas is inductively defined as ϕ ::= > | π | ¬ϕ | ϕ ∨ ϕ | ϕ UI ϕ, where
π ∈ AP and > is true.

1

0
1
−1
1

0
0.5

0

−0.5
x2

−1

−1

x1

Using a metric d [46], we can define a distance function
that captures how far away a point y ∈ Y is from a set S ⊆
Y . Intuitively, the distance function assigns positive values
when y is in the set S and negative values when y is outside
the set S. The metric d must be at least a generalized quasimetric as described in [5] which also includes the case where
d is a metric as it was introduced in [25].

Figure 3: The specification robustness landscape
over the set of initial conditions [−1, 1]2 for Example 1. The blue level set at robustness level -1 represents the initial conditions generating trajectories
that falsify the specification.
output signal y

Temporal Logic
Robustness

System Σ
initial
conditions χ0 &
input signal u

Optimization
Algorithm

Minimum
Robustness

Definition 3.1 (Signed Distance).
point, S ⊆ Y be a set and d be a metric.
the Signed Distance from y to S to be

−distd (y, S)
Distd (y, S) :=
distd (y, Y \S)}

Falsifying
Trajectory

robustness ε

Let y ∈ Y be a
Then, we define
if y 6∈ S
if y ∈ S

where
distd (y, S) := inf{d(y, y 0 ) | y 0 ∈ S}
and inf is the infimum.

Figure 4: Overview of the solution to the MTL falsification problem posed as an optimization problem.

We should point out that we use the extended definition
of supremum (t) and infimum (u). In other words, the
supremum of the empty set is defined to be bottom element
of the domain, while the infimum of the empty set is defined
to be the top element of the domain. For example, sup ∅ :=
−∞ and inf ∅ := +∞.

by still maintaining the input/output system definition of
Section 2.1. We assume that the output space Y of the
system Σ comprises of the original output space YΣ of the
system (equipped with the nontrivial metric), an auxiliary
output space YA (which for now we leave undefined) and a
finite space YF . That is, Y = YΣ × YA × YF .

S-TaLiRo [14] originally supported the following metrics.
When Y = Rn , then we use the Euclidean metric d(y1 , y2 ) =
ky1 − y2 k. When Y is a hybrid space, e.g., Y = Rn × Q with
YΣ = Rn and YF = Q, where Q is the set of states of a
single statechart in the model, then we use the

 following
generalized quasi-metric [42, 5] dh : Y × Y → N ∪ ∞, R+
with definition:



dh (hx, qi , x0 , q 0 ) =

0
0

* d(x, x )i
+ if q = q
 h0,

The output space YF plays an important role since it captures the state of important components in the system. For
example, it can capture the state of switch blocks in state
diagrams or the state of statechart machines. Thus, the coverage metrics can be defined as simply set coverage metrics
over the space YF or more generally as coverage of sequences
of symbols from YF∗ . This paper focuses on the former coverage criterion.
Problem 2 (Coverage Guarantees). Given a system Σ with output space Y = YΣ × YA × YF and an MTL
specification ϕ, solve the MTL falsification problem while at
the same time maximizing the coverage of the set YF .




π(q, q 0 ),

min

q→q 00

π(q,q 0 )−1

;

distd (x, Gt (q, q 00 ))

otherwise

q0

where π is the shortest path metric on a graph, d is a metric
on Rn , and Gt denotes that the guard set that activates the
transition from state q to state q 0 in the statechart. We assume that Gt (q, q 00 ) ⊆ YΣ . Note that we use the superscript
t to indicate that the guard may be changing with respect
to time. Finally, the min operator quantifies over all neighboring states q 00 of q that are on a shortest path from q to
q 0 . A more detailed discussion can be found in [5].

Formally, if a falsification algorithm produces a finite set
of tests T = {(ỹi , τi )}i , then we are trying to maximize
| ∪(ỹ,τ )∈T ∪prYF (ỹ)|. Informally speaking, prYF is the projection of sequence of tuples from Y on YF .

34

Therefore, when the two points hx, qi , hx0 , q 0 i are in the same
statechart state, then the distance computation reduces to
the distance computation between the points in the continuous state space. When the two points hx, qi , hx0 , q 0 i are in
different statechart states, then the distance is the path distance between the two statechart states “weighted” by the
distance to the closest guard that will enable the transition
to the next statechart state that reduces the path distance.
Essentially, the last condition is a heuristic that gives preference to shortest paths.

2

Robustenss

1.5
1
0.5
0

Definition 3.2 (Robust Semantics). Consider an extended generalized quasi metric space (Y, d). Let µ ∈ L(Σ)
and O : AP → P(Y ), then the robust semantics of any formula ϕ ∈ M T L with respect to µ at sample time i ∈ N is
recursively defined as:
G
[[>, O]]d (µ, i) := Range(d)

0
−0.5
−1

−1

x1

Figure 5: The resulting robustness landscape for
specification ϕ00 in Example 3.
1
0.5

i0 ∈τ −1 (τ (i)+R I)

0

0

x2

ui≤i00 <i0 [[ϕ1 , O]]d (µ, i00 )
00

−0.5
x2

[[¬ϕ1 , O]]d (µ, i) := − [[ϕ1 , O]]d (µ, i)
[[ϕ1 ∨ ϕ2 , O]]d (µ, i) :=[[ϕ1 , O]]d (µ, i) t [[ϕ2 , O]]d (µ, i)
G
[[ϕ1 UI ϕ2 , O]]d (µ, i) :=
([[ϕ2 , O]]d (µ, i0 )u

0

0

0.5

[[π, O]]d (µ, i) :=Distd (ỹ(i), O(π))

00

1
0.5

−0.5
1

−0.5

−1

where t +R I = {t ∈ R | ∃t ∈ I . t = t + t }, τ
is the
inverse function of τ , and − is an unary operator defining
the “negative” values of the range of d, i.e., Range(d).

−1
−1.5
−2
−2

The semantics of the other operators can be defined using
the above basic operators. For example, 3I φ ≡ T UI φ and
2I φ ≡ ¬3I ¬φ.

−1

0

1
x1

2

3

4

Figure 6: Example 3: The samples selected during
the falsification process and the falsifying witness.

Example 3. [Cont. Example 1] If we consider now the
specification ϕ0 = ϕ(a0 , b0 ) with O(a0 ) = O(a) × {l1 , l2 } and
O(b0 ) = O(b)×{l1 , l2 }, then the robustness landscape is identical to the one in Fig. 3. On the other hand, if we change
in ϕ00 = ϕ(a00 , b00 ) the mapping of the atomic propositions
to O(a00 ) = O(a) × {l2 } and O(b00 ) = O(b) × {l2 } and we
map the resulting hybrid robustness values to the real line
(see map2line.m function in S-TaLiRo), then we get the
robustness landscape of Fig. 5. It is clear that in this case
the search is biased towards moving to mode l2 of the simple hybrid automaton. Indeed, when S-TaLiRo is run on
the system of Fig. 1 with the new atomic propositions using
Simulated Annealing for up to 500 tests 100 times, then it
always finds a falsifying behavior within 62 tests on average.
A successfully falsifying execution of S-TaLiRo is presented
in Fig. 6.

components. We extend the metric in a natural way using
the maximum pairwise hybrid distance. Namely, when Y =
Rn × Q1 × . . . × Qm , where Q1 , . . ., Qm are the sets of states
of m statecharts, we use the following metric:


0 
)=
dmax
(hx, q1 , . . . , qm i , x0 , q10 , . . . , qm
h

 0 0


0 
max{dh (hx, q1 i , x , q1 ), . . . , dh (hx, qm i , x0 , qm
).}
We remark that later in the text we will present how we
instrument the model under test to expose additional realvalued signals to the testing algorithm. These signals will
become part of the auxiliary output space YA . For the purposes of computing the distance metric, the output spaces
YΣ and YA will be treated as a Euclidean metric space.
That is, in dmax
we assume that YΣ × YA = Rn . Thereh
fore, YF = Q1 × . . . × Qm .

As Example 3 hints, our goal is to use coverage metrics to
guide the search towards less visited states or logical conditions.

4.

COVERAGE GUIDED FALSIFICATION

In this section, we present the basic steps behind our coverage guided specification falsification framework. In the
following, we will refer to the finite system states as modes
to differentiate them from the continuous infinite state variables of the system.

When dealing with industrial size models it is unrealistic
to assume that there is going to be a single statechart or
that it is going to be efficient to flatten all the different
statecharts into one. Thus, for the purposes of this work,
we have extended S-TaLiRo to handle multiple finite state

35

In case no mode information or multiple modes are dictated for some atomic propositions, the falsification algorithm starts with the default search algorthm without any
coverage guidance. As the search process evolves, coverage
statistics are collected for the output space YF . Some of the
proposed coverage metrics are:

System Σ

output signals
yΣ or
yA
yF

initial
conditions χ0 &
input signal u

1. Number of unique occurrences2 of each mode qi ∈ Qi
for each statechart Qi .

Coverage
Metrics
′

Temporal Logic
Robustness
robustness ε

Minimum
Robustness
Falsifying
Trajectory

Optimization
Algorithm

2. Percentage of test time (samples) that the system remained in each mode qi ∈ Qi for each statechart Qi .
3. Number of unique occurrences of each combination of
modes hq1 , . . . , qm i of the statecharts.

Figure 7: Overview of the basic components of the
coverage guided falsification framework.

4. Percentage of test time (samples) that the system remained in each combination of modes hq1 , . . . , qm i of
the statecharts.
Since these are all heuristic metrics, more options are possible especially when considering sequences of modes. Another point which will need to be experimentally studied in
the future is whether to collect such statistics over all test
cases or the test cases with smallest robustness value found.
If the falsification process terminates successfully, then the
coverage information can also be returned to the user. If the
falsification process fails, then the search algorithm switches
to the coverage guided search. In coverage guided search,
preference is first given to combinations of modes with the
least coverage values.

Figure 8: Switch block case 1.

5.

Due to the complexity of the systems that we consider, in
general, it is not possible to know whether a specific combination of modes is reachable [30]. Clearly, it is also not
possible, in general, to compute initial conditions and parameters that would make a specific combination of modes
reachable. Therefore, we modify our specification to bias
the search towards the desired combination of modes while
still trying to falsify the original specification. In particular, if the original specification is ϕ and the least visited (or
not visited at all) set of combinations of modes is QDes ⊆
Q1 × . . . × Qm , then we define a new atomic proposition
pDes with O(pDes ) = Rn × QDes and we create a new MTL
formula

5.1

Model Instrumentation

In the model instrumentation, a Simulink model is analyzed
and information is collected about blocks that introduce
nonlinearities in a model. For instance, targets for instrumentation are switch blocks, absolute value blocks, saturation blocks, lookup tables, etc. Here, we will only present
the process for switch blocks through some examples since
all other blocks are treated in similar ways.

ϕ0 = ϕ ∨ ¬3(pDes )

In Fig. 8 and 9, we present 2 cases of interest for switch
blocks. In both cases, the switch block chooses either signal
A or signal B based on the switching condition provided in
the middle port. Each such switch can be modeled using
a two state statechart with transition guards the switching
conditions of the blocks (see Fig. 10).

The formula ϕ0 now becomes the target for the falsification
process. Hence, now, the falsification algorithm while it tries
to minimize the robustness, it indirectly pushes the system
to go to the modes provided by the atomic proposition pDes
since its robustness will be minimized as well.

Our instrumentation algorithm analyzes locally the switch
blocks and introduces output ports that become elements
in the output spaces YA and YF . In particular, consider the
switch in Fig. 8. In this case, Out1 is part of the output space
YΣ . Through the instrumentation, we introduce the output
port Out5 to the set YA . Moreover, in an outer harness for
the model, we compute whether the statechart is in state A
or B and this value becomes an element in the output set
YF . The information that corresponds to the left statechart

The basic architecture of the coverage guided falsification
algorithm is presented in Fig. 7.
Example 4. [Cont. Example 1] We remark that the specification ϕ(a, b)∨¬3(pDes ) with O(pDes ) = R2 ×{l2 } induces
the same robustness landscape to the one in Fig. 5.
2

IMPLEMENTATION

Next, we discuss details regarding our S-TaLiRo implementation of the coverage guided falsification for Simulink/Stateflow models. An important component of the process
is the instrumentation of the models. This is important in
order to handle automatically industrial size models.

I.e., we ignore consecutive repetitions of the same mode.

36

user unless the user would like to manually instrument the
model or parts of the model.
Among the current options provided to the user for coverage
guided falsification are:
1. The number of MTL formula updates.
2. The number of tests/simulations before the MTL formula is updated.
3. The coverage metric utilized.
4. Whether all the tests/simulations are utilized in the
computation of the coverage metrics.

Figure 9: Switch block case 2.
Out5< 0.5

B

5. Whether in a formula update the next mode combination is chosen randomly or in some other order.

Out6 ≥ 10

A
Out5≥0.5

B

A
S-TaLiRo can be downloaded from the website [1] along
with the examples in this paper.

Out6<10

6.

Figure 10: Left: Statechart corresponding to switch
in Fig.8. Right: Statechart corresponding to switch
in Fig.9.

in Fig. 10 is also automatically extracted and utilized in the
computation of the distance metric dmax
.
h
The instrumentation for the case of the switch in Fig. 9 is
similar. In this case, Out2 is part of the output space YΣ .
The instrumentation introduces Out6 and Out7 as elements
of the sets YA and YF , respectively. The output port Out7
captures the state of the switch, while the value in the output
port Out6 along with the right statechart in Fig. 10 are
needed for computing the distance metric dmax
.
h

A survey of recent results on simulation based verification
methods has appeared in [37] while older results are surveyed in [4, 48]. For the sake of completeness, here we will
briefly mention some methods which are not directly related
to specification robustness guided falsification.
Three major research directions in simulation based verification are (i) robust testing [36, 27, 21, 32, 33, 19], (ii)
randomized tree exploration testing [15, 43, 18] and (iii) the
combination of the two aforementioned approaches [29, 17].
In robust testing, the underlying principle is that each simulation actually corresponds to a neighborhood of simulations. Therefore, it becomes possible to exhaustively cover
the search space of the hybrid system with only a finite number of simulations and, thus, prove system correctness up to
a finite time horizon. One drawback of robust testing is that
it only applies to certain types of systems for which bounds
on the divergence of nearby system trajectories can be computed. The aforementioned methods [36, 27, 21, 32, 33, 19]
essentially differ on the theory utilized for computing the
divergence bounds.

In the previous examples, any computed coverage information directly corresponds to state coverage for the switch
block. In other words, condition coverage is identical to
mode coverage. However, in many cases, a Boolean input
signal to the middle port of a switch block may be the output of a blackbox or whitebox Boolean circuit. In the former
case, we have to resort to condition coverage in the relational
operator blocks as in Fig. 9. In the latter case, we would
have to solve a satisfiability problem in order to directly
control the state of the switch block.
Currently, the Simulink/Stateflow model instrumentation is
performed automatically by S-TaLiRo for a few commonly
occurring blocks. Our instrumentation function recursively
instruments any subsystems unless they are masked linked
systems. However, the users can manually instrument any
block even if such work can be tedious.

5.2

RELATED WORK

Recently, the research direction of simulation guided approaches for verification has gained a lot of traction. Among
the reasons for the recent research focus is that simulation
guided methods bridge the gap between exhaustive formal
verification and ad hoc testing: they are applicable to industrial size problems while providing probabilistic guarantees
of completeness.

On the other hand, tree exploration methods [15, 43, 18]
try to grow a tree in the state or output space of the system. Among the advantages of these methods are: (1) they
can offer coverage guarantees on both the continuous and
the discrete state space of a hybrid system; (2) they are
very efficient on systems with complex nonlinear continuous
dynamics; and (3) they can handle systems with blackbox
components. On the other hand, it is not easy to use such
methods to falsify real-time specifications and they cannot
be effectively used in hardware-in-the-loop testing.

S-TaLiRo Details

Figure 11 provides an overview of the modular architecture
of S-TaLiRo along with the data flow among the different
components. The user provides the model, the specification
and whether she would like to execute coverage guided falsification. The internal components are transparent to the

37

MTL Spec , Model Σ, S-TaLiRo options
S-TaLiRo Coverage

Robustness
Computation
Block
robustness
ε

Stochastic
Optimization Engine
SA

CE

distance
TaLiRo
,

…

Minimum
Robustness
Observation
output signals
y …y , …
Statecharts

next
,
Generate
Input
Signals

Modified
MTL Spec ′

Convex
Optimization

Functional
Coverage
Observation
of finite
output space
…

…

,
System Simulator Engine
Hybrid
Automata

Falsifying
Trajectory

User Defined
Functions
(blackbox)

Simulink
Model

Hardwarein-the-loop

Processorin-the-loop

Instrumentation

Modified
Simulink
Model

Figure 11: S-TaLiRo architecture for coverage guided falsification.
It is important to note that the aforementioned techniques
have found applications beyond the falsification problem as
defined in Section 2.2. Interesting applications range from
the conformance testing problem [6, 8] to the specification
mining problem [35, 49, 38]. Thus, the results developed in
this paper can also be applied to these problems as well.

brid systems have discontinuities which renter certain behaviors rare events. Our new work utilizes structural information about these discontinuities in order to sample more
frequently around regions that correspond to rare system
behaviors. Our current work has been implemented in our
toolbox S-TaLiRo [14, 1].

A more recent simulation based verification framework is
referred to as trajectory splicing. Trajectory splicing was
initially proposed as a complementary falsification technique
to traditional overapproximate verification techniques which
usually provide an abstract counter example if they fail.
Trajectory splicing can be used produce a concrete violation when it exists. The first version [51] used off the shelf
optimization techniques and the later versions switched to a
graph based simulation framework capable of handling black
box dynamics [50]. Symbolic execution of controller code
was subsequently incorporated [52].

This research direction is still in its infancy. Many coverage metrics that have been developed for software may be
adapted to testing hybrid systems. Especially, we would like
to focus on coverage metrics for achieving path coverage in
hybrid systems. Another practical direction is to experiment with these testing methods on hardware-in-the-loop
systems. Finally, our current research topic is the integration of trajectory splicing methods with the falsification results in this paper.

Acknowledgments
The authors would like to thank the Model Based Development group at the Toyota Technical Center for the many
fruitful discussions on this topic and their continuing support. This research was funded in part by NSF awards CNS1319560, CNS-1319457, CNS-1350420, IIP-1361926 and the
NSF I/UCRC Center for Embedded Systems.

The idea behind trajectory splicing is to iteratively search
in the space of trajectory segments. However, such disconnected segments do not form concrete violations due to the
gaps that exist between the ending state of one segment and
the starting state of the subsequent segment. Therefore, a
local search is used to minimize the gap between these segments, effectively splicing them together to form a concrete
trajectory.

7.

8.

REFERENCES

[1] TaLiRo Tools.
https://sites.google.com/a/asu.edu/s-taliro/.
[2] H. Abbas and G. Fainekos. Linear hybrid system
falsification through local search. In Automated
Technology for Verification and Analysis, volume 6996
of LNCS, pages 503–510. Springer, 2011.
[3] H. Abbas and G. Fainekos. Convergence proofs for
simulated annealing falsification of safety properties.
In Proc. of 50th Annual Allerton Conference on

CONCLUSIONS

We have presented our recent work in improving property
falsification methods for hybrid systems by incorporating
coverage metrics. Coverage metrics can assist falsification
methods by biasing/guiding the search towards regions of
the state space that have not been explored sufficiently before. This is an important improvement since many hy-

38

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]
[12]
[13]

[14]

[15]

[16]

[17]

[18]

Communication, Control, and Computing. IEEE
Press, 2012.
H. Abbas and G. Fainekos. Computing descent
direction of mtl robustness for non-linear systems. In
American Control Conference, 2013. [Under review].
H. Abbas, G. E. Fainekos, S. Sankaranarayanan,
F. Ivancic, and A. Gupta. Probabilistic temporal logic
falsification of cyber-physical systems. ACM
Transactions on Embedded Computing Systems,
12(s2), May 2013.
H. Abbas, B. Hoxha, G. Fainekos, J. V. Deshmukh,
J. Kapinski, and K. Ueda. Conformance testing as
falsification for cyber-physical systems. Technical
Report 1401.5200, arXiv, 2014.
H. Abbas, B. Hoxha, G. Fainekos, and K. Ueda.
Robustness-guided temporal logic testing and
verification for stochastic cyber-physical systems. In
Proc. of IEEE International Conference on CYBER
Technology in Automation, Control, and Intelligent
Systems, 2014.
H. Abbas, H. Mittelmann, and G. Fainekos. Formal
property verification in a conformance testing
framework. In 12th ACM-IEEE International
Conference on Formal Methods and Models for System
Design, 2014.
H. Abbas, A. Winn, G. Fainekos, and A. A. Julius.
Functional gradient descent method for metric
temporal logic specifications. In American Control
Conference, 2014. [Under review].
T. Akazaki and I. Hasuo. Time robustness in mtl and
expressivity in hybrid system falsification. In
Computer Aided Verification, volume 9207 of LNCS,
pages 356–374. Springer, 2015.
R. Alur. Principles of Cyber-Physical Systems. MIT
Press, 2015.
P. Ammann and J. Offutt. Introduction to Software
Testing. Cambridge University Press, 2008.
Y. S. R. Annapureddy and G. E. Fainekos. Ant
colonies for temporal logic falsification of hybrid
systems. In Proceedings of the 36th Annual Conference
of IEEE Industrial Electronics, pages 91–96, 2010.
Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and
S. Sankaranarayanan. S-TaLiRo: A tool for temporal
logic falsification for hybrid systems. In Tools and
algorithms for the construction and analysis of
systems, volume 6605 of LNCS, pages 254–257.
Springer, 2011.
M. Branicky, M. Curtiss, J. Levine, and S. Morgan.
Sampling-based planning, control and verification of
hybrid systems. IEE Proc.-Control Theory Appl.,
153(5):575–590, 2006.
X. Chen, E. Abraham, and S. Sankaranarayanan.
Flow*: An analyzer for non-linear hybrid systems. In
Computer-Aided Verification, 2013.
T. Dang, A. Donze, O. Maler, and N. Shalev. Sensitive
state-space exploration. In Proc. of the 47th IEEE
Conference on Decision and Control, pages 4049–4054,
Dec. 2008.
T. Dang and N. Shalev. State estimation and
property-guided exploration for hybrid systems
testing. In International Conference Testing Software
and Systems, volume 7641 of LNCS, pages 152–167.

Springer, 2012.
[19] Y. Deng, A. Rajhans, and A. A. Julius. Strong: A
trajectory-based verification toolbox for hybrid
systems. In Quantitative Evaluation of Systems,
volume 8054 of LNCS, pages 165–168. Springer, 2013.
[20] A. Donze. Breach, a toolbox for verification and
parameter synthesis of hybrid systems. In Computer
Aided Verification, volume 6174 of LNCS, pages
167–170. Springer, 2010.
[21] A. Donze and O. Maler. Systematic simulation using
sensitivity analysis. In Hybrid Systems: Computation
and Control, volume 4416 of LNCS, pages 174–189.
Springer, 2007.
[22] A. Donze and O. Maler. Robust satisfaction of
temporal logic over real-valued signals. In Formal
Modelling and Analysis of Timed Systems, volume
6246 of LNCS. Springer, 2010.
[23] J. Eker, J. Janneck, E. A. Lee, J. Liu, X. Liu,
J. Ludvig, S. Sachs, and Y. Xiong. Taming
heterogeneity - the ptolemy approach. Proceedings of
the IEEE, 91(1):127–144, Jan. 2003.
[24] G. Fainekos and G. J. Pappas. Robustness of temporal
logic specifications. In Formal Approaches to Testing
and Runtime Verification, volume 4262 of LNCS,
pages 178–192. Springer, 2006.
[25] G. Fainekos and G. J. Pappas. Robustness of temporal
logic specifications for continuous-time signals.
Theoretical Computer Science, 410(42):4262–4291,
2009.
[26] G. Fainekos, S. Sankaranarayanan, K. Ueda, and
H. Yazarel. Verification of automotive control
applications using s-taliro. In Proceedings of the
American Control Conference, 2012.
[27] G. E. Fainekos, A. Girard, and G. J. Pappas.
Temporal logic verification using simulation. In
E. Asarin and P. Bouyer, editors, Proceedings of the
4th International Conference on Formal Modelling and
Analysis of Timed Systems, volume 4202 of LNCS,
pages 171–186. Springer, 2006.
[28] G. Frehse, C. L. Guernic, A. Donzé, S. Cotton,
R. Ray, O. Lebeltel, R. Ripado, A. Girard, T. Dang,
and O. Maler. Spaceex: Scalable verification of hybrid
systems. In Proceedings of the 23d CAV, 2011.
[29] A. Girard and G. J. Pappas. Verification using
simulation. In Hybrid Systems: Computation and
Control (HSCC), volume 3927 of LNCS, pages 272 –
286. Springer, 2006.
[30] T. A. Henzinger, P. W. Kopke, A. Puri, and
P. Varaiya. What’s decidable about hybrid automata?
J. Comput. Syst. Sci., 57(1):94–124, 1998.
[31] B. Hoxha, H. Abbas, and G. Fainekos. Using s-taliro
on industrial size automotive models. In Proc. of
Applied Verification for Continuous and Hybrid
Systems, 2014.
[32] Z. Huang and S. Mitra. Computing bounded reach
sets from sampled simulation traces. In The 15th
International Conference on Hybrid Systems:
Computation and Control (HSCC 2012), Beijing,
China., 2012.
[33] Z. Huang and S. Mitra. Proofs from simulations and
modular annotations. In Proceedings of the 17th
International Conference on Hybrid Systems:

39

Computation and Control, pages 183–192, 2014.
[34] J.-B. Jeannin, K. Ghorbal, Y. Kouskoulas,
R. Gardner, A. Schmidt, and E. Z. A. Platzer. A
formally verified hybrid system for the next-generation
airborne collision avoidance system. In TACAS,
volume 9035 of LNCS, pages 21–36. Springer, 2015.
[35] X. Jin, A. Donze, J. Deshmukh, and S. Seshia. Mining
requirements from closed-loop control models. In
Hybrid Systems: Computation and Control. ACM
Press, 2013.
[36] A. A. Julius, G. E. Fainekos, M. Anand, I. Lee, and
G. J. Pappas. Robust test generation and coverage for
hybrid systems. In Hybrid Systems: Computation and
Control, volume 4416 of LNCS, pages 329–342.
Springer, 2007.
[37] J. Kapinski, J. Deshmukh, X. Jin, H. Ito, and K. R.
Butts. Simulation-guided approaches for verification of
automotive powertrain control systems. In American
Control Conference, 2015.
[38] Z. Kong, A. Jones, A. M. Ayala, E. A. Gol, and
C. Belta. Temporal logic inference for classification
and prediction from data. In Proceedings of the 17th
International Conference on Hybrid Systems:
Computation and Control, 2014.
[39] R. Koymans. Specifying real-time properties with
metric temporal logic. Real-Time Systems,
2(4):255–299, 1990.
[40] J. Lygeros, K. H. Johansson, S. N. Simic, J. Zhang,
and S. Sastry. Dynamical properties of hybrid
automata. IEEE Transactions on Automatic Control,
48:2–17, 2003.
[41] O. Maler and D. Nickovic. Monitoring temporal
properties of continuous signals. In Proceedings of
FORMATS-FTRTFT, volume 3253 of LNCS, pages
152–166, 2004.
[42] T. Nghiem, S. Sankaranarayanan, G. E. Fainekos,
F. Ivancic, A. Gupta, and G. J. Pappas. Monte-carlo
techniques for falsification of temporal properties of
non-linear hybrid systems. In Proceedings of the 13th
ACM International Conference on Hybrid Systems:
Computation and Control, pages 211–220. ACM Press,
2010.
[43] E. Plaku, L. E. Kavraki, and M. Y. Vardi.
Falsification of ltl safety properties in hybrid systems.
In Proc. of the Conf. on Tools and Algorithms for the
Construction and Analysis of Systems (TACAS),
volume 5505 of LNCS, pages 368 – 382. Springer, 2009.
[44] A. Platzer. Logical Analysis of Hybrid Systems:
Proving Theorems for Complex Dynamics. Springer,
Heidelberg, 2010.
[45] S. Sankaranarayanan and G. Fainekos. Falsification of
temporal properties of hybrid systems using the
cross-entropy method. In ACM International
Conference on Hybrid Systems: Computation and
Control, 2012.
[46] A. K. Seda and P. Hitzler. Generalized distance
functions in the theory of computation. The Computer
Journal, 53(4):bxm108443–464, 2008.
[47] P. Tabuada. Verification and Control of Hybrid
Systems: A Symbolic Approach. Springer, 2009.
[48] S. Tripakis and T. Dang. Model-Based Design for
Embedded Systems, chapter Modeling, Verification and

[49]

[50]

[51]

[52]

40

Testing using Timed and Hybrid Automata, pages
383–436. CRC Press, 2009.
H. Yang, B. Hoxha, and G. Fainekos. Querying
parametric temporal logic properties on embedded
systems. In Int. Conference on Testing Software and
Systems, volume 7641, pages 136–151. Springer, 2012.
A. Zutshi, J. V. Deshmukh, S. Sankaranarayanan, and
J. Kapinski. Multiple shooting, cegar-based
falsification for hybrid systems. In Proceedings of the
14th International Conference on Embedded Software,
page 5. ACM, 2014.
A. Zutshi, S. Sankaranarayanan, J. V. Deshmukh, and
J. Kapinski. A trajectory splicing approach to
concretizing counterexamples for hybrid systems. In
Decision and Control (CDC), 2013 IEEE 52nd
Annual Conference on, pages 3918–3925. IEEE, 2013.
A. Zutshi, S. Sankaranarayanan, J. V. Deshmukh,
J. Kapinski, and X. Jin. Falsification of safety
properties for closed loop control systems. In
Proceedings of the 18th International Conference on
Hybrid Systems: Computation and Control, pages
299–300. ACM, 2015.

Proceedings of the 2007 IEEE/RSJ International
Conference on Intelligent Robots and Systems
San Diego, CA, USA, Oct 29 - Nov 2, 2007

WeD7.5

From Structured English to Robot Motion

∗

Hadas Kress-Gazit, Georgios E. Fainekos and George J. Pappas
GRASP Laboratory, University of Pennsylvania
Philadelphia, PA 19104, USA
{hadaskg,fainekos,pappasg}@grasp.upenn.edu
Abstract— Recently, Linear Temporal Logic (LTL) has been
successfully applied to high-level task and motion planning
problems for mobile robots. One of the main attributes of LTL is
its close relationship with fragments of natural language. In this
paper, we take the first steps toward building a natural language
interface for LTL planning methods with mobile robots as the
application domain. For this purpose, we built a structured
English language which maps directly to a fragment of LTL.

I. I NTRODUCTION
Successful paradigms for task and motion planning for
robots require the verifiable composition of high level planning with low level controllers that take into account the
dynamics of the system. Most research up to now has
targeted either high level discrete planning or low level
controller design that handles complicated robot dynamics
(for an overview see [2], [16]). Recent advances [1], [4], [6],
[17] try to bridge the gap between the two distinct approaches
by imposing a level of discretization and taking into account
the dynamics of the robot.
The aforementioned approaches in motion planning can
incorporate at the highest level any discrete planning methodology [2], [16]. One such framework, is based on automata
theory where the specification language is the so-called
Linear Temporal Logic (LTL) [3]. In the case of known
and static environments, LTL planning has been successfully
employed for the non-reactive path planning problem of a
single robot [8], [9] or even robotic swarms [12]. For robots
operating in the real world, one would like them to act
according to the state of the environment, as they sense it, in
a reactive way. In our recent work [14], we have shifted to a
framework that solves the planning problem for a fragment
of LTL [21], but now it can handle and react to sensory
information from the environment.
One of the main advantages of using this logic as a specification language is that LTL has a structural resemblance
to natural language 1. Nevertheless LTL is a mathematical
formalism which requires expert knowledge of the subject
if one seeks to tame its full expressive power and avoid
mistakes. This is even more imperative in the case of the
fragment of Linear Temporal Logic that we consider in this
paper. This fragment has an assume-guarantee structure that
makes it difficult for the non-expert user even to understand
a specification, let alone formulate one.
∗ This work is partially supported by National Science Foundation EHS
0311123, National Science Foundation ITR 0324977, and Army Research
Office MURI DAAD 19-02-01-0383.
1 A. N. Prior - the father of modern temporal logic - actually believed that
tense logic should be related as closely as possible to intuitions embodied
in everyday communications.

1-4244-0912-8/07/$25.00 ©2007 IEEE.

Ultimately, the human-robot interaction will be part of the
every day life. Nevertheless, most of the end users, that is the
humans, will not have the required mathematical background
in formal methods in order to communicate with the robots.
In other words, nobody wants to communicate with a robot
using logical symbols - hopefully not even the experts in
Linear Temporal Logic. Therefore, in this paper we advocate
that structured English should act as a mediator between the
logical formalism that the robots accept as input and the
natural language that the humans are accustomed to.
From a more practical point of view, structured English
helps even the robot savvy to understand better and faster
the capabilities of the robot without having an intimate
knowledge of the system. This is the case since structured
English can be tailored to the capabilities of the robotic
system, which eventually restricts the possible sentences in
the language. Moreover, since different notations are used
for the same temporal operators, a structured English framework targeted for robotic applications can offer a uniform
representation of temporal logic formulas. Finally, usage
of a controlled language minimizes the problems that are
introduced in the system due to ambiguities inherent in
natural language [22]. The last point can be of paramount
importance in safety-critical applications.
Related research moves along two distinct directions. First,
in the context of human-robot interaction through natural language, there has been research that converts natural language
input to some form of logic (but not temporal) and then maps
the logic statements to basic control primitives for the robot
[15], [18]. The authors in [20] show how human actions
and demonstrations are translated to behavioral primitives.
Note that these approaches lack the mathematical guarantees
that our work provides for the composition of the low level
control primitives for the motion planning problem. The
other direction of research deals with controlled language. In
[11], [13], whose application domain is model checking [3],
the language is mapped to some temporal logic formula. In
[23] it is used to convey user specific spatial representations.
In this work we assume the robot has perfect sensors that
give it the information it needs. In practice one would have
to deal with uncertainties and unknowns. The work in [19]
describes a system in which language as well as sensing can
be used to get a more reliable description of the world.
II. P ROBLEM F ORMULATION
Our goal is to devise a human-robot interface where the
humans will be able to instruct the robots in a controlled
language environment. The end result of our procedure

2717

should be a set of low level controllers for mobile robots
that generate continuous behaviors satisfying the user specifications. Such specifications can depend on the state of the
environment as sensed by the robot. Furthermore, they can
address both robot motion, i.e. the continuous trajectories,
and robot actions, such as making a sound or flashing a light.
To achieve this, we need to specify the robot’s workspace and
dynamics, assumptions on admissible environments, and the
desired user specification.
Robot workspace and dynamics: We assume that a mobile
robot (or possibly several mobile robots) is operating in
a polygonal workspace P . We partition P using a finite
number of convex polygonal regions P 1 , . . . , Pn , where
P = ∪ni=1 Pi and Pi ∩ Pj = ∅ if i = j. We discretize
the position of the robot by creating boolean propositions
Reg = {r1 , r2 , . . . , rn }. Here, ri is true if and only if
the robot is located in P i . Since {Pi } is a partition of
P , exactly one ri is true at any time. We also discretize
other actions the robot can perform, such as operating the
video camera or transmitter. We denote these propositions
as Act = {a1 , a2 . . . , ak } which are true if the robot is
performing the action and false otherwise. In this paper we
assume that such actions can be turned on and off at any
time, i.e., there is no minimum or maximum duration for the
action. We denote all the propositions that the robot can act
upon by Y = {Reg, Act}.
Admissible environments: The robot interacts with its
environment using sensors, which in this paper are assumed
to be binary. This is a reasonable assumption to make since
decision making in the continuous world always involves
some kind of abstraction. We denote the sensor propositions
by X = {x1 , x2 , . . . , xm }. An example of such sensor
propositions might be TargetDetected when the sensor
is a vision camera. The user may specify assumptions on
the possible behavior of these propositions, thus making
implicit assumptions on the behavior of the environment.
We guarantee that the robot will behave as desired only if
the environment behaves as expected, i.e., is admissible, as
explained in Section III.
User Specification: The desired behavior of the robot is
given by the user in structured English. It can include motion,
for example “Go to rooms [1, 2, 3] infinitely often”. It can
include an action that the robot must perform, for example
“If you are in room 5, then play music”. It can also depend
on the environment, for example “If you see Mika, go to
room 3 and stay there”.
Problem 1 (From Language to Motion): Given the robot
workspace, initial conditions, and a suitable specification in
structured English, construct (if possible) a controller so that
the robot’s resulting trajectories satisfy the user specification
in any admissible environment.
III. A PPROACH
In this section we give an overview of our approach to
creating the desired controller for the robot. Figure 1 shows
the three main steps. First, the user specification, together
with the environment assumptions and robot workspace and
dynamics, are translated into a temporal logic formula ϕ.

Environment
Assumptions

User
Specification

Robot
Workspace

Temporal Logic Formula
ϕ
Synthesis Algorithm
Automaton A
Hybrid Controller

Continuous Trajectories and Actions
Satisfying the User Specification

Fig. 1: Overview of the approach

Next, an automaton A that implements ϕ is synthesized.
Finally, a hybrid controller based on the the automaton A
is created.
The first step, the translation, is the main focus of this
paper. In Section IV, we give a detailed description of the
logic that we use and in Section VI we show how some
behaviors can be automatically translated. For now, let us
assume we have constructed the temporal logic formula ϕ
and that its atomic propositions are the sensor propositions
X and the robot’s propositions Y. The other two steps, i.e.
the synthesis of the automaton and creation of the controller,
are addressed in [14]. Here, we give a high level description
of the process through an illustrative example.
Hide and Seek: Our robot is moving in the workspace
depicted in Figure 3. It can detect people (through a camera)
and it can “beep” (using it’s speaker). We want the robot to
play “Hide and Seek” with Mika, so we want the robot to
search for Mika in rooms 1, 2 and 3. If it sees her, we want it
to stay where she is and start beeping. If she disappears, we
want the robot to stop beeping and look for her again. We
do not assume Mika is willing to play as well. Therefore, if
she is not around, we expect the robot to keep looking until
we shut it off.
This specification is encoded in a logic formula ϕ that
includes the sensor proposition X = {Mika} and the robot’s
propositions Y = {r1 , . . . , r4 , Beep}. The synthesis algorithm outputs an automaton A that implements the desired
behavior, if this behavior can be achieved. The automaton
can be non-deterministic, and is not necessarily unique, i.e.
there could be a different automaton that satisfies ϕ as well.
The automaton for the Hide and Seek example is shown in
Figure 2. The circles represent the automaton states and the
propositions that are written inside each circle are the robot
propositions that are true in that state. The edges are labelled
with the sensor propositions that enable that transition, that is
a transition labelled with “Mika” can be taken only if Mika
is seen. A run of this automaton can start, for example, at
the top most state. In this state the robot proposition r 1 is
true indicating that the robot is in room 1. From there, if the
sensor proposition M ika is true a transition is taken to the

2718

r1

A. LTL Syntax and Semantics

Mika

Syntax: Let AP be a set of atomic propositions. In our
setting AP = X ∪ Y, including both sensor and robot
propositions. LTL formulas are constructed from atomic
propositions π ∈ AP according to the following grammar

r1 Beep
Mika
r4

r1
r2
Mika
r2 Beep

ϕ ::= π | ¬ϕ | ϕ ∨ ϕ | 	 ϕ | 3ϕ

Mika
r4

r2

where 	 is the next time operator and 3 is the eventually
operator. As usual, the boolean constants True and False
are defined as True = ϕ ∨ ¬ϕ and False = ¬True
respectively. Given negation (¬) and disjunction (∨), we can
define conjunction (∧), implication (⇒), and equivalence
(⇔). Furthermore, we can also derive the always operator
as 2ϕ = ¬3¬ϕ.
Semantics: The semantics of an LTL formula ϕ is defined
on an infinite sequence σ of truth assignments to the atomic
propositions π ∈ AP . For a formal definition of the semantics we refer the reader to [3]. Informally, the formula 	ϕ
expresses that ϕ is true in the next “step” (the next position
in the sequence). The sequence σ satisfies formula 2ϕ if ϕ
is true in every position of the sequence, and satisfies the
formula 3ϕ if ϕ is true at some position of the sequence.
Sequence σ satisfies the formula 23ϕ if ϕ is true infinitely
often.

r3
Mika
r3 Beep
Mika
r3

r4

Fig. 2: Automaton for the Hide and Seek example

1

1

4

4

3

2

3

2

(a) The robot found Mika in 2

(b) Mika disappeared from 2 and
the robot found her again in 3

Fig. 3: Simulation for the Hide and Seek example

B. Special class of LTL formulas
state that has both r1 and Beep true meaning that the robot
is in room 1 and is beeping, otherwise, a transition is made
to the state in which r4 is true indicating the robot is now
in room 4 and so on.
The hybrid controller used to drive the robot and control its
actions continuously executes the discrete automaton. When
the automaton transitions from a state in which r i is true to
a state in which rj is true, the hybrid controller envokes a
simple continuous controller that is gueranteed to drive the
robot from P i to Pj without going through any other cell [1],
[6], [17]. Based on the current automaton state, the hybrid
controller also activates actions whose propositions are true
in that state and deactivates all other robot actions.
Returning to our example, Figure 3 shows a sample
simulation. Here Mika is first found in room 2, therefore
the robot is beeping (indicated by the lighter colored stars)
and staying in that room (Figure 3.a). Then, Mika disappears
so the robot stops beeping (indicated by the dark dots) and
looks for her again. It finds her in room 3 where it resumes
the beeping (Figure 3.b).
IV. T EMPORAL L OGIC
We use a fragment of Linear Temporal Logic (LTL) [3]
to formally describe the assumptions on the environment,
the dynamics of the robot and the desired behavior of the
robot, as specified by the user. We first give the syntax and
semantics of the full LTL. Then, following [21], we describe
the specific structure of the LTL formulas that will be used
in this paper.

Following [21], we consider a special class of temporal
logic formulas. These LTL formulas are of the form ϕ =
ϕe ⇒ ϕs . The formula ϕ e acts as an assumption about the
sensor propositions and, thus, as an assumption about the
environment, and ϕ s represents the desired robot behavior.
The formula ϕ is true if ϕ s is true, i.e., the desired robot
behavior is satisfied, or ϕ e is false, i.e., the environment
did not behave as expected. This means that when the
environment does not satisfy ϕ e and is thus not admissible,
there is no guarantee about the behavior of the robot. Both
ϕe and ϕs have the following structure
ϕe = ϕei ∧ ϕet ∧ ϕeg ; ϕs = ϕsi ∧ ϕst ∧ ϕsg
ϕei and ϕsi describe the initial condition of the environment and the robot. ϕ et represents the assumptions on the
environement by constraining the next possible sensor values
based on the current sensor and robot values. ϕ st constrains
the moves the robot can make and ϕ eg and ϕsg represent the
assumed goals of the environment and the desired goals of
the robot, respectively. For a detailed description of these
formulas the reader is referred to [14].
Despite the structural restrictions of this class of LTL
formulas, there does not seem to be a significant loss in
expressivity as most specifications encountered in practice
can be either directly expressed or translated to this format.
Furthermore, the structure of the formulas very naturally
reflects the structure of most sensor-based robotic tasks.
V. E NVIRONMENT AND M OTION C ONSTRAINTS
As mentioned before, we can view the LTL formulas as
encoding three components. First, ϕ e represents the assumptions we make on the behavior of the environment, as sensed

2719

by the robot. Second, ϕ si and ϕst describe the robot’s initial
condition and dynamics. Finally, ϕ sg represents the desired
behavior of the robot. Note that in some cases, the desired
behavior is also encoded in ϕ st as discussed in Section VI.
A. Environment Assumptions
In this paper we allow the user to choose between two
types of environments. The first, which is the most general
case, is when we have no assumptions on the behavior of the
environment, just initial conditions of the sensors. The user
input in this case is “Environment with initial conditions”
E“.” where E is the set of all sensors that are initially true.
In this case
ϕeGeneral = ∧x∈E x ∧x∈E ¬x ∧ 2True ∧ 23True
The second is the case in which the robot behavior does
not depend on it’s environment, for example “go to room
4” (no sensing specified). The user input in this case is
“Any Environment.”. Here a dummy sensor proposition must
be defined for the completeness of this special class of
LTL formulas. We arbitrarily choose it to be always false.
Therefore, we have
ϕeNoSensors = ¬Dummy ∧ 2¬Dummy ∧ 23True
The logic formulation allows much richer environment assumptions. Creating a language interface for them is a topic
for future work.
B. Motion Constraints
The position of the robot is represented by the propositions
ri ∈ Y. The robot can only move, at each discrete step, from
one cell to an adjacent cell and it can not be in two cells at the
same time (mutual exclusion). We can automatically translate
these constraints from a description of the workspace into a
logic formula. A transition is encoded as
ϕstTransition(i)

= 2(ri ⇒ (	ri ∨r∈N 	r))

where N is the set of all the regions that are adjacent to ri . All transitions are encoded as ϕ stTransitions =
∧i=1,...,n ϕstTransition(i) . The mutual exclusion is encoded as
ϕstMutualExclusion = 2(∨1≤i≤n (ri ∧1≤j≤n,i=j ¬rj ))
Constraints on the other actions of the robots, if such exist,
should be encoded into ϕ st as well. In this paper we assume
there are no such constraints.
VI. D ESIRED B EHAVIOR
Our goal in this section is to design a controlled language
for the motion and task planning problems for a mobile robot.
Similar to [10], [13], we first give a simple grammar (Table
I) that produces the sentences in our controlled language and
then we give the semantics of some of the sentences in the
language with respect to the LTL formulas. We distinguish
between two forms of behaviors, Safety and Liveness. Safety
includes all behaviors that the robot must always satisfy, such
as “Always avoid corridor 2” or “If Mika is found, then stay
there”. These behaviors are encoded in ϕ st and are of the
form 2(f ormula). The other behavior, liveness, includes

things the robot should always eventually satisfy, such as
“Go to room 4 infinitely often” or “Go to room 1 infinitely
often unless Mika is seen”. These behaviors are encoded in
ϕsg and are of the form 23(f ormula).
Some of the rules of the grammar for our controlled
language L appear in Table I. Note that L is actually an
infinite language. The literal terminals are marked using
quotation marks “...”, the non-literal terminals are denoted by
bold face (capital letters denote lists of symbols while small
letters just one symbol) and non-terminals by italics. In some
cases, we allow for synonyms in the literal terminals. For
example, “go to” can be replaced by “visit” or “reach”, while
“detected” by “found” or “seen”. The terminal R ranges over
subsets of Reg, i.e., over sets of regions of interest. For
example R can be replaced by {room 1, corridor 2}. C ranges
over sets of active actions at the initial state. The terminal
s ranges over the predicates for the sensors, for example
“Mika”, “fire”, “person” and so on, while the terminals a 1 ,
a2 , . . . range over predicates for the actions, for example
“beep”, “picture”, “medic”, “fireman” and so on. A point
that we should make is that the grammar is designed so as
the user can write specifications for only one robot. Any
inter-robot interaction comes into play through the sensor
propisitions. For example we can add a sensor proposition
“Robot2in4”, which is true whenever the other robot is in
room 4, and then refer to that proposition: “If Robot2in4,
then go to room 1”.
We now show how several simple commands are translated
automatically to an LTL formula ϕ.
Initial Conditions: The initial condition of the robot is
given by the user by specifying the initial region that the
robot is in and all other output propositions that are initially
True. Let Rr = Reg − {r}, then the sentence “You start in
r with initial conditions C” is translated to
ϕsi = r ∧r̄∈Rr ¬r̄ ∧a∈C a ∧a∈Act\C ¬a
Motion Rules: The requirement “go to r infinitely often”
is mapped to the temporal formula:
ϕsgGoTo(r) = 23r
This formula makes sure the robot visits room r infinitely
often. We can request the robot to visit multiple rooms, such
as “go to R′ infinitely often” for R ′ ⊆ Reg, by taking
conjunctions of “go to” specifications. Note that such a
conjunction does not specify in which order the rooms must
be visited. It only requests that all rooms be visited infinitely
often.
The “go to” specification does not make the robot stay
in room r, once it arrived there. If we want to specify “go
to room r and always stay there” 2 , we must add a safety
behavior that requires the robot to stay in room r once it
arrives there. The specification is translated to
ϕstgGoStay(r) = 23r ∧ 2(r ⇒ 	r)
2 Note that the simple grammar in Table I allows for “go to r infinitely
often and go to q and always stay there”. This is an infeasible specification,
and the synthesis algorithm will inform the user that it is unrealizable.

2720

Start
Conditional

::=
::=

Condition

::=

Action
Action+
Action−
Motion
Motion+
Motion−

::=
::=
::=
::=
::=
::=

“You start in” r “with initial conditions” C “.” (Conditional | Motion “.” | Motion “.” Conditional)
Conditional Conditional | “If” Condition “, then” (Motion+ | Action) “.” |
| (Motion+ | Action) “unless” Condition “.” | (Motion+ | Action) “iff” Condition
Condition “and” Condition | Condition “or” Condition | “you are in” R |
| “you are not in” R | “You detect” s | s “is detected” | . . .
Action “and” Action | Action+
Action− | “do not” Action−
a1 | “take” a2 | “call” a3 | . . .
Motion “and” Motion | Motion− | “go to” r “and always stay there”
Motion− | “stay there”
“go to” R “infinitely often” | “always avoid” R | . . .

TABLE I: The basic grammar rules for the motion planning problem.

This formula states that if the robot is in room r, in the next
step it must be in room r as well. We define both Motion
and Motion+ to allow sentences of the form “If you sense
Mika, then stay there” while prohibiting combinations such
as “always avoid r and stay there”.
Another motion primitive is avoidance. Since avoidance
is a safety behavior, it is encoded in ϕ st . The specification
“always avoid r” is translated into
ϕstAvoid(r)

8

21

22

5
24

9

17

12
13

10

14

19

23
18

15

= 2(¬ 	 r)

4

2

The semantics of the conditional rules depend on the rules
used in the consequence. For example, “If condition, then go
to r” converts to
ϕsgIfGoTo(Condition,r) = 23(Condition ⇒ r)
While “If condition then avoid r” translates to
ϕstIfAvoid(Condition,r) = 2(Condition ⇒ ¬ 	 r)
For lack of space we will not discuss further how such
conditionals are translated to LTL.
Now we turn to the composition of conditionals with
action primitives. Turning on or off other outputs of the robot
will typically be a safety behavior of the form “If on(off)condition, then (do not) action”.
ϕstDoNot(a)

6

20
16

11

3

meaning, the robot will not be in room r in the next step.
Again, as before, we can tell the robot to avoid several rooms
taking a conjunction of ϕ stAvoid(r)
Conditional Rules: We can translate “if ... then ...” or “...
unless ...” commands using temporal logic by connecting the
condition and the requirement with the appropriate logical
connective. As an example for a condition, the sentence
“you are in R ′ ”, where R ′ ⊆ Reg, translates to the boolean
formula
ϕin(R′ ) = ∨r∈R′ r

ϕstDo(a)

7
1

Fig. 4: Simulation for the Visit and Beep example

VII. E XAMPLES
In the following, we assume that the workspace of the
robot contains 24 rooms (Figures 4, 5). Given this workspace
we automatically generate ϕ stTransitions and ϕstMutualExclusion
relating to the motion constraints
No Sensors: Here we assume the robot has no sensor
inputs, therefore we will automatically generate the dummy
proposition and ϕ e = ϕeNoSensors
Visit and Beep: In this example the robot can move
and beep, therefore Y = {r 1 , . . . , r24 , Beep}. The user
specification is: “Any Environment. You start in r 1 with
initial conditions ∅. Go to {r 1 , r3 , r5 , r7 } infinitely often.
Beep iff you are in {r 9 , r12 , r17 , r23 }.”
The behavior of the above example is first automatically
translated into the formula ϕ:

= 2( OnCondition ⇒ 	a)
= 2( OffCondition ⇒ ¬ 	 a)

The conditional “... iff ... ” is short for if and only if and is
created by taking the conjunction of “If” Condition “, then”
(Motion+ | Action) “.” and “If” NOT Condition “, then” NOT
(Motion+ | Action) “.”
One final note is that the different sentences in the Start
rule are converted to a temporal formula by taking conjunctions of the respective temporal subformulas. We give several
examples in the next section.

ϕe

=

ϕs

=

¬Dummy ∧ 2¬Dummy ∧ 23True

r1 ∧i=2,...,24 ¬ri ∧ ¬Beep



 ∧ϕstTransitions ∧ ϕstMutualExclusion
∧23(r1 ) ∧ 23(r3 ) ∧ 23(r5 ) ∧ 23(r7 )


∧2((r

9 ∨ r12 ∨ r17 ∨ r23 ) ⇒ 	Beep)

∧2(¬(r9 ∨ r12 ∨ r17 ∨ r23 ) ⇒ ¬ 	 Beep)

Then an automaton is synthesized and a hybrid controller is
constructed. Sample simulations are shown in Figure 4. As
before, beeping is indicated by lighter colored stars.
Sensors: Let us assume that the robot has two sensors, a
camera that can detect an injured person and another sensor
that can detect a gas leak, therefore X = {Person, Gas}.
Search and Rescue: Here, other than moving, the robot can
communicate to the base station a request for either a medic
or a fireman. We assume that the base station can track the
robot therefore it does not need to transmit it’s location. We

2721

7
6

20

1
8

16

11

21

22

5
24

9

13
10

17

12

14

19

23
18

15

4

3
2

Fig. 5: Simulation for the Search and Rescue example

define Y = {r1 , . . . , r24 , Medic, Fireman}. The user specification is “Environment with initial conditions ∅. You start
in r1 with initial conditions ∅. Go to {r 1 , . . . , r24 } infinitely
often. Call Medic iff Person is found. Call Fireman iff Gas
is detected.”
A sample simulation is shown in Figure 5. Here, a person
was detected in region 10 resulting in a call for a Medic
(light cross). A gas leak was detected in region 24 resulting
in a call for a Fireman (light squares). In region 12, both a
person and a gas leak were detected resulting in a call for
both a Medic and a Fireman (dark circles)
VIII. C ONCLUSIONS - F UTURE WORK
In this paper we have described a method for automatically
translating robot behaviors from a user specified description
in structured English to actual robot controllers and trajectories. Furthermore, this framework allows the user to specify
reactive behaviors that depend on the information the robot
gathers from its environment at run time. We have shown
how several complex robot behaviors can be expressed using
structured English and how these phrases can be translated
into temporal logic. The extension of the results in this paper
to deal with complex dynamics [7] as well as non-holonomic
vehicles [5] follows naturally.
As mentioned in this paper, we have not yet captured
the full expressive power of the special class of LTL formulas. This logic allows the user to specify sequences of
behaviors, different environment assumptions and other robot
constraints. This is a topic of future work.
We also intend to construct a corpus of what people
would typically ask a robot to do and use it to explore if
and how natural language might be translated into the logic
formulation.
IX. ACKNOWLEDGMENTS
We would like to thank David Conner for allowing us
to use his code for the potential field controllers and Nir
Piterman, Amir Pnueli and Yaniv Sa’ar for allowing us to
use their code for the synthesis algorithm.
R EFERENCES
[1] C. Belta and L. Habets. Constructing decidable hybrid systems with
velocity bounds. In IEEE Conference on Decision and Control,
Bahamas, 2004.

[2] H. Choset, K. M. Lynch, L. Kavraki, W. Burgard, S. A. Hutchinson,
G. Kantor, and S. Thrun. Principles of Robot Motion: Theory,
Algorithms, and Implementations. MIT Press, Boston, USA, 2005.
[3] E. M. Clarke, O. Grumberg, and D. A. Peled. Model Checking. MIT
Press, Cambridge, Massachusetts, 1999.
[4] D. C. Conner, H. Choset, and A. Rizzi. Towards provable navigation
and control of nonholonomically constrained convex-bodied systems.
In Proceedings of the 2006 IEEE International Conference on Robotics
and Automation (ICRA ’06), May 2006.
[5] D. C. Conner, H. Kress-Gazit, H. Choset, A. A. Rizzi, and G. J.
Pappas. Valet parking without a valet. In IEEE/RSJ Int’l. Conf. on
Intelligent Robots and Systems, San Diego, CA, October 2007.
[6] D. C. Conner, A. A. Rizzi, and H. Choset. Composition of Local
Potential Functions for Global Robot Control and Navigation. In
IEEE/RSJ Int’l. Conf. on Intelligent Robots and Systems, pages 3546
– 3551, Las Vegas, NV, October 2003.
[7] G. E. Fainekos, A. Girard, and G. J. Pappas. Hierarchical synthesis
of hybrid controllers from temporal logic specifications. In Hybrid
Systems: Computation and Control, number 4416 in LNCS, page
203216. Springer, 2007.
[8] G. E. Fainekos, H. Kress-Gazit, and G. J. Pappas. Hybrid controllers
for path planning: A temporal logic approach. In IEEE Conference
on Decision and Control, pages 4885–4890, Seville, Spain, 2005.
[9] G. E. Fainekos, H. Kress-Gazit, and G. J. Pappas. Temporal logic
motion planning for mobile robots. In IEEE International Conference
on Robotics and Automation, pages 2020–2025, Barcelona, Spain,
2005.
[10] S. Flake, W. Müller, and J. Ruf. Structured english for model checking
specification. In GI–Workshop Methoden und Beschreibungssprachen
zur Modellierung und Verifikation von Schaltungen und Systemen in
Frankfurt, Berlin, 2000. VDE Verlag.
[11] A. Holt and E. Klein. A semantically-derived subset of english for
hardware verification. In Proceedings of the 37th annual meeting
of the Association for Computational Linguistics on Computational
Linguistics, pages 451–456, Morristown, NJ, USA, 1999. Association
for Computational Linguistics.
[12] M. Kloetzer and C. Belta. Hierarchical abstractions for robotic
swarms. In Proceedings of the IEEE International Conference on
Robotics and Automation, pages 952 – 957, 2006.
[13] S. Konrad and B. H. C. Cheng. Facilitating the construction of
specification pattern-based properties. In Proceedings of the IEEE
International Requirements Engineering Conference, Paris, France,
August 2005.
[14] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas. Where’s waldo?
sensor based temporal logic motion planning. In IEEE International
Conference on Robotics and Automation, pages 3116–3121, Rome,
Italy, 2007.
[15] S. Lauria, T. Kyriacou, G. Bugmann, J. Bos, and E. Klein. Converting
natural language route instructions into robot-executable procedures.
In Proceedings of the 2002 IEEE International Workshop on Robot and
Human Interactive Communication, pages 223–228, Berlin, 2002.
[16] S. M. LaValle. Planning Algorithms. Cambridge University Press,
Cambridge, U.K., 2006. Available at http://planning.cs.uiuc.edu/.
[17] S. Lindemann and S. LaValle. Computing smooth feedback plans
over cylindrical algebraic decompositions. In Proceedings of Robotics:
Science and Systems, Cambridge, USA, June 2006.
[18] A. J. Martignoni III and W. D. Smart. Programming robots using
high-level task descriptions. In M. Rosenstein and M. Ghavamzadeh,
editors, Proceedings of the AAAI Workshop on Supervisory Control of
Learning and Adaptive Systems, pages 49–54, June 2004.
[19] N. Mavridis and D. Roy. Grounded situation models for robots: Where
words and percepts meet. In IEEE/RSJ Int’l. Conf. on Intelligent
Robots and Systems, Beijing, China, October 2006.
[20] M. Nicolescu and M. J. Mataric. Learning and interacting in humanrobot domains. IEEE Transactions on Systems, Man, and Cybernetics,
Part B,special issue on Socially Intelligent Agents - The Human in the
Loop, 31(5):419–430, 2001.
[21] N. Piterman, A. Pnueli, and Y. Sa’ar. Synthesis of Reactive(1) Designs.
In VMCAI, pages 364–380, Charleston, SC, Jenuary 2006.
[22] S. Pulman. Controlled language for knowledge representation. In Proceedings of the 1st International Workshop on Controlled Language
Applications, 1996.
[23] E. A. Topp, H. Hüttenrauch, H. I. Christensen, and K. S. Eklundh.
Bringing together human and robotics environmental representations
/ a pilot study. In Proc. IEEE/RSJ Intl Conf on Intell. Robots and
Systems (IROS-06), Beijing, CH, October 2006.

2722

Towards composition of conformant systems

arXiv:1511.05273v2 [cs.SY] 18 Nov 2015

Houssam Abbas and Georgios Fainekos

Abstract— Motivated by the Model-Based Design process for
Cyber-Physical Systems, we consider issues in conformance
testing of systems. Conformance is a quantitative notion of
similarity between the output trajectories of systems, which
considers both temporal and spatial aspects of the outputs.
Previous work developed algorithms for computing the conformance degree between two systems, and demonstrated how
formal verification results for one system can be re-used for
a system that is conformant to it. In this paper, we study the
relation between conformance and a generalized approximate
simulation relation for the class of Open Metric Transition
Systems (OMTS). This allows us to prove a small-gain theorem
for OMTS, which gives sufficient conditions under which the
feedback interconnection of systems respects the conformance
relation, thus allowing the building of more complex systems
from conformant components.

I. I NTRODUCTION
In Model-Based Design (MBD) of systems, an executable
model of the system is developed early in the design process.
This allows the verification engineers to conduct early testing [3]. The model is then refined iteratively and more details
are added, e.g., initially ignored physical phenomena, time
delays, etc. This eventually leads to the final model that gets
implemented on some computational platform, for example
via automatic code generation. See Fig. 1.
Each of the above transformations and calibrations introduces discrepancies between the output behavior of the
original system (the nominal system) and the output behavior of the derived system (the derived system). These
discrepancies are spatial (e.g., slightly different signal values
in response to same stimulus, dropped samples, etc) and
temporal (e.g., different timing characteristics of the outputs,
out-of-order samples, delayed responses, etc) and their magnitude can vary as time progresses.
Ideally, the initial (simpler) model should be amenable
to formal synthesis and verification methods (cycle 1 in
Fig. 1) through tools like [5], [18]. To understand how the
formal verification results on the simpler nominal model
can be applied to the derived more complex system, it
is necessary to quantify the conformance degree between
them. The conformance degree, introduced in [1], [2], is a
measure of both spatial and temporal differences between the
output behaviors of two systems. It relaxes traditional notions
of distance, like sup norm and approximate simulation, to
H. Abbas is with the Department of Electrical, Computer and
Energy Engineering, Arizona State University, Tempe, U.S.A.

hyabbas@asu.edu
G. Fainekos is with the School of Informatics, Decisions and
Systems Engineering, Arizona State University, Tempe, U.S.A.

gfaineko@asu.edu
This work was partially supported by NSF awards CNS 1350420 and
CPS 1446730.

Calibration and
Deployment Sd

4

Specifications

Simple Model
Ms

1

Complex Model
Mc

2

3

3

Implementation
Si (HIL)

Automatic Code
Generation

Fig. 1.

Model-Based Development V-process.

encompass a larger class of systems, and to allow re-ordering
of output signal values. In [2], it was shown how the formal
properties satisfied by the derived system can be automatically obtained from knowledge of the properties satisfied
by the nominal system, and knowledge of the conformance
degree between them. In this paper, we extend that work by
studying feedback interconnections of systems. Specifically,
we are concerned with the following question: suppose we
have a feedback interconnection of a plant and controller,
and the closed-loop system has been formally verified to
satisfy some properties. If the controller (or the plant) is
replaced by another controller which is conformant to it,
is the new closed-loop system conformant to the original
closed-loop system? If yes, can we estimate its conformance
degree without explicitly re-computing it? A positive answer
to both questions would allow us to leverage the results in
[2] and automatically deduce the properties satisfied by the
new interconnection.
In this paper, we give a positive answer to both questions
for a general class of dynamical systems modeled as Open
Metric Transition Systems (OMTS). These are defined in
Section II-A. The tool we use is a generalized notion of
Space-Time Approximate Simulation (STAS) relation, which
is defined in Section III-A. We show in Section III-B that
the existence of such a relation between two OMTS implies
that they are also conformant, and yields the conformance
degree between them. In Section IV we provide a smallgain theorem for OMTS, which gives sufficient conditions
under which feedback interconnections of OMTS respect
approximate simulation, and therefore conformance. This is
done via STAS functions, which are Lyapunov-like functions
that certify the existence of a STAS relation between two
systems.

Notation. For a positive integer n, [n] = {1, . . . , n}.
Given a set Σ, Σ∗ is the set of finite strings on Σ, i.e.
Σ∗ = {s0 s1 . . . sn | si ∈ Σ, n ∈ N}. Given two sets A, B
and (a, b) ∈ A × B, prA ((a, b)) = a.
II. C ONFORMANCE OF O PEN M ETRIC T RANSITION
S YSTEMS
In this section, we define a general system model, namely,
Open Metric Transition Systems (OMTS). These extend Metric Transition Systems [8] in that they allow interconnection
of systems, and will be our formalism of choice in this paper.
We then define the conformance relations for OMTS and
feedback interconnections for OMTS, which allows us to
speak of controlled OMTS and compositionality in Section
IV. As an illustration, we show how hybrid systems can be
modeled as OMTS.
A. Open metric transition systems and conformance
A Metric Transition System (MTS) serves to model, at an
abstract level, a fairly large class of systems. An MTS is a
tuple T = (Q, Σχ , →, Q0 , Π, h i) where Q is a set known as
the state space, Q0 ⊂ Q is the set of initial states, Σχ is the
set of labels on which transitions take place, →
− ⊂ Q×Σχ ×Q
is the transition relation, Π is the output set, and hi : Q → Π
σχ
is the output map. We write q −−→ q 0 to denote an element
(q, σχ , q 0 ) ∈→. Both Q and Π are metric spaces, that is,
they are equipped with metrics dQ and dΠ . Moreover, for
any q ∈ Q and any label subset S ⊂ Σχ , the set
Post(q, S) = ∪σχ ∈S Post(q, σχ )

(1)

is compact in the metric-induced topology.
Given a string of labels σ¯χ = σχ ,1 σχ ,2 . . . σχ ,m , we write
σ¯χ [i] ∈ Σ∗χ for the prefix string σχ ,1 σχ ,2 . . . σχ ,i , i ≤ m.
The sets Σχ and Σ∗χ are equipped with pseudo-metrics1 dΣχ
and dΣ∗χ , respectively, and Π is equipped with a metric dΠ .
When two MTS share the same Σχ (Σ∗χ , Π), they also share
the same associated (pseudo-)metrics.
An Open Metric Transition System (OMTS) is a tuple
T = (Q, Σ, →
− T , Q0 , Π, h i , p) where (Q, Σ, →T , Q0 , Π, h i)
is an MTS as above. The label set Σ of an OMTS has
a special structure: Σ ⊂ Σu × Σχ for sets Σu , Σχ . The
intuition behind this division is that Σu will be used to
model input signals to the system embedded as an OMTS,
and Σχ will be used to model the domain of that input
signal. This departs from earlier approaches to embedding
forced dynamical systems as MTS [7], because we need a
way to describe interconnections of MTS, while preserving
timing information in the interconnection. A generic label σ
thus has two components: σ = (σu , σχ ). The string prefix
σ̄[i] is defined similarly to the case of MTS. The port map
p : (−
→T ) → Σ ∪ {ν} associates a label to each transition
in →
− T , or a special empty label ν. The empty label, as we
will see, is used to allow a system to make empty transitions
which don’t change its state and don’t advance time. The
output of the port map will be used to compose OMTS.
1A

pseudo-metric does not separate points.

This makes them similar to hybrid I/O automata [14] but
enriched with a metric structure, and with ‘discrete actions’
and ‘trajectories of input variables’ lumped into one label
set, which fits well our usage of hybrid time.
We now define conformance between two OMTS T1 and
T2 . Conformance quantifies the similarity between systems,
and accounts for the fact that in a typical MBD process
(Fig. 1), the output signals of the derived model will have
temporal and spatial differences with the outputs of the
nominal model. From the knowledge of the conformance
degree between two systems, we can conclude what formal
specifications are satisfied by one, given the specifications
satisfied by the other [2].
Definition 2.1 (Conformance): Let T1 and T2 be two
OMTS with a common output space Π and common label
set Σ. Let τ, ε be two non-negative reals. Let D ⊂ Q01 × Q02
be a relation defined on their initial sets. We refer to D as
the derivation relation. We say T2 conforms to T1 with
precision (τ, ε) and derivation relation D, which we write
0 0
T1 C
τ,ε T2 , if for all (q1 , q2 ) ∈ D, and any sequence of T1
transitions
σ

σ

σ

...

1
n
1 2
2
m
q10 −→
→1 . . . −−→
1 q1 −→1 q1 −
1 q1

there exists a sequence of T2 transitions
α

α

...

α

0

1
2
n
1
2
m
q20 −→
→2 . . . −−→
2 q2 −→2 q2 −
2 q2

such that

  
 
(a) for all q1i , i ∈ [m], there exists q2k s.t. dΠ ( q1i , q2k ) ≤
ε and dΣ∗ (σ̄[i] , ᾱ[k] ) ≤ τ

  
 
(b) for all q2i , i ∈ [m0 ], there exists q1k s.t. dΠ ( q1k , q2i ) ≤
ε and dΣ∗ (σ̄[k] , ᾱ[i] ) ≤ τ
Intuitively, the definition requires T2 to be able to match any
execution of T1 , with some allowed deviation between the
states that each execution visits, and some allowed deviation
between the labels on which transitions take place. The
matching is required not only for the final reached states
0
q1m and q2m , but for all intermediary states. The relation D
is meant to capture the mapping between the initial states of
one model (T1 ) and the initial states of its implementation
(T2 ). For example, if T2 is obtained by model order reduction
from T1 , D captures the reduction mapping as applied to the
initial states. Because some of the labels in either transition
sequence may be the empty label ν, more than one state in
one sequence may match with the same state in the other
sequence.
B. Feedback interconnection of OMTS
Given two OMTS T1 and T2 , we define their feedback
interconnection as follows.
Definition 2.2 (Feedback in OMTS): Let Ti be an OMTS
(Qi , Σ, →
− i , Q0i , Πi , h ii , pi ), i = 1, 2, such that Σ = Σu ×
Σχ . Assume that Σ ⊃ p2 (−
→2 ) and Σ ⊃ p1 (−
→1 ). Their
feedback interconnection is a (closed) MTS (Q, Σχ 12 , →
−
, Q0 , Π, h i), denoted T1 ◦ T2 , where
• Q = Q1 × Q2
• Σχ 12 ⊂ Σχ

Q0 = Q01 × Q02
• Π = Π1 × Π2
• h(q1 , q2 )i = (hq1 i1 , hq2 i2 )
σχ
• →
− : (q1 , q2 ) −−→ (q10 , q20 ) iff ∃σ1 = (σ1,u , σχ ) ∈ Σ and
σ1
σ2
0
0
σ2 = (σ2,u , σχ ) ∈ Σ s.t. q1 −→
1 q1 , q2 −→2 q2 , and
σ
σ2
1
0
0
σ1 = p2 (q2 −→2 q2 ), σ2 = p1 (q1 −→1 q1 ).
The output set distance is given by
•

dΠ ((q1 , q2 ), (q10 , q20 )) = h̃(dΠ1 (q1 , q10 ), dΠ2 (q2 , q20 ))
for some positive non-decreasing function h̃.
This is meant to model the situation when two hybrid systems
are feedback interconnected, such that T1 ’s outputs constitute
the inputs to T2 , and vice versa. Note that the definitions of
output set, output map and associated distance function are
somewhat arbitrary and ultimately depend on the application
domain.
To simplify the statement of the main theorem and its
proof, we introduce the following ‘lifting’ of Σχ 12 to Σ × Σ.
The set Σ12 defined below contains all label pairs (σ1 , σ2 ) ∈
Σ1 × Σ2 allowed by the interconnection T1 ◦ T2 . Formally:
σ

2
0
Σ12 := {(σ1 , σ2 ) ∈ Σ × Σ | σ1 = p2 (q2 −→
2 q2 ),

σ

1
0
σ2 = p1 (q1 −→
1 q1 ), σχ 1 = σχ 2 ∈ Σχ 12 ,

σ

σ

2
1
0
0
for some transitions q2 −→
2 q2 and q1 −→1 q1 }
(2)

We note two properties of Σ12 :
1) Σ12 ⊂ Σ × Σ
2) minimizing a function over the transitions enabled by
labels in Σχ 12 yields the same result as minimizing it
over the transitions enabled by labels in the lifting Σ12 .
C. Problem formulation
The formal statement of this paper’s problem follows:
Given two OMTS T1 and T2 connected in a feedback loop,
and OMTS T3 that conforms to T1 with precision (τ, ε) and
derivation relation D, is T3 ◦T2 conformant to the T1 ◦T 2? If
yes, what is the conformance degree between the two loops?
D. Embedding a hybrid system as an OMTS
Hybrid systems can be represented using, or embedded
as, OMTS. This enables us to apply the compositionality
result to them. We briefly define hybrid systems to show the
embedding. Let C and D be subsets of Rn+m , U ⊂ Rm be a
set of input values, F : Rn+m ⇒ Rn and G : Rn+m ⇒ Rn
be set-valued maps with C ⊂ domF and D ⊂ domG. Let
z : Rn → Rnz be a function. The hybrid dynamical system
H with data (C, F, D, G, z), internal state x ∈ Rn and output
y ∈ Rnz is governed by [10]

∈ F (x, u)
(x, u) ∈ C
 ẋ
x+ ∈ G(x, u)
(x, u) ∈ D
H
(3)

y
= z(x)
The ‘jump’ map G models the change in system state at a
mode change, or ‘jump’, and the jump set D captures the
conditions causing a jump. The ‘flow’ map F models state

evolution away from jumps, while (x, u) is in the flow set
C. System trajectories start from a specified set of initial
conditions H0 ⊂ prRn (C ∪ D). Finally, the output of the
system y is given as a function z of its internal state, and its
input is given by u which takes values in a set U .
Solutions (φ, u) to (3) are given by a hybrid arc φ and an
input arc u sharing the same hybrid time domain domφ =
domu, and with standard properties that can be reviewed
in [9, Ch. 2] .
Definition 2.3 (Hybrid time domains and arcs [10]): A
subset E ⊂ R+ × N is a compact hybrid time domain if
E=

J−1
[

[tj , tj+1 ] × {j}

j=0

for some finite increasing sequence of times 0 = t0 ≤ t1 ≤
t2 ≤ . . . ≤ tJ . A hybrid arc φ is a function supported over
a hybrid time domain φ : E → Rn , such that for every j,
φ(·, j) is locally absolutely continuous in t over Ij = {t :
(t, j) ∈ E}; we call E the domain of φ and write it domφ.
A hybrid system H = (C, F, D, G, z) can be embedded
as an OMTS T = (Q, Σ, →, Q0 , Π, h i , p) as follows: Q =
{x ∈ Rn | ∃u : (x, u) ∈ C ∪ D}, Q0 ⊂ Q, h i = z, and
Π = Rnz . The label set is made of input arcs and their
domains, and the empty label ν:
Σ = {(u, domu) | u is an input arc} ∪ {ν}

(4)

σ

The transition relation is defined as q −
→ q 0 iff either σ = ν
0
is the empty label and q = q , or σ = (u, domu) and there
exists a solution pair (φ, u) s.t. φ(0, 0) = q, φ(t, j) = q 0 for
some (t, j) in domu. The port map p is defined as

(z(q), (0, 0))
if σ = ν
σ
p(q −
→ q0 ) =
(z ◦ φ, domφ) otherwise
where (φ, u) is the solution pair of H corresponding to σ as
defined above in (4).
Later in the paper, we will need to impose a requirement
on dΣ , namely, equation (5) from Section III-B. The rest of
this section shows how dΣ can be defined so this requirement
is met. First, given an input arc u with domain E and two
subsets E 0 ⊂ E, E 00 ⊂ E such that (0, 0) ∈ E 0 ∩ E 00
and supj E 0 = supj E 00 , the restrictions of u to E 0 and E 00
respectively are said to have a common extension. (So the
restricted arcs start at (0, 0) and make the same number of
jumps).
Let σ = (u, E), σ 0 = (u0 , E 0 ) be two labels with E =
0
J−1
∪j Ij × {j}, E 0 = ∪jJ −1 Ij0 × {j} compact hybrid time
domains with J and J 0 jumps, respectively. Define

u and u0 have a
maxj dH (Ij , Ij0 )
0
dΣ (σ, σ ) :=
common extension

∞
otherwise
Here, dH is the symmetric Haussdorff distance between two
sets. A string s = σ1 σ2 . . . σm is then a concatenation of the

input arcs and their hybrid time domains2 , and is itself a
valid pair (input arc, hybrid time domain). That is, in this
case, Σ∗ ⊂ Σ. Therefore given two strings s and a, we
simply define dΣ∗ (s, a) = dΣ (s, a). It can be shown that
this satisfies (5).

V24

T2

T4

T1

T3

III. F ROM SIMULATION RELATIONS TO CONFORMANCE
RELATIONS

A. Space-Time Approximate Simulations
A Space-Time Approximate Simulation (STAS) relation is
an approximate simulation relation in the sense of [12]. We
choose to introduce the new terminology in order to avoid
potentially awkward (and possibly confusing) references to
‘simulation relations in the sense of [xyz]’. STAS were
introduced in [12] and applied in [13] to the study of
networked control systems.
Our interest in this paper is on conformance as defined
earlier, which is a notion defined on entire trajectories.
STAS relations, defined on individual states of systems, is a
related notion which has the advantage of having a functional
characterization, much like Lyapunov functions characterize
stability. In this section, we define STAS relations and connect them to conformance. The functional characterization
of STAS can then be used to characterize conformance.
Definition 3.1 (STAS): Given two OMTS Ti
=
(Qi , Σ, →
− i , Q0i , Π, hii , pi ), i = 1, 2, and positive reals
τ, ε, consider a relation R ⊂ Q1 × Q2 , and the following
three conditions:
1) ∀(q1 , q2 ) ∈ R, dΠ (hq1 i , hq2 i) ≤ ε
σ1 ∈Σ
2) ∀(q1 , q2 ) ∈ R, ∀q1 −−
−→ q10 , ∃σ2 ∈ Bτ (σ1 ) and a
σ2
transition q2 −→ q20 s.t. (q10 , q20 ) ∈ R
3) ∀q10 ∈ Q01 , ∃q20 ∈ Q02 s.t. (q10 , q20 ) ∈ R
where Bτ (σ) = {σ 0 ∈ Σ | dΣ (σ, σ 0 ) ≤ τ }. If R satisfies the
first 2 conditions, then it is a (τ, ε)-space-time approximate
simulation (STAS) of T1 by T2 . If in addition it satisfies the
third, then we say T2 simulates T1 with precision (τ, ε).
STAS relations describe what happens when T1 ‘plays’ label
σ1 , and T2 is allowed to respond by playing a label from
Bτ (σ1 ). In particular, it says that T2 can always find a label
such that the distance between the reached outputs is less
than ε. In the rest of this paper, we will often simply speak
of a simulation to mean a STAS.
B. From simulation to conformance
The connection between STAS, which is a relation between states, and conformance, which is a relation between
executions, is captured in the following proposition.
Proposition 3.1: Given two OMTS Ti = (Qi , Σ, →
−i
, Π, hii , gi ), i = 1, 2, let R be a (τ, ε)-STAS relation between
them, and let D ⊂ Q01 × Q02 be a derivation relation between
2
concatenation of two compact
time domains E =
SJ1The
SJ2 −1hybrid
−1
0
0 0
j=0 ([tj , tj+1 ] × j) and E =
j=0 ([tj , tj+1 ] × j) is the hybrid
SJ1 −1
SJ2 −1 0
time domain Ec = j=0 ([tj , tj+1 ] × j) ∪ j=0 ([tj + tJ1 , t0j+1 +
tJ1 ] × {j 0 + N1 })

V13
Fig. 2.

Interconnections of similar MTS

them. Assume that the label pseudo-metrics dΣ , dΣ∗ are such
that for any two strings σ̄ = σ1 . . . σi and ᾱ = α1 . . . αi ,
(∀k ≤ i, dΣ (σk , αk ) ≤ τ ) =⇒ dΣ∗ (σ̄[i] , ᾱ[i] ) ≤ τ

(5)

If D ⊂ R, then T2 conforms to T1 with precision (τ, ε) and
with derivation relation D.

Proof: Take any pair (q10 , q20 ) ∈ D, and any sequence
of T1 transitions
σ

σ

σ

σ

1
2
3
n
q10 −→
q11 −→
q12 −→
. . . −−→
q1n

α

1
1
Because D ⊂ R, there exists a T2 transition 
q20 −→

 q12 s.t.
0 0
1
α1 ∈ Bτ (σ1 ) and (q1 , q2 ) ∈ R, therefore dΠ ( q1 , q2 ) ≤
ε. Proceeding in this way for every k ≤ n, we build a
sequence q2 of T2 transitions

α

α

...

α

1
2
n
q2 = q20 −→
q21 −→
q22 −→ . . . −−→
q2n

  
 
such that dΣ (σk , αk ) ≤ τ and dΠ ( q1k , q2k ) ≤ ε for all k.
i
Now

 i we
 check
 condition (a) of Def.2.1. For any q1 , i ≤ n,
i
dΠ ( q1 , q2 ) ≤ ε and by property (5) of the label pseudometric, dΣ∗ (σ[i] , α[i] ) ≤ τ . Thus condition (a) is satisfied.
By construction of the execution q2 and symmetry of dΠ
and dΣ , we also have condition (b).

IV. C OMPOSITIONALITY
In this section, we prove a general small gain condition
under which the feedback interconnection of OMTS preserves similarity relations. By Prop. 3.1, this implies that
conformance is also preserved under these conditions. We
work in the OMTS formalism as it bypasses unnecessary
technicalities and allows us to establish the result in greater
generality, while maintaining continuity with the work of
[13].
A. Compositionality of similar metric transition systems
Consider OMTS T1 , T2 , T3 , T4 with label sets Σ1 = Σ2
and Σ3 = Σ4 . Systems T1 and T2 are feedback interconnected to yield T1 ◦T2 , with state space Q12 = Q1 ×Q2 , and
label set Σχ 12 . Similarly, systems T3 and T4 are feedback
interconnected to yield T3 ◦T4 , with state space Q34 = Q3 ×
Q4 , and label set Σχ 34 . See Fig. 2. We seek conditions under
which T3 ◦T4 simulates T1 ◦T2 ; based on Prop.3.1, this would

imply that under the same conditions, T1 ◦T2 C
τ,ε T3 ◦T4 for
some (τ, ε). To do so, we use the functional characterization
of STAS.
Definition 4.1: [12, Def. 3.2] Given two OMTS T1 and
T2 with common output set Π and label set Σ, and nonnegative real τ , a function V : Q1 × Q2 → R+ ∪ {∞} is
a τ -simulation function of T1 by T2 if for all (q1 , q2 ) ∈
Q1 × Q2 ,
A0) V (q1 , q2 ) ≥ dΠ (hq1 i , hq2 i)
V (q10 , q20 )
A1) V (q1 , q2 ) ≥ sup σ∈Σ 0 inf σ0 ∈Bτ (σ)
−−→q1 q2 −−−−−−→q20
q1 −
A τ -simulation function defines a (τ, ε)-STAS relation via its
level sets. Namely, as shown in [12, Thm. 3.4], the ε-sublevel
set of V
LVε = {(q, q 0 ) ∈ Q1 × Q2 | V (q, q 0 ) ≤ ε}

(6)

is a (τ, ε)-STAS relation of T1 by T2 for all ε ≥ 0.
To keep the equations readable, in what follows, we define
the following: given σ12 = (σ1 , σ2 ) ∈ Σ12 ,
Bτ34 (σ12 ) := {(σ3 , σ4 ) ∈ Σ34 | dΣχ (σχ 1 , σχ 3 ) ≤ τ }
(Σ34 is defined analogously to Σ12 in (4)). The ball
Bτ34 (σ12 ) contains all labels in Σ34 whose ‘chronological
component’ σχ 3 is no more than τ -away from σχ 1 . Note
that by definition for any (σ3 , σ4 ) ∈ Σ34 , σχ 3 = σχ 4 (and
analogously σχ 1 = σχ 2 ) so the above definition effectively
bounds the distance between both chronological components
of the label.
Consider the OMTS T1 , T2 , T3 , T4 , with T1 in a feedback
loop with T2 , and T3 with T4 . Let V13 be a τ13 -STAS
function of T1 by T3 (Def. 4.1), and V24 be a τ24 -STAS
function of T2 by T4 . All systems share the same label set Σ.
We introduce the following functions to keep the equations
manageable: given q10 ∈ Q1 , q3 ∈ Q3 , σi ∈ Σ, define
V13 (q10 , q3 , σ1 ) :=

inf
V13 (q10 , q30 )
0
q3 −−−−−−−−→q3

V24 (q20 , q4 , σ2 ) :=

inf
V24 (q20 , q40 )
q4 −−−−−−−−→q40

σ3 ∈Bτ
(σ1 )
13

σ4 ∈Bτ
(σ2 )
24

Consider V13 : if we think of T3 as trying to match T1
transitions by minimizing V13 over the label ball Bτ13 , then
V13 measures how well it does it. Similarly for V24 .
Because STAS functions certify STAS relations via (6), the
following theorem provides a way to build STAS functions
for interconnections of systems, from the STAS functions of
the individual connected systems.
Theorem 4.1: Consider the OMTS T1 , T2 , T3 , T4 with
common label set Σ interconnected as described above. Let
V13 be a τ13 -STAS function of T1 by T3 , and V24 be a τ24 STAS function of T2 by T4 . Set τ = min(τ13 , τ24 ).
Define V : Q12 × Q34 → R+ to be V ((q1 , q2 ), (q3 , q4 )) =
h(V13 (q1 , q3 ), V24 (q2 , q4 )) where h is continuous and nondecreasing in both arguments.
Recall the definition of lifted label sets Σ12 , Σ34 in (2).
Let g : R → R be a non-decreasing function s.t. g(x) ≥ x

and for all q12 ∈ Q12 , q34 ∈ Q34 , g satisfies
h(V13 (q10 , q3 , σ1 ), V24 (q20 , q4 , σ2 )) ≥
sup
0
−−−−−−−−→q12
q12 −


(σ1 ,σ2 )∈Σ×Σ

sup
h(V13 (q10 , q3 , σ1 ), V24 (q20 , q4 , σ2 ))
0
q12 −
−−−−−−−→q12
(7)

g

(σ1 ,σ2 )∈Σ12

Also, let γ1 , γ2 : R → R+ be continuous non-increasing
functions s.t. γi (x) ≤ x, i = 1, 2, and for all σ12 =
(σ1 , σ2 ) ∈ Σ12 , for all (q3 , q4 ) ∈ Q34 , and all (q10 , q20 ) ∈ Q12
V13 (q10 , q30 ))
inf
−−−−−→q30
q3 −
0
V24 (q2 , q4 , σ2 ) ≥ γ2 (
inf
V24 (q20 , q40 ))
34 (σ )
Bτ
12
q4 −
−−−−−→q40
V13 (q10 , q3 , σ1 ) ≥ γ1 (

(8)

34 (σ )
Bτ
12

(9)

If the following conditions hold:
(a) V is continuous in the product topology of Q12 × Q34 .
(b) For all q12 ∈ Q1 × Q2 , q34 ∈ Q3 × Q4 ,
V (q12 , q34 ) ≥ dΠ (hq12 i , hq34 i)

(10)

(c) Function g distributes over h, that is
g(h(x, x0 )) = h(g(x), g(x0 )) ∀x, x0
(d) [Small Gain Condition] For all x ∈ R,
g ◦ γ1 (x) ≥ x, g ◦ γ2 (x) ≥ x
then V is a τ -STAS function of T1 ◦ T2 by T3 ◦ T4 .

Before proving the theorem, a few words are in order about
its hypotheses. A function g satisfying (7) always exists: by
observing that Σ12 ⊂ Σ×Σ, we see that g can be taken to be
the identity. A non-identity function quantifies how restrictive
is the interconnection T1 ◦ T2 . It does so by quantifying
the difference between the full label set Σ × Σ available
to the individual systems operating without interconnection
(on the LHS of inequality (7)), and the restricted label set
Σ12 available to them as part of the interconnection (on the
RHS).
Similarly, functions γ1 , γ2 satisfying (9) always exist: we
can take γi to be identically zero. These choices, however, are unlikely to be useful: we need γi to quantify
how restrictive is the interconnection T3 ◦ T4 . They do so
by quantifying the difference between the full label ball
Bτ13 (σ1 ) × Bτ24 (σ2 ) available to the individual systems
operating without interconnection, and the restricted label
ball Bτ34 (σ12 ) ⊂ Bτ13 (σ1 ) × Bτ24 (σ2 ) available to them as
part of the interconnection. See Fig.3 for an illustration of
the label sets.
These two aspects are similar to the conditions, in more
classical Lyapunov-based small gain theorems, placing a
minimum on the rate of decrease of the Lyapunov functions
of the individual systems, and that bound is related to
the growth of the other system’s Lyapunov function. (For
example results on input-to-state stability [11],[21], and for
bisimulation functions in non-hybrid systems [6]). Now the

T2#

T2#

σ2in#Σ2#

their suprema over Σ1 and Σ2 respectively.) Using (7), it
comes
h(V13 , V24 ) ≥

#

σ12#in#Σ12!"σχ,12#in#
Σχ#

σ1in#Σ1#
T1#

T1#

sup
h(V13 (q10 , q3 , σ1 ), V24 (q20 , q4 , σ2 )))
0
q12 −
−−−−−−−→q12

g(

(σ1 ,σ2 )∈Σ12

Applying (8),(9) to the RHS of this last inequality,
h(V13 , V24 ) ≥

Fig. 3. Label sets constrained by interconnection. Σ12 is the set of label
pairs compatible with the interconnection as given in Def.2.2.

g(

sup

h(γ1 ( 34inf

(σ1 ,σ2 )∈Σ12

Bτ (σ12 )

0
q12 −
−−−−−−−→q12

more restrictive T1 ◦ T2 is, the bigger g can be. The more
restrictive T3 ◦ T4 is, the smaller γi need to be. The Small
Gain Condition (SGC) says that the restrictiveness of T1 ◦ T2
must be balanced by that of T3 ◦T4 : if T3 ◦T4 is too restrictive
(γi (x) << x) relative to T1 ◦ T2 (g ◦ γi (x) < x), then T1 ◦ T2
can play a label σ12 that can’t be matched, and thus we lose
similarity of the systems. Thus similar to the classical results
(e.g., [6]), the SGC balances the gains of the feedback loops.
Proof: (Thm. 4.1)
We seek a STAS function V : Q12 × Q34 → R+ which
would certify that T3 ◦ T4 simulates T1 ◦ T2 , and we seek the
corresponding precision (τ, ε).
For notational convenience, introduce

V13 ), γ2 ( 34inf

Bτ (σ12 )

V24 ))

where we are using inf Bτ34 (σ12 ) Vij as an abbreviation for
Vij (qi0 , qj0 )
inf
qj −
−−−−−→qj0
34 (σ )
Bτ
12

We now establish two inequalities. First, note that
γ1 ( 34inf

Bτ (σ12 )

V13 ) ≥

inf

Bτ34 (σ12 )

γ1 (V13 )

(11)

Indeed, let
Q̄3 = Post(q3 , Bτ34 (σ12 ))

be the set over which the infimization is happening. We have
that v∗ := inf Bτ34 (σ12 ) V13 (q10 , q30 ) is finite since V is lower
:=
inf
V
0
34
σ ∈Bτ (σ12 )
bounded by 0. Now since v∗ ≤ v for all v ∈ V13 (Q̄3 ), and
0
q34 −
−−−−
−−−→q34
γ1 is non-increasing, it follows that γ1 (v∗ ) ≥ γ1 (v) for all
By definition, V must satisfy for all (q12 , q34 ) ∈ Q12 × v ∈ V13 (Q̄3 ). Taking the infimum on the RHS, the inequality
(11) follows. An inequality analogous to (11) holds for γ2
Q34 ,
by a similar argument.
A0) V (q12 , q34 ) ≥ dΠ (hq12 i , hq34 i)
Second, note that because γi and V are continuous, and
A1)
Q̄3 is compact, then the set γi ◦ V (Q̄3 ) is compact as well.
0
0
V (q12 , q34 ) ≥
sup
(
inf
V (q12
, q34
)) Since h is continuous as well, it achieves its infimum over
34 (σ)
σ 0 ∈Bτ
σ∈Σ12
compact sets and therefore
0
0
q12 −
−−−→q12 q34 −−−−−−−→q34
0
V(q12
, q34 , σ12 )

0
0
(q12
, q34
)

V (q12 , q34 ) ≥

0
sup
V(q12
, q34 , σ)
0
q12 −
−−−−−−−→q12
(σ1 ,σ2 )∈Σ12

≥

≥
=

sup sup h(V13 (q10 , q3 , σ1 ), V24 (q20 , q4 , σ2 ))

=

sup
(σ1 ,σ2 )∈Σ1 ×Σ2

sup

g(

sup
σ12

0
q12 −
−→q12

Σ2

Σ2

g(

σ12

≥

Σ1

h(γ1 ◦ V13 , γ2 ◦ V24 )

g(

sup
σ12

h(V13 (q10 , q3 , σ1 ), V24 (q20 , q4 , σ2 ))

where we used property A1 for V13 and V24 and the fact that
h is non-decreasing to obtain the first inequality, and the nondecreasing nature of h to obtain the second inequality. (The
second inequality becomes equality if V13 and V24 achieve

inf

0
q12 −
−→q12

h(sup V13 (q10 , q3 , σ1 ), sup V24 (q20 , q4 , σ2 )
Σ1

=

Bτ34 (σ12 )

inf

Bτ34 (σ12 )

γ2 (V24 ))
(12)

(V13 , V24 )

h(V13 (q1 , q3 ), V24 (q2 , q4 ))
≥

γ1 (V13 ),

We can proceed as
h

For all q1 , q2 , q3 , q4 ,

h( 34inf

Bτ (σ12 )

Condition A0 is the same as (10), and so is true by
hypothesis. Now for A1. First we restate it using V:

0
q12 −
−→q12

=

h(γ1 ( 34inf

Bτ (σ12 )

h( 34inf

Bτ (σ12 )

inf

Bτ34 (σ12 )

V13 ), γ2 ( 34inf

γ1 (V13 ),

Bτ (σ12 )

inf

Bτ34 (σ12 )

V24 )))

γ2 (V24 )))

h(γ1 ◦ V13 , γ2 ◦ V24 ))

sup
inf g ◦ h(γ1 ◦ V13 , γ2 ◦ V24 )
σ12
Bτ34 (σ12 )
0
q12 −
−→q12

To obtain the second inequality, we used (11) and the fact
that h and g are non-decreasing. To obtain the equalities, we
used (12) and the fact that g is non-decreasing.

By distributivity of g over h and the SGC
h(V13 , V24 )
inf h(g ◦ γ1 ◦ V13 , g ◦ γ2 ◦ V24 )
sup
σ12
Bτ34 (σ12 )
0
−→q12
q12 −
h(V13 , V24 )
inf
≥
sup
34 (σ )
σ12
Bτ
0
0
−→q12
q12 −
−−
−−12−→q34
q34 −
≥

thus concluding that V = h(V13 , V24 ) satifies A1, and so is
a τ -STAS function.
About the other conditions The distributivity assumption
in (c) holds, for example, if h is the max operator, i.e.
h(x, x0 ) = max(x, x0 ).
Thm. 4.1 assures us that feedback interconnection respects
similarity relation, and therefore also respects conformance
relations.
However, the conditions defining g and γi (equations (7)
and (9),(8)) are technical conditions that are are hard to
check. Turning them into a computational tool for particular
classes of systems is the subject of current research. A
simpler, and more conservative, criterion is given in the
following theorem:
Theorem 4.2: If
inf Q1 inf Q3 V13 (q1 , q3 )
<∞
k1 :=
supQ3 supQ1 V13 (q1 , q3 )
then γ1 (v) = k1 v satisfies (8). Similarly, if
k2 :=

inf Q2 inf Q4 V24 (q2 , q4 )
<∞
supQ2 supQ4 V24 (q2 , q4 )

then γ2 (v) = k2 v satisfies (9).

Proof: We give the proof for k1 , that for k2 is
B 34 (σ12 )

similar. Define Q̄3 = {q30 | ∃q3 −−τ−−−−→ q30 } and Q̂3 =
Bτ

(σ1 )

{q30 | ∃q3 −−−13−−−→ q30 }. Since prΣ (Bτ34 (σ12 )) ⊂ Bτ13 (σ1 ),
Q̄3 ⊂ Q̂3 ⊂ Q3 . Thus for any q10 ∈ Q1
V13 (q10 , q30 ) ≥ 0inf V13 (q10 , q30 )

inf

q3 ∈Q3

q30 ∈Q̂3

inf Q̄3 V13 (q10 , q30 )
q3 ∈Q3
supQ3 V13 (q10 , q30 )
inf (q1 ,q30 )∈Q1 ×Q3 V13 (q1 , q30 )
inf V13 (q10 , q30 )
≥
sup(q1 ,q30 )∈Q1 ×Q3 V13 (q1 , q30 ) Q̄3

≥

inf V13 (q10 , q30 )
0

= k1 inf V13 (q10 , q30 )
q30 ∈Q̄3

The challenge with the choice of γ1 and γ2 in Thm. 4.2
is that g is now required to always ‘compensate’ for the
worst-case behavior to satisfy the SGC. I.e. we need g(x) ≥
x/ max(k1 , k2 ) for all x. This may lead to a violation of (7).
The next result follows from Thm.4.1, the fact that h is
increasing, and [12, Thm. 3.6].
Theorem 4.3: Let ε13 = supQ01 inf Q03 V13 (q1 , q3 ) and
ε24 = supQ02 inf Q04 V24 (q2 , q4 ), so that T3 (τ13 , ε13 )simulates T1 , and T4 (τ24 , ε24 )-simulates T2 . Then T3 ◦
T4 (τ, ε)-simulates T1 ◦ T2 with τ = min(τ13 , τ24 ), ε =
h(ε13 , ε24 ).

V. R ELATED WORKS
In this paper we understand conformance as a notion that
relates systems, as done in [22], rather than a system and
its specification as done for example in [4]. Most existing
works on system conformance, either requires equality of
outputs, or does not account for timing differences, as
in [15] where an approximate method for verifying formal
equivalence between a model and its auto-generated code
is presented. The approach to conformance of Hybrid Input/Output Automata in [17] and falls in the domain of
nondeterministic abstractions, and a thorough comparison
between this notion and ours is given in [16]. The works
closest to ours are [12] and [19]. The work [12] defines the
STAS relation we used in this paper. The goal in [12] is to
define robust approximate synchronization between systems
(rather than conformance testing). The refinement relation
between systems given in [20] allows different inputs to
the two systems. Conformance requires the same input be
applied, which is a more stringent requirement. The current
theoretical framework also allows a significantly wider class
of systems than in [20].
VI. C ONCLUSIONS
When a system model goes through multiple design and
verification iterations, it is necessary to get a rigorous and
quantitative measure of the similarities between the systems. Conformance testing [2] allows us to obtain such a
measure, and to automatically transfer formal verification
results from a simpler model to a more complex model
of the system. In this paper, we extended the reach of
conformance testing by developing the sufficient conditions
for feedback interconnections of conformant systems to be
conformant. As pointed out earlier, these conditions apply
to Open Metric Transition Systems, and while this means
they are very broadly applicable, they must be specialized
to specific classes of dynamical systems. The next step is
to compute STAS functions for various classes of dynamial
systems, including hybrid systems. This is the subject of
current research. In addition, we aim to apply the compositionality theory developed here to problems in source code
generation.
R EFERENCES
[1] H. Abbas, B. Hoxha, G. Fainekos, J. V. Deshmukh, J. Kapinski,
and K. Ueda. Conformance testing as falsification for cyber-physical
systems. Technical Report arXiv:1401.5200, January 2014.
[2] H. Abbas, H. Mittelmann, and G. Fainekos. Formal property verification in a conformance testing framework. In MEMOCODE, 2014.
[3] K. Butts.
Presentation: Toyota’s direction.
[Online
at:
http://cmacs.cs.cmu.edu/presentations/verif csystems
/06 KenButts.pdf], 2010.
[4] T. Dang and T. Nahhal. Coverage-guided test generation for continuous and hybrid systems. Formal Methods in System Design, 34(2):183–
213, 2009.
[5] G. Frehse, C. L. Guernic, A. Donze, S. Cotton, R. Ray, O. Lebeltel,
R. Ripado, A. Girard, T. Dang, and O. Maler. Spaceex: Scalable
verification of hybrid systems. In Proceedings of the 23d CAV, 2011.
[6] A. Girard. A composition theorem for bisimulation functions. Technical Report, 2007.

[7] A. Girard and G. J. Pappas. Approximate bisimulations for constrained
linear systems. In Proceedings of 44th IEEE Conference on Decision
and Control and European Control Conference, pages 4700–4705,
2005.
[8] A. Girard and G. J. Pappas. Approximation metrics for discrete and
continuous systems. IEEE Trans. Auto. Cont., 52(5):782–798, 2007.
[9] R. Goebel, R. G. SanFelice, and A. R. Teel. Hybrid Dynamical
Systems: modeling, stability and robustness. Princeton University
Press, 2012.
[10] R. Goebel and A. Teel. Solutions to hybrid inclusions via set and
graphical convergence with stability theory applications. Automatica,
42(4):573 – 587, 2006.
[11] Z.-P. Jiang, I. M. Mareels, and Y. Wang. A lyapunov formulation of
the nonlinear small-gain theorem for interconnected {ISS} systems.
Automatica, 32(8):1211 – 1215, 1996.
[12] A. Julius and G. Pappas. Approximate equivalence and approximate
synchronization of metric transition systems. In Decision and Control,
2006 45th IEEE Conference on, pages 905–910, Dec 2006.
[13] A. A. Julius, A. D’Innocenzo, M. D. D. Benedetto, and G. J. Pappas.
Approximate equivalence and synchronization of metric transition
systems. Systems and Control Letters, 58(2):94 – 101, 2009.
[14] N. Lynch, R. Segala, and F. Vaandrager. Hybrid i/o automata.
Information and Computation, 185(1):105 – 157, 2003.
[15] R. Majumdar, I. Saha, K. Ueda, and H. Yazarel. Compositional
equivalence checking for models and code of control systems. In
Decision and Control (CDC), 2013 IEEE 52nd Annual Conference
on, pages 1564–1571, Dec 2013.
[16] M. Mohaqeqi, M. R. Mousavi, and W. Taha. Conformance testing of
cyber-physical systems: A comparative study. ECEASST, 70, 2014.
[17] M. Osch. Hybrid input-output conformance and test generation. In
K. Havelund, M. Nunez, G. Rosu, and B. Wolff, editors, Formal
Approaches to Software Testing and Runtime Verification, volume 4262
of Lecture Notes in Computer Science, pages 70–84. Springer Berlin
Heidelberg, 2006.
[18] A. Platzer and J.-D. Quesel. KeYmaera: A hybrid theorem prover for
hybrid systems. In A. Armando, P. Baumgartner, and G. Dowek,
editors, International Joint Conference on Automated Reasoning,
volume 5195 of LNCS, pages 171–178. Springer, 2008.
[19] J.-D. Quesel. Similarity, Logic, and Games: Bridging Modeling
Layers of Hybrid Systems. PhD thesis, Carl Von Ossietzky Universitat
Oldenburg, July 2013.
[20] J.-D. Quesel, M. Fränzle, and W. Damm. Crossing the bridge
between similar games. In S. Tripakis and U. Fahrenberg, editors, 9th
FORMATS, Aalborg, Denmark, 21-23 September, 2011. Proceedings,
volume 6919 of LNCS, pages 160–176. Springer, Sep. 2011.
[21] R. G. Sanfelice. Input-output-to-state stability tools for hybrid systems
and their interconnections. IEEE Transactions on Automatic Control,
May 2014.
[22] J.-P. Talpin, P. Guernic, S. Shukla, and R. Gupta. A compositional
behavioral modeling framework for embedded system design and conformance checking. International Journal of Parallel Programming,
33(6):613–643, 2005.

i

i

i

i

Probabilistic Temporal Logic Falsiﬁcation of Cyber-Physical Systems
HOUSSAM ABBAS and GEORGIOS FAINEKOS, Arizona State University
SRIRAM SANKARANARAYANAN, University of Colorado, Boulder
FRANJO IVANČIĆ and AARTI GUPTA, NEC Laboratories America

We present a Monte-Carlo optimization technique for finding system behaviors that falsify a metric temporal
logic (MTL) property. Our approach performs a random walk over the space of system inputs guided by a
robustness metric defined by the MTL property. Robustness is guiding the search for a falsifying behavior
by exploring trajectories with smaller robustness values. The resulting testing framework can be applied to
a wide class of cyber-physical systems (CPS). We show through experiments on complex system models that
using our framework can help automatically falsify properties with more consistency as compared to other
means, such as uniform sampling.
Categories and Subject Descriptors: G.3 [Mathematics of Computing]: Probability and Statistics—
Probabilistic algorithms (including Monte Carlo)
General Terms: Verification
Additional Key Words and Phrases: Hybrid systems, testing, robustness, metric temporal logic
ACM Reference Format:
Abbas, H., Fainekos, G., Sankaranarayanan, S., Ivančić, F., and Gupta, A. 2013. Probabilistic temporal logic
falsification of cyber-physical systems. ACM Trans. Embed. Comput. Syst. 12, 2s, Article 95 (May 2013),
30 pages.
DOI:http://dx.doi.org/10.1145/2465787.2465797

1. INTRODUCTION

Model-based design (MBD) and automatic code generation are becoming the development methodologies of choice for safety critical applications. Most prominently, such
design methodologies have been adopted by the automotive, medical, and aerospace
industries [Esterel Technologies 2011; Mathworks 2011] where correctness of the end
product is of paramount importance. The types of systems in these industrial domains
are particularly challenging because software is controlling the safe operation of a
physical system. Such systems are also known as cyber-physical systems (CPS). One
of the pressing challenges in the MBD of CPS is how to verify the correctness of the
developed model of the system as early as possible in the design cycle.
In answering such a problem, one must first specify what is an appropriate mathematical model that captures the behavior of the system and, second, what is an appropriate specification framework that has a nice mathematical structure that can help
in analyzing the mathematical model of the system. One such popular mathematical
This work was partially supported by NSF grants CNS-1017074, CNS-1116136, and CNS-1016994.
Authors’ addresses: H. Abbas, School of Electrical, Computer, and Energy Eng., Arizona State University;
G. Fainekos (corresponding author), School of Computing, Informatics and Decision Systems Eng., Arizona
State University; email: fainekos@asu.edu.; S. Sankaranarayanan, Department of Computer Science, University of Colorado, Boulder; F. Ivančić and A. Gupta, NEC Laboratories America.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights
for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component
of this work in other works requires prior specific permission and/or a fee. Permissions may be requested
from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212)
869-0481, or permissions@acm.org.
c 2013 ACM 1539-9087/2013/05-ART95 $15.00

DOI:http://dx.doi.org/10.1145/2465787.2465797
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

95
i

i
i

i

i

i

i

i

95:2

H. Abbas et al.

framework for CPS modeling is hybrid automata [Henzinger 1996]. Unfortunately, in
general, the verification problem for hybrid automata is undecidable even for simple
safety requirements [Henzinger et al. 1998], that is, there is no terminating algorithm
that can answer whether a CPS ever enters a set of bad states. Thus, a lot of research
has focused on discovering the classes of hybrid automata where the safety verification
problem is decidable [Alur et al. 2000] and on reachability analysis and testing-based
techniques [Tripakis and Dang 2009].
However, in many cases, the system requirements extend well beyond simple safety
properties. For example, we might be interested in conditional requirements such that
“if the temperature increases above 10 degrees and remains above 10 degrees for 1 min,
then it should be drop below 10 degrees within 2 min and remain below 10 degrees
for 30 min.” Such specifications can be captured using metric temporal logic (MTL)
[Koymans 1990].
In this article, we propose a testing-based technique for finding counterexamples
to MTL properties for CPS through global minimization of a robustness metric. The
global optimization is carried out using a Monte-Carlo technique that performs a random walk over the space of inputs consisting of initial states and control inputs. The
robustness metric defines the satisfaction of an MTL property over a given trajectory
as a real number, as opposed to the Boolean notion used in Logic. The sign of the
metric for a given trajectory y and formula ϕ indicates whether y satisfies ϕ (written
as y |= ϕ). Furthermore, nearby trajectories, defined using a metric over trajectories
whose distances from y are smaller than its robustness, also have the same outcome
for the property ϕ as y.
Given a robustness metric, finding a counterexample to a given property ϕ reduces to
finding a trajectory y that minimizes the robustness score with respect to ϕ. This can
be viewed as an optimization problem over the space of inputs of the system. However,
in practice, this optimization problem is not necessarily guaranteed to be tractable. In
almost all cases, the optimization problem (objective function and constraints) cannot
be written down in a closed functional form. Nevertheless, such optimization problems can often be solved satisfactorily using Monte-Carlo techniques that perform a
random walk in order to sample from a probability distribution defined implicitly by
the robustness metric [Rubinstein and Kroese 2008]. Over the long run, the random
walk converges to a stationary distribution over the input space such that inputs with
smaller values of robustness are sampled more frequently than inputs with larger values. Furthermore, Monte-Carlo techniques do not require the distribution itself to be
known in a closed form. Instead, these techniques simply require the ability to compare the values (ratio) of the probability density function at two given points in the
search space. In practice, this reduces to simulating the system using the sampled
inputs.
The contributions of this work can be summarized as follows.
(1) We show that metrics used for robust testing naturally define objective functions
that enable us to cast the problem of falsifying MTL properties into a global optimization problem.
(2) We demonstrate the use of hit-and-run Monte-Carlo samplers to carry out this
optimization in the presence of (possibly non-convex) constraints over the inputs.
(3) We extend our notions to CPS using quasi-metrics to provide a notion of robustness
for hybrid trajectories with respect to properties that can involve discrete as well
as continuous state variables.
Our approach is applicable even if the property has been proven using a verification technique. In such cases, our technique obtains system trajectories that have low
robustness values with respect to the requirements. In practice, finding non-robust
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:3

trajectories may imply designs with smaller safety margins. Traditional testing or verification techniques do not consider such trajectories using Boolean notions of temporal
satisfaction. Our approach is readily applicable to Simulink/StateflowTM (S/S) models,
since simulating the system is the only primitive needed. We have implemented our
approach in the Matlab (TM) toolbox S-T A L I R O [Annapureddy et al. 2011] and use
it to discover counterexamples to MTL properties. We establish that random walks
guided by robustness metrics can often falsify MTL properties that cannot be easily
falsified using blind (uniform random) search.
Preliminary results of this work have appeared in Nghiem et al. [2010], while the
architecture of our toolbox S-T A L I R O has appeared in Annapureddy et al. [2011]. In
this article, we reformulate the problem and its solution into a more general framework, we present the proofs that were omitted from Nghiem et al. [2010], we provide
new hybrid metrics in Section 4, and we perform more thorough experimental analysis
using our toolbox S-T A L I R O.
2. PRELIMINARIES

In this section, we provide a formal and concise definition of the problem that this
work addresses. Then, we introduce metrics and utilize them to provide continuous
semantics for metric temporal logic (MTL) specifications over continuous time trajectories. We will be using the following notation: R is the set of real numbers; R is the
closure of the reals, that is, [ −∞, +∞]; R+ is the set of positive real numbers and R+
its closure, that is, R+ = [ 0, +∞]; N is the set of natural numbers (including 0) and
N∞ = N ∪ {+∞}; Z is the set of integers and Z∞ = Z ∪ {±∞}. Given sets A and B, BA
defines the set of all functions from A to B, and P(A) denotes the powerset of A.
2.1. Problem Deﬁnition

In this work, we take a very general approach in modeling real-time embedded systems
that interact with physical systems that have non-trivial dynamics. Such systems are
also referred to as hybrid systems or cyber-physical systems (CPS). In the following,
we will be using the term hybrid systems since it is more concise. However, we would
like to caution the reader against associating hybrid systems with hybrid automata
[Alur et al. 1995] since the scope of our work is more general.
We view a system  as a mapping from a compact set of initial conditions X0 and input signals U ⊆ U R to output signals Y R . Here, R is a bounded time domain equipped
with a metric dR , U is a compact set of possible input values at each point in time
(input space), and Y is the set of output values (output space). This view of a system
is standard in signals and systems [Lee and Varaiya 2003]. We impose four assumptions/restrictions on the systems that we consider.
(1) The input signals (if any) must be parameterizable using a finite number of parameters. That is, there exists a function U such that for any u ∈ U, there exist two
parameter vectors λ = [ λ1 . . . λm ]T ∈ , where  is a compact set, and τ = [ τ1 . . .
τm ]T ∈ Rm , where τi < τj for i < j, such that for all t ∈ R, u(t) = U(λ, τ )(t).
(2) The output space Y must be equipped either with a metric d or with a generalized
metric d which may contain a subspace Z equipped with a metric d.
(3) For a specific initial condition x0 and input signal u, there must exist a unique
output signal y defined over the time domain R. That is, the system  is deterministic and we implicitly assume that the system does not exhibit Zeno behaviors
[Lygeros et al. 2003].
(4) For considering the convergence of our sampling scheme, we assume that the
space of inputs is bounded and discretized to a large but finite set. In practice, any
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:4

H. Abbas et al.

Fig. 1. The schematic of the modified version of the Simulink (TM) Automatic Transmission Demo.

representation of the input through a vector of floating point numbers inside the
computer must be finite and, therefore, implicitly discretizes the space of inputs.
Thus, this assumption does not pose a restriction.
Under Assumption 3, a system  can be viewed as a function  : X0 × U → Y R
which takes as input an initial condition x0 ∈ X0 and an input signal u ∈ U and
produces as output a signal y : R → Y (also referred to as trajectory). When the output
signals are only a function of the initial condition, that is,  : X0 → Y R , then the
system  is called autonomous. In either case, the set of all output signals of  will be
denoted by L(). That is, L() = {y | ∃x0 ∈ X0 . ∃u ∈ U . y =  (x0 , u)} or in case of
autonomous systems, L() = {y | ∃x0 ∈ X0 . y =  (x0 )}.
Our high-level goal is to infer the correctness of the system  by observing its response (output signals) to particular input signals and initial conditions. In particular,
we are interested in finding witnesses, that is, output signals, which prove that a requirement or specification is not satisfied by the system. The process of discovering
such witnesses is usually referred to as falsification.
Example 2.1. As a motivating example, we will consider the Automatic Transmission example which was also considered in Zhao et al. [2003]. This is a slightly modified
version of the Automatic Transmission model provided by Mathworks as a Simulink
demo.1 It is a model of an automatic transmission controller (see Figure 1) with the
following modifications. The only input to the system is the throttle schedule, while the
break schedule is set simply to 0 for the duration of the simulation which is 30 sec, that
is, R = [0, 30]. Finally, the system has two outputs: the speed of the engine ω (RPM)
and the speed of the vehicle v, that is, Y = R2 and y(t) = [ω(t) v(t)]T for all t ∈ [0, 30].
Internally, the system has two continuous-time state variables: the vehicle speed v
and engine speed ω. That is, for this example, the output of the system is the same as
the continuous state of the system. Initially, the vehicle is at rest at time 0, that is,
X0 = {[0 0]T } and x0 = y(0) =[0 0]T . Therefore, the output trajectories depend only on
the input signal u which models the throttle, that is, y =  (u). The throttle at each
point in time can take any value between 0 (fully closed) to 100 (fully open). Namely,
u(t) ∈ U = [0, 100] for all t ∈ [0, 30]. We remark that the system is deterministic, that
is, under the same input u, we will always observe the same output y.
We will assume that a system specification requires that the vehicle speed v is always under 120 km/h or that the engine speed ω is always below 4,500 RPM. Our goal
is to falsify this specification. In other words, we would like to generate tests such that
the vehicle speed v and the engine speed ω exceed the values 120 km/h and 4,500 RPM,
respectively. Such a falsifying system trajectory appears in Figure 2.
1 Demo sldemo autotrans available at http://www.mathworks.com/products/simulink/demos.html.

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:5

Fig. 2. Example 2.1. Left: The schematic for the switching logic for the automatic drivetrain; Right: An
input signal and the corresponding output signals that falsify the specification.

The model contains 69 blocks out of which there are two integrators (i.e., two
continuous state variables), three look-up tables, three look-up 2D tables, and a Stateflow chart. The Stateflow chart (see Figure 2 for a schematic) contains two concurrently executing finite state machines (FSM) with four and three states, respectively.
Even though this is a small size model and the specification is a simple bounded
time reachability requirement, it already exhibits all the complexities, that is, look-up
tables, switching conditions which depend on inputs, etc., that prevent formal modeling and analysis using the state of the art tools, for example, SpaceEx [Frehse et al.
2011].
Reachability requirements as described in Example 2.1 do not suffice to specify all
system behaviors in practice. This is especially true for real-time embedded systems
wherein richer properties such as timing requirements, sequencing of events, conditional requirements, stability and so on are equally important. Metric temporal logic
(MTL) introduced by Koymans [1990] is a popular formalism that can express such
properties. Our objective in this work is to provide efficient tools for the falsification of
bounded time MTL properties for CPS.
Problem 2.1 (MTL Falsification). For an MTL specification ϕ, the MTL falsification
problem consists of finding an output signal y of the system  starting from some
valid initial state x0 ∈ X0 under an input signal u ∈ U such that y does not satisfy
specification ϕ.
An overview of our proposed solution to Problem 2.1 appears in Figure 3. The sampler produces a point x0 from the set of initial conditions and a vector of parameters λ
that characterize the control input signal u. These are passed to the system simulator
which returns an execution trace (output trajectory). The trace is then analyzed by the
MTL robustness analyzer which returns a robustness value. In turn, the robustness
score computed is used by the stochastic sampler to decide on a next input to analyze.
If in this process, a falsifying trace is found, it is returned to the user, who can then
proceed to examine it inside the system modeling environment.
In this article, not only do we provide an efficient solution to Problem 2.1, we are
also able to provide a measure of how robustly the system satisfies or not an MTL
property. That is, our falsification framework does not have to return the first falsifying trajectory it detects, but it can continue searching for the least possible robust
system behavior. Similarly, even if the system is not falsifiable, our tool returns the
least robust correct behavior that was detected. Such information can be valuable to
the system designer.
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:6

H. Abbas et al.

Fig. 3. Overview of the solution to the MTL Falsification of CPS.

2.2. Metrics and Distances

When given a collection of objects, it is frequently necessary to reason about how close
these objects are to each other. In other words, we need a way to measure or compute
the distance between any two objects in the collection. In mathematics, the distance
between two objects that belong to a set Y can be quantified by a metric d. The pair
(Y, d) is called a metric space.
Metrics arise very naturally in control and analysis of physical systems [Sontag
1998]. Interesting metrics can also be defined in computation theory with a number
of diverse applications [Seda and Hitzler 2008]. In either case, the interest in defining
metrics is usually to show that a function is contractive (and, thus, to prove some notion of stability [Sontag 1998] or utilize a fixed-point computation [Seda and Hitzler
2008]) or that we can define an interesting topology [Kopperman 1988]. Here, our interest in metrics is different. We are interested in quantifying set membership questions, that is, how deep the object is within the set to which it belongs or how far
away it is from the set to which it should belong. At a high level, quantification of set
membership questions is the subject of study in fuzzy mathematics [Bandemer and
Gottwald 1995]. The fundamental difference between fuzzy set theory and our work is
that fuzzy set theory abstracts away any topological information regarding the degree
of membership. Such topological information is vital in our case, as we will demonstrate in Section 2.3. Next, we briefly review the notion of generalized metrics and
refer the reader to Seda and Hitzler [2008] and the references therein for a more detailed exposition.
Definition 2.2 (Positively Ordered Commutative Monoid).
— A semigroup (V, +) is a set V together with a binary operation + such that (i) the
set is closed under + and (ii) + is associative.
— A monoid is a semigroup which has an identity element 0, that is, for any v ∈ V,
v + 0 = 0 + v = 0.
— A commutative monoid is a monoid whose binary operation is commutative.
— An ordered monoid (V, +, 	) is a monoid with an (partial) order relation 	 which is
compatible with +, that is, v1 	 v2 implies v1 + v3 	 v2 + v3 and v3 + v1 	 v3 + v2 for
all v1 , v2 , v3 ∈ V.
— A positively ordered monoid is an ordered monoid such that for all v ∈ V, 0 	 v.
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:7

Definition 2.3 (Generalized Metric). Let (V, +, 	) be a positively ordered commutative monoid and Y be an arbitrary set. A generalized metric d is a function d :
Y × Y 
→ V which satisfies the following properties for y1 , y2 , y3 ∈ Y: Identity:
d(y1 , y2 ) = 0 iff y1 = y2 , Symmetry: d(y1 , y2 ) = d(y2 , y1 ), and Triangle Inequality: d(y1 , y3 ) 	 d(y1 , y2 ) + d(y2 , y3 ).
If V also has an absorbing element ∞, that is, for any v ∈ V, v+∞ = ∞+v = ∞, then
d is called an extended generalized metric. If the Symmetry condition is dropped from
the definition, then d is termed a generalized quasi-metric. If (V, +, 	) is (R+ , +, ≤)
with the usual addition + and total order ≤, then we drop the term “generalized” from
the terminology and denote the metric by d.
Using a generalized metric d, we can define the distance of a point y ∈ Y from a set
S ⊆ Y. Intuitively, this distance is the shortest distance from y to all the points in S.
In a similar way, the depth of a point y in a set S is defined to be the shortest distance
of y from the boundary of S.
Definition 2.4 (Distance, Depth, Signed Distance [Boyd and Vandenberghe 2004] §8).
Let y ∈ Y be a point, S ⊆ Y be a set, and d be a generalized metric on Y. Then, we
define the following.
— Distance from y to S to be distd (y, S) := inf{d(y, y ) | y ∈ S}.
— Signed Distance Distd (y, S) to be −distd (y, S) if y 
∈ S and distd (y, Y\S) if y ∈ S.
We should point out that we use the extended definition of supremum and infimum.
In other words, the supremum of the empty set is defined to be the bottom element of
the domain, while the infimum of the empty set is defined to be the top element of the
domain. For example, when we reason over R, then sup ∅ := −∞ and inf ∅ := +∞.
Also of importance is the notion of an open ball of radius ε centered at a point y ∈ Y.
Given a generalized metric d, a radius ε ∈ V, and a point y ∈ Y, the open ε-ball
(or neighborhood) centered at y is defined as Bd (y, ε) = {y ∈ Y | d(y, y ) ≺ ε}. The
previous definition of a neighborhood includes all points y which have distance from
y less than ε. Since in this work we also use quasi-metrics, we also need the notion of
neighborhood-to. The neighborhood-to includes all points y which have distance to y
less than ε. Similar to Bd , we define Nd (y, ε) = {y ∈ Y | d(y , y) ≺ ε}.
Finally, in order to reason in time about the system behavior, we need to define
metrics over signal spaces. If y and y are two system output signals y, y : R → Y that
take values in a generalized metric space (Y, d), we will use ρd to denote the metric
ρd (y, y ) = supt∈R {d(y(t), y (t))}.
2.3. Robustness of Trajectories

With the help of metrics we can now provide a robust interpretation (semantics) to
MTL formulas. Details are available in our previous work [Fainekos and Pappas 2009].
In this section, we refer to output signals simply as signals.
Definition 2.5 (MTL Syntax). Let AP be the set of atomic propositions and I be any
non-empty interval of R+ . The set MTL of all well-formed MTL formulas is inductively
defined as ϕ ::=  | p | ¬ϕ | ϕ ∨ ϕ | ϕ UI ϕ, where p ∈ AP and  is true.
For (real-time) hybrid systems, the atomic propositions label subsets of the output
space Y. An observation map O : AP → P(Y) maps each proposition p ∈ AP to a set
O(p) to a subset of Y. We require that for all p ∈ AP, ∅ ⊂ O(p) ⊂ Y. We emphasize
here that the results in Fainekos and Pappas [2009] require that the output space Y
be equipped with an extended metric d. In Section 4, we relax this requirement and
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:8

H. Abbas et al.

demonstrate how these results are extended to output spaces which are equipped with
a generalized quasi-metric.
We provide semantics that maps an MTL formula ϕ and a signal y(t) to a value
drawn from the linearly ordered set R. The semantics for the atomic propositions evaluated for y(t) consists of the distance between y(t) and the set O(p) labeling atomic
proposition p. Intuitively, this distance represents how robustly the point y(t) lies
within (or is outside) the set O(p). If this distance is zero, then the smallest perturbation of the point y can affect the outcome of y ∈ O(p). We denote the robust
valuation of the formula ϕ over the signal y at time t by [[ ϕ, O]]d (y, t). Formally,
[[ ·, ·]]d : (MTL × P(Y)AP ) → (Y R × R → R).
Definition 2.6 (Robust Semantics). Consider a metric space (Y, d), where d is an
extended metric. Let y ∈ Y R , c ∈ R, and O ∈ P(Y)AP , then the robust semantics of any
formula ϕ ∈ MTL with respect to y is recursively defined as follows.
[[ , O]]d (y, t) := + ∞
[[ p, O]]d (y, t) :=Distd (y(t), O(p))
[[ ¬ϕ1 , O]]d (y, t) :=−[[ ϕ1 , O]]d (y, t)
[[ ϕ1 ∨ ϕ2 , O]]d (y, t) := max([[ ϕ1 , O]]d (y, t), [[ ϕ2 , O]]d (y, t))



[[
ϕ
,
O]]
(y,
t
)
,
[[ ϕ1 UI ϕ2 , O]]d (y, t) := sup min [[ ϕ2 , O]]d (y, t ), inf
1
d


t ∈(t+R I )

where t ∈ R and t +

RI

t<t <t

= {τ | ∃τ  ∈ I . τ = t + τ  } ∩ R.

Example 2.7. The requirement expressed in natural language in Example 2.1 can
0
AT
be formally written as φ0AT = 2pAT
1 ∨ 2p2 , where each atomic proposition pi is mapped
AT
to O(pAT
1 ) = [120, +∞) × R and O(p2 ) = R× [4500, +∞), respectively. From the designer perspective, it might be easier to conceptualize the falsification problem as a
test generation problem and, therefore, pose the formal requirement as the negation
AT
of the behavior that she/he would like to observe, that is, φ1AT = ¬(3pAT
1 ∧3p2 ). Under
the semantics of Definition 2.6, the two formulas are equivalent.
For the purposes of the following discussion, let (y, t, O) |= ϕ denote the standard
Boolean MTL satisfiability. For clarity in the presentation, we define the satisfiability relation for the base case, that is, for atomic propositions p ∈ AP, (y, t, O) |= ϕ
if y(t) ∈ O(p). Note that Boolean MTL satisfiability reduces to an application of
Definition 2.6 wherein the negation is defined to be the Boolean negation and the
metric d is the discrete metric: for y1 , y2 ∈ Y, d(y1 , y2 ) = 0 if y1 = y2 and d(y1 , y2 ) = 1
if y1 
= y2 . It is easy to show that if the signal satisfies the property, then its robustness is nonnegative and, similarly, if the signal does not satisfy the property, then its
robustness is nonpositive. The following result holds [Fainekos and Pappas 2009].
T HEOREM 2.8. Given an output space (Y, d), where d is an extended metric, a formula ϕ ∈ MTL, an observation map O ∈ P(Y)AP , and an output signal y ∈ Y R , the
following hold.
(1) If (y, t, O) |= ϕ, then [[ ϕ, O]]d (y, t) ≥ 0. Conversely, if [[ ϕ, O]]d (y, t) > 0, then
(y, t, O) |= ϕ.
(2) If (y, t, O) 
|= ϕ, then [[ ϕ, O]]d (y, t) ≤ 0. Conversely, if [[ ϕ, O]]d (y, t) < 0, then
(y, t, O) 
|= ϕ.
(3) If for some t ∈ R+ , ε =[[ ϕ, O]]d (y, t) 
= 0, then for all y ∈ Bρd (y, |ε|), we have
(y, t, O) |= ϕ if and only if (y , t, O) |= ϕ, that is, ε defines a robustness tube around
the trajectory such that other nearby trajectories lying inside this tube also satisfy ϕ.
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:9

Theorem 2.8 establishes the robust semantics of MTL as a natural measure of signal
robustness. Namely, a signal is ε robust with respect to an MTL specification ϕ if it can
tolerate perturbations up to size ε and still maintain its current Boolean truth value.
Alternatively, a signal with the opposite outcome for ϕ, if it exists, has a distance of at
least ε away.
This is the main differentiating property from other works that also consider quantitative semantics for temporal logics (e.g., [de Alfaro et al. 2004; Lamine and Kabanza
2000]). Namely, our semantics maintain the topological information which can be used
to define neighborhoods for signals, while in quantitative or fuzzy semantics, such
information is lost. A more thorough comparison with other quantitative logics is provided in Fainekos and Pappas [2009].
3. FALSIFYING SYSTEMS WITH METRIC OUTPUT SPACES

In this section, we provide the basic formulation of MTL falsification as a global minimization of the robustness metric defined in Section 2 when the output space (Y, d) is
a metric space, that is, when (Y, d) = (Z, d), and describe a Monte-Carlo technique to
solve this global optimization problem.
Let  be a system as defined in Section 2.1. Let ϕ be a given MTL property that we
wish to falsify. Given a signal y, we have defined a robustness metric [[ϕ, O]]d (y, t) that
denotes how robustly y satisfies (or falsifies) ϕ from time t onwards. For the following
discussion, we assume a fixed label map O and always interpret the truth (and robustness) of MTL formulas evaluated at the starting time t = 0. Let Dϕ (y) = [[ϕ, O]]d (y, 0)
denote the robustness metric for y under these assumptions.
The robustness metric Dϕ maps each output signal y to a real number r. The sign of r
indicates whether y |= ϕ and its magnitude |r| measures its robustness. Ideally, for the
MTL verification problem, we would like to prove that infy∈L() Dϕ (y) > ε > 0, where
ε is a desired robustness threshold. For the MTL falsification problem (Problem 2.1),
we attempt to solve the following problem.
Find y ∈ L() s.t. Dϕ (y) < 0.

(1)

More generally, given a robustness threshold ε ≥ 0, we would like to solve the following
problem.
Find y ∈ L() s.t. Dϕ (y) < ε.

(2)

In this work, we provide a solution to either problem through the following optimization problem.
y = arg min Dϕ (y).
y∈L()

(3)

If Dϕ (y ) < ε, then we have produced a counterexample that can be used for debugging.
In the following, we provide parameterizations of the search space and a MonteCarlo sampling method that will help us solve Equation (3).
3.1. Autonomous Systems

The space of output signals is not the true search space for the falsification problem.
For instance, it is hard to explore the space of trajectories directly while guaranteeing that each trajectory considered is valid. Fortunately, for deterministic systems,
we may associate each input x0 ∈ X0 with a unique trajectory y and vice-versa. Let
Fϕ (x0 ) = Dϕ ( (x0 )) denote the robustness of the trajectory obtained corresponding to
the initial state x0 ∈ X0 . Therefore, the optimization can be expressed over the space
of inputs as follows.
min Fϕ (x0 ).

x0 ∈X0

(4)

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:10

H. Abbas et al.

The components of the vector x0 are the search variables of the problem, and the
optimization is carried out subject to the constraints in X0 .
Continuous trajectories are hard to compute precisely, even when the analytical form
of the solution of the system is known. Thus, trajectories have to be approximated nu˜  that supports robust evaluation of
merically. An approximate simulation function 
the given property ϕ should guarantee that for some finite sampling R̃ of the bounded
˜  (x0 ) and for y =  (x0 ), |[[ φ, O]]d (y, t)−[[ φ, O]]d (ỹ, t)| ≤ 
,
time domain R, for ỹ = 
for all t ∈ R̃, for a sufficiently small positive 
. Such a robust simulation function
suffices, in practice, to resolve properties that may be of interest to system designers. An appropriate simulation function can be obtained for a large class of ODEs
using numerical simulation techniques of an appropriate order, such as Runge-Kutta
or Taylor-series methods, with adaptive step sizes [Press et al. 1992]. Numerical integration schemes can also be adapted to provide reliable bounds 
 on the distance
between the actual and the numerical solution. Thus, the robustness value Dϕ (y) can
be approximated by a value D̃ϕ (ỹ) using the set of sample points ỹ obtained by a numerical integrator. Details on how D̃ϕ (ỹ) can be computed can be found in Fainekos
and Pappas [2009].
Unfortunately, for a trajectory ỹ obtained as the output of a numerical integrator
with known error bounds, the trace distance function may no longer satisfy D̃ϕ (ỹ) ≥ 0
whenever y |= ϕ. Instead, we may conclude the existence of some interval [−
2 , 
1 ]
for some 
1 , 
2 ≥ 0, such that if D̃ϕ (ỹ) ≤ −
2 , then y 
|= ϕ and if D̃ϕ (ỹ) ≥ 
1 , then
y |= ϕ. In general, we may not draw any conclusions if −
1 ≤ Dϕ (ỹ) ≤ 
2 . Furthermore,
the bounds 
1 , 
2 are often unknown for a given system. Nevertheless, the presence
of such a bound implies that it still makes sense to perform the optimization using a
numerically simulated trajectory ỹ. Thus, our optimization problem becomes
˜  (x0 )).
min Fφ (x0 ) = min D̃ϕ (

x0 ∈X0

x0 ∈X0

(5)

In practice, even minimally robust simulated trajectories will often be of great interest
to system designers, even if mathematically speaking they do not violate the property
under consideration.
Remark 3.1. If the user is willing to tolerate additional computational cost, then
it is possible to bound the inaccuracies of the numerical simulation even under the
presence of floating-point errors [Fainekos et al. 2009]. Then, these bounds can be used
to provide bounds on the robustness of the actual continuous-time trajectory [Fainekos
and Pappas 2009].
The resulting optimization problem of Equation (5) can be quite complex, unlikely
to be convex for all but the simplest of cases. Furthermore, the objective function F,
though computable for any given input through simulation, is not expressible in a
closed form. Directly obtaining gradients, Hessians, and so on is infeasible for all but
the simplest of cases. We now present Monte-Carlo techniques that can solve such
global optimization problems through a randomized technique that mimics gradient
descent in many cases.
3.2. Monte-Carlo Sampling

The Monte-Carlo techniques presented here are based on acceptance-rejection sampling [Andrieu et al. 2003; Chib and Greenberg 1995]. These techniques were first introduced in statistical physics, wherein they were employed to simulate the behavior
of particles in various potentials [Frenkel and Smit 1996]. Variations of Monte-Carlo
techniques are also widely used for solving global optimization problems [Rubinstein
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:11

and Kroese 2008]. In this article, we focus on a class of Monte-Carlo sampling techniques known as Markov-Chain Monte-Carlo (MCMC) techniques. These techniques
are based on random walks over a Markov chain that is defined over the space of
inputs.

1
2

3
4
5
6
7

ALGORITHM 1: Monte-Carlo Sampling Algorithm
Input: X0 : Input Space, f (·): Robustness Function, ε: Robustness threshold, PS(·): Proposal
Scheme
Output: x ∈ X0
begin
Choose some initial input x ∈ X0 ;
while (f (x) ≥ ε) do
/* Select x using Prop. Scheme
*/
x ← PS(x) ;
α ← exp(−β(f (x ) − f (x)));
r ← UniformRandomReal(0, 1) ;
if (r ≤ α) then
/* Accept proposal? */
x ← x ;
end
end

We first present the basic sampling algorithm for drawing samples from a probability distribution and then the technique of hit-and-run sampling that respects the
(convex) constraints on the input space due to X0 . Let f (x) = Fϕ (x) be a computable
robustness function, given a property ϕ. We seek to minimize f over the inputs in the
set X0 . We wish to sample X0 such that any two points x, x ∈ X0 with robustness val−βfϕ (x)
ues f (x) and f (x ) are sampled with probability proportional to e−βfϕ (x ) , where β > 0 is
e
a temperature parameter explained in the following.
Algorithm 1 shows the schematic implementation of the algorithm. Each iteration
of the sampler generates a new proposal x ∈ X0 from the current sample x using some
proposal scheme defined by the user (Line 3). The objective f (x ) is computed for this

proposal. Subsequently, we compute the ratio α = e−β(f (x )−f (x)) (Line 4) and accept the
proposal randomly, with probability α (Line 5). Note that if α ≥ 1 (i.e, f (x ) ≤ f (x) ), then
the proposal is accepted with certainty. Even if f (x ) > f (x), the proposal may still be
accepted with some nonzero probability. If the proposal is accepted, then x becomes a
new sample. Failing this, x remains the current sample. In general, MCMC techniques
require the design of a proposal scheme for choosing a proposal x given the current
sample x. The convergence of the sampling to the underlying distribution defined by f
depends critically on the choice of this proposal distribution.
Proposal Scheme. A proposal scheme is generally defined by a probability distribution P(x |x) that specifies the probability of proposing a new sample input x given the
current sample x. In general, there are three requirements that a proposal scheme
need to satisfy so that its use in Algorithm 1 converges to the distribution defined by
f (x).
— Detailed Balance. f (x )P(x |x) = f (x)P(x|x ) (see [Chib and Greenberg 1995]).
— Irreducibility. Given any two inputs x, x ∈ X0 , it should be possible with nonzero
probability to generate a series of proposals x, x1 , x2 , . . . , x that takes us from input
x to x . This is necessary in order to guarantee that the entire input state space can
be covered.
— Aperiodicity. The greatest common divisor of the lengths of all nonzero probability
cycles starting from a state x of the chain must be 1.
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:12

H. Abbas et al.

Convergence. Convergence of the sampling scheme guarantees that eventually after drawing a large but finite number of samples, the distribution of the samples approaches the distribution defined by the robustness function f . We will discuss convergence under the simplifying but practically relevant assumption of discreteness.
We assume that the space of inputs X0 is bounded and discrete, consisting of a large
but finite number of points. This assumption is always relevant in practice, since the
inputs in X0 that we consider are finitely-represented floating point numbers inside a
computer. As a result, the proposal scheme P defines a discrete Markov chain on the
space of inputs. Convergence of MCMC sampling follows directly from the convergence
of random walks on ergodic Markov Chains [Chib and Greenberg 1995; Randall 2006;
Rubinstein and Kroese 2008].
1 −βf (x)
The function f (x) over X0 induces a discrete probability distribution p(x) = M
e
,
where M is an unknown normalizing factor added to ensure that the probabilities add
up to one. Suppose Algorithm 1 were run to generate a large number of samples N.
Let γ denote the frequency function mapping subsets ofthe input space to the number
of times a sample was drawn from the set. Let P(S) = x∈S p(x) denote the volume of
the probability function for a set S ⊆ X0 .
T HEOREM 3.2. In the limit, the acceptance rejection sampling technique (almost
(S)
surely) generates samples according to the distribution p, P(S) = limN→∞ γ N
.
As a direct consequence, one may conclude, for instance, that an input x1 with f (x1 ) =
−100 is more likely to be sampled, as compared to some other input x2 with f (x2 ) =
100, in the long run.
It is possible, in theory, to prove assertions about the number N of samples required
for the sampled distribution to converge within some distance to the desired distribution governed by e−βfϕ (x) . This rate of convergence is governed by the mixing time of
the Markov chain on the inputs defined by the proposal scheme. This time is invariably
large (polynomial in the number of input points), and depends on the proposal scheme
used [Randall 2006].
Importance of β. The overall algorithm itself can be seen as a randomized gradient
descent, wherein at each step a new point x in the search space is compared against
the current sample. The probability of moving the search to the new point follows an

exponential distribution on the difference in their robustness values: p ∼ e−β(f (x )−f (x)) .
In particular, if f (x ) ≤ f (x), the new sample is accepted with certainty. Otherwise, it is

accepted with probability e−β(f (x )−f (x)) . Informally, larger values of β ensure that only
reductions to f (x) are accepted whereas smaller values correspondingly increase the
probability of accepting an increase in f (x). As a result, points with lower values of f
are sampled with an exponentially higher probability, as compared to points with a
higher value of the function f .
Adapting β. One of the main drawbacks of Algorithm 1 is that, based on the nature
of the distribution, the sampling may get trapped in local minima. This typically results in numerous proposals getting rejected and few being accepted. Even though we
are guaranteed eventual convergence, the presence of local minima slows down this
process, in practice. We therefore periodically adjust the values of β (and also the proposal scheme) to ensure that the ratio of accepted samples versus rejected samples
remains close to a fixed value (1 in our experiments). This is achieved by monitoring
the acceptance ratio during the sampling process and adjusting β based on the acceptance ratio. A high acceptance ratio indicates that β needs to be increased, while a low
acceptance rate indicates that β needs to be reduced.
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:13

Fig. 4. Hit-and-run proposal scheme.

Proposal Schemes. It is relatively simple to arrive at viable schemes for generating
new proposals. However, designing a scheme that works well for the underlying
problem requires a process of experimentation. For instance, it suffices to simply
choose an input x uniformly at random from the inputs, regardless of the current
sample. However, such a scheme does not provide many advantages over uniform
random sampling. In principle, given a current sample x, the choice of the next sample
x must depend upon x.
A typical proposal scheme samples from a normal distribution centered at x with a
suitably adjusted standard deviation (using some covariance matrix H). The covariance can be adjusted periodically based, once again, on the observed samples as well
as the acceptance ratio. A smaller standard deviation around x yields samples whose
robustness values differ very little from f (x), thus increasing the acceptance ratio.
However, it is hard to respect the constraint x ∈ X0 using such a proposal scheme.
Hit-and-Run Proposal Scheme. Hit-and-run schemes are useful in the presence of
input domains such as X0 ⊆ Rn . For simplicity, we assume that X0 is convex. Therefore,
any line segment in some direction v starting from x has a maximum offset δM such
that the entire segment between x and x + δv lies inside X0 . At each step, we propose a
new sample x based on the current sample x. This is done in three steps.
(1) Choose a random unit vector v uniformly (or use a Gaussian distribution) (Cf.
Figure 4). In practice, one may choose a random vector h and generate a unit vector
using v = |h|h .
2
(2) Discover the interval [δm , δM ], such that ∀δ ∈ [δm , δM ] , x + δv ∈ X0 . In other words,
v yields a line segment containing the point x along the directions ±v and [δm , δM ]
represent the minimum and maximum offsets possible along the direction v starting from x. If X0 is a polyhedron, bounds [δm , δM ] may be obtained efficiently by
using a variant of the minimum ratio test. For a more complex convex set X0 , value
of δm (resp. δM ) may be obtained by solving the one-dimensional optimization problem min(max) δ s.t. x + δv ∈ X0 , by using a bisection procedure given an initial guess
on [δm , δM ].
(3) Finally, we choose a value δ ∈ [δm , δM ] based on some probability distribution with
a mean around 0. The variance of this distribution is an important parameter that
can be used to control the acceptance ratio (along with β) to accelerate convergence.
Hit-and-run samplers can also be used for non-convex input domains, such as unions
of polytopes and so on. A detailed description of the theory behind such sampling techniques is available elsewhere [Rubinstein and Kroese 2008; Smith 1996].
However, care must be taken to ensure that the input space X0 is not skewed along
some direction v . In the worst case, we may imagine X0 as a straight line segment.
In such cases, the hit-and-run proposal scheme fails to generate new samples. This is
remedied by adjusting the scheme for selecting unit directions to take the skew of X0 ,
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:14

H. Abbas et al.

Fig. 5. (a) Time trajectory violating the property 2[0,2] ¬a, where O(a) = [−1.6, −1.4] × [−.9, −1.1] along
with the scatter plot of sampled inputs and (b) robustness value as a function of the simulation step number.

embedding X0 inside a subspace spanned by the independent variables, and finally,
applying a suitable transformation to X0 that aids in sampling.
In practice, hit-and-run samplers can work over non-convex, disconnected domains.
Theoretical results on these samplers are very promising. Smith [1984] proves the
asymptotic convergence of hit-and-run sampling over arbitrary open subsets of Rn .
Lovasz [1999] and Lovasz and Vempala [2006] further demonstrated convergence in
time O(n3 ) for hit-and-run sampling of uniform distribution over a convex body in n
dimensions. Algorithms for global optimization such as hide-and-seek [Romeign and
Smith 1994] and improving hit-and-run [Zabinsky et al. 1993] have combined hit-andrun sampling with Monte-Carlo to generate global optimization techniques.
Example 3.3. Let y(t) = [ y1 (t) y2 (t)]T . Consider the following time varying system

 

dy1 (t)
dy(t)
y1 (t) − y2 (t) + 0.1t
,
= dydt
=
2 (t)
y2 (t) cos(2π y2 (t)) − y1 (t) sin(2π y1 (t)) + 0.1t
dt
dt
with initial condition y(0) = x0 ∈ X0 = [−1, 1] × [−1, 1]. In this case, Y = R2 and thus,
we choose to use the Euclidean metric. We wish to falsify the property 2[0,2] ¬a, wherein
O(a) = [−1.6, −1.4] × [−.9, −1.1]. Our simulation uses a numerical ODE solver with a
fixed time step over the time interval t ∈ R = [0, 2]. Figure 5(a) shows the trajectory
that falsifies our safety property using the hit-and-run sampler and the scatter plot
consisting of the samples generated by the Monte-Carlo sampler. Figure 5(b) plots the
robustness of the trajectory at each simulation step. We observe that the sampling is
concentrated in the more promising regions in the set of initial conditions.
3.3. Non-Autonomous Systems

We now consider extensions to non-autonomous CPS. Again, for pragmatic reasons,
˜  (x0 , ũ) of the actual trajectory y =  (x0 , u).
we focus on the approximation ỹ = 
Here, the input signal ũ is a discrete-time approximation of the actual continuoustime input signal u. Therefore, in a naive search for a falsifying input signal, we may
consider each sampling instance as a search variable. However, such an approach is
infeasible for long simulation times with fast sampling rates.
Our goal is to recast the search for control input signals ũ in terms of a search in
the set of parameters λ ∈  and τ ∈ Rm , where m << |R̃|, that is, m is substantially
smaller than the number of samples from R. Since we have assumed that the input
signal space can be parameterized on λ and τ , we can produce a discrete-time approximation ũ = Ũ(λ, τ ) to u = U(λ, τ ), and thus we are able to represent realistic input
signals. Now our optimization problem becomes
min

x0 ,λ,τ ∈X0 ××Rm

f (x0 , λ, τ ) =

min

x0 ,λ,τ ∈X0 ××Rm

˜  (x0 , Ũ(λ, τ ))).
D̃ϕ (

(6)

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:15

In practical terms, there exist numerous ways to parameterize the space of control
inputs. We discuss a few such parameterizations next.
Piece-wise Constant
	 Input. We partition the overall time interval R = [0, T] into
a set of intervals m
i=1 [τi−1 , τi ), wherein τ0 = 0 and τm = T. For each interval
[τi−1 , τi ), i ≥ 1, the control u(t) is restricted to be a constant value λi−1 .
Piece-wise Linear Input. Piece-wise constant control may be extended to piecewise
linear controls. Once again, we partition R = [0, T] into m disjoint intervals. For each
interval [τi−1 , τi ], we restrict the form of each control input to be piece-wise linear, that
is, for t ∈ [ti−1 , ti ), we have u(t) = (1−α(t))λi−1 +α(t)λi , where α(t) = (−τi−1 )/(τi −τi−1 ).
Spline Functions. We can choose a family of spline functions US (λ, τ ). Details on utilizing splines to represent control input signals can be found in Egerstedt and Martin
[2009].
Example 3.4. In order to parameterize the input signal space of Example 2.1, we
used a piece-wise constant signal with seven control points uniformly distributed over
the time domain [0, 30]. That is, our search for a minima is performed over a bounded
seven-dimensional space. Furthermore, since the output space Y is R2 , we are using the Euclidean metric for the distance computations in the formula defined in
Example 2.7. The outcome of S-T A L I R O appears in Figure 2. As evident from the
figure, the vehicle speed and the engine rotation indeed reach the specified thresholds.
The Simulink model was simulated 41 times for this particular test.
4. FALSIFYING SYSTEMS WITH GENERALIZED QUASI-METRIC OUTPUT SPACES

In the previous sections, we demonstrated that MTL falsification of systems is possible as long as we can define a non-trivial metric on the output space. However, specifications on CPS usually have requirements on both the discrete output space of the
system and the continuous output space. Unfortunately, it is not straightforward to
define metrics over such hybrid (discrete and continuous) output spaces. Therefore, in
order to formulate and analyze such specifications, we need to relax our constraint on
the system having metric output spaces.
Example 4.1. Let us revisit Example 2.1. We are looking to generate tests such that
the system visits each state in the state chart selection state (see Figure 2), that is,
steady state, upshifting, and downshifting, when the vehicle speed exceeds 79. In
this case, the output trajectory y of the system model must not only contain information about the physical system quantities, that is, engine rotation and vehicle speed,
but also about the current state in the Stateflow chart. Therefore, the temporal logic
analysis must be performed over the output space Y = {steady state, upshifting,
downshifting} × R2 .
In this section, we first generalize Theorem 2.6 to signals over generalized quasimetric output spaces. Then, we introduce a modeling formalism for hybrid systems
and two interesting generalized quasi-metrics on output trajectories of such hybrid
systems.
4.1. Robustness of Signals over Generalized Quasi-Metrics Spaces

The only requirement in the definition of the robust semantics of MTL formulas
(Section 2.3) is that both the trajectory under study and the specifications take values from the same space. We can prove (see Appendix) by induction on the structure of
formula ϕ that Theorem 2.8 also holds in the case where the metric d is replaced by a
generalized quasi-metric d.
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:16

H. Abbas et al.

T HEOREM 4.2. Given an output space (Y, d), where d is an extended generalized
quasi-metric, a formula ϕ ∈ MTL, an observation map O ∈ P(Y)AP , and an output
signal y ∈ Y R , then
(1) If (y, t, O) |= ϕ, then [[ ϕ, O]]d (y, t)  0. Conversely, if [[ ϕ, O]]d (y, t)  0, then
(y, t, O) |= ϕ.
(2) If (y, t, O) 
|= ϕ, then [[ ϕ, O]]d (y, t) 	 0. Conversely, if [[ ϕ, O]]d (y, t) ≺ 0, then
(y, t, O) 
|= ϕ.
(3) If for some time t ∈ R, ε =[[ ϕ, O]]d (y, t) 
= 0, then for all y ∈ Bρd (y, |ε|), we have
(y, t, O) |= ϕ if and only if (y , t, O) |= ϕ.
Note that now the definition of the robustness valuation function for a formula ϕ over
a signal y at time t is a function [[ ·, ·]]d : (MTL × P(Y)AP ) → (Y R × R → V). The set
V must include the set V of the positively ordered monoid (V, +, 	) in the definition of
the generalized quasi-metric d, and also, it must be ordered under the same ordering
relation 	. Furthermore, appropriate definitions of negation and absolute value are
required as well as careful treatment of the absorbing elements (if any). Essentially,
we need (V, +, 	) to be an Abelian group with two absorbing elements ±∞.
4.2. Generalized Quasi-Metrics for Hybrid Signals

In order to define quasi-metrics for hybrid signals, we need to take into account some
information about the structure of the system that generates the output signals. Here,
we will be using a generalization of hybrid automata [Alur et al. 1995] as a basic
modeling language for CPS. We remark that our formalism resembles hierarchical
hybrid systems [Alur et al. 2003].
Definition 4.3 (Hybrid System). A hybrid system H consists of components H, H0 ,
Y, U, O, G, R, D, →, wherein the following hold.
— H = L × X is the state space of the system and L is a finite set of locations (modes
or control locations).
— H0 ⊆ H represents the set of initial conditions.
— Y = L × Z is the output space with a generalized metric and where (Z, d) is a metric
space.
— U ⊆ U R is the set of possible input signals.
— O : X → Z is an output map.
— G : L × L × X × U → P(Z) is the guard set for the transitions between control
locations.
— R : (L × L) → (X → X) is the reset function for the transitions between control
locations.
— D : L → (X × R × U → X R ) is a mapping of each control location  ∈ L to a deterministic subsystem, which given an initial condition x0 , an initial time t0 , and an input
signal u, returns the unique state trajectory of the subsystem x = D (x0 , t0 , u).
— →⊆ L × L is a set of (discrete) transitions such that for each 1 , 2  ∈→, that is,
1 → 2 , the system moves from 1 ∈ L to 2 ∈ L if the output state z = O(x) of the
system before the transition is in the set G(1 , 2 , x, u) and after the transition is at
the point z = O(x ), where x = R1 ,2  (x).
We remark that our definition of a hybrid system allows each control location to
be any arbitrary subsystem as long as it is deterministic and its state can be fully
described by the function D . For example, each control location can be a hybrid system
as well. The reason behind utilizing such a general model is that we are not necessarily
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:17

interested in the whole structure of the hybrid system, but only on its part that is
directly related to the functional specification that we are trying to falsify.
Example 4.4. The Simulink/Stateflow model in Example 2.1 has the following
state-space.
{first, second, third, fourth} × {steady state, upshifting, downshifting} × R2 .
In Example 4.1, the specification requirements focus only on the state chart selection
state. Therefore, our hybrid system will have the following components of interest.
— L = {steady state, upshifting, downshifting}, and →, as defined in Figure 2.
— X = {first, second, third, fourth} × R2 , Z = R2 and O is the projection of X on R2 .
The reset function R changes the state of the state chart gear state, and the guard
G is computed by the Threshold Calculator block in the Simulink model in Figure 1.
Note that G depends on the state x and the input u. However, we are not interested in
R and G in this example.
A timed trace of a hybrid system is a finite2 sequence of states t, , x ∈ R × L × Xof
the form t0 , 0 , x0 , t1 , 1 , x1 , t2 , 2 , x2 ,. . ., such that initially, at time t0 , we have
0 , x0  ∈ H0 , and for each consecutive state pair ti , i , xi , we either make discrete
transition from i to i+1 and set xi+1 = Ri ,i+1  (xi ), or we evolve under the subsystem
Di from xi to xi+1 , that is, xi+1 = Di (xi , ti , u)(ti+1 ).
A hybrid system H is deterministic if and only if starting from some initial state
t0 , 0 , x0  there exists a unique timed trace. Given a timed
trace,
we can construct a



hybrid system trajectory y : R → Y by setting y(t) = l(t), z(t) for t ∈ [ ti , ti+1 ), where
l(t) = i and z(t) = O(x(t)) with x(t) = Di (xi , ti , u)(t). Therefore, again, we may view
a hybrid system as a function H from the set of initial conditions H0 and the input
signals U to output signals Y R .
˜ H (h0 , ũ) represent the approximate simulation function for a deterministic hyLet 
˜ H (h0 , ũ) approximates the time trajectories with
brid system H. We assume that 
some given tolerance bound 
 by adjusting the integration method. In practice, this
may be harder to achieve for hybrid systems than for purely continuous systems due
to the problem of robust event detection [Esposito and Kumar 2004]. However, assuming that such a simulator is available (see [Sanfelice and Teel 2010] for conditions), we
may translate the trace fitness function defined for continuous simulations to hybrid
simulations with discrete transitions.
Specifications for hybrid automata involve a sequence of locations of the discrete
subsystem. The simplest such property being the (un)reachability of a given error location. As a result, continuous state distance based on a norm (or a metric distance)
does not, in general, provide a true notion of distance between the specification and the
trace. This is especially true in the presence of discrete transitions with reset maps. For
the case of hybrid systems with reset maps, the robustness metrics used in Section 3
cannot be used to compare the hybrid states (, z) and ( , z ) in terms of some norm
distance between z and z . Therefore, structural considerations based on the graph
that connects the different modes of the hybrid automata have to be considered while
designing fitness functions. We now consider (generalized quasi-) metrics for hybrid
automata.
First, we have to define what is the distance between two modes of the hybrid automaton. We claim that a reasonable metric is the shortest path distance between two
2 Again, we implicitly assume that the system does not exhibit Zeno behaviors [Lygeros et al. 2003].

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:18

H. Abbas et al.

locations. A similar metric was used for guiding the exploration in a model checker for
hybrid systems in Alur et al. [2003]. Intuitively, the shortest path distance provides us
with a measure of how close we are to a desirable or undesirable operating mode of the
automaton. Such information is especially useful in the class of falsification algorithms
that we consider in this article.
In the following, given hybrid automaton H, we let (H) = (L, →) represent the
directed graph formed by its discrete modes and transitions. The shortest path distance from node  to node  in the graph (H) will be denoted by π(,  ). Note that
π(,  ) = ∞ if and only if there is no path from  to  in the graph (H). It is well
known (and it is easy to verify) that the shortest path distance satisfies all the criteria
for a quasi-metric.
The shortest path metric can be computed on-the-fly by running a breadth first
search (BFS) [Cormen et al. 2001] algorithm on the graph. It is well known that
BFS runs in linear time on the size of the input graph. However, it is preferable
to use an all-pairs shortest path algorithm [Cormen et al. 2001] to precompute the
distances between all pairs of control locations of the hybrid automaton. In our implementation, we are using the Floyd-Warshall algorithm which has running time
(|L|3 ).
In order to reason over output trajectories y in the hybrid state space Y, we need
to introduce a generalized distance function [Seda and Hitzler 2008]. In the following,
we will denote the hybrid space L × Z by H to indicate that a metric is defined over a
∞
particular space. Let dh : H × H → V∞
+ , where
 + = V+ ∪ +∞, +∞ and V+ = N × R+ ,

  V

with definition for h = , z ∈ H and h =  , z ∈ H,



0, d(z, z )
if  =  ;




dh (h, h ) =
π(,  ), min ∈∂ Nπ (, ) distd (z, Gt (,  )) otherwise,
where π is the shortest path metric, d is a metric on Z, and ∂Nπ (,  ) = Nxt() ∩
Nπ ( , π(,  )). Here, Nxt() = { ∈ L |  →  } and Gt denotes that the guard set may
be changing with respect to time. Informally, ∂Nπ (,  ) is the boundary of all locations
which are closer to  than  and may be visited from  within one transition. Therefore,
when the two points h, h are in the same control location, then the distance computation reduces to the distance computation between the points in the continuous state
space. When the two points h, h are in different control locations, then the distance
is the path distance between the two control locations weighted by the distance to the
closest guard that will enable the transition to the next control location that reduces
the path distance. Essentially, the last condition is a heuristic that gives preference to
shortest paths.
Next, we need to define an appropriate addition + and a partial order 	 such that
the triplet (V+ , +, 	) is a positively ordered
monoid. First, the addition

  
 commutative

is defined component-wise, that is, for k, r , k , r ∈ V+ , we define

  
   


k, r + k , r = k + k , r + r .
The commutativity property
 is immediately
satisfied. Second, we order the set using



the dictionary order. Given k, r , k , r ∈ Z∞ × R, we define the order relation ≺ as


  
  
k < k if k 
= k ;
k, r ≺ k , r iff
r < r if k = k .
It is easy to verify that the dictionary order is compatible with the addition as
defined for V+ . Hence, V+ has a smallest element, namely 0 = 0, 0, and V∞
+ has an
absorbing element, namely +∞ = +∞, +∞, which is also the least upper bound.
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:19

Finally, Proposition A.1 in the Appendix demonstrates that the generalized distance
dh satisfies the identity and triangle inequality properties. In other words, dh is a
generalized quasi-metric on H.
The generalized distance function dh requires computations of a point to each guard
set in a control location. This may potentially increase the computational load or it
could be the case that the computation of the distance to the guard might not be possible (e.g., in certain Simulink/Stateflow models). Therefore, we also introduce the generalized distance function d0h : H × H → V∞
+ with definition

⎧



⎨ 
0, d(z, z )  if  =  ;
0


dh (h, h ) =
π(,  ), 0 if  
=  and π(,  ) < +∞;
⎩
+∞, +∞ otherwise.
In this case, the distance function ignores the guard sets and simply checks whether
the two points are in the same control location or not. The distance function d0h is a
generalized quasi-metric as well.
Therefore, we are in position to reason about hybrid system trajectories by utilizing
the MTL robustness Definition 2.6 and Theorem 4.2. Now the atomic propositions can
map to subsets of H placing, thus, requirements not only on the continuous statespace,

  but also on the mode of the hybrid system. Informally, a robustness value of
k, r =[[ ϕ, O]]dh (y, t) will mean the following.
— If k = 0 and r 
= 0, then we can place a tube of radius |r| around the continuous
part of the trajectory which will guarantee equivalence under the MTL formula.
Moreover, it is required that at each point in time t, the locations are the same for
all such trajectories.
— If k > 0, then the specification is satisfied, and moreover, the trajectory is at least k
discrete transitions away from being falsified.
— If k < 0, then the specification is falsified, and moreover, the trajectory is at least k
discrete transitions away from being satisfied.
Remark 4.5. Note that both functions Distdh and Distd0 never evaluate to some
h



value of the form k, ±∞ with k ∈ Z (see Proposition A.3). This is important because the temporal logic robustness value is now going to be a member of the set
V∞ = V ∪ {±∞}, where V = Z × R. In order for the triplet (V, +, 	) to be an ordered
Abelian group and, thus, the robust MTL semantics to have a proper definition of
negation, each member of V must have an inverse. The negation for the MTL robust
semantics induced by the aforementioned metrics is simply the pairwise negation. In
Proposition A.3, we also demonstrate how the distance functions Distdh and Distd0
h
can be computed based on the well-known and understood distance functions Distπ
and Distd .
4.3. Monte-Carlo Sampling

One of the issues that arises when giving generalized (or hybrid) robust semantics to
MTL formulas is how to sample over the space H0 ×  × Rm . Recall that  × Rm is the
space of parameters that parameterize the input signals. In other words, what is the
probability distribution induced by the robustness function f ? In general, this issue
can only be addressed in a case-by-case scenario, depending on the generalized metric
d that is utilized.
In this work, for the generalized quasi-metric dh , we propose using a Parallel
Metropolis coupled Markov chain Monte Carlo algorithm (see Algorithm 2). For a point
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:20

1
2

3
4
5
6
7
8

H. Abbas et al.

ALGORITHM 2: Parallel Monte-Carlo Sampling Algorithm
Input: H0 ×  × Rm : Input Space, f (·): Robustness Function, ε: Robustness Threshold,
PS(·): Proposal


Scheme
Output: h, λ, τ ∈ H0 ×  × Rm
begin



Choose some initial input h, λ, τ ∈ H0 ×  × Rm ;
while (f (h, λ, τ 
) ≥ ε) do
/* Select h , λ , τ  using the Proposal Scheme
*/

   



h , λ , τ ← PS( h, λ, τ ) ;
α1 ← exp(−β1 (f1 (h , λ , τ  ) − f1 (h, λ, τ )));
α2 ← exp(−β2 (f2 (h , λ , τ  ) − f2 (h, λ, τ )));
r ← UniformRandomReal(0, 1) ;
  
  
if (((f

 1 (h ,λ , τ
 ) = f 1 (h,
 λ, τ )) ∧ (r ≤ α2 )) ∨ ((f1 (h , λ , τ ) 
= f1 (h, λ, τ )) ∧ (r ≤ α1 ))) then
h, λ, τ ← h , λ , τ  ;
end
end





˜ H (h0 , Ũ(λ, τ ))).
h0 , λ, τ ∈ H0 ××Rm , the robustness function is now f (h0 , λ, τ ) = D̃ϕ (

 
∞
If f (h0 , λ, τ ) = k, r ∈ V , then we define
f1 (h0, λ, τ ) = k ∈ Z∞ and f2 (h0 , λ, τ ) = r ∈ R.


,
λ
In brief,
in
Algorithm
2,
an
input
h
1
1 , τ1 will be more likely sampled over an



input h1 , λ1 , τ1 if f1 (h1 , λ1 , τ1 ) = f1 (h2 , λ2 , τ2 ) and f2 (h1 , λ1 , τ1 ) << f2 (h2 , λ2 , τ2 ), or
if f1 (h1 , λ1 , τ1 ) 
= f1 (h2 , λ2 , τ2 ) and f1 (h1 , λ1 , τ1 ) << f1 (h2 , λ2 , τ2 ). The discussion in
Section 3.2 on the importance of β and the proposal schemes still applies. Similarly,
we can define a sampling algorithm for the metric d0h .
5. EXPERIMENTS

We have implemented our techniques and, in particular, the new metrics inside our
Matlab toolbox S-T A L I R O [Annapureddy et al. 2011]. Our toolbox is general enough
to interact with various means for modeling CPS, including Simulink/Stateflow models. We currently support full time bounded MTL for continuous as well as hybrid
time trajectories. We remark that all the benchmark problems are distributed with ST A L I R O at https://sites.google.com/a/asu.edu/s-taliro/, which also includes all
the MTL specifications used in this section.
We performed a comparison of our implementation (MC) against a simple uniform
random (UR) exploration of the state-space. Both MC and UR are each run for a maximum number of 1,000 tests, terminating early if a falsifying trajectory is found. Since
these techniques are randomized, each experiment was repeated 100 times (runs) under different seeds in order to obtain statistically significant results. Uniform random
exploration provides an ideal measure of the difficulty of falsifying a property over a
given input. Its rate of success empirically quantifies the difficulty of falsifying a given
property. Finally, we have already argued about the importance of obtaining the least
robust trajectory where falsification cannot be achieved. To this end, we compare the
set of minima found using MC as well as that using UR and the corresponding running
times.
Table I reports on the results of our comparison on two benchmark problems
using different MTL properties or problem instances. The first benchmark problem
is the Automatic Transmission (AT) model considered in Example 2.1. We consider a
number of MTL specifications of increasing difficulty to falsify. As an example, formula
φ1AT is described in Example 2.7. The second benchmark is a Simulink model of a
3rd-order  −  modulator whose description can be found in Dang et al. [2004]. The
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:21

Table I. Experimental Comparison of Monte-Carlo (MC) vs. Uniform Random (UR) Falsification on Benchmark
Problems with Euclidean Output Spaces
Problem

ψ

#Fals.
MC
UR

AT

φ1AT

97

100

AT

φ2AT

96

100

AT

φ3AT

51

0

AT

φ4AT

0

0

AT

φ5AT

0

0

P−
[−0.45,0.45]

φ−

84

81

P−
[−0.4,0.4]

φ−

58

40

P−
[−0.35,0.35]

φ−

21

1

Robustness
MC
UR
2.54, 7,
48.5
3.03, 137,
6.6 · 104 
−4
0.04, 0.96,
8 · 10 , 0.42,
0.35
1.2
5.86, 5.95,
5.91, 6.06,
0.02
0.01
0.15, 0.41,
0.25, 0.57,
2.55
0.06
0.00, 0.04,
0.00, 0.01,
4.6 · 10−4 
1.2 · 10−4 
0.00, 0.06,
0.00, 0.03,
7.9 · 10−4 
2.2 · 10−4 
0.00, 0.07
0.01, 0.06
2.1 · 10−3 
7.9 · 10−4 

Time (sec)
MC

UR

0.2, 11, 92

0.2, 3, 16

0.2, 16, 94

0.2, 10, 48

7, 61, 94

93, 94, 99

92, 93, 93

92, 92, 93

93, 93, 94

92, 93, 94

0.2, 19, 41

0.2, 19, 43

0.7, 26, 39

0.3, 30, 38

4.1, 35, 49

5.4, 37, 44

Note: Each instance was run 100 times, and each run was executed for a maximum of 1,000 tests. Legend:
#Fals.: the number of runs falsified; Robustness: min, average, variance of the runs that were not
falsified; Time: min, average, max time in seconds per run.

3rd-order  −  modulator has unknown initial conditions in the set [−0.1, 0.1]3 and a
one-dimensional input signal that takes values in a set [um , uM ]. The problem instances in Table I indicate the bounds on the input signal [um , uM ]. The specification
for the  −  modulator is that the state of the system should always remain in the
set [−1, 1]3 .
We find that the performance varies depending on the ease with which the property
can be violated by means of uniformly sampling the input space. If the property can
be easily falsified, then it is advantageous to utilize uniform random search. MC for
easy problem instances seems to converge and get trapped at local minima. In practice, we may periodically reset the MC simulation using random restarts. However,
such restarts were not used in our experimental comparison. The use of MC is clearly
advantageous when the problem is challenging. In hard problem instances, MC can falsify the specification when UR fails to falsify. Moreover, even when falsification fails,
MC still computes lower minimum and average robustness values with the same computational cost. Further experimental results that attest the same conclusions can be
found in Nghiem et al. [2010].
Table II compares the performance of the falsification algorithm on benchmark problems with hybrid output space. We compared UR with MC on two benchmark problems
on various temporal logic formulas of increasing difficulty to falsify. The first benchmark problem was AT. As opposed to the previous experiments, the specifications now
not only place conditions on the continuous state of the system, but also on the discrete
locations. As an example, formula φ6AT is informally described in Example 4.1. Since
S-T A L I R O does not support yet automatic extraction of guard conditions, we compared
only UR with MC using the metric d0h for the distance computations.
The second example that we consider is the Navigation (NV) benchmark problem
from Fehnker and Ivančić [2004]. This is a hybrid automaton benchmark problem,
and both the control locations and the guards of the transitions are available to us.
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:22

H. Abbas et al.
Table II. Experimental Comparison of Monte-Carlo (MC) vs. Uniform Random (UR) Falsification on
Benchmark Problems with Hybrid Output Spaces

Problem

ψ
MC-H

AT
AT
AT
NV[0,25]
NV[0,12]
NV[0,12]
NV[0,12]
NV[0,12]

φ6AT
φ7AT
φ8AT
φ1NV
φ2NV
φ3NV
φ4NV
φ5NV

#Fals.
MC-H0

UR

MC-H

Time
MC-H0

UR

-

93

86

-

0.4, 24, 138

0.4, 56, 139

-

94

55

-

0.1, 25, 128

0.6, 81, 127

-

0

0

-

110, 115, 139

109, 111, 115

63

68

34

4.2, 542, 831

34, 545, 865

44, 623, 817

100

100

100

1.1, 24, 140

1.7, 25, 168

0.9, 22, 108

100

100

100

0.8, 8.7, 62

0.8, 17, 503

0.7, 4.0, 22

100

100

100

38

47

5

1.2, 18, 85

1.4, 26, 66

0.8, 35, 427

21.0, 419, 595

15, 390, 584

9.4, 404, 437

Note: Each instance was run 100 times, and each run was executed for a maximum of 1,000 tests.
Legend: #Fals.: the number of runs falsified; Time: min, average, max time in seconds per run; MCH: MC with metric dh ; MC-H0: MC with metric d0h .

Thus, we compared the performance of the Monte-Carlo sampling algorithm under the
metrics dh and d0h with the performance of uniform random sampling under the dh
metric. The problem instance that is used in our experiments is presented in Nghiem
et al. [2010].
First, we observe that on easy problem instances, that is, φ2NV -φ4NV , the performance
of all algorithms is comparable in terms of computation time. On hard problem instances, both MC-H and MC-H0 outperform UR in terms of numbers of falsifications.
The experimental results indicate that the best way to approach hybrid system
falsification/verification is with a layered approach. Assuming that at the initial design stages the errors are abundant, then it is preferable to run random sampling
for the falsification process. As the system design becomes more mature, then MonteCarlo sampling with the new metrics introduced in this article can be utilized for the
falsification. When the level of confidence in the system design has increased and
potentially the system design is robust enough, then the designer may use a reachability analysis algorithm (for example SpaceEx [Frehse et al. 2011]). However, we
remark that currently reachability analysis tools cannot handle arbitrary MTL specifications. A more detailed discussion on system verification that compares the advantages/disadvantages of falsification and reachability methods can be found in Abbas
and Fainekos [2011a, 2011b].
6. RELATED WORK

Due to the known undecidability results in the analysis of hybrid systems [Alur et al.
1995] and the state explosion problem of the reachability computation algorithms (see
[Julius et al. 2007] for some related references), a lot of recent research activity has
concentrated on testing approaches to the verification of continuous and hybrid systems [Kapinski et al. 2003; Zhao et al. 2003].
The use of Monte-Carlo techniques for model checking has been considered previously by Grosu and Smolka [2005]. Whereas Grosu and Smolka consider random
walks over the automaton defined by the system itself, our technique defines random
walks over the input state space. These are, in general, distinct approaches to the
problem. In practice, our approach does not have the limitation of being restricted
by the topology of the system’s state transition graph. Depending on this topology,
the probability of visiting states deeper in the graph can sometimes be quite small
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:23

in pathological cases. On the other hand, Grosu and Smolka’s technique can be
extended readily to the case of systems with control inputs without requiring a finite
parameterization of the control. We are currently investigating the possibility of
combining both types of random walks in a single framework. Previous work by some
of the authors in this work considered Monte-Carlo techniques for finding bugs in
programs [Sankaranarayanan et al. 2007]. However, our previous efforts did not have
the systematic definition of robustness that we employ here.
There exist two main approaches to the testing problem of hybrid systems. The first
approach is focused on choosing inputs and/or parameters in a systematic fashion so as
to cover the state-space of the system [Bhatia and Frazzoli 2004; Branicky et al. 2006;
Esposito et al. 2004; Nahhal and Dang 2007; Plaku et al. 2007]. These approaches are
mainly based on the theory of rapidly exploring random trees (RRTs). The other approach is based on the notion of robust simulation trajectory [Donzé and Maler 2007;
Girard and Pappas 2006; Julius et al. 2007; Lerda et al. 2008]. In robust testing, a simulation trajectory can represent a neighborhood of trajectories, thus achieving better
coverage guarantees. Recently, Dang et al. [2008] have made the first steps in bridging
these two aforementioned approaches.
On the research front of falsification/verification of temporal logic properties through
testing, the results are limited [Fainekos et al. 2006; Plaku et al. 2009; Rizk et al.
2008]. The work that is the closest to ours appears in Rizk et al. [2008]. The authors
of that work develop a different notion of robustness for temporal logic specifications,
which is also used as a fitness function for optimization problems. Besides the differences in the application domain, that is, Rizk et al. [2008] focus on parameter estimation for biological systems whereas our article deals with the falsification of hybrid
systems, the two works have also several differences at the theoretical and computational levels. At the theoretical level, we have introduced a new metric for hybrid
spaces which enables reasoning over hybrid trajectories, while at the computational
level our approach avoids set operations, for example, union, complementation, etc.,
which, in general, increase the computational load.
Younes and Simmons and, more recently, Clarke et al. have proposed the technique
of Statistical Model Checking (SMC). SMC targets stochastic system models, such as
continuous-time Markov chains [Younes and Simmons 2006] or Stochastic Hybrid Automata (SHA) [Clarke et al. 2009]. For example, in order to model imperfect sensors in
Example 2.1, we may add Gaussian noise to the sensor that reads the engine speed.
Then, the resulting system would be an SHA. The goal of SMC is to assess the probability that a system satisfies a given probabilistic temporal logic property ϕ. This
probability can be safely approximated using Wald’s probabilistic ratio test. SMC, like
our technique, requires a simulator to be available for the system, but not a transition
relation representation. In contrast to SMC, our approach is guided by a robustness
metric towards less robust trajectories. On the other hand, the complex nature of the
system and the robustness metrics imply that we cannot yet provide guarantees on
whether our algorithm has converged to the global minimum of the temporal logic
robustness function. However, this is an on-going endeavor.
Remark 6.1. Our method does not try to assess the probability of failure, but to
detect a failure. That is, our goal is to provide the engineer with tools in order to
detect design problems in the system rather than perform a failure analysis. In our
framework, if a failure is detected, then the designer has a counterexample to work
with in order to debug the system. Moreover, if a failure is not detected, then the
designer is still provided with the least robust behavior found. The fact that the system
might be correct with probability one does not imply that the system is robustly correct.
Therefore, we view SMC and our approach as complementary. In an MBD cycle, the
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:24

H. Abbas et al.

model should be first assessed for its robustly correct behavior, then a failure analysis
should be performed under various failure models and requirements.
7. CONCLUSIONS

Embedded systems require the verification of elaborate specifications, such as those
that can be expressed in MTL. The undecidability of the MTL verification problem
over such complex continuous systems mandates the use of lightweight formal methods that usually involve testing. In this article, we have presented a testing framework
for the metric temporal logic (MTL) falsification of hybrid systems using Monte-Carlo
optimization techniques. The use of hit-and-run Monte-Carlo optimization is required
in order to overcome the difficulties in handling the complex system dynamics, as well
as the nonlinearities in the objective function. Moreover, in order to enable more efficient search in hybrid state-spaces, a generalized distance function was introduced.
Experimental results indicate the superiority of our testing framework over random
search on the hard benchmark examples. The advantages of our approach are not limited only to the fact that we can falsify arbitrary systems, but also that we can provide
robustness guarantees even to systems that have been proven correct. The techniques
and the methods that were introduced in this article have been implemented in our
Matlab toolbox S-T A L I R O [Annapureddy et al. 2011].
APPENDIX

P ROOF OF T HEOREM 4.2. The proof is by induction on the structure of the formula.
(1) We will present only the base cases, since the other cases are identical with those
in the proofs in Fainekos and Pappas [2006, 2009].
— If [[ p, O]]d (y, t)  0, then by definition Distd (y(t), O(p))  0, which implies
that y(t) ∈ O(p), and thus, that (y, t, O) |= p.
— If (y, t, O) |= p, then by definition y(t) ∈ O(p), which implies that
depthd (y(t), O(p)) = Distd (y(t), O(p))  0, and thus, that [[ φ, O]]d (y, t)  0.
Note that the equality in the first case fails when the signal value y(t) is right on
the boundary of the set O(p), that is, y(t) ∈ ∂O(p). If [[ p, O]]d (y, t) = 0, then we
cannot distinguish whether (y, t, O) |= p or (y, t, O) 
|= p.
(2) Similar to the previous proof.
(3) We will present the base case and the negation (the other cases are based on the
definition of supremum and infimum over the partial order 	 of d and are similar
to the negation).
— Base case.
— If [[ p, O]]d (y, t) = ε  0, then (y, t, O) |= p and, by definition,
depthd (y(t), O(p)) = ε  0, which implies that Bd (y(t), ε) ⊆ O(p). Since
y ∈ Bρd (y, ε), we have ρd (y, y ) = supt∈R d(y(t), y (t)) ≺ ε. That is,
d(y(t), y (t)) ≺ ε, and thus, y (t) ∈ Bd (y(t), ε) ⊆ O(p). Hence, (y , t, O) |= p.
— Similar to the previous case.
— Negation.
— Positive case. If [[ ¬φ, O]]d (y, t) = ε  0, then (i) (y, t, O) |= ¬φ, that is,
(y, t, O) 
|= φ, and (ii) [[ φ, O]]d (y, t) = −ε ≺ 0. Then, by (ii) and the induction
hypothesis, we have that for all y ∈ Bρd (y, ε), (y , t, O) 
|= φ.
— Negative case. Similar to the previous case.
We chose to present negation in order to demonstrate the properties that the negation
must satisfy.
P ROPOSITION A.1. The generalized distance function dh is a quasi-metric.

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:25

P ROOF. We will need to demonstrate that the identity property and the triangle
inequality hold. In the following, we let hi = (i , zi ) ∈ H with i = 1, 2, 3.
Identity. Since π is a quasi-metric, we have π(1 , 2 ) = 0 if and only if 1 = 2 . Since
d is a metric, we have d(z1 , z2 ) = 0 if and only if z1 = z2 . Hence, dh (h1 , h2 ) = 0, 0 if
and only if h1 = h2 .
Triangle Inequality. We need to show that for all h1 , h2 , h3 ∈ H, dh (h1 , h2 ) ≤
dh (h1 , h3 ) + dh (h3 , h2 ). We proceed by case by case analysis.
(1) Case 1 = 2 = 3 . Then,


 


dh (h1 , h2 ) = 0, d(z1 , z2 ) ≤ 0, d(z1 , z3 ) + d(z3 , z2 )
 




= 0, d(z1 , z3 ) + 0, d(z3 , z2 ) = dh (h1 , h3 ) + dh (h3 , h2 ).
(2) Case 1 = 2 =

 3 . Then, π(1 , 3 ) > 0 and π(3 , 2 ) > 0 and



dh (h1 , h2 ) = 0, d(z1 , z2 ) ≤ π(1 , 3 ) + π(3 , 2 ), 0 ≤ π(1 , 3 ), 0 + π(3 , 2 ), 0
 


t
t
min
distd (z1 , G (1 , )) + π(3 , 2 ),
min
distd (z3 , G (3 , ))
≤ π(1 , 3 ),
∈∂ Nπ (1 ,3 )

∈∂ Nπ (3 ,2 )

= dh (h1 , h3 ) + dh (h3 , h2 ).
(3) Case 1 
= 2 and 1 = 3 . Then,

dh (h1 , h2 ) = π(1 , 2 ),

min

∈∂ Nπ (1 ,2 )


distd (z1 , Gt (1 , )) ,

but π(1 , 2 ) = 0 + π(3 , 2 ) = π(1 , 3 ) + π(3 , 2 ), and also,
min

∈∂ Nπ (1 ,2 )

distd (z1 , Gt (1 , )) =

≤

min

∈∂ Nπ (1 ,2 )

= d(z1 , z3 ) +
(1 =3 )

=



min

∈∂ Nπ (1 ,2 )

inf{d(z1 , z) | z ∈ Gt (1 , ))}

inf{d(z1 , z3 ) + d(z3 , z) | z ∈ Gt (1 , )}
min

∈∂ Nπ (1 ,2 )

d(z1 , z3 ) +

inf{d(z3 , z) | z ∈ Gt (1 , )}

min

∈∂ Nπ (3 ,2 )

distd (z3 , Gt (3 , )).


distd (z1 , G (1 , ))
t

Thus, dh (h1 , h2 ) = π(1 , 2 ),
min
∈∂ Nπ (1 ,2 )


t
≤ π(1 , 3 ) + π(3 , 2 ), d(z1 , z3 ) +
min
distd (z3 , G (3 , ))
∈∂ Nπ (1 ,2 )

 

:0


t

= 
min
distd (z3 , G (3 , ))
π(
1 , 2 ), d(z1 , z3 ) + π(3 , 2 ),
∈∂ Nπ (1 ,2 )

= dh (h1 , h3 ) + dh (h3 , h2 ).

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:26

H. Abbas et al.

(4) Case 1 
= 2 and 2 = 3 . Then,

dh (h1 , h2 ) = π(1 , 2 ),

min

∈∂ Nπ (1 ,2 )


distd (z1 , Gt (1 , )) ,

but, π(1 , 2 ) = π(1 , 3 ) + 0 = π(1 , 3 ) + π(3 , 2 ), and also,
min

∈∂ Nπ (1 ,2 )

distd (z1 , Gt (1 , ))

(2 =3 )

=

≤

min

∈∂ Nπ (1 ,3 )

min

∈∂ Nπ (1 ,3 )

distd (z1 , Gt (1 , ))

distd (z1 , Gt (1 , )) + d(z3 , z2 ),

since d(z3 , z2 ) ≥ 0. Thus,


t
min
distd (z1 , G (1 , ))
dh (h1 , h2 ) = π(1 , 2 ),
∈∂ Nπ (1 ,2 )


t
≤ π(1 , 3 ) + π(3 , 2 ),
min
distd (z1 , G (1 , )) + d(z3 , z2 )
∈∂ Nπ (1 ,3 )

 

:0


t

= π(1 , 3 ),
min
distd (z1 , G (1 , )) + 
π(
3 , 2 ), d(z3 , z2 )
∈∂ Nπ (1 ,3 )

= dh (h1 , h3 ) + dh (h3 , h2 ).
(5) Case 1 
= 2 , 1 
= 3 and 2 =

 3 . Then, π(1 , 2 ) ≤ π(1 , 3 ) + π(3 , 2 ), and


min
distd (z1 , Gt (1 , ))
dh (h1 , h2 ) = π(1 , 2 ),
∈∂ Nπ (1 ,2 )


≤ π(1 , 3 ),

≤ π(1 , 3 ) + π(3 , 2 ), 0 = π(1 , 3 ), 0 + π(3 , 2 ), 0
 

min
distd (z1 , Gt (1 , )) + π(3 , 2 ),
min
distd (z3 , Gt (3 , ))

∈∂ Nπ (1 ,3 )

∈∂ Nπ (3 ,2 )

= dh (h1 , h3 ) + dh (h3 , h2 ).
P ROPOSITION A.2. The generalized distance function d0h is a quasi-metric.
P ROOF. The proof is similar to the proof of Proposition A.1.
P ROPOSITION A.3.
Let


 the current point be h = , z and O(p) = Lp × Zp , then
Distd0 (h, O(p)) 
= k, ±∞ for any k ∈ Z. Similarly for Distdh (h, O(p)).
h



P ROOF. Actually, we will show that Distd0 (h, O(p)) = k, ±∞ if and only if k = ±∞.
h

(1) h 
∈ O(p) and  
∈ Lp , and if Lp is not reachable from , then for any  ∈ Lp , we have
π(,  ) = +∞. Thus, ∂Nπ (,  ) = ∅ and min ∈∂ Nπ (, ) distd (z, Gt (,  )) = +∞.
Hence, Distdh (h, O(p)) = −distdh (h, O(p)) = −∞, −∞. Also, Distd0 (h, O(p)) =
h
−∞, −∞ by definition.
(2) If h 
∈ O(p) and  
∈ Lp , and if Lp is reachable from , then
∂Nπ (,  ) 
= ∅, since (i) at least one of the neighbors of  will have distance to Lp less than distπ (, Lp ), and (ii) we have assumed that Gt (,  ) 
=
distd (z, Gt (,  )) < +∞ for all  ∈
∅ for all  ∈ Nxt(). Then,



∗
∂Nπ (,  ). Let  ∈ arg min{ π(,  ), min ∈∂ Nπ (, ) distd (z, Gt (,  )) |  ∈
Lp }, and set δ ∗ = min ∈∂ Nπ (,∗ ) distd (z, Gt (,  )) < +∞. Therefore,
ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:27

Distdh (h, O(p)) = −distdh (h, O(p)) = −π(, ∗ ), −δ ∗ . Finally, by definition, we



have Distd0 (h, O(p)) = −distdh (h, O(p)) = −distπ (, Lp ), 0 .
h
(3) If h 
∈ O(p), but  ∈ Lp , that is, z ∈ Zp , then Distdh (h, O(p)) = −distdh (h, O(p)) =
−distdh (h, (Lp \{} × Zp ) ∪ ({} × Zp )) = − min{distdh (h, Lp \{} × Zp ), distdh (h, {} ×



Zp )} = −distdh (h, {} × Zp )} = 0, −distd (z, Zp ) . However, distd (z, Zp ) < +∞ since
∅ ⊂ O(p) ⊂ Y by assumption. Similarly for Distd0 (h, O(p)).
h
(4) If h ∈ O(p) and Zp ⊂ Z, then Distdh (h, O(p)) = depthdh (h, O(p)) =
distdh (h, Y\O(p)) = distdh (h, ((L\Lp )×Z)∪(L×(Z\Zp ))) = min{distdh (h, (L\Lp )×



Y), distdh (h, L × (Z\Zp ))} = distdh (h, L × (Z\Zp ))} = 0, distd (z, Zp ) since  ∈ Lp ⊆
L. However, distd (z, Zp ) < +∞ since ∅ ⊂ O(p) ⊂ Y by assumption. Similarly for
Distd0 (h, O(p)).
h
(5) If h ∈ O(p) and Zp = Z, that is, Lp ⊂ L, then Distdh (h, O(p)) = depthdh (h, O(p)) =
distdh (h, Y\O(p)) = distdh (h, ((L\Lp ) × Z) ∪ (L × (Z\Zp ))) = distdh (h, ((L\Lp ) ×
Z) ∪ (L × ∅)) = distdh (h, (L\Lp ) × Z)}. Now, we have two cases.
— If L\Lp is reachable from , then as in Case (2), we have Distdh (h, O(p)) =
π(, ∗ ), δ ∗  with δ ∗ < +∞.
— If L\Lp is not reachable from , then distπ (, L\Lp ) = +∞, and as in Case
(1), we also have ∂Nπ (,  ) = ∅ for all  ∈ L\Lp . Thus, Distdh (h, O(p)) =
+∞, +∞.
Similarly, we can derive the value of Distd0 (h, O(p)).
h

This concludes the proof since we have considered all possible cases.
ACKNOWLEDGMENTS
The authors would like to thank Truong Nghiem and Professor George Pappas for their useful discussions
and the reviewers for their careful readings of the manuscript and numerous comments which have improved the article.

REFERENCES
Abbas, H. and Fainekos, G. 2011a. Linear hybrid system falsification through descent. Tech. rep.
arXiv:1105.1733.
Abbas, H. and Fainekos, G. 2011b. Linear hybrid system falsification through local search. In Automated
Technology for Verification and Analysis. Lecture Notes in Computer Science, vol. 6996. Springer,
503–510.
Alur, R., Dang, T., and Ivančić, F. 2003. Progress on reachability analysis of hybrid systems using predicate abstraction. In Hybrid Systems: Computation and Control. Lecture Notes in Computer Science,
vol. 2623. Springer, 4–19.
Alur, R., Henzinger, T. A., Lafferriere, G., and Pappas, G. J. 2000. Discrete abstractions of hybrid systems.
Proc. IEEE 88, 2, 971–984.
Alur, R., Courcoubetis, C., Halbwachs, N., Henzinger, T. A., Ho, P.-H., Nicollin, X., Olivero, A., Sifakis, J., and
Yovine, S. 1995. The algorithmic analysis of hybrid systems. Theor. Comput. Sci. 138, 1, 3–34.
Alur, R., Dang, T., Esposito, J., Hur, Y., Ivancic, F., Kumar, V., Lee, I., Mishra, P., Pappas, G. J., and Sokolsky,
O. 2003. Hierarchical modeling and analysis of embedded systems. Proc. IEEE 91, 1, 11–28.
Andrieu, C., Freitas, N. D., Doucet, A., and Jordan, M. I. 2003. An introduction to MCMC for machine
learning. Machine Learn. 50, 5–43.
Annapureddy, Y. S. R., Liu, C., Fainekos, G. E., and Sankaranarayanan, S. 2011. S-taliro: A tool for temporal
logic falsification for hybrid systems. In Tools and Algorithms for the Construction and Analysis of
Systems. Lecture Notes in Computer Science, vol. 6605. Springer, 254–257.

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:28

H. Abbas et al.

Bandemer, H. and Gottwald, S. 1995. Fuzzy Sets, Fuzzy Logic, Fuzzy Methods, with Applications. Wiley, New
York, NY.
Bhatia, A. and Frazzoli, E. 2004. Incremental search methods for reachability analysis of continuous and
hybrid systems. In Proceedings of HSCC. Lecture Notes in Computer Science, vol. 2993. Springer,
142–156.
Boyd, S. and Vandenberghe, S. 2004. Convex Optimization. Cambridge University Press.
http://www.stanford.edu/~boyd/cvxbook.html.
Branicky, M., Curtiss, M., Levine, J., and Morgan, S. 2006. Sampling-based planning, control and verification
of hybrid systems. IEE Control Theory Appl. 153, 5, 575–590.
Chib, S. and Greenberg, E. 1995. Understanding the Metropolis-Hastings algorithm. Amer. Statistician 49, 4,
327–335.
Clarke, E., Donze, A., and Legay, A. 2009. Statistical model checking of analog mixed-signal circuits with
an application to a third order δ − σ modulator. In Hardware and Software: Verification and Testing.
Lecture Notes in Computer Science, vol. 5394/2009. 149–163.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., and Stein, C. 2001. Introduction to Algorithms 2nd Ed. MIT
Press/McGraw-Hill.
Dang, T., Donzé, A., and Maler, O. 2004. Verification of analog and mixed-signal circuits using hybrid system
techniques. In Proceedings of the 5th International Conference on Formal Methods in Computer-Aided
Design. Lecture Notes in Computer Science, vol. 3312. Springer, 21–36.
Dang, T., Donze, A., Maler, O., and Shalev, N. 2008. Sensitive state-space exploration. In Proceedings of the
47th IEEE CDC. 4049–4054.
de Alfaro, L., Faella, M., and Stoelinga, M. 2004. Linear and branching metrics for quantitative transition
systems. In Proceedings of the 31st ICALP. Lecture Notes in Computer Science, vol. 3142. Springer,
97–109.
Donzé, A. and Maler, O. 2007. Systematic simulation using sensitivity analysis. In Proceeding of HSCC.
Lecture Notes in Computer Science, vol. 4416. Springer, 174–189.
Egerstedt, M. and Martin, C. 2009. Control Theoretic Splines: Optimal Control, Statistics, and Path Planning. Princeton University Press, Princeton, NJ.
Esposito, J. M. and Kumar, V. 2004. An asynchronous integration and event detection algorithm for simulating multi-agent hybrid systems. ACM Trans. Model. Comput. Simul. 14, 4, 363–388.
Esposito, J. M., Kim, J., and Kumar, V. 2004. Adaptive RRTs for validating hybrid robotic control systems.
In Proceedings of the International Workshop on the Algorithmic Foundations of Robotics.
Esterel Technologies. 2011. Scade success stories.
http://www.esterel-technologies.com/technology/success-stories/.
Fainekos, G. E. and Pappas, G. J. 2006. Robustness of temporal logic specifications for finite state sequences
in metric spaces. Tech. rep. MS-CIS-06-05, Dept. of CIS, Univ. of Pennsylvania.
Fainekos, G. E. and Pappas, G. J. 2009. Robustness of temporal logic specifications for continuous-time
signals. Theor. Comput. Sci. 410, 42, 4262–4291.
Fainekos, G. E., Girard, A., and Pappas, G. J. 2006. Temporal logic verification using simulation. In Proceedings of FORMATS. Lecture Notes in Computer Science, vol. 4202. Springer, 171–186.
Fainekos, G. E., Sankaranarayanan, S., Ivančić, F., and Gupta, A. 2009. Robustness of model-based simulations. In Proceedings of the IEEE Real-Time Systems Symposium. 345–354.
Fehnker, A. and Ivančić, F. 2004. Benchmarks for hybrid systems verification. In Proceedings of HSCC.
Lecture Notes in Computer Science, vol. 2993. Springer, 326–341.
Frehse, G., Guernic, C. L., Donz, A., Cotton, S., Ray, R., Lebeltel, O., Ripado, R., Girard, A., Dang, T., and
Maler, O. 2011. Spaceex: Scalable verification of hybrid systems. In Proceedings of the 23rd CAV.
Frenkel, D. and Smit, B. 1996. Understanding Molecular Simulation: From Algorithms to Applications.
Academic Press, Walthan, MA.
Girard, A. and Pappas, G. J. 2006. Verification using simulation. In Proceedings of HSCC. Lecture Notes in
Computer Science, vol. 3927. Springer, 272–286.
Grosu, R. and Smolka, S. 2005. Monte carlo model checking. In Proceedings of TACAS. Lecture Notes in
Computer Science, vol. 3440. Springer, 271–286.
Henzinger, T. A. 1996. The theory of hybrid automata. In Proceedings of LICS. 278–292.
Henzinger, T. A., Kopke, P. W., Puri, A., and Varaiya, P. 1998. What’s decidable about hybrid automata? J.
Comput. Syst. Sci. 57, 1, 94–124.
Julius, A. A., Fainekos, G. E., Anand, M., Lee, I., and Pappas, G. J. 2007. Robust test generation and coverage
for hybrid systems. In Proceedings of HSCC. Lecture Notes in Computer Science, vol. 4416. Springer,
329–342.

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

Probabilistic Temporal Logic Falsification of Cyber-Physical Systems

95:29

Kapinski, J., Krogh, B. H., Maler, O., and Stursberg, O. 2003. On systematic simulation of open continuous systems. In Proceedings of HSCC. Lecture Notes in Computer Science, vol. 2623. Springer,
283–297.
Kopperman, R. 1988. All topologies come from generalized metrics. Amer. Math. Month. 95, 89–97.
Koymans, R. 1990. Specifying real-time properties with metric temporal logic. Real-Time Syst. 2, 4,
255–299.
Lamine, K. B. and Kabanza, F. 2000. Using fuzzy temporal logic for monitoring behavior-based mobile robots.
In Proceedings of the IASTED International Conference Robotics and Applications, M. Hamza Ed.,
116–122.
Lee, E. A. and Varaiya, P. 2003. Structure and Interpretation of Signals and Systems. Addison Wesley,
Reading, MA.
Lerda, F., Kapinski, J., Clarke, E. M., and Krogh, B. H. 2008. Verification of supervisory control software using state proximity and merging. In Proceedings of HSCC. Lecture Notes in Computer Science, vol. 4981.
Springer, 344–357.
Lovasz, L. and Vempala, S. 2003. Hit-and-run is fast and fun. Tech rep. MSR-TR-2003.05.
http://www-math.mit.edu/~vempala/papers/logcon-hitrun.ps.
Lovasz, L. and Vempala, S. 2006. Hit-and-run from a corner. SIAM J. Comput. 35, 4, 985–1005.
Lygeros, J., Johansson, K. H., Simic, S. N., Zhang, J., and Sastry, S. 2003. Dynamical properties of hybrid
automata. IEEE Trans. Autom. Control 48, 2–17.
Mathworks. 2011. Simulink user stories.
http://www.mathworks.com/products/simulink/userstories.html.
Nahhal, T. and Dang, T. 2007. Test coverage for continuous and hybrid systems. In Proceedings of CAV.
Lecture Notes in Computer Science, vol. 4590. Springer, 449–462.
Nghiem, T., Sankaranarayanan, S., Fainekos, G. E., Ivancic, F., Gupta, A., and Pappas, G. J. 2010.
Monte-carlo techniques for falsification of temporal properties of non-linear hybrid systems. In Proceedings of the 13th ACM International Conference on Hybrid Systems: Computation and Control.
211–220.
Plaku, E., Kavraki, L. E., and Vardi, M. Y. 2007. Hybrid systems: From verification to falsification. In
Proceedings of CAV. Lecture Notes in Computer Science, vol. 4590. Springer, 463–476.
Plaku, E., Kavraki, L. E., and Vardi, M. Y. 2009. Falsification of ltl safety properties in hybrid systems. In
Proceedings of TACAS. Lecture Notes in Computer Science, vol. 5505. Springer, 368–382.
Press, W. H., Flannery, B. P., Teukolsky, S. A., and Vetterling, W. T. 1992. Numerical Recipes: The Art of
Scientific Computing 2nd Ed. Cambridge University Press.
Randall, D. 2006. Rapidly mixing markov chains with applications in computer science and physics. Comput.
Sci. Eng. 8, 2.
Rizk, A., Batt, G., Fages, F., and Soliman, S. 2008. On a continuous degree of satisfaction of temporal logic
formulae with applications to systems biology. In Proceeding of the 6th International Conference on
Computational Methods in Systems Biology. Lecture Notes in Computer Science, vol. 5307. Springer,
251–268.
Romeijn, H. and Smith, R. 1994. Simulated annealing for constrained global optimization. J. Global
Optim. 5, 101–126.
Rubinstein, R. Y. and Kroese, D. P. 2008. Simulation and the Monte Carlo Method. Wiley Series in Probability and Mathematical Statistics.
Sanfelice, R. G. and Teel, A. R. 2010. Dynamical properties of hybrid systems simulators. Automatica 46, 2,
239–248.
Sankaranarayanan, S., Chang, R. M., Jiang, G., and Ivancic, F. 2007. State space exploration using feedback
constraint generation and monte-carlo sampling. In Proceedings of ESEC/SIGSOFT FSE. 321–330.
Seda, A. K. and Hitzler, P. 2008. Generalized distance functions in the theory of computation. Comput.
J. 53, 4.
Smith, R. 1984. Monte Carlo procedures for generating points uniformly distributed over bounded regions.
Oper. Res. 38, 3, 1296–1308.
Smith, R. L. 1996. The hit-and-run sampler: A globally reaching markov chain sampler for generating
arbitrary multivariate distributions. In Proceedings of the 28th Conference on Winter Simulation.
260–264.
Sontag, E. D. 1998. Mathematical Control Theory: Deterministic Finite Dimensional Systems 2nd Ed.
Springer.
Tripakis, S. and Dang, T. 2009. Model-Based Design for Embedded Systems. CRC Press, 383–436.

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

i

i

i

i

95:30

H. Abbas et al.

Younes, H. L. S. and Simmons, R. G. 2006. Statistical probabilitistic model checking with a focus on timebounded properties. Inform. Comput. 204, 9, 1368–1409.
Zabinsky, A., Smith, R., MacDonald, J., Romeijn, H., and Kaufman, D. 1993. Improving hit-and-run for
global optimization. J. Global Optim. 3, 171–192.
Zhao, Q., Krogh, B. H., and Hubbard, P. 2003. Generating test inputs for embedded control systems. IEEE
Control Syst. Mag. Aug., 49–57.
Received June 2011; revised November 2011; accepted December 2011

ACM Transactions on Embedded Computing Systems, Vol. 12, No. 2s, Article 95, Publication date: May 2013.

i

i
i

i

Falsification of Temporal Properties of Hybrid Systems
Using the Cross-Entropy Method
Sriram Sankaranarayanan

Georgios Fainekos

University of Colorado, Boulder, CO, USA.

Arizona State University, Tempe, AZ, USA

srirams@colorado.edu

fainekos@asu.edu

ABSTRACT
Randomized testing is a popular approach for checking properties
of large embedded system designs. It is well known that a uniform random choice of test inputs is often sub-optimal. Ideally, the
choice of inputs has to be guided by choosing the right input distributions in order to expose corner-case violations. However, this
is also known to be a hard problem, in practice. In this paper, we
present an application of the cross-entropy method for adaptively
choosing input distributions for falsifying temporal logic properties of hybrid systems. We present various choices for representing
input distribution families for the cross-entropy method, ranging
from a complete partitioning of the input space into cells to a factored distribution of the input using graphical models.
Finally, we experimentally compare the falsification approach
using the cross-entropy method to other stochastic and heuristic
optimization techniques implemented inside the tool S-Taliro over
a set of benchmark systems. The performance of the cross entropy
method is quite promising. We find that sampling inputs using the
cross-entropy method guided by trace robustness can discover violations faster, and more consistently than the other competing methods considered.

Categories and Subject Descriptors
G.3 [Mathematics of Computing]: Probability and Statistics—
Probabilistic algorithms (including Monte Carlo)

General Terms
Verification

Keywords
Hybrid Systems, Testing, Robustness, Metric Temporal Logic, MonteCarlo Simulation, Cross-Entropy Method.

1.

INTRODUCTION

In this paper, we propose the use of the cross-entropy method
[33, 32] for falsifying Metric Temporal Logic (MTL) properties on

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
HSCC’12, April 17–19, 2012, Beijing, China.
Copyright 2012 ACM 978-1-4503-1220-2/12/04 ...$10.00.

125

complex hybrid systems. Testing through the random sampling of
input vectors is a simple, yet popular approach for checking hybrid
system models that are too complex to be verified using more rigorous formal verification techniques. However, the algorithm used
for choosing input vectors is crucial for the success of randomized
testing. Often, the choice of inputs needs to incorporate detailed
knowledge about the system in the form of appropriate input distributions that are easy to sample from, while also providing a bias
towards input choices exhibiting property violations. Such user
guidance is often impractical, since it requires a detailed knowledge of the system’s internals along with insights as to how this
knowledge may be incorporated into an appropriate input distribution. Secondly, distributions that are ideal for exposing property
violations tend to be quite hard to sample from, in practice.
In this paper, we employ a versatile approach to sampling known
as the Cross-Entropy Method [6, 32, 33], guided by the notion of
robustness of execution traces of continuous and hybrid systems
w.r.t MTL properties [17, 18, 28], in order to solve the problem of
generating test inputs that falsify a given set of MTL properties.
The robustness semantics of MTL associates a real value with
each trajectory. Formally, this value denotes the radius of a cylinder around the trajectory (defined using an appropriate metric over
states), such that all trajectories inside this cylinder have an identical outcome for the given property as the given reference trajectory
(Cf. Figure 2). As a result, the robustness value of a trajectory provides a mathematically sound notion of distance that can be used to
express how “far away” a given trace is from violating a property.
The notion of robustness of MTL formulae can, in turn, be used to
associate an ideal probability distribution that samples each input
according to the robustness of the resulting trajectory. However,
this distribution is often complex and not known in a closed form.
In this work, the cross-entropy (CE) method is used to sample
from this complex distribution. The CE method is, fundamentally, a
technique for sampling from a complex probability distribution that
is not necessarily known in a closed form. The applications of this
method include rare-event simulation, variance reduction for estimation problems and stochastic optimization [33]. The CE method
seeks to approximate the target distribution by choosing amongst
a family of distributions such as piecewise uniform distributions
or Gaussian distributions, that are “easy” to sample from [32, 6].
The technique iteratively searches for a specific distribution from
this family that is “as close as possible” to the intended distribution. Here closeness of distributions is measured using the standard Kullback-Liebler (KL) divergence (also known as the crossentropy distance) between the distributions. At each step, crossentropy method generates samples according to a current candidate
distribution from the family. Next, it uses these samples to tilt the
current candidate distribution towards a new candidate that mini-

mizes the empirically estimated KL divergence over the current set
of samples between the new candidate and the target distribution.
As a result of this iteration, the candidate distribution is seen to get
closer in the sense of KL divergence to the target distribution.
Applying the cross-entropy method requires choosing a family
of distributions that is easy to sample from, while at the same time
able to approximate the complex distribution induced by the trajectory robustness values. We find that a natural approach is to use
piecewise uniform distributions, whenever the space of inputs is
bounded. Such distributions are defined by subdividing the space of
input vectors into finitely many cells and associating a fixed probability of choosing an input from a given cell. However, the number
of cells grows exponentially in the number of components in the input vector. Therefore, we consider the application of cross-entropy
method on factored input representations, wherein the distribution
is factored into various marginal probability distributions that relate
a small set of input variables. In this paper, we derive the necessary
rules for tilting the cross entropy method for factorings based on
graphical models.
Finally, we present a prototype implementation of our approach
on the S-Taliro tool for testing Simulink/Stateflow models [3]. Our
experimental evaluation compares the performance of the CrossEntropy method against Monte-Carlo methods [28, 33] and simple
uniform random sampling.

~x0
System
~v

ai , bi ∈ R ∪ ±∞. Since the system is assumed to be deterministic,
its output ~
y = S(~
x0 , ~
u) can be written as a function of its initial
state ~
x0 and inputs ~
u.
Parameterizing Input Signals: Let U denote the space of all
measurable functions ~
u : [0, T ] 7→ Rk . The overall goal of randomized testing is to explore many points in the space the space
X0 × U of inputs. However, arbitrary (measurable) input signals
from a function space U are often hard to represent. Therefore, we
restrict our attention to a class of signals from U that can be succinctly described in a finite dimensional space by a finite set of real
valued parameters. Common examples of such families include:
• Piecewise constant (or linear) signals that are described by
the values ~
u0 , ~
u1 , . . . , ~
uk at a fixed set of time points:
0 = T0 < T1 < T2 < · · · < Tk < Tk+1 = T ,
wherein ~
u(t) = ~
uj for all t ∈ [Tj , Tj+1 ) and j = 0, . . . , k.
• Polynomial signals defined by parameters ~a1 , . . . , ~al , wherein,
~
u(t) = ~a0 + ~a1 t + ~a2 t2 + · · · + ~al tl .
• Splines [15] can be specified piecewise by specifying a finite
set of time points along with signal values and derivatives at
these time points.
In practice, the family is chosen so that any signal of interest
from U can be represented approximately with some small error.
Thus, the chosen representation R for the signals ensures a finite set
of parameters ~v ∈ V such that each ~v can be mapped onto a unique
input U(~v ) : [0, T ] → U . The process of sampling described in
this paper can therefore focus on sampling real numbers.

PRELIMINARIES

In this section, we present some background on system models,
metric temporal logics (MTL) and roubstness of traces. More details on our approach are available from our previous work on using
stochastic optimization techniques for temporal falsification [28].

2.1

Signal
Gen

Figure 1: Block diagram of the system after parameterizing
input signals.

Summary of Contributions: (a) We present the use of the CE
method for falsifying MTL properties using the robustness metrics
over hybrid trajectories. (b) We consider the problem of specifying a family of input distributions that can approximate complex
distributions with small KL divergences, while at the same time,
be parameterized by a small number of parameters. We explore
the use of factored input distributions using graphical models. (c)
We present an experimental evaluation of our approach over a set of
benchmarks, using a prototype implementation in our tool S-Taliro,
along with a comparison with other optimization approaches supported inside S-Taliro that are also guided by MTL robustness.
Finally, proofs of key propositions have been omitted due to
space considerations. These will be made available on-line or upon
request. The techniques presented in this paper have been implemented as part of our tool S-Taliro. S-Taliro is available as an open
source tool on-line at http://sites.google.com/a/asu.
edu/s-taliro.

2.

~
y (t)

2.2

Systems and Inputs

We assume a black-box model of deterministic systems including continuous, discrete, and hybrid systems that combine continuoustime dynamics with instantaneous discrete switches [1].
A system S maps the initial conditions ~
x0 ∈ Rn , and input sigk
nals ~
u : [0, T ] 7→ R to output values ~
y : [0, T ] 7→ Y , wherein
T > 0 is assumed to be a large, but finite time limit1 . We assume that the initial state ~
x0 ∈ X0 for some set X0 ⊆ Rn and
k
~
u(t) ∈ U ⊆ R for all time t ∈ [0, T ]. Furthermore, the sets X0
and U are assumed to be boxes, which are Cartesian products of
intervals of the form [a1 , b1 ] × [a2 , b2 ] × · · · × [an , bn ], wherein
1

Since the goal in this paper is that of testing hybrid systems, it is
not strictly necessary to define input and output maps that extend
for all time.

126

Metric Temporal Logic

Functional specifications for real-time embedded systems usually involve a number of critical properties such as timing requirements, stability and bounded response. Metric Temporal Logic
(MTL) introduced by Koymans [24] is a popular formalism for
expressing such properties. The problem of verifying MTL specifications is undecidable for hybrid systems. Consequently, the
bounded-time verification or falsification of such properties has been
studied [28, 17].
Table 1 summarizes the syntax of MTL formulae. Let ϕ be an
MTL formula, t0 ≥ 0 be a time instant and ~
y : [0, T ] 7→ Y be an
output trajectory. To define the semantics, we first define observation maps that provide meaning to the atomic propositions.
D EFINITION 2.1 (O BSERVATION M AP ). An observation map
O : AP → P(Y ) maps each proposition p ∈ AP to a set
O(p) ⊆ Y . For simplicity, we assume that O(p) ⊆ Y is closed
and compact for each p ∈ AP .

>
p ∈ AP
ϕ1 ∧ ϕ2
ϕ1 ∨ ϕ2
¬ϕ
2I ϕ
3I ϕ
ϕ1 UI ϕ2

Table 1: Metric Temporal Logic (MTL) Operators and their formal semantics at time t = t0 .
true
Tautology
~
y (t0 ) ∈ O(p)
Atomic Proposition holds
(~
y , t0 , O) |= ϕ1 ∧ (~
y , t0 , O) |= ϕ2
Conjunction
(~
y , t0 , O) |= ϕ1 ∨ (~
y , t0 , O) |= ϕ2
Disjunction
(~
y , t0 , O) 6|= ϕ
Negation
(∀t ∈ I)((t0 + t < T ) ⇒ (~
y , t0 + t, O) |= ϕ)
ϕ is Invariant in I
(∃t ∈ I)((t0 + t < T ) ∧ (~
y , t0 + t, O) |= ϕ)
ϕ eventually holds in I
(∃t ∈ I)((t0 + t < T ) ∧ (~
y , t0 + t, O) |= ϕ2 ∧ (∀t0 ∈ [0, t)) (~
y , t0 + t0 , O) |= ϕ1 ) ϕ1 until ϕ2

We denote the satisfaction of the formula ϕ by the trajectory ~
y
starting from time t = t0 by (~
y , t0 , O) |= ϕ. The semantics of
MTL in terms of the |= relation is also provided in Table 1.

S

P ROBLEM 2.1 (MTL FALSIFICATION ). For an MTL specification ϕ, the MTL falsification problem consists of finding valid
initial state ~
x0 and input signals ~
u : [0, T ] → U , such that the resulting output trajectory ~
y : [0, T ] → Y falsifies the specification
ϕ, i.e., (~
y , 0, O) 6|= ϕ.

ε

Robustness of Trajectories Our proposed solution for Problem
2.1 quantifies the robustness of satisfaction of an MTL formula over
a system trajectory to guide the search for falsifications [18].
We briefly present the robust interpretation (semantics) of MTL
formulas. Details are available from our previous work [18, 28].
We provide semantics that maps an MTL formula ϕ and a trajectory ~
y (t) to a value drawn from the linearly ordered set R =
R ∪ {±∞}. The semantics for the atomic propositions evaluated
for ~
y (t) consists of the distance between ~
y (t) and the set O(p) labeling the atomic proposition p. Intuitively, this distance represents
how robustly the point ~
y (t) lies within (or outside) the set O(p).
First, let d be a distance metric on Y . For each point ~
y ∈ Y , we
define the open ball Bd (~
y , ) = {~z | d(~
y , ~z) < }.

Figure 2: Illustration of robustness of trajectory shown in solid
line. The property asserts the “unreachability” of the set S.
The robustness value ε defines a cylinder around the trajectory, so that all trajectories that lie inside a cylinder of radius ε
(dashed lines) also satisfy the property.
not satisfy the property, then its robustness is non-positive. The
following result holds [18].
T HEOREM 2.1. Given a formula ϕ ∈ M T L, an observation
map O ∈ P(Y )AP and a trajectory ~
y ∈ Y [0,T ] , the following
hold:

D EFINITION 2.2 (S IGNED D ISTANCE ). Let y ∈ Y be a point,
S ⊆ Y be a set and d be a distance metric on Y . We define the
signed distance from y to S to be

− inf{d(y, y 0 ) | y 0 ∈ S}
if y 6∈ S
Distd (y, S) :=
inf{d(y, y 0 ) | y 0 ∈ Y \S} if y ∈ S

(1) If (~
y , t, O) |= ϕ, then [[ϕ, O]]d (~
y , t) ≥ 0.
(2) Conversely, if [[ϕ, O]]d (~
y , t) > 0, then (~
y , t, O) |= ϕ.
(3) If for some t ∈ R+ , ε = [[ϕ, O]]d (~
y , t) 6= 0, then for all ~
y0 ∈
0
Bd (~
y , |ε|), we have (~
y , t, O) |= ϕ if and only if (~
y , t, O) |=
ϕ. I.e, ε defines a cylinder around the trajectory such that trajectories lying entirely inside this cylinder also satisfy ϕ.

If this distance is zero, then the smallest perturbation of the point
y can affect the outcome of y ∈ O(p). We denote the robust valuation of the formula ϕ over the signal ~
y at time t by [[ϕ, O]]d (~
y , t).
Formally, [[·, ·]]d : (M T L × P(Y )AP ) → (Y [0,T ] × [0, T ] → R).
D EFINITION 2.3 (ROBUST S EMANTICS ). Let ~
y ∈ Y [0,T ] , c ∈
AP
R and O ∈ P(Y ) , then the robust semantics of any formula
ϕ ∈ M T L with respect to ~
y is recursively defined as follows for
t ∈ [0, T ]:

In other words, if a trajectory ~
y satisfies the formula ϕ at time instant t ≥ 0 then its robustness value is non-negative.
Theorem 2.1 establishes the robust semantics of MTL as a natural measure of trajectory robustness. Namely, a trajectory is ε
robust with respect to an MTL specification ϕ, if it can tolerate perturbations up to size ε and still maintain its current Boolean truth
value. Alternatively, a trajectory with the opposite outcome for ϕ,
if it exists, has a distance of at least ε away.
The efficient computation of MTL robustness over continuous
and hybrid system trajectories has been investigated in [18, 17]. Implementations are available as part of the tool Taliro, which forms
the core of our approach to temporal logic falsification [3].

[[>, O]]d (~
y , t)
:= +∞
[[p, O]]d (~
y , t)
:= Distd (~
y (t), O(p))
[[¬ϕ1 , O]]d (~
y , t)
:= −[[ϕ1 , O]]d (~
y , t)
[[ϕ1 ∨ ϕ2 , O]]d (~
y , t) := max([[ϕ1 , O]]d (~
y , t), [[ϕ2 , O]]d (~
y , t))
[[ϕ1 UI ϕ2 , O]]d (~
y , t) :=

00
sup
min [[ϕ2 , O]]d (~
y , t0 ), inf
[[ϕ
,
O]]
(~
y
,
t
)
1
d
00
0
t0 ∈(t+[0,T ] I)

t≤t <t

where t +[0,T ] I = {τ | ∃τ 0 ∈ I . τ = t + τ 0 } ∩ [0, T ].

2.3

Temporal Falsification as Optimization

Given a system S : X0 × V 7→ Y (Cf. Figure 1), along with
a MTL specification ϕ, we are interested in finding input signals ~
u

It is easy to show that if the trajectory satisfies the property, then
its robustness is non-negative and, similarly, it the trajectory does

127

and initial conditions ~
x0 such that the resulting output falsifies ϕ.
More generally, we can search for inputs such that the robustness
value of the resulting output trajectory w.r.t specification ϕ is the
least possible. Let R(~
x0 , ~v ; ϕ, S) denote the robustness value w.r.t
ϕ for the trajectory ~
y resulting from inputs ~
x0 , ~
u to system S

Our presentation will focus mostly on how cross-entropy method
can be used to sample from a distribution Ω over the space of inputs X0 × V . As a first step, we fix a family of distributions pθ ,
parameterized by a set of parameters θ ∈ P .
• Piecewise-Uniform Family: The piecewise uniform family
is useful when the input space X0 × V is bounded. We partition the input space into a set of mutually disjoint measurable cells C1 , . . . , Ck , wherein each Ci is bounded and has
a finite volume. The family is parameterized by the individual cell sampling probabilities θ : (p1 , . . . , pk ) ∈ [0, 1]k ,
P
such that, ki=1 pi = 1. Here pk denotes the probability
that an input from the cell Ci is chosen. In order to sample from a given distribution pθ in the family, we choose a
cell according Ci with probability pi . Next we choose input
(~
x0 , u) ∈ Ci , uniformly at random.

R(~
x0 , ~v ; ϕ, S) = [[ϕ, O]]d (~
y , 0), wherein ~
y = S(~
x0 , ~v ) .
Consider the optimization problem of finding inputs that yield the
minimal robustness value possible:
(~
x0 , ~v ) =

argmin R(~
x0 , ~v ; S, ϕ) .
~
x0 ∈X0 ,~
v ∈V

If the minimal robustness value is negative then the corresponding
inputs yield a falsifying test case. Solving for ~
x0 , ~v is hard, even
for the simplest of systems. Our goal is therefore to search for trajectories ~
y that have small robustness values by sampling from the
space of initial conditions X0 and input signals V . If we discover a
violation in the process, we can report such a violation to the user.
Failing this, our search simply presents the least robust trajectory
discovered thus far.
The strategy used for finding a trajectory with as small a robustness value by sampling is to draw samples according to a probability distribution. Let p be a probability density function over a set
of support X. A sampling scheme produces a sequence of samples
x1 , . . . , xN ∈ X, such that for any (measurable) subset I ⊆ X,

Z
N
X
1(xi ∈ I)
1 if ϕ
=
p(x)dx , where 1(ϕ) =
.
lim
0 otherwise
N →∞
N
I

The piecewise uniform family can be made to approximate
any distribution with arbitrary precision by (a) increasing the
number of partitions and (b) by choosing the probabilities of
each partition appropriately.
• Gaussian Distribution: A multivariate Gaussian distribution Nµ~ ,C is parameterized by its mean µ
~ and its co-variance
matrix C (a positive semi-definite matrix). These distributions (and other exponential distributions) are suitable when
X0 × V is unbounded. A simple extension to this model
considers a mixture of Gaussian distributions, by averaging
a fixed number of Gaussian distributions.

i=1

In other words, as we draw a large number of samples, the empirical
sample distribution converges in the limit to the distribution p.
Suppose we were able to draw numerous samples according to
the probability distribution Ω over X0 × V , defined as

3.1

Let Ω be a (complex) distribution over I : X0 ×V that we wish to
sample from. We assume that Ω(~
x, ~v ) 6= 0 for all (~
x, ~v ) ∈ X0 ×V .
In general, we may not know Ω as a closed form formula. However,
for any two points (~
x0 , ~v0 ) and (~
x1 , ~v1 ) in the input space I, it is
x0 ,~
v0 )
. Consequently, it is possible
possible to compute the ratio Ω(~
Ω(~
x1 ,~
v1 )
to compare the values of Ω at two or more points and rank these
points according to the value of Ω.
Let pθ be a family of distributions parameterized by θ ∈ P .
We assume that each pθ has a set of support that contains X0 ×
V . In other words, pθ (~
x, ~v ) 6= 0 for all (~
x, ~v ) ∈ X0 × V . Our
goal is to find a distribution pθ from the family that is “as close”
to Ω as possible. However, the notion of the “closeness” of two
distributions needs to be formalized. We use the standard KullbackLiebler (KL) divergence from information theory.

1 −K·R(~x0 ,~v;S,ϕ)
e
,
W
wherein K > 0 is some chosen weighting factor and W is used to
normalize the total mass of the distribution over X0 × V . Given
the nature of the distribution, the probability of encountering inputs ~
x0 , ~v that yield negative robustness values (if such inputs exist)
is exponentially larger than that of obtaining a positive robustness
value. The precise ratio of these probabilities is controlled by K.
Drawing samples according to Ω promises to be an effective way
of searching for falsifications. However, there are two main problems: (a) Ω is not known in a closed form. To compute Ω(~
x0 , ~v ),
we obtain R(~
x0 , ~v ; S, ϕ) by simulating the system S over the inputs (~
x0 , ~v ). However, the normalizing factor W is also unknown.
(b) Techniques that attempt to sample inputs according to Ω often
require a large number of simulations to converge [28].
An alternative approach is to start from a family of distributions F (eg., normal distributions) and attempt to find a distribution
which is as close to Ω as possible. The tradeoff involved here is that
we are sampling from a distribution family F, which may not contain the distribution Ω. On the other hand, the distributions in F are
chosen from known families such as normal or piecewise uniform
families that are relatively easier to sample from. The cross-entropy
method due to Rubinstein and Kroese attempts to solve this problem in a systematic manner [33, 32].
Ω(~
x0 , ~v ) =

3.

Overview of Cross-Entropy Method

D EFINITION 3.1 (K ULLBACK -L IEBLER D IVERGENCE ). Let
us assume two distributions p(·) and q(·) over some set of support
S, such that ∀~
x ∈ S, p(~
x) 6= 0, q(~
x) 6= 0. The Kullback-Liebler
(KL) divergence is defined as

 


Z
p(x)
p(x)
p(x)dx = Ep log
,
D(p, q) =
log
q(x)
q(x)
S
wherein Ep denotes the expectation over the distribution p.
Note that the KL divergence is not a metric. In general, D(p, q) 6=
D(q, p). However, it can be shown that for all distributions p, q,
D(p, q) ≥ 0. Furthermore, D(p, q) = 0 iff p = q.
Our goal here is to choose a distribution pθ from the chosen family that minimizes the KL divergence D(Ω, pθ ) 2 . Since Ω is not
known in a closed form, it is not possible to evaluate D(Ω, pθ ) for a

CROSS-ENTROPY METHOD

In this section, we present a brief overview of the cross entropy method which is a widely used rare-event simulation technique. Further details including a theoretical analysis of crossentropy method are available elsewhere [32, 33, 6].

2

Note that this is not the same as minimizing D(pθ , Ω). The choice
of Ω as the first argument makes the minimization over samples
possible without knowing Ω in a closed form.

128

θ(h + 1) = λθ(h) + (1 − λ)θ0 (h) .
Updating rules for other families such as the Gaussian distributions and “natural exponential families” (NEF) are considered by
Rubinstein and Kroese [32].

(a) Draw a fixed number Ns according to pθ using the current set
of parameters θ = θ(h).

3.2

(b) Let ~
x(0) , . . . , ~x(Ns ) be the samples sorted in descending order
according to their Ω values.

(d) Obtain a new set of parameters θ(h + 1) by tilting. The new
parameter set θ(h+1) minimizes the empirically estimated KL
divergence D(Ω, pθ ) over the sample points ~
x(0) , . . . , ~
x(m−1) ,
for all θ ∈ P .
!
m−1 
x(i) ))Ω(~
x(i) )
1 X log(pθ (~
.
θ(h + 1) = argmin −
m i=0
pθ(h) (~
x(i) )
θ∈P

dG
dt
dX
dt
dI
dt

Termination is based upon some fixed convergence criterion. After termination, we sample extensively from the final distribution
θ(h + 1) to search for a possible violation.
Tilting: Given the distribution θ(h) ∈ P for the current iteration
and the sample points ~
x(0) , . . . , ~x(m−1) , we seek to minimize the
empirical KL divergence over the sample points
!
m−1 
x(i) ))Ω(~
x(i) )
1 X log(pθ (~
θ(h + 1) = argmin −
,
m i=0
pθ(h) (~
x(i) )
θ∈P

ϕ : ¬(2[0,20.0] (G ∈ [−2, 10]) ∧ 2[20,200.0] (G ∈ [−1, 1])) .

to obtain the parameters for the subsequent iteration. Writing γi =

Informally, ϕ specifies that the value of glucose should not be in
the range [−2, 10] during the first 20 minutes, or fail to remain the
range [−1, 1] over the next 180 minutes.
We ran a cross-entropy sampling guided by trace robustness to
search for a suitable input. Each signal u(t) is represented by a
spline with 4 control points. This yields 7 input parameters. The
range of permissible values for each input parameter is subdivided
into 10 equally spaced subintervals. Figure 3 shows the final results of applying the cross-entropy method for 25 iterations lasting
roughly 570 seconds. The technique does not find a falsifying input, it finds an input schedule that comes quite close yielding a
low robustness value of 0.3. Figure 3 plots the minimal robustness
trace. The run of cross-entropy method is illustrated by showing the
tilted probability distributions at iteration numbers 1, 5, . . . , 25.

we note that γi can be evaluated for each sample up to

some fixed but unknown positive scaling factor W . However, this
suffices to carry out the optimization for tilting. Simplifying, we
obtain
!
m−1
X
(i)
θ(h + 1) = argmax
γi log(pθ (~
x )) .
(1)
θ∈P

i=0

The result depends, in general, on the distribution family chosen. It
is relatively straightforward to solve for the optima above by computing partial derivatives w.r.t θ to obtain a closed form for standard families such as piecewise uniform and exponential distributions [32]. This yields an updating rule Θp for family p:
θ(h + 1) = Θp (θ(h), ~
x(0) , γ0 , . . . , ~x(m−1) , γm−1 ) .

= −p1 G − X(G + Gb ) + P (t)
= −p2 X + p3 I
= −n(I + Ib ) + u(t)/VI

wherein state variable G refers to the level of glucose in the blood
plasma above a fixed basal value Gb , I refers to the level of insulin
above a fixed basal value Ib and X is a quantity that is proportional
to the level of insulin that is effective in controlling blood glucose
level. The function P (t) refers to the addition of glucose in the
blood after digestion. Following Fisher, we set P (t) = ke−Bt
to model the characteristic peak and decay of the level of glucose
added to the blood during the digestion process. The input u(t)
refers to the insulin infused directly by means of a direct infusion
into the blood, wherein 0 ≤ u(t) ≤ 3 for all t ≥ 0.
Initial conditions are chosen from the intervals G(0) ∈ [6, 10],
X(0) ∈ [0.05, 0.1] and I(0) ∈ [−.1, .1]. We wish to find an initial
condition and a value of u(t) that falsifies the MTL property

The derivation of the formula above is shown elsewhere [32].

Ω(~
x )
,
pθ(h) (~
x(i) )

Illustrative Example

We now illustrate the operation of the cross-entropy method for
finding an appropriate insulin infusion schedule for controlling the
blood glucose level of a type II diabetic patient following the ingestion of a meal. The model and the parameters chosen have been
inspired by the work of Fisher [19]. The dynamics of insulin and
glucose in the patient are modeled by the ODE

(c) Choose the top m samples for some m  Ns .

(i)



1 if a ∈ S
In practice, the tilting is
0 otherwise
always performed gradually using a discount factor λ, by updating
wherein 1(a ∈ S) =

given θ. The idea is to adaptively search for suitable parameter values θ by performing the optimization over finitely many data points
obtained through sampling. Therefore, the cross-entropy method
proceeds by approximating D(Ω, pθ ) empirically from samples and
adaptively choosing values of θ. We start with some initial θ(0) ∈
P and iterate until some termination criterion.

(2)

4.
Updating Rules for Piecewise Uniform Distributions: Let us
assume that the input space X0 × V is partitioned into disjoint
cells C1 , . . . , Ck . Let ~
x(1) , . . . , ~x(m) be the samples chosen for
tilting. Our goal is to update the current values of the cell sampling
~
: (θh,1 , . . . , θh,k ) to yield new set of parameters
probabilities θ(h)
~
θ(h + 1) according to Eq. (2). This can be performed by setting the
partial derivatives with respect to each unknown parameter θh+1,j
to zero. The resulting update formula is given by
Pm−1
x(i) ∈ Cj )γi
i=0 1(~
,
θh+1,j =
Pm−1
i=0 γi

FACTORED INPUT DISTRIBUTIONS

In this section, we present some basic ideas on how families of
input distributions may be formed and represented for applying the
cross-entropy method for falsifying temporal properties. In general, there are two conflicting concerns that affect the choice of a
family of distributions: (a) the ability to represent arbitrary input
distributions to a good degree of approximation and (b) keeping
the number of parameters that describe the family small.
We focus on piecewise uniform distributions obtained by subdividing the input space into many disjoint cells C1 , . . . , CK . Let us
represent the vector of inputs in X0 × V ⊆ Rk by (z1 , . . . , zk ) ∈
Rk . We have assumed that the set of legal input values form a

129

(1)

(5)

(10)

(15)

(20)

(25)

Figure 3: Results of cross-entropy method for the insulin glucose model. (Left) plot showing the least robust simulation result.
(Right) Probability distributions over the various input subintervals at rounds 1, 5, . . . , 25.
optimal parameters θ∗ = (P1,1 , . . . , Pk,n ) such that
!
m−1
X
∗
(l)
θ = argmax
γl log(pθ (~
x ))

bounded box [a1 , b1 ]×[a2 , b2 ]×· · ·×[ak , bk ]. We partition the set
of possible values for each input variable zi ∈ [ai , bi ] into a fixed
number n > 0 different disjoint sub-intervals Ui,1 , . . . , Ui,n 3 .
This represents a partitioning of input space into nk rectangular
cells, wherein each cell Cj1 ,...,jk is a product of intervals U1,j1 ×
U2,j2 ×· · ·×Uk,jk . As a result, representing the piecewise uniform
distribution requires nk parameters, which is exponential in the dimensionality of the input vector. Therefore, we consider tradeoffs
in representing the family by means of factored distributions.

We may write log(pθ (~
x(l) )) as
log(pθ (~
x(l) )) =

n
X

Pi,j = 1 .

(l)

P ROOF. This lemma is a special case of the more general Lemma 4.2
for graphical models that will be presented subsequently.

The family of fully factored distributions are parameterized by
the values Pi,j for i ∈ [1, k] and j ∈ [1, n]. The probability of
choosing a cell Cj1 ,...,jk is assumed to be given by the product

One of the key advantages of a fully factored form of the input
distribution is that the number of parameters representing the family is simply k × n as opposed to nk . However, the assumption of
independent choice of intervals along each dimension diminishes
the ability to represent arbitrary probability distributions.

Pr(Cj1 ,...,jk ) = Πki=1 Pi,ji .
Once a cell is chosen using the discrete distribution defined above,
a point in the cell is chosen uniformly at random. In other words,
the choice of a cell is obtained by independently choosing intervals
for each input zi .
We will now derive the update rule for tilting using families of
fully factored piecewise uniform distributions by solving the optimization involved in Equation (1). Let ~
x(1) , . . . , ~x(m) be the m
samples used to compute the tilting. Furthermore, for each samW Ω(~
x(l) )
.
pθ(h) (~
x(l) )

log(Pi,j )1(~
xi ∈ Ui,j ) .

Lemma 4.1. The optimal value of parameters Pi,j that maximizes the objective in Equation (3) are given by
Pm−1
(l)
x ∈ Ui,j )
l 1(~
l=0 γ
Pm i
Pi,j =
.
l=1 γl

j=1

ple, we obtain the value γl =

k X
n
X
i=1 j=1

Fully Factored Distribution: A simple scheme for representing probability distributions over the cells is to associate a uniform
probability value Pi,j for each cell Ui,j for input zi and interval
Ui,j , such that
∀ i ∈ [1, k]

(3)

l=0

Example 4.1. Figure 4 shows a distribution over two inputs
z1 , z2 wherein there is a significant degree of correlation between
the choices of particular intervals for z1 and for z2 . A fully factored
representation loses this information to produce a poor approximation of this distribution. This situation presents interesting parallels
to the general problem of abstracting sets of states that is considered in techniques such as symbolic model checking and abstract
interpretation of systems.

Our goal is to compute

Graphical Model Factoring: An alternative to a fully factored
representation consists of maintaining correlations between some
of the input variables. In the setting of this paper, two inputs are

3

For simplicity, we assume that the number of subdivisions along
each dimension is the same.

130

Example 4.2. Figure 5 shows an example of a graphical model
along with the type of conditional probability table for each node.
The overall probability of drawing a sample from a cell in the input
space is written out as a product of individual probabilities from
each of the tables in the model according to Equation (4).
As a result, each graphical model G represents a family of piecewise uniform distributions parameterized by the entries in the tables associated with each node in the graph. The number of such
parameters is bounded by O(kn∆+1 ) wherein ∆ is the maximum
in-degree of any node in the graph. Consider an entry in a table of
the form shown in Eq. (4). The event associated with the entry is
denoted by the predicate:
zj ∈ Uj,i ∧ zj1 ∈ Uj1 ,i1 ∧ · · · ∧ zjl ∈ Ujl ,il .
Once again, we consider update rules for factored distributions
for solving the optimization involved in Equation 1. Let ~x(1) , . . . , ~x(m)
be the m samples used to compute the tilting with associated weights
γ1 , . . . , γm . Our goal is to compute optimal parameters θ∗ =
(P1 , . . . , PN ) where each entry Pi stands for some unknown table entry representing some conditional property in the graphical
model. Our goal once again is to optimize
!
m−1
X
∗
(l)
θ = argmax
γl log(pθ (~
x ))
(5)

Figure 4: A distribution that cannot be factored.

z1

z4

z2

z3

Node
z1
z2
z3
z4

Cond. Table Type
P (z1 ∈ U1,i )
P (z2 ∈ U2,i |z1 ∈ U1,i1 )



 z1 ∈ U1,i1 ,

P z3 ∈ U3,i 
z2 ∈ U2,i2
P (z4 ∈ U4,i )

l=0

The update rule for graphical models considers entries in a given
table Ti associated with a node zi , for i ∈ [1, k]. For parameter Pi,j , let ϕi,j denote the associated event. Furthermore, let
1(~x(l) |= ϕi,j ) denote the condition that the lth sample satisfies
the event associated with table entry Pi,j .

Figure 5: Example graphical model over 4 variables z1 , . . . , z4
along with the types of tables associated with each node.

correlated if, for the purposes of finding a falsifying input, the value
chosen of one variable will affect the choice of a value for the other.
Often, it is natural to consider correlations between certain classes
of inputs during falsification. For instance, the value of a control
input u at two adjacent time intervals can often be regarded as correlated. Depending on how input signals are parameterized, the
choice of an input for the next time step may need to take the current choice of input into consideration.
In this section, we consider generic graphical models that can
represent a factored probability distribution. Once again, we assume that the input space for input variable zi has been partitioned
into pairwise disjoint sub-intervals Ui,1 , . . . , Ui,n for i ∈ [1, k].
A graphical model G is a directed acyclic graph (DAG) with
nodes N = {z1 , . . . , zk }, one node for each variable and a set of
directed edges E ⊆ N × N . A graphical model represents a factored distribution. For each node zj , let {e1 : zj1 → zj , . . . , zjl →
zj } represent the set of all incoming edges into zj . We associate a
conditional probability table Tj that has entries of the form
P (zj ∈ Uj,i | zj1 ∈ Uj1 ,i1 ∧ · · · ∧ zjl ∈ Ujl ,il ),
for i, i1 , . . . , il ∈ [1, n]

Lemma 4.2. The optimal parameter value for parameter Pi,j
in table Ti that maximizes the objective in Equation (5) is given by
Pm−1
γl 1(~
x(l) |= ϕi,j )
.
Pi,j = Pm−1 Pl=0
x(l) |= ϕi,r )
l=0
r∈Entries(Ti ) γl 1(~
P ROOF. A proof of this theorem is given in the appendix.

(4)

Thus, each variable is associated with a table of conditional probabilities for the variable belonging to a sub-interval in its domain,
given a combination of choices of sub-intervals for the predecessors of the variable in the graph. The overall distribution is written
as a product of its factors:





 ^
z1 ∈ U1,l1

k
 = Π P zi ∈ Ui,li 
...
Pr 
zj ∈ Uj,lj  .

i=1
 zj →zi ∈E
zk ∈ Uk,lk
A fully factored distribution is simply a graphical model G with
the empty set of edges.

131

The lemma above shows that the updating rule for factored distributions is quite simple given the samples ~
x(l) and weights γl .
We now briefly comment on the choice of an appropriate graphical model for factoring the input. Often, the fully factored representation is the easiest to implement. As mentioned earlier, this
representation can be improved by tracking the joint distribution
between the value of parameters that pertain to an input signal at
the current time step to the input at the next time step. However,
decisions on other inputs may need to be considered jointly for successful falsification, in practice.
Currently, it is unclear as to how such inputs may be identified.
If, for instance, the function of the inputs to the system are well
understood, it may sometimes be possible to classify sets as inputs
as tightly coupled or otherwise. However, this requires detailed
knowledge of the system’s inner workings. In this regard, the problem of automatically identifying an ideal factoring of the input distribution for testing remains an open challenge.

5.

IMPLEMENTATION & EXPERIMENTAL
EVALUATION

We have implemented a prototype version of the techniques described thus far inside the S-Taliro framework for falsification of
MTL properties. S-Taliro is implemented as a Matlab toolbox and
supports the specification of a variety of system models including

Simulink/Stateflow diagrams, Matlab functions and C programs interfaced with Matlab. The latest version of the tool supports various
core primitives such as the specification of MTL formulas through
a simple, user-friendly interface, various utilities to simulate models and visualize trajectories, support for input parameterization,
ranging from piecewise constant inputs to splines obtained by specifying control points, and support for robustness metrics over both
continuous and hybrid traces. S-Taliro includes implementations of
various search heuristics for optimization including UR: uniform
random sampling and MC: Monte-Carlo sampling with simulated
annealing. A detailed description of the framework is available
elsewhere [3]. Furthermore, the latest version of the tool (along
with the benchmarks used here) are available on-line as a opensource tool4 .
The implementation of the cross entropy method inside S-Taliro
directly uses the key primitives implemented inside S-Taliro. Currently, our implementation supports piecewise uniform probability
distributions in a fully factored form. Support for graphical models
is currently being implemented.

form of random walks over the state space of the system and by our
previous work in the form of input sampling using Markov-Chain
Monte-Carlo (MCMC) techniques [34, 28]. The techniques presented in the latter work were implemented as part of the S-Taliro
framework [3]. The two approaches are quite distinct from each
other. In practice, the rate convergence of random walks on the
state space depends critically on the topology of the state transition
graph. On the other hand, techniques that walk the state space can
be extended readily to the case of systems with control inputs without requiring a finite parameterization of the control. The problem
of integrating the two approaches remains a challenge.
In practice, the use of MCMC techniques has proven problematic for certain benchmarks due to the slow rate of convergence of
MCMC techniques and their susceptibility to local minima in the
search space. This has been instrumental in our quest for efficient
stochastic search techniques that can exhibit faster convergence to
the desired underlying distribution. We have also explored the use
of other optimization techniques including ant-colony optimization
(ACO) and genetic algorithms (GA) in conjunction with robustness
metrics in the S-Taliro framework [2].
Other approaches to testing hybrid systems have focused on the
use of state-space exploration techniques such as Rapidly exploring Random Trees (RRTs) [16, 4, 5, 27, 29] as well as notions of
robustness over simulation trajectories [14, 20, 22, 25]. The work
of Dang et al. attempts to bridge these approaches [13].
On the research front of falsification/verification of temporal logic
properties through testing, the results are limited [30, 31, 17]. The
work that is the closest to ours appears in [31]. The authors of
that work develop a different notion of robustness for temporal
logic specifications, which is also used as a fitness function for
optimization problems. Besides the differences in the application
domain, i.e., [31] focuses on parameter estimation for biological
systems, whereas our paper deals with the falsification of hybrid
systems. Furthermore, we have extended robustness metrics from
purely continuous to hybrid trajectories, wherein we define robustness of trajectories using quasi-metrics instead of metrics [28].
Younes and Simmons, and more recently, Clarke et al. have proposed the technique of Statistical Model Checking (SMC) [36, 10],
which generates uniform random inputs to a system subject to some
constraints, thus converting a given system into a stochastic system.
A probabilistic model checker can be used to prove assertions on
the probability that the system satisfies a given temporal property
ϕ within some given confidence interval. Statistical model checking, like our technique, requires a simulator to be available for the
system but not a transition relation representation. In contrast to
SMC, our approach is guided by a robustness metric towards less
robust trajectories. On the other hand, the complex nature of the
system and the robustness metrics imply that we cannot yet provide guarantees on the probability of satisfaction of the formula.
Recent observations by Clarke and Zuliani have noted the need for
importance sampling and rare-event simulation techniques for Statistical model checking [11]. Some of the ideas from this work
on the use of factored input distributions and graphical models can
also benefit statistical model checkers.
The work of Chockler et al. explores the use of the cross-entropy
method for finding bugs in concurrent programs [7] and more recently for reconstructing concurrent executions for program replay [8].
Additionally, the use of cross-entropy method as a general combinatorial state-space search technique has been well-studied 5 .

Experimental Evaluation: Table 2 briefly describes the benchmarks used in our evaluation along with the properties checked for
these benchmarks. These benchmarks along with a detailed explanation of the properties are available as part of the S-Taliro distribution. Furthermore, more detailed and up-to-date data comparing the various solvers on a larger set of benchmarks will be made
available on our tool website.
Experimental Results: Table 3 shows the experimental comparisons over the set of benchmarks described in Table 2. We ran a
fixed number of repetitions for each benchmark and property. Each
run had a limit on the total number of tests (simulations) permitted
as indicated in the table. The cross entropy method was applied for
the maximum number of iterations that corresponds to 100 simulations per iteration. Each technique terminates upon encountering
a falsification. Due to the sheer size and number of these experiments, we ran them on a cluster with many different machines of
roughly similar specifications — Intel machines running 64 bit operating systems with 6 − 12 cores and 6 − 32 GB of RAM. To
facilitate comparison, we run all instances of each benchmark on
the same machine (different cores).
Table 3 reports for each benchmark instance, the number of repetitions that resulted in a falsification and the average, minimum and
maximum times. We notice from this comparison that the cross entropy method performed quite well on the IG, Mod and Air benchmarks, resulting in the most amount of falsifications and was competitive on the remaining AT and PT benchmarks, wherein there
were no clear winners between the three techniques compared. The
cross entropy seems to outperform Monte Carlo simulations both in
terms of time and number of falsifications on all but a few of the
benchmarks, and is often competitive or better than uniform random testing which has negligible overhead.

6.

RELATED WORK

It is well known that falsification of temporal logic properties for
hybrid systems is a hard problem [1]. As a result, testing is a natural
approach to the verification of continuous and hybrid systems [23].
The question of how to guide the choice of test cases better is an
active area of research.
In this regard, Monte-Carlo techniques have been explored quite
extensively. The use of Monte Carlo techniques for model checking was considered previously by Grosu and Smolka [21] in the
4

5
Cf. Rubinstein et al. [32] and the web site http://www.
cemethod.org for a description.

https://sites.google.com/a/asu.edu/s-taliro

132

Name
Mod1-3
IG1-3
AT1
AT2
AT3-5
PT1
PT2
Air1
Air2
Air3
Air4
Air5

7.

Table 2: Benchmark systems and properties used in our evaluation.
Description
Model Type
Property Type
Third order Delta-Sigma Modulator [12] S/S diagram
2a
with varying initial conditions
Insulin Glucose control (Cf. Section 3.2) ODE (matlab function) 2[0,20.0] p ∧ 2[20,200.0] q
with varying initial conditions
Auto Transmission Simulink demo [37]
S/S diagram
¬(3p1 ∧ 3[0,10] p3 )
¬(3(p1 ∧ 3[0,7.5] p3 ))
different predicates qi,j
¬(3q1,i ∧ 3q2,i ∧ 3q3,i )
Power train model [9]
Checkmate model [35] ¬3(g2 ∧ 3(g1 ∧ 3g2 ))
2((¬g1 ∧ Xg1 ) ⇒ 2[0,2.5] ¬g2 )
Aircraft model [26]
ODE (matlab function) ¬(2[.5,1.5] a ∧ 3[3,4] b)
¬(2[0,4] a ∧ 3[3.5,4] d)
¬3[1,3] e
¬2[0,.5] h
¬2[2,2.5] i

CONCLUSION

ACKNOWLEDGEMENTS

The authors would like to thank the anonymous reviewers for
their detailed comments. This work was supported, in part, by NSF
awards CNS-1016994, CPS-1035845 and CNS-1017074.

9.

1000
1000
1000
1000
1000
1000
500
1000
2000
2500
2500

[7] H. Chockler, E. Farchi, B. Godlin, and S. Novikov.
Cross-entropy based testing. In FMCAD, pages 101–108.
IEEE Computer Society, 2007.
[8] H. Chockler, E. Farchi, B. Godlin, and S. Novikov.
Cross-entropy-based replay of concurrent programs. In
Fundamental Approaches to Software Engineering, volume
5503 of LNCS, pages 201–215. Springer, 2009.
[9] A. Chutinan and K. R. Butts. Dynamic analysis of hybrid
system models for design validation. Technical report, Ford
Motor Company, 2002.
[10] E. Clarke, A. Donze, and A. Legay. Statistical model
checking of analog mixed-signal circuits with an application
to a third order δ − σ modulator. In Hardware and Software:
Verification and Testing, volume 5394/2009 of LNCS, pages
149–163, 2009.
[11] E. M. Clarke and P. Zuliani. Statistical model checking for
cyber-physical systems. In ATVA, volume 6996 of LNCS,
pages 1–12. Springer, 2011.
[12] T. Dang, A. Donzé, and O. Maler. Verification of analog and
mixed-signal circuits using hybrid system techniques. In
ICFEM, volume 3142 of LNCS, pages 97–109. Springer,
2004.
[13] T. Dang, A. Donze, O. Maler, and N. Shalev. Sensitive
state-space exploration. In Proc. of the 47th IEEE CDC,
pages 4049–4054, Dec. 2008.
[14] A. Donzé and O. Maler. Systematic simulation using
sensitivity analysis. In HSCC, volume 4416 of LNCS, pages
174–189. Springer, 2007.
[15] M. Egerstedt and C. Martin. Control Theoretic Splines:
Optimal Control, Statistics, and Path Planning. Princeton
University Press, 2009.
[16] J. M. Esposito, J. Kim, and V. Kumar. Adaptive RRTs for
validating hybrid robotic control systems. In Proceedings of
the International Workshop on the Algorithmic Foundations
of Robotics, 2004.
[17] G. Fainekos, A. Girard, and G. J. Pappas. Temporal logic
verification using simulation. In FORMATS, volume 4202 of
LNCS, pages 171–186. Springer, 2006.
[18] G. Fainekos and G. Pappas. Robustness of temporal logic
specifications for continuous-time signals. Theoretical
Computer Science, 410(42):4262–4291, 2009.

In conclusion, we have presented a framework for falsification of
temporal logic properties using the Cross-Entropy method guided
by a notion of robustness of trajectories w.r.t MTL formulae. We
have also presented some ideas behind using factored probability
distributions in the cross-entropy method and extended our notions
to handle distributions factored using graphical models. Experimental results seem quite promising. In the future, we wish to run
further experiments to quantify the effect of factoring on the overall
performance. Furthermore, the problem of automatically identifying correlated input variables that can jointly influence the falsification remains to be investigated. Finally, we also wish to consider
the application of our ideas to more general classes of distributions.

8.

Tests
1000

REFERENCES

[1] R. Alur, C. Courcoubetis, N. Halbwachs, T. A. Henzinger,
P.-H. Ho, X. Nicollin, A. Olivero, J. Sifakis, and S. Yovine.
The algorithmic analysis of hybrid systems. Theoretical
Computer Science, 138(1):3–34, 1995.
[2] Y. S. R. Annapureddy and G. E. Fainekos. Ant colonies for
temporal logic falsification of hybrid systems. In Proc. IEEE
Industrial Electronics, pages 91 – 96, 2010.
[3] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and
S. Sankaranarayanan. S-taliro: A tool for temporal logic
falsification for hybrid systems. In TACAS, volume 6605 of
LNCS, pages 254–257. Springer, 2011.
[4] A. Bhatia and E. Frazzoli. Incremental search methods for
reachability analysis of continuous and hybrid systems. In
HSCC, volume 2993 of LNCS, pages 142–156. Springer,
2004.
[5] M. Branicky, M. Curtiss, J. Levine, and S. Morgan.
Sampling-based planning, control and verification of hybrid
systems. IEE Proc.-Control Theory Appl., 153(5):575–590,
2006.
[6] J. A. Bucklew. Introduction to Rare-Event Simulations.
Springer, 2004.

133

Table 3: Experimental comparison of the cross-entropy method with other optimization engines available in S-Taliro. Experiments
were run on a variety of machines in a cluster. To enable comparison, each row is executed on different cores of the same machine.
All timings are in seconds, rounded to the nearest integer. Note: MC run on PT2 did not finish after many days (dnf). Legend: #F:
number of falsifying runs, av: average, lb: min, ub: max, #Rnds: number of iterations for CE.
Bench.

# Runs
#F

IG1
IG2
IG3
Mod1
Mod2
Mod3
AT1
AT2
AT3
AT4
AT5
PT1
PT2
Air1
Air2
Air3
Air4
Air5

25
25
25
100
100
100
100
100
100
100
100
25
25
100
100
100
100
100

25
25
25
97
87
13
36
0
99
97
0
25
24
100
100
99
100
100

Cross Entropy (CE)
Time
#Rnds
(av,lb,ub)
(lb,ub)
47,[3,91]
[1,4]
65,[20,124]
[1,6]
141,[81,286]
[3,7]
15,[1,43]
[1,10]
25,[1,43]
[1,10]
41,[0,50]
[1,10]
102,[43,116]
[5,10]
111,[97,114]
[10,10]
34,[0,114]
[1,10]
53,[1,116]
[1,10]
111,[98,121]
[10,10]
170,[7,886]
[1,2]
1013,[32,6381] [1,10]
8,[0,29]
[1,1]
134,[3,386]
[1,9]
316,[120,984]
[3,20]
2,[0,10]
[1,1]
10,[0,53]
[1,1]

[19] M. E. Fisher. A semiclosed-loop algorithm for the control of
blood glucose levels in diabetics. IEEE transactions on
bio-medical engineering, 38(1):57–61, 1991.
[20] A. Girard and G. J. Pappas. Verification using simulation. In
HSCC, volume 3927 of LNCS, pages 272 – 286. Springer,
2006.
[21] R. Grosu and S. Smolka. Monte carlo model checking. In
TACAS, volume 3440 of LNCS, pages 271–286, 2005.
[22] A. A. Julius, G. E. Fainekos, M. Anand, I. Lee, and G. J.
Pappas. Robust test generation and coverage for hybrid
systems. In HSCC, number 4416 in LNCS, pages 329–342.
Springer, 2007.
[23] J. Kapinski, B. H. Krogh, O. Maler, and O. Stursberg. On
systematic simulation of open continuous systems. In HSCC,
volume 2623 of LNCS, pages 283–297. Springer, 2003.
[24] R. Koymans. Specifying real-time properties with metric
temporal logic. Real-Time Systems, 2(4):255–299, 1990.
[25] F. Lerda, J. Kapinski, E. M. Clarke, and B. H. Krogh.
Verification of supervisory control software using state
proximity and merging. In HSCC, volume 4981 of LNCS,
pages 344–357. Springer, 2008.
[26] J. Lygeros. On reachability and minimum cost optimal
control. Automatica, 40:917–927, 2004.
[27] T. Nahhal and T. Dang. Test coverage for continuous and
hybrid systems. In CAV, volume 4590 of LNCS, pages
449–462. Springer, 2007.
[28] T. Nghiem, S. Sankaranarayanan, G. E. Fainekos, F. Ivančić,
A. Gupta, and G. J. Pappas. Monte-carlo techniques for
falsification of temporal properties of non-linear hybrid
systems. In HSCC, pages 211–220. ACM Press, 2010.
[29] E. Plaku, L. E. Kavraki, and M. Y. Vardi. Hybrid systems:
From verification to falsification. In CAV, volume 4590 of
LNCS, pages 463–476. Springer, 2007.

Monte Carlo (MC)
#F
Time
(av,lb,ub)
2
299,[3,443]
0
257,[209,317]
0
270,[184,324]
84
11,[0,92]
58
16,[0,94]
21
61,[6,94]
51
61,[7,94]
0
93,[92,93]
93
24,[0,138]
94
25,[0,128]
0
115,[110,139]
23
754,[14,7630]
dnf
dnf
100
43,[1,177]
100
68,[6,244]
78
511,[50,1290]
100
54,[0,233]
100
77,[0,256]

Unif. Rand. (UR)
#F
Time
(av,lb,ub)
20
103,[1,275]
17
156,[25,279]
4
256,[33,298]
81
19,[0,43]
40
28,[0,38]
1
37,[5,44]
0
94,[93,99]
0
93,[92,93]
86
56,[0,139]
55
81,[1,127]
0
111,[109,115]
25
99,[14,329]
25 689,[21,2392]
100
10,[1,296]
69
345,[1,612]
3
1030,[7,1244]
100
5,[0,77]
100
12,[0,57]

[30] E. Plaku, L. E. Kavraki, and M. Y. Vardi. Falsification of
LTL safety properties in hybrid systems. In TACAS, volume
5505 of LNCS, pages 368 – 382, 2009.
[31] A. Rizk, G. Batt, F. Fages, and S. Soliman. On a continuous
degree of satisfaction of temporal logic formulae with
applications to systems biology. In 6th International
Conference on Computational Methods in Systems Biology,
number 5307 in LNCS, pages 251–268. Springer, 2008.
[32] R. Y. Rubinstein and D. P. Kroese. The Cross-Entropy
Method: An unified approach to combinatorial optimization,
Monte-Carlo Simulation and Machine Learning.
Springer–Verlag, 2004.
[33] R. Y. Rubinstein and D. P. Kroese. Simulation and the Monte
Carlo Method. Wiley Series in Probability and Mathematical
Statistics, 2008.
[34] S. Sankaranarayanan, R. M. Chang, G. Jiang, and F. Ivančić.
State space exploration using feedback constraint generation
and Monte-Carlo sampling. In ESEC/SIGSOFT FSE, pages
321–330. ACM, 2007.
[35] B. I. Silva, K. Richeson, B. H. Krogh, and A. Chutinan.
Modeling and verification of hybrid dynamical system using
checkmate. In ADPM 2000, 2000.
[36] H. L. S. Younes and R. G. Simmons. Statistical
probabilitistic model checking with a focus on time-bounded
properties. Information & Computation, 204(9):1368–1409,
2006.
[37] Q. Zhao, B. H. Krogh, and P. Hubbard. Generating test
inputs for embedded control systems. IEEE Control Systems
Magazine, pages 49–57, August 2003.

134

2012 IEEE/RSJ International Conference on
Intelligent Robots and Systems
October 7-12, 2012. Vilamoura, Algarve, Portugal

Approximate Solutions for the Minimal Revision Problem of
Specification Automata
Kangjin Kim and Georgios E. Fainekos
Then, the user would be able to understand what are the
limitations of the robot and, also, he/she would be able to
choose among a number of possible feasible plans.
In [15], we made the first steps towards solving the
debugging (i.e., why the planning failed) and revision (i.e.,
what the robot can actually do) problems for automata
theoretic LTL planning [16]. We remark that many robotic
applications, e.g., [4], [6], [10]–[12], [14], are utilizing this
particular method. In the follow-up paper [17], we studied the
theoretical foundations of the specification revision problem
when both the system and the specification can be represented by ω-automata [18]. We focused on the Minimal Revision Problem (MRP), i.e., finding the “closest” satisfiable
specification to the initial specification, and we proved that
the problem is NP-complete even when severely restricting
the search space. Furthermore, we presented an encoding
of MRP as a satisfiability problem and we demonstrated
experimentally that we can quickly get the exact solution
to MRP for small problem instances.
In this paper, we revisit the MRP problem that we
introduced in [17]. We present a heuristic algorithm that
can approximately solve the MRP problem in polynomial
time. We prove that our algorithm is a 2-approximation
algorithm. We experimentally establish that the heuristic
algorithm always returns the optimal solution on random
problem instances and on LTL planning scenarios from our
previous work. Furthermore, we demonstrate that now we
can quickly return a solution to the MRP problem on large
problem instances. Finally, we provide examples where the
algorithm is guaranteed not to return the optimal solution.
Related Research: The automatic specification revision
problem for automata based planning techniques is a relatively new problem. Finding out why a specification is not
satisfiable on a model is a problem that is very related to
the problems of vacuity and coverage in model checking
[19]. In the context of general planners, the problem of
finding good excuses on why the planning failed has been
studied in [20]. Another related problem is the detection of
the causes of unrealizability in LTL games. In this case, a
number of heuristics have been developed in order to localize
the error and provide meaningful information to the user
for debugging [21], [22]. Along these lines, LTLMop [23]
was developed to debug unrealizable LTL specifications in
reactive planning for robotic applications.

Abstract— As robots are being integrated into our daily
lives, it becomes necessary to provide guarantees of safe and
provably correct operation. Such guarantees can be provided
using automata theoretic task and mission planning where the
requirements are expressed as temporal logic specifications.
However, in real-life scenarios, it is to be expected that not all
user task requirements can be realized by the robot. In such
cases, the robot must provide feedback to the user on why it
cannot accomplish a given task. Moreover, the robot should
indicate what tasks it can accomplish which are as “close”
as possible to the initial user intent. Unfortunately, the latter
problem, which is referred to as minimal specification revision
problem, is NP complete. This paper presents an approximation
algorithm that can compute good approximations to the minimal revision problem in polynomial time. The experimental
study of the algorithm demonstrates that in most problem
instances the heuristic algorithm actually returns the optimal
solution. Finally, some cases where the algorithm does not
return the optimal solution are presented.

I. I NTRODUCTION
As robots become mechanically more capable, they are
going to be more and more integrated into our daily lives.
Non-expert users will have to communicate with the robots
in a natural language setting and request a robot or a team of
robots to accomplish complicated tasks. Therefore, we need
methods that can capture the high-level user requirements,
solve the planning problem and map the solution to low level
continuous control actions. In addition, such frameworks
must come with mathematical guarantees of safe and correct
operation for the whole system and not just the high level
planning or the low level continuous control.
Linear Temporal Logic (LTL) [1] can provide the mathematical framework that can bridge the gap between (i) natural
language and high-level planning algorithms [2], [3], and
(ii) high-level planning algorithms and control [4]–[8]. LTL
has been utilized as a specification language in a range of
robotics applications (see [4]–[14]).
All the previous methods are based on the assumption that
the LTL planning problem has a feasible solution. However,
in real-life scenarios, it is to be expected that not all complex
task requirements can be realized by a robot or a team of
robots. In such failure cases, the robot needs to provide
feedback to the non-expert user on why the specification
failed. Furthermore, it would be desirable that the robot
proposes a number of plans that can be realized by the robot
and which are as “close” as possible to the initial user intent.

II. P ROBLEM F ORMULATION

This work has been partially supported by award NSF CNS 1116136.
K. Kim and G. Fainekos are with the School of Computing, Informatics
and Decision Systems Engineering, Arizona State University, Tempe, AZ
85281, USA {Kangjin.Kim,fainekos}@asu.edu

978-1-4673-1736-8/12/S31.00 ©2012 IEEE

In this paper, we work with discrete abstractions (Finite
State Machines) of the continuous robotic control system [4].
265

Each state of the Finite State Machine (FSM) T is labeled
by a number of symbols from a set Π = {π0 , π1 , . . . , πn }
that represent regions in the configuration space [24] of the
robot or, more generally, actions that can be performed by
the robot. The control requirements for such a system can be
posed using specification automata B with Büchi acceptance
conditions [18] also known as ω-automata.
When a specification B is not satisfiable on a particular
system T , then the current motion planning and control
synthesis methods, e.g., [4], [10], [14], based on automata
theoretic concepts [16] simply return that the specification is
not satisfiable without any other user feedback. In such cases,
we would like to be able to solve the following problem and
provide feedback to the user.
Problem 1 (Minimal Revision Problem (MRP)): Given a
system T and a specification automaton B, if the specification B cannot be satisfied on T , then find the “closest”
specification B ′ to B which can be satisfied on T .
Problem 1 was first introduced in [15] for Linear Temporal
Logic (LTL) specifications. In [15], we provided solutions to
the debugging and (not minimal) revision problems and we
demonstrated that we can easily get a minimal revision of
the specification when the discrete controller synthesis phase
fails due to unreachable states in the system.
Assumption 1: All the states on T are reachable.
In [17], we introduced a notion of distance on a restricted
space of specification automata and, then, we demonstrated
that MRP is in NP-complete. Since brute force search is
prohibitive for any reasonably sized problem, we presented
an encoding of MRP as a satisfiability problem. Nevertheless,
even when utilizing state of the art satisfiability solvers, the
size of the systems that we could handle remained small
(single robot scenarios in medium complexity environments).
Contributions: In this paper, we provide an approximation algorithm for MRP. The algorithm is based on Dijkstra’s
single-source shortest path algorithm (DSPA) [25], which
can be regarded both as a greedy and a dynamic programming algorithm [26]. We prove that our algorithm is a 2approximation algorithm. We demonstrate through numerical
experiments that not only the algorithm returns an optimal
solution in various scenarios, but also that it outperforms in
computation time our satisfiability based solution.

is the transition relation; and, hT : Q → P(Π) maps each
state q to the set of atomic propositions that are true on q.
We define a path on the FSM to be a sequence of states
and a trace to be the corresponding sequence of sets of
propositions. Formally, a path is a function p : N → Q
such that for each i ∈ N we have p(i) →T p(i + 1)
and the corresponding trace is the function composition
p̄ = hT ◦ p : N → P(Π). The language L(T ) of T consists
of all possible traces.
In this work, we are interested in the ω-automata that will
impose certain requirements on the traces of T . ω-automata
differ from the classic finite automata in that they accept
infinite strings (traces of T in our case).
Definition 2: A automaton is a tuple B
=
B
(SB , sB
0 , Ω, δB , FB ) where: SB is a finite set of states; s0 is
the initial state; Ω is an input alphabet; δB : SB ×Ω → P(SB )
is a transition function; and FB ⊆ SB is a set of final states.
l
When s′ ∈ δB (s, l), we also write s →B s′ or
′
(s, l, s ) ∈→B . A run r of B is a sequence of states r :
N → SB that occurs under an input trace p̄ taking values in
Ω. That is, for i = 0 we have r(0) = sB
0 and for all i ≥ 0 we
p̄(i)

have r(i) → B r(i+1). Let lim(·) be the function that returns
the set of states that are encountered infinitely often in the
run r of B. Then, a run r of an automaton B over an infinite
trace p̄ is accepting if and only if lim(r) ∩ FB 6= ∅. This is
called a Büchi acceptance condition. Finally, we define the
language L(B) of B to be the set of all traces p̄ that have a
run that is accepted by B.
A specification automaton is an automaton with Büchi acceptance condition where the input alphabet is the powerset
of the labels of the system T , i.e., Ω = P(Π). In order to
simplify the discussion in Section III-B, we will be using the
following assumptions and notation
•

•

we define the set EB ⊆ SB ×SB , such that (s, s′ ) ∈ EB
l
iff ∃l ∈ Ω , s →B s′ ; and,
we define the function λB : SB ×SB → Ω which maps a
pair of states to the label of the corresponding transition,
l
i.e., if s →B s′ , then λB (s, s′ ) = l; and if (s, s′ ) 6∈ EB ,
then λB (s, s′ ) = ∅.

In brief, our goal is to generate paths on T that satisfy
the specification Bs . In automata theoretic terms, we want to
find the subset of the language L(T ) which also belongs to
the language L(Bs ). This subset is simply the intersection of
the two languages L(T ) ∩ L(Bs ) and it can be constructed
by taking the product T × Bs of the FSM T and the
specification automaton Bs . Informally, the automaton Bs
restricts the behavior of the system T by permitting only
certain acceptable transitions. Then, given an initial state
in the FSM T , we can choose a particular trace from
L(T ) ∩ L(Bs ) according to a preferred criterion.
Definition 3: The product automaton A = T × Bs is the
automaton A = (SA , sA
0 , P(Π), δA , FA ) where: SA = Q ×
Bs
SBs ; s A
)
|
q
=
{(q
,
s
0 ∈ Q0 }; δA : SA ×P(Π) → P(SA )
0 0
0
s.t. (qj , sj ) ∈ δA ((qi , si ), l) iff qi →T qj and sj ∈ δBs (si , l)
with l ⊆ hT (qj ); FA = Q × F is the set of accepting states.

III. P RELIMINARIES
In this section, we review basic results from [4], [15]–
[17]. In detail, we provide a review of the automata theoretic planning and the specification revision problem. Our
contributions in Section IV will be founded on these results.
A. Constructing Discrete Controllers
We assume that the combined actions of the robot/team of
robots and their operating environment can be represented
using an FSM.
Definition 1 (FSM): A Finite State Machine is a tuple
T = (Q, Q0 , →T , hT , Π) where: Q is a set of states;
Q0 ⊆ Q is the set of possible initial states; →T = E ⊆ Q×Q
266

minimal relaxations of some Bs , but B1 k B2 and, moreover,
B1 requires the modification of only one transition while B2
requires the modification of two transitions. Therefore, we
must define a metric on the set R(Bs , T ), which accounts
for the number of changes from the initial specification
automaton Bs .
Definition 6: Given a system T and a specification automaton Bs , we define the distance
P of any B ∈ R(Bs′, T )
from Bs to be distBs (B) =
(s,s′ )∈EBs |λBs (s, s ) −
λB (s, s′ )| where | · | is the cardinality of the set.
Therefore, Problem 1 can be restated as:
Problem 2: Given a system T and a specification automaton Bs such that L(T × Bs ) = ∅, find B ∈
arg min{distBs (B ′ ) | B ′ ∈ R(Bs , T )}.

Note that L(A) = L(T ) ∩ L(Bs ). We say that Bs is
satisfiable on T if L(A) 6= ∅. Moreover, finding a satisfying
path on T × Bs is an easy algorithmic problem [1]. First, we
convert automaton T × Bs to a directed graph and, then, we
find the strongly connected components (SCC) in that graph.
If at least one SCC that contains a final state is reachable
from an initial state, then there exist accepting (infinite) runs
on T × Bs that have a finite representation. Each such run
consists of two parts: prefix: a part that is executed only
once (from an initial state to a final state) and, lasso: a part
that is repeated infinitely (from a final state back to itself).
Note that if no final state is reachable from the initial or if no
final state is within an SCC, then the language L(A) is empty
and, hence, the high level synthesis problem does not have
a solution. Namely, the synthesis phase has failed and we
cannot find a system behavior that satisfies the specification.

C. Minimal Revision as a Graph Problem
In order to solve Problem 2, we construct a directed
labeled graph GA from the product automaton A = T × Bs .
The edges of GA are labeled by a set of atomic propositions
which if removed from the corresponding transition on Bs ,
they will enable the transition on A. The overall problem
then becomes one of finding the least number of atomic
propositions to be removed in order for the product graph to
have an accepting run. Next, we provide the formal definition
of the graph GA which corresponds to a product automaton
A while considering the effect of revisions.
Definition 7: Given a system T and a specification automaton Bs , we define the graph GA = (V, E, vs , Vf , Π, Λ),
which corresponds to the product A = T × Bs as follows:
V = S is the set of nodes; E = EA ∪ED ⊆ S×S, where EA
is the set of edges that correspond to transitions on A, i.e.,
l
((q, s), (q ′ , s′ )) ∈ EA iff ∃l ∈ P(Π) . (q, s) →A (q ′ , s′ ); and
ED is the set of edges that correspond to disabled transitions,
l
i.e., ((q, s), (q ′ , s′ )) ∈ ED iff q →T q ′ and s →Bs s′ with
′
A
l ∩ (Π − hT (q )) 6= ∅; vs = s0 is the source node; Vf = FA
is the set of sinks; Π = {hπ, (s, s′ )i | π ∈ Π, (s, s′ ) ∈ EBs };
Λ : E → P(Π) is the edge labeling function such that
if e = ((q, s), (q ′ , s′ )), then Λ(e) = {hπ, (s, s′ )i | π ∈
(λBs (s, s′ ) − hT (q ′ ))}.
If Λ(e) 6= ∅, then it specifies those atomic propositions in
λBs (s, s′ ) that need to be removed to enable the edge in the
product state. Note that the labels of the edges of GA are
subsets of Π rather than Π. This is due to the fact that we
are looking into removing an atomic proposition π from a
specific transition (s, l, s′ ) of Bs rather than all π in Bs .

B. The Specification Revision Problem
Intuitively, a revised specification is one that can be
satisfied on the discrete abstraction of the workspace or the
configuration space of the robot. To search for a minimal
revision, we define an ordering relation on automata as well
as a distance function between automata. Similar to the case
of LTL formulas in [15], we do not want to consider the
“space” of all possible Büchi automata, but rather the “space”
of specification automata which are semantically close to the
initial specification automaton Bs . The later will imply that
we remain close to the initial intention of the designer. We
propose that this space consists of all the automata that can
be derived from Bs by removing atomic propositions from
the transition input. Our definition of the ordering relation
between automata relies on the previous assumption.
1
Definition 4 (Relaxation): Let B1 = (SB1 , sB
0 , Ω, →B1 ,
B2
FB1 ) and B2 = (SB2 , s0 , Ω, →B2 , FB2 ) be two Büchi
automata. Then, we say that B2 is a relaxation of B1 and we
B2
1
write B1  B2 if and only if SB1 = SB2 = S, sB
0 = s0 ,
FB1 = FB2 and
1) ∀(s, l, s′ ) ∈→B1 − →B2 . ∃l′ .
(s, l′ , s′ ) ∈→B2 − →B1 and l′ ⊆ l.
2) ∀(s, l, s′ ) ∈→B2 − →B1 . ∃l′ .
(s, l′ , s′ ) ∈→B1 − →B2 and l ⊆ l′ .
We remark that if B1  B2 , then L(B1 ) ⊆ L(B2 ) since
the relaxed automaton allows more behaviors to occur. If two
automata B1 and B2 cannot be compared under relation ,
then we write B1 k B2 .
We can now define the set of automata over which we will
search for a minimal solution that has nonempty intersection
with the system.
Definition 5: Given a system T and a specification automaton Bs , the set of valid relaxations of Bs is defined as
R(Bs , T ) = {B | Bs  B and L(T × B) 6= ∅}.
We can now search for a minimal solution in the set
R(Bs , T ). That is, we can search for some B ∈ R(Bs , T )
such that if for any other B ′ ∈ R(Bs , T ), we have B ′  B,
then L(B) = L(B ′ ). However, this does not imply that
a minimal solution semantically is minimal structurally as
well. In other words, it could be the case that B1 and B2 are

IV. A N A PPROXIMATION A LGORITHM FOR MRP
In this section, we present an approximation algorithm
(AAMRP) for the Minimal Revision Problem (MRP). It is
based on Dijkstra’s shortest path algorithm (DSPA) [25]. The
main difference from DSPA is that instead of finding the
minimum weight path to reach each node, AAMRP tracks
the number of atomic propositions that must be removed
from each edge on the paths of the graph GA .
The pseudocode for the AAMRP is presented in Algorithms 1 and 2. The main algorithm (Alg. 1) divides the problem into two tasks. First, in line 5, it finds an approximation
267

Algorithm 1 AAMRP

Algorithm 2 F IND M IN PATH

Inputs: a graph GA = (V, E, vs , Vf , Π, Λ).
Outputs: the list L of atomic propositions form Π that must
be removed Bs .
1: procedure AAMRP(GA )
2:
L←Π
3:
M[:, :] ← (Π, ∞)
⊲ Each entry is set to (Π, ∞)
4:
M[vs , :] ← (∅, 0)
⊲ Initialize the source node
5:
hM, P, Vi ← F IND M IN PATH(GA , M, 0)
6:
if V ∩ Vf = ∅ then
7:
L←∅
8:
else
9:
for vf ∈ V ∩ Vf do
10:
Lp ← G ETAPF ROM PATH(vs , vf , M, P)
11:
M′ [:, :] ← (Π, ∞)
12:
M′ [vf , :] ← M[vf , :]
13:
G′A ← (V, E, vf , {vf }, Π, L)
14:
hM′ , P′ , V ′ i ← F IND M IN PATH(G′A , M′ , 1)
15:
if vf ∈ V ′ then
16:
Ll ← G ETAPF ROM PATH(vf , vf , M′ , P′ )
17:
if |Lp ∪ Ll | ≤ |L| then
18:
L ← Lp ∪ Ll
19:
end if
20:
end if
21:
end for
22:
end if
23:
return L
24: end procedure
The function G ETAPF ROM PATH((vs , vf , M, P)) returns the
atomic propositions that must be removed from Bs in order
to enable a path on A from a starting state vs to a final state
vf given the tables M and P.

Inputs: a graph GA = (V, E, vs , Vf , Π, Λ), a table M and
a flag lasso on whether this is a lasso path search.
Variables: a queue Q, a set V of visited nodes and a table
P indicating the parent of each node on a path.
Output: the tables M and P and the visited nodes V
1: procedure F IND M IN PATH (GA ,M,lasso)
2:
V ← {vs }; Q ← V − {vs }
3:
P[:] ← ∅
⊲ Each entry of P is set to ∅
4:
for v ∈ V such that (vs , v) ∈ E and v 6= vs do
5:
hM, Pi ← R ELAX((vs , v), M, P, Λ)
6:
end for
7:
if lasso = 1 then
8:
if (vs , vs ) ∈ E then
9:
M[vs , 1] ← M[vs , 1] ∪ Λ(vs , vs )
10:
M[vs , 2] ← |M[vs , 1] ∪ Λ(vs , vs )|
11:
P[vs ] = vs
12:
else
13:
M[vs , :] ← (Π, ∞)
14:
end if
15:
end if
16:
while Q =
6 ∅ do
17:
⊲ Get node u with minimum M[u, 2]
18:
u ← E XTRACT MIN(Q)
19:
if M[u, 2] < ∞ then
20:
V ← V ∪ {u}
21:
for v ∈ V such that (u, v) ∈ E do
22:
hM, Pi ← R ELAX((u, v), M, P, Λ)
23:
end for
24:
end if
25:
end while
26:
return M, P, V
27: end procedure

to the minimum number of atomic propositions from Π that
must be removed to have a prefix path to each reachable sink
(see Section III-A). Then, in line 10, it repeats the process
from each reachable final state to find an approximation to
the minimum number of atomic propositions that must be
removed so that a lasso path is enabled. The combination
of prefix/lasso that removes the minimal number of atomic
propositions is returned to the user.
Algorithm 2 follows closely DSPA [25]. It maintains a
list of visited nodes V and a table M indexed by the graph
vertices which stores the set of atomic propositions that must
be removed in order to reach a particular node on the graph.
Given a node v, the size of the set |M[v, 1]| is an upper
bound on the minimum number of atomic propositions that
must be removed. That is, if we remove all π ∈ M[v, 1]
from Bs , then we enable a simple path (i.e., with no cycles)
from a starting state to the state v. The size of |M[v, 1]|
is stored in M[v, 2] which also indicates that the node v is
reachable when M[v, 2] < ∞.
The algorithm works by maintaining a queue with the
unvisited nodes on the graph. Each node v in the queue
has as key the number of atomic propositions that must be

removed so that v becomes reachable on A. The algorithm
proceeds by choosing the node with the minimum number
of atomic propositions discovered so far (line 18). Then,
this node is used in order to updated the estimates for the
minimum number of atomic propositions needed in order to
reach its neighbors (line 22). A notable difference of Alg.
2 from DSPA is the check for lasso paths in lines 7-15.
After the source node is used for updating the estimates of
its neighbors, its own estimate for the minimum number of
atomic propositions is updated either to the value indicated
by the self loop or the maximum possible number of atomic
propositions. This is required in order to compare the different paths that reach a node from itself.
The following example demonstrates how the algorithm
works and indicates the structural conditions on the graph
that make the algorithm non-optimal.
Example 1: Let us consider the graph in Fig. 1. The
source node of this graph is vs = v1 and the set of sink
nodes is Vf = {v6 }. The Π set of this graph is {π 1 , . . . , π 4 }.
Consider the first call of F IND M IN PATH (line 5 of Alg. 1).
•

268

Before the first execution of the while loop (line 16):

Algorithm 3 R ELAX
Inputs: an edge (u, v), the tables M and P and the edge
labeling function Λ
Output: the tables M and P
1: procedure R ELAX ((u, v),M,P,Λ)
2:
if |M[u, 1] ∪ Λ(u, v)| < M[v, 2] then
3:
M[v, 1] ← M[u, 1] ∪ Λ(u, v)
4:
M[v, 2] ← |M[u, 1] ∪ Λ(u, v)|
5:
P[v] ← u
6:
end if
7:
return M, P
8: end procedure

difference of AAMRP over DSPA is that we have set
theoretic operations. We will assume that we are using a data
structure for sets that supports O(1) set cardinality quarries,
O(log n) membership quarries and element insertions [25]
and O(n) set up time. Under the assumption that Q is implemented in such a data structure, each E XTRACT MIN takes
O(log V ) time. We have O(V ) such operations (actually
|V | − 1) for a total of O(V log V ).
Setting up the data structure for Q will take O(V ) time.
Furthermore, in the worst case, we have a set Λ(e) for
each edge e ∈ E with set-up

 time O(EΠ). Note that the
initialization of M[v, :] to Π, ∞ does not have to be
implemented since we can have indicator variables indicating
when a set is supposed to contain all the (known in advance)
{π 1 }
elements.
{π 1 }
Assuming that E is stored in an adjacency list, the total
{π 3 }
v1
v2
number of calls to R ELAX at lines 4 and 21 of Alg. 2 will
{π 1 , π 3 }
{π 2 }
v5
v6
be O(E) times. Each call to R ELAX will have to perform
{π 4 }
a union of two sets (M[u, 1] and Λ(u, v)). Assuming that
v3
v4
{π 4 }
{π 1 , π 4 }
both sets have in the worst case |Π| elements, each union
will take O(Π log Π) time. Finally, each set size quarry takes
Fig. 5. The graph of Example 4. The source
is denoted by an
Fig. 1. The graph of Example 1. The source vs = v1 is denoted by an
O(1) time and updating the keys in Q takes O(log V ) time.
arrow and the sink v6 by double circle (Vf = {v6 }).
Therefore, the running time of F IND M IN PATH is O(V +
EΠ + V log V + E(Π log Π + log V )).
Note that under Assumption 1 all nodes of T are reachable
The queue contains Q = {v2 , . . . , v6 }. The table M (|V | < |E|), the same property does not hold for the product
has the following entries: M[v1 , :] = h∅, 0i, M[v2 , :] = automaton. (e.g, think of an environment T and a specificah{π 1 }, 1i, M[v

 3 , :] = h{π 1 , π 3 }, 2i, M[v4 , :] = . . . = tion automaton whose graphs are Directed Acyclic Graphs
M[v6 , :] = Π, ∞ .
(DAG). However, we still have (|V | < |E|). F IND M IN PATH
• Before the second execution of the while loop (line
takes O(E(Π log Π+log V )). Therefore, we observe that the
16): The node v2 was popped from the queue since running time also depends on the size of the set Π. However,
it had M[v2 , 2] = 1. The queue now contains Q = such a bound is very pessimistic since not all the edges will
{v3 , . . . , v6 }. The table M has the following rows: be disabled on A and, moreover, most edges will not have
M[v1 , :] = h∅, 1i, M[v2 , :] = h{π 1 }, 1i, M[v3 , :] = the whole set Π as candidates for removal.
h{π 1 , π 3 }, 2i,
 4 ] = h{π 1 , π 2 }, 2i, M[v5 , :] =

 M[v
Finally, we consider AAMRP. The loop at line 9 is going
M[v6 , :] = Π, ∞ .
to be called O(Vf ) times. At each iteration, F IND M IN PATH
• At the end of F IND M IN PATH (line 27): The queue
is called. Furthermore, each call to G ETAPF ROM PATH is gonow is empty. The table M has the following rows: ing to take O(V Π log Π) time (in the worst case we are going
M[v1 , :] = h∅, 0i, M[v2 , :] = h{π 1 }, 1i, M[v3 , :] = to have |V | unions of sets of atomic propositions). Thereh{π 1 , π 3 }, 2i, M[v4 , :] = h{π 1
, π 2 },2i, M[v5 , :] = fore, the running time of AAMRP is O(V (V Π log Π +
f
h{π 1 , π 2 , π 4 }, 3i, M[v6 , :] = Π, 4 , which corre- E(Π log Π + log V ))) = O(V E(Π log Π + log V )) which
f
sponds to the path v1 , v2 , v4 , v5 , v6 .
is polynomial in the size of the input graph.
Note that algorithm returns a set of atomic propositions
Approximation bound: We can provide theoretical guarLp = Π which is not optimal (|Lp | = 4). The path v1 , v3 , antees on the quality of the approximation. In particular, in
v4 , v5 , v6 would return Lp = {π 1 , π 3 , π 4 } with |Lp | = 3. △ the worst case, AAMRP returns a solution whose size is
Correctness: The correctness of AAMRP is based on the twice the size of the optimal solution.
fact that a node v ∈ V is reachable on GA if and only if
Theorem 1: AAMRP is a 2-approximation algorithm.
M[v, 2] < ∞. The argument for this claim is similar to the
V. E XAMPLES AND N UMERICAL E XPERIMENTS
proof of correctness of DSPA in [25]. If AAMRP returns a
set of atomic propositions L which are removed from Bs ,
In this section, we present experimental results using our
then the language L(A) is non-empty. This is immediate by prototype implementation of AAMRP. The prototype implethe construction of the graph GA (Def. 7).
mentation is in Python. Therefore, we expect the running
Running time: The running time analysis of the AAMRP times to substantially improve with a C implementation using
is similar to that of DSPA. In the following, we will abuse state-of-the-art data structure implementations.
notation when we use the O notation and treat each set
For the experiments, we utilized the ASU super computing
symbol S as its cardinality |S|.
center which consists of clusters of Dual 4-core processors,
First, we will consider F IND M IN PATH. The fundamental 16 GB Intel(R) Xeon(R) CPU X5355 @2.66 Ghz running
269

CentOS 5.5. Our implementations do not utilize the parallel
architecture. The clusters were used to run the many different
test cases in parallel.
In order to experimentally demonstrate the approximation
ratio of AAMRP, we compared the solutions returned by
AAMRP with our Answer Set Programming (ASP) implementation of MRP that we developed in [17]. The ASP
implementation is guaranteed to return a minimal solution
to the MRP problem.
Example 2 (Robot Motion Planning): We revisit our example introduced in [17]. The product automaton of this
example has 85 states, 910 transitions and 17 reachable
final states. It takes 0.095 sec by AAMRP and 0.699 sec
by ASP. AAMRP returns the set of atomic propositions
{hπ4 , (s2 , s4 )i} as a minimal revision to the problem, which
is revision(3) among the three minimal revisions of the
example. Thus, it is an optimal solution.
△
We performed a large number of experimental comparisons on random benchmark instances of various sizes.
The first series of experiments involved randomly generated
DAGs. Each test case consisted of two randomly generated
DAGs which represented an environment and a specification.
Both graphs have self-loops on their leaves so that a feasible
lasso path can be found. The number of atomic propositions
in each instance was equal to four times the number of
nodes in each acyclic graph. For example, in the benchmark
where the graph had 9 nodes, each DAG had 3 nodes, and
the number of atomic propositions was 12. The sinks are
chosen randomly and they represent 5%-40% of the nodes.
The number of edges in most instances were 2-3 times more
than the number of nodes.
Table I compares the results of the ASP solver with
the results of AAMRP on test cases of different sizes
(total number of nodes). For each graph size, we performed
200 tests and we report minimum, average and maximum
computation times in sec. Both algorithms were able to finish
the computation and return a minimal revision for all the test
cases. Nevertheless, in the large problem instances, AAMRP
achieved a 10 time speed-up on the average running time. An
interesting observation is that the maximum approximation
ratio is experimentally determined to be 2 which validates
the theoretical analysis.
For the next experiment, each test case was a cross product
graph of two bidirectional spanning trees. One represents the
environment and the other the specification. The number of
atomic propositions was equal to two times the number of
nodes in each spanning tree. For example, in the instance
having 9 nodes, each spanning tree had 3 nodes, and, thus,
it had 6 atomic propositions. Each instance had 5%-40% of
sinks. The number of edges in most instances was three times
more then the number of nodes in each instance.
The results are presented in Table II. The observations on
the results are similar to the previous experiments. However,
we remark that in this case ASP was not able to provide
an answer to all the test cases within a 2hr window. The
comparison for the approximation ratio was possible only
for the test cases where ASP successfully completed the

computation. In this case, in the large problem instances,
AAMRP achieved at least 100x speed-up on average running
time.
Finally, we attempted to determine the problem sizes that
our prototype implementation can handle. The results are
presented in Table III. We observe that approximately 60,025
nodes would be the limit of the AAMRP implementation in
Python. However, we expect that we can achieve at least a
10 times speed up with a C implementation and we plan to
pursue this direction in the future.
VI. C ONCLUSIONS
In this paper, we provided a polynomial time approximation algorithm for the problem of minimal revision of specification automata. The minimal revision problem is useful
when automata theoretic planning fails and the modification
of the environment is not possible. In such cases, it is
desirable that the user receives feedback from the system
on what the system can actually achieve. The challenge in
proposing a new specification automaton is that the new specification should be as close as possible to the initial intent
of the user. Our proposed algorithm experimentally achieves
approximation ratio very close to 1. Furthermore, the running
time of our prototype implementation is reasonable enough
to be able to handle realistic scenarios.
Future research will proceed along several directions.
Since the initial specification is ultimately provided in some
form of natural language, we would like the feedback that
we provide to be in a natural language setting as well. Second, we would like to develop an approximation algorithm
that improves upon the approximation ratio 2. Finally, we
plan on developing a robust and efficient publicly available
implementation of our approximation algorithm.
R EFERENCES
[1] E. M. Clarke, O. Grumberg, and D. A. Peled, Model Checking.
Cambridge, Massachusetts: MIT Press, 1999.
[2] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Translating
structured english to robot controllers,” Advanced Robotics, vol. 22,
no. 12, pp. 1343–1359, 2008.
[3] J. Dzifcak, M. Scheutz, C. Baral, and P. Schermerhorn, “What to do
and how to do it: Translating natural language directives into temporal
and dynamic logic representation for goal management and action
execution,” in Proceedings of the IEEE international conference on
robotics and automation, 2009.
[4] G. E. Fainekos, A. Girard, H. Kress-Gazit, and G. J. Pappas, “Temporal
logic motion planning for dynamic robots,” Automatica, vol. 45, no. 2,
pp. 343–352, Feb. 2009.
[5] S. Karaman, R. Sanfelice, and E. Frazzoli, “Optimal control of mixed
logical dynamical systems with linear temporal logic specifications,”
in IEEE Conf. on Decision and Control, 2008.
[6] A. Bhatia, L. E. Kavraki, and M. Y. Vardi, “Sampling-based motion planning with temporal goals,” in International Conference on
Robotics and Automation. IEEE, 2010, pp. 2689–2696.
[7] T. Wongpiromsarn, U. Topcu, and R. M. Murray, “Receding horizon
control for temporal logic specifications,” in Proceedings of the 13th
ACM international conference on Hybrid systems: computation and
control. New York, NY, USA: ACM, 2010, pp. 101–110.
[8] P. Roy, P. Tabuada, and R. Majumdar, “Pessoa 2.0: a controller
synthesis tool for cyber-physical systems,” in Proceedings of the 14th
international conference on Hybrid systems: computation and control,
ser. HSCC ’11. New York, NY, USA: ACM, 2011, pp. 315–316.
[9] H. Kress-Gazit, G. E. Fainekos, and G. J. Pappas, “Temporal logic
based reactive mission and motion planning,” IEEE Transactions on
Robotics, vol. 25, no. 6, pp. 1370 – 1381, 2009.

270

Nodes
9
100
196
324
400
529

ASP
min
0.003
0.099
0.335
0.869
1.267
3.086

avg
0.0071
0.1954
1.25058
5.3316
12.87
34.1642

max
0.012
1.405
6.003
14.731
35.58
103.638

succ
200/200
200/200
200/200
200/200
200/200
200/200

AAMRP
avg
max
0.0157
0.025
0.06727
0.09
0.22372 0.289
0.6601
0.912
1.28913 1.351
3.107
4.141

min
0.013
0.027
0.057
0.113
0.131
0.37

succ
200/200
200/200
200/200
200/200
200/200
200/200

min
1
1
1
1
1
1

RATIO
avg
1.00667
1.000625
1
1.001417
1
1

max
2
1.125
1
1.2
1
1

TABLE I
N UMBER OF NODES VERSUS THE RESULTS OF ASP SOLVER AND AAMRP. U NDER THE ASP AND AAMRP COLUMNS THE NUMBERS INDICATE
COMPUTATION TIMES IN sec. RATIO INDICATES THE EXPERIMENTALLY OBSERVED APPROXIMATION RATIO TO THE OPTIMAL SOLUTION .

Nodes
9
100
196
306
400
506

ASP
min
0.005
0.378
3.336
9.801
21.744
58.67

avg
0.0097
18.4679
31.995
75.524
124.7486
241.167

max
0.039
3502.343
685.819
2795.337
164.5459
1054.98

succ
200/200
200/200
167/200
149/200
148/200
152/200

AAMRP
avg
max
0.0153 0.0449
0.063
0.09
0.203
0.249
0.5493
0.7
1.124
1.2929
2.0795
1.821

min
0.012
0.028
0.0439
0.101
0.134
0.2329

succ
200/200
200/200
200/200
200/200
200/200
200/200

min
1
1
1
1
1
1

RATIO
avg
max
1
1
1.001
1.2
1
1
1.000839
1.125
1
1
1.002193 1.333333

TABLE II
N UMBER OF NODES VERSUS THE RESULTS OF ASP SOLVER AND AAMRP. U NDER THE ASP AND AAMRP COLUMNS THE NUMBERS INDICATE
COMPUTATION TIMES IN sec. RATIO INDICATES THE EXPERIMENTALLY OBSERVED APPROXIMATION RATIO TO THE OPTIMAL SOLUTION .

Nodes
1024
10000
20164
50176
60025

min
24.438

ASP
avg
max
168.2133 237.758

succ
10/10
0/10
0/10
0/10
0/10

min
0.125
15.723
50.325
425.362
6734.133

AAMRP
avg
max
0.23
0.325
76.164
128.471
570.737
1009.675
1993.449 4013.717
6917.094 7100.055

RATIO
succ
9/10
9/10
8/10
3/10
2/10

1

TABLE III
N UMBER OF NODES VERSUS THE RESULTS OF ASP SOLVER AND AAMRP. U NDER THE ASP AND AAMRP COLUMNS THE NUMBERS INDICATE
COMPUTATION TIMES IN

sec. RATIO INDICATES THE EXPERIMENTALLY OBSERVED APPROXIMATION RATIO TO THE OPTIMAL SOLUTION .

[10] M. Kloetzer and C. Belta, “Automatic deployment of distributed teams
of robots from temporal logic specifications,” IEEE Transactions on
Robotics, vol. 26, no. 1, pp. 48–61, 2010.
[11] L. Bobadilla, O. Sanchez, J. Czarnowski, K. Gossman, and S. LaValle,
“Controlling wild bodies using linear temporal logic,” in Proceedings
of Robotics: Science and Systems, Los Angeles, CA, USA, June 2011.
[12] A. Ulusoy, S. L. Smith, X. C. Ding, C. Belta, and D. Rus, “Optimal multi-robot path planning with temporal logic constraints,” in
IEEE/RSJ International Conference on Intelligent Robots and Systems,, 2011, pp. 3087 –3092.
[13] B. Lacerda and P. Lima, “Designing petri net supervisors from ltl
specifications,” in Proceedings of Robotics: Science and Systems, Los
Angeles, CA, USA, June 2011.
[14] A. LaViers, M. Egerstedt, Y. Chen, and C. Belta, “Automatic generation of balletic motions,” IEEE/ACM International Conference on
Cyber-Physical Systems, vol. 0, pp. 13–21, 2011.
[15] G. E. Fainekos, “Revising temporal logic specifications for motion
planning,” in Proceedings of the ICRA, May 2011.
[16] G. D. Giacomo and M. Y. Vardi, “Automata-theoretic approach to
planning for temporally extended goals,” in European Conference on
Planning, ser. LNCS, vol. 1809. Springer, 1999, pp. 226–238.
[17] K. Kim, G. Fainekos, and S. Sankaranarayanan, “On the revision
problem of specification automata,” in Proceedings of the IEEE
Conference on Robotics and Automation, May 2012.
[18] J. R. Buchi, “Weak second order arithmetic and finite automata,”
Zeitschrift für Math. Logik und Grundlagen Math., vol. 6, pp. 66–
92, 1960.
[19] O. Kupferman, W. Li, and S. A. Seshia, “A theory of mutations with

[20]

[21]

[22]
[23]

[24]
[25]
[26]

271

applications to vacuity, coverage, and fault tolerance,” in Proceedings
of the International Conference on Formal Methods in ComputerAided Design. IEEE Press, 2008, pp. 25:1–25:9.
Moritz Göbelbecker and Thomas Keller and Patrick Eyerich and
Michael Brenner and Bernhard Nebel, “Coming up with good excuses:
What to do when no plan can be found,” in Proceedings of the
20th International Conference on Automated Planning and Scheduling.
AAAI, 2010, pp. 81–88.
A. Cimatti, M. Roveri, V. Schuppan, and A. Tchaltsev, “Diagnostic
information for realizability,” in Verification, Model Checking, and
Abstract Interpretation, ser. LNCS, F. Logozzo, D. Peled, and L. Zuck,
Eds. Springer, 2008, vol. 4905, pp. 52–67.
R. Konighofer, G. Hofferek, and R. Bloem, “Debugging formal
specifications using simple counterstrategies,” in Formal Methods in
Computer-Aided Design. IEEE, Nov. 2009, pp. 152 –159.
V. Raman and H. Kress-Gazit, “Analyzing unsynthesizable specifications for high-level robot behavior using LTLMoP,” in 23rd International Conference on CAV, ser. LNCS, vol. 6806. Springer, 2011, pp.
663–668.
S. M. LaValle, Planning Algorithms. Cambridge University Press,
2006. [Online]. Available: http://msl.cs.uiuc.edu/planning/
T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction
to Algorithms, 2nd ed. MIT Press/McGraw-Hill, Sep. 2001.
M. Sniedovich, “Dijkstras algorithm revisited: the dynamic programming connexion,” Control and Cybernetics, vol. 35, no. 3, pp. 599–
620, 2006.

ICCPS'14, April 14-17, 2014, Berlin, Germany

WiP Abstract: Conformance Testing as Falsification for
Cyber-Physical Systems
Houssam Abbas, Bardh Hoxha, and Georgios Fainekos
CPS Lab, Arizona State University, Tempe, AZ, USA

{hyabbas, fainekos, bhoxha}@asu.edu
Jyotirmoy V. Deshmukh, James Kapinski, and Koichi Ueda,
Toyota Technical Center, Gardena, CA, USA

{jyotirmoy.deshmukh, jim.kapinski, koichi.ueda}@tema.toyota.com
In a typical Model-Based Design (MBD) process for
Cyber-Physical Systems, an initial ‘simple’ Model is successively refined and made more accurate and complex;
then it is implemented on a real-time computational
platform, and further modified to yield an Implementation. The goal is to produce a system that satisfies a
formal specification Φ. This successive refinement raises
the question of how “close” are the “simple” Model and
the “complex” Implementation. Answering this question
is important because it is not always possible to verify
formally that the Implementation satisfies the specification Φ. Moreover, even if the Implementation satisfies Φ, it will have unspecified behavior which might
exhibit bugs. By quantifying the ‘closeness’ between
Model and Implementation, our level of confidence in
the Implementation derives from our confidence in the
Model, and the fact that the Model satisfies Φ.
Because formal analysis of non-deterministic models
is rarely utilized and supported by industry tools, language inclusion can not be used to answer this question. Thus, an appropriate notion of closeness, or conformance, between Model and Implementation is required. Conformance testing is the process of establishing whether behaviors exhibited by Model and Implementation are conformant. Existing works apply only
to certain classes of systems and rely on the full knowledge of the mathematical representations of Model and
Implementation, often not available for industrial CPS.
In this work, we give a rigorous mathematical definition of conformance between two output trajectories
yM and yI of the Model and Implementation, resp.,
when driven from the same initial conditions, with the
same control input. We term this conformance notion

978-1-4799-4930-4/14/$31.00 ©2014 IEEE

(T, J, (τ, ε))-closeness. Its distinctive feature is that it
measures the difference between yM and yI in both
space and time. Coarsely, two output trajectories are
conformant with degree (τ, ε) ∈ R2+ , over a hybrid timehorizon (T, J) ∈ R+ × N, if every yM -point has a yI point ε-close to it within a window of width 2τ , and viceversa. Several application-dependent notions of system
similarity can be shown to be implied by (T, J, (τ, ε))closeness.
Using (T, J, (τ, ε))-closeness, it is possible to perform
the following MBD tasks in a rigorous manner:
◦ Define conformance between a Model and Implementation, which are said to be conformant with degree
(T, J, (τ, ε)) iff given the same initial conditions, and
the same input signal, they produce trajectories that
are (T, J, (τ, ε))-close.
◦ Given a tuple (τ, ε), determine whether the Model
and Implementation are conformant by performing a
search over the initial conditions and input signal space
for two trajectories that are not (T, J, (τ, ε))-close. If
such a pair is found, then the Implementation needs to
be revised to conform the Model.
◦ Given T and J, determine a smallest pair (τ, ε)
such that the two systems are (T, J, (τ, ε))-close. Such
a smallest value is termed the degree of conformance
between the two systems.
We demonstrate the above tasks on an industrial automatic transmission, where the Model is in Simulink,
and the Implementation is a high-fidelity engine model
from Simuquest with a large number of black box components. Using our methods, we can reliably approximate the degree of conformance between the two systems.
Details of this work are available online as report
arXiv:1401.5200. This work benefited from the input
of Raymond Turin,and was partially funded under NSF
awards CNS 1116136, CNS 1319560, IIP-0856090 and
the NSF I/UCRC Center for Embedded Systems.

211

2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Congress Center Hamburg
Sept 28 - Oct 2, 2015. Hamburg, Germany

V I S PEC: A graphical tool for elicitation of MTL requirements
Bardh Hoxha1 , Nikolaos Mavridis2 and Georgios Fainekos1

Abstract— One of the main barriers preventing widespread
use of formal methods is the elicitation of formal specifications.
Formal specifications facilitate the testing and verification process for safety critical robotic systems. However, handling the
intricacies of formal languages is difficult and requires a high
level of expertise in formal logics that many system developers
do not have. In this work, we present a graphical tool designed
for the development and visualization of formal specifications by
people that do not have training in formal logic. The tool enables
users to develop specifications using a graphical formalism
which is then automatically translated to Metric Temporal
Logic (MTL). In order to evaluate the effectiveness of our tool,
we have also designed and conducted a usability study with
cohorts from the academic student community and industry.
Our results indicate that both groups were able to define formal
requirements with high levels of accuracy. Finally, we present
applications of our tool for defining specifications for operation
of robotic surgery and autonomous quadcopter safe operation.

I. I NTRODUCTION
As robots become commercially available, their correct
operation is of paramount importance. Especially for safety
critical systems, safety must be guaranteed. As for example
in autonomous vehicles [24] and medical robots [17], [13].
Safety requirements are usually expressed in natural language, which is inherently ambiguous, in general. When it is
used for defining system specifications, this ambiguity may
lead to misunderstandings between development teams that
may result in increased costs and delays in development. If
the misunderstandings are not detected, then a product that
does not meet the intended specifications will be developed.
Ideally, specifications should be defined in a mathematical
language, using formal logics. This not only removes ambiguity, but also allows system developers to utilize a vast set
of methods [22] that have been developed by the academic
community for testing and verification of systems. The academic community has also developed automatic tools such as
S-TA L I RO [2], [11], FAPAS [25], SpaceEx [9], CheckMate
[19], F LOW [4], Breach [6], C2E2 [7], KeYmaera [18] and
S TRONG [5] that enable developers to conduct system testing
and verification.
Even though it has been shown, that utilizing formal
specifications can lead to improved testing and verification
[8], the industry still utilizes natural language as the premier
approach in defining specifications. One may conjecture
that the most important reason for doing so is because the
development of specifications through a formal logic requires
1 Bardh Hoxha and Georgios Fainekos are with the School of Computing,
Informatics and Decision Systems Engineering, Arizona State University

{bhoxha,fainekos}@asu.edu
2 Nikolaos Mavridis is with the Interactive Robots and Media Lab and
NCSR Demokritos nmav@alum.mit.edu

978-1-4799-9994-1/15/$31.00 ©2015 IEEE

a level of mathematical training that many users may not
have [23]. Furthermore, even for expert users, writing formal
specifications is an error prone task [10]. As a result, the
industry has been less willing to utilize formal specifications
in their processes.
In this work, we present a graphical formalism that enables
non-expert users to develop formal specifications for control
systems. The formalism enables the visualization of a large
fragment of MTL. The main challenge in the development
of the formalism lies in finding the right balance between
expressive power and ease-of-use. It is designed for use with
systems and signals and enables both event and time based
specifications. This is the first time that a visual formal
language representation is developed for specifications for
Cyber-Physical Systems (CPS). Here by CPS we define
any system that has discontinuous nonlinear dynamics and
complex safety critical requirements. Prime examples are
medical robotics and autonomous vehicles. A specification
visualization tool has been developed based on the graphical
formalism presented in this work. To evaluate the usefulness
of the tool in terms of usability and ease-of-use, we have
conducted a usability study.
S UMMARY OF C ONTRIBUTIONS :
•
•
•
•

•

We present a graphical formalism that enables the
development of formal specifications.
We present the visual specification tool based on the
graphical formalism.
We conducted a usability study to evaluate the tool.
Through the usability study we proved that both nonexpert users and expert users are able to define formal
requirements accurately using the tool, and derived
suggestions for improvement of the tool.
We present applications of the tool for real-world robots.

R ELATED WORKS : In order to help address the formal
specification challenge, various graphical formalisms have
been studied in the past [20], [1], [15], [3], [26], [21]. The
most relevant works appear in [3] and [26]. In [3], the authors
extend Message Sequence Charts and UML 2.0 Interaction
Sequence Diagrams to propose a scenario based formalism
called Property Sequence Chart (PSC). The formalism is
mainly developed for specifications on concurrent systems.
In [26], PSC is extended to Timed PSC which enables the
addition of timing constructs to specifications.
In terms of usability studies for formal requirements very
few works exist. In [23], the authors study the ability
of expert users to develop requirements in Z. A related
usability study for requirement representation is presented
in [16], where the authors present and evaluate a system

3486

for generating, troubleshooting and executing controllers for
robots using natural language.
II. V ISUAL S PECIFICATION T OOL
The Visual Specification Tool (V I S PEC)1 enables the
development of formal specifications for CPS. Users can
develop requirements in a graphical formalism which is then
translated to Metric Temporal Logic (MTL) [14].
The topic of capturing requirements through graphical
formalisms has been studied in the past [20], [1], [15], [3],
[26]. However, to the best of the authors knowledge, the work
presented here is the first attempt to do so specifically aimed
for the development of specifications for CPS. The initial
idea for the graphical formalism was first presented in [11]
while the tool was still in the early stages of development.
However, in this work we present an updated version of the
tool along with its usability study. The improvements over
the previous version include: a more streamlined interface;
an updated representetion of signals in the interface; and an
updated template definition process.
For CPS specifications, it is often needed to account for
both timing and event sequence occurrence. Both of these are
necessary for reasoning over systems and signals. Consider
the specification 2[0,5] ((speed > 100) → 2[0,5] (rpm >
4000)). It states that whenever within the first 5 seconds,
the vehicle speed goes over 100, then from that moment
on, the engine speed (rpm), for the next 5 seconds, should
always be over 4000. Here both the sequence and timing of
the events are of critical importance.
To ensure that the tool can be utilized by non-expert users,
the following goals for the tool are defined: 1) The user
interface is intuitive to use, i.e, it does no have a high learning
curve; 2) The visual representation of the requirements is
visualy distinct and unambiguous; 3) There is a one-to-one
mapping from the visual representation of the requirement
and the corresponding requirement in MTL.
The set of specifications that can be generated from this
graphical formalism is a proper subset of the set of MTL
specifications. Formally, the following grammar produces
the set of formulas that can be expressed by the proposed
graphical formalism:
S
T
A
B
C
D
P

−→
−→
−→
−→
−→
−→
−→

¬T | T
A | B | C
P | ( P∧A) | ( P⇒A)
2I D | 3I D
2I 3I D | 3I 2I D
p | ( p→A) | ( p∧A) | ( p→B ) | ( p∧B )
p | 2I p | 3I p

where p is an atomic proposition. In practice, the atomic
propositions are automatically derived from the templates.
Throughout the development process of the formalism,
it was noticed that the more expressive the formalism, the
more challenging to use it became. Therefore, we focused
on several widely used classes of specifications which are
1 Available
at
https://sites.google.com/a/asu.edu/
s-taliro/vispec

described in Table I. Examples of the classes of specifications
are presented in the rest of this section.
To make the tool easier to use, we placed several constraints on the types of signals used. Specifically, the signals
and requirements are one dimensional. This enables clear and
structured visualization on a two dimensional user interface.
The main building blocks of the formalism are templates.
These are used for defining temporal logic operators, their
timing intervals, and the expected signal shape. The user
starts with an empty template and a setup assistant presents
the user with a sequence of dialog boxes that aid in the development of the template. The process is context dependent
where each option selection leads to a potentially different
set of options for the next step.
The first step in the template definition process is to
define the temporal operator. Among the choices (and their
corresponding MTL symbols) are: Always (2), At Least
Once (3), Eventually Always (32), Repeatedly Often and
Finally (23), and now. The options available enable users to
define a wide range of specifications. The following sections
will present examples of a subset of formulas that can be
generated using this graphical formalism.
After the temporal operator is selected, the user sets
the timing bounds for it. Many users might have difficulty
defining timing bounds, especially for specifications with
temporal operators such as Eventually Always (32) and
Repeatedly Often and Finally (23). To illustrate the process,
the tool provides a fill-in-the-blanks sentence format to
the user. For example, if the operator Eventually Always
is selected, the user will have to complete the following
sentence with the timing bounds: “Eventually, between
and
seconds, the signal will become true, and from that
point on, will stay true in the next
to
seconds”.
The set of timing intervals are visualized with color shaded
regions in the template.
The next step in the process is in defining whether the
predicate will evaluate to true when the signal is above
or below a set threshold. For example, for the Always (2)
operator, a signal is selected that is either always above or
below a specified threshold. Once either option is selected,
various signals that fit the requirement are automatically
generated and presented visually. Instead of drawing the
signal, the user will select from one of the generated options.
Consider the following example:
Example 1 A specification from the fragment of MTL formulas called Safety MTL specifications is presented. Specifically, the specification φ1 = 2[0,36] (rpm < 4000). The
formula states that in the next 36 seconds, engine speed
should always be less than 4000. The corresponding graphical formalism for this formula is presented in Fig. 1. Note
that, in regards to the specification, the signal can be of any
shape as long as it is always below the 4000 threshold.
Consider the following example for the At Least Once (3)
temporal operator:
Example 2 A specification from the fragment of MTL for-

3487

TABLE I: Classes of specifications expressible with the graphical formalism
Specification Class

Explanation

Safety
Reachability
Stabilization

Specifications of the form 2φ used to define specifications where φ should always be true.
Specifications of the form 3φ used to define specifications where φ should be true at least once in the future (on now).
Specifications of the form 32φ used to define specifications that, at least once, φ should be true and from that point
on, stay true.
Specifications of the form 23φ used to define specifications that, it is always the case, that at some point in the future,
φ is true.
Specifications of the form φ → ψ requires the ψ should hold when φ is true.
Specifications of the form N (φ → M ψ), where N and M are temporal operators, used to define an implicative
response between two specifications where the timing of M is relative to timing of N .
Specifications of the form φ ∧ ψ used to define the conjunction of two sub-specifications
Specifications of the form N (φ ∧ M ψ), where N and M are temporal operators, used to define a conjunction between
two specifications where the timing of M is relative to timing of N .

Recurrence
Implication
Reactive Response
Conjunction
Non-strict Sequencing

mulas called Reachability MTL specifications is presented.
Specifically, the specification φ2 = 3[0,39] (speed > 100).
The formula states that eventually, within the next 39 seconds, the vehicle speed will go over 100. The corresponding
graphical formalism for this formula is presented in Fig. 2.
Again, in regards to the specification, the signal can be of
any shape as long as at one point, within the timing bounds
of the temporal operator, it is above the 100 threshold.

User
Input

V I S PEC
Tool

Tree
Structure

Fig. 3: The specification development process using V I S PEC
the MTL formula. There is a bijection between the visual
representation of a specification and the MTL formula. An
overview of the process is provided in Fig. 3.
An example of the tree structure for MTL formula φ =
2(a ∧ 3b) → (2c ∧ 3(d → (a ∧ 2b))) is shown in Fig.
4. The recursive algorithm for traversing the tree structure
and generating the MTL formula is presented in Alg. 1.
Note that the functions ADD PAREN C ONN{A,B,C,D} add
the parenthesis and connectives between predicates. A more
detailed presentation of the algorithm is presented in the
technical report [12].
Root

Fig. 1: Example 1: The graphical formalism for the Safety
MTL specification φ1 = 2[0,36] (rpm < 4000).

N1 , 1, 2, a
N12 , 1, 3, b

N3 ,2,,
N31 , 2, 2, c
N321 , 3, , a

Fig. 2: Example 2: The graphical formalism for the Reachability MTL specification φ2 = 3[0,39] (speed > 100).
For more examples of specifications and their corresponding graphical formalism see the technical report [12]. In
Section VI, we present two application specifications that
illustrate the various interactions between templates.
The variety of templates and the connections between
them allow users to express a wide variety of specifications.
III. G RAPHICAL F ORMALISM
The specification development process in V I S PEC is divided in two sub processes. First, given a user input in the
V I S PEC tool, it is translated to a tree structure where the
nodes contain template information such as temporal operators, their corresponding timing parameters, group and the
value threshold for the predicates. Secondly, the generated
tree structure is traversed by a recursive algorithm to generate

MTL

Graphical
Formalism

N32 , 2, 3, d
N322 , 3, 2, b

Fig. 4: The corresponding tree structure for formula φ =
2(a ∧ 3b) → (2c ∧ 3(d → (a ∧ 2b))) where a,b,c and
d are predicates. Each node is composed of a node name,
group number, temporal operator, and predicate. The symbol
 indicates empty parameters.
IV. U SABILITY S TUDY
A. Hypotheses
The aim of the study is to evaluate whether V I S PEC
enables users to develop formal specifications. Two groups
were considered:

3488

1) Non-expert users: These are users who declared that
they have no experience in working with requirements.
2) Expert users: These are users who declared that they
have experience working with system requirements.
Note that they do not necessarily have experience in
writing requirements using formal logics.

Algorithm 1 WriteMTL - Algorithm for generating the MTL
formula given a tree structure of the graphical formalism
Input: Tree Structure T = hV, Ei where v ∈ V and v =
hG, Op, Si where G is the group, Op is the temporal
operator and S is the predicate string; formula φ.
Output: φ
1: function WRITE MTL(T, φ)
2:
C ← T.getChildren().
3:
sC ← size(C)
4:
for node i in C do
5:
φ ← CONC(φ, i.Op)
6:
if i.isParent then
7:
if not(i.S.isEmpty) then
8:
subC ← t.getChildren(i)
9:
φ ← ADD PAREN C ONNA(φ, subC)
10:
φ ← WRITE MTL(i.subtree, φ)
11:
φ ← ADD PAREN C ONN B(φ, subC)
12:
else
13:
φ ← CONC(φ, ’(’)
14:
φ ← WRITE MTL(i.subtree, φ)
15:
φ ← ADD PAREN C ONN C(sC, φ)
16:
end if
17:
else
18:
φ ← CONC(φ, i.S)
19:
φ ← ADD PAREN C ONN D(φ, sC)
20:
end if
21:
end for
22: end function
Some of the interesting questions we wanted to investigate,
which are also presented as hypotheses in Tab. II, are:
• Whether the graphical formalism enables non-experts
and experts to formalize requirements accurately.
• How well the expert cohort performs in comparison to
the non-expert cohort.
• How user friendly and easy-to-use V I S PEC is.
Writing formal requirements is a challenging task that
requires a significant amount of training. Therefore, it is safe
to assume that we can reject Hypothesis 1a as supported by
our informal experience. Hypothesis 2a will be tested in a
future work. In addition, we analyze user interaction and
behavior to measure the ease-of-use of the tool.
B. Demographics
The non-expert cohort was comprised of twenty subjects
from the student community of Arizona State University.
Most of the subjects are from an engineering background
with little to no experience working with requirements. The
student demographics are presented in Tab. III.
The expert subject cohort was comprised of ten subjects
from the industry in the Phoenix area. The subjects have
experience working with specifications and come from an
engineering background.
C. Experimental Design
Each subject received a task list to complete. The task
list contained ten tasks related to automotive system specifications. Each task asked the subject to formalize a natural

language specification through V I S PEC and generate an
MTL formula. The list of tasks is presented in Table VI.
The tasks become more complex throughout the session.
The higher the number of the task, the more steps necessary
to complete the task successfully.
Each session is at most 45 minutes long. Subjects received
a one minute and thirty second tutorial on using V I S PEC to
develop specifications. The computer screen was recorded
and actions were logged for each session. The subjects also
completed a demographic and post-completion questionnaire.
D. Metrics
Two metrics are used for performance evaluation:
Task completion: this is a binary measure, which indicates
whether users were able to finish the task within the set time.
Measure of Accuracy: a value from one to five which is
used to quantify the accuracy of subject generated formulas.
The formulas are graded by formal specification experts
which were given the following two suggested criteria: a)
How accurate the meaning of the natural language specification is captured, and b) Whether the inaccuracies in the user
submitted formula can be easily debugged and corrected in
the testing and verification process. Furthermore, in order to
decrease subjectivity, the following instructions were given
to the expert graders in order to anchor the meanings of
the five different grades of the scale used: A grade of one
indicates that the generated formula is totally inaccurate. A
grade of two indicates that the formula is mostly inaccurate.
A grade of three indicates an inaccurate formula which can
be easily debugged and corrected to the proper formal logic
specification by formal specification experts and thus this is
the minimum acceptable satisfactory result. A grade of four
indicates that the formula is inaccurate but can be debugged
and improved by automated specification debugging tools.
A grade of five indicates that the generated formula is
completely accurate. The group of expert graders consisted
of experts in formal methods and logic.
V. R ESULTS
1) Average grade per task: For both cohorts, the task
performance is presented in Fig. 8. It can be observed that
overall, the mean grade per task for both cohorts is high.
2) Hypothesis 1b: To test Hypothesis 1b, we need to
establish what is an acceptable threshold for accuracy in
order to test the hypothesis. As discussed in the metrics
section, we claim that a mean grade higher than three
is an acceptable threshold for non-expert users. Therefore,
hypothesis 1b is reduced to the null hypothesis: the mean
grade per user is less than or equal to three for non-experts.
Let us define the average grade per user as a random
variable Ȳ . Specifically, Ȳ : Ω → R, where Ω ∈ {y : 1 ≤
y ≤ 5}. The sample data from 20 subjects has a mean grade
of 4.43 and standard deviation of 0.41. We test for normality
with the Kolmogorov-Smirnov test, the Chi-square g.o.f test,
and the Anderson-Darling test and all three fail to reject the
null hypothesis that the data follows the normal distribution.
If we assume that the data constitute a random sample from

3489

TABLE II: Hypotheses and test results with level of significance α = 0.05. User groups as defined in section IV.A.
Reject null hypothesis

Hypothesis
1a
1b
2a
2b
3alt
T xalt

Non-expert users are able to define formal requirements accurately using formal logics such as MTL.
Non-expert users are able to define formal requirements accurately using the Visual Specification Tool.
Expert users from the industry are able to define formal requirements accurately using formal logics such as MTL.
Expert users from the industry are able to define formal requirements accurately using the Visual Specification Tool.
The mean grade per user for expert users is greater the mean grade per user for non-expert users.
The mean grade per task x for industry users is greater than to the mean grade per task x for non-expert users.

TABLE III: Hypothesis 1b Subject Demographics
Freshman
Sophomore
Junior
Senior
Masters
PhD

2
2
5
5
4
2

Computer Science
Software Engineering
Electrical Engineering
Mechanical Engineering
Engineering, other

5
3
3
6
3

Male
Female

12
8

a normal distribution, i.e. Ȳ ∼ N , we can use the t-statistic
to test the hypothesis. We reject the null hypothesis with a
p-value very close to 0.
3) Hypothesis 2b: Similarly, we test Hypothesis 2b for
the expert cohort. Hypothesis 2b is reduced to the null
hypothesis: the mean grade per user is less than or equal to
three for expert users. We test for normality as in the previous
case and all three test fail to reject the null hypothesis that
the data follows the normal distribution.
Consider the average grade per user as a random variable
Z̄. Specifically, Z̄ : Ω → R, where Ω ∈ {y : 1 ≤ y ≤ 5}.
The sample data from 10 subjects has a mean grade of 4.76
and standard deviation of 0.26. If we assume that the data
constitute a random sample from a normal distribution, i.e.
Z̄ ∼ N we can use the t-statistic to test the hypothesis.We
reject the null hypothesis with a p-value very close to 0.

Yes
Yes
Yes
Partially

5) Hypothesis T x: Next, we compare the mean grade of
both cohorts in regards to each task. A two sample t-test
is conducted for each task. The results for the tests are
presented in Tab. V. Task 9 is the most difficult task when
it comes to the number of errors generated, and this is the
only task where there is a clear difference in performance
between the expert and non-expert cohorts.
TABLE V: Hypothesis testing of T xnull with α = 0.05
x

Rej. T xnull

p-val.

Conclusion

4
5
6
7
8
9
10

No
No
No
No
No
Yes
No

0.065
0.165
0.074
0.100
0.424
0.016
0.063

potentially
false
potentially
potentially
false
true
potentially

true with more investigation
true with more investigation
true with more investigation
true with more investigation

Fig. 5: Example 2: The graphical formalism for the Reachability MTL specification φ2 = 3[0,39] (speed > 100).

We observe that the only null hypothesis rejected is for
task nine indicating that the mean grade for expert users is
greater than the mean grade for non-expert users. The subject
accuracy grades over tasks for is shown in Fig. 8.
6) Ease-of-use analysis: One indicator for the ease-of-use
of the application is the total time spent per task. As can be
observed in Fig. 5, the mean time spent per task on average
is at most 167 seconds. For easier identification of points of
difficulty, we divided each task into subtasks. It was observed
that there is no correlation between the length of time spent
in a subtask and correctness. This potentially indicates, as
also verified by correlation testing between times and grades,
that the subjects were unaware of mistakes in the process.
From these and other observations, such as misclicks, and
subject feedback, we have developed a set of refinements
on the tool to improve the user experience. A partial list of
improvements is presented in Table IV.

TABLE IV: V I S PEC improvements

VI. A PPLICATIONS

Task completion time for non−expert and expert cohorts
250
non−expert
expert

Time(sec.)

200
150
100
50
0

T1

T2

T3

T4

T5

T6

T7

T8

T9

T10

# Improve...

Prime Indicators

A. Robotic Surgery

1.
2.

misclicks; user feedback
task accuracy grade

In the last few decades, there has been a significant
increase in the number of robotics systems, especially in the
health care system. They have been successfully introduced
in multiple areas such as rehabilitation, telesurgery, physical
therapy, elderly care, and remote physician care. In the
following, we will focus on autonomous robotic systems for
surgery where of paramount importance is the safety of these
systems [13]. Specifically, we will consider a model of a
robotic serial link manipulator as presented in [17].
One of the main tasks in surgery is the puncturing action.
The high precision and repeatability of the process, make
robot systems ideal for this task. Also, the trauma induced

3.

the process of creating child templates
the tutorial by placing more emphasis
on the difference between implication
and conjunction between templates
the visual representation of grouped
templates

task accuracy
user feedback

grade;

4) Hypothesis 3alt : To test Hypothesis 3alt , we conduct
a two sample t-test. The p-value returned from the test is
0.0024 and for a significance level of 0.01, we reject the
null hypothesis. Therefore we claim that the mean grade per
user for expert users is greater than the mean grade per user
for non-experts.

3490

TABLE VI: Task list with automotive system specifications presented in natural language
Task

Natural Language Specification

1.
2.
3.
4.
5.
6.
7.

In the first 40 seconds, vehicle speed should always be less than 160.
In the first 30 seconds, vehicle speed should go over 120.
At some point in time in the first 30 seconds, vehicle speed will go over 100 and stay above for 20 seconds.
At every point in time in the first 40 seconds, vehicle speed will go over 100 in the next 10 seconds.
It is not the case that, for up to 40 seconds, the vehicle speed will go over 100 in every 10 second period.
If, within 40 seconds, vehicle speed is above 100 then within 30 seconds from time 0, engine speed should be over 3000.
If, at some point in time in the first 40 seconds, vehicle speed goes over 80 then from that point on, for the next 30
seconds, engine speed should be over 4000.
In the first 40 seconds, vehicle speed should be less than 100 and engine speed should be under 4000.
At some point in time in the first 40 seconds, vehicle speed should go over 80 and then from that point on, for the next
30 seconds, engine speed should be over 4000.
If, at some point in time in the first 40 seconds, vehicle speed goes over 80 then from that point on, if within the next 20
seconds the engine speed goes over 4000, then, for the next 30 seconds, the vehicle speed should be over 100.

Safety
Reachability
Stabilization
Recurrence
Recurrence
Implication
Reactive Response

8. Conjunction
9. Non-strict sequencing
10. Long sequence

around the region is much lower and therefore the recovery
process for the patient is quicker. To complete the puncturing
action, the robot has to move towards the puncturing location.
Test the tissue for various indicators to calibrate for optimal
puncture, bring the puncturing needle to a perpendicular
position and, finally, puncture with correct force and angle. If
the force or angle is miscalculated, it might pose unintended
harm to the patient. Consider the specifications from [17]
that should hold on a serial manipulator for puncturing:
1) From [17]: The force applied to the patient by the end
effector is always less than a given threshold, except
for the puncturing subtask. Formally, assuming that
the operation time is 30 seconds, we have: φs1 =
2[0,30] (¬puncturing → f ≤ fmax ).
2) From [17]: The task is feasible, and the position of
the needle once it stops is inside the target region
R. Formally, assuming that the operation time is 40
seconds, we have: φs2 = 3[0,40] (Stop ∧ needle ∈ R)).
3) Also, other requirements can be expressed for such a
system. For example, the end effector speed should not
be less than vmin and should not be greater than vmax .
Formally: φs3 = 2[0,40] (vmin < vef f < vmax )
The V I S PEC tool is utilized to develop the specifications
for the robotic manipulator. For φs1 , the specification is
presented in Fig. 6. We assume that fmax = 10. The visual
representations with V I S PEC for item 2 and 3 are presented
in the technical report [12].

in the academic community and industry. Among others, they
are used in military operations, nuclear disaster assessment,
firefighting and entertainment. The challenges faced in developing these devices and their control algorithms come from
the flight dynamics and the highly dynamical environment
that they operate in. Also, as the complexity of these devices
increases, so do the performance and reliability requirements.
Consider the following specifications for a quadrotor:
1) The absolute value of the pitch and roll angle should
always be bellow certain thresholds. Formally, assuming
that the operation time is 40 seconds, we have: φq1 =
2[0,40] (|α| < αmax ) ∧ 2[0,40] (|β| < βmax ).
2) If distance to the target region is smaller than a certain threshold d, then for then next 20 seconds, the
speed should not exceed vmax . Formally, assuming that
the operation time is 40 seconds, we have: φq1 =
2[0,40] (dist < d → 2[0,20] (v < vmax )).
The V I S PEC tool is utilized to develop the specifications
for the quadrotor. For φq1 , the specification is presented in
Fig. 7. We assume that αmax = 45 deg, βmax = 45 deg and
γmax = 60 deg. The visual representations with V I S PEC
for item 2 is presented in the technical report [12].

Fig. 7: The graphical formalism for φq1 .
VII. C ONCLUSION AND F UTURE W ORK
Fig. 6: The graphical formalism for φs1 .
B. Quadcopter
In recent years, quadcopters and other unmanned aerial
vehicles (UAVs) have become a major focus for research both

As robots and other cyber-physical systems become more
complex and ubiquitous, so does the need for better testing
and verification. A set of formal methods that improve
this process require some formal representation of system
specifications. In this work, a graphical formalism and a tool

3491

Bar plot of mean grade and std. dev. over tasks for expert users
6
5
4
3
2
1

Grade

Bar plot of mean grade and std. dev. over tasks for non−expert users
6
5
4
3
2
1
T1

T2

T3

T4

T5

T6

T7

T8

T9 T10

T1

Grade

Box plot of grades over tasks for non−expert users

T2

T3

T4

T5

T6

T7

T8

T9 T10

Box plot of grades over tasks for expert users

6
5
4
3
2
1

6
5
4
3
2
1
T1

T2

T3

T4

T5 T6
Task

T7

T8

T9 T10

T1 T2 T3 T4 T5 T6 T7 T8 T9 T10
Task

Fig. 8: Subject accuracy grades over tasks for both the expert and non-expert cohorts.
that enables users to easily develop formal specifications are
presented. The V I S PEC tool enables users who have little to
no mathematical training in formal logics to develop formal
specifications, as was verified by a usability study that was
conducted in order to evaluate the usefulness of the tool
and to get insights on potential improvements. The tool was
utilized to formalize specifications for two robots.
Last but not least, we would like to investigate if the potential inaccuracies of the specifications that users generate with
the tool can be attributed mainly to the inherent ambiguity
of the natural language descriptions which were given, or if
not, which other factors contribute and to what extent. Thus,
in an improved usability study, we aim towards exploring
alternative methods of generation of requirements from engineers for a system, that do not involve the administration of a
natural language description by the experimenter. This would
enable us to study to what extent inherent natural language
ambiguity causes the observed less-than-perfect accuracy that
is sometimes, even if rarely, exhibited.
ACKNOWLEDGMENT: Partial support under NSF awards
CNS-1319560, CNS-1116136, IIP-1454143, IIP-1361926
and the NSF I/UCRC Center for Embedded Systems. We
thank all the participants in the usability study and the
reviewers for the detailed reviews.
R EFERENCES
[1] A. Alfonso, V. Braberman, N. Kicillof, and A. Olivero. Visual timed
event scenarios. In Proceedings of the 26th Int. Conference on
Software Engineering, pages 168–177. IEEE Computer Society, 2004.
[2] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan. S-taliro: A tool for temporal logic falsification for hybrid
systems. In Tools and algorithms for the construction and analysis of
systems, volume 6605 of LNCS, pages 254–257. Springer, 2011.
[3] M. Autili, P. Inverardi, and P. Pelliccione. Graphical scenarios for
specifying temporal properties: an automated approach. Automated
Software Engineering, 14(3):293–340, 2007.
[4] X. Chen, E. Abraham, and S. Sankaranarayanan. Flow*: An analyzer
for non-linear hybrid systems. In Computer-Aided Verification (CAV),
volume 8044 of LNCS, pages 258–263. Springer-Verlag, 2013.
[5] Y. Deng, A. Rajhans, and A. A. Julius. Strong: A trajectory-based
verification toolbox for hybrid systems. In Quantitative Evaluation of
Systems, pages 165–168. Springer, 2013.
[6] A. Donze. Breach, a toolbox for verification and parameter synthesis
of hybrid systems. In Computer Aided Verification, volume 6174 of
LNCS, pages 167–170. Springer, 2010.
[7] P. S. Duggirala, S. Mitra, and M. Viswanathan. Verification of
annotated models from executions. In Proc. of the Eleventh ACM
Int. Conf. on Embedded Software, page 26. IEEE Press, 2013.
[8] G. Fainekos, S. Sankaranarayanan, K. Ueda, and H. Yazarel. Verification of automotive control applications using s-taliro. In Proceedings
of the American Control Conference, 2012.

[9] G. Frehse, C. L. Guernic, A. Donz, S. Cotton, R. Ray, O. Lebeltel,
R. Ripado, A. Girard, T. Dang, and O. Maler. Spaceex: Scalable
verification of hybrid systems. In Proceedings of the 23d CAV, 2011.
[10] G. J. Holzmann. The logic of bugs. In Proc. of the 10th ACM SIGSOFT
symp. on Foundations of soft. eng., pages 81–87. ACM, 2002.
[11] B. Hoxha, H. Bach, H. Abbas, A. Dokhanchi, Y. Kobayashi, and
G. Fainekos. Towards formal specification visualization for testing
and monitoring of cyber-physical systems. In Int. Workshop on Design
and Implementation of Formal Tools and Systems. October 2014.
[12] B. Hoxha, N. Mavridis, and G. Fainekos.
V I S PEC: a graphical tool for elicitation of MTL requirements.
Available at
https://sites.google.com/a/asu.edu/s-taliro/ViSpecTechRpt15.pdf.
[13] Y. Kouskoulas, D. W. Renshaw, A. Platzer, and P. Kazanzides. Certifying the safe design of a virtual fixture control algorithm for a surgical
robot. In C. Belta and F. Ivancic, editors, Hybrid Systems: Computation and Control (part of CPS Week 2013), HSCC’13, Philadelphia,
PA, USA, April 8-13, 2013, pages 263–272. ACM, 2013.
[14] R. Koymans. Specifying real-time properties with metric temporal
logic. Real-Time Systems, 2(4):255–299, 1990.
[15] H. Kugler, D. Harel, A. Pnueli, Y. Lu, and Y. Bontemps. Temporal
logic for scenario-based specifications. In Tools and Alg. for the
Construction and Analysis of Systems, pages 445–460. Springer, 2005.
[16] C. Lignos, V. Raman, C. Finucane, M. Marcus, and H. Kress-Gazit.
Provably correct reactive control from natural language. Autonomous
Robots, 38(1):89–105, 2015.
[17] R. Muradore, D. Bresolin, L. Geretti, P. Fiorini, and T. Villa. Robotic
surgery. Robotics & Automation Magazine, IEEE, 18(3):24–32, 2011.
[18] A. Platzer and J.-D. Quesel. KeYmaera: A hybrid theorem prover for
hybrid systems. In A. Armando, P. Baumgartner, and G. Dowek,
editors, International Joint Conference on Automated Reasoning,
volume 5195 of LNCS, pages 171–178. Springer, 2008.
[19] B. I. Silva and B. H. Krogh. Formal verification of hybrid systems
using CheckMate: a case study. In Proceedings of the American
Control Conference, volume 3, pages 1679 – 1683, June 2000.
[20] M. H. Smith, G. J. Holzmann, and K. Etessami. Events and constraints:
A graphical editor for capturing logic requirements of programs. In Requirements Engineering, 2001. Proceedings. Fifth IEEE International
Symposium on, pages 14–22. IEEE, 2001.
[21] S. Srinivas, R. Kermani, K. Kim, Y. Kobayashi, and G. Fainekos. A
graphical language for LTL motion and mission planning. In Robotics
and Biomimetics (ROBIO), 2013 IEEE International Conference on,
pages 704–709. IEEE, 2013.
[22] S. Tripakis and T. Dang. Model-Based Design for Embedded Systems,
chapter Modeling, Verification and Testing using Timed and Hybrid
Automata, pages 383–436. CRC Press, 2009.
[23] R. Vinter, M. Loomes, and D. Kornbrot. Applying software metrics
to formal specifications: A cognitive approach. In Software Metrics
Symposium, 1998. Metrics 1998. Proceedings. Fifth International,
pages 216–223. IEEE, 1998.
[24] T. Wongpiromsarn, S. Mitra, A. Lamperski, and R. M. Murray. Verification of periodically controlled hybrid systems: Application to an
autonomous vehicle. ACM Trans. Embed. Comput. Syst., 11(S2):53:1–
53:24, Aug. 2012.
[25] B. Yordanov, J. Tmov, I. ern, J. Barnat, and C. Belta. Formal analysis of piecewise affine systems through formula-guided refinement.
Automatica, 49(1):261 – 266, 2013.
[26] P. Zhang, B. Li, and L. Grunske. Timed property sequence chart.
Journal of Systems and Software, 83(3):371–390, 2010.

3492

Automatic Parallelization of Multirate Block Diagrams of Control
Systems on Multicore Platforms
CUMHUR ERKAN TUNCALI, GEORGIOS FAINEKOS, and YANN-HANG LEE,
Arizona State University

This article addresses the problem of parallelizing model block diagrams for real-time embedded applications
on multicore architectures. We describe a Mixed Integer Linear Programming formulation for finding a
feasible mapping of the blocks to different CPU cores. For single-rate models, we use an objective function
that minimizes the overall worst-case execution time. We introduce a set of heuristics to solve the problem
for large models in a reasonable time. For multirate models, we solve the feasibility problem for finding a
valid mapping. We study the scalability and efficiency of our approach with synthetic benchmarks and an
engine controller from Toyota.
CCS Concepts:

r

Computer systems organization → Embedded software;

Additional Key Words and Phrases: Multicore platforms, embedded control systems, scheduling, optimization, model-based development, Simulink, multirate, task allocation
ACM Reference Format:
Cumhur Erkan Tuncali, Georgios Fainekos, and Yann-Hang Lee. 2016. Automatic parallelization of multirate
block diagrams of control systems on multicore platforms. ACM Trans. Embed. Comput. Syst. 16, 1, Article 15
(October 2016), 26 pages.
DOI: http://dx.doi.org/10.1145/2950055

1. INTRODUCTION

Model-Based Design (MBD) has gained a lot of traction in the industries that develop
safety-critical systems. This is particularly true for industries that develop CyberPhysical Systems (CPSs), for which the software implements control algorithms for
the physical system. Using MBD, system developers and control engineers can design
control algorithms on high-fidelity models. Most important, they can test and verify
the system properties before having a prototype of the system. The (certified) autocodegeneration facility of MBD tools provides an additional concrete benefit that is helping
to eliminate programming errors. Another advantage of MBD is the ability to generate
platform-specific code from a platform-independent model [Kim et al. 2013].
However, currently, the autocode-generation processes of commercial tools focus on
single-core systems. Namely, at the model level, there is no automatic support for
producing code that runs on a multicore system. This is problematic since advanced
control algorithms, for example, Model Predictive Control algorithms [Huang et al.
2013], are computationally demanding and may not be executed within the limited
computation budget of a single-core embedded system. In this article, we address
This research was partly funded by the NSF awards CNS-1446730 and IIP-1361926, and the NSF I/UCRC
Center for Embedded Systems.
Authors’ addresses: Arizona State University, Centerpoint Bldg. STE 203, 660 S. Mill Ave. Tempe, AZ 85281;
emails: {etuncali, fainekos, yhlee}@asu.edu.
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for profit or commercial advantage and that
copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for
components of this work owned by others than ACM must be honored. Abstracting with credit is permitted.
To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this
work in other works requires prior specific permission and/or a fee. Permissions may be requested from
Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212)
869-0481, or permissions@acm.org.
c 2016 ACM 1539-9087/2016/10-ART15 $15.00

DOI: http://dx.doi.org/10.1145/2950055

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15

15:2

C. E. Tuncali et al.

this problem at the model level. Given a dataflow diagram of an embedded control
algorithm, the worst-case execution times (WCETs) of the blocks, and a computation
budget (deadline or sampling period), can we automatically map the blocks of a model
onto multiple submodels that are executed on different cores and satisfy real-time
constraints?
Depending on system requirements, the controller model can have single or multiple sampling rates. For instance, communicating with different hardware systems
may require different subsystems to operate with different sampling periods/rates. In
addition, for satisfying the hardware interface and performance requirements or for
maintaining stability of the system, the system designer has to determine the optimal
sampling frequencies for the subsystems [Åström and Wittenmark 1997]. Most MBD
R
R
tools, for example, Simulink
from MathWorks
, support multirate design. For multirate designs, the problem of mapping the blocks onto the cores requires an analysis
for the interaction between the blocks with different sample rates and a consideration
of the task scheduling algorithm on the target platform.
We focus on control models built in Simulink for demonstration of our approach. Our
goal is to produce a framework that determines the mapping of each block onto a CPU
core and an execution order of the blocks inside the tasks. We aim at creating a single
task for each sample rate on a CPU core, that is, a single task on each core for single-rate
models and possibly multiple tasks on each core for multirate models. A task contains
all blocks with the same sample rate that are mapped on the same core. Our consideration for scheduling the tasks on the target platform is based on the rate-monotonic
scheduling algorithm, which is a fixed-priority scheduling mechanism in which tasks
are statically assigned to CPU cores. Especially, in safety-critical systems, scheduling
in a predictable and deterministic manner is highly important for verification and for
satisfying the certification requirements that are mandated by regulatory authorities.
Multicore architectures are classified as highly complex in the 2011/6 final report of
the European Aviation Safety Agency [EASA 2012] and in the Certification Authorities Software Team (CAST) position paper CAST-32 Multi-core processors [CAST 2014].
These classifications highlight the difficulty of certifying safety-critical systems that
are based on multicore architectures. To our knowledge, there is no certified tool that
can automatically parallelize the generated code to multiple cores. However, certified
R
code generators for single-core platforms are available, for example, Embedded Coder
R
R
from MathWorks
, Esterel KCG
, and so on. Parallelizing the system at the model
level will result in separate models for each CPU core. Then, certified code generators
can be used to generate code from the resulting models. This will help the designer in
better understanding which part of the software runs in which core. The remaining
step toward certification is for guaranteeing the correct partitioning of the model. This
is expected to be a smaller effort compared to doing the parallelization at a lower level,
for example, at the compiler level.
In our previous work [Tuncali et al. 2015], our approach for single-rate models is
explained. Our approach is based on having separate executables for each core while
Simulink blocks are allocated in each core and executed in the execution order that
we compute. In other words, we determine the execution order of the blocks inside
each core while respecting the data dependencies between them. In this article, we are
extending our approach for single-rate models to multirate models. Our approach for
the multirate models is based on seeking a mapping of the blocks onto different tasks
on the CPU cores and an execution order of the blocks within the tasks in order to
satisfy the deadline requirements of all the tasks. After code generation, we have a
separate task for each sampling period in a model. The scheduling of the tasks should
be taken into account for parallelizing multirate models. It must be guaranteed that
the preemptions of the low-priority tasks by the high-priority tasks does not cause
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:3

deadline misses. Our Mixed-Integer Linear Program (MILP) formulation for multirate
models incorporates scheduling-related constraints between the tasks with different
rates.
The contributions of this article are as follows:
1. Providing a practical, automated solution to the block diagram parallelization problem for multicore architectures while considering the deadline requirements and
scheduling of the parallelized application on the target platform, and
2. Extending available MILP formulations for parallelizing control models to allow
multirate execution.
2. RELATED WORK

There is a large amount of research being done on the optimization of scheduling
multiple tasks on multicore processors or multiple processors in the literature.
An exhaustive survey on real-time scheduling techniques for homogeneous multiprocessor architectures is provided by Davis and Burns [2011]. That survey
evaluates different techniques by discussing their advantages and disadvantages.
The authors state the main practical advantage of statically assigning the tasks onto
the processors as the ability to apply available uniprocessor scheduling techniques and
analyses on each processor in the system.
There are multiple studies on task parallelization. For optimal mapping of tasks to
CPU cores, Yi et al. [2009], Bender [1996], and Ostler and Chatha [2007] discuss Integer
Linear Programming (ILP) techniques that constitute the foundation for our optimization formulation. These approaches can be applied to single-rate Simulink models by
substituting the tasks in the formulation with Simulink blocks, that is, considering the
blocks as tasks with dependencies. On the other hand, for multirate models, a set of
blocks with the same rate should be considered as a single task in those approaches,
but this eliminates the parallelization opportunities inside a task. For more realistic
models that consist of a significant number of blocks, ILP-based approaches require
introduction of heuristics to find an optimal or suboptimal solution in a reasonable
amount of time. Yi et al. [2009] make use of available loop-level parallelism or functional pipelining in the system. An efficient constraint programming approach to the
task allocation problem is described by Hladik et al. [2008], who introduce a constraint
programming approach to solve the static task allocation to distributed processors
problem. Their algorithm can also prove nonexistence of a solution when it cannot
find one. Another interesting feature of their algorithm is that it separates the allocation problem from the scheduling problem. Their algorithm incorporates a method
for learning from the schedulability analysis to remodel the allocation problem and
to improve performance. However, the only experiment results given in that work is
with 40 tasks, and the scalability of that approach is not studied. Another constraint
programming–based approach for parallel execution of safety-critical applications is
studied by Puffitsch et al. [2015]. The objective of that work is executing the tasks
of Prelude applications on multi- and manycore architectures in which the tasks are
scheduled by nonpreemptive offline scheduling. Our work differs from that work in the
sense that we are doing the multicore mapping of the blocks in a model that results in
splitting a task into subtasks that run on different cores, in which the tasks in a core
are scheduled by a preemptive rate-monotonic scheduler. Cotton et al. [2011] discuss
the use of Satisfiability Modulo Theories (SMT) solvers and multi-criteria optimization
for mapping tasks to multiprocessors. Application of SMT solvers in manycore scheduling for data-parallel applications is discussed by Tendulkar et al. [2014]. Feljan and
Carlson [2014] propose a heuristic that utilizes information on how the tasks delay
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:4

C. E. Tuncali et al.

each other, for finding a good solution for task allocation problems in a short solver
execution time.
There are also several studies focusing on the parallelization of Simulink models.
Kumura et al. [2012] propose methods to flatten Simulink models for parallelization
without giving a detailed description of the optimization formulation. In that work,
Simulink blocks are considered as tasks. Canedo et al. [2010] introduce the concepts
of strands for breaking the data dependencies in the model to achieve thread-level
parallelism on multicore. The authors define a strand as a chain of blocks that are
driven by Mealy blocks. The proposed method searches for available strand split points
in Simulink models and relies heavily on strand characteristics in target models. Cha
et al. [2011] have focused on automating code generation for multicore systems in which
the parallel blocks are grouped by user-defined parallelization start and end S-functions
into the model. An approach for WCET analysis of Simulink models is described by
Kirner et al. [2000]. Although WCET analysis is crucial for going from Simulink models
to executables on a multicore system, we do not focus on WCET analysis in our work, but
we assume that the WCET of the blocks are readily available as an input. A compilerlevel parallelization of the code generated by Simulink is studied by Umeda et al. [2015],
who propose an automatic parallelization approach using the OSCAR compiler. While
Umeda et al. [2015] propose a compiler-level parallelization approach, we approach
the problem at the model level. We believe that model-level parallelization provides
a better architectural picture for control engineers since they can see the functional
partitioning in the model. This helps the engineers to understand the parallel execution
of their software better and to debug easier.
Deng et al. [2015] study model-based synthesis flow from Simulink models to
AUTOSAR [2015] runnables and runnables to tasks on multicore architectures. The
authors extend the Firing Time Automaton (FTA) [Lublinerman and Tripakis 2008]
model to specify activations and requested execution time at activation points. They
define modularity as a measure of number of generated runnables and reusability as
a measure of false dependencies introduced by runnable generation. The authors use
modularity, reusability, and schedulability metrics for evaluation of runnable generations. They also propose different heuristics and compare their results with the results
obtained by utilizing a simulated annealing algorithm. Although that work is targeting
a similar problem to our target problem for single-rate models, they are providing experiment results for systems with less than 50 blocks, and are not considering intercore
communication and memory overhead.
A study on multi/manycore execution of multirate Simulink models is done by Pagetti
et al. [2014], who describe an approach to execute multirate Simulink models on
multi/manycore architectures. However, for this purpose, the authors propose doing
a translation from Simulink models to Prelude [Forget et al. 2010]. Our work differs
from that since we focus on finding a mapping of blocks on the available CPU cores
for meeting deadline and shared memory–related constraints. We do code generation
directly for execution on the target architecture, while Pagetti et al. [2014] focus on
translation to Prelude without seeking a feasible mapping of the input model/blocks to
the target cores.
A linear programming approach for the partition-scheduling problem for strictly
periodic tasks on multiprocessor Integrated Modular Avionics (IMA) architectures is
studied by Al Sheikh et al. [2012], who incorporate available resource constraints
such as memory limitations along with IMA-related constraints into their linear programming formulation. They are also proposing a game theory–based, best-response
algorithm as a heuristic that is proven to converge. Our work differs from that work
by the heuristics that we introduce and our model-level approach, which creates a
parallelization before the code that forms the tasks is generated.
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:5

A scheduling methodology for multicore systems is described by Elhossini et al.
[2010], in which directed acyclic graphs for the tasks are used for task partitioning. The
approach in that work groups the tasks in a system as ordinary tasks and multirate
tasks. The ordinary tasks are defined as the tasks that must be executed at every
cycle of the system. The multirate tasks are defined as the tasks that do not need to
be executed at every cycle but can be scheduled during idle times of the schedule. The
problem targeted in that work differs from ours since, in our problem, tasks cannot
be grouped as ordinary and multirate tasks as is done in that work. Instead, we are
dealing with a set of tasks consisting of blocks of a model design in which tasks have
distinct rates and must complete within their periods under an available scheduling
algorithm.
The scalability of the constraint programming–based approaches is studied by
Gorcitz et al. [2015], who experimentally showed that the constraint programming–
based approaches can be efficiently used for small- to medium-sized systems, but they
diverge rapidly when the system becomes larger. The authors also state the necessity
of heuristic methods for larger systems, which is along the lines of the experimental
results in our work.
The use of conditional sporadic Directed Acyclic Graph (DAG) tasks by Baruah [2015]
have similarities to our approach for multirate models in which execution order dependencies of the blocks, induced by the block-dependency graphs of different sample rates,
change for different firing times with possible preemptions of the tasks at the firing
times.
Our work mainly differs from the other works in the literature by
1. providing a complete flow for automatically parallelizing single- and multirate block
diagrams,
2. incorporating the communication time cost in the optimization problem both in the
transmitter and the receiver side,
3. having total available shared memory and task priority constraints, and
4. being able to handle large models with more than 100 blocks in a reasonably short
time using the proposed heuristics.
3. PROBLEM DESCRIPTION
3.1. Preliminaries
R
R
Model-based design platforms such as Simulink
from MathWorks
, Esterel SCADE
R

Suite , and Ptolemy [Eker et al. 2003] utilize synchronous block diagrams for describing the model of a system. Figure 1 displays an example of a block diagram from a
simple Simulink model. A precise introduction to synchronous block diagrams is given
by Lublinerman et al. [2009]. Here, we provide a brief summary. A synchronous block
diagram contains blocks (possibly inside other blocks), each with a nonnegative number of input and output ports, and connections between the blocks through their input
and output ports. A block can either be macro or atomic. An atomic block can be defined
as a block that cannot be partitioned into smaller blocks. A macro block encapsulates
a block diagram. A flattening operation on block diagrams removes the hierarchy hidden inside macro blocks by replacing the macro blocks with the block diagrams that
they are encapsulating until no macro blocks are left. Macro blocks correspond to the
virtual subsystems in Simulink. Details on the flattening operation can be found in
Lublinerman et al. [2009].
Every block in a synchronous block diagram has a sampling rate that describes the
rate at which the block is executed during the execution of the system being modeled.
If all blocks have the same sampling rate, the model is referred as a single-rate model.
Otherwise, the model is referred as a multirate model.

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:6

C. E. Tuncali et al.

Fig. 1. Simulink block diagram.

Fig. 2. Intermediate block diagram.

Fig. 3. Flattened block diagram.

For describing the problem that we are targeting, it is convenient to represent the
dependencies between the blocks of a synchronous block diagram in a graph structure.
For this, we flatten the given block diagram. The first step in flattening a block diagram
is removing the hierarchy in it. Figure 2 gives an example of this operation, in which the
“Subsystem” block in Figure 1 is replaced with the block diagram that it encapsulates.
MBD tools typically supply some mechanisms to the user for routing signals inside
the diagram in a visually clear way. For instance, a “Goto”–“From” block pair represents
a data connection from the source of “Goto” to the destination of “From” in a Simulink
model. Since these blocks do not represent any operation done by the system that is
being modeled, we call these blocks virtual routing blocks, and we replace these blocks
with lines representing the data connections between the blocks in the flattened block
diagram. Figure 3 gives an example of such a transformation. The “Goto”–“From” pair
in Figure 2 is replaced with a line in Figure 3. We refer to the block diagram obtained by
performing a flattening operation, that is, removing hierarchy and replacing the virtual
routing blocks with lines, as the flattened block diagram. Every block in a flattened
block diagram is atomic.
Definition 1: A block dependency graph (BDG) G = (V, E) is a graph representation
of a flattened block diagram. It is an acyclic directed graph with the vertex set V =
{vi : i ∈ [1, n]}, where each vi corresponds to a block and |V| = n is the total number of
blocks in the block diagram, with a set E of directed edges.
A similar concept, task-data graphs, are discussed by Cotton et al. [2011]. In contrast
to that concept, we use blocks instead of tasks, the WCETs of blocks instead of the
amount of work associated with tasks, and we consider the data communication size
between blocks. Figure 4 illustrates a sample BDG that corresponds to the flattened
block diagram given in Figure 3. There is a one-to-one correspondence between the
vertices in V and the blocks in the flattened block diagram. We use vi in order to refer
to the block that the vertex vi ∈ V corresponds to. A directed edge (vi , v j ) ∈ E is sourced
from the vertex vi and has the vertex v j as its destination. Such an edge represents the
existence of a direct data connection from the output ports of the block vi to the input
ports of the block v j .
In a flattened block diagram, there can be data connections representing data transfers from previous iterations of their source blocks. We call the blocks with such incoming data connections delay introducing blocks. The edge set E of a BDG excludes such
data connections. Every edge (vi , v j ) ∈ E has an associated positive weight ci, j , which
represents the amount of data transferred from the block vi to the block v j . When the
blocks vi and v j are executed on different CPU cores, there will be a communication
cost in terms of time for transferring ci, j amount of data between the CPU cores. The
communication cost for such a connection is divided into transmission and reception
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:7

Fig. 4. A block dependency graph.

parts, where txi, j denotes the time required for the transmission part of the communication and rxi, j denotes the time required for the reception part of the communication.
For each block vi ∈ V, its WCET is denoted by wi and its sampling period is denoted
by πi .
3.2. Problem Definition

We are addressing the problem of automatically parallelizing synchronous block diagrams on to multicore architectures to satisfy WCET constraints on the target platform.
We have different problem definitions for single- and multirate models.
Assumptions 1 (for single- and multirate models):
(a) All of the CPU cores on the target platform are identical.
(b) The time cost for data communication between a pair of blocks on different CPU
cores is identical for any pair of CPU cores.
(c) The time cost for transferring some data between a pair of blocks on the same CPU
core is zero.
(d) There are no cycles in the given BDG.
(e) The execution order dependencies of the blocks with the same period are only
defined by the data dependencies between them.
(f) All blocks with a period π become available to execute at every π amount of time,
and they all must complete their execution in π amount of time after they become
available.
Assumptions 2 (for multirate models):
(a) Distinct sampling periods in the model are harmonic.
(b) On the target platform, for each CPU core, there will be a separate task for each
distinct period for the blocks with that period and mapped on that CPU core.
(c) On the target platform, tasks within a CPU core will be scheduled by a ratemonotonic scheduling algorithm.
(d) No protected resource is shared between the blocks with different sampling periods.
Any resource sharing between the same-rate blocks is known in advance through
the model structure.
Problem 1 – Single-rate models: Given the number m of available CPU cores on
the target platform and a BDG G = (V, E) such that π1 = · · · = πn = π , where n = |V|,
compute an optimal mapping of the blocks to the target CPU cores and an execution
ordering of these blocks with the objective of minimizing the makespan of all the blocks
within their period on the target platform. Report if no feasible solution can be found
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:8

C. E. Tuncali et al.

Fig. 5. An overview of our approach.

that allows a makespan, that is, the overall completion time of execution of all blocks,
shorter than the period π . We impose Assumptions 1 on this problem.
In Tuncali et al. [2015], we focused on Problem 1 for single-rate embedded control
applications that are modeled in Simulink. In this article, we extend the problem to
the multirate models, and propose a solution for the extended problem.
Problem 2 – Multirate models: Given the number m of available CPU cores on the
target platform and a BDG G = (V, E) such that πi = π j for some vi , v j ∈ V, compute
a mapping of the blocks to the target CPU cores and an execution ordering of these
blocks so that execution of every block can be started and finished within its period on
the target platform. We impose Assumptions 1 and 2 on this problem.
3.3. Solution Overview

In this article, we present a unified solution for Problems 1 and 2. For demonstration
purposes, our target platform is a Qorivva MPC5675K-based evaluation board from
Freescale Semiconductor Inc. The processor is a dual-core 32b MCU that is targetR
ing automotive applications. Micrium μC/OS-II
is ported to our target platform, and
a library to support Simulink code generation is devised for the platform by Bulusu
R
[2014]. Embedded Coder
is used for code generation from the models. In multitasking
mode, which is the case for multirate models, Embedded Coder combines the blocks of
the same rate into a task that is scheduled by a rate-monotonic scheduler on a single
core. For this reason, our approach is based on combining blocks of the same rate in
a single task when they are mapped on the same core. The priorities of these tasks
increase as their sampling periods decrease. Each core on our target platform has a
separate copy of μC/OS-II kernel. The multicore operation is supported by utilizing intercore synchronization and communication protocols through a shared memory space,
as described by Bulusu [2014]. The operating system kernel on each core uses a ratemonotonic scheduling algorithm for scheduling the tasks within the core. Preemption
of the tasks is allowed.
An overview of our approach to Problems 1 and 2 is illustrated in Figure 5. Although
our approach for these two problems has some differences that are explained later
in this section, the illustration given in Figure 5 is applicable to both problems. In
this section, we first explain our approach for single-rate models; then, we extend the
discussion to multirate models.
We approach Problem 1, which is for single-rate models, in five steps, as also
described in our previous paper [Tuncali et al. 2015]: (1) Creating a BDG from the
given block diagram. (2) Finding an optimal or near-optimal mapping of blocks to
different CPU cores by formulating an MILP and solving the resulting optimization
problem with off-the-shelf MILP solvers. Details of our MILP formulation are given in
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:9

Section 4. (3) Automatically updating the original Simulink model by adding intercore
communication blocks where necessary in accordance with the most optimal solution.
We handle intercore data communications by utilizing available shared memory and
intercore semaphores that are used for synchronization between tasks across cores
and protecting global critical sections as described in Bulusu [2014]. For the purpose
of utilizing this approach in Simulink, we model the transmission and reception of
data with two separate S-function blocks that implement intercore transmission and
reception using intercore semaphores and shared memory. We refer to these S-function
blocks as inter-core communication blocks. (4) Generating separate code for each target
core. We first partition the model into separate models for each core. For this, we create
a copy of the model for each core and automatically comment out the blocks that are
not mapped to the corresponding core. Then, we do Simulink code generation from each
of these model copies. (5) Compiling the generated code and deploying it on the target
platform. Since we do separate code generation for each core, we compile the generated
code for each core and deploy each of the executables on its corresponding core.
Our approach for Problem 2, which is for multirate models, follows similar steps as
our approach for Problem 1, with modifications in some of these steps. First, in addition
to creating a BDG for the model as a whole, we create a separate BDG for each distinct
sampling period in the model. In the second step, instead of optimizing with an objective
function, we are utilizing MILP solvers for seeking a feasible solution to satisfy the
WCET limits imposed by the periods of the blocks. For this purpose, we first calculate a
hyperperiod from the distinct periods in which a block may become available to execute
more than once. In our MILP formulation, we are targeting to find a solution for one
hyperperiod since the execution of the system on the target platform repeats itself at
every hyperperiod. Details of our MILP formulation are described in Section 4. For the
multirate models, since the transmitter and the receiver block of some communicated
data can have different periods, communication between such blocks require ratetransition blocks. As a communication mechanism between different rate blocks on
different cores, we utilize the asynchronous three-slot mechanism described by Chen
and Burns [1997]. Implementation details of this mechanism, which we refer to as
intercore rate-transition blocks on our target platform, are explained by Bulusu [2014].
For the blocks with the same rate that are executed on different cores, we use the same
intercore communication mechanism that we use in the third step of our approach to
Problem 1. Although there is no difference in the final two steps of our approach from
the approach to Problem 1, the generated code from a multirate Simulink model has a
separate function for each distinct sample time. We place each of these functions in a
separate task in the executables for the target CPU cores.
4. MILP FORMULATION

In this section, we present our MILP formulation for the parallelization problem of synchronous block diagrams. An MILP formulation for single-rate models was described in
our previous work [Tuncali et al. 2015]. In this article, we are extending this formulation to multirate models. Our MILP formulation is based on the formulations proposed
by Yi et al. [2009], Bender [1996], and Ostler and Chatha [2007]. We introduce an
extension to these formulations by dividing the cost of communication to the transmission and reception parts, by adding a constraint on the usage of the available shared
memory for intercore communications, and extending the formulation to address multirate models. Our MILP formulation for multirate models seeks a feasible solution
that satisfies the constraints induced by the desired block periods and available shared
memory on the target platform without having any objective function. In Section 4.5,
we describe our heuristics to reduce the number of constraints for allowing the MILP
solvers to find better solutions within a feasible time.
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:10

C. E. Tuncali et al.

The blocks mapped on the same core with the same period will be executed in the
same task. Thus, there will be a separate task for each distinct sampling period of the
blocks that are mapped to the same core.
In the rate-monotonic scheduling algorithm, a task that contains blocks with smaller
periods will have higher priority than the tasks that contain blocks with larger periods.
Thus, when low- and high-priority tasks are available at the same time, the tasks with
lower priorities will wait for higher-priority tasks to either complete or to get blocked.
According to our MILP formulation, when a high-priority task waits for data from
another core, no lower-priority task is executed during the data wait time. However,
in an actual execution, a ready, lower-priority task may be executed during this time
when the higher-priority task gets blocked. On the other hand, because our target
platform allows preemption of task executions, an execution of a lower-priority task will
be preempted by a higher-priority task when the higher-priority task becomes ready.
Thus, assuming that the WCETs and the worst-case communication times are available
for the MILP formulation, in an actual execution, a high-priority task will never be
completed later than the time computed by the MILP solver. On the other hand, a lowerpriority task may start to execute before the time that was found by the MILP solver. In
such a case, by applying the interchange argument from Section 12.3 of Lee and Seshia
[2015], we can swap the time reserved by the MILP solver for the execution of the
lower-priority task with any data-waiting time of the higher-priority task. This can be
iteratively applied for any pair of tasks, and it can be shown that, even if a lower-priority
task starts execution while a higher-priority task is waiting for data, the execution
completion time for any task can never be later than its completion time computed
by the MILP solver. Recall that here our assumption is that no tasks with different
periods share a protected resource (Assumptions 2.d). This assumption must hold to
avoid experiencing any anomaly in the scheduling of the tasks as described by Graham
[1969] and Thiele and Kumar [2015]. However, the change in execution ordering of
lower- and higher-period blocks of a Simulink model as described earlier may result
in different execution semantics in the target platform. Thus, the system designer
must use appropriate mechanisms for maintaining the execution semantics by use
of appropriate lock mechanisms, data-transfer mechanisms that ensure determinism,
or ensuring the execution ordering by the task scheduler. Mechanisms for preserving
execution semantics for multirate models are discussed by Caspi et al. [2008]. Details
of such mechanisms are implementation specific, and not discussed in this article.
4.1. Notation and Constants

The notation used for the MILP formulation is given in Table I. The notation given for
the problem description in Section 3 is also utilized in the MILP formulation and, for
convenience, we repeat it in Table I.
The BDG G must be acyclic as it is defined in Section 3. Since algebraic loops are not
allowed in Simulink, the flattened block diagram of a Simulink model cannot have cycles, due to algebraic loops. However, the flattened block diagram of a Simulink model
can have cycles that contain at least one (delay-introducing) block, which is introducing data dependencies to previous iterations of the model execution, for example, Unit
Delay, Memory, Integrator, and so on. When creating a BDG, we discard the incoming
connections to the delay introducing blocks from their predecessor blocks. Since these
discarded connections represent data dependencies to an earlier iteration of the execution, discarding them does not affect the dependency relations that we are formulating.
However, since these deleted connections will not go into our formulation, if no precaution is taken, the formulation will not consider the intercore communication between
a delay-introducing block and its predecessor block when they are mapped to different
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:11

Table I. Notation Used in MILP Formulation
Notation
G = (V, E)
n
V = {vi : i ∈ [1, n]}
wi
πi
E

ci, j
txi, j / rxi, j
Z ⊆ V2 − E
N
m
P = {Pi : i ∈ [1, m]}
r
R = {Ri : i ∈ [1, r]}
rj
j
Vj = {vi : i ∈ [1, r j ]}
Gj = (Vj , Ej )
H
firing time
F = {cγ : cγ < H,
γ ∈ R, c ∈ N}
f = |F|
vi,c
M = {vi,c : vi ∈ V,
c ∈ N, cπi ∈ F}
sSize
cCount
totMem
aSize
MAX

Description
A graph representation of the flattened block diagram, i.e., a BDG, which
is a DAG
The number of blocks in the flattened block diagram
The vertex set, in which each vertex corresponds to a block in the flattened
block diagram
The worst-case execution time of the block vi
The sampling period of the block vi
The directed edge set, where (vi , v j ) ∈ E corresponds to the data connection
from block vi to block v j , excluding the connections to the delay-introducing
blocks
The amount of data transferred from block vi to block v j
The time required for transmission/reception part of the communication
from vi to v j when the blocks are executed on different cores
Set of the connections to delay introducing blocks that are not included
in E
The set of natural numbers
The number of available CPU cores
The set of available CPU cores
The number of distinct periods
The set of distinct sampling periods (“sample time” in Simulink)
The number of blocks with period R j
The set of blocks that have a sampling period of R j , where Vj ⊆ V and
∪rj=1 Vj = V
The induced subgraph of G on the vertex set Vj
The hyperperiod, which is the least common multiple of all distinct periods
in R
Start of each period and its repetitions in the time interval [0, H)
The set of distinct firing times
The number of distinct firing times
cth repetition of a block vi ∈ V in the hyperperiod, where c ∈ N and cπi < H
The set of repetitions of the blocks
The size of a global semaphore structure in bytes
The number of copies of the data communicated in an intercore ratetransition structure
Size of the total available shared memory in bytes
Data alignment size in bytes (word size)
A very large constant that is used in the program formulation to dominate
other terms, allowing constraints to be ignored under certain conditions
(big-M method)

cores. To avoid this issue, we force any delay-introducing block and its predecessor to
be mapped on the same CPU core by introducing a constraint.
Recall that we have assumed that different rate blocks do not share protected resources (Assumption 2.d) because such a case can create scheduling anomalies. Samerate blocks accessing shared resources are assumed to be known in advance. We add
such blocks into the set Z as if there were a connection between these blocks. This
forces such blocks to be on the same core and consequently in the same task due to the
constraints in the formulation.
For a single-rate model, the problem simplifies as follows: for all i, πi = π , r = 1,
R = {R1 = π }, V1 = V, E1 = E, G1 = G, f = 1, H = π , F = {0}, and M = {vi,0 : vi ∈ V}.
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:12

C. E. Tuncali et al.

4.2. Variables

The variables used in the MILP formulation are:
bi, p: A Boolean variable indicating whether the block vi is mapped to the core Pp or
not. It is defined for all vi ∈ V and for all Pp ∈ P. If vi is mapped to core Pp, then bi, p
takes value 1. If vi is mapped to another core, then bi, p takes value 0.
di, j : A Boolean variable indicating whether the block vi executes before or after the
block v j when both blocks are mapped to the same core. It is defined for all pairs of
same-period blocks that do not have any data dependency to each other. When vi and
v j are mapped to the same core, if vi executes before v j , then di, j takes value 1, and if
vi executes after v j , then di, j takes value 0. The variable di, j does not have a meaning
when the blocks vi and v j are mapped to different cores.
dic , j : A Boolean variable indicating whether a block finishes its execution before it
can be preempted by executions of blocks with a smaller period in an upcoming firing
time. It is defined for all blocks vi,c ∈ M and F j ∈ F such that c πi < F j < (c + 1) πi .
The variable dic , j takes value 1 if vi,c finishes its execution before the firing time F j . It
takes value 0 if vi,c starts its execution after all of the blocks in Mk,z that are mapped
to same core with vi finish their execution where k, z satisfy Rk < πi , (z Rk) = F j .
si,c : The start time for the execution of the cth repetition of the block vi , that is, vi,c . It
is defined for all vi,c ∈ M.
4.3. Constraints

—A block shall be assigned to a single core:
m

bi, p = 1
∀vi ∈ V,

(1)

p=1

—Delay-introducing blocks and their predecessor blocks (or protected resource-sharing
blocks) shall be assigned to the same core:
∀zi, j ∈ Z ∧ ∀Pp ∈ P, bi, p − b j, p = 0
(2)
—Start time of every repetition of a block shall be greater than or equal to its firing
time:
(3)
∀vi,c ∈ M, si,c ≥ c πi
—Execution of every repetition of a block shall be completed within the block’s period:
∀vi,c ∈ M, si,c + wi ≤ (c + 1) πi

(4)

—If there is a data connection from a block vi to a block v j in which both blocks have the
same period, then block v j shall not start execution until (i) block vi finishes execution
and transmission of its output data to its successor blocks that are mapped on other
cores and (ii) block v j finishes receiving all of its input data that are sent by the
blocks on other cores:
Considering that block vi is mapped to the core Pp and v j is mapped to the core Pq ,
∀Pp, Pq ∈ P, ∀vi,c , v j,c ∈ M s.t. (vi , v j ) ∈ E, πi = π j = Rk ∈ R, vi , v j ∈ Vk ,
si,c + wi +


vx

∈Vk

[txi,x (1 − bx, p)] ≤ s j,c −


vy

[rxy, j (1 − by,q )] + (2 − bi, p − b j,q ) MAX

(5)

∈Vk

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:13

—Execution of independent blocks with the same period that are mapped to the same
core shall not overlap:
Considering an independent pair of blocks vi and v j , which is mapped to the same
core Pp, we have two different constraints for this requirement:
∀Pp ∈ P, ∀vi,c , v j,c ∈ M s.t. (vi G v j ) ∧ (v j G vi ), πi = π j = Rk ∈ R, vi , v j ∈ Vk ,


si,c + wi +

vx ∈Vk

s j,c + w j +



[txi,x (1 − bx, p)] ≤ s j,c −

[rxy, j (1 − by, p)] + (3 − bi, p − b j, p − di, j ) MAX (6)

v y ∈Vk



[tx j,y (1 − by, p)] ≤ si,c −

v y ∈Vk



[rxx,i (1 − bx, p)] + (2 − bi, p − b j, p + di, j ) MAX (7)

vx ∈Vk

Here, we use the notation (vi G v j ) to represent that no path from vi to v j exists
in G. Since MAX is a very large constant, Equation (6) will be valid when block vi,c
executes before v j,c , that is, when di, j = 1, and Equation (7) will be valid when block
vi,c executes after v j,c , that is, when di, j = 0.
—A block shall (i) either finish execution and output transmission before an upcoming
firing time where smaller period block executions are fired (ii) or start execution after
all the blocks with a smaller period in an upcoming firing time are finished:
∀Pp ∈ P, ∀vi,c , v j,c ∈ M, ∀Fw ∈ F s.t. cπi < Fw < (c + 1)πi
where πi = Rk ∈ R, i.e., vi ∈ Vk , πi > π j = Rl ∈ R, v j ∈ Vl , Fw = c π j , c ∈ N,
si,c + wi +


vx

s j,c + w j +


v y ∈Vl

[txi,x (1 − bx, p)] ≤ Fw + (2 − bi, p − dic ,w ) MAX

(8)

∈Vk

[tx j,y (1 − by, p)] ≤ si,c −



[rxx,i (1 − bx, p)] + (2 − bi, p − b j, p + dic ,w ) MAX (9)

vx ∈Vk

Since MAX is a very large constant, Equation (8) will be valid when block vi,c executes
before Fw , that is, when dic ,w = 1 and Equation (9) will be valid when block vi,c
executes after low period blocks fired at Fw , that is, when dic ,w = 0.
Considering the execution order between a block and an upcoming firing time, the
following constraint must also be added to make sure that if the parameter dic ,w is 0
(block vi,c executes after Fw ), then dic ,w̄ is also 0 for all Fw̄ < Fw (block vi,c executes
after Fw̄ ).
∀vi,c ∈ M, ∀Fw , Fw̄ ∈ F s.t. cπi ≤ Fw̄ < Fw < (c + 1)πi , Fw = c π j , Fw̄ = c πk
where πi > π j , πi > πk, πi , π j , πk ∈ R, c , c ∈ N,
dic ,w̄ < dic ,w

(10)

—Blocks shall not start execution until other blocks with smaller periods from same or
previous firing times finish their execution and transmission of their outputs when
these blocks are mapped to the same core:
∀Pp ∈ P, ∀vi,c , v j,c ∈ M, Fw ∈ F s.t. Fw = c π j ≤ cπi < (c + 1)π j
where c, c ∈ N, πi = Rk ∈ R, i.e., vi ∈ Vk and πi > π j = Rl ∈ R, i.e.,v j ∈ Vl ,

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:14

C. E. Tuncali et al.

s j,c + w j +



[tx j,x (1 − bx, p)] ≤ si,c −

vx ∈Vk



[rxy,i (1 − by, p)] + (2 − bi, p − b j, p) MAX (11)

v y ∈Vl

—Since the intercore communications are done over the available limited shared memory space, the total memory needed for semaphores and communication buffers shall
be less than or equal to the total amount of available shared memory:
⎡



	


m


ci, j
⎣
sSize +
aSize |bi, p − b j, p|
aSize
p=1 (vi ,v j )∈E,πi =π j
(12)
⎤



	



ck,l
sSize + cCount
aSize |bk, p − bl, p| ⎦ < totMem
+
aSize
(k,l)∈E,πk =πl

4.4. Objective Function

For single-rate models, where πi = π for all vi ∈ V, we focus on Problem 1. In this case,
the goal is to minimize the makespan for one iteration of the model execution, and the
objective function for the MILP problem is to minimize π as described in our previous
paper [Tuncali et al. 2015].
For multirate models, that is, πi = π j for some vi , v j ∈ V, we do not impose any
objective function on the MILP formulation as it already includes the scheduling constraints. Since single-rate models can be considered as a special case of the multirate
models, one can also use the multirate approach for parallelization of single-rate models. With this approach, instead of seeking the minimum makespan, one can seek a
feasible mapping for a predetermined makespan, which can also help in decreasing the
solver execution time for single-rate models.
4.5. Improving Solver Execution Time

In this section, we introduce our heuristic techniques for dealing with large models.
The heuristics described in this section are targeting single-rate models, that is,
Problem 1. These heuristics can be adapted for Problem 2 as well. That is, for
multirate models, they can be applied only to the blocks with the same rate. However,
we do not expect them to be as useful as they are for Problem 1 since they can
eliminate opportunities to fit blocks with lower rates in between the completion time
of the higher rate blocks and the upcoming firing times.
For two same-rate blocks, if there exists a directed path between the corresponding vertices in the BDG, then we say that these blocks are dependent on each other.
Otherwise, we say that these blocks are independent of each other.
The majority of the constraints in the MILP formulation are related to the execution
ordering of the independent blocks, that is, the inequalities Equations (6) and (7). This is
because, for blocks dependent on each other, the execution of each block has constraints
related to the directly connected blocks. These relations also impose lower and upper
bounds for execution time of the blocks and limit the search space for each block’s
execution. Thus, the solver execution time is not dramatically affected by increasing
the number of dependent blocks. However, there are constraints between each pair of
independent blocks. The number of combinations for independence relations between
the blocks quadratically increases as the model size increases for most industrial size
applications. The heuristics that we introduce are targeting to decrease the number
of or completely eliminate these constraints for independent blocks. These heuristics
impose some restrictions on the execution ordering of the blocks. Thus, given infinite
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:15

time, the solver will be seeking a less optimal solution. However, since we limit the
solver execution time, it becomes very hard, if not impossible, to find an optimal or
even a feasible solution without heuristics. However, with heuristics, the solver can
find solutions with larger speedup values in a limited execution time, even though the
solutions may not be the globally optimal solutions for the original problem.
4.5.1. Partial Ordering of Independent Blocks. In order to have more parallelization opportunities in a model, the flattened block diagram must preferably have a large number
of blocks that are independent of each other. Typically, in an industrial-sized model
with a large number of blocks, both the number of blocks that are independent of each
other and the number of blocks that are dependent on each other are large. However,
if the number of blocks that are independent of each other is very large, then when
we consider all possible combinations of execution orders between these independent
blocks, the number of constraints introduced by inequalities Equations (6) and (7) becomes very large. As a consequence, finding an optimal solution within a feasible time
becomes harder.
We address this problem by deciding the execution order between certain pairs of independent blocks—say, vi , v j —in advance. That is, before formulating the optimization
problem, we decide the values of the di, j variables for these block pairs. Since the di, j
variables become constants in this case, the MILP solver does not need to seek their
values. Also, since at least one of the inequalities Equations (6) and (7) becomes invalid
(satisfied always), the number of constraints for the MILP formulation decreases. Note
that our execution order decision is valid only when these blocks are mapped onto the
same core. Thus, this does not prevent these blocks from being mapped on different
cores, thus executed in a different order than what we specify.
Our partial-ordering heuristic is based on comparing the execution start time frames
of independent blocks. The execution start time frame of a block is defined as the time
frame between its best-case and worst-case start-time values. The best-case and worstcase start-time values of a block vi ∈ V are defined as bsi and wsi respectively. The
variable bsi is determined by using the best-case completion time for all of the blocks
corresponding to the vertices from which there exists a path to vi ∈ V in G. In the best
case, all of this workload before the block vi is distributed equally on all of the cores.

−
→
→ wk)/m, where Yi = {vk : vk ∈
The best-case start time of vi is calculated as bsi = ( v ∈−
k Yi
V, πk = πi and there exists a path from vk to vi in G}. The variable wsi is determined by
using the best-case completion time for all of the blocks corresponding to the vertices to
which there is a path from vi ∈ V in G and the WCET of the block
vi itself, subtracted
− wk)/m, where
from the deadline. The WCET of vi is calculated as wsi = πi − (wi + v ∈←
k Yi
←
−
Yi = {vk : vk ∈ V, πk = πi and there exists a path from vi to vk in G}.
For all independent block pairs vi , v j ∈ V, if ((bs(i) ≤ bs( j))∧(ws(i) < ws( j)))∨((bs(i) <
bs( j)) ∧ (ws(i) ≤ ws( j))), then we decide vi to execute before v j by setting di, j to 1.
Otherwise, if ((bs(i) ≥ bs( j)) ∧ (ws(i) > ws( j))) ∨ ((bs(i) > bs( j)) ∧ (ws(i) ≥ ws( j))), then
we decide vi to execute after v j by setting di, j to 0. If we compute di, j as 1, then we
replace the di, j in Equation (6) with 1, and we do not add the constraint given by
Equation (7) into the formulation. Similarly, if we compute di, j as 0, then we replace
the di, j in Equation (7) with 0, and we do not add the constraint given by Equation (6).
4.5.2. Total Ordering of Independent Blocks. Even though ordering independent blocks
using the partial-ordering heuristic improves the performance, this may not be enough
for models with a very large number of blocks. For example, we could not find a feasible
solution to models with more than 100 blocks with this approach. For dealing with
those large models, we propose deciding the execution order of all the independent
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:16

C. E. Tuncali et al.

blocks when they are mapped on the same core. The intuition behind the total-ordering
heuristic is based on comparing the midpoints of the execution start-time frames for
these blocks. For independent blocks vi , v j ∈ V, if (bsi + wsi )/2 < (bs j + ws j )/2, then
we decide vi to be executed before v j , and vice versa if otherwise. Thus, we replace
the di, j values in Equations (6) and (7) to the calculated values, and we do not add the
constraint defined by Equation (6) when di, j is 0. Similarly, we do not add the constraint
defined by Equation (7) when di, j is 1 into our formulation. Here, the decided value for
di, j determines the ordering of the blocks only when they are mapped to the same core
and our discussion on the case when these blocks are mapped to different cores in the
previous section is still valid.
4.5.3. Merging Highly Coupled Blocks. In this heuristic, we merge blocks vi and v j when
block v j is the only block connected to the output port(s) of block vi and block vi is the
only block connected to the input port(s) of block v j . The merging operation copies all
incoming and outgoing edges of v j to vi except the edge (vi , v j ) between these blocks.
Then, it updates wi with wi + w j and, finally, it deletes v j .
4.5.4. Merging Small Blocks with Large Blocks. In this heuristic, we merge blocks vi and
v j based on their ratio of execution times. If block v j is the only block connected to
the output port(s) of block vi and the WCET of block vi is very small when compared
to the WCET of block v j , then block vi is merged into block v j . If block vi is the only
block connected to the input port(s) of block v j and the WCET of block v j is very small
when compared to the WCET of block vi , then block v j is merged into block vi . We
find this technique useful for reducing the number of blocks of concern in a way that
parallelization will be focused on blocks with higher impact on execution time. The ratio
between the WCETs of the blocks for determining a merge operation can be defined
depending on how much reduction is needed in the number of blocks.
These merging heuristics can be used for decreasing the number of nodes in very
large models in which the MILP solver can no longer find a good solution. These
merging techniques are also dependent on the structure of the model. Although, in
general, they assist in finding better solutions, there can be cases in which the number
of nodes cannot be reduced to an acceptable level.
5. IMPLEMENTATION
R
In this section, we describe the details of the implementation of our tool in MATLAB
.
Some of the concepts explained here were described earlier in Section 3.
Our tool accepts as an input a block diagram of a Simulink model that is ready
to compile. The user can also input the desired depth of blocks to be parallelized.
The desired depth sets an upper bound on the hierarchical depth for the flattening
operation done on the model block diagram. Even though the desired depth is set, if
there is a delay introducing a block that has a larger depth, it will still be discovered
and flattening will be performed in order to flatten the hierarchy for such a block.
This is because a macro block containing such a delay-introducing block can cause a
cycle in the block diagram that must be handled. In Simulink, public “Goto”–“From”
block pairs can create data dependencies between the blocks in different hierarchical
levels. Thus, for the subsystems that have a public virtual (“Goto”–“From”) connection
with any block outside the subsystem, the user-defined desired depth is ignored and
flattening is performed. Since determining the WCET is not in scope of this article, we
assume that the WCET for each block is already determined and given as an input to
the tool.
The first step in our approach is to create a BDG from the given model block diagram.
Our tool loads the model block diagram, reads specific block information, for example,
block type, parents, and sample time, and all the relations between blocks along with

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:17

the width and size of the data on the ports. For datatypes that are not built in, the
user input is required to define the data size in bytes. The block diagram is flattened
by taking blocks inside subsystems out of their parent blocks and by discarding the
remaining blocks, such as input and output ports of subsystems and the emptied
subsystem container blocks. Simulink provides virtual routing blocks like “Goto” and
“From.” These virtual routing blocks serve the purpose of virtually adding a connection
between the blocks. Thus, these blocks do not really perform an operation and they are
only virtual blocks that help the designer to create connections between the blocks in
a cosmetically nice way. Our tool discards these virtual routing blocks and considers
them as regular lines connecting the blocks in the model. After these operations, we
end up with having the flattened block diagram of the model as illustrated in Figure 3.
Our tool then creates a directed graph representation of the flattened block diagram. The vertices of this directed graph correspond to the blocks in the flattened
block diagram and the directed edges correspond to the connections from one block
to another. Then, the tool removes the incoming edges to delay-introducing blocks.
The delay-introducing blocks contain states that are initialized to a value, and in an
iteration (including the first iteration), their outputs depend on their internal states.
Thus, removing the incoming edges of such blocks removes any possible cycles without
violating execution order dependencies. An issue arising here is that since we remove
these edges, the data connection from a block to a delay-introducing block is no longer
considered and we can fail to model an intercore communication if a delay-introducing
block and its predecessor block are mapped to different cores. For resolving this issue,
we keep track of such block pairs for forcing them to be mapped on the same core. At
this point, we have a BDG representation of the flattened block diagram, as given in
Figure 4. The merge-based heuristics that are described in Section 4.5 are executed on
the BDG in order to obtain a smaller-sized graph, if the user chooses to apply them.
The BDG and the number of CPU cores on the target architecture are used in
generating the MILP formulation presented in Section 4. Our tool takes the MILP
solver to be used as an input option and executes this solver with an upper bound on
solver execution time, which, again, is taken from the user as an input option. For the
multirate models, the tool generates the BDGs for every distinct sample rate value.
The BDG for a sample rate contains the blocks with the same sample rate and the data
dependencies between these blocks. Since the rate-transition blocks have one sample
rate for their inputs and another sample rate for their outputs, they are added to
both sample rate graphs. The WCET of the rate-transition blocks may be different for
different sample rates. When there is more than one sample rate, the problem must
be solved to satisfy the constraints for all tasks in a hyperperiod. For this purpose,
the hyperperiod is calculated as the least common multiple of the distinct sample
periods. During a hyperperiod H, a task containing the blocks with a period π will be
repeated H/π times. The starting time for each of these repetitions in the hyperperiod
is called the firing time. The tool calculates the firing times and determines the periods
and the blocks corresponding to each firing time. The BDGs for the whole model and
for the distinct period values,—together with the hyperperiod, the firing times, and the
periods/blocks corresponding to the firing times—are used in the MILP formulation
described in Section 4. The MILP solver seeks a feasible mapping of blocks to the
CPU cores satisfying the constraints and returns the mapping found and execution
start times for all the executions of the blocks during the hyperperiod. The MILP
solver returns the solution for mapping the blocks to the available CPU cores and
the execution order between these blocks if a feasible solution is found. If no feasible
solution is found, the MILP solver reports this and our tool as well reports this to the
user and exits.

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:18

C. E. Tuncali et al.

Fig. 6. Intercore communication blocks (the coloring of the blocks represents core mapping).

The solution from the MILP solver is used to add intercore communication blocks
between the blocks with the same period that are mapped on different CPU cores. The
relevant outputs of a block that are sending data to a block on a different core are connected to intercore data transmitting S-function blocks. Similarly, the corresponding
intercore data receiving S-function blocks for each transmitter are connected to the
relevant inputs of the block that is receiving data on a different core. The intercore
communication blocks are added by setting unique IDs that set each pair of transmitting and receiving blocks to use a dedicated intercore semaphore and a dedicated
shared memory location. For the multirate models, the intercore rate-transition blocks
that are described in Section 3 are added between the different rate blocks mapped on
the different cores that have a data communication between each other.
An example of the transformation of a block diagram for intercore communication of
the same rate blocks is given in Figure 6. The output of B1 is connected to the input of B2
in the original model. This connection is then replaced by the intercore communication
blocks. After adding all needed communication blocks, we set the priority attributes
of the Simulink blocks using the execution start-time values obtained from the optimization solution. This is done in order to guarantee that for every iteration in the
sampling process of the Simulink model, the total order of the block execution induced
by Simulink is consistent with the partial order of the BDG that we create that imposes
the MILP formulation constraints. Embedded Coder uses the priority attributes of the
blocks with respect to the other blocks in the same subsystem, as an execution ordering
that is reflected to the generated code as long as the priority settings do not conflict
with the data dependencies between the blocks. Because of this behavior of Embedded
Coder, depending on the selected model depth for the parallelization, our tool may be
implicitly suggesting a different structure for the model, that is, splitting subsystems
into more than one subsystem through the execution ordering of the blocks. While this
can be automated, our tool does not change the structure of the model automatically;
rather, it leaves this to the control engineer.
As the final step, a copy of the model is created for each CPU core in which the
blocks that are mapped on other cores are commented out. Code generated from each
of these models can be compiled to create separate executables for each core. For the
multirate models, Simulink generates separate functions for different sample periods.
These functions are executed in different tasks and these tasks are scheduled by the
rate-monotonic scheduling algorithm on the target platform, as described by Bulusu
[2014].
6. EXPERIMENTS

For studying the scalability and efficiency of our approach for the single-rate models,
we utilize randomly generated DAGs with different numbers of nodes. We present
the results of these experiments in Section 6.1 and the results of our case studies
for single-rate models in Section 6.3. We illustrate our approach for multirate models
with a simple example in Section 6.2. We use SCIP from Achterberg [2009] as the
MILP solver, which is interfaced with MATLAB through the Opti Toolbox by Currie
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:19

R
R
R
and Wilson [2012]. Experiments are run on a Microsoft
Windows
7 PC with Intel
R
Xeon
E5-2670 CPU and 64GB RAM.

6.1. Randomly Generated DAGs

For evaluating performance of our approach for single-rate models, we generate random
DAGs in which the WCET, communication costs, and connections between blocks are
assigned randomly. We use the random DAG generator tool provided by Gwinner [2011].
Then, we solve Problem 1 for a dual-core system with the basic MILP formulation
given in Section 4 and with the partial- and total-ordering heuristics for deciding the
execution order of any independent blocks. We set 5h (18,000s) as an acceptable upper
time limit for the solver runtime, which is a time bound that the MILP solver cannot
return a solution on the larger-sized DAGs without using the proposed heuristics.
We have done 500 experiments with different-sized and completely random DAGs for
increasing the confidence level in the benchmarks. Here, we present a comparison of
the performance of these three approaches in terms of the average speed-up achieved,
the average solver execution time, and the ability to find a solution in the given time
limit. The speedup is computed as the overall single-core WCET of the model divided
by the overall WCET of the parallelized model.
Given infinite solver execution time, the basic MILP formulation is expected to find
more optimal solutions than the other approaches do for the same problem size. However, when the solver execution time is limited (5h in our experiments), it fails to find
satisfactory solutions for large problems. Table II gives a comparison of the performance of the different approaches with the number of tests executed for each problem
size. The average speedup achieved by basic MILP formulation, the partial- and the
total-ordering heuristics (denoted as basic, partial, and total, resp.,) and corresponding
solver runtime values are presented in the table for different problem sizes. We also
present the ratio of the solutions found over all the experiments. For a problem size, the
lines corresponding to the approaches that could not return any solutions are discarded
in the table. As it can be seen from the results presented in Table II, as the number
of blocks in a model increases, any heuristic that (partially) sets the execution order
performs better both in terms of solver runtime and optimality of solutions. According
to our observations, for finding an optimal mapping, the basic MILP formulation performs best when there are less than 30 blocks. The partial-ordering heuristic performs
best when there are 30 to 50 blocks. For more than 50 blocks in the model, the totalordering heuristic outperforms other approaches in terms of the achieved speedup and
the ability to return a solution. The basic MILP formulation fails to return any solution
for models with 70 or more blocks. The partial-ordering heuristic fails to return any
solution for models with more than 110 blocks. Although this detail is not illustrated in
Table II because of averaging, according to our experimental results, the total-ordering
heuristic can occasionally achieve very low speedup values compared to the other approaches when there are less than 20 blocks in the model. However, this issue is not
observed when there is a large number of blocks. This behavior is parallel to our expectations since optimization can significantly reduce the effect of possible nonoptimal
execution-order decisions by trying a large number of different mappings of blocks to
different cores.
In Figure 7, we illustrate the comparison between the two heuristics and the basic
MILP formulation in terms of the achieved speedup over the number of nodes. The solid
lines in the plot represent how much average speedup is achieved by each approach.
The dashed lines represent the corresponding minimum and maximum speedup for
each approach. For very small numbers of nodes, the basic MILP formulation is better
than the other approaches. However, when the number of nodes increases, first, the
partial-ordering heuristic and, then, the total-ordering heuristic perform best.
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:20

C. E. Tuncali et al.
Table II. Comparison of Different Approaches

# Nodes
10–15

30

40

50

60
70
80
90
100
110
130
150
170

Approach
Basic
Partial
Total
Basic
Partial
Total
Basic
Partial
Total
Basic
Partial
Total
Basic
Partial
Total
Partial
Total
Partial
Total
Partial
Total
Partial
Total
Partial
Total
Total
Total
Total

Average speed-up
1.48
1.47
1.46
1.68
1.71
1.46
1.48
1.62
1.55
1.2
1.66
1.67
1.09
1.55
1.59
1.54
1.75
1.39
1.7
1.38
1.61
1.08
1.64
1.04
1.67
1.56
1.62
1.61

Average
solver time
(seconds)
2
1
0.5
2620
1558
26
9256
2091
606
18000
12481
5174
18000
17400
11685
18000
18000
18000
18000
18000
18000
18000
18000
18000
18000
18000
18000
18000

% found
Solutions
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
100%
64%
100%
100%
100%
100%
100%
100%
60%
100%
50%
100%
30%
100%
100%
100%
100%

# Tests
150

50

50

50

50
30
30
20
30
10
10
10
10

Fig. 7. Comparison of speedup values between different approaches.

In Figure 8, we illustrate the comparison between the two heuristics and the basic
MILP formulation in terms of the average solver execution time over the number
of nodes. Each line in the graph represents the average solver execution time spent
for each approach. As is expected, due to the time limit given to the solver, as the
number of nodes increases, the solution times for all approaches converge. However,
the experiments on models with smaller numbers of nodes suggests that the proposed
heuristics can shorten the solver execution time. In the graph, it can be observed
that the average solver execution time for the proposed heuristics (as a function of
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:21

Fig. 8. Comparison of solver execution time between different approaches.

Fig. 9. An example multirate block diagram.

node count) is smaller than the basic formulation. Combining the observations from
Figures 7 and 8, we can see that the total-ordering heuristic returns better solutions
within shorter solver runtime compared to the other approaches.
6.2. An Example on Multirate Models

We illustrate our approach for multirate models on a simple synthetic example. Figure 9
illustrates the block diagram of an example model. We included WCET and sampling
period information for each block in Figure 9. The notation for this information is in the
format “block name, (WCET:sampling period).” For instance, the block “A” has a WCET
of 1ms and a sampling period of 20ms. It can be seen that the blocks “A” to “G” have a
sampling period of 20ms, while the blocks “H” to “Y” have a sampling period of 80ms.
The blocks “RT1” and “RT2” are Simulink built-in rate-transition blocks that provide a
mechanism for data transfer between the blocks of different rates. The rate-transition
blocks will have their inputs and outputs executing on different sampling periods. In
this example, “RT1” has a sampling period of 20ms for its input and 80ms for its output,
and “RT2” has a sampling period of 80ms for its input and 20ms for its output. For
the rate-transition blocks, we provide the WCETs for both sampling periods, separated
by a comma. The intercore communication costs are 8μs for transmission and 8μs for
reception for any data connection between the blocks.
The total WCET is 13ms for the blocks with the sampling period of 20ms, including
the executions of rate-transition blocks for this sampling period. The total WCET for
the blocks with the sampling period of 80ms is 90ms. This makes a task generated
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:22

C. E. Tuncali et al.

Fig. 10. Block dependency graph for 20ms.

Fig. 11. Block dependency graph for 80ms.

from the blocks with period 80ms not schedulable without seeking a feasible partition
of the blocks to multiple cores.
Our tool computes the hyperperiod as H = lcm(20, 80) = 80ms, where lcm() computes
the least common multiple of its parameters. The firing times in the hyperperiod are
given as F = {0, 20, 40, 60} in milliseconds, which are the multiples of the sampling
periods during the hyperperiod. Note that the firing time at 80ms is actually the
beginning of the next iteration of the hyperperiod. The blocks with the sampling period
of 20ms are fired at every firing time. On the other hand, the blocks with a sampling
period of 80ms are only fired at the beginning of the hyperperiod. Then, the BDGs for
each rate are created. Figures 10 and 11 give the BDGs for the sampling periods of
20ms and 80ms, respectively.
In the next step, the MILP solver is utilized to find a feasible mapping for the blocks.
Here, we target a dual-core architecture. The updated model with the block-to-core
mapping is given in Figure 12. For any connection between different cores, we add
an intercore sender block to the sending core and an intercore receiver block to the
receiving core. Because of space considerations, we cannot provide the figures of the
model for each core here. In brief, the copy of the model for each core has the blocks of
the other core commented out. Thus, in the generated model for Core 1, only the blocks
that are mapped to Core 1 are active, while all the others are commented out and vice
versa for Core 2. With this suggested mapping and computed ordering of the blocks,
all of the blocks can complete execution in their periods on a multicore architecture.
Figure 13 gives the core mapping of the blocks with the execution-time information in
a hyperperiod. The horizontal lines illustrate the execution of each block. The notation
for the labels is (block name, execution copy in hyperperiod : sampling time). For
instance (RT1, 0 : 20) corresponds to the execution copy 0 of “RT1” block for sampling
period 20ms. Note that the copy counts start from 0 for the first execution. The ratetransition blocks “RT1” and “RT2” execute for both sampling periods. In Figure 13, we
can observe that, at every firing time, first, the blocks with smaller sampling periods
are executed first; then, the blocks from larger sampling periods are executed. For
instance, on the CPU core 1, in the time window starting from the firing time at 0ms,
up to the firing time at 20ms, first, the blocks with a period of 20ms are executed.
After execution of these blocks is completed, blocks with a period of 80ms, which have
a total WCET smaller than or equal to the remaining time to the next firing time, that
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:23

Fig. 12. Updated model for multicore partitioning (contains blocks for both cores).

Fig. 13. CPU core mapping and execution information of blocks.

is, the part of “RT1” for 80ms and the block “J,” are executed. Note that the execution
information is based on WCETs. An actual execution on the target platform would have
the same execution ordering with possibly shorter execution durations and earlier start
times (since an actual execution time may be shorter then the WCET).
6.3. Case Study: Toyota Diesel Engine Controller

We used the diesel engine controller model from Huang et al. [2013] as a single-rate
case study from the industry. The model has 1004 blocks when flattened, as described
in Section 5. It has 7 inputs that are multiplexed into a single-input bus signal and
6 outputs that are multiplexed into a single-output bus signal. Since the model has
cycles inside the subsystems, our tool flattens the model by searching all blocks inside
virtual subsystems, breaks the cycles as described in Section 5, and merges blocks
inside subsystems without introducing new cycles. For parallelizing this model, we set
the target model depth to 2. The BDG capturing a flattened representation of the model
up to the target model depth is generated. The generated BDG contains 153 nodes and
a total of 184 connections between these nodes. Our target platform for this case study
is the dual-core architecture from Freescale, which is described in Section 3. In our
target hardware setup, we have a total of 3.8KB shared memory available.
For a model of this size, both the basic MILP formulation and the partial ordering
heuristic fail to find a solution in 10h. However, by merging blocks of subsystems with
depth more than 2, and using our total-ordering heuristic, our tool returned a solution
to the given problem within an average of 1.2h of solver time. Here, the average is
taken over 20 experiments with different sets of WCET assignments, that is, with
randomly generated WCETs that are proportional to the complexity of the blocks. The
ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:24

C. E. Tuncali et al.

tool suggested multicore mappings with a speedup factor of 1.44, on average. This result
is parallel with our expectations based on the experiments carried out on randomly
generated DAGs, and it illustrates the applicability of our approach to reasonably large
problems in industry.
7. CONCLUSIONS

In this article, we present an approach for parallelizing single-rate and multirate
block diagram models on multi-core architectures. We propose a heuristic for partially
deciding execution order of independent blocks when they are mapped to the same core.
According to the experimental results for single-rate models with randomly generated
DAGs, the MILP solver returns better solutions with this proposed heuristic in a
reasonable limited solver execution time for models with around 50 to 60 blocks in
our experimental environment. For models with a larger number of blocks, we propose
another heuristic in which the execution order of all the independent blocks is decided
in advance. With this approach, our tool could handle models larger than 150 blocks.
We present this heuristic together with block-merging methods on a single-rate case
study from the industry, in which our tool reduced 1004 blocks to 153 nodes on the
BDG, and solved the problem on the reduced BDG. The results from the case study
illustrate how our approach can handle single-rate models that are large enough for
a practical application in industry. The introduced heuristics may not be as useful in
multirate models, because these heuristics may eliminate the opportunity to fit small
blocks in the idle times of the schedule in which no higher-priority task is executing.
For future work, we consider extending this work by introducing heuristics for
solving the optimization problem for the multirate models, and by studying models
with blocks that have priority assignments. In addition, available parallelization under
different triggering conditions should be further analyzed for the event-triggered
models to get more optimal results. For large models, in order to improve efficiency of
the heuristics, investigating control-flow level parallelization opportunities inside the
models is another promising approach to be studied. Similar to the schedule-generation
approach proposed by Lee et al. [2012], a depth-first traversal on the BDG can be done
to explore the model, and the merging of the blocks can be done in a smarter way
based on the parallel paths in the graph. Furthermore, we plan to incorporate WCET
estimation tools in our framework.
ACKNOWLEDGMENTS
We would like to thank Dr. Ken Butts and Toyota Technical Center for providing us the diesel engine model.

REFERENCES
Karl J. Åström and Björn Wittenmark. 1997. Computer-controlled Systems (3rd ed.). Prentice-Hall, Inc.,
Upper Saddle River, NJ.
Tobias Achterberg. 2009. SCIP: Solving constraint integer programs. Mathematical Programming Computation 1, 1, 1–41.
Ahmad Al Sheikh, Olivier Brun, Pierre-Emmanuel Hladik, and Balakrishna J. Prabhu. 2012. Strictly periodic
scheduling in IMA-based architectures. Real-Time Systems 48, 4, 359–386.
AUTOSAR. 2015. AUTOSAR Specification.Retrieved September 7, 2016 from http://www.autosar.org.
Sanjoy Baruah. 2015. The federated scheduling of systems of conditional sporadic DAG tasks. In Proceedings
of the 12th International Conference on Embedded Software (EMSOFT’15). IEEE Press, Piscataway, NJ,
1–10. http://dl.acm.org/citation.cfm?id=2830865.2830866
Armin Bender. 1996. Design of an optimal loosely coupled heterogeneous multiprocessor system. In European
Design and Test Conference (ED&TC’96). Proceedings. IEEE, 275–281.
Girish Rao Bulusu. 2014. Asymmetric Multiprocessing Real Time Operating System on Multicore Platforms.
Master’s thesis. Arizona State University, Tempe, AZ.

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

Automatic Parallelization of Multirate Block Diagrams of Control Systems

15:25

Arquimedes Canedo, Takeo Yoshizawa, and Hideaki Komatsu. 2010. Automatic parallelization of Simulink
applications. In Proceedings of the 8th Annual IEEE/ACM International Symposium on Code Generation
and Optimization. ACM, 151–159.
Paul Caspi, Norman Scaife, Christos Sofronis, and Stavros Tripakis. 2008. Semantics-preserving multitask
implementation of synchronous programs. ACM Transactions on Embedded Computing Systems 7, 2,
15.
CAST. 2014. Position Paper CAST-32 Multi-core Processors. Technical Report. Federal Aviation Administration.
Minji Cha, Kyong Hoon Kim, Chung Jae Lee, Dojun Ha, and Byoung Soo Kim. 2011. Deriving highperformance real-time multicore systems based on Simulink applications. In IEEE Ninth International
Conference on Dependable, Autonomic and Secure Computing (DASC’11). IEEE, 267–274.
Jing Chen and Alan Burns. 1997. A three-slot asynchronous reader/writer mechanism for multiprocessor
real-time systems. Report-University of York Department of Computer Science YCS.
Scott Cotton, Oded Maler, Julien Legriel, and Selma Saidi. 2011. Multi-criteria optimization for mapping
programs to multi-processors. In 6th IEEE International Symposium on Industrial Embedded Systems
(SIES). IEEE, 9–17.
Jonathan Currie and David I. Wilson. 2012. OPTI: Lowering the barrier between open source optimizers and
the industrial MATLAB user. Foundations of Computer-aided Process Operations. 8–11.
Robert I. Davis and Alan Burns. 2011. A survey of hard real-time scheduling for multiprocessor systems.
ACM Computing Surveys 43, 4, 35.
Peng Deng, Fabio Cremona, Qi Zhu, Marco Di Natale, and Haibo Zeng. 2015. A model-based synthesis flow
for automotive CPS. In Proceedings of the ACM/IEEE 6th International Conference on Cyber-Physical
Systems. ACM, 198–207.
EASA. 2012. EASA/2011/6 Final Report. Technical Report. European Aviation Safety Agency.
Johan Eker, Jörn W. Janneck, Edward Lee, Jie Liu, Xiaojun Liu, Jozsef Ludvig, Stephen Neuendorffer, Sonia
Sachs, Yuhong Xiong, and others. 2003. Taming heterogeneity-the Ptolemy approach. Proceedings of
IEEE 91, 1, 127–144.
Ahmed Elhossini, John Huissman, Basil Debowski, Shawki Areibi, and Robert Dony. 2010. An efficient
scheduling methodology for heterogeneous multi-core processor systems. In International Conference on
Microelectronics (ICM’10). IEEE, 475–478.
Juraj Feljan and Jan Carlson. 2014. Task allocation optimization for multicore embedded systems. In 40th
EUROMICRO Conference on Software Engineering and Advanced Applications. IEEE, 237–244.
Julien Forget, Frédéric Boniol, David Lesens, and Claire Pagetti. 2010. A real-time architecture design language for multi-rate embedded control systems. In 25th ACM Symposium on Applied Computing. Sierre,
Switzerland, 527–534. Retrieved September 7, 2016 from https://hal.archives-ouvertes.fr/hal-00688490
Raul Gorcitz, Emilien Kofman, Thomas Carle, Dumitru Potop-Butucaru, and Robert De Simone. 2015. On
the scalability of constraint solving for static/off-line real-time scheduling. In Formal Modeling and
Analysis of Timed Systems. Springer, 108–123.
Ronald L. Graham. 1969. Bounds on multiprocessing timing anomalies. SIAM Journal on Applied Mathematics 17, 2, 416–429.
Frederik Gwinner. 2011. Transitive reduction of a DAG v1.2. (2011). Retrieved September 7, 2016 from http://
www.mathworks.com/matlabcentral/fileexchange/32723-transitive-reduction-of-a-dag.
Pierre-Emmanuel Hladik, Hadrien Cambazard, Anne-Marie Déplanche, and Narendra Jussien. 2008. Solving a real-time allocation problem with constraint programming. Journal of Systems and Software 81,
1, 132–149.
Meng Huang, Hidemoto Nakada, Srinivas Polavarapu, Richard Choroszucha, Ken Butts, and Ilya
Kolmanovsky. 2013. Towards combining nonlinear and predictive control of diesel engines. In American Control Conference (ACC’13). IEEE, 2846–2853.
BaekGyu Kim, Linh TX Phan, Oleg Sokolsky, and Lnsup Lee. 2013. Platform-dependent code generation for
embedded real-time software. In International Conference on Compilers, Architecture and Synthesis for
Embedded Systems (CASES’13). IEEE, 1–10.
Raimund Kirner, Roland Lang, Peter Puschner, and Christopher Temple. 2000. Integrating WCET analysis
into a MATLAB/Simulink simulation model. In Proceedings of the 16th IFAC Workshop on Distributed
Computer Control Systems. 79–84.
Takahiro Kumura, Yuichi Nakamura, Nagisa Ishiura, Yoshinori Takeuchi, and Masaharu Imai. 2012. Model
based parallelization from the Simulink models and their sequential C code. In Proceedings of the
17th Workshop on Synthesis and System Integration of Mixed Information Technologies (SASIMI’12).
186–191.

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

15:26

C. E. Tuncali et al.

Edward Ashford Lee and Sanjit Arunkumar Seshia. 2015. Introduction to Embedded Systems - A CyberPhysical Systems Approach (2nd ed). LeeSeshia.org.
Haeseung Lee, Weijia Che, and Karam Chatha. 2012. Dynamic scheduling of stream programs on embedded
multi-core processors. In Proceedings of the 8th IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis. ACM, 93–102.
Roberto Lublinerman, Christian Szegedy, and Stavros Tripakis. 2009. Modular code generation from synchronous block diagrams: Modularity vs. code size. SIGPLAN Not. 44, 1, 78–89.
Roberto Lublinerman and Stavros Tripakis. 2008. Modular code generation from triggered and timed block
diagrams. In Real-Time and Embedded Technology and Applications Symposium. IEEE, 147–158.
Chris Ostler and Karam S. Chatha. 2007. An ILP formulation for system-level application mapping on
network processor architectures. In Proceedings of the Conference on Design, Automation and Test in
Europe. EDA Consortium, 99–104.
Claire Pagetti, David Saussié, Romain Gratia, Eric Noulard, and Pierre Siron. 2014. The ROSACE case study:
From Simulink specification to multi/many-core execution. In IEEE 20th Real-Time and Embedded
Technology and Applications Symposium (RTAS’14). IEEE, 309–318.
Wolfgang Puffitsch, Eric Noulard, and Claire Pagetti. 2015. Off-line mapping of multi-rate dependent task
sets to many-core platforms. Real-Time Systems 51, 5, 526–565.
Pranav Tendulkar, Peter Poplavko, Ioannis Galanommatis, and Oded Maler. 2014. Many-core scheduling of
data parallel applications using SMT solvers. In 17th Euromicro Conference on Digital System Design
(DSD). IEEE, 615–622.
Lothar Thiele and Pratyush Kumar. 2015. Can real-time systems be chaotic?. In Proceedings of the 12th
International Conference on Embedded Software. IEEE Press, 21–30.
Cumhur Erkan Tuncali, Georgios Fainekos, and Yann-Hang Lee. 2015. Automatic parallelization of Simulink
models for multi-core architectures. In IEEE 12th International Conference on Embedded Software and
Systems (ICESS). IEEE, 964–971.
Dan Umeda, Takahiro Suzuki, Hiroki Mikami, Keiji Kimura, and Hironori Kasahara. 2015. Multigrain
parallelization for model-based design applications using the OSCAR compiler. In Proceedings of the
28th International Workshop on Languages and Compilers for Parallel Computing. 151–165.
Ying Yi, Wei Han, Xin Zhao, Ahmet T. Erdogan, and Tughrul Arslan. 2009. An ILP formulation for task
mapping and scheduling on multi-core architectures. In Design, Automation & Test in Europe Conference
& Exhibition (DATE’09). IEEE, 33–38.
Received October 2015; revised February 2016; accepted May 2016

ACM Transactions on Embedded Computing Systems, Vol. 16, No. 1, Article 15, Publication date: October 2016.

2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)
Windsor Oceanico Hotel, Rio de Janeiro, Brazil, November 1-4, 2016

Traffic Light Status Detection Using Movement Patterns of Vehicles
Joseph Campbell1 , Heni Ben Amor1 , Marcelo H. Ang Jr.2 , and Georgios Fainekos1

Abstract— Vision-based methods for detecting the status of
traffic lights used in autonomous vehicles may be unreliable due
to occluded views, poor lighting conditions, or a dependence
on unavailable high-precision meta-data, which is troublesome
in such a safety-critical application. This paper proposes a
complementary detection approach based on an entirely new
source of information: the movement patterns of other nearby
vehicles. This approach is robust to traditional sources of error,
and may serve as a viable supplemental detection method. Several different classification models are presented for inferring
traffic light status based on these patterns. Their performance
is evaluated over real and simulated data sets, resulting in up
to 97% accuracy in each set.

Fig. 1: Example of traffic light occlusion by other vehicles.
The light is obscured in the left image but becomes visible
in the right image as the traffic starts moving.

I. I NTRODUCTION
One of the many challenges facing autonomous vehicles is
the ability to safely navigate complex environments such as
intersections while maintaining compliance with local traffic
regulations. Vehicles and pedestrians with varying directions
of travel cross paths while being guided by traffic lights
that are optimized for identification by human drivers. This
issue has been partially addressed with the introduction of
intelligent traffic light systems which actively communicate
their signal to nearby vehicles through Vehicular Ad Hoc
Networks [1], [2]. Nonetheless, as observed by [3], such
systems have thus far been limited to small-scale academic
experiments and a timely integration into current road networks seems unlikely.
It is for this reason that recent work has focused on the
real-time identification of traffic light signals via visionbased systems [3], [4]. This approach can work well but
is subject to errors that can lead to the misidentification
of the status of traffic light signals. These errors can arise
due to poor lighting conditions which interfere with the
camera sensor or an obstructed view resulting from a dirty
lens or another vehicle, as demonstrated in Fig. 1. This can
potentially lead to disastrous results – an autonomous vehicle
erroneously passing through an intersection could find itself
in a situation in which it is unable to avoid a collision.
This paper proposes a complementary traffic light identification system based on an alternative source of information:
the behavior of other nearby vehicles based on positional
data. Conceptually, the system infers the status of a traffic
light from the movements of other vehicles around or in the

corresponding intersection. The advantage of such a system
is not that it has fewer failure-inducing cases than a visionbased system, but rather that they are different failure cases.
Ideally, this system will be paired with a vision-based one
such that they complement each other and reduce the total
points of failure.
Consider the following scenario: a traffic light is nonfunctional due to an extenuating circumstance. As is typical
on US roads, a law enforcement officer is directing traffic
through the intersection. A typical vision-based recognition
system is of no help in this scenario, however, by observing
when other vehicles start to pass through the intersection and
from which direction, the proposed system can infer which
traffic the officer is allowing to pass through the intersection.
Similarly, consider a situation in which a vehicle stops at a
red light behind a larger vehicle that is occluding the traffic
light. Suppose the preceding vehicle suffers a mechanical
failure and is blocking traffic; the traffic light cycles through
its phases and surrounding traffic bypasses the offending
vehicle in other lanes. Once again, a vision-based system
would not be of assistance in this scenario; however, the
proposed system may indicate that the traffic light is green
and, therefore, alternative action should be taken.
The contributions of this paper are as follows: we present
a system for predicting the state of a traffic light based on
the spatial movement of nearby vehicles, and evaluate its
effectiveness in simulated and real-world conditions.
II. R ELATED W ORK
Vision-based traffic light detection systems have been
widely analyzed in previous works. The majority of these
works have focused purely on image recognition [5], [6],
[7], [8]. Of particular interest, however, are those that seek
to minimize the risk posed by errors inherent to vision-based
detection systems. In [4], the authors propose using a detailed
map of traffic lights to act as prior knowledge so that the

1 J. Campbell, H. B. Amor, and G. Fainekos are with the School
of Computing, Informatics, and Decision Systems Engineering, Arizona
State University, Tempe, AZ 85281, USA. {jacampb1, hbenamor,

fainekos}@asu.edu
2 M. H. Ang Jr. is with the National University of Singapore, Kent Ridge,
Singapore. mpeangh@asu.edu
This material is based upon work supported by the National Science
Foundation EAPSI Fellowship under Grant No. 1515589 and CPS 1446730.

978-1-5090-1889-5/16/$31.00 ©2016 IEEE

283


T
gn,t = xn,t , yn,t .

A

If we place the target vehicle at the origin of a Cartesian
coordinate plane with the positive x-axis extending towards
the front of the vehicle and the positive y-axis extending
towards the left-hand side of the vehicle, then x is the
distance along the x-axis from the target vehicle to the
observed vehicle n. Similarly, y is the distance along the yaxis to vehicle n. This yields a conditional probability of the
following form, where N is the total number of observable
vehicles at time t,

3
1

2
x
y

(1)

B

Fig. 2: A scenario in which vehicle A’s current position is
ambiguous, as there are multiple paths it could have taken
which could be used to infer different traffic light states.

p(zt |g1,t , g2,t , ..., gN,t ) = p(zt |g1:N,t ).

(2)

However, this approach has a potential drawback which is
visualized in Fig. 2. If vehicle A is an observable vehicle at
time t, it may have taken several different paths to arrive at
this position: path 1, 2, or 3. Each of these paths could result
in a different traffic light state zt . For example, if vehicle B
is our target vehicle and we are observing A, zt could be
green if vehicle A followed path 2, red if path 1, and either
green or red if path 3 (depending on local traffic regulations
for right-on-red turns). This leads to an ambiguous situation,
in which the state of vehicle A at this point in time does not
necessarily help us determine zt .
We can alleviate this problem if we consider a temporal
trace of the position. We could alter the vehicle state to
include information on the position over time in the form
of velocity,

detection system knows when it should be able to see traffic
lights. If traffic lights are not detected at an expected position,
the autonomous vehicle can take preventative action such as
slowing down under the assumption that the light is red or
yellow. However, this could have unintended consequences
since if the light is green this action may result in a collision
with human-operated vehicles due to unpredictability.
Similarly, in [3] the authors acknowledge the difficulties in
building a purely vision-based traffic light detection system
and so augment theirs with prior map knowledge as well
as temporal information. While yielding good results, the
system still fails to identify traffic light signals in certain
cases. Indeed, the authors indicate that a possible approach
for improvement would be to introduce 3-dimensional LIDAR data into the mix in order to improve recognition of
the traffic lights themselves.
In [9], the authors use the movement patterns of pedestrians to apply semantic labels to the environment. They
infer the location of pedestrian crossings, sidewalks, and
building entrances and exits based on the activity patterns
of pedestrians. This is similar in spirit, if not in execution,
to the labeling of traffic lights based on vehicle movement
patterns introduced in this paper.


T
gn,t = xn,t , yn,t , ẋn,t , ẏn,t .

(3)

This is susceptible to the same ambiguity problem, however. In the example from Fig. 2, if path 2 resulted from
A accelerating through a light which recently turned green,
then the velocity at time t could be roughly the same for all
paths. The same holds true when acceleration is considered:
T

gn,t = xn,t , yn,t , ẋn,t , ẏn,t , ẍn,t , ÿn,t .

(4)

A more effective approach is to consider the state of
vehicle n not just for a single time step t, but rather over
a time window, i.e., t − 1, t − 2, and so on. If we consider
a window size of T time steps in the past, then we can
represent the state of vehicle n as a time series s at time t:

III. P ROBLEM F ORMULATION
We can formalize the problem from a probabilistic perspective as follows: let Z be a discrete random variable which
represents the state of a traffic light with respect to a target
vehicle. The specific value of Z is denoted by z, and in this
paper can take the value of either green or red. The goal is
to then determine the probability that a traffic light is either
green or red with respect to our target vehicle at a specific
point in time t: p(Zt = zt ). To simplify the notation, from
this point on we will refer to this probability as simply p(zt ).
Clearly, we cannot determine an accurate probability for
p(zt ) without additional information. Therefore, we would
like to consider observations of nearby vehicles when determining this probability. The simplest approach is to consider
the spatial position of every nearby vehicle independently at
each point in time. We define the state g of vehicle n at time
t as:

sn,t = gn,t , gn,t−1 , ..., gn,t−Tn

(5)

p(zt |s1,t , s2,t , ..., sN,t ) = p(zt |s1:N,t ).

(6)

If observations are ideal, then the entire path for vehicle A
is now taken into account and there is no more ambiguity. In
practice, this may not be the case and the effective window
size Tn may vary from vehicle to vehicle. For example, A
may only enter the sensor range of our target vehicle once
it reaches the position depicted in Fig. 2.
Problem: Given a set of observations L of nearby vehicles, determine p(zt |L) under the following assumptions.
284

1) L is either a set of independent vehicle states g, or a
set of independent series of states s.
2) Each series s may contain a variable number of states
corresponding to sequential time points.
3) At least one vehicle must be observed for at least one
time step.
In practice, Assumption 2 is not strong as this is implicitly
satisfied by a Bayesian tracking algorithm in this paper.

B. Bidirectional Long Short Term Memory Networks
Standard RNNs suffer from a problem known as the
vanishing gradient [15], in which the hidden layer node
weights for previous inputs converge to zero over time, thus
preventing an RNN from effectively learning from inputs
that span a long time period. A variant of the RNN known
as the Long Short Term Memory (LSTM) [16] network was
designed to mitigate this problem by introducing the concept
of LSTM nodes that are more effective at retaining previous
values. Furthermore, the Bidirectional Long Short Term
Memory (BLSTM) network was shown to be exceptionally
well-suited for sequence classification [17].
The bidirectional aspect of a BLSTM network is a concept lifted from Bidirectional Recurrent Neural Networks
(BRNNs) [18]. In a BRNN, two RNNs – one processing
the input series forward in time and one backward in time
– are connected to the same output layer. This architecture
yields greater prediction accuracy as it predicts based on past
inputs as well as future inputs.

IV. M ETHODOLOGY
In order to find the probability in Eq. (6), we adopt a
Bayesian interpretation which yields the following posterior:
p(s1:N,t |zt )p(zt )
.
(7)
p(s1:N,t )
We employ a discriminative model to find this posterior
directly. Artificial neural networks (ANNs) have excellent
predictive capabilities given nonlinear input-output mappings, particularly when applying a classification label to
a time series input. Depending on the cost function and
network complexity, ANNs can also accurately approximate
a Bayesian posterior directly [10], in our case p(zt |s1:N,t ).
p(zt |s1:N,t ) =

V. E XPERIMENTS
A. Experimental Setup

A. Artificial Neural Networks
Artificial neural networks are mathematical models capable of accurately approximating any continuous function [11]. In this work, we employ ANNs in a supervised
pattern classification capacity to approximate the posterior
probability in Eq. (2). In other words, the input to the
network is the feature vector gn,t and the expected output is
zt . Each observed vehicle state gn,t is treated as independent,
and the goal is to learn which states correspond to each
value of zt . In a feed-forward neural network (FFNN), the
nodes are not allowed to form cycles. This is suitable for
simple pattern classification, however, it is not ideal when
we would like to consider some inputs as dependent and
use multiple inputs to derive a single output. This is the case
when approximating the posterior probability in Eq. (6), as it
is conditional on a time series of vehicle states sn,t as defined
in Eq. (5). This is known as sequence classification [12], and
recurrent neural networks have been previously used with
great effect [13]. A recurrent neural network (RNNs) [14]
is a type of neural network that is allowed to form cyclical
connections among hidden layer nodes.
We use RNNs to estimate p(zt |sn,t ) by generating a single
output zt from a sequence of feature vectors gn,t , which
together form the time series sn,t of state vectors for vehicle
n. However, this is not the same as the posterior probability
defined in Eq. (6) which is conditional on all observed
vehicles, not just one. The feature vector to our network must
be a constant size. This rules out simply concatenating the
feature vectors of all observed vehicles, since the number
of observed vehicles may vary at any given time. Instead,
we take the mean probability of p(zt |sn,t ) for all observed
vehicles at time t and use that as an approximation:
PN
p̂(zt |sn,t )
p̂(zt |s1:N,t ) ≈ n=1
.
(8)
N

In order to evaluate how well these networks can approximate the posterior probabilities, we collected two sets
of data with which to perform experiments. The first set
was generated from real-world sensor data collected by an
autonomous vehicle from 56 intersections in the vicinity of
the National University of Singapore campus in Singapore.
Spatial point cloud data was collected with a SICK LMS 151
LIDAR sensor operating at 50Hz. As there is no ground truth
available with which to form the vehicle time series, the data
was fed through a two-stage vehicle tracking algorithm.
The first stage decomposes the point cloud data into
a subset of clusters, in which each cluster consists of a
collection of points in close proximity to each other. The
clusters are then tracked over several measurement frames
to yield an average spatial position and a velocity vector
for a given point in time [19]. The second stage treats
these independent measurements as observations to a particle
filter-based multi-target tracking algorithm [20]. Vehicle time
series are then derived from the particle filters and downsampled to 10Hz. Supervised labels were manually generated
from camera inputs collected simultaneously with the LIDAR
data. This process yielded a data set consisting of 1011
unique time series.
Despite the inherent value of real-world data, there is
a limit to how much can be collected. Additionally, due
to practical constraints, we could only collect data from
nearby intersections which limits how well we can generalize. Therefore, we turned to synthetic data generated
with the SUMO traffic simulator [21]. Road networks for
13 intersections were generated from OpenStreetMap data:
3 in Tempe, Arizona, 2 in New York City, New York,
and 8 in Singapore. Simulations were run in which traffic
passed through the intersections from each direction and
either traveled straight, turned left, or turned right. Vehicles
285

Classifier

Feature Set

1-NN
1-NN
1-NN
FFNN
FFNN
FFNN
BLSTM
BLSTM
BLSTM

x, y
x, y, ẋ, ẏ
x, y, ẋ, ẏ, ẍ, ÿ
x, y
x, y, ẋ, ẏ
x, y, ẋ, ẏ, ẍ, ÿ
x, y
x, y, ẋ, ẏ
x, y, ẋ, ẏ, ẍ, ÿ

Real
(No Track)
0.678
0.910
0.669
0.850

Real

Sim

Sim-Real

0.853
0.977
0.943
0.697
0.897
0.899
0.655
0.790
0.782

0.737
0.968
0.972
0.655
0.796
0.862
0.764
0.870
0.908

0.719
0.934
0.969
0.690
0.774
0.852
0.683
0.740
0.804

Sim
(Noisy)
0.813
838
0.833
0.642
0.692
0.695
0.765
0.874
0.863

Sim-Real
(Noisy)
0.599
0.648
0.627
0.684
0.716
0.709
0.679
0.742
0.718

TABLE I: The mean test accuracy for 1-Nearest Neighbor (1-NN), Feed-forward Neural Network (FFNN), and Bidirectional
Long Short Term Memory (BLSTM) classifiers. The best classifier for each data set is highlighted in green, while the
classifiers that are not significantly different are highlighted in yellow.

were uniformly distributed to one of three behavior models:
aggressive, average, and submissive.
SUMO is capable of writing floating car data (FCD)
output, which contains the position, velocity, and heading of
every vehicle at each sampling interval for the duration of the
simulation. To correspond with the real data set, the sampling
interval was fixed to 10Hz. This data was then transformed
with respect to a chosen target vehicle, and used to generate
state vectors for each other vehicle within a 50m sensor range
of the target. Since the FCD data includes a vehicle identifier,
these states can then be assembled into a time series for
each vehicle. These time series’ were segmented in order to
coincide with the states of the intersection’s traffic light and
labeled as either green or red. This process yielded a data
set consisting of 2311 unique time series.
The BLSTM network used in these experiments is composed of an input layer followed by two parallel LSTM
layers with 32 nodes each; one layer processes the input
sequence forward and one layer backwards. The output from
the LSTM layers is concatenated into a dropout layer with a
0.5 drop rate. The FFNN is a standard feed-forward network
with 3 hidden layers and 256 nodes per layer. In both
networks, the size of the input layer is dependent on the
number of vehicle state variables, while the output layer
always consists of two nodes in order to produce a one-hot
encoding of zt . The networks are trained using RMSProp
backpropagation with categorical cross-entropy loss and a
softmax activation function. Additionally, a simple K-Nearest
Neighbor algorithm was evaluated to serve as another point
of comparison. For all experiments, K = 1.

the Bayesian tracking had a significant impact on the 1-NN
performance. Thus, we created a Real (No Track) data set
with only the raw measurements obtained by the clustering
algorithm. However, despite slightly reduced performance,
the 1-NN classifier is still the best performer on this data set.
Results for BLSTM and feature sets containing acceleration
are not included for this data set as they require the time
series information provided by the tracking algorithm.
Furthermore, 1-NN has the highest classification accuracy
on the Simulation data set. This seems to indicate that the
Sim data set is a good approximation of the real data set
since it yields similar results, but on further analysis the test
sample distribution between the two data sets is strikingly
different. This can be observed in the first figure of each
row in Fig. 3. The Real data set is heavily skewed, with a
large portion of the test samples coming from intersections
where only a small number of vehicles were observed for a
short period of time. Meanwhile, the Sim data has a much
flatter distribution over a wider domain.
In order to determine whether this distribution has a prominent effect on classification accuracy, we ran an optimization algorithm to minimize the Kullback-Leibler divergence
between the distributions of the two data sets. This was
accomplished by using the truncation factor of a random
portion of the time series as the search parameter. The initial
KL divergence between the Real and Sim data sets is 1.35,
however, after this optimization routine that was reduced
to 0.09. The resulting data set is referred to as Sim-Real,
and it can be seen in Fig. 3 that the associated test sample
distribution is similar to that of the Real data set. As in
the other data sets, the 1-NN classifier is again the best
performer on the Sim-Real data and indicates robustness
to changes in the test sample distribution. Additionally,
since the simulation data yields similar results to the realworld data and is capable of closely approximating the realworld observation distribution, we consider it an accurate
representation of the real-world data.

B. Results and Discussion
The first experiment of interest is to evaluate the relative
performance of each classifier on our data sets, the results
of which are shown in Table I. The classification accuracy is
evaluated for the posterior probabilities produced by both the
FFNN and BLSTM classifiers, with a train/validation/test set
split of 60%/20%/20%, as well as the 1-NN classifier with a
80%/20% train/test split. This experiment reveals that despite
being the simplest, the 1-NN classifier performs significantly
better than all other classifiers on the Real data set with a
97% classification rate. Since this is an unexpected result,
we were interested in whether the noise reduction caused by

The only time we observed the 1-NN classifier perform
poorly is on data sets with a considerable amount of noise.
Gaussian noise with a standard deviation of 2.0 was applied
to all values in the Sim and Sim-Real data sets, resulting
in Noisy variations. The results in Table I show that 1286

0

0.8

10
20
30
Num obs. vehicles
1

1

800
600
400
200
10
20
Mean obs. length (s)

Sim
Confidence

0.6

2
4
6
8
Num obs. vehicles
Test accuracy

Num samples

Real
Confidence

0.6

10
20
30
Num obs. vehicles

1,000

0

0.8

Test accuracy

2,000

1

Test accuracy

4,000

Real
Sim
Sim-Real

Test accuracy

Num samples

1
6,000

0.8
0.6

0.8
0.6

2
4
6
Mean obs. length (s)

10
20
Mean obs. length (s)

Fig. 3: The first figure in each row shows the distribution of test samples in each data set according to the number of
observed vehicles per time step, and the mean observation length among all observed vehicles per time step. The remaining
figures in each row show the BLSTM (full feature set) test accuracy for real data (solid blue line) and simulation data (solid
green line) at each time step for both criteria. The red dashed indicates the prediction confidence at each time step.
Feature Set
x, y, ẋ, ẏ
x, y, ẋ, ẏ, ẍ, ÿ
x, y, ẋ, ẏ
x, y, ẋ, ẏ, ẍ, ÿ
x, y, ẋ, ẏ
x, y, ẋ, ẏ, ẍ, ÿ

NN yielded a considerably worse classification accuracy in
this scenario, while BLSTM was largely unaffected by the
additional noise and achieved the best accuracy with 87%
and 74% on the Sim and Sim-Real data sets respectively.
The results in Table I also allow us to examine the impact
of the different vehicle states defined in Eqs. (1), (3), and (4)
on the overall accuracy. The first observation we can make is
that the addition of velocity information into the feature set
results in a statistically significant (p-value < 0.05) increase
in accuracy for every classifier on every data set. This is
a strong result, and in line with the hypothesis that the
introduction of velocity information will help alleviate the
intersection ambiguity problem. However, it is interesting
to note that the addition of acceleration information does
not always lead to a further increase in accuracy. The noisy
data sets, in particular, actually exhibit either a statistically
significant decrease in accuracy or no change at all. This
suggests that we can reduce the complexity of our classifiers
without penalizing accuracy on noisy data sets by leaving
acceleration out of the feature set.

α
1
1
2
2
3
3

Mean Real
0.693
0.718
0.837
0.842
0.877
0.876

Mean Sim
0.861
0.866
0.863
0.870
0.868
0.876

TABLE II: The BLSTM mean test accuracy for all time steps
with at least α observed vehicles.

the observations that have occurred before the current time
step are considered. The mean classification accuracy for all
time steps is shown in Table II.
With further analysis, it is evident that a significant number
of misclassified time steps occur when only one vehicle
is observed. As more distinct vehicles are observed, the
classification accuracy increases, which is an intuitive result.
This is visualized in the top row of Fig. 3. If we examine
the distribution of test samples over the number of observed
vehicles, it is clear that a large portion of the samples
occur when only one vehicle is observable. Taking this into
consideration, if the test accuracy is evaluated only for time
steps in which two or more vehicles are observed, then the
accuracy increases from 71% to 84% on the Real data set as
shown in Table II. In contrast, the simulation data has a flatter
distribution, and as a result the corresponding accuracy does
not see a proportional increase. With the positive correlation
between accuracy and the number of vehicles, we might also
expect such a relationship between the classification accuracy
and the length of time that vehicles are observed. The plots
in the second row of Fig. 3 show a positive correlation,
indicating that this is true to some extent.

The second experiment is designed to test how the BLSTM
classifier would perform in a realistic scenario. In real-world
use, we do not have access to the full vehicle time series
in the data sets; we only have the vehicle observations that
have occurred until the current time step. The network is
first trained with the full vehicle time series from all but one
of the intersections. With the remaining time series, time
is treated as a discrete value and incremented in steps. At
every time step, the network is used to estimate the mean
temporal probability in Eq. (8) from the vehicle time series
that have had an observation within the past 3 seconds. Only
287

16

the same, we envision that the best use of our system is to
combine it with a traditional vision-based method. Different
failure cases suggests that the systems will complement each
other, and result in a more robust detection system.

x

14
12
10
8

R EFERENCES
10 8

6
y

4

2

[1] N. Maslekar, M. Boussedjra, J. Mouzna, and H. Labiod, “Vanet based
adaptive traffic signal control,” in Vehicular Technology Conference
(VTC Spring), 2011 IEEE 73rd. IEEE, 2011, pp. 1–5.
[2] V. Gradinescu, C. Gorgorin, R. Diaconescu, V. Cristea, and L. Iftode,
“Adaptive traffic lights using car-to-car communication,” in Vehicular
Technology Conference, 2007. VTC2007-Spring. IEEE 65th. IEEE,
2007, pp. 21–25.
[3] J. Levinson, J. Askeland, J. Dolson, and S. Thrun, “Traffic light
mapping, localization, and state detection for autonomous vehicles,” in
Robotics and Automation (ICRA), 2011 IEEE International Conference
on. IEEE, 2011, pp. 5784–5791.
[4] N. Fairfield and C. Urmson, “Traffic light mapping and detection,” in
Robotics and Automation (ICRA), 2011 IEEE International Conference
on. IEEE, 2011, pp. 5421–5426.
[5] J.-H. Park and C.-s. Jeong, “Real-time signal light detection,” in 2008
Second International Conference on Future Generation Communication and Networking Symposia. IEEE, 2008, pp. 139–142.
[6] H. Tae-Hyun, J. In-Hak, and C. Seong-Ik, “Detection of traffic lights
for vision-based car navigation system,” in Advances in Image and
Video Technology. Springer, 2006, pp. 682–691.
[7] F. Lindner, U. Kressel, and S. Kaelberer, “Robust recognition of traffic
signals,” in Intelligent Vehicles Symposium, 2004 IEEE. IEEE, 2004,
pp. 49–53.
[8] R. De Charette and F. Nashashibi, “Real time visual traffic lights
recognition based on spot light detection and adaptive traffic lights
templates,” in Intelligent Vehicles Symposium, 2009 IEEE. IEEE,
2009, pp. 358–363.
[9] B. Qin, Z. J. Chong, T. Bandyopadhyay, M. H. Ang, E. Frazzoli,
and D. Rus, “Learning pedestrian activities for semantic mapping,” in
Robotics and Automation (ICRA), 2014 IEEE International Conference
on. IEEE, 2014, pp. 6062–6069.
[10] M. D. Richard and R. P. Lippmann, “Neural network classifiers
estimate bayesian a posteriori probabilities,” Neural computation,
vol. 3, no. 4, pp. 461–483, 1991.
[11] K.-I. Funahashi, “On the approximate realization of continuous mappings by neural networks,” Neural networks, vol. 2, no. 3, pp. 183–192,
1989.
[12] Z. Xing, J. Pei, and E. Keogh, “A brief survey on sequence classification,” SIGKDD Explor. Newsl., vol. 12, no. 1, pp. 40–48, Nov.
2010.
[13] A. Graves, “Sequence transduction with recurrent neural networks,”
ICML Representation Learning Worksop, 2012.
[14] J. Schmidhuber, “Deep learning in neural networks: An overview,”
Neural Networks, vol. 61, pp. 85–117, 2015.
[15] Y. Bengio, P. Simard, and P. Frasconi, “Learning long-term dependencies with gradient descent is difficult,” IEEE transactions on neural
networks, vol. 5, no. 2, pp. 157–166, 1994.
[16] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural
computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[17] A. Graves and J. Schmidhuber, “Framewise phoneme classification
with bidirectional lstm and other neural network architectures,” Neural
Networks, vol. 18, no. 5, pp. 602–610, 2005.
[18] M. Schuster and K. K. Paliwal, “Bidirectional recurrent neural networks,” Signal Processing, IEEE Transactions on, vol. 45, no. 11, pp.
2673–2681, 1997.
[19] X. Shen, S.-W. Kim, and M. Ang, “Spatio-temporal motion features
for laser-based moving objects detection and tracking,” in Intelligent
Robots and Systems (IROS 2014), 2014 IEEE/RSJ International Conference on. IEEE, 2014, pp. 4253–4259.
[20] D. Schulz, W. Burgard, D. Fox, and A. B. Cremers, “Tracking multiple
moving targets with a mobile robot using particle filters and statistical
data association,” in Robotics and Automation, 2001. Proceedings
2001 ICRA. IEEE International Conference on, vol. 2. IEEE, 2001,
pp. 1665–1670.
[21] D. Krajzewicz, J. Erdmann, M. Behrisch, and L. Bieker, “Recent development and applications of SUMO - Simulation of Urban MObility,”
International Journal On Advances in Systems and Measurements,
vol. 5, no. 3&4, pp. 128–138, December 2012.

Fig. 4: Scenario in which pedestrians mistaken for a vehicle
result in a mis-classification with high confidence. The
camera image is on the left, and the corresponding time series
given by the particle filter is on the right.

Furthermore, there is also a positive relationship between
the accuracy and the BLSTM classifier’s prediction confidence, which we define as the maximum probability among
all values of zt . In other words, as the classifier observes
more vehicles it grows more confident in the prediction and
this results in a higher classification accuracy. However, there
are instances in which this does not hold true. Specifically,
it can be seen that the accuracy is poor while the prediction
confidence is high for the Real data set when the mean
observation length is between 4s and 5s in Fig. 3. On further
analysis, this occurred when the target vehicle was stopped in
front of pedestrians crossing a red light as shown in Fig. 4.
A single vehicle was tracked for several seconds moving
directly in front of the target vehicle with an average speed
of 2.83m/s. The most likely scenario is that the pedestrians
crossing the street were mistaken for a vehicle turning left,
which resulted in a prediction of a green light when in fact,
the light was red.
VI. C ONCLUSION
This paper has shown that it is possible to accurately
infer the current state of a traffic light by analyzing the
spatial movements of nearby vehicles with respect to a
target vehicle. This method was evaluated on real-world
data gathered in Singapore and synthetic data generated
from a traffic simulator. In both cases, encouraging results
were achieved with three different classifiers: a feed-forward
neural network, a bidirectional long short-term memory
network, and a nearest neighbor classifier. It was found
that in most tested scenarios, a nearest neighbor classifier
obtained the best classification results. However, if the data
is particularly noisy, better accuracy may be achieved with
a BLSTM classifier.
Similar to a vision-based approach, the methodology presented here has failure cases in which inference produces
wrong results. The most obvious case is when no vehicles
are in observation range, however, it was also seen that in
some scenarios more than one vehicle may need to be in
observation range in order to make an accurate prediction.
Likewise, there are specific instances in which the inference
may be wrong if other vehicles are only observed for an
extremely brief period of time. However, since the failure
cases for our approach and a vision-based approach are not
288

Proceedings of the 2005 IEEE
International Conference on Robotics and Automation
Barcelona, Spain, April 2005

Temporal Logic Motion Planning for Mobile Robots∗
Georgios E. Fainekos, Hadas Kress-Gazit and George J. Pappas
GRASP Laboratory, Departments of ESE and CIS
University of Pennsylvania
Philadelphia, PA 19104, USA
{fainekos,hadaskg,pappasg}@grasp.upenn.edu

Abstract— In this paper, we consider the problem of robot
motion planning in order to satisfy formulas expressible in
temporal logics. Temporal logics naturally express traditional
robot specifications such as reaching a goal or avoiding
an obstacle, but also more sophisticated specifications such
as sequencing, coverage, or temporal ordering of different
tasks. In order to provide computational solutions to this
problem, we first construct discrete abstractions of robot
motion based on some environmental decomposition. We then
generate discrete plans satisfying the temporal logic formula
using powerful model checking tools, and finally translate the
discrete plans to continuous trajectories using hybrid control.
Critical to our approach is providing formal guarantees
ensuring that if the discrete plan satisfies the temporal logic
formula, then the continuous motion also satisfies the exact
same formula.
Index Terms— Motion planning, temporal logics, model checking, discrete abstractions, hybrid control.

I. I NTRODUCTION
Robot motion planning problem has historically focused
on generating trajectories which reach a goal configuration
while avoiding obstacles [1], [2]. Mathematically formulating specifications such as motion sequencing, synchronization, or temporal ordering of different motions present
new challenges for motion planning, as they require not
only novel formulations, but also powerful computational
approaches due to the inherent problem complexity.
Formally defining such specifications can be achieved using
temporal logics, such as linear temporal logic (LTL) and
computation tree logic (CTL), developed in concurrency
theory. The applicability of temporal logics in robotics
was advocated as far back as [3]. Over the years, the formal methods community has developed very sophisticated
model checking tools such as S PIN [4] and N U S MV [5],
which verify whether a discrete transition system satisfies
a temporal logic formula. More recently, model checking
approaches have been used for discrete planning in order
to satisfy temporal logic specifications. This research has
led to planning algorithms and tools such as M BP [6],
TL PLAN [7] and U MOP [8]. These tools generate highlevel, discrete plans that do not take into consideration
the dynamic model of the robot, resulting in potentially
infeasible plans.
∗ This work is partially supported by NSF EHS 0311123, NSF ITR
0324977, and ARO MURI DAAD 19-02-01-0383.

0-7803-8914-X/05/$20.00 ©2005 IEEE.

This paper addresses the novel problem of generating
continuous trajectories for mobile robots while satisfying
formulas in temporal logic. Our approach first lifts the
problem to the discrete level by partitioning the environment into a finite number of equivalence classes. A variety
of partitions are applicable, in particular the cellular decomposition in [9] or the triangular decomposition in [10].
The partition results in a natural discrete abstraction for
robot motion which is used then for planning using model
checking tools, in particular S PIN and N U S MV.
In order to ensure that the discrete plan is feasible at the
continuous level, the decomposition must satisfy the socalled bisimulation property [11]. Bisimulations allow us to
prove that if the abstract, discrete robot model satisfies the
LTL formula, then the continuous robot model also satisfies
the same formula. To ensure this critical property we utilize
the hybrid control framework of [10], even though the
framework of [9] is equally applicable but computationally
more demanding.
Related work can be found in the hybrid systems community, and in particular the recent work of [12] which focuses
on designing controllers for discrete-time control systems
in order to satisfy temporal logic specifications. In [13],
controllers are designed for satisfying LTL formulas by
composing controllers using navigation functions [14]. In
[15], the U PPAAL model checking tool for timed automata
has been used for multi-robot motion planning using CTL
formulas, but without taking into account the dynamics of
the robots. This paper differentiates itself from all previous
approaches by building upon the framework proposed
in [10] which has, comparatively, the best computational
properties, is fully automated, and is ideally suited for
interfacing with model checking tools.
In addition to addressing this novel problem, we believe
that this direction of research is important for at least
three reasons. First, this work formally connects high-level
planning with low-level control, resulting in a mathematically precise interface between discrete AI planning and
continuous motion planning. Second, the mapping from
temporal logic to physical motion is the first important
step in the mapping from natural language to physical
motion in a compositional manner. Finally, this work can
be extended to multi-agent environments where formal
specifications and computational solutions will result in
verified coordination logic for cooperating robots.

2020

II. P ROBLEM F ORMULATION
We consider a fully actuated, planar model of robot motion
operating in a polygonal environment P . The motion of the
robot is expressed as
ẋ(t) = u(t) x(t) ∈ P ⊆ R2

u(t) ∈ U ⊆ R2

(1)

where x(t) is the position of the robot at time t, and u(t)
is the control input. The goal of this paper is to construct
a control input u(t) for system (1) so that the resulting
trajectory x(t) satisfies a formula in a temporal logic, such
as the temporal logic LTL [16]. The formulas are built
from a finite number of atomic propositions or observables
which label areas of interest in the environment such as
rooms or obstacles. Let Π = {π1 , π2 , . . . πn } be a set
of such propositions. For system (1) we then associate an
observation map
hC : P → Π
(2)
which maps the continuous states of the robot to the finite
set of propositions.1 Proposition πi ∈ Π represents an area
of interest in the environment which can be characterized
by a convex set of the form:
^
Pi = {x ∈ R2 |
aTk x + bk ≤ 0, ak ∈ R2 , bk ∈ R}
1≤k≤m

In other words, the observation map hC : P −→ Π has the
form hC (x) = πi iff x belongs in the associated set Pi .
We first give some informal examples of LTL formulas
and defer the formal syntax and semantics of LTL to
Section III. Propositional logic is the traditional logic of
conjunction (∧), disjunction (∨), negation (¬), implication
(⇒), and equivalence (⇔). LTL is obtained from standard
propositional logic by adding temporal operators such as
eventually (3), always (2), next (
) and until (U). Some
LTL examples that express interesting properties include:
•

•

•

Reach goal while avoiding obstacles: The formula
¬(o1 ∨ o2 ∨ · · · ∨ on )Uπ expresses the property that
eventually π will be true, and until π is reached, we
must avoid all obstacles labeled as oi , i = 1, . . . , n.
Sequencing: The requirement that we must first visit
π1 , π2 , and π3 in this order is naturally captured by
the formula 3(π1 ∧ 3(π2 ∧ 3π3 )).
Coverage: Formula 3π1 ∧ 3π2 ∧ · · · ∧ 3πm reads as
the robot will eventually reach π1 and eventually π2
and ... eventually πm , requiring the robot to eventually
visit all regions of interest in any order.

Problem 1: [Temporal logic motion planning] Given robot
model (1), observation map (2), initial condition x(0) ∈ P ,
and a LTL temporal logic formula ϕ, construct a control
input u(t) so that the resulting robot trajectory x(t) satisfies
the formula.
Example 1: In order to better explain the different steps
in this paper, we will consider throughout the paper the
following example. Consider a robot that is moving in
a square environment with four areas of interest denoted
by π1 , π2 , π3 , π4 . Initially, the robot is placed somewhere
in the region labeled π1 (see Figure 1). The desired
specification for the robot given in natural language is:
“Visit area π2 then area π3 then area π4 and, finally, return
to region π1 while avoiding areas π2 and π3 ”.
III. L INEAR T EMPORAL L OGIC
In this section, we formally describe linear temporal logic
(LTL) by giving its syntax and semantics.
Syntax: LTL formulas are interpreted over all trajectories
of the system starting from some initial state x(0) [16].
The atomic propositions of the logic are labels representing
areas of interest in the environment such as rooms or obstacles. Let Π = {π1 , π2 , . . . } be a set of such propositions.
The LTL formulas are defined according to the following
grammar:
φ

::=

π | ¬φ | φ ∨ φ | φ Uφ

As usual, the Boolean constants > and ⊥ are defined
as > = π ∨ ¬π and ⊥ = ¬> respectively. Given
negation (¬) and disjunction (∨), we can define conjunction
(∧), implication (⇒), and equivalence (⇔). Furthermore,
we can also derive additional temporal operators such as
eventuality 3φ = >Uφ and safety 2φ = ¬3¬φ. Note that
our syntax does not contain the so-called next operator 
φ.
Semantics: We define the continuous semantics of LTL
formulas over robot trajectories. Let x(t) for t ≥ 0 denote
the state of the robot at time t and let x[t] be a possible
robot trajectory starting at x(t). That is x[t] = {x(s) | s ≥
t and ẋ(t) = u(t)} or x[t] denotes the flow of x(s) under
the input u(s) for s ≥ t.

More complicated specifications can be composed from
more basic specifications using the logic operators. For
such temporal logic formulas, in this paper we provide
computational solution of the following problem.
1 Uninteresting regions of the state space could be mapped to a dummy
proposition or no proposition (resulting in a partial observation map).
Furthermore, one can easily consider overlapping propositions resulting
in non-deterministic observation maps.

Fig. 1. Example 1. The 4 areas of interest and the initial position of the
robot marked with x.

2021

LTL formulas φ are interpreted over a trajectory x[t].
x[t] |=C φ denotes the satisfaction of the formula φ over
the trajectory x[t] starting at x(t). The semantics of any
formula can be recursively defined as:
•
•
•
•

x[t] |=C π iff hC (x(t)) = π
x[t] |=C ¬φ if x[t] 6|=C φ
x[t] |=C φ1 ∨ φ2 if x[t] |=C φ1 or x[t] |=C φ2
x[t] |=C φ1 Uφ2 if there exists s ≥ t such that x[s] |=C
φ2 and for all s0 with t ≤ s0 < s we have x[s0 ] |=C φ1

Therefore, the formula φ1 Uφ2 intuitively expresses the
property that over the trajectory x[t] φ1 is true until
φ2 becomes true. Formula 3φ indicates that over the
trajectory the formula φ becomes eventually true, whereas
2φ indicates that φ is true over the trajectory x[t] for all
time t0 ≥ t.
Example 2: Coming back to Example (1), we can now
formally define the specification using temporal logic formulas. Let πi be the proposition that is true when the robot
is in area i. Using LTL the precise specification is:
φ = 3(π2 ∧ 3(π3 ∧ 3(π4 ∧ (¬π2 ∧ ¬π3 )Uπ1 )))
IV. T EMPORAL L OGIC M OTION P LANNING

Fig. 2. The triangulation of the workspace of Example 1 appears with
solid lines. The edges of the dual graph appear with dashes. The numbers
denote the nodes of the undirected graph.

contains all states x ∈ P which are contained in the triangle
labeled by q and {T −1 (qi ) | qi ∈ Q} is a partition of the
state space. Given such a partition of P , we can naturally
abstract the robot motion by defining a finite transition
system
D = (Q, q(0), →D , hD )

Our solution to generating continuous robot trajectories
satisfying LTL formulas φ consists of the following three
steps:
1) Discrete Abstraction of Robot Motion: Decompose
the environment P into a finite number of equivalence classes resulting in a finite state model of robot
motion.
2) Temporal Logic Planning using Model Checking:
Construct plans for the discrete robot motion satisfying desired specifications using model checkers.
3) Continuous Implementation of Discrete Plan: Implement the discrete plan at the continuous level while
preserving the satisfaction of the temporal formula.
A. Discrete Abstraction of Robot Motion
We first partition the workspace P of the robot into a
finite number of equivalence classes (or cells). Clearly,
we can use many efficient cell decomposition methods for
polygonal environments [2]. In this paper, we chose to
triangulate P for two main reasons. First, there exist several
efficient triangulation algorithms which can partition very
complicated environments [17]. Second, the choice of
controllers used in Section IV-C is proven to exist and
be efficiently computable on triangles [10]. Despite this
choice, many of the results in this section can be easily
adapted to similar decompositions, such as the decomposition described in [9].
Let T : P −→ Q denote the map which sends each state
x ∈ P to the finite set Q = {q1 , . . . , qn } of all equivalence
classes (triangles in this paper). In other words, T −1 (q)

(3)

where Q is the finite set of states, and q(0) ∈ Q is
the cell containing the initial robot state x(0) ∈ P , that
is q(0) = T (x(0)). The dynamics are captured by the
transition relation →D ⊆ Q × Q, defined as qi →D qj
iff the cells labeled by qi , qj are topologically adjacent,
that is triangles T −1 (qi ) and T −1 (qj ) have a common
line segment. The transition relation →D is also known
as the dual graph of the triangulation and can be easily
computed. Having defined transitions →D for transition
system D, we can define trajectories p of D as sequences
of the form p[i] = pi →D pi+1 →D pi+2 →D . . . , where
pi = p(i) ∈ Q.
In addition to defining the transition relation, we also define
the observation map hD : Q −→ Π, as hD (q) = π,
if there exists x ∈ T −1 (q) such that hC (x) = π. In
order to ensure that hD is well defined, we must impose
the requirement that the decomposition is proposition or
observation preserving, that is for all x1 , x2 ∈ P and all
π ∈ Π, T (x1 ) = T (x2 ) ⇒ hC (x1 ) = hC (x2 ). In other
words, states that belong in the same equivalence class or
cell, map to the same observations.
Example 3: Revisiting Example 1, we can now triangulate
the environment (see [18] for the algorithm used) and
construct the dual graph of the triangulation (Figure 2). The
resulting undirected graph has 34 states and 49 transitions.
The transition system D will serve as an abstract model of
robot motion. We must now lift our problem formulation
from the continuous to the discrete domain. In the previous
section we defined the semantics of LTL formulas over
continuous trajectories. We keep the LTL syntax exactly

2022

the same, but we reformulate the semantics of the temporal
logic formula to be interpreted over the discrete trajectories
generated by transition system D.
Discrete LTL Semantics: Path formulas φ are interpreted
over an execution p[i], denoted as p[i] |=D φ. The semantics of any path formula can be recursively defined as:
•
•
•
•

p[i] |=D π iff hD (p(i)) = π
p[i] |=D ¬φ if p[i] 6|=D φ
p[i] |=D φ1 ∨ φ2 if p[i] |=D φ1 or p[i] |=D φ2
p[i] |=D φ1 Uφ2 if there exists j ≥ i s. t. p[j] |=D φ2 ,
and for all j 0 with i ≤ j 0 < j we have p[j 0 ] |=D φ1

We are interested in understanding the relationship between
the continuous robot model satisfying formula x[0] |=C φ
with continuous LTL semantics and the transition system
D satisfying formula p[0] |=D φ, where p(0) = T (x(0)),
but with the discrete LTL semantics.
B. Temporal Logic Planning using Model Checking
In a nutshell, model checking is the algorithmic procedure
for testing whether a specification formula holds over some
semantic model [19]. The model of the system is usually
given in the form of a discrete transition system like the
one described in Section IV-A. The specification formula is
usually given in the form of temporal logics such as LTL.
As mentioned earlier, we are looking for computation
paths p[i] that satisfy the temporal formula p[0] |=D φ.
In the model checking community, this is known as the
generation of witnesses. Unfortunately, the current versions
of the model checking software tools do not support
the construction of witnesses as they are mainly analysis
tools. Hence, we have to employ the algorithms that solve
the dual problem, i.e. the generation of counterexamples.
In this case, when the model checker determines that a
formula φ is false, it constructs a finite trace p[0] which
demonstrates that the negation of φ is true, i.e. p[0] |=D ¬φ.
Let φ be the formula that the system should satisfy. Assume
now that we give as input to our model checking algorithm
the LTL formula ¬φ, representing the negation of the
desired behavior. If the formula is false in our discrete
model of the environment, then the model checker will
return a finite trace p[0] that satisfies the formula ¬(¬φ) ≡
φ and, thus, we are done as we have found a finite path
that satisfies the original LTL formula φ.
Out of the variety of model checking tools that have been
developed over the years, we chose the most dominant
ones, that is, N U S MV [5] which is based on symbolic
model checking techniques and is mainly targeted for CTL
(but it can also handle LTL) model checking problems,
and S PIN [4] which uses an automaton approach to the
model checking problem and accepts only LTL formulas. Both toolboxes support hierarchy and composition,
multiple agents, generation of counterexamples in case
the temporal formula is invalidated and nondeterministic

environments. Of course, there are also several differences
between the two toolboxes mainly concerning the way they
deal with the model checking problem, the user interface
and the expressive power of the underlying logic. S PIN only
supports asynchronous communication among agents, but
it gives us the option for the generation of traces that are
optimal in the sense of minimum number of transitions
(trace length). The conversion of the discrete transition
system of Section IV-A to the input language of N U S MV
or to the input language of SPIN is straightforward and it
is automated.
Example 4: Using N U S MV for our example, we get the
following witness trace p = {33, 34, 24, 25, 27, 16, 15, 14,
3, 4, 5, 32, 23, 26, 29, 30, 3, 14, 33}, which satisfies our
specification.
C. Continuous Implementation of Discrete Trajectory
Our next task is to utilize the discrete trajectory p[0]
in order to construct a control input u(t) for t ≥ 0
and, therefore, a continuous trajectory x[0] that satisfies
exactly the same path formula. We achieve this desired
goal by simulating (or implementing) at the continuous
level each discrete transition of p[0]. This means that if
the discrete system D makes a transition pi →D pj , then
the continuous system must match this discrete step by
moving the robot from states in triangle T −1 (pi ) to states
in triangle T −1 (pj ).
We define a transition relation →C ⊂ P × P between
continuous robot states in P . Formally, there is a transition
x →C x0 if x and x0 belong to adjacent triangles, and it is
possible to construct a trajectory x(t) for 0 ≤ t ≤ T with
x(0) = x and x(T ) = x0 , and, furthermore, for all 0 ≤ t ≤
T we have x(t) ∈ (T −1 (T (x)) ∪ T −1 (T (x0 ))). Informally,
x →C x0 if we can steer the robot from x to x0 without
visiting any triangle other than the triangle containing x
or the neighboring triangle containing x0 . Having defined
→C allows us to formally define a transition system C =
(P, x(0), →C , hC ).
In order to ensure that the continuous system can implement any discrete plan obtained by the model checker, we
require that the decomposition of P satisfies the so called
bisimulation property [11].
Definition 1 (Bisimulations): A partition T : P −→ Q is
called a bisimulation if the following properties hold for
all x, y ∈ P :
•

•

(Observation preserving) If T (x) = T (y), then
hC (x) = hC (y)
(Reachability preserving) If T (x) = T (y), then if
x →C x0 then y →C y 0 for some y 0 with T (x0 ) =
T (y 0 ).

In other words, the triangulation is a bisimulation if the
whole triangle is mapped to the same observation, and
furthermore, if one state x can move to the adjacent triangle

2023

Fig. 4.
Fig. 3.

Example 6: Visit all the rooms

Example 1: Continuous trajectory implementation

to some state x0 , then all states y in the same triangle with
x can also move to the same triangle with x0 .
Assuming that this property is satisfied by the partition with
respect to transitions we just defined, it is straightforward
to show the following proposition.
Proposition 1: Let φ be an LTL path formula, and let T :
P −→ Q be a bisimulation. If p[0] |=D φ, then for every
x(0) ∈ T −1 (p(0)) there exists a trajectory x[0] satisfying
x[0] |=C φ.
It remains to design controllers that satisfy the so-called
bisimulation property. There are several recent approaches
for generating such controllers, such as [9], [10] and [20].
We use the framework developed in [10] due to its computational properties in triangular environments. In this
approach, an affine vector field is created in each triangle
that drives the robot to the desired adjacent triangle, while
taking into consideration any velocity bounds the robot
might have. For a description of this controller design, we
refer the reader to [10].
Note however, that by satisfying the bisimulation property
using feedback controllers, the temporal logic formula is
robustly satisfied not only by the initial state x(0), but
also by all other states in the same triangle. Furthermore,
the design of the controllers in [10] can guarantee the
continuity of the vector fields at the common edges of
adjacent triangles.
Example 5: Figure 3 shows the continuous trajectory corresponding to our example, which was created using the
triangulation from Example 3 and the discrete path generated by N U S MV in example 4.
V.

SIMULATIONS

In order to test our approach to the problem of motion planning, we ran several simulations. We started with simple
environments and continued by increasing the complexity
of both the environment and the specification in order to
make sure our approach scales well. In this section, we
describe the process of creating a solution to the motion

planning problem, and we show examples of non-trivial
behaviors in complex environments, which may include
holes and regions of interest.
The first step consists of specifying the environment. The
environment is described as a set of vertices which define
the outer contour, inner holes and inner regions of interest
(such as rooms). We specify these vertices either by using
a M ATLAB based graphical user interface which allows
the user to select points on a grid or by writing M ATLAB
functions that create vertices in a desired pattern. Next, we
triangulate the polygonal environment using the software
developed in [18] and we create the input code for the
model checker which we augment with the temporal logic
formula. The required path is generated as a counter
example trace using a model checker. The final step is
to create the control law u(t) for t ≥ 0 and to simulate
the robot path. This step is performed in M ATLAB and the
control law is generated according to the method developed
in [10] using linear programming.
Example 6: Figure 4 is an example of a trajectory, generated by N U S MV, satisfying a coverage requirement. In this
example the desired behavior was to visit each of the rooms
(shaded areas) in no particular order. The LTL formula that
captures the specification is: 3r1 ∧ 3r2 ∧ 3r3 ∧ 3r4 ∧
3r5 ∧ 3r6 . For problems of this size, the generation of the
discrete path is almost instant and the controller synthesis
in MATLAB takes less then 15 seconds.
Example 7: This is an example of a trajectory satisfying
a more complex requirement. In this example the desired
behavior is “Visit room r2 , then room r1 and then cover
rooms r3 , r4 , r5 - all this while avoiding obstacles o1 , o2 ,
o3 ”. Figure 5 depicts the path generated by S PIN.
Example 8: Figure 6 is an example of a very large environment. This environment includes 1156 areas of interest
(rooms) and its discrete abstraction consists of 9250 triangles. The specification for this example was “Start in
the white room and go to both black rooms”. Even though
this environment is very large, the computation time was a
few seconds for the triangulation, about 55 seconds for the
path generation in N U S MV and around 90 seconds for the

2024

a set R of initial conditions (i.e. ∀x(0) ∈ R ⇒ x[0] |=C
φ). Furthermore, we plan to run experiments testing our
approach using ACTIV M EDIA mobile robots as a testbed.
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers
for their comments.
R EFERENCES

Fig. 5. Example 7: While avoiding the obstacles go to room 2, then to
room 1 and then go to rooms 3, 4, 5 (in any order)

Fig. 6. Example 8: Complex environment - Visit the two square areas
in black color

controller synthesis of a path of 145 triangles in M ATLAB.
VI. C ONCLUSIONS - F UTURE

WORK

In this paper, we have described our approach to the
problem of motion planning, which begins at a high level
of behavior specification, expressed in temporal logic, and
ends in creating continuous control inputs for the robot
that satisfy those requirements. We have shown that this
approach is computationally feasible, that complex environments can be handled easily and that many complex
robot behaviors can be expressed and satisfied.
We find this approach to be very promising and there are
several directions in which we are planning to proceed,
such as, extending this framework to multiple robots,
incorporating natural language as a higher level specification (which will be automatically translated into temporal
logic), and looking at different cell decomposition techniques.
Currently, we are investigating the extension of the presented approach to the design of hybrid controllers that
would guarantee the satisfaction of a path formula φ in
the presence of localization and actuation errors, in the
presence of observable predicates (sensory input) and under

[1] S. M. LaValle, ”Planning Algorithms”, [Online, Available at
http://msl.cs.uiuc.edu/planning/], 2004
[2] H. Choset, K. M. Lynch, L. Kavraki, W. Burgard, S. A. Hutchinson,
G. Kantor, and S. Thrun. Robotic Motion Planning: Foundations and
Implementation. 2004. In preparation.
[3] M. Antoniotti and B. Mishra, ”Discrete Event Models + Temporal
logic = Supervisory Controller: Automatic Synthesis of Locomotion
Controllers”, IEEE International Conference on Robotics and Automation, 1995.
[4] G.J. Holzmann, ”The Spin Model Checker Primer and Reference
Manual”, Addison-Wesley, Reading Massachusetts, 2004.
[5] A. Cimatti, E. M. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore, M. Roveri, R. Sebastiani and A. Tacchella, ”NuSMV 2: An
OpenSource Tool for Symbolic Model Checking”, In Proceeding
of International Conference on Computer-Aided Verification (CAV
2002), Copenhagen, Denmark, July 27-31, 2002.
[6] P. Bertoli, A. Cimatti, M. Pistore, M. Roveri, and P. Traverso, ”MBP:
A Model Based Planner”, In Proc. IJCAI’01 Workshop on Planning
under Uncertainty and Incomplete Information, 2001.
[7] F. Bacchus and F. Kabanza, ”Using Temporal Logics to Express
Search Control Knowledge for Planning”, Artificial Intelligence, vol
116, 2000.
[8] R.M. Jensen and M. M. Veloso, ”OBDD-based Universal Planning
for Synchronized Agents in Non-Deterministic Domains”, Journal of
Artificial Intelligence Research, 2000, Volume 13, 189-226.
[9] D.C. Conner, A. Rizzi, and H. Choset, ”Composition of local potential
functions for global robot control and navigation”, Proceedings of
2003 IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS 2003), IEEE, Vol. 4, October, 2003, pp. 3546-3551.
[10] C. Belta and L.C.G.J.M. Habets, ”Constructing decidable hybrid
systems with velocity bounds”, 43rd IEEE Conference on Decision
and Control, Bahamas, Dec 2004.
[11] R. Alur, T. A. Henzinger, G. Lafferriere, and G. J. Pappas. ”Discrete
abstractions of hybrid systems”, Proceedings of the IEEE, 88:971984,
2000.
[12] P. Tabuada and G. J. Pappas. Model checking LTL over controllable
linear systems is decidable. Hybrid Systems : Computation and
Control. volume 2623 of Lecture Notes in Computer Science.
Springer-Verlag, Prague, 2003.
[13] S. Loizou and K. Kyriakopoulos, ”Automatic Synthesis of MultiAgent Motion Tasks Based on LTL Specifications”, 43rd IEEE
Conference on Decision and Control, Bahamas, Dec 2004.
[14] E. Rimon and D. E. Kodischek, ”Exact robot navigation using
artificial potential functions”, IEEE Transactions on Robotics and
Automation, 8(5):501–518, 1992.
[15] M.M. Quottrup, T. Bak, and R. Izadi-Zamanabadi, ”Multi-Robot
Planning: A Timed Automata Approach”, Proc. 2004 IEEE Int. Conf.
on Robotics and Automation, New Orleans, LA.
[16] A. E. Emerson, ”Temporal and Modal Logic”, in: Van Leeuwen (ed)
Handbook of Theoretical Computer Science, Vol. B, pp. 997-1072,
Elsevier Science Publishers, 1990.
[17] M. de Berg, M. van Kreveld, M. Overmars and O. Schwarzkopf,
”Computational Geometry: Algorithms and Applications”, 2nd rev.
ed. 2000.
[18] A. Narkhede, and D. Manocha, ”Fast Polygon Triangulation
based on Seidel’s Algorithm”, [Online at
http://www.cs.unc.edu/ dm/CODE/GEM/chapter.html#Seidel91].
[19] E. M. Clarke, O. Grumberg and D. A. Peled, ”Model Checking”,
The MIT Press, Cambrige, MA, 1999.
[20] L.C.G.J.M. Habets and J.H. van Schuppen. A control problem for
affine dynamical systems on a full-dimensional polytope. Automatica,
40:21–35, 2004.

2025

Linear Hybrid System Falsification Through
Descent⋆

arXiv:1105.1733v4 [cs.SY] 17 Jul 2011

Houssam Abbas and Georgios Fainekos
Arizona State University, Tempe, AZ, USA,
{hyabbas,fainekos}@asu.edu

Abstract. In this paper, we address the problem of local search for the
falsification of hybrid automata with affine dynamics. Namely, if we are
given a sequence of locations and a maximum simulation time, we return the trajectory that comes the closest to the unsafe set. In order
to solve this problem, we formulate it as a differentiable optimization
problem which we solve using Sequential Quadratic Programming. The
purpose of developing such a local search method is to combine it with
high level stochastic optimization algorithms in order to falsify hybrid
systems with complex discrete dynamics and high dimensional continuous spaces. Experimental results indicate that indeed the local search
procedure improves upon the results of pure stochastic optimization algorithms.
Keywords: Model Validation and Analysis; Robustness; Simulation;
Hybrid systems

1

Introduction

Despite the recent advances in the computation of reachable sets in medium
to large-sized linear systems (about 500 continuous variables) [1, 2], the verification of hybrid systems through the computation of the reachable state space
remains a challenging problem [3, 4]. To overcome this difficult problem, many
researchers have looked into testing methodologies as an alternative. Testing
methodologies can be coarsely divided into two categories: robust testing [5–7]
and systematic/randomized testing [8–11].
Along the lines of randomized testing, we investigated the application of
Monte Carlo techniques [12] and metaheuristics to the temporal logic falsification
problem of hybrid systems. In detail, utilizing the robustness of temporal logic
specifications [13] as a cost function, we managed to convert a decision problem,
i.e., does there exist a trajectory that falsifies the system, into an optimization
problem, i.e., what is the trajectory with the minimum robustness value? The
resulting optimization problem is highly nonlinear and, in general, without any
⋆

This work was partially supported by a grant from the NSF Industry/University
Cooperative Research Center (I/UCRC) on Embedded Systems at Arizona State
University and NSF award CNS-1017074.

obvious structure. When faced with such difficult optimization problems, one
way to provide an answer is to utilize some stochastic optimization algorithm
like Simulated Annealing.
In our previous work [12], we treated the model of the hybrid system as a
black box since a global property, such as convexity of the cost function, cannot
be obtained, in general. One question that is immediately raised is whether we
can use “local” information from the model of the system in order to provide
some guidance to the stochastic optimization algorithm.
In this paper, we set the theoretical framework to provide local descent information to the stochastic optimization algorithm. Here, by local we mean the
convergence to a local optimal point. In detail, we consider the falsification problem of affine dynamical systems and hybrid automata with affine dynamics where
the uncertainty is in the initial conditions. In this case, the falsification problem
reduces to an optimization problem where we are trying to find the trajectory
that comes the closest to the unsafe set (in general, such a trajectory is not
unique). A stochastic optimization algorithm for the falsification problem picks
a point in the set of initial conditions, simulates the system for a bounded duration, computes the distance to the unsafe set and, then, decides on the next
point in the set of initial conditions to try. Our goal in this paper is to provide
assistance at exactly this last step. Namely, how do we pick the next point in
the set of initial conditions? Note that we are essentially looking for a descent
direction for the cost function in the set of initial conditions.
Our main contribution, in this paper, is an algorithm that can propose such
descent directions. Given a test trajectory sx0 : R+ 7→ Rn starting from a point
x0 , the algorithm tries to find some vector d such that sx0 +d gets closer to
the unsafe set than sx0 . We prove that it converges to a local minimum of the
robustness function in the set of initial conditions, and demonstrate its advantages within a stochastic falsification algorithm. The results in this paper will
enable local descent search for the satisfaction of arbitrary linear temporal logic
specifications, not only safety specifications.

2

Problem Formulation

The results in this paper will focus on the model of hybrid automata with affine
dynamics. A hybrid automaton is a mathematical model that captures systems
that exhibit both discrete and continuous dynamics. In brief, a hybrid automaton
is a tuple
H = (X, L, E, Inv, F low, Guard, Re)
where X ⊆ Rn is the state space of the system, L is the set of control locations,
E ⊆ L × L is the set of control switches, Inv : L → 2X assigns an invariant set to
each location, F low : L × X → Rn defines the time derivative of the continuous
part of the state, Guard : E → 2X is the guard condition that enables a control
switch e and, finally, Re : X × E → X × L is a reset map. Finally, we let
H = L × X to denote the state space of the hybrid automaton H.

Formally, the semantics of a hybrid automaton are given in terms of generalized or timed transition systems [14]. For the purposes of this paper, we define
a trajectory ηh0 starting from a point h0 ∈ H to be a function ηh0 : R+ → H.
In other words, the trajectory points to a pair of control location - continuous
state vector for each point in time: ηh0 (t) = (l(t), sx0 (t)), where l(t) is the location at time t, and sx0 (t) is the continuous state at time t. We will denote
by loc(ηh0 ) ∈ L∗ ∪ Lω the sequence of control locations that the trajectory ηh0
visits (no repetitions). The sequence is finite when we consider a compact time
interval [0, T ] and η is not Zeno.
Assumptions: In the following, we make a number of assumptions. First,
we assume that for each location v ∈ L the system dynamics are affine, i.e.,
ẋ = F low(v, x) = Ax + b, where A and b are matrices of appropriate dimensions.
Second, we assume that the guards in a location are non-overlapping and that
the transitions are taken as soon as possible. Thirdly, we assume that the hybrid
automaton is deterministic, i.e., starting from some initial state, there exists
a unique trajectory ηh0 of the automaton. This will permit us to use directly
results from [6]. We also make the assumption that the simulation algorithms
for hybrid systems are well behaved. That is, we assume that the numerical
simulation returns a trajectory that remains close to the actual trajectory on a
compact time interval. To avoid a digression into unnecessary technicalities, we
will assume that both the set of initial conditions and the unsafe set are included
in a single (potentially different) control location.
Let U ⊆ H be an unsafe set and let DU : H 7→ R+ be the distance function
to U, defined by

dU (x) if v ∈ prL (U)
DU (v, x) =
+∞
otherwise
where prL is the projection to the set of locations, prX is the projection to the
continuous state-space and
dU (x) = inf ||x − u||.
u∈U

Definition 1 (Robustness) Given a compact time interval [0, T ], we define
the robustness of a system trajectory ηh starting at some h = (l, x) ∈ H to be
f (h) , min0≤t≤T DU (ηh (t)). When l is clear from the context, we’ll write f (x).
Our goal in this paper is to find operating conditions for the system which
produce trajectories of minimal robustness, as they indicate potentially unsafe
operation. This can be seen as a 2-stage problem: first, decide on a sequence of
locations to be followed by the trajectory. Second, out of all trajectories following
this sequence of locations, find the trajectory of minimal robustness. This paper
addresses the second stage. The central step is the solution the following problem:
Problem 1 Given a hybrid automaton H, a compact time interval [0, T ], a set
of initial conditions H0 ⊆ H and a point h0 = (l0 , x0 ) ∈ H0 such that 0 <
f (h0 ) < +∞, find a vector dx such that h′0 = (l0 , x0 + dx), loc(ηh0 ) = loc(ηh′0 )
and f (h′0 ) ≤ f (h0 ).

An efficient solution to Problem 1 may substantially increase the performance
of the stochastic falsification algorithms by proposing search directions where the
robustness decreases. In summary, our contributions are:
– We formulate Problem 1 as a nonlinear optimization problem, which we
prove to be differentiable w.r.t. the initial conditions. Thus it is solvable
with standard optimizers.
– We developed an algorithm, Algorithm 1, to find local minima of the robustness function.
– We demonstrate the use of Algorithm 1 in a higher-level stochastic falsification algorithm, and present experimental results to analyze its competitiveness against existing methods.

3

Finding a descent direction

Consider an affine dynamical system in Rn ,
ẋ = F (x) = Ax + b
which we assume has a unique solution
sx0 (t) = eAt x0 + c(t)
where x0 ∈ X0 is the initial state of the trajectory
Let U ⊂ Rn be the convex set of bad states, and U its closure. Note that even
for linear systems, f : X0 7→ R+ is not necessarily differentiable or convex. Our
goal is to find the trajectory of minimum robustness. That is done by a local
search over the set of initial conditions.
Given an initial state x0 and a trajectory sx0 that starts at x0 , define the
time t∗ of its closest proximity to U, and the point u∗ ∈ U which is closest to
the trajectory:
t∗ = arg min dU (sx0 (t)), u∗ = arg min ||sx0 (t∗ ) − u||
t≥0

3.1

u∈U

Partial descent based at the nearest point

Given t∗ , choose an approach vector d′ such that sx0 (t∗ ) + d′ is closer to U than
sx0 (t∗ ). Such a vector always exists given that sx0 has a positive distance to U.
Moreover, it is not unique. Thus we have
f (x0 ) = ||sx0 (t∗ ) − u∗ || > min ||sx0 (t∗ ) + d′ − u||
u

Define d = e

−At∗ ′

d . Then
∗

∗

f (x0 ) > min ||sx0 (t∗ ) + d′ − u|| = min ||eAt x0 + c(t) + eAt d − u||
u

u

≥ min min ||(x0 + d)eAt + c(t) − u|| = f (x0 + d) ≥ 0
t

u

and d is a descent direction, provided that x0 + d ∈ X0 .
It is easy to see that for any x0 ∈ X0 and d′ ∈ Rn ,
sx0 +e−At∗ d′ (t) = sx0 (t∗ ) + d′
so the new distance is achieved at the same time t∗ as the old one. This new
distance dU (sx0 +d (t∗ )) is an upper bound on the new trajectory’s robustness. In
general, the new trajectory’s robustness might be even smaller, and achieved at
some other time t′ 6= t∗ .
As pointed out earlier, the approach d′ is not unique. The requirement on
′
d is that sx0 (t∗ ) + d′ be closer to U than sx0 (t∗ ). So define the set P (x0 ; t∗ ) of
points that are closer to U than sx0 (t∗ ) (see Fig. 1):
P (x0 ; t∗ ) , {x ∈ Rn |dU (x) ≤ f (x0 )}

(1)

P(x0;t*)

U

sx0(t*)
Fig. 1. The unsafe set U and the set P (x0 ; t∗ ). The system trajectory sx0 appears as
a dashed curve.
∗

Then d′ must satisfy sx0 (t∗ )+d′ ∈ P (x0 ; t∗ ) ⇔ d ∈ e−At (P (x0 ; t∗ )−sx0 (t∗ )).
Combined with the requirement that x0 + d ∈ X0 , we get
\
∗
d ∈ (X0 − x0 ) e−At [P (x0 ; t∗ ) − sx0 (t∗ )]

Any point in the above descent set is a feasible descent direction. As a special
∗
case, it is easy to verify that d = e−At (u − sx0 (t∗ )), for any u ∈ U, is a descent
direction that leads to 0 robustness. Coupled with the requirement that x0 + d
must be in X0 , it comes
\
∗
d ∈ (X0 − x0 ) e−At (U − sx0 (t∗ ))
If computing P is too hard, we can approximate it with the following U U :
imagine translating U along the direction v = sx0 (t∗ ) − u∗ , so it is being drawn
closer to sx0 (t∗ ), until it meets it. Then we claim that the union of all these
translates forms a set of points closer to U than sx0 (t∗ ):

Proposition 1. Let U be a convex set, sx0 (t∗ ) a point outside it, and U U (v)
be the Minkowski sum of U and {αv|α ∈ [0, 1]}. Then for any p in U U (v),
dU (p) ≤ dU (sx0 (t∗ ))
Proof. U U is convex by the properties of Minkowski sums. Let u ∈ ∂U. Then for
any α ≤ 1, dU (u + αv) ≤ ||u + αv − u|| = α||v|| = αf (x0 ) ≤ f (x0 ). So translates
of boundary points are closer to U than sx0 (t∗ ).
Now we show that all points in U U /U are translates of boundary points.
Consider any point p = u + αv in U U /U: u is in U, but p is not, so the line [u, p]
crosses ∂U for some value αo : u + αo v ∈ ∂U. And, p = u + αv = (u + αo v) +
(α − αo )v, so by what preceded, dU (p) ≤ f (x).
When p ∈ U, of course, dU (p) = 0 ≤ f (x).
We have thus defined 3 possible descent sets: U ⊂ U U ⊂ P (x0 ; t∗ ).
3.2

Implementation

The question we address here is: how do we obtain, computationally, points in
the descent set W, where W = U, P (x0 ) or U U (v)? The following discussion is
based on Chapters 8 and 11 of [15].
Since we’re assuming X0 and U to be convex, then the descent set is also
convex. Describe X0 with a set of NX inequalities qi (x) ≤ 0 where the qi are
convex and differentiable, and W = {x|pi (x; x0 ) ≤ 0, i = 1...k} for convex differentiable pi (the particular form of the pi will depend on the descent set at
hand). We assume dom pi = dom qi , Rn .
Given an already simulated trajectory sx0 and its time of minimum robustness t∗ , we are looking for a feasible x1 such that sx1 (t) ∈ W for some t. Thus
we want to solve the following feasibility problem
min

(x,ν)

ν

s.t. pi (sx (t); x0 ) ≤ ν, i = 1 . . . k

(t-PDP(x0 ))

(2)

qi (x) ≤ ν, i = 1 . . . NX
This is a convex program, which can be solved by a Phase I Interior Point
method [15]. A non-positive minimum ν ∗ means we found a feasible x; if W = U,
then our work is done: we have found an unsafe point. Else, we can’t just stop
upon finding a non-positive minimum: we have merely found a new point x1
whose robustness is less than x0 ’s, but not (necessarily) 0. So we iterate: solve
t-PDP(x0 ) to get x1 , solve t-PDP(x1 ) to get x2 , and so on, until f (xi ) = 0, a
maximum number of iterations is reached, or the problem is unsolvable. If the
minimum is positive, this means that for this value of t, it is not possible for any
trajectory to enter U at time t.
The program suffers from an arbitrary choice of t. One approach is to sample
the trajectory at a fixed number of times, and solve (2) for each. This is used in
the experiments of this section. A second approach, used in the next section, is
to let the optimization itself choose the time, by adding it to the optimization
variable. The resulting program is no longer necessarily convex.

3.3

Numerical Experiments

In this section, we present some numerical experiments demonstrating the practical significance of the previous theoretical results.
Example 1 We consider the verification problem of a transmission line [16].
The goal is to check that the transient behavior of a long transmission line has
acceptable overshoot for a wide range of initial conditions. Figure 2 shows a
model of the transmission line, which consists of a number of RLC components
(R: resistor, L: inductor and C: capacitor) modeling segments of the line. The left
side is the sending end and the right side is the receiving end of the transmission
line.
x1
vin

r

x3
l
x2

r
c

x9
l
x4

c

r

l
x10

c

Fig. 2. RLC model of a transmission line.

The dynamics of the system are given by a linear dynamical system
ẋ(t) = Ax(t) + bVin (t) and Vout (t) = Cx(t)
where x(t) ∈ R81 is the state vector containing the voltage of the capacitors and
the current of the inductors and Vin (t) ∈ R is the voltage at the sending end.
The output of the system is the voltage Vout (t) ∈ R at the receiving end. Here,
A, b and C are matrices of appropriate dimensions. Initially, we assume that
the system might be in any operating condition such that x(0) ∈ [−0.1, 0.1]41 ×
[−0.01, 0.01]40. Then, at time t = 0 the input is set to the value Vin (t) = 1.
The descent algorithm is applied to the test trajectory that starts from x(0) =
0 and it successfully returns a trajectory that falsifies the system (see Fig. 3).

4

Hybrid systems with affine dynamics

We now turn to the case of hybrid systems with affine dynamics in each location.
The objective is still to find a descent direction in H0 , given a simulated trajectory ηh0 originating at point h0 ∈ H0 . Note that since we have assumed that
prL (H0 ) is a singleton set, the problem reduces to finding a descent direction in
X0 = prX (H0 ).
Assumptions. At this point, we make the following assumptions:
a. The continuous dynamics in each location are stable.1
1

This is not a restrictive assumption since we can also consider incrementally stable
systems [17], and even unstable linear systems [18].

1.6
U
Initial
Worst

1.4
1.2
1
0.8
0.6
0.4
0.2
0
−0.2
0

0.5

1

1.5

2

Fig. 3. The unsafe set U , the initial test trajectory starting from x(0) = 0 and the
trajectory that falsifies the system.

b. For every transition e ∈ L2 , the resets Re(·, e) are differentiable functions
of their first argument.
c. Conditions 4 and 5 of Theorem III.2 in [19] are satisfied, namely: for
all i, there exists a differentiable function σi : Rn 7→ R such that Inv(li ) =
{x ∈ Rn |σi (x) ≥ 0}; and, for all i, x such that σi (x) = 0, the Lie derivative
LF σi (x) 6= 0. This allows us to have a differentiable transition time tx of the
trajectory starting at the initial point x ∈ X0 .
d. The sequence of locations loc(ηh0 ) enters the location of the unsafe set.
This is required for our problem to be well-defined (specifically, for the objective
function to have finite values). The task of finding such an h0 is delegated to the
higher-level stochastic search algorithm, within which our method is integrated.
4.1

Descent in the Robustness Ellipsoid

Consider a trajectory ηh0 with positive robustness, with loc(ηh0 ) = l0 l1 . . . lN .
This is provided by the simulation. Let the initial set X0 be in location l0 and
let lU denote the location of U. In order to solve Problem 1, we assume that
lU appears in loc(ηh0 ) (see Assumption d above) - otherwise, f (h0 ) = +∞ and
the problem as posed here is ill-defined. We search for an initial point h′0 ∈ H0
(actually x′0 ∈ X0 ), whose trajectory gets closer to the unsafe set than the
current trajectory ηh0 .
In order to satisfy the constraints of Problem 1, we need to make sure that
the new point h′0 that we propose generates a trajectory that follows the same
sequence of locations as ηh0 . This constraint can be satisfied using the notion
of robust neighborhoods introduced in [6]. In [6], it is shown that for stable
systems and for a given safe initial point h0 = (l0 , x0 ), there exists an ‘ellipsoid
of robustness’ centered on x0 , such that any trajectory starting in the ellipsoid,

remains in a tube around ηh0 . The tube has the property that all trajectories in
it follow the same sequence
of locations as ηh0 . Therefore, we restrict the choice
T
of initial point to X0 E(x0 ), where E(y) = {x|(x − y)T R−1 (x − y) ≤ 1} is the
ellipsoid of robustness centered on x0 , with shape matrix R. Formally, in [6], the
following result was proven.
Theorem 1 Consider a hybrid automaton H, a compact time interval [0, T ],
a set of initial conditions H0 ⊆ H and a point h0 = (l0 , x0 ) ∈ H0 . Then, we
can compute a number ε > 0 and a bisimulation function φ(x1 , x2 ) = (x1 −
x2 )T M (x1 − x2 ), where M is a positive semidefinite matrix, such that for any
x′0 ∈ {y ∈ X | φ(x0 , y) ≤ ε}, we have loc(ηh0 ) = loc(η(l0 ,x′0 ) ).
Remark 1 (i) In [6], in the computation of ε, we also make sure that any point
in the robust neighborhood generates a trajectory that does not enter the unsafe
set. In this work, we relax this restriction since our goal is to find a point that
generates a trajectory that might enter the unsafe set. (ii) In view of Theorem
1, the shape matrix for the ellipsoid is defined as R = ε2 M −1 .
We now proceed to pose our search problem as a feasibility problem. Let t0
be the time at which sx0 is closest to U. We choose P (x0 ; t0 ) as our descent set:
recall that it is the set of all points
T which are closer to U than sx0 (t0 ) (Def. 1).
Therefore, if we can find x∗ ∈ X0 E(x0 ) such that sx∗ (t∗ ) ∈ P (x0 ; t0 ) for some
t∗ , it follows that f (x∗ ) ≤ f (x0 ). To simplify notation, let W = P (x0 ; t0 ) be the
descent set. As before, it is assumed that W = {x ∈ Rn : pi (x) ≤ 0, i = 1 . . . k}
for differentiable pi . The search problem becomes:
T
Given ηh0 , find x∗ ∈ X0 E(x0 ) and t∗ ≥ 0, such that sx∗ (t∗ ) ∈ W. This is
cast as an optimization problem over z ∈ Rn × R+ × R:
min ν

z=(x,t,ν)

s.t. C0 x − g0 ≤ 0
(x − x0 )T P −1 (x − x0 ) − 1 ≤ ν
pi (sx (t); x0 ) ≤ ν, i = 1 . . . k

(3)

where sx (t) = prX (η(l0 ,x) (t)) and X0 = {x|C0 x − g0 ≤ 0}.
Remark 2 Note that Problem (3) is specific to a choice of initial point x0 ; this
will be important in what follows. In our implementation, the first constraint is
specified as bounds to the optimization and so is always satisfied.
Later in this section, we discuss how to solve this optimization problem. For
now, we show how solving this problem produces a descent direction for the
robustness function. For convenience, for z = (x, t, ν), we define the constraint

functions
G0 (z) = C0 x − g0
GE (z) = (x − x0 )T P −1 (x − x0 ) − 1


p1 (sx (t); x0 )


..
GW (z) = 

.

(4a)
(4b)
(4c)

pk (sx (t); x0 )

A point z is feasible if it satisfies the constraints in Problem (3). Finally, define
the objective function F (z) = ν.
The objective function F (z) measures the slack in satisfying the constraints:
a negative ν means all constraints are strictly satisfied, and in particular, GW .
Thus, we have a trajectory that enters W and, hence, gets strictly closer to U.
This reasoning is formalized in the following proposition:
Proposition 2. Let z ∗ = (x∗ , t∗ , ν ∗ ) be a minimum of F (z) in program (3).
Then f (l0 , x∗ ) ≤ f (l0 , x0 ).
Proof. It is assumed that the optimizer is iterative and that it returns a solution
that decreases the objective function. In what follows, for a vector y ∈ Rn , max y
is the largest entry in y.
We first remark that for a given x and t that satisfy the constraints in (3),
z = (x, t, max{GE (x, t), GW (x, t)})
is feasible, and F (z) ≤ F (x, t, ν) for any feasible (x, t, ν). Therefore, we may only
consider points with F (z) = ν = max{GE (x, t), GW (x, t)}.
Let z0 = (x0 , t0 , ν0 ) be the initial point of the optimization. Because x0 is the
center of E(x0 ), GE (z0 ) = −1. And, because sx0 (t0 ) ∈ ∂W, max GW (z0 ) = 0.
Thus ν0 = 0. Therefore, at the minimum z ∗ = (x∗ , t∗ , ν ∗ ) returned by the
optimizer, ν ∗ ≤ ν0 = 0. In particular, GW (z ∗ ) ≤ 0, and the new trajectory sx∗
enters W. Therefore, its robustness is no larger than that of the initial trajectory
sx 0 .
We now address how Problem 3 might be solved. Functions F , G0 and
GE are differentiable in z = (x, t, ν). It is not clear that GW , or equivalently,
pi (sx (t); x0 ), as a function of z, is differentiable. We now show that under some
asumptions on the pi , for trajectories of linear systems, pi is in fact differentiable
in both x and t, over an appropriate range of t. This implies differentiability in
z. Therefore, standard gradient-based optimizers can be used to solve Problem
3.
For the remainder of this section, we will re-write sx (t) as s(x, t) to emphasize
the dependence on the initial point x. s(i) (x, τ ) will denote the point, at time τ ,
on the trajectory starting at x ∈ Inv(li ), and evolving according to the dynamics
of location i. When appearing inside location-specific trajectories such as s(i) , the
time variable will be denoted by the greek letter τ to indicate relative time: that

is, time measured from the moment the trajectory entered li , not from datum
0. s(x, t) (without superscript) will denote the hybrid trajectory, traversing one
or more locations. We will also drop the x0 from pi (y; x0 ), and write it simply
as pi (y).
We first prove differentiability in x. Therefore, unless explicitly stated otherwise, the term ‘differentiable’ will mean ‘differentiable in x’. Start by noting
that pi (s(x, t)) is a composite function of x ∈ X0 . Since pi is differentiable, it
is sufficient to prove that s(x, t) is differentiable. The hybrid trajectory s(x, ·) is
itself the result of composing the dynamics from the visited locations l0 , ..., lN −1 .
Recall that E(x0 ) is the ellipsoid of robustness centered at x0 . As shown by
Julius et al. [6], the following times are well-defined:
T
Definition 2 (Transition times) Given x0 ∈ X0 , let E0 , int(E(x0 ) X0 ).
ti is the time at which trajectory s(x0 ) transitions from Inv(li−1 ) into Inv(li )
through guard Guard(li−1 , li ).
t−
i is the maximal time for which the image of E0 under the hybrid dynamics is
contained in Inv(li−1 ):
t−
i = max{t|s(E0 , t) ⊂ Inv(li−1 )}
In other words, t−
i is the time at which occurs the first li−1 -to-li transition of a
point in s(E0 ).
t+
i is the minimal time for which the image of E0 under the hybrid dynamics
is contained in Inv(li ):
t+
i = min{t|s(E0 , t) ⊂ Inv(li )}
In other words, t+
i is the time at which occurs the last li−1 -to-li transition of a
point in s(E0 ).
For a given point x ∈ X0 , txi−1→i (τxi−1→i ) is the absolute (relative) transition
time of trajectory s(i) (x) from Inv(li−1 ) into Inv(li ) through guard Guard(li−1 , li ).
, with
+ τy1→2
= τx0→1
and t2 = tx1→2
= τx0→1
Thus, for example, t1 = tx0→1
0
0
0
0
0
0
0→1
y0 = s (x0 , tx0 ). When the transition is clear from context, we will simply
write tx (τx ).
We will first show differentiability of a trajectory that visits only 2 locations
l0 and l1 :
s(x0 , t) = s(1) (Re(s(0) (x0 , tx ), (l0 , l1 )), t − tx )
(5)
Example 2 We first present a simple 1D example to illustrate the definitions
and the idea of the proof. Consider the hybrid system with three locations
H = (R, {0, 1, 2}, {(0, 1), (1, 2)}, Inv, F low, Guard, Id)
where Inv(l) = R for l = 0, 1, 2, and the flow is defined by

x(t) if l ∈ {0, 2}
F low(l, x) = ẋ(t)
−x(t)
if l = 1

The guards are Guard(0, 1) = {1} and Guard(1, 2) = {1/4}. Id is the identity
map, so there are no resets. The initial set is X0 = [0, 1/2]. The solutions in the
individual locations are then
s(0) (x, t) = et x
s(1) (x, t) = e−t x
s(2) (x, t) = et x
We can solve, in this simple case, for τx0→1 : eτx x = 1 ⇒ τx0→1 = ln(1/x).
Similarly for τx1→2 : e−τx · 1 = 1/4 ⇒ τx1→2 = ln(4x).
We first show differentiability of the trajectory over locations 0 and 1. We
then do the same for a trajectory over locations 1 and 2. Then we stitch the
two together and show differentiability over 3 locations. For locations 0 and 1:
s(x, t) = s(1) (s(0) (x, tx ), t − tx ) = s(1) (1, t − tx ) = e−(t−tx ) · 1 = e−t /x ⇒
d
e−t
dt s(x, t) = − x2 .
Moving on the trajectory over locations 1 and 2, the procedure is the same:
from an initial point x ∈ Guard(0, 1) = {1}, for a fixed (relative time) τ ∈
(2) (1)
(t2 − t1 , t−
(s (x, τx ), τ − τx ) = s(2) (1/4, τ + ln(1/4x)) =
3 − t1 ): s(x, τ ) = s
eτ
d
τ +ln(1/4x)
τ
e
1/4 = e /16x ⇒ dτ s(x, τ ) = − 16x
2.
Finally we stitch up the 2 portions of the trajectory: x ∈ X0 , t ∈ [t2 , t−
3 ].
s(x, t) = s(2) (s(1) (s(0) (x, t1 ), t2 − t1 ), t − t2 ) = s(2) (s(1) (1, t2 − t1 ), t − t2 ) =
s(2) (1/4, t − t2 ) = et−t2 /4. Since t2 = tx0→1 + τ11→2 = ln(1/x) + ln(4 · 1) =
t
d
ln(4/x) ⇒ s(x, t) = e4 eln(x/4) = xet /16 ⇒ dt
s(x, t) = et /16.
We now prove the general case.
Proposition 3. Let x0 ∈ E0 , and fix t ∈ (t1 , t−
2 ]. Consider the hybrid trajectory over 2 locations in Eq.(5). If Assumptions a-d are satisfied, then s(x, t) is
differentiable at x0 .
Proof. In what follows, e = (l0 , l1 ).
Z

τx

e(τx −s)A0 bds
Z τx
τ x A0
τ x A0
e−sA0 bds
= |e {z x} + |e {z }
0
term1
term2 |
{z
}

s(0) (x, τx ) = eτx A0 x +

0

term3

Rt
Terms 1 and 2 are clearly differentiable in x. For term3, write M (t) = 0 e−sA0 bds
so term3 = M (τx ). M (t) is differentiable by the 2nd Fundamental Theorem of
Calculus and its derivative is M ′ (t) = e−tA0 b. As a consequence of Assumption c, τx itself is differentiable in x (Lemma III.3 in [19]), and the chain
rule allows us to conclude that term3 is differentiable in x. Thus s(0) (x, τx )
is differentiable over E0 . Since Re(·, e) is differentiable by Assumption b, then

Re(s(0) (x, τx ), e) is differentiable over E0 . Note that E0 is open and s(0) is continuous, so U = {w ∈ Rn |w = s(0) (x, tx ) for some x ∈ E0 } ⊂ Guard(e) is open.
Since Re(·, e) is continuous, then Re(U, e) is open. Next,
s(x, t) = s(1) (Re(s(0) (x, tx ), e), t − tx )
(t−tx )A1

= |e {z

term4

} Re(s

(0)

(t−tx )A1

(x, tx ), e) + |e {z

term5

}

Z
|

t−tx

0

e−sA1 b1 ds
{z
}

term6

Using the same argument as above, terms 4, 5 and 6 are differentiable in x. In
conclusion, s(x, t) is differentiable at over E0 , and this ends the proof.
The following proposition generalizes Prop. 3 to trajectories over more than
2 locations.
Proposition 4. Fix t ∈ (tN −1 , T ], and consider the hybrid trajectory over N ≥
1 locations. Then s(x, t) is differentiable at x0 for all x0 ∈ E0 .
Proof. We argue by induction over the number of locations N . The base case
N = 1 is true by hypothesis, and the case N = 2 has been proven in Prop.
3. For N > 2 and t ≤ tN −1 , let ζ(x, t) be the trajectory over the first N − 1
locations, so that s(x, t) = s(N −1) (Re(ζ(x, τN −2 ), (lN −2 , lN −1 )), t−tN −1 ). By the
induction hypothesis, ζ(x, t) is differentiable at x0 . Then ζ and s(N −1) satisfy
the conditions of the case N = 2.
Differentiability with respect to time is easily proven:
Proposition 5. Let x0 ∈ E0 and t ∈ (tN −1 , T ), that is, a time at which the
trajectory is in the last location. Consider the hybrid trajectory over N ≥ 1
locations. Then s(x0 , t) is differentiable in t over [tN −1 , T ).
Proof. s(x0 , t) = s(N −1) (x0 , t − tN −1). The location-specific trajectories s(i) (x, ·)
are solutions of differential equations involving at least the first time derivative.
Therefore, they are smooth over (tN −1 , T ). This implies differentibility of the
hybrid trajectory s(x0 , ·) over the same interval. At t = T , the trajectory is only
left-differentiable, since it’s undefined from the right.
The following result is now a trivial application of the chain rule to pi ◦ s:
Proposition 6. Let x0 ∈ E0 , t ∈ (tN −1 , T ). If pi is differentiable for all i =
1, . . . , k, then GW is differentiable in z over E0 × R+ × R.
We choose Sequential Quadratic Programming (SQP), as a good generalpurpose optimizer to solve Problem 3. SQP is a Q-quadratically convergent iterative algorithm. At each iterate, GW (xi , ti , νi ) is computed by simulating the
system at xi . This is the main computational bottleneck of this method, and
will be discussed in more detail in the Experiments section.

Algorithm 1 Robustness Ellipsoid Descent (RED)
Input: An initial point x0 ∈ X0 , and corresponding t0 .
Output: zQ .
1: Initialization: i = 0
2: Compute zi∗ = (x∗i , t∗i , νi∗ ) = minimum of Prob3[Wi ].
3: while νi∗ < 0 do
4:
xi+1 ← x∗i
5:
ti+1 = arg mint dU (sxi+1 (t))
6:
Wi+1 = P (xi+1 )
7:
Compute zi∗ = (x∗i , t∗i , νi∗ ) = min of Prob3[Wi+1 ].
8:
i=i+1
9: end while
10:
11: Return zQ , zi∗

4.2

Convergence to a local minimum

Solving Problem (3), for a given W, produces a descent direction for the robustness function. However, one can produce examples where a local minimum of
F (·) is not a local minimum of the robustness function f . This section derives
conditions under which repeated solution of Problem (3) yields a local minimum
of the robustness function.
T
For i = 0, 1, 2, . . . , let xi ∈ X0 E(xi−1 ), and let ti be the time when sxi
is closest to U. Let Wi = P (xi ; ti ) be the descent set for this trajectory. For
each Wi , one can setup the optimization Problem (3) with W = Wi , and initial
point (xi , ti , 0); this problem is denoted by Prob3[Wi ]. (Recall from the proof
of Proposition 2 that ν = 0 at the initial point of the optimization problem).
Finally, let zi∗ = (x∗i , t∗i , νi∗ ) be the minimum obtained by solving Prob3[Wi ].
Algorithm 1 describes how to setup a sequence of optimization problems that
leads to a local minimum of f . It is called Robustness Ellipsoid Descent, or RED
for short.
Proposition 7. Algorithm 1 (RED) terminates
Proof. Proposition 2 holds for each problem Prob3[Wi ]. Therefore, each solution
with νi < 0 gives a trajectory sx∗i with a smaller robustness than sx∗i−1 : f (x∗i ) <
f (x∗i−1 ). Thus (f (xi ))i∈N is a decreasing sequence, lower bounded by 0. Therefore, it converges to a limit r ≥ 0. But how to prove that this limit is indeed a
minimum of f?
Proposition 8. Assume that Algorithm 1 halts at a point zQ = (xQ , tQ , νQ ),
for which there exist t1 , t2 such that:
– 0 ≤ t1 ≤ tQ ≤ t2
– dU (sxQ (t)) > f (xQ )∀t ∈ TR , [0, t1 ] ∪ [t2 , T ), and
– t2 − t1 is ‘sufficiently small’.

Then xQ is a local minimum of the robustness function f .
Proof. We assume that the trajectory starting at xQ is safe - otherwise, we’re
done since we found an unsafe trajectory.
Two tubes will be constructed: one contains sxQ over (t1 , t2 ), the other contains it over TR . They are such that no trajectory in them gets closer to WQ
than sxQ . Then it is shown that all trajectories in a neighborhood of xQ are
contained in these tubes, making xQ a local minimum of the robustness function
f.

Fig. 4. [Proof of Prop.8] All trajectories starting in a neighborhood of xQ will be
contained in the orange tube over TR and in the green tube over (t1 , t2 )

By the halting condition, νQ = 0. Since the optimizer always returns a local
minimum of the objective function F , there exists a neighborhood N (zQ ) of zQ
such that for all z ∈ N (zQ ), F (z) ≥ F (zQ ) = νQ = 0
⇔ ∀(x, t, ν) ∈ N (zQ ), sx (t) ∈
/ intWQ
⇔ ∀(x, t, ν) ∈ N (zQ ), dU (sx (t)) ≥ f (xQ )
N (zQ ) can be expressed as
N (zQ ) = B(xQ , ǫ) × (t3 , t4 ) × (−νl , νl )
ǫ > 0, νl > 0, B(xQ , ǫ) ⊂ E(x0 ) ∩ X0
(Since Rn × R+ × R is a finite product, the box and product topologies are
equivalent, so it doesn’t matter which one we use.)
We now precise the notion of ‘small enough’: we require that
(t1 , t2 ) ⊆ (t3 , t4 )

Therefore
∀x ∈ B(xQ , ǫ), t ∈ (t1 , t2 ), dU (sx (t)) ≥ f (xQ )
Thus
∀x ∈ B(xQ , ǫ),

inf

t∈(t1 ,t2 )

dU (sx (t)) ≥ f (xQ )

(6)

We now study the behavior of trajectories starting in B(xQ , ǫ) over the remaining time periord TR . Recall that U ⊂ WQ . Let wo be any point on the
boundary ∂WQ . Then
∀t ∈ TR , dU (sxQ (t)) > f (xQ ) = dU (wo ) > 0
⇒ ∀t ∈ TR , dWQ (sxQ (t)) > 0
Then
Λ = inf{dWQ (sxQ (t))|t ∈ TR } > 0
sx is continuous as a function of x for every t, therefore
∃δ > 0 s.t. x ∈ B(xQ , δ) ⇒ d(sxQ (t), sx (t)) < Λ
Pick any point w ∈ WQ . Then ∀x ∈ B(xQ , δ) and t ∈ TR
d(sxQ (t), w) ≤ d(sxQ (t), sx (t)) + d(sx (t), w)
< Λ + d(sx (t), w)
⇒ d(sx (t), w) > d(sxQ (t), w) − Λ
Minimizing both sides over w ∈ WQ ,
dWQ (sx (t)) > dWQ (sxQ (t)) − Λ ≥ 0
⇒ inf dWQ (sx (t)) ≥ 0
t∈TR

In conclusion
∀x ∈ B(xQ , δ), inf dU (sx (t)) ≥ f (xQ )
t∈TR

Putting Eqs.(6) and (7) together, it comes that ∀x ∈ B(xQ , min{ǫ, δ})
inf dU (sx (t)) ≥ f (xQ )

t∈R+

⇔ ∀x ∈ B(xQ , min{ǫ, δ}), f (x) ≥ f (xQ )
and xQ is a local minimum of the robustness f .

(7)

Algorithm 2 RED with Simulated Annealing (SA+RED)
Input: An initial point x ∈ X0 .
Output: Samples Θ ⊂ X0 .
Initialization: BestSoFar = x, fb = f (BestSoFar)
1: while f (x) > 0 do
2:
x′ = ProposalScheme(x)
3:
α = exp (−β(f (x′ ) − fb ))
4:
if U (0, 1) ≤ α then
5:
x∗ = RED(x′ )
6:
x = x∗
7:
else// Use the usual acceptance criterion
8:
α = exp (−β(f (x′ ) − f (x)))
9:
if U (0, 1) ≤ α then x = x′
10:
end if
11:
end if
12:
(BestSoFar,fb ) = BetterOf(x, BestSoFar)
13: end while

4.3

Ellipsoid Descent with Stochastic Falsification

As outlined in the introduction, the proposed method can be used as a subroutine in a higher-level stochastic search falsification algorithm. A stochastic
search will have a ProposalScheme routine: given a point x in the search space,
ProposalScheme will propose a new point x′ as a falsification candidate. Robustness Ellipsoid Descent (RED) may then be used to further descend from some
judiciously chosen proposals. Algorithm 2 illustrates the use of RED within the
Simulated Annealing (SA) stochastic falsification algorithm of [12]. U (0, 1) denotes a number drawn uniformly at random over (0, 1). Given two samples x and
y, BetterOf(x, y) returns the sample with smaller robustness, and its robustness.
For each proposed sample x′ , it is attempted with certainty if its robustness
is less than the smallest robustness fb found so far. Else, it is attempted with
′
probability e−β(f (x )−fb ) (lines 3-4). If x′ is attempted, RED is run with x′ as
starting point, and the found local minimum is used as final accepted sample
(line 6). If the proposed sample is not attempted, then the usual acceptance′
rejection criterion is used: accept x′ with probability min{1, e−β(f (x )−f (x)) }. As
in the original SA method, ProposalScheme is implemented as a Hit-and-Run
sampler (other choices can be made). The next section presents experimental
results on three benchmarks.
4.4

Experiments

This section describes the experiments used to test the efficiency and effectiveness of the proposed algorithm SA+RED, and the methods compared against
it.
We chose 3 navigation benchmarks from the literature: Nav0 (4-dimensional
with 16 locations) is a slightly modified benchmark of [20], and it is unknown

Fig. 5. The navigation benchmark example.

whether it is falsifiable or not. Nav1 and Nav2 (4-dimensional with 3 locations)
are the two hybrid systems in the HSolver library of benchmarks [21], and are
falsifiable. We also chose a filtered oscillator, Fosc (32-dimensional with 4 locations), from the SpaceEx library of benchmarks [22]. We describe the Nav0
benchmark that we used, as it a slightly modified version of the benchmark
in [20].
Example 3 (Navigation Benchmark [20]) The benchmark studies a hybrid
automaton H with a variable number of discrete locations and 4 continuous variables x1 , x2 , y1 , y2 that form the state vector x = [x1 x2 y1 y2 ]T . The structure
of the hybrid automaton can be better visualized in Fig. 5. The invariant set of
every (i, j) location is an 1 × 1 box that constraints the position of the system,
while the velocity can flow unconstrained. The guards in each location are the
edges and the vertices that are common among the neighboring locations.
Each location has affine constant dynamics with drift. In detail, in each location (i, j) of the hybrid automaton, the system evolves under the differential
equation ẋ = Ax − Bu(i, j) where the matrices A and B are
0 0 1

 0

0
0
0
0
00 0
1
and B = −1.2 0.1
A = 0 0 −1.2 0.1
0 0 0.1 −1.2

0.1 −1.2

and the input in each location is
u(i, j) = [sin(πC(i, j)/4) cos(πC(i, j)/4)]T .
The array C is one of the two parameters of the hybrid automaton that the user
can control and it defines the input vector in each discrete location. Here, we
consider the input array denoted in Fig. 5.

The set of initial conditions is the set H0 = {13} × [0.2 0.8] × [3.2 3.8] ×
[−0.4 0.4]2 (green box in Fig. 5) and the unsafe set is U = {4} × {x ∈ R4 | ||x −
(3.5 0.5 0 0)|| ≤ 0.3} (red circle in Fig. 5). This is slightly modified from the
original benchmark to simplify the programming of the pi functions. Sample trajectories of the system appear in 5 for initial conditions [0.8 3.2 − 0.2 0.35]T
(red trajectory) and [0.4 3.3 − 0.1 − 0.1]T (blue trajectory). Note that the two
trajectories follow different discrete locations.
The methods compared are: SA+RED, pure Simulated Annealing (SA) [12],
mixed mode-HSolver (mm-HSolver) [21], and the reachability analysis tool SpaceEx
[22]. Because ours is a falsification framework, SpaceEx is used as follows: for
a given bound j on the number of discrete jumps, SpaceEx computes an over approximation R(j) of the set reachable in j jumps R(j) : R(j) ⊂ R(j). If
R(j) ∩ U is empty, then a fortiori R(j) ∩ U is empty, and the system is safe if
trajectories are restricted to j jumps. If, however, R(j) ∩ U 6= ∅, no conclusion
can be drawn.
Because SA and SA+RED are stochastic methods, their behavior will be
studied by analyzing a number of runs. A regression will mean a fixed number of
runs, all executed with the same set of parameters, on the same benchmark. mmHSolver is deterministic, and thus one result is presented for benchmarks Nav1
and Nav2 (Nav0 was not tested by mm-HSolver’s authors [21]). The mm-HSolver
results are those reported in the literature. SpaceEx was run in deterministic
mode on Nav0 (specifically, we set parameter ‘directions’ = ‘box’ [22]).
Parameter setting: We set the test duration T = 12sec, which we estimate is long enough to produce a falsifying trajectory for Nav0 if one exists.
For SA+RED, we chose to generate 10 samples (|Θ| = 10). We will see that
even this small number is enough for the algorithm to be competitive. A regression consists of 20 jobs. The SpaceEx parameters were varied in such a way
that the approximation R of the reachable set R became increasingly precise.
Clustering% was given the values 0, 20 and 80 (the smaller the Clustering%, the
better the approximation and the longer the runtime). The ODE solver timestep
δ was given the values 0.0008, 0.02, 0.041 seconds. These are, respectively, the
minimum, median, and average values of δ used by the variable step-size ODE
solver used by SA+RED. The smaller δ, the better the approximation and the
longer the runtime. The following parameters were fixed: ‘directions’ = ‘box’,
‘Local time horizon’ = 10sec, rel-err = abs-err = 1.0e-10. The Nav0 SpaceEx
configuration files can be obtained by request from the authors.
The performance metrics: Each run produces a minimum robustness.
For a given regression, we measure: the smallest, the average, and the largest
minimum robustness found by the regression (min, avg, max in Table 1). The
standard deviation of minimum robustness is also reported (σf ). For SpaceEx,
we had to simply assess whether R(j) intersected U or not.
The cost metric: Each run also counts the number of simulated trajectories in the course of its operation: SA simulates a trajectory for each proposed
sample, SA+RED simulates a trajectory each time the constraint function of
Prob3[Wi ] is evaluated (and for each sample), and mm-HSolver simulates tra-

jectories in falsification mode. The trajectories simulated by SA and SA+RED
have a common, fixed, pre-determined duration T . Thus the cost of these algorithms can be compared by looking at the Number of Trajectories (NT) each
simulates (column N T in Table 1 - the overline denotes an average). The trajectories computed by mm-HSolver have varying lengths, determined by a quality
estimate. So for comparison, we report the number of single simulation steps
(SS), i.e. the number of points on a given trajectory (column SS - mm-HSolver,
being deterministic, has one value of SS). Unfortunately, SS doesn’t include the
cost of doing verification in mm-HSolver, so it should be considered as a lower
bound on its computational cost. On the other hand, because of the choice of
T , the SS numbers reported for SA+RED should be treated as upper bounds:
choosing a shorter a-priori T will naturally lead to smaller numbers. An exact
comparison of the costs of SA+RED and mm-HSovler would require knowing
the duration of the shortest falsifying trajectory, and setting the a-priori T to
that, and somewhat incorporating the cost of verification. The operations that
SpaceEx does are radically different from those of the other methods compared
here. The only way to compare performance is through the runtime.
Experimental setup: we impose an upper limit N TMAX on N T : SA+RED
is aborted when its N T reaches this maximum, and SA is made to generate
N TMAX samples. (Of course, SA+RED might converge before simulating all
N TMAX trajectories). 3 values were chosen for N TMAX : 1000, 3000 and 5000.
For each value, a regression is run and the results reported. This allows us to
measure the competitiveness of the 2 algorithms (i.e. performance for cost).
Experiments: Table 1 compares SA+RED to SA: we start by noting that
SA+RED falsified Nav2, whereas SA failed to so. On most regressions, SA+RED
achieves better performance metrics than SA, for the same (or lower) computational cost. This is consistent whether considering best case (min), average
case (avg) or worst case (max). There are 2 exceptions: for Nav1 and Nav2,
N TMAX = 5000 produces better average and max results for SA than for
SA+RED. When running realistic system models, trajectory simulation is the
biggest time consumer, so effectively N T is the limiting factor. So we argue that
these 2 exceptions don’t invalidate the superiority of SA+RED as they occur for
high values of N T that might not be practical with real-world models. (In these
cases, we observed that SA eventually produces a sequence of samples whose
trajectories finish by making a large number of jumps between locations 3 and
2, with a relatively high robustness. From there SA then produces a sample
with 0 (or close to 0) robustness. This happens on every Nav1 run we tried, and
most Nav2 runs, resulting in the numbers reported. The RED step in SA+RED
seems to avoid these trajectories by ‘escaping’ into local minima, and is worthy
of further study.)
Table 2 compares SA+RED to mm-HSolver. We note that SA+RED
fies the benchmarks, as does mm-HSolver. For Nav1, SS is greater than
HSolver’s SS, though the falsifying runs have SS values (last column)
smaller and larger than mm-HSolver. For Nav2, which appears to be more

falsimmboth
chal-

System N TM AX

NT
σf SA+RED Rob.
SA Rob.
(σNT )
min, avg, max
min, avg, max
Nav0
1000
1004 (1.4) 0.022 0.2852, 0.30,0.35 0.2853,0.33,0.33
3000 2716 (651) 0.019 0.2852,0.29,0.32 0.2858,0.31,0.36
5000 4220 (802) 0.009 0.285,0.28,0.32
0.286,0.32,0.35
Nav1
1000
662 (399) 0.21
0,0.43,0.65
0,0.96,1.88
3000 1129 (1033) 0.23
0,0.39,0.65
0,0.99,1.80
5000 1723 (1770) 0.23
0,0.38,0.68
0,0,0
Nav2
1000
902 (246) 0.32
0,0.54,0.78
0.3089,1.11,1.90
3000 1720 (1032) 0.3
0,0.53,0.83
0.3305,1.29,1.95
5000 1726 (1482) 0.27
0,0.62,0.79
0,0.002,0.01
Fosc
1000
1000 (9.3) 0.024 0.162,0.206,0.251 0.1666,0.216,0.271
3000
3000 (8.7) 0.024 0.163,0.203,0.270 0.173,0.212,0.254
5000
5000 (11) 0.028 0.167,0.193,0.258 0.185, 0.218, 0.245
Table 1. Comparison of SA and SA+RED. To avoid clutter, Robustness values are
reported to the first differing decimal, with a minimum of 2 decimals. σf is standard
deviation of robustness for SA+RED.

System N TM AX

SS
σf SA+RED Rob mm-HSolver
SS at min Rob
(σSS )
min, avg, max Rob, N T , SS
for SA+RED
Nav1
1000
47k (30k) 0.21 0,0.43,0.65
0, 22,5454
0,1560,16k
3000
79k (76k) 0.23 0,0.39,0.65
0,0,1600, 127k
5000 143k (141k) 0.23 0,0.38,0.68
7660, 38k, 102k, 159k
Nav2
1000
63k (18k) 0.32 0,0.54,0.78
0, 506, 138k
2888, 74k
3000 126k (80k) 0.3 0,0.53,0.83
14k, 57k, 210k
5000 124k (114k) 0.27 0,0.622,0.79
3450, 121k, 331k
Table 2. Comparison of SA+RED and mm-HSolver. The last column shows some of
the SS values at which min robustness is achieved by SA+RED on various runs.

lenging, SA+RED performed better on average than mm-HSolver. However, we
point out again that exact comparison is hard.
For SpaceEx running on Nav0, we observed that our initial parameter set
produces an R(j) that intersects U. Since this is inconclusive, we modified the
parameters to get a better approximation. For parameter values (Clustering%,
δ) = (0, 0.0008), R(j) and U were almost tangent, but SpaceEx runtimes far
exceeded those of SA+RED (more than 1.5 hours). Moreover, SpaceEx did not
reach a fixed point of its iterations (we tried up to j = 200 iterations before
stopping due to high runtimes). Thus, we can not be sure that all of the reachable
space was covered. While this may be seen as an analogous problem to the choice
of T in SA+RED, the computational cost of increasing j is much more prohibitive
than that of increasing T . We now present some detailed runtime results. For
SA+RED, ‘runtime’ means the User time reported by the Unix time utility.
SA+RED was run on a dedicated Intel Xeon processor, x86-64 architecture,
under the Unix OS. SpaceEx reports its own runtime. It was run on a Dual-

Clustering%

δ(sec)
SA+RED Runtime (sec) N TM AX
0.0008 0.002 0.041
min,avg,max
80
737
30
15
324, 426, 596
1000
20
1066
53
33
620, 1132, 1385
3000
10
1460 NA NA
767,1617, 2216
5000
0
> 5400 NA NA
Table 3. Comparison of SA+RED and SpaceEx runtimes. NA means the experiment
was not run, because a more accurate run was required. The right-most columns shows
the N TM AX constraint for which the SA+RED runtimes were obtained.

Core Intel Centrino processor, under a Windows7 64b OS, with no other user
applications running.
Thus we may conclude that stochastic falsification and reachability analysis
can play complementary roles in good design practice: first, stochastic falsification computes the robustness of the system with respect to some unsafe set.
Guided by this, the designer may make the system more robust, which effectively
increases the distance between the (unknown) reachable set and the unsafe set.
Then the designer can run a reachability analysis algorithm where coarse overapproximations can yield conclusive results.

5

Conclusions

The minimum robustness of a hybrid system is an important indicator of how safe
it is. In this paper, we presented an algorithm for computing a local minimum
of the robustness for a certain class of linear hybrid systems. The algorithm can
also be used to minimize the robustness of non-hybrid linear dynamic systems.
When integrated with a higher-level stochastic search algorithm, the proposed
algorithm has been shown to perform better than existing methods on literature
benchmarks, and to complement reachability analysis. We will next deploy this
capability to perform local descent search for the falsification of arbitrary linear
temporal logic specifications, not only safety specifications. This investigation
opens the way to several interesting research questions. Most practically, reducing the number of tests N T results in an immediate reduction of the computation
cost. Also useful, is the determination of an appropriate test duration T , rather
than a fixed arbitrary value.
In terms of performance guarantees, obtaining a lower bound on the optimum
achieved in Problem 3 could lead to a lower bound on the optimal robustness.
One level higher in the algorithm, it is important to get a theoretical understanding of the behavior of the Markov chains iterated by SA+RED to further
improve it.

References
1. Girard, A., LeGuernic, C.: Efficient reachability analysis for linear systems using
support functions. In: IFAC World Congress. (2008) 22–35

2. Asarin, E., Dang, T., Maler, O., Testylier, R.: Using redundant constraints for
refinement. In: International Symposium on Automated Technology for Verification
and Analysis. Volume 6252 of LNCS., Springer (2010)
3. LeGuernic, C., Girard, A.: Reachability analysis of hybrid systems using support functions. In: Computer Aided Verification. Volume 5643 of LNCS., Springer
(2009) 540–554
4. Althoff, M., Stursberg, O., Buss, M.: Computing reachable sets of hybrid systems using a combination of zonotopes and polytopes. Nonlinear Analysis: Hybrid
Systems 4(2) (2010) 233 – 249
5. Girard, A., Pappas, G.J.: Verification using simulation. In: Hybrid Systems: Computation and Control (HSCC). Volume 3927 of LNCS., Springer (2006) 272 – 286
6. Julius, A.A., Fainekos, G., Anand, M., Lee, I., Pappas, G.: Robust test generation
and coverage for hybrid systems. In: Hybrid Systems: Computation and Control.
Volume 4416 of LNCS., Springer-Verlag Berlin Heidelberg (2007) 329–342
7. Dang, T., Donze, A., Maler, O., Shalev, N.: Sensitive state-space exploration. In:
Proc. of the 47th IEEE Conference on Decision and Control. (2008) 4049–4054
8. Branicky, M., Curtiss, M., Levine, J., Morgan, S.: Sampling-based planning, control
and verification of hybrid systems. IEE Proc.-Control Theory Appl. 153(5) (2006)
575–590
9. Plaku, E., Kavraki, L.E., Vardi, M.Y.: Falsification of ltl safety properties in hybrid
systems. In: Proc. of the Conf. on Tools and Algorithms for the Construction and
Analysis of Systems (TACAS). Volume 5505 of LNCS. (2009) 368 – 382
10. Rizk, A., Batt, G., Fages, F., Soliman, S.: On a continuous degree of satisfaction
of temporal logic formulae with applications to systems biology. In: International
Conference on Computational Methods in Systems Biology. Number 5307 in LNCS,
Springer (2008) 251–268
11. Zuliani, P., Platzer, A., Clarke, E.M.: Bayesian statistical model checking with
application to simulink/stateflow verification. In: Proceedings of the 13th ACM
International Conference on Hybrid Systems: Computation and Control. (2010)
243–252
12. Nghiem, T., Sankaranarayanan, S., Fainekos, G., Ivancic, F., Gupta, A., Pappas,
G.: Monte-carlo techniques for falsification of temporal properties of non-linear
hybrid systems. In: Hybrid Systems: Computation and Control. (2010)
13. Fainekos, G., Pappas, G.:
Robustness of temporal logic specifications for
continuous-time signals. Theoretical Computer Science 410(42) (2009) 4262–4291
14. Henzinger, T.A.: The theory of hybrid automata. In: Proceedings of the 11th
Annual Symposium on Logic in Computer Science, IEEE Computer Society Press
(1996) 278–292
15. Boyd, S., Vandenberghe, L.: Convex Optimization. Cambridge University Press
(2004)
16. Han, Z.: Formal Verification of Hybrid Systems using Model Order Reduction and
Decomposition. PhD thesis, Dept. of ECE, Carnegie Mellon University (2005)
17. Tabuada, P.: Verification and Control of Hybrid Systems: A Symbolic Approach.
Springer (2009)
18. Julius, A.A., Pappas, G.J.: Trajectory based verification using local finite-time
invariance. In: Hybrid Systems: Computation and Control. Volume 5469 of LNCS.,
Springer (2009) 223–236
19. Lygeros, J., Johansson, K.H., Simic, S.N., Zhang, J., Sastry, S.: Dynamical properties of hybrid automata. IEEE Transactions on Automatic Control 48 (2003)
2–17

20. Fehnker, A., Ivancic, F.: Benchmarks for hybrid systems verification. In: Hybrid
Systems: Computation and Control. Volume 2993 of LNCS., Springer (2004) 326–
341
21. Ratschan, S., Smaus, J.G.: Finding errors of hybrid systems by optimizing an
abstraction-based quality estimate. In: Proceedings of the Third Int’l Conf. on
Tests and Proofs, Zurich, Switzerland (2009) 153–168
22. Frehse, G., Guernic, C.L., Donz, A., Cotton, S., Ray, R., Lebeltel, O., Ripado, R.,
Girard, A., Dang, T., Maler, O.: Spaceex: Scalable verification of hybrid systems.
In: Proceedings of the 23d CAV. (2011)

Fiftieth Annual Allerton Conference
Allerton House, UIUC, Illinois, USA
October 1 - 5, 2012

A Model-Based Approach to Synthesizing Insulin Infusion Pump Usage
Parameters for Diabetic Patients
Sriram Sankaranarayanan, Christopher Miller, Rangarajan Raghunathan, Hadi Ravanbakhsh
and Georgios Fainekos
Abstract— We present a model-based approach to synthesizing insulin infusion pump usage parameters against varying
meal scenarios and physiological conditions. Insulin infusion
pumps are commonly used by type-1 diabetic patients to
control their blood glucose levels. The amounts of insulin
to be infused are calculated based on parameters such as
insulin-to-carbohydrate ratios and correction factors that need
to be calibrated carefully for each patient. Frequent and
careful calibration of these parameters is essential for avoiding
complications such as hypoglycemia and hyperglycemia.
In this paper, we propose to synthesize optimal parameters
for meal bolus calculation starting from models of the patient’s
insulin-glucose regulatory system and the infusion pump. Various off-the-shelf global optimization techniques are used to
search for parameter values that minimize a penalty function
defined over the predicted glucose sensor readings. The penalty
function “rewards” glucose levels that lie within the prescribed
ranges and “penalizes” the occurrence of hypoglycemia and
hyperglycemia. We evaluate our approach using a model of the
insulin-glucose regulatory system proposed by Dalla Man et al.
Using this model, we compare various strategies for optimizing
pump usage parameters for a virtual population of in-silico
patients.

I. I NTRODUCTION
Insulin infusion pumps are commonly used by type-1
diabetic patients to control their blood glucose levels. These
pumps supply insulin at programmable rates over time. Typically, the use of insulin infusion pumps has two components:
(a) continuous background infusion provided at a fixed basal
rate to offset the endogenous glucose production, and (b)
a fixed amount of insulin bolus provided to cover elevated
glucose levels, especially after a meal. The basal rate is set
by trial and error until the level of glucose remains steady
during fasting conditions (eg., overnight). Likewise, the bolus
dosage is decided by a fixed insulin to carbohydrate ratio
(icRatio) and a correction factor (Cor). The parameter icRatio
is used to calculate the amount of insulin bolus required to
address the increase in blood glucose levels following a meal,
based on the amount of carbohydrates in the meal. Likewise,
the parameter Cor can be used to help reduce higher than
desired blood glucose levels.
This work was funded, in part, by National Science Foundation (NSF)
grants under award numbers CPS-1035845, CNS-1016994 and CNS1017074. All views expressed are those of the authors and not necessarily
of the NSF.
S. Sankaranarayanan C. Miller, R. Raghunathan and H. Ravanbakhsh are
with the Department of Computer Science, University of Colorado, Boulder.
E-mail: last.firstname@colorado.edu.
G. Fainekos is with the School of Computing, Informatics and
Decision Systems Engineering at Arizona State University. E-mail:
fainekos@asu.edu.

978-1-4673-4539-2/12/$31.00 ©2012 IEEE

In this paper, we propose the use of mathematical models
of the insulin glucose regulatory system to find ideal values of the basal rate, the insulin-carbs and the correction
factor. Mathematical models of the insulin glucose regulatory system are quite sophisticated and can capture many
key physiological processes that govern the insulin glucose
regulation [1], [2], [3]. Furthermore, these models include a
large number of parameters that can potentially be adjusted
to fit the data available for an individual patient including
their carbohydrate intake, insulin infusion and blood glucose
readings over an extended period of time. The models have
the potential to account for short-term and medium-term
changes in insulin sensitivity and changes to the physical
fitness levels that can require changes in the pump usage
parameters.
Assuming the availability of a mathematical model with
parameters fitted to a particular patient, we consider the problem of finding optimal parameters for insulin infusion pump
usage. The criterion for finding the parameters include the
absence of hypoglycemia (the glucose concentration remains
above a minimum value), the absence of hyperglycemia
(the blood glucose concentration remains below a maximum
value) and the settling of the glucose concentration within
a narrow range roughly 3 hours post-meal. Our approach
involves the formulation of a penalty function that measures
the undesirability of the blood glucose concentrations over
time resulting from a scenario with fixed values of the
pump usage parameters, the amount of meal carbohydrates
and the starting value of the blood glucose concentration.
Starting with a natural penalty function that measures the
“robustness” of the glucose concentrations w.r.t. correctness
properties specified in Metric Temporal Logic (MTL) [4], we
modify the robustness metric to provide proper weightage to
hypoglycemia, which is much more undesirable than hyperglycemia. Furthermore, we penalize hypo-/hyper-glycemia
that persist for a long amount of time as opposed to transient
violations.
Finally, we define optimization problems to discover pump
usage parameters that minimize the penalty objective. However, the resulting objective function cannot be expressed
in a convenient closed form. In this paper, we use various
heuristic global optimization techniques such as simulated
annealing, cross-entropy and genetic algorithms [5].
We present an implementation of the setup based on
the model of insulin-glucose regulation proposed by Dalla
Man et al. [3]. This model is part of the commercially
available UVa-Padova simulator that was originally designed

1610

for testing control algorithms for the artificial pancreas
concept [1]. Our simulation environment includes models of
commonly recommended pump usage strategies governed by
the parameters to be optimized. The simulation environment
allows us to compute the objective function for the optimization of the pump usage parameters. This optimization
is performed under various configurations for a virtual set
of in-silico patients available as part of the simulator. We
conclude that our approach is viable for synthesizing pump
usage parameters automatically in a relatively short amount
of time. Our approach can be incorporated into tools that
can analyze a patient’s pump usage logs and automatically
recommend pump usage parameters for patient.
A. Related Work
Our ongoing project on robustness-guided model checking
studies the use of optimization algorithms for finding input
signals and parameter values to falsify correctness properties
of system designs [6], [7]. The tool S-Taliro provides an
implementation of these ideas to analyze MTL properties
of Simulink/Stateflow (tm) diagrams [8]. S-Taliro was used
previously to study insulin infusion pump usage models.
Therein, we examined the effect of various types of system
failures and user mistakes on the occurrence of hyper- and
hypoglycemia [9]. The key difference in this paper is the
focus on synthesizing parameters that minimize the overall
robustness. Furthermore, we modify the robustness metric
to obtain a penalty function that addresses some of the
characteristics of this problem.
Recently, Jha et al. presented the use of statistical model
checking to tune the parameters for a Proportional-IntegralDerivative (PID) controller that regulates insulin infusion
based on glucose sensor readings [10]. Their approach
searches for the proportional, integral and differential gain
parameters that satisfies a given set of temporal properties
with a given probability at a high level of confidence. The
search is guided by the number of simulations required
before the statistical model checker rejects the correctness
criterion. A higher number indicates likely property satisfaction. In contrast, our approach uses a robustness metric
in lieu of Boolean property satisfaction to search for pump
usage parameters that are optimal with respect to the chosen
robustness metric. The approach of Jha et al. is applicable to
the problem proposed here if additional information in the
form of probability distributions over the initial physiological
state and meal intake profiles are available. A detailed
comparison of the two approaches will be carried out in the
future.
Our work is similar in spirit to the idea of program
sketching proposed originally by Solar-Lezema et al. [11].
In particular, the patient’s usage strategy shown in Figure 4
can be seen as a simple program with “holes” specified by
the parameters basal, icRatio and Cor. A recent extension
to sketching uses program smoothing, wherein a discrete
program is modeled as a continuous function by adding noise
to the program variables and computing the expected output [12]. In contrast to the work on sketching, the technique

proposed here does not provide any guarantees of correctness
by construction. This is primarily due to the complexity
of the non-linear hybrid system model being treated here,
whereas work on correct-by-construction sketching is mostly
restricted to programs with linear guards and updates.
Model predictive control algorithms proposed for the artificial pancreas [13] use optimization techniques to control
infusions in real time. However, the presence of delays in
sensing glucose values and the action of insulin hinders the
ability to control blood glucose levels in the presence of
unannounced meal disturbances. The problem of retrofitting
artificial pancreas with meal disturbance prediction and
estimation has been studied recently by Lee et al. [14].
They report substantial improvements in the ability of their
retrofitted technique to handle meal disturbances.
A number of other works study the parameter synthesis
problem for biological systems [15], [16], [17]. In general,
the problem is posed as follows. Given a hybrid or nonlinear
dynamical system and a temporal logic specification, find the
parameter ranges for which the resulting system trajectories
satisfy the specification. In particular, in [16], the authors
use sensitivity analysis in order to quantify neighborhoods of
trajectories with the same qualitative behavior under uncertain system parameters and initial conditions. The authors in
[17] study the parameter synthesis problem for discrete-time
piecewise affine systems with parametric uncertainties. Rizk
et al. [15] provide an alternative definition of robustness for
temporal logic specifications. In addition, they use evolutionary optimization methods in order to find biochemical kinetic
parameter values satisfying properties in temporal logic.
II. BACKGROUND
In this section, we briefly describe models of insulinglucose regulatory system and insulin infusion pumps. Further details are available from numerous surveys and monographs on this topic [18], [19].
A. Diabetes
The healthy human body has a sophisticated closed-loop
control mechanism to maintain the level of glucose in the
blood within upper and lower limits (roughly 60 mg/dl to
100 mg/dl under the fasting state). This is achieved mainly
by the action of the pancreas, using the hormones insulin
and glucagon. Insulin regulates blood glucose levels in many
ways including the promotion of glucose uptake by the
liver and skeletal muscles, the inhibition of glucagon and
conversion of glucose by the fat cells.
Diabetes Mellitus is a condition wherein this control
system is disrupted either by damage to the β-cells in the
pancreas that secrete insulin (type-1 diabetes) or by reduced
sensitivity of the cells in the body to insulin (type-2 diabetes).
As a result, the blood glucose levels are chronically elevated,
damaging many organs including the kidneys, eyes and
nerves.
A common treatment for chronic type-1 diabetes involves
the external delivery of artificial insulin (or insulin analogs)
directly through a syringe, or sub-cutaneously through an

1611

insulin infusion pump. The everyday delivery of insulin is
controlled by the patient with advance knowledge of their
activities such as diet and exercise. Furthermore, diabetic
patients are required to monitor their blood glucose levels
intermittently. This can be done through “finger stick” blood
glucose monitors, or continuous glucose monitors (CGMs)
that provide frequent estimates of the blood glucose concentration by measuring the subcutneous glucose concentration.

Meal Carbs, Meal Time

Meal
Absorption
Model

Meal Carbs, Meal Time
basal, icRatio, Cor

Insulin-Glucose
Regulation
Model

User
Control
Strategy

Insulin
Infusion
Pump

Glucose
Monitor

B. Insulin Infusion Pumps
Insulin infusion pumps are commonly used by type-1
diabetic patients to infuse artificial insulin subcutaneously.
Commercially available pumps include numerous features,
including the ability to deliver insulin at a preset rates
through the day (basal insulin) and the ability to deliver
a programmable amount of insulin (bolus insulin) upon
request. The amount, timing and shape of the bolus can also
be adjusted by the user.
The use of insulin infusion pump poses numerous challenges to the patient. Too much insulin poses the risk of
hypoglycemia, wherein the patient’s blood glucose levels are
dangerously low. This condition seriously impairs the patient,
causing coma in extreme situations. On the other hand,
too little insulin poses the risk of hyperglycemia, wherein
the patient’s blood glucose levels are too high causing
dangerous conditions such as ketacidosis. Likewise, blood
glucose levels that are chronically elevated can also cause
damage to important organs such as the kidneys, eyes and
heart. Thus, the patient using the insulin pump has to choose
appropriate basal rates and bolus amounts at the appropriate
times to maintain their blood glucose level inside the ideal
range.
In practice, physicians and diabetic educators use a widely
accepted system based on three parameters that are calibrated
for each patient individually [20]. These include: (a) the basal
rate (basal), (b) an insulin-to-carbohydrates ratio (icRatio)
and (c) a correction factor (Cor). These parameters dictate the
user’s pump usage strategy for covering two major sources
of glucose: (1) endogenous glucose production by the liver
covered by the basal infusion and (2) meal glucose absorbed
by the digestive system covered by bolus infusions. Finally, a
bolus infusion is called for periodically to correct high blood
glucose levels, as measured by a glucose monitor.
Consequently, an infusion pump is typically used as follows:
1) The patient is expected to infuse a background insulin at
the basal rate basal. Basal rates can be varied depending
on the time of the day and physical activity level.
2) The patient frequently measures the blood glucose level
G and infuses a correction bolus using the correction
factor Cor as follows:
correction = Cor∗(G−Gdesired ) if G > Gdesired +∆ .
Here Gdesired is the normal glucose level (eg.,
80mg/dl) and ∆ represents a tolerance factor (eg.,
∆ = 20mg/dl).

Fig. 1. Key components in the meal insulin infusion pump usage scenario.

3) Roughly ∆T minutes prior to each meal, the patient
infuses a meal bolus to compensate for the amount
carbohydrates due to the meal (mealCarbs). The value
of ∆T depends on the meal composition. Typical values
for ∆T are in the range of 15 to 20 min.
mealBolus = icRatio ∗ mealCarbs .
Typically, the usage parameters (basal, icRatio, Cor) are
calibrated individually through trial and error, starting from
an initial guess given by the patient’s weight and daily
carbohydrate consumption. These parameters are periodically
readjusted to account for longer term changes in the patient’s
insulin sensitivity due to factors such as illness, medications
and physical fitness levels.
III. M ODELING
We will now discuss the process of modeling the various
parts of the insulin infusion scenario in order to optimize
the pump parameters for the user. Figure 1 shows the main
parts of the overall model for the insulin infusion pump
usage scenario. Commonly used models of insulin glucose
regulatory system use non-linear ODEs to predict the blood
glucose concentration. On the other hand, the model of
insulin infusion pump and the patient’s usage strategies
involve discrete actions. The overall composed model is a
non-linear hybrid system.
A. Modeling Insulin-Glucose Regulation
In this paper, we seek to synthesize pump usage parameters using models of the patient’s insulin glucose regulatory
system that are periodically updated based on data that
includes the patient’s insulin infusion log, food intake and
blood glucose data. We first briefly review the state-of-theart for modeling the physiological processes involved in the
regulation of glucose. Details on the models and the model
identification process are available elsewhere [18], [19], [3],
[2].
There are numerous modeling approaches for the insulin
glucose regulatory system [18]. These models attempt to
predict the key physiological state variables including the
blood glucose levels and the insulin levels in various tissues,
along with key physiological process including the action
of insulin on glucose consumption, endogenous glucose

1612



meal
Gut
Absorption

bolus(amt)! →

insulin
Subcutaneous
Absorption

start
Endogenous
Production
(Liver)

Glucose
System

t0 := t, I0 := I
J := amt,

Basal Mode
y(t) = basal
dI = y(t)
dt

Insulin
System



Bolus Mode
y(t) = basal + Fb (t − t0 ; J)
dI = y(t)
dt

I − I0 ≥ J

Fig. 3. Hybrid automaton modeling basal and bolus infusion delivery by
an infusion pump. Variable y refers to current infusion rate, I: amount of
infused so far, t: current time. The input event “bolus(amt)” is parameterized
by the amount of bolus requested amt. Function Fb models the shape of
the bolus as a function of time from start of bolus.

Glucose
Utilization

Fig. 2. Block diagram showing the major physiological processes involved
in the insulin-glucose regulatory system for a type-1 diabetic patient using
a subcutaneous infusion pump. Adapted from Dall Man et al. [21].

production, renal clearance of glucose, glucose secretion,
gut absorption of glucose from meal and the transfer of
subcutaneously infused insulin into the plasma. Figure 2
shows a block diagram that depicts these processes and the
interactions between them.
Modeling approaches can be broadly classified into minimal models that attempt to capture the basic trends without
modeling the underlying physiological processes that gives
rise to these trends and comprehensive models that predict
the blood glucose levels using models of the physiological
processes mentioned above. A popular example of a minimal
model is the Bergman minimal model [22]. Two recent examples of comprehensive models used in developing artificial
pancreas controllers include the Hovorka model [23], [2] and
the Dalla Man model [21].
We will use the Dalla Man model in our work following
descriptions available elsewhere [21], [3]. This model, along
with the patient parameters from the UVa-Padova simulator
will be used in this paper as the reference model for insulin
glucose regulation. The model is a non-linear ODE with ∼
13 continuous variables. The dynamics are hybrid due to the
discrete action of renal clearance which is activated whenever
the blood glucose level exceeds a threshold.
B. Modeling Insulin Infusion Pumps
Insulin infusion pumps are responsible for delivering insulin to the patient at a programmable rate. For the purposes
of this paper, we model two key aspects of the insulin
infusion pump: (a) the delivery of a continuous infusion at
a fixed basal rate (basal) and (b) the delivery of a fixed
bolus at the maximum rate, specified by the bolus amount.
Our model assumes a fixed delivery profile for the bolus
(“sine wave bolus”) with a small width. Figure 3 shows the
basic model of the pump. This model is a hybrid automaton
consisting of two modes for basal and bolus delivery.
C. User Control Strategy
Another important part of our overall model is an idealized
model of pump usage by the patient. We specifically focus
on the process of controlling glucose levels surrounding a
meal. Let us assume that the meal is started at time t = Tm

assert(t ∈ [Tm − 20, Tm − 15]);
mealBolus := mealCarbs ∗ icRatio;
G := glucoseSensor(t);
if ( G > Gdesired + 10 )
correctionBolus := (G − Gdesired ) ∗ Cor;
else
correctionBolus := 0;
deliverBolus(mealBolus + correctionBolus);

assert(t ∈ [Tm + 120, Tm + 150]);
G := glucoseSensor(t);
if ( G > Gdesired + 10 )
correctionBolus := (G − Gdesired ) ∗ Cor;
else
correctionBolus := 0;
deliverBolus(correctionBolus);

Fig. 4. An idealized user control strategy for insulin bolus centered around
a meal taken at time t = Tm minutes. (Top) Pre-meal and correction bolus
15 − 20 minutes prior to the meal and (Bottom) post-meal correction 120 −
150 minutes post-meal. Note that the strategy is dependent on the pump
usage parameters basal, icRatio and Cor in addition to the pre-meal glucose
levels and the estimated amount of carbohydrates in the meal.

minutes. Following the widely prescribed guidelines, we
assume that the user infuses a “pre-bolus” at time t =
Tm − [15, 20] minutes. This combines a bolus to cover the
planned meal, using the insulin-carbs ratio icRatio and a
correction factor in case the pre-meal glucose levels are
elevated. Similarly, we assume that the user checks their
post-meal blood glucose levels roughly [120, 150] minutes
post meal and uses a correction bolus if required. Figure 4
shows the calculation of bolus amounts as part of the user
control strategy.
D. Model Implementation
The models for the various components of the infusion
were implemented inside the Simulink/Stateflow (tm) programming environment. As mentioned earlier, we implement
the model proposed by Dalla Man et al. [21], [3]. An
implementation is commercially available as part of the
University of Virginia (UVa) -Padova simulator along with
representative parameter sets for 30 “in-silico” patients. We
reimplemented the publicly available Dalla Man model, as
described in papers by Dalla Man and co-workers [3], [21],

1613

G (mg/dl)

(c) The settling of the glucose concentrations to a narrow
range three hours after the meal:
(∀t), t ≥ Tm + 180min ⇒ G(t) ∈ [60, 90]mg/dl .

Hyperglycemia
170
90
Settle
60
50
Hypoglycemia

t = Tm − 30

t = Tm

t = Tm + 180

Time (min)

Fig. 5. Correctness requirements for ideal glycemic control at a glance.
The requirements include (a) No hypoglycemia, (b) No hyperglycemia, and
(c) Settle within a narrow range. Note that axes on the graph are not to
scale.

[24] with in silico parameters available from the commercial
simulator. This was performed in order to provide a more
convenient integration of the resulting model inside the
overall optimization scheme for finding pump parameters.
The final model requires a few parameters to be specified
by the user at the start of the simulation, including (a) the
amount of carbohydrates to be consumed during the meal
(mealCarbs), (b) the starting glucose value for the simulation
and (c) the pump usage parameters (basal, icRatio, Cor).
The simulation involves a single meal consumed at Tm =
30 with a fixed duration of 15 minutes. The simulation is
carried out for a total time period of T = 720 minutes (12
hours), assuming no meals in the intervening period. Other
than the first meal at t = Tm , we assume no other meals
during the simulation. However, the model can be easily
modified to support multiple meals over a longer time period.
IV. T RACE ROBUSTNESS
We discuss the desired properties of the insulin infusion
process and the derivation of a penalty function. These
properties can be expressed as formulae in Metric Temporal
Logic (MTL) [4] involving the blood glucose concentration
G(t) as a function of time. We then define a notion of
robustness of a trace that assigns a numerical score that penalizes situations such as hypoglycemia and hyperglycemia
(implicitly “rewarding” their absence). The design of the
penalty function requires careful consideration of the weights
given to hypoglycemia and hyperglycemia. Finally, we pose
the problem of calibrating the pump usage in terms of
an optimization of the trace robustness, or equivalently a
minimization of the trace penalty. We show different ways
of formulating this optimization to account for varying meal
sizes and initial physiological states.
Figure 5 depicts the three main correctness requirements
for meal insulin bolus selection. The correctness specifications refer to the observed values of blood glucose concentration over time G(t). These include
(a) No hypoglycemia: (∀t) G(t) ≥ 50mg/dl,
(b) No hyperglycemia: (∀t) G(t) ≤ 170mg/dl, and

A. Robustness
Given the correctness specifications provided in the previous section, it is an easy problem to check if a given
signal G(t) (specified by means of samples at discrete time
points) satisfies the specification. As a result, given a trace
of glucose levels G(t), we may obtain a true/false answer to
whether it satisfies the specifications or not. In this paper, we
seek further information about “nearby” traces G0 (t) that are
within some  distance from G. We first present the notion of
robustness, that augments the true/false answer obtained from
the formula satisfaction with a value  ∈ R that specifies the
robustness of G(t) w.r.t the specification.
Definition 4.1 (Robustness Metric): Given a trace G(t)
and a property ϕ involving G, the robustness metric robϕ (G)
satisfies the following main properties:
1) If G(t) satisfies the property ϕ, then robϕ (G(t)) > 0.
2) If G(t) violates ϕ, then robϕ (G(t)) < 0.
3) Let robϕ (G) = . Consider any trace G0 (t) that is
contained in an  cylinder around G(t), i.e, for all t,
|G0 (t) − G(t)| ≤ ||. It follows that G0 has the same
outcome for the property ϕ as G. In other words, both
G, G0 satisfy the property or both violate the property
ϕ.
The general theory of robustness metrics for continuous
signals and MTL properties has been described by Fainekos
et al. [25], [26]. Their work provides a systematic definition of the robustness metric given a trace and a property
described in MTL. Since the conditions for hyperglycemia,
hypoglycemia and failure to settle can be described in MTL,
the work of Fainekos et al. is directly applicable to obtain
a robustness metric. Based, on their work, we obtain the
following functions for the robustness of a signal G(t) w.r.t
each of the three properties for the ideal control of post-meal
blood glucose levels:
1) The robustness Rhyper for hyperglycemia is given by
Rhyper (G) = max(170 − G(t)) .
t

2) The robustness Rhypo for hypoglycemia is given by
Rhypo (G) = max(G(t) − 50) .
t

3) The robustness Rsettle for failure to settle is given by
Rsettle (G) =

max

(min(90 − G(t), G(t) − 60)) .

t≥Tm +180

The reader can verify that the robustness metrics for each
of the three properties satisfy the requirements for being a
robustnes metric.
Robustness metrics directly lead to a penalty function
defined as
F (G) = − min(Rhyper (G), Rhypo (G), Rsettle (G)) .
A large positive value of this penalty function implies
a low, negative value of robustness. In turn, this implies a

1614

“blatant” violation wherein nearby traces are also violations.
Likewise, a low negative penalty implies a large positive
robustness and thus a robust satisfying trace with nearby
traces also satisfying the properties.

icRatio
Cor

B. Modified Robustness Metrics

Simulate
Model

G(t)

Evaluate
Robustness

obj. val.

basal

While robustness metrics provide a natural means for
associating a numerical measure of satisfaction with a trace,
they are not entirely suitable for the purposes of providing a
penalty score for the trace G(t) resulting from a fixed set of
parameters basal, icRatio and Cor. This is due to two reasons:
1) The metric penalizes a violation based on the maximum/minimum value of G(t) over a time interval. In
practice, a hypoglycemia that persists for a significant
period of time may be more harmful than a transient
hypoglycemia for a short time period.
2) Secondly, hypoglycemia is generally deemed much
more harmful than hyperglycemia. For instance G(t) =
40mg/dl is a significant problem whereas G(t) =
180mg/dl is only a problem if it persists for a long
time. As a result, the metric needs to provide appropriate
weights for hyperglycemia vs. hypoglycemia.
Weighting Hyperglycemia vs. Hypoglycemia One approach to appropriately penalizing hypoglycemia is to provide an exponential penalty for hypoglycemia. As a result,
the penalty function for hypoglycemia may be defined as
Fhypo (G) = max(eλ(50−G(t)) − 1) , for some fixed λ > 0.
t

The penalty functions for hyperglycemia and failure to settle
are given by the robustness metric. The overall penalty is
obtained by adding the various penalty functions from the
three properties together.
In this model, assuming λ = 0.3, a hypoglycemic trace
with Gmin = 40mg/dl yields a penalty e3 − 1 ∼ 20. This
is equivalent to the penalty induced by a hyperglycemic
trace with Gmax = 190mg/dl. However, the exponential
nature of the scale ensures that a significant hypoglycemia
Gmin = 30mg/dl yields the same penalty as a significant
hyperglycemia with Gmax = 630mg/dl.
Integrating Violations As an alternative to the use of
extremal glucose values (obtained by the use of max and
min in the robustness function), we propose integrating the
penalty in order to differentiate between a property violation
that is corrected soon as opposed to a violation that persists.
As a result, we define the penalty function for hypoglycemia
as
R
Fhypo (G) = Thypo (e0.3(50−G(t)) − 1)dt
where Thypo = {t | G(t) ≤ 50} .
If G(t) is assumed to be a continuous function of time, then
the integral above is well-defined. Note that the function
Fhypo (G) > 0 if a trace G(t) violates the hypoglycemia
property, while Fhypo (G) = 0 if G(t) satisfies the property.
Likewise, we may define Fhyper (G) and Fsettle (G) by
integrating the penalties over all time intervals that pertain

Fig. 6. The objective function F for the optimization problem takes in
three parameters, performs a simulation and reports the penalty function
value on the resulting simulation trace.

to property violations.
R
Fhyper (G) = Thyper (G(t) − 170)dt,
where ThyperR= {t | G(t) ≥ 170} R
Fsettle (G) = Tup (G(t) − 90)dt + Tdown (60 − G(t))dt,
where Tup = {t | t ≥ 180 + Tm ∧ G(t) ≥ 90}
and Tdown = {t | t ≥ 180 + Tm ∧ G(t) ≤ 60} .
V. O PTIMIZATION
We will now present the setup for the optimization problem for setting up the various pump usage parameters. We
first present a joint optimization setup wherein all parameters
are jointly optimized for a fixed meal scenario.
Figure 6 shows the setup for the optimization problem.
The penalty function F has parameters (basal, icRatio, Cor).
The optimization seeks to minimize the penalty function
over a permissible range of values for the usage parameters
(basal, icRatio, Cor).
Formally, let P be the set of search parameters. Namely,
given a point (basal, icRatio, Cor) ∈ P and a function Σ that returns the system trace G(t) for parameters
(basal, icRatio, Cor), then the optimization problem that we
try to solve is
min F(~
p) = min F (Σ(~
p))
p
~∈P

p
~∈P

Non-linear Objective Function: We note that the overall
model of the insulin infusion process is a hybrid system with
discrete mode switches induced by the insulin pump and
the usage models. Furthermore, each mode has non-linear
dynamics due to the physiological model. As a result, the
function F cannot be written down in a closed form suitable
for optimization. We can evaluate F numerically to some
given degree of precision using a simulation environment
such as Simulink/Stateflow (tm).
As a result, the optimization cannot be solved exactly.
However, we may use heuristic techniques to obtain pump
usage parameters that yield an acceptable value of the penalty
function, possibly satisfying the desired properties for ideal
control of glucose levels. Examples of heuristic techniques
include stochastic optimization techniques such as simulated
annealing and the cross-entropy method [5], heuristic global
optimization techniques such as genetic algorithms, and
gradient descent techniques that estimate an approximate
gradient by evaluating the objective function.

1615

Implementation
The optimization routines provided
in the global optimization toolbox (fmincon,
simulannealbnd and ga) were used to carry out
the optimization. The ranges of the pump usage parameters
were restricted to basal ∈ [0.1, 5], icRatio ∈ [0.05, .5] and
Cor ∈ [0.05, 2] for our experiments.
VI. E XPERIMENTAL R ESULTS
We will now present an experimental evaluation of our
approach to optimizing pump usage. We report on the results
of our optimization procedure and the performance over a
virtual set of 10 adult patients, namely d1 to d10, available
as part of the UVa-Padova simulator [1] 1 .
We consider the optimization for a meal scenario
with the starting values of the blood glucose level
Gstart = 140mg/dl and the amount of meal carbohydrates
mealCarbs = 120gms. Table I shows the tuned parameters
for the single meal scenario. We compare two scenarios:
(a) all three parameters basal, icRatio, Cor are jointly optimized for the scenario and (b) The parameters icRatio, Cor
jointly optimized with a fixed value of the basal rate that is
calibrated separately. The calibration of the basal rate was
performed by running an optimization over basal assuming
no meal input to search for a basal rate that held the blood
glucose level stable within the range [75, 85]mg/dl.
With the exception of three patients (d3, d6 and d7),
the joint optimization produces markedly lower penalty values than the separate optimization of the basal parameter.
We note that joint optimization produces acceptable maximal/minimal values of the blood glucose levels in almost all
cases, with a possible severe hypoglycemia in one case and
potential hyperglycemia for patient d9. The performance of
separate basal optimization is slightly worse producing both
severe hyperglycemia and hypoglycemia for patient d9, and
hyperglycemia for patients d1, d10.
The running times for the optimization are mostly within
15 minutes. While these running times are not suitable for
practical implementation, we can reduce them considerably
given more efficient simulation algorithms (eg., compiling
the simulator down to native code), parallel simulations and
a better choice of optimization algorithm.
VII. T HREATS T O VALIDITY
In this section, we discuss some of the threats to validity
and address remedial steps taken to ensure that the results in
this work are applicable to real-life situations.
With any result involving in silico simulations, there is
a risk that we are observing modeling quirks that are not
reflective of what happens in reality. However, the models
used here have been extensively evaluated against studies on
real patients [21], providing evidence for their validity.
This work considers the joint optimization of pump parameters under a single meal scenario that consists of a
single meal with fixed amount of carbohydrates taken at
some time t = Tm and no futher meal disturbances for

the next 12 hours. While this scenario is feasible, a realistic
scenario involves three meals at times that correspond to
breakfast, lunch and dinner times. Discrepancies between
announced meal carbohydrates and actual meal consumed
are very common. Another limitation of the scenario is the
assumption that the meal times are fixed. The choice of the
pump parameters should consider some variability in the
meal times. However, the framework presented here can be
extended naturally to cover a more complex meal scenario.
The model is currently simulated starting from a fixed
initial physiological state (blood glucose concentration, blood
insulin concentration, insulin infusion history, meal history
etc.). This is an unrealistic assumption in practice. Our
optimization needs to consider the choice of parameters that
perform well under varying physiological states prior to the
meal.
Finally, our work does not consider the problem of fitting
parameters to the patient’s glucose monitor and insulin
infusion logs, which is essential to build personalized models
for the patients. In practice, model parameters are fitted using
an expensive tracer study under physiological controlled conditions that cannot be carried out frequently on a patient [21].
We are currently investigating the use of parameter fitting
techniques that start from an assumed prior set of parameter
values measured for a patient with similar body weight and
daily insulin requirements.
VIII. C ONCLUSIONS
We have provided a technique to optimize insulin infusion
pump usage parameters based on repeated simulations to
minimize a penalty function. Our preliminary evaluation
demonstrates the advantage of a joint optimization of the
three pump usage parameters against a meal scenario, as
opposed to the more commonly used separate optimization
of the basal infusion rate. Our ultimate goal is to provide
a model-based analysis tool that can fit models to patient
data and use the resulting models to identify optimal pump
usage parameters against meal scenarios. As noted in our
discussion on threats to validity (Section VII), a lot needs
to be done before such a tool can be made available to
patients. Our future research will focus on piecewise affine
abstractions of the non-linear model, which will enable us
to simplify the dynamics of the model. The optimization
of pump usage parameters against uncertain initial physiological states and multiple meal scenarios will also be
investigated.

1 The results on the entire available virtual set of 10 adults, 10 adoloscents
and 10 children are available upon request

1616

R EFERENCES
[1] B. P. Kovatchev, M. Breton, C. Dalla-Man, and C. Cobelli, “In Silico
preclinical trials: A proof of concept in closed-loop control of type 1
diabetes,” J. Diabetes Science and Technology, vol. 3, no. 1, January
2009.
[2] M. Wilinska, L. Chassin, C. L. Acerini, J. M. Allen, D. Dunber,
and R. Hovorka, “Simulation environment to evaluate closed-loop
insulin delivery systems in type 1 diabetes,” J. Diabetes Science and
Technology, vol. 4, January 2010.
[3] C. Dalla-Man, D. M. Raimondo, R. A. Rizza, and C. Cobelli, “GIM,
simulation software of meal glucose-insulin model,” J. Diabetes Sci.
and Tech., vol. 1, no. 3, May 2007.

ID

PARAMS
BS

IC

T

P EN

minG

maxG

After Tm + 180 min
minG maxG avgG

6886
744
573
0
115
15127
560
554
47338
3121

49
54
48
60
54
49
49
53
43
48

201
140
140
168
158
153
140
154
184
193

49
54
49
61
54
49
49
53
43
48

141
117
110
90
98
136
77
101
182
123

81
75
86
80
80
96
68
81
107
81

12021
1852
322
5
310
1152
87
886
244300
4878

49
50
49
59
51
50
54
50
39
49

210
140
140
174
161
169
140
161
311
202

49
50
50
59
51
50
54
50
39
49

160
127
108
89
102
129
82
112
295
134

72
66
76
75
73
72
72
72
94
74

COR

Joint Optimization of Parameters
d1
1.42
0.13
0.08
747
d2
1.57
0.16
0.2
746
d3
1.97
0.11
0.12
727
d4
1.22
0.07
0.07
946
d5
2.15
0.12
0.27
723
d6
1.8
0.15
0.08
741
d7
1.75
0.06
0.06
770
d8
1.46
0.06
0.08
1101
d9
0.8
0.08
0.4
721
d10 1.9
0.06
0.4
720
Basal Separately Calibrated
d1
1.93
0.09
0.06
731
d2
2.13
0.16
0.08
838
d3
2.15
0.13
0.06
664
d4
1.30
0.05
0.10
698
d5
2.44
0.10
0.26
712
d6
2.19
0.12
0.06
775
d7
1.73
0.05
0.05
1072
d8
1.72
0.06
0.05
693
d9
1.91
0.07
0.06
696
d10 2.28
0.13
0.19
702

TABLE I
O PTIMIZED PUMP PARAMETERS AND THE PERFORMANCE . T HE TABLE REPORTS THE PERFORMANCE WHEN ( A ) THE BASAL RATE IS OPTIMIZED
JOINTLY WITH THE OTHER TWO PARAMETERS AND ( B ) BASAL IS CALIBRATED SEPARATELY.

L EGEND : BS : BASAL RATE (U/ HR ), IC : I NSULIN -C ARBS
(U/ GM ), COR : S ENSITIVITY FACTOR (U/( MG / DL )), T: TIME TAKEN FOR OPTIMIZATION ( SEC ), P EN : P ENALTY VALUE ( NEGATION OF FITNESS ),
MIN G: MINIMAL VALUE OF BLOOD GLUCOSE ( MG / DL ), MAX G: MAXIMAL VALUE OF GLUCOSE ( MG / DL ) AND AVG G: AVERAGE VALUE OF BLOOD
GLUCOSE ( MG / DL ).

RATIO

[4] R. Koymans, “Specifying real-time properties with metric temporal
logic.” Real-Time Systems, vol. 2, no. 4, pp. 255–299, 1990.
[5] R. Y. Rubinstein and D. P. Kroese, Simulation and the Monte Carlo
Method. Wiley Series in Probability and Mathematical Statistics,
2008.
[6] T. Nghiem, S. Sankaranarayanan, G. E. Fainekos, F. Ivančić, A. Gupta,
and G. J. Pappas, “Monte-carlo techniques for falsification of temporal
properties of non-linear hybrid systems,” in Hybrid Systems: Computation and Control. ACM Press, 2010, pp. 211–220.
[7] S. Sankaranarayanan and G. E. Fainekos, “Falsification of temporal
properties of hybrid systems using the cross-entropy method,” in
HSCC. ACM, 2012, pp. 125–134.
[8] Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan, “S-taliro: A tool for temporal logic falsification for hybrid
systems,” in Tools and algorithms for the construction and analysis
of systems, ser. LNCS, vol. 6605. Springer, 2011, pp. 254–257.
[9] S. Sankaranarayanan and G. Fainekos, “Simulating insulin infusion
pump risks by In-Silico modeling of the insulin-glucose regulatory
system,” in Computational Methods in Systems Biology (CMSB), ser.
Lecture Notes in Computer Science, vol. 7605, 2012, pp. 322–339.
[10] S. K. Jha, R. Datta, C. Langmead, S. Jha, and E. Sassano, “Synthesis
of insulin pump controllers from safety specifications using bayesian
model validation,” in Proceedings of 10th Asia Pacific Bioinformatics
Conference, (APBC), 2012.
[11] A. Solar-Lezama, R. M. Rabbah, R. Bodı́k, and K. Ebcioglu, “Programming by sketching for bit-streaming programs,” in PLDI. ACM,
2005, pp. 281–294.
[12] S. Chaudhuri and A. Solar-Lezama, “Smoothing a program soundly
and robustly,” in CAV, ser. Lecture Notes in Computer Science, vol.
6806. Springer, 2011, pp. 277–292.
[13] R. Hovorka, V. Canonico, L. Chassin, U. Haueter, M. Massi-Benedetti,
M. Frederici, T. Pieber, H. Shaller, L. Schaupp, T. Vering, and M. Wilinska, “Nonlinear model predictive control of glucose concentration in
subjects with type 1 diabetes,” Physiological Measurement, vol. 25,
pp. 905–920, 2004.
[14] H. Lee, B. Buckingham, D. Wilson, and W. Bequette, “A closed-loop
artificial pancreas using model predictive control and sliding meal size
estimator,” J. Diabetes Science and Technology, vol. 3, no. 5, Sept
2009.

[15] A. Rizk, G. Batt, F. Fages, and S. Soliman, “Continuous valuations of
temporal logic specifications with applications to parameter optimization and robustness measures,” Theor. Comput. Sci., vol. 412, no. 26,
pp. 2827–2839, 2011.
[16] A. Donze, E. Fanchon, L. M. Gattepaille, O. Maler, and P. Tracqui,
“Robustness analysis and behavior discrimination in enzymatic reaction networks,” PLoS ONE, vol. 6, no. 9, p. e24246, 09 2011.
[17] B. Yordanov and C. Belta, “Parameter synthesis for piecewise affine
systems from temporal logic specifications,” in Proceedings of the 11th
international workshop on Hybrid Systems: Computation and Control,
ser. LNCS, vol. 4981. Springer, 2008, pp. 542–555.
[18] F. Chee and T. Fernando, Closed-Loop Control of Blood Glucose.
Springer, 2007.
[19] C. Cobelli, C. Dalla-Man, G. Sparacino, L. Magni, G. D. Nicolao,
and B. P. Kovatchev, “Diabetes: Models, signals and control (methodological review),” IEEE reviews in biomedical engineering, vol. 2, pp.
54–95, 2009.
[20] G. Scheiner, Think like a pancreas: A Practical guide to managing
diabetes with insulin. Da Capo Press, 2011.
[21] C. Dalla-Man, R. A. Rizza, and C. Cobelli, “Meal simulation model
of the glucose-insulin system.” IEEE Transactions on Biomedical
Engineering, vol. 1, no. 10, pp. 1740–1749, 2006.
[22] R. N. Bergman, “Minimal model: Perspective from 2005,” Hormone
Research, pp. 8–15, 2005.
[23] R. Hovorka, F. Shojaee-Moradie, P. Carroll, L. Chassin, I. Gowrie,
N. Jackson, R. Tudor, A. Umpleby, and R. Hones, “Partitioning
glucose distribution/transport, disposal and endogenous production
during IVGTT,” Am. J. Physiol. Endocrinol. Metab., vol. 282, pp.
992–1007, 2002.
[24] C. Dalla-Man, M. Camilleri, and C. Cobelli, “A system model of
oral glucose absorption: Validation on gold standard data,” Biomedical
Engineering, IEEE Transactions on, vol. 53, no. 12, pp. 2472 –2478,
dec. 2006.
[25] G. Fainekos and G. J. Pappas, “Robustness of temporal logic specifications for continuous-time signals,” Theoretical Computer Science,
vol. 410, pp. 4262–4291, 2009.
[26] G. E. Fainekos, “Robustness of temporal logic specifications,” Ph.D.
dissertation, Department of Computer and Information Science, University of Pennsylvania, 2008.

1617

An Eﬃcient Algorithm for Monitoring Practical
TPTL Speciﬁcations
Adel Dokhanchi, Bardh Hoxha, Cumhur Erkan Tuncali, and Georgios Fainekos
Arizona State University, Tempe, AZ, U.S.A.
Email: {adokhanc,bhoxha,etuncali,fainekos}@asu.edu
Abstract—We provide a dynamic programming algorithm for
the monitoring of a fragment of Timed Propositional Temporal
Logic (TPTL) speciﬁcations. This fragment of TPTL, which is
more expressive than Metric Temporal Logic, is characterized
by independent time variables which enable the elicitation of
complex real-time requirements. For this fragment, we provide
an eﬃcient polynomial time algorithm for oﬀ-line monitoring
of ﬁnite traces. Finally, we provide experimental results on a
prototype implementation of our tool in order to demonstrate
the feasibility of using our tool in practical applications.

I.

Introduction

In Cyber-Physical Systems (CPS), many safety critical
components of the system are controlled by embedded computers which interact with the physical environment. Due to
the safety-critical nature of these applications, it is important
to verify their correctness during system development stages.
However, the veriﬁcation problem for CPS with respect to
safety requirements is undecidable, in general [1]. An alternative to formal veriﬁcation is semi-formal model-based testing
and monitoring of CPS. We utilize formal logic, in order to
formally specify real-time requirements.
Metric Temporal Logic (MTL) was introduced to provide
the formalization of real-time speciﬁcations [16]. Since its
introduction, MTL and its variants have been used in the
veriﬁcation of real-time systems [20]. Several tools, such as
S-TaLiRo [3] and Breach [7], have been developed by the
academic community for the purpose of semi-formal veriﬁcation of MTL speciﬁcations. These tools use oﬀ-line and
on-line monitoring algorithms to check whether the execution
trace of a CPS satisﬁes/falsiﬁes an MTL formula. In oﬀline monitoring, the execution trace is ﬁnite and generated by
running the system for a bounded amount of time. Then, the
oﬀ-line monitor checks whether the execution trace satisﬁes
the speciﬁcation. On the other hand, an on-line monitor runs
simultaneously with the system. In this paper, we consider oﬀline monitoring of TPTL speciﬁcations.
The time complexity of oﬀ-line monitoring for MTL is
linear to the size of a ﬁnite system trace and linear to the size of
MTL formula. Several algorithms using dynamic programming
[10] or sliding windows [8] have been proposed for MTL
monitoring of CPS. In this paper, we consider TPTL speciﬁcations which are more expressive than MTL speciﬁcations
[4]. TPTL is an extension of Linear Temporal Logic (LTL)
with freeze quantiﬁers represented as “x.”. A freeze quantiﬁer
x. assigns to time variable x the “current” time stamp when
the corresponding subformula x.ϕ(x) is evaluated [2]. Then, the
time value (stored in x) can be evaluated inside time constraints
which are linear inequalities over the time variables.

978-1-5090-2791-0/16/$31.00 ©2016 IEEE

184

Since its introduction, two semantics where considered for
TPTL [2], [4]. Alur’s semantics [2] allows two time variables
in time constraints (for example x + 1 ≤ y + 4). In contrast,
Raskin’s semantics allows only one time variable in the time
constraint (x ≤ 4) and implicitly considers the current time as
the second time variable [4], [21]. Since the latter semantics
was ﬁrst considered by Jean-Franois Raskin in [21], we will
refer to it as “Raskin’s TPTL semantics” in this paper. Raskin’s
TPTL semantics was mentioned with alternative terms such
as “Timed LTL” in [17]. In another line of work, in [6], the
authors augmented Alur’s time constraints with more complex
temporal-special predicates to deﬁne the closeness property of
two diﬀerent CPS trajectories. However, the authors in [6] did
not provide a TPTL monitoring algorithm.
Since TPTL subsumes MTL, it is expected that the monitoring problem of TPTL is computationally more complex
[11]. It has been proven that monitoring of a ﬁnite trace with
respect to Alur’s TPTL speciﬁcation is PSPACE-hard [18].
In [18], the authors transform a Quantiﬁed Boolean Formula
(QBF), which is PSPACE-hard, into a TPTL formula with real
value time variables. A similar complexity result (PSPACEhard) for Raskin’s TPTL semantics is obtained for integer
time variables in [11]. It is mentioned in [11] that in order
to obtain a polynomial time algorithm for TPTL monitoring
(path checking), we need to ﬁx the number of time variables.
In other words, if the number of time variables is bounded
then the ﬁnite trace monitoring will be polynomial to the size
of the TPTL formula. However, in [11], the authors did not
provide any applicable algorithm for TPTL monitoring and
they focused only on the complexity class.
In this work, we move one step further from [11], and allow
the number of time variables to be arbitrary, but they must
be independent to each other1 . For this fragment of TPTL,
we provide an eﬃcient TPTL monitoring algorithm which has
time complexity quadratic in the length of the ﬁnite trace. In
addition, the runtime of the algorithm is proportional to the
number of time variables in TPTL.
In terms of related work, a rewriting based algorithm for
TPTL has been provided in [5]. In [5], the authors did not
evaluate the time complexity of their proposed algorithm.
The rewriting technique was used for on-line monitoring of
TPTL speciﬁcations in [13]. The authors used the relativization
of TPTL formula with respect to the sequence of observed
states [13], and it was reported that the time complexity is
exponential to the size of TPTL formula [13]. To the best of
our knowledge, our paper is the ﬁrst work where an eﬃcient
1 In

Section II-B, Deﬁnition 5, we introduce independent time variables.

and practical TPTL oﬀ-line monitoring algorithm is provided.
II.

Preliminaries

We assume a sampled representation of system behavior
with a discrete trace as the input to the monitoring algorithm.
We utilize the notion of Timed State Sequences (TSS) [2] to
represent the sampled behavior of a system using a digital
clock. We interpret TPTL formulas over TSS. Assume AP =
{a, b, · · · } is a set of atomic propositions, R+ is the set of nonnegative real numbers, and N denotes non-negative integers.
Deﬁnition 1 (State and Time Sequences [2]): A state sequence σ = σ0 σ1 σ2 · · · is an inﬁnite sequence of states σi ⊆
AP, where i ∈ N. A (sampled) time sequence τ = τ0 τ1 τ2 . . .
is an inﬁnite sequence of time stamps τi ∈ R+ , where i ∈ N.
We assume that the time sequence τ is:
1)
2)
3)

Initialized, which means that the start up time is zero
(τ0 = 0).
Monotonic, which means that τi ≤ τi+1 for all i ∈ N.
Progressive, which means that for all t ∈ R+ there is
some i ∈ N such that τi > t.

Deﬁnition 2 (Timed State Sequence (TSS) [2]): A
timed state sequence ρ = (σ, τ) is a pair consisting
of a state sequence σ and a time sequence τ where
ρ0 ρ1 ρ2 · · · = (σ0 , τ0 )(σ1 , τ1 )(σ2 , τ2 ) · · · .
Given an inﬁnite TSS ρ, we consider a ﬁnite preﬁx of ρ as a
ﬁnite TSS. The symbol ρ̂ = (σ̂, τ̂) is used to denote a ﬁnite
TSS with the size of |ρ̂| = |σ̂| = |τ̂|. In this paper, we consider
the monitoring of ﬁnite TSS with the size of |ρ̂| which is equal
to the number of simulation/execution samples.
A. TPTL Syntax and Semantics
To prevent any confusion in the presentation, we consider
Raskin’s TPTL semantics [21], [4]2 . TPTL is an extension of
LTL that enables the formalization of real-time properties by
including time variables and a freeze time quantiﬁer [2].

Deﬁnition 4 (Discrete-Time Semantics for T PT L): Let
ρ̂ = (σ̂, τ̂) be a ﬁnite TSS and i ∈ N where i < |ρ̂| is the index
of the current sample, a ∈ AP, ϕ ∈ T PT L, and an environment
ε : V → R+ . The satisfaction relation (ρ̂, i, ε) |= ϕ is deﬁned
recursively as follows:
(ρ̂, i, ε) |= 
(ρ̂, i, ε) |= a iﬀ a ∈ σi
(ρ̂, i, ε) |= ¬ϕ iﬀ (ρ̂, i, ε) |= ϕ
(ρ̂, i, ε) |= ϕ1 ∧ ϕ2 iﬀ (ρ̂, i, ε) |= ϕ1 and (ρ̂, i, ε) |= ϕ2
(ρ̂, i, ε) |= ϕ1 ∨ ϕ2 iﬀ (ρ̂, i, ε) |= ϕ1 or (ρ̂, i, ε) |= ϕ2
(ρ̂, i, ε) |= 	ϕ iﬀ (ρ̂, i + 1, ε) |= ϕ and i < (|ρ̂| − 1)
(ρ̂, i, ε) |= ϕ1 Uϕ2 iﬀ ∃ j, i ≤ j < |ρ̂| s.t. (ρ̂, j, ε) |= ϕ2
and ∀k, i ≤ k < j it holds that (ρ̂, k, ε) |= ϕ1
(ρ̂, i, ε) |= x ∼ r iﬀ (τi − ε(x)) ∼ r i.e.
(current time stamp) − ε(x) ∼ r
(ρ̂, i, ε) |= x.ϕ iﬀ (ρ̂, i, ε[x := τi ]) |= ϕ
The semantics of TPTL are deﬁned over an evaluation
function ε : V → R+ which is an environment for the time
variables. Assume x = r where x ∈ V, and r ∈ R+ , then we have
ε(x) = r. Given a variable x ∈ V and a real number q ∈ R+ , we
denote the environment with ε = ε[x := q] which is equivalent
to the environment ε on all time variables in V except variable
x. The assignment operation x := q changes the environment ε
to the new environment ε . Formally, ε (y) = ε(y) for all y  x
and ε (x) = q. We write 0 for the (zero) environment such that
0(x) = 0 for all x ∈ V. We say that ρ̂ satisﬁes ϕ (ρ̂ |= ϕ) iﬀ
(ρ̂, 0,0) |= ϕ. A variable “x” that is bounded by a corresponding
freeze quantiﬁer “x.” saves the local temporal context τi (now)
in “x”. Assume ϕ(x) is a formula with a free variable x. The
TSS ρ̂ satisﬁes x.ϕ(x) if it satisﬁes ϕ(τ0 = 0), where ϕ(0) is
obtained from ϕ(x) by replacing all the free occurrences of the
variable x with constant 0 [2].
B. TPTL Fragments
In this section, we introduce a TPTL fragment for which
we have developed a monitoring algorithm. This restriction is
crucial for obtaining the polynomial runtime of the algorithm.

Deﬁnition 3 (Syntax for T PT L): The set of TPTL formulas ϕ over a ﬁnite set of atomic propositions (AP) and a ﬁnite
set of time variables (V) is inductively deﬁned according to
the following grammar:

Deﬁnition 5 (Independent Time Variable): A time variable
x is independent if it is in the scope of only one freeze
quantiﬁer x. and no other time variable is in the scope of the
corresponding freeze quantiﬁer (x.).

ϕ ::=  | a | x ∼ r | ¬ϕ | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 | 	 ϕ | ϕ1 Uϕ2 | x.ϕ

For example in x.(ψ(x) ∨ y.ϕ(x, y)), neither x nor y is
independent. This is because x is within the scope of the freeze
time quantiﬁers x. in x.(ψ(x) ∨ y.ϕ(x, y)) and y. in y.ϕ(x, y).
Similarly, y is not the only time variable that is within the scope
of y. in y.ϕ(x, y). However, both x and y are independent in
x.(ψ(x) ∨ y.ϕ(y)).

where x ∈ V, r ∈ R+ , a ∈ AP, and ∼ ∈ {≤, <, =, >, ≥}, and 
is the symbol for “True”.
The time constraints of TPTL are represented in the form of
x ∼ r. The freeze quantiﬁer x. assigns the current time of
the formula’s evaluation (at each sampled time τi ) to the time
variable x. A TPTL formula is closed if every occurrence of
a time variable is within the scope of a freeze quantiﬁer [2].
In TPTL speciﬁcations, we always deal with closed formulas.
We note that “False” is represented as ⊥ ≡ ¬ and
“Implication” is represented as ϕ1 → ϕ2 ≡ ¬ϕ1 ∨ ϕ2 . For
all formulas ψ, φ, ψ ≡ Uψ (Eventually ψ), ψ ≡ ¬¬ψ
(Always ψ), and ψRφ ≡ ¬(¬ψU¬φ) (ψ Releases φ) are deﬁned
in the conventional way. Since we focus on oﬀ-line monitoring,
we only consider the TPTL semantics for ﬁnite traces.
2 We

will explain in Section II-B why we chose Raskin’s semantics.

185

Now we explain why we focus on Raskin’s semantics in
our monitoring algorithm. In Raskin’s semantics, each time
constraint contains a single time variable (see Deﬁnition 3).
However, in Alur’s semantics each time constraint contains
two time variables [2]. In Alur’s semantics, time variables in
the same constraint are dependent to each other. As a result,
in order to beneﬁt from independent time variables, we should
consider Raskin’s semantics.
Deﬁnition 6 (Encapsulated TPTL formula): Encapsulated
TPTL formulas are TPTL formulas where all the time
variables are independent.

In other words, an encapsulated formula is a closed formula
in which every sub-formula has at most one free time variable.
Deﬁnition 7 (Frozen Subformula): Given an encapsulated
TPTL formula Φ, a frozen subformula φ of Φ is a subformula
which is bounded by a freeze quantiﬁer corresponding to (an
independent) time variable.
In encapsulated formulas, all the closed subformulas are
frozen. For example the formula x.(ψ(x) ∨ y.ϕ(x, y)) is not an
“encapsulated” formula because y.ϕ(x, y) is not frozen since
x, y are not independent. Here are two TPTL formulas ϕ1 ,ϕ2
that look similar but only one of them is encapsulated.
•

ϕ1 = x.(a ∧ x ≤ 10 ∧ y.(y ≤ 2 ∧ y ≥ 1 ∧ b))

•

ϕ2 = x.(a ∧ x ≤ 10 ∧ y.(x ≤ 2 ∧ y ≥ 1 ∧ b))

տ

߮ଶ ൌ ߠଶ Ǥ ‫ݐ݊݁ݎܽ݌‬

x.

߮ଷ ൌ ߠଶ Ǥ ‫ݐ݋݋ݎ‬

‫ۍ‬
‫ר‬

߮ସ
߮ହ
߮଻

ߠଷ

y.

՜
x൑ͳ

a

଼߮
߮ଵଵ

‫ۍ‬
՜

y൑ͳ

ߠଶ

ߠଵ

߮଺ ൌ ߠଵ Ǥ ‫ݐ݊݁ݎܽ݌‬
߮ଽ ൌ ߠଵ Ǥ ‫ݐ݋݋ݎ‬
߮ଵ଴

൓

߮ଵଶ

b

߮ଵଷ

Fig. 1. Binary tree of Example 1 (φ) with three subtrees corresponding to
sets of subformulas θ1 , θ2 , θ3 .

In the above, ϕ1 is encapsulated, but ϕ2 is not encapsulated
since y.(x ≤ 2 ∧ y ≥ 1 ∧ b) where x ≤ 2 is inside the scope
of “y.”.
Lemma 1: Any MTL formula can be represented by an
“encapsulated” TPTL formula.
Proof: Each time interval of an MTL temporal operator can be represented with a unique time variable which
is independent of the rest of time variables. The syntactic
modiﬁcation works as follows: every MTL formula of the form
ϕ = ψU[l,u] φ can be recursively represented as the following
TPTL formula ϕ = x.(ψU(x ≥ l ∧ x ≤ u ∧ φ)). The resulting
TPTL formula is encapsulated.
Lemma 2: MTL is less expressive than “encapsulated”
TPTL formulas.
Proof: It is proven in [4] that the following TPTL formula,
which is evidently encapsulated, cannot be expressed by any
MTL formula [4]: ψ = x.(a ∧ x ≤ 1 ∧ (x ≤ 1 → ¬b))
In the rest of the paper, we focus on the following problem:
Problem 1: Given a ﬁnite TSS ρ̂ and an “encapsulated”
TPTL formula ϕ, check whether ρ̂ satisﬁes ϕ (ρ̂ |= ϕ).
III.

߶ ൌ ߮ଵ

Monitoring Encapsulated TPTL Formulas

A. TPTL Representation
In the following, we will describe the data structure that
will be utilized to capture the solution for the TPTL monitoring
problem. We store each TPTL formula in a binary tree data
structure. Consider the following example:
Example 1: Assume AP = {a, b} and let
φ = x.((x ≤ 1 → a) ∧ y.(y ≤ 1 → ¬b))
φ ≡ x.((x ≤ 1 → a) ∧ y.ψ1 (y)) ≡ x.ψ2 (x)
where we use ψ1 and ψ2 to simplify the presentation:
ψ1 (y) ≡ (y ≤ 1 → ¬b)
ψ2 (x) ≡ ((x ≤ 1 → a) ∧ y.ψ1 (y))
In this example, we have two independent time variables x and
y. The binary tree of Example 1 is depicted in Fig. 1. There,
the thirteen nodes correspond to thirteen subformulas.
In Fig. 1, each subformula ϕi has a node corresponding to
the highest operator for ϕi . In addition, for each subformula
ϕi we assign an index i. The order of indexes is generated
according to a topological sort where parents have lower index

186

values than children. Therefore, the original subformula φ
obtains the index 1 because it is the ﬁrst visited. To evaluate
each node’s /⊥ value we need to evaluate its children’s /⊥
value before, this is because of the TPTL recursive semantics
(see Deﬁnition 4). If we evaluate the nodes in the decreasing
order of indexes, we would be able to evaluate all the children
before their parents.
Now, we must partition the formula tree into subtrees
rooted by the freeze time operators. Since in Example 1, we
have two independent time variables, we created 2+1 subtrees
(two for time variables and one for the original formula). Each
subtree contains a set of subformulas. These subformulas and
their corresponding subtrees θ1 , θ2 , θ3 are shown in Fig. 1 with
diﬀerent colors:
The set θ1 contains subformulas rooted at node ϕ9 represented in the light-gray subtree. The set θ1 contains the
subformulas of y.ψ1 (y) as follows θ1 = {(y ≤ 1 → ¬b), y ≤
1 → ¬b, y ≤ 1, ¬b, b} = {ϕ9 , ϕ10 , ϕ11 , ϕ12 , ϕ13 }.
The set θ2 contains subformulas rooted at node ϕ3 represented in the white subtree. The set θ2 contains the subformulas of x.ψ2 (x) as follows θ2 = {((x ≤ 1 → a) ∧
y.ψ1 (y)), (x ≤ 1 → a) ∧ y.ψ1 (y), (x ≤ 1 → a), y.ψ1 (y), x ≤
1, a} = {ϕ3 , ϕ4 , ϕ5 , ϕ6 , ϕ7 , ϕ8 }.
The set θ3 contains subformulas rooted at node ϕ1 represented in dark-gray subtree. The set θ3 contains the subformulas of θ3 = {x.ψ2 (x) , x.ψ2 (x)} = {ϕ1 , ϕ2 }.
Each of the subtrees θ1 and θ2 have distinguished ﬁelds
referencing to (the index of) parent and root nodes which are
represented in Fig. 1 as follows:
1) θ1 .parent = 6 and θ1 .root = 9.
2) θ2 .parent = 2 and θ2 .root = 3.
Note that θ1 is subformula of θ2 , and θ2 is subformula
of θ3 . This ordering is very important for our algorithm.
We created these subtrees because each frozen subformula
can be separately evaluated. Therefore, we can guarantee the
polynomial runtime. The method will be described in details
in Section IV.
B. Monitoring Table
We assume that the sampled system output is mapped
(projected) on a ﬁnite TSS ρ̂; therefore, we can evaluate the
system output using our oﬀ-line monitor. If the speciﬁcation

does not have a freeze time operator, then the formula is an
LTL formula for which the existing monitoring algorithms will
be utilized [22]. If the speciﬁcation has a freeze time operator,
we ﬁrst “instantiate” the time variable with the time label of the
current sample before formula evaluation. Then, we compute
⊥/ values of the corresponding time constraints. When time
constraints are evaluated, they will be resolved to ⊥/, and
then, the frozen subformula (x.ϕ(x)) is converted into an LTL
formula. Hence, we can apply dynamic programming method
[22] to compute the Boolean value of the frozen subformula.
For each frozen subformula (x.ϕ(x)) at each time instance
τi , we must ﬁrst precompute the Boolean (⊥/) value of the
corresponding time constraints to transform this frozen subformula into an LTL. A two-dimensional matrix M|φ|×|ρ̂| with
height (number of rows) |φ| , and width (number of columns)
|ρ̂| is created. Here |φ| denotes the number of subformulas in
φ, and |ρ̂| is the number of samples. Note that row indexing
starts from 1 (φ ≡ ϕ1 ) up to |φ| and column indexing starts
from 0 (ρ0 ) up to |ρ̂| − 1.
The monitoring table of Example 1 is presented in Table I.
At the beginning, the system outputs corresponding to atomic
propositions (AP = {a, b}) are stored in the rows which belong
to the propositions a (row ϕ8 ) and b (row ϕ13 ) in Table I.
In Fig. 1, the subformula ψ2 (x) is depicted inside the white
subtree and ψ1 (y) is depicted inside the light-gray subtree. In
the following, we explain the other rows of Table I and provide
a high level overview of the monitoring of φ:
1st Run) We ﬁrst instantiate time variable y at each sample
i with the corresponding timed instance τi to evaluate the
Boolean values for the corresponding time constraint y ≤ 1
(row ϕ11 ). The instantiation transforms y.ψ1 (y) into an LTL
formula. Then we compute the Boolean values of ψ1 (τ0 ),
ψ1 (τ1 ), ψ1 (τ2 ), . . . , ψ1 (τ6 ) from left to right. Now the Boolean
value of y.ψ1 (y) for each time stamp τi is available for the
higher level subtree of the Table I. Therefore, the Boolean
values should be copied from row ϕ9 to row ϕ6 .
2nd Run) Given the ⊥/ values of y.ψ1 (y), we can
instantiate x at each time stamp τi and modify formula x.ψ2 (x)
into an LTL formula. Then we compute the Boolean values of
ψ2 (τ0 ), ψ2 (τ1 ), ψ2 (τ2 ), . . . , ψ2 (τ6 ) from left to right. Now the
Boolean values of x.ψ2 (x) are available for each time stamp τi
for the higher subtree. As a result, the ⊥/ values should be
copied from row ϕ3 to row ϕ2 .
3rd Run) The Boolean value of x.ψ2 (x) is computed
given the Boolean values of ψ2 (τi ) according to the semantics
of Always () operator:
6
φ≡
ψ2 (τi )
i=0

IV.

TPTL Monitoring Algorithm

The algorithms has the main following steps.
1)
2)

For each time variable (frozen subformula) and for
each time stamp.
Resolve the time constraints into ⊥/ values (This
step converts the corresponding frozen subformula
into an LTL formula).

187

TABLE I.

The Monitoring Table of formula φ of Example 1 (Fig. 1)

ϕi (OP)
ϕ1 ()
ϕ2 (x.)

τ0
{⊥/}
ψ2 (0)

τ1

τ2

τ3

τ4

τ5

τ6

ψ2 (τ1 )

ψ2 (τ2 )

ψ2 (τ3 )

ψ2 (τ4 )

ψ2 (τ5 )

ψ2 (τ6 )

ϕ3 ()
ϕ4 (∧)
ϕ5 (→)
ϕ6 (y.)
ϕ7 (x ≤ 1)
ϕ8 (a)

ψ2 (0)

ψ2 (τ1 )

ψ2 (τ2 )

ψ2 (τ3 )

ψ2 (τ4 )

ψ2 (τ5 )

ψ2 (τ6 )

ψ1 (0)

ψ1 (τ1 )

ψ1 (τ2 )

ψ1 (τ3 )

ψ1 (τ4 )

ψ1 (τ5 )

ψ1 (τ6 )

ϕ9 ()
ϕ10 (→)
ϕ11 (y ≤ 1)
ϕ12 (¬)
ϕ13 (b)

ψ1 (0)

ψ1 (τ1 )

ψ1 (τ2 )

ψ1 (τ3 )

ψ1 (τ4 )

ψ1 (τ5 )

ψ1 (τ6 )

3)
4)

Compute ⊥/ value of the resulting LTL formula
using the dynamic programming algorithm.
These ⊥/ values of frozen subformula are used to
evaluate the higher level subformulas.

In the following, a detailed description and pseudo code of the
proposed algorithm for TPTL monitoring will be explained.
A. TPTL to LTL Transformation
The pseudo code of the monitoring algorithm is provided
in Algorithm 1 and its main loop has |V| + 1 iterations
where |V| is the number of freeze time variables. Algorithm
1 calls Algorithm 2 for computing the Boolean value of LTL
subformulas. The ﬁrst line of Algorithm 1 sets the monitoring
table entries of the corresponding atomic propositions, namely
the Boolean value of each p ∈ AP is extracted from the ﬁnite
state sequence σ̂. In addition, Line 1 sets the monitoring table
entries for constant boolean values ⊥/. For each time variable
vk (in Line 2), we need to compute the ⊥/ value of the
subtree θk . The order of k is in such away that the inner most
subtree (θ1 ) is evaluated ﬁrst then θ2 , and ﬁnally, θ3 (See Fig
1 for Example 1). This order is crucial for the correctness of
the algorithm, because higher level subformulas consider the
lower level frozen subformulas as ⊥/.
To transform the frozen formula into LTL for each sample
time t between 0 to |ρ̂| − 1 (see Line 3), we must ﬁrst
instantiate the time variable vk to the corresponding time
stamp τt , then compute the Boolean value of the corresponding
time constraint vk ∼ r. The instantiation evaluates the whole
constraint row into ⊥/ in Lines 4-13 of Algorithm 1. The
environment is updated based on the time stamp τt and
the formula translated into an LTL formula. Now we use a
dynamic programming algorithm based on [22] to compute the
⊥/ value of the frozen subformula in Lines 14-18. In Line 15
of Algorithm 1, θk .max (θk .min) is the maximum (minimum)
index of subformulas in the subtree θk . In Example 1:
1) θ1 .min = 9 and θ1 .max = 13
2) θ2 .min = 3 and θ2 .max = 8
When the Boolean value of the frozen subformula of
vk .ψ(vk ) (θk .root) at time stamp vk = τt is resolved, this
Boolean value is copied to the parent of θk (θk .parent) to be
used by higher level subformulas (see Line 19 of Algorithm
1). The loop of Line 3-20 continues for the other time
stamps (τ1 . . . τ|ρ̂|−1 ) and computes the ⊥/ value of the frozen
subformula for each instantiation of vk to the time stamps
τ1 . . . τ|ρ̂|−1 in this order. Now we resolved the ⊥/ value of the
frozen subformula of vk .ψ(vk ) for all time stamps. We continue
this process for other time variables (Lines 2-21).

Algorithm 1 TPTL Monitor
Input: ϕ, ρ̂ = (σ0 , τ0 )(σ1 , τ1 ) · · · (σT , τT ); Global variables:
M|ϕ|×|ρ̂| ; Output: M[1, 0].
procedure TPTLMonitor(ϕ, ρ̂)
1: Initialize all rows in M|ϕ|×|ρ̂| corresponding to predicates
ϕ j ≡ p ∈ AP with /⊥ value according to σ̂.
2: for k ← 1 to |V| do
3:
for t ← 0 to |ρ̂| − 1 do
4:
for u ← t to |ρ̂| − 1 do
5:
for each ϕ j ≡ vk ∼ r ∈ θk where
6:
j is the index of vk ∼ r in M do
7:
if (τu − τt ) ∼ r then
8:
M[ j, u] ← 
9:
else
10:
M[ j, u] ← ⊥
11:
end if
12:
end for
13:
end for
14:
for u ← |ρ̂| − 1 down to t do
15:
for j ← θk .max down to θk .min do
16:
M[ j, u] ← ComputeLT L(ϕ j , u, M|ϕ|×|ρ̂| )
17:
end for
18:
end for
19:
M[θk .parent, t] ← M[θk .root, t]
20:
end for
21: end for
22: for u ← |ρ̂| − 1 down to 0 do
23:
for j ← θ|V|+1 .max down to θ|V|+1 .min do
24:
M[ j, u] ← ComputeLT L(ϕ j , u, M|ϕ|×|ρ̂| )
25:
end for
26: end for
27: return M[1, 0] // Return the value of the ﬁrst cell/row in
M|ϕ|×|ρ̂| table
end procedure

When the Boolean values of the frozen subformulas are
resolved for each time variable v1 . . . vk . . . v|V| in this order, we
have an LTL formula for the highest level subformula where it
corresponds to subtree θ|V|+1 . To compute the ⊥/ value of the
highest set of subformulas we run Lines 22-26 of Algorithm
1. Note that Lines 22-26 are almost identical to Lines 1418 because the highest set of subformulas is in LTL. The ﬁnal
value that corresponds to the monitoring trace is stored in table
entry M[1, 0] and it will be returned to the user. The table entry
M[1, 0] contains the Boolean value of the TPTL speciﬁcation
(ϕ1 ) at sampled index 0.
B. LTL Monitoring
Now we explain how to compute the Boolean values of
the LTL subtree. Algorithm 2 is based on [22], and follows
Deﬁnition 4. Algorithm 1 calls Algorithm 2 at each sample u.
Algorithm 2 has the following 5 cases to compute the Boolean
values of the corresponding LTL operators:
1)
2)
3)
4)
5)

Lines
Lines
Lines
Lines
Lines

1-2 for the NOT operation (¬).
3-4 for the AND operation (∧).
5-6 for the OR operation (∨).
7-12 for the NEXT operation (	).
13-19 for the UNTIL operation (U).

Algorithm 2 LTL Monitor
Input: ϕ j , u, M|ϕ|×|ρ̂| ; Output: M[ j, u].
procedure ComputeLTL(ϕ j , u, M|ϕ|×|ρ̂| )
1: if ϕ j ≡ ¬ϕm then
2:
return ¬M[m, u]
3: else if ϕ j ≡ ϕm ∧ ϕn then
4:
return M[m, u] ∧ M[n, u]
5: else if ϕ j ≡ ϕm ∨ ϕn then
6:
return M[m, u] ∨ M[n, u]
7: else if ϕ j ≡ 	ϕm then
8:
if u = |ρ̂| − 1 then
9:
return ⊥
10:
else
11:
return M[m, u + 1]
12:
end if
13: else if ϕ j ≡ ϕm Uϕn then
14:
if u = |ρ̂| − 1 then
15:
return M[n, u]
16:
else
17:
return M[n, u] ∨ (M[m, u] ∧ M[ j, u + 1])
18:
end if
19: end if
end procedure
Note that Algorithm 2 (ComputeLTL) is O(1) complexity. Since we can evaluate each frozen subformula (x.ϕ(x))
separately because of independent time variables, the time
complexity of the algorithm is proportional to the number of
time variables and the size of the subformula. On the other
hand, for each time sample we instantiate each time variable
to convert the TPTL subformula into an LTL subformula in
O(|ρ̂|) then run the LTL monitoring algorithm in O(|ρ̂|). As a
result, the upper bound on the time complexity of Algorithm 1
is O(|V| × |ϕ| × |ρ̂|2 ), where |V| is the number of time variables,
|ϕ| is the number of subformulas, and |ρ̂| is the number of TSS
samples. Both algorithms’ correctness proofs are provided in
Section VII.
C. Running example
In this section, we utilize our monitoring algorithm to
compute the solution for Example 1. First step of the algorithm
is the /⊥ computation of the frozen subformula y.ψ1 (y) which
corresponds to subtree θ1 and is represented in light-gray rows
of Tables I and II. In Table II, when the time value of y is
instantiated to 0, then the value of the time constraint y ≤ 1 will
be resolved for all the samples of i between 0 to 6 according to
the following inequality τi − 0 ≤ 1. Now ψ1 (0) is transformed
into LTL and ψ1 (0) is evaluated, i.e., ψ1 (0) ≡  (see row ϕ9
column τ0 ). Then, the time value of y is instantiated to τ1 = 0.3
and the value of the time constraint y ≤ 1 will be resolved for
all the samples of i between 1 to 6 according to the following
inequality τi − 0.3 ≤ 1. Similarly, ψ1 (0.3) is transformed into
LTL and ψ1 (0.3) can be computed, i.e., ψ1 (0.3) ≡  (see row
ϕ9 column τ1 ). We continue the computation of ψ1 (τi ) with
the following instantiation τ2 = 0.7, . . . , τ6 = 1.9 similar to τ0 .
Now ⊥/ values of the frozen subformula y.ψ1 (y) for each
time stamp τi are available in row ϕ9 of Table II.
The Boolean values of subtree θ1 should be available
for higher level subformulas. Therefore, the row ϕ9 will be

188

copied to row ϕ6 (in Table II both rows have the same color).
Now we can continue the second run of the algorithm. The
/⊥ computation of the frozen subformula x.ψ2 (x) which
corresponds to subtree θ2 is represented in white rows of Table
I and II. In Table II, the time value of x is instantiated to 0, then
the value of ψ2 (0) is computed, i.e., ψ2 (0) ≡  (see row ϕ3
column τ0 ). Now, the time value of x is instantiated to τ1 = 0.3
and the value of ψ2 (0.3) is computed ψ2 (0.3) ≡  (see row ϕ3
column τ1 ). We continue the computation of ψ2 (τi ) similarly
with τ2 = 0.7 . . . τ6 = 1.9. Now the ⊥/ values of the frozen
subformula x.ψ2 (x) for each time stamp τi are available in
row ϕ3 of Table II. Since the Boolean values of subtree θ2
should be available for higher level subformulas, the row ϕ3
is copied to row ϕ2 . Finally, we compute φ = x.ψ2 (x) using
Lines
22-26 of Algorithm 1 which corresponds to following:
6
φ=
ψ2 (τi ) ≡ ⊥
i=0

V. Experiments
An implementation of our TPTL monitoring algorithm is
provided in the S-TaLiRo testing framework [15]. S-TaLiRo
is a Matlab toolbox that uses stochastic techniques to ﬁnd
initial states and inputs to Simulink models which result in
trajectories that falsify MTL formulas. With our TPTL oﬀ-line
monitoring algorithm, S-TaLiRo can evaluate speciﬁcations
that are more expressive than MTL.
A. Runtime Analysis
We measured the runtime of our TPTL monitoring algorithm using the S-TaLiRo toolbox. The system under test
was the Automatic Transmission (AT) model provided by
Mathworks as a Simulink demo [19]. We introduced a few
modiﬁcations to the model to make it compatible with the STaLiRo framework, which are explained in [14]. AT has two
inputs of Throttle and Brake. The outputs contain two realvalued traces: the rotational speed of the engine ω and the
speed of the vehicle v. In addition, the outputs contain one
discrete-valued trace gear with four possible values.
To provide TPTL speciﬁcations, we deﬁned four atomic
propositions corresponding to the following predicates:
1) a1 ≡ (ω ≥ 4500): “rotational speed of the engine ≥ 4500”
2) a2 ≡ (ω ≤ 1500): “rotational speed of the engine ≤ 1500”
3) a3 ≡ (v ≥ 40): “speed of the vehicle ≥ 40”
4) a4 ≡ (v ≤ 120): “speed of the vehicle ≤ 120”
Note that these predicates are chosen to be non-trivial and have
meaning in the CPS context. The TPTL formulas are generated
based on typical safety reactive response speciﬁcations. We
generated these TPTL formula patterns to check the runtime
with respect to: 1) Size of system trace 2) Number of temporal
operators 3) Number of time variables.
We created 18 TPTL formulas that cannot be expressed in
MTL. All the speciﬁcations have the reactive response pattern:
(a1 → ψ) where ψ is categorized in two groups:
1)
2)

EA group (ψEA ): contains Eventually/Always speciﬁcations with 2, 4 and 8 temporal operators.
UR group (ψUR ): contains Until/Release speciﬁcations with 2, 4 and 8 temporal operators.

We ﬁrst chose a ψ speciﬁcation in LTL from Table III column
(LTL template). In Table III, column (#) represents the number

189

of temporal operators for each LTL template. Then, we added
time variables to create a TPTL speciﬁcation. The last column
in Table III represents the number of TPTL formulas that we
created by adding time constraints on ψ. The time variables
that we add to ψ correspond to individual temporal operators.
In this case, for ψEA2 we create two TPTL formulas with one
and two time variables respectively given as φ1 and φ2 :
EA
EA

φ1 = (a1 → x.(a2 ∧ (a3 ∨ a4 ∧ C x )))
φ2 = (a1 → x.(a2 ∧ C x ∧ y.(a3 ∨ a4 ∧ Cy )))

where C x and Cy are the corresponding time constraints for x
and y. Similarly for ψUR2 we created two TPTL formulas with
one and two time variables respectively given as φ1 and φ2 :
UR
UR

φ1 = (a1 → x.(a2 U(a3 R(a4 ∧ C x ))))
φ2 = (a1 → x.(a2 Ua4 ∧ C x ∧ y.(a3 R(a4 ∧ Cy )))

We used a similar method to generate φ3 with one time
variable, φ4 with two time variables, and φ5 with four time
variables based on ψEA4 and ψUR4 with the total number of six
TPTL formulas. Finally, we create eight TPTL formulas based
on ψEA8 and ψUR8 . These formulas are φ6 , φ7 , φ8 , φ9 and they
are represented in Table IV. Our experiments were conducted
on a 64-bit Intel Xeon CPU (2.5GHz) with 64-GB RAM and
Windows Server 2012. We used Matlab 2015a and Microsoft
Visual C++ 2013 Professional to compile our algorithms’ code
(in C) using the Matlab mex compiler.
The runtime is provided in Table IV. Each row considers
two TPTL formulas in EA or UR conﬁguration. For example,
the ﬁrst column φ1 represents (a1 → x.(a2 ∧(a3 ∨a4 ∧C x )))
and (a1 → x.(a2 U(a3 R(a4 ∧ C x )))) in EA and UR conﬁgurations, respectively. In Table IV the second column (#)
represents the number of temporal operators in the corresponding frozen subformula, namely, the number of of temporal
operators in ψEA# or ψUR# . The third column (|V|) in Table
IV represents the number of time variables in ψEA# or ψUR# .
We tested our algorithm with the execution traces of
the length 1000, 2000, and 10000. For each TPTL formula,
we tested our algorithm 100 times where the AT’s throttle
input is provided by random signal generator (without brake).
We reported the mean value (in Bold) and variance of the
algorithm’s runtime in Table IV. It can be seen that when
the length of the trace doubles from |ρ̂|=1,000 to |ρ̂|=2,000
, the runtime quadruples (see Mean values in Table IV).
Similarly, when the length of trace increases ten times from
|ρ̂|=1,000 to |ρ̂|=10,000 the runtime increased 100 times (see
Mean values in Table IV). Now, consider the mean values
of φ1 and φ2 . The number of time variables in φ1 is one
and in φ2 is two. It can be seen that mean values of φ2 are
twice as those of φ1 . Similarly, comparing φ3 and φ4 and φ5
shows that the runtime is proportional to the number of time
variables. Finally, comparing rows φ1 and φ3 and φ6 shows
that the runtime relates to the number of temporal operators.
The experimental results indicate that the runtime behaves as
expected, considering that our algorithm is in O(|V| × |ϕ| × |ρ̂|2 ).
B. Case Study
In this section, we consider CPS requirements which are
impossible to formalize in MTL [4], but we formalize them
in TPTL, very easily. The ultimate goal is to run the testing

TABLE II.
ϕi
ϕ1
ϕ2
ϕ3
ϕ4
ϕ5
ϕ6
ϕ7
ϕ8
ϕ9
ϕ10
ϕ11
ϕ12
ϕ13

subformula

φ = x.ψ2 (x)
x.ψ2 (x) ≡ x.((x ≤ 1 → a) ∧ y.ψ1 (y))
((x ≤ 1 → a) ∧ y.ψ1 (y))
(x ≤ 1 → a) ∧ y.ψ1 (y)
x≤1→a
y.ψ1 (y) ≡ y.(y ≤ 1 → ¬b)
x≤1
a
(y ≤ 1 → ¬b)
y ≤ 1 → ¬b
y≤1
¬b
b

TABLE III.
LTL
ψEA2
ψEA4
ψEA8
ψUR2
ψUR4
ψUR8

Computing the Boolean values for φ = x.ψ2 (x). Boolean values correspond to the final snapshot of Monitoring Table.

#
2
4
8
2
4
8

τ0 = 0
⊥
ψ2 (0) ≡ 

⊥
⊥
ψ1 (0) ≡ 

⊥




⊥

τ1 = 0.3
⊥
ψ2 (τ1 ) ≡ 

⊥
⊥
ψ1 (τ1 ) ≡ 

⊥




⊥

τ2 = 0.7
⊥
ψ2 (τ2 ) ≡ 



ψ1 (τ2 ) ≡ 



⊥

⊥


Specifications of ψ before adding time variables.
LTL template
(a2 ∧ (a3 ∨ a4 )
(a2 ∧ (a3 ∨ a4 ∧ ψEA2 )
(a2 ∧ (a3 ∨ a4 ∧ (a2 ∧ (a3 ∨ a4 ∧ ψEA4 ))))
a2 U(a3 Ra4 )
a2 U(a3 R(a4 ∧ ψUR2 ))
a2 U(a3 R(a4 ∧ (a2 U(a3 R(a4 ∧ ψUR4 )))))

τ3 = 1.0
⊥
ψ2 (τ3 ) ≡ 



ψ1 (τ3 ) ≡ 






⊥

τ4 = 1.1
⊥
ψ2 (τ4 ) ≡ ⊥
⊥
⊥

ψ1 (τ4 ) ≡ ⊥


⊥
⊥

⊥


τ6 = 1.9
⊥
ψ2 (τ6 ) ≡ ⊥
⊥
⊥
⊥
ψ1 (τ6 ) ≡ ⊥

⊥
⊥
⊥

⊥


7KURWWOH

100

TPTLs
2
3
4
2
3
4

τ5 = 1.5
⊥
ψ2 (τ5 ) ≡ ⊥
⊥
⊥
⊥
ψ1 (τ5 ) ≡ ⊥

⊥
⊥
⊥

⊥


50
0

0

5

10

algorithm on these requirements. Our TPTL monitoring algorithm is provided as add-on to the S-TaLiRo testing framework.
S-TaLiRo searches for counterexamples to MTL properties
through global minimization of a robustness metric [9]. The
robustness of an MTL formula ϕ is a value that measures
how far is the trace from the satisfaction/falsiﬁcation of ϕ.
This measure is an extension of Boolean values (/⊥) for
representing satisfaction or falsiﬁcation. A positive robustness
value means that the trace satisﬁes the property and a negative
value means that the property is not satisﬁed. The stochastic
search then returns the simulation trace with the smallest
robustness value that was found.
To falsify safety requirements in TPTL which are more
expressive than MTL, we should use our proposed TPTL
monitor that can handle those speciﬁcations. Now let us
consider the Automatic Transmission (AT) system. It contains
the discrete output gear signal with four possible values
(gear = 1, ..., gear = 4) which indicate the current gear
in the auto-transmission controller. We use four atomic
propositions g1 , g2 , g3 , g4 for each possible gear value, where
(gear = i) ≡ gi . Then we deﬁne three up-shifting events as
follows:
1) e1 = g1 ∧ 	g2 means shift from gear one to gear two.
2) e2 = g2 ∧ 	g3 means shift from gear two to gear three.
3) e2 = g3 ∧ 	g4 means shift from gear three to gear four.
In CPS, it is possible that we need to specify the safety
requirement about three or more events in sequence,
but the time diﬀerence between the ﬁrst and last event
happening should be of importance. In general, these types of
speciﬁcation are impossible to represent in MTL. We provide
two very succinct TPTL speciﬁcations that can formalize
these challenging requirements.
The ﬁrst requirement is as follows:
“Always if e1 happens, then if e2 happens in future and if e3
happens in future after e2 , then the duration between e1 and
e3 should be equal or more than 8.”
This speciﬁcation is formalized in the following formula:
Φ1 = z.(e1 → (e2 → (e3 → z ≥ 8)))

190

0

15

20

25

30

20

25

30

20

25

30

%UHDN

500

0

5

10

15

*HDU

4
2

6.68
0

0

5

10

15

Fig. 2. Falsiﬁcation of Φ1 using S-TaLiRo. The duration between e1 and e3
is less than 8 seconds.
7KURWWOH

100
50
0

0

5

10

0

15

20

25

30

20

25

30

20

25

30

%UHDN

500

0

5

10

15

*HDU

4
2

17.88
0

0

5

10

15

Fig. 3. Falsiﬁcation of Φ2 using S-TaLiRo. The duration between e1 and e3
is more than 12 seconds.

S-TaLiRo successfully falsiﬁed Φ1 which is represented in Fig.
2. In Fig. 2 the Throttle, Break, and Gear trajectory of the
corresponding falsiﬁcation is presented. It can be seen that the
duration between e1 and e3 is less that 8. Its actual value is
8.4 − 1.72 = 6.68 < 8.
The second requirement is as follows:
“Always if e1 happens, then e2 should happen in future, and
e3 should happen in future after e2 , and the duration between
e1 and e3 should be equal or less than 12.”
This speciﬁcation is formalized by the following formula:
Φ2 = z.(e1 → (e2 ∧ (e3 ∧ z ≤ 12)))
In Fig. 3 the Throttle, Break, and Gear trajectories of the
falsiﬁcation of Φ2 are represented. It can be seen that the
duration between e1 and e3 is more than 12, its actual value is
19.2−1.32 = 17.88 > 12. This case study shows that S-TaLiRo

TABLE IV.

The runtime of Monitoring Algorithm for 18 TPTL formulas. All the values are in seconds.

φ

#

|V|

|ρ̂|=1,000
EA (ψEA# )
UR (ψUR# )
Mean
Var.
Mean
Var.

|ρ̂|=2,000
EA (ψEA# )
UR (ψUR# )
Mean
Var.
Mean
Var.

|ρ̂|=10,000
EA (ψEA# )
UR (ψUR# )
Mean
Var.
Mean
Var.

φ1

2

1

0.077

0.0002

0.064

φ2

2

2

0.151

0.0005

0.137

0.000

0.326

0.001

0.250

0.0013

8.512

0.066

6.427

0.068

0.0003

0.5887

0.0018

0.551

0.002

14.31

0.191

13.67

φ3

4

1

0.142

0.0003

0.097

0.175

0.0001

0.5885

0.002

0.382

0.002

15.33

0.232

10.46

φ4

4

2

0.205

0.0003

0.154

0.15

0.0002

0.871

0.0032

0.604

0.002

22.9

0.344

16.35

φ5

4

4

0.417

0.24

0.0012

0.38

0.0004

1.721

0.0058

1.558

0.007

46.25

7.08

41.2

1.077

φ6

8

1

φ7

8

2

0.227

0.0001

0.154

0.0002

0.948

0.005

0.552

0.0046

30.27

9.708

17.01

2.184

0.367

0.025

0.235

0.0011

1.474

0.0078

1.023

0.0137

41.59

2.17

26.95

φ8

8

2.204

4

0.533

0.0042

0.437

0.0013

2.26

0.024

1.751

0.0115

66.13

34.36

48.95

φ9

8

8.857

8

1.145

0.025

1.093

0.0066

4.9

0.0391

4.346

0.1413

137

220

124.6

184

can be used for the falsiﬁcation problem of challenging TPTL
requirements. The method we propose in this work opens
the possibility for CPS oﬀ-line monitoring of very complex
speciﬁcations in TPTL using an eﬃcient algorithm.
VI.

[10]

[11]

Conclusions and Future works

In this paper, we provide an eﬃcient polynomial time
algorithm for a practical subset of TPTL speciﬁcations. We
show that very complex speciﬁcations can be succinctly represented in this TPTL subset. In addition, we can combine
full TPTL with a bounded number of time variables with
our suggested algorithm to test the speciﬁcations that have an
arbitrary number of independent time variables and full TPTL
with limited number of time variables. Finally, our method
can help CPS developers to eﬃciently test requirements that
cannot be expressed in MTL.

[12]

[13]
[14]

[15]

Acknowledgments: This research was partially funded
by NSF awards CNS-1350420 and CNS-1319560.

[16]

References

[17]

[1]

[2]
[3]

[4]
[5]

[6]

[7]

[8]

[9]

R. Alur, C. Courcoubetis, N. Halbwachs, T. A. Henzinger, P.-H. Ho,
X. Nicollin, A. Olivero, J. Sifakis, and S. Yovine. The algorithmic
analysis of hybrid systems. Theoretical Computer Science, 138(1):3–
34, 1995.
R. Alur and T. A. Henzinger. A really temporal logic. Journal of the
ACM, 41(1):181–204, 1994.
Y. S. R. Annapureddy, C. Liu, G. E. Fainekos, and S. Sankaranarayanan.
S-TaLiRo: A tool for temporal logic falsiﬁcation for hybrid systems.
In Tools and algorithms for the construction and analysis of systems,
volume 6605 of LNCS, pages 254–257. Springer, 2011.
P. Bouyer, F. Chevalier, and N. Markey. On the expressiveness of TPTL
and MTL. Inf. Comput., 208(2):97–116, 2010.
M. Chai and H. Schlingloﬀ. A rewriting based monitoring algorithm
for TPTL. In Proceedings of the 22nd International Workshop on
Concurrency, Speciﬁcation and Programming, Warsaw, Poland, pages
61–72, 2013.
J. V. Deshmukh, R. Majumdar, and V. S. Prabhu. Quantifying conformance using the skorokhod metric. In Computer Aided Veriﬁcation
- 27th International Conference, CAV 2015, San Francisco, CA, USA,
July 18-24, 2015, Proceedings, Part II, pages 234–250, 2015.
A. Donze. Breach, a toolbox for veriﬁcation and parameter synthesis
of hybrid systems. In Computer Aided Veriﬁcation, volume 6174 of
LNCS, pages 167–170. Springer, 2010.
A. Donze, T. Ferrre, and O. Maler. Eﬃcient robust monitoring for STL.
In Proceedings of the 25th International Conference on Computer Aided
Veriﬁcation, CAV, pages 264–279, Berlin, Heidelberg, 2013. SpringerVerlag.
G. Fainekos and G. J. Pappas. Robustness of temporal logic speciﬁcations for continuous-time signals. Theor. Comput. Sci., 410(42):4262–
4291, 2009.

191

[18]
[19]

[20]

[21]
[22]

G. Fainekos, S. Sankaranarayanan, K. Ueda, and H. Yazarel. Veriﬁcation of automotive control applications using S-TaLiRo. In Proceedings
of the American Control Conference, 2012.
S. Feng, M. Lohrey, and K. Quaas. Path checking for MTL and
TPTL over data words. In Developments in Language Theory - 19th
International Conference, DLT 2015, Liverpool, UK, July 27-30, 2015,
Proceedings., pages 326–339, 2015.
R. Gerth, D. Peled, M. Y. Vardi, and P. Wolper. Simple on-theﬂy automatic veriﬁcation of linear temporal logic. In Proceedings
of the Fifteenth IFIP WG6.1 International Symposium on Protocol
Speciﬁcation, Testing and Veriﬁcation XV, pages 3–18, London, UK,
UK, 1996.
J. Håkansson, B. Jonsson, and O. Lundqvist. Generating online test
oracles from temporal logic speciﬁcations. STTT, 4(4):456–471, 2003.
B. Hoxha, H. Abbas, and G. Fainekos. Benchmarks for temporal logic
requirements for automotive systems. In Proc. of Applied Veriﬁcation
for Continuous and Hybrid Systems, 2014.
B. Hoxha, H. Bach, H. Abbas, A. Dokhanchi, Y. Kobayashi, and
G. Fainekos. Towards formal speciﬁcation visualization for testing and
monitoring of cyber-physical systems. In Int. Workshop on Design and
Implementation of Formal Tools and Systems. October 2014.
R. Koymans. Specifying real-time properties with metric temporal logic.
Real-Time Systems, 2(4):255–299, 1990.
K. J. Kristoﬀersen, C. Pedersen, and H. R. Andersen. Runtime veriﬁcation of timed LTL using disjunctive normalized equation systems. In
Proceedings of the 3rd Workshop on Run-time Veriﬁcation, volume 89
of ENTCS, pages 1–16, 2003.
N. Markey and J.-F. Raskin. Model checking restricted sets of timed
paths. Theor. Comput. Sci., 358(2):273–292, Aug. 2006.
MathWorks.
Modeling an automatic transmission controller,
available
at:
http://www.mathworks.com/help/simulink/examples/
modeling-an-automatic-transmission-controller.html.
J. Ouaknine and J. Worrell. Some recent results in metric temporal logic.
In Formal Modeling and Analysis of Timed Systems, 6th International
Conference, FORMATS 2008, Saint Malo, France, September 15-17,
2008. Proceedings, pages 1–13, 2008.
J.-F. Raskin. Logics, automata and classical theories for deciding realtime. Ph.D. Thesis, University of Namur, Belgium, 1999.
G. Rosu and K. Havelund. Synthesizing dynamic programming algorithms from linear temporal logic formulae. Technical report, Research
Institute for Advanced Computer Science (RIACS), 2001.

VII.

Appendix

In this section, we will prove the correctness of Algorithms
1 and 2. Our method ﬁrst transforms the TPTL formula into
LTL formula using Algorithm 1. Then it uses the dynamic
programming method for monitoring LTL using Algorithm 2.
A. Proof of the correctness of Algorithm 1
Theorem 1: Given an encapsulated TPTL formula ϕ, and
a ﬁnite TSS ρ̂, after the execution of Algorithm 1 the returned

value is:

M[1, 0] =  iﬀ (ρ̂, 0, 0) |= ϕ

To prove this theorem, we must show that the Boolean value
of the subformulas that are computed using Algorithm 1,
follows the TPTL semantics in Deﬁnition 4. Since Algorithm
1 does not evaluate propositional and temporal operators, their
corresponding proof will be provided in Section VII-B.
According to the TPTL semantics in Deﬁnition 4, for each
freeze time operation x.ϕ(x), and for each time stamp τi we
must instantiate the time variable x with the value of τi .
This instantiation enables us to evaluate time constraints and
transform TPTL to LTL. The loop of Lines 2-21 is the main
loop of Algorithm 1 which instantiates each variable vk with
each time sample τt in Line 3.
Lemma 3: The loop invariant of Algorithm 1 is as follows:
∀ j, k, t where ϕ j ≡ vk .ϕi , 0 ≤ t < |ρ̂| :
M[ j, t] =  iﬀ (ρ̂, t, ε) |= vk .ϕi
We use induction to prove the loop invariant of Algorithm 1.
Base: If |V| = 0, then formula is in LTL and algorithm
does not enter the to loop of Lines 2-21 (only executes Lines
22-26). The proof of LTL is provided in Section VII-B.
Induction Hypothesis: We assume for all vl , where l < k
the invariant holds. In other words
∀ j, l < k, t where ϕ j ≡ vl .ϕi , 0 ≤ t < |ρ̂| :
M[ j, t] = M[θl .parent, t] =  iﬀ (ρ̂, t, ε) |= vl .ϕi
Induction Step: To show the correctness for the case of
vk , we prove that Algorithm 1 correctly transform TPTL into
LTL. Then we apply the correctness of LTL (See Section
VII-B) to establish the correctness of invariant considering vk .
Thus, we consider two cases that instantiate and evaluate vk
and show that Algorithm 1 follows the semantics in Deﬁnition
4. According to I.H. and since time variables are independent,
we can correctly consider frozen subformulas of ϕi as /⊥.
As a result, we will conclude that ϕi is in LTL.
Case of vk .ϕi :
Consider the semantics of the freeze operator in Deﬁnition 4:
(ρ̂, t, ε) |= vk .ϕi iﬀ (ρ̂, t, ε[vk := τt ]) |= ϕi
According to this semantics, the freeze operation “vk .” ﬁrst
assigns a new value to the variable (vk := τt ). Then the /⊥
value of vk .ϕi ≡ ϕ j will be resolved to the same /⊥ value
of ϕi (with the new environment update). Therefore, for each
variable assignment (vk := τt ), we ﬁrst update the environment
variables (Algorithm 1, Line 3), and then copy the ϕi ’s /⊥
value into vk .ϕi ’s corresponding row (Algorithm 1, Line 19).
Since each time variable vk is independent, we create
the subtree (set) θk corresponding to the subformulas of
vk .ϕi (vk ) (see Section III-A). To evaluate vk .ϕi (vk ), we must
ﬁrst instantiate variable vk for each time stamp τ0 . . . τ|ρ̂|−1 .
This instantiation is considered in Line 2 of Algorithm 1 for
time variable vk and for each sample of time 0 . . . (|ρ̂| − 1) in
Line 3 of Algorithm 1. Now we must copy the resulting /⊥

192

value from ϕi back to vk .ϕi . The row corresponding to θk .root
contains the /⊥ value of ϕi which is the root of θk subtree.
This values must be copied to the row θk .parent which is the
parent of subtree θk and it corresponds to ϕ j (Algorithm 1,
Line 19).
Case of vk ∼ r:
Consider the semantics of time constraints in Deﬁnition 4:
(ρ̂, u, ε) |= vk ∼ r iﬀ (τu − ε(vk )) ∼ r
In the above semantics, ε(vk ) corresponds to the frozen value
of the time variable vk (environment of vk ). In the previous
case for vk .ϕi , we mentioned that we should instantiate vk
at each time stamp τ0 . . . τ|ρ̂|−1 . According to semantics in
Deﬁnition 4, each freeze operator assigns the environment
variable for the current and future samples of time t:
(ρ̂, t, ε) |= vk .ϕi iﬀ (ρ̂, t, ε[vk := τt ]) |= ϕi
Which means that the environment updates ε[x := τt ] are
observable for the current and the future samples (t ≤ u).
Therefore, after we instantiated variable vk at each time stamp
τt , the environment update will aﬀect all the samples u between
t ≤ u ≤ |ρ̂| − 1. As a result, the time constraint vk ∼ r must be
updated for all future samples of t ≤ u ≤ |ρ̂| − 1 for ε[vk := τt ]
instantiation.
Lines 4-13 of Algorithm 1 follow the above discussion.
Namely, for time variable vk , we instantiate each time stamp
τt (Line 3), the time constraints of current/future samples
are evaluated according to the frozen time stamp τt . Actual
evaluation happens in the Line 7 of Algorithm 1, where
(τu − τt ) ∼ r follows the semantic (τu − ε(vk )) ∼ r for
each environment assignment of ε[vk := τt ]. Lines 14-18 of
Algorithm 1 will evaluate the LTL formula ϕi (τt ).
So far, we transformed TPTL vk .ϕi (vk ) into LTL ϕi (τt ) for
each time stamp τt . Now we can prove that the loop invariant
of Algorithm 1 holds for vk .
Proof: We will prove the Induction Step by assuming the
correctness of LTL formula ϕi according to Section VII-B:
∀i, t, ε where ϕi ⊂ LT L, 0 ≤ t < |ρ̂|
M[i, t] =  iﬀ (ρ̂, t, ε) |= ϕi
Since for each θk , i = θk .root is the index of the highest LTL,
M[θk .root, t] will also contain the correct /⊥ value, therefore
M[i, t] = M[θk .root, t] =  iﬀ (ρ̂, t, ε) |= ϕi (vk = τt ) iﬀ
(ρ̂, t, ε[vk := τt ]) |= ϕi
Since in Line 19 M[θk .parent, t] ← M[θk .root, t]
and j = θk .parent we have
M[ j, t] ← M[i, t], as a result
M[ j, t] = M[θk .parent, t] =  iﬀ (ρ̂, t, ε) |= vk .ϕi ≡ ϕ j

B. Proof of the correctness of Algorithm 2
LTL formulas consider only propositional and temporal
operators; therefore, the time variables’ environment (ε) is not
aﬀected by Algorithm 2. Since time variables do not change
during Algorithm 2, we assume that Algorithm 2 considers

time constraints as /⊥ values since they are already evaluated
in Algorithm 1. In this section, we prove that the output of
Algorithm 2 corresponds to the correct evaluation of the LTL
subformula ϕ j at sample instance u based on Deﬁnition 4.

M[n, u] = 
Thus, M[m, u]∧M[n, u] =  iﬀ (ρ̂, u, ε) |= ϕm and (ρ̂, u, ε) |= ϕn
Therefore, M[m, u] ∧ M[n, u] =  iﬀ (ρ̂, u, ε) |= ϕm ∧ ϕn ≡ ϕ j
As a result M[ j, u] =  iﬀ (ρ̂, u, ε) |= ϕ j

In essence, we will prove M[ j, u] =  if (ρ̂, u, ε) |= ϕ j
and similarly M[ j, u] = ⊥ if (ρ̂, u, ε) |= ϕ j . For the proof of
Algorithm 2, we use induction:

Case 3: ϕ j ≡ ϕm ∨ ϕn :
Consider M[ j, u] ← M[m, u] ∨ M[n, u] (Algorithm 2, Line 6).
According to Deﬁnition 4: (ρ̂, u, ε) |= ϕm ∨ ϕn iﬀ (ρ̂, u, ε) |= ϕm
or (ρ̂, u, ε) |= ϕn
Based on IH: M[m, u] =  iﬀ (ρ̂, u, ε) |= ϕm and M[n, u] = 
iﬀ (ρ̂, u, ε) |= ϕn
We know that, M[m, u] ∨ M[n, u] =  iﬀ M[m, u] =  or
M[n, u] = 
Thus, M[m, u] ∨ M[n, u] =  iﬀ (ρ̂, u, ε) |= ϕm or (ρ̂, u, ε) |= ϕn
Therefore, M[m, u] ∨ M[n, u] =  iﬀ (ρ̂, u, ε) |= ϕm ∨ ϕn ≡ ϕ j
As a result M[ j, u] =  iﬀ (ρ̂, u, ε) |= ϕ j

Base: In Section IV, we mentioned that in Line 1 of
Algorithm 1 the corresponding values for atomic propositions
are stored in the monitoring table. In essence, for each a ∈ AP,
and for each time stamp τu , we save the following values in the
monitoring table entry M[aindex , u], where aindex is the index
of atomic proposition a in the monitoring table M|ϕ|×|ρ̂| :
1)
2)

M[aindex , u] ←  if a ∈ σu if (ρ̂, u, ε) |= a
M[aindex , u] ← ⊥ if a  σu if (ρ̂, u, ε) |= a

Since evaluation of predicates is independent of the time
variables’ environment (ε) the above cases are always satisﬁed
for all sample instances u and all environments ε. As a
result, every table entry corresponding to a predicate, correctly
reﬂects the satisfaction of the predicate with respect to the state
trace σ̂ and the environment ε. Similarly, the table entries for
constant Boolean values (/⊥) are trivially correct.
Induction Hypothesis: Algorithm 1 updates the values
of Table from right to left, i.e., for the samples with indexes
|ρ̂| − 1 down to 0. This is because we resolve temporal
operators looking into the future. Namely, if the Boolean
value in the next samples of time are resolved, then we can
resolve the Boolean evaluation for the current sample of time.
For the Induction Hypothesis, we assume the table entries for
the proper subformulas of ϕ j at the same or future samples
contain the correct /⊥, i.e, we assume that
∀ϕk ⊂ ϕ j , ∀v ≥ u, M[k, v] =  iﬀ (ρ̂, v, ε) |= ϕk
And also for the same subformula (ϕ j ), we assume the table
entries for all the future samples contain the correct /⊥
values as follows:
∀v > u, M[ j, v] =  iﬀ (ρ̂, v, ε) |= ϕ j
Induction Step: For the induction step we consider ﬁve
cases of ϕ j :
Case 1: ϕ j ≡ ¬ϕm :
Consider M[ j, u] ← ¬M[m, u] (Algorithm 2, Line 2).
According to Deﬁnition 4: (ρ̂, u, ε) |= ¬ϕm iﬀ (ρ̂, u, ε) |= ϕm
Based on IH: M[m, u] = ⊥ iﬀ (ρ̂, u, ε) |= ϕm iﬀ (based on Def.
4) (ρ̂, u, ε) |= ¬ϕm ≡ ϕ j
Therefore, M[ j, u] = ¬M[m, u] = ¬⊥ iﬀ (ρ̂, u, ε) |= ϕm iﬀ
(ρ̂, u, ε) |= ¬ϕm ≡ ϕ j
As a result M[ j, u] =  iﬀ (ρ̂, u, ε) |= ϕ j
Case 2: ϕ j ≡ ϕm ∧ ϕn :
Consider M[ j, u] ← M[m, u] ∧ M[n, u] (Algorithm 2, Line 4).
According to Deﬁnition 4: (ρ̂, u, ε) |= ϕm ∧ ϕn iﬀ (ρ̂, u, ε) |= ϕm
and (ρ̂, u, ε) |= ϕn
Based on IH: M[m, u] =  iﬀ (ρ̂, u, ε) |= ϕm and M[n, u] = 
iﬀ (ρ̂, u, ε) |= ϕn
We know that, M[m, u] ∧ M[n, u] =  iﬀ M[m, u] =  and

193

Case 4: ϕ j ≡ 	ϕm
Consider M[ j, u] ← M[m, u + 1] if u < |ρ̂| − 1 (Line 11) and
M[ j, u] ← ⊥ otherwise (Line 9 of Algorithm 2).
According to Deﬁnition 4 we have two cases:
Case 4.1) u < (|ρ̂| − 1):
(ρ̂, u, ε) |= 	ϕm iﬀ (ρ̂, u + 1, ε) |= ϕm
Based on IH: M[m, u + 1] =  iﬀ (ρ̂, u + 1, ε) |= ϕm iﬀ
(ρ̂, u, ε) |= 	ϕm ≡ ϕ j
As a result M[ j, u] = M[m, u + 1] =  iﬀ (ρ̂, u, ε) |= ϕ j
Case 4.2) u = |ρ̂| − 1:
by Deﬁnition 4, (ρ̂, u, ε) |= ⊥
Line 9 of Algorithm 2 similarly assigns M[ j, u] ← ⊥
Case 5: ϕ j ≡ ϕm Uϕn
According to [12], Until operation can be simpliﬁed according
to following equivalence relation:
φUψ ≡ ψ ∨ (φ ∧ 	(φUψ))
In other words, we need to consider current value of 	(φUψ)
(future value of φUψ at the next sample) and use the current
values of φ and ψ to resolve and evaluate φUψ at the current
sample using equation ψ∨(φ∧	(φUψ)). Algorithm 2 considers
two case for ϕ j ≡ ϕm Uϕn ≡ ϕn ∨ (ϕm ∧ 	(ϕm Uϕn )):
Case 5.1) u < (|ρ̂| − 1):
Now consider the update of M[ j, u] ← M[n, u] ∨ (M[m, u] ∧
M[ j, u + 1]) according to Line 17 of Algorithm 2.
Based on IH: M[n, u] =  iﬀ (ρ̂, u, ε) |= ϕn and M[m, u] = 
iﬀ (ρ̂, u, ε) |= ϕm and
M[ j, u + 1] =  iﬀ (ρ̂, u + 1, ε) |= ϕ j iﬀ (ρ̂, u, ε) |= 	ϕ j
According to Case 2 (Conjunction) M[m, u] ∧ M[ j, u + 1] = 
iﬀ (ρ̂, u, ε) |= ϕm and (ρ̂, u, ε) |= 	ϕ j
Therefore, M[m, u] ∧ M[ j, u + 1] =  iﬀ (ρ̂, u, ε) |= ϕm ∧ 	ϕ j
We know that, M[ j, u] =  iﬀ M[n, u] =  or M[m, u] ∧
M[ j, u + 1] = 
According to Case 3 (Disjunction) M[ j, u] =  iﬀ (ρ̂, u, ε) |= ϕn
or (ρ̂, u, ε) |= ϕm ∧ 	ϕ j
As a result, M[ j, u] =  iﬀ (ρ̂, u, ε) |= ϕn ∨ (ϕm ∧ 	ϕ j )
Case 5.2) u = |ρ̂| − 1:
According to Case 4.2 for Next operator: (ρ̂, u, ε) |= ⊥
This implies that ϕ j ≡ ϕn ∨ (ϕm ∧ ⊥) ≡ ϕn ∨ ⊥ ≡ ϕn
Now consider the update of M[ j, u] ← M[n, u] according to
Line 15 of Algorithm 2.
Based on IH: M[n, u] =  iﬀ (ρ̂, u, ε) |= ϕn
Therefore after the assignment, M[ j, u] =  iﬀ (ρ̂, u, ε) |= ϕ j

