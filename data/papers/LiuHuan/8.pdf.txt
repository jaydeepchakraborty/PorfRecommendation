See	discussions,	stats,	and	author	profiles	for	this	publication	at:	https://www.researchgate.net/publication/298797075

Medical	image	classification	using	spatial
adjacent	histogram	based	on	adaptive	local
binary	patterns
Article		in		Computers	in	Biology	and	Medicine	·	March	2016
DOI:	10.1016/j.compbiomed.2016.03.010

CITATION

READS

1

92

6	authors,	including:
Huiling	Chen
Wenzhou	University
67	PUBLICATIONS			765	CITATIONS			
SEE	PROFILE

All	content	following	this	page	was	uploaded	by	Huiling	Chen	on	22	April	2016.

The	user	has	requested	enhancement	of	the	downloaded	file.	All	in-text	references	underlined	in	blue	are	added	to	the	original	document
and	are	linked	to	publications	on	ResearchGate,	letting	you	access	and	read	them	immediately.

Computers in Biology and Medicine 72 (2016) 185–200

Contents lists available at ScienceDirect

Computers in Biology and Medicine
journal homepage: www.elsevier.com/locate/cbm

Medical image classiﬁcation using spatial adjacent histogram based on
adaptive local binary patterns
Dong Liu a,b, Shengsheng Wang a,b,n, Dezhi Huang a,b, Gang Deng c, Fantao Zeng a,b,
Huiling Chen d
a

Jilin University, College of Computer Science and Technology, Changchun 130012, China
Jilin University, Key Laboratory of Symbolic Computation and Knowledge Engineering of the Ministry of Education, Changchun 130012, China
c
Renmin Hospital of Wuhan University, Department of Neurosurgery, Wuhan 430060, China
d
College of Physics and Electronic Information Engineering, Wenzhou University, Wenzhou 325035, China
b

art ic l e i nf o

a b s t r a c t

Article history:
Received 2 September 2015
Received in revised form
16 March 2016
Accepted 16 March 2016

Medical image recognition is an important task in both computer vision and computational biology. In
the ﬁeld of medical image classiﬁcation, representing an image based on local binary patterns (LBP)
descriptor has become popular. However, most existing LBP-based methods encode the binary patterns
in a ﬁxed neighborhood radius and ignore the spatial relationships among local patterns. The ignoring of
the spatial relationships in the LBP will cause a poor performance in the process of capturing discriminative features for complex samples, such as medical images obtained by microscope. To address
this problem, in this paper we propose a novel method to improve local binary patterns by assigning an
adaptive neighborhood radius for each pixel. Based on these adaptive local binary patterns, we further
propose a spatial adjacent histogram strategy to encode the micro-structures for image representation.
An extensive set of evaluations are performed on four medical datasets which show that the proposed
method signiﬁcantly improves standard LBP and compares favorably with several other prevailing
approaches.
& 2016 Elsevier Ltd. All rights reserved.

keywords:
Local binary patterns
Image classiﬁcation
Feature extraction
Medical images
Microscope images

1. Introduction
Medical images have played an important role in the diagnostic
workup of patients. Automated classiﬁcation of medical images is
a desirable tool to assign the interpretation of images, and then
would help the expert in diagnosis of diseases [1–3]. Compared
with general image recognition, medical image recognition is
more challenging because of the higher ambiguity and complexity;
most of the medical image contents are quite similar, but also
different in their emphasis.
In terms of the features used for medical image recognition, it
can be mainly classiﬁed into three groups: shape, color, and texture features. For example, in [4], shape features such as moment
invariants and Fourier descriptor are employed to classify medical
X-ray images. A color vector ﬁeld is considered in [5] for improving
the performance of endoscopic image classiﬁcation.
The local binary patterns, ﬁrst proposed by [6], are widely
considered as a state-of-the-art image feature descriptor among
n
Corresponding author at: Jilin University, College of Computer Science and
Technology, Changchun 130012, China.
E-mail address: wss@jlu.edu.cn (S. Wang).

http://dx.doi.org/10.1016/j.compbiomed.2016.03.010
0010-4825/& 2016 Elsevier Ltd. All rights reserved.

texture descriptors, since it can more effectively describe texture
information. It has been successfully applied to many applications,
such as face recognition, texture classiﬁcation, scene recognition,
human detection and others. LBP has several attractive advantages: it has proven to be a powerful discriminator with low
computational cost, it is robust against changes in image intensity,
and it can be easily implemented. Due to these merits, it makes a
good choice for extracting ﬁne features for medical images.
However, the standard LBP still suffers from several drawbacks,
including limited semantic description of local patterns, sensitive
to non-uniform patterns and afﬁne transformation, and missing of
efﬁcient spatial encoding among patterns. To overcome these
shortcomings, numerous works [9–11] focused on improving LBP
in recent years, in terms of rotation-invariant, multi-scale, the
utilization of non-uniform patterns, and so on. There are two types
of LBP patterns: uniform and non-uniform patterns. Some works,
such as [7], only considered uniform patterns for extracting LBP
features since non-uniform patterns involve noise and high
dimensionality. And the work [8] proposed a hierarchical multiscale LBP to further utilize the information of non-uniform patterns. They also certify that, the percentage of non-uniform patterns increases as the neighborhood radius increases. To reduce
the LBP dimensionality, center-symmetric local binary patterns

186

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

(CSLBP) [15] is studied and applied to image recognition. Since LBP
is sensitive to noise in near uniform regions, Local Ternary Pattern
[14] with three value coding scheme was proposed to address this
problem. The rotation invariant [6] descriptor can be obtained
through the circular neighborhood deﬁnition, but in some cases
the anisotropic structural information is lost. To utilize these anisotropic structural information, a novel elliptical binary pattern
(EBP) [16] has been proposed for face recognition, in which elliptical neighborhood deﬁnitions are studied. Completed LBP [13]
utilizes both the sign and magnitude information in the difference
between the central pixel and the neighborhood pixels. In the
work [18], LBP is combined with Gabor ﬁlters to achieve a better
classiﬁcation performance. The study [19] extracted the most frequent patterns in LBP histogram and formed a novel descriptor,
which achieved better performance with this technique. Mesh-LBP
[21] is novel method which computed the mesh-local binary
pattern on a triangular-mesh manifold. In [22], a scale- and
rotation-invariant LBP is proposed, in which the rotation-invariant
is combined with a scale-adaptive texton for texture classiﬁcation.
SOALBP [23] constructed a novel scale- and orientation invariant
LBP feature combined in a multi-resolution representation, which
has been proven superior in texture classiﬁcation.
The basic idea behind LBP is that it describes an image by local
patterns. The existing methods have been proven to improve the
LBP to some extent by reconﬁguring or utilizing the patterns.
However, most of existing works encode the binary patterns in a
ﬁxed neighborhood radius. This ﬁxed neighborhood radius strategy is irrelevant to local image content and disregards microstructure information of the multi-scale patterns. Intuitively, the
micro-structures, i.e. the spatial relationships among local patterns
generated by adaptive radius, provide crucial feedback in disambiguating texture information especially for complex medical
images, i.e. microscope images that involve with pathological
changes. This subsequently leads to improved recognition performance. To this end, our target is to design a novel LBP histogram
representation for medical images to (1) compute the local binary
patterns in an adaptive neighborhood radius, and (2) encode
micro-structures among the multi-scale patterns. In the ﬁrst stage,
with the help of gradient operators, we obtain a gradient map
from each original image, and the adaptive LBP neighborhood
radius could be then determined for each pixel by utilizing the
gradient information. As a result, our adaptive strategy will assign
a relatively small radius to pixels that are located in local regions
with dramatic gray variation, while assigning a relatively large
radius to pixels that are located in local regions with slight gray
variation. This adaptive technique will provide the image with rich
micro-structure textures, which is discriminative in image representation. Then in the next stage, we propose a spatial adjacent
histogram based on adaptive LBP radius to describe these discriminative micro-structure features. Finally, the adaptive LBP

radius and spatial adjacent histogram strategies produce a much
more powerful LBP variant, which performs well in four benchmark medical datasets and compares favorably to other methods.
In this context, our contribution is threefold.
1) Using the adaptive strategy we proposed, the neighborhood
radius of LBP is determined based on local image content,
therefore more adaptive and useful features can be obtained.
2) We propose to use spatial adjacent histogram to encode the
micro-structures produced by adaptive strategy, which results
in convincing improvement on the standard LBP histogram.
3) Our approach also considers three LBP coding schemes, i.e. set
the threshold T in three different ways when computing the LBP
value. And we further evaluate the three LBP coding schemes in
order to ﬁnd which one performs more competitive in medical
image classiﬁcation.
The remainder of this paper is organized as follows. In Section
2, we introduce the proposed algorithm, i.e. spatial adjacent histogram based on adaptive local binary patterns for image classiﬁcation. Section 3 presents an extensive set of experimental evaluations on four medical image datasets, and ﬁnally, in Section 4,
we draw the conclusions.

2. Spatial adjacent histogram based on adaptive local binary
patterns for image classiﬁcation
In this section, we propose a novel idea using spatial adjacent
histogram based on adaptive local binary patterns for medical
image classiﬁcation. We ﬁrst present a concise review of standard
local binary patterns (LBP) in subsection 2.1. Next, we explain how
to determine the adaptive radius for each pixel in subsection 2.2,
then in subsection 2.3, three coding schemes are introduced to
compute the LBP value for each pixel. In subsection 2.4, we propose a spatial adjacent histogram technique based on adaptive LBP
to represent the whole image. Finally, the proposed image classiﬁcation framework using our spatial adjacent histogram based on
adaptive local binary patterns is presented in subsection 2.5.
2.1. Brief review of LBP
Given an image I, the LBP is a gray-scale texture operator that
characterizes the local spatial patterns of the image texture, which
is calculated at each pixel by evaluating the binary differences
between it and its neighbors:
(
PX
1
1; x Z 0
LBPðP; RÞ ¼
sðg i  TÞ2i ; sðxÞ ¼
ð1Þ
0; x o 0
i¼0

where P is the number of pixels in the neighborhood, R is the

Fig. 1. Three circularly symmetric neighborhood sets for different (P, R).

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

radius of the neighborhood and T is a threshold. The original LBP
set T as the gray value of the central pixel and gi is the gray value of
its neighborhood. Fig. 1 shows examples of different conﬁgurations of (P, R). A pattern is considered uniform if the number of
transitions in the sequence between 0 and 1 is less than or equal to
two. For instance, LBP pattern 00100000 is uniform (2 times
transition) and 00101000 is non-uniform (4 times transition).
2.2. Determining the adaptive radius R
In order to extract micro-structures of different scales, the key
idea behind this paper is to adaptively obtain the LBP radius of
each pixel by analyzing the differences based on calculated gradients. Given an image I and we use f(x,y) as the gray value of pixel
(x, y), then the Sobel [20] gradient magnitude g(x, y) can be
obtained by Eq. (2) and Eq. (3).
8
g ¼ ½ f ðx  1; y þ 1Þ þ2f ðx; y þ 1Þ þ f ðx þ 1; yþ 1Þ
>
>
> x
>
<  ½ f ðx  1; y  1Þ þ 2f ðx; y 1Þ þ f ðx þ 1; y  1Þ
ð2Þ
g y ¼ ½ f ðx þ1; y  1Þ þ 2f ðx þ 1; yÞ þ f ðx þ 1; y þ1Þ
>
>
>
>
:  ½ f ðx  1; y  1Þ þ 2f ðx  1; yÞ þ f ðx  1; y þ 1Þ
gðx; yÞ ¼

qﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
g x 2 þg y 2

ð3Þ

Then, given a center pixel gc and its neighborhood radius k, the
average gradients Gk ðx; yÞ in (2kþ 1)  (2kþ 1) image blocks is
deﬁned as follows:
xP
þk

Gk ðx; yÞ ¼

yP
þk

gði; jÞ

i ¼ xk j ¼ yk
2

ð2k þ 1Þ

; k A f1; 2; :::; Rmax g

ð4Þ

where Rmax is the maximal search radius.
Finally, the gray variation is deﬁned as the intensity difference
among the average gradients in different sizes of image blocks.
Thus, the neighborhood radius Rgc of the central pixel gc can be
obtained according to the maximum value:


Rgc ¼ arg max Gk þ 1  Gk ; k A f1; 2; :::; Rmax g
ð5Þ
k

An illustration of the proposed adaptive radius computing
process for a central point in a 7  7 blocks is provided in Fig. 2.
The input central point and its neighborhood of 7  7 blocks,
which are described as gradient magnitude, appears on the left
part of Fig. 2. Then the three scales of blocks and the average
gradients are deﬁned by Eq. (4). It is due to the fact that the most
dramatic change lies between G2 and G3, so the adaptive radius for
the central pixel is set as 2, which are presented in the right part of
Fig. 2. This means the outermost neighborhood pixels are not
considered based on our adaptive radius strategy, because they
adopt irrelevant gray value and may be harmful for the robustness.
Three toy examples of adaptive radius map are illustrated in
Fig. 3. In each example, the original image, adaptive radius map
and the percent of pixels with different radius are arranged from

187

left to right. In each adaptive radius map, four colors denote different LBP radii for each pixel, i.e. red denotes R ¼4, green denotes
R¼3, blue denotes R¼2 and black denotes R ¼1. The ﬁrst and
second original images in Fig. 3 are taken from the two different
categories (microtubules and endosome) of 2D HeLa dataset [28],
respectively, in which the pixels outside the objects are not considered since it represents the black background. It is observed
that Fig. 3(a) and Fig. 3(b) have much of different spatial distribution of adaptive radius, and the micro-structures produced by
neighbor adaptive radius are much discriminative for two images.
Another intuitive instance can be found in Fig. 3(c), in which the
original image is a scene image. Therefore, one could conclude that
the micro-structures of neighbor adaptive radius are much related
to image contents. Furthermore, we could discover that our
adaptive strategy assigned a relatively small radius to pixels that
are located in local regions with dramatic gray variation, while
assigning a relatively large radius to pixels that are located in local
regions with slight gray variation. In the rest of this paper, we will
show how to utilize these discriminative features coming from
micro-structures.
2.3. LBP coding schemes based on adaptive radius
In this subsection, we formulate the process of LBP coding
based on adaptive radius R. Given a center pixel gc, the neighborhood radius R can be computed by Eq. (5). Inspired by state-ofthe-art LBP coding strategy, three coding schemes are selected
based on setting different thresholds to T of Eq. (1) adaptively,
which are named T1, T2 and T3 for short, respectively. And LBPT1,
LBPT2 and LBPT3 denote standard LBPs obtained by the three
coding schemes, respectively.
We start with an original image I, let gc be a center pixel and gi
denotes its neighborhood pixel. P denotes the total number of the
neighbors, and R denotes the adaptive radius of gc obtained during
the process in subsection 2.2.
(1) The ﬁrst coding scheme T1
Set threshold T as the gray value of the central pixel, i.e. T1 ¼gc.
thus, the LBPT1 can be formulated as
LBPT 1 ¼

PX
1

sðg i  T 1 Þ2i

ð6Þ

i¼0

(2) The second coding scheme T2
Let mi ¼| gi  gc |, set T2 as the mean value of mi, i.e.
T2 ¼

PX
1
i¼0

mi =P ¼

PX
1

j g i  g c j =P

i¼0

Fig. 2. An example of proposed adaptive radius computing process for determining the radius.

ð7Þ

188

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

Fig. 3. Toy examples of adaptive radius map, i.e. different radius of each pixel: red denotes R ¼4, green denotes R ¼3, blue denotes R ¼2 and black denotes R¼ 1. (For
interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this article.)

Then we can deﬁne the third LBPT3 as follows

Then, the LBPT2 are presented as follows:
LBPT 2 ¼

PX
1
i¼0

sðmi  T 2 Þ2i ¼

PX
1



sðg i g c   T 2 Þ2i

ð8Þ

i¼0

Set T3 as the mean gray value of the (2Rþ1)  (2Rþ1) image
blocks, i.e.
N
X
i¼1

g i =N;

N ¼ ð2R þ 1Þ  ð2R þ 1Þ

PX
1

sðg i  T 3 Þ2i

ð10Þ

i¼0

(3) The third coding scheme T3

T3 ¼

LBPT 3 ¼

ð9Þ

Fig. 4 illustrates the coding process using different thresholds
for the 3  3 sample blocks. Note that the ﬁrst and second coding
schemes are equivalent to the standard LBP [6] and LDBP [12],
respectively. For visualization, LBP transformed the images by
replacing each pixel of the image with its LBP value, these are also
presented. Fig. 5 shows examples of LBP transformed images with
three coding schemes. From the examples, we can see that all
schemes retain the global structure of the image, but display much
diversity in capturing the local structures. In the next experiments,
we will evaluate performances of the three coding schemes based

Fig. 4. Coding process of the three thresholds. (Here R ¼1, P¼ 8).

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

189

Fig. 5. Example image and its LBP transformed images with three coding schemes.

on our proposed algorithm to explore which one is more competitive in medical image classiﬁcation.
2.4. Spatial adjacent histograms based on adaptive LBP
From the Fig. 3, one can see that adaptive radius map provides
the image with rich micro-structure textures. These microstructures reﬂect discriminative features and can be well represented by the approaches of histogram analysis. In this subsection,
we explain how to construct the spatial adjacent histogram for an
image when considering both micro-structures and adaptive
radius patterns.
As mentioned in subsection 2.2, each pixel of an image has
different neighborhood radius during our adaptive strategy, however, different conﬁgurations of (P, R) will result in LBPTi of each
pixel mapping to different dimension. In this paper, we set the
number of involved adaptive neighbors as 8, i.e. P ¼8, in a similar
fashion to [22]. Besides, our spatial adjacent histogram encoding
strategy will result in the ﬁnal feature vector with 2  Rmax  2p
dimensions. This means that increasing the values for P and Rmax
will make the feature dimension signiﬁcantly large, that will further increase the time complexity. Considering the trade-off
between description and performance, we set the maximal
search radius Rmax as 4. Moreover, increasing Rmax means that
more image pixels are involved to interpolate and form neighborhoods with ﬁxed number P¼ 8. This may bring more noise to
the interpolated neighborhoods. So we think it is appropriate to
set Rmax as 4.

Then, four histograms with 256 bins under four radii can be
extracted for each image:
X
hðiÞj Rk ¼
isequalðlbpðjÞ ¼ iÞ; i ¼ 1; :::; D; k ¼ 1; :::; 4
ð11Þ
j A Rk

where Rk indicates the set of pixels with radius R ¼k, and D
denotes the dimension of LBP histogram (here D is equal to 256).
The function lbp(j) returns the LBP value of pixels j, and the
function isequal(lbp(j)¼i) returns 1 if lbp(j)¼ i, else returns 0.
Then for image representation, an easy option is that we
directly concatenate (for short, we name this histogram construction strategy as DC strategy) the four histograms under the
different radii, then the concatenated histogram DCLBP is as follows.
DCLBP T i ¼ H T i ðR1 Þð þ ÞH T i ðR2 Þð þ ÞH T i ðR3 Þð þ ÞH T i ðR4 Þ; i A f1; 2; 3g

ð12Þ

where (þ )indicates the operation of concatenation, superscript Ti
denotes the three coding schemes we have selected. A brief
example is shown in Fig. 6(a).
Based on the preliminary experimental results, we found that
the pixels which have been assigned R ¼1 are sparse but discriminative. We propose to use R¼ 1 to calculate the spatial relation between them and pixels with larger radii for two reasons:
(1) As shown in Fig. 3, the pixels with R¼ 1 are mainly located in
the regions with dramatic changes in gray value. The pixels
with dramatic changes are also involved with ample microstructures of different scales, i.e. spatial correlation of neighbor pixels with different LBP radii. We do not choose pixels

Fig. 6. The two strategies of combining sub-histograms of pixels with different radii to represent the image. (a) the directly concatenate strategy; (b) the spatial adjacent
histograms strategy.

190

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

Table 1
The percentage of non-uniform patterns in medical datasets.

2D-Hela [28]
Hep-2 [29]
PAP [30]

R ¼ 1, P¼ 8 (%)

R¼ 2, P¼ 8 (%)

R¼ 3, P ¼8 (%)

R ¼4, P ¼8 (%)

27.84
10.96
13.82

38.24
18.78
18.58

44.21
21.86
22.06

45.13
26.89
24.82

with larger radii for constructing the spatial adjacent histogram, such as R¼ 4, since they are mainly located in regions
with relative smooth change in gray value. Intuitively, the
spatial correlation between pixels with dramatic changes and
its neighbor pixels provide crucial feedback in disambiguating
texture features.
(2) Using R ¼1 is helpful to incorporate uniform idea. It has been
validated that uniform patterns show superiority in texture
classiﬁcation and some non-uniform patterns involve noise
[7]. Uniform patterns are also considered as the major parts of
all patterns. Moreover, [8] certify that, the percentage of nonuniform patterns increases as the neighborhood radius
increases. Table 1 shows the percentage of non-uniform
patterns in three medical datasets and presents the same
conclusion with [8]. An appropriate way of incorporating
uniform idea and avoiding noise caused by some nonuniform patterns, in our case, is to choose pixels with R¼1
(that involve the most uniform patterns) as baseline to
construct the spatial adjacent histogram. Note that our goal

is not discarding the non-uniform local patterns, since some
non-uniform patterns also can provide much useful features.
And how to dig out the useful non-uniforms among all nonuniforms is another topic.
Therefore, instead of using original histograms of pixels with
R¼1, we propose to use spatial adjacent histogram strategy to
embed the micro-structures information to hðiÞj R1 . For each pixel
jA R1 of an image, we calculate not only the number of occurrences
of each LBP (j) in the image, but also the number hðiÞj ðR1 ; Rk Þ, that
is the number of pixels with radius Rk which appears next to pixel
j.
X
X
isequalðLBPðjÞ ¼ iÞ; k ¼ 1; 2; 3; 4
ð13Þ
hðiÞj ðR1 ; Rk Þ ¼
j A R1 ;w A Rk w A NðjÞ

Where N(j) is the four-neighbor system of j. Then the spatial
adjacent histogram (SAH) for pixels set with radius R¼ 1 can be
deﬁned as:
SAHðR1 Þ ¼ fhðiÞj R1 ; hðiÞj ðR1 ; R1 Þ; hðiÞj ðR1 ; R2 Þ; hðiÞj ðR1 ; R3 Þ;
hðiÞj ðR1 ; R4 Þg; i ¼ 1; :::; 256

ð14Þ

It is easy to ﬁnd that the dimension of h(i)|(R1,Rk) is 256,
resulting in that the dimension of SAH(R1) is 256 þ256*4 ¼1280.
Thus, the dimension of the histogram in Formula (14) is quintuple
larger than that in Formula (11).
A toy example of explaining how to count SAH(R1) is present in
Fig. 7, we design three image patches with 5  5 size, i.e. 25 pixels.
To simplify the visualization, note that, we assume that the pixels

Fig. 7. Histograms for representing the pixels set with radius R¼ 1.

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

with radius R¼1 only be assigned to four types of LBP values, i.e. A
to D (0 oA oB oC oD o255). Furthermore, each pixel has an
adaptive radius which is marked by different colors and textures,
i.e. yellow pixel with no texture denotes R ¼1, green pixel with
vertical texture denotes R¼ 2, blue pixel with crossed texture
denotes R¼3, and red pixel with horizontal texture denotes R¼4.
Then the corresponding histogram and feature vectors are shown
in Fig. 7. The four black bins with gradual change in each histogram denote the number of occurrences of A, B, C, and D, respectively. Note that the numbers of occurrences of A, B, C, and D are
the same in the three image patches, i.e. for all image patches: h
(A)|R1 ¼3, h(B)|R1 ¼2, h(C)|R1 ¼2 and h(D)|R1 ¼2. Following each
black bin with gradual change, there are four bins with different
textures which denote the number of four-neighbor pixels with
four different radii, i.e. h(A)|(R1,R1), h(A)|(R1,R2), h(A)|(R1,R3), and h
(A)|(R1,R4), respectively.
More speciﬁcally, looking at the image patches in Fig. 7(a), the
ﬁrst black bin with gradual change denotes the number of occurrences of A. Since there exist three yellow pixels with no texture
located in the four-neighbors of all type A, then h(A)|(R1,R1) ¼3,
drawn as the ﬁrst yellow bin with no texture. Note that if two fourneighbor pixels are marked as the same type, then we count it
only one time to update the histogram. For example, two pixels
marked with A in Fig. 7(a) are mutual four-neighbors, but we
count it only one time to update h(A)|(R1,R1). There is only one

191

green pixel with vertical texture located in the four-neighbors of
all type A, so h(A)|(R1,R2)¼1, drawn as the ﬁrst green bin with
vertical texture. There is also only one blue pixel with crossed
texture located in the four-neighbors of all type A, so h(A)|(R1,R3) ¼
1, drawn as the ﬁrst blue bin with crossed texture. And there are
four red pixels with horizontal texture located in the fourneighbors of all type A, so h(A)|(R1,R4) ¼4. It is similar for counting the other non-black bins, i.e. h(B)|(R1,R1), h(B)|(R1,R2), h(B)|(R1,
R3), h(B)|(R1,R4), h(C)|(R1,R1), h(C)|(R1,R2), h(C)|(R1,R3), h(C)|(R1,R4), h
(D)|(R1,R1), h(D)|(R1,R2), h(D)|(R1,R3) and h(D)|(R1,R4).
Comparing the three image patches in Fig. 7, using the original
LBP histogram model, the pixels set with radius R¼1 in three
image patches are represented as the same feature histogram
(3,2,2,2) as shown by the black bins in each histogram. But using
the histograms obtained by our spatial adjacent histogram (SAH)
strategy, these image patches can be effectively distinguished from
each other. This indicates that the micro-structure features have
been effectively utilized in SAH strategy, that had been ignored in
DC strategy.
As explained above, for an image, we can obtain four histograms, i.e. one histogram with 1280 dimensions to represent the
pixels set with radius R¼ 1 (see Eq. (14) ), and three histograms
with 256 dimensions to represent the pixels set with radii R¼ 2, 3,
4, respectively (see Eq. (11)). Then, the ﬁnal LBP feature vectors

Fig. 8. Example images and its spatial adjacent histograms (the third coding scheme T3 is employed here).

192

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

with our spatial adjacent histograms strategy can be computed as:
Ti

Ti

Ti

Ti

Ti

SAHLBP ¼ SAH ðR1 Þð þ ÞH ðR2 Þð þ ÞH ðR3 Þð þÞH ðR4 Þ; iA f1; 2; 3g
ð15Þ
where ( þ) indicates the operation of concatenation, superscript Ti
denotes the three coding schemes above. And the dimension of
SAHLBP is 1280 þ (256*3) ¼ 2048. Fig. 6 shows the comparison of
the directly concatenate strategy and the spatial adjacent histograms strategy to represent the images.
In order to present an intuitive example, Fig. 8 shows four
images and its SAHLBP histogram features. The ﬁrst two images
come from the ‘golgpp’ category of 2D HeLa dataset, while the last
two images come from the ‘nucleolus’ category of 2D HeLa dataset.
Though it may be a challenge to distinguish the two categories
with human vision, but the SAHLBP histogram features can provide
much discriminative information to distinguish the two different
types of patterns. Therefore, our SAHLBP method can be expected
to perform well in medical image classiﬁcation, we will give a
complete evaluation in next experiments.
2.5. The proposed image classiﬁcation framework
As illustrated in Fig. 9, the framework for medical image classiﬁcation consists of four steps, i.e. determining the adaptive LBP
radius for each pixel, computing the spatial adjacent histogram
based on adaptive LBP radius, representing the image based on the
spatial adjacent histograms, and training a SVM classiﬁer for
recognizing new samples. Furthermore, the ﬁrst three steps can be
considered as feature extraction for medical image, which is the
key idea of our proposal.

3. Experimental results
3.1. Experimental datasets
The medical datasets for the evaluation of the proposed
method are selected based on their variety and broadness of their

use. Experiments are performed on the following four reference
datasets.
3.1.1. The 2D HeLa dataset
This dataset [28] is composed of 862 single-cell images (16 bit
gray scale of size 512 by 382 pixels) from ten classes, i.e. Actin,
Nucleus, Endsome, ER, Golgi Giantin, Golgi GPP130, Lysosome,
Microtubules, Mitochondria, and Nucleolus. The description of the
dataset in terms of samples per class is presented in Table 2, and
some sample images from the ten categories are shown in Fig. 10.
In our experiments, the LBP based histogram bin with the highest
occurrence is discarded since it represents the black background.
3.1.2. Hep-2 cell dataset
Hep-2 cell dataset [29] consists of 28 slide images, and each
image contains several cells that are segmented by specialist. The
total number of cells is 1455, including training set with 721 cells
and testing set with 734 cells. And each cell has been assigned to
one of the six categories: centromere, homogeneous, nucleolar,
coarse speckled, ﬁne speckled, and cytoplasmatic. A summary of
the Hep-2 cell dataset in terms of number of training set, testing
set and classes is reported in Table 3. Some sample images are also
presented in Fig. 11.
3.1.3. PAP dataset
The PAP smear dataset [30] contains 917 samples collected at
the Herlev University Hospital using a digital camera and microscope. As shown in Table 4, the samples belong to seven different
classes. And two skilled cyto-technicians further classiﬁed each
sample into two super classes (normal and abnormal). The sample
images that came from the two super classes are shown in Fig. 12.
3.1.4. The brain tumor dataset
The brain tumor dataset used throughout this experiment
consists of 285 images of size 256*256, which was collected at the
department of neurosurgery in Renmin Hospital of Wuhan University, P.R China. All samples are derived from real pathological
images and 19 patients who suffer different types of brain tumor

Fig. 9. Overview of the proposed image classiﬁcation framework.

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

Table 2
A summary of the 2D HeLa dataset: classes
and number of samples per class.
Class
Actin
Nucleus
Endsome
ER
Golgi Giantin
Golgi GPP130
Lysosome
Microtubules
Mitochondria
Nucleolus
Total

193

Table 3
A summary of the Hep-2 cell dataset: classes and number of samples per class.
Class

Training set

Testing set

Number of each class

Centromere
Homogeneous
Nucleolar
Coarse speckled
Fine speckled
Cytoplasmatic

208
150
102
109
94
58

149
180
139
101
114
51

357
330
241
210
208
109

Total

721

734

1455

Number
98
87
91
86
87
85
84
91
73
80
862

are involved. In pathological analysis, the high resolution microscopy (Olympus BX51) was used to perform on the tumor lesion in
order to get a histopathological diagnosis. Then ﬁve categories of
microscopic images could be obtained according to the ﬁve types
of brain tumor, i.e. astrocytoma, tuberculum sellae meningioma,
olfactory groove meningioma, acoustic neuroma and pituitary
tumor. Table 5 reports the number in each class and Fig. 13 depicts
the microscopic images from each category.
Note that the original images in Hep-2 cell, PAP and brain
tumor datasets are color images. In this study, the LBP variants and
SIFT descriptors are extracted from the grayscale version of the
corresponding images. The grayscale values are transformed by a
weighted sum of R (red), G (green), B (blue) channels, i.e. Gray ¼
0.2990 * R þ0.5870 * G þ0.1140 * B.
3.2. Experimental setup and implementation
We implement the experiments in an iterated random
splitting-scheme (consistent among all methods) for training and
testing. Each dataset is randomly divided into 80% for training and
20% for testing. We use the training-split to optimize the SVM
parameters and train model in a 5-fold cross validation. And then
the trained model is employed for the test-split. The random
splitting is repeated 30 times. For performance quantiﬁcation, the

average mean classiﬁcation accuracy over 30 times iterations with
its standard deviation is reported. In order to use this evaluation
protocol consistently in all datasets, we merge the training and
testing set for Hep-2 cell dataset, as shown in Table 3.
Since different classes may have different numbers of samples,
we use stratiﬁed cross validation instead of standard cross validation to handle this imbalance of image numbers among classes.
In stratiﬁed cross validation, the distribution of samples among
classes in each subset is basically consistent with that in original
dataset.
For the classiﬁer, we employ the SVM with linear kernel in the
next experiment. For the implementation of the SVM classiﬁer, the
public LIBSVM library [31] is employed.
3.3. Evaluation of our methods
In this section, we report our experimental results using the
methods and dataset with performance indicators described in
previous sections. Evaluation of the proposed model is accomplished through two different tasks: (1) evaluate the performance
of three different coding schemes for medical image datasets;
(2) verify that the spatial adjacent histograms is effective to
increase the classiﬁcation accuracy based on our adaptive radius
strategy.
For the ﬁrst task, we report on the classiﬁcation accuracy of
standard LBP with three scales (R ¼1, P ¼8), (R ¼2, P ¼8), and
(R¼ 2, P ¼16) and our method that adopted three coding schemes
respectively, i.e. LBPT1(R ¼ 1, P ¼ 8), LBPT2(R ¼ 1, P ¼ 8), LBPT3(R ¼ 1, P ¼ 8),

Fig. 10. Ten type of 2D-Hela images.

194

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

Fig. 11. Six type of Hep-2 cell image: homogeneous, centromere, nucleolar, ﬁne speckled, coarse speckled and cytoplasmatic.
Table 4
A summary of the PAP smear dataset: classes and number of samples per class.
Class

Pap dataset Super classes Total

Superﬁcial squamous epithelial
Intermediate squamous epithelial
Columnar epithelial
Mild squamous non-keratinizing dysplasia
Moderate squamous non-keratinizing
dysplasia
Severe squamous non-keratinizing
dysplasia
Squamous cell carcinoma in situ
intermediate

74
70
98
182
146

Normal
Normal
Normal
Abnormal
Abnormal

197

Abnormal

150

Abnormal

(2)

242

675

LBPT1(R ¼ 2, P ¼ 8), LBPT2(R ¼ 2, P ¼ 8), LBPT3(R ¼ 2, P ¼ 8), LBPT1(R ¼ 2, P ¼ 16),
LBPT2(R ¼ 2, P ¼ 16), LBPT3(R ¼ 2, P ¼ 16), SAHLBPT1, SAHLBPT2 and
SAHLBPT3, as shown in Table 6. In each table, the best results in
each dataset are bolded.
For the second task, we compare the methods generated by
spatial adjacent histograms (SAH) strategy and directly concatenate (DC) strategy under the three coding schemes, respectively, i.e. DCLBPT1 and SAHLBPT1, DCLBPT2 and SAHLBPT2, DCLBPT3
and SAHLBPT3. The results are also reported in Table 6.
Examining the Table 6, we can make the following conclusions:
(1) Our SAHLBP models consistently outperform standard LBP
with (R¼ 1, P ¼8) and (R¼ 2, P¼ 8) on the four medical datasets, no matter which coding schemes that are employed. Our
SAHLBP models also outperform standard LBP with R ¼2, P ¼16
in all cases except that perform on PAP dataset with T2, i.e.
only SAHLBPT2 is inferior to LBPT2(R ¼ 2, P ¼ 16) on PAP dataset.
Moreover, the dimension of our method (i.e. 2048 dimensions) is much smaller than that of LBPT(R ¼ 2, P ¼ 16) (i.e. 65536
dimensions). This is probably because standard LBPs cannot
capture spatial relationships among local textures, while our
SAHLBP models describe micro-structures obtained by

(3)

(4)

(5)

adaptive radius and perform successfully well in capturing
the valuable structural information, which is beneﬁcial to
medical image classiﬁcation.
The models with the third coding scheme T3 achieved higher
accuracy, on the average, than that with the ﬁrst and second
coding schemes. More speciﬁcally, for the standard LBP with
R¼1and P ¼8, the ﬁrst coding scheme T1 gained the best
performance in the 2D-Hela and Tumor datasets, while T3
gained the best performance in the PAP smear and Hep-2 cell
datasets. For the standard LBP with R¼2 and P ¼16, T1 gained
the best performance in the 2D-Hela dataset and T3 proves
superior in the remaining datasets. For SAHLBPs, the T3
performed better than the other coding schemes in the PAP
smear, 2D-Hela and Tumor datasets, while the T1 achieved the
best performance in the Hep-2 cell datasets.
Particularly interesting are the results of the methods with the
second coding scheme T2, performs slightly worse than the
other two schemes in most of the cases. However, the coding
scheme T2 has been proven in [12] that it describes the global
structure successfully and has a good performance in natural
scene image classiﬁcation. From this observation, we can
appreciate that the micro-structure features also remain very
relevant to coding scheme.
LBPTi with (R ¼2, P ¼16) performs better than DCLBPTi. We
conjecture that it is because the LBPTi with (R ¼2, P ¼16)
captures more texture information with very large feature
dimension (i.e. 65536 dimensions), while the feature dimension of DCLBPT is 1024. However, the DCLBPTi achieves higher
accuracies than LBPTi with both (R¼1, P ¼8) and (R¼ 2, P ¼8)
in most cases. The comparison between the DCLBPTi and LBPTi
suggests that the adaptive radius is not very suitable to combine with directly concatenate strategy. We mainly compare
the DCLBPTi with SAHLBPTi to show the superiority of adaptive
radius combined with spatial adjacent histogram.
Our spatial adjacent histogram (SAH) based on adaptive radius
is better than directly concatenate strategy for all datasets, no

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

195

Fig. 12. Sample images from the pap smear dataset.
Table 5
A summary of the brain tumor dataset: classes and number of
samples per class.
Class
Astrocytoma
Tuberculum sellae meningioma
Olfactory groove meningioma
Acoustic neuroma
Pituitary tumor
Total

Number
58
54
54
56
63
285

matter which coding schemes T adopted, i.e. SAHLBPTi is
always better than DCLBPTi. Therefore, one can conclude that
SAH is highly suitable for representing the micro-structures
which is discriminative in medical image classiﬁcation.
To provide more robust results, we further perform the Wilcoxon ranksum test in combination with the iterated splitting
scheme to compare the methods. More speciﬁcally, for each
method in Table 6, we can obtain 30 classiﬁcation results during
30 times splitting iterations for each dataset. Then for a pair of
compared methods, we perform Wilcoxon ranksum test with their
30 classiﬁcation results over one speciﬁc dataset.

Fig. 13. Microscope images for different types of brain tumor lesion. (a) astrocytoma; (b) tuberculum sellae meningioma; (c) olfactory groove meningioma; (d) acoustic
neuroma; (e) pituitary tumor.

196

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

Table 6
Classiﬁcation accuracy of each method over four datasets.
Methods

LBPT1(R ¼ 1, P ¼ 8)
LBPT2(R ¼ 1, P ¼ 8)
LBPT3(R ¼ 1, P ¼ 8)
LBPT1(R ¼ 2, P ¼ 8)
LBPT2(R ¼ 2, P ¼ 8)
LBPT3(R ¼ 2, P ¼ 8)
LBPT1(R ¼ 2, P ¼ 16)
LBPT2(R ¼ 2, P ¼ 16)
LBPT3(R ¼ 2, P ¼ 16)
DCLBPT1
DCLBPT2
DCLBPT3
SAHLBPT1
SAHLBPT2
SAHLBPT3

Table 7
Classiﬁcation accuracy of compared methods over four datasets.

Datasets
PAP

2D-Hela

Hep-2

Tumor

81.127 2.3
80.92 7 1.7
81.877 1.5
80.34 7 2.5
79.767 2.5
82.78 7 2.3
85.477 2.2
84.56 7 2.0
85.56 7 1.9
83.96 7 1.9
82.147 1.9
83.29 7 1.9
86.69 7 2.1
84.03 7 2.1
88.03 7 1.7

85.247 2.4
83.23 7 1.9
84.317 2.1
86.077 2.5
82.59 7 1.8
85.39 7 2.2
87.327 2.2
86.23 7 1.9
86.767 2.1
84.96 7 1.4
85.34 7 1.4
87.847 2.2
89.687 2.0
87.29 7 1.6
90.06 7 1.5

75.65 7 1.1
72.177 1.2
79.947 1.6
82.147 1.4
76.23 7 1.5
80.23 7 1.1
87.677 1.4
85.23 7 1.0
87.927 1.2
81.317 0.8
76.39 7 1.0
82.227 1.1
91.897 0.8
88.95 7 0.8
91.86 7 0.9

75.417 1.8
74.45 7 1.7
75.22 7 1.8
75.047 2.1
73.62 7 2.1
73.78 7 2.1
79.177 1.6
78.82 7 1.9
79.25 7 2.0
77.69 7 1.9
75.22 7 1.8
78.137 1.5
82.917 1.6
81.247 2.1
84.487 1.8

More speciﬁcally, for 2D-HeLa dataset, we have compared the
following approaches using the Wilcoxon ranksum test:
1. SAHLBPTi versus LBPTi (i¼1, 2, 3) with different scales, SAHLBPTi
wins against LBPTi with all scales (R ¼1, P ¼8), (R¼ 2, P ¼8), and
(R¼2, P ¼16), i.e. we reject the null hypothesis at the level of
signiﬁcance 0.05, and accept that SAHLBPTi and LBPTi have signiﬁcant different performance.
2. SAHLBPTi versus DCLBPTi (i¼1, 2, 3), SAHLBPTi wins against
DCLBPTi.
3. SAHLBPT3 versus SAHLBPTi (i¼ 1, 2), SAHLBPT3 wins against
SAHLBPT2, however, SAHLBPT3 and SAHLBPT1 have no signiﬁcant
different performance in 2D-HeLa dataset.
We also do the same Wilcoxon ranksum test for the other three
datasets, and most of the conclusions remain valid. Very few different conclusions are marked as the following: (1) For PAP and
brain tumor datasets, SAHLBPT3 wins against both SAHLBPT1 and
SAHLBPT2. (2) For PAP dataset, SAHLBPT2 and LBPT2(with R ¼2,
P ¼16) have no signiﬁcant different performance. The p-values for
all tests are presented in Appendix A.
Finally, we analyze the confusion matrices for SAHLBPT3 which
display the best results selected from the 30 times iterations for
each dataset. The confusion matrices for the three multiclass
datasets, i.e. 2D-HeLa, Hep-2 cell, and brain tumor datasets, are
presented in Appendix A. From the results, we can conﬁrm that
our method is very useful for some particular patterns, such as
actin, dna, golgia, golgpp, nucleolus patterns in 2D-Hela dataset
and nucleolar pattern in Hep-2 cell dataset.
From the analysis of the above experimental results, it is clear
the advantage of our spatial adjacent histogram strategy employed
the third coding scheme T3, i.e. the SAHLBPT3. Hence, to achieve a
tradeoff between description and performance, we have chosen
the SAHLBPT3 in the remainder of the experiments.
3.4. Comparison of the LBP-based methods
The tests in this subsection are aimed at comparing our method
with the recent LBP variants reported in the literature. In particular, the following methods are evaluated which are often used
for medical image classiﬁcation:
1) LBP-r [6], the standard LBP with rotation invariant;
2) EBP [24], the elliptical binary pattern variant;
3) LBPsu2[22], scale-adaptive and subuniform-based rotation
invariant LBP;

Methods

PAP

2D-Hela

Hep-2

Tumor

LBP-r
ELBP
LBPsu2
LBPnr
LBP-HF
LDBP
CLBP
CoALBP

75.5 7 1.2
80.02 7 1.5
82.42 7 1.3
83.147 1.8
84.137 1.5
81.26 7 1.7
87.217 1.4
87.02 7 1.9

81.21 71.9
85.11 71.7
84.82 71.5
85.76 72.1
85.14 72.0
82.5 71.9
88.91 71.1
87.72 72.1

75.23 7 0.9
80.177 1.1
83.23 7 0.6
82.767 1.3
87.23 7 1.0
79.58 7 0.7
87.917 0.9
92.767 1.1

73.717 1.4
75.82 7 1.5
76.727 0.6
78.29 7 2.0
77.75 7 1.7
75.117 2.0
81.127 1.8
81.337 1.9

SAHLBPT3

88.037 1.7

90.06 71.5

91.86 7 0.9

84.487 1.8

4) LBPnr[22], scale-adaptive LBP without rotation invariant, that
employs the LBPsu2 approach by using non-rotation invariant
instead of rotation invariant.
5) LBP-HF[25], local binary pattern histogram Fourier features;
6) LDBP[12], the local difference magnitude binary pattern variant;
7) CLBP[26], in which three types of features are combined to form
the completed LBP features;
8) CoALBP [27], in which the co-occurrence among adjacent LBPs
has been considered. The effectiveness of CoALBP for medical
images can be conﬁrmed since it won the ﬁrst prize in the 2012
HEP-2 cells classiﬁcation contest.
In Table 7, we report the classiﬁcation accuracies using the
datasets and the compared methods described above. In each
table, the best result in each datasets is bolded.
From Table 7, we can make the following ﬁndings.
First, SAHLBPT3 is one of the best variants proposed in this
work. It achieves, on average, a better result than the compared
methods. Also, SAHLBPT3 achieves the highest accuracy in PAP, 2DHela, and Brain tumor datasets. We conjecture that it is because
our method enhanced its performance by exploiting the spatial
information of the adaptive radius with different scales, which
produced more discriminative features for medical images.
Second, CoALBP works better than SAHLBPT3 in Hep-2 cell
dataset, and SAHLBPT3 outperforms the CoALBP for the other three
datasets. However, our SAHLBPT3 has one advantage over the
CoALBP: its feature dimension is much smaller. The experimental
feature sizes of SAHLBPT3 and CoALBP are 2048 and 3072,
respectively.
Finally, SAHLBPT3 works much better than the methods with
rotation invariant, such as LBP-r and LBPsu2, even though the
rotation invariant features are not involved in our methods.
However, the rotation invariant contains additional discriminative
information. How to utilize this rotation invariant feature based on
our adaptive strategy will be explored in our future research.
From Table 7, it can be observed that CLBP, CoALBP, and
SAHLBPT3 achieve similar classiﬁcation accuracies. To provide
another basis for comparison of the three methods, we have also
reported the macro-averaged F1-scores as shown in Table 8. Note
that the reported classiﬁcation accuracy in Table 7 is deﬁned as the
number of samples correctly classiﬁed divided by the total number
of samples in the test set. It is equivalent to the micro-averaged F1
score in the single-label classiﬁcation task. Comparing the results
Table 8
Macro-averaged F1 scores of the three compared methods over four datasets.
Methods

PAP

2D-Hela

Hep-2

Tumor

CLBP
CoALBP
SAHLBPT3

82.87 72.1
81.45 71.9
84.23 71.9

87.127 1.9
86.23 7 1.7
88.767 1.5

86.417 1.5
91.897 1.7
91.29 7 1.5

78.65 7 2.1
79.23 7 2.0
83.817 1.9

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

Table 9
Statistical signiﬁcance of differences in classiﬁcation accuracies for different
methods.
Datasets

Compared methods

PAP

SAHLBPT3
SAHLBPT3
SAHLBPT3
SAHLBPT3
SAHLBPT3
SAHLBPT3
SAHLBPT3
SAHLBPT3

2D-Hela
Hep-2
Tumor

vs.
vs.
vs.
vs.
vs.
vs.
vs.
vs.

CLBP
CoALBP
CLBP
CoALBP
CLBP
CoALBP
CLBP
CoALBP

p-values

Corrected α

Result

0.1435
0.0122
0.0028
o 0.0001
o 0.0001
0.1723
o 0.0001
o 0.0001

0.00625
0.00625
0.00625
0.00625
0.00625
0.00625
0.00625
0.00625

NS
NS
*
*
*
NS
*
*

197

the computational time for feature extraction (for a single image),
training and testing on 2D-Hela dataset, as shown in Table 10. The
results show that SAHLBPT3 is slower than standard LBP (with both
R¼1, P ¼8 and R¼2, P ¼16) and CoALBP, which is caused by the
increased time demand time for searching the adaptive radius and
computing spatial adjacent histogram. It is worth stating that, in
training and testing stage, our method is faster than LBP (with
R¼2, P ¼16) and CoALBP. This is because the feature dimension of
our method (i.e. 2048 dimensions) is shorter than LBP(R ¼ 2, P ¼ 16)
(i.e. 65536 dimensions) and CoALBP (i.e. 3072 dimensions). Based
on consideration of both time and performance, we infer that
SAHLBPT3 is suitable for medical image classiﬁcation.

Fig. 14. Classiﬁcation accuracies of our method on four database for different SVM kernels.

of Table 7 and Table 8, we can ﬁnd out that the micro- and macroaveraged results do not differ signiﬁcantly and the previous ﬁndings based on accuracy would not change considering the macroaveraged F1-score.
In order to further perform statistical analysis for comparing
our SAHLBPT3 with the other two representative methods, i.e.
CLBP and CoALBP, we employ Wilcoxon ranksum test and the
Bonferroni method [36] for multiple pair-wise comparisons. In this
case, the level of signiﬁcance has been corrected as α ¼0.05/
8 ¼0.00625 according to the Bonferroni method. The signiﬁcant pvalues and corrected α are reported in Table 9, where * denotes
that the two methods have signiﬁcant different performance and
NS denotes that the two methods have no signiﬁcant different
performance.
In summary, we can conclude that our method is indeed a
superior algorithm with a clear motivation, convincing improvements, and an easy implementation. The advantage of our method
with respect to other variants makes it a good choice for medical
image classiﬁcation.
3.5. Runtime performance analysis
To study the computational demand of the proposed method,
we analyze the required time of our model and some representative methods. The MATLAB R2014a are employed, running on
an Intel i5-2400 processor at 3.1 GHz with 4 GB RAM. We report
Table 10
Computation time for feature extraction (single image), training and testing on 2DHela dataset.
Methods

Feature extraction

Training

Testing

LBP(R ¼ 1, P ¼ 8)
LBP(R ¼ 2, P ¼ 16)
CoALBP
SAHLBPT3

0. 103 s
0.197 s
0.562 s
0.823 s

1.423 s
814.27 s
12.37 s
6.553 s

0.056 s
44.305 s
0.798 s
0.493 s

Furthermore, The computational time for feature extraction
mainly depends on the descriptor and the image size, while the
training and testing are mainly dependant on the classiﬁer, feature
dimension and the scale of the dataset. Our method has took
0.823 s in the feature extraction stage per image with 512  382
size and 6.553 s in the training stage for 862 samples with 3072
feature dimensions. We think that our computational demand is
an adequate trade-off. Viewed from this perspective, we believe
our method can be extended to large-scale datasets. Due to the
limitations of the scale of medical image datasets, we will evaluate
our method on more general datasets with larger scale in our
future research.
3.6. Inﬂuence of different SVM kernels
Since the choice of the SVM kernel may have an impact on the
classiﬁcation rates, we also conducted an experiment by using
several SVM kernels. Though abundantly new kernels have been
proposed, the most frequently used kernel functions [32,33] in
image classiﬁcation are linear, polynomial, Radial Basis Function
(RBF), and histogram intersection (HI) kernels [34], formulated as
in Eq.(16)–Eq.(19), respectively.
ð1Þ

Linear : Kðxi ; xj Þ ¼ xi T xj

ð16Þ

ð2Þ

Polynomial : Kðxi ; xj Þ ¼ ðγ xi T xj þ rÞd ; γ 4 0

ð17Þ

ð3Þ

Radial basis functionðRBF Þ

: Kðxi ; xj Þ ¼ expð  γ ‖xi xj ‖2 Þ; γ 4 0
ð4Þ

Histogram intersectionðHI Þ : Kðxi ; xj Þ ¼

ð18Þ
n
X

minðxi ; xj Þ

ð19Þ

i¼1

Here, γ , r, and d are kernel parameters.
In our test, the default parameter values are used for different
kernels. Fig. 14 shows the average classiﬁcation accuracies we
achieved with different kernels on the four datasets. Note that we

198

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

Table 11
Classiﬁcation accuracy of compared descriptors in dense BoVW framework over
four datasets.
PAP
BoVW
framework

Proposed
framework

SIFT
LBP
SAHLBPT3
SIFT þ
SAHLBPT3
SAHLBPT3

2D-Hela

Hep-2

Tumor

84.03 72.3 83.79 7 2.5 80.88 71.5 78.23 7 1.7
81.43 72.1 81.477 2.1 77.52 71.9 75.217 2.1
86.21 72.0 84.89 7 2.2 85.06 72.0 81.45 7 1.7
87.63 72.1 86.217 2.5 83.47 71.8 83.34 7 1.9
88.03 71.7 90.06 7 1.5

datasets

Compared methods

p-values

Corrected α

Result

PAP

SAHLBPT3 vs. SIFT
SAHLBPT3 vs. LBP
SIFT þ SAHLBPT3 vs.
SAHLBPT3 vs. SIFT
SAHLBPT3 vs. LBP
SIFT þ SAHLBPT3 vs.
SAHLBPT3 vs. SIFT
SAHLBPT3 vs. LBP
SIFT þ SAHLBPT3 vs.
SAHLBPT3 vs. SIFT
SAHLBPT3 vs. LBP
SIFT þ SAHLBPT3 vs.

0.0031
o 0.0001
0.0053
0.0079
o 0.0001
0.0370
o 0.0001
o 0.0001
0.0208
o 0.0001
o 0.0001
0.0013

0.00417
0.00417
0.00417
0.00417
0.00417
0. 00417
0.00417
0.00417
0.00417
0.00417
0.00417
0.00417

*
*
NS
NS
*
NS
*
*
NS
*
*
*

2D-Hela

91.86 70.9 84.487 1.8
Hep-2

Table 12
Macro-averaged F1 score of compared descriptors in dense BoVW framework over
four datasets.
PAP
BoVW
framework

Table 13
Statistical signiﬁcance of differences in classiﬁcation accuracies for different local
descriptors in BoVW model.

SIFT
LBP
SAHLBPT3
SIFT þ
SAHLBPT3

2D-Hela

Hep-2

Tumor

SAHLBPT3

SAHLBPT3

SAHLBPT3

SAHLBPT3

Tumor

77.97 7 2.5 82.29 7 2.4 79.767 1.8 77.077 1.9
73.17 7 2.5 80.137 2.1 76.197 1.7 74.017 2.1
81.58 7 2.4 83.75 7 2.0 84.057 1.9 80.137 1.7
83.27 7 2.4 85.357 2.3 82.317 2.1 82.417 1.9

have not optimized SVM kernel parameters in Fig. 14. Particularly
noteworthy, in our case is that, the parameter optimization performed for SVM with RBF kernel is time-consuming, while the
parameter optimization performed for SVM with linear kernel has
a little inﬂuence on classiﬁcation performance. This means the
classiﬁcation result of our method has little change if we set different cost factor for SVM with linear kernel. This may be due to
the fact that the feature vectors of our method are rather sparse
with high dimensionality. Based on the average results on four
datasets, linear SVM kernels should be preferred in this case, since
computation time in this case varies linearly with the size of the
training data.
3.7. Evaluating the performance of the SAHLBPT in BoVW framework
In this section, for the sake of completeness, we further test the
performance of our texture descriptor within the bag of visual
words (BoVW) framework. The BoVW model is one of the most
popular algorithms for image representation by using visual words
formed by vector-quantizing local features with a clustering
method (such as K-means). The standard LBP and our SAHLBPT3
method can also be used as local texture descriptors for BoVW. In
the experiment, we use dense sampling strategy for the BoVW
model. More speciﬁcally, the local features are extracted from
16  16 image patches on a regular grid spaced at 8 pixels for all
images. Since the SIFT descriptor is probably the most widely used
descriptor for describing the local patches in BoVW model, we
mainly compare our method with dense SIFT descriptor. For dense
SIFT descriptor, the two parameters patch size and grid spacing are
set as 16 and 8, respectively, to allow for dense sampling. Moreover, the spatial pyramid matching (SPM) [37] settling is employed
for SIFT descriptor. The SPM is calculated at three levels. At the
ﬁrst level, the original image is considered as a sub-region. At the
second and the third level, the original image is divided into 2  2
and 4  4 sub-regions, respectively. Then all BoVW histograms of
21 sub-regions are concatenated to form the SPM representation
of the image. Additionally, single feature may fail to capture the
rich information within local image patches, as such, it is reasonable to extract multiple features for compensation. Therefore, we
also use multiple features that consist of SIFT and SAHLBPT3 to
describe local patches and then apply it to construct the visual
vocabulary (named SIFT þ SAHLBPT3 for short).

The classiﬁcation accuracies and the macro-averaged F1 scores
for different local descriptors used in BoVW model are reported in
Table 11 and Table 12, respectively. Here the visual vocabulary size
is 200 for all methods.
To perform statistical analysis, we also compare the SAHLBPT3
with SIFT, LBP and SIFTþSAHLBPT3 within BoVW framework tested by Wilcoxon ranksum test, the test protocol is the same as that
in subsection 3.4. In this test, the level of signiﬁcance has been
corrected as α ¼ 0.05/12 ¼0.00417 according to the Bonferroni
method. The p-values and corrected α are reported in Table 13,
where * denotes that the two methods have signiﬁcant different
performance and NS denotes that the two methods have no signiﬁcant different performance.
From Table 11, Table 12 and Table 13, we can make the following conclusions.
(1) From Table 11 and Table 12, it can be observed that the
SAHLBPT3 consistently outperforms both SIFT and LBP on the
four datasets when they are applied to BoVW framework.
However, the LBP is slightly weaker than SIFT as local
descriptors in BoVW model. Looking at the signiﬁcance of
differences in Table 13, we can ﬁnd out that the improvements
of SAHLBPT3 over LBP are signiﬁcant on the four datasets.
Moreover, SAHLBPT3 and SIFT have signiﬁcant different performance in PAP, Hep-2 cell and Tumor datasets.
(2) The BoVW model using the multiple features, i.e. SIFT þ
SAHLBPT3, excels that using a single feature on PAP, 2D-Hela,
and Tumor datasets based on the accuracy and the macroaveraged F1 score. However, the SAHLBPT3 works better than
SIFTþ SAHLBPT3 on Hep-2 cell dataset, which means that SIFT
and SAHLBPT3 descriptors do not provide very useful compensation for Hep-2 cell dataset. Looking at Table 13, SIFTþ
SAHLBPT3 and SAHLBPT3 have signiﬁcant different performance in Tumor datasets, but they have no signiﬁcant different performance in PAP, 2D-Hela and Hep-2 cell datasets. This
means that SIFT and our SAHLBPT3 are complementary features for Tumor datasets in BoVW model.
(3) To discuss, we return to the classiﬁcation performance of the
SAHLBPT3 in our framework and also re-record the results in
Table 7. We can easily ﬁnd that SAHLBPT3 in our framework
achieves better classiﬁcation results than that in the BoVW
framework. This is because our SAHLBPT3 aims to describe the
micro-structures of the whole image and these microstructures tend to play the largest role with a globally
encoding mode. Encoding the micro-structures in local image
patches would slightly decrease the performance of SAHLBPT3.
Moreover, the run-time for clustering in BoVW framework is
time-consuming. Based on both the classiﬁcation result and

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

199

Fig. 15. Comparison of classiﬁcation accuracies on 2D-Hela datasets using different
vocabulary sizes for BoVW model.
Fig. 16. Confusion matrices of the proposed method for 2D-HeLa dataset. C1:actin;
C2:dna; C3:endosome; C4: er; C5:golgia; C6:golgpp; C7:lysosome; C8:mircrotubules; C9:mitochondiria; C10: nucleolus.

Table 14
P-values of statistical tests for compared methods on four datasets.
Compared methods
SAHLBPT1
SAHLBPT2
SAHLBPT3
SAHLBPT1
SAHLBPT2
SAHLBPT3
SAHLBPT1
SAHLBPT2
SAHLBPT3
SAHLBPT1
SAHLBPT2
SAHLBPT3
SAHLBPT3
SAHLBPT3

vs.
vs.
vs.
vs.
vs.
vs.
vs.
vs.
vs.
vs.
vs.
vs.
vs.
vs.

LBPT1(R ¼ 1,P ¼ 8)
LBPT2(R ¼ 1,P ¼ 8)
LBPT3(R ¼ 1,P ¼ 8)
LBPT1(R ¼ 2,P ¼ 8)
LBPT2(R ¼ 2,P ¼ 8)
LBPT3(R ¼ 2,P ¼ 8)
LBPT1(R ¼ 2,P ¼ 16)
LBPT2(R ¼ 2,P ¼ 16)
LBPT3(R ¼ 2,P ¼ 16)
DCLBPT1
DCLBPT2
DCLBPT3
SAHLBPT1
SAHLBPT2

PAP

2D-Hela

Hep-2

Tumor

o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
0.0213
0.1072
0.0019
o 0.0001
o 0.0001
o 0.0001
0.0181
o 0.0001

o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
0.0021
0.0033
o 0.0001
o 0.0001
0.0018
o 0.0001
0.0823
o 0.0001

o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
o 0.0001
0.1823
0.0013

o0.0001
o0.0001
o0.0001
o0.0001
o0.0001
o0.0001
o0.0001
0.0015
o0.0001
o0.0001
o0.0001
o0.0001
0.0109
o0.0001

time complexity, the SAHLBPT3 involved in our framework
should be more preferred in medical image classiﬁcation task.
Finally, we then report the classiﬁcation accuracies of the
methods using different vocabulary sizes. In Fig. 15, the classiﬁcation accuracies have a similar trend as the visual vocabulary size
increases, i.e. the performance saturates when the vocabulary size
larger than 200. Moreover, SAHLBPT3 consistently outperforms
both SIFT and LBP using different vocabulary sizes.

Fig. 17. Confusion matrices of the proposed method for Hep-2 cell dataset. C1:
centromere; C2:coarse speckled; C3:cytoplasmatic; C4: ﬁne speckled; C5:homogeneous; C6:nucleolar.

Despite the well achieved accuracy, there are still some open
problems in our framework.
4. Conclusion and future work
In this paper, we proposed a novel framework based on our
adaptive local binary patterns and spatial adjacent histogram for
medical image classiﬁcation. We ﬁrst employed gradient operator
to determine the adaptive neighborhood radius of each pixel. Then
three coding schemes based on adaptive radius were introduced
for processing the LBP histograms. To capture the discriminative
micro-structures features produced by the adaptive radius, we
proposed to using spatial adjacent histogram strategy for image
representation. Finally, a SVM classiﬁer is learned for medical
image classiﬁcation task. We also evaluated four SVM kernels into
our algorithm to enhance its classiﬁcation power. Based on the
experiments on PAP smear, 2D-Hela, Hep-2 cell and Brain tumor
datasets, we can draw a conclusion that our proposed method
achieved better performance compared with other LBP-based
approaches.

(1) The dimension of our model is much larger than that of the
standard LBP, and this will result in the computational time
increasing linearly as training data grow in number. The scale
of medical image datasets is generally not large, however, our
method will cost more time when encountering general
datasets with large scale. The feature selection techniques
could be employed to solve this problem.
(2) In our proposal, we focus on improving LBP in terms of
encoding the micro-structures features, and we did not design
patterns with rotation invariant. However, the rotation invariants are expected to further improve the performance of
our model.
(3) We mainly employ SVM with linear kernel and we also report
the performance of different kernels with default parameter
values. However, a number of optimization algorithms could
be employed to further improve the classiﬁcation performance, such as swarm intelligence optimization algorithm.

200

D. Liu et al. / Computers in Biology and Medicine 72 (2016) 185–200

Fig.18. Confusion matrices of the proposed method for brain tumor dataset. C1:
astrocytoma; C2: tuberculum sellae meningioma; C3: olfactory groove meningioma; C4: acoustic neuroma; C5: pituitary tumor.

We will explore these problems in the future towards a more
powerful medical image classiﬁcation model.

Conﬂict of interest statement
None declared.

Acknowledgments
This work was supported by the National Natural Science
Foundation of China (61472161, 61133011, 61402195, 61502198,
61303132, 61202308), Science and Technology Development Project of Jilin Province (20140101201JC), the Science and Technology
Plan Project of Wenzhou of China (G20140048) and the Program of
China Scholarships Council (No. 201406170116).

Appendix A. Supporting information
The p-values of statistical tests for compared methods mentioned in Section 3.3 are presented in Table 14.
The confusion matrices for 2D-HeLa, Hep-2 cell, and brain
tumor datasets, are presented in Fig. 16, Fig. 17, and Fig. 18,
respectively. For each confusion matrix, the average classiﬁcation
accuracies for individual classes are listed along the diagonal, and
the entry in the ith row and jth column is the percentage of images
from the class i that are misidentiﬁed as class j.

References
[1] K. Doi, Computer-aided diagnosis in medical imaging: historical review, current status and future potential, Comput. Med. Imaging Graph. 31 (4) (2007)
198–211.
[2] F. Lalys, L. Riffaud, X. Morandi, P. Jannin, Automatic Phases Recognition in
Pituitary Surgeries by Microscope Images Classiﬁcation. In Information Processing in Computer-assisted Interventions, Springer Berlin Heidelberg (2010),
p. 34–44.
[3] T.F. Cootes., C.J. Taylor., Statistical models of appearance for medical image
analysis and computer vision. Medical imaging 2001, Int. Soc. Opt. Photon.
(2001) 236–248.

[4] H. Pourghassem, H. Ghassemian, Content-based medical image classiﬁcation
using a new hierarchical merging scheme, Comput. Med. Imaging Graph. 32
(2008) 651–661.
[5] M. Häfnera, M. Liedlgruber, A. Uhl, A. Vécsei, F. Wrba, Color treatment in
endoscopic image classiﬁcation using multi-scale local color vector patterns,
Medical Image Analysis, 16, pp. 75–86.
[6] T. Ojala, M. Pietikäinen, T. Mäenpää, Multiresolution gray-scale and rotation
invariant texture classiﬁcation with local binary pattern, IEEE Trans. Pattern
Anal. Mach. Intell. 24 (7) (2002) 971–987.
[7] H. Zhou, R. Wang, C. Wang, A novel extended local binary pattern operator for
texture analysis, Inf. Sci. 22 (2008) 4314–4325.
[8] Z.H. Guo, L. Zhang, D. Zhang, X.Q. Mou, Hierarchical multiscale lbp for face and
palmprint recognition, in: Proceedings of the 17th IEEE International Coference Image Processing (ICIP 2010), 2010, pp. 4521–4524.
[9] L. Nanni, A. Lumini, S. Brahnam, Survey on LBP based texture descriptors for
image classiﬁcation, Expert Syst. Appl. 39 (2012) 3634–3641.
[10] J.F. Ren, X.D. Jiang, J.S. Yuan, Noise-resistant local binary pattern with an
embedded error-correction mechanism, IEEE Trans. Image Process. 22 (10)
(2013) 4049–4060.
[11] Jun Shang, et al., Robust image region descriptor using local derivative ordinal
binary pattern, J. Electron. Imaging 24 (3) (2015) 033009.
[12] X.L. Meng, Z.Z. Wang, L.Z. Wu, Building global image features for scene
regognition, Pattern Recognit. 5 (2012) 373–380.
[13] Z. Guo, L. Zhang, D. Zhang, A completed modeling of local binary pattern
operator for texture classiﬁcation, IEEE Trans. Image Process. 19 (2010) (16751663).
[14] X. Tan., B. Triggs., Enhanced local texture feature sets for face recognition
under difﬁcult lighting conditions, IEEE Trans. Image Process. 19 (6) (2010)
1635–1650.
[15] C. Zhu, C.E. Bichot, L. Chen, Multi-scale color local binary patterns for visual
object classes recognition, in: Proceedings of the International Conference on
Pattern Recognition (ICPR), 2010, pp. 3065–3068.
[16] S. Liao, A.C.S. Chung, In: Face Recognition by Using Elongated Local Binary
Patterns with Average Maximum Distance Gradient Magnitude, Asian Conference on Computer Vision, 2007.
[18] W. Zhang, S. Shan, W. Gao, X. Chen, H. Zhang, Local Gabor binary pattern
Histogramse quence (LGBPHS): a novel non-statistical model for face representation and recognition, Int. Conf. Comput. Vision. 1 (2005) 786–791.
[19] S. Liao, M.W.K. Law, A.C.S. Chung, Dominant local binary patterns for texture
classiﬁcation, IEEE Trans. Image Process. 18 (2009) 1107–1118.
[20] N. Senthilkumaran, R. Rajesh., Edge detection techniques for image segmentation–a survey of soft computing approaches, Int. J. Recent Trends Eng. 1 (2)
(2009).
[21] N. Werghi, S. Berretti, A.D. Bimbo, The mesh-LBP: a framework for extracting
local binary patterns from discrete manifolds, IEEE Tans. Image Process. 24 (1)
(2015).
[22] Z. Li, G. Liu, Y. Yang, et al., Scale-and rotation-invariant local binary pattern
using scale-adaptive texton and subuniform-based circular shift, Image Process. IEEE Trans. 21 (4) (2012) 2130–2140.
[23] S. Hegenbart, A. Uhl, A scale-and orientation-adaptive extension of Local
Binary Patterns for texture classiﬁcation, Pattern Recognit. 48 (8) (2015)
2633–2644.
[24] S. Liao, A.C.S. Chung, Face recognition by using elongated local binary patterns
with average maximum distance gradient magnitude, Asian Conf. Comput.
Vision (2007) 627–629.
[25] T. Ahonen, J. Matas, C. He, M. Pietikainen, Rotation invariant image description
with local binary pattern histogram Fourier features, Image Anal. (2009)
61–70.
[26] Z. Guo, L. Zhang, D. Zhang, A completed modeling of local binary pattern
operator for texture classiﬁcation, IEEE Trans. Image Process. 19 (2010)
1657–1663.
[27] Ryusuke Nosaka, Yasuhiro Ohkawa, Kazuhiro Fukui., Feature Extraction Based
on Co-occurrence of Adjacent Local Binary Patterns. Advances in Image and
Video Technology, Springer Berlin Heidelberg (2012), p. 82–91.
[28] A. Chebira, Y. Barbotin, C. Jackson, T. Merryman, G. Srinivasa, R.F. Murphy,
J. Kovačević, A multiresolution approach to automated classiﬁcation of protein
subcellular location images, BMC Bioinform. 8 (1) (2007) 210.
[29] P. Foggia, G. Percannella, P. Soda, M. Vento, Benchmarking HEp-2 cells classiﬁcation methods, Med. Imaging IEEE Trans. 32 (10) (2013) 1878–1889.
[30] J. Jantzen, J. Norup, G. Dounias, B. Bjerregaard, Pap-smear benchmark data for
pattern classiﬁcation, Nat. Inspired Smart Inf. Syst. (2005) 1–9.
[31] C.C. Chang, C.J..Lin, LIBSVM: A Library for Support Vector Machines, 2001.
Software available from: 〈http://www.csie.ntu.edu.tw/  cjlin/libsvm〉.
[32] H. Byun, S.W. Lee, Applications of Support Vector Machines for Pattern
Recognition: A Survey[m]/Pattern Recognition with Support Vector Machines,
Springer Berlin Heidelberg (2002), p. 213–236.
[33] G.B. Huang, D.H. Wang, Y. Lan, Extreme learning machines: a survey, Int. J.
Mach. Learn. Cybern. 2 (2) (2011) 107–122.
[34] S. Maji, A.C. Berg, J. Malik, Classiﬁcation using intersection kernel support
vector machines is efﬁcient[C]/Computer Vision and Pattern Recognition,
2008, CVPR 2008, IEEE Conference on IEEE, 2008: pp. 1–8.
[36] J.M. Bland, D.G. Altman, Multiple signiﬁcance tests: the Bonferroni method,
BMJ 310 (6973) (1995) 170.
[37] S. Lazebnik, C. Schmid, J. Ponce, Beyond bags of features: spatial pyramid
matching for recognizing natural scene categories, Comput. Vision. Pattern
Recognit. (CVPR) (2006).

