Computational & Mathematical Organization Theory 6, 61–82, 2000.
c 2000 Kluwer Academic Publishers. Printed in The Netherlands.
°

Negotiation and Equilibria in User Competition
for Resources: A Dynamic Plot Approach
GIAMPIERO E.G. BEROGGI
School of Technology, Policy, and Management, Delft University of Technology, P.O. Box 5015, 2600 GA Delft,
The Netherlands
email: beroggi@sepa.tudelft.nl
PITU B. MIRCHANDANI
Systems and Industrial Engineering Department, The University of Arizona, Tucson, Arizona 85721, USA
email: pitu@sie.arizona.edu

Abstract
We consider a scenario where two users are competing for substitutable facilities and where the costs to a user
for using a facility depend on its usage as well as the usage by the other user. This results in a nonlinear dynamic
game the “solution” of which implies an allocation that satisfies both users. Games with four different types of
solution spaces are presented where the equilibria and the process to reach a negotiated compromise solution
have different characterizations. Nash equilibria and nondominated points are discussed in this context and an
interactive graphical dynamic plot approach is presented for obtaining negotiated solutions in such nonlinear
dynamic games.
Keywords: negotiation, user competition, resource management

1.

Introduction

Competitors for substitutable resources or processes—referred to as “facilities” in this
paper—face tactical and operational decision situations concerning the assignment of their
workload, jobs, activities, investments, etc.—referred to as “investments” in this paper—to
the different facilities. Examples are transportation companies facing the choice to assign
cargoes to different roads or different facilities (e.g., airports), manufacturers requesting
processing from various machine shops, telecommunication service providers competing
for transmission capacities, and financial institutions bidding for investment opportunities.
The economic implications of their decisions, however, depend on the courses of action
of all competitors. If all competitors decide to assign all of their investments to one and
the same facility, the costs could be disadvantageous to all of them. On the other hand,
if all competitors distribute their investments across all the available facilities, then the
costs might be reasonable for all of them. Consequently, the competitors are interesting in
reaching some sort of equilibrium concerning the assignments of investments to different
facilities.

62

BEROGGI AND MIRCHANDANI

The research presented here relates to three areas in economics, operations research and
related fields: game theory, multicriteria decision making (MCDM) and resource allocation
modeling. By and large, MCDM and resource allocation literature deals with problems
of a single user (or single firm); and in presence of multiple criteria, resource allocation
problems have been studied where either a set of nondominated, or Pareto optimal, solutions
are needed, or where a single solution is sought that appropriately trades off the criteria (e.g.,
by means of a utility function). Game theory, on the other hand, deals with multiple players
(or users in our context), but reported applications to problems of resource allocation with
dynamic interactions are surprisingly few. Nevertheless, the concept, from game theory,
of equilibrium among “noncooperative” players (in our case, the users of the facilities are
noncooperative), particularly the “Nash Equilibrium”, (see Nash, 1951, or most game theory
texts, e.g., Osborne and Rubinstein, 1994) plays an important role in the characterization of
the nonlinear dynamic games described in the paper. At a Nash equilibrium point a unilateral
deviation from the current allocation decision of a user does not improve its cost. In what
follows, we will refer to the Nash equilibria in our nonlinear dynamic games as simply the
equilibria.
The authors are aware of some related works that should be noted, however. A significant
body of work relates to finding equilibria in networks where a large number of players make
“user optimal” route decisions, specially in transportation planning (e.g. Florian, 1984),
telecommunication routing and flow control (e.g., Korlis and Lazar, 1995; Economides and
Silvester, 1991; and Orda et al., 1993), and spatial markets (e.g., Barros and Weintraub,
1986). Most of that research assumes user cost functions that are increasing convex, where
a facility’s cost to a user increases with its usage; papers often report on conditions for
existence of equilibria and/or methods to compute equilibria. The cost functions assumed
in this paper are more general; however, we limit our developments to scenarios where only
two users compete for two facilities.
Advanced information and communications technologies motivate organizations to make
best use of real-time data and information to optimize their operations. This refers not only
to the acquisition of information but also to their dissemination to competitors concerning
their tactics and strategies. For example, competing air carriers are aware of their mutual
assignments of cargoes to alternative airports and the resulting costs. In turn, the companies
can use this information to adjust the originally devised strategies in an attempt to optimize
their assignments. However, they must take into consideration that the competitors, in turn,
can react to any changes of their strategy in a way that might turn out to be disadvantageous
to them. Therefore, companies will try to balance their strategies to account for the competitors possible decisions and the associated dynamic interactions and costs. Although the
competitors remain noncommunicative and noncooperative in the sense that they disclose
only part of their information and that they cannot be expected to comply with any contracts, a “virtual” negotiation process takes place when the companies react to each other’s
allocations and the resulting costs.
In such nonlinear dynamic game settings, we design a computer-based interactive virtual
negotiation process; here each player provides its possible allocation decision and lets the
other player know of its position via a computer screen where its and the competitor’s cost

A DYNAMIC PLOT APPROACH

63

trajectories are plotted (referred to as “dynamic plots” by Beroggi, 2000, forthcoming). This
negotiation process relates to auctions and bidding processes described in game-theoretic
literature (e.g., Osborne and Rubinstein, 1994). In resource allocation applications, the
authors are aware of related work in natural gas and electric power transmission (McCabe
et al., 1990), airport time slot allocation (Rassenti et al., 1982), and allocation of rail tracks
(Brewer and Plott, 1994). We note that another approach to affecting resource allocation or
architecting an efficient solution is by manipulating the capacity available to the users (see,
e.g., Korlis et al., 1995), or through pricing the facilities, based on shadow prices, demands,
opportunity costs, etc. (see, e.g., Korlis et al., 1997a, b). In this paper, we assume that the
facility providers in our scenario are passive; that is, they announce their cost functions to
the users and the cost functions remain the same throughout the “game.”
Section 2 introduces a general cost function for two competitors assigning investments to
two different facilities. The resulting two-dimensional cost space for the two competitors is
then visualized with the geometric plot method (Luce and Raiffa, 1985). Different types of
equilibria corresponding to specific parameters of the general cost function are discussed in
Section 3. Section 4 contains a discussion of the dynamic behavior of the competitors using
the dynamic plot. The paper concludes with a summary of the results, a brief discussion of
an interactive software for conducting virtual negotiation and an outline of possible future
research directions.
2.
2.1.

A Model for User Competition for Resources
Problem Definition

The problem: two competitors X and Y face the option of assigning a certain fraction of
their investments to two facilities A and B. The costs to the two competitors are determined
by how much the two assign to the two facilities. For example, if both assign all their
investments to the same facility, then they might face higher costs than if each of them
assigns all of its investments to a different facility. On the other hand, one facility might be
more attractive than the other, but only up to a given total investment.
Let p be the fraction of its investment assigned by competitor X to facility A, and q
the fraction of its investment assigned by competitor Y also to facility A. Then, cost to
competitor X , cx , of assigning a fraction of p of its investment to facility A is composed of
a cost related to both X and Y allocations to facility A, and a cost related to the remaining
assignments to facility B. The corresponding assumptions hold for competitor Y . With the
view that p and q are relative frequencies of amounts of investments (i.e., approximated by
probabilities) we can assume that p and q are probabilistically independent. This assumption
is reasonable because we cannot presume that the competitors will comply with any contracts
concerning their investments. Thus, we assume the following general cost functions for the
two competitors:
cx = A x pe p[qaxa +(1−q)a ya ] + Bx (1 − p)e(1− p)[qbxa +(1−q)b ya ]
c y = A y qeq[ paxb +(1− p)a yb ] + B y (1 − q)e(1−q)[ pbxb +(1− p)b yb ]

(1)

64

BEROGGI AND MIRCHANDANI

The coefficients have the following meaning (where A and B refers to facilities A and B,
respectively):
•
•
•
•
•
•
•
•
•
•
•
•

A x : cost coefficient for X ’s allocation to A;
Bx : cost coefficient for X ’s allocation to B;
A y : cost coefficient for Y ’s allocation to A;
B y : cost coefficient for Y ’s allocation to B;
axa : interaction parameter for X ’s allocation to
a ya : interaction parameter for X ’s allocation to
bxa : interaction parameter for X ’s allocation to
b ya : interaction parameter for X ’s allocation to
axb : interaction parameter for X ’s allocation to
a yb : interaction parameter for X ’s allocation to
bxb : interaction parameter for X ’s allocation to
b yb : interaction parameter for X ’s allocation to

A with Y ’s allocation to A in X ’s cost;
A with Y ’s allocation to B in X ’s cost;
B with Y ’s allocation to A in X ’s cost;
B with Y ’s allocation to B in X ’s cost;
A with Y ’s allocation to A in Y ’s cost;
A with Y ’s allocation to B in Y ’s cost;
B with Y ’s allocation to A in Y ’s cost;
B with Y ’s allocation to B in Y ’s cost.

Equation (1) represents a very large family of nonlinear cost functions (special cases give
linear functions) that could appropriately model many user competitive systems. This
family is considered to illustrate the types of nonlinear dynamic games and the resulting
equilibria and negotiations that may occur within this scenario.
Cost functions (1) define a two-dimensional cx − c y cost space which is derived from any
combination of p, q ∈ [0, 1]. Figure 1 depicts the space from an example of cost functions
generated by (1), where the cost coefficients are: A x = Bx = 1, A y = B y = 2, axa = ln(4),
axb = ln(2), bxa = ln(3), byb = ln(2), and aya = ayb = bya = bxb = 0. Each point (cx , c y ) in
the shaded space corresponds to a pair ( p, q).
Obviously, both competitors would like to minimize their costs within the shaded region.
Therefore, competitor X would aim for any point along the line defined by the two points

Figure 1.

Example of cost space.

65

A DYNAMIC PLOT APPROACH

(cx , c y ) = (1, 2) and (cx , c y ) = (1, 4), whereas Y would want to settle in one of the two
points (cx , c y ) = (1, 2) or (cx , c y ) = (3, 2). Therefore, if both reached their minimum costs
at (cx , c y = (1, 2), which corresponds to p = 1 and q = 0, no further negotiation would be
sought. This means that, at “equilibrium,” X will assign all of its investments to facility A
while Y will direct all of its investments to facility B.
In this cost space, we are especially interested in the four corner points: (i) (x11 , y11 )
determined by p = 1 and q = 1; (ii) (x12 , y12 ) determined by p = 1 and q = 0; (iii) (x21 , y21 )
determined by p = 0 and q = 1; and (iv) (x22 , y22 ) determined by p = 0 and q = 0. The
situation is illustrated in the table below:
Y
q =1

q =0

p=1

x11 , y11

x12 , y12

p=0

x21 , y21

x22 , y22

X

In the example of figure 1, we have the following corner points:
Y
q =1

q =0

p=1

4, 4

1, 2

p=0

3, 2

1, 4

X

To characterize and analyze other such nonlinear dynamic games, we will assign these four
corner points some predetermined values. The cost coefficients that result in the given corner
points, for the cost functions (1), can be determined with an inverse-transform technique as
follows:
•
•
•
•
•
•
•
•

cx ( p = 1, q = 1) = A x eaxa = x11 ,
c y ( p = 1, q = 1) = A y eaxb = y11 ,
cx ( p = 1, q = 0) = A x ea ya = x12 ,
c y ( p = 1, q = 0) = B y ebxb = y12 ,
cx ( p = 0, q = 1) = Bx ebxa = x21 ,
c y ( p = 0, q = 1) = A y ea yb = y21 ,
cx ( p = 0, q = 0) = Bx eb ya = x22 ,
c y ( p = 0, q = 0) = B y eb yb = y22 .

This means for example, that if both companies assign 100% of their investments to facility A
( p = q = 1), the cost for company X is x11 , and for company Y it’s y11 . To analyze different
competitive settings, we will take the corner point costs to correspond to the ones proposed
by Rapoport and Guyer (1966) in their study of 2 × 2 conflict situations for non-cooperative
competitors: {x 11 , x12 , x21 , x22 } = {1, 2, 3, 4} and {y11 , y12 , y21 , y22 } = {1, 2, 3, 4}. That is,

66

BEROGGI AND MIRCHANDANI

for ( p, q) taking on the values (1, 1), (1, 0), (0, 1), and (0, 0), each xij and yij of the corner
points takes on the values 1, 2, 3, 4 exactly once. We note that Rapoport and Guyer’s study
referred to competitors choosing pure strategies; that is, each competitor faces the choice
of one of the two facilities. In this paper, however, we consider the possibility to choose
fractions of investments to go to different facilities, also referred to as mixed strategies.
The objective for both competitors is to minimize their costs by choosing appropriate
values for p and q, respectively. In general, these two objectives might be conflicting: that
is, the most favorable assignment for one competitor may not be the most favorable for
the other. For example, a company X may like to assign everything to its most profitable
facility, without competitor Y interfering with X ’s business. However, competitor Y may
not agree to such a (disadvantageous) solution if it did not also minimize its costs. Obviously,
in the nonlinear dynamic situation the costs to both competitors are mutually dependent
on each other’s actions. Thus, as we will illustrate below, an equilibrium point, perhaps
a compromise for both competitors, may be reached in an interactive dynamic fashion
with virtual negotiations. In such a negotiation, a proposed (or even implemented) interim
strategy of one competitor might not even be its long-term best option—it might just be an
attempt to tell the competitor how much it is willing to compromise for the sake of reaching
an aspired goal.
3.

Types of Nonlinear Dynamic Competitions

In this section we will analyze four types of competitive settings that result due to different
cost coefficients in Eqs. (1). We refer to the four cases of competitive settings we consider
as: (i) non-conflict equilibrium, (ii) multiple efficient equilibria, (iii) weakly stable deficient equilibrium with non-symmetric efficient frontier, and (iv) strongly stable deficient
equilibrium with symmetric efficient frontier. We remark, however, that because of the
nonlinearities in the cost functions, the equilibrium points might be quite unpredictable.
The geometric plot representations of the four cases of competitive settings are illustrated
in figure 2. Each of these cases is described below.
3.1.

Non-Conflict Equilibrium (Case I)

We consider the following corner points for the non-conflict equilibrium case:
Case I:
Y
q =1

q =0

p=1

4, 4

2, 3

p=0

3, 2

1, 1

X

A DYNAMIC PLOT APPROACH

67

Figure 2. Geometric plot representations of conflict situations. (a) Case I, non-conflict equilibrium; (b) Case II,
multiple efficient equilibria; (c) Case III, weakly stable deficient equilibrium with non-symmetric efficient frontier;
(d) Case IV, strongly stable deficient equilibrium with symmetric efficient frontier.

The corresponding cost coefficients of Eq. (1) are determined with the inverse transform
technique. Inserting them into Eq. (1) gives the following cost functions for the two competitors:
cx = 2 peln(2) pq + (1 − p)eln(3)(1− p)q
c y = 2qeln(2)q p + (1 − q)eln(3)(1−q) p

(2)

As can be seen from figure 2(a), here the competitors face a non-conflict situation where
both competitors have their minimum costs at (cx , c y ) = (1, 1) with ( p, q) = (0, 0); that is,
both assign all their investments to facility B.

68
3.2.

BEROGGI AND MIRCHANDANI

Multiple Efficient Equilibria (Case II)

The corner point costs resulting in multiple efficient equilibria are the following:
Case II:
Y
q =1

q =0

p=1

3, 3

1, 2

p=0

2, 1

4, 4

X

The inverse transform technique gives a set of cost coefficients. Inserting them into (1) we
get the following cost functions:
cx = 1 peln(3) pq + 2(1 − p)eln(2)(1 − p)(1 − q)
c y = 1qeln(3)q p + 2(1 − q)eln(2)(1 − q)(1 − p)

(3)

The two competitors reach their minimum costs in different points (see figure 2b). While
competitor X ’s minimum is (cx , c y ) = (1, 2), competitor Y ’s is at point (cx , c y ) = (2, 1).
However, each of these two points is not an equilibrium point; one or the other competitor
can reduce its costs here. Nevertheless, there are three sets of nondominated solutions as
shown in figure 3: (i) from O1 to E, (ii) from O2 to F, and (iii) from E 0 to F 0 . It should be
noted that O1 is where ( p, q) = (0, 1), and O2 is where ( p, q) = (1, 0).

Figure 3.

Efficient frontiers.

69

A DYNAMIC PLOT APPROACH

Obviously, E lies on the curve with q = 1. Inserting q = 1 into (3) gives:
cx = peln(3) p + 2(1 − p)
c y = eln(3) p
From the second equation we get p = ln(cx )/ln(3). Inserting this into the first equation
gives:
cx =

µ
¶
ln(c y )
ln(c y )
cy + 2 1 −
.
ln(3)
ln(3)

Setting the partial derivatives equal to zero,
µ
¶
1
2
dcx
1 + ln(c y ) −
=
= 0,
dc y ln(3)
cy
gives c y = 1.455, which we use to compute
p = ln(1.455)/ln(3) = 0.341,
and
cx = peln(3) p + 2(1 − p) = 1.814.
The point E is therefore defined by:
c y = 1.455,

cx = 1.814,

p = 0.341,

q = 1.

To compute the values for E 0 , we use cx = 1.814, and look for p and q, such that:
1.814 = cx = 1 peln(3) pq + 2(1 − p)eln(2)(1 − p)(1 − q)
min: c y = 1qeln(3)q p + 2(1 − q)eln(2)(1 − q)(1 − p) .
This gives us for E 0 : p = 0.564, q = 0.654, and c y = 1.749.
By symmetry, coordinates for F and F 0 are easily determined. In summary points
E, E 0 , F, and F 0 are:
Points

cx

cy

p

q

E

1.814

1.455

0.341

1.000

E0

1.814

1.749

0.564

0.655

F

1.455

1.814

1.000

0.341

F0

1.749

1.814

0.655

0.564

70

BEROGGI AND MIRCHANDANI

The frontier between points E 0 and F 0 is Pareto optimal, as illustrated for selected points:
cx

cy

1.814

1.749

1.800

1.768

1.790

1.780

1.780

1.790

1.785

1.785

1.770

1.798

1.760

1.806

1.750

1.813

1.749

1.814

These points are plotted in figure 4.
The p and q values of the symmetric point cx = c y = 1.785 on the efficient frontier can
be computed from
minimize
such that

cx
p = q.

The solution is p = q = 0.606. However, this point, although nondominated, is not an
equilibrium because each competitor can reduce its cost at this point by an unilateral move.
Moreover, there is no equilibrium in this neighborhood. The only equilibria for this conflict
situation are the two points E and F where neither of the two competitors can reduce its
cost unilaterally.

Figure 4.

An efficient frontier for Case II.

71

A DYNAMIC PLOT APPROACH

3.3.

Weakly Stable Deficient Equilibrium with Non-Symmetric
Efficient Frontier (Case III)

The corner point costs resulting in a weakly stable deficient equilibrium with non-symmetric
efficient frontier are the following:
Case III:
Y
q =1

q =0

p=1

4, 3

2, 4

p=0

3, 1

1, 2

X

The inverse transform technique gives a set of cost coefficients. Inserting them into (1) we
get the following cost functions:
cx = 2 peln(2) pq + 1(1 − p)eln(3)(1− p)q
c y = 1 peln(3)q p + 2(1 − q)eln(2)(1−q) p

(4)

The frontier between the points (cx , c y ) = (3, 1) corresponding to ( p, q) = (0, 1), and
(cx , c y ) = (1, 2), corresponding to ( p, q) = (0, 0) is Pareto optimal but not symmetric
(figure 2). However, due to the non-linearity in the cost functions, the user equilibrium
does not lie on the efficient frontier. Figure 5 shows the isolines for p = constant and q =
constant; observe that the user equilibrium lies somewhere inside the cost set.

Figure 5. Weakly stable deficient equilibrium with efficient frontier (Case III); dotted curves are generated by
changing p from 0 to 1 at an increment of 0.005 while q is constant, and solid curves are generated by changing
q from 0 to 1 at an increment of 0.005 while p is constant.

72

BEROGGI AND MIRCHANDANI

To compute the equilibrium we set the derivatives of the cost functions cx for q = constant
and c y for p = constant equal to zero,
dcx
= 2eln(2) pq + 2 ln(2) pqeln(2) pq − eln(3)(1− p)q − ln(3)(1 − p)qeln(3)(1− p)q = 0
dp
dc y
= eln(3)q p + ln(3)qpeln(3)qp − 2eln(2)(1−q) p − 2 ln(2)(1 − q) peln(2) p(1−q) = 0
dq
The solution to these two equalities is: p = 0.37296303, q = 0.95073383, which gives
cx = 2.16081071 and c y = 1.50338666. We refer to this equilibrium as weakly stable because it lies very close to the efficient frontier and this might reveal to the competitors a
(non-equilibrium) solution on the frontier that dominates it.
3.4.

Strongly Stable Deficient Equilibrium with Symmetric Efficient Frontiers (Case IV)

The corner point costs resulting in a strongly stable deficient equilibrium with symmetric
efficient frontiers are the following:
Case IV:
Y
q =1

q =0

p=1

3, 3

1, 4

p=0

4, 1

2, 2

X

The inverse transform technique gives two sets of solutions for the coefficients: either all
coefficients being positive or all negative. Inserting the set of negative coefficients into (1)
gives the following cost functions:
cx = 3 pe−ln(3) p(1−q) + 4(1 − p)e−ln(2)(1− p)(1−q)
c y = 3qe−ln(3)q(1− p) + 4(1 − q)e−ln(2)(1−q)(1− p)

(5)

The graph for Case IV in figure 2(d) shows that the point (cx , c y ) = (3, 3) is a deficient
equilibrium; that is, neither of the two competitors can unilaterally reduce the costs, and
the point is not efficient. Obviously, X would like to settle at (cx , c y ) = (1, 4), while Y
would like (cx , c y ) = (4, 1). However, these are unstable points; what is optimal for one
competitor is worst, and unacceptable, for the other. Figure 2(d) indicates a compromise at
(cx , c y ) = (2, 2). Unfortunately, this point is also unstable, because each competitor could
be tempted to defect to its best cost. Therefore, we recognize that Case IV is a non-linear
dynamic counterpart of the well-known prisoner dilemma game (e.g., Luce and Raiffa,
1985).

A DYNAMIC PLOT APPROACH

73

The p and q values corresponding to the two points R = (cx,S , 2) and R = (2, c y,R )
which define the efficient frontiers WR and US of figure 2(d) can be found by solving
• min: cx,S , s.t. c y,S = 2.0, which gives p and q for S, and
• min: c y,R , s.t. cx,R = 2.0, which gives p and q for R.
The symmetric solutions are: (cx,S, c y,S ) = (3.20, 2.00), for p = 0.00 and q = 0.68; and
(cx,R, c y,R ) = (2.00, 3.20), for p = 0.68 and q = 0.00.
4.

Dynamic Plot Approach for Negotiated Solutions

The analyses of the equilibria for the four cases indicate where the competitors might
settle and their corresponding costs. To reach a point which satisfies the two competitors,
we expect the competitors will continuously exchange information about their investments
and, in response, readjust their strategies. An intuitive way to visualize this dynamic process
is with dynamic plots (Beroggi, 2000, forthcoming).
A dynamic plot is a geometric plot expanded by its isolines for p = constant and
q = constant, respectively. The dynamic plots for the four cases of the last section are given
in figure 6. For illustration, figure 7 shows the dynamic plot for such a nonlinear game. The
dots indicate points where p = 0 and q = 0, 0.05, 0.1, 0.15, . . . , and points were q = 0 and
p = 0, 0.05, 0.1, 0.15, . . . , respectively. The thick lines indicate possible virtual negotiating trajectories defined by sequential adjustments of the competitors’ moves. Competitors
alternatively change their values of p (for competitor X ) and q (for competitor Y ). That
is, at any point in time X can ‘move’ along a curve defined by q = constant, while Y can
‘move’ along a curve defined by p = constant. That is, each competitor may change its
assignment assuming that the other waits for its response.
Let’s assume that the virtual negotiation process starts with both competitors assigning
all their investments to facility A; that is, p = q = 1, and cx = c y = 4. A hill-descending
approach (HDA) means to minimize the costs at each move. If the two competitors employ
a HDA, they will not reach the desired equilibrium point (cx , c y ) = (1, 2). Instead they will
end up in the second equilibrium point. This can be computed by setting the first derivative
of the cost function
cx = peln(4) pq + (1 − p)eln(3)(1− p)q
c y = 2qeln(2)q p + 2(1 − q)eln(2)(1− p)(1−q)
equal to zero:
dcx
= eln(4) pq + ln(4) pqeln(4) pq − eln(3)(1− p)q − ln(3)(1 − p)qeln(3)(1− p)q = 0
dp
dc y
= 2eln(2)q p + 2 ln(2)qpeln(2)qp − 2eln(2)(1−q)(1− p)
dq
−2 ln(2)(1 − q)(1 − p)eln(2)(1−q)(1− p) = 0

74

BEROGGI AND MIRCHANDANI

Figure 6.

Dynamic plots of conflict situations. (a) Case I, (b) Case II, (c) Case III, (d) Case IV.

Solving for p and q, the result is p = 0.44 and q = 0.56 which gives the deficient equilibrium (cx , c y ) = (1.41, 2.37). This equilibrium with HDA is reached in two moves (see
figure 7). First, X moves to p = 0.44 which, with q = 1.0, gives (cx , c y ) = (1.85, 2.71);
then, Y moves to q = 0.56 which gives, with p = 0.44, the equilibrium point (cx , c y ) =
(1.41, 2.37). Thus, HDA does not necessarily lead to the optimal decision and therefore,
competitors must adopt some other strategies to reach their optimum. (The HDA path is
the dark thick path in figure 7.)
4.1.

Non-Conflict Equilibrium (Case I)

Let’s assume that the negotiation process for Case I starts with both competitors assigning
all their investments to A; that is p = q = 1, which gives cx = c y = 4. Obviously, both
are interested in reducing their costs. Let’s assume that competitor X does the first move

A DYNAMIC PLOT APPROACH

Figure 7.

75

Dynamic plot with hill-descending path ending in deficient equilibrium.

as a HDA which leads to p = 0.38, while q = constant = 1. This gives cx = 2.21 and
c y = 2.60. Then, Y reacts also as a HDA which leads to q = 0.00, while p = constant =
0.38. This yields cx = 1.38 and c y = 1.52. The last move is by X which gives p = 0.00
while q = constant = 0.00. At this point the game ends with a non-conflict equilibrium at
p = 0, q = 0. That is, both competitors have switched their total investments from facility
A to facility B. The corresponding costs are cx = 1.00 and c y = 1.00 which is the optimal
solution for both the competitors. The path of this virtual negotiation process is shown in
figure 6(a).
It is interesting to note that the path which lead to the optimal solution did not go along
the edges of the cost space. If, for example, X had set p = 0.40 instead of p = 0.38, Y
would have set q = 0.05 at the next move, rather than q = 0.00. Then, X would have set
p = 0.00, and in response Y would have at q = 0.00 terminated the negotiation. In this
case, one more iteration would be needed before the optimum is reached.
4.2.

Multiple Efficient Equilibria (Case II)

In the symmetric competition case, one of the two facilities, say A, is more “profitable”
than the other (B), in the sense that if both competitors assign all their investments to A,
then the costs are lower than if both assigned all their investments to B. The competition is
symmetric because each of the two competitors has an equal advantage in one of the two
facilities (X in A and Y in B). The cost function cx (c y ) for each competitor consists of
two components. The first component of cx (c y ) reflects the costs to company X (Y ) for the
amount that both assign to facility A. The second component of cx (c y ) reflects the costs to
company X (Y ) for the amount that both assign to facility B.
The virtual negotiation process can start at any point, for example at (4, 4) where both
competitors assign all their investments to facility B. Then, one competitor, say X , alters

76

BEROGGI AND MIRCHANDANI

its assignment from p = 0 to, say, p = 0.2 which results in cx = 2.99 and c y = 3.48. As
a response, Y may change its assignment to A from q = 0 to, say, q = 1, which results in
cx = 1.85 and c y = 1.25. Then, X could respond to Y ’s move by setting p = 0.32, which
results in cx = 1.81 and c y = 1.42. These moves are highlighted in figure 6(b).
The virtual negotiation process continues until one competitor renounces its move. Then
the negotiation process pauses (but it could be resumed later on). The equilibrium, whether
temporary or for a longer period, may also depend on the minimum aspiration levels of the
two competitors. For example, competitor X might be happy if the costs are below 2.5.
This gives it quite some room for negotiation because the best possible costs are 1.00. On
the other hand, if competitor X aspires to have costs below 1.5, then, it may not settle for
cx = 1.81 and c y = 1.42, or even the symmetric solution c y = cx = 1.785 on the efficient
frontier. As we discussed earlier, this efficient symmetric point is not an equilibrium point.
The only two equilibria are at points E and F (figure 3) which probably will not be chosen
in this dynamic virtual negotiation setting if both competitors’ aspiration levels are not
satisfied here.
Moreover, one competitor could be willing to accept temporary losses to push the other
competitor out of business. For this conflict situation, a loss means to have costs higher
than 3.00, which are the minimum costs that each competitor can reach independent of the
other’s strategy.
4.3.

Weakly Stable Deficient Equilibrium with Non-Symmetric
Efficient Frontier (Case III)

In this case, let us assume that both competitors have initial plans to assign investments
solely to facility B( p = q = 0). Then, facility A decides to attract more customers, including
X and Y , by modernizing its services. However, if both X and Y go to facility A, A charges
higher costs than if one of the two competitors stays exclusively with B. Y is better off by
changing unilaterally to A. However, because X would do better if both stayed with B, X
may try to keep Y from going to A by diverting some of its investments to A, increasing
losses for both itself and Y .
Again, the cost function for each competitor consists of two components. The first component reflects the cost due to the investment assigned to facility A, and the second component
the cost due to the investment assigned to facility B. The corresponding dynamic plot is
given in figure 6(c). Each curve originating with a dark square is for a fixed q value with
p ranging from 0 to 1 at an increment of 0.05.
In this case, suppose the virtual negotiation process starts with p = q = 0, with cx = 1.00,
c y = 2.00. We would expect Y to alter its assignment to q = 1 (i.e., signaling that it wants
to invest all in facility A), which results in cx = 3.00, c y = 1.00. Next, X can use HDA and
“reassign” to, say, p = 0.38, which results in cx = 2.21, c y = 1.52. As a response, Y
might alter its assignment to q = 0.95, which results in cx = 2.16, c y = 1.51. At this point,
X cannot reduce its cost any more. However, if X had a minimum aspiration level of 2.0, it
could deteriorate Y ’s costs to 2.32 by setting p = 0.81 (which gives cx = 2.99). This might
signal to Y that X is willing to consider some losses if Y does not compromise. Thus, Y
might decide to give in to X by reassignment to q = 0.42 (resulting in cx = 2.26, c y = 2.22)

A DYNAMIC PLOT APPROACH

77

and not to q = 0.66 which would be the optimal point for Y (cx = 2.56, c y = 2.01). In the
next move, X may again use HDA and set p = 0.15 (resulting in cx = 1.57, c y = 1.68) and
the negotiation process may end. Note that this point does not lie on the efficient frontier
which is defined by the edge form (1, 2) to (3, 1); that is, other points exist that dominate
this solution.
4.4.

Strongly Stable Deficient Equilibrium with Symmetric Efficient Frontier (Case IV)

For Case IV (figure 6(d)) let us assume that both competitors have initial plans to invest solely
in facility A. Suppose facility B enters into the business because of capacity limitations
of A. Facility A wants to attract as many investments as possible and therefore gives volume
discounts, and announces that the costs for the remaining investor are lowered if one should
leave, to discourage the investment from going to B. On the other hand, B wants to encourage
both competitors to use its resources and, therefore, decreases costs for two new investors
but raises costs for a sole new investor.
Let the virtual negotiation process start with both competitors investing everything in
A ( p = q = 1). Both would realize that they cannot reduce their costs if they are not
prepared, at least temporarily, to alter their assignments to the advantage of the opponent
but with a disadvantage to themselves. So, X might decide to reduce its investment in A to
p = 0.9. This gives cx = 3.10 and c y = 2.69. In return, Y might respond by also reducing
its investment to q = 0.9. This gives cx = 2.84 and c y = 2.84. The two competitors might
now realize that this strategy of mutual cost reduction might be advantageous to both of
them, if they proceeded consistently. On the other hand, both competitors would also realize
that they can always return to the original situation where all investments go to A, and which
assures them a maximum cost of 3.00. Thus, X ’s next move may be to invest everything
in B( p = 0), which gives cx = 3.73 and c y = 1.83. If Y now sets q = 1, it would reach its
lowest cost; however, in this case, X could, in turn, set p = 1 and the negotiation process
would start all over again. On the other hand, Y may decide to invest everything in B(q = 0)
which gives cx = 2.00 and c y = 2.00, and the negotiation process may end with an efficient
compromise. This point is unstable. However, unless one of the competitors does not aspire
to have its costs below 2.00, there will be no reason for the two to continue the negotiation
process.

5.

Computer Implementation and Experimental Assessment

To test the concept of dynamic plots we developed a computer system that allows competitors
to perform such virtual negotiations. Figure 8 shows a screen view of the computer system.
The parameter values for different conflict situations are stored in the system. Changes in
assignments (i.e., changes of the p and q values, respectively) are made by moving a slide
bar. When one competitor is done with its move, or if it renounces its move, it can click on
the button “Done,” allowing the other to go on with its changes.
An experimental assessment of the virtual negotiation process was conducted with six
sets of conflicting parties. They all performed cases II, III, and IV of the conflict situations

78

BEROGGI AND MIRCHANDANI

Figure 8. Screen view of dynamic plot system; the software can be downloaded at: http://www.sepa.tudelft.nl/
webstaf/beroggi/user comp.html.

discussed in this paper (see figure 6). The two competitors, Ai and Bi , i = 1, . . . , 6, were
introduced to the concept of dynamic plots with an example to get accustomed to the use
of the software and the rules of the game. They were told that no verbal or non-verbal
communication was allowed. The objective was to minimize their individual costs at the
end of the conflict process. The results of the experimental assessment are shown in Table 1.
All of the six conflicting parties in Case I had an almost symmetric solution, with five
of them being almost efficient. Parties 1, 2, and 6 got close to the point F, and party 5 got
close to point E, and party 4 got close to the middle point on the curve between F 0 and E 0
(see figure 3). Party 3 did not get close to the efficient frontier. A3 ’s tactics was to explore
the space, while B3 used a rational approach to equalize costs. Their main reason to agree
on a settlement was that the solution was symmetric; this was more important to them than
reaching an efficient solution. By far the worst result in Case I was obtained by party 5. A3 ’s
rationale was to arrive at equal distributions, p = q, while B3 ’s tactic was to minimize costs.
Their conflicting tactics were the reason for the high number of moves; nevertheless, they
settled on the efficient frontier and they reached the second to best total costs (3.52) in Case I.
In Case II the competitors could not reach the efficient frontier with a Hill-DescendingApproach (see figure 6). Four of the five conflicting parties (note that conflicting party 3

79

A DYNAMIC PLOT APPROACH

Table 1.

Results of experiment.
Case II
Moves

Costs

Case III
Moves

1.47

Costs

Case IV
Moves

Total
costs

2

5.26

A1

Group DM Professor

4

10.85

B1

Group DM Professor

1.8

1.79

2

5.59

A2

Senior Policy Analyst

1.7

2.22

2

5.92

4

11.35

B2

Senior Policy Analyst

2

5.39

A3

Math Professor

2

15

3.27

3.58

1.79

Costs

24

5

1.84

3.78

3.77

10

4

1.55

1.93
8

3.58

2.04
2

3.83

11

2

5.97

4

11.61

B3

Math Professor

1.93

1.79

2

5.72

A4

Senior Policy Analyst

1.83

2.21

3

7.04

B4

Senior Game Theorist

1.76

A5

Ph.D. Student

1.85

B5

Professor

A6

Senior Game Theorist

7

65

Junior Policy Analyst

14

3.66

15

1.45

3.52

10

1.67
1.78
2

B6

3.59

3.62
1.84

1.77
3

3.25
1.48

6

6

13.25

3

6.21

2

3.85

4

7.52

2

3.67

2

5.55

4

10.87

2

5.32

Total
moves

36

24

21

36

75

11

Gray cells contain the number of moves made by the two competitors to arrive at their costs.
Bold-framed cells contain the sum of the cells above and below.
Italic numbers are the sum of all costs for each competitor.

did not compete for Case II since they used too much time to accomplish Case I) did
not reach the efficient frontier. Only conflicting party 5 did, and on a very straight track
too. Most of the conflicting parties realized where the efficient frontier was; in fact, even
the parties who did not settle on the efficient frontier were moving for a while along the
efficient frontier. The reason for conflicting party 5 to reach the efficient frontier was that
the two competitors exhibited politeness, cooperation, and mutual respect (also underlined
by the lowest number of total moves)—all characteristics which they are used to from
their professional relationship. To play down the fact that an emotional tie was the main
reason to agree on the settlement, they both rationalized that this was the only “reasonably”
possible solution—a hypothesis which must be rejected when looking at how the other
parties performed.
In Case III, all but one conflicting reached the symmetric but non-stable point in (2, 2).
The reason why party 4 did not arrive at this settlement was that A4 was never willing to
give in, in the hope to be rewarded by B4 in the next move. B4 realized how the moves

80

BEROGGI AND MIRCHANDANI

should be done to arrive at the point 2, 2 (see figure 6)) and he signaled to A4 that he is
willing to accept costs at his move, if he gets rewarded in A4 ’s next move. However, A4
did not react to those offers so they ended up at the non-efficient Nash equilibrium in (1, 1).
B4 , a game theorist, noted quite frustrated “Prisoner dilemma strikes again!”
This experimental assessment brought up two sets of findings. The first set refers to the
tactics of changing assignments, the second set refers to behavioral aspects of decision
making.
A) Tactical Findings
• The visualization of costs with dynamic plots helps competitors identify strategies to
arrive at a desired point or to keep the competitor from getting to their desired point.
• Dynamic plots support the competitors to find quickly Nash equilibria, efficient frontiers, and symmetric solutions.
• Dynamic plots help competitors to think in terms of resulting costs, rather than in
terms of assignments.
B) Behavioral Findings
• Competitors use dynamic plots to “communicate” non-verbally to one another, by
“pushing” beyond their objectives but still within recoverable ranges.
• Competitors take on leader-follower roles, where the first-mover was not necessarily
the leader.
• Competitors employ subjective utility functions which depend on their relationships
to each other, including politeness, respect, trust, and frustration.
The experimental assessment revealed the technical feasibility and behavioral relevance of
dynamic plots. However, more realistic settings will have to be devised in future research.
An important aspect is also to have competitors who do not know each other, or to give them
clear achievement goals so that they are forced to compete with each other more vigorously.
6.

Conclusions

We described and studied two-person nonlinear dynamic conflict situations, where two
users compete for two substitutable facilities and where the costs to a user for using a
facility depends on its usage as well as the usage by the other user. Conflict situations with
four different types of solution spaces were presented where the equilibria and the process
to reach a negotiated compromise solution have different characterizations. Examples of
such user competition arises in transportation, manufacturing, communication, and market
economics.
Using quite general user cost functions, we were able numerically to characterize the
(Nash) equilibria for various conflict situations. As shown theoretically and in other contexts
(e.g., Dubey, 1986) using user-optimal strategies, such as the hill-descending-approach, it
is easy to arrive at deficient equilibrium solutions. This happens in two of the four conflict
situations introduced in the paper. Hence, we developed a “virtual negotiation” process that

A DYNAMIC PLOT APPROACH

81

utilizes real-time information on potential decisions of the users for providing “dynamic
plots” through which the two users could negotiate. Here, each player indicates its possible
allocation decision and lets the other competitor know of its position via a computer screen
on which the two competitors’ cost trajectories are plotted. For our purpose, the dynamic
plots were exhibited via a software system as illustrated in figure 8.
The dynamic plot can be drawn for any cost function and each competitor can change
its assignments by moving a slide bar. The resulting costs are displayed in real-time. This
visualization of the cost space and the moves made by the competitors enhance the cognitive
process of finding an amenable solution that satisfies both competitors.
The experimental assessment with six groups of competing parties confirmed the technical and conceptual realism of dynamic plots. Future research will be centered on investigating the operationalization of this approach in a real-world setting. One could then study
the realism of this approach, the attitudes and behavior of different organizations, and the
types of solutions that they settle for or compromise on.
The types of dynamic plots that may arise in real investment allocation settings must
also be locked at. Perhaps, in most real situations, the equilibria are actually efficient and
the virtual negotiation may be of marginal benefit. However, the authors are currently
investigating other competitive “resource allocation” problems and preliminary findings
appear to indicate that indeed problems can arise where virtual negotiation will help to
achieve efficient solutions.
Acknowledgments
Pitu Mirchandani acknowledges the support received from the School of Technology, Policy,
and Management, Delft University of Technology, The Netherlands, where he was a Visiting
Professor in 1996.
References
Barros, O. and A. Weintraub (1986), “Spatial Market Equilibrium Problems as Network Models,” Discrete Applied
Mathematics, 13, 109–130.
Beroggi, G.E.G. (2000, forthcoming), “Dynamic Plots in Virtual Negotiations,” Computational and Mathematical
Organization Theory, 6(2).
Brewer, P.J. and R.P. Plott (1994), “A Binary Conflict Ascending Price Mechanism for Decentralized Allocation
of the Right to Use Railroad Tracks,” Working Paper, Division of Humanities and Social Sciences, California
Institute of Technology.
Dubey, P. (1986), “Inefficiency of Nash Equilibria,” Mathematics of Operations Research, 11, 1–8.
Economides, A.A. and J.A. Silvester (1991), “Multiobjective Routing in Integrated Services Networks: A Game
Theory Approach,” Proceedings of INFOCOM 1991, 1220–1225.
Florian, M. (ed.) (1984), Transportation Planning Models. North-Holland, Amsterdam, The Netherlands.
Korlis, Y.A. and A.A. Lazar (1995), “On the Existence of Equilibria in Noncooperative Optimal Flow Control,”
Journal of ACM, 42, 584–613.
Korlis, Y.A., A.A. Lazar and A. Orda (1997a), “Architecting Noncooperative Networks,” IEEE Journal on Selected
Areas in Communications, 13, 1241–1251.
Korlis, Y.A., T.A. Varvarigou and S.R. Ahuja (1997b), “Pricing Noncooperative Networks,” Working Paper, Bell
Laboratories, Lucent Technologies, Holmdel, New Jersey.

82

BEROGGI AND MIRCHANDANI

Luce R.D. and H. Raiffa (1985) (1957), Games and Decisions: Introduction and Critical Survey. Dover Publications, Inc., New York.
McCabe, K.A., S.J. Rassenti and V.L. Smith (1990), “Experimental Research on Deregulating Natural Gas Pipeline
and Electric Power Transmission Networks,” Working Paper, Center for Law and Economic Studies, Columbia
University School of Law, New York.
Nash, J.F. (1951), “Noncooperative Games,” Annals of Mathematics, 54, 286–295.
Orda, A., R. Rom and N. Shimkin (1993), “Competitive Routing in Multiserver Communication Networks,”
IEEE/ACM Transactions on Networking, 1, 510–521.
Osborne, M.J. and A. Rubinstein (1994), A Course in Game Theory. Massachusetts Institute of Technology Press,
Cambridge, Massachusetts.
Rapoport A. and M. Guyer (1966), “A Taxonomy of 2∞2 Games,” General Systems, 11, 203–214.
Rassenti, S.J., V.L. Smith and R.L. Buffin (1982), “A Combinatorial Auction Mechanism for Airport Time Slot
Allocation,” Bell Journal of Economics, 1982, 402–415.

Giampiero E.G. Beroggi is Associate Professor of policy analysis at the School of Technology, Policy, and
Management, Delft University of Technology, Netherlands. He holds a Ph.D. from Rensselaer Polytechnic
Institute (RPI), an M.S. in OR&Stat from RPI, and an M.S. in Civil Eng. from ETH-Zürich. His research deals with
operational risk management, decision modeling, and conflict resolution. He has published in scholarly journals,
including Management Science, European Journal of Operational Research, and Decision Support Systems.
Pitu B. Mirchandani is a Professor at the University of Arizona with joint appointments in Systems & Industrial
Engineering and in Electrical & Computer Engineering Department. He is also the Director of the recently
established ATLAS (Advanced Traffic and Logistics Algorithms and Systems) Research Center at the University
of Arizona. He has BS/MS degrees in Engineering from UCLA, a SM from MIT in Aeronautics and Astronautics,
and a ScD in Operations Research, also from MIT. His areas of technical expertise include optimization, logistics
(scheduling, location, and routing), stochastic networks, and design of real-time decision and control systems
for spatially distributed systems. He has over 70 publications including two books on Location Theory. Dr.
Mirchandani has been a principal investigator on numerous projects in logistics, transportation and manufacturing
systems, has been funded by various governmental organizations including NSF, USDOT, AzDOT, NYDOT,
NASA; several US cities; and many firms (GE, GM, IBM, Alcoa, Hughes, etc.).

Computers & Operations Research 36 (2009) 1423 – 1436
www.elsevier.com/locate/cor

Covering a line segment with variable radius discs
Alessandro Agnetisa , Enrico Grandeb , Pitu B. Mirchandanib,∗ , Andrea Paciﬁcic
a Università di Siena, Dipartimento di Ingegneria dell’Informazione, via Roma 56, 53100 Siena, Italy
b ATLAS Center, The University of Arizona, Tucson, AZ 85721, USA
c Università di Roma “Tor Vergata”, Dipartimento di Ingegneria dell’Impresa, via del Politecnico 1, 00133 Roma, Italy

Available online 23 February 2008

Abstract
The paper addresses the problem of locating sensors with a circular ﬁeld of view so that a given line segment is under full
surveillance, which is termed as the disc covering problem on a line. The cost of each sensor includes a ﬁxed component f, and a
variable component that is a convex function of the diameter of the ﬁeld-of-view area. When only one type of sensor or, in general,
one type of disc, is available, then a simple polynomial algorithm solves the problem. When there are different types of sensors, the
problem becomes hard. A branch-and-bound algorithm as well as an efﬁcient heuristic are developed for the special case in which
the variable cost component of each sensor is proportional to the square of the measure of the ﬁeld-of-view area. The heuristic very
often obtains the optimal solution as shown in extensive computational testing.
Scope and purpose
Problems of locating facilities to cover sets of points on networks and planes have been widely studied. This paper focuses on
a new covering problem that is motivated by an application where a line segment is to be kept under surveillance using different
types of radars. Using reasonable assumptions, some nonlinear covering problems are formulated. Efﬁcient exact algorithms and
heuristics are developed and analyzed for “easy” and “hard” cases, respectively.
䉷 2008 Elsevier Ltd. All rights reserved.
Keywords: Sensor location; Network covering problems; Mixed integer nonlinear programming

1. Introduction
In this paper we introduce and study a new locational decision problem: given a set of discs with variable radii with
costs depending on their radii and ﬁxed costs, ﬁnd a subset covering a unit length segment at minimum cost.
This problem was motivated by the following application, part of which was an industry-funded radar surveillance
project at The University of Arizona. We have a river over which we need to track possible activities of non-collaborative
or antagonistic objects or people (e.g., unauthorized boats, dangerous ﬂoating objects, swimmers, etc). For this purpose,
we need to locate a set of radars so that every point on the river is under surveillance by at least one radar. It is assumed
that the river can be modeled as a tree network consisting of line segments and that each radar has a ﬁeld of view deﬁned
by a radius and an angle of view (a pie-shaped coverage), with this angle large enough so that the coverage area may be
∗ Corresponding author. Fax: +1 520 621 6555.

E-mail address: pitu@sie.arizona.edu (P.B. Mirchandani).
0305-0548/$ - see front matter 䉷 2008 Elsevier Ltd. All rights reserved.
doi:10.1016/j.cor.2008.02.013

1424

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

approximated as a disc. Although the problem is relatively easily stated, the actual locational decision is complicated
due to several additional factors. Coverage depends not only on the river topology, radar type and power, but also on
several parameters such as width of river and obstacles over it, potentially forbidden areas where radars may not be
located, elevation of the potential location sites, and other characteristics associated with the physical environment,
dealing with, for example, the atmospheric and water conditions. Further details on this scenario and the scope of the
project are reported in [1].
This radar sensors location model relates to several broad classes of geometric locational problems. Many important
land-use planning decisions deal with locating facilities at sites, choosing from a given set of potential sites, so that
another given set of points are “covered” (i.e., they are within a speciﬁed distance from the closest located facility)
while optimizing a speciﬁed objective. Models for locating at points within continuous spaces, as well as locating
among set of discrete points or on a network, are widely used by geographers, regional scientists, network planners,
and others facing locational decisions problems which can be modeled as such covering problems (for a comprehensive
review of the literature see, for example, [2–5]). From the methodological viewpoint, the radars location problem relates
closely to the class of geometric covering problems where potential facilities and demand points are embedded on a
Euclidean plane, for which there is considerable literature. We brieﬂy review below results that are most relevant for
our application.
Problems related to covering with discs consists of identifying the minimum number of discs with ﬁxed radius to
cover a given set of points in the plane. A number of articles have appeared in the last three decades addressing this NPhard problem. In 1975, Chvátal introduced the Art Gallery Problem in [6], where one has to ﬁnd the minimum number
of watchmen (or cameras) needed to observe every wall of an art gallery room. The art gallery is assumed to be a n-sided
polygon, possibly with polygonal holes. It has been shown that an art gallery with h holes and n walls (including holes’
sides) requires at most (n + h)/3 watchmen (the bound is tight, see [7,8]). Another important paper, by Hochbaum
and Maas [9], presents polynomial approximation algorithms for different versions of geometric covering problems,
including covering by discs. Subsequently, several papers have appeared with improved approximation factors and
running times (see for example, [10,11]).
The problem of partial covering, also referred to as the robust k-center problem, is analyzed in [12], where computational complexity is discussed and approximation algorithms together with computational evidence of their performance
are provided.
The geometric Disc Covering Problem relates also to the deployment of wireless transmission networks. Surveys on
coverage problems dealing with this particular application can be found in [13,14]. We limit our literature review to a
few papers dealing with applications similar to the radar sensors location problem. Alt et al. [15] consider a problem
where a set of points demand connectivity. Their goal is to locate a set of sensors, modeled as discs with variable radii,
covering the demand points at minimum total cost. Each sensor’s transmission cost has the form f (r) = r  where r
is the covering radius of the sensor. Several results are presented in [15], including complexity characterization and
approximation algorithms. Although different scenarios are addressed, depending on possible restrictions on discs’
locations and demand points, their analysis is limited to discrete sets of points.
Article [16] addresses the problem of locating base stations for wireless communication where the demands and
potential facilities are represented by a discrete set of points and each station can broadcast up to a maximum distance.
A polynomial approximation scheme is given, together with complexity results. The following disc-covering geometric
problem applied to wireless communication is addressed by Franceschetti et al. [17]: given an inﬁnite square grid G,
determine how many discs, centered at the vertices of G, with a given radius r, are required, in the worst case, to
completely cover a disc with the same radius arbitrarily placed on the plane. The authors show that this number is
an integer in {3, 4, 5, 6} depending on r and on the grid spacing. In addition, they discuss the applicability of this
model to the design of approximation algorithms for facility locations on regular grids and to base station placement for wireless communication. The expected quality of service (level of surveillance) of a given sensor network
is analyzed in [18,19], where the authors exploit computational geometry and graph theoretic techniques, such as
Voronoi diagrams, Delaunay triangulation and graph search, to design exact polynomial algorithms for some special
cases.
Location of railway stops is another application of the Disc Covering Problem. In [20], the effect of introducing
additional stops in the existing railway network is addressed. The problem comprises of covering a set of points in the
plane by discs with the restriction that their centers have to lie on a set of line segments that represents the railway
tracks. A similar problem is addressed in [21], where the discs must be centered on two intersecting lines.

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

1425

The location problem we address in this paper is a special Disc Covering Problem in the following ways:
1. There are different types of facilities, which in our case are radar sensors, where the area covered by each radar is
a disc with a diameter x that depends on the power of the radar unit.
2. The cost ci of locating disc i includes a nonnegative ﬁxed cost fi and a variable cost, which may be approximated
by an homogeneous polynomial function gi (xi ). In particular, gi (xi ) is modeled as a second-order polynomial, that
is gi (xi ) = bi xi2 , where xi is the radius of the ﬁeld of view of radar i and bi is a positive real number.
3. A line segment with negligible width has to be covered by the discs. As it will be clear in Section 3, we may assume
that the segment has unit length with no loss of generality.
We refer to our problem as the Disc Covering Problem on a Line.
The paper is organized as follows. In Section 2 some preliminary results are presented for the case of identical disc
(radar) types and convex cost functions; in Sections 3–5 we focus on the problem with assumptions 1–3. In Section 3
a quadratic programming formulation is developed. A Lagrangean relaxation of the problem and a technique to solve
such a relaxation is also proposed. Section 4 presents a branch-and-bound algorithm for the problem: upper and lower
bounding techniques are illustrated and a branching strategy is discussed. Some computational results are given in
Section 5. Finally, some concluding remarks are made in Section 6.
2. Notation and preliminary results
We denote by Q the set of the q available discs (radars). For all i ∈ Q, at most one copy of disc i may be used for
covering the line segment and any power level is allowed so that we can have any disc coverage distance 0 xi 1.
These assumptions may appear restrictive for real applications but note that (i) usage of multiple copies of the same
disc type may be modeled by including in Q a suitable number of items with the same characteristics and (ii) if a limit
D exists on the coverage distance, then the problem may be decomposed by splitting the segment into pieces whose
lengths are not greater than D and solving the problems for each segment separately (this may be an effective heuristic
approach).
For any selected disc i ∈ Q, the coverage distance is the diameter of the disc xi ∈ R+ , and its contribution in the
total cost function is

0
if xi = 0,
ci (xi ) =
fi + gi (xi ) if xi > 0,
where gi (·) is convex with gi (0)=0 and the setup cost fi is nonnegative. Although, because of the ﬁxed cost component,
the cost function ci (xi ) is nonconvex in 0 xi 1, when the set of selected discs S, i.e., those for which xi > 0, is ﬁxed,
then total coverage is in fact convex and the problem of determining the covering diameters is easily solved using KKT
conditions (see Section 3).
Note that once xi is given for all i ∈ Q (we will have xi = 0 for those radars that are not selected), it is trivial to
ﬁnd the set of optimal locations: just align the discs so that they do not intersect and they cover the entire line. For this
purpose we choose the diameters in such a way that their sum is equal to the length of the line, which in our case is
equal to 1. An illustration of a feasible solution to our problem is given in Fig. 1.
We now present some simple results concerning the case when all available discs are of the same type, that is, for
all i ∈ Q and x > 0, ci (x) = c(x) is a general nonnegative convex function. To the best of our knowledge, these
results, though straightforward, are not present in the literature. However, it is worthwhile to point out that, differently

1 unit
Fig. 1. Example of a feasible solution.

1426

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

from [15], where the objective function is of the form r  and both the potential facility locations and the demand points
are discrete sets, we exploit the fact that we deal with a continuous line segment to obtain efﬁcient solutions for even
more general cost functions.
When the discs are all of the same type, our problem reduces to ﬁnding the optimal number k q of copies and the
optimal coverage area for each copy.
Proposition 1. When all the discs are of the same type having the cost functions ci (·) = c(·), for all i ∈ Q, if an optimal
solution consists of locating k discs, then there is one solution where each of the k discs has the same diameter.
Proof. Based on the convexity of c(x), for any k-uple of nonnegative numbers x1 , . . . , xk , with
k


xi = 1,

i=1

we have:
k·c

  
k
1

c(xi ).
k

(1)

i=1

Hence, the cost of locating k discs (of the same type) with equal diameters—that is, each disc covers an equal portion
of the line segment—does not exceed the cost of any other feasible solution that uses k discs. 
Proposition 1 clearly indicates the optimal locations of the discs since they need to be uniformly spaced over the line
segment.
The next natural question we need to ask is “What is an optimal number of such discs, that is the best value for k?”.
First we write c(x) = f + g(x) with f 0 and g(0) = 0. Note that we may install at most q discs of the same type on
the line. It is easy to observe that with zero setup costs (f = 0) the cheapest solution consists of installing the largest
possible number (q) of facilities.
A solution that uses k + 1 discs costs no more than a solution with k discs if and only if the following is true:


 
1
1
f + (k + 1) · g
k · g
.
(2)
k+1
k
If f = 0, the last inequality is always valid, because of the convexity of g(·). Therefore, it is cost-effective to locate
another disc if the additional setup cost does not exceed the gain in the variable costs.
The effective cost of locating k discs is
 
 
1
1
F (k) = kc
= kg
+ kf .
(3)
k
k
Since g(·) is convex,
  2 
1 j g 
j2 F
=
0.
2
jk
k 3 jk 2  1

(4)

k

Hence, there must be 1 k ∗ q such that
F (1)F (2) · · · F (k ∗ )

and F (k ∗ ) F (k ∗ + 1)  · · · F (q).

(5)

Therefore, since a binary search can be used to efﬁciently ﬁnd the k ∗ , the following proposition holds.
Proposition 2. When the q discs are all of the same type with cost functions ci (·) = c(·), for all i ∈ Q, the problem is
solvable in O(C log(q)) time, where C is the maximum computational effort for calculating c(1/k).

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

1427

3. Problem formulation
In this section we develop a quadratic programming formulation of the general problem where the q discs (radars)
may have different properties. Using the notation introduced in Section 2, the cost contribution of any disc i ∈ Q that
covers an area having diameter xi is a quadratic polynomial
ci (xi ) = fi + bi xi2
with fi 0, bi > 0. Then the location problem can be formulated as the following Mixed Integer Quadratic Program.

z∗ = min
fi yi + bi xi2
i∈Q

s.t.
(P )

xi yi for all i ∈ Q (c1)

xi = 1,
(c2)
i∈Q

q

x ∈ R+ ,

(c3)

y ∈ {0, 1}q .

(c4)

In the solution of P , y is the vector to indicate selected discs (radars) in Q where yi = 1 if disc i is used, yi = 0
otherwise. Constraints (c1) force the disc coverage diameter xi to be zero when the corresponding disc i is not selected
(and therefore the corresponding cost contribution is zero). Constraint (c2) is the coverage constraint that assures that
the whole line segment is covered.
As stated before, the unit length assumption does not introduce any loss of generality. It is clear that P can be
 where the line has length   = 1. Let I˜ be an instance of P
 where the cost coefﬁcients
equivalently used for a problem P
for the disc i are f˜i and b̃i . Then we can solve I˜ by solving an equivalent instance I of the unit length problem P having
cost coefﬁcients fi = f˜i and bi = 2 b̃i . If (x, y) is an optimal solution of I, then (x, y) is optimal for I˜.
In the remainder of the paper we propose methods to solve problem P and discuss the results of some computational
experiments to evaluate the performance of these methods.
Our ﬁrst observation concerns the existence of efﬁcient methods to ﬁnd the optimal coverage when the set S ⊆ Q of
selected discs (i.e. active radars) is given or known a priori. Under this assumption, the variables yi = 1 for all i ∈ S in
problem P and the resulting problem is easily solved by applying Karush–Kuhn–Tucker optimality (KKT) conditions.
In fact, this restriction of the problem can be written as
	




2
(RP) z(S) = min
fi + b i x i :
xi = 1; xi ∈ R+ , i ∈ S .
i∈S

i∈S

Problem RP is a convex
optimization problem. Deﬁne the following Lagrangean function (without loss of generality,

the constant term i∈S fi has been omitted in the objective function below):





L(x, , ) =
bi xi2 +  1 −
xi −
i x i .
i∈S

i∈S

i∈S

The KKT conditions, for the triple (x ∗ , ∗ , ∗ ), are
∇x L(x ∗ , ∗ , ∗ ) = 0q ,

xi = 1,
i∈S

∗ x ∗ = 0,
T

x ∗ 0q ,
∗ 0q .

1428

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

It follows from xi∗ > 0 that ∗i = 0 for all i ∈ S. Then,
∗ =

1


j ∈S

1
2bj

and
1
∗

2b
i
xi∗ =
=
,

1
2bi
j ∈S
2bj

i∈S

satisfy the KKT conditions and, therefore, are a global optimum for problem RP.
Although coverage diameters may be computed in a closed-form, choosing the subset S ⊆ Q of active radars is a
tedious computational task. The branch-and-bound algorithm described in Section 4 relies on a dual bound estimation
which is developed in the next subsection.
3.1. Lagrangean relaxation of P
We will use Lagrangean relaxation to obtain a lower bound (LB) on z∗ , the optimal solution value of problem P .
Relaxing constraints (c1) of P using nonnegative Lagrangean multipliers i , i = 1, . . . , |Q|, we obtain the following
problem:

zLRP () = min
(fi − i )yi + bi xi2 + i xi
i∈Q

s.t.

(LRP)



i∈Q

xi = 1

(c5)

q

x ∈ R+ ,

(c6)

y ∈ {0, 1}q .

(c7)

Problem LRP, a relaxation of P for any  0q , is decomposable since optimal values for the yi variables are independent
of the values of the xi variables. In particular, we may choose the following optimal values for y:

1 if fi < i
∗
yi =
for all i ∈ Q.
0 if fi i
The remaining convex program, which depends on the x variables only, is

zLRP 	 () = min
bi xi2 + i xi
i∈Q

(LRP	 )

s.t.



i∈Q

xi = 1,
q

x ∈ R+ ,
and therefore
zLRP () = zLRP 	 () +



(c8)
(c9)

(fi − i )yi∗ .

i∈Q

In order to solve problem LRP	 , we deﬁne the following Lagrangean function, where we use multiplier  ∈ R for
q
constraint (c8) and multipliers  ∈ R+ for nonnegativity constraints (c9):
⎞
⎛


L (, ) = min
(bi xi2 + i xi − i xi ) +  ⎝1 −
xi ⎠ .
i∈Q

i∈Q

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

1429

Then the KKT conditions are
∇xi L (x ∗ , ∗ , ∗ ) = 2bi xi∗ + i − ∗i − ∗ = 0

xi∗ = 1,

for all i ∈ Q,

(6)
(7)

i∈Q

∗i xi∗ = 0
xi∗ 0,

for all i ∈ Q,
∗i 0

(8)

for all i ∈ Q.

(9)

From (6) we have
xi∗ =

1 ∗
( + ∗i − ∗i )
2bi

for all i ∈ Q.

(10)

In order to ﬁnd values for xi∗ , ∗ , ∗ that satisfy KKT conditions (6)–(9), let S (so far unknown) include the set of
indices that correspond to positive covering diameters in the optimal solution, that is S = {i ∈ Q : xi∗ > 0}. Given S,
we have from (8) that ∗i = 0 for all i ∈ S and we obtain the following relations:
xi∗ =

1 ∗
( − i ),
2bi

∗i = 0 for all i ∈ S,

(11)

∗i = i − ∗ for all i ∈ Q\S.

xi∗ = 0,

(12)

Furthermore, from (11) and (12), we have that
xi∗ > 0 ⇒ ∗ > i

for all i ∈ S,

(13)

∗i 0 ⇒ ∗ i

for all i ∈ Q\S.

(14)

Suppose now, without loss of generality, that the i values are listed in nondecreasing order. From relations (13) and
(14), we have
 2  · · · h < ∗  h+1  · · · q .
1





S

(15)

Q\S

{1, . . . , h∗ },

Hence, S has the form S =
(12)):
 ∗ i
1 + hi=1
2bi
> 0.
∗ =
h∗ 1
i=1
2bi

h∗ q, and we obtain the following expression for ∗ (using Eqs. (7), (11),

(16)

Since the feasible region of LRP	 is a closed convex set and its objective function is convex, this problem admits a
(ﬁnite) optimal solution. In particular any local optimum that satisﬁes the KKT conditions is an optimal solution for
LRP	 and vice versa. Therefore, there must exist an optimal solution x ∗ of LRP	 , together with corresponding optimal
q
multipliers ∗ ∈ R,  ∈ R+ , that satisfy the KKT conditions (6)–(9).
Therefore, once the i are arranged in nondecreasing order, a set of indices S = {1, . . . , h} (1 h q) necessarily
exists such that (15) is satisﬁed, and expressions (11), (12), and (16), return an optimal solution (x ∗ , ∗ , ∗ ) to LRP	 .
We may ﬁnd h, that is, the set S = {1, . . . , h} of indices corresponding to selected discs, with a O(log q) binary
search. Because it is the sum of at most q elements, it is possible to compute ∗ by (16) in O(q) time. The same time
is required to compute the values xi∗ , which are at most q and each is computable in constant time (using expression
(11)). Additional O(q) steps are necessary to determine the value for the y variables. Hence the following proposition
holds:
q

Proposition 3. Given a set of q nonnegative Lagrangean multipliers  ∈ R+ , the solution of the Lagrangean problem
LRP	 can be found in time O(q log q), which is the computational cost of ordering the multipliers.

1430

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

Recalling that
zLRP () = zLRP 	 () +



(fi − i )yi∗ ,

i∈Q

we observe that a solution of problem LRP—and therefore a LB for the optimal solution value of P —can be found in
time O(q log q).
4. An exact algorithm for P
In this section, we develop a branch-and-bound algorithm that ﬁnds an optimal solution of P . This implicit enumeration scheme exploits the LBs obtained by a subgradient optimization algorithm described in Section 4.1 and
upper bounds (UBs) by an efﬁcient local search-based heuristic (described in Section 4.2). Branching and subproblem
solution strategies are discussed in Section 4.3.
4.1. LB via a subgradient algorithm
q

For any  ∈ R+ , the optimal solution value zLRP () of LRP provides a LB on the value of the optimal solution value
of P . We are now interested in obtaining the best (largest) LB by solving the following Lagrangean Dual Problem:
q

∗
= zLRP (∗ ) = max{zLRP () :  ∈ R+ }.
(DP) zLRP

In our approach, the solution of DP is obtained by a standard subgradient optimization algorithm that is summarized in
Fig. 2. The proposed Lagrangean relaxation method not only provides the LBs that we use in our enumeration scheme
but it is also exploited in an efﬁcient heuristic procedure which is presented in the next section.
4.2. UB via a heuristic algorithm
The basic idea for this heuristic algorithm based on the Lagrangean Relaxation is to obtain a feasible solution of
LRP by establishing all the discs (radars) corresponding to xi > 0 (i.e., i ∈ S) and, possibly, removing unused discs
(i.e., switching off all the unnecessary radars) (i ∈
/ S).
In general, given a subset S ⊆ Q, we may easily compute feasible values for the coverage diameters xi , for all i ∈ S,
using the KKT conditions—as described in Section 3. Note that the values xi provided by the solution of LRP	 are

Fig. 2. Subgradient algorithm for DP .

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

1431

Fig. 3. Heuristic procedure for P .

feasible but, in general, they may not be optimal since the corresponding set of discs S may not be optimal. We may
further reﬁne the set S using a simple local search which exploits the KKT conditions to ﬁnd the cheapest location and
coverage for a given set of selected discs. Fig. 3 summarizes the heuristic.
4.3. Exact branch-and-bound algorithm
In this section, we present a branch-and-bound algorithm for P that uses the lower and upper bounds developed
above in Sections 4.1 and 4.2.
4.3.1. Solution strategy
First, at the root node of the branch-and-bound tree we use an UB using the heuristic shown in Fig. 3
In the branch-and-bound tree, each node  represents a subproblem that is deﬁned by (i) a set T of selected discs
(i.e. active radars which must be ON) in the solution, that is T = {i : yi = 1; i = {1, . . . , q}} ⊆ Q, (ii) a set of discs
that cannot be in the solution (i.e. radars that must be OFF) and (iii) a set of discs that are not yet decided upon (i.e.,
radars that are not yet ﬁxed to ON or OFF). If a radar is OFF, we consider the corresponding disc deleted from the set
of available discs (radars) for that speciﬁc subproblem. Let Q() be the set of available discs at node (subproblem) .
Then the generic subproblem may be formulated as follows:


min
(fi yi + bi xi2 ) +
(fi + bi xi2 )
i∈Q()\T

i∈T

s.t. xi yi for all i ∈ Q()\T

(P (T , ))
xi = 1,
i∈Q()

xi 0

for all i ∈ Q(),
yi ∈ {0, 1} for all i ∈ Q()\T ,

(c1 )
(c2 )
(c3 )
(c4 )

1432

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

Again, similarly to what was done in Section 3.1 for problem LRP, relaxing constraints (c1 ) in a Lagrangean fashion,
using multipliers i with i = 0 for all i ∈ T , we obtain problem LRP(T , ):
⎫
⎧
⎬
⎨ 


(bi xi2 + i xi ) +
(fi − i )yi +
fi : (c2 ), (c3 ) and (c4 )
min
⎭
⎩
i∈Q()

i∈Q()\T

which, in turn, is equivalent to
⎧
⎫
⎨ 
⎬
min
(bi xi2 + i xi ) : (c2 ), (c3 ) +
⎩
⎭
i∈Q()

i∈T


i∈Q()\T :fi <i

(fi − i ) +



fi .

i∈T

Neglecting the last two constant summations, we have a problem in the x variables which is a special instance of LRP	
deﬁned in Section 3.1. Thus, a LB can be computed at each node by solving the Lagrangean dual of the corresponding
problem LRP(T , ), by means of the procedure summarized in Fig. 2.
4.3.2. Branching strategy
At node  of the enumeration tree, we branch on a binary variable yi , i ∈ Q()\T , splitting subproblem  into two
new subproblems 	 and 		 . Disc i is selected in 	 (i.e. yi = 1 and T := T ∪ {i}) and it is deleted in 		 (i.e. yi = 0 and
Q(		 ) := Q()\{i}).
Let ∗i be the optimal values for the multipliers in the solution of the Lagrangean dual, and xi∗ , yi∗ , i ∈ Q()\T the
optimal variable values obtained for LRP(T , ). The branching rule is to branch on a variable yi , such that yi∗ = 0 and
xi∗ > 0. If such a variable does not exist (i.e., x ∗ and y ∗ are feasible for the subproblem ) then branch on variable yi∗ ,
such that yi∗ = 1, xi∗ < 1 and ∗i > 0. If such a variable does not exist then ∗i (yi∗ − xi∗ ) = 0, for all i ∈ Q()\T and,
therefore, the x ∗ and y ∗ are (feasible and) optimal for subproblem . The corresponding node in the enumeration tree
is then fathomed.
5. Computational experiments
The design of the computational experiments is described in the next subsection while the computational results are
discussed in Section 5.2. All the results reported in this section refer to tests performed on a 3.00 GHz Pentium IV,
1024 MB RAM, running Windows XP. The algorithms have been coded in C + +. See [22] for more details.
5.1. Design of experiments
Any instance of Problem P is characterized by a pair of vectors with q components (b, f ), representing discs’
variable and ﬁxed costs.
We say that a disc i dominates disc j if (bi bj ), (fi fj ), and (bi , fi )  = (bj , fj ). In our experiments no disc pair
exists such that one is dominated by the other, since there is no sense in considering dominated disc types in Q.
Therefore, we impose the following cost relations:
b1 b2  · · · bq

and f1 f2  · · · fq .

We start with a special class of instances (“base class”) having the following properties:
• (bi  = bj ) and (fi  = fj ), for all 1 i < j q.
• On the average, bi+1 ≈ bi + 1 for all 1 i < q.
• bi = fq−i+1 , for all 1 i q (to exclude dominated cases).
We generate all the instances used in the experiments by suitable modiﬁcations of a randomly generated base class
instance. In particular, any instance is identiﬁed by the four integers (q, s, t, u), where
q: The number of available discs which determines the size of the instance.
s: Ampliﬁcation factor by which b of the base class instance is multiplied. For instances with this parameter, on the
average, b ≈ {s, 2s, . . . , qs}.

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

1433

Table 1
Preliminary test-set results.
q

150

200

350

400

500

CPU time

1217.97 s

2544.76 s

∼ 3.5 h

∼ 15.0 h

> 16 h

t: The parameter that characterizes the vector of setup costs f, which is obtained using t 1 as a multiplication factor
of the b vector determined as above: on the average, fq−i+1 ≈ tbi for instances with this parameter.
u: The parameter that identiﬁes the conﬁguration for the test instance where a suitable subset of the cost coefﬁcients
bi , or the setup costs fi , or both, have the same value. 10 conﬁgurations were deﬁned and u was labeled 0, 1, . . . , 9
where u = 0 deﬁnes the base class where bi and fi all have different values. For example u = 2 deﬁnes the class
where the fi for the selected discs in the optimal base class solution are set to the maximum f value in the base
class. Parameter u attempts to make systematic changes with respect to fi and bi values in various instances.
While some other u labels are described later in this paper, see [22] for more details on the other u labels.
As an example, the class (50, 1, 100, 0) refers to instances with 50 discs, all different types (since u=0), cost coefﬁcients
bi as in the base class, and setup costs fi ampliﬁed by a factor t = 100.
A set of preliminary tests were performed to determine the largest instances that our algorithm is able to solve
optimally, in order to design our experiments. Results are reported in Table 1. All the instances of this preliminary
test-set belong to the class (q, 1, 1, 0). The branch-and-bound algorithm solved instances up to q = 400 in less than
16 h. No instance with q = 500 was solved within the same time limit.
Based on these preliminary results, we planned our experiments with the following sizes: q ∈ {10, 25, 50, 100, 200,
350, 400}. Maximum running time was set to 1 h (CPU time), except for the case q = 400 where there was no timeout
requirement. For each class except the q = 400 case (for which only one instance was tested), 10 random instances
were generated and the following average quantities were tracked:
•
•
•
•
•

CPU time.
Number of nodes in the enumeration tree.
Depth of the enumeration tree.
UB at the root node, which is obtained via our heuristic of Fig. 3
Optimal solution value, if any. (A minus “–” symbol is shown when the optimum is not reached within the time
limit.)
• Best LB available after 1 h.
• Percentage gap (U B − LB)/U B.
5.2. Results and analysis
Table 2 summarizes the results of the experiments. Each row shows, in order, the quantities of the above list, for one
class of instances. Class name is reported in the ﬁrst column where an asterisk “∗ ” denotes that, in at least one instance
of the class, the algorithm did not reach the optimal solution value within the time limit (i.e. CPU time greater than
3600 s). The table also gives the initial “gap” between the UB and the LB at the root node, computed as (UB − LB)/UB.
The results for classes with u = 3, 4, 6, 8, 9 are not reported in Table 2 for the sake of brevity. For these classes, the
performance of the algorithm is indeed comparable or even better than those reported.
Note ﬁrst the excellent performance of the heuristic: in all the experiments the value found by this procedure (UBroot )
equals the optimal value (opt.) found by the branch-and-bound algorithm.
Now a few comments on the results:
1. Not surprisingly, branch-and-bound computational time is strictly related to the enumeration tree size: Table 3
shows strong positive correlation of CPU time with the number of nodes in the enumeration tree.
2. For a given number of discs q, we note that the CPU time does depend on the particular cost conﬁguration, that is,
on the particular pair (s, t). The most difﬁcult instances have t = 1 (i.e., bi ≈ fq−i+1 ); and, vice versa, the larger
the t in comparison to s, the faster the computation.

1434

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

Table 2
Experiments results.
Instance (q, s, t, u)

CPU time (s)

Nodes’ #

Depth

UBroot

Opt.

LB

Gapa (%)

10,10,1,0
10,10,1,1
10,10,1,5
10,1,100,0
10,1,100,1
10,1,100,5
100,10,1,0
100,10,1,1
100,10,1,5
100,1,100,0
100,1,100,1
100,1,100,5
200,10,1,0
200,10,1,1
200,10,1,5*
200,1,100,0
200,1,100,1
200,1,100,5
350,10,1,0*
350,10,1,1
350,10,1,5*
350,1,100,0
350,1,100,1
350,1,100,5
400,1,1,0

1.547
1.469
1.562
0.063
0.062
0.047
464.81
464.25
932.47
31.937
32.125
33.047
2586.01
2866.91
> 3600
208.7
189.281
206.38
> 3600
959.97
> 3600
985.38
959.97
964.44
36705.2

29
27
37
0
0
0
987
1009
1955
135
131
131
2737
2527
> 2597
341
361
337
> 2021
1827
 1289
719
703
673
17 373

10
10
10
0
0
0
100
100
96
67
65
65
200
200
 195
169
174
167
 345
345
 344
350
350
328
400

77.368
80
110
506
110
506
345.96
348.35
496.22
200
200
596
539.14
540.8
737.98
300
300
696
775.7
776.91
1022.49
450
450
846
84.71

77.368
80
110
506
110
506
345.96
348.35
496.22
200
200
596
539.14
540.8
–
300
300
696
–
776.91
–
450
450
846
84.71

44.8017
46.696
75.526
506
110
506
135.31
135.74
172.64
187.44
187.5
584.92
189.31
189.66
227.93
241.54
241.67
639.7
234.2
234.74
285.4
301.56
298.51
700.2
24.28

42.01
41.63
31.64
0
0
0
60.89
61.03
65.21
6.28
6.25
1.86
64.89
64.93
69.12
19.49
19.45
8.09
69.81
69.79
72.09
32.99
33.67
17.23
71.34

a Gap

is computed as the initial (UB − LB)/UB, where LB is the (initial) lower bound at the root node.

Table 3
Correlation coefﬁcient between CPU time and number of nodes of the enumeration tree.
q

10

25

50

100

nodes

0.982

0.998

0.999

0.999

3. Classes with u = 2 and 5 are the hardest. Parameters are chosen so that ﬁnding the set of selected discs becomes
more difﬁcult. For any instance I of the base class, we build the corresponding u = 5 instance I 	 as follows. Let S
/ S, bi	 = max{b1 , . . . , bq } if
be the set of selected discs in the optimal solution of I. The costs in I 	 are: bi	 = bi if i ∈
	
	
i ∈ S. Analogously fi = fi if i ∈
/ S, fi = max{f1 , . . . , fq } if i ∈ S.
The u = 2 class is designed similarly but with bi	 = bi , for all i = 1, . . . , q. (Experimental results for the u = 2 class
were similar to those of the u = 5 class; therefore Table 2 reports only the latter.)Fig. 4
4. shows the CPU time cumulative distribution. The histogram was obtained empirically over 90 instances (with
q = 25): 80% of the instances are solved in a time smaller than 2.6 s. while the largest CPU time is an order of
magnitude higher (17.4 s.).
We noted previously that ﬁxed costs are related to the choice of the subset S and they heavily affect the computational
effort required to optimally solve an instance. An evidence of this fact is illustrated in Table 4 where the results of the
experiments with q, s, t = 10, 1, 1 are compared for three values of u (u = 0, 1, 3). Note that the u = 0 class is the base
class.
Given an instance I of the base class, we build the corresponding u=1 (u=3, respectively) instance I 	 as follows. Let
S be the set of selected discs in the optimal solution of I. The costs in I 	 are: bi	 =max{b1 , . . . , bq } (fi	 =min{f1 , . . . , fq },
respectively) for i ∈ S. All the other parameters remain equal to those in the base class.

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

1435

1
0.9

% of instances

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.2

2.6

5.6

10.8

15.4 17.4

Seconds
Fig. 4. CPU time cumulative distribution (q = 25, time in seconds).
Table 4
Set S ∗ (optimal set) response to fi and bi variations for q = 10 and u = {0, 1, 3} .
Instance (q, s, t, u)

S∗

Opt. radii xi , i ∈ S ∗

10,1,1,0
10,1,1,1
10,1,1,3

{9, 10}
{9, 10}
{7, 8, 9}

{0.526, 0.474}
{0.5, 0.5}
{0.377, 0.330, 0.293}

When the bi are varied (compare classes with u = 0 and 1 in Table 4) the optimal solutions are slightly different but
the set of selected radars is the same. However, when the fi vary (compare classes with u = 0 and 3) the two optimal
solutions drastically differ from each other: there are three discs selected instead of two.
6. Conclusions and future work
In this paper we introduced and addressed the problem of covering a single line segment with radar sensors having
a circular ﬁeld of view. When the sensors are required to have identical radius, a simple polynomial search solves
for optimal radius and number of sensors. When the sensors are modeled with variable diameter discs the problems
becomes hard. We provided an exact solution algorithm which is based on a Lagrangean relaxation and a subgradient
algorithm to ﬁnd a LB (see Fig. 2). A feasible solution is provided by the heuristic summarized in Fig. 3. These bounds
were exploited to design a branch-and-bound algorithm. Extensive computational testing, based on approximately 400
experiments, showed that the developed heuristic performs very well; the UBs were equal to the optimal solution
whenever the latter was known (see Table 2). The experiments also show that setup costs play a crucial role both in
computational effort and attainment of the optimal solution set.
Several directions for future work are being pursued. The two-arc network and planar tree network cases are being
investigated (both for single and multiple discs types, for ﬁxed and variable radius). Since discs can be located both
on the arcs and on the plane, these are mixed network–planar problems and the development of locational models and
algorithms is indeed very challenging.
Acknowledgments
The authors wish to acknowledge the support of the ATLAS Center at the University of Arizona where most of this
research was conducted and the support of Waveband Inc. that partially funded this effort through its SBIR Contract
ARMY03-T18 with the US Army.

1436

A. Agnetis et al. / Computers & Operations Research 36 (2009) 1423 – 1436

The authors also gratefully acknowledge the helpful comments and constructive suggestions of the two anonymous
referees.
References
[1] Paciﬁci A, Mirchandani P, Mecoli M, Agnetis A. Locational decisions for barge-tracking radars, Technical Report, The A.T.L.A.S. research
center, 2004.
[2] Ghosh A, Rushton G. Spatial analysis and allocation–location modeling. New York: Van Nostrand Reinhold Company; 1987.
[3] Kolen A, Tamir A. Discrete location theory: covering problems. New York: Wiley; 1990 p. 263–304 [chapter 6].
[4] Love RF, Morris JG, Wesolowsky GO. Facility location: models and methods. New York: North-Holland Publishing Company; 1988.
[5] Mirchandani PB, Francis RL. Discrete location theory. New York: Wiley; 1990.
[6] Chvátal V. A combinatorial theorem in plane geometry. Journal of Combinatorial Theory 1975;18:39–41.
[7] Hoffmann F, Kaufmann M, Kriegel K. The art gallery theorem for polygons with holes. In: 32nd Annual symposium on foundations of computer
science, San Juan, Puerto Rico, October 1991, p. 39–48.
[8] O’Rourke J. Art gallery theorems and algorithms. Oxford: Oxford University Press; 1987.
[9] Hochbaum DS, Maas W. Approximation schemes for covering and packing problems in image processing and VLSI. Journal of the ACM
1985;32(1):130–6.
[10] Brönnimann H, Goodrich MT. Almost optimal set covers in ﬁnite VC-dimension. Discrete Computational Geometry 1995;14:463–79.
[11] Franceschetti M, Cook M, Bruck J. A geometric theorem for approximate disk covering algorithms. Technical report, California Institute of
Technology, 2001.
[12] Xiao B, Zhuge Q, Zhang Y, Sha EH-M, Algorithms for disk covering problems with the most points. In: Proceedings of the IASTED international
conference on parallel and distributed computing and systems (IASTED PDCS), Marina del Ray, CA, November 2003, p. 541–6.
[13] Huang C-F, Tseng Y-C. A survey of solutions to the coverage problems in wireless sensor networks. Journal of Internet Technology 2005;6:
1–8.
[14] Wang B. A survey on coverage problems in wireless sensor networks. Technical report, ECE Department, National University of Singapore,
2006.
[15] Alt H, Arkin EM, Brönnimann H, Erickson J, Fekete SP, Knauer C, Lenchner J, Mitchell JSB, Whittlesey K. Minimum-cost coverage of point
sets by disks. In: Proceedings of the 22nd annual ACM symposium on computational geometry. June 5–7, 2006. p. 449–58.
[16] Galota M, Glaßer C, Reith S, Vollmer H. A polynomial-time approximation scheme for base station positioning in UMTS networks. In:
Proceedings of the 5th international workshop on discrete algorithms and methods for mobile computing and communications. 2001. p. 52–9.
[17] Franceschetti M, Cook M, Bruck J. A geometric theorem for network design. IEEE Transactions on Computers 2004;53:483–9.
[18] Meguerdichian S, Koushanfar F, Potkonjak M, Srivastava MB. Coverage problems in wireless ad-hoc sensor networks. In: INFOCOM 2001.
20th annual joint conference of the IEEE computer and communications societies, vol. 3, Anchorage, AK, USA, 2001. p. 1380–7.
[19] Li X-Y, Wan P-J, Frieder O. Coverage in wireless ad hoc sensor networks. IEEE Transactions on Computers 2003;52:753–63.
[20] Hamacher H, Liebers A, Schöbel A, Wagner D, Wagner F. Locating new stops in a railway network. Electronic Notes in Theoretical Computer
Science 2001;50:11.
[21] Mammana MF, Mecke S, Wagner D. The station location problem on two intersecting lines. Electronic Notes in Theoretical Computer Science
2003;92(1):12.
[22] Grande E. Localizzazione di radar per il monitoraggio di bacini ﬂuviali (english translation: Radar locations for river monitoring). Master’s
thesis, University of Rome “Tor Vergata”, Italy, 2005.

This article was downloaded by: [149.169.221.39] On: 22 June 2017, At: 11:32
Publisher: Institute for Operations Research and the Management Sciences (INFORMS)
INFORMS is located in Maryland, USA

Transportation Science
Publication details, including instructions for authors and subscription information:
http://pubsonline.informs.org

Abstracts for the 2002 Transportation Science Section
Dissertation Prize Competition
Pitu B. Mirchandani,

To cite this article:
Pitu B. Mirchandani, (2003) Abstracts for the 2002 Transportation Science Section Dissertation Prize Competition.
Transportation Science 37(2):223-229. https://doi.org/10.1287/trsc.37.2.223.15246
Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions
This article may be used only for the purposes of research, teaching, and/or private study. Commercial use
or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher
approval, unless otherwise noted. For more information, contact permissions@informs.org.
The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness
for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or
inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or
support of claims made of that product, publication, or service.
© 2003 INFORMS
Please scroll down for article—it is on subsequent pages

INFORMS is the largest professional society in the world for professionals in the fields of operations research, management
science, and analytics.
For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org

Downloaded from informs.org by [149.169.221.39] on 22 June 2017, at 11:32 . For personal use only, all rights reserved.

Abstracts for the 2002 Transportation
Science Section Dissertation
Prize Competition
Pitu B. Mirchandani

Chair 2002, TSS Dissertation Prize Committee, University of Arizona, Tucson, Arizona 85721

T

he Dissertation Prize awarded by the Transportation Science Section (TSS) of INFORMS is the
most prestigious award for new scholars in our ﬁeld.
For the most recent award, eligible dissertations were
those completed between June 1, 2001, and May 31,
2002, in the general area of transportation science. A
thesis must be nominated by the dissertation supervisor for it to be considered for the prize.
The competition draws entries from premier transportation programs around the world. The committee received 12 submissions, all of excellent caliber. The TSS Dissertation Prize Committee that carefully reviewed all submissions consisted of Professor
Patrick Jaillet, Massachusetts Institute of Technology;
Professor Oli Madsen, Technical University of Denmark; Professor Srinivas Peeta, Purdue University;
Professor Michael Zhang, University of California at
Davis; and myself.
Most of the entries this year were excellent. After
considerable review and deliberation, both via e-mail
and conference call, the committee, with difﬁculty,
narrowed down the ﬁeld to two. The committee was
of the opinion that these two were of equal caliber
and decided to award them both the ﬁrst prize. The
awardees are Dr. Alvin Lim from John Hopkins University and Dr. Iris Vis from Erasmus Universiteit Rotterdam. The awards were announced and presented
at the 2002 INFORMS meeting in San Jose, California.
Below are the abstracts of the 12 submissions. The
ﬁrst two abstracts are of the winning dissertations,
organized in alphabetical order by the authors’ last
names. The other 10 abstracts are of the nominated
dissertations, also listed in alphabetical order by the
authors’ last names. The abstracts indicate the depth
and diversity of the type of research being conducted
by the brightest new scholars in our ﬁeld.

0041-1655/03/3702/0223$05.00
1526-5447 electronic ISSN

FIRST PRIZE (shared)

Transportation Network Design Problems: An
MPEC Approach
Alvin C. Lim

T

he process of transportation network design has
become a signiﬁcant part in the planning and
management of such networks. Utilization of a transportation network involves the interaction of two
groups of people—the network’s managers, and its
users—each having its own objectives. To some
extent, the criteria by which network users choose
their routes do not coincide with society’s goal of utilizing the network efﬁciently. In an attempt to maximize the beneﬁt of a network to society, the network
managers are generally concerned with minimizing
a design cost (i.e., an aggregate cost for construction, operation, maintenance, etc.). In contrast, each
network user would select what he or she perceives
as a least cost travel path leading to a state of user
equilibrium. A comprehensive network design process incorporating such user behavior will generally
require solving mathematical programs with equilibrium constraints (MPECs).
In this study, we develop a uniﬁed model of some
important transportation network design problems by
treating them as MPECs. Incorporated into this model
are the capacity enhancement problem, the congestion toll pricing problem, the signal setting problem,
and the origin-destination matrix adjustment problem. In place of various currently employed heuristics, we systematically apply certain MPEC algorithms to solve these problems, and we verify certain
conditions essential for the algorithms’ convergence.
Applied to numerical examples that have appeared in
the literature, these MPEC algorithms produce better
solutions than those produced by previously reported
methods.
Transportation Science © 2003 INFORMS
Vol. 37, No. 2, May 2003, pp. 223–229

Downloaded from informs.org by [149.169.221.39] on 22 June 2017, at 11:32 . For personal use only, all rights reserved.

Dissertation Abstracts

To solve large scale versions of the problems, we
propose a conceptual algorithm based on delayed
path generation and using the MPEC framework.
This algorithm takes advantage of the promising
MPEC approach to the network design problems
while avoiding the need to enumerate all the paths in
a network. Computational examples suggest that the
resulting path-generation approach performs well.

In Part III simulation studies are performed to test
the concepts developed in Parts I and II in the context of container terminals. It is demonstrated that the
results of these studies can be helpful in the design of
container terminals.

The thesis supervisor was Jong-Shi Pang, John Hopkins
University.

Load Plan Selection for Package Express Fleets

The thesis supervisors were Rene de Koster and Rommert
Dekker, Erasmus University, Rotterdam.

David E. Benson

FIRST PRIZE (shared)

Planning and Control Concepts for Material
Handling Systems
Iris F. A. Vis

S

upply chains are under constant pressure to operate efﬁciently. Some of the slowest logistics activities in supply chains occur within the nodes of supply chains, such as warehouses and container terminals. Transshipment and internal transport of products belong to these types of activities. The objective
of this thesis is to develop new planning and control
concepts for internal transport equipment using techniques from operations research.
Part I of this thesis discusses automated guided
vehicles (AGVs). The problem discussed is the determination of the number of vehicles required to transport a set of loads. In Chapter 3 the problem is formulated as a network problem. A minimum ﬂow algorithm is developed to ﬁnd the minimum number of
directed paths (i.e., vehicles) covering each node in
exactly one path in polynomial time. An extension of
this problem is the case in which each load has a time
window in which the transport should start. In Chapter 4 this problem is formulated as an integer linear
programming model and as a set partitioning model.
Storage and retrieval machines (SRMs) take care of
the storage and retrieval of unit loads, such as pallets and containers. A storage area with both storage
and retrieval operations at both sides is examined.
In Part II a new dynamic programming algorithm is
developed to sequence storage and retrieval requests
for a SRM operating in a number of parallel aisles
in polynomial time. This solution method has been
inspired by the algorithm of Ratliff and Rosenthal.
However, due to the speciﬁc properties of this problem, it differs in many ways.

224

A

loader serves two roles during the loading process for package delivery. First, given a load
plan, which is an assignment of regions to delivery
vehicles, the loader takes each package to be delivered and one-by-one reads the address and assigns it
to the proper vehicle, according to the load plan. Second, the loader can decide whether or not to change
the load plan during the loading process. Changing
a load plan involves the reassignment of regions to
vehicles and, when appropriate, removing packages
from one vehicle and placing them on another vehicle.
Moving already assigned packages takes time, delays
ﬂeet departure, and hence generates additional cost.
However, load plan adjustment can better balance
delivery workload, which reduces cost. The objective
of the research presented is to aid the loader during
the loading process in deciding whether or not the
current load plan should be continued, and if not,
identify a better load plan, assuming that the current
package load of each delivery vehicle is known. The
load plan selection process is modeled as a Markov
decision process (MDP) and analyzed in Chapter 2.
We present structured results for the expected costto-go function that lead to an improved algorithm for
computing an optimal load plan policy. We describe
the improved algorithm and compare it to traditional
dynamic programming methods in Chapter 3. We
present a heuristic, based on conditions for action
elimination, that is computationally superior to the
exact methods. In Chapter 4, we present a prototype decision support system (DSS) for load plan
selection in package express. We develop a statistical
model to reﬂect a more complex information state and
describe the implementation of the statistical model
in an actual operation. We model the load plan selection process for air packages and suggest a solution
technique. Conclusions are presented in Chapter 5.
Transportation Science/Vol. 37, No. 2, May 2003

Dissertation Abstracts

Downloaded from informs.org by [149.169.221.39] on 22 June 2017, at 11:32 . For personal use only, all rights reserved.

The thesis supervisor was Chelsea C. White, III, Michigan University (currently at the Georgia Institute of
Technology).
Generalized Real-Time Route Guidance Strategies
in Urban Networks
Yi-Chang Chiu

C

onsidered as critical components in the ATMIS
architecture, the dynamic trafﬁc assignment
(DTA) problems have been extensively studied in the
last decade. Researchers have proposed various DTA
problem classes and formulations and have gained
basic understanding of the solution characteristics.
Although a vast amount of intellectual effort has been
invested in characterizing and solving DTA problems, the current state-of-the-art falls short of providing DTA solutions that are guaranteed to be effective and robust in real-world operation. This dissertation is motivated by the need for a DTA framework that offers signiﬁcant potential for successful
real-world operation. The objective of this dissertation
is to develop a generalized DTA framework that combines the advantages of both centralized and decentralized paradigms and circumvents the respective
disadvantages, so as to provide efﬁcient and robust
dynamic trafﬁc assignment solutions under various
network conditions in the real-time operational environment.
To achieve the generalization of the DTA framework, this dissertation presents a hybrid DTA (HDTA)
framework. The HDTA approach envisions a Stackelberg game-theoretic routing decision process achieved
through the careful interplay between a centralized
DTA model (CDTA) and a decentralized DTA (DDTA)
capability. The CDTA model supplies anticipatory a
priori routing decisions, taking into account DDTA’s
possible reactions to CDTA anticipatory routing policies, while the DDTA model generates locally reactive
solutions online, given CDTA’s anticipatory solutions.
To further improve online operating performance
and robustness of the HDTA, an online routing proﬁle updating automaton (ORPUA) model is proposed.
The ORPUA dynamically adjusts the routing proﬁle based on the online performance competitiveness
measures of CDTA- and DDTA-guided vehicles. If
one of the two classes of vehicles is detected to underperform the counterpart class, certain vehicles in this

Transportation Science/Vol. 37, No. 2, May 2003

class will be assigned with guidance from the counterpart class for the remaining portion of the trip. The
ORPUA constantly monitors and maintains the competitiveness between CDTA- and DDTA-class vehicles
in the HDTA framework. It allows HDTA to adaptively maintain online operating performance vis-àvis general demand or supply scenarios. Numerical
experiments demonstrate the effectiveness of ORPUA
under the scenarios in which CDTA’s inputs are of
varying accuracy levels.
The thesis supervisor was Hani S. Mahmassani, University
of Texas at Austin (currently at the University of Maryland).
Improving Crew Scheduling by Incorporating Key
Maintenance Routing Decisions
Amy E. M. Cohn

N

umerous important real-world problems are
found in the areas of transportation and logistics. Many of these problems pose tremendous challenges because of characteristics such as complex networks, tightly constrained resources, and very large
numbers of heavily interconnected decisions. As a
result, mathematical models can be critical in solving
these problems. These models, however, can be computationally challenging or even intractable. In this
thesis we discuss how greater tractability can sometimes be achieved with composite-variable models—
models in which individual binary variables encompass multiple decisions.
In Part I, we discuss common challenges found
in solving large-scale transportation and logistics
problems. We introduce the idea of composite variables and discuss the potential beneﬁts of compositevariable models. We also note some of the drawbacks
of these models and discuss approaches to addressing
these drawbacks. In Parts II and III, we demonstrate
these ideas using two real-world examples, one from
airline planning and the other from service parts logistics. We build on our experience from these two applications in Part IV, providing some broader insights for
composite-variable modeling. We focus in particular
on the dominance property seen in the service parts
logistics example and on the fact that we can relax
the integrality of the composite variables in the airline
planning example. In both cases, we introduce broader
classes of problems in which these properties can also
be found. We offer conclusions in Part V.
225

Downloaded from informs.org by [149.169.221.39] on 22 June 2017, at 11:32 . For personal use only, all rights reserved.

Dissertation Abstracts

The contributions of the thesis are three-fold. First,
we provide a new model and solution approach for an
important real-world problem from the airline industry. Second, we provide a framework for addressing
challenging problems in service parts logistics. Third,
we provide insights into how to construct compositevariable models for greater tractability. These insights
can be useful not only in solving large-scale problems, but also in integrating multiple stages within
a planning environment, developing better heuristics
for solving large problems in real time, and providing
users with greater control in trading off solution time
and quality.
The thesis supervisor was Cynthia Barnhart, Massachusetts Institute of Technology.
Dynamic Travel Time Models for Pricing and
Route Guidance: A Fluid Dynamics Approach
Soulaymane Kachani

T

his thesis investigates dynamic phenomena that
arise in a variety of systems that share similar
characteristics. A common characteristic of particular
interest in this work is travel time. We wish to address
questions of the type: How long does it take a driver to
traverse a route in a transportation network? How long
does a unit of product remain in inventory before being
sold?
To address these issues, we develop general models
for travel times. To make these models more accessible, we describe them as they apply to transportation systems. We propose ﬁrst-order and second-order
ﬂuid models. We enhance these models to account for
spillback and bottleneck phenomena. Based on piecewise linear and piecewise quadratic approximations
of the departure or exit ﬂows, we propose several
classes of travel time functions.
In the area of supply chain, we propose and study
a ﬂuid model of pricing and inventory management
for make-to-stock manufacturing systems. This model
is based on how price and level of inventory affect
the time a unit of product remains in inventory. Our
motivation is based on the observation that in inventory systems, a unit of product incurs a delay before
being sold. This delay depends on the level of inventory of this product, its unit price, and prices of competitors. The model includes joint pricing, production
and inventory decisions in a competitive, capacitated,
multiproduct dynamic environment.

226

Finally, we consider the anticipatory route guidance problem, an extension of the dynamic userequilibrium problem. This problem consists of providing messages to drivers, based on forecasts of trafﬁc
conditions, to assist them in their path-choice decisions. We propose two equivalent formulations that
are the ﬁrst general analytical formulations of this
problem. We establish, under weak assumptions, the
existence of a solution to this problem.
The thesis supervisor was Georgia Perakis, Massachusetts
Institute of Technology.
Airline Fleet Assignment and Schedule Design:
Integrated Models and Algorithms
Manoj Lohatepanont

I

n scheduled passenger air transportation, airline
proﬁtability is critically inﬂuenced by the airline’s
ability to construct ﬂight schedules containing ﬂights
at desirable times in proﬁtable markets. In this dissertation, we study two elements of the schedule generation process: schedule design and ﬂeet assignment.
The schedule design problem involves selecting an optimal set of ﬂight legs to be included in the schedule,
while the ﬂeet assignment problem involves assigning
aircraft types (or ﬂeets) to ﬂight legs to maximize revenues and minimize operating costs simultaneously.
With the ﬂeet assignment problem, we investigate
the issues of network effects, spill, and recapture. On
a constrained ﬂight leg in which demand exceeds
capacity, some passengers are not accommodated, or
spilled. When passengers travel on two or more constrained legs, ﬂight leg interdependencies or network
effects arise because spill can occur on any of these
legs. In most basic ﬂeet assignment models, simplistic modeling of network effects and recapture leads to
sometimes severe miscalculations of revenues. Recapture occurs when some of the spilled passengers are
reaccommodated on alternate itineraries in the system. In this dissertation, we develop new ﬂeet assignment models that capture network effects, spill, and
recapture. Another beneﬁt of one of our models is
its tractability and potential for integration with other
schedule planning steps. Our study shows that the
beneﬁts of modeling these elements exceed $100 million annually for a major U.S. airline.
We develop two models for schedule design, one
assuming that the market share of an airline remains
Transportation Science/Vol. 37, No. 2, May 2003

Downloaded from informs.org by [149.169.221.39] on 22 June 2017, at 11:32 . For personal use only, all rights reserved.

Dissertation Abstracts

constant with schedule changes, and the other assuming that market share varies with schedule changes.
The constant market share model, while less precise
in its modeling, is much easier to solve than the variable market share model. We estimate that the potential beneﬁts of these models range from $100 to $350
million annually.
The thesis supervisor was Cynthia Barnhart, Massachusetts Institute of Technology.
Models for the Design and Analysis of a Large
Package Sort Facility

provide an analysis of the effectiveness of the solution strategy and of potential sort facility architectures. The second set of experiments produced substantial improvements in the current sort facility layout and provided a deﬁnitive recommendation on a
future architecture.
The thesis supervisors were Michael Ball and Lawrence
Bodin, University of Maryland.
Design and Operation of Multimode, Multiservice
Logistics Systems
Karen R. Smilowitz

Major Paul W. McAree, United States Air Force

I

n a hub-and-spoke system that represents a large
package, overnight delivery operation, packages
are loaded onto aircraft at origin airports, moved to
a sort facility, unloaded and sorted using a forklift,
and loaded onto aircraft for delivery to destination
airports. The sort facility represents the hub of this
operation, and the spokes are the package movements
between the airports and hub. In this operation, a
forklift movement can take several minutes and there
can be congestion. The large package sort facility
operation of Federal Express is the motivation for this
research. The objective of the analysis is to determine
the minimum cost design of the sort facility.
In the dissertation several integer programming
models are described and analyzed; these models
include the bin and rack assignment model (BRAM),
the bin assignment model (BAM), and the rack assignment model (RAM). Because real problem instances
could not be solved directly using BRAM, the BAM
and RAM models were developed and embedded into
a heuristic called the BAM and RAM algorithm for
generating feasible solutions to the BRAM.
The BAM determines the assignment of inbound
ULDs to bins for a ﬁxed assignment of outbound
ULDs to racks. The RAM determines the assignment
of outbound ULDs to racks for a ﬁxed assignment
of inbound ULDs to bins. The BAM and RAM algorithm iteratively solves the BAM and RAM where
the RAM’s optimal solution is a feasible solution to
the BAM, the BAM’s optimal solution is a feasible
solution to RAM, and the overall solution is continuously improving. Computational experiments show
that this approach represents an effective heuristic.
The dissertation reports on results of a comprehensive set of computational experiments. These results
Transportation Science/Vol. 37, No. 2, May 2003

T

his thesis introduces design strategies and operational plans for multimode, multiservice package
delivery networks where service levels are deﬁned
by guaranteed delivery times (i.e., overnight, twoday delivery). Large-scale network design problems
are typically challenging because of the number of
interdependent decision variables and constraints.
These problems are even more complex with multiple service levels. Conventional design and routing models cannot sufﬁciently capture the complexity
of multimode, multiservice networks. This thesis discusses two principal design and routing approaches,
and shows how the two can be integrated. In one
approach, detailed mixed-integer programming formulations and numerical methods are utilized. In
the other, less detailed models based on continuous approximations are used. While the former provide a higher level of detail, the latter are more
revealing of “the big picture.” Numerical methods
are well suited for operational control, while continuous approximation methods are particularly effective
for strategic planning and design, especially under
uncertainty. A novel approach is developed based
on the complementary use of the two methods to
develop, test, and evaluate integrated strategies. This
is the ﬁrst application of hybrid continuous approximation/numerical optimization to design and operate
large-scale integrated networks with shipment choice.
As such, advancements in continuous approximation
and numerical optimization techniques, and in the
integration of the two, are required. The cost functions developed are capable of modeling complex systems, and their accuracy is demonstrated using independent cost validation. With creative solution techniques, these complex models are reduced to a series
227

Downloaded from informs.org by [149.169.221.39] on 22 June 2017, at 11:32 . For personal use only, all rights reserved.

Dissertation Abstracts

of subproblems that are solvable using spreadsheet
technology. Results suggest that integration beneﬁts
are greater when deferred demand exceeds express
demand. This insight helps to explain the different
business strategies of package delivery ﬁrms today.
This research shows how integration strategies can
reduce operating costs and how hybrid modeling
approaches can be used to better understand and better plan distribution strategies.
The thesis supervisor was Carlos F. Daganzo, University
of California, Berkeley.
The Capacitated Arc Routing Problem with
Vehicle/Site Dependencies: An Application of Arc
Routing and Partitioning
John S. Sniezek

T

he capacitated arc routing problem (CARP) is a
class of vehicle routing problems in which service requirements are associated with network arcs.
In the capacitated arc routing problem with vehicle/site dependencies (CARP-VSD), there are restrictions on the types of vehicles that can service or traverse each network arc. In general, vehicles may vary
in other characteristics as well, including their cost
parameters and capacities. The scheduling of residential solid waste collection vehicle motivated the study
of the CARP-VSD. Real instances of these problems
can have several thousand network elements.
In this dissertation, the composite approach for
solving CARP-VSD is described and analyzed. The
composite approach is composed of the vehicle decomposition algorithm (VDA), a mathematical program
(MPP), and a cost model. The VDA determines an initial vehicle ﬂeet mix, partitions the arcs requiring service into partitions, forms a minimum deadhead time
travel path over each partition, and uses betweenroute arc exchanges to improve the solution. In a test
region in Philadelphia, the VDA saved 5 of 23 vehicles.
The MPP is primarily used as a route-improvement
procedure. As a route-improvement procedure, the
MPP can alter the ﬂeet mix in a solution. In most prior
vehicle routing research, between-route improvement
procedures do not change the ﬂeet mix.
The cost model considers capital and operating
costs and is used to compare or generate solutions.
While the objective functions in classical vehicle routing models generally minimize total travel time or

228

travel distance, the CARP-VSD models developed in
this dissertation consider a complex set of cost components related to the nonhomogeneous nature of the
vehicle ﬂeet, route compactness, and other factors.
Extensive computational experiments are presented, including many based on real problem
instances.
The thesis supervisor was Lawrence Bodin, University of
Maryland.
The Dynamic Assignment Problem
Michael Z. Spivey

I

n this thesis we introduce the dynamic assignment
problem, which involves the solution of assignment
problems over time with evolving information on the
availability of resources and tasks, contributions for
assigning them and restrictions on the ability to assign
them. This thesis is the ﬁrst major work on extending
the classic assignment problem to a dynamic setting.
Because the dynamic assignment problem consists of
solving sequences of assignment problems over time,
it lies at an intersection of both linear and dynamic
programming. This thesis is one of the ﬁrst to work
at the conﬂuence of these two fundamental areas of
operations research.
We provide a formal model of the dynamic assignment problem. Our model explicitly includes both
the physical process (the actual arrivals of resources
and tasks to the system) and the information process (knowledge about these arrivals and of properties of resources and tasks). We also derive a number
of structural properties of the classic assignment problem and certain types of dynamic assignment problems. These properties help provide insight into the
problem class and are used in the design of approximation strategies.
We then introduce an approximation strategy for
the value function that produces a computationally tractable algorithm that signiﬁcantly outperforms
simple myopic heuristics. Our algorithmic strategy
avoids the state space problems of classical dynamic
programming. Techniques from stochastic programming (which use scenarios or cuts based on nestedBenders decomposition) lose the natural integrality
properties of the assignment problem. Our approach
involves solving sequences of assignment problems
based on sample realizations.
Transportation Science/Vol. 37, No. 2, May 2003

Downloaded from informs.org by [149.169.221.39] on 22 June 2017, at 11:32 . For personal use only, all rights reserved.

Dissertation Abstracts

We also examine the effects of aggregation of
resources and tasks on the dynamic assignment problem. Aggregation allows us to use the values of
resources and tasks that we already know to help
approximate values of resources and tasks that are
new to the system. This in turn allows us to apply
our value function approximation algorithm to even
larger problems. We also develop a version of our
algorithm that dynamically chooses an appropriate
level of aggregation, and we show that this algorithm outperforms our algorithm in which the level
of aggregation is static.
The thesis supervisor was Warren Powell, Princeton University.
Territory Planning and Vehicle Dispatching with
Stochastic Customers and Demand
Hongsheng Zhong

T

his paper investigates the construction of routes
for local delivery of packages. The primary objective of this research is to provide realistic models to optimize vehicle dispatching when customer
locations and demand vary from day to day, while
maintaining driver familiarity with their service ter-

Transportation Science/Vol. 37, No. 2, May 2003

ritories and dispatch consistency. The objective of
increasing driver familiarity tends to make routes or
service territories ﬁxed. On the other hand, to serve
varying demand, it is advantageous to reassign vehicles/drivers and service territories each day. To balance the trade-offs between these two objectives, we
developed concepts of “cell,” “core area,” “ﬂex-zone,”
and a two-stage vehicle routing model—the strategic
core area design model and operational cell routing
model—and explicitly considered the value of driver
familiarity by introducing a driver learning with forgetting model.
The testing results showed that the tabu search
meta-heuristic for solving the strategic model is capable of ﬁnding near-optimal solutions, as evidenced by
the lower bounds constructed for the nonlinear generalized assignment problem. Moreover, the core areas
and ﬂex-zone identiﬁed on the strategic level provides
a good framework for building low cost yet consistent
dispatch plans over certain period, as evidenced by
the favorable comparison to the no-core-area method
as well as by the lower bound constructed on the
operational level for the learning-incorporated vehicle
routing problems.
The thesis advisor was Randolph W. Hall, University of
Southern California.

229

Computational & Mathematical Organization Theory 6, 5–6, 2000.
c 2000 Kluwer Academic Publishers. Printed in The Netherlands.
°

Preface
The globalization of national and world markets, coupled with the rapid growth of communications networks and the advent of information processing technologies, call for new
approaches to support negotiations among users, often remote from each other. Examples of
evolving domains are: negotiations on pricing and priorities in liberalized telecommunications markets; electricity supply/demand management in deregulated energy markets; congestion pricing in transportation routing and assignment with satellite-based vehicle/traffic
monitoring systems, inventory and logistics management in supply chains, and resource
allocation in electronic commerce environments.
To develop models in support of strategic and operational decision making a blending
of traditional methods and theories (e.g., game theory, optimization, resource allocation
methodologies) and modeling paradigms is necessary. The considerations that need to be
addressed are threefold: (1) the definition of the theoretical, conceptual, and managerial
landscape of this new domain; (2) theoretical contributions at the intersection of multiple
methodologies and modeling paradigms; and (3) the integration of theories and practice
with case studies. A special challenge in this respect is to emphasize mathematical, logical,
and computational models, or the validation of such models using case studies or field data.
This special issue comprises six papers. Kijima, Nakagawa, and Namatame discuss
competitive price equilibria where consumers have a reservation utility below which they
will not purchase the product. Of special consideration is the impact of the reservation
utility on the price equilibrium, since the reservation utility can change dynamically in an
operational environment. Their findings show that an increasing reservation utility causes
both prices and Nash equilibrium to change.
Gabriel and Bernstein address the classical shortest path problem in transportation networks from a competitive multi-agent perspective. They consider the case with non-additive
travel costs. The authors develop good heuristics since such types of problems are difficult
to solve exactly.
Homburg and Schneeweiss address the problem of negotiations on price and order quantities within supply chains which involve suppliers and retailers. They propose a structuring of the negotiation process that captures uncertainties of the retailer’s future demands
and changes in supplier’s cost structure and production facilities. The authors show how
strategic and operational decisions within a supply chain can be coordinated through these
negotiations. They propose a process for suppliers and retailers to negotiate and exchange
information which builds and maintains a long-term relationship.
Beroggi and Mirchandani discuss dynamic plots that visually display the dynamics of
resource allocation in a competitive operational environment and support the negotiation
among the competitors. They discuss theoretical equilibria for classical negotiation settings
and test their theories in an experimental setting with human subjects. The authors conclude
the technical feasibility and behavioral relevance of dynamic plots.

6

BEROGGI AND MIRCHANDANI

Gross and Finlay develop a comprehensive framework for formulating bids to supply
power and energy in a perfectly competitive electricity market. This framework provides a
basis for the dispatcher of the power pool to commit electricity generation to meet forecasted
demand as well as for the suppliers in the pool to specify bids. A Lagrangian relaxation based
approach is used in the numerical method to solve the dispatching and bidding problem.
In the last paper, Eiselt addresses the problem of competition among planners to lure
firms to locate facilities in their region by offering subsidies. He considers two types of
subsidies: returning to the firms a fixed proportion of their fixed costs, and returning to
the firms a fixed proportion of the benefits that the region accrues as a result of attracting
the firm. The author’s computational experiments indicate few “not so intuitive results”
including cases where regions offering the subsidies incur substantial monetary losses.
The papers in this special issue highlight the importance of capturing user competition
in methods for resource allocation and operational and strategic decision-making. From
the contents of the papers and the affiliations of the authors, the relevance for different
scholarly disciplines is clearly evident. As information and communications technologies
further progress, the challenge will be to operationalize these theoretical concepts and the
associated methodologies, and to integrate them into intelligent decision support systems.
Only a successful blending of theories, methods, and technologies has the potential to improve the efficient allocation and use of resources in a competitive dynamic environment in
terms of economical and environmentally sustainable growth.
Giampiero E.G. Beroggi
Pitu B. Mirchandani
(Guest Editors)

Computational & Mathematical Organization Theory 6:2 (2000): 191–217
c 2000 Kluwer Academic Publishers. Manufactured in The Netherlands
°

Nondominated Schedules for a Job-Shop
with Two Competing Users
A. AGNETIS
Dipartimento di Ingegneria dell’Informazione, Università di Siena, via Roma 56 - 53100 Siena, Italy
P.B. MIRCHANDANI
Department of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ 85721, USA
D. PACCIARELLI
Dipartimento di Informatica e Automazione, Università di Roma Tre, Via della Vasca Navale 84, 00146 Roma,
Italy
A. PACIFICI
Dipartimento di Informatica, Sistemi e Produzione, Università di Roma “Tor Vergata”, via di Tor Vergata
110, 00133 Roma, Italy

Abstract
We consider the scenario where two users compete to perform their respective jobs on a common set of resources.
The job for each user has a due-date and the cost function associated with the due-date is quasi-convex (i.e., it has
a single local minimum). We characterize the set of nondominated schedules over which the users may negotiate
and develop a polynomial algorithm to find this nondominated set.
Keywords: scheduling, negotiation, coordination, job shop, nonregular objective function, Pareto-optimality

1.

Introduction

When two jobs compete for a set of resources (for example, machines), then a need arises
to schedule the jobs so that a set of given objectives functions, one for each job, are
“appropriately” considered. This paper addresses the problem in which there are two users,
each having to perform one job on the common set of resources. The cost function for each
user is non-regular and quasi-convex (i.e., it has a single local minimum), but the cost to one
user may not be directly traded off with the cost to the other user, since there is no reason
to assume that these costs have the same units or have comparable preference or disutility
functions (a $100 cost to one user may not be equally unattractive as a $100 cost to the second
user). In this case it is beneficial to determine a set of nondominated schedules, to allow
the two users to negotiate among the nondominated schedules to achieve a compromise
schedule.
The initial motivation for this research was in fact related to the two-user scenario.
Two major companies were proposing a joint venture to construct a modern flexible

192

AGNETIS ET AL.

manufacturing system to manufacture their respective (large, expensive) products (they
both produced a similar family of products). Discussion with these companies indicated
that a decision support system that allows the two parties to negotiate the use of, and hence
their respective schedules on the new manufacturing system would in fact be extremely
useful. Subsequent consideration of the model has pointed to other following applications,
some surprising common but not addressed before:
• scheduling multiple flights of different airlines on a common set of airport runways,
• scheduling berths and material/people movers (cranes, walkways, etc.) at a port for
multiple ships,
• scheduling clerical workers among different “bosses” in an office, and
• scheduling a mechanical/electrical workshop for different users.
Note that in each of the above application, each user, or “player” from a game-theoretic
perspective, has his/her/its objective, perhaps dictated by his/her/its company’s goals.
Examination of the literature for multiple player scheduling problems and on methods
to find nondominated schedules from the multiple-player perspective yielded surprisingly
little results. Although there are some results and algorithms for the case of a single user
with multiple objectives—here each job in the jobset has the same set of objectives—the
nondominated (or Pareto optimal) solutions do not pertain to trading of one job’s schedule
with the other job’s schedule (see, e.g., Raghavachari, 1988; Baker and Scudder, 1990; Hall
and Posner, 1991). We remark that there is some literature on economic markets where
players bid for resources (e.g., Rassenti et al., 1982; McCabe et al., 1990), but the time
dimension, or more specifically the scheduling of resource usage, does not play a part
because the bidding is for either a one-shot deal or for a single time period. Thus, in
fact, the concept developed here can be extended to bidding for schedules in an economic
market. A related, but perhaps more complicated problem is on scheduling of trains on a
railway track (or, more generally, a railway network), where conflicts occur when two trains
require the same segment of track at the same time (e.g., Kraay et al., 1991; Cai and Goh,
1994; Carey and Lockwood, 1995) but the reported works mostly address the single-user
case. An exception is the work reported by Brewer and Plott (1994) who devised a bidding
mechanism for the right to use a single railtrack among multiple players. Extension of the
research reported in this paper could address Brewer and Plott’s problem in the development
of a method to come up with nondominated schedules over which the players may negotiate.
In the next section we will first formally define our two-player scheduling problem.
We will then define some concepts on the span of a schedule and prove that one needs to
consider only schedules that minimize this span to solve our problems. Section 3 will present
an algorithm to find one such schedule. Section 4 describes the envelope of such schedules
on the plane defined by the completion times for the two jobs—referred to as the (C A , C B )
plane. In the succeeding Section 5, we discuss the concept of zones in this plane (related
to the earliness or the tardiness of the jobs). For example, zone z IV turns out to be the case
when both jobs are tardy. We also characterize the set of nondominated schedules in the
(C A , C B ) plane, and we elaborate on these nondominated schedules. The characterization

NONDOMINATED SCHEDULES FOR A JOB-SHOP

193

of nondominated schedules turns out to be largely independent of the particular objective
functions considered (as long as they are quasi-convex).
Section 6 concludes with a summary of the results, their implications and suggestions
for future research.
2.

Problem Formulation and Minimum-span Schedules

We shall refer to the two players as Player A and Player B, and their respective jobs as J A
and J B . At initial time t = 0 we shall assume that both jobs are available for processing.
(The results given in the paper can easily be extended to the case when one job is available
at time t = 0 and the other some given time later.) Completion time of job J A (or J B ) will
be denoted by C A (or C B ). Each player has an ideal due date for job completion time: due
date d A for job J A and d B for job J B . Cost of being tardy increases monotonically with
lateness of the job, and the cost of being early also increases monotonically with earliness,
that is, the cost function f i (Ci ) is non-regular with a minimum at Ci = di , i = A, B.
A nondominated schedule is one for which there is no other schedule where cost for
one player is lower and for the other player it is at least as good. Note that, depending on
the particular cost functions of the two players, several schedules, even having different
completion times for the two jobs, may yield the same pair of cost values. In this case, we
are only interested in finding at least one of these schedules, not all of them. Let the cost
pair associated with a schedule σ be ( f A (C A ), f B (C B )), and the cost pair associated with
a schedule σ 0 be ( f A (C 0A ), f B (C B0 )). The cost pair ( f A (C A ), f B (C B )) dominates the cost
pair ( f A (C 0A ), f B (C B0 )) if f A (C 0A ) ≥ f A (C A ), f B (C B0 ) ≥ f B (C B ), and at least one of the two
inequalities is strict. However, we say that the schedule σ dominates the schedule σ 0 if
f A (C 0A ) ≥ f A (C A ) and f B (C B0 ) ≥ f B (C B ), even if the cost function values in the two cases
are identical. We are indeed interested in finding at least one schedule for each nondominated cost pair. Then, if we know such a schedule for each nondominated cost pair, we
will have all the schedules over which the two players can negotiate. Now, the two-player
two-job scheduling problem can be stated simply as:
Problem 1. Find the set of all nondominated cost pairs and associated schedule when
Player A has to perform job J A and Player B job J B , on the same set of resources, each
with a cost function that is quasi-convex with respect to its completion time.
For the developments to follow, we need to define the span of a schedule.
Definition 1. The span of a schedule for a jobset is the time between the beginning of the
first operation and the end of the last operation in the jobset.
Definition 2.

A minimum span schedule is a schedule whose span is minimum.

Note that a minimum makespan schedule is simply a minimum span schedule where the
first operation starts at time t = 0.

194

AGNETIS ET AL.

In any two-job scheduling problem, a nondominated solution will have a difference of k
time units between the completion times of the two jobs, where k could be zero or negative
k = CB − C A.

(1)

When k = 0, then both jobs end at the same time. If there is an algorithm that finds this
nondominated solution, then by inserting at the end a dummy non-competing operation of
duration |k| for job J A when k is positive (or for job J B when k is negative), the algorithm will
still produce the same schedule since this dummy operation will not affect the real completion times of the two jobs. We are now in the position to provide some more useful definitions
in terms of schedules that utilize this dummy operation resulting in an offset of k units.
Definition 3.

A k-offset schedule is a schedule such that C B − C A = k.

Definition 4.
minimum.

A minimum span k-offset schedule is a k-offset schedule whose span is

A minimum makespan k-offset schedule is simply a minimum span k-offset schedule
where the first operation of the jobset starts at time t = 0. Any minimum span k-offset
schedule can be obtained by postponing a minimum makespan k-offset schedule, that is,
by increasing the start of all operations by the same amount.
Given a nondominated schedule, let k ∗ be the difference C B∗ − C ∗A between the completion
times of the two jobs. Obviously, there exists a minimum span k ∗ -offset schedule which is
also nondominated, namely the one for which C A = C ∗A and C B = C B∗ . Therefore, if k ∗ is
known, in order to find a nondominated schedule we could restrict our search to minimum
span k ∗ -offset schedules. In the next section we illustrate how to find a minimum makespan
k-offset schedule for a given k. Later, in a succeeding section, we show how to find such
schedules efficiently for all values of k.
In the developments to follow we will need additional notation. Although, new terminology and notation will be defined as we use them first, Table 1 lists the complete set of notation used in the paper—for convenient reference for following the ensuing developments.
3.

An Algorithm to Find Minimum Makespan
k-offset Schedules

In this section we show how to compute a minimum makespan schedule with the constraint
that the difference between the completion times is C B − C A = k, that is, a minimummakespan k-offset schedule. In what follows, for the sake of simplicity, we consider only
the case C B ≥ C A . The case C A ≥ C B can be analyzed analogously by exchanging the roles
of the two jobs.
3.1.

Grid Representation of a Job Shop with Two Jobs

First we briefly summarize the grid representation used by several researchers (Akers and
Friedman, 1955; Szwarc, 1960; Hardgrave and Nemhauser, 1963; Brucker, 1988; Agnetis

NONDOMINATED SCHEDULES FOR A JOB-SHOP
Table 1.

195

Notation.

ni

number of operations of job Ji , i = A, B

J A = {A1 , A2 , . . . , An A }, J B = {B1 , B2 , . . . , Bn B }

two jobs and corresponding operations

p Ai , p Bi

processing times of operation i of the two jobs

σ

schedule of the two jobs

dA , dB

due dates of the two jobs

t =0

common release date of the two jobs

C A = C An A (σ ), C B = C Bn B (σ )

completion times of the two jobs

k = CB − CA

fixed difference between completion times (offset)

Cmax = max{C A , C B }

makespan

f A (C A ), f B (C B )

cost functions of the two jobs

E A = max{0, d A − C A }, E B = max{0, d B − C B }

earliness of the two jobs

T A = max{0, C A − d A }, TB = max{0, C B − d B }

tardiness of the two jobs

IP

ideal point (d A , d B ) in the C A /C B plane

and Oriolo, 1995) to solve the problem of minimizing the makespan of a job shop with two
jobs, that is, the problem 2/m/J/Cmax in the scheduling notation of French (1982).
Consider two-axes plane, the horizontal axis corresponding to job J A and the vertical
to J B . On each axis, the operations of the respective job are indicated by segments, the
lengths being proportional to the corresponding durations of the operations. Parallel lines
to this segments results inP
a grid in the
(see, e.g., figure 1). Let O be the origin of
Pplane
A
B
p Ah , nh=1
p Bh ), that is, the upper-right point of the grid.
the axes and D the point ( nh=1
If the operations Ai and B j require the same machine, they cannot be done in parallel, and
therefore they form an incompatible pair. In the pictorial representation of the grid, the
rectangles corresponding to incompatible pairs are shaded (see figure 1).
Any feasible schedule of the two jobs can be represented on the grid by a path consisting of
horizontal, vertical and diagonal (45◦ ) segments. The diagonal path segment in a rectangle
implies that both operations are performed concurrently, on different machines, in that
schedule. Horizontal (vertical) segments correspond to time periods during which only J A
(J B ) is processed, and the other job is waiting. Shaded regions on the grid indicate the
operations which compete for the given resources and, hence, it is not feasible to take a
diagonal path through these regions. Hence, we refer to these regions as obstacles. The
upper-left and lower-right vertices of each obstacle will be referred to as NW and SE vertices
respectively.
P A
p Ah plus the total length
The makespan corresponding to a feasible path is givenP
by nh=1
B
p Bh plus the total length of
of the vertical segments of the path (or, equivalently, by nh=1
the horizontal segments). Clearly, in order to minimize Cmax , the line must go diagonally
whenever possible, and it must go horizontally or vertically only when an obstacle is hit.
It can be shown easily that the problem of finding a line corresponding to a minimum
makespan schedule can be reformulated in terms of shortest path on an acyclic graph G,
defined as follows. Nodes of G correspond to the vertices O, D and the NW and SE vertices
of each obstacle. The node corresponding to O is the origin node and D in the destination
node of the graph G. An arc exists from node i to node j if drawing a 45◦ line from i on the

196

AGNETIS ET AL.

Figure 1.

Grid representation of a two-jobs job shop problem and some paths.

grid (possibly, the origin node), the line either hits the obstacle containing the vertex j, or, if
j is the destination node, the border of the grid. The length of arc ai j in G corresponds to the
time required to perform the operations from node i to node j, which is max(xi j , yi j ) where
xi j and yi j are the lenghts on the x and y axes, respectively, between the two nodes. Brucker
(1988) has shown that G can be built in O(r log r ) (where r is the number of incompatible
pairs), and this is also the overall complexity of the corresponding shortest-path algorithm.
3.2.

The Auxiliary Problem

We now consider an auxiliary problem, obtained by reversing the order of the operations of
each job, and including an offset k between the two jobs. Introducing this problem would
not be strictly necessary from a theoretical viewpoint. However, it allows us to introduce
easily several other concepts and does not add to the overall solution complexity.

NONDOMINATED SCHEDULES FOR A JOB-SHOP

197

Let J Ā and J B̄ be two jobs, having n A and n B operations respectively, defined as follows:
Āi = An A −i+1 i = 1, . . . , n A ;
B̄ j = Bn B − j+1 j = 1, . . . , n B .

(2)
(3)

Processing times and incompatibility between operation pairs are defined accordingly.
If we reverse the Gantt chart of a feasible schedule for the auxiliary problem we get immediately a feasible schedule for the original problem with the same makespan.
Now we want to solve a makespan minimization problem with the constraint that job
J B̄ starts at time 0, whereas job J Ā starts at time k. We will refer to this problem as
2/m/J, s Ā1 = k, s B̄1 = 0/Cmax . (Notice that for some k this problem may not have a feasible
solution.) The constraint s Ā1 = k and s B̄1 = 0 guarantees that the difference between the
completion times is C B − C A = k in the original problem.
Problem 2/m/J, s Ā1 = k, s B̄1 = 0/Cmax can be solved conveniently using the above grid
representation. We only need to appropriately interpret the constraint on the starting times
of Ā1 and B̄1 in terms of feasible paths on the grid. With this in mind, we add first a dummy
operation Ā0 of length k at the beginning of job J Ā . This operation is compatible with all
the operations of J B̄ .
Let O be the new origin of the grid (see figure 1). Recalling that a vertical segment
corresponds to idle time for job J Ā , to ensure that Ā1 starts exactly at time k, the path
corresponding to a feasible schedule must not have any vertical segment between 0 and
k + p Ā1 . Using this simple constraint we can easily find the shortest route from origin O
to the destination D.
We now illustrate the algorithm with an example.
Example 1. Consider the following precedence among operations for the two jobs J A and
J B , where operation ( p Ai , R j ) denotes that i-th operation for job J A requires processing
time p Ai on resource R j :
J A = {(10, R2 ), (12, R3 ), (6, R1 ), (4, R2 ), (6, R1 ), (6, R2 ), (8, R1 )};
J B = {(4, R3 ), (6, R1 ), (4, R2 ), (2, R3 ), (8, R2 ), (2, R3 ), (6, R1 ), (4, R3 ), (6, R2 ),
(4, R4 ), (4, R3 ), (4, R1 )}.
Reversing the order of the operations, we have the grid shown in figure 1. Note that for
C B ≥ C A , k must have values greater than or equal to 4 for a feasible k-offset schedule;
when C B ≤ C A , we must have k < −8 for feasible k-offset schedules. In figure 1 we show
the feasible paths P1 , P2 , P3 , and P4 corresponding to minimum span k-offset schedules for
k = 30, k = 4, k = −8, and k = −38, respectively; we also indicate a path P 0 from point O
to D which corresponds to a feasible schedule but not a k-offset schedule since the initial
vertical segment implies that there is some idle time between the dummy job of k units
and the last operation of J A , which means the offset is really greater than the specified k.
Figure 2 shows the Gantt chart for the minimum span k-offset schedule corresponding to
the feasible shortest path P2 . The arrows in the chart indicate when the jobs compete for
resources in the schedule; immediately after one job’s operation is completed the other job’s
operation is executed at this points.

198

AGNETIS ET AL.

Figure 2.

4.

Gantt chart of the optimal schedule for Example 1 with k = 4.

The Schedule Envelope

Each feasible schedule can be represented by a point in the (C A , C B ) plane. (Obviously,
several different schedules may correspond to the same point.) For a given k, all feasible
k-offset schedules lie on the 45◦ line C B = C A + k. Clearly, no feasible point exists on this
line below the point corresponding to a minimum-makespan k-offset schedule. Hence, in
order to plot the border between feasible and infeasible schedules, we need to compute
minimum-makespan k-offset schedules for all values of k. We call this curve the schedule
envelope, since it is the envelope of all the points corresponding to feasible schedules. The
feasible region consists of all the points that can be expressed as (C A + x, C B + x) for any
x ≥ 0, where (C A , C B ) is a point of the envelope.
Again, we will only discuss the case C B ≥ C A . Hence, in what follows, we consider the
backward jobs J Ā and J B̄ , and we define the dummy operation Ā0 of length k ≥ 0. We will
refer to Example 1 illustrate the procedure.
When k = 0, a feasible schedule exists if and only if operations Ā1 and B̄1 are compatible.
+
= p B̄1 .
Otherwise, the first positive value of k for which a feasible schedule exists is k = kmin
(Correspondingly, the largest negative value of k for which a feasible schedule exists is
−
= p Ā1 .)
k = kmax
Consider now some feasible value of k. Starting from O, we proceed diagonally (i.e.,
at 45◦ to the axis implying that the corresponding operations of the two jobs are being
processed in parallel) until an obstacle is met, corresponding to an incompatible operation
i ≥ 2. The distance (i.e., time span) c(O, NW) from O
pair ( Āi , B̄ j ). Let us first suppose thatP
j
to the NW corner of the obstacle
is
h=1 p B̄h . The distance c(O, SE) from O to the SE
Pi
corner of the obstacle is k + h=1 p Āh . If we let c(NW, D) (and c(SE, D)) be the value
of the shortest path from the NW (and SE) corner of the obstacle to the destination D on
the grid, then the minimum makespan is given by
min{c(O, NW) + c(NW, D), c(O, SE) + c(SE, D)}
where we note that only the second term depends (linearly) on k.
Suppose that, for a given k = k 0 , the shortest path length is c(O, NW) + c(NW, D) (i.e.,
the shortest path passes above the obstacle). Moreover, suppose that ( Āi , B̄ j ) remains

NONDOMINATED SCHEDULES FOR A JOB-SHOP

199

P
Pj
the first conflict up to a k value of k̂ = h=1 p B̄h − i−1
h=1 p Āh . In this case, such a path is
optimal, and of constant length, for k 0 ≤ k ≤ k̂. The conflict ( Āi , B̄ j ) no longer occurs for
higher values of k. Because we are dealing with the case Cmax = C B ≥ C A , and the value
of C B is constant in this neighborhood, the schedule envelope is a horizontal segment for
all the values of k in the range k 0 ≤ k ≤ k̂.
Now suppose that, for a given k = k 00 , the shortest path length is c(O, SE) + c(SE, D).
(i.e., the shortest path passes below the obstacle.) The length of such a path increases with
k. This path
c(O, NW) + c(NW, D),
P remains optimal until the length of the pathPexceeds
j
(i.e., k + ih=1 p Āh + c(SE, D) becomes greather than h=1 p B̄h + c(NW, D)). Let k̃ be
the smallest value of k for which this event occurs, that is
k̃ =

j
X
h=1

p B̄h −

i
X

p Āh + c(NW, D) − c(SE, D)}.

(4)

h=1

Then, for all the values of k in the range k 00 ≤ k ≤ k̃, C B = Cmax increases linearly with
k, while C A remains constant. This corresponds to a vertical segment on the envelope.
Note that it may happen that k̃ coincides with the value k̂ for which the obstacle ( Āi , B̄ j )
disappears.
Let us summarize the above discussion. For k in some interval [ku , kv ], ( Āi , B̄ j ) is the
first conflicting pair in the jobset (we still maintain i ≥ 2). For small values of k within this
interval, up to some value kc ≥ ku , the shortest path passes below the obstacle, while for
kc ≤ k ≤ kv the path above the obstacle turns out to be more profitable. Thus, in general,
the interval [ku , kv ] (which is associated with an obstacle on the grid) is mapped on the
(C A , C B ) plane by a step consisting of a vertical segment followed by a horizontal segment.
The corner of the step corresponds to the value kc . We call this point an internal breakpoint.
For k > kv , another obstacle, if any, becomes the first conflict on the shortest path. Hence,
we have a new step in the (C A , C B ) plane, with its own internal breakpoint. From k = kv−
to k = kv+ , the envelope may turn from horizontal to vertical; therefore, we call the point on
the envelope at kv an external breakpoint. However, we may have degenerate steps, when
a horizontal segment follows a horizontal segment, or a vertical segment follows a vertical
segment. In these cases, the external breakpoint may lie along the interior of a horizontal
or vertical segment of the envelope. We then refer to such a breakpoint as a degenerate
external breakpoint.
Referring to Example 1, consider the range k ∈ [4, 10). For 4 ≤ k < 6, the first obstacle
is ( Ā2 , B̄4 ). The shortest path is the one labeled by P2 in figure 1. Since the distance from
0 to the SE vertex of the first obstacle is c(O, SE) = 14 + k, in this range the length of
the minimum makespan k-offset schedule is Cmax = C B = 64 + k. For k = 6 both paths
passing above and below the obstacle ( Ā2 , B̄4 ) are minimum makespan k-offset schedules
and Cmax = C B = 70. For k > 6 the path passing above the obstacle is the shortest (and
therefore C B remains constant) until k = 10, after which the conflict between Ā2 and B̄4
disappears. The points of the envelope corresponding to k ∈ [4, 10) in the (C A , C B ) plane
are depicted in figure 3. Note that the point (64, 70), corresponding to k = 6, is an internal
breakpoint.

200

Figure 3.

AGNETIS ET AL.

Schedule envelope for Example 1.

Let us consider now higher values of k. For k = 10, the first obstacle becomes ( Ā3 , B̄6 ).
However, since the shortest path passes above this obstacle, Cmax = C B remains constant at
70 as k increases, up to k = 14. Hence, at k = 10 we have a degenerate external breakpoint.
So far, we have assumed that the first conflict involves an operation Āi with i ≥ 2. Let us
now analyze the case in which i = 1, that is, the first conflict is due to an obstacle ( Ā1 , B̄ j ).
Recall that, since we are looking for a k-offset schedule, operation Ā1 must start exactly at
time k. As a consequence, any admissable path on the grid meeting obstacle ( Ā1 , B̄ j ) must
pass below the obstacle. Referring again to Example 1, the first conflict is ( Ā1 , B̄6 ) for
all k ∈ (14, 28). Since the path must pass below the obstacle, the length of the admissable
shortest path increases with k and Cmax = C B = 56 + k. The point (56, 70) (corresponding
to k = 14) is therefore another external breakpoint on the envelope. Notice that the step
corresponding to the obstacle ( Ā1 , B̄6 ) is degenerate, since it consists of a vertical line.
For k = 28, the conflict between Ā1 and B̄6 disappears. For k = 28 − ε (with ε arbitrarily
small) we were still constrained to pass below the obstacle. This implies the insertion
of some idle time for J B̄ , between B̄5 and B̄6 . When the conflict disappears, this idle
time becomes unnecessary. As a result, now the previously conflicting operation B̄6 may
be completed before Ā1 starts and, therefore, the value of the minimum makespan koffset schedule can actually improve. In fact, for k = 28 we have Cmax = C B = 82, while for

NONDOMINATED SCHEDULES FOR A JOB-SHOP

201

k = 28 − ε we had Cmax = C B = 84 − ε. That is, for k = 28 the envelope has a discontinuity.
We refer to the corresponding point (54, 82) on the envelope as a jump breakpoint, which
is a special type of external breakpoint. We will refer to those external breakpoints which
are not jump breakpoints as normal breakpoints.
+
+
−
−
> 0 (if −kmax
> 0), then at kmin
(at kmax
) there is a particular jump
Notice that if kmin
breakpoint. The difference from other jump breakpoints is that the envelope is not defined
+
−
< k < kmin
.
for kmax
Suppose we have a jump breakpoint (C 0A , C B0 ) at k = k 0 , due to the obstacle ( Ā1 , B̄ j ).
That is, the graph of the envelope resumes from point (C B0 − k 0 , C B0 ). The next theorem
gives a lower bound on C B0 , which implies that the envelope cannot jump too low. First,
let (C 0A , C B0 ) be the last normal breakpoint (at k = k 0 ). Note that, in general, there may be
other jump breakpoints between (C 0A , C B0 ) and (C 0A , C B0 ), due to obstacles which are below
( Ā1 , B̄ j ) in the grid (e.g., see figure 12 in Section 5).
We will denote the first of these obstacles as ( Ā1 , B̄r ). Note that, for all k 0 ≤ k < k 0 the
envelope consists of vertical lines, since the shortest path must pass below the first obstacle
encountered on the grid.
Theorem 1. If breakpoint (C 0A , C B0 ) at k = k 0 > 0 is normal and there is a jump breakpoint (C 0A , C B0 ) at k = k 0 > k 0 , then C B0 ≥ C B0 .
Proof: In what follows, ( Ā1 , B̄ j ) is the obstacle associatedPwith the breakpoint (C 0A , C B0 ).
B
p B̄h plus the total length
For a given path on the grid, the value of C B is given by nh=1
of the horizontal segments. Consider the two shortest paths on the grid corresponding to
k = k 0 and k = k 0 , and call them P 0 and P 0 respectively (see figure 4). Path P 0 passes

Figure 4.

0

Paths P 0 , P 0 and P 0 in the proof of Theorem 1.

202

AGNETIS ET AL.

through the SE corner of the obstacle ( Ā1 , B̄r ), with r ≤ j. Path P 0 passes through the NW
0
0
corner of the obstacle ( Ā1 , B̄ j ). Now consider a path P 0 obtained as follows: P 0 starts
from point (−k 0 , 0) and follows P 0 up to the SE corner of the obstacle ( Ā1 , B̄r ). At this
0
point, P 0 goes up vertically until it meets P 0 , and then follows P 0 until D. (Note that, in
0
general, P 0 corresponds to a schedule which is not semi-active, since we are introducing
0
unnecessary idle time on job J Ā , between operations Ā1 and Ā2 ). Therefore, C B0 , the value
0
of C B associated with P 0 , is greater than or equal to C B0 . On the other hand, we observe
0
0
that P 0 does not contain horizontal segments before it merges with P 0 , and therefore C B0
is not greater than C B0 . Hence, C B0 ≥ C B0 .
2
The above theorem states, in other words, that whenever the envelope has a jump at a
value k > 0, it cannot resume from a point which is lower than the last horizontal segment
of the envelope. Observe that the length of the vertical segment on the envelope starting
at k = k 0 is p Ā1 + p B̄r . In fact, when k increases from k 0 to k 0 + p Ā1 + p B̄r , the shortest
path on the grid passes below the obstacle ( Ā1 , B̄r ). Hence, C B remains constant while
C A increases by p Ā1 + p B̄r . Returning to Example 1, for k = 28, both the paths above
and below the first obstacle ( Ā2 , B̄8 ) have length 82. For higher values of k only the path
above the obstacle is more profitable and, therefore, the envelope becomesPhorizontal (C B
A
is constant at 82). When k = 30, C A reaches its minimum value 52, since nh=1
p Āh = 52.
Hence, (52, 82) is an external breakpoint. Thereafter the envelope goes up vertically.
Analogously, the envelope can be drawn for C A ≥ C B by simply exchanging the roles of
the two jobs. In particular, the dummy operation of length k is now defined for job J B̄ , and
a symmetrical result to Theorem 1 holds:
Theorem 2. If breakpoint (C 0A , C B0 ) at k = k 0 < 0 is normal and there is a jump breakpoint (C 0A ,C B0 ) at k = k 0 < k 0 , then C 0A ≥ C 0A .
In other words, if the envelope jumps at a value k < 0, it resumes from a point which is not
strictly left of the last vertical segment of the envelope. Continueing our example, we find
that at k = −10 there is an external breakpoint, there are two consecutive jump breakpoints
at k = −20 and k = −30, there is an internal breakpoint at k = −36, and an external one at
k = −38.
Finally, using the same arguments the following can be proved easily:
+
−
−
+
Theorem 3. Let (C +
A ,C B ) and (C A ,C B ) be the jump breakpoints corresponding to k = kmin
−
−
and k = kmax . If (C A , C B ) is a point on the envelope at k > 0 then C B > C B , and if (C A , C B )
is a point on the envelope at k < 0 then C A > C +
A.

Observe that the whole envelope can be partitioned into steps (some possibly degenerate),
each corresponding to an obstacle representing the first conflict between two operations. If
the obstacle ( Āi , B̄ j ) is the first conflict for all k such that ku ≤ k ≤ kv , then there is a step
having the extreme points at ku and kv as possible external breakpoints. Therefore, it is
sufficient to consider only the values of k for which the first obstacle changes in the shortest
paths on the grid. This is equivalent to enumerating values of k such that a 45◦ line drawn
from O passes through a vertex of each first obstacle encountered by a path on the grid.

NONDOMINATED SCHEDULES FOR A JOB-SHOP

203

This information can be easily obtained from the acyclic graph G introduced in Section 3.1
defined for the forward job pair J A , J B . For the sake of convenience, we label the node of
G corresponding to the SE corner of the obstacle (Au , Bv ) as Au | Bv , to indicate that the
conflict is solved by giving priority to job J A over J B (accordingly, the node corresponding
to the NW corner is denoted as Bv | Au .) Now consider the node Au | Bv of G preceding the
sink. Since there are no more conflicts until the end of the schedule, the difference between
the completion times of the two jobs is given by
CB − CA =

nB
X

p Bh −

h=v

nA
X

p Ah

(5)

h=u+1

and this is exactly the value of k defined by Eq. (1). Likewise, for the node Bv | Au preceding
the destination, the difference between C B and C A is given by
CB − CA =

nB
X

p Bh −

h=v+1

nA
X

p Ah

(6)

h=u

Clearly, a shortest path on G from the origin to a node Au | Bv (Bv | Au ) corresponds to a
shortest path on the reverse grid from the NW (from the SE) corner of ( Ān A −u+1 , B̄n B −v+1 )
to node D.
The breakpoints can be computed by first developing a shortest-path tree from destionation node D and then determining the breakpoints that result due to the first obstacle from
some origin (and corresponding k-offset). The complexity for developing the shortest path
tree is O(r log r ).
There cannot be more external breakpoints than the number of obstacles. As a consequence, the number of external breakpoints and the number of corresponding schedules is
O(r ).
Thus, the overall complexity to develop the schedule envelope, which can be constructed
once the external breakpoints are known, is O(r log r ).
The pictorial representation of the envelope is particularly convenient to characterize the
nondominated schedules, as will be show in the next section.
5.

Due Date Objectives and Zones in (CA , CB ) Plane

In our definition of the scheduling problem (Section 2), each job has an objective function
related to its due date. In particular, since we assume a quasi-convex objective function, the
penalty for being tardy is nondecreasing with tardiness and the penalty for being early is
nonincreasing with earliness. This leads us to define the following zones in the (C A , C B )
plane that depend on only the due dates d A and d B :
ZI
Z II
Z III
Z IV

=
=
=
=

{(C A , C B ) | C A
{(C A , C B ) | C A
{(C A , C B ) | C A
{(C A , C B ) | C A

≤ dA, CB
≤ dA, CB
≥ dA, CB
≥ dA, CB

≤ d B },
≥ d B },
≤ d B },
≥ d B }.

204

Figure 5.

AGNETIS ET AL.

Domination among schedules in the four zones.

In this section, we characterize the points of the envelope which correspond to nondominated schedules. First we establish whether an ideal schedule exists. An ideal schedule is
a schedule in which both jobs finish exactly at their due dates d A and d B . Such a schedule
is denoted by point IS = (d A , d B ) on the (C A , C B ) plane.
Now consider the ray starting from IS and pointing downwards along the 45◦ line
C B = C A + k, where k = |d A − d B |. If this ray intersects the envelope at some point (C ∗A , C B∗ ),
then an ideal schedule can be obtained by delaying both jobs by an amount d A − C ∗A =
d B − C B∗ . This schedule obviously is optimal and dominates any other schedule in the
(C A , C B ) plane.
Hence, in what follows we will assume that an ideal schedule does not exist. A simple
but useful result is given by the following proposition (see figure 5).
Proposition 1. Let (C̃ A ,C̃ B ) be a point on the envelope. The schedule corresponding to
(C̃ A , C̃ B ) dominates any schedule corresponding to points (C A , C B ) in the following cases:

NONDOMINATED SCHEDULES FOR A JOB-SHOP

1.
2.
3.
4.

205

C A ≤ C̃ A , C B ≤ C̃ B , and (C̃ A , C̃ B ) is in zone Z I ,
C A ≤ C̃ A , C B ≥ C̃ B , and (C̃ A , C̃ B ) is in zone Z II ,
C A ≥ C̃ A , C B ≤ C̃ B , and (C̃ A , C̃ B ) is in zone Z III ,
C A ≥ C̃ A C B ≥ C̃ B , and (C̃ A , C̃ B ) is in zone Z IV .

Figure 5 shows schedules Pi ∈ Z i and the corresponding dominated sets Di , i = I, II,
III, IV. For convenience, in what follows we indicate the border between zones X and Y
as border X/Y. We start our analysis by ruling out zone Z I .
5.1.

Zone Z I

The following simple result holds.
Proposition 2. Let (C AI , C BI ) be a point on the envelope, located in the interior of zone
Z I , and let σ be the minimum makespan k-offset schedule corresponding to (C AI , C BI ). We
can get a schedule σ 0 which is at least as good as σ by moving both jobs forward by an
amount min{d A − C AI , d B − C BI }.
Proof: Since (C AI , C BI ) is in the interior of zone Z I , both jobs are early in the schedule σ .
Hence, none of the costs increase if the starts of both jobs are shifted forward (postponed).
This holds until one of the two jobs is no longer early, and this occurs when the shift equals
2
min{d A − C AI , d B − C BI }.
Note that, in the new schedule, at most one of the two jobs is early and the other ends
exactly on time. Hence, the corresponding point in the (C A , C B ) plane lies either on the
border I/II or on the border I/III. This means that to find nondominated schedules we need
not consider any point in the interior of zone Z I .
5.2.

Zone Z IV

We next characterize all the nondominated points in zone Z IV . Consider first the external
breakpoints in zone Z IV . Due to Proposition 1, each such breakpoint dominates all the
points on the adjacent segment(s) on the envelope. Precisely, an external normal breakpoint
dominates both its adjacent horizontal and vertical segments. (Observe that all the internal
breakpoints are dominated also.) A jump breakpoint dominates the points on the adjacent
vertical or horizontal segment.
If the intersection of the border II/IV and the envelope is non-empty, then there are points
on the envelope corresponding to schedules for which job J A meets its due date exactly,
while J B is late. Among them, the point having smallest C B dominates any other point in
zone Z IV having greater or equal C B . Hence, this intersection point is nondominated.
If the intersection of the border II/IV and the envelope is empty, then either (i) the envelope has no points in zone Z II , or (ii) it does. Case (i) is trivial, in that there are no other
nondominated points in zone Z IV . In case (ii), let k1 be the smallest value of k such that a
minimum span k-offset schedule exists in Z II . Let (C 1A , C B1 ) be the point on the envelope
corresponding to the minimum makespan k1 -offset schedule. This implies that at k = k1 the
envelope has a jump breakpoint. Note that (C 1A , C B1 ) is either in zone Z I or Z II . By suitably
postponing the schedule corresponding to (C 1A , C B1 ), we can get a schedule corresponding

206

AGNETIS ET AL.

to point (d A , d A + k1 ) (see, for instance, figure 7, dominates any other point in Z IV having
C B ≥ d A + k1 . Observe that, in general, this point does not belong to the schedule envelope;
that is, the point may not correspond to a minimum makespan k-offset schedule. (However,
the point obviously does correspond to a minimum span k-offset schedule.)
Symmetric arguments hold with respect to the border III/IV. In particular, k10 indicates the
largest value of k such that a minimum span k-offset schedule exists in zone Z III . By suitably
postponing the schedule at k = k10 on the envelope, we can get a schedule corresponding to
point (d B − k10 , d B ). In conclusion, we may state the following theorem.
Theorem 4. All the nondominated points in Z IV are included among the following point
sets:
1. the external breakpoints in zone Z IV ,
2. the point (d A , d A + k1 ) corresponding to a feasible minimum span k1 -offset schedule
lying on the border II/IV having smallest C B , if it exists, and
3. the point (d B − k10 , d B ) corresponding to a feasible minimum span k10 -offset schedule
lying on the border III/IV having smallest C A , if it exists.
Proof: Let ψ indicate the union of the three point sets mentioned above. We only need
show that any other feasible point in zone Z IV is dominated. Consider any feasible point
R = (C A , C B ) ∈ Z IV , and draw the 45◦ line (C A − x, C B − x), for x > 0, until the line either
meets the envelope at a point R 0 or a border of zone IV at a point R 00 . In the first case, since
we are in zone Z IV , R is dominated by R 0 , which either belongs to ψ or is in turn dominated
by a point in ψ (the external breakpoint lying at the left or below R 0 ). In the latter case,
if the border is II/IV, R is dominated by R 00 , which is dominated by point (d A , d A + k1 ).
2
Analogous discussion holds if R 00 is on the border III/IV.
Notice that the point set ψ may contain dominated points. This is the case, for instance,
when one jump breakpoint dominates another jump breakpoint (see figure 11).
5.3.

Zones Z II and Z III

Let us now turn to zone Z II . (Obviously, an analogous discussion holds for zone Z III .) We
will deal separately with the following three cases: (i) the intersection between the envelope
and the border II/IV is a discrete set of points, (ii) the intersection is empty and (iii) the
intersection is a vertical segment.
Case (i) is addressed by the following theorem.
Theorem 5. Suppose that the intersection between the envelope and the border II/IV is a
discrete set of points, and let (C IIA ,C BII ) be the intersection point having smallest C B . Then,
this point dominates all the points corresponding to feasible schedules in zone Z II .
Proof: Let k II be the value of k corresponding to (C IIA , C BII ). Since the intersection set
consists of discrete points, the envelope crosses the border II/IV along horizontal segments.
All the points of the envelope for k > k II have C B ≥ C BII , even if these are at jump breakpoints
(due to Theorem 1). Therefore, from Proposition 1, all the points in zone Z II corresponding
2
to feasible schedules are dominated by (C IIA , C BII ).

207

NONDOMINATED SCHEDULES FOR A JOB-SHOP

Let us now turn to case (ii). In this case, no minimum makespan k-offset schedule exists
such that C A = d A . In what follows, if (CAX , CBX ) and (CAY , CBY ) are two points on the
(C A , C B ) plane, we let [(CAX , CBX ), (CAY , CBY )] indicate the closed segment going from
(CAX , CBX ) through (CAY , CBY ). Notation [(CAX , CBX ), (CAY , CBY )) indicates the semi-open
segment that does not include the extreme point (CAY , CBY ).
Recall that, in leading to Theorem 4, k1 was defined as the smallest value of k such
that a minimum span k-offset schedule exists in zone II, and (C 1A , C B1 ) as the point on the
envelope corresponding to a minimum makespan k1 -offset schedule. Note that since we are
considering the case that the intersection between the envelope and the border II/IV is empty,
it must hold that k1 > 0. Consider the closed segment L 1 = [(C B1 − k1 , C B1 ), (d A , d A + k1 )].
(L 1 is illustrated in figure 12.) All the points of this segment correspond to minimum
span (not minimum makespan!) k1 -offset schedules obtained by postponing the schedule
corresponding to point (C B1 − k1 , C B1 ). Similarly, we may have other jump breakpoints,
q
at k = k2 , k3 , . . . , kq with k1 < k2 < k3 < · · · < kq and C B1 > C B2 > · · · > C B . We define
i−1
i−1
i
i
semi-open segments L i = [(C B − ki , C B ), (C B − ki , C B )), for i = 2, . . . , q (see again
figure 12). Then case (ii) is addressed by the following theorem.
Theorem 6. Suppose that the envelope has points in Z II , and that the intersection between
the envelope and the border II/IV is empty. Let {k1 , k2 , . . . , kq } be the set of all values of
q
k at jump breakpoints, such that k1 < k2 < · · · < kq , and C B1 > C B2 > · · · > C B . Let ψ
be the union of the segments L 1 , . . . , L q , where L 1 = [(C B1 − k1 , C B1 ), (d A , d A + k1 )] and
L i = [(C Bi − ki , C Bi ), (C Bi−1 − ki , C Bi−1 )), for i = 2, . . . , q. Then all nondominated points in
zone Z II are included in ψII = ψ ∩ Z II .
Proof:

q

q

Let us divide the proof into two cases: (a) C B ≥ d B and (b) C B < d B .

Case (a) In this case the set ψ is entirely in zone Z II . Consider segment L 1 . All of
its points are nondominated, since the earliness of J A decreases and the tardiness of
J B increases as we move from (C B1 − k1 , C B1 ) towards (d A , d A + k1 ) along L 1 . Using
Proposition 1, the points of L 1 dominate all the other points in Z II corresponding to
feasible schedules with C B ≥ C B1 . For the same reason, all the points of the segments L i
are also nondominated. By construction, we see that if a feasible point (C A , C B ) in Z II
is such that C Bi ≤ C B < C Bi−1 , for 1 ≤ i ≤ q, then there is a point on L i having the same
C B that dominates it, since it has a larger C A (see figure 12).
Case (b) In this case let us consider the value k̂ such that (d B − k̂, d B ) ∈ ψ. This point
belongs to some L j , 1 ≤ j ≤ q, and clearly dominates all the points of ψ in the interior
of Z I . Thus, the set
¡ j−1
¡ j−1 ¢¤
∪ L j−1 ∪ L j−2 ∪ · · · ∪ L 1
(d B − k̂, d B ), C B − k̂, C B

£

dominates all feasible schedules in zone Z II .

2

Notice that, due to Theorem 1, all the breakpoints at values of k in the interval [k1 , kq ]
are jump breakpoints.

208

AGNETIS ET AL.

Finally, let us turn to case (iii) where the intersection is a vertical segment. Recall the
definition of k1 (Section 5.2). The lowest point on the segment lying along the border
II/IV is (C 1A , C B1 ); in this case K 1 corresponds to a breakpoint. If it is a normal breakpoint,
(C 1A , C B1 ) dominates all the points in Z II . If it is a jump breakpoint, it can be considered as
a degenerate case (ii) where the two endpoints of segment L 1 coincide (i.e., L 1 has length
zero) at the II/IV border. Therefore, the same result holds.
5.4.

Examples

We will now illustrate the above cases, using the schedule envelope of Example 1. We will
determine the set φ of the nondominated schedules for different values of the due dates d A
and d B .
Example 2.

d A = 53, d B = 55

The envelope (see figure 6) crosses the border II/IV at point (53, 82), and the border
III/IV at point (92, 55). Therefore, the nondominated schedules all belong to zone Z IV , and

Figure 6.

Set φ for Example 2. Dots are non-dominated schedules.

NONDOMINATED SCHEDULES FOR A JOB-SHOP

Figure 7.

209

Set φ for Example 3.

correspond to the discrete set φ = {(53, 82); (56, 70);(64, 68);(70, 60); (78, 58);(86, 56);
(92, 55)}.
Example 3.

d A = 55, d B = 59

The intersections of the envelope with the borders II/IV and III/IV are empty (see figure 7).
Hence, there are nondominated schedules in zones Z II , Z III and Z IV . In the interior of zone
Z IV , the points (56, 70), (64, 68), (70, 60) are nondominated. In addition, we have one
segment in zone Z II and one in zone Z III . In zone Z II , the segment L 1 = [(54, 82), (55, 83)]
is nondominated (this segment corresponds to k1 = 28.) In zone Z III , the segment L 01 =
[(78, 58), (79, 59)] is nondominated (corresponding to k10 = −20). Hence, φ = {(56, 70);
(64, 68); (70, 60)} ∪ L 1 ∪ L 01 .
Example 4.

d A = 66, d B = 64

The envelope (see figure 8) lies entirely in zones Z II and Z III . Again, the intersections
of the envelope with the borders II/IV and III/IV are empty. Consider first zone Z II .
+
= 4. All the points of the segment L 1 = [(64, 68), (66, 70)] are
Notice that now k1 = kmin

210

Figure 8.

AGNETIS ET AL.

Set φ for Example 4.

nondominated. Similarly, the segment in zone Z III , L 01 = [(70, 62), (72, 64)] (correspond−
= −8) is nondominated. Hence, φ = L 1 ∪ L 01 .
ing to k = kmax
Example 5.

d A = 72, d B = 66

The envelope (see figure 9) has points in zone Z I , Z II and Z III . The nondominated points
in Z II consist of the segment L 1 = [(64, 68), (72, 76)]. In Z III , the nondominated points
consist of a sub-segment of L 01 = [(70, 62), (74, 66)], obtained by removing the points lying
in the interior of Z I . Hence, φ = L 1 ∪ [(72, 64), (74, 66)].
Example 6.

d A = 72, d B = 58

The border II/IV intersects the envelope (see figure 10) at point (72, 60). This point dominates
all feasible points in zone Z II . The border III/IV intersects the envelope along the semiopen segment [(78, 58), (88, 58)). The leftmost point of the segment dominates all feasible
points in zone Z III . There are no nondominated points in the interior of zone Z IV . Hence
φ = {(72, 60); (78, 58)}. The next example illustrates the structure that ψII may have when
there are several consecutive jump breakpoints in zone Z II .

NONDOMINATED SCHEDULES FOR A JOB-SHOP

Figure 9.

211

Set φ for Example 5.

Example 7. Consider the following jobs J A and J B : J A = (7, R1 ) (30, R3 ) (33, R2 )
(15, R1 ), J B = (5, R3 ) (9, R1 ) (8, R3 ) (5, R2 ) (6, R3 ) (6, R2 ) (1, R1 ) (5, R3 ) (4, R2 ) (5, R1 )
(1, R2 ) (3, R1 ) (5, R2 ) (7, R1 ), with due dates d A = 129 and d B = 120.
The grid representing the reverse jobs J Ā and J B̄ is depicted in figure 11, where the shortest
paths at the nondegenerate breakpoints are indicated. The corresponding k values are 33,
31, 21, 12, 7, −15, −55. The portion of the envelope that falls in zone Z II is shown in
+
figure 12. The breakpoint having smallest k in zone Z II is (121, 128), attained at kmin
= 7.
(In Section 5.5 we refer to this value of k as k p .) With reference to the notation of Theorem 6,
the nondominated points in Z II consist of three segments, L 1 = [(121, 128), (129, 136)],
L 2 = [(103, 124), (107, 128)) and L 3 = [(89, 120), (93, 124)). Notice that L 3 is obtained
by removing from segment [(87, 118), (93, 124)) the portion belonging to the interior
of zone Z I . Also, note that the jump breakpoint (117, 132) ∈ Z II is dominated (e.g., by
(121, 128)).
−
= −15 (that
In accordance with Theorem 3, observe that the jump breakpoint for kmax
+
= 7. The
is, point (125, 110)) is located south-east of the breakpoint (121, 128) for kmin
−
= −15 lies in zone Z I . (In Section 5.5 we refer to this value of k as k p0 .)
breakpoint at kmax

212

AGNETIS ET AL.

Figure 10.

Set φ for Example 6.

The nondominated points in zone Z III form the segment L 01 = [(129, 114), (135, 120)],
which goes from the border I/III to the border III/IV. The normal breakpoint (125, 85) (not
shown in the figure) lies in zone Z I and is dominated by the lower endpoint of segment L 01 .
The envelope has no points in zone Z IV .

5.5.

Computation of the Nondominated Set φ

In Section 4 we described the schedule envelope. So far in this section we have characterized
the set φ of nondominated schedules. Now, suppose we have all the external breakpoints
listed in decreasing order of their k values. Let E be this ordered set. Along with each ki
value, we store with E the corresponding point (C iA , C Bi ) on the envelope, as well as the
information concerning its zone and the type of breakpoint (normal or jump). Recall that
E can be easily obtained from graph G, as illustrated at the end of Section 4. We now show
that φ can be computed in time O(|E|).
+
−
< d B − d A < kmin
,
First, we must check whether an ideal schedule exists. Obviously, if kmax
+
−
an ideal schedule does not exist. If either d B − d A ≥ kmin , or d B − d A ≤ kmax , then we need

NONDOMINATED SCHEDULES FOR A JOB-SHOP

Figure 11.

Grid representation of Example 7.

Figure 12.

The schedule envelope for Example 7.

213

214

AGNETIS ET AL.

to find a quick method to check if an ideal solution exists. To do this, we first define, with
reference to the list E,
ksup = min{k | k ∈ E, k ≥ (d B − d A )},
kinf = max{k | k ∈ E, k ≤ (d B − d A )},
sup

(7)
(8)

sup

inf
and let (C A , C B ) and (C inf
A , C B ) be the corresponding points on the envelope.
Consider first the case that kinf > 0. Consider the ray (d A − x, d B − x), with x ≥ 0. For
an ideal schedule to exist, the envelope must intersect this ray. Such an intersection may
occur along a horizontal or a vertical segment. It occurs along a horizontal segment only
sup
sup
if (C A , C B ) ∈ Z I and ksup corresponds to a normal breakpoint. It occurs along a vertical
inf
segment only if (C inf
A , C B ) ∈ Z I (in this case kinf may either correspond to a normal or
sup
sup
a jump breakpoint). It is straightforward to prove that if either (C A , C B ) ∈ Z I and is a
inf
inf
normal breakpoint, or (C A , C B ) ∈ Z I , then an ideal schedule exists.
inf
Now consider the case ksup < 0. An ideal schedule exists if and only if either (C inf
A , CB )
sup
sup
∈ Z I and is a normal breakpoint or we have that (C A , C B ) ∈ Z I (or both).
+
−
Finally, consider ksup > 0 and kinf < 0 (obviously, in this case kmax
= kmin
= 0.) An ideal
sup
sup
inf
schedule exists if and only if either (C A , C B ) ∈ Z I and is a normal breakpoint or (C inf
A , CB )
∈ Z I and is a normal breakpoint (or both conditions hold). The computation of the quan+
−
, kmax
, ksup , kinf is done by scanning the ordered set E; then we know an ideal
tities kmin
schedule exists by simply checking the type of breakpoints and zones for ksup and kinf .
Now suppose that an ideal schedule does not exist. What follows is a direct consequence
of the Theorems in Section 5. We recall that once the value k1 is known, the analysis of
the nondominated points in Z II can be performed very easily by considering only jump
breakpoints at ki ≥ k1 . In order to determine k1 we define k p as the smallest value ki ∈ E
p
p
such that ki ≥ k1 . We let (C A , C B ) be the corresponding breakpoint. Let us distinguish two
cases:

1. the intersection between the envelope and the border II/IV is nonempty
2. the intersection between the envelope and the border II/IV is empty
In case 1, the point of the envelope for k = k1 lies on the border II/IV. If k1 is a breakpoint,
then obviously k p = k1 . If k1 is not a breakpoint, then the envelope crosses the border II/IV
p
p
horizontally. In both subcases, (C A , C B ) lies in Z II . Case 2 arises only when k1 ≥ 0 and
p
p
the envelope at k1 has a jump. Therefore, k1 = k p . Notice that in this case (C A , C B ) may
either lie in Z I or Z II .
In conclusion, k p can be determined as the minimum ki ∈ E satisfying at least one of the
following two conditions, corresponding to cases 1 and 2 above:

ki > 0

¢
¡ i
C A , C Bi ∈ Z II
¡
¢
and C iA , C Bi ∈ Z I ∪ Z II

(9)

Given k p , we can identify all nondominated points in zone Z II by simply scanning the
ordered set E for increasing ki ≥ k p . In particular, if k p corresponds to a normal breakpoint,

NONDOMINATED SCHEDULES FOR A JOB-SHOP

215

p

then the point (d A , C B ) dominates all feasible schedules in Z II . If k p corresponds to a
jump breakpoint, then a nondominated segment is given by the portion of line segment
p
p
L p = [(C A , C B ), (d A , d A + k p )] falling in zone Z II . Other segments (open at the upper
extreme) are defined (according to Theorem 6) every time a value ki is found such that
the corresponding breakpoint is lower (i.e., having a smaller C B value) than the currently
lowest breakpoint. (If a breakpoint is found in Z I , then all the nondominated points in Z II
have been found, and the procedure stops.)
A perfectly symmetrical discussion holds for the border III/IV. In this case we define k p0
as maximum ki ∈ E satisfying at least one of the following two conditions:

ki < 0
p0

¢
¡ i
C A , C Bi ∈ Z III
¡
¢
and C iA , C Bi ∈ Z I ∪ Z III

(10)

p0

Let (C A , C B ) be the corresponding point on the envelope. Given k p0 , we can identify
all nondominated points in zone Z III by simply scanning the ordered set E for decreasp0
ing ki ≤ k p0 . In particular, if there is a normal breakpoint at k p0 , then the point (C A , d B )
dominates all feasible schedules in Z III . If k p0 corresponds to a jump breakpoint, then the
p0
p0
segment [(C A , C B ), (d B − k p0 , d B )] ∩ Z III is nondominated. Other segments (open at the
left extreme) are defined every time a value ki is found such that the corresponding breakpoint is at the left of the currently leftmost breakpoint. (If a breakpoint is found in Z I , then
all the nondominated points in Z III have been found, and the procedure stops.)
Finally, let us consider zone Z IV . Obviously, degenerate breakpoints can be immediately
ruled out. Recall that, because of Theorem 1, a nondegenerate normal breakpoint in zone
IV is nondominated.
Concerning jump breakpoints, we note that some of them may be dominated. A jump
y
y
y
breakpoint (C Ax , C Bx ) is dominated by another jump breakpoint (C A , C B ), if C Ax ≥ C A and
y
x
C B ≥ C B . Hence, to find nondominated breakpoints with ki > 0 we only need scan E in
+
(if k p < 0, there are no breakpoints in Z IV for positive ki ).
decreasing order from k p to kmin
−
(obviously,
Similarly, for the case ki < 0 we will scan E in increasing order from k p0 to kmax
if k p0 > 0, there are no breakpoints in Z IV for negative ki ).
We can summarize the procedure to find nondominated points from E as follows:
1.
2.
3.
4.
5.

Check for the existence of an ideal schedule. if it exists, STOP.
Compute k p and k p0 satisfying (9) and (10), respectively.
Find nondominates points in Z II by scanning E in increasing order starting from k p .
Find nondominates points in Z III by scanning E in decreasing order starting from k p0 .
If k p > 0, find nondominates points in Z IV by scanning E in decreasing order from k p
+
to kmin
, If k p0 < 0, find nondominates points in Z IV by scanning E in inecreasing order
−
.
from k p0 to kmax
6. STOP.
This procedure can be implemented to run in time O(|E|). Hence, the overall complexity
of the two-user problem is determined by the phase in which E or the schedule envelope

216

AGNETIS ET AL.

is developed. This, as shown in Section 4, has the complexity O(r log r ) (where r is the
number of incompatible pairs).
6.

Conclusions

This paper addressed a new resource scheduling problem where there are two users competing for a common set of resources to perform their respective jobs. The objective of each
competitor is a general quasi-convex cost function of the completion time of his job. The
problem consists of finding the nondominated schedules over which the two competitors
may negotiate to come up with a compromise schedule.
We have characterized the set of nondominated schedules in this scenario and have shown
that this set can be generated very efficiently, in polynomial time.
This leads to an important problem for future research. Suppose each job is provided
with a nominal “starting time”, in addition to a due date. One case may be to develop a
method to find nondominated schedules when there are additional penalties for starting
early (i.e., expediting costs). Here we may model the starting-time cost functions as being
regular. A more general, and possibly much more challenging, problem arises when there
are costs for both starting earlier than the nominal time and starting later than then nominal
time (due to, for example, inventory carrying costs).
Acknowledgments
This work was done while P.B. Mirchandani was visiting professor at the “Istituto di Analisi
dei Sistemi e Informatica” (IASI-CNR)—Roma. Dr. A. Pacifici was partially supported by
the CNR-PF Trasporti Research Project. Dr. D. Pacciarelli was partially supported by the
EC (project N. TR 4004, COMBINE).
References
Agnetis, A. and G. Oriolo (1995), “The Machine Duplication Problem in a Job Shop with Two Jobs,” International
Transactions on Operational Research, 2(1), 45–60.
Akers, S.B. and J. Friedman (1955), “A Non-Numerical Approach to Production Scheduling Problems,” Operations
Research, 3(4), 429–442.
Baker, K.R. and G.D. Scudder (1990), “Sequencing with Earliness and Lateness Penalties: A Review,” Operations
Research, 38, 22–36.
Brewer, P.J. and R.P. Plott (1994), “A Binary Conflict Ascending Price Mechanism for Decentralized Allocation
of the Right to Use Railroad Tracks,” Working Paper, Division of Humanities and Social Sciences, California
Institute of Technology.
Brucker, P. (1988), “An Efficient Algorithm for the Job-Shop Problem with Two Jobs,” Computing, 40, 353–359.
Cai, X. and C.J. Goh (1994), “A Fast Heuristic for the Train Scheduling Problem,” Computers and Operations
Research, 21, 499–510.
Carey, M. and D. Lockwood (1995), “A Model, Algorithms, and Strategy for Train Pathing,” Journal of Operational
Research Society, 46, 988–1005.
French, S. (1982), Sequencing and Scheduling: An Introduction to the Mathematics of the Job Shop. Ellis Horwood
Ltd., Chichester, UK.

NONDOMINATED SCHEDULES FOR A JOB-SHOP

217

Hall, N.G. and M.E. Posner (1991), “Earliness-Tardiness Scheduling Problems. I: Weighted Deviation of Completion Times about a Common Due Date,” Operations Research, 5, 836–846.
Hardgrave, W.W. and G.L. Nemhauser (1963), “A Geometric Model and a Graphical Algorithm for a Sequencing
Problem,” Operations Research, 11(6), 889–900.
Kraay, D., P.T. Harker and B. Chen (1991), “Optimal Pacing of Trains in Freight Railroads: Model Formulation
and Solution,” Operations Research, 39, 82–99.
McCabe, K.A., S.J. Rassenti and V.L. Smith (1990), “Experimental Research on Deregulating Natural Gas Pipeline
and Electric Power Transmission Networks,” Working Paper, Center for Law and Economic Studies, Columbia
University School of Law.
Raghavachari, M. (1988), “Scheduling Problems with Non-regular Penalty Functions—A Review,” Opsearch, 25,
145–164.
Rassenti, S.J., V.L. Smith and R.L. Bulfin (1982), “A Combinatorial Auction Mechanism for Airport Time Slot
Allocation,” Bell Journal of Economics, 402–415.
Szwarc, W. (1960), “Solution of the Akers-Friedman Scheduling Problem,” Operations Research, 8(6), 782–788.

Alessandro Agnetis is Associate Professor of Operations Research at the Department of Information Engineering
of the University of Siena. His fields of interest include production planning and scheduling, combinatorial optimization and decision models in logistics. He has published on several international journals including Management Science, IEEE Transactions on Robotics and Automation, Discrete Applied Mathematics, IIE Transactions
and European Journal of Operational Research.
Pitu B. Mirchandani is a Professor at the University of Arizona with joint appointments in Systems & Industrial
Engineering and in Electrical & Computer Engineering Department. He is also the Director of the recently
established ATLAS (Advanced Traffic and Logistics Algorithms and Systems) Research Center at the University
of Arizona. He has BS/MS degrees in Engineering from UCLA, a SM from MIT in Aeronautics and Astronautics,
and a ScD in Operations Research, also from MIT. His areas of technical expertise include optimization, logistics
(scheduling, location, and routing), stochastic networks, and design of real-time decision and control systems
for spatially distributed systems. He has over 70 publications including two books on Location Theory. Dr.
Mirchandani has been a principal investigator on numerous projects in logistics, transportation and manufacturing
systems, has been funded by various governmental organizations including NSF, USDOT, AzDOT, NYDOT.
NASA; Several US cities; and many firms (GE, GM, IBM, Alcoa, Hughes, etc.).
Dario Pacciarelli is Assistant Professor at the Department of Computer Science and Automation of the Roma Tre
University. His fields of interest include Machine Scheduling, Production Planning, Supply Chain Scheduling and
Conflict Resolution in Rail Transportation Industry. He has published in major international journals including
Discrete Applied Mathematics, IIE Transactions and European Journal of Operational Research.
Andrea Pacifici is Assistant Professor at the Department of Computer Science, Systems and Production, University
of Rome “Tor Vergata”, Italy. His research work mainly concerned the design of efficient algorithms for machine
layout and material flow management problems, Scheduling for Logistics and Production Management, Autonomous Agents.

Intelligent Transportation Systems

Editor: Alberto Broggi
University of Parma, Italy
broggi@ce.unipr.it

The VISTA Project and Its
Applications
Fei-Yue Wang and Pitu B. Mirchandani, Program for Advanced Research in Complex
Systems, and Advanced Traffic and Logistics Algorithms and Systems Center,
University of Arizona
Zhixue Wang, Intelligent Control and Systems Engineering Center,
Chinese Academy of Sciences

This interesting installment presents the current projects and research activities under investigation at the University of Arizona and at the Chinese Academy of Science’s Intelligent Control and Systems Engineering Center.
The authors describe the VISTA Project and its main achievements so far and discuss the most important objectives that will be reached in 2005, at this initiative’s end.
If you have any comment on this department, feel free to contact me. I also seek contributions on the current
status of ITS projects worldwide as well as ideas on and trends in future transportation systems. Contact me at
broggi@ce.unipr.it; www.ce.unipr.it/broggi.
—Alberto Broggi

I

n Arizona, a window of opportunity exists for using
planned infrastructure expenditures to construct “intel-

ligent lanes” on Interstate Highway 10 between Phoenix
and Tucson for deploying intelligent vehicles (IVs). The
Arizona Department of Transportation (ADOT) has identified the need for a third lane on I-10 in each direction
between the two cities by 2005 and a fourth lane by 2020.
Research shows that deploying IVs is feasible and beneficial if the communication and electronics infrastructure
can be incorporated with minimal additional cost into the
construction of additional lanes.1 In fact, a study by BRW
has proposed a six-phase, three-track approach that addresses both the need to increase the Phoenix–Tucson corridor’s capacity and the deployment of IVs if necessary.2
Although BRW discussed options for IV technologies
for the Phoenix–Tucson corridor, it did not recommend
any specific technology. The choice of technology involves these issues:
• The vehicle’s “intelligence” must be affordable by a
large segment of the population.
• Initially, conventional vehicles should be able to use the
infrastructure.
• The additional agency cost for equipping the infrastructure must not be so high that it offsets the IV’s benefits.
In 1998, the University of Arizona formed the Vehicles
with Intelligent Systems for Transport Automation research
72

team, which the ADOT charged with the mission of investigating new and existing technologies and concepts that
address those issues. The Arizona state legislature and
ADOT funded the VISTA Project initially. The VISTA
team consisted of 16 faculty members, research associates, and assistants from the University of Arizona and
Arizona State University.3 Since 2000, the VISTA project
has been continuing as a joint project with the Chinese
Academy of Science’s Intelligent Control and Systems
Engineering Center (ICSEC), sponsored partly by the
University of Arizona’s ATLAS (Advanced Traffic and
Logistics Algorithms and Systems) Center, China’s National Natural Science Foundation, the Triangle Group,
and the CASIC Corporation.

The vehicle and control system
To demonstrate the deployability of VISTA’s IV and
automated-highway-system concepts, the team built
VISTA Vehicle I, a demonstration vehicle based on the
PATH (Partners for Advanced Transit and Highways)
Vehicle.4 Figure 1 shows VISTA Vehicle I and its hardware. VISTA Vehicle II, built at ICSEC, is equipped with
an additional Differential Global Positioning System, an
inertial measurement unit, and a laser reader that determines the vehicle’s position and velocity by reading a
special bar code on the ground for calibration.
Based on the behavior-programming approach for robotic
vehicles,5 the VISTA vehicles’ control system comprises
a set of hierarchically organized agent programs. These
agents perform such functions as long-range path plan-

1094-7167/02/$17.00 © 2002 IEEE

IEEE INTELLIGENT SYSTEMS

Braking controller
Radar

Camera
Radar

Throttle controller
Camera
Control panel
Driver
interface
computer

Encoder
Steering Steering
controller wheel
Tachometer
Vehicle computer

(a)

(b)

Figure 1. (a) VISTA Vehicle I and its (b) hardware (based on the PATH vehicle4).

ning, radar-based headway maintenance,
radar-based road following, and close vehicle following. One agent classifies the driving conditions into different modes and
then activates the agent corresponding to
the current mode to control the vehicle.
Figure 2 presents the VISTA control system’s hierarchical control structure.
Each agent consists of a set of fuzzy rules
that organize basic control commands. The
system obtains many of the fuzzy rules
directly by mimicking human driving behaviors. Because fuzzy control rules use
linguistic terms such as “if the distance
between the two vehicles is a little large,
then increase the speed a little bit,” the team
can easily convert human driving skills and
experiences into agents. At first, the system
used a nonadaptive fuzzy technology. Later,
the team implemented the neurofuzzy
method3 to add learning capability to the
agents to improve driving performance.

Methods
To achieve the specified objectives, the
team has developed and tested three methods.
The first is calibration-based vehicle
control instead of guidance-based vehicle
control. The team uses bar code-based calibration stations to determine the vehicle’s
position with high accuracy. These stations
also offer a parameterized curve representing the center line of a lane to be followed
for a long distance ahead. The distance between two stations is relatively large (about
one mile in the test); between them, the vehicle uses only the in-vehicle sensory information for driving. The control system recalibrates the in-vehicle sensors when the
NOVEMBER/DECEMBER 2002

Display

Driver
Trajectory generation
Long-range
information

Target trajectory
Identification

Mode selection

Vehicle dynamic
information

Short-range
information

Driving mode

Task execution
Processed sensor
information

Real-time instruction
to actuators

Sensor
information

Vehicle and sensors

Sensor information

Figure 2. The VISTA control system’s hierarchical structure.

vehicle passes a station. This method reduces the cost of constructing and maintaining road-site sensors and provides vehicles with long-range road information.
The second method is trajectory planning and optimization based on the longrange road information. This can help
reduce energy consumption and air pollution while increasing traffic throughput for
vehicles and traffic control.
The third is distributed hierarchical agentbased control instead of traditional functional
decomposition into sensing, planning, and
acting. As we mentioned before, the vehicle
control system is decomposed into hierarchically organized special-purpose task-achieving modules—that is, agent programs.
On 21 March 1999, the VISTA team successfully demonstrated autonomous control
computer.org/intelligent

of VISTA Vehicle I to its Technical Advisory
Committee at an Arizona State University
field test (see Figure 3a). On 27 and 28 April
1999, the VISTA team successfully demonstrated VISTA Vehicle I’s longitudinal and
lateral controls to the public and ADOT on
Highway 51 in Phoenix (see Figure 3b).

Applications
The three methods have applications in
many fields; here are three examples.
Automated vehicle proving grounds. Deployment of calibration-based vehicle control (or
any automated driving techniques, for that
matter) for automated driving on highways
will take a long time. However, this method
is practical, economical, and reliable for
constructing automated vehicle-proving
73

(a)

(b)

Figure 3. (a) Field test and (b) demonstration of autonomous control of VISTA Vehicle I on Highway 51 in Phoenix, Arizona. (In both
pictures, the front car is a human-driven test vehicle and the car behind is VISTA Vehicle I.)

grounds to test mass-produced cars. Because
proving grounds are controlled, known environments, barcode-based calibration stations
can provide accurate information on vehicle
position and velocity. They can also greatly
simplify the computational and communications requirements for automated driving on
vehicle test tracks.6 China’s National HighTechnology Research and Development Program (also called the 863 Program) is using
calibration-based vehicle control to construct
a prototype of an automated vehicle- and
tire-proving ground.
Recommending vehicle speeds and steering
angles. Current technologies such as Global
Positioning System, Global Information System, Global System for Mobile Communication, and digital maps support long-range
road information. Because the VISTA approach exploits such information, vehicle
trajectory planning and optimization become
practical and useful. The current GPS-based
vehicle navigation systems give drivers only
the direction and distance. With optimaltrajectory planning, a vehicle navigation system can calculate online or offline the desired
vehicle speed and steering wheel angle, at
any time and point, for driving to a destination on a specified path. The system can also
take into account optimality criteria such as
minimum energy consumption, minimum
time, and minimum jerk (the rate of change in
acceleration). So, instead of just suggesting
direction and distance, the system might also
recommend the appropriate speeds (for
example, telling the driver to speed up or
slow down a little bit) and steering angles (for
74

example, telling the driver to turn the steering
wheel left or right a little bit). Initial results
for this application appear elsewhere.7
Individualized automatic vehicle control.
Because human driving skills and experiences are easily converted into agents,
VISTA’s control system can train an autonomous IV to acquire a human driver’s
behavior using a neurofuzzy network. The
basic idea is to install an initial automated
control system using a fuzzy-logic agent
and then modify its control rules to fit an
individual driver’s behavior.
To achieve this, the system records driving actions and the corresponding vehicle
motions during the learning phase. Through
the neurofuzzy network implementation of
the initial control system, the system plays
back the recorded information offline as the
training data to refine the membership functions for linguistic-input signal patterns,
output control actions, and conjunction operators in the fuzzy reasoning. After extensive training, automated driving adapts to
the driver’s behavior.
This method provides an effective mechanism to construct driving control systems
with personality for IVs. Initial results for
learning longitudinal driving behaviors
appear elsewhere.8

T

he US Federal Highway Administration,
ADOT, and CASIC are sponsoring the Arizona Digital Highway Project through the
ATLAS Center. This project uses VISTA’s
computer.org/intelligent

methods to develop and test digital vehicle
and highway technologies to enhance driving
safety. The project’s basic technical concept
is that if, through state-of-the-art sensor and
geolocation technology, a vehicle knows
within centimeters where it is and knows to a
similar precision where the roadway is, many
highway accidents can be prevented by warning drivers of possible hazardous situations.
Furthermore, if, through vehicle-to-vehicle
communication, the vehicle knows where all
other vehicles in its vicinity are, most highway fatalities can be eliminated. The project
will be completed in 2005.

Acknowledgments
We express our appreciation to the VISTA
team for their great effort in the project. We also
thank the Arizona Dept. of Transportation, especially Tim Wolfe and Steve Owen, for their support and confidence in our endeavor. Finally, we
appreciate the VISTA Technical Advisory Committee’s input. The State of Arizona Dept. of
Transportation, the US Dept. of Transportation,
an Outstanding Oversea Scholar Award, and the
Outstanding Young Scientist Research Fund
partly supported this research.

References
1. S. Kuppuswamy and P.B. Mirchandani, Systems Analysis of Tucson-Phoenix Intelligent
Lanes, report FHWA-AZ00-461, Ariz. Dept.
of Transportation, Phoenix, Ariz., 2001.
2. D.W. Bruggeman, Concept Study: Intelligent
Express Lanes I-10, Phoenix to Tucson, tech.
report, Ariz. Dept. of Transportation, Phoenix,
Ariz., Dec. 1997.
IEEE INTELLIGENT SYSTEMS

3. F.-Y. Wang, P.B. Mirchandani, and Y.C. Kuo,
“Vehicles with Intelligent Systems for Transport Automation: VISTA Report,” report
FHWA-AZ00-462, Ariz. Dept. of Transportation, Phoenix, Ariz., 2001.
4. S. Sheikholeslam et al., “Automated Vehicle
Control Developments in the PATH Program,” IEEE Trans. Vehicular Technology,
vol. 40, no. 1, Feb. 1991, pp. 114–130.

Fei-Yue Wang is a professor in the University of Arizona’s Systems &
Industrial Engineering Department and the director of the University’s
Program for Advanced Research for Complex Systems. He is also the
director of the Intelligent Control and Systems Engineering Center at the
Chinese Academy of Sciences’ Institute of Automation. His major technical interests are intelligent and complex systems. He received his BS in
chemical engineering from the Shandong Institute of Chemical Technology, his MS in mechanics from Zheijiang University, and his PhD in
Computer Science and Systems Engineering from Rensselaer Polytechnic Institute. Contact him at feiyue@sie.arizona.edu.

5. F.-Y. Wang and P.J.A. Lever, “An Intelligent
Robotic Vehicle for Lunar and Martian
Resource Assessment,” Recent Trends in
Mobile Robots,Y.F. Zheng, ed., World Scientific, Singapore, 1994, pp. 327–358.

Zhixue Wang is a research scientist at the Chinese Academy of Sciences’ Intelligent Control and Systems Engineering Center. His major
technical interests are intelligent control, intelligent vehicles, and
embedded systems.

6. F.-Y. Wang, Design of Test Driving Robots
and Automated Vehicle Proving Grounds,
Intelligent Control and Systems Eng. Center
tech. report 0602, Inst. of Automation, Chinese Academy of Sciences, Beijing, 2002.
Pitu B. Mirchandani is the Salt River Project Professor of Technology

7. L. Li and F.-Y. Wang, “Vehicle Trajectory
Generation for Optimal Driving Guidance,”
Proc. IEEE Int’l Conf. Intelligent Transportation Systems, IEEE Press, Piscataway,
N.J., 2002, pp. 156–172.
8. Y.T. Lin et al, “Implementing Adaptive Driving Systems for Intelligent Vehicles by
Using Neuro-Networks,” J. Transportation
Research Board, no. 1,774, Nov. 2001, pp.
106–115.

at the University of Arizona and has joint appointments in the university’s Systems & Industrial Engineering Department and Electrical &
Computer Engineering Department. His technical interests include optimization, logistics and design of real-time decision and control systems,
and distribution of services and goods. He received his BS and MS in
engineering from the University of California, Los Angeles, and his SM
in aeronautics and astronautics and his ScD in operations research from
the Massachusetts Institute of Technology. Contact him at the Systems &
Industrial Eng. Dept., Univ. of Arizona, Tucson, AZ 85721; pitu@sie.
arizona.edu.

MEDICINE,
AND HEALTH CARE NOW HAS A NEW SPONSOR!

A LEADING JOURNAL ON TECHNOLOGY IN

The IEEE Computer Society has joined the IEEE Engineering
in Medicine and Biology Society in delivering IEEE
Transactions on Information Technology in Biomedicine.
Peer-reviewed articles feature topics such as
•
•
•
•
•
•
•
•

biomedical engineering
virtual reality applications for surgery
visualization and biomedical imaging
ethical issues in biomedical applications
information infrastructures in health and medicine
high performance biomedical computing
biotechnology
broadband technologies in medicine

IEEE Computer Society members can subscribe
for the low member rate of $25!
Read more about IEEE Transactions on Information Technology in Biomedicine

http://www.ieee.org/organizations/pubs/transactions/titb.htm

Intl. Trans. in Op. Res. 15 (2008) 565–582

INTERNATIONAL
TRANSACTIONS
IN OPERATIONAL
RESEARCH

Truck schedule recovery for solid waste collection in Porto
Alegre, Brazil
Jing-Quan Lia, Denis Borensteinb and Pitu B. Mirchandania
a

b

Systems and Industrial Engineering, The University of Arizona, Tucson, AZ 85721, USA,
Management School, Universidade Federal do Rio Grande do Sul, R. Washington Luis 855, Porto Alegre 90010-460, RS,
Brazil
E-mail: jingquan@email.arizona.edu [Li]; pitu@sie.arizona.edu [Mirchandani]; dborenst@ea.ufrgs.br [Borenstein]
Received 10 October 2007; received in revised form 5 March 2008; accepted 6 March 2008

Abstract
This paper considers a truck schedule recovery problem in the context of solid waste collection in the city of
Porto Alegre, Brazil. When a truck on a scheduled trip breaks down, a backup truck needs to be selected to
serve the cargo on that trip and other trucks might be rescheduled in order to gain the minimum operating
and delay costs. The problem consists of designing, in the case of a severe disruption in a trip, new schedules
taking into account the existing trucks in the system and a set of unﬁnished and not initiated collection
trips, on which the trucks collect the solid waste in ﬁxed routes and empty the loads in one of the several
operational recycling facilities. The main objective is to minimize the total distances traveled and delay
costs, as well as to obtain balanced assignments of truck unloads into the recycling facilities, due to the
social beneﬁts of the solid waste program. We modeled the problem as a mixed-integer linear problem and
used CPLEX to solve it. Finally, computational experiments are conducted on real-world data. The results
show that our approach successfully reduces the distances traveled and delays, simultaneously balancing
the number of trucks unloading at each recycling facility, in comparison with the current manual strategy.
Keywords: vehicle scheduling; logistics; solid waste management; developing countries

1. Introduction
Solid waste management is receiving increasing attention due to its impact on the public concern
over the environment. Recycling is becoming the most eﬀective option for the disposal of solid
waste. Waste recycling involves collection, transportation and unloading in a recycling facility for
processing. Municipal authorities are generally responsible for the collection and transportation
of solid waste. Nevertheless, these are very expensive services provided for the residents, because
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies
Published by Blackwell Publishing, 9600 Garsington Road, Oxford, OX4 2DQ, UK and 350 Main St, Malden, MA 02148, USA.

566

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

between 75% and 80% of the solid waste management budget is spent on collecting and
transporting waste (Bhat, 1996).
In Porto Alegre, the capital of the southernmost Brazilian state, Rio Grande do Sul, with a
population over 1.3 million people, waste collection is carried out by DMLU, a Portuguese
acronym for Departamento Municipal de Limpeza Urbana (Urban Waste Municipal Department, in English). DMLU has an annual budget of more than US$20 million and employs 3500
workers. Several services, including beach sanitation, public toilet maintenance, garbage and solid
waste collection, transportation and disposal, are provided by DMLU, which pioneered the
establishment of a solid waste management system in Brazil. Currently, the system has become
widely recognized in developing countries due to its operational aspects and the degree of
satisfaction of residents.
Although the system is eﬃcient in terms of the volume of solid waste collected and processed,
the costs involved are high (around 25% of DMLU budget). Previous DMLU eﬀorts have
focused on the design of eﬃcient collection routes in order to shorten the service time to cover
more compact regions. DMLU has not conducted a systematic planning for scheduling trucks.
Managers in DMLU are concerned about the eﬃciency of the existing waste-ﬂow for each shift of
a collection day, mainly when the system encounters disruptions that prevent it from operating as
planned. Truck breakdowns and problems in the recycling facilities are the main examples of
frequent disruptions that demand the rescheduling of vehicles. Currently, DMLU managers apply
a simplistic strategy: to send a backup truck from depot to recover the disrupted trip, without
changing the schedule of the remaining unﬁnished trips. However, it might be possible to
reschedule trucks in the system to recover the disrupted collection trip, avoiding larger delays in
all future collection trips. Furthermore, even if the new schedule avoids delays, it cannot be
employed unless the balanced assignment of solid waste into recycling facilities is attained. A
schedule is not acceptable if the trucks unload the solid waste only in some facilities and leave
others empty.
The development of new information technologies (e.g., global positioning system,
geographical information systems, cellular phones, etc.) has raised DMLU interest in automatic
recovery strategies. As real-time information is now available at low-cost, human schedulers
might react to unexpected events in real time. Such uncertain situations have not been eﬀectively
incorporated in DMLU due to the lack of automatic recovery tools speciﬁcally designed for its
solid waste collection program.
In this paper we propose a mixed-integer linear programming formulation to implement an
automatic recovery tool for solid waste collection carried out by DMLU. The problem consists of
deﬁning new implementable schedules for a set of previously scheduled trips, given that a trip has
been severely disrupted. The main objective of the model is to minimize the involved operation
cost, ﬁxed truck cost and delay cost, under the conditions that incomplete collection trips have to
be ﬁnished (including the disrupted one), and balanced trip assignments into recycling facilities
are attained. We demonstrate that our approach is eﬀective, running some experiments with realworld data from DMLU.
The paper is organized as follows. Section 2 reviews the related literature. Section 3 describes
the solid waste collection problem in Porto Alegre and provides the terminology and formal
problem description. In Section 4, a mixed-integer programming model is proposed to reschedule
the collection trips in the event of a disruption. Section 5 gives computational results using our
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

567

approach to real-world data. In the concluding Section 6, a summary of the results and areas of
future research are discussed.

2. Literature review
Because automatic recovery from disruptions is a relatively new operational strategy, the
literature related to the dynamic aspects of the vehicle rescheduling problem is sparse. The
majority of the research conducted in this area is related with the dynamic vehicle routing problem
(VRP) and with the airline recovery problem.
The dynamic VRP, occurring when new requests arise during operations, has gained increasing
attention since the late 1980s. Recent surveys on dynamic VRP can be found in Psaraftis (1995),
Ghiani et al. (2003) and Gendreau and Potvin (1998). Ichoua et al. (2000) have designed a
heuristic based on tabu search to handle the real-time vehicle dispatching problem. Yang et al.
(2004) have developed a general framework for dynamic VRP in which new requests can arrive
during operations, where the travel time is considered as a variable. Stochastic programming has
also been used to tackle uncertainty in vehicle scheduling and routing (e.g., see Laporte and
Louveaux, 1998; Powell et al., 1995).
Although the above-mentioned eﬀorts have studied dynamic aspects of the vehicle scheduling/
routing, the requirements of the truck schedule recovery problem, including ﬁnding a backup
vehicle and picking up cargo from the breakdown vehicle, have not been properly addressed.
The literature on aircraft disruption includes Carlson (2000), Lettovský (1997), Rosenberger
et al. (2003) and Teodorović and Stojković (1995). These research works developed optimization
models that reschedule legs by minimizing aircraft rerouting and cancellation costs. Given the
high number of operational and safety requirements involved, the majority of the developed
algorithms are computational intensive. As a consequence, it is unrealistic to use such approaches
directly for a simpler problem as the truck schedule recovery.
To the best of our knowledge, the only contributions toward solving the dynamic vehicle
scheduling problem (VSP) are found in Huisman et al. (2004) and Li et al. (2004). Huisman et al.
(2004) have proposed an approach to the dynamic VSP by solving a sequence of optimization
problems. Their work is motivated by designing robust vehicle schedules to avoid trips starting
late in environments characterized by signiﬁcant traﬃc jams. Li et al. (2004) have developed a
parallel auction algorithm for the bus rescheduling problem. The bus rescheduling problem is
modeled as several VSP problems, each corresponding to the use of a diﬀerent vehicle as an
alternative to backup the disrupted trip. All problems are solved using a parallel implementation
of a combined forward–backward auction algorithm developed by Freling et al. (2001), designed
for the quasi-assignment problem. The parallel algorithm has proved to be computationally
eﬃcient, even for large problems. Li et al. (2007) also designed a decision support system for the
vehicle rescheduling problem (VRSP) to be used within an automated recovery strategy.
Some studies have been conducted to describe the application of Operations Research methods
and techniques toward solid waste management. A recent review on waste management models
can be found in Morrissey and Browne (2004), a study that emphasizes designing appropriate
policies for eﬃcient and economic collection. Eisenstein and Iyer (1997) investigate a dynamic
scheduling model based on a Markov decision process to reduce truck capacity. Bodin et al.
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

568

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

(1989) developed a heuristic procedure to generate daily collection routes for a truck based on the
statistical load information and collection travel time. Bhat (1996) designed a simulationoptimization model to allocate trucks to disposal sites. All of these studies ignore the real-time
aspects of the solid waste collection problem, focusing on its oﬀ-line planning.

3. Solid waste collection problem in Porto Alegre
Solid waste collection in Porto Alegre involves 150 neighborhoods. More than 60 tons of solid
waste are collected per day and distributed to eight recycling units. The collection and distribution
of solid waste are carried out by DMLU. Recycling facilities are managed by cooperatives, whose
members are mostly poor and are not part of the mainstream economy. In these facilities, the solid
waste is separated, appraised, stored and commercialized. The proﬁt remains with the
cooperatives and it is transformed into an important income source for 450 workers.
The collection is performed weekly in each street of the city. The solid waste should be put out
at a maximum of 30 min before the collection. Strict ﬁnes might be imposed on the residents who
do not obey this rule. DMLU distributes informative leaﬂets containing the schedule of the
collection trucks for each street. The main purpose is to protect the proﬁts of the cooperatives that
run the recycling units, because independent companies may collect the waste before DMLU in
order to obtain economic value from the waste.
Every day, trucks leave the depot at 08:00 hours and start a collection route. The routes were
deﬁned by DMLU managers based on the municipality neighborhood division. The idea is to
conduct the collection of all streets within the same neighborhood. When a truck completes its
collection, it moves toward a recycling facility to unload the collected waste. The choice of which
facility will be used by each truck is based on several criteria, such as distance from the collection
ending point to the facilities, the current available capacity of the facilities and so forth. Because
there are currently eight recycling facilities located in diﬀerent places within the city limits, and the
collection in a shift is conducted in distant neighborhoods simultaneously, DMLU managers have
decided to send trucks directly to the recycling facilities, instead of consolidating the cargo in a
larger truck. When a truck arrives at the recycling facility, it is weighed and unloaded. After
unloading, the truck returns to the depot or serves the next collection trip. All trucks should go
back to depot at 12:00 hours for lunch. The same routine is executed in the afternoon, starting at
14:00 hours and ﬁnishing at 18:00 hours.
Although the system is eﬀective, unexpected circumstances have not been eﬀectively
incorporated. Vehicle breakdown is a typical example of possible disruptions that demand the
rescheduling of vehicles. Truck breakdown may also cause the delay of trips due to vehicle
reassignments. Therefore, managers in DMLU are concerned about disruption management when
an unexpected event occurs. Furthermore, schedules are frequently poor regarding imbalanced
trip assignments to recycling facilities: some recycling facilities may be allocated excessive
collection trips, while others may be idle. Such schedules are rejected by the human schedulers,
because the social aspects of the solid waste program are given signiﬁcant consideration in each
decision. The speciﬁc objective of this study is to answer the following question: ‘‘What is the best
rescheduling strategy when an unexpected event occurs?’’
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

569

3.1. Problem description
We ﬁrst introduce some deﬁnitions and notation related to the truck schedule recovery problem
applied to solid waste collection. Collection trip refers to the movement of a truck while collecting
the solid waste in the streets of a city. Deadheading trips are all movements carried out by trucks that
are not in collection trip. To relate to a cut in a graph, we call a disrupted trip due to a disabled
vehicle, or a vehicle that is eﬀectively inoperable, a cut trip. Breakdown point is the point at which the
cut trip is disrupted. Current trip is the trip on which a vehicle is running. Future trip is a trip that
has not yet been initiated. It includes both collection and deadheading trips. The vehicle that serves
the remaining portions of the cut trip is referred as the backup vehicle. This vehicle can be identiﬁed
through the trip just served, which will be referred as the backup trip subsequently.
A truck can suﬀer a breakdown in ﬁve diﬀerent kinds of situations as follows:
1.
2.
3.
4.
5.

while
while
while
while
while

in a regular collection trip;
deadheading from a collection trip to a recycling facility;
deadheading from a recycling facility to a future collection trip;
deadheading from the depot to a future collection trip; and
deadheading from a recycling facility to the depot.

In the ﬁrst and second cases, the truck is loaded with solid waste that has to be served. The solution
includes sending a backup truck to the breakdown point, and from there completing the cut trip,
serving its cargo. We assume that a truck should ﬁrst complete its current trip before being
rescheduled. In the third and fourth cases, we do not need to pick up the cargo in the breakdown
truck because it is empty. The solution is to assign a backup truck to the starting location of the
next trip of the breakdown truck. We do not need to conduct rescheduling in the ﬁfth situation.
For all the situations, it is very likely that the solution to the problem provides new routes (a
reassignment) for a subset of the pre-assigned vehicles. Also, we can expect some delays in the cut
trip in the ﬁrst two situations. Meanwhile, the breakdown truck may also cause the delay of other
trips. Consider a situation where a backup truck was previously assigned to another trip, but not
the cut trip. The previously assigned trip would certainly be delayed if its starting point is too far
from other trucks or the depot. However, if the delay for other trips, except the cut trip, is too
signiﬁcant, the scheduler might not accept the new assignment. For this situation, we can set a
maximum delay for each future trip. If the delay exceeds this limit, this is not a feasible schedule.
The truck schedule recovery problem can be deﬁned as follows. Given a depot and a series of
trips with prescribed starting and ending times, given the travel times between all pairs of locations,
and given a cut trip, ﬁnd a feasible minimum-cost (including operational, ﬁxed and delay costs)
reschedule in which (1) any uncompleted trip is served by a truck, (2) the solid waste cargo on the
cut trip is served and (3) the delay for other trips, except the cut trip, cannot exceed a given limit.
The next section presents our mixed-integer linear programming formulation for this problem.

4. Modeling the truck scheduling recovery problem
The classical VSP formulation may not be applied to this speciﬁc case study, due to the following
additional constraints: (i) it is not allowed that a truck comes from the depot and goes directly to a
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

570

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

recycling facility; (ii) after ﬁnishing its collection trip, a truck has to ﬁrst go to a recycling facility for
unloading the garbage instead of going to the depot directly or serving a new trip; and (iii) it is allowed
that any of the uncompleted trips is delayed due to vehicle rescheduling, while in classical VSP, the
starting time of trips is ﬁxed. Thus, we need to investigate a new model to formulate the problem.
Before giving the formulation, we introduce the following notation used in the remainder of the
paper:
Bi: prescribed starting time of trip i.
Wi: prescribed waste collection time of trip i.
Tij: travel time from the ending point of trip i to the starting time of trip j.
Di: maximum delay allowed for trip i.
F: breakdown time.
U: unloading time at each recycling facility.
s: denotes the depot as the leaving point for all trucks.
t: denotes the depot as the arriving point of all trucks.
The most important and complicating aspect of the truck scheduling recovery problem is that
the solution is dependent on the existing status of trucks and available alternatives to serve the cut
trip. As mentioned in the previous section, a breakdown truck may be in ﬁve diﬀerent positions
during its operation. Likewise, the remaining existing trucks can also be in ﬁve diﬀerent positions.
In order to give the mathematical formulation, we need to deﬁne the new vehicle scheduling
network capable of representing the problem.

4.1. Deﬁnition and classiﬁcation of trips
In this section, the nodes of the vehicle scheduling network are deﬁned. Let A1 be the set of trips
that are being served by a truck in the instant of a trip disruption (Situation 1 in the previous
section). Let A2 be the set of deadheading trips from a collection trip to a recycling facility being
served by a truck at certain instant F (Situation 2). In both situations, trucks need to go to a
recycling facility for unloading the waste and do not need a truck assignment. For each trip in A2,
set Wi to be 0.
Let A3 be the set including all collection trips with Bi4F (e.g., all future collection trips). If a
truck breaks down on a collection trip or while in deadheading trip from the collection trip to the
recycling facility, the cut trip is also included into set A3 with a new starting time equal to F.
Otherwise, we do not need to include it into A3. As mentioned in the previous section, the solution
in these situations is to allocate a backup truck for the starting location of the next trip of the
deadheading truck. Trips in set A3 might be re-assigned to diﬀerent trucks from their pre-assigned
ones in the initial schedule, while trips in set A1 [ A2 cannot be reassigned. A1 [ A2 [ A3 can be
seen as the set of all unﬁnished trips.
In VSP, a vehicle can be generally assigned from depot to any trip before its starting time.
Nevertheless, it may fail to assign a vehicle from the depot to some future trips in the rescheduling
problem if the arrival time of the truck, which is from the depot to the starting point of a trip, is
beyond the maximal delay. Hence, we can treat the depot s as a special trip and deﬁne its starting
time to be the breakdown time. This time is used to determine if a backup truck from the depot is
too late to serve a future trip.
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

571

For each unﬁnished collection trip in set A1 [ A3, we create K associated dummy trips representing
the K recycling facilities, respectively. The starting time of each recycling facility associated (RFA)
trip is the ending time of the corresponding collection trip plus the travel time from the ending point
of its collection trip to a recycling facility. The duration of each RFA trip is unloading and service
times at the facility. After determining the starting and ending times of each RFA trip, we can
construct the potential scheduling network in such a way that a collection trip is connected to all
recycling facilities through RFA trips. There are no direct connections among collection trips,
meeting the problem requirements. Let R(i) be the RFA trips associated with collection trip i in the
set A1 [ A3. Let R ¼ Rð1Þ [ Rð2Þ [    [ RðjA1 j þ jA3 jÞ be the set of all RFA trips.
We also need to deﬁne nodes representing trucks on other deadheading trips (Situations 3, 4 and
5). If a truck is in the Situations 3, 4 or 5 in an instant of disruption, this truck is ready to be
rescheduled, because it has not started a collection trip. This position can be seen as a pseudodepot with capacity 1, and from there a truck can be dispatched for any trip in A3. We can deﬁne
set PD as the existing pseudo-depots in an instant F. Similar to the real depot s, we treat a pseudodepot as a special trip and deﬁne its starting time as the vehicle breakdown time, in order to
determine if this special trip can construct possible compatible trip pairs with other collection trips.
Finally, let N 5 A1 [ A2 [ A3 [ R [ PD be the set of all nodes in the vehicle rescheduling
network.

4.2. Deﬁnition of potential scheduling networks
The potential scheduling network for our problem can be deﬁned as a graph in which the nodes
represent collection trips, deadheading trips in set A2, RFA trips, depots and pseudo-depots; while
the arcs represent deadheading trips that are not in set A2. Arcs in the network correspond to
possible truck assignments to trips. Arcs are deﬁned formally as follows.
Let E1 ¼ fði; jÞji 2 fA1 [ A2 [ A3 g; j 2 RðiÞg be the set of arcs representing deadheading trips
from collection trips and deadheading trips being served by a truck in the instant of a trip
disruption to a recycling facility, and let E2 ¼ fði; jÞjctði; jÞ ¼ 1; i 2 R; j 2 A3 g be the set of arcs
representing deadheading trips from a recycling facility to a collection trip. We use a binary
relation ct to determine whether two trips may characterize a compatible pair of trips. If ðBi þ
Wi þ Tij þ Di Þ)ðBj þ Dj Þ; ctði; jÞ ¼ 1. Otherwise, ct(i, j) 5 0.
Let E3 ¼ fði; jÞjctði; jÞ ¼ 1; i 2 PD; j 2 A3 g be the set of arcs representing deadheading trips
from a pseudo-depot to a future collection trip. If a pseudo-depot, which represents an existing
truck, is too far from the starting point of a trip there is no arc between them.
Let E4 ¼ fðs; jÞjctðs; jÞ ¼ 1; j 2 A3 g be the set of arcs representing deadheading trips from the
depot to a collection trip. The recovery schedule network is deﬁned as G 5 hV, Zi with nodes
V 5 N [ {s, t} and arcs Z 5 E1 [ E2 [ E3 [ E4 [ E5 [ E6, where E5 5 R  t and E6 5 PD  t.

4.3. Problem formulation
Given a vehicle scheduling network G 5 hV, Zi, the truck schedule recovery problem may be
formulated as a mathematical program with the following decision variables:
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

572


yij ¼

1 if a vehicle is assigned to trip j directly after trip i;
0 otherwise;

8ði; jÞ 2 Z

sti 5 the real starting time of trip i, 8i 2 A1 [ A2 [ A3 .
The mathematical programming formulation is deﬁned as follows:
X
X
min
Cij yij þ
Pi ðsti  Bi Þ;
i2A3

ði;jÞ2Z

subject to
X

yij ¼ 1;

8i 2 A1 [ A2 [ A3 [ PD;

ð1Þ

ð2Þ

j:ði; jÞ2Z

X

yij ¼ 1

8j 2 A3 ;

ð3Þ

i:ði; jÞ2Z

X

X

yij ¼

i:ði; jÞ2Z

sti ¼ Bi ;

8i 2 A1 [ A2 ;

stj ¼ sti þ Wi þ Tij ;
sti *Bi ;

8j 2 R;

yjk ;

ð4Þ

k:ðj;kÞ2Z

ð5Þ

8i 2 A1 [ A2 [ A3 ; j 2 RðiÞ;

8i 2 A3 ;

sti )Bi þ Di ;

ð7Þ

8i 2 A3 ;

stj *ðsti þ U þ Tij Þyij ;

ð6Þ
ð8Þ

8i 2 R; j 2 A3 ; ði; jÞ 2 Z;

ð9Þ

where Cij 5 cTij is deﬁned as the distance traveled cost of arc (i, j)AZ, c the average operational
cost of a truck per time unit and Pi the penalty corresponding to a delay of one unit time in trip i.
The value of Pi is diﬀerent for each diﬀerent trip i. Smaller penalties are imposed on the cut trip,
while greater penalties are imposed on other trips. The latter are supposed to suﬀer delays only
if necessary in order to obtain a solution. This strategy is motivated by the concerns of crew
members.
The objective function (1) minimizes the combination of operating and penalty costs.
Constraints (2) and (3) guarantee that only one truck serves any collection trip. Constraint (2) also
guarantees that a truck goes to a recycling facility after ﬁnishing a collection trip and only one
truck is from pseudo-depot. Constraint (4) guarantees ﬂow conservation for the trucks arriving at
each RFA trip. The number of deadheading trips arriving at each RFA must be equal to the
number of deadheading trips leaving from that RFA. Constraints (2), (3) and (4) considered
simultaneously guarantee that all schedules for the trucks ﬁnish at the depot.
Constraint (5) sets the starting time of collection trips in A1 and A2 as the prescribed starting
time. Collection trips in A1 and deadheading trips in A2 cannot be rescheduled. Constraint (6) sets
the starting time of each RFA trip as the ending time of the corresponding collection trip plus the
travel time from the ending point of its collection trip to the recycling facility.
Constraints (7) and (8) guarantee that the starting time of any collection trip iAA3 is not earlier
than its prescribed starting time and does not exceed its delay limit, Di. Constraint (9) establishes
that the starting time of each future collection trip is dependent on the required deadheading
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

573

travelling and unloading times of its previous RFA trip. If a future collection trip is served by the
truck from the depot, its starting time is equal to the prescribed time.
Because this formulation includes the nonlinear terms (sti1U1Tij )yij, the big M technique is
used to linearize them. Let mij 5 (sti1U1Tij )yij replace the nonlinear term; mij can be deﬁned as
follows:
0)mij )ðsti þ U þ Tij Þ;
mij )Myij ;

8i 2 R; j 2 A3 ; ði; jÞ 2 Z;

8i 2 R; j 2 A3 ; ði; jÞ 2 Z;

mij *ðsti þ U þ Tij Þ þ Mðyij  1Þ;
stj *mij ;

8i 2 R; j 2 A3 ; ði; jÞ 2; Z

8i 2 R; j 2 A3 ; ði; jÞ 2 Z;

ð10Þ
ð11Þ
ð12Þ
ð13Þ

where M is a big number.
As a result, the linear program formulation of the truck rescheduling problem has the objective
function presented in (1), subject to constraints (1)–(8) and (10)–(13).

5. Computational experiments and analysis
We evaluated our approach using real-world data from DMLU, including statistical data about
trip disruptions. In Section 5.1, we present the analyzed scenarios and the main assumptions,
while the results are discussed in Section 5.2. All tests reported in this section were executed using
CPLEX 7.0 on a 900 MHz Sun Workstation.

5.1. Experiment conﬁguration
The main purpose of our computational experiments is to investigate the operational planning of
the solid waste collection in Porto Alegre for each working day during a week, assuming that
disruptions occur. The analysis was conducted from Monday to Thursday. Because the number of
collection trips on Friday and Saturday is 13, which is smaller than the number of total available
trucks (24), the schedules for these two days do not demand a careful analysis. Table 1 presents
the number of trips and the number of original trucks, which is obtained using the auction
algorithm developed by Freling et al. (1995) for the VSP.
The experiments were performed for diﬀerent scenarios taking into account diﬀerent
breakdown times and cut trips as follows:
1.
2.
3.
4.
5.

Scenario
Scenario
Scenario
Scenario
Scenario

I: The truck serving trip 2 breaks down at 08:31 hours
II: The truck serving trip 2 breaks down at 08:55 hours
III: The truck serving trip 8 breaks down at 09:31 hours
IV: The truck serving trip 8 breaks down at 09:55 hours
V: The truck serving trip 1 breaks down at 10:31 hours

It should be noted that in order to simplify the analysis, we consider the distance traveled by each
collection truck as the only operational cost involved. All remaining cost items are deﬁned as ﬁxed
costs. This is coherent with the public service characteristic of DMLU, in which the costs related
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

574

Table 1
Number of trips and original trucks
Day

# of trips

# of trucks

Monday
Tuesday
Wednesday
Thursday

29
26
23
31

17
16
15
17

with personnel and infrastructure do not depend on the productivity of the system. For each arc
from the depot, we add this value into the arc cost to represent the truck ﬁxed cost.
It is worth noting that, in our experiments, we do not know the exact location of the trucks
when a disruption occurs. In real life this information will be provided by a crew member or a
GPS signal. We use approximate values, which are based on DMLU routes and information,
given by the geographical information system designed by Porto Alegre municipality.
Scenarios were evaluated using the following measures: (i) delayed trips (DT); (ii) total delay time of
the cut trip in minutes (Delay 1); (iii) total delay time of all trips in minutes, except the cut trip (Delay
2); (iv) total distances traveled in km starting from truck breakdown, excluding waste collection trips
(Dist); (v) number of trucks (excluding the disabled one) required to ﬁnish the remaining collection
trips (Trucks); (vi) backup trip (Backup); (vii) sampling variance of collection trips assigned to
recycling facilities (SV); and (viii) CPU seconds required to solve the problem (CPU).

5.2. Results and analysis
Before executing a complete operational plan, we decided to use the schedule for Tuesday as an
example to perform a detailed analysis. This analysis helped us to deﬁne general recovery
strategies and to compare the results with the rescheduling strategy currently adopted by DMLU
(e.g., to send a backup truck from the depot to the disrupted trip). Table 2 gives original schedule
and new schedules, while Table 3 presents the assignment of collection trips to each recycling
facility, for all disruption scenarios. In all tables, T denotes a collecting trip, Vi denotes a truck
i and Rj denotes a recycling facility j.
Although all new reschedules presented in Table 2 are solutions with the minimum cost, they
cannot be employed because several recycling facilities are not used. These new schedules are not
balanced in terms of the use of recycling facilities (see Table 3). Recycling facilities R1, R3 and R8
are barely used in the new schedules, while R2, R4 and R6 together receive more than 70% of the
collection trips. The solutions provided by the MILP are unacceptable by DMLU managers
taking into consideration the social beneﬁts of the solid waste program.
In order to obtain a more suitable solution, which considers the social and ﬁnancial aspects
involved, we decided to restrict the number of trips assigned to each recycling facility. The
following constraint is included in our MILP formulation:
X X
yij )Gk ; 8k 2 f1; 2; . . . ; Kg;
ð14Þ
j2Rk i:ði; jÞ2Z

r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

CPU
Dist

V1
V2
V3
V4
V5
V6
V7
V8
V9
V10
V11
V12
V13
V14
V15
V16
DT

T2–R8–T10–R3
T3–R7–T15–R7
T4–R2–T6–R4
T5–R2
T7–R5–T12–R4
T8–R1–T16–R8
T9–R3
T11–R8–T23–R6
T14–R5–T13–R5
T17–R1
T18–R7–T27–R8
T19–R6
T21–R4–T22–R8
T24–R3–T1–R3
T25–R3–T20–R4
T26–R4

1.19
215.25

T15–R2
T3–R6–T10–R4
T4–R2–T6–R2
T5–R2
T7–R4–T26–R4
T8–R7–T12–R2
T9–R4
T11–R7–T27–R2
T14–R5–T13–R2
T17–R6
T18–R6–T23–R2
T19–R4
T21–R7–T22–R2
T24–R6–T1–R4
T25–R7–T20–R4
T2–R6–T16–R6
T2 (17.4 min)

I
T15–R2
T3–R6–T19–R4
T4–R74–T9–R4
T5–R2
T7–R4–T26–R4
T8–R7–T27–R2
T10–R4
T11–R7–T6–R2
T14–R5–T13–R2
T17–R6
T18–R6–T16–R6
T22–R7–T12–R2
T21–R7–T2–R6–T23–R2
T24–R6–T1–R4
T25–R7–T20–R4
T15–R2
T2 (19.7 min)
T8 (2.5 min)
T12 (1.4 min)
1.19
213.65

II

Truck Original schedule New schedule for scenario

Table 2
New schedules for Tuesday

0.19
213.00

T2–R6–T23–R2
T3–R6–T10–R4
T4–R2–T6–R2
T5–R2
T7–R4–T26–R4
T8–R7–T12–R2
T9–R4
T11–R7–T27–R2
T14–R5–T13–R2
T17–R6
T18–R6–T16–R6
T19–R4
T21–R4–T22–R2
T24–R6–T1–R6
T25–R7–T20–R4
T9–R4
T8 (7.5 min)

III

0.32
197.70

T2–R6–T23–R2
T3–R7–T8–R7–T12–R2
T4–R2–T6–R2
T5–R2
T7–R4–T26–R4
T10–R4
T15–R2
T11–R7–T27–R2
T14–R5–T13–R2
T17–R6
T18–R6–T16–R6
T19–R4
T21–R4–T22–R2
T24–R3–T1–R4
T25–R1–T20–R4
T26–R4
T8 (7.6 min)

IV

0.74
188.60

T1 (6.4 min)

T2–R8–T10–R4
T3–R7–T15–R2
T4–R4–T20–R4
T5–R2
T7–R4–T9–R4
T8–R1–T1–R4
T6–R2
T11–R7–T27–R2
T14–R5–T13–R2
T17–R6
T18–R6–T16–R6
T19–R4
T21–R4–T22–R7–T23–R2
T24–R3
T25–R7–T12–R2

V

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582
575

r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

576

Table 3
Trip assignments for Tuesday’s schedule
Scenario

R1

R2

R3

R4

R5

R6

R7

R8

I
II
III
IV
V

0
0
0
0
1

9
7
9
9
7

0
0
0
1
1

7
8
8
8
9

1
1
1
1
1

6
6
6
4
3

4
5
3
4
4

0
0
0
0
1

where Gk is a limit on the number of trucks unloading their cargos at recycling facility k, and Rk is
the set of RFA trips representing the recycling facility k. This set of constraints avoids some
recycling facilities being allocated excessive collection trips, and other recycling facilities being
idle. The main idea is to deﬁne balanced schedules, considering the social aspects of the program,
as stated in Section 3. The MILP formulation for the truck rescheduling problem, considering
balanced truck unloads among the recycling facilities, has the objective function presented in (1),
subject to constraints (1)–(8) and (10)–(14).
Tables 4 and 5 present the solutions limiting the number of trucks unloading at each recycling
facility. Although each recycling facility is not assigned the same number of trips, there is a
signiﬁcant improvement in the results. All recycling facilities are now used (see Table 5).
Delay times were not inﬂuenced by the inclusion of constraint (14). However, these balanced
schedules demand higher distances traveled by the trucks, increasing the total collection costs for
DMLU by 28.85% on average. This increase is easily justiﬁed. Without constraint (14), the MILP
model selects the closest recycling facility for a truck to unload its cargo. With constraint (14), the
closest recycling facility might not be available, because its limit can be exceeded. The truck will
need to travel further to unload its cargo. Balanced schedules require also larger CPU time in
seconds to be solved: an increase of 220% on average. Although both the number of experiments
and size of problems are small, DMLU managers agree that the absolute diﬀerence is quite
acceptable in practice, because all solutions present compatible computational times with the
complexity of the problem. As a result, DMLU managers are willing to use balanced schedules,
despite the increase in costs and the required CPU time, because the main objective of the solid
waste collection is related to social and environmental goals.
We decided to compare the possible operational strategies for all ﬁve scenarios, considering
all working days in the analysis. Tables 6–9 present a comparison among the results obtained
using the current DMLU recovery strategy, and the results obtained using our optimization
approach, considering (14) for each recycling facility. DMLU strategy is to send a backup truck
from the depot based on the original schedule. DMLU strategy always keeps the original schedule
in spite of any delay. In this strategy, all trips (if any) assigned for the same truck serving the cut
trip are also delayed for the same recovery time plus the loading time (if any) of the cut trip. A
loading time of 5 min, based on DMLU data, was considered. The last two columns of the tables
present the percentage savings in the total distances traveled (SD), and total delay times (ST )
respectively, resulting from the utilization of the optimization algorithm. These measures are
deﬁned as
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

CPU
Dist

V1
V2
V3
V4
V5
V6
V7
V8
V9
V10
V11
V12
V13
V14
V15
V16
DT

T2–R8–T10–R3
T3–R7–T15–R7
T4–R2–T6–R4
T5–R2
T7–R5–T12–R4
T8–R1–T16–R8
T9–R3
T11–R8–T23–R6
T14–R5–T13–R5
T17–R1
T18–R7–T27–R8
T19–R6
T21–R4–T22–R8
T24–R3–T1–R3
T25–R3–T20–R4
T26–R4

1.68
294.00

T15–R2
T3–R6–T10–R3
T4–R7–T20–R4
T5–R2
T7–R4–T26–R4
T8–R7–T12–R4
T9–R3
T11–R7–T6–R2
T14–R5–T13–R5
T17–R6
T18–R6–T23–R8
T19–R3
T21–R8–T22–R8
T24–R6–T1–R3
T25–R1–T16–R1
T2–R1–T27–R7
T2 (17.4 min)

I
T15–R2
T3–R6–T10–R3
T4–R7–T12–R4
T5–R2
T7–R4–T26–R4
T8–R7–T6–R2
T9–R3
T11–R7–T20–R4
T14–R5–T13–R5
T17–R6
T18–R6–T23–R8
T19–R3
T21–R7–T2–R1–T27–R8
T24–R6–T1–R3
T25–R1–T16–R1
T22–R8
T2 (19.7 min)
T8 (2.5 min)
6.61
273.10

II

Truck Original schedule New schedule for scenario

Table 4
New schedules for Tuesday considering constraint (14)

1.25
263.50

T2–R1–T27–R8
T3–R6–T10–R3
T4–R7–T6–R2
T5–R2
T7–R4–T26–R4
T8–R7–T12–R7
T9–R3
T11–R7–T20–R4
T14–R5–T13–R5
T17–R6
T18–R6–T23–R8
T19–R3
T21–R4–T22–R8
T24–R6–T1–R3
T25–R1–T16–R1
T15–R2
T8 (7.5 min)

III

1.25
248.30

T2–R1–T27–R1
T3–R7–T8–R7–T12–R2
T4–R7–T6–R2
T5–R2
T7–R4–T26–R4
T10–R3
T15–R2
T11–R6–T23–R8
T14–R5–T13–R5
T17–R6
T18–R6–T9–R3
T19–R3
T21–R4–T22–R8
T24–R3–T1–R6
T25–R1–T16–R1
T20–R4
T8 (7.6 min)

IV

0.84
225.35

T2–R8–T10–R3
T3–R7–T15–R2
T4–R7–T27–R8
T5–R2
T7–R4–T20–R4
T8–R1–T1–R6
T6–R2
T11–R7–T12–R7
T14–R5–T13–R5
T17–R1
T18–R6–T9–R3
T19–R3
T21–R4–T22–R1–T16–R6
T24–R3
T25–R6–T23–R8
T26–R4
T1 (6.4 min)

V

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582
577

r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

578

Table 5
Trip assignments for Tuesday schedule considering constraint (14)
Situation

R1

R2

R3

R4

R5

R6

R7

R8

I
II
III
IV
V

3
3
3
4
3

3
3
3
4
3

4
4
4
4
4

4
4
4
4
4

2
2
2
2
2

4
4
4
4
4

4
4
4
3
4

3
3
3
2
3

Table 6
Comparison between DMLU strategy and optimization method for Tuesday
Scenario

Methods

Delay 1

Delay 2

Trucks

Distance

Backup

SV

I

Manual
CC
Manual
CC
Manual
CC
Manual
CC
Manual
CC

17.4
17.4
20.7
19.7
7.5
7.5
15.8
7.6
13.5
6.4

22.4
0
25.7
2.5
12.5
0
20.8
0
0
0

16
16
16
16
16
16
16
16
16
15

336.20
294.00
337.75
273.10
317.60
263.50
301.63
248.30
264.95
225.35

Depot
Depot
Depot
T21
Depot
Depot
Depot
T3
Depot
T8

1.98
0.55
1.98
0.55
1.98
0.55
1.98
0.84
1.98
0.55

II
III
IV
V

SD ¼100 

DM  DO
ð%Þ
DM

TM  TO
ST ¼100 
ð%Þ
TM

SD (%)

ST (%)

CPU

12.55

56.28

1.68

19.14

52.16

6.61

17.03

62.50

1.25

17.68

79.23

1.25

14.94

52.59

0.84

;

where DM (DO) and TM (TO) are the total distances traveled in km and the total delay times
respectively, assuming DMLU strategy (optimization algorithm).
Sending a backup truck from the depot to the cut trip occurs in 35% of the 20 analyzed
situations, while in 65% of the cases, a truck already being in the network is selected as the
backup. Even in the situations in which the backup trip is from the depot, our approach deﬁnes
the new schedules for almost all unﬁnished trips. Considering the results for Tuesday (see Table
4), we noticed that the sequences of future collection trips and recycling facilities are completely
changed in the new schedules. Only two trucks (V4 and V7) kept their original scheduling in all
scenarios. Because these long collection trips had already started when the disruptions occurred,
there was no use in changing their schedules. Our approach attempts to minimize the deadheading
distances and delays involved by reassigning future collection trips and recycling facilities to
trucks when the truck breaks down at an instant F. This fact justiﬁes the diﬀerences in the values
of the distances traveled and delay times in Tables 6–9, even if the backup trip is the same.
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

579

Table 7
Comparison between DMLU strategy and optimization method for Monday
Scenario

Methods

Delay 1

Delay 2

Trucks

Distance

Backup

SV

I

Manual
CC
Manual
CC
Manual
CC
Manual
CC
Manual
CC

24.0
24.0
36.0
28.2
12.0
12.0
18.0
7.6
15.0
15.0

29.0
0.5
41.0
0
17.0
0
23.0
0
20.0
0

17
17
17
17
17
17
17
17
17
17

422.00
348.40
428.00
396.40
396.40
340.20
380.30
339.60
340.80
305.60

Depot
Depot
Depot
T21
Depot
Depot
Depot
T3
Depot
T11

1.98
0.55
1.98
0.27
1.98
0.55
1.98
0.55
1.98
0.27

II
III
IV
V

SD (%)

ST (%)

CPU

17.44

53.77

15.00

7.38

63.38

8.65

14.33

58.62

3.69

10.70

81.46

3.10

10.33

57.14

6.76

SD (%)

ST (%)

CPU

17.98

55.12

5.10

19.85

63.60

8.95

21.99

75.51

6.81

15.12

75.51

1.84

7.90

21.54

0.09

SD (%)

ST (%)

CPU

22.51

57.53

3.54

20.25

57.31

5.68

22.09

65.24

1.57

17.10

36.70

1.49

9.22

65.78

0.35

Table 8
Comparison between DMLU strategy and optimization method for Wednesday
Scenario

Methods

Delay 1

Delay 2

Trucks

Distance

Backup

SV

I

Manual
CC
Manual
CC
Manual
CC
Manual
CC
Manual
CC

21.9
21.9
33.9
26.5
2.4
2.4
2.4
2.4
24.6
18.8

26.9
0
38.9
0
7.4
0
7.4
0
0
0.5

15
15
15
15
15
15
15
15
15
15

313.20
256.90
319.20
255.85
307.20
239.65
291.30
247.25
235.95
217.30

Depot
Depot
Depot
T21
Depot
Depot
Depot
Depot
Depot
T4

0.70
0.41
0.70
0.41
0.70
0.13
0.70
0.41
0.70
0.70

II
III
IV
V

Table 9
Comparison between DMLU strategy and optimization method for Thursday
Scenario

Methods

Delay 1

Delay 2

Trucks

Distance

Backup

SV

I

Manual
CC
Manual
CC
Manual
CC
Manual
CC
Manual
CC

14.1
14.1
19.05
18.4
5.7
5.7
12.35
10.0
22.50
7.7

19.1
0
24.05
0
10.7
0
17.35
8.8
0
0

17
17
17
17
17
17
17
17
17
17

397.75
308.20
394.90
314.95
377.35
294.00
338.50
280.63
274.95
249.60

Depot
Depot
Depot
T21
Depot
Depot
Depot
T14
Depot
T8

1.55
0.13
1.55
0.13
1.55
0.70
1.55
0.13
1.55
0.13

II
III
IV
V

r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

580

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

The optimization method has outperformed DMLU strategies in terms of the total distances
traveled (an average improvement of 17.79%). As the number of collection trips increases, the
savings increase. The algorithm has the best saving averages for the Thursday schedule, with 31
trips. The same behavior is observed in terms of balanced scheduling. Our approach has a much
smaller sample variation in terms of the number of trucks unloading in each recycling facility. Our
approach presents an average SV of 0.43, while the DMLU strategy has an average of 1.55.
However, the most signiﬁcant result of our optimization approach concerns the delay time.
Considering all possible delays in trips, including the cut trip, the optimization approach decreases
the total delay by 59.55% on average. This reduction is very important for DMLU, because high
delays have a direct impact on its level of service. When a trip has a large delay, DMLU receives
several phone calls from residents and from recycling facility managers, complaining about the
situation. This is a crucial aspect because the quality of the program is highly dependent on the
collaboration of residents. Without their cooperation, such as separating the solid waste in their
homes, the program fails completely, no matter how eﬃcient the collection is.
There are no savings in terms of the number of trucks required to perform the collection trip
after the disruption, except for scenario V on Tuesday. Again, this is a very good result for our
optimization approach, because DMLU strategy has as its main objective the minimization of the
number of extra trucks required. Our approach obtains the same result with smaller distances
traveled, with more balanced schedules and smaller delays. For several cases, distances traveled at
a later breakdown time are larger than distances at an earlier breakdown time, considering
constraint (14). With the inclusion of constraint (14) in the mathematical formulation, some
routes cannot be considered because the recycling facilities involved in the route may be saturated.
In terms of computation times, our optimization method requires 0.35 to 15 CPU seconds to
solve all instances, depending on the size of the problem being solved. These times can be
considered acceptable, and the human schedulers were very satisﬁed with the computational times
of our optimization approach, considering the quality of the solutions obtained and the
complexity of the problems.
Overall, DMLU managers responded positively to the optimization approach. Analysis and
evaluation of possible recovery operational strategy, through our optimization approach, provide
a means to study each alternative with respect to several measures and make more objective
decisions, avoiding the use of simple strategies. However, given the complexity of the problem,
there is a gap between the existence of a solution algorithm and its application to real world cases.
As a result, a decision support system is being implemented in DMLU to cope with both the truck
scheduling and the truck recovery problems. The development of a computer-based tool, which is
capable of providing a user-friendly environment and emphasizing ﬂexibility, eﬃciency and
adaptability, becomes an important aspect in terms of the eﬀective use of real-time vehicle
scheduling strategy.

6. Conclusion
In this paper we have presented a mixed-integer linear programming model for the truck
scheduling recovery problem. The main objective of the model is to minimize both the distance
traveled and delay costs, resulting from a serious disruption in one of the trips pre-assigned to a
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

581

truck in the system. The model was applied to a solid waste collection problem in Porto Alegre,
Brazil, where the municipality is responsible for the collection, whereas the recycling is conducted
by cooperatives. The main objective of the case study was to develop an operational plan for this
kind of collection in case of a truck breakdown. Several scenarios were analyzed, assuming
diﬀerent breakdown trucks and times, for the main collection days of the week. If we compare the
results obtained by our optimization approach with the currently applied recovery strategy, our
model performs very well, decreasing both the distance traveled and trip delays. Furthermore, our
approach oﬀers more balanced reschedules in terms of the number of trucks unloading at each
recycling facility, guaranteeing the employment of several workers in the recycling facility.
The formulation can be applied to other contexts (bus companies and logistic systems). Because
examples of the problems discussed herein can be very complex, involving thousands of trips and
hundreds of vehicles, we want to develop a heuristic method to solve our formulation in a
reasonable amount of time. This is necessary if our optimization approach is to be used in more
generic real-world VRSPs.

Acknowledgments
The second author acknowledges the support from CAPES and CNPq, Brazil. The remaining
authors acknowledge the support received for this research from USDOT/FHWA and Arizona
DOT through their sponsorship of the ATLAS Programs. Also, the authors would like to express
their sincere thanks to the anonymous referees for their valuable suggestions.

References
Bhat, V.N., 1996. A model for the optimal allocation of trucks for solid waste management. Waste Management and
Research 14, 87–96.
Bodin, L., Fagin, G., Welegby, R., Greenberg, J., 1989. The design of a computerized sanitation vehicle routing and
scheduling systems for the town of Oyster Bay, New York. Computers and Operations Research 16, 1, 42–54.
Carlson, P.M., 2000. Exploiting the opportunities of collaborative decision making: A model and eﬃcient solution
algorithm for airline use. Transportation Science 34, 381–393.
Eisenstein, D.D., Iyer, A.V., 1997. Garbage collection in Chicago: A dynamic scheduling model. Management Science
43, 7, 922–933.
Freling, R., Paixão, J., Wagelmans, A.P., 1995. Models and algorithms for vehicle scheduling. Econometric Institute
Report 31, Erasmus University Rotterdam, Econometric Institute.
Freling, R., Wagelmans, A., Paixão, J.M., 2001. Models and algorithms for single-depot vehicle scheduling.
Transportation Science 35, 165–180.
Gendreau, M., Potvin, J.-Y., 1998. Dynamic vehicle routing and dispatching. In Crainic, T., Laporte, G. (eds) Fleet
Management and Logistics. Kluwer, New York, 115–126.
Ghiani, G., Guerriero, F., Laporte, G., Musmanno, R., 2003. Real-time vehicle routing: Solution concepts, algorithms
and parallel computing strategies. European Journal of Operational Research 151, 1, 1–11.
Huisman, D., Freling, R., Wagelmans, A., 2004. A robust solution approach to the dynamic vehicle scheduling
problem. Transportation Science 38, 447–458.
Ichoua, S., Gendreau, M., Potvin, J.-Y., 2000. Diversion issues in real-time vehicle dispatching. Transportation Science
34, 426–438.
r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

582

J.-Q. Li et al. / Intl. Trans. in Op. Res. 15 (2008) 565–582

Laporte, G., Louveaux, F.V., 1998. Solving stochastic routing problems with integer l-shaped method. In Crainic, T.,
Laporte, G. (eds) Fleet Management and Logistics. Kluwer, New York, 159–167.
Lettovský, L., 1997. Airline operations recovery: an optimization approach. Ph.D. thesis, Georgia Institute of
Technology, USA.
Li, J., Mirchandani, P.B., Borenstein, D., 2004. Parallel auction algorithm for bus rescheduling. Proceedings of the 9th
International Conference on Computer-Aided Scheduling of Public Transport, San Diego, CA, USA.
Li, J.-Q., Borenstein, D., Mirchandani, P.B., 2007. A decision support system for the single-depot vehicle rescheduling
problem. Computers and Operations Research 34, 1008–1032.
Morrissey, A.J., Browne, J., 2004. Waste management models and their application to sustainable waste management.
Waste Management 24, 3, 297–308.
Powell, W.B., Jaillet, P., Odoni, A., 1995. Stochastic and dynamic networks and routing. In Ball, M.O., Magnanti,
T.L., Monma, C.L., Nemhauser, G.L. (eds) Handbooks in Operations Research and Management Science, Network
Routing. North-Holland, Amsterdam, the Netherlands, 141–295.
Psaraftis, H.N., 1995. Dynamic vehicle routing: Status and prospects. Annals of Operations Research 61, 143–164.
Rosenberger, J.M., Johnson, E.L., Nemhauser, G.L., 2003. Rerouting aircraft for airline recovery. Transportation
Science 37, 408–421.
Teodorović, D., Stojković, G., 1995. Model to reduce airline schedule disturbances. Journal of Transportation
Engineering-ASCE 121, 324–331.
Yang, J., Jaillet, P., Mahmassani, H.S., 2004. Real-time multivehicle truckload pickup and delivery problems.
Transportation Science 38, 135–148.

r 2008 The Authors.
Journal compilation r 2008 International Federation of Operational Research Societies

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 4, NO. 2, JUNE 2003

99

Methods of Analyzing Traffic Imagery Collected
From Aerial Platforms
Alejandro Angel, Mark Hickman, Pitu Mirchandani, Senior Member, IEEE, and Dinesh Chandnani

Abstract—A limitation of most traditional methods of traffic
data collection is that they rely on techniques that are strictly local
in nature. Aerial imagery sensors can provide sufficient resolution
to sense vehicle locations and movements across broader spatial
and temporal scales. Digital imagery, global positioning systems,
and automated image processing can be used to improve the spatial coverage, accuracy and cost-effectiveness of the data collection
and reduction. In this paper, an approach for collecting and analyzing aerial imagery is given. To illustrate the value of the imagery,
the paper outlines methods to generate estimates of speeds, travel
times, densities, and queueing delays.
Index Terms—Aerial video, image processing, remote sensing,
traffic monitoring.

I. INTRODUCTION

R

ESEARCH in the use of aerial imagery for transportation
has been conducted for over 75 years. In 1927, aerial
photography was used to estimate traffic densities on a highway
between Baltimore and Washington [1]. In 1947, Greenshields
published a paper that dealt with the potential use of aerial
photographs in traffic analysis [2]. Other researchers continued
to work with aerial photography during the 1950s, 1960s,
and early 1970s for traffic operations analysis. Although the
data was found to be very useful, this research slowed in the
mid-to-late 1970s because of the cost of data collection and the
large time and money required to manually reduce the data.
Although some of the limitations faced by researchers three
decades ago still exist, the technology available today and the
understanding gained on remote sensing allow researchers to
overcome many of them.
One of the aspects where technology has helped is on
minimizing the amount of manual work. During the past two
decades a substantial amount of work has been done to automate image processing for traffic management applications;
see, for example [3]–[6]. For the most part, these research
efforts have focused on observing traffic with cameras at fixed
locations, and commercial products are widely available for this
purpose. One obvious drawback of fixed platforms, however, is

that these camera platforms are not mobile, and hence cannot
easily observe the spatial progression and movement of traffic
beyond the field of view.
Mobile platforms may be more easily deployed in a variety
of geographic areas. There has been growing research activity in
the area of aerial surveillance and object tracking; examples include the excellent summary in [7] and several systems with dynamic object tracking, described in [8], [9]–[10], among many
others. Some of these systems are similar to the work described
in this paper. However, within the application domain considered in this paper, there are some additional considerations, including: 1) the platform must be low-cost, meaning that data
quality and accuracy may not match those of other applications;
2) there are limitations on the processing power available; and
3) one can exploit the application domain to consider the specific data requirements for civilian traffic flow monitoring.
As part of an ongoing project, researchers at the University
of Arizona have been studying transportation applications of
imagery collected from airborne platforms. The objective of
the project is to identify the data needs and technical requirements of remote sensing for various traffic planning and management applications. The considerations listed above allow us
to tailor the image processing needs to the required traffic data
needs more directly. Our interest has been to develop a civilian,
low-cost traffic monitoring system that can automatically track
vehicles and derive traffic parameters of interest from a moving
surveillance platform under heavy traffic conditions.
This paper describes the methods used to collect and reduce aerial imagery. It also introduces specific methods for
estimating speeds, travel times, densities, and queueing delays
from this imagery. For each of these traffic parameters, the
types of data required from the imagery are described, and the
specific image processing techniques to obtain that data are
outlined.
II. IMAGE PROCESSING
A. Data Collection

Manuscript received February 13, 2003; revised September 23, 2003. This
work was supported in part by the National Consortium on Remote Sensing in
Transportation—U.S. Department of Transportation. The Guest Editors for this
paper were R. L. Cheu, D. Srinivasan, and D.-H. Lee.
A. Angel and M. Hickman are with the Department of Civil Engineering and
Engineering Mechanics, University of Arizona, Tucson, AZ 85721-0072 USA
(e-mail: aangel@engr.arizona.edu; mhickman@engr.arizona.edu).
P. Mirchandani is with the University of Arizona, ATLAS Center, Tucson,
AZ 85721-0020 USA (e-mail: pitu@sie.arizona.edu).
D. Chandnani was with the University of Arizona, ATLAS Center, Tucson,
AZ 85721-0020 USA. He is now with Microsoft Corporation, Redmond, WA
98052 USA.
Digital Object Identifier 10.1109/TITS.2003.821208

The experiments to date have used digital imagery, taken from
an airborne platform, to observe traffic behavior. In these experiments, a consumer-grade digital video camera and a digital still camera were mounted vertically on a skid of a helicopter, to minimize any distortion due to the angular perspective of the imagery (Fig. 1). At the same time, the altitude and
position of the helicopter were recorded using a Global Positioning System (GPS) receiver. To register the video frames to
known geographic locations, ground control points were used
in an initial experiment (May 2001). A subsequent experiment

1524-9050/03$17.00 © 2003 IEEE

100

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 4, NO. 2, JUNE 2003

Fig. 1. Data collection setup.

(May 2002) used an inertial measurement unit (IMU) to collect
data on the roll, pitch and yaw of the helicopter. High-precision
GPS and IMU data are then used to automatically register the
imagery, providing an accurate means of geo-referencing.
The video camera provides excellent temporal coverage, capturing RGB imagery in a 720 480 pixel sensor at a rate of
30 frames/s. However, previous experiments [6] suggest that
the imagery can be sampled at rates of 1 frame/s or less with
minimal loss of traffic information. On the other hand, the still
1704 pixels)
camera has a higher resolution sensor (2272
but the maximum capture rate is approximately 0.15 frames/s.
Therefore, as will be discussed later, the selection of a camera
type depends on the application being pursued.
Given the focal length of the cameras, flying at an altitude
of 300 m (1000 ft) above ground produced a field of view of
approximately 253 m (830 ft) on the video camera and 314 m
(1030 ft) on the still camera. This field of view allows a considerable number of vehicles to be included in the image, such
as a large “platoon” of vehicles or the complete queues on all
approaches to an intersection. In our imagery to date, the scale
of the frames is typically between 3 and 4 pixels/m.
B. Image Registration and Vehicle Recognition
The analysis of video can be greatly enhanced through automated image processing. Many researchers have studied this
problem, primarily from fixed camera locations. In contrast, the
use of a mobile camera platform adds additional complications
to the image processing task, as the motion of both the vehicles
and the camera platform must be considered. In addition, the
objective of this research has been to develop an algorithm that
can run close to “real time”: in this case, the image processing
must be completed in 2–3 s.
The algorithm presented below for vehicle detection and
tracking is still being developed and tested. It uses many
well-established image processing techniques for fixed cameras. However, the main contribution of our technique is to
compensate for the motion of the camera platform. To do this,
the idea is to detect individual vehicles in a frame, to register
consecutive frames, and then to employ image transformation,
image subtraction, and object matching to track individual

Fig. 2. Image processing flowchart.

Fig. 3. Ellipse weight-assignment method.

vehicles. The process we are using to do this is illustrated in
Fig. 2 and described below. The common elements of the image
processing technique are included for completeness.
1) Two frames 1 or 2 s apart are extracted from the video;
2) To accelerate vehicle identification, the frames are preprocessed. Preprocessing operations include converting
the frames to 8-bit grayscale and identifying the areas
of the frame that contain the road. A geo-referenced
roadway mask is used to define the roadway edges and
centerline. An example of the result of preprocessing is
illustrated in Figs. 4 and 5 later in the paper;
3) Within the roadway boundary (mask), the frames are
parsed to search for concentration of pixels that contrast
with a predefined pavement pixel value. This identifies
both moving and stationary objects. Vehicle identification is also shown in Figs. 4 and 5 later in the paper;
4) The coordinates of the center of each image are found
from the GPS and IMU data. The precise scale of each
frame is calculated from the camera’s focal length and
the elevation of the helicopter with respect to the road;
5) The second frame is registered to the first one using the
location, orientation and scale information from Step 4;

ANGEL et al.: METHODS OF ANALYZING TRAFFIC IMAGERY

101

(a)

(b)

Fig. 4. Frame 1 (a) before and (b) after vehicle identification.

(a)

(b)

Fig. 5. Frame 2 (a) before and (b) after vehicle identification.

6) The two frames are overlapped and subtracted. The
overlap between the two frames is usually, by intention, between 65% and 85%, depending on the frame
sampling interval, the image scale and the speed of the
helicopter;
7) After subtraction, only moving objects (vehicles) should
have pixel values different from zero in the overlapping
portion of the two frames. However, in many cases stationary objects may be seen as moving objects (pixel
values different from zero) because of limitations in georeferencing accuracy. This is solved by setting a minimum
speed threshold for moving objects (e.g. only objects with
a displacement of more than 20 pixels). Moving vehicles
and their positions are thus identified;
8) Matching the cars in the two frames can be done using
several different algorithms. One of the algorithms used in
this research is described in the speed estimation section
below;
9) After matching the vehicles, vehicle trajectories can then
be derived from the time and position information in order
to obtain traffic parameters such speed, density, spacing,
etc. This procedure is then repeated for all the frames.

III. TRAFFIC APPLICATIONS
In this section, several traffic applications using aerial video
are described. These are meant to be illustrative of the methodology and potential of the technology.
A. Speeds
Accurately matching vehicles between two frames is perhaps
the most important step in the speed estimation process. A minimum cost algorithm that uses a bipartite network for matching
is used in this case. This algorithm is applied separately to each
direction of travel, using the roadway centerline in the road
mask (see Step 2 above). Once this is done, the algorithm involves the following operations:
1) for each vehicle detected in the frame 1, assume the speed
at which the vehicle will travel and predict its location in
the frame 2;
2) build a bipartite graph with arcs from the predicted position of the vehicle to all the detected vehicles in frame 2;
3) assign weights to the arcs created in Step 2 assuming that
cars are more likely to accelerate or decelerate than to
change lanes. With this assumption, several equal-likelihood ellipses, with the major axis in the direction of

102

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 4, NO. 2, JUNE 2003

Fig. 6. Images after registration and subtraction.

motion of the vehicle, can be drawn around the vehicle’s
predicted location. Fig. 3 illustrates how, using the ellipse
method, the original vehicle is more likely to be matched
with vehicle in frame 2 than with vehicle although vehicle is closer to the vehicle’s predicted location;
4) repeat the same procedure for all the vehicles detected in
frame 1;
5) using the resulting network, solve the minimum cost
problem to match the detected vehicles.
The image registration and vehicle matching algorithms described previously were tested on imagery from a flight in May
2002. Figs. 4 and 5 show two frames 2 s apart after vehicle identification. Both frames (720 480 pixels in size) were converted
to grayscale to reduce processing time. The vehicle identification process produced “blobs” identified with bounding boxes
in Figs. 4 and 5. Note that not all vehicles were detected (particularly in frame 2) and that due to long shadows, the location
of the boxes was not always directly over the vehicle. The result of registering and subtracting the two images is presented in
Fig. 6. After solving the minimum cost problem, five vehicles
were matched. Four of those five matches were true matches.
Some vehicles could not be matched because they moved outside of the camera’s field of view or because they were not detected by the feature identification algorithm. After registering
the two frames and matching the vehicles, the distance traveled by each vehicle can be easily calculated by multiplying the
number of pixels traveled by the scale of the image in meters per
pixel (from the GPS data and the camera’s focal length). Vehicles speeds are then found by dividing the distance traveled by
the time between frames. In the case presented here, the speed
of the vehicles ranged from 77.6–84.8 km/h (48.2–52.7 mph).
In preliminary results, using a small sample of imagery,
the matching algorithm produced approximately 90% correct
matches for 720 480 pixel images 2 s apart. The algorithm
was also tested on higher resolution images 10 s apart (from the
still camera) and produced close to 80% correct matches. These
results were achieved using imagery from freeways, where

speeds are more consistent across vehicles than for arterial
roadways with signalized intersections. Because of the speed
variations, the performance of the algorithm is expected to
degrade in arterial roadways. In terms of CPU time, processing
a set of two 720
480 pixel images took 1.7 s using a 1.8
GHz Pentium 4 personal computer. Real-time processing of
high resolution images cannot be achieved without the use of a
roadway mask to reduce the number of pixels to be processed
(and therefore, the processing time). Additional experimentation with a wider set of helicopter imagery is important to
validating these results and is now being conducted by the
research team.
B. Travel Times
As part of the aerial video experiments, a method to estimate
travel times using a helicopter was developed. This technique
could be used on any highway as an alternative to traditional
test car techniques [12]. Such travel time estimates are useful
for estimating the level of congestion and delay on the arterial;
they are also useful in measuring the level of service on arterials
[13].
In this method, travel times for a platoon of vehicles, rather
than a single vehicle, are recorded. A platoon of vehicles at an
intersection that defines the beginning of the arterial segment
(e.g., a signalized intersection) is selected for the run and placed
in the video camera’s field of view. The helicopter then follows
the platoon through the entire section or corridor, stopping and
hovering when required to keep the platoon within the camera’s
field of view. To capture the travel time of vehicles absorbed by
the platoon being tracked and the travel time of vehicles left behind by the platoon, the helicopter must hover during one signal
cycle at the initial and final intersection before and after the run,
respectively.
An experiment to test this procedure was conducted during
a helicopter flight. For that purpose, the data from the helicopter was compared to ground measurements of travel time
from video cameras set up at the endpoints of the segment, and
from a test car. The site for the experiment was a 4.69-km seg-

ANGEL et al.: METHODS OF ANALYZING TRAFFIC IMAGERY

103

TABLE I
TRAVEL TIMES BY DIFFERENT TECHNIQUES

TABLE II
TRAVEL TIMES BY SEGMENT

Fig. 7. Vehicle trajectories derived from aerial video.

ment along Speedway Boulevard in Tucson, extending from Euclid Avenue to Alvernon Way. Speedway is a major arterial with
closely and unevenly spaced signals, pedestrian crossings, as
well as high traffic volumes. For this experiment, one complete
run in each direction was made. The travel time estimate obtained from the aerial video was compared with those of the
ground cameras and the test car. The results in Table I show that
the travel time from the aerial video was closer to the “true”
travel time (from the ground cameras) than the travel time of
the test car. The sample size for the ground video (five cars)
represents the number of cars from the same platoon that were
captured in the ground video.
Although the sample size was small, this remote sensing
technique eliminates the driver subjectivity involved in test
car studies, and increases the statistical validity of the travel
time estimate. Additionally, since this method tracks several
vehicles per run (9 in the case illustrated), information about
within-platoon travel time variation can be derived. The between-platoon travel time variation can also be captured using
this method by performing multiple runs.
Another useful feature of the proposed methodology is that
it allows link by link analyses, such as the one presented in
Table II. This cannot be accomplished with the ground cameras
without great expense. Using the travel times from the ground
video, the average speed was 36.9 km/h (Table I). This result
seems to indicate that the arterial was operating adequately.
However, the link by link analysis in Table II shows high speed
variability between links, ranging from 15.1–73.5 km/h. Aerial
video can help identify problematic links and can provide more
detailed travel time estimates (e.g. link by link) than license
plate matching and other ITS technologies that only determine
the total travel time over a given section.

Furthermore, since time-position profiles can be derived for
each vehicle, it is possible to derive other traffic parameters of
interest. This gives much more useful information than travel
times alone. Fig. 7 shows the time-position profiles of several
vehicles derived from an aerial video of Speedway Boulevard in
Tucson, AZ. Several traffic parameters can be determined from
the plot; among those the three fundamental variables of traffic
flow theory: speed, density and flow. The slope of each trajectory corresponds to the speed of the vehicle, the number of vehicles per unit of length at a point in time measures density and the
vehicles per unit of time across a point represent flow. Other parameters that can be measured from this type of diagram include
the spacing and headway between vehicles, platoon dispersion
and delay (the deviation from the desired free flow speed).
C. Densities
Probably the most straight-forward traffic application
of aerial images is the determination of density (in vehicle/km/lane) because it provides snapshots of segments of
roadway at one instant in time. The basic estimate of density
can be obtained by manually counting the number of vehicles
in an image and dividing it by the field of view of the image
and the number of lanes. As a matter of fact, a few companies
currently use this method commercially to conduct congestion
studies (e.g., [14]).
The procedure can be easily automated using edge detection
algorithms because it only requires vehicle detection (as opposed to identification, geo-referencing and matching for speed
estimation). However, as with many image processing tasks, the
automation is complicated by a number of factors. For densities,
this includes the need to classify vehicles into different groups
(e.g., passenger cars, trucks, buses, and recreational vehicles)
and deal with ambient lighting (day or night), shadows, vehicle
occlusion, inclement weather, and so on. Precise vehicle counts,
or at least systematic under- or overcounting, is also necessary
to ensure accurate density estimates.
A more accurate estimate of density can be computed by
accounting for the impact of trucks and recreational vehicles
(RVs) in the traffic stream by expressing density in terms of passenger cars per kilometer per lane (pc/km/ln). The Highway Ca-

104

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 4, NO. 2, JUNE 2003

(a)
Fig. 8.

(b)

Freeway image before and after edge detection.

(a)
Fig. 9.

(b)

Vehicle detection and outline of the polygon for intersection delay.

pacity Manual (HCM) [13] provides passenger car equivalents
for trucks and RVs. In image processing, certain blobs can be
classified as trucks or RVs by setting a blob size threshold (determined by the scale of the image). With this in mind, highway
density can be calculated with the following equation:
(1)
where
traffic density [pc/km/ln];
number of passenger cars in the image [pc];
number of trucks and buses in the image [veh];
passenger car equivalent for trucks [pc/veh];
number of RVs in the image [veh];
passenger car equivalent for RVs [pc/veh];
field of view of the image [km];
number of lanes in freeway segment.
Fig. 8 shows an image of Interstate 10 in Tucson. As an example, given the field of view (approximately 220 m), and the
fact that there are two lanes per direction, the density for each
direction can be computed. In this case, the eastbound density
is 21.6 pc/km/ln, which is slightly higher than the 18.2 pc/km/ln
westbound.

Because still cameras generally have higher sensor resolution
than video cameras, they can provide greater spatial coverage at
the same scale (in pixels/m). Also, the sampling rates provided
by still cameras are normally sufficient for density estimation.
Therefore, they are better suited for this type of analysis than
video cameras. Finally, it should be mentioned that in order to
convert density measures into level of service, the highway must
be segmented as described in [13]; in doing this several sampling considerations come up. A detailed discussion of this subject can be found in [15].
D. Intersection Delay Analysis
Intersection delay measurements are of interest to many organizations because it is the preferred measure of performance to
quantify intersection level of service. Aerial video can provide
the field of view necessary to monitor all lanes of all approaches
even for very long queues. An automated procedure for estimation of queue lengths and stopped delay using aerial video is
described here.
The first step is to extract video frames at a fixed frame sampling rate. Then, consecutive frames are analyzed using edge
detection techniques to find vehicles that remained in the same
position (stopped vehicles). Those vehicles are assumed to be
stopped for the length of the sampling interval [13]. Instead of

ANGEL et al.: METHODS OF ANALYZING TRAFFIC IMAGERY

105

TABLE III
INTERSECTION STOPPED DELAY

counting individual cars, a polygon containing all the detected
vehicles in the approach can be delineated (see Fig. 9). The instantaneous length of queue (in vehicles) for an approach is the
area of the polygon divided by the average lane width and vehicle spacing:
(2)
where
total number of vehicles in queue for the approach;

area of the polygon
;
average lane width (m);
image scale (pixel/m);
average spacing for stopped vehicles (m).
In the example in Fig. 9, the area of the polygon is 9819
. Assuming 3.65 m lanes
pixels, which corresponds to 915
and an average spacing of 7.0 m, the estimated length of the
queue is 36 vehicles. Since the actual number of vehicles in
queue in this image is 38, the estimation error is 5.3%.

106

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 4, NO. 2, JUNE 2003

Using data on the number of vehicles arriving to the intersection, the stopped delay for each approach can be computed as:
Avg. Stopped Delay

(3)

where
queue length for the approach in image (vehicles);
frame sampling interval (sec);
number of departures from the intersection during the
sample period.
This formula is taken from the ITE Manual of Transportation
Engineering Studies [16]. It assumes the average vehicle in
queue has been stopped in queue for one-half the sampling
interval before, and one-half the sampling interval after, the
observation.
This methodology was tested on three 3-min video segments
taken during the morning peak, off-peak and evening peak
hour while the helicopter hovered over the intersection of
Speedway Boulevard (running east-west) and Euclid Avenue
(running north-south) in Tucson. Frames from the video were
sampled every 10 s. The total number of stopped vehicles were
counted for each of the sampled frames, and the total number
of vehicles departing the intersection for each 3-min period
were also counted. These calculations were completed for each
lane group in the intersection in order to determine control
delay and level of service.
The results from that analysis were also compared to control
delay and level of service estimates obtained by entering the
observed signal timing, volumes, right turns on red and other
parameters into a highway capacity analysis software package.
The results of both analyses are shown in Table III.
The table shows that although the intersection operated at
LOS C or D throughout the day, many of the left turn movements
experienced LOS E or F. Perhaps the most notable case was the
westbound left movement into Euclid Avenue in the A.M. peak.
For this movement, the delay obtained from the aerial methodology was over 110 s. The HCM methodology estimated a delay
of only 70 s. To verify the validity of our results, the video was
reviewed, and it was found that indeed most of the westbound
turning vehicles did not negotiate the turn in the same cycle in
which they had joined the queue (the cycle length was 90 s).
This kind of comparison is useful because it allows researcher
to evaluate the accuracy of tools like the HCM methodology.
Overall, the HCM methodology seemed to consistently underestimate the delay of left turning vehicles and overestimate the
delay of right turns. More extensive results of this comparison
of intersection analysis methodologies are reported in [17].
These findings show that it is possible to get reasonable estimates of intersection delays from aerial video. Also, while only
three minutes of video were sampled, longer periods could be
used to provide more robust estimates of delay. This would also
resolve other sampling issues, such as the lack of observed delay
for northbound left turns shown in Table III.
IV. CONCLUSION
The level of detail obtained from aerial video permits analysis of several traffic variables and platoon dynamics of interest
such as speed, density, travel time and intersection delay. Aerial

video provides a reasonable sampling of travel times and supplies information about both between-platoon and within-platoon travel time variations. The technique described for measuring delay has been tested and the results suggest that it can
provide accurate estimates of queue length and stopped delay.
Finally, at the current time, the cost of collecting aerial video
to collect a single traffic measure (speeds, densities, delays,
travel times, etc.) is higher than the cost of traditional means
of data collection. However, since aerial video provides information on many traffic measures, and collecting those by other
means would require additional studies. Note that the study requirements may affect the flight plan in order to emphasize one
type of data over the other. However, the time-space diagrams
and the data contained in them can be derived from any flight
pattern. This indicates that no matter what flight plan is used, a
significant amount of traffic data may be obtained. In this light,
aerial video can be a cost-effective alternative (in terms of cost
per unit of data) for extensive traffic studies in which a wide
diversity of traffic data (such as travel time, density, speed and
delay, etc.) are desired.
In addition, other aerial platforms, such as uninhabited aerial
vehicles (UAVs) or even model aircraft, may also prove to be
more cost-effective than a helicopter or other aircraft. Preliminary investigation suggests that such low-cost platforms can
provide the same level of resolution in the imagery as the current off-the-shelf video camera technology, which should be adequate for traffic monitoring applications. The project team is
currently experimenting with these platforms.
There are also a number of very important, but open, issues
associated with the methods presented here. These include the
usual challenges in image processing associated with lighting
conditions, shadows, occlusion of objects, etc. In addition,
within the traffic monitoring domain, the methods presented
in this paper depend on effective techniques for: 1) developing
a road “mask” to define the roadway features of interest
and limit image processing time; 2) precise geo-referencing
of the imagery; 3) vehicle identification and matching; and
4) improvements in vehicle tracking techniques to increase
both the percentage of vehicles tracked and the accuracy of
vehicle position estimates in ground coordinates. However, the
rapid development of technology in geographic referencing
systems and computer processing capabilities suggest many
possibilities for the development of improved, automated data
reduction methods in the near future.
REFERENCES
[1] A. N. Johnson, “Maryland aerial survey of highway traffic between Baltimore and Washington,” in Proc. Highway Research
Board. Washington, D.C.: Highway Research Board, 1928, vol. 8, pp.
106–115.
[2] B. D. Greenshields, “The potential use of aerial photographs in traffic
analysis,” in Proc. Highway Research Board. Washington, D.C.: National Research Council, 1947, vol. 27, pp. 291–297.
[3] J. Malik and S. Russell, “Measuring traffic parameters using video image
processing,” in Intellimotion, vol. 6. Richmond, CA, 1997, pp. 6–7.
[4] D. J. Dailey and L. Li, “Video Image Processing to Create a Speed
Sensor,” U.S. Dept. Transportation, Univ. Washington, Mar. 1999.
[5] R. T. Collins, A. J. Lipton, T. Kanade, H. Fujiyoshi, D. Duggins, Y.
Tsin, D. Tolliver, N. Enomoto, and O. Hasegawa, “A System for Video
Surveillance and Monitoring: VSAM Final Report,” Robotics Institute,
Carnegie Mellon Univ., Tech. Rep. CMU-RI-TR-00-12, May 2000.

ANGEL et al.: METHODS OF ANALYZING TRAFFIC IMAGERY

[6] B. Coifman, D. Beymer, P. McLauchlan, and J. Malik, “A real-time computer vision system for vehicle tracking and traffic surveillance,” Transport. Res.-Part C, vol. 6, pp. 271–288, 1999.
[7] R. Kumar, H. Sawhney, S. Samarasekera, S. Hsu, H. Tao, Y. Guo, K.
Hanna, A. Pope, R. Wildes, D. Hirvonen, M. Hansen, and P. Burt,
“Aerial video surveillance and exploitation,” Proc. IEEE, vol. 89, pp.
1518–1539, Oct. 2001.
[8] B. Lucas and T. Kanade, “Detection and Tracking of Point Features,”
Carnegie Mellon Univ., Tech. Rep. CMU-CS-91-132, 1991.
[9] G. Medioni, I. Cohen, F. Bremond, S. Hongeng, and R. Nevatia, “Event
detection and analysis from video streams,” IEEE Trans. Pattern Anal.
Machine Intell., vol. 23, pp. 873–889, Aug. 2001.
[10] H. Tao, H. Sawhney, and R. Kumar, “Object tracking with Bayesian
estimation of dynamic layer representations,” IEEE Trans. Pattern Anal.
Machine Intell., vol. 24, pp. 75–89, Jan. 2002.
[11] M. Hickman, P. Mirchandani, A. Angel, and D. Chandnani, NCRST-F
Year 1 Report, Project 3—Needs assessment and allocation of imaging
resources for transportation planning and management, in National Consortium on Remote Sensing in Transportation—Flows, Univ. Arizona,
Tucson, Sept. 2001.
[12] S. M. Turner, W. L. Eisele, R. J. Benz, and D. J. Holdener, “Travel Time
Data Collection Handbook,” FHWA, U.S. Dept. Transportation, Report
FHWA-PL-98-035, 1998.
[13] Highway Capacity Manual, Transportation Research Board, National
Research Council, Washington, DC, 2000.
[14] Traffic Research and Analysis Inc., Skycomp Inc., Mini/Micro Technology Inc., Heffernan & Associates, ATD, and Northwest, 1998 MAG
Regional Congestion Study, Phoenix, AZ, Sept. 2000.
[15] A. Angel and M. Hickman, “A Method for Measuring Freeway
Level of Service From Airborne Imagery,” National Consortium on
Remote Sensing in Transportation—Flows, Univ. Arizona, Tucson,
http://www.ncrst.org/research/ncrst-f/library/cookbook_reports.html,
June 2002.
[16] H. D. Robertson, Ed., Manual of Transportation Engineering
Studies. Englewood Cliffs, NJ: Institute of Transportation Engineers
(ITE); Prentice-Hall, 1994.
[17] A. Angel and M. Hickman, “A method for analyzing the performance of
signalized intersections from airborne imagery,” presented at the 82nd
Annu. Meeting Transportation Res. Board, Jan. 2003.

Alejandro Angel received the B.S. degree in civil engineering from Universidad
EAFIT, Colombia, and the M.S. degree in transportation from the University of
Arizona, Tucson.
Currently, he works as a Traffic Engineer for MMLA, Incorporated, Tucson,
AZ. He has also worked as a Transportation Engineer for Integral S.A. in
Colombia. His areas of interest include optimization of traffic operations and
real-time and planning applications of innovative technologies in transportation.
Mr. Angel is a Member of the Institute of Transportation Engineers (ITE) and
the American Society of Civil Engineers (ASCE).

107

Mark Hickman received the B.S. degree in civil engineering and the M.S. degree in transportation in 1988, and the Ph.D. degree in transportation systems
in 1993, all from the Massachusetts Institute of Technology (MIT), Cambridge.
He has worked for Charles River Associates, Boston, MA, as a Transportation
Consultant and has worked in research at the PATH program at the University
of California—Berkeley. He was an Assistant Professor at Texas A&M University, College Station. Currently, he is an Assistant Professor in the Department
of Civil Engineering and Engineering Mechanics at the University of Arizona,
Tucson. His areas of interest include quantitative analysis of transportation systems, new technology in transportation, and public transit planning and operations.
Dr. Hickman is a Member of INFORMS, the Institute of Transportation Engineers (ITE), the American Society of Civil Engineers (ASCE), and the Transportation Research Board (TRB).

Pitu Mirchandani (M’80–SM’82) received the Sc.D. degree from the Massachusetts Institute of Technology (MIT), Cambridge, in 1975.
He is the Salt River Project Professor of Technology, Public Policy and Markets in the Systems & Industrial Engineering and Electrical & Computer Engineering Departments, and the Director of the ATLAS Research Center, University of Arizona, Tucson. He has coauthored two books and authored or coauthored over 90 journal articles. He has been a principal investigator on a large
number of research programs and consulted with several private companies and
public agencies. His areas of interests include optimization, stochastic systems
and decision-making under uncertainty, with application to transportation, logistics and real-time systems.
He is a Member of INFORMS, the Institute of Industrial Engineers (formerly AIIE, now IIE), the Transportation Research Board (TRB), and a Charter
Member of Intelligent Transportation Society of Arizona (ITS-Arizona).

Dinesh Chandnani received the M.S. degree in computer science from the University of Arizona, Tucson, in May 2002.
Previously, he was with the ATLAS Center, University of Arizona, Tucson.
Currently, he is with Microsoft Corporation, Redmond, WA.

J Math Model Algor (2014) 13:169–189
DOI 10.1007/s10852-013-9226-8

A Heuristic Algorithm for the Earliest Arrival
Flow with Multiple Sources
Hong Zheng · Yi-Chang Chiu · Pitu B. Mirchandani

Received: 30 July 2012 / Accepted: 30 April 2013 / Published online: 31 May 2013
© Springer Science+Business Media Dordrecht 2013

Abstract This paper presents a heuristic algorithm for the earliest arrival flow
problem. Existing exact algorithms, even polynomial in the output size, contain
submodular function optimization as a frequently called subroutine, and thus are not
practical in real-life applications. In this paper we propose an algorithm that does
not involve the submodular function optimization. Although solving an EAF nearoptimal, the algorithm is remarkably simple and efficient as it only involves shortest
path computations on a static network. A numerical example illustrates how the
algorithm works. As an application, we demonstrate the algorithm’s solution quality
and computational performance by solving a real-size network.
Keywords Network flows · Dynamic flows · Earliest arrival flows ·
Flows over time · Heuristics

1 Introduction
The earliest arrival f low problem is a topic in dynamic f lows, which models f lows over
time on a dynamic network. A dynamic network consists of the same static network,
with an additional arc attribute τij measuring a pre-defined constant traversal time
from the tail of an arc (i, j) to its head. Although τij is regarded as constant in a

H. Zheng (B) · Y.-C. Chiu
Department of Civil Engineering and Engineering Mechanics,
University of Arizona, 1209 E 2nd St, Rm 206, Tucson, AZ 85721, USA
e-mail: hzheng@email.arizona.edu
Y.-C. Chiu
e-mail: chiu@email.arizona.edu
P. B. Mirchandani
School of Computing, Informatics and Decision Systems Engineering,
Arizona State University, Tempe, AZ 85287, USA
e-mail: pitu@asu.edu

170

J Math Model Algor (2014) 13:169–189

dynamic network, a dynamic flow model specifies flows entering the network at each
time point so that flows on arcs are not constant but vary over time. Obviously, one
can consider the constant arc traversal time on a dynamic network as a constant
flow-independent link-travel-time on a traffic network, so that a dynamic flow
problem models time-varying flows but with a simple link performance function. On
a dynamic network, not only flows to be transmitted but also the time needed for the
transshipment play vital roles.
Dynamic flows (also called f lows over time) were introduced by Ford and
Fulkerson [1], in their study of finding the maximal s − t flow (from a single source
s to a single sink t) with a given horizon, known as the maximum dynamic flow
problem. Ford and Fulkerson showed that there is always a solution of this problem
falling in the class of temporally repeated f lows, and then transformed the maximum
dynamic flow into a static min-cost circulation on an extended network, where the
traversal times on arcs are interpreted as the cost variables. In an obvious way, most
dynamic flow problems can be solved via easy static flow computations on a timeexpanded network, which contains one copy of the original network for each discrete
time step; such an algorithm is pseudopolynomial. Since Ford and Fulkerson [1],
a vast body of research highlights that the technique of temporally repeated flow
is a key concept—not computing flows on arcs at each individual time step, but
producing flows remaining constant during a long time period—to solve a dynamic
flow problem eliminating the time-expanded network. Excellent surveys of dynamic
flows can be found in [2–4]. Overall, two approaches have been taken to model
dynamic flows, i.e., discrete time and continuous time. There is no much difference
between the two methods, for most known discrete-time algorithms can be extended
to produce continuous flows [5].
Given a time horizon T and a dynamic network N , where each arc (i, j) ∈ N has
an associated capacity uij and traversal time τij , a flow over time that simultaneously
maximizes the amount of flow reaching the sink during every interval [0, τ ] such
that 0 ≤ τ ≤ T is called an earliest arrival f low (EAF). Let νmax(τ ) be the value of
the maximum dynamic flow that one can send from sources to the sink until time τ ;
an EAF achieves the value of νmax(τ ) simultaneously at any τ such that 0 ≤ τ ≤ T.
Gale [6] and Philpott [7] showed, in discrete and continuous time respectively, the
existence of an EAF on a single-source single-sink network. An EAF may not exist
on a network with multiple sinks. Fleischer [8] presented an instance on a network
with two sinks where an EAF does not exist. On a single-sink network with multiple
sources, however, an EAF always exists if the network parameters are pre-defined
[9, 10].
Applications of the earliest arrival flow problem are seen in evacuation models.
Chalmet et al. [11] modeled the quickest transshipment problem in a building
evacuation, via constructing a maximum dynamic flow on a time-expanded network.
Jarvis and Ratliff [12] showed that if the cost of the arrival flow associated with
time τ is cτ and c1 < c2 < · · · < cT , known as a turnstile cost, then the following
three optimization objectives—[i] earliest arrival flow, [ii] min-turnstile cost flow,
i.e., min-cost dynamic flow in which arrival flows areassociated
   with
  the cost vector
cτ , [iii] quickest transshipment flow—have a relation i = ii ⊆ iii . Hamacher and
Tjandra [13] gave a thorough survey on techniques of modeling dynamic flows in an
evacuation context.
Most evacuation models placed on a dynamic network above do not capture the
spatial/temporal flow dynamic effects among links. According to traffic flow theories,

J Math Model Algor (2014) 13:169–189

171

congestion builds up and may exponentially increase the travel time when inflow
exceeds the capacity; the resultant traffic jam continuously propagates backward
along the roadway (spillback) and may collapse the facility supply. The phenomena
are all around in an evacuation scenario due to the pent up demand. In this regard,
research by the transportation community desires to measure a flow dependent travel
time to capture flow dynamic and even queue spillback effects within and/or cross
links. Introducing flow-dependent arc traversal time in a dynamic flow problem
escalates the model’s complexity significantly [14, 15].
Recently, the system optimal dynamic traffic assignment (SO-DTA) problem on
a single sink network [16], which encapsulates a discretized macroscopic traffic flow
model—called the cell-transmission model (CTM) [17, 18], is widely applied in a
handful of vehicular evacuation scenarios [19–23], due to its simple but high fidelity
of capturing spatial/temporal flow dynamics featured by CTM. In fact, the widely
applied CTM based SO-DTA model is closely related to the EAF.
Zheng and Chiu [24] showed that the CTM based SO-DTA is equivalent to an
EAF placed on a space-time discretized network, i.e., network is discretized into
cells and time span is discretized into small steps. They showed that the SO-DAT
respecting the backward wave propagation constraint is optimal if and only if the
arrival flow exhibits the earliest arrival pattern. Moreover, in a specialized case where
cell properties are time-invariant, Zheng et al. [25] further proved that an EAF
placed on a network without space-time discretization and not constrained by the
backward wave propagation constraint is theoretically a subset of CTM based SODTA. Consequently, one can apply an EAF algorithm to solve SO-DTA.
Solution algorithms to the EAF differ substantially in two cases, i.e., single source
and multiple sources. In the single source case, the earliest arrival s–t flow has
been well studied. Wilkinson [26] and Minieka [27] both gave pseudopolynomial
algorithms based on the successive shortest path (SSP) method. The algorithm keeps
on augmenting flows along the shortest paths found on the residual network and
turns static flows into dynamic flows via Ford and Fulkerson’s temporally repeated
flow technique. Hoppe and Tardos [28] gave an approximate polynomial method for
this problem, through a capacity scaling algorithm within a factor of 1 +  for a given
error  > 0.
On a single-sink network with multiple sources, the EAF problem has been an
active research area. Hajek and Ogier [29] solved this problem for a special case
where all traversal times are zero. They obtained a polynomial-time algorithm for a
fractional value by reducing it to |N| maximum flow computations. This result was
further sped up by Fleischer [8]. Rauf [30] solved for another special case where
sources are tight; the problem was reduced to one lexicographical maximum dynamic
flow computation. As for the general case of multi-source earliest arrival flow
problem, Fleischer and Skutella [31] gave an approximate method via a condensed
time-expanded network technique.
Recently, Baumann and Skutella [32] gave the only known exact algorithm
(referred to as B-S algorithm hereafter) for the multi-source EAF problem in
a general case. They gave a combinatorial approach which indentifies a nested
sequence of sources S0  S1  · · ·  Sk together with corresponding time θ0 ≤ θ1 ≤
· · · ≤ θk such that the sources in Si \Si +1 have run empty at time θi+1 . To identify
the subset Si along with its θi , they employed a parametric submodular function
optimization. These steps only compute the amount of an EAF, or the EAF pattern,
without identifying its associated flow transshipment. To realize the earliest arrival

172

J Math Model Algor (2014) 13:169–189

transshipment, they solved an equivalent quickest transshipment problem on an
extended multi-source multi-sink network, where the number of sinks in the worst
case could be exponential in the input size. Furthermore, in B-S algorithm of realizing
the earliest arrival transshipment, it involves the submodular function optimization
again due to the quickest transshipment algorithm given in [33]. Although proven to
be polynomial in the output size, B-S algorithm is mainly considered as a theoretical
result, and not very practical in the real-life implementation, because it contains
submodular function optimization as a frequently called subroutine.
This paper presents a heuristic algorithm for the multi-source EAF problem.
Similar to B-S algorithm, we also identify a nested sequence of sources Si together
with corresponding time θi such that the sources in Si \Si +1 have run empty by
time θi+1 . Our contribution is that we do not call submodular function optimization.
The main body of the algorithm consists of a series of SSP-based earliest arrival
s–t flow computations. Moreover, we solve the EAF pattern and its associated
transshipment simultaneously only on the input network. The method is heuristic
but remarkably simple and efficient as it only involves shortest path computations
on a static network.
The remainder of the paper is organized as follows. In Section 2 we define notation
and introduce preliminary dynamic flow algorithms. The detail of the algorithm is
articulated in Section 3, followed by numerical examples in Section 4. Not only
does an illustrative example show the algorithmic procedure, we also demonstrate
an application of the proposed algorithm on a real-life network. Finally Section 5
concludes the paper.

2 Preliminaries
2.1 Notation
Dynamic network N = (N, A, u, τ, S) consists of a set of nodes N, a set of arcs A,
where each arc (i, j) ∈ A is associated with a positive capacity uij and a non-negative
traversal time (or length) τij , and a subset of nodes called terminals. Terminals consist
of a set of sources, denoted by S+ , and a set of sinks, denoted by S− . If s is the
single source and t is the single sink in the network, the network is called an s −
t network. Given an s − t network, if one use a dummy arc to connect t to s, the
resultant network is called a circulation network.
A static f low defines afunction 
of f on arcs of a graph that maintains
f low

conservation condition
fij −
f ji = 0 for all i ∈ N\ S+ ∪ S− . A static
(i, j)∈A

( j,i)∈A

circulation is a static flow that also admits flow conservation condition at terminals.
f is called feasible if it obeys capacity constraint 0 ≤ fij ≤ uij for all (i, j) ∈ A. The
residual network of a static flow f is the same network, with the residual capacity
f
function defined by uij = uij − fij . For any feasible f on a s − t network N , we say f
constructs a circulation on the circulation network by sending | f | amount of flows on
the dummy arc (t, s).
A continuous dynamic f low xij (τ ) is a function that defines the rate of f low
(amount of flow per time unit) that leaves the tail of (i, j) ∈ A at moment τ , and
reaches the head at τ + τij . Assume xij (τ ) = 0 for τ < 0. For a path P which is denoted

J Math Model Algor (2014) 13:169–189

173

by a set of ordered arcs, denote by τ (P) :=


(i, j)∈P

τij the traversal time/length of P,

and denote by u (P) = min uij the capacity of P. Given a horizon T, a dynamic flow
(i, j)∈P

maintains the following flow conservation conditions.
  θ
  θ −τ ji 	


x ji τ − τ ji dτ −
xij (τ ) dτ ≥ 0
( j,i)∈A

0

 

( j,i)∈A



∀i ∈ N\ S+ ∪ S−
,
∀θ ∈ [0, T)

(1)



xij (τ ) dτ = 0 ∀i ∈ N\ S+ ∪ S−

(2)

(i, j)∈A 0

T−τ ji

 
	


x ji τ − τ ji dτ −

0

(i, j)∈A

T
0

Equation 1 indicates that the dynamic flow permits hold-over at intermediate nodes.
If hold-over is not allowed, then the flow conservation condition admits (Eq. 3)
instead of Eq. 1.


  θ −τ ji 	
  θ


∀i ∈ N\ S+ ∪ S−
x ji τ − τ ji dτ −
xij (τ ) dτ = 0
, (3)
∀θ ∈ [0, T)
0
0
( j,i)∈A

(i, j)∈A

We say a dynamic flow x =(xij (τ )) is feasible if the capacity constraint (Eq. 4) holds.
xij (τ ) ≤ uij

∀ (i, j) ∈ A,
∀τ ∈ [0, T)

(4)

The value of a dynamic flow x = (xij (τ )) is denoted by |x|.
2.1.1 Temporally Repeated Flows
Given
a static
 flow f = ( fij ), decompose f into f p on a set of paths P ∈ P such that
fij =
f P . Send flows at a constant rate f P along P, repeating from time zero
P∈P (i, j)∈P

till T–τ (P)—the maximum moment when f P is able to reach the sink node t by T.
The dynamic flow induced in such a manner is called a temporally repeated f low. The
value of a temporally repeated flow x can be computed by



|x| =
τP fP = T | f | −
τij fij 1
(5)
(T − τ (P)) f P = T | f | −
P∈P

P∈P

(i, j)∈A

Temporally repeated flows show a simple way one can turn a static flow into a
dynamic flow. Hoppe and Tardos [33] generalized this concept to chain flows. The
algorithm throughout this paper utilizes the concept of chain flows.
2.1.2 Chain Flows—Hoppe and Tardos’ Def inition [33]
A chain flow γ = (|γ | , P) is a static flow of value |γ | ≥ 0 along path (or cycle)
P which starts from the source set S+ and ends in the sink set S− . The traversal
time/length of the chain flow τ (γ ) is the traversal time/length of path P. Given a
time horizon T no less than τ (γ ), a chain flow γ induces a dynamic flow [γ ]T by

1 Ford

and Fulkerson originally defined temporally repeated flows in discrete times. The value of a
temporally repeated flow computed here is in continuous times due to [5].

174

J Math Model Algor (2014) 13:169–189


sending flows at the same rate |γ | along P at every moment τ ∈ 0, T − τ (γ )). The
value of [γ ]T is computed by
   
 T
 γ =

T−τ (γ )

|γ | = (T − τ (γ )) · |γ |

(6)

0

Let  = {γ1 , γ2 , ..., γn } be a set of chain flows which is a decomposition of static flow f
n


|γi |. Given a horizon T, if every
if
γi = f . The value of  is denoted by || :=
γi ∈

i=1

chain flow in  has a length no more than T,  induces a dynamic flow by summing
up each dynamic flow induced by γi ∈ . The dynamic flow induced in this manner is
denoted by []T . The value of []T is denoted by

 T 
[]  =
|[γi ]T | =
(T − τ (γi )) · |γi |
γi ∈

(7)

γi ∈

Chain flows differ from temporally repeated flows slightly as in the former some
chain flow γi may use arcs in the opposite direction as f does. If so the induced
dynamic flows are also called non-standard chain decomposable f lows. In such a case
one needs to be careful of feasibility of the induced dynamic flows.
2.1.3 Chain Flows—A General Way
All prior methods turning static flows into dynamic flows based on the concept
of chain flows repeat from time zero. Our method extends the means to repeat
flows from a nonnegative time. Denote a time window W := [T1 , T2 ], where
T1 < T2 , given a chain flow in γ with a length no more than T2 , γ induces a
dynamic flow by sending flows at the same rate |γ | along P at every moment

 T
τ ∈ max (0, T1 − τ (γ )) , T2 − τ (γ )). The induced dynamic flow is denoted by γ T21 .
 T2
The value of γ T1 is computed by
   
 T2 
 γ T1  =

T2 −τ (γ )
max(0,T1 −τ (γ ))

|γ | = (T2 − τ (γ ) − max (0, T1 − τ (γ ))) · |γ |

(8)

  
 T
Equation 8 indicates that if τ (γ )≥ T1 , γ induces a dynamic flow with value  γ 0 2 .
Otherwise
 is Eq. 9, which indicates γ induces a dynamic flow with value
    there
 T2   T1 
 γ 0  −  γ 0 .
   
 T2 
 γ T1  =

T2 −τ (γ )
T1 −τ (γ )

     


 T  T
|γ | = (T2 − τ (γ )) − (T1 − τ (γ )) · |γ | =  γ 0 2  −  γ 0 1  (9)

Let  = {γ1 , γ2 , ..., γn } be a set of chain flows which is a decomposition of static flow
n


|γi |. Given a time window W =
f if γi = f . The value of  is denoted by || :=
i=1

γi ∈

[T1 , T2 ]: T1 < T2 , if every chain flow in  has a length no more than T2 ,  induces

J Math Model Algor (2014) 13:169–189

175

a dynamic flow by summing up each dynamic flow induced by γi ∈ . The dynamic
flow induced in this manner is denoted by []TT21 . The value of []TT21 is denoted by



 T2  
|[γi ]TT21 | =
(T2 − τ (γi ) − max(0, T1 − τ (γi ))) · |γi |
(10)
[]T1  =
γi ∈

γi ∈

Note that if T1 = 0 and T2 = T, then []TT21 induces the same dynamic flow with a
horizon T as referenced in [33]. Otherwise there are:
[]TT21 = []0T2 − []0T1

 
 

 T2   T2   T1 
[]T1  = []0  − []0 

(11)
(12)

In the case of a time window W := [T1 , T2 ]: T1 ≥ T2 , any chain flow γ induces
an empty dynamic flow with value zero, and any set of chain flow  = {γ1 , γ2 , ..., γn }
also induces an empty dynamic flow with value zero.
2.2 The Problems
Maximum dynamic f lows The objective of the maximum dynamic f low problem is
to send the maximal amount of flow from a source s to a sink t at the end of horizon
T. Mathematically the maximum dynamic flow problem can be stated as:
max vmax(T) = v

(13)

Subject to
 

T

xsj (τ ) dτ = v

(14)

(s,i)∈A 0

 T
(i,t)∈A

0

xit (τ − τit ) dτ = v

(15)

(1) , (2) , (4)

Earliest arrival f lows (EAF) In the EAF problem terminals are associated with a
supply/demand vectorb . Every source i ∈ S+ has b (i) ≥ 0 and the sink node
 t has
b (t) ≤ 0, such that
b (i) = 0. For any subset S ⊆ S+ , denote b (S) =
b (i).
i∈{S+ ∪S− }

i∈S

The EAF problem can be stated as:
max vmax (θ ) = v (θ ) for all θ ∈ [0, T)

(16)

Subject to
 

θ

xij (τ ) dτ  b (i)

∀i ∈ S+ , ∀θ ∈ [0, T)

(17)

(i, j)∈A 0

 
( j,t)∈A

θ

	


x jt τ − τ jt dτ = v (θ )

∀θ ∈ [0, T)

(18)

0

v (θ ) ≤


i∈S+

b (i)

∀θ ∈ [0, T)

(1) , (2) , (4)

(19)

176

J Math Model Algor (2014) 13:169–189

Here v(θ ) is a mapping of θ which denotes the value of a feasible dynamic flow has
been sent to the sink at time θ . The objective is to maximize v(θ ) at all possible time
θ ∈ [0, T). vmax (θ ) is a mapping of θ which denotes the maximal value of a dynamic
flow has been sent to the sink at θ . Clearly, function θ → vmax (θ ) denotes the EAF
pattern.
Proposition 1 [32, 34].
(I) On a single-source single-sink network, vmax (θ ) is piecewise linear and convex.
(II) On a single sink network with multiple sources, vmax (θ ) is piecewise linear.
Proof For (I) see Theorem 1 in [34]. For (II) see Corollary 2.1 in [32].





Given that vmax (θ ) is continuous and piecewise linear,
	 + 
denote the right-hand-side

(RHS) derivative of vmax (θ ) at time θ ∈ [0, T) by vmax
θ , and left-hand-side (LHS)
	 −


derivative at time θ ∈ (0, T) by vmax
θ . That is,
	 +

vmax (θ + ε) − vmax (θ )

: θ ∈ [0, T)
vmax
θ = lim
ε↑0
ε

(20)

	 −

vmax (θ + ε) − vmax (θ )

vmax
: θ ∈ (0, T)
θ = lim
ε↓0
ε

(21)

and

2.3 SSP Based Earliest Arrival s − t Flow Algorithm
In this section we focus on dynamic flows on a s − t network. Given a horizon T Ford
and Fulkerson showed that there is always a maximum dynamic flow featured in the
class of temporally repeated
 flows. Maximizing the value of a temporally repeated
flow equals minimizing
τij fij − T | f |, according to Eq. 5. This equals solving a
(i, j)∈P

minimum cost circulation flow f on a circulation network, where the traversal time
is interpreted as cost, and the sink t is connected to the source s by a dummy arc with
cost −T and infinite capacity. Hence the maximum dynamic flow can be solved via
one min-cost circulation flow computation. The method is due to [1].
Consider a special min-cost circulation flow that is computed by the SSP algorithm
in the circulation network above. Denote by [SSP] the set of s − t chain flows
obtained by the SSP
θ such that θ ∈ [0, T), the subset
 algorithm.

 Given an instance

of chain flows  = γi ∈ SSP : τ (γi ) < θ also establishes a min-cost circulation on
the circulation network where t is connected to s by an uncapacited arc with length
−θ . This concludes that the min-cost circulation obtained by SSP induces a maximum
dynamic flow not only at T, but at any time θ ∈ [0, T), which is clearly an EAF. This
leads to the SSP-based earliest arrival s − t flow algorithm, which is due to [26, 27].
While Algorithm 1 runs in a sufficiently efficient manner in practice, it is not
polynomial as the number of paths involved in Step 2 could be exponential [35].

J Math Model Algor (2014) 13:169–189

177

Algorithm 1 SSP-based Algorithm for the Earliest Arrival s − t Flow

3 Algorithm
Define the function θ → oθ (.) as follows [32, 33]. Given a subset of sources S :
S ⊆ S+ on a multi-source single-sink network, let oθ (S) be the value of a maximal
dynamic flow that S can send to t jointly, regardless of the supply in source S
(ignore supply demand function). oθ (S) can be obtained by one maximal dynamic
flow computation on an extended network N (o), which is constructed as follows.
Create a supersource node s and connect it to all sources in S by uncapacitated arcs
with length zero. Since oθ (S) is the value of a maximal dynamic flow on N (o), it can
be computed by one min-cost circulation computation on the circulation network by
connecting t to s through an uncapacitated arc with length −θ on N (o).
Proposition 2 Given a set of sources S ⊆ S+ , oθ (S) is piecewise linear and convex.
Proof The result follows immediately by (I) of Proposition 1.





As oθ (S) is piecewise linear, we can define the derivative function similar to
+
vmax (θ ). Denote the RHS derivative of oθ (S) at time θ ∈ [0, T) by oθ (S), and
θ −
the LHS derivative at time θ ∈ (0, T) by o (S). The following properties on the
derivatives of oτ (S) are helpful to solve the multi-source EAF problem.
Lemma 3 [34] Given a set of sources S ⊆ S+ , let G θ be the class of all sets of chain
f lows that induces a dynamic f low with value oθ (S) on N (o), and  be any set of
chain f lows in G θ . Let min (max ) be
 	 f lows with theminimal (maximal)


 a set of chain
value among G θ , i.e., min ∈ arg min || :  ∈ G θ max ∈ arg max || :  ∈ G θ
(I) The value || is a subgradient
of oθ (S) at time θ .

θ −
(II) o (S) = |min | = γi [SSP] |γi | : τ (γi ) < θ .
−

Proof Burkard et al. [34] proved (I) and the result of oθ (S)= |min | in discrete
flows. Their results
are also correct in continuous flows. Here, we just need to

show |min | = γi [SSP] |γi | : τ (γi ) < θ . Due to Algorithm 1, the set of s − t chain flows

178

J Math Model Algor (2014) 13:169–189





obtained by SSP on N (o), i.e.,   = γi : γi ∈ SSP 	τ (γi ) < θ  , induces
a dynamic

flow 
with value of oθ (S). So there are   ∈ G θ and |min | ≤   . The static flow
f =
γ measures the amount of flow being sent per time unit at θ and thus
   γi ∈  i
  = | f | measures the LHS derivative of oθ (S) at θ . Observe that reduce the value
 
−
−
of   results in a strictly decrease
of oθ (S), it implies oθ (S) = |min | ≥   . It then




concludes that |min | =    and completes the proof.
Lemma 4 Let subset S ∈ S+ be sources which have not run empty by time θ and
compare the derivative of vmax (θ ) and oθ (S). We have the following results.
	 −

−

(I) vmax
θ ≤ oθ (S) for any θ ∈ (0, T).
	 +

+

θ ≤ oθ (S) for any θ ∈ [0, T).
(II) vmax
Proof Create the extended network N (o). Construct the circulation network by connecting t to s using an uncapacitated arc with length −θ , where 0 < θ < T. Compare
the LHS derivative between vmax (θ ) and oθ (S)
 at time θ . Due to (II) of Lemma
−
3, we have oθ (S) = ||, where  = γi : γi ∈ SSP 	τ (γi ) < θ constructs a minvalue min-cost circulation
network regardless of supply/demand
	 − 
on the  circulation

function b (·), and vmax
θ =  , where   constructs a feasible circulation flow on
the circulation network. Note that we do not know what   should be, except that it
is a feasible static flow on N (o). Observe that each γi = (v, P) ∈   is with a length
	 −


strictly less than θ (because inducing γi with a length ≥ θ won’t affect vmax
θ ),
it implies γi must construct a negative-cost-circulation on the circulation network.
Such paths must be saturated by , for otherwise violating that  constructs
a min 
cost circulation on the circulation network. We then conclude that    ≤ ||, so the
result of (I) follows.
Since both vmax (θ ) and oθ (S) are piecewise linear and continuous. The result of
(II) then follows immediately from (I).



Lemma 4 suggests an intuitive idea for the multi-source earliest arrival flow
problem, where we always send flows at the maximum possible rate. Initially vmax (θ )
is constructed at the same rate of oθ (S+ ), until supply in a certain source δ ∈ S+
is depleted
know what
the appropriate


	 + 
 at some time θ1 . At time θ ≥ θ1 , we do not
+ 	

v max
θ shall be, but we know it must be bounded by oθ S+ \δ followed by Lemma
4. Thus, if we can show
a dynamic flow induced by the maximum
	 +that

 somehow
+

possible rate, i.e., vmax
θ = oθ (S\δ), is feasible for θ ≥ θ1 , we are done because
Lemma 4 guarantees that vmax (θ ) produced in such a manner is at the maximal
possible
rate.

 At the current stage, suppose that inducing a dynamic flow at a	rate of


+ 	
oθ S+ \δ is feasible and continue constructing vmax(θ ) at the same rate as oθ S+ \δ ,
until we identify the next time θ2 when another source runs empty. Continue the
algorithm until supply in all sources is depleted.
Following this method, we describe
an algorithm for the multi-source EAF

problem. It consists of solving  S+  iterations of oθ (·) by the SSP method on a set
+
of N (o), where the supersource
 S+  . The function
 +  s is connected to a set of subsets of



vmax (θ ) is separated into S segments, identified by i = 0, 1, ..., S  − 1, and each
segment i is identified by a time θi+1 , a set of source Si such that supply in Si \Si+1 is
depleted at θi+1 , and a set of chain flows  i that induces the EAF. In each segment

J Math Model Algor (2014) 13:169–189

179

	 +

+

θ = oθ (Si ). The pseudo-code is presented below. To avoid the
we maintain vmax
algorithm ill-behaved, we assume all sources have feasible paths reaching the sink.
Algorithm 2 Earliest arrival flow with multiple sources

Algorithm 2 is an extension of Algorithm 1 with multiple sources. Initially the
algorithm starts from θ0 = 0 and S0 = S+ , where S0 denotes a set of sources whose
supply is positive at θ0 . The algorithm applies SSP to compute a set of chain flows
 0 that induces a dynamic flow with value of oθ (S0 ). Whenever finds a new path
with length of τ (γ ) in SSP, we assume to induce a dynamic flow by  0 and check is
there any source has run empty by τ (γ ). If yes we identify a minimum time θ1 with

180

J Math Model Algor (2014) 13:169–189

a source δ such that supply in δ runs empty at θ1 . Between the interval θ ∈ [0, θ1 ),
the algorithm finalizes vmax (θ ) = oθ (S0 ) and updates the remaining supply in S0 at θ1
 θ
by inducing  0 01 . Sources with positive supply at θ1 become S1 = S0 \δ. Next, the
algorithm treats θ1 as a new starting point and constructs vmax (θ ) at the same rate of
oθ (S1 ), until θ2 when another source empties its supply, and so on. Note that  i wrt
each iteration i in Step 2 are obtained from different N (o), where s is connected to
different set of sources Si . One may loosely understand that the network is saturated
before θi but still empty after θi , so in each iteration the algorithm starts from a fresh
new network in Step 2.1. The size of Si reduces at least one during each iteration in
the while loop in Step 2.
At step 2.2.3, the minimal time θmin when a source δ depletes its supply can be
computed as follows. For each source s ∈ Si , compute a time θ (s) when the source s
depletes its supply by Eq. 22.


b (s) =

i

γ ∈[



|γ | · θ (s) − max {τ (γ ) , θi } , ∀s ∈ Si

(22)

]: s(γ )=s

where b (s) stands for the remaining supply of s at θi ; s(γ ) represents the source where
γ originates.
Then
θmin ← min {θ (s) : s ∈ Si }
δ ← s : θ (s) = θmin
τ (γ )

If θmin < τ (γ ), it means δ ∈ Si runs empty at θmin < τ (γ ) in [ i ]θi , then the
algorithm goes into “YES” branch at step 2.2.3. Otherwise θmin ≥ τ (γ ), the algorithm
goes into “NO” branch, add γ into  i and continues.
The remaining task is to show the dynamic flow induced by Algorithm 2 is feasible,

| S+ |−1
θ
i.e., i=0 [ i ]θi+1
obeys the arc capacity constraints at every moment. This might
i
be a problem because  i wrt each iteration i is computed on the freshly new network
N (o) rather than the residual network continued by previous iterations (see Step 2.1
in Algorithm 2). The following demonstrates an example.
In Fig. 1 suppose γ1 ∈  i and γ2 ∈  i+1 . Following Step 3 in Algorithm 2,  i sends
γ1 until θi+1 − τ (γ1 ), and  i+1 sends γ2 starting from θi+1 − τ (γ2 ) (suppose τ (γ2 )<
θi+1 ). In the illustrated network, (y, z) is touched by γ1 until time θi+1 − 2 and touched

Fig. 1 Illustration of the arc
that may be invoked by
multiple chain flows at the
same time in Algorithm 2

(1,1)

(1,2)

(2,1)

J Math Model Algor (2014) 13:169–189

181

by γ2 beginning θi+1 − 3. Both γ1 and γ2 induce dynamic flows
 on arc (y, z) (we use
the tail-point of the arc as a benchmark) during interval η = θi+1 − 3, θi+1 − 2). As γ1
and γ2 are computed on two different networks in Step 2.1, we must ensure that flows
along arc (y, z) induced by both γ1 and γ2 are bounded by u yz at any time point in η.
Theorem 5 The dynamic f low induced in Algorithm 2 is feasible.

Proof The flow conservation constraints are trivial, so we consider capacity constraints only. Apply the induction method.  0 is a min-cost circulation solved by
SSP and thus induces an earliest arrival s − t flow, which is obviously feasible.
 

  i θi+1
Suppose k−1
is feasible at iteration k–1, where k ∈ Z+ , 1 < k <  S+ , we
i=0  θi

  θ
show ki=0  i θi+1
is also feasible at iteration k.
i
Before
continuing
the proof,
 some definitions need to be clarified. Denote by

 iyz = γ ∈  i : (y, z) ∈ P (γ ) the subset of chain flows that uses arc (y, z), where
P(γ ) denotes the path of chain flow γ . Denote by p y (γ ) the corresponding length
from node y to the sink t along P(γ ). Given a time instance θ , denote by  iyz (θ ) ⊆  iyz
 θ
the subset of chain flows such that for any γ ∈  iyz (θ ), the γ -induced flow γ θi+1
i
touches (y, z) at θ . By definition,  iyz (θ ) = {γ ∈  iyz : θi − θ ≤ p y (y) < θi+1 − θ }.
Consider the arc capacity constraint of arc (y, z) at θ , which is affected by



k−1 i
θi+1
θ
and [ kyz (θ )]θk+1
only. Consider any pair γ |γ  such that γ ∈
i=0 [ yz (θ )]θi
k

k−1 i

k

i=0  yz (θ ), γ ∈  yz (θ ) , and both dynamic flows induced by γ and γ touch (y, z)

k−1 i
θ
at θ . If such a pair does not exist then obviously the dynamic flows i=0 [ yz (θ )]θi+1
i
θ
and [ kyz (θ )]θk+1
never touch (y, z) at the same time, and thus maintain feasik


bility. Otherwise, due to  iyz (θ ) = γ ∈  iyz : θi − θ ≤ p y (γ ) < θi+1 − θ , we have
	 

p y (γ ) < θi+1 − θ ≤ θk − θ , and p y γ  ≥ θk − θ . That is, p y(γ )< p y (γ  ). It implies
that when we apply SSP solving  i , i = 0, 1, ..., k − 1, the subpath from y to t along
P(γ ) for every γ ∈  iyz (θ ) must be saturated by the subset of chain flows   i+1 =


	 

γ  ∈  i+1
:
θ
−
θ
≤
p
−
θ
(for otherwise violating SSP in solving  i+1 );
γ
<
θ
i
y
i+1
yz
and this condition holds for every i = 0, 1, ..., k − 1. Moreover, since  kyz (θ ) = ∅, it
means some chain flow γ ∈  k is able to touch (y, z) at θ , which implies the subpath
from y to t for every γ ∈  i , i = 0, 1,

 ..., k − 1 must be saturated by chain flows
	 


k
γ ∈  yz : θi − θ ≤ p y γ < θi+1 − θ , i = 0, 1, ..., k − 1 respectively, for otherwise
violating SSP in solving  k .
So






|γ | ≤

0≤i≤k−1 γ ∈ iyz (θ )

|γ | +



|γ |



|γ | +

γ ∈ kyz : p y (γ )<θ1 −θ

≤ ··· ≤



1≤i≤k−1 γ ∈ iyz (θ )

γ ∈ kyz : p y (γ )<θ1 −θ

≤





γ ∈ kyz : p y (γ )<θk −θ

γ ∈ kyz :θ1 −θ ≤ p y (γ )<θ2 −θ

|γ |

|γ | +





2≤i≤k−1 γ ∈ iyz (θ )

|γ |

182

Then

J Math Model Algor (2014) 13:169–189





0≤i≤k−1 γ ∈ iyz (θ )

|γ | =





|γ | +

0≤i≤k−1 γ ∈ iyz (θ )

|γ | =

γ ∈ kyz : p y (γ )≥θk −θ

This concludes the feasibility of


k
i=0



|γ | ≤

γ ∈ kyz (θ )



+




|γ |

γ ∈ kyz : p y (γ )<θk −θ

|γ | ≤ u yz

γ ∈ kyz

θ

[ i ]θi+1
at any θ and completes the proof.
i





The reason that the current version of the algorithm does not warrant an optimal
solution is because the time θi solved in such a manner does not guarantee the actual
time when a source depletes its supply in an EAF.
Theorem 6 If the set of θi obtained in Algorithm 2 is the actual time when a source
depletes its supply in an optimal EAF pattern, then Algorithm 2 solves an exact solution
of the EAF problem.
θ

Proof In Algorithm 2 we have  i that induces [ i ]θi+1
. Due to Algorithm 1 obviously
i
θ
the value of dynamic flow [ i ]θ0i equals oθi (Si ), and the value of [ i ]0i+1 equals
θ
θ
oθi+1 (Si ). According to Eq. 12 we have |[ i ]θi+1
| = |[ i ]0i+1 | − |[ i ]θ0i | = oθi+1 (S) −
i
θi
o (S).

Given a θ ∈ θi , θi+1 ), if we use θ replace θi+1 in above analysis, the dynamic flow
induced in Step 3 maintains
 

v (θ ) − v (θi ) = oθ (Si ) − oθi (Si ) : θ ∈ θi , θi+1 ) , ∀i = 0, 1, ...,  S+  − 1
(23)
	


Suppose
θi , clearly it maintains v θ + = oθ + (Si ) for
 +
 we obtain the appropriate


any θ ∈ θi , θi+1 ) , ∀i = 0, 1, ..., S − 1. The rate of the induced dynamic flow is
clearly maximal possible at any time instance θ ∈ [0, T) due to Lemma 4. This
concludes that the induced dynamic flow is an EAF and completes the proof.



Suppose that we successfully identify the appropriate θi , following is an intuitive
interpretation of Algorithm 2 We identify a set of sources Si which have not run
empty at θi and use chain flows  i to establish oθ (Si ). We construct vmax (θ ) as follows.
Use  0 to induce a dynamic flow with value of oθ (S0 ); cut oθ (S0 ) between interval
[θ0 , θ1 ) and add it to vmax (θ ). Use  1 to induce a dynamic flow with value of oθ (S1 );
θ
cut o
(S 1 ) between interval [θ1 , θ2 ) and add it to vmax (θ ). Repeat the procedure until
 +

i = S  − 1 and S|S+ | = φ. This procedure is illustrated in Fig. 2.
3.1 Complexity
 
In Algorithm 2, the number of iterations in Step 2 is bounded by  S+ . In each
iteration, the loop in Step 2.2 excluding 2.2.2 runs at most the same time as computing
an earliest arrival s − t flow by the SSP method. One computation of Step 2.2.2 takes
# †i O (1) time, where # †i denotes the cardinality of  i . In the SSP method, each
path in  i indicates a breakpoint in vmax (θ ), so # †i is bounded by total number of
breakpoints in vmax (θ ), denoted by λ.	Step
 2.2.2

 is repeated in Step 2.2 at most λ
times, so overall Step 2.2.2 runs in O  S+  · λ2 . The complexity of the algorithm is

J Math Model Algor (2014) 13:169–189

183

Fig. 2 Illustration of vmax (θ)
and oθ (·)

	  	



O  S+  EAF + λ2 , where EAF denotes computation time of an earliest arrival
s − t flow by the SSP method. Since EAF is not polynomial, the presented algorithm
is not polynomial.

4 Numerical Examples
4.1 An Illustrative Example
In this section, we use an example to illustrate how to apply Algorithm 2 to solve the
multi-source EAF problem. The example dynamic network is given in Fig. 3. Nodes
1–3 are sources and each source has 50 units of flow to be sent to the single sink, node
9. Create an extended network by connecting supersource s to S0 = {1, 2, 3}. Apply
Algorithm 2, the solutions in terms of θi , Si , and [ i ] are tabulated in Table 1.
Initially we start from θ0 = 0 and [ 0 ] = Ø. The algorithm finds the shortest s − t
path in N , which is γ1 = {3, 4, 5, 8, 9}, with a capacity of 3 and length 8. Repeat [ 0 ]
until 8; since [ 0 ] = Ø, none of flows are induced by [ 0 ] until 8. Following Step 2.2.2
and 2.2.4 in Algorithm 2, we add γ1 into [ 0 ] and update residual network. The next
iteration gives another shortest path γ2 = {1, 4, 5, 8, 9}, with capacity 2 and length 11.
Again repeating [ 0 ] until 11, we have 9 units of flow reach the sink along γ1 . As
none of the supply is able to be depleted by time 11, include γ2 in [ 0 ]. Continue the
algorithm until adding γ3 = {3, 6, 8, 9} and γ4 = {3, 6, 9} into [ 0 ], the next shortest

184

J Math Model Algor (2014) 13:169–189

(τ ij , uij )
Fig. 3 Dynamic network in the example

path on the residual network is {1,4,5,7,8,9} with length 20. Suppose repeating
[ 0 ]= {γ1 , γ2 , γ3 , γ4 } until 20, the dynamic flow originated from source s3 computes a
θ (s3 ) = 17.5 < 20. This implies inducing [ 0 ] until 17.5, before the next breakpoint of

20, would deplete the supply in source s3 . Let θ1 = 17.5 and we finalize vmax
(τ ) : τ <
θ1 by inducing [ 0 ] = {γ1 , γ2 , γ3 , γ4 } until 17.5. Update the remaining supply at θ1 ; it
is b (s1 ) = 37, b (s2 ) = 50, and b (s3 ) = 0.
In the next iteration, we discard the residual network and start from N again.
Connect supersource s to sources with positive remaining supply, i.e., {1, 2}. The
algorithm finds the shortest path γ1 = {1, 4, 5, 8, 9} with length 11 and adds γ1 into
Table 1 Solution solved in the example
i

θi

Si

i

τ (γ )

|γ |

{1, 2, 3}

{3, 4, 5, 8, 9}
{1, 4, 5, 8, 9}
{3, 6, 8, 9}
{3, 6, 9}
{1, 4, 5, 8, 9}
{2, 4, 5, 6, 8, 9}
{2, 4, 5, 6, 9}
{2, 4, 7, 8, 9}
{2, 4, 7, 9}
{2, 4, 6, 9}
{1, 4, 5, 8, 9}
{1, 2, 4, 5, 6, 8, 9}
{1, 2, 4, 5, 6, 9}
{1, 2, 4, 7, 8, 9}
{1, 2, 4, 7, 9}

8
11
13
15
11
16
18
18
19
20
11
17
19
19
20

3
2
2
5
5
2
4
5
8
1
5
2
4
5
4

0

0

1

17.5

{1, 2}

2

20.95

{1}

3

21.9375

Ø

J Math Model Algor (2014) 13:169–189
Fig. 4 The amount of earliest
arrival flow solved in the
example

185

160
Arrival flow
At least a source runs empty

140

Arrival Flow

120
100
80
60
40
20
0
6

8

10

12

14

16

18

20

22

24

Time

[ 1 ]. We continue the algorithm and solve the problem, where the result is shown in
Table 1.
 
 
In Table 1, examine γ = {2, 4, 5, 6, 8, 9} ∈  1 and γ  = {1, 2, 4, 5, 6, 9} ∈  2 ,
where τ (γ ) = 16, τ (γ  ) = 19, and arc (5,6) is overlapped by γ and γ  . The final
dynamic flow repeatedly sends γ during [1.5, 4.95) and γ  during [1.95, 2.9375). This
means that the overlapped arc (5,6) (endpoint of the arc) will be occupied by γ until
12.95 and invoked by γ  at 10.95. During η = [10.95, 12.95), the chain flows γ and γ 
are induced together. The value of γ is 2 and γ  is 4, which together is 6 and obeys
the capacity of arc (5,6). In fact, all subpaths from node 6 to sink node 9 that are
shorter than subpath {6, 9} are saturated by [ 2 ] ({1, 2, 4, 5, 6, 8, 9} in [ 2 ] saturates
the subpath {6, 8, 9} which is shorter than {6, 9}). This illustrates how repeatedly
sending flow along an arc that is overlapped by different [ i ] during an overlapped
time window induces a feasible dynamic flow.
The EAF pattern is tabulated in Table 2 and plotted in Fig. 4, where the round
breakpoint stands for finding a new path in the SSP, and the triangular breakpoint
indicates that at least one source depletes its supply. Note that the slope after the
round break point always increasing due to the convexity of oτ (Si ); in a multi-source
EAF the slope may decline afterwards a triangular break point, indicating a reduced
throughput due to a depleted supply. One can verify that the heuristic algorithm
actually solves an exact solution in this example.
4.2 A Real-Life Example
In this section we carry a numerical experiment of the proposed EAF algorithm on a
real-size network—Dallas Fort-Worth network, as shown in Fig. 5. We examine the
solution quality and computational performance of the algorithm.

Table 2 The amount of earliest arrival flow solved in the example
τ

8

11

13

15

17.5

18

19

20

20.95

21.9375

v(τ )

0

9

19

33

63

66.5

82.5

106.5

130.25

150

186

J Math Model Algor (2014) 13:169–189
100

156

116

118

67

130

81

1
19

119

68

82

131

121

69

80

83

70

20

22

3

4

122

85

159

102

151

103

91

144

96

104

24

26

5

6

27

29

65

66

140

145

7

8

92

146

152

99

31

33

141

147

153

155

90

176
30

32

34

35

37

36
72

124

73

86

160

161

106

39

163

164

38
10

9

162

105

107

123

158

25

28

71

101

97

89

84
132

157
98

21

23
120

139

2

165

108

93

177

178

142

148

154

109

94

149

95

110

166

41
167

40
42

125
126

11

74
75

175

76

127

77

133

12

43
44
45

47

46
13

134

48 14

168

143

150

179

49
51
52

50
135

137

111

53

171
54

128

78

87

88

16

15

113

114

112

55

169

56
136
129

79

138

59

57
17

172
58

60

61

63
62

170

18
173
174

64

115
117

Fig. 5 Dallas—fort worth network

The network consists of 180 nodes, 445 arcs and 13 traffic analytic zones (TAZ).
The size of the network, in term of total miles, is about 122 miles. In this network we
have 11 sources and 10 sinks, and total demand of 1,100. To maintain the single sink
network structure we create a supersink and connect all sinks to the supersink.

J Math Model Algor (2014) 13:169–189
Fig. 6 Comparison of the
optimal and approximated
arrival flows

187

1100
1000
900

Arrival Flow

800
700
600
500
400
300
200
Optimal (Earliest) Arrival Flow
Approximated Arrival Flow

100
0
0

20

40

60

80

100

120

Time (Step)

As B-S algorithm involves submodular function optimization, it is not very
practical to be implemented. Baumann and Skutella did not try their algorithm
numerically, because “...although there are fully combinatorial, strongly polynomial
time algorithms for minimizing submodular functions, their implementation would be
intractable. . . ” [36]. For this reason we compare the solution quality of our proposed
algorithm with the one solved by LP. The solutions are plotted in Fig. 6.
It turns out our algorithm obtain the EAF at the beginning time, until around
72 time step, and thereafter, the heuristic algorithm finds an arrival flow lower than
the optimal one. The EAF get cleared at the 97th time step, however, this number is
119.307 obtained by the heuristic algorithm. The optimal objective function is 79,339.
The objective function obtained by the heuristic algorithm is 85,446.65. The error,
measured by the clearance time is about 23 %; measured by the objective function is
around 7.7 %. At the optimal clearance time, the heuristic algorithm successfully
sends nearly 88 % of the total demand to the sink. The results are tabulated in
Table 3.
As to the computational performance, it only takes 0.6 seconds to optimum. In
this numerical experiment we see the computational performance is outstanding.
In the real-life implementation, the computational time of the proposed algorithm
primarily depends on two factors: (1) number of paths found in the SSP algorithm; and (2) number of sources. In this example, both are trivial, thus lead to
a fast running time. Start-of-the-art methods to further improve the shortest path
computations would be a key to improve the computational performance of the
proposed algorithm. More discussion on this topic is beyond the scope of the
paper.

Table 3 Comparison of solutions obtained by the heuristic algorithm
Objective function
Clearance time

Optimal

Heuristic

Error

79,339
97

85,446.65
119.307

7.7 %
23 %

188

J Math Model Algor (2014) 13:169–189

5 Conclusions
In this paper we present a heuristic algorithm for the multi-source EAF problem. It
is an extension of SSP based earliest arrival s–t flow algorithm, which only involves
shortest path computations. The algorithm is pseudopolynomial in the output size.
Compared with prior algorithms, we don’t utilize submodular function optimization
as subroutines, and we solve the EAF pattern and its associated transshipment
simultaneously only on the input network. The algorithm merely explores the static
network flow algorithm on the original input network, via solving the shortest paths
repeatedly.
We also conduct a numerical analysis in an illustrative network, to demonstrate
how the algorithm works. The numerical experiment carried on a real-life network
demonstrates that the algorithm can solve multi-source EAF problem with fairly
good quality, and demonstrates an outstanding run-time performance.
Given the close relation between EAF and SO-DTA on a single sink network,
the proposed algorithm may serve an alternative approach to solve SO-DTA on a
real-life network.
Acknowledgements This research is partially supported by the Arizona Transportation Research
Council at the Arizona Department of Transportation. The authors are thankful to an anonymous
referee for the constructive comments that have improved the presentation of the paper.

References
1. Ford, Jr., L.R., Fulkerson, D.R.: Constructing maximal dynamic flows from static flows. Oper.
Res. 6(3), 419–433 (1958)
2. Aronson, J.E.: A survey of dynamic network flows. Ann. Oper. Res. 20, 1–66 (1989)
3. Bookbinder, J.H., Sethi, S.P.: The dynamic transportation problem: a survey. Nav. Res. Logist.
Q. 27(3), 447–452 (1980)
4. Skutella, M.: An introduction to network flows over time. In: Cook, W.J., Lovasz, L., Vygen, J.
(eds.) Research Trends in Combinatorial Optimization, pp. 451–482. Springer, Berlin Heidelberg
(2008)
5. Fleischer, L., Tardos, E.: Efficient continuous-time dynamic network flow algorithms. Oper. Res.
Lett. 23(3–5), 71–80 (1998)
6. Gale, D.: Transient flows in networks. Mich. Math. J. 6(1), 59–63 (1959)
7. Philpott, A.B.: Continuous time flows in networks. Math. Oper. Res. 15(4), 640–661 (1990)
8. Fleischer, L.K.: Faster algorithms for the quickest transshipment problem. SIAM J. Optim. 12(1),
18–35 (2001)
9. Fleischer, L., Skutella, M.: Quickest flows over time. SIAM J. Comput. 36(5), 1600–1630 (2007)
10. Richardson, D., Tardos, E.: Cited as personal communication in Fleischer, L., Skutella, M. 2007
(2000)
11. Chalmet, L.G., Francis, R.L., Saunders, P.B.: Network models for building evaucation. Manag.
Sci. 28(1), 86–105 (1982)
12. Jarvis, J.J., Ratliff, H.D.: Some equivalent objectives for dynamic network flow problems. Manag.
Sci. 28(1), 106–109 (1982)
13. Hamacher, H.W., Tjandra, S.A.: Mathematical modelling of evacuation problems: a state of art.
In: Schreckenberg, M., Sharma, S.D. (eds.) Pedestrian and Evacuation Dynamics, pp. 227–266.
Springer (2002)
14. Kohler, E., Skutella, M.: Flows over time with load-dependent transit times. In: Proceedings of
the 13th Annual ACM-SIAM Symposium on Discrete Algorithms, pp. 174–183. SIAM (2002)
15. Carey, M., Subrahmanian, E.: An approach to modelling time-varying flows on congested networks. Transp. Res. 34B(3), 157–183 (2000)
16. Ziliaskopoulos, A.K.: A linear programming model for the single destination system optimum
dynamic traffic assignment problem. Transp. Sci. 34(1), 37–49 (2000)
17. Daganzo, C.F.: The cell transmission model: a dynamic representation of highway traffic consistent with the hydrodynamic theory. Transp. Res. 28B(4), 269–287 (1994)

J Math Model Algor (2014) 13:169–189

189

18. Daganzo, C.F.: The cell transmission model part ii: network traffic. Transp. Res. 29B(2), 79–93
(1995)
19. Chiu, Y.-C., Zheng, H., Villalobos, J., Gautam, B.: Modeling no-notice mass evacuation using a
dynamic traffic flow optimization model. IIE Trans. 39(1), 83–94 (2007)
20. Cova, T.J., Johnson, J.P.: A network flow model for lane-based evacuation routing. Transp. Res.
37A, 579–604 (2003)
21. Tuydes, H., Ziliaskopoulos, A.: Network re-design to optimize evacuation contraflow. In:
Proceeding of the 83rd Annual Meeting of the Transportation Research Board (CD-ROM),
Article No. 04-4715(2004)
22. Shen, W., Nie, Y., Zhang, H.M.: Dynamic network simplex method for designing emergency
evacuation plans. Transp. Res. Record 2022, 83–93 (2007)
23. Chiu, Y.-C., Zheng, H.: Real-time mobilization decisions for multi-priority emergency response
resources and evacuation groups: model formulation and solution. Transp. Res. 43E(5), 710–736
(2007)
24. Zheng, H., Chiu, Y.-C.: A network flow algorithm for the cell based single destination system
optimal dynamic traffic assignment problem. Transp. Sci. 45(1), 121–137 (2011)
25. Zheng, H., Chiu, Y.-C., Mirchandani, P.B.: On the system optimal dynamic traffic assignment
and earliest arrival flow problems. Transp. Sci. (2013, in press)
26. Wilkinson, W.L.: An algorithm for universal maximal dynamic flows in a network. Oper. Res.
19(6), 1602–1612 (1971)
27. Minieka, E.: Maximal, lexicographic, and dynamic network flows. Oper. Res. 21(2), 517–527
(1973)
28. Hoppe, B., Tardos, E.: Polynomial time algorithms for some evacuation problems. In: Proceedings of the 5th Annual ACM-SIAM Symposium on Discrete Algorithms, pp. 433–441 (1994)
29. Hajek, B., Ogier, R.G.: Optimal dynamic routing in communication networks with continuous
traffic. Networks 14(3), 457–487 (1984)
30. Rauf, I.: Earliest Arrival Flows with Multiple Sources, Master. Saarland University,
Saarbrücken, Germany, Thesis (2005)
31. Fleischer, L., Skutella, M.: The quickest multicommodity flow problem. In: Proceedings of the
9th Conference on Integer Programming and Combinatorial Optimization, pp. 36–53 (2002)
32. Baumann, N., Skutella, M.: Earliest arrival flows with multiple sources. Math. Oper. Res. 34(2),
499–512 (2009)
33. Hoppe, B., Tardos, E.: The quickest transshipment problem. Math. Oper. Res. 25(1), 36–62
(2000)
34. Burkard, R.E., Dlaska, K., Klinz, B.: The quickest flow problem. ZOR - Methods Models Oper.
Res. 37(1), 31–58 (1993)
35. Zadeh, N.: A bad network problem for the simplex method and other minimum cost flow
algorithms. Math. Program. 5, 255–266 (1973)
36. Baumann, N.: Evacuation by Earliest Arrival Flows. Ph.D. thesis, TU Dortmund, Dortmund,
Germany (2007)

Intelligent Transportation Systems

Editor: Fei-Yue Wang
University of Arizona and
Chinese Academy of Science
feiyue@sie.arizona.edu

RHODES to Intelligent
Transportation Systems
Pitu Mirchandani, University of Arizona
Fei-Yue Wang, University of Arizona and Chinese Academy of Science

E

ver since the major initiatives of the US, Europe, and
Japan in the early 1990s to exploit communication,

control, and computer advances to make transportation
more efficient, reliable, and safe (as embodied in the US
Intelligent Transportation System program), there have
been implicit promises that the implementation will be
soon. You only have to read the various articles on smart
roads, smart vehicles, vehicle telematics, and so on to realize that the promises haven’t yet been kept. For example,
one promise was that, by now, most roads would include
infrastructure allowing communication from a central system to most vehicles. In addition, most vehicles would be
equipped so that through this communication drivers could
obtain route guidance, warnings on lane departures, notification of vehicle malfunctions, and so on.
To be sure, researchers have conducted tests to show the
feasibility of many of the promises, but full-scale deployment is still a ways away. Transportation agencies and automobile companies have realized that maybe they had
promised too much and now have more modest goals and

Editor’s Perspective
The IEEE Technical Activities Board has opened a new chapter in
ITS-related R&D in the history of IEEE communities by elevating the
ITS Council to an IEEE ITS Society. As the president-elect of the ITSS, I
encourage you to participate in our activities through this department and the new society. While work to build the foundations of
ITS technology has significantly accelerated over the last decade,
many fundamental questions remain unanswered regarding ITS
design, modeling, sensing, control, optimization, communication,
architecture, implementation, performance, reliability, and so on.
Nevertheless, there has been a proliferation of ITS methods, techniques, and commercial products, many of which have already been
used successfully in real-world applications. This article summarizes
recent R&D in Advanced Traffic Management Systems at the University of Arizona.
—Fei-Yue Wang

milestones. Even the US Federal Highway Administration’s
latest initiatives, such as the Intelligent Vehicle Initiative
(www.its.dot.gov/ivi/ivi.htm) and Vehicle Infrastructure Integration initiative (www.its.dot.gov/initiatives/initiative9.
htm), have modest goals for the next five to 10 years.
To help fulfill the promises of ITS, the ATLAS (Advanced
Traffic and Logistics Algorithms and Systems—see the
sidebar for more information) research center is developing and testing the RHODES (Real-Time Hierarchical Optimized Distributed Effective System) traffic control system.1 We believe that RHODES will play a major role in the
realization of future Advanced Traffic Management Systems, a major component of ITS.

The future of traffic management
It’s envisioned that future ATMSs will know every vehicle’s location (but not necessarily the identification of the
vehicle or its driver, unless the driver has provided this information for extra services). Also, traffic management
controls and advisories will ensure that vehicles in the network have the smoothest, safest, and most efficient ride
from their origin to their destination.
The controls and advisories will include
• Traffic signals and the phase timings (A set of active
signal lights—for example, north-south green with a
red left-turn arrow and east-west red—is a phase; phase
timing refers to the sequence of phases and each phase’s
time and duration.)
• Roadside or above-road changeable message signs
• Highway advisory radio
• Pretrip information through radio, television, and invehicle navigation systems
• Incident and road work information through radio and
in-vehicle systems
• En route route guidance through in-vehicle systems
ATMSs will obtain traffic information from these
sources:
• Inductive-loop detectors below the road surface

10

1541-1672/05/$20.00 © 2005 IEEE
Published by the IEEE Computer Society

IEEE INTELLIGENT SYSTEMS

ATLAS
The objectives of the Advanced Traffic and Logistics Algorithms and Systems research center are to
• Conduct basic research and system development on advanced
technologies, information systems, and methods for traffic and
logistics management
• Collaborate with agencies and industries and assist in the
study and implementation of the state of the art in traffic
and logistics management systems
• Enhance education and technology transfer activities that
advance the state of the practice in traffic and logistics management
ATLAS collaborates with the US Federal Highway Administration, several state and local transportation agencies, other
universities and research laboratories and institutes (including
some in Europe, Asia, and South America), and many traffic
and transportation companies in the private sector.
ATLAS has conducted research, development, and deployment in
• ATMS components, notably on RHODES, the MILOS (Multiobjec-

• Video detectors over the roads that count
vehicles in defined fields of view
• Other types of detectors such as microwave detectors, infrared detectors, acoustic detectors, and sonar detectors
• In-vehicle automatic vehicle locators that
transmit the vehicle’s location and other
information (for example, some transit
AVL systems provide location, passenger
counts, and schedule adherence)
• Roadside vehicle identification sensors
that read, for example, a permit allowing
a vehicle’s passage in a lane through toll
payment or special permission (for example, HOT lanes on some highways allow a high-occupancy [HO] vehicle free
passage while charging a toll [T] for
single or low-occupancy vehicles)
• Drivers who voluntarily provide information to obtain a service (for example,
route guidance)
RHODES doesn’t yet employ all these controls, advisories, and information sources.
However, its modular architecture will let
us build on the communication-controlcomputer infrastructure to provide additional functions for ITS.

The RHODES system
RHODES takes as input sensor data from
detectors, AVLs, transponders, and so on.
It produces real-time predictions of traffic
flow and “optimally” controls the flow
JANUARY/FEBRUARY 2005

tive Integrated Large-Scale Optimized Ramp-Metering Control System) system for adaptive ramp metering, transit priority methods, wide-area traffic management, and real-time
evacuation management
• Advanced Traveler Information Systems, including SPARTA (see
the sidebar “The Living Laboratory”) and the I-KIOSK for providing bus status and schedules
• Advanced public-transportation systems, including itinerary
planning on the Web, online transit rescheduling, and integrating automatic vehicle location and traffic control for
transit priority
• Intelligent-vehicles research, notably the VISTA (Vehicles with
Intelligent Systems for Transport Automation) program, lane
departure warning, and autopilots
ATLAS is also investigating new technologies and systems such
as aerial data collection and monitoring and pedestrian recognition for traffic-adaptive signal control. In addition, the research
center is developing new methodologies in traffic modeling,
simulation, statistical evaluation, optimization, sensor location,
and real-time algorithms.

System objectives

Decision and control systems
Derived measurements and parameters
(including models and algorithms)

Decision and control
actions

Feedback

Estimation and prediction of state system
(including models and algorithms)

Real traffic system
Sensor data
Figure 1. A feedback control diagram for traffic-adaptive systems.

through the transportation network, using
phase timing.
Traffic-adaptive signal control
Vehicle arrival at a traffic signal is stochastic; vehicles arrive sometimes singly
and sometimes in batches or platoons.
Interarrival times (times between vehicles
or platoons) vary nondeterministically, being affected by time-of-day traffic conditions, the vehicle mix, upstream incidents
and bottlenecks, the mix of driver types
(defined by purpose, socioeconomic and
demographic variables, and driver personality), and the physical layout of the road
and lanes. To be effective, real-time traffic-adaptive signal control must proactively respond to the arrival streams to
www.computer.org/intelligent

minimize vehicle stops and delays as much
as possible.
The feedback control diagram in Figure 1
illustrates an effective traffic-adaptive signal
control system. The sensors monitor the
traffic on the network. Using a traffic model,
the system estimates the current traffic flow
and predicts future traffic flow. Using an optimization algorithm or an optimum-seeking
heuristic, it then determines the best plan or
phase timing to apply for the next control
period. The traffic-adaptive systems being
implemented in the US, Europe, Australia,
and a few Asian countries differ in
• What they assume about traffic flow
patterns
• How they estimate traffic flow
11

Processed
data
Decision
system

Estimation and prediction of queues and arrivals
Raw data

Feedback
and decisions

Sensors, signals, and communication

Bus stop A

Bus stop B

Figure 2. A simplified diagram of RHODES operation.

Network flow control subsystem
Platoon
arrivals
and queues

APRES-NET

REALBAND

Intersection control subsystem
Vehicle
arrivals
and queues

PREDICT

Control algorithms

Turn ratios
Travel times
Discharge
rates
Sensors
Figure 3. The middle and lower levels of the RHODES hierarchical control architecture.

• How they optimize signal phasing
RHODES employs a traffic-adaptive signal
control architecture that
• Decomposes the traffic control problem
into subproblems that are interconnected
hierarchically.
• Predicts traffic flow at appropriate resolution levels (individual vehicles, platoons, transit vehicles, emergency response units, and trains) to enable
proactive control.
• Supports various optimization modules
for solving the subproblems.
• Employs data structure and computation
and communication approaches that allow fast solution of the subproblems.
12

This lets RHODES implement each decision
within an appropriate rolling time horizon
of the corresponding subproblem.
As the main optimization approach,
RHODES uses dynamic programming (DP).
The performance criterion for the DP can
be any provided by the authority responsible for the system, as long as it’s based on
traffic measures of effectiveness (such as
average delays, stops, and throughput).
How RHODES operates
Figure 2 depicts a simplified operational
diagram for RHODES. Basically, the system
carries out two main processes. The first is
estimation and prediction, which takes the
sensor data and estimates the actual flow
www.computer.org/intelligent

profiles in the network and the flows’ subsequent propagation. The second process
involves the decision system, which selects
the phase timing to optimize a given objective function, the optimization being based
on DP and decision trees. Possible objectives include minimizing the average delay
per vehicle, minimizing the average queues
at intersections, and minimizing the number of stops. When the objective function
considers delays, the computation of the
objective function’s value might involve
assigning a weight to each vehicle to reflect
its delay. This weight increases when the
vehicle waits too long in a queue.
The decision system has a hierarchical
control structure. At the highest level is a
dynamic network loading (DNL) model
that captures traffic characteristics that vary
slowly over time. These characteristics pertain to the network geometry (available
routes including road closures, construction, and so on), travel demand (roughly,
the number of people wanting to go from
their origin to their destination), and the
travelers’ typical route selection (for example, choosing routes such that travel times
on a selected set of routes from an origin to
a destination are nearly equal). On the basis
of these characteristics, the system can estimate the load on each particular road segment, in terms of vehicles per hour. These
estimates provide RHODES with prior allocations of green times (times when the traffic
signals are green) for each different demand
pattern and each phase (north-south throughmovement, north-south left turn, east-west
left turn, and so on).
At the middle level, called network flow
control, the system updates the green-time
decisions. At this level, the system measures traffic flow characteristics in terms of
platoons of vehicles and their speeds.
Given the approximate green times, the
intersection control at the lowest level selects the appropriate times for phase changes.
It does this on the basis of observed and predicted arrivals of individual vehicles at each
intersection.
Figure 3 depicts the control structure for
the middle and lower levels. Essentially,
each of these levels contains an estimation
module and a control module. APRES-NET
and PREDICT are estimation modules, and
REALBAND is a control module. The control
algorithms at the intersection control level
are the DP optimization models, such as
the CAPRI (Categorized Arrivals Based
IEEE INTELLIGENT SYSTEMS

30

Delay (seconds/vehicle)

Delay (seconds/vehicle)

35
25
20
15
RHODES
Actuated control

10
5
0
3,000

3,100

3,200

(a)

3,300

3,400

3,500

3,600

Volume (vehicles/hour)

3,700

3,800

3,900

400
350
RHODES
300
Semiactuated control
250
200
150
100
50
0
7,000 8,000 9,000 10,000 11,000 12,000 13,000 14,000

(b)

Offered load (vehicles/hour)

Figure 4. Average vehicle delays versus throughput (vehicle trips per hour): comparing RHODES with (a) actuated control at an
interchange and (b) semiactuated control for a major surface street segment.

Phase Reoptimization at Intersections)
strategy.2–6

RHODES AND ATMS
Each level of RHODES control has potential useful applications in ATMS.
Dynamic network loading
The DNL module hasn’t been fully developed or field tested. However, we’ve
simulated tests of the preliminary models.
Once operational, this module will take as
input all the transportation planning data
(obtainable from planning agencies), such
as daily trips by mode, time of day, and day
of week, from origins to destinations. It will
fuse this data with real-time sensor data to
estimate current traffic patterns. Besides
predictions for lower-level control in RHODES,
this module will provide
• Pretrip and in-vehicle route guidance
• Route advisories for specialized vehicles
such as emergency responders (fire department, police, and ambulances) and
vehicles carrying hazardous materials
• Time-dependent traffic data for better
design of transportation networks
One application of DNL that ATLAS is studying is real-time traffic management for emergency evacuation. Given real-time traffic information and estimates of the population
distribution at the time of the emergency incident (which are available from planners),
this application provides a regional perspective to guide vehicles, in real time, from the
incident location to safe destinations.7
Network flow control
Effectively, the network control level
JANUARY/FEBRUARY 2005

tries to open green bands for the defined
platoons. (In a green band, traffic signals at
a set of consecutive intersections are timed
to be green so that vehicles in the platoon
don’t have to stop at the intersections.) But
two other “clients” of ATMSs require special considerations when using a signalized
network: emergency vehicles and trains.
An emergency vehicle, such as a fire truck
that requires fast, safe passage from its station to the emergency site, can be considered a platoon of one that requires a green
band. The RHODES architecture allows signal optimization so that the emergency vehicle gets the green light while the rest of
the traffic faces minimal delays.
Trains, on the other hand, already have a
preemption authority that makes their signal green regardless of the network traffic
when road-level railroad crossings exist. If
RHODES can obtain advance information on
the train’s movement through crossings, it
can provide green lights for the affected
vehicles so that they’re moved out of the
crossing zones and delayed less. In addition, if changeable-message signs are near
railroad crossings, ATMSs can provide drivers information on alternative routes in
conjunction with the optimized phase timings that RHODES provides.3
Intersection control
Other ATMS clients are buses and other
transit vehicles. When a bus is running late,
it would be appropriate to give it some priority through signalized intersections to decrease its delay while not greatly increasing
other drivers’ delays. The DP optimization
model lets RHODES give a higher weight to a
delayed bus (that is, much higher than that
for a private automobile). This weight apwww.computer.org/intelligent

propriately takes into account trade-offs between bus delays and other vehicle delays in
setting phase durations. Simulation-based
experiments show that we can significantly
reduce bus delays with little effect on traffic
delays on the cross streets (the traffic delay
in the bus’s direction generally decreases).
We’re also planning to field-test how well
RHODES performs with this transit priority.8
If sensors can be designed that detect
pedestrians and bicycles—also ATMS
clients—the intersection control module
will also be able to consider trade-offs
among delays of pedestrians, bicycles,
cars, and buses. ATLAS is developing videobased pedestrian detectors and is planning
to field-test a RHODES version that considers
both pedestrian and vehicular demands.

Testing RHODES
Figure 4a shows typical simulation results.
The figure is from an analysis using a simulation model of a diamond interchange in
Tempe, Arizona. (A diamond interchange is
an interchange between a freeway and a
surface street that looks like a diamond.) It
indicates that RHODES could decrease vehicle
delays compared to well-timed actuated control for the same interchange. (Actuated control slightly increases or decreases a phase
duration on the basis of some logical function of the actuations of the loops just upstream of the intersection.)
Figure 4b compares RHODES with semiactuated control (also called actuated coordinated control) for a major surface street
segment with eight intersections at Tara
Boulevard in Atlanta. RHODES performs
much better than semiactuated control;
average vehicle delays decrease from 50
percent (for low loads) to 30 percent (for
13

The Living Laboratory

high loads). In the high-load case, not only
are the average delays smaller but also the
delay’s variance is significantly reduced,
making movement through the network
more predictable for the driver.
We conducted the first RHODES field test
in Tempe, Arizona, in September 2000.9
Subsequently, we tested it in Seattle in
summer 2002; in Tucson, Arizona, in winter 2002; in Oakville, Canada, in summer
2004; and in Santa Clara, California, in
fall 2004. In most of the tests, RHODES
improved traffic performance; it didn’t hurt
performance in any test (that is, it at least
matched a well-timed system). We plan
more tests, with further enhancement of
RHODES, in Pinellas County, Florida, in
Seattle, and in Houston, Texas. The Chinese Academy of Sciences in Beijing is
also using RHODES to develop the Green14

Pass traffic control and management system for the 2008 Olympics.10 GreenPass
is undergoing field testing in Shandong,
China. In addition, ATLAS is using RHODES
in conjunction with its Living Laboratory
for Transportation Technologies (see the
sidebar “The Living Laboratory”).

R

HODES can provide a strategic road
toward realizing the promise of ITS’s
advanced-traffic-management functions.
Preliminary simulation analyses and field
testing have planted seeds that might eventually produce fruit that will benefit travelers on our congested highways and streets.
Of course, full realization of RHODES’s
potential will require the confidence and
the cooperation of traffic agencies, and

www.computer.org/intelligent

Alvernon Rd.

Country Club Rd.

Tucson Blvd.

Campbell Ave.

Cherry Ave.

Mountain
Ave.

Park Ave.

Euclid/1st Ave.

Howard

An important component of ATLAS (see the other sidebar) is
and peer communications status, providing a rich source of
the Living Laboratory for Transportation Technologies, which
data. With appropriate login permissions, researchers can
lets researchers pretest and post-evaluate technologies and
retrieve this second-by-second information for any time pesystems. Besides typical traffic equipment such as traffic conriod. SPARTA also lets researchers obtain derived measures, such
trollers, traffic signal cabinets, and computers, it includes highas occupancy, lane utilization, volume counts (per lane), phase
speed network connections via optical fiber to the Traffic Oputilization, phase splits (the distribution of green times for a
erations Center in Tucson, Arizona. This lets researchers access
phase), and cycle lengths. (A phase is a set of active signal
near-real-time status information for over 350 intersections in
lights—for example, north-south green with a red left-turn arthe Tucson metropolitan region. A similar connection with the
row and east-west red.) Using Rhodes controller information,
city’s public-transportation operations provides ATLAS real-time
we can also obtain estimated queue lengths and are working
status and position information of all transit fleet vehicles. A
to obtain estimates of travel times for road segments, turn
network of 15 intersections near the University of Arizona has
proportions (the percentage of traffic that goes straight, turns
also been instrumented to provide real-time status informaright, and turns left), and queue discharge rates.
tion, such as second-by-second detector
and signal status, which is available for
research and monitoring. Figure A indiGrant Rd.
cates the intersections that constitute
this network, which are being monitored
Pima/Elm
and tested with the RHODES traffic control
system. (For more on RHODES, see the main
article.)
Speedway Blvd.
This network connectivity has let the
Second St.
laboratory design SPARTA (System for the
Prediction and Analysis of Real-Time TrafATLAS
Third/University
fic on Arterials), a Web-based traffic information system. Each second, SPARTA
updates its database with each intersection’s signal status, active timing plan,
vehicle detector and pedestrian actuaFigure A. The Living Laboratory for Transportation Technologies includes a section of
tions (which occur when a vehicle goes
the transportation network near the University of Arizona that has been instrumented
over an induction-loop detector or a
for testing the RHODES traffic control system. Circles indicate RHODES-controlled
intersections.
pedestrian presses a crosswalk button),

national organizations such as the Federal
Highway Administration will need to convince local agencies that ITS and ATMS
can benefit all citizens.

Acknowledgments
The Federal Highway Administration, the
National Science Foundation (Grant CMS0231458), the Arizona Department of Transportation, and the cities of Tucson and Tempe
have supported this research. This article’s
contents reflect the views of the authors, who
are responsible for the facts and the accuracy
of the data presented herein. The contents
don’t necessarily reflect the official views of
this research’s sponsors. We especially acknowledge Larry Head and David Lucas of
ATLAS for their contributions to RHODES. We
also thank others who have worked on develIEEE INTELLIGENT SYSTEMS

oping RHODES: research colleagues Suvrajeet
Sen (Univ. of Arizona) and Paolo Dell’Olmo
(Univ. of Rome, La Sapienza); former students Steve Shelby and Douglas Gettman;
and Douglas Crawford (Siemens Intelligent
Transportation Systems), Raj Ghaman (Federal Highway Administration), Jim Decker
(City of Tempe), Tim Wolfe (Arizona Dept. of
Transportation), and Sarath Joshua (Maricopa
Assoc. of Governments), who all collaborated
on the field tests.

Pitu Mirchandani is the Salt River Project Professor of Technology,

Public Policy, and Markets at the University of Arizona and has joint
appointments in the university’s Systems & Industrial Engineering
Department and Electrical & Computer Engineering Department.
He’s also the director of the ATLAS (Advanced Traffic and Logistics
Algorithms and Systems) Center at the university. Contact him at the
ATLAS Center, Old Engineering Bldg. 20, Univ. of Arizona, Tucson,
AZ 85721; pitu@sie.arizona.edu.
Fei-Yue Wang is a professor in the University of Arizona’s Systems & Industrial Engineering
Department and the director of the University’s Program for Advanced Research for Complex
Systems. He is also the director of the Intelligent Control and Systems Engineering Center at
the Chinese Academy of Sciences’ Institute of Automation. Contact him at the Systems &
Industrial Eng. Dept., Univ. of Arizona, Tucson, AZ 85721; feiyue@sie.arizona.edu.

References
1. P.B. Mirchandani and K.L. Head, “A RealTime Traffic Signal Control System: Architecture, Algorithms, and Analysis,” Transportation Research Part C, vol. 9, no. 6, 2001,
pp. 415–432.
2. S. Sen and K.L. Head, “Controlled Optimization of Phases at an Intersection,” Transportation Science, vol. 31, no. 1, 1997, pp. 5–17.
3. P.B. Mirchandani and D.E. Lucas, “Integrated
Transit Priority and Rail/Emergency Preemption in Real-Time Traffic Adaptive Signal Control,” J. Intelligent Transportation Systems, vol. 8, no. 2, 2004, pp. 101–115.
4. P. Dell’Olmo and P.B. Mirchandani, “REALBAND: An Approach for Real-Time Coordination of Traffic Flows on a Network,” Transportation Research Record, no. 1,494, 1995,
pp. 106–116.
5. P. Dell’Olmo and P.B. Mirchandani, “A Model
for Real-Time Traffic Coordination Using
Simulation-Based Optimization,” Advanced
Methods in Transportation Analysis, L.
Bianco and P. Toth, eds., Springer-Verlag,
1996, pp. 525–546.
6. K.L. Head, “An Event-Based Short-Term Traffic Flow Prediction Model,” Transportation
Research Record, no. 1,510, 1995, pp. 45–52.
7. P.K.G.R. Rao, Dynamic Traffic Management
Methodology for Flooding Evacuation, MS
thesis, Systems and Industrial Eng. Laboratory, Univ. of Arizona, Tucson, Dec. 2004.
8. P.B. Mirchandani et al., “An Approach
towards the Integration of Bus Priority, Traffic Adaptive Signal Control, and Bus Information/Scheduling Systems,” ComputerAided Scheduling of Public Transport, S. Vos
and J. Daduna, eds., Springer-Verlag, 2001,
pp. 319–334.
9. P.B. Mirchandani and D.E. Lucas, Implementation and Field Testing of RHODES, A
Real-Time Traffic Adaptive Control System,
Final Report FHWA-AZ01-447, Ariz. Dept.
of Transportation, 2001.

portation Systems for the 2008 Olympics,”
IEEE Intelligent Systems, vol. 18, no. 6, 2003,
pp. 8–11.

For more information on this or any other computing topic, please visit our Digital Library at
www.computer.org/publications/dlib.

IEEE Pervasive Computing...
delivers the latest developments
in pervasive, mobile, and
ubiquitous computing. With
content that’s accessible and
useful today, the quarterly
publication acts as a catalyst for
realizing the vision of pervasive
(or ubiquitous) computing Mark
Weiser described more than a
decade ago—the creation of
environments saturated with
computing and wireless
communication yet gracefully
integrated with human users.
Editor in Chief: M. Satyanarayanan
Carnegie Mellon University
Associate EICs: Roy Want, Intel Research;
Tim Kindberg, HP Labs; Gregory Abowd,
Georgia Tech; Nigel Davies, Lancaster University
and Arizona University

UPCOMING ISSUES:
✔ Energy Harvesting and
Conservation
✔ The Smart Phone
✔ Ubiquitous Computing
in Sports

MOBILE AND UBIQUITOUS SYSTEMS

✔ Rapid Prototyping

SUBSCRIBE NOW!
www.computer.org/pervasive/subscribe.htm

10. F.-Y. Wang et al., “Toward Intelligent TransJANUARY/FEBRUARY 2005

www.computer.org/intelligent

15

J Sched (2014) 17:541–567
DOI 10.1007/s10951-013-0339-8

Review of real-time vehicle schedule recovery methods
in transportation services
Monize Sâmara Visentini · Denis Borenstein ·
Jing-Quan Li · Pitu B. Mirchandani

Received: 10 November 2011 / Accepted: 28 June 2013 / Published online: 12 July 2013
© Springer Science+Business Media New York 2013

Abstract This paper presents a comprehensive review on
methods for real-time schedule recovery in transportation
services. The survey concentrates on published research on
recovery of planned schedules in the occurrence of one or
several severe disruptions such as vehicle breakdowns, accidents, and delays. Only vehicle assignment and rescheduling
are reviewed; crew scheduling and passenger logistics problems during disruptions are not. Real-time vehicle schedule recovery problems (RTVSRP) are classified into three
classes: vehicle rescheduling, for road-based services, trainbased rescheduling, and airline schedule recovery problems.
For each class, a classification of the models is presented
based on problem formulations and solution strategies. The
paper concludes that RTVSRP is a challenging problem that
requires quick and good quality solutions to very difficult
and complex situations, involving several different contexts,
restrictions, and objectives. The paper also identifies research
gaps to be investigated in the future, stimulating research in
this area.

M. S. Visentini · D. Borenstein (B)
Management School, Universidade Federal do Rio Grande do Sul,
Porto Alegre, Brazil
e-mail: denisb@ea.ufrgs.br
M. S. Visentini
e-mail: monize.s.visentini@gmail.com
J.-Q. Li
California PATH, University of California, Berkeley,
Berkeley, CA, USA
e-mail: jingquan@path.berkeley.edu
P. B. Mirchandani
School of Computing, Informatics, and Decision Systems Engineering,
Arizona State University, Phoenix, AZ, USA
e-mail: pitu@asu.edu

Keywords
Aircraft

Rescheduling · Recovering · Vehicle · Train ·

1 Introduction
Many optimization-based algorithms have been developed
in the last decades for generating vehicle schedules in transportation services. However, the planned schedules are sometimes disrupted by unforeseen events. Some of these disruptions are severe enough to prevent the system from operating
as planned, such as inclement weather, terrorist events, and
vehicle breakdowns. When these situations occur, rescheduling is approached as a real-time vehicle schedule recovery
problem (RTVSRP). The main objective of this paper is to
review and synthesize the literature on contributions toward
solving such problems for ground and airline transportation
services.
Clausen et al. (2010) classify a disrupted situation where
the deviation from the plan is sufficiently large to impose
a substantial change in operations. Severe weather conditions, accidents, maintenance, and the breakdown of vehicles are the examples of possible disruptions that demand
the rescheduling of vehicles. Disruption data in transportation services are impressive. In 2008, on average 17.67 %
of the Brazilian commercial flights were delayed more than
30 min, and on average 2.67 % were canceled according to
Brazilian Civil Aviation Agency (2010). Similar numbers are
presented by Eggenberg et al. (2010) for European flights.
In the railway sector, Jespersen-Groth et al. (2009) reported
that the Dutch railway network has approximately 17 disruptions per day with an average duration of 1.8 h, 35 % of
them being related to technical failures and 35 % related to
the third parties (e.g., accidents). For transit service examples, San Francisco Municipal Transportation Agency had

123

542

only 71 % bus trips on time from 2007 to 2010 (see http://
www.sfog.us/sfmuni.htm). SunTran transit agency in Tucson, Arizona, had 82 road calls in July 2011 (see SunTran
2011), where small accidents were fixed quickly by drivers,
but some serious accidents led to towing the disabled bus
back to a depot.
The economic impact of disruptions is also significant.
Disruptions introduce additional costs and decrease in service level. Based on data from the Air Transportation of
America, Ball et al. (2007) reported that US$ 6.5 billion
were spent in 2000 by customers and airline companies to
deal with delays. According to Guarino and Firestine (2010)
several snowstorms in the USA during February 2010 generated the greatest proportion of weather-related cancelations
on record, with 4.2 % of all flights being canceled (20,206
flights). These cancelations were estimated to have a cost
of about $80–$100 million. Severe weather has also caused
delays and cancelations in Swedish railways. During the winter of 2010–2011, heavy snowfall and record cold resulted
in approximately four million hours in delays and $372 million in lost working hours (Swedish Transport Administration 2011).
Until recently, real-time vehicle schedule recovery was
exclusively conducted by human schedulers, based on their
experience and common sense. However, the implementation of new information and communication technologies
(e.g., automatic vehicle locaters, the global positioning system, geographical information systems, and wireless communication) in transportation systems and the unprecedented
increase in the capacity of the computers to solve large
instances of problems enables providing real-time information and implement real-time disruption recovery algorithms
at reasonable costs. As a consequence, a growing body of
contributions on several aspects of real-time vehicle schedule recovery in transportation services has appeared in the
operations research and related literature. Indeed, some of
the recently proposed models present increased levels of realism and incorporate a large variety of needed constraints and
operational requirements that have resulted in effective computer algorithms used by transportation/logistic companies.
An interesting alternative to address disruption problems
is to build robustness into the schedule throughout schedule design process. The main idea of robust schedule is to
incorporate the possibility of disruptions during the schedule
design to enhance potential recovery actions, such as adding
buffers or slack time between operations in schedules or having standby vehicles and part-time crews. Ahuja et al. (2009)
present a compilation of papers dealing with robust optimization theory in transportation systems. Robust scheduling is becoming an important topic in transportation services
and several research papers have appeared in the last two
decades on this subject. Huisman et al. (2004), Kramkowski
et al. (2009), and Amberg et al. (2012) deal with robust bus

123

J Sched (2014) 17:541–567

scheduling; Zwaneveld et al. (1996), Zwaneveld et al. (2001),
Fischetti et al. (2009), and Caprara et al. (2010) consider
robust train scheduling; Ageeva (2000), Lan et al. (2006), Lee
et al. (2007), Weide et al. (2009), Borndörfer et al. (2009),
and Dück et al. (2012) address robust aircraft scheduling. As
pointed out by Ahuja et al. (2009) and Clausen et al. (2010),
robust scheduling and real-time vehicle schedule recovery
are tightly coupled problems. The former constitutes a proactive approach, while the latter assumes a reactive approach to
deal with disruptions during operation. This paper is focused
on the real-time vehicle schedule recovery problem.
Another related aspect in the rescheduling context is stability. This term refers to schedules where “there is little
deviation between the pre-[initial] schedule and the executed
schedule” (Leus and Herroelen 2005). Stability should be an
important consideration in the schedule design so that during
rescheduling, perturbations in the initial scheduling are small
(Rangsaritratsamee et al. 2004), so that the costs involved in
the disruption management process are also small. In the
transportation context, stability can be a schedule characteristic that relates to the ability to return to normal operation
after a disturbance occurs (D’Ariano 2008). Although this
term is often used in production management as a rescheduling performance index (Herroelen and Leus 2004; Raheja
and Subramaniam 2002), stability has not been a major consideration due to the complex dynamics of the disruption
management in transportation.
From a modeling point of view, the RTVSRP is modeled
and solved using similar models, but not the same, as their offline planning counterparts. In general, an underlying network
structure representing the problem is designed. This network
representation describes how vehicles can be rescheduled,
taking into consideration the current planned schedule, the
current situation when the disruption occurred, and technical
and timing constraints. Based on the network representation,
optimization- and heuristic-based methods are developed.
The most important modeling difference between the realtime recovery problem and the schedule planning problem is
that the underlying network is dependent on the existing situation and feasible alternatives to address the disruption. As
the number of alternatives increases, the complexity of the
problem increases exponentially. Clearly, the RTVSRP also
differs with the industry. In the airline industry, the problem
is characterized by the high costs involved and the highly regulated environment. In bus public transportation services, the
number of alternatives to recover the disruptions is extremely
large when the transportation systems of large cities are considered. In the railway sector, the sharing of some resources
(tracks) is critical in its operations, and additional technical constraints demand the introduction of several new features in the modeling approaches. However, schedule recovery requires solutions to be provided very quickly. The main
challenge for the scheduling researchers is to develop pow-

J Sched (2014) 17:541–567

erful and robust algorithms for quickly solving these large
and complex problems.
This paper reviews most of the recent contributions dealing with RTVSRP regarding both airline and ground transportation. We have emphasized textual description, given the
heterogeneity of formulations and models presented in the
literature. Most of the formulations reviewed have been proposed in the last decade. This survey mostly focuses on papers
in OR-oriented journals. Also, the authors limit this survey to
vehicle rescheduling. Crew scheduling and passenger logistics problems during disruption are not reviewed and even
though many studies in these areas are certainly relevant to
the real-time disruption management. The paper does not
review vessel schedule recovery problems, since there is little reported research on this problem. An exception is the
work of Dirksen (2011) which presents mathematical models for disruption in shipping inspired by developments for
the aircraft schedule recovery problem. For a deeper understanding on ship routing and scheduling see the survey by
Christiansen et al. (2004).
The paper is organized as follows. Section 2 discusses the
general concepts for the real-time schedule recovery problem, including general definitions and network structures
developed to solve the problem. Sections 3, 4, and 5 survey
the vehicle rescheduling problem (VRSP) for bus/freight services, the rescheduling of train services after disruptions, and
the aircraft rescheduling problems, respectively. Section 6
presents some concluding remarks, focusing on similarities and differences among road, railway, and aircraft-based
transportation. The paper ends presenting some directions
for further research.

2 Basic models and problem formulations
Real-time vehicle schedule recovery problem can be stated as
follows. Given a set of depots (or stations), a set of vehicles,
and a series of trips with fixed starting and ending times or
with service time windows, given the travel times between all
pairs of locations, given a serious disruption that interrupts
at least one currently scheduled trip and given the current
location and the current status of the vehicles in the system,
find a feasible schedule that optimizes a set of (sometimes
conflicting) objectives, in which trips are either rescheduled
(some with delays) or canceled, and each vehicle performs a
feasible sequence of trips (or track segments, in the case of
trains). When the vehicles are buses or trucks, the problem
will be referred to as vehicle rescheduling problem (VRSP).
When the vehicle is a train, the problem will be called train
rescheduling problem (TRP). Finally, when the vehicle is
an airplane, the problem will be called aircraft rescheduling
problem (ARP).

543

A very important aspect in the rescheduling process is the
strategy used. Based on the literature (Acuna-Agost et al.
2011; Ionescu et al. 2010), it is possible to identify three
rescheduling strategies: dynamic, predictive (also called offline), and reactive (also called on-line). In dynamic strategy,
trains are dispatched using local information with a decentralized control method based on rules. The strategy is widely
used by human schedulers, since it is easy to implement and
offer solutions very quickly. Predictive schedules are generated within robust scheduling contexts, where the main
objective is to generate schedules able to deal with minor
disturbances. In such situation, all disruptions and scenarios
are known in advance. Reactive strategies consist on finding
a new schedule after the occurrence of one or several events,
including severe disruptions, minimizing some measure of
the effects. This strategy is based on an accurate monitoring of the resources involved, in terms of capacity, position,
and speed. New schedules are generated in real-time. Ionescu
et al. (2010) compared these strategies for the airline recovery problem using data from an European airline. Two criteria were used to evaluate them: punctuality of flight arrival
and run-time efficiency. The dynamic strategy, as expected,
offered poor solutions very quickly. They also concluded that
the offline approach, although more efficient, is not a practicable recovery technique in comparison with the online strategy, although it provides a theoretical lower bound for the
recovery problem.
Since all classes of RTVSRPs are strongly related to the
counterpart schedule planning problems, they are usually formulated and solved using similar, but not identical network
models. In these problems, the network will be referred to as
the underlying recovery network. Based on such networks,
mathematical formulations and solution methods are developed and tested.
The main purpose of the underlying recovery network is to
represent all possible alternatives for rescheduling. The definition of the network is dependent on the pre-assigned configuration of the system when a disruption occurs, the status
of the vehicles in the system, and the times needed to perform
compatible sequences of trips (flight legs in the airline context; track segments in the railway context). As identified by
Clausen et al. (2010), the literature on airline recovery generally uses three types of network representations; namely,
connection networks (CNs), time-line networks (TLN), and
time-band networks (TBN). CNs are activity-on-node networks, where nodes represent trips, stations, airports, etc.,
and the arcs describe connections between the nodes, representing, for example, deadheading. Each path of a source to
a sink refers to a feasible sequence of a trip for a vehicle.
CNs are widely used in planning schedules and their application to recovery problems is quite natural. Examples of
CNs abound in the literature (see Freling et al. 2001; Bertsimas and Patterson 2000, and Li et al. 2004). The other

123

544
Table 1 Hypothetical train
scheduling

J Sched (2014) 17:541–567

Trains

Train
number

Station of
origin

Station of
destination

Train
departure

Train
arrival

Travel
time

Train A

01

LED

SHL

17:00

18:30

1:30

02

SHL

LED

19:00

20:30

1:30

11

HFD

NVP

16:20

17:10

0.50

12

NVP

HFD

17:20

18:20

1:00

13

HFD

NVP

19:00

20:00

1:00

14

NVP

HFD

20:15

21:15

1:00

31

SHL

HFD

15:10

16:10

1:00

32

HFD

LED

16:30

17:10

0:40

33

LED

HFD

17:30

18:10

0:40

34

HFD

SHL

18:50

20:00

1:10

Train B

Train C

Fig. 1 The time-line network
of the sample schedule (based
on Clausen et al. 2010)

15 h

16 h

17 h

18 h

19 h

20 h

21 h

SHL
02

31

HFD

34
11

13

32
01

LED

NVP

two network types have their main applications in recovery problems. TLN are activity-on-edge networks, in which
all events (represented in the nodes) of a resource (such as
station, airport, and track segments) are placed on a timeline corresponding to that resource. Arcs connect events in
the same time-line (which involves the same resource) or in
different time-lines (when different resources are involved).
TBN were developed by Argüello et al. (1997) to specifically
deal with aircraft recovery. They are networks positioned
with respect to two-dimensional axes, one representing time
and the other one space or stations. A node placed in this
space represents specific activities at a station during a segment of time. Arcs represent arrival to or departures from a
station if they are directed into a node or originated from a
node, respectively. In order to illustrate these networks, we
use a hypothetical example, with four Netherland train stations, as follows: Schiphol (SHL), Hoofddorp (HFD), Leiden (LED), and Niew Vennep (NVP), and three trains, which
stop at each station for a period for passenger embarking and
disembarking, and cleaning activities. Table 1 presents the
trains’ timetable. Figures 1, 2, and 3 show the TLN, TBN,
and CNs, respectively, for this sample schedule. The TBN
represents a network that can be constructed dynamically as

123

33

12

14

disruptions occur. For the hypothetical example of Table 1,
suppose that train C becomes out of service from 15:00 to
22:00 for unplanned maintenance. We defined the time-bands
to be around 30 min. Figure 2 shows not all, but some of the
possible new schedules for the two remaining trains, one
starting in LED and the other one in HFD; and ending in
either LED or HFD. In Fig. 2, an illustrative case for a recovery rotation for train B is SHL-31-11 (delayed 40 min)—
12 (delayed 70 min)—34 (delayed 70 min)—SHL for which
the complete path is SHL (source)—HFD—NVP—HFD—
SHL—SHL (sink).
Considering these network models, the RTVSRP has
been formulated based on the classical network problem
formulations such as the minimum cost flow problem, the
multi-commodity network flow, and the set packing problem; by adding some binary variables, together with constraints representing problems peculiarities, and expanding
the objective function to include delay and cancelation costs
(Clausen et al. 2010; Törnquist 2006). The literature does
not present a generic formulation for this problem, given the
heterogeneity of contexts where this problem can be applied
both in terms of the disruption and the attendant recovery
decisions. However, based on the models available in the lit-

J Sched (2014) 17:541–567

545

Fig. 2 A partial time-band
network of the sample schedule
(based on Clausen et al. 2010)

SHL

HFD

LED

NVP

15:10

15:00
15:30

31

16:00
16:30

17:00

17:00

17:00
17:30

11

18:00
18:30
19:00

18:40

18:30
12

19:00

19:30
20:00

20:00
34
20:40

20:30
21:00
21:30

21:30
21:40

21:40

22:00
22:30

22:30

23:00

23:00
23:30
00:00

Train A
Fig. 3 The connection network
of the sample schedule (based
on Clausen et al. 2010)

Train B
14

LED

LED
01

31
13

SHL

SHL
32
02

34

HFD

HFD
12
33
11

NVP

erature, it is possible to formulate a generic model for the
RTVSRP based on a CN, where the nodes are represented
by trips, and the arcs connect two compatible pair of trips.
Trips i and j are a compatible pair of trips if the same vehicle
can reach the starting point of trip j after it finishes trip i and
the vehicle has technical and capacity attributes to perform
both the trips. It should be noted that several relevant aspects
found in real-world rescheduling problems are missing in
this representation. Peculiarities found in the train rescheduling problem, such as the sharing of uni- or bi-directional
tracks in a single or double line or the slot sharing at airports

NVP

in the context of ARP, are for now intentionally excluded
for the sake of generality for the three classes of problems.
The main objective now for introducing the underlying CN
is to explicitly illustrate the main constraints involved in a
large fraction of instances of the problems described in the
literature.
Before giving the formulation, we introduce the following
notation:
Bi = prescribed starting time of trip i.
Wi = prescribed time of trip i.

123

546

J Sched (2014) 17:541–567

Tij = travel time from the ending point of trip i to the
starting time of trip j.
Di = maximum delay allowed for trip i.
U = service time at station.
Pi = trip i delay cost.
Ci = trip i cancelation cost.
F = time of the disruption.
Let A be the set of trips that are being served by vehicles
at the instant of a trip disruption. Let N denote the set of all
future service trips, including the disrupted trip (which still
needs to be served), numbered according to non-decreasing
starting times. Trips in set N might be re-assigned to different
vehicles from their pre-assigned ones in the initial schedule,
while trips in set A cannot be reassigned. Set A ∪ B can be
seen as the set of all unfinished trips. Let Z denote the set
of all compatible pair of trips (i, j), in which j starts after
F. Assume that each vehicle k ∈ K in the network can be
rescheduled at time F. In reality, this number could be much
smaller than the number of vehicles in the system because
technical and capacity constraints, as well as the position of
the vehicles in the network in time F, will limit this number.
The model has three sets of decision variables, sti , the starting
time of trip i ∈ A ∪ B and two binary ones, namely xijk and
z i , where xijk = 1 if vehicle k ∈ K is assigned to trip j ∈ N
directly after trip i ∈ A ∪ B, and z i = 1 if service trip i ∈ N is
canceled. Thus the RTVSRP can be formulated as follows:


 
cijk xijk +
Ci z i +
Pi (sti − Bi ) (1)
Min
(k∈K ) (i,j)∈Z

(i∈N )

subject to


xijk =
xjik
j:(i,j)∈N



(i∈N )

∀i ∈ N , k ∈ K

(2)

j:(i,j)∈N



xijk + z i = 1

∀i ∈ N

(3)

(k∈K ) j:(i,j)∈Z

sti = Bi

∀i ∈ A

(4)

sti ≥ Bi

, ∀i ∈ N

(5)

∀i ∈ N
sti ≤ Bi + Di


stj ≥ sti + U + Tij xijk
xijk ∈ {0, 1}

(6)
∀ (i, j) ∈ Z , k ∈ K

∀ (i, j) ∈ Z , k ∈ K

sti ≥ 0, z i ∈ {0, 1}

∀i ∈ A ∪ B

(7)
(8)
(9)

where cijk is the distance-based cost of arc (i, j) by vehicle k to
perform trips i and j. This cijk could take into account aspects
such as fixed and operation costs of vehicle k (applicable
mostly for airplanes and trains), distance traveled, and penalties due to rescheduling. The objective function (1) minimizes the weighted sum of operations, delay, penalty, and
trip cancelation costs. Constraints (2) guarantee flow conservation for vehicles. Constraints (3) assure that any trip i ∈ N

123

is either serviced or canceled. Constraints (4) set the starting
time of trips in A as the prescribed starting time, since they
cannot be rescheduled. Constraints (5) and (6) guarantee that
the starting time of any trip i ∈ N is not earlier than its prescribed starting time and does not exceed its delay limit. Constraints (7) establish that the starting time of each future trip
j ∈ N is dependent on the required deadheading (traveling
plus unloading) times of its previous trip i ∈ N . Constraints
(7) are nonlinear. Li et al. (2008) has showed that this term
can be easy linearized using the big-M technique. Constraints
(8)–(9) define the domain of the decision variables.
The RTVRSP has also been formulated and solved based
on models and methods developed for the real-time schedule recovery of machines (Raheja and Subramaniam 2002),
mainly in the railway transportation. Vehicles can be viewed
as jobs, and trips or block segments (in railway context) as
machines. The processing of a job by a machine for a given
amount of time, characterizing an operation, corresponds to
the allocation of a vehicle to a trip. Each operation can be
processed by only one machine, in the manufacturing context, and a trip can only be allocated to a vehicle in the transportation area. Machine breakdowns and delay in operations
can be approached as vehicle breakdowns and trip delays,
respectively. Based on these similarities, the TRP was formulated as a job shop problem with additional constraints
(Sahin 1999; D’Ariano et al. 2007a; D’Ariano et al. 2008).
The most interesting additional constrain is the so-called
blocking constraint. While in the machine context, infinite
buffer capacity can be considered between two consecutive
machines, this is not the case in transportation. However, the
real-time machine recovery problem presents some peculiarities, such as the possibility of changes in the routes of jobs
and flexible machines. As a result, this problem is very difficult to solve optimally, given the large number of alternative
solutions, even for a very small number of machines and
jobs. The real-time machine recovery has been solved using
mainly heuristic procedures, based on artificial intelligence
techniques, and simulation. As a consequence, the real-time
machine recovery methods and techniques are having little impact on road vehicles and aircraft recovery problems,
where optimization-based methods prevail.
The complexity of the problem is related to the number
of rescheduling alternatives currently assigned trips, viewed
as binary variables in a mathematical programming formulation. The difficulty of solving integer programming problems with a large number of variables is well known. The
literature presents complexity analysis for some classes or
subclasses of the RTVSRP. Li et al. (2009) showed that the
VRSP is an NP-hard problem. Corman et al. (2010) demonstrated that the train conflict detection and resolution (CDR),
a sub-class of the TRP, is NP-complete, while Berger et al.
(2011b) proved that the online railway delay management
(ORDM) problem is PSPACE-hard (Arora and Barak 2009).

J Sched (2014) 17:541–567

547

Fig. 4 Scheduling and
disruption decision-making
process (Li et al. 2007a)

Concerning the aircraft rescheduling problem, Liu et al.
(2008) and Babić et al. (2010) showed that the problem is
NP-hard for multi-fleet scheduling, while Luo and Yu (1997)
showed the NP-hardness of the problem when ground delay
is the considered disruption.
The most important aspect of the RTVSRP is the dynamic
environment in which the rescheduling process has to take
place. That is, while the rescheduling is being performed, the
status of the transportation system is changing at the same
time. As a consequence, to be used in the real-world, the
RTVSRP requires quick solutions. Since the rescheduling
problems that have to be solved are large and complex, the
realization of short computation times for exact rescheduling algorithms is still a large scientific challenge (Kroon and
Huisman 2011). The next sections discuss how these challenges have been addressed in the RTVSRP for ground services, trains, and airlines.

3 Schedule recovery for road–vehicle services
In this section, we focus on rescheduling of transportation
services that operate vehicles on roads and streets, for example bus services and pick-up and delivery services, when the
availability of vehicles decreases due an unforeseen event
such as a vehicle breakdown. The VRSP can be approached
as a dynamic version of the classical vehicle scheduling problem (VSP) except now assignments are generated dynamically. Real-time rescheduling tools should be very useful in
helping decision-makers in disruption situations, especially
when fleet size is limited, but, unfortunately the numbers
of companies/agencies that use computerized rescheduling
algorithms for generating new candidate schedules are few,

since most of them reschedule vehicles are based solely on
the experience of a human scheduler.
This section is divided into two parts: (i) in the first subsection the vehicle rescheduling context and recovery decision
process are discussed, and (ii) in the second, schedule recovery models and solution approaches are discussed.
3.1 Rescheduling context and decision process
The VRSP arises in the operation context of a bus/truck transportation system when a previously assigned trip is seriously
disrupted. Such problem involves the dynamic rescheduling of the fleet, ensuring that all previously scheduled trips
are either completed in a reasonable amount of time or canceled. Traffic accidents, medical emergencies, and vehicle
breakdowns are examples of possible disruptions that require
vehicle rescheduling. Instances of VRSP happen in applications such as school bus transportation, public transit services, industrial/hospital refuse collection, mail delivery, etc.
Li et al. (2007b) presented a decision diagram showing the interactions between schedule planning, disruption
decision-making processes, and rescheduling (Fig. 4). First,
the scheduling process can be characterized as the classical
single-depot VSP (SDVSP) when only one depot is involved
(otherwise it is the multi-depot version). Second, the severity
of disruption is defined by the experience of human schedulers. Small disruptions usually need few adjustments and, in
general, the initial schedule is not changed by much. Otherwise, when the disruptions are larger, this initial schedule is
used as a basis for rescheduling the remaining unfinished and
future trips; then the current schedule could change substantially. We notice that, in order to develop a rescheduling decision support, information technology is essential to capture

123

548

information on disruptions, such as time and place disruption,
number of passengers or vehicle cargo size, and subsequently
to quickly compute and communicate new candidate schedules. Much of this schedule recovery process applies also to
the other two domains reviewed in the paper—rescheduling
of trains and planes.
3.2 Vehicle rescheduling models
Bunte and Kliewer (2009) presented a comprehensive
overview on vehicle scheduling models and found that much
research has been done on it in the last decades, but considerations on vehicle rescheduling are still relatively unexplored.
Major contributions toward solving VRSP are found in Huisman et al. (2004) and Li et al. (2004).
Huisman et al. (2004) considered an environment with
significant traffic jams and developed a cluster-reschedule
heuristic to solve what they called a “dynamic” VSP problem.
The “dynamic” aspect was mainly related to delays in the previously assigned trips. The problem formulation was based
on the multi-depot VSP (MDVSP) and solved as a sequence
of optimization problems. First, trips were clustered using the
static VSP, and then rescheduled for each depot. Real data of
a public transport company was used to test their approach.
The results indicated that the number of trips starting late
was reduced at the price of using a few extra vehicles. In a
later paper, Huisman and Wagelmans (2006) integrated the
dynamic VSP with crew scheduling, solving the integrated
system dynamically. Two algorithms were developed. The
first one uses a sequential approach (first schedule vehicles
and then schedule crews); the other uses what the author
called an “integrated approach.” The integrated approach
consists of solving a sequence of integrated vehicle and crew
scheduling problems, formulated as binary linear programs.
Historical data from a large bus company in the Netherlands
for a period of 10 days were used for some computational
tests. Two problem sizes were tested: a small single-depot
(164 trips) instance and a medium-sized multiple-depot (304
trips) instance. The integrated approach significantly outperformed the sequential approach for the larger problems; for
the smaller problems, the performances were not that different. A limitation of the integrated approach is that computation times may be too high for practical real-time operations.
In Huisman’s papers, delays on trips due to disruptions
were the major considerations in their predictive rescheduling strategies. A different approach is taken by Li et al.
(2004), which considers disruptions due to vehicle breakdowns or severe vehicle accidents for schedule recovery,
introducing the reactive strategy for this problem class. The
problem is modeled as several VSPs, each one corresponding
to the use of a different vehicle as an alternative for backing
up the disrupted trip. Each backup vehicle k ∈ K generates a
CN, G(k), referred as a feasible network. The paper describes

123

J Sched (2014) 17:541–567

an algorithm to find all possible backup vehicles for a serious
disruption, considering the peculiarities of the transportation
service being addressed, for example, bus routes may partly
share the same itinerary. In order to solve the problem, a
parallel auction algorithm has been developed. The parallel
algorithm has proven to be computationally efficient in random generated instances up to 1,300 trips. Li et al. (2007a)
improved the solution time of the parallel auction algorithm
by introducing the common feasible network (CFN) notion.
The CFN can be obtained from the intersection of all possible feasible networks as follows: C F N = ∩k∈K G(k). The
idea is to find a good set of initial “prices” using the CFN,
characterizing a better initial assignment, to speed up the auction algorithm. The algorithm performs well for a large number of trips and vehicles. However, the modeling approach
was based on the following two restrictive assumptions: (i)
rescheduled trips, except the disrupted trip, cannot suffer
delays; and (ii) there are no restrictions on the number of
trips that may be reassigned. In practice, these assumptions
reduce the size of the problem, restricting the number of possible rescheduling alternatives.
In order to minimize the restrictive assumptions involving auction-based algorithm, Li et al. (2009) developed a
Lagrangian heuristic approach for the VRSP. The heuristic
approach incorporates Lagrangian relaxation, a sub-gradient
search and an insertion-based primal heuristic. The developed formulation expands the applicability of the model by
simultaneously taking into account the previously neglected
real-world aspects such as reducing trip cancelation costs,
and decreasing the number of rescheduled trips (toward facilitating the crew rescheduling, since several bus crews will be
familiar with the complete itinerary of a subset of all possible
trips). Li et al. (2009) observed that the Lagrangian heuristic
did not demonstrate many improvements in situations where
a large number of remaining trips exist, when a backup vehicle is available at the depot, or when the vehicle breaks down
at the beginning of the disrupted trip.
The importance of rescheduling in practice was also
recognized by Li et al. (2007b, 2008). In Li et al. (2007b)
a decision support system (DSS) was developed to facilitate a practical application for rescheduling trucks for solid
waste collection in a Brazilian city. The approach helps to
solve the complex problem of recovery from severely disrupted trips, minimizing the involved disruption costs. The
SDVRSP was treated as a sequence of SDVSPs. A quasiassignment formulation and a combined forward–backward
auction algorithm were used to model and solve, respectively, the SDVSPs within the DSS. CPLEX was used to
solve computational experiments with randomly generated
data. The results indicated that the DSS has potential as an
effective and efficient tool for real-time operational planning
in transportation/logistic companies. In a following paper,
Li et al. (2008) proposes a nonlinear programming formula-

J Sched (2014) 17:541–567

tion for the waste-collection problem, minimizing not only
disruption costs, but also trip delays. The big-M technique
was used to linearize the formulation, simplifying its solution. The main objective of the model was to minimize the
sum of operation costs, fixed vehicle costs and delay costs,
under the conditions that all incomplete trips have to be finished (including the disrupted one), and trip assignments into
waste-recycling facilities were balanced. In that paper, each
vehicle operating in the network at the time of the disruption could be considered as a pseudo-depot with unit capacity, making the mathematical formulation now being based
on the MDVSP. Experiments based on real-world data were
carried out using CPLEX as the commercial solver, since the
instances used were small, consisting of 23 vehicles and 31
trips. The developed model decreased both the total distance
traveled and total trip delay when comparing with the manual
recovery strategy used by the company.
Ernst et al. (2007) developed a software to solve the
dynamic scheduling of vehicles, referred to as the Dynamic
Vehicle Assignment and Scheduling System (D-VASS), assisting a large New Zealander recreational-vehicle-rental company in its daily operations. The main purpose of D-VASS
was to respond to availability queries by reservation staff
and to incorporate new bookings into the schedule. It also
adjusted the schedule in response to operational contingencies, like vehicle breakdowns and late returns. D-VASS
applies a heuristic improvement method based on the successive shortest path for solving the assignment problem and
perform updates as quickly as possible. The model only considered the beginning and end data of a trip, but did not consider important information like the place and time that the
vehicle suffers the disruption; also public transport applications were not considered.
Table 2 summarizes the reviewed literature and highlights some attributes of interest in the developed models.
In sum mary, the models, formulations, and solution procedures developed for the VRSPs are much related to their
static counterpart, mostly using the connection network as
the representation of the problem, and the MDVSP solution
methods as inspiration for the design of algorithms for the real
problems. The applications of VRSP include the scheduling
of buses, trucks, and rental vehicles (Ernst et al. 2007). The
computational experiences reported include some large problem instances, up to 1,300 unfinished trips when a disruption
occurs.
4 Rescheduling train services during disruptions
Rail transportation provides services for passenger traffic
and freight shipping. However, train scheduling is a difficult
problem primarily due to its size and the significant interdependencies between the train movements and operational
constraints.

549

4.1 Train rescheduling considerations
Jespersen-Groth et al. (2009) noted that trains do not always
run on time due to unexpected events like infrastructure malfunctions, rolling stock break downs, accidents, and weather
conditions. The so-called “snow ball effect” (that is a deviation from the planned operations of a train which can
have a cascading effect on several other trains’ operations
in the surrounding traffic area due to sharing of physical
resources, such as tracks and stations) is a major complexity in train rescheduling. The compounding factors include
(Acuna-Agost et al. 2011; Tornquist and Persson 2007):
a. Trains cannot share the same track in opposite directions
at the same time. To avoid collisions, railway networks
are often composed of blocks, which are track sections
that can be used by at most one train at a time due to safety
restrictions. The lengths of block segments are variable
and are dependent on traffic density. To increase safety,
a buffer space of one or two blocks between two trains is
exerted by several train control systems;
b. There is a much diversity in railway infrastructure; some
blocks are single-tracked, others are double-tracked or
even n-tracked;
c. The train traffic is quite heterogeneous; heavy cargo trains
share tracks with passenger trains;
d. There are minimum and maximum idle times of trains
at each station. Although these values can be changed in
case of a disruption, it can cause itinerary problems to
passengers.
For more details on the constraints related to train scheduling refer to Cordeau et al. (1998) and Jespersen-Groth et al.
(2009).
The TRP consists in defining a new re-allocation of trains
to blocks, modifying the original timetable while respecting all the required technical and commercial constraints and
(usually) attempting to minimize the total train (or passenger)
delay. In addition, given the real-time aspect of the problem,
the new schedule has to be consistent with the current state
of the system and has to be generated very quickly, since
the solution must take into consideration that some trains are
already delayed at the moment, the new schedule is implemented (Acuna-Agost et al. 2011).
Jespersen-Groth et al. (2009) introduced a schematic view
of the train disruption management process (see Fig. 5). The
process can be briefly summarized as follows: when a disruption occurs, the Network Traffic Control (NTC) needs to
decide about the final dispatching plan for all trains in the network and communicate it to the Local Traffic Control (LTC)
and to the operators. The LTC has to implement the new
train routes and to change platform assignments, accordingly.

123

123

Problem
definition

Dynamic
vehicle
scheduling

Vehicle
rescheduling

Dynamic
vehicle and
crew
scheduling

Vehicle
rescheduling

Vehicle
rescheduling

Vehicle
rescheduling

Vehicle
rescheduling

Vehicle
rescheduling

Authors

Huisman
et al.
(2004)

Li et al.
(2004)

Huisman and
Wagelmans
(2006)

Li et al.
(2007a)

Li et al.
(2007b)

Ernst et al.
(2007)

Li et al.
(2008)

Li et al.
(2009)

Reduce the
number of
trips
starting late
and the
delay costs
Minimize
operating
and delay
costs
Minimize
the total
sum of
vehicle,
delays,
and crew
costs
Minimize
operating
and delay
costs
Minimize
operating
and delay
costs
Minimize
total
costs
Minimize
operating
and delay
costs
Minimize
total
costs

Objective

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

Delay Vehicle
Cancel
breakdown

Bus Truck Rental
vehicles

x

x

x

Passenger
connection

Functionality

Dynamic context

Vehicle

Table 2 Summary of reviewed truck and bus rescheduling problems

x

Crew
scheduling

1,300
remaining
trips

31 trips

4,000
vehicles

1,300
remaining
trips

1,300
remaining
trips

304 trips

1,300
remaining
trips

1,104 trips

Maximum
instances

No

Yes

Yes

Yes

No

Yes

No

Yes

Real-life
data

Strategy

Connection Predictive

Connection Reactive

Connection Predictive

Feasible
network

Lagrangian
heuristic

Shortestpath
method
B&B

Reactive

Connection Reactive

Connection Reactive

Time-line

Connection Reactive
Sequential/
parallel
auction
algorithm
Auction-based Connection Reactive
algorithm

Column
generation

Parallel
auction
algorithm

Clusterreschedule
heuristic

Solution
method

550
J Sched (2014) 17:541–567

J Sched (2014) 17:541–567

551

Fig. 5 Train disruption
management (Jespersen-Groth
et al. 2009)

The Network Operations Control (NOC) monitors and modifies the rolling stock and crew scheduling based on the new
train routes. The Local Operations Level coordinates the local
activities at the stations, such as the shunting processes.
Until recently, the TRP was solved manually, evaluating
a limited number of possible corrective actions of reordering and/or rerouting trains. The increased capacities and
speeds of computational resources available and the recent
advances on solving large integer linear programming problems have resulted in algorithmic-based decision support that
quickly gives better solutions. The next section will briefly
discuss some of these TRP solution methods. Since railway
crew rescheduling problem is beyond the scope of this review
paper, we refer to Potthoff et al. (2010) and Veelenturf et al.
(2012) for this related topic.
4.2 Train rescheduling models
Törnquist (2006) has presented an overview of research on
train scheduling and dispatching. Of the reviewed 48 articles,
published between 1973 and 2005, 21 dealt with rescheduling. The major objective of the reviewed models was the minimization of the total delay. Some small variations, like the
introduction of weights to emphasize the delay of some trains,
are also addressed. The reader is referred to Törnquist (2006)
for a pre-2005 review of train rescheduling; this review
focuses on train rescheduling work reported after 2005.
Different infrastructure representations have been addressed, including lines and general networks, bidirectional or
unidirectional tracks, parallel tracks, etc. In general, the most
complex models cannot deal efficiently with more than 30
trains. Table 3 presents a summary of the main characteristics

of the reviewed papers. Unlike the VRSP, which usually relies
on mathematical programming solution approaches, TRP
methods reported include a greater variety of approaches.
Improvement heuristics, construction heuristics, and simulation have been used as alternative methods to find good
solutions in reasonable time, which are justified due to the
complexity of the real-world TRPs. An interesting aspect of
contemporary literature on the TRP is that almost all papers
present experimental evaluations with real-data, demonstrating the applicability of the developed tools.
Tornquist and Persson (2007) developed an interesting
mathematical formulation for the rescheduling of n-tracked
railway traffic. The railway network studied included several
merging and crossing points. The problem was formulated as
a mixed-integer linear program (MILP), based on an eventdriven representation of time, and solved using CPLEX 8.0.
An event was defined as the conditional resource request by a
train for a segment of a track. Two alternative objective functions have been considered: minimize the total final delay of
traffic, and minimize the total costs associated with delays
of trains at the final destinations. Since the authors noticed
that only few modifications in the initial timetable were necessary to obtain a good solution, different strategies, such as
“allow swaps of tracks but maintain order,” were evaluated
on large practical size problems. The solution approaches,
based on different strategies, seemed to perform well with
respect to run-time efficiency and solution quality in several cases. Acuna-Agost et al. (2011) proposed an extension of this model, allowing the possibility of two trains in
the same direction to use the same track segment simultaneously. The MILP formulation presented, which used the
same notation as Tornquist and Persson (2007), attempts to

123

123

Alternative
graph

Alternative
graph

Alternative
graph

Train
scheduling

Real-time
train
dispatching

Train
D’Ariano
et al.
scheduling
and routing
(2008)
Nielsen (2008) Rolling stock
rescheduling
problem

D’Ariano and
Pranzo
(2009)
Corman et al.
(2010)

GarcíaRódenas
et al.
(2009)
Luethi et al.
(2009)
Sato et al.
(2009)

MILP

Train
rescheduling

Tornquist
and
Persson
(2007)
D’Ariano
et al.
(2007a)
D’Ariano
et al.
(2007b)

Real-time
train
dispatching
Train
rescheduling
and routing

NA

Real-time train
rescheduling
Crew and train
rescheduling

Alternative
graph

0–1 integer
programming
formulation
Alternative
graph

NA

Train
coordination

MILP

NA

Train
rescheduling

Norio et al.
(2005)

Problem
formulation

Problem
definition

Authors

x

Minimize the
maximum
delay

Minimize total
train delay

Minimize total
train delay
Minimize
total costs
x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

Platform/line Crew
allocation
scheduling

x

x

Train
connection

Special constraints

Line Network Passenger
connection

Infrastructure

Minimize the
maximum
delay
x
Minimize
canceling trips,
changes to the
shunting plans,
and off
balances
Minimize total
x
waiting time of
the system

Minimize the
maximum
delay
Minimize the
maximum
delay

Minimize total
delay and total
cost

Minimize
passengers’
dissatisfaction

Objective

Table 3 Summary of reviewed train rescheduling problems

Yes

Yes

Yes

Yes

No

Yes

Yes

Yes

Yes

Yes

Yes

Real-life
data

Partial exchange
heuristic, local
search heuristics
B&B, first come
first served
(FCFS)
Tabu search

Railway simulation

Constructive
heuristic
algorithm

B&B and heuristic
for balancing the
end-of-day
inventories

Simple dispatching
rules, greedy
heuristic, and
branch-and-bound
algorithm
B&B and local
search algorithm

B&B

PERT (program
evaluation and
review technique)
and simulated
annealing
B&B

Solution
method

Strategy

Reactive

Connection Reactive

Connection Reactive

Connection Reactive

Connection Reactive

Connection Reactive

Connection Reactive

Connection Reactive

Connection Reactive

Connection Reactive

Time-line

Connection Reactive

Feasible
network

552
J Sched (2014) 17:541–567

Train
rescheduling

Train
rescheduling

Fekete et al.
(2011)

Sato and
Fukumura
(2012)

Berger et al.
(2011a)

Integer
programming
formulation

Integer linear
programming
(ILP)

Event graph

Maximizing the
number of trips that
still will be served in
the re-optimized
dispatching
timetable
Minimize the
total workload

Minimize the
total delay of
all passengers
Maximize
passengers’
satisfaction

Event graph

Online railway
delay
management
Real-time
train
disposition

Almodóvar and
GarcíaRódenas
(2013)
Berger et al.
(2011b)

MILP

MILP

Graphs

Train
rescheduling
Rolling stock
rescheduling

Acuna-Agost
et al. (2011)
Nielsen
(2011)

Train
rescheduling

Crew and train
rescheduling

Sato et al.
(2010)

Minimize total
train delay

NA

Minimize total
costs and
resources
(vehicle or
crew)
Minimize
total costs
Balance of multiples
objectives: minimize
the changes to the
shunting plans, the
off-balances, the
canceled trips, the
operational cost, and
adequate seat capacity
Minimize the
total time in
system

Train
timetabling
and train
rescheduling

Meng et al.
(2010)

Objective

Problem
formulation

Integer
programming
formulation

Problem
definition

Authors

Table 3 continued

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

x

x

Yes

Real-life
data

x

Line Network Passenger Train
Platform/line Crew
connection connection allocation
scheduling

Infrastructure Special constraints

column
generation

Uncapacitated
multicommodity
flow
B&B

simulation

Alternative
greedy
heuristic

Local search
heuristics
B&B and heuristic
for balancing the
end-of-day
inventories

Improved particle
swarm
optimization
(IPSO)
algorithm
Lagrangian
relaxation
method

Solution
method

Predictive

Strategy

Reactive

Predictive

Reactive

Connection Reactive

Time-space Reactive

Time-line

NA

Connection Reactive

Connection Reactive

Time-line

Connection Reactive

Time-line

Feasible
network

J Sched (2014) 17:541–567
553

123

554

minimize the total rescheduling cost based on the total
delay. The performance of four solution methods were evaluated and compared as follows: (i) Right-shift rescheduling
(RS) keeps most of the system characteristics, postponing
each remaining trip after disruption by the amount of time
needed to make the schedule feasible, limiting the propagation delays; (ii) MILP-based local search method using RS as
initial solution; (iii) IP-based local search method + CPLEX;
and (iv) Iterative MILP-based local search method (LS). Two
different real rail networks have been used for the computational experiments: the first is a line located in France, and
the second is a railway network in Chile. The Iterative MILPbased local search procedure was able to obtain better solutions (average gap <1 %) within 5 min of computational time;
thus it seems to be viable for real-world situations.
Nielsen (2008) presented a generic framework for the
rolling stock rescheduling problem, when several changes to
the timetable may occur and the circulation has to be updated
every time. The problem is formulated as a MILP. The objective function minimizes simultaneously the number of canceled trips, changes to the original rolling stock plan, and
changes on the planned end-of-day balance of rolling stock
on each depot. The instances used in the experiments come
from rolling stock circulations used by Netherlands Railways
and solved using CPLEX 10.1. The observed computation
times varies from a few seconds to a minute depending on
the size of the considered instance. There is a direct positive
correspondence between the experienced computation times
and the length of the considered time horizon (in hours). In his
PhD thesis, Nielsen (2011) studied the disruption management in a context of rescheduling of passenger railway rolling
stock. The model contemplates real-life aspects and penalizes cancelations of trains, changes on shunting processes,
carriage kilometers, seat shortage kilometers, as well as deviations from the planned end-of-day rolling stock off-balances
on each depot. The previously developed model is expanded
considering the dynamics of passenger flows and incorporates the passenger behavior by applying an iterative solution
procedure that unifies the optimization of the rolling stock
assignment with detailed simulation of the passenger flow.
All the tested instances were based on real data from one of
the Dutch railway operators.
Berger et al. (2011a) developed an optimization tool for
solving the train disposition problem, concerned with defining whether a train should wait for an incoming delay train or
not. The problem is represented using an event-graph and formulated as a variant of the uncapacitated multi-commodity
flow. The major objective of the model is the satisfaction
of passengers, through three different objective functions as
follows: (i) the overall lateness at the destination, (ii) the
deviation from original travel plans of passengers, and (iii)
the number of passengers that do not reach their destination.
The authors carried out experiments, considering real and

123

J Sched (2014) 17:541–567

artificial delay scenarios (based on data from German Railways). The results have demonstrated that the approach is
fast enough to be applied in a real system, enabling quick
decisions.
Fekete et al. (2011) employed an ILP programming formulation based on the event-activity network, suggested by
Serafini and Ukovich (1989), for schedule recovery of railbased urban mass transit systems. It focuses on scenarios
where the system faces a bottleneck, such as the direction
of a track is shutdown. The formulation incorporates constraints to cope with unplanned turns or unplanned returns
to a depot. The rescheduling objective was to maximize the
number of trips that will still be served after the disruption.
Since frequency of most subway systems is high and canceling few trips lead to only minor delays and inconveniences
for the passengers, minimizing the overall delay was only
a secondary objective. Four scenarios of real-life instances
have been evaluated, differing in shutdown location, transit times, topology of the switches, and turn possibilities.
CPLEX was used to solve the problems. This model has the
potential for real applications since good quality solutions
were found within a minute.
Some ad-hoc heuristics have been suggested for solving
the TPR. Norio et al. (2005) proposed a heuristic algorithm
for automatic train rescheduling, in which the main objective is to minimize passengers’ dissatisfaction measured by a
planned dissatisfaction index. The algorithm combined simulated annealing (SA) and Program Evaluation and Review
Technique (PERT). The PERT module enabled reducing the
search space for the SA procedure, resulting in an efficient
algorithm. To test the algorithm, a whole-day schedule for
564 trains was developed for an urban line in Tokyo, about
40 km long and containing 19 stations. New schedules were
obtained in approximately 1 min for recorded disruptions.
Meng et al. (2010) used particle swarm/genetic algorithms
for train timetabling and train rescheduling. Three different
algorithms were developed: normal particle swarm optimization (PSO) algorithm, genetic algorithm, and improved particle swarm optimization (IPSO). The algorithms were evaluated in double lines autolocking section in China, considering
five stations and 60 trains. The best results were obtained by
the IPSO algorithm.
Almodóvar and García-Ródenas (2013) studied a train
capacity problem where a service line is substantially disrupted due to a heavy unexpected demand that exceeds the
service line capacity. A greedy heuristic and an event-based
simulation model were applied to determine the best vehicle reassignment decisions. This approach provides nearoptimal solutions, but it involves a high computational
cost and does not currently seem applicable for real-time
response. García-Ródenas et al. (2009) also used simulation
models for schedule recovery. The authors dealt with on-line
management of public transport systems under disruptions,

J Sched (2014) 17:541–567

such as non-recurrent congestion and in situations in which
demand is greater than the capacity offered by the current
transit line. Their problem was to decide which vehicles, and
in which time instants, must be reassigned to the disrupted
line in order to minimize the waiting time in the system.
Some train network constraints were not taken into consideration to decrease the complexity of the problem. Their online optimization approach was based on a predictive simulation model, a queuing model, and a constructive heuristic algorithm. Luethi et al. (2009) developed a simulation
model for the real-time train rescheduling aiming at reducing buffer times without impacting schedule reliability. The
simulation was carried out on a critical bottleneck block in
the Swiss rail network. Simulation experiments show that a
real-time rescheduling system could significantly reduce the
total delays even in the case where additional trains are added
to the timetable. Simulation has also been used by Berger et
al. (2011b) in order to solve the ORDM problem, in which
passengers have a fixed network route, but are allowed to
adapt the choices of the trains based on delays. The major
objective is to minimize the total delay of passengers. A websimulation platform has been developed where a simulation
framework and a heuristic approach have been integrated
to evaluate and compare different heuristics for solving the
ORDM considering stochastic delays. The model design and
application were directed to a robust rather than a real-time
context, developing a powerful tool to design policies for
coping with railway delay management.
Sato et al. (2009) added the crew rescheduling problem to
the TRP. They set up a scenario in which a train broke down
between stations for 2 h, resulting in a large-scale disruption
and several timetable changes, such as canceled train services
and extra trains. The problem was formulated as an integer
programming problem. The solution was based in a twophase approach. The first one uses a partial exchange heuristic, generating a feasible solution by modifying the original
schedule. The second approach uses a local search for alternative solutions to search for alternatives that improve an
evaluation value that includes crew scheduling effects, while
maintaining the schedule feasibility. The results of numerical experiments with real-world data showed that the proposed method generated feasible solutions within a practical amount of time, and the two-phase solution approach
improved the solution quality. Later, Sato et al. (2010) used
a Lagrangian relaxation as a solution mechanism for the
crew and VRSP, formulated as network flow models. They
used real-world data from a Japanese railway line to conduct
numerical experiments for vehicle rescheduling.
Recently, Sato and Fukumura (2012) focus on the
rescheduling of locomotives that haul freight trains in Japan.
Two problems have been formulated as integer programming models, namely the train rescheduling problem and
the uncovered train detection problem. Both problems were

555

solved by column generation. They tested the model performance with real data obtained in a Japan railway line with
high frequency. The results show that the proposed algorithms provide satisfactory solutions within 30 s on a PC
(32-bit Windows PC Core i7 CPU, 3.2 GHz, 3 GB RAM)
for several studied cases.
Several papers in the TRP literature are specially focused
on the CDR problem in network railways, which is related
to the real-time train scheduling and routing (D’Ariano et al.
2007a, b; D’Ariano et al. 2008; D’Ariano and Pranzo 2009;
Corman et al. 2010). The CDR consists of changing dwell
times, train speeds as well as train ordering and routing
(Corman et al. 2010). Their modeling and solution methods
use alternative graph formulations (Mascis and Pacciarelli
2002). Alternative graph was especially developed to cope
with the scheduling problems where the response time is a
critical factor for the evaluation of a method. An example,
based on a slightly larger one presented in Mascis and Pacciarelli (2000), illustrates the alternative graph. Figure 6 shows
a small railway with two trains traveling in opposite directions. Train A is moving from block section 1 to 10, while
train B is moving from section 9 to 1. Train B needs to pass
through platform 4. This railway has four block sections (1,
7, 9, and 10), three junctions (2, 5, and 8) and trains A and
B share four resources (sections 2, 5, 6, and 8).
Figure 7 shows the alternative graph for this small railway. For sake of clarity, each node of the alternative graph
is indicated with a pair (train-block section), e.g., A2 indicates that train A is traversing block section 2. There are four
pairs of alternative arcs, represented by connecting the two
paired arcs with a small circle. The initial position of train A
implies that train B is not allowed to precede train A in section 2. The required time to pass through all track segments
is represented by α.
The main advantage of the alternative graph formulation
is the detailed representation of the network topology at the
level of railway signals and operational rules. D’Ariano et al.
(2007a) propose a truncated branch-and-bound (B&B) algorithm for the CDR problem with fixed routing, aiming to minimize the maximum secondary delay for all trains at all visited
stations. Due to the interaction between trains, delays caused
by technical failures and disturbances may be propagated
to other trains in the network, defined as secondary delays.

B
4

9

A
1

7
2

3

5

6

8

10

Fig. 6 A small railway network for two trains in the opposite direction
(based on D’Ariano and Pranzo 2009)

123

556

J Sched (2014) 17:541–567

Fig. 7 The alternative graph
for the sample railway (based on
D’Ariano and Pranzo 2009)

A1

B1

A2

B2

Computational experiments were carried for a real rail network and for multiple delayed trains. The model incorporates
a detailed description of the network topology, including railway signals and safety rules. Effective static implementation rules for conflict resolution problem were developed. It
resulted in a significant reduction in the computation times
obtaining near-optimal schedules for practical size problems.
D’Ariano et al. (2007b) also studied a variable speed model
that coordinated speed among consecutive trains, based on
the alternative graph formulation where safe distance headway between trains is respected. The model simultaneously
considers speeds of all trains with the objective of minimizing the maximum delay due to conflicts. Three approaches
were used to solve the problem: simple dispatching rules, a
greedy heuristic based on the alternative graph formulation,
and a B&B algorithm. B&B provides better quality solutions,
but requires more computation time. Moreover, the results
indicated that fixed-speed model underestimates the consequences of braking and acceleration, while the variable-speed
model presents more realistic solutions.
In D’Ariano et al. (2008), D’Ariano and Pranzo (2009),
and Corman et al. (2010), rolling stock and passenger connections are included in the models. D’Ariano et al. (2008)
described the traffic management system railway traffic optimization by means of alternative graphs (ROMA) which is
able to solve the CDR problem in real-time for moderate size
dispatching areas. A B&B algorithm was used to sequence
train movements, while a local search algorithm was used for
rerouting optimization purposes. Computational tests, carried out for a Dutch dispatching area between Utrecht and
Den Bosch, including instances with multiple delayed trains
and different blocked tracks in the network, showed that significant delay reductions were achieved by the rescheduling
of train movements.
D’Ariano and Pranzo (2009) extended ROMA to proactively evaluate the effects of train rescheduling actions for
short-term prediction of train traffic. The truncated B&B
algorithm introduced by D’Ariano et al. (2007a) was reapplied with the first come first served scheduling rule by
D’Ariano and Pranzo (2009). The authors focused on disturbances caused by train delays and temporary unavailability of

123

A3

B4

A5

B5

A6

A8

A 10

B6

B8

B9

some tracks. Since the prediction of railway traffic can result
in computationally intractable instances, the time horizon
was decomposed into smaller time intervals that are solved
sequentially, with the objective of improving train punctuality. To detect and solve conflicts at each time interval, the
ROMA dispatching system was employed. The independent
solution of each hour of dispatching permits handling large
time horizons with a linear increase of computation time.
This approach was compared with a formulation in the problem for the full-time horizon, in order to evaluate the error
due to the problem decomposition. The temporal decomposition proved to solve large scheduling problems; however,
the full time-horizon solution gave smaller time delays but
with much larger solution times.
Corman et al. (2010) considered passenger connections,
multiple delayed trains, and heavy network disruptions. With
the objectives of increasing the solution quality and reducing computation times, in comparison of the approaches in
D’Ariano et al. (2007a) and D’Ariano et al. (2008), they
developed a tabu search strategy. Their experiments on practical size problem instances, such as the Dutch dispatching
area between Utrecht and Den Bosch, showed that (i) the
tabu search strategy decreased the optimality gap for small
instances where the optimal solutions were known, and (ii)
for large instances, the solution quality was better and computational times were lower.

5 Airline schedule recovery problem
The airline recovery problem is the most studied class of
problems in the RTVSRP. Since a disruption in the airline
traffic could have severe operational and economical consequences (Ball et al. 2007), the development of fast and reliable recovery methods is of much interest to airline companies. In particular, airline passenger companies have become
very interested in this problem since passenger delay is a
major issue as the growth in air transportation has outpaced
the capacity at some busy airports (Petersen et al. (2012)).
The development of optimization models for airline schedule
recovery has been a challenge to the O.R community since

J Sched (2014) 17:541–567

557

Fig. 8 Airline disruption
management (Liu et al. 2008)

the eighties; Teodorovic and Guberinic (1984) is perhaps the
most cited early work. Since then, several optimization and
heuristic rescheduling methods have been developed.
5.1 Aircraft rescheduling considerations
The process of airline disruption management, developed
by Liu et al. (2008) is shown in Fig. 8. A small disruption might require no rescheduling, due to the inherent
flexibilities and slack in the original schedule. However, if
the deviation between the disrupted and original schedule
becomes large, rescheduling becomes a necessity. Unplanned
events that impact airport infrastructure and air traffic control,
extreme weather conditions, and emergencies to maintain
safety are examples of disruptions that can ripple throughout
the system, resulting in cancelation or delays. Three types of
disruptions—that could occur concurrently—might disturb
a planned aircraft schedule (Bisaillon et al. 2011):
1. Flight disruption—when a flight is delayed or canceled.
2. Aircraft disruption—when an aircraft is unavailable for
a period of time.
3. Airport disruption—the departure or arrival capacities of
an airport are temporarily reduced.
Often when an airport disruption occurs, a Ground Delay
Program (GDP) is issued at this airport. The GDP purpose is
to increase the time gap between successive flight landings
in order to ensure safe operations during the adverse conditions period. Under most GDPs, the available number of
slots for flight landings becomes less than planned. Therefore, a scheduled flight could be held at its origin, diverted

to a nearby airport, or in the worst case it could be canceled
(Abdelghany et al. 2008).
When a severe disruption occurs, many resources (crew,
aircraft, passengers, slots, catering, cargo, etc.) have to be
rescheduled. Large airlines usually react to this by solving
the rescheduling problems in a sequential fashion. First, the
aircraft rescheduling problem is solved. Next, the crew pairing problem is solved. Finally, a solution for the crew rostering problem is defined. Although the three rescheduling
problems are highly related, this paper focuses on the ARP.
We refer to Clausen et al. (2010) for an extensive review of
disruption management in the airline industry.
An ARP solution gives a new route for each aircraft, given
that a serious disruption occurred. The new routes must comply with several technical, commercial, and regulatory constraints based on rules defined by national and international
aviation organizations. Airline companies’ policies, aircraft
capacity, and airports’ conditions typically define constraints
to be taken into consideration when determining a revised
schedule. The solution of the problem gives a set of feasible
routes that can minimize the adverse effects of the disruption.

5.2 Aircraft rescheduling models
As mentioned earlier, Clausen et al. (2010) provide an excellent survey on airline disruption management. In their literature review of ARP, 34 papers identified were published
between 1984 and 2008. The authors concluded that the
majority of the mathematical models and solution methods
for solving the ARP are similar to the methods applied for
schedule planning. The ARP was formulated based on network flow models (Jarrah et al. 1993; Cao and Kanafani

123

558

1997a, b), TLN (Yan and Yang 1996; Thengvall et al. 2000),
TBN (Argüello et al. 1997; Bard et al. 2001), and the set partitioning problem on CNs (Rosenberger et al. 2003; Andersson
and Värbrand 2004). To solve the formulated models, solutions methods based on the out-of-kilter algorithm (Mathaisel 1996), B&B (Bard et al. 2001), Lagrangian relaxation
(Yan and Yang 1996; Andersson and Värbrand 2004), greedy
randomized adaptive search procedure (Argüello et al. 1997),
and tabu search (Andersson 2006) have been proposed. Most
models and methods have been evaluated using real-life problem instances. Although most of the algorithmic approaches
are capable of considering several important real-life requirements, the solution times of many of them were not practical
for real-time applications.
For the sake of economy and to restraint excessive overlaps
with previous reviews, we focused on papers published from
2000 onwards. Bard et al. (2001) and Clausen et al. (2010)
offer comprehensive reviews of earlier paper related to ARP.
Table 4 summarizes the reviewed papers. With the exception
of Ionescu et al. (2010), analyzed on section 2, all reviewed
papers applied a reactive strategy.
Since weather-related disturbances are the main causes of
disruptions in the airline industry (Rosenberger et al. 2003),
aircraft disruption has been receiving less attention in the
literature compared with flight and airport disruptions. Aircraft mechanical problems are included as possible events
causing flight disruptions. Eggenberg et al. (2010) also considered disruptions caused by maintenance events. A column
generation algorithm was implemented to solve the problem.
The advantage of the developed technique is that it is flexible
enough to be applied for aircraft, crew, or passenger recovery problems. The algorithm is based on recovery networks,
encoding each unit’s (aircrafts, crew, or passengers) feasible route. The computational results show that the algorithm
is efficient, solving instances with real data and reasonable
complexity in low computation times.
5.2.1 Flight disruption
Bertsimas and Patterson (2000) set up a multi-aircraft optimization model minimizing the weather delay cost, based
on deterministic weather scenarios. The problem was modeled as a dynamic network flow model with additional constraints. The authors presented a mathematical programming
approach referred to as the Lagrangian generation algorithm (LGA). The LGA comprises a Lagrangian relaxation
to generate aggregate flows; a randomized rounding heuristic that decompose the aggregate flows into a collection of
flight paths for individual aircrafts as well as an integer programming formulation of the packing problem whose solution generates feasible and near-optimal routes for individual
flights. The model did not explicitly allow flights to be canceled. Three scenarios were used to evaluate the algorithm

123

J Sched (2014) 17:541–567

efficiency, with problem solution times varying between 116
and 330 s.
Thengvall et al. (2000) expanded the model developed by
Yan and Yang (1996), developing an integer network flow
model based on TLN to deal with flight delays and cancelations in daily operations. A rounding heuristic was developed
to improve the LP-relaxation of the integer formulation. Real
data from Continental Airlines for B757 and B737 schedules, solved separately, were used to evaluate the developed
model. Good quality solutions were obtained within reasonable computational times, validating its application to realworld cases.
Bard et al. (2001) developed a time-band optimization
model for generating new aircraft routings when groundings
and delays occur in the midst of daily operation. The problem
is represented as a TBN and modeled as a minimum cost
flow model with side constraints. Several experiments were
carried out to demonstrate the effectiveness of the approach,
using data from Continental Airlines. The reported results
show that very good solutions are obtained in 3 CPU minutes,
on average.
Løve et al. (2002) solved the ARP that included flights
delays and cancelation costs using two local search
approaches: the steepest ascent local search (SALS) and
the iterated local search. The heuristic methods were based
on a network formulation, where nodes are either aircraft
or flights. Assigning an aircraft to a given flight corresponds to selecting the edge connecting the aircraft and
flight for the solution. Any candidate solution is altered by
swaps that exchange flights between two aircrafts. With randomly generated data, the SALS approach quickly finds a
local optimum (2.11 s on average). Kohl et al. (2007) confirmed the results of Løve et al. (2002) on real-life data.
As part of the DESCARTES project, they also presented a
crew scheduling solver and described a prototype multipleresource rescheduling decision-support system for a disruption management of aircrafts, flights, and crews.
Dožić (2009) presented a formulation for the ARP which
had the objective of minimizing the total delay costs. The
model incorporated the following constraints: time-window
constraints, aircraft maintenance constraints, aircraft balance
constraints, and capacity constraints. A local search heuristic was developed for obtaining a list of feasible solutions
ordered according to the objective function value. The heuristic is based on rotation crossing of delayed flights, achieved
by removing part of one rotation and adding to another rotation, or by interchanging parts of two rotations. A numerical
example for one operational day was conducted for 29 aircraft (nine different aircraft types), assigned to 126 flights. A
feasible solution list is obtained in less than 10 s for selection
and implementation by a dispatcher.
Bratu and Barnhart (2006) proposed two optimization
models to generate integrated recovery plans for aircraft,

Airport
disruption
Aircraft/airport
disruption

Filar et al.
(2007)
Liu et al.
(2008)

Abdelghany
et al.
(2008)

Airport
disruption
(GDP)

Flight
disruption

Kohl et al.
(2007)

Bratu and
Barnhart
(2006)

Aircraft/airport
(GDP)
disruption
Flight
disruption

Rosenberger
et al. (2003)

Flight
disruption

Airport
disruption

x

x

x

522

19

2

NA

302

x

x

x

96

79

332

NA

x

x

x

27

16 B757
27 B737

NA

x

x

x

x

x

x

Minimize flights
delays and
cancelations
Optimal trade-off
between airline
operating costs
and passenger
delay costs
Multiple-resource
decision-support
system

Minimize the
total costs
Minimize the
delay costs
(inconvenience
to passengers)
Minimizes the
total costs

x

x

Minimize flights
delays and
cancelations

x

x

x

x

x

x

Aircraft

Cancel Retime Multi-fleet Crew
scheduling

2,040

210

517

20

1,074

469

339

2,921

42 B757
162
B737
162

71

Flights

Instances analyzed

Functionality

x

Maximize
revenue
minus cost
Minimize
cancelation
costs
Maximize total
profit

Airport/flight
disruption

Thengvall
et al.
(2001,
2003)
Løve et al.
(2002)

Minimize
the delay
costs

Flight
disruption

Bertsimas
and
Patterson
(2000)
Thengvall
et al.
(2000)
Bard et al.
(2001)

Airport/flight
disruption

Objective

Problem context

Authors

Table 4 Summary of reviewed aircraft rescheduling problems

NA

11

1

NA

74

NA

44

149

Yes

Yes

Yes

Yes

Yes

No

Yes

Yes

Yes

Yes

30 B757
13 B737
30

Yes

4

Airports

Real-life
data

Greedy
optimization
strategy

Multi-objective
genetic
algorithm

Extension of the
local search
heuristic of
Løve et al.
(2002)
B&B

Steepest ascent
local search
(SALS) and
iterated local
search (ILS)
Aircraft
selection
heuristic
B&B based
algorithm

B&B followed by
a rounding
heuristic
Branch-andbound based
algorithm
B&B/bundle
method

Lagrangian
generation
algorithm

Solution
method

Reactive

Reactive

NA

Connection

Reactive

Reactive

Time-line

Time-line

Reactive

Reactive

Connection

Time-line

Reactive

Time-line

Reactive

Time-band

Reactive

Reactive

Time-line

Timeline/timeband

Reactive

Strategy

Connection

Feasible
network

J Sched (2014) 17:541–567
559

123

123
Minimize the
delay costs
Minimize the total
cost associated
with flights,
aircrafts, and
passengers
Minimize delay,
cancelation and
parking costs
Minimize total
cost associated
to flights,
aircrafts, and
passengers
Minimize the total
cost associated
to flights,
aircrafts, crew,
and passengers

Aircraft/airport
disruption

Aircraft
disruption
Aircraft
disruption

Aircraft
disruption

Aircraft
disruption

Airport
disruption

Liu et al.
(2010)

Eggenberg et al.
(2010)
Zegordi
and
Jafari
(2010)

Aguiar et al.
(2011)

Jafari and
Zegordi
(2011)

Petersen
et al.
(2012)

Minimize the
flights delay

Minimize total
expected
delay cost
Minimize the
total costs
Compare different
resolution
approaches

Airport
disruption

Mukherjee
and Hansen
(2009)
Dožić
(2009)
Ionescu
et al.
(2010)

Flight/aircraft
disruption
Flight/aircraft
disruption

Objective

Problem context

Authors

Table 4 continued

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

NA

13

51

13

16

7

NA

29

800

100

3,521

100

242

39

200

126

351

15

3

Flights

Crew
scheduling

Aircraft

Multi-fleet

Cancel

Retime

Instances analyzed

Functionality

NA

19

3

19

4

6

NA

2

3

Airports

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Real-life
data

Benders
decomposition

Hill-climbing
simulated
annealing genetic
algorithm
B&B

Ant colony
optimization
algorithm

Specific methods
for each tested
resolution
approach
Hybrid
multi-objective
genetic algorithm
Column generation

Specific heuristic

Stochastic model

Solution
method

Time-line

Connection

Connection

Connection

Time-line

Reactive

Reactive

Reactive

Reactive

Reactive

Reactive

Dynamic/
predictive
/reactive

NA

NA

Reactive

Reactive

Strategy

Connection

Connection

Feasible
network

560
J Sched (2014) 17:541–567

J Sched (2014) 17:541–567

crews, and passengers which allow to delay or cancel flight
departures, while ensuring the compliance of crew regulations and aircraft maintenance requirements. Their objective
function finds the optimal trade-off between airline operating
costs and passenger delay costs. An airline operations control
center simulator was developed to evaluate the airline recovery models for real instances of airline operations. Compared
to the actual operations data which included actual passenger
delays, the models of Bratu and Barnhart reduced the number
of disrupted passengers who stayed overnight by 17.2 %, and
reduced average passenger delay by 5.2 %.
Considering the crew connection problem, Aguiar et al.
(2011) developed an aircraft recovery approach, taking into
account a multi-objective approach that optimizes delays and
other costs associated to the use of aircrafts. To solve the
ARP, three different meta-heuristics were implemented: hillclimbing, SA, and genetic algorithm. Although all developed
heuristics performed well in terms of obtaining acceptable
delays through time, the genetic algorithm implementation
presented the better results. The crew connecting problem is
solved by the solution obtained on the aircraft recovery. To
solve it, hill-climbing and SA algorithms were developed and
tested using data from TAP Portugal. Simulated annealing
presented better results in terms of wages decrease.
Testing another meta-heuristic, Zegordi and Jafari (2010)
solved the ARP with an ant colony algorithm, adding considerations about disrupted passengers to the problem. To
achieve that, the authors consider aircraft rotations and passengers’ itineraries instead of flights. The aircraft recovery is
formulated as a MILP in which the objective is to minimize
the total cost associated to recovering all flights, aircrafts, and
passengers affected by the disruption. The ant colony algorithm is tested on real-world instances obtained from Andersson (2006), and solved the problem with good solutions
within few minutes of computation time. This same model is
solved in Jafari and Zegordi (2011), using real data instances
presented by Andersson and Värbrand (2004). LINGO was
employed to solve the problems. However, as the size of
the instances increase, the commercial solver could not find
solutions in a reasonable amount of time. Four preprocessing
steps were then developed to decrease the problem complexity, aiming at reducing the number of integer variables and
constraints. The computational time for solving the problem
is not mentioned, but the costs are equal to or smaller than
those found by the precursor paper for the tested instances.
5.2.2 Airport disruption
Thengvall et al. (2001, 2003) extended their previous work
(Thengvall et al. 2000) to deal with hub closures in a multifleet context. In the 2001 paper, three multi-commodity flow
problems were introduced aiming at maximizing the revenue
minus costs of disrupted flights. Two models (Models 1 and

561

2) are based on time-line networks, while the third model
(Model 3) is based on a TBN. Model 3 is quicker for shorter
closure times, but slower for larger closure times. A bundle
algorithm to solve the Lagrangian relaxation of Model 3 is
introduced in the 2003 paper. Optimal solutions were found
by the bundle method quicker in extensive experiments using
data from Continental Airlines.
Filar et al. (2007) studied airport disruptions, and developed a new optimization model called model for adaptive
rescheduling of flights in emergencies (MARFE). MARFE
modifies schedules for both aircrafts that are still on the
ground and for those that are already in the air, constrained
by airport capacity levels. MARFE attempts to minimize the
sum of delay costs, curfew violation costs, cancelation costs,
and diversion costs. MARFE took less than 5 min to solve
problems to optimality for real data obtained from the Sydney airport in Australia, consisting of 517 flights a day, 261
flight arrivals, and 256 departures.
Liu et al. (2008) considered the situation of a 1-h temporary closure of two airports. A multi-objective airline disruption management model was proposed. A genetic algorithm (called MMGA) was developed to generate a timeeffective multi-fleet aircraft recovery aiming at simultaneously minimizing the cost for schedule recovery (considering additional assignment and crew reassignment costs), and
passengers’ inconvenience. The model formulation considered ground turn-around times, flight connection times, flight
swaps, total flight delay time, and a constraint on 30-min
maximum delay time from the original schedules. Real flight
schedules obtained from a Taiwanese domestic airline were
used for evaluation. No running times were given, but the
authors indicated that “simulation results demonstrate that
the application is capable of presenting high-quality solutions in minutes”. In Liu et al. (2010) two soft constraints
were added to the previous model for a daily short-haul aircraft schedule recovery problem to minimize delay time variance and the number of delayed flights. Suboptimal solutions
(with a 4 % optimality gap) were found in 3.6 min on average;
optimal solutions needed an average of 7.5 min.
Rosenberger et al. (2003) presented an aircraft recovery
approach based on the set partitioning problem that considers both aircraft disruptions and station disruptions. The
optimization model reschedules legs and reroutes aircraft by
minimizing an objective function involving rerouting and
cancelation costs. An efficient aircraft selection heuristic
was included to identify the subset of aircraft that may be
rerouted. The model was validated by simulation experiments considering 500 days of airline operations; three different fleets were analyzed separately.
Abdelghany et al. (2008) developed a decision support
tool, DSTAR, for airline schedule recovery during irregular
operations aimed at an integrated recovery of aircraft, pilots,
and flight attendants. The tool is composed of two integrated

123

562

models, a schedule simulation and a resource assignment
optimization model. The first one predicts the list of disrupted
flights in the system as function of resource availability and
aviation rules. The second one seeks to find the optimal plan
of crew and aircraft swapping, reserve utilization, and flight
reassignment to recover the projected list of disrupted flights.
The recovery horizon was divided into stages, where the simulation model produces the list of disrupted flights for the
remaining horizon, and the optimization solver makes minimum cost resource reassignments. The recovery problem
at each stage is formulated as a MILP, aiming to minimize
the total recovering cost, including resource reassignment
cost, total delay cost, and cancelation cost. An experimental investigation using real data indicated that DSTAR has
saved approximately 5 % in recovery costs when compared
with human schedulers.
Petersen et al. (2012) presented an innovative research,
attempting at solving the fully integrated airline recovery
problem. The developed optimization-based approach seeks
to repair (in an integrated way, rather than sequentially) the
flight schedule, aircraft rotations, crew schedule, and passenger itineraries. Given the extreme complexity of the integrated ARP, a routine is included to limit the size of the problem, introducing the notion of disruptable flight set. The routine analyzes the flights that are directly affected by a resource
at the airport. Next, these flights are expanded to consider
aircraft, crews, and passengers. The disruptable flight set
receives all resources that force a delay or cancelation. The
solution method, based on a Benders decomposition scheme,
has a main objective to optimize passenger delay, consisting
in the integration of several complex subproblems, each one
corresponding to solve scheduling decisions affecting aircrafts routes and rotations, crew, and passenger itineraries.
The authors use data from an American regional company,
involving 800 flights and 2 fleets, to evaluate their approach.
Solutions are found in reasonable time for several disruption
scenarios. Moreover, the quality of the solutions, considering
the integrated approach, is improved in comparison with the
more traditional sequential method.

6 Summary and conclusions
As transportation services become larger and more complex to serve growing demands, the occurrence of severe
disruptions grows and their impacts are increasingly costly.
A severe disruption can cause significant economic loss and
many negative effects on the level and quality of service provided by transportation/logistics companies. The objective of
this paper is to present a state-of-the-art review in real-time
vehicle schedule recovery modeling and solution methods
within train, airline, and road-based transportation. Meeting
the challenges of solving RTSVRP quickly and with good

123

J Sched (2014) 17:541–567

quality, considering different vehicle types and disruption
causes, provides operations researchers, systems engineers,
mathematicians, and computer scientists opportunities for
beneficial research and more discoveries.
Considering the flowchart presented in Figs. 4, 5, and 8,
it is possible to conclude that the schedule recovery process
for air, train, and road-based transportation is similar. The
process starts with an analysis of the disruption and its consequence for the initial off-line planning. In general, an experienced staff is responsible for defining whether a disruption
is severe enough to ask for a complex recovery of the system, involving reallocation of a set of resources (vehicles,
crew, passengers, tracks, cargo, etc.), or a simple recovery
heuristic is sufficient to handle the unexpected event. For this
initial decision, criteria such as costs and benefits, governmental regulations, duration of the disruption, among others,
play very important roles. Clearly, some disruptions do not
deserve complex small recovery actions, as follows: traffic
delays in the road-based transportation; mishandled luggage
and overbooked flight legs in the airline sector; and excessive time for dis/embarking in crowded train stations. The
generation of schedule recovery plans is the next step. This
process is done in a sequential way, first the vehicle schedule is solved, followed by the crew rescheduling. Next, the
impact on passengers is addressed. The recovery process is
iterated until a feasible solution is reached for all resources.
Considering the diversity of resources involved, disruption
causes and contexts, government regulations, and user preferences, the whole recovery problem presents several and
conflicting objectives and a very large number of constraints.
Until recently, the generation of recovery plans was made
by human experts, employing common sense and past experiences. They are content in producing a very small number
of viable plans (sometimes, just one), given the complexity
of the task (Clausen et al. 2010). The technological developments on real-time monitoring of mobile units and status of
transportation services, and the emergence of new algorithms
to solve large optimization models in the last two decades,
have resulted in the development of new models and solution
methods to cope with real-time recovery in transportation
services, especially for the RTVSRP. For two major reasons
modeling and solving vehicle recovering problems are more
complex than modeling and solving the counterpart planning
problems. First, large amounts of data are required to solve
the recovery problems and these must be collected in realtime. Second, the recovery problems are quite complex and
need to be solved quickly.
The RTVSRP is a large class of problems, considering
different vehicle types, several different contexts (mainly
in terms of the disruption cause), and many objectives.
Although there is a great variety in the way RTVSRP
instances are formulated and solved, all reviewed papers follow a similar modeling approach. The problems are initially

J Sched (2014) 17:541–567

represented using an underlying network structure to model
the schedules. In these structures, possible alternatives and
some constraints are explicitly represented. Based on these
networks, the problems are mathematically formulated and
solved using approaches that either decompose the problem into smaller easier-to-solve classical OR problems or
use heuristic search methods. Section 2 presents a generic
(and didactical) formulation for the RTVSRP. Next, we analyze the underlying networks, mathematical formulation, and
solution methods employed to solve the RTVSRP instances
for airline and ground transportation, identifying similarities
and differences.
Based on Tables 2, 3, and 4, three different network structures were identified in the RTVSRP literature, namely connection, time-line, and time-band. The most commonly used
network for this problem is the connection. This is not a
surprise, since this structure is also the most used in offline scheduling processes. In the road-base transportation,
almost all problems with the exception of Ernst et al. (2007)
use this structure. But the problem is directed to recreational
rental vehicles rather than to public transportation, as usual
in the RTVSRP applied to road-based transportation. In the
railway-based transportation, the time-line network appears
in some papers (around 18 % of the revised papers). But it
is in the airline-based transportation that the alternative networks to connection seem to have an important role (44 %
of the revised papers use time-line or time-based networks).
Although time-line and TBN are more complex, they explicitly account for time and space simultaneously, while in the
connection only space is represented; time is only implicitly
represented in the arcs. We speculate that the costs involved
in the airline-based transportation demand more precise solutions and better ways to generate recovery plans. Bard et al.
(2001) and Thengvall et al. (2001, 2003) claim that time-line
and TBN, however more complex to be generated, are able to
offer these benefits when solving real-world problems, originating mathematical models quicker to solve. In particular,
Thengvall et al. (2001) presents a comparison on the use of
these networks for the same problem. Time-band performed
better when the disruption time was lower. On the other hand,
time-line performed better when the disruption time was
larger. This can be explained by the greater level of detail
demanded by the TBN. As the disruption time increases, the
number of components being represented increases exponentially, generating excessive binary variables in the respective
mathematical formulation.
The RTVSRP is often modeled using similar approaches
as their planning counterpart problems. Several mathematical
formulations are based on multi-commodity network flows,
set partitioning, and assignment problems. The real-time
perspective is represented by including a set of integer (in
general, binary) decision variables and side constraints. The
VRSP and the ARP present some similarities in the ways their

563

subproblems are formulated, based on classical integer linear
programming models such as the network flow problem, the
set partitioning problem, and the assignment problem. Specific technical-related constraints, involving track number,
track directions, and train types, make the TRP a little different. TRP has been formulated considering event-activity networks, disjunctive programs, and event-driven MILP. As for
their computational complexity, both VRSP and ARP have
the same complexity, and are proven to be NP-hard problems.
Strotmann (2007) proved that TRP is NP-complete.
The solution methods used to solve the RTVSRP are
also similar to the ones used for off-line planning problems,
such as B&B, Lagrangian relaxation, column generation, soft
computing heuristics, and local-search based heuristics. The
solution approaches for VRSP are based on traditional optimization methods developed for the schedule design process;
soft computing and local search based heuristics have been
neglected. Based on the reviewed literature, the TRP seems
to be the most difficult problem to solve in practice, as a consequence of the following aspects: the severe security measures (two trains cannot occupy simultaneously the same segment); the number of resources involved (trains, segments,
blocks, and stations); the control of the decision is disperse
through different levels; and the generalized impacts of the
so-called “snow ball effect”. In the TRP, a common solving
approach clearly emerged due to its high complexity. The
problem is initially relaxed or transformed into a simpler one.
This problem is solved using the classical developed methods to handle large integer programming models (Lagrangian
relaxation and column generation). Soft computing and local
search based heuristics are then developed to improve or to
build a viable solution from this initial solution. In the ARP,
several different solving methods can be observed. Besides
the two approaches previously described for the VRSP and
the TRP, metaheuristic approaches have become popular in
the last years. The capacity of generating multiple solutions
with different characteristics in a very reasonable amount of
time (Andersson 2006), even for real-time context, justifies
its wide utilization in the ARP, highly dependent on a set of
alternative plans as presented in Fig. 8.
The analysis of the literature on the RTVSRP reveals some
additional interesting facts. The first is that the literature
on VRSP is scant compared with train and aircraft recovery literature. This aspect was highlighted by Daduna and
Paixão (1995) and remains true today. Disruptions and realtime recovery for buses and trucks are topics that need to be
further explored, mainly on the application of new solution
methods. A good starting point for some new approaches for
VRSP would be to apply some of the methods developed for
ARP, given the similarities of the problems.
Another observation based on the literature review is
the small number of papers related to major technical failures or severe accidents in the RTVSRP. The majority

123

564

of the reviewed papers consider delays as the only cause
of disruption. Exceptions are Li et al. (2007a, b, 2008,
2009) for the VRSP, and Eggenberg et al. (2010) for the
ARP. Although not as common as delays, vehicle mechanical problems and accidents have higher average durations
among vehicle disruptions (Acuna-Agost et al. 2011). Vehicle breakdowns/accidents require the consideration of additional issues, such as the need to serve the passengers/cargo
involved in the disruption. Solution methods that solve for
only delays, in general, cannot be directly applied to mechanical failures and accidents. Furthermore, new robust strategies evolve when technical failures are considered, such as
the necessity of keeping spare vehicles parked in strategic
locations to recover the passengers/cargo.
Few papers integrate vehicle, crew, and passenger recovery. For the VRSP, Huisman and Wagelmans (2006) analyzed
these aspects in an integrated way, but the developed solution method required high computation times. For the TRP,
Sato et al. (2009) integrated the TRP and crew rescheduling problem based on a network flow model. The situation
is slightly better in the ARP, where Kohl et al. (2007) and
Abdelghany et al. (2008) integrated the aircraft and crew
scheduling, while Bratu and Barnhart (2006) and Petersen
et al. (2012) integrated aircraft, crew, and passenger recovery. The solutions provided in the ARP context show the
great potential of integrated approaches for obtaining global
solutions for disruption management. In general, the optimum solutions of the VRSP/ARP/TRP could be far from the
optimum integrated solution for a recovery.

7 Implications for future research
The RTVSRP provides OR scientists with an interesting and
challenging field of study. There is still much work to be done
and much to discover on the subject. The following subjects
are promising areas for future research.
The RTVSRP can also involve multiple and conflicting objectives in regulated environments. Although several
papers formulate RTVSRPs to include costs and delays
in their objective functions, very few papers use multiobjective optimization for solving the problem. Among
papers reviewed, Liu et al. (2008, 2010) are well-received
exceptions, adopting a multi-objective optimization approach
for the ARP. As multiple, often conflicting, objectives arise
naturally in the RTVSRP, multi-objective approaches, should
receive greater attention in the near future.
There is a clear trend in our review of solving the RTVRSP
to improve the operational efficiency of the transportation
service provider. Very few papers include or put emphasis
on passengers’ wishes and objectives in their formulations.
Nielsen (2008, 2011) and Berger et al. (2011a) in the TRP,
and Liu et al. (2008) and Petersen et al. (2012) in the ARP are

123

J Sched (2014) 17:541–567

recent developments in this direction. The problem is quite
complex and several aspects such as passengers’ behavior
toward serious disruptions was not properly addressed. We
are quite sure that passenger disruption management will be
a very hot research topic in the near future.
Robust and real-time scheduling are highly correlated
themes of research. However, they have been treated as isolated and completely independent problems. We believe that
the integration of these approaches into decision support systems can offer very effective tools to minimize the effects
of light as well as severe disruptions on daily operations of
transportation services. A promising field of study related
with robust scheduling is to introduce stability as a performance measure index to analyze and evaluate rescheduling
in transportation.
The use of TLN is observed in the three types of transportation services discussed in this paper, being more common in train and ARPs. Extensions of this kind of network,
called time-space networks, were developed for the off-line
scheduling processes. The time-space networks was first suggested by Hane et al. (1995) and Clarke et al. (1996) for solving an airline scheduling problem. In a time-space network, a
node represents a specific location at a particular time while
an arc corresponds to a transition in time, representing actions
that can be performed by a vehicle. The dynamics within a
location is represented by using a time-line that connects all
possible start and end events that can occur in this location.
Pull-in/out arcs to/from stations or depots, and deadheading
arcs are added to model schedules. Additionally, these networks are modeled in a cycle, which forces the solution to be
a circulation flow through the network. Kliewer et al. (2006)
adapted them to solve the bus scheduling problem. Following, Steinzen (2007) and Steinzen et al. (2010) expanded
these networks to be used in an integrated multiple depot
vehicle and crew scheduling problem. They also developed
techniques that lead to a drastic reduction of deadheading
arcs, reducing the network size in comparison to connection networks. The application of time-space networks to
the RTVRSP could generate very friendly networks, allowing the development of innovative and less complex models
with quicker solution methods.
In the last decade, constraint programming (CP) has
been widely applied to scheduling problems (Lombardi and
Milano 2012). CP has as its major principle the “deduction
of additional constraints from existing ones by logical reasoning” (Baptiste et al. 2001). Although CP is aligned of
how RTVRSP is solved in practice, we could not find any
application of CP to this problem as CP has proven very successful in scheduling, offering significant advantages such as
fast program development support, economic program maintenance, and efficient run time performance (Wallace 1996),
we believe that CP can be applied toward the development
of good and quick solution methods to the RTVRSP.

J Sched (2014) 17:541–567
Acknowledgments We are indebted to the anonymous referees for
very useful comments and criticism. This work was partially funded
by Conselho Nacional de Desenvolvimento Científico e Tecnológico
(CNPq), Brazil.

References
Abdelghany, K., Abdelghany, A., & Ekollu, G. (2008). An integrated
decision support tool for airlines schedule recovery during irregular
operations. European Journal of Operational Research, 185(2), 825–
848.
Acuna-Agost, R., Michelon, P., Feillet, D., & Gueye, S. (2011). A
MILP-based local search method for the railway rescheduling problem. Networks, 57, 69–86.
Ageeva, Y. (2000). Approaches to incorporating robustness into airline
scheduling. Master’s thesis. Massachusetts Institute of Technology,
Cambridge.
Aguiar, B., Torres, J., & Castro, A. J. M. (2011). Operational problems
recovery in airlines—a specialized methodologies approach. Lecture
Notes in Computer Science, 7026, 83–97.
Ahuja, R. K., Möhring, R. H., & Zaroliagis, C. D. (2009). Robust and
online large scale optimization: Models and techniques for transportation systems. Berlin: Springer.
Amberg, B., Amberg, B., & Kliewer, N. (2012). Increasing delaytolerance of vehicle and crew schedules in public transport by
sequential, partial-integrated and integrated approaches. ProcediaSocial and Behavioral Sciences, 20, 292–301.
Andersson, T. (2006). Solving the flight perturbation problem with meta
heuristics. Journal of Heuristics, 12, 37–53.
Andersson, T., & Värbrand, P. (2004). The flight perturbation problem.
Transportation Planning and Technology, 27, 91–117.
Almodóvar, M., & García-Ródenas, R. (2013). On-line reschedule optimization for passenger railways in case of emergencies. Computers
& Operations Research, 40(3), 725–736.
Argüello, M., Bard, J., & Yu, G. (1997). A GRASP for aircraft routing in response to groundings and delays. Journal of Combinatorial
Optimization, 5, 211–228.
Arora, S., & Barak, B. (2009). Computational complexity: A modern
approach. Cambridge: Cambridge University Press.
Babić, O., Kalić, M., Pavković, G., Dožić, S., & Čangalović, M. (2010).
Heuristic approach to the airline schedule disturbances problem.
Transportation Planning and Technology, 33(3), 257–280.
Bard, J., Yu, G., & Argüello, M. (2001). Optimizing aircraft routings in
response to groundings and delays. IIE Transactions, 33, 931–947.
Ball, M., Barnhart, C., Nemhauser, G., & Odoni, A. (2007). Air transportation: Irregular operations and control. In C. Branhart & G.
Laporte (Eds.), Handbook in OR & MS (Vol. 14, pp. 1–67). Amsterdam: Elsevier.
Baptiste, P., Pape, C., & Nuyten, W. (2001). Constraint-based scheduling: Applying constraint programming to scheduling problems. New
York: Springer-Verlag LLC.
Berger, A., Blaar, C., Gebhardt, A., Müller-Hannemann, M., & Schnee,
M. (2011a). Passenger flow-oriented train disposition. Lecture Notes
in Computer Science, 6942, 227–238.
Berger, A., Hoffmann, R., Lorenz, U., & Stiller, S. (2011b). Online
railway delay management: Hardness, simulation and computation.
Simulation, 87(7), 616–629.
Bertsimas, D., & Patterson, S. S. (2000). The traffic flow management
rerouting problem in air traffic control: A dynamic network flow
approach. Transportation Science, 34(3), 239–255.
Bisaillon, S., Cordeau, J.-F., Laporte, G., & Pasin, F. (2011). A large
neighborhood search heuristic for the aircraft and passenger recovery
problem. 4OR, A Quarterly Journal of Operations Research, 9(2),
139–157.

565
Bratu, S., & Barnhart, C. (2006). Flight operations recovery: New
approaches considering passenger recovery. Journal of Scheduling,
9, 279–298.
Brazilian Civil Aviation Agency. (2010). Anuário do Transporte
Aéreo 2010 (1st ed.). http://www2.anac.gov.br/estatistica/anuarios.
asp. Accessed 10 Apr 2010.
Borndörfer, R., Dovica, I., Nowak, I., & Schickinger, T. (2009). Robust
tail assignment. ZIB, Report 10–08.
Bunte, S., & Kliewer, N. (2009). An overview on vehicle scheduling
models in public transport. Public Transport, 1(4), 299–317.
Caprara, A., Galli, L., Kroon, L., Maróti, G., & Toth, P. (2010). Robust
train routing and online re-scheduling. In T. Erlebach & M. Lübbecke
(Eds.), 10th Workshop on algorithmic approaches for transportation modelling, optimization, and systems (ATMOS’10) (pp. 24–33).
Dagstuhl.
Cao, J.-M., & Kanafani, A. (1997a). A real-time decision support for
integration of airline flight cancellation and delays, part I: Mathematical formulation. Transportation Planning and Technology, 20,
183–199.
Cao, J.-M., & Kanafani, A. (1997b). A real-time decision support for
integration of airline flight cancellation and delays, part II: Algorithm
and computation. Transportation Planning and Technology, 20, 201–
217.
Christiansen, M., Fagerholt, K., & Ronen, D. (2004). Ship routing and
scheduling: Status and perspectives. Transportation Science, 38(1),
1–18.
Clarke, L. W., Hane, C. A., Johnson, E. L., & Nemhauser, G. L. (1996).
Maintenance and crew considerations in fleet assignment. Transportation Science, 30(3), 249–260.
Clausen, J., Larsen, A., Larsen, J., & Rezanova, N. J. (2010). Disruption
management in the airline industry: Concepts, models and methods.
Computers & Operations Research, 37(5), 809–821.
Cordeau, J.-F., Toth, P., & Vigo, D. (1998). A survey of optimization
models for train routing and scheduling. Transportation Science,
32(4), 380–404.
Corman, F., D’Ariano, A., Pacciarelli, D., & Pranzo, M. (2010).
A tabu search algorithm for rerouting trains during rail operations. Transportation Research Part B: Methodological, 44(1), 175–
192.
D’Ariano, A. (2008). Improving real-time train dispatching: Models,
algorithms and applications. Ph.D thesis. Department of Transport
& Planning, Faculty of Civil Engineering and Geosciences, Delft
University of Technology, The Netherlands.
D’Ariano, A. D., & Pranzo, M. (2009). An advanced real-time train
dispatching system for minimizing the propagation of delays in a
dispatching area under severe disturbances. Networks and Spatial
Economics, 9(1), 63–84.
D’Ariano, A., Corman, F., Pacciarelli, D., & Pranzo, M. (2008).
Reordering and local rerouting strategies to manage train traffic in
real-time. Transportation Science, 42(4), 405–419.
D’Ariano, A., Pacciarelli, D., & Pranzo, M. (2007a). A branch and
bound algorithm for scheduling trains in a railway network. European Journal of Operational Research, 183(2), 643–657.
D’Ariano, A., Pranzo, M., & Hansen, I. A. (2007b). Conflict resolution
and train speed coordination for solving real-time timetable perturbations. IEEE Transactions on Intelligent Transportation Systems,
8(2), 208–222.
Daduna, J. R., & Paixão, J. M. (1995). Vehicle scheduling for public mass transit—an overview. In Proceedings of the 6th international conference on computer-aided scheduling of public transport,
Boston, MA, pp. 76–90.
Dirksen, B. J. (2011). Disruption management in liner shipping. Master’s dissertation. Technical University of Denmark.
Dožić, S., Kalić, M., Babić, O., & Čangalović, M. (2009). Heuristic
approach to the airline schedule disturbances problem: Multi-fleet

123

566
case. In Multidisciplinary international conference on scheduling:
Theory and applications (MISTA 2009). Dublin, Ireland.
Dück, V., Ionescu, L., Kliewer, N., & Suhl, L. (2012). Increasing stability of crew and aircraft schedules. Transportation Research Part
C: Emerging Technologies, 20, 47–61.
Ernst, A. T., Horn, M., Krishnamoorthy, M., Kilby, P., Degenhardt,
P., & Moran, M. (2007). Static and dynamic order scheduling for
recreational rental vehicles at tourism holdings limited. Interfaces,
37(4), 334–341.
Eggenberg, N., Salani, M., & Bierlaire, M. (2010). Constraint-specific
recovery network for solving airline recovery problems. Computers
& Operations Research, 37(6), 1014–1026.
Fekete, S. P., Kroeller, A., Lorek, M. & Pfetsch, M. E. (2011). Disruption
management with rescheduling of trips and vehicle circulations. In
Proceedings of the 5th ASME/ASCE/IEEE Joint Rail Conference.
Pueblo, Colorado, USA.
Filar, J. A., Manyem, P., Panton, D. M., & White, K. (2007). A model for
adaptive rescheduling of flights in emergencies (MARFE). Journal
of Industrial and Management Optimization, 3(2), 335–356.
Fischetti, M., Salvagnin, D., & Zanette, A. (2009). Fast approaches
to improve the robustness of a railway timetable. Transportation
Science, 43(3), 321–335.
Freling, R., Wagelmans, A. P. M., & Paixão, J. M. P. (2001). Models
and algorithms for single-depot vehicle scheduling. Transportation
Science, 35(2), 165–180.
García-Ródenas, R., Almodóvar, M., & Parreño, F. (2009). Heuristic
algorithm for coordination in public transport under disruptions. Lecture Notes in Computer Science, 5484, 808–817.
Guarino, J., & Firestine, T. (2010). Effects of the February 2010 snowstorms on airline performance. Special Report-021, Rita Bureau of
Transportation Statistics, US Department of Transportation.
Hane, C. A., Barnhart, C., Johnson, E. L., Marsten, R. E., Nemhauser, G.
L., & Sigismondi, G. (1995). The fleet assignment problem: Solving
a large-scale integer program. Mathematical Programming, 70, 211–
232.
Herroelen, W., & Leus, R. (2004). The construction of stable project
baseline schedules. European Journal of Operational Research, 156,
550–565.
Huisman, D., & Wagelmans, A. (2006). A solution approach for
dynamic vehicle and crew scheduling. European Journal of Operational Research, 172(2), 453–471.
Huisman, D., Freling, R., & Wagelmans, A. P. M. (2004). A robust
solution approach to the dynamic vehicle scheduling problem. Transportation Science, 38(4), 447–458.
Ionescu, L., Kliewer, N., & Schramme, T. (2010). A comparison of
recovery strategies for crew and aircraft schedules. In B. Hu, K.
Morasch, S. Pickl, & M. Siegle (Eds.), Operations research proceedings 2010 (pp. 269–274). Berlin: Springer.
Jafari, N., & Zegordi, S. H. (2011). Simultaneous recovery model for
aircraft and passengers. Journal of the Franklin Institute, 348, 1638–
1655.
Jarrah, A., Yu, G., Krishnamurthy, N., & Rakshit, A. (1993). A decision support framework for airline flight cancellation and delays.
Transportation Science, 27, 266–280.
Jespersen-Groth, J., Potthoff, D., Clausen, J., Huisman, D., Kroon, L.,
Gábor, M., et al. (2009). Disruption management in passenger railway transportation. In R. K. Ahuja (Ed.), Robust and online largescale optimization (pp. 399–421). Berlin: Springer-Verlag.
Kliewer, N., Mellouli, T., & Suhl, L. (2006). A time-space network based exact optimization model for multi-depot bus scheduling. European Journal of Operational Research, 175(3), 1616–
1627.
Kohl, N., Larsen, A., Larsen, J., Ross, A., & Tiourine, S. (2007).
Airline disruption management—perspectives, experiences and outlook. Journal of Air Transport Management, 13(3), 149–162.

123

J Sched (2014) 17:541–567
Kramkowski, S., Kliewer, N., & Meier, C. (2009). Heuristic methods for
increasing delay-tolerance of vehicle schedules in public bus transport. In Proceedings of the metaheuristic international conference
VIII. Hamburg, Germany.
Kroon, L. G. & Huisman, D. (2011). Algorithmic support for disruption
management at Netherlands Railways. Econometric Institute Report.
EI 2011–06. Econometric Institute, Erasmus University, Rotterdam.
Lan, S., Clarke, J.-P., & Barnhart, C. (2006). Planning for robust airline
operations: Optimizing aircraft routings and flight departure times
to minimize passenger disruptions. Transportation Science, 40(1),
15–28.
Lee, L. H., Lee, U. C., & Tan, Y. P. (2007). A multi-objective genetic
algorithm for robust flight scheduling using simulation. European
Journal of Operational Research, 177, 1948–1968.
Leus, R., & Herroelen, W. (2005). The complexity of machine scheduling for stability with a single disrupted job. Operations Research
Letters, 33(2), 151–156.
Li, J. Q., Borenstein, D., & Mirchandani, P. B. (2008). Truck schedule
recovery for solid waste collection in Porto Alegre. International
Transactions in Operational Research, 15, 565–582.
Li, J. Q., Mirchandani, P. B., & Borenstein, D. (2004). Parallel auction
algorithm for bus rescheduling. In Proceedings of ninth international
conference on computer-aided scheduling of public transport. San
Diego, CA.
Li, J. Q., Mirchandani, P. B., & Borenstein, D. (2007a). The vehicle
rescheduling problem: Model and algorithms. Networks, 50(3), 211–
229.
Li, J., Borenstein, D., & Mirchandani, P. B. (2007b). A decision support
system for the single-depot vehicle rescheduling problem. Computers & Operations Research, 34(4), 1008–1032.
Li, J. Q., Mirchandani, P. B., & Borenstein, D. (2009). A Lagrangian
heuristic for the real-time vehicle rescheduling problem. Transportation Research Part E: Logistics and Transportation Review, 45(3),
419–433.
Liu, T. K., Chen, C. H., & Chou, J. H. (2010). Optimization of short-haul
aircraft schedule recovery problems using a hybrid multiobjective
genetic algorithm. Expert Systems with Applications, 37(3), 2307–
2315.
Liu, T. K., Jeng, C. R., & Chang, Y. H. (2008). Disruption management of an inequality-based multi-fleet airline schedule by a multiobjective genetic algorithm. Transportation Planning and Technology, 31(6), 613–639.
Lombardi, M., & Milano, M. (2012). Optimal methods for resource
allocation and scheduling: A cross disciplinary survey. Constraints,
17(1), 51–85.
Løve, M., Sørensen, K. R., Larsen, J., & Clausen, J. (2002). Disruption
management for an airline—rescheduling of aircraft. In EvoWorkshops 2002, LNCS 2279 (pp. 315–324). Berlin, Heidelberg: SpringerVerlag.
Luethi, M., Medeossi, G., & Nash, A. (2009). Structure and simulation
evaluation of an integrated real-time rescheduling system for railway
networks. Networks and Spatial Economics, 9(1), 103–121.
Mathaisel, D. (1996). Decision support for airline system operations control and irregular operations. Computers and Operations
Research, 23, 1083–1098.
Mascis, A., & Pacciarelli, D. (2000). Machine scheduling via alternative
graphs. Working paper, Dipartamento di Informatica e Automazione,
Università degli Studi Roma, Tré, Italy.
Mascis, A., & Pacciarelli, D. (2002). Job shop scheduling with blocking
and no-wait constraints. European Journal of Operational Research,
143(3), 498–517.
Meng, X., Jia, L., & Qin, Y. (2010). Train timetable optimizing and
rescheduling based on improved particle swarm algorithm. Transportation Research Record: Journal of the Transportation Research
Board, 2197(1), 71–79.

J Sched (2014) 17:541–567
Mukherjee, A., & Hansen, M. (2009). A dynamic rerouting model for air
traffic flow management. Transportation Research Part B: Methodological, 43(1), 159–171.
Nielsen, L. K. (2008). A decision support framework for rolling stock
rescheduling. Technical report ARRIVAL-TR-0158.
Nielsen, L. K. (2011). Rolling stock rescheduling in passenger
railways—applications in short-term planning and in disruption
management. PhD thesis. Erasmus University, Rotterdam, The
Netherlands.
Norio, T., Yoshiaki, T., Noriyuki, T., Chikara, H., & Kunimitsu, M.
(2005). Train rescheduling algorithm which minimizes passengers’
dissatisfaction. Lecture Notes in Computer Science, 3533, 829–838.
Petersen, J. D., Gustaf, S., Johnson, E. L., Clarke, J. P., & Shebalov,
S. (2012). An optimization approach to airline integrated recovery
system. Transportation Science, 46(4), 482–500.
Potthoff, D., Huisman, D., & Desaulniers, G. (2010). Column generation with dynamic duty selection for railway crew rescheduling.
Transportation Science, 44(4), 493–505.
Raheja, A. S., & Subramaniam, V. (2002). Reactive recovery of job
shop schedules—a review. International Journal of Advanced Manufacturing Technology, 19, 756–763.
Rangsaritratsamee, R., Ferrel, W. G., & Kurtz, M. B. (2004). Dynamic
scheduling that simultaneously considers efficiency and stability.
Computers & Industrial Engineering, 46, 1–15.
Rosenberger, J. M., Johnson, E. L., & Nemhauser, G. L. (2003). Rerouting aircraft for airline recovery. Transportation Science, 37(4), 408–
421.
Sahin, I. (1999). Railway traffic control and train scheduling based on
inter-train conflict management. Transportation Reseacrh: Part B,
33, 511–534.
Sato, K., & Fukumura, N. (2012). Real-time freight locomotive
rescheduling and uncovered train detection during disruption. European Journal of Operational Research, 221, 636–648.
Sato, T., Shuichiro, S., Morita, T., Ueki, N. & Murata, T. (2009). Crew
and vehicle rescheduling based on a network flow model and its
application to a railway train operation. IAENG International Journal
of Applied Mathematics, 39(3), IJAM_39_2.
Sato, T., Tomiyama, T., Morita, T. & Murata, T. (2010). Lagrangian
relaxation method for network flow modeled crew and vehicle
rescheduling. In Proceedings of the 2nd international conference
on advanced computer control (ICACC) (pp. 403–408).
Serafini, P., & Ukovich, W. (1989). A mathematical model for periodic
scheduling problems. SIAM Journal on Discrete Mathematics, 2(4),
550–581.
Steinzen, I. (2007). Topics in integrated vehicle and crew scheduling in
public transit. PhD thesis. University of Paderborn, Germany.
Steinzen, I., Gintner, V., Suhl, L., & Kliewer, N. (2010). A time-space
network approach for the integrated vehicle-and crew-scheduling
problem with multiple depots. Transportation Science, 44(3), 367–
382.
Strotmann, C. (2007). Railway scheduling problems and their decomposition. Ph.D. thesis. Universität Osnabrück, Germany.

567
SunTran (2011, July). SunTran Monthly report.
Swedish Transport Administration. (2011). Annual Report 2011. http://
publikationswebbutik.vv.se/upload/6814/2012_083_swedish_
transport_administration_annual_report_2011.pdf. Accessed 10
Apr 2010.
Teodorovic, D., & Guberinic, S. (1984). Optimal dispatching strategy on
an airline network after a schedule perturbation. European Journal
of the Operational Research, 15, 178–182.
Thengvall, B., Bard, J. F., & Yu, G. (2000). Balancing user preferences
for aircraft schedule recovery during irregular operations. IIE Transactions, 32, 181–193.
Thengvall, B., Bard, J. F., & Yu, G. (2003). A bundle algorithm approach
for the aircraft schedule recovery problem. Transportation Science,
37, 392–407.
Thengvall, B., Yu, G., & Bard, J. F. (2001). Multiple fleet aircraft schedule recovery following hub closures. Transportation Research Part
A, 35, 289–308.
Törnquist, J. (2006). Computer-based decision support for railway traffic scheduling and dispatching: A review of models and algorithms.
In Proceedings of the 5th workshop on algorithmic methods and
models for optimization of railways (ATMOS 2005).
Tornquist, J., & Persson, J. (2007). N-tracked railway traffic rescheduling during disturbances. Transportation Research Part B:
Methodological, 41(3), 342–362.
Veelenturf, L. P., Potthoff, D., Huisman, D., & Kroon, L. G. (2012).
Railway crew rescheduling with retiming. Transportation Research
Part C: Emerging Technologies, 20(1), 95–110.
Wallace, M. (1996). Practical applications of constraint programming.
Constraints: An International Journal, 1, 139–168.
Weide, O., Ryan, D., & Ehrgott, M. (2009). An iterative approach to
robust and integrated aircraft routing and crew scheduling. Computers & Operations Research, 37, 833–844.
Yan, S., & Yang, D.-H. (1996). A decision support framework for
handling schedule perturbations. Transportation Research Part B:
Methodological, 30, 405–419.
Luo, S., & Yu, G. (1997). On the airline schedule perturbation problem
caused by the ground delay program. Transportation Science, 31(4),
298–311.
Zegordi, S. H., & Jafari, N. (2010). Solving the airline recovery problem
by using ant colony optimization. International Journal of Industrial
Engineering & Production Research, 21(3), 121–128.
Zwaneveld, P. J., Kroon, L. G., Romejinn, H. E., Salomon, M., DauzerePeres, S., van Hoesel, C. P. M., et al. (1996). Routing trains through
railway stations: Model formulation and algorithm. Transportation
Science, 30, 181–194.
Zwaneveld, P. J., Kroon, L. G., & van Hoesel, C. P. M. (2001). Routing
trains through a railway station based on a node packing model.
European Journal of Operations Research, 128, 14–33.

123

Annals of Operations Research 136, 229–257, 2005
c 2005 Springer Science + Business Media, Inc. Manufactured in The Netherlands.


Locating Active Sensors on Traffic Networks
M. GENTILI ∗
mgentili@unisa.it
Computing Science Department, University of Salerno, Via Ponte Don Melillo, 84084, Fisciano (Sa), Italy
P.B. MIRCHANDANI
pitu@sie.arizona.edu
System and Industrial Engineering Department, ATLAS Research Center, The University of Arizona, Tucson,
AZ 85721-0020, USA

Abstract. Sensors are used to monitor traffic in networks. For example, in transportation networks, they
may be used to measure traffic volumes on given arcs and paths of the network. This paper refers to an
active sensor when it reads identifications of vehicles, including their routes in the network, that the vehicles
actively provide when they use the network. On the other hand, the conventional inductance loop detectors
are passive sensors that mostly count vehicles at points in a network to obtain traffic volumes (e.g., vehicles
per hour) on a lane or road of the network.
This paper introduces a new set of network location problems that determine where to locate active
sensors in order to monitor or manage particular classes of identified traffic streams. In particular, it focuses
on the development of two generic locational decision models for active sensors, which seek to answer these
questions: (1) “How many and where should such sensors be located to obtain sufficient information on
flow volumes on specified paths?”, and (2) “Given that the traffic management planners have already located
count detectors on some network arcs, how many and where should active sensors be located to get the
maximum information on flow volumes on specified paths?”
The problem is formulated and analyzed for three different scenarios depending on whether there are
already count detectors on arcs and if so, whether all the arcs or a fraction of them have them. Location of an
active sensor results in a set of linear equations in path flow variables, whose solution provide the path flows.
The general problem, which is related to the set-covering problem, is shown to be NP-Hard, but special cases
are devised, where an arc may carry only two routes, that are shown to be polynomially solvable. New graph
theoretic models and theorems are obtained for the latter cases, including the introduction of the generalized
edge-covering by nodes problem on the path intersection graph for these special cases. An exact algorithm
for the special cases and an approximate one for the general case are presented.
Keywords: location theory, sensors, traffic networks, network covering problems, linearly independent
equations

1.

Introduction

Sensors may be classified as “passive” or “active” depending on the level of information
that a vehicle provides en-route from its point of origin to its destination. For example,
the inductance loop detector is a passive sensor in view of the fact that the vehicle does
not actively generate a signal on its location or speed; when it passes over the inductance
∗

Corresponding author.

230

GENTILI AND MIRCHANDANI

loop embedded in the road pavement the change in the magnetic field sends a electrical
signal that indicates the vehicle passage and, from the shape of the electrical signal,
an approximate measure of the vehicle speed. Generally, such loop detectors are used
to count vehicles in order to give traffic volumes (e.g., vehicles per hour) on a lane
or road of a network. On the other hand, for automatic toll collection systems, vehicles
actively provide an “identification”, that may be picked up by roadside (or lane overhead)
readers in order to charge an appropriate toll for usage of some facility. The underlying
technology for active sensors could be based on microwave transmission from vehicle
to reader, or on some sort of installed barcode on the vehicle that a laser-based reader
decodes, or cameras that read vehicles-specific characters in acquired visual images, or
some other sensor technology and other sensor media.
In general, whether a sensor is active or passive, a sensor obtains an “image” of
vehicle/traffic flow (using sensing media such as, electrical, radar, laser, microwave,
audio, etc.) and processes it to identify characteristics of the vehicle (car, bus, truck, etc.)
or the traffic flow. Recognition of a bus or a truck could provide information on its path.
Recognition of a vehicle’s license plate could provide its origin and/or destination. As we
mentioned above, “images” could also be coded transmission from vehicles that provide
additional information and the sensors (readers) de-code such transmission to obtain,
for example, freight information from trucks (good carried, its origin, its destination,
container weight, custom clearance, fees paid, etc.), route/schedule information from
buses (route number, schedule number, passenger count, etc.) and account information
from electronic toll tags (tolls paid, credit remaining, vehicle ID, etc.). In this paper, we
will refer to active sensors also as path-ID sensors, which effectively give the vehicle ID
and their paths. Passive sensors will be characterized by the processing images at points
on lanes to count vehicles or measure traffic flow, or on nodes where vehicles may be
tracked in a visual image to measure turning ratios.
For both active and passive sensors, a new set of location problems arise on where
to locate such sensors to monitor or manage the particular class of traffic detected. In
this paper, we will consider some type of generic sensors and their locations that address
a large number of sensor location problems. The paper is focused, in particular, on the
development of two generic locational decision models for active sensors, which seek
to answer these questions: (1) “How many and where should path-ID sensors be located
to obtain sufficient information on flow volumes on paths?”, and (2) “Given that the
traffic management planners have already located count detectors (counting sensors) on
some network arcs, how many and where should path-ID sensors be located to get the
maximum information on flow volumes on paths?”
The paper is organized as follows. The rest of this section briefly describes kinds
of sensors that lead to our research questions. Sections 2 and 3 define and model specific
scenarios addressed for locating path-ID sensors on a network. Polynomial instances
are presented in Section 4 and a greedy-type heuristic for the general case is given in
Section 5.
We now discuss the two new types of sensors that can be located, in addition to
the conventional counting sensors, to measure traffic flow: (i) sensors on arcs that detect

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

231

Figure 1. A network of 7 nodes and 8 arcs, having flows on four paths from origin node O to destination
node D. The number label on each arc denotes the flow volume on that arc.

flow volumes on paths (path-ID sensors) and (ii) sensors on nodes that detect turning
ratios (image sensors).
1.1. Path-ID sensors
Flow on an arc contains flow from several paths; we assume that when locating a path-ID
sensor on an arc of the network we can measure the flow volumes of each path to which
that arc belongs. On the simple network in figure 1 there are four paths that have a common origin O and a common destination D. The number labeled on each arc is the total
flow on that arc. On arc (1, 3), for example, there are 22 units of flow (such information
may be available through counting sensors). On this arc, there are two paths, path 1 and
path 2. We assume that by locating a path-ID sensor on arc (1, 3), for example, we can
measure the flow volumes of path 1 and of path 2, that is, we know how the 22 units
of flow on that arc are decomposed. For such a model to be applied, we must assume,
active identification is provided by the class of vehicles been monitored. In many countries/states/cities, special vehicles such as commercial trucks, buses, emergency vehicles,
and trucks carrying hazardous material have electronic “tags” or transponders installed
on them that transmit some sort of identification, from which one can obtain its planned
path through the network.
1.2. Image sensors
Video vehicle detection systems provide non-intrusive vehicle detection through machine vision. Such systems allow users to place virtual detectors in the field of view,

232

GENTILI AND MIRCHANDANI

rather than physically placing the detectors on the roadway pavement, providing flexible
detector placement. Video systems overcome the maintenance and reliability concern of
conventional inductive loop technology and provide detection regardless of pavement
conditions. However, the performance of video-based detection systems depends on visual conditions (daylight, dark, reflection, etc.). An image can be obtained from either
(i) a fixed camera mounted on a tall building or a pole or (ii) a moving camera installed
on an air-borne platform such as a helicopter. Processing the images obtained by fixed or
mobile cameras, it is possible to recognize vehicles on the scene and movement of these
vehicles. In this way, for example, by locating a fixed video camera that takes images of
the traffic situation at an intersection of the network we can estimate the turning ratios
at the intersection. For example, locating an image sensor on node 3 of the network in
figure 1, we can measure the turning ratios at this node. That is, we are able to measure the
proportion of flow that goes to the out-going arcs (3, 4) and (3, 5) from each in-coming
arc (1, 3) and (2, 3).
Since the problems modeled and analyzed are new, there is no previous literature on
them. There are a few sensor location problems, however, that are related to estimating
traffic volumes from origins (O) to destinations (D) for a general network where vehicles
use shortest routes from O to D. Here sensors determine traffic volumes on arcs and the
goal of the problems is to update a prior OD matrix to obtain a new OD matrix that
“results” in traffic volumes closer to the measured values; by “resulting” we mean that
the underlying model assumes vehicles choose shortest routes and a traffic equilibrium
results where used routes have equal travel times (see, e.g., Wardrop, 1952; Cascetta and
Nguyen, 1988). In this scenario, Lam and Lo (1990) proposed some heuristic procedures
to define where to locate sensors on the arcs of the network in order to obtain a better
estimate of the OD matrix. Yang, Iida, and Sasaki (1991) proposed the so-called “OD
covering rule” to locate sensors on arcs to bound the OD estimation error. Yang and
Zhou (1998) defined three other rules to locate sensors on arcs to better estimate the
OD matrix and proposed some heuristic procedures. Bianco, Confessore, and Reverberi
(2001) and Bianco, Confessore, and Gentili (2003) studied a combinatorial optimization
problem (the Sensor Location Problem) to locate sensors on nodes to get information on
arc volumes on the non-monitored portion of the network. The models developed in this
paper may be applied in such scenarios if all vehicles are equipped with active sensors
and in the resulting equilibrium most vehicles from an O to D use only a few known
paths. (Such an application may arise in the future, only if drivers feel comfortable with
use of active sensors and are not concerned about “big brother” monitoring them.)

2.

Locating path-ID sensors on arcs

In this section we describe the general problem addressed. First we need some additional
notation and terminology.
Let R = (N , A) be a graph representing the traffic network, where the set N of nodes
has size |N | = n and the set of arcs A has size |A| = m. A path Y = {a1 , a2 , . . . , as } is a

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

233

sequence of arcs ai ∈ A such that ai = (v, w) and ai+1 = (w, z), ∀i = 1, . . . , s −1. Since
flow on an arc contains flow from several paths, from different origin-destination pairs,
we need to define total flow in terms of path flows. We will simply let this total flow be
decomposed into path flows yi on path Yi , i = 1, . . . , p, where p is the number of paths
used in the network. We will let f a be the total flow on arc a ∈ A for the time interval being
considered (a counting sensor on arc a measures f a ). Let Y = {Y1 , Y2 , . . . Y p } be the set
of all the paths on the network. Given an arc a ∈ A, we denote by Ya = {Yi : a 
∈ Yi } the
set of paths that contain that arc. Given a subset of arcs A ⊆ A, the set Y A = a∈A Ya
is the set of the paths that contain at least one arc in the set A , and we say this set is
covered by A . Let B = {bi j }, i ∈ {1, 2, . . . , m}, j ∈ {1, 2, . . . , p} be the m × p arc/paths
incidence matrix, that is bi j = 1 if arc ai belongs to the path Y j and bi j = 0 otherwise.
For example, the i-th column of matrix B, B i = [0, 1, 1, 0, 1] denotes a path with arcs
a2 , a3 , a5 in a five-arc network consisting of arcs A = {a1 , a2 , a3 , a4 , a5 }. The index set
of columns, i = 1, 2, . . . , p, will also be denoted by C and the i-th column of B will be
denoted by B i .
Our aim is to determine the flow volume y j of each path Y j , j = 1, . . . , p, on
the network by locating path-ID sensors on the arcs of the network. We recall that by
locating a path-ID sensor on an arc of the network we are able to measure the flow of the
paths to which that arc belongs. In our notation, it means that locating a path-ID sensor
on arc a ∈ A, such that a ∈ Yi ∩ Y j ∩ Yk we can know the flows yi , y j , yk .
Figure 2(a) shows a subnetwork of n = 10 nodes and m = 13 arcs, defined by p = 8
given paths on which there is possible flow. With each arc ai ∈ A in the subnetwork,
the set of the paths Yai is associated. For example with arc a8 , the set Ya8 = {Y3 , Y5 }
denotes the set of paths that contains arc a8 . In figure 2(b) the number labeled on each arc
denotes the total volume of flow on that arc. For example on arc a8 there is a flow of 21
units. We can associate with each arc a linear equation decomposing the flow volumes
on the arc into flows on paths. For example with arc a8 , we can associate the equation
y3 + y5 = 21.
Let counting sensors be located on all the arcs of the network. In this case, we know
the entire vector f = { f 1 , f 2 , . . . , f m } of the arc flows. To know the path flow volumes
we should solve the system of linear equations:
By = f

(1)

Let rank(B) = k be the rank of matrix B. If k = p and m ≥ p then any p independent
arc flows will allow us to compute unique p path flows {y1 , y2 , . . . , y p }.
The more complex, and interesting problem, is when k < p, in which case our new
sensors need to be located to determine the path flows if they are determinable (i.e., if a
unique feasible set of path flows exists). Thus, from here on, we assume min(m, p) = p
and rank(B) = k < p. Under this assumption, system (1) does not have a unique
solution. This means that even by locating counting sensors on all arcs of the network
we may not know (considering all data to be consistent) the flow volume of each path
Y j , j = 1, . . . , p.

234

GENTILI AND MIRCHANDANI

Figure 2. A network of 10 nodes and 13 arcs with flows on 8 paths. Variables Yi on each arc denote the paths
that use the arc.

In the example of figure 2, the flows on paths are given by solving the following
system of linear equations:
y1
a1
1
a2  0

a3  0

a4  0

a5  0

a6  1

a7  0

a8  0
a9 
0
a10 
0
a11 
1
a12  0
a13 0


y2
1
0
0
0
0
1
0
0
0
0
0
0
1

y3
0
1
0
0
0
0
0
1
0
0
0
1
0

y4
0
1
0
0
0
0
0
0
1
0
0
1
0

y5
0
0
1
0
0
0
0
1
0
1
0
0
0

y6
0
0
1
0
0
0
0
0
1
1
0
0
0

y7
0
0
0
1
1
0
1
0
0
0
1
0
0

y8

 
0
12
 18 
0

 
0     10 
 y1
 
1
 10 
  y2   
1     10 
 y   
0   3   12 
 y   
1   4  =  10 
 y   
0   5   21 
 y   
0  6  7 
y7
 10 
0
 y
 

 7 
8
0
 

 18 
0
1
15

(2)

The rank of the matrix of system (2) is rank(B) = 6, and, the number of variables
(path flows) is p = 8. Therefore, the system does not have a unique solution. Indeed, by
setting the value of p − rank(B) = 2 variables, we can determine the values of all the
other variables. It means that if we somehow know the exact flows of two paths of the
network, we can find the flow volumes of all the remaining paths (assuming that data
are consistent). In the example, if we can measure, by locating path-ID sensors on some
arcs of the network, the flow volumes, for instance y1 , y4 , we can determine the volumes
of all the remaining paths by using (2). That is, by locating path-ID sensors on arcs we
add to the system (1) a set of new linear equations in order to have a unique solution for
the path flows.

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

235

In the example, if we locate a sensor on arc a1 , we may get the following two new
equations to the system: y1 = 2 and y2 = 10. The rank of the new matrix, (15 × 8), B  =
B

( u 1 ), obtained by adding to matrix B the two new rows u 1 = (1, 0, 0, 0, 0, 0, 0, 0) and
u2

u 2 = (0, 1, 0, 0, 0, 0, 0, 0), is now rank(B  ) = 7, and we do not get a unique solution.
Note that, knowing y1 and y2 we can indirectly determine some of the other path volumes:
y7 = f a11 − y1 on arc a11 and y8 = f a7 − y7 on arc a7 .
If we locate two sensors on the network, one on arc a1 and one on arc a4 , we add
4 new equations to the original system (1) and the new (17 × 8) matrix B  is such that
rank(B  ) = 7, thus, again, these four new equations are still insufficient to determine all
path flows. In summary, the question we want to answer is:
Question 1. What is the minimum number of path-ID sensors to locate on the network,
and where should they be located in order to add new equations to system (1) that result
in the new system having full rank (i.e., a unique solution)?
Note that, in the above example by locating two path-ID sensors, one on arc a4 and one on
arc a8 we get 4 new equations and the new matrix becomes full rank. This is an optimal
solution for the problem. Also, we assumed the knowledge of the flows on every arc of
the network. This may not be true in all scenarios. Indeed, in general, we might know
flows on only some arcs of the network where counting sensors are already located. That
is, we suppose that a subset f 1 = {ai1 , ai2 , . . . , aik }, i k < m, of arc flows corresponding
to the arc subset A1 ⊆ A are known, resulting in the system:
B1 y = f 1

(3)

where B 1 is a submatrix B obtained by the set of equations associated to the arcs in A.1
The question in this case is:
Question 2. What is the minimum number of path-ID sensors to locate on the network
and where should they be located in order to add new equations to system (3) that results
in the new system having a unique solution?
We refer to this problem as the Sensor Location on Arc Problem (SLAP). In order to
better understand the complexity we distinguish three different scenarios:
• Zero count information: we do not know the flow volume on any arc;
• Total count information: we know the flows on each arc of the network (i.e., we have
system (1)); and
• Partial count information: we know the flows on some arcs of the network (i.e., we
have system (3)).
In the next section we give a model formulation for the problem and we will refer again
to these scenarios as SLAP-zero SLAP-tot and SLAP (or SLAP-par) respectively.

236

3.

GENTILI AND MIRCHANDANI

Formulations and analyses of problem scenarios

In this section we formulate and analyze each scenario (Zero, Total and Partial count information) in order to better characterize the feasible region of the problem. The problem
for the general case is NP-hard as proved in Gentili (2002). We give here model formulations for the three different scenarios. Some polynomial instances and a polynomial
algorithm are given in Section 4.

3.1. Zero count information: SLAP-zero
In case of zero count information, we do not know any arc flow and we need to locate
path-ID sensors to determine all path flows.
Consider again the network of figure 2. Suppose we locate a path-ID sensor on arc
a1 and determine exactly the path volumes of Y1 and Y2 . Then, if we knew total flow on
arc a11 we can find indirectly the volume on path Y7 , but in this case we do not know
the total flow on arc a11 . Therefore, in the case of zero count information, the number
of path volumes to be directly measured is equal to the number of paths. It follows that
a feasible solution for SLAP-zero is a set of arcs that covers all the paths. We then have
the following definition.
Definition 1. A set A ⊆ A of arcs is feasible for SLAP-zero if Y A = Y
In this case the optimization problem has a set-covering formulation. We define the binary
variable xi = (0, 1), xi = 1 if a path-ID sensor is located on arc ai ∈ A and 0 otherwise.
The minimum number of path-ID sensors required to determine all the path flows is the
solution of the following problem:
[SLAP-zero]

min

m


xi

(4)

i=1

subject to
m


bi j xi ≥ 1

j = 1, . . . , p

(5)

i=1

xi ∈ {0, 1}

i = 1, . . . , m

(6)

The objective function (4) requires us to locate the minimum number of path-ID sensors
on the arcs of the network. Constraints (5) state that the location of the path-ID sensors
must cover all the paths of the network.

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

237

3.2. Total count information: SLAP-tot
In the example of figure 2 we saw that, in the case of total count information, we need to
measure directly only a subset of path volumes; the others can be determined through the
dependencies among the arc flow equations. We also observed that the number of path
flow volumes to be directly monitored is equal to the number of free variables of system
(1). More formally, if the number of paths is p and the rank of the incidence matrix is
rank(B) = k, then we need to measure directly at least p − k variables. Obviously, not
every set of p − k paths to be measured requires the same number of path-ID sensors.
Our aim is to choose, among all the subsets of p − k paths, that subset which requires
the minimum number of path-ID sensors.
Let us observe some “wrong” choices of p − k variables. That is, there are some
sets of p − k variables that, if directly measured, are not enough to solve the system.
In this example, it turns out that if flows on paths Y1 , Y4 are measured, all other paths
are known. On the other hand, measuring directly, say paths Y1 and Y2 (through a pathID sensor on arc a1 ) we do not know indirectly all the other path flows. This implies
that there are some “wrong” choices of arcs too. The question is, “Which are the good
choices of arcs that result in a feasible subset of arcs for SLAP-tot, that is those arcs that
produce a unique solution to system (1)?”. In order to answer this question we need to
characterize first the good set of variables, those subsets of p − k path flows which, if
directly monitored, allow us to determine all other path flows. Lemma 1 to follow will help
us characterize a right subset of path flows. We refer this subset as rank-filling subset of
variables.
At this point, we need some additional notation and definitions. Let H = {Yi1 , Yi2 ,
. . . , Yih }, H ⊆ Y, be a subset of paths whose flows are yi1 = f i1 , yi2 = f i2 , . . . , yih = f ih .
We associate with H the set of p-dimensional row vectors U H = {u i1 , u i2 , . . . , u ih } where
u i j = (0, 0, . . . , 	

1 , . . . , 0, 0). Let f H denote the column vector ( f i1 , f i2 , . . . , f i p ).
ij

Definition 2. Given system (1) of linear equations, where matrix B is an m × p matrix
and rank(B) = k < p, a subset of variables H = {yi1 , yi2 , . . . , yih } is rank-filling for
the system if the following two conditions are satisfied:
(i) the size of the set is such that |H | = h ≥ p − k;
(ii) the system ( UBH )y = ( ffH ) has a unique solution.
Thus, a rank-filling set of variables is a “good” set of variables to solve our problem.
From Definition 2 it follows directly that a subset of variables of size h < p −k cannot be
a rank-filling subset for the system. Note that any set of p −k free variables for system (1)
is a minimum rank-filling set of variables for that system, and vice versa. This is because
each subset H of free variables contains h = p − k elements, and fixing the value of
the free variables is equivalent to adding to the system the set of linearly independent

238

GENTILI AND MIRCHANDANI

equations U H y = f H . Also, note that there is a one-to-one correspondence among sets
of free variables (i.e., minimum rank filling sets) of a system of linear equations and
the maximal linearly independent columns of the matrix of the system. Let us illustrate
this by an example. Consider system (1) with matrix B of rank k < p. Without loss
of generality, let B = ( B1 B2 ), y = ( yy12 ), B1 y1 + B2 y2 = f . If B1 is a non-singular
matrix with rank k, then y2 is the set of free variables with respect to matrix B1 . Hence,
all the minimum rank-filling sets of variables of a system can be obtained by enumerating
all the maximal linearly independent sets of columns of matrix B. This correspondence
holds for every rank-filling set (not necessarily minimum) of variables as stated by the
following lemma, whose detailed proof is given in Gentili (2002).
Lemma 1. A set of h variables H = {Yi1 , Yi2 , . . . , Yih }, corresponding to columns of B
with index in C H = (i 1 , i 2 , . . . , i h ), h ≥ p − k, rank(B) = k, is rank-filling for system
(1) if and only if the columns whose index is in C\C H are linearly independent.
The corollary below follows directly.
Corollary 1. If H is a rank-filling set of variables such that |H | = h > p − k there
exists a subset H  ⊆ H such that H  is a rank-filling set and |H  | = p − k.
The rank-filling sets of variables can be characterized by Lemma 1. In the example of
figure 2, we see that by locating path-ID sensors on arcs a4 and a8 we can measure the
flows {y3 , y5 , y7 , y8 }. Indeed, this set is a rank-filling set of variables, and the remaining set of columns of B are linearly independent. Clearly, we want to locate path-ID
sensors on arcs such that the set of variables we directly monitor is a rank-filling set.
We have, in this way, characterized the feasible solution (as a set of arcs) for problem
SLAP-tot.
Definition 3. A subset of arcs A ⊆ A is feasible for SLAP-tot if the corresponding set
of variables Y A ⊆ Y is a rank-filling set for system (1).
By Corollary 1, each rank-filling set of variables contains a minimum rank-filling set,
therefore if A ⊆ A is a feasible set of arcs for SLAP-tot, each A ⊇ A is feasible too,
because Y A ⊇ Y A . In the example of figure 2, the subset A = {a1 , a4 } ⊆ A is feasible
for SLAP-tot. All the subsets A ⊇ A are also feasible. Since we are looking for the
set of minimum size, we can focus only on those feasible subsets of arcs covering a
minimum rank-filling set of variables.
We can now state the general model formulation for SLAP-tot that is effectively a
set covering formulation with additional constraints. Let us define by C p−k the family
of subsets of indices of the columns of matrix B that correspond to rank-filling sets of
variables for system (1) and whose size is p − k, and let S be any element of C p−k . Then
SLAP-tot can be modelled as follows.

239

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

[SLAP-tot]
min
subject to

m

i=1
m


xi
bi j xi ≥ 1

(7)
∀j ∈ S

(8)

i=1

S ∈ C p−k
xi ∈ {0, 1}

i = 1, . . . , m

(9)
(10)

The objective function (8) is the same as that of SLAP-zero. Constraints (9) and (10)
require that each set of path-ID sensors located on the network measure at least one
subset of paths containing a minimum rank-filling set.
Observe that the definition of the rank-filling set of variables of the system is
useful from a model formulation point of view. Indeed, checking if a set of variables
is rank-filling requires a polynomial number of Gaussian eliminations. We will see in
Section 4 that the concept of rank-filling set of variables will be useful for the definition
of the polynomial instances of the three different scenarios (zero, total and partial count
information) of the problem.

3.3. Partial count information: SLAP-par
SLAP-par, or simply SLAP, refers to the general problem of locating path-ID sensors
when some arc flows are known. Analysis of SLAP-zero in Section 3.1 was useful to
introduce the set-Covering formulation of such problems, and analysis of SLAP-tot in
Section 3.2 to introduce the concept of minimum rank-filling subsets. We now further
the analysis and integrate the results to study the general SLAP problem.
In case of partial information, recall the system (3) of linear equations, where the
dimension of the matrix B 1 is m 1 × r , m ≤ m 1 . For example, consider again the graph
in figure 2. Let us suppose we know only the total flow volume on two arcs a1 and a11 .
That is, we have the following system of two linear equations:
(a1 )
(a11 )

y1 + y2 =
y1 + y7 =

f a1
f a11

(11)

The matrix of system (11) has rank of 2 and the number of variables is 8 (variables
y1 , y2 , y7 have coefficient equal to 1 in (11), variables y3 , y4 , y5 , y6 , y8 have coefficient equal to zero). Then, as in the case of SLAP-tot, to determine all the path flows,
we must monitor a subset of paths and derive the other volumes from the arc flow
dependencies (11) of the system. Also, in this case, we need to characterize a set
of paths which, if directly monitored, allow us to determine all the other path
flows.

240

GENTILI AND MIRCHANDANI

In this example we have to monitor directly at least p − r (B 1 ) = 8 − 2 = 6 paths to
determine all the other path volumes. As in SLAP-tot, the sets of variables to be measured
for SLAP are the rank-filling sets related to the system of linear equation (system (11)
for the illustrative example or system (3) for the general case).
We can obtain a model formulation for the SLAP which is identical to the formulation obtained for SLAP-tot. However, the rank-filling sets for the case of partial count
information have a defined structure, and it is possible to give an alternative model formulation that better characterizes the structure of the rank-filling sets of variables, and
includes the SLAP-zero and SLAP-tot formulations as special cases.
In the example of figure 2, it is easy to see that for system (11) there are only
three rank-filling sets of minimum size p − r (B 1 ) = 6. These sets contain the four
variables yi , i = 3, 4, 5, 6 and they differ only with respect to the remaining two
variables chosen among y1 , y2 , y7 . That is, they contain all the variables having zero
coefficients in equations (11) and two out of three among the other variables in (11)
with coefficient 1. This is a common structure of minimum rank filling sets in case
of partial information. We will state these observations in Lemma 2 to
follow.
Given the system of equation (3), we partition the set Y of variables into two subsets
Y 0 and Y 1 representing respectively the variables with zero coefficients in the system
and the variables with non-zero coefficient in the system. Consider the reduced system:
B̄ ȳ = f 1

(12)

obtained from (3) by eliminating all the zero columns (that is, those columns corresponding to the variables in Y 0 ). Clearly, r (B 1 ) = r ( B̄) and the Lemma 2 follows.
Lemma 2. Each minimum rank-filling set for system (3) is obtained by a minimum
rank-filling set of system (12) plus the set Y 0 of variables.
Corollary 2. A subset of arcs A ⊆ A is a feasible solution for SLAP-par if and only
if the corresponding set of variables Y A contains a minimum rank-filling set of system
(12) and the set Y 0 of variables.
Now we are ready to give the alternative formulation for the SLAP problem. Let C0
be the set of indices of columns of B corresponding to variables in Y 0 and let C1 be be
the family of subsets of indices of the columns of matrix B corresponding to minimum
rank-filling sets of variables for the reduced system (12) and let S be any element of it.
We can now formulate SLAP as follows:
[SLAP]
min

m

i=1

xi

(13)

241

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

subject to

m


bi j xi ≥ 1 ∀ j ∈ S

(14)

i=1

S ∈ C1
m

bi j xi ≥ 1 ∀ j ∈ C0

(15)
(16)

i=1

xi ∈ {0, 1}

i = 1, . . . , m

(17)

The objective function (13) requires us to minimize the number of path-ID sensors to
locate on the arcs of the network and it is the same as for SLAP-zero and SLAP-tot.
Constraints (14), (15) and (16) together require that each set of path-ID sensors located
on the network measure a subset of paths containing a minimum rank-filling set for
system (3). More specifically, constraints (14) and (15) require that each set of pathID sensors located on the network measure a subset of paths containing a minimum
rank-filling set for the reduced system (12) and constraints (16) requires that the path-ID
sensors measure all the path in Y 0 .
Observe that this formulation contains as special cases the formulations SLAP-zero
and SLAP-tot. Indeed, if Y 0 = ∅ and Y 1 = Y, then we have SLAP-tot. On the other hand,
if Y 0 = Y and Y 1 = ∅ we have the SLAP-zero formulation.
The next section analyzes the special cases for the three scenarios when we assume
that on each arc there are exactly two paths. The particular structure of the rank-filling
set will help us define a polynomial algorithm to solve these particular instances.
4.

Polynomially solvable cases: Exactly two paths on each arc

The assumption for these cases is that on each arc a ∈ A there are exactly two paths,
and therefore, the incident arc/path matrix B has exactly two non-zero elements for
each row. The reasons for selecting these cases, which are idealistic, were that (a) this
is possible in a sparse network, where each arc carries trucks or buses equipped for
active sensors that belong to one or two paths, and, (b), more importantly, to investigate
whether the SLAP problems are always NP-hard or whether polynomial cases exist. In
what follows, we will show that the three special cases are equivalent to solving the
Generalized Vertex Covering by Edges Problem (GVCE). We will show that the latter is
polynomially solvable and thus our problems are too.
From the hypothesis that each arc a ∈ A has two paths associated with it, we have

p
that j=1 bi j = 2, ∀i = 1, . . . , m. This property allows us to work on a related graph:
the intersection graph of the paths, referred to as the path intersection graph in the sequel.
For clarity of presentation, the path intersection graph G will be referred to in terms of
vertices and edges, whereas the underlying traffic network R in terms of nodes and arcs.
Let G = (V, E) be a graph such that each vertex vi ∈ V corresponds to the path Yi ∈ Y
and there is an edge between vertex vi ∈ V and vertex v j ∈ V if the corresponding paths
Yi , Y j have a common arc. We will denote an edge of G by e(i, j) to point out the fact

242

GENTILI AND MIRCHANDANI

Figure 3. A network of 10 nodes and 19 arcs with exactly two paths on each arc. The path intersection graph
for this network is shown in figure 4.

Figure 4. The path intersection graph for the network of figure 3. Each vertex corresponds to a path, and
there is an edge between two vertices if the corresponding paths have a common arc. Observe that two of
the three components, {v1 , v2 , v7 , v8 } and {v3 , v4 , v5 , v6 }, are bipartite.

that e(i, j) = (vi , v j ). Thus, |V | = |Y| = p and |E| ≤ |A| = m. Figure 4 shows the path
intersection graph G related to the network R of figure 3 whose set of paths satisfies the
assumption.
In the sequel we will show that the three problems are easily redefined on the path
intersection graph. Once we know the optimal choice of edges on the path intersection
graph G, it is an immediate step to find the corresponding optimal set of arcs on the
network R.
4.1. SLAP-zero with two paths for each arc: SLAP-zero(2)
We show now that an optimum set for SLAP-zero(2) can be obtained by solving the
Vertex Covering by Edges Problem (VCE) on the path intersection graph G. First we

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

243

recall the decision version of VCE and then we prove the correspondence among the
optimal solutions of the two problems.
The Vertex Covering by Edges problem (VCE)
Instance: A graph G = (V, E) and a positive integer K ≤ |V |.
Question. Is there a subset E  ⊆ E of edges of size K or less that covers the set of
vertices V , that is, where each vertex in V is incident to at least one edge in E  ?
An optimum covering set for VCE is a feasible set of minimum size.
Theorem 1. A subset A ⊆ A of arcs is an optimum set for SLAP-zero(2) if and only if
A corresponds to an optimum covering set E  on the path intersection graph.
Proof. Let R = (N , A) be a network and Y = {Y1 , Y2 , . . . , Y p } be the set of paths
defined on R. Let G = (V, E) be the intersection graph of the set of paths Y and
E  = {e1 , e2 , . . . , es } be an optimum covering set of G. By feasibility, we have that
{v1 , v2 , . . . , v p } = V is the set of vertices covered by E  and this set, by construction,
corresponds to the entire set of paths Y. We now build from E  a feasible set of arcs A
for SLAP-zero(2) on R of the same cardinality. For each edge (vi , v j ) ∈ E  select any arc
a ∈ A such that a ∈ Yi and a ∈ Y j . Let the selected arcs form the set A . We now have a
set A which has the same size of E  and it is feasible for SLAP-zero(2). Indeed, if there
is one path Yk ∈
/ Y A then the solution E  does not cover the corresponding vertex vk ;
that is a contradiction. Thus, the optimum covering E  corresponds to an optimum set for
SLAP-zero(2). Conversely, let A = {a1 , a2 , . . . , as } be an optimum set for SLAP-zero(2)
on R, that is Y A = Y. For each a ∈ A , let {Yi , Y j } be the two paths covered by a, and
select the edge ei j = (vi , v j ) ∈ E to obtain E  . This set E  is such that |E  | = |A | and
it covers the entire set of vertices V , thus is an optimum covering set for G.
The VCE problem for a graph G is polynomially solvable (see for example
Proposition 4.5 pp. 639 in Nemhauser and Wolsey (1988)). Thus, Theorem 1 defines
a way to solve SLAP-zero(2) under the assumption that there are exactly two paths on
each arc of the network.
4.2. SLAP-tot with two paths on each arc: SLAP-tot(2)
In this section we will define some properties of the rank-filling set of variables. We will
show the relation among the rank-filling sets and the connected components of the path
intersection graph G. We will see that the optimal solution value for the SLAP-tot(2) is
strictly related to the number of connected components of the path intersection graph
and that an optimum choice of arcs can be easily obtained.
We recall some additional terminology and some simple properties of undirected
graphs. Let G = (V, E) be an undirected graph with |V | = n vertices and |E| = m edges.
Let Z be the edge/vertex incident matrix of G. A forest is an acyclic partial subgraph of
G. A forest is spanning if it spans the vertex set of G. A tree is a connected forest. A

244

GENTILI AND MIRCHANDANI

Figure 5. Example of L-forest (a) and L-odd sets (b).

spanning tree is a connected spanning forest. A spanning forest F = (V, E T ) is maximal
if by adding any edge e ∈ E\E T the subgraph F ∪ {e} contains a cycle. An L-forest of
G is the graph obtained from a forest by adding at most one edge e to each component
of the forest, and the cycle containing e is odd (see figure 5(a)). Two vertex disjoint odd
cycles, together with a path between them or a pair of odd cycles with a common vertex,
form an L-odd set (see figure 5(b)). A maximal L-forest F is a spanning L-forest such
that by adding any edge e ∈ E\E T the corresponding subgraph F ∪ {e} contains an
L-odd set or an even cycle.
Lemma 3. If G is connected then n − 1 ≤ rank(Z ) ≤ n.
Proof. Matrix Z is an m × n matrix. Thus rank(Z ) ≤ n. A spanning tree of G corresponds to a set of n − 1 linearly independent rows of Z (see, for example, Proposition
6.1 pp.76 in Nemhauser and Wolsey (1988)) and thus n − 1 ≤ rank(Z ).
Theorem 2. Let G be a connected graph, then rank(Z ) = n if and only if G contains
an odd cycle.
Proof. (⇒) Let us consider a set of n linearly independent rows of Z . These rows
correspond to a set of edges of G and, since they are linearly independent they are
distinct, thus define a subgraph G  with n vertices and n distinct edges. Therefore, G 
contains a cycle. Let C be such a cycle. Consider the submatrix Z C corresponding to this
cycle. If the cycle contains an even number of edges then the determinant of matrix Z C
is zero and the corresponding rows are linearly dependent, contradicting the hypothesis.
Thus, C contains an odd number of edges.

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

245

(⇐) Conversely, consider a maximal L-forest of G. Since G is connected, a maximal
L-forest F is obtained from a spanning tree T by adding a single edge e that introduces an
odd cycle. Let C be such a cycle and let n c be the number of its edges. We want to prove
the n rows corresponding to the edges of the maximal L-forest are linearly independent.
To do that, let us consider a system of linear equations defined on the edge set of F. This
is a system with n variables (corresponding to the vertex set) and n equations. We will
show this system has a unique solution, and thus the rows of the corresponding matrix
are linearly independent.
Consider the subsystem obtained by considering the equations associated with the
odd cycle of the L-forest. This is a system with n c equations and n c variables. The corresponding submatrix is non-singular (because the cycle is odd) and thus a unique solution
to this subsystem can be achieved; that is, the values of the variables corresponding to
the vertices of the cycle can be obtained. Consider now the subgraph G  obtained from F
by deleting the edges of the cycle C. G  has at most n c connected acyclic component G i
and each one contains at least one vertex of the cycle. Let n i be the number of vertices of
each component G i . To each component G i is associated a subsystem in n i variables and
n i −1 linearly independent equations. Thus, fixing the value of at least one variable of the
subsystem, specifically that corresponding to a vertex in C, a solution for the subsystem
can be achieved. Therefore, each subsystem has a unique solution. Since the subsystems
are independent from each other (because they correspond to different components of
the graph G  ), a unique solution to the original system is obtained.
From Theorem 2 the corollary below directly follows.
Corollary 3. Let G be a connected graph, then rank(Z ) = n − 1 if and only if G is
bipartite.
Lemma 4. Let G be a graph with p connected components, then rank(Z ) = n −h where
h ≤ p is the number of its bipartite components.
Proof. Columns and rows of matrix Z can be rearranged to obtain the diagonal block
structure


Z1 0 . . . 0
 0 Z2 . . . 0 


... ...
0
0 . . . Zs
where Z i is the edge/vertex incidence matrix of component G i . Therefore, rank(Z ) =

p
i=1 rank(Z i ). If Z i corresponds to a bipartite component G i with n i vertices then, by
Corollary 3, rank(Z i ) = n i − 1. If Z i corresponds to a non-bipartite component G i , then
by Lemma 2, rank(Ai ) = n i . Hence, the theorem follows.
Let us now consider the set L of all the forests and L-forests of G, that is, L = {F : F
is a forest or an L-forest of G}.

246

GENTILI AND MIRCHANDANI

Theorem 3. Each set of linearly independent rows of Z has a one-to-one correspondence
to an element of L.
Proof. (⇒) Consider a set of k linearly independent rows of Z . Let E be the corresponding set of edges on the graph. If the subgraph G  induced by E is connected then
it can have k or k − 1 vertices. If G  has k − 1 vertices then it is acyclic, therefore is a
tree and thus a forest. If G  has k vertices, then, by Theorem 3, it has an odd cycle, and
thus it is an L-forest. If G  is not connected then, applying the same reasoning to each
of the connected components, this satisfies the hypothesis.
(⇐) Conversely, let F be an element of L. If F is connected then it can be acyclic
or contain an odd cycle. If F is acyclic then the corresponding set of edges are linearly
independent. If F contains an odd cycle then, by Theorem 2, the corresponding rows are
linearly independent. If F is not connected then, applying the same reasoning to each
component, the hypothesis follows.
Thus, each set of maximal linearly independent rows of Z corresponds to a maximal
L-forest or a maximal forest of G.
An extension and formalization of Theorem 3 in matroid context has been defined
in Conforti and Rao (1987). Theorem 3 holds also when G has multiple edges, because a
multiple edge introduces an even cycle and does not change the structure of the odd cycles
of the network. Now we return to our problem and show the relationship between the
arc/path incidence matrix B and the edge/vertex incident matrix Z of the path intersection
graph G.
Lemma 5. The edge/vertex incidence matrix Z has the same rank of the arc/path matrix
B.
Proof. We will prove this by showing that each row of Z corresponds to a subset of
identical rows of matrix B, and, vice versa, that each row of matrix B corresponds to a
row of Z . Recall that each row Bi of B corresponds one edge of G. In particular, if row Bi
is such that elements bik = 1 and biq = 1 then there exists in G the edge e(k,q) = (vk , vq ).
Vice versa, let us consider an edge e(i, j) = (vi , v j ) ∈ E, then there exists in B the set
of identical rows with bki = 1 and bk j = 1. Since by definition there is a one-to-one
correspondence between each row Z k of Z and each edge of G, the hypothesis follows.

Observation 1. By proof of Lemma 5, it is evident that matrix Z is obtained from B by
eliminating identical rows Bi1 , Bi2 , . . . , Bit . Thus, the system
Zy = f 

(18)

where f  is obtained from f by eliminating elements f i1 , f i2 , . . . , f it , is equivalent to
system (1).

247

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

We know, by Lemma 4, that the rank of the edge/vertex incidence matrix of an undirected
graph is equal to the number of vertices of the graph minus the number of its bipartite
connected components; the consequence with respect to B is stated in the following
lemma.
Lemma 6. The rank of the arc/path matrix B is equal to the number of paths minus the
number of bipartite connected components of the path intersection graph.
Let us now analyze SLAP-tot(2) on the path intersection graph. Let h = p − k be the
number of bipartite connected components of G, where p is the number of the paths and
k is the rank of matrix Z . We recall that a feasible solution to SLAP-tot(2) is a subset of
arcs in R covering a rank-filling set of h variables. All the rank-filling sets of variables
are easily defined using the path intersection graph G. The following result is a direct
consequence of Lemmas 5 and 6.
Lemma 7. Every minimum rank-filling set of variables for system (1) is composed of
h elements where h is the number of bipartite connected components of G.
When the path intersection graph is connected we have the following result.
Lemma 8. If the path intersection graph G is connected then the optimal solution value
of SLAP-tot(2) is at most 1.
Proof. By Lemma 3, the rank of matrix B can be either (i) rank(B) = p or (ii)
rank(B) = p − 1. Therefore, if rank(B) = p then a unique solution to system (1)
is already achieved and no path-ID sensors need to be located. On the other hand, if
rank(B) = p − 1, then only one variable has to be directly measured, that is, each minimum rank-filling set has size 1. Then, every arc a ∈ A covers a minimum rank-filling
set.
Theorem 4. If the path intersection graph G has h bipartite connected components, then
each set H = {Yi1 , Yi2 , . . . , Yih } of h variables is a minimum rank-filling set of variables
for system (1) if and only if the corresponding vertices {vi1 , vi2 , . . . , vih } belong to the h
different bipartite connected components of G.
Proof. By Observation 1 we can consider system (18) and its coefficient matrix Z . We
can define the block diagonal structure of matrix Z


Z1
 0

0

0
Z2
...
0

...
...
...
...


0
0 

Zs

248

GENTILI AND MIRCHANDANI

where each submatrix Z i is the edge/vertex incidence matrix of a connected component
of G. Thus, a solution to system (18) (and hence to system (1)) can be obtained solving
separately the s subsystems Z i y = f i .
Each subsystem’s variables correspond to the vertex set for the associated component, and its equations correspond to the component’s edge set. Each subsystem that
represents a component G i with an odd cycle (that is G i is not a bipartite component)
corresponds to a subsystem Z i y = f i that has a unique solution (by Theorem 2). For
each subsystem that represents a bipartite component G i with n i vertices such that
rank(Z i ) = n i − 1 (recall Corollary 3), a solution can be achieved fixing the value of
any variable of the subsystem.
Thus, system (18) (and hence system (1)) has a unique solution ⇔ each subsystem
has a unique solution ⇔ each subsystem corresponding to a bipartite component has a
solution. Therefore, we can fix the values of h variables, each corresponding to h vertices
each of which belongs to a different bipartite component of G.
Necessary and sufficient conditions for a subset of arcs A ⊆ A to be feasible for SLAPtot(2) follow from Theorem 4. Let G 1 = (V1 , E 1 ), G 2 = (V2 , E 2 ), . . . , G h = (Vh , E h )
be the bipartite connected components of the intersection graph, where Vi and E i , i =
1, 2, . . . , h are the vertex and the edge sets, respectively, of the component G i .
Corollary 4. Given the path intersection graph G = (V, E). A subset A ⊆ A is
feasible for SLAP-tot(2) if and only if A corresponds to a subset of edges E  ⊆ E such
that |VE  ∩ Vi | ≥ 1, i = 1, 2, . . . , h, where VE  ⊆ V is the subset of vertices spanned by
E .
Proof. Given A feasible, for each a ∈ A let {Yi , Y j } be the two paths covered by a and
select the edge evi ,v j ∈ E to obtain E  . If there exists a Vk such that VE  ∩ Vk = ∅, then
all the variables corresponding to the vertices v ∈ Vk are not covered by A . But A is
feasible and, thus, by Theorem 4, this results in a contradiction. This proves sufficiency.
By similar reasoning the necessary part of the proof holds.
The lemma below, whose proof is omitted, follows directly.
Lemma 9. Let G 1 = (V1 , E 1 ) and G 2 = (V2 , E 2 ) be any two connected components of
G. There does not exist any arc a = (i, j) ∈ A, in the original network R, with vi ∈ V1
and v j ∈ V2 .
Let us denote by z ∗ the optimal solution of SLAP-tot(2).
Lemma 10. If the path intersection graph G has h bipartite connected components,
z ∗ = h.
Proof. Since an edge of G corresponds to an arc of R = (N , A), then by choosing one
edge for each bipartite component of G we obtain a subset E  of size h that corresponds

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

249

to a subset A of the same size that is feasible for SLAP-tot, that is z ∗ ≤ h. If A
is feasible, then the corresponding set E  covers all the bipartite components of G, i.e.
|VE  ∩Vi | ≥ 1, i = 1, 2, . . . , h. By Lemma 9, a set Vi cannot exist such that |VE  ∩Vi | = 1
and therefore no edge covers two components. Thus, at least h edges are required to cover
all components, that is h ≤ z ∗ . Hence z ∗ = h.
Corollary 4 and Lemmas 9 and 10 result in the following theorem.
Theorem 5. The optimal solution of SLAP-tot(2) is given by choosing h arcs {a1 , a2 , . . . ,
ah } ⊆ A such that:
(i) h is the number of bipartite connected components of the path intersection graph G;
(ii) each arc ai , i = 1, 2, . . . , h corresponds to an edge ei ∈ E of G that belongs to the
bipartite connected components G i , i = 1, 2, . . . , h.
Therefore, once we obtain the path intersection graph, we can then easily determine a
rank-filling set of variables that corresponds to an optimal set of arcs for SLAP-tot(2). For
the path intersection graph in figure 4, the optimal solution value of the problem is equal
to h = 2 the number of bipartite connected components of the graph G. A rank-filling
set of variables of minimum size contains two variables corresponding to two vertices,
one each from the two bipartite connected components of G. Thus, for example {Y1 , Y2 }
is not a rank-filling set, but {Y1 , Y4 } is. Since, by Lemma 9, we cannot find a single
edge that can cover a minimum rank-filling set, the optimal choice is to take one edge ei
from each bipartite connected component Vi and to select in A the corresponding arcs.
From the graph of figure 4, an optimum subset of edges in G comprises, for example,
edges (v1 , v2 ) in E 1 and (v3 , v4 ) in E 2 which correspond to arcs a1 and a2 in the original
network R. Observe that a13 also covers vertices v3 and v4 . Observing the network R in
figure 3 we see that paths Y3 and Y4 both use arcs a2 and a13 and path-ID sensor location
on either of them gives the same information.
4.3. SLAP-par with two paths on each arc: SLAP-par(2)
In this section we will show the SLAP-par(2) problem, or simply SLAP(2), is polynomially solvable when there are exactly two paths for each arc of the network. Analysis
in Section 4.1 allowed us to show the equivalence of SLAP-zero(2) and the polynomially solvable VCE problem on a graph. Analysis in Section 4.2 related the solution of
SLAP-tot(2) to the number of bipartite components in the path intersection graph G and
to selecting an edge in each component resulting in a polynomial algorithm. We now
address the special case of the general problem, SLAP(2), and utilize the results of Sections 4.1 and 4.2. We will define a new problem on the path intersection graph and refer
to it as the Generalized Vertex Covering by Edges Problem (GVCE). We will show an

250

GENTILI AND MIRCHANDANI

Figure 6. The subgraph G 1 of the path intersection graph (for the network of figure 3) in case of partial information, when total volumes on arcs a1 , a5 , a8 , a12 , a14 are known. This subgraph has 7 bipartite connected
components: {v1 , v2 }, {v7 , v8 }, {v3 , v5 }, {v4 }, {v6 }, {v10 , v11 , v12 }, {v9 }.

optimum solution to SLAP(2) corresponds to an optimum set for GVCE. Then we will
prove GVCE is equivalent to the VCE problem and thus is polynomially solvable.
Consider the network of figure 3 and suppose we know the flows on a subset of the
arcs, say a1 ,a5 ,a8 , a12 , a14 . Matrix B 1 of system (3) in this case is:
y1
a1
1
a5 
0
a8 
0
a12  0
a14 0


y2
1
0
0
0
0

y3
0
0
1
0
0

y4
0
0
0
0
0

y5
0
0
1
0
0

y6
0
0
0
0
0

y7
0
1
0
0
0

y8
0
1
0
0
0

y9
0
0
0
0
0

y10
0
0
0
1
0

y11
0
0
0
1
1

y12

0
0 

0 

0 
1

The rank of this matrix is k = 5, the number of flow variables is p = 12, and therefore,
a minimum rank-filling set of variables has size h = 12 − 5 = 7. Consider the subgraph
G 1 of the path intersection graph G obtained with only the edges corresponding to arcs
in the set A1 = {a1 , a5 , a8 , a12 , a14 } (see figure 6). Note that in this case there are three
isolated vertices corresponding to the three paths Y4 , Y6 and Y9 which are not included
in the subsystem defined by G 1 .
The edge/vertex incidence matrix of G 1 has the same rank of matrix B 1 and all the
properties of the connected components of G 1 proven for the path intersection graph G
with total count information still hold for this case. If we define a degenerate component
consisting of a single vertex to be a bipartite component of G 1 , then, using the results of
the previous section, and by Lemma 2, we have the following corollary.
Corollary 5. Let G 1 = (V 1 , E 1 ) be the subgraph of the path intersection graph related
to matrix B 1 . A subset H = {yi1 , yi2 , . . . , yih } is a minimum rank-filling set of variables
for system (3) if and only if vk ∈ Vk1 , k = i 1 , i 2 , . . . , i h , where G 11 , G 12 , . . . , G 1h are

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

251

all of the bipartite components of G and Vi1 is the vertex set of the bipartite connected
component G i1 .
That is, as in the case of SLAP-tot(2), we can easily characterize all the minimum rankfilling sets for SLAP(2). In figure 6, the graph G 1 has seven bipartite connected components. Each minimum rank-filling set for system (3) is obtained by choosing seven
variables corresponding to seven vertices of G 1 that belong to the different bipartite connected components. For example, the set H = {Y1 , Y3 , Y4 , Y6 , Y7 , Y9 , Y12 } is a minimum
rank-filling set because the corresponding vertices v1 ,v3 ,v4 ,v6 ,v7 ,v9 and v12 belong to
different bipartite connected components of G 1 . However, we cannot derive the same
result as stated by Theorem 5 because Lemma 9 does not hold in this case. Indeed, since
G 1 is a subgraph of G, there may be some edges in E, say e(i, j) , such that vi and v j belong
to different connected components of G 1 (for example the edge (v3 , v4 ) or (v4 , v6 )). That
is, choosing 7 arcs in A corresponding to 7 edges of G 1 that belong to different bipartite
connected components as stated by Theorem 5, may not give the optimal solution to
SLAP(2). Indeed, for the network of figure 3, choosing only four arcs, say a8 , a9 , a11
and a16 can cover the set of paths H = {Y1 , Y3 , Y4 , Y6 , Y7 , Y9 , Y12 }, which is a minimum
rank-filling set for this example.
We now define the Generalized Vertex Covering by Edges Problem. First, we will
show that each optimum solution of SLAP(2) corresponds to an optimum solution of
GVCE, then we will prove GVCE to be polynomially solvable (also, GVCE belongs to
the more general class of the Generalized Subgraph Problems as defined in Feremans
(2001)).
Generalized Vertex Covering by Edges Problem (GVCE)
Instance: A graph G = (V, E), a family U = {U1 , U2 , . . . , Uh } of disjoint subsets of
the vertices and a positive integer K ≤ |V |.
Question. Is there a subset E  ⊆ E of size K or less that covers the sets of the family U.
That is, does an E  ⊆ E exist with |E  | ≤ K such that for each subset Ui there exists
at least one vertex u i ∈ Ui and a vertex v ∈ V for which (v, u i ) ∈ E  ?
A subset E  of edges of G is feasible for GVCE if at least one vertex in each set Ui is incident to one or more edges in E  . For example, for the graph in figure 6, we define the family
of disjoint subsets U = {{v1 , v2 }, {v3 , v5 }, {v4 }, {v6 }, {v7 , v8 }, {v9 }, {v10 , v11 , v12 }}.
The subset of edges E  = {(v4 , v6 ), (v1 , v7 ), (v3 , v4 ), (v9 , v11 )} is feasible for
GVCE; indeed it covers at least one vertex from each of the components in the
family.
Let G be the intersection graph of the set of the paths Y. Consider the spanning
subgraph G 1 = (V, E 1 ) of G obtained considering those edges of G corresponding to
the set of arcs A1 and let G i1 = (Vi , E i1 ),i = 1, 2, . . . , h be the bipartite connected
components of G 1 . Let U = {U1 , U2 , . . . , Uh } be the family of disjoint subsets of the
vertex set V such that Ui = Vi .

252

GENTILI AND MIRCHANDANI

Lemma 11. A ⊆ A is feasible for SLAP(2) if and only if A corresponds to a set E  ⊆ E
of the same size that is feasible for the GVCE on the path intersection graph with the
family U.
Proof. Let E  = {e1 , e2 , . . . , es } be a feasible set of edges for the GV C E on G and
the family U. We now build from E  a feasible set of arcs A for SLAP(2) on R of the
same cardinality. For each edge (vi , v j ) ∈ E  select any arc a ∈ A such that a ∈ Yi and
a ∈ Y j . This set A is the same size as E  and by Corollary 5 it is feasible for SLAP(2).
Now consider the contrary. Let the set A = {a1 , a2 , . . . , as } be a feasible set for
SLAP(2) on R. We now build a feasible set for GVCE of the same size. For each a ∈ A ,
let {Yi , Y j } be the two paths covered by a, and select the edge ei j = (vi , v j ) ∈ E. Let the
selected edges form the set E  . We have that |E  | = |A | and, by Corollary 5, it covers
the family U, and thus is feasible.
Theorem 6. A subset A ⊆ A is optimum for SLAP(2) if and only if A corresponds to
a set E  ⊆ E that is optimum for the GVCE on the path intersection graph with bipartite
components forming its family U.
Proof. Let A be an optimum set for SLAP(2), the corresponding set E  of the same
size is also optimum for GVCE, because otherwise there would exist a feasible set E ∗
for GVCE with |E ∗ | ≤ |E| and the corresponding feasible set A∗ with |A∗ | ≤ |A |
contradicting the optimality of A . The same reasoning is applied for the i f (sufficiency)
part of the proof.
We now prove that any instance of GVCE can be reduced to an instance of VCE and thus
GVCE is polynomially solvable.
Theorem 7. The GVCE problem is polynomially solvable.
Proof. Let G = (V, E), a family U = {U1 , U2 , . . . , Uh } of disjoint subsets of vertices
and a positive integer K ≤ |V | be any instance of GVCE. We build a graph G  = (Z , X )
and consider a positive integer K  such that G has a subset E  ⊆ E of size K or less that
covers the family U if and only if G  has a subset X  ⊆ X of size K  or less that covers
the set of vertices Z .
The construction of G  is made by considering a vertex set Z of size h such that
each vertex z i ∈ Z corresponds to the set Ui of the family U, and by considering the
edge set X such that: (i) there is the edge (z i , z j ) ∈ X if there exists at least one edge
(u, v) ∈ E such that u ∈ Ui and v ∈ U j and (ii) there is a loop-edge (z i , z i ) ∈ E  if either
there exists at least one edge (u, v) ∈ E such that u ∈ Ui and v ∈ Ui or there exists one
edge (u, v) ∈ E such that u ∈ Ui and v ∈
/ Uk for each k = 1, 2, . . . , h (see illustration
of figure 7). This construction is done in polynomial time.
We now have to show that G has a subset E  ⊆ E of size K or less that covers
the family U if and only if G  has a subset X  ⊆ X of size K  or less that covers the set

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

253

Figure 7. The reduction of GV C E to V C E. From any instance of GV C E on graph G, a graph G  is built for
V C E. The family of disjoint sets of vertices of G is: U1 = {v1 , v2 }, U2 = {v3 }, U3 = {v6 }, U4 = {v7 , v8 }.
For example, the loop edge of vertex z 2 is associated with the edges (v1 , v2 ) and (v1 , v4 ) and the edge (z 2 , z 3 )
is associated with the edge (v1 , v3 ).

of vertices Z . First suppose that E  , |E  | ≤ K , is a subset of edges in G that covers the
family U. We choose a subset X  ⊆ X of edges of G  in the following way:
– for each e = (u, w) ∈ E  such that u ∈ Ui and w ∈ U j select the edge (z i , z j ) ∈ X ;
– for each e = (u, w) ∈ E  such that u ∈ Ui and w ∈ Ui select the edge (z i , z i ) ∈ X ;
/ Uk for each k = 1, 2, . . . , h
– for each e = (u, w) ∈ E  such that u ∈ Ui and w ∈
select the edge (z i , z i ) ∈ X .
Let the selected edges form the set X  . Setting K  = K we have now obtained a set X 
such that |X  | ≤ K  and X  covers the vertex set Z . Indeed, if there is a vertex in Z that
is not covered, say z k , there is no edge in E  covering the subset Uk , which leads to a
contradiction.
Conversely, let X  ⊆ X , |X  | ≤ K  , be a subset of edges of G  that covers the set
of vertices Z . We choose a subset E  ⊆ E of edges of G in the following way:
– for each (z i , z j ) ∈ X  select any edge (u, w) ∈ E such that u ∈ Ui and w ∈ U j ;
– for each (z i , z i ) ∈ X  select any edge (u, w) ∈ E such that either u ∈ Ui and w ∈ Ui
or u ∈ Ui and w ∈
/ Uk for each k = 1, 2, . . . , h.
Let these selected edges form the set E  .
Setting K = K  we have obtained a set E  such that |E  | ≤ K that covers the
family U. Indeed, if there is a set in U that is not covered, say Uk , there is no edge in X 
covering the corresponding vertex vk , which leads to a contradiction.
Obviously, the SLAP-tot(2) and SLAP-zero(2) are special cases of SLAP(2), and
therefore correspond to particular instances of the GVCE problem. The SLAP-zero(2)
instance is obtained when the family U = {U1 , U2 , . . . , Uh } of the set of vertices of G

254

GENTILI AND MIRCHANDANI

is such that each set corresponds to a single vertex, i.e. Ui = {vi } for each vi ∈ V . On
the other hand, when each set of the family corresponds to the vertex set of a bipartite
connected component of G we obtain the SLAP-tot(2) instance.
Thus, we develop the following polynomial algorithm to solve SLAP(2) when there
are exactly two paths on each arc of the network.
Algorithm 1 for SLAP(2).
Input: A network R = (N , A), a set of paths Y = {Y1 , Y2 , . . . , Y p } such that on each
arc of the network there are exactly two paths, a set A1 ⊆ A of arc flow volumes.
Output: An optimum set A ⊆ A that solves SLAP(2).
Step 1. Build the path intersection graph G = (V, E);
Step 2. Define the subset of edges E 1 ⊆ E corresponding to the subset of arcs A1 ⊆ A;
Step 3. Define the family U = {U1 , U2 , . . . , Uh } of disjoint subsets of vertices, where
each subset is the vertex set of a bipartite component of G 1 = (V, E 1 );
Step 4. Solve the GVCE on G with family U and let E  be the optimum subset of edges;
Step 5. A is a subset of arcs which corresponds to the set E  .
5.

An algorithm for the general case

In Section 4 we showed that SLAP(2) was polynomially solvable and provided Algorithm
1 that solves it in polynomial time. To fully address the general case of SLAP, with more
than 2 paths on some arcs, we present here a greedy-type approximate algorithm. We first
describe the algorithm for the total count information case and then present the modified
versions for the zero and partial count information scenarios.
The algorithm is implemented through appropriate manipulation of the coefficient
matrix B. It is based on the following observation. Given an arc a ∈ A that is common to
q paths. If we know the volumes of q − 1 paths containing arc a and we know the total
flow volume of this arc, then we can compute the volume flow of the remaining path. We
state this as a remark.
Observation 2. Given an equation yi1 + yi2 + · · · + yiq = f k of the initial system
of equations By = f , if we add to the system the q − 1 equations yh = f h , h =

q−1
i 1 , i 2 , . . . , i q−1 then yiq = f k − h=1 f ih .
Suppose we locate a path-ID sensor on arc ai ∈ A corresponding to row Bi of the matrix.
Then, all path flows on arc ai become known and the i-th row of the matrix B become
redundant; this is effected by setting element bi j = 0, j = 1, 2, . . . , p. Also, when
biq = 1 the flow on path Yq is known; therefore, the column B q is no longer needed and
can be eliminated. Then, if there is a row, say Bk , such that bkl = 1 is the only non-zero
element, then flow on path Yl is determined (by Observation 2) and we no longer need

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

255

to consider that row and also column B l . We can repeat the process until the rows of the
remaining matrix are all equal to zero or at least have two non-zero elements. Choose
one of the rows with non-zero elements according to a given selection criterion to locate
a sensor and repeat the above process. Continue until all of the rows of matrix B become
zero.
The steps of the Algorithm 2, based on the above observations, to obtain a feasible
solution to the general problem are as follows.
Algorithm 2 for SLAP-tot
Step 1 Set k = 0.
Step 2 (Selection)
Select row Bi(k) = 0 according to the given selection criterion to locate a path-ID
sensor on an arc.
Step 3 (Deletion)
Update the B (k) matrix to obtain the matrix B (k+1) in the following way:
(k)
Step 3.1 If biq
= 1 eliminate corresponding columns B (k)q as well as row Bi(k) ;
(k)
Step 3.2 If a row B (k)
j of remaining matrix is such b jq = 1 is the only element different
from zero, then set j = i and k = k + 1 and goto Step 3.

Step 4 (Stopping criterion)
If bi j = 0 for all i = 1, 2, . . . , m and for all j = 1, 2, . . . , p then stop. Otherwise set
k = k + 1 and go to Step 2.
Theorem 8. Algorithm 2 finds a feasible solution for SLAP-tot.
The proof follows directly from the observations that led to the algorithm. For the
case when all the components of the path intersection graph are bipartite, we have the
following corollary.
Corollary 6. If there are exactly two paths on each arc and all the components of the
path intersection graph are bipartite, then the Algorithm 2 finds an optimal solution for
SLAP-tot(2)
Proof. Let G be the path intersection graph. Let h be the number of connected components of G. Since the algorithm defines a subset of arcs A ⊂ A that is feasible for the
problem, then |A | ≥ h. We prove it cannot be |A | > h. Since the connected component
of the graph are all bipartite, then an optimal solution for SLAP-tot(2) is obtained by
choosing exactly one edge for each component (Theorem 5); therefore, if A is not an
optimum set (i.e., |A | > h) then there are two arcs, say ai , a j ∈ A that corresponds
to edges of G, say ei , e j , that belongs to the same connected component. Suppose the
algorithm chooses arc ai first. Since e j is in the same connected component of ei the
following three cases may occur:

256

GENTILI AND MIRCHANDANI

(i) Ya j = Yai : the row B j of the matrix, after Step 3.1, effectively becomes zero and
the arc a j cannot be chosen subsequently;
(ii) |Ya j ∩ Yai | = 1: the row B j of the matrix, after Step 3.1, has only one element
different from zero. Thus, after Step 3 it will be eliminated and arc a j cannot be
chosen subsequently;
(iii) Ya j ∩ Yai = ∅: let Ya j = {Y j1 , Y j2 } and Yai = {Yi1 , Yi2 }, be respectively the set of
paths associated with arc a j and arc ai . Since ai and a j belong to the same connected
component there exists in G a path of length say l connecting vertex v js , s = 1, 2 to
vertex vik , k = 1, 2. Let {Bi , B j1 , . . . , B jl−2 , B j } be the corresponding rows of the
matrix. These rows are such that b jk ik−1 = 1 and b jk ik = 1 and thus after l iterations
of Step 3.2 row B j will be equal to zero and arc a j cannot be chosen subsequently.
Thus, we have a contradiction and the hypothesis follows.

In case of zero count information we cannot apply Observation 2 and thus Step 3.2 of
the algorithm cannot be applied. Then, Algorithm 2 reduces to the greedy algorithm for
solving the set covering problem Nemhauser and Wolsey (1988). On the other hand, in
case of partial count information, Observation 2 can be applied only to the rows of the
matrix corresponding to arcs in A1 , that is Step 3.2 is applied only when row B k+1
, under
j
consideration, corresponds to arc a j ∈ A .
6.

Summary and further research

In this paper, we addressed the problem of locating active sensors on the arcs of a traffic
network where the sensors can provide data on paths. We showed that each sensor located
on an arc results in a set of linear equations in path flow variables that may be used for
finding path flows. Then, the problem becomes the selection of the minimum number of
arcs that add linear equations that result in a full rank coefficient matrix. We presented
a formulation of the problem and analyzed three different scenarios depending of the
number of conventional counting sensors already located on the network. The general
problem was shown to be NP-hard. However, we were able to introduce polynomial
instances for it. Through the proofs of the polynomially solvable cases, some new graph
theoretic models and theorems were obtained, which in their own right add to the graph
theoretic knowledge base, besides providing insight to develop an approximate algorithm
for the general case.
Another related sensor location problem, which we alluded to in the introductory section, arises when image sensors can be located on the nodes of the network
(intersections) to provide turning ratios. Processing the images, obtained by either fixed
or mobile video cameras, it is possible to recognize vehicles on the scene and track their
movements. For example, by locating a fixed camera that takes images of the traffic
flows at an intersection of the network we can estimate (i) the arc flow volume of each

LOCATING ACTIVE SENSORS ON TRAFFIC NETWORKS

257

arc incident to the node and (ii) the turning ratios at the intersection. The turning ratio
t ijk at node i is the proportion of flow on arc ( j, i) that goes to arc (i, k). Therefore, we
can associate with each node, as for the path-ID sensors, a set of equations that might be
added to the linear system if an image sensor is located on that node. Thus, the imagesensor-on-node location problem becomes a generalization of the active-sensor-on-arc
location problem addressed in this paper, albeit a more complex one. We are currently
formulating a general model for locating image sensors on nodes, and analyzing and
developing solution approaches.
References
Bianco, L., G. Confessore, and P. Reverberi. (2001). “A Network Based Model for Traffic Sensor Location
with Implications on O/D Matrix Estimates.” Transportation Science 35(1), 50–60.
Bianco, L., G. Confessore, M. Gentili. (2003). “Combinatorial Aspects of the Sensor Location Problem.”
Annals of Operations Research (to appear).
Cascetta, E. and S. Nguyen. (1988). “A Unified Framework for Estimating or Updating Origin/Destination
Trip Matrices from Traffic Counts.” Transportation Research B 22, 437–455.
Conforti, M. and M.R. Rao. (1987). “Some New Matroids on Graphs: Cut Sets and the Max Cut problem.”
Mathematics of Operations Research 12(2), 193–204.
Feremans, C. (2001). “Generalized Spanning Trees and Extensions.” PhD Thesis, Université Libre de
Bruxelles, Institut de Statistique et de Recherche Opérationelle .
Gentili, M. (2002). “New Models and Algorithms for the Location of Sensors on Traffic Networks.” PhD
Thesis. Department of Statistic, Probability and Applied Statistics, University of Rome “La Sapienza”.
Lam, W.H.K. and H.P. Lo.(1990). “Accuracy of O-D Estimates from Traffic Counts.” Traffic Engineering
and Control 31, 358–367.
Nemhauser, G.L. and L.A. Wolsey. (1988). Integer and Combinatorial Optimization. New York, N.Y: J.
Wiley and Sons.
Wardrop, J.G. (1952). “Some Theoretical Aspects of Road Traffic Research.” In Proceedings of the Institute
of Civil Engineering, Part II, pp. 325–378.
Yang, H., Y. Iida, and T. Sasaki. (1991). “An Analysis of the Reliability of an Origin/Destination Trip Matrix
Estimated from Traffic Counts.” Transportation Research B 25, 351–363.
Yang, H. and J. Zhou. (1998). “Optimal Traffic Counting Locations for Origin-Destination Matrix Estimation.” Transportation Research 32B(2), 109–126.

The Vehicle Rescheduling Problem: Model and Algorithms

Jing-Quan Li and Pitu B. Mirchandani
Department of Systems and Industrial Engineering, The University of Arizona, Tucson, Arizona 85721
Denis Borenstein
Management School, Universidade Federal do Rio Grande do Sul, R. Washington Luis 855, Porto Alegre
90010-460, RS, Brazil

When a vehicle on a scheduled trip breaks down, one or
more vehicles need to be rescheduled to serve the customers on that trip with minimum operating and delay
costs. The problem of reassigning vehicles in real-time
to this cut trip as well as to other scheduled trips with
given starting and ending times, is referred to as the
vehicle rescheduling problem (VRSP). This paper considers modeling, algorithmic, and computational aspects
of the single-depot VRSP. The paper formulates a model
for this problem and develops several fast algorithms
to solve it, including parallel synchronous auction algorithms. The concept of the common feasible network
(CFN) is introduced to ﬁnd a good set of initial “prices” for
speeding up the auction algorithm. Computational experiments on randomly generated problems are described.
Computational results show that, for small problems,
all of the developed algorithms demonstrate very good
computational performances. For large problems, parallel CFN-based auction algorithms provide the optimal
solution with much smaller computation times. © 2007
Wiley Periodicals, Inc. NETWORKS, Vol. 50(3), 211–229 2007

Keywords: vehicle scheduling; rescheduling; auction algorithm;
parallel processing

1. INTRODUCTION
The vehicle rescheduling problem (VRSP) arises when
a previously assigned trip is disrupted. A trafﬁc accident, a
medical emergency and a breakdown of a vehicle are examples of possible disruptions that demand the rescheduling of
vehicle trips. The VRSP can be approached as a dynamic version of the classical vehicle scheduling problem (VSP) where
assignments are generated dynamically.
The VRSP arises in a wide array of practical applications.
Instances of VRSP occur in school bus routing, operational

Received November 2004; accepted February 2007
Correspondence to: P. B. Mirchandani; e-mail: pitu@sie.arizona.edu
Contract grant sponsor: CAPES, USDOT/FHWA, Arizona DOT
DOI 10.1002/net.20199
Published online in Wiley InterScience (www.interscience.wiley.
com).
© 2007 Wiley Periodicals, Inc.

NETWORKS—2007—DOI 10.1002/net

planning of public transportation systems, industrial/hospital
refuse collection, mail delivery, telecommunication systems,
etc. Because of our initial motivation, which arose from bus
rescheduling, in this paper special contextual reference is
made to the VRSP problem in public transit systems, where a
trip disruption results not only in the increase of operational
and delay costs, but also in considerations to accommodate
passengers whose plans have been disrupted by the vehicle
breakdown.
We note that the VRSP is one of two major subproblems
that must be considered in the real-time operational planning of a transportation/logistic system; the other is crew
rescheduling. Although in strategic planning, the vehicle
scheduling and crew scheduling problems are being studied, separately as well as in an integrated fashion [7, 13],
the corresponding rescheduling problems have received little
attention from a real-time operational planning perspective.
Nevertheless, we have decided to focus this paper on solving the VRSP. Integration of crew rescheduling in real-time
operations is a topic of future research.
The literature describes several different approaches to
solve the VSP [12], but the literature on VRSP is scant. However, when ﬂeet size is limited and disruptions are frequent,
good automated rescheduling tools to assist decision makers
become important. Very few companies or agencies use automated rescheduling policies, and there is a gap in availability
of algorithms for VRSP. The goal of this research is to address
this gap. In particular, the single-depot VRSP is modeled, and
algorithms that solve this problem in a reasonable amount of
time are proposed.
The most pertinent decision for VRSP is which vehicle
should backup the disrupted trip. The existence of several alternatives generates, in comparison to VSP, several
possible feasible networks for the problem, each one corresponding to a possible choice of a backup vehicle. The
selection of the backup vehicle involves several factors such
as the time when the trip was disrupted, the position of
the remaining vehicles, the available capacity of the potential backup vehicles, and the itinerary compatibility among
trips. The existence of several possible feasible networks

makes the VRSP a very interesting but difﬁcult problem to
solve.
This paper has the following major objectives: (i) to model
the single-depot VRSP (SDVRSP), and (ii) based on previous algorithms developed for the VSP, to describe several
possible algorithms for solving the problem, including a parallel auction algorithm speciﬁcally implemented to solve the
SDVRSP. To improve the performance of the algorithms, we
develop the notion of the common feasible network (CFN).
Since the difference among feasible networks is small, one
promising approach is to perform the algorithm in two stages.
In the ﬁrst stage, the algorithm is carried out for a reduced
network that does not include the disrupted trip or the backup
vehicle candidates. Then an assignment close to the original
one is obtained, since this reduced network is very similar to
the original feasible networks. In the second stage, we include
the disrupted trip and backup vehicle candidates to reconstruct the feasible networks for the VRSP problem and apply
the auction algorithms again, considering the initial assignments from the ﬁrst stage. The second stage is then performed
for all candidate backup vehicles. CFN often improves the
computational performance of the auction algorithms due to
better initial assignments.
The major contributions of this paper to the literature are
as follows: (i) the deﬁnition of the VRSP, dealing with issues
such as common itineraries, available capacities, time constraints, and backup vehicle candidates; (ii) the introduction
of the CFN approach for reducing the computational time of
auction assignment algorithms; and (iii) the implementation
of a fast parallel auction algorithm for solving the VRSP,
using message-passing to speed up communication among
the several processors.
This paper is organized as follows: Section 2 reviews the
literature on VRSP and related problems. Terminology and
formal description of the problem are provided in Section
3. Section 4 presents our formulation for the SDVRSP, and
Section 5 describes some fast auction-based algorithms for
solving the SDVRSP. In Section 6, the CFN-based auction
algorithm is proposed to further reduce computation times.
Section 7 presents computational experiments to evaluate the
performance of the algorithms. In the concluding Section 8,
a summary of the results is presented and areas of future
research are discussed.
2. LITERATURE REVIEW
Automatic recovery from disruptions is a relatively new
operational strategy; therefore literature related to the topic
is scarce. Currently, most transit companies typically avoid
reassigning trips during operational disruptions by simply
using a backup vehicle from the depot. Since VRSP is
strongly related to VSP, we brieﬂy review the literature on the
state-of-the art on modeling and solving the VSP, for which
there is a vast literature.
Overviews of algorithms and applications for the singledepot VSP (SDVSP) and some of its extensions can be
found in [1, 5, 10, 12, 18]. The SDVSP has been formulated

212

NETWORKS—2007—DOI 10.1002/net

as a linear assignment problem, a transportation problem,
a minimum-cost ﬂow problem, a quasi-assignment problem, and a matching problem in the literature. Bokinge and
Hasselstrom [6] propose a minimum-cost ﬂow approach that
uses a signiﬁcant reduction on the size of the model in
terms of the number of variables at the price of an increased
number of constraints. An O(n3 ) successive shortest-path
algorithm and variations for the SDVSP were proposed
in [15, 24, 30]. Paixão and Branco [27] propose an O(n3 )
quasi-assignment algorithm that is especially designed for
the SDVSP. Freling et al. [18] use a quasi-assignment model
and employ a forward/reverse auction algorithm for the solution. Computational results presented by [18] show that this
approach signiﬁcantly outperforms the previous approaches
that are based on minimum-cost ﬂow and linear assignment
models.
The majority of the research on real-time schedule recovery relates to the dynamic vehicle routing problem (VRP), the
airline operations recovery problem and the train rescheduling problem.
The dynamic vehicle routing problem, where new requests
arise in midst of operations, has gained increasing attention
since the late eighties. Recent surveys on dynamic VRP can
be found in [19, 20, 28]. Tabu search [23], genetic algorithm [21], assignment, and insertion-based heuristics [17],
approximate dynamic programming [31], and nearest-vehicle
based heuristic [16] have been proposed to consider online
requests and uncertain travel time in the dynamic VRP problem. Yang et al. [34] have developed a general framework for
the dynamic vehicle routing problem in which new requests
can arrive during operations.
The literature on airline schedule recovery includes
Carlson [8], Lettovský [25], and Teodorović and Stojković
[32]. These research efforts develop exact optimization
models that reschedule ﬂight legs and reroute aircraft by
minimizing rerouting and cancellation costs. These exact
algorithms consider only several hundreds of ﬂights. Rosenberger et al. [29] present a heuristic method for selecting
which aircraft can be rerouted prior to generating new routes,
allowing to solve many large recovery instances quickly.
However, when applied to real-life problems, consisting
of 469 ﬂights and 96 planes, the method, on average, has
required more than 50,000 sec in CPU time to solve recovery
instances.
Some research has been reported on the train rescheduling
problem. Chiu et al. [11] design a labeling-based heuristic to reduce time table disruptions incurred by accidents or
train delays. Medanic and Dorfman [26] propose a discreteevent model and a travel advance strategy to produce an
efﬁcient train schedule, and to reschedule in case of disruptions. Walker et al. [33] utilize a branch-and-bound method
to minimize the deviation of the new schedule obtained from
the initial schedule, due to train delays.
To the best of our knowledge, the only contribution
towards solving the dynamic VSP is due to Huisman et al.
[22] who proposed an approach to the problem by solving a
sequence of formulated optimization problems. Their work

is motivated to design robust vehicle schedules that avoid
trips starting late in environments characterized by signiﬁcant
trafﬁc jams.
Although the literature has interesting and useful ideas
towards the development of automated recovery tools, there
is a gap in this literature related to the consideration of vehicle breakdown. Since vehicle breakdowns have not been
explicitly considered in train rescheduling [11, 26], dynamic
VSP [22], or dynamic VRP [16, 17, 21, 23, 31, 34], most of
results available are not directly applicable to our problem.
Although aircraft breakdown is considered in some studies
of airline operations recovery, most of the available algorithms [8, 25, 29, 32] involve a small number of trips and
aircrafts. The majority of these algorithms are computationally intensive, requiring thousands of CPU seconds to solve
recovering instances involving hundreds of trips and dozens
of planes. As a consequence, it is unclear whether they can be
directly applied to our more generic VRSP problem, which
can involve thousands of trips and hundreds of vehicles.
3. PROBLEM DESCRIPTION
We ﬁrst introduce some deﬁnitions and notation to
describe the vehicle rescheduling problem. To relate to a cut
in a graph, we refer to a disrupted trip due to a disabled vehicle, or a vehicle that is effectively inoperable, as a cut trip.
Breakdown point is the point in the cut trip where the trip is
disrupted. Current trip is the trip on which a vehicle is running. It includes both regular and deadheading (movement
of a vehicle to a destination without serving any passenger)
trips. The vehicle that serves the remaining passengers in the
cut trip, referred to as the backup vehicle in the sequel, can be
identiﬁed from the trip just served, which may be referred to
as the backup trip. Then, essentially, the vehicle assignment
problem is to assign (the vehicle from) a node representing
a backup trip, or assign (a vehicle from) the depot, to the
passengers of the cut trip.
Trips i and j are a compatible pair of trips if the same
vehicle can reach the starting point of trip j after it ﬁnishes trip
i. A route is a sequence of trips in which all consecutive pairs
of trips in the sequence are compatible. Trip i is an itinerary
compatible trip with trip j if trip i shares the same itinerary
of cut trip j from the breakdown point until the ending point
of trip j.
The SDVRSP can be deﬁned as follows. Given a depot and
a series of trips with ﬁxed starting and ending times, given
the travel times between all pairs of locations, and given a
cut trip, ﬁnd a feasible minimum-cost reschedule in which
(1) each vehicle performs a feasible sequence of trips, and
(2) all passengers or cargo (if there are any) on the cut trip
are served. Unlike the SDVSP, in which the ﬁxed capital cost
is dominant, the SDVRSP problem focuses on operating and
delay costs. Furthermore, in order that transit crews can be
reassigned on a new schedule, the computation of SDVRSP
needs to be carried out as fast as possible.
There are two possible situations in SDVRSP. The ﬁrst is
when the cut trip is a regular one. Unless the disruption is such

that it is impossible to reach the breakdown point, the passengers (or cargo, but from this point we will only refer to serving
passengers in rescheduling of buses) of the cut trip have to be
served. The solution comprises sending a backup vehicle to
the breakdown point, and from there completing the cut trip,
and serving its passengers. However, since it is very likely that
some trips have common itineraries, the passengers can also
be served incidentally by the vehicles that cover compatible
itineraries after the breakdown point. Consider the following
situation: a backup vehicle changes its original schedule and
travels towards the breakdown point, but all the passengers
from the disabled vehicle have been incidentally picked up
by vehicles that cover compatible itineraries with the cut trip.
Such a situation needs to be avoided. If the cut trip is a deadheading trip, the solution is to assign a backup vehicle for the
starting location of the next trip of the deadheading vehicle.
In both cases, it is very likely that the SDVRSP provides new
routes (a reassignment) for a subset of the pre-assigned vehicles. Also, we can expect some delays in the cut trip, mainly
in the ﬁrst situation.
From the viewpoint of the cut trip, the remaining trips can
be divided into two categories: (1) unﬁnished trips that have
compatible itineraries with the cut trip from the breakdown
point, and (2) the remaining unﬁnished trips. Figure 1 illustrates these two categories where paths Oi − Di denotes trip
i from origin Oi to destination Di . The breakdown point is
point X on trip 1. Trips 2 and 3 are compatible with trip 1
from point X onwards.
Deﬁne set A to be the set of unﬁnished itinerary compatible
trips with the cut trip from the point X, ordered by the arrival
time from their current position to point X. Deﬁne set B to be
the remaining unﬁnished trips (including a trip directly from
the depot).
If the backup trip alternatives are from set A, the backup
vehicles can pick up the passengers incidentally. Although
a reschedule to service the cut trip may not be necessary, it
may be necessary to assign a vehicle from set B to cover the
unﬁnished trips originally assigned to the disabled vehicle. If
the backup trip alternatives are from set B, backup vehicles
need to travel toward the breakdown point for picking up the
passengers on the disabled vehicle.
In VSP, a vehicle can be generally assigned from the depot
to any trip before its starting time. Nevertheless, assigning a
vehicle from the depot to some future trips in the rescheduling

FIG. 1.

Example of compatible itinerary trips.

NETWORKS—2007—DOI 10.1002/net

213

problem may fail if the arrival time of a rescheduled vehicle
from the depot to the starting point of a trip is later than the
speciﬁed starting time of this trip. We may treat the depot s as
a special trip (or node) and deﬁne its starting time to be breakdown time. This time is used to determine if a backup vehicle
from the depot is too late to serve a speciﬁed future trip.
In VSP, there is no need to consider assigning a speciﬁc
vehicle to trips, since all vehicles are identical, and we can
assign them arbitrarily after the schedule is determined. However, unlike VSP, VRSP has to take into account this issue,
since many vehicles are not at the depot but at different locations in the service region when a vehicle becomes disabled.
The corresponding operating costs are also different. This
situation creates different possible feasible networks depending on the selected backup vehicle. Whereas there is a unique
feasible network in VSP, the VRSP may have several feasible networks (sharing same nodes, but with different arcs
connecting them).
Suppose that a regular trip becomes disrupted, and a
backup vehicle needs to go to the breakdown point to pick
up the passengers. The starting time of this cut trip is dependent on the backup vehicle. The cost and compatible trips
are different for alternative backup vehicles, since the serving vehicles are in different positions of the network, rather
than at the depot as is assumed in the VSP. This property
also provides a solution approach for VRSP; solving VRSP is
equivalent to solving a collection of several simple VSPs. It is
worth mentioning that, although there may exist many feasible networks, the differences among the networks are the arcs
associated with the cut trip and the backup trip candidates.
Vehicle rescheduling needs to be solved quickly, since
disruption delays will have a negative inﬂuence on system
performance, because they simultaneously result in increasing costs and deterioration of the level of service. Moreover,
crew members should be notiﬁed as quickly as possible of
a new schedule. However, it is very difﬁcult to deﬁne an
upper bound for the time to obtain a new schedule, since
this real-time operational issue is highly context dependent. Nevertheless, computational time requirements may be
somewhat mitigated by following a strategy where vehicles
currently serving regular trips can only change their routes
after ﬁnishing their current trips. We believe that a reasonable target for the computational time to reschedule should
be no more than a minute or two. Therefore, we assume the
following in our SDVRSP formulation:
• scheduled trips, except of course the cut trip, cannot suffer
delays; and
• there are no restrictions on the number of trips that may be
reassigned.

The next few sections describe our model formulation and
solution approaches for the SDVRSP. First, in Section 4.1,
we present a procedure to deﬁne the possible backup trip
candidates to construct the set of all feasible networks. This
is an essential step to solve the SDVRSP and it is included
in all of the developed algorithms. Next, in Section 4.2, an
integer linear programming formulation for the SDVRSP is
developed.

214

NETWORKS—2007—DOI 10.1002/net

In order to exploit problem structure, a sequential auction algorithm is described in Sections 5.1 and 5.2, based
on the algorithm developed by Freling et al. [18] for the
quasi-assignment formulation of the VSP. To further decrease
computational time, a parallel version of the auction algorithm that allows the bidding to be simultaneously conducted
in several processors is discussed in Section 5.3. Computational time is possibly further reduced when the solution
procedure is in two stages, where the ﬁrst stage provides an
initial solution for the second stage; Section 6 describes this
procedure.
4. MODELING THE VEHICLE RESCHEDULING
PROBLEM
The objective of the SDVRSP is to minimize operating and
delay costs over all possible underlying feasible networks. As
a consequence, any solution approach needs to explicitly or
implicitly generate the set of feasible networks.
4.1. Generation of Feasible Networks
The most important and complicating aspect of the
SDVRSP is that the solution is dependent on the current status of vehicles and the available alternatives to serve the cut
trip. Each possible conﬁguration of a recovery can be translated as a possible feasible network. These feasible networks
share the nodes (the trips), but have different arcs connecting them. The deﬁnition of the set of all possible feasible
networks is dependent on the pre-assigned conﬁguration of
trips, the available capacity of the involved vehicles, and the
times to carry out deadheading and regular trips. As commented in Section 3, it is possible to have a different feasible
network for each possible backup vehicle candidate. Since
vehicles are assigned to trips in the vehicle scheduling problem and network nodes are deﬁned as trips, we can use backup
trips (nodes) to deﬁne the feasible networks. This subsection
describes a procedure to generate the feasible networks based
on the available capacities of the involved vehicles, times to
service trips in the network and the compatibility of itineraries
of the trips.
A capacity problem appears if the backup trip is from
set A. It is quite possible that some passengers remain in
the disabled vehicle that was servicing the cut trip. If the
number of passengers remaining on the cut trip is greater
than the vacant capacity of the ﬁrst vehicle that can serve the
backup trip, this vehicle is not enough for picking up all of
the passengers. Thus, it is possible that more than one vehicle
needs to be sent to the breakdown point. The ﬁrst vehicle to
arrive at the breakdown point picks up some passengers, the
next vehicle picks up some more passengers, and so forth
until all passengers from the cut trip are served. If the backup
vehicle is from set B, it is an empty vehicle. In that case,
we assume that one vehicle is enough to pick up all of the
passengers from the disabled vehicle.
In addition to the capacity problem, we need to consider
time constraints related to the travel times of vehicles on

current trips. It is not possible to select a vehicle (or vehicles)
from set A if it has already passed the breakdown point when
the disruption occurs. Also, it is important to note that if a
vehicle from set B cannot reach the breakdown point earlier
than a vehicle from set A that will have enough vacant capacity, then it is inefﬁcient to use a vehicle from the set B to
service the cut trip.
To generate the set of possible feasible networks, we need
ﬁrst to determine how many backup trips from set A are sufﬁcient to serve all the passengers from the disabled vehicle. Let
C(i) be the empty seats (or remaining capacity) of the backup
vehicle from trip i when it reaches the breakdown point. Let
T (i) be its arrival time at the breakdown point. The values
of both variables may be obtained in real time, based either
on information to be provided by the vehicle crew or through
an automated GPS-based locator and passenger count system. Otherwise, estimations based on conservative values,
provided through historical data, are recommended to assure
that passengers on the cut trip will be served.
Let A(n) be the subset of A that includes the ﬁrst n elements of A. Let P be the number of passengers in the disabled
vehicle. Let Td be the disruption time. Let n∗ be the number
of backup trips in A that are capable of picking up passengers
from the cut trip. n∗ satisﬁes the following properties,

C(i) ≥ P
i∈A(n∗ )



C(i) < P

i∈A(n∗ −1)

T (i) ≥ Td ,

i ∈ A(n∗ ).

It is possible to deﬁne T (an∗ ) as the time by which the
n∗ vehicles can serve the passengers on the disabled vehicle,
where ai is the i-th element in set A(n∗ ). Then, we can determine B∗ , the set of backup trips candidates from set B that
can pick up the passengers between Td and T (an∗ ), by
B∗ = {m|Td ≤ T (m) < T (an∗ ), ∀m ∈ B}.
If B∗ is empty, then all backup trips are from set A(n∗ ).
In this situation, there is only one feasible network, resulting from eliminating the cut trip from the original network,

FIG. 2.

and the problem can be treated as a VSP. If at least one
backup trip candidate is from set B∗ , we can construct an
arc from this backup trip to the breakdown point to deﬁne
the corresponding feasible network. We may have several
feasible networks since several backup trip candidates may
exist.
If there is no value of n∗ that respects the above set of
inequalities, we set T (an∗ ) ← ∞, and set B∗ = B. In this
case, a vehicle from set B has to backup the cut trip.
After determining the set of backup vehicle candidates
(and the corresponding backup trips), we can generate the set
of all possible feasible networks as follows. Each regular trip
is a “node” of the feasible network, graphically represented as
a circle with a short interior line segment to indicate starting
and ending points of the trip (e.g., Fig. 2). Let b denote the cut
trip and K be the set of possible backup trip candidates. “Arcs”
in the feasible network correspond to vehicle assignment to
trips. For example, the arc from node 2 to node 4 in Figure 2a
implies the same vehicle may be assigned to trip 4 after it has
served trip 2. Let s and t denote the same depot in the network,
where s simply means the depot as a vehicle’s starting point,
and t as its terminating point. Let N  = N − {b} be the
set of total remaining trips excluding the cut trip, numbered
according to non-decreasing starting times. Let P ∈ N denote
the trips that vehicles are currently serving. If trip i, i ∈ P is a
deadheading trip, its starting time and ending time are set as
the current time, since the vehicle on this deadheading trip can
be rescheduled right away. Deﬁne arc-set E(k) = E ∪{(k, b)},
where E = {(i, j) ∈ {N ∪ s} × N  |[i < j]∧ [i and j are
compatible trips]} is the set of arcs that correspond to the
deadheading trips. A feasible network for backup trip k can
be deﬁned as G(k) = {V , X(k)} with nodes V = N ∪ {s, t}
and arcs X(k) = E(k) ∪ (s × P) ∪ (N × t), for k ∈ K, where k
is the backup trip. Since the trip in P is currently being served
by a vehicle, there is no need to allocate another vehicle to
cover it. The arcs, (s × P), are included only for modeling
convenience. We deﬁne G = {G(k)|k ∈ K} as the set of all
feasible networks.
We illustrate with an example, a set of feasible networks
and our procedure to construct them. Suppose we need to
perform four trips with the starting and ending times as indicated in Table 1, and the travel time from the ending point of

Examples of feasible networks.

NETWORKS—2007—DOI 10.1002/net

215

TABLE 1.

Travel times.

Trip

Starting time

Ending time

Duration

1
2
3
4
5

8
1
18
20
3

14
16
25
28
11

6
15
7
8
8

each trip (or depot) to the starting point of another trip is a
constant (4 time units).
Suppose a vehicle breaks down on trip 1 at a point X at
time 11, and the travel time from point X to the ending point
of trip 1 is 3 units. Other data for this example are as follows:
• the disabled vehicle is carrying 11 passengers at point X;
• on average, all vehicles have more than 16 available seats;
• trip 2 is an itinerary compatible trip with trip 1 from breakdown
point X, and vehicle serving trip 2 has not yet passed the point
X;
• the time required from any vehicle to reach the breakdown
point after completing its current regular trip is a constant, 3
time units; and
• the time of a vehicle from the depot to the breakdown point is
12 time units.

Thus, set A = {2} and set B = {0, 3, 4, 5}, where the
element 0 denotes the assignment of a vehicle from the depot.
Since the expected vacant capacity of the vehicle on trip 2
is 16, this vehicle can pick up all passengers. If the vehicles
from set B reach point X later than the time when the vehicle
on trip 2 arrives at point X, they cannot be considered as
backup trip candidates. Times vehicles reach point X from
set B are as follows: for trip 3, 25 + 3 = 28 time units, for
trip 4, 28 + 3 = 31 time units, and for trip 5, 11 + 3 = 14
time units.
The following cases are described in Figure 2 to illustrate the generation of the possible feasible networks, where
Figure 2a shows the initial schedule.
Case 1 (Suppose vehicle on trip 2 can reach point X at time
unit 11). In this case, the only backup trip candidate is trip
2. Although we do not need any backup vehicle to go to
the breakdown point, it is possible that an extra vehicle is
needed to cover some remaining trips assigned to the disabled
vehicle. In this case, there is only one feasible network (see
Fig. 2b). Trip 2 is ﬁnished on time. The feasible network can
be constructed by removing trip 1 and the associated arcs.
Case 2 (Suppose vehicle on trip 2 can reach point X at time
unit 13). In this case, the backup vehicle candidates are (i)
the vehicle assigned to trip 2, and (ii) an extra vehicle from
the depot. If the backup vehicle is the vehicle on trip 2, the
feasible network is given in Figure 2b. Figure 2c represents
the feasible network if the backup vehicle is an extra vehicle
from the depot. The time for this vehicle to ﬁnish trip 1 would
be 12 + 3 = 15. If this vehicle was also assigned to trip 3,
the time to the starting point of trip 3 is 15 + 4 = 19, which

216

NETWORKS—2007—DOI 10.1002/net

is more than the speciﬁed starting time of trip 3. Therefore
trips 1 and 3 become incompatible (19 > 18) and this new
vehicle cannot be assigned to trip 3.
Case 3 (Suppose vehicle on trip 2 can reach point X at time
unit 15). In this case, we have three possible backup trip
candidates, namely trip 5 and the same two as in case 2. If
the backup vehicle is on trip 2 or from the depot, the possible
feasible networks are depicted in Figures 2b and c, respectively. If the backup vehicle is the vehicle serving trip 5, its
time to ﬁnish trip 1 is 14 + 3 = 17; then the time to reach the
starting points of trips 3 and 4 is 17 + 4 = 21. Hence, trips
1 and 3, and trips 1 and 4, become incompatible (21 > 18
and 21 > 20, respectively). The feasible network for this
situation is given in Figure 2d. Notice that this case presents
three different feasible networks and the solution of the VRSP
involves ﬁnding the minimum operation and delay cost over
the three feasible networks.
Based on the underlying feasible networks, we can model
the VRSP as a VSP in each feasible network, and the VRSP
optimal schedule is the one with the minimum total cost over
all possible feasible networks. In order to decrease the number
of possible feasible networks if there are a large number, we
may deﬁne a time limit by which a vehicle has to arrive at
the breakdown point. If there are very many elements in B∗ ,
some candidates that exceed this time limit can be deleted
using this constraint and, hence, fewer feasible networks will
be considered.
4.2. Mathematical Formulation
The SDVRSP can be modeled as a minimization problem over several SDVSP problems, each corresponding to a
possible feasible network. Let yij be a binary decision variable, with yij = 1 if a vehicle is assigned to trip j directly
after trip i, yij = 0 otherwise. Let cij be the vehicle cost on
arc (i, j) ∈ X(k), which is a function of travel time and idle
time. Let Dk be the delay cost corresponding to the solution
with trip k as the backup trip. The quasi-assignment based
formulation for the SDVRSP is as follows:





min min
cij yij + Dk

G 
(i,j)∈X(k)

st



yij = 1

∀i ∈ N

yij = 1

∀j ∈ N

j:(i,j)∈X(k)



i:(i,j)∈X(k)

yij ∈ {0, 1} ∀(i, j) ∈ X(k).
The objective of this formulation is to ﬁnd a schedule with
the minimal operating plus delay cost. The constraints in the
formulation assure that each trip is assigned to exactly one
predecessor and one successor.

Freling et al. [18] compared the efﬁciency of several algorithms for the VSP, including the Hungarian algorithm [27],
successive shortest path algorithm [14], and the minimum
cost ﬂow approach [6] and showed that auction based algorithms are the fastest and most stable on average. Since
solving single-depot vehicle rescheduling problem is equivalent to solving |G| vehicle scheduling problems, the auction
algorithm was selected as our approach due to its excellent results for the VSP [18]. The auction method is also
well suited for implementation on parallel machines [4],
improving overall computational performance. This property
is important for the vehicle rescheduling problem since it
needs to be solved very quickly.
The next section discusses our sequential and parallel implementations of the auction-based algorithm for the
SDVRSP.
5. AUCTION-BASED ALGORITHMS FOR SOLVING
THE SDVRSP
Before describing the developed algorithms, we will
introduce the basic concepts related to auction algorithms.
5.1. Auction Algorithms: An Introduction
The auction algorithm was originally proposed by
Bertsekas [3] for the classical symmetric assignment problem. Given its computational performance, it was further
developed for the shortest path, the asymmetric assignment
problem, and the transportation problem [3]. In the classical
symmetric assignment problem, we need to match n persons
and n objects on an one-to-one basis. Let aij be the beneﬁt
of matching person i and object j. The objective function is
to maximize the total beneﬁt. In the auction algorithm, each
object j has a price pj , and this price is updated upwards as
persons bid for their best object, that is, the object for which
the corresponding beneﬁt minus the price is maximal.
The auction algorithm is composed of two phases: bidding phase and assignment phase. In the bidding phase, every
unassigned person looks for its “best” object; in the assignment phase, the object selects the person with the highest bid
since it may receive more than one bid. Meanwhile, if some
objects that have already been assigned to certain persons in
a preceding iteration are now assigned to new persons, the
persons who lost their objects are inserted into an unassigned
set. After all the persons and objects are matched, the auction
algorithm is terminated.
The combined forward and backward auction algorithm
consists of forward and backward auction iterations. In the
forward iteration, unassigned persons attempt to bid for
objects, while, in the backward iteration, unassigned objects
attempt to bid for persons. The combined auction algorithm
has also been used for quasi-assignment problems [18]. The
combined auction algorithm for these problems is similar to
the combined algorithm for the classical assignment problem,
except that the person and object which represent the depot
do not participate in the bidding. In the combined auction

algorithm for VSP, the person can be seen as the trip that is
forward assigned, and the object can be seen as the trip that is
backward assigned. The algorithms developed in the paper to
solve SDVRSP are based on the combined auction algorithm
developed by Freling et al. [18].
The performance of the auction algorithm is often
improved by using the  scaling of Bertsekas [3], where an 
is added to the prices, with  gradually decreasing in subsequent iterations. When  is less than n1 , where n is the number
of elements to assign, an optimal solution is obtained. As
suggested by Bertsekas and Castañon [4], a possible implementation of  scaling is as follows: the integer beneﬁts of
aij are ﬁrst multiplied by n + 1 and the auction algorithm is
applied with progressively lower values of , up to the point
where  becomes 1 or smaller. Using -scaling, the complexity of the algorithm is O(nm, log nC), where m is the number
of possible assignments between pairs of elements and C is
the maximum absolute beneﬁt.
Freling et al. [18] describes the auction algorithm as follows: The value of a bid of trip i (or person i) for another trip
j (or object j), which is a candidate for forward assignment,
is denoted by fij = aij − pj . The value of a bid of trip i for the
depot is denoted by fit = ait . Let N be the set of all trips and
M the arcs in the feasible network, respectively. Introduce πj
to denote the price of object j when the backward auction is
conducted.
Algorithm A_QP: Auction Algorithm for the QuasiAssignment Problem
Step 1. Perform the forward auction algorithm for each trip
i ∈ N (or person i) which is currently not assigned to a trip j
(or object j) or the depot.
Step 2. Determine the trip or depot ji with the maximum
bid value βi = max{fij |j : (i, j) ∈ M}. Determine also the
second highest value γi = max{fij |j : (i, j) ∈ M, j = ji }. If
trip i (or person i) has only one arc (i, j) ∈ M, set γi = −∞;
If ji = t go to step 4.
Step 3. Update the prices: pji = pji + βi − γi +  = aiji −
γi + , and πi = aiji − pji . Update the assignments. If trip
ji was already backward assigned, then remove the previous
assignment. Return to Step 1.
Step 4. Update the price: πi = ait , update the assignment,
and return to step 1.
The reverse auction procedure is similar, with bids for
candidates for the forward assignments replaced by bids for
candidates for the backward assignments [18].
5.2. Sequential Auction Algorithm for the VRSP
The sequential auction algorithm is based on the combined
forward-backward auction algorithm developed by Freling
et al. [18], considering the existence of several possible

NETWORKS—2007—DOI 10.1002/net

217

feasible networks to be solved. The algorithm is described
as follows:
Algorithm SA_VRSP: Sequential Auction Algorithm
for VRSP
Step 1. Based on the starting and ending times of trips and
travel time between trips, apply the procedure described in
Section 4.1 to build the set of all possible feasible networks.
Calculate the costs for the compatible trip pairs and the total
delay cost of each feasible network.
Step 2. For each feasible network, apply the forwardbackward combined auction algorithm [18] to ﬁnd the minimum cost scheduling (i.e., assignment) for each feasible
network as follows:
Step 2.1. Set the initial prices to 0. Set the initial  =
(n + 1) ∗ C, where C is the maximum absolute beneﬁt.
Step 2.2. Using current  and prices from last iteration,
conduct the bidding and assignment until all trips are both
forward and backward assigned.
Step 2.3. If  ≤ 1, the auction algorithm for current
feasible network terminates. Otherwise, set  = 0.5 ∗ 
and clear the assignment, go to step 2.2.
Step 3. Select the minimal operating and delay cost
schedule as the solution.
5.3. Parallel Auction Algorithm
The system for the parallel synchronous algorithm is
composed of an assignment processor and several bidding
processors, where the assignment processor is in charge of

FIG. 3.

218

NETWORKS—2007—DOI 10.1002/net

determining the prices and making the assignment, and the
bidding processor is in charge of conducting the bidding.
We employ the Jacobi method to implement the parallel auction algorithm since this method needs less synchronization
than the Gauss–Seidel method [4]. Suppose there are T bidding processors that conduct bidding. Then in the forward
(backward) auction, the unassigned persons (objects) are
partitioned into T subsets. Every bidding processor simultaneously conducts the bidding for a different subset. After
bidding in each processor is completed, the results, including the partial assignment and prices of persons and objects
for the speciﬁc subset, are sent to the assignment processor. When the assignment processor receives all results from
the T bidding processors, it combines them to determine the
new assignment and prices for all the unassigned persons
and objects. If some objects (persons) that have already been
assigned to some persons (objects) in a preceding iteration are
now assigned to new persons (objects), the persons (objects)
who lose the objects (persons) will be put into the set of
unassigned persons (objects).
The new assignment information is sent back to the T
bidding processors and the auction continues. After all the
persons and objects are assigned, the auction algorithm is terminated. A method that partitions the unassigned trips will be
presented later. Figure 3 illustrates the parallel synchronous
implementation of the Jacobi method.
Since the forward–backward combined auction algorithm
is used to solve SDVRSP, we have to determine if the auction should be forward or backward at each new iteration.
The ﬁrst iteration always uses a forward auction operation.
We employ the method from [3] to refrain from switching
between forward and backward auction until at least one more
person-object pair has been added to the assignment.
To partition the unassigned trips and simultaneously conduct the bidding, a simple partitioning method is used to
allocate each unassigned person (object) to the bidding

Parallel synchronous auction algorithm.

processors. Every bidding processor is assigned an ID, in
the range 0, 1, . . . , T − 1. Considering that there are M unassigned persons (objects) stored in a list L, the unassigned
persons (objects) for the bidding processor is deﬁned by
Q[ai ] = i mod T , 0 ≤ i ≤ M − 1, where ai is the i-th unassigned person (object) in list L, and Q[ai ] is the designed
bidding processor of person (object) ai .
A preprocessing technique is also employed for accelerating the computation and reducing the data-handling trafﬁc.
Consider the following situation: If there is an excessive number of unassigned persons for each bidding processor (this
typically happens in the early stages of auction algorithms),
it is quite likely that several persons bid for the same object
in the same bidding processor. It is possible to make partial assignments in each bidding processor rather than in the
assignment processor, considering the most dominant person requesting an object in the bidding processor. After the
partial assignment is carried out in each processor, only one
person bids for the same object in this bidding processor. This
partial assignment can reduce the amount of data sent to the
assignment processor. Computational experiments show that
this method signiﬁcantly reduces the running time of the parallel implementation. The parallel algorithm is described as
follows.
Algorithm PA_T_VRSP: Parallel Auction Algorithm
with T Processors for the VRSP
Step 1 and Step 3 are the same as the corresponding steps
in the sequential auction algorithm. Step 2 is as follows:
Step 2. For each feasible network, apply the forwardbackward combined parallel auction algorithm to ﬁnd the
minimum cost schedule for each feasible network as follows:
Step 2.1. Set the initial prices to 0. Set the initial  =
(n + 1) ∗ C. Send the information to bidding processors.
Step 2.2a. Upon receiving current , assignment and
prices from assignment processor, conduct the bidding
for the persons or objects allocated on each processor.
Then, make a partial assignment and send the results
to the assignment processor.
Step 2.2b. Based on the information received from
the bidding processors, determine a minimum-cost
assignment and the corresponding prices. If all persons
and objects are assigned, go to step 2.3. Otherwise, send
the assignment results to bidding processors and go to
step 2.2a.

computational performance if a better set of initial prices is
used. Bertsekas [3] states that “if the prices are near optimal,
we expect that the number of iterations to solve the problem
will be relatively small”. In this section, a method to ﬁnd near
optimal prices, referred to as the common feasible network,
is proposed.
Although the number of feasible networks can be large for
a problem involving several trips, the total number of backup
trip candidates is much smaller than the total trips. As a consequence, the large parts of the feasible networks are similar,
except for the arcs related to the cut trip. In a feasible network, the incoming arc of the cut trip is one from a backup
trip to the cut trip; this arc is different in different feasible
networks since the backup trip is different. Meanwhile, the
starting time of the cut trip is dependent on the backup trip.
Accordingly, the outgoing arcs of the cut trip are also dependent on the backup trip, since arc cost and compatible trip
pairs are based on the starting time of a trip. These arcs are
also different in the different feasible networks. Therefore,
if the cut trip and all the backup trips (they correspond to
nodes here) and the arcs associated with them are removed
from each feasible network, a sub-network that is common
for all feasible networks is obtained. If the backup trip is
from the depot, the node that denotes the depot is still kept in
the common feasible network, since every node needs to be
connected to the depot.
The common feasible network (CFN) can be obtained
from the intersection
 of all possible feasible networks as
follows: CFN =
k∈K G(k), where |K| ≥ 2. Figure 4
illustrates the common feasible network obtained from the
feasible networks presented in Figure 2.
The basic idea of the CFN approach is to solve the VRSP
in two stages. First, the auction algorithm is applied to the
CFN to obtain optimal prices of person and objects for this
reduced network. Next, the auction algorithm is applied for
all the feasible networks, using the ﬁnal prices obtained in
stage 1 as initial prices. The optimal prices obtained in stage
1 are likely to be closer to optimal and, therefore, these prices
provide a good set of initial prices for the second stage. With
better initial prices, the computation time for the second stage
is signiﬁcantly reduced.
To construct the feasible network corresponding to a
backup trip k, G(k) from CFN , the following nodes need

Step 2.3. If  ≤ 1, the schedule for the current feasible
network is optimal. Otherwise, set  = 0.5 ∗ , clear the
assignment and send the information to bidding processor,
and go to step 2.2.
6. COMMON FEASIBLE NETWORK APPROACH
As the computational time of the auction algorithm is
highly dependent on initial prices, it is possible to improve the

FIG. 4.

The common feasible network for the Figure 2 example.

NETWORKS—2007—DOI 10.1002/net

219

to be added to CFN: (i) the cut trip (b), and (ii) all backup
trip candidates, deﬁned by set K. Also, the following arcs
are added to CFN: (i) arc (k, b); (ii) arcs (b, j) such that b
and j are compatible trips, j ∈ N; (iii) arcs (c, j) such that c
and j are compatible trips, c ∈ K − {k}, j ∈ N; and (iv) arcs
(s, c), c ∈ K.
Appendix A gives an analysis why CFN improves computational performance towards solving VRSP, where we show
that the computational time to solve VRSP using the CFN
approach is expected to be less than without the use of the
CFN. Results presented in Section 7 support this analysis.
However, it cannot be claimed that the approach with the
CFN is better on every VRSP instance due to the following
reasons: (i) the upper bounds of the auction algorithms with
and without the CFN approach are not tight; and (ii) in order
to make this claim it is necessary to prove that the lower
bound of the approach without the CFN is worse than the
upper bound of the CFN approach. Both issues are presently
being investigated by the authors.
The CFN based auction algorithm is described as
follows.
Algorithm CFN_VRSP: Auction Algorithm for the VRSP
Using CFN
Step 1.

Determine the possible backup trips.

Step 2. Remove the cut trip and all backup trip candidates
and the arcs associated with them. Build CFN.
Step 3. Apply the sequential auction algorithm (or the
parallel auction algorithm when T ≥ 2 processors are
used) described in Section 5.2 (or Section 5.3) for the CFN
constructed in step 1.
Step 4. For each possible backup trip, build the corresponding feasible network from CFN.
Step 5. Using the optimal prices obtained in step 3 as the
initial prices, apply the sequential auction (a parallel auction when T processors are used) algorithm for each feasible
network.
Step 6. Select the optimal solution with the minimal
operating and delay cost.
We will denote CFN_T_VRSP as the parallel version of
the above algorithm when T ≥ 2 processors are used.
7. COMPUTATIONAL EXPERIMENTS
The main objective of computational experiments was
to compare the performance of the developed algorithms,
in terms of CPU time needed to obtain the optimum solution. Therefore, for convenience, we only included cost
of reallocating vehicles (including the vehicle for each

220

NETWORKS—2007—DOI 10.1002/net

backup trip) and not the cost of delay to passengers
on the disabled vehicle in the objective function for the
SDVRSP.
Since the constraint matrix is totally unimodular, the
solution of the linear relaxation for the VRSP provides an
optimal solution. Nevertheless, solving linear relaxation may
require longer times than the auction algorithm, because the
latter was specially designed to solve the VSP. We used
CPLEX 7.0 Network Optimizer to solve the linear relaxation of VRSP. CPU times of the linear relaxation and
of the auction algorithms were compared for veriﬁcation
purposes.
The algorithms were implemented in C++ on Sun-Fire880 Workstations, each of which with 2 UltraSPARCIII
processors at 900 MHz, 4 GB of RAM and a Solaris 9 operating system. The communication protocol used for parallel
implementation was developed based on the Socket/Stream
protocol. The following notation is used in the tables to
indicate the implemented algorithms:
(a) CPLEX: The use of CPLEX7.0 to solve the linear
relaxation of VRSP;
(b) SAV : The sequential auction algorithm, SA_VRSP;
(c) PA2: The parallel auction algorithm using two processors, PA_2_VRSP;
(d) PA4: The parallel auction algorithm using four processors, PA_4_VRSP;
(e) CFN: The sequential auction algorithm with CFN,
CFN_VRSP;
(f) CFN2: The parallel auction algorithm with CFN using
two processors, CFN_2_VRSP;
(g) CFN4: The parallel auction algorithm with CFN using
four processors, CFN_4_VRSP.

7.1. Experiments Conﬁguration
The experiments were designed using Carpaneto et al.’s [9]
random data generation method for VSP. Let ρ1 , ρ2 , . . . , ρv
be relief points (i.e., points where trips can start or ﬁnish)
of a transportation network. We generate them as uniformly
random points on a (60 × 60) square and compute the corresponding travel times θρa ,ρb as Euclidean distances between
relief points ρa and ρb . To simulate the trips, we generate
for each trip Tj (j = 1, . . . , n) the starting and ending relief
points, ρj and ρj , randomly selected from ρ1 , ρ2 , . . . , ρv . The
travel time between trips Ti and Tj is deﬁned as θρi ρj , ∀i, j. The
starting and ending times, sj and ej , of trip Tj are generated
by considering two classes of trips: short trips and long trips.
For short trips, sj is a uniformly random integer in interval
(420, 480) with probability 0.15; in interval (480, 1020) with
probability 0.70; and in interval (1020, 1080) with probability 0.15. Since ending time ej for trip Tj must include a travel
time between ρj and ρj , and dwell time at vehicle stops, we
generate ej as a uniformly random integer in (sj + θρj ,ρj + 5,
sj + θρj ,ρj + 40). For long trips, we assume they start and end
at the same point, and the travel time depends on the length
of resultant cycles and associated stops. Then we generate
sj as a uniformly random integer in (300, 1200), and ej as
uniformly random integer in (sj + 180, sj + 300). Costs cij ,

csi and cjt are deﬁned to include travel time and waiting time;
we used
• cij = 10θi,j + 2(sj − ei − θi,j ), for all compatible pairs (Ti , Tj );
• csi = 10 (Euclidean distance between the depot and the starting point of trip Ti )
 + 2,000, for trips from the depot to route
Ti ; and
• cjt = 10 (Euclidean distance between the depot and the
ending point of trip Tj )
 + 2,000, for trips from Tj to the
depot.

In order to compare the computational efﬁciency of the
different algorithms, we consider two situations: (i) the total
number of trips is composed of a 40:60 combination of short
and long trips (class L); (ii) the total number of trips is only
composed of short trips (class S).
To evaluate the performance of the algorithms, we ﬁrst
generated a VSP problem and solved it. Then, a disruption
was introduced so that an early short trip is chosen as the cut
trip (trip Tb ). Since in Carpaneto et al.’s [9] data generation
method, long trips are cycles with same start and end locations, making it difﬁcult to deﬁne a breakdown point with
respect to start time, we only chose short trips as possible
cut trips. We assumed that vehicles break down in the middle of the cut trip in time and distance. The arrival time of
a backup vehicle candidate to the breakdown point is calculated as follows: (i) for a backup vehicle on a regular trip,
the arrival time is the ending time of the current trip plus the
travel time from the ending point to the breakdown point; and
(ii) for a vehicle on a deadheading trip, the arrival time is the
current time plus the travel time from its current location to
the breakdown point. Euclidean distances are used as travel
distances.
In real-life situations, the determination of backup trip
candidates requires knowledge of vehicle capacity and common itineraries (see Section 4.1). However, in our experiments, the backup trip candidates are generated based
on distances and travel times. In order to simplify the
experiments and to better compare the algorithms, we
assumed that K, the number of backup trips, is such that
K ∈ {2, 3, 5, 10, 15, 20, 25, 30, 35, 40} for test cases with
more than 300 remaining trips. For test cases with 100
and 300 remaining trips, K ∈ {2, 3, 5, 10} and K ∈
{2, 3, 5, 10, 15, 20}, respectively, since smaller-size problems
have fewer backup vehicles. We sorted the existing vehicles
using their arrival times to the breakdown point and selected
the ﬁrst K vehicles as the backup vehicle candidates. Note
that these considerations are coherent with the main objective of the experiments, to compare the performance of the
implemented algorithms. The procedure to ﬁnd the backup
vehicle candidates, described in Section 4.1, has already been
tested in a real life application described in [35]. The new
starting time, ST , of the cut trip is the arrival time of a particular backup vehicle at the breakdown point plus a 3− min
start-up service time. The costs of the out-going arcs of the
cut trip i are calculated using the expression deﬁned for cij ,
i
considering the new ending time of trip i as ST + ei −s
2 .

7.2. Results
Tables 2 and 3 compare the performance of algorithms
CPLEX, SAV, PA2, PA4, CFN, CFN2, and CFN4 for 10
instances of each problem in classes L and S, respectively.
The ﬁrst ﬁve columns display the number of remaining
trips, the average original number of vehicles, the number of
backup trips considered, the average number of new vehicles
required to ﬁnish remaining trips, and the average optimal
cost, respectively. Remaining columns show the average CPU
times in seconds, excluding input and output time, for the
seven algorithms. For example, if the remaining trips are 100
in class L, the number of vehicles needed for the original
VSP is 28.6 on average over 10 instances (see ﬁrst row in
Table 2). If the number of remaining trips is 500 and there
are two backup trip candidates in class L, the average number
of vehicles needed for the VRSP is 122.1, and the optimal
solution cost averaged 564,555 over 10 instances. Problems
in class S are much more difﬁcult to solve since this class
contains only short trips, increasing the number of arcs in
each possible feasible network.
The tables show that an increase in the number of available
backup trips decreases optimal cost, characterizing a tradeoff between CPU time and the optimal cost, deﬁned by the
number of possible backup trip alternatives being considered.
Taking into consideration (i) the small differences in the average optimum cost between 2 and 40 backup trips alternatives
for large problems, and (ii) the considerable increase in the
average CPU time for these problems, it may be worthwhile
to develop heuristics to prune the number of possible backup
trip alternatives, specially for large trips. The idea is to select
and solve the problem only for a representative subset, in
a way that the feasible network that leads to the optimum
solution is included, with a high probability, in the solution
space.
An extra vehicle is needed to replace the disabled vehicle when the number of vehicles in the rescheduling problem
turns out to be equal to the number of vehicles in the original scheduling. This is conﬁrmed by the values presented in
second and fourth column in Tables 2 and 3, in which the average number of vehicles to ﬁnish the trips is, in many cases,
approximately equal to the average initial number of vehicles. The reason why an extra vehicle is sometimes needed in
VRSP, as compared to VSP, is that in the vehicle rescheduling at the current system state, some deadheading vehicles
are out of the depot at inconvenient positions in the network,
while some trips need still to be ﬁnished.
The average CPU time for all algorithms is highly dependent on the problem size. The table shows that for small
problems (100 remaining trips) all algorithms are extremely
fast, solving problems, even with high values of |K| in less
than 1s CPU time. Comparing CPLEX and SAV, we can
afﬁrm that the auction-based algorithm is more efﬁcient for
all analyzed situations. To ﬁnd the optimum solution, algorithm SAV reduces the required CPU time over the CPLEX
by, on the average, 328.63%. The auction algorithm is more
efﬁcient for small and medium-sized problems (up to 1,000

NETWORKS—2007—DOI 10.1002/net

221

TABLE 2.

Computational results - class L.
Average CPU seconds

Remaining
trips

Initial #
of vehicles

Backup
trips

New #
of vehicles

Objective
value

CPLEX

SAV

PA2

PA4

CFN

CFN2

CFN4

100

28.6

300

76.0

500

121.6

700

165.2

900

211.0

1,100

253.6

1,300

302.8

2
3
5
10
2
3
5
10
15
20
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40

29.0
28.8
28.6
28.6
76.6
76.4
76.2
76.0
76.0
76.0
122.1
122.0
121.9
121.6
121.6
121.6
121.6
121.6
121.6
121.6
165.8
165.5
165.3
165.1
165.1
165.1
165.1
165.1
165.1
165.1
211.0
210.9
210.9
210.7
210.7
210.7
210.7
210.7
210.7
210.7
253.5
253.5
253.5
253.2
253.2
253.2
253.1
253.1
253.1
253.1
302.8
302.6
302.6
302.5
302.4
302.4
302.4
302.4
302.4
302.4

135, 407
134, 516
133, 601
133, 511
356, 042
355, 100
354, 189
353, 284
353, 256
353, 233
564, 555
564, 071
563, 603
562, 277
562, 267
562, 232
562, 219
562, 214
562, 193
562, 179
767, 241
766, 037
765, 181
764, 322
764, 213
764, 154
764, 151
764, 141
764, 135
764, 128
1, 029, 542
1, 028, 997
1, 028, 957
1, 028, 106
1, 028, 091
1, 028, 066
1, 028, 059
921, 768
818, 583
818, 576
1, 218, 215
1, 218, 200
1, 218, 162
1, 216, 918
1, 216, 906
1, 216, 885
1, 216, 458
1, 216, 446
1, 216, 446
1, 216, 444
1, 440, 810
1, 439, 972
1, 439, 964
1, 439, 139
1, 438, 699
1, 438, 686
1, 438, 686
1, 438, 674
1, 438, 662
1, 438, 662

0.09
0.13
0.22
0.45
0.88
1.32
2.20
4.42
6.65
8.87
2.96
4.41
7.31
14.55
21.80
29.05
36.33
43.58
50.82
58.09
6.71
10.07
16.82
33.56
50.41
67.31
84.16
101.03
117.96
134.85
13.15
19.81
33.16
66.46
99.85
133.31
166.81
200.22
233.61
267.11
21.54
32.32
54.12
108.87
163.53
217.79
271.89
325.98
380.22
434.49
33.04
49.38
82.52
165.47
248.13
331.27
414.24
496.81
580.11
662.99

0.01
0.02
0.03
0.07
0.21
0.31
0.51
1.01
1.49
1.98
0.72
1.07
1.78
3.50
5.16
6.78
8.43
10.08
11.73
13.38
1.73
2.60
4.30
8.33
12.47
16.43
20.33
24.21
28.05
31.90
4.16
6.23
10.31
20.62
30.86
41.07
51.19
61.16
71.19
81.17
10.99
16.47
27.23
54.03
80.40
106.77
133.17
159.13
185.34
211.48
18.91
28.31
46.66
91.86
136.87
182.19
226.62
271.51
315.62
359.45

0.05
0.08
0.13
0.25
0.18
0.27
0.48
0.91
1.32
1.75
0.50
0.75
1.16
2.29
3.30
4.32
5.29
6.34
7.35
8.35
0.82
1.26
2.07
4.06
6.10
8.11
10.03
11.94
13.97
15.87
1.45
2.17
3.55
7.10
10.46
13.84
17.16
20.45
23.69
26.99
2.84
4.30
7.02
13.48
19.82
26.38
32.80
39.20
45.63
51.95
4.34
6.51
10.97
21.64
32.19
42.68
52.70
62.88
73.05
82.80

0.04
0.05
0.08
0.18
0.17
0.25
0.41
0.75
1.13
1.52
0.35
0.53
0.91
1.82
2.69
3.56
4.41
5.24
6.05
6.92
0.70
1.07
1.78
3.53
5.22
6.84
8.39
9.96
11.51
13.12
1.18
1.74
2.87
5.73
8.52
11.35
14.07
16.79
19.56
22.32
2.03
3.15
5.35
10.62
15.73
20.97
26.11
31.24
36.43
41.60
3.53
5.31
8.88
17.50
25.74
34.25
42.25
50.52
58.45
66.21

0.02
0.03
0.03
0.07
0.23
0.30
0.45
0.80
1.19
1.52
0.84
1.12
1.68
3.05
4.24
5.34
6.71
8.36
9.47
10.78
2.06
2.70
4.07
7.02
10.06
12.47
15.49
18.60
20.90
23.55
4.32
5.49
7.49
13.70
19.40
25.33
31.56
40.07
46.27
49.70
10.54
13.43
19.36
35.09
49.48
65.28
81.47
97.13
113.97
128.50
19.45
25.22
34.92
63.65
91.33
128.65
149.93
181.64
213.66
232.24

0.04
0.06
0.09
0.19
0.22
0.30
0.45
0.77
1.01
1.33
0.54
0.66
1.07
1.88
2.71
3.28
4.32
5.27
5.97
6.80
1.10
1.42
2.09
3.94
5.71
6.86
8.49
10.12
11.55
13.24
1.58
2.22
2.96
5.79
7.86
10.03
13.04
16.48
18.73
19.84
2.96
3.67
6.43
10.74
15.64
20.94
25.77
29.51
34.85
37.36
5.12
7.11
9.75
18.79
28.23
39.78
45.88
58.80
68.93
72.95

0.04
0.07
0.10
0.18
0.17
0.24
0.36
0.63
0.91
1.12
0.46
0.56
0.91
1.64
2.29
2.99
3.72
4.53
5.32
5.95
0.93
1.27
1.96
3.40
4.75
5.89
7.49
8.88
9.94
11.29
1.33
1.75
2.34
4.59
6.60
8.53
10.62
13.79
15.59
16.56
2.32
3.08
4.51
8.58
12.01
15.66
19.69
23.49
27.73
30.87
4.03
5.39
7.65
15.00
21.92
31.82
37.49
43.91
53.17
56.47

222

NETWORKS—2007—DOI 10.1002/net

TABLE 3.

Computational results - class S.
Average CPU seconds

Remaining
trips

Initial #
of vehicles

Backup
trips

New #
of vehicles

100

18.1

300

48.9

500

78.0

700

106.7

900

133.2

1,100

163.5

1,300

190.4

2
3
5
10
2
3
5
10
15
20
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40

18.6
18.3
18.1
18.1
49.7
49.4
49.3
49.0
48.9
48.9
77.4
77.8
78.2
78.5
78.6
78.3
78.1
78.0
78.0
78.0
106.5
107.4
107.3
107.1
107.1
106.9
106.8
106.8
106.8
106.8
133.2
133.4
133.2
133.1
133.1
133.0
133.0
133.0
133.0
133.0
164.6
164.7
164.6
164.5
164.5
164.5
164.5
164.5
164.4
164.4
190.4
190.4
190.4
190.1
190.1
190.0
189.9
190.0
190.0
190.0

Objective
value

CPLEX

SAV

PA2

PA4

CFN

CFN2

CFN4

93, 739
92, 280
91, 431
91, 358
249, 782
248, 387
247, 896
246, 580
246, 133
246, 099
392, 235
391, 764
391, 273
389, 579
389, 562
389, 512
389, 487
389, 478
389, 468
389, 462
551, 275
548, 699
547, 782
547, 300
547, 294
547, 257
547, 241
547, 222
547, 220
547, 207
695, 105
695, 058
694, 177
693, 700
693, 690
693, 241
693, 226
693, 223
693, 219
693, 219
885, 735
884, 557
884, 499
883, 151
883, 141
883, 141
883, 084
883, 084
883, 081
883, 079
999, 106
998, 612
998, 565
996, 805
996, 758
996, 328
995, 883
995, 876
995, 875
995, 875

0.11
0.17
0.28
0.56
1.24
1.86
3.09
6.19
9.28
12.37
4.02
6.03
10.06
20.15
30.28
40.41
50.54
60.66
70.76
80.89
9.70
14.55
24.12
48.23
72.35
96.46
120.64
144.86
169.05
193.16
18.65
28.02
46.71
93.55
140.23
186.72
233.17
279.89
326.61
373.07
31.07
46.66
77.59
155.49
233.24
310.56
387.71
464.80
541.97
619.06
46.03
69.15
115.23
229.85
345.76
461.09
576.78
693.54
810.69
927.38

0.02
0.03
0.05
0.11
0.37
0.55
0.90
1.77
2.61
3.43
1.29
1.96
3.23
6.25
9.29
12.30
15.26
18.17
21.11
23.98
3.43
5.06
8.28
16.38
24.70
32.37
39.99
47.66
55.59
63.12
12.87
19.11
31.69
63.83
95.41
126.29
156.82
187.21
217.84
248.46
27.26
40.47
66.55
131.78
196.42
263.57
328.93
393.78
458.62
523.49
43.52
65.45
108.57
215.81
321.79
425.71
531.14
639.36
747.78
854.38

0.07
0.10
0.14
0.32
0.32
0.50
0.82
1.55
2.19
2.81
0.81
1.21
2.01
3.84
5.75
7.59
9.40
11.27
13.10
14.98
1.82
2.68
4.49
8.95
13.45
17.49
21.69
25.78
29.99
33.94
3.537
5.273
8.785
17.505
26.278
34.673
43.244
51.384
59.702
67.652
6.02
8.93
14.74
29.57
44.03
58.66
73.51
87.88
102.21
116.60
9.38
13.93
22.98
45.70
68.32
91.21
113.51
136.19
159.09
181.83

0.04
0.06
0.11
0.24
0.20
0.31
0.53
1.14
1.72
2.29
0.70
1.03
1.64
3.17
4.67
6.15
7.61
9.05
10.51
11.98
1.43
2.13
3.54
6.93
10.52
13.85
17.15
20.40
23.78
26.91
2.719
4.094
7.013
13.541
20.273
27.147
34.007
40.215
46.685
52.978
5.02
7.62
12.23
24.22
36.10
48.36
60.74
72.74
84.39
96.13
7.65
11.62
19.25
37.87
56.59
74.79
93.21
112.51
131.04
150.13

0.02
0.04
0.05
0.10
0.46
0.61
0.86
1.66
2.36
3.17
1.56
2.23
3.21
5.58
7.76
9.88
12.03
13.55
15.53
17.33
4.03
5.44
8.19
14.79
21.79
28.89
33.97
38.55
45.92
51.01
14.40
18.66
26.90
48.51
69.07
90.84
115.44
139.14
157.50
181.35
28.44
37.26
54.10
92.98
138.58
181.24
228.69
269.41
327.80
370.36
48.00
63.03
90.96
158.85
227.91
292.17
353.78
433.50
502.44
569.10

0.09
0.10
0.12
0.31
0.41
0.57
0.70
1.51
2.12
2.86
1.17
1.47
2.22
4.07
5.42
6.93
8.29
9.96
11.18
12.90
2.31
3.53
4.96
9.62
13.34
18.39
23.25
24.17
29.41
32.09
3.77
5.83
8.19
16.92
22.89
29.26
38.87
47.29
55.13
62.11
7.08
8.93
12.81
25.14
34.53
48.05
63.46
74.55
92.55
108.62
10.76
13.68
22.50
40.24
56.85
75.83
94.55
115.12
132.42
145.46

0.05
0.08
0.12
0.18
0.31
0.42
0.60
1.08
1.59
2.04
0.80
1.26
1.74
3.15
4.42
5.58
6.66
7.80
8.92
10.28
1.74
2.46
3.87
6.91
10.40
13.67
16.21
18.33
22.13
24.29
3.26
4.14
6.31
11.47
16.40
21.67
28.47
36.09
40.62
47.72
5.29
6.88
10.62
18.51
27.66
36.95
47.76
58.09
70.82
83.69
9.04
11.33
16.67
31.54
44.84
60.51
74.99
93.03
106.24
119.42

NETWORKS—2007—DOI 10.1002/net

223

remaining trips). As the problem size increases, the auction
algorithm slightly reduces its efﬁciency. For large-sized problems, the CPU time differences between CPLEX and SAV
are much smaller for class S than for class L. There are
much more arcs in class S than in class L. It appears that
the auction algorithm tends to be more inﬂuenced by the
underlying network density than the network simplex used
in the CPLEX method. In summary, we can conclude that
the auction based algorithms are computationally efﬁcient in
solving the SDVRSP.
Computational results show that parallel processing does
not improve CPU times for small problems. The reason
for this due to the required communication cost among the
multiple processors. However, for large problems, the communication time decreases its relevance and the slightly
increased time is compensated by the fast processing time
of the auction algorithm. The parallel auction with common
feasible network using 4 processors is, on average, the most
efﬁcient for large problem sizes, in terms of the number of
remaining trips and possible backup trips. Even for very large
problems, such as 1300 remaining trips and 40 backup trips,
this algorithm provides optimal solution in an acceptable
amount of time (around 119s, considering only short trips).
The parallel algorithms with the common feasible network
(CFN2 and CFN4) become more efﬁcient for both classes
as problem size increases (more remaining trips and more
backup trips).
Figures 5 and 6 present a pairwise comparison on the average relative CPU time percentage, referred to as CPUper ,

FIG. 5.

224

considering SAV as the comparison basis. Figure 5 compares the algorithms in terms of the number of remaining
trips, while Figure 6 compares them in terms of the number
of backup trips. CPUper is computed as follows:
CPUper = 100 ×

where CPUSAV is the CPU time required by the algorithm
SAV to ﬁnd the optimum solution of SDVRSP, and CPUA
is the CPU time required by the algorithm being compared,
say algorithm A. For problems with more than 300 remaining
trips, the use of parallelism results in signiﬁcant reductions
on the average CPU time required to solve the problems.
Reductions in the CPU times are more signiﬁcant for larger
problems and more backup trips.
Table 4 indicates the main explanation for the good performance of the CFN-based algorithms. This table gives
the average number of iterations required by the sequential
auction algorithm with and without using CFN to solve 10
instances of each problem for both the classes. In this table,
we report the relative percentage of the number of iterations
for CFN-based algorithms, deﬁned by
Iper = 100 ×

ICFN
I

where I is the number of iterations without using CFN and
ICFN is the number of iterations using the CFN approach.

Average CPU time percentage vs. the number of remaining trips.

NETWORKS—2007—DOI 10.1002/net

CPUA
CPUSAV

FIG. 6.

Average CPU time percentage vs. the number of backup trips.

For class L, CFN algorithms requires, on average, 74.91%
the number of iterations in comparison with non-CFN algorithms. For class S, the percentage was, on average, 84.78%.
However, note that for very small number of backup trips
(especially 2 and 3), the CFN algorithm does not work better, on average, than algorithms that do not use CFN (see
plots in Fig. 6). For example, for problems with 100 remaining trips and 2 backup trips, the CFN algorithm requires,
on average, an 11.30% increase in the number of iterations.
This is because of the -scaling method used in the second stage of CFN approach to obtain convergent stability.
As a consequence, the optimal prices from stage 1 are near
optimal prices for the ﬁrst subproblem in stage 2. In our
implementations, the ratio, say R, between the average number of iterations in stage 2 and the total number of iterations
in stage 1 is in the range [0.55, 0.82]. If we consider that
the average number of iterations without using CFN is given
by |K|L, where L is the average number of iterations for
each k ∈ K, then the number of iterations for CFN will
be approximately given by L + |K|RL. For |K| = 2, the
average number of iterations will be 2L without using CFN,
and about L + 2 × 0.82 × L = 2.64L when using CFN,
resulting in an increase in the number of iterations. However, for |K| = 40, the corresponding values are 40L and
L + 40 × 0.83 × L = 34.2L, respectively, generating a
smaller Iper .
Table 5 presents the speedup factors for algorithms with
and without using CFN. Since parallel implementations are
not faster for small-size problem, we only present speedup

factors for problems with more than 300 remaining trips.
We can see that when the problem becomes larger, parallel
implementations provide signiﬁcant CPU time reduction. For
example, when there are 1,100 remaining trips in class L, a
parallel auction algorithm with two processors is, on average,
four times faster than its sequential counterpart. This is possibly explained as follows. For a large problem, the CPU cache
is not sufﬁcient for the sequential algorithm, resulting in
swapping between the CPU cache and slower RAM, increasing signiﬁcantly the CPU time of sequential algorithms to
ﬁnd the optimum solution. Since in parallel implementations,
every processor conducts computations on a subset of the
whole problem, the use of CPU cache is smaller than for its
sequential counterpart, mitigating swapping between CPU
cache and RAM.
8. CONCLUSIONS
This paper introduces and models the single depot vehicle rescheduling problem and presents several algorithms to
solve this problem. The solution approach is based on (i) the
generation of all possible feasible networks obtained when
a trip is disrupted, and (ii) the application of auction algorithms for solving the resultant vehicle scheduling problem.
In addition, the use of parallel processing and the common
feasible network (CFN) approach improves the speed of the
auction algorithms.
The CFN method performs the auction algorithm in two
stages. In the ﬁrst stage, the algorithm is carried out for a

NETWORKS—2007—DOI 10.1002/net

225

TABLE 4.

Comparison of the number of iterations for the sequential auction algorithm with and without using the CFN.
Class L

Remaining
trips
100

300

500

700

900

1,100

1,300

226

Class S

Backup
trips

Without CFN

With CFN

I_per (%)

Without CFN

With CFN

I_per (%)

2
3
5
10
2
3
5
10
15
20
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40
2
3
5
10
15
20
25
30
35
40

4, 370
6, 562
11, 015
22, 092
20, 622
30, 871
51, 082
101, 788
151, 998
202, 247
41, 682
62, 177
103, 954
206, 484
306, 520
405, 176
504, 779
605, 166
704, 922
805, 760
69, 545
104, 537
173, 789
339, 789
509, 738
674, 101
837, 457
1, 000, 397
1, 162, 426
1, 324, 799
100, 059
149, 861
248, 334
495, 989
742, 760
988, 506
1, 232, 593
1, 474, 668
1, 717, 956
1, 961, 265
142, 379
213, 160
351, 301
697, 461
1, 040, 391
1, 381, 852
1, 724, 343
2, 063, 246
2, 405, 397
2, 745, 713
180, 424
271, 627
449, 410
886, 438
1, 318, 516
1, 753, 211
2, 178, 847
2, 610, 488
3, 035, 719
3, 457, 568

4, 864
6, 390
9, 800
18, 846
21, 993
28, 488
41, 530
72, 618
108, 810
140, 121
46, 756
61, 023
89, 950
160, 767
225, 004
287, 815
358, 126
444, 217
508, 677
583, 449
78, 666
101, 265
149, 187
256, 528
364, 453
456, 892
569, 597
680, 809
772, 101
873, 473
98, 261
124, 123
168, 303
303, 054
424, 118
553, 871
688, 691
868, 447
1, 010, 284
1, 086, 438
133, 731
168, 960
241, 161
436, 318
612, 454
806, 060
1, 002, 762
1, 198, 551
1, 400, 586
1, 583, 387
182, 643
237, 701
327, 699
596, 912
862, 114
1, 220, 468
1, 427, 534
1, 726, 665
2, 033, 132
2, 203, 216

111.30
97.39
88.97
85.31
106.65
92.28
81.30
71.34
71.59
69.28
112.17
98.14
86.53
77.86
73.41
71.03
70.95
73.40
72.16
72.41
113.1
96.87
85.84
75.50
71.50
67.78
68.02
68.05
66.42
65.93
98.20
82.83
67.77
61.10
57.10
56.03
55.87
58.89
58.81
55.39
93.93
79.26
68.65
62.56
58.87
58.33
58.15
58.09
58.23
57.67
101.23
87.51
72.92
67.34
65.39
69.61
65.52
66.14
66.97
63.72

5, 543
8, 314
13, 909
28, 249
28, 079
42, 162
69, 619
137, 310
202, 778
266, 421
59, 180
89, 561
148, 339
288, 727
429, 713
569, 305
706, 917
843, 121
979, 928
1, 113, 859
108, 024
159, 770
262, 051
519, 543
782, 475
1, 027, 346
1, 27, 0495
1, 514, 442
1, 766, 807
2, 008, 187
158, 272
235, 163
391, 965
789, 359
1, 182, 914
1, 568, 450
1, 949, 303
2, 329, 861
2, 711, 335
3, 090, 942
231, 976
344, 989
570, 423
1, 13, 0573
1, 683, 398
2, 254, 404
2, 812, 030
3, 370, 602
3, 927, 923
4, 485, 906
293, 920
439, 263
731, 269
1, 458, 431
2, 179, 992
2, 888, 851
3, 601, 806
4, 322, 864
5, 042, 982
5, 753, 194

6, 220
8, 311
12, 185
24, 862
35, 273
46, 617
65, 664
125, 162
176, 913
238, 173
70, 764
99, 875
142, 688
243, 909
339, 443
430, 656
523, 377
591, 957
677, 673
759, 086
125, 506
167, 659
248, 179
444, 486
648, 405
859, 393
1, 012, 623
1, 147, 414
1, 363, 320
1, 515, 446
179, 998
234, 565
341, 189
617, 562
869, 626
1, 15, 3300
1, 491, 448
1, 832, 350
2, 091, 371
2, 435, 687
241, 933
318, 412
462, 232
787, 783
1, 177, 799
1, 556, 979
1, 986, 139
2, 367, 075
2, 871, 917
3, 359, 065
318, 473
417, 065
605, 347
1, 064, 770
1, 521, 593
1, 973, 755
2, 399, 003
2, 912, 496
3, 367, 081
3, 842, 732

112.21
99.97
87.61
88.01
125.62
110.57
94.32
91.15
87.24
89.40
119.58
111.52
96.19
84.48
78.99
75.65
74.04
70.21
69.16
68.15
116.18
104.94
94.71
85.55
82.87
83.65
79.70
75.76
77.16
75.46
113.73
99.75
87.05
78.24
73.52
73.53
76.51
78.65
77.13
78.80
104.29
92.30
81.03
69.68
69.97
69.06
70.63
70.23
73.12
74.88
108.35
94.95
82.78
73.01
69.80
68.32
66.61
67.37
66.77
66.79

NETWORKS—2007—DOI 10.1002/net

TABLE 5.

Speedup factors.

Class L

Class S

Remaining trips

300

500

700

900

1100

1300

300

500

700

900

1100

1300

SAV/PA2
SAV/PA4
CFN/CFN2
CFN/CFN4

1.13
1.29
1.06
1.30

1.54
1.94
1.59
1.84

2.05
2.42
1.83
2.11

2.94
3.61
2.49
3.03

4.00
5.14
3.29
4.21

4.30
5.34
3.34
4.28

1.15
1.64
1.13
1.50

1.61
1.97
1.41
1.78

1.85
2.35
1.59
2.14

3.64
4.66
3.10
4.14

4.49
5.42
3.81
4.93

4.69
5.68
4.01
5.01

reduced network that excludes the cut trip and the backup
trip candidates (served by possible backup vehicles). Then
an assignment close to the original one is obtained since
this reduced network is very similar to the original feasible networks. In the second stage, the cut trip and backup
trips are introduced to reconstruct feasible networks. The
auction algorithms are applied again, using the initial prices
obtained in the ﬁrst stage. The second stage is performed for
all candidate backup vehicles.
From extensive computational experiments performed on
randomly generated data, the following observations were
made:
1. For small problems (less than 300 remaining trips), both
sequential and parallel implementations are fast. The
sequential algorithm, without using parallel processing,
provided the solution with the smallest CPU time on
average, because the added communication time between
processors was not offset by the computational efﬁciency
gained with parallel algorithms.
2. For large problems (more than 300 remaining trips), the
parallel algorithms using CFN very often provided the best
performance on average. On average, the fastest algorithm
was the parallel auction using CFN and four processors.
3. While CFN-based algorithms do not reduce computation
time when candidate backup trips are two or three, they
considerably mitigate computational efforts when backup
trips are more than ﬁve. The good performance of CFNbased algorithms is explained by the smaller number of
iterations required to ﬁnd the optimal solution. On average, the use of the CFN approach requires around 79.85%
of the iterations required by the auction algorithm that
does not use CFN.

In summary, it can be concluded that the solution
approaches developed in this paper are computationally efﬁcient for their application to real-time schedule recovery
problems.
We included two major assumptions in this study: (i) only
the cut trip can suffer delays; and (ii) there is no restriction
on the number of rescheduled trips. These assumptions may
not be true for some applications. In some cases, a vehicle
breakdown may also delay other trips (e.g., when the starting
point of the next trip that the breakdown vehicle is scheduled
to cover is too far from the depot and other vehicles). As a next
step, a trip cancellation strategy is being introduced to handle
such cases. The research team is also planning to include a
strategy to limit the number of trips that can be rescheduled.

Moreover, to reduce the travel delay for some major transit
routes, a transit signal priority technique is being combined
with this rescheduling algorithm.
Acknowledgments
This paper was written while the third author visited the
ATLAS Center at the University of Arizona. Also, the authors
like to express their sincere thanks to the anonymous referees
for their valuable suggestions.
APPENDIX: ANALYSIS OF THE CFN-BASED
ALGORITHMS
The main objective of this analysis is to determine an upper
bound for the total number of operations required by the auction algorithms with and without using the CFN approach. It
is expected that the upper bound using CFN is no greater than
the upper bound without using CFN to solve the SDVRSP.
Let the maximal arc beneﬁt in the network be C. Let N =
{1, 2, . . . n} be the set of persons, and let O = {1, 2, . . . n} be
the set of objects (|N| = |O|). Two different cases, with and
without CFN, will be considered.
In this analysis, we make the following assumptions: (i)
All arc costs, aij , are integer and nonnegative; (ii) The initial
prices of all objects are set to 0; and (iii) For each node in
the network, there is a list that stores the information of its
adjacent arcs.
The major operation of the auction algorithm is to scan the
adjacency list to determine the best and the second best object
prices. In the sequel, the term “operation” means scanning an
arc in the list and updating an object price if necessary [2].
Case 1: Without Common Feasible Network
Let the ﬁnal optimal price of object j be p∗j . Since ﬁnding the optimal price is the objective of the dual assignment
problem, the auction algorithm terminates when the optimal
prices are obtained [3]. In the auction algorithm, the price
increment is deﬁned as the proﬁt of the best object minus the
proﬁt of the second best object plus an increment . Bertsekas [3] showed that if  < 1/n, the ﬁnal assignment is
optimal.
Therefore, if object j receives a bid, the minimal increment
is . Hence, the total number of iterations in which the object
j receives a bid is no more than (p∗j − 0)/ = p∗j /. Consider
an iteration in which object j increases its price. The worst

NETWORKS—2007—DOI 10.1002/net

227

case occurs when all persons bid object j. In this situation,
the complexity for person i’s bid is d(i), where d(i) is the
out-degree of person i, since the major operation involves
scanning the whole adjacency list of node i. Thus, the total
number
of operations for object j at any iteration is, at most,
	
d(i)
= Y.
i∈N
Since there are at most p∗j / iterations conducted for
the object j, the number of operations for object j are at
most Yp∗j /. Since there are n objects, the total number of
operations, in the worst-case, is Y (p∗1 + p∗2 + · · · + p∗n )/.
Case 2: With Common Feasible Network
Here, a two-stage mechanism is employed. In stage 1, let
the initial prices of all objects be 0. Let N1 be the set of
persons and O1 be the set of objects that are removed in stage
1 (|N1 | = |O1 | = n1 and n1  n) to deﬁne the common
feasible network. In VRSP, N1 and O1 include the persons
and objects that represent the cut trip and all backup trip
candidates. The network composed by N − N1 persons and
objects is deﬁned as the CFN. Some associated objects of
person k may belong to O1 . Let the number of associated
objects of person k belonging to O1 be d1 (k), and the number
of associated objects of person k belonging to O − O1 be
d2 (k). Obviously, d(k) = d1 (k) + d2 (k). Figure 7 illustrates
these deﬁnitions.
The auction algorithm is ﬁrst applied for the CFN, and
optimal prices are obtained for this reduced network. In stage
2, we set the initial prices of objects in O − O1 as the corresponding ﬁnal prices from stage 1, and set prices of objects in
O1 as 0. The auction algorithm is then applied for all persons
and objects.
Stage 1. Auction algorithm for common feasible network
Analysis here is similar to case 1. However, there are n−n1
persons and objects respectively. The set of objects is {n1 +
1, n1 + 2, . . . , n}.
Let the ﬁnal optimal price of object j be p̄∗j . There are n−n1
objects, so the total number of operations, in the worst-case,

FIG. 7.

228

Example of different objects in the CFN.

NETWORKS—2007—DOI 10.1002/net

	
is Y1 (p̄∗n1 +1 + p̄∗n1 +2 +· · ·+ p̄∗n )/, where Y1 = i∈(N−N1 ) d2 (i)
is the total number of arcs connecting the n − n1 persons in
N − N1 to the n − n1 objects in O − O1 .
Stage 2.

Including the persons in N1 and objects in O1

The ﬁnal optimal price for object j is p∗j . The auction algorithm terminates when this optimal price is obtained. Two
kinds of objects need to be considered. One kind belongs to
O1 , whose initial prices are 0. The other belongs to O − O1 ,
whose initial prices are p̄∗j , obtained in stage 1.
For objects in O1 , the analysis is similar to case 1, therefore the total number of operation in the worst-case can be
expressed as Y (p∗1 + p∗2 + · · · + p∗n1 )/.
For objects j in O − O1 , the price needs to be increased
by p∗j − p̄∗j . It should be noted that we assume p∗j ≥ p̄∗j here.
If object j receives a bid, the minimal increment is . Total
number of iterations in which the object j receives a bid is no
more than (p∗j − p̄∗j )/. Therefore, the number of operations
for object j is at most Y (p∗j − p̄∗j )/. Since there are n − n1
objects being considered, the total number of operations is
Y (p∗n1 +1 − p̄∗n1 +1 + p∗n1 +2 − p̄∗n1 +2 + · · · + p∗n − p̄∗n )/.
Therefore, the total number of operations for all objects is
at most



Y p∗1 + p∗2 + · · · + p∗n1 /



+ Y p∗n1 +1 − p̄∗n1 +1 + p∗n1 +2 − p̄∗n1 +2 + · · · + p∗n − p̄∗n /.
This expression can be reduced to





Y p∗1 + p∗2 + · · · + p∗n − p̄∗n1 +1 + p̄∗n1 +2 + · · · + p̄∗n /.
Complexity Analysis
For case 1, let the total number of operations be F =
Y (p∗1 + p∗2 + · · · + p∗n )/. For case 2, let the total number of
operations in stage 1 be F1 = Y1 (p̄∗n1 +1 + p̄∗n1 +2 +· · ·+ p̄∗n )/ .
Let the total number of operations in stage 2 be F2 = Y (p∗1 +
p∗2 + · · · + p∗n − (p̄∗n1 +1 + p̄∗n1 +2 + · · · + p̄∗n ))/.
Let K be the set of backup trip candidates. There are |K|
backup trips; therefore for case 1, the regular auction needs
to be applied |K| times. The total number of operations is
approximately |K|F. Using the two-stage method, stage 1
needs to be conducted only once, and stage 2 needs to be performed |K| times. Thus, the total operation is approximately
F1 +|K|F2 . Our objective is to show that |K|F > F1 +|K|F2 .
This means that
F1
K>
.
F − F2
Observe that



Y1 p̄∗n1 +1 + p̄∗n1 +2 + · · · + p̄∗n
F1
Y1
 = .
= 
 ∗
∗
∗
F − F2
Y
Y p̄n1 +1 + p̄n1 +2 + · · · + p̄n
Since YY1 is less than 1, and |K| ≥ 2, |K|F > F1 + |K|F2
always holds. This means that we can expect the CFN

approach to reduce the number of operations required by the
auction algorithm to ﬁnd the optimum solution.
REFERENCES
[1]

[2]
[3]
[4]

[5]
[6]

[7]

[8]

[9]

[10]
[11]

[12]

[13]

[14]

[15]

[16]

F. Baita, R. Pesenti, W. Ukovich, and D. Favaretto, A comparison of different solution approaches to the vehicle scheduling
problem in a practical case, Comput Oper Res 27 (2000),
1249–1269.
D. Bertsekas, Linear network optimization: Algorithms and
codes, The MIT Press, Massachusetts, 1991.
D. Bertsekas, Auction algorithms for network ﬂow problems:
a tutorial introduction, Comput Optim Appl 1 (1992), 7–66.
D. Bertsekas and D. Castañon, Parallel synchronous and
asynchronous implementations of the auction algorithm,
Parallel Comput 17 (1991), 707–732.
L. Bodin and B. Golden, Classiﬁcation in vehicle routing and
scheduling, Networks 11 (1981), 97–108.
U. Bokinge and D. Hasselstrom, Improved vehicle scheduling in public transport through systematic changes in the
time-table, Eur J Oper Res 5 (1980), 388–395.
R. Borndoerfer, A. Loebel, and S. Weider, A bundle method
for integrated multi-depot vehicle and duty scheduling in public transit, Proceedings of the 9th international conference on
computer-aided scheduling of public transport, In CDROM,
San Diego, California, USA, 2004.
P.M. Carlson, Exploiting the opportunities of collaborative
decision making: A model and efﬁcient solution algorithm
for airline use, Transport Sci 34 (2000), 381–393.
G. Carpaneto, M. Dell’Amico, M. Fischetti, and P. Toth,
A branch and bound algorithm for the multiple depot vehicle
scheduling problem, Networks 19 (1989), 531–548.
A. Ceder, Urban transit scheduling: framework, review and
examples, J Urban Plann Develop 128 (2002), 225–244.
C.K. Chiu, J.H.M. Lee, H.F. Leung, and Y.W. Leung, A
constrained-based interactive train rescheduling tool, Constraints 7 (2002), 167–198.
J.R. Daduna and J.M. Paixão, Vehicle scheduling for public
mass transit—an overview, Proceedings of the 6th International conference on computer-aided scheduling of public
transport, Boston, MA, 1995, pp. 76–90.
S. de Groot and D. Huisman, Vehicle and crew scheduling: Solving large real-world instances with an integrated
approach, Proceedings of the 9th international conference on
computer-aided scheduling of public transport, In CDROM,
San Diego, California, USA, 2004.
M. Dell’Amico, Una nuova procedura di assegnamento per
il vehicle scheduling problem, Ricerca Operativa 5 (1989),
13–21.
M. Dell’Amico, M. Fischetti, and P. Toth, Heuristic algorithms for the multiple depot vehicle scheduling problem,
Management Science 39 (1993), 115–125.
T.C. Du, E.Y. Li, and D. Chou, Dynamic vehicle routing
for online b2c delivery, Omega-Int J Manage Sci 33 (2005),
33–45.

[17]

B. Fleischmann, S. Gnutzmann, and E. Sandvoss, Dynamic
vehicle routing based on online trafﬁc information, Transport
Sci 38 (2004), 420–433.

[18]

R. Freling, A.P.M. Wagelmans, and J.M. Paixão, Models and
algorithms for single-depot vehicle scheduling, Transport Sci
35 (2001), 165–180.
M. Gendreau and J.-Y. Potvin, Dynamic vehicle routing and
dispatching, Fleet management and logistics, T. Crainic and
G. Laporte (Editors), Kluwer, New York, 1998, pp. 115–
126.

[19]

[20]

G. Ghiani, F. Guerriero, G. Laporte, and R. Musmanno,
Real-time vehicle routing: solution concepts, algorithms and
parallel computing strategies, Eur J Oper Res 151 (2003),
1–11.

[21]

A. Haghani and S. Jung, A dynamic vehicle routing problem with time-dependent travel time, Comput Oper Res 32
(2005), 2959–2986.
D. Huisman, R. Freling, and A.P.M. Wagelmans, A robust
solution approach to the dynamic vehicle scheduling problem, Transport Sci 38 (2004), 447–458.
S. Ichoua, M. Gendreau, and J.-Y. Potvin, Diversion issues
in real-rime vehicle dispatching, Transport Sci 34 (2000),
426–438.
R. Jonker and A. Volgenant, Improving the Hungarian
assignment problem, Oper Res Lett 5 (1986), 171–176.
L. Lettovský, Airline operations recovery: An optimization
approach, Ph.D. thesis, Georgia Institute of Technology,
USA, 1997.

[22]

[23]

[24]
[25]

[26]

J. Medanic and M.J. Dorfman, Efﬁcient scheduling of trafﬁc on a railway line, J Optim Theory Appl 115 (2002),
587–602.
[27] J.M. Paixão and I. Branco, A quasi-assignment algorithm for
bus scheduling, Networks 17 (1987), 249–269.
[28] H.N. Psaraftis, Dynamic vehicle routing: Status and
prospects, Annals Oper Res 61 (1995), 143–164.
[29] J.M. Rosenberger, E.L. Johnson, and G.L. Nemhauser,
Rerouting aircraft for airline recovery, Transport Sci 37
(2003), 408–421.
[30] T. Song and L. Zhou, A new algorithm for the quasiassignment problem, Ann Oper Res 37 (1990), 205–223.
[31] M.Z. Spivey and W.B. Powell, The dynamic assignment
problem, Transport Sci 38 (2004), 399–419.
[32] D. Teodorović and G. Stojković, Model to reduce airline
schedule disturbances, J Transport Eng ASCE 121 (1995),
324–331.
[33] C.G. Walker, J.N. Snowdon, and D.M. Ryan, Simultaneous
disruption recovery of a train timetable and crew roster in
real time, Comput Oper Res 32 (2005), 2077–2094.
[34] J. Yang, P. Jaillet, and H.S. Mahmassani, Real-time multivehicle truckload pickup and delivery problems, Transport Sci
38 (2004), 135–148.
[35] J.-Q. Li, D. Borenstein, and P.B. Mirchandani, A decision
support system for the single-depot vehicle rescheduling
problem, Comput Oper Res 34 (2007), 1008–1032.

NETWORKS—2007—DOI 10.1002/net

229

Computer-Aided Civil and Infrastructure Engineering 25 (2010) 89–100

Locating a Surveillance Infrastructure in and Near
Ports or on Other Planar Surfaces to Monitor Flows
Pitu B. Mirchandani∗
School of Computation, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA

Jing-Quan Li
California PATH, University of California, Berkeley, Richmond, CA, USA

&
Yejuan Long
Systems and Industrial Engineering, University of Arizona, Tucson, AZ, USA

Abstract: A safety and security issue of concern for traffic managers and homeland security is the monitoring of
flows on “planar surfaces,” such as ports and border areas. This article addresses the problem of locating surveillance radars to cover a given target surface that may have
barriers through which radar signals cannot penetrate.
The area of coverage of a radar is assumed to be a disc, or
a partial disc when there are barriers, with a known radius. The article shows that the corresponding location
problems relate to two well studied problems: the setcovering model and the maximal covering problem. In
the first problem, the minimum number of radars is to be
located to completely cover the target area; in the second
problem a given number M of radars are to be located
to cover the target area as much as possible. Based on a
discrete representation of the target area, a Lagrangian
heuristic and a two-stage procedure with a conquer-anddivide scaling are developed to solve the above two models. The computational experiences reported demonstrate
that the developed method solves well the radar location
problems formulated here.

∗ To

whom correspondence should be addressed. E-mail: pitu@sie.
arizona.edu.


C 2009 Computer-Aided Civil and Infrastructure Engineering.
DOI: 10.1111/j.1467-8667.2009.00623.x

1 INTRODUCTION
A safety and security issue of concern for traffic managers and homeland security is the monitoring of
flows on transportation networks and “planar surfaces.”
Problems of surveillance of networks have been studied by several researchers including by one of the authors (see, e.g., Gentili and Mirchandani, 2005, 2008).
This article addresses the problem of surveillance of a
“plane” on which flows can take place. It is motivated by
a project led by the first author where the objective was
to locate small radars in, on, and near rivers and ports
to monitor flows of small vehicles or swimmers which
may pose security and safety concerns. The results from
the project that pertained to locating radars to monitor
a river (which can be modeled with line segments) has
been already reported elsewhere (Agnetis et al., 2008).
Sea ports are spatial areas through which international freight and passengers flow. The threat of a
small vessel carrying an explosive and detonating the
device within a port is real. For instance, small vessels have been successfully used overseas by terrorists
to transport waterborne improvised explosive devices
(Department of Homeland Security, 2008). Port security presents unique protection requirements that go
beyond the standard issues associated with perimeter

90

Mirchandani, Li & Long

security. One approach to maintain security of ports is
to develop an infrastructure of surveillance radars that
can detect, track, and identify intruders. However, determining best locations for the radars pose challenging optimization problems due to complicated physical
and geometrical considerations, including (1) the region
of a port is usually very irregular; (2) a radar can be
located on the land as well as in the water; and (3) there
are some areas that become barriers through which a
surveillance radar cannot penetrate for monitoring, for
example, a large high profile ship.
Two different radar locations problems arise in terms
of number of them to be located. In some critical situations it may be required that all of a given area needs
to be kept under surveillance. The corresponding optimization model pertains to the problem of locating
the minimum number of radars to monitor completely
a given target region. On the other hand, complete coverage may not be needed in some cases but the maximum coverage subject to a budget that allows the acquisition and installation of a given number of radars. In
summary, two relevant radar location problems are: (1)
where to locate a minimum number of radars for complete surveillance of a given target region and (2) where
to locate a given number of radars to maximize the coverage of the target region.
Although the models and algorithms presented in this
article were motivated by the design of a surveillance infrastructure, these models are also applicable is surveillance situations where a planar surface with barriers
need to be covered, where movement of people or vehicles can be anywhere on the surface except on the barriers, and where each sensor has a limited field of view.
The authors can envision applications in (1) monitoring international border regions through which people
can enter illegally; (2) surveillance of critical facilities
which are defined by a fence—the radars, in turn, define an electronic surveillance fence; and (3) using threedimensional versions of the models to develop a surveillance cover for a facility in space such as a space station
or an airborne/space-borne vehicle.
The radar location models we develop in this article
may be referred to as “spatial covering problems” having the following two assumptions: (1) the region covered by each radar corresponds to a covering disc with
a fixed radius and (2) the cost of each radar is fixed no
matter where it is located. For assumption (1), the authors spoke with the sponsors of this research project,
and they indicated that the small radars that were being used in fact nearly covered a circle when the atmospheric conditions were ideal, while assumption (2) can
easily be relaxed in the model and algorithms presented
in the article. Nevertheless, the results from the algorithms should be considered as preliminary design, and
if any of the numerical results are to be applied, a de-

tailed design must be developed before the surveillance
infrastructure is to be deployed.
In this article, the spatial covering problems are formulated as nonlinear continuous problems which are
then approximated as two common discrete location
models in the literature—namely the set covering problem and the maximal covering problem, both of which
have been well studied. The contributions of the article are (1) the integration of some common heuristics,
namely a modified greedy and a Lagrangian relaxation,
and (2) the development of a two-stage efficient procedure that includes a conquer-and-divide scaling approach that iteratively operates on finer and finer grid
approximations until an acceptable result is obtained.
The article is organized as follows. Some background
and a literature review on location–allocation decision
models are given in Section 2. In Section 3, we model
our continuous coverage location problems by a discretization approach. Section 4 describes a formulation and a Lagrangian heuristic for the problems; Section 5 proposes a two-stage heuristic method for the
corresponding maximal covering problem. Computational experiments and a decision support system are
described in Section 6. Section 7 discusses a model generalization. Conclusions and ideas for further study are
given in Section 8.

2 LITERATURE REVIEW
As we have discussed, locating radars to monitor flows
in and near ports is a typical facility location problem, where many prominent researchers and practitioners make seminal contributions. Drezner and Hamacher
(2002) provide an excellent review on location models, algorithms, and applications. Due to the properties
of radars and our target surveillance region, two broad
classes of decision-making models may be applicable for
locating radars that are (1) location on planes and (2)
location on a network or discrete set of points.
In the first class of models, the prototypical problem
is to locate items (e.g., facilities) on a plane so that all
the areas in the plane (e.g., all demands distributed on
the plane) are covered such that a given objective function is optimized (e.g., minimize the average travel cost
from demands to facilities) (Francis et al. (1992) provide
a good introduction to planar location models). Geographers, regional scientists, and land-use planners are especially interested in such models. In addition, this class
of problems is considered as continuous location problems based on the continuous nature of a plane. There
is considerable literature on location on planes. We
limit our review to the few topics related to our radar
location problem. One problem related to the radar
location is the maximal covering problem with the fixed

Locating a surveillance infrastructure in and near ports

radius, which attempts to find the center of a circular
disk with the given radius r to cover the largest possible area. Drezner (1981) proposed an algorithm that
takes O(M2 log M) time to solve the problem, where M
is the number of points in the area to be covered. The
algorithm was improved to O(M2 ) by Chazelle and Lee
(1986). The maximal covering problem can be extended
to locate p circles with fixed radius r to cover the largest
possible area, which has been referred to be p-maximal
covering problem. The complexity of p-maximal covering problem with the Euclidean distance dramatically
increases with p and M (Drezner, 1986). A comprehensive literature review on continuous location problem is
given by Ghosh and Rushton (1987).
The radar location problem relates closely to the class
of geometric covering problems with discs whose objective is to determine the minimum number of discs
with fixed radius to cover a given set of points on the
plane. The Art Gallery Problem introduced by Chvatal
(1975) is one of the many articles addressing this class
of problem, where one has to find the minimum number of watchmen (or cameras) needed to observe every wall of an art gallery room. Another important paper is by Hochbaum and Maass (1985), which proposed
a polynomial-time approximation scheme to solve the
problem of finding the minimum number of disks with
radius r to cover a set of points on a continuous region.
A “grid-shifting” technique was proposed to achieve a
near-optimal solution in polynomial-time. Brönnimann
and Goodrich (1995) provide an improved polynomialtime algorithm for this set covering problem.
The second class of models is to locate items among
some potential sites in order that a given set of points
is covered to optimize a specified objective. There are
many models and applications within this class. An example of such a model is to locate traffic sensors on
a transportation network so that all traffic flows on
the network are monitored (Gentili and Mirchandani,
2005). Another example of such a model is to choose a
set of sites, among a finite set of possible sites, to locate
service facilities so that the demands from various zones
are within a specified distance threshold. The first subclass is referred to as network location problem, while
the second subclass is referred to as discrete location
problem (Mirchandani and Francis, 1990; Daskin, 1995).
Although the radar location problems addressed in
this article relate to continuous location problems, the
discretization approach developed here may be included in the subclass of discrete location problems,
since we divide the target area into grid points (as will
be discussed in the next section) and the problem objective becomes the covering of these points. The developed model approximates the region with a discrete set
of points where the radars must be deployed and our
solution methods search this set for optimal locations.

91

Related to these radar location problems are location models associated with wireless cellular systems,
since the cell sensors can be approximated as discs (or
some convex polygons). Huang and Tseng (2005) discuss a covering problem in this context; their problem
is to determine sensor locations so that every point in
the service area is covered by at least one sensor, for
which they propose a polynomial-time algorithm. Alt
et al. (2006) study different scenarios for wireless transmission networks where the goal is to select a number of locations for server stations so that every point
in the target area is within some server’s transmission range; they provide both exact and approximation
algorithms.
There are also the problems of locating wireless sensors in a planar region so that every point is covered
by at least one sensor. Often the coverage area of
each sensor is modeled as a disc (see, e.g., Xing et al.,
2005; Lazos and Poovendran, 2006). Xing et al. provide
a geometric analysis that relates coverage of the sensors to connectivity of the associated wireless network.
Lazos and Poovendran (2006) analyze a related problem where the sensors are randomly distributed over a
planar region.

3 MODELING RADAR LOCATION PROBLEMS:
A DISCRETIZATION APPROACH
Since the target region is continuous and radars may be
located anywhere within continuous planar areas, an exhaustive discrete list of potential sites for locating facilities cannot be given. The radar location problem results
in a nonlinear optimization model due to the use of Euclidian distances in the related covering problem. This
nonlinear optimization problem is quite complicated,
especially when the target area of a port is a highly irregular region.
To reduce the complexity of the problem, we employ
a discretization approach, where the continuous area is
divided into a grid network. Based on the grid network,
the problem turns out to be a discrete location problem; every grid point corresponds to a demand point
with defined coordinates. Figure 1a gives an example
of the polygon representation of a target region, while
Figure 1b presents a corresponding grid network where
now the target region is represented by a set of grid
points. When the grid is sufficiently dense, the errors
between the discrete approximation and continuous region are small.
Given a potential site of the radar location and the
radius of coverage of the radar, a grid point can be
covered by a radar located at the site if (1) the grid
point is within the radius of coverage, and (2) the grid
point is not behind a barrier that the radar cannot

92

Mirchandani, Li & Long

Fig. 1. An example of the discretization process.

penetrate. As in the standard covering problems, a coverage matrix can be generated in terms of each potential
site and its coverage. Below is an example of a coverage
matrix A.
⎤
⎡
0 0 1 0 1 0 1 1
⎢0 0 0 1 1 0 1 1⎥
⎥
⎢
⎢0 1 0 0 1 1 0 0⎥
⎥
⎢
⎥
⎢
⎢0 0 1 0 0 0 1 1⎥
⎥
⎢
⎥
⎢
⎥
⎢
1
0
1
0
1
0
0
0
A= ⎢
⎥
⎢0 0 0 0 0 0 0 1⎥
⎥
⎢
⎥
⎢
⎢1 0 0 0 1 1 1 1⎥
⎥
⎢
⎥
⎢
⎣0 1 0 1 0 0 1 1⎦
0 0 1 0 1 0 1 1
In matrix A, each row represents a grid point that
needs to be covered by the radars. Each column denotes
a potential site where the radars may be located. Matrix
cell ai j is 1 if grid point i (corresponding to Row i) can be
covered by the radar at site j (corresponding Column j)
for the specified radius of coverage with no interference
from a barrier; otherwise ai j is 0. In this article, we assume that feasible radar location areas are given, which
could include the banks of the ports and subareas within
the port itself. Thus, based on the coverage matrix, we
can translate this continuous location problem with barriers into a standard discrete covering problem, which is
typically 0-1 integer linear optimization. From this perspective, the radar location problems can be modeled as
covering problems and maximal covering problems defined as follows.
1. Covering Problem: given a coverage matrix A,
what is the minimum number of radars and their
locations so that all required points are covered?
(See, e.g., Mirchandani and Francis, 1990.)
2. Maximal Covering Problem: given a coverage matrix A, and p radars, where should the radars be

located to maximize the number of required points
that are covered? (See, e.g., Church and Meadows,
1979; Daskin, 1983.)
It is well known that both problems are computationally NP-hard (see review in Daskin, 1995). For
such problems, solution techniques can be classified
as exact and heuristic methods. The first group often
includes methods based on linear, integer, or mixedinteger programming models to yield an optimal solution; the second group includes a variety of heuristic
methods that may yield optimal or near optimal solutions. Good heuristic techniques have the following advantages when compared with mathematical programming techniques, as discussed in many related papers
(see, e.g., Brearley et al., 1975; and Hoffman and Padberg, 1991): (1) large problems can be solved relatively
quickly; (2) many objective functions can be used; and
(3) a range of alternative, marginally sub-optimal solutions can be identified. The major drawback of heuristic
methods is that they do not guarantee an exact optimal
solution.
In this article, some heuristics methods are designed
and discussed—to obtain good solutions for both covering problem and maximal covering problem. In addition, to apply these heuristics effectively, a decision support system was developed to provide a user-friendly
environment for users.
4 SOLVING THE COVERING PROBLEM
In the covering problem each grid point needs to be covered by at least one radar, and the objective is to minimize the number of radars to be located. The covering problem (also known as the set covering problem) is
defined as follows. Let N represent the grid points that
need to be covered, and let P represent the potential
sites where the radars may be located. Let the binary
decision variable x j be 1 if a radar is located at the site

Locating a surveillance infrastructure in and near ports

j ∈ P, and let x j be 0 otherwise. Then the optimization
problem formulation is as follows:

min
xj
(1a)

93

better solution may be found if this algorithm is embedded into a Lagrangian heuristic, where the modified
greedy algorithm is executed iteratively.

j∈P

st


4.2 Lagrangian relaxation algorithm
ai j x j ≥ 1,

∀i ∈ N

j∈P

x j ∈ {0, 1},

(1b)

∀j ∈ P

where objective function (1a) is to minimize the total
numbers of radars, and the constraint (1b) assures that
every grid point is covered by at least one radar.
A recent survey on the covering problem is given in
Caprara et al. (1999). This article develops a heuristic
approach based on a greedy algorithm and a Lagrangian
heuristic, which is described in the next subsection.
4.1 Greedy algorithm
The greedy algorithm is a method that performs a single procedure within a recipe over and over again until it
cannot be performed any more. It is often effective and
a widely used method, even though it is based on a simple idea. In our covering problem, the algorithm locates
a radar every iteration so as to cover as many remaining uncovered points until all points have been covered.
That is, the algorithm makes a myopic decision at each
iteration without considering the effect it may have on
future decisions.
Based on the adding and substitution algorithm proposed by Daskin (1995), we developed a modified
greedy heuristic for the radar location problem. The
idea of the adding and substitution algorithm is as follows. In every iteration, we locate a radar at a candidate
site that has the maximal coverage for the remaining uncovered points. If there are several such sites, we select
the site which we refer to as our indicator. We update
the lists of selected and unselected sites. Then, we obtain a new indicator among those unselected sites. Each
site on the selected list is temporarily exchanged with
the indicator to see if the total coverage of demands is
increased; if the coverage performance is increased, the
difference is recorded. After all selected sites have been
temporarily exchanged with the indicator, we choose
the site that has the largest difference. If the improvement is positive, we move the radar to the indicator, and
find a new indicator among unselected lists. We repeat,
until the largest improvement is zero or negative, and
then place the radar at the indicator. We then start with
new lists of selected and unselected sites, and repeat the
process.
This modified greedy algorithm itself may not obtain
good results due to its myopic nature. Nevertheless, a

A Lagrangian relaxation-based heuristic has been
proved to be an effective approach to the set covering
problem; it was first introduced by Balas and Ho (1980)
and then improved by Fisher and Kedian (1990). The
main idea of Lagrangian relaxation is to relax some hard
constraints so that simple subproblems are easily solved.
We use Lagrangian multipliers ui for each grid point
i ∈ N in constraints (1b). After relaxing constraints
(1b), we obtain the Lagrangian dual problem written as
follows:
	





ai j ui x j +
ui
1−
max L(u)u≥0 = min
j∈P

such that
x j ∈ {0, 1},

i∈N

i∈N

(2)
∀j ∈ P

We attempt to minimize the objective function with
respect to the decision variable x j , and maximize the objective function with respect to the Lagrangian multipliers ui . It is well known that the solution of Lagrangian
relaxation provides a lower bound to the original problem. The outline of our Lagrangian heuristic is as follows.
Step 1 (Lagrangian Relaxation): Relax constraints
(1b) and solve the Lagrangian subproblem. Update the
lower bound if necessary.
Step 2 (Primal Heuristic): Based on the solution of
the Lagrangian subproblem, apply the greedy algorithm
to obtain a feasible solution for the primal problem. Update the upper bound if necessary.
Step 3 (Subgradient Search): Conduct a subgradient
search to update the Lagrangian multipliers.
Step 4 (Termination Condition): Repeat Steps 1–3
until a given time-limit is exceeded or sufficient solution
accuracy is attained.
4.2.1 Solving the Lagrangian relaxation. Clearly, the
optimal solution for the 
relaxed problem is given by
=
1
if
1
−
inspection:
x
j
j = 0 if 1 −
i∈N ai j ui < 0, x

a
u
>
0,
and
x
=
0
or
1
if
1
−
i
j
i
j
i∈N
i∈N ai j ui =
0. The objective of the Lagrangian
subproblem

is
j∈P (1 −
i∈N ai j ui )x j +
 calculated by summing
i∈N ui ,which is a lower bound to the original problem.
4.2.2 Finding a feasible solution. The solution of the
Lagrangian subproblems have two properties: (1) the
solution may be infeasible to the original problem, that
is, some grid points (rows) are not covered; and (2)

94

Mirchandani, Li & Long

when the Lagrangian multipliers are near optimal, the
solution of the Lagrangian subproblems is a promising
candidate for leading to an optimal solution.
When some grid points (rows) are covered by radars
while other grid points are not, we keep the radar locations obtained from the solution of the subproblem.
Then we locate an extra radar in a greedy way so
that the largest number of remaining uncovered grid
points are covered. Again, we remove the covered grid
points and repeat this process until all grid points are
covered.
4.2.3 Updating the Lagrangian multipliers. The classical subgradient optimization is used to solve the Lagrangian dual problem. This approach generates a sequence u0 , u1 , . . . of nonnegative Lagrangian multiplier vectors and it is intended to quickly produce a
near-optimal Lagrangian multiplier vector. Held and
Karp (1971) proposed a method
uk+1 as fol to update
k+1
k
k
lows: ui = max(ui + θk(1 − j ai j x j ), 0) for all i ∈ N,
where θk =

k
)]

λk [U B−L(u
k 2
i ||1−
j ai j x j ||

is a step size computed to de-

termine how far the new multiplier should differ from
the previous one, where U B is the best upper bound of
the original problem; L(uk) is the solution of Lagrangian
problem when the multiplier is uk and λk is a given constant.
The starting Lagrangian multiplier vector is defined
in a greedy way as follows (Caprara et al., 1999):
ui = min j∈Ji (1/|I j |) for each Row i where I j = {i ∈
r ows; ai j = 1} is the row subset covered by Column j and
Ji = { j ∈ columns; ai j = 1} is the set of columns covering Row i.
Usually, λk begins with constant such as λk = 2. The
value of λk is generally halved if the upper bound UB
has not decreased in a given number of consecutive iterations. In this project, we employed a method proposed
by Caprara et al. (1999) to update the parameter λk. For
every 20 iterations, the worst and best lower bounds in
the last 20 iterations are compared. If the difference between two values is more than 1%, the current value of
step size is halved; otherwise, the step size is multiplied
by 1.5.
5 SOLVING THE MAXIMAL COVERING
PROBLEM
In the covering model version of the problem, we locate
radars in such a way to minimize the number (or cost)
of the radars while insuring that all target points are under surveillance. However, when the number of radars
is insufficient, the location problem turns out to be the
maximal covering problem: locate the budgeted number
radars to maximize the points under surveillance.

Let M be the maximum number of radars to be located. Let zi be 1 if the grid point i ∈ N is covered, and
let zi be 0 otherwise. Then the maximal covering problem can be formulated as follows:

max
zi
(3a)
st


i∈N

ai j x j ≥ zi ,
j∈P

x j ≤ M,

∀i ∈ N

j∈P

x j ∈ {0, 1},

∀j ∈ P

zi ∈ {0, 1},

∀i ∈ N

(3b)

(3c)

where objective (3a) is to maximize the number of grid
points covered in the target area, constraints (3b) assures that every grid point is covered or not, and constraint (3c) guarantees that the number of radars located does not exceed the given number, M.
The maximal covering problem is also computationally a NP-hard problem (Daskin, 1983; Garey and Johnson, 1979). As it is very difficult to obtain an exact optimal solution, we adopted a two-stage heuristic, where
the first stage is a greedy algorithm for determining
the initial set of radar locations, and the second stage
is a local search mechanism for improving the locations obtained from the greedy algorithm. A new scaling method is embedded into the two-stage heuristic to
reduce the computational time.
5.1 A two-stage heuristic: greedy algorithm
and local search
A greedy algorithm is used to obtain an initial solution
for the maximal covering problem. The idea is similar to
the greedy algorithm adopted for finding a feasible solution for the covering problem. Initially, no grid point
(row) is covered. We then calculate the number of grid
points that can be covered by a radar at each candidate site, and find a radar location so that the number
of grid points covered is maximized. Then the covered
grid points are removed from consideration and another
radar site that covers the maximal number of remaining
grid points is chosen. Adding and substitution steps are
also embedded in the greedy algorithm to find better solutions. We repeat this process until all the given radars
are used.
After the greedy algorithm terminates, we use a local search to adjust the radar locations to increase the
number of covered grid points. An important concept
in the local search is the definition of a neighborhood.
For the maximal covering problem, the neighborhood
of a radar location may be defined as several potential
sites near this location. Then, every possible site in the

Locating a surveillance infrastructure in and near ports

neighborhood for a radar is examined for the improvement in the objective function, while other radars keep
their current positions; if the number of covered points
increases, the radar is moved to the new site. This process is applied until all the radars are examined.
Certainly, every site may have a different neighborhood structure. In our study, we consider the neighborhood of a site as a square with the center at this site.
Figure 2 shows an example of the neighborhoods for
three radar sites. The neighborhood is the grid points
in the square with the dashed line. The larger the area
of a neighborhood, the more opportunities to obtain
a better solution. However, the corresponding computational time to obtain an improved solution also increases. The area of the neighborhood can be determined experimentally considering the requirements of
computational times.
5.2 The two-stage heuristic with scaling
In the two-stage algorithm, the greedy heuristic gets a
good solution very quickly. Most time consumed in the
algorithm is the local search process since all the potential sites of a radar need to be examined for an improvement. If the neighborhood size increases, the computational time increases significantly. To increase the
opportunity to investigate more neighborhoods and si-

95

multaneously have an acceptable computational time,
we developed an important mechanism, scaling, to solve
the maximal covering problem. The key idea of the
scaling mechanism is to divide the polygon region into
a larger grid network that contains much fewer grid
points. Figure 3 gives an example of grid networks with
the different grid sizes.
The greedy heuristic and the local search are first
applied on the larger-grid network. Due to fewer grid
points in the larger-grid network, the local search is
completed very quickly. The radars move to the best
locations found in the larger-grid network. For example, Figure 4a shows a larger grid size and three radars
are located at points shown with little computation time.
Then we reduce the grid size and a new smaller-grid
network with more grid points is generated only in the
neighborhood of the currently located radars; see, for
example, Figure 4b. On the new grid network, we use
the local search only in the neighborhoods of the located radars to obtain a new set of locations. We then
reduce grid size further and continue with finer scale local searches; we keep reducing grid size until we end up
with a predefined minimum grid size. Note that this approach of locating and searching at successively smaller
grid sizes—which we refer to as the conquer-and-divide
method—allows us to avoid the evaluation of all grid
points at the finest resolution. The computational times

Fig. 2. An example of neighborhoods for three radars.

Fig. 3. An example of the networks with different grid lengths.

96

Mirchandani, Li & Long

Fig. 4. Local searches at (a) grid size 2 and (b) at unit grid size.

substantially decreased with this new scaling mechanism
in comparison with the times when the local search was
directly applied on the finest grid network. In our implementation, we set the initial grid length as 8. The
grid length was halved when each local search was completed. The procedure was terminated after the search
was done with grid length of 1.
The outline of the two-stage heuristic with the scaling
is as follows.
Step 1 (Greedy Algorithm): Apply the greedy algorithm in the original finest grid network to determine
the initial locations for the given radars.
Step 2 (Initialize the Grid Length for Local Search):
Set an initial grid length as a large value and construct
the corresponding grid network.
Step 3 (Local Search): Apply the local search based
on the current grid network and move the radars to the
best locations found in the local search.
Step 4 (Scaling): If the grid length is one unit, stop.
Otherwise, the grid length is halved and the corresponding grid network is constructed. Then, go to Step 3.
In the covering problem formulation, we assumed
that the cost of each radar is fixed no matter where it
is located. The fixed cost assumption may not hold in
some situations. For example, the cost of installing a
radar in the water may be higher than the cost of locating it on the land due to the costs of elevating the radar.
The covering problem can be easily extended to consider different fixed costs by including cost coefficients
in the objective
 function (1a) to the revised objective
function min j∈P c j x j , where c j is the cost of locating
a radar at site j. Our Lagrangian heuristic can be easily
adapted to solve the revised objective. The fixed cost assumption is not used in the maximal covering problem
since the number of the radars is given in this formulation, and the objective is to maximize coverage for this
fixed number of radars.

6 COMPUTATIONAL EXPERIMENTS
Some computational experiments were conducted to
evaluate our algorithms for the radar location problems.
From a geographical description of any given port a
polygonal area can be constructed. As our method of
generating the input is based on the standard data format of polygons, it is easy to generate the input for
any real port when the corresponding polygon data are
available. (We note, however, that the polygonal area
used in the computational experiments reported here is
not for a real port.)
Three cases, Case 1, Case 2, and Case 3, were studied.
Each case study corresponds to one polygon with different size and shape, with Case 1 having the most number
of grid points and Case 3 the fewest. To test the impact
of barriers, a barrier is included in Case 1, to have two
more cases; Figure 5 presents the geometry of Case 1
without barriers and with barriers in different positions.
In our experiments, we divide each polygon with the
same grid sizes, so higher number of grid points represents a larger region. Both the covering problem and the
maximal covering problem were investigated for each
case. Table 1 gives the number of grid points for the different cases. For each case, we tested radar with different fields of view (i.e., different covering radii), resulting
in different coverage matrices.
The computational experiments on the covering
problem were conducted on a Windows machine (Intel Processor 1.6 Ghz, RAM 512M). The algorithms for
the covering and maximal covering problems were implemented in C.

6.1 Covering problem
For the largest case (Case 1), we ran for 40 minutes,
while for Cases 2 and 3, we ran for 10 minutes. Table 2

Locating a surveillance infrastructure in and near ports

97

Fig. 5. Graphical illustration of barriers in Case 1.
Table 1
The number of grid points in different cases
Case 1 without barriers

Case 1 with barrier I

Case 1 with barrier II

Case 2

Case 3

2,776

2,776

1,352

1,122

2,938

Table 2
Computational results of the covering problem
Case 1 without barriers
Radius
LB
Solution

1,000
3.83
5

800
6.02
8

600
9.44
13

Case 1 with barrier I
1,000
4.47
5

800
5.86
7

600
9.67
12

presents computational results of the covering problem
for five instances: Case 1 without barriers, Case 1 with
barrier I, Case 1 with barrier II, Case 2, and Case 3.
Rows 1, 2, and 3 give the radius of the radar, the lower
bound on the number of radars required for the complete coverage, and the number of radars obtained from
our Lagrangian heuristic, respectively.
We observe that fewer radars are needed to cover the
whole area if the radius of radars are larger. We also
observe that although a region with barriers has smaller
areas that need to be covered than the same region without barriers, the geometry with barriers may be more
irregular, requiring the same or more radars. For example, Case 1 with barrier II needs the same number
of radars as Case 1 without a barrier although it has a
smaller area to cover (compare solutions in Columns 2–
4 with Columns 8–10, Row 4 in Table 2).
For some cases, our Lagrangian heuristic finds the
optimal solution. For example, in Case 1 with barrier
II and radius 1,000 (Column 5 in Table 2), the lower
bound is 4.47, while Lagrangian heuristic obtains a solution with five radars. As the number of radars is an
integer, the solution with five radars is in fact an optimal solution. However, in some situations, we do not
know if the Lagrangian heuristic gives us the optimal
solution. For example, in Case 2 with radius 200, the
lower bound of radars required is 12.69; that is, at least
13 radars are needed. The solution from our Lagrangian

Case 1 with barrier II
1,000
3.84
5

800
6.13
8

600
9.79
13

Case 2
200
12.69
17

Case 3
300
6.1
8

200
7.53
10

300
3.76
5

heuristic suggests 17 radars, which is four more than the
lower bound (Column 11 in Table 2).
6.2 Maximal covering problem
Table 3 shows our computational results for the maximal covering problem. Columns 2 and 3 are the radius
of radars and number (M) of given radars, respectively.
Columns 4 and 5 give the percentage of coverage with
the given number of radars and CPU seconds, respectively, when the two-stage heuristic without the scaling
mechanism is used. Columns 6 and 7 show the corresponding values for the two-stage heuristic with the
scaling. Column 8 is the improvements in CPU times,
defined as CPU time for the heuristic with scaling as
a percentage of the CPU time of the heuristic without
scaling.
For example, for Case 1 without barriers and radius of
coverage 600 (see Row 8), 69.29% regions are covered
with five radars; it took 832 CPU seconds for this computation. When scaling was used 69.23% regions were
covered and the corresponding computational time was
162 seconds. The scaling method required only 19.47%
of the computational time of the heuristic without the
scaling while the covered region is almost the same. In
general, the results clearly show that the scaling method
significantly reduced the computational time while the
coverage remained about the same.

98

Mirchandani, Li & Long

Table 3
Maximal covering problem: the two-stage heuristic with and without scaling
Without scaling
Case
Case 1 without barriers

Radar radius

No. of radars

Coverage %

CPU secs

Coverage %

CPU secs

CPU%

1,000

2
3
4
2
3
4
4
5
6

76.17%
89.85%
99.38%
54.25%
72.87%
86.69%
59.97%
69.29%
79.06%

348
292
204
272
546
435
447
832
750

75.43%
90.23%
98.77%
54.25%
72.09%
85.77%
59.97%
69.23%
78.73%

143
115
101
95
184
176
148
162
224

41.09%
39.38%
49.51%
34.93%
33.70%
40.46%
33.11%
19.47%
29.87%

2
3
4
2
3
4
4
5
6

74.31%
89.45%
96.44%
51.01%
69.60%
84.94%
60.73%
69.63%
80.18%

342
320
372
486
464
393
711
716
644

73.99%
88.90%
96.10%
50.79%
69.48%
84.83%
60.59%
69.38%
77.70%

124
100
107
117
156
140
177
175
197

36.26%
31.25%
28.76%
24.07%
33.62%
35.62%
24.89%
24.44%
30.59%

2
3
4
2
3
4
4
5
6

70.64%
85.77%
99.24%
53.20%
71.83%
85.80%
60.37%
70.28%
81.16%

366
272
155
436
424
356
701
695
614

73.09%
85.59%
98.70%
52.95%
71.75%
85.59%
60.37%
70.13%
80.04%

139
81
77
97
128
130
156
175
188

37.98%
29.78%
49.68%
22.25%
30.19%
36.52%
22.25%
25.18%
30.62%

3
4
3
4

30.40%
40.53%
70.34%
81.29%

116
138
78
141

30.40%
40.53%
70.34%
80.03%

37
44
29
46

31.90%
31.88%
37.18%
32.62%

3
4
3
4

52.67%
69.34%
91.44%
98.84%

65
119
55
39

52.67%
68.00%
91.44%
98.84%

19
32
55
39

29.23%
26.89%
100.00%
100.00%

800

600

Case 1 with barrier I

1,000

800

600

Case 1 with barrier II

1,000

800

600

Case 2

300
200

Case 3

With scaling

300
200

As would be expected, when the number of available
radars increases, the coverage of regions also increases.
For example, if two radars of radius 1,000 are available for Case 1 without barrier, 75.43% of region is covered, while 90.23% of region is covered when 3 radars
are available. However, when the number of available
radars continues to increase, the marginal increase in
coverage keeps diminishing. For example, when four
radars are available, 98.77% region is covered, only an
8.54% increase in coverage.
Similar to the covering problem, the irregular geometry caused by barriers makes the maximal covering
problem more complicated. If the number and covering radius of the radars are the same, the coverage of

a region with barriers is always less than the coverage
without the barriers. For example, when three radars of
radius 1,000 are used for Case 1 without barrier, 90.23%
of region is covered by the scaling algorithm. However,
only 88.90% of region is covered for Case 1 with barrier
I, and 85.59% of region is covered for Case 1 with barrier II (see Rows 4, 13, and 22, of Column 6 in Table 3
for these percentages).
6.3 Graphical representation in the decision
support system
To use our models conveniently, we developed a simple decision support system (DSS) using C++ and Java.

Locating a surveillance infrastructure in and near ports

99

Fig. 6. Graphical output of the decision support system for the maximal covering problem.

Figure 6 presents two graphical representations for the
maximal covering problem with three and four radars
for Case 2. Observe that the locations of the radars for
the three-radar case are moved when the fourth radar
is being located (compare the locations in (a) and (b)
of Figure 6). In the DSS we input the polygonal representation of the region to be under surveillance, the
number of radars available (M) and the radar coverage
radius; the DSS returns the location of the radars.
When there are barriers to be considered, these barriers are also simply input as polygons in the plane.
Simple preprocessing modifies the coverage matrix to
change some aij entries from 1 to zero when the barrier
prevents a radar located at i to cover grid point j.

7 CONCLUSIONS AND FUTURE RESEARCH
This article addressed the problem of locating sensors,
in this case surveillance radars, to monitor planar regions that can allow vehicular, boats, people, etc. to
move within. The original nonlinear continuous problems were approximated as two common discrete location models in the literature—namely the set covering problem and the maximal covering problem, both
of which are well studied. The contributions of this research are (1) the integration of some common heuristics, namely a modified greedy and a Lagrangian relaxation, and (2) the development of a two-stage procedure that includes a conquer-and-divide scaling approach that iteratively operates on finer and finer grid
approximations until an acceptable result is obtained.
Computational experiments show that the conquerand-divide scaling improves greatly the computational

times of available approaches with little or no loss in
the coverage performance.
One immediate useful modification of the developed
procedure is that of allowing variable power of radars,
so that the radius of coverage may be increased or decreased, by increasing or decreasing the power of the
radar, at a cost. The corresponding coverage models
would be interesting optimization problems to study in
themselves.
Finally, it would be useful to use these models in
other applications, some of which were mentioned in
the introductory section of the article. Perhaps the applications themselves could identify other issues that
location and infrastructure planning models should
address—much in the same way the radar surveillance
problem led to the new coverage models described in
this article.
REFERENCES
Agnetis, A., Grande, E., Mirchandani, P. B. & Pacifici, A.
(2008), Covering a line segment with variable radius discs,
Computers and Operations Research, 36, 1423–36.
Alt, H., Arkin, E. M., Brönnimann, H., Erickson, J., Fekete,
S. P., Knauer, C., Lenchner, J., Mitchell, J. S. B. &
Whittlesey, K. (2006), Minimum-cost coverage of point sets
by disks, Proc. 22nd Annual ACM Symposium on Computational Geometry, June, 449–58, ACM Press, New York.
Balas, E. & Ho, A. (1980), Set covering algorithms using
cutting planes, heuristics, and subgradient optimization—
a computational study, Mathematical Programming Study,
12, 37–60.
Brearley, A. L., Mitra, G. & Williams, H. P. (1975), Analysis
of mathematical programming problems prior to applying
the simplex algorithm, Mathematical Programming, 8, 54–
83.

100

Mirchandani, Li & Long

Brönnimann, H. & Goodrich, M. T. (1995), Almost optimal
set covers in finite VC dimension, Discrete and Computational Geometry, 14(4), 463–79.
Caprara, A., Fischetti, M. & Toth, P. (1999), A heuristic
method for the set covering problem, Operations Research,
47, 730–43
Chazelle, B. & Lee, D. (1986), On a circle placement problem,
Computing, 36, 1–16.
Church, R. L. & Meadows, M. (1979), Location modeling
utilizing maximum service distance criteria, Geographical
Analysis, 11, 358–79.
Chvatal, V. (1975), A combinatorial theorem in plane geometry, Journal of Combinatorial Theory, 18, 39–41.
Daskin, M. S. (1983), A maximum expected covering location model: formulation, properties and heuristic solution,
Transportation Science, 17, 48–70.
Daskin, M. S. (1995), Network and Discrete Location: Models,
Algorithms, and Applications, John Wiley and Sons, New
York.
Department of Homeland Security, Small vessel security
strategy, http://www.dhs.gov/xlibrary/assets/small-vesselsecurity-strategy.pdf, 2008 (accessed on Sept. 6, 2008).
Drezner, Z. (1981), On a modified one-center problem, Management Science, 27, 227–30.
Drezner, Z. (1986), P-cover problem, European Journal of
Operational Research, 26, 312–13.
Drezner, Z. & Hamacher, H. W. (2002), Facility Location: Applications and Theory, Springer-Verlag, New York.
Fisher, M. L. & Kedian, P. (1990), Optimal solution of set covering partitioning problem using dual heuristic, Management Science, 36, 674–88.
Francis, R. L., McGinnis, L. F. & White, J. A. (1992), Facility Layout and Location: An Analytical Approach, 2nd edn.
Prentice Hall, Englewood Cliffs, NJ.

Garey, M. R. & Johnson, D. S. (1979), Computers and Intractability: A Guide to the Theory of NP-Completeness, W.
H. Freeman.
Gentili, M. & Mirchandani, P. B. (2005), Locating active sensors on traffic networks, Annals of Operations Research,
136, 229–57.
Gentili, M. & Mirchandani, P. B. (2008), Locating sensors on
traffic network: an overview, Proceedings of ISOLDE XI,
International Symposium on Locational Decisions. June 26–
July 1, 2008, Santa Barbara, CA.
Ghosh, A. & Rushton, G. (1987), Spatial Analysis and
Location-Allocation Models, Van Nostrand Reinhold, New
York.
Held, M. & Karp, R. M. (1971), The traveling salesman problem and minimum spanning trees: Part II, Mathematical
Programming, 1, 6–25.
Hochbaum, D. S. & Maass, M. (1985), Approximation
schemes for covering and packing problems in imageprocessing and VLSI, Journal of ACM, 32, 130–36.
Hoffman, K. L. & Padberg, M. (1991), LP-based combinatorial problem solving, Annals of Operations Research, 4, 145–
94.
Huang, C. F. & Tseng Y. C. (2005), The coverage problem in
a wireless sensor network, Journal of Internet Technology,
6, 1–8.
Lazos, L. & Poovendran, R. (2006), Stochastic coverage in
heterogeneous wireless sensor networks, ACM Transactions on Sensor Networks, 8, 325–58.
Mirchandani, P. B. & Francis, R. L. (1990), Discrete Location
Theory, Wiley and Sons.
Xing, G. L., Wang, X. R., Zhang, Y. F., Lu, C., Pless, R. & Gill,
C. (2005), Integrated coverage and connectivity configuration for energy conservation in sensor networks, Transport
Sensor Networks, 1, 36–72.

8th Cologne-Twente Workshop on
Graphs and Combinatorial
Optimization
CTW09

École Polytechnique and CNAM
Paris, France, June 2-4, 2009

Proceedings of the Conference

Sonia Cafieri,

Antonio Mucherino, Giacomo Nannicini,
Fabien Tarissan, Leo Liberti
(Eds.)

8th Cologne-Twente Workshop on
Graphs and Combinatorial Optimization (CTW09)
École Polytechnique and CNAM
Paris, France, June 2-4, 2009
The Cologne-Twente Workshop (CTW) on Graphs and Combinatorial Optimization started off as a series of workshops organized bi-annually by either Köln
University or Twente University. As its importance grew over time, it re-centered its
geographical focus by including northern Italy (CTW04 in Menaggio, on the lake
Como and CTW08 in Gargnano, on the Garda lake). This year, CTW (in its eighth
edition) will be staged in France for the first time: more precisely in the heart of
Paris, at the Conservatoire National d’Arts et Métiers (CNAM), between 2nd and
4th June 2009, by a mixed organizing committee with members from LIX, École
Polytechnique and CEDRIC, CNAM.
As tradition warrants, a special issue of Discrete Applied Mathematics (DAM)
will be devoted to CTW09, containing full-length versions of selected presentations
given at the workshop and possibly other contributions related to the workshop
topics. The deadline for submission to this issue will be posted in due time on the
CTW09 website http://www.lix.polytechnique.fr/ctw09.
The Proceedings Editors wish to thank the members of the Program Committee: U. Faigle (Universität zu Köln), J. Hurink (Universiteit Twente), L. Liberti
(École Polytechnique), F. Maffioli (Politecnico di Milano), G. Righini (Università
degli Studi di Milano), R. Schrader (Universität zu Köln), R. Schultz (Universität
Duisburg-Essen), for setting up such an attractive program. Special thanks also go
to the anonymous referees. This conference was partially sponsored by: the Digiteo
(www.digiteo.fr) foundation, CNRS, and the Thales Chair at LIX.

Editors:
S ONIA C AFIERI
A NTONIO M UCHERINO
G IACOMO NANNICINI
FABIEN TARISSAN
L EO L IBERTI
LIX, École Polytechnique
Paris, May 2009

Organization
The CTW09 conference is co-organized by the Laboratoire d’Informatique
(LIX) at École Polytechnique and by the Centre d’Etude et Recherche en Informatique du CNAM (CEDRIC) at the Conservatoire National d’Arts et Mtiers (CNAM).

Scientific Committee
•
•
•
•
•
•
•

U. Faigle (Universität zu Koln)
J.L. Hurink (Universiteit Twente)
L. Liberti (École Polytechnique, Paris)
F. Maffioli (Politecnico di Milano)
G. Righini (Università degli Studi di Milano)
R. Schrader (Universität zu Koln)
R. Schultz (Universität Duisburg-Essen)

Organizing Committee
•
•
•
•
•
•
•
•
•
•
•

S. Cafieri (LIX, École Polytechnique)
M.-C. Costa (CEDRIC, CNAM)
C. Dürr (LIX, École Polytechnique)
L. Liberti (Chair – LIX, École Polytechnique)
A. Mucherino (LIX, École Polytechnique)
G. Nannicini (LIX, École Polytechnique)
C. Picouleau (CEDRIC, CNAM)
M.-C. Plateau (GdF)
J. Printz (CMSL, CNAM)
E. Rayssac (LIX, École Polytechnique)
F. Tarissan (LIX, École Polytechnique)

Table of Contents

Traveling Salesman Problem
Lecture Hall A, Tue 2, 08:45–10:15
C. Dong, C. Ernst, G. Jaëger, D. Richter, P. Molitor
Effective Heuristics for Large Euclidean TSP Instances Based on Pseudo Backbones

3

M. Casazza, A. Ceselli, M. Nunkesser
Efficient Algorithms for the Double Traveling Salesman Problem with Multiple Stacks

7

M. Bruglieri, A. Colorni, A. Lue
The Parking Warden Tour Problem

11

Graph Theory I
Lecture Hall B, Tue 2, 08:45–10:15
I. Sau, D. Thilikos
On Self-Duality of Branchwidt in Graphs of Bounded Genus

19

S. Nikolopoulos, C. Papadopoulos
A Simple Linear-Time Recognition Algorithm for Weakly Quasi-Threshold Graphs

23

H. Gropp
From Sainte-Laguë to Claude Berge — French Graph Theory in the Twentieth Century

28

Combinatorial Optimization
Lecture Hall A, Tue 2, 10:30–12:30
J. Maßberg, T. Nieberg
Colored Independent Sets

35

V. Lozin
A Note on the Parameterized Complexity of the Maximum Independent Set Problem

40

G. Nicosia, A. Pacifici, U. Pferschy
On Multi-Agent Knapsack Problems

44

L. Simonetti, Y. Frota, C. Souza
An Exact Method for the Minimum Caterpillar Spanning Problem

48

Coloring I
Lecture Hall B, Tue 2, 10:30–12:30
R. Machado, C. de Figueiredo
NP-Completeness of Determining the Total Chromatic Number of Graphs that do not
Contain a Cycle with a Unique Chord

55

R. Kang, T. Müller
Acyclic and Frugal Colourings of Graphs

60

P. Petrosyan, H. Sargsyan
On Resistance of Graphs

64

E. Bampas, A. Pagourtzis, G. Pierrakos, V. Syrgkanis
Colored Resource Allocation Games

68

Cutting and Packing
Lecture Hall A, Tue 2, 14:00–15:30
C. Arbib, F. Marinelli, C. Scoppola
A Lower Bound for the Cutting Stock Problem with a Limited Number of
Open Stacks

75

H. Fernau, D. Raible
Packing Paths: Recycling Saves Time

79

J. Schneider, J. Maßberg
Rectangle Packing with Additional Restrictions

84

Paths
Lecture Hall B, Tue 2, 14:00–15:30
F. Usberti, P. França, A. França
The Open Capacitated Arc Routing Problem

89

M. Maischberger
Optimising Node Coordinates for the Shortest Path Problem

93

R. Bhandari
The Sliding Shortest Path Algorithms

97

Quadratic Programming
Lecture Hall A, Tue 2, 15:45–16:45
W. Ben-Ameur, J. Neto
A Polynomial-Time Recursive Algorithm for some Unconstrained
Quadratic Optimization Problems

105

I. Schuele, H. Ewe, K.-H. Kuefer
Finding Tight RLT Formulations for Quadratic Semi-Assignment Problems

109

Trees
Lecture Hall B, Tue 2, 15:45–16:45
V. Borozan, R. Muthu, Y. Manoussakis, C. Martinhon, A. Abouelaoualim, R. Saad
Colored Trees in Edge-Colored Graphs

115

K. Cameron, J. Fawcett
Intermediate Trees

120

Plenary Session I
Lecture Hall A, Tue 2, 16:45–17:30
A. Lodi
Bilevel Programming and Maximally Violated Valid Inequalities

125

Integer Programming
Lecture Hall A, Wed 3, 08:45–10:15
R. Schultz
Decomposition Methods for Stochastic Integer Programs with
Dominance Constraints

137

S. Kosuch, A. Lisser
On a Two-Stage Stochastic Knapsack Problem with Probabilistic Constraint

140

G. Cornuéjols, L. Liberti, G. Nannicini
Improved Strategies for Branching on General Disjunctions

144

Graph Theory II
Lecture Hall B, Wed 3, 08:45–10:15
G. Katona, I. Horváth
Extremal Stable Graphs

149

V.A. Leoni, M.P. Dobson, Gr. Nasini
Recognizing Edge-Perfect Graphs: some Polynomial Instances

153

M. Freitas, N. Abreu, R. Del-Vecchio
Some Infinite Families of Q-Integral Graphs

157

Applications
Lecture Hall A, Wed 3, 10:30–12:30
A. Ceselli, R. Cordone, M. Cremonini
Balanced Clustering for Efficient Detection of Scientific Plagiarism

163

V. Cacchiani, A. Caprara, M. Fischetti
Robustness in Train Timetabling

171

F. Roda, L. Liberti, F. Raimondi
Combinatorial Optimization Based Recommender Systems

175

G. Righini, R. Cordone, F. Ficarelli
Bounds and Solutions for Strategic, Tactical and Operational Ambulance Location

180

Coloring II
Lecture Hall B, Wed 3, 10:30–12:30
E. Hoshino, C. de Souza, Y. Frota
A Branch-and-Price Approach for the Partition Coloring Problem

187

M. Soto, A. Rossi, M. Sevaux
Two Upper Bounds on the Chromatic Number

191

F. Bonomo, G.A. Durán, J. Marenco, M. Valencia-Pabon
Minimum Sum Set Coloring on some Subclasses of Block Graphs

195

A. Lyons
Acyclic and Star Colorings of Joins of Graphs and an Algorithm for Cographs

199

Exact Algorithms
Lecture Hall A, Wed 3, 14:00–15:30
H. Fernau, S. Gaspers, D. Kratsch, M. Liedloff, D. Raible
Exact Exponential-Time Algorithms for Finding Bicliques in a Graph

205

L. Bianco, M. Caramia
An Exact Algorithm to Minimize the Makespan in Project Scheduling with
Scarce Resources and Feeding Precedence Relations

210

R. Macedo, C. Alves, V. de Carvalho
Exact Algorithms for Vehicle Routing Problems with Different Service Constraints

215

Networks I
Lecture Hall B, Wed 3, 14:00–15:30
D. Lozovanu, S. Pickl
Algorithmic Solutions of Discrete Control Problems on Stochastic Networks

221

L. Belgacem, I. Charon, O. Hudry
Routing and Wavelength Assignment in Optical Networks by Independent Sets
in Conflict Graphs

225

A. Guedes, L. Markenzon, L. Faria
Recognition of Reducible Flow Hypergraphs

229

Complexity
Lecture Hall A, Wed 3, 15:45–16:45
A. Scozzari, F. Tardella
On the Complexity of Graph-Based Bounds for the Probability Bounding Problem

235

B. Engels, S. Krumke, R. Schrader, C. Zeck
Integer Flow with Multipliers: The Special Case of Multipliers 1 and 2

239

Polyhedra
Lecture Hall B, Wed 3, 15:45–16:45
R. Stephan
Classification of 0/1-Facets of the Hop Constrained Path Polytope
Defined on an Acyclic Digraph

247

A. Galluccio, C. Gentile, M. Macina, P. Ventura
The k-Gear Composition and the Stable Set Polytope

251

Plenary Session II
Lecture Hall A, Wed 3, 16:45–17:30
M. Habib
Diameter and Center Computations in Networks

257

Polynomial-time Algorithms
Lecture Hall A, Thu 4, 08:45–10:15
M. Bodirsky, G. Nordh, T. von Oertzen
Integer Programming with 2-Variable Equations and 1-Variable Inequalities

261

D. Müller
Faster Min-Max Resource Sharing and Applications

265

A. Bettinelli, L. Liberti, F. Raimondi, D. Savourey
The Anonymous Subgraph Problem

269

Graph Theory III
Lecture Hall B, Thu 4, 08:45–10:15
A. Rafael, F.-T. Desamparados, J.A. Vilches
The Number of Excellent Discrete Morse Functions on Graphs

277

F. Bonomo, G.A. Durán, L.N. Grippo, M.D. Safe
Partial Characterizations of Circle Graphs

281

T. Shigezumi, Y. Uno, O. Watanabe
A Replacement Model for a Scale-Free Property of Cliques

285

Graph Theory IV
Lecture Hall A, Thu 4, 10:30–12:30
A. Darmann, U. Pferschy, J. Schauer, G. Woeginger
Combinatorial Optimization Problems with Conflict Graphs

293

J.M. Sigarreta, I. Gonzlez Yero, S. Bermudo, J.A. Rodrı́guez-Velázquez
On the Decomposition of Graphs into Offensive k-Alliances

297

M. Brinkmeier
Increasing the Edge Connectivity by One in O(λG n2 log(∗) n) Expected Time
V. Giakoumakis, O. El Mounir
Enumerating all Finite Sets of Minimal Prime Extensions of Graphs

301
305

Networks II
Lecture Hall B, Thu 4, 10:30–12:30
C. Bentz
On Planar and Directed Multicuts with few Source-Sink Pairs

313

F. Usberti, J. Gonzlez, C.L. Filho, C. Cavellucci
Maintenance Resources Allocation on Power Distribution Networks with
a Multi-Objective Framework

317

E. Grande, P.B. Mirchandani, A. Pacifici
Column Generation for the Multicommodity Min-cost Flow Over Time Problem

321

F. Tarissan, C. La Rota
Inferring Update Sequences in Boolean Gene Regulatory Networks

325

Bioinformatics
Lecture Hall A, Thu 4, 14:00–15:30
N. Van Cleemput, G. Brinkmann
NANOCONES – A Classification Result in Chemistry

333

A. Mucherino, C. Lavor, N. Maculan
The Molecular Distance Geometry Problem Applied to Protein Conformations

337

G. Collet, R. Andonov, N. Yanev, J.-F. Gibrat
Protein Threading

341

Clustering
Lecture Hall B, Thu 4, 14:00–15:30
J. Correa, N. Megow, R. Raman, K. Suchan
Cardinality Constrained Graph Partitioning into Cliques with Submodular Costs

347

F. Liers, G. Pardella
A Simple M AX -C UT Algorithm for Planar Graphs

351

E. Amaldi, S. Coniglio, K. Dhyani
k-Hyperplane Clustering Problem: Column Generation and a Metaheuristic

355

Games
Lecture Hall A, Thu 4, 15:45–16:15
U. Faigle, J. Voss
A System-Theoretic Model for Cooperation and Allocation Mechanisms

361

Matrices
Lecture Hall B, Thu 4, 15:45–16:15
L.A. Vinh
Distribution of Permanent of Matrices with Restricted Entries over Finite Fields

367

Plenary Session III
Lecture Hall A, Thu 4, 16:45–17:30
J. Lee
On the Boundary of Tractability for Nonlinear Discrete Optimization

373

List of Authors

385

List of Sessions

388

List of Timeslots

389

Keywords

390

Traveling Salesman Problem

Lecture Hall A

Tue 2, 08:45–10:15

Effective Heuristics for Large Euclidean TSP
Instances Based on Pseudo Backbones 1
C. Dong, C. Ernst, G. Jäger, D. Richter, P. Molitor
Computer Science Institute, University Halle, D-06120 Halle, Germany
{dong,ernstc,jaegerg,richterd,molitor}@informatik.uni-halle.de

Abstract
We present two approaches for the Euclidean TSP which compute high quality tours for
large instances. Both approaches are based on pseudo backbones consisting of all common
edges of good tours. The first approach starts with some pre-computed good tours. Using
this approach we found record tours for seven VLSI instances. The second approach is
window based and constructs from scratch very good tours of huge TSP instances, e. g., the
World TSP.
Key words: Euclidean Traveling Salesman Problem, Pseudo Backbone, Problem
Contraction, Iterative Approach, Window Based Approach

1. The overall approach

Given a set of cities and the distances between each pair of them, the Traveling
Salesman Problem (TSP) is the N P-hard problem of finding a shortest cycle visiting each city exactly once. In this paper we consider Euclidean TSP whose cities
are embedded either in the Euclidean plane using the Euclidean distance or a ball
using the spherical grid of latitude and longitude. The backbone of a TSP instance
consists of all edges, which are contained in each optimum tour of the instance, and
is an important criterion for the hardness of a TSP instance. The larger the backbone of an instance, the simpler is the remaining sub-instance. Unfortunately it is
usually hard to compute the backbone of an instance. An interesting observation is
that tours of an instance with good quality are likely to share many edges. We can
presume that these edges are also contained in optimum tours and call them pseudo
backbone edges. This basic observation is elaborated in detail in our approach. Assume that for a given TSP instance a set of pseudo backbone edges is computed.
1

This work is supported by German Research Foundation (DFG) with grant number MO
645/7-3.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

a

b

c

d

e

f

Fig. 1. Illustration of the first approach. The instance has 12 points in the Euclidean plane.
By the three starting tours given in (a), (b), and (c), we receive the pseudo backbone edges
(d). From the maximal paths consisting only of pseudo backbone edges, only one has a
length greater than 1. Only this path contributes to the size reduction. After contracting,
we receive a new instance with 8 points which contains 3 p-edges (e). The three p-edges
are fixed while searching tours for the new instance. In (e) an optimal tour t0 for the new
instance is shown. After re-contracting the p-edges by the corresponding paths, we receive
a tour t for the original instance (f). For this instance, the final tour is optimal.

Our idea is to contract maximal paths of pseudo backbone edges to single edges
which are kept fixed during the following process. By the contraction step, a new
TSP instance with smaller size is created which can be attacked more effectively.

2. Using good starting tours for pseudo backbone computation
Let a TSP instance be given as a complete graph G = (V, E) with E = V × V .
Our first approach undergoes the following five steps (see Fig. 1). The first step is
to find a set Ω of good tours for G which are called starting tours. The second step
is to collect the pseudo backbone edges, i. e., compute the set B := {e ∈ E; e ∈
∩T ∈Ω T } of edges which are contained in each tour of Ω. Let VB be the set of
vertices which are endpoints of at least one edge of B. The third step is to construct
all maximal paths consisting only of edges in B and contract each of these maximal
paths to an edge, the endpoints of which are that of the path. We denote them by pedges (path edges) and the set of all end points of the p-edges by Vp . The contraction
step results in a new TSP instance H = (W, F ) with W = (V \ VB ) ∪ Vp ,
F = W × W , where the weight of the p-edges can be chosen arbitrarily. The fourth
step is to find a good tour t0 for the new TSP instance H subject to the condition
that all p-edges must be in the tour. Finally, the fifth step is to obtain a tour t for the
original TSP instance G by re-contracting the p-edges by the corresponding paths in
the computed tour t0 . The experimental results strongly demonstrate the effectivity
of the approach: for seven VLSI instances with sizes 13584, 17845, 19402, 21215,
28924, 47608 and 52057 we could find better tours than the best tours known so
far (see TSP homepage: http://www.tsp.gatech.edu/). The success of this approach

4

strongly depends on having good starting tours generated by different methods – for
the above mentioned results we used starting tours which had been constructed by
different tolerance based algorithms presented in [3] (see [1] for more information
on tolerances).

3. Iterative window based pseudo backbone computation

Our second approach computes tours of large Euclidean TSP instances from
scratch, i. e., it does not require starting tours. In fact, computing multiple different
good starting tours for the World TSP with 1,904,711 cities is hardly realizable in
reasonable time. The basic idea of our window based approach consists of splitting
the bounding box of the vertices of the TSP instance in non-disjoint windows by
moving a window frame across the bounding box of the vertices of the TSP instance
with a step size of half the width (height) of the window frame (see Fig. 2). Thus
each vertex is contained in up to four windows. Each window defines a sub-instance
for which a good tour is computed, e. g., by Helsgaun’s LKH [2], independently of
the neighboring sub-instances. Now, the approach is based on the assumption that
an edge (u, w), which is contained in the same four windows and in each of the four
tours, has high probability to appear in an optimal tour of the original TSP instance
– in some sense the four windows together reflect the surrounding area of (u, w)
with respect to the four directions. Such edges are declared as pseudo backbone
edges (see Fig. 3(a)-3(c)). After the contraction of the maximum paths of pseudo
backbone edges, the approach is iterated with monotonically increasing window
frame. We applied the described algorithm to the World TSP and required about
4.75 days for computing from scratch a tour of length 7,569,766,108 which is only
at most 0.7661% greater than the length of an optimum tour. Currently, our approach is still dominated in some sense by LKH. By assigning the right values to
the parameters, LKH computes a tour for the World TSP in less than two days
which is at most 0,1174% greater than the length of an optimal tour [4]. † However, note that till now we have used only default parameters for LKH without any
parameter tuning. By detailed parameter tuning – as done by Helsgaun – the window frames of our approach can be chosen much larger which should lead to an
improvement of the computed tours and running times.

References
[1] B. Goldengorin, G. Jäger, and P. Molitor. Tolerances applied in combinatorial
optimization. J. Comput. Sci. 2(9), 716-734, Science Publications, 2006.
†

Note that the computation times, Helsgaun states in [2], do not include the computation
times of the starting tours [4].

5

Fig. 2. Illustration of the window based technique of splitting large TSP instances into
sub-instances.

(a)

Pseudo backbone edges
found by the four top left-hand
windows

(b)

Pseudo backbone edges
found in the current iteration.

(c) Constrained ETSP after contraction of the paths shown in (b).

Fig. 3. Window based pseudo backbone computation and contraction.

[2] K. Helsgaun. An Effective Implementation of K-opt Moves for the LinKernighan TSP heuristic. Writings on Computer Science 109, Roskilde University, 2007.
[3] D. Richter, B. Goldengorin, G. Jäger, and P. Molitor. Improving the Efficiency of Helsgaun’s Lin-Kernighan Heuristic for the Symmetric TSP. Proc.
of the 4th Workshop on Combinatorial and Algorithmic Aspects of Networking (CAAN), Lecture Notes in Comput. Sci. 4852, 99-111, 2007.
[4] K. Helsgaun. Private Communication, March 2009.

6

Efficient algorithms for the Double Traveling
Salesman Problem with Multiple Stacks
Marco Casazza, a Alberto Ceselli, a Marc Nunkesser b
a Dept.

of Information Technologies - University of Milan
{marco.casazza, alberto.ceselli}@unimi.it
b Inst.

of Theoretical Computer Science - ETH Zürich
mnunkess@inf.ethz.ch

Key words: Traveling Salesman Problem, LIFO constraints, efficient algorithms

1. Introduction
Routing is a key issue in logistics, and has been deeply studied in the literature; however, several practical applications require the loading of vehicles to
be explicitly considered. The Double Traveling Salesman Problem with Multiple
Stacks (DTSPMS) is one of the simplest examples of integrated routing and loading problem: two cities are given, in which N customers are placed. Items have to
be collected from the customers through a tour in the first city, and then delivered
through a tour in the second city. During the pickup tour, the items have to be organized in stacks on the back of the vehicle; the delivery operations can start only
from the top of the stacks. The DTSPMS is NP-Hard, as it includes the TSP as a
special case. Both heuristics [1] [2] and exact methods [3] have been proposed to
solve it.
The main aim of this paper is to investigate on theoretical properties of the DTSPMS; we also propose and test an efficient heuristic algorithm which exploits
such properties.
2. Formulation and properties
The DTSPMS can be modeled as the following graph optimization problem.
We are given a set of customers numbered 1 . . . N and two (di-)graphs G + (N+ , A+ )
and G − (N− , A− ) with weights c+ and c− respectively on the arcs. The former is the
pickup graph and latter is the delivery graph. Both sets N+ and N− consist of one
−
vertex n+
i and ni for each customer i, and an additional vertex 0 which represents
a depot. Hence the number of vertices is the same in the two graphs. Each customer
i requires the pickup of an item in vertex n+
i and the delivery of the same item in
−
vertex ni .
We indicate as pickup tour (resp. delivery tour) any permutation of vertices of the
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

pickup graph (resp. delivery graph). Each tour starts from and ends at the depot.
Each tour has a cost, which is the cost for traveling from one vertex to the next,
according to the order indicated by the permutation. Given two customers i and j,
+
we say that i precedes j on the pickup tour if n+
i appears to the left of nj in the
corresponding permutation. In a similar way, i precedes j on the delivery tour if n−
i
appears to the left of n−
j in the corresponding permutation.
The vehicle has a given number S of stacks available for transportation. A loading
plan is a mapping l from each customer i to a pair (s, p), representing the arrangement of the items in the stacks of the vehicle. In particular, l(i) = (s, p) if the item
of customer i occupies position p on stack s, with (s, 1) representing the bottom of
stack s.
Each stack actually represents a Last-In-First-Out structure: a loading plan is feasible with respect to a pickup tour (and vice versa) if, given any pair of customers i
and j such that i precedes j in the pickup tour, either l(i) = (s, p) and l(j) = (t, q)
with s 6= t, or p < q. That is, if item i is picked up before item j, i cannot be
placed on top of j in the same stack. A similar definition holds for the delivery tour.
If i precedes j in both the pickup and the delivery tour, it must be l(i) = (s, p)
and l(j) = (t, q) with s 6= t, and we say that customers i and j are incompatible.
Hence, a solution of the DTSPMS is composed by two ingredients: a pair of pickup
and delivery tours and a loading plan; such solution is feasible if the loading plan
is feasible with respect to both tours.
In the following we show that, given one of the two ingredients of a feasible solution, the remaining one can be found in polynomial time. This holds in particular
for an optimal solution. We present only a sketch of the proofs.
Problem (1): Given a pickup tour and a delivery tour, find a feasible loading
plan using the minimum number of stacks.
Proposition 1. Problem (1) can be solved in polynomial time.
We define a conflict graph C having one vertex for each customer, and one edge for
each pair of incompatible customers. Problem (1) can be re-stated as the problem of
coloring graph C with the minimum number of colors: different colors represents
different stacks; since no adjacent vertices can take the same color in a feasible
coloring, no incompatible customers can be assigned to the same stack. The order of the items inside each stack can be chosen according to their order in one
of the tours. We show that C is a permutation graph, which is a special case of
perfect graph. In these graphs coloring problems can be solved in polynomial time
by means of flow computations [4]. As far as efficiency is concerned, we show that
Problem (1) can be solved in O(N · logN) time by an adaptation of the algorithm
presented in [4].
Problem (2): Given a loading plan, find a delivery tour which is feasible with
respect to the loading plan and has minimum cost.
Problem (3): Given a loading plan, find a pickup tour which is feasible with respect
to the loading plan and has minimum cost.

8

Proposition 2. Problem (2) and Problem (3) can be solved in polynomial time.
In fact, once a feasible loading plan is given, suppose to incrementally build partial
delivery tours by choosing items on the top of the stacks. Let f (s1 , . . . , sS , p) be
the minimum cost of a partial tour in which s1 items are left in stack 1, s2 items are
left in stack 2 and so on, and in which the item on the top of stack p is the next to
be delivered. Let i be the customer corresponding to the item on top of stack p; if i
is the first customer to be visited, then f (s1 , . . . , sS , p) = c−
0,i ; otherwise, consider
any stack q, which has on top item j: f (s1 , . . . , sS , p) = minq=1..S {f (s1 , . . . , sq +
S+1
) time by com1, . . . , sS , q) + c−
j,i }. An optimal solution can be found in O(|N|
puting all the values for f () using dynamic programming recursion. Informally, the
computation can be repeated to solve Problem (3) by considering the items of each
stack in reverse order.
However, given two random tours, it might not be possible to find a loading
plan using at most S stacks. Therefore we define as partial loading plan a loading
plan in which the items of a subset of customers do not appear, and we consider the
following:
Problem (5): Given a pickup and a delivery tour, find a feasible partial loading plan
using at most S stacks, including the maximum number of items.
Proposition 3. Problem (5) can be solved in polynomial time.
We build a graph having a vertex for each customer and two vertices for the depot
(start and end), an arc between the vertex of each customer and the vertices of
its compatible customers, between the start depot vertex and each customer vertex,
and between each customer vertex and the end depot vertex. The start and end depot
vertices are respectively a source and a sink of S units of flow. We assign capacity 1
and cost 0 to each arc, and cost −1 to each customer vertex. Problem (5) can be restated as the problem of finding a minimum cost flow on a suitable modification of
this graph. Informally, the S units of flow define sequences of customers included
in the same stack. Every time a vertex receives flow, the corresponding customer is
inserted in a stack, and a value −1 is collected; therefore in an optimal solution the
maximum number of customers is included.
3. Algorithms
We elaborated on the previous results to obtain a heuristic algorithm for the
DTSPMS. The algorithm works in five steps: (a) find a pickup tour and a delivery tour (b) solve Problem (5), creating a feasible partial loading plan including
the highest number of customers (c) solve Problem (2) and Problem (3) considering only customers in the partial loading plan, creating optimal partial pickup and
delivery tours (d) create a feasible DTSPMS solution by including the remaining
customers in the stacks using a best insertion policy (e) create a candidate solution
for the next iteration of the algorithm by including the remaining customers in the
partial tours using a best insertion policy (f) repeat steps (b) – (f).
First we note that the number of customers which are inserted in the partial loading
plan, which is found in step (b), is always non decreasing from one iteration to the
next. In fact, customers whose items are included in a partial loading plan during
9

iteration k appear in the tours according to the order given by the partial loading
plan; our insertion algorithm do not change that order; hence, during iteration k + 1
it is always possible to rebuild the partial loading plan of iteration k. Therefore,
we stop the algorithm whenever no additional customer is inserted in the partial
loading plan during step (c). In order to obtain a feasible solution in step (d), we
consider the items which are not included in the loading plan in a random order.
We try to place every item in each possible position in the stacks, and in each compatible insertion point in the tours. Then, we place each item in the position of the
loading plan giving minimum insertion cost. Instead, in order to obtain a candidate
solution in step (e), we consider in a random order each customer whose item is
not in the partial loading plan, and we perform a best insertion operation in both
the pickup and delivery tours. We keep the best solution found in step (d) during
the iterations of the main algorithm as final solution. In the literature, it is common
to further constrain the problem by imposing a limit on the number of items which
can be placed in the same stack. When such a constraint is imposed, during step (d)
we remove from the partial loading plan each item exceeding the limit, and we care
not to insert additional items in full stacks.
We implemented our heuristic algorithm in C, using MCF library for the flow subproblems and CONCORDE to obtain tours in step (a). We considered the testbed of
10 instances involving 33 customers proposed in [1] and [3]. We run experiments
on a 1.83GHz notebook ∗ . As a benchmark, we considered the results of the HVNS
metaheuristic [1], when let run for ten seconds. Our method provides in a fraction
of a second solutions whose quality is about 8% worse than those given by HVNS.
This highlights as a promising research direction to combine our algorithm with
local search methods.
References
[1] A. Felipe, M.T. Ortuno and G. Tirado (2008) Neighborhood structures to solve
the double TSP with multiple stacks using local search. FLINS Proceedings,
Madrid, September 21–24 2008
[2] H. Petersen and O. Madsen. (2008) The double travelling salesman problem
with multiple stacks - formulation and heuristic solution approaches. European Journal of Operational Research, forthcoming
[3] H. Petersen, C. Archetti and M.G. Speranza (2008) Exact Solutions to the
double TSP with multiple stacks. Tech. rep, University of Brescia
[4] A. Brandstädt (1992) On Improved Time Bounds for Permutation Graph
Problems. Lecture Notes in Computer Science 657

∗

A full table is available at: http://www.dti.unimi.it/∼ceselli/DTSPMS.thml

10

The Parking Warden Tour Problem
Maurizio Bruglieri, a Alberto Colorni, a Alessandro Lué b
a INDACO,

Politecnico di Milano, via Durando 38/a, 20158 Milano, Italy
{maurizio.bruglieri,alberto.colorni}@polimi.it

b POLIEDRA, Politecnico

di Milano, via Garofalo 39, 20133 Milano, Italy
lue@poliedra.polimi.it

Key words: irregular parking, parking warden tour, arc routing problem.

1. Introduction

Irregular parking is a scourge for most of the Italian cities and in most of the
cases enforcement ([6]) is not effective. Unfortunately, municipalities have limited resources to hire a sufficient number of parking wardens, and the tours and
schedule of the existing wardens are not planned using quantitative models. For
the municipality of Como (Italy), we are studying how to re-configure the parking system, considering both pricing and organizational aspects. Within this study,
we developed a model to improve the level of efficiency of the parking enforcement optimizing the parking warden tours. The problem is the following. The team
of parking wardens, the city road network, the link travel time, and the estimated
profit deriving from the sanctions applied to the cars irregularly parked are given.
We want to determine the tour of each warden (that is a cycle where both vertices
and edges may be repeated and having total duration less than the warden service
time), with the aim of maximizing the total profit collected. In the literature, we do
not find mathematical models that face this problem. This problem differs from the
Profitable Arc Tour problem [1] since in the latter both the arc profits and costs are
fixed whereas in our problem they depend on the moment of the day (the average
number of irregular parked cars can vary during the day) and on the time passed
from the previous inspection of a warden (the profit on a link slumps to zero if a
warden has just visited this link). This peculiarity occurs in other different routing problems. For instance, in the snowplough vehicles routing problem the profit
collected is the amount of snow removed, which depends on the time passed from
the previous transit of a snowplough, supposing that it is snowing during the operations. At the best of our knowledge ( [1], [4] [5]), this is the first study of an
arc routing problem where the arc profit depends also on the solution itself. For

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

this new arc routing problem, we present a MILP formulation from which we also
develop a simple but effective heuristic approach.

2. Graph representation of the problem

Since the wardens inspect the road network by foot, the problem can be modelled by way of an undirected graph where each edge represents a road link that can
be travelled in both the directions. In each road link the cars can be parked from
one to four sides according to the width of the road and the presence or not of a
traffic island. Each side is visited by the wardens in different moments, except the
two sides of the traffic islands. Therefore, we have to duplicate the ending vertices
of the original road links if they have two parking sides or triplicate the ending vertices if in addition there is a traffic island, to avoid parallel edges. The edges linking
the copies of the same vertex represent the action of crossing the road to change the
side and no profit is associated to them.

3. Mixed Integer Linear Programming formulation
Beside the undirected graph G = (V, E) described in the previous section, we
suppose also given the following data:
W = parking warden set
T = parking warden service time
ce = travel time by foot of edge e
q = time needed to sanction one car
p = profit for one irregularly parked car
se = estimation of irregularly parked cars on edge e
Re = estimation of turn-over time on edge e
We assume that a team of wardens is available at a single depot, represented by
vertex 0, and they have to come back to depot at the end of the service. Moreover
we assume that the profit of an edge e slumps to zero when such edge is visited
by a warden. Afterwards, the profit increases linearly from 0 to pse until the turnover time Re is reached, after which it remains constant until the next visit. Under
these assumptions, we state that the Parking Warden Tour Problem (PWTP) can be
modeled by way of the following Mixed Integer Linear Program (MILP), where K
is an upper bound on the number of edges that the wardens can visit along their
T
tour (for instance K = mine∈E
) and δ(0) denotes the edges incident to the depot.
ce

12

max

PK P
k=1

P

e∈E

w∈W

PK

k=1

πkw

(3.1)

(ce xekw + qse zekw ) ≤ T ∀w ∈ W

(3.2)

∀w ∈ W

(3.3)

P
xe1w
Pe∈δ(0)
e∈E

=1

xekw ≤ 1

∀k = 2,...,K, ∀w ∈ W

P

P

PK
v0kw
Pk=2
i∈V

=1

vikw ≤ 1

v
≥ vjkw
i:{i,j}∈E ik+1w

i∈N

PK+1

v 0
k0 =k+1 ik w

πk00 w ≤

P

(3.5)

∀w ∈ W

(3.6)

∀k = 2,...,K + 1, ∀w ∈ W

(3.7)

∀j ∈ V, ∀k = 1,...,K, ∀w ∈ W

(3.8)

≤ (K − k + 1) (1 − v0kw )

xekw ≥ vikw + vjk+1w − 1
xekw ≤ vikw
xekw ≤ vjk+1w
zekw ≤ xekw
t1w = 0
P
(c x
tkw ≥ tk−1w +
e∈E e ek−1w
πkw ≤ p

(3.4)

∀w ∈ W

v01w = 1

s z
e∈E e ekw

∀k = 2,...,K, ∀w ∈ W
∀e = {i, j} ∈ E, ∀k = 1,...,K, ∀w ∈ W
∀e = {i, j} ∈ E, ∀k = 1,...,K, ∀w ∈ W
∀e = {i, j} ∈ E, ∀k = 1,...,K, ∀w ∈ W
∀e = {i, j} ∈ E, ∀k = 1,...,K, ∀w ∈ W
∀w ∈ W
+ qse zek−1w )

(3.9)
(3.10)
(3.11)
(3.12)
(3.13)
(3.14)

∀k = 2,...,K + 1, ∀w ∈ W
∀k = 1,...,K, ∀w ∈ W

(3.15)
(3.16)
00

k −1

t 00 −t 0
pse k wR k w
e

+

pS(2 − zek00 w − zek0 w +

X

zekw )

0

k=k +1
0

∀e ∈ E, ∀k 0, k 00= 1,...,K : k 00 > k , ∀w ∈ W

πk00 w00 ≤ pse

πk0 w0 ≤ pse

t 00
k

t 0

w

k w

00 −t 0 0
k w
Re

0 −t 00 00
k w
Re

+pS(1 +

(3.17)

T
)(3 − zek00 w00 − zek0 w0 − yk0 k00 w0 w00 )
Re
0

00

0

00

0

00

0

00

0

00

0

00

∀e ∈ E, ∀k , k = 1,...,K, ∀w , w ∈ W : w < w
T
+pS(1 +
)(2 − zek00 w00 − zek0 w0 − yk0 k00 w0 ,w00 )
Re

∀e ∈ E, ∀k , k = 1,...,K, ∀w , w ∈ W : w < w
tk00 w00 − tk0 w0
− zek0 w0 − zek00 w00
yk0 k00 w0 w00 ≤ 3 +
T
0
00
0
00
0
00
∀e ∈ E, ∀k , k = 1,...,K, ∀w ,w ∈ W : w < w
t 00 00 − tk0 w0
+ zek0 w0 + zek00 w00
yk0 k00 w0 w00 ≥ −2 + k w
T
0
00
0
00
0
00
∀e ∈ E, ∀k , k = 1,...,K, ∀w ,w ∈ W : w < w
xekw ≥ 0
∀e ∈ E, ∀k = 1, ...,K, ∀w ∈ W
yk0 k00 w0 w00 ∈ {0, 1}
∀k 0 , k 00 = 1, ...,K, ∀w 0 , w 00 ∈ W : w 0 < w 00
vikw ∈ {0, 1}
∀i ∈ V, ∀k = 1, ...,K + 1, ∀w ∈ W
zekw ∈ {0, 1}
∀e ∈ E, ∀k = 1, ...,K, ∀w ∈ W
πkw ≥ 0
∀k = 1, ...,K, ∀w ∈ W
0 ≤ tkw ≤ T
∀k = 1, ...,K + 1, ∀w ∈ W

(3.18)

(3.19)

(3.20)

(3.21)
(3.22)
(3.23)
(3.24)
(3.25)
(3.26)
(3.27)

Variables πkw model the profit collected by warden w when visiting the k-th
edge of his/her tour: these variables are settled by constraints (3.16) and by big-M
constraints (3.17), (3.18) and (3.19), where S = maxe∈E se . Therefore the objective
function (3.1) models the maximization of the total collected profit.
Variables vikw are equal to 1 if vertex i is the k-th vertex visited by warden w, 0

13

otherwise. Thanks to constraints (3.10), (3.11) and (3.12), variables xekw are binary
although not directly constrained to be so: in particular they are equal to 1 if edge
e is the k-th edge visited by warden w in his/her tour (independently on the fact
that its profit is collected or not), are equal to 0 otherwise. Indeed (3.10), (3.11)
and (3.12) can be seen as McCormick linearization constraints ([3]) imposing that
variables xekw have the same behaviour of bilinear terms vikw vjk+1w where e is the
edge linking vertices i and j.
Variables zekw are equal to 1 if edge e is the k-th edge visited by warden w in his/her
tour and its profit is collected, are equal to 0 otherwise.
Variables tkw model the time instant when the k-th edge is visited by warden w;
variables yk0k00 w0w00 model the precedence relationships in the visit of the same edge
by different wardens: in particular when the k 0 -th edge travelled by warden w 0 and
the k 00 -th edge travelled by warden w 00 coincide, such variables are equal to 1 if w 00
precedes w 0 , are equal to 0 otherwise.

4. Some computational results
We notice that MILP (1)-(27) involves O(|E|K|W | + K 2 |W |2) binary variables and O(|E|K 2|W |2) linear constraints, therefore in practice we cannot think
of applying this model directly to the whole team of wardens, unless to consider
just small instances. Anyway from the MILP model we can build a simple but effective heuristic approach. It consists in iteratively solving, with the MILP (1)-(27),
|W | instances of PWTP with one warden, where, at each iteration, the profit collection of the edges already visited with profit in the previous iterations, is forbidden.
We have implemented the MILP (1)-(27) in AMPL [2] and considered random instances with number of vertices between 10 and 50, number of edges between 30
and 150 and up to 4 wardens. The preliminary computational results obtained with
CPLEX11.0 solver show that the heuristic is able to find a solution always in few
seconds, whereas the MILP can require hundreds of seconds up to 2 wardens and
also several hours for 4 wardens. Concerning the solution quality, we have found
an average percentage gap between the heuristic and the optimal solution of about
5.8%.

References
[1] D. Feillet, P.Dejax, M.Gendreau. The Profitable Arc Tour Problem: Solution
with a Branch-and-Price Algorithm. Transportation Science, 39(4):539–552,
2005.
[2] R. Fourer and D. Gay The AMPL Book. Duxbury Press, Pacific Grove, 2002.
[3] G.P. McCormick. Computability of global solutions to factorable nonconvex

14

programs: part I-convex underestimating problems. Mathematical Programming, 10:146–75, 1976.
[4] N. Perrier, A. Langevin, J.F. Campbell. A survey of models and algorithms for
winter road maintenance. Part IV: Vehicle routing and fleet sizing for plowing
and snow disposal. Computers & Operations Research, 34:258–294, 2007.
[5] N. Perrier, A. Langevin, A. Amaya. Vehicle routing for urban snow plowing
operations. Les Cahiers du GERAD, G-2006-33, 2006.
[6] R. Petiot Parking enforcement and travel demand management. Transport
Policy, 11:399–411, 2004.

15

Graph Theory I

Lecture Hall B

Tue 2, 08:45–10:15

On Self-Duality of Branchwidth
in Graphs of Bounded Genus ?
Ignasi Sau, a Dimitrios M. Thilikos b
a Mascotte

project INRIA/CNRS/UNSA, Sophia-Antipolis, France; and Graph Theory and
Comb. Group, Applied Maths. IV Dept. of UPC, Barcelona, Spain.

b Department

of Mathematics, National Kapodistrian University of Athens, Greece.

Abstract
A graph parameter is self-dual in some class of graphs embeddable in some surface if its
value does not change in the dual graph more than a constant factor. Self-duality has been
examined for several width-parameters, such as branchwidth, pathwidth, and treewidth. In
this paper, we give a direct proof of the self-duality of branchwidth in graphs embedded in
some surface. In this direction, we prove that bw(G∗ ) ≤ 6 · bw(G) + 2g − 4 for any graph
G embedded in a surface of Euler genus g.
Key words: graphs on surfaces, branchwidth, duality, polyhedral embedding.

1. Preliminaries
A surface is a connected compact 2-manifold without boundaries. A surface Σ
can be obtained, up to homeomorphism, by adding eg(Σ) crosscaps to the sphere.
eg(Σ) is called the Euler genus of Σ. We denote by (G, Σ) a graph G embedded
in a surface Σ. A subset of Σ meeting the drawing only at vertices of G is called
G-normal. If an O-arc is G-normal, then we call it a noose. The length of a noose is
the number of its vertices. Representativity, or face-width, is a parameter that quantifies local planarity and density of embeddings. The representativity rep(G, Σ) of
a graph embedding (G, Σ) is the smallest length of a non-contractible noose in Σ.
We call an embedding (G, Σ) polyhedral if G is 3-connected and rep(G, Σ) ≥ 3.
See [7] for more details. For a given embedding (G, Σ), we denote by (G∗ , Σ) its
dual embedding. Thus G∗ is the geometric dual of G. Each vertex v (resp. face r)
in (G, Σ) corresponds to some face v ∗ (resp. vertex r ∗ ) in (G∗ , Σ). Also, given a set
X ⊆ E(G), we denote as X ∗ the set of the duals of the edges in X.
? This work has been supported by IST FET AEOLUS, COST 295-DYNAMO, and by the
Project “Kapodistrias” (AΠ 02839/28.07.2008) of the National and Kapodistrian University of Athens (project code: 70/4/8757).

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

S

S

Given a graph G and a set X ⊆ E(G), we define ∂X = ( e∈X e)∩( e∈E(G)\X e)
(notice that ∂X = ∂(E(G)\X)). A branch decomposition (T, µ) of a graph G consists of an unrooted ternary tree T (i.e., all internal vertices are of degree three) and
a bijection µ : L → E(G) from the set L of leaves of T to the edge set of G. For
every edge f = {t1 , t2 } of T we define the middle set mid(e) ⊆ V (G) as follows:
Let L1 be the leaves of the connected component of T \ {e} that contain t1 . Then
mid(e) = ∂µ(L1 ). The width of (T, µ) is defined as max{|mid(e)| : e ∈ T }. An
optimal branch decomposition of G is defined by a tree T and a bijection µ which
give the minimum width, called the branchwidth of G, and denoted by bw(G).
Suppose G1 and G2 are graphs with disjoint vertex-sets and k ≥ 0 is an integer.
For i = 1, 2, let Wi ⊆ V (Gi ) form a clique of size k and let G0i (i = 1, 2) be
obtained from Gi by deleting some (possibly none) of the edges from Gi [Wi ] with
both endpoints in Wi . Consider a bijection h : W1 → W2 . We define a clique-sum
G1 ⊕ G2 of G1 and G2 to be the graph obtained from the union of G01 and G02 by
identifying w with h(w) for all w ∈ W1 .
Let G be a class of graphs embeddable in a surface Σ. We say that a graph
parameter CRRAP is (c, d)-self-dual on G if for every graph G ∈ G and for its
geometric dual G∗ , CRRAP (G∗ ) ≤ c · CRRAP (G) + d. Results concerning selfduality of pathwidth can be found in [4; 1]. Branchwidth is (1, 0)-self-dual in planar
graphs that are not forests [9], while analogous results have been proven for other
parameters such as pathwidth [3; 1] and treewidth [5; 2; 6]. In this note, we give
a proof that branchwidth is (6, 2g − 4)-self-dual in graphs of Euler genus at most
g. We also believe that our result can be considerably improved. In particular, we
conjecture that branchwidth is (1, g)-self-dual.
2. Self-duality of banchwidth
If (G, Σ) is a polyhedral embedding, then the following proposition follows by
an easy modification of the proof of [4, Theorem 1].
Proposition 2.1. Let (G, Σ) and (G∗ , Σ) be dual polyhedral embeddings in a surface of Euler genus g. Then bw(G∗ ) ≤ 6 · bw(G) + 2g − 4.
In the sequel, we focus on generalizing Proposition 2.1 to arbitrary embeddings. For
this we first need some technical lemmata, whose proofs are easy or well known,
and omitted in this extended abstract. Note that the removal of a vertex in G corresponds to the contraction of a face in G∗ , and viceversa.
Lemma 2.2. The removal of a vertex or the contraction of a face from an embedded graph decreases its branchwidth by at most 1.
Lemma 2.3. (Fomin and Thilikos [3]) Let G1 and G2 be graphs with one edge or
one vertex in common. Then bw(G1 ∪ G2 ) ≤ max{bw(G1 ), bw(G2 ), 2}.
Theorem 2.4. Let (G, Σ) be an embedding with g = eg(Σ). Then bw(G∗ ) ≤

20

6 · bw(G) + 2g − 4.
Proof. The proof uses the following procedure that applies a series of cutting
operations to decompose G into polyhedral pieces plus a set of vertices whose size
is linearly bounded by eg(Σ). The input is the graph G and its dual G∗ embedded
in Σ.
1. Set B = {G}, and B∗ = {G∗ } (we call the members of B and B∗ blocks).
2. If (G, Σ) has a minimal separator S with |S| ≤ 2, let C1 , . . . , Cρ be the connected components of G[V (G) \ S] and, for i = 1, . . . , ρ, let Gi be the graph
obtained by G[V (Ci) ∪ S] by adding an edge with both endpoints in S in
the case where |S| = 2 and such an edge does not already exist (we refer to
this operation as cutting G along the separator S). Notice that a (non-empty)
separator S of size at most 2 corresponds to a non-empty separator S ∗ of
G∗ , and let G∗i , i = 1, . . . , ρ be the graphs obtained by cutting G∗ along S ∗ .
We say that each Gi (resp G∗i ) is a block of G (resp. G∗ ) and notice that
each G and G∗ is the clique sum of its blocks. Therefore, from Lemma 2.3,
bw(G∗ ) ≤ max{2, max{bw(G∗i ) | i = 1, . . . , ρ}} (1). Observe that we
may assume that for each i = 1, . . . , ρ, Gi and G∗i are embedded in a surP
face Σi such that Gi is the dual of G∗i and eg(Σ) = i=1,...,ρ eg(Σi ). Notice
that bw(Gi ) ≤ bw(G), i = 1, . . . , ρ (2), as the possible edge addition does
not increase the branchwidth, since each block of G is a minor of G. We set
B ← B \ {G} ∪ {G1 , . . . , Gρ } and B∗ ← B∗ \ {G∗ } ∪ {G∗1 , . . . , G∗ρ }.
3. If (G, Σ) has a non-contractible and non-surface-separating noose meeting a
set S with |S| ≤ 2, let G0 = G[V (G) \ S] and let F be the set of of faces in
G∗ corresponding to the vertices in S. Observe that the obtained graph G0 has
an embedding to some surface Σ0 of Euler genus strictly smaller than Σ that,
in turn, has some dual G0∗ in Σ0 . Therefore eg(Σ0 ) < eg(Σ). Moreover, G0∗
is the result of the contraction in G∗ of the |S| faces in F . From Lemma 2.2,
bw(G∗ ) ≤ bw(G0∗ ) + |S| (3). Set B ← B \ {G} ∪ {G0 } and B∗ ← B∗ \
{G∗ } ∪ {G0∗ }.
4. Apply (recursively) Steps 2–4 for each block G ∈ B and its dual.
We now claim that before each recursive call of Steps 2–4, it holds that bw(G∗ ) ≤
6 · bw(G) + 2eg(Σ) − 4. The proof uses descending induction on the the distance
from the root of the recursion tree of the above procedure. Notice that all embeddings of graphs in the collections B and B∗ constructed by the above algorithm are
polyhedral, except from the trivial case that they are just cliques of size 2. Then the
theorem follows directly from Proposition 2.1.
Suppose that G (resp. G∗ ) is the clique sum of its blocks G1 , . . . , Gρ (resp.
G∗1 , . . . , G∗ρ ) embedded in the surfaces Σ1 , . . . , Σρ (Step 2). By induction, we have
that bw(G∗i ) ≤ 6 · bw(Gi ) + 2eg(Σi ) − 4, i = 1, . . . , ρ and the claim follows from
P
Relations (1) and (2) and the fact that eg(Σ) = i=1,...,ρ eg(Σ).

21

Suppose now (Step 3) that G (resp. G∗ ) occurs from some graph G0 (resp. G0∗ )
embedded in a surface Σ0 where eg(Σ0 ) < eg(Σ) after adding the vertices in S
(resp. S ∗ ). From the induction hypothesis, bw(G0∗ ) ≤ 6 · bw(G0 ) + 2eg(Σ0 ) − 4 ≤
6 · bw(G0 ) + 2eg(Σ) − 2 − 4 and the claim follows easily from Relation (3) as
|S| ≤ 2 and bw(G0 ) ≤ bw(G).
3. Recent results and a conjecture
Very recently Mazoit [6] proved that treewidth is a (1, g + 1)-self-dual parameter in graphs embeddable in surfaces of Euler genus g. Using that the branchwidth
and the treewidth of a graph G, with |E(G)| ≥ 3, satisfy bw(G) ≤ tw(G) + 1 ≤
3
bw(G) [8], this implies that bw(G∗ ) ≤ 23 bw(G) + g + 2, improving the con2
stants of Theorem 2.4. We believe that an even tighter self-duality relation holds
for branchwidth and hope that the approach of this paper will be helpful to settle
the following conjecture.
Conjecture 1. If G is a graph embedded in some surface Σ, then bw(G∗ ) ≤
bw(G∗ ) + eg(Σ).
References
[1] O. Amini, F. Huc, and S. Pérennes. On the Pathwidth of Planar Graphs. SIAM
Journal on Discrete Mathematics, 2009. To appear.
[2] V. Bouchitté, F. Mazoit, and I. Todinca. Chordal embeddings of planar graphs.
Discrete Mathematics, 273(1-3):85–102, 2003. EuroComb’01 (Barcelona).
[3] F. V. Fomin and D. M. Thilikos. Dominating Sets in Planar Graphs: BranchWidth and Exponential Speed-Up. SIAM Journal on Computing, 36(2):281–
309, 2006.
[4] F. V. Fomin and D. M. Thilikos. On self duality of pathwidth in polyhedral
graph embeddings. Journal of Graph Theory, 55(1):42–54, 2007.
[5] D. Lapoire. Treewidth and duality for planar hypergraphs, 1996:
http://www.labri.fr/perso/lapoire/papers/dual planar treewidth.ps.

[6] F. Mazoit. Tree-width of graphs and surface duality. To appear in DIMAP
workshop on Algorithmic Graph Theory (AGT), Warwick, U.K., March 2009.
[7] B. Mohar and C. Thomassen. Graphs on surfaces. John Hopkins University
Press, 2001.
[8] N. Robertson and P. Seymour. Graph minors. X. Obstructions to Treedecomposition. J. Comb. Theory Series B, 52(2):153–190, 1991.
[9] P. Seymour and R. Thomas. Call routing and the ratcatcher. Combinatorica,
14(2):217–241, 1994.

22

A simple linear-time recognition algorithm
for weakly quasi-threshold graphs 1
Stavros D. Nikolopoulos, Charis Papadopoulos
Department of Computer Science, University of Ioannina
P.O.Box 1186, GR-45110 Ioannina, Greece
{stavros,charis}@cs.uoi.gr

Abstract
Weakly quasi-threshold graphs form a proper subclass of the well-known class of cographs
by restricting the join operation. In this paper we characterize weakly quasi-threshold
graphs by a finite set of forbidden subgraphs: the class of weakly quasi-threshold graphs coincides with the class of {P4 , co-(2P3 )}-free graphs. Moreover we give the first linear-time
algorithm to decide whether a given graph belongs to the class of weakly quasi-threshold
graphs, improving the previously known running time. Based on the simplicity of our
recognition algorithm, we can provide certificates of membership (a structure that characterizes weakly quasi-threshold graphs) or non-membership (forbidden induced subgraphs)
in additional O(n) time. Furthermore we give a linear-time algorithm for finding the largest
induced weakly quasi-threshold subgraph in a cograph.

1. Introduction
The well-known class of cographs is recursively defined by using the graph operations of ‘union’ and ‘join’ [4]. Bapat et al. [1], introduced a proper subclass of
cographs, namely the class of weakly quasi-threshold graphs, by restricting the join
operation and studied their Laplacian spectrum. In the same work they proposed
a quadratic-time algorithm for recognizing such graphs. Here we characterize the
class of weakly quasi-threshold graphs by the class of graphs having no P4 (chordless path on four vertices) or co-(2P3 ) (the complement of two disjoint P3 ’s). This
characterization also shows that the complement of a weakly quasi-threshold graph
is not necessarily weakly quasi-threshold graph. Moreover we give a tree representation for such graphs, similar to the cotrees for cographs, and propose a linear-time
recognition algorithm.
1

This research work is co-financed by E.U.-European Social Fund (75%) and the Greek
Ministry of Development-GSRT (25%).

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

P4 -free

cographs

a

d
c

co-qt-graphs
{P4 , 2K2 }-free

f

wqt-graphs

{P4 , co-(2P3 )}-free

e

b
1

{P4 , co-(2P3 ), 2K2 }-free

qt-graphs

{P4 , C4 }-free

simple cographs

z 1

c
{P4 , C4 , 2K2 }-free

threshold

(a)

0 y

x 0

a

1 w

f
b

d

e

(b)

Fig. 1. (a) Subclasses of cographs and (b) a co-(2P3 ) and its cotree.

The class of cographs coincides with the class of graphs having no induced P4
[5]. There are several subclasses of cographs. Trivially-perfect graphs, also known
as quasi-threshold graphs, are characterized as the subclass of cographs having
no induced C4 (chordless cycle on four vertices), that is, such graphs are {P4 , C4 }free graphs, and are recognized in linear time [3; 6]. Another interesting subclass of
cographs are the {P4 , C4 , 2K2 }-free graphs known as threshold graphs, for which
there are several linear-time recognition algorithms [3; 6]. Clearly every threshold
graph is trivially-perfect but the converse is not true. Gurski introduced the class of
{P4 , co-(2P3 ), 2K2 }-free graphs in his study of characterizing graphs of certain restricted clique-width [7]. Together with the class of weakly quasi-threshold graphs
(that are exactly the class of {P4 , co-(2P3 )}-free graphs as we show in this paper),
we obtain the inclusion properties for the above families of graphs that we depict
in Figure 1 (a).
For undefined terminology we refer to [3; 6]. A vertex x of G is universal if
NG [x] = V (G) and is isolated if it has no neighbors in G. Two vertices x, y of G are
called false twins if NG (x) = NG (y). A clique is a set of pairwise adjacent vertices
while an independent set is a set of pairwise non-adjacent vertices. A chordless
cycle on k vertices is denoted by Ck and a chordless path on k vertices is denoted
by Pk . The complement of the graph consisting of two disjoint P3 ’s is denoted by
co-(2P3 ). Given two vertex-disjoint graphs G1 = (V1 , E1 ) and G2 = (V2 , E2 ), their
union is G1 ∪ G2 = (V1 ∪ V2 , E1 ∪ E2 ). Their join G1 + G2 is the graph obtained
from G1 ∪ G2 by adding all the edges between the vertices of V1 and V2 . The class
of cographs, also known as complement reducible graphs, is defined recursively as
follows:
(c1) a single vertex is a cograph;
(c2) if G1 and G2 are cographs, then G1 ∪ G2 is also a cograph;
(c3) if G1 and G2 are cographs, then G1 + G2 is also a cograph.
The class of cographs coincides with the class of P4 -free graphs [5]. Along with
other properties, it is known that cographs admit a unique tree representation, called
a cotree [4]. For a cograph G its cotree, denoted by T (G), is a rooted tree having
O(n) nodes. The vertices of G are precisely the leaves of T (G) and every internal
node of T (G) is labelled by either 0 (0-node) or 1 (1-node). Two vertices are adja-

24

cent in G if and only if their least common ancestor in T (G) is a 1-node. Moreover,
if G has at least two vertices then each internal node of the tree has at least two
children and any path from the root to any node of the tree consists of alternating
0- and 1-nodes. The complement of any cograph G is a cograph and the cotree of
the complement of G is obtained from T (G) with inverted labeling on the internal
nodes of T (G). Note that we distinguish between vertices of a graph and nodes of a
tree. Cographs can be recognized and their cotrees can be computed in linear time
[5; 8; 2].

2. A characterization of weakly quasi-threshold graphs
Bapat et al., introduced in [1] the class of weakly quasi-threshold graphs (or
wqt graphs for short) and defined the given class as follows:
(w1) a single vertex is a wqt graph;
(w2) if G1 and G2 are wqt graphs then G1 ∪ G2 is a wqt graph;
(w3) if G is a wqt then adding a universal vertex in G results in a wqt graph;
(w4) if G is a wqt graph then adding a vertex in G having the same neighborhood
with a vertex of G results in a wqt graph.
By definition the class of cographs and wgt graphs have certain similarities. Clearly
every wqt graph is a cograph but the converse is not true. Properties c1,c2 and
w1,w2 completely coincide, whereas properties w3–w4 correspond to a restricted
version of c3. Moreover it follows that in a connected wqt graph there is either a
universal vertex or a false twin. Then it is not difficult to see that the class of wqt
graphs is closed under taking induced subgraphs, that is, the class of wqt graphs is
hereditary.
Lemma 2.1. The class of wqt graphs can be defined recursively as follows:
(a1) an edgeless graph is a wqt graph; (a2) if G1 and G2 are wqt graphs then
G1 ∪ G2 is a wqt graph; (a3) if G is a wqt graph and H is an edgeless graph then
G + H is a wqt graph.
Proof. Properties w2 and a2 are exactly the same. By properties w1 and w2
we have that edgeless graphs are wqt graphs. We need to show that property a3
can substitute both properties w3–w4. If G is a wqt graph and H is an edgeless
graph then the graph G + H is obtained by first adding a universal vertex in G
and then by the addition of false twins. Hence G + H is a wqt graph. For the
converse let G be a connected wqt graph. First observe that G can be reduced
to a disconnected wqt graph G[A] by repeatedly removing a universal vertex or
a false twin vertex. Let S be a set of the removal vertices. Let xn , . . . , xk be an
order of S where xi is either universal or false twin in Gi = G[{xi , . . . , xk } ∪ A],
n ≤ i ≤ k. We show that there is such an order of {xn , . . . , xk } where all the false
twin vertices appear consecutive. If there is a universal vertex xj between two false
twin vertices xi and xk then swapping the positions of xj and xk keeps the same
property for the resulting order. We apply this operation for every universal vertex
25

between two false twin vertices and obtain an order of the vertices of S where the
false twin vertices appear consecutive. Observe that the set of the false twin vertices
induces an edgeless graph in G. Thus the join operation between a wqt graph and
an edgeless graph is sufficient to construct a connected wqt graph.
Next we give a characterization of weakly quasi-threshold graphs through forbidden subgraphs based on Lemma 2.1.
Theorem 2.1. A graph G is weakly quasi-threshold if and only if G does not contain any P4 or co-(2P3 ) as induced subgraphs.

3. A linear-time recognition algorithm
In this section we give a linear-time algorithm for deciding whether an arbitrary
graph is wqt. Let G be the input graph. We first apply the linear-time recognition
algorithm for checking whether G is a cograph [5]. If G is not a cograph then we
know that G is not a wqt graph as it contains a P4 . Otherwise G admits a cotree
T (G) that can be constructed in linear time [5; 8]. Now it suffices to efficiently
check an induced co-(2P3 ) on G by using the cotree T (G). For that purpose, we
modify T (G) and obtain T ∗ from T (G) by applying the following two operations:
(i) delete the subtree rooted at a 0-node having only leaves as children and (ii)
remove a leaf that has 1-node as parent. Next we check if every 1-node in T ∗ has
at most one child. In case of an affirmative answer we output that G is a wqt graph;
otherwise, we output that G is not a wqt graph. Correctness of the algorithm is
based on the following lemma.
Lemma 3.1. Let G be a cograph and let T ∗ be its modified cotree. Then G is wqt
graph if and only if every 1-node of T ∗ has at most one child.
Theorem 3.1. Weakly quasi-threshold graphs can be recognized in O(n+m) time.
Furthermore given a graph G there is an O(n + m) algorithm that reports either an
induced P4 or co-(2P3 ) of G whenever G is not a weakly quasi-threshold graph.
As already mentioned every wqt graph is a cograph but the converse is not necessarily true. We show that the problem of removing the minimum number of vertices
from a cograph so that the resulting graph is wqt can be done in linear time. Note
that the proposed algorithm can serve as a recognition algorithm as well. Let T (G)
be the cotree of G and let T ∗ be the modified cotree. Our algorithm starts by traversing both T (G) and T ∗ from the leaves to the root and computes for each node of
T (G) a largest induced wqt subgraph; the one computed at the root of T (G) provides the largest induced wqt subgraph of G. The computed graph is represented
by a cotree T 0 that we construct during the traversal of T (G). Let Hu be the induced subgraph of G corresponding to the leaves of the subtree rooted at a node u
of T (G). Every time the algorithm visits a node u of T (G) it computes the triple

26

(n(u), MC(u), MI(u)) where n(u) is the number of vertices of Hu , MC(u) is the
maximum clique of Hu , and MI(u) is the maximum independent set of Hu . Let
u1 , u2 , . . . , uk be the children of u in T (G). If u is a 0-node or a 1-node with at
most one child then the algorithm assigns to u the correct triple by Lemma 3.1 and
copies node u in T 0 . If u is a 1-node and u has at least two children in T ∗ then we
need to modify the subtree rooted at u. Let u∗1 , u∗2 , . . . , u∗` be the children of u in
T ∗ ; note that each child u∗1 is a 0-node, 1 ≤ i ≤ `. Based on Lemma 3.1 we modify every subtree in T (G) rooted at u∗i except that u∗p having the maximum value
among min{n(u∗i ) − |MC(u∗i )|, n(u∗i ) − |MI(u∗i )|}. For every other node u∗j 6= u∗p
we do the following operations: if |MC(u∗j )| > |MI(u∗j )| then we delete the subtree
rooted at u∗j and add the vertices of MC(u∗j ) as children of u; otherwise we remove
the nodes of the subtree rooted at u∗j and add the vertices of MI(u∗j ) as children of
u∗j .
Theorem 3.2. Given a cograph G there is an O(n + m) algorithm that finds a
largest induced weakly quasi-threshold subgraph of G.

References
[1] R.B. Bapat, A.K. Lal, and S. Pati. Laplacian spectrum of weakly quasi-threshold
graphs. Graphs and Combinatorics, 24:273–290, 2008.
[2] A. Bretscher, D. Corneil, M. Habib, and C. Paul. A simple linear time LexBFS cograph recognition algorithm. SIAM Journal on Discrete Mathematics, 22:1277–1296,
2008.
[3] A. Brandstädt, V.B. Le, and J.P. Spinrad. Graph Classes: A Survey. SIAM Monographs on Discrete Mathematics and Applications, 1999.
[4] D.G. Corneil, H. Lerchs, and L.K. Stewart. Complement reducible graphs. Discrete
Applied Mathematics, 3:163–174, 1981.
[5] D.G. Corneil, Y. Perl, and L.K. Stewart. A linear recognition algorithm for cographs.
SIAM Journal on Computing, 14:926–934, 1985.
[6] M. C. Golumbic. Algorithmic Graph Theory and Perfect Graphs. Second edition.
Annals of Discrete Mathematics 57. Elsevier, 2004.
[7] F. Gurski. Characterizations for co-graphs defined by restricted NLC-width or cliquewidth operations. Discrete Mathematics, 306:271–277, 2006.
[8] M. Habib and C. Paul. A simple linear time algorithm for cograph recognition. Discrete Applied Mathematics, 145:183–197, 2005.

27

From Sainte-Laguë to Claude Berge — French graph
theory in the twentieth century ??
Harald Gropp a
a Hans-Sachs-Str.

6, D-65189 Wiesbaden
d12@ix.urz.uni-heidelberg.de

Key words: graph theory, Berge graph

1. Introduction

Dedicated to CLAUDE BERGE (1926-2002),
mathematician and man of culture
In 1926 the zeroth book on graph theory was published by A. Sainte-Laguë [9].
It collects the knowledge on graphs at this early stage and particularly focusses on
the French development of this new field in mathematics. The first French pioneer
in graph theory, Georges Brunel (see [7]) prepared the first decades of the last
century. Ten years after the zeroth book, in 1936, the first book on graph theory by
D. König [8] was published.
Sainte-Laguë’s life and work is discussed in [6]. His book [10] of 1937 (and
reprinted in 1994) contains the analysis of many mathematical games and famous
problems in combinatorics, e.g. La Tour d’Hanoı̈, Les quinze demoiselles, Les
trente-six officiers, La ville de Koenisberg and Le jeu d’Hamilton.
In the annexe of the new edition of 1994 Claude Berge discusses the starting
points of the abstract theory of graphs.
De très nombreux problèmes de ce livre ont été le point de départ de théorèmes généraux.
Encore fallait-il poser les bases d’une théorie abstraite.
??This paper was not actually presented at the conference, as the author withdrew his participation.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

One of the examples which Berge discusses is the Problème du loup, de la
chèvre, et du chou. Berge also displays a graph of the problem. The general background and the history of these river-crossing problems is further described in [5].
1926 is also the birth year of Claude Berge who died in 2002 and was not only
the most influential man in French graph theory in the second half of the twentieth
century but also somebody very broadly interested in cultural fields like literature
and Oceanic art.
In 1958 Claude Berge published his first book on graph theory [1] which was
soon translated into several other languages.

2. Sainte-Laguë’s zeroth book on graph theory

Sainte-Laguë’s book [9] is not much known today. It is not available in many
libraries. Even in France it is nearly forgotten. In König’s book [8] it is mentioned
as a reference several times. Claude Berge was one of the few mathematicians who
really made use of it. It should be discussed whether it would be useful to reprint
the book, together with comments and perhaps a translation into English.
This short report does not replace my paper [6] but will just give a brief introduction. André Sainte-Laguë was born in Saint-Martin-Curton (Dépt. Lot-etGaronne) on April 20, 1882. He died in Paris on January 18, 1950. After he had
studied mathematics till 1906 he became a teacher at different schools between
1906 and 1927 when he joined the CNAM ( Conservatoire National des Arts et
Métiers) in Paris. In 1937 he organized the mathematical presentations for the world
exhibition in Paris, and in 1938 he got the chair of mathematics and applications
at the CNAM. During the German occupation of France in World War II he was a
leading member of the Résistance.
Sainte-Laguë wrote his dissertation on graphs in 1924 which contained already
many proofs of theorems which he presented in his book of 1926. This book contains of 9 chapters on 64 pages. The 9 chapters are as follows: Introduction and
definition, Trees, Chains and circuits, Regular graphs, Cubic graphs, Incidence matrices, Hamiltonian graphs, Chess problems, and Knight’s move problems where
the titles are given in modern terminology and not in the words of Sainte-Laguë.
The list of 223 references is a good survey of the combinatorial literature earlier
than 1926.
Sainte-Laguë describes important sources for graph theory such as recreational
problems or physics or chemistry.

29

3. Claude Berge’s books

In the following two of Claude Berge’s books will be further discussed in order
to show his attitude towards graph theory and combinatorics and their history. A
third book will be briefly mentioned. It is not the aim of this short paper to give a
full survey on Claude Berge’s books. In this extended abstract the books will only
be briefly described.

3.1

Claude Berge: The Theory of Graphs and its applications (1962), French
1958

Claude Berge’s book of 1958 [1] was a breakthrough for the development of
the new mathematical field, called graph theory, not only in France, but for the
whole world. After the books of Sainte-Laguë (1926) [9] and König (1936) [8] who
for different reasons did not become widely circulated the book of Berge found a
broad acceptance and was soon translated into many other languages. In his introduction of two pages Berge introduces graphs as applied in physics, chemistry,
economics, psychology etc. This close link to all possible areas of applications was
certainly one of the main aspects of Claude Berge’s graph theory.

3.2

Claude Berge: Principles of Combinatorics (1971), French 1968

What is Combinatorics ?
In the introduction of his book Principles of Combinatorics [2] Claude Berge
describes the main characteristics of combinatorics by using configurations as combinatorial structures. Configurations are here just special objects with certain constraints, not configurations as defined by Reye and discussed in many of my papers
(e.g. see [6]).

3.3

Claude Berge: Graphes et Hypergraphes (1970)

It should not be forgotten that sometimes Claude Berge was called Monsieur la
théorie des hypergraphes. In fact he pushed forward this extended aspect of graph
theory very much, also as the author of his book on hypergraphs [4]. Hypergraphs
were only ”invented” around 1960, but similar concepts had already been around
much earlier. The real importance of these combinatorial structures will only become clear in the future and will not be further discussed in this short paper.

30

4. Claude Berge, literature and art

Last but not least let me mention here Claude Berge’s activities in literature and
art. He was a member of the group OULIPO ( Ouvroir de Littérature Potentielle)
which was founded in 1960 and works on the connections between mathematics
and literature. Some prominent members as writers are Raymond Queneau and
Georges Perec. Claude Berge himself wrote the novel Qui a tué le Duc de Densmore
? in 1994 [3] in which he used a combinatorial theorem of Hajós to tell a criminal
story.
It is generally known that Claude Berge was very much interested in the cultures of the Pacific Ocean, in particular in the art of Papua - New Guinea. He himself
had sculptured similar objects and collected all kind of information on Oceanic Art.
As a small footnote let me mention here that he was in close contact to the Konrad
family in Mönchengladbach (Germany) who gave an important Asmat collection
to the Völkerkundemuseum in Heidelberg. The Asmat are one of the many peoples
in Papua.

5. A few last words

Let me close this short paper which discusses two remarkable and unusual
French mathematicians of the twentieth century by explicitly mentioning the extreme friendliness and kindness of Claude Berge. Although he became one of the
most prominent and important experts in his field he always stayed a man just very
much interested in many things, not only in mathematics and graph theory.
The very last words should just remind us of Claude Berge’s enormous influence on the graph theory of the twentieth century and express our thanks (in the
French language, of course):
Merci beaucoup !

References
[1] C. Berge, Théorie des graphes et ses applications,Paris (1958), in English:
The theory of graphs and its applications, London-New York (1962).
[2] C. Berge, Principes de combinatoire, Paris (1968), in English: Principles of
combinatorics, New York-London (1971).
[3] C. Berge, Qui a tué le Duc de Densmore ?, Bibliotheque Oulipienne (1994).
[4] C. Berge, Graphes et hypergraphes, Paris (1970).

31

[5] H.Gropp, Propositio de lupo et capra et fasciculo cauli — On the history of
river-crossing problems, in: Charlemagne and his heritage, 1200 years of civilization and science in Europe, Vol. 2, (eds. P.L. Butzer, H.Th. Jongen, W.
Oberschelp), Turnhout (Belgium) (1998), 31-41.
[6] H. Gropp, On configurations and the book of Sainte-Laguë, Discrete Math.
191 (1998), 91-99.
[7] H. Gropp, ”Réseaux réguliers” or regular graphs — Georges Brunel as a
French pioneer in graph theory, Discrete Math. 276 (2004), 219-227.
[8] D. König, Theorie der endlichen und unendlichen Graphen, Leipzig (1936).
[9] A. Sainte-Laguë, Les réseaux (ou graphes), Paris (1926).
[10] A. Sainte-Laguë, Avec des nombres et des lignes, Paris (1937).

32

Combinatorial Optimization

Lecture Hall A

Tue 2, 10:30–12:30

Colored Independent Sets
J. Maßberg and T. Nieberg
Research Institute for Discrete Mathematics
University of Bonn, Lennéstr. 2, 53113 Bonn, Germany
{massberg, nieberg}@or.uni-bonn.de

Abstract
We study graphs with colored vertices and prove that it is NP-complete to decide if there
is an independent set in the graph containing at least one vertex of each color. The proof
immediately yields that the problem remains NP-complete even when restricting the graph
to the class of Unit Disk Graphs (UDGs).
We present and discuss also an application where the problem arises in the area of VLSI
routing: Conflict-free and thus disjoint wiring interconnects for a set of pins on a circuit
have to be chosen from a precomputed set of paths.
Key words: Colored Graphs, Unit Disk Graph, VLSI Design

1. Introduction
Given a graph G together with a color κv ∈ {1, . . . , K} for each vertex v ∈
V (G), we seek an independent set I ⊆ V (G) in G that maximizes the objective
function
c(I) := min |{i ∈ I|κi = k}|.
k∈{1,...,K}

Clearly, if all vertices have the same color, this amounts to the classical Maximum Independent Set problem, which is known to be NP-hard. The C OLORED
I NDEPENDENT S ET decision problem is the following:
Given an r ∈ N, is there an independent set I ⊆ V (G) with c(I) ≥ r?
In the following, we restrict ourselves to the class of Unit Disk Graphs which
capture the same geometric property of the application presented next.
Definition 1. A graph G is called a U NIT D ISK G RAPH (UDG) if there exists a
map f : V (G) → R2 satisfying: (u, v) ∈ E(G) ⇔ kf (u) − f (v)k ≤ 1.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Fig. 1. Conflicting and conflict-free pin access paths (via and wiring on higher layer) for a
circuit with three pins (shaded on lower layer).

2. Application

We consider the following problem in detailed VLSI routing, where the above
C OLORED I NDEPENDENT S ET problem occurs. Given a circuit (a collection of
pins) placed on the chip-area, we want to connect each pin by a short access path
that legally connects it to the overall routing grid used to cover larger distances.
Usually, the routing is done sequentially, i.e. one connection after the next, in
order to create disjoint interconnects. Especially when the pins are situated very
dense, this gives frequent complications when a path blocks the access to a not yet
connected pin (see Figure 1).
Our solution to this problem is to preprocess each circuit by first computing
a set of access paths for each pin of a given circuit, and then selecting a disjoint
and conflict-free subset that is used in the sequential routing phase. For the latter,
a conflict graph is built for a circuit so that each path connecting to a certain pin
receives the same color, and two paths are connected by an edge if they create a
short circuit when used at the same time.
Clearly, an independent set having a vertex (i.e. path) of each color (i.e. pin)
corresponds to a conflict-free pin access situation.
li1 (κi,1
l )
vi (κiv )

vi1 (κi,1
v )
v1i (κi,1
v )

vi2 (κi,2
v )

v2i (κi,2
v )

...

vim (κi,m
v )
i,m
vm
i (κv )

vi (κiv )

2

li (κi,2
l )
Fig. 2. Example for a ’variable’ graph Gxi . Here xi ∈ Z1 and xi ∈ Z2 . The color of the
vertices are enclosed in brackets.

36

3. NP-Completeness

In this section we give our main result, formulated for Unit Disk Graphs.
Theorem 1. The C OLORED I NDEPENDENT S ET
NP-complete even for r = 1.

IN

UDG S decision problem is

Membership in NP is obvious. We prove that 3S ATISFIABILITY polynomially
transforms to C OLORED I NDEPENDENT S ETS IN UDG S. Given a collection Z of
clauses Z1 , . . . , Zm over X = {x1 , . . . , xn }, each clause containing three literals,
we shall construct a UDG G that contains an independent set I with c(I) ≥ 1 iff Z
is satisfiable.
The graph G contains for each variable xi ∈ X two vertices vi , vi of color κiv ,
and for pair of variable xi ∈ X and clause Zj ∈ Z two vertices vij , v ji of color κi,j
v .
These vertices indicate whether the variables xi are true or false.
Additionally the graph contains for each variable in a clause xi ∈ Zj two
j
vertices lij , li of color κi,j
l linking the variables and the clauses.
Moreover we have for each clause Zj containing the variables xa , xb , xc four
vertices zaj , zbj , zcj and z j of color κjz showing if the corresponding literals and the
complete clause are satisfied or not.
Finally we have a ’satisfiability’ vertex s of color κs indicating if Z is satisfiable in total. Note that all defined colors are pairwise disjoint.
Based on these vertices, the graph contains three different types of subgraphs
representing the variables, the clauses and the last one showing if the problem is
satisfiable.
The first type are the graphs Gxi representing the variables xi ∈ X. Let Axi :=
j
{vi , v i } ∪ {vij , v ji |1 ≤ j ≤ m}, Bxi := {lij |xi ∈ Zj }, B xi := {li |xi ∈ Zj }. Then,
V (Gxi ) := Axi ∪ Bxi ∪ B xi and
m
m
E(Gxi ) := {(vi , v1i ), (v1i , vi1), (vi1 , v 2i ), . . . , (vm
i , vi ), (vi , v i )}
j

∪{(lij , vji ) | xi ∈ Zj } ∪ {(li , vij ) | xi ∈ Zj }.

It is easy to see that there is a UDG representation for Gxi (see Figure 2): The
subgraph induced by Axi is a path from vi to v i . We place the vertices of the path
on a horizontal line with distance 1 between two intermediate vertices. The vertices
of Bxi will be placed above and the vertices of B xi below their adjacent vertices of
Axi , again at distance 1.

37

laj (κa,j
l )

lb (κb,j
l )

j

lcj (κc,j
l )

zaj (κjz )

zbj (κjz )

zcj (κjz )

Fig. 3. Example for a ’clause’ graph GZj for Zj = xa ∨ xb ∨ xc .

z 6 (κ6z )z 5 (κ5z )
z 1 (κ1z )

s(κs )

z 4 (κ4z )

z 2 (κ2z )z 3 (κ3z )
Fig. 4. Graph S for a 3SAT instance with 6 clauses.

The second type of graphs are the graphs GZj representing each clause Zj ∈ Z
(Figure 3). We set
j

V (GZj ) := {zij | xi ∈ Zj ∨ xi ∈ Zj } ∪ {li | xi ∈ Zj } ∪ {lij | xi ∈ Zj } and
j

E(GZj ) := {(zij , li )| xi ∈ Zj } ∪ {(zij , lij )| xi ∈ Zj }.

The last type just contains a complete graph S with V (S) := {z 1 , . . . , z j , s}
and E(S) := {(v, w)| v, w ∈ V (S), v 6= w} (Figure 4).
The graph G is the union of {Gxi }1≤i≤n , {GZk }1≤j≤m and S.
It is evident that this is a polynomial transformation, and it now remains to
show that G correctly encodes the instance Z.
• Z is satisfiable ⇒ G contains an independent set I with c(I) ≥ 1.
Let T : X → {true, false} be a truth assignment that satisfies Z. We show that
there exists an independent set I in G with c(I) ≥ 1. Set
I := {vi , vi1 , . . . , vim | T (xi ) = true} ∪ {v i , v1i , . . . , v m
i | T (xi ) = false}
j
∪{li | xi ∈ Zj ∨ xi ∈ Tj , T (xi ) = true}
j

∪{li | xi ∈ Zj ∨ xi ∈ Tj , T (xi ) = false}
∪{zij | (xi ∈ Zj ∧ T (xi ) = true) ∨ (xi ∈ Zj ∧ T (xi ) = false)} ∪ {s}.

38

It is easy to verify that this is indeed an independent set. Now we have to show
that each color is represented by an vertex of I. Obviously there are vertices of
i,j
colors κiv , κi,j
v , κl , κs , 1 ≤ i ≤ n, 1 ≤ j ≤ m in I.
It remains to show that for each 1 ≤ j ≤ m there is a vertex of color κjz in I.
As each clause Zj is satisfied, there is an xi ∈ Zj with T (xi ) = true or an xi ∈ Zj
with T (xi ) = false. This gives zij ∈ I in both cases.
• G contains an independent set I with c(I) ≥ 1 ⇒ Z is satisfiable.
Let I be an independent set I with c(I) ≥ 1. The task now is to construct a truth
assignment T : X → {true, false} that satisfies Z.
Set Pi = {vi , vi1 , . . . , vim } and Ni = {vi , v 1i , . . . , vm
i } for 1 ≤ i ≤ n. Note that
all vertices of Pi ∪ Ni are on a path and elements of Pi are only adjacent to vertices
of Ni and vice versa. By construction of Gxi either (Pi ⊂ I and Ni ∩ I = ∅) or
(Ni ⊂ I and Pi ∩ I = ∅). In the first case we set T (xi ) = true and in the second
case T (xi ) = false.
Now let Zj ∈ Z be a clause. We claim that Zj is satisfied. Since c(I) ≥ 1, the
vertex s must be in I as it is the only vertex of color κs . The vertices z j and s are
adjacent and I is an independent set so z j ∈
/ I. But there must be a vertex of color
j
i
κz in I, i.e. there exists an i with zi ∈ I. We have either xi ∈ Zj or xi ∈ Zj . In
j
j
the case xi ∈ Zj , the vertex zij is connected to li and therefore li ∈
/ I. From this
j
i,j
/ I
it follows that li ∈ I as there must be a vertex of color κl in I. But then v ji ∈
which means that we have set T (xi ) = true. The clause Zj is satisfied. Similar
arguments apply to the case that xi ∈ Zj . Here we conclude that T (xi ) = false and
again get that Zj is satisfied.
Therefore Z is satisfied, and the proof is complete.

39

2

A note on the parameterized complexity of the
maximum independent set problem
Vadim V. Lozin a
a DIMAP

and Mathematics Institute, University of Warwick, Coventry, UK

Key words: Parameterized complexity, Independent set, Ramsey Theory

1. Introduction

We study the MAXIMUM INDEPENDENT SET problem parameterized by the
solution size k, which we call k-INDEPENDENT SET. A parameterized problem
is fixed-parameter tractable (fpt for short) if it can be solved in f (k)nO(1) time,
where f (k) is a computable function depending on the value of the parameter only.
In general, the k-INDEPENDENT SET problem is W[1]-hard, which means it is not
fixed-parameter tractable unless P = NP . On the other hand, fpt-algorithms have
been developed for segment intersection graphs with bounded number of directions
[6], triangle-free graphs [8], graphs of bounded vertex degree [5], planar graphs,
and more generally, graphs excluding a single-crossing graph as a minor [3]. A
common feature of all these classes is that all of them are hereditary (i.e., closed
under vertex deletion) and all of them are small in the following sense. It is known
(see e.g. [2]) that for every hereditary class X, the number Xn of n-vertex graphs in
1
X (also known as the speed of X) satisfies limn→∞ log2nXn = 1 − k(X)
, where k(X)
(2 )
is a natural number called the index of the class. The triangle-free graphs have index
2 and the index of all other classes mentioned above is 1 (see [7] for the speed of
minor-closed graph classes). In this paper, we focus on hereditary classes of index
k > 1. Each class X in this range can be approximated by a minimal class of the
same index. The main result of this paper is that the problem is fixed-parameter
tractable in all minimal classes of index k for all values of k.
We use the following notations. For a subset U ⊆ V (G), we denote by G[U]
the subgraph of G induced by U. Kn stands for the complete graph on n vertices
and K n for its complement. Also, pK2 is the disjoint union of p copies of K2 .
For a set of graphs M, we denote by F ree(M) the class of graphs containing no
induced subgraphs isomorphic to graphs in M. It is known that a class X of graphs
is hereditary if and only if X = F ree(M) for a certain set M. For two graph classes

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

X and Y , denote by XY the class of graphs whose vertices can be partitioned into
two subsets, one of which induces a graph in X and another one a graph in Y . Let
us denote by G1 ∨ G2 the union of two graphs G1 = (V, E1 ) and G2 = (V, E2 ) with
a common vertex set V , i.e., G1 ∨ G2 = (V, E1 ∪ E2 ). If A and B are two classes
of graphs, then A ∨ B := {G1 ∨ G2 : G1 ∈ A, G2 ∈ B}.
2. Complexity of the problem in classes of high speed

The main result of the paper is consequence of a series of technical lemmas.
Lemma 1. Let A, B be two classes of graphs such that (1) A ⊆ F ree(pK2 ) for
some constant p, (2) B is a hereditary class of graphs admitting an fpt-algorithm
for the k-INDEPENDENT SET problem, (3) there is an algorithm that for any graph
G ∈ A ∨ B, finds in polynomial time two graphs G1 ∈ A and G2 ∈ B such that
G = G1 ∨ G2 . Then the k-INDEPENDENT SET problem is fixed-parameter tractable
in the class A ∨ B.
Proof. An fpt-algorithm for graphs in A ∨ B can be outlined as follows. Given
a graph G ∈ A ∨ B, first, find two graphs G1 ∈ A and G2 ∈ B such that G =
G1 ∨ G2 . Next, for each maximal under inclusion independent set I in G1 , solve the
k-INDEPENDENT SET problem in G2 [I] ∈ Y by an fpt-algorithm. If the algorithm
finds an independent set of size k in G2 [I] ∈ Y , output this set for the graph G.
Otherwise (i.e., if the fpt-algorithm says NO for each graph G2 [I] ∈ Y ), answer
NO for the graph G. Correctness of the procedure follows from the fact that every
independent set in G also is independent both in G1 and G2 . To estimate its time
complexity, observe that the number of inclusionwise maximal independent sets in
pK2 -free graphs is bounded by a polynomial [1] and all of them can be found in
polynomial time [9].
Lemma 2. If XY is a class of graphs with X ⊆ F ree(K m ) and Y ⊆ F ree(Kn ),
then XY ⊂ F ree(mK2 ) ∨ F ree(Kn ).
Proof. Let G = (V, E) be a graph in XY and let V = V1 ∪ V2 be a partition
of V such that G[V1 ] ∈ X and G[V2 ] ∈ Y . Denoting G1 = (V, E − E(G[V2 ])) and
G2 = (V, E(G[V2 ])), we conclude that G = G1 ∨ G2 . Obviously, G2 ∈ F ree(Kn ).
To see that G1 ∈ F ree(mK2 ) observe that if M is an induced subgraph of degree
1 in G1 then at least one endpoint of each edge of M belongs to V1 (because V2 is
independent in G1 ). Since V1 can contain at most m − 1 independent vertices, the
size of M is at most m − 1.
Lemma 3. For any constant q, the k-INDEPENDENT SET problem is fixed-parameter
tractable in the class F ree(Kq ).

41

Proof. It can be decided in time O(nq ) if G has an independent set of size
k ≤ q. For k > q, we employ the Ramsey theory. Let R(t) be the diagonal Ramsey
number. It is known [4] that R(t) ≤ 22t−3 . Moreover, the proof given in [4] is
constructive and shows how to find in a graph with n ≥ 22t−3 vertices a subset
inducing an independent set or a clique of size t in time O(tn).
Let k > q. If the number of vertices of a graph G ∈ F ree(Kq ) is at most 22k−3 ,
then we can check in time O(2(2k−3)k ) if G has an independent set of size k. If G
has n > 22k−3 vertices, we know that G has an independent set of size k (because
G is Kq -free) and this set can be found in time O(kn).
Lemma 4. For any X ⊆ F ree(K m ) and Y ⊆ F ree(Kn ), there exists a constant
τ = τ (X, Y ) such that for every graph G = (V, E) ∈ XY and every subset B ⊆ V
with G[B] ∈ Y , at least one of the following statements holds:
(a) ∃ A ⊆ V such that G[A] ∈ Y , G[V − A] ∈ X, and |A − B| ≤ τ ,
(b) ∃ C ⊆ V such that G[C] ∈ Y , |C| = |B| + 1, and |B − C| ≤ τ .
Proof. By Ramsey Theorem, for each positive integers m and n, there is a
constant R(m, n) such that every graph with at least R(m, n) vertices contains
either a K m or a Kn as an induced subgraph. Given two sets X ⊆ F ree(K m ) and
Y ⊆ F ree(Kn ), we define τ = τ (X, Y ) to be equal R(m, n).
Let G = (V, E) be a graph in XY , and B a subset of V such that G[B] ∈ Y .
Consider an arbitrary subset A ⊆ V such that G[A] ∈ Y and G[V − A] ∈ X. If (a)
does not hold, then |A−B| > τ . In addition, G[B −A] ∈ X ∩Y ⊆ F ree(K m , Kn ),
and hence |B − A| ≤ τ . Consequently, |A| > |B|. But then any subset C ⊆ A such
that A ∩ B ⊆ C and |C| = |B| + 1 satisfies (b).
Theorem 1. If m and n are constants and XY is a class of graph such that X ⊆
F ree(K m ) and Y ⊆ F ree(Kn ), then the k-INDEPENDENT SET problem is fixedparameter tractable in the class XY .
Proof. We apply Lemma 1. Conditions (1) and (2) of the lemma follows from
Lemmas 2 and 3. For condition (3), we develop the following algorithm:
Input: A graph G = (V, E) ∈ XY with X ⊆ F ree(K m ) and Y ⊆ F ree(Kn )
Output: Graphs G1 ∈ F ree(mK2 ), G2 ∈ F ree(Kn ) such that G = G1 ∨ G2 .
(1) Find in G any maximal under inclusion subset B ⊆ V inducing a graph in
F ree(Kn ).
(2) If there is a subset C ⊆ V satisfying condition (b) of Lemma 4, then set
B := C and repeat Step (2).
(3) Find in G a subset A ⊆ V such that |B − A| ≤ τ , |A − B| ≤ τ , G[A] ∈
F ree(Kn ), G1 = (V, E − E(G[A])) ∈ F ree(mK2 ).
(4) Output G1 = (V, E − E(G[A])) and G2 = (V, E(G[A])).

42

Correctness of the algorithm follows from Lemmas 2 and 4. To estimate
   its

time complexity, observe that in Step (2) the algorithm inspects at most |Vτ | τ|V+1|
subsets C and for each of them, verifies whether G[C] ∈ F ree(Kn ) in time O(|V |n ).
Since Step (2) loops at most |V | times, its time complexity is O(|V |2τ +n+2 ). In
 2
Step (3), the algorithm examines at most |Vτ | subsets A. For each A, it verifies
whether G[A] ∈ F ree(Kn ) in time O(|V |n ) and whether G[V − A] ∈ F ree(K m )
(and hence G1 ∈ F ree(mK2 )) in time O(|V |m ). Summarizing, we conclude that
the total time complexity of the algorithm is O(|V |2τ +m+n ).
Denote by Ei,j the class of graphs whose vertices can be partitioned into at most
i independent sets and j cliques. Then the index k(X) of a class X is the maximum
k such that X contains a class Ei,j with i + j = k, i.e. the classes Ei,j with i + j = k
are the only minimal classes of index k. Obviously, Ei,j ⊆ F ree(K i+1 )F reeKj+1 .
Therefore,
Corollary 1. For any natural i and j, the k-INDEPENDENT
parameter tractable in the class Ei,j .

SET

problem is fixed-

References
[1] E. Balas, Ch.S. Yu, On graphs with polynomially solvable maximum-weight
clique problem, Networks 19 (1989) 247-253.
[2] J. Balogh, B. Bollobás, D. Weinreich, The speed of hereditary properties of
graphs, J. Combin. Theory, Ser. B 79 (2000) 131–156.
[3] E.D. Demaine, M. Hajiaghayi, D.M. Thilikos, Exponential speedup of fixedparameter algorithms for classes of graphs excluding single-crossing graphs
as minors, Algorithmica, 41 (2005) 245–267.
[4] R. Diestel, Graph theory. Third edition. Graduate Texts in Mathematics, 173.
Springer-Verlag, Berlin, 2005. xvi+411 pp.
[5] J. Flum, M. Grohe, Parameterized complexity theory. Texts in Theoretical
Computer Science. Springer-Verlag, Berlin, 2006. xiv+493 pp.
[6] J. Kára, J. Kratochvı́l, Fixed parameter tractability of Independent Set in segment intersection graphs, LNCS, 4169 (2006) 166–174.
[7] S. Norine, P. Seymour, R. Thomas, P. Wollan, Proper minor-closed families
are small, J. Combinatorial Theory Ser. B, 96 (2006) 754–757.
[8] V. Raman, S. Saurabh, Triangles, 4-Cycles and Parameterized
(In−)Tractability, Lecture Notes in Computer Science, 4059 (2006) 304–315.
[9] S. Tsukiyama, M. Ide, H. Ariyoshi, I. Shirakawa, A new algorithm for generating all the maximal independent sets, SIAM J. Computing, 6 (1977) 505517.

43

On multi-agent knapsack problems
Gaia Nicosia, a Andrea Pacifici, b Ulrich Pferschy c
a Dipartimento
b Dipartimento

di Informatica e Automazione, Università degli studi “Roma Tre”, Italy
nicosia@dia.uniroma3.it

di Ingegneria dell’Impresa, Università degli Studi di Roma “Tor Vergata”,
Italy
pacifici@disp.uniroma2.it

c Institut

für Statistik und Operations Research, Universität Graz, Austria
pferschy@uni-graz.at

Key words: multi-agent optimization, knapsack and subset sum problem, games.

1. Introduction

In this work we consider knapsack-like problems in a multi-agent setting.
These kinds of problems occur in several different application environments and
different methodological fields, such as artificial intelligence, decision theory, operations research etc. We focus on the following situation: There are two agents,
each of them owning one of two disjoint sets of items. The agents have to select
items from their set for packing them in a common knapsack and thus sharing a
given common resource. Each agent wants to maximize a payoff function which
is given by its own items’ profits. The problem is how to compute solutions which
take into account each agent’s payoff function, and that can be used to support the
negotiation among the agents.
We present some results about two different classes of problems, namely, a
subset sum game and a special knapsack game with unitary weights. We characterize Pareto and global optima and provide solution algorithms both in the centralized
and multi-agent scenarios.
The problem that we address in this work is relatively new, however 0-1 knapsack problems (KP) in a multi-decision environment have been considered in the
literature for two decades: from game-theoretic to auction scenarios there is a variety of papers dealing with this classical combinatorial optimization problem. Hereafter, we limit to report a few of them.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

A related problem in which different players try to fit their own items in a
common knapsack is the so called knapsack sharing problem studied by several
authors (see for instance [3; 4]). A single objective function that tries to balance the
profits among the players is considered in a centralized perspective.
An interesting game, based on the maximum 0-1 knapsack, interpreted as a
special on-line problem, is addressed in [5] where a two person zero-sum game,
called knapsack game, is considered. Knapsack problems are also considered in the
context of auctions. For instance, in [1], an application for selling advertisements
on Internet search engines is considered. In particular, there are n agents wishing
to place an item in the knapsack and each agent gives a private valuation for having
an item in the knapsack, while each item has a publicly known size.
In the following, A and B indicate both the agents’ names and the corresponding set of items, while n(A) and n(B) denote the number of items of each agent.
B
A
B
Moreover, pA
i , pj are the profits and wi , wj are the weights of items i ∈ A and
j ∈ B, respectively. Finally, let c be the capacity of the knapsack.
2. Subset Sum game with rounds
B
A
B
Here we consider a subset sum game, i.e. pA
i = wi and pj = wj for all
items i = 1, . . . , n(A), j = 1, . . . , n(B). The aim of the game is for each agent
to select a subset of its items with maximum total weight. The game can be seen
as a sequence of rounds, where in each round A selects one of its items (which
was not selected before) and puts it into the knapsack. Then B does the same. The
total weight of all selected items must not exceed the capacity c at any time. All
information is public. We adopt a sort of online perspective, in which we want to
determine the best strategy for agent A assuming that B is rational and is pursuing
its own objective.

Given any deterministic strategy of B an optimal strategy of agent A can be
computed via backward induction by enumerating all possible sequences of item
selection in a decision tree, similar to a game in extensive form. Naturally, this takes
exponential time.
In contrast to this intractable approach we provide a natural greedy algorithm
for this problem, where agent A simply selects in every round the item with the
largest weight that does not violate the capacity constraint. We show that such a
greedy algorithm may reach only half of the weight attained by an optimal strategy
but can not do worse than that.
It can also be shown that the price of anarchy, i.e. the ratio between a centrally
determined optimal solution maximizing the sum of weights selected by both play-

45

ers over the sum of weights derived by a selfish optimization of each player, can be
arbitrarily high.

3. Multi-Agent Knapsack

In this section, we consider the multi-agent problem in another scenario. Here,
weights wiA = 1 and wjB = 1 for all items i = 1, . . . , n(A), j = 1, . . . , n(B).
Therefore, given the capacity c ∈ Z+ , exactly c items fit into the knapsack. We
may view the game as a set of c rounds where, in each round, the two agents pick
one of their (unpacked) items and submit it for being packed in the knapsack. Only
one of the two agents items is packed (i.e. wins this round) and the item of the other
agent is discarded. At the end of the c rounds, each agent has a profit corresponding
to the total profit of its packed items. We assume the input list of available items
is public, but the submissions in each round occur simultaneously and in secret.
However most of the following results are sort of off-line centralized results.
Suppose agent A submits an item i and agent B an item j. Here, we consider
two possible rules for deciding which of the two submitted items wins and is packed
into the knapsack:
B
Rule 1: if pA
i > pj then A wins;
∗
B
Rule 2: if pA
i < pj then A wins.

A graph model is useful to represent this problem. Each agent’s item is associated to a node of a complete bipartite graph G = (A ∪ B, EA ∪˙ EB ). An arc (i, j)
belongs to EA or to EB depending on the rule, namely
B
A
B
Rule 1: (i, j), with profit pij = max{pA
i , pj }, belongs to EA if pi ≥ pj
(i.e. if A wins), otherwise it belongs to EB ;
B
A
B
Rule 2: (i, j), with profit pij = min{pA
i , pj }, belongs to EA if pi ≤ pj
(i.e. if A wins), otherwise it belongs to EB .

Any solution may be represented as a c-matching M on G, where the payoff of A
P
P
is pA (M) = ij∈M ∩EA pij and that of B is pB (M) = ij∈M ∩EB pij . Thus, determining a global optimum can be done in polynomial time by solving a weighted
cardinality assignment problem [2]. Note that matching problems on graphs with
edges partitioned into two sets are explicitly addressed in [6].
Obviously, in case of Rule 1 each agent will always submit its c most profitable
items. For this case we prove the following results.
• There is no preventive strategy for the agents, i.e. for any possible strategy one
∗

In case of a tie we assume that A always wins.

46

agent, say A, may choose, it cannot attain more than its worst solution since
B can always maximize its own payoff (thus minimizing A’s payoff).
• There are at most c efficient solutions (Pareto optimal solutions) that can be
computed in polynomial time. Each of these solutions corresponds to the fact
that agent A wins in x rounds, with 0 ≤ x ≤ c, and agent B wins the remaining c − x rounds.
• There exist no Nash equilibria, except for trivial instances where only one
Pareto optimum exists.
• The best-worst ratio, i.e. the ratio between the values of the global optimum
and the sum of the agents’ payoffs in any efficient solution, is no more than 2.
In case of Rule 2, when at each round the less profitable item wins, it is not
obvious for the agents how to select the c items to submit.
• Also in this case, there is no preventive strategy for an agent and no Nash
equilibria exist (except for trivial instances).
• However, differently from Rule 1, given an integer x, with 0 ≤ x ≤ c, exponentially many Pareto optimal solutions may exist such that the number of
winning rounds for agent A is equal to x.
• Given two arbitrary values QA and QB , it is NP-complete to find a solution
M such that pA (M) ≥ QA and pB (M) ≥ QB .
• Under Rule 2, the best-worst ratio, as defined above, can be arbitrarily high.
References
[1] G. Aggarwal, J. D. Hartline. Knapsack auctions, Proceedings of the 17th annual ACM-SIAM Symposium on Discrete Algorithm, pp. 1083–1092, 2006.
[2] M. Dell’Amico, S. Martello. The k-cardinality assignment problem, Discrete
Applied Mathematics, 76, pp. 103–121, 1997.
[3] M. Fujimoto, T. Yamada. An exact algorithm for the knapsack sharing problem with common items, European Journal of Operational Research, 171(2),
pp. 693–707, 2006.
[4] M. Hifi, H. M’Hallab, S. Sadfi. An exact algorithm for the knapsack sharing
problem, Computers & Operations Research, 32(5), pp. 1311–1324, 2005.
[5] V. Liberatore. Scheduling Jobs Before Shut Down, Lecture Notes in Computer
Science, 1851, Algorithm Theory - SWAT 2000, pp. 461–466, Springer, 2000.
[6] C. Nomikos, A. Pagourtzis, S. Zachos. Randomized and Approximation Algorithms for Blue-Red Matching. Lecture Notes in Computer Science 4708,
pp. 715–725, Springer, 2007.

47

An exact method for the minimum caterpillar
spanning problem
L. Simonetti, a Y. Frota, a C.C. de Souza a,??
a Universidade

Federal de Campinas, UNICAMP, Instituto de Computação, Caixa Postal
6176, 13084-971, Campinas, SP, Brazil, {luidi,yuri,cid}@ic.unicamp.br

Key words: caterpillar trees, combinatorial optimization, integer programming

Introduction. Let G = (V, E) be an undirected graph where V = {v1 , · · · , vn } is
the vertex set and E is the edge set. We assume that G is complete and associate to
each edge (i, j) the costs c1ij and c2ij . A tree T in G is said to be a caterpillar if the
subgraph remaining after removing all the leaves from T is a path. Vertices in this
path are called central. The Minimum Spanning Caterpillar Problem (MSCP) consists in finding a caterpillar containing all the vertices of G whose cost is minimal.
The cost of an edge (i, j) in the caterpillar is c2ij if both its extremities are central
vertices and c1ij otherwise.
MSCP is N P-hard [10] and applications of it are found in simplifications of
complex real-world situations which, when considered in their full extent, are very
difficult to deal with (e.g., [1], [8]). This includes problems arising in vehicle routing in hierarchical logistics, telecommunication networks design and fiber optics
networks [2]. Not too much attention has been given to algorithms for the MSCP
and, to our knowledge, no exact methods are available. However, the minimum
ring-star problem (MRSP) is closely related to the MSCP and was investigated earlier(see [11; 7]). In fact, it can be shown that any algorithm that solves the MSCP
also computes the MRSP and vice-versa. The relationship between the two problems is equivalent to the one existing between Hamiltonian paths ant the traveling
salesman problems.

In [5] good results were achieved by adapting an integer programming (IP)
formulation for the minimum Steiner arborescence problem (MSAP) to a class of
1

First author is supported by grant # 2008/01497-8 from Fundação de Amparo à Pesquisa
do Estado de São Paulo, Brazil. Second author is supported by a scholarship from CAPES
(Brazilian Ministry of Education). Third author is partially supported by Conselho Nacional de Desenvolvimento Cientı́fico e Tecnológico , Brazil, grants # 301732/2007-8 and
# 472504/2007-0.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

problems involving the computation of optimal trees in graphs. In the MSAP we
are given a directed graph with costs associated to the edges, a special vertex r
and a set R of terminal vertices. The goal is to find a minimum cost arborescence
rooted at r and spanning all vertices in R. In this paper a similar idea is used to
reduce the MSCP to the MSAP in a layered graph. This reduction is the basis for
the development of an efficient branch-and-cut algorithm for the MSCP. In the sequel we formulate the problem as a Steiner problem and report on our numerical
experiments.
IP model. We start by reducing the MSCP to the MSAP. To this end, we build a
directed graph GN = (VN , AN ) from the graph G = (V, E) given at the input for
the MSCP. The graph GN has three layers numbered 0, 1 and 2. The first one is
composed solely by the special vertex 0. Now, for every vertex i ∈ V , two vertices
are created in VN , namely, the vertex i1 and the vertex i2 in the second and third
layers, respectively. To each edge (i, j) in E, two arcs (i1 , j1 ) and (j1 , i1 ) are created
in AN . The remaining arcs of AN are of the form (i1 , i2 ) and (0, i1 ), for all i ∈ V ,
and (i1 , j2 ), for all (i, j) ∈ E. As it can be seen, most of the arcs in GN go from
layer h to layer h + 1, h ∈ {0, 1}. As an abuse of language, we refer to GN as a
layered graph although the subgraph induced by the vertices in layer 1 is a complete
digraph.
We mean to use the arcs with both extremities in layer 1 to identify the central
vertices. Besides, the arcs from layer 1 to layer 2 are meant to identify the edges of
E joining a central vertex to a leaf of the caterpillar. Therefore, the costs of the arcs
in AN are computed as follows. For every vertex i ∈ V , the costs of arcs (0, i1 ) and
(i1 , i2 ) are given by M and 0, respectively. The value of M is chosen to be large
enough to ensure that any optimal solution for the MSAP defined over GN contains
exactly one arc leaving vertex 0. Now, given two distinct vertices i and j in V , the
cost of the arc (i1 , j2 ) is set to c1ij while the costs of the arcs (i1 , j1 ) and (j1 , i1 ) are
both set to c2ij .
To cast the MSCP as an MSAP we have to define the root vertex and the set R of
terminals. This is done by assigning vertex 0 to the root and all the vertices of VN in
layer 2 to the set R. In addition, side constraints are created requiring that at most
one arc leaves a vertex in layer 1 to reach another vertex in this layer. Notice that
these constraints are not present in the classical MSAP. Moreover, recall that, the
high costs attributed to the arcs emanating from the root forces any optimal solution
to have precisely one such arc. Together with the side constraints, this guarantees
that the subgraph induced by the vertices of layer 1 in an optimal solution is a path.
We now turn our attention to the development of an IP model for the MSAP.
Initially, we define the binary variables xuv for each arc (u, v) ∈ AN and set it
to one if and only if (u, v) belongs to the optimal Steiner arborescence. Then, the

49

MSAP

for the graph GN derived from G is formulated by the IP below:
P

(StM) min (u,v)∈AN cuv xuv
P
s. t.
j∈V −{i} xi1 j1 ≤ 1,
P
P
u∈VN \S
v∈S xuv ≥ 1,
xi1 j1 ∈ {0, 1}, xi1j2 ≥ 0,
x0j1 ≥ 0, xj1 j2 ≥ 0,

∀i∈V
∀ S ⊂ VN \{0}, S ∩ R 6= {∅}
∀ i 6= j, (i, j) ∈ E
∀j ∈V

(0.1)
(0.2)

Constraints (0.1) forces the creation of a path joining the central vertices (those in
layer 1). Constraints (0.2) are the Steiner cuts which ensure that the terminal vertices are spanned. Notice that in this formulation some of the integrality constraints
have been relaxed. One can show that they are satisfied as long as we impose the
integrality of the variables for arcs that are internal to layer 1. Besides the Steiner
cuts in (0.2), our branch-and-cut algorithm also uses the 2-matching constraints
discussed in [3] and given in Theorem 1 below.
Theorem 1. For H ⊂ V and T ⊂ δ(H), inequality (0.3) is valid for conv(StM)
if (i) {i, j} ∩ {k, w} = ∅, ∀(i, j) and (k, w) ∈ T ; and (ii) |T | ≥ 3 and odd.
X

i∈H,j∈H,(i,j)∈E

xi1 j1 +

X

(i,j)∈T

xi1 j1 ≤

X

i∈H

xi1 i2 +

|T | − 1
.
2

(0.3)

Computational experiments. The StM model is the starting point for the development of our branch-and-cut algorithm. The code is implemented in C++ and
uses XPRESS 2008 as the IP solver. All tests were carried out on an Intel Core2
Quad processor with 2.83GHz and 8Gb of RAM. A fast polynomial-time algorithm
based on the minimum edge cut problem in graphs is used to separate the Steiner
cuts (0.2). Moreover, the heuristic proposed in [4] was implemented to compute
violated 2-matching inequalities from Theorem 1.
To test the algorithm, we modified 24 instances from TSPLIB 2.1 [9] with sizes
ranging from 26 to 299 vertices. The edge costs were adapted from the original TSP
instances through the following calculations. Let cij be the distance between vertices i and j in the TSP instance. The two costs assigned to edge (i, j) in the MSCP
instance are given by: c1ij = d(10 − α)cij e and c2ij = dαcij e for α ∈ {3, 5, 7, 9}.
Since each TSP instance give rise to four MSCP instances, one for each value of α,
in total, our benchmark is composed of 96 instances. Notice that, for higher values
of α, the optimal solutions is expected to have many leaves while, for lower values,
most vertices are likely to be central.
The experimental results are summarized in Table 1. The relative gaps displayed are computed by (UB − LB )/LB, where UB and LB denote, respectively, the
best upper and lower bounds achieved. The number of nodes explored during the
enumeration and the total time spent to solve the instances are shown too. The data
are also gathered by different values of α and instance sizes.

50

All

gap (%)

α=3

α=5

α=7

α=9

|V | < 100

|V | < 200

|V | < 300

Avr

Max

Avr

Max

Avr

Max

Avr

Max

Avr

Max

Avr

Max

Avr

Max

Avr

0.11

0.85

0.31

0.32

0.10

0.33

0.04

0.03

0.00

0.33

0.05

0.85

0.15

0.41

0.08

nodes

90.9

1483

345.4

745

43.5

13

2.6

1

1

39

3.7

1483

120.6

1433

185.8

time(s)

1008

25893

1616

25387

1532

7025

369

8810

529

22

2.5

1602

132

25893

6564

Table 1. Summary of computational results.

The results revealed that our algorithm is capable to solve to optimality MSCP
instances with up to 300 nodes in reasonable time. All those with at most 200
vertices were computed is less than 30 minutes. The linear relaxation at the root
node contributes for this success, providing very dual bounds in all cases. As a
matter of fact, 42 instances were solved at the root node. The strength of the linear
relaxations can also be assessed by the small number of nodes explored by the
enumeration. One can see that the algorithm performs better for larger values of α,
when more vertices are expected to be leaves.
References
[1] G. S. Adhar. Optimum interval routing in k-caterpillars and maximal outer planar
networks. In Applied Informatics, pages 692–696, 2003.
[2] R. Baldacci, M. Dell’Amico and J.J. Salazar. The Capacitated m-Ring Star Problem.
Operations Research, 55:1147–1162, 2007.
[3] P. Bauer. The circuit polytope: Facets. Oper Res, 22:110-145, 1997.
[4] M. Fischetti, J.J. Salazar and P. Toth. A branch-and-cut algorithm for the symmetric
generalized traveling salesman problem. Oper Res, 45:378-394, 1997.
[5] L. Gouveia, L. Simonetti and E. Uchoa. Modelling the hop-constrained minimum
spanning tree problem over a layered graph. In International Network Optimization
Conference, 2007.
[6] E. A. Hoshino and C. C. de Souza. Column Generation Algorithms for the Capacitated m-Ring-Star Problem. Lecture Notes in Computer Science, vol. 5092, pages
631–641, 2008.
[7] M. Labbé, G. Laporte, I.R. Martı́n and J.S. González. The Ring Star Problem: Polyhedral Analysis and Exact Algorithm. Networks, 43:177–189, 2004.
[8] A. Proskurowski and J. A. Telle. Classes of graphs with restricted interval models.
Disc. Math. and Theoretical Computer Science, 3(4):167–176, 1999.
[9] G. Reinelt. A traveling salesman problem library. ORSA J Comp, 3:376–384, 1991.
[10] J. Tan and L. Zhang. Approximation Algorithms for the Consecutive Ones Submatrix
Problem on Sparse Matrices. Lecture Notes in Computer Science, vol. 3341, pages
835–846, 2004.
[11] J. Xu, S.Y. Chiu and F. Glover. Optimizing a ring-based private line telecommunication network using tabu search. Manag Sci, 45:330–345, 1999.

51

Coloring I

Lecture Hall B

Tue 2, 10:30–12:30

NP-completeness of determining the total chromatic
number of graphs that do not contain a cycle with a
unique chord
Raphael Machado, a,b Celina de Figueiredo a
a COPPE
b Instituto

- Universidade Federal do Rio de Janeiro

Nacional de Metrologia, Normalização e Qualidade Industrial

Abstract
The total chromatic number of a graph is the least number of colours sufficient to colour
the elements (vertices and edges) of this graph in such a way that no incident or adjacent
elements are coloured the same. The class C of graphs that do not contain a cycle with
a unique chord was recently studied by Trotignon and Vušković [5], who proved strong
structure results for these graphs. In the same work, the authors determine, for the class
C, the complexity of vertex-colouring problem (polynomial), maximum clique problem
(polynomial) and maximum stable set problem (NP-complete). The edge-colouring problem is NP-complete [3] when restricted to C. In the present work, we show that also the
total-colouring problem is NP-complete when restricted to C.
Key words: total chromatic number, cycle with a unique chord, regular graphs

1. Introduction
Let G = (V, E) be a simple graph. The maximum degree of a vertex in G is
denoted ∆(G). A total-colouring of G is a function π : V ∪E → C such that no two
incident or adjacent elements receive the same colour c ∈ C. If C = {1, 2, ..., k},
we say that π is a k-total-colouring. The total chromatic number of G, denoted
by χT (G), is the least k for which G has a k-total-colouring. The Total Colouring
Conjecture [1; 6], which states that every graph G is (∆(G) + 2)-total colourable,
is open since 1964.
The class C of graphs that do not contain a cycle with a unique chord was first
investigated by Trotignon and Vušković [5], who proved strong structure results for
these graphs. Class C is of interest also because it is an example of a χ-bounded
class, that is, there exists a function f : N → N such that, for each G ∈ C, χ(G) ≤
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

f (ω(G)), where χ(G) is the (vertex-) chromatic number of G and ω(G) is the
clique-number of G. In the present work, we prove that the total-colouring problem
restricted to C is NP-complete. Additionally, we propose the study of the Total
Colouring Conjecture restricted to graphs in C.
2. NP-completeness result

The term TOTCHR(P ) (resp. CHRIND(P )) denotes the problem of determining the total chromatic number (resp. chromatic index) restricted to graph inputs
with property P . For example, TOTCHR(graph of C) (resp. CHRIND(graph of C))
denotes the problem whose instance is a graph G of C and that questions whether
χT (G) = ∆(G)+1 (resp. χ0 (G) = ∆(G)). The problem TOTCHR(∆-regular bipartite graph) is NP-complete [4] for each ∆ ≥ 3. The problem CHRIND(∆-regular
graph) is NP-complete [2] for each ∆ ≥ 3.
The NP-completeness gadget used in [4] has cycles with unique chords. The
goal of our proposed NP-completeness proof is to modify the gadget used in [4]
in order to have a gadget in C. The proposed modification leads to a non-regular
gadget. In order to obtain an NP-completeness result for regular graphs, we present,
in Theorem 2 a novel technique based on an induction on the minimum degree of a
graph.
Graph St , t ≥ 3, is used in the present work exactly as defined in [4]: St is
obtained from the complete bipartite graph Kt−1,t by adding t pendant edges to the
t vertices of degree t − 1. We generalize the graph Ht of [4] by defining graph Hn,t ,
t > n ≥ 1: H2,t = Ht , and, more generaly, Hn,t is constructed by putting together
two copies of St and identifying t − n pendant edges of the first copy with t − n
edges of the second copy. (See St and Hn,t in Figure 1 at Appendix A.)
The original “replacement” graph R of [4] contains cycles with unique chords.
We modify and extend R to a family Rt , t ≥ 3, of “replacement” graphs in C.
Take t + 1 copies of Hn,t, with n = d(t + 1)/2e, and denote these copies by
H (1) , H (2) , ..., H (t+1) . The “replacement” graph Rt is such that each copy of Hn,t
in Rt has one pendant edge – which is called real – or two pendant edges – one of
which is called real. For, identify each of t pendant vertices of H (i) , i = 1, 2, ..., t +
1, with a distinct H (j), j 6= i, by choosing one of the pendant vertices of H (j) (see
R3 and R4 in Figure 2 at Appendix A).
Lemma 1. Let π be a partial (t + 1)-total-colouring of Rt , t ≥ 3, in which the t + 1
real pendant edges have different colours and the pendant vertices of the t + 1 real
pendant edges are also coloured (and nothing else is coloured). Then π extends to
a (t + 1)-total-colouring of Rt Moreover, in any (t + 1)-total-colouring of Rt the
t + 1 real pendant edges have all different colours.

56

The “forcer” graph Fn,t , t > n ≥ 2, is used exactly as in [4]. Graph Fn,t is
constructed by linking n copies of the graph H2,t (see Figure 3 at Appendix A).
Lemma 2. (McDiarmid and Sánchez-Arroyo [4]) Let π be a partial (t + 1)-totalcolouring of Fn,t , t > n ≥ 2, in which the pendant edges have the same colour
and the pendant vertices are also coloured (and nothing else is coloured). Then π
extends to a (t + 1)-total-colouring of Fn,t . Moreover, in any (t + 1)-total-colouring
of Fn,t the pendant edges have all the same colour.
Theorem 2 proves the NP-completeness of total-colouring ∆-regular graphs
that do not contain a cycle with a unique chord, for each fixed degree ∆ ≥ 3. Before
proving Theorem 2 for regular graphs, we prove a weaker result: Lemma 3 proves
the NP-completeness of problem P∆,δ =TOTCHR(graph in C with maximum degree
∆, minimum degree ≥ δ, and such that every edge is incident to a maximum-degree
vertex) for δ = 1. Theorem 2 obtains a regular graph based on a novel strategy of
induction on the minimum degree.
Lemma 3. For each ∆ ≥ 3, P∆,1 is NP-complete.
Proof (Sketch). Let G be an instance of the NP-complete problem CHRIND
(∆-regular graph). We construct an instance G0 of problem P∆,1 satisfying that G0
is (∆ + 1)-total-colourable if and only if G is ∆-edge-colourable. The construction
of graph G0 is carried out with the following procedure (see Figure 4 at Appendix A
for an example where G = K4 ). Construct a graph L by replacing each vertex v of
G with a copy of R∆ . Two different copies of the “replacement” graph have pendant
edges identified according to the adjacencies in the original graph G. Observe that
L has |V (G)| pendant edges if ∆ is odd – each of them is real – and (∆ + 2)|V (G)|
pendant edges if ∆ is even – |V (G)| of which are real and (∆ + 1)|V (G)| of which
are not real. Construct G0 by identifying the |V (G)| real pendant edges of L with
|V (G)| pendant edges of a forcer graph Fd|V (G)|/2e,∆ . 
Theorem 2. For each ∆ ≥ 3, TOTCHR(∆-regular graph in C) is NP-complete.
Proof (Sketch). By Lemma 3, the problem P∆,1 is NP-complete. Assume, as
induction hypothesis, that the problem P∆,k , k < ∆, is NP-complete. We prove
the theorem by induction on k. Let G be an instance of the problem P∆,k and construct an instance G0 of problem P∆,k+1 as follows. Let G1 and G2 be two graphs
isomorphic to G. Let H1 , ..., Hx be as many graphs isomorphic to H1,∆ as there
are degree-k vertices in G. We prove that there is a (∆ + 1)-total-colouring of H1,∆
such that its two pendant vertices receive the same colour and its two pendant edges
receive the same colour. Denote the degree-k vertices of G1 (resp. G2 ) by v1 , ..., vx
(resp. by w1 , ..., wx ). Construct G0 by taking graphs G1 and G2 and, for each Hi ,
identifying one pendant vertex with vi and the other pendant vertex with wi . Graph
G0 belongs to C, has maximum degree ∆, minimum degree ≥ k + 1, and every edge
is incident to a maximum-degree vertex. Moreover, G0 is (∆ + 1)-total-colourable
if and only if G is (∆ + 1)-total-colourable. So, P∆,k+1 is NP-complete and the
57

theorem follows by induction. 
Remark our proposed inductive strategy is not used in [4]. The gadgets constructed in [4] are regular, while the proposed gadgets in C are not.
3. Final remarks and current work
We consider the total-colouring problem restricted to C. We propose an inductive strategy for NP-completeness proofs that may be applied to general regular
graphs. At the moment we investigate two additional problems on total-colouring.
First, we investigate whether it is possible to extend the NP-completeness proof
of the present work to bipartite graphs that do not contain a cycle with a unique
chord. Second, we investigate the validity of the Total Colouring Conjecture in C:
the upper bound χT (G) ≤ ∆(G) + 4 follows from the results of [5].
References
[1] M. Behzad. Graphs and their chromatic numbers. Ph.D. Thesis. Michigan
State University (1965).
[2] D. Leven and Z. Galil. NP-completeness of finding the chromatic index of
regular graphs. J. Algorithms 4 (1983) 35–44.
[3] R. C. S. Machado, C. M. H. de Figueiredo, and K. Vušković. Edge-colouring
graphs with no cycle with a unique chord. Proc. of Alio/Euro Workshop
(2008).
[4] C. J. H. McDiarmid, A. Sánchez-Arroyo. Total colouring regular bipartite
graphs is NP-hard. Discrete Math. 124 (1994) 155-162.
[5] N. Trotignon and K. Vušković. A structure theorem for graphs with no cycle
with a unique chord and its consequences. To appear in J. Graph Theory.
[6] V. G. Vizing. On an estimate of the chromatic class of a p-graph. Metody
Diskret. Analiz. 3 (1964) 25–30. In Russian.

58

Figures

Fig. 1. Graphs St (left) and Hn,t (right).

Fig. 2. Graphs R3 (left) and R4 (right).

Fig. 3. The forcer graph and its schematic representation.

Fig. 4. Construction of G0 for the proof or Lemma 3, in the case where G = K4 .

59

Acyclic and frugal colourings of graphs
Ross J. Kang, a,1 Tobias Müller b
a School
b School

of Computer Science, McGill University, 3480 University Street, Montréal,
Québec, H2A 2A7, Canada.

of Mathematical Sciences, Sackler Faculty of Exact Sciences, Tel Aviv University,
Tel Aviv 69978, Israel.

Key words: graph colouring, frugal, acyclic, improper

1. Introduction
In this paper, a (vertex) colouring of a graph G = (V, E) is any map f :
V → Z+ . The colour classes of a colouring f are the preimages f −1 (i), i ∈ Z+ .
A colouring of a graph is proper if adjacent vertices receive distinct colours; however, in this paper, we will devote considerable attention to colourings that are not
necessarily proper, but that satisfy another condition. A colouring of G is t-frugal
if no colour appears more than t times in any neighbourhood. The notion of frugal
colouring was introduced by Hind, Molloy and Reed [5]. They considered proper
t-frugal colourings as a way to improve bounds related to the Total Colouring Conjecture (cf. [6]). In Section 2, we study t-frugal colourings for graphs of bounded
maximum degree.
In Section 3, we impose an additional condition that is well-studied in the
graph colouring literature (cf. [3]). A colouring of V is acyclic if each of the bipartite graphs consisting of the edges between any two colour classes is acyclic. In
other words, a colouring of G is acyclic if G contains no alternating cycle (that is,
an even cycle that alternates between two distinct colours). For graphs of bounded
maximum degree, the study of acyclic proper colourings was instigated by Erdős
(cf. [2]) and more or less settled asymptotically by Alon, McDiarmid and Reed [3].
Extending the work of Alon et al., Yuster [9] investigated acyclic proper 2-frugal
colourings. In Section 3, we expand this study to different values of t and colourings that are not necessarily proper.
1

Part of this research was done while this author was a doctoral student at Oxford University. He was partially supported by NSERC of Canada and the Commonwealth Scholarship
Commission in the UK.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Let us outline our notation. As usual, the chromatic number χ(G) (resp. acyclic
chromatic number χa (G)) denotes the least number of colours needed in a proper
(resp. acyclic proper) colouring. Analogously, for t ≥ 1, we define the t-frugal
chromatic number ϕt (G), proper t-frugal chromatic number χtϕ (G), acyclic tfrugal chromatic number ϕta (G) and acyclic proper t-frugal chromatic number
χtϕ,a (G). We have designated ϕ as a mnemonic for frugal. We are interested in
graphs G of bounded degree, so let χ(d) denote the maximum possible value of
χ(G) over all graphs G with ∆(G) = d. We analogously define χa (d); ϕt (d),
χtϕ (d), ϕta (d) and χtϕ,a (d) for t ≥ 1. The square of a graph G, i.e. the graph formed
from G by adding edges between any two vertices at distance two, is denoted G2 .
Note the following basic observations.
Proposition 1. For any graph G and any t ≥ 1, the following hold:
(i) χ1ϕ (G) = χ1ϕ,a (G) = χ(G2 );
(ii) ϕt (G) ≤ χtϕ (G), ϕta (G) ≤ χtϕ,a (G); ϕt (G) ≤ ϕta (G), χtϕ (G) ≤ χtϕ,a (G);
t
t+1
t
t+1
t
(iii) ϕt+1 (G) ≤ ϕt (G), χt+1
ϕ (G) ≤ χϕ (G), ϕa (G) ≤ ϕa (G), χϕ,a (G) ≤ χϕ,a (G);
and
(iv) ϕt (G) ≥ ∆(G)/t.
We may invoke basic probabilistic tools such as the Lovász Local Lemma,
details of which can be found in various references, e.g. Molloy and Reed [7].

2. Frugal colourings

As a way to improve bounds for total colouring (cf. [6]), Hind et al. [5], showed
d)5
that χ(ln
(d) ≤ d + 1 for sufficiently large d. Recently, this was improved.
ϕ
ln d/ ln ln d
Theorem 1. (Molloy and Reed [8]) χ50
(d) ≤ d + 1 for sufficiently large
ϕ
d.

Since χtϕ (Kd+1 ) ≥ d + 1, it follows that χtϕ (d) = d + 1 for t = t(d) ≥
50 ln d/ ln ln d. For smaller frugalities, Hind et al. [5] also showed the following.
Theorem 2. (Hind et al. [5]) For any t ≥ 1 and sufficiently large d, χtϕ (d) ≤
n
l
mo
max (t + 1)d, e3 d1+1/t /t .
By Proposition 1(i), χ1ϕ (d) ∼ d2 . We note that an example based on projective
geometries due to Alon (cf. [5]), to lower bound χtϕ (d), is also valid for ϕt (d).
Proposition 2. For any t ≥ 1 and any prime power n, ϕt (nt + · · · + 1) ≥ (nt+1 +
· · · + 1)/t.

61

The following consequence shows (by Proposition 1(ii)) that Theorem 2 is
asymptotically tight up to a constant multiple when t = o(ln d/ ln ln d).
Corollary 1. Suppose that t = t(d) ≥ 2, t = o(ln d/ ln ln d), and  > 0 fixed.
Then, for sufficiently large d, ϕt (d) ≥ (1 − )d1+1/t /t.
Theorems 1 and 2 determine the behaviour of χtϕ (d) up to a constant multiple
for all t except for the range such that t = Ω(ln d/ ln ln d) and t ≤ 50 ln d/ ln ln d.
Recall from Proposition 1(iv) that ϕt (d) ≥ d/t. For the case t = ω(ln d), we give a
tight upper bound for ϕt (d).
Theorem 3. Suppose t = ω(ln d) and  > 0 fixed. Then, for sufficiently large d,
ϕt (d) ≤ d(1 + )d/te .
proof 1. Let G = (V, E) be a graph with maximum degree d and let x = d(1 + )d/te.
Let f be a random colouring where for each v ∈ V , f (v) is chosen uniformly
and independently at random from {1, . . . , x}. For a vertex v and a colour i ∈
{1, . . . , x}, let Av,i be the event that v has more than t neighbours with colour i. If
none of these events hold, then f is t-frugal. Each event is independent of all but at
most d2 x  d3 others. By a Chernoff bound,
Pr (Av,i ) = Pr (BIN(d, 1/x) > t) ≤ Pr (BIN(d, 1/x) > d/x + ct)




≤ exp −c2 t2 /(2d/x + 2ct/3)

where c = /(1 + ). Thus, e Pr (Av,i ) (d3 + 1) = exp(−Ω(t))d3 < 1 for large
enough d, and by the Lovász Local Lemma, f is t-frugal with positive probability
for large enough d.

3. Acyclic frugal colourings
Using the Lovász Local Lemma, Alon et al. [3] established a o(d2 ) upper
bound for χa (d), answering a long-standing question of Erdős (cf. [2]). Using a
probabilistic construction, they also showed this upper bound to be asymptotically
correct up to a logarithmic multiple.
Theorem 4. (Alon et al. [3]) χa (d) ≤ d50d4/3 e, χa (d) = Ω(d4/3 /(ln d)1/3 ).
Yuster [9] considered acyclic proper 2-frugal colourings of graphs and showed
that χ2ϕ,a (d) ≤ dmax{50d4/3 , 10d3/2 }e. For acyclic frugal colourings, we first consider the smallest cases then proceed to larger values of t. For t = 1, 2, 3, notice
that Corollary 1, Proposition 1(i) and Yuster’s result imply that ϕ1a (d) = Θ(d2 ),
ϕ2a (d) = Θ(d3/2 ), χ2ϕ,a (d) = Θ(d3/2 ) and ϕ3a (d) = Ω(d4/3 ). Next, we show that
χ3ϕ,a (d) = O(d4/3 ). This implies that χtϕ,a (d) = O(d4/3 ) for any t ≥ 3, a bound that
62

is within a logarithmic multiple of the lower bound implied by Theorem 4. This
answers a question of Esperet, Montassier and Raspaud [4].
Theorem 5. χ3ϕ,a (d) ≤ d40.27d4/3 e.
proof 2. (Outline.) Our proof is an extension of the proof of Theorem 4 in which
we add a fifth event to ensure that the random colouring f is 3-frugal:
V For vertices v, v1 , v2 , v3 , v4 with {v1 , v2 , v3 , v4 } ⊆ N(v), let E{v1 ,...,v4 } be the
event that f (v1 ) = f (v2 ) = f (v3 ) = f (v4 ).
For acyclic frugal colourings which are not necessarily proper, for larger values
of t, we have adapted a result of Addario-Berry et al. [1] to show the following.
Theorem 6. For any t = t(d) ≥ 1, ϕta (d) = O(d ln d + (d − t)d).
d−1
This implies, for instance, that ϕd−1
a (d) and χϕ,a (d) differ by a multiplicative
factor of order at least d1/3 /(ln d)4/3 . The result is obtained by studying total kdominating sets — given G = (V, E), D ⊂ V is total k-dominating if each vertex
has at least k neighbours in D.

References
[1] Addario-Berry, L., Esperet, L., Kang, R. J., McDiarmid, C. J. H., and Pinlou,
A. Acyclic t-improper colourings of graphs with bounded maximum degree,
2009+. To appear in Discrete Mathematics.
[2] Albertson, M. O. and Berman, D. M. The acyclic chromatic number, Proceedings of the Seventh Southeastern Conference on Combinatorics, Graph Theory,
and Computing (Louisiana State Univ., Baton Rouge, La., 1976), 1976, pages
51–69.
[3] Alon, N., McDiarmid, C. J. H., and Reed, B. Acyclic coloring of graphs. Random Structures and Algorithms, 2 (1991), no. 3, pages 277–288.
[4] Esperet, L., Montassier, M., and Raspaud, A. Linear choosability of graphs.
Discrete Math., 308 (2008), no. 17, pages 3938–3950.
[5] Hind, H., Molloy, M., and Reed, B. Colouring a graph frugally. Combinatorica,
17 (1997), no. 4, pages 469–482.
[6] Hind, H., Molloy, M., and Reed, B. Total coloring with ∆+poly(log ∆) colors.
SIAM J. Comput., 28 (1999), no. 3, pages 816–821 (electronic).
[7] Molloy, M. and Reed, B. Graph Colouring and the Probabilistic Method. Algorithms and Combinatorics, 23, Springer-Verlag, Berlin, 2002.
[8] Molloy, M. and Reed, B. Asymptotically optimal frugal colouring. SODA ’09:
Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete
Algorithms, 2009, pages 106–114.
[9] Yuster, R. Linear coloring of graphs. Discrete Math., 185 (1998), no. 1-3, pages
293–297.

63

On resistance of graphs
P.A. Petrosyan, a,b H.E. Sargsyan b
a Institute

for Informatics and Automation Problems of NAS of RA
pet petros@{ipia.sci.am, ysu.am, yahoo.com}
b Department

of Informatics and Applied Mathematics,YSU
sargsyanhasmik@gmail.com

Key words: edge coloring, interval coloring, resistance of a graph

1. Introduction

The graph coloring problems play a crucial role in Discrete Mathematics. The
reason for that is the fact of existence of many problems in Discrete Mathematics which can be formulated as graph coloring problems (factorization problems,
problems of Ramsey theory, etc.), the tight relationship between graph coloring
problems and scheduling of various timetables. For example, the problem of constructing an optimal schedule for an examination session can be reduced to the
problem of finding the chromatic number of a graph. On the other hand, the sport
scheduling problems can be reduced to the problem of finding the chromatic index
of a graph, etc..
One of the aspects of the problems of scheduling theory is the construction
of timetables without “gaps”. For studying the coloring problems corresponding to
ones of constructing a timetable without a “gap”, a definition of an interval coloring of a graph was introduced [1]. Many bipartite graphs such as regular bipartite graphs [1; 2], trees, complete bipartite graphs [11], subcubic bipartite graphs
[8], doubly convex bipartite graphs [3], grids [5], outerplanar bipartite graphs [7],
(2, ∆) −biregular bipartite graphs [9; 13; 15] and some classes of (3, 4) −biregular
bipartite graphs [4; 16] have interval colorings. Unfortunately, it is known that not
all graphs have interval colorings, therefore, it is expedient to consider a measure
of closeness for a graph to be interval colorable. First attempt to introduce such a
measure was done in [6]. The deficiency [6] of a graph is the minimum number
of pendant edges whose attachment to the graph makes the resulting graph interval
colorable.
In this work we introduce a new measure of closeness for a graph to be interval

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

colorable. We call it a resistance. More precisely, the resistance of a graph is the
minimum number of edges that should be removed from a given graph to obtain an
interval colorable graph.

2. Main results

All graphs considered in this work are finite, undirected and have no loops
or multiple edges. Let V (G) and E(G) denote the sets of vertices and edges of
G, respectively. An edge coloring of a graph G with colors 1, 2, . . . , t is called an
interval t−coloring if at least one edge of G is colored by i, i = 1, 2, . . . , t, the
colors of edges incident to each vertex of G are distinct and form an interval of
integers. The set of all interval colorable graphs is denoted by N [1; 12].
We define the resistance of a graph G (res(G)) in the following way:
res(G) ≡ minG\F ∈N|F |.
Clearly, 0 ≤ res(G) ≤ |E(G)| − 1 for every graph G, and res(G) = 0 iff
G ∈ N.
First, we give some general facts on resistance of graphs.
Proposition 1. Let G be a connected graph with |V (G)| = p, |E(G)| = q.
Then
res(G) ≤ q − p + 1.
Proposition 2. Let G be an r−regular graph with an odd number of vertices.
Then
res(G) ≥ 2r .
Proposition 3. For any k ∈ N there is a graph G such that G ∈
/ N and
res(G) = k.
A.S. Asratian and R.R. Kamalian [1] proved that the problem “Does a given
regular graph is interval colorable or not?”is NP −complete. This immediantely
implies the following result:
Proposition 4. Let G be an r−regular (r ≥ 3) graph and k is a nonnegative
integer. Then the problem of deciding res(G) ≤ k is NP −complete.
In [18] S.V. Sevast’janov showed that it is an NP −complete problem to decide
whether a bipartite graph has an interval coloring. From here we have the following
result:
65

Proposition 5. Let G be a bipartite graph and k is a nonnegative integer. Then
the problem of deciding res(G) ≤ k is NP −complete.
Next, we determine the exact value of res(G) for simple cycles, wheels, complete graphs, Schwartz’s graphs [17] and we obtain upper bounds for res(G) in
case of complete balanced k−partite graphs [14] and Hertz’s graphs [10; 6].
Proposition 6. For any n ≥ 3



 0,

res(Cn ) =
Theorem 1. For any n ≥ 4
res(Wn ) =
Theorem 2. For any n ∈ N

if n is even,


 1,



 0,



if n is odd.

if n = 4, 7, 10,

1, otherwise.





0, if n is even,
res(Kn ) =  j k
 n , if n is odd.
2

Theorem 3. For any n, k ∈ N

(1) res(Kn,n,...,n ) = 0, if nk is even,
(2)

(k−1)n
2

≤ res(Kn,n,...,n ) ≤

(k−1)n2
,
2

if nk is odd.

Theorem 4. For any odd k ≥ 3
res(S(k)) = k − 1.
Theorem 5. For any p ≥ 4, q ≥ 3
(1) res(Hp,q ) = 0, if p ≤ b 2(q+1)
c
q−1
(2) res(Hp,q ) ≤ p − b 2(q+1)
c, if p > b 2(q+1)
c.
q−1
q−1
References
[1] A.S. Asratian, R.R. Kamalian, Interval colorings of edges of a multigraph,
Appl. Math. 5 (1987) 25-34 (in Russian).

66

[2] A.S. Asratian, R.R. Kamalian, Investigation on interval edge-colorings of
graphs, J. Combin. Theory Ser. B 62 (1994) 34-43.
[3] A.S. Asratian, T.M.J. Denley, R. Haggkvist, Bipartite Graphs and their Applications, Cambridge University Press, Cambridge, 1998.
[4] A.S. Asratian, C.J. Casselgren, J. Vandenbussche, D.B. West, Proper pathfactors and interval edge-coloring of (3, 4)-biregular bigraphs, Journal of
Graph Theory, 2009, to appear (arXiv:0704.2650v1, math.co, 2007).
[5] K. Giaro, M. Kubale, Consecutive edge-colorings of complete and incomplete
Cartesian products of graphs, Congr, Numer. 128 (1997) 143-149.
[6] K. Giaro, M. Kubale, M. Malafiejski, On the deficiency of bipartite graphs,
Discrete Appl. Math. 94 (1999) 193-203.
[7] K. Giaro, M. Kubale, Compact scheduling of zero-one time operations in
multi-stage systems, Discrete Appl. Math. 145 (2004) 95-103.
[8] H.M. Hansen, Scheduling with minimum waiting periods, Master’s Thesis,
Odense University, Odense, Denmark, 1992 (in Danish).
[9] D. Hanson, C.O.M. Loten, B. Toft, On interval colorings of bi-regular bipartite graphs, Ars Combin. 50 (1998) 23-32.
[10] A. Hertz, unpublished result, 1991.
[11] R.R. Kamalian, Interval colorings of complete bipartite graphs and trees,
preprint, Comp. Cen. of Acad. Sci. of Armenian SSR, Erevan, 1989 (in Russian).
[12] R.R. Kamalian, Interval edge colorings of graphs, Doctoral Thesis, Novosibirsk, 1990.
[13] R.R.Kamalian, A.N.Mirumian, Interval edge colorings of bipartite graphs of
some class, Dokl. NAN RA, 97 (1997) 3-5 (in Russian).
[14] R.R.Kamalian, P.A. Petrosyan, On interval colorings of complete k−partite
graphs Knk , Math. probl. of comp. sci. 25 (2006) 28-32.
[15] A.V. Kostochka, unpublished manuscript, 1995.
[16] A.V. Pyatkin, Interval coloring of (3, 4) −biregular bipartite graphs having
large cubic subgraphs, J. Graph Theory 47 (2004) 122-128.
[17] A. Schwartz, The deficiency of a regular graph, Discrete Math. 306 (2006)
1947-1954.
[18] S.V. Sevast’janov, Interval colorability of the edges of a bipartite graph,
Metody Diskret. Analiza 50 (1990) 61-72 (in Russian).

67

Colored Resource Allocation Games 1
Evangelos Bampas, a Aris Pagourtzis , a George Pierrakos , b
Vasileios Syrgkanis a
a National

Technical University of Athens, School of Elec. & Comp. Engineering
{ebamp,pagour}@cs.ntua.gr, syrganis@corelab.ntua.gr
b School

of Electrical Engineering & Computer Sciences, UC Berkeley
georgios@cs.berkeley.edu

Potential Games are a widely used tool for modeling network optimization
problems under a non-cooperative perspective. Initially studied in [18] with the
introduction of congestion games and further extended in [15] in a more general
framework, they have been successfully applied to describe selfish routing in communication networks (e.g. [19]). The advent of optical networks as the technology
of choice for surface communication has introduced new aspects of networks that
are not sufficiently captured by the models proposed so far. This work comes to
close this gap and presents a class of potential games useful for modeling selfish
routing and wavelength assignment in multifiber optical networks.
In optical networking it is highly desirable that all communication be carried
out transparently, that is, each signal should remain on the same wavelength from
source to destination. The need for efficient access to the optical bandwidth has
given rise to the study of several optimization problems in the past years. The most
well-studied among them is the problem of assigning a path and a color (wavelength) to each communication request in such a way that paths of the same color
are edge-disjoint and the number of colors used is minimized. Nonetheless, it has
become clear that the number of wavelengths in commercially available fibers is
rather limited—and will probably remain such in the foreseeable future. Therefore,
the use of multiple fibers has become inevitable in large scale networks. In the context of multifiber optical networks several optimization problems have been defined
and studied, the objective usually being to minimize either the maximum fiber multiplicity per edge or the sum of these maximum multiplicities over all edges of the
graph.
1

This work has been funded by the project PENED 2003. The project is cofinanced 75% of
public expenditure through EC–European Social Fund, 25% of public expenditure through
Ministry of Development–General Secretariat of Research and Technology of Greece and
through private sector, under measure 8.3 of Operational Programme “Competitiveness” in
the 3rd Community Support Programme.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Preliminaries. We introduce Colored Resource Allocation Games, a class of
games that can model non-cooperative versions of routing and wavelength assignment problems in multifiber all-optical networks. They can be viewed as an extension of congestion games where each player has his strategies in multiple copies
(colors). When restricted to (optical) network games, facilities correspond to edges
of the network and colors to wavelengths. The number of players using an edge
in the same color represents a lower bound on the number of fibers needed to implement the corresponding physical link. We consider both egalitarian (max) and
utilitarian (sum) player costs. For our purposes it suffices to restrict our study to
identity latency functions.
Definition 1. (Colored Resource Allocation Games) A Colored Resource Allocation Game is defined as a tuple hF, N, W, {Ei}i∈[N ] i, such that F is a set of facilities, N is the number of players, W is the number of colors, and Ei is a set of
possible facility combinations for player i. For any player i, Ei ⊆ 2F .
For any player i, the set of possible strategies is Si = Ei × [W ]. We denote
by Ai = (Ei , ci ) the strategy that player i actually chooses, where Ei ∈ Ei denotes
the set of facilities she chooses, and ci denotes her color. Furthermore, we use
the standard notation A = (A1 , . . . , AN ) for a strategy profile for the game, and
the notation nf,c (A) for the number of players that use facility f in color c in the
strategy profile A.
Definition 2. Depending on the player cost function we define two subclasses of
Colored Resource Allocation Games. Colored Congestion Games, with player cost
P
Ci (A) = e∈Ei ne,ci (A), and Colored Bottleneck Games, with player cost Ci (A) =
maxe∈Ei ne,ci (A).
We use the price of anarchy (PoA) introduced in [11] as a measure of the
deterioration caused by lack of coordination. We estimate the PoA of our games
under three different social cost functions. Two of them are standard in the literature (see e.g. [8]): the first (SC1 ) is equal to the maximum player cost and the
second (SC2 ) is equal to the sum of player costs (equivalently, the average player
cost). The third one is specially designed for the setting of multifiber all-optical
networks; it is equal to the sum over all facilities of the maximum color congestion
on each facility. Note that in the optical network setting this function represents the
total fiber cost needed to accommodate all players; hence, it captures the objective
of a well-studied optimization problem [17; 16; 1]. Let us also note that the SC1
function under the egalitarian player cost captures the objective of another well
known problem, namely minimizing the maximum fiber multiplicity over all edges
of the network (see e.g. [12]).
Related work. Bottleneck games have been studied in [7; 4; 9; 13]. In [7] the
authors study atomic routing games on networks, where each player chooses a path

69

Table 2. The pure price of anarchy of Colored Congestion Games (utilitarian player cost).
Results for classical congestion games are shown in the right column.

Colored Congestion Games
SC1 (A) = max Ci (A)

Θ

i∈[N ]

X

SC2 (A) =
X

max nf,a (A)

a∈[W ]

f ∈F

N
W

5
2

Ci (A)

i∈[N ]

SC3 (A) =

q

Θ



q

W |F |

Congestion Games
√ 
Θ N [8]
5
2



[8]
—

Table 3. The pure price of anarchy of Colored Bottleneck Games (egalitarian player cost).
Results for classical bottleneck games are shown in the right column.

Colored Bottleneck Games
SC1 (A) = max Ci (A)

Θ

i∈[N ]

SC2 (A) =

X

Θ

Ci (A)

i∈[N ]

SC3 (A) =

X

f ∈F




N
W
N
W




|EA | N
|EOPT | W

max nf,a (A)

a∈[W ]

Bottleneck Games
Θ(N) [7]
Θ(N) [7]
—

to route her traffic from an origin to a destination node, with the objective of minimizing the maximum congestion on any edge of her path. A further generalization
is the model of Banner and Orda [4], where they introduce the notion of bottleneck
games.
Selfish path coloring in single fiber all-optical networks has been studied in [6;
5; 10; 14]. Bilò and Moscardelli [6] consider the convergence to Nash Equilibria
of selfish routing and path coloring games. Bilò et al. [5] consider several information levels of local knowledge that players may have and give bounds for the
PoA in chains, rings and trees. The existence and complexity of computing Nash
equilibria under various payment functions are considered by Georgakopoulos et
al. [10]. In [14] they study the PoA of selfish routing and path coloring, under
functions that charge a player only according to her own strategy. Selfish path multicoloring games are introduced in [3] where it is proved that the pure price of anarchy is bounded by the number of available colors and by the length of the longest
path; constant bounds for the PoA in specific topologies are also provided. In those
games, in contrast to the ones studied here, routing is given in advance and players
choose only colors.
Our results. Our main contribution is the derivation of tight bounds on the
price of anarchy for Colored Resource Allocation Games. These bounds are summarized in Tables 2 and 3. It can be shown that the bounds for Colored Congestion

70

Games remain tight even for network games. Observe that known bounds for classical congestion and bottleneck games can be obtained from our results by simply
setting W = 1. On the other hand one might notice that our games can be casted
as classical congestion or bottleneck games with W |F | facilities. However, we are
able to derive better upper bounds for most cases by exploiting the special structure
of the players’ strategies. Finally, we provide a potential function for Colored Bottleneck Games in order to prove the existence and convergence to pure equilibria
and we show that the price of stability (as defined in [2]) is equal to 1.

References
[1] M. Andrews and L. Zhang. Minimizing maximum fiber requirement in optical
networks. J. Comput. Syst. Sci., 72(1): 118–131 (2006).
[2] E. Anshelevich, A. Dasgupta, J. Kleinberg, E. Tardos, T. Wexler, and
T. Roughgarden. The price of stability for network design with fair cost allocation. FOCS 2004, 295–304.
[3] E. Bampas, A. Pagourtzis, G. Pierrakos, and K. Potika. On a non-cooperative
model for wavelength assignment in multifiber optical networks. ISAAC
2008, 159–170.
[4] R. Banner and A. Orda. Bottleneck routing games in communication networks. INFOCOM 2006.
[5] V. Bilò, M. Flammini, and L. Moscardelli. On Nash equilibria in noncooperative all-optical networks. STACS 2005, 448–459.
[6] V. Bilò and L. Moscardelli. The price of anarchy in all-optical networks.
SIROCCO 2004, 13–22.
[7] C. Busch and M. Magdon-Ismail. Atomic routing games on maximum congestion. AAIM 2006, 79–91.
[8] G. Christodoulou and E. Koutsoupias. The price of anarchy of finite congestion games. STOC 2005, 67–73.
[9] D. Fotakis, S. Kontogiannis, E. Koutsoupias, M. Mavronicolas, and P. Spirakis. The structure and complexity of Nash equilibria for a selfish routing
game. ICALP 2002, 123–134.
[10] G.F. Georgakopoulos, D.J. Kavvadias, and L.G. Sioutis. Nash equilibria in
all-optical networks. WINE 2005, 1033–1045.
[11] E. Koutsoupias and C.H. Papadimitriou. Worst-case equilibria. STACS 1999,
404–413.
[12] G. Li and R. Simha. On the wavelength assignment problem in multifiber
WDM star and ring networks. IEEE/ACM Trans. Netw., 9(1): 60–68 (2001).
[13] L. Libman and A. Orda. Atomic resource sharing in noncooperative networks.
Telecommunication Systems, 17(4): 385–409 (2001).
[14] I. Milis, A. Pagourtzis, and K. Potika. Selfish routing and path coloring in

71

[15]
[16]

[17]
[18]
[19]

all-optical networks. CAAN 2007, 71–84.
D. Monderer and L.S. Shapley. Potential games. Games and Economic Behavior, 14: 124–143 (1996).
C. Nomikos, A. Pagourtzis, K. Potika, and S. Zachos. Routing and wavelength assignment in multifiber WDM networks with non-uniform fiber cost.
Computer Networks, 50(1): 1–14 (2006).
C. Nomikos, A. Pagourtzis, and S. Zachos. Routing and path multicoloring.
Inf. Process. Lett., 80(5): 249–256 (2001).
R.W. Rosenthal. A class of games possessing pure-strategy Nash equilibria.
Int. J. Game Theory, 2: 65–67 (1973).
T. Roughgarden. Selfish routing and the price of anarchy. The MIT Press,
2005.

72

Cutting and Packing

Lecture Hall A

Tue 2, 14:00–15:30

A Lower Bound for
the Cutting Stock Problem with a
Limited Number of Open Stacks
Claudio Arbib, a Fabrizio Marinelli, b Carlo M. Scoppola c
a Università

degli Studi di L’Aquila, Dipartimento di Informatica,
via Vetoio, I-67010 Coppito, L’Aquila, Italia
arbib@di.univaq.it
b Università

Politecnica delle Marche,
Dipartimento di Ingegneria Informatica, Gestionale e dell’Automazione
via Brecce Bianche, I-60131 Ancona, Italy
marinelli@diiga.univpm.it
c Università

degli Studi di L’Aquila, Dipartimento di Matematica Pura e Applicata,
via Vetoio, I-67010 Coppito, L’Aquila, Italia
scoppola@univaq.it

Abstract
This paper proposes an algorithm to compute a lower bound for the cutting stock problem subject to a limited number s of open stacks. The algorithm employs an enumeration
scheme based on algebraic properties of the problem. Search is shortened by bounds computed via column generation and by symmetry breaking, implemented to avoid the repeated
evaluation of equivalent solutions. A preliminary computational experience confirms the
effectiveness of the method.
Key words: Cutting Stock Problem, Lower Bounds

1. The problem
Consider a sufficiently large set of stock items having standard length w, and a
finite set B of m batches, the i-th consisting of a known amount di of required parts
of length wi (i ∈ B). A cutting pattern k specifies the number aik ≥ 0 of items
of type i that are produced when the pattern is applied on a single stock item. The
Cutting Stock Problem (CSP ) calls for finding a set P of feasible cutting patterns
and deciding how many stock items must be cut according to each k ∈ P , with the
objective of satisfying the requirements of parts with a minimum total number of
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

stock items [3].
Any CSP solution P is in general implemented by applying its patterns in some
order π, but not all the orders are feasible if the cutting machine has an s-slot
outbuffer able to maintain up to s distinct batches at a time, and a slot occupied by
parts of some type can be released only if the relevant batch has been completed.
With this kind of technological constraint we speak of a Cutting Stock Problem with
a Limited Number s of Open Stack (CSPs ) [2].
More formally, we say that a CSP solution P is schedulable if it can be sequenced
in an order π so that, at any time, the number of distinct batches which are not
completed (open stacks) never exceeds s. Then, CSPs can be stated as follows:
Problem 1. Find a schedulable cutting stock solution that produces all the required
batches with a minimum trim loss.
Let Q be a 0-1 matrix with m = |B| rows, none of which null. We call Q a track
for a CSP solution P if, for any k ∈ P , there exists a column t with qit > 0 for
all i ∈ B such that aik > 0. Reciprocally, we say that P is supported by Q, and
in particular that a single part type i is supported by a column qt of Q if qit = 1.
A track Q is dominated by a track R if the set of CSP solutions supported by R
includes that supported by Q. With no loss of generality, from now on we assume
the columns of Q mutually non-dominated, that is, no two columns qr , qt are such
that qir ≤ qit for all i ∈ B.
Let ω(Q) denote the largest number of non-zero elements in a column of a track
Q. We then say that Q is feasible if
• it has the consecutive one property (C1P) by rows, that is, qij = qik = 1 ⇒
qih = 1 for j < h < k and all i ∈ B;
• ω(Q) ≤ s.
Proposition 1. A CSP solution P is schedulable if and only if it is supported by
a feasible track Q.
Proposition 2. Every feasible track Q with ω(Q) = s is dominated by a feasible
track R having (i) each column with exactly s non-zero elements and (ii) any two
adjacent columns different for exactly two elements.

2. Computing a lower bound
Let CSP (s) indicate a cutting stock problem where no pattern can produce
more than s distinct types. The solution of (the linear relaxation of) CSP (s) provides a valid lower bound to CSPs . An improved lower bound zLB can be obtained
on the basis of Propositions 1 and 2 by enumerating all the non-dominated feasible tracks. In fact, let Rk denote the submatrix consisting of the first k columns

76

of a track R. An implicit enumeration can be performed by calling, for any 0-1
m-vector r with s non-zeroes, the following recursive function track_enum()
with parameters 1, r and B.
track_enum(k, Rk , Bk )
For all columns r with s non-zeroes in Bk and such that r · rk = s − 1 do
(1) Rk+1 := [Rk |r]
(2) For i ∈ Bk do if rik > ri then Bk+1 := Bk − {i}
(3)if zLB (Rk+1) ≤ zLB then track_enum(k + 1, Rk , Bk )
Removing row i from Bk at Step 2 corresponds to fixing to 0 the i-th element
of any columns generated from then on: this ensures that the resulting matrix has
the C1P. As soon as m − s + 1 elements have been fixed, non-dominated columns
with s non-zeroes cannot be added any longer. Step 3 performs fathoming: zLB is
the best lower bound found so far and zLB (Rk+1 ) is a lower bound to the optimum
attainable with patterns supported by the uncompleted track Rk+1 .
Call K the set of the cutting patterns that either (i) are supported by Rk+1 , or (ii)
produce ≤ s part types in Bk+1 . Then zLB (Rk+1 ) is the optimum value of linear
program (2.1), which can be computed by a standard column generation procedure.
zLB (Rk+1) = min{

X

k∈K

xk |

X

k∈K

aik xk = di , i ∈ B, xk ≥ 0, k ∈ K}

(2.1)

3. Symmetry breaking

Symmetry breaking means in general to fathom unnecessary equivalent tracks
in order to reduce the search space. Tracks corresponding to column permutations
are equivalent in the sense that produce by program (2.1) identical optimal solutions
and lower bounds. A maximal set of equivalent tracks is an orbit of a permutation
group G. Of course, we are not interested in all the column permutations of G, but
only in those, called feasible, which preserve the C1P: one is for instance the mirror
permutation µ that sends each column j ∈ C into |C| − j. To this purpose, let us
introduce the following notion.
Definition 2. Let Q be a track with columns indexed in C. Then S ⊆ C is said to
be permutable if any permutation π such that π(j) = j for j ∈ C − S is feasible.
Maximal permutable sets are defined in the obvious way. We call trivial a permutable set consisting of a single column, and we say that a row i ∈ B of a track
Q is a unit row if it contains exactly one non-zero element. In order to identify
equivalent tracks we characterize permutable sets as follows.
Theorem 3. S ⊆ C is permutable if and only if for any row i ∈ B either qij = qik
for all j, k ∈ S or i is a unit row of Q.
77

On the basis of Theorem 3 it can be observed that every non-trivial permutable
set St hits at least |St | unit rows, for otherwise C would have identical columns.
Thus a permutable set is identified as soon as a unit row is detected during the
generation of a track, i.e., when the current uncompleted track Rk contains a row
i for which rik−2 = 0, rik−1 = 1 and rik = 0. Hence to avoid tracks having the
same permutable set it is sufficient to apply the lexicographic order to the rowsubsequences 010.

4. Preliminary computational results

A preliminary computational test was done on a set of 80 random instances, of
which 40 with s = 2 and 40 with s = 3, and all with m = 10 part types. A feasible
solution was computed by the first-sequence-then-cut heuristic proposed by [1]. In
49 cases the lower bound obtained by the linear relaxation of CSP (s) provided the
same value of the feasible solution, which therefore turned out to be optimal. In the
remaining 31 cases our algorithm improved the bound, and in 3 of these allowed
closing the gap.

References
[1] Arbib, C., F. Marinelli, F. Pezzella, Trim Loss Minimization Under a Given
Number of Open Stacks, XXXIX Conference, AIRO2008, Ischia, Italy,
September 7-11, 2008.
[2] Belov, G. and G. Scheithauer, Setups and open-stacks minimization in onedimensional stock cutting, INFORMS J. on Computing, 19 1 (2007) 27-35.
[3] Wäscher G., H. Haußner, H. Schumann, An improved typology of cutting and
packing problems, European Journal of Operational Research, 183 (2007)
1109-1130.

78

Packing Paths: Recycling Saves Time
Henning Fernau, a Daniel Raible a
a Universität

Trier, FB 4—Abteilung Informatik, D-54286 Trier, Germany
{fernau,raible}@uni-trier.de

Key words: parameterized algorithms, graphs, packings

1. Introduction and Definitions
A Pd is a path of length d and therefore has d + 1 vertices. A Pd -packing of a
graph G(V, E) is a set of vertex-disjoint copies of a Pd in G. It is maximal if any
addition of a further Pd would violate the vertex disjointness property. The problem
we investigate in this paper is Pd -PACKING (d ≥ 3):
Given G(V, E), and the parameter k.
We ask: Is there a Pd -packing of size k?
P. Hell and D. Kirkpatrick [5; 4] showed that general M AXIMUM H -PACKING is
N P-complete. Here, H is a graph with at least three vertices in some connected
component. A subcase of H-packing is of course a Pd -packing if d ≥ 2. d = 1
corresponds tothe classical matching problem.
For the special case of P2 -packing there have been already publications in
the fields of parameterized and approximation algorithms. The currently fastest
algorithm solving P2 -packing in time MCO∗ (2.4823k ) is the one of H. Fernau and
D. Raible [3]. This algorithm combines the 7k-kernel of J. Wang et al. [8] together
with the idea to improve the recyclability of vertices in an inductive approach.
Although no linear kernels are known for Pd -packing (for d > 2), we propose
here a similar approach that helps with the second, color-coding phase of hitherto
published packing algorithms.
More specifically, in [7] it was shown that for any maximal 3-set packing
CRRAP of size j there is a packing Q of size j + 1 reusing at least 2j vertices
from CRRAP . We show that this result is also valid for general `- SET PACKING
and therefore also for Pd -packing. Thus, the algorithm of [7] can easily be adapted
to Pd - PACKING. In [3], we showed that for P2 -packings, we can reuse at least 2.5j
vertices of a P2 -packing of size j. We prove similar results for Pd - PACKING if
3 ≤ d ≤ 5. Namely, we show that one can reuse 3j vertices for d = 3 and d = 5

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Algorithm-type
`- SET

PACKING

Pd - PACKING

P3 - PACKING

P4 - PACKING

P5 - PACKING

MCO∗ (6.994k )

MCO∗ (8.985k )

MCO∗ (10.66k )

MCO∗ (4.184k )

MCO∗ (6.995k )

MCO∗ (6.996k )

Table 4. The tables gives the running times of ordinary `-S ET PACKING-algorithm (see
Alg. 1) and their improvements due to better reusability results in case of Pd -packing.

and 2.5j vertices for d = 4. Considering this results we can speed up the algorithm for Pd - PACKING yielding run times of MCO ∗ (5.80064k ), MCO∗ (6.98575k )
and MCO∗ (6.996k ) for d = 3, d = 4 and d = 5, respectively. Table 4 lists our run
times, where for P3 -packings we employed a refined analysis technique.
A path is an ordered set of vertices p1 . . . pj such that {pi , pi+1 } ∈ E for 1 ≤
i ≤ j − 1. Generally, the paths p1 . . . pj and pj . . . p1 are considered the same, as
their edge-sets are the same. Nevertheless, at some points we need to order the
considered path. We set E(p) := {{pi , pi+1 } | 1 ≤ i < j} and V (p) := {pi | 1 ≤
S
i ≤ j}. For a set of sets S = {S1 , . . . , Sm } we let V (S) = 1≤i≤m Si , i.e., V (S)
comprises the elements of which the Si consist. A path p is called subpath of a path
p0 if a E(p) ⊆ E(p0 ). Two paths p and p0 intersect if V (p) ∩ V (p0 ) 6= ∅.
2. Properties of Pd -Packings
The general strategy is that we use an already existent maximal solution CRRAP
of a `-set packing instance of size j to obtain a solution Q of size j + 1. For this
task it is of importance how many of the d · j vertices of V (CRRAP ) appear also
in V (Q). Among all `-set-packings of size (j + 1), we will consider those packings
Q that maximize
|CRRAP ∩ Q|.

(2.1)

We subsume these packings under the name MCLd(1) . In MCLd(1) , we find those
packings Q that ’reuse’ the maximum number of sets from the packing CRRAP .
The authors of [3] showed the next proposition with respect to P2 -packings by
strengthening a proposition of [7]. But browsing their proof shows that it can be
generalized straightforward for `-set packings.
Proposition 2.1. If Q ∈ MCLd(1) , then for any p ∈ CRRAP with p 6∈ Q, there are
q 1 , q 2 ∈ Q, q 1 6= q 2 , with |V (p) ∩ V (q i )| ≥ 1 (i = 1, 2).
The algorithm of [7] for 3-S ET-PACKING also serves for `- SET- PACKING if we
modify it slightly, see Alg. 1:
The color-coding and the dynamic programming
part in Alg. 1 can be up
∗
∗ Pj+1 2j(d−1)+d
(`−2)k
) ⊆ MCO∗ (22k(`−1) ),
perbound by MCO (6.1
) and MCO ( z=1
dz
80

respectively.
Lemma 2.2. We can find a `-set packing in time MCO∗ (c`k
` ) (c` =

√
`

24.4`−2 · 4).

Any Pd - PACKING instance can be transferred into a (d + 1)-S ET- PACKING
instance. In the cases of P3 , P4 and P5 - PACKING we will show that we can ’recycle’
more than 2j vertices. Similar improvements have been achieved by [3] for P2 PACKING . This accelerates Alg. 1 quite drastically.
Let CRRAP be a maximal Pd -packing of size j. Among all Pd -packings of
size j + 1 we will only consider those who maximize property (2.1). We subsumed
them in Qd(1) . Consequently, we have Qd(1) = MCLd+1
(1) with respect to the corresponding d + 1-S ET- PACKING instance. Furthermore, from the set Qd(1) we only
comprise those Pd -packings Q0 , which maximize the following second property:
X

X

p∈MCP q∈MCQ0

|E(p) ∩ E(q)|.

(2.2)

The set of the remaining Pd -packings will be called Qd(2) . Qd(2) contains those packings from Qd(1) which reuse the maximum number of edges in E(CRRAP ). We
further distinguish the packings in Qd(2) by considering only those minimizing
|MCP2 (MCQ)|, where MCPi (MCQ) = {p ∈ MCP | i = |p∩V (MCQ)|}.(2.3)
These packings are referred to as Qd(3) and contain those packings from Qd(2) with
the least number of paths from CRRAP such that only two vertices are reused.
Path-packings can benefit from the flexibility of folding and shifting paths on
graph edges. We refrain from giving formal definitions due to reasons of space.
Lemma 2.3. (i) If q ∈ Q with Q ∈ Qd(2) is `-shiftable on p ∈ CRRAP with
respect to q1 (qd+1 , resp.) then there is p0 ∈ CRRAP such that qd+1 . . . qd+1−`
(q1 . . . q`+1 , resp.) is a subpath of p0 6= p.
(ii) If Q ∈ Qd(2) then no q ∈ Q is `-foldable, ` ≥ 1.
(iii) If Q ∈ Qd(3) then no q ∈ Q is 2-shiftable on p ∈ CRRAP with |V (p) ∩
V (Q)| = 2.
Algorithm 1 An Algorithm for general path packing
Greedily find a maximal `-set packing CRRAP of G.
if j := |CRRAP | ≥ k return CRRAP .
Color the vertices V \ V (CRRAP ) with (` − 2)j + ` colors by color-coding.
Color V (CRRAP ) by `j additional colors arbitrarily.
Check if there are `(j + 1) vertices with pairwisely different colors that can be perfectly packed by a `-set packing CRRAP 0 using dynamic programming. CRRAP ←
CRRAP 0 .
6: goto 2.

1:
2:
3:
4:
5:

81

3. P3 , P4 and P5 -packings
Henceforth, we will only consider Pd -packings from Qd(3) . We show that if
CRRAP is a maximal Pd -packing with d ∈ {3, 4, 5} of size j, we can reuse more
than 2j of its vertices. More formally: If there is a Pd -packing Q of size j + 1 we
can rely on |V (CRRAP ) ∩ V (Q)| ≥ 2.5j. Actually, in most cases we prove a
sharper statement. Namely, for all p ∈ CRRAP we have |V (p) ∩ V (Q)| ≥ 3.
Suppose a path p = p1 . . . pd+1 ∈ CRRAP shares exactly one vertex pq0 , pq00
with paths q 0 , q 00 ∈ Q each (i.e., |V (p) ∩ V (Q)| = 2). Due to Proposition 2.1,
q 0 , q 00 must exist. Subsequently, pq0 , pq00 are the cut vertices of these q 0 , q 00 ∈ Q with
p ∈ CRRAP2 (Q).
Let pi := pq0 and pj := pq00 ; w.l.o.g., i < j. Then pi and pj define three (possibly empty) subpaths on p: Xq0 := p1 . . . pi−1 , Xq0 q00 := pi+1 . . . pj−1 and Xq00 :=
pj+1 . . . pd+1 . Subsequently, we write |Xi| for |V (Xi )|. Next we will discuss the
case where pq0 and pq00 are not end-points of q 0 and q 00 , respectively. For any path p
of length d the mid-points is the set {pdd+1/2e , pbd+1/2c }. A vertex mq is a Q-midpoint if there is a q ∈ Q with mq being a mid-point of q.
Lemma 3.1. Let CRRAP be a maximal Pd -packing, p ∈ CRRAP , V (p)∩V (Q) =
{pq0 , pq00 }.
(i) If d ∈ {3, 5} then one of pq0 , pq00 must be a Q-end-point, w.l.o.g., pq0 .
(ii) If d ∈ {3, 4, 5}, such that pq00 is not an Q-end-point but pq0 is. Then pq0 is
1-shiftable for d = 4 and 2-shiftable for d ∈ {3, 5}.
(iii) For d ∈ {3, 5} pq00 is a Q-end-point.
Lemma 3.1.(i) does not hold for P4 -packings and any Pd -packing with d > 5. For
P5 -packings, this lemma immediately gives the desired recycling:
Lemma 3.2. Let CRRAP be a maximal P5 -packing of size j. If there is a packing
of size j + 1, then there is also a packing Q ∈ Q5(3) such that for all p ∈ CRRAP
we have |V (p) ∩ V (Q)| ≥ 3.
P3 -packings are more subtle. Among the packings Q3(3) are those packings Q
that maximize
X

X

p∈MCP q∈MCQ

|end(p) ∩ E(q)|

(3.4)

where end(p) denotes the set of two end-edges, i.e., when p = p1 . . . p4 is a path,
then {p1 , p2 } and {p3 , p4 } are comprised in the set end(p). We call those Q3(4) . In
Q3(4) are those packings from Q3(3) such that greatest number of end-edges is reused.
We call a path q ∈ Q end-1-shiftable on some p ∈ P if q is 1-shiftable and we can
shift q by one in a way that we cover an end-edge of p.
Theorem 3.3. Let CRRAP be a maximal P3 -packing of size j. If there is a P3 -

82

packing of size j + 1 then exists Q ∈ Q3(4) such that for all p ∈ CRRAP we have
|V (p) ∩ V (Q)| ≥ 3.
Further speed-up techniques, using ideas from [8], are necessary to show the
claimed running time. We could only prove a weaker lemma for P4 -packings:
Lemma 3.4. Let CRRAP be a maximal P4 -Packing with size j. If there is a P4 packing of size j + 1 then there is also a packing Q ∈ Q4(3) such that we have
|V (CRRAP ) ∩ V (Q)| ≥ 2.5 · j.
4. Conclusion
Our algorithmic approach is of the iterative expansion type. Starting from a
maximal solution, investigate the relation to a possible larger solution. For path
packing problems, a certain amount of vertices in the old solution also appears in
the larger one, reducing the cost of the expansion step. The question of reusability
is an interesting issue in extremal combinatorics on its own right. So, the following
type of questions should be explored independently of possible algorithmic consequences: Given a maximization problem and a feasible solution S of size k to that
problem for a certain instance, is it possible to either construct a solution of size
(k + 1) (or larger), re-using as many elements from S as possible, or to conclude
that no such larger solution exists?
References
[1] J. Chen and S. Lu. Improved algorithms for weighted and unweighted set
splitting problems. In COCOON, LNCS 4598, 537–547, 2007.
[2] J. Chen and S. Lu. Improved parameterized set splitting algorithms: A probabilistic approach. Algorithmica, To appear.
[3] H. Fernau and D. Raible. A parameterized perspective on packing paths of
length two. In COCOA, LNCS 5165, 54–63, 2008.
[4] P. Hell and D. G. Kirkpatrick. Star factors and star packings. Technical Report
82-6, Computing Science, Simon Fraser University, Burnaby, Canada, 1982.
[5] D. G. Kirkpatrick and P. Hell. On the completeness of a generalized matching
problem. In Symposium on Theory of Computing STOC, 240–245, 1978.
[6] I. Koutis. Faster algebraic algorithms for path and packing problems. In
ICALP, LNCS 5125, 575–586, 2008.
[7] Y. Liu, S. Lu, J. Chen, S.-H. Sze. Greedy localization and color-coding: improved matching and packing algorithms. In IWPEC, LNCS 4169, 84–95,
2006.
[8] J. Wang, D. Ning, Q. Feng, J. Chen. An improved parameterized algorithm
for a generalized matching problem. In TAMC, LNCS 4978, 212–222, 2008.

83

Rectangle Packing with Additional Restrictions
Jens Maßberg, a Jan Schneider a
a Research

Institute for Discrete Mathematics
Lennéstr. 2, 53113 Bonn, Germany
{massberg,schneid}@or.uni-bonn.de
Key words: rectangle packing, NP-completeness

1. Problem Formulation

R ECTANGLE PACKING as a decision problem, i.e. the question if a set of rectangles can be disjointly packed into a bounding box of given dimensions or area, is
easily seen to be NP-complete [1].
However, in practical applications it is often possible to restrict the instances
in one or another way. It might be possible to guarantee that the rectangles do not
have extreme aspect ratios, or do not differ very much in their area consumption.
Also, the bounding box could be a given percentage larger than the total size of
the rectangles in the instance. In [3], we parameterized R ECTANGLE PACKING to
incorporate restrictions of these kinds and analyzed the computational complexity
of the resulting problems. The decision problem (α, β, γ)-PACKING is defined as
follows:
Instance: A set of n rectangles with widths wi and heights hi and a real number A
satisfying
P
• A ≥ α · ni=1 wi hi
• wi hi ≤ β · wj hj for 1 ≤ i, j ≤ n
• max{wi , hi } ≤ γ · min{wi , hi } for 1 ≤ i ≤ n
Question: Is there a disjoint packing of the rectangles such that their bounding
box has an area of at most A?
To simplify notation, (α, β, ∞)-PACKING shall denote the version of the problem where only the first two conditions hold with the given α and β. Analogously,
(α, ∞, γ)-PACKING stands for the version where only the first and last conditions
hold.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. Results
The parameters α, β, and γ can be varied in many ways to generate different
problems. The first one considered is the one with β = 1, meaning that all rectangles in the instance have the same area, and γ = ∞, so that the aspect ratio
of single rectangles can be arbitrarily large. Theorem 1 states that this problem is
NP -complete even if the packing’s density is arbitrarily low:
Theorem 2.1. (α, 1, ∞)-PACKING is NP -complete for every α ≥ 1.
Corollary 1. (α, β, ∞)-PACKING is NP -complete for every α ≥ 1 and β ≥ 1.
The next theorem considers squares (i.e. γ = 1) whose areas differ by a factor
of at most 1 + :
Theorem 2.2. (1, 1 + , 1)-PACKING is NP -complete for every  > 0.
We found a similar result for rectangles which are almost squares (aspect ratio
below 1 + ) and have the same area:
Theorem 2.3. (1, 1, 1 + )-PACKING is NP -complete for every  > 0.
It becomes apparent that many versions of (α, β, γ)-PACKING are still NP complete. But there are also some cases where the answer is trivial – the most
obvious one being (1, 1, 1)-PACKING, whose instances only contain squares of the
same size. As soon as the rectangles in the instance have similar size and bounded
aspect ratio, it is clear that packings with a certain density are possible. The first
result is achieved by simply arranging all rectangles in a row:
√
Theorem 2.4. If α ≥ βγ, then the answer to (α, β, γ)-PACKING is yes.
We present a strip packing method to find a more elaborate result:
Lemma 2.5. Let r1 , . . . , rn be the rectangle set from an instance of (α, β, γ)-PACKING
and P the output of the strip packing algorithm running on the input r1 , . . . , rn . If
P
A denotes the area of P ’s bounding box, then A < (1 + β + βγ
) · ni=1 wi hi .
n

Theorem 2.6. If α > β + 1, then (α, β, γ)-PACKING can be decided in time O(1).
Pavel Novotný proved in [2] that any set of squares with a total area of 1 can
be packed into a rectangle of area 1.53. Hence, the following theorem holds:
Theorem 2.7. If α ≥ 1.53, then the answer to (α, ∞, 1)-PACKING is yes.
To conclude, the following table shows a summary of the results on (α, β, γ)PACKING.

85

α=1

γ=1

1<γ<∞

γ=∞

Trivial for β = 1

NPC

NPC

Trivial for α > β + 1
√
Trivial for α ≥ βγ

NPC

NPC otherwise
α>1

Trivial for α ≥ 1.53
√
Trivial for α ≥ β

References
[1] Richard E. Korf. Optimal Rectangle Packing: Initial Results. In ICAPS ’03:
Proceedings of the International Conference on Automated Planning and
Scheduling, pages 287–295, AAAI, 2003.
[2] Pavel Novotný. On Packing of Squares Into a Rectangle. Archivum Mathematicum (Brno), 32(1):75–83, 1996.
[3] Jan Schneider. Macro Placement in VLSI Design. Dimplomarbeit, Rheinische
Friedrich-Wilhelms-Universität Bonn, 2009.

86

Paths

Lecture Hall B

Tue 2, 14:00–15:30

The open capacitated arc routing problem
Fábio Luiz Usberti, a Paulo Morelato França, b
André Luiz Morelato França a
a FEEC/UNICAMP, C.P.

6102, 13083-970 Campinas SP, Brazil
fusberti@yahoo.com

b FCT/UNESP,

C.P. 468, 19060-900 Presidente Prudente SP, Brazil

Key words: Arc Routing Problem, NP-hard Problem, Problem Reduction

Introduction. The Capacitated Arc Routing Problem (CARP) [1] is a wellknown combinatorial optimization problem in which, given an undirected graph
G(V, E) with non-negative costs and demands associated to the edges, we have M
identical vehicles with capacity D that must traverse all edges with positive demand. The vehicles must start and end their routes at a depot node, without transgressing their capacity. The objective is to search a solution of minimum cost. This
work introduces the Open Capacitated Arc Routing Problem (OCARP), where vehicle’s routes are not constrained to form cycles, therefore we are searching for
minimum cost paths.
Problem Definition. The Open Capacitated Arc Routing Problem (OCARP)
can be defined on an undirected graph G(V, E) with edge costs cij = cji and demands dij = dji. Edges with positive demands are called required (R ⊆ E) and
must be serviced. M identical vehicles of capacity D are available. N(i) denotes
the nodes adjacent to node i in G. There are two set of decision variables: xkij = 1 if
k
vehicle k traverses edge (i, j), xkij = 0 otherwise; lij
= 1 if vehicle k services (i, j),
k
lij
= 0 otherwise. The OCARP objective is to find a set of paths with minimum
total cost without overloading any vehicle capacity. The model uses the following
auxiliary variables: αik , βik , ySk , ukS and vSk (i ∈ V, k ∈ {1, . . . , M}, S ⊆ V ). An
integer linear programming model for the OCARP is given.

MIN

M
X
X

cij xkij

(0.1)

k=1 (i,j)∈E

st

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

X

(xkji

j∈N (i)

X

j∈N (i)

X

i∈V

xkij
M
X

6








αik

(i ∈ V, k ∈ {1, . . . , M})




(xkji − xkij ) > −βik 



αik 6

i∈V

X

−

xkij )

(0.2)



1



(k ∈ {1, . . . , M})




βik 6 1 


>

(0.3)
((i, j) ∈ E, k ∈ {1, . . . , M})
(0.4)

k
lij

k
k
(lij
+ lji
)=1

((i, j) ∈ R)

k=1

XX
i

(0.5)
k
lij
dij 6 D

(k ∈ {1, . . . , M})

j

X

(i,j)∈(S,S)

X

xkij − |S|2ySk 6
xkij + ukS > 1

(i,j)∈(S,S̃)

X

xkij

(i,j)∈(S̃,S̃)

−

|S̃|2 vSk

ySk + ukS + vSk 6 2
k
xkij , lij



|S| − 1 













60
















(0.6)

(S ⊆ V, S̃ = V \ S, k ∈ {1, . . . , M})

(0.7)
((i, j) ∈ E, k ∈ {1, . . . , M})
(0.8)
(k ∈ {1, . . . , M})
(0.9)
(k ∈ {1, . . . , M}, S ⊆ V )
(0.10)

∈ {0, 1}

αik , βik ∈ {0, 1}
ySk , ukS , vSk ∈ {0, 1}

The objective function (0.1) minimizes the solution cost. Constraints (0.2) and
(0.3) guarantee that the nodes visited by a vehicle will have indegree equal to their
outdegree, except for at most two nodes, which can have an unitary difference between indegree and outdegree (likewise a path). Constraints (0.4) state that serviced
edges must be traversed; (0.5) force all required edges to be serviced; (0.6) are the
capacity constraints; finally, constraints (0.7) assures path connectivity.

90

OCARP Applications. In this section, we consider some problems of practical
interest which can be easily modeled (i.e., polynomially reduced) into an OCARP.
The Routing Meter Reader Problem [2; 3] interesses major electric, water and
gas distribution companies which periodically meter read their clients. This problem inspired the conception of OCARP and concerns the creation of a set of open
routes for meter readers with limited amount of work time which visit all street
segments containing clients in minimum traversal time. A service time is incurred
always that a worker meter reads, while a shorter deadheading time is computed
when the worker is not reading. While all street segments have positive deadhead
time, some of them may have zero service time, which means there is no client on
that segment.
In the Cut Path Determination Problem [4] the trajectories of a set of blowtorchs are defined on a rectangular steel plate in order to produce a pre-defined set
of polygonal shaped pieces in minimum time. A piece is produced when its shape is
fully traversed by one or more blowtorchs. The blowtorchs have a limited amount
of energy to spend and must not traverse the interior of any shape, but they may
deslocate above the plate level, which reflects additional elevating and lowering
maneuvers times.
In the Parallel Machine Scheduling with Resource Constraints [5], we have
a set of distinct jobs that must be executed by a number of identical machines,
with limited amount of resources. Each job has a processing time and demands an
amount of resources. Each job may not be processed in more than one machine
simultaneously and no machine can process more than one job at a time. The objective is minimize the schedule lenght (makespan).
Complexity Results. This section gives a polynomial reduction CARP 6 OCARP,
which concludes OCARP NP-hardness. Given any CARP instance G(V, E), with
M vehicles with capacity D, add 2M dummy nodes (V0 ) and 2M dummy required
edges (R0 ), with demands d(r ∈ R0 ) = B > D, and zero cost. These dummy edges
link dummy nodes with the depot v0 . The vehicles capacity should be increased to
D + 2B. A new graph G1 (V0 ∪ V, R0 ∪ E) is then formed. This transformation has
complexity O(M), and assuming M 6 |R|, then it is linear with respect to the size
of G. The relationship between the CARP optimal solution L∗G and the OCARP
optimal solution PG∗ 1 is the following: L∗G = PG∗ 1 \ {R0 ∪ V0 } and c(L∗G ) = c(PG∗ 1 ).
Solution Strategy. This work considers reducing OCARP into CARP and then
adopting a CARP heuristic to solve the former. The OCARP 6 CARP reduction is
given next. Consider an OCARP instance G(V, E) with M vehicles and capacity
D. Add a dummy depot node v0 and a set N0 of non-required edges, with costs
c(e ∈ N0 ) = B  max [c(e)], linking v0 to every node in G. We then form a
e∈E

new graph G1 (v0 ∪ V, N0 ∪ E). This reduction has complexity O(|V |), hence is
linear with the size of G. The relationship between the OCARP optimal solution

91

PG∗ and the CARP optimal solution L∗G1 is the following: PG∗ = L∗G1 \ {N0 ∪ v0 }
and c(PG∗ ) = c(L∗G1 ) − 2B.
Computational Tests. The standard set of CARP instances ∗ , which includes
23 gdb, 34 val and 24 egl instances, was used to form the set of OCARP instances,
simply by considering the depot a regular node. Lower bounds were obtained by
summing the costs of all required edges. Upper bounds were achieved through a
path-scanning CARP heuristic [6], after applying the OCARP 6 CARP reduction
of the previous section. The overall average deviation from lower bounds were
15,1% (gdb 0,61%, val 7,75%, egl 42,74%). From the set of 81 solutions, 19 solutions from gdb were proven optimal.
Conclusions and Future Works. This work introduced a new NP-hard combinatorial problem belonging to the arc routing problems family. It has presented
many practical problems that can be modeled as an OCARP. A solving strategy has
been given by transforming an OCARP into a CARP. Computational experiments
were conducted with a set of 81 OCARP instances, using an efficient path-scanning
heuristic. The first lower and upper bounds are given, with some proven optimal solutions. Future works should focus on specific OCARP heuristics design in order
to further tighten the upper bounds. Exact algorithms, using column generation and
cutting planes approaches, as well as lower bounding procedures, should also be
investigated.
Acknowledgment. This work was supported by CNPq (processes 305114/20069 and 474099/2006-7).
References
[1] B. L. Golden, R. T. Wong (1981), ”Capacitated arc routing problems”, Networks, Vol. 11, pp. 305-315.
[2] H. I. Stern, M. Dror (1979), ”Routing electric meter readers”, Computers and
Operations Research, Vol. 6, pp. 209-223.
[3] J. Wunderlich, M. Collette, L. Levy, L. Bodin (1992), ”Scheduling meter readers for Southern California gas company”, Interfaces, Vol. 22, pp. 22-30.
[4] L. M. Moreira, J. F. Oliveira, A. M. Gomesa, J. S. Ferreira (2007), ”Heuristics
for a dynamic rural postman problem”, Computers and Operations Research,
Vol. 34, pp. 3281-3294.
[5] E. Mokotoff (2001), ”Parallel machine scheduling problems: A survey”, Asia
- Pacific Journal of Operational Research, Vol. 18(2), pp. 193-243.
[6] L. Santos, J. Coutinho-Rodrigues, J. R. Current (2008), ”An improved heuristic for the capacitated arc routing problem”, Computers and Operations Research, doi:10.1016/j.cor.2008.11.005.
∗

http://www.uv.es/˜belengue/carp.html

92

Optimising node coordinates for the shortest path
problem
Mirko Maischberger a
a Dipartimento

di Sistemi e Informatica, Università degli Studi di Firenze, Italy

Key words: goal oriented shortest path, coordinate generation

1. Introduction

In the shortest path problem [1] the exploitation of geographical coordinates is
a common mean to obtain shorter computational times.
However there are cases in which geographical coordinates are not known and
cannot be easily obtained. In other cases, when the objective to be minimized is
loosely coupled with the geographical displacement, straight-line distance can simply be a bad choice.
The contribution of this work is the introduction of a new model and a new
method for the generation of good artificial coordinates for goal oriented algorithms. The only previous work on the subject of generation of coordinates for
shortest path computation is [5].
In [5] coordinates are generated with two methods. The first method they use
is the barycentric one, which is very fast in the generation phase, but gives suboptimal results. The second method proposed in the same article, the tailored model,
uses a Kamada-Kawai [7] like objective with fewer terms: they only consider members directly connected by an edge. Both models could lead to euclidean distances
between nodes greater than their effective distance. This kind of unconstrained approach forces them to scale the generated coordinates down so that the euclidean
distance is an admissible heuristic again (w.r.t. the goal oriented algorithm they
use). In their experiments, results from the tailored method yield results comparable with real geographical coordinates.
Our contribution is reasonably fast in the preprocessing phase, yields admissible coordinates without the need for rescaling, and, to the best of our knowledge,
outperforms the previous techniques halving the average query time.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. A constrained model for the assignment of coordinates to be used by goal
oriented searches
Given a graph G = (V, E) with |V | = n, |E| = m, where V is the vertex set
with coordinates pi ∈ R2 , and E ⊆ V ×V is the edge set with non-negative weights
w ∈ Rm , we are interested in finding the best admissible heuristic h : V × V → R
such that, for every pair of nodes, h assigns an estimate distance near to, but not
exceeding, the cost of the shortest path between them.




T
 px 

We will refer to P ∈ R2×n as the coordinates matrix, so that P = 



pTy
where px and py are vectors containing the x and y coordinates of the vertices and
P = [p1 p2 . . . pn ] so that pi ∈ R2 is the vector containing the coordinates of the i-th
vertex.
Let dij be the cost of the shortest path from i ∈ V to j ∈ V , our ideal objective
will be to have h(i, j) = dij ∀(i, j) ∈ V × V so that the heuristic is exactly
accurate for every pair of nodes. This cannot be achieved in the general practice
since not all graphs are realizable in a limited number of dimensions [2]. We will
try to make h(i, j) closest to dij while posing h(j, j) ≤ dij to preserve admissibility.
A very simple model that has proved effective in practice can be obtained using
an objective that maximizes the weighted sum of the squared euclidean distance
between all pairs of vertices.
maxP
s.t.

P

1
(i,j)∈V ×V,i6=j d2
ij

2
kpi − pj k2 ≤ wi,j

(kpi − pj k2 ),

(2.1)

∀(i, j) ∈ E.

The resultant model is a convex maximization problem on a convex set, an
hard problem [4].
We solved our problem with up to about twenty thousand variables and ten
thousand constraints using the Frank-Wolfe method [3, 215-218]. Given a problem
in the form
maxf (x)
x

s.t. x ∈ X,
the Frank-Wolfe method [3, 215-218] is a way to generate a feasible direction xk −
xk that satisfies the descent condition ∇f (xk )0 ((x)k − xk ) < 0 to be used in the
update rule.
The sub-problem obtained applying the method has a linear objective func-

94

tion, it’s quadratically constrained, and it can be solved efficiently with a dedicated
solver for QCQP (Quadratically Constrained Quadratic Program):
max∇fx (pkx )T px + ∇fy (pky )T py ,
P

2
s.t. kpki + pi − pkj − pj k2 ≤ wi,j

∀(i, j) ∈ E.

3. Testing environment, computational results and conclusions

In our experiments we used two road networks, Florence and Lisbon (c.f.r.
table 5). We also generated a new set of coordinates for the timetable data used
in [8; 5] and, as they made their code publicly available, we were able to compare
with the original implementation on the original coordinates.
graph

nodes

edges

Florence

4 466

8 932

Lisbon

10 056

11 499

de-org

6 960

931 746

Table 5. The number of nodes and edges of the test graphs.

Sources was built with GNU Compiler Collection version 4.3.2. All the binary
was run on a Pentium 4 processor running a 32bit Linux 2.6.27 kernel at 3GHz
equipped with 1GiB of main memory.
We have generated new sets of coordinates for all the graphs in table 5. A
summary of results, including results from the graph of Lisbon, are presented in
table 6 and 7. In particular table 7 is a direct comparison with previous coordinate
generation approaches.
ms

graph

expanded nodes

original

generated

original

generated

Florence

0.34

0.25

553

378

Lisbon

0.25

0.13

5026

1847

Table 6. Average query response time and average number of nodes expanded by the goal
oriented algorithm on 250 000 random queries (the same for all the runs) on the two cities
with original and generated coordinates.

In table 7 we used the original code in [8] to compare the average query time
and average number of expanded nodes of our coordinates (de-constrained),
the geographical ones (de-org) and the best result from the tailored model presented in [5] (de-tailored).

95

graph

ms

edges

de-org

22.5

20 995

de-tailored

−

20 052

de-constrained9.4

9 899

Table 7. Average query response time and number of nodes touched by the goal oriented
algorithm. de-org is the original Germany’s timetable, de-tailored reports results
from the best of the tailored models from Brandes et al., and de-constrained is the
same timetable with coordinates generated by our proposed method.

In conclusion we proposed a new model and a new solution approach for the
generation of nodes coordinates w.r.t. goal oriented shortest path calculation. This
approach does not require any change in the goal oriented algorithms: generated
coordinates can be used as a drop-in replacement for geographical ones in existing
implementations [6].

References
[1] A HUJA , R. K., M AGNANTI , T. L., AND O RLIN , J. B. Network flows: theory,
algorithms and applications. Prentice Hall, New Jersey, 1993.
[2] A LFAKIH , A. Y. Graph rigidity via euclidean distance matrices. Linear Algebra and its Applications 310 (2000), 149–165.
[3] B ERTSEKAS , D. P. Nonlinear Programming, second edition ed. Athena Scientific, Belmont, Massachussets, 1999.
[4] B OYD , S. P., AND VANDENBERGHE , L. Convex Optimization. Cambridge
University Press, 2004.
[5] B RANDES , U., S CHULZ , F., WAGNER , D., AND W ILLHALM , T. Generating
node coordinates for shortest-path computations in transportation networks. J.
Exp. Algorithmics 9 (2004), 1.1.
[6] D ELLING , D., S ANDERS , P., S CHULTES , D., AND WAGNER , D. Engineering
route planning algorithms. Algorithmics of Large and Complex Networks (to
appear.).
[7] K AMADA , T., AND K AWAI , S. An algorithm for drawing general undirected
graphs. Inf. Process. Lett. 31, 1 (1989), 7–15.
[8] S CHULZ , F., WAGNER , D., AND W EIHE , K. Dijkstra’s algorithm on-line:
an empirical case study from public railroad transport. J. Exp. Algorithmics 5
(2000), 12.

96

The Sliding Shortest Path Algorithms
Ramesh Bhandari
Laboratory for Telecommunications Sciences
8080 Greenmead Drive
College Park, Maryland 20740, USA
rbhandari@ieee.org

Key words: constrained routing, rerouting, sliding shortest path, algorithm, minimal
weight increment, edge cutset, OSPF, networks, optimization, graphs

1. Introduction

The problem of finding optimal administrative link weights in response to a
given network demand matrix has received immense attention in the recent past,
see, e.g., [1-4]. In this paper, we address the problem of changing the link weights
for a specific demand (a single source-destination pair) to be rerouted through a
desired link or vertex not already on the shortest path of the given demand. Such
rerouting may be necessary in practice to satisfy the quality of service, as perhaps
warranted by a service-level agreement, or to meet a special request of an important business customer. For this rerouting, we require that the number of links on
which the weights are changed be as small as possible in order to reduce the implementation time of link weight changes within the current OSPF-type network
environment [2]. We further require that the weight changes (increments) be as
small as possible in order to minimize the number of other shortest paths (routes of
other demands) that might be affected. The problem is treated as an uncapacitated
problem [3-4]. To our knowledge, it has not been dealt with before.

2. Problem Definition
Let G = (V, E) denote an undirected graph, representing a bidirectional network (e.g., a single autonomous system); V is the set of vertices (or nodes), and E
is the set of weighted edges (or links); weights are non-negative integers; routing
of traffic demands from one point to another within the network takes place along
single shortest paths. We also make the assumption that graph G is biconnected (or

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2-connected), i.e., there always exists a simple path, which connects a given pair
of vertices, s and t, and includes a given arc pq [5]. A simple path refers to a path
in which a given vertex is not visited more than once. Unless otherwise stated, in
what follows, the term path refers to a simple path.
Let SP (s, t) denote a shortest path from vertex s to t in the given graph
G = (V, E). Let Γa denote a set of edges ∈ E, whose weights are incremented
to change the shortest path SP (st). Let xi , i = 1, .., |Γa | denote the corresponding
increments. The problem to solve can be stated as:
Given an undirected, weighted graph G = (V, E), and a pair of vertices s, t ∈
V , and an edge pq ∈ E,
minimize |Γa |

(2.1)

subject to arc pq (or arc qp) ∈ SP (s, t),
minimize xi , i = 1, .., M

(2.2)

subject to arc pq (or arc qp) ∈ SP (s, t); M = |ΓM |, the result obtained in Eq. (1)
above.
The problem in Eq. (2.1), which is the primary problem, is to identify the
minimum cardinality edge set whose weights should be incremented to alter the
given s − t flow path to include edge pq; the problem in Eq. (2), which is the
secondary problem, is a set of multiobjective functions to minimize the weight
increments on the edges found in Eq. (1). To solve it, it can be reformulated as a
minimization over the sum of the individual increments, xi ; this corresponds to
equal importance of all edges involved in the increment process.
It can be shown that the problem in Eq. (1) is equivalent to the following problem:
minimize |Γc |

(2.3)

subject to arc pq (or arc qp) ∈ SP (s, t),
where |Γc | is interpreted to mean a set of edges ∈ E, which when cut, alters
SP (s, t). The optimal value in Eq. (3) is the same as in Eq. (1), i.e., M = |ΓM |.
Problems, Eq. (3) and Eq. (2), are difficult problems, which appear to be NPhard. In this paper, we solve these problems, using simple heuristics (Section 3).

98

3. The Sliding Shortest Path Algorithm
In a given, undirected, weighted graph G = (V, E), this algorithm determines
(in accordance with a certain cutting criterion) the minimal cardinality set of edges,
which, when cut, force the shortest path between vertices s and t to include a given
constraint edge pq. Let Γ denote this set. Then the following steps determine Γ:
(i) Assign Γ = ∅
(ii) Compute the initial flow path, the shortest path SP (s, t) from s to t. If this
path contains edge pq, terminate; otherwise, go to Step 3.
(iii) Compute the shortest pair of vertex-disjoint paths [6], one path connecting s to
p (or q) (call it SP 1), and the other connecting vertex t to q (or p) (call it SP 2);
the vertex-disjoint path algorithms compute SP 1 and SP 2 simultaneously
and automatically determine whether SP 1 is a connection from s to p or s to
q; if SP 1 turns out to be a connection from s to p, SP 2 is a connection from
t to q, and vice versa.
(iv) Initialize i = 1
(v) Assign Γ(i) = ∅, where Γ(i) denotes the ith set of cut edges.
(vi) Find the first edge of SP (s, t), which does not overlap with SP 1 (cut-edge
selection criterion); cut this edge from the graph; denote this edge by L.
(vii) Set Γ(i) = Γ(i) ∪ L.
(viii) Compute new SP (s, t) in the trimmed graph.
(ix) If the new path contains edge pq, terminate; otherwise go to Step 6.
(x) Set i = i + 1
(xi) If i < 3, repeat Steps 5-9 in the original graph, replacing SP (s, t) with
SP (t, s), and SP 1 with SP 2; otherwise, terminate; SP (t, s) denotes the shortest path from t to s, which is taken to be SP (s, t) in the reverse order.
(xii) If |Γ(1)| < |Γ(2)|, set Γ = Γ(1); if |Γ(2)| < |Γ(1)|, set Γ = Γ(2); if |Γ(1)| =
|Γ(2)|, set Γ = Γ(1) or Γ(2).
If the SP (s, t) path already contains edge pq, the algorithm terminates, returning Γ = ∅; otherwise it performs two runs of an iterative process. The iterative
process consists of trimming the graph by cutting one edge at a time and recomputing the shortest path after each edge cut until the shortest path between s and t
slides over the given constraint edge pq. The edge to cut is determined by an edgeselection criterion (Step 6). In the first run (i = 1) of the iterative process, path SP 1
acts as the reference path for the cut-edge selection, and in the second run (i = 2),
path SP 2 acts as the reference path for edge-cut selection (Step 6). The two runs
of the iterative process of the algorithm yield two cut-sets, Γ(1) and Γ(2), which
can be different. In Step 12, the desired set Γ is identified with the one, which has
fewer edges. If there is a tie, Γ is set equal to either of the two. Below we state some
theorems without proving them:

99

Theorem 1: In a given graph G = (V, E), the shortest path from s to t, including edge pq, is comprised of the edge pq (traversed along the arc pq or arc qp) and
the shortest pair of vertex-disjoint paths, one path connecting s to p (or q) and the
other connecting q (or p) to t.
Theorem 2: In the given algorithm, the process of cutting one edge at a time
until the shortest path from s to t slides over edge pq does not disconnect t from s,
i.e., the algorithm always converges to a feasible solution.
Theorem 3: Path SP (s, t) after termination of the algorithm comprises paths
SP 1, SP 2, and edge pq (arc pq or qp)
Once a solution is obtained, using the above heuristic, the problem, Eq. (2), is
solved as follows:
Instead of cutting the first non-overlapping edge (see Step 6 of the algorithm),
increment its weight:
xj = l(Pf ) − l(Pj ) + e,

(3.4)

where xj is the weight increment for the first non-overlapping edge encountered in
the jth iteration of Steps 6-9 of the algorithm; l(Pj ) is the length of the corresponding shortest path (SP (s, t) or SP (t, s), as the case may be); l(Pf ) is the length of
the final desired path; l(Pf ) = l(SP 1) + l(SP 2) + wpq , where w indicates an edge
weight; e is an infinitesimally small positive number. For the integral weights, e
= 1. The increment xj defined above is the minimal amount needed to make path
Pj greater (in length) than the desired path Pf ; as a result, the latter becomes the
shortest path in the final (modified) graph.

4. Discussion

The Sliding Shortest Path Algorithm is presented as a heuristic for the difficult
problem, Eq. (1). Its extension via Eq. (4) then solves the problem, Eq. (2). The
algorithm is easily extended to the case of rerouting over a specified vertex by
collapsing the constraint edge into a single vertex. The efficiency of the algorithm
is determined by the number of times the Dijkstra algorithm has to be run. In the
worst-case scenario, where almost all the edges have to be cut, the efficiency is i)
O(|V |2 )ρ for dense graphs (almost fully connected), 2) O(|V |)ρ for sparse graphs
(almost tree-like), where ρ denotes the efficiency of the Dijkstra algorithm. ρ is
O(|V |2 ), and there are improvements due to more efficient implementations [7].
The heuristic is therefore very fast and its computer code has successfully run on
graphs consisting of as many as 200,000 vertices.
The edge cuts in the algorithm emanate from the reference path SP 1 or SP 2,
100

depending upon whether it is the first run or the second. Larger the degree of the
vertices of the reference path, larger the number of edges that would be cut on
the average. As a result, |Γ(1)| and |Γ(2)| can be significantly different, depending
upon the densities (degrees of vertices) of the subgraphs the paths SP 1 and SP 2
lie in. Furthermore, based on our initial theoretical studies of very small graphs
(10 vertices or so), we expect the algorithm to perform well (i.e., give a solution
close to the true solution) in graphs with approximately uniform density, but, in
those (uncommon) instances, where the density of the graph in the region between
the reference paths, SP 1 and SP 2, may drop sharply, we expect the performance
to degrade because the algorithm looks only along the paths SP 1 and SP 2 for
cuts, and not away from them. One way to assess the performance of this heuristic computationally is by comparing its results directly with the optimal solutions.
The optimal solution to the problem can be obtained in the following way: try all
possible cutsets, starting with cutsets of cardinality unity, then cutsets of cardinality two, and so on (at least one edge in the cutset always belonging to the initial
path, SP (s, t)) until the desired shortest path is obtained. Such a method, however,
quickly becomes exponential in run time. In the detailed version of the paper and
the talk, we will provide numerical results of the algorithms’s performance, keeping
in mind the inefficiency of the optimal solution method.

References
[1] B. Fortz and M. Thorup, Internet Traffic Engineering by Optimizing OSPF
Weights, Proc. of the 19th IEEE INFOCOM, Tel-Aviv, Israel (2000) pp.519528
[2] B. Fortz and M. Thorup, Optimizing OSPS/IS-IS Weights in a Changing
World, IEEE Journal on Selected Areas in Communications, 20 (2002) pp
756-767
[3] W. Ben-Ameur and E. Gourdin, Internet Routing and Related Topology Issues, SIAM Journal of Discrete Mathematics, 17(1) (2003) pp. 18-49
[4] A. Bley, Finding Small Administrative Lengths for Shortest Path Routing,
Proc. of 2nd International Network Optimization Conference, Lisbon, Portugal (2005) pp.121-128.
[5] R.K. Ahuja, T.L. Magnanti, J.B. Orlin, Network Flows: Theory, Algorithms,
and Applications, Prentice Hall, 1993.
[6] R. Bhandari, Survivable Networks: Algorithms for Diverse Routing, Kluwer
Academic Publishers, 1998.
[7] M. Gondran and M. Minoux, Graphs and Algorithms, John Wiley, 1990.

101

Quadratic Programming

Lecture Hall A

Tue 2, 15:45–16:45

A polynomial-time recursive algorithm for some
unconstrained quadratic optimization problems
Walid Ben-Ameur, a José Neto a
a Institut

TELECOM, TELECOM & Management SudParis, CNRS Samovar,
9, rue Charles Fourier, 91011 Evry, France
{Walid.Benameur,Jose.Neto}@it-sudparis.eu

Key words: arrangements, unconstrained quadratic programming, complexity

1. Introduction
Consider a quadratic function q : Rn → R given by: q(x) = xt Qx, with Q ∈
Rn×n . An unconstrained (−1, 1)-quadratic optimization problem can be expressed
as follows:
(QP ) Z ∗ = min{q(x) | x ∈ {−1, 1}n },
where {−1, 1}n denotes the set of n-dimensional vectors with entries either equal to
1 or −1. We consider here that the matrix Q is symmetric and given by its spectrum,
i.e. the set of its eigenvalues and associated unit pairwise orthogonal eigenvectors.
Problem (QP ) is a classical combinatorial optimization problem with many
applications, e.g. in statistical physics and circuit design [2; 8; 10]. It is well-known
that any (0,1)-quadratic problem expressed as: min{xt Ax + ct x | x ∈ {0, 1}n },
A ∈ Rn×n , c ∈ Rn , can be formulated in the form of problem (QP ) and conversely
[9; 4].
The contribution of this work is 3-fold:
(i) We slightly extend the known polynomially solvable cases of (QP ) to when
the matrix Q has fixed rank and the number of positive diagonal entries is
O(log(n)).
(ii) We introduce a new (to our knowledge) polynomial-time algorithm for solving
problem (QP ) when it corresponds to such a polynomially solvable case.
(iii) Preliminary experiments indicate that the proposed method may be computationally efficient. [7] .

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. Properties of optimal solutions for peculiar instances of (QP )
Let us firstly introduce some notation to be used hereafter. The eigenvalues
of the matrix Q will be noted λ1 (Q) ≤ λ2 (Q) ≤ . . . ≤ λn (Q) (or more simply
λ1 ≤ λ2 ≤ . . . ≤ λn when clear from the context) and the corresponding unit (in
Euclidean norm) and pairwise orthogonal eigenvectors: v1 , . . . , vn . The j-th entry
of the vector vi is noted vij . Given some set of vectors a1 , . . . , aq ∈ Rn , q ∈ N, we
note Lin(a1 , . . . , aq ) the subspace spanned by these vectors.
In this section we shall make the following assumptions on the matrix Q:
(i) Q has rank p ≤ n,
(ii) Q has nonpositive diagonal entries only, and
P
(iii) Q is given by its set of rational eigenvalues and eigenvectors: Q = pi=1 λi vi vit .

Any optimal solution y ∗ to the problem miny∈{−1,1}n y t Qy can be shown to
satisfy the following implication:
p
X
i=1

λi αi vij > 0 ⇒ yj∗ = −1

(2.1)

And analogously:
p
X
i=1

λi αi vij < 0 ⇒ yj∗ = 1.

(2.2)

From this simple property we can namely show that in order to find an optimal solution of problem (QP ), it is sufficient to enumerate over all vectors y ∈ {−1, 1}n for
P
which there exists a vector α ∈ Rp such that yj = −sign( pi=1 λi αi vij ) (or equivaP
P
lently yj = sign( pi=1 λi αi vij ), see hereafter), pi=1 λi αi vij 6= 0, ∀j ∈ {1, . . . , n},
with sign(x) = 1 if x > 0 and −1 if x < 0. In the next section we focus on finding
such a set of vectors.

3. Determining cells in an arrangement of n hyperplanes
Let v1 , ..., vp ∈ Rn denote p independent vectors. Let V ∈ Rn×p denote the
matrix whose columns correspond to the vectors v1 , . . . , vp and Vi the i-th row of V .
From this set of vectors we define n hyperplanes in Rp : Hj = {α ∈ Rp | Vj .α = 0}
with j ∈ {1, . . . , n}. Then we can notice that there is a one-to-one correspondence
between the set of vectors in {−1, 1}n for which there exists a vector α ∈ Rp such
P
P
that yj = sign( pi=1 αi vij ), with pi=1 αi vij 6= 0, ∀j ∈ {1, . . . , n} and the cells
(i.e. the full dimensional regions) in Rp of the hyperplane arrangement A(H) that
is defined by the family of hyperplanes (Hj )nj=1 . To see this just interpret the sign
vector y as the position vector of the corresponding cell c w.r.t. an orientation of
106

the space by the vector Vj : cell c is above hyperplane Hj iff yj > 0 and under
otherwise.
For a general arrangement in Rp that is defined by n hyperplanes (see e.g.
[6; 11] for
further elements on arrangements), the number of cells is upper bounded
Pp n
by i=0 i (which is in O(np )). (For a proof we refer the reader e.g., to Lemma
1.2 in [6]). In our case, since all the hyperplanes considered contain the origin (i.e.
the arrangement is central), this number reduces to O(np−1 ) (see Section 1.7 in
[6]).
We have introduced [3] a simple procedure with time complexity lying between the time complexity of the incremental algorithm [6; 5] (in O(np−1 )) and
that of the reverse search algorithm [1; 7] (in O(n LP (n, p) C) where C denotes
the number of cells in A(H) and LP (n, p) is the time needed to solve a linear program with n inequalities and p variables) in order to compute a set of vectors in
{−1, 1}n corresponding to a description of a set containing the cells of the arrangement A(H). Space complexity can be shown to be polynomially bounded by the
ouput size. To our view the interest of the proposed method by comparison with the
former ones is 2-fold:
(i) it is very easy to understand and implement,
(ii) computationally, by using proper data structures (to be specified latter) we
could solve instances of the same magnitude as the ones reported in [7], without parallelization and substantially improved computation times.
The basic principle of the proposed method may be expressed as follows.
Given some integer q ∈ {1, . . . , n}, let Bq (H) denote the arrangement in the
subspace {α ∈ Rp | Vq α = 0} that is defined by the hyperplanes (in Rp−1)
{Hj ∩ Hq | j ∈ {1, . . . , n} and j 6= q}. Any cell of Bq (H) (which is a region
of dimension p − 1) corresponds to a facet of exactly two cells of the arrangement
A(H) i.e. one on each side of the hyperplane Hq . The other cells of A(H) i.e. those
not intersecting Hq , are cells of the arrangement C q (H) in Rp which is defined by
the n − 1 hyperplanes {Hj | j ∈ {1, . . . , n} and j 6= q}. Since each cell of A(H)
intersects at least one of the hyperplanes (Hj )nj=1, it follows that all the cells of
A(H) can be derived from the ones of all the arrangements Bq (H), q = 1, . . . , n.
A recursive use of this argument leads to the generation of all the cells of A(H).
From a complexity study of the proposed method we can show the following
result.
Theorem 3.1. For a fixed integer p ≥ 2, if the matrix Q (given by its nonzero
eigenvalues and associated eigenvectors) has rank at most p and O(log(n)) positive
diagonal entries, then problem (QP ) can be solved in strongly polynomial time.

107

4. Conclusion

We propose a new (up to our knowledge) approach for solving in polynomial
time some unconstrained quadratic optimization problems. Preliminary computational results illustrate that the recursive procedure briefly presented here can be
a valuable approach on some instances by comparison with a reverse search w.r.t.
computation times.
Further computational studies are under work and could involve a parallelization of the code in order to deal with larger instances.

References
[1] D. Avis and K. Fukuda: Reverse search for enumeration. Discrete Applied
Mathematics 65, 21-46 (1996)
[2] F. Barahona and M. Grötschel and M. Jünger and G. Reinelt: An application of
Combinatorial Optimization to Statistical Physics and Circuit Layout Design.
Operations Research 36, 493–513 (1988)
[3] W. Ben-Ameur and J. Neto: Spectral bounds for the maximum cut problem.
Institut TELECOM, TELECOM & Management SudParis, Evry. Rapport de
recherche 08019-RS2M (2008)
[4] C. De Simone: The cut polytope and the Boolean quadric polytope. Discrete
Mathematics 79, 71-75 (1990)
[5] H. Edelsbrunner and J. O’Rourke and R. Seidel: Constructing arrangements
of lines and hyperplanes with applications. SIAM Journal on Computing 15,
341-363 (1986)
[6] H. Edelsbrunner: Algorithms in Combinatorial Geometry. Springer (1987)
[7] J.A. Ferrez and K. Fukuda and T.M. Liebling: Solving the fixed rank convex quadratic maximization in binary variables by a parallel zonotope construction algorithm. European Journal of Operational Research 166(1), 35-50
(2005)
[8] M. Grötschel and M. Jünger and G. Reinelt: Via minimization with pin preassignment and layer preference. Zeitschrift für Angewandte Mathematik und
Mechanik, 69, 393–399 (1989)
[9] P. Hammer: Some network flow problems solved with pseudo-Boolean programming. Operations Research 32, 388-399 (1965)
[10] R.Y. Pinter: Optimal Layer Assignment for Interconnect. J. VLSI Comput.
Syst. 1, 123–137 (1984)
[11] G. M. Ziegler: Lectures on Polytopes, Graduate Texts in Mathematics 152.
Springer-Verlag New-York (1995)

108

Finding tight RLT formulations for Quadratic
Semi-Assignment Problems
Ingmar Schüle, a Hendrik Ewe, a Karl-Heinz Küfer a
a Fraunhofer

Institute for Industrial Mathematics, Kaiserslautern, Germany
ingmar.schuele@itwm.fraunhofer.de

Key words: Quadratic Semi-Assignment Problem, Reformulation Linearization
Technique

1. Introduction

A wide range of combinatorial optimization problems can be formulated as
Quadratic Semi-Assignment Problems (QSAP). The QSAP usually describes the
assignment of resources to consumers and is a generalization of the widely studied
Quadratic Assignment Problem (QAP).
Not only are both QAP and QSAP hard to solve in theory (the decision problems are NP-hard) but also in practice today’s computer systems are often unable
to solve even small instances to optimality. In order to get a lower bound for the
solution, a Reformulation Linearization Technique (RLT) can be applied resulting
in a Linear Program that is much easier to solve, cf. [1] and [2].
In this paper we present a graph-theoretical analysis of the RLT applied to
the QSAP. A class of graphs is constructed the size of which can be proven to be
minimal. It is then used to determine the level of the RLT necessary for a tight
formulation of the problem. A tight formulation here means that for all possible bij
and cijkl , the optimal objective function value of the RLT-t formulation equals the
optimal objective function value of the QSAP.

2. RLT formulation of the Quadratic Semi-Assignment Problem
Given the index sets M = {1, . . . , m} and Ni = {1, . . . , ni } ∀i ∈ M, the
Quadratic Semi-Assignment Problem is to assign to each i ∈ M exactly one ele-

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

ment j ∈ Ni . It is defined by the Mixed Integer Program (MIP)
ni
m X
X

min
s.t.

bij xij +

cijkl xij xkl

i=1 k=i+1 j=1 l=1

i=1 j=1
ni
X

j=1

nk
ni X
m X
X

m−1
X

xij = 1 ∀i ∈ M,

xij ∈ {0, 1}.
Note that we focus on the symmetric form where cijkl = cklij . When we apply the
level-1 Reformulation Linearization Technique we introduce new variables yijkl =
xij · xkl and some additional constraints. After relaxing all 0/1-variables we get the
linearized formulation
ni
m X
X

min
s.t.

bij xij +

i=1 j=1
ni
X

j=1
ni
X

j=1
nk
X

m−1
X

nk
ni X
m X
X

cijkl yijkl

i=1 k=i+1 j=1 l=1

xij = 1 ∀i ∈ M,

yijkl = xkl

∀i, k ∈ M (i < k), l ∈ Nk ,

yijkl = xij

∀i, k ∈ M (i < k), j ∈ Ni ,

l=1

xij ∈ [0, 1],

yijkl ∈ [0, 1].

3. Level-t RLT

To obtain the general level-t RLT formulation for the QSAP, we add new variables and constraints to the level-(t − 1) formulation. Accordingly, the new constraints are of the form
nk
X

(t+1)

(t)

ϑi1 j1 ,...,it+1jt+1 = ϑi1 j1 ,...,ik−1jk−1 ,ik+1 jk+1 ,...,it+1jt+1 ,

jk =1

∀k ∈ {1, ..., t + 1}, ∀i1 , ..., it+1 ∈ M (i1 < ... < it+1 ), ∀js ∈ Nis , s ∈ M \ {k}.
To complete the recursive definition of the RLT-t formulation, we set
ϑ(0) = 1,

(1)

(2)

ϑi1 j1 = xi1 j1 and ϑi1 j1 ,i2 j2 = yi1 j1 i2 j2 .

Each feasible solution of the RLT can be transformed into a solution-graph. In this
duality, a variable xij corresponds to a vertex vij and the linearized variables yijkl
with yijkl > 0 correspond to edges eijkl = {vij , vkl }. By induction it is easy to prove

110

that a solution-graph of a level-t RLT formulation contains at least one (t + 1)clique. Furthermore any solution-graph that contains an m-clique has a subgraph
that corresponds to a solution of the QSAP. Thus it follows that there is a finite
t for which the optimal objective function value of both the RLT and the original
MIP are identical. Note that any solution of the original MIP is also valid for the
RLT formulation since the additional constraints solely arise from multiplying both
sides of already existing constraints by certain variables.

4. Tightness of the RLT formulation
In this section we present a minimal graph GtRLT and a corresponding ϑvariable assignment that help to determine the minimal RLT-level that is necessary
for a tight RLT formulation. This graph satisfies the RLT-constraints up to level t
but does not contain a clique of size t + 2. We say that a graph satisfies the RLTconstraints if there exists a corresponding ϑ-variable assignment that satisfies the
constraints.

Fig. 1. Graph G2RLT not containing a 4-clique.
t
t
We define the graph GtRLT = (VRLT
, ERLT
) by
t
VRLT
= {vij : i ∈ {1, ..., t + 2}, j ∈ {1, ..., t + 1}} ,
t
ERLT = {eijkl : i, k ∈ {1, ..., t + 2} (i < k), j, l ∈ {1, ..., t + 1} (j 6= l)} .

The corresponding variable assignment that satisfies the RLT-constraints is
(1)

1
t
, if vij ∈ VRLT
,
t+1
v
Y
1
=
, ∀v ∈ {2, ..., t + 1},
s=1 (t + 2 − s)
t
if ∃k, l ∈ {1, ..., v} (k < l) : eik jk il jl ∈ ERLT
,

ϑij = xij =
(v)

ϑi1 j1 ,...,iv jv

and zero for all other variables. The following theorem deals with the minimality
of GtRLT in the context of the given problem.

111

Theorem 4.1. GtRLT is the minimal graph that satisfies all RLT-constraints up to
level t and that contains no (t + 2)-clique.
We omit the full proof due to space limitations. The main ideas are the following
four steps:
– show that GtRLT satisfies the RLT-t-constraints,
– show that GtRLT contains no (t + 2)-clique,
– show that for any graph that satisfies the RLT-t-constraints and that contains
no (t + 2)-clique ∃S ⊆ M, |S| ≥ t + 2, such that ∀i ∈ S : ni ≥ t + 1,
t
– show that there is no graph with less edges than |ERLT
| that satisfies the RLTt-constraints and that contains no (t + 2)-clique.
As a result from Theorem 1 we directly obtain for each M and the corresponding
sets Ni , i ∈ M, the smallest number tmin for which the RLT-t formulation is tight.
If the sets Ni are ordered according to their size (n1 < ... < nm ), tmin is defined by
tmin = min{t ∈ N : nt+2 < t + 1}.
5. Conclusion and future work

In this paper we presented some theoretical results on the tightness of the RLT-t
formulation for the QSAP. The gained insights can be used e.g. in a stepwise elimination process of possible occurences of the minimal graphs GtRLT in the problem
formulation. A first implementation of such an algorithm showed promising results
compared to established approaches. As future work we plan to transfer our results
to the QAP.

References
[1] Adams, W.P., Guignard, M., Hahn, P.M. and Hightower, W.L. A level-2
reformulation-linearization technique bound for the quadratic assignment
problem, European Journal of Operational Research, 180, 3, p. 983–996,
2007.
[2] Hahn, P.M., Kim, B., Guignard, M., Smith, J.M. and Zhu, Y., An algorithm
for the generalized quadratic assignment problem Comput. Optim. Appl. 40,
3, p. 351–372, Kluwer Academic Publishers, Norwell, MA, USA, 2008.

112

Trees

Lecture Hall B

Tue 2, 15:45–16:45

Colored trees in edge-colored graphs
A. Abouelaoualim, a V. Borozan, a Y. Manoussakis, a
C. Martinhon, b R. Muthu, a R. Saad a
a University
b Inst.

of Paris-XI, Orsay LRI, Bât. 490, 91405 Orsay Cedex, France

of Comp. / Fluminense Federal University, Niterói, Brazil

Key words: Colored spanning trees, acyclic graph, c-edge-colored graph,
nonapproximability bounds, polynomial algorithms, NP-completeness

1. Introduction

The study of problems modeled by edge-colored graphs has given rise to important developments during the last few decades. For instance, the investigation
of spanning trees for graphs provide important and interesting results both from a
mathematical and an algorithmic point of view (see for instance [1]). From the point
of view of applicability, problems arising in molecular biology are often modeled
using colored graphs, i.e., graphs with colored edges and/or vertices [6]. Given such
an edge-colored graph, original problems translate to extracting subgraphs colored
in a specified pattern. The most natural pattern in such a context is that of a proper
coloring, i.e., adjacent edges having different colors. Refer to [2; 3; 5] for a survey
of related results and practical applications. Here we deal with some colored versions of spanning trees in edge-colored graphs. In particular, given an edge-colored
graph Gc , we address the question of deciding whether or not it contains properly
edge colored spanning trees or rooted edge-colored trees with a given pattern.
Formally, let Ic = {1, 2, . . . , c} be a given set of colors, c ≥ 2. Throughout,
Gc denotes an edge-colored simple graph, where each edge is assigned some color
i ∈ Ic . The vertex and edge-sets of Gc are denoted V (Gc ) and E(Gc ), respectively.
The order of Gc is the number n of its vertices. A subgraph of Gc is said to be
properly edge-colored if any two of its adjacent edges differ in color. A tree in Gc
is a subgraph such that its underlying non-colored graph is connected and acyclic.
A spanning tree is one covering all vertices of Gc . From the earlier definitions, a
properly edge-colored tree is one such that no two adjacent edges are on a same
color. A tree T in Gc with fixed root r is said to be weakly properly edge-colored
if any path in T , from the root r to any leaf is a properly edge-colored one. To
facilitate discussions, in the sequel a properly edge-colored (weakly properly edgecolored) tree will be called a strong (weak) tree. Notice that in the case of weak
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

trees, adjacent edges may have the same color, while this may not happen for strong
trees. When these trees span the vertex set of G, they are called strong spanning
tree (SST) and weak spanning tree (WST).
Here we prove that the problems of finding SST and WST in colored graphs
are both NP-complete. The problem of SST remains NP-complete even when restricted to the class of edge-colored complete graphs. We present nonapproximability results by considering the optimization versions of these problems. We provide
polynomial time algorithms for these problems on the important class of colored
acyclic graphs, i.e. graphs without properly edge-colored cycles. We also present
an interesting graph theoretic characterization of colored complete graphs which
have SSTs.
2. NP-completeness and nonapproximability
The SST problem is NP-complete for Gc if c is a constant, because it generalizes the degree-constrained spanning tree problem, which extends the Hamiltonian
path problem. Here, the degree constraint of a node v is the number of different colors used on its incident edges. The next result is a stronger one, and is proved using
a kind of self-reduction from the SST problem on a constant number of colors.
Theorem 2.1. The SST is NP-complete even for c = Ω(n2 ).
The hardness result for WST stated below is obtained by a reduction from the 3-SAT
problem.
Theorem 2.2. Given a 2-edge colored graph Gc = (V, E c ) and a specified vertex
r of V , it is NP-complete to determine if Gc has a WST rooted at r.
We view the optimization versions of these problems as finding the corresponding
trees covering as many vertices as possible. The following results on nonapproximability bounds are obtained by the gap-reduction technique using the MAX-3-SAT
problem.
Theorem 2.3. The maximum weighted tree (MWT) problem is nonapproximable
within 63/64 +  for  > 0 unless P = NP .
Theorem 2.4. The maximum strong tree (MST) problem is nonapproximable within
53/54 +  for  > 0 unless P = NP .
3. Colored trees in acyclic edge-colored graphs
In this section, we present results demonstrating that the SST and WST problems can be solved efficiently when restricted to the class of edge colored-acyclic
graphs. We present a proof sketch and an algorithm for the SST problem on colored acyclic complete graphs. The case of SST on general colored acyclic graphs is
similar, but more involved and appears in a longer version of the paper. We do not
provide the details of the WST problem either, due to space constraints.
An important tool we use is a theorem due to Yeo ([7],[4]), which states that
every colored acyclic graph has a vertex v, such that the edges between any component Ci of G \ v and v are monochromatic. We call such a vertex a yeo-vertex. If
in addition, the colors of the edges between v and the various components obtained

116

by deleting it are all distinct, we call it a rainbow yeo-vertex. It is easy to see that a
colored acyclic graph with a nonrainbow yeo-vertex has no SST.
For the rest of this section, we assume we are dealing with colored acyclic
complete graphs (Knc -acyclic). We compute a partial ordering of the vertices and
construct the SST by incorporating the vertices in the reverse of this order. The first
block consists of all the yeo-vertices of the graph. They induce a monochromatic
clique and the edges between this group of vertices and the rest of the graph are
also monochromatic with the same color. We repeat this procedure iteratively, by
considering the residual (also) acyclic complete graph obtained by deleting these
vertices from the original graph. The second block is also monochromatic but with
a different color.
We use k to denote the number of blocks in the above partial order and the
blocks themselves are denoted B1 , . . . , Bk . We use ci to denote the associated color
of block Bi . Recall that the color associated with successive blocks differ. We denote the total number of vertices in the blocks Bi , . . . , Bk by ti and the number of
such vertices whose associated color is l by tli . We now state a lemma, which given
an acyclic edge colored complete graph determines whether or not it contains an
SST.
Lemma 3.1. (SST-Complete Acyclic) An acyclic edge colored complete graph has
an SST iff
(i) Last block Bk has two vertices, and
(ii) for each i < k,
• IF block Bi has the same color as the last block Bk , THEN
tci i − 2 ≤ t2i .
• ELSE tci i ≤ t2i .
We now describe our algorithm to construct the SST. It is based on the previous
lemma. Its running time is O(n2 ), as it can be implemented by modifying the basic
Breadth-First-Search (BFS) procedure.

117

Algorithm 1 SST for Knc -acyclic
1: compute the order described above
2: if last block Bk has more than two vertices then return “No SST”
3: if last block Bk has two vertices then connect the two vertices of Bk to get an
initial Strong Tree
4: for i = k − 1 to 1 do
5:
if condition 2 of Lemma 3.1 is true then
6:
join the vertices of Bi as leaves, to distinct vertices already incorporated
in the tree which have not used an edge of color ci in the partial strong
tree obtained in the previous iteration.
7:
else
8:
return ”NO SST”
9:
end if
10: end for
11: return the SST
To conclude this section, we now state our more general result.
Theorem 3.2. The
colored graphs.

SST

and

WST

problems can be solved efficiently for acyclic

4. Properly edge-colored spanning trees in edge-colored complete graphs
The SST problem remains hard even when stringently restricted, as the following result states. The hardness is proved by a reduction from the SST problem in
general graphs.
Theorem 4.1. The SST is NP-complete for complete graphs Knc , colored with |c| ≥
3 colors.
Observe, that for the case c = 2, the SST problem reduces to the Hamiltonian Path problem, which is known to be polynomial [3]. Notice also that the WST
problem is trivial in Knc as any spanning star is a WST. Concerning SST, we provide below a graph-theoretic characterization for edge-colored complete graphs Knc
which have SSTs. This characterization is interesting from a mathematical point of
view, but the implied conditions cannot be computed in polynomial time, in view
of the hardness result above.
Theorem 4.2. Assume that the vertices of Knc are covered by a strong tree T and a
set of properly edge-colored cycles, say C1 , C2 · · · , Ck all these components being
pairwise vertex-disjoint in Knc . Then Knc has a strong spanning tree.
References
[1] R. K. Ahuja, T. L. Magnanti, J. B. Orlin, Network Flows: Theory, Algorithms
and Applications, Prentice Hall, 1993.
[2] J. Bang-Jensen, G. Gutin, Digraphs: Theory, Algorithms and Applications,
Springer, 2002.
[3] A. Benkouar, Y. Manoussakis, V. T. Paschos, R. Saad, On the Complexity of

118

[4]

[5]
[6]
[7]

Some Hamiltonian and Eurelian Problems in Edge-colored Complete Graphs
RAIRO - Operations Research, 30, 417-438, 1996.
J. Grossman and R. Häggkvist, properly edge-coloredCycles in EdgePartioned Graphs, Journal of Combinatorial Theory, Series B, 34 (1983) 7781.
Y. Manoussakis, properly edge-coloredPaths in Edge-Colored Complete
Graphs, Discrete Applied Mathematics, 56 (1995) 297-309..
P. A Pevzner, DNA Physical Mapping and Properly Edge-colored Eurelian
Cycles in Colored Graphs, Algorithmica, 13 (1995) 77-105 .
A. Yeo, A Note on Alternating Cycles in Edge-colored Graphs, Journal of
Combinatorial Theory, Series B 69 (1997) 222-225 .

119

Intermediate Trees ?
Kathie Cameron, a Joanna Fawcett b
a Université

Pierre et Marie Curie (Paris VI), Équipe Combinatoire et Optimisation, Paris,
France
kcameron@wlu.ca

b Department

of Pure Mathematics, University of Waterloo, Waterloo, Canada
joannafawcett@gmail.com

Key words: spanning tree, vertex degree, pivot algorithm

The intermediate spanning tree problem is: Given two distinct spanning trees,
T and T 0 , of a graph G, is there another spanning tree, T 00 , of G such that the degree
of each vertex in T 00 is between its degree in T and its degree in T 0 ? More precisely,
is there a spanning tree T 00 of G such that for each vertex v of G, either degT (v) ≤
degT 00 (v) ≤ degT 0 (v) or degT 0 (v) ≤ degT 00 (v) ≤ degT (v), where degH (v) denotes
the degree of vertex v in H? Such a tree T 00 is called an intermediate tree of T and
T 0.
The intermediate spanning tree problem is NP-hard in general.
A theorem of Ken Berman [1] implies that if T and T 0 are edge-disjoint and
don’t have the same degree at each vertex, then an intermediate tree T 00 exists.
Cameron and Edmonds [2] gave an algorithm which finds the intermediate tree in
this case.
Generally, some pairs of spanning trees in a graph will have an intermediate
tree and others won’t. For example, in the cycle C4 on four vertices, v1 , v2 , v3 , v4 , v1 ,
there are four spanning trees, and each is a hamiltonian path: T1 from v1 to v4 , T2
from v2 to v1 , T3 from v3 to v2 , and T4 from v4 to v3 . Trees T1 and T3 have T2 and
T4 as intermediate trees, but T1 and T2 have no intermediate tree.
We have characterized the graphs in which no pair of spanning trees has an intermediate tree. One such graph is the complete graph on three vertices, K3 , which
has three spanning trees, no two of which have an intermediate tree. However, as
? Research supported by the Natural Sciences and Engineering Research Council of
Canada.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

the following theorem shows, K3 is essentially the only graph where no pair of
spanning trees has an intermediate tree.
Theorem 1. Let G be a simple connected graph with at least 3 vertices. No
pair of spanning trees of G has an intermediate tree if and only if G consists of K3
together with a tree rooted at each vertex of the K3 .
We are interested in characterizing the graphs in which every pair of spanning
trees has an intermediate tree.
Theorem 2. In the following classes of graphs, every pair of spanning trees
has an intermediate tree:
• Complete graphs Kn where n ≥ 5
• Complete bipartite graphs Km,n where m, n ≥ 4
Note that each of K4 and K3,4 contains a pair of spanning trees that have no
intermediate tree.
In most cases, we can find an intermediate tree of a given pair of spanning trees
in graph G by adding at most one edge to G.

References
[1] Kenneth A. Berman, Parity results on connected f -factors, Discrete Math. 59
(1986), 1-8.
[2] Kathie Cameron and Jack Edmonds, Some graphic uses of an even number of
odd nodes, Ann. Inst. Fourier 49 (1999), 815-827.
[3] Douglas B. West, Introduction to Graph Theory, Prentice Hall, Upper Saddle
River, 2001.

121

Plenary Session I

Lecture Hall A

Tue 2, 16:45-17:30

Bilevel Programming and Maximally Violated Valid
Inequalities
Andrea Lodi, a Ted K. Ralphs b
a DEIS,

University of Bologna
Viale Risorgimento 2, 40136, Bologna
andrea.lodi@unibo.it
b Department

of Industrial and Systems Engineering
Lehigh University, Bethlehem, PA 18015
ted@lehigh.edu

Key words: Bilevel Programming, Cutting Planes, Separation

1. Introduction

In recent years, branch-and-cut algorithms have become firmly established
as the most effective method for solving generic mixed integer linear programs
(MIPs). Methods for automatically generating inequalities valid for the convex hull
of solutions to such MIPs are a critical element of branch-and-cut. This paper examines the nature of the so-called separation problem, which is that of generating
a valid inequality violated by a given real vector, usually arising as the solution
to a relaxation of the original problem. We show that the problem of generating
a maximally violated valid inequality often has a natural interpretation as a bilevel
program. In some cases, this bilevel program can be easily reformulated as a singlelevel mathematical program, yielding a standard mathematical programming formulation for the separation problem. In other cases, no reformulation exists. We
illustrate the principle by considering the separation problem for two well-known
classes of valid inequalities.
Formally, we consider a MIP of the form
min{c> x | Ax ≥ b, x ≥ 0, x ∈ ZI × RC },

(1.1)

where A ∈ Qm×n , b ∈ Qm , c ∈ Qn , I is the set of indices of components that must
take integer values in any feasible solution and C consists of the indices of the
remaining components. We assume that other bound constraints on the variables (if
any) are included among the problem constraints.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

The continuous or linear programming (LP) relaxation of the above MIP is
the mathematical program obtained by dropping the integrality requirement on the
variables in I, namely
min c> x,

(1.2)

x∈P

where P = {x ∈ Rn | Ax ≥ b, x ≥ 0} is the polyhedron described by the linear
constraints of the MIP (1.1). It is not difficult to see that the convex hull of the
set of feasible solutions to (1.1) is also a polyhedron. This means that in principle,
any MIP is equivalent to a linear program over this implicitly defined polyhedron,
which we denote as PI .
A bilevel mixed integer linear program (BMIP) is a generalization of a standard
MIP used to model hierarchical decision processes. In a BMIP, the variables are
split into a set of upper-level variables, denoted by x below, and a set of lowerlevel variables, denoted by y below. Conceptually, the values of the upper-level
variables are fixed first, subject to the restrictions of a set of upper-level constraints,
after which the second-stage variables are fixed by solving a MIP parameterized on
the fixed values of the upper-level variables. The canonical integer bilevel MIP is
given by
n

min c1 x + d1 y | x ∈ PU ∩ (ZI1 × RC1 ),

o

y ∈ argmin{d2 y | y ∈ PL (x) ∩ (ZI2 × RC2 )} ,

where

n

PU = x ∈ Rn1 | A1 x ≥ b1 , x ≥ 0
is the polyhedron defining the upper-level feasible region;
n

o

PL (x) = y ∈ Rn2 | G2 y ≥ b2 − A2 x, y ≥ 0

o

is the polyhedron defining the lower-level feasible region with respect to a given
x ∈ Rn1 ; A1 ∈ Qm1 ×n1 ; b1 ∈ Qm1 ; A2 ∈ Qm2 ×n1 , G2 ∈ Qm2 ×n2 ; and b2 ∈ Qm2 .
The index sets I1 , I2 , C1 , and C2 are the bilevel counterparts of the sets I and C defined previously. For more detailed information, [5] provide an introduction to and
comprehensive survey of the bilevel programming literature, while [14] introduce
the discrete case. [9] provides a detailed bibliography.
A valid inequality for a set § ⊆ Rn is a pair (α, β), where α ∈ Rn is the
coefficient vector and β ∈ R is the right-hand side, such that α> x ≥ β for all x ∈ §.
Associated with any valid inequality (α, β) is the half-space {x ∈ Rn | αx ≥ β},
which must contain §. It is easy to see that any inequality valid for § is also valid
for the convex hull of §.
For a polyhedron Q ⊆ Rn , the so-called separation problem is to generate
a valid inequality violated by a given vector. Formally, we define the problem as
follows.
126

Definition 1. The separation problem for a polyhedron Q is to determine for a
given x̂ ∈ Rn whether or not x̂ ∈ Q and if not, to produce an inequality (ᾱ, β̄) ∈
Rn+1 valid for Q and for which ᾱ> x̂ < β̄.
A closely associated problem that is more relevant in practice is the maximally
violated valid inequality problem (MVVIP), which is as follows.
Definition 2. The maximally violated valid inequality problem for a polyhedron Q
is to determine for a given x̂ ∈ Rn whether or not x̂ ∈ Q and if not, produce an inequality (ᾱ, β̄) ∈ Rn+1 valid for Q and for which (ᾱ, β̄) ∈ argmin (α,β)∈Rn+1 {α> x̂−
β | α> x ≥ β ∀x ∈ Q}.
It is well-known that both the separation problem and the MVVIP for a polyhedron
Q are polynomially equivalent to the associated optimization problem, which is to
determine minx∈Q d> x [12] for a given d ∈ Rn . In the present context, this means
it is unlikely that the MVVIP for PI can be solved easily unless the MIP itself can
be solved easily.
Because the general MVVIP is usually too difficult to solve, valid inequalities
are generated by solving (either exactly or approximately) the MVVIP for one or
more relaxations of the original problem. These relaxations often come from considering valid inequalities in a specific family or class, i.e., inequalities that share
a special structure. [1] called this paradigm for generation of valid inequalities the
template paradigm. Generally speaking, a class of valid inequalities for a given set
§ is simply a subset of all valid inequalities for §. Such subsets can be defined in
a number of ways and may be either finite or infinite. Associated with any given
class C is its closure FC , consisting of the region defined by the intersection of all
half-spaces associated with inequalities in the class. If the class is finite, then the
closure is a polyhedron. Otherwise, it may or may not be a polyhedron.
Let us consider a given class of valid inequalities C. Assuming the closure FC
is a polyhedron, both the separation problem and the MVVIP for C can be identified
with the previously defined separation problem and MVVIP for FC . A number of
authors have noted that the MVVIP for certain classes of valid inequalities can be
formulated as structured mathematical programs in their own right and solved using
standard optimization techniques (see, e.g., [2], [4] and [10]). We wish to show that
the underlying structure of the MVVIP is inherently bilevel.
The bilevel nature of the MVVIP for a class C arises from the fact that for
a given coefficient vector α ∈ Rn , the calculation of the right-hand side β required to ensure (α, β) is a member of the class (if such a β exists) may itself be
an optimization problem that we refer to as the right-hand side generation problem (RHSGP). The complexity of the separation problem depends strongly on the
complexity of the RHSGP. In cases where the RHSGP is in the complexity class
NP -hard, it is generally not possible to formulate the separation problem as a tradi-

127

tional mathematical program. In fact, such separation problems may not even be in
the complexity class NP. Roughly speaking, the reason for this is that the problem
of determining whether a given inequality is valid is then itself a hard problem.
Putting these question aside for now, however, let us simply define the set
Cα ⊆ Rn to be the projection of C into the space of coefficient vectors. In other
words, Cα is the set of all vectors that are coefficients for some valid inequality
in C. Then the MVVIP for C with respect to a given x̂ ∈ Rn can in principle be
formulated mathematically as
min α> x̂ − β
α ∈ Cα
β = min α> x
x ∈ FC .

(1.3)
(1.4)
(1.5)
(1.6)

The problem (1.3)–(1.6) is a bilevel program in which the upper-level objective (1.3)
is to find the maximally violated inequality in the class. The upper-level constraints (1.4) require that the inequality is a member of the class. The lower-level
problem (1.5)–(1.6) is to generate the strongest possible right-hand side associated
with a given coefficient vector.
It is easy to see that the above separation problem may be very difficult to
solve in some cases. In fact, the complexity depends strongly on the complexity
of the RHSGP and whether the sense of the optimization “agrees” with that of the
MVVIP itself. Most of the separation algorithms appearing in the literature define
the set FC in such a way that the bilevel program (1.3)–(1.6) collapses into a singlelevel program, generally linear or mixed integer linear.
In the remainder of the paper, we describe two well-known classes of valid inequalities and give a bilevel interpretation of their associated separation problems.
In Section 2, we consider the well-known class of disjunctive valid inequalities for
general MIPs. For such a class, we show that it is quite straightforward to convert the BMIP (1.3)–(1.6) into a single-level mathematical program, though the
MVVIP might nevertheless remain difficult from a practical standpoint. In Section
3, we focus on the so-called capacity constraints for the classical Capacitated Vehicle Routing Problem (CVRP). There are several closely-related variants of this
class of valid inequalities and we show that for the strongest of these, there is no
straightforward way to convert the BMIP into a single-level program. That is the
main contribution of the present paper, and to the best of our knowledge, it is a new
result. Finally, some conclusions are drawn in Section 4.

128

2. Disjunctive Valid Inequalities for general MIPs

Given a MIP in the form (1.1), [2] showed how to derive a valid inequality by
exploiting any disjunction of the form
π > x ≤ π0

OR π > x ≥ π0 + 1 ∀x ∈ Rn ,

(2.7)

where π ∈ ZI × 0C and π0 ∈ Z. More precisely, the family of disjunctive inequalities (also called split cuts) are all those valid for the union of the two polyhedra,
denoted by P1 and P2 , obtained from P by adding inequalities (−π, −π0 ) and
(π, π0 + 1), respectively.
For a given disjunction of the form (2.7), the separation problem for the associated family of disjunctive inequalities with respect to a given vector x̂ ∈ P can
be written as a the following bilevel LP:
min α> x̂ − β
αj ≥ u> Aj − uo πj j ∈ I ∪ U
αj ≥ v > Aj + vo πj j ∈ I ∪ U
u, v, u0, v0 ≥ 0
u0 + v0 = 1
β = min α> x
x ∈ P1 ∪ P2 .

(2.8)
(2.9)
(2.10)
(2.11)
(2.12)
(2.13)
(2.14)

Constraints (2.9) and (2.10) together with the non-negativity requirements on the
dual multipliers (2.11) ensure the coefficients constitute those of a disjunctive inequality. (Constraint (2.12) is one of the possible normalizations to make the mathematical program above bounded, see, e.g., [11].) Once the coefficient vector and
the corresponding dual multipliers are known, the RHSGP is easy to solve. To obtain a valid inequality, one has only to set β to min{u> b − u0 π0 , v > b + v0 (π0 + 1)},
which is the smallest of the right-hand sides obtained by the sets of multipliers
(u, u0) and (v, v0 ) corresponding to the constraints of P1 and P2 , respectively. It
is easy to reformulate the bilevel LP above into the following (single level) linear
program by a well-known modeling trick:
min α> x̂ − β
αj ≥ u> Aj − uo πj j ∈ I ∪ U
αj ≥ v > Aj + vo πj j ∈ I ∪ U
β ≤ u> b − u0 π0
β ≤ v > b + v0 (π0 + 1)
u0 + v0 = 1
u, v, u0, v0 ≥ 0.

129

(2.15)

(2.16)
(2.17)

Indeed, note that for given values of the remaining variables, any value of
β satisfying the two inequalities (2.16) and (2.17) above yields a valid disjunctive constraint. Furthermore, these two inequalities ensure that β ≤ min{u> b −
u0 π0 , v > b + v0 (π0 + 1)}, while the objective function (2.15) ensures that the largest
possible value of β is indeed selected, i.e., β = min{u> b−u0 π0 , v > b+v0 (π0 +1)}.
In other words, the objective function (2.15) gives for free the best value of the
right-hand side, thus finding the strongest cut.
If the disjunction is not given a priori, i.e., one is searching among the set
of possible disjunctions for the one yielding the most violated constraint, the above
program can still be used, but π and π0 become integer variables. The same trick can
be applied to transform the bilevel separation problem into a single-level one, but
the problem remains difficult because (i) some of the constraints contain bilinear
terms, and (ii) the program involves the integer variables π and π0 . The solution of
such a formulation has been addressed by [3] and [8].
3. Capacity Constraints for the CVRP

Here, we consider the classical Capacitated Vehicle Routing Problem (CVRP),
as introduced by [7], in which a quantity di of a single commodity is to be delivered
to each customer i ∈ N = {1, . . . , n} from a central depot {0} using a homogeneous fleet of k vehicles, each with capacity K. The objective is to minimize total
cost, with cij ≥ 0 denoting the fixed cost of transportation from location i to location j, for 0 ≤ i, j ≤ n. The costs are assumed to be symmetric, i.e., cij = cji and
cii = 0.
This problem is naturally associated with the complete undirected graph consisting of nodes N ∪ {0}, edge set E = N × N, and edge costs cij , {i, j} ∈ E. In
this graph, a solution is the union of k cycles whose only intersection is the depot
node and whose union covers all customers. By associating an integer variable with
each edge in the graph, we obtain the following integer programming formulation:
min

X

ce xe

e∈E

X

xe = 2k

(3.18)

xe = 2 ∀i ∈ N

(3.19)

xe ≥ 2b(S) ∀S ⊂ N, |S| > 1

(3.20)

e={0,j}∈E

X

e={i,j}∈E

X

e={i,j}∈E
i∈S,j6∈S

0 ≤ xe ≤ 1 ∀e = {i, j} ∈ E, i, j 6= 0
0 ≤ xe ≤ 2 ∀e = {0, j} ∈ E
xe integral ∀e ∈ E.
130

(3.21)
(3.22)
(3.23)

Constraints (3.18) and (3.19) are the degree constraints. In constraints (3.20), referred to as the capacity constraints, b(S) is any of several lower bounds on the
number of trucks required to service the customers in set S. These constraints can
be viewed as a generalization of the subtour elimination constraints from the Traveling Salesman Problem and serve both to enforce the connectivity of the solution
and to ensure that no route has total demand exceeding the capacity K. The easily
P
calculated lower bound i∈S di/K on the number of trucks is enough to ensure the
formulation (3.18)–(3.23) is correct, but increasing this bound through the solution
of a more sophisticated RHSGP will yield a stronger version of the constraints.
The MVVIP for capacity constraints with a generic lower bound b(S) can be
formulated as a BMIP of the form (1.3)–(1.6) as follows. Because we are looking
for a set S̄ ⊂ N for which an inequality (3.20) is maximally violated, we define the
binary variables
yi =
and
ze =



1

0



1


0

if customer i belong to S̄

i ∈ N,

(3.24)

e ∈ E,

(3.25)

otherwise

if edge e belong to δ(S̄)
otherwise

where δ(S̄) denotes the set of edges in E with one endpoint in S̄, to model selection
of the members of the set S̄ and the coefficients of the corresponding inequality.
Thus, the formulation is
min

X

e∈E

x̂e ze − 2b(S̄)

(3.26)

ze ≥ yi − yj
ze ≥ yj − yi
max b(S̄)
b(S̄) is a valid lower bound.

∀e = {i, j}
∀e = {i, j}

(3.27)
(3.28)
(3.29)
(3.30)

For improved tractability, the RHSGP (3.29)–(3.30) can be replaced by the calculation of a specific bound. One of the strongest possible lower bounds is obtained
by solving to optimality the (strongly NP -hard) Bin Packing Problem (BPP) with
the customer demands in set S̄ being packed into the minimum number of bins of
size K ([6] describe a further strengthening of the right-hand side, but we we do
not consider this bound here). The RHSGP based on the BPP can be modeled by

131

using the binary variables
wi` =



1

h` =



1

and


0


0

if customer i is served by vehicle `

(i ∈ N, ` = 1, . . . , k), (3.31)

otherwise

if vehicle ` is used

(` = 1, . . . , k).

(3.32)

otherwise

Then the full separation problem reads as follows:
min

X

e∈E

x̂e ze − 2b(S̄)

ze ≥ yi − yj
ze ≥ yj − yi
b(S̄) = min

n
X

(3.33)
∀e = {i, j}
∀e = {i, j}

h`

`=1
n
X

(3.36)

wi` = yi

∀i ∈ N

(3.37)

` = 1, . . . , n,

(3.38)

`=1

X

i∈N

(3.34)
(3.35)

di wi` ≤ Kh`

where of course all variables y, z, w and h are binary.
It is clear that the BMIP (3.33)–(3.38) cannot be straightforwardly reduced
to a single-level program because the sense of the optimization of the RHSGP is
opposed to that of the MVVIP. In other words, because of the upper-level objective
function (3.33), the absence of the lower-level objective would result in a BPP
solution using the largest number of bins instead of the smallest.
We can simplify the RHSGP by relaxing the integrality requirement on w and
h to obtain
b(S̄) = min

n
X

`=1
n
X

h`

(3.39)

wi` = yi

`=1

X

di wi` ≤ Kh`

i∈N
wi` ∈

[0, 1], h` ∈ [0, 1]

∀i ∈ N

(3.40)

` = 1, . . . , n

(3.41)

i ∈ N, ` = 1, . . . , n,

(3.42)

which is also a lower bound for the BPP. In this case, the RHSGP can be solved in

132

closed form, with an optimal solution being
b(S̄) =

P

i∈S̄

di

K

=

P

i∈N

K

di y i

.

(3.43)

Hence, the MVVIP reduces to a single-level MIP that can in turn be solved in
polynomial time by transforming it into a network flow problem as proven by [13].
An intermediate
bound is obtained by rounding the bound (3.43),

 Pvalid lower

i.e., using b(S) =

i∈N

K

di yi

. Although such rounding can be done after the fact,

relaxing the integrality on w, but not h, i.e., replacing conditions (3.42) by
wi` ∈ [0, 1], h` ∈ {0, 1} i ∈ N, ` = 1, . . . , n,
results in reduction of the MVVIP to the single-level MIP
min

X

e∈E

x̂e ze − 2b

ze ≥ yi − yj
ze ≥ yj − yi
P
di y i
b ≥ i∈N
K
b integral
yi ∈ {0, 1}, ze ∈ {0, 1}

∀e = {i, j}
∀e = {i, j}

∀i ∈ N, ∀e ∈ E,

which was shown by [6] to be NP -hard.

4. Conclusions

We have presented a conceptual framework for the formulation of general separation problems as bilevel programs. This framework reflects the inherent bilevel
nature of the separation problem arising from the fact that calculation of a valid
right-hand side for a given coefficient vector is itself an optimization problem. In
cases where this optimization problem is difficult in a complexity sense, it is generally not possible to formulate the separation problem as a traditional mathematical
program. We conjecture that the MVVIP for most classes of valid inequalities can
be thought of as having this hierarchical structure, but that certain of them can
nonetheless be reformulated effectively. This is either because the RHSGP is easy
to solve or because it goes “in the right direction” with respect to the MVVIP itself. We believe that the paradigm presented here may be useful for the analysis of
other intractable classes of valid inequalities. In a future study, we plan to further
formalize the conceptual framework presented here with a further investigation of
the complexity issues, additional examples of this phenomena, and an assessment
whether these ideas may be useful from a computational perspective.
133

Acknowledgements

We warmly thank Leo Liberti for useful comments about the paper.

References
[1] D. L. Applegate, R. E. Bixby, V. Chvátal, and W. J. Cook. The Traveling Salesman Problem: A Computational Study. Princeton University Press,
2007.
[2] E. Balas. Disjunctive programming. Annals of Discrete Mathematics, 5:3–51,
1979.
[3] E. Balas and A. Saxena. Optimizing over the split closure. Mathematical
Programming, 113:219–240, 2008.
[4] A. Caprara and A. Letchford. On the separation of split cuts and related
inequalities. Mathematical Programming, 94:279–294, 2003.
[5] B. Colson, P. Marcotte, and G. Savard. Bilevel programming: A survey. 4OR:
A Quarterly Journal of Operations Research, 3:87–107, 2005.
[6] G. Cornuéjols and F. Harche. Polyhedral Study of the Capacitated Vehicle
Routing Problem. Mathematical Programming, 60:21–52, 1993.
[7] G. B. Dantzig and R. H. Ramser. The Truck Dispatching Problem. Management Science, 6:80–91, 1959.
[8] S. Dash, O. Günlük, and A. Lodi. On the MIR closure of polyhedra. In M. Fischetti and D. P. Williamson, editors, Integer Programming and Combinatorial
Optimization - IPCO 2007, volume 4513 of Lecture Notes in Computer Science, pages 337–351. Springer-Verlag, 2007.
[9] S. Dempe. Annotated bibliography on bilevel programming and mathematical
programs with equilibrium constraints. Optimization, 52:333–359, 2003.
[10] M. Fischetti and A. Lodi. Optimizing over the first Chvátal closure. Mathematical Programming, 110:3–20, 2007.
[11] M. Fischetti, A. Lodi, and A. Tramontani. On the separation of disjunctive
cuts. Technical Report OR-08-2, DEIS, University of Bologna, 2008.
[12] M. Grötschel, L. Lovász, and A. Schrijver. The ellipsoid method and its consequences in combinatorial optimization. Combinatorica, 1:169–197, 1981.
[13] S. T. McCormick, M. R. Rao, and G. Rinaldi. Easy and difficult objective
functions for max cut. Mathematical Programming, 94:459–466, 2003.
[14] J. Moore and J. Bard. The mixed integer linear bilevel programming problem.
Operations Research, 38:911–921, 1990.

134

Integer Programming

Lecture Hall A

Wed 3, 08:45–10:15

Decomposition Methods for Stochastic Integer
Programs with Dominance Constraints
Rüdiger Schultz
Department of Mathematics, University of Duisburg-Essen
Lotharstr. 65, D-47048 Duisburg, Germany
schultz@math.uni-duisburg.de

Key words: stochastic integer programming, stochastic dominance, decomposition
methods

Stochastic programming models are derived from random optimization problems with information constraints. For instance, we may start out from the random
mixed-integer linear program
min{c> x + q > y + q 0> y 0 : T x + W y + W 0 y 0 = z(ω),
0
m0
x ∈ X, y ∈ Zm̄
+ , y ∈ R+ },

(0.1)

together with the information constraint that x must be selected without anticipation
of z(ω). This leads to a two-stage scheme of alternating decision and observation:
The decision on x is followed by observing z(ω) and then (y, y 0) is taken, thus
depending on x and z(ω). Accordingly, x and (y, y 0) are called first- and secondstage decisions, respectively.
Assume that the ingredients of (0.1) have conformable dimensions, that W, W 0
are rational matrices, and that X ⊆ Rm is a nonempty polyhedron, possibly involving integer requirements to components of x.
The mentioned two-stage dynamics becomes explicit by the following reformulation of (0.1)
min{c> x + Φ(z(ω) − T x) : x ∈ X}
x

where
0

0
m
Φ(t) := min{q > y + q 0> y 0 : W y + W 0y 0 = t, y ∈ Zm̄
+ , y ∈ R+ }.

(0.2)

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

In this way, the random optimization problem (0.1) gives rise to the family of random variables


>

c x + Φ(z(ω) − T x)



.

(0.3)

x∈X

Two principal alternatives arise at this point. Either the aim is to find “a best” element in this family of random variables or the aim is to single out “acceptable”
elements and optimize some objective function over the feasible set arising.
Traditional stochastic programming, see for instance [4], followed the first alternative by judging the quality of the random variables in (0.3) according to their
expectations
h

i

QE (x) := Eω c> x + Φ(z(ω) − T x) .
leading to the optimization problem
min{QE (x) : x ∈ X}.
This model, however, is risk neutral. Introducing risk aversion into the first alternative of handling (0.3) leads to mean-risk models
min{QM R (x) : x ∈ X}
where
h

i

QM R (x) := (E + ρ · R) c> x + Φ(z − T x) = QE (x) + ρ · QR (x)
with some fixed ρ > 0. Here R denotes a statistical parameter reflecting risk (risk
measure). For a possible specification see for instance [5].
Partial orders of random variables provide a possibility to formalize the second alternative of handling (0.3). A (real-valued) random variable X is said to
be stochastically smaller in first order than a random variable Y (X 1 Y) iff
Eh(X) ≤ Eh(Y) for all nondecreasing functions h for which both expectations
exist. X is said to be stochastically smaller than Y in increasing convex order
(X icx Y) iff Eh(X) ≤ Eh(Y) for all nondecreasing convex functions h for which
both expectations exist.
Equivalent formulations read as follows (see,e.g., [3]):
X 1 Y

iff

P[{ω : X(ω) ≤ η}] ≥ P[{ω : Y(ω) ≤ η}] ∀η ∈ R

(0.4)

and
X icx Y

iff

Eω [X(ω) − η]+ ≤ Eω [Y(ω) − η]+ ∀η ∈ R

138

(0.5)

with [.]+ denoting the non-negative part.
With a prescribed reference random variable d(ω), “acceptance” of a random
variable f (x, ω) := c> x + Φ(z(ω) − T x) can be formalized as
f (x, ω) ι d(ω), with either ι = 1 or ι = icx.
This means that only those x ∈ X are acceptable whose associated cost profile
f (x, ω), in a stochastic sense, is not worse than the prescribed (critical) random
profile d(ω). With an objective function g : Rm → R this leads to the following
stochastic optimization problem with dominance constraints
min{g(x) : f (x, ω) ι d(ω), x ∈ X}, ι = 1, icx.

(0.6)

Stochastic optimization problems with dominance constraints involving general
random variables were pioneered in [1; 2], with first results on structure, stability,
and algorithms for (0.6) if general random variables replace f (x, ω). The random
variables f (x, ω) are more specific, since essentially given by the mixed-integer
value function in (0.2). Nevertheless, the results from [1; 2] are not applicable here
since Φ in (0.2) fails to be smooth, let alone linear, and often even turns out discontinuous.
The talk will address the following:
- (departing from (0.4) and (0.5)) equivalent mixed-integer linear programming
formulations for (0.6) if the probability distributions of z and d are discrete
with finitely many realizations,
- branch-and-bound based decomposition algorithms for solving these mixedinteger linear programs,
- cutting plane based decomposition algorithms if there are no integer variables
in the second stage.
References
[1] Dentcheva, D.; Ruszczyński, A.: Optimization with stochastic dominance
constraints, SIAM Journal on Optimization 14 (2003), 548 - 566.
[2] Dentcheva, D.; Ruszczyński, A.: Optimality and duality theory for stochastic
optimization with nonlinear dominance constraints, Mathematical Programming 99 (2004), 329 - 350.
[3] Müller, A.; Stoyan, D.: Comparison Methods for Stochastic Models and
Risks, Wiley, Chichester, 2002.
[4] Ruszczyński, A.; Shapiro, A. (eds.): Handbooks in Operations Research and
Management Science, 10: Stochastic Programming, Elsevier, 2003.
[5] Schultz, R., Tiedemann, S.: Conditional value-at-risk in stochastic programs
with mixed-integer recourse, Math. Progr. 105 (2006), 365–386.

139

On a Two-Stage Stochastic Knapsack Problem with
Probabilistic Constraint
Stefanie Kosuch and Abdel Lisser
LRI, Université Paris XI, Orsay, France

Key words: stochastic programming, two-stage knapsack problem, probabilistic constraint

1. Introduction

The knapsack problem is a widely studied combinatorial optimization problem. Special interest arises from the numerous real life applications for example in
logistics and scheduling. The basic problem consists in choosing a subset out of a
given set of items such that the total weight (or size) of the subset does not exceed
a given limit (the capacity of the knapsack) and the total benefit of the subset is
maximized.
However, most real life problems are non-deterministic in the sense that some of
the parameters are not known in the moment when the decision has to be made. We
will study the case where the item weights are random. This case entail the problem
that we cannot be sure that the total weight of the items chosen in advance (i.e. before the revealing of the actual weights) will respect the capacity. Depending on the
situation given, the resulting stochastic problem can be modeled in two different
ways: Either using a single stage problem which means that the final decision has
to be made before the random parameters are revealed ([3], [2]); or by a two- or
multi-stage problem that allows later corrections of the decision made in the first
stage ([2]).
In this paper, we discuss a two-stage stochastic knapsack problem (see section
2) and we assume the item weights to be independently distributed following a
(known) normal distribution. The first aim of this paper is to show how to obtain
upper bounds on the overall problem or on subproblems (i.e. with some of the first
stage variables already fixed). The second aim is to compute high probable lower
bounds on the overall problem, given a first stage decision. These upper and lower
bounds could afterwards be used in a branch-and-bound framework such as presented in [1] or [3] in order to search the solution space of the first stage variables
for good lower bounds on the overall problem.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. Mathematical formulation

We consider a stochastic knapsack problem of the following form: Given a
knapsack with fixed weight capacity c > 0 as well as a set of n items. Each item
has a weight that is not known in the first stage and that comes to be known before the second stage decision has to be made. We handle the weights as random
variables and assume that weight χi of item i is independently normally distributed
with mean µi > 0 and standard deviation σi . Furthermore, each item has a fix reward per weight unit ri > 0.
In the first stage, items can be put in the knapsack (first stage items) and we assume that, in case of an overload, these items can be removed in the second stage.
However, removing items entails a penalty that is proportional to the total weight
of the removed items. We restrict the percentage of cases where the first stage items
lead to an overload by introducing a probabilistic constraint in the first stage. In the
second stage, the weights of all items are revealed and the aim is to minimize the
total penalty.
(T SKP )

max n

x∈{0,1}

s.t.

Pn

E[

i=1 ri χi xi ]

P

− d · E [Q(x, χ)]

P{ ni=1 χi xi ≤ c} ≥ p
P
Q(x, χ) = miny∈{0,1}n ni=1 χi yi ,
s.t. yk ≤ xk , k = 1, . . . , n.
Pn
i=1 (xi − yi )χi ≤ c,

(2.1)
(2.2)
(2.3)
(2.4)

where P{A} denotes the probability of an event A, E [·] the expectation, d > 1 and
p ∈ (0.5, 1].
3. Computing upper and lower bounds
3.0.0.1 Upper bounds: Given a first stage solution x̃, the expectation of the
second stage solution can be bounded (from below) by
"

n
X

E[Q(x̃, χ)] ≥ E [

i=1

+

x̃i χi − c]

#

The right hand side of the inequality equals the expectation of the optimal solution
of the second stage problem in case of continuous second stage variables. For normally distributed weights, it has a deterministic equivalent closed form ([1],[3]).
An upper bound on the optimal solution of the T SKP (2.1) is thus given by the
optimal solution of the following simple recourse problem:
(SRKP )

max n

x∈{0,1}

Pn

E[

i=1 ri χi xi ]

141

P

− d · E [[

xi χi − c]+ ]

P{

s.t.

Pn

i=1

χi xi ≤ c} ≥ p

(3.5)
(3.6)

This problem can be solved by the method presented in [3].

3.0.0.2 Lower bounds: If we are not able to solve the second stage problem to
optimality (given a first stage decision), we need good lower bounds on the overall
problem (i.e. good upper bounds on the second stage problem) to be able to exclude
subtrees in a branch-and-bound framework.
Given a first stage solution x̃, the expectation of the optimal second stage solution
E[Q(x̃, χ)] can be written
"

n
X

E[Q(x̃, χ)] = E [

i=1

+

x̃i χi − c]

#

+E

"
X

yi∗ χi

i∈S

n
X

−[

i=1

+

x̃i χi − c]

#

where y ∗ = y ∗ (x̃) is a corresponding optimal second stage decision and S ⊆
P
P
{1, . . . , n} such that i ∈ S if and only if x̃i = 1. i∈S yi∗ χi − [ ni=1 x̃i χi − c]+ is
the amount of weight we remove from the knapsack in addition to the overweight.
This amount can be bounded independently of the second stage solution y ∗ as in
the worst case the knapsack weight might fall maxi∈S χ̂i −  under the capacity due
to the removal of items in the second stage (where  > 0 and, for all i = 1, . . . , n,
χ̂i is the actual outcome of random variable χi ). As items have to be removed in at
most 1−p
percent of all cases, we get the following lemma:
100
Lemma 3.1.

E

"
X

yi∗χi

i∈S

n
X

−[

i=1

+

x̃i χi − c]

#

< (1 − p) · E[max χi ]
i∈S

Lemma 3.2. If the probability for any item to have twice the size of another item
is at most π, it follows
E

"
X
i∈S

yi∗ χi

n
X

−[

i=1

+

x̃i χi − c]

#









< (1 − p) (1 − π) · E min χ̂i + π · E max χi
i∈S

i∈S



In the case of normally distributed weights, neither E [maxi∈S χi ] nor E [mini∈S χi ]
are easily computable. Let us define the random variables χSmax := maxi∈S χi and
χSmin := mini∈S χi . Let Φi be the cumulative distribution function of χi , and ΦSmax
and ΦSmin the cumulative distribution functions of χSmax and χSmin , respectively.
Q
Q
Then one can easily show that ΦSmax = i∈S Φi and ΦSmin = 1 − i∈S (1 − Φi ).
Furthermore, if there exists a β < ∞ such that P{maxi∈S χi ∈ (−∞, β]} = 1
(resp. P{mini∈S χi ∈ (−∞, β]} = 1), we can bound E [maxi∈S χi ] (resp. E [mini∈S χi ])
by splitting the interval (−∞, β] in K disjunct intervals (K scenarios) (αk , βk ],
k = 1, . . . , K, and it follows
E [maxi∈S χi ] ≤

PK

k=1

βk P{maxi∈S χi ∈ (αk , βk ]} =

142

PK

S
k=1 βk (Φmax (βk )

− ΦSmax (αk ))

E [mini∈S χi ] ≤

PK

k=1 βk P{mini∈S

χi ∈ (αk , βk ]} =

PK

k=1

βk (ΦSmin (βk ) − ΦSmin (αk ))

Of course, in the case of normally distributed weights no such β exists. However, as
for every  there exists a β such that P{∃i ∈ S|χi ≥ β} < , we can approximate
the upper bound by defining β in such a way that P{∃i ∈ S|χi ≥ β} is (sufficient)
small.
Proposition 3.3. Let β such that P{∃i ∈ S|χi > β} = 0 and define (αk , βk ]
(k = 1, . . . , K) such that (−∞, β] = ∪K
k=1 (αk , βk ]. Let the probability for any item
to have twice the size of another item be at most π. Then, given a first stage solution
x̃, the following lower bound on the T SKP (2.1) hold:
E

" n
X
i=1

#

ri χi x̃i − d · E [Q(x̃, χ)] >


+(1 − p)(1 − π) ·

K
X

βk

k=1

Y

i∈S

n
X
i=1

"

n
X

ri µi x̃i − d · E [

(1 − Φi (αk )) −
+π · βk (

Y

i∈S

Y

i∈S

i=1

x̃i χi − c]+

(1 − Φi (βk ))

Φi (βk ) −

Y

i∈S

!!



Φi (αk ))

References
[1] A. Cohn, C. Barnhart, The Stochastic Knapsack Problem with Random
Weights: A Heuristic Approach to Robust Transportation Planning, Proceedings of the Triennial Symposium on Transportation Analysis (TRISTAN III),
1998.
[2] A. Gaivoronski, A. Lisser, R. Lopez, Knapsack problem with probability constraints, Technical Report No. 1498 of the Laboratoire de recherche en informatique, Orsay, France, 2008.
[3] S. Kosuch, A. Lisser, Stochastic Knapsack Problems, Technical Report No.
1505 of the Laboratoire de recherche en informatique, Orsay, France, 2008.

143

#

Improved strategies for branching
on general disjunctions
Gerard Cornuéjols, a Leo Liberti, b Giacomo Nannicini b
a LIF,

Faculté de Sciences de Luminy, Marseille, France
and Tepper School of Businness, Carnegie Mellon University, Pittsburgh, PA
gc0v@andrew.cmu.edu
b LIX,

École Polytechnique, 91128 Palaiseau, France
{liberti,giacomon}@lix.polytechnique.fr
Key words: Integer programming, branch and bound, split disjunctions

1. Extended abstract

In this paper we consider the Mixed Integer Linear Program in standard form:
>

min c x
Ax = b

∀j ∈ NI














x≥0 





xj ∈ Z, 

P

(1.1)

where c ∈ Rn , b ∈ Rm , A ∈ Rm×n and NI ⊂ N = {1, . . . , n}. The LP relaxation of (1.1) is the linear program obtained by dropping the integrality constraints,
and is denoted by P̄. The Branch-and-Bound algorithm makes an implicit use of
the concept of disjunctions [1]: whenever the solution of the current relaxation is
fractional, we divide the current problem P into two subproblems P1 and P2 such
that the union of the feasible regions of P1 and P2 contains all feasible solutions to
P. Usually, this is done by choosing a fractional component x̄i (for some i ∈ NI )
of the optimal solution x̄ to the relaxation P̄, and adding the constraints xi ≤ bx̄i c
and xi ≥ dx̄i e to P1 and P2 respectively.
Within this paper, we take the more general approach whereby branching can
occur with respect to a direction π ∈ Rn by adding the constraints πx ≤ β0 ,
πx ≥ β1 with β0 < β1 to P1 and P2 respectively, as long as no integer feasible
point is cut off. Karamanov and Cornuéjols [2] proposed using disjunctions arising

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

from Gomory Mixed-Integer Cuts generated directly from the rows of the optimal
tableau. We consider split disjunctions arising from Gomory Mixed-Integer Cuts
generated from linear combinations of the rows of the simplex tableau; by computing combinations that yield a stronger intersection cut, we generate split disjunctions that cut deeply into the feasible region, thereby reducing the total number of
nodes in the enumeration tree. By combining branching on simple disjunctions and
on general disjunctions, we obtain an improvement over traditional branching rules
on the majority of the test instances.

References
[1] E. Balas. Disjunctive programming. Annals of Discrete Mathematics, 5:3–51,
1979.
[2] M. Karamanov and G. Cornuéjols. Branching on general disjunctions. Technical report, Carnegie Mellon University, 2005.

145

Graph Theory II

Lecture Hall B

Wed 3, 08:45–10:15

Extremal Stable Graphs
Gyula Y. Katona, a Illés Horváth b
a Department

of Computer Science and Information Theory
Budapest University of Technology and Economics
1521, P. O. B.: 91, Hungary
kiskat@cs.bme.hu
b Department

of Stochastics
Budapest University of Technology and Economics
1521, P. O. B.: 91, Hungary
pollux@math.bme.hu

Key words: extremal properties, stability, stable graphs

1. Introduction

There is a wide range of graph theoretical questions that is a special case of the
following very general question: Let Π be a graph property so that if H ∈ Π and H
is a subgraph of G then G ∈ Π. (i. e. being non-Π is a hereditary graph property.)
What is the minimum number of edges in a graph G ∈ Π on n vertices if removing
any k edges or vertices from the graph still preserves Π?
A few examples:
• What is the minimum number of edges in a k-connected or k-edge connected
graph?
• What is the miminum number of edges in hypo-hamiltonian graph?
• What is the mininum number of edges in graph that is still Hamiltonian after
removing k edges (or vertices)? [2]
In the present paper we will concentrate on the problem where Π is the property
thet G contains a given fixed subgraph H. We only consider simple, undirected
graphs.
1

Research partially supported by the Hungarian National Research Fund and by the National Office for Research and Technology (Grant Number OTKA 67651)

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Definition 1. (Stability) Let H be a fixed graph. If the graph G has the property
that removing any k edges of G, the resulting graph still contains (not necessarily
spans!) a subgraph isomorphic with H, then we say that G is k-stable.
By S(n, k) we denote the minimum number of edges in a k-stable graph on n
vertices, and by S(k) the minimum number of edges in any k-stable graph (that is,
S(k) = minn S(n, k)).
For clarity, we do not include H in the notation, instead just keep in mind
that a graph H is always fixed. We regard calculating the value of S(k) a separate
question for each H.
Note that if n is fixed, then S(n, k) is decreasing in k, because if there is a
k-stable graph on n vertices, one can add isolated vertices to get k-stable graphs on
n + 1, n + 2, . . . vertices. This implies that for any fixed k, S(n, k) = S(k) if n
is large enough. In the present paper, we settle this question for several H graphs.
Our main concern is H = P4 (the path of 3 edges on 4 distinct vertices), but other
graphs are of interest in their own right.
If H = P2 (that is, a single edge containing 2 vertices), then naturally S(k) =
k + 1 and any graph with k + 1-edges is k-stable. We can state a general remark.
Remark 1. If H is fixed, then S(k) ≥ k + |V (H)|.
Proposition 1.
(a) If H = P3 , then S(k) = k + |V (H)| = k + 3.
(b) If H is the graph on 4 vertices with two nonadjacent edges, then S(k) = k +
|V (H)| = k + 4.
A general upper bound for the value of S(k) holds too.
Proposition 2. For any fixed H, S(k) ≤ (|V (H)| + 3)k if k is large enough.
The main morale of these propositions is that for any choice of H, S(k) is
of a linear order. Of course, identifying the exact S(k) functions is a completely
different matter.
From now on, we fix H = P4 .
The question of P4 was raised in [1] during the examination of Hamiltonian
chains in hypergraphs. The authors calculated the value of S(k) for k ≤ 8 and
posed a conjecture for larger k’s ([1], Conjecture 13). In the present paper we prove
this conjecture.

150

2. Main result

Our main result is the following:
Theorem 1. S(1) = 4, and if k ≥ 2, then S(k) = k +

lq

2k + 94 +

3
2

m

.

Although it is written in an explicit form above, the following alternative definition may be easier to understand and just as useful.
Proposition 3. The above formula for S(k) is equivalent with the following: S(1) =
4, S(2) = 6, and if k ≥ 3, then

S(k) =



 S(k


 S(k

− 1) + 2 if k =

 
l
2

for some l

− 1) + 1 otherwise.

Now let us take a look at the graphs containing no P4 .
Proposition 4. If the graph G contains no P4 as a subgraph, then all of its components are triangles and stars.
Proposition 5. If G has e edges on n vertices, then G is k-stable ⇐⇒ G cannot
be covered by k + n − e stars and any number of triangles.
In order to prove Theorem 1, we use the following theorem.




Theorem 2. Let G be a graph with e ≥ 5 edges. If e ≥ l−1
+ 1, then there are
2
l − 1 edges of the graph which contain no P4 as a subgraph.
The extremal graphs are shown for k = 1, . . . , 12 on Figure 1.

References
[1] P. F RANKL , G. Y. K ATONA, Extremal k-edge-hamiltonian hypergraphs, Discrete Mathematics (2008) 308, pp. 1415–1424
[2] M. PAOLI , W. W. WONG , C. K. WONG, Minimum k-Hamiltonian graphs.
II., J. Graph Theory (1986) 10, no. 1, pp. 79–95
[3] D. R AUTENBACH, A linear Vizing-like relation between the size and the
domination number of a graph, J. Graph Theory (1999) 31, no. 4, pp. 297–
302
[4] V. G. V IZING, An estimate of the external stability number of a graph, Dokl.
Akad. Nauk SSSR (1965) 52, pp. 729–731

151

Fig. 1. A display of the values of S(k) and the minimal k-stable graphs for smaller k’s. The
values of k where S(k) jumps 2 are marked. Note that the examples are almost-Kn graphs
except where 3|n.

152

Recognizing edge-perfect graphs: some polynomial
instances 1
M. P. Dobson, a V. A. Leoni, a,b,c G. L. Nasini a,b
a

Depto. de Matemática. F.C.E.I.A. Universidad Nacional de Rosario, Av. Pellegrini 250,
2000 Rosario, Argentina.
b Consejo

Nacional de Investigaciones Cientficas y Tcnicas, Argentina.

c Corresponding

author. E-mail: valeoni@fceia.unr.edu.ar

Key words: stability number, edge-covering number, odd chordless cycle, polynomial
instances

1. Preliminaries and notation
Packing and covering games defined by 0, 1 matrices were introduced in [1] as
particular classes of combinatorial optimization games. The authors left open for
both cases the problem of characterizing matrices defining totally balanced games,
that is, games for which every induced subgame is balanced.
Van Velzen [4] showed that the only matrices defining totally balanced covering games are clique-node matrices of perfect graphs, proving that they may be
recognized in polynomial time. In contrast, a complete characterization of matrices
defining totally balanced packing games remains open.
Given a 0, 1 matrix A with column set M, G(A) denotes the associated graph
of A, that is, the graph with vertex set M and where two vertices are adjacent if
there is a row in A with two 1’s in their corresponding positions.
In Escalante et al. [2] it is proved that given a matrix A, the edge-perfection of
G(A) gives a sufficient condition for A to define a totally balanced packing game.
In case A has exactly two ones per row, this condition is also sufficient. The authors
left open the problem of characterizing edge-perfect graphs.
In this work we give two characterizations of edge-perfect graphs, present
some known classes of graphs in which the edge-perfection recognition is poly1

Partially supported by grants of ANPCyT-PICT2005 38036 and CONICET PIP 5810.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

nomial and derive sufficient conditions for a graph in order to be polynomially
edge-perfect recognized.
Throughout this work, graphs are simple and connected. Most notation and
conventions are similar to those in [5].
Let G = (V (G), E(G)) be a graph. For v ∈ V (G), NG (v) denotes the neighborhood of v in G and dG (v) = |NG (v)|, the degree of v. A vertex v ∈ V (G) is
a pendant if dG (v) = 1. Vertices v and w are twins, if NG (v) = NG (w). We call
two-twin pair, a pair of twins in G of degree exactly two.

Fig. 1. A scheme of graphs with a two-twin pair: {v, w}.

Given T ⊆ V (G), G \ T denotes the induced subgraph of G by the vertices
in V (G) \ T , that is, the subgraph obtained by the deletion of the elements in T .
Following the terminology introduced in [2], G0 = G \ T with T ⊆ V (G) is an
edge-subgraph if T is the union of the endpoints of the edges in some subset of
E(G).
Denoting by α(G) and ρ(G) the stability and edge-covering numbers of G,
respectively, it is known that α(G) ≤ ρ(G). When the equality holds, G is called
edge-good. Besides, G is edge-perfect if G0 is edge-good, for every edge-subgraph
of G. From Knig’s edge cover theorem [3], bipartite graphs are edge-good. Hence,
we have that bipartite graphs are edge-perfect.

2. Characterizations of edge-perfect graphs
Let us first characterize those induced subgraphs of G which are edge-subgraphs.
Proposition 2.1. Let G be a graph and G0 = G \ T with T ⊆ V (G) . Then, G0 is
an edge-subgraph of G if and only if for all v ∈ T , NG (v) ∩ T 6= ∅.
Given an induced subgraph G0 = G \ T of G, we will say that a vertex v is a
savior of G0 if v ∈ T and NG (v) ∩ T = ∅, or equivalently, NG (v) ⊆ V (G0 ).
The following simple result will become a fundamental property on the way of
finding a characterization of edge-perfect graphs.
154

Lemma 2.2. Let G be an edge-perfect graph and G0 a edge-subgraph of G which
is not edge-good. Then there exists a savior of G0 .
We state a first characterization for edge-perfect graphs, whose proof is based
on lemma 2.2 together with some technical results, the most relevant listed below.
Theorem 2.3. A graph G is edge-perfect if and only if for every odd chordless
cycle C of G, C has a pendant savior, or there exists a two-twin pair {v, w} with
NG (v) = NG (w) ⊆ V (C).
The proof makes use of the following results:
(i) Let v ∈ V (G) be a pendant vertex. If NG (v) = {w} and G0 = G \ {v, w},
then G is edge-good if and only if G0 is edge-good.
(ii) If {v, w} is a two-twin pair of G with NG (v) = NG (w) = {s, t}, it holds:
• G is edge-good if and only if G0 = G \ {v, w, s, t} is edge-good.
• Let u ∈ V (G) with u 6= v such that {u, w} is a two-twin pair of G. Then,
G is edge-perfect if and only if G \ {w} is edge-perfect.
(iii) If G is an edge-perfect graph, then every triangle induced subgraph T of G
has a pendant savior, or one of its edges is the diagonal of a kite like the one
induced by {v, s, w, t} in the first picture of figure 1.
The condition given by the theorem above does not seem to be easy to check for
an arbitrary non bipartite graph. This motivates us to analyze further the structure
of certain edge-subgraphs of a given graph.
Given a graph G, let us denote by {wj1, wj2 } for j = 1, · · · , k, all pairs of twotwins and by {zj } for j = 1, · · · , h, all pendant vertices of G. Also, denote by
Pj = NG (wj1 ) = NG (wj2 ), for j = 1, · · · , k, {rj } = NG (zj ), for j = 1, · · · , h,
S
S
S
S
W = kj=1 {wj1, wj2 }, Z = hj=1 {zj }, P = kj=1 Pj and R = hj=1{rj }.
Consider the edge-subgraph G∅ = G \ (W ∪ P ∪ Z ∪ R) and, for K ⊆ P
denote by GK , the subgraph induced by the vertices in V (G∅ ) ∪ K.
We may state another characterization for edge-perfect graphs:
Theorem 2.4. G is edge-perfect if and only if GK is bipartite, for all K ⊆ P with
|K ∩ Pj | ≤ 1, for all j = 1, . . . , k.
3. Polynomial instances

Since the edge-perfection of a graph with at most four vertices is easily verified, we consider graphs with at least five vertices.

155

Although checking the condition in each of the characterizations given by theorems 2.3 and 2.4 could be exponential, we study some families of graphs for which
this task becomes polynomial. Clearly we have the following:
Lemma 3.1. If G has no two-twin pair, then G is edge-perfect if and only if G∅ is
bipartite.
From this result it is clear that, for every graph with minimum degree at least
three, we can decide in polynomial time if it is edge-perfect or not. Moreover, we
can derive the polinomiality of the edge-perfection recognition problem on some
known classes of graphs. For example, quasi-line graphs and outerplanar graphs.
On the other hand and based on the result in theorem 2.3, families of graphs
with a polynomial number of odd chordless cycles also define instances where the
edge-perfection recognition problem is polynomial. For example, the well-known
class of perfect graphs.
Finally, some other polynomial instances may be derived from certain connectivity conditions.
Theorem 3.2. Let G be a graph such that for every v ∈ P with dG (v) ≥ 4,
NG{v} (v)∩V (G∅ ) 6= ∅. If there exists K ⊆ P with |K ∩Pj | ≤ 1 for all j = 1, . . . , k
and GK bipartite and connected, then recognizing if G is edge-perfect is polynomial.
We have presented a wide family of instances where the edge-perfection recognition problem is polynomial. Even though, its computational complexity remains
open.

References
[1] X. Deng, T. Ibaraki and H. Nagamochi, Algorithms aspects of the core of
combinatorial optimization games. Mathematics of Operations Research 24
(3) (1999) 751-766.
[2] M. Escalante, V. Leoni and G. Nasini, A graph theoretical model for total balancedness of combinatorial games, submitted to Graphs and Combinatorics,
2009.
[3] D. Knig, Graphen und Matrizen. Math. Lapok, 38 (1931) 116-119.
[4] B. van Velzen, Discussion Paper: Simple Combinatorial Optimisation Cost
Games. Tilburg University (The Netherlands). ISSN 0924-7815. (2005)
[5] D. West, Introduction to Graph Theory, Prentice Hall, 2001, 2nd. ed.

156

Some infinite families of Q-integral graphs
Maria Aguieiras A. de Freitas, a Nair M. Maia de Abreu, a
Renata R. Del-Vecchio b
a Federal

University of Rio de Janeiro, Brazil
maguieiras@im.ufrj.br , nair@pep.ufrj.br
b Fluminense

Federal University, Brazil
renata@vm.uff.br

Key words: signless Laplacian, Q-integral graph, double graph, hierarchical product

1. Introduction
Let G = (V, E) be a simple graph on n vertices. The signless Laplacian matrix
of G is Q(G) = A(G) + D(G), where A(G) is its adjacency matrix and D(G) =
diag(d1 , . . . , dn ) is the diagonal matrix of the vertex degrees in G [1]. The characteristic polynomial of Q(G), PQ (G, x), is called the Q-polynomial of G and its roots
are the Q-eigenvalues of G. The spectrum of Q(G), SpQ (G) = (q1 , . . . , qn−1 , qn ),
is the sequence of the eigenvalues qi , i = 1, · · · , n, of Q(G) displayed in nonincreasing order. Recently, studies about the signless Laplacian matrix have been
appeared in the literature and some results related to Q(G) and its spectrum can be
found in [1], [2] and [3].
If all Q- eigenvalues of G are integer numbers, G is called a Q-integral graph
and we can find some few classes of these graphs in [2; 3]. Our aim in this paper
is to build new families of Q-integral graphs, obtained by three different operations: double graph, inserting edges between two copies of complete graphs and
hierarchial products of graphs.

2. Infinite families of Q-integral graphs
For i = 1, 2, let Gi = (Vi , Ei ) be graphs on ni vertices. The union of G1 and G2
is the graph G1 ∪ G2 such that the vertex set is V1 ∪ V2 and the edge set is E1 ∪ E2 .
The cartesian product of G1 and G2 is the graph G1 × G2 , such that the vertex set
is V = V1 × V2 and where two vertices (u1 , u2 ) and (v1 , v2 ) are adjacent if and only
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

if u1 is adjacent to v1 in G1 and u2 = v2 or u1 = v1 and u2 is adjacent to v2 in G2 . It
is well known that the operations of union and cartesian product of graphs preserve
the property of integrality and Laplacian integrality of graphs. As consequence of
our result below, we have that these operations also preserve the Q-integrality of
graphs.
Theorem 4. For i = 1, 2, let Gi be graphs on ni vertices, with Q-eigenvalues
qi,1 , . . . , qi,ni . Then the Q-eigenvalues of G1 ∪ G2 and G1 × G2 are q1,1 , . . . , q1,n1 ,
q2,1 , . . . , q2,n2 and q1,j + q2,k , j = 1, . . . , n1 , k = 1, . . . , n2 , respectively.
It is clear that one can generate infinitely many examples of Q-integral graphs
by successive applications of the operations above between Q-integral graphs. On
the next results we show other ways of building Q-integral graphs.
If G = (V, E) is a graph on n vertices, the double graph of G, D[G], is the
graph whose vertex set is V (D[G]) = V × {0, 1} and where two vertices (i1 , j1 )
and (i2 , j2 ) are adjacent if and only if the vertices i1 and i2 are adjacent in G [5].
Figure 1 shows the graph D[K3 ].

Fig. 1. D[K3 ]

The Kronecker product of matrices A and B, A ⊗ B, is the block matrix obtained by replacing each enter aij of A by the matrix aij B for all i and j. The
adjacency matrix of D[G] can be represented as A(D[G]) = J2 ⊗ A(G), where J2
is the all ones 2 × 2 matrix. Then the signless Laplacian matrix of D[G] is given
by Q(D[G]) = I2 ⊗ (Q(G) + D(G)) + (J2 − I2 ) ⊗ A(G), where Q(G) the signless Laplacian matrix of G and D(G) = diag(d1 , . . . , dn ) is the diagonal matrix of
vertex degrees in G.
In [5], the spectra of A(D[G]) and L(D[G]) = A(D[G]) − D(D[G]) were determined in terms of the vertex degrees of G and A(G) and L(G)-spectra. It was
shown that D[G] is an integral (Laplacian integral) graph if and only if G is an integral (Laplacian integral) graph. We prove that this property can also be extended
to Q-integral graphs.
Theorem 5. The Q-spectrum of D[G] is given by 2d1 , . . . , 2dn , 2q1 , . . . , 2qn , where
d1 , . . . , dn are the vertex degrees of G and q1 , . . . , qn are the Q-eigenvalues of G.
Consequently, D[G] is a Q-integral graph if and only if G is Q-integral.
Let D 1 [G] = D[G] and, for i ∈ N, D i+1 [G] = D[D i[G]]. Based on the theorem
above, for each Q-integral graph G, {D i [G], i ∈ N} is an infinite family of Qintegral graphs.

158

Let KKnj be the graph obtained from two copies of the complete graph Kn
by adding j edges between one vertex of a copy of Kn and j vertices of the other
copy. For j = 2, we obtain the graph KKn , which was introduced in [4]. Figure 2
displays the graph KK62 .

Fig. 2. KK62

Theorem 6. If j ≤ n ∈ N, n ≥ 3, the characteristic polynomial of Q(KKnj ) is
PQ (KKnj , x) = (x − 2n + 2)(x − n + 1)j−1 (x − n + 2)2n−j−2 (x2 − (3n + j − 3)x +
2(n2 + n(j − 2) − 2j + 1)).
As an immediate consequence of the above theorem, we have the following
characterization:
Corollary 1. The graph KKnj is Q-integral if and only if (n − j − 1)2 + 8j is a
perfect square.
The next result provides new infinite families of Q-integral graphs.
Corollary 2. For n, k, j ∈ N, if one of the conditions bellow is satisfied, the KKnj
graph is Q-integral:
(i)
(ii)
(iii)
(iv)
(v)

n = 3j;
n = 2j − 1;
n = 5k − 2 and j = 3k;
n = 3k + 6 and j = 2k + 6;
n = j= k(k+1)
.
2

In [6], the hierarchical product H = G2 u G1 of two graphs G1 and G2 having
root vertices, labeled 0, is defined as the graph whose the vertex set is V = V2 × V1
such that (u2 , u1) is adjacent to (v2 , v1 ) if and only if u1 is adjacent to v1 in G1 or
u1 = v1 = 0 and u2 is adjacent to v2 in G2 . Note that this definition depends on the
specified root of G1 . Figure 2 shows the graph K3 u K4 .

Fig. 3. K3 u K4

Under some appropriated labelling of its vertices, the adjacency matrix of G2 u
G1 can be given by D1 ⊗ A(G2 ) + A(G1 ) ⊗ In2 , where n2 is the order of G2 and D1
= diag(1, 0, . . . , 0) has size n2 × n2 . Then the signless Laplacian matrix of G2 u G1
159

is represented by Q(G2 u G1 ) = D1 ⊗ Q(G2 ) + Q(G1 ) ⊗ In2 . In the special case
where G1 = K2 , we obtain the following result.
Theorem 7. Let G be a graph on n vertices whose
q Q-eigenvalues are q1 , . . . , qn .
qi + 2 ± n qi2 + 4
Then the Q-eigenvalues of G u K2 are
, for i = 1, . . . , n.
2
As a immediate consequence of this, we have that G u K2 is not a Q-integral
graph, for every connected graph G on n ≥ 2 vertices.
Theorem 8. Let j, n ∈ N, n ≥ 3. The characteristic polynomial of Q(Kj u Kn )
is PQ (Kj u Kn , x) = (x − n + 2)(n−2)j (x2 − (3n + j − 6)x + 2n2 − 10(n − 1) +
j(2n − 3))j−1(x2 − (3n + 2j − 6)x + 2n2 − 10(n − 1) + 2j(2n − 3)).
From the theorem above, we obtain the following characterization:
Corollary 3. Let j, n ∈ N, n ≥ 3. The graph Kj u Kn is Q-integral if and only if
(n − j + 2)2 + 4(j − 2) and (n − 2j + 2)2 + 8(j − 1) are perfect squares.
Based on the last corollary, we can see that hierarchical product of complete
graphs can be Q-integral graph or not. For example, {Ki(i+1) u Ki(i+1)+1 , i ∈ N} is
an infinite family of Q-integral graphs, while, for every n ≥ 2, the graph Kn u Kn
is not Q-integral.

References
[1] D. Cvetković, P. Rowlinson, S. Simić, “Signless Laplacian of finite graphs”,
Linear Algebra and its Applications 423 (2007) 155-171.
[2] S. Simić, Z. Stanić, “Q-integral graphs with edge-degrees at most five”, Discrete Math. 308 (2008) 4625-4634.
[3] Z. Stanić, “There are exactly 172 connected Q-integral graphs up to 10 vertices”, Novi Sad J. Math. 37 n. 2 (2007) 193-205.
[4] D. Stevanović, I. Stanković, M. Milosević, “More on the relation between
energy and Laplacian energy of graphs”, MATCH Commun. Math. Comput.
Chem. 61 n. 2 (2009) 395-401.
[5] E. Munarini, C.P. Cippo, A. Scagliola, N.Z. Salvi, “Double graphs”, Discrete
Math. 308 (2008) 242-254.
[6] L. Barrière, F. Comellas, C. Dalfó, M.A. Fiol, “The hierarchical product of
graphs”, Discrete Appl. Math 157 (2009) 36-48.

160

Applications

Lecture Hall A

Wed 3, 10:30–12:30

Balanced clustering for efficient detection of scientific
plagiarism
Alberto Ceselli, a Roberto Cordone, a Marco Cremonini a
a DTI

- Università degli Studi di Milano, Italy
{alberto.ceselli,roberto.cordone,marco.cremonini}@unimi.it
Key words: Clustering, Dynamic programming, Tabu Search, Branch-and-bound

1. Introduction

Duplication, co-submission and plagiarism are rising phenomena in modern
scientific publishing, as the number of peer-reviewed journals and the perceived
chances of escaping detection are increasing. On the other side, electronic indexes
and new text-searching tools such as the search engine eTBLASTmight provide
an effective deterrent of unethical publications. Though manual inspection is unavoidable in the end, automatic detection might strongly reduce the work required.
However, the size of online databases makes a full search impractical even by algorithmic tools. In this paper, we consider the problem of structuring a textual
database so as to optimize queries for potential duplicates.

2. Formulations and properties
The database is modelled as a set N of n elements, with a distance function
d : N × N → R+ enjoying symmetry and triangle inequality (dij = dji and
dij ≤ dik + dkj for all i, j, k ∈ N). A trivial duplication check would compare
the new item i to each element j ∈ N, to ascertain whether their distance dij
exceeds or not a suitable threshold δ. To reduce the effort one can select s “centres”
j1 , . . . , js , partition N into clusters Cj1 , . . . , Cjs associated to the centres and assign
a “radius” rj = maxk∈Cj dkj to each cluster. Then, i can be compared to each centre
j: if dij > rj + δ, the triangle inequality guarantees that i is not a duplicate of any
element in Cj . Otherwise, one should compare i to all elements in Cj .
Definition 3. Ordering constraint: if an element i is assigned to a centre j, all
elements k such that dkj ≤ dij + δ (that is, closer or sligtly farther from the centre)
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

must also be assigned to j. Therefore, all elements k such that dkj ≤ rj + δ are
assigned to j.
For the sake of simplicity, in the following we assume δ = 0, thus searching
only for exact duplicates under the given metric.
Proposition 1. Under the ordering constraint with δ = 0, a duplicate item i satisfies condition dij ≤ rj + δ for a single centre j.
In this case, then, at most one cluster must be fully explored and the total worstcase computational effort is given by the comparisons to the centres (proportional
to the number of clusters s), plus the comparison to the only candidate cluster
(proportional to the largest cardinality).
The resulting problem consists in partitioning set N into clusters under the
ordering constraint and minimizing the sum of the number of clusters plus the
maximum cardinality of a cluster. One can formulate the problem as follows: let
zij = 1 if element i is the farthest element of a cluster centred in element j; zij = 0
otherwise; let η be the cardinality of the largest cluster.
min f =

X X

zij + η

(2.1a)

i∈N j∈N

X X

zkj = 1

i∈N

(2.1b)

|Iij | zij ≤ η

j∈N

(2.1c)

i, j ∈ N

(2.1d)

j∈N k∈Eij

X

i∈N

zij ∈ {0, 1}

where Eij = {k ∈ N : dkj ≥ dij } and Iij = {k ∈ N : dkj ≤ dij }.
But one can also set xij = 1 if element i belongs to a cluster centred in element
j; xij = 0 otherwise, and set η as the cardinality of the largest cluster.
min f =

X

i∈N

xii + η
X

xij = 1

i∈N

(2.2b)

xij ≤ η

j∈N

(2.2c)

j∈N

X

i∈N

(2.2a)

xij ≤ xkj
i ∈ N, j ∈ N, k ∈ Iij
xij ∈ {0, 1}
i, j ∈ N

(2.2d)
(2.2e)

Proposition 2. Formulations (2.1) and (2.2) are equivalent.
Formulation (2.1) is much faster to solve because it has O (n2 ) constraints
instead of O (n3 ). Both formulations are, most of the time, very weak: the lower
bound is just slightly larger than 2. However, they can easily be strengthened by

164

additional linear constraints and by fixing to zero a number of variables.
Proposition 3. The continuous relaxation of Formulation (2.1) can be strengthP
ened by including the linearization of constraint ηs ≥ n, where s = i,j∈N zij .
Proposition 4. For all feasible solutions whose cost is strictly lower than fH
zij = 0 for all i, j ∈ N : |Iij | >

fH − 1 +

q

(fH − 1)2 − 4n
2

√

Proposition 5. The problem is n-approximable by two trivial algorithms: a) build
a single cluster of n elements, b) build n singleton clusters.
Proposition 6. If N is a set of points on a line, i. e. ∃πi : N → R such that
dij = |πj − πi | for all i, j ∈ N, then the problem can be solved in O (n3 ) time.
3. Algorithms

The exact solution of the problem is strongly supported by the availability of
good heuristic solutions, which allow to prune branching nodes and force to zero
some decision variables (Proposition 4). We implemented a greedy algorithm and
a Tabu Search to obtain such solutions and applied the commercial MIP solver
CPLEX 11.0 to Formulation (2.1), strengthened as described.

Greedy algorithm Each step of the greedy algorithm builds a feasible cluster by
selecting a pair (i, j) and setting i as the farthest element of a new cluster centred
in j (i.e., zij = 1). The chosen pair maximises the cardinality |Iij | of the resulting cluster. In case of ties, the algorithm selects the pair which leaves the highest
number of feasible pairs after the fixing. To avoid building excessively large clusters, and √
to reduce the computational complexity, it is forbidden to select pairs with
|Iij | > α n where α ≥ 1 is a suitable coefficient. The purpose is to build
√ as many
clusters as possible with a size as close as possible to the ideal value n.

Tabu Search algorithm The Tabu Search algorithm is based on the following
neighbourhood: each pair (i, j) corresponds either to shrinking a current cluster (if
j is a centre and i is already assigned to it) or to inflating it (possibly, to creating
a new cluster). In the first case, after shrinking the selected cluster, we apply the
greedy heuristic to obtain a complete solution. In the second case, we first shrink
all cluster which include the elements assigned to the inflated (or newly created)
cluster and then√complete the solution with the greedy heuristic. All pairs (i, j)
with |Iij | > β n (where β ≥ α) are forbidden, to avoid building excessively
165

large clusters √
and to reduce the computational complexity. Thus, the neigbourhood
includes O (n n) solutions. The tabu mechanism saves for each pair (i, j) the last
iteration in which the current solution included cluster (i, j). For a specified number
of iterations L (tabu tenure), the move based on pair (i, j) is forbidden, unless the
resulting solution improves the best known one (aspiration criterion). At each step,
the whole neighbourhood is visited and the best non tabu solution (or the best tabu
solution respecting the aspiration criterion) is accepted as the incumbent one. The
algorithm terminates after a specified total number of iterations I.

4. Results
We have generated 25 Euclidean 3D instances, of five different sizes (from 50
to 250 elements by steps of 50) and 25 instances (with the same sizes) in which
random distances are generated and the triangle inequality is enforced by replacing
direct distances by the lengths of shortest paths.
Parameter α proves relevant for the greedy algorithm: the gap with respect to
the best known result decreases from 23.8% for α = 0.8 to 19.5% for α = 1.1, then
increasing up to 25.5% for α = 1.2 (it is better to start with clusters slightly larger
than the ideal value). The computational time on a 1.59GHz Intel Core 2 laptop
with 2 GB of RAM is always lower than 0.1 seconds.
Parameter β has a similar influence on the Tabu Search: the gap decreases
from 2.0% (β = 1.1) to 1.4% (β = 1.2), then increasing up to 1.7% (β ≥ 1.4).
The total number of iterations I has been fixed to 200 and the tabu tenure L to
10 (lower values induced cyclic behaviours on some instances). The computational
time for the largest instances ranges from about 10 minutes (β = 1.1) to about 25
(β = 1.5). Presently, the role of Tabu Search is not fully clarified: the objective
decreases in the first steps, usually stabilizing on the final value with few (if any)
intermediate increases. This suggests that the problem might be characterized by
large plateaus, in which, besides avoiding cycles, some further guiding mechanism
might be relevant.
The formulation strongly gains from the additional cutting planes and variable
fixings: all Euclidean instances up to n = 100 and all but two of the random instances with n ≤ 200 could be solved exactly in a limit time of 10 minutes. The
average final gap is about 12%. The truncated branch-and-bound improved the result produced by Tabu Search on 13 of the 50 instances.
As a final test, we have created an instance from real-world data by selecting
five papers from the combinatorial optimization literature, including a paper by
J.B. Shearer plagiarized by D. Marcu. We have split these papers in subsections,
keeping only alpha-numeric characters, obtaining an instance of 55 blocks. We have

166

defined the distance between two blocks i and j, respectively consisting of I and J
characters, as follows:
dij = max{I, J} − LCS(i, j)
where LCS(i, j) denotes the length of the Longest Common Subsequence of characters between i and j. This distance function showed some predictive power, being
able to correctly identify the plagiarism by Marcu.
We have been able to find the optimal solution of value 18 to this instance in
few seconds by using model (2.1a) – (2.1d) and CPLEX 11. Our Greedy and Tabu
Search algorithms found respectively a value of 20 and 18 in fractions of a second,
confirming our former computational experience.

167

Appendix (Proofs of the propositions)
Proposition 1 Under the ordering constraint with δ = 0, a duplicate item i satisfies condition dij ≤ rj + δ for a single centre j.
proof 1. Let δ = 0 and i be a duplicate of element k ∈ N. By contradiction, let
i be close to two centres (dij1 ≤ rj1 + δ = rj1 and dij1 ≤ rj2 + δ = rj2 ). Then
dkj1 ≤ dki + dij1 ≤ rj1 and dkj2 ≤ dki + dij2 ≤ rj2 . The ordering constraint requires
to assign k to both centres, which is unfeasible.

Proposition 2 Formulations (2.1) and (2.2) are equivalent.
proof 2. Start from any feasible solution to Formulation (2.2) and define xij =
k∈Eij zkj .

P

min f =

X X

zki + η

i∈N k∈Eii

X X

zkj = 1

i∈N

zkj ≤ η

j∈N

j∈N k∈Eij

X X

i∈N k∈Eij

X

k∈Eij

k∈Eij

zkj ∈ {0, 1}

X

Since Eii = N and
min f =

X X

X

zkj ≤

P

i∈N

zki + η

i ∈ N, j ∈ N, l ∈ Iij

zkj

k∈Elj

P

k∈Eij

zkj =

i, j ∈ N
P

k∈N

P

i∈Ikj

zkj

i∈N k∈N

X X

zkj = 1

i∈N

zkj ≤ η

j∈N

j∈N k∈Eij

X X

k∈N i∈Ikj

X

X

k∈Eij

zkj ≤

k∈Eij

zkj ∈ {0, 1}

X

zkj

k∈Elj

i ∈ N, j ∈ N, l ∈ Iij
i, j ∈ N

The third constraint is redundant (Elj ⊇ Eij for l ∈ Iij ) and the fourth can be
reduced to zkj ∈ {0, 1}. Suitably changing the names of some indexes, one obtains Formulation (2.1). Therefore, any feasible solution to Formulation (2.2) corresponds to a feasible solution of identical cost to Formulation (2.1).

168

The converse is also true. Start from any feasible solution to Formulation (2.1)
and define zij = xij − xσi j where σi is the successor of i in the list of the elements
sorted by increasing distances from j (let zij = xij when i is the farthest element
from j).
min f =

X X

i∈N j∈N

(xij − xσi j ) + η

X X

(xkj − xσk j ) = 1

i∈N

|Iij | (xij − xσi j ) ≤ η

j∈N

j∈N k∈Eij

X

i∈N

Since

P

i∈N

min f =

(xij − xσi j ) = xjj and

X

j∈N

X

i∈N

(xij − xσi j ) ∈ {0, 1}

xjj + η
X

P

k∈Eij

xij = 1

i∈N

|Iij | (xij − xσi j ) ≤ η

j∈N

j∈N

(xij − xσi j ) ∈ {0, 1}

i, j ∈ N

(xkj − xπk j ) = xij

i, j ∈ N

Since |Iσi j | = |Iij | + 1
min f =

X

j∈N

X

i∈N

xjj + η
X

xij = 1

i∈N

[|Iij | xij − (|Iσi j | − 1) xσi j ] ≤ η

j∈N

j∈N

xij ≥ xσi j
xij ∈ {0, 1}

i, j ∈ N
i, j ∈ N

which yields Formulation (2.1).

Proposition 3 The continuous relaxation of Formulation (2.1) can be strengthP
ened by including the linearization of constraint ηs ≥ n, where s = i,j∈N zij .

proof 3. Since s is the number of cluster and η their maximum cardinality, constraint ηs ≥ n states that the number of elements does not exceed their product.
The convex hull of the integer points respecting this condition is a politope providing valid inequalities for the problem.

169

Proposition 4 For all feasible solutions whose cost is strictly lower than fH
zij = 0 for all i, j ∈ N : |Iij | >

fH − 1 +

q

(fH − 1)2 − 4n
2

proof 4. If the solution is better than fH ,q
then it satisfies both s + η ≤ fH − 1 and
fH − 1 + (fH − 1)2 − 4n
ηs ≥ n. This implies that η ≤
. As no cluster includes
2
more than η elements, i cannot be assigned to centre j when |Iij | > η.
√
Proposition 5 The problem is n-approximable by two trivial algorithms: a)
build a single cluster of n elements, b) build n singleton clusters.
proof 5. Since ηs ≥ n,
√ the objective is f = s + η ≥ s + n/s. The minimum of
s + n/s for s ≥ 0 is 2 n. Since both trivial algorithms
provide a √
solution costing
√
∗
fapx = n + 1 ≤ 2n, the optimum is at least f ≥ 2 n and fapx ≤ nf ∗ .
Proposition 6 If N is a set of points on a line, i. e. ∃πi : N → R such that
dij = |πj − πi | for all i, j ∈ N, then the problem can be solved in O (n3 ) time.
proof 6. Due to the ordering constraint, each cluster corresponds to an interval
[πi , πj ] along the line. Let π̃i and π˜j be the coordinates of the elements preceding i
and following j, respectively (with π̃i = −∞ if i is the first element and π˜j = +∞
if j is the last). Not all such intervals are feasible: to be feasible, an interval must
admit a central element k ∈ N such that (π̃i + πj ) /2 ≤ πk ≤ (πi + π˜j ) /2. All the
unfeasible intervals can be filtered out in O (n2 log n) time (actually O (n2 ) if thery
are scanned lexicographically).
Now, build an auxiliary graph with a vertex i for each element and an arc (i, j)
for each pair of elements such that the interval between i and the element preceding
j is feasible. There is a one-to-one correspondence between the paths from the first
to the last vertex in this graph and the partitions of N into feasible clusters. For
each fixed value of η ∈ {1, . . . , n}, one can remove the arcs corresponding to the
clusters of size exceeding η and determine in O (n2 ) time, by a simple breadth-first
visit, the shortest path from the first to the last vertex with respect to the number of
arcs. By repeating this procedure for all values of η, one can solve the problem to
optimality in O (n3 ) time.

170

Robustness in Train Timetabling
V. Cacchiani, a A. Caprara, a M. Fischetti b
a DEIS,

University of Bologna, Italy
{valentina.cacchiani,alberto.caprara}@unibo.it
b DEI,

University of Padova, Italy
fisch@dei.unipd.it

Key words: Train Timetabling, Robustness, Lagrangian relaxation

1. Abstract

We propose a Lagrangian-based heuristic approach to obtain robust solutions
to the Train Timetabling Problem (TTP) on a corridor (i.e. a single one-way line
connecting two major stations). Roughly speaking, we define a solution to be robust if it allows to avoid delay propagation as much as possible. In particular, in
the planning phase that we are considering the aim is to build timetables characterized by buffer times that can be used to absorb possible delays occurring at an
operational level. In the TTP, we are given a set of stations S along the corridor, a
set of trains T , and for each train an ideal timetable (i.e. the timetable suggested by
the Train Operator). In the nominal TTP the aim is to change the ideal timetables
for the trains as little as possible, while satisfying the track capacity constraints
consisting of:
- departure constraints (imposing a minimum headway between two consecutive departures from a station);
- arrival constraints (imposing a minimum headway between two consecutive
arrivals at a station);
- overtaking constraints (avoiding overtaking between consecutive stations, since
we are considering a single one-way line).
In order to obtain feasible timetables we are allowed to change the departure of any
train from its first station (shift) and/or to increase the minimum stopping time in
one or more of the visited stations (stretch). Each train is assigned an ideal profit
which is gained if it is scheduled according to its ideal timetable. The profit is decreased (according to a linear function) if shift and/or stretch are applied; if the
profit becomes null or negative the train is cancelled. A common approach to deal

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

with the nominal TTP is to discretize the time horizon and to formulate the problem on a space-time graph G = (V, A). Each node of the set V corresponds to a
possible time instant at which a train can depart from or arrive at a station. Each arc
in A represents the travel of a train from a station to the next one (segment arcs) or
the stop of a train at a station (station arcs). Furthermore, each timetable for a train
corresponds to a suitable path in G. We refer the reader to [1] for further details
on the space-time graph representation. Given the graph G, a common Integer Linear Programming (ILP) formulation based on arc binary variables (see [1]) is the
following:

max

X X

pa xa

(1.1)

t∈T a∈At

X

X

≤ 1,

xa

a∈δ+ (σ)∩At

xa =

a∈δ− (v)∩At

X

xa

a∈C

xa

P

a∈δ+ (v)∩At

t∈T
xa , t ∈ T, v ∈ V \ {σ, τ }

(1.2)
(1.3)

≤ 1,

C ∈ C,

(1.4)

∈ {0, 1},

a∈A

(1.5)

where:
- At is the set of arcs in A that may be used by the path for train t;
- xa is a binary variable which assumes value 1 if arc a ∈ At is selected in the
solution for train t ∈ T , and 0 otherwise;
- pa is the profit gained if arc a ∈ At is in the solution
- C is the collection of all the cliques of incompatible arcs, with respect to track
capacity constraints.
The drawback of the nominal problem is that it does not take into account possible delays that can occur in the operational phase and that can affect the feasibility
and the quality of the solution. We describe how to change the model so as to move
towards robust solutions, that take into account the possible presence of delays.
Namely, we want to introduce buffer times for absorbing delays: this is obtained
by favoring longer stops at the stations with respect to the minimum stopping time,
so that, if a “short” delay occurs, it will not be propagated to the following trains.
On the other hand, allowing for buffer times that can absorb any reasonable delay
would be too conservative and produce solutions which are not acceptable from a
practical point of view. The aim of the robust problem is then bi-objective: to maximize the profits of the scheduled trains (efficiency) while maximizing the buffer
times (robustness). The new objective function reads:
max

X X

t∈T a∈At

pa xa +

X X

ba xa

(1.6)

t∈T a∈AtB

172

where AtB ⊆ At is the set of arcs corresponding to buffer times for train t ∈ T and
ba is the profit achieved if we select buffer arc a ∈ AtB . We consider the Lagrangian
relaxation of the constraints (1.4) of the model (1.6), (1.2)-(1.5), and solve it within
a subgradient optimization framework. In particular, the Lagrangian objective is:
max

X X

pa xa +

t∈T a∈At

=

X X

t∈T a∈AtB

p̄a xa +

X X

t∈T a∈AtB

X

ba xa +

X

C∈C

λC

λC (1 −

X

xa ) =

(1.7)

a∈C

(1.8)

C∈C

P

Here, for t ∈ T and a ∈ At , p̄a := pa − C∈Ca λC + ba (we assume ba = 0 for
a ∈ At \ AtB ), where Ca ⊆ C denotes the subfamily of cliques containing arc a. The
Lagrangian relaxation thus calls for finding the maximum profit path in the graph
G for each train, in an analogous way as in [1].
We present some preliminary computational results on real-life instances of
the corridor Modane-Milan with 100 and 200 trains, respectively, used for a comparison between the described approach and the method proposed in [3]. In [3],
Fischetti et al. develop different methods for improving the robustness of a given
TTP solution. In particular, they propose an event-based model (by adapting the
Periodic Event Scheduling Problem for the periodic case), and investigate different
approaches to get robust solutions: stochastic models and a light robustness approach (see [2]). In order to evaluate the robustness of a given solution in a more
realistic way, rather than simply considering the second objective above, an external validation method method is used in [3]. Given a TTP solution, the validation
method considers different realistic external delay scenarios and, assuming that all
the trains in the solution have to be scheduled and all train precedences are fixed,
adapts the solution to make it feasible with the given external delays, evaluating the
overall resulting delay.
In Table 8, we perform a comparison between our method and the method
of [3], by considering the solutions obtained by [3] when the precedences are left
unfixed, as is the case in our approach. The comparison is done on the efficiency Eff.
of the solutions found (the first objective above) and the outcome of the validation
method, which provides the cumulative delay Delay in the scenarios considered.
Our heuristic is run for 1000 iterations, which take less than 2000 seconds, and the
method [3] is run with a time limit of 2 hours. The best nominal solutions obtained
with the Lagrangian heuristic algorithm of [1] have efficiencies equal to 9297 and
18542, respectively. We mention that the Lagrangian approach obtains one solution
per iteration and we report in Table 8 only the values of three selected solutions.
As it can be observed, the Lagrangian-based approach finds solutions of comparable efficiency producing smaller cumulative delays than in [3] (in slightly shorter
computing times). Note that the cumulative delay is not necessarily increasing
when efficiency increases (e.g., this can be due to a better distribution of the buffer

173

Instance

#trains

Eff. ([3])

Delay ([3])

Eff.

Delay

MdMI1

100

9209

16683

9220

14331

MdMI1

100

8837

14070

9020

14728

MdMI1

100

8372

12675

8889

14508

MdMI2

200

18437

36376

18041

32962

MdMI2

200

17692

32355

17848

31653

MdMI2

200

16761

29716

16911

24723

Table 8. Comparison between the solutions in [3] and our solutions.

times in a solution with higher efficiency value). Ongoing work consists of testing
other instances and different parameter settings in order to produce more robust
solutions.

References
[1] A. Caprara, M. Fischetti and P. Toth, “Modeling and Solving the Train
Timetabling Problem”, Operations Research 50, 851–861 (2002).
[2] M. Fischetti and M. Monaci, “Light Robustness”, Technical Report DEI,
(2008).
[3] M. Fischetti, D. Salvagnin and A. Zanette, “Fast Approaches to Improve the
Robustness of a Railway Timetable”, to appear in Transportation Science,
(2009).

174

Combinatorial optimization based recommender
systems
Fabio Roda, a Leo Liberti, b Franco Raimondi c
a DisMoiOu,

33 rue des Jeuneurs, 75002 Paris, France, and
LIX, École Polytechnique, 91128 Palaiseau, France
fronline@libero.it

b LIX,

École Polytechnique, 91128 Palaiseau, France
liberti@lix.polytechnique.fr

c Deptartment

of Computer Science, UCL, London, UK
f.raimondi@cs.ucl.ac.uk

Key words: collaborative filtering, maximum capacity path

1. Introduction

Recommender systems exploit a set of established user preferences to predict topics or products that a new user might like [2]. Recommender systems have
become an important research area in the field of information retrieval. Many approaches have been developed in recent years and the interest is very high. However, despite all the efforts, recommender systems are still in need of further development and more advanced recommendation modelling methods, as these systems must take into account additional requirements on user preferences, such as
geographic search and social networking. This fact, in particular, implies that the
recommendation must be much more “personalized” than it used to be.
In this paper, we describe the recommender system used in the “DisMoiOu”
(“TellMeWhere” in French) on-line service (http://dismoiou.fr), which
provides the user with advice on places that may be of interest to him/her; the
definition of “interest” in this context is personalized taking into account the geographical position of the user (for example when the service is used with portable
phones such as the Apple iPhone), his/her past ratings, and the ratings of his/her
neighbourhood in a known social network.
Using the accepted terminology [6], DisMoiOu is mainly a Collaborative Filtering System (CFS): it employs opinions collected from similar users to suggest
likely places. By contrast with existing recommender systems, ours puts together

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

the use of a graph theoretical model [4] and that of combinatorial optimization
methods [1]. Broadly speaking, we encode known relations between users and
places and users and other users by means of weighted graphs. We then define
essential components of the system by means of combinatorial optimization problems on a reformulation of these graphs, which are finally used to derive a ranking
on the recommendations associated to pairs (user,place).
We remark that this is work in progress relating the first few months of work
in an industrial Ph.D. thesis. Preliminary computational results on the three classical evaluation parameters for recommender systems (accuracy, recall, precision
[3]) show that our system performs well with respect to accuracy and recall, but
precision results need to be improved.

2. Formalization of the problem
We employ the usual graph-theoretical notation, e.g. for a vertex v of a graph
+
−
G, δG
(v), δG
(v) are the set of vertices adjacent to incoming and respectively out+
+
going arcs. For vertices u, v of G we also let ∆G (u, v) = δG
(u) ∩ δG
(v).
We are given two finite sets U (the users) and P (the places), and a vertex set
V = U ∪ P . We are also given two directed graphs as follows.
• A ratings bipartite digraph R = (V, A) where A ⊆ U × P is weighted by a
function ρ : A → [−1, 1], which expresses the ratings of users with respect to
the places.
• A social network S = (U, B) weighted by a function γ : B → [0, 1] which
encodes a confidence coefficient between users.
The union of the two graphs G = R ∪ S is a mixed ratings/social network
which is used to establish new arcs in U × U or to change the values that γ takes on
existing arcs: a missing relation of confidence between two users can be established
if both like (almost) the same places in (almost) the same way. Moreover, even
when a confidence relation is already part of B, its strength can change according
to similar shared preferences situations. This is encoded by the reformulated graph
G0 described below.
We define a graph G0 with vertex set V 0 = U ∪ P and arc set B 0 (weighted by
a function γ 0 : B 0 → [0, 1]) defined in the following way.
(i) For every k, ` ∈ U such that (k, `) 6∈ B and subgraph H = (VH , AH )
of R induced by the vertex set VH = {k, `} ∪ ∆R (k, `) (see Fig. 1) such
0
that AH 6= ∅, B 0 contains the arc (k, `) weighted by γk`
= f (ϑ), where

176

k

ϑ=

`

X
1
|ρki−ρ`i |.(2.1)
|∆R (k, `)| i∈∆R (k,`)

∆R (k, `)
Fig. 1. A subgraph H of R.

ϑ represents the difference between users. The bigger it is, the lower the con0
0
fidence γk`
. γk`
is obtained as a function f of ϑ.
(ii) For every k, ` ∈ U such that (k, `) ∈ B and subgraph H = (VH , AH ) of
R induced by the vertex set VH = {k, `} ∪ ∆R (k, `) such that AH 6= ∅, B 0
0
contains the arc (k, `) weighted by γk`
= g(γk`, ϑ).
We let X = (U × P ) r A be the set of all recommendations that the system is
supposed to be able to make.

2.1 Identification of maximum confidence paths
Given (k ∗ , i∗ ) ∈ X, we consider the graph Z = (W, C) where W = U ∪ {i∗ }
and C = B 0 ∪ {(k, i∗ ) | k ∈ δR− (i∗ )}. Our aim is to compute a ranking for the
known ratings {ρki∗ | k ∈ δR− (i∗ )} by means of the confidence relations encoded
in the network Z, using paths (or sets thereof) ensuring maximum confidence. By
convention, we extend the confidence function γ to arcs in C adjacent to i∗ as
follows: ∀k ∈ δR− (i∗ ) (γki∗ = 1).
We make the assumption that for a path p ⊆ C in Z, γ(p) = min γk` , i.e. that
(k,`)∈p

the confidence on a path is defined by the lowest confidence arc in the path. This
implies that finding the maximum confidence path between k ∗ and i∗ is the same as
finding a path whose arc of minimum weight γ is maximum (among all paths k ∗ →
i∗ ). Considering Z as a network where γ are capacities on the arcs, a maximum
confidence path is the same as a maximum capacity path between k ∗ and i∗ , for
which there exists an algorithm linear in the number of arcs [5]. The mathematical

177

programming formulation for the M AXIMUM C APACITY PATH (MCP) problem is:
max

t

x,t

s.t.

P

+ ∗
`∈δR
(k )

∀` ∈ W r {k ∗ , i∗ }
∀(k, `) ∈ C

P

xk∗ ` = 1

−
h∈δR
(`)

xh` =

P

+
h∈δR
(`)

t ≤ γk` xk`

x ∈ {0, 1}, t ≥ 0,

x`h



























+ M(1 − xk` ) 








(2.2)

where M ≥ max γk` . Let p̄ ⊆ C be the maximum confidence path (i.e. the set
(k,`)∈C

of arcs (k, `) such that xk` = 1), and α(p̄) = argmin{γk` | (k, `) ∈ p̄}. Removing α(p̄) from C 1 = C yields a different set of arcs C 2 with associated network
Z 2 = (W, C 2 ), in which we can re-solve (2.2) to obtain a path p̄2 as long as Z 2 is
connected (otherwise, define p̄2 = ∅): this defines an iterative process for obtaining
a sequence of triplets (Z r , p̄r ). Given a confidence threshold Γ ∈ [0, 1] and an integer q > 0, we define the set Ω = {p̄r | p̄r 6= ∅ ∧ r ≤ q ∧ γα(p̄r ) ≥ Γ} of all high
confidence paths from k ∗ to i∗ .
2.2 Ranking the ratings
Recall each p ∈ Ω ends in i∗ , so we can define λ : Ω → δR− (i∗ ) such that λ(p)
is the last arc of p. Thus, we extend ρ to Ω as follows:
ρ(p) = ρ(λ(p)).
Let Θ = {σ ∈ [−1, 1] | ∃p ∈ Ω (σ = ρ(p))} be the set of ratings for i∗ available
to k ∗ . We evaluate each rating by assigning it the sum of the confidences along the
corresponding paths. Let v : Θ → R+ be given by
∀σ ∈ Θ v(σ) =

X

γ(p).

p∈Ω
ρ(p)=σ

We use v to define a ranking on Θ (i.e. an order < on Θ): for all σ, τ ∈ Θ (σ <
τ ↔ v(σ) < v(τ )). Naturally, this set-up rests on the fact that |Θ| < |Ω|, which
is exactly what happens in DisMoiOu’s implementation. The recommender system
then picks the greatest σ in Θ (i.e. the rating with highest associated cumulative
confidence) as the recommendations to user k ∗ concerning the place i∗ . Finally, the
output of the recommender system is a set of high confidence recommendations for
user k ∗ as i∗ ranges in P .

178

3. Extensions

One of the troubles with the recommender system described in Sect. 2 is that
paths in Ω might be too long: although in our formalization paths are only weighted
by the value of the arc of minimum confidence, in practice it also makes sense to
require that the paths should either be shortest or at least of constrained cardinality,
for confidence usually wanes with distance in social networks. Enforcement of the
first idea yields a bi-criterion path problem as (2.2) with an additional objective
function:
min
x,t

X

xk` .

(3.3)

(k,`)∈C

Enforcement of the second idea (say with paths having cardinality at most K) yields
the corresponding constraint:
X

(k,`)∈C

xk` ≤ K.

(3.4)

References
[1] G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender
systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge and Data Engineering, 17(6):734–749, 2005.
[2] J. Breese, D. Heckerman, and C. Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In G. Cooper and S. Moral, editors, Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence, pages
43–52, San Francisco, 1998. Morgan Kaufmann.
[3] C. Cleverdon, J. Mills, and M. Keen. Factors Determining the Performance
of Indexing Systems: ASLIB Cranfield Research Project. Volume 1: Design.
ASLIB Cranfield Research Project, Cranfield, 1966.
[4] Z. Huang, W. Chung, and H. Chen. A graph model for e-commerce recommender systems. Journal of the American Society for Information Science and
Technology, 55(3):259–274, 2004.
[5] A. Punnen. A linear time algorithm for the maximum capacity path problem.
European Journal of Operational Research, 53:402–404, 1991.
[6] E. Vozalis and K. Margaritis. Analysis of recommender systems algorithms. In
E. Lipitakis, editor, The 6th Hellenic European Conference on Computer Mathematics & its Applications, pages 732–745, Athens, 2003. Athens University
of Economics and Business.

179

Bounds and solutions for strategic, tactical and
operational ambulance location
Roberto Cordone, a Federico Ficarelli, a Giovanni Righini a
a Dipartimento

di Tecnologie dell’Informazione
Università degli Studi di Milano
Via Bramante 65, 26013 Crema, Italy
{roberto.cordone,federico.ficarelli,giovanni.righini}@unimi.it

Key words: Location, Emergency services, Integer Linear Programming

1. Introduction

The organization and management of an emergency health care system requires decisions at different levels and involves several stake-holders and decisionmakers, with different and possibly conflicting objectives. The service is typically
provided by a fleet of ambulances which are dispatched to the patients’ homes upon
arrival of phone calls to an operating center. The available ambulances are parked in
specially equipped areas, scattered in the territory so as to reach the patient within a
limit time (in urban environments, a few minutes). The parking areas must be built
in advance, and this is a strategic decision taken by the municipality. Part of the
areas are selected to host the available ambulances, and this is a tactical decision
taken by the managers at the operating center; the problem is known as Maximum
Covering Location Problem [2]. This problem is made harder by the variability of
the resources (number of available ambulances) and of the demand, both in time
and space: the demand is typically stronger at daytime and during working days
than by night or during week-ends; it is more concentrated in residential areas during the night, in areas with working places during the working days.
Furthermore, the number of available ambulances changes along the day as
some get busy servicing new calls and others become available again after terminating their service. A compelling operational problem is to optimally cover the
territory when some ambulances are busy by re-locating the available ones. In large
cities, the calls and the consequent operational decisions are very frequent, and it is
advisable to pre-compute optimal solutions for a number of possible scenarios as a
useful guideline. This problem has been considered for instance in [3].

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

In this paper we consider an integrated approach to three decision problems,
usually tackled at different levels: the choice of parking areas (strategic level), the
location of ambulances in each time slot (tactical level) and the relocation of the
available ambulances according to their number (operational level). We present an
integer linear programming formulation and some preliminary computational results with general-purpose solvers.

2. Mathematical models

2.1 Model n.1: Parking areas construction and ambulance location
Model 1 integrates the strategic and tactical levels. Let T denote the set of time
slots and I the set of demand points, where service requests are concentrated; dit
is the amount of demand for each point i ∈ I and time slot t ∈ T , At ambulances
are available in time slot t. Let C denote the set of candidate parking areas and C
the number of areas which can be built. The ambulances can only be assigned to
parking places that have been built. Each demand point i can be covered within a
prescribed maximum intervention time from a known subset Ci of parking areas.
The problem of selecting the parking areas to build and allocating to them the
ambulances available in each time slot, in order to provide maximum coverage to
the population, can be modelled by the following binary variables: xc indicates
whether a parking area is built or not in candidate location c ∈ C; yct whether an
ambulance is assigned or not to parking area c ∈ C during time slot t; zit whether
demand point i is covered or not during time slot t.
maximize v =

XX

dit zit

(2.1a)

i∈I t∈T

s.t. zit ≤

X

yct

c∈Ci

yct ≤ xc
X
c∈C

yct ≤ At

c∈C

xc ≤ C

X

xc ∈ {0, 1}
yct ∈ {0, 1}
zit ∈ {0, 1}

181

∀t ∈ T

(2.1b)

∀c ∈ C ∀t ∈ T

(2.1c)

∀t ∈ T

(2.1d)
(2.1e)

∀c ∈ C
∀c ∈ C ∀t ∈ T
∀i ∈ I ∀t ∈ T .

(2.1f)
(2.1g)
(2.1h)

2.2 Model n.2: Ambulance location and relocation

Model 2 integrates the tactical and operational levels. In this problem, there is a
single time slot and the parking areas have already been chosen. On the other hand,
the number of available ambulances a varies between 1 and A and they must be
relocated, depending on the value of a, to maximize coverage in all scenarios, under
the constraint that only one ambulance can be relocated each time a varies. So, the
locations of a and a + 1 ambulances must have a parking areas in common. The
model can be easily generalized to allow for more relocations, but here we neglect
this extension since it is unrealistic. The binary variables yac indicate whether an
ambulance is assigned or not to parking area c when a ambulances are available;
variables zia indicate whether demand point i is covered or not when a ambulances
are available. The datum wa represents the weight attributed to the configuration
with a available ambulances and it depends on the fraction of time for which exactly
a ambulances are available. This is estimated by a queuing theory model.
maximize v2 =

A
XX

di wa zia

(2.2a)

i∈I a=1

s.t. zia ≤

X

∀a = 1, . . . , A

(2.2b)

∀a = 1, . . . , A

(2.2c)

c∈C

yac ≤ ya+1 c
yac ∈ {0, 1}
zia ∈ {0, 1}

∀c ∈ C ∀a = 1, . . . , A
∀a = 0, . . . , A ∀c ∈ C
∀i ∈ I ∀a = 1, . . . , A.

(2.2d)
(2.2e)
(2.2f)

X

yac

c∈Ci

yac = a

We also considered a third model, resulting from the fusion of the two models
above, where all three decision levels are integrated. In such a model we have variables ycta , indicating whether an ambulance is assigned to parking area c in time
slot t when there are a ambulances available, and zita , indicating whether demand
point i is covered in time slot t when a ambulances are available.

3. Computational results

We have performed some preliminary experiments with the models introduced
above on real-world instances referring to the city of Milan. Five time slots have
been identified, based on the profiles of the phone calls and the ambulance speed
along the day, as recorded in the database of the emergency health care system. The
demand points (|I| ≈ 12 000) have been located on the street graph of Milan and
each one is associated with a demand dit in each time slot, derived from the historical data. Smaller instances have been produced by selecting only 5000 or 8000
182

demand points from the larger instances. The number of ambulances ranges from
20 to 30 to 40, corresponding approximately to the current availability of public
and private ambulances offering the service in Milan. Correspondingly, the number of parking areas to be built has been fixed to twice the number of ambulances
(hence, 40, 60, or 80), chosen among 100, 150 or 200 candidate sites, according
to the number of demand points. These sites have been located by maximizing
the total distance between each other with a Maximum Diversity algorithm [1]. We
consider instances with a single time slot, 3 time slots or 5 time slots. This produces
3 · 3 · 3 = 27 different instances.
All instances have been submitted to CPLEX 11.0 with a time limit of one
hour. It could solve most problem instances with 5000 demand points and some
with 8000 demand points, sometimes at the root node, sometimes after branching.
For the instances not solved to optimality it could achieve a very small gap between
the upper and the lower bounds (from about 5% to less than 1%). When confronted
with instances with 12442 demand points CPLEX could solve the linear relaxation
at the root node only with the barrier method and it could not solve any instance to
proven optimality. This suggests the development of alternative ad hoc approaches,
such as Lagrangian relaxation, which is the subject of ongoing research.

References
[1] Aringhieri R., Cordone R., Melzani Y., Tabu Search vs. GRASP for the Maximum Diversity Problem, 4OR: A Quarterly Journal of Operations Research
6:1 (2008) 45–60
[2] Church R.L., ReVelle C.S., The maximal covering location problem, Papers
of the Regional Sciences Association 32 (1974) 101-118
[3] Gendreau M., Laporte G., Semet F., The maximal expected coverage relocation problem for emergency vehicles Journal of the Operational Research
Society 57 (2006) 22-28

183

Coloring II

Lecture Hall B

Wed 3, 10:30–12:30

A branch-and-price approach for the Partition
Coloring Problem
E. A. Hoshino, a Y. Frota, b C.C. de Souza b
a University

of Mato Grosso do Sul, Department of Computing and Statistics, Campo
Grande MS, Brazil

b University

of Campinas, Institute of Computing, Campinas SP, Brazil

Key words: partition coloring, formulation by representatives, branch-and-price

Introduction. Let G = (V, E) be a undirected graph, where V is the set of vertices,
E is the set of edges, and Q = (V1 , . . . , Vq ) is a partition of V into q disjoint sets.
The Partition Coloring Problem (PCP) consists of finding a subset V 0 of V with
exactly one vertex from each set Vk ∈ Q and such that the chromatic number of the
graph induced in G by V 0 is minimum.
This problem was first introduced in [5], motivated by the routing and wavelength assignment problem in optical networks. The authors proved that PCP is
NP-hard and proposed heuristics extending classical methods for the vertex coloring problem (VCP). Different integer programming formulations were proposed
to model the VCP. Mehrotra and Trick developed a column generation algorithm
based on the classical independent set (IS) formulation [6]. Campêlo et. al. [2]
proposed an alternative formulation in which a representative vertex is chosen to
identify each color. Later, Campêlo et. al. [1] unified both formulations into a cut
and price method to handle the VCP.
In this work, we explore this same idea of [1] to introduce a new integer programming (IP) formulation for the PCP. To the best of our knowledge, the only
exact algorithm available for the PCP to date is the branch-and-cut approach based
on the representatives formulation presented in [3]. An experimental comparison
between these algorithms is also carried out here.
IP formulation. Let P be the set of all independent sets of G. Each independent
set p in P can be represented by the characteristic vector ap , where api = 1 if and
1

First and second authors are supported by scholarships from Capes (Brazilian Ministry
of Education). Third author is partially supported by CNPq – Conselho Nacional de Desenvolvimento Cientı́fico e Tecnológico – Grants # 301732/2007-8 and # 472504/2007-0.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

only if the vertex i belongs to p. We now associate a binary variable λp to each
independent set p in P . The formulation of the PCP that combines the IS and the
representatives formulations is described below:
(PCPr)
subject to

min
X

X

p∈P
rip λp

λp

(0.1)

≤ 1, ∀i ∈ V

(0.2)

p∈P

(0.3)

p∈P

api λp ≤ 1, ∀i ∈ V

X

X X

(

p∈P i∈Vk

api )λp = 1, ∀ Vk ∈ Q

λp ∈ {0, 1}, ∀p ∈ P

(0.4)
(0.5)

where rip = 1 if, and only if i is the representative vertex of the independent set
related to p. The objective function (0.1) counts the number of independent sets,
i.e., the number of colors. Constraints (0.2) state that a vertex can represent at most
one independent set. A constraint in (0.3) forbids a vertex to be in two or more
independent sets simultaneously. Finally, constraints (0.4) enforce that, in each set
Vk ∈ Q, precisely one vertex is colored.
Let π, µ and α be the dual variables related to constraints (0.2), (0.3) and (0.4),
respectively, in the linear relaxation of the (PCPr). Thus, the reduced cost of an
P
P
independent set p is cP = 1 − i∈V (µi + αQ[i] )api − i∈V πi rip , where Q[i] is the set
of the partition that contains the vertex i, i.e., i ∈ VQ[i] . Now, for every vertex i in
V , let P (i) = {p ∈ P : i is the representative vertex of p}. Clearly, these sets form
a partition of P . Therefore, a solution to the pricing problem can be computed by
solving independently |V | subproblems of the form:
(IS(i))

πi + max

X

(µj + αQ[j])xj

j∈N (i)

subject to xu + xv ≤ 1,

x ∈ {0, 1}|N (i)| ,

where Ẽ =

Sq

k=1 {(u, v)

∀ (u, v) ∈ Ẽ and u, v ∈ N(i),

∈ Vk × Vk } ∪ E and N(i) = {j ∈ V \ VQ[i] : (i, j) 6∈ E}.

It is not difficult to prove that the relaxation of (PCPr) provides dual bounds
which are at least as good as those given by the representatives model described
in [3], even when the latter is amended with all the external cuts introduced in
that paper. Because these inequalities were claimed to be the most effective ones
in cutting plane approaches, we were not compelled to implement a branch-cutand-price algorithm. Indeed, our results showed that a simpler branch-and-price is
already quite efficient.
Empirical analysis. We developed a branch-and-price algorithm using the model
presented above. The code was implemented in C++ and XPRESS (version 2008)
188

was used as the linear programming solver. We applied the same branching strategy
and primal heuristic described in [3]. The dual bound of Lasdon [4] was computed
at each node of the branch-and-bound tree. To this end, we included the constraint
P
p∈P λp ≤ UB in the formulation (PCPr), where UB is the best known primal
bound at that current node.
We experimented our algorithm with the same instance classes reported in [3].
The class RAND consists of 80 randomized instances while the class NSF contains
49 instances related to the routing and wavelength assignment problem. The tests
were ran on a Pentium Core2 Quad 2.83 GHz with 8Gb of RAM. We established a
limit of 1800 seconds on the running time for all experiments.
First, we analyzed four algorithms to solve the pricing problem: (1) TRICK, (2)
(3) ADAPTIVE, and (4) ADAPTIVE *. The first one consists of the algorithm proposed in [6] by Mehrotra and Trick to compute the maximum weighted
independent set. The second algorithm uses an ILP solver. The method ADAPTIVE
decides between TRICK and SOLVER depending on the density of the input graph.
Finally, ADAPTIVE * uses pricing heuristics to solve the pricing first and, if it fails,
the ADAPTIVE algorithm is called. Table 9 shows the average performance in each
case to solve the linear relaxation at the root node for the 40 instances in class
RAND . Line opt exhibits the total number of instances solved at optimality. Consider now just the instances solved at optimality by the four algorithms. Line fast
shows the number of instances that were solved faster for each algorithm while
line speed-up presents the average speed-up rate defined as the ratio between
the running times of the slower and the current method, respectively.
SOLVER,

SOLVER

TRICK

ADAPTIVE

ADAPTIVE *

opt

40

30

40

40

fast

0

25

0

5

1.01

15.29

12.38

12.18

speed-up

Table 9. Comparison among different algorithms to solve the pricing problem.

We can see from Table 9 that TRICK’s algorithm solved more instances faster
than the others, but it could not solve all instances to optimality. The difficulty
for this method is related to graphs with low density (≤ 30%). Overall, the best
performance was achieved by the ADAPTIVE * algorithm.
The performance of our branch-and-price algorithm with ADAPTIVE * pricing
(BP) is now compared to that of the branch-and-cut (BC) from [3], whose code was
made available to us. The results are summarized in Table 10. Columns opt, fast,
and speed-up have the same meaning as in Table 9. Column dual represents
the total of instances with better dual bound at the root node. It came as no surprise
that the dual bounds from BP surpassed those from BC since, as mentioned earlier,
the linear relaxation of the former is at least as good as the one used in the latter.

189

Inspecting column opt, we can see that BP solved more instances to optimality
than BC. Moreover, the improvement in the speed-up rate using the BP code was
far more impressive. However, BC presented a slight better performance for the
NSF class.
BC
instance

BP

opt

fast

dual

speed-up

opt

fast

dual

speed-up

RAND

47

15

6

3.22

64

29

73

36.9

NSF

37

28

3

6.17

49

9

23

4.17

Table 10. Comparative between BC and BP.

Conclusions. We proposed a new formulation for the Partition Coloring Problem
which combines the IS and the representatives models. A branch-and-price algorithm was developed to compute this model exactly. Experiments showed that our
approach is highly competitive with a branch-and-cut algorithm proposed earlier,
outperforming the latter for random graphs. The development of the branch-andprice algorithm is still on going and we plan to test the code on other classes which
include practical instances.

References
[1] M. Campêlo, V. Campos, R. Corrêa, and C. Rodrigues. On fractional and
integral chromatic numbers of a graph via cutting and pricing. In Proceedings
of the Fifth ALIO/EURO Conference on Combinatorial Optimization (2005)
pp. 42–42.
[2] M. Campêlo, R. Corrêa, and Y. Frota. Cliques, holes and the vertex coloring
polytope. Information Processing Letters 89 (2004) pp. 159–164.
[3] Y. Frota, N. Maculan, T. Noronha, and C.C. Ribeiro. A branch-and-cut algorithm for partition coloring. In Proceedings of the International Network
Optimization Conference (2007).
[4] L. Lasdon. Optimization Theory for Large Systems. MacMillan (1970).
[5] G. Li and R. Simha. The partition coloring problem and its application to
wavelength routing and assignment. in Proceedings of the First Workshop on
Optical Networks (2000).
[6] A. Mehrotra and M. A. Trick. A column generation approach for graph coloring. INFORMS Journal on Computing 8 (1996) pp. 344–354.

190

Two upper bounds on the Chromatic Number
Marı́a Soto, 1 André Rossi, Marc Sevaux
Université de Bretagne-Sud
Lab-STICC, CNRS UMR 3192
Centre de Recherche B.P. 92116
F-56321 Lorient Cedex FRANCE
Key words: Graph coloring, Chromatic number, Upper bounding scheme

1. Introduction

Processor cache memory management is a challenging issue as it deeply impact performances and power consumption of electronic devices. It has been shown
that allocating data structures to memory for a given application (as MPEG encoding, filtering or any other signal processing application) can be modeled as a
minimum k-weighted graph coloring problem, on the so-called conflict graph. The
graph coloring problem plays an important role as a particular case of the minimum
weighted graph coloring problem, and providing upper bounds on the minimum
number of colors to be used is an important issue for addressing these memory allocation problems.
A coloring of graph G = (X, U) is a function F : X → N∗ ; where each node
in X is allocated an integer value that is called a color. A proper coloring satisfies
F (u) 6= F (v) for all (u, v) ∈ U [2]. The chromatic number of G, denoted by χ(G),
is the smallest number of colors involved in any proper coloring. Determining χ(G)
for any graph G is a N P-hard problem [1] however there are some well known particular cases: χ(G) = 1 if and only if G is a totally disconnected graph, χ(G) = 2
for any exactly bipartite graphs (including trees and forests) and χ(G) = |X| if G
is complete.
In this paper, we focus on upper bounds for χ(G) for any simple undirected
graph G. The following bounds on the chromatic number can be found in [1].
• χ(G) ≤ δ(G)√ + 1 = d, where δ(G) is the highest degree on G.
• χ(G) ≤ b 1+ 8m+1
c = l, where n = |X| is the number of vertexes and m = |U|
2
1

Corresponding author: maria.soto@univ-ubs.fr

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

is the number of edges.

This paper is organized as follows. The next section introduces two new upper bounds for the chromatic number, without making any assumption on the graph
structure. The first bound ξ is based on the number of the edges and nodes, and is to
be applied to any connected component of the graph. The second bound ζ is based
on the degree of the nodes in the graph. Section three briefly sketches the results
obtained on a large set of instances used for assessing the quality of these bounds.
This section will be widely extended in the full paper version of this abstract. Section four provides some conclusions and directions for future work.

2. Two new upper bounds on the chromatic number

Lemma 2.1. The following inequality holds for any connected, simple, undirected
graph.
χ(G) ≤

3 +

q

9 + 8(m − n) 
2

=ξ

(2.1)

Proof of Lemma 2.1. There exists at least one edge between any pair of colors [1].
Such an edge joins node u and node v with F (u) 6= F (v). Since G is not directed,
(u, v) = (v, u), there are at least χ(G)(χ(G) − 1)/2 such edges. The minimum
number of nodes connected by χ(G)(χ(G) − 1)/2 edges are the χ(G) nodes of a
clique. Then, these χ(G)(χ(G) − 1)/2 edges must connect at least χ(G) nodes in
X (because the structure that involves k nodes and k(k − 1)/2 edges is a k-clique,
that is a complete partial graph of G). As G is connected, at least n − χ(G) other
edges are required for connecting the other n − χ(G) nodes to the χ(G) nodes
previously considered. Therefore m can be lower bounded as follows:
m≥

χ(G)(χ(G) − 1)
+ n − χ(G)
2

This inequality leads to a second degree polynom in the variable χ(G), and solving
it leads to (2.1).
2
Lemma 2.2. The chromatic number of any non directed, simple graph has the following property:
χ(G) ≤ ζ where ζ is the greatest integer such that there exist at least ζ nodes in X
which degree is greater than or equal to ζ − 1.

192

The second bound is indirectly based on the degree of saturation † of nodes, DS(v)
and its proof relies on Theorem 2.3. The following notation are used in this paper.
• C = {1..χ(G)} is the minimum set of colors used in any valid coloring.
• A valid (or proper) coloring using exactly χ(G) colors is said to be a minimal
coloring.
• The neighborhood of node v denoted N(v) is the set of all nodes u such that
(u, v) belongs to U.
Theorem 2.3. Let F be a minimal coloring of G. For all color k in C, there exists a
node v colored with k,(i.e. F (v) = k), such that its degree of saturation is χ(G)−1,
i.e. DS(v) = χ(G) − 1.
Proof of Theorem 2.3. The theorem is shown by contradiction.
It is shown that for all k in C there exists a node v, colored with k, such that
DS(v) = χ(G) − 1. To do so, it is assumed that there exists a color k such that all
node v colored with k have a degree of saturation being strictly less than χ(G) − 1.
Then, for all v ∈ X such that F (v) = k, ∃c ∈ C\{k} such that there does not
exist u ∈ N(v)|F (u) = c. Consequently, a new valid coloring can be by setting
F (v) = c. This operation can be performed for any node colored with k, leading
to a coloring that involves χ(G) − 1 colors, which is impossible by definition of the
chromatic number.
2
Proof of Lemma 2.2. It can be deduced from Theorem 2.3 that there exist at least
χ(G) nodes in G which degree is at least χ(G) − 1. So, ζ = χ(G) is the smallest
integer such that there exist ζ nodes which degree is at least ζ − 1 and such that
χ(G) ≤ ζ. Consequently χ(G) is less than or equal to the greatest integer satisfying this condition.
2

3. Assessing the new bounds quality

The new bounds introduced in this abstract were tested with existing bounds
on a large set of instances from literature. As a result, ζ and ξ have the best performances on chromatic number bounds because ζ reaches the best value on 95 % of
the instances and so does ξ on the remaining 5 %. Furthermore, ζ is significantly
better than the others bounds as its value is in average 48% lesser than the others
ones. It can also be observed that there is no dominance relationship between ξ and
d as d is better than ξ on 45 % of the instances where ξ is on average 44% lesser
than d, and d is better than ξ on 55 % of the instances where d is on average only
34% lesser than ξ. Whereas, it has been proved that ξ ≤ l, these bounds have per†

The degree of saturation of a node v ∈ X denoted DS(v) is the number of different
colors at the nodes adjacent to v [3], [2].

193

formances very closer in practice.
Due to a lack of space, extended results will be presented at the conference.

4. Conclusion

The two upper bounds on the chromatic number introduced in this paper appear
to be significantly better than the previously known ones. They are of particular
interest for microprocessor cache memory management as they enable to reduce
the search space for non conflicting memory allocations. These new bounds are
easily computable even for large graphs as ξ complexity is O(1) and ζ is O(m).
However, there is room for improvement as the gap with the chromatic number
remains quite large. Using more information on graphs topology appears to be a
promising direction for future work.

References
[1] Reinhard Diestel. Graph Theory, volume 98 of Graduate Texts in Mathematics. Springer-Verlag, Heidelberg, July 2005.
[2] Klotz Walter, Graph Coloring Algorithms, Mathematik-Bericht 5 (2002),1-9,
Tu Clausthal.
[3] Brélaz, D.,New methods to color the vertices of a graph, Communications of
the Assoc. of Comput. Machinery 22 (1979), 251-256

194

Minimum sum set coloring on some subclasses of
block graphs 1
Flavia Bonomo, a Guillermo Durán, b Javier Marenco, c
Mario Valencia-Pabon d
a CONICET,

Argentina and Departamento de Computación, FCEN, Universidad de
Buenos Aires, Argentina
fbonomo@dc.uba.ar

b CONICET,

Argentina and Departamento de Matemática, FCEN, Universidad de Buenos
Aires, Argentina and Departamento de Ingenierı́a Industrial, FCFyM, Universidad de
Chile, Chile
gduran@dm.uba.ar

c Departamento

de Computación, FCEN, Universidad de Buenos Aires, Argentina and
Instituto de Ciencias, Universidad Nacional de General Sarmiento, Argentina
jmarenco@ungs.edu.ar
d LIPN,

Université Paris-Nord, France
valencia@lipn.univ-paris13.fr

Abstract
In this work we study the Minimum Sum Set Coloring Problem (MSSCP) which consists
in assign a set of ω(v) positive integers to each vertex v of a graph so that the intersection
of sets assigned to adjacent vertices is empty and the sum of the assigned set of numbers to
each vertex of the graph is minimum. This problem generalizes the well known Minimum
Sum Coloring Problem, which is solvable in polynomial time on block graphs. We study
two versions of the MSSCP (preemptive and non-preemptive) on two subclasses of block
graphs: trees and line graphs of trees. This allows us to show that both versions of the
problem are NP-complete on block graphs. We also find polynomial-time algorithms for
the MSSCP under certain conditions.
Key words: graph coloring, minimum sum coloring, set-coloring, block graphs

A vertex coloring of a graph is an assignment of colors (positive integers)
to its vertices such that adjacent vertices receive different colors. The sum of the
1

Partially supported by ANPCyT PICT-2007-00518 and 00533, UBACyT Grants X069
and X606 (Arg.), FONDECyT Grant 1080286 and Millennium Science Institute “Complex
Engineering Systems” (Chile), and BQR-UPN-2008 Grant (France).

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

coloring is the sum of the colors assigned to the vertices. The chromatic sum Σ(G)
of a graph G is the smallest sum that can be achieved by any vertex coloring of G.
In the Minimum Sum Coloring Problem (MSCP) we have to find a coloring of G
with sum Σ(G).
The MSCP was introduced by Kubicka [11]. The problem is motivated by applications in scheduling [1; 2; 8; 9] and VLSI design [15; 17]. The computational
complexity of determining the vertex chromatic sum of a simple graph has been
studied extensively since then. In [12] it is shown that the problem is NP-hard
in general but solvable in polynomial-time for trees. The dynamic programming
algorithm for trees can be extended to partial k-trees and block graphs [10]. Furthermore, the MSCP is NP-hard even when restricted to some classes of graphs for
which finding the chromatic number is easy, such as bipartite or interval graphs [2;
17]. A number of approximability results for various classes of graphs were obtained in the last ten years [1; 6; 8; 9; 4].
In an analogous way, it has been defined the edge coloring version of the
MSCP: the Minimum Sum Edge Coloring Problem (MSECP). The MSECP is NPhard for bipartite graphs [7], even if the graph is also planar and has maximum
degree 3 [13]. Furthermore, in [13] is also shown that the MSECP is NP-hard for
3-regular planar graphs and for partial 2-trees. For trees, the MSECP can be solved
in polynomial time [7; 16; 18] by a dynamic programming algorithm that uses
weighted bipartite matching as a subroutine (see also [10]). In [3] it has been shown
that this problem is also polynomial-time solvable for multicycles (i.e., cycles with
parallel edges). For general multigraphs, a 1.829-approximation algorithm for the
MSECP is presented in [9]. For bipartite graphs there exist better approximation
ratios: a 1.796-approximation algorithm is given in [8], and a 1.414-approximation
algorithm is proposed recently in [5].
An interesting application of the MSECP is to model dedicated scheduling of
biprocessor jobs. The vertices correspond to the processors and each edge e = uv
corresponds to a job that requires a time unit of simultaneous work on the two
preassigned processors u and v. The colors correspond to the available time slots.
A processor cannot work on two jobs at the same time, this corresponds to the
requirement that a color can appear at most once on the edges incident to a vertex.
The objective is to minimize the average time before a job is completed. When
there can be ω(e) instances of the same job, it arises the notion of set-coloring of
the corresponding conflict graph. Formally, given a simple graph G = (V, E) and a
demand function ω : V → Z + , a vertex set-coloring of (G, ω) consists in assigning
to each vertex v ∈ V a set of ω(v) colors in such a way that adjacent vertices will
be assigned disjoint sets of colors. Given a vertex set-coloring of a graph G with
demand function ω, the sum of the set-coloring is the sum of the colors in the set
assigned to each one of the vertices. The chromatic set-sum Σ(G, ω) of (G, ω) is
the smallest sum that can be achieved by any proper set-coloring of (G, ω). In the
Minimum Sum Set Coloring Problem (MSSCP) we have to find a set-coloring of

196

(G, ω) with sum Σ(G, ω). Clearly, when ω(v) = 1 for each vertex v of the graph,
the MSSCP becomes the MSCP. The dedicated scheduling of biprocessor jobs with
multiple instances can be modeled as a MSSCP on the line graph of the conflict
graph. A similar problem where each job e requires ω(e) time units of dedicated
biprocessors, thus leading to a different objective function, was studied in [14].
In this case, sometimes it is allowed that a job is interrupted and continue later :
the set of colors assigned to a vertex does not have to be consecutive. This type
of scheduling is called preemptive (assuming that preemptions can happen only at
integer times). Otherwise, if the set of colors assigned to each vertex needs to be
consecutive, then the scheduling is called non-preemptive. In our case, the nonpreemptive case arises when each job requires a high cost setup on the processors,
and thus the objective is to minimize the average time before a job is completed,
within the solutions minimizing the setup costs. Therefore, we have two variants of
the MSSCP : the preemptive (pMSSCP) and the non-preemptive (npMSSCP) one.
Let G = (V, E) be a graph with a demand function ω : V → Z + . Denote n =
|V |, ∆ the maximum degree of G, and ωmax = maxv∈V ω(v). The family of block
graphs includes as special cases trees and line graphs of trees. We found dynamic
programming algorithms for pMSSCP and npMSSCP on trees and line graphs of
trees, that run in polynomial time under certain assumptions, like bounded degree
or demand, or considering nωmax as the size of the input. This last assumption
makes sense specially in the preemptive case, where the output of the algorithm
are the lists of ω(v) colors assigned to each vertex v, and they can be formed by
non-consecutive numbers.
2
Theorem 0.1. The npMSSCP on trees can be solved in O(n∆2 ωmax
) time.

Theorem 0.2. The pMSSCP on trees can be solved in O(n(∆ωmax )2ωmax ) time.
Theorem 0.3. The npMSSCP for line graphs of trees can be solved in
∆+1
O(∆3 n∆+2 ωmax
) time.
As a counterpart, we showed the NP-completeness of the preemptive and nonpreemptive MSSCP on trees and their line graphs, respectively.
Theorem 0.4. The pMSSCP on trees and the npMSSCP on line graphs of trees
are NP-complete, even considering the sum of the demands as the size of the input
graph.
These results show that the MSSCP is NP-hard on block graphs, both in the
preemptive and non-preemptive case, and that the computational complexity of the
MSCP and the MSSCP (resp. the pMSSCP and the npMSSCP) can be different for
the same family of graphs.

197

References
[1] A. Bar-Noy, M. Bellare, M. M. Halldórsson, H. Shachnai, and T. Tamir.
On chromatic sums and distributed resource allocation. Inf. Comput.,
140(2):183–202, 1998.
[2] A. Bar-Noy and G. Kortsarz. Minimum color sum of bipartite graphs. J.
Algorithms, 28(2):339–365, 1998.
[3] J. Cardinal, V. Ravelomanana, and M. Valencia-Pabon. Minimum Sum Edge
Coloring of Multicycles. Manuscript (ext. abstract in ENDM, 30:39–44,
2008).
[4] U. Feige, L. Lovász, and P. Tetali. Approximating min sum set cover. Algorithmica, 40(4):219–234, 2004.
[5] R. Gandhi and J. Mestre. Combinatorial algorithms for data migration to
minimize average completion time. To appear in Algorithmica.
[6] K. Giaro, R. Janczewski, M. Kubale, and M. Malafiejski. Approximation
algorithm for the chromatic sum coloring of bipartite graphs. Lect. Notes
Comput. Sci. 2462:135–145, 2002.
[7] K. Giaro and M. Kubale. Edge-chromatic sum of trees and bounded cyclicity
graphs. Inf. Process. Lett., 75(1–2):65–69, 2000.
[8] M. M. Halldórsson, G. Kortsarz, and H. Shachnai. Sum coloring interval and
k-claw free graphs with application to scheduling dependent jobs. Algorithmica, 37(3):187–209, 2003.
[9] M. M. Halldórsson, G. Kortsarz, and M. Sviridenko. Min Sum Edge Coloring
in Multigraphs Via Configuration LP. Lect. Notes Comput. Sci. 5035:359–
373, 2008.
[10] K. Jansen. Complexity results for the optimum cost chromatic partition problem. Lect. Notes Comput. Sci. 1256:727–737, 1997.
[11] E. Kubicka. The Chromatic Sum of a Graph. PhD thesis, Western Michigan
University, 1989.
[12] E. Kubicka and A. J. Schwenk. An introduction to chromatic sums. In Proc.
of ACM Computer Science Conf., p. 15–21. Springer, 1989.
[13] D. Marx. Complexity results for minimum sum edge coloring. To appear in
Discrete Appl. Math.
[14] D. Marx. Minimum sum multicoloring on the edges of trees. Theoret. Comput. Sci., 361(2-3):133–149, 2006.
[15] S. Nicoloso, M. Sarrafzadeh, and X. Song. On the sum coloring problem on
interval graphs. Algorithmica, 23(2):109–126, 1999.
[16] M. Salavatipour. On sum coloring of graphs. Discrete Appl. Math.,
127(3):477–488, 2003.
[17] T. Szkaliczki. Routing with minimum wire length in the dogleg-free manhattan model is NP-complete. SIAM J. Comput., 29(1):274–287, 1999.
[18] X. Zhou and T. Nishizeki. Algorithm for the cost edge-coloring of trees. J.
Comb. Optim., 8(1):97–108, 2004.

198

Acyclic and Star Colorings of Joins of Graphs and an
Algorithm for Cographs
Andrew Lyons
Computation Institute, University of Chicago and
Mathematics and Computer Science Division, Argonne National Laboratory
lyonsam@gmail.com

Key words: acyclic coloring, star coloring, cographs

An acyclic coloring of a graph is a proper vertex coloring such that the subgraph induced by the union of any two color classes is a disjoint collection of trees.
The more restricted notion of star coloring requires that the union of any two color
classes induces a disjoint collection of stars. The acyclic and star chromatic numbers of a graph G are defined analogously to the chromatic number χ(G) and are
denoted by χa (G) and χs (G), respectively. In this paper, we consider acyclic and
star colorings of graphs that are decomposable with respect to the join operation,
which builds a new graph from a collection of two or more disjoint graphs by
adding all possible edges between them. In particular, we present a recursive formula for the acyclic chromatic number of joins of graphs and show that a similar
formula holds for the star chromatic number. We also demonstrate the algorithmic implications of our results for the cographs, which have the unique property
that they are recursively decomposable with respect to the join and disjoint union
operations.

1. Introduction

Both acyclic and star colorings have applications in the field of combinatorial
scientific computing, where they model two different schemes for the evaluation of
sparse Hessian matrices. The general idea behind the use of coloring in computing
derivative matrices is the identification of entities that are essentially independent
and thus may be computed concurrently; see [5] for a survey.
A number of results exist for acyclic and star colorings of graphs formed by
certain graph operations. Results have been obtained for Cartesian products of
paths [4], trees [9], cycles [7], and complete graphs [8]. In Section 2, we describe
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

the acyclic and star chromatic numbers of graphs formed by the join operation. The
join of a collection {Gi = (Vi , Ei )}i∈I of pairwise disjoint graphs, denoted ⊕, is
S
the graph G = (V, E), where V = i∈I Vi and E = {ab | ab ∈ Ei , i ∈ I} ∪ {ab |
a ∈ Vi , b ∈ Vj , i, j ∈ I, i 6= j}. Here and throughout this paper, I denotes a finite
index set.
The problems of finding optimal acyclic and star colorings are both N P-hard
and remain so even for bipartite graphs [2; 1]. It was shown recently [6] that every
coloring of a chordal graph is also an acyclic coloring. Since recognizing and optimally coloring chordal graphs can be done in linear time, this result immediately
implies a linear time algorithm for the acyclic coloring problem on chordal graphs.
A generalization of this result and other related results can be found in [10], where
it is shown that the graphs for which every acyclic coloring is also a star coloring
are exactly the cographs. In Section 3, we show that our results imply a linear time
algorithm for finding optimal acyclic and star colorings of cographs.

2. Joins of graphs

In this section, we outline a proof of the following theorem.
Theorem 9. Let {Gi = (Vi , Ei )}i∈I be a finite collection of graphs. Then
(i) χa

Gi =

M

Gi =

i∈I

(ii) χs

!

M
i∈I

!

X

χa (Gi ) + min

X

χs (Gi ) + min

i∈I

i∈I

j∈I

j∈I


 X


 i∈I,i6=j
 X


i∈I,i6=j




(|Vi | − χa (Gi )) ;




(|Vi | − χs (Gi )) .


For ease of exposition, we will focus on the case where G is the join of exactly
two graphs as in the following lemma. To see that these results generalize to joins
of arbitrarily large collections of graphs, first observe that the join operation is
commutative and associative; the result is then obtained by using induction on |I|.
Lemma 4. Let G1 = (V1 , E1 ) and G2 = (V2 , E2 ) be graphs. Then
(i) χa (G1 ⊕ G2 ) = χa (G1 ) + χa (G2 ) + min {|V1 | − χa (G1 ), |V2 | − χa (G2 )} ;
(ii) χs (G1 ⊕ G2 ) = χs (G1 ) + χs (G2 ) + min {|V1 | − χs (G1 ), |V2| − χs (G2 )} .
We now sketch the idea behind the proof of this lemma. Suppose we are given
graphs G1 and G2 and we wish to find an optimal acyclic or star coloring of their
join. Since every vertex in V1 is adjacent to every vertex in V2 , no color can occur in
V1 and V2 simultaneously. Moreover, the desired coloring must also be valid for the
subgraphs induced by each Vi , i ∈ {1, 2}, where the lower bound will be χa (Gi ) or
χs (Gi ) depending on the type of coloring that is sought. The key observation is that
200

at least one Vi must be saturated, meaning that each vertex receives a unique color.
It can be shown that G will otherwise contain a bichromatic cycle – a violation of
the conditions of acyclic coloring. Furthermore, such a bichromatic cycle implies a
bichromatic path on four vertices, which cannot occur in a star coloring. Thus, given
disjoint optimal acyclic colorings of G1 and G2 , an optimal acyclic coloring of their
join can be constructed by saturating the graph Gi that minimizes |Vi | − χa (Gi ). It
is easy to see that the same procedure can be used in the context of star coloring.

3. Cographs

In this section, we outline a linear time algorithm for finding optimal acyclic
and star colorings of cographs. The algorithm works on the cotree — defined below
— in a way that is typical for algorithms on cographs. We begin with some definitions. The disjoint union of a collection {Gi = (Vi , Ei )}i∈I of pairwise disjoint
S
S
graphs, denoted ∪, is the graph G = (V, E), where V = i∈I Vi and E = i∈I Ei .
A graph G = (V, E) is a cograph if and only if one of the following is true:
(i) |V | = 1;
[
(ii) there exists a collection {Gi }i∈I of cographs such that G = Gi ;

(iii) there exists a collection {Gi }i∈I of cographs such that G =

i∈I
M

Gi .

i∈I

Cographs can be recognized in linear time [3], where most recognition algorithms
also produce a special decomposition structure when the input graph G is a cograph.
We associate with a cograph G a tree TG called a cotree, whose leaves correspond
to the vertices of G and whose internal nodes are labeled either 0 or 1. The 0-nodes
correspond to the disjoint union of their children, and the 1-nodes correspond to the
join of their children.
As in Section 2, we describe the binary case, which can be appropriately generalized. The algorithm proceeds by traversing the cotree starting with the leaves,
such that no node is visited before both of its children have been visited. We do the
following when we visit a node t ∈ TG with children t1 and t2 . If t is a 0-node,
we construct a coloring that uses χa (t) = max{χa (t1 ), χa (t2 )} colors in the obvious way. If t is a 1-node, we use the process described in Section 2 to construct
a coloring that is optimal by Theorem 9. Since the algorithm produces an optimal
acyclic coloring for every node in the cotree, the last step will produce an optimal acyclic coloring of G itself. Our final theorem follows from the fact that every
acyclic coloring of a cograph is also a star coloring and vice versa.
Theorem 10. An optimal acyclic coloring of a cograph can be found in linear time.
Furthermore, the obtained coloring is also an optimal star coloring.

201

Acknowledgments. This work was supported in part by U.S. Department of
Energy, under Contract DE-AC02-06CH11357.

References
[1] Thomas F. Coleman and Jin-Yi Cai. The cyclic coloring problem and estimation of sparse Hessian matrices. SIAM J. Alg. Disc. Meth., 7:221–235, 1986.
[2] Thomas F. Coleman and Jorge J. Moré. Estimation of sparse Hessian matrices
and graph coloring problems. Mathematical Programming, 28(3):243–270,
1984.
[3] Derek G. Corneil, Yehoshua Perl, and Lorna K. Stewart. A linear recognition
algorithm for cographs. SIAM Journal on Computing, 14(4):926–934, 1985.
[4] Guillaume Fertin, Emmanuel Godard, and André Raspaud. Acyclic and kdistance coloring of the grid. Information Processing Letters, 87(1):51–58,
2003.
[5] Assefaw Hadish Gebremedhin, Fredrik Manne, and Alex Pothen. What color
is your Jacobian? Graph coloring for computing derivatives. SIAM Review,
47(4):629–705, 2005.
[6] Assefaw Hadish Gebremedhin, Alex Pothen, Arijit Tarafdar, and Andrea
Walther. Efficient computation of sparse Hessians using coloring and automatic differentiation. INFORMS J. Computing, 21(2), 2009.
[7] Robert E. Jamison and Gretchen L. Matthews. Acyclic colorings of products
of cycles. Bulletin of the Institute of Combinatorics and its Applications,
54:59–76, 2008.
[8] Robert E. Jamison and Gretchen L. Matthews. On the acyclic chromatic number of hamming graphs. Graph. Comb., 24(4):349–360, 2008.
[9] Robert E. Jamison, Gretchen L. Matthews, and John Villalpando. Acyclic
colorings of products of trees. Information Processing Letters, 99(1):7–12,
2006.
[10] Andrew Lyons. Restricted coloring problems and forbidden induced subgraphs. Preprint ANL/MCS-P1611-0409, Mathematics and Computer Science Division, Argonne National Laboratory, April 2009.

202

Exact Algorithms

Lecture Hall A

Wed 3, 14:00–15:30

Exact exponential-time algorithms for finding
bicliques in a graph
Henning Fernau, a Serge Gaspers, b Dieter Kratsch, c
Mathieu Liedloff, d Daniel Raible a
a Universität
b LIRMM
c LITA,

Trier, FB 4—Abteilung Informatik, D-54286 Trier, Germany
{fernau,raible}@uni-trier.de

– University of Montpellier 2, CNRS, 34392 Montpellier, France
gaspers@lirmm.fr
Université Paul Verlaine - Metz, 57045 Metz Cedex 01, France
kratsch@univ-metz.fr

d LIFO,

Université d’Orléans, 45067 Orléans Cedex 2, France
liedloff@univ-orleans.fr

Key words: graph, exact exponential-time algorithm, NP-hard problem, biclique

1. Introduction
Throughout the paper all graphs G = (V, E) are undirected and simple. An induced biclique of G is a complete bipartite induced subgraph of G. A non-induced
biclique is a complete bipartite (not necessarily induced) subgraph of G. Equivalently, the pair (X, Y ) of disjoint vertex subsets X ⊆ V and Y ⊆ V is a noninduced biclique of G if {x, y} ∈ E for all x ∈ X and y ∈ Y . If, additionally, X
and Y are independent sets, then (X, Y ) is also an induced biclique of G. Let the
pair (X, Y ) be an induced or non-induced biclique. We call it a (k1 , k2 ) biclique if
|X| = k1 and |Y | = k2 . Its cardinality is |X| + |Y |.
The literature dealing with bicliques is rich and diverse. There are applications of bicliques (induced or non-induced on bipartite graphs or general graphs) in
various different areas such as data mining, automata and language theory, artificial
intelligence and biology, see e.g. [1]. Therefore bicliques and algorithmic problems
about bicliques have been studied extensively.
Known results. Already in [3], the complexity of finding certain bicliques has
been considered. For example, deciding whether a bipartite graph has a balanced
biclique of size (at least) k is NP-complete ([GT24] in [3]). A maximum cardinality induced biclique can be computed in polynomial time on bipartite graphs [2],
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

wheras this problem is NP-complete for general graphs [7]. Another related problem that asks to compute a non-induced biclique with a maximum number of edges
is also known to be NP-hard [6].
The above-mentioned NP-completeness of the balanced biclique problem on
bipartite graphs implies the NP-completeness of the following two problems about
the existence of induced and non-induced bicliques, respectively.
Induced (k1 , k2 ) Biclique
Input: An undirected graph G = (V, E), positive integers k1 and k2 .
Question: Does G have an induced (k1 , k2 ) biclique (X, Y )?
Non-Induced (k1 , k2 ) Biclique
Input: An undirected graph G = (V, E), positive integers k1 and k2 .
Question: Does G have a non-induced (k1 , k2 ) biclique (X, Y )?
There is a trivial O ∗ (3n ) algorithm for finding and also for enumerating all induced and non-induced (k1 , k2 ) bicliques, respectively. ∗ It considers all partitions
of the vertex set into X, Y and V \ (X ∪ Y ) and verifies for each whether (X, Y )
fulfils all conditions.
Our results. For generating all non-induced (k1 , k2 ) bicliques, note that there
is no hope in obtaining a faster algorithm than the above-described O ∗ (3n ) algorithm, as a complete graph on n vertices has 3n poly(n) non-induced (bn/3c, bn/3c)
bicliques. For solving the Non-Induced (k1 , k2 ) Biclique problem, however, we
give a polynomial-space O(1.8899n) algorithm and an exponential-space O(1.8458n)
algorithm.
There is also an O ∗ (3n/3 ) time algorithm to solve Induced (k1 , k2 ) Biclique.
This algorithm is based on enumerating all maximal induced bicliques of the graph
with a polynomial delay algorithm and on the fact that an n-vertex graph has
O ∗ (3n/3 ) maximal induced bicliques [4].

2. Polynomial-space algorithms for finding a non-induced biclique
We start by describing two simple O ∗ (2n ) time algorithms for the Non-Induced
(k1 , k2 ) Biclique problem. We will use these algorithms as subroutines in our third
algorithm with running-time O(1.8899n) and polynomial space usage.
The first algorithm, NIB1, verifies all sets Xc ⊆ V with |Xc | = k1 as candidates for being the set X in the pair (X, Y ). It computes for each Xc the set
∗

Throughout the paper we write f (n) = O∗ (g(n)) if f (n) ≤ p(n) · g(n) for some
polynomial p(n).

206

B(Xc ) := {v ∈ V \ Xc | ∀x ∈ Xc : v ∈ N(x)}. If |B(Xc )| < k2 then the
algorithm rejects the candidate Xc . Otherwise it picks an arbitrary set Yc ⊆ B(Xc )
with |Yc | = k2 , and clearly (Xc , Yc ) is a non-induced (k1 , k2) biclique. The only
exponential part is the enumeration step and thus the running-time is O ∗ (2n ).
The second algorithm, NIB2, verifies all sets U ⊆ V with |U| = k1 + k2 and
checks for each whether there is a non-induced biclique (X, Y ) such that |X| = k1
and |Y | = k2 . This can be done in polynomial time by computing the connected
components of the complement of G[U]. If s1 , s2 , . . . , st are the sizes of those components, then there is a non-induced biclique as described above iff there is an
P
I ⊆ {1, 2, . . . , t} such that i∈I si = k1 . Such a S UBSET S UM problem can be
solved in time O(nW ) by dynamic programming, where W = maxi si . The only
exponential part is the enumeration step and thus the running-time is O ∗ (2n ).
For the third algorithm, NIB3, suppose w.l.o.g. that k1 ≤ k2 . If k1 ≤ bn/3c,
thenrun 
NIB1, otherwise run NIB2. Thus, the running-time
of NIB3
 is at most
n
n
n
∗
∗
= O(1.8899n)
= O(1.8899 ) if NIB1 is executed and at most O
O
2n/3
n/3
if NIB2 is executed.
Theorem 2.1. Algorithm NIB3 solves the Non-Induced (k1 , k2 ) Biclique problem in time O(1.8899n) and polynomial space.

3. Exponential-space algorithm for finding a non-induced biclique

In this section we provide an exponential-space algorithm for the the NonInduced (k1 , k2 ) Biclique problem in time O(1.8458n ). The algorithm relies on a
preprocessing involving a dynamic programming approach. It is described by the
forthcoming three steps called Partitioning, Preprocessing and Computing.

3.1 Description of the algorithm
Partitioning Step. Let α be a constant to be determined. Given the graph G =
(V, E), compute an arbitrary partition of the vertex set into two subsets L and R
such that |R| = dαne and |L| = b(1 − α)nc.
Preprocessing Step. This step focuses on the vertices of R. For any two (not
necessarily disjoint) subsets X, Y ⊆ R and any two integers i and j, 0 ≤ i, j ≤ |R|,
we compute the value of the boolean R-biclique[X, i, Y, j] which is true iff there
exist two subsets X 0 ⊆ X and Y 0 ⊆ Y such that (X 0 , Y 0 ) is a non-induced (i, j)
biclique. To compute the values of R-biclique, the sets X, Y and the integers i, j
are considered by increasing cardinality and order.

207

For any X, Y ⊆ R and i, j, such that 0 ≤ i, j ≤ |R|, R-biclique[X, 0, Y, 0] is
clearly true. Obviously R-biclique[∅, i, Y, j] is true iff i = 0 and R-biclique[X, i, ∅,
j] is true iff j = 0. For any other value, R-biclique[X, i, Y, j] is true iff
W

W

v∈X
v∈Y



R-biclique[X \ {v}, i, Y, j] ∨ R-biclique[X \ {v}, i − 1, N (v) ∩ Y, j] ∨


R-biclique[X, i, Y \ {v}, j] ∨ R-biclique[N (v) ∩ X, i, Y \ {v}, j − 1] .

Computing step. If the graph admits a non-induced (k1 , k2 ) biclique, then it is
found during this final step. For every two disjoint subsets XL , YL ⊆ L for which
(XL , YL) is a non-induced biclique with |XL | ≤ k1 , |YL| ≤ k2 , let XR0 = {v ∈ R : v
is adjacent to every vertex of YL} and YR0 = {v ∈ R : v is adjacent to every vertex
of XL }; if R-biclique[XR0 , k1 − |XL |, YR0 , k2 − |YL |] is true then the graph has a
non-induced (k1 , k2 ) biclique and “Yes” is returned.
If the algorithm was not able to find any XL , YL such that R-biclique[XR0 , k1 −
|XL |, YR0 , k2 − |YL |] is true, then the graph has no non-induced (k1 , k2 ) biclique and
it returns “No”. The correctness of the algorithm is shown in the next section. Note
that instead of returning “Yes” or “No”, our algorithm can easily be modified (by
standard backtracking techniques) to indeed return a non-induced (k1 , k2 ) biclique
if one exists.

3.2 Correctness of the algorithm
Assume that G has a non-induced (k1 , k2 ) biclique and let (X, Y ) be such a
biclique. Since (L, R) is a partition of V , it holds that X = XL ∪ XR and Y =
YL ∪ YR where XL = X ∩ L, XR = X ∩ R, YL = Y ∩ L and YR = Y ∩ R. Since
(X, Y ) is a biclique, note that XR ⊆ XR0 and YR ⊆ YR0 where XR0 = {v ∈ R : v is
adjacent to every vertex of YL } and YR0 = {v ∈ R : v is adjacent to every vertex of
XL }. Moreover |XR | = k1 − |XL| and |YR | = k2 − |YL|.
Thus, assuming that XL and YL are given, by definition of R-biclique it is
sufficient to know whether R-biclique[XR0 , k1 − |XL |, YR0 , k2 − |YL |] is true. Since
the Computing step goes through all possible choices for XL and YL, it remains to
show that the formula of the Preprocessing step is correct. Clearly, the base cases
are correct. Let us consider the inductive step. The value R-biclique[X, i, Y, j] is
true iff there exists a vertex v ∈ X (the same argument can be used if v is a vertex of
Y ) such that R-biclique[X \ {v}, i, Y, j] is true (i.e. v does not belong to the (i, j)biclique and thus it is removed from X) or R-biclique[X \ {v}, i − 1, N(v) ∩ Y, j]
is true (i.e. v is a vertex of the (i, j)-biclique and thus it remains to find a (i − 1, j)biclique from X \ {v} and {u ∈ Y \ {v} : {u, v} ∈ E}).

208

3.3 Analysis of the running-time

The Partitioning step can clearly be done in polynomial time. During the Preprocessing step we need to compute R-biclique[X, i, Y, j] for any (not necessarily disjoint) subsets X, Y ⊆ R and any integers i and j, 0 ≤ i, j ≤ |R|. For
each such 4-tuple, R-biclique can be evaluated in polynomial time: go through
all vertices of X ∪ Y and use the previously computed values of R-biclique –
recall that X and Y are considered by increasing cardinality. Thus, to enumerate all X and Y , the algorithm needs O ∗ (4αn ) time. The Computing step needs
to consider all disjoint subsets XL , YL ⊆ L and then to look for already computed values of R-biclique. Consequently, it needs O ∗ (3(1−α)n ) time. Finally the
value of α is choosen to balance the running-time of the last two steps. By setting
α = log(3)/(2 + log(3)) ≈ 0.44211..., our main theorem follows.
Theorem 3.1. The described algorithm solves the Non-Induced (k1 , k2 ) Biclique
problem in time O(1.8458n ) and exponential space.

References
[1] J. Amilhastre, M.C. Vilarem, P. Janssen, Complexity of minimum biclique
cover and minimum biclique decomposition for bipartite dominofree graphs.
Discrete Appl. Math. 86, pp. 125–144 (1998).
[2] M. Dawande, J. Swaminathan, P. Keskinocak, S. Tayur, On bipartite and multipartite clique problems. J. Algorithms 41, pp. 388–403 (2001).
[3] M.R. Garey, D.S. Johnson, Computers and Intractability: A guide to the Theory of NP-completeness. Freeman, New York, 1979.
[4] S. Gaspers, D. Kratsch, M. Liedloff, On Independent Sets and Bicliques in
Graphs, Proceedings of WG 2008, Springer, LNCS 5344, pp. 171-182.
[5] D.S. Hochbaum, Approximating clique and biclique problems, J. Algorithms
29, pp. 174–200 (1998).
[6] R. Peeters, The maximum edge biclique problem is NP-complete, Discrete
Appl. Math. 131, pp. 651–654 (2003).
[7] M. Yannakakis, Node and edge deletion NP-complete problems, Proceedings
of STOC 78, ACM, pp. 253-264 (1978).

209

An Exact Algorithm to Minimize the Makespan in
Project Scheduling with Scarce Resources and
Feeding Precedence Relations
Lucio Bianco, a Massimiliano Caramia a
a Dipartimento

di Ingegneria dell’Impresa, Università di Roma “Tor Vergata”, Via del
Politecnico, 1 - 00133 Roma, Italy
{bianco,caramia}@disp.uniroma2.it

Key words: Branch and bound, Feeding precedences, Lagrangian relaxation

1. Introduction
In this paper we study an extension of the classical Resource-Constrained
Project Scheduling Problem (RCPSP) with minimum makespan objective by introducing a further type of precedence constraints denoted as “Feeding Predecences”
(FP). This problem happens in that production planning environment, like maketo-order manufacturing, which commonly requires the so-called project-oriented
approach. In this approach a project consists of tasks, each one representing a manufacturing process, that is an aggregate activity. Due to the physical characteristics
of these processes the effort associated with a certain activity for its execution can
vary over time. An example is that of the human resources that can be shared among
different simultaneous activities in proportion variable over time. In this case the
amount of work per time unit devoted to each activity, so as its duration, are not
univocally defined. This kind of problems is in general modelled by means of the so
called Variable Intensity formulation, that is a variant of the Resource Constrained
Project Scheduling Problem (see, e.g., Kis, 2006). As the durations of the activities
cannot be taken into play, the traditional finish-to-start precedence relations, so as
the generalized precedence relations, cannot be used any longer, and we need to
introduce the so called “feeding precedences” (see, e.g., Kis, 2005, 2006). Feeding
precedences are of four types:
• Start-to-%Completed (S%C) between two activities (i, j). This constraint imposes that the processed percentage of activity j successor of i can be grater
than 0 ≤ gij ≤ 1 only if the execution of i has already started.
• %Completed-to-Start (%CS) between two activities (i, j). This constraint is
used to impose that activity j successor of i can be executed only if i has been
processed for at least a fractional amount 0 ≤ qij ≤ 1.
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

• Finish-to-%Completed (F%C) constraints between two activities (i, j). This
constraint imposes that the processed fraction of activity j successor of i can
be greater than 0 ≤ gij ≤ 1 only if the execution of i has been completed.
• %Completed-to-Finish (%CF) constraints between two activities (i, j). This
constraint imposes that the execution of activity j successor of i can be completed only if the fraction of i processed is at least 0 ≤ qij ≤ 1.
In the following we propose a new mathematical formulation of the RCPSP
with FP constraints in terms of mixed integer programming. For this formulation a
branch and bound algorithm has been designed and a computational experimentation an randomly generated instances will be provided.

2. The Mathematical Model
We will assume that the planning horizon within which all the production processes have to be scheduled is [0, T ), where T is the project deadline, and it is discretized (without loss of generality) into T unit-width time periods [0, 1), [1, 2), . . . , [T −
1, T ). Let us define with
• qij1 , the fraction of activity i that has to be at least completed in order to let
activity j start;
• qij2 , the fraction of activity i that has to be at least completed in order to let
activity j finish;
• gij1 , the fraction of j that can be at most completed before the starting time of
activity i;
• gij2 , the fraction of j that can be at most completed before the finishing time of
activity i;
• A, the set of activities to be carried out;
• A1 , A2 , A3 and A4 , the sets of pairs of activities for which a S%C, %CS,
F %C, and %CF constraint exists, respectively;
• K, the set of renewable resources each one available in an amount of bk units,
with k = 1, . . . , K;
• qik , the amount of units of resource k necessary to carry out activity i.
Furthermore, let us consider the following decision variables
• xit , the percentage of i executed till time period t.
• sit , fit , binary variables that assumes value 1 if activity i has started or finished
in a time period τ ≤ t, respectively, and assumes value 0 otherwise.


Since the completion time of an activity i ∈ A can be expressed as fi = T −
the objective function can be written as:
n



min {maxi∈A fi } = min maxi∈A T −
211

PT

t=1

fit + 1

o

PT



t=1 fit + 1 ,

that can be easily linearized. The FP relations can be modelled as follows
xjt ≤ si,t−1 + gij1

sjt ≤ xi,t−1 + (1 − qij1 )

xjt ≤ fi,t−1 + gij2

∀(i, j) ∈ A1 , t = 1, . . . , T (1)
∀(i, j) ∈ A2 , t = 1, . . . , T (2)
∀(i, j) ∈ A3 , t = 1, . . . , T (3)

fjt ≤ xi,t−1 + (1 − qij2 )

∀(i, j) ∈ A4 , t = 1, . . . , T (4)

xit ≤ xi,t+1

∀i ∈ A, t = 1, . . . , T − 1

(5)

sit ≤ si,t+1

∀i ∈ A, t = 1, . . . , T − 1

(6)

fit ≤ fi,t+1

∀i ∈ A, t = 1, . . . , T − 1

(7)

siT = fiT = xiT = 1

∀i ∈ A

(8)

si0 = fi0 = xi0 = 0

∀i ∈ A

(9)

fit ≤ xit ≤ sit

∀i ∈ A, t = 1, . . . , T

(10)

P|A|

i=1 qik (xit

− xi,t−1 ) ≤ bk k = 1, . . . , K, t = 1, . . . , T (11)

sit , fit ∈ {0, 1}

∀i ∈ A, t = 1, . . . , T

(12)

xit ≥ 0

∀i ∈ A, t = 1, . . . , T

(13)

Constraints from (1) to (4) model S%C, %CS, F %C and %CF feeding constraints, respectively. Constraints (5) regulate the total amount processed of an activity i ∈ A over time. Constraints (6) imply that if an activity i ∈ A is started
at time t, then variable siτ = 1 for every τ ≥ t, and, on the contrary, if activity i
is not started at time t, siτ = 0 for every τ ≤ t. Constraints (7) are the same as
constraints (6) when finishing times are concerned. Constraints (8) say that every
activity i ∈ A must start and finish within the planning horizon. Constraints (9)
represent initialization conditions for variable sit , fit , xit when t = 0. Constraints
(10) force xit to be zero if sit = 0, and fit to be zero if xit < 1. Resource constraints are represented by relations (11). Constraints (12) and (13) limit the range
of variability of the variables.

3. The Exact Algorithm Scheme
The exact algorithm proposed exploits the mathematical formulation presented
in the previous section and is based on branch and bound rules. The root node α0
of the search tree is associated with the whole problem P0 and two bounds, i.e.,
the trivial upper bound on the minimum makespan given by the time horizon T
and the lower bound on the minimum makespan based on a Lagrangian relaxation
of the resource constraints of the mathematical model (see, Bianco and Caramia,
2009). Each level of the search tree is associated with an activity in the set A of

212

activities, which means that the tree has at most |A| levels. Assume that activity i is
associated with the first level of the tree; then level 1 is formed by T subproblems,
denoted P1t with t = 1, . . . , T , each associated with a time slot t in the time horizon at which activity i can start at the very latest, i.e., at each node α1t at level 1 of
the tree the subproblem P1t associated is obtained from P0 (its parent) by imposing sit = 1. The same analysis described for level 1 can be applied for every level
of the tree, i.e., from a subproblem Piτ at level i we can generate T subproblems
Pi+1,t at level i + 1, with t = 1, . . . , T , each obtained from Piτ by fixing sjt = 1,
where j is the activity associated with level i + 1. Each subproblem Pit undergoes
a bounding phase in which a lower bound on the minimum makespan is computed
as done for the root node. Here we can have three alternative outcomes: (1) the
mathematical program associated with the Lagrangian lower bound is empty, i.e.,
some feeding precedence relations cannot be obeyed, (2) the solution of the Lagrangian relaxation is not feasible with respect to some resource constraints, (3)
the latter solution respects all the resource constraints. Clearly, in the first case the
subtree generating from problem Pit is fathomed since a feasible solution cannot
be found, with a consequent backtracking to the previous level; in the case (2) the
Lagrangian solution value La(Pit ) is a lower bound for subproblem Pit and it is
compared with the best upper bound UB ∗ found so far; if La(Pit ) ≥ UB ∗ then
the tree is pruned again (with a consequent backtracking) otherwise the search is
continued in a depth first search strategy. In the last occurrence, i.e., in the case (3),
the solution value f (Pit ), obtained by substituting xit , sit , fit values obtained by
the Lagrangian relaxation in Pit , is an upper bound for the latter subproblem and
therefore it is an upper bound on the whole problem P0 . Now, if this solution to Pit
satisfies the complementary slackness conditions, it is the optimal solution for Pit
and the tree can be pruned, possibly updating UB ∗ to f (Pit ) if the former is greater
than the latter. If the solution is not optimal for Pit then the search continues in a
depth first search strategy possibly updating UB ∗ to f (Pit ) if UB ∗ > f (Pit ).

4. Preliminary Computational Results

The implementation of our algorithm has been carried out in the C language.
The performance of our approach has been compared to that of the commercial
solver CPLEX, implementing the mathematical formulation presented in Section 2
in the AMPL language, version 8.0.0. The machine used for the experiments is a PC
Core Duo with a 1.6 GHz Intel Centrino Processor and 1 GB RAM. Experiments
have been generated with the following features:
•
•
•
•

the number of activities |A| has been chosen equal to 10, 20, and 30;
a density f d of feeding precedences has been set equal to 30%;
the number K of renewable resources has been kept equal to 4;
an amount bk of resource availability per period for each resource k = 1, . . . , K
has been set equal to 4;
213

• a request qik of resource k = 1, . . . , K for every activity i ∈ A has been
assigned uniformly at random from 1 to 3;
• the values gij1 , qij1 , gij2 , qij2 have been assigned uniformly at random in the range
(0.00, 1.00);
• the time horizon T , that is the starting upper bound at the root node of the
search tree, has been fixed to 80.
Preliminary results, given as averages over five instances, are shown in Table
11 (an extensive experimentation is in progress). We listed the following values:
OPT CPLEX and OPT BB, being the average values of the makespan, computed
over the instances solved at the optimum, achieved by CPLEX and by our algorithm, respectively; # Opt CPLEX and # Opt BB, being the number of instances,
out of the five, solved at the optimum by CPLEX and by our algorithm, respectively; CPU CPLEX and CPU BB, being the average CPU time (in seconds) elapsed
by CPLEX and by our algorithm to find the optimal solutions, respectively.
The comparison shows that our algorithm is able to solve all the instances with
sizes from 10 to 30 activities, differently from CPLEX that for 30 activities solved
only two out of the five instances within the time limit of two hours. Moreover,
CPU BB is always lower than CPU CPLEX.
|A|

Opt CPLEX # Opt CPLEX CPU CPLEX

OPT BB # Opt BB CPU BB

10

5.2

5/5

0.7

5.2

5/5

0.3

20

9.0

5/5

67.6

9.0

5/5

34.2

30

14.2

2/5

1826.6

15.8

5/5

1248.9

Table 11. Comparison between the performance of CPLEX and our algorithm

References
[1] Bianco, L., M. Caramia. 2009. Minimizing the Completion Time of a Project
Under Resource Constraints and Feeding Precedence Relations: a Lagrangian
Relaxation Based Lower Bound, RR-03.09 - University of Rome “Tor Vergata”.
[2] Kis, T. 2005. A branch-and-cut algorithm for scheduling of projects with
variable-intensity activities, Mathematical Programming 103(3), pp. 515-539.
[3] Kis, T. 2006. Rcps with variable intensity activities and feeding precedence
constraints. In Perspectives in Modern Project Scheduling, Springer, pp. 105129.

214

Exact Algorithms for Vehicle Routing Problems with
Different Service Constraints
Rita Macedo , a Cludio Alves , a J. M. Valrio de Carvalho

a

a Centro

de Investigacao Algoritmi da Universidade do Minho,
Escola de Engenharia, Universidade do Minho, 4710-057 Braga, Portugal
{claudio,rita,vc}@dps.uminho.pt
Key words: Vehicle Routing Problem, Branch-and-price, Cutting planes

1. Introduction

In this paper we analyze a routing problem related with the waste collection
in urban areas, which is formulated as a Vehicle Routing Problem with additional
constraints. There is a single depot, which is the beginning, o, and the end, d, of all
vehicle routes. The fleet of vehicles is homogeneous, with a capacity of W units. It
is assumed that there are K available vehicles in the fleet. A vehicle that leaves the
depot must fulfill a minimum filling constraint by coming back with at least Lmin
units of waste. Each waste collection point is seen as a client i ∈ N = {1, . . . , m},
with a given load, li , that is stored in a container. A container is considered to be
full if it has more than a given amount of waste wmax . It is only mandatory that the
waste of a given client i is collected if its container is full. Clients that do not have
full containers will only be visited if necessary, in order to ensure that a pre-defined
minimal amount of waste LTmin is collected. The first set of clients is denoted by
N1 and the second by N2 . We use an exact branch-and-price-and-cut algorithm
to solve the integer problem. The column generation model is a Dantzig-Wolfe
decomposition of a network flow model over arcs, whose variables are also used in
our branching scheme. We apply dynamic stabilization techniques to the column
generation algorithm and use dual-feasible functions to derive valid cutting planes
from implicit constraints of the model. An extensive survey on time constrained
routing and scheduling problems can be found in [1].

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. Mathematical Model
Our routing problem is defined in a graph G = (V, A), where V = N ∪ {o, d}
represents the set of nodes in the graph and A the set of oriented arcs. The graph
is assumed to be unique and complete Each arc (i, j) ∈ A has a cost cij , that
represents the distance between i and j, as well as other eventual costs that may
be incurred by traveling through it. The optimization objective of the plan is to
minimize the total cost of the vehicles routes.

2.1 Column Generation Model

The column generation model is a network flow model over paths that results
from a Dantzig-Wolfe decomposition of a network flow model over arcs. The reformulated model consists of a master problem (2.1)-(2.6) with binary variables,
λp , that represent feasible vehicle routes, and a pricing subproblem that consists of
a shortest path problem with additional constraints. The column generation model
is stronger than the original arc-flow formulation and does not have symmetry. Let
Ω denote the set of all feasible routes, cp the cost of a path p ∈ Ω and lp the total
amount of waste picked up in route p. Constraints (2.2) and (2.3) guarantee, respectively, that clients that belong to set N1 are visited exactly once, and that the
other clients have, at most, one visit. Constraint (2.4) ensures that the number of
used routes does not exceed the number of available vehicles. The minimum filling
constraint is guaranteed in (2.5). Model (2.1)-(2.6) can be seen as a set-partitioning
model with additional constraints.
min

X

cp λ p

(2.1)

X

(2.2)

p∈Ω

aip λp = 1, ∀i ∈ N1 ,
aip λp ≤ 1, ∀i ∈ N2 ,

(2.3)

p∈Ω

λp ≤ K,

(2.4)

p∈Ω

(2.5)

p∈Ω

lp λp ≥ LTmin ,

λp ∈ {0, 1}, ∀p ∈ Ω.

(2.6)

p∈Ω

s.t.

X

X

X

Solving the pricing subproblem generates a new column to be added to the master
problem. This column, which represents a valid path in the primal space, is the one
with the lowest reduced cost. The reduced cost of a path p ∈ Ω is given by c0p =
P
cp − i∈N1 ∪N2 aip πi − lp δ − θ. In our implementation, we solved this subproblem
using a dynamic programming algorithm. Recently, new cuts based on dual-feasible
216

functions have been described in the literature. In our routing problem, we can
apply these principles by considering a valid constraint for (2.1)-(2.6). Being fp
P
the free space in a vehicle that goes through route p, we have that p∈Ω fp λp ≤
K × W − LTmin .
2.2 Stabilization Strategies

The introduction of dual cuts [2; 3] is one of the most promising methods
proposed in the literature to accelerate the convergence of column generation algorithms. We derived a new cut, valid in the dual space, which represents the possibility of exchanging clients in a route.
Proposition 2.1. Given a client i ∈ N, let S be a subset of clients such that |S| > 1
P
and j∈S lj = li , and P be a path between all the clients of S. The cost of that path
is denoted by cS . Let c1min and c2min be the first and the second smaller cost of arcs
incident in i, respectively. Let a and b be the nodes at the extremities of P , and d1max
and d2max be the higher costs among the arcs incident in a and b, respectively. If P
is a circuit, pick the higher arc costs incident in two nodes of S. Let πn , n ∈ N, θ
and δ, be the dual variables associated to the constraints (2.2)-(2.3), (2.4) and (2.5),
P
1
2
1
2
respectively. The cut −πi + j∈S πj ≤ cS − (cimin
+ cimin
) + (dSmax
+ dSmax
) is valid
in the dual space.
Proof. Let (π, θ, δ) be the dual solution corresponding to an optimal solution
to the column generation problem (2.1)-(2.6). This solution is, according to the
P
optimality conditions, valid in the dual space, which means that n∈N anp π n +
θ + lp δ ≤ cp , ∀p ∈ Ω. Two cases may occur: (i) i ∈ N1 or (i ∈ N2 and client
i is visited in the optimal solution) or (ii) i ∈ N2 and client i is not visited in
the optimal solution . Let us consider case (i). There is, in the optimal solution, at
least one positive basic variable corresponding to a path p0 = (a1p0 , . . . , amp0 ), with
aip0 = 1 and asp0 ∈ {0, 1}, ∀s ∈ S. Its reduced cost is null, which means that cp0 =
P
e = (a1pe, . . . , ampe), with aipe = aip0 − 1 = 0,
n∈N anp0 π n + θ + lp0 δ. Consider path p
aj ep = ajp0 + 1, ∀j ∈ S, and anpe = anp0 , ∀n ∈ N \ (S ∪ {i}). Path pe is a valid
path corresponding to the exchange of client i by clients j ∈ S. Clearly, cpe − cp0 ≤
2
1
1
2
)+(dSmax
+dSmax
) and lpe = lp0 . Suppose that there is a cut that is not
+cimin
cS −(cimin
P
1
2
1
2
valid in the dual space, i.e., −π i + j∈S πj > cS − (cimin
+ cimin
) + (dSmax
+ dSmax
).
P
P
P
Then, −π i + j∈S π j > cpe−cp0 ⇒ −π i + j∈S πj > cpe−( n∈N anp0 π n +θ +lp0 δ).
P
P
P
It is clear that −π i + j∈S π j = n∈N anpeπ n − n∈N anp0 π n , which implies that
P
the validity of solution (π, θ, δ). Let us
n∈N anp
eπ n + θ + lpeδ > cpe, contradicting
P
now consider case (ii). Given that p∈Ω aip λp = 0, by the complementary slackness
P
theorem, πi = 0. Moreover, as i ∈ N2 and j∈S lj = li , we know that j ∈ N2 , ∀j ∈
P
P
S, and thus that j∈S π j ≤ 0. Therefore, −π i + j∈S π j ≤ 0. Let cij1 and cij2 be
the costs of the arcs incident in i and j1 , and i and j2 , respectively, with j1 , j2 ∈ S.
We know that cij1 + cij2 ≥ c1min + c2min and cij1 + cij2 ≤ d1max + d2max . This means
217

that d1max + d2max ≥ c1min + c2min =⇒ cp − (c1min + c2min ) + (d1max + d2max ) ≥ 0 =⇒
P
−π i + j∈S π j ≤ cp − (c1min + c2min ) + (d1max + d2max ).
2
2.3 Branch-and-Bound

In the branching scheme, we used the binary decision variables of the network
flow model over arcs, xij , being i and j the beginning and end of an arc. The resulting branching constraints, xij = 1 and xij = 0, representing two new branching
nodes of the branching tree, are easily enforced in the master problem (2.1)-(2.6),
whose variables are not used to branch as it would cause a regeneration of columns,
unless the pricing subproblem was reformulated in a more complicated way.

3. Conclusions

In this paper, we defined an exact branch-and-price-and-cut algorithm for a
routing problem arising in an urban waste management system. We conducted preliminary computational experiments on a set of random instances with promising
results. For the sake of brevity, we do not present the list of results obtained, but
we can say that for instances with 50 clients, we usually converge to a small optimality gap in a reasonable amount of time. In what concerns the cut described in
§2.1, its performance depends on the values of parameters like K, Lmin or LTmin ,
whereas the dual cut described in §2.2 performs well when the clients are organized
in geographically scattered groups.

References
[1] J. Desrosiers, Y. Dumas, M. Solomon and F. Soumis. Time Constrained Routing and Scheduling. in M.O. Ball et al., Eds., Handbooks in OR & MS, Vol. 8,
Elsevier Science B.V., 1995.
[2] J.M. Valrio de Carvalho. Using extra dual cuts to accelerate column generation. INFORMS Journal on Computing, 17(2):175-182, 2005.
[3] F. Clautiaux, C. Alves and J. M. Valrio de Carvalho. New stabilization procedures for the cutting stock problem. In revision for INFORMS Journal on
Computing, 2007.

218

Networks I

Lecture Hall B

Wed 3, 14:00–15:30

Algorithmic Solutions of Discrete Control Problems
on Stochastic Networks
Dmitrii Lozovanu, a Stefan Pickl b
a Institute

of Mathematics and Computer Science, Academy of Sciences,
Academy str., 5, Chisinau, MD–2028, Moldova
lozovanu@math.md

b Institut

für Theoretische Informatik, Mathematik und Operations Research,
Fakultät fur Informatik, Universität der Bundeswehr, München
stefan.pickl@unibw.de

Abstract
Classical discrete optimal control problems which are based on a graph-theoretic structure
are introduced. The paper focusses now on a stochastic extension of such processes. Based
on the concept of general Markov processes, stochastic networks are characterized. Suitable
algorithms exploiting the time-expanded network method are presented.
Key words: Stochastic Networks, Markov Processes, Time-Expanded Network

1. Introduction
Classical discrete optimal control problems are introduced in [1; 2; 4]. We consider now such control problems for which the discrete system in the control process may admit dynamical states where the vector of control parameters is changing
in a random way. We call such states of the dynamical system uncontrollable dynamical states. So, we consider the control problems for which the dynamics may
contain controllable states as well as uncontrollable ones. We show that these types
of problems can be modeled on stochastic networks. New algorithmic approaches
for their solving based on the concept of Markov processes and dynamic programming from [3] can be described. The approach is based on the time-expanded network method. This is a comfortable graph-theoretic structure which was introduced
in [4; 5].
2. The General Graph-Theoretic Structure
We consider a time-discrete system L with a finite set of states X ⊂ Rn . At
every time-step t = 0, 1, 2, . . . , the state of the system L is x(t) ∈ X. Two states
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

x0 and xf are given in X, where x0 = x(0) represents the starting state of system L
and xf is the state in which the system L must be brought, i.e. xf is the final state of
L. We assume that the system L should reach the final state xf at the time-moment
T (xf ) such that T1 ≤ T (xf ) ≤ T2 , where T1 and T2 are given. The dynamics of
the system L is described as follows
x(t + 1) = gt (x(t), u(t)), t = 0, 1, 2, . . . ,

(2.1)

where
x(0) = x0

(2.2)

and u(t) = (u1 (t), u2(t), . . . , um (t)) ∈ Rm represents the vector of control parameters. For any time-step t and an arbitrary state x(t) ∈ X a feasible finite set
k((x(t))
Ut (x(t)) = {u1x(t) , u2x(t) , . . . ux(t) }, for the vector of control parameters u(t) is
given, i.e.
u(t) ∈ Ut (x(t)), t = 0, 1, 2, . . . .

(2.3)

We assume that in (2.1) the vector functions gt (x(t), u(t)) are determined uniquely
by x(t) and u(t), i.e. x(t+1) is determined uniquely by x(t) and u(t) at every timestep t. Additionally, we assume that at each moment of time t the cost ct (x(t), x(t+
1)) = ct (x(t), gt (x(t), u(t))) of system’s passage from the state x(t) to the state
x(t+1) is known. Let x0 = x(0), x(1), x(2), . . . , x(t), . . . be a trajectory generated
by given vectors of control parameters u(0), u(1), . . . , u(t − 1), . . . . Then either
this trajectory passes through the state xf at the time-moment T (xf ) or it does not
pass through xf . We denote by
T (xf )−1

Fx0 xf (u(t)) =

X

ct (x(t), gt (x(t), u(t)))

(2.4)

t=0

the integral-time cost of system’s passage from x0 to xf if T1 ≤ T (xf ) ≤ T2 ; otherwise we put Fx0 xf (u(t)) = ∞. In [1; 2; 4] the following problem has been formulated: Determine vectors of control parameters u(0), u(1), . . . , u(t), . . . which
satisfy the conditions (2.1)-(2.3) and minimize the functional (2.4). This problem
can be regarded as a control model with controllable states because for an arbitrary state x(t) at every moment of time the determination of a vector of control
parameter u(t) ∈ Ut (x(t)) is assumed to be at our disposition.
In this paper we assume that the dynamical system L may contain uncontrollable states, i.e. for the system L there exists dynamical states in which we are not
able to control the dynamics of the system and the vector of control parameters
u(t) ∈ Ut (x(t)) for such states is changing by a random way according to a given

222

distribution function
k(x(t))

p : Ut (x(t)) → [0, 1],

X

p(uix(t) ) = 1.

(2.5)

i=1

on the corresponding dynamical feasible sets Ut (x(t)). If an arbitrary dynamic state
x(t) of system L at given moment of time t is characterized by its position (x, t)
then the set of positions XT = {(x, t) | x ∈ X, t ∈ {0, 1, 2, . . . }} of the dynamical
system can be divided into two disjoint subsets XT = XTC ∪ XTN (XTC ∩
XTN = ∅), where XTC represents the set of controllable positions of L and XTN
represents the set of positions (x, t) = x(t) for which the distribution function (2.5)
of the vectors of control parameters u(t) ∈ Ut (x(t)) are given. This means that the
dynamical system L is expressed by the following behavior: If the starting point
belongs to the set of the controllable positions then the decision maker choose a
vector of these control parameters and we reach the state x(1). If the starting state
belongs to the set of uncontrollable positions then the system passes to the next
state in a random way. After that step if at the time-moment t = 1 the state x(1)
belongs to the set of controllable positions then the decision maker may choose the
vector of control parameter u(t) ∈ Ut (x(t)) and we obtain the state x(2). If x(1)
belong to the set of uncontrollable positions then the system passes to the next state
again in a random way and so on.
3. The Main Concept
In this dynamic process the final state may be reached at a given moment of
time with a probability which depends on the control vectors (in the controllable
states) as well as on the expectation of the integral time cost. Our main results
are concerned with solving the following problems which are based on a graphtheoretic structure:
Algorithmic Procedure
1. For given vectors of control parameters u0 (t) ∈ Ut (x(t)), x(t) ∈ XTC ,
determine the probability that the final state will be reached at the moment of time
T (x2 ) such that T1 ≤ T (xf ) ≤ T2 .
2. Find the vectors of control parameters u∗ (t) ∈ Ut (x(t)), x(t) ∈ XTC for
which the probability in problem 1 is maximal?
3. For given vectors of control parameters u0 (t) ∈ Ut (x(t)), x(t) ∈ XTC ,
estimate the integral-time cost after T stages.
4. For given vectors of control parameters u0 (t) ∈ Ut (x(t)), x(t) ∈ XTC ,
determine the integral-time cost of system’s passage from the starting state x0 to
the final state xf when the final state is reached at the time-moment T (xf ) such that
T1 ≤ T (xf ) ≤ T2 .
5. Minimization problem I:
For which vectors of control parameters u∗(t) ∈ Ut (x(t)), x(t) ∈ XTC is the
expectation of the integral-time cost in problem 3 minimal?

223

6. Minimization problem II:
For which vectors of control parameters u∗(t) ∈ Ut (x(t)), x(t) ∈ XTC is the
expectation of the integral-time cost in problem 4 minimal?
Note that problems 1-6 extend and generalize the deterministic and stochastic
dynamic problems from[1; 2; 3] using a certain graph-theoretic approach.
4. Control Problems on Stochastic Networks
If the dynamics and input data of the problems 1-6 are known then the stochastic network can be obtained by the following way:
Each position (x, t), x ∈ X, t = 0, 1, 2, . . . , T2 of the dynamical system L
can be identified with a vertex (x, t) of the network and each vector of the control
parameter u(t) which provide a system passage from the state x(t) = (x, t) to the
state x(t + 1) = (y, t) is associated with a directed edge e = ((x, t), (y, t + 1))
of our network. To each directed edge e = ((x, t), (y, t + 1)) -originated in the
uncontrollable position (x, t)- we associate the probability p(e) = p (u(t)) (, where
u(t) is the vector of control parameters which determines the passage from the
state x = x(t) to the state x(t + 1) = (y, t + 1)). Additionally we associate to
each edge e = ((x, t), (y, t + 1)) the cost c((x, t), (y, t + 1)) = ct (x(t), x(t + 1))
(which corresponds to the cost of the system to pass from the state x(t) to the state
x(t + 1)). The obtained stochastic network has a structure of a T2 -partite network.
5. Resume
After having introduced a new comfortable structure to analyze stochastic networks on partite networks, we propose a new procedural concept for the underlying control problems. Suitable algorithms exploiting the time-expanded network
method and distinguished Markov properties method will be presented.
References
[1] Bellman R., Kalaba R., Dynamic programming and modern control theory.
Academic Press, New York and London (1965).
[2] Boltjanski, W.G., Optimale Steuerung diskreter Systeme. Leipzig Akademische Verlagsgesellschaft Geest & Portig K.-G., Leipzig (1976).
[3] Howard, R.A., Dynamic Programming and Markov Processes. Wiley (1960).
[4] Lozovanu D., Pickl S., Optimization and Multiobjective Control of TimeDiscrete Systems. Springer (2009).
[5] Lozovanu D., Pickl S., Algorithms for solving multiobjective discrete control
problems and dynamic c-games on networks. Discrete Applied Mathematics
155 (2007) 1856–1857.

224

Routing and Wavelength Assignment in optical
networks by independent sets in conflict graphs
Lucile Belgacem, a Irène Charon, b Olivier Hudry b
a Orange

Labs FT R&D, 38-40, rue du Gnral Leclerc, 92794 Issy-les-Moulineaux Cedex 9,
France

b Telecom

ParisTech & CNRS - LTCI UMR5141, 46, rue Barrault, 75634 Paris Cedex 13,
France

Key words: Combinatorial optimization, Optical networks WDM, Routing and
wavelength assignment (RWA), Scheduled Lightpath Demands (SLD), Heuristic, Descent
method, Independent set, Conflict graph

1. Introduction

We consider two problems related to the routing and wavelength assignment
problem (RWA) in wavelength division multiplexing (WDM) optical networks. For
a given network topology, represented by an undirected graph G, the RWA problem consists in establishing a set of traffic demands (or connection requests) in
this network. Traffic demands may be of three types: static (permanent and known
in advance), scheduled (requested for a given period of time) and dynamic (unexpected). In this communication, we deal with the case of scheduled lightpaths
demands (SLDs), which is relevant because of the predictable and periodic nature
of the traffic load in real transport networks (more intense during working hours,
see [4]).
An SLD can be represented by a quadruplet s = (x, y, α, β), where x and y are
some vertices of G (source and destination nodes of the connection request), and
where α and β denote the set-up and tear-down dates of the demand. The routing
of s = (x, y, α, β) consists in setting up a lightpath between x and y, i.e. a path
between x and y in G and a wavelength w. In order to satisfy the SLD s, this
lightpath must be reserved during all the span of [α, β].
The same wavelength must be used on all the links travelled by a lightpath
(wavelength continuity constraint). Moreover, at any given time, a wavelength can
be used at most once on a given link; in other words, if two demands overlap in

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

time, they can be assigned the same wavelength if and only if their routing paths
are disjoint in edges (wavelength clash constraint).
The two problems that we consider here are the following:
• minimize the number of wavelengths necessary to satisfy all the demands;
• given a number of wavelengths, maximize the number of connection demands
that can be satisfied with this number of wavelengths.
These problems are NP-hard (see [3]), and have been extensively studied (see,
among others, [1], [2], [4], [5] and the reference therein). In both problems, a solution is defined by specifying, for each SLD, the lightpath chosen for supporting the
connection (i.e. a path and a wavelength), so that there is no conflict between any
two lightpaths (let us recall that two lightpaths are in conflict if they use the same
wavelength, they have at least one edge in common and the corresponding demands
overlap in time). To solve these problems, we design a modelisation of the problem
as the search of successive independent sets (IS) in some conflict graphs. Then we
apply a descent heuristic improved by a post-optimization method.

2. Independent sets in conflict graphs
To solve these problems, we build a conflict graph H defined as follows. For
each SLD s = (x, y, α, β), we compute a given number k of paths between x and
y in G (for instance, k = 5): Cs1 , Cs2 , ..., Csk . We associate a vertex of H with each
path Csi for each SLD s. Thus, if δ denotes the number of SLDs, the number of
vertices of H is equal to kδ. The edges of H are of two types:
• for each SLD s and for 1 ≤ i < j ≤ k, all the edges {Csi , Csj } are in H; thus
these edges induce, for each SLD s, a clique (i.e., a complete graph) on the
vertices Cs1 , Cs2 , ..., Csk ;
• for any SLD s = (x, y, α, β) and any other SLD s0 = (z, t, γ, ), we add the
edges {Csi , Csj0 } for 1 ≤ i ≤ k and 1 ≤ j ≤ k if the time windows of s and s0
overlap ([α, β] ∩ [γ, ) 6= ∅) and if the paths Csi and Csj0 are not edge-disjoint;
such an edge {Csi , Csj0 } represents a conflict between s and s0 : it is not possible
to assign a same wavelength to s and s0 if we decide to route s thanks to Csi
and s0 thanks to Csj0 .
Our algorithm consists in applying the following two steps successively:
• compute an independent set I in H;
• remove from H all the cliques associated with the satisfied SLDs to obtain a
new current conflict graph H.

226

We perform this process in order to obtain a series of ISs I1 , I2 , ..., Iq in successive
conflict graphs. This will provide a solution to our problem. Indeed, if the vertex
Csi belongs to Ij , then we route s thanks to the path Csi with the j-th wavelength.
Each Ij allows us to route |Ij | SLDs with a same wavelength. We stop when all the
SLDs are satisfied (first problem) or when q is equal to the prescribed number of
wavelengths (second problem).

3. The heuristic to compute an independent set
To compute an IS in the current conflict graph H, we apply an iterative improvement method, also called descent (we tried more sophisticated methods as
simulated annealing, but these methods were too long to obtain interesting results).
We start from an IS of cardinality 1, and we look for another IS of cardinality 2, 3,
and so on, until reaching a value λ for which we do not succeed in finding an IS of
cardinality λ. Then the method returns the last IS of cardinality λ − 1 as a solution.
To look for an IS Iλ of cardinality λ from an IS Iλ−1 of cardinality λ − 1, we
add a random vertex to Iλ−1 . Usually, we thus obtain a set Iλ inducing a subgraph
containing some edges. Then we try to minimize the number of edges by performing elementary (or local) transformations, in order to find a set Iλ which will be an
IS. It is for this minimization that we apply a descent.
The elementary transformation that we adopt consists in removing a vertex
belonging to Iλ and simultaneously to add another vertex which does not belong to
Iλ . Such a transformation is indeed accepted if the number of edges decreases.
When the descent stops, if the set Iλ still induces a subgraph which is not an
IS, then we stop and we keep the previous IS Iλ−1 as the solution. Otherwise, we
add a vertex and we apply the same process once again.
In fact, we improve this method in two manners. The first one consists, after
the construction of each IS I, in trying to add extra SLDs with a greedy algorithm.
For this, we consider each unsatisfied SLD s, and we look for a path in G that would
allow us to route s with the current wavelength, i.e. a path which would not contain
any edge of paths associated with another SLD s0 routed with the same wavelength
and of which the time window overlaps the one of s. Such a situation may occur
since we limit ourselves to k paths in the construction of H, while we look for a
path in G to add extra SLDs.
The other improvement consists in applying a post-optimization method (already applied in [1]), after the computation of the series of ISs I1 , I2 , ..., Iq . The
aim is to reduce the overall values of the wavelengths in order to decrease the total
number of wavelengths for the first problem or to make some place to extra SLDs,

227

still unsatisfied, for the second problem. For this, given a wavelength w, we try to
empty, at least partially, the set of SLDs routed with w, by assigning them lower
wavelengths. So we change the wavelengths assigned to SLDs which are currently
routed with the wavelenths 1, 2, ..., w−1; in this process, all the SLDs with a current
wavelength between 1, 2, ..., w − 1 will keep a wavelength in this interval. For the
first problem, it may then happen that a wavelength becomes useless; then we remove it definitively and so the number of required wavelengths decreases. For the
second problem, the changes involved in the assignments of the wavelenghts are
such that, sometimes, we may route an SLD which was unsatisfied; so this process
allows us to route extra SLDs.

4. Results

We experimentally study the impact of the formulation of the problem as
the search of successive ISs in conflict graphs as well as the impact of the postoptimization method. The experiments are done on several networks, with numbers
of SLDs up to 3000. The results, not detailed here, show that these two approaches
are quite beneficial for both problems, when their results are compared to the one
of the method developped in [5].

References
[1] L. Belgacem, I. Charon, O. Hudry: A post-optimization method for the routing
and wavelength assignment problem. Submitted for publication
[2] L. Belgacem, N. Puech: Solving Large Size Instances of the RWA Problem
Using Graph Partitioning. Proceedings of the 12th Conference on Optical Network Design and Modelling, Vilanova i la Geltr, Spain, 1–6, 2008.
[3] I. Chlamtac, A. Ganz, G. Karmi: Lightpath communications: an approach to
high-bandwidth optical WANs. IEEE Trans. Commun. 40, 1171–1182, 1992.
[4] J. Kuri, N. Puech, M. Gagnaire, E. Dotaro, R. Douville: Routing and Wavelength Assignment of Scheduled Lightpaths Demands, IEEE Journal on Selected Areas in Communications 21 (8), 1231–1240, 2003.
[5] N. Skorin-Kapov: Heuristic Algorithms for the Routing and Wavelength Assignment of Scheduled Lightpath Demands in Optical Networks. IEEE Journal on Selected Areas in Communications 24 (8), 2-15, 2006.

228

Recognition of Reducible Flow Hypergraphs ?
A. L. P. Guedes, a L. Markenzon, b L. Faria c
a Universidade

Federal do Paraná, PR, Brazil
andre@inf.ufpr.br

b Universidade

Federal do Rio de Janeiro, RJ, Brazil
markenzon@nce.ufrj.br

c Universidade

do Estado do Rio de Janeiro, RJ, Brazil
luerbio@cos.ufrj.br

Key words: Directed hypergraphs, Reducible flow graphs, Recognition algorithm

1. Introduction

Reducible flow graphs were introduced by Allen [1] to model the control flow
of computer programs. Although they were initially used in code optimisation algorithms, several theoretical and applied problems have been solved for the class.
Directed hypergraphs [2; 4] are a generalisation of digraphs and they can model
binary relations among subsets of a given set. Such relationships appears in different areas of Computer Science such as database systems [2], parallel programming
[9] and scheduling [5]. Reducible flow hypergraphs were defined by Guedes et al.
[7; 6].
In this paper, we present flow hypergraphs and the extension of reducibility for
this family. We show that the characterisation of reducible flow graphs using the
transformation approach yields a polynomial recognition algorithm.
? Partially supported by grants 485671/2007-7, 306893/2006-1 and 473603/2007-1,
CNPq, Brazil.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. Directed Hypergraphs
Definition 1. A directed hypergraph H = (V, A) is a pair, where V is a non
empty finite set of vertices and A is a collection of hyper-arcs. A hyper-arc a =
(X, Y ) ∈ A is an ordered pair where X and Y are non empty subsets of V , such
that X = Org(a) is called the origin and Y = Dest(a) is called the destination
of a.
The notation Org and Dest can be extended to a collection A0 of hyper-arcs,
where Org(A0) = ∪e∈A0 Org(e) and Dest(A0 ) = ∪e∈A0 Dest(e).
Definition 2. Let H = (V, A) be a directed hypergraph and v ∈ V . The collection
of hyper-arcs entering vertex v is denoted by BS(v) = {e ∈ A | v ∈ Dest(e)}, the
backward star set of v.
Definition 3. [7] Let H = (V, A) be a directed hypergraph and u and v be vertices
of H. A B-path of size k from u to v is a sequence P = (ei1 , ei2 , ei3 , . . . , eik ), such
that u ∈ Org(ei1 ) and v ∈ Dest(eik ), and for each hyper-arc eip of P , 1 ≤ p ≤ k,
we have:
• Org(eip ) ⊆ (Dest(ei1 , ei2 , . . . , eip−1 ) ∪ {u}
• Dest(eip ) ∩ (Org(eip+1 , eip+2 , . . . , eik ) ∪ {v}) 6= ∅.
Org(ei1 ) and Dest(eik ) are denoted by Org(P ) and Dest(P ), respectively.
Definition 4. A flow hypergraph H = (V, A, s) is a triple, such that (V, A) is a
directed hypergraph, s ∈ V is a distinguished source vertex, and there is a B-path
from s to each other vertex in V .

3. Reducibility of Flow Hypergraphs

In [8], Hecht and Ullman presented a characterisation of reducible flow graphs
based on two transformations. We extend these operations in order to define reducible flow hypergraphs and to develop a recognition algorithm.
Given a flow hypergraph, two transformations, T1 and T2 , can be defined, performing the contraction of a hyper-arc.
Definition 5. (T1 ) Let H = (V, E, s) be a flow hypergraph and a = ({x}, {x}) ∈
E be a simple loop. The hypergraph T1 (H, a) is defined as H − {a}.
Definition 6. (T2 ) Let H = (V, E, s) be a flow hypergraph and a = ({x}, Y ) ∈ E
be a hyper-arc (with |Org(a)| = 1), such that ∀y ∈ Y \ {x}, Org(BS(y)) = {x};
230

x = s or s 6∈ Y ; and a is not a simple loop. The hypergraph T2 (H, a) is defined by
removing a from H and merging the vertices of Y with x.
1
a

1

1

1

a

a

a
e

2

2

3

2

3

2

3

3

c

T2 (c)

e
4

5

T2 (d)

e

T1 (e)

f

b

b

b

b

f

d

d

6

g

7

7

7

7
6

g

g

g

f

f
8

(a)

8

8

(b)

(c)

8

(d)

Fig. 1. Transformations T1 and T2

To use such transformations in an algorithm they need to be, together, a finite
“Church-Rosser” transformation [3; 8]. This means that starting with flow hypergraph H, any sequence of hypergraphs generated by applying of these transformations is finite and ends generating the same hypergraph, says T ∗ (H).
Theorem 3.1. Let H be a flow hypergraph. There is a unique flow hypergraph
T ∗ (H) resulting from any sequence of applications of T1 and T2 in H and in which
T1 and T2 can not be applied.
The reducibility can now be defined in terms of the transformations.
Definition 7. H is called reducible if T ∗ (H) is a flow hypergraph with just one
vertex and no hyper-arcs.
Definition 8. Let H = (V, A) be a directed hypergraph and a ∈ A. The hyper-arc
a is contractible if one of the transformations T1 or T2 can be applied at a (see
Definitions 5 and 6).
It can be proved that any sequence of possible transformations is valid. So, the
recognition algorithm consists in applying the transformations to any contractible
hyper-arc (it is necessary to verify this condition). It stops when there are no more
contractible hyper-arcs; at this point, the resulting flow hypergraph must be checked.
It is easy to see that the algorithm always stop and leads to the T ∗ (H) flow
hypergraph.

231

reducible(H = (V, A, s))
T∗ ← H
repeat
find a contractible hyper-arc a in G
apply the appropriate transformation in T ∗ at a
until there is no contractible hyper-arc
test if T ∗ = ({s}, ∅, s)
The following aspects must be considered to establish the complexity of the
algorithm:
• testing whether or not a hyper-arc a = ({x}, Y ) is contractible can be performed in time O(|Y |∆), being ∆ the maximum size of the backward star
sets (BS(v)). So, it takes O(|V | × |A|).
• Finding a contractible hyper-arc in the flow hypergraph H = (V, A, s) may
imply that all hyper-arcs are tested. So, it takes O(|V | × |A|2 ).
• If H is reducible then every hyper-arc will be contractible, at some point. So,
the above test may be performed |A| times. The whole algorithm takes time
O(|V | × |A|3 ).
References
[1] F. E. Allen. Control flow analysis. SIGPLAN Not., 5(7):1–19, 1970.
[2] G. Ausiello, A. D’Atri, and D. Saccà. Strongly equivalent directed hypergraphs. In Analysis and Design of Algorithms for Combinatorial Problems,
vol. 25 of Ann. of Disc. Math., 1–25. North-Holland, Amsterdam, 1985.
[3] A. Church and J. B. Rosser. Some properties of conversion. Trans. of the
American Mathematical Society, 39(3):472–482, 1936.
[4] G. Gallo, G.Longo, S. Nguyen, and S. Pallottino. Directed hypergraphs and
applications. Disc. Appl. Math., 42:177–201, 1993.
[5] G. Gallo and M. Scutellà. Minimum makespan assembly plans. Technical
Report TR-10/98, Dip. di Inf., Univ di Pisa, 1998.
[6] A.L.P. Guedes, L. Markenzon, and L. Faria. Flow hypergraph reducibility.
Electronic Notes in Discrete Mathematics, 30:255 – 260, 2008.
[7] A.L.P. Guedes. Hipergrafos Direcionados. D.Sc. thesis, Universidade Federal
do Rio de Janeiro, Rio de Janeiro, RJ, Brasil, 2001. (in portuguese)
[8] M. S. Hecht and J. D. Ullman. Flow graph reducibility. SIAM J. of Computing,
2(2):188–202, 1972.
[9] S. Nguyen, D. Pretolani, and L. Markenzon. On some path problems on oriented hypergraphs. RAIRO - Informatique Theorique et Applications (Theoretical Informatics and Applications), 32(1):1–20, 1998.

232

Complexity

Lecture Hall A

Wed 3, 15:45–16:45

On the complexity of graph-based bounds for the
probability bounding problem
Andrea Scozzari, a Fabio Tardella a
a Universitá

di Roma “La Sapienza” Via del Castro Laurenziano 9, 00161 Roma,
Dip. di Matematica per le Decisioni Economiche, Finanziarie ed Assicurative
{andrea.scozzari,fabio.tardella}@uniroma1.it

Key words: coherent probability, boolean probability bounding problem, cherry trees,
chordal graphs, NP-completeness

1. Extended Abstract

In many real world applications we often need to reason with uncertain information under partial knowledge. A common situation is when a coherent probability assessment Pn is defined on a family of n conditional or unconditional events.
Given a further event, logically dependent on the others, there exists an interval
[p0 , p00 ] such that every probability pn+1 ∈ [p0 , p00 ] assigned to the new event together with Pn forms a coherent probability assessment on the resulting family of
n + 1 events. In case of unconditional events the above result is known as the Fundamental Theorem of the Theory of Probability of de Finetti [5; 6]. The problem of
finding the maximum and minimum value of pn+1 such that Pn ∪ pn+1 is coherent,
has been already identified in the seminal work of Boole, who called it the “general
problem in the theory of probabilities” [1]. In this paper we focus on the special case
of finding upper bounds for the probability of the (logical) union of n events when
the individual probabilities of the events as well as the probabilities of all intersections of k-tuples of these events are known, where k ≤ m < n, and m is called the
order of the bound. This problem is also known as the Boolean Probability Bounding Problem (BPBP) [3]. In spite of its long history, its theoretical complexity is
still unknown. More precisely, we have recently shown [2] that for this problem the
complexity of deciding whether a given probability assessment is coherent is NPhard, and we strongly conjecture that this is also the case for the problem of finding
the best upper bound for the union, when we are given a feasible probability assessment for the events and their intersections. However, this is still an open problem.
Since BPBP is hard in practice, several authors have proposed efficient techniques
for finding relaxed solutions (bounds) for this problem (see [3; 4; 7; 9; 11; 13]

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

and the references therein). However, while most bounding procedures clearly require polynomial time, the complexity of some recent graph-based methods has
not yet been established. Let A1 , ..., An be a set of arbitrary events in a probability
space Ω. We assume that the single events probability P (Ai), i = 1, ..., n, and the
T
probability of the intersections P ( i∈I Ai ) for all subsets I ⊆ {1, 2, . . . , n} with
cardinality |I| ≤ m < n, are known. Our problem consists in finding upper bounds
for the probability of the union of the n events P (A1 ∪ A2 ∪, ..., ∪An ). In this paper
we focus on graph-based upper bounds. Let G = (V, E) be the complete graph
associated to the events A1 , ..., An , with vertex set V = {1, 2, ..., n}, and associate
with each edge (i, j) a weight wij = P (Ai ∩ Aj ). Hunter and Worsley [9; 13] have
shown that the inequality
n
P (A1 ∪ A2 ∪, ..., ∪An ) ≤

X
i=1

P (Ai ) −

X

wij

(1.1)

(i,j)∈T

holds for every spanning tree T of G. Thus, the second order bound provided by the
right hand side of (1.1), which can be computed by solving a max weight spanning
tree of G, is called the Hunter-Worsely bound. Bukszár and Prékopa [4] presented
a third order bound, which considers also the intersections among triples of events,
and improves on the one by Hunter and Worsley. This third order bound is based
on a new type of graph called cherry tree. A cherry tree is a triple ∆ = (V, E, ϕ),
where (V, E) is an undirected graph, and the set ϕ is a collection of subsets of
vertices of cardinality three called cherries. Cherries are recursively defined in the
following manner (see [4]): (i) An adjacent pair of vertices is the only cherry tree
with exactly two vertices of G; (ii) from a cherry tree, obtain a new cherry tree by
adding a new vertex and two new edges connecting this new vertex with two already
existing vertices of the tree. The vertices belonging to these two edges constitute a
cherry. With every cherry {i, j, k} ∈ ϕ we associate a weight wijk . The weight of a
cherry tree ∆ is:
P

P

(1.2)
W (∆) = (i,j)∈E wij − {i,j,k}∈ϕ wijk .
Given weights wij = P (Ai ∩ Aj ), i 6= j, and wijk = P (Ai ∩ Aj ∩ Ak ),
i 6= j 6= k, Bukszár and Prékopa provided the following bound on the probability
of the union:
P (A1 ∪ A2 ∪, ..., ∪An ) ≤

Pn

i=1

P (Ai) − W (∆).

(1.3)

In particular, the Bukszár and Prékopa’s bound is obtained by considering a special cherry tree called t-cherry tree. A t-cherry tree is found when at each step
in (ii), the two vertices to which a new vertex is connected are adjacent. In this
case a cherry constitutes a triangle and a t-cherry tree is a triangulated graph.
Bukszár and Prékopa also provide a polynomial time algorithm for finding a tcherry tree by first calculating a maximum spanning tree of the graph G associated to the events A1 , ..., An , and then improving it to find a spanning t-cherry
tree. However, the t-cherry tree provided by this algorithm is not guaranteed to
be the heaviest one. Moreover, in their paper the complexity of finding the heaviest t-cherry tree spanning the complete graph G is not assessed. We note that the

236

weights wij = P (Ai ∩Aj ) and wijk = P (Ai ∩Aj ∩Ak ) are not arbitrary values, but
they must represent a feasible and coherent probability distribution for the events
A1 , ..., An . Another third order upper bound, which exploits the concept of chordal
graphs, is introduced in [3; 7]. Let C = (V, E) be a chordal graph with weights wij
associated to the edges and weights wijk associated to the triangles of C. Denote
by E(C) the set of the edges of C, and by Γ(C) the set of triangles whose sides
belong to C. We define the weight W (C) of the graph C as:
W (C) =

P

(i,j)∈E(C)

wij −

P

{i,j,k}∈Γ(C) wijk .

(1.4)

Given any chordal graph C spanning G with weights wij = P (Ai ∩ Aj ) and wijk =
P (Ai ∩ Aj ∩ Ak ), the following is an upper bound on the probability of the union
[3; 7]:
P (A1 ∪ A2 ∪, ..., ∪An ) ≤

Pn

i=1

P (Ai) − W (C)

(1.5)

Also in this case, neither in [3] nor in [7], the complexity of finding the chordal
graph C of maximum weight W (C) is assessed. We note that finding a spanning
chordal graph of maximum weight W (C) is an extension of the problem of finding
a maximum weight spanning chordal subgraph of a given graph G in the special
case where wijk = 0 ∀i 6= j 6= k. This problem has been uncertain for a long time.
The first proof of NP -completeness is attributed to A. Ben-Dor in [10]. Here, we
study the problem of finding a chordal graph C spanning G of maximum weight
W (C) by exploiting some recent results on the complexity of the problem of deciding the existence of a maximum spanning chordal subgraph of a given graph
[12]. Our main results concern the NP-completeness of the following two open
problems:
1. Maximum Weight Spanning t-Cherry Tree Bounding problem
INSTANCE: A complete graph G = (V, E) with weights 0 ≤ wij ≤ 1 assigned to its edges, and weights 0 ≤ wijk ≤ 1 assigned to its triangles that represent
a coherent probability distribution for the events A1 , ..., An .
QUESTION: Does there exist a t-Cherry Tree spanning the graph G with total
weight W (∆) at least L?
2. Maximum Weight Chordal Bounding problem
INSTANCE: A complete graph G = (V, E) with weights 0 ≤ wij ≤ 1 assigned
to its edges, and weights 0 ≤ wijk ≤ 1 assigned to its triangles that represent a
coherent probability distribution for the events A1 , ..., An .
QUESTION: Does there exist a chordal graph C spanning G with total weight
W (C) at least L?

237

References
[1] Boole G., Laws of thought, American Reprint of 1854 edition, Dover, 1854.
[2] Boros E., Scozzari A., Tardella F., Veneziani P., Polynomially Computable
Bounds for the Probability of a Union of Events, working paper.
[3] Boros E., Veneziani P., Bounds of degree 3 for the probability of the union of
events, Rutcor Research Report, RRR 3-2002, 1-21.
[4] Bukszár J., Prékopa A., Probability bounds with cherry trees, Mathematics of
Operations Research, 26 2001, 174-192.
[5] de Finetti B., Sull’impostazione assiomatica delle probabilitá, Annali Universitá di Trieste, 19 1949, 3-55.
[6] de Finetti B., Teoria della Probabilitá, Einaudi, Torino, 1970.
[7] Dohmen K., Bonferroni-Type Inequalities via Chordal Graphs, Combinatorics, Probability and Computing, 11 2002, 349-351.
[8] Hailperin T., Best possible inequalities for the probability of a logical function
of events, American Mathematical Monthly, 72 1965, 343-359.
[9] Hunter D., An upper bound for the probability of a union Journal of Applied
Probability, 13 1976, 597-603.
[10] Natanzon A., Shamir R., Sharan R., Complexity classification of some edge
modification problems, Discrete Applied Mathematics, 113 2001, 109-128.
[11] Prékopa A., Gao L., Bounding the Probability of the Union of Events by the
Use of Aggregation and Disaggregation in Linear Program, Discrete applied
Mathematics, 145 2005, 444-454.
[12] Scozzari A., Tardella F., On the complexity of some subgraph problems Discrete applied Mathematics, to appear.
[13] Worsley K.J., An improved bonferroni inequality and application Biometrika,
69 1982, 297-302.

238

Integer Flow with Multipliers:
The Special Case of Multipliers 1 and 2
Birgit Engels a Sven Krumke b Rainer Schrader a Christiane Zeck b
a ZAIK,
b AG

University of Cologne

Optimization, University of Kaiserslautern

Abstract
The problem to find a valid integer flow with flow multipliers on nodes or arcs is long
known to be NP-complete [8]. We show that the problem is still hard when restricted to
instances with a limited number of integral multipliers. We demonstrate that for the multipliers 1 and 2 optimal solutions with fractions 21n , n ∈ N can occur. For special instances
which are motivated by some applications we prove that the optimal solution is halfintegral.
Finally, we extend the Successive Shortest Path Algorithm [2; 6; 7], to the minimum cost
flow problem with multipliers. For the application based instances with halfintegral optimal
solutions, we try to find acceptable integral solutions.
Key words: generalized flow, successive shortest paths, rounding heuristics

1. Introduction
A flow f : A → R is a function which assigns a flow value f (aij ) to each arc
of a digraph N = (V, A) (called network) such that the capacity(∀aij ∈ A : lij ≤
P
P
f (aij ) ≤ uij ) and balance (∀vi ∈ V : ali =(vl ,vi )∈A f (ali ) − aik =(vi ,vk )∈A f (aik ) =
b(vi ), ∀ai ∈ A : fout (aij ) = fin (aij )) constraints hold. Generalized flows or flows
with gains and losses differ from such flows in networks in one respect: a flow may
be damped or amplified when traversing an arc. Depending on the arc multiplier
µij , a unit of flow entering arc aij can result in more or less than one unit leaving
the arc. Denoting the incoming and outgoing flow by fin (aij ) and fout (aij ) we have
fout (aij ) = µij · fin (aij ).
The introduction of flow multipliers detroys the total unimodularity of the network matrix and thus integral optimal solutions are no longer guaranteed or even
impossible. It is known that finding an optimal integer solution is NP-complete for
generalized flows [5; 8]. There seem to be no results for the special case where the
multipliers are restricted to a few fixed numbers or even to the single additional

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

multiplier 2. However, this special case occurred when we modeled a railway disposition problem. We encountered some ’merely generalized’ flow instances with
the property that the underlying network essentially is a bipartite digraph, all excesses, demands (node balances), arc capacities (costs) are integral and we have
only multipliers 1 and 2.
2. Complexity and fractional solutions
The NP-completeness proof for generalized flows by Sahni [8] employs the
subset sum problem. It can be extended to hold for the restriction to multipliers
1 and 2. However this extension does not hold for the the disposition networks,
i.e. the special graph instances which arise from our application. Thus, we show a
reduction from 3V2LSAT, where the constructed graph meets all requirements of
Definition 1.
Definition 1. A disposition network N = (V = X ∪ Y, A) is bipartite digraph
with µa ∈ {1, 2} for all arcs a and all arcs with µ(a) = 2 are directed from X to
Y . Moreover, for all paths from a source s to a sink t the product of multipliers of
all arcs along the path (path multiplier) is either 1 or 2.
Let α = C1 ∧ · · · ∧ Cn be a boolean formula with at most three literals per
clause where each variable vk , 1 ≤ k ≤ m can only occur 3 times in total and
maximal 2 times as one of the corresponding literals. Tovey showed that 3V2LSAT
is NP-complete [9]. In our network Nα we have vertices nk for every variable vk
and additional two vertices n0k , n1k for the corresponding literals ¬lk , lk , which occur
in α. For every nk the node balance bk is +1 and 0 for the literal nodes. Nodes nk
are connected to ’their’ literal nodes by arcs with multiplier 2. For each clause Ci
in α we add a vertex ni , which has incoming arcs from those literal nodes which
correspond to literals occuring in Ci . Finally we add two sink nodes ssat , srest with
node balances bsat = −n and brest = −2m + n to the graph. We connect the
clause nodes to both sinks by arcs (ni , ssat ) with capacity 1 and arcs (ni , srest) with
unlimited capacity (see Figure 1). Unless otherwise noted, any node balances are 0
multipliers are 1, capacity unlimited and costs 0. We conclude:
Theorem 11. The decision problem for a valid integral flow in a disposition network with integral values is NP-complete.
An optimal solution to the min cost flow problem with multipliers 1 and 2 can
contain arbitrarily small fractions of flow: We can construct examples with flows
1
in a graph G(V, A), |V | = 3n in the optimal solution (Figure 1). Yet, we can
2n
transform disposition networks into a generalized minimum cost flow circulation
instance G0 and show that the Circuit Cancelling (CC) algorithm always yields a
half-integral solution to the minimum cost circulation problem on G0 which can be
transfered to the flow instance G.

240

µn1,n01 = 2

n01
n c1

b(n1) = +1

capnc1,ssat = 1
b(ssat) = −n

n1

l = 1 +1

c = 1, µ = 2

l = 2 +1

c = 1, µ = 2

ssat
µn1,n11 = 2

n11

...

capncn,ssat = 1

...
n0m

l = 3 +1

µnm,n0m = 2

l=

srest

n1m

nm

−1
c = 1, µ = 1
c = 1, µ = 2
−1

b(srest) = −2m + n

n cn

b(nm) = +1

−1
c = 1, µ = 1

n
3

+1

c = 1, µ = 2
−1
c = 1, µ = 2
−2n + 1

µnm,n1m = 2

Fig. 1. Construction of network Nα and
µsa = 2

1
2n -solution

a
µat =

s

for a graph with 3n nodes.

1
2

t
b

Fig. 2. Two s-t-ways with identical arc cost, but different de facto per unit cost.

3. Modified SSP Algorithm (MSSP)
The CC algorithm is the first (and to our knowledge only) classical combinatorial minimum cost flow or circulation algorithm so far, which was extended to the
generalized case by Wayne [10]. (Other approaches for solving generalized flow
problems are of course provided by LP techniques and the modified network simplex method of Dantzig [3; 1].) We give a generalization of the Successive Shortest
Path (SSP) algorithm [7; 6; 2], which is based on the principle of pseudoflows,
i.e. flows respecting the non-negativity and capacity constraints, but not the node
balance constraints. We first need to define a shortest path on a network with multipliers: Consider Figure 2, where all arc costs and multipliers are 1 if not depicted
otherwise. The two possible paths from s to t result in costs of 2 accounting only
on arc costs. Yet actually sending one unit of flow along s − a − t creates two units
of flow at a which are passed on to t to deliver one unit at t but arise arc cost of 2
on (a, t).
Definition 2. We define the path costs of a flow multiplier path πuv = u1 −· · ·−un
P
Q
with u = u1 and un = v from u to v as: c0 (πuv ) = ni=2 i−1
j=1 µj(j+1) · c((i − 1)i).

We can easily adjust Dijkstra’s [4] algorithm ∗ by introducing a tentative per
node parameter mv , which accounts for the product of arc multipliers on the (tentative) shortest path from s to every node v. Besides this modification, we take the
flow multipliers into account when we compute the maximum flow δ to be augmented. After each augmentation a residual network is built: For each arc e(u, v)
with a positive flow f (e), an arc ē = (v, u) with capacity cap(ē) = f (e), cost
c(ē) = −c(e), multiplier µē = µ1e and flow 0 is added. If f (e) equals cap(e), then
∗

Dijkstra’s algorithm can be used as a plug-in to the SSP, because of the throughout nonnegative edge weights.

241

arc e is removed from the network. The correctness can be shown with the reduced
cost optimality criterion. The running time of the (unscaled) SSP is pseudopolynomial in the sum of excesses and demands, as in each augmentation at least one unit
of flow is sent. As δ does not need to be integral in our case and because there is no
general lower bound (n) < δ(n), we cannot give an appropriate running time for
general instances. Still we can use the modified SSP on all instances with optimal
solutions of certain fractions. Especially, in the case of disposition networks δ ≥ 21 ,
which (without scaling) also results in a (pseudo)polynomial running time.
4. Rounding to acceptable integer solutions
To obtain an acceptable integral solution we temporarily allow cap(bj , t) to be
violated by 21 . The heuristic can always be applied to a halfintegral solution until there are only integral flows, because in each iteration, at least two halfintegral
flows are rounded (up or down) to integral flows. The node balances can be violated: Although demands do not stay over-saturated in the end (without halfintegral
flows, a violation of cap(bj , t) by ’only’ 21 is impossible), there can be additional
unsaturated deficits and rest excesses, which could be reallocated by another MSSP
application. If we accept the solution nevertheless, we gain a 2-approximate solution.
Rounding
1: while

(∃ halfintegral flow f)

3:

Find cheapest f from s to t

4:

if (f = f +

5:

Round f up, most expensive s-t-flow f’ down.

6:

else Round f down, cheapest s-t-flow f’ up.

1
2

violates bal(t) by at most 21 )

8: end

References
[1] R.K. Ahuja, T.L. Magnanti, J.B. Orlin ”Network Flows - Theory, Algorithms
and Applications” Prentice Hall, 1993.
[2] R.G. Busaker, P.J. Gowen ”A procedure for determining minimal-cost network flow patterns” ORO Technical Report 15, Operational Research Office,
John Hopkins University, Baltimore, MD, 1961.
[3] G.B. Dantzig ”Linear Programming and Extensions” Princeton University
Press, Princeton NJ, 1963.
[4] E. Dijkstra ”A note on two problems in connexion with graphs” Numeriche
Mathemacis 1 pp. 269-271, 1959.
[5] M. Garey and D. Johnson ”Computers and Intractability: A guide to the theory
of NP-Completeness” W.H. Freeman, New York, 1979.
242

[6] M. Iri ”A new method of solving transportation-network problems” Journal
of the Operations Research Society of Japan 3, 27-87, 1960.
[7] W.S. Jewell ”Optimal Flow though networks with gains” Operations Research
10, 476-499, 1962.
[8] S. Sahni ”Computationally Related Problems” SIAM Jr. on Computing, 3, 4,
262-279, 1974.
[9] Craig A. Tovey ”A Simplified NP-Complete Satisfiability Problem” Discrete
Applied Mathematics 8, 85-89, 1984.
[10] Kevin D. Wayne ”A polynomial combinatorial algorithm for generalized minimum cost flow” Mathematics of Operations Research, Vol.27, No.3, 445459, 2002.

243

Polyhedra

Lecture Hall B

Wed 3, 15:45–16:45

Classification of 0/1-facets of the hop constrained
path polytope defined on an acyclic digraph
Rüdiger Stephan a
a Institut

für Mathematik, Technische Universität Berlin, Straße des 17. Juni 136, 10623
Berlin
stephan@math.tu-berlin.de

Key words: path polytope, hop constraints, dynamic programming

1. Introduction

In this paper we study the polytope associated with the hop constrained shortest path problem defined on an acyclic digraph. The aim is to show that all facet
defining 0/1-inequalities for this polytope can be classified via the inherent structure of dynamic programming.
Let D = (N, A) be an acyclic digraph with node set N = {0, 1, . . . , n} and
arc set A = {(i, j) : i = 0, . . . , n − 1, j = i + 1, . . . , n}. A (0, n)-path is a set
of arcs {a1 , . . . , ar } such that ai = (ip−1 , ip ) for p = 1, . . . , r with i0 = 0 and
ir = n. Given a length function d : A → R and a nonnegative integer k ≤ n, the
hop constrained shortest path problem is the problem of finding a (0, n)-path with
at most k arcs of minimum length. Since D is an acyclic digraph, the problem can
be solved in polynomial time for every k and length function d.
k
The hop constrained path polytope, denoted by P0,n-path
(D), is the convex hull
of the incidence vectors of all paths with at most k arcs. Its integer points are characterized by the system

x(δ out (0)) = 1,
x(δ in (n)) = 1,
x(δ out (i)) − x(δ in (i)) = 0,
x(A) ≤ k,
xij ∈ {0, 1}

i = 1, . . . , n − 1,
for all (i, j) ∈ A.

(1.1)
(1.2)
(1.3)
(1.4)
(1.5)

Here, δ out (j) and δ in (j) denote the set of arcs leaving and entering node j, respecP
tively. Moreover, for an arc set F ⊆ A we set x(F ) := (i,j)∈F xij .
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

The hop constrained path polytope and some closely related polyhedra have
been paid some attention in the literature, see [3; 4; 5; 6; 7]. However, a complete
k
linear description of P0,n-path
(D) is unknown, and to the best of our knowledge
just a characterization of all facet defining inequalities bT x ≥ β with coefficients
bij ∈ {0, 1} for (i, j) ∈ A were not given before.
k
2. All 0/1-facet defining inequalities for P0,n-path
(D)

k
The hop constrained path polytope P0,n-path
(D) has some nice properties that
gain access to a promising polyhedral investigation by the dynamic programming
paradigm. We start with a tight connection of this polytope and its dominant
k
k
dmt(P0,n-path
(D)) := P0,n-path
(D) + RA
+ . Proofs are ommited due to lack of space.

Theorem 12. Denote by P0,n-path (D) the ordinary path polytope (k = n). Then, for
k
k
every nonnegative integer k, P0,n-path
(D) = dmt(P0,n-path
(D)) ∩ P0,n-path (D).
k
Theorem 12 implies that a complete linear description of P0,n-path
(D) can be given
T
by nonnegative inequalities b x ≥ β, that is, b ≥ 0.

From the inherent structure of the Bellman-Ford algorithm [2] a so called dynamic programming graph D = (N , A) for the hop constrained shortest path problem can be quite easily constructed. The algorithm computes (the value of) a shortest (i, j)-path for each pair of nodes (i, j), provided D has no negative cycles. In
the main loop of the algorithm the length of a shortest (i, j)-path with at most `
arcs will be computed for ` = 2, . . . , n. The correctness of the algorithm is based
on the Bellman Equations
(1)

uij = dij ,

(`)



(`−1)

uij = min uim
m∈N

+ dmj



for ` = 2, . . . , n,

(2.6)

where u`ij denotes the length of a shortest (i, j)-path with at most ` arcs.
Suppose that the Bellman-Ford algorithm will be executed until ` = k. Fixing i = 0, we associate with each accessable state u`0j a node [j, `] and with each
(`)
(`−1)
possible decision u0j = u0m + dmj an arc ([m, ` − 1], [j, `]) at cost dmj . Substituting all arcs ([i, `], [n, ` + 1]) by ([i, `], [i, ` + 1]) for i = 2, . . . , n − 1, ` =
1, . . . , min{i − 1, k − 2} at cost 0 and removing the nodes [n, `], ` = 1, . . . , k − 1,
the hop constrained shortest path problem is quite easily viewed as one of finding a
shortest ([0, 0], [n, k])-path in the digraph D = (N , A), where N is a disjoint union
of node sets
N0 := {[0, 0]}, Ni := {[i, j] : j = 1, . . . , γi}, i = 1, . . . , n − 1, Nn := {[n, k]}

248

Fig. 1. An acyclic digraph D = (N, A) on node set N = {0, 1, . . . , 7} and associated
DP-graph D = (N , A) for k = 5. Arc set A is omitted; Illustration of a (0, 7)-path and its
analogue in D.

with γi := min{i, k − 1}, and A is given by
A = {([0, 0], [n, k])} ∪ {([0, 0], [i, 1]), ([i, γi], [n, k]) : i = 1, . . . , n − 1}
∪ {([i, j], [i, j + 1]) : i = 2, . . . , n − 1, j = 1, . . . , γi − 1}
∪ {([i, j], [h, j + 1]) : i = 1, . . . , n − 2, j = 1, . . . , min{k − 2, γi },
h = i + 1, . . . , n − 1}.
An illustration of the model is given in Figure 1.
The Bellman equations (2.6) provide us an avenue to derive a classification of
k
all 0/1-facet defining inequalities for dmt(P0,n-path
(D)). To this end, we consider
(h)
the numbers u0j , [j, h] ∈ N as values of a set function π0 : N → R, that is,
(h)
π0 ([j, h]) := u0j for all [j, h] ∈ N . Each function π : N → R induces a valid
P
k
(D)) via
inequality (i,j)∈A µπij xij ≥ π([n, k]) − π([0, 0]) for dmt(P0,n-path
µπij := max{0} ∪ {π([j, `]) − π([i, h]) : ([i, h], [j, `]) ∈ A} for (i, j) ∈ A.(2.7)

k
This result can be proved with the projection theory of Balas [1] applied to dmt(P0,n-path
(D))
and dmt(P[0,0],[n,k]-path(D)).

Observations
(i) π0 is row-monotone. A function π : N → R is called row-monotone if
π([(i, j)]) ≥ π([i, j + 1]) for i = 1, . . . , n − 1, j = 1, . . . , γi − 1.
(ii) π0 is up-monotone. A function π : N → R is said to be up-monotone if
for every node [i, j] ∈ N \ {[0, 0]}, π([i, j]) = π[(h, `)] + µπhi for some arc
([h, `], [i, j]) ∈ δ in ([i, j]), where µπii := 0.
We define an analogue of property (2) for δ out ([i, j]). A function π : N → R
is said to be down-monotone if for every node [i, j] ∈ N \ {[n, k]}, π[(h, `)] =
249

π([i, j]) + µπih for some arc ([i, j], [h, l]) ∈ δ out ([i, j]), where µπii := 0. Next, π
is said to be row-up-and-down-monotone if it is row-, up-, and down-monotone.
Finally, π is called tight if for each arc (i, j) ∈ A it exists an arc ([i, h], [j, `] ∈ A
such that µπij = π([j, `]) − π([i, h]).
Denote by Π the collection of all set functions π : N → R with π([0, 0]) =
0, π([n, k]) = 1, and 0 ≤ π([i, j]) ≤ 1 for all [i, j] ∈ N \ {[0, 0], [n, k]}. We
are now able to characterize all 0/1-facet defining inequalities for the dominant
k
dmt(P0,n-path
(D)).
Theorem 13. Row-up-and-down-monotone 0/1-functions π ∈ Π and nontrivial
k
facet defining 0/1-inequalities for dmt(P0,n-path
(D)) are in 1-1-correspondence, that
is,
(a) each row-up-and-down-monotone 0/1-function π ∈ Π induces a facet defining
k
0/1-inequality for dmt(P0,n-path
(D));
k
(b) each nontrivial facet defining 0/1-inequality for dmt(P0,n-path
(D)) is induced
by a row-up-and-down-monotone 0/1-function π ∈ Π;
(c) if two row-up-and-down-monotone 0/1-functions π, π̃ ∈ Π induce the same
k
facet defining inequality for dmt(P0,n-path
(D)), then π = π̃.
Corollary 1. Tight row-up-and-down-monotone 0/1-functions π ∈ Π and nontrivk
ial facet defining 0/1-inequalities for P0,n-path
(D) are in 1-1-correspondence.

References
[1] E. BALAS, Projection, lifting and extended formulation in integer and combinatorial optimization., Ann. Oper. Res., 140 (2005), pp. 125–161.
[2] R. B ELLMAN, On a routing problem., Q. Appl. Math., 16 (1958), pp. 87–90.
[3] G. DAHL , N. F OLDNES , AND L. G OUVEIA, A note on hop-constrained walk
polytopes., Oper. Res. Lett., 32 (2004), pp. 345–349.
[4] G. DAHL AND L. G OUVEIA, On the directed hop-constrained shortest path
problem., Oper. Res. Lett., 32 (2004), pp. 15–22.
[5] G. DAHL AND B. R EALFSEN, The cardinality-constrained shortest path
problem in 2-graphs., Networks, 36 (2000), pp. 1–8.
[6] V. H. N GUYEN, A complete linear description for the k-path polyhedron,
Preprint 2003.
[7] R. S TEPHAN, Facets of the (s,t)-p-path polytope, http://www.
citebase.org/abstract?id=oai:arXiv.org:math/
0606308, 2006.

250

The k-gear composition and the stable set polytope
A. Galluccio, a C. Gentile, a M. Macina, a P. Ventura a
a IASI-CNR,

viale Manzoni 30, 00185 Rome (Italy)
{galluccio,gentile,ventura}@iasi.cnr.it,
matteo.macina@fastwebnet.it
Key words: Stable set polytope, Polyhedral combinatorics

1. Introduction
Given a graph G = (V (G), E(G)) and a vector w ∈ QV+ of node weights,
the stable set problem is to find a set of pairwise nonadjacent nodes (stable set)
of maximum weight. The stable set polytope ST AB(G) is the convex hull of the
incidence vectors of the stable sets of G: finding its linear description has been one
of the major research problems in combinatorial optimization. A useful strategy to
face this problem is by defining graph compositions that have polyhedral counterparts for the stable set polytope, such as substitutions or complete joins [3]. The
gear composition, introduced in [5], is one of these operations: it builds a graph G
by replacing a suitable edge e of a given graph H with the graph B (gear) shown
in Fig. 1(a).
The polyhedral properties of the gear composition have been extensively studied
in [4]. There we proved that all the facet defining inequalities for ST AB(G) are
obtained by extending the facet defining inequalities describing ST AB(H) and
ST AB(H e ), where H e is obtained from H by subdividing the edge e. Inequalities generated by repeated applications of the gear composition are named multiple
geared inequalities.
The gear composition revealed also a very effective tool to approach the longstanding open problem of finding a linear description of the stable set polytope of clawfree graphs, i.e. graphs such that the neighborhood of each node has no stable set
of size three. For these graphs there exist polynomial time algorithms to optimize
over ST AB(G) [9; 10]; so, by the equivalence of optimization and separation problems [8], one would expect that an explicit linear description for ST AB(G) when
G is claw-free is easy to get. But, as noticed in [8], “in spite of considerable efforts, no decent system of inequalities describing ST AB(G) for claw-free graphs
is known”.
Using the decomposition theorem for claw-free graphs of Chudnovsky and Seymour [1; 2] and the gear composition, we provided the defining linear system of
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

ST AB(G) for a large subclass of claw-free graphs with stability number at least 4.
Indeed, Chudnovsky and Seymour [1; 2] stated that a claw-free graph which does
not admit a 1-join either has stability number at most 3 or it is a fuzzy circular
interval graph or a composition of three types of graphs, called strips: fuzzy linear
interval strips, fuzzy XX-strips, fuzzy antihat strips. In [6] we proved that an XXstrip is in fact a gear plus two extra nodes. This led us to consider the claw-free
graphs that are obtained by composing fuzzy linear interval strips and XX strips.
We named these graphs XX-graphs and we proved that:
Theorem 1.1. [7] The stable set polytope of XX-graphs is described by nonnegativity inequalities, rank inequalities, lifted 5-wheel inequalities and multiple geared
inequalities.
In this paper we look for a generalization of the above result. In particular, we
generalize the gear into a k-gear and, accordingly, we extend the class of claw-free
graphs with the graphs obtained by composing fuzzy linear interval strips, fuzzy
antihat strips, and k-gears. Interestingly, the stable set problem on this superclass
of claw-free graphs is still polynomial time solvable by adapting the algorithm in
[10]. Thus, as for the claw-free graphs, the linear description of their stable set
polytope should be “easy” to obtain. Here, we study the polyhedral structure of
ST AB(G) when G results from the k-gear composition of a k-gear and a given
graph H.

u6

u7

w7

w6

u8

u4

u5

u3

w5

w3
h1

h1

h2

u4

h2

w4
u1

u2

w2

u3

u1

(a)

u2

w2

w3

(b)
Fig. 1. (a) A gear; (b) A 4-gear.

2. k-gear graphs and the k-gear composition
A (2k + 1)-antiwheel W = (h : u1 , . . . , u2k+1) consists of a k-antihole C 2k+1
defined on nodes u1 , . . . , u2k+1 plus a hub h adjacent to each node of C 2k+1 .
Definition 1. Let W1 = (h1 : u1 , . . . , u2k+1 ) and W2 = (h2 : w1 , . . . , w2k+1 ) be
two (2k + 1)-antiwheels with k ≥ 2. The k-gear Bk is the graph such that
252

1) V (Bk ) = V (W1 ) ∪ V (W2 ) and u1 = w1 , u2k = w2k , h1 = w2k+1 , and
h2 = u2k+1,
2) E(Bk ) is E(W1 ) ∪ E(W2 ) plus the edges ui wj , ∀i, j ∈ {2, . . . , k − 1} and
ui wj , ∀i, j ∈ {k + 2, . . . , 2k − 1}.
A k-gear graph Bk with k = 4 is depicted in Fig. 1(b). Since a (2k + 1)-wheel
coincides with a (2k + 1)-antiwheel when k = 2, we have that the gear as defined
in [5] is actually a 2-gear. Interestingly, while ST AB(B2 ) does not admit a facet
defining inequality that has full support on the gear B2 , for k ≥ 3 the k-gear Bk
does support an inequality that is facet defining for ST AB(Bk ). Indeed we prove
that:
Theorem 2.1. Let k ≥ 3 and let Bk be a k-gear. Then the inequality
X

v∈V (Bk )\{h1 ,h2 }

xv + 2(xh1 + xh2 ) ≤ 3.

(2.1)

is facet defining for ST AB(Bk ).
An edge v1 v2 of a graph H is said to be simplicial if K1 = N(v1 ) \ {v1 } and
K2 = N(v2 ) \ {v2 } are two nonempty cliques of H.
Definition 2. Let H be a graph with a simplicial edge v1 v2 and let Bk be a kgear, k ≥ 2. The k-gear composition of H and Bk produces a k-geared graph G,
denoted by G = (H, Bk , v1 v2 ), such that V (G) = V (H) \ {v1 , v2 } ∪ V (Bk ) and
E(G) = E(H) \ δ(v1 ) ∪ δ(v2 ) ∪ E(Bk ) ∪ F1 ∪ F2 , with F1 = {uk u, uk+1u|u ∈
K1 } and F2 = {wk u, wk+1u|u ∈ K2 } (see Fig. 2).
u6

u7

w7

w6

u8
u5

w5

K1

v1

v2

h1

h2

K2

u4

w4
u1

K1

u3

K2

(a)

u2

w2

w3

(b)

Fig. 2. (a) H with a simplicial edge v1 v2 ; (b) the k-geared graph G = (H, Bk , v1 v2 ).

For k = 2 we obtain the definition of gear composition given in [5]. In the
following we show that, as the gear composition, also the k-gear composition has
the polyhedral feature of preserving the property of an inequality of being facet
defining for the stable set polytope. In particular, we show that:

253

Theorem 2.2. Let H be a graph with simplicial edge v1 v2 and let (π, π0 ) be a
facet defining inequality for ST AB(H) different from xv1 + xv2 ≤ 1 and such that
πv1 = πv2 = λ > 0. Let Bk be a k-gear graph with k ≥ 2. Then the following
inequality, called k-geared inequality associated with (π, π0 ),
X

v∈V (H)\{v1 ,v2 }

πv xv + λ

X

v∈V (Bk )\{h1 ,h2 }

xv + 2λ(xh1 + xh2 ) ≤ π0 + 2λ

(2.2)

is facet defining for ST AB(G), where G = (H, Bk , v1 v2 ) is the k-geared graph.
It is worth noticing that the above results do not hold if we generalize the gear
with (2k + 1)-wheels instead of (2k + 1)-antiwheels.

References
[1] M. Chudnovsky and P. Seymour. The structure of claw-free graphs. In Surveys
in Combinatorics, volume 327 of London Math. Soc. Lecture Notes. 2005.
[2] M. Chudnovsky and P. Seymour. Claw-free graphs IV: Decomposition theorem. J. Comb. Th. B, 98(5):839–938, 2008.
[3] V. Chvátal. On certain polytopes associated with graphs. J. Comb. Th. B,
18:138–154, 1975.
[4] A. Galluccio, C. Gentile, and P. Ventura. Gear composition of stable set polytopes and G-perfection. Technical Report 661, IASI - CNR, 2007. To appear
in Mathematics of Operations Research.
[5] A. Galluccio, C. Gentile, and P. Ventura. Gear composition and the stable set
polytope. Operations Research Letters, 36:419–423, 2008.
[6] A. Galluccio, C. Gentile, and P. Ventura. The stable set polytope of claw-free
graphs I: XX-strip composition versus gear composition. 2008. Submitted.
[7] A. Galluccio, C. Gentile, and P. Ventura. The stable set polytope of claw-free
graphs II: XX-graphs are G-perfect. 2008. Submitted.
[8] M. Grötschel, L. Lovász, and A. Schrijver. Geometric algorithms and combinatorial optimization. Springer Verlag, Berlin, 1988.
[9] G.J. Minty. On maximal independent sets of vertices in claw-free graphs. J.
Comb. Th. B, 28:284–304, 1980.
[10] G. Oriolo, U. Pietropaoli, and G. Stauffer. A new algorithm for the maximum
weighted stable set problem in claw-free graphs. LNCS, 5035:77–96, 2008.

254

Plenary Session II

Lecture Hall A

Wed 3, 16:45-17:30

Diameter and Center Computations in Networks
Michel Habib
LIAFA, CNRS & Université Paris Diderot
habib@liafa.jussieu.fr

Key words: Diameter, Breadth-First Search, δ-hyperbolic metric spaces

Abstract:

Starting form a very practical question : what is the best algorithm available to
compute or to approximate the diameter of a huge network ? At first, to compute
the diameter of a given graph, it seems necessary to compute all-pairs shortest
paths, which is not known to be computable in linear time, see [1] and [10].
We first present the well-known 2-sweap Breadth-First Search approximation
procedure and some experimental results of its randomized version on huge graphs
[2], [4], [5], [11]. In order to explain the efficiency of this 2-sweap linear time
procedure, we study its properties on various graph classes and its relation with
classical graph parameters such as: k-chordality or tree-length [7].
We then emphasize on a notion introduced by M. Gromov in 1987 [8], namely
the δ-hyperbolic metric spaces via a simple 4-point condition: for any four points
u, v, w, x the two larger of the distance sums d(u, v) + d(w, x), d(u, w) + d(v, x),
d(u, x) = d(v, w) differ by at most 2δ. δ-hyperbolic metric spaces play an important role in geometric group theory, geometry of negatively curved spaces, and
have recently become of interest in several areas of computer science including
computational geometry and networking.
A connected graph G = (V, E) equipped with its standard graph metric dG
is δ-hyperbolic if the metric space (V, dG ) is δ-hyperbolic. This very interesting
notion captures the distance from a graph to a tree in a metric way. Moreover δhyperbolicity is polynomially computable and easy to approximate.
We survey some results about δ-hyperbolicity of graphs, and in particular we
show that δ-hyperbolicity generalizes tree-length with respect to the 2-sweap algorithm. We provide some experimental results on real data (i.e. graphs extracted

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

from the Internet), showing that δ-hyperbolicity can be a very practical measure
[9].
We finish with a comparison on the computational complexity of the diameter
and the center of a given graph, listing some open questions [12], [3].

References
[1] T. M. Chan, All-pairs shortest paths for unweighted undirected graphs
ino(mn) time, SODA 2006.
[2] V. Chepoi, F. Dragan, A linear time Algorithm for finding a central vertex of
a chordal graph, ESA (1994) 159-170.
[3] V. Chepoi, F. Dragan, B. Estellon, M. Habib, Y. Vaxès, Diameters, centers,
and approximation trees of δ-hyperbolic spaces and graphs, ACM Computational Geometry Conf. (2008) 59-68.
[4] D.G. Corneil, F. Dragan, M. Habib, C. Paul, Diameter determination on restricted graph families, Discrete Applied Mathematics 113 (2001) 143-166.
[5] D.G. Corneil, F. Dragan, E. Khler, On the power of BFS to determine a
graph’s diameter, Networks, vol 42(4), (2003) 209-223.
[6] F. Dragan, Estimating all pairs shortest paths in restricted graph families: a
unified approach, J. of Algorithms 57(2005) 1-21.
[7] Y. Dourisboure, C. Gavoille, Tree-decomposition of graphs with small diameter bags, Discrete Math. 307 (2007) 208-229.
[8] M. Gromov, Hyperbolic Groups, in Essays in GroupTheory (S.M. Gersten
ed.), MSRI Series 8 (1987) 75-263.
[9] R. Kleinberg, Geographic routing Using hyperbolic space, INFOCOM (2007)
1902-1909.
[10] D. Kratsch, J. Spinrad, Between O(mn) and O(nα ), SODA (2003) 709-716.
[11] C. Magnien, M. Latapy, M. Habib, Fast Computation of Empirically Tight
Bounds for the Diameter of Massive Graphs, ACM J. of Experimental Algorithms, 13 (2008).
[12] M. Parnas, D. Ron, Testing the diameter of Graphs, Random Structures &
Algorithms Vol 20, (2002)165 - 183.

258

Polynomial-time Algorithms

Lecture Hall A

Thu 4, 08:45–10:15

Integer programming with 2-variable equations and
1-variable inequalities
Manuel Bodirsky, a Gustav Nordh, b Timo von Oertzen c
a École

Polytechnique, LIX (CNRS UMR 7161), Palaiseau, France
bodirsky@lix.polytechnique.fr

b Theoretical
c Max

Computer Science Laboratory, Linköping University, Sweden
nordh@lix.polytechnique.fr

Planck Institute for Human Development, Berlin, Germany
vonoertzen@mpib-berlin.mpg.de

Key words: Integer programming, computational complexity, efficient algorithms

1. Introduction

We present an efficient algorithm to find an optimal integer solution of a given
system of 2-variable equalities and 1-variable inequalities with respect to a given
linear objective function. More precisely, the input consists of
• a finite set of variables x1 , . . . , xn ,
• equations of the form ax + by = c where x and y are variables, and a, b, c are
rational numbers,
• inequalities of the form x ≤ u or x ≥ l, where x is a variable and u, l are
rational numbers, and
P
• a linear objective function ni=1 wi xi where the the wi ’s are rational numbers.

The task is to find an assignment of integer values to the variables x1 , . . . , xn such
P
that all equations and inequalities are satisfied and the function ni=1 wixi is maximized.

If instead of 2-variable equalities we are given 2-variable inequalities, then
the problem obviously becomes NP-hard (this can be seen by a reduction from
the maximum independent set problem). If instead of 2-variable equalities we are
given 3-variable equalities, then the problem again becomes NP-hard. This follows
by a trivial reduction from the NP-complete problem 1-in-3-SAT, where each 1-in3 clause 1-in-3(x, y, z) is reduced to x + y + z = 1, x, y, z ≥ 0. Hence, 2-variable

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

equalities and 1-variable inequalities is a maximal tractable class in the sense that
allowing longer equalities or longer inequalities results in NP-hard problems.
We remark that finding integer solutions to linear equation systems without inequalities is tractable [4], and has a long history. Faster algorithms have been found
in for example [2; 8]. Integer programming can also be solved in polynomial time
if the total number of variables is two [6]; Lenstra [5] has generalized this result
to any fixed finite number of variables. See [3] for one of the fastest known algorithms for 2-variable integer programming, and for more references about linear
programming in two dimensions.
In our algorithm for a system of 2-variable equalities and 1-variable inequalities over the integers we use the fact that such equation systems reduce to systems
that define a one-dimensional solution space. This idea was also used by Aspvall
and Shiloach [1] in their algorithm for solving systems of 2-variable equations over
the rational numbers. We use this fact to compute an optimal integer solution by
solving a system of modular equations in polynomial time. One of our contributions
is to show that the necessary computations can be performed in total quadratic time
in the input size.
Since the problem to decide whether a single 2-variable equation ax + by = c
with a, b, c ∈ Z has an integer solution for x, y is equivalent to deciding whether the
gcd of a and b is a divisor of c, we cannot expect an algorithm for our problem that is
faster than gcd computations. There are sub-quadratic algorithms for computing the
gcd of two N bit integers with running times in O(log(N)M(N)), where M(N) is
the bit-complexity of multiplying two N bit integers. Using the classical Schönhage
Strassen [7] integer multiplication algorithm, this gives a running time for gcd in
O(N(log(N))2 log(log(N))).
We view it as an interesting open problem whether integer programming over
2-variable equalities and 1-variable inequalities can be shown to be no harder than
gcd computations, i.e., with a running time of O(G(N)) where G(N) is the bit
complexity of computing gcd of two N bit integers. We also emphasize that the
quadratic time algorithm we give does not rely on sub-quadratic algorithms for
multiplication, division, or gcd.

2. Reduction to an acyclic system

We show how to partition the system of equations into independent subsystems, each having a one-dimensional solution space (i.e., the solution space can be
expressed using one free parameter). The graph of an instance of our problem is the
graph that has a vertex for each variable and an edge for each equation (connecting
the two vertices corresponding to the variables in the equation). A instance of our

262

problem is called an acyclic (or connected) system if the graph of the system is
acyclic (or connected, respectively), and a connected component of a system F is a
subsystem of F whose graph is a connected component of the graph of F .
Proposition 1. There is an O(N 2 ) time algorithm that computes for a given system
of two variable linear equations an equivalent acyclic subsystem.
The upper and lower bounds on the variables translate into an upper and lower
bound on the parameter x. If y has the upper bound u and the expression for y is
y = ax + c, then in case that a is positive we get the bound b(buc − c)/ac ≥ x, and
in case a is negative we get the bound d(buc − c)/ae ≤ x. Lower bounds l on y are
treated analogously. After translating all bounds we can obtain the strongest upper
bound and lower bound on x, denoted u∗ and l∗ respectively (obviously, if u∗ < l∗ ,
then there is no solution).

3. Computing an optimal solution
Assume for the sake of presentation that the coefficients a, b, c in all equations
ax + by = c are integer. This is without loss of generality since every equation can
be brought into this form by multiplying both sides of the equation by the product
of the denominators of a, b, and c. This can clearly be done in quadratic time and
increases the bit size of the input by at most a constant factor. Check that each
individual equation ax + by = c has integer solutions. Recall that a Diophantine
equation of the form ax + by = c has integer solutions if and only if gcd(a, b)|c.
Simplify the equations by dividing a, b, and c by gcd(a, b). In the resulting system
we now have gcd(a, b) = 1 for each equation ax + by = c.
Proposition 2. There is an O(N 2 ) time algorithm for solving acyclic connected
systems of two variable equations over the integers.
Proof Sketch. We perform a depth-first search on the graph of the system, starting with any variable x from the system. The goal is to find an expression for the
solution space of the form x ≡ s (mod t). That is, the assignment x := i can be
extended to an integer solution to the entire system if and only if i ≡ s (mod t).
If we enter a variable y in the DFS and y has an unexplored child z, then continue
recursively with z. If z is a leaf in the tree, meaning that there is a unique equation ay + bz = c where z occurs, then rewrite the equation as ay ≡ c (mod b).
Note that an assignment y := i can be extended to a solution of ay + bz = c if
and only if ai ≡ c (mod b). Compute the multiplicative inverse a−1 of a (mod b)
(which exists since gcd(a, b) = 1 and can be retrieved from the gcd computation).
The congruence above can now be rewritten as y ≡ c0 (mod b) where c0 = ca−1 .
If all children of y have been explored, then y is explored and we backtrack. If
v is the parent of y through the equation dv + ey = f , then rewrite the equation

263

using the congruence y ≡ c0 (mod b), into dv + e(c0 + kb) = f which is equivalent to dv + ebk = f − ec0 . Check that gcd(d, eb)|(f − ec0 ) (otherwise there is no
solution and we reject) and divide d, eb, and f − ec0 by gcd(d, eb) giving the equation d0 v + e0 k = f 0 with gcd(d0, e0 ) = 1. Rewrite this equation as the congruence
d0 v ≡ f 0 (mod e0 ) which in turn is rewritten as v ≡ f 00 (mod e0 ) by multiplying
both sides with the multiplicative inverse of d0 (mod e0 ) (which again exists since
gcd(d0, e0 ) = 1). Suppose that v already has an explored child (with congruence
v ≡ c (mod b)) when we have finished exploring another child of v, giving rise to
the congruence v ≡ c0 (mod b0 ). We then combine these congruences in a similar
fashion as discussed above already twice (by computing greatest common divisors
and multiplicative inverses). The result (if a solution exists) is a congruence v ≡ c00
(mod b00 ), which replaces the two old congruences, and we continue the depth first
search. We omit the proof that the algorithm runs in quadratic time.
Theorem 14. There is an algorithm that computes the optimal solution of a given
integer program with 2-variable equalities and 1-variable inequalities in O(N 2 )
time, where N is the number of bits in the input.

References
[1] B. Aspvall and Y. Shiloach. A fast algorithm for solving systems of linear
equations with two variables per equation. Linear Algebra and its Applications, 34:117–124, 1980.
[2] T. Chou and G. Collins. Algorithms for the solution of systems of linear
diophantine equations. SIAM J. Comput., 11(4):687–708, 1982.
[3] F. Eisenbrand and S. Laue. A linear algorithm for integer programming in the
plane. Math. Program., 102(2):249–259, 2005.
[4] R. Kannan and A. Bachem. Polynomial algorithms for computing the smith
and hermite normal forms of an integer matrix. SIAM J. Comput., 8(4):499–
507, 1979.
[5] H.W. Lenstra. Integer programming with a fixed number of variables. Mathematics of Operations Research, 8(4):538–548, 1983.
[6] H. E. Scarf. Production sets with indivisibilities. part ii: The case of two
activities. Econometrica, 49:395–423, 1981.
[7] A. Schönhage and V. Strassen. Schnelle Multiplikation grosser Zahlen. Computing, 7:281–292, 1971.
[8] A. Storjohann and G. Labahn. Asymptotically fast computation of hermite
normal forms of integer matrices. In ISSAC, pages 259–266, 1996.

264

Faster Min-Max Resource Sharing and Applications
Dirk Müller 1
Research Institute for Discrete Mathematics, University of Bonn
mueller@or.uni-bonn.de
Key words: min-max resource sharing, fractional packing, approximation algorithms,
VLSI design

The problem of sharing a set of limited resources between users (customers) in
an optimal way is fundamental. The common mathematical model has been called
the min-max resource sharing problem. Well-studied special cases are the fractional
packing problem and the maximum concurrent flow problem. The only known exact algorithms for these problems use general linear (or convex) programming.
Shahrokhi and Matula [9] were the first to design a combinatorial approximation
scheme for the maximum concurrent flow problem. Subsequently, this result was
improved, simplified, and generalized many times. This work is a further step on
this line. In particular we provide a simple algorithm and a simple proof of the
best performance guarantee in significantly smaller running time. Moreover, we
implemented the algorithm for an application to global routing of VLSI chips.
The problem. The M IN -M AX R ESOURCE S HARING P ROBLEM is defined as
follows. Given finite sets R of resources and C of customers, a convex set Bc , called
block, of feasible solutions for customer c (for c ∈ C), and a nonnegative continuous
convex function gc : Bc → RR
+ for c ∈ C specifying the resource consumption, the
task is to find bc ∈ Bc (c ∈ C) approximately attaining
∗

λ := inf

(

max
r∈R

X
c∈C




(gc (bc ))r  bc


)

∈ Bc (c ∈ C) ,

(0.1)

i.e., approximately minimizing the largest resource consumption. We assume that
gc can be computed efficiently and we have a constant 0 ≥ 0 and oracle functions
R
fc : RR
+ → Bc , called block solvers, which for c ∈ C and ω ∈ R+ return an element
bc ∈ Bc with ω > gc (bc ) ≤ (1 + 0 )O PT c (ω), where O PT c (ω) := inf b∈Bc ω > gc (b).
Block solvers are called strong if 0 = 0 or 0 > 0 can be chosen arbitrarily small,
otherwise they are called weak.
1

joint work with J. Vygen

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Note that previous authors often required that Bc is compact, but we do not
need this assumption. Some algorithms require bounded block solvers: for c ∈ C,
>
ω ∈ RR
+ , and µ > 0, they return an element bc ∈ Bc with gc (bc ) ≤ µ1 and ω gc (bc ) ≤
>
(1 + 0 ) inf{ω gc (b) | b ∈ Bc , gc (b) ≤ µ1} (by 1 we denote the all-one vector).
They can also be strong or weak.
All algorithms that we consider are fully polynomial approximation schemes
relative to 0 , i.e., for any given  > 0 they compute a solution bc ∈ Bc (c ∈ C) with
P
maxr∈R c∈C (gc (bc ))r ≤ (1+0 +)λ∗ , and the running time depends polynomially
on −1 . By θ we denote the time for an oracle call (to the block solver). Moreover,
r
we write ρ := sup{ (gcλ(b))
| r ∈ R, c ∈ C, b ∈ Bc }.
∗
Previous work. Grigoriadis and Khachiyan [4] were the first to present such
an algorithm for the general M IN -M AX R ESOURCE S HARING P ROBLEM. Their
algorithm uses O(|C|2 log |R|(−2 +log |C|)) calls to a strong bounded block solver.
They also have a faster randomized version.
In [5] they proposed an algorithm which needs O(|C||R|(−2 log −1 +log |R|))
calls to a strong, but not bounded, block solver. They also showed that
O(|C|2 log |R|(−2 + log |R|)) calls to a strong bounded block solver suffice.
Jansen and Zhang [6] generalized this and allowed weak block solvers. Their
algorithm needs O(|C||R|(log |R| + −2 log −1 )) calls to a block solver.
block solver
Grigoriadis, Khachiyan [4] strong, bounded
Grigoriadis, Khachiyan [5] strong, unbounded
Jansen, Zhang [6]
weak, unbounded
our algorithm
weak, unbounded
our algorithm
weak, bounded

running time
Õ(−2 |C|2 θ)
Õ(−2 |C||R|θ)
Õ(−2 |C||R|θ)
Õ(−2 ρ|C|θ)
Õ(−2 |C|θ)

Table 12. Approximation algorithms for the M IN -M AX R ESOURCE S HARING P ROBLEM.
Running times are shown for fixed 0 ≥ 0, and logarithmic terms are omitted.

Fractional packing. The special case where the functions gc (c ∈ C) are linear
is often called the F RACTIONAL PACKING P ROBLEM (although sometimes this
name is used for different problems). For this special case faster algorithms using unbounded block solvers are known. Plotkin, Shmoys and Tardos [8] require a
strong block solver and O(−2 ρ|C|θ(log |R|+−1 )) oracle calls to solve the feasibility version (where λ∗ = 1 is known). Young’s algorithm [11] needs O(−2ρ|C|(1 +
0 )2 θ ln |R|) calls to a weak block solver. Charikar et al. extended the result of [8]
to weak block solvers resulting in O(−2 ρ|C|(1 + 0 )2 θ log(ρ(1 + 0 )−1 )) oracle
calls.
Bienstock and Iyengar [2] managed to reduce the dependence on  from O(−2 )
to O(−1 ). Their algorithm does not call a block solver, but requires the resource
consumption functions to be explicitly specified by a |R| × dim(Bc )-matrix Gc for
266

each c ∈ C. So their algorithm does not apply to the general M IN -M AX R ESOURCE
S HARING P ROBLEM, but to an interesting special case which includes
q the M AX −1
IMUM C ONCURRENT F LOW P ROBLEM. The algorithm solves O(
Kn log |R|)
separable
convex
quadratic
programs,
where
P
P
n := c∈C dim(Bc ), and K := max1≤i≤|R| c∈C kic , with kic being the number of
nonzero entries in the i-th row of Gc .
block solver
running time
Plotkin, Shmoys, Tardos [8] ∗ strong, unbounded Õ(−2 ρ|C|θ)
weak, unbounded
Õ(−2 ρ|C|θ)
Young [11]
−2
Charikar et al. [3] ∗
weak, unbounded
Õ(√
ρ|C|θ)
−1
—
Õ(
KnTQP )
Bienstock, Iyengar [2]
−2
our algorithm
Õ( ρ|C|θ)
weak, unbounded
weak, bounded
Õ(−2 |C|θ)
our algorithm
Table 13. Approximation algorithms for the fractional packing problem. Entries with ∗
refer to the feasibility version (λ∗ = 1). Running times are shown for fixed 0 ≥ 0, and
logarithmic terms are omitted. TQP is the time for solving a convex separable quadratic
program over Bc1 × . . . × Bc|C| .

Our results. We describe an algorithm for the general M IN -M AX R ESOURCE
S HARING P ROBLEM. It uses ideas of Grigoriadis and Khachiyan [5], Young [11],
Albrecht [1], and Vygen [10]. The same algorithm and a quite simple analysis
yields two results: With a weak unbounded block solver we obtain a running time
of O(|C|θρ(1 + 0 )2 log |R|(log |R| + −2 (1 + 0 ))). This generalizes several results for the linear case and improves on results for the general case for moderate
values of ρ. With a weak bounded block solver the running time is O(|C|θ(1 +
0 )2 log |R|(log |R| + −2 (1 + 0 ))). This improves on previous results by roughly
a factor of |C| or |R|. The running times are summarized in Tables 1 and 2.
Our motivation is an application to VLSI design. In global routing instances of
the (nonlinear) M IN -M AX R ESOURCE S HARING P ROBLEM occur naturally when
dealing with today’s constraints and objectives (see e. g. [7]). We incorporate a
speed-up technique that drastically decreases the number of oracle calls in practice.
We generalize the randomized rounding paradigm to our problem and obtain an
improved bound. Finally we present experimental results for instances from current
chips, with millions of customers and resources. We show that such problems can
be solved efficiently.

References
[1] Albrecht, C.: Global routing by new approximation algorithms for multicommodity flow. IEEE Transactions on Computer Aided Design of Integrated Circuits and Systems 20 (2001), 622–632

267

[2] Bienstock, D., and Iyengar, G.: Concurrent Flows in O ∗ ( 1 ) iterations. In Proceedings of the 2004 Symposium on Theory of Computing, pp. 146–155,
2004.
[3] Charikar, M., Chekuri, C., Goel, A., Guha, S., and Plotkin, S.: Approximating
a finite metric by a small number of tree metrics. Proceedings of the 39th
Annual IEEE Symposium on the Foundations of Computer Science (1998),
pp. 379–388
[4] Grigoriadis, M. D., and Khachiyan, L. D.: Fast approximation schemes for
convex programs with many blocks and coupling constraints. SIAM Journal
on Optimization, Vol. 4, No. 1, pp. 86–107, 1994.
[5] Grigoriadis, M. D., and Khachiyan, L. D.: Coordination complexity of parallel
price-directive decomposition. Mathematics of Operations Research, Vol. 21,
No. 2, pp. 321–340, 1996.
[6] Jansen, K., and Zhang, H.: Approximation algorithms for general packing
problems and their application to the multicast congestion problem. Mathematical Programming 114, Ser. A, pp. 183–206, 2008.
[7] Müller, D.: Optimizing yield in global routing. Proceedings of the IEEE International Conference on Computer-Aided Design, pp. 480–486, 2006.
[8] Plotkin, S.A., Shmoys, D.B., and Tardos, É.: Fast approximation algorithms
for fractional packing and covering problems. Mathematics of Operations Research 2 (1995), 257–301
[9] Shahrokhi, F., and Matula, D.W.: The maximum concurrent flow problem.
Journal of the ACM 37 (1990), 318–334
[10] Vygen, J.: Near-optimum global routing with coupling, delay bounds, and
power consumption. In: Integer Programming and Combinatorial Optimization; Proceedings of the 10th International IPCO Conference; LNCS 3064 (G.
Nemhauser, D. Bienstock, eds.), Springer, Berlin 2004, pp. 308–324
[11] Young, N.E.: Randomized rounding without solving the linear program. Proceedings of the 6th ACM-SIAM Symposium on Discrete Algorithms (1995),
pp. 170–178

268

The Anonymous Subgraph Problem
Andrea Bettinelli, a Leo Liberti, b Franco Raimondi, c
David Savourey b
a Dept.

of Mathematics, Universitá degli Studi di Milano, Italy
andrea.bettinelli@unimi.it

b LIX,

École Polytechnique, F-91128 Palaiseau, France
{liberti,savourey}@lix.polytechnique.fr

c Dept.

of Computer Science, University College London, UK
f.raimondi@cs.ucl.ac.uk

Key words: anonymity, anonymous routing, secret santa, graph’s topology

1. Introduction
Many problems can be modeled as the search for a subgraph S ⊆ A with
specific properties, given a graph G = (V, A). There are applications in which it is
desirable to ensure also S to be anonymous. In this work we formalize an anonymity
property for a generic family of subgraphs and the corresponding decision problem.
We devise an algorithm to solve a particular case of the problem and we show
that, under certain conditions, its computational complexity is polynomial. We also
examine in details several specific family of subgraphs.

2. Characterization of anonymity
Given a digraph G = (V, A), let |V | = n and |A| = m. We are interested
in finding if a certain family A of subgraphs is anonymous with respect to G. By
anonymous we mean that it is not possible to single out a subgraph S ∈ A, nor to
identify any other arc in the subgraph, given the topology of the graph and a subset
C of the arcs in S. We call C a partial view of S. Let P V : P(A) × A → {0, 1}
be the function
P V (X, S) =



1

0

X is a partial view of S
otherwise

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

that defines which subsets are considered a partial view of a certain subgraph.
Definition 4. (Anonymous family of subgraphs) Given a digraph G = (V, A)
and a function P V : P(A) × A → {0, 1}, a family of subgraphs A ⊆ P(A)
is anonymous in G if
∀S ∈ A, ∀C ∈ {X|P V (X, S) = 1} , ∀b ∈ S \ C

∃T ∈ A : C ⊆ T ∧ b ∈
/ T.

We call anonymous subgraphs the elements of an anonymous family A. It is now
possible to define Anonymous Subgraph Problem (ASP) as the decision problem of
checking if a family of subgraphs contains an anonymous family with respect to a
graph.
Definition 5. (Anonymous Subgraph Problem) Given a digraph G = (V, A), a
function P V : P(A) × A → {0, 1}, and a family of subgraphs S, is there a non
empty subset A of S which is anonymous in G?
Here we restrict our analysis to the case where the set of partial views of a
subgraph S is {C| C ⊆ S ∧ |C| = 1}, i.e. only one arc of the subgraph is known.
With this restriction, we obtain the following definition of anonymity:
Definition 6. Given a digraph G = (V, A), a family of subgraphs A ⊆ P(A) is
anonymous in G if
∀S ∈ A, ∀a 6= b ∈ S

∃T ∈ A : a ∈ T ∧ b ∈
/ T.

We will refer to ASP1 to denote the Anonymous Subgraph Problem where Definition 6 is used to characterize anonymity. In Section 3 we propose an algorithm to
solve the ASP1 and we show under what conditions its computational complexity is
polynomial in the size of the graph G, even if the family S contains a combinatorial
number of subgraphs.

3. Algorithm
Algorithm 1 Algorithm for solving the ASP1
1: F INDA NONYMOUS SG(G, S, P ):
2: for all a 6= b ∈ P do
3:
if F IND SG(G, S, P \ {b}, {a}) = ∅ then
4:
return F INDA NONYMOUS SG(G, S, P \ {a})
5:
end if
6: end for
7: return F IND SG(G, S, P, ∅)
Algorithm 1 solves the ASP1: it returns an element of A, if A exists, and an
270

empty set otherwise. It is a recursive algorithm and at the top level P is equal to the
arc set A. The algorithm is based on the following observation: if there exists two
distinct arcs a, b ∈ A such that no subset T ∈ S contains a but not b, it implies that
all the subsets S ∈ S that contain a are not anonymous. Thus, we can transfer the
anonymity property from the subsets to the arcs. The algorithm iteratively remove
arcs from the set P of permitted arcs and uses this set as additional constraints
when looking for possible subgraphs. If no subgraphs can be found satisfying the
additional constraints given by P the family is not anonymous in G.
We assume the correctness of the subroutine F IND SG(G, S, P, X): it returns
an empty set if and only if it doesn’t exist a subgraph S ∈ S ∩ P(P ) : x ∈ S∀x ∈
X.
Theorem 15. Alg. 1 correctly solves the ASP1.
Proof. First we observe that, if the algorithm returns a non empty solution, at line
7 the set A of subgraphs in S where every arc belongs to P is anonymous in G.
Let S ⊆ P be an element of A, we know that ∀a, b ∈ S ∃T ∈ A s.t. a ∈ T
and b ∈
/ T , otherwise a would have been banned from P . Assume now there is a
solution to ASP1 and Alg. 1 fails. The existence of a solution implies the existence
of a non empty anonymous set A. If our algorithm reached line 7 with A ⊆ P(P ),
then, because F IND SG(G, S, P, X) is correct, our algorithm would not have failed.
Thus we know that the algorithm reached line 7 with A \ P(P ) 6= ∅. Consider
the first time an arc a ∈ A used in at least one element of A has been removed
from P . At that time A ⊆ P(P ), so a would not have been removed because
∀b 6= a ∈ P ∃T ∈ A s.t. a ∈ T and b ∈
/ T.
Since initially |P | = m and at every recursive call the cardinality of P is decreased by one, we are sure that the number of recursive calls is bounded by m. At
each call the subroutine F IND SG is executed up to m2 times. Thus, if F IND SG has
computational complexity O(γ), the worst case complexity of the overall algorithm
is O(m3γ). In conclusion, if we are provided a polynomial algorithm to solve the
subproblem, we can solve ASP1 in polynomial time.

4. Special cases and applications.

Definition 4 holds for a generic family of subsets. In real application we usually have to deal with a family S characterized by specific properties. By exploiting
them, we can describe S implicitly and, in some cases, obtain polynomial procedures to solve F IND SG even if the cardinality of S is combinatorial in the size of
the graph.
We now analize some families of subgraphs that lead to interesting applica-

271

tions.

Secret Santa Problem.
If the family S is the set of all Vertex Disjoint Circuit Covers (VDCCs), we
obtain the Secret Santa Problem described in [2].
The basic concept of the Secret Santa game is simple. All of the participants’
names are placed into a hat. Each person then chooses one name from the box, but
doesn’t tell anyone which name was picked. He/she is now responsible for buying a
gift for the person selected. When the Secret Santa wraps his/her gift, he/she should
label it with the recipient’s name but doesn’t indicate whom the present is from. All
the gifts are then placed in a general area for opening at a designated time.
Additional constraints are considered in the definition of the problem: it may
be required that self-gifts and gifts between certain pairs of participants should be
avoided. The problem can be modeled with a digraph, where vertices represent
the participants and arcs the possibility of a participant giving a gift to another
participant. We want to determine if the topology of the graph allows an anonymous
exchange of gifts, that is nobody can discover who made a gift to whom, knowing
the graph and the receiver of his gift.
The problem can be formulated as an ASP1 where S is the family of all the
VDCCs of the graph.
Definition 7. A Vertex Disjoint Circuit Cover (VDCC) for G = (V, A) is a subset
S ⊆ A of arcs of G such that: (a) for each v ∈ V there is a unique u ∈ V , called
the predecessor of v and denoted by πS (v), such that (u, v) ∈ S; (b) for each v ∈ V
there is a unique u ∈ V , called the successor of v and denoted by σS (v), such that
(v, u) ∈ S. We denote by C the set of all VDCCs in G.
In this case F IND SG(G, S, P, {(i, j)} requires to find a VDCC with restrictions
1
on the arcs can be used. As shown in [2] it can be done in O(n 2 m) by solving
an assignment problem on a bipartite graph B = (U1 , U2 , A0 ), where U1 = U2 =
V \ {i, j} and A0 = P .
Anonymous routing.

In many contexts it is desirable to hide the identity of the users involved in
a transaction on a public telecommunication network. According to the specific
application, we may be interested in:

272

• sender anonymity to a node, to the receiver or to a global attacker;
• receiver anonymity to any node, to the sender or to a global attacker;
• sender-receiver unlinkability to any node or a global attacker. This means that
a node may know that A sent a message and B received one, but not that A’s
message was actually received by B.
Several protocols to provide anonymous routing features has been proposed in the
literature ([1; 4; 3]). Using these protocols every node traversed by a message has
only a partial knowledge on the path the message is being routed on. Typically a
node knows only the next step, or the next and the previous one.
Attacks against these protocols are usually based on traffic analysis. Thus, if
the topology of the network contains “forced paths”, they can leak information to
an attacker who is monitoring the traffic.
Some protocols, like Onion Routing, require the topology of the network to
be known to every participant. Every time a node leave or a new node joins the
protocol, the topology of the network changes. Therefore it may be useful to check
the network against the presence of “forced paths”. This can be done by solving, for
each pair of nodes (s, t) of the network, an instance of ASP1 where G is the graph
representing the network and S is the family of all paths of length at least 2 between
the two nodes. We exclude paths involving one arc because they naturally fail in
providing anonymity. The subproblem F IND SG(G, S, P \ {b}, {(i, j)}) requires,
in this case, to find two paths: one from s to i and one from j to t. It can be done in
O(n + m) using a graph traversing algorithm.
Anonymous routing protocols usually generate pseudo-random path in order to
maximize the level of anonymity provided and the robustness against traffic analysis attacks. This introduces delays in the transaction (e.g. in onion routing we have
to apply a layer of cryptography for each node in the path) that cannot be tolerated
in certain application, i.e. when the content of the message is part of an audio or
video stream, or in financial market transactions. In these situations we may want
to give up some anonymity in exchange for performances. We may, for example,
force the routing protocol to choose quasi shortest paths, instead of random ones.
Again, we would like the topology of the graph to allow them to be anonymous.
We can check this property in a way similar to what we have done in the previous
case, but this time the family S will contain only the s − t paths S whose length is
not greater than α times the length of the shortest path from s to t, where α ≥ 1 is
a given parameter.

References
[1] D. Chaum.
Untraceable electronic mail, return addresses, and digital
pseudonyms. Communications of the ACM, 24:84–88, 1981.

273

[2] Leo Liberti and Franco Raimondi. The secret santa problem. In R. Fleischer
and J. Xu, editors, AAIM08 Proceedings, pages 271–279. Springer, 2008.
[3] M. Reiter and A. Rubin. Crowds: anonymity for web transactions. ACM Transactions on Information and System Security, 1(1):66–92, 1998.
[4] P F Syverson, D M Goldschlag, and M G Reed. Anonymous connections and
onion routing. In IEEE Symposium on Security and Privacy, 1997.

274

Graph Theory III

Lecture Hall B

Thu 4, 08:45–10:15

The number of excellent discrete Morse functions on
graphs ?
R. Ayala, a D. Fernández-Ternero, a J.A. Vilches a
a Dpto.

de Geometrı́a y Topologı́a, Universidad de Sevilla, 41080, Sevilla, SPAIN
{rdayala, desamfer, vilches}@us.es

Abstract
In [5] the number of non-homologically equivalent excellent discrete Morse functions defined on S1 was obtained in the differentiable setting. We carried out the analogous study in
the discrete setting for some kind of graphs, including S 1 , in [2]. In this paper we complete
this study counting excellent discrete Morse functions defined on any infinite locally finite
graph.
Key words: infinite locally finite graph, critical simplex, gradient vector field, gradient
path, excellent discrete Morse function

1. Introduction

Through all this paper, we only consider infinite graphs which are locally finite.
Given such a graph G, a bridge is an edge whose deletion increases the number of
connected components of G. A graph is said to be bridgeless if it contains no
bridges. We consider non trivial connected bridgeless graphs, that is, connected
bridgeless graphs not consisting of a unique vertex.
Let B the set of all bridges of G. The bridge components of G are the connected components of G − B. For other topics of graph theory we follow [4].
We introduce here the basic notions of Discrete Morse theory [3]. A discrete
Morse function is a function f : G −→ R such that, for any p-simplex σ ∈ G:
(M1) card{τ (p+1) > σ/f (τ ) ≤ f (σ)} ≤ 1.
? The authors are partially supported by the Plan Nacional de Investigación 2.007, Project
MTM2007-65726, España, 2008.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

(M2) card{υ (p−1) < σ/f (υ) ≥ f (σ)} ≤ 1.
A p-simplex σ ∈ G is said to be a critical simplex with respect to f if:
(C1) card{τ (p+1) > σ/f (τ ) ≤ f (σ)} = 0.
(C2) card{υ (p−1) < σ/f (υ) ≥ f (σ)} = 0.
A value of a discrete Morse function on a critical simplex is called critical value.

A ray is a sequence of simplices:
v0 , e0 , v1 , e1 , . . . , vr , er , vr+1 . . .
If there is a discrete Morse function f defined on G, a decreasing ray is a ray
verifying that:

f (v0 ) ≥ f (e0 ) > f (v1 ) ≥ f (e1 ) > · · · ≥ f (er ) > f (vr+1 ) ≥ · · ·
A critical element of f on G is either a critical simplex or a decreasing ray.
Given c ∈ R the level subcomplex G(c) is the subcomplex of G consisting of
all simplices τ with f (τ ) ≤ c, as well as all of their faces, that is,
G(c) =

[

[

σ

f (τ )≤c σ≤τ

Theorem 1.1. [1] Let G be a graph and let f be a discrete Morse function defined
on G such that the numbers mi (f ) of critical i-simplices of f with i = 0, 1 are
finite and f has no decreasing rays. Then:
(i) m0 (f ) ≥ b0 and m1 (f ) ≥ b1 , where bi denotes the i-th Betti number of G
with i = 0, 1.
(ii) b0 − b1 = m0 (f ) − m1 (f ).
Given a discrete Morse function defined on G, we say that a pair of simplices
(v < e) is in the gradient vector field induced by f if and only if f (v) ≥ f (e).
Given a gradient vector field V on G, a V -path is a sequence of simplices
(p)

(p+1)

α0 , β0

(p)

(p+1)

, α1 , β1

(p)

, . . . , βr(p+1) , αr+1 , . . . ,

(p)

(p+1)

such that, for each i ≥ 0, the pair (αi < βi
278

(p+1)

) ∈ V and βi

(p)

(p)

> αi+1 6= αi .

Given a 0-critical simplex in G, we say that any vertex w of G is rooted in v if
there exists a finite V -path joining w and v.
Proposition 1.2. [2] Let G be an infinite graph and let f be a discrete Morse function defined on G with no decreasing rays. It holds that:
(i) Given w any vertex of G, there is a unique 0-critical simplex on which w is
rooted.
(ii) Given any 0-critical simplex v, the set of all V -paths rooted in it is a tree called
the tree rooted in v and denoted by Tv .
(iii) Any two of such rooted trees are disjoint.
Theorem 1.3. [2] Under the above definitions and notations, the forest F consisting of all rooted trees in G can be obtained by removing all critical edges of f on
G.

2. The number of excellent discrete Morse functions on a graph
A discrete Morse function defined on a graph G is called excellent if all its
critical values are different.
Two excellent discrete Morse functions f and g defined on a graph G with critical values a0 < a1 < · · · < am−1 and c0 < c1 < · · · < cm−1 respectively will be
called homologically equivalent if for all i = 0, . . . , m − 1 the level subcomplexes
G(ai ) and G(ci ) have the same Betti numbers.
Let f be an excellent discrete Morse function defined on G with m critical
simplices and critical values a0 , . . . , am−1 . We denote the level subcomplexes G(ai )
by Gi for all i = 0, . . . , m − 1. The homological sequences of f are the two
sequences B0 , B1 : {0, 1, . . . , m−1} → N containing the homological information
of the level subcomplexes G0 , . . . , Gm−1 , that is, Bp (i) = bp (Gi ) = dim(Hp (Gi ))
for each i = 0, . . . , m − 1 and p = 0, 1.
Notice that the homological sequences of f satisfy:
B0 (0) = B0 (m − 1) = b0 = 1, B0 (i) > 0, |B0 (i + 1) − B0 (i)| = 0 or 1;
B1 (0) = 0, B1 (m − 1) = b1 ,

B1 (i) ≥ 0, B1 (i + 1) − B1 (i) = 0 or 1.

Lemma 2.1. [2] For each i = 0, 1, . . . , m − 2 it holds one and only one of the
following identities:
(H1) B0 (i) = B0 (i + 1).
(H2) B1 (i) = B1 (i + 1).

279

Note that identity (H1) reveals us the creation of a new 1-cycle of G on this
process and therefore it holds this identity for exactly b1 values of i. If we remove
B0 (i + 1) for these values of i in the sequence B0 , we obtain a walk in Z>0 starting
and ending at 1, with even length 2k and steps
  of size ±1. The number of such
1
walks is the k-th Catalan number Ck = k+1 2k
.
k

Lemma 2.2. If G is a connected graph with at least one bridge and b1 < +∞,
then G = P1 ∪ P2 ∪ · · · ∪ Pp ∪ F , where P1 , . . . , Pp are the non trivial bridge
components of G, F is a forest and every tree in F intersects each Pi in at most one
vertex. Moreover, if G is infinite, then F has at least an infinite tree.

Theorem 2.3. Under the notations of the above Lemma, the number of homology
equivalence classes of excellent discrete Morse functions with
m = b0 + b1 + 2k critical elements on a graph G with b1 < +∞ is:
!

m−2
if G is a non trivial bridgeless graph.
(i) Ck
2k !
m−1
if G is infinite or has at least one vertex with degree one.
(ii) Ck
2k
!!
!
!
k−1
X
2j + b12 + 1 2(k − j) + b11 − 2
m−1
if G is
−
Cj Ck−j−1
(iii)
2(k − j) − 1
2j
2k
j=0
finite, G has at least one bridge and the degree of any vertex of G is greater
than one, where b11 = min{b1 (Pi ) : F ∩ Pi is a unique vertex } and b12 =
b1 − b11 .
References
[1] R. Ayala, L.M. Fernández and J.A. Vilches, Discrete Morse inequalities on
infinite graphs,The Electronic Journal of Combinatorics 16 (1) (2009) R38,
11 pp. (electronic).
[2] R. Ayala, L.M. Fernández, D. Fernández-Ternero and J.A. Vilches, Discrete
Morse Theory on graphs, to appear in Topology Appl.
[3] R. Forman, A user’s guide to discrete Morse theory, Sém. Lothar. Combin. 48
(2002), Art. B48c, 35 pp. (electronic).
[4] J. L. Gross, J.Yellen (ed.), Handbook of graph theory. Discrete Mathematics
and its Applications. CRC Press, 2004.
[5] L. I. Nicolaescu, Counting Morse functions of the 2-sphere, Compositio Math.
144 (2008), pp. 1081–1106.

280

Partial characterizations of circle graphs
Flavia Bonomo, a,b,1,2 Guillermo Durán, a,c,d,1,3
Luciano N. Grippo, a,b,e,1 Martı́n D. Safe a,b,1
a CONICET,
b Departamento

c Departamento

de Computación, Facultad de Ciencias Exactas y Naturales, Universidad
de Buenos Aires, Argentina
{fbonomo, mdsafe}@dc.uba.ar
de Matemática, Facultad de Ciencias Exactas y Naturales, Universidad
de Buenos Aires, Argentina
gduran@dm.uba.ar

d Departamento
e Instituto

Argentina

de Ingenierı́a Industrial, Facultad de Ciencias Fı́sicas y Matemáticas,
Universidad de Chile, Chile

de Ciencias, Universidad Nacional de General Sarmiento, Argentina
lgrippo@ungs.edu.ar

Key words: circle graphs, Helly circle graphs, structural characterizations.

1. Introduction

Circle graphs were introduced in [7] to solve a problem of queues and stacks
posed by Knuth in [11]. A graph G = (V, E) is a circle graph if it is the intersection
graph of a family L = {Cv }v∈V of chords on a circle (i.e., for each v, w ∈ V ,
vw ∈ E if and only if v 6= w and Cv ∩ Cw 6= ∅). L is called a circle model of
G. In [1; 8; 12], recognition algorithms based on the fact that circle graphs are
closed by split composition (cf. [4]) were presented. In [2], Bouchet proved that
a graph G is a circle graph if and only if each graph that is locally equivalent to
G contains none of 3 prescribed forbidden induced subgraphs. However, there are
not known characterizations of circle graphs by forbidden induced subgraph that
do not involve the notion of local equivalence. We present some results in this
direction, providing forbidden induced subgraph characterizations of circle graphs
1

Partially supported by ANPCyT PICT-2007-00518 and UBACyT X069 (Arg.).
Partially supported by ANPCyT PICT-2007-00533 and UBACyT X606 (Arg.).
3 Partially supported by FONDECyT Grant 1080286 and Millennium Science Institute
“Complex Engineering Systems” (Chile).
2

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Fig. 1. Some small graphs

restricted to graphs that belong to one of the following graph classes: linear domino,
{chair,triangle}-free, P4 -sparse, and tree-cographs.
The concept of Helly circle graph is due to Durán [6]. A graph belongs to
this class if it has a circle model whose chords are all different and satisfy the
Helly property. In [6], it is conjectured that a circle graph is a Helly circle graph if
and only if it is a diamond-free graph. This conjecture was recently affirmatively
settled affirmatively in [5]. Therefore, the Helly circle graph recognition problem
is solvable in polynomial time. Nevertheless, to best of our knowledge, there is no
characterization for the whole class of Helly circle graphs by forbidden induced
subgraphs. In this work we completely characterize unit Helly circle graphs, which
are those having a model whose chords have all the same length, are all different,
and satisfy the Helly property.

2. Characterizations
The local complement of a graph G = (V, E) with respect to a vertex u ∈ V is
the graph G ∗ u that arises from G by replacing the induced subgraph G[N(u)] by
its complement. Two graphs G and H are locally equivalent if and only if G arises
from H by a sequence of local complementations.
Theorem 1. ([2]) Let G be a graph. Then, G is a circle graph if and only if no
graph locally equivalent to G contains W5 , W7 or BW3 as induced subgraph.
As a consequence, we can prove the following result.
Theorem 2. Let G be a graph. If G is not a circle graph, then any graph H that
arises from G by edge subdivisions is not a circle graph.
Some small graphs to be referred in the sequel are depicted in Figure 1. A
triangle is a complete with 3 vertices. A P4 is a chordless path on 4 vertices.

282

A graph G is domino if all its vertices belong to at most two cliques. If each
of its edges belongs to at most one clique, then G is a linear domino graph. Linear
domino graphs coincide with {claw,diamond}-free graphs [10]. A prism is a graph
that consists of two disjoint triangles {a1 , a2 , a3 } and {b1 , b2 , b3 } linked by three
vertex-disjoint paths P1 , P2 , P3 , whose internal vertices have degree two and where
Pi links ai and bi for i = 1, 2, 3. The graph C6 is a prism where each path has just
one edge. By Theorem 1, C6 is not a circle graph. Besides, since every prism arises
from C6 by edge subdivision, Theorem 2 implies that prisms are not circle graphs.
Theorem 3. Let G be a linear domino graph. Then, G is a circle graph if and only
if G contains no induced prism.
The proof relies on the split decomposition of a graph into stars, completes and
prime graphs (cf. [4]) and the fact that circle graphs are closed by split composition
[1; 8].
Chudnovsky and Kapadia gave a polynomial-time algorithm to decide if a
graph contains a theta or a prism [3] (a theta is a graph arising from K2,3 by edge
subdivision). Theorem 3 and the existence of a polynomial-time algorithm for recognizing circle graphs imply an alternative polynomial-time algorithm to find a
theta or a prism in linear domino graphs, because a domino graph cannot contain a
theta.
Next, we characterize those {chair,triangle}-free graphs that are circle graphs.
Theorem 4. Let G be a {chair,triangle}-free graph. Then, G is a circle graph if
and only if G contains no induced BW3 .
Cographs are the graphs with no chordless paths on 4 vertices; i.e., P4 -free.
It is well known that cographs are circle graphs. P4 -sparse graphs are a natural
generalization of cographs. Hoàng [9] defined a graph to be P4 -sparse if every five
vertices induce at most one P4 . For any graph G, let G+ denote the graph that arises
from G by adding a universal vertex.
Theorem 5. Let G be a P4 -sparse graph. Then, G is a circle graph if and only if G
contains no induced net+ , no induced tent+ and no induced tent-with-center.
Tree-cographs are defined recursively as follows: trees are tree-cographs, the
disjoint union of tree-cographs is a tree-cograph, and if H is a tree-cograph, then
H is a tree-cograph.
Theorem 6. Let G be a tree-cograph. Then, G is a circle graph if and only if G
contains no induced (bipartite-claw)+ and no induced co-(bipartite-claw).
Our last result is a complete characterization of unit Helly circle graphs. Let Cn∗
denote the graph that arises from a chordless n-cycle by adding an isolated vertex.

283

Theorem 7. Let G be a graph. Then the following assertions are equivalent: (i) G
is a unit Helly circle graph; (ii) G contains no induced paw, no induced diamond
and no induced Cn∗ for any n ≥ 3; (iii) G is a chordless cycle, a complete graph, or
a disjoint union of chordless paths.
The proof is of geometric nature and relies on properties of tangent lines to a
circle.

References
[1] A. Bouchet. Reducing prime graphs and recognizing circle graphs. Combinatorica, 7, 243–254, 1987.
[2] A. Bouchet. Circle graphs obstructions. J. Combin. Theory Ser. B, 60, 107–
144, 1994.
[3] M. Chudnovsky and R. Kapadia. Detecting a theta or a prism. SIAM J. Discrete Math., 22, 1164–1186, 2008.
[4] W. H. Cunningham. Decomposition of directed graphs. SIAM J. Alg. Disc.
Meth., 3, 214–228, 1982.
[5] J. Daligault, D. Gonçalves, and M. Rao. Diamond-free circle graphs are Helly
circle. Manuscript, 2008.
[6] G. Durán. Some new results on circle graphs. Mat. Contemp., 25, 91–106,
2003.
[7] S. Even and A. Itai. Queues, stacks and graphs. In A. Kohavi and A. Paz, editors, Theory of Machines and Computations, pages 71–86. Academic Press,
New York, 1971.
[8] C. Gabor, K. Supowit, and W. Hsu. Recognizing circle graphs in polynomial
time. J. ACM, 36, 435–473, 1989.
[9] C. T. Hoàng. Perfect graphs. PhD thesis, School of Computer Science, McGill
University, Montreal, 1985.
[10] T. Kloks, D. Kratsch, and H. Müller. Dominoes. Lect. Notes Comput. Sci.,
93, 106–120, 1995.
[11] D. E. Knuth. The Art of Computer Programming, volume 1. Addison-Wesley,
Reading, MA, 1969.
[12] J. P. Spinrad. Recognition of circle graphs. J. Algorithms, 16, 264–282, 1994.

284

A Replacement Model
for a Scale-Free Property of Cliques
Takeya Shigezumi, a Yushi Uno, b Osamu Watanabe a
a Department

of Mathematical and Computing Sciences, Tokyo Institute of Technology,
Tokyo 152-8552, Japan
{Takeya.Shigezumi, watanabe}@is.titech.ac.jp

b Department

of Mathematics and Information Sciences, Graduate School of Science,
Osaka Prefecture University, Sakai 599-8531, Japan
uno@mi.s.osakafu-u.ac.jp

Key words: degree, isolated clique size, power-law, replacement model.

1. Introduction

It has been observed that many large graphs (networks) that express some real world
relationships possess certain characteristics such as power-law degree distributions,
large cluster coefficients, etc. Recently, Uno et al. [1] found another ‘scale-free’
property by investigating a graph from some real network. They observed that the
size distributions of ‘isolated cliques’, cliques that can be separated easily from the
other part, follows power-law. Furthermore, it keeps this property after contracting
every isolated clique to one vertex; that is, the clique structure of the graph has selfsimilarity. (Though a different type, some self-similarity has been also studied by
Song et al. [2].) In this paper we show a way to generate graphs with this recursive
clique structure. Our method is to expand an initial graph for a few times so that
the obtained graph has a recursive clique structure. One important point is that the
basic characteristics of the initial graph are kept through this expansion process.
Preliminaries: Consider any (sufficiently large) graph G and let us fix it in the
following explanation. We use V and E (or more specifically V (G) and E(G))
to denote its set of vertices and edges, respectively, and let n denote the number
of vertices in G. For a vertex v, let N(v) denote the set of its neighbor vertices,
namely, N(v) = {u | {u, v} ∈ E}, and for any U ⊂ V , we also use N(U) to
S
denote v∈U N(v). The degree of v is defined as deg(v) , |N(v)|. By “subgraph”
of G, we imply its induced subgraph.
Isolated Clique and Contraction: A subgraph of G is called clique if every pair of
vertices in this subgraph is adjacent. A clique C is called c-isolated if the number of
outgoing edges from V (C) to V \V (C) is less than or equal to c|V (C)|. Although
finding large cliques in the graph is intractable, finding isolated cliques is not so
hard. Furthermore, 1-isolated clique can be enumerated in linear time [3], and it is
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

investigated in [1]. Note that very few overlaps occur among 1-isolated cliques and
they are easy to be separated. Throughout this paper, we consider 1-isolated clique
and we simply call them isolated clique. We consider a process of contracting an
isolated clique of G into one vertex. We use C(G) to denote a graph obtained from
G by contracting all isolated cliques in G.
Power-law and Scale-free Property: The scale-freeness is considered as one of
the basic properties characterizing real world large graphs. We say that G is ‘scalefree’ if its degree distribution follows power-law, i.e., a distribution proportional to
k −γ for some constant γ. Let us make these notions more precise for our discussion. The degree distribution of G is a sequence {nk }k≥1 , where nk is the number
of vertices in G with degree k. Then we say that G’s degree distribution follows a
power-law if nk = Θ(k −γ ) for some γ, that is, there are some constants c1 and c2
such that c1 k −γ ≤ nk ≤ c2 k −γ for all k ≥ 1. The parameter γ is called a power-law
exponent. In this paper we extend this notion to isolated clique size distributions.
The isolated clique size distribution of G is a sequence {ms }s≥1, where ms is the
number of isolated cliques of s vertices. We say that G’s isolated clique size follows
power-law if the sequence {ms }s≥1 satisfies ms = Θ(s−γ ) for some γ.
Remark on constants. It does not make sense for discussing the above properties
for any fixed finite graph G. Thus, in this paper, we will consider a family of graphs
consisting of infinite number of graphs defined in a certain way and discuss powerlaw properties with constants c1 and c2 that are independent from k and the choice
of a graph in the family. Thus, when claiming for example that G’s degree distribution follows a power-law with some exponent γ, we formally imply that its degree
sequence {nk }k≥1 satisfies nk = Θ(k −γ ) under some fixed constants c1 and c2 for
all graphs in our assumed graph family.

Cluster Coefficient: Another basic property is on a cluster coefficient, a way to
measure the density of triangles in a given graph. For any vertex v, the following
ratio is called the cluster coefficient of v:
CC(v) = |{ {u, w} ∈ E | u, w ∈ N(v) }|

.

deg(v)
2



.

Then let CC(U) denote the average cluster coefficient of all vertices in U (i.e., the
arithmetic mean of CC(v) of all vertices v in U). We say that G has a large cluster
coefficient if CC(V (G)) is larger than some constant. (Here again the remark above
is applicable. By “constant” we mean some constant that works for all graphs in
our assumed graph family.) Note that the cluster coefficient is the probability that
any pair of two neighbors of some vertex have an edge (when such a pair is chosen
uniformly at random); thus, on a graph G with a large cluster coefficient, it is likely
that vertices adjacent to some vertex are also adjacent.

286

2. Model

We describe our model, that is, a way of defining graphs that possess self-similarity
as observed in [1]. We give a method for expanding a graph randomly; it is designed
so that a graph with our desired self-similarity is obtained with high probability by
applying this expansion some number of times to a given initial graph that is defined
by some other model. Our expansion method is simple. For each degree k ≥ 3, we
select each vertex v of degree k independently with probability pk , and then replace
it with a clique of size k, where each edge to a vertex u in N(v) is replaced with
an edge between u and one vertex vu in the clique (see Figure 1). We introduce one
parameter p and define the probability pk as follows:
pk =


 p/(k
 0,

− 1), if k ≥ 3, and
otherwise.

For any graph G, let E(G) denote a
graph obtained by applying this random expansion. Note that E(G) is a random variable. We consider graphs obtained by applying this random expansion t times. In
the following analysis, we fix one initial
Fig. 1. An expansion of a vertex of degraph that is taken from a certain graph
gree four.
family, and let G0 denote it. For example,
we may assume that G0 is generated by some known scale-free graph model. Then
for a given t, let Gt denote a graph obtained by applying E(·) for t times to G0 . In
order to simplify our discussion, we assume in this paper that G0 has no isolated
cliques. Throughout this paper, we assume that t is sufficiently large, but it is still
regarded as a constant. (Some results can be generalized for the non-constant case.)

3. Analysis
Fix G0 and consider randomly generated graphs Gi , 1 ≤ i ≤ t. We first show
that two basic properties characterizing real world large graphs are inherited in
G1 , . . . , Gt . That is, if G0 has a power-law degree distribution and/or has a large
cluster coefficient, then so does Gt with high probability.
First consider the degree distribution of Gt . For each k ≥ 1, let nk and Nkt denote
the number of degree k vertices in G0 and Gt , respectively. Then for any k ≥ 3, it
is easy to show the following. (Note that from our setting p1 = p2 = 0, the number
of vertices of degree 1 or 2 does not change by expansion.)
Theorem 3.1. E[Nkt ] = (1 + p)t nk , and for any δ (0 < δ < 1), we have

287

Pr[ |Nkt

−

E[Nkt ]|

>δ·

E[Nkt ] ]

−

< 2te

pδ 2 nk
12t2 (k−1)

.

Thus, if nk is large enough, we may assume that Nkt ’s concentration around its
expectation is high. Therefore, if nk follows power-law with exponent γ, then with
high probability Nkt also follows the power-law with the same exponent.
Next consider cluster coefficients. We analyze a cluster coefficient for vertices of
each degree k; that is, for each k ≥ 1, we let ΣCCik denote the sum of the cluster
coefficients of all degree k vertices in Gi , and we analyze this quantity. Then we
have the following bound for k ≥ 5. (For small degree k ≤ 4, a similar bound can
be shown by detail case analysis.)
Theorem 3.2. E[ ΣCCtk ] > αt ΣCC0k + 51 ((1 + p)t − αt )nk , where α = 1 −

p
.
k−1

From these bounds, we can derive a bound for the degree-wise cluster coefficient
by simply dividing ΣCCtk by Nkt . Recall here that E[Nkt ] = (1 + p)t nk and that
Nkt is close to this expectation with high probability if we can assume that nk is
large enough. Hence, for example, we can show for any k ≥ 5 that E[ CC(Vkt ) ] >
β t CC(Vk0 ) + (1 − β t )/5, where Vki is the set of vertices of degree k in Gi and
β = 1 − (p/(1 + p))(k/(k − 1)) ' 1 − p. Notice that the above bound is either close
to CC(Vk0 ) or larger than some constant, say, 1/5. Hence if the original degree-wise
cluster coefficient CC(Vk0 ) is large, then CC(Vkt ) is also large (provided nk is large).
On the other hand, if nk is small for supporting some reasonable concentration on
Nkt , then the influence of vertices in Vk in CC(V (Gt )) can be ignored. Therefore,
we can conclude that E[CC(V (Gt ))] is either close to CC(V (G0 )) or larger than
some constant.
Next consider an isolated clique size distribution. Let Msi be the number of isolated
cliques of size s in Gi . Again this is a random variable except for Ms0 , which was
assumed to be 0 (i.e., no isolated cliques in G0 ). Then for any s ≥ 3, we can show
the following bounds.
Theorem 3.3. (1 + p)t−1 pns /s < E[Mst ] < (1 + p)t ns /s.
Thus (regarding p and t as constants) we can conclude that if {nk }k≥1 follows
power-law with some exponent γ, then on average {Mst }s≥1 follows power-law
with exponent γ + 1. That is, Gt has a large cluster coefficient if G0 ’s degree distribution follows power-law. A concentration result similar to the one for Nkt can be
also shown.
Finally consider the self-similarity or recursive structure of Gt . We would like to
see, e.g., whether Gt keeps a similar isolated clique size distribution after contracting it several times. For any j ≥ 0, let H j be the graph obtained from Gt
by applying the contraction C(·) for j times. That is, H 0 = Gt , H 1 = C(H 0 ),
H 2 = C(H 1 ), . . ., and so on. It should be noted here that the contraction C(·) is
not the inverse of our expansion E(·) in general. Thus, H 1 = Gt−1 does not hold
in general, and it is not at all trivial that H j has a similar clique size distribution.

288

Nevertheless, for the number Csj of cliques of size s in H j , we can show that the
following bound for any s ≥ 3, which supports that H j keeps a similar clique
distribution on s.
Theorem 3.4. E[Csj ] > (1 − e−p )j E[Mst−j ] > (1 − e−p )j (1 + p)t−j−1 pns /s.
References
[1] Y. Uno, T. Kiyotani and F. Oguri, Investigating web structure by cliques and
stars, RIMS Technical Report, to appear.
[2] C. Song, S. Havlin and H.A. Makse, Self-similarity of complex networks, in
Nature, 433, 392–395, 2005.
[3] H. Ito, K. Iwama and T. Osumi, Linear-time enumeration of isolated cliques,
in Proc. ESA, LNCS 3669, 119–130, 2005.

289

Graph Theory IV

Lecture Hall A

Thu 4, 10:30–12:30

Combinatorial optimization problems with conflict
graphs
Andreas Darmann, a Ulrich Pferschy, b Joachim Schauer, b
Gerhard J. Woeginger c
a University

of Graz, Institute of Public Economics, Universitaetsstr. 15, A-8010 Graz,
Austria
andreas.darmann@uni-graz.at

b University

c Eindhoven

of Graz, Department of Statistics and Operations Research,
Universitaetsstr. 15, A-8010 Graz, Austria
{pferschy, joachim.schauer}@uni-graz.at

University of Technology, Department of Mathematics and Computer Science,
P.O. Box 513, 5600 MB Eindhoven, The Netherlands
gwoegi@win.tue.nl

Key words: knapsack problem, minimum spanning tree, conflict graph

1. Introduction

Conflict graphs impose disjunctive constraints for pairs of jobs, items, edges
or other objects in a combinatorial optimization problem. Equivalently, the feasible
domain of the considered problem is restricted to stable sets in the given conflict
graph. After reviewing in our presentation results from the literature for bin packing and scheduling problems with conflict graphs, we first consider the classical 0-1
knapsack problem. Adding a conflict graph makes the problem strongly NP-hard
but for three special graph classes, namely trees, graphs with bounded treewidth and
chordal graphs, we can develop pseudopolynomial algorithms. From these we can
easily derive fully polynomial time approximation schemes (FPTAS). Secondly, we
study the minimum spanning tree problem and show that the border between polynomially solvable and NP-hard is given by moving from a conflict graph containing
only isolated edges to paths of length 2.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. The Knapsack Problem with Conflict Graphs

For a formal definition of the knapsack problem with conflict graph (KCG), let
n be the number of items, each of them with profit pj and weight wj , j = 1, . . . , n,
and c the capacity of the knapsack. Let G = (V, E) with |V | = n be a conflict
graph, where the vertices uniquely correspond to the items of the knapsack. G is
not necessarily connected and may therefore contain isolated vertices.
Then KCG is determined by the following ILP formulation:
(KCG)

max
s.t.

n
X

j=1
n
X

j=1

pj xj

(2.1)

wj xj ≤ c

(2.2)

xi + xj ≤ 1 ∀ (i, j) ∈ E
xj ∈ {0, 1} j = 1, . . . , n.

(2.3)
(2.4)

From a graph theoretical perspective, KCG can also be seen as a generalization
of the independent set problem. For every given instance of the independent set
problem we can superimpose an instance of KCG by introducing trivial items for
every vertex with profit and weight equal to 1 and capacity c = n. Therefore it
follows immediately, that KCG for general graphs is strongly NP-hard (cf. [4]) and
does not permit pseudo-polynomial algorithms (under P 6= NP ). Motivated by
this complexity status and our main task is to identify graph classes for which we
can prove the existence of a pseudo-polynomial time and space algorithm and use
them to attain fully polynomial time approximation schemes (FPTAS).
For trees as conflict graphs we introduce a dynamic programming algorithm
P
that solves KCG in O(nP 2 ) time using O(log(n)P + n) space where P = ni=1 pi .
If we consider any vertex i ∈ T , by the property of trees as conflict graphs, when
including i into the knapsack solution, it is not allowed to include the parent vertex
p of i as well as any of the k child vertices c1 . . . ck of i. Indeed these vertices are
the only vertices in T that are in conflict with i. The main idea of our algorithm is
to process T in depth-first order starting at some root vertex r.
For graphs of bounded treewidth as conflict graphs (including series-parallel
graphs, outerplanar graphs, Halin graphs... ([2])), we derive a dynamic programming algorithm solving KCG with a conflict graph of bounded treewidth k in
O(nP 2) time using O(log(n)P + n) space. For algorithmic purposes, the structure of the decomposition is restricted to four simple configurations corresponding
to a nice tree decomposition, which can be be computed from a tree-decomposition
in O(n) time (cf. [3]) .

294

For every chordal graph G (graphs that do not contain induced cycles other
than triangles) there exists a clique tree T = (K, E), where the maximal cliques K
of G are vertices of T and for each vertex v ∈ G all cliques K containing v induce
a subtree in T . The basic idea for treating chordal graphs lies in utilizing special
separation properties of the clique-tree of a chordal graph along with the fact that
from every maximal clique of G at most one vertex can be added to the knapsack solution. The three relevant separation properties can be found with detailed
proofs in [1]. Our algorithm can be implemented to run in O((n + m)P 2 ) time and
O(min {m, n log n} ∗ P + m) space where m denotes the number of edges of G.
All the algorithms mentioned above do admit FPTASs by scaling the profit
space in a standard way (see e.g. [5]). In fact, the correctness of this scaling procedure depends only on the cardinality of the solution set, which is trivially bounded
by n. The running time complexities of the resulting FPTASs differ from the above
2
bounds in the following way: every occurrence of the factor P is replaced by n for
the scaled instances and thus the required complexity of an FPTAS is attained.

3. Minimum Spanning Trees with Conflict Graphs (MST CG)
In this part of our presentation we consider an extension of the minimum
spanning tree problem. In addition to the well studied problem of finding a minimum spanning tree in an undirected connected graph G = (V, E) with weight
function w, there exist incompatibilities for certain pairs of edges. These symmetric conflict relations are represented by means of an undirected conflict graph
Ḡ = (E, Ē), where every vertex of Ḡ corresponds uniquely to an edge e ∈ E and
edges ē = (i, j) ∈ Ē imply that the two vertices adjacent to ē cannot occur together
in a solution.
First we show that MST CG is already NP-hard for an easy subclass of all
possible conflict graphs, namely for conflict graphs Ḡ consisting of components
that are described by three vertices (w.l.o.g. e1 , e2 and e3 ) which are connected by
two edges (w.l.o.g. (e1 , e2 ) and (e2 , e3 )). We call such graphs Ḡ 3-ladder. In terms
of the underlying graph G this means that in a feasible spanning tree including
e1 the edges e2 and e3 are necessarily excluded. Obviously this result implies that
MSTCG is already NP-hard on paths as conflict graphs. The stated result is then
shown by reducing a special variant of 3 − SAT to MST CG.
On the other hand we also show that MST CG is easy for disjunctive conflicting pairs of edges (we call them ladder). This is done by showing that the conflicting structure imposed by a ladder is a matroid. Then by the matroid intersection
theorem of Edmonds (cf. [7]) by intersecting the above matroid and the graphic
matroid, which describes the minimum spanning trees, the desired result follows.

295

4. Concluding remarks

After considering chordal graphs the natural next step would be the more general class of perfect graphs. This question however can be settled by a result due
to Milanič and Monnot [6]. There it was shown the exact weighted independent set
problem (EWIS) for perfect graphs is strongly NP-complete. But this problem can
be reduced to KCG. Furthermore, motivated by the result for minimum spanning
trees, it seems worthwile to consider other classical combinatorial optimization
problems that do admit polynomial algorithms and combine them with additional
constraints, imposed by a conflict graph.

References
[1] J. R. S. Blair and B. Peyton. An introduction to chordal graphs and clique trees.
In A. George, J. R. Gilbert, and J. H. U. Liu, editors, Graph Theory and Sparse
Matrix Computations, pages 1–29, New York, 1993. Springer.
[2] H. L. Bodlaender. A tourist guide through treewidth. Acta Cybernetica, 11:1–
21, 1993.
[3] H. L. Bodlaender and A. M. C. A. Koster. Combinatorial optimization on
graphs of bounded treewidth. The Computer Journal, 51(3):255–269, 2008.
[4] M. C. Golumbic. Algorithmic Graph Theory and Perfect Graphs (Annals of
Discrete Mathematics, Vol 57). North-Holland Publishing Co., Amsterdam,
The Netherlands, 2004.
[5] H. Kellerer, U. Pferschy, and D. Pisinger. Knapsack Problems. Springer, 2004.
[6] M. Milanič and J. Monnot. Combinatorial Optimization - Theoretical Computer Science : interfaces and Perspectives, chapter The complexity of the exact weighted independent set problem, pages 393–432. Wiley-ISTE, 2008.
[7] A. Schrijver. Combinatorial Optimization, Polyhedra and efficiency, volume B.
Springer, 2003.

296

On the decomposition of graphs into offensive
k-alliances
José M. Sigarreta, a Ismael G. Yero, b Sergio Bermudo, c
Juan A. Rodrı́guez-Velázquez b
a Faculty

of Mathematics, Autonomous University of Guerrero, Carlos E. Adame 5, Col.
La Garita, Acapulco, Guerrero, México

b Department

c Department

of Computer Engineering and Mathematics, Rovira i Virgili University, Av.
Paı̈sos Catalans 26, 43007 Tarragona, Spain
ismael.gonzalez@urv.cat

of Economy, Quantitative Methods and Economic History, Pablo de Olavide
University, Carretera de Utrera Km. 1, 41013-Sevilla, Spain

Abstract
The (global) offensive k-alliance partition number of a graph Γ = (V, E), denoted by
(ψkgo (Γ)) ψko (Γ), is defined to be the maximum number of sets in a partition of V such that
each set is an offensive (a global offensive) k-alliance. We obtain tight bounds on ψko (Γ) and
ψkgo (Γ) in terms of several parameter of the graph. As a consequence of the study we show
the close relationships that exist among the chromatic number of Γ and ψ0go (Γ). Moreover,
we study the particular case of partitioning the vertex set of the cartesian product of graphs
into (global) offensive k-alliances.
Key words: Offensive alliances, chromatic number, cartesian product of graphs

1. Introduction
Since (defensive, offensive and powerful) alliances in graph were first introduced by P. Kristiansen, S. M. Hedetniemi and S. T. Hedetniemi [5], several authors have studied their mathematical properties [1; 2; 3; 4; 5; 6; 7]. We focus
our attention in the problem of partitioning the vertex set of a graph into (global)
offensive k-alliances. This problem have been previously studied, for the case of
defensive k-alliances, by K. H. Shafique and R. D. Dutton [6; 7] and the particular case k = −1 have been studied by L. Eroh and R. Gera [2; 3] and by T. W.
Haynes and J. A. Lachniet [4]. We begin by stating the terminology used. Throughout this article, Γ = (V, E) denotes a simple graph of order |V | = n and size
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

|E| = m. We denote the degree of a vertex v ∈ V by δ(v), the minimum degree
by δ and the maximum degree by ∆. For a nonempty set X ⊆ V , and a vertex
v ∈ V , NX (v) denotes the set of neighbors v has in X and the degree of v in X
will be denoted by δX (v) = |NX (v)|. The complement of the set S in V will be
S
denoted by S̄, moreover, the boundary of S is defined as ∂(S) := v∈S NS (v).
For k ∈ {2 − ∆, ..., ∆}, a nonempty set S ⊆ V is an offensive k-alliance in Γ
if δS (v) ≥ δS (v) + k, ∀v ∈ ∂(S). An offensive k-alliance S is called global
if it is a dominating set. The (global) offensive k-alliance number of Γ, denoted
by (γko (Γ)) aok (Γ), is defined as the minimum cardinality of any (global) offensive
k-alliance in Γ. We denote by (ψkgo (Γ)) ψko (Γ) the maximum number of sets in a
partition of V such that each set is an offensive k-alliance. Notice that if every vertex of Γ has even degree and k is odd, then every offensive k-alliance in Γ is an
offensive (k + 1)-alliance and vice versa. Hence, in such a case, aok (Γ) = aok+1 (Γ),
go
o
o
γko (Γ) = γk+1
(Γ), ψko (Γ) = ψk+1
(Γ) and ψkgo (Γ) = ψk+1
(Γ). Analogously, if every
vertex of Γ has odd degree and k is even, then every offensive k-alliance in Γ is an
offensive (k + 1)-alliance and vice versa. Hence, in such a case, aok (Γ) = aok+1 (Γ),
go
o
o
γko (Γ) = γk+1
(Γ), ψko (Γ) = ψk+1
(Γ) and ψkgo (Γ) = ψk+1
(Γ). We say that a graph Γ
go
is partitionable into (global) offensive k-alliances if (ψk (Γ) ≥ 2) ψko (Γ) ≥ 2.
2. Results
Proposition 1. For any graph Γ without isolated vertices, there exists k ∈
{0, ..., δ} such that Γ is partitionable into global offensive k-alliances.
Corollary 2. Any graph without isolated vertices is partitionable into global offensive 0-alliances.
Theorem 3. If a graph is partitionable into r ≥ 3 global offensive k-alliances, then
k ≤ 3 − r.
From Theorem 3 we have that if a graph is partitionable into r ≥ 3 global
offensive k-alliances, then k ≤ 0, so we obtain the following interesting consequence.
Corollary 4. If Γ is partitionable into global offensive k-alliances for k ≥ 1, then
ψkgo (Γ) = 2.
From Corollary 2 we have that any graph without isolated vertices is partitionable into global offensive 0-alliances. Therefore, the above result leads to the
following consequence.
Corollary 5. For any graph without isolated vertices, 2 ≤ ψ0go (Γ) ≤ 3.
An example of graph where ψ0go (Γ) = 2 is the complete graph and an example
of graph where ψ0go (Γ) = 3 is the cycle graph C3t , t ≥ 1.

298

Now we are going to show the relationship that exists among the chromatic
number of Γ, χ(Γ), and ψ0go (Γ).
Theorem 6. Any set belonging to a partition of a graph into r ≥ 3 global offensive
k-alliances is a (−k)-dependent set.
Corollary 7. If ψ0go (Γ) = 3, then χ(Γ) ≤ 3.
A trivial example where ψ0go (Γ) = 3 = χ(Γ) is the cycle graph Γ = C3 . In the
case of the cycle graph Γ = C6 it is satisfied ψ0go (Γ) = 3 and χ(Γ) = 2.
Remark 2.1. If Γ is a non bipartite graph and ψ0go (Γ) = 3, then χ(Γ) = 3.
An example of graph where χ(Γ) > 3 and ψ0go (Γ) = 2 is the complete graph
Γ = Kn , with n ≥ 4.
Corollary 8. For any graph Γ without isolated vertices and chromatic number
greater than 3, ψ0go (Γ) = 2.
Theorem 9. For any graph Γ without isolated vertices containing a vertex of odd
degree, ψ0go (Γ) = 2.
Theorem 10.
If a graph
j
k Γ is partitionable into global offensive k-alliances, then
go
2m−n(k−4)
ψk (Γ) ≤
.
2n
The above bound is attained, for instance, for the cycle graph C3t , where
= 3.

ψ0go (C3t )

go
Theorem 11. Let C(r,k)
(Γ) be the minimum number of edges having its endpoints
in different lsets of a partition
of Γ into r ≥ 2 global offensive jk-alliances, then
m
k
go
go
(r−1)(2m+nk)
(r−1)(2m−nk)
C(r,k) (Γ) ≥
.
Moreover,
if
r
≥
3,
then
C
(Γ)
≤
.
(r,k)
4
4(r−2)

From the above result we have that if ψkgo (Γ) ≥ 3, then ψkgo (Γ) ≤

Notice also that, for k ≤ δ, 2 ≤

j

6m+nk
2m+nk

k

j

6m+nk
2m+nk

, so we obtain the following bound.

Corollary 12. For any graph Γ of order n and size m, ψkgo (Γ) ≤

j

6m+nk
2m+nk

k

.

k

.

The above bound is attained, for instance, for the cycle graph Γ = C3t , where
= 3.

ψ0go (Γ)

Theorem 13. [1] Let Γi = (Vi , Ei ) be a graph of minimum degree δi and maximum
degree ∆i , i ∈ {1, 2}. If Si is an offensive ki -alliance in Γi , i ∈ {1, 2}, then, for
k = min{k2 − ∆1 , k1 − ∆2 }, S1 × S2 is an offensive k-alliance in Γ1 × Γ2 .
From the above result we deduce that, a partition Πi of Γi into ri offensive kialliances, i ∈ {1, 2}, induces a partition of Γ1 × Γ2 into r1 r2 offensive k-alliances,
299

with k = min{k2 − ∆1 , k1 − ∆2 }. So, we obtain the following result.
Corollary 14. For any graph Γi of order ni and maximum degree ∆i , i ∈ {1, 2},
and for every k ≤ min{k1 − ∆2 , k2 − ∆1 }, ψko (Γ1 × Γ2 ) ≥ ψko1 (Γ1 )ψko2 (Γ2 ).
o
Example of equality in the above result is ψ−3
(C4 ×K4 ) = 4 = ψ0o (C4 )ψ1o (K4 ).

Theorem 15. Let Γi = (Vi , Ei ) be a graph of order ni and let Πi be a partition of Γi
into ri global offensive ki -alliances, i ∈ {1, 2}. If xi = min {|X|}, yi = max {|X|}
X∈Πi

X∈Πi

and k ≤ min{k1 , k2}. Then γko (Γ1 × Γ2 ) ≤ min{n2 x1 , n1 x2 }, and ψkgo (Γ1 × Γ2 ) ≥
max{ψkgo1 (Γ1 ), ψkgo2 (Γ2 )}.

Corollary 16. If a graph Γi of order ni is partitionable into global offensive kialliances, i ∈ {1, 2}, then for k ≤ min{k1 , k2 },
γkgo (Γ1 × Γ2 ) ≤

n1 n2
.
max {ψkgoi (Γi )}

i∈{1,2}

Example of equality is γ1o (C4 × K2 ) =

4·2
max{ψ1go (C4 ),ψ1go (K2 )}

= 4.

Acknowledgments: This work was partly supported by the Spanish Ministry
of Science and Innovation through projects TSI2007-65406-C03-01 “E-AEGIS”,
CONSOLIDER INGENIO 2010 CSD2007-0004 ”ARES”.
References
[1] S. Bermudo, J. A. Rodrı́guez-Velázquez, J. M. Sigarreta and I. G. Yero, On
global offensive k-alliances in graphs. Submitted.
[2] L. Eroh, R. Gera, Global alliance partition in trees. J. Combin. Math. Combin.
Comput. 66 (2008) 161-169.
[3] L. Eroh, R. Gera, Alliance partition number in graphs. Accepted.
[4] T. W. Haynes and J. A. Lachniet, The alliance partition number of grid graphs.
AKCE Int. J. Graphs Comb. 4 (1) (2007) 51-59.
[5] P. Kristiansen, S. M. Hedetniemi and S. T. Hedetniemi, Alliances in graphs.
J. Combin. Math. Combin. Comput. 48 (2004) 157-177.
[6] K. H. Shafique, Partitioning a Graph in Alliances and its Application to Data
Clustering. Ph. D. Thesis, 2004.
[7] K. H. Shafique and R. D. Dutton, On satisfactory partitioning of graphs.
Congr. Numer. 154 (2002) 183-194.

300

Increasing the Edge Connectivity by One in
O(λGn2 log(∗) n) Expected Time
Michael Brinkmeier
Technische Universaität Ilmenau
Faculty of Computer Science and Automation
Institute for Theoretical Computer Science
mbrinkme@tu-ilmenau.de

Key words: Undirected graphs, edge connectivity, minimum cut, polynomial time
algorithm, edge connectivity augmentation, extreme set, maximum adjacency order

In some situations an undirected multigraph has to be ‘enriched’ by a minimum
number of additional edges, such that there exists at least a given number k of edgedisjoint paths between every pair of vertices. Due to the duality of maximum flows
and minimum cuts, this corresponds to the increase of the edge connectivity to the
target value k by a minimum number of additional edges. Finding this minimum
k-augmenting set of additional edges is called the edge connectivity augmentation
problem (ECA). In this paper we will concentrate on the case k = λG + 1, ie. the
problem of edge connectivity augmentation by one (ECA1).
Several strongly and pseudo-polynomial algorithms for ECA are known up
to date. Basically these can be split into two groups. The algorithms of the first
type use the process of edge splitting. Based on the results of Cai and Sun [3],
Frank [5] described such a strongly polynomial algorithm requiring time O(n5 ) on
2
2
a graph with n vertices and m edges. Gabow [8]
 obtained O (n m log
 (n /m))).
Nagamochi and Ibaraki [13; 14] described an O nm log n + n2 log2 n algorithm.
The other group of algorithms does not use edge splitting explicitly. Many of
them iteratively solve ECA1, ie. they increase the edge connectivity of the graph
one by one. This approach usually results in pseudo-polynomial runtimes, which
depend on the number of necessary steps, ie. the difference k−λG . One of the eldest
is described in [15] and requires O(kLn4 (kn + m)) time with L = min{k, n}.
Naor, Gusfield and Martel [12] described an O(δ 2 nm+δ 3 n2 +n·M(G)) algorithm,
where δ is the number of required steps and M(G) the time required by a maximum
flow algorithm on the graph G. In [6; 7] Gabow describes an algorithm requiring
O(m + k 2 n log n) time for simple graphs.
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Benczúr and Karger [1] describe a nondeterministic algorithm mixing both approaches. They use a probabilistic algorithm for the construction of all extreme sets
as defined in [15] of vertices and then use these to implicitly construct an edge
splitting, increasing the edge connectivity to k − 1. For the last step they suggest
a cactus based ∗ algorithm, like those in [12] or [9]. The resulting algorithm constructs a minimum k-augmenting set in time O(n2 log5 n) with high probability. In
[10; 11] Nagamochi describes an algorithm, which allows the deterministic computation of all extreme sets in an undirected, weighted graph in O(mn + n2 log n)
time, resulting in an algorithm for ECA in the fashion of Benczúr and Karger, requiring O(mn + n2 log n) time and O(m + n) space.
In this paper we present a new algorithm for the solution of ECA1. We show
that its runtime is bounded by O(λG n2 log n) and that its expected runtime is
O(λG n2 log(∗) n). Furthermore, due to a quite conservative estimation, the average
runtime of the algorithm may be significantly lower. The algorithm may either be
used to solve ECA iteratively, or as the last step in Benczúr and Karger’s algorithm,
avoiding the construction of the cactus.
We assume, that the edge connectivity λG of the underlying integer weighted
graph is already known (see eg. [2]). Our algorithm consists of two main components. The first component is an algorithm for the computation of all λG -extreme
sets, which are the minmal minimum cuts of G. As we show, this can be achieved
in time O(λG n2 ) by using Lax-Adjacency Orders as introduced in [2].
It is a simple observation, that the increase of the edge connectivity by one,
requires that for every λG -extreme at least one new edge has to leave it. This leads
to a lower bound of d 2l e for the number of required additional edges, where l is
the number of λG -extreme sets. As proven in [5], this lower bound is in fact the
minimum number of edges required to solve ECA1. In other words, an optimal
solution consists of b 2l c disjoint pairs of λG -extreme sets and edges between the two
components of each pair. If l is odd, then one additional edge leaving the remaining
set has to be added.
Due to the minimality of the λG -extreme sets and the fact that the intersection
of two minimum cuts is again a minimum cut, every minimum cut contains at least
on λG -extreme set. We call a pair (X, Y ) of λG -extreme sets illegal, if there exists
a minimum cut Z, that contains X and Y and no other λG -extreme set. In this
situation the addition of an edge between X and Y would require that an additional
edge leaves Z, implying that the pair cannot be part of an optimal solution.
Basically our algorithm chooses an arbitrary pairing of the λG -extreme sets
and then detects illegal pairs by constructing all λG -extreme sets in the graph, in
which edges between the pairs were added. The edges induced by legal pairs remain
∗

Cactus-based means that the algorithm requires the construction of the cactus representation of all minimum cuts in the multigraph G, as described in [4; 6]

302

in the solution, while the illegal pairs are split again, and the process is repeated
until no illegal pair was found.
As we observed, each λG -extreme set can be a member of at most two illegal pairs. If known illegal pairs are avoided in subsequent rounds, it can be
shown that at most O(log n) rounds are required, leading to a total runtime of
O(λg n2 log n). A more thorough analysis reveals, that a random choice of the pairings is expected to require only O(log(∗) n) rounds, leading to an expected runtime
of O(λG n2 log(∗) n).
References
[1] András A. Benczúr and David R. Karger. Augmenting undirected edge connectivity in õ(n2 ) time. J. Algorithms, 37(1):2–36, 2000.
[2] Michael Brinkmeier. A simple and fast min-cut algorithm. Theory of Computing Systems, 41:369–380, 2007.
[3] Guo-Ray Cai and Yu-Geng Sun. The minimum augmentation of any graph to
a k-edge-connected graph. Networks, 19:151–172, 1989.
[4] E.A. Dinic, A.V. Karzanov, and M.V. Lomonosov. On the structure of a family
of minimal weighted cuts in a graph. Studies in Discrete Optimization, pages
290–306, 1976.
[5] András Frank. Augmenting graphs to meet edge-connectivity requirements.
SIAM J. Discrete Math., 5(1):25–53, 1992.
[6] Harold N. Gabow. Applications of a poset representation to edge connectivity
and graph rigidity. In FOCS, pages 812–821. IEEE, 1991.
[7] Harold N. Gabow. Applications of a poset representation to edge connectivity
and graph rigidity. Technical Report CU-CS-545-91, University of Colorado,
1991.
[8] Harold N. Gabow. Efficient splitting off algorithms for graphs. In STOC,
pages 696–705, 1994.
[9] David R. Karger and Clifford Stein. A new approach to the minimum cut
problem. J. ACM, 43(4):601–640, 1996.
[10] Hiroshi Nagamochi. Computing extreme sets in graphs and its applications.
In Proceedings of the 3rd Hungarian-Japanese Symp. on Disc. Math. and Its
Appl., pages 349–357, Tokyo, 2003.
[11] Hiroshi Nagamochi. Graph algorithms for network connectivity problems.
Journal of the Operations Research Society of Japan, 47(4):199–223, 2004.
[12] Dalit Naor, Dan Gusfield, and Charles U. Martel. A fast algorithm for optimally increasing the edge-connectivity. In FOCS, volume II, pages 698–707.
IEEE, 1990.
[13] Hiroshi Nagamochi and Toshihide Ibaraki. Deterministic Õ(nm) time edge-

303

splitting in undirected graphs. In STOC, pages 64–73, 1996.
[14] Hiroshi Nagamochi and Toshihide Ibaraki. Graph connectivity and its augmentation: applications of MA orderings. Discrete Applied Mathematics,
123(1-3):447–472, 2002.
[15] Toshimasa Watanabe and Akira Nakamura. Edge-connectivity augmentation
problems. J. Comput. Syst. Sci., 35(1):96–144, 1987.

304

Enumerating all finite sets of minimal prime
extensions of graphs
V. Giakoumakis, a C.B. Ould El Mounir

a

a MIS,

Université d’Amiens, France
Vassilis.Giakoumakis@u-picardie.fr

Abstract
In [2] V. Giakoumakis and S. Olariu characterized all classes of graphs whose set of minimal prime extensions is finite. In this extended abstract we propose an efficient algorithm
that enumerates all minimal prime extensions of these classes of graphs.
Key words: modules in graphs, modular decomposition, minimal prime, extension,
enumeration algorithm.

1. Motivation, notation and terminology

For terms not defined here the reader is refered to [1]. All considered graphs
are finite, without loops nor multiple edges. Let G be a graph, the set of its vertices
will be noted by V (G) while the set of its edges will be noted by E(G). An edgeless
(resp. complete) graph of n vertices is denoted On (resp. Kn ) while [W ] will denote
the subgraph of G induced by W ⊆ V (G). A chordless path (or chain) of k vertices
will be denoted Pk and a chordless cycle of k vertices wil be denoted by Ck . A bull
is a graph formed from a P4 and a vertex x which is adjacent to the middle vertices
and misses the two extremities of this P4 . The vertex x will be called the top vertex
of the bull. A diamond (resp. paw) is a graph formed from a P3 (resp. a P3 ) and a
universal vertex with respect to the set of vertices of this P3 (resp. P3 ). A set M ⊆
V (G) is called a module if every vertex of G outside M is adjacent to all vertices of
M or to none of them. The empty set, V (G) and the singletons are trivial modules
and whenever G has only trivial modules is called prime or indecomposable. A non
trivial module M is also called homogeneous set. The graph G0 is a minimal prime
extension of G if G0 is prime, it contains an induced subgraph isomorphic to G and
is minimal with respect to set inclusion and primality. Ext(G) will denote the set
of minimal prime extensions of G. It is well known that Ext(G) is not necessarily
a finite set.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Finding characterizations of the set of minimal prime extensions of classes of
graphs could lead to efficient optimization algorithms (see in [2] for details) and
this has motivated many researching works in this direction. In ([4]) is proved that
if G is a P4 - homogeneous graph (i.e. every non trivial module of G induces a
subgraph of a P4 ) then Ext(G) is a finite set.
The open problem of giving necessary and sufficient conditions for the finiteness of Ext(G) was recently solved in [2] where it is proved that Ext(G) is a finite
set iff G is either a P4 - homogeneous graph or a 2P4 - homogeneous graph whose
definition is given below:
Definition 1.1 Let G be a connected graph which is not P4 -homogeneous such
that G contains exactly two connected components C1 and C2 . Then, G and G are
said to be 2P4 - homogeneous graphs if [C1 ] and [C2 ] are subgraphs of a chordless
chain and one of the following conditions holds:
• [C1 ] is a singleton and G0 = G \ u is a P4 - homogeneous graph
• [C1 ] is isomorphic to a P1 ∪ P3 or to a P1 ∪ P4 or to an O3 or to an O2 ∪ P2
and [C2 ] is isomorphic to a P4 , P 3 or a P 2 .
Using as framework the theoretical results in [2] and [4] we present in this abstract
an efficient and easily programming method which enumerates the set of all minimal prime extensions in the finite case. In this way we unify also several previous
researching works where this set is obtained by examining separately each particular case of the graphs under consideration.

2. Enumeration of Ext(G) for a P4 -homogeneous graph G
We shall first give the structure of the modular decomposition tree T (G) of a
P4 -homogeneous graph G. We shall classify G in to 3 classes as follows:
Definition 2.1. Let G be a connected P4 −homogeneous graph, let T (G) be its
corresponding modular decomposition tree and let r(T ) be the root of T . Then
(i) G is of type 1 if r(T ) is an N-node and the subgraph of G corresponding to
each son of r(T ) is isomorphic to a subgraph of a P4
(ii) G is of type 2 if r(T ) is an S-node having two sons and the subgraph of G
corresponding to each son of r(T ) is isomorphic to either a P4 or to a P3 or to
P2 or to a P1 .
(iii) G is of type 3 if G is isomorphic to a C3 or to a diamond or to a paw.
Theorem 2.2 Let G be a connected graph and let T (G) be its corresponding

306

modular decomposition tree. If G is P4 -homogeneous then G is of type 1, 2 or 3.
We recall that since the construction of the modular decomposition tree of a
graph can be obtained in linear time on the size this graph (see [1]), Theorem 2.2
implies that the recognition of a P4 -homogeneous graph G can be obtained in linear
time on the size of G. The modular decomposition tree of a P4 -homogeneous graph
will be used in the enumeration algorithm presented below. Before, we give some
definitions and we recall some known results.
Definition 2.3 ([3]) Let G be an induced subgraph of a graph H, and let W be a
homogeneous set of G. We define a W -pseudopath in H as a sequence
R = (u1 , u2 , ..., ut ), t ≥ 1, of pairwise distinct vertices of V (H) \ V (G) satisfying
the following conditions:
(i) u1 is partial with respect to W .
(ii) ∀ i = 2, ..., t either ui est adjacent to ui−1 and indifferent with respect to
W ∪ {u1, ..., ui−2 } or ui is total with respect to W ∪ {u1 , ..., ui−2} and not
adjacent to ui−1 ( when i = 2 , {u1 , u2 , ..., ut } = ).
(iii) ∀ i = 2, ..., t − 1, ui is total with respect to N(W ) and indifferent with respect
to V (G) − N(W ) and either ut is not adjacent to a vertex of N(W ) or ut is
adjacent to a vertex of V (G) − N(W ).
From ([3]) we know that for every homogeneous set W of a graph G there is a
W -pseudopath with respect to any induced copy of G in Ext(G).
Definition 2.4 Let W be a non trivial module of a graph G and let x be a partial
vertex with respect to W . We shall say that x is a strong partial vertex for W if W
does not contain an homogeneous set in the graph induced by V (G) ∪ {x}. If x is
the first vertex of a W -pseudopath P , P will be called a strong pseudopath.
Definition 2.5 A graph G will be called (P4 , bull)-homogeneous graph if every
homogeneous set of G induces either a subgraph of a P4 or is isomorphic to a bull.
From ([4]) we know that for every homogeneous set W of a P4 -homogeneous
graph G there is in Ext(G) a strong W -pseudopath P = x1 or a pseudopath P =
x1 , x2 . The latter case occurs whenever [W ∪ {x1 }] is isomorphic to a bull and
W ∪ {x1 } forms a non trivial module in the graph induced by V (G) ∪ {x1 }. In this
case x2 is a strong W ∪ {x1 }-pseudopath such that x2 either is only adjacent to the
top vertex x1 of [W ∪ x1 ] and misses all vertices of W or x2 is not adjacent to x1
and is total with respect to W .
We are now in position to present our enumeration algorithm. We shall enumerate
the set of minimal prime extensions of a connected P4 -homogeneous graph G of
type 1 or 2. A graph G of type 3 is a particular case of a P4 -homogeneous graphs
and Ext(G) is already known by previous researching works. Although we could

307

adapt our algorithm in order to enumerate also Ext(G) in this case, we prefer to
invite the reader to see [2] for the related references. Finally, whenever G is
disconnected, the set of minimal prime extensions H of G will be the set of the
complementary graphs of H (see [2]).

The enumeration algorithm of Ext(G)
Input: A connected P4 -homogeneous graph Q of type 1 or 2
Output: The set of minimal prime extensions H of Q
(i) Consider the set F (Q) = {G1 , ..., Gt } of (P4 , bull)-homogeneous graphs containing Q as induced subgraph
(ii) Let Gi be a graph of F (Q) and let U1 , ..., Uk be the set of the maximal non
trivial modules of Gi that can be computed from the modular decomposition
tree of Gi .
(iii) Ext1 (Gi ) is the set of all graphs obtained by adding to Gi the set X =
{x1 , ..., xk } of new vertices such that:
(a) each xi form a strong Ui - pseudopath of length 1 and [X] is edgeless
(b) there is no edge between xi and Uj , i 6= j and i, j = 1...k
(iv) Ext2 (Gi ) is be the set of all graphs obtained by considering every graph of
Ext1 (Gi ) and then identifying in all possible ways the vertices of X of (the
neighborhood of the vertex resulted from the identification of the two vertices
x and y is N(x) ∪ N(y)). Ext3 (Gi ) is the set of all graphs obtained by adding
edges in all possible ways between the vertices of V (Gj ) ∩ X, of every graph
Gj of Ext2 (Gi ) . Finally, Ext4 (Gi ) is the set of all graphs obtained by adding
edges in all possible ways between the vertices of V (Gl ) ∩ X of every graph
Gl of Ext3 (Gi ) and the non trivial modules of Gl in the following manner: for
x ∈ V (Gl ) ∩ X and for an homogeneous set U of Gl such that x is indifferent
with respect to U, we add all edges between x and the vertices of U if [U] is not
isomorphic to a P3 or to its complement; if [U] is isomorphic to a P3 = abc or
to its complement we add either all edges between x and {a, b, c} or the edge
xb or the edges xa and xc.
(v) The set of minimal prime extensions H of Q is obtained from the union of the
sets Ext1 (Gi ) ∪ Ext2 (Gi ) ∪ Ext3 (Gi ) ∪ Ext4 (Gi ), i = 1, ..., t.
3. Enumerating Ext(G) whenever G is a 2P4 - homogeneous graph
The space limitations of this extended abstract do not allow us to give the
details for obtaining Ext(G) in all cases that may occur for a 2P4 -homogeneous
graph G. We shall only present here a general method for enumerating Ext(G).
We first enumerate Ext([C2 ]) (since [C2 ] is a P4 -homogeneous graph, Ext([C2 ])

308

can be found as exposed in previous section). Let H be a graph of Ext([C2 ]) and
let A be a set of new vertices such that [A] is isomorphic to [C1 ]. Then add edges
between A and V (H) as follows:
1 A is partial with respect to V (H) and the graph induced by V (H) ∪ A is a
minimal prime extension of G. Let F1 be the set of graphs obtained in this
manner.
2 A is total with respect to V (H). Hence the graph H 0 induced by V (H) ∪ A
contains two maximal modules, A and V (H). Then add to H 0 a strong Bpseudopath and a strong V (H)-pseudopath which is 2K2 -free and containing
at most 9 vertices. Let F2 be the set of graphs obtained with this manner.
3 Ext(G) is a subset of F1 ∪ F2 .
Remark. Following the structure of the 2P4 -homogeneous graph G under consideration, the general method presented above can be consequently adapted in order
to enumerate with precision the corresponding set of graphs F1 ∪ F2 .
References
[1] A. Brandstädt, V.B. Lee and J. Spinrad, Graph classes: a survey, SIAM
Monographs on Disrete Mathematics and Applications, 1999.
[2] V. Giakoumakis, Stephan Olariu, All minimal prime extensions of hereditary
classes of graphs, Theor. Comput. Sci. 370(1-3): 74-93 (2007)
[3] I. Zverovich, Extension of hereditary classes with substitutions, Discrete Applied Mathematics 128, (2-3), (2003) 487-509
[4] I. Zverovich, A finiteness theorem for primal extensions, Discrete Mathematics, 293, (1), (2005), 103-116.

309

Networks II

Lecture Hall B

Thu 4, 10:30–12:30

On planar and directed multicuts with few
source-sink pairs
Cédric Bentz a
a LRI,

Univ. Paris-Sud and CNRS, 91405 ORSAY Cedex
cedric.bentz@lri.fr

Key words: Multicuts, Graph algorithms, NP-hardness, APX-hardness

1. Introduction
Assume we are given a n-vertex m-edge (di)graph G = (V, E), a weight function c : E → N∗ and a list N of pairs (source si , sink s0i ) of terminal vertices. The
minimum multicut problem, or M IN MC, consists in selecting a minimum weight
set of edges (or arcs) whose removal leaves no (directed) path from si to s0i for each
i. The minimum multiterminal cut problem (M IN MTC) is a particular minimum
multicut problem in which, given a set of r vertices {t1 , . . . , tr }, the source-sink
pairs are (ti , tj ) for i 6= j.
For |N | = 1, M IN MC is equivalent to the classical minimum cut problem, and
therefore is polynomial-time solvable both in directed and in undirected graphs.
However, M IN MC (resp. M IN MTC) becomes NP-hard, and even APX-hard, as
soon as |N | = 3 (resp. r = 3) in undirected graphs [7] (the cases r = 2 and
|N | = 2 being tractable [12]), and as soon as |N | = 2 (resp. r = 2) in digraphs
[10]. For an arbitrary number of source-sink pairs, M IN MC is APX-hard even in
unweighted stars [9]. Moreover, M IN MC is polynomial-time solvable in directed
trees (the constraint matrix being totally unimodular) and M IN MTC is polynomialtime solvable in directed acyclic graphs [6].
It is generally believed that M IN MC is not significantly simpler in directed
acyclic graphs. In [2], it was proved that M IN MC is NP-hard even in unweighted
directed acyclic graphs (or DAG) having a very special structure (namely, their underlying undirected graph is a bipartite cactus of bounded path-width and of maximum degree three), but its APX-hardness remained open, as well as its complexity
when |N | is fixed. Moreover, M IN MTC is known to be NP-hard in planar graphs,
where it becomes tractable if r is fixed [7], and, in [1], M IN MC has been shown

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

to be polynomial-time solvable in planar graphs where all the terminals lie on the
outer face, if |N | is fixed.
In this extended abstract, we first show that M IN MC is APX-hard in DAG,
even if |N | = 3. The proof is surprisingly simple, and only relies on the APXhardness of V ERTEX C OVER in bounded-degree undirected graphs. Then, we improve the result in [1], by giving a nearly linear-time algorithm for M IN MC when
the graph is planar, |N | is fixed, and the terminals lie on the outer face.
2. APX-hardness proof for DAG

The structure of our proof is simple: we will give an approximation-preserving
reduction from V ERTEX C OVER in graphs of maximum degree 3, which is known
to be APX-hard [11], to M IN MC in unweighted DAG with |N | = 3. This will
immediately implies the APX-hardness of the latter problem.
As in [2], we consider an instance of V ERTEX C OVER in graphs of maximum
degree 3, and transform this (undirected) graph G into a DAG, by first numbering
the vertices arbitrarily, and then orienting the edges so that this numbering defines
a topological order. Then, we replace each vertex vi by an arc (vi0 , vi00) and any arc
of the form (vi , vj ) by an arc (vi00 , vj0 ). Let G0 be this new digraph (note that G0 is
also a DAG, and has maximum degree 4). To finish the reduction, we add six new
vertices s1 , s2 , s3 , s01 , s02 , s03 , and, following the topological order of the vi0 in G0 , we
link, for each pair (vi0 , vj00 ) such that (vi , vj ) is an arc of G, vertex sh to vi0 and vj00 to
s0h by two new arcs, where h ∈ {1, 2, 3} is the smallest index such that there is no
arc from vi00 to s0h yet.
Since G is of maximum degree 3, it is not difficult to show that:
Claim 1. Such an index h always exists, so the construction is always possible.
This yields a M IN MC instance where the terminal pairs are (si , s0i ) for i =
1, 2, 3, and which, as can be easily seen, is such that: for each integer S, there is a
vertex cover of size S in G iff there is an arc multicut of size S in G0 . So:
Theorem 16. M IN MC is APX-hard in unweighted DAG, even when |N | = 3.
An interesting open problem would be to settle the case where there are only
two source-sink pairs (recall that M IN MC is then APX-hard in general digraphs
[10]). Moreover, our result is best possible (up to constant factors), in the sense that
there exists a trivial 3-approximation algorithm for M IN MC when |N | = 3 (for
each i, compute a minimum simple cut between si and s0i , then take as a multicut the
union of these three cuts). It also matches the best inapproximability result known
for this problem in unrestricted digraphs that is based on the assumption that P6=NP
314





[10] (the Ω logloglogn n inapproximability bound of Chuzhoy and Khanna [5] being
based on a stronger complexity assumption, and the Ω(1) inapproximability bound
of Chawla et al. [3] being based on a different one, namely the Unique Games
Conjecture).

3. An efficient algorithm for planar graphs
In [1], a polynomial algorithm for M IN MC in planar graphs with fixed |N | and
all the terminals lying on the outer face was given, but it was not an FPT algorithm
[8]. Here we give the sketch of an FPT algorithm for this case.
Recall that the algorithm in [1] was based on a refinement of an idea from
[7]: when we remove the edges of any optimal solution to a M IN MC instance,
the terminals are clustered in p ≤ 2|N | connected components. So, after having
“guessed” the right clustering of the terminals (which is done by brute force enumeration on the set of terminals), we can obtain an equivalent M IN MTC instance
by merging, for each cluster, all the terminals of this cluster into a single terminal.
If the graph remains planar after this operation, then we can use the algorithm given
in [7]; this was the main idea used in [1]. However, if, in the M IN MTC instance
we obtain, all the terminals were lying on the outer face, then we could use the
much more efficient algorithm given in [4], which runs in O(n log n) time. The
basic idea of our new algorithm is thus to call this fast algorithm several times, in
order to split up the graph into several (connected) components, each one of them
being, in turn, a new M IN MTC instance on which we can apply the same algorithm
once again. So, we follow a divide-and-conquer approach, and, unlike in [1], solve
several planar M IN MTC instances (whose terminals lie on the outer face) in order
to solve the M IN MTC instance (whose terminals does not necessarily lie on the
outer face) associated with the optimal clustering of the initial M IN MC instance.
But how should we split up the graph? The next lemma is our starting point:
Lemma 5. Assume we are given a M IN MC instance M in an undirected 2-vertexconnected planar graph G where the terminals lie on the outer face, and an optimal
clustering of the terminals for this instance. Let us denote by C1 , . . . , Cq the clusters
of this clustering which are not included in other clusters (a cluster C being included
in another cluster C 0 if any path on the outer face linking, clockwise, two terminals
of C is included in some path on the outer face linking, clockwise, two terminals
of C 0 ). Then, the edges of any optimal solution for the M IN MTC instance obtained
in G by considering only the terminals in C1 , . . . , Cq and merging, for each i, the
terminals in Ci into a single terminal, are part of an optimal solution for M.
The ideas used in the proof of this lemma are rather simple: start from an
optimal multicut, and replace the edges lying between the connected components
associated with the clusters Ci by an optimal solution of the M IN MTC instance
315

described in the lemma. It is a reasonably easy task to show that the new solution
is also an optimal multicut. Hence, starting from G, we can recursively define a
M IN MTC instance by taking the Ci ’s as terminals, solve it (by the algorithm given
in [4], since the terminals lie on the outer face), and then apply this approach on
each one of the connected components obtained by removing the edges of this
optimal multiterminal cut. The algorithm given in [4] runs in O(n log n) time, and,
for a given clustering (there are O(1) possible clusterings when |N | is fixed), we
call it O(|N |) times: therefore, for fixed |N |, our –FPT– algorithm also runs in
O(n log n) time. An interesting open problem would be to determine whether a
linear-time algorithm exists.

References
[1] Bentz, C.: A simple algorithm for multicuts in planar graphs with outer terminals. Discrete Applied Mathematics 157 (2009) 1959–1964.
[2] Bentz, C.: On the complexity of the multicut problem in bounded tree-width
graphs and digraphs. Discrete Applied Mathematics 156 (2008) 1908–1917.
[3] Chawla, S., Krauthgamer, R., Kumar, R., Rabani, Y., Sivakumar, D.: On the
hardness of approximating multicut and sparsest-cut. Proc. CCC (2005).
[4] Chen, D.Z., Wu, X.: Efficient algorithms for k-terminal cuts on planar graphs.
Algorithmica 38 (2004) 299–316.
[5] Chuzhoy, J., Khanna, S.: Hardness of Cut Problems in Directed Graphs. Proc.
STOC (2006) 527–536.
[6] Costa, M.-C., Létocart, L., Roupin, F.: Minimal multicut and maximal integer
multiflow: a survey. European J. of Operational Research 162 (2005) 55–69.
[7] Dahlhaus, E., Johnson, D.S., Papadimitriou, C.H., Seymour, P.D., Yannakakis, M.: The complexity of multiterminal cuts. SIAM J. Comput. 23
(1994) 864–894.
[8] Downey, R.G., Fellows, M.R.: Parameterized Complexity. Springer, NY
(1999).
[9] Garg, N., Vazirani, V.V., Yannakakis, M.: Primal-dual approximation algorithms for integral flow and multicut in trees. Algorithmica 18 (1997) 3–20.
[10] Garg, N., Vazirani, V.V., Yannakakis, M.: Multiway cuts in node weighted
graphs. Journal of Algorithms 50 (2004) 49–61.
[11] Papadimitriou, C., Yannakakis, M.: Optimization, approximation, and complexity classes. J. Comput. and System Sciences 43 (1991) 425–440.
[12] Yannakakis, M., Kanellakis, P., Cosmadakis, S., Papadimitriou, C.: Cutting
and partitioning a graph after a fixed pattern. Proc. ICALP (1983) 712–722.

316

Maintenance resources allocation on power
distribution networks with a multi-objective
framework
Fábio Luiz Usberti, a José Federico Vizcaino González, a
Christiano Lyra Filho, a Celso Cavellucci a
a FEEC/UNICAMP, C.P.

6102, 13083-970 Campinas SP, Brazil
fusberti@yahoo.com

Key words: Network Optimization, Integer Non-Linear Problem, Pareto Frontier

Introduction. Power distribution companies are incumbent to transport electrical energy in order to attend all clients in a given network, subject to specified
quality and reliability levels. The occurrence of network components failure is the
main factor which compromise power systems reliability. Therefore, maintenance
actions like repairs and component replacements are needed to reestablish the network healthy activity. These maintenance actions can be classified as preventive,
when executed before the component failure, or corrective, otherwise. Given the
increasing demand of reliable (uninterrupt) power supply and more severe quality
inspections imposed by regulations entities, it becomes mandatory to rationalize
investments on distribution network maintenance. This is done by first defining the
relationship between maintenance and reliability, and then achieving the network
reliability target through the lowest maintenance cost possible, or alternatively,
seeking the most reliable network under maintenance resources constraints. This
work proposes a multi-objective approach to tackle the Maintenance Resources
Allocation Problem (MRAP), i.e., we have considered optimizing simultaneously
both objectives: maintenance cost and network reliability, and so providing power
distribution companies with a set of non-dominated (Pareto optimum) solutions to
access the companies’ decisions on maintenance investments.
Problem Definition. Most power distribution networks operate with a radial
configuration, which means that, using a graph terminology, the network can be
represented as a tree T (V, E) rooted at a substation that provides a unique path
from the substation to each load point (or node) v. Each node attends a given number of clients and contains a set of electrical equipments subject to failure. The
occurrence of any equipment failure will determine power supply interruption of
the corresponding node and recursively of all his offsprings. The MRAP is defined

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

in a time horizon of t = 1, . . . , T years. In the following, we give some notation
used in this work:
•
•
•
•
•
•
•
•

xte = 1 if equipment e receives maintenance in year t, 0 otherwise.
δet = failure rate of equipment e in year t.
Nv = number of clients affected (including offsprings) by failure on node v.
pe = preventive maintenance cost for equipment e.
ce = corrective maintenance cost for equipment e.
me0 = failure multiplier for equipment e on lack of maintenance.
me1 = failure multiplier for equipment e when maintenance is executed.
mte = failure multiplier applied on equipment e failure rate in year t.

We define the nature in which the network equipments deteriorate or improve
along the time horizon, whether if they receive or not maintenance, as failure rate
model. In this model, the equipments failure rates are updated through the failure
rate multipliers, according to the actions applied (0.1). The maintenance cost is
expressed in terms of corrective maintenance cost (0.2) and preventive maintenance
cost (0.3). The network reliability is given through the SAIFI (System Average
Interruption Frequency Index) (0.4).


 δ t−1 me1

δjt = 


Cct =

if equipment e receives maintenance

e

δet−1 me0

XX

(0.1)

otherwise

ce δet

(0.2)

pe xte

(0.3)

v∈V e∈v

Cpt =

XX

v∈V e∈v

SAIF I t =

X

v∈V

(Nv
X

X

δet )

e∈v

(0.4)

Nv

v∈V

The bi-objective integer non-linear mathematical model for MRAP is given:
MIN
MIN

X

1
(Cct + Cpt )
t
(1
+
i)
t
SAIF I = max(SAIF I t )

CT =

(0.5)
(0.6)

t

st
mte = xte me1 + (1 − xte )me0
δet = δet−1 mt−1
e
xte ∈ {0, 1}

∀e, ∀t
∀e, ∀t
∀e, ∀t

(0.7)
(0.8)
(0.9)

The objective function (0.5) minimizes the maintenance total cost, adjusted by the
present value, given an interest rate i. The objective function (0.6) minimizes the
maximum SAIF I t obtained through all the time horizon. Constraints (0.7) guarantee that the failure multiplier mte applied to each equipment e and year t must
318

be one of two possible values, me0 or me1 ; (0.8) determine the failure rate of each
equipment along the time period, depending on the maintenance applied; finally,
(0.9) correspond the binary constraints on the decision variables.
Solving Strategy. To solve the MRAP model, we use a traditional scalarization technique, the ε-Constraint Method [2], where only one of the objectives, maintenance cost, is minimized, while the SAIFI is transformed into a constraint (0.10). To obtain the set of non-dominated solutions, the previous model
should be solved p times under distinct values of εk , where ε1 = SAIF Imax and
εp = SAIF Imin. These SAIFI extreme values can be calculated by considering
xte = 0 and xte = 1 (∀t, ∀e), respectively. To distribute the p values of εk uniformly
between the SAIF I extreme values, they are computed by (0.11).
max(SAIF I t ) 6 εk

(0.10)

t

εk = SAIF Imin +

(SAIF Imax − SAIF Imin )(k − 1)
p−1

k = 1, . . . , p (0.11)

Given a power distribution network, the Pareto frontier is thus obtained after p
iterations of the ε-constraint method. To solve each iteration, an efficient genetic
algorithm specifically developed for MRAP [1] is executed.
Composition of Pareto Frontiers. In general, a power distribution company
is expected to have not one, but several distribution networks. In theory, all these
networks could be considered as a single instance and then solved by the procedure
previously described. Nevertheless, this would result in an overwhelming computational effort. This work introduces a divide-and-conquer technique to surmount this
problem: it first solves each network individually (division phase) and then composes all Pareto frontiers into a single one (conquer phase). This last phase introduces a new combinatorial problem, which we call Composition of Pareto Frontiers
Problem (CPFP).
The input of the CPFP is a set of n Pareto frontiers and a vector NC i (i =
1, . . . , n) which represents the number of clients attended by network i. For the
sake of simplicity, we are considering that each frontier has the same number p
of non-dominated solutions. The j th solution from the ith Pareto frontier Sji =
(CTji , SAIF Iji ) is represented by the pair of objectives. In the CPFP we select one
solution from each Pareto frontier (i.e., some j for each i = {1, . . . , n}), in order to
produce a composite solution S C = (CT C , SAIF I C ) which we desire to be nondominated. Supposing we have chosen the n solutions as (Sj11 , Sj22 , ..., Sjnn ), then the
composite solution can be determined by (0.12).
n
X

SC = (

i=1

n
X

NC i SAIF Ijii

CTjii , i=1 X
n

)
NC

i

i=1

319

(0.12)

A naive strategy to determine a set of p well distributed non-dominated composite solutions could be choosing all possible solution combinations of the Pareto
frontiers and then filtering p well distributed non-dominated compositions. That
would lead to pn composite calculations, which is excessive considering that power
distribution companies may have, for example, more than n = 50 networks, and
that a good Pareto frontier should have at least p = 20 solutions. A better way
to achieve this is to compound the Pareto frontiers two-by-two, always preserving
p well distributed non-dominated compositions in the resulting frontier; the process is repeated until only one frontier remains. This will reduce the calculations to
(n − 1)p2 , which is perfectly acceptable.
Study Cases. The methodology described above was applied to a fictional
small-scaled group of three distribution networks (15600 clients, 105 equipments),
based on [3], and to real large-scale group of five distribution networks (48247
clients, 6314 equipments). The results confirm the suitability of the strategy to find
good quality non-dominated solutions for the MRAP, and then composing them
into one Pareto frontier.
Conclusions. This work proposes a multi-objective approach to solve MRAP:
a hard, non-linear, combinatorial problem which concerns major power distribution
companies. The purpose of the methodology is to help decisions on investments applied to network maintenance, giving the companies decision makers proper information about the best trade-offs between maintenance investments and their feedback into system reliability.
Acknowledgment. The authors acknowledge the support from the Brazilian
National Council for Scientific and Technological Development (CNPq).

References
[1] P. A. Reis (2007), ”Reliability based optimization of maintenance plans for
power distribution systems”, Master’s Thesis, FEEC-UNICAMP, Campinas SP (in Portuguese).
[2] M. Ehrgott (1995), ”Multicriteria Optimization”, Springer, pp. 97-123.
[3] A. Sittithumwat and F. Soudi and K. Tomsovic (2004), ”Optimal allocation of
distribution maintenance resources with limited information”, Electric Power
Systems Research, Vol. 68, pp. 208-220.

320

Column Generation for the Multicommodity
Min-cost Flow Over Time Problem
Enrico Grande, a Pitu B. Mirchandani, b Andrea Pacifici a
a Dip.

di Ingegneria dell’Impresa, Università degli Studi di Roma “Tor Vergata”, Italy
{grande,pacifici}@disp.uniroma2.it
b Systems

and Industrial Engineering Dept., University of Arizona, USA
pitu@sie.arizona.edu

Key words: flows over time, column generation, exact algorithm.

1. Introduction

In most networks flows models, the time dimension is not explicitly considered. This assumption is unrealistic in several applications such as road and air
traffic management, or water distribution. In flows-over-time models, the flow is allowed to vary over time and it requires a positive amount of time to travel through
an arc. Reviews of applications and fundamental theory results are reported in the
surveys [2; 5; 8].
The notion of flows over time (or dynamic flows) is introduced by Ford and
Fulkerson. In [6; 7] they give efficient solution algorithms for the maximum flow
over time problem: Given a capacitated network G = (V, E), source and destination nodes, and arcs traversal times, find a flow over time maximizing the amount
of flow reaching the destination node within a given time horizon T . Capacity
constraints are expressed as upper bounds on the flow rates on the arcs. A related problem, polynomially solvable, is the quickest (s, t)-flow: Find a dynamic
flow such that a certain demand is shipped and the time horizon T is minimized
(see Burkard et al. [12]). Gale [4] introduce the earliest arrival flows, i.e., flows
such that the amount reaching the destination node is maximal for all times t,
0 ≤ t ≤ T . Pseudo-polynomial algorithms for finding such flows—which are
based on the successive shortest path algorithm—have been devised by Wilkinson
and Minieka [13; 11].
If we consider arc-dependent costs and we look for minimum cost dynamic
flows satisfying a demand within a given time horizon T , things get harder. Klinz
and Woeginger [3] show that the single source, single destination case is NP-hard

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

even for series-parallel graphs. Fleischer and Skutella in [10] show that the mincost single commodity problem never requires the flow to wait at intermediate
nodes. The multicommodity setting is, of course, NP-hard as well, as showed by
Hall, Hippler and Skutella [1]. On the positive side, Fleischer and Skutella [9] provide an approximation algorithm for the quickest multicommodity dynamic problem.
In this paper we present an exact algorithm for the Multicommodity Flow over
Time Problem (MFTP) which is based on a column generation approach for a pathbased linear programming model. The column generation subproblem is shown
to be binary NP-hard and we devise a pseudo-polynomial dynamic programming
algorithm for its solution. The results of a preliminary computational study is also
reported.

2. A linear programming model for MFTP
We use the following notation. G = (V, E) is a digraph. K is a set of commodities to be served within the time horizon (or makespan) T : Each commodity
k ∈ K is identified by the triple (sk , tk , bk ) ∈ (V × V × R+ ), i.e. source, destination and demand of commodity. Pk is the set of paths that one can use to serve
S
T
commodity k ∈ K. We assume that k∈K Pk = ∅ ∗ and let P = k∈K Pk . The
capacity of arc e ∈ E, expressed as a rate (unit of flow/time), is ue , ce its cost, and
P
te its traversal time. Given a path p ∈ P , we let cp = e∈p ce be the cost and tp
the traversal time of p. Moreover, if e ∈ p, we let te,p be the traversal time of path
p ∈ P up to (and including) arc e ∈ E. (Clearly, if e0 is the last arc of path p, then
tp = te0 ,p .) We also use an incidence vector δe,p = 1 [0] if e ∈ p [e ∈ E \ p].
In the following linear programming problem, decision variable fp (t) represents the amount of flow starting from the origin of path p at time t, p ∈ P ,
t = 1, . . . , T .

min

X

X

cp fp (t)

p∈P t∈{1,...,T }

s.t.
(P)

X

p∈P

fp (t − te,p )δe,p ≤ ue , ∀ t ∈ {1, . . . , T }, ∀ e ∈ E

X

X

t∈{1,...,T } p∈Pk

fp (t) ≥ 0,

(2.1)

fp (t) ≥ bk , ∀ k ∈ K
∀ p ∈ P, 1 ≤ t ≤ T − tp

∗

Note that, of course, one arc may be part of two or more paths serving the same or
different commodities.

322

The first family of capacity constraints considers the times taken by the flows
traveling on different paths until arc e. More precisely, a unit of flow reaching the
head v of arc e = (u, v) at time t, using path p ∈ Pk , left its origin sk at time t−te,p .
The second family of constraints imposes the demand to be fulfilled. Linear program (2.1) is non-compact: With respect to the input size, there are exponentially
many variables. Furthermore the number of constraints is pseudo-polynomial since
it depends on the time horizon T . It is therefore worthwhile to devise a column
generation approach in order to provide an exact solution for P.
3. Column generation subproblem
Suppose P̄k ⊂ Pk is the restricted set of paths for commodity k ∈ K used
so far in the primal. If we associate variables we (t), (t, e) ∈ {1, . . . , T } × E, to
primal capacity constraints and variables σ k , k ∈ K, to demand constraints, the
column generation subproblem consists of finding a path p ∈ Pk \ P̄k such that
P
cp + e∈p we (t + te,p ) < σ k for all 1 ≤ t ≤ T , k ∈ K, and e ∈ E.

Fix t ∈ {1, . . . , T } and let tu,p be the arrival time at node u along path p and
observe that t + t(u,v),p = tu,p + t(u,v) . Note that, due to the structure of the original
(primal) problem, we do not have to consider waiting times at intermediate nodes.
Hence, we search for a path p ∈ Pk \ P̄k such that, for all e ∈ E:
X

cu,v + wu,v (tu,p + t(u,v) ) < σ k

(u,v)∈p

This is in fact a special shortest-path problem: Find a minimum cost path in a
network where the cost of any arc (u, v) is time-dependent and arc traversal times
are constant values. Unfortunately, the following negative result holds:
Theorem. The column generation subproblem is binary NP-hard.
However, we devise a dynamic programming solving the column generation
subproblem that runs in (pseudo-polynomial) time O(|V |3 T ). It is worthwhile to
point out that the dynamic programming algorithm looks for the minimum cost
path from each node to one destination, for each t ∈ {1, . . . , T }.
4. Preliminary Results

Preliminary computational results, performed on a standard PC, show that the
approach presented here is promising. It is reasonably effective against increasing
networks size and efficient in terms of CPU times. We are able to optimally solve

323

in few seconds instances of the problem with T ≤ 100, k ≤ 10 and hundreds of
nodes.

References
[1] M. S. Alex Hall, Steffen Hippler. Multicommodity flows over time: Efficient algorithms and complexity. Theoretical Computer Science, 379:387–
404, 2007.
[2] J. E. Aronson. A survey of dynamic network flows. Annals of Operations
Research, 20:1–66, 1989.
[3] G. J. W. B. Klinz. Minimum-cost dynamic flows: the series parallel case.
Networks, 43:153–162, 2004.
[4] D. Gale. Transient flows in networks. Michigan Mathematical Journal, 6:50–
63, 1959.
[5] H. Hamacher and S. A. Tjandra. Mathematical modelling of evacuation problems: A state of the art. In Pedestrian and Evacuation Dynamics, 2002.
[6] L. R. F. Jr. and D. R. Fulkerson. Constructing maximal dynamic flows from
static flows. Operations Research, 6(3):419–433, 1958.
[7] L. R. F. Jr. and D. R. Fulkerson. Flows in Networks. Princeton University
Press, 1962.
[8] B. Kotnyek. An annotated overview of dynamic network flows. Technical
report, INRIA, 2003.
[9] M. S. L. Fleischer. Quickest flows over time. SIAM Journal on Computing,
36(6):1600–1630, 2007.
[10] M. S. Lisa Fleisher. Minimum cost flows over time without intermediate storage. In Proceedings of the 14th Annual ACM-SIAM Symposium on Discrete
Algorithms, pages 66–75, 2003.
[11] E. Minieka. Maximal, lexicographic and dynamic network flows. Operations
Research, 21:517–527, 1973.
[12] B. K. Rainer E. Burkard, Karin Dlaska. The quickest flow problem. Methods
and Models of Operations Research, 37:31–58, 1993.
[13] W. L. Wilkinson. An algorithm for universal maximal dynamic flows in a
network. Operations Research, 19:255–266, 1971.

324

Inferring Update Sequences in Boolean Gene
Regulatory Networks
Fabien Tarissan, a Camilo La Rota b
a Complex

System Institute (ISC) & CNRS, Palaiseau, France
tarissan@lix.polytechnique.fr

b Complex

System Institute (IXXI), Lyon, France
camilo.larota@ens-lyon.fr

Key words: Mathematical programming, Inverse problems, Gene regulatory networks
reconstruction

1. Introduction
This paper employs mathematical programming and mixed integer linear programming techniques for solving a problem arising in the study of genetic regulatory networks. More precisely, we solve the inverse problem consisting in the
determination of the sequence of updates in the digraph representing the gene regulatory network (GRN) of Arabidopsis thaliana in such a way that the generated
gene activity is as close as possible to the observed data.
Differences among cells of different tissues depend on the specific set of genes that
are active in each tissue. Therefore, one usually assumes that the different steady
states of a GRN dynamics correspond to the different possible cell fates ([7]). This
leads to explain the changes observed during the development of the organisms by
the fact that perturbations on specific elements of the network make the system
switch from one steady state to another. Some hypothesis can be made about these
perturbations, which are then treated as initial conditions for the new tissue being
formed. However, an important unknown is (are) the update sequence(s) of the gene
activity that let the system evolve from a given set of initial conditions to the set of
steady states. Indeed, different update sequences determine different sets of basins
of attraction of the GRNs. However, the steady states remain the same under any
sequence.
Usually, a specific update sequence is assumed to rule the dynamics of the
GRNs [1; 3]. The present study differs from this approach in that we sought to
infer the update sequence from the biological observations. It also differs from our
previous paper as we focus here on asynchronous sequences whereas in [6] the
updates were synchronous.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. The problem
Given a directed graph G = (V, E), a discrete set T of time instants (which we
suppose to be an initial contiguous proper subset of N) and the following functions:
•
•
•
•
•
•

a function α : E → {+1, −1} called the arc sign function;
a function ω : E 7→ R+ called the arc weight function;
a function χ : V × T 7→ {0, 1} called the gene state function;
a function ι : V 7→ {0, 1} called the initial configuration;
a function θ : V 7→ R called the threshold function;
a function γ : V × T 7→ {0, 1} called the updating function.

A gene regulatory network (GRN) is a 8-tuple (G, T, α, ω, θ, χ, ι, γ) such that:
∀v ∈ V

χ(v, 0) = ι(v)



 H(v, t − 1)

∀v ∈ V, t ∈ T r {0} χ(v, t) = 


(2.1)
if γ(v, t) = 1

(2.2)

χ(v, t − 1) otherwise

where H is the Heaviside function defined for v ∈ V and t ∈ T by
H(v, t) =




1


0

if

P

u∈δ− (v)

α(u, v)ω(u, v)χ(u, t) ≥ θ(v)

(2.3)

otherwise,

with δ − (v) = {u ∈ V | (u, v) ∈ E} for all v ∈ V . Eqns. (2.1)-(2.2)-(2.3) together
are called the evolution rules of the GRN. For any particular t ∈ T , χ(·, t) : V →
{0, 1} is called a configuration. Since the evolution rules relate a configuration at
time t with a configuration at time t − 1, χ(·, t) is called a fixed configuration
(or fixed point) if it remains invariant under the application of one complete cycle
of updates encoded by γ. Furthermore, as long as the evolution rules are purely
deterministic (as is modelled above), a fixed point of a GRN is determined by its
initial configuration.
In this paper we deal with an inverse problem related to the estimation of update sequence in GRNs. More precisely, we address the following.
U PDATE S EQUENCE E STIMATION IN GRN S (USEGRN). Given a digraph G, a
time instant set T , an arc sign function α, an arc weight function ω, a threshold
function θ and a set I of initial configurations, find an update function γ with
the property that for all ι ∈ I there exists a gene activation function χ such that
(G, T, α, ω, θ, χ, ι, γ) are GRNs whose fixed points are at a minimum distance
to observed data.
In other words, we attempt to estimate the sequence of updates in a GRN from the
knowledge of the digraph topology in such a way that (a) the GRN evolution rules

326

are consistent with respect to a certain set of initial configurations and (b) the fixed
points induced by the estimated values are as close as possible to the observed ones.
As the reader might notice, the problem strongly depends on the modelling of the
update sequence encoded by γ. In [3], the authors proposed to describe such a
sequence by means of periods and delays parameters for each gene. Assuming pv
and dv to be such values for gene v, we can reformulate Equation 2.2 in the previous
modellisation according to the following relation:
∀t ∈ T

γ(v, t) = 1 ⇐⇒ ∃n ∈ N s.t. t = npv + dv

3. The mathematical programming formulation
The methodology we shall follow is that of modelling the USEGRN by means
of a mathematical programming formulation:
minx f (x)






subject to g(x) ≤ 0, 

where x ∈ Rn are the decision variables and f : Rn → R is the objective function
to be minimized subject to a set of constraints g : Rn → Rm which may also include variable ranges or integrality constraints on the variables.
The primary concern in solving the USEGRN is thus modellistic rather than algorithmic. One of the foremost difficulties is that of employing a static modelling
paradigm — such as mathematical programming — in order to describe a problem whose very definition depends on time. Another important difficulty resides in
describing the necessary and sufficient conditions for a configuration to be a fixed
point in a mathematical form. We solve this difficulty by introducing two decision
variables: a binary variable s stating that the network has been stable for at least
two successive time steps; a binary variable y that will indicate the first time the
network is stable. The last difficulty concerns the proper modelling of the update
sequence as proposed in [3]. The solution relies on the use of two binary variables
π and δ for each gene and indexed over the possible values for the periods and the
delays. Then, πv (p) (resp. δv (d)) is set to 1 if the period (resp. delay) of v is p (resp.
d). We provide above such a formulation:
• Sets: V of genes in the network, E of edges in the network, T of time instants,
P of periods values, D of delay values and R of regions.
• Parameters:
· ι : R × V 7→ {0, 1} is the initial configuration of the network (vector of
boolean values affected to the genes) for each region.
· α : A → {+1, −1} is the sign of the arc weights;
· w : V 7→ R+ is the arc weight function;
· θ : V 7→ R is the threshold function;
· φ : V × R 7→ {0, 1} is the targeted fixed configuration for region r.
• Variables:
327

· for all r ∈ R, v ∈ V , t ∈ T , xtr,v ∈ {0, 1} is the activation state of gene v
at time t in region r;
· for all r ∈ R, v ∈ V , t ∈ T , htr,v ∈ {0, 1} is the projection of state of
gene v at time t in region r according to Heaviside function;
· s : R × T 7→ {0, 1} is a decision variable indicating that the network is
stable during at least two successive time steps in region r.
· y : R × T 7→ {0, 1} is a decision variable that indicates the first time the
network reaches a stable state in region r.
· for all v ∈ V , p ∈ P , πv,p ∈ {0, 1} is a decision variable that indicates
that the periodicity of gene v is p.
· for all v ∈ V , d ∈ D δv,d ∈ {0, 1} is a decision variable that indicates
that the delay of gene v is d.
• Objective function:
min

X



X

(yrt−1 − yrt )

r∈R t∈T \{1}

X

v∈V



|xtr,v − φr,v | .

• Constraints:
· Heaviside function computation rule (for all t ∈ T \ {1}, v ∈ V, r ∈ R) :
θv htr,v −|V |(1 −htr,v ) ≤

X

u∈δ−(v)

t
t
αuv wuv xt−1
r,u ≤ (θv −1)(1 −hr,v ) + |V |hr,v

· state transition rules (for all r ∈ R, v ∈ V , p ∈ P , d ∈ D):
x0r,v = ιr,v
∀t ∈ T \ {1} s.t. t 6= np + d πv,p δv,d xtr,v = πv,p δv,d xt−1
r,v
∀t ∈ T \ {1} s.t. t = np + d πv,p δv,d xtr,v = πv,p δv,d ht−1
r,v
πv,p δv,d d ≤ p
· fixed point conditions (for all r ∈ R, t ∈ T \ {1}):
P

v∈V

t
|xtr,v − xt−1
r,v | ≤ kV ksr

v∈V

t
|xtr,v − xt−1
r,v | ≥ sr

P

yrt frt = 0
P

u>t

(1 − yrt ) ≤ frt

sur = frt (|P | + |D|)2 ≤

P

τ ∈T

yrτ

4. Reformulations and solutions
The above problem is a nonconvex Mixed-Integer Non-Linear Problem that
can be reformulated exactly to a Mixed-Integer Linear Problem using the techniques proposed in [5]. After standard mathematical manipulations, all the nonlinearities reduce to product terms of binary and/or integer variables, which can be

328

reformulated by adding new auxiliary variables and constraints as follows:
xy terms (x, y : binary)
η≥0
η≤y
η≤x
η ≥x+y−1

xz terms (x : binary, z : integer)
ζ ≥ zL x

ζ ≤ z + (|z L | + |z U |)(1 − x)
ζ ≤ zU x

ζ ≥ z − (|z L | + |z U |)(1 − x)

where z L and z U stand for the boundaries of z and η and ζ are the new variables
that replace the products in the equations.
We solved to optimality a few real-life instances from the GRN of Arabidopsis
thaliana using AMPL [2] to model the problem and CPLEX [4] to solve it. The
size of the GRNs involved were such that CPLEX obtained the optimal solution in
a matter of minutes.
5. Acknowledgements
This work was supported by EU FP6 FET Project M ORPHEX. We are deeply
grateful to L. Liberti (LIX) for his feedback on the mathematical formulation.
References
[1] J. Demongeot, A. Elena, and S. Sené. Robustness in Regulatory Networks: a
Multi-Disciplinary Approach. Acta Biotheoretica, 56(1-2):27–49, 2008.
[2] R. Fourer and D. Gay. The AMPL Book. Duxbury Press, Pacific Grove, 2002.
[3] Carlos Gershenson. Classification of random boolean networks. In Abbass
Standish and Bedau, editors, Artificial Life VIII, Proceedings of the Eighth International Conference on Artificial Life, pages 1–8. MIT Press, 2002.
[4] ILOG. ILOG CPLEX 10.1 User’s Manual. ILOG S.A., Gentilly, France, 2006.
[5] L. Liberti, S. Cafieri, and F. Tarissan. Reformulations in mathematical programming: A computational approach. In A. Abraham, A.-E. Hassanien, and
P. Suarry, editors, Global Optimization: Theoretical Foundations and Application, Studies in Computational Intelligence. Springer, New York, to appear.
[6] F. Tarissan, C. La Rota, and L. Liberti. Network reconstruction: a mathematical programming approach. In Proceedings of the European Conference of
Complex Systems (ECCS’08), to appear.
[7] R Thomas and M Kaufman. Multistationarity, the basis of cell differentiation
and memory. i. structural conditions of multistationarity and other nontrivial
behavior. Chaos, 11(1):170–179, Mar 2001.

329

Bioinformatics

Lecture Hall A

Thu 4, 14:00–15:30

N ANOCONES
A classification result in chemistry
Gunnar Brinkmann, Nico Van Cleemput
Applied Mathematics and Computer Science, Ghent University,
Krijgslaan 281 S9, 9000 Ghent, Belgium
{ Gunnar.Brinkmann, Nicolas.VanCleemput}@UGent.be
Key words: Nanocone, Enumeration, Classification

1. Introduction
Nanocones are carbon networks conceptually situated in between graphite and
the famous fullerene nanotubes. Graphite is a planar carbon network where each
atom has three neighbours and the faces formed are all hexagons. Fullerene nanotubes are discussed in two forms: once the finite, closed version where except
for hexagons you have 12 pentagons and once the one-side infinite version where
6 pentagons bend the molecule so that an infinite tube with constant diameter is
formed. A nanocone lies in the middle of these: next to hexagons it has between 1
and 5 pentagons, so that neither the flat shape of graphite nor the constant diameter
tube of the nanotubes can be formed. Recently the attention of the chemical world
in nanocones has strongly increased. Figure 1 shows an overview of these types of
carbon networks.

Fig. 1. graphite - nanocone - nanotube

The structure of graphite is uniquely determined, but for nanotubes and
nanocones an infinite variety of possibilities exist. There already exist fast algorithms to generate fullerene nanotubes (see [3]) that are e.g. used to detect energetically possible nanotubes. In this talk we describe a generator for nanocones.
2. Patches
For computer generation of these structures we first need to describe them in
a finite way. We describe the infinite molecule by a unique finite structure from
CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Fig. 2. Two views of a patch with two pentagons.

which the cone can be reconstructed. The aim of this talk is to describe this step
and give an idea of the algorithm to generate these finite representations.
A finite and 2-connected piece of a cone that contains all the pentagons is
called a patch. All the vertices (atoms) in a cone have degree 3, so the vertices
along the boundary of a patch will have degree 2 or 3. It can be easily shown that
if the boundary of a patch doesn’t contain any consecutive threes, then the number
of neigbouring twos is equal to 6 − p, where p is the number of pentagons in the
patch.

2
2

3

3

2

2
3

2

2

3

2
2

Fig. 3. A cone patch with boundary (2(23)1 )4 and four neighbouring twos.

We can interpret patches without consecutive threes as polygons where the
consecutive twos are the corners, and the lengths of the sides are determined by
their number of threes.
3. Classification
Definition 1. A symmetric patch is a patch that has a boundary of the form
(2(23)k )6−p , with 1 ≤ p ≤ 5.
A nearsymmetric patch is a patch that has a boundary of the form (2(23)k−1)
(2(23)k )6−p−1 , with 1 < p < 5.
So in a symmetric patch all sides have an equal length and in a nearsymmetric
patch all sides except one have an equal length and that one side is just one shorter
than the others.
Theorem 3.1. All cones with 1 or 5 pentagons contain a symmetric patch, and all
cones with 2, 3 or 4 pentagons contain a symmetric or a nearsymmetric patch.

334

Table 14. The complete classification of cone patches.

25 = (2(23)0 )5

2(23)1 (2(23)2)2

(2(23)1 )4

(2(23)2 )2

2(23)0(2(23)1 )3

2(23)2 2(23)3

(2(23)1 )3

2(23)5

This result was first established in [5]. Here we sketch a proof that is not only
shorter but can also easily be generalized to other periodic structures.
We interpret a nanocone as a disordered graphite lattice. Choosing a path
around all disordering pentagons in the cone (described by right and left turns)
and repeating the first edge at the end, and then following this path in the graphite
lattice, the first and last edge in the resulting path don’t agree anymore. It can be
shown that the first edge and the last edge can be mapped onto each other by a symmetry of the lattice which is in fact a rotation by p ∗ 60◦ . This method to classify
disordered patches was invented in [4], extended in [2] and in [1] it was shown that
(under the circumstances described here), two disorders of the same tiling are isomorphic – except for a finite region – if and only if these symmetries are equivalent.
Two rotations are said to be equivalent when they rotate among the same angle, and
the centers of rotation are equivalent under a symmetry of the tiling.

335

In our case there are only a limited number of possibilities for these symmetries.
They are all rotations and are depicted in Table 14. The patches in Table 14 are
patches that correspond to these symmetries.
It is easily proven that adding or removing layers of hexagons does not change the
type of the boundary, i.e. whether the boundary is symmetric or nearsymmetric.
So together with the theorem of Balke, this proves that all cones are equivalent to
one of the cones obtainable from the patches in Table 14.
It also follows from Table 14 that no cone contains a symmetric and a nearsymmetric patch which both contain all the pentagons in the cone, because such boundaries
correspond to different automorphisms.
Choosing the boundary that exists due to Theorem 3.1 in a shortest way leads to a
unique patch that fully describes the nanocone.
In fact this classification even leads to a unique patch, so we have the following
theorem.
Theorem 3.2. There is a 1-1 correspondence between the set of symmetric and
nearsymmetric patches and the set of nanocones.
An algorithm to generate these patches will be sketched in the talk. It was
implemented and tested against an independent algorithm to verify the results.
References
[1] Ludwig Balke, Classification of Disordered Tilings, Annals of Combinatorics
1, 1997, pp.297–311.
[2] G. Brinkmann, Zur mathematischen Behandlung gestrter Pflasterungen,
Ph.D. thesis, University of Bielefeld, 1990.
[3] G. Brinkmann, U. von Nathusius and A.H.R. Palser, A constructive enumeration of nanotube caps., Discrete Applied Mathematics 116, 2002, pp. 55–71.
[4] A.W.M. Dress, On the Classification of Local Disorder in Globally Regular
Spatial Patterns., Temporal Order, Synergetics 29 Springer, 1985, pp. 61–66.
[5] D.J. Klein, Topo-combinatoric categorization of quasi-local graphitic defects,
Phys. Chem. Chem. Phys. 4, 2002, pp.2099–2110.

336

The Molecular Distance Geometry Problem
Applied to Protein Conformations
A. Mucherino, a C. Lavor, b N. Maculan c
a LIX,

École Polytechnique, Palaiseau, France
mucherino@lix.polytechnique.fr
b Dept.

of Applied Mathematics (IMECC-UNICAMP), State University of Campinas,
Campinas-SP, Brazil
clavor@ime.unicamp.br

c Federal

University of Rio de Janeiro (COPPE–UFRJ), C.P. 68511, 21945-970, Rio de
Janeiro - RJ, Brazil
maculan@cos.ufrj.br

Key words: distance geometry, protein molecules, branch and prune

Molecules are sets of atoms that bond to each other forming particular threedimensional structures, which can reveal important features of the molecules. One
of the most used approaches to discover these structures is based on the Nuclear
Magnetic Resonance (NMR). This is an experimental technique which is able to
detect the distances between particular pairs of atoms of the molecule. Once a subset of distances between atoms has been obtained, the problem of identifying the
coordinates of the considered atoms is known as the M OLECULAR D ISTANCE G E OMETRY P ROBLEM (MDGP) [3].
Many researchers worked on this problem and proposed different approaches.
The most common approach is to formulate the MDGP as a continuous global
optimization problem, in which the function to be minimized is a penalty function
monitoring how much the known distances are violated in possible conformations
of the atoms of the molecule. One of the most used objective functions is the Largest
Distance Error (LDE):
LDE({x1 , x2 , . . . , xn }) =

1 X ||xi − xj || − dij
,
|m| {i,j}
dij

where {x1 , x2 , . . . , xn } represents a conformation, dij is the known distance between the atom xi and the atom xj and m is the total number of known distances.
If the subset of given distances is feasible, then the value of the LDE function in
correspondence with a solution is 0.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

We are studying a particular subclass of instances of the MDGP for which
a combinatorial formulation can be supplied. Let G = (V, E, d) be a weighted
undirected graph, where V represents the set of atoms, edges in E indicate that
the distances between the connected atoms are known, and the weights d represent
the numeric value of the distances. As shown in [4; 5; 6; 7], if the following two
assumptions are satisfied
(i) E contains all cliques on quadruplets of consecutive atoms,
(ii) consecutive vertices cannot represent perfectly aligned atoms,
for a given order in G, then the MDGP can be formulated as a combinatorial problem. We refer to this problem as the D ISCRETIZABLE M OLECULAR D ISTANCE
G EOMETRY P ROBLEM (DMDGP).
The DMDGP is NP-complete [4]. Moreover, it is interesting to note that the assumption (i) in the definition of the DMDGP is the tightest possible for the problem
to be NP-complete. If E contains all cliques on quintuplets, and not only quadruplets, of consecutive atoms, then G is a trilateration graph. By [2], the MDGP
associated to a trilateration graph can be solved in polynomial time. Therefore,
graphs having cliques on sequences of 4 consecutive vertices correspond to an
NP-complete problem, whereas graphs with cliques on sequences of 5 consecutive vertices bring to easy-to-solve problems. There is a sort of barrier after which
the DMDGP becomes simple to solve. This is very interesting, because, when data
from biology are considered, the corresponding DMDGP approaches to this barrier,
but it is not able to go beyond and to be classified as an easy-to-solve problem.
We are particularly interested in protein molecules. Proteins are formed by
smaller molecules called amino acids, that bond to each other by forming a sort of
chain. Because of their particular structure, the MDGP related to protein molecules
can be formulated as a combinatorial problem, because the aforementioned assumptions are satisfied, in most of the cases. Instances used to test the performances
of approaches to the MDGP are usually artificially generated from the known conformations of some proteins. In [1; 8], for example, the used instances are generated
by computing the distances between all the possible pairs of atoms of the molecule,
and by keeping only the distances smaller than 6Å. This simulates instances obtained by NMR, because this technique is able to detect only distances which are
not larger than 6Å. Currently, our attention is focused on protein backbones only,
and therefore, in previous works, the considered atoms are limited to the backbone
atoms only. In particular, the sequence of atoms N−Cα −C, defining the backbone
of a protein, is considered.
A B RANCH & P RUNE (BP) algorithm [4] is used for solving the combinatorial problem efficiently (Algorithm 1). It is based on the exploration of a binary tree
containing solutions to the problem. During the search, branches of the binary tree
are pruned as soon as they are discovered to be infeasible. This pruning phase helps

338

Algorithm 1 The BP algorithm.
0: BP(i, n, d)
for (k = 1, 2) do
compute the k th atomic position for the ith atom: xi ;
check the feasibility of the atomic position xi :
if (| ||xi − xj || − dij | < ε, ∀j < i) then
the atomic position xi is feasible;
if (i = n) then
a solution is found;
else
BP(i + 1,n,d);
end if
else
the atomic position xi is pruned;
end if
end for
in reducing the binary tree quickly, so that an exhaustive search of the remaining
branches is not computationally expensive. The computational experiments presented in [4; 6; 7] showed that the combinatorial approach can provide much more
accurate solutions to the problem.
Our final aim is to be able to solve instances containing real data (i.e. data
obtained by NMR) by the combinatorial approach. This is not trivial. Indeed, the
artificially generated instances used in the experiments are still far from instances
obtained by NMR. Indeed, the NMR is able to identify distances between hydrogen
atoms only. Therefore, instances generated as explained above simulate real data
only because of the rule of the 6Å threshold, but not for the kind of considered
atoms.
Let us suppose that the sequence of atoms N−Cα −C (defining the protein
backbones) and all the hydrogens H bonded to such atoms are considered. Let G =
(V, E, d) be the associated weighted undirected graph. Since only hydrogens are
detected by NMR, there is an edge between two vertices only if both the vertices
refer to hydrogens, or if one vertex represents a hydrogen and the other one is the
carbon or the nitrogen bonded to it (bond lengths are known a priori). It follows
that the subgraph GH , such that G ⊃ GH = (VH , EH , dH ) and containing all the
vertices in V to which at least two edges are associated, refers to hydrogen atoms
only. Given an order on the vertices in VH for which the assumptions (i) and (ii)
are satisfied, the MDGP can be formulated as a DMDGP, and solved by the BP
algorithm. From a chemical point of view, however, the solutions provided by BP
are incomplete in this case, because they provide the coordinates of the hydrogen
atoms only, whereas the sequence N−Cα −C is of interest. The problem is to find
the coordinates of the atoms associated to the vertices of G − GH by exploiting
the coordinates of the atoms associated to the vertices of GH , and some distances

339

between pairs of vertices (v, vH ), where v ∈ V − VH and vH ∈ VH . Suitable
strategies for solving this problem are currently under investigation.
Acknowledgments
The authors would like to thank the Brazilian research agencies FAPESP and
CNPq, the French research agency CNRS and École Polytechnique, for financial
support. The authors also thank Leo Liberti for the fruitful comments to this work.
References
[1] P. Biswas, K.-C. Toh, and Y. Ye, A Distributed SDP Approach for LargeScale Noisy Anchor-Free Graph Realization with Applications to Molecular
Conformation, SIAM Journal on Scientific Computing 30, 1251–1277, 2008.
[2] T. Eren, D.K. Goldenberg, W. Whiteley, Y.R. Yang, A.S. Morse, B.D.O. Anderson and P.N. Belhumeur, Rigidity, Computation, and Randomization in
Network Localization, IEEE Infocom Proceedings, 2673–2684, 2004.
[3] T.F. Havel, Distance Geometry, D.M. Grant and R.K. Harris (Eds.), Encyclopedia of Nuclear Magnetic Resonance, Wiley, New York, 1701-1710, 1995.
[4] C. Lavor, L. Liberti, and N. Maculan, Discretizable Molecular Distance Geometry Problem, Tech. Rep. q-bio.BM/0608012, arXiv, 2006.
[5] C. Lavor, L. Liberti, A. Mucherino, and N. Maculan, Recent Results on the
Discretizable Molecular Distance Geometry Problem, Proceedings of the
Conference ROADEF09, Nancy, France, February 10–12, 2009.
[6] C. Lavor, L. Liberti, A. Mucherino and N. Maculan, On a Discretizable Subclass of Instances of the Molecular Distance Geometry Problem, Proceedings
of the Conference SAC09, Honolulu, Hawaii, March 8–12, 2009.
[7] L. Liberti, C. Lavor, and N. Maculan, A Branch-and-Prune Algorithm for the
Molecular Distance Geometry Problem, International Transactions in Operational Research 15 (1), 1–17, 2008.
[8] D. Wu and Z. Wu, An Updated Geometric Build-Up Algorithm for Solving the
Molecular Distance Geometry Problem with Sparse Distance Data, Journal
of Global Optimization 37, 661–673, 2007.

340

Protein Threading
Guillaume Collet, a Rumen Andonov, b Nikola Yanev, c
Jean-François Gibrat b
a Symbiose
b INRA,

team, IRISA, Campus de Baulieu, 35042 Rennes, France

Unité Mathématique, Informatique et Génome UR1077, F-78352 Jouy-en-Josas
Cedex, France

c Faculty

of Mathematics and Informatics, University of Sofia, 1164 Sofia, 5 James
Bourchier Blvd., Bulgaria

Key words: Integer programming, combinatorial optimization, protein threading problem,
protein structure alignment

1. Introduction

The most important in silico methods, to exploit the amount of new genomic
data, are based on the concept of homology. The principle of homology-based analysis is to identify a homology relationship between a new protein and a protein
whose function is known. For remote homologs, sequence alignment methods fail.
In such a case one aligns the sequence of a new protein with the 3D structures of
known proteins. Such methods are called fold recognition methods or threading
methods.
Lathrop & Smith [1] were the first to propose an algorithm based on a branch
& bound technique providing the global alignment with the optimal score and to
prove the problem to be NP-Hard. Since then, other methods have been developed
that improved the efficiency of the sequence – structure global alignment algorithm
([2; 3; 4]).
This paper describes a new algorithm that expands upon algorithms proposed
in previous works ([3; 4]) to allow implementation of local sequence – structure
alignments. This allows threading methods to cover the whole spectrum of alignment types needed to analyze homologous proteins.
Our definition of alignments is based on the definition of the Protein Threading
Problem (PTP) given in [1].

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. Outline of the Protein Threading Problem

Query Sequence and Structure Template: A query sequence is a string of
length N over the 20-letter amino acid alphabet. A structure template is an ordered
set M of m blocks which correspond to the secondary structure elements (SSEs).
Block k has a fixed length of Lk amino acids. Let I ⊆ {(k, l) | 1 ≤ k < l ≤ m} be
the set of blocks interactions.
Alignment: An alignment of a structure template with a query sequence corresponds to positioning blocks of the template along the sequence. A global alignment requires that all blocks are aligned, preserve their order, and do not overlap.
This alignement has been modelized by mixed integer programming (MIP) approach in [2; 3]. In this paper, we extent the model presented in [3].

3. Local alignments : towards better PTP models

Global alignment assumes that all blocks are aligned with the query sequence.
However, it sometimes happens that some members of a protein family do not share
exactly the same number of SSEs. An alignment which permits to omit blocks is
called a local alignment. To solve this local alignment, we propose two models:
(1) A compact model (CM) where we modify constraints to omit blocks. (2) An
extended model (EM) where we add dummy positions for each block. When a
dummy position is chosen, the block is omitted. These models are described very
briefly below. For more details, the interested reader can refer to our research report
[5].

3.1 Compact model
We define a digraph G(V, A) with vertex set V and arc set A. Each vertex
(i, k) ∈ V represents block k at position i along the sequence. A block k can take
nk = N − Lk + 1 positions along the query sequence. A cost Cik (resp. Dikjl ) is
associated to each vertex (i, k) (resp each arc ((i, k), (j, l))). Let yik (resp. zikjl ) be
binary variables associated with vertices (resp. arcs). Based on these notations, we
obtain the following model:

max

nk
m X
X

k=1 i=1

Cik yik +

X

((i,k),(j,l))∈A

342

Dikjl zikjl

(3.1)

Subject to:
yik ∈ {0, 1},
0 ≤ zikjl ≤ 1,
nk
X
i=1

nl
X

j=i+Lk

yik ≤ 1,

zikjl − yik ≤ 0,

k ∈ M, i ∈ [1, n]
((i, k), (j, l)) ∈ A

(3.2)
(3.3)

k∈M

(3.4)

(k, l) ∈ I, i ∈ [1, nk ]

(3.5)

(k, l) ∈ I, j ∈ [1, nl ]

(3.6)

1 ≤ k ≤ l ≤ m, i ∈ [1, nk ]

(3.7)

(k, l) ∈ I

(3.8)

min(j−Lk ,nk )

X

zikjl − yjl
i=1
min(nk ,i+Lk −1)

yik +

X

j=1
nk
X

yik +

nl
X
i=1

i=1

yil −

nl
X

j−L
Xk

j=Lk +1 i=1

≤ 0,

yjl ≤ 1,

zikjl ≤ 1,

Constraints (3.4) allow a block be aligned or not. Constraints (3.5) and (3.6) allow
an arc, leaving (resp. entering) an activated vertex, be activated or not. Constraints
(3.7) preserve the order of blocks. Finaly, constraints (3.8) coerce the activation of
an arc if its vertices are activated.
3.2 Extended Model
Denote by dik , i ∈ [1, N], k ∈ [1, m] a variable which we call dummy variables. The objective function is given by (3.1). This model uses constraints (3.2),
(3.3), (3.5), (3.6) and (3.8). Additional constraints are the following:

j
X

min(j,nk )

dik +

i=1

X
i=1

yik −

j
X
i=1

nk
X

dik ∈ {0, 1} k ∈ M, i ∈ [1, nk ] (3.9)
yik +

N
X

i=1
i=1
j−Lk−1

dik−1 −

X
i=1

dik = 1

k ∈ M (3.10)

yi(k−1) ≤ 0 k ∈ [2, m], j ∈ N (3.11)

Constraints (3.10) state that exactly one vertex (either real or dummy), must be
activated in a column. Constraints (3.11) preserve the order of the blocks.

4. Results

Two indicators have been used, computation time and the relative gap (RG)
between the solution of the relaxed problem (LP ) and the optimal solution (OP T ):
343

−OP T
. RG is a good indicator of the efficiency of the model since the
RG = LPOP
T
smaller RG, the easier for the branch & bound algorithm to find the solution.

Fig. 1. Comparison of the computation times obtained

−OP T
) beFig. 2. Comparisons of relative gaps ( LPOP
T

by EM and CM. Each point represents an alignment.

tween models EM and CM. Each point is a sequence –

Times are expressed in seconds and are plotted using a

structure alignment.

base 10 logarithm scale.

Figure 1 shows that EM is faster than CM for 99% of the instances. Moreover,
Figure 2 shows that EM always gives a smaller RG than CM. It must be noted that
LP relaxation directly gives the integer solution in 41% of the cases for the CM
model and 52% of the cases for the EM model.

References
[1] R.H. Lathrop and T.F. Smith. Global optimum protein threading with gapped
alignment and empirical pair potentials. Journal of Molecular Biology
255:641-665 (1996).
[2] J. Xu, et al. RAPTOR: optimal protein threading by linear programming.
Journal of Bioinformatics and Computational Biology 1(1):95-118 (2003).
[3] R. Andonov, et al. Protein Threading Problem: From Mathematical Models to
Parallel Implementations. INFORMS Journal on Computing 16(4):393:405
(2004).
[4] R. Andonov, et al. Recent Advances in Solving the Protein Threading Problem. Grids for Bioinformatics and Computational Biology, E-G. Talbi and A.
Zomaya, editors. Chapter 14, pages 325-356. Wiley-Interscience (2007)
[5] Collet G., et al. Flexible Alignments for Protein Threading. INRIA Research
Report, RR-6808 (2009).

344

Clustering

Lecture Hall B

Thu 4, 14:00–15:30

Cardinality Constrained Graph Partitioning into
Cliques with Submodular Costs
J.R. Correa, a N. Megow, b R. Raman, b K. Suchan c
a Departamento

de Ingenierı́a Industrial, Universidad de Chile, Chile
correa@dim.uchile.cl

b Max-Planck-Institut

für Informatik, Saarbrücken, Germany
{nmegow, rraman}@mpi-inf.mpg.de

c Universidad

Adolfo Ibáñez, Facultad de Ingenierı́a y Ciencias, Chile
karol.suchan@uai.cl

Key words: graph partitioning, cardinality constraint, submodular functions

1. Introduction

We consider the problem of partitioning a graph into cliques of bounded cardinality. The goal is to find a partition that minimizes the sum of clique costs where
the cost of a clique is given by a set function on the nodes. We present a general
algorithmic solution based on solving the problem variant without the cardinality
constraint. We yield constant factor approximations depending on the solvability
of this relaxation for a large class of submodular cost functions. We give optimal
algorithms for special graph classes.
More formally, we are given a simple graph G = (V, E), a set function f : 2V → R+ , and a bound B ∈ Z+ . The problem is to find a partition
of the graph G into cliques K1 , . . . , K` (the value of ` is not part of the input)
of size at most B, that is, |Ki | ≤ B, i = 1, . . . , `, such that the objective funcP
tion `i=1 f (Ki ) is minimized. We denote our problem as partition into cliques of
bounded size PCliq(G, f, B).
Let V be a finite set. The function f : 2V → R is called submodular if for
all subsets A, B ⊆ V holds f (A) + f (B) ≥ f (A ∪ B) + f (A ∩ B). We consider
non-negative submodular functions that satisfy the following exchange properties.
For all subsets A, B ⊆ V with f (A) ≥ f (B) and elements u, v ∈ V \ (A ∪ B)
with f (u) ≥ f (v) holds
f (A + u) + f (B + v) ≤ f (A + v) + f (B + u) .

(E1)

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Moreover, for all sets A, B ⊆ V such f (A) ≥ f (B) and all elements u ∈ V \ (A ∪
B), holds that
f (A + u) ≥ f (B + u).
(E2)
This class of set functions contains well-known cost functions such as maximum
function [7], chromatic entropy [2], probabilistic coloring [3], etc.
The problem PCliq(G, f, B) is generally N P-hard because it contains the classic N P-hard problems partition into cliques (or clique cover) and graph coloring [5]. If the bound on the clique size B equals 2 then the problem corresponds
to a maximum cardinality matching problem in G and can be solved optimally in
polynomial time.
Graph partitioning and coloring problems (without cardinality constraints) are
among the fundamental problems in combinatorial optimization. Various results are
known for particular cost functions and graph classes. Recently, also generalized set
functions have been considered in this context. Gijswijt, Jost, and Queyranne [6]
introduce value-polymatroidal set functions which are polymatroid rank functions
(i.e. nondecreasing, submodular, and f (∅) = 0) that satisfy a slightly weaker exchange property than we require above. For every A, B ⊆ V such that f (A) ≥
f (B) and every u ∈ V \ (A ∪ B), holds that f (A + u) + f (B) ≤ f (A) + f (B + u).
They consider the problem PCliq(G, f, ∞) and derive polynomial time algorithms
for interval graphs and circular arc graphs. Fukunaga, Halldorsson, and Nagamochi [4] consider monotone concave cost functions and provide a general algorithmic scheme which yields a factor 4 approximation for perfect graphs. They
also give a result for general graphs depending on the solvability of the maximum
independent set problem on the complement of the graph.
Graph partitioning (or coloring) with a constraint on the clique size has been
addresses rarely so far. Bodlaender and Jansen [1] investigated a special case
of PCliq(G, f, B) with the objective to minimize the number of cliques, that is,
f (S) = 1 for all S ⊆ 2V . They show that the decision variant of the problem on
co-graphs is N P-complete whereas it is polynomial time solvable on split graphs,
bipartite graphs and interval graphs.

2. Our Results

2.1 Optimal algorithm for complete graphs and proper interval graphs
Consider the problem PCliq(K, f, B) on a complete graph K. The following
simple algorithm solves the problem optimally.
Algorithm PART K

348

Order elements u ∈ K in non-increasing order of f (u) and group them greedily
into sub-cliques of size B beginning with the elements of largest value.
Theorem 2.1. PART K solves the problem PCliq(K, f, B) on a clique K for submodular functions with exchange property optimally in polynomial time.
The exchange properties are indeed substantial to the result above. The problem of partitioning a complete graph is generally N P-hard for submodular functions, and even for polymatroid rank functions.
Theorem 2.2. The problem PCliq(K, f, B) on a clique K is NP-hard even if we
restrict f to polymatroid rank functions, that is, non-decreasing, submodular functions with f (∅) = 0.
Proof 1. Reduction from graph partitioning with unit node weights [5].
Additionally, we devise a dynamic program that solves the problem optimal
for another special graph class.
Theorem 2.3. The problem PCliq(G, f, B) on a proper interval graph G can be
solved optimally in pseudopolynomial time for submodular functions with exchange property. If the number of distinct values for single elements f (u) for
all u ∈ V is bounded, then this algorithm runs in polynomial time.
2.2 An (c + 1)−approximation for general graphs
Our algorithmic framework is based on solving two relaxation of the given
problem PCliq(G, f, B). One relaxation concerns ignoring the graph structure, i.e.,
PCliq(K, f, B) for K being a complete graph as considered above. In the other relaxation we assume that the cardinality of the cliques is not bounded, or B ≥ |V |.
We denote it as PCliq(G, f, ∞). Optimal values for both relaxations considered individually may give arbitrarily bad lower bounds on an optimum solution. Still, we
derive constant factor approximation guarantees when combining them. Consider
the following polynomial time algorithm.
Algorithm PART
(i) Solve the relaxation PCliq(G, f, ∞) without cardinality restrictions.

(ii) For all cliques Ki : Solve the problem PCliq(Ki , f, B).

Theorem 2.4. Let f be a submodular function with exchange property. If there
exists a c-approximation algorithm for the problem PCliq(G, f, ∞) without cardinality constraint, then PART is a (c + 1)−approximation for PCliq(G, f, B).
Sketch of Proof:

Let K1 , . . . , K` be the solution of the relaxed problem
349

PCliq(G, f, ∞). For each of the cliques Ki let Ki1 , . . . , Ki`i denote the partition into
subcliques (Step 2). Assume that all sets are indexed such that f (Kij ) ≥ f (Kij+1 )
for j = 1, . . . , `i − 1. Then the value of the algorithms solution is
PART =

`i
X̀ X

i=1 j=1

f (Kij )

=

X̀

f (Ki1 )

+

i=1

≤ c O PT (G, f, ∞) +

`i
X̀ X

f (Kij )

i=1 j=2

`i
X̀ X

f (Kij ) .

i=1 j=2

P

P

i
The main effort lies in proving `i=1 `j=2
f (Kij ) ≤ O PT (K, f, B). We first
observe: For two sets A, B ⊆ V with |A| ≥ |B| holds that if each element v ∈ B
can be mapped to a distinctive element in u ∈ A such that f (v) ≤ f (u),
then f (A) ≥ f (B). This fact combined with Algorithm PART K and Theorem 2.1
allows us to apply a charging scheme where we map the elements of the cliques Kij
with i > 1 to the optimal solution.

Since the set functions we consider are value-polymatroidal, can employ the
optimal algorithm in [6] and yield a quite general result for interval graphs which
are of particular interest in applications.
Corollary 2. There is a factor 2 approximation algorithm for PCliq(G, f, B) on
interval graphs and circular arc graphs.

References
[1] H. L. Bodlaender and K. Jansen. Restrictions of graph partition problems.
Part I. Theoretical Computer Science, 148(1):93–109, 1995.
[2] J. Cardinal, S. Fiorini, and G. Joret. Minimum entropy coloring. J. Comb.
Optim., 16(4):361–377, 2008.
[3] F. D. Croce, B. Escoffier, C. Murat, and V. T. Paschos. Probabilistic coloring
of bipartite and split graphs. In ICCSA (4), volume 3483 of Lecture Notes in
Computer Science, pages 202–211, 2005.
[4] T. Fukunaga, M. M. Halldórsson, and H. Nagamochi. Robust cost colorings.
In SODA’08, pages 1204–1212, 2008.
[5] M. R. Garey and D. S. Johnson. Computers and Intractability, A Guide to the
Theory of NP-Completeness. W.H. Freeman and Company, New York, 1979.
[6] D. Gijswijt, V. Jost, and M. Queyranne. Clique partitioning of interval graphs
with submodular costs on the cliques. RAIRO Oper. Res., 41:275–287, 2007.
[7] S. V. Pemmaraju and R. Raman. Approximation algorithms for the maxcoloring problem. In ICALP’05, volume 3580 of Lecture Notes in Computer
Science, pages 1064–1075, 2005.

350

A simple MAX - CUT algorithm for planar graphs ?
F. Liers, a G. Pardella a
a Institut

für Informatik, Universität zu Köln, Pohligstraße 1, D-50969 Köln, Germany
{liers,pardella}@informatik.uni-koeln.de

Key words: max-cut, planar graph, combinatorial algorithm, Kasteleyn city

Graph partitioning problems have many relevant real-world applications, e.g.,
VIA minimization in the layout of electronic circuits [1], or in physics of disordered systems [2]. In its most basic version, the task is to partition the nodes of a
graph into two disjoint sets such that the weight of edges connecting the two sets is
either minimum or maximum (assuming uniform weights in case the graph is unweighted). For general edge weights, the MAX - CUT problem is NP-hard. When restricting to certain graph classes, polynomial-time solution algorithms are known.
This is true especially for planar graphs which are the subject of this extended
abstract. In 1990 Shih, Wu, and Kuo [7] presented a mixed MAX - CUT algorithm
for arbitrary weighted planar graphs. They solve the problem in time bounded by
3
O(|V | 2 log |V |) which is the best worst-case running time known to date. First,
the dual graph is constructed which is then expanded in such a way that (optimum)
matchings in the latter correspond to (optimum) cuts in the former. In this work, we
follow this general algorithmic scheme which leads to an algorithm with the same
3
worst-case running time O(|V | 2 log |V |). However, in our procedure the expanded
dual graph has a simpler structure and contains a considerably smaller number of
both nodes and edges. As the bulk of the running time is spent in the matching computation and the latter scales with the size of the graph, our algorithm is much faster
in practice. Our new MAX - CUT algorithm for arbitrary weighted planar graphs is
a generalization of the methods proposed in [8; 6] which are based on the work
of Kasteleyn [3] from the 1960s. This extended abstract bases upon a technical report [4] in which we both describe the algorithm in detail and present experimental
results.
? Financial support from the German Science Foundation is acknowledged under contract
Li 1675/1-1

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

1. The MAX-CUT Algorithm
In the following we assume we are given a planar embedding of G. At first, we
calculate its dual graph GD = (VD , ED ), where the weight of a dual edge is chosen
as w(ẽ) = w(e) if ẽ ∈ ED is the dual edge crossed by e ∈ E. Subsequently, we
split all dual nodes ṽ ∈ VD with degree deg(ṽ) > 4 into b(deg(ṽ) − 1)/2c nodes
and connect the copies by a path of new edges receiving zero weight. Let split
nodes denote nodes created by a splitting operation. Edges incident to the original
node are equally distributed among the split nodes such that the degree of each
node is at most four. We denote the resulting graph by Gt = (Vt , Et ). It is easy
to see that after the splitting operations, no node in Gt has a degree smaller than
three or larger than four. The connectedness of G and GD yields connectedness
of Gt . Next, we expand each node in Gt to a K4 subgraph (a so-called Kasteleyn
city). Newly generated edges again receive weight zero, while edge weights from
Gt are assigned to the corresponding edges in the expanded graph. We denote the
resulting graph by GE . Next, we calculate a minimum-weight perfect matching M
Algorithm 1 MAX - CUT algorithm for planar graphs
Require: Embedding of a simple, connected planar graph G
Ensure: MAX-CUT δ(Q) of G
1. Build dual graph GD
2. Split each node v ∈ GD with deg(v) > 4 and call resulting graph Gt
3. Expand each node v ∈ Gt to a K4 and call resulting graph GE
4. Compute a minimum-weight perfect matching M in GE
5. Shrink back all artificial nodes and edges while keeping track of matched dual
edges
6. Matched dual edges in GD induce optimum Eulerian subgraphs and thus optimum max-cut δ(Q) of G
7. return δ(Q)
in GE . Subsequently, we undo the expansion, i.e., shrink back all K4 subgraphs
and all (possibly created) split nodes, while keeping track of matched dual edges.
Consider the subgraph of GD induced by the matching edges that are still present
in the dual after shrinking. Each node in this subgraph has even degree. Therefore,
it is a minimum weight Eulerian graph. It is well known that there is a one-toone correspondence between Eulerian subgraphs in the dual and cuts in its primal
graph, see also Alg. 1 for a compact statement of the algorithm.
In order to prove correctness of the algorithm, we need to show that there
always exists a perfect matching M in the expanded graph GE . Then, we need
to prove that the constructed perfect matching in GE induces a subgraph in the
dual in which all node degrees are even. We first show the latter. We call edges
not contained in a K4 outgoing and count the number of matched outgoing edges
on some K4 for an arbitrary perfect matching in GE . Clearly, any possible perfect
matching in a K4 subgraph leads to either zero, two or four outgoing matching
352

edges. An odd number of outgoing matching edges always leaves an odd number of
K4 nodes unmatched, which contradicts the matching’s perfectness. Shrinking back
the artificial nodes to the corresponding split nodes does not affect the number of
outgoing matching edges. Consequently, after having collapsed all split nodes back
to its dual nodes, each dual node has an even number of adjacent matching edges,
too. Hence the matching induced subgraph is Eulerian and therefore defines a cut
δ(Q) in the original graph G. Let w(M) be the weight of a minimum-weight perfect
matching in GE , which is the same weight of the Eulerian subgraph, therefore the
weight of the induced Eulerian subgraph is minimum, and thus the weight of the
cut δ(Q), too. We summarize this in the next theorem.
Theorem 17. The algorithm described above computes a MIN - CUT (or MAX - CUT)
in an arbitrarily weighted planar graph.
The proof that the expanded graph GE indeed has a perfect matching M is based on
the following observations. GE is connected and has an even number of nodes. A
trivial perfect matching exists as in each K4 all nodes can be covered by matching
edges contained in the K4 . Therefore, a perfect matching in GE always exists.
There also always exists another perfect matching in which not only artificial edges
contained in the K4 subgraphs are matched. This is reasonable due to the structure
of the dual graph GD , as any two adjacent nodes in GD are connected by at least
one simple cycle that is preserved during the expansion step. A possible nontrivial
perfect matching in Gt may consist of those cycle edges and additionally of some
artificial edges in each K4 subgraph on the cycle. For all other Kasteleyn cities,
edges contained in the K4 can be matched.
For establishing running time bounds, we start with a given embedding of a
planar graph. The geometric dual can be constructed in time O(|V |). Furthermore,
the described expansion of the dual graph can be done in time linear in |V |, and
only O(|V |) new nodes (edges) are created. Next, the most time consuming step
is performed - the calculation of a minimum-weight perfect matching. Using a
maximum-weight matching algorithm by Lipton and Tarjan [5], based on the planar separator theorem, together with an appropriate weight-function, the calcula3
tion of the minimum-weight perfect matching needs time O(|V | 2 log |V |). Finally,
all nodes blown up in the expansion are shrunk back in time O(|V |). With these
considerations, we state the following theorem.
Theorem 18. Using the method described above, a MIN - CUT (or MAX - CUT) in a
3
planar graph can be determined in time bounded by O(|V | 2 log |V |).
Space may become a crucial factor especially for large input graphs. Our
method is less space demanding than the construction of [7]. This is important
as the matching part depends on the graph size and is the bottleneck in the algorithm. The latter implies that our algorithm is faster in practice. Let F denote the
set of faces of a maximum planar graph. Our method constructs a graph GE with

353

at most |VE | = 4|F | = 4(2|V | − 4) nodes, and 6|F | + |ED | = 15|V | − 30 edges.
The procedure by [7] generates for each dual node a “star” subgraph of seven nodes
and nine edges. Thus yields an expanded dual graph with 7(2|V | − 4) nodes and
21|V | − 42 edges. These bounds are sharp as the first step of Shih, Wu, and Kuo
is always a triangulation of the graph. Our procedure, in comparison, computes a
matching on a much smaller and sparser graph, even in the case the graph is a triangulation. Moreover, the practical running time of the method stated in [7] might
increase, as the matching induced even-degree edge set may be empty in which
case an additional O(|V |) time step is needed to compute a nontrivial even-degree
edge set.
It turns out that with our implementation of the presented algorithm we can
compute MAX - CUTS in planar graphs with up to 106 nodes within reasonable time.

References
[1] BARAHONA , F., G R ÖTSCHEL , M., J ÜNGER , M., AND R EINELT, G. An application of combinatorial optimization to statistical physics and circuit layout
design. Operations Research 36, 3 (1988), 493–513.
[2] H ARTMANN , A. K., AND R IEGER , H. Optimization Algorithms in Physics.
Wiley-VCH, 2002.
[3] K ASTELEYN , P. W. Dimer statistics and phase transitions. Journal of Mathematical Physics 4, 2 (1963), 287–293.
[4] L IERS , F., AND PARDELLA , G. A simple max-cut algorithm for planar
graphs. Tech. rep., Combinatorial Optimization in Physics (COPhy), Sep.
2008, http://www.zaik.uni-koeln.de/˜paper/preprints.html?show=zaik2008579.
[5] L IPTON , R. J., AND TARJAN , R. E. Applications of a planar separator theorem. SIAM J. Comput. 9, 3 (1980), 615–627.
[6] PARDELLA , G., AND L IERS , F. Exact ground states of large two-dimensional
planar Ising spin glasses. Physical Review E (Statistical, Nonlinear, and Soft
Matter Physics) 78, 5 (2008), 056705.
[7] S HIH , W. K., W U , S., AND K UO , Y. S. Unifying maximum cut and minimum cut of a planar graph. IEEE Trans. Comput. 39, 5 (1990), 694–697.
[8] T HOMAS , C. K., AND M IDDLETON , A. A. Matching Kasteleyn cities for
spin glass ground states. Physical Review B (Condensed Matter and Materials
Physics) 76, 22 (2007), 220406(R).

354

k-hyperplane clustering problem: column generation
and a metaheuristic
Edoardo Amaldi, a Stefano Coniglio, a Kanika Dhyani b
a Dipartimento

di Elettronica e Informazione, Politecnico di Milano
Piazza L. da Vinci 32, 22133, Milano
{amaldi,coniglio}@elet.polimi.it
b Neptuny,

Politecnico di Milano
Via G. Durando 10, 20158, Milano
dhyani@elet.polimi.it

Key words: hyperplane clustering, column generation, metaheuristic

1. Introduction
In the k-Hyperplane Clustering problem (k-HC), given a set of m points P =
{a1 , . . . , am } in Rn , we have to determine k hyperplanes Hj = {a ∈ Rn | wTj a =
γj , wj ∈ Rn , γj ∈ R}, with 1 ≤ j ≤ k, and assign each point to a single Hj ,
thus partitioning P into k h-clusters, so as to minimize the sum-of-squared 2-norm
orthogonal distances dij from each point to the corresponding hyperplane, where
|wT a −γj |
.
dij = j w i
k j k2
k-HC naturally arises in many areas such as data mining [3], operations research [7], line detection in digital images [2] and piecewise linear model fitting [4].
k-HC is N P-hard, since it is N P-complete to decide whether k lines can fit m
points in R2 with zero error [7]. In [3] Bradley and Mangasarian propose a heuristic for k-HC which extends the classical k-means algorithm to the hyperplane case.
The bottleneck version of k-HC in which, given a maximum deviation tolerance , k is minimized, has been studied in [5]; it is closely related to the M IN PFS problem of partitioning an infeasible linear system into a minimum number
of feasible subsystems [2]. Variants of k-HC where linear subspaces of different
dimensions are looked for are also considered, e.g., in [1].
In this work we propose a column generation algorithm and an efficient metaheuristic.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. Column generation algorithm (CG)

We consider the following set covering master problem (MP):
min

X

ds y s

(2.1)

s∈S

s.t.

X

s∈S

x̃is ys ≥ 1

s∈S

ys ≤ k

X

1≤i≤m

(2.2)
(2.3)

ys ∈ {0, 1}

s ∈ S,

where S is the set of (exponentially many) feasible h-clusters and, for each s ∈ S,
the variable ys equals 1 if the h-cluster s is in the solution and 0 otherwise. The
parameter ds is the sum-of-squared 2-norm orthogonal distances to the hyperplane
Hs of the points contained in the h-cluster s and the parameter x̃is equals 1 if the
point ai is contained in h-cluster s, and 0 otherwise.
We tackle this formulation with a column generation approach. Let S 0 ⊂ S
be the initial pool of columns. Let πi and µ be the dual variables of constraints
(2.2) and (2.3), corresponding to an optimal solution of (MP) when restricted to the
only columns in S 0 and with the integrality constraints relaxed. The column s ∈
/ S0
Pm
with the largest negative reduced cost c̄s0 , with c̄s0 = ds0 − i=1 πi xis0 − µ, can be
obtained by solving the following nonlinear 2-norm pricing problem (PP):
min

m
X
i=1

((w T ai − γ)2 − πi )xi − µ

s.t. kwk2 ≥ 1
xi ∈ {0, 1}
w ∈ Rn , γ ∈ R,

(2.4)

1≤i≤m

(2.5)
(2.6)

where (w, γ) are the parameters of Hs0 and the binary variable xi is equal to 1 if the
point ai is assigned to Hs0 and 0 otherwise. Note that xi takes integer values in any
optimal solution and hence (2.6) can be relaxed into xi ∈ [0, 1]. (PP) is nonconvex
due to (2.5) and can be solved to local optimality with state-of-the-art nonlinear
programming solvers such as SNOPT.
√
Since n kwk2 ≥ kwk1 , substituting kwk1 ≥ 1 for (2.5) yields kwk2 ≥ √1n
and thus a relaxation of k-HC. This 1-norm constraint can be linearized with standard techniques, see [5]. Given any 1-norm solution, a corresponding feasible 2norm solution can be obtained by fixing the point-to-hyperplane assignment and
recomputing the hyperplane parameters in the closed-form proposed in [3].
To speed up convergence, a dual-stabilization technique [8] is used. At each
iteration t that is a multiple of the frequency parameter f , the current dual vector

356

π t is replaced by a convex combination π 0t of π t and the previous dual vector π t−1 ,
namely π 0t := ηπ t + (1 − η)πt−1 with η ∈ (0, 1).
3. Point-Reassignment metaheuristic (PR)

Our Point-Reassignment metaheuristic (PR) relies on a simple criterion to
identify, at each iteration, points which are likely to be ill-assigned in the current
d
solution, based on the distance ratio min 0 ij d 0 .
j 6=j

ij

Starting from a randomly generated solution, at each iteration the set I of possibly ill-assigned points is identified as follows. Let mj , with 1 ≤ j ≤ k, be the
number of points currently assigned to hyperplane Hj and rank them w.r.t. the rad
tio min 0 ij d 0 . Indeed, points with large ratio have larger distance w.r.t. Hj and are
j 6=j ij
close to another hyperplane Hj 0 , hence being more likely to be ill-assigned. Given
a control parameter α (“temperature”), the set I then contains the α · mj points of
each cluster with the largest ratio.
A move consists in assigning each point ai in I to the closest hyperplane which
differs from the current one ai is assigned to, and in assigning the points in P \
I to the closest Hj , if it is not already the case. The hyperplane parameters are
then recomputed in the closed-form described in [3]. To avoid cycling and try to
escape from local minima, we adopt two Tabu Search features (see e.g. [6]): a list
of forbidden moves of length l and a partial aspiration criterion.
Since early solutions are expected to have a larger number of ill-assigned
points, the control parameter α is initially set to a large enough value α0 and is then
progressively decreased to stabilize the search process, thus progressively reducing
the variability that is introduced at each iteration. More precisely, α is updated as
αt = α0 ρt , where t is the index of the current iteration and ρ ∈ (0, 1) determines
the speed at which α is driven to 0. When α = 0, I becomes empty and, after all
points are assigned to the closets Hj , the algorithm terminates in a local minimum.
The best solution found is stored and returned.

4. Computational results and conclusions

We compare CG and PR with a multi-start version of Bradley and Mangasarian’s algorithm (BM, [3]) on a set of challenging, randomly generated instances [4].
CG is implemented in AMPL using SNOPT and CPLEX as solvers. PR and BM
are implemented in C++. Tests are run on an Intel Xeon machine, with 2.8 GHz
and 2 GB RAM, equipped with Linux and gcc 4.1.2.

357

CG is tested on 8 instances with m = 20 − 70, n = 2 − 3 and k = 3 − 6. η is
set to 0.7 and is reduced to 0.4 when 90% of the dual variables become zero. The
frequency f is set to 5. Because of the nonlinearities in the 2-norm pricing problem,
CG with 2-norm gets often stuck in local minima and leads to poor quality solutions. CG with 1-norm finds solutions with very small objective function values,
but since the 1-norm pricing problem is a non-trivial mixed-integer linear program,
the overall computation time scales poorly with the size of the instances.
PR is tested on 95 instances with m = 100 − 2500, n = 2 − 6 and k = 3 − 8.
Parameters are set to α0 = 0.9, ρ = 0.6, l = 2. We compare the best solutions
found by running PR and BM for a fixed amount of time and restarting them from
randomly generated solutions each time a local minimum is found. The time limit
is set to 120 and 180 seconds for instances with up to, respectively, 750 points
and 2500 points. PR finds better results in 89 cases out of 95 (with strictly better
solutions in 59 cases). On average, BM yields solutions worse than those found
by PR by a factor of 25%. Neglecting the 30 instances for which both algorithms
find solutions of the same value (since they may be optimal), the factor amounts
to 35.5%.

References
[1] P. K. Agarwal and C. M. Procopiouc, Approximation algorithms for the projective clustering, Journal of Algorithms 46 (2003), no. 2, 115–139.
[2] E. Amaldi and M. Mattavelli, The MIN PFS problem and piecewise linear model
estimation, Discrete Appl. Math. 118 (2002), 115–143.
[3] P.S. Bradley and O.L. Mangasarian, k-plane clustering, J. of Global Optimization 16 (2000), no. 1, 23–32.
[4] S. Coniglio and F. Italiano, Hyperplane clustering and piecewise linear model
fitting, Master’s thesis, DEI, Politecnico di Milano, 2007.
[5] K. Dhyani, Optimization models and algorithms for the hyperplane clustering
problem, Ph.D. thesis, Politecnico di Milano, 2009.
[6] F. Glover and M. Laguna, Tabu search, Kluwer Academic Publishers, 1997.
[7] N. Megiddo and A. Tamir, On the complexity of locating linear facilities in the
plane, Operations Research Letters 1 (1982), 194–197.
[8] A. Pessoa, E. Uchoa, M. Poggi de Aragão, and R. Rodrigues, Algorithms
over arc-time indexed formulations for single and parallel machine scheduling problems, Tech. Report 8, Universidade Federal Fluminense, 2008.

358

Games

Lecture Hall A

Thu 4, 15:45–16:15

A System-theoretic Model for Cooperation and
Allocation Mechanisms
Ulrich Faigle, Jan Voss
Universität zu Köln
Zentrum für Angewandte Informatik
Weyertal 80, D-50931 Köln, Germany {faigle,voss}@zpr.uni-koeln.de
Key words: Cooperation, system, allocation mechanism, value, randomization, symmetry,
core, Weber set

1. Introduction

The classical model of cooperative games assumes that arbitrary subsets of
agents can join to form feasible coalitions and create values in a given economic
context. The main problem is: How should a commonly generated value be distributed among the agents?
Weber [13] developed a model of so-called probabilistic values (including the Shapley value, the Banzhaf value etc.) for the classical model.
However many real problems are not covered by the classical model. The notions of
cooperation and allocation have often a more dynamic flavor. In the past there were
many approaches that aimed for a suitable generalization of the classical model.
For example Kalai and Samet [10] studied games with block structure, i.e., certain critical coalitions partition the set of agents. Models for cooperative games
under precedence constraints were developed by Derks and Gilles [8] and Faigle
and Kern [9]. Bilbao et al. [1; 2; 3; 4; 5; 6] have studied models for cooperative
games with underlying combinatorial coalition structures such as convex geometries, antimatroids or matroids. In all these generalizations, analogues of Shapley‘s
[12] classical value and possibly also the core are sought.
Our present research wants to take a first step towards viewing cooperation and
allocation as dynamic processes and thus to approach cooperative games system
theoretically. Our model includes all the above mentioned models as special cases.
Also the classical results can be shown to extend to this wider context.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

2. Cooperation Systems and Cooperative Games
A cooperation system is a quadruple Γ = (N, V, A, A), where N is a finite
set of agents, V a finite set of states of cooperation and A a finite set of feasible
transitions x → y between states, which we assume to be partitioned into pairwise
disjoint blocks Ai , indexed by the agents i ∈ N. We denote the latter partition by
A = {Ai |i ∈ N} and think of the block Ai ∈ A as the set of transitions that are
governed by the agent i: Intuitively, i can take the “action” (x → y) ∈ Ai and
transform the current state x of cooperation into the state y ∈ V .
By identifying (x → y) with the pair xy ∈ V × V , we obtain G = (V, A) as the
(directed) transition graph of Γ with vertex set V and arc set A. For simplicity of
exposition, we assume throughout:
(Γ0 ) There is one unique initial state S ∈ V (i.e. s− := {u ∈ V |us ∈ A} = ∅).
(Γ1 ) G is acyclic.
This means every x ∈ V can be reached by a directed path that starts in s. Moreover each such path extends to a path that ends in a sink t (i.e.:t+ := {u ∈ V |tu ∈
A} = ∅). A source-sink path is called a cooperation instance and we denote by P
the set of all cooperation instances.
A cooperative game is a pair (Γ, v), where v : V → R is a valuation of the states
of cooperation (the so-called characteristic function of the game) with the property that v(s) = 0. The vector space of all cooperative Games on Γ is denoted by
V(= V(Γ)).
A selector is an operator X 7→ σ(X) on the subsets of N such that σ(X) ⊆ N \ X
for all X ⊆ N. We show how cooperative games with selectors fit in our model.
All mentioned generalizations of the classical model are such games with selectors.
All cooperative games with selector suffice the following singular action property
in words of cooperation instances:
(SA) |P ∩ Ai | ≤ 1 for all P ∈ P and i ∈ N.
3. Allocation and Symmetries

We define an allocation mechanism to be a computational scheme for allocating payoffs to the individual agents in the context of a cooperative game (Γ, v). We
make some axiomatic assumption:
(A0 ) The null game should yield zero payoffs.
(A1 ) The allocation to the agent i should only depend on his action set Ai and

362

should be linear in v.
Let ∂ : V → RA , ∂xy (v) := v(y) − v(x) be the marginal operator. Since ∂ is a
monomorphism, it is an isomorphism on ∂(V). A linear allocation mechanism is
therefore described by a vector α ∈ RA that determines the individual values for
i ∈ N:
φαi (v) :=

X

αxy ∂xy (v).

xy∈Ai

We call the linear functional v 7→ φα (v) := αT ∂(v) the group value associated
with the allocation mechnism α.
Together with the two assumptions (A0 ) and (A1 ) we develope a theory of linear allocation mechanisms strongly inspired by the theory of Weber [13] for the classical
case. We define a Shapley allocation mechanism in our model and show that it is a
generalization of the Shapley values proposed in the above mentioned models and
expose it to be the unique mechanism of maximal entropy in some sense. Moreover
we define λ-mechnisms as a generalization of weighted Shapley values studied by
Shapley [11; 12] and Kalai and Samet [10].
Laxly speaking a symmetry of Γ is a permutation ρ of V which leaves the structure
of Γ invariant, i.e.:
(S0 ) ρ is a graph automorphism of G. (Note that this is equivalent for ρ to leave
invariant P)
(S1 ) ρ respects A, i.e.: ρ(Ai ) ∈ A for all i ∈ N.
In some sense the group of symmetries of Γ acts on the set of λ-values. A symmetry
ρ of Γ is called an automorphism of a game v, if
v(ρ(x)) = v(x) f or all x ∈ V.
We extend a classical result of Owen and Carreras [7] to our model and show under
the assumption (SA) that the automorphisms of a game v are exactly the symmetries
of Γ which stabilize all λ-values. Sadly this statement may become false, if (SA) is
dropped.

4. Core and Weber Sets

Finally we discuss the concept of a core of a cooperative game and its relation
to the Weber set. For this discussion we restrict ourselves to cooperation systems
that arise from selection structures. We propose a core concept as well as marginal
vectors for our model as a generalization of the classical case.
The convex hull of all marginal vectors is classically called the Weber set of a

363

game. Weber [13] showed that in the classical model the core is always a subset
of the Weber set. We extend this idea to games with selection structures and show
how our results lead to Webers result as a special case.

References
[1] E. Algaba, J.M Bilbao, R. van den Brink and A. Jiménez-Losada: Cooperative
games on antimatroids. Discr. Mathematics 282 (2004), 1-15.
[2] J.M. Bilbao, Cooperative Games on Combinatorial Structures. Kluwer Academic Publishers, 2000.
[3] J.M. Bilbao, E. Lebrón and N. Jiménez: The core of games on convex geometries. Europ. J. Operational Research 119 (1999), 365-372.
[4] J.M. Bilbao, T.S.H. Driessen, N. Jiménez Losada E. Lebrón: The Shapley
value for games on matroids. Math. Meth. Oper. Res. 53 (2001), 333-348.
[5] J.M. Bilbao and P. Edelman: The Shapley value on convex geometries. Discrete Appl. Math. 103 (2000), 33-40.
[6] J.M. Bilbao, N. Jiménez, E. Lebrón and J.J López: The marginal operators
for games on convex geometries. Intern. Game Theory Review 8 (2006), 141151.
[7] F. Carreras and G. Owen: Automorphisms and weighted values. Intern. J.
Game Theory 26 (1997), 1-10.
[8] J. Derks and R.P. Gilles: Hierarchical organization structures and constraints
in coalition formation. Intern. J. Game Theory 24 (1995), 147-163.
[9] U. Faigle and W. Kern: The Shapley value for cooperative games under precedence constraints. Intern. J. Game Theory 21 (1992), 249-266.
[10] E. Kalai and D. Samet: On weighted Shapley values. Int. Journ. Game Theory
16 (1987), 205-222.
[11] L.S. Shapley: Additive and non-additive set functions. PhD Thesis, Department of Mathematics, Princeton University Press, 1953.
[12] L.S. Shapley: A value for n-person games. In: Contributions to the Theory of
Games, H.W. Kuhn and A.W. Tucker eds., Ann. Math. Studies 28, Princeton
University Press, 1953, 307-317.
[13] R.J. Weber: Probabilistic values for games. In: A.E. Roth (ed.), The Shapley
Value, Cambrigde University Press, Cambridge, 1988, 101-120.

364

Matrices

Lecture Hall B

Thu 4, 15:45–16:15

Distribution of permanent of matrices with restricted
entries over finite fields ?
Le Anh Vinh
Mathematics Department, Harvard University, Cambridge, MA, 02138, USA

Key words: permanent, matrices over finite fields

1. Motivation
Throughout this paper, let q = pr where p is an odd prime and r is a positive integer. Let Fq be a finite field of q elements. The prime base field Fp of Fq
may then be naturally identified with Zp . Let M be an n × n matrices, two basic
parameters of M are its determinant
X

Det(M) :=

sgn(σ)

σ∈Sn

n
Y

aiσ(i) ,

i=1

and its permanent
Per(M) :=

n
X Y

aiσ(i) .

σ∈Sn i=1

The distribution of the determinant of matrices with entries in a finite field Fq
has been studied by various researchers. Suppose that the ground field Fq is fixed
and M = Mn is a random n × n matrices with entries chosen independently from
Fq . If the entries are chosen uniformly from Fq , then it is well known that
Pr(Mn is nonsingular) →

Y

(1 − q −i) as n → ∞.

(1.1)

i>1

It is interesting that (1.1) is quite robust. Specifically, J. Kahn and J. Komlós [4]
proved a strong necessary and sufficient condition for (1.1).
Theorem 19. ([4]) Let Mn be a random n×n matrix with entries chosen according
to some fixed non-degenerate probability distribution µ on Fq . Then (1.1) holds if
and only if the support of µ is not contained in any proper affine subfield of Fq .
? This paper was not actually presented at the conference, as the author did not attend (nor
communicate his cancellation). The talk was replaced by the communication: S. Margulies,
Computing Infeasibility Certificates for Combinatorial Problems via Hilbert’s Nullstellensatz.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

An extension of the uniform limit is to random matrices with µ depending on
n was considered by Kovalenko, Leviskaya and Savchuk [5]. They proved that the
standard limit (1.1) under the condition that the entries mij of M are independent
and Pr(mij = α) > (log n + ω(1))/n for all α ∈ Fq . The behavior of the nullity
of Mn for 1 − µ(0) close to log n/n and µ(α) = (1 − µ(0)/(q − 1) for α 6= 0 was
also studied by Blömer, Karp and Welzl [2].
Another direction is to fix the dimension of matrices. For an integer number
n and a subset E ⊆ Fnq , let Mn (E) denote the set of n × n matrices with rows
in E. For any t ∈ Fq , let Nn (E; t) be the number of n × n matrices in Mn (E)
having determinant t. Ahmadi and Shparlinski [1] studied some natural classes of
matrices over finite fields Fp of p elements with components in a given subinterval
[−H, H] ⊆ [−(p − 1)/2, (p − 1)/2]. They showed that
(2H + 1)n
Dn ([−H, H] ; t) = (1 + o(1))
p

2

n

(1.2)

if t ∈ F∗q and H  q 3/4 . In the case n = 2, the lower bound can be improved to
H  q 1/2+ε for any constant ε > 0.
Covert et al. [3] studied this problem in a more general setting. A subset E ⊆
is called a product-like set if |Hd ∩ E| . |E|d/n for any d-dimensional subspace
Hd ⊂ Fnq . Covert et al. [3] showed that

Fnq

D3 (E; t) = (1 + o(1))

|E|3
,
q

if t ∈ F∗q and E ⊂ F3q is a product-like set of cardinality |E|  q 15/8 . Using the geometry incidence machinery developed in [3], and some properties of non-singular
matrices, the author [7] obtained the following result for higher dimensional cases
(d ≥ 4):
2

|A|n
Dn (A ; t) = (1 + o(1))
,
q
n

d

if t ∈ F∗q and A ⊆ Fq of cardinality |A|  q 2d−1 .
On the other hand, little has been known about the permanent. The only known
uniform limit similar to (1.1) for the permanent is due to Lyapkov and Sevast’yanov
[6]. They proved that the permanent of a random n × m matrix Mnm with elements
from Fp and independent rows has the limit distribution of the form
lim Pr(Per(Mnm ) = k) = ρm δk0 + (1 − ρm )/p, k ∈ Fp ,

n→∞

where δk0 is Kronecker’s symbol. The purpose of this paper is to study the distribution of the permanent when the dimension of matrices is fixed. For any

368

t ∈ Fq and E ⊂ Fdq , let Pn (E; t) be the number of n × n matrices with rows
in E having determinant t. We are also interested in the set of all permanents,
Pn (E) = {Per(M) : M ∈ Mn (E)}.
2. Statement of results
The main result of this paper is that, if E is a sufficient large subset of Fnq then
Pn (E) covers Fq . More precisely, our main result is the following theorem.
Theorem 20. Suppose that q is an odd prime power and gcd(q, n) = 1.
a) If E ∩ (F∗q )n 6= ∅, and |E| > cq

n+1
2

, then F∗q ⊆ Pn (E).

b) If E ⊂ Fnq of cardinality |E| > nq n−1 , then F∗q ⊆ Pn (E).
A is a sufficient large subset of Fq then Pn (An ) covers Fq . More precisely, our
main result is the following theorem.
Theorem 21. Suppose that q is an odd prime power and gcd(q, n) = 1.
a) If E ∩ (F∗q )n 6= ∅, and |E| > cq

n+1
2

, then F∗q ⊆ Pn (E).

b) If E ⊂ Fnq of cardinality |E| > nq n−1 , then F∗q ⊆ Pn (E).
1

1

c) If A ⊂ Fq of cardinality |A|  q 2 + 2n , then F∗q ⊆ Pn (An ).
b) If A ⊆ Fq of cardinality |A|  q 2/3 , then for each t ∈ F∗q
P3 (A3 ; t) = (1 + o(1))

|E|3
.
q

Note that the bound in Part b) of Theorem 20 is tight up to a factor of n. For
example, |{x1 = 0}| = q n−1 and Pn ({x1 = 0}) = 0. When E is a product-like set,
we can get a positive proportion of the permanents under a weaker assumption.
Theorem 22. Suppose that q is an odd prime power and gcd(q, n) = 1. If E ⊂ Fnq
n2

is a product-like set of cardinality |E|  q 2(n−1) , then
|Pn (E)| > (1 − o(1))q.
In the special case E = A × . . . × A, we have the following corollary.
Corollary 1. Suppose that q is an odd prime power and gcd(q, n) = 1. If A ⊆ Fq
1
1
of cardinality |A|  q 2 + 2(n−1) , then |Pn (An )| > (1 − o(1))q.
Furthermore, if we restrict our study to matrices over a finite field Fp of p
elements (p is a prime) with components in a given interval, we obtain a stronger
result.

369

Theorem 23. Suppose that q = p is a prime, and entries of M are chosen from a
given interval I := [a + 1, a + b] ⊆ Fp , where
p1/2

b
→ ∞, p → ∞,
log p

then
2

bn
Pn (I ; t) = (1 + o(1))
p
n

for any t ∈ Fp .
Throughout the abstract, the implied constants in the symbols ‘o’ and ‘’ may
depend on integer parameter n. We recall that the notation U  V is equivalent to
the assertion that the inequality U  c|V | holds for some constant c > 0.
References
[1] O. Ahmadi and I. E. Shparlinski, Distribution of matrices with restricted entries over finite fields, Inda. Mathem. 18(3) (2007), 327–337.
[2] J. Blömer, R. Karp, and E. Welzl, The rank of sparse random matrices over
finite fields, Random Structures and Algorithms 10 (1997) 407–419.
[3] D. Covert, D. Hart, A. Iosevich, D. Koh, and M. Rudnev, Generalized incidence theorems, homogeneous forms and sum-product estimates in finite
fields, European Journal of Combinatorics, to appear.
[4] J. Kahn and J. Komlós, Singularity probabilities for random matrices over
finite fields, Combinatorics, Probability and Computing 10 (2001), 137–157.
[5] I. N. Kovalenko, A. A. Leviskaya, and M. N. Savchuk, Selected Problems in
Probabilistic Combinatorics (1986), Naukova Dumka, Kiev. In Russian.
[6] L. A. Lyapkov and B. A. Sevast’yanov, The limiting probability distribution of
a permanent of a random matrix in a GF (p) field, Diskr. Matem., 8(2) (1996),
3–13.
[7] L. A. Vinh, On the distribution of determinants of matrices with restricted
entries over finite fields, Journal of Combinatorics and Number Theory, to
appear.

370

Plenary Session III

Lecture Hall A

Thu 4, 16:45-17:30

On the boundary of tractability for
nonlinear discrete optimization
Jon Lee
IBM TJ Watson Research Center, PO Box 218, Yorktown Heights, NY 10598
jonlee@us.ibm.com

Key words: mixed integer nonlinear programming, nonlinear discrete optimization

This paper covers the material from my talk at CTW 2009, Paris. ∗ I am indebted to the Scientific Committee and to Leo Liberti and the other members of the
Organizing Committee for the opportunity to present this paper.
Nonlinear discrete optimization, in its broadest sense, is simply the study of
optimization models involving nonlinear functions in discrete variables. This is so
hopelessly broad as to be a subject ripe for charlatans and cranks. Sober individuals cannot hope to devise efficient methods — practical or theoretical — for the
entire class of such problems. So we set out some reasonable goals in the hope of
delineating some of the boundary between tractable and intractable.
In §1, we look at polynomial optimization in integer variables from a complexity point of view. We summarize some key hardness results and also describe
positive algorithmic results. More details regarding the material on polynomial optimization is collected in [14].
In §2, we take a different slice across nonlinear discrete optimization. In the
context of a structured parametric nonlinear discrete optimization model, we describe some hardness results and also several broad cases for which we can give efficient exact or approximation algorithms. Much of that material is from [4; 19; 5].
I am enormously indebted to Shmuel Onn and Robert Weismantel for allowing me
to survey some of our joint work which is the essence of §2. A full treatment of that
material, which is only summarized here, will appear in our forthcoming monograph [20]. Further thanks are due to Yael Berstein who was also a key player in
the development of some of that material.
∗

Cologne Twente Workshop 2009, 8th Cologne-Twente Workshop on Graphs and Combinatorial Optimization, Ecole Polytechnique and CNAM, Paris, France June 2-5, 2009.

CTW09, École Polytechnique & CNAM, Paris, France. June 2–4, 2009

Finally, in §3, we describe a recent effort to implement one of the more novel
algorithms from §2, using ultra-high precision arithmetic on a high-performance
computational platform. I owe considerable gratitude to John Gunnels and Susan
Margulies who were partners of mine in the work [10] summarized in §3.
1. Polynomial optimization

Polynomial optimization in continuous or integer variables refers to the model
min / max {f0 (x) : fi (x) ≤ 0, i = 1, . . . , m; x ∈ D n },
where the fi : Rn → R are polynomials, and D is either R or Z. Often one looks
at the special case in which the constraint functions f1 , . . . , fm are affine functions,
and so the feasible region is either a polyhedron or the integer points in a polyhedron. Polynomial optimization in integer variables constitutes a very broad and
natural class of nonlinear discrete optimization problems. As we shall soon see,
some very simple subclasses are intractable, while for another broad subclass we
get tractability, and for another broad subclass we get strong approximability.
First, we point out how hardness of nonlinear discrete optimization also implies hardness for nonlinear continuous optimization. Specifically, the max-cut
problem can be modeled as minimizing a quadratic form over the cube [−1, 1]n ,
and Håstad [12] demonstrated inapproximability for max-cut. Thus we have the
following result:
Theorem 1.1. Polynomial optimization in continuous variables over polytopes in
varying dimension is NP-hard. Moreover, there does not exist a fully polynomialtime approximation scheme, unless P = NP.
However, polynomial optimization in continuous variables over polytopes can
be solved in polynomial time when the dimension is fixed. This follows from Renegar’s general result on the complexity of approximating solutions to general algebraic formulae over the reals (see [23]).
For integer variables, hardness sets in for very low dimension. Based on reduction from the NP-complete problem of determining if there exists a positive integer
x < c with x2 ≡ a (mod b), we have the following (see [9; 6]):
Theorem 1.2. The problem of minimizing a degree-4 polynomial over the integer
points of a convex polygon is NP-hard.
Moreover, hardness sets in with a vengeance. The negative solution of Hilbert’s
tenth problem by Matiyasevich [21; 22], building on earlier work by Davis, Putnam
and Robinson [7], implies that nonlinear integer programming over unbounded fea-

374

sible regions is incomputable. Due to Jones’ strengthening [16] of Matiyasevich’s
negative result, there also cannot exist any such algorithm for the cases of feasible
regions for even a small fixed number of integer variables (see [6]):
Theorem 1.3. The problem of minimizing a linear form over polynomial constraints in at most 10 integer variables is not computable by a recursive function.
Another consequence, as shown by Jeroslow [15], is that even integer quadratic
programming is incomputable.
Theorem 1.4. The problem of minimizing a linear form over quadratic constraints
in integer variables is not computable by a recursive function.
So far, we have painted a rather bleak picture for polynomial optimization. But
the inherent difficulty is related to non-convexity, and it becomes worse in varying dimension. On the positive side, Khachiyan and Porkolab have demonstrated
that in fixed dimension, the problem of minimizing a convex polynomial objective
function over the integers, subject to polynomial constraints describing a convex
body, can be solved in time polynomial in the encoding length of the input [17].
This result was strengthened by Heinz [13] to achieve the following result based on
generalizing Lenstra’s algorithm for linear integer optimization in fixed dimension
[18].
Theorem 1.5. Let the dimension n be fixed. The problem of minimizing f0 (x) on
the set of integer points satisfying fi (x) ≤ 0, i = 1, 2, . . . , m, where the fi : Rn →
R are quasi-convex polynomials with integer coefficients, for i = 0, 1, . . . , m, can
be solved in time polynomial in the degrees and the binary encoding of the coefficients.
Owing to the difficulty, already, of optimizing (non-convex) degree-4 polynomials over the integer points in a convex polygon (Theorem 1.2), the best that we
can hope for, in fixed dimension without a convexity assumption on the objective, is
an approximation result. In fact, a very strong result — namely a fully polynomialtime approximation scheme — has been established (see [6]):
Theorem 1.6. Let the dimension n be fixed. Let P ⊂ Rn be a rational convex
polytope. Let f be a polynomial with rational coefficients that is non-negative on
P ∩ Zn , given as a list of monomials with rational coefficients cβ encoded in binary
and exponent vectors β ∈ Zn+ encoded in unary. Then we can find a feasible solution x ∈ P ∩ Zn with fmax − f (x) ≤ fmax , in time polynomial in the input and
1/.

375

2. Parametric Nonlinear Discrete Optimization

In this section, we take another view across the landscape of nonlinear discrete
optimization. While in the last section our viewpoint was to look at specializations of mathematical programming models, in the present section our viewpoint
more closely aligned with that taken in combinatorial optimization. From this different viewpoint, we will see other aspects of the boundary between tractable and
intractable nonlinear discrete optimization models.
We consider the parametric nonlinear discrete optimization model
min / max {f (W x) : x ∈ F },
where W ∈ Zd×n , f : Rd → R is specified by a comparison oracle, and F ⊂ Zn is
well described (i.e., we have access to an oracle for optimizing an arbitrary linear
objective on F ). One motivation for the study of such a model is multi-objective
optimization, where we view each row of W as specifying a linear objective, and
then the nonlinear f balances the d competing linear objectives. Besides this appealing motivation, the structure of this model also provides a nice structure for
exploring the boundary between intractable and tractable. So, in the remainder of
this section, we will expose some of this boundary, as we vary hypotheses on f , W
and F .
We make some brief comments about our general hypothesis on F , that it is
well described. Usually such a term would be formally defined as meaning that we
have a separation oracle for conv(F ). But of course the polynomial equivalence of
separation and optimization is well known (see [11]). Finally, the hypothesis that
we can optimize arbitrary linear functions on the discrete set F is very natural,
from both the theoretical and practical viewpoints, as we try to lift up to nonlinear
discrete optimization.
One of our primary complexity levers is the encoding of W . We will see that
typically for binary-encoded W , we will have intractability, and so to obtain positive results we will need to hypothesize that the number of rows d is fixed, and that
the entries of W are somehow small. The exact hypotheses vary over the results that
we present, so we lay out here the possibilities: (i) unary encoding of the wij , (ii)
wij ∈ {a1 , . . . , ap }, where p is fixed and the ak ∈ Z are binary encoded input, (iii)
P
wij ∈ {a1 , . . . , ap }, where a1 , . . . , ap ∈ Z+ are fixed, (iv) wij = k λij
k ak , where p
ij
is fixed, the ak ∈ Z are binary-encoded input, and the λk are unary-encoded input.
In this last case, we say that W has a unary encoding over {a1 , . . . , ap }.
The following three results demonstrate the strong intractability of parametric
nonlinear discrete optimization. The results emphasize matroids, because for linear
objectives such problems are very easy — the greedy algorithm works.

376

Theorem 2.1. Computing the optimal objective value of
min / max {f (wx) : x ∈ F },
when d = 1, w ∈ Zn+ , f is a univariate function presented by a comparison oracle,
and F is the set of bases of a uniform or graphic matroid on an n-element ground
sets, cannot be done in time polynomial in n and the binary encoding of w.
Theorem 2.2. Computing the optimal objective value of
min / max {f (W x) : x ∈ F },
when d = n, W = In , f : Rn → R presented by a comparison oracle, and F is the
set of bases of a uniform or graphic matroid on an n-element ground sets, cannot
be done in time polynomial in n.
Theorem 2.3. Determining whether the optimal objective value is zero for
min {f (wx) : x ∈ F },
when d = 1, binary-encoded w ∈ Zn+ , f is the explicit convex univariate function
f (y) := (y − u1 )2 , and F is the set of bases of a uniform or graphic matroid on an
n-element ground sets, is NP-complete.
Despite the strong intractability of the general model, we are able to get positive complexity results for broad classes of interest. We are able to do this, for the
most part, by fixing the number of rows of W and restricting the encoding of its entries. Depending on the precise restrictions on W , we are able to address different
types of functions f .
Theorem 2.4. If F is well described, f is quasi-convex, and W has a fixed number
of rows and has a unary encoding over binary encoded {a1 , . . . , ap }, then there is
an efficient deterministic algorithm for max {f (W x) : x ∈ F }.
Theorem 2.5. If F is well described, f is a norm, and W has a fixed number of
rows and is binary-encoded and non-negative, then there is an efficient deterministic constant-approximation algorithm for max {f (W x) : x ∈ F }.
A function f : Rd+ → R is ray concave if
λf (u) ≤ f (λu) for u ∈ Rd+ , 0 ≤ λ ≤ 1.
For example, if f is a norm on Rd , then it ray-concave and non-decreasing on Rd+ .
As a further example, f (u) := kuk1 − kuks , for any integer s ≥ 1 or infinity, is
ray-concave and non-decreasing on Rd+ . Notice that already for d = 2 and s = ∞ ,
f (u) is not a norm — indeed, for this case f (u) = min(u1 , u2 ) .

377

Theorem 2.6. If F is well described, f is ray concave and non-decreasing, and
W has a fixed number of rows and has a unary encoding over binary encoded
{a1 , . . . , ap }, then there is an efficient deterministic constant-approximation algorithm for min {f (W x) : x ∈ F }.
Turning to general functions f , we must be much more modest in our expectations. The next results establishes very strong intractability. An independence
system F ⊂ {0, 1}n has the property that for x ∈ F and y ∈ {0, 1}n with y ≤ x,
we have y ∈ F .
Theorem 2.7. There is no efficient algorithm for computing an optimal solution
of the one-dimensional nonlinear optimization problem min / max {f (wx) : x ∈
F } over a well-described independence system, with f presented by a comparison
oracle, and single weight vector w ∈ {2, 3}n.
Still, we can establish a positive result, using a new notion of approximation
that is appropriate for general functions f . We say that x∗ ∈ F is r-best for
min / max {f (W x) : x ∈ F },
if at most r better values than f (W x∗ ) are achievable as f (W x), over points x ∈ F .
A p-tuple a is primitive if its entries are distinct positive integers having gcd 1.
Theorem 2.8. For every primitive p-tuple a, there is a constant r(a) and an efficient algorithm that, given any well-described independence system F ⊆ {0, 1}n ,
a single weight vector w ∈ {a1 , . . . , ap }n , and function f : Z → R presented by a
comparison oracle, finds an r(a)-best solution to min / max {f (wx) : x ∈ F }.
Moreover, (i) if ai divides ai+1 for i = 1, . . . , p − 1, then the algorithm provides
an optimal solution; (ii) for p = 2, that is, for a = (a1 , a2 ), the algorithm provides
an (a1 a2 − a1 − a2 )-best solution.
Even though the situation for arbitrary well described independence systems is
tough, for a matroid even presented by an independence oracle, we have an efficient
algorithm for optimizing general functions f .
Theorem 2.9. If F is the set of characteristic vectors of bases or independent sets
of a single matroid presented by an independence oracle, cT ∈ Zn is binary encoded, f is arbitrary and given by a comparison oracle, and d × n matrix W has a
fixed number of rows and has entries in binary encoded {a1 , . . . , ap } with p fixed,
then there is an efficient deterministic algorithm for min / max {cx+f (W x) : x ∈
F }.
Turning to vectorial matroids (over the rationals so as to make our complexity
statements simple), and modifying the assumptions on the encoding of W , we are
able to again get an efficient algorithm.

378

Theorem 2.10. If F is the set of characteristic vectors of bases or independent sets
of a single rational vectorial matroid represented by a binary-encoded integer matrix A, f is arbitrary and given by a comparison oracle, and W has a fixed number
of rows and is unary encoded, then there is an efficient deterministic algorithm for
min / max {f (W x) : x ∈ F }.
Finally, for matroid intersection, again for vectorial matroids, we are able to
get an efficient randomized algorithm for general f .
Theorem 2.11. If F is the set of characteristic vectors of common bases or independent sets of a pair of rational vectorial matroids, represented by binary-encoded
integer matrices A1 and A2 , on a common ground set, f is arbitrary and given by a
comparison oracle, and W has a fixed number of rows and is unary encoded, then
there is an efficient randomized algorithm for min / max {f (W x) : x ∈ F }.
3. Supercomputing
In §2, we have omitted the algorithms and analyses that form the proofs of
the theorems. Many of the algorithms are not particularly esoteric, so the range of
parameters for which they are practical is mostly apparent.
But this generalization has some exceptions. The algorithms that form the
bases of the proofs of Theorems 2.10 and 2.11 might seem to be of only theoretical
interest. In this section we describe the algorithm from the proof of Theorem 2.10,
and a bit about how we have implemented it, in ultra-high precision arithmetic on
a Blue Gene/L supercomputer [1].
Without loss of generality, we can assume that W is non-negative and that we
are optimizing over the bases of M (the case of arbitrary W and independent sets is
treated, easily, in [20]). Let A ∈ Z r×n be the matrix representation of the (rational)
vectorial matroid M, and let F be the set of characteristic vectors of bases of M.
It turns out that it is sufficient to be able to efficiently calculate an optimal W x
— there is a simple methodology for recovering an associated x. The motivating
idea of the algorithm is to determine, in one go, the entire set of points
U := {W x : x is the characteristic vector of a base of M}.
We observe that U is a subset of Z := {0, 1, · · · , rω}d. By our assumptions, |Z| is
bounded by a polynomial in the size of the data encoding. So, once we have U, we
can easily determine an optimal W x using the comparison oracle of f .

379

Define the following polynomial in d variables y1 , . . . , yd:
g = g(y) :=

X

u∈Z

gu

d
Y

ykuk ,

k=1

where the coefficient gu corresponding to u ∈ Z is the non-negative integer
gu :=

Xn

o

det2 (Ax ) : x ∈ F , W x = u ,

where Ax is the r × r submatrix of A indicated by the 0/1 vector x. Now, det2 (Ax )
is positive for every x ∈ F . Thus, the coefficient gu corresponding to u ∈ Z is
non-zero if and only if there exists an x ∈ F with W x = u . So the desired set U
Q
is precisely the set of exponent vectors u of monomials dk=1 ykuk having non-zero
coefficient gu in g .
Next, a simple lemma provides a key ingredient for our algorithm.
Lemma 3.1.
g(y) = det(AY AT ) .
Finally, the key idea is that we can determine the coefficients gu of the monomials in g indirectly, by using the lemma to evaluate g at enough points. Thus we
get Algorithm 1.
Algorithm 1: Efficient enumeration of the image of F under W
input: full row-rank A ∈ Zr×n (binary encoded), W ∈ Zd×n
(unary encoded);
+
let ω := max wi,j , s := rω + 1 and Z := {0, 1, · · · , rω}d ;
Qd
wi,j
;
let Y := diagj
i=1 yi
d
for t = 1, 2, . . . , s do
i−1
let Y (t) be the numerical matrix obtained by substituting ts for yi
(i = 1, 2, . . . , d) in Y ;
compute det(AY (t)AT );
end
compute thePunique solution gu , u ∈ Z, of the square linear system:
d
P
ui si−1
gu = det(AY (t)AT ), t = 1, 2, . . . , sd ;
u∈Z t i=1
return U := {u ∈ Z : gu > 0}.
We would like to view the system of equations from the algorithm a bit more
concretely in the form
V Tg = b ,

(3.1)

where V is an order sd square matrix, g is an sd vector of real variables, and
the right-hand side b is an sd -vector of constants. Clearly we will let bt :=
det(AY (t)AT ), for t = 1, 2, . . . , sd . As for the variables, we need a numbering

380

of the elements of Z . A natural numbering is via the φ : Z → {1, 2, . . . , sd } deP
fined by φ(u) := 1 + di=1 uisi−1 . In fact this map is just a lexical ordering of the
elements of Z ; for example, φ((0, 0, . . . , 0)T ) = 1 and φ((rω, rω, . . . , rω)T ) = sd .
With this notation, we can now view the linear system as
d

s
X

tj−1 gj = bt , t = 1, 2, . . . , sd .

(3.2)

j=1

Letting k := sd , we let the k × k matrix V T be defined by
T
Vt,j
:= tj−1 , for 1 ≤ t, j ≤ k .

With this definition of V T , (3.2) has the form (3.1).
In this form, we see that V is a (special) Vandermonde matrix (so it is invertible), and the system (3.1) that we wish to solve is a so-called “dual problem.” We
propose to solve it simply by evaluating V −1 , and letting g := V −T b .
Our Vandermonde matrix is a very special one. It even has a closed form for
the inverse V −1 :
−1
Vi,j
:=



1

 (−1)i+k (i−1)!(k−i)!


 i V −1

i,j+1

h

i

+

h

k+1
j+1

i

,

j=k;

−1
Vi,k
,1≤j<k,

where k+1
denotes a Stirling number of the first kind (see [8], though they define
j+1
−1
things slightly differently there). The form for Vi,j
indicates how each row of V −1
can be calculated independently, with individual entries calculated from right to
left, albeit with the use of Stirling numbers of the first kind. We note that the Stirling
−1
number used for Vi,j
does not depend on the row i , so the needed number can be
computed once for each column j . The (signed) Stirling numbers of the first kind
can be calculated in a “triangular manner” as follows (see [24]). For −1 ≤ j ≤ k ,
we have
"




0





,
#
k+1
:= 1 ,

j+1



h i


k
j

k ≥ 0 , j = −1 ;
−k

h

k
j+1

i

k ≥ −1 , j = k ;
, k > j ≥ −1 .

A remark is in order concerning the practicality of working with large Vandermonde systems and Stirling numbers. The numerics would quickly get out of
hand, using ordinary limited-precision arithmetic, when k = sd is even modest in
magnitude. So, the practical implementation of [10] uses the ultra-high precision
arithmetic library ARPREC (see [2; 3]).

381

Finally, it is easy to see that there is enormous potential for parallelism in the
calculation of the needed Stirling numbers and in the formation and use of the
Vandermonde inverse (see [10] for details).

4. Remarks

It is not the case that algorithms and implementations like those described in
§3 are currently very practical. After all, not everyone has a supercomputer, and
even for the lucky few, there remains a large gap between instances that we would
like to solve and those that we can currently handle. However, I hope that we have
demonstrated that as computational platforms evolve, our view of what is possible
and eventually practical for discrete optimization should evolve accordingly. We
have only worked out the details and implemented one algorithm — the one for
Theorem 2.10. An algorithm for Theorem 2.11, though more complicated, is based
on similar ideas, and there is clearly the potential to make an effective implementation for it. Certainly, a broad paradigm for solving discrete optimization based on
matrix algebra in ultra-high precision on supercomputers would be very attractive.
We hope that this work is a first step in such a direction.

References
[1] G. Almási, C. Archer, J. Castaños, J. Gunnels, C. Erway, P. Heidelberger,
J. Moreira, K. Pinnow, J. Ratterman, B. Steinmacher-Burow, W. Gropp &
B. Toonen (2005). Design and implementation of message-passing services
for the Blue Gene/L supercomputer, IBM Journal of Research and Development, 49(2–3):393–406.
[2] D. H. Bailey, ARPREC,
crd.lbl.gov/∼dhbailey/mpdist/mpdist.html.
[3] D. H. Bailey (2005). High-precision arithmetic in scientific computation,
Computing in Science and Engineering, 7(3):54–61.
[4] Y. Berstein, J. Lee, H. Maruri-Aguilar, S. Onn, E. Riccomagno, R. Weismantel & H. Wynn (2008). Nonlinear matroid optimization and experimental design, SIAM Journal on Discrete Mathematics, 22(3):901–919.
[5] Y. Berstein, J. Lee, S. Onn & R. Weismantel (2008). Nonlinear optimization
for matroid intersection and extensions, Report RC24610, IBM Research.
[6] J. A. De Loera, R. Hemmecke, M. Köppe & R. Weismantel (2006). Integer
polynomial optimization in fixed dimension, Mathematics of Operations Research, 31(1):147–153.
[7] M. Davis, H. Putnam & J. Robinson (1961). The decision problem for exponential diophantine equations, Ann. of Math. (2), 74:425–436.

382

[8] A. Eisinberg, G. Franzé & P. Pugliese (1998). Vandermonde matrices on integer nodes, Numerische Mathematik, 80(1):75–85.
[9] M. R. Garey & D. S. Johnson (1979). Computers and Intractability: A Guide
to the Theory of NP-completeness, W. H. Freeman and Company, New York,
NY.
[10] J. Gunnels, J. Lee & S. Margulies (2008). Efficient high-precision dense matrix algebra on parallel architectures for nonlinear discrete optimization, Report RC24682, IBM Research.
[11] M. Grötschel, L. Lovász & A. Schrijver (1981). The ellipsoid method and its
consequences in combinatorial optimization, Combinatorica, 1:169–197.
[12] J. Håstad (1997). Some optimal inapproximability results, in: Proceedings of
the 29th Symposium on the Theory of Computing (STOC), (pp. 1–10), ACM.
[13] S. Heinz (2005). Complexity of integer quasiconvex polynomial optimization,
J. Complexity, 21(4):543–556.
[14] R. Hemmecke, M. Köppe, J. Lee & R. Weismantel (2008). Nonlinear integer
programming, Mathematical Programming (to appear).
[15] R. G. Jeroslow (1973). There cannot be any algorithm for integer programming with quadratic constraints, Operations Research, 21(1):221–224.
[16] J. P. Jones (1982). Universal diophantine equation, Journal of Symbolic Logic,
47(3):403–410.
[17] L. Khachiyan & L. Porkolab (2000). Integer optimization on convex semialgebraic sets., Discrete and Computational Geometry, 23(2):207–224.
[18] H. W. Lenstra, Jr. (1983). Integer programming with a fixed number of variables, Math. Oper. Res., 8(4):538–548.
[19] J. Lee, S. Onn & R. Weismantel (2008). Nonlinear optimization over a
weighted independence system, Report RC24513, IBM Research.
[20] J. Lee, S. Onn & R. Weismantel (2009). Nonlinear Discrete Optimization,
draft monograph.
[21] Yu. V. Matiyasevich (1970). Enumerable sets are diophantine, Doklady
Akademii Nauk SSSR, 191:279–282, (Russian); English translation, Soviet
Mathematics Doklady, vol. 11 (1970), pp. 354–357.
[22] Yu. V. Matiyasevich (1993). Hilbert’s tenth problem, The MIT Press, Cambridge, MA, USA.
[23] J. Renegar (1992). On the computational complexity of approximating solutions for real algebraic formulae, SIAM Journal on Computing, 21(6):1008–
1025.
[24] I. Tweddle (2003). James Stirling’s Methodus Differentialis: An Annotated
Translation of Stirling’s Text, Sources and Studies in the History of Mathematics and Physical Sciences, Springer.

383

List of Authors
Abouelaoualim A., 115
Alves C., 215
Amaldi E., 355
Andonov R., 341
Arbib C., 75
Ayala R., 277

de Souza C.C., 48, 187
Del-Vecchio R. R., 157
Dhyani K., 355
Dobson M. P., 153
Dong C., 3
Durán G., 195, 281

Bampas E., 68
Belgacem L., 225
Ben-Ameur W., 105
Bentz C., 313
Bermudo S., 297
Bettinelli A., 269
Bhandari R., 97
Bianco L., 210
Bodirsky M., 261
Bonomo F., 195, 281
Borozan V., 115
Brinkmann G., 333
Brinkmeier M., 301
Bruglieri M., 11

Engels B., 239
Ernst C., 3
Ewe H., 109
Faigle U., 361
Faria L., 229
Fawcett J., 120
Fernández-Ternero D., 277
Fernau H., 79, 205
Ficarelli F., 180
Filho C. L., 317
Fischetti M., 171
Frota Y., 48, 187
Galluccio A., 251
Gaspers S., 205
Gentile C., 251
Giakoumakis V., 305
Gibrat J.-F., 341
González J. F. V., 317
Grande E., 321
Grippo L. N., 281
Gropp H., 28
Guedes A. L. P., 229

Cacchiani V., 171
Cameron K., 120
Caprara A., 171
Caramia M., 210
Casazza M., 7
Cavellucci C., 317
Ceselli A., 7, 163
Charon I., 225
Collet G., 341
Colorni A., 11
Coniglio S., 355
Cordone R., 163, 180
Cornuéjols G., 144
Correa J.R., 347
Cremonini M., 163

Habib M., 257
Horváth I., 149
Hoshino E. A., 187
Hudry O., 225
Jäger G., 3

Darmann A., 293
de Abreu N.M.M., 157
de Carvalho J.M.V., 215
de Figueiredo C., 55
de Freitas M.A.A., 157

Küfer K., 109
Kang R. J., 60
Katona G. Y., 149
Kosuch S., 140
Kratsch D., 205
385

Krumke S., 239

Nunkesser M., 7

La Rota C., 325
Lavor C., 337
Lee J., 373
Leoni V. A., 153
Liberti L., 144, 175, 269
Liedloff M., 205
Liers F., 351
Lisser A., 140
Lodi A., 125
Lozin V. V., 40
Lozovanu D., 221
Lué A., 11
Lyons A., 199

Ould El Mounir C.B., 305
Pacifici A., 44, 321
Pagourtzis A., 68
Papadopoulos C., 23
Pardella G., 351
Petrosyan P. A., 64
Pferschy U., 44, 293
Pickl S., 221
Pierrakos G., 68
Raible D., 79, 205
Raimondi F., 175, 269
Ralphs T.K., 125
Raman R., 347
Richter D., 3
Righini G., 180
Roda F., 175
Rodrı́guez-Velázquez J. A., 297
Rossi A., 191

Müller D., 265
Müller T., 60
Maßberg J., 84
Macedo R., 215
Machado R., 55
Macina M., 251
Maculan N., 337
Maischberger M., 93
Manoussakis Y., 115
Marenco J., 195
Margulies S., 367
Marinelli F., 75
Markenzon L., 229
Martinhon C., 115
Maßberg J., 35
Megow N., 347
Mirchandani Pitu B., 321
Molitor P., 3
Morelato França A. L., 89
Morelato Frana P., 89
Mucherino A., 337
Muthu R., 115

Saad R., 115
Safe M. D., 281
Sargsyan H. E., 64
Sau I., 19
Savourey D., 269
Schüle I., 109
Schauer J., 293
Schneider J., 84
Schrader R., 239
Schultz R., 137
Scoppola C. M., 75
Scozzari A., 235
Sevaux M., 191
Shigezumi T., 285
Sigarreta J. M., 297
Simonetti L., 48
Soto M., 191
Stephan R., 247
Suchan K., 347
Syrgkanis V., 68

Nannicini G., 144
Nasini G. L., 153
Neto J., 105
Nicosia G., 44
Nieberg T., 35
Nikolopoulos S.D., 23
Nordh G., 261

Tardella F., 235
Tarissan F., 325

386

Thilikos D. M., 19
Uno Y., 285
Usberti F. L., 89, 317
Valencia-Pabon M., 195
Van Cleemput N., 333
Ventura P., 251
Vilches J. A., 277
Vinh L.A., 367
von Oertzen T., 261
Voss J., 361
Watanabe O., 285
Woeginger G. J., 293
Yanev N., 341
Yero I. G., 297
Zeck C., 239

387

List of Sessions
Applications, 163, 171, 175, 180
Bioinformatics, 333, 337, 341
Clustering, 347, 351, 355
Coloring I, 55, 60, 64, 68
Coloring II, 187, 191, 195, 199
Combinatorial Optimization, 35, 40,
44, 48
Complexity, 235, 239
Cutting and Packing, 75, 79, 84
Exact Algorithms, 205, 210, 215
Games, 361
Graph Theory I, 19, 23, 28
Graph Theory II, 149, 153, 157
Graph Theory III, 277, 281, 285
Graph Theory IV, 293, 297, 301, 305
Integer Programming, 137, 140, 144
Matrices, 367
Networks I, 221, 225, 229
Networks II, 313, 317, 321, 325
Paths, 89, 93, 97
Plenary I, 373
Plenary II, 125
Plenary III, 257
Polyhedra, 247, 251
Polynomial-time Algorithms,
265, 269

261,

Quadratic Programming, 105, 109
Traveling Salesman Problem, 3, 7, 11
Trees, 115, 120

388

List of Timeslots
Thu 4 [08:45–10:15], 261, 265, 269,
277, 285
Thu 4 [10:30–12:30], 281, 293, 297,
301, 305, 313, 317, 321, 325
Thu 4 [14:00–15:30], 333, 337, 341,
347, 351, 355
Thu 4 [15:45–16:15], 361, 367
Thu 4 [16:45–17:30], 373
Tue 2 [08:45–10:15], 3, 7, 11, 19, 23,
28, 64
Tue 2 [10:30–12:30], 35, 40, 44, 48,
55, 60, 68
Tue 2 [14:00–15:30], 75, 79, 84, 89,
93, 97
Tue 2 [15:45–16:45], 105, 109, 115,
120
Tue 2 [16:45–17:30], 125
Wed 3 [08:45–10:15], 137, 140,
149, 153, 157
Wed 3 [10:30–12:30], 163, 171,
180, 187, 191, 195, 199
Wed 3 [14:00–15:30], 205, 210,
221, 225, 229
Wed 3 [15:45–16:45], 235, 239,
251
Wed 3 [16:45–17:30], 257

144,
175,
215,
247,

389

Keywords
Q-integral graph, 157
δ-hyperbolic metric spaces, 257

clustering, 163
cographs, 199
coherent probability, 235
collaborative filtering, 175
colored graphs, 35
colored spanning trees, 115
coloring, 35
column generation, 321, 355
combinatorial algorithm, 351
combinatorial optimization, 48, 225,
293, 341
complexity, 105
computational complexity, 261
conflict graph, 225, 293
conformation, 337
constrained routing, 97
cooperation, 361
coordinate algorithm, 93
core, 361
critical simplex, 277
cutting plane, 215
cutting planes, 125
Cutting Stock Problem, 75
cycle with a unique chord, 55

acyclic, 60
acyclic coloring, 199
acyclic graph, 115
allocation mechanism, 361
anonymity, 269
anonymous routing, 269
anonymous subgraph problem, 269
approximation algorithms, 265
APX-hardness, 313
arc routing problem, 11, 89
arrangements, 105
Berge graph, 28
biclique, 205
bilevel programming, 125
bioinformatics, 337, 341
block graphs, 195
boolean probability bounding problem,
235
boundary of tractability, 373
branch and bound, 144, 163, 210
branch and prune, 337
branch-and-price, 187, 215
branching, 144
branchwidth, 19
Breadth-First Search, 257

decomposition methods, 137
degree, 285
descent method, 225
diameter, 257
directed hypergraph, 229
discrete control problems, 221
distance geometry, 337
dominance constraints, 137
double graph, 157
duality, 19
dynamic programming, 163, 247

c-edge-colored graph, 115
cardinality constraint, 347
cartesian product of graphs, 297
caterpillar trees, 48
center computations, 257
chemistry, 333
cherry trees, 235
chordal graphs, 235
chromatic number, 191, 297
circle graphs, 281
classification, 333
clique, 285, 347

edge coloring, 64
edge connectivity, 301
edge connectivity augmentation, 301
edge cutset, 97
edge-covering number, 153

390

edge-perfect graph, 153
efficient algorithms, 7, 261
emergency services, 180
enumeration, 333
enumeration algorithm, 305
Euclidean traveling salesman problem,
3
exact algorithm, 205, 321
exact algorithms, 215
exact method, 48
excellent discrete Morse function, 277
exponential-time algorithm, 205
extremal properties, 149
extremal stable graphs, 149
extreme set, 301

hyperplane clustering, 355

feeding precedences, 210
finite fields, 367
flows over time, 321
formulation by representatives, 187
fractional packing, 265
frugal, 60

Kasteleyn city, 351
knapsack and subset sum problem, 44
knapsack problem, 293

improper, 60
independent set, 35, 40, 225
infinite locally finite graph, 277
integer flow, 239
integer linear programming, 180
integer nonlinear programming, 317
integer programming, 48, 137, 144,
180, 261, 341
intermediate trees, 120
interval coloring, 64
inverse problems, 325
isolated clique size, 285
iterative approach, 3

Lagrangian relaxation, 171, 210
LIFO constraints, 7
linear-time recognition algorithm, 23
location, 180
lower bounds, 75

games, 44, 68
gene regulatory networks reconstruction, 325
general disjunctions, 144
generalized flow, 239
goal directed search, 93
goal oriented shortest path, 93
gradient path, 277
gradient vector field, 277
graph, 19, 55, 60, 79, 97, 149, 153,
157, 199, 205, 277, 293, 297
graph algorithms, 313
graph coloring, 60, 191, 195
graph partitioning, 347
graph theory, 28
graph’s topology, 269
graphs on surfaces, 19

makespan, 210
Markov processes, 221
mathematical programming, 325
matrices, 367
matrices over finite fields, 367
max-cut, 351
maximally violated valid inequalities,
125
maximum adjacency order, 301
maximum capacity path, 175
maximum independent set problem, 40
metaheuristic, 355
min-max resource sharing, 265
minimal prime extension, 305
minimal weight increment, 97
minimum caterpillar spanning problem, 48
minimum cut, 301
minimum spanning tree, 293
minimum sum coloring, 195

Helly circle graphs, 281
heuristic, 3, 225, 239
hierarchical product, 157
hop constraints, 247
hypergraph, 229
391

problem contraction, 3
problem reduction, 89
protein, 337, 341
protein molecules, 337
protein structure alignment, 341
protein threading problem, 341
pseudo backbone, 3

mixed integer nonlinear programming,
373
modular decomposition, 305
modules in graphs, 305
molecule, 337
Morse functions, 277
multi-agent optimization, 44
multicommodity min-cost flow over
time, 321
multicuts, 313
multiobjective optimization, 317
multipliers, 239

quadratic semi-assignment problem,
109
quasi-threshold graphs, 23
Ramsey Theory, 40
randomization, 361
recognition algorithm, 229
rectangle packing, 84
reducible flow graph, 229
reformulation linearization technique,
109
regular graphs, 55
replacement model, 285
rerouting, 97
resistance of a graph, 64
resource allocation, 68
restricted entries, 367
RLT, 109
robustness, 171
rounding heuristics, 239
RWA, 225

nanocone, 333
network, 97, 257
network optimization, 317
nonapproximability bounds, 115
nonlinear discrete optimization, 373
NP-completeness, 55, 84, 115, 235
NP-hard problem, 205
NP-hardness, 89, 313
Nullstellensatz, 367
odd chordless cycle, 153
offensive alliances, 297
optical networks, 225
OSPF, 97
packings, 79
parameterized algorithms, 79
parameterized complexity, 40
pareto frontier, 317
parking, 11
parking warden tour, 11
partition coloring, 187
path polytope, 247
permanent, 367
pivot algorithm, 120
planar graph, 351
polyhedral combinatorics, 251
polyhedral embedding, 19
polynomial algorithm, 301
polynomial algorithms, 115
polynomial instances, 153
power-law, 285
probabilistic constraint, 140

scheduling, 210
secret santa, 269
separation, 125
set-coloring, 195
shortest path, 93, 239
signless Laplacian, 157
SLD, 225
sliding shortest path, 97
spanning tree, 120
split disjunctions, 144
stability, 149
stability number, 153
stable graphs, 149
stable set polytope, 251
star coloring, 199
stochastic dominance, 137
392

stochastic integer programming, 137
stochastic network, 221
stochastic programming, 140
structural characterizations, 281
submodular functions, 347
successive shortest paths, 239
symmetry, 361
system, 361
tabu search, 163
time-expanded network, 221
total chromatic number, 55
train timetabling, 171
traveling salesman problem, 3, 7
two-stage knapsack problem, 140
unconstrained quadratic programming,
105
undirected graphs, 301
unit disk graph, 35
upper bounding scheme, 191
upper bounds, 191
value, 361
vehicle routing problem, 215
vertex degree, 120
VLSI design, 35, 265
WDM, 225
Weber set, 361
window based approach, 3

393

Available online at www.sciencedirect.com

European Journal of Operational Research 194 (2009) 711–727
www.elsevier.com/locate/ejor

Production, Manufacturing and Logistics

Real-time vehicle rerouting problems with time windows
Jing-Quan Li a,*, Pitu B. Mirchandani b, Denis Borenstein c
a
California PATH, University of California, Berkeley, Richmond, CA 94804, United States
Department of Systems and Industrial Engineering, The University of Arizona, Tucson, AZ 85721, USA
c
Management School, Universidade Federal do Rio Grande do Sul, R. Washington Luis 855, Porto Alegre 90010-460, RS, Brazil
b

Received 5 June 2007; accepted 21 December 2007
Available online 1 February 2008

Abstract
This paper introduces and studies real-time vehicle rerouting problems with time windows, applicable to delivery and/or pickup services
that undergo service disruptions due to vehicle breakdowns. In such problems, one or more vehicles need to be rerouted, in real-time, to
perform uninitiated services, with the objective to minimize a weighted sum of operating, service cancellation and route disruption costs.
A Lagrangian relaxation based-heuristic is developed, which includes an insertion based-algorithm to obtain a feasible solution for the
primal problem. A dynamic programming based algorithm solves heuristically the shortest path problems with resource constraints that
result from the Lagrangian relaxation. Computational experiments show that the developed Lagrangian heuristic performs very well.
Ó 2008 Elsevier B.V. All rights reserved.
Keywords: Vehicle routing; Rerouting; Schedule recovery; Lagrangian heuristic

1. Problem statement
The dynamic vehicle routing problem has gained increasing attention among logisticians since the late eighties with the
focus on uncertain travel times and online requests arising in midst of operations (Bertsimas and Simchi-Levi, 1996; Gendreau and Potvin, 1998; Ghiani et al., 2003; Psaraftis, 1995). However, freight logistics systems can also suﬀer unexpected
disruptions such as vehicle breakdowns and traﬃc accidents. When trucks used by delivery/pickup companies are involved
in severe accidents, the ﬂeet plan needs to be adjusted in real-time depending on the current state of the system. Few studies
have addressed such real-time rerouting and rescheduling problems.
1.1. Naive approaches
In manual approaches, the schedulers often cancel the services that are initially scheduled for the disabled truck when no
extra truck is available at the depot. When extra trucks are available at the depot and the original service is to deliver packages to customers, a simple approach is to send an extra truck to the breakdown point to collect the packages and then to
deliver these packages to the corresponding customers. When the original service is to pickup the packages from the customers, the solution of naive re-planning consists of sending an extra truck to pickup the packages from the customers that
are initially scheduled to be collected by the breakdown vehicle. In both problems, some additional constraints, such as
vehicle capacities and time windows, need to be satisﬁed. Therefore, a few services may have to be cancelled in some situations. A typical such instance is when the breakdown point is at a considerable distance from the depot and other
*

Corresponding author.
E-mail addresses: jingquan@path.berkeley.edu (J.-Q. Li), pitu@sie.arizona.edu (P.B. Mirchandani), denisb@ea.ufrgs.br (D. Borenstein).

0377-2217/$ - see front matter Ó 2008 Elsevier B.V. All rights reserved.
doi:10.1016/j.ejor.2007.12.037

712

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

2

SD 1

SD 1

2

SD 1

1

0

7

1

0

SD 2

4

2

3

3

3
7

1

0

7
Customer

10

X

SD 2

10

X

8

SD 2

5

6

10

X

8

Depot

8

5

6

5

6

Pseudo−depot
Initial Route

9

9
Naive Approach
for Delivery Services

Initial Route

9
Naive Approach
for Pickup Services

New Route
X

Breakdown
Point

Fig. 1. An example of the naive approach with a backup vehicle at the depot.

operating vehicles, or when there is no extra vehicle at the depot. The naive approach may produce a poor solution since it
only employs simple recovery strategies.
An example is used to illustrate the vehicle rerouting problem and a naive approach. Fig. 1a shows the initial route,
where three vehicles serve 10 customers. Vehicle 1 serves the customers 1, 2 and 3; vehicle 2 serves the customers 8, 9
and 10; and vehicle 3 serves the customers 4, 5, 6 and 7. Suppose that vehicle 3 breaks down at point X. Vehicle 1 has
ﬁnished serving customer 1 and is currently traveling toward the customer 2 at the breakdown time; vehicle 2 is traveling
toward customer 8. If the naive approach is used and no extra vehicle is available at the depot, vehicle 3 will be towed to the
depot and the services scheduled for customers 5, 6 and 7 may be cancelled.
Fig. 1b presents the new route by the naive approach for the delivery service when a backup vehicle is available at the
depot. The naive approach sends the backup vehicle to the breakdown point X for collecting the packages. Then customers
5 and 6 are served by the backup vehicle, but the service of customer 7 is cancelled since the delivery is delayed and the time
window constraint of customer 7 cannot be satisﬁed. If the original routing problem is for the pickup service, the backup
vehicle starts from the depot to pickup the packages from customers 5 and 6 directly. It is not necessary for the backup
vehicle to go to the breakdown point ﬁrst to load the packages (see Fig. 1c).
1.2. Optimization based approaches
Alternative approaches for real-time vehicle rerouting are to use optimization algorithms which can produce good vehicle route reassignments based on the status of the whole ﬂeet. The development of technologies, such as global positioning
systems, geographical information systems and wireless communication, makes it possible to provide the real-time information at low cost and makes it practical to employ real-time vehicle rerouting algorithms.
For the static vehicle routing problem, one usually does not distinguish between the pickup and delivery problems.
However, these problems have to be considered diﬀerently in real-time rerouting setting. If a vehicle breaks down in a
pickup problem, other vehicles can change their routes to collect the packages from customers not originally scheduled
in. When the vehicle breakdown occurs in a delivery problem, the vehicles may change their routes to ﬁrst pickup the packages currently loaded on the breakdown vehicle and then deliver to the corresponding customers, but they cannot serve the
customers that are initially scheduled for other vehicles if exchanging goods between vehicles is not allowed. If the original
service is to pickup the packages, the corresponding rerouting problem will be referred to as the vehicle rerouting problem
for the pickup service; if the original service is to delivery the packages, the corresponding rerouting version will be referred
to as the vehicle rerouting problem for the delivery service. It is expected that the rerouting problem for pickup services has a
more complicated underlying network than the corresponding delivery one, since a vehicle in the rerouting problem for
pickup services can visit more customers.
The vehicle rerouting problem with time windows presents some special considerations. An important issue is related to
route disruptions. If only operating costs and service cancellation costs are minimized, the original routes might be considerably disrupted. Thus, it is crucial to reduce the number of changes in the development of new routes since truck drivers
may not be familiar with new delivery or pickup points. Our strategy is to impose penalties on each route change in order
to reduce route disruptions.
Currently operating vehicles need to be modeled explicitly in the rerouting setting since the operating vehicles are at different positions at time of the breakdown and may have diﬀerent operating costs to service each of the given customers. In
the rerouting problem, an operating vehicle can be modeled as a pseudo-depot with one available vehicle: the vehicles
currently serving customers can only change their routes after ﬁnishing their current service, while the vehicles currently

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

713

deadheading or waiting can be rerouted immediately. An availability time is also associated with each pseudo-depot in
order to determine if this operating vehicle can be on time to serve a future customer. If an operating vehicle is currently
servicing a customer, the availability time of the vehicle at the corresponding pseudo-depot is set as the ending time of that
service; if an operating vehicle is deadheading or waiting, the availability time of the vehicle at the corresponding pseudodepot is set as the breakdown time.
Another issue in rerouting is related to backup vehicles from the depot. Freight companies may have extra vehicles available at the depot. It is likely to allocate these extra vehicles to complete some services if an accident occurs. Nevertheless,
this assignment may fail in the rerouting setting if the arrival time of the backup vehicle, from the depot to the customer, is
later than the speciﬁed latest starting time of the service. When we assign an availability time to the backup vehicles at the
depot, we can use it to determine if a backup vehicle from the depot can be on time to serve a customer in its time window.
In this context, the availability time may be deﬁned as the vehicle breakdown time plus some setup time.
Thus, the real-time vehicle rerouting problem with time windows can be deﬁned as follows. Given a depot, a number of
vehicles with the limited capacities, and a set of customer services having demands with time windows, given the travel time
between all pairs of locations, given the vehicle routes originally planned, and given a breakdown vehicle with the breakdown time and position, ﬁnd feasible route reassignments with the minimum weighted sum of operating, ﬁxed vehicle, service cancellation and route disruption costs, in which (i) each vehicle performs a feasible sequence of services, satisfying
constraints related to the service time windows and vehicle capacities; and (ii) a service is either satisﬁed, or cancelled with
a large service cancellation cost when some constraints cannot be satisﬁed.
In addition, in order that drivers can be reassigned on new route en route on their customer schedules, the computation
needs to be completed quickly. We may also assume that disabled vehicles may towed back to the depot possibly with packages. We will not consider using the currently operating vehicles to transport the packages loaded on the breakdown vehicles back to the depot.
1.3. Preview of the paper
The major contributions in this paper include: (i) a path-based formulation of the vehicle rerouting problem with time
windows; (ii) the development of a Lagrangian heuristic, incorporating Lagrangian relaxation and an insertion based primal heuristic; and (iii) a dynamic programming based heuristic for solving the Lagrangian relaxation problem quickly
instead of solving it to optimality.
This paper is organized as follows. Section 2 reviews related work on real-time schedule recovery. Section 3 models and
formulates the vehicle rerouting problem with time windows. A Lagrangian heuristic is proposed in Section 4. The
Lagrangian relaxation problem turns out to be some shortest path problems with time window and vehicle capacity constraints. Due to NP-hard complexity of constrained shortest path problems and the requirement of solving the problem in
real-time, a dynamic programming based algorithm is proposed to obtain a good solution for the Lagrangian relaxation
heuristically rather than optimally. Based on the solution of the Lagrangian relaxation problem, an insertion based heuristic is designed to obtain a solution for the primal problem. The Lagrangian multipliers are updated by using a subgradient based method. Section 5 presents results of computational experiments. Areas of future research are discussed in
Section 6.
2. Literature review
Recent surveys on dynamic vehicle routing/scheduling problems can be found in Bertsimas and Simchi-Levi (1996),
Gendreau et al. (1996a), Gendreau and Potvin (1998), Ghiani et al. (2003), and Psaraftis (1995). The dynamic vehicle routing problem considering online requests and uncertain travel times has been solved by tabu search (Gendreau et al., 1996b,
2001; Ichoua et al., 2000), genetic algorithms (Haghani and Jung, 2005), assignment and/or insertion based heuristics (Fleischmann et al., 2004; Shieh and May, 1998), approximation dynamic programming (Spivey and Powell, 2004), rule-based
heuristics (Regan et al., 1996, 1998), local optimization approach (Mahmassani et al., 2000), dynamic column generation
(Chen and Xu, 2006) and nearest-vehicle based heuristic (Du et al., 2005). Yang et al. (2004) have developed a general
framework for the dynamic vehicle routing problem in which new requests can arrive during operations. Huisman et al.
(2004) propose an dynamic vehicle scheduling approach in order to avoid trips starting late in environments characterized
by signiﬁcant traﬃc jams. El Rhalibi et al. (2003) use a genetic algorithm for a container transport problem with unexpected disruptions. Fabri and Recht (2006) consider a dynamic pickup and delivery problem for taxi services with online
phone requests. Stochastic programming has also been used to tackle uncertainty in vehicle scheduling and routing (Gendreau et al., 1995; Laporte and Louveaux, 1998; Powell et al., 1995). Larsen et al. (2004) study a dynamic traveling repairman problem where some of customer requests occur dynamically.
Numerous studies have been done in airline schedule recovery problems, which includes Carlson (2000), Lettovský
(1997), Rosenberger et al. (2003), Yan and Yang (1996), Jarrah et al. (1993), Yu et al. (2003), Teodorović and Stojković

714

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

(1995). These research eﬀorts develop exact optimization models that reschedule ﬂight legs and reroute aircraft by minimizing rerouting and cancellation costs.
However, the schedule disruption costs and vehicle breakdowns are not fully considered in above dynamic routing and
airline recovery problems. In a series of previous studies (Li et al., 2004, 2007a,b,c), the authors have introduced the single
depot vehicle rescheduling problem for public transit systems in case some vehicles break down in the midst of operations.
The problem was modeled as a sequence of static vehicle scheduling problems and was pseudo-polynomially solved by the
several auction based algorithms (Li et al., 2004, 2007b); a decision support system to facilitate practical applications in the
solid waste collection was further developed (Li et al., 2007a). However, reducing schedule disruptions was not considered
in these studies. A Lagrangian-relaxation-based trip insertion heuristic is developed in Li et al. (2007) to consider the
scheduled disruption and trip cancellation costs. The earlier studies of the authors were in the context of public transportation systems; delivery/pickup issues related to vehicle capacities and customer demands with time windows were not
considered.
3. Modeling the problem
In this paper, we do not distinguish between an operating vehicle and the corresponding pseudo-depot since every operating vehicle is modeled as a pseudo-depot.
3.1. Constructing the underlying network for rerouting
Let s simply mean the depot as a starting point, and t as a terminating point. We will allow more than one vehicle breakdown at any time; let B be the set of vehicle breakdowns with positions and time. Let SD be the set of pseudo-depots with
locations and availability times, which represent the currently operating vehicles. SD [ fsg denotes the set of all depots. Let
tij be the travel time from node i to node j plus the service time at node i.
3.1.1. Vehicle rerouting for pickup services
Let N be the set of the nodes representing the customers with uninitiated services. The time window of node i 2 N is
½ai ; bi . Each node i 2 N has a demand qi . To satisfy the constraint of vehicle capacities, the demand of a pseudo-depot
is deﬁned as the sum of demands of the customers that are already loaded on the vehicle. The demand of s is 0.
For each pseudo-depot/depot d 2 SD [ fsg, deﬁne the set EðdÞ ¼ fði; jÞjai þ tij 6 bj ; i 2 N [ fdg; j 2 N [ ftgg, representing the arcs for the pseudo-depot/depot d. If arc ði; jÞ appears in the original route of the pseudo-depot d, no penalty
values are added. Otherwise, a penalty is added to reduce route disruptions.
3.1.2. Vehicle rerouting for delivery services
A special aspect of the rerouting problem for the delivery service is that currently operating vehicles have to go to the
breakdown points for collecting the packages ﬁrst and then to delivery these packages to their corresponding customers.
Our strategy is to create some pickup nodes with the demand and time windows at the breakdown point, where each pickup
node corresponds to a delivery service. Let P ðbÞ be the set of these pickup nodes for the breakdown vehicle b 2 B. Thus, for
each node i 2 P ðbÞ; b 2 B, there exist a corresponding delivery node dðiÞ, which represents the customer that the pickup
package should be delivered to. Let DðbÞ ¼ fdðiÞji 2 P ðbÞ; b 2 Bg be the set of delivery nodes for breakdown vehicle b.
Let P ¼ [b2B P ðbÞ be the set of all pickup nodes, and let D ¼ [b2B DðbÞ be the set of all corresponding delivery nodes.
For each node d 2 SD, deﬁne the OðdÞ to the set of nodes representing the customers whose packages are loaded in the
currently operating vehicle d. For the real depot s; OðsÞ is an empty set. Let N ¼ [d2SD OðdÞ [ P [ D be the set of the nodes
that the vehicles may service in the operations. Note that, for each pseudo-depot d 2 SD, its corresponding vehicle can only
visit the nodes in OðdÞ [ P [ D [ ftg; for a vehicle from real depot s, it can only visit the nodes in P [ D [ ftg.
For the pickup nodes in P, we deﬁne the earliest service time to be the breakdown time and the latest service time to be
the arrival time of the tow truck from the depot. If other vehicles arrive at the breakdown point later than the latest service
time, these packages have already been towed back to the depot.
For each pseudo-depot/depot d 2 SD [ fsg, deﬁne arc set E1ðdÞ ¼ fði; jÞjai þ tij 6 bj ; i 2 OðdÞ [ P [ D [ fdg; j 2 OðdÞ[
P [ D [ ftgg, representing the possible travel between the nodes. However, some infeasible arcs need to be removed from
this set E1ðdÞ to develop the underlying network. The arcs from the delivery nodes to their corresponding pickup nodes
need to be removed. Let E2ðbÞ ¼ fði; jÞjai þ tij 6 bj ; i 2 DðbÞ; j 2 P ðbÞg represent the arcs from the delivery nodes to their
corresponding pickup nodes for the breakdown vehicle b 2 B. Let the set E2 ¼ [b2B E2ðbÞ include all such arcs for all the
breakdown vehicles.
Each pickup node in P ðbÞ; b 2 B has the same time windows and is at the same locations, which results in some unnecessary arcs between the pickup nodes in P ðbÞ. For example, consider an operating vehicle that goes to a breakdown point
to pickup two packages. The visiting order of two pickup nodes is not important. We can remove unnecessary arcs by

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

715

ordering each pickup node set P ðbÞ using the demand of each package. For each breakdown vehicle b 2 B, the arc set
fði; jÞji 2 P ðbÞ; j 2 P ðbÞ; i is ordered before jg, represents the possible travel between the pickup nodes at the same breakdown point. Deﬁne set E3ðbÞ ¼ fði; jÞji 2 P ðbÞ; j 2 P ðbÞ; j is ordered before ig to be the unnecessary arcs that need to be
removed. Let set E3 ¼ [b2B E3ðbÞ be such unnecessary arcs for all the pickup nodes.
Therefore, for each pseudo-depot/depot d 2 SD [ fsg, the underlying network for rerouting is deﬁned as
GðdÞ ¼ fN ðdÞ; EðdÞg with nodes N ðdÞ ¼ OðdÞ [ P [ D [ fd; tg and arcs EðdÞ ¼ E1ðdÞ  E2  E3. For the pseudo-depot
d 2 SD, arc cost cdij is deﬁned as a combination of travel time along arc ði; jÞ 2 EðdÞ and possible penalty values due to
a route disruption.
The demand of an operating vehicle includes the sum of demands of the customers that are currently loaded in the vehicle. For the pickup node, the demand qi is positive, while for other nodes, the demand is negative.
3.2. Set covering based formulation
First, we note that the real-time vehicle rerouting problem with time windows is NP-hard (see the sketch of the proof in
Appendix). The path-based formulation has been successfully used for the vehicle routing problem with time windows
(Desrochers et al., 1992). The deﬁnition of admissible paths for the vehicle rerouting problem with time windows is as follows: (i) the total vehicle capacity cannot be exceeded at any node in the path; (ii) the service starting time at each node has
to be within the time window; and (iii) in the rerouting problem for the delivery service, before delivering a package to a
customer that is originally scheduled for a breakdown vehicle, the corresponding pickup node has to be visited.
Let PH ðdÞ represent the set of all origin-destination admissible paths in EðdÞ from d to t, for all d 2 SD [ fsg. Introduce
a binary variable y dp , where y dp ¼ 1 if the path p 2 PH ðdÞ is selected as the path starting from d, and y dp ¼ 0 otherwise. The
cost of path p 2 PH ðdÞ is denoted as cdp , which equals the sum of costs of all the arcs in the path. The arc cost includes the
operating cost plus the possible disruption cost. Let dpij equal 1 if arc ði; jÞ is covered by path p 2 PH ðdÞ and equal 0 otherwise. Let C i be the service cancellation cost at node i 2 N , which is related to the importance of a service. Introduce a binary variable zj , where zj ¼ 1 if service j is cancelled, and zj ¼ 0 otherwise.
The path-based formulation of the real-time vehicle rerouting problem with time windows is as follows (formulation F1):
X
X
X X
cdij dpij y dp þ
C j zj ;
ð1aÞ
min
d2D p2PH ðdÞ i:ði;jÞ2EðdÞ

s:t:

X

y dp

j2N

d ¼ s;

ð1bÞ

8d 2 SD;

ð1cÞ

6W

p2PH ðdÞ

X

y dp ¼ 1

p2PH ðdÞ

X X

X

dpij y dp þ zj ¼ 1

8j 2 N ;

d2D p2PH ðdÞ ði;jÞ2EðdÞ

y dp 2 f0; 1g 8p 2 PH ðdÞ; d 2 SD [ fsg;
zj 2 f0; 1g

8j 2 N :

ð1dÞ

Constraint (1b) guarantees that extra vehicles from the depot cannot exceed a given number, W; W is zero when there are
no vehicles available at the depot. Constraints (1c) ensure that capacity of each pseudo-depot is one. Constraints (1d) guarantee that each uninitiated service is either covered or cancelled.
P
P P
Variables zj can be removed as follows: (i) replace zi in the objective function as 1  d2D p2PH ðdÞ i:ði;jÞ2EðdÞ dpij y dp ; and (ii)
P
P P
replace the constraints (1d) as d2D p2PH ðdÞ i:ði;jÞ2EðdÞ dpij y dp 6 1. The alternative formulation (formulation F2) is:
X
X
X X
ðcdij  C j Þdpij y dp þ
Cj ;
ð2aÞ
min
d2D p2PH ðdÞ i:ði;jÞ2EðdÞ

s:t:

X

y dp

j2N

d ¼ s;

ð2bÞ

8d 2 SD;

ð2cÞ

6W

p2PH ðdÞ

X

p2PH ðdÞ

y dp ¼ 1

X X

X

dpij y dp 6 1

8j 2 N ;

ð2dÞ

d2D p2PH ðdÞ ði;jÞ2EðdÞ

y dp 2 f0; 1g 8p 2 PH ðdÞ; d 2 SD [ fsg:
Two formulations have diﬀerent impacts on the algorithmic performance, which is discussed in detail in the next section.

716

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

We will develop a Lagrangian heuristic to solve the rerouting problem since Lagrangian relaxation has been successful
for many combinatorial optimization problems, such as the set covering problem (Caprara et al., 1999) and the vehicle
routing problem with time windows (Kohl and Madsen, 1997). Better Lagrangian multipliers are found, longer the algorithm runs. If near-optimal Lagrangian multipliers are obtained, slightly adjusting the solution from the Lagrangian subproblem may result in a very good solution (Larsson and Patriksson, 2006).
The real-time vehicle rerouting problem needs to be solved quickly. It is also very diﬃcult to pre-deﬁne an upper bound
on the time needed to obtain a new route, since this real-time operational issue is highly dependent on their status. We
believe that a reasonable target on the computational time should be no more than a minute or two.
4. A lagrangian heuristic for the problem
If formulation F1 is used and constraint sets (1b) and (1c) are relaxed, it is highly possible that in the solution of
Lagrangian relaxation, more than one path originate from the same pseudo-depot. The solution of Lagrangian relaxation
is diﬃcult to adjust to yield a feasible solution to the primal problem. Thus, covering constraints (1d) are selected to be
relaxed. By same arguments in formulation F2, constraints (2d) are selected to be relaxed.
Using multipliers lj for the constraint (1d), the Lagrangian dual problem based on formulation F1 is (LD1):
X X
X
X
X
max LðuÞ ¼ min
ðcdij  lj Þdpij y dp þ
ðC j  lj Þzj þ
lj ;
ð3aÞ
s:t:

d2D p2PH ðdÞ ði;jÞ2EðdÞ

X

y dp

6W

j2N

j2N

d ¼ s;

ð3bÞ

8d 2 SD;

ð3cÞ

p2PH ðdÞ

X

y dp ¼ 1

p2PH ðdÞ

y dp 2 f0; 1g

8p 2 PH ðdÞ; d 2 SD [ fsg;

zj 2 f0; 1g 8j 2 N :
If multipliers lj are used for constraint (2d), the Lagrangian dual problem based on formulation F2 is (LD2):
X
X X
X
X
max LðlÞ ¼ min
ðcdij  C j þ lj Þdpij y dp 
lj þ
Cj ;
lP0

s:t:

d2D p2PH ðdÞ ði;jÞ2EðdÞ

X

y dp 6 W

j2N

ð4aÞ

j2N

d ¼ s;

ð4bÞ

p2PH ðdÞ

X

y dp ¼ 1

8d 2 SD [ fsg;

ð4cÞ

p2PH ðdÞ

y dp 2 f0; 1g 8p 2 PH ðdÞ; d 2 SD [ fsg:
Note that equality constraints of (1d) correspond to unrestricted dual variables, while inequality constraints of (2d) correspond to non-negative dual variables. The Lagrangian dual problem LD2 has a smaller solution space than LD1, and
it would seem that formulation F2 is better than formulation F1. However, this may not be the case for the vehicle rerouting problem with time windows.
Observe that the Lagrangian relaxation problems of both F1 and F2 are shortest path problems with the time window
and vehicle capacity constraints. When the arc cost is deﬁned as the Lagrangian reduced cost, negative cycles possibly exist
in the network, which makes the problem very diﬃcult. The elementary shortest path problem with resource constraints
has been proved to be NP-hard in the strong sense (Dror, 1994). Formulation F2 is more likely to generate negative cycles
because of the following. When vehicle breakdowns occur, freight companies attempt to avoid cancelling the services,
which means the use of a large cancellation cost ðC j Þ for each service. In LD2, the reduced cost is deﬁned as cdij  C j þ
lj . When C j is large, cdij  C j þ lj tends to be negative, especially when lj is small in early stages of algorithm execution.
In LD1, the reduced cost is cdij  lj , which tends to be non-negative, especially at the early stages of algorithm execution.
The impact of the arc cost on the Lagrangian relaxation is mentioned in Kohl and Madsen (1997). Our preliminary experiments support this point. Thus, we only used formulation F1 and Lagrangian dual LD1 to develop the algorithm.
4.1. A dynamic programming based heuristic for the lagrangian relaxation
Some dynamic programming based algorithms have been proposed to solve the elementary constrained shortest path
problems (Feillet et al., 2004; Righini and Salani, 2006). Due to the nature of strong NP-hardness, the computational time
of these algorithms may be exponential in the worst case. Some pseudo-polynomial algorithms have been proposed to solve

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

717

a relaxed version by eliminating two cycles (Desrochers et al., 1992; Houck et al., 1980) and k ðk P 3Þ cycles (Irnich and
Villeneuve, 2006). When k becomes larger, the computational time increases signiﬁcantly (Irnich and Villeneuve, 2006).
Therefore, we decided to employ the 2-cycle elimination technique to solve a relaxed constrained shortest path.
Each state is represented by a label, ði; t; qÞ, where i is the last reached node, t is the availability time and q is the accumulated demand. The cost of label ði; t; qÞ is cði; t; qÞ, representing the accumulative cost from the pseudo-depot/depot. The
label cost of the pseudo-depot/depot is 0. The dynamic programming algorithm for the constrained shortest path problem
is based on some dominance criteria. A label ði; t1 ; q1 Þ dominates another label ði; t2 ; q2 Þ if and only if (1)
cði; t1 ; q1 Þ 6 cði; t2 ; q2 Þ; (2) t1 6 t2 ; and (3) q1 6 q2 .
We use the technique of Larsen (1999) to eliminate 2-cycles. Each label has a type being either strongly dominant, semistrongly dominant, or weakly dominant. The label is extended to ði; t; q; predÞ, where pred is the predecessor of node i. A
label ði; t; q; predÞ is denoted strongly dominant if it is not dominated by any other labels and at least one of the following
additional conditions are satisﬁed: (4) t þ ti;pred > bpred ; and (5) q þ qpred > Q, where Q is the vehicle capacity, ti;pred is the
travel time from i to pred, and qpred is the demand at customer pred. If at least one of (4) and (5) are satisﬁed, the vehicle
cannot go back to visit pred after customer i is ﬁnished. Thus, 2-cycles are avoided. The label is called semi-strongly dominant if it is not dominated by any other labels and none of the conditions (4) and (5) is satisﬁed. A label is called weakly
dominant if it is only dominated by semi-strongly dominant labels, and the weakly dominant label and corresponding semistrongly dominant label do not have a common predecessor. When the semi-strongly dominant label attempts to extend to
its predecessor, it is disallowed and the weakly dominant label is used instead. That is the only use of the weakly dominant
label. Details can be found in Larsen (1999).
4.1.1. Special aspects in the rerouting problem for the delivery service
The above dominance criteria are not suﬃcient in the rerouting problem for delivery services, where before a package is
delivered to the customer that is originally scheduled to be served by a breakdown vehicle, the corresponding pickup node
has to be visited to load the package. A label cannot be extended to the delivery node (i.e., the delivery node cannot be
reached) until the corresponding pickup node has been visited. Thus, if a pickup node has been visited in label X, it cannot
be dominated by label Y that has not visited this pickup node, even if label Y dominates label X by the dominance rule
discussed above. Label X is able to be extended for delivering the package to the customer that is originally scheduled
for the breakdown vehicle, but label Y cannot be extended.
This special aspect corresponds to the precedence constraint in the vehicle routing problem with pickup and delivery,
which is solved by listing feasible paths explicitly in Dumas et al. (1991). The approach of listing the paths explicitly, however, may not be suitable for the vehicle rerouting problem since the pickup and delivery nodes are not known until a
breakdown occurs.
In our approach, the information for visiting pickup nodes is added in each state. The label is expanded to
ði; t; q; pred; SÞ, where S is a vector indicating if the pickup nodes have been already visited. The dimension of S is the number of pickup nodes. If label X has included a visit at a pickup node and label Y does not, label Y cannot dominate label X.
The disadvantage of the approach is that more computer memory is required.
4.1.2. Solving the constrained shortest path problem heuristically
The dynamic programming algorithm for the constrained shortest path problem is based on the label dominance. The
number of labels signiﬁcantly impacts the algorithm performance. In the vehicle rerouting problem, the number of constrained shortest path problems that need to be solved in each iteration equals the number of the pseudo-depots and real
depot. Thus, solving the constrained shortest path problems becomes the computational bottleneck of the problem. Sometimes, even solving a single constrained shortest path problem optimally takes a long time. Righini and Salani (2006) present computational details for solving the elementary constrained shortest path problems using benchmark instances
developed by Solomon (1987). Desrochers et al. (1992) give the total computational time when the constrained shortest
path problem with 2-cycle elimination is used, but the time for solving a single constrained shortest path is not presented.
In order to obtain a solution quickly, we decide to solve the constrained shortest path problems heuristically. Since the
number of labels impacts the computational time signiﬁcantly, our approach is to limit the number of non-dominated
labels in each node. We deﬁne a upper bound for non-dominated labels for each node. When the number of non-dominated
labels of a node exceeds the upper bound, an existing label is dropped. We ﬁrst attempt to delete the label with the latest
arrival time. If some ties occur, a label with a larger cost is deleted.
The strategy that limits the number of non-dominated labels of each node eﬀectively reduces the computational time.
However, the Lagrangian relaxation problem is not guaranteed to be solved to optimality. As a consequence, the solution
of the Lagrangian relaxation problem using the dynamic programming based heuristic may not be a lower bound to the
vehicle rerouting problem, which makes it impossible to evaluate the optimality gap.
The upper bound for non-dominated labels is related to the problem size, width of time window, vehicle capacities and
computing power. It will be determined by the computational experiments.

718

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

4.1.3. Implementation based on the generalized bucket
The generalized bucket (Desrochers and Soumis, 1988) is an eﬃcient label setting algorithm to implement the constrained shortest path algorithm. Let tmin be the minimal time-length of any arc. Whenever a label is extended, the time
of the new label is at least increased by tmin . If the new label is extended from a label with the presently smallest time t0 ,
it cannot dominate any of the labels in the interval ½t0 ; t0 þ tmin . In the implementation, the total interval, from the breakdown time to the latest ending time, is chopped into smaller intervals of size tmin . The labels are then inserted in the corresponding intervals as they are generated. Note that, it is not necessary to keep all non-dominated labels at the terminating
depot.
Dynamic Programming Heuristic for the Constrained Shortest Path Problem
Step 1: For all the buckets:
Step 1.1: For all the labels in the current bucket:
Step 1.1.1: For all the out-going arcs from the node of the current label:
Step 1.1.1.1: Determine if a new label can be extended from the current label. If so, determine the type of the
new label. If the new label is not dominated, insert it into the corresponding bucket and go to Step
1.1.1.2.
Step 1.1.1.2: Examine if the new label can dominate other existing labels of the corresponding node. If so, delete
these dominated labels. Go to Step 1.1.1.3.
Step 1.1.1.3: Examine if the total number of labels exceeds the given upper bound. If so, delete a label with the
latest arrival time.
Step 2: The label in the terminating depot t with the minimum cost is selected. The shortest path is obtained by backtracking the nodes from this label.
It should be noted that our dynamic programming based heuristic may yield inadmissible paths when a pickup node is
visited, but the corresponding delivery node is not visited. Some techniques for the elementary shortest path (Righini and
Salani, 2006) may be used to remove these inadmissible paths. However, a large computational time may be needed. Our
approach is to allow the generation of such paths in the dynamic programming heuristic. The pickup node in such inadmissible paths is then removed when a solution for the primal problem is constructed.
Fig. 2 is an example to illustrate the dynamic program for the delivery problem. The initial route is shown in Fig. 2a,
where vehicle 1 serves customers 1 and 2, and vehicle 2 serves customers 3 and 4. Suppose that vehicle 2 breaks down at
point X at time 10. Vehicle 1 has ﬁnished serving customer 1 and is currently traveling toward customer 2 at the time 10.
Fig. 2b shows the underlying network after unnecessary nodes are removed. Five remaining nodes are 0; SD1 ; 2; X , and 4.
The travel time for arcs ðSD1 ; X Þ and (0, X) is 2 and 5, respectively, while the travel time of other arcs is 1. The service time
is included in the travel time. The time window of both nodes 2 and 4 is (Dumas et al., 1991; Ghiani et al., 2003), while the
time window of node X is (Dumas et al., 1991; Gendreau et al., 1995) since the tow truck from the depot will reach node X
at time 15 to tow the breakdown vehicle. Assume that the operating cost for each arc is 1, and no penalty is imposed for
each route change. The capacity of the vehicle is 5. The demand of nodes 2 and 4 is 1, while the demand of node X is 1.
The Lagrangian multipliers of nodes 2, X and 4 are 0, 2 and 2, respectively. For arc ði; jÞ, the Lagrangian reduced arc cost,
cdij  lj , is used to calculate the shortest path. Assume that node 0 is allowed to have unlimited numbers of labels, while
other nodes can have only one non-dominated label. The minimal time-length, tmin , is 1.
For the backup vehicle from the real depot, only X and 4 can be visited. Hence, the only route is (0–X–4–0). We consider
the dynamic program for pseudo-depot SD1 . The ﬁrst bucket is at breakdown time 10. The label is (SD1, 10, 1, NIL), where
SD1 is the current node, 10 is the availability time, 1 is the accumulative demand, and NIL denotes no previous node. We
name it as A and the cost is 0 (See Table 1 for the details). Starting from label A, the partial path can be extended to nodes
2 and X. Two new labels are B and C. Now the current bucket is at time 11 and label B is selected. Starting from label B, the
partial path can be extended to node X with the new label (X, 12, 1, 2) and cost 0. But node X has label C. The non-dominated label (X, 12, 1, 2) is not kept since only one label is allowed to exist. Starting from label B, the partial path can be

2

SD 1

3

X

X
1

0
Initial Route

4

Customer

2

SD 1
0

4

Underlying Network

Depot
Pseudo−depot
X Breakdown
Point

Fig. 2. An example of dynamic programming in the delivery service.

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

719

Table 1
Labels in the dynamic programming example
Label

Cost

Name

Previous label

(SD1, 10, 1, NIL)
(2, 11, 0, SD1)
(X, 12, 2, SD1)
(2, 13, 2, X)
(X, 12, 1, 2)
(0, 12, 0, 2)
(0, 13, 2, X)
(4, 13, 1, X)
(2, 14, 0, 4)
(0, 14, 1, 4)

0
1
1
0
0
2
0
2
1
1

A
B
C

NIL
A
A
C
B
B
C
C
F
F

D
E
F
G

Note

Not kept
Not kept

No kept

extended to node 0. The new label, (0, 12, 0, 2), is called label D. Now the current bucket is at time 12 and label C is selected.
From label C, the vehicle can reach node 2 with the label (2, 13, 2, X) and cost 0. It is not kept because node 2 has label B
with the smaller arrival time. From label C, the path can be extended to nodes 0 and 4. Two corresponding labels are E and
F. Now, the current bucket is at time 13 and label F is selected. Similarly, the partial path can be extended to node 2 with
cost 1, but the new label, (2, 14, 0, 4), is not kept. The vehicle can reach node 0 from label F. The new label is G with the
cost 1. Finally, three valid labels of node 0 are D, E and G. The cost of G is the smallest. The corresponding route is
(SD1–X–4–0).
4.2. An insertion based heuristic for obtaining the primal solution
The solution of Lagrangian relaxation is an input to the primal heuristic. The solution of Lagrangian relaxation problem
has the following properties: (i) a cycle may exist even with the 2-cycle elimination strategy; (ii) in the rerouting problem for
delivery services, there possibly exist some inadmissible paths, where a pickup node is visited, but the corresponding delivery node is not visited; and (iii) some customers are not covered, while some customers may be covered by more than one
vehicle.
The insertion algorithm was originally proposed for vehicle routing and scheduling problems with time window constraints by Solomon (1987). Its main idea is to insert an uncovered node between two adjacent nodes on a partial route,
where each of the nodes is satisﬁed with time window and vehicle capacity constraints. We ﬁrst remove the cycles from the
solution of the Lagrangian relaxation problem, which can be completed eﬃciently by scanning the solution. At the same
time, if we ﬁnd an inadmissible path where only a pickup node is visited but its delivery node is not visited, we remove the
pickup node from the path. Finally, we remove any redundant covering in the relaxation problem solution to increase the
opportunity for covering unserved customers. As shown by Caprara et al. (1999), removing redundant covering in an optimal way is a set-covering problem. Since our vehicle rerouting problem needs to be solved quickly, we use a simple heuristic
to remove redundant paths: (i) for each covered node i 2 N , if this node is covered by more than one path, select the ﬁrst
path, and remove this node from other paths; (ii) repeat until each covered node is covered only once.
The cost increment in node insertion is deﬁned as the operating cost after inserting the uncovered node minus the sum of
service cancellation and operating costs before the insertion. The service cancellation cost is considered here because the
total service cancellation cost is reduced if the uncovered node is inserted. The best position for an uncovered node is
the position with the minimum cost increment, while the best uncovered node for insertion is the one that has the minimum
cost increment after the insertion.
In the vehicle rerouting problem for the delivery service, if an uncovered node is a pickup (delivery) node, it is also necessary to determine a position for the corresponding delivery (pickup) node in the same partial route. Only if positions for
both uncovered pickup and delivery nodes are found, and if the new route satisﬁes time window and vehicle capacity constraints, we have feasible positions for this insertion request. The cost increment in this case is deﬁned as the sum of the
increment for the pickup node and the increment for the delivery node. Being similar to the insertion algorithm discussed
3
by Campbell and Savelsbergh (2004), the overall complexity of the heuristic is OðjN j Þ.
Observe that the insertion algorithm can be directly applied to the remaining part of the original schedule when a breakdown occurs. In this situation, the uncovered nodes correspond to the services that are originally scheduled for the breakdown vehicle, while the partial routes are the remaining parts of the original schedule. If there is a backup vehicle from the
depot, a partial route from the starting depot to the ending depot is included into the existing partial routes. Then, the
insertion algorithm is applied to all the partial routes. This direct insertion method does not require partial routes from
the dynamic program and is completed in only one insertion iteration.
Due to the greedy nature of the insertion algorithm, the direct insertion always attempts to insert an uncovered node
even if cancelling the service may be a better option, for example, in the situation of large penalties for each route change.

720

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

The trade-oﬀ between the disruption cost and cancellation cost is more balanced in the Lagrangian heuristic by the use of
the Lagrangian reduced cost. In our Lagrangian heuristic, we ﬁrst get a solution by using the naive approach. Then, a solution is obtained by inserting directly into the remaining part of the original schedule. The two solutions are compared and
the better one is used as the initial solution of the Lagrangian heuristic.
4.3. Updating lagrangian multipliers
The subgradient approach has been used to solve many Lagrangian dual problems. The subgradient vector sðuÞ assoP
P P
ciated with a given u is deﬁned by: sj ðuÞ ¼ 1  zj  d2D p2PH ðdÞ i:ði;jÞ2EðdÞ dpij y dp ; j 2 N . This approach generates a sequence
u0 ; u1 ; . . . of Lagrangian multiplier vectors. Held and Karp (1971) proposed a method to update the
k

Þ
lk ; k P 1 : lkþ1
¼ maxflkj þ k UBLðu
s ðuk Þg; 8j 2 N , where UB is an upper bound (total cost), Lðuk Þ is the lower bound
j
ksðuk Þk2 j

obtained by solving the Lagrangian dual problem for the given uk , and k > 0 is a given step-size parameter.
However, since the Lagrangian relaxation problem (LD1) is not guaranteed to be solved to optimality in the dynamic
programming based heuristic, the objective value of LD1 may not be a lower bound and it is not easy to construct a subgradient vector from the solution of Lagrangian relaxation. Our strategy is to use the approximate subgradient and lower
k
bound to update the Lagrangian multipliers:
the objective
P value pofd LD1 is multiplied by 0.7 to approximate Lðu Þ when
P (i)P
kþ1
calculating l ; and (ii) sj ðuÞ ¼ 1  zj  d2D p2PH ðdÞ i:ði;jÞ2EðdÞ dij y p ; j 2 N is used to approximate the subgradient. We
employ the method presented by Caprara et al. (1999) to update the k. The initial k was set to 0.5.
5. Computational experiments
Computational experiments were conducted to examine the rerouting problem for pickup services and the rerouting
problem for delivery services, using (i) the naive manual rerouting approach, (ii) the direct insertion and (iii) the Lagrangian heuristic.
Solomon (1987) benchmark problems were used as our problem instances. Solomon presented two problem sets. Set 1
allows 5 to 10 customers per route in order to follow the constraints of vehicle capacities and time windows. Set 2 allows
more than 30 customers per route, which is generally considered to be the most diﬃcult problem. In this study, we considered only Set 1. The solutions of static vehicle routing problems are the initial routes of our vehicle rerouting problems,
which are available on Professor Cordeau’s web site (http://neumann.hec.ca/chairedistributique/data/vrptw/old).
Then, a vehicle breakdown is introduced at an early time in the schedule. We considered only one vehicle breakdown
since it is the most common case that actually arises (the algorithm can be used for the multiple simultaneous breakdowns
without any changes). The number of backup vehicles available at the depot is 0 or 1.
Based on the service duration and latest time window, the breakdown times are set as follows: for the problem R1 and
RC1, the breakdown times are 40 and 60, respectively; and for the problem C1, the breakdown times are 100 and 200,
respectively. However, we do not present all our results in order to limit the length of the paper.
Service cancellations have very negative inﬂuence, and freight companies tend to avoid cancelling services. Therefore, we
used a large cost for each service cancellation. We deﬁne the trip cancellation cost C i for the service i as C i ¼
b10 ðdemand of service iÞc þ C, where C is a ﬁxed cost for every service. In the computational experiments we used C ¼ 100.
When reducing the route disruptions is a major purpose of a freight company, a large penalty can be used for each
change. We evaluated penalty values of 100, 50, 25 and 0.
For all compatible pairs ði; jÞ; cij is deﬁned as the Euclidean distance between nodes i and j. If an arc is from the real
depot s, a ﬁxed cost, 100, is added. The corresponding cdij is deﬁned as

if ði; jÞ is originally appearing in the route for pseudo  depot d 2 D;
cij
d
cij ¼
cij þ penalty otherwise:
For pickup services, the upper bound of the number of non-dominated labels for each node is set to 70, while the upper
bound is set to 1000 for delivery services due to the smaller size of the underlying network. The setup time of allocating a
backup vehicle from the depot was set to 5 minutes.
We ran 40 iterations for the rerouting problem for pickup services, and ran 300 iterations for the rerouting problem for
delivery services. The algorithms were implemented in C++ on Sun-Fire-880 Workstations, each of which with 2 UltraSPARCIII processors at 900 MHz, 4 GB of RAM and a Solaris 9 operating system.
5.1. Algorithm analysis
The rerouting algorithm includes two major parts: the dynamic programming based heuristic for solving the constrained
shortest path problem and the insertion algorithm for improving the solution from the dynamic program. Fig. 3 presents

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727
Pickup Services/R1
Breaktime 40/Backup 1/Penalty 100

721

Delivery Services/R1
Breaktime 60/Backup 0/Penalty 25
2500

2400

2000

Total Costs

2000

1500
1500

After
Subproblem

Before
Insertion
1000

1000

800

0

After
Insertion
5

10

15

20

25

Number of Iterations

30

800

0

20

40

60

80

Number of Iterations

Fig. 3. Total costs obtained in diﬀerent stages of the algorithm.

typical plots for the total costs obtained directly from the dynamic programming heuristic (after Lagrangian relaxation),
from removal of the redundant covering, and from the insertion algorithm. Since many combinations of the problem type,
the breakdown time, the availability of backup vehicles, and penalty value for each rerouting change, we only present two
situations in Fig. 3. It appears that the insertion step contributes more to eﬃciency of the algorithm than the dynamic programming heuristic. However, the smaller cost obtained after the insertion step is generally based on the better results of
the dynamic programming step (note the sharper changes in the ﬁrst few ‘‘after subproblem” and ‘‘after insertion” iterations in Fig. 3). This observation follows the general understanding of the Lagrangian heuristic: if the solution of the
Lagrangian relaxation is good and is slightly adjusted by a heuristic, the adjusted solution is usually good Larsson and
Patriksson, 2006.
Since the Lagrangian relaxation problem is not guaranteed to solve to optimality, the solution of Lagrangian relaxation
may not be a lower bound to the vehicle rerouting problem. Thus, we do not know the optimality gap of the solution.
5.2. Results
5.2.1. Rerouting for the pickup service
Table 2 compares the performance of the naive manual approach (M), direct insertion (INS) and Lagrangian heuristic
(OPT) for the problems R1, RC1, and C1, respectively. The ﬁrst ﬁve columns give the problem type, the breakdown time,
the average number of remaining services, the number of backup vehicles from the depot, and the penalty on each change
in the original route. Columns seven to thirteen provide the average number of cancelled services, the average trip cancellation cost, the average operating cost, the average number of route changes, the minimum, maximum and average percentage change for each route, the total cost, and CPU seconds for the method, respectively.
For example, if the breakdown time is 40 in problem R1, the average number of remaining services is 85.25 over 12
instances (see row 3, columns 1 to 3 in Table 2). Using the Lagrangian heuristic (OPT), the average number of cancelled
services is 5.25, the average service cancellation cost is 1143.33, the average operating cost is 865.75, the average route

722

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

Table 2
Computational results of the pickup service
Prob
type

Breakdown
time

Remaining
services

Backup
vehicles

Penalty

Algorithm

R1

40

85.25

0

N/A
100

M
INS
OPT
INS
OPT
INS
OPT
INS
OPT
M
INS
OPT
INS
OPT
INS
OPT
INS
OPT

50
25
0
1

N/A
100
50
25
0

RC1

60

78.50

0

N/A
100
50
25
0

1

N/A
100
50
25
0

C1

200

77.22

0

N/A
100
50
25
0

1

N/A
100
50
25
0

Cancel trips

Cancel
costs

Operating
costs

Route
changes

Change ratio (%)
min/max/avg

Total
costs

CPU(s)

7.75
5.17
5.25
5.17
5.17
5.17
5.08
5.17
5.17
1.50
1.92
1.25
1.67
1.00
1.67
0.92
1.67
1.25

1800.00
1152.50
1143.33
1152.50
1148.33
1152.50
1046.67
1152.50
1118.33
362.50
340.00
226.67
295.83
186.67
293.33
165.00
294.17
229.17

848.33
877.33
876.75
877.33
876.42
877.33
882.08
877.33
889.17
1034.50
1034.83
1034.67
1048.33
1035.75
1053.67
1040.50
1050.75
1053.08

0.00
4.00
3.83
4.00
4.00
4.00
5.58
4.00
12.75
0.00
0.00
0.00
2.67
0.50
2.83
1.08
3.75
5.67

0.00/0.00/0.00
0.00/36.77/4.37
0.00/33.44/4.16
0.00/36.77/4.37
0.00/36.77/4.37
0.00/36.77/4.37
0.00/45.28/5.96
0.00/36.77/4.37
3.43/48.02/14.16
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/28.99/3.02
0.00/5.83/0.73
0.00/29.94/3.26
0.00/11.94/1.32
0.00/36.35/3.85
0.00/19.77/6.06

2648.33
2429.83
2403.42
2229.83
2224.75
2129.83
2068.33
2029.83
2007.50
1397.00
1374.83
1261.33
1477.50
1247.42
1417.83
1232.58
1344.92
1282.25

N/A
N/A
9.43
N/A
22.07
N/A
27.21
N/A
48.08
N/A
N/A
6.81
N/A
9.69
N/A
8.72
N/A
20.50

M
INS
OPT
INS
OPT
INS
OPT
INS
OPT
M
INS
OPT
INS
OPT
INS
OPT
INS
OPT

7.50
6.12
5.88
6.12
5.50
6.12
5.62
6.12
6.25
2.50
2.25
1.88
2.00
1.75
2.00
1.38
2.00
2.00

2081.25
1751.25
1606.25
1751.25
1351.25
1751.25
1398.75
1751.25
1745.00
691.25
512.50
425.00
455.00
400.00
455.00
303.75
455.00
455.00

867.12
888.25
887.75
888.25
902.75
888.25
894.25
888.25
890.25
1071.25
1075.50
1072.25
1091.88
1072.62
1091.88
1088.50
1091.12
1088.25

0.00
2.38
3.25
2.38
7.12
2.38
8.88
2.38
8.25
0.00
0.00
0.50
2.00
1.00
2.00
3.25
2.12
1.62

0.00/0.00/0.00
0.00/26.29/3.00
0.00/32.04/3.77
0.00/26.29/3.00
0.00/56.70/8.91
0.00/26.29/3.00
0.00/61.98/11.06
0.00/26.29/3.00
0.00/33.88/9.98
0.00/0.00/0.00
0.00/0.00/0.00
0.00/6.25/0.62
0.00/23.02/2.46
0.00/8.13/1.22
0.00/23.02/2.46
0.00/32.99/3.85
0.00/24.21/2.55
0.00/17.51/1.98

2948.38
2877.00
2819.00
2758.25
2610.25
2698.88
2514.88
2639.50
2635.25
1762.50
1588.00
1547.25
1646.88
1522.62
1596.88
1473.50
1546.12
1543.25

N/A
N/A
3.19
N/A
4.55
N/A
7.58
N/A
9.41
N/A
N/A
1.83
N/A
2.48
N/A
3.08
N/A
7.73

M
INS
OPT
INS
OPT
INS
OPT
INS
OPT
M
INS
OPT
INS
OPT
INS
OPT
INS
OPT

10.67
7.33
8.56
7.33
7.22
7.33
6.78
7.33
5.78
0.89
0.89
0.89
0.33
0.33
0.33
0.33
0.33
0.11

2366.67
1677.78
1922.22
1677.78
1633.33
1677.78
1444.44
1677.78
1200.00
177.78
177.78
177.78
66.67
66.67
66.67
66.67
66.67
22.22

480.56
572.56
528.56
572.56
579.33
572.56
625.00
572.56
687.56
639.56
639.89
637.78
699.11
653.67
690.67
651.56
715.78
679.00

0.00
5.67
3.44
5.67
6.22
5.67
8.67
5.67
23.67
0.00
0.00
0.00
4.22
1.11
3.78
1.11
6.22
10.56

0.00/0.00/0.00
0.00/29.39/6.75
0.00/22.73/3.97
0.00/29.39/6.75
0.00/32.73/7.36
0.00/29.39/6.75
0.00/41.92/10.05
0.00/29.39/6.75
2.22/75.53/28.07
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/23.83/4.75
0.00/12.10/1.21
0.00/23.52/4.25
0.00/12.35/1.23
0.00/33.84/6.77
0.00/52.01/11.43

2847.22
2817.00
2795.22
2533.67
2523.78
2392.00
2286.11
2250.33
1887.56
817.33
817.67
815.56
976.89
775.89
851.78
746.00
782.44
701.22

N/A
N/A
6.56
N/A
6.18
N/A
7.33
N/A
13.01
N/A
N/A
2.02
N/A
2.48
N/A
3.36
N/A
7.78

change is 3.83, the minimum, maximum and average change percentage for each route are 0.00%, 33.44% and 4.16%, the
total cost is 2403.42, and CPU seconds used are 9.43. This is when the breakdown time is 40, the number of backup vehicles
is 0, and the route change penalty is 100 (see row 5, columns 7 to 13 in Table 2).
The disruptions are eﬀectively mitigated by using a penalty for each change. Larger penalties result in the smaller numbers of route changes. For example, for problem R1 with the breakdown time 40, only 3.83 route changes occur on average

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

723

if the number of backup vehicles is 0 and the penalty for each change is 100, while 12.75 route changes occur if no penalty
for each change is imposed (see column 10, rows 5 and 11 in Table 2). When the number of route changes increase, the
maximum and average percentage change for each route also increases. In the same example, if the penalty for each change
is 100, the maximum and average change percentages for each route are 33.44% and 4.16%; However, the maximum and
average change percentages are 48.02% and 14.16% if the penalty is set to be 0 for each change. Given the same penalty
value for each change, the number of route changes usually decreases when the number of backup vehicles increases (for
example, see column 10, rows 9 and 18 in Table 2). This may be because more currently operating vehicles have to be rerouted in order to cover the uninitiated services if the number of backup vehicles at the depot is smaller.
The service cancellation costs are considerably reduced by the Lagrangian heuristic in comparison with the solution of
the naive manual approach. For example, in problem C1, if no backup vehicle is available at the depot, the average service
cancellation cost with the naive rerouting is 2366.67, whereas the average cancellation cost using the Lagrangian heuristic is
1633.33 if the penalty for each change is 50 (see column 8, rows 39 and 43 in Table 2). In general, the operating costs are
slightly increased by using the Lagrangian heuristic. In the same example, the naive approach leads to 480.56 in operating
costs, while the Lagrangian heuristic yields a solution with 579.33 in operating costs (see column 9, rows 39 and 43 in Table
2). The Lagrangian heuristic considerably reduces the total costs compared to the naive approach. In the example, the average total cost by the Lagrangian heuristic is 2533.78, whereas the average total cost by the naive approach is 2847.22 (see
column 12, rows 39 and 43 in Table 2).
The direct insertion always attempts to insert the uncovered nodes in the remaining parts of original schedules even
though serious route disruptions may occur. Therefore, service cancellation costs are generally reduced in comparison with
the naive approach. For example, for problem C1, if no backup vehicle is available at the depot, the average service cancellation cost with the naive rerouting is 2366.67, while the average service cancellation cost by direct insertion is 1677.78
with any penalty value (see column 8, rows 40, 42, 44 and 46 in Table 2). In comparison with the solution of the Lagrangian
heuristic, the direct insertion sometimes yields the smaller cancellation costs when the penalty on route changes is larger.
For instance, in the above example, the average service cancellation cost by the Lagrangian heuristic is 1922.22 with penalty value 100 (see column 12, row 41 in Table 2), which is larger than 1677.78. However, the Lagrangian heuristic generally
generates smaller total costs than the direct insertion.
The total costs are reduced more signiﬁcantly using the Lagrangian heuristic when the number of backup vehicles is
smaller. For example, for the problem RC1, if the number of backup vehicles is 1, the average total cost with the naive
approach is 1762.50, while the total cost by the Lagrangian heuristic is 1522.62 when the penalty is 50, a saving of
239.88 in costs (see column 12, rows 30 and 34 in Table 2). If the number of backup vehicles is 0, the total costs by the
naive and Lagrangian heuristic are 2948.38 and 2610.25, respectively, a saving of 338.63 in costs (see column 12, rows
21 and 25 in Table 2). This is because if the number of backup vehicles is smaller, the naive approach tends to cancel more
services, which would otherwise be served by other operating vehicles where the Lagrangian heuristic is used.
Our Lagrangian heuristic obtains good solutions within a reasonable amount of time. The largest average computational time, 48.08 CPU seconds, occurs in problem R1 when no backup vehicle is available from the depot, and the penalty
for each route change is 0 (see column 13, row 11 Table 2). When the penalty for the route change is smaller, computational
times are larger (see column 13, rows 5, 7, 9 and 11 in Table 2) since the use of smaller penalty values provide more opportunities to generate large negative arc costs. Note that the reduced arc cost is deﬁned as cdij  lj . When the penalty value is
smaller, cdij  lj is smaller on average, which tends to yield more negative cycles.
When the penalty value on the route change is same, the Lagrangian heuristic needs more CPU time on average when
less backup vehicles are available from the depot (for example, see column 13 in Table 2). When more backup vehicles are
available at the depot, the number of services covered in the Lagrangian relaxation problem tends to be larger. Thus,
uncovered nodes that seek feasible insertion positions in the primal heuristic are smaller, which leads to less insertion
requests in the primal heuristic.
5.2.2. Rerouting comparisons between delivery services and pickup services
Table 3 compares the performance of the naive approach, direct insertion and Lagrangian heuristic for delivery services.
As we expect, the solutions for the delivery service have the similar properties to the pickup service: (i) the disruptions are
eﬀectively reduced by using penalties for each change; (ii) the service cancellation costs and total costs are considerably
reduced by the Lagrangian heuristic; and (iii) the operating costs are slightly increased by the Lagrangian heuristic.
However, there are some remarkable diﬀerences between two problems. First, on average, more services are cancelled
for delivery service than pickup service if the same algorithm and settings are used. For example, 6.25 services on average
are cancelled for delivery service, while 1.50 services on average are cancelled for pickup service, when the naive approach is
used for problem R1, the breakdown time is 40, and the number of backup vehicles from the depot is 1 (see column 7, row
12 in Tables 2 and 3). If the Lagrangian heuristic is used and the penalty for each change is 25, 5.67 service calls on average
are cancelled for delivery service, while 0.92 service calls on average are cancelled for pickup service. If the direct insertion
is used, 6.67 calls are cancelled for delivery service, while 1.67 calls are cancelled for pickup service (see column 7, rows 17

724

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

Table 3
Computational results of the delivery service
Prob
type

Breakdown
time

Remaining
services

Backup
vehicles

Penalty

Algorithm

R1

40

85.25

0

N/A
100
50
25
0

1

N/A
100
50
25
0

RC1

60

78.50

0

N/A
100
50
25
0

1

N/A
100
50
25
0

C1

200

77.22

0

N/A
100
50
25
0

1

N/A
100
50
25
0

Cancel
trips

Cancel
costs

Operating
costs

Route
changes

Change ratio (%)
min/max/avg

Total
costs

CPU(s)

M
INS
OPT
INS
OPT
INS
OPT
INS
OPT
M
INS
OPT
INS
OPT
INS
OPT
INS
OPT

7.75
7.67
7.75
7.67
7.08
7.67
6.75
7.67
6.33
6.25
6.75
6.25
6.75
6.08
6.67
5.67
6.67
5.25

1800
1782.50
1800.00
1782.50
1661.67
1782.50
1611.67
1782.50
1584.17
1475
1431.67
1335.83
1431.67
1305.83
1414.17
1258.33
1414.17
1216.67

848.33
850.25
848.33
850.25
862.08
850.25
864.42
850.25
871.17
981.67
1003.75
987.75
1003.75
989.67
1005.67
995.92
1005.67
1001.92

0.00
0.33
0.00
0.33
1.83
0.33
2.83
0.33
9.58
0.00
0.00
0.00
0.00
0.50
0.33
1.83
0.33
7.75

0.00/0.00/0.00
0.00/4.17/0.23
0.00/0.00/0.00
0.00/4.17/0.23
0.00/26.19/1.89
0.00/4.17/0.23
0.00/34.82/2.68
0.00/4.17/0.23
0.00/65.16/10.21
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/5.56/0.40
0.00/4.17/0.22
0.00/20.52/1.48
0.00/4.17/0.22
0.00/49.47/7.37

2648.33
2666.08
2648.33
2649.42
2615.42
2641.08
2546.92
2632.75
2455.33
2456.67
2435.42
2323.58
2435.42
2320.50
2428.17
2300.08
2419.83
2218.58

N/A
N/A
23.63
N/A
16.94
N/A
32.77
N/A
21.87
N/A
N/A
12.64
N/A
10.99
N/A
45.18
N/A
21.00

M
INS
OPT
INS
OPT
INS
OPT
INS
OPT
M
INS
OPT
INS
OPT
INS
OPT
INS
OPT

7.50
7.50
7.50
7.50
7.50
7.50
7.25
7.50
6.38
6.00
6.50
6.00
6.50
6.00
6.50
6.00
6.50
5.12

2081.25
2081.25
2081.25
2081.25
2081.25
2081.25
2050.00
2081.25
1978.75
1648.75
1618.75
1500.00
1618.75
1500.00
1618.75
1500.00
1618.75
1455.00

867.12
867.12
867.12
867.12
867.12
867.12
869.62
867.12
879.88
1017.62
1056.12
1025.25
1056.12
1025.25
1056.12
1025.25
1056.12
1034.25

0.00
0.00
0.00
0.00
0.00
0.00
0.62
0.00
6.38
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
5.75

0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/8.93/0.74
0.00/0.00/0.00
0.00/47.61/6.97
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/30.69/5.57

2948.38
2948.38
2948.38
2948.38
2948.38
2948.38
2935.25
2948.38
2858.62
2666.38
2674.88
2525.25
2674.88
2525.25
2674.88
2525.25
2674.88
2489.25

N/A
N/A
3.51
N/A
3.85
N/A
4.80
N/A
4.67
N/A
N/A
3.62
N/A
4.01
N/A
4.70
N/A
4.50

M
INS
OPT
INS
OPT
INS
OPT
INS
OPT
M
INS
OPT
INS
OPT
INS
OPT
INS
OPT

10.67
10.44
10.67
10.44
10.33
10.44
10.22
10.44
10.11
9.67
9.67
9.67
9.67
9.44
9.67
9.33
9.44
9.00

2366.67
2300.00
2366.67
2300.00
2255.56
2300.00
2244.44
2300.00
2233.33
2155.56
1944.44
1944.44
1944.44
1900.00
1944.44
1877.78
1900.00
1844.44

480.56
487.00
480.56
487.00
494.33
487.00
494.67
487.00
504.56
618.33
622.33
622.33
622.33
628.33
622.33
634.89
628.33
648.67

0.00
0.67
0.00
0.67
1.11
0.67
1.33
0.67
2.33
0.00
0.00
0.00
0.00
0.67
0.00
1.11
0.67
2.67

0.00/0.00/0.00
0.00/5.13/0.57
0.00/0.00/0.00
0.00/5.13/0.57
0.00/8.55/0.95
0.00/5.13/0.57
0.00/9.89/1.10
0.00/5.13/0.57
0.00/15.54/1.73
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/0.00/0.00
0.00/5.13/0.51
0.00/0.00/0.00
0.00/7.41/0.74
0.00/5.13/0.51
0.00/17.13/1.71

2847.22
2853.67
2847.22
2820.33
2805.44
2803.67
2772.44
2787.00
2737.89
2773.89
2566.78
2566.78
2566.78
2561.67
2566.78
2540.44
2528.33
2493.11

N/A
N/A
2.61
N/A
3.73
N/A
5.22
N/A
6.47
N/A
N/A
2.58
N/A
3.76
N/A
6.41
N/A
10.05

and 18 in Tables 2 and 3). The corresponding cancellation costs for delivery service are of course increased. The higher
numbers of cancelled services and larger cancellation costs for delivery service can be explained as follows. In delivery service, the backup vehicles need to go to the breakdown point for collecting the packages ﬁrst before these packages can be
delivered to the customers. The travel time towards the breakdown point and time for loading the packages on the backup
vehicle are not needed in the rerouting problem for pickup service. Thus, for a pickup call, the backup vehicle is more likely

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

725

Table 4
Reduction of total costs by using the Lagrangian heuristic
Problem

Breakdown time

Service type

Backup vehicles

R1

40

Pickup

0
1
0
1
0
1
0
1
0
1
0
1

Delivery
RC1

60

Pickup
Delivery

C1

200

Pickup
Delivery

Penalty 100 (%)

Penalty 50 (%)

Penalty 25 (%)

Penalty 0 (%)

M

INS

M

INS

M

INS

M

INS

9.25
9.71
0.00
5.42
4.39
12.21
0.00
5.29
1.83
0.22
0.00
7.47

1.09
9.00
0.67
4.81
2.06
2.63
0.00
5.93
0.78
0.26
0.23
0.00

15.99
10.71
1.24
5.54
11.47
13.61
0.00
5.29
11.36
5.07
1.47
7.65

0.23
15.57
1.28
4.72
5.37
7.55
0.00
5.59
0.39
20.58
0.53
0.20

21.90
11.77
3.83
6.37
14.70
16.40
0.45
5.29
19.71
8.73
2.63
8.42

2.89
13.07
3.57
5.28
6.82
7.73
0.45
5.59
4.43
12.42
1.11
1.03

24.20
8.21
7.29
9.69
10.62
12.44
3.04
6.64
33.71
14.21
3.84
10.12

1.10
4.66
6.74
8.32
0.16
0.19
3.04
6.94
16.12
10.38
1.76
1.39

to reach the location of customers earlier, and the time window constraints are more likely to be satisﬁed. Thus, less service
calls are cancelled in the rerouting problem for the pickup service.
In the rerouting problem for delivery service, if no backup vehicle is available from the depot, the Lagrangian heuristic
yields a similar result to the naive approach for some instances. For example, in problem RC1, the total costs by the
Lagrangian heuristic, naive and direct insertion approaches are 2948.38 if the penalty is 100 and the number of backup
vehicles is 0 (see column 12, rows 21 to 23 in Tables 3). Note that, in the rerouting problem for pickup service, the corresponding diﬀerence is still signiﬁcant (see column 12, rows 21 to 23 in Tables 2). If there is no backup vehicle from the
depot in the rerouting problem for the delivery service, only currently operating vehicles can be used to cover the calls that
are originally scheduled for the breakdown vehicles. The underlying network for delivery service calls is less ﬂexible to yield
a new solution than the rerouting problem for pickup service calls (having a larger underlying network) and the rerouting
problem for delivery service with more backup vehicles (therefore with more options to serve the customers).
The vehicle rerouting problem for delivery service requires less computational time than for the problem for pickup service, since the underlying network for the delivery service is much smaller. However, the Lagrangian relaxation and primal
heuristic are more complicated for delivery service.
Table 4 presents the cost reduction by using the Lagrangian heuristic in diﬀerent situations. When the penalty value is
larger and there is no backup vehicle at the depot, the Lagrangian heuristic tends to yield the similar results as the direct
insertion (see column 6, rows 3, 5, 7, 9, 11 and 13 in Tables 4) since the remaining parts of original routes in this situation
are more likely to be near optimal partial route generated by the dynamic program. If the medium penalty values (50 and
25) are used and a backup vehicle is available at the depot, the Lagrangian heuristic considerably improves the solution in
comparison with the direct insertion, especially for pickup service (see columns 8 and 10, rows 4, 6, 8, and 10 in Tables 4).
This may be because the remaining parts of original routes in these situations are far from the near optimal solution.
6. Conclusion
This paper deﬁnes and studies real-time vehicle rerouting problems with time windows, applicable to schedule disruption
situations in pickup and/or delivery services due to the breakdown of one or more service vehicles. The objective of such
problems to ﬁnd vehicle route reassignments with consideration of operating, service cancellation and route disruption
costs. Each service can be assigned a cancellation cost based on its importance. In order to reduce the changes of the initial
vehicle routes, a penalty value may be imposed for each change. It is observed that the rerouting problem for pickup service
and the rerouting problem for delivery service need to be distinguished when exchanging packages between vehicles is not
allowed. These problems can be shown to be NP-hard by association with the vehicle routing problem with time windows
and the travel salesman problem with time windows.
Lagrangian relaxation is used to relax the hard constraints, and the resulting Lagrangian relaxation problem is decomposed into constrained shortest path problems with time window and vehicle capacity constraints. The solution of the
relaxation problem provides a starting solution to a primal heuristic. In order to obtain a solution for the Lagrangian relaxation problem quickly, a dynamic programming based heuristic solves the constrained shortest path problem heuristically
rather than optimally. An insertion algorithm is used in the primal heuristic to obtain a feasible solution for the primal
problem.
Extensive computational experiments performed on the benchmark problems developed by Solomon (1987), providing
the following observations: (i) changes in routes are reduced by using a penalty for each change; (ii) on average, the service

726

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

cancellation costs and total costs are reduced with the Lagrangian heuristic, in comparison with the results from a naive
approach and with a direct insertion approach; (iii) the operating costs are, on average, slightly increase when the Lagrangian heuristic is used; (iv) when the penalty for each schedule change is large and there is no backup vehicle at the depot, the
Lagrangian heuristic generates similar total costs as the direct insertion, otherwise, the total costs are considerably reduced
by the Lagrangian heuristic; and (v) on average, the total cancellation costs for delivery services are more than the corresponding cancellation costs for pickup services for same problem setting. The cost reductions for diﬀerent situations are
shown in Table 4.
The observations on the computational times of the algorithms are: (i) when the penalty for each change is small, the
computational time is large; and (ii) the computational times on the rerouting problem for pickup service are much larger
than the computational times for the corresponding delivery service problems since the underlying network for pickup service is much larger than the network for delivery service.
In the developed model for the vehicle rerouting problem with time windows, some services are cancelled if the constraints of time windows or vehicle capacities cannot be satisﬁed. However, this assumption may not held in for some applications. For example, if a school bus that is used for transporting students breaks down, the students still have to be sent
home even with signiﬁcant delays. The same situation with ‘‘soft” time windows can happen when a vehicle breaks down in
a dial-a-ride service. Such recovery problems are topics of future study.
Acknowledgements
The authors would like to express their sincere thanks to two anonymous referees for their valuable and constructive
suggestions.
Appendix. NP-hardness of the Vehicle Rerouting Problem
1. The vehicle rerouting problem with time windows for the pickup serviceIn the classical vehicle routing problem with
time windows and K available vehicles, if we split the depot into K pseudo-depots with one available vehicle in each
pseudo-depot and impose a suﬃciently large cost for the service cancellation, the classical vehicle routing problem with
time windows (which is NP-hard) can be transformed to a vehicle rerouting problem with time windows without disruption costs. Thus, the vehicle rerouting problem with time windows for the pickup service is NP-hard.
2. The vehicle rerouting problem with time windows for the delivery serviceConsider a special case of the vehicle rerouting
problem for the delivery service, where the customers that are originally scheduled for the breakdown vehicles can only
be served by a vehicle from the depot, while each operating vehicle can just service the customers that are originally
scheduled for it. Thus, this special case of the vehicle rerouting problem with time windows turns out to solve some traveling salesman problems with time windows, which is a well-know NP-hard problem. Each traveling salesman corresponds to a pseudo-depot/depot. Thus, the general vehicle rerouting problem with time windows for the delivery
service is NP-hard.

References
Bertsimas, D.J., Simchi-Levi, D., 1996. A new generation of vehicle routing research: Robust algorithms, addressing uncertainty. Operations Research 44
(2), 286–304.
Campbell, A.M., Savelsbergh, M., 2004. Eﬃcient insertion heuristics for vehicle routing and scheduling problems. Transportation Science 38 (3), 369–378.
Caprara, A., Fischetti, M., Toth, P., 1999. A heuristic method for the set covering problem. Operations Research 47 (5), 730–743.
Carlson, P.M., 2000. Exploiting the opportunities of collaborative decision making: A model and eﬃcient solution algorithm for airline use.
Transportation Science 34 (4), 381–393.
Chen, Z.L., Xu, H., 2006. Dynamic column generation for dynamic vehicle routing with time windows. Transportation Science 40 (21), 74–88.
Desrochers, M., Soumis, F., 1988. A generalized permanent labeling algorithm for the shortest path problem with time windows. INFOR 26 (3), 191–212.
Desrochers, M., Desrosiers, J., Solomon, M.M., 1992. A new optimization algorithm for the vehicle-routing problem with time windows. Operations
Research 40 (2), 342–354.
Dror, M., 1994. Note on the complexity of the shortest-path models for column generation in vrptw. Operations Research 42 (5), 977–978.
Du, T.C., Li, E.Y., Chou, D., 2005. Dynamic vehicle routing for online b2c delivery. Omega-International Journal of Management Science 33 (1), 33–45.
Dumas, Y., Desrosiers, J., Soumis, F., 1991. The pickup and delivery problem with time windows. European Journal of Operational Research 54 (1), 7–22.
El Rhalibi, A., Kelleher, G., 2003. An approach to dynamic vehicle routing, rescheduling and disruption metrics. In: IEEE International Conference on
Systems, Man and Cybernetics. Washington DC, USA, pp. 3613–3618.
Fabri, A., Recht, P., 2006. On dynamic pickup and delivery vehicle routing with several time windows and waiting times. Transportation Research Part BMethodological 40 (4), 335–350.
Feillet, D., Dejax, P., Gendreau, M., Gueguen, C., 2004. An exact algorithm for the elementary shortest path problem with resource constraints:
Application to some vehicle routing problems. Networks 44 (3), 216–229.

J.-Q. Li et al. / European Journal of Operational Research 194 (2009) 711–727

727

Fleischmann, B., Gnutzmann, S., Sandvoss, E., 2004. Dynamic vehicle routing based on online traﬃc information. Transportation Science 38 (4), 420–
433.
Gendreau, M., Potvin, J.-Y., 1998. Dynamic vehicle routing and dispatching. In: Crainic, T., Laporte, G. (Eds.), Fleet Management and Logistics.
Kluwer, New York, pp. 115–126.
Gendreau, M., Laporte, G., Seguin, R., 1995. An exact algorithm for the vehicle routing problem with stochastic demands and customers. Transportation
Science 29 (2), 143–155.
Gendreau, M., Laporte, G., Seguin, R., 1996a. Stochastic vehicle routing. European Journal of Operational Research 88 (1), 3–12.
Gendreau, M., Laporte, G., Seguin, R., 1996b. A tabu search heuristic for the vehicle routing problem with stochastic demands and customers. Operations
Research 44 (3), 469–477.
Gendreau, M., Laporte, G., Semet, F., 2001. A dynamic model and parallel tabu search heuristic for real-time ambulance relocation. Parallel Computing
27 (12), 1641–1653.
Ghiani, G., Guerriero, F., Laporte, G., Musmanno, R., 2003. Real-time vehicle routing: Solution concepts, algorithms and parallel computing strategies.
European Journal of Operational Research 151 (1), 1–11.
Haghani, A., Jung, S., 2005. A dynamic vehicle routing problem with time-dependent travel time. Computers and Operations Research 32 (11), 2959–2986.
Held, M., Karp, R.M., 1971. The traveling salesman problem and minimum spanning trees: Part II. Mathematical Programming 1, 6–25.
Houck, D.J., Picard, J.C., Queyranne, M., Vemuganti, R.R., 1980. The travelling salesman problem as a constrained shortest path problem: Theory and
computational experience. Opsearch 17, 93–109.
Huisman, D., Freling, R., Wagelmans, A.P.M., 2004. A robust solution approach to the dynamic vehicle scheduling problem. Transportation Science 38
(4), 447–458.
Ichoua, S., Gendreau, M., Potvin, J.-Y., 2000. Diversion issues in real-time vehicle dispatching. Transportation Science 34 (4), 426–438.
Irnich, S., Villeneuve, D., 2006. The shortest-path problem with resource constraints and k-cycle elimination for k P 3. INFORMS Journal on Computing
18 (3), 391–406.
Jarrah, A.I.Z., Yu, G., Krishnamurthy, N., Rakshit, A., 1993. A decision support framework for airline ﬂight cancellations and delays. Transportation
Science 27 (3), 266–280.
Kohl, N., Madsen, O.B.G., 1997. An optimization algorithm for the vehicle routing problem with time windows based on Lagrangian relaxation.
Operations Research 45 (3), 395–406.
Laporte, G., Louveaux, F.V., 1998. Solving stochastic routing problems with integer l-shaped method. In: Crainic, T., Laporte, G. (Eds.), Fleet
Management and Logistics. Kluwer, New York, pp. 159–167.
Larsen, J., 1999. Parallelizatin of the vehicle routing problem with time windows. PhD Dissertation, Department of Mathematical Modeling, Technical
University of Denmark, Lyngby, Denmark.
Larsen, A., Madsen, O.B.G., Solomon, M.M., 2004. The a priori dynamic traveling salesman problem with time windows. Transportation Science 38 (4),
459–572.
Larsson, T., Patriksson, M., 2006. Global optimality conditions for discrete and nonconvex optimization – with applications to Lagrangian heuristics and
column generation. Operations Research 54 (3), 436–453.
Lettovský, L., 1997. Airline operations recovery: An optimization approach. PhD Thesis, Georgia Institute of Technology, USA.
Li, J.-Q., Mirchandani, P.B., Borenstein, D., 2004. Parallel auction algorithm for bus rescheduling. In: Proceedings of the 9th International Conference on
Computer-Aided Scheduling of Public Transport. San Diego, California, USA.
Li, J.-Q., Borenstein, D., Mirchandani, P.B., 2007a. A decision support system for the single-depot vehicle rescheduling problem. Computers and
Operations Research 34 (4), 1008–1032.
Li, J.-Q., Mirchandani, P.B., Borenstein, D., 2007b. Vehicle rescheduling problem: Model and algorithms. Networks 50 (3), 211–229.
Li, J.-Q., Mirchandani, P.B., Borenstein, D., 2007c. A vehicle rescheduling problem with real-time vehicle reassignments and trip cancellations. Tech. Rep.
A-2007-1, The University of Arizona.
Mahmassani, H.S., Kim, Y., Jaillet, P., 2000. Local optimization approaches to solve dynamic commercial ﬂeet management problems. Transportation
Research Record 1733, 71–79.
Powell, W.B., Jaillet, P., Odoni, A., 1995. Stochastic and dynamic networks and routing. In: Ball, M.O., Magnanti, T.L., Monma, C.L., Nemhauser, G.L.
(Eds.), Handbooks in Operations Research and Management Science, Network Routing. North-Holland, Amsterdam, The Netherlands, pp. 141–295.
Psaraftis, H.N., 1995. Dynamic vehicle routing: Status and prospects. Annals of Operations Research 61, 143–164.
Regan, A.C., Mahmassani, H.S., Jaillet, P., 1996. Dynamic decision making for commercial ﬂeet operations using real-time information. Transportation
Research Record 1537, 91–97.
Regan, A.C., Mahmassani, H.S., Jaillet, P., 1998. Evaluation of dynamic ﬂeet management systems simulation framework. Transportation Research
Record 1645, 176–184.
Righini, G., Salani, M., 2006. Symmery helps: Bounded bi-directional dynamic programming for the elementary shortest path problem with resource
constraints. Discrete Optimization 3, 255–273.
Rosenberger, J.M., Johnson, E.L., Nemhauser, G.L., 2003. Rerouting aircraft for airline recovery. Transportation Science 37 (4), 408–421.
Shieh, H.M., May, M.D., 1998. On-line vehicle routing with time windows, optimization-based heuristics approach for freight demands requested in realtime. Transportation Research Record 1617, 171–178.
Solomon, M.M., 1987. Algorithms for the vehicle-routing and scheduling problems with time window constraints. Operations Research 35 (2), 254–265.
Spivey, M.Z., Powell, W.B., 2004. The dynamic assignment problem. Transportation Science 38 (4), 399–419.
Teodorović, D., Stojković, G., 1995. Model to reduce airline schedule disturbances. Journal of Transportation Engineering-ASCE 121 (4), 324–331.
Yan, S., Yang, D.-H., 1996. A decision support framework for handling schedule perturbation. Transportation Research Part B-Methodological 30 (6),
405–419.
Yang, J., Jaillet, P., Mahmassani, H.S., 2004. Real-time multivehicle truckload pickup and delivery problems. Transportation Science 38 (2), 135–148.
Yu, G., Argüello, M., Song, G., McCowan, S.M., White, A., 2003. A new era for crew recovery at continental airlines. Interfaces 33 (1), 5–22.

Intelligent Transportation Systems

Editor: Alberto Broggi
University of Parma, Italy
broggi@ce.unipr.it

Creating a Digital-Vehicle
Proving Ground
Fei-Yue Wang, Chinese Academy of Sciences
Xiaojing Wang, Research Institute of Highway Systems, Beijing
Li Li and Pitu Mirchandani, University of Arizona

This installment presents the state of the art of ITS research in China, particularly the facilities and the proving
ground for testing automated vehicles. The 2003 IEEE ITS Conference will be held in China; I'm sure this could be
an interesting opportunity to visit these facilities. Please check www.ieeeitsc.org for updates.
If you have any comment on this department, feel free to contact me. I also seek contributions on the current
status of ITS projects worldwide as well as ideas on and trends in future transportation systems. Contact me at
broggi@ce.unipr.it; www.ce.unipr.it/broggi.
—Alberto Broggi

T

he Chinese automotive industry has become an
important component of the worldwide automotive

industry. According to the leading Chinese newspaper,
People’s Daily (25 Dec. 2002), the Chinese automotive
industry has established more than 600 joint ventures and
introduced 1,000 foreign technical inventions over the last
20 years. The total foreign investment has exceeded US$20
billion, more than 40 percent of the total Chinese automotive capital. The 2001 output reached 2.34 million vehicles,
up from 0.71 million in 1991. This is a 3.3-fold increase
and a 15 percent average annual increase, compared to the
1.5 percent annual increase worldwide in the same period.
The 2002 output was 3.25 million vehicles.
The driving force for the Chinese automotive industry is
passenger cars, whose production increased from 81,000 in
1991 to 700,000 in 2001, a 8.7-fold increase and a 24 percent annual increase. The National Information Center
estimates that in 2003 the demand for passenger cars in
China will be 1.5 million: 1.435 million domestic cars, an
increase of 26.4 percent, and 90,000 imports (International Finance News, 17 Dec. 2002). The Chinese automotive industry has a 5 percent share of the worldwide
automobile market; its share should reach 20 percent by
2020, assuming a 5 percent annual increase and a total
output of 10 million vehicles. Figure 1 shows China’s
automobile output from 1990 to 2002.
The Chinese automotive industry’s rapid growth demands an increased, enhanced effort in R&D in vehicular
12

technology, reliability, quality, safety, human comfort, and
environmental impact. In 1999, China created its National
Center of Intelligent Transportation Systems Engineering
and Technology (the ITSC) and established the National
Field Testing Complex (NFTC), a state-of-art, comprehensive facility in Tong County, Beijing. One major task
for the ITSC is R&D in intelligent-vehicle technology to
enhance safety, reliability, and performance. The Complex
Systems and Intelligence Science Lab at the Institute of
Automation, Chinese Academy of Sciences, has started a
similar initiative. Since the early 1990s, the University of
Arizona’s ATLAS (Advanced Traffic and Logistics Algorithms and Systems) and PARCS (Program for Research
for Advanced Systems) research centers have also made
significant progress in ITS, particularly in vehicle technology, as demonstrated by the VISTA (Vehicles with Intelligent
Systems for Transport Automation) and digital-highway
projects.1,2 To combine their strengths, in 2002 the ITSC,
the Chinese Academy of Sciences, and the University of
Arizona agreed to conduct joint research on a digital automobile proving ground (DAPG) for automated-vehicle
driving tests based on their Beijing and Tucson facilities.
Here we describe this international collaboration’s status
and progress.

Field-testing a complex DAPG
Figure 2 is a bird’s-eye view of the NFTC. More than
400 million yuan (approximately US$60M) has been
invested in this facility for design and testing equipment.
It serves mainly as a proving ground for R&D prototype

1094-7167/03/$17.00 © 2003 IEEE
Published by the IEEE Computer Society

IEEE INTELLIGENT SYSTEMS

Number of automobiles
(millions)

0.51
1990

1.06
1992

1.35

1.46

1.63

1994

1996

1998

2.07

2000

Year

2.63

2002
Jan.—Oct.

Figure 1. Automobile output in China from 1990 to 2002. (information source: Chinese Association of Automobile Manufacturers)

testing in ITS technology and an evaluation
and certification center for commercial
transportation and vehicle products. The
international collaborators will use this
complex to build a highly automated DAPG
that provides test, engineering, and simulation services to a broad range of vehicle
developers, manufacturers, and users, and
government agencies. The first phase (2002–
2005) will set up a proof-of-concept system at the NFTC. The system has these
main purposes:
• Achieve reliable, qualitative, and repeatable testing results by eliminating variability due to human operations and
reducing other varying factors.
• Implement fast, flexible, anytime, allweather, and all-condition testing.
• Release human drivers from dull and
hazardous vehicle-testing tasks.

Figure 2. A bird’s-eye view of the National Field Testing Complex.

Figure 3 presents the DAPG layout. The
DAPG’s completion will involve these key
issues and technologies:
• Offline and real-time digital geographical information systems
• High-precision differential GPS
• A surface bar code calibration system
• An in-vehicle navigation system
• A vehicle-testing robot
• Data acquisition
• Wireless communication
• A control and command center
• Task-generating, planning, scheduling,
and safety assurance systems

The communication and
control & command centers
The field-testing complex is about 70
miles from the research facilities at the Chinese Academy of Sciences and the Research
MARCH/APRIL 2003

Figure 3. The layout of the digital automobile proving ground.

Institute of Highway. The Communication
Center (CC—see Figure 4a) provides wireless communication capabilities to those
remote facilities and the local testing vehicles at the DAPG. The Control & Command
Center (CCC—see Figure 4b) implements
computer.org/intelligent

and monitors vehicle-testing task planning,
generation, scheduling, and execution.
A wireless (based on IEEE 802.11b) LAN
that covers the testing area connects the field
vehicles and surface equipment to the CC
network via a network address translation
13

(a)

(b)

Figure 4. The DAPG’s (a) Communication Center and (b) Control & Command Center.

In-vehicle sensors

On-field sensors

Vehicle position
Route selection

Central monitoring system
Emergency situation

Situation assessment

Driving course
Geographic
information
system

Path planning

+

Trajectory planning

Real-time
cache

Obstacle handling

Sensor data fusion

Desired path
Desired trajectory

• Tests for steering input, steering effort,
lane changes, steady-state cornering,
and other related vehicle dynamics, normally involving short distances on goodcondition roads
• Vehicle durability tests on special roads
and surfaces, normally involving long
distances on poor-condition roads
• Traction-control tests that evaluate and
optimize tire and suspension performance over a range of conditions

Obstacle evaluation

The second comprises special driving tests:

Desired motion
Testing vehicle

Obstacle prediction

Figure 5. The DAPG system architecture.

box that keeps the set of local IP addresses
invisible from outside the LAN. Currently, a
set of laptops and computers serves as the
gateway to link field vehicles, vision systems, and surface equipment to the CC
network. Embedded communication capacity will be added later. For real-time management and operation, the DAPG uses a
simple protocol to send and receive control
and feedback information between the CCC
and fixed and moving equipment in the field.

A system architecture for
testing automated vehicles
Figure 5 shows the DAPG system architecture. The CCC uses a bar-code-based
surface-coordinate system, magnetic nails,
differential GPS, and in-vehicle navigation
systems to track the vehicles on the DAPG.
As we mentioned before, it also provides
communication and control information to
14

and among them. Each vehicle has a unique
wireless ID. The CCC instructs and monitors each vehicle’s movement for various
driving tests. Each vehicle is considered an
autonomous agent, equipped with various
in-vehicle sensors and a driving-test robot,
and communicating with the CCC and various surface sensors. The driving-test robot
collects information from both the in-vehicle
and surface sensors and decides its driving
actions on the basis of its testing task under
the CCC’s guidance and supervision.3
The generation of testing tasks can be
interactive or passive. In interactive generation, the CCC generates the task under operator instruction. In passive generation, the
CCC chooses a preprogrammed task according to a task schedule. Normally, routine,
repetitive tests will use passive generation.
The testing tasks fall into two groups.
The first comprises standard driving tests:
computer.org/intelligent

• An accelerated vehicle corrosion test,
which occurs mainly in a special
chamber
• Low-friction tests for antilock braking
systems, which are mainly for global
brake certification and are in conjunction
with the traction control test and an allwheel-driving test
For each test, special driving trajectory
and robot control sequences are planned
and produced.

S

even projects on wireless communication, robotic driving, in-vehicle sensory
fusion, on-field calibration, trajectory generation, test-task planning, and system control and monitoring have been scheduled for
the DAPG. The first application to assess
DAPG’s effectiveness will be the accelerated testing of a special tire design’s driving
performance.
IEEE INTELLIGENT SYSTEMS

Fei-Yue Wang is a professor in the University of Arizona’s Systems &
Industrial Engineering Department and the director of the University’s
Program for Advanced Research for Complex Systems. He is also the
director of the Intelligent Control and Systems Engineering Center at the
Chinese Academy of Sciences’ Institute of Automation. Contact him at
feiyue@sie.arizona.edu.

Acknowledgments
This work is supported partly by the US
Department of Transportation, the Knowledge
Innovation Project, the 863 Hi-Tech Project, the
National Key Project in ITS, the Outstanding
Oversea Scientist Program, the National Young
Outstanding Scientist Research Award from the
Chinese Academy of Sciences, the PRC Ministry
of Science and Technology, and the Chinese
National Science Foundation.

Xiaojing Wang is the director of the National Center for Intelligent Trans-

portation Systems and Engineering and the associate director of the Research
Institute of Highway Systems, Beijing. His main research interest is in intelligent transportation systems, especially intelligent-vehicle technology, standards, and policies. He received his BS and MS from the National Defense
University, Changsha, China. Contact him at wxj@itsc.com.cn.

References
1. F.-Y. Wang, Z.X. Wang, and P.B. Mirchandani, “The VISTA Project and Its Applications,” IEEE Intelligent Systems, vol. 17, no.
6, Nov./Dec. 2002, pp. 72–75.
2. F.-Y. Wang, G. Lai, and P.B. Mirchandani,
“Deployment of Digital Vehicle/Highway
Technology for Safety Enhancement,” to be
published in Proc. IEEE Int’l Intelligent Vehicles Symp., IEEE Press, 2003.

Li Li is a doctoral student in the University of Arizona’s Systems and Industrial Engineering

Department.
Pitu Mirchandani is the Salt River Project Professor of Technology at
the University of Arizona and has joint appointments in the university’s
Systems & Industrial Engineering Department and Electrical & Computer Engineering Department. Contact him at the Systems & Industrial
Eng. Dept., Univ. of Arizona, Tucson, AZ 85721; pitu@sie.arizona.edu.

3. F.-Y. Wang, Design of Test Driving Robots
and Automated Vehicle Proving Ground,
ICSEC Tech. Project 0602, Inst. of Automation, Chinese Academy of Sciences, 2002.

Call for Papers
IEEE Intelligent Systems Special Issue

Submission deadline: 1 Aug. 2003
Submission address: qyang@cs.ust.hk
Publication date:
Jan. 2004

Mining the Web for Actionable Knowledge
Recently, there is much work on data mining on the Web to discover novel and
useful knowledge about the Web and its users. Much of this knowledge can be
consumed directly by computers rather than humans. Such actionable knowledge
can be applied back to the Web for measurable performance improvement.
For this special issue, we invite original, high-quality submissions that address all
aspects of Web mining for actionable knowledge. Submissions must address the
issues of what knowledge is discovered and how such knowledge is applied to
improve the performance of Web based systems. We are particularly interested
in papers that offer measurable gains in terms of well-defined performance criteria through Web data mining. Topics of interest include but are not limited to
• Web information extraction and wrapping
• Web resource discovery and topic distillation
• Web search
• Web services
• Web mining for searching, querying, and crawling
• Web content personalization
• Adaptive Web sites
• Adaptive Web caching and prefetching
Submissions should be 3,000 to 7,500 words (counting a standard figure or table as
250 words) and should follow the magazine’s style and presentation guidelines (see
http://computer.org/intelligent/author.htm). References should be limited to 10 citations.
Guest Editors:
. Craig Knoblock, University of Southern California
. Xindong Wu, University of Vermont
. Qiang Yang, Hong Kong University of Science and Technology

Telecommunication Systems 13 (2000) 413–439

413

Virtually fixed channel assignment in cellular mobile
networks with recall and handoffs
Zuoying Xu a , Pitu B. Mirchandani b and Susan H. Xu c
a

Cable and Wireless USA, Internet Engineering, 11700 Plaza America Drive, Reston, VA 20191, USA
b
Systems and Industrial Engineering Department, University of Arizona, Tucson, AZ 85721, USA
c
Department of Management Science and Information Systems, Smeal College of Business
Administration, The Pennsylvania State University, University Park, PA 16802, USA

Received January 1995; in final form September 1999

A promising approach for implementing channel assignment and control in cellular mobile telephone networks is the virtually fixed channel assignment (VFCA) scheme. In VFCA
channels are allocated to cells according to the fixed channel assignment (FCA) scheme,
but cells are allowed to borrow channels from one another. As such, VFCA maintains the
efficiency of FCA, but adds the flexibility lacking in FCA. One feature of a VFCA network
is that, to prevent co-channel interference, it requires several channels to be locked to serve
a single call that borrows a channel. This feature raises the concern that VFCA may lead
to chain reaction in channel borrowing among cells and cause the network performance to
degrade, especially under heavy traffic conditions. In this paper, we propose the virtually
fixed channel assignment with recall (VFCAWR) scheme: The network is implemented according to VFCA, but a cell can recall a locked channel to service an arriving handoff call,
which occurs when a mobile unit crosses the boundary of its cell. We model the network as
a three-dimensional Markov chain and derive its steady-state performance. Through modification of this basic model, we evaluate two dynamic channel assignment strategies, the
virtual channel reservation (VCR) strategy and the linear switch-over (LSO) strategy, which
exploit the unique borrowing/recall capability of VFCAWR to reduce the weighted cost of
blocking fresh and handoff calls by reserving several virtual channels (the channels that
may be borrowed from adjacent cells when necessary) for handoff calls. We validate the
analytical models by simulation; the simulation test cases show that our models accurately
predict the system performance measures of interest. Numerical and simulation results also
show that both dynamic strategies outperform conventional channel reservation schemes
based on fixed channel assignment and hybrid channel assignment.

1.

Introduction

A commonly implemented channel assignment method in a cellular mobile telephone network is the fixed channel assignment (FCA) method [3,8,15,16]. In FCA,
each cell is allocated a fixed number of frequency channels, or nominal channels. To
ensure calls remain free of frequency interference, the allocation of frequent channels
must satisfy the co-channel constraints: the distance between the centers of any two
 J.C. Baltzer AG, Science Publishers

414

Z. Xu et al. / Virtually fixed channel assignment

cells using the same channel must be greater than or equal to the minimum reuse
distance D.
One of the major considerations in cellular mobile telephone networks is handoff:
When a mobile terminal moves to another cell, it requests a channel via the new base
station so that its call can continue. A handoff call will be prematurely terminated if
there is no channel assigned to it. To increase the utilization of frequency channels, the
average cell size in a high-capacity cellular system has become smaller, say 2–5 km
in radius, in order for channels to be used concurrently in many cells. This, of course,
causes mobile units to cross boundaries frequently and, in turn, increases the possibility
of unsuccessful handoffs. Since involuntary call termination produces a negative effect
on customers’ satisfaction, the blocking probability of a handoff call needs to be kept
at an extremely low level. Hong and Rappaport [11] propose two channel reservation
schemes aimed at reducing the blocking probability of handoff calls, Bh , in a FCA
network:
• Scheme I. A small number of nominal channels in a cell is reserved exclusively for
handoff calls, while the other channels are shared by fresh and handoff calls.
• Scheme II. Same as scheme I, except that it allows the buffering of handoff calls.
That is, a handoff call arriving to a saturated new cell will wait in a buffer and
be served in the future, provided that the new cell can allocate a channel to the
handoff call before the mobile unit moves away from the handoff area.
In scheme II, Hong et al. assume the dwell time, the time that a mobile unit
stays within the handoff area, is exponentially distributed and model the network as a
Markov chain. As one would expect, scheme II produces a smaller Bh than scheme I
does. Shetty [22] and Jaomes et al. [12] used petri-net models to evaluate the above
schemes and other similar ones. Rappaport and Purzynski [19] extended the channel
reservation strategies to the system with mixed services (different types of calls, e.g.,
voice, data, image, etc.).
Although channel reservation reduces Bh , they do so at the expense of decreased
channel utilization. Consequently, the overall (fresh and handoff) blocking probability
increases. In view of the reality that the frequency band available for cellular radio
services is very limited and the demand for services is steadily increasing, it is necessary to search for other control strategies that can utilize available frequency resources
more efficiently.
The major drawback of FCA is its inflexibility: once a channel is allocated to
a set of co-channel cells (cells that are allocated the same channels), it cannot be
used in other cells. To improve the flexibility of channel assignment, several authors [7,16,23] consider the dynamic channel assignment (DCA) method: all channels
are kept in a “central pool”; a channel is assigned to a cell when a call arrives and
the channel assignment will not cause frequency interference, and is returned to the
central pool when the call leaves the cell. Because the optimal DCA is equivalent to a
graph-coloring problem [10], which is a NP-complete problem, various heuristic DCA
methods have been proposed. The simplest DCA heuristic is the first-available strat-

Z. Xu et al. / Virtually fixed channel assignment

415

egy, in which a call is assigned to the first available channel found when searching the
central pool. Cox and Reudink [4,5] proposed other simple heuristic DCA schemes.
Through simulation studies, researchers found that these strategies outperform FCA in
light traffic, but underperform FCA in heavy traffic. Among more sophisticated heuristics, Metzger [17], Zoellner and Beall [29], Box [2], Gamst and Rave [9], and Sengoku
et al. [21], among others, considered the graph decomposition approach to solve the
graph coloring problem. Rose and Yetes [20] modeled a DCA network as a Markov
process and used dynamic programming to find a nearly optimal policy. Although
these approaches improve the performance of DCA significantly, on-line algorithms
for dynamic channel allocation are computationally intensive, and are impractical to
implement as distributed algorithms.
Mixtures of FCA and DCA channel management methods are also reported in
the literature. For example, hybrid channel assignment (HCA) allocates a proportion
of channels available to the system as fixed channels, while keeps others in the central
pool as dynamic channels [5,13,26,28]. Simulation and mathematical analyses show
that HCA performs better than simple DCA strategies if a proper portion (usually a
small percentage) of channels are allotted as dynamic ones [13]. It is worth mentioning
that channel reservation strategies have also been studied in DCA (e.g., [24,27]) and
HCA (e.g., [14]).
Virtually fixed channel assignment (VFCA), also known as borrowing channel
assignment, is another type of combination of FCA/DCA [6]. The idea behind it is
simple: The channels available in the network are all allocated to cells according to
FCA so that each cell has a list of nominal channels. A cell assigns a nominal channel
to an arriving call if there is one available; otherwise it “borrows” an available channel
from a neighboring cell, a virtual channel, to service this call. Channel borrowing
enables the system to adjust the ratio of “dynamic channels” and fixed channels in a
cell, individually and adaptively, when responding to the random fluctuation of calls.
As such, VFCA takes the advantages of the efficiency (channel reuse) in FCA and the
flexibility of DCA. While simulation studies [1,6,18,28] show that VFCA improves the
system efficiency significantly, the literature addressing VFCA modeling, performance
evaluation, and dynamic control issues is lagging. The technical difficulties involved
in analyzing VFCA are mainly due to the special feature of channel borrowing: When
a call is serviced by a borrowed channel i, channel i has to be locked in the cells
within the minimum reuse distance D to prevent co-channel interference. Channel i
will be unlocked simultaneously in these cells when the borrowed channel is returned
(we describe the detailed channel borrowing mechanism in section 2). This feature
introduces strong correlation in channel assignment among cells and makes the exact
analysis of VFCA formidable. Xu and Mirchandani [25] develop an approximate
analytical model to access the system performance of VFCA, where the effect of
handoff calls is assumed negligible.
One concern about VFCA is the potential chain reaction in channel borrowing,
caused by cells borrowing channels from one another. Since a borrowed channel has to
be locked in several cells to service a single borrowing call, the network performance

416

Z. Xu et al. / Virtually fixed channel assignment

may degrade due to this chaining in borrowing. This degradation can be significant in
heavy traffic conditions.
In this paper, we propose the virtually fixed channel assignment with recall
(VFCAWR) scheme: The network is operated according to VFCA, but a cell can recall
a locked nominal channel to service a handoff call. The recall feature of VFCAWR
reduces the chance of blocking a handoff call and the number of locked channels in
the network. We address modeling, performance evaluation and dynamic control issues in a VFCAWR network. We propose an analytical model that approximates the
channel assignment process by a 3-dimensional Markov chain. We derive the equilibrium distribution of the Markov chain and compute several performance measures
of interest. We propose two simple, yet efficient, dynamic channel assignment strategies, the virtual channel reservation and linear switch-over strategies, which exploit
the unique borrowing/recall feature of VFCAWR to reduce the blocking probability
of handoffs by reserving several “virtual” channels, instead of nominal channels, for
handoff calls. Unlike the commonly adopted channel reservation strategies, which reduce the blocking probability of handoff calls via the decreased channel utilization, our
strategies simultaneously reduce the blocking probability of handoff calls and increase
overall channel utilization. We validate the analytical models by simulation, which
demonstrates that the models estimate system performance with reasonable accuracy.
We also compare, via simulation, our dynamic stategies with the FCA scheme II [11]
and the HCA dynamic channel reservation scheme using the first available rule. The
reason we chose HCA over DCA for comparisons is that previous simulation studies [13] show that HCA is superior to DCA when a simple channel selection rule is
used. Numerical and simulation results show that our proposed strategies outperform
significantly both FCA and HCA channel reservation schemes.
The paper is organized as follows. Section 2 describes the system environment of
VFCAWR. Section 3 develops the basic Markov chain model for VFCAWR. Section 4
derives the equilibrium distribution and other relevant performance measures using the
basic model. Section 5 modifies the basic model to incorporate the features introduced
by two dynamic channel assignment strategies; these strategies aim at minimizing
the total penalty cost caused by fresh and handoff call blocking. Section 6 reports
simulation and numerical results and compares different strategies. The concluding
section 7 summarizes our contributions.
2.

System environment of VFCAWR

We assume that our network has the following characteristics: A service area
is subdivided into many regular polygons (called cells) with each polygon having the
same shape and size. The service area is very large so that boundary effects are
negligible. Cells are partitioned into identical clusters, with each cluster comprising
G cells. Channels available to the system are divided into G groups, with each group of
channels allocated to one cell in a cluster. For example, figure 1 shows a 7-cell cluster
(G = 7) configuration: The cells within the bold-line boundaries comprise one cluster.

Z. Xu et al. / Virtually fixed channel assignment

417

Figure 1. Channel allocation in FCA.

The cells labeled by number i are allocated the ith group of channels, i = 1, 2, . . . , G.
The cells allocated the same group of channels are called the co-channel cells.
Fresh calls generated from each cell form a Poisson process with rate λ. The call
duration time, the time for a caller to complete his/her conversation, is an exponential
random variable with rate µf . The mobile dwell time, the time that a mobile unit
travels within a cell, is also an exponential random variable with rate µd . A handoff
occurs if the mobile dwell time is less than its call duration time. In such a case, the
mobile unit is equally likely to arrive at any of its adjacent cells.
Let the cells be denoted by c1 , c2 , c3 , . . . . Let the channels available to the system
be numbered as 1, 2, . . . . Since a channel can be used concurrently in many cells,
it functions virtually as many different carriers, here a “carrier” means a channel
allocated to a cell. Specifically, let each carrier be indexed by a channel number and a
cell number. We denote a carrier by fil if channel i is allocated to cell cl . Note fil and
fik are different carriers if l 6= k, although both fil and fik use the same channel i.
We describe channel borrowing as follows: Suppose cell ck wishes to borrow
a channel, say channel i, from cell cl to meet a new call request, provided the cochannel constraints are satisfied. We denote the borrowing by fil → ck . To prevent
co-channel interference during the borrowing, channel i has to be locked in the cells
within the minimum reuse distance D. We assume that a cell cannot borrow a locked
channel. Thus, when ck borrows a channel, some free carriers must be locked until
the borrowed channel is returned. We refer to the call that borrows a channel as
a borrowing call, the resulting locked carriers1 as the interferable carriers, and the
cells where the interferable carriers are located as the interferable cells with respect
1

When we say a carrier fil is locked, we mean that channel i is locked in cell cl .

418

Z. Xu et al. / Virtually fixed channel assignment

to fil → ck . If there does not exist i and l such that fil → ck is feasible then we say
the call is blocked. Blocked calls are lost, and, thus, cleared from the system.
To illustrate, consider a cellular system with a 7-cell cluster pattern as shown
in figure 2(a). Cells labeled with the same number at upper corners are co-channel
cells (allocated the same group of channels). Cell numbers appear at lower corners.
Suppose that c26 wishes to borrow channel i from c25 to meet a call request. Let c21
and c37 be within the minimum reuse distance D when fi,25 → c26 occurs. Therefore,
to make the borrowing free of co-channel interference, fi,25 , fi,21 and fi,37 must be
free when fi,25 → c26 is initialized, and they must remain locked until fi,25 → c26
ends. Thus {fi,21 , fi,25, fi,37 } are the interferable carriers and {c21 , c25 , c37 } (the shaded
cells in figure 2(a)) are the interferable cells with respect to fi,25 → c26 .
We say a cell is saturated if all the nominal channels are busy and self-saturated
if the cell is saturated and all the channels are serving calls from its own cell. To
prevent chain reaction in channel borrowing among cells, we allow a cell to recall
a locked nominal channel if the cell is saturated but not self-saturated at the arrival
epoch of a handoff call. That is, when a handoff call arrives at a saturated cell that
has at least one locked nominal channel, the cell will recall one of the locked nominal
channels to serve the arriving handoff call. The recall will preempt the service of the
borrowing call using the locked channel and thus unlock the set of interferable carriers
with respect to the borrowing call. The preempted call will be treated as a new handoff
call arriving to its own cell. Hence, if the preempted call finds a locked channel in its
own cell, it will recall the locked channel and continue its conversation on the recalled
channel; otherwise it will borrow another non-nominal channel whenever feasible. In
the example of figure 2(a), if channel i is recalled by any of the interferable cells
{c21 , c25 , c37 } with respect to fi,25 → c26 , then the borrowing call using channel i prior
to the recall is preempted and hence becomes a new handoff call arriving to c26 . If c26
has some locked nominal channels, then c26 will recall a locked nominal channel to
service the preempted call. If c26 has no locked nominal channel but channel borrowing
is feasible, c26 will borrow another non-nominal channel to service the preempted
call. If c26 has no locked nominal channel and channel borrowing is infeasible, the
preempted call is blocked. However, we prohibit a fresh call to recall a locked nominal
channel, because the consequence of terminating an on-going call is more severe than
that of blocking a fresh call. Thus, a fresh call arriving at a saturated cell will be
serviced by a virtual channel when channel borrowing is successful; otherwise, the
fresh call is blocked.
The virtual channel i associated with fil → ck is returned to cl as soon as one
of the following three events occurs:
1. The borrowing call terminates its service on channel i.
2. A nominal channel in ck is released and the borrowing call using channel i is
transferred to the just-released channel so that channel i is freed.
3. Channel i is recalled by one of the interferable cells with respect to fil → ck .

Z. Xu et al. / Virtually fixed channel assignment

419

(a)

(b)
Figure 2. (a) Channel borrowing; (b) generation of fictitious calls.

In the example of figure 2(a), channel i is returned to c25 when either a nominal channel in c26 becomes available for the borrowing call, or the borrowing call
terminates on channel i, or the recall of channel i occurs in one of the interferable

420

Z. Xu et al. / Virtually fixed channel assignment

cells {c21 , c25 , c37 }. When a borrowed channel is returned, the corresponding set of
interferable carriers is unlocked.
3.

The basic model

In this section, we develop an approximate model for a VFCAWR network. We
refer to this model as the basic model. In the basic model, calls are not subject to any
control. That is, a call will be accepted as long as the feasibility condition is satisfied.
In section 5, we use the basic model to evaluate the performance of various dynamic
control policies, in which a cell controller can either accept or reject a fresh call.
Due to the homogeneity of the system configuration, all the cells are considered
equivalent. Hence, it is sufficient to analyze the performance of an arbitrary cell,
say ck . Suppose that ck wishes to borrow a virtual channel from its neighbors and
finds that the borrowing fil → ck is feasible for some i and l. Let ν be the number of
interferable cells with respect to fil → ck . Conceptually, the borrowing call generates
ν fictitious calls that go to the interferable cells and occupy the interferable carriers
(see figure 2(b)). That is, the price for letting ck use a virtual channel is that the system
has to service ν fictitious calls. When fil → ck ends, the services of those ν fictitious
calls are completed and the set of interferable channels are released simultaneously.
With this viewpoint, cell ck is equivalent to a multiple server loss queueing network
with three streams of arrivals: fresh calls, handoff calls, and fictitious calls (generated
by fresh and handoff calls from neighboring cells). Here we do not distinguish a
fictitious call generated by a fresh call or by a handoff call, because, by the memoryless
property of the exponential distribution, the remaining call duration time of a handoff
call is stochastically identical to that of a fresh call. In addition, ck treats them
indifferently. However, we need to distinguish fresh and handoff calls, because ck
treats them differently.
The exact solution of this loss queueing network appears formidable, due to the
borrowing/recall feature of the traffic flows. Therefore, we resort to an approximate
analysis by making the following assumptions:
(A1) Fresh calls, handoff calls and fictitious calls arrive to ck according to three
independent Poisson processes with rates λ, λh , and λb , respectively.
(A2) The recall time, the time from the instant a channel is locked in ck until the
instant ck recalls the locked channel, is an exponential random variable with
rate µr .
(A3) The transfer time, the time from the instant ck assigns a virtual channel to a call
until the instant ck switches the call to a just-released nominal channel, is an
exponential random variable with rate µt .
(A4) The recall time, the transfer time, the call duration time, and the mobile dwell
time are mutually independent.

Z. Xu et al. / Virtually fixed channel assignment

421

(A5) We assume that the (unknown) parameters λh , λb , µt and µr are state-invariant,
that is, they do not depend on the state of the network. Parameter β, the probability that a borrowing is feasible, will be shown to be dependent on the system
state.
For the reader’s convenience, a list of notation used throughout is appended at
the end of the paper.
To formulate the system as a Markov chain, let us take a closer look at the
different types of calls in ck . As we noted, the remaining service times of fresh and
handoff calls have the same distribution. Thus, as soon as a call is admitted to ck ,
it becomes an on-going call which has the same characteristics of a handoff call.
Therefore, we can distinguish a call in ck according to whether the call is a fictitious
call or a real call, and, in the latter case, whether it occupies a nominal channel or
a virtual channel. Specifically, we call the fresh and handoff calls using nominal
channels the type I calls, the fictitious calls locking nominal channels the type II calls,
and the fresh and handoff calls using virtual channels the type III calls.
An arriving call in ck and the type it is admitted as have the following relationship:
• If ck is not saturated, a fresh or handoff call will enter ck as a type I call, and a
fictitious call will enter ck as a type II call.
• If ck is saturated but not self-saturated, a fresh call will become a type III call
when channel borrowing is successful and be blocked otherwise, a handoff call will
become a type I call by recalling a locked nominal channel, and a fictitious call
will not be admitted to ck as it is already full.
• If ck is self-saturated, a fresh or handoff call will be admitted as a type III call
when channel borrowing is feasible and blocked otherwise, and fictitious calls will
cease to arrive.
Now we are ready to formulate the channel assignment process in cell ck as a
Markov process. We denote the state of the system by (i, j, k), where
i: number of type I calls in ck (i.e., number of nominal channels in use),
j: number of type II calls in ck (i.e., number of locked nominal channels),
k: number of type III calls in ck (i.e., number of virtual channels in use).
Let M be the number of nominal channels allocated to a cell, L (<M ) the
maximum number of “loanable” nominal channels in a cell (i.e., the maximum number
of channels a cell can lend to other cells), and V the maximum number of virtual
channels “borrowable” in a cell (i.e., the maximum number of channels a cell can
borrow from other cells). Then the state space of the Markov chain for cell ck is

S = (i, j, 0): i + j 6 M , 0 6 j 6 L, and
	
(i, j, k): i + j = M , 0 6 j 6 L, 0 < k 6 V .
Next we consider the service times of different types of calls in ck . Recall that
the call duration time and the mobile dwell time are exponential random variables with

422

Z. Xu et al. / Virtually fixed channel assignment

rates µf and µd , respectively. This implies that the service time of a type I call in ck
is an exponential random variable with rate µ := µf + µd .
To obtain the service time distribution of a type II call, let us consider a fictitious
call which locks channel i in ck . Suppose the fictitious call was generated by a call
in cl which borrows channel i. Channel i is unlocked in ck as soon as either the
borrowing call is transferred to a just-vacated nominal channel in cl (with rate µt ), or
the borrowing call terminates its service (with rate µ), or one of the ν interferable cells,
including ck , recalls its locked nominal channel (with rate νµr ), whichever occurs first.
From (A2)–(A4), the service time of a type II call is an exponential random variable
with rate µ + νµr + µt .
To obtain the service time of a type III call, it is important to realize the duality
relationship between type II and type III calls: Because of the homogeneous configuration of the network, the time that a call from some other cell borrows a channel
from ck must be stochastically identical to the time that a call from ck borrows a
channel of some other cell. Hence, the service time of a type III call has the same
distribution as that of a type II call, which follows an exponential distribution with
rate µ + νµr + µt . Therefore,
1
= E(service time of a type II call)
µ + νµr + µt
= E(service time of a type III call).

(1)

Using this duality relationship between type II and type III calls, we may derive other quantities useful in future analysis. Because each borrowing call will lock
ν interferable carriers, the expected number of locked nominal channels in ck must be
the same as the expected number of virtual channels in ck multiplied by ν. In other
words,
E(J) = νE(K),

(2)

where E(J) and E(K) are the expected numbers of types II and III calls in ck . Also,
by (A2)–(A4),
µr
.
(3)
P (a type II call is preempted by ck ) =
µ + νµr + µt
4.

The equilibrium distribution of the basic model

Let pi,j,k be the equilibrium probability that a cell is in state (i, j, k) of the basic
model. The equilibrium probability distribution {pi,j,k } is derived as follows:
Step 1. Derive balance equations for {pi,j,k } in terms of known parameters λ, µ =
µf + µd and unknown parameters λh , λb , µt , µr and β;
Step 2. Use the conservation law and the duality property to determine the expressions
of unknown arrival rates λh and λb in terms of pi,j,k ;

Z. Xu et al. / Virtually fixed channel assignment

423

Step 3. Use Little’s formula and equation (3) to derive the expressions of unknown
parameters µt and µr ;
Step 4. Estimate β using the assumption that cells are independent.
Equations developed in steps 1–4 can then be solved iteratively to obtain {pi,j,k }
as well as the unknown parameters.
Step 1. Derive balance equations for {pi,j,k }
For convenience, we denote µb := µ + (ν − 1)µr + µt . One interprets µb as the
service rate of a type II call, provided that ck never preempts the call. Similarly, one
may think of µ + νµr as the service rate of a type III call, provided that ck never
transfers the call to a nominal channel.
Figure 3(a) illustrates the transition rate diagram of the Markov process with
M = 4, L = 3 and V = 2. We derive three sets of balance equations, depending
on whether ck is not saturated, saturated but not self-saturated, and self-saturated. We
assume pi,j,k = 0 if (i, j, k) does not belong to the state space S.
(a) Cell ck is not saturated
(λ + λh + λb + iµ + jµb )pi,j,0
= (λ + λh )pi−1,j,0 + λb pi,j−1,0 + (i + 1)µpi+1,j,0 + (j + 1)µb pi,j+1,0,
i + j < M , j < L,
(λ + λh + iµ + Lµb )pi,L,0
= (λ + λh )pi−1,L,0 + λb pi,L−1,0 + (i + 1)µpi+1,L,0 , i < M − L.

(4)
(5)

Equation (4) bears the following explanation:
• The outflow from state (i, j, 0) can occur owing to an arrival of a call or a service
completion of either a type I or a type II call.
• The inflow into state (i, j, 0) can occur from state (i − 1, j, 0) owing to an arrival of
a fresh or handoff call, or from state (i, j − 1, 0) owing to an arrival of a fictitious
call, or from state (i + 1, j, 0) owning to a service completion of a type I call, or
from state (i, j + 1, 0) owing to a service completion of a type II call.
The explanation of (5) is similar to that of (4), except that the fictitious calls will
cease to arrive when ck can no longer provide loanable channels to them.
(b) Cell ck is saturated but not self-saturated

βλ + λh + (i + k)µ + jµb + kνµr pi,j,k
= βλpi,j,k−1 + λh pi−1,j+1,k + (i + k + 1)µpi,j,k+1

+ (j + 1)µb + (k + 1)νµr pi−1,j+1,k+1, i + j = M , 0 < k < V , j > 0, (6)

424

Z. Xu et al. / Virtually fixed channel assignment

Figure 3(a). The Markov chain with M = 4, L = 3 and V = 2.


βλ + λh + (M − j)µ + jµb pM −j,j,0
= (λ + λh )pM −j−1,j,0 + λb pM −j,j−1,0 + λh pM −j−1,j+1,0

+ (M − j + 1)µpM −j,j,1 + (j + 1)µb + νµr (1 − β) pM −j−1,j+1,1,

λh + (M − j + V )µ + jµb + V νµr pM −j,j,V
= βλpM −j,j,V −1 + λh pM −j−1,j+1,V , j > 0.

j > 0, (7)
(8)

Z. Xu et al. / Virtually fixed channel assignment

425

Figure 3(b). Expressing the Markov chain using notation β0 and β1 .

One understands (6) as follows:
• ck will flow out of state (i, j, k) if a fresh call arrives and channel borrowing is
feasible (with probability β), or a handoff call arrives that will trigger the recall
of a locked nominal channel to service the handoff call, or a call (of any type)
completes its service, or one of the k type III calls is preempted due to recall (at

426

Z. Xu et al. / Virtually fixed channel assignment

rate kνµr ) that will subsequently cause ck to recall a locked channel (the preempted
type II call will return to its own cell).
• The inflow into state (i, j, k) can occur from state (i, j, k − 1) if a fresh call arrives
and channel borrowing is feasible, or from state (i − 1, j + 1, k) if a handoff call
arrives that will recall a locked nominal channel and enter ck as a type I call, or
from state (i, j, k + 1) if either a type I call finishes (then a type III call will be
transferred to the just-vacated nominal channel) or a type III call finishes, or from
state (i − 1, j + 1, k + 1) if either a type II call finishes (then a type III call is
transferred to the just-available nominal channel) or a type III call is preempted
that will subsequently preempt a type II call and become a type I call.
Equations (7) and (8) are derived using the same logic.
(c) Cell ck is self-saturated

β(λ + λh ) + (M + k)µ + (1 − β)kνµr pM ,0,k
= β(λ + λh )pM ,0,k−1 + λh pM −1,1,k

+ (M + k + 1)µ + (k + 1)νµr (1 − β) pM ,0,k+1

+ µb + (k + 1)νµr pM −1,1,k+1, 0 < k < V ,
(9)

β(λ + λh ) + M µ pM ,0,0
= (λ + λh )pM −1,0,0 + λh pM −1,1,0

+ (M + 1)µ + (1 − β)νµr pM ,0,1 + (µb + νµr )pM ,1,0,
(10)

(M + V )µ + V νµr (1 − β) pM ,0,V = β(λ + λh )pM ,0,V −1 + λh pM −1,1,1. (11)
Justification of equation (9) is as follows (the justifications of (10) and (11) are
similar):
• When ck is self-saturated, the outflow can occur if a fresh or handoff call arrives
and channel borrowing is feasible, or a type I or type III call completes its service, or a virtual channel is recalled and the channel borrowing for the preempted
type III call is infeasible (state (M , 0, k) will not change if the channel borrowing
is feasible).
• The inflow into state (M , 0, k) can occur from state (M , 0, k − 1) if a fresh or
handoff call arrives and channel borrowing is feasible, or from state (M − 1, 1, k)
if a handoff call arrives that will cause the type II call to be preempted, or from
state (M , 0, k + 1) if either a type I call is completed so that a type III call will
become a type I call, or a type III call is completed, or a virtual channel is recalled
and a channel borrowing is feasible. The inflow into state (M , 0, k) can also occur
from state (M − 1, 1, k + 1) if either a type II call is completed so that a type III
call is switched to the unlocked channel and become a type I call, or a type III call
is preempted that will subsequently preempt a type II call.

Z. Xu et al. / Virtually fixed channel assignment

Finally, we have the normalizing equation
X
pi,j,k = 1.

427

(12)

(i,j,k)∈S

Step 2. Determine arrival rates λh and λb
First, consider λh , the arrival rate of handoffs. Let Bf and Bh be the probabilities that fresh and handoff calls are blocked instantaneously at their arrival instants,
respectively. Let λr be the rate that preempted type III calls are blocked due to infeasibility of channel borrowing. Because every cell has the same traffic characteristics
in a homogeneous system, we can equate the rate that handoff calls arrive in ck to the
rate that calls depart ck as handoff calls:

µd 
λh =
λ(1 − Bf ) + λh (1 − Bh ) − λr .
(13)
µd + µf
Equation (13) states that the arrival rate of handoff calls to ck equals the departure
rate of the completed calls from ck multiplied by the probability that a departing call
requests a handoff. Solving (13) yields
λh =

λµd (1 − Bf ) − µd λr
.
µf + µd Bh

(14)

The instantaneous blocking probabilities of fresh and handoff calls, Bf and Bh , are
determined by
X
X
pi,j,V + (1 − β)
pi,j,k
(15)
Bf =
i+j=M

i+j=M

k<V

and
Bh = pM ,0,V + (1 − β)

X

pM ,0,k .

(16)

06k<V

Equation (15) states that a fresh call will be blocked upon its arrival if ck is saturated
and channel borrowing is infeasible. Equation (16) bears a similar explanation.
We determine λr , the rate of the blocked type III calls due to recalls, as follows.
A type III call will be blocked if, when a recall occurs, ck is self-saturated and channel
borrowing is infeasible, for otherwise the preempted type III call will either recall a
locked nominal channel and continue its service on the recalled channel, or borrow
another virtual channel when feasible. Since the recalls of the virtual channels in state
(M , 0, k) occur at rate kνµr , the expected number of blocked type III calls per unit
time is
X
kνµr pM ,0,k .
(17)
λr = (1 − β)
0<k6V

Substituting (15)–(17) into (14) yields the expression for λh .

428

Z. Xu et al. / Virtually fixed channel assignment

To determine λb , the arrival rate of fictitious calls, we use the duality property
(recall the explanation for equations (1) and (2)): the entering rate of type II calls
must equal the entering rate of type III calls multiplied by ν (because each type III
call locks ν interferable channels),
#
"
X
X
X
X
λb
pi,j,0 = ν βλ
pi,j,k + βλh
pM ,0,k + β
kνµr pM ,0,k , (18)
i+j<M
j<L

i+j=M
06k<V

k<V

k6V

where the terms within the bracket on the right hand side of (18) are, in turn, the
entering rates of type III calls generated by fresh calls, handoff calls, and the preempted
type III calls.
Step 3. Derive expressions for µt and µr
We determine µt and µr by developing two expressions that they must satisfy.
The first expression is obtained by using Little’s formula to relate the expected
time a type II call spends in ck , the expected number of type II calls in ck , and the
entering rate of type II calls to ck . The expected number of type II calls in ck , E(J),
is
X
jpijk .
(19)
E(J) =
(i,j,k)∈S

The entering rate of type II calls to ck is λb

P
i+j<M
j<L

pij0 . Using equation (1) and

Little’s law,
P

E(J)
1
(i,j,k)∈S jpijk
= P
= P
.
µ + νµr + µt
λb i+j<M pij0
λb i+j<M pij0
j<L

(20)

j<L

To derive the second expression of µt and µr , recall from (3) that the probability that
a type II call is preempted in ck is µr /(µ + νµr + µt ). This probability, however, is
also the ratio of the preemptive rate of type II calls to the entering rate of type II calls.
Therefore,
µr
=
µ + νµr + µt

λh

P

P
i+j=M pijk +
i+j=M kνµr pijk
j>0, k>0
j>0, k>0
.
P
λb i+j<M pij0
j<L

Step 4. Estimate β
Let the neighboring cells that may lend channels to ck be ck1 , . . . , ckm . Let
Event Aj = {fi,kj → ck is feasible for some i}, j = 1, . . . , m.

(21)

Z. Xu et al. / Virtually fixed channel assignment

429

Let Acj be the complement of Aj . Then


β = Prob(A1 ∪ · · · ∪ Am ) = 1 − Prob Ac1 ∩ · · · ∩ Acm .

(22)

To compute the exact probability appears to be an unwieldy task because the channel borrowing/recall process makes the cells stochastically dependent on one another.
Therefore, we approximate β by ignoring the dependence among Aj , j = 1, . . . , m.
Due to the homogeneous structure of the network, Prob(Ai ) = Prob(Aj ). Therefore,
m

(23)
β ≈ 1 − 1 − Prob(A1 ) .
Because event Aj implies that each of the ν interferable cells corresponding to borrowing fi,kj → ck has at least one free channel, we have
ν

X
Prob(A1 ) =
pi,j,k .
(24)
i+j<M,j<L

Substituting (23) into (22),



β ≈1− 1−

X

ν m
pi,j,k

.

(25)

i+j<M, j<L

Note that equation (25) gives the unconditional probability that a channel borrowing
is feasible. However, by conditioning on certain states of the system, β can be approximated more accurately. In fact, under either of the two following conditions, at
least one neighboring cell cannot loan a channel to ck :
• Condition 1. ck is in state (i, j, k) with j > 1. This implies that there exists one
fictitious (type II) call in ck from a neighboring cell, say ckj , which in turns implies
that one of the ν interferable cells corresponding to channel borrowing from ckj
to ck , is saturated. So channel borrowing from ckj to ck is infeasible.
• Condition 2. ck is in state (i, j, k) with j = 0, k > 0, when a virtual channel
borrowed from a neighboring cell is recalled. Evidently, at this moment ck can only
borrow a channel from one of the remaining m − 1 cells to service the relinquished
call.
Based on the above observations, we adjust equation (25) as follows:


ν m−1
P

=
1
−
1
−
p
, if the system is either in
β
1
i+j<M
i,j,k


j<L
condition 1 or 2,
β=

ν m
P


,
otherwise.
 β0 = 1 − 1 −
i+j<M pi,j,k

(26)

j<L

Figure 3(b) illustrates the dependency of the blocking probability on the system
state, using the same example as in figure 3(a).
One can solve iteratively the equations developed in steps 1–4 to obtain estimates
of λh , λb , µt , µr , β, and the limiting distribution {pi,j,k }. Subsequently, several performance measures of interest can be obtained as the functions of {pi,j,k }. For example,

430

Z. Xu et al. / Virtually fixed channel assignment

(15) and (16) give the probabilities that a fresh call and a handoff call are blocked upon
arrival, respectively. Equations (19) and (2) compute the expected numbers of type II
and type III calls in ck . The total blocking rate of on-going calls in ck , including the
instantaneous blocking rate of handoff calls and the blocking rate of preempted type III
calls, is
λh Bh + λr ,

(27)

where λr is given by (17). Therefore, the probability that an on-going call is forced
to terminate in ck , BF , is
BF =

5.

λh Bh + λr
.
λh + λ(1 − Bf )

(28)

Dynamic channel assignment strategies

Given that the voice quality is acceptable, major concerns of a network controller
are the blocking of call initialization and the forced termination of an on-going call.
In particular, it is considered extremely harmful from a customer service perspective
to terminate an on-going call. In this section, we consider some dynamic channel
assignment strategies that can improve the performance of a VFCAWR network.
We assume that a handoff call arriving to ck must be accepted whenever possible. That is, a handoff call will be assigned a nominal channel as long as ck is not
self-saturated (possibly by recalling a locked nominal channel); otherwise, it will be
assigned a virtual channel if channel borrowing is feasible. However, the network
controller may either accept or reject a fresh call, depending on the state of ck at the
arrival epoch of the fresh call. We wish to find a policy of controlling fresh calls that
minimizes the total penalty cost of blocking fresh and on-going calls per unit time
in ck :

	
min wf λBf + wh (λh Bh + λr ) ,
(29)
where the minimization is taken over all control policies, λBf and λh Bh + λr are the
blocking rates of fresh and on-going calls (see (27)), and wf and wh are the penalty
costs of blocking a fresh and an on-going calls, respectively. We do not consider the
cost associated with fictitious calls because they are not real calls.
Recall that handoffs are generated from fresh calls whose call duration times
exceed their mobile dwell times (see (13) for the relationship between the arrival rates
of fresh calls and handoff calls). Clearly, λh Bh + λr decreases as λBf increases, and
vice versa. That is, the more fresh calls are denied entry initially, the less admitted
calls are blocked in the future. The “trade off” is between increasing the blocking rate
of fresh calls and decreasing the blocking rate of on-going calls.
Due to the complexity of the network and the dependence among cells, finding
the exact optimal policy is intractable. In this paper, we restrict our attention to the
classes of virtual channel reservation (VCR) and linear switch-over (LSO) strategies.

Z. Xu et al. / Virtually fixed channel assignment

431

The optimal policy within each class is easy to determine, yet our computational results
show that they can improve the system performance significantly.
5.1. The virtual channel reservation
The virtual channel reservation (VCR) strategy proposed here is a generalization
of the channel reservation strategy in FCA, where several nominal channels are reserved exclusively for the handoff calls. The VCR strategy is designed to take the
advantage of channel borrowing in a VFCAWR network. The strategy is based on
the following idea: When a cell can borrow up to V channels, then, conceptually, a
cell possesses M + V channels. The V virtual channels do not exist physically, but
are accessible when needed. Like nominal channels, a cell may also “reserve” virtual
channels for handoff calls. Reserving virtual channels for handoff calls increases the
number of nominal channels to be shared by fresh and handoff calls and thus decreases
blocking probabilities.
Definition 1. Let (i, j, k) be the state of ck at the arrival epoch of a fresh call; C
be the number of virtual channels reserved for handoff calls. Let πC be the virtual
channel reservation (VCR) strategy that accepts the fresh call if and only if
M + V − (i + j + k) > C,

C = 1, 2, . . . , M + V − 1.

(30)

Let
ΠC := {πC : C = 0, 1, . . . , M − V + 1}

(31)

be the collection of all the VCR policies.
Under πC , a fresh call will be blocked if the total number of calls in ck is
greater than C, whereas handoff and borrowing calls are accepted in ck whenever
possible. If C 6 V , then the C virtual channels are reserved for handoff calls, and
all the nominal channels and the remaining V − C virtual channels are shared by
fresh and handoff calls. Thus, a fresh call is allowed to borrow a virtual channel
provided that the number of busy channels (including virtual channels) in ck is less
than M + V − C. On the other hand, if C > V , then the C − V nominal and V
virtual channels are reserved for handoff calls, and the remaining M + V − C nominal
channels are shared by fresh and handoff calls. Because a fresh call that sees more
than M + V − C busy nominal channels in ck is cleared from the system, it cannot
generate fictitious calls from ck (i.e., all the fictitious calls are generated by handoffs
from neighboring cells when C > V ). The network under policy π0 corresponds to
the basic model.
Let πC ∗ be the optimal policy within ΠC . In most realistic situations, C ∗ 6 V .
That is, no nominal channels need to be reserved for handoff calls in normal teletraffic
conditions. For simplicity, here we only develop the model for policy πC with C 6 V .

432

Z. Xu et al. / Virtually fixed channel assignment

To evaluate the cell performance under πC , we modify the basic model as follows.
Let

n

0 if i + j = M , k > V − C,
(32)
1 otherwise.
Hence, δ(i, j, k)λ represents the arrival rate of fresh calls when ck is in state (i, j, k).
Replacing λ by δ(i, j, k)λ in equations (4)–(11) gives us the balance equations for
the Markov process corresponding to policy πC , C 6 V . All other equations developed so far remain valid (after appropriately adjusting the state-dependent arrival rate
δ(i, j, k)λ), except that the counterpart of (15) is
X
X
pi,j,k + (1 − β)
pi,j,k
(33)
Bf =
δ(i, j, k) =

i+j=M, k>V −C

i+j=M, k<V −C

and the counterpart of (18) is


X
X
X
X
λb
pi,j,0 = ν βλ
pi,j,k + βλh
pM ,0,k + β
kνµr pi,j,k . (34)
i+j<M,
j<L

i+j=M,
k<V −C

k<V

k6V

One can solve these revised equations recursively to obtain the equilibrium distribution of the Markov chain and relevant performance measures under policy πC .
This allows us to evaluate the cost function (29) for each given C 6 V and select C ∗
that minimizes (29).
5.2. The linear switch-over policy
In the virtual channel reservation policy, the decision to accept a fresh call is
based on the total number of calls in ck when the fresh call arrives, ignoring the
distribution of different types of calls currently in ck . In particular, due to call transfer
(from a virtual channel to a nominal channel whenever possible) and channel recall,
a type II (fictitious) call is likely to depart ck much sooner than a type I or a type III
call. The linear switch-over policy takes this factor into consideration.
We define the expected work load of ck in state (i, j, k) as


j
µ
i
k
1
µ
+
i+
+
=
j+
k .
µ µb µ + νµr
µ
µb
µ + νµr
Note that, in defining the expected work load, we use 1/µb as the expected conditional
service time of a type II call, given that ck will not preempt the call. This is because,
if the call is preempted in ck , the type II call will be replaced by a type I call and
the work load in ck will not reduce. Similarly, we use 1/(µ + νµr ) as the expected
conditional service time of a type III call, given that ck will not transfer the call to
a nominal channel. This is because call transfer is possible only when a type I call
departs ck . We call
µ
µ
j+
k
(35)
i+
µb
µ + νµr

Z. Xu et al. / Virtually fixed channel assignment

433

the standard work load of ck in state (i, j, k). In other words, when computing the
standard work load, the work of a type I call is counted as one unit, and the work of
a type II (or III) call is the ratio of the service rate of a type I call to the service rate
of its own type (II or III). If we understand M + V as the standard offered load of ck ,
the remaining offered load of ck in state (i, j, k) is


µ
µ
M +V − i+
j+
k .
µb
µ + νµr
Definition 2. Let the (i, j, k) be the state of ck at the arrival epoch of a fresh call. Let
πW be the linear switch-over (LSO) policy that accepts the fresh call if and only if
the remaining offered load of ck is greater than W (W is a real number):


µ
µ
M +V − i+
j+
k > W , 0 < W < M + V.
(36)
µb
µ + νµr
We call πW the linear switch-over policy because (36) defines a linear curve that
divides the state space S into an accepting region and a rejecting region, and a fresh
call is accepted if and only if at its arrival epoch the state of the system is in the
accepting region. Let
ΠW := {πW : 0 < W < M − V }

(37)

be the collection of the LSO policies.
As in the VCR policy, W < V implies that an arriving fresh call can use a virtual
channel when the standard work load of ck is less than M + V − W , and W > V
implies that an arriving fresh call cannot borrow a channel from an adjacent cell of ck .
The solution approach to find the optimal switch-over policy πW ∗ within ΠW
follows the same iterative procedure as for πC ∗ . We omit the details.
6.

Simulation and numerical results

We developed a simulation model for VFCAWR with and without virtual channel
reservation, in order to validate the Markov chain model that approximates a VFCAWR
network (section 3). We also developed a simulation model to evaluate the performance
of HCA with dynamic channel reservation, using the first-available rule. We now
compare the optimal VCR and LSO policies with the optimal FCA scheme II described
in section 1, and the optimal HCA dynamic channel reservation using the first-available
rule.
6.1. System configuration and parameter setting
The simulated cellular system contains 49 hexagonal cells, as shown in figure 4.
The left and right boundaries of the service area are regarded as being adjacent, and
so are the upper and lower boundaries. For example, cell c43 is adjacent to c1 , c2 ,

434

Z. Xu et al. / Virtually fixed channel assignment

Figure 4. The service area for simulation of VFCAWR and HCA.

c42 , and c49 is adjacent to c1 , c7 and c43 . This makes the simulation equivalent to
that of an infinitely large homogeneous system, since removing the boundary effects
results in each cell having the same topological orientation. We adopt a 7-cell cluster
pattern (figure 1), and do not allow adjacent frequencies to be used in the same cell
simultaneously.
The call requests to each cell follow a Poisson process, and different call arrival
streams are independent. Totally 210 channels are available to the system. To evaluate
the effect of traffic intensity on system performance, fresh call arrival rate λ is gradually
increased from 10/min to 13/min, with increment being 0.5/min. We set µf =
0.5/min, and µd = 0.4/min.
For VFCAWR, each cell is allocated M = 30 channels. In order to satisfy
the adjacent channel constraint, a cell can only borrow channels from four (m = 4)
adjacent cells. For example, c9 in figure 4 may only borrow channels from c1 , c8 , c10 ,
and c17 . It cannot borrow channels from c2 or c16 , because the frequencies in these
two cells are adjacent to the frequencies allocated to c9 .
For the HCA system, we found that the fixed-to-dynamic ratio 28 : 2 gives the
best performance for the traffic intensities tested. That is, of the 210 channels available,
196 are allocated as fixed channels (with each cell having 28 nominal channels), and
the remaining 14 consist the pool of dynamic channels. The optimal thresholds for the
virtual channel reservation in VFCAWR and the dynamic channel reservation in HCA
were determined by exhaustive search.
The same set of system parameters described above is used in numerical computations to obtain the optimal solutions of FCA scheme II and the VFCAWR analytical
model. In the comparison, the cost weights for fresh call blocking and handoff blocking
were chosen to be wf = 1, and wh = 15.

Z. Xu et al. / Virtually fixed channel assignment

435

Table 1
Validation of the analytical VFCAWR-VCR model via simulation.
λ

Simulation model
∗

10.0
10.5
11.0
11.5
12.0
12.5
13.0

Analytical model
∗

n

Bf (%)

Bh (%)

cost

n

Bf (%)

Bh (%)

cost

2
2
2
3
4
4
5

0.27
0.46
0.83
1.95
3.72
5.01
7.92

0.012
0.025
0.051
0.048
0.038
0.078
0.030

0.042
0.081
0.170
0.318
0.523
0.821
1.089

2
2
2
3
3
4
5

0.27
0.49
0.85
1.96
3.81
5.03
8.02

0.013
0.027
0.051
0.043
0.036
0.076
0.035

0.043
0.086
0.162
0.291
0.516
0.767
1.102

n∗ is the optimal number of reserved virtual channels.
Table 2
Performance comparison of fixed and dynamic channel reservation strategies.
λ

10.0
10.5
11.0
11.5
12.0
12.5
13.0

FCA scheme II
(analytical)

HCA
(simulation)

VFCAWR-VCR
(analytical)

VFCAWR-LSO
(analytical)

Bf
(%)

Bh
(%)

n∗

cost

Bf
(%)

Bh
(%)

n∗

cost

Bf
(%)

Bh
(%)

n∗

cost

Bf
(%)

Bh
(%)

n∗

cost

1.12
1.78
2.66
3.74
5.00
6.42
7.96

0.023
0.037
0.056
0.079
0.107
0.139
0.174

0
0
0
0
0
0
0

0.140
0.233
0.364
0.535
0.747
0.997
1.284

1.23
2.05
2.94
3.87
4.95
5.90
7.43

0.116
0.619
1.077
2.421
3.390
4.730
5.921

10
10
10
10
11
10
12

0.261
0.975
1.691
3.586
5.105
7.162
9.114

0.27
0.49
0.85
1.96
3.81
5.03
8.02

0.013
0.027
0.051
0.043
0.036
0.076
0.035

2
2
2
3
3
4
5

0.043
0.086
0.162
0.291
0.516
0.767
1.102

0.3
1.96
0.84
1.96
2.81
4.99
6.31

0.0133
0.027
0.051
0.044
0.089
0.077
0.160

2.98
3.37
3.73
4.30
4.44
4.79
4.82

0.043
0.086
0.162
0.290
0.489
0.764
1.140

n∗ is the optimal number of reserved nominal or virtual channels for respective strategies.

6.2. Test case results
The simulation and numerical results are summarized in tables 1–2. Table 1
validates, via simulation, the analytical Markov model for VFCAWR-VCR. The table
demonstrates that the Markov model produces reasonably accurate performance measurements for VFCAWR-VCR. It turned out that the analytical model also correctly
determined the optimal thresholds for VFCAWR-VCR for all arrival rates tested, except
for λ = 12, where the analytical and simulation models gave the optimal thresholds
of 3 and 4 channels, respectively.
Table 2 compares the performances of different channel reservation strategies,
namely, the FCA scheme II, HCA with dynamic channel reservation, VFCAWR-VCR,
and VFCAWR-LSO. One may notice from table 2 that under the FCA scheme II, no
nominal channels need to be reserved. In fact, we found that only when the traffic
intensity λ is high (> 14/min) or cost ratio wh /wf is large (> 20), it is worthwhile
to reserve one or more nominal channels in the FCA scheme II. This is because the
FCA scheme II allows the buffering of handoff calls and, consequently, reduces Bh

436

Z. Xu et al. / Virtually fixed channel assignment

Figure 5. Performance of VFCAWR with and without dynamic control.

at the expense of keeping handoff calls waiting, whereas the service of a handoff is
instantaneous for VFCAWR under both VCR and LSO.
Table 2 shows that both VFCAWR dynamic policies outperform the FCA
scheme II and HCA dynamic channel reservation significantly, for every traffic load
tested. One observes that as the traffic intensity increases from 10/min to 13/min,
the cost savings achieved by the VFCAWR dynamic policies over FCA scheme II decrease from 70% to 15%. That is, the dynamic control in VFCAWR is most effective
when the traffic intensity is moderate, as occurring often in realistic situations. If the
VFCAWR dynamic policies also allow for queuing of handoff calls, as it is assumed
in the FCA scheme II, its costs can be reduced even further.
One can also conclude from table 2 that in selecting a dynamic control strategy for
VFCAWR, it is sufficient to restrict our attention to the class of VCR policies, because
the performances of the two dynamic strategies, VCR and LSO, are not markedly
different, but LSO demands more computational effort than VCR does.
Figure 5 shows VFCAWR without dynamic control degrades repidly as the traffic
intensity increases. By including VCR, the cost associated with call blocking decreases
significantly, especially under high traffic intensity.
7.

Summary
The contributions of this paper are:

1. The introduction of the virtually fixed channel assignment with recall (VFCAWR)
method for a cellular mobile telephone network. This scheme is based on VFCA,

Z. Xu et al. / Virtually fixed channel assignment

437

but now a cell is allowed to recall a locked nominal channel to service an arriving
handoff call. The recall function of VFCAWR prevents the possibility of a chain
reaction in channel borrowing that may occur under VFCA.
2. The explicit analytical modeling of handoff calls, which are ignored in most performance studies.
3. The development of an approximate analytical model to evaluate the performance
of a VFCA-type network. The basic model developed in this paper, we believe, is
the first analytical model for a VFCA-type network which explicitly models handoff
calls. This analytical model can be used to investigate different VFCAWR dynamic
policies with negligible effort (the runtime of the analytical model is only a tiny
fraction of that required to run the corresponding simulation model).
4. The analysis of dynamic control for VFCAWR networks. We proposed some simple,
yet efficient, dynamic channel assignment strategies and have evaluated their performance. To the best of our knowledge, this is the first attempt to introduce VFCA
channel reservation strategies with dynamic control. Numerical results suggest that
our strategies significantly outperform reported channel reservation schemes.
List of notations
λ: arrival rate of fresh calls;
λb : arrival rate of fictitious calls;
λh : arrival rate of handoff calls;
λr : blocking rate of type III calls due to recall;
1/µf : average call duration time of fresh calls;
1/µd : average mobile dwell time in a cell;
µ = µf + µd : service rate of a call in a cell;
µr : the rate that a cell recalls a locked nominal channel;
µt : the rate that a cell transfers a call from a virtual channel to a nominal channel;
µb = µ + (ν − 1)µr + µt : the service rate of a fictitious call in a cell, given that the
cell never preempts the call;
β: the probability that a borrowing is feasible;
ν: number of interferable cells with respect to a borrowing;
m : number of neighboring cells that channels may be borrowed from;
C: number of virtual channels reserved for handoff calls;
M : number of nominal channels allocated to a cell;
L: maximal number of nominal channels in a cell that are loanable to other cells;

438

Z. Xu et al. / Virtually fixed channel assignment

V : maximal number of virtual channels allowed in a cell;
Bf : instantaneous blocking probability of a fresh call;
Bh : instantaneous blocking probability of a handoff call;
BF : the probability that an on-going call is forced to terminate;
wf : penalty cost of blocking a fresh call;
wh : penalty cost of blocking an on-going call;
πC : the VCR policy which accepts a fresh call if and only if (29) is satisfied;
ΠC : the collection of all the VCR policies;
πW : the LSO policy which accepts a fresh call if and only if (35) is satisfied;
ΠW : the collection of all the LSO policies.
Acknowledgements
The authors would like to thank the two anonymous referees for their helpful
comments. Susan H. Xu’s research is supported in part by the NSF grant DMI 9812994.
References
[1] L.G. Anderson, A simulation study of some dynamic channel assignment algorithms in a high
capacity mobile telecommunications system, IEEE Transactions on Vehicular Technology 22(4)
(1973) 210–217.
[2] F. Box, A heuristic technique for assigning frequencies to mobile radio nets, IEEE Transactions on
Vehicular Technology 27(2) (1978) 116–120.
[3] G.K. Chan and S.A. Mahamoud, Interference analysis of a land mobile cellular radio system, in:
6th Sympos. and Exhibition on Electromagn. Compat., Zurich, Switzerland (1986).
[4] D.C. Cox and D.O. Reudink, Dynamic channel assignment in two-dimensional large-scale mobile
radio systems, Bell Systems Technical Journal 51 (1972) 1611–1629.
[5] D.C. Cox and D.O. Reudink, Increasing channel occupancy in large-scale mobile radio systems:
Dynamic channel assignment, IEEE Transactions on Communications 21 (1973) 1302–1306.
[6] S. Elnoubi, R. Singh and S.C. Gupta, A new frequency channel assignment algorithm in high
capacity mobile communication systems, IEEE Transactions on Vehicular Technology 31(3) (1982)
125–131.
[7] D.E. Everitt and D. Manfield, Performance analysis of cellular mobile communication systems
with dynamic channel assignment, IEEE Journal on Selected Areas in Communications 1 (1989)
1172–1180.
[8] A. Gamst, Homogeneous distribution of frequencies in a regular hexagonal cell system, IEEE
Transactions on Vehicular Technology 31(3) (1982) 132–144.
[9] A. Gamst and W. Rave, On frequency assignment in mobile automatic telephone systems, in: Proc.
of GLOBECOM ’82 (IEEE, Press, New York, 1982) pp. B3.1.1–B3.1.7.
[10] W.K. Hale, Frequency assignment: Theory and application, Proceedings of IEEE 68 (1980) 1497–
1514.

Z. Xu et al. / Virtually fixed channel assignment

439

[11] D. Hong and S.S. Rappaport, Traffic model and performance analysis for cellular mobile radio
telephone systems with prioritized and nonprioritized handoff procedures, IEEE Transactions on
Vehicular Technology 35(3) (1986) 77–92.
[12] F.J. Jaomes, D. Munoz, C. Monila and H. Tawfik, Modiling resource management in cellular systems
using Petri nets, IEEE Transactions on Vehicular Technology 46(2) (1997) 298–312.
[13] T.J. Kahwa and N.D. Georganas, A hybrid channel assignment scheme in large-scale cellularstructured mobile communication systems, IEEE Transactions on Communications 26(4) (1978)
432–438.
[14] E. Lopez and C. Molina, High level modeling of handoff and channel allocation algorithms for
telecommunications mobile systems, in: Proc. of IEEE Internat. Conf. on Systems, Man and Cybernetics, Vancouver, Canada (1995) pp. 1216–1221.
[15] V.H. MacDonald, Advanced mobile phone service: the cellular concept, Bell Systems Technical
Journal 58 (1979) 15–41.
[16] D. McMillan, Analysis of control strategies for cellular mobile networks, in: 5th Australian Teletraffic Research Seminar (1990).
[17] B.H. Metzger, Spectrum management techniques, in: The 38th National ORSA Meeting, Detroit,
MI (1970).
[18] P.B. Mirchandani and Z. Xu, Channel assignment in mobile telephone, Working Paper #8905,
Information and Decision Science Laboratory, Rensselaer Polytechnic Institute (1989).
[19] S.S. Rappaport and C. Purzynski, Prioritized resource assignment for mobile cellular communication
systems with mixed services and platform types, IEEE Transactions on Vehicular Technology 45(3)
(1996) 443–460.
[20] C. Rose and R.D. Yetes, Near-optimal call admission to single cells of a cellular mobile network,
Winlab. Technical Report TR61 (1993).
[21] M. Sengoku, M. Kurata and Y. Kajitani, Reassignment of switching networks and its application
to a mobile radio communication system, in: Proc. IEEE Internat. Conf. on Circuit and Computer
(1980) pp. 402–405.
[22] R. Shetty, Modeling techniques for a mobile communication system, Master thesis, Electrical,
Computer and System Engineering Department, Rensselaer Polytechnic Institute (1989).
[23] K.N. Sivarajan, R.J. McEliece and J.W. Ketchum, Dynamic channel assignment in cellular ratio,
in: IEEE Transactions on Vehicular Technology Conf. (1990) pp. 631–637.
[24] H. Xie and S. Kuek, Priority handoff analysis, in: IEEE Vehicular Technology Conf. (1993) pp. 855–
858.
[25] Z. Xu and P.B. Mirchandani, An analytical model for virtually fixed channel assignment in cellular mobile radio networks, Technical Report, Systems and Industrial Engineering Department,
University of Arizona (1991).
[26] W. Yue, Analytical methods to calculate the performance of a cellular mobile radio communication
system with hybrid channel assignment, IEEE Transactions on Vehicular Technology 40(2) (1991)
453–460.
[27] Q. Zeng, K. Mukumoto and A. Fukuta, Performance analysis of mobile cellular radio systems with
priority reservation handoff procedures, in: IEEE Vehicular Technology Conf. (1994) pp. 1829–1833.
[28] M. Zhang and T.P. Yum, Comparison of channel-assignment strategies in cellular mobile telephone
systems, IEEE Transactions on Vehicular Technology 38(4) (1991) 211–215.
[29] J.A. Zoellner and C.L. Beall, A breakthrough in spectrum conserving frequency assignment technology, IEEE Transactions on Electromagnetic Compatibility 19(3) (1977) 313–351.

2430

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 17, NO. 9, SEPTEMBER 2016

A New Hardware-in-the-Loop Traffic Signal
Simulation Framework to Bridge Traffic
Signal Research and Practice
Pengfei Li and Pitu B. Mirchandani

Abstract—In this paper, we present a new hardware-in-the-loop
traffic signal simulation framework, which is referred to as
HILS-NG. With this proposed framework, pioneering traffic signal control strategies proposed by researchers can be separated
from traffic simulation engine while interacting with simulations as
independent applications via standard traffic control communication. The advantages of this new framework include the following.
First, pioneering traffic signal logic only needs to be programmed
once for simulation, and the same code can be deployed to the
field with minimal porting efforts. Second, control algorithms are
hosted in supplemental hardened single-board computers (SBCs)
do not require replacing traffic signal controllers in the field;
therefore, the proposed framework will not compromise the existing signal safety protections in signal cabinets, such as phase
conflict monitor. We expect that this new framework will greatly
facilitate the prototyping and field tests of new traffic signal control strategies for scholars and practitioners. To further demonstrate the potential of this new framework, in the second part
of this paper, we utilize an industrial communication standard
for traffic signal controllers in North America, i.e., the National
Transportation Communications for ITS Protocol (NTCIP), to
set up real-time communications with a full-scale traffic signal
emulator in simulation and then develop and evaluate a set of
innovative e signal control strategies. A set of new signal control
strategies is also presented to demonstrate how to design control
functions and the corresponding NTCIP communication stacks.
Index Terms—Traffic simulation, optimization, traffic signal
control, adaptive signal control, signal optimization, NTCIP.

I. I NTRODUCTION

T

HE advancement of traffic signal simulation enables researchers to develop and evaluate innovative signal control
strategies in traffic simulation. In the meantime, many innovative signal control strategies involve unconventional control
logic and must be retrofitted into the control equipment in
the field test. This task requires not only the expertise in
transportation but also in information technology. As a result,
only a small portion of conceptual signal systems were tested

Manuscript received November 12, 2015; accepted January 11, 2016. Date
of publication April 15, 2016; date of current version August 25, 2016. This
work was supported in part by the U.S. Department of Transportation University Transportation Centers under Contract DTRT13-G-UTC55/SubaXward
UNR-14-60. The Associate Editor for this paper was D. Wu.
The authors are with the School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ 85281 USA
(e-mail: pengfeili@asu.edu; pitu@asu.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TITS.2016.2523443

Fig. 1. System architecture of the “HILS-NG” signal simulation platform.

and eventually deployed in the field in the past. To address
this issue, we propose a new hardware-in-the-loop traffic signal
simulation framework to fill the gap between traffic signal
research and signal operations (referred to as HILS-NG hereafter). In the last two decades, numerous efforts have been
dedicated to improving interoperability among various traffic
equipment manufactures. As a direct result, communication
between different brands of traffic signal controllers and traffic
central systems have been standardized. For instance, in North
America, such communication standard is the National Transportation Communications for ITS Protocol or NTCIP [1]. With
this industrial standard, it is possible to manipulate standardcompliant traffic signal controllers with an external program.
In the meantime, some mainstream traffic simulation packages
have also evolved to include advanced traffic signal emulators.
For instance, PTV VISSIM has embedded a fully functional
traffic signal emulator into its latest release which not only emulates functions the hardware traffic signal controllers but also
provides a full-scale NTCIP-compliant communication module
[2]. Based on these new technical developments in traffic
simulation, any new control strategies are programmed into an
independent program residing in supplemental hardened signal
board computers (SBC) aside existing control equipment. Then
SBCs can communicate with traffic signal emulator in VISSIM
through NTCIP. In general, the control program is composed of
two modules, control logic module and communication module.
As in Fig. 1, while VISSIM is running, the control program
in SBC reads the detector and phase statuses from the ASC/3

1524-9050 © 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

LI AND MIRCHANDANI: HILS-NG TO BRIDGE TRAFFIC SIGNAL RESEARCH AND PRACTICE

SILS as well as updates of signal timings. The SBC also writes
back new signal timings to the ASC/3 SILS via NTCIP. Since
the control logic is completely separated from VISSIM and the
communication between the SBC and ASC/3 SILS is purely
based on NTCIP, the control strategies in the same SBC can
be evaluated both with the signal emulators in simulation and
with the hardware NTCIP-compliant signal controllers in the
field. Therefore, it is expected that the HILS-NG simulation
framework will facilitate the deployment of innovative signal
systems in the future.
The rest of this paper is organized as: first, literature on traffic
signal simulation technology is reviewed. Then the HILS-NG
architecture and related technologies are elaborated. Thirdly, as
a demonstration of how to apply the HILS-NG framework to
non-conventional traffic signal control logic designs, we present
a set of non-conventional traffic signal control strategies and
show what control functions could be provided and their corresponding communication objects in the HILS-NG framework.
In the end, the proposed traffic signal control strategies are extensively evaluated with the new signal simulation framework
through a case study.
II. L ITERATURE R EVIEW
There are two concerns in traffic signal simulation including:
the mechanism of data exchange between traffic simulation engine and signal emulators; and the form in which the signal control strategies are realized. As characterized by Stevanovic et al.
[3] and Day et al. [4], the progression of traffic signal simulation
technologies can be divided into four generations:

2431

of Cabinet-in-the-loop (CILS) which essentially uses the whole
traffic signal cabinet as a CID [13]. Liu and his research team
retrieved high-resolution events from traffic signal controller
and signal cabinets to estimate queue length [14], [15]. In
these HILS systems, the data exchange between traffic simulation and signal controllers are based on either NEMA-TS1 or
NEMA-TS2, the standard communication protocols between
signal controllers and signal cabinets [16]. NEMA-TS1-TS2based HILS has both advantages and drawbacks: a major
advantage is that all collections of advanced control functions
in physical signal controllers can be evaluated in simulation
whereas a major drawback is that the simulation speed must
be lowered to one step per second to synchronize with the
on-board clock of signal controllers. With many simulation
scenarios, it often takes very long simulating time.
More recently, Dixon and Islam proposed a new concept of
HILS, called external logic architecture. With the external logic
architecture, the control strategies are hosted in supplemental
microcontrollers and real signal controllers only serve as an
intermediate module to exchange data between traffic simulation and the supplemental microcontrollers via NTCIP [17].
Similarly, Head and his research group developed innovative
multi-modal traffic signal control applications hosted in the
road-side unit of dedicated short-range communication (DSRC)
which issue control demand to traffic signal control via NTCIP
[18]–[20]. A major advantage of the external logic architecture
is that it can provide more flexibility of implementing control
logic other than the limited capacity within the signal controllers. The HILS-NG simulation framework presented in this
paper shares some similarity with the framework of Dixon and
Isam’s work and Head’s work.

A. Emulator-in-the-Loop System (EILS)
Most fine-grained traffic simulation packages include signal
emulators containing basic control functions. Examples include
the signal emulators in CORSIM [5], VISSIM [6], AIMSUN [7]
and TransModeler [8]. Compared to fully functional signal controllers, these signal emulators can meet the basic control needs
while they cannot realize many advanced functions. In addition to the provided signal emulators, some traffic simulation
packages also provide flexible application program interfaces,
or APIs, for users to build customized control emulators. Since
the signal emulators are an integral part of traffic simulation,
users do not need tackle the mechanism of data exchange or
synchronization between signal emulators and traffic simulation.
B. Hardware-in-the-Loop System (HILS)
The objective of HILS is to replace the simplified signal
emulators in traffic simulation with real signal controllers via
controller interface devices (CID). Examples of CIDs include
the NIATT CID II [9] and Naztec CID [10]. In North America,
Bullock and his research group first presented the concept of
HILS using CORSIM in 1998 [11], [12]. Following these earliest efforts, several variants of HILS systems were developed.
One example is that Roelof and Abbas introduced a concept

C. Software-in-the-Loop System (SILS)
The objective of SILS was to overcome the drawbacks of
EILS and HILS. Some early efforts include integrating centralized adaptive signal control systems, such as SCOOT [21]
and SCATS [22], with VISSIM [23]. Nowadays the software
in signal controllers is often modulated and segregated from
hardware for multiple hardware platforms. This design method
makes it possible to integrate real control software with traffic
simulation. A well-known SILS system was developed based on
the ASC/3 control software from Econolite Inc. and VISSIM
from PTV [2]. In this system, the ASC/3 control module is
fully functional and the same as the firmware in real ASC/3
signal controllers. SILS almost overcomes all the aforementioned drawbacks of EILS and HILS and is considered the
latest development of traffic signal simulation. Nonetheless,
because the ASC/3 SILS is a real control software for practice,
it does not provide flexible approach for non-conventional
signal timing designs, creating barriers for researcher to develop innovative control logic. Based on the SILS system,
Stevanovic et al. developed a simulation-based optimization
system [24] and then later optimized traffic signal timing for
over congested traffic conditions [3], [25]. Park et al. designed
and evaluated innovative traffic signal control logic in the SILS
environment [26].

2432

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 17, NO. 9, SEPTEMBER 2016

D. System-in-the-Loop
The system in this context refers to high-level regional
traffic management systems, such as Advanced Traffic Management Systems (ATMS), which includes traffic signal control,
equipment health monitoring and traffic data capturing, etc. In
other words, the scope of system-in-the-loop can be beyond
traffic signal systems. To the authors’ best knowledge, in North
America, there is only one such simulation system reported
to couple a ATMS system with PTV VISSIM in order to
evaluate an adaptive signal control system [4]. While VISSIM
is running, the detector statuses are retrieved from the ASC/3
control software in VISSIM and sent to the ATMS system. The
concept of system-in-the-loop is rather broad and it can be used
not only for traffic signal control but also for many other traffic
managements.
III. S IGNIFICANCE OF THE R ESEARCH
An ideal roadmap to develop innovative signal control strategies may start with designing control logic and then evaluate
in simulation as well as in the field. Eventually, the new signal
control strategies can be built into controller software by traffic
signal manufactures and widely deployed. However, only a
small portion of innovative control strategies can complete
this journey compared to the numerous research efforts. In
practice, the signal manufactures may concern about the risk
of deploying forward-looking control strategies and therefore
they are hesitant to incorporate new control strategies into
their control software before extensively tested in the field.
On the other hand, many innovative control strategies are so
pioneering that they require significant changes to the existing
control framework, discouraging traffic practitioners to accept.
Furthermore, many pioneering signal control strategies involve
intensive computing and optimization and the computing demand will be too high for most mainstream controllers’ CPUs.
In order to promote the development of traffic signal research,
it is important to provide addition computing power for traffic
signal controllers both in simulation and in the field; it will be
also necessary to take into account the current hardware constraints in the existing signal control systems to avoid requiring
fundamental and costly changes.
With the proposed HILS-NG framework, any new control
strategies developed for simulation can be easily and safely
evaluated in the field. As an immediate result, the new framework will facilitate traffic signal researchers to evaluate their
control strategies both in simulation and in the field. In the
meantime, keeping the existing signal controller in the loop will
also guarantee that any innovative control strategies will only
need reasonable changes to the existing signal systems.
IV. HILS-NG T RAFFIC S IGNAL S IMULATION F RAMEWORK
Compared with the other NTCIP-based signal simulation
systems, such as the external logic architecture [17], the new
framework in this paper contains some differences. If a traffic
simulation system is based on hardware signal controllers and
hardware CIDs, it will require at least one hardware signal

controller and CID at each signalized intersection, which may
be prohibitively expensive for those scenarios with many intersections or not even practical due to CID’s limited availability.
In addition, the simulation speed must be slowed down to the
real-world time due to the on-board clock in physical signal
controllers. By contrast, the HILS-NG framework in this paper
utilizes the SILS emulator to play a similar role of hardware
CID and signal controllers. Through using “GET” (read up)
and “SET” (write down) NTCIP messages, it is possible to
retrieve the detector statuses and signal timings as well as
adjust the signal timings in each SILS emulator in a realtime manner. Also, NTCIP data exchange and control logic on
highly-powered SBCs is almost instantaneous on non-sharing
Ethernet and faster than the simulation engine at its maximum
speed. Therefore, HILS-NG can also be used within a fast-pace
simulation environment.
Fig. 1 shows the communication architecture and work flow
of the proposed framework. After VISSIM is launched, all preconfigured SILS emulators will be populated and each SILS
emulator will create a User Datagram Protocol (UDP) server on
the VISSIM host computer. The SBC hosting the new control
strategies will be assigned with a different IP address within the
same subnet as the VISSIM host computer’s. While VISSIM
is running, the SBC continuously communicates with SILS
ASC/3 emulators using NTCIP messages.
In order to capture certain instantaneous events within signal
controllers, such as the detector pulses, the communications
between the SBC and the SILS emulators needs to be short
but frequent. As such, the Simple Transportation Management
Protocol (STMP) is selected over the popular Simple Network
Management Protocol (SNMP) to set up such communications.
STMP is defined in NTCIP 1103 and particularly designed to
meet to the short-but-frequent communication pattern in traffic
signal systems [1]. Each STMP message is built from a userdefined NTCIP object ID (OID) collection, also known as the
dynamic objects. If the SBC and SILS emulators have the same
prior knowledge of the customized dynamic objects such as:
version, MIB collection and SET/GET requests, the STMP
messages can significantly reduce the overhead as required in
the standard SNMP messages. To ensure both communication
sides hold the same prior knowledge, it is necessary to customize the dynamic objects in the SILS emulator first before the
SBC and SILS emulators can exchange STMP messages. For
more details of the STMP configuration, readers are suggested
to refer to DeVoe et al.’s work [27].
After the dynamic objects in the SILS emulators are initialized, the SBC can either retrieve the information of detectors
and phases by sending a STMP “GET” message or modify
the signal timings by sending STMP “SET” messages to the
SILS emulators. The GET-SET process is repeated during the
simulation. After simulation is finished, the users can either
retrieve the measures of effectiveness (MOE) from the traffic
data log files in SBC or retrieve the MOEs summarized in
VISSIM.
After extensive evaluation in VISSIM, the same SBC can
be directly connected to hardware signal controllers in the
field. Like in simulation, the dynamic objects in the real controllers must also be initialized first using the same routine in

LI AND MIRCHANDANI: HILS-NG TO BRIDGE TRAFFIC SIGNAL RESEARCH AND PRACTICE

2433

Fig. 3. Demonstration of the adaptive signal control strategy.
Fig. 2. Detector configuration for the new adaptive control strategies.

A. Periodical Signal Timing Optimization
the SBC and then the SBC can continuously retrieve traffic
data or modify signal timings using STMP “GET” or “SET”
messages. The results can be archived in the SBC for post
processing.

V. D EVELOPMENT OF N ON -C ONVENTIONAL S IGNAL
C ONTROL S TRATEGIES W ITH THE F IELD -R EADY
T RAFFIC S IGNAL S IMULATION F RAMEWORK
In this section, we demonstrate how to develop nonconventional control strategies with the proposed HILS-NG
framework. In addition to the traditional signal control functions design for SBC, the corresponding NTCIP communication stack and dynamic objects between SBC and traffic signal
controllers also need customization to meet the requirements by
any proposed signal control logic.
According to a report published by US Federal Highway
Administration, the evolution of signal control systems can
be divided into four distinct generations [28]: 1. fixed signal
control strategies with pre-stored timing plans; 2. responsive
signal control strategies with automated selecting and loading
of existing timing plans; 3. Periodical adaptive signal control
strategies (ACS) to generate dynamic timing plans according to
the latest aggregated detector data (e.g., in 15 minutes); 4. Continuous adaptive signal control strategies with dynamic timing
plans generated according to high-resolution signal events, such
as detector pulses or phase changes.
The proposed signal control strategy in this paper combines
the advantages of the 3rd and 4th generation of ACS concepts
in the sense that it optimizes the timing plans periodically
according to the latest traffic data whereas it is also capable
of responding to certain high-resolution events within each
cycle, such as platoon identification and accommodation. In
the meantime, the adaptive signal control strategy presented in
this paper is solely based on fixed-spot detectors because the
fixed-spot detectors are still the primary data inputs for most
traffic signal systems today. A typical detector configuration is
illustrated in Fig. 2.
Fig. 3 demonstrates the concept of the new signal control
strategy. The main input is the detector events. The signal
timings are adjusted periodically (e.g., 15 minutes). If an approaching platoon on the mainline is identified and the control
strategy will truncate the current mainline red to accommodate
the platoon.

The signal timings at intersections are optimized and adjusted every 15 minutes. The objective function is based on the
control delay estimation model in the HCM 2010 [29] proposed
by Strong and Rouphail [30] through (1) through (5);

0.5 i=1 (Qi−1 +Qi )ti
(Shared left-through lane group)
d1 =
qC
(1)
2

0.5C 1 − Cg

 (Other types of lane groups)
d1 =
1 − min(1,X)g
C

d2 = 900T (XA − 1) +

d3 =

3,600
vT



8kIXA
(XA − 1)2 +
CA T

(2)

	
(3)




Q2 − Q2e0
Qb + Qe − Qe0
Q2
+ e
− e
(4)
tA
2
2CA
2CA

d = d1 + d2 + d3

(5)

where:
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•

D: total control delay;
d1 : uniform delay;
d2 : incremental delay;
d3 : initial queue delay;
ti : duration of the ith section in the Incremental Queue
Accumulation diagram;
T: analysis period (in hours)
C: cycle length;
g: effective green;
v: traffic volume
Qi : the number of vehicles in Queue after the ith section;
CA : the average capacity based on the saturation rate
1,900 vehicles per hour per lane;
XA : the average v/c ratio;
I: upstream filtering adjustment factor;
Qb : initial queue length (veh);
Qe : queue at the end of the analysis period (veh);
Qe0 : queue at the end of the analysis period when v ≥ CA
and Qb = 0.0 (veh);

Estimate the maximum queue length: assuming no residual
queues, the maximum queue length for each lane group within

2434

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 17, NO. 9, SEPTEMBER 2016

each cycle can be estimated as:
Qmax = vr ∗ r

(6)

where:
• vr is the traffic volume during red; and
• r stands for the red duration;
In order to balance the delays on the main line and minor
approaches, the objective function is designed as follows:


max(D,D2 ,...)
30
(7)
min Dm 1 − e−

Fig. 4. Platoon identification based on mid-block detectors.

B. Platoon Identification and Accommodation

where:
• Dm : the mainline control delay;
• Dt : the control delays on the minor streets;
In (7), the major objective is to minimize the mainline delay
with a discount factor between 0 and 1. If any minor approach
has excessive delay under a particular timing plan, the resulting
discount factor will become close to 1 and therefore the corresponding timing plan will not generate the minimal delays. This
form of objective function will guarantee the solver can consider the mainline delay and minor approach delay together. It
should be noted that maximum green and minimum green constraints (8) on green times will help avoid unrealistic solutions.
The constraints are needed not only to guarantee the ring
structure of NEMA signal controllers but also to guarantee the
maximum queue length estimated with (6) is shorter than the
corresponding link length. Using the standard 8 NEMA phases
are used as the example, the constraints can be expressed as:
⎧
⎪
g1 + g2 = g5 + g6
⎪
⎪
⎪
3
4
7
8
⎪
⎪
⎪g + g = g + g
⎪
⎪
⎪
⎪g 1 + g 2 + g 3 + g 4 + L = C
⎨
Qnmax < ln
⎪
⎪
⎪
g n >g1n + g2n (n = 1, 2, . . . , 8)
⎪
⎪
⎪
⎪
⎪
Gnmin (No ped phase enabled)
⎪
n
⎪

⎪
⎩g > maxGn , Gn + Gn
(Enabled ped phase)
min

walk

Ped_clear

(8)
where:
• L: lost time with each cycle
• ln : the length of approach n in terms of the number of
vehicles;
• g n : effective green on approach n;
• Gnmin : minimum green on approach n;
• Gnwalk : pedestrian walk time on approach n; and
• Gnped_clear : pedestrian clearance on approach n;
A robust open-source solver developed by the Sandia National Laboratories of USA was selected to solve the above
optimization problem, named OPT+plus; [31]. Using an
ARM-9 800 MHz CPU on the SBC, the solver in general gets
a global optimum or a quansi-optimum solution to the above
problems within 1-2 seconds.

Under actuated control mechanism, any unused greens on
side streets are likely returned to the main line in order to
increase the mainline throughput. This phenomenon is referred
as “early return to green” [32]. As a result, the upstream queue
may reach the downstream intersection before the downstream
green starts, increasing the vehicle stops and degrading the
traffic progression. Obviously, the best time to start the downstream green varies from cycle to cycle, depending on when the
upstream queue is released. There is no one single offset value
effective all the time.
If a platoon can be identified in advance by the downstream
intersection, the downstream intersection can either extend the
current mainline green or truncate the mainline red to ensure the
platoon crosses the downstream intersection without stopping.
It is necessary to continuously monitor the traffic, identify
arriving platoons in advance and adjust the downstream signal
timings properly. Therefore, this function belongs to the 4th
generation of signal control systems. Fig. 4 illustrates the
concept of platoon identification and offsets adjustments.
Compared to other headway-based platoon identification algorithms [18], [33], the proposed platoon identification method
in this paper is simplified in that it does not predict vehicles’
arriving time at stop lines and will respond immediately after
an arriving platoon is. The rationale of this simplified method
is that advance detectors are often not placed too far away from
intersections, especially for those closely spaced intersections.
Whenever a platoon is identified, the front vehicle of this
platoon has passed the advance detector 20 seconds and is most
likely close to the downstream intersection and needs immediate reaction. As in Fig. 4, whenever a new vehicle is discovered
by a mid-block pulse detector, the algorithm will look backward
20 seconds. A platoon will be identified if the number of
discovered vehicles per lane in the last 20 seconds is equal to or
greater than 8 (i.e., the average headway in the last 20 seconds
is equal to or less than 2.5 seconds). Chaudhary et al. used
similar thresholds to identify platoons [33].
To accommodate the arriving platoons, whenever an approaching platoon is identified, the control strategy at the downstream intersection will first examine the current mainline phase
status. If it is already green, it means the mainline phase at the
downstream intersection also returns to the green earlier than
schedule within the current cycle and it is likely for the platoon
to cross the next intersection without stopping. If the current

LI AND MIRCHANDANI: HILS-NG TO BRIDGE TRAFFIC SIGNAL RESEARCH AND PRACTICE

2435

TABLE I
C OLLECTION OF NTCIP O BJECTS N ECESSARY
FOR THE P ROPOSED C ONTROL F UNCTIONS

Fig. 5. Platoon accommodation.

mainline phase at the downstream intersection is red, it will be
truncated to ensure the mainline green starts before the platoon
arrives and increase the probability that the platoon crosses
the downstream intersection without stopping. Fig. 5 shows the
concept of platoon accommodation.
When the mainline red needs to be truncated, the current
greens on minor approaches are reduced as:
gi = max(0.5gi0 , Gmin,i + yi + ra )

(9)

where:
•
•
•
•
•

gi : green duration after adjustment;
gi0 : programmed max green duration;
Gmin,i : minimum green of phase i;
yi : yellow time; and
ra : all red clearance;

In case that the current green time on the minor approach
exceeds the reduced green time, the current green will be
terminated immediately.
When a queue spillback, the mid-block loops will be occupied by vehicles for a long time. As a result, the loop’s
presence channel will be constantly on a LOGIC ON while
the counting channel has zero counts (we assume each queue
detectors are accommodated with both presence channel and
count channel). In that case, a queue spillback occurs. If the
green on a minor approach maxed out with the last cycle, or
the corresponding queue detector is currently occupied, this
phase will not be shortened for the platoon accommodation. If
the subject phase gaps out with the last cycle (either under the
programmed maximum green or shortened maximum green),
its programmed green will be shortened to favor the mainline
progression when needed.
C. NTCIP Communication Stack and Dynamic
Objects Design
To accommodate the aforementioned control functions, the
necessary NTCIP objects as summarized in Table I.
1) Periodical Signal Timing Adjustment: The base signal
timing is implemented in the coordination mode. In each coordination pattern, there is a split pattern, cycle length and offset.
Whenever the optimization module in the SBC generates new
timing plans, the communication module in the SBC will send
the new signal timings to the ASC/3 emulator(s) using STMP
“GET” or “SET” messages containing the above OIDs.

2) Platoon Identification: The platoon identification is based
on the high-resolution events of pulse detectors. To capture such
events, it is necessary to continuously poll the corresponding
detector channels. The frequency of such polling must be equal
to or higher than 10 Hz to avoid missing any high-voltage
events.
3) Phase Max-Out Identification: Several OIDs of phase
status should be polled continuously so as to understand the
green usages of each phase. If the actual minor-street green
within a cycle is equal to the programmed values, it means a
max out occurs.
4) Queue Identification: If a queue detector is on LOGIC
ON constantly, it means a queue has spilled back.
5) Platoon Accommodation: Whenever the downstream intersection needs to respond to an approaching platoon, the
control logic will replace the current coordination pattern with
a new coordination pattern with the same cycle length and
offset but different signal timing. The new timing plan will
have shorter greens on the minor streets and longer mainline
green(s) consequently. As a result, the current greens on the
minor approaches will be forced off and the mainline green(s)
will start before the platoon reaches the intersection. After the
current cycle ends, the original coordination pattern will be
restored. Since the cycle length and offsets are not changed,
this method can prevent the controller from the lengthy process
of coordination recovery.
VI. C ASE S TUDY: S IMULATION S TUDY ON THE 124 TH
S TREET C ORRIDOR IN E DMONTON , C ANADA
The aforementioned adaptive signal control logic is also
practicable in the real world. In this section, a simulation-based
case study is conducted to evaluate the potential benefits of

2436

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 17, NO. 9, SEPTEMBER 2016

TABLE II
T URNING M OVEMENT C OUNTS AT THE PM P EAK H OURS

Fig. 7. Link travel time comparison between simulation and the field
observation.

Figs. 7 and 8, the link travel time and the turning movement counts based on individual vehicle records at one major
intersection are highly consistent with the field observation.
Therefore, the simulation model was valid for evaluating the
new control strategy.
B. Performance Evaluation
Fig. 6. Road layout and signal configuration on the 124th street.

the new control strategies. The selected road segment is 3.22
kilometers long with five coordinated intersections on the 124th
Street in Edmonton. The actual signal timings in Fig. 6 were
just optimized with SYNCHRO 7 by the City of Edmonton
according to the turning movement counts as in Table II. As
such, it was assumed that the baseline signal timings shown in
Fig. 6 were optimal and any improvements in traffic mobility
were counted on the new control strategy.
A. Simulation Model Calibration
Simulation models must be well calibrated before evaluation.
Two elements were considered for the calibration: the link
travel time and turning movement counts at the intersections.
The calibration results of all five intersections are very similar and therefore we only show one as an example. From

In order to make the new control strategy fully functional,
it is necessary to place additional mid-block detectors. The
minimal distances from stop lines for the mid-block detectors
on the main line were determined by the distance a vehicle
could travel after it passes the advance detectors. In this case,
the minimal distances were calculated as the 85 percentile
speed [31] multiplied by 20 seconds. As for the mid-block
detectors on the minor approaches, they were placed either right
after the upstream intersections or empirically. The new control
strategy did not optimize the cycle length, programmed offsets
and phasing sequence in this case study.
The simulation model ran 10 times under the baseline signal
timing and the new control strategy respectively. The selected
system MOEs included the link travel time and total stops on
the 124th Street. From Table III, the link travel time and total
stops were both reduced. In other words, the mainline progression was improved under the new control strategy according to
the simulation results.

LI AND MIRCHANDANI: HILS-NG TO BRIDGE TRAFFIC SIGNAL RESEARCH AND PRACTICE

2437

TABLE IV
E VALUATION OF THE N EW C ONTROL S TRATEGY AT I NTERSECTIONS

Fig. 8. Turning movement counts comparison between simulation and the field
observation at the stony plain road.

TABLE III
S YSTEM E VALUATION OF THE N EW C ONTROL S TRATEGY

The performance of the new control strategy was also evaluated at individual intersections. From Table IV, it is clear that
the control delays at all intersections were reduced by 6% to
33%. The intersections at the 118th Avenue and Stony Plain
Road had less reduction of mainline delay and less reduction of
maximum queue length than the other intersections. However,
those two intersections also had low v/c ratios on the other approaches. It means less cycle failures on the other approaches.
Such differences were caused by the platoon identification
and accommodation. After the signal timings were optimized
according to the latest traffic, the control delays and v/c ratios
of each lane group would be optimal and last until the next
time of timing optimization. The new control strategy was
more responsive to the short-term traffic fluctuation compared
with the traditional actuated coordination. Nonetheless, even
though the periodical signal timing optimization can achieve
improvement, the mainline platoons may be still released earlier
than schedule due to the early return to green, degrading the
mainline traffic progression. When a platoon was identified, the
control strategy truncated the greens on the minor approaches.
Although such efforts further reduced the mainline delays and
queue lengths, the remaining queues on the minor approaches
had to wait until the next cycle and the v/c ratios on the minor
approaches were, consequently, increased at the 111 Avenue,
107 Avenue and 102 Avenue.

Lastly, the mainline green durations were also analyzed with
the simulation outputs. The purpose of this analysis is to identify whether the platoon identification function is important.
From the log file saved in SBC, the platoon identification
function was frequently called during the simulation and as
a result, the effective mainline greens at some intersections
were significantly longer than the programmed values as shown
in Table V. Especially when the traffic on side streets is low,
early returns to green on the mainline occurred a lot. Once the
early return to green occurred at one intersections, most the
downstream intersections triggered the platoon accommodation
algorithms within the scope. By contrast, at those intersections
with no platoon identification, the changes were mainly caused
by the periodical signal timing adjustment and they were relatively insignificant. As such, it was concluded that the platoon
identification and responding plays an important role in the new
control strategy.

2438

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 17, NO. 9, SEPTEMBER 2016

TABLE V
E VALUATION OF THE N EW C ONTROL S TRATEGY AT I NTERSECTIONS

VII. C ONCLUSION R EMARK AND F UTURE W ORK
In this paper, a new concept of hardware-in-the-loop traffic
signal simulation framework, referred to as HILS-NG, is presented. The HILS-NG framework extends the current softwarein-the-loop (SILS) and hardware-in-the-loop (HILS) signal
simulation and places the control logic in a hardened single
board computer (SBC). The HILS-NG framework can greatly
bridge traffic signal research and practice because the same host
SBC can be coupled with both simulation and the traffic signal
controller in the field.
Compared to the other signal simulation platforms, the proposed HILS-NG framework in this paper does not require
hardware control interface devices (CID) or hardware signal
controllers. And computing on highly-powered SBCs and data
exchange between SBC and controller (or emulator) are also
suitable for fast-pace simulation environment. In other words,
it addresses two major issues in the hardware-in-the-loop traffic
signal simulation: Expensive equipment requirements and slow
simulation speed. In addition, this framework will not compromise the safety of signal systems because the SBCs are only
supplemental and will not completely replace the existing traffic
controllers.
To demonstrate how to design non-conventional control logic
and how to design the corresponding NTCIP dynamic objects,
a set of adaptive signal control strategies is designed as well
as evaluated in simulation. The new HILS-NG prevents fundamental changes to the existing signal system and can guarantee
safety in the field.
Although in this paper we focus on how to facilitate researchers to try out their signal research efforts in the field, the
proposed HILS-NG framework can go beyond that scope. In
essence, new control logic does not have to always stay with
SBCs in the field. It can also be hosted in a central traffic management system and remotely access traffic signal controllers
in the field via reliable and low-latency network connections.
In that sense, the proposed framework is the same helpful to
practitioners to explore more innovative traffic management
measures in the practice.
ACKNOWLEDGMENT
Any opinions, findings, and conclusions or recommendations
expressed in this material are those of the authors and do
not necessarily reflect the official views or policies of the
above organizations, nor do the contents constitute a standard,
specification, or regulation of these organizations.

R EFERENCES
[1] The National Transportation Communications for ITS Protocol, 2013.
[Online]. Available: http://www.ntcip.org/
[2] “Asc/3 software in the loop controller—asc/3 sil,” Econolite Group, Inc.,
Anaheim, CA, USA, 2013. [Online]. Available: https://www.econolite.
com/files/1214/1384/0766/2014-Product-Suite-Controllers.pdf
[3] A. Stevanovic, A. Abdel-Rahim, M. Zlatkovic, and E. Amin, “Microscopic modeling of traffic signal operations,” Transp. Res. Rec., J. Transp.
Res. Board, vol. 2128, pp. 143–151, 2009.
[4] C. Day et al., “Adaptive signal control performance measures: A systemin-the-loop simulation case study (12-0059),” in Proc. Transp. Res. Board
91st Annu. Meet., Washington, DC, USA, 2012, pp. 1–31.
[5] Corsim:
“
Microscopic traffic simulation model,” McTrans Center,
Gainesville, FL, USA, 2013.
[6] PTV VISION: VISSIM 5. 40-User Manual, PTV Group. Karlsruhe,
Germany, 2013.
[7] Transportation Simulation Systems: Aimsun, 2013.
[8] “Transmodeler traffic simulation software,” Caliper Inc., Newton, MA,
USA, 2013.
[9] L. Zhen, M. Kyte, and B. Johnson, “Hardware-in-the-Loop Real-Time
Simulation Interface Software Design,” in Proc. IEEE 7th Int. Conf. Intell.
Transp. Syst., 2004, pp. 1012–1017.
[10] Naztec
“
ts2 test box,” Naztec Inc., Sugarland, TX, USA, 2013.
[Online]. Available:http://naz.simpleapp2.net/sites/default/files/documents/
manuals/testbox_manual.pdf
[11] D. Bullock and A. Catarella, “A real-time simulation environment for
evaluating traffic signal systems,” Transp. Res. Rec., J. Transp. Res.
Board, vol. 1634, no. 1, pp. 130–135, 1998.
[12] D. Bullock, B. Johnson, R. B. Wells, M. Kyte, and Z. Li, “Hardware-inthe-loop simulation,” Transp. Res. C, Emerging Technol., vol. 12, no. 1,
pp. 73–89, Feb. 2004.
[13] R. Engelbrecht and M. Abbas, A Framework for Hardware-the the-Loop
Traffic Simulation.
[14] H. X. Liu, X. Wu, W. Ma, and H. Hu, “Real-time queue length estimation for congested signalized intersections,” Transp. Res. C, Emerging
Technol., vol. 17, no. 4, pp. 412–427, Aug. 2009.
[15] X. Wu, H. X. Liu, and D. Gettman, “Identification of oversaturated
intersections using high-resolution traffic signal data,” Transp. Res. C,
Emerging Technol., vol. 18, no. 4, pp. 626–638, Aug. 2010.
[16] L. A. Klein, M. K. Mills, and D. R. P. Gibson, Traffic Detector Handbook,
3rd ed., McLean, VA, USA: Turner-Fairbank Highway Res. Center,
DTFH61-03-P00317 FHWA, 2006.
[17] M. Dixon and M. Islam, “An external logic architecturer for implementing
traffic signal system control strategies,” Nat. Inst. Adv. Transp. Technol.,
Univ. Idaho, Moscow, ID, USA, Sep. 2011.
[18] Q. He, K. L. Head, and J. Ding, “PAMSCOD: Platoon-based arterial
multi-modal signal control with online data,” Transp. Res. C, Emerging
Technol., vol. 20, no. 1, pp. 164–184, Feb. 2012.
[19] Q. He, K. L. Head, and J. Ding, “Multi-modal traffic signal control with
priority, signal actuation and coordination,” Transp. Res. C, Emerging
Technol., vol. 46, pp. 65–82, Sep. 2014.
[20] Y. Feng, K. L. Head, S. Khoshmagham, and M. Zamanipour, “A real-time
adaptive signal control in a connected vehicle environment,” Transp. Res.
C, Emerging Technol., vol. 55, pp. 460–473, Jun. 2015.
[21] P. B. Hunt, D. I. Robertson, R. D. Bretherton, and R. I. Winton, Scoot—
A traffic method of coordinating signals, Transp. Road Res., Bershire,
U.K., Lab. Rep. LR 1014, 1981.
[22] A. G. Sims and K. W. Dobinson, “The sydney coordinated adaptive
traffic (scat) system philosophy and benefits,” IEEE Trans. Veh. Technol.,
vol. VT-29, no. 2, pp. 130–137, May 1980.
[23] A. Stevanovic, C. Kergaye, and P. Martin, “Scoot and scats: A closer look
into their operations,” Transp. Res. Board, Washington, DC, USA, Tech.
Rep. 09–1672, 2009.
[24] A. Stevanovic, J. Stevanovic, and P. Martin, “Optimizing signal timings
from the field: VISGAOST and VISSIM-ASC/3 software-in-the-loop simulation,” Transp. Res. Rec., J. Transp. Res. Board, vol. 2128, pp. 114–120,
2009.
[25] A. Stevanovic and P. Martin, “Split-cycle offset optimization technique and
coordinated actuated traffic control evaluated through microsimulation,”
Transp. Res. Rec., J. Transp. Res. Board, vol. 2080, pp. 48–56, 2008.
[26] I. Yun, M. Best, and B. Park, “Evaluation of adaptive maximum feature
in actuated traffic controller: Hardware-in-the-loop simulation,” Transp.
Res. Rec., J. Transp. Res. Board, vol. 2035, pp. 134–140, 2007.
[27] D. DeVoe, S. Giri, and R. Wall, “Distributed ethernet network of advanced
pedestrian signals,” Transp. Res. Rec., J. Transp. Res. Board, vol. 2128,
no. 1, pp. 184–191, 2009.

LI AND MIRCHANDANI: HILS-NG TO BRIDGE TRAFFIC SIGNAL RESEARCH AND PRACTICE

[28] S. Malek, R. Denney, and J. Halkias, “Advanced transportation management technologies participant notebook,” Federal Highway Admin.,
Washington, DC, USA, Tech. Rep. FHWA-SA-97-060, 1997.
[29] Chapter 18: Signalized intersection Highway Capacity Manual, Transp.
Res. Board, Nat. Acad., Washington, DC, USA, 2010, p. 1650.
[30] D. Strong and N. M. Rouphail, “Incorporating effects of traffic signal progression into proposed incremental queue accumulation method,” Transp.
Res. Board, Washington, DC, USA, 2006.
[31] “Opt+plus;: An object-oriented nonlinear optimization library,” Sandia
National Lab., Albuquerque, NM, USA, 2013. [Online]. Available: https://
software.sandia.gov/opt++/
[32] P. Koonce et al., “Traffic signal timing manual,” Federal Highway Admin., U.S. Dept. Transp., Washington, DC, USA, Tech. Rep. FHWAHOP-08-024, Jun. 2008.
[33] N. Chaudhary, M. Abbas, and H. Charara, “Development and field testing
of platoon identification and accommodation system,” Transp. Res. Rec.,
J. Transp. Res. Board, vol. 1978, pp. 141–148, 2006.

Pengfei Li received the Ph.D. degree in civil engineering from Virginia Polytechnic Institute and State
University, Blacksburg, VA, USA, in 2009. Since
2014, he has been with Arizona State University,
Tempe, AZ, USA, where he is currently an Associate
Research Scientist with the School of Computing, Informatics, and Decision Systems Engineering. From
2009 to 2013, he worked with the University of
Kentucky, Lexington, KY, USA, and then with the
University of Alberta, Edmonton, AB, USA, Canada,
as a Research Engineer and a Postdoctorate Fellow,
respectively. His main research interests include traffic signal control, connected vehicles, optimization, traffic network modeling, and network flow
theories.

2439

Pitu B. Mirchandani received the Sc.D. in operations research from Massachusetts Institute of
Technology in 1975. He is currently the AVNET
Chair Professor for Supply Chain and Logistics with
the School of Computing, Informatics and Decision
Systems Engineering, Arizona State University and a
Fellow of INFORMS. He served on the journal editorial boards for IIE Transactions on Scheduling and
Logistics, Transportation Science, Advanced Transportation, Industrial Mathematics, and Transportmetrica. His research interests include optimization,
decision-making under uncertainty, real-time control and logistics, application
interests in urban service systems, transportation, and homeland security.

375

IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, VOL. SMC-2, NO. 3, JULY 1972

An

Auditory

Display in a
Tracking Task

Dual-Axis

PITU B. MIRCHANDANI

Abstract-An auditory display in a dual-axis compensatory tracking
task was studied. Subjects were presented concurrently with the primary
task of controlling a second-order plant and the secondary task of
controlling a first-order plant. The plant errors for the two tasks were
shown on separate visual displays. An auditory display, whose output
varied in frequency and volume with the error, was used to supplement
the secondary task in half of the runs. To study the effects of the auditory
display, two performance measures were obtained: 1) the integral of the
squared error (ISE) and 2) the describing functions of the human
operator.
Statistical analysis of the ISE measures indicated that when the
secondary task was supplemented with an auditory display, there was a
significant improvement in performance on the secondary task. The
performance on the primary task improved on the average, but not
significantly. The variances of the ISE values decreased for both the
tasks, indicating a more consistent behavior with the auditory display.
The describing function analysis showed that supplementing the secondary
task with the auditory display increased the low frequency gain of the
human operator for this task. The describing functions for the primary
task did not show any apparent changes.

INTRODUCTION
ISCUSSION of human tracking performance in
D manual control often conjures in the minds of people
the image of an operator receiving signals via a visual display and responding with appropriate commands via a
hand device. So much so that visual displays have become
an important consideration in manual control theory. However, there are other types of displays that can be used,
such as tactile displays [6] and auditory displays [7]. The
investigation reported here concerns the evaluation of an
auditory display in a manual control system.
Auditory displays have been frequently used for some
purposes. An important and a common use is in neurophysiology. Here a frequency regulating auditory display
is used as an electrode potential monitor; when the potential
at the electrodes changes so does the pitch of an auditory
signal. This allows the examiner to have his eyes free to
observe the movement of the electrode through a microscope in order to place the electrode at an appropriate
location. An earlier application of auditory displays was in
the "four-course range" used in airplane navigation; this
was in common use before the advent of the omnirange.
The pilot was able to guide his plane on one of the four
available courses by aural cues. An on-course trajectory
produced a continuous tone, while off-course trajectories
Manuscript received September 13, 1971; revised February 18, 1972.
This work was supported in part by NASA under Grant NGL-22009-025.
The author is with the Man-Vehicle Laboratory, Department of
Aeronautics and Astronautics, Massachusetts Institute of Technology,
Cambridge, Mass. 02139.

gave different discontinuous aural signals on either side of
the course.
Although there have been several qualitative considerations in the design of auditory displays for specific applications, quantitative investigations of auditory displays have
been few and far between. One of the first major attempts in
the evaluation and application of auditory displays was by
DeFlorez [3], where the possibility of using aural displays
for "blind" flights was investigated. Later, Forbes et al. [5]
reported a more complete study on the same topic. Both
investigations concluded that although auditory displays
could be followed, replacing visual displays with auditory
displays in an airplane would generally produce an inferior
performance. The more recent well-controlled experimental
study of acoustic displays in flight vehicles reported by
Katz et al. [7] also had similar conclusions. In their experiment on aural displays for tracking tasks, they were
not able to show significant improvement in performance
when some of the visual displays were replaced by auditory
displays. Their comparison was based mainly on various
error scores and no attempt was made to evaluate the
changes in human operator dynamics for the two conditions. They also did not examine the possibility of supplementing the visual displays, rather than replacing them,
with auditory displays.
A recent study by Vinje and Pitkin [15] showed the
human operators could perform as well with auditory cues
as with visual cues for single-axis tracking tasks. However,
when the aural and the visual presentations were combined
no improvement in performance was evident for the singleaxis tasks considered. Nevertheless, for multiaxis multitask
situations this result does not necessarily hold. One could
think of several reasons why supplementing existing visual
displays in multicontrol tasks with an auditory mode may
improve the system performance. Some of these are:
1) The eyes have too many visual displays to handle. The
cycle of switching attention from one visual display to
another, accommodating, reading, and performing the appropriate control may take 1 to 2 s in a simple control task
[10]. When there are many displays, the total scanning and
processing time could be several seconds and this substantial amount of time may be critical in some situations.
2) Visual displays could sometimes compete for the attention of the operator and this could lead to a reduction of
effectiveness. For example, in VFR (visual flight rules)
flying conditions, visual displays in the aircraft are used
to complement direct visual contact. However, if the
pilot pays too much attention to any one instrument, a
deterioration in performance may result.

376

IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, JULY

1972

3) Sometimes, the visual processes of the operator are
hampered due to physiological factors and visual displays
lose their effectiveness in such cases. For instance, in a
high g or vibration environment, the visual system is
affected [12] and hence nonvisual displays could be more
effective.
~~~
s
4) Since auditory cues provide another sensory modality,
OSCILLOSCOPE
rS
CHART
the information retrieval rate obtainable from a combined
RECORDER
audio-visual display may exceed that obtainable from a
visual display. Even if the human operator is considered as
a single channel information processor [4], [13], aural cues
could increase the information transmission rate provided
the channel capacity is not already filled [16].
R ECO RIDNER
Consideration of the preceding factors gives one a reason
l COM PUTrE R
l
(PDP -8)
to believe that in a dual-task compensatory system, introduction of a supplementary auditory display may result in
Fig. 1. Experimental setup.
an improved performance. The investigation reported here
concerns the evaluation of a supplementary auditory display
in a dual-task compensatory control system with separated
Both the plants were continuously disturbed by pseudovisual displays. The auditory display is used as a sup- random inputs. The two random inputs had the same
plementary display for the secondary task.
frequency spectrum consisting of a sum of 16 sinusoids but
were presented separately and out of phase. The break
METHOD
frequency of the input was 2.8 rad/s, the 8 high-frequency
Four subjects, all graduate students at M.I.T., were sinusoids being attenuated by 20 dB. The rms displacement
presented with two concurrent tracking tasks. They were of the scope was approximately 0.75 in. A schematic diagram
all right handed and had no hearing or visual defects. They of the experimental setup is presented in Fig. 1. A GPS
had had previous training in similar control tasks and were, analog computer was used for the simulation of the plants
in fact, well motivated operators. The primary task was the and the generation of the auditory display.
control of a second-order plant (with dynamics represented
The display for the secondary task was supplemented
by 1/s2 in the Laplacian notation) and the secondary task with an auditory display when the combined auditory-visual
was the control of a first-order plant (with dynamics repre- display was being tested. The auditory display was a simple
sented by Ils). The position of the primary plant was dis- continuous tone generation. Other types of auditory displayed as a continuous vertical line on an oscilloscope and plays such as discontinuous dichotic signal generation or
the control of the plant was a spring-restrained joy-stick more complex auditory displays could have been considered,
which moved about a horizontal axis in a direction com- but since the motivation of the experiment was to investigate
patible with the display (left-right motion). The oscilloscope whether an auditory display would improve system perwas on the right side of the operator's field of view and the formance, a simple tone generating display was chosen.
control was by his right hand. The display for the secondary
Three types of continuous tone generating displays were
task was a separate oscilloscope, and the state of the plant evaluated in some preliminary experiments, a volume regwas represented by a continuous horizontal line. This was ulating system, a frequency regulating system, and a frecontrolled by another joy-stick which also moved about a quency-volume regulating system. The last display was
horizontal axis in a direction compatible with the display found to be superior in that it gave better performance
(forward-backward motion). This oscilloscope was on the measures (integral of the squared error (ISE) scores). A
left side of the operator's field of view and the control was positive error increased the volume as well as the pitch,
by his left hand. The oscilloscopes had a 5-in diameter. and a negative error increased the volume but decreased
The centers of the displays were approximately 18 in apart the pitch. The null position frequency was 1250 Hz. This
and the subject's eyes were approximately 30 in from the frequency was chosen because normal subjects have a
displays. The decision to use orthogonal control axes which high pitch sensitivity for low volumes at this frequency (see
were in directions compatible with the displays was based Licklider [8]). The frequency range encountered in this
on the results of some preliminary experiments where the experiment was from 500 Hz (for an error -3 cm) to
subjects showed preference for the above arrangement since 2000 Hz (for an error +3 cm). The zero position volume
it seemed to produce less interference and confusion. The was a little above the operator's threshold of hearing and
experimental configuration of having a first-order secondary the maximum volume encountered was below irritation
plant and a second-order primary plant was chosen because level (below 100 dB, ref. 0.0002 dyne/cm2). Further details
it was a dual-axis task of reasonable difficulty requiring of the auditory display and the experiment are available
skill and training and because the primary task display in [l1].
could be identified with the heading indicator in an aircraft
The subjects were asked to keep both the plants at null
and the secondary task display with the artificial horizon.
position and were told that their primary concern was the

377

MIRCHANDANI: AUDITORY DISPLAY IN TRACKING TASK

TABLE I
ORDER OF TESTING FOR EACH SUBJECT (SEPARATION INTO BOXES IN EACH
Row INDICATES DIFFERENT DAYS)
Run No. .

1

2

3

4

5

6

7

8

9

10

TABLE II
MEANS AND VARIANCES OF ISE SCORES AND t VALUES BETWEEN MEANS
FOR EACH SUBJECT FOR PRIMARY TASK
FOR THE PRIMARY TASK

SUBJECT

Subject 4
DM

N

N

A

A

A

A

N

N

A

N

co

N

A

A

N

N

N

A

A

N

A

NV

A

N

A

A

N

N

N

A

A

N

MG

A

A

N

N

A

N

N

A

N

A

DM

WITHOUT AUDIO

MEAN VARIANCE
13.64

6.89

WITH AUDIO

MEAN VARIANCE
14.90

4.55

t

SIGNIFICANCE
LEVEL

-0.83

NS

Co

9.44

13.29

3.92

5.93

2.82

.05

NV

4.10

12.80

3.40

4.68

0.38

NS

MG

6.90

11.30

5.20

1.70

1.06

NS

N indicates the condition without audio display
A indicates the condition with audio display

control of the second-order plant (the primary task). Prior
to each run, the subjects were told whether or not the
secondary task was supplemented with the auditory display.
Before taking actual data, the subjects were trained until
they became quite skillful in these particular tasks as evident
from nearly constant performance measures (the ISE
scores). Each run lasted 128 s. Before each run the subjects
were given 2 min warmup practice. Each subject had 10
runs, 5 runs with visual display only, and 5 runs with the
combined auditory-visual display. The runs were presented
in random order. Each subject had at least two days of data
taking runs separated by at least a week. This minimized
learning effects. The order of the runs is given in Table I.
Two types of performance measures were obtained. One
was the ISE; a lower ISE score indicates a better performance. The other performance measure was the measure of
the describing function of the human operator. The describing functions were obtained by a fast Fourier transform
technique [1] using the Man-Vehicle Laboratory hybrid
computer facility at M.I.T. Details of the method are available in [14]. The describing functions were not corrected for
the remnant because the exact representation of the -human
operator dynamics was not required but only the approximate changes in the dynamical characteristics when
the secondary task was supplemented with the auditory
display. However, some Fourier transforms were examined
to get an idea of the power of the remnant at various
frequencies. The remnant was small at low frequencies
(below I rad/s), but at higher frequencies the power of the
remnant was comparable to the linear portion of the
operator output.
RESULTS AND DISCUSSION
Analysis of ISE Performance Measures
The means and the variances of the ISE values for each
plant and for each subject were calculated for the two

conditions (with audio display and without audio display).
The results are presented in Tables II and III. It can be
noted that except for one subject, the means of the ISE
scores decreased (that is, the performance improved) for
both the primary and the secondary task when the latter
was supplemented with an auditory display. Calculations

TABLE III
MEANS AND VARIANCES OF ISE SCORES AND t VALUES BETWEEN MEANS
FOR EACH SUBJECT FOR SECONDARY TASK
FOR THE SECONDARY TASK
SUBJECT

WITHOUT AUDIO

MEAN VARIANCE

WITH AUDIO

MEAN VARIANCE

t

SIGNIFICANCE
.02

LEVEL

DM

13.24

52.71

3.38

1.66

2.99

Co

13.90

23.30

3.54

3.48

4.48

.01

NV

8.72

34.55

5.30

2.20

1.26

NS

MG

13.00

49.00

5.20

5.70

2.36

.05

show that the average percentage decrease in the ISE value
of the primary task was 23 percent and the average decrease
for the secondary task was 62 percent. Student t test performed on the means indicates that the change in the mean
of the ISE value of the primary task was significant at the
0.05 level for only one of the four subjects while, at the same
level of significance, three of the four subjects showed an
improvement in performance on the secondary task.
Another important observation made from Tables II
and III is that in all cases the variance of the ISE scores
decreased when the secondary task was supplemented with
an auditory display. This would imply that the subjects
tended to be more consistent when they continuously received aural information on the state of the secondary
control system.
Two more statistical tests were performed on the ISE
measures, the t test for correlated means [2], and the
analysis of variance [2]. Since the performance on each
test depends on the subject, the samples for the analysis are
not independent. In other words, for each subject, the means
for the two conditions are correlated. Hence, to see whether
the two tested conditions, with audio display and without
audio display, differ significantly in performance on the
average, the t test for correlated means was used. This test
entails the comparison of the differences between the two
conditions. The test showed that when the secondary task
was supplemented with an auditory display there was no
significant change in the performance on the primary task
but there was an improvement in performance on the
secondary task at a 0.02 level of significance.
Finally, to consider the effects of both, the subjects and
the interaction between the subjects and the conditions, an
analysis of variance (or the F test) was performed on the

378

IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, JULY

TABLE IV
RESUL1rS OF ANALYSIS OF VARIANCE
RESULTS OF ANALYSIS 0O

SS,

DF2
MS3
F62'
17.723 DF27MS3
1 27.723 3.62S

INTERACTION
WITHIN COMBINATIONS
TOTAL

F

27.723

BETWEEN CONDITIONS

BETWEEN SUBJECTS

--

IF VARIANCE FOR THE PRIMARY TASK

625.297
60.874
244.570

3
3
32

958. 4 64

39

208.432
20.291
7.65

1.376
27.25
2.66

SL
.1
NS
.001
.1

RESULTS OF ANALYSIS OfF VARIANCE FOR THE SECONDARY TASK

BETWEEN CONDITIONS

BETWEEN SUBJECTS
INTERACTION

WITHIN COMBI[NATIONS
TOTAL

SS

DF

MS

617.796

1

617.796

24.797
74.917
!690.420
1'407.930
sc fuares

3
3

8.266
24.972
21.580

32

F

SL

28.605

.001

.38
1.16

NS
NS

24.75' .02

39

l SS denotes sum of
DF denotes degrees c

2

af freedom

MS denotes mean squa

4

ance level obtained from F-tables
onditions are considered fixed effects
when conditions are considered fixed effects and subjects
are considered randcom effects
SL denotes significa

when subjects and cc

ISE scores. The anal:ysis was a two-way analysis of variance
with five observationIs per combination, the two parameter
groups being subjecits and conditions and each run constituting an observa tion. The results of the analysis of
variance are presente d in Table IV.
The results of the analysis of variance on primary task
performance show thLat the differences between the subjects
were

highly significaint. The results also show that for the

four subjects tested, the improvement in performance when
the secondary task was supplemented with the auditory

display

was

significaint at the 0.1 Ilevel. However, using the

"mixed effects" mod[el [2], the difference between the two
conditions was not s;ignificant for general population. The
0.1 level of significaince for the interaction between the
subjects and the con ditions probably reflects the fact that
for subject CO the auditory display improved the performance significant ly while it did not change the performance significantlly for the other subjects (see Table I).
From the results of the analysis of variance on the
secondary task it ca n be seen that there is no significant
difference between tihe subjects. The improvement in performance when the s;econdary task was supplemented with
the auditory display was significant at the 0.001 level for
the four subjects teste d. However, for the general population
the improvement in Iperformance was significant at the 0.02
level. The results of the analysis show that the interaction
between the conditioins and the subjects was negligible.

1972

Describing Function Analysis
The means and variances of the data points which construct the describing functions of the human operator were
plotted on a single graph for each subject. Differences in
the describing functions for the two conditions were apparent only in the describing functions for the secondary
task. The describing functions for the primary task did not
seem to be different for the two conditions. The amplitude
ratio plots and the phase angle plots of the describing
functions are presented in Figs. 2-5.
It can be seen from the amplitude ratio plots of the
describing functions of each subject that the low frequency
gain of the human operator for the secondary task is increased with the addition of an aural cue. Table V lists the
approximate gains of the describing function for the secondary task, for frequencies less than 1 rad/s. It can be seen
from the table that the minimum increase of gain at low
frequencies was 5 dB and the average increase was approximately 6 dB. The gains at higher frequencies are not
included because they did not seem to indicate a constant
difference between the two conditions. Also, the large
remnant at higher frequencies make this part of the plots
at the higher frequencies less representative of the human
operator.
The first-order lead with corner frequency close to I rad/s
on the amplitude ratio plots of the describing functions is
probably due to the high-frequency remnant. This is because
in this experimental method of obtaining the describing
functions, the large remnant at high frequencies results in
the superposition of the plant under control at those
frequencies.
Considering the theory of human operator dynamics [9],
one would tend to think that since the operator functions
as a "good" servo system, an increase in gain would have
to be accompanied by an increase in lead, otherwise instability or very low phase margin may result. The phase
angle plots of the describing functions do seem to indicate
a tendency for a decrease in phase lag at the higher frequencies when the secondary task is supplemented with an
auditory display. However, because of intrasubject variability and the fact that the observed differences are small
the phase angle plots show considerable overlap at the
higher frequencies. To obtain statistical significance for the
differences between the phase angle plots for the two
conditions considerable more data would be required.
There could also be a decrease in human operator time
delay due to the fact that the operator does not have to
shift his scan to the visual display of the secondary task
before taking an action; as soon as the aural signal is heard
the operator takes an appropriate action while he is shifting
his scan to the visual display (if he has to). Some subjects
did indicate that they concentrated less on the secondary
task visual display when the auditory display was present.
However, from the insufficient high frequency data of this
experiment and without accurate model fitting, one is unable
to show whether or not there is a decrease in the effective
time delay for the human operator dynamics when the
secondary task is supplemented with an auditory display.

379

MIRCHANDANI: AUDITORY DISPLAY IN TRACKING TASK
M.]f

,

20

lTl

10

0

_

Amplitud
Ratio

(decibels)

(decibels)

r

i With audio display
iWithout audio display
(Bars indicate ± std. dev.)

0

30

30)

60

i tt

if

II

0 - Amplitude
Rotio

i With audio display
i Without audio display
(Bars indicate t std. devJ)

0

t

T;

Phase A

(dFgre n
(radians /second)
_Frequency
90
[|1 II
Ill

60

q+
- Isi

901

r
r-

..

Phase Arngle

)
(degreesn

Frequency (rodions/second)
0.1

Fig. 2. Describing functions for secondary task-subject DM.

Fig. 3. Describing functions for secondary task-subject CO.

0.1

Fig. 4. Describing functions for secondary task-subject NV.
TABLE V
APPROXIMATE GAIN (IN DB) OF SUBJECTS' DESCRIBING FUNCTIONS FOR
SECONDARY TASK, AT FREQUENCY LESS THAN 1 RAD/S
WITHOUT AUDIO

WITH AUDIO

DIFFERENCE

DM

4

10

6

CO

5

13

NV

7

12

5

7

13

6

SUBJECT

Fig. 5. Describing functions for secondary task-subject MG.
average percentage

decrease in the ISE value of the

secon-

dary task being 62 percent.
3) For the four subjects tested, there seemed to be an
improvement in the performance of the primary task, but
only at a significance level of 0.1, the average percentage
decrease in the ISE value of the primary task being 23
percent.

4) The improvement in performance of the secondary
task was significant at the 0.02 level for the general
population.
5) The differences in the performance on the primary
Further research in this direction, using more data and task were not significant for the general population.
obtaining accurate model-fits to investigate the effects of
6) The quasilinear dynamical representation of the human
auditory displays on effective time delay, may be worth- operator showed an increase in low frequency gain in keepwhile.
ing with the error reduction considerations from basic
control theory.
SUMMARY AND CONCLUSIONS
These results indicate that the performance on multiaxis
Summarizing the important results of the investigation, control systems involving separated displays which require
it was found that when the secondary task of a dual task considerable operator training, would probably be imcompensatory system was supplemented with an auditory proved when one or more of the secondary tasks are supdisplay.
plemented with an auditory display. These findings could
1) The variance in the performance decreased for both have a significant effect in present manual control systems.
tasks, indicating a more consistent behavior.
It is conceivable that supplementary auditory displays in
2) For the four subjects tested, the performance of the existing systems, such as, in airplanes (especially helicopters
secondary task improved at a significant level of 0.001, the and VTOL), in space maneuvers, in real time command

380

IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, VOL.

and control systems, in monitoring systems, in dark environments, and in situations where the visual processes of
the operator are hampered due to physiological factors,
could improve the performance of the operators and make
the systems more efficient. Further research in this area is
necessary, in order to utilize the full capacity of the human
operator in processing peripheral information via the
auditory system.
ACKNOWLEDGMENT
The author wishes to thank Prof L. R. Young, Prof.
R. E. Curry, J. Allum, and C. Oman of the Man-Vehicle
Laboratory at M.I.T. for their helpful suggestions and
comments.
REFERENCES
[1] G. D. Bergland, "A guided tour of the fast Fourier transform,"
IEEE Spectrum, vol. 6, pp. 41-52, July 1969.
[2] A. H. Bowker and G. J. Lieberman, Engineering Statistics.
Englewood Cliffs, N.J.: Prentice-Hall, 1964.
[3] L. DeFlorez, "True blind flight," J. Aeronaut. Sci., vol. 3, Mar.
1936.
[4] J. I. Elkind and L. T. Sprague, "Transmission of information in
simple manual control systems," IRE Trans. Hum. Factors Electron. (Commun.), vol. HFE-2, pp. 58-60, Mar. 1961.
[5] T. W. Forbes, W. R. Garner, and J. G. Howard, "Flying by
auditory reference ("Flybar")," Office of Sci. Res., Dev. Nat.
Defense Res. Comm., OSRD Rep. 5123, June 1945.

Associatron-

SMC-2,

NO.

3, JULY 1972

[6] J. Hirsch, "Rate control in man-machine systems," Biomed.
Hum. Factors Div. ASME, ASME Winter Annu. Meet., Los
Angeles, Calif., Nov. 1969.
[7] D. Katz, J. A. Emery, R. A. Gabriel, and A. A. Burrows, "Experimental study of acoustic displays of flight parameters in a
simulated aerospace vehicle," NASA, Washington, D.C., NASA
CR-509, July 1966.
[8] J. C. R. Licklider, "Basic correlates of the auditory stimulus," in
Handbook of Experimental Psychology, S. S. Stevens, Ed. New
York: Wiley, 1951.
[9] D. T. McRuer, D. Graham, E. S. Krendal, and W. Reisener, Jr.,
"Human pilot dynamics in compensatory systems: theory,
models, and experiments with controlled element and forcing
function variations," Wright-Patterson AFB, Ohio, AFFDL-TR65-15, July 1965.
[10] R. Massa and R. Keston, "Minimum attention display techniques," Navigat. J. Inst. Navigat., vol. 12, no. 2, Summer 1965.
[11] P. B. Mirchandani, "Evaluation of a supplementary auditory
display in a dual-axis compensatory tracking task," M.S. thesis,
Massachusetts Inst. Technol., Cambridge, June 1971.
[12] E. M. Roth, Ed., "Compendium of human responses to the
aerospace environment," vol. II, NASA, Washington, D.C.,
NASA CR-1205(II), Nov. 1968.
[13] J. W. Senders, "The human operator as a monitor and controller
of multidegree of freedom systems," IEEE Trans. Hum. Factors
Electron., vol. HFE-5, pp. 2-5, Sept. 1964.
[14] N. A. J. Van Houtte, "Display instrumentation for V/STOL
aircraft in landing, vol. III," Sc.D. dissertation, Massachusetts
Inst. Technol., Cambridge, 1970.
[15] E. W. Vinje and E. T. Pitkin, "Human operator for aural compensatory tracking," in Proc. Seventh Annu. NASA-AF-Univ.
Conf. on Manual Control, Univ. Southern California, Los
Angeles, June 1971.
[16] T. E. Wempe and D. L. Baty, "Human information processing
rates during certain multiaxis tracking tasks with a concurrent
auditory task," IEEE Trans. Man-Machine Syst., vol. MMS-9,
pp. 129-138, Dec. 1968.

A Model of Associative Memory
KAORU NAKANO

Abstract-Thinking in the human brain greatly depends upon association mechanisms which can be utilized in machine intelligence. An
associative memory device, called "Associatron," is proposed. The
Associatron stores entities represented by bit patterns in a distributed
manner and recalls the whole of any entity from a part of it. If the part is
large, the recalled entity will be accurate; on the other hand, if the part is
small, the recalled entity will be rather ambiguous. Any number of
entities can be stored, but the accuracy of the recalled entity decreases
as the number of entities increases.
The Associatron is considered to be a simplified model of the neural
network and can be constructed as a cellular structure, where each cell is
connected to only its neighbor cells and all cells run in parallel. From its
mechanisms some properties are derived that are expected to be utilized
for human-like information processing. After these properties have been
analyzed, an Associatron which deals with entities composed of less than
180 bits is simulated by a computer. Simple examples of its applications
for concept formation and game playing are presented and the thinking
process by the sequence of associations is described.

I. INTRODUCTION
'THE PURPOSE of this paper is to outline an approach
for simulating certain functions of the human brain.
It has been known that an association mechanism is
essential to information processing in the human brain.
Association in the human brain has been studied mainly
in the field of psychology. Quite a few semantic models for
association have been presented in the past few years.
Now biological studies are beginning gradually to reveal
the structure of the nervous system, but our present knowledge is still not sufficient to construct the structure artificially, although models of nerve cells have been presented

[1], [2].

In this situation, it will be important, from the viewpoint
of artificial intelligence, to construct a machine with
homogeneous structure where the microscopic behavior of
its
components gather to form the macroscopic behavior
Manuscript received January 11, 1971; revised July 5, 1971 and
February 21, 1972. This work was supported by the Science and such as pattern recognition, concept formation, game playTechnology Agency of Japan.
ing, etc. Perceptron [3] and Adaline [4] have this property
The author is with the Faculty of Engineering, University of Tokyo,
to some extent, although they do not provide the functions
Tokyo, Japan.

Optim Lett (2014) 8:2245–2259
DOI 10.1007/s11590-014-0731-0
ORIGINAL PAPER

Computational complexity analysis of the sensor
location flow observability problem
Monica Gentili · Pitu Mirchandani

Received: 18 February 2013 / Accepted: 4 February 2014 / Published online: 2 March 2014
© Springer-Verlag Berlin Heidelberg 2014

Abstract The sensor location flow observability problem is studied from the computational complexity point of view. Although the general problem is shown to be
NP-complete, by studying the special cases of input matrix structures and data where
the corresponding problems are polynomially solvable, the boundary between NPcomplete and polynomial solvable problems is delineated.
Keywords

Computational complexity · Sensor location · Traffic network

1 The sensor location flow observability problem on traffic networks
Consider the network of Fig. 1 with six nodes and eight arcs and let a set of five
routes be defined on the network (these are listed in the left-most column of Table 1
as subsets of arcs). Suppose we can locate either path-ID sensors or counting sensors
on the arcs of the network, and our aim is to find flow volumes on each route in the
network. When we locate a path-ID sensor on a link we assume that one is able to
know the flow volume on each route that uses the link [15]. For example, by locating
a path-ID sensor on link a3 we can observe: f Y1 = 30, f Y2 = 20, f Y3 = 10, where
f Yi is the flow volume on route Yi . That is, we obtain three simple linear equations,
in this case defining our “observations” of three of the five unknown variables f Yi ,

M. Gentili (B)
Department of Mathematics, University of Salerno,
Via Giovanni Paolo II n. 132, 84084 Fisciano (SA), Italy
e-mail: mgentili@unisa.it
P. Mirchandani
School of Computing, Informatics and Decision Systems Engineering,
Arizona State University, Tempe, AZ, USA
e-mail: pitu@asu.edu

123

2246

M. Gentili, P. Mirchandani

i = 1, . . . , 5. On the other hand, when we locate a counting sensor on a link of the
network we can observe only the total flow on that link and express it as the sum of
the flows of the routes that use the link. For example, if we locate a counting sensor
on link a3 and count 60 vehicles per unit time we obtain the following single linear
equation: f Y1 + f Y2 + f Y3 = 60.
By selecting different sensors to be located on the arcs, we obtain different systems
of linear equations. The sensor location flow observability problem is to find the
location of the minimum number of sensors, located on the arcs of the network, so that
the resulting system of equations has a unique solution and hence all the route flow
volumes can be observed. Let the coefficient matrix L be the coefficient matrix of the
system of linear equations that is obtained by the union of all the possible equations
associated with all the path-ID sensors and all counting sensors that can be located on
our example network. The resulting matrix is the following:
⎛
(s1 : path − I D on a1 )
(s2 : path − I D on a2 ) ⎜
⎜
(s3 : path − I D on a3 ) ⎜
⎜

⎜
⎜

⎜
⎜
(s4 : path − I D on a4 ) ⎜
⎜

⎜
⎜
(s5 : path − I D on a5 ) ⎜
⎜

⎜
⎜
(s6 : path − I D on a6 ) ⎜
⎜

⎜
⎜

⎜
⎜
(s7 : path − I D on a7 ) ⎜
⎜

⎜
⎜
(s8 : path − I D on a8 ) ⎜
⎜
(s9 : counting on a1 ) ⎜
⎜
(s10 : counting on a2 ) ⎜
⎜
(s11 : counting on a3 ) ⎜
⎜
(s12 : counting on a4 ) ⎜
⎜
(s13 : counting on a5 ) ⎜
⎜
(s14 : counting on a6 ) ⎜
⎜
(s15 : counting on a7 ) ⎝
(s16 : counting on a8 )

f Y1
0
0
1
0
0
1
0
1
0
0
0
0
0
0
0
0
0
1
1
1
0
0
0

f Y2
0
0
0
1
0
0
0
0
0
1
0
0
1
0
0
0
0
1
0
0
1
1
0

f Y3 f Y4
1
0
0
1
0
0
0
0
1
0
0
0
1
0
0
0
1
0
0
0
0
1
0
0
0
0
0
1
0
0
1
0
0
1
1
0
1
0
1
0
0
1
0
1
0
0

f Y5
⎞
0
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
1⎟
⎟
0⎟
⎟
0⎟
⎟
1⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
0⎟
⎟
1⎟
⎟
0⎠
1

Let R be the set of rows of matrix L and let us denote by L h ∈ R, h = 1, 2, . . . , the
hth row of matrix L. Assign to each row L h a different colorc(L h ) = i corresponding
to the sensor si with which it is associated and let c(S) = L h ∈S c(L h ) be the set of
different colors in the subset S ⊆ R of rows. Each location of a set of k sensors on the
network corresponds to the selection of a subset S of rows of L such that |c(S)| = k.
Looking for the minimum number of sensors to be located on the arcs of the network
so that the resulting associated system of equations has a unique solution corresponds

123

Sensor location flow observability problem

2247

Fig. 1 A network example

Table 1 Routes, route flows
and arc flows related to the
network in Fig. 1

Routes Yi

Route flows f Yi

Y1

a3

a4

a5

Y2

a3

a6

a7

Y3

a1

a3

a4

Y4

a2

a6

a7

30
20
a5

10
40

Y5

a6

a8

Arcs

a1

a2

a3

a4

a5

a6

a7

a8

Link flows

10

40

60

40

40

90

60

30

30

to determining a submatrix of L of full rank with the minimum number of different
colors.
Returning to the general case of the sensor location flow observability problem, let
L be a 0–1 (q × p) matrix (q > p) with rank(L) = p, C be a set of colors, and R be
the set of rows of matrix L. Let c(L h ) = i denote the color assigned to row L h ∈ R
of matrix L and L S be the submatrix of L composed of the rows S ⊆ R. Let k be a
positive integer. We consider the two following problems:
Problem P1
Does there exist a set S ⊆ R of linearly independent rows of matrix L such that (1)
the corresponding submatrix L S has rank(L S ) = rank(L) and (2) |c(S)| ≤ k (i.e.
the number of different colors assigned to the rows in S is less than or equal to k)?
Let S0 be a subset of linearly independent rows of L.
Problem P2
Does there exist a set S ⊆ R\S0 of linearly independent rows of matrix L such
that (1) the submatrix L S0 ∪S has rank(L S0 ∪S ) = rank(L) and (2) |c(S)| ≤ k (i.e. the
number of different colors assigned to the rows in S is less than or equal to k)?
Both the problems have been defined in [15] as the sensor location flow observability
problem and the extended sensor location flow observability problem, respectively.
The latter problem relates to the case when some sensors, corresponding to S0 are
already located. The authors in [15] showed that several combinatorial optimization
problems in the literature on optimally locating sensors on a traffic network to observe
all flow volumes in the network [1,2,5,6,9,12–14,19] are special instances of the

123

2248

M. Gentili, P. Mirchandani

Table 2 Some possible configurations of types of sensors, a-priori parameters and flows of interest that
determine set of equations as particular cases of problem P1 or P2
Configurations

Sensor type

A-priori parameters

Flows of interest

Case A

Counting on arcs

Arc choice proportions

OD flows

Case B

Counting on nodes

Arc choice proportions

OD flows

Case C

Counting on arcs

Arc/route coefficients

Route flows

Case D

Counting on nodes

Arc/route coefficients

Route flows

Case E

Counting on arcs

Split ratios

Arc flows

Case F

Counting on nodes

Split ratios

Arc flows

Case G

Counting on arcs

Link/route coefficients

Arc flows

Case H

Path-ID on arcs

Arc/route coefficients

Route flows

Case I

Images on nodes

Arc/route coefficients

Route flows

Case L

Vehicle-ID on arcs

Arc/route coefficients

Route flows

above problems according to the special structure of the underlying matrix L. Each
of the contributions in the literature addresses a special case of the problem; however,
the computational complexity boundary of the general problem, when considering
various structures of matrix L, has not been studied. This is the aim of this paper.
The location problems studied in the literature differ according to the three following elements: (1) sensor types to be located on the network (e.g., counting sensors,
image sensors, automatic vehicle identification readers), (2) available a-priori information, (3) flows of interest [e.g., origin-destination (OD) flows, route flows, arc flows].
Different combinations of these elements determine a different problem, that however, corresponds to a particular case of either problem P1 or problem P2. Table 2
shows particular cases that have been addressed in the literature (for a more detailed
description of the problem and of its special cases, the reader can refer to [15]).
Section 2 gives two alternative mathematical formulations of the problem, discussing the relationships with well-known combinatorial problems in the literature.
Analysis of special cases of the problem and of their computational complexity is the
object of Sect. 3.
2 Mathematical formulations
Problems P1 and P2 can be formulated either as the minimization of a submodular
function over the basis of a matroid [formulations (P1) and (P2) to follow] or as
the minimization of a linear function subject to submodular constraints [formulations
(P1.B) and (P2.B) to follow]. Before introducing the mathematical formulation, we
need to recall some properties and definitions about matroid theory and submodular
functions. For additional notations we refer to [17,22].
Let E be a finite set. A matroid M = (E, I) on E is a collection I of subsets of E
satisfying the following properties:
(i) if S ∈ I, T ⊂ S, then T ∈ I;
(ii) if S, T ∈ I, |S| = |T | + 1, there exists an element e ∈ S\T such that T ∪ {e} ∈ I.

123

Sensor location flow observability problem

2249

A member of I is an independent set. A subset of E which is not a member of I is a
dependent set. A maximal independent set is a basis. A rank function r (T ), T ⊆ E,
is associated with a matroid M:
r (T ) = max{|S| : S ∈ I} T ⊆ N
S⊆T

to denote the size of a maximum cardinality independence set in T . A basis is a
maximal independent set T ⊆ N and r (T ) = r (E). We recall now, two classes of
matroids that are useful for our analysis.
1. Matric matroids
Let A be an n × m matrix, and let N be the index set of the columns of A. Define the
independence system (N , I) by F ∈ I if the set of columns defined by F is linearly
independent. For any submatrix A T with columns A j for j ∈ T , every maximal set
of linearly independent columns contains r (T ) = rank(A T ) columns. (N , I) is a
matroid and is a matric matroid.
2. Partition matroids

m
Given m disjoint finite sets E i for i ∈ I = {1, 2, . . . , m}, let E = i=1
E i . F ⊆ E is
independent if |F ∩ E i | ≤ 1 for all i	∈ I . For any T ⊆ E, the cardinality of a maximal
independent set contained in T is i∈I δi , where δi = 1 if T ∩ E i 	= ∅ and δi = 0
otherwise. The independence set (E, I) is a partition matroid.
The rank function of a matroid belongs to the more general class of submodular
functions. Let E be a finite set, and let f be a real-valued function on the subsets of
E.
Definition 1 f is submodular if
f (S) + f (T ) ≥ f (S ∪ T ) − f (S ∪ T ) S ⊆ E
Definition 2 f submodular is nondecreasing if
f (S) ≤ f (T ) S ⊆ T ⊆ E
A rank function of a matroid is a submodular and nondecreasing function.
We are ready now to formulate our problems.
Let us consider the partition {Ri ⊆ R : c(L h ) = i, L h ∈ R, i ∈ C} of the row set
R induced by the color function c : R → C defined on the rows. We can define then,
the following two matroids on the row set R: (1) the partition matroid M1 = (R, F1 )
with partition sets {Ri }i∈C and rank function m 1 (S), S ⊆ R; (2) the matric matroid
M2 = (R, F2 ) with rank function m 2 (S), S ⊆ R. To keep notation simple, in the sequel
we denote with P1 and P2 the optimization versions of the problems, respectively.
Problem P1 can be formulated as finding a subset S ⊆ R that minimizes the rank
function of matroid M1 and contains a basis of matroid M2 :
[P1] min{m 1 (S) : m 2 (S) ≥ m 2 (R), S ⊆ R}.

123

2250

M. Gentili, P. Mirchandani

Note that, when S is a basis of M2 the inequality m 2 (S) ≥ m 2 (R) dominates inequalities m 2 (S  ) ≥ m 2 (R), for each S  ⊇ S. Since m 1 (S) is a non-decreasing function, we
can restrict the feasible set of solutions to be the clutter of the basis of matroid M2 :
[P1.A] min{m 1 (S) : m 2 (S) ≥ m 2 (R) and m 2 (S) ≥ |S|, S ⊆ R}.
An alternative mathematical formulation can be obtained by considering the following
function:







Ri = max |S| : S ∈ F2 , S ⊆
Ri , B ⊆ C .
f (B) = m 2
i∈B

i∈B

f (B)
 is the rank of the maximal independent set of the matric matroid M2 contained
in i∈B Ri . Note that this function is submodular as proven in [21] and f (C) =
m 2 ( i∈C Ri ) = m 2 (C). In this case, we want to choose a minimum number of sets
of the partition {Ri }i∈C such that the union of the elements of the sets contains a basis
of matroid M2 . Thus, another formulation for P1 is:
[P1.B] min{|B| : f (B) = f (C), B ⊆ C}.
Formulations [P1] and [P1.B] are equivalent as per the following Lemma, whose
proof is omitted.
Lemma 1 A subset S ∗ ⊆ R is optimum for [P1] if and only if S ∗ corresponds to a
subset B ∗ ⊆ C that is optimum for [P1.B], and m 1 (S ∗ ) = |B ∗ |.
Similar formulation can be obtained for problem P2:
[P2] min{m 1 (S) : m 2 (S ∪ S0 ) ≥ m 2 (R), S ⊆ R},
[P2.B] min{|B| : f (B ∪ {0}) = f (C), B ⊆ C},
where the set of elements in S0 corresponds to color {0}.
The minimization of a submodular function is a polynomial problem (see for example [11]). However the constrained minimization of a submodular function is in general
an NP-complete problem. Polynomial cases are found by restricting the family of sets
over which the submodular function is minimized [16,17]. The feasibility set of both
of our problems does not belong to any of the family sets where the problem of minimizing a submodular function is polynomially solvable. Indeed, both of our problems
are NP-complete as proven in the next section.
3 Complexity analysis
In this section we analyze the complexity of P1 and P2. Theorem 1 gives the NPcompleteness proof of both the problems. We then deepen the study (in the subsequent
sections) of the complexity of these problems by analyzing special instances arising
from different characterizations of matrix L.

123

Sensor location flow observability problem

2251

We prove the NP-completeness of P1 by reduction from the 3—Exact Cover Problem, a well-known NP-complete problem [20], that we recall first.
3. Exact cover problem
Given a collection S = {S1 , . . . , Sn } of subsets of {1, 2, . . . , p}, where |Si | = 3,
i = 1, . . . , n.

Is there a collection I of disjoint subsets of S with |I | = 3p and such that i∈I Si =
{1, 2, . . . , p}?
Theorem 1 Problem P1 is NP-complete.
Proof Suppose S j = { j1 , j2 , j3 }. To transform 3—Exact Cover into P1 define the set
R of rows, of dimension p, in the following way. With each subset S j associate three
row vectors L j1 , L j2 , L j3 , such that row L ji has a 1 in position ji and 0’s elsewhere,
for i = 1, 2, 3. Assign the same color j to each row associated with subset S j . Set
k = 3p .

It is easy to see that for
|I | = 3p , the rows with colors in C = i∈I i are linearly


independent if and only if i∈I Si = {1, 2, . . . , p}.
Corollary 1 Problem P2 is NP-complete.
Proof Since P1 is a special case of P2, the latter is also NP-complete.




3.1 Analysis of special instances
We consider two main characteristics of the matrix L: (1) the number of non-zero
elements in each row of the matrix; (2) the number of rows of matrix L that have the
same color [i.e., the size of sets Ri = {L h ∈ R : c(L h ) = i}, for each i ∈ C]. This
choice is motivated by analyzing the related applications that arise in the context of
sensor location. Indeed, the number of non-zero elements in each row defines the types
of equations that are added after the location of a sensor. For example, by locating
path-ID sensors on the arcs of the network we add equations of the type: f Yi = fˆ that
correspond to rows in matrix L with exactly a single non-zero entry. The location of
counting sensors or image sensors on the network adds more general equations of the
type: f Yi1 + f Yi2 + · · · + f Yi p = fˆ. We distinguished the cases when the number of
non-zero entries in the corresponding rows is exactly equal to 1, exactly equal to 2
and greater than 2.
On the other hand, the number of rows in the matrix having the same color is equal
to the number of equations that correspond to a located sensor. For example, consider
the case where a path-ID is to be located on an arc. The number of equations of type
f Yi = fˆ that are added, corresponds to the number of routes that use the arc. Now
consider the case when we locate a counting sensor on an arc; then we add a single
equation of type f Yi1 + f Yi2 + · · · + f Yi p = fˆ, that is |Ri | = 1 for any i ∈ C. Assume
now, the network under consideration is a line network as in Fig. 2. Such networks
can occur in transit applications, where each bus route traverses a part of the network.
Assume we may locate counting sensors (or also image sensors, see [15]) on any node.
Such a location adds exactly two equations of type f Yi1 + f Yi2 + · · · + f Yi p = fˆ, i.e.,
|Ri | = 2, for each i ∈ C.

123

2252

M. Gentili, P. Mirchandani

Fig. 2 A simple oriented path. In this case locating a counting sensor on a node produces two equations
of the type f Yi + f Yi + · · · + f Yi = fˆ
1

2

p

Table 3 Problem P1 and P2
|Ri | = 1 ∀i

|Ri | = 2 ∀i

|Ri | > 2 for some i

N Z h = 1 ∀L h

P

P

NP-C

N Z h = 2 ∀L h

P

P

NP-C

N Z h > 2 for some L h

P

?

NP-C

(1) See Theorem 5; (2) Theorem 6; (3) Theorem 4; (4) Theorem 1; (5) Theorem 3
Complexity results

Table 3 is a summary of our results obtained for problem P1 and P2. Each cell of the
table defines an instance of the problem characterized by (1) the number of non-zero
elements in each row L h (i.e., rows N Z h = 1 ∀L h , N Z h = 2 ∀L h , N Z h > 2 for some
L h ) and (2) the number of rows of L having the same assigned color i (i.e., columns
|Ri | = 1 ∀i, |Ri | = 2 ∀i, |Ri | > 2, for some i ∈ C). In each cell, P indicates that the
problem instance is polynomially solvable, while NP-C means it is NP-complete.
To complete the description of the complexity of the problems addressed in this paper,
we analyzed both the problems also when the objective function needs to be maximized. In this case both the problems become polynomially solvable since they reduce
to the problem of looking for a common independent set of maximum cardinality in
two matroids; the proof is given in Appendix B.
3.2 NP-complete instances
Consider now the special cases of P1 and P2 obtained when each row of matrix L has
exactly two non-zero elements and |Ri | > 2, ∀i ∈ C [that is, cell (2, 3) in Table 3].
For this particular cases the problem consists in looking for a spanning L-forest of
an edge-colored graph with the minimum number of different colors. The definition
of L-forest was introduced in [10] and some properties about the relationship between
L-forest and the edge/vertex incident matrix of the related graph has been studied in
[12]. Here we recall some basic definitions and properties, for a detailed explanation
the reader is referred to [10].
Let G = (V, E) be an undirected graph with |V | = n nodes and |E| = m arcs.
An L-forest of G is obtained from any forest F of G by adding at most one edge to
any component of F that introduces an odd cycle. Let Z be the edge/vertex incident
matrix of G. The following theorem and properties hold [10]:
Theorem 2 Each set of maximal independent rows of Z corresponds to a maximal
L-forest of G.
Property 1 If G is bipartite then each spanning L-forest is a forest.

123

Sensor location flow observability problem

2253

Property 2 If G is connected then each maximal L-forest is obtained from a spanning
tree by adding a single edge {e} that introduces an odd cycle.
Property 3 If G is bipartite and connected then each maximal L-forest is a spanning
tree.
Let us consider the intersection graph G = (V, E) of the columns of our matrix L
for problem P1, under the mentioned assumptions. That is, node v j ∈ V , |V | = p,
corresponds to column L j and there is an edge between v j and vh if and only if the
corresponding columns L j , L h have a non-zero element in the same row (i.e. there
exists k for which lk j = lkh = 1). Since matrix L may have identical rows, G may
have multiple edges. To each edge er ∈ E assign the color of the corresponding row
of L, that is c(er ) = i iff c(L r ) = i. Obviously, with any subset S of rows of matrix
L with |c(S)| = k, corresponds a subset of edges of the graph G having exactly k
different colors, and vice versa.
Since a set S ⊆ R is feasible for P1 if and only if it corresponds to a maximal set of
linearly independent rows then, by Theorem 2, the following lemma follows directly.
Lemma 2 A subset of rows S ⊆ R is feasible for P1 if and only if S corresponds to
a set of edges E S ⊆ E that is a maximal L-forest of G.
The following two problems become special instance of P1 and P2, respectively.
Minimum colored L-forest problem (MCF)
Let G be a multigraph, c : E → C be a coloring (not necessarily proper) of the
edge set and k any positive integer.
Is there a maximal L-forest F of G such that |c(F)| ≤ k?
Minimum extended colored L-forest problem (MECF)
Let G = (V, E) be a multigraph, G  = (V  , E  ) an L-forest of G, c : E\E  → N
a coloring (not necessarily proper), and, k any positive integer.
Is there a maximal L-forest F = (V, E  ) of G such that (i) E  ⊆ E  and (ii)
|c(F)| ≤ k?
When G does not have multiple edges and is bipartite and connected, then (by
Property 3) a maximal L-forest is a spanning tree. The problem of finding a spanning
tree with fewest colors on an edge-colored graph [minimum labelled spanning tree
problem (MLST)] has been defined in [3,7], where the problem was proved to be
NP-complete. We slightly modify the proof in [3] to provide NP-completeness proofs
of both MC F and M EC F.
We prove that MCF is NP-complete by reduction from the dominating set problem
(DSP) [18]. A similar reasoning can be applied to prove M EC F is NP-complete by
reduction from the mixed dominating set problem (MDSP) [8]. This last theorem is
given in Appendix A.
Now, we recall the decisional version of the DSP.
Dominating set problem (DSP)
Let G = (V, E) be a graph, and k be any positive integer.
Is there a dominating set D of size |D| ≤ k, that is, is there a subset of nodes
D ⊆ V of size less than or equal to k such that for each node v ∈ V \D there exists a
node w ∈ D such that (v, w) ∈ E?

123

2254

M. Gentili, P. Mirchandani

Fig. 3 The reduction from the dominating set problem

Theorem 3 MCF is NP-complete.1
Proof MCF is in NP. A non-deterministic algorithm can guess a maximal L-forest F
of G and then check in linear time whether |c(F)| ≤ k.
Let G = (V, E) be a graph, and k a positive integer. We build a multigraph H =
(Z , A), a coloring c : A → N and define a positive integer k  , such that G has
a dominating set D with size |D| ≤ k if and only if H has a maximal L-forest
F = (Z , A ) such that |c(F)| ≤ k  .
Let V = {v1 , . . . , vn }. For each vi ∈ V add a new vertex u i and the edge (u i , vi )
with color c(u i , vi ) = i. For each vertex vi and each edge (vi , v j ) ∈ E add a new
vertex u i j , an edge (vi , u i j ) with color c(vi , u i j ) = j and a parallel edge (vi , u i j ) with
color c(vi , u i j ) = i. Add a new vertex z and all the edges from z to the u-vertices with
color n + 1. This construction (see Fig. 3) of a multigraph can be done in polynomial
time. Now we show that G has a dominating set D with size |D| ≤ k if and only H
has a maximal L-forest F = (Z , A ) and |c(F)| ≤ k  . H is a connected graph and
does not contain odd cycles. Indeed, all the two-arc cycles of H contain one vi vertex
and four-arc cycles contain vertex z and one vertex vi . Each vi is connected to vertex
z by paths of length 2. Therefore, H is connected and bipartite and thus each maximal
L-forest is a spanning tree (see Property 3). Let D be a dominating set for G with
|D| ≤ k. For each vi ∈ V choose one vertex v j ∈ D such that either vi = v j or
(vi , v j ) ∈ E. In H choose the corresponding edge (v j , u j ) with color j or the edge
(vi , u i j ) with color j. That is, in H we chose n edges with at most k colors. Adding
all the edges with color n + 1 we obtain the edge set of a spanning tree with at most
k + 1 colors.
Conversely, let F be a spanning tree of H such that |c(F)| ≤ k  . F contains at least
one edge with color n + 1. For each vi ∈ Z there is exactly one path p of two edges
from z to vi in F. Replace all other edge (vi , u) ∈
/ p incident to vi in F by the edge
(z, u) incident with z and u. This new tree, say F  , is such that |c(F  )| ≤ k  . Define the
dominating set D in G in the following way: for each vi ∈ V , if the edge in F  incident
to vi has color j then v j ∈ D, if it has color i then vi ∈ D, thus |D| ≤ k  = k +1.



1 This corresponds to cell (2, 3) in Table 3.

123

Sensor location flow observability problem

2255

3.3 Polynomial instances
We analyze now the case where (1) each row of matrix L has exactly two non-zero
elements, and, (2) |Ri | = 2, ∀i ∈ C [that is, cell (2, 2) in Table 3]. This means that
the number of edges having the same color in the intersection graph G = (V, E)
associated to the matrix is equal to two. This particular instance is equivalent to the
graphic matroid parity problem as shown in [4], for the MLST and whose proof is
valid also if the graph is a multigraph as in our case. Therefore, the following theorem
holds:
Theorem 4 If each row of matrix L has exactly two non-zero elements, and, |Ri | = 2
for each i ∈ C, then P1 and P2 are polynomially solvable.2
Consider now the simple cases when |Ri | = 1 for each i ∈ C, that is consider cases
corresponding to the first column of Table 3. Recall the definition of the two matroids
defined in Sect. 2. In this case the objective function of the problems is m 1 (S) = |S|,
S ⊆ R. Since each basis of a matroid has the same size, then any basis of matroid
M2 is an optimum set for problem P1; and for P2, any basis that contains the initial
set of rows S0 is an optimum set for P2. Finding a basis of a matroid or extending an
independent set of a matroid to be a basis are polynomially solvable problems [22].
This proves the following theorem.
Theorem 5 If |Ri | = 1 for each i ∈ C problems P1 and P2 are polynomially
solvable.3
Now consider instances of P1 such that (1) there is a single non-zero element in
each row L i and (2) each set Rk of the partition contains exactly two distinct rows of
L, Rk = {L i , L j } and L i 	= L j for each k ∈ C [that is, cell (1, 2) in Table 3]. We
can assume, without loss of generality, that the sets of the partition are distinct. Let us
define the following graph G = (V, E): each vertex vi corresponds to a column of L
and there is an edge ek = (vi , v j ) ∈ E if there exists a set Rk = {L s , L t } such that
rows L s and L t have the single non-zero element corresponding to column L i and L j
(that is, lsi = 1 and lt j = 1). In this way, each set Rk of the partition corresponds to
a single edge ek of G. Thus, with the subset S of rows is associated the set of edges
E = {ek : S ∩ Rk 	= ∅} and m 1 (S) = |E|.
We show now that a subset of rows S with m 1 (S) ≤ k is feasible for P1 if and only
if it corresponds to a subset of edges E, with |E| ≤ k that covers all the nodes of G.
Recall that the vertex covering by edges problem is polynomially solvable (see [22]).
Theorem 6 If there is a single non-zero element in each row L i of matrix L, and
|Ri | = 2 for each i ∈ C, then P1 is polynomially solvable.4
Proof Let S be a feasible set for P1 with m 1 (S) ≤ k. The corresponding set E has
size |E| ≤ k. It covers all the node set V , because, if otherwise there is a node, say vh
2 This corresponds to cell (2, 2) in Table 3.
3 This corresponds to the cells in column 1 of Table 3.
4 This corresponds to cell (1, 2) in Table 3.

123

2256

M. Gentili, P. Mirchandani

that is not covered by E, then the submatrix L S has the null column L h and L S has
not full rank.
Conversely, let E be a set with |E| ≤ k that covers all the nodes in V . Let
{Si1 , Si2 , . . . , Sis } be
 the sets of the partition that correspond to the edges in E. Consider the set S = sh=1 Si h . By construction m 1 (S) = |E| ≤ k, we have also that
rank(L S ) = rank(L) = p. Indeed, L S is such that there are at least p distinct
rows (that are linearly independent, since each has exactly a single non-zero element)
otherwise E would not cover all the nodes in V . This proves the theorem.


For similar instances of P2 the proof of the following theorem applies using similar
arguments, which is omitted for convenience.
Theorem 7 If there is a single non-zero element in each row L i of matrix L, and
|Ri | = 2 for each i ∈ C, then P2 is polynomially solvable.
Appendix A
We report here the NP-completeness proof for problem MECF by reduction from the
MDSP. First we recall its decisional version.
Let the vertices V of a graph G be partitioned into three subsets V1 , V2 , V3 , where
V1 consists of free vertices, V2 consists of bound vertices and V3 consists of required
vertices. A mixed dominating set in G is a set M of vertices which contains all the
required vertices, (i.e. V3 ⊆ M) and which dominates (by adjacency) all the bound
vertices (i.e. every vertex v ∈ V2 is either in M or is adjacent to at least one vertex in
M). Free vertices need not be dominated by M, but may be included in M in order to
dominate bound vertices. A mixed dominating set of minimum size solves the M DS P.
MDSP was defined in [8] as a generalization of the DSP. Indeed, when V2 = V and
V1 = V3 = ∅ MDSP is the DSP. Thus, MDSP is N P-complete. We will use this result
to show that MECF is N P-complete too. We state now its decision version slightly
changed from the original one to make the proof simpler.
Mixed dominating set problem (MDSP)
Let G = (V, E) be a graph, U ⊆ V a subset of nodes, and, k any positive integer.
Is there a mixed dominating set D ⊆ V with |D| ≤ k, that is, is there a subset D
of size less than or equal to k such that for each v ∈ U \D there exists a node w ∈ D
such that (v, w) ∈ E?
Theorem 8 MECF is NP-complete
Proof MECF is in NP. A non-deterministic algorithm can guess a maximal L-forest
F of G that contains the L-forest F  and then check in linear time whether |c(F)| ≤ k.
Let G = (V, E) be a graph, U ⊆ V a subset of the nodes and k a positive integer.
We will build a multigraph H = (Z , A), an L-forest H  = (Z  , A ), a coloring
c : A\A → N and define a positive integer k  , such that G has a mixed dominating
set D with size |D| ≤ k if and only H has a maximal L-forest F = (Z , A ) such that
A ⊆ A and |c(F)| ≤ k  .
Let U = {v1 , . . . , vu }. For each vi ∈ U add a new vertex u i and the edge (u i , vi ).
For each vi ∈ U and each edge (vi , v j ) ∈ E, add a new vertex u i j , an edge (vi , u i j )

123

Sensor location flow observability problem

2257

with color c(vi , u i j ) = i and a parallel edge (vi , u i j ) with color c(vi , u i j ) = j. Add
a new vertex z and all the edges from z to the u i j -vertices with color n + 1. Observe
that H does not contain odd cycles. Indeed, all the cycles in H include two or four
arcs, and each four-arc cycle contains vertex z and one vertex vi . Each vi is connected
to vertex z by a path of length 2. Therefore H is bipartite and connected, thus each
maximal L-forest is a spanning tree and an L-forest is a forest (Property 3).
Define the subgraph H  = (Z  , A ) with Z  = {u 1 , v1 , u 2 , v2 , . . . , u u , vu } and

A = {(u 1 , v1 ), (u 2 , v2 ), . . . , (u u , vu )}. The subgraph H  contains edges without any
color, is acyclic, and thus a forest. Hence H is an L-forest. Clearly, this construction
of H and H  can be done in polynomial time.
Now we show that G has a mixed dominating set D with size |D| ≤ k if and only
H has a maximal L-forest F = (Z , A ) such that A ⊆ A and |c(F)| ≤ k  .
Let D be a mixed dominating set for G with |D| ≤ k. For each vi ∈ U ∩ D choose
in H any edge (vi , u i j ) with color i. For each vi ∈ U \D choose one vertex v j ∈ D
such that (vi , v j ) ∈ E and select in H the edge (vi , u i j ) with color j. Add all the
edges (vi , u i ). Finally, add all the edges with color n + 1 incident to z to define the
spanning tree F. Set k  = k. We built, in this way, a spanning tree F containing the
forest H  and such that |c(F)| ≤ k  .
Conversely, let F be a spanning tree of H containing the forest H  and such that
|c(F)| ≤ k  . F contains at least one edge with color n + 1 and all the edges in H  . For
each vi ∈ Z  there is exactly one path p of length 2 from z to vi passing through a u i j
vertex. Replace all other edges (vi , u i j ) ∈
/ p incident to vi in F, by the edges (z, u i j )
incident with z. This new tree, say F  , is such that |c(F  )| ≤ k  . Define the mixed
dominating set D in G in the following way: for each vi ∈ U , if the edge (vi , u i j ) in


F  has color j then v j ∈ D, if it has color i then vi ∈ D, thus |D| ≤ k  = k.
Appendix B
To complete the description of the complexity of the problems addressed in this paper,
we show now that problem P1 and P2 when the objective function needs to be
maximized become polynomially solvable since they reduce to the problem of looking
for a common independent set of maximum cardinality in two matroids.
Given two matroids M1 = (R, F1 ) and M2 = (R, F2 ) defined on the same ground
set R with M1 a partition matroid, we want to find a basis of matroid M2 that maximizes
the rank function of matroid M1 . We refer to this problem as P3 whose formulation
is:
[P3] max{m 1 (Q) : m 2 (Q) ≥ m 2 (R) and m 2 (Q) ≥ |Q|, Q ⊆ R}
We will show Problem P3 is equivalent to finding a common independent set (for both
the matroids) of maximum cardinality, and thus the problem is polynomially solvable
(see for example [22]). Broesma and Li [3] proved the result when M2 is a graphic
matroid, we extend their proof for the general case in which M2 is any matroid. Let
m i (Q),Q ⊆ R, be the rank function of matroid Mi , i = 1, 2. A subset Q ⊆ R is
optimum for P3 if:

123

2258

M. Gentili, P. Mirchandani

• m 2 (Q) = m 2 (R) = |Q| (Q is a basis for M2 )
• m 1 (Q) = k
• there is not any other basis Q  ⊆ E of M2 such that m 1 (Q  ) > k
A subset I ⊆ R is an optimum common independent set for M1 and M2 if:
• m 1 (I ) = |I | (I is an independent set in M1 )
• m 2 (I ) = |I | (I is an independent set in M2 )
• there is not any other set I  ⊆ R such that m 1 (I  ) = m 2 (I  ) = |I  | and |I  | > |I |
Theorem 9 A subset Q is optimum for P3 if and only if Q is obtained by extending
an optimum common independent set I for M1 and M2 to be a basis of M2 .
Proof (⇒) Let Q be an optimum set for P3. Since m 1 (Q) = k ≤ |Q|, let Q  ⊆ Q
be the maximal independent set with respect to matroid M1 contained in Q. That is,
m 1 (Q  ) = m 1 (Q) = |Q  | = k. Since Q  is a subset of Q that is independent in
M1 , then Q  is independent in M2 too, i.e. m 2 (Q  ) = |Q  | ≤ |Q|. This set Q  is an
optimum common independent set for M1 and M2 . Otherwise, there exists I ⊆ R
such that:
(i) m 1 (I ) = |I |
(ii) m 2 (I ) = |I |
(iii) |I | > |Q  |
If I is a basis of M2 then it is feasible for P3 and inequality (iii) contradicts the
maximality of Q. If I is not a basis of M2 , we can add to I elements e ∈ R\I in
order to build I ∗ that is a basis for M2 and thus is feasible for P3. Since I ∗ ⊇ I then
m 1 (I ∗ ) ≥ m 1 (I ) > k contradicting the maximality of Q. Hence Q  is an optimum
common independent set for M1 and M2 , and, Q corresponds to Q  .
(⇐) Conversely, let I be an optimum common independent set for M1 and M2 :
• m 1 (I ) = |I |
• m 2 (I ) = |I |
If I is not a basis for M2 , we can add elements e ∈ R\I to I in order to obtain a basis
I ∗ for M2 :
• m 2 (I ∗ ) = m 2 (R) = |I ∗ |
• m 1 (I ∗ ) ≥ m 1 (I ) = |I |
The set I ∗ is feasible for P3 and is optimum. Otherwise, if Q ⊆ R is a basis of M2
with m 1 (Q) > m 1 (I ∗ ). We could find the set Q  ⊆ Q such that:
• m 2 (Q  ) = |Q  |
• m 1 (Q  ) = |Q  | = m 1 (Q)
that is independent in both the matroids and such that m 1 (Q) > m 1 (I ∗ ) ≥ m 1 (I )
contradicting the maximality of I .
Then, to solve P3 it is sufficient to find a maximum cardinality independent set Q


for both the matroids and then extend Q to be a basis for M2 .

123

Sensor location flow observability problem

2259

References
1. Bianco, L., Confessore, G., Reverberi, P.: A network based model for traffic sensor location with
implication in o-d matrix estimates. Transp. Sci. 35, 50–60 (2001)
2. Bianco, L., Confessore, G., Gentili, M.: Combinatorial aspects of the sensor location problem. Ann.
Oper. Res. 144, 201–234 (2006)
3. Broersma, H., Li, X.: Spanning trees with many or few colors in edge colored graphs. Discuss. Math.
Graph Theory 17, 259–269 (1997)
4. Brüggemann, T., Monnot, J., Woeginger, G.J.: Local search for the minimum label spanning tree
problem with bounded color classes. Oper. Res. Lett. 31, 195–201 (2003)
5. Castillo, E., Menéndez, J.M., Jiménez, P.: Trip matrix and path flow reconstruction and estimation
based on plate scanning and link observations. Transp. Res. Part B 42, 455–481 (2008)
6. Castillo, E., Gallego, I., Menndez, J.M., Rivas, A.: Optimal use of plate scanning resources for route
flow estimation in traffic networks. IEEE Trans. Intell. Transp. Syst. 11(2), 380–391 (2010)
7. Chang, R.-S., Leu, S.-J.: The minimum labeling spanning trees. Inf. Process. Lett. 63, 277–282 (1997)
8. Cockayne, E., Goodman, S., Hedetniemi, S.: A linear algorithm for the domination number of a tree.
Inf. Process. Lett. 4(2), 41–44 (1975)
9. Confessore, G., Dell’Olmo, P., Gentili, M.: Experimental evaluation of approximation and heuristic
algorithms for the dominating paths problem. Comput. Oper. Res. 32, 2383–2405 (2005)
10. Conforti, M., Rao, M.R.: Some new matroids on graphs: cut sets and the max cut problem. Math. Oper.
Res. 12(2), 193–204 (1987)
11. Fleischer, L.: Recent progress in submodular function minimization. Optima 64, 1–11 (2000)
12. Gentili, M.: New models and algorithms for the location of sensors on traffic networks. PhD dissertation.
Department of Statistics Probability and Applied Statistics, University of Rome La Sapienza (2002)
13. Gentili, M., Mirchandani, P.B.: Location of active sensors on traffic network. Ann. Oper. Res. 136,
229–257 (2005)
14. Gentili, M., Mirchandani, P.: Survey of models to locate sensors to estimate traffic flows. Transp. Res.
Rec J Transp Res Board 2243, 108–116 (2011)
15. Gentili, M., Mirchandani, P.B.: Locating sensors on traffic networks: models, challenges and research
opportunities. Transp. Res. Part C Emerg. Technolog. 24, 227–255 (2012)
16. Goemans, M.X., Ramakrishnan, V.S.: Minimizing submodular set functions over families of sets.
Combinatorica 15(4), 499–513 (1995)
17. Grötschel, M., Lovász, L., Schrijver, A.: Geometric Algorithms and Combinatorial Optimization.
Springer, New York (1988)
18. Hedetniemi, S.T., Laskar, R.C.: Topics on domination. Annals of discrete mathematics, 48. Sole distributors for the USA and Canada, Elsevier Science, New York (1991)
19. Hu, S., Peeta, S., Chu, C.: Identification of vehicle sensor locations for link-based network. Transp.
Res. Part B 43, 873–894 (2009)
20. Karp, R.M.: Reducibility among combinatorial problems. In: Miller, R., Thatcher, J. (eds.) Complexity
of Computer Computations, pp. 85–103. Plenum Press, New York (1972)
21. Nemhauser, G.L., Wolsey, L.A., Fischer, M.L.: An analysis of approximations for maximizing submodular set functions-I. Math. Program. 14, 265–294 (1978)
22. Nemhauser, G.L., Wolsey, L.A.: Integer and Combinatorial Optimization. Wiley, New York (1988)

123

Computers & Operations Research 34 (2007) 1008 – 1032
www.elsevier.com/locate/cor

A decision support system for the single-depot vehicle
rescheduling problem
Jing-Quan Lia , Denis Borensteinb,∗ , Pitu B. Mirchandania
a Systems and Industrial Engineering, The University of Arizona, Tucson, AZ 85721, USA
b Management School, Universidade Federal do Rio Grande do Sul, R. Washington Luis 855,

Porto Alegre 90010-460, RS, Brazil
Available online 22 December 2005

Abstract
Disruptions in trips can prevent vehicles from executing their schedules as planned. Mechanical failures, accidents,
and trafﬁc congestion often hinder a vehicle schedule. When a vehicle on a scheduled trip breaks down, one or more
vehicles need to be rescheduled to serve the passengers/cargo (if there are any) on that trip. The main objective of the
vehicle rescheduling problem (VRSP) is to minimize operation and delay costs, while serving the passengers/cargo
on the disrupted trip and completing all remaining trips that include the disrupted one. We report on a prototype
decision support system (DSS) that recommends solutions for the single-depot rescheduling as well as vehicle
scheduling (VSP) problems, since VRSP is closely related to VSP. The system was designed for human schedulers
to obtain optimal vehicle assignments and reassignments. An experimental study, using randomly generated
data, shows the efﬁciency of the developed algorithm. A real world problem, which involves the solid waste collection operational planning for a Brazilian city, is selected as the case study to illustrate the effectiveness of the
developed DSS.
䉷 2005 Elsevier Ltd. All rights reserved.
Keywords: Vehicle scheduling; Decision support systems; Operational planning; Rescheduling

∗ Corresponding author. Tel.: +55 51 316 3459; fax: +55 51 316 3991.

E-mail addresses: jingquan@email.arizona.edu (J.-Q. Li), denisb@ea.ufrgs.br, denis@adm.ufrgs.br (D. Borenstein),
pitu@sie.arizona.edu (P.B. Mirchandani).
0305-0548/$ - see front matter 䉷 2005 Elsevier Ltd. All rights reserved.
doi:10.1016/j.cor.2005.05.022

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1009

1. Introduction
Transportation and logistic systems often encounter disruptions that prevent them from operating as
planned. Severe weather conditions, accidents, and the breakdown of vehicles are examples of possible
disruptions that demand the rescheduling of vehicles. The vehicle rescheduling problem (VRSP) consists
of deﬁning a new schedule for a set of previously scheduled trips, given that a trip has been severely
disrupted. The main objective of the vehicle rescheduling problem is to minimize the involved operation and delay costs, under the condition that uncompleted trips must be ﬁnished (including the
disrupted one).
Rescheduling is usually made by human experts. They often employ common sense and past experiences that are blended in a fuzzy, sometimes inconsistent, and not well-understood way. When ﬂeet size
is limited and disruptions are frequent [1], good automated rescheduling tools with effective algorithms
become important for the following reasons:
• For large problems that involve thousands of trips and hundreds of vehicles, the number of feasible
solutions for the rescheduling problem may be so large that even the most skillful human scheduler
may overlook good rescheduling options. The availability of a systematic procedure, based on an
optimization algorithm, will guarantee that a good reassignment is obtained.
• Rescheduling needs to be obtained quickly, since disruption delays will have a negative inﬂuence on
system performance, because they simultaneously result in increasing costs and deterioration of the
level of service.
• Since crews might be reassigned to a new schedule, the computation of VRSP needs to be completed
as fast as possible. Without automated rescheduling tools, often the easiest and quickest approach of
the human scheduler is to send a vehicle from the depot to backup the disrupted trip, which might be
a poor solution.
This means that there is a potential for improvement through a decision support system (DSS) due to the
complexity of the problem. The development of new information technologies (e.g., global positioning
system, geographical information systems, cellular phones, etc.) has raised the interest in automatic
recovery strategies. As real-time information is now available at low-cost, human schedulers are forced
to react to unexpected events in real time [2]. The VRSP arises in a wide array of practical applications
such as school bus routing, operational planning of public transportation systems, industrial/hospital
refuse collection, mail delivery, telecommunication systems, etc.
The VRSP can be approached as a dynamic version of the classical vehicle scheduling problem where
assignments are generated dynamically. Although there is an abundant literature dealing with vehicle
scheduling (usually in the context of planning a schedule), there is still a lack of methodologies that
can efﬁciently solve the VRSP. In this paper, we develop the speciﬁcations for of a prototype decision
support system for both the single-depot VSP (SDVSP) and single-depot VRSP (SDVRSP) problems.
The DSS is designed to help human schedulers to assign and reassign vehicle schedules towards obtaining
optimal solution for both problems. The robust capability of solving both problems, with emphasis on
the automatic rescheduling through integration with real time information, makes the DSS an effective
computer-based tool to be used by human schedulers in transportation/logistic companies. The main
contribution of this paper is to describe a DSS, which is able to support both SDVSP and SDVRSP in an
efﬁcient and effective manner.

1010

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

The paper is organized as follows. Section 2 reviews the literature on the static and dynamic contexts
of the VSP. The descriptions of the SDVSP and SDVRSP problems and models are provided in Section 3.
Section 4 describes the developed DSS, with a discussion about the procedures used to optimize both
the SDVSP and the SDVRSP. Section 5 presents computational experiments to evaluate the performance
of the algorithms by comparing the developed algorithm with CPLEX, using randomly generated data.
In Section 6, the application of the DSS for a real-world problem, the solid waste collection operational
planning for a Brazilian city, is described. In the concluding Section 7, summary of the results and areas
of future research are discussed.

2. Literature review
In this section we present an overview of the static and dynamic SDVSP literature. As a classical
optimization problem [3], the static SDVSP can be deﬁned as the problem of assigning vehicles to a set of
predetermined trips with prescribed starting and ending times while minimizing the total capital and travel
costs, and satisfying the following constraints: (i) every trip has to be assigned to exactly one vehicle; (ii)
each vehicle performs a feasible sequence of trips; and (iii) only one depot exists. Deterministic and static
versions, where all the characteristics of the trips are known in advance and every parameter assumed
certain, have been widely studied in the literature. Overviews of algorithms and applications for the static
SDVSP and some of its extensions can be found in [3–6]. This problem has already been formulated as a
linear assignment problem, a transportation problem, a minimum-cost ﬂow problem, a quasi-assignment
problem, and a matching problem in the literature.
Bokinge and Hasselstrom [7] propose a minimum-cost ﬂow approach that uses a signiﬁcant reduction
on the size of the model in terms of the number of variables at the price of an increased number of
constraints. A successive shortest-path algorithm and variations for the SDVSP were proposed in [8–10].
Paixão and Branco [11] propose an O(n3 ) quasi-assignment algorithm that is especially designed
for the SDVSP. Freling et al. [6] use a quasi-assignment model and employ a forward/reverse auction
algorithm for the solution. Computational results show that the approach relating to quasi-assignment
signiﬁcantly outperforms approaches based on the minimum-cost ﬂow and linear-assignment models.
Currently, one of the best model and algorithm for SDVSP is the quasi-assignment and auction algorithm
[6], respectively. Bertsekas and Eckstein [12] show that if -scaling is used, that is applying the auction
algorithm starting with a large value of  and gradually reducing it to a ﬁnal value that is less than 1/n, the
complexity is O(nm log nC), where n is the number of elements to assign, m is the number of possible
assignments between pairs of elements, and C is the maximum of absolute beneﬁts.
Since automatic recovery from disruptions is a relatively new operational strategy, the literature related
to the dynamic aspects of vehicle rescheduling is sparse. The majority of the research conducted in this
area is related with the dynamic vehicle routing problem (VRP) and with the airline recovery problem.
Dynamic vehicle routing problem, where new requests arise in midst of operations, has gained increasing attention since the late eighties [2]. Recent surveys on dynamic VRP can be found in [13–15].
Ichoua et al. [2] have designed a heuristic based on tabu search to handle the real-time vehicle dispatching problem. Yang et al. [16] have developed a general framework for dynamic vehicle routing problem
in which new requests can arrive during operations, where the travel time is considered as a variable.
Stochastic programming has also been used to tackle uncertainty in vehicle scheduling and routing (e.g.,
see [17,18]).

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1011

Although the above efforts have studied dynamic aspects of the vehicle scheduling/routing, the requirements of the vehicle rescheduling problem, including ﬁnding a backup vehicle and picking up
passengers/cargo from the breakdown vehicle, have not been addressed.
The literature on aircraft disruption includes [19–22]. These works developed optimization models
that reschedule legs and reroute aircraft by minimizing rerouting and cancellation costs. The developed
models are airline speciﬁc and involve a limited number of trips and airplanes; and most of associated
algorithms are computationally intensive. As a consequence, they cannot be used for a more generic
problem such as the VRSP, which can involve thousands of trips and hundreds of vehicles.
To the best of our knowledge, the only contributions towards solving our dynamic VSP are found
in [23,24]. Huisman et al. [23] have proposed an approach to the dynamic VSP by solving a sequence
of optimization problems. Their work is motivated by designing robust vehicle schedules to avoid trips
starting late in environments characterized by signiﬁcant trafﬁc jams. Li et al. [24] have developed a
parallel auction algorithm for bus rescheduling. There, the bus rescheduling problem is modeled as several
VSP problems, each one corresponding to the use of a different vehicle as an alternative to backup the
disrupted trip. All problems are solved using a parallel implementation of a combined forward-backward
auction algorithm developed by Freling et al. [6] designed for the quasi-assignment problem. The parallel
algorithm has been proven to be computationally efﬁcient, even for large problems. Therefore, it has
potential to be used in automated recovery tools.
Given the complexity of the SDVRSP problem, there is a gap between the existence of efﬁcient algorithms and their application to real world cases [25]. For an effective application of these algorithms, a
great deal of knowledge and expertise is required. Furthermore, implementation of the developed algorithms is not so straightforward, after the speciﬁc requirements of transportation and logistics companies
are considered. As a result, very few companies utilize automated rescheduling policies. Thus, the development of a computer-based tool, which is capable of providing a friendly environment for users and
emphasizing ﬂexibility, efﬁciency, and adaptability, becomes an important aspect for the effective use of
real-time vehicle scheduling strategies. Although some DSSs have already been developed in the area of
vehicle routing [26–28] and scheduling [3], they do not address the vehicle rescheduling problem.

3. Problem description
Vehicle rescheduling problems arise when a scheduled trip is severely disrupted. Although most disruptions do not warrant rescheduling to be performed, some disruptions are severe enough to prevent the
trip being ﬁnished in a reasonable amount of time. Vehicle breakdown and accidents are examples of
severe disruptions that might request a reassignment of vehicles, mainly if the vehicle of the disrupted trip
is carrying passengers or cargo. Fig. 1 describes a typical decision process involving both the scheduling and the disruption decision-making sub-processes. The scheduling decision-making process can be
characterized as the classical single-depot vehicle scheduling problem.
Before considering mathematical formulations, we introduce some deﬁnitions and notations. Deadheading trips are movements of vehicles without serving passengers. Trips i and j constitute compatible
pair of trips if the same vehicle can reach the starting point of trip j after it ﬁnishes the trip i. We
use a binary relation symbol ct to determine whether two trips characterize a compatible pair of trips.
If ct(i, j ) = 1, trips i and j constitute a compatible pair of trips. Otherwise, if ct(i, j ) = 0, trips i and j
do not constitute a compatible pair of trips.

1012

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

Trips

Scheduling
Trips

Disruption
Decision
Process

Disruption

Serious?

No

Yes

Scheduling
Perform
Adjustment

Initial
Schedule

Reschedule
No

Acceptable?

Yes

Crew
Scheduling

Dispatcher

Fig. 1. Scheduling and disruption decision-making process.

Let N = {1, 2, . . . , n} be the set of trips, numbered according to increasing starting time, and let
E = {(i, j )|i < j, ct(i, j ) = 1, i ∈ N, j ∈ N } be the set of arcs corresponding to deadheading trips. The
vehicle-scheduling network be G = V , Z with nodes V = N ∪ s, t and arcs Z = E ∪ (s × N) ∪ (t × N),
where s and t denote the same depot in the network, with s simply meaning the depot as a starting point,
and t as the terminating point. A path from s to t in the network represents a feasible vehicle schedule.
The SDVSP can be formulated as a quasi-assignment problem as follows [6]:

min
cij yij
(i,j )∈Z

s.t.



yij = 1

∀i ∈ N ,

yij = 1

∀j ∈ N,

j :(i,j ) ∈Z



i:(i,j ) ∈Z

yij ∈ {0, 1}

∀(i, j ) ∈ Z,

where
cij = cost of arc (i, j ) ∈ Z,

1 if a vehicle is assigned to trip j directly after trip i,
yij =
0 otherwise.

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1013

The constraints in the formulation assure that each trip is assigned to exactly one predecessor and one
successor. We refer to Freling et al. [6] for a discussion about algorithms to solve the SDVSP.
If a disruption occurs, the human schedulers use their expertise to deﬁne if the disruption is severe or
not. If it is not severe, only small adjustments are necessary and, in general, the initial schedule is not
changed. In case of a serious disruption, rescheduling is necessary, and the initial schedule (excluding the
already ﬁnished trips) is used as a basis for rescheduling. This paper presents in Section 3.3 how vehicle
rescheduling is formulated, modeled, and optimally solved. However, it is possible that even an optimal
solution cannot be implemented in practice due to real-world considerations, such as crew recovery
issues, or poor service for important users of the system. In this sense, the human schedulers can use
their expertise to ﬁnd a good compromise between the mathematical solution and these real world issues.
Therefore, some schedulers are willing to accept “suitable” solutions after taking into consideration the
company strategy to deal with this problem, rather than optimal ones.
It should be noted that the disruption decision-making process is highly dependent on the existence
of an effective information system that is able to quickly capture information about disruptions, such as
disruption time and place, and the number of passengers or cargo size in the vehicle of the disrupted trip.
After the VRSP is solved, the new schedule should also be quickly provided to the involved personnel
(vehicle conductors and associated crew). We assume here that the transportation/logistic company has
already developed or is able to develop such an information system.
We need to introduce some additional deﬁnitions and notations to describe VRSP. To relate to a cut in
a graph, we refer to a disrupted trip due to a disabled vehicle, or a vehicle that is effectively inoperable,
as a cut trip. Breakdown point is the point in the cut trip where the trip is disrupted. Current trip is the
trip on which a vehicle is serving. It includes both regular and deadheading trips. The vehicle that serves
the remaining passengers in the cut trip, referred to as the backup vehicle in the sequel, can be identiﬁed
from the trip just served, which will be referred to as backup trip in the sequel. The assignment problem
is effectively assigning the node representing the backup trip, or assigning (a vehicle from) the depot, to
the passengers/cargo of the cut trip. Trip i is an itinerary compatible trip with trip j if trip i shares the
same itinerary of cut trip j from the breakdown point until its ending point.
The VRSP can be deﬁned as follows. Given a depot and a series of trips with prescribed starting and
ending times, given the travel times between all pairs of locations, and given a cut trip, ﬁnd a feasible
minimum-cost reschedule in which (1) each vehicle performs a feasible sequence of trips, and (2) all
passengers or cargo (if there are some) on the cut trip are served. There are two possible situations in
the SDVRSP. The ﬁrst one is when the cut trip is a regular one. Unless the disruption is of a nature that
it is impossible to reach the disruption point, the passengers/cargo of the cut trip have to be served. The
solution comprises of sending a backup vehicle to the breakdown point, and from there completing the cut
trip, serving its passengers/cargo. However, since it is highly likely some trips have common itineraries,
the passengers/cargo can also be served incidentally by vehicles that cover compatible itineraries after
the breakdown point. Let us consider the following situation: a backup vehicle changes its schedule and
travels towards the breakdown point, but all the passengers/cargo from the disabled vehicle have been
picked up already by vehicles that cover compatible itineraries with the cut trip (see [24] for details).
This situation needs to be avoided. The second situation arises when the cut trip is a deadheading trip,
the solution is to assign a backup vehicle for the starting location of the next trip of the vehicle on the
disrupted deadheading trip. In both cases, it is highly likely that the solution of the SDVRSP provides
new routes for a subset of the pre-assigned vehicles. Also, we can expect some delays in the cut trip,
mainly in the ﬁrst situation. The main objective of the SDVRSP is to minimize the total delay cost.

1014

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

Table 1
Starting and ending times of trips
Trip

Starting time

Ending time

1
2
3
4

5
1
20
22

10
13
25
28

1

3

(a)

1

2

3

4

(b)

1

2
X

3

4

2
X
4

(c)

Fig. 2. Example of feasible networks.

The most important aspect of the SDVRSP is that the solution is dependent on the current existing
situation and available alternatives to serve the cut trip. Each possible conﬁguration of a recovery can
be translated as a corresponding feasible network. These feasible networks share the same nodes (i.e.,
the trips to be served), but have different arcs connecting them. The deﬁnition of the set of all possible
feasible networks is dependent on the pre-assigned conﬁguration of the trips, the available capacity of
the involved vehicles, and times to carry out deadheading and regular trips.
It is possible to have a different feasible network for each possible backup vehicle. We illustrate the
idea of feasible networks with an example. Suppose we have to carry out four trips with the travel times
indicated in Table 1. Suppose the travel time from the ending point of each trip (or depot) to the starting
of a trip is a constant equal to 4 time units. A possible initial scheduling is presented in Fig. 2(a). Each
regular trip is a “node” of the feasible network, which is graphically represented as a short line segment to
indicate starting and ending points of the trip. Two vehicles can cover the four trips. Vehicle 1 is assigned
to trips 1 and 3, while vehicle 2 is assigned to trips 2 and 4.
Suppose vehicle 2 breaks down on trip 2 at time unit 10. There are two possible backup vehicle
alternatives. The ﬁrst is to use vehicle 1; Fig. 2(b) presents the feasible network representing this situation.
In this network the dashed lines represent the new possible assignments of vehicles to trips. Observe that
an additional vehicle from depot may be used to complete trip 3 or trip 4. The second alternative is to send
a new vehicle from depot to the breakdown point in trip 2. This situation is depicted in Fig. 2(c). Both
ﬁgures present the set of all possible feasible networks, in which a new schedule should be determined.
Section 3.2 describes a formal procedure to generate the set of all possible feasible networks.

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1015

Based on these feasible networks, we can model the VRSP as a VSP in each feasible network. The
VRSP optimal schedule is the one with the minimal cost over the set of all possible feasible networks.
It is quite likely that the remaining vehicles have their routes changed to accommodate the disturbances
caused by the cut trip. As the number of trips grows, the number of backup vehicle candidates may grow
largely. For example, if there are 1300 trips in the network, more than 300 vehicles may be needed to
cover these trips [6]. It means that there are about 300 possible backup vehicles, and therefore about
300 possible feasible networks. The large number of backup vehicle candidates makes the problem very
difﬁcult to solve. Next section describes in detail the developed DSS for helping human schedulers to
solve the decision processes shown in Fig. 1.

4. The decision support system
The proposed prototype of DSS uses the integration of information technology and efﬁcient algorithms
to solve both the VSP and the VRSP. Considering the steps presented in Fig. 1, the DSS includes the
following requirements:
1. To provide an interactive interface that allows the users to retrieve, build and change trips and vehicles
databases.
2. To obtain optimal solutions to the SDVSP.
3. To obtain optimal solution for the SDVRSP when an unexpected event occurs.
4. To provide an interactive environment to create and modify possible operational scenarios.
The DSS is composed of three common basic components: user-interface subsystem, database management subsystem, and model subsystem. Fig. 3 presents the architecture of the DSS. The arrows represent
the information ﬂow. Web-based graphic interface is implemented, so that the human schedulers can
remotely access the system at any time without the limitations of geographical location and time zone.
The DSS is also designed to be independent of the speciﬁc platform, and it supports Unix, PC and Apple
environments. This allows the user to conﬁgure the DSS to meet technical requirements of a speciﬁc
transportation/logistic company.
4.1. User interface subsystem
This subsystem is a visual interactive tool for scheduling and rescheduling of vehicles. It includes
the functions: (i) to control the ﬂow of information among the modules within the software system, (ii)
to run the different algorithms within the DSS, (iii) to build, interactively, the databases, and (iv) to
present the results. This module uses extensive graphical facilities and menu-driven interfaces to achieve
a satisfactory level of interaction, present the output in a meaningful way and provide a smooth and
reliable communication with the user.
The user interface provides a meaningful framework within which information can ﬂow in both the
directions between the user and the computer, so that the user can take full responsibility on the decision.
Fig. 4 presents an example of the several windows in the user interface subsystem. In particular, this
window shows the schedules obtained by executing the algorithms in the model subsystem.

1016

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032
Personal
Computer

Workstation

Apple

User Interface Subsystem: Client

DSS

Information
Query
Internet

Data Changing

System
Administration
Scheduling/
Rescheduling

Database Subsystem
User Interface
Subsystem:Server

Database

Communication
DBMS

Network

Model Subsystem
Unit 1
Vehicles/Crews

Auction algorithm for VSP/
VRSP
Auction algorithm with
dynamic penalty

Unit N
Auction algorithm for VSP/
VRSP
Auction algorithm with
dynamic penalty

Fig. 3. DSS architecture.

4.2. Database subsystem
The database subsystem is responsible for the management of the databases. The database subsystem
contains all the information needed for the scheduling and rescheduling of vehicles. Typical data includes
the following attributes: trips (starting and ending times, starting and ending places), vehicles (identity,
geographical position, crew and capacity), and routes (vehicle ID and sequence of trips). The database
subsystem provides functionality for querying, storing, recovering, and controlling data. Through this
module, the company can create, maintain and update all the information available to human schedulers in the “user interface subsystem”. Moreover, this subsystem enables companies to obtain/deliver
real-time information or data that guarantees the effectiveness of both scheduling and rescheduling
decision making processes, automatically updating all changes in attributes during the operation of
the system.

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1017

Fig. 4. Graphical representation of schedules in the DSS.

4.3. Model subsystem
The model subsystem is used by the DSS to solve the classical SDVSP and the SDVRSP. Since the
former problem is a well-studied topic, this section will focus on the model and the solution approach for
the latter problem. Due to their simplicity and efﬁciency, the quasi-assignment and auction algorithm are
selected for solving SDVSP (see Section 2). Since SDVRSP is treated as a sequence of SDVSP problems,
the quasi-assignment formulation and the combined forward-backward auction algorithm, developed by
[6], are used to model and solve, respectively, the SDVSP within the DSS.
As described in Section 3, the SDVRSP can be modeled as a minimization problem over several
SDVSP problems, each one relating to a possible feasible network. It is possible to have a different
feasible network for each possible backup vehicle candidate (or each backup trip, since there is a unique
correspondence between the vehicle and its current trip in the vehicle scheduling problems). A feasible
network is deﬁned formally as follows. Let b denote the cut trip and K be the set of possible backup trip
candidates. “Arcs” in the network correspond to vehicle assignment to trips. Let N  = N − {b} be the set

1018

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

of total remaining trips excluding the cut trip, numbered according to the non-decreasing starting times.
Deﬁne E(k) = E ∪ {(k, b)}. A feasible network for backup trip k can be deﬁned as G(k) = V , X(k)
with nodes V = N ∪ {s, t} and arcs X(k) = E(k) ∪ (s × N  ) ∪ (N × t), for k ∈ K, where k is the backup
trip. We can deﬁne G = {G(k)|k ∈ K} as the set of all feasible networks.
The SDVRSP can be modeled as a quasi-assignment problem, based on the SDVSP formulation
presented in Section 3, as follows:
⎧
⎫
⎨
⎬

min min
cij yij + Dk
⎭
G ⎩
(i,j )∈X(k)

s.t.



yij = 1

∀i ∈ N ,

yij = 1

∀j ∈ N,

j :(i,j ) ∈X(k)



i:(i,j )∈X(k)

yij ∈ {0, 1}

∀(i, j ) ∈ X(k),

where
cij = cost of arc (i, j ) ∈ X(k),
Dk = delay cost related to the VSP solution for the kth backup trip.
The objective of this formulation is to ﬁnd a schedule with the minimal operating and delay cost
over the set of all possible feasible networks. The constraints in the formulation assure that each trip is
assigned to exactly one predecessor and one successor. However, this formulation requires considerable
computational time for its solution, since |G| integer linear programs with |N  | zero-one variables need
to be solved (see results in Table 2). As |G| and |N  | can be very large, it is necessary to ﬁnd another
practical approach to solve the SDVRSP. Our solution approach is described brieﬂy as follows:
Step 1: Based on the initial schedule, deﬁne the set of backup trip (vehicle) candidates.
Step 2: For each backup trip, construct the corresponding feasible network.
Step 3: Solve the VRSP for each feasible network.
Step 4: Select the feasible network with the minimum scheduling cost.
In order to solve the VRSP, we need ﬁrst to generate the set of all possible feasible networks. This
task is based on the available capacity of the involved vehicles, time to reach the breakdown point
and the compatibility of itineraries among trips. Actually, the available capacity and travel time are
random variables, but in this deterministic model we use average values. Since some trips have common
itineraries, the passengers/cargo may be served incidentally by vehicles that cover compatible itineraries
after breakdown point. As we mentioned earlier, we need to avoid the situation where a backup vehicle is
traveling towards the breakdown point but all the passengers/cargo from the disabled vehicle have been
incidentally picked up by the vehicles that cover compatible itineraries with the cut trip.
From the viewpoint of the cut trip, the remaining trips can be divided into two categories: (1) unﬁnished
trips that have compatible itineraries with the cut trip from the breakdown point, and (2) the remaining

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1019

O1
D4

O3
X

D1

D2

O2
O4

D3

Fig. 5. Example of itinerary compatible trips.

unﬁnished trips. Fig. 5 illustrates these two categories where paths Oi − Di denotes trip i from origin Oi
to destination Di . The breakdown point is point X on trip 1. The set of compatible trips with trip 1 from
point X is {2, 3}.
Deﬁne set A to be the set of unﬁnished compatible itinerary trips with the cut trip from the point
X, ordered by the travel time from their current position to point X. Deﬁne set B to be the remaining
unﬁnished trips (including the trips directly from the depot). If the backup trip alternatives are from set
A, the backup vehicles can pick up the passengers/cargo incidentally. Although a reschedule may not be
necessary, it may be necessary to assign a vehicle from set B to cover unﬁnished trips originally assigned to
the disabled vehicle. If the backup trip alternatives are from set B, backup vehicles need to travel towards
the breakdown point for picking up the passengers on the disabled vehicle. The following procedure
Build-Feasible-Networks was developed to accomplish this task (where K is the set of all possible backup
trip candidates):
Procedure Build-Feasible-Networks
Step 1: Divide the unﬁnished trips in two different sets, A and B. Set K ← ∅.
Step 2: Find n∗ , the number of backup vehicles serving the trips in A 
 = ∅, using the routine described
in Fig. 6, where C(i) be the available capacity of the vehicle serving trip i when it reaches the breakdown
point, T (i) be its arrival time at the breakdown point, P be the capacity of the vehicle needed to serve
the breakdown trip, Td be the disruption time, and Tl be a time limit for a backup vehicle to arrive at the
breakdown point (only vehicles which arrive at the breakdown point before this limit Tl , are selected as
backup vehicle candidates).
Step 3: If the system has a feasible solution n∗ > 0, and an associated time T (an∗ ) by which the n∗
vehicles serve the passengers/cargo on the disabled vehicle, then we can determine B ∗ , the set of candidate
backup trips from set B, by using
B ∗ = {m|[Td  T (m) < T (an∗ ), ∀m ∈ B, ai is the ith element in set A(n∗ )] ∧ [T (m)  Tl ]}
where A(n) is the subset of A that includes the ﬁrst n elements of A.
Set K ← K ∪ B ∗ . Go to step 5.
Step 4: If the system of inequalities does not have a feasible solution, set T (n∗ ) ← ∞, and treat B ∗ as
B. Set K ← K ∪ B ∗ .

1020

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

Fig. 6. Routine ﬁnd_n∗ .

Step 5: For each backup trip candidate k ∈ K (corresponding to the assigned backup vehicle candidate),
build the corresponding feasible network.
Based on these feasible networks, we can model the SDVRSP as a SDVSP in each feasible network.
The optimal schedule of SDVRSP is the one with the minimum total cost over the set of all feasible
networks. The overall procedure, which we refer to as SA_VRSP, to obtain the optimal solution to VRSP
is based on the combined forward-backward auction algorithm developed by Freling et al. [6].
Algorithm SA_VRSP: Sequential Auction Algorithm for VRSP
Step 1: Based on the starting and ending times of trips and travel time between trips, apply the procedure
Build-Feasible-Networks to build the set of all possible feasible networks.
Step 2: Calculate the costs for the compatible trip pairs and the total delay cost of each feasible network.
Step 3: For each feasible network in G, apply the forward-backward combined auction algorithm
developed in [6] to ﬁnd the minimum cost scheduling of each feasible network.
Step 4: Select the minimal operating and delay cost scheduling as the solution.
4.4. Implementation
The DSS is designed to run in a platform-independent environment with the Internet browser. The
software system uses several programming languages. MySQL v4.0.17 is used to implement the database
management module. In order to implement the web-based interface, Apache v1.3.29 is used as the
web server. Apache is well known for its efﬁciency and stability. Moreover, PHP 4.3.4 is chosen as the
programming language for the interface. PHP has specially designed tools to access MySQL. A major
advantage of our system is that MySQL, PHP and Apache are all free software, and all of them
have different versions for multiple platforms. The VSP and VRSP algorithms are implemented using
standard C++.

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1021

5. Computational experiments
The main objective of the computational experiments is to evaluate the performance of the developed
auction-based algorithm, in terms of the required CPU time, to obtain the optimum solution. We used the
MIP network solver of the CPLEX, based on the formulation presented in Section 4.3, as the basis for
comparison.
The experiments were designed using Carpaneto et al.’s [29] random data generation method for VSP.
Let 1 , 2 , . . . , v be relief points (i.e., points where trips can start or ﬁnish) of a transportation network.
We generate them as uniformly random points in a (60×60) square and compute the corresponding travel
times a,b as the Euclidean distances between relief points a and b. Concerning the trips, we generate for
each trip Tj (j = 1, . . . , n) the starting and ending relief points, j and j , as uniformly random integers
in [1, . . . , v]. The time between trips Ti and Tj is deﬁned as i,j = i j . The starting and ending times,
sj and ej , of trip Tj were generated by considering two classes of trips: short trips (with probability 40%)
and long trips (with probability 60%). For short trips, bj is a uniformly random integer in (420,480) with
probability 15%, in (480,1020) with probability 70%, and in (1020,1080) with probability 15%, ej is a
uniformly random integer in (sj + j ,j + 5, sj + j ,j + 40). For long trips, sj is a uniformly random
integer in (300,1200) and ej is a uniformly random integer in (sj + 180, sj + 300). Costs cij ,csi and cj t
are deﬁned as follows:
1. cij = 10i,j + 2(bj − ej − i,j ), for all compatible pairs (Ti , Tj );
2. csi = 2000 for depot and trips Ti ; and
3. cj t = 
10 (Euclidean distance between depot and j ) + 2000 for trip Tj and depot.
In order to compare the computational efﬁciency of the auction-based algorithm and the MIP solver of
CPLEX we consider a situation in which the trips are composed of a combination of short (with probability
40%) and long (with probability 60%) trips. To evaluate the performance of the algorithms, we generate
ﬁrst a VSP problem and solve it. Then, disruption was introduced so that an early trip is chosen as cut
trip (trip Tb ). Since in real-life situations, determination of backup trips requires knowledge of vehicle
capacity and common itineraries whereas in the simulation trips are generated only by distance and travel
times, we simply assumed the possible number of backup trips to be among the number {2,3,5,10}. The
experiments were carried out on 900 MHz Sun Workstations.
Table 2 compares the performance of both algorithms. The ﬁrst three columns give the number of
remaining trips, the number of backup trips considered, and the average optimal cost. The next two
columns show the average CPU seconds, excluding input and output time, for the SA_VRSP and the
MIP CPLEX solver. The last column presents the gap between the two solution methods, computed as
follows:
CPUgap = 100 ×

CPUCPLEX − CPUSA_VRSP
CPUCPLEX

Larger CPUgap implies that the CPU for SA_VRSP is less than the CPU for MIP-CPLEX.
The average CPU time for both solution methods is highly dependent on the problem size. The tables
show that for small problems (100 remaining trips) both methods are fast, solving the problem in less
than 1s CPU time, even for high number of backup vehicle. The auction-based algorithm is more efﬁcient

1022

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

for all analyzed situations. On average, algorithm SA_VRSP reduces by 70.12% the required CPU time
for CPLEX to ﬁnd the optimum solution. The auction algorithm is more efﬁcient for small and mediumsized problems (until 1000 remaining trips). As the problem size increases, the auction algorithm slightly
reduces its efﬁciency. In summary, we can conclude that algorithm SA_VRSP is computationally efﬁcient
in schedule recovery applications.

6. Case study
To demonstrate the use of the rescheduling DSS, we present a case study based on the solid waste
collection services in City of Porto Alegre, Brazil. The solid waste collection involves 150 neighborhoods,
with a population of more than 1.3 million. More than 60 tons of solid waste are collected per day
and distributed to 8 recycling facilities. The collection and distribution of the solid waste are carried
out by a municipal company named DMLU, a Portuguese acronym for Departamento Municipal de
Limpeza Urbana (Urban Waste Municipal Department, in English). The recycling facilities are managed
by cooperatives, where members are mostly poor and are not part of the mainstream economy. In these
facilities, the solid waste is separated, appraised, stored, and commercialized. The proﬁt remains with the
cooperatives, making it an important income source for more than 450 workers. As a consequence, the
solid waste management program has balanced social and ecological beneﬁts [http://www.lixo.com.br
accessed 9 September 2004].
The collection is weekly performed on each street of the city. A requirement is that the solid waste
should be on the street for a maximum of 30 min before its collection. Severe ﬁnes might be imposed on
the residents who do not follow this rule. DMLU distributes informative leaﬂets giving the schedule of
the collection trucks for each street. The main purpose is to protect the proﬁts of the cooperatives that
run the recycling facilities, since other independent companies may collect the waste before DMLU.
A team of solid waste collectors is composed of one driver and three garbage collectors. There are
24 specially designed trucks to support the waste collection. On average, 23 trucks are used during
each shift.
Although the system is efﬁcient in terms of collection, the costs involved are high (around 35% of
the DMLU budget). Uncertain situations, such as vehicle breakdowns and problems in the recycling
facilities, have not been effectively incorporated. Consequently, managers in DMLU are concerned about
the efﬁciency of the existing waste-ﬂow methods. Furthermore, the current system generates unacceptable
schedules in terms of imbalanced trip assignments to recycling facilities (where some facilities may be
allocated excessive collection trips, while other facilities may be idle), which are rejected by the human
scheduler.
6.1. Experiment conﬁguration
The goal of the case study was to demonstrate the potential of the DSS as an effective and efﬁcient
operational planning tool for this logistics problem. The speciﬁc objective of the study was to answer
the following three questions: (1) What is the best routing and scheduling plan using the dedicated
collection vehicles? (2) What is a good routing pattern that has both good operating costs and balanced
trip assignment to each recycling facility? (3) What is the best scheduling strategy when an unexpected
event occurs and the original plan cannot be used?

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1023

Table 2
Simulation results
Remaining trips

Backup trips

Objective function value

Average CPU Time (s)
SA_VRSP

CPUgap (%)

CPLEX

100

2
3
5
10

137244
137182
137138
135804

0.038
0.055
0.091
0.180

0.162
0.244
0.409
0.808

76.54
77.46
77.75
77.72

300

2
3
5
10

344513
344477
341700
341700

0.394
0.607
1.022
2.078

1.819
2.726
4.549
9.133

78.34
77.73
77.53
77.25

500

2
3
5
10

558427
558422
558372
558326

1.507
2.258
3.752
7.623

5.976
8.973
14.952
29.914

74.78
74.84
74.91
74.52

700

2
3
5
10

752984
752882
752863
752824

3.621
5.399
9.051
18.126

12.573
18.900
31.493
63.040

71.20
71.43
71.26
71.25

900

2
3
5
10

950713
950695
950625
950281

6.779
10.157
17.002
35.629

23.564
35.394
58.933
117.794

71.23
71.30
71.15
69.75

1100

2
3
5
10

1140430
1140390
1139960
1139940

16.098
23.971
40.116
80.125

39.081
58.557
97.520
194.906

58.81
59.06
58.86
58.89

1300

2
3
5
10

1346500
1346470
1346400
1346370

23.157
35.162
59.395
120.564

59.004
88.568
147.449
295.093

60.75
60.30
59.72
59.14

In order to study these questions, we ﬁrst use the time schedules of all trips and travel time of deadheading trips to construct a feasible network for solving VSP; this answers the ﬁrst question. Then, the
number of trips which is assigned to each recycling facility is checked. If the assignment is not balanced,
the capacity issue is considered for each facility. A variation of auction algorithm is called to solve the
problem. Finally, to answer the third question, disruption was simulated where an early trip is chosen

1024

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

Fig. 7. Collection trips conducted on Monday morning.

as cut trip. Then candidates of backup vehicles are selected and corresponding feasible networks are
generated. The developed algorithm for VRSP is called to solve this problem.
The collection data for Monday morning was selected for our case study (see Fig. 7). All computational
experiments were conducted on a 900 MHz Sun Workstation.
6.2. Modeling the problem
The solid waste collection problem can be treated as a VSP/VRSP problem with a special structure.
Initially, all vehicles leave the depot to serve the collection trips. After serving a collection trip, the
vehicle must unload the collected solid waste in a recycling facility. Then, the vehicle can go back to
the depot or continue to serve a new compatible trip, if it can arrive in the starting place of the next
trip before its starting time. Two situations are not allowed in this service: (1) a vehicle comes from
the depot and directly goes to the recycling facility, and (2) after ﬁnishing its collection trip, a
vehicle directly goes to the depot or goes to serve a new trip without unloading its cargo at a
recycling facility.

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1025

Regular Trip

Deadheading
Dummy Arc

Recycle Unit
1

1

2

8

2
3

1

2

8
1

2

8

Fig. 8. An example of feasible network structure for the solid waste collection problem.

First, we need to construct a feasible network structure that simultaneously represents the problem and is in accordance with the algorithms implemented within the DSS. In this structure both the
collection trips and recycling facilities are represented as nodes. For each collection trip, we created
eight associated dummy trips which represent eight recycling facilities respectively. Fig. 8 illustrates
the network structure for this problem. The starting time of each recycling facility associated (RFA)
trip of a is the ending time of the corresponding collection trip plus the travel time from the ending point of its collection trip to the recycling facility. The duration of each RFA trip is the unloading and service times at the facility. After determining the starting and ending times of each such
RFA trip, we can construct the feasible network in such a way that a collection trip is connected
to all recycling facilities through eight RFA trips. There are no direct connections among collection
trips. Since in vehicle scheduling problems, every trip needs to be covered, we introduce dummy
arcs connecting the depot to all recycling facility nodes, and from these nodes to the depot (see Fig.
8). As a consequence, several dummy vehicle assignments are carried out only to fulﬁll this VSP
peculiarity. These dummy assignments are easily discarded in the ﬁnal solutions. For example, in
Fig. 8, trip 1 has eight RFA trips. Vehicles from the depot can go to trip 1, therefore there is an
arc from depot to trip 1. After serving trip 1, vehicle has to go to recycling facility to unload the
waste. Therefore, there are arcs from trip 1 to eight RFA trips. Since it is not allowed for a vehicle to go back to depot directly unless the waste is unloaded at the recycling facility, there is no arc
from trip 1 to depot. After unloading the waste at a recycling facility, the vehicle can go back to
the depot or serve next compatible trips. Thus, there is an arc from the recycling facility to the depot, and there are also arcs from recycling facility to trips 2 and 3. Since every recycling facility is
represented by a RFA trip, there are arcs from the depot to all RFA trips so that all of them can be
covered.
It should be noted that in order to simplify the analysis, we consider the distance traveled by each collection truck as the only variable operational cost involved. All remaining cost items are deﬁned as ﬁxed costs.
This is coherent with the public service characteristic of DMLU, where the costs related with personnel

1026

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

Table 3
Solutions for the VSP
Vehicle

Solution 1

Solution 2

Solution 3

Solution 4

Solution 5

V1
V2
V3
V4
V5
V6
V7
V8
V9
V10
V11
V12
V13
V14
V15
V16
V17
V18
V19
Distance (km)
Total Costs

T1-R8-T15-R5
T2-R8-T24-R8
T3-R1-T5-R8
T4-R1-T9-R1
T6-R6
T7-R5-T14-R5
T8-R1-T19-R1
T10-R5
T11-R1-T23-R1
T12-R1-T13-R6
T17-R5
T18-R8-T16-R8
T21-R1-T22-R1-T20-R8
T25-R8-T27-R8
T26-R1
T28-R8
T29-R1

T1-R8-T5-R8
T2-R8-T24-R8
T3-R6-T19-R2
T4-R2-T29-R7
T6-R7
T7-R5-T14-R5
T8-R3-T27-R8
T10-R2
T11-R3-T9-R6
T12-R6-T13-R6
T15-R5
T17-R5
T18-R1-T16-R1
T21-R7-T22-R1-T20-R8
T25-R1-T23-R4
T26-R4
T28-R1

455.00
295.79

457.10
296.05

T1-R8-T24-R8
T2-R8-T27-R8
T3-R6-T19-R6
T4-R1-T9-R4
T5-R8
T6-R3
T7-R2-T14-R5
T8-R3
T10-R2
T11-R3-T23-R4
T12-R6-T13-R4
T15-R5
T17-R5
T18-R1-T16-R4
T21-R4-T22-R4
T25-R6-T20-R1
T26-R4
T28-R6
T29-R4
452.90
323.52

T1-R8-T24-R8
T2-R6-T19-R4
T3-R6-T13-R6
T4-R3-T16-R1
T5-R8
T6-R7
T7-R5-T14-R5
T8-R3-T9-R1
T10-R2
T11-R4-T23-R7
T12-R6-T22-R3
T15-R5
T17-R2
T18-R1-T20-R7
T21-R4
T25-R8-T27-R8
T26-R5
T28-R1
T29-R7
462.50
324.74

T1-R4-T13-R6
T2-R8-T24-R8
T3-R6-T19-R6
T4-R7-T27-R8
T5-R8
T6-R7
T7-R5-T14-R5
T8-R1
T10-R4
T11-R3-T9-R1
T12-R6-T22-R1-T20-R8
T15-R5
T17-R4
T18-R1-T16-R1
T21-R7
T25-R7-T23-R7
T26-R7
T28-R1
T29-R7
488.30
328.01

and infra-structure do not depend on the productivity of the system. The total cost is deﬁned as follows:
C=

V

i=1

ci di +

V


fi ,

i=1

where ci is the average operational cost of vehicle based on its diesel fuel consumption (we used a value
of US$ 0.127/Km, considering the current diesel price in Brazil and the average diesel consumption
of the vehicles), fi is the average diary ﬁxed cost (this includes taxes, maintenance, etc.) of vehicle i
(deﬁned as a constant equal to US$ 14.00, based on DMLU databases), di is the distance travelled by
vehicle i (excluding waste collection trips), and V is the total number of vehicles used to collect the
solid waste.
6.3. Solving vehicle scheduling
Tables 3 and 4 present the results for the scheduling decisions. Table 3 gives a summary of the resulting
schedules, while Table 4 presents the assignment of collection trips to each recycling facility. In all tables,
T denotes a collecting trip, Vi denotes a vehicle i, and Rj denotes a recycling facility j. Solution 1 shows
the initial optimal schedule deﬁned by the DSS. Although this solution obtains the minimum cost, it
cannot be employed since several recycling facilities are not used, and the optimal solution is imbalanced
in terms of the use of the recycling facility capacities (see Table 4). Recycling facilities R2, R3, R4 and R7
are not used in this schedule, while R1 receives 9.2 tons, comparing with the average 7.5 tons collected

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1027

Table 4
Trip distributions in each recycling facility
Facility

Solution 1

Solution 2

Solution 3

Solution 4

Solution 5

1

T3 T4 T8 T9
T11 T12 T19
T21 T22 T23
T26 T29

T16 T18 T22
T25 T28

T4 T18 T20

T9 T16 T18
T28

T8 T9 T16
T18 T22 T28

T4 T10 T19
T8 T11
T23 T26

T7 T10
T6 T8 T11
T9 T13 T16
T21 T22 T23
T26 T29
T14 T15 T17

T10 T17
T4 T8 T22
T11 T19 T21

T11
T1 T10 T17

2
3
4

5
6

T7 T10 T14
T15 T17
T6 T13

T7 T14 T15
T17
T3 T9 T12
T13
T6 T21 T29

T1 T2 T5 T16
T18 T20 T24
T25 T27 T28

T1 T2 T5 T20
T24 T27

7

8

T3 T12 T19
T25 T28

T7 T14 T15
T26
T2 T3 T12
T13
T6 T20 T23
T29

T1 T2 T5 T24
T27

T1 T5 T24
T25 T27

T7 T14 T15
T3 T12 T13
T19
T4 T6 T21
T23 T25 T26
T29
T2 T5 T20
T24 T27

Fig. 9. Routine Dynamic Penalty.

by each trip (based on DMLU databases). This imbalanced scheduling solution is unacceptable by the
human schedulers taking into consideration the social beneﬁts of the solid waste program.
In order to obtain a more suitable solution, which compromises the social and ﬁnancial aspects involved,
we decided to restrict the number of trips assigned to each recycling facility. Penalties were introduced
in the auction algorithm implemented in the DSS to solve the VSP. Each time the number of trips serving
a recycling facility exceeds a given limit, all remaining arcs connecting trips to this speciﬁc recycling
facility are penalized, making them less attractive in the ﬁnal solution. Specially, the following routine
DynamicPenalty (see Fig. 9) was included of the auction-based algorithm developed by Freling et al. [6]
at the beginning of each iteration. Here penalties are dynamically imposed on arcs as the assignments are
performed at any iteration of a sub-problem. We decided to use penalties instead of constraints in order to

1028

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

avoid infeasibility. The given limit of each recycling facility is related to its capacity and the total number
of collection trips. Solution 2 in Table 2 presents the solution obtained using penalties with 4 as the given
limit for each recycling facility. Although the number of trips assigned to each recycling facility is not
equal, there is a signiﬁcant improvement in the results. All recycling facilities are now used (see Table 4).
We attempted to improve the solution by cutting arcs between trips and recycling facilities, and increasing/decreasing the number of trips using the less/over utilized facilities. Solutions 3–5 are the results
obtained for some cuts introduced in Solution 2. Solution 3 corresponds to a network in which all trips,
except T1, T5, T2, T24 and T27, are not connected to recycling facility 8. Solution 4 corresponds to the
network in which trips T20 and T25 are not connected to recycling facilities 8 and 1, respectively; while
solution 5 corresponds to situation in which the number of trips allowed to use recycling facilities 3 and 4
are increased to 6. None of the several attempts offered better results than solution 2 in terms of total costs
and balanced use of the recycling facility capacities. The number of vehicles increases from 17 to 19 in
solutions 3, 4 and 5. Although solutions 4 and 5 decreases the total distance traveled by the vehicles, they
are not interesting due to the need of extra vehicles, which increases the total costs. Solutions 3–5 were
therefore rejected by the human schedulers. Solution 2 was considered as the most suitable schedule.
A human scheduler also developed a schedule manually. Solution 2 reduces signiﬁcantly the costs
components in comparison with the solution of human scheduler. The number of vehicles reduced from
23 to 17 vehicles; and the traveled distance excluding waste collection trips decreased from 649.70
to 457.10 km; as a result, the total cost was reduced from US$ 404.51 to US$ 296.05, resulting in an
estimated saving of 26.81% for Monday mornings. Furthermore, the manual solution used only ﬁve
recycling facilities, leaving three units not being utilized.
6.4. Solving vehicle rescheduling
The following situation was addressed to answer what it is the best plan of action when an unexpected
event occurs. A possible breakdown of vehicle serving trip T3 at 8:50 was introduced in the initial
schedule proposed by the VSP (solution 2 in Table 3). The breakdown data was based on previous
statistics maintained by the DMLU. It should be noted that we assume that a vehicle in a collection trip
can change its recycling facility destination, but vehicles in deadheading trips should deliver the collected
waste at the recycling facility deﬁned in solution 2.
Since only a vehicle covers a speciﬁc street, itinerary compatible trips do not exist in this problem.
Therefore, in the algorithm Build-Feasible-Networks, set A is empty, and step 2 does not have a solution.
In this situation, B ∗ is treated as B. The human schedulers decided to set Tl = 9: 15, since a higher
value creates serious disturbances in the collection process. In this case, the backup vehicles candidates
comprise vehicles serving trip T12, trip T21, and an extra vehicle from depot.
Algorithm SA_VRSP, including routine DynamicPenalty in step 3 (to obtain a better balance in the
number of trips assigned to each recycling facility), was used to solve this disruption decision making
process. Tables 5 and 6 present the solutions obtained for the following three alternatives for the backup
vehicle: (i) the vehicle serving trip T12; (ii) the vehicle serving trip T21; and (iii) an extra vehicle from
depot. The total cost for each backup trip candidate k is
Ck =

V

i=1

ci di +

V

i=1

fi + cD k ,

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1029

Table 5
New schedules considering a breakdown in vehicle serving trip T3
Vehicle

Backup trip T12

Backup trip T21

Backup vehicle from depot

V1
V2
V3
V4
V5
V6
V7
V8
V9
V10
V11
V12
V13
V14
V15
V16
V17
V18
Distance (km)
Delay (min)
Total costs

T1-R8-T24-R8
T2-R5-T14-R5
T5-R1
T4-R4-T6-R3
T15-R5
T7-R2-T23-R4
T8-R3-T9-R1
T10-R2
T11-R3-T20-R3
T12-R6-T3-R6-T13-R3
T19-R6
T17-R2
T18-R8-T27-R8
T21-R6-T22-R2
T25-R1-T16-R8
T26-R3
T28-R6
T29-R4
446.70
1
308.98

T1-R6-T13-R6
T2-R6-T19-R6
T5-R8
T4-R4-T23-R4
T6-R4
T7-R5-T14-R5
T8-R3-T27-R8
T10-R2
T11-R4-T29-R3
T12-R4-T22-R7-T20-R7
T15-R5
T17-R2
T18-R7-T16-R6
T21-R7-T3-R7-T24-R8
T25-R1-T9-R1
T26-R7
T28-R6

T1-R6-T24-R8
T2-R4-T19-R6
T3-R4-T5-R8
T4-R1-T20-R4
T6-R4
T7-R5-T14-R5
T8-R3-T27-R8
T10-R4
T11-R3-T23-R5
T12-R4-T22-R3
T15-R5
T17-R4
T18-R1-T16-R1
T21-R7-T13-R6
T25-R1-T9-R6
T26-R3
T28-R1
T29-R4
496.80
10
317.59

453.10
3
296.29

Table 6
Trip distributions in each recycling facility
Facility

Backup trip T12

Backup trip T21

Backup vehicle from depot

1
2
3
4
5
6
7
8

T5 T9 T25
T7 T10 T17 T22
T6 T8 T11 T13 T20 T26
T4 T23 T29
T2 T14 T15
T3 T12 T19 T21 T28

T9 T25
T10 T17
T8 T29
T4 T6 T11 T12 T23
T7 T14 T15
T1 T2 T13 T16 T19 T28
T3 T18 T20 T21 T22 T26
T5 T24 T27

T4 T16 T18 T25 T28

T1 T16 T18 T24 T27

T8 T11 T22 T26
T2 T3 T6 T10 T12 T17 T20 T29
T7 T14 T15 T23
T1 T9 T13 T19
T21
T5 T24 T27

where c is the delay cost per unit time (the human schedulers deﬁned it as US$ 0.25/min, considering the
problem peculiarities), and Dk is the total delay (in min) for backup trip k.
The best solution is with the backup vehicle serving trip T21. This solution gives the lowest total cost,
an acceptable delay time (3 min) in accordance with the human schedulers, uses the same number of
vehicles as solution 2 (17 vehicles), and has the best distribution of waste among the recycling facilities
(see Table 6). Nevertheless, R4, R6, and R7 are overloaded in comparison to R1, R2, R3, and R8. We
compared the solutions given by human schedulers for this speciﬁc situation. They usually send a new

1030

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

vehicle from depot to backup the cut trip. In general, all trips in which this vehicle is scheduled are
delayed (at least for an hour) or cancelled, causing severe effects in the DMLU’s level of service. When
this happens, DMLU receives several phone calls from residents and the recycling facility managers,
complaining about the situation. Unfortunately, it is impossible to compute the ﬁnancial impacts, since
DMLU does not record data on disruptions.
Observe that the three scenarios introduced several changes in the initial schedule. Considering vehicle
schedules, the new schedule with trip T12 as the backup trip changes all vehicle schedules except the
vehicles serving trips T10 and T15. For the solution with backup vehicle from depot and the solution with
backup trip T21, only four vehicles keep their initial schedules. Observe also, as a consequence of vehicle
schedule changes, the trip distributions for each recycling facility also change. These changes can make
the crew rescheduling problem difﬁcult, since we have to guarantee that all teams know the itinerary of
each collection trip and how to drive to recycling facilities after the trips. This is not so serious in this
case study, since all teams know all trip itineraries. However, it may not always be the case. Although it is
almost impossible to obtain a solution for the VRSP without effecting the initial schedule, it is possible, in
order to decrease the number of possible changes in the initial schedule, to introduce penalties in the cost
of some arcs of the feasible networks. The implementation of these penalties will require modiﬁcations
in the auction algorithm. This is a topic of future research, with the objective of increasing the modeling
capabilities of the DSS.
In terms of computation times, we did not perform precise measurements on the test problems. Based
on approximate estimates, the VSP and the VRSP algorithms require 3–20 CPU seconds and 5–25 CPU
seconds, respectively, depending on the size of problems being solved. These times can be considered
acceptable given the complexity of the problems, and the human schedulers were very satisﬁed with the
DSS solution times.
Overall, the human schedulers responded positively to the prototype. The main advantage of the DSS
was to offer a tool for objective analysis, avoiding the evaluation of scheduling/rescheduling options
being based only on empirical factors or only simple operational and ﬁnancial measures. Analysis and
evaluation of the possible scheduling/rescheduling alternatives, through our model-based DSS, provides
a means to study each alternative with respect to several measures and make more objective decisions.
The possibility to alter operational scenarios interactively, to evaluate them in an efﬁcient and effective
manner, and to include real-world constraints and limitations make the DSS an effective tool for schedule
recovery.

7. Conclusions
This paper describes a decision support system for the single-depot vehicle scheduling/rescheduling
problem. The main objective of the DSS is to help human schedulers to ﬁnd optimal schedules with
and without unexpected incidents. The DSS can play an important role in the operational planning of
transportation/logistics companies.
The developed DSS introduces a systematic procedure for prescriptive decision-making for both
scheduling and rescheduling due to disruptions. The approach helps to solve the complex problem of
recovery from severely disrupted trips. Computational experiments to evaluate the performance of the
algorithms, by comparing the developed algorithm with the MIP solver of CPLEX, using randomly generated data, show that the DSS has potential as an effective and efﬁcient tool for real-time operational

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

1031

planning in transportation/logistic companies. A case study was used to illustrate the developed DSS and
its use in an actual system.
Future research is directed towards the following: (i) the expansion of the modeling capabilities with
the inclusion of additional constraints in our VRSP formulation, restricting the number of trips that are
rescheduled for a vehicle; (ii) the integration of the crew scheduling problem into the DSS; and (iii) the
improvement of the computational capabilities of the DSS.
Acknowledgements
This paper was written while the second author visited the ATLAS Center at the University of Arizona,
through funding by CAPES, Brazil. The ﬁrst and third authors acknowledge the support received for this
research from USDOT/FHWA and Arizona DOT through their sponsorship of the ATLAS Programs.
References
[1] Meecham M. Airport trafﬁc increase reﬂects airline recovery. Aviation Week and Space Technology 1995;143(5):36.
[2] Ichoua S, Gendreau M, Potvin JY. Diversion issues in real-time vehicle dispatching. Transportation Science 2000;34:
426–38.
[3] Baita F, Pesenti R, Ukovich W, Favaretto D. A comparison of different solution approaches to the vehicle scheduling
problem in a practical case. Computers and Operations Research 2000;27:1249–69.
[4] Bodin L, Golden B. Classiﬁcation in vehicle routing and scheduling. Networks 1981;11:97–108.
[5] Daduna JR, Paixão JM. Vehicle scheduling for public mass transit—an overview. In: Proceedings of sixth international
conference on computer-aided scheduling of public transport. Boston, MA; 1995. p. 76–90.
[6] Freling R, Wagelmans A, Paixão J. Models and algorithms for single-depot vehicle scheduling. Transportation Science
2001;35:165–80.
[7] Bokinge U, Hasselstrom D. Improved vehicle scheduling in public transport through systematic changes in the time-table.
European Journal of Operational Research 1980;5:388–95.
[8] Amico D, Fischetti M, Toth P. Heuristic algorithms for the multiple depot vehicle scheduling problem. Management
Science 1993;39:115–25.
[9] Jonker R, Volgenant T. Improving the Hungarian assignment problem. Operations Research Letters 1986;5:171–6.
[10] Song T, Zhou L. A new algorithm for the quasi-assignment problem. Annals of Operations Research 1990;37:205–23.
[11] Paixão JM, Branco I. A quasi-assignment algorithm for bus scheduling. Networks 1987;17:249–69.
[12] Bertsekas D, Eckestein J. Dual coordinate step methods for linear network ﬂow problems. Mathematical Programming
1988;42:203–43.
[13] Psaraftis HN. Dynamic vehicle routing: status and prospects. Annals of Operations Research 1995;61:143–64.
[14] Ghiani G, Guerriero F, Laporte G, Musmanno R. Real-time vehicle routing: solution concepts, algorithms and parallel
computing strategies. European Journal of Operational Research 2003;151(1):1–11.
[15] Gendreau M, Potvin JY. Dynamic vehicle routing and dispatching. In: Crainic T, Laporte G, editors. Fleet Management
and Logistics. New York: Kluwer; 1998. p. 115–26.
[16] Yang J, Jaillet P, Mahmassani H. Real-time multivehicle truckload pickup and delivery problems. Transportation Science
2004;38:135–48.
[17] Laporte G, Louveaux FV. Solving stochastic routing problems with integer L-shaped method. In: Crainic T, Laporte G,
editors. Fleet management and logistics. New York: Kluwer; 1998. p. 159–67.
[18] Powell WB, Jaillet, P, Odoni A. Stochastic and dynamic networks and routing. In: Ball MO, Magnanti TL, Monma CL,
Nemhauser GL, editors. Handbooks in operations research and management science, Network Routing. Amsterdam, The
Netherlands: North-Holland; 1995. p. 141–295.
[19] Carlson PM. Exploiting the opportunities of collaborative decision making: a model and efﬁcient solution algorithm for
airline use. Transportation Science 2000;34:381–93.

1032

J.-Q. Li et al. / Computers & Operations Research 34 (2007) 1008 – 1032

[20] Lettovský L. Airline operations recovery: an optimization approach. PhD thesis. Georgia Institute of Technology USA,
1997.
[21] Rosenberger JM, Johnson EL, Nemhauser GL. Rerouting aircraft for airline recovery. Transportation Science 2003;37:
408–21.
[22] Teodorović D, Stojković G. Model to reduce airline schedule disturbances. Journal of Transportation Engineering
1995;121:324–31.
[23] Huisman D, Freling R, Wagelmans A. A robust solution approach to the dynamic vehicle scheduling problem.
Transportation Science 2004;38:447–58.
[24] Li JQ, Mirchandani PB, Borenstein D. Parallel auction algorithm for bus rescheduling. In: Proceedings of ninth international
conference on computer-aided scheduling of public transport. California, USA: San Diego; 2004.
[25] Desrochers M, Lenstra JK, Savelsbergh MWP, Stougie L. Towards a model and algorithm management system for vehicle
routing and scheduling problems. Decision Support Systems 1999;25:109–13.
[26] Basnet C, Foulds L, Igbaria M. Fleet Manager: a microcomputer-based decision support system for vehicle routing.
Decision Support Systems 1996;16:195–207.
[27] Nussbaum M, Sevulpeda M, Cobian A, Gaete J, Parra E, Cruz J. A fuel distribution knowledge-based decision support
system. Omega 1997;25:225–34.
[28] Ruiz R, Maroto C, Alcaraz J. A decision support system for a real vehicle routing problem. European Journal of Operational
Research 2004;153:593–606.
[29] Carpaneto G, Dell’Amico M, Fischetti M, Toth P. A branch and bound algorithm for the multiple depot vehicle scheduling
problem. Networks 1989;19:531–48.

256

I E E E J O U R N A L OF R O B O T I C S A N D A U T O M A T I O N . VOL. 4. N O . 3 , J U N E 1988

Concurrent Routing, Sequencing, and Setups for a
Two-Machine Flexible Manufacturing; Cell

Abstract-An approach proposed for scheduling o f Flexible Manufacturing Systems (FMS) i s to sequentially solve three related subproblems,
commonly referred to as the “FMS loading,” “job routing,” and
“operation sequencing” problems. However, the use of this approach
results in assigning a fixed set of resources for each machine prior to
sequencing, and thus may unnecessarily restrict the capability of the
flexible manufacturing system, especially if the machines are very
versatile.
In this paper, we present an approach which allows in-process
“machine loading” through magazine setups, and which concurrently
routes and sequences the jobs on the versatile machines.
To illustrate the concurrent approach, a specific two-versatile-machine
flowshop scheduling problem, referred to as 2-VFSP, i s defined and
studied i n detail. Theoretical results show that the optimal schedule f o r 2VFSP need not have more than two in-process magazine setups, giving
rise to the three possible scheduling configurations. Further, i t i s proven
that to obtain the optimal schedule i s an NP-complete problem.
A heuristic i s developed and tested on sets o f random joblists, with
different setup times corresponding to varying degrees o f machine
versatility. Results indicate that schedules which incorporate in-process
magazine setupb) may be more desirable when the setup time i s small.
Thus the use of concurrent scheduling approach which allows in-process
magazine setups may be especially useful f o r systems with very versatile
machines.

I. INTRODUCTION

HE ADVANCEMENTS in integrated automation, comT p u t e r , and machine tool technology have led to the
development of machines which are versatile. For example, a
modern numerically controlled (NC) machine can automatically perform many different operation types, and can now
replace several conventional machines. Such versatile machines are especially attractive to the mid-volume production
sector of the metal-working industry where ‘‘flexibility’’ has
become an important and desirable feature [ 151. When these
NC machines are further automated and integrated by advanced computer technology, a new mode of manufacturing
emerges in the form of a Flexible Manufacturing System
(FMS) [41.
In particular, a Flexible Manufacturing Cell (FMC) is a
class of FMS’s consisting of two or more versatile machines
(such as machining centers) with a material handling system
that can transport partpieces to the machines within the cell
Manuscript received December 17, 1986; revised September 4, 1987. This
work was partially supported by IBM under Grant on Manufacturing
Education, and by the FMS Program at RPI sponsored by ALCOA, GE, GM,
KODAK, and RCA. Part of the material in this paper was presented at the
1986 IEEE International Conference on Robotics and Automation, San
Francisco, CA, April 7-10, 1986.
The authors are with the Electrical, Computer, and Systems Engineering
Department, Rensselaer Polytechnic Institute, Troy. NY 12180.
IEEE Log Number 8718906.

quickly (such as a robot). The operational design of FMC’s are
becoming increasingly important especially since recent surveys [4], [16] indicate that both the users of flexible
automation and machine tool makers have begun emphasizing
a step-by-step approach, starting with small-scale flexible
manufacturing cells.
An important aspect of the operational design of an FMC
involves scheduling. In this paper, we shall study a specific
two-versatile-machine FMC. Section I1 explains the “concurrent strategy” undertaken in developing the scheduling algorithm. This is followed by a section on notation and
definitions. Some theoretical results and heuristics for the
problems are reported in Section IV. Schedules of sets of
random joblists are developed using the heuristics. Finally,
Section V concludes with a discussion on this scheduling
strategy, and some possible research extensions.
11. THE“CONCURRENT”
SCHEDUI.ING
STRATEGY

Briefly, scheduling includes the basic decisions of routing
(machines-to-a-partpiece allocation) and sequencing (partpieces-to-a-machine assignment). In the traditional dedicatedmachine environment, each machine can only perform one
operation type, and, therefore, the technological constraints of
the processing needs dictate the route for each partpiece.
Consequently, the corresponding operational scheduling problem reduces to only the sequencing of the partpieces.
In the FMC versatile-machine environment, since each
machine can perform more than one operation type, a
particular operation of a partpiece may bc performed by more
than one machine. This enables each partpiece to have several
alternative routings through the machines. Thus the corresponding operational scheduling problem involves both routing
and sequencing.
In essence, the significant difference between the dedicatedmachine environment and the versatile-machine environment
lies in that the only scheduling concern in the former case
depends solely on the characteristics of the processing
requirements of the partpieces such as job precedence and
operations ordering. Scheduling in the latter case, however,
requires the consideration of the capabilities (versatility) and
constraints (tool magazine capacity limitation) of the machines
in addition to the processing requirements of the partpieces.
When the total number of tools required to process all the
partpieces does not exceed the magazine capacity of each
machine, then each partpiece can basically be processed on
any of the machines. If the partpiece requires a tool that is
resident in the tool magazine, then a tool exchange occurs

0882-4967/88/0600-0256$01.OO 0 1988 IEEE

LEE AND MIRCHANDANI: TWO-MACHINE FLEXIBLE MANUFACTURING CELL

257

between the machine spindle and the magazine. This tool a tool-task. A dedicated machine can perform only a single
exchange, sometimes also referred to as the spindle-setup, is tool-task, while a versatile machine can perform a number of
performed automatically with negligible setup time, and this is different tool-tasks depending on the number of tools its tool
what basically constitutes the versatility feature of the ma- magazine can hold. The maximum number of distinct tooltasks that machine i can perform without the need for
chine.
However, in most practical applications, the total number of additional magazine setup corresponds to the size of its tool
tools exceeds the magazine capacity. In this case, three magazine capacity C;. Thus for a total number of N distinct
possible situations may occur when a partpiece arrives at the tool-tasks among the jobs-and hence, N distinct tools
machine. The first two situations occur when the required tool required-and a tool magazine capacity of size C,,, among the
to process the partpiece 1) is resident on the spindle, or 2) is machines, at least rN/Cmaxldifferent tool-sets need to be
available on the tool magazine. In these situations, either 1) no loaded.
An operation consists of one or more tool-tasks. An
setup, or 2) an automatic tool exchange takes place.
If, however, 3) the required tool is not resident in the operation that may be performed by tool-set j is referred to as
magazine, then another type of setup may be required. This an operation type j . To the machines, each operation type
setup, referred to as a magazine setup, involves the replace- corresponds to one of its possible feasible tool-sets that can be
ment of some or all of the tools in the magazine. In scheduling loaded on its magazine.
a set of partpieces, the number of times that magazine setups
As an illustration, suppose three types of partpieces, A , B ,
are performed depends on the tool allocation and the tool and C , are to be scheduled in a production cycle, requiring,
distribution strategies employed by the tool management respectively, tool sets { 1, 2, 3}, (4, 5 , 6 } , and { 1, 5 , 6 ) (note
system (TMS). In addition, the amount of time needed to N = 6 ) . Suppose we have a single versatile machine with C,,,
perform each magazine setup will depend on the FMC and = 4. If operation type X corresponds to tool set { 1, 2, 3, 4)
TMS technologies of the system; it may range from a and operation type Y to { 1, 2, 5 , 6 } , then part A requires only
negligibly short time interval to a significant amount of time. operation type X , part C requires only operation type Y , and
By allowing in-process magazine setups to take place, the part B requires both operation types. Thus scheduling in our
versatility of the machines in an FMC can be utilized to their context is viewed in terms of partpieces, each partpiece being
fullest potential, and at the same time, a greater number of part defined as a job comprised of operations, and each operation
types may be processed during a production period due to the belonging to an operation type.
increased system flexibility. In the concurrent scheduling
IV. THE2-VFSP PROBLEM
strategy developed in this paper, the scheduling decisions
involving routing and sequencing are performed concurrently
A scheduling problem can be described in terms of its shop
and are integrated with decisions on if and when any magazine characteristics, its job characteristics, and the optimality
setups are to be performed.
criterion with which the evaluation of each schedule can be
In the literature, only a few research studies related to this made (see, e.g., [3]). The specific 2-VFSP problem studied
type of magazine setups have been reported. Hankins and here is described below using this framework.
Rovito [7] conducted computer simulations and reported
performance results for two different magazine setup strate- Shop Characteristics
gies. They concluded that a comprehensive tool management
The shop consists of two identical machines, P and Q;
system is essential to the success of an FMS.
each with a tool magazine of equal finite capacity C .
In her investigation of automated tooling for FMS’s,
Each machine can perform all operations of the two
ElMaraghy [5] concluded that, irrespective of the selected
different operation types, X and Y .
level of automation, productivity can be maximized and idle
Each machine can perform only one operation at a time.
time minimized through the increased utilization of machines
Each operation type corresponds to C tools.
by ensuring the availability of the necessary tools when
The setup operation, S x y (Syx),
changes the tool-set for
needed-using in-process magazine setups.
operation type X ( Y ) with the tool-set for operation type
Tang and Denardo [13], [14] considered the problem of
Y ( X ) . Both setup operations are assumed to take the
finding the sequence in which to process a joblist on a single
same amount of time to perform; the time may be
machine and the tools to load on the machine, if necessary,
negligible, or finite.
before each job is processed. The two optimality criteria
A setup operation must be performed when the machine
considered were the minimization of the total number of tool
needs to perform the other operation type.
switches, and the minimization of the total number of instants
The transfer or transport time of a partpiece from one
at which tools are switched. The procedures developed for
machine to the other is negligible.
each optimality criterion were also extended to the case with m
Job Characteristics
machines in sequence.
Each partpiece requires a job composed of one operation
111. NOTATION
A N D DEFINITIONS
of type X , followed by one operation of type Y .
For each physical partpiece is associated a “logical” entity
The operations cannot be performed simultaneously on a
referred to as its job, which describes its processing needs.
partpiece.
The processing activity requiring a single tool is referred to as
The type X operation must be completed before its type

258

IEEE JOURNAL OF ROBOTICS AND AUTOMATION, VOL. 4, NO. 3. JUNE 1988

Y operation may commence. This corresponds to an
operation precedence constraint.
All partpieces are immediately available for processing
once production begins.

GANTT CHARTS

ROUTINGS

Optimality Criterion
To minimize the makespan of the schedule for the given
joblist.
Clearly, this problem resembles the well-known conventional two-machine flowshop problem [9] except that it has
versatile machines rather than dedicated machines. In the
dedicated machine environment, a flowshop is defined in
terms of workstations (or machines): the routing of each job
through the workstations is the same. Thus a sequencing of the
jobs defines a schedule for the flowshop. For the versatile
machine environment, even when the operation order is the
same for each of the jobs (type X operation before type Y
operation), jobs may have different routings (some jobs may
be done on a single machine, others may be done on both
machines; see, for example, Fig. 1). In this context, we define a flowshop in terms of operation types: the operations
precedence order of each job is the same. It is for this reason
that we refer to this problem as the two-versatile-machine
flowshop scheduling problem (2-VFSP).

A . Some Theoretical Results
We present here two theoretical results specific to our 2VFSP problem. The first, Theorem 1 and its corollary, shows
that the optimal schedule requires at most two setups-each
one on a different machine. The second, Theorem 2, states
that the 2-VFSP problem belongs to the class of “difficult”
problems known as NP-complete [6].

Theorem I : For the 2-VFSP, an optimal schedule exists
with at most two setups, of which at most one is in each
machine and both are of the S X ytype.

5xY

P

Q
sx(

(C)
Fig. 1. The three possible configurations of the optimal schedule and the
corresponding routing patterns for the partpieces. (Doubly cross-hatched
region represents setup operation.) (a) Zero-setup schedule. (b) One-setup
schedule. (c) Two-setup schedule.

type Y operations, the resultant new schedule remains
feasible. However, the setups immediately before and after
this S y X setup, if any exist, are of Sxy type. Thus the
interchange will make these S X y setups redundant and eliminate their need, but will require an S X y in place of the Syx
setup.
Clearly, therefore, any feasible schedule with S y X types of
setups can undergo a series of such interchanges until at most
one setup, an S X y setup, results on machine P.
The “interchange” process done on one machine is
performed independently without affecting the original schedule of the other machine. Thus the same “interchange”
process can be performed on machine Q , if there exist any
SyXsetups, until machine Q will also have at most one setup,
an S X ysetup. Therefore, if we have an optimal schedule with
more than one setup on either machine, we can perform these
“interchanges” until we have at most one Sxysetup on each
machine and still remain optimal. This completes the proof.

When the setup time is nonzero, we have a stronger result,
Proof: Without loss of generality, we first show that all namely Corollary 1 below, which states that an optimal
SYX setups in a machine, if any exist, can be removed in a schedule will not have more than two necessary setups. We
feasible schedule to obtain another feasible schedule with only state this corollary without proof.
one Sx, setup on this machine without increasing the
Corollary I : For the 2-VFSP, if the setup time is nonzero,
makespan.
then an optimal schedule is one which has no more than two
Consider a feasible schedule that has an S y X type setup on,
setups, both being of the S X ytype, and of which at most one is
say, machine P. Thus there is a set of consecutive jobs whose
on each machine.
type Y operations are scheduled immediately before this setup. Since the schedule is feasible for the given precedence
Theorem 1 and Corollary 1 provide valuable information
constraints, the type X operation of each of these jobs must concerning the possible configuration of the optimal schedule,
have been scheduled to be completed before any of the type Y and its corresponding routing pattern. Note that the optimal
operations commence. (These type X operations may have solution of the 2-VFSP provides both the sequencing and the
been scheduled on either of the machines.) Therefore, if the routing decisions concurrently. In all, there are three possible
type Y operations are rescheduled to be processed at a later optimal schedule configurations-with zero, one, or two
setups. Fig. 1 depicts these configurations with the correstime, the resultant schedule will still remain feasible.
Similarly, if the set of consecutive type X operations that ponding routing patterns.
The existence of three possible configurations of the optimal
are scheduled immediately after this Syxsetup are rescheduled
to be processed at an earlier time, the schedule will remain schedule suggest an approach to solve the 2-VFSP which
involves solving a subproblem corresponding to each configufeasible without any increase in the makespan.
Hence, if these two sets of operations are interchanged so ration. These subproblems shall be referred to as zero-setup,
that the set of type X operations are scheduled before the set of one-setup, and two-setup problems, respectively. The first

259

LEE AND MIRCHANDANI: TWO-MACHINE FLEXIBLE MANUFACTURING CELL

subproblem corresponds to the conventional two-machine
flowshop problem which is solved optimally by the polynomial-time algorithm of Johnson [9]. However, for the other
two subproblems-the one-setup and two-setup problemsthere are no known algorithms.
The next theoretical result, Theorem 2, states that 2-VFSP
belongs to the class of problems known as NP-complete, such
as the traveling-salesman problem, which has defied attempts
for exact solutions, short of some type of enumeration of all
feasible solutions. In essence, it is suspected that no polynomial-time algorithm exists which exactly solves all problem
instances of an NP-complete problem; in the unlikely event
that a polynomial-time algorithm exists for an NP-complete
problem, then all problems in this class are solvable in
polynomial time.

iii) processing times for type Y operations being en+I =
cn+2 =
= ~ 2 ~ -=2 0 , c ~ =~3M- - ~2K, and
ch = 2h4where
*

e

*

n

M=

We claim that there exists a subset S C { 1, 2,
c,=K

if and only if there exists an E C { 1, 2,
cj+

ts =

e ,

2n) such that

ts.

cj+
jBE

(Zfi) Clearly, since c2,- and c2, adds up to
n

5 M - 2 K > z cj
j=I

they must be separated and each performed on a different
machine. Hence, since e,, = 0, we have

c

T WO-SETUP:

-

e ,

j€S

/€E

Given n jobs, each job i requiring integer operation times of
c; and en+;(with c; preceding e,+;), corresponding to the
first and the second operation type, respectively, and setup
time of ts, is there a schedule such that for S C { 1, 2, *
2n), we have

*

n - 2) with

Theorem 2: 2-VFSP is NP-complete.
Proof: To prove Theorem 2, it suffices to show that at
least one of the subproblems is NP-complete and that each
subproblem of 2-VFSP is either polynomially solvable or NPcomplete.
We first prove that the two-setup problem is NP-complete.
This subproblem may be formulated as a decision problem as
follows:

K.

cj>
j=I

jES

cj

+ ts + C2,.

Since

a ,

cj=M-C

C c j + t s = c cj+ts ?

j ES

jES

j + 2 n - 1.2n

i BS

j€S

it follows directly from arithmetic that
Clearly, TWO-SETUP is in NP since a nondeterministic
algorithm need only to guess a subset S of { 1, 2, * , 2 n } and
check in polynomial time that the total processing time of the
operations in S is the same as that for the rest of the operations,
and that the precedence constraint has not been violated.
Now consider the following well-known NP-complete
problem:

c,=K.

- -

0-1 KNAPSACK:
Given integers cj, j = 1, * * , n and K, is there a subset
S E (1, 2,
n ) such that
-

a

-

,

C c,=K?

j€S

(Only $) Suppose that
cj=K
j€S

for some S C { 1, 2,
ately that

c
j ES

j€S

There exists a polynomial transformation for a problem
instance from 0-1 KNAPSACK to TWO-SETUP, as follows:
and K
Given any instance of (n - 2) integers c1,
,
of 0-1 KNAPSACK, we construct the following instance of
T WO-SETUP with:

- -

i) a setup time of ts 2 0;
ii) processing times for type X operations of n jobs, being
cl, . . * ,
e,,
= c, = 0;

* *

, n - 2). Then it follows immedi-

cj+ts+c2,-1=

cj+ t s + ~ 2 n *
jBS
jf2n-I32n

Next, we need to show that the precedence constraint has
not been violated. Clearly, since e,- I = Cn = Cn+ 1 = * * c ~ =~ 0, - no ~operation pair c; and en+; violates that
constraint.
This proves that TWO-SETUP, and hence, the two-setup
problem, is NP-complete.
In a similar fashion, the one-setup problem can be
formulated as a decision problem, and proved to be NPcomplete.
Finally, since the zero-setup problem is polynomially
solvable, it follows that each subproblem of 2-VFSP is either

260

IEEE JOURNAL OF ROBOTICS AND AUTOMATION, VOL. 4 , NO. 3, JUNE 1988

polynomially solvable or NP-complete. Hence 2-VFSP is NPcomplete.

1
Obviously, the results of Theorem 2 suggest that it is
impractical to develop exact algorithms to solve the one-setup
and two-setup problems optimally. Thus heuristics that solve
these NP-complete subproblems of 2-VFSP suboptimally have
been developed and described in the next subsection.

B. Heuristics for 2- VFSP
As mentioned before, there already exists a known (Johnson’s) algorithm that optimally solves the zero-setup subproblem. In this section, we describe two heuristics, ONE-SETUP
and TWO-SETUP developed for the one-setup, and the twosetup subproblems, respectively.

The One-Setur, Case
One may make several important observations on the
characteristics of the one-setup schedule. Fig. 2 shows a onesetup schedule with machine P as the setup machine. In this
schedule, there are essentially two classes of jobs. The first
class consists of “2-machine’’ jobs, each using both machines
to process it-in this case, type X operation is performed on
machine P, and type Y on machine Q. The second class
consists of “1-machine’’ jobs each having both of its
operations processed on one machine, the setup machine. In
this case, machine P is the setup machine.
One-setup scheduling can thus be viewed as the simultaneous scheduling of these two job classes so as to minimize the
makespan. Clearly, due to the operation precedence constraint
on each job, any schedule obtained by sequencing the “2machine” jobs will inevitably incur idle periods If and ZQ for
machines P and Q, respectively. The optimal schedule,
therefore, essentially “fits” the set of “1-machine’’ jobs (plus
the setup operation) into the idle period of the setup machine.
Therefore, to obtain the optimal one-setup schedule, it is
necessary to identify both the setup machine and the two job
classes.
We next observe that Johnson’s (zero-setup) schedule
consists of only “2-machine’’ jobs; and it minimizes not only
makespan, but also the idle periods on each machine. The onesetup scheduling heuristic in essence improves on the zerosetup schedule by shortening the makespan by “moving”
some operations from one machine (with the shorter idle
period) to the other machine.
Note that there may be cases when the one-setup schedule
for a joblist becomes undesirable. This occurs when the sum of
the setup time and the smallest processing time among the jobs
performed by the nonsetup machine is greater than the idle
period of the setup machine in the zero-setup schedule. In this
case, a setup on either of the machines would, instead,
increase the makespan of the zero-setup schedule. In the
algorithm presented below, we include a check to ensure that
the determination of the one-setup schedule terminates when
this case occurs.
ONE-SETUP (Heuristic I )

Step I (To select the setup machine):

I-Machine

lobs

P
TYPO Y

I

Fig. 2 . One-setup schedule with P as a setup machine.

Obtain the zero-setup schedule using the Johnson’s algorithm. Let If be the total idle time for machine P and IQ for
machine Q. The setup machine, say M , is selected to
correspond to the machine with the larger total idle time; that
is, I,,,, = max (Ip, le).
Termination Check. Let b = max {min (c,,i = 1, ., n ) ,
min (c,, j = n + 1,
2 n ) ) . If ts > (IM
- b ) , stop (a onesetup schedule cannot be optimal), otherwise, go to step 2.

-

e ,

Step 2 (To identify the set of 1-machine jobs):
Let T denote the “desired” total processing time of the
operation9 reassigned from the nonsetup machine to the setup
machine, where T = (IM
- ts)/2.
From the initial zero-setup schedule in step 1, select the
operations on the nonsetup machine that have a combined total
processing time “closest” to T. The jobs corresponding to the
selected operations will be the 1-machine jobs; the rest form
the 2-machine jobs.
Step 3 (“Fitting” the 1-machine jobs in the setup machine):
Obtain the partial zero-setup schedule for the 2-machine
jobs using the Johnson’s algorithm. Then, fit the 1-machine
jobs into the partial schedule by sequencing them in the idle
period of the setup machine so that their type X operations are
processed first, followed by a setup, and then their type Y
operations.
The Two-Setup Case
In the two-setup schedule, generally there are three job
classes assigned on each machine; a set of 1-machine jobs, a
subset of 2-machine jobs having type X operation on this
machine, and the complementary subset of 2-machine jobs
having type Y operation on this machine.
The scheduling heuristic for the two-setup case involves
two steps. First, an initial schedule consisting only of 1machine jobs for each machine is determined using a
partitioning heuristic. The second step is a refinement that
tries to improve on the initial schedule by balancing the
workloads on the machines. This is achieved by identifying a
subset of the 1-machinejobs which will give a more balanced
workload if their operations are distributed so that each
machine performs one operation-thus transforming them into
2-machine jobs. (A 0-1 KNAPSACK heuristic may be
employed in this refinement step.)
TWO-SETUP (Heuristic 2)
Step I (Partition the 1-machine jobs):
Treat each job i as a 1-machine job with an integer value,
di = (ci + c,+;),corresponding to the combined processing
times of both its operations.

’ We can use a 0-1 KNAPSACK heuristic for this selection, with K
(see, e . g . , [SI).

=

T

26 1

LEE AND MIRCHANDANI: TWO-MACHINE FLEXIBLE MANUFACTURING CELL

Partition these n integers (on the two machines) so as to
minimize

12

TABLE I
JOB PROCESSING TIMESFOR THE ILLUSTRATIVE EXAMPLE

Job Name

d J - C dJ
j BS

e ,

-

a) Sort the jobs such that dill 2 dI2, * L dlnl,where [i]
denotes the job number of the ith largest combined
processing times in { d l ,d2, * d n } .
b) If all jobs have been assigned, then stop.
Otherwise, assign the current largest job to the machine
with the smaller interim total processing time. Repeat
this until every job has been assigned.

C

B

- - .

-

~

3
4

5
2

7
1

8
5

2
6

Total

7

7

8

13

8

2 A

5 I
E

0

12 13

25

18 20

25
18

26

(a)

0

Total
_ _

ROUTINGS

D
13
l 8 I8l C 2(
1 A fl D I 8 v / / / h i
8

2

_

mDB

GANTT CHARTS
0

~

D
E
_____ ~ _

X
Y

e ,

Step 2 (Refinement to balance workload):
Let CO be the smallest processing time for all the operations,
where CO = min {c;;i = 1,
2n}.
Let Tp and TQbe the total processing times of machines P
and Q, respectively, and denote their difference by D,where
D = ITp - Tel.

A

~-

with S C { 1, 2,
n } , using the following first-fit
decreasing heuristic for the bin-packing problem (see, e.g.,

PI).

---

Operation
Type

IS

IO

2

P

Q

- e . ,

0

3

5

IS

9

2 0 22

23

(b)
0

P

8

I 1 13

18

D A

22

’

Q
a) Let machine M be the machine with maximum total
O
S
12 14 16 17
23
C.E
processing time TM = max ( T p , TQ).
(C)
If there are no more 1-machinejobs on machine M , then Fig. 3. The schedules and their corresponding routing patterns for the three
subproblems of the illustrative example. (a) Zero-setup schedule. (b) Onestop.
setup schedule. (c) Two-setup schedule.
Otherwise
i) If D < 2c, then stop.
time periods, with I p = 1 and IQ = 8. Hence, machine Q is
ii) Otherwise, from the 1-machinejobs on machine M , identified as the setup machine, and I,,,, = IQ = 8.
identify the job j which has one of its operation Step 2:
times being “closet” to 0 1 2 .
Now, T = IM - tJ2 = 3. From those operations on the
If Icj - 0 / 2 ( < JC,+~ - D / 2 ) , then classify job non-setup machine ( P ) ,we select job A as a (in this case, the
j as a 2-machine job by distributing its operations SO only) 1-machinejob because its type X operation time (A, =
that its type Y operation remains on the same 3) is “closest” to T.
machine, but its type X operation is reassigned to Step 3:
the other machine.
Implementing the Johnson’s algorithm for the 2-machine
- 0/21 > ( c ~ -+ D/21,
~
then split job j so jobs { B , C, D , E } , we obtain the partial schedule which has
If
that its type X operation remains on the same an idle time of 8 units on the setup-machine Q . Rescheduling
machine, but its type Y operation is reassigned to the operations on machine Q so that all existing idle time
the other machine. (Break ties arbitrarily.)
occurs before job E (the first job in Johnson’s schedule) results
b) Update the values of Tp, TQ,and D.Go to step 2a).
in 9 time units becoming available to perform both operations
of job A (the 1-machine job) plus the setup.
Thus fitting in job A on machine Q gives the final oneC. An Illustrative Example
setup
schedule of Fig. 3(b) with a makespan of 23 time units.
We will illustrate the above heuristics with an example.
In the two-setup case, Heuristic 2 was used as follows:
Suppose we need to schedule five jobs, A to E , with
processing times as shown in Table I. Let the setup time be 2 Step I :
Using the first-fit decreasing heuristic on the combined
time units.
processing time for each job results in a schedule with jobs
The zero-setup schedule gives a makespan of 26 time units,
{ D,A } on machine P and jobs { B , C, E } on machine Q.
while the one-setup and two-setup schedules obtained from
Step 2:
the above heuristics give makespans of 23 and 24 time units,
Now, co = C y = 1, and the difference between the total
respectively. Fig. 3 depicts these schedules with the sequence
processing times of machines P and Q, D = I Tp - T Q =
~ 3.
of the jobs at each machine, and the corresponding routing
patterns for each job.
a) Machine Q is the machine with the larger total processBriefly, the one-setup schedule was obtained (using Heurising time and all the jobs are 1-machine jobs.
tic 1) as follows:
i) Clearly, D = 3 > 2co.
ii) Here we select job B which has its type Y operation
Step I :
The zero-setup schedule gives the values of the two idle
of 2 time units being closest to 0 1 2 = 1.5 time units.

,CI

262

IEEE’JOURNAL OF ROBOTICS AND AUTOMATION, VOL. 4. NO. 3, JUNE 1988

We then split job B so that its type X operation
remains on machine Q, but its type Y operation is
reassigned to machine P.
b) The updated values for the machines are Tp = 24, TQ =
23, and D = 1.
Going to step 2a, we now have D < 2c, so we stop.
The final two-setup schedule is shown in Fig. 3(c) with a
makespan of 24 time units.
Specific to the above example, we remark that an exhaustive
enumeration of all feasible solutions reveals that each of the
schedules obtained in Fig. 3 has the shortest makespan
corresponding to the zero-setup, one-setup, and two-setup
cases, respectively. Among these, the one-setup schedule has
the shortest makespan and hence is the optimal solution to this
instance of 2-VFSP problem. The optimal routings of the jobs
to the two machines are also given in Fig. 3(b).
Table I1 shows the improvements achieved when in-process
magazine setups are allowed. The machine utilization ratio is
defined as the ratio of machine utilization time to makespan.
Observe that, in this example, both the average utilization
increases and the makespan decreases when in-process magazine setups are allowed.

D. Some Empirical Tests
Johnson’s (zero-setup) algorithm and the two heuristics
were computer coded in Fortran 77 for empirical testing. Ten
different joblists were randomly generated. The values for the
“number of jobs” for each joblist, and for the processing
times of the two types of operations for each job, were also
randomly generated. These corresponding values ranged from
5 to 10 (for the number of jobs in a joblist), and from 1 to 10
(for the processing times).
These ten joblists were each tested with different values of
setup times so as to correspond to varying degrees of machine
8, 10, and 12 time units were
versatility. Setup times of 1,
considered. For each value of setup time and each joblist, the
three schedules corresponding to the zero-setup, one-setup,
and two-setup schedules were generated. Among these three
schedules, the one with the minimum makespan was designated the “best” schedule.
Table I11 summarizes the results of our tests. For each value
of the setup time that corresponds to a row in Table 111, ten
joblists were used. Thus the entries in the column for “best”
schedule are from ten different joblists. The results reveal that
the use of setups during scheduling may or may not be
desirable depending on the magnitude of the setup time. When
the setup time is small, the schedules that incorporate setup(s)
tend to have shorter makespan than the corresponding zerosetup schedules. As the setup time increases, the reverse
occurs; schedules without setups tend to be the “best.” This
observation is in line with one’s intuition that “as setup time
increases, incorporating setups in the schedule becomes less
and less desirable.”
A joblist parameter available prior to determining any
schedule corresponds to the “difference between the two total
processing times of type X and type Y operations” which we
shall denote by Dxy.
Our preliminary findings also suggest an
interesting relationship between this joblist parameter and the

-

e ,

TABLE I1
IMPROVEMENTS ACHIEVEDWHEN IN-PROCESS SETUPS ARE ALLOWED

__

._

~

~

~

Schedule Type (Makespan)
Zero-Setup (26) One-Setup (23) Two-Setup (24)
Machine

P

Q

P
~

Machine
utilization time
Utilization
ratio

Q

P

Q

~~~

25

18

22

21

22

21

096

069

096

091

092

0 88

Average
utilization
Improvement
in average
utilization
Makespan
improvement

0 83

0 94

0 90

(NA)

I O 8%

6 9%

(NA)

11 5 %

17%

TABLE 111
SUMMARY OF THE EMPIRICAL TESTS

Setup
Time

1
2
3
4
5
6
I
8
10
12

Number of Times the “Best” Schedule Has
Zero Setup
One Setup
Two Setups

0
0
2
4
5
5
5

1
9
9

5
6
6
5
4
4
4
3
1
1

5
4
2
1
1
1
1

0
0
0

number of setups in the “best” schedule for that joblist. Table
IV illustrates this relationship.
In Table IV, each row corresponds to one of the ten joblists
tested. The entries in the column for “best” schedule are the
results of testing of ten different setup times for each joblist. In
the zero-setup schedules obtained from Johnson’s algorithm,
we note that the maximum among the total idle periods of the
two machines, IM, is directly correlated with Dxy.
Since it is
essentially this idle time period of the zero-setup schedule that
is used to improve the makespan via setups, the schedules with
setups appear to give better results when D x yis large. This
can be observed in Table IV, where we can see a gradual
decrease in the number of times the zero-setup schedule is the
“best,” when Dxy,
and hence IM, increases.

E. Some Further Remarks on the 2- VFSP
Note that we solved the 2-VFSP by solving all the three
subproblems. It may sometimes be possible to solve the 2VFSP without necessarily solving all three subproblems by
using some useful bounds associated with the one-setup and
two-setup schedules. We outline such a procedure below.
The lower bound for each of these schedules can be
calculated from the joblist data as follows. For the one-setup
schedule, this corresponds to L , , where L I = r(Tp + TQ + ts
+ t,,,in)/21;where tmi, = min { ci, i = 1, . . . , 2 n ) . And for

263

LEE AND MIRCHANDANI: TWO-MACHINE FLEXIBLE MANUFACTURING CELL

TABLE IV
RELATIONSHIP BETWEEN Dxu AND THE NUMBER OF SETUPS USED IN
THE “BEST” SCHEDULE

Difference
DXY

0
1
5
7
7
9
11
11
12
21

Idle Time Number of Times the “Best” Schedule Has
IM
Zero Setup One Setup Two Setups
3
4
6
8
8
10
12
12
12
23

the two-setup schedule, this corresponds to L2, where L2 =
r(Tp + T~ + 2ts)/21.
The procedure first determines the zero-setup schedule and
uses this makespan, MO, to compare with the two lower
bounds, L1 and L2. If MO I min { L l , L 2 } , then the zerosetup schedule is optimal; otherwise, the one-setup schedule
needs to be determined next. Then the one-setup makespan
M I is compared with MOand L2. If A41 < MOand M I ILz,
then the one-setup schedule is optimal; otherwise, the twosetup schedule also needs to be determined. Thus with this
checking of lower bounds, it is possible to solve the 2-VFSP
without always solving the three subproblems together.
Finally, we remark that although in our empirical tests we
have assumed finite setup times, new advancement in machine-tool technology and tool management systems may
make it possible for magazine setups to become automated
resulting in negligible setup times. For this case, in general,
the optimal schedule is one that incorporates setup(s).
V. CONCLUSIONS
In this paper, we introduced a concurrent approach to
scheduling a 2-machine FMC. The approach utilizes the
machine versatility feature to integrate the tool management
system into the scheduling system by allowing in-process
“machine loading” through magazine setups. In essence, it
solves both the routing and sequencing subproblems concurrently. To illustrate the utility of the concurrent approach, we
defined in detail a specific two-versatile-machine flowshop
scheduling problem, referred to as 2-VFSP.
We distinguish two types of setups, the tool exchange (or
the spindle-setup) which is automatic, and the magazine setup
which may or may not be automatic. The concurrent strategy
adopted allows both types of setups to take place during a
production cycle and solves both the routing and sequencing
problems concurrently.
An alternative sequential strategy may be employed. This
strategy allows only tool exchanges to take place and does not
permit any in-process magazine setups. Here, production is
scheduled so that no operation is assigned to a machine that
does not have the tools (required for the operation) resident in
the magazine. Such type of strategies has been reported for
the scheduling of large-scale FMS’s by Stecke [I I], Kusiak
[lo], Berrada and Stecke [2], and Ammons et al. [ 13 among

8
8
7
7
6
3
2
2
3
0

0
0
3
3
4
7
6
8
0
8

2
2
0
0
0
0
2
0
7
2

others, where the “loading,” “routing,” and “sequencing”
problems are solved sequentially.
If the sequential strategy is employed in the 2-VFSP, then
each machine would have been dedicated with only the tool-set
of a particular operation type. This, in essence, transforms the
2-VFSP into the conventional 2-(dedicated) machine flowshop
problem solvable by Johnson’s algorithm-thereby giving
only the zero-setup schedule. However, we remark that the
“loading” problem for deciding on which tools to load onto
the magazine becomes the critical problem in this sequential
strategy.
In the theoretical study of 2-VFSP, we showed that an
optimal schedule exists which has at most two in-process
magazine setups-one on each machine. This gives rise to
three possible configurations for an optimal schedule having
zero, one, or two setups, respectively. However, we proved
that to obtain the optimal schedule is an NP-complete problem.
We, therefore, developed a heuristic approach with which the
subproblems of determining the one-setup and two-setup
schedules are solved approximately.
The heuristic was tested on sets of random joblists, for
different values of setup times corresponding to varying
degrees of machine versatility. Results showed that in-process
magazine setups may be desirable especially if the setup time
is small; by appropriately scheduling the consequent inprocess magazine setups, the makespan of the resultant
schedule may be shorter than the Johnson’s (zero-setup)
schedule.
Finally, although we have applied the concurrent approach
to problems involving only two machines, we have gained
valuable insights. The results for the 2-VFSP suggest that
concurrent routing and sequencing more effectively captures
the available machine versatility for FMC’s consisting of
versatile machines, and the zero-setup schedule obtained
using the sequential scheduling strategy may not be optimal in
such cases. This points to the need for further research on the
concurrent approach for scheduling FMC’s with a larger
number of machines, that may incorporate appropriate inprocess magazine setups when necessary.
REFERENCES
[I] J. C. Ammons, C. B. hfgren, and L. F. McGinnis, “A large scale
work station loading problem,” in Proc. 1st ORSA/TIMS Special
Interest ConJ. on FMS (Michigan), pp. 249-256, 1984.

264
[21 M. Berrada and K . E. Stecke, “A branch-and-bound approach for
machine loading,” in Proc. 1st ORSA/TIMS Special Interest Conf.
on FMS (Michigan), pp. 256-271, 1984.
131 R. W. Conway, W. L. Maxwell, and L. W. Miller, Theory of
Scheduling. Reading, MA: Addison-Wesley, 1967.
141 J . S. Edghill and A. Davies, “Flexible manufacturing systems-The
myth and reality,” Int. J . Adv. Matiuf. Techno/., vol. 1, no. I , pp.
37-54. 1985.
H. A. ElMaraghy, “Automated tool management in flexible manufacturing,” J. Manuf. Syst., vol. 4,no. 1, pp. 1-13, 1985.
M. R. Garey and D. S . Johnson, Computers and Intractability: A
Guide to the Theory of NP-Completeness. San Francisco, CA:
Freeman, 1979.
171 S. L. Hankins and V. P. Rovito, “A comparison of two tool allocation
and distribution strategies for FMS,” in Proc. 1st ORSAS/TIMS
Special Interest Conf. on FMS (Michigan), pp. 212-217, 1984.
[SI T. C. Hu. Cornbinaiorial Algorithms. New York, NY AddisonWesley, 1982.
191 S. M. Johnson, “Optimal two- and three-stage production schedules
with setup times included,” Naval Res. Logistics Quart., vol. 1, pp.
61-68, 1954.
A. Kusiak, “Loading models in flexible manufacturing systems,’’ in
Proc. 7th Int. Conf. on Production Research (Windsor, Ont.,
Canada), pp. 6 4 - 6 4 9 , 1983.
K. E. Stecke. “Formulation and solution of nonlinear integer production planning problems for flexible manufacturing systems,” Manag.
Sci., vol. 29, pp. 273-288, 1983.
-,
“Design, planning, scheduling, and control problems of flexible
manufacturing systems,” in Proc. 1st ORSA/TIMS Special Interest
Conf. on FMS (Michigan), pp. 1-7, 1984.
C. S. Tang and E. V. Denardo, “Models arising from a flexible
manufacturing machine-Part I: Minimization of the number of tool
switches,” Working Paper No. 341, Graduate School of Management,
UCLA, CA, 1986.
-,
“Models arising from a flexible manufacturing machine-Part
11: Minimization of the number of switching instants,” Working Paper
No. 342, Graduate School of Management, UCLA, CA, 1986.
D. M. Zelenovic, “Flexibility: A condition for effective production
systems,’’ Ini. J. Production Res., vol. 20, pp. 318-337, 1982.
J . Zygmont, “Flexible manufacturing systems: Curing the cure-all,”
High Technology, pp. 22-27. Oct. 1986.

IEEE JOURNAL OF ROBOTICS AND AUTOMATION, VOL. 4, NO. 3, JUNE 1988

Eng-Joo Lee (S’86) received the B.S. and M. Eng.
degrees in computer and systems engineering from
Rennsselaer Polytechnic Institute (RPI), Troy, NY,
in 1984 and 1985, respectively. He is currently a
doctoral candidate at RPI.
Since 1984, he has been a Research Assistant in
the Information and Decision Systems Laboratory at
RPI. Currently he is involved with the industrysponsored FMS Program within the Center for
Manufacturing Productivity and Technology Transfer at RPl. His research interests include combinatorial optimization and the application of operations research and systems
engineering to robotics and automation.
Mr. Lee is a member of Eta Kappa Nu. Tau Beta Pi, ORSA. and ACM.

Pitu B. Mirchandani (M’60-SM’82) received the
B.S. and M.S. degrees from the University of
California at Los Angeles in 1966 and 1967,
respectively. and the Sc.D. degree in operations
research from Massachusetts Institute of Technology, Cambridge, in 1975.
He is currently a Professor in the Electrical,
Computer, and Systems Engineering Department at
Rensselaer Polytechnic Institute, Troy, NY. His
research interests include optimization of stochastic
systems, network analysis. combinatorial optimization, and the application of operations research and systems engineering to
logistics, transportation, manufacturing, automation, and decision support
systems. He is the co-author of Location on Networks: Theory and
Algorithms. He is an associate editor for Transportation Science.
Dr. Mirchandani is a member of ORSA, TIMS, IIE, ACM, and the
Mathematical Programming Society.

264

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 9, NO. 2, JUNE 2008

Online Behavior-Robust Feedback Information
Routing Strategy for Mass Evacuation
Yi-Chang Chiu and Pitu B. Mirchandani, Senior Member, IEEE

Abstract—Disaster response to manmade and natural events
involves the quick evacuation of the affected population to safer
areas. Given the potential for large-scale loss of life and property,
there is a need for effective emergency strategies to mitigate the
adverse effects of these disasters. Most existing evacuation traffic management strategies focus on increasing network capacity
along the evacuation direction such as contraflow lanes, but other
information or routing strategies have not been fully explored.
Optimal routing strategies can be presented to evacuees as recommended routes. Advising evacuees that take system-optimal
routes help balance the distribution of evacuation flows among
multiple evacuation routes. However, a critical aspect in evaluating
the effectiveness of such strategies is to properly account for the
possible evacuation route-choice behavior. This study analyzed
the situation in which evacuees are given a set of system-optimal
paths; evacuees choose their evacuation routes, following a certain
route-choice behavior (rational, panic, etc.). Discussions focus on
the extent to which the routing effectiveness can be properly
estimated, subject to the route-choice behavior. This paper further
proposes a behavior-robust feedback information routing (FIR)
strategy to further improve system performance. The FIR is based
on the concept of closed-loop control that reacts to the system
state and updates the advised routes. The FIR that targets the
system-optimal routing strategy has been shown to be effective and
robust for real-time evacuation traffic management.
Index Terms—Behavior robust, DynusT, feedback information
routing (FIR), mass evacuation, traffic simulation.

I. I NTRODUCTION

M

ASS evacuation is called for when an extreme event
strikes a populated area; therefore, the population is
exposed to immediate or foreseeable life-threatening danger. In
current practice, for evacuation of disasters with a high probability of occurrence and relatively sufficient lead time (i.e.,
short-notice disasters, such as a hurricane), evacuation management agencies usually determine alternate evacuation routes

Manuscript received October 31, 2006; revised July 15, 2007. This work
was supported in part by the National Science Foundation under Award
SES-0332001 and Award CMS-0231458, by the U.S. Department of Transportation under the ATLAS Center Project, and by the Federal Highway
Administration through the Arizona Department of Transportation under
Project H644904X. The Associate Editor for this paper was W. Scherer.
Y.-C. Chiu is with the Department of Civil Engineering and Engineering
Mechanics, University of Arizona, Tucson, AZ 85721 USA (e-mail: chiu@
email.arizona.edu).
P. B. Mirchandani is with the Department of System and Industrial Engineering, ATLAS Center, University of Arizona, Tucson, AZ 85721 USA (e-mail:
pitu@sie.arizona.edu).
Color versions of one or more of the figures in this paper are available online
at http://ieeexplore.ieee.org.
Digital Object Identifier 10.1109/TITS.2008.922878

a priori, based on the expected spatial–temporal trajectories of
the disaster. Citizens are then given advisories on which major
roadways to use for evacuation. Existing practice does not
impose how evacuees should choose a route and departure time.
It has often been observed that collective synchronized behavior
exists in evacuation [1], that is, evacuees leave at similar time
windows and take similar routes. This causes sudden surges of
traffic flow and creates gridlock on certain evacuation routes,
which not only creates life-threatening risks but also causes
emotionally exhausting and uncomfortable journeys to move
out of harm’s way. In an unexpected disastrous event such
as a dam burst or a biochemical attack, evacuating a large
population becomes more challenging due to the short lead time
and highly unpredictable pedestrian or vehicular traffic flows.
In this case, evacuees can crowd roadways and may cripple the
entire transportation system.
To improve upon the state of practice, some fundamental modeling issues are revisited with three key questions:
1) If an optimal evacuation flow assignment model exists and
evacuees were to strictly follow the given instructions, to what
extent can evacuation effectiveness be achieved? 2) Is there an
ideal benchmark for an evacuation operation; how can such a
benchmark be used to assess the effectiveness of an evacuation
strategy? 3) Knowing this benchmark, can one propose an
effective and practical real-time traffic management strategy
that can significantly improve upon existing practices?
This paper addresses these issues from a modeling perspective with specific goals to achieve the following objectives:
1) to develop an optimal evacuation assignment flow model that
simultaneously determines the optimal evacuation destinations,
routes, and flows; 2) to investigate the impact of possible route
choice behavior on evacuation effectiveness; and 3) to develop
a feedback information routing (FIR) strategy to maintain an
efficient evacuation operation.
To address the first objective, a simulation-based traffic flow
optimization approach is proposed to simultaneously solve for
the optimal evacuation destination, routes, departure times, and
flows. With regard to the second objective, we quantify the
evacuation effectiveness degradation resulting from evacuees
choosing their own evacuation routes from a set of routes
(either recommended by the emergency management authority
or assumed by the evacuees), based on various evacuee route
choice behaviors. Compared with the ideal benchmark, where
all evacuees are fully compliant with the optimal evacuation
route directives, the extent of suboptimality that various route
choice behaviors impose on evacuation effectiveness is quantified. Finally, related to the third objective, efforts were placed
to develop the FIR strategy to move the system performance

1524-9050/$25.00 © 2008 IEEE

CHIU AND MIRCHANDANI: ONLINE BEHAVIOR-ROBUST FIR STRATEGY FOR MASS EVACUATION

toward the ideal benchmark. That is, the benchmark provides a
target for the feedback control (where control is the provision
of routing guidance) at which to aim.
The contributions of this paper are twofold: First, it provides model-based evidence, as well as quantitative assessment
on how evacuees’ collective evacuation route choice behavior
leads to degraded evacuation effectiveness because of inefficient use of highway capacities. Second, a feedback strategy
that provides real-time pretrip route guidance is shown to
improve evacuation effectiveness, regardless of the behavioral
assumptions. To the best of the authors’ knowledge, both issues
have not been empirically studied in the literature. The research
findings underscore the need to both further understand evacuation behavior and provide directions for designing behaviorrobust strategies for evacuation operations.
The next section reviews the short-notice evacuation studies.
Section III presents a model that will determine the optimal
evacuation traffic flow. Section IV discusses the Evacuation
Route Choice Model (ERCM). Section V focuses on the numerical analyses and comparison of both the open-loop and
closed-loop (feedback) schemes. Concluding remarks are given
in Section VI.
II. L ITERATURE R EVIEW
Over the past decade, a number of computer models have
been developed to assist in emergency evacuation planning,
for mitigating disasters ranging from nuclear plant failures to
hurricanes. Studies in the 1980s focused on evacuations due to
the Three Mile Island incident that occurred in 1979 [2]–[4].
Much recent research has focussed on hurricane evacuation,
because a number of extremely devastating hurricanes have hit
the U.S. in the 1990s [1], [5], as well as in 2005 [6], [7]. After
the September 11, 2001, incident, there is growing concern
about mass evacuation due to terrorist attacks [8], [9].
From a traffic flow modeling perspective, existing approaches to planning evacuation routes can be classified as
static or dynamic approaches. Static models use static transportation information or assume network link flows to be at steady
states. Most geographic-information-system-based models or
static traffic assignment models fall into this category [10].
Examples of dynamic models include the following. Early
work, such as that of Sheffi et al. [2], proposed a macroscopic
flow-based evacuation optimization model. DYNEV [3], which
is a macroscopic simulation model, was developed in the early
1980s to model evacuation from nuclear power plant sites.
MASSVAC used macroscopic traffic flow models for the hurricane evacuation of Virginia Beach, VA [11]. An evacuation
model proposed by the Oak Ridge Evacuation Modeling System used a CORSIM microscopic simulation model to simulate
link flows, speeds, and percent evacuated at each time period,
as well as the total evacuation time. Several other evacuation
studies using CORSIM as a modeling tool also exist in the
literature [4], [12]. The use of other microscopic simulation
models such as MITSIM [13] or VISSIM [14] can also be
found in more recent literature. However, it should be noted that
microscopic models require a vast amount of data for model
building and calibration. Such models are also computation-

265

ally demanding, making them limited to modeling only small
networks.
Some recent mesoscopic dynamic traffic assignment (DTA)
models such as DynusT [15], DYNASMART-X, and DynaMIT
[16], [17] can potentially be utilized to estimate traffic conditions during evacuation, but these models were primarily
designed for the purpose of managing regular daily traffic
conditions where a certain type of traffic equilibrium is assumed
among the users who are assumed to be familiar with daily traffic conditions. Further modifications are needed for evacuation
modeling purposes.
Most evacuation planning models require assumed inputs
or mechanisms on evacuation travel activity behaviors, such
as evacuation participation rate and route or departure time
choices. In the literature, evacuation behavior has mostly
been understood in social or psychological contexts [18]–[20];
quantitative behavioral analysis that can be incorporated into
evacuation operation has been limited [21]. Challenges in this
regard include the facts that evacuation travel behavior is event
dependent, events cause different anxiety levels for different
evacuees, and route choices are made under different decision
contexts for various disaster events. Furthermore, opportunities
for data collection are not abundant, and the data required
by disaggregate travel behavior models (e.g., the multinomial
logit (MNL) or probit model) are difficult to collect during
evacuation. Mechanisms to undertake surveys soon after the
disaster may not exist. Models that focus on aggregate data
analysis of event traffic (e.g., regression analysis on alternative
evacuation route flow patterns) may also be difficult to obtain,
let alone, in the context of route choice, to guide the use of
optimization models.
One of the few studies that addressed the evacuation/
no-evacuation behavior decision in an aggregated representation is that of Wilmot and Mei [22]. They developed alternative forms of trip generation of evacuation traffic using
logistic regression and neural network models to estimate the
evacuation participation rate of residents in the southwest part
of Louisiana, following Hurricane Andrew. A recent paper
summarized basic sociodemographic attributes from prior hurricane studies [21]. That study provided useful information
and assumptions on which the hurricane-related simulation
that was studied can be based. In general, limited evacuation
behavior studies, in terms of evacuation departure times and
route choices, have been reported. Most of the aforementioned
simulation-based studies were based on certain behavioral assumptions that have hardly been verified or validated. Further
research in this regard is needed.
In summary, many factors that contribute to the discrepancies
between model prediction and actual traffic flows exist. These
factors include the following: 1) the lack of understanding on
how evacuees choose routes; 2) inherent stochasticity in evacuation trip generation, departure time, and route choice behavior;
and 3) approximations in the traffic flow representation in
the model. These discrepancies challenge most existing traffic
management strategies. In this paper, it is argued that real-time
behavior-robust feedback strategies, where the network conditions are monitored in real time and prescriptive/normative
network flow control strategies are generated and implemented

266

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 9, NO. 2, JUNE 2008

Fig. 1. Zonal aggregation for evacuation flow assignment modeling.

online, are more robust, vis-à-vis the discrepancies in model
predictions. As shown in the succeeding sections, feedback
controls can significantly reduce the difference between the
optimal evacuation flows (the ideal benchmark) and the actual
realizations of the evacuation traffic flows and improve the
overall evacuation effectiveness.
III. D YNAMIC O PTIMAL E VACUATION F LOW A SSIGNMENT
This presented research proposes a modeling scheme based
on the DTA methodology that simultaneously solves for the
optimal evacuation destinations, routes, and flow splits from
evacuation zones to safe zones. The scheme allows all regular traffic analysis zones [see Fig. 1(a)] to be identified as
either evacuation, intermediate, or safe zones for the purpose
of evacuation. While the evacuation and intermediate zone
topology remains unchanged, all the nodes in the safe zones
adjacent to the intermediate or hot zones are considered the
destinations that will be connected to a hypothetical safe (sink)
node via virtual links. Vehicles are considered safe upon arrival
at these destination nodes. By connecting these nodes to the
“virtual safe node,” the evacuation flows will traverse only
through these nodes to the virtual safe node. Theoretically, more
destination nodes yield more roadway capacities leading to the
safe zone, but such decisions are dependent on the disaster
scenario and desired evacuation directions, as well as the traffic
network topology.
This hypothetical safe node serves as the single supervirtual
destination for all the evacuation flows [Fig. 1(b)]. The evacu-

ation trip generation will be estimated based on the new topology, and the flow assignment problem of interest is transformed
into a many-to-one network flow problem. Corresponding trip
demand information needs to reflect the evacuation-zone-tosafe-zone evacuation direction. Multiple safe zones defined in
the original topology need to be aggregated into one single
zone for the purpose of origin-destination (OD) demand matrix
estimation. This feature makes the trip distribution process
simple and accurate since all the flow outbound from evacuation
zones will just need to be pointed toward this “virtual safe
node.” At this point, the modeling is completed, and the optimal
destination, routes, and flow decision will be determined based
on the modified topologies and associated OD trip information.
The Optimal Evacuation Destinations, Routes, and Flows
(OEDRF) problem is formulated as a many-origin-to-singledestination system optimal traffic assignment problem with the
objective of minimizing the total travel time of all evacuees.
The notation and model formulation are given as follows:
number of vehicles that need to be evacuated from
ri
origin i;
A
set of all links in the network;
P
set of all nodes in the network;
I
set of origins in evacuation zones I ⊆ P ;
K(i, τ ) set of paths between origin i and the evacuation
virtual safe node at departure time τ that are
assigned with flows;
B(p)
set of adjacent links incident from node p, p ∈ P ;
C(p)
set of adjacent links incident to node p, p ∈ P ;
H
total experienced travel time for all evacuees;
F (·)
link-path mapping function;
G(·)
experienced travel time mapping function;
number of vehicles that enter link b at time period
dt,b
p
t, b ∈ B(p);
number of vehicles that exit link c at time period t,
mt,c
p
c ∈ C(p);
number of vehicles that enter the network from
Ept
node n at time period t;
number of vehicles that exit the network at node n
Opt
at time period t;
τ
number of vehicles leaving origin i ∈ I toward the
ri,k
virtual safe node at departure time period τ by
taking path k ∈ K(i, τ );
number of vehicles that enter link a at time
xta
period t;
τ
experienced travel time from origin i to the virtual
Ti,k
safe node at departure time τ by taking path k ∈
K(i, τ );
τ,t,a
time-dependent link-path incidence indicator,
σi.k
which is equal to 1 if vehicles departing from i
to the virtual safe node at departure time period τ
assigned to path k ∈ K(i, τ ) are present on link a
τ,t,a
takes the value
at time period t; otherwise, σi.k
of zero.
The OEDRF model can be expressed as

min
H=
τ
ri,k


τ

i


k∈K(i,τ )



τ
τ
ri,k
· Ti,k



(1)

CHIU AND MIRCHANDANI: ONLINE BEHAVIOR-ROBUST FIR STRATEGY FOR MASS EVACUATION

Fig. 2.

Modeling and solution procedure with the DynusT simulator.

subject to
 
τ

xta

τ
ri,k

k∈K(i,τ )

=


τ ≤t

i

∀ i

= ri





b

=G
dt,b
p



=

τ,t,a
τ
ri,k
· σi,k

(2)


∀ a, t

(3)

k∈K(i,τ )

τ,t,a
σi,k
= F [K(i, τ )

τ
Ti,k

267

τ
ri,k





mt,c
p

∀ i, τ ≤ t] ∀ i, k ∈ K(i, τ ), τ, t, a
(4)
∀ i, k, τ
+

Ept

−

Opt

(5)
∀ p

(6)

c

other definitional constraints.

(7)

At the time of evacuation, assume that the number of
evacuating vehicles at each node i in the evacuation zone is
known as ri . Equation (1) is the objective function aimed at
minimizing the evacuees’ total travel time from all nodes in
the evacuation zones to the virtual safe node. Equation (2)
states the conservation of evacuation flows at the origin nodes.
Constraint (3) describes the time-dependent incidence relationship that expresses the total number of vehicles on link
a as a mapping function of assigned flows of all OD pairs
and routes over all departure times. Constraint (4) is nonlinear
due to the dependence of the link-path incidence variables on
path assignment. They are usually evaluated by a simulation
model. Several essential physical traffic properties, such as firstin–first-out discipline on arcs, and preclusion of unintended
holding of vehicles, have to be maintained in F (·). Function
(5) denotes the experienced travel time as a function of deτ
τ
. Function G(ri,k
) is usually evaluated by
cision variable ri,k
simulation. Constraint (6) represents the flow conservation at
any node in the study area. These constraints ensure that no
vehicle will disappear at node p if it is not the virtual safe
node, and no vehicles are generated at node p, unless it is
an origin node. The definitional constraints are primarily the
nonnegativity constraints for all decision variables.
The solution procedures used to solve the OEDRF problem
are depicted in Fig. 2. After applying the assumed participa-

tion rate, chosen route, and set departure time, vehicles are
generated, loaded, and simulated based on the mesoscopic
traffic simulation model DynusT [15]. Note that the participant
rate determines how much total traffic will be headed toward
the safe zone while others maintain the original trip OD.
Resultant time-dependent link/node performance measures, including link travel times, node penalties, and hazard exposure
measures, are input into the minimal exposure shortest path
algorithm. Over the iterations, the choice path sets are increased
τ
are updated to optimally
and updated. Decision variables ri,k
τ
distribute flow ri to all paths in the choice set for each departure time interval, upon which, the new evacuation traffic
for each departure time is generated and simulated again. The
algorithm stops when the convergence criterion is met or until
the maximum number of iterations is reached.

IV. E VACUATION R OUTE C HOICE M ODELING
The evacuation route choice context addressed in this paper
is primarily aimed at characterizing the degradation of evacuation effectiveness, based on plausible route-choice behavior. In
the studied scenario, evacuees are assumed to be individually
provided with a set of evacuation paths from their origins
of evacuation to a designated safe zone, where the optimal
evacuation paths are obtained by the OEDRF model described
in Section III. Evacuees are assumed to choose one path from
the given path set based on an underlying route-choice model
described here, and they start on the evacuation journey at the
designated time on the selected path without deviating from it.
The OEDRF evacuation flow assignment model generates the
system optimal solutions consisting of a set of paths Ξτ(i,j) at
each departure time τ for each
 OD pair (i, j) and the optimal
flow split among path fr , r∈Ξτ fr = 1.0 ∀r ∈ Ξτ(i,j) . Be(i,j)
cause fr is difficult to enforce in reality, our scenario assumes
that each evacuee is presented with path set Ξτ(i,j) , and he/she
chooses one path from it based on the route-choice model
described hereinafter. It should be noted that, although several
assumptions are included in this decision context, the ERCM
discussed is intended to serve not as an exact representation

268

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 9, NO. 2, JUNE 2008

of the actual route-choice behavior during evacuation but as
a plausible representation since the objective is to highlight
the degradation of evacuation effectiveness compared with the
optimal route choice behavior.
ERCM is an MNL-based route-choice model that is calibrated through the stated preference approach. Equation (8),
shown at the bottom of the page, depicts the probability for an
evacuee k to choose route r as a logit-based function of random
utility consisting of the following variables:
length of path r for user k;
Lkr
commonality factor (CF) of path r for
CFrk
user k;
freeway bias of path r for user k;
F Brk
familiarity factor of path r for user k;
F Frk
set of possible paths for user k;
Jk
probability that user k chooses path r;
Pk (r)
alternative-specific constant for path r;
βr
β1 , β2 , β3 , β4 coefficients for utility function variables.
The commonality between multiple partially overlapped
paths is captured by CFrk in the utility function. Overlap
between paths commonly exists in most typical urban networks.
Route alternatives violate the Independence of Irrelevant Alternatives condition of the logit model if the overlap between
paths is not properly addressed. Cascetta et al. [23] proposed
the C-logit model, which adjusts the path utilities based on the
degree of overlap, by means of a CF incorporated into the utility
function of the MNL model. One of the several forms of the
proposed CF is





1
(9)
la 
δaj 
CFrk = ln 
Lr
a∈Γr

j∈Jk

where la is the length of link a, Γr refers to the set of links in
path r, and δaj is the link-path incidence index, whose value is
1 if link a belongs to path j and 0 otherwise.
The logarithmic form of the CF ensures that CFrk = 0 if path
r is strictly unique (i.e., no overlap with any other paths in the
choice set). For overlapped paths, the argument is less than one
and thereby reduces the utility of the paths under consideration.
The day-to-day operation of a road network composed of
arterials and freeways is typically assumed to take place under
a user equilibrium (UE) condition, where it is expected that
drivers have tested different routes and that each has adopted
the route that minimizes his/her perceived travel time. Freeway
bias has been observed in the real world, where arterial routes
have exhibited shorter travel times when compared with parallel
freeway routes with significant congestion-based degraded performance [24]. This phenomenon indicates that motorists may
perceive freeway travel time to be lower than that on other
parallel arterials, even though the actual situation may be
otherwise.

In ERCM, the freeway bias is represented by F Brk , which
accounts for the preference of motorists to freeways over arterials. Here, the magnitude of the bias is quantified as being
directly proportional to the percentage of a path’s length that is
composed of freeways
F Brk = lr(f ) /Lkr
(f )

where lr is the total length of freeway links in path r, and Lkr
is the length of evacuation path r for user k.
In addition, it is hypothesized that an individual’s awareness/
familiarity about an alternative in a choice set may also result
in higher utility for that alternative. Similar to the implicit
availability/perception model proposed by Cascetta and Papola
[25], the familiarity factor of an evacuation path r connecting
OD pair (i, j) is proportionally weighted to the frequency at
which the comprising links are used in the regular UE paths.
In other words, for two alternative evacuation routes, if the
comprising links of one route are more often used under regular
UE traffic condition than those of the other route, then evacuees
are considered to be more familiar with the former path than the
latter one. Specifically, the familiarity factor is expressed as
  

k
¯
φ(i, j, a)la
φ(i, j, a)¯la
(11)
F Fr =
a∈Γr

r∈Ξτ(i,j) a∈Γr

where ¯la is the length of link a, φ(i, j, a) is the percentage use
of link a with respect to all other links in the 
path set connecting OD pair (i, j), and φ(i, j, a) = f (i, j, a)/ a∈Γr f (i, j, a).
Furthermore, f (i, j, a) is the frequency that link a appears in all
UE paths (preevacuation normal
 traffic condition) connecting
OD pair (i, j). f (i, j, a) = τ r∈Ξτ δar , where δar = 1 if
(i,j)
a ∈ Γr and 0 otherwise.

In (11), the term a∈Γr φ(i, j, a)¯la can be regarded as the
weighted
average length
of path r with which user k is famil
¯
iar, and r∈Ξτ
a∈Γr φ(i, j, a)la is the total length in the
(i,j)
τ
choice set r ∈ Ξ(i,j) with which user k is familiar. Furthermore,
0 ≤ F Frk ≤ 1.0, and the higher the F Frk is, the more familiar
user k is with path r.
The proposed ERCM was calibrated using the stated preference approach. The stated preference questionnaire respondents
were given a graphical representation of the entire network, as
well as the route choice set. Routes were clearly marked with
distance. The overlaps of routes in the choice set were also
clearly illustrated to the respondents. Subsequently, the utility
function attributes were postprocessed based on each selection.
In other words, the questionnaire respondents were not asked to
assess the familiarity or freeway bias when making the choice.
He/she made the choice based on the graphical representation
of the network given to him/her. The attribute values were later
calculated based on the choice.



exp βr + β1 · Lkr + β2 · CFrk + β3 · F Brk + β4 · F Frk


k
k
k
k
j∈Jk exp βr + β1 · Lj + β2 · CFj + β3 · F Bj + β4 · F Fj

Pk (r) = 

(10)

(8)

CHIU AND MIRCHANDANI: ONLINE BEHAVIOR-ROBUST FIR STRATEGY FOR MASS EVACUATION

269

TABLE I
ERCM MODEL CALIBRATION RESULT

It is nonetheless emphasized again that the focus of this aspect of research is not to calibrate an exact route-choice model
but to devise a plausible route-choice behavior to shed light
on how actual route choice results in evacuation performance
deviating from the optimum.
A total of 90 valid observations were collected in a conditional logit scheme that was used in LIMDEP, i.e., an econometric modeling tool, to obtain estimates of the coefficients
of the four variables in the ERCM. As shown in Table I, the
CF is the only coefficient that does not appear to be significant
among the four examined variables. The three other coefficients
are statistically significant. The coefficient for the path length
is significant and has a negative sign, indicating that the shorter
the distance, the more preferable the route. The coefficient of
the freeway bias factor is significant and has a positive sign,
indicating that a higher freeway proportion in an evacuation
route is preferred. The result for the coefficient of the familiarity
factor indicates that routes that are utilized more during normal
traffic conditions are also preferred during evacuation.
V. C OMPARING O PEN -L OOP AND
R EAL -T IME -F EEDBACK -B ASED E VACUATION S TRATEGIES
Section III introduces a model to solve for the optimal
evacuation plan when the flooding scenario is predicted (the
short-notice case), the origin–destination demands are known,
and evacuees exactly follow the guidance on path choice and
departure times. This is referred to as the benchmark or system
optimal with flooding (SO.FL) scenario.
In Section IV, it is postulated that evacuees do not exactly
follow the system optimal guidance but rather select a path
based on ERCM that considers familiarity of the path, bias
toward freeways, and path length. The degradation of the evacuation effectiveness of ERCM with respect to the system optimal
solution is compared in detail in this section. The evacuees in
this scenario are not assumed to be real-time monitored and
managed after the guidance is given; this type of strategy is
referred to as the “open-loop” strategy. A benchmark scenario
is also proposed in which evacuees randomly choose paths and
departure times to represent the possible panicky or stressful
situation in which evacuees may randomly be choosing a path
without carefully considering the attributes of the path.
This open-loop control is compared with a real-time feedback (RT.FB) information strategy, where traffic is continuously
monitored, and pretrip guidance is updated every τ min (see
Fig. 5). This strategy, which is referred to as RT.FB control,
tries and changes guidance to the evacuation performance
achieved by the SO.FL solution. Indeed, the simulation-based
results show that RT.FB considerably improves evacuation
effectiveness.

Fig. 3. Test network with normal traffic pattern.

The test network (see Fig. 3) consists of 18 nodes and
56 links. The traffic analysis zones defined with respect to
normal traffic patterns include five zones. Flooding was predicted to inundate the northeast side of the network (see Fig. 4).
Links affected by the flood were gradually closed according
to flooding progression. After a link was closed, vehicles were
not allowed to travel across that particular link. The southwest
side of the network was defined as a safe zone. Residents were
ordered to evacuate 1 h before the flood had arrived. An evacuee
was considered safely evacuated when he/she arrived at any one
of the destination nodes (node 1, 2, 3, 4, or 6).
Four different open-loop scenarios were evaluated on the
sample network. Each scenario differed from the other in one
or more of the following aspects:
•
•
•
•

assumed travel behavior;
assumed objective;
available knowledge of disaster effects;
assumed network loading levels (15 000, 25 000, and
35 000 vehicles).

The following measures of effectiveness were examined for
each scenario:
• total and average evacuation time;
• total and average evacuation distance.
The four scenarios are described here and summarized in
Table II.
Scenario (TD.UE): Time-dependent UE
This was the nonflooding base case scenario in which traffic
was loaded onto the sample network using the OD matrices reflecting regular trip activity conditions. This scenario provided
the measures of attributes such as familiarity factor and freeway
proportions for the ERCM model to simulate the route choice
decisions. For the sample network, OD demand matrices, which
reflected day-to-day travel between each of the five zones, were
loaded onto DynusT, with UE as the objective, and the traffic
measures were collected over the simulation period. Note that
flooding was not modeled in this scenario. A network with three
different vehicle loading levels were considered and analyzed.

270

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 9, NO. 2, JUNE 2008

Fig. 4. Test network with flooding scenario and evacuation scheme.
TABLE II
OPEN-LOOP SCENARIOS

Scenario (SO.FL): System optimal trafﬁc assignment +
ﬂooding + evacuation ordered
In this scenario, flooding was modeled, and evacuation was
ordered such that the trips were mandated to change from
normal to the evacuation pattern. The optimal evacuation flow
assignment solutions were solved using the OEDRF model
described in Section III. Each evacuee was assumed to be
provided with an optimal route prior to his/her departure time,
and the evacuee was assumed to strictly follow the assigned
path. This was an ideal scenario and was used as the benchmark
representing the optimal evacuation realization.
Scenario (SO.FL.ERC): System optimal trafﬁc assignment +
ﬂooding + ERCM evacuees
This scenario was similar to the (SO.FL) scenario in that
the optimal flow assignment scenario remained unchanged.
However, instead of full compliance, evacuees chose one path
from the SO evacuation path choice set according to the ERCM
behavior model. This scenario was aimed at measuring the
possible deviation between the optimal and actual flow splits,
considering a plausible route choice behavior.
Scenario (SO.FL.RM): System optimal trafﬁc assignment +
ﬂooding + random route choice evacuees
This scenario was similar to the (SO.FL.ERC) scenario, with
the exception that evacuees were assumed to randomly choose
a path from the provided path set. This scenario was aimed at
testing a hypothetical panicky or stressful situation in which
evacuees may have chosen routes without carefully considering

specific characteristics of the routes. The experimental specifications for the four open-loop scenarios are summarized in
Table II.
A. Open-Loop Evacuation Guidance
In the open-loop evacuation guidance scenario, after solving
for the optimal evacuation assignment, the solutions were presented to evacuees in terms of a set of recommended evacuation
routes. Evacuees chose one evacuation route according to the
ERCM or random mechanism (RM) and continued with the
route until reaching the safe evacuation destination. In this case,
system performance was neither monitored nor fed back to
evacuation operations (Fig. 5).
The results in Fig. 7 show a comparison between
(SO.FL.ERC) and (SO.FL.RM), in terms of degradation of
evacuation effectiveness with respect to the ideal case (SO.FL).
Comparing the system optimal evacuation (SO.FL) with the
evacuee ERCM route choice (SO.FL.ERC) or random route
choice case (SO.FL.RM), it can be seen that the system
evacuation effectiveness degrades in scenarios where evacuees
choose routes according to reasonable behavioral rules. The
results shown in Fig. 6 indicate that when the network loading is low (15 000 vehicles), the flows reflecting the ECRM
route choice behavior result in an increase in evacuation time
(3.28 min) by 12%, compared with the SO.FL benchmark case
(2.93 min). Evacuation effectiveness more severely degrades

CHIU AND MIRCHANDANI: ONLINE BEHAVIOR-ROBUST FIR STRATEGY FOR MASS EVACUATION

Fig. 5.

271

Evaluation framework for open-loop evacuation effectiveness.

Fig. 6. Evacuation effectiveness degradation due to ECRM route choices
compared with the SO.FL case.

effectiveness when compared with the ERCM case. At the three
loading levels tested, the increased evacuation times are in
the range of 11%–33%, which are less, compared with those
of the ERCM case (12%–57%). Such results suggest that the
random choice tends to even out the flows among evacuation
routes, whereas the ERCM choices lead to concentrate flows on
preferred routes, hence leading to higher congestion on these
preferred routes.
Further examination of the deviations yields more insights
into the pattern of traffic flow resulting from route choice
behavior. The differences of the actual flow on each evacuation
route were calculated with respect to the optimal flow. The
root-mean-squared deviation (RMSD) represents the degree of
deviation of each route. For a given origin i, destination j, and
τ
is
departure time τ , with permissible path set K(i, j, τ ), δi,j
defined as the RMSD between the optimal and actual flows for
paths connecting (i, j) at departure time τ , i.e.,


 ∗


¯ 2
 k∈K(i,j,τ ) fk − fk
τ
∀i, j, τ
(12)
δi,j =
|K(i, j, τ )|
where
fk∗

Fig. 7. Evacuation effectiveness degradation due to random route choices
compared with the SO.FL case.

with heavier network loading. At the intermediate loading level,
the evacuation effectiveness degradation is 17% (6.00 min
versus 5.12 min). At the highest network loading level
(35 000 vehicles), an increase in evacuation time of 57% is
observed. In addition, the increase in the evacuation trip distance for ERCM indicates that many evacuees choose longer
routes when the choices are based on preferences as opposed to
optimal route guidance.
From a control-theoretic viewpoint, one can envision the
route choice behavior as optimal choices plus behavioral noise,
where, for ERCM, this noise is governed by a logit model, and
for the random route choice, this noise is uniformly distributed
over the paths in the choice set. Fig. 7 indicates that the latter
noise model actually leads to a milder degradation of evacuation

optimal flow assignment percentage for path k
connecting OD pair (i, j) at departure time τ ;
actual flow assignment percentage for path k
f¯k
connecting OD pair (i, j) at departure time τ .
Fig. 8 shows that about 56% of the paths have an RMSD of
less than 0.05 in the 15 000-vehicle ERCM route choice case.
In other words, for about 44% of the paths, the ERCM flows
significantly deviate from the optimal levels, with the maximum
deviation being more than 0.9. For the 35 000-vehicle loading
case, the deviation pattern is similar to that for the lower
loading case. On the other hand, the RMSD for the random
route choice case is lower than that for ERCM, also with lower
maximum deviations. This effect may explain why considerable
unbalanced use of evacuation routes has often been observed in
actual evacuation situations.
B. Close-Loop FIR Strategy for Evacuation Management
The closed-loop, or real-time feedback, scheme constantly
monitors system traffic conditions, vis-à-vis the system optimal
routing, and provides corrective actions to trend toward optimal system performance. In a real-world evacuation situation,

272

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 9, NO. 2, JUNE 2008

Fig. 8. RMSD flow deviations for both ERCM and random route choice.

Fig. 9. Evaluation framework for closed-loop evacuation effectiveness.

the evacuees’ route choice of behavior cannot precisely be predicted, and as previously mentioned, it can be regarded that this
behavior introduces noise into the system and causes the traffic
pattern to deviate from the ideal one. When the deviations are
regularly monitored and corresponding corrective actions are
taken to maintain a trajectory to the ideal flow, this closed-loop
evacuation strategy has greater potential to more efficiently
manage evacuation traffic than the open-loop schemes.
To this end, the FIR strategy is proposed to maintain satisfactory evacuation effectiveness. The FIR strategy is to exclude
any path with higher travel time than desired from the next
provided route guidance path set. As illustrated in Fig. 9, the
OEDRF optimal evacuation model was executed at an operatorspecified interval. Evacuees departing after each solution update were given the latest available routes and corresponding

route guidance. As before, evacuees were assumed to select
routes according to the ERCM or random route choice behavior.
Then, the resultant network traffic flow was observed (in our
experiments, where the DynusT simulation model represents
real life, network flows are simply provided by the model), and
OEDRF recalculates new optimal flows, given current observations, and provides new pretrip optimal guidance. Following the
notations previously defined, the optimal solutions comprise a
set of optimal paths Ξτ(i,j) at solution update instance τ for each

OD pair (i, j) and optimal path flow splits fr , r∈Ξτ fr =
(i,j)
1.0 ∀r ∈ Ξτ(i,j) . At any solution update instance, the following
is performed: Let
Ξτ(i,j) = Ξτ(i,j) \ k, if Tk > λ · TΞ

∀k ∈ Ξτ(i,j) .

(13)

CHIU AND MIRCHANDANI: ONLINE BEHAVIOR-ROBUST FIR STRATEGY FOR MASS EVACUATION

273

fairly implementable feedback strategy such as FIR remains
robust and well performed under the situation in which the
evacuee’s route choice behaviors cannot precisely be modeled
or predicted.
VI. C ONCLUDING R EMARK

Fig. 10. Pretrip feedback control results under the ERCM route choice
behavior rule.

In (13), Tk is the travel time on path k, TΞ is the average
travel time over all paths in Ξτ(i,j) , and λ is an operator-defined
control parameter, where 1.0 ≤ λ ≤ 2.0.
Equation (13) indicates that, at update time τ , if path k’s
travel time is greater than (λ − 1.0) ∗ 100% of the average
travel time of all paths in Ξτ(i,j) , (i.e., TΞ ), then path k will
be excluded from the path set provided to evacuees departing
between time τ and the next update instance. Doing so will
reduce additional traffic being injected into path k that has been
found to be overloaded. This update is repeated at each solution
update instance until the end of the evacuation.
The effect of the proposed real-time feedback control was
studied for various guidance update intervals ∆, ranging from
1.0 to 40.0 min. The results of applying the pretrip guidance
control strategy to the (SO.FL.ERC), as shown in Fig. 10,
indicate the considerable advantages of the FIR strategy. Recall
that, in the ideal evacuation situations (SO.FL), the evacuation
travel times are 2.93, 5.12, and 5.56 min for the three different loading levels, respectively (see Fig. 6). In the open-loop
ERCM case, the evacuation travel times increase to 3.28, 6.00,
and 8.71 min, which are equivalent to 12%, 17%, and 57%
increases, respectively. With the FIR strategy, the evacuation
travel time improves to 3.01, 5.53, and 7.21 min (based on a
1-min update interval), which are equivalent to 77%, 53%, and
47% improvements, respectively, compared with those of the
open-loop case.
The effect of different update intervals ∆ ranging from 1 to
40 min was further examined. From a control-theoretic perspective, increasing ∆ means an increase in feedback latency
and, hence, a decrease in response time. Lower response time
implies that the feedback scheme is not as responsive to changes
in the traffic pattern and should result in lower evacuation
performance. As can be observed from Fig. 10, the evacuation
time monotonically increases with increasing ∆. As expected,
the 1-min update interval yields the best system performance
for all three loading levels, and the degradation over the optimal
increases as ∆ increases.
The experimental results also show that the system performance remains relatively unchanged when the update interval is greater than or is equal to 5 min, indicating that FIR
becomes ineffective when the update interval becomes large.
In summary, the overall results indicate that a simple and

This paper reviews current research and existing approaches
for short-notice mass evacuation, which are predominantly
planning oriented and necessarily require that planners consider “what-if” scenarios and plan for each scenario if it
happens. The approaches are either lists of procedures for
mobilization and traffic management or models that rely on
evacuees choosing optimal paths to their destinations or exactly
following paths recommended by the models. As shown in
this paper, evacuee route choice behavior, as opposed to
selecting optimal routes, leads to significant degradation of
evacuation effectiveness. To mitigate this situation, we proposed an FIR strategy and showed this strategy to be effective in improving the evacuation effectiveness toward the
optimal situation. The findings suggested that regularly providing frequently updated evacuation route information is an
effective strategy. This strategy is practical since it utilizes
existing intelligent transportation system infrastructures, such
as a surveillance system, that have already been deployed in
many modern cities. Additional effort is needed to calculate
the optimal routes on a regular basis based on the updated
traffic data.
It should also be noted that the en-route information strategy
should also be considered in future research. The en-route
information can be disseminated through various broadcasting
technologies, such as highway advisory radios, regular radio,
dynamic message signs, or cellular phones.
ACKNOWLEDGMENT
The authors assume the responsibility for the facts presented,
viewpoints expressed, and accuracy of the data in this paper.
The authors would like to thank P. Korada for assisting in
conducting computational experiments and the anonymous
reviewers for providing constructive suggestions that have
improved the quality of this paper.
R EFERENCES
[1] B. Wolshon, “Planning for the evacuation of New Orleans,” ITE J., vol. 72,
no. 2, pp. 44–49, Feb. 2002.
[2] Y. Sheffi, H. S. Mahmassani, and W. B. Powell, “A transportation network
evacuation model,” Transp. Res., Part A, vol. 16, no. 3, pp. 209–218,
May 1982.
[3] KLD, Formulations of the DYNEV and I-DYNEV Trafﬁc Simulation Models Used in ESF. Washington, DC: Federal Emergency Manage. Agency,
1984.
[4] T. Urbanik and A. E. Desrosiers, An Analysis of Evacuation Time
Estimates Around 52 Nuclear Power Plant Sites. Rockville, MD:
U.S. Nuclear Regulatory Commission, 1981.
[5] “Southeast United States Hurricane Evacuation Traffic Study: Evacuation Travel Demand Forecasting System,” Tech. Memo. 2. Tallahassee,
FL: PBS&J, 2000. Final Rep.
[6] M. L. Burton and M. J. Hicks, “Hurricane Katrina: Preliminary estimates
of commercial and public sector damages,” in Center for Business and
Economic Research. Huntington, WV: Marshall Univ., 2005.

274

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 9, NO. 2, JUNE 2008

[7] “Long road to recovery—ASCE investigates lessons from Hurricanes
Katrina and Rita,” Texas Civil Eng., vol. 76, pp. 16–18, 2005.
[8] VDEM, Terrorism Information: The Facts—How to Prepare—How to
Respond. Richmond, VA: Virginia Dept. Emergency Manage, 2005.
[Online]. Available: http://www.vdes.state.va.us/prepare/terrorismtoolkit/
terrguide/index.htm
[9] NCHRP, NCHRP Transportation Security Projects, vol. 2005.
[10] A. Pal, A. J. Graettinger, and M. H. Triche, “Emergency evacuation
modeling based on geographical information system data,” in Proc. 82nd
Annu. Meeting Transp. Res. Board, Washington, DC, 2003. CD-ROM.
[11] A. G. Hobeika, A. E. Radwan, and B. Jamei, “Transportation actions to
reduce evacuation times under hurricane/flood conditions: A case study of
Virginia Beach City,” presented at the Annu. Meeting Transp. Res. Board,
Washington, DC, 1985.
[12] E. Lim and B. Wolshon, “Modeling and performance assessment of
contraflow evacuation termination points,” Transp. Res. Rec., vol. 1922,
pp. 118–128, 2005.
[13] M. Jha, K. Moore, and B. Pashaie, “Emergency evacuation planning with
microscopic traffic simulation,” Transp. Res. Rec., vol. 1886, pp. 40–48,
2004.
[14] B. M. Williams, A. P. Tagliaferri, S. S. Meinhold, J. E. Hummer, and
N. M. Rouphail, “Simulation and analysis of freeway lane reversal for
coastal Hurricane evacuation,” J. Urban Plann. Dev., vol. 133, no. 1,
pp. 61–72, Mar. 2007.
[15] Y.-C. Chiu, E. Nava, H. Zheng, and B. Bustillos, DynusT User’s
Manual. Tucson, AZ: DynusT, 2008. [Online]. Available: http://dynust.
net/wikibin/doku.php
[16] Y. Hawas, H. S. Mahmassani, Y.-C. Chiu, N. Huynh, and A. Abdelfatah,
Development of DYNASMART-X Software for Real-Time Dynamic Trafﬁc
Assignment. Austin, TX: Center Transp. Res., 1997.
[17] M. Ben-Akiva, Development of a Deployable Real-Time Dynamic Trafﬁc
Assignment System. Evaluation Report (Part B): Planning Functionality
(DynaMIT-P) and Applications. Cambridge, MA: MIT Press, 2003.
[18] E. J. Baker, “Hurricane evacuation behavior,” Int. J. Mass Emerg.
Disasters, vol. 9, no. 2, pp. 287–310, Aug. 1991.
[19] B. E. Aguirre, D. E. Wenger, T. A. Glass, M. Diaz-Murillo, and
G. Vigo, “The social organization of search and rescue: Evidence from
Guadalajara gasoline explosion,” Int. J. Mass Emerg. Disasters, vol. 13,
pp. 67–92, 1995.
[20] M. Diaz-Murillo, B. E. Aguirre, D. W. Wenger, T. A. Glass, G. Vigo,
and W. R. Tombrowsky, “Solidarity during snow disasters,” Int. J. Mass
Emerg. Disasters, vol. 1, no. 1, pp. 189–205, 1983.
[21] M. K. Lindell and C. S. Prater, “Critical behavioral assumptions in evacuation time estimate analysis for private vehicles: Examples from Hurricane
research and planning,” J. Urban Plann. Dev., vol. 133, no. 1, pp. 18–29,
2007.
[22] C. G. Wilmot and B. Mei, “Comparison of alternative trip generation
models for Hurricane evacuation,” in Proc. 82nd Annu. Meeting Transp.
Res. Board, Washington, DC, 2003. CD-ROM.
[23] E. Cascetta, A. Nuzzzolo, F. Russo, and A. Vitettarks, “A modified logit
route choice model overcoming path overlapping problems: Specification
and some calibration results for interurban network,” in Proc. 13th Int.
Symp. Transp. Trafﬁc Theory, Lyon, France, 1996, pp. 697–711.

[24] V. P. Shah and K. Wunderlich, Detroit Freeway Corridor and Its Evaluation, 2001. MitreTek Systems 0998610D-01.
[25] E. Cascetta and A. Papola, “Implicit availability/perception logit models
for route choice in transportation network,” presented at the 8th World
Conf. Transport Research, Antwerp, Belgium, 1998.

Yi-Chang Chiu received the B.S. degree in civil
engineering from National Taiwan University,
Taipei, Taiwan, R.O.C., the M.S. degree in
transportation engineering from National ChiaoTung University, Hsinchu, Taiwan, and the Ph.D.
degree in transportation engineering from the
University of Texas, Austin.
He is currently an Assistant Professor of civil
engineering and engineering mechanics with the
Department of Civil Engineering and Engineering
Mechanics, University of Arizona, Tucson. His research has been published in various journals, such as Transportation Research,
Institute of Industrial Engineers Transactions, the ASCE Journal of Urban
Planning and Development, and the Journal of Infrastructure Systems. His
research interests include the theoretical developments and applications of
dynamic traffic assignment, large-scale vehicular traffic evacuation modeling,
system dynamics and interdependence modeling, and intelligent transportation
system modeling.

Pitu B. Mirchandani (M’80–SM’82) received the
B.S. degree in engineering from the University of
California, Los Angeles (UCLA), and the S.M. degree in aeronautics and astronautics and the Sc.D. degree in operations research from the Massachusetts
Institute of Technology, Cambridge.
He is currently a Professor of systems and industrial engineering and electrical and computer
engineering at The University of Arizona and is the
Director of the ATLAS Research Center. He has
coauthored two books and more than 90 papers in a
variety of journals, magazines, and books. His technical expertise and research
interests include theories, models, and algorithms in operations research and
systems engineering and their application to transportation, logistics, homeland
security, and real-time information and control systems.
Dr. Mirchandani has been on the Editorial Boards of IIE TransactionsScheduling and Logistics; Transportation Science; the Journal of Industrial
Mathematics; the Journal for Advanced Transportation; and the Journal of
Technology, Policy and Management. He is a member of the Institute for
Operations Research and the Management Sciences, IIE, the Production and
Operations Management Society, and the Transportation Research Board; a
Charter Member of Intelligent Transportation Systems-Arizona; and a past
member of the Association for Computing Machinery and the Intelligent
Transportation Society of America.

50

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 8, NO. 1, MARCH 2007

Queuing Models for Analysis of
Traffic Adaptive Signal Control
Pitu B. Mirchandani, Senior Member, IEEE, and Ning Zou

Abstract—Microsimulation models are normally used to evaluate traffic-adaptive signal control systems. This paper develops an
analytical approach for this evaluation based on queuing models.
In particular, a queuing model is developed for a simplified adaptive control strategy that is based on rolling horizon scheme, in
which a signal serves two movements alternatively. In this strategy,
the first movement is served until the queue dissipates, then the
second movement is served until the queue dissipates, then the signal goes back to serving the first movement, and this cyclic process
repeats. A numerical algorithm is developed in a stochastic context
to compute steady-state performance measures such as average
delays and expected queue lengths. These results are compared
with simulation-based results, and indeed, the analytically derived
numerical method predicts well the simulation results.
Index Terms—Adaptive control, busy period, delay, queuing
modeling.

I. I NTRODUCTION

S

EVERAL performance criteria can be used to evaluate a
signalized intersection, such as average number of stops
per vehicle, vehicle throughput, average queue length, and
average stop delay. Among these indicators, delay is perhaps
the most important since it is easily understood, related to travel
costs and vehicle emission. For example, in [10], Highway
Capacity Manual uses it as the only measurement to determine
the level of service of signalized intersections.
Over the last 50 years, there have been many queuing models
reported in the literature for analyzing delays and queues at a
signalized intersection. The most well known model is that due
to Webster [11], who came up with analytical expressions for
delays and queues under the assumption of Poisson arrivals.
Miller [4] and Newell [5] proposed analytical models to estimate residual queues that exist at the end of green phase at
traffic signal on fixed-time plan. These are steady-state results
that assume that the arrival pattern remains the same throughout a period large enough to assume steady-state conditions.

Manuscript received March 5, 2006; revised July 3, 2006, September 9,
2006, and September 14, 2006. This work was supported in part by Grant
CMS-0231458 from the National Science Foundation and by the Intelligent
Transportation System (ITS) Partnership Agreement with Federal Highway
Administration (FHWA) and the Arizona Department of Transportation for the
Advanced Traffic and Logistics: Algorithms and Systems (ATLAS) Research
Center at the University of Arizona. The Associate Editor for this paper was
B. de Schutter.
P. B. Mirchandani is with the Department of Systems and Industrial
Engineering, University of Arizona, Tucson, AZ 85721 USA (e-mail: pitu@
sie.arizona.edu).
N. Zou is with the Department of Systems and Industrial Engineering,
University of Arizona, Tucson, AZ 85721 USA, and also with Kittelson and
Associates, Inc., Tucson, AZ 85701 USA (e-mail: zoun@email.arizona.edu).
Digital Object Identifier 10.1109/TITS.2006.888619

Hurdle [2] has discussed the limitations of such steady-state
models.
The Highway Capacity Manual [10] includes a generalized
time-dependent queuing model for computing average delay for
fixed-time signal control. Although the expressions for delays
are similar to these from queuing models, they need to be
calibrated for locations and regions, and in fact, Akcelik [1] has
studied these and corresponding Australian and Canadian expressions and their calibration. Olszewski [7], [8] has also proposed a stochastic queuing model to analyze queue and delay
distribution at intersections operating under fixed-time plans.
In this paper, a stochastic queuing model is developed for a
two-phase simplified adaptive control strategy where the signal
is switched to the other phase when the served queues just
vanish, and after the queues next served are depleted, it switches
back to the current phase. A numerical method is developed
to obtain the steady-state distribution of delays, queues, etc.,
using this queuing model. These steady-state distributions are
compared with those obtained through a simulation model. We
note that such an adaptive control strategy was first presented
and studied by Newell [6].
In Section II of this paper, the green phase distribution, or
the conditional “busy period” of this adaptive control strategy,
given multiple vehicles waiting at the beginning of green phase,
is calculated using transform methods. The result shows that
when k vehicles are queued up at the beginning of green phase,
then the expected time to clear the queue is k times the busy
period of the corresponding queuing system with same parameters. This result is used in Section III to build the queuing model
for the adaptive control analyzed in this paper. In Section IV,
numerical results are given and compared with simulationbased results. Several loading patterns are studied, including
symmetric intersection with equal arrival rates and asymmetric
intersection with unequal arrival rates. The results show that the
analytical model predicts well the simulation results.
II. B USY P ERIOD A NALYSIS
In a general first-in first-out single-server queuing system, a
busy period begins when a customer arrives and finds no queue
and the server is free to serve him immediately. A busy period
ends when the server completes the service of a customer and
finds there are no customers in queue waiting for service (i.e.,
it is a zero queue again). The interval between the end of a busy
period and the beginning of the next constitutes an idle period.
The intersection can be viewed as an M/G/1 system, where M
means the arrival process is Poisson; G means the service time
follows general distribution, and 1 means there is single server.

1524-9050/$25.00 © 2007 IEEE

MIRCHANDANI AND ZOU: QUEUING MODELS FOR ANALYSIS OF TRAFFIC ADAPTIVE SIGNAL CONTROL

Since arrivals are Poisson in an M/G/1 system, the idle period,
which ends with the next arrival, has a negative exponential
distribution. The distribution of the busy period of an M/G/1
system is available in many queuing theory textbooks (e.g., [3]).
In this paper, we study different types of busy periods that
occur due to the competition of the green phases for the various
vehicle streams approaching an intersection.
Assume vehicles arrive in a Poisson manner with rate λ. Let
the service rate (or the saturation flow rate) of the intersection
be µ. Let ν denote the time to serve one vehicle, its distribution
as b(ν) with expectation ν = 1/µ, and B e (s) is its s transform.
Let q be the busy period when there is only one vehicle
waiting at the beginning of the green phase. Define f (q) as the
distribution function of q and F e (s) as its s transform, which is
defined as
∞

e

F (s) =

−sq

e

f (q)dq.

(2.1)

0

The expectation of q is (e.g., [3])
E(q) =

1/µ
.
1 − λ/µ

(2.2)

We will now compute the expectation of busy period, say, q
when k vehicles are waiting at the beginning of green phase.
Define f (q  ) as the distribution function of q  , F e (s) is its
s transform. The length of the busy period q  consists of the
length of service kν for the first k vehicles, plus the length of
the busy period for the subsequently arriving customers. If n
vehicles arrive during the period kν, then these n customers
may be visualized as standing aside for service. The first of the
n customers gets serviced immediately after the termination of
service of the initial k vehicles; if there are any new arrivals
during this service time, then without loss of generality in
computing total service time, they may be considered to be
served before another customer of the (n − 1) remaining in
queue is admitted for service. The same modified priority rule
may be applied when the next customer goes into service.
Therefore, the total busy period is
q  = kν + q1 + q2 + · · · + qn

(2.3)

where the qi are independent (since the arrival process is
Poisson) and have the same distribution as q. Consequently, the
conditional Laplace-transform of q  , given there are n arrivals
in time kν, is
−sq 

F (s/n, kν) = E[e

−skν

]=e

e

n

[F (s)] .

(2.4)

To find the unconditional s transform, we note that the
unconditional distribution may be derived by


f (q ) =

∞ 
∞

f (q  /n, kν)P [n/(kν)] b(ν)dν

(2.5)

0 n=0

where
P [n/(kν)] = (λkν)n e−λkν /n!,

and b(ν) is the service time distribution. The s transform of
(2.5) gives
e

F (s) =

∞ 
∞

F e (s/n, kν)P [n/(kν)] b(ν)dν.

(2.7)

0 n=0

Using (2.4) and (2.6), and summing appropriate elements,
we get
e

∞

F (s) =

e−[ks+kλ−kλF

e

(s)]ν

b(ν)dν.

(2.8)

0

By definition of s transform, the above relation becomes
F e (s) = B e [ks + kλ − kλF e (s)] .

(2.9)

By differentiation, the expected length of a busy period caused
by the k vehicles in queue is
d e
F (s)|s=0
ds
d
d
[ks + kλ − kλF e (s)] |s=0 .
= − B e (0) ∗
ds
ds

E(q  ) = −



e

51

n = 0, 1, 2, . . .

(2.6)

(2.10)

Substituting ν = −(d/ds)B e (0) in (2.10), we have
E(q  ) = ν̄ ∗ [k + kλ ∗ E(q)] .

(2.11)

From (2.2) and (2.11), we get
E(q  ) =

k/µ
.
1 − λ/µ

(2.12)

This result means that the expectation of busy period caused
by k vehicles in queue is k times the expectation of the busy
period caused by one vehicle in queue. Intuitively, if one treats
the queuing discipline as a last-in–first-out system (noting
that the length of busy period remains unchanged, because
the number of vehicles being served is irrelevant), then all k
vehicles can be served one by one at times when the busy
period of the previous vehicle is just terminated. Hence, each
of these k vehicles constitutes an independent busy period q.
The total busy period caused by these k vehicles is thus k times
the individual expected busy period q.
III. A NALYSIS OF A DAPTIVE S IGNAL C ONTROL
Consider an isolated two-phase intersection with one-way
traffic streams without turning movements. Let phase Φ1 serve
the W–E flow and Φ2 the N–S flow. As illustrated in Fig. 1, let
the arrival rate and intersection service rate of the W–E (N–S)
direction be λ1 (λ2 ) veh/s and µ1 (µ2 ) veh/s, respectively. We
will assume that there is sufficient intersection capacity so
that flow ratio ρi = λi /µi is less than one. Furthermore, for
the existence of a steady state for the signal control, we will
assume that total effective service rate, which includes startup loss during queue discharge, is greater than total arrival
rate. In the figure, the time axis is divided into half cycles for

52

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 8, NO. 1, MARCH 2007

Fig. 2.
Fig. 1. Adaptive traffic phases at an intersection. L: Time lost during initial
queue discharge. c: Half cycle.

the convenience of analysis. Each half cycle ci is composed
of a constant queue discharge lost time L plus a green phase.
The odd (even) subscript on c means it serves the W–E (N–S)
direction (see Fig. 1).
In the adaptive control scheme analyzed in this paper, phase
Φ1 serves the W–E queue and new arrivals until there is no
queue. Then, Φ2 serves N–S queue and arrivals until there is no
queue. Then, it goes back to Φ1 , and so on.
If vehicles arrive at deterministically constant rates, then
the optimal signal times (with minimum average delay) for
adaptive control can be easily computed as follows. During
phase Φ2 , exactly (c1 + c2 ) · λ2 vehicles, which arrived in the
last half cycle, and the current one need to be served, while total
service capacity during this half cycle is (c2 − L) · µ2 . Analysis
for the next phase Φ1 , for time c3 , is similar. That is
(c1 + c2 ) ∗ λ2 = (c2 − L) ∗ µ2
(c2 + c3 ) ∗ λ1 = (c3 − L) ∗ µ1 .

(3.1)

At steady state, c1 = c3 = c5 . . ., and c2 = c4 = c6 . . ..
Then, optimal half-cycle lengths of two directions are
c1 =

1 + ρ1 − ρ2
L
1 − ρ1 − ρ2

(3.2a)

c2 =

1 − ρ1 + ρ2
L.
1 − ρ1 − ρ2

(3.2b)

Now, consider Poisson arrivals. For a reasonable initialization of the process needed for our numerical analysis, let us
assume we start with half cycle c1 and c2 given by (3.2).
Starting at the beginning of c2 , the W–E vehicle arrivals become
Poisson with rate λ1 . Beginning of c3 , N–S vehicles arrive in
Poisson manner with rate λ2 . This initialization does not affect
the steady state.
Since the adaptive signal serves one direction until queue
dissipates, then switches to the other direction, and the switching continues, the c3 , c4 , . . . , cn are random variables, whose
distributions depend on time needed to serve the queue. Based
on the distribution of the half cycles, one can calculate the
distribution of delays, cycle lengths, and number of vehicles
served during each cycle, as will be shown below.
Let X2i denote the number of vehicles that arrive in the
W–E direction during (c2i + L) and X2i+1 denote the N–S

Queue length curve in one cycle.

vehicles during (c2i+1 + L). Then, the probability mass function (PMF) of X2 is
Pk2 = P (X2 = k2 ) =

[λ1 ∗ (c2 + L)]k2 −λ1 ∗(c2 +L)
e
.
k2 !

(3.3)

From (2.11), we can get the conditional (given k2 ) expected
green phaselength
c3 − L = k2 ∗

1/µ1
.
1 − ρ1

(3.4)

The traffic signal switches as soon as the queue becomes
zero. Assuming vehicles depart at saturation flow rate during
the green phase, the conditional expected number of vehicles
served during (c3 − L) is
n3 = (c3 − L) ∗ µ1 =

k2
.
1 − ρ1

(3.5)

To calculate the total delay of W–E vehicles in cycle (c2 +
c3 ), we need the distribution of the vehicle arrival times in
this cycle. Suppose n vehicles arrived in (0, t). Given the
Poisson arrival process, the arrival times of these n vehicles
s1 , s2 , . . . , sn are independently and uniformly distributed in
this interval (e.g., [9]). Therefore, the conditional expected total
delay D3 can be viewed as the area of the triangle in Fig. 2


1
1
k2 /µ1
. (3.6)
D3 = k2 ∗ (c2 + c3 ) = k2 ∗ c2 + L +
2
2
1 − ρ1
Hence, the conditional average delay d3 of the W–E vehicles
during (c2 + c3 ) is



k2
1
k2 /µ1
d3 = D3 /n3 = k2 ∗ c2 + L +
2
1 − ρ1
1 − ρ1
=

1
[(c2 + L) ∗ (1 − ρ1 ) + k2 /µ1 ] .
2

(3.7)

The (unconditional) expectation of d3 is
E(d3 ) =

∞


Pk2 ∗D3 /n3

k2 =1
∞
1
1 
k2
= [1−P (k2 = 0)]∗(c2 +L)∗(1−ρ1 )+
Pk 2 ∗ .
2
2
µ1
k2 =1

(3.8)

MIRCHANDANI AND ZOU: QUEUING MODELS FOR ANALYSIS OF TRAFFIC ADAPTIVE SIGNAL CONTROL

53

The next step is the calculation of the distribution of X3 ,
which is the number of N–S vehicles arriving in the time
interval (c3 + L). Since c3 is a discrete random variable, whose
PMF is given by (3.3) and (3.4), the calculation of PMF of X3
is different from that of X2 . For any realization of (c3 + L),
we can get the probability of exactly k3 N–S vehicle arrivals.
The summation of these probabilities over all possible (c3 + L)
gives the probability of exactly k3 vehicle arrivals during
(c3 + L), that is, the following PMF of X3 :
Pk3 = P (X3 = k3 )

P [X3 = k3 |(c3 + L)] ∗ P [(c3 + L)]
=
all(c3 +L)

=

∞


Pk 2

k2 =0

=

∞

k2 =0

=

∞

k2 =0

Pk 2



	


k2 /µ1

∗ P X3 = k3  (c3 + L) = 2L +
1 − ρ1
[λ2 ∗ (c3 + L)]k3 −λ2 ∗(c3 +L)
e
∗
k3 !

Pk 2 ∗



λ2 ∗ 2L +

k2 /µ1
1−ρ1


k3

k3 !



−λ2 ∗ 2L+

e

k2 /µ1
1−ρ1

k2 =1


.

From (2.12), the conditional (given k3 ) green phase (c4 − L),
which serves the N–S direction, is
1/µ2
.
1 − ρ2

(3.10)

The conditional expected number of vehicles served during this
green phase is
n4 = (c4 − L) ∗ µ2 = k3 ∗

1/µ2
k3
∗ u2 =
.
1 − ρ2
1 − ρ2

(3.11)

Similarly, the conditional expected total delay of the N–S
vehicle during (c3 + c4 ) is
1
D4 = k3 ∗ (c3 + c4 )
2


1
k3 /µ2
= k3 ∗ c3 + L +
2
1 − ρ2


k2 /µ1
k3 /µ2
1
+
+ 2L .
= k3 ∗
2
1 − ρ1
1 − ρ2

The (unconditional) expectation of d4 is


∞

1
1/µ1
Pk 2 ∗
k2
E(d4 ) = (1−ρ2 )∗ 2L∗[1−P (k3 = 0)]+
2
1−ρ1

(3.9)

c4 − L = k3 ∗

Fig. 3. Scenario tree of the system.

(3.12)

Hence, the conditional average delay d4 during (c3 + c4 ) is
d4 = D4 /n4



k3
1
1/µ1
k3 /µ2
= k3 ∗ k2 ∗
+ 2L +
2
1 − ρ1
1 − ρ2
1 − ρ2


 
1/µ1
1 k3
1
+ 2L +
. (3.13)
= (1 − ρ2 ) ∗ k2 ∗
2
1 − ρ1
2 µ2

+

∞
1 
k3
Pk 3 ∗
.
2
µ2

(3.14)

k3 =1

Using such expressions on succeeding half cycles until
steady state is reached, one can get the steady-state distribution of 1) the number of vehicles served in a cycle,
2) green phaselengths, and 3) vehicular delays, including average vehicular delays in each direction and in each cycle.
In our initialization of half-cycle lengths, uniform arrivals
were assumed. Other initial half cycles could have been used.
The reason we selected these half cycles was because they
are close enough to steady state so that steady state can be
calculated faster.
The final issue in this section concerns the numerical computation of the steady-state probabilities and associated performance measures. Since there are infinite possible realizations
of X2 , X3 , . . . and the number of possible scenarios goes up
exponentially, it may appear that the computational load is
unmanageable, but if we truncate the state space by neglecting
extremely low probability scenarios, the computational load
is very manageable. At any stage, we fathom a node in the
scenario tree when its probability is below a given threshold.
We then can get a relationship of the various measures of
interest from one half cycle to another.
Suppose at step 1 of the computational process, the finite
PMF for X2 is calculated (by ignoring very low possibility
scenarios). Then, one can easily compute the distribution of
(c3 + L) since it is linearly related to the PMF of X2 . This
allows the computation of the conditional probability of k3
arrivals for each realization of (c3 + L), which gives us the
PMF of X3 in step 2 of the process. This scenario tree is
schematically represented in Fig. 3; note that now, the number
of scenarios does not blow up exponentially. The formulas
to compute various measures from step to step are derived
below. In most cases, less than 30 steps were needed for the

54

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 8, NO. 1, MARCH 2007

expressions of steady-state probabilities to converge within a
threshold of 10−6 .
When the distribution of Xi−1 , which is the number of vehicle arrivals in (ci−1 + L), is known, we can get the distribution
of the expected length of (ci + L), since it is linearly related to
ki−1 as ci + L = 2L + (ki−1 /µj /1 − ρj ), where j = 1 when i
is odd and j = 2 when i is even.
Then, the distribution of Xi is given by
Pki = P (Xi = ki )

P [Xi = ki | (ci +L)] ∗ P (ci +L)
=
all(ci+L)

 ∞



Pki−1



ki−1 =0







∗ P Xi = ki | (ci +L) = 2L+ ki−1 /µ1 ,
1−ρ1
=
∞



Pk


ki−1 =0 i−1







∗ P Xi = ki | (ci +L) = 2L+ ki−1 /µ2 ,
1−ρ2

The conditional average delay di+1 during (ci + ci+1 ) is
i is odd

i is even.

(3.19)
Finally, the (unconditional) expectation of di+1 is

i is odd

i is even.
(3.15b)

Since the relationship between the conditional green phaselength (ci+1 − L) and ki is

ci+1 − L =


i /µ2
 k1−ρ
, i is odd
2
 ki /µ1 , i is even
1−ρ1

(3.16)

the conditional expected number of vehicles served during this
green phase, given by the product of the green phaselength and
the service rate, is
ni+1 =


 (ci+1 − L) ∗ µ2 =

ki /µ2
1−ρ2

∗ µ2 =

ki
1−ρ2 ,

i is odd

 (c

ki /µ1
1−ρ1

∗ µ1 =

ki
1−ρ1 ,

i is odd.

i+1

− L) ∗ µ1 =

Di+1
ni+1




ki
 1 ki ∗ ki−1 /µ1 + 2L + ki /µ2
2
1−ρ1
1−ρ2

  1−ρ2

=
ki
 1 ki ∗ ki−1 /µ2 + 2L + ki /µ1
2
1−ρ2
1−ρ1
1−ρ1
 



 1 (1 − ρ2 ) ∗ ki−1 /µ1 + 2L + 1 ki , i is odd
2
 1−ρ1

 2  µ2 
=
 1 (1 − ρ1 ) ∗ ki−1 /µ2 + 2L + 1 ki , i is even.
2
1−ρ2
2 µ1

di+1 =

Since Xi arrivals are Poisson, (3.15a) can be simplified to

Pk i

1
Di+1 = ki ∗ (ci + ci+1 )
2



ki /µ2

, i is odd
 12 ki ∗ ci + L + 1−ρ
2
=



 1 ki ∗ ci + L + ki /µ1 , i is even
2
1−ρ1



k
/µ
ki /µ2
1
i−1
1

 2 ki ∗
1−ρ1 + 1−ρ2 + 2L , i is odd
=



 1 ki ∗ ki−1 /µ2 + ki /µ1 + 2L , i is even.
2
1−ρ2
1−ρ1
(3.18)

(3.15a)



ki
 
ki−1 /µ1

λ
∗
2L+

∞
2
1−ρ


1


Pki−1 ∗

ki !

 ki−1 =0







ki−1 /µ1


 × e−λ2 ∗ 2L+ 1−ρ1 ,
=

ki
 

k
/µ2

λ1 ∗ 2L+ i−1

∞
1−ρ2




Pki−1 ∗

ki !


ki−1 =0







k
/µ2

−λ1 ∗ 2L+ i−1

1−ρ2
×e
,

Using the queue length trajectories as shown in Fig. 2, the
conditional expected total delay during the two half cycles
(ci + ci+1 ) is

(3.17)

E(di+1 )

(1−ρ2 )
(1−ρ2 )∗[1−P (ki = 0)]∗L+ 2(1−ρ


1)



 
∞
∞




ki
1


×
Pki−1 ∗ kµi−1
+
P
∗
k
i

2
µ2 , i is odd
1
 ki−1 =0
ki =1
=
(1−ρ1 )


(1−ρ1 )∗[1−P (ki = 0)]∗L+ 2(1−ρ

2)



 

∞
∞




ki
1

Pki−1 ∗ kµi−1
+
P
∗
k
×
i
2
µ1 , i is even.
2
ki−1 =0

ki =1

(3.20)
Equation (3.20) was used to propagate expected delay from half
cycle to half cycle until it converged.
IV. M ODEL E VALUATION
In this section, the analytical queuing model is evaluated by
comparing its numerical solution with simulation-based results.
The simulation model of the adaptive control strategy is built in
MATLAB. The random number generator of MATLAB was to
generate two groups of exponentially distributed random variables for vehicle interarrival times of the two directions. Service
rates and lost time were the same as those of the analytical models. For each type of loading pattern, the simulation model was
run 10 times, with a length of 500 000 s each. The first 10 000 s
of each run were considered warm-up periods and truncated.

MIRCHANDANI AND ZOU: QUEUING MODELS FOR ANALYSIS OF TRAFFIC ADAPTIVE SIGNAL CONTROL

55

TABLE I
COMPARISON OF AVERAGE NUMBER OF VEHICLES SERVED IN
ONE CYCLE AND AVERAGE HALF-CYCLE LENGTHS

Fig. 4. Average intersection delays.

Several loading patterns were simulated. In each case, we examined 1) the average number of served vehicles in one cycle,
2) the average half-cycle lengths given by the numerical method
and simulation, 3) the average delays, and 4) the number of
iterations for the numerical method to converge.
Case 1: Symmetric Intersection With Balanced Flow Ratios:
In this case, the saturation flow rates of the two directions are
0.5 veh/s, the arrival rates of two traffic streams are equal, and
range from 0.05 to 0.2 veh/s. Queue discharge lost time was set
to 4 s for all the cases.
Since the system is symmetric, performance measures should
be the same for either direction, and therefore, only measures
for one direction are listed in Table I, which gives the average
number of vehicles served in a cycle and average half-cycle
lengths. The table shows that the means of these measures
computed by the analytical model match well with those given
by the simulation model. Another interesting finding is that
the means of these two measures for adaptive signal control
are equal to those of a system with deterministically constant
arrivals (with same arrival and service rate) and corresponding
optimal half cycles.
Fig. 4 shows the average intersection delays calculated by
the queuing model and obtained by simulation. The delay plots
show that the average delays given by the two methods match
well when the total flow ratio is less than 0.6. As the total flow
ratio increases beyond this point, the differences increase but
are still less than 10%. The analytical model always tends to
underestimate the average delays compared to the simulation
model. The differences are due to the method of calculating
the green phaselength; the analytical model truncates low probability states and uses expected green phaselength while the
simulation model uses actual phaselength (i.e., the distribution
of the green phaselengths). Since the truncation threshold is

Fig. 5. Number of iterations to converge.

very small, say 10−6 , decreasing the threshold will not reduce
the differences very much. The difference can be reduced by
using the distribution of the phaselength.
For a numerical method, its convergence, in terms of iterations needed, is a major issue. Fig. 5 shows the numbers of
iterations needed to converge, which is defined as when the
performance measure does not change by more 10−6 from
iteration to iteration. Of course, the time to converge depends
on the initial cycle lengths. “Optimal initial cycle” in the figure
indicates that the initial cycle length determined by (3.2). For
comparison, we also used a long initial cycle (where the optimal
cycle length is doubled) and a short initial cycle (where the
length is halved). While the initial signal settings do not affect
the final states at convergence, the system converges much
faster with optimal initial cycle where, in most cases, less than
ten iterations are needed to reach steady state. The figure also
shows that as the total flow ratio increases, the number of
iterations needed to converge also increases.
Case 2: Symmetric Intersection With Unbalanced Flow
Ratios: The departure flow rates for both directions were set to
0.5 veh/s again. The arrival rates of N–S vehicles ranged from
0.03 to 0.13 veh/s, while the arrival rates of E–W vehicles were
twice those of N–S vehicles.

56

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 8, NO. 1, MARCH 2007

TABLE II
COMPARISON OF AVERAGE NUMBERS OF VEHICLES SERVED IN ONE
CYCLE AND AVERAGE HALF-CYCLE LENGTHS IN N–S DIRECTION

Fig. 7.

Average delays of E–W vehicles.

Fig. 8.

Average intersection delays.

Fig. 9.

Number of iterations to converge.

Fig. 6. Average delays of N–S vehicles.

Table II gives the average numbers of vehicles served in one
cycle and average half-cycle lengths in the N–S direction, given
by the analytical model and the simulation model. The results
match well. As in Case 1, the performance measures given by
the adaptive signals are equal to those of a system with deterministically constant arrivals and using corresponding optimal
half-cycle lengths. The results for the E–W vehicles lead to the
same conclusions.
Figs. 6 and 7 show the average delays in the two directions
given by the two methods. The delay plots show that the average
delays given by the two methods are very close when the total
flow ratio is relatively low, say, less than 0.6. As the total
flow ratio increases, the differences increase. As before, the
numerical queuing model tends to underestimate the average
delay as compared with the simulation model. The differences
in the E–W direction (which has a higher flow ratio) are larger.
Fig. 8 shows the average intersection delays.
Fig. 9 plots the numbers of iterations needed to converge at
various flow ratios. Again, when optimal initial cycle lengths
are used, the numerical method converges much faster; with a
“bad” initial cycle, it still converges to the same steady state,
but it is much slower. As before, more iterations are needed to
converge when the flow ratio increases.

Case 3: Asymmetric Intersection With Balanced Flow
Ratios: In this case, the departure rate of N–S vehicles is
0.5 veh/s and of E–W vehicles is 1.0 veh/s. The arrival rates
of N–S direction ranges from 0.05 to 0.20 veh/s, and the arrival
rates of E–W direction are twice of those of the N–S vehicles.
Table III gives the average numbers of vehicles served in
one cycle and average half-cycle lengths in the E–W direction
given by the analytical model and the simulation. Again, the

MIRCHANDANI AND ZOU: QUEUING MODELS FOR ANALYSIS OF TRAFFIC ADAPTIVE SIGNAL CONTROL

57

TABLE III
COMPARISON OF AVERAGE NUMBERS OF VEHICLES SERVED IN ONE
CYCLE AND AVERAGE HALF-CYCLE LENGTHS OF E–W DIRECTION

Fig. 11. Average delays of E–W vehicles.

Fig. 12. Average intersection delays.

Fig. 10. Average delays of N–S vehicles.

results of the two models match well. Also, as for Case 1,
results of the adaptive signals equal to those of a system with
deterministically constant arrivals and optimal half cycles. The
results for the E–W vehicles lead to the same conclusions.
The average delays in the two directions and the combined
intersection delays are given in Figs. 10–12. The number of
iterations needed for convergence for different flow ratios and
initial signal cycles are given in Fig. 13. In summary, the
numerical solution of the queuing model approximates well the
simulation results and converges quickly.
Case 4: Asymmetric Intersection With Equal Arrival Rates:
In this last case, the departure rates in the two directions are
same as those of the Case 3. The arrival rates in the two
directions are equal and range from 0.06 to 0.28.

Fig. 13. Number of iterations to converge.

Table IV gives the average numbers of vehicles served during
one cycle and average half-cycle lengths in the N–S direction
given by analytical and simulation models.
The average delays in the two directions and for the whole
intersection are given in Figs. 14–16. The number of iterations
needed for convergence for difference flow ratios and initial
signal cycles are given in Fig. 17. Again, the analytical results
match well with the simulation results, and the numerical
solution of the analytical model converges quickly.

58

IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. 8, NO. 1, MARCH 2007

TABLE IV
COMPARISON OF AVERAGE NUMBERS OF VEHICLES SERVED IN ONE
CYCLE AND AVERAGE HALF-CYCLE LENGTHS OF N–S DIRECTION

Fig. 15.

Average delays of E–W vehicles.

Fig. 16.

Average intersection delays.

Fig. 17.

Number of iterations to converge.

Fig. 14. Average delays of N–S vehicles.

Summarizing the evaluation of the queuing model of the
four different cases of intersection loading, we conclude the
following.
1) The numerical solution of the queuing model estimates
very well the average number of vehicles served in each
cycle and average half-cycle length of the strategy.
2) The adaptive signal control strategy, for Poisson vehicle
arrivals, performs as well as the optimal strategy for a
system with deterministically constant arrivals, where the
arrival rates are the same for both systems.
3) When total flow ratio is lower than 0.6, the estimations
of average delays given by the analytical model are very
close to the simulation-based results. The queuing model
underestimates the average delay slightly when the total
flow ratio is higher than 0.60.
4) When the initial cycle lengths are optimal, the numerical
method converges very quickly: in less than ten iterations.
With other initial cycle lengths (twice or half the optimal
lengths), the model still converges but at a slower rate.
Also, in general, more iterations are needed when the flow
ratio increases.

V. C ONCLUSION AND F UTURE R ESEARCH D IRECTIONS
This paper develops an analytical queuing model to analyze
the queues and delays at an isolated two-phase intersection
control that uses a simple adaptive signal strategy originally
proposed by Newell [6]. In this strategy, the first movement is
served until the queue dissipates, then the second movement is
served until the queue dissipates, and, then, the signal goes back
to serving the first movement, and this cyclic process repeats.
A numerical algorithm was developed to compute steady-state
performance measures such as average delays and expected
queue lengths.
Numerical solution of the model was compared with results from a simulation model. The comparison shows that

MIRCHANDANI AND ZOU: QUEUING MODELS FOR ANALYSIS OF TRAFFIC ADAPTIVE SIGNAL CONTROL

the analytical model approximates very well the simulation
results when the flow ratio is less than 0.60. The model slightly
underestimates the average delays when flow ratio increases.
We are currently investigating the use of this modeling
methodology to model an adaptive control strategy for a fourphase intersection control, where the signal switches to the
next phase after queues being served in the current phase are
depleted. We also plan to develop such queuing models for
an intersection operating under fixed signal timing. The major
complication in modeling this scenario is the consideration of
residual queues, when they occur, from one cycle to another.
(In our adaptive strategy, there are no residual queues.) In
order to reduce the differences between the results of numerical
method and those of the simulation, the exact distribution of the
busy period is being studied. We also plan to model queues at
ramp meters using this approach.
A major assumption, and perhaps a weakness, of the model
is the assumption of Poisson arrivals. We plan to investigate
if such a model can be used for other arrival distributions, in
particular, an arrival pattern that approximates batch (platoon)
arrivals.
ACKNOWLEDGMENT
The contents of this paper reflect the views of the authors,
who are responsible for the facts and the accuracy of the data
presented herein. The contents do not necessarily reflect the
official views of the sponsors of this work.
R EFERENCES
[1] R. Akcelik, “The highway capacity manual delay formula for signalized
intersections,” ITE J., vol. 58, no. 3, pp. 23–28, Mar. 1988.
[2] V. F. Hurdle, “Signalized intersection delay models—A primer for the
uninitiated,” Transp. Res. Rec., no. 971, pp. 96–105, 1984.
[3] L. Kleinrock, Queueing Systems. Volume 1. Theory. Hoboken, NJ:
Wiley, 1975.
[4] A. J. Miller, “Settings for fixed-cycle traffic signals,” Oper. Res. Q.,
vol. 14, no. 4, pp. 373–386, Dec. 1963.

59

[5] G. F. Newell, “Approximation methods for queues with applications to the
fixed-cycle traffic light,” SIAM Rev., vol. 7, no. 2, pp. 223–240, Apr. 1965.
[6] ——, “The rolling horizon scheme of traffic signal control,” Transp. Res.
Part A, vol. 32, no. 1, pp. 39–43, Jan. 1998.
[7] P. S. Olszewski, “Modeling of queue probability distribution at traffic
signals,” in Proc. 11th Int. Symp. Transp. and Trafﬁc Theory, Tokyo,
Japan, 1990, pp. 569–588.
[8] ——, “Modeling probability distribution of delay at signalized intersections,” J. Adv. Transp., vol. 28, no. 3, pp. 253–274, fall/winter 1994.
[9] S. Ross, Stochastic Process, 2nd Edition. Hoboken, NJ: Wiley, 1996.
[10] TRB, Special Report 209: Highway Capacity Manual, 1985, Washington,
DC: TRB, Nat. Res. Council.
[11] F. V. Webster, “Traffic signal settings,” Road Res. Lab., Ministry Transport, HMSO, London, U.K., pp. 1–43, Road Research Technical Paper 39,
1958.

Pitu B. Mirchandani (M’80–SM’82) received
the B.S. and M.S. degrees in engineering from
the University of California, Los Angeles, and the
S.M. degree in aeronautics and astronautics and
the Sc.D. degree in operations research from the
Massachusetts Institute of Technology, Cambridge.
He is a Professor of systems and industrial engineering with the University of Arizona, Tucson.
His interests span a broad variety of areas of operation research, including optimization, control of
stochastic systems, and logistics, routing, location,
and scheduling.

Ning Zou received the B.S. and M.S. degrees in
mechanical and electrical engineering from Zhejiang
University, Hangzhou, China, in 1997 and 2000,
respectively, and the M.S. degree in industrial engineering from the University of Arizona, Tucson,
in 2004. He is currently working toward the Ph.D.
degree in systems and industrial engineering at the
University of Arizona.
He is a Transportation Analyst with Kittelson and
Associates, Inc., Tucson. His research focuses on
mathematical modeling of traffic systems.

Covering a line segment with variable radius discs
Alessandro Agnetis∗

Enrico Grande†

Pitu B. Mirchandani†

Andrea Pacifici‡

arXiv:0707.2921v1 [cs.DM] 19 Jul 2007

February 11, 2013

Abstract
The paper addresses the problem of locating sensors with a circular field of view
so that a given line segment is under full surveillance, which is termed as the Disc
Covering Problem on a Line. The cost of each sensor includes a fixed component
f , and a variable component b that is proportional to the field-of-view area. When
only one type of sensor or, in general, one type of disc, is available, then a simple
polynomial algorithm solves the problem. When there are different types of sensors
in terms of the f and b parameters, the problem becomes hard. A branch-andbound algorithm as well as an efficient heuristic are developed. The heuristic very
often obtains the optimal solution as shown in extensive computational testing.

Scope and Purpose
Problems of locating facilities to cover sets of points on networks and planes have
been widely studied. This paper focuses on a new covering problem that is motivated by an application where a line segment is to be kept under surveillance using
different types of radars. Using reasonable assumptions, some nonlinear covering
problems are formulated. Efficient exact algorithms and heuristics are developed
and analyzed for “easy” and “hard” cases, respectively.
Keywords: Sensor location, network covering problems, mixed integer nonlinear
programming.
∗ Università

di Siena, Dipartimento di Ingegneria dell’Informazione, via Roma 56, 53100 Siena, Italy.
Center, The University of Arizona, Tucson AZ 85721. Email: pitu@sie.arizona.edu. Fax: 520-621 6555.
‡ Università di Roma “Tor Vergata”, Dipartimento di Ingegneria dell’Impresa, via del Politecnico 1, 00133 Roma, Italy.

† ATLAS

1

1

Introduction

In this paper we introduce and study a new locational decision problem: given a set of discs with variable
radii with costs depending on their radii and fixed costs, find a subset covering a unit length segment at
minimum cost.
This problem was motivated by the following application, part of which was an industry-funded radar
surveillance project at The University of Arizona. We have a river over which we need to track possible
activities of non-collaborative or antagonistic objects or people (e.g., unauthorized boats, dangerous
floating objects, swimmers, etc). For this purpose, we need to locate a set of radars so that every point
on the river is under surveillance by at least one radar. It is assumed that the river can be modeled as a
tree network consisting of line segments and that each radar has a field of view defined by a radius and
an angle of view (a pie-shaped coverage), with this angle large enough so that the coverage area may be
approximated as a disc. Although the problem is relatively easily stated, the actual locational decision
is complicated due to several additional factors. Coverage depends not only on the river topology, radar
type and power, but also on several parameters such as width of river and obstacles over it, potentially
forbidden areas where radars may not be located, elevation of the potential location sites, and other
characteristics associated with the physical environment, dealing with, for example, the atmospheric and
water conditions. Further details on this scenario and the scope of the project are reported in [20].
This radar sensors location model relates to several broad classes of geometric locational problems.
Many important land-use planning decisions deal with locating facilities at sites, choosing from a given
set of potential sites, so that another given set of points are “covered” (i.e., they are within a specified
distance from the closest located facility) while optimizing a specified objective. Models for locating at
points within continuous spaces, as well as locating among set of discrete points or on a network, are widely
used by geographers, regional scientists, network planners, and others facing locational decisions problems
which can be modeled as such covering problems (for a comprehensive review of the literature see, for
example, [7, 13, 15, 18]). From the methodological viewpoint, the radars location problem relates closely
to the class of geometric covering problems where potential facilities and demand points are embedded
on a Euclidean plane, for which there is considerable literature. We briefly review below results that are
most relevant for our application.
Problems related to Covering with discs consists of identifying the minimum number of discs with
fixed radius to cover a given set of points in the plane. A number of articles have appeared in the last
three decades addressing this NP-hard problem. In 1975, Chvátal introduced the Art Gallery Problem in
2

[3], where one has to find the minimum number of watchmen (or cameras) needed to observe every wall
of an art gallery room. The art gallery is assumed to be a n-sided polygon, possibly with polygonal holes.
It has been shown that an art gallery with h holes and n walls (including holes’ sides) requires at most
⌊(n+h)/3⌋ watchmen (the bound is tight, see [11, 19]). Another important paper, by Hochbaum and Maas
[10], presents polynomial approximation algorithms for different versions of geometric covering problems,
including covering by discs. Subsequently, several papers have appeared with improved approximation
factors and running times (see for example, [2, 4]).
The problem of partial covering, also referred to as the robust k-center problem, is analyzed in [22],
where computational complexity is discussed and approximation algorithms together with computational
evidence of their performance are provided.
The geometric disc covering problem relates also to the deployment of wireless transmission networks.
Surveys on coverage problems dealing with this particular application can be found in [12] and [21]. We
limit our literature review to a few papers dealing with applications similar to the radar sensors location
problem. Alt et al. [1] consider a problem where a set of points demand connectivity. Their goal is to
locate a set of sensors, modeled as discs with variable radii, covering the demand points at minimum total
cost. Each sensor’s transmission cost has the form f (r) = rα where r is the covering radius of the sensor.
Several results are presented in [1], including complexity characterization and approximation algorithms.
Although different scenarios are addressed, depending on possible restrictions on discs’ locations and
demand points, their analysis is limited to discrete sets of points.
Article [6] addresses the problem of locating base stations for wireless communication where the
demands and potential facilities are represented by a discrete set of points and each station can broadcast
up to a maximum distance. A polynomial approximation scheme is given, together with complexity
results. The following disc-covering geometric problem applied to wireless communication is addressed
by Franceschetti et al. [5]: given an infinite square grid G, determine how many discs, centered at the
vertices of G, with a given radius r, are required, in the worst case, to completely cover a disc with
the same radius arbitrarily placed on the plane. The authors show that this number is an integer in
{3, 4, 5, 6} depending on r and on the grid spacing. In addition, they discuss the applicability of this
model to the design of approximation algorithms for facility locations on regular grids and to base station
placement for wireless communication. The expected quality of service (level of surveillance) of a given
sensor network is analyzed in [17] and [14], where the authors exploit computational geometry and graph
theoretic techniques, such as Voronoi diagrams, Delaunay triangulation and graph search, to design exact
polynomial algorithms for some special cases.
3

Location of railway stops is another application of the disc covering problem. In [9], the effect of
introducing additional stops in the existing railway network is addressed. The problem is comprised of
covering a set of points in the plane by discs with the restriction that their centers have to lie on a set of
line segments that represents the railway tracks. A similar problem is addressed in [16], where the discs
must be centered on two intersecting lines.
The location problem we address in this paper is a special disc covering problem in the following ways:

• There are different types of facilities, which in our case are radar sensors, where the area covered
by each radar is a disc with a diameter x that depends on the power of the radar unit.
• The cost ci of locating disc i includes a nonnegative fixed cost fi and a variable cost, which may be
approximated by an homogeneous polynomial function g(xi ). In particular, g(xi ) is modeled as a
second-order polynomial.
• A line segment with negligible width has to be covered by the discs. As it will be clear in Section 3,
we may assume that the segment has unit length with no loss of generality.

We refer to our problem as the Disc Covering Problem on a Line.
The paper is organized as follows. In Section 2 some preliminary results are presented for the case
of identical disc (radar) types and convex cost functions. In Section 3, the general case is presented
and a quadratic programming formulation is developed. A Lagrangean relaxation of the problem and a
technique to solve such a relaxation is also proposed. Section 4 presents a branch-and-bound algorithm for
the problem: upper and lower bounding techniques are illustrated and a branching strategy is discussed.
Some computational results are given in Section 5. Finally, some concluding remarks are made in Section 6.

2

Notation and preliminary results

We denote by Q the set of the q available discs (radars). For all i ∈ Q, at most one copy of disc i may be
used for covering the line segment and any power level is allowed so that we can have any disc coverage
distance 0 ≤ xi ≤ 1. These assumptions may appear restrictive for real applications but note that (i)
usage of multiple copies of the same disc type may be modeled by including in Q a suitable number of
items with the same characteristics and (ii) if a limit D exists on the coverage distance, then the problem

4

may be decomposed by splitting the segment into pieces whose lengths are not greater than D and solving
the problems for each segment separately (this may be an effective heuristic approach).
For any selected disc i ∈ Q, the coverage distance is the diameter of the disc xi ∈ R+ , and its
contribution in the total cost function is

 0
ci (xi ) =
 f + g (x )
i
i i

if xi = 0

,

if xi > 0

where gi (·) is convex with gi (0) = 0 and the setup cost fi is nonnegative. Although, because of the fixed
cost component, the cost function ci (xi ) is nonconvex in 0 ≤ xi ≤ 1, when the set of selected discs S, i.e.,
those for which xi > 0, is fixed, then total coverage is in fact convex and the problem of determining the
covering diameters is easily solved using KKT conditions (see Section 3).
Note that once xi is given for all i ∈ Q (we will have xi = 0 for those radars that are not selected), it
is trivial to find the set of optimal locations: just align the discs so that they do not intersect and they
cover the entire line. For this purpose we choose the diameters in such a way that their sum is equal to
the length of the line, which in our case is equal to 1. An illustration of a feasible solution to our problem
is given in Figure 1.

1 unit

Figure 1: Example of a feasible solution
We now present some simple results concerning the case when all available discs are of the same type,
that is, for all i ∈ Q and x > 0, ci (x) = c(x) is a general nonnegative convex function. To the best of
our knowledge, these results, though straightforward, are not present in the literature. However, it is
worthwhile to point out that, differently from [1], where the objective function is of the form rα and both
the potential facility locations and the demand points are discrete sets, we exploit the fact that we deal
with a continuous line segment to obtain efficient solutions for even more general cost functions.
When the discs are all of the same type, our problem reduces to finding the optimal number k ≤ q of
copies and the optimal coverage area for each copy.

5

Proposition 1 When all the discs are of the same type having the cost functions ci (·) = c(·), for all
i ∈ Q, if an optimal solution consists of locating k discs, then there is one solution where each of the k
discs has the same diameter.
Proof. Based on the convexity of c(x), for any k-uple of nonnegative numbers x1 , . . . , xk , with
1, we have:

  X
k
1
c(xi ).
≤
k·c
k
i=1

Pk

i=1

xi =

(1)

Hence, the cost of locating k discs (of the same type) with equal diameters—that is, each disc covers an
equal portion of the line segment—does not exceed the cost of any other feasible solution that uses k
discs. 
Proposition 1 clearly indicates the optimal locations of the discs since they need to be uniformly spaced
over the line segment.
The next natural question we need to ask is “What is an optimal number of such discs, that is the
best value for k?”.
First we write c(x) = f + g(x) with f ≥ 0 and g(0) = 0. Note that we may install at most q discs of
the same type on the line. It is easy to observe that with zero setup costs (f = 0) the cheapest solution
consists of installing the largest possible number (q) of facilities.
A solution that uses k + 1 discs costs no more than a solution with k discs if and only if the following
is true:
f + (k + 1) · g



1
k+1



≤k·g

 
1
.
k

(2)

If f = 0, the last inequality is always valid, because of the convexity of g(·). Therefore, it is cost-effective
to locate another disc if the additional setup cost does not exceed the gain in the variable costs.
The effective cost of locating k discs is
1
F (k) = kc( ) = kg
k
Since g(·) is convex,
∂2F
=
∂k 2



1
k3



Hence, there must be 1 ≤ k ∗ ≤ q such that

 
1
+ kf.
k


∂ 2 g 
≥0
∂k 2  1

(3)

(4)

k

F (1) ≥ F (2) ≥ . . . ≥ F (k ∗ ) and F (k ∗ ) ≤ F (k ∗ + 1) ≤ . . . ≤ F (q).

(5)

Therefore, since a binary search can be used to efficiently find the k ∗ , the following proposition holds.
6

Proposition 2 When the q discs are all of the same type with the cost functions ci (·) = c(·), for all
i ∈ Q, the problem is solvable in O(C log(q)) time, where C is the maximum computational effort for
calculating c( k1 ). 

3

Problem formulation

In this section we develop a quadratic programming formulation of the general problem where the q discs
(radars) may have different properties. Using the notation introduced in Section 2, the cost contribution
of any disc i ∈ Q that covers an area having diameter xi is a quadratic polynomial
ci (xi ) = fi + bi x2i
with fi ≥ 0, bi > 0. Then the location problem can be formulated as the following Mixed Integer Quadratic
Program.
z ∗ = min

X

fi yi + bi x2i

i∈Q

s.t.
(P )

xi ≤ yi , for all i ∈ Q
X
xi = 1

(c1)
(c2)

i∈Q

x ∈ Rq+

(c3)

y ∈ {0, 1}q

(c4)

In the solution of P , y is the vector to indicate selected discs (radars) in Q where yi = 1 if disc i is used,
yi = 0 otherwise. Constraints (c1) force the disc coverage diameter xi to be zero when the corresponding
disc i is not selected (and therefore the corresponding cost contribution is zero). Constraint (c2) is the
coverage constraint that assures that the whole line segment is covered.
As stated before, the unit length assumption does not introduce any loss of generality. It is clear that
e where the line has length ℓ 6= 1. Let I˜ be an instance of
P can be equivalently used for a problem P

e where the cost coefficients for the disc i are f˜i and b̃i . Then we can solve I˜ by solving an equivalent
P
instance I of the unit length problem P having cost coefficients fi = f˜i and bi = ℓ2 b̃i . If (x, y) is an

˜
optimal solution of I, then (ℓx, y) is optimal for I.
In the remainder of the paper we propose methods to solve problem P and discuss the results of some
computational experiments to evaluate the performance of these methods.

7

Our first observation concerns the existence of efficient methods to find the optimal coverage when
the set S ⊆ Q of selected discs (i.e. active radars) is given or known a priori. Under this assumption,
the variables yi = 1 for all i ∈ S in problem P and the resulting problem is easily solved by applying
Karush-Kuhn-Tucker optimality (KKT) conditions. In fact, this restriction of the problem can be written
as
(RP )

z(S) = min

(

X

fi +

bi x2i

:

i∈S

X

xi = 1; xi ∈ R+ , i ∈ S

i∈S

)

.

Problem RP is a convex optimization problem. Define the following Lagrangean function (without loss
P
of generality, the constant term i∈S fi has been omitted in the objective function below):
!
X
X
X
2
L(x, µ, λ) =
bi xi + λ 1 −
µi xi
xi −
i∈S

∗

∗

i∈S

i∈S

∗

The KKT conditions, for the triple (x , µ , λ ), are
∇x L(x∗ , λ∗ , µ∗ )
X
x1

= 0q
= 1

i∈S

T

µ∗ x∗

= 0

x∗

≥ 0q

µ∗

≥ 0q

It follows from x∗i > 0 that µ∗i = 0 for all i ∈ S. Then,
λ∗ = P

1

1
j∈S 2bj

and
x∗i =

1

λ∗
= P 2bi
2bi
j∈S

1
2bj

,

i∈S

satisfy the KKT conditions and, therefore, are a global optimum for problem RP .
Although coverage diameters may be computed in a closed-form, choosing the subset S ⊆ Q of active
radars is a tedious computational task. The branch-and-bound algorithm described in Section 4 relies on
a dual bound estimation which is developed in the next subsection.

3.1

Lagrangean relaxation of P

We will use Lagrangean relaxation to obtain a lower bound on z ∗ , the optimal solution value of problem
P . Relaxing constraints (c1) of P using nonnegative Lagrangean multipliers κi , i = 1, . . . , |Q|, we obtain
the following problem:
8

zLRP (κ) = min

X

(fi − κi )yi + bi x2i + κi xi

i∈Q

s.t.

(LRP )

X

xi = 1

(c5)

i∈Q

x ∈ Rq+

(c6)

y ∈ {0, 1}q

(c7)

Problem LRP, a relaxation of P for any κ ≥ 0q , is decomposable since optimal values for the yi variables
are independent of the values of the xi variables. In particular, we may choose the following optimal
values for y:


 1 if
yi∗ =
 0 if

f i < κi

for all i ∈ Q.

f i ≥ κi

The remaining convex program, which depends on the x variables only, is:
zLRP ′ (κ) = min
s.t.

(LRP ′ )

bi x2i + κi xi
X
xi = 1

(c8)

i∈Q

x ∈ Rq+
and therefore zLRP (κ) = zLRP ′ (κ) +

P

i∈Q

(c9)

(fi − κi )yi∗ . In order to solve problem LRP ′ , we define the

following Lagrangean function, where we use multiplier λ ∈ R for constraint (c8) and multipliers µ ∈ Rq+
for nonnegativity constraints (c9):
Lκ (λ, µ) = min

X

i∈Q

Then the KKT conditions are



(bi x2i + κi xi − µi xi ) + λ 1 −

∇xi Lκ (x∗ , λ∗ , µ∗ ) = 2bi x∗i + κi − µ∗i − λ∗ = 0
X
x∗i = 1

X

i∈Q



xi .

for all i ∈ Q

(6)
(7)

i∈Q
T

µ∗i x∗i = 0

for all i ∈ Q

(8)

x∗i ≥ 0, µ∗i ≥ 0

for all i ∈ Q.

(9)

From (6) we have
x∗i =

1 ∗
(λ + µ∗i − κ∗i )
2bi

for all i ∈ Q.

(10)

In order to find values for x∗i , λ∗ , µ∗ that satisfy KKT conditions (6)–(9), let S (so far unknown) include
the set of indices that correspond to positive covering diameters in the optimal solution, that is S = {i ∈
9

Q : x∗i > 0}. Given S, we have from (8) that µ∗i = 0 for all i ∈ S and we obtain the following relations:
x∗i =

1 ∗
(λ − κi ),
2bi

µ∗i = 0

x∗i = 0, µ∗i = κi − λ∗

for all i ∈ S

(11)

for all i ∈ Q \ S.

(12)

Furthermore, from (11) and (12), we have that
x∗i > 0 ⇒ λ∗ > κi

for all i ∈ S

(13)

µ∗i ≥ 0 ⇒ λ∗ ≤ κi

for all i ∈ Q \ S.

(14)

Suppose now, without loss of generality, that the κi values are in nondecreasing order. From relations
(13) and (14), we have:
κ1 ≤ κ2 ≤ . . . ≤ κh < λ∗ ≤ κh+1 ≤ . . . ≤ κq .
|
{z
}
|
{z
}
S

∗

(15)

Q\S

∗

Hence, S has the form S = {1, . . . , h }, h ≤ q, and we obtain the following expression for λ∗ (using
equations (7), (11), (12)):
∗

λ∗ =

h
X
κi
1+
2bi
i=1
∗

h
X
1
2b
i
i=1

> 0.

(16)

Since the feasible region of LRP ′ is a closed convex set and its objective function is convex, this problem
admits a (finite) optimal solution. In particular any local optimum that satisfies the KKT conditions is
an optimal solution for LRP ′ and vice versa. Therefore, there must exist an optimal solution x∗ of LRP ′ ,
together with corresponding optimal multipliers λ∗ ∈ R, µ ∈ Rq+ , that satisfy the KKT conditions (6)–(9).
Therefore, once the κi are arranged in nondecreasing order, a set of indices S = {1, . . . , h} (1 ≤ h ≤ q)
necessarily exists such that (15) is satisfied, and expressions (11), (12), and (16), return an optimal
solution (x∗ , λ∗ , µ∗ ) to LRP ′ .
We may find h, that is, the set S = {1, . . . , h} of indices corresponding to selected discs, with a O(log q)
binary search. Because it is the sum of at most q elements, it is possible to compute λ∗ by (16) in O(q)
time. The same time is required to compute the values x∗i , which are at most q and each is computable
in constant time (using expression (11)). Additional O(q) steps are necessary to determine the value for
the y variables. Hence the following proposition holds:
Proposition 3 Given a set of q nonnegative Lagrangean multipliers κ ∈ Rq+ , the solution of the Lagrangean problem LRP′ can be found in time O(q log q), which is the computational cost of ordering the
multipliers. 
10

Recalling that zLRP (κ) = zLRP ′ (κ) +

P

i∈Q

(fi − κi )yi∗ , we observe that a solution of problem LRP —and

therefore a lower bound for the optimal solution value of P —can be found in time O(q log q).

4

An exact algorithm for P

In this section, we develop a branch-and-bound algorithm that finds an optimal solution of P . This implicit
enumeration scheme exploits the lower bounds (LB) obtained by a subgradient optimization algorithm
described in Section 4.1 and upper bounds (UB) by an efficient local search-based heuristic (described in
Section 4.2). Branching and subproblem solution strategies are discussed in Section 4.3.

4.1

Lower bound via a subgradient algorithm

For any κ ∈ Rq+ , the optimal solution value zLRP (κ) of LRP provides a lower bound on the value of the
optimal solution value of P . We are now interested in obtaining the best (largest) lower bound by solving
the following Lagrangean Dual Problem:
(DP )

∗
zLRP
= zLRP (κ∗ ) = max {zLRP (κ) : κ ∈ Rq+ }

In our approach, the solution of DP is obtained by a standard subgradient optimization algorithm that
is summarized in Figure 2. (The actual values of parameters α and ti used in the implementation are
reported later.) The proposed Lagrangean relaxation method not only provides the lower bounds that
we use in our enumeration scheme but it is also exploited in an efficient heuristic procedure which is
presented in the next section.

4.2

Upper bound via a heuristic algorithm

The basic idea for this heuristic algorithm based on the Lagrangean Relaxation is to obtain a feasible
solution of LRP by establishing all the discs (radars) corresponding to xi > 0 (i.e., i ∈ S) and, possibly,
removing unused discs (i.e., switching off all the unnecessary radars) (i ∈
/ S).
In general, given a subset S ⊆ Q, we may easily compute feasible values for the coverage diameters
xi , for all i ∈ S, using the KKT conditions—as described in Section 3. Note that the values xi provided
by the solution of LRP ′ are feasible but, in general, they may not be optimal since the corresponding set
of discs S may not be optimal. We may further refine the set S using a simple local search which exploits
11

Subgradient optimization algorithm for DP.
S1 Set the parameters: choose an α such that 0 < α < 2; LB := −∞;
U B provided by heuristic; κ = 0q .
S2 Solve LRP. Let x∗i , yi∗ be the optimal variable values obtained for
LRP and zLRP (κ) its optimal value. If x∗i ≤ yi∗ and κi (yi∗ − x∗i ) = 0,
∀i = {1, . . . , q}, then x∗i , yi∗ are feasible and optimal for the original
problem P .
S3 Set LB := max{LB, zLRP (κ)}. If LB does not improve for a maximum number (typically 20) of iterations, set α := α/2.
S4 Set subgradient si = x∗i − yi∗ and step ti =

α(U B − LB)
Pq
.
2
i=1 si

S5 Update multipliers κi = max{0, κi + ti si }, ∀i = {1, . . . , q}.
S6 If number of iterations exceeds a specified limit: STOP. Else: go to
step S2.

Figure 2: Subgradient algorithm for DP .
KKT conditions to find the cheapest location and coverage for a given set of selected discs. Figure 3
summarizes the heuristic.

4.3

Exact branch-and-bound algorithm

In this section, we present a branch-and-bound algorithm for P that uses the lower and upper bounds
developed above in Sections 4.1 and 4.2.

4.3.1

Solution strategy

In the branch-and-bound tree, each node ν represents a subproblem that is defined by (i) a set T of selected
discs (i.e. active radars which must be ON) in the solution, that is T = {i : yi = 1; i = {1, . . . , q}} ⊆ Q,
(ii) a set of discs that cannot be in the solution (i.e. radars that must be OFF) and (iii) a set of
discs that are not yet decided upon (i.e., radars that are not yet fixed to ON or OFF). If a radar is
OFF, we consider the corresponding disc deleted from the set of available discs (radars) for that specific
subproblem. Let Q(ν) be the set of available discs at node (subproblem) ν. Then the generic subproblem
may be formulated as follows:

12

Heuristic algorithm for P.
H1 Choose nonnegative values for penalties (Lagrangean multipliers)
κi , i = {1, . . . , q} (e.g., those found by the subgradient algorithm
in Figure 2).
H2 Sort vector κ in nondecreasing order.
H3 Compute the set S of selected discs and the corresponding values for the xi using the KKT-based method presented end of
Section 3.1. Then, the cost of this feasible solution is z(S) =
n
o
P
i
min i∈S fi + bi P 1/2b1/2b
.
j
j∈S

H4 Perform a local [greedy] search on S for a limited number of iterations, by
(a) Trying to remove a disc (starting from the one with the largest
fi among those selected) and computing the resultant z(S).
Update S if the solution is improved.
(b) Trying to establish a disc (starting from the one with the smallest fi among those not located) and computing the resultant
z(S). Update S if the solution is improved.

Figure 3: Heuristic procedure for P .

13

min

X

i∈Q(ν)\T

s.t.
(P (T, ν))

 X

fi yi + bi x2i +
fi + bi x2i
i∈T

xi ≤ yi for all i ∈ Q(ν) \ T
X
xi = 1

(c1ν )

xi ≥ 0

(c3ν )

(c2ν )

i∈Q(ν)

for all i ∈ Q(ν)

yi ∈ {0, 1}

for all i ∈ Q(ν) \ T

(c4ν )

Again, similarly to what was done in Section 3.1 for problem LRP, relaxing constraints (c1ν ) in a
Lagrangean fashion, using multipliers κi with κi = 0 for all i ∈ T , we obtain problem LRP (T, ν):



 X
X
X

(fi − κi ) yi +
fi : (c2ν ), (c3ν ) and (c4ν )
min
bi x2i + κi xi +


i∈Q(ν)

i∈T

i∈Q(ν)\T

which, in turn, is equivalent to



 X

bi x2i + κi xi : (c2ν ), (c3ν ) +
min


i∈Q(ν)

X

(fi − κi ) +

i∈Q(ν)\T, fi <κi

X

fi

i∈T

Neglecting the last two constant summations, we have a problem in the x variables which is a special

instance of LRP ′ defined in Section 3.1. Thus, a lower bound can be computed at each node by solving
the Lagrangean dual of the corresponding problem LRP (T, ν), by means of the procedure summarized in
Figure 2.
An upper bound at the root node is provided by the heuristic in Figure 3.

4.3.2

Branching strategy

At node ν of the enumeration tree, we branch on a binary variable yi , i ∈ Q(ν) \ T , splitting subproblem
ν into two new subproblems ν ′ and ν ′′ . Disc i is selected in ν ′ (i.e. yi = 1 and T := T ∪ {i}) and it is
deleted in ν ′′ (i.e. yi = 0 and Q(ν ′′ ) := Q(ν) \ {i}).
Let κ∗i be the optimal values for the multipliers in the solution of the Lagrangean dual, and x∗i , yi∗ ,
i ∈ Q(ν) \ T the optimal variable values obtained for LRP (T, ν). The branching rule is to branch on a
variable yi , such that yi∗ = 0 and x∗i > 0. If such a variable does not exist (i.e., x∗ and y ∗ are feasible for
the subproblem ν) then branch on variable yi∗ , such that yi∗ = 1, x∗i < 1 and κ∗i > 0. If such a variable
does not exist then κ∗i (yi∗ − x∗i ) = 0, for all i ∈ Q(ν) \ T and, therefore, the x∗ and y ∗ are (feasible and)
optimal for subproblem ν. The corresponding node in the enumeration tree is then fathomed.
14

5

Computational experiments

The design of the computational experiments is described in the next subsection while the computational
results are discussed in Section 5.2. All the results reported in this section refer to tests performed on a
3.00 GHz Pentium IV, 1024 MB RAM, running Windows XP. The algorithms have been coded in C++.
See [8] for more details.

5.1

Design of experiments

Any instance of Problem P is characterized by a pair of vectors with q components (b, f ), representing
discs’ variable and fixed costs.
We say that a disc i dominates disc j if (bi ≤ bj ), (fi ≤ fj ), and (bi , fi ) 6= (bj , fj ). In our experiments
no disc pair exists such that one is dominated by the other, since there is no sense in considering dominated
disc types in Q.
Therefore, we impose the following cost relations:
b1 ≤ b2 ≤ · · · ≤ bq

and f1 ≥ f2 ≥ · · · ≥ fq .

We start with a special class of instances (“base class”) having the following properties:
• (bi 6= bj ) and (fi 6= fj ), for all 1 ≤ i < j ≤ q.
• On the average, bi+1 ≈ bi + 1 for all 1 ≤ i < q.
• bi = fq−i+1 , for all 1 ≤ i ≤ q (to exclude dominated cases).
We generate all the instances used in the experiments by suitable modifications of a randomly generated
base class instance. In particular, any instance is identified by the four integers (q, s, t, u), where
q: the number of available discs which determines the size of the instance.
s: amplification factor by which b of the base class instance is multiplied. For instances with this
parameter, on the average, b ≈ {s, 2s, . . . , qs}.
t: the parameter that characterizes the vector of setup costs f , which is obtained using t ≥ 1 as a
multiplication factor of the b vector determined as above: on the average, fq−i+1 ≈ tbi for instances
with this parameter.
15

u: the parameter that identifies the configuration for the test instance where a suitable subset of the
cost coefficients bi , or the setup costs fi , or both, have the same value. 10 configurations were
defined and u was labeled 0, 1, . . . , 9 where u = 0 defines the base class where bi and fi all have
different values. For example u = 2 defines the class where the fi for the selected discs in the
optimal base class solution are set to the maximum f value in the base class. Parameter u attempts
to make systematic changes with respect to fi and bi values in various instances. While some other
u labels are described later in this paper, see [8] for more details on the other u labels.

As an example, the class (50, 1, 100, 0) refers to instances with 50 discs, all different types (since u = 0),
cost coefficients bi as in the base class, and setup costs fi amplified by a factor t = 100.
A set of preliminary tests were performed to determine the largest instances that our algorithm is
able to solve optimally, in order to design our experiments. Results are reported in Table 1. All the
instances of this preliminary test-set belong to the class (q, 1, 1, 0). The branch-and-bound algorithm
solved instances up to q = 400 in less than 16 hours. No instance with q = 500 was solved within the
same time limit. Almost all the instances with q up to 200 are solved within one hour.
q

150

200

350

400

500

CPU time

1217.97 s.

2544.76 s.

∼ 3.5 hr.

∼ 15.0 hr.

> 16 h

Table 1: Preliminary test-set results

Based on these preliminary results, we planned our experiments with the following sizes: q ∈ {10, 25, 50,
100, 200, 350, 400}. Maximum running time was set to 1 hour (CPU time), except for the case q = 400
where there was no timeout requirements. For each class except the q = 400 case, 10 random instances
were generated and the following average quantities were tracked:

• CPU time.
• Number of nodes in the enumeration tree.
• Depth of the enumeration tree.
• Upper bound at the root node.
• Optimal solution value, if any. (A minus “–” symbol is shown when the optimum is not reached
within the time limit.)
16

• Best lower bound available after 1 hour.
• Percentage gap (U B − LB)/U B.

5.2

Results and analysis

Table 2 summarizes the results of the experiments. Each row shows, in order, the quantities of the above
list, for one class of instances. Class name is reported in the first column where an asterisk “∗ ” denotes
that, in at least one instance of the class, the algorithm did not reach the optimal solution value within
the time limit (i.e. CPU time greater than 3600 sec.). The table also gives the initial “gap” between the
UB and the LB at the root node, computed as (U B −LB)/U B. The results for classes with u = 3, 4, 6, 8, 9
are not reported in Table 2 for the sake of brevity. For these classes, the performance of the algorithm is
indeed comparable or even better than those reported.
First, we highlight the excellent performance of the heuristic: in all the experiments the value found
by this procedure (U Broot ) equals the optimal value (opt.) found by the branch-and-bound algorithm.
A few comments are in order:
1. Not surprisingly, branch-and-bound computational time is strictly related to the enumeration tree
size: Table 3 shows strong positive correlation of CPU time with the number of nodes in the
enumeration tree.
2. For a given number of discs q, we note that the CPU time does depend on the particular cost
configuration, that is, on the particular pair (s, t). The most difficult instances have t = 1 (i.e.,
bi ≈ fq−i+1 ); and, viceversa, the larger the t in comparison to s, the faster the computation.
3. Classes with u = 2 and u = 5 are the hardest. Parameters are chosen so that finding the set of
selected discs becomes more difficult. For any instance I of the base class, we build the corresponding
u = 5 instance I ′ as follows. Let S be the set of selected discs in the optimal solution of I. The
costs in I ′ are: b′i = bi if i 6∈ S, b′i = max{b1 , . . . , bq } if i ∈ S. Analogously fi′ = fi if i 6∈ S,
fi′ = max{f1 , . . . , fq } if i ∈ S.
The u = 2 class is designed similarly but with b′i = bi , for all i = 1, . . . , q. (Experimental results for
the u = 2 class were similar to those of the u = 5 class; therefore Table 2 reports only the latter.)
4. Figure 4 shows the CPU time cumulative distribution. The histogram was obtained empirically
over 90 instances (with q = 25): 80% of the instances are solved in a time smaller than 2.6 s. while
the largest CPU time is an order of magnitude higher (17.2 s.).
17

instance

CPU

(q, s, t, u)

time (s.)

10,10,1,0

nodes’ #

depth

U Broot

opt.

LB

gap†

1.547

29

10

77.368

77.368

44.8017

42.01%

10,10,1,1

1.469

27

10

80

80

46.696

41.63%

10,10,1,5

1.562

37

10

110

110

75.526

31.64%

10,1,100,0

0.063

0

0

506

506

506

0%

10,1,100,1

0.062

0

0

110

110

110

0%

10,1,100,5

0.047

0

0

506

506

506

0%

100,10,1,0

464.81

987

100

345.96

345.96

135.31

60.89%

100,10,1,1

464.25

1009

100

348.35

348.35

135.74

61.03%

100,10,1,5

932.47

1955

96

496.22

496.22

172.64

65.21%

100,1,100,0

31.937

135

67

200

200

187.44

6.28%

100,1,100,1

32.125

131

65

200

200

187.5

6.25%

100,1,100,5

33.047

131

65

596

596

584.92

1.86%

200,10,1,0

2586.01

2737

200

539.14

539.14

189.31

64.89%

200,10,1,1

2866.91

2527

200

540.8

540.8

189.66

64.93%

200,10,1,5*

> 3600

> 2597

≥ 195

737.98

–

227.93

69.12%

200,1,100,0

208.7

341

169

300

300

241.54

19.49%

200,1,100,1

189.281

361

174

300

300

241.67

19.45%

200,1,100,5

206.38

337

167

696

696

639.7

8.09%

350,10,1,0*

> 3600

> 2021

≥ 345

775.7

–

234.2

69.81%

350,10,1,1

959.97

1827

345

776.91

776.91

234.74

69.79%

350,10,1,5*

> 3600

≫ 1289

≥ 344

1022.49

–

285.4

72.09%

350,1,100,0

985.38

719

350

450

450

301.56

32.99%

350,1,100,1

959.97

703

350

450

450

298.51

33.67%

350,1,100,5

964.44

673

328

846

846

700.2

17.23%

400,1,1,0

36705.2

17373

400

84.71

84.71

24.28

71.34%

Table 2: Experiments results. († Gap is computed as the initial (U B − LB)/U B, where LB is the (initial) lower
bound at the root node.)

18

q

10

25

50

100

ρnodes

0.982

0.998

0.999

0.999

Table 3: Correlation coefficient between CPU time and number of nodes of the enumeration tree.

1
0,9

% of instances

0,8
0,7
0,6
0,5
0,4
0,3
0,2
0,1
0
0,2

2,6

5,6

10,8

15,4 17,4

Seconds

Figure 4: CPU time cumulative distribution (q = 25, time in seconds).
We noted previously that fixed costs are related to the choice of the subset S and they heavily affect
the computational effort required by an instance. An evidence of this fact is illustrated in Table 4 where
the results of the experiments with q, s, t = 10, 1, 1 are compared for three values of u (u = 0, 1, 3). Note
instance

Opt. radii

S∗

xi , i ∈ S ∗

(q, s, t, u)
10,1,1,0

{9,10}

{0.526, 0.474}

10,1,1,1

{9,10}

{0.5, 0.5}

10,1,1,3

{7,8,9}

{0.377, 0.330, 0.293}

Table 4: Set S ∗ (optimal set) response to fi and bi variations for q = 10 and u = {0, 1, 3}.

that the u = 0 class is the base class.
Given an instance I of the base class, we build the corresponding u = 1 (u = 3 respectively) instance
′

I as follows. Let S be the set of selected discs in the optimal solution of I. The costs in I ′ are:
b′i = max{b1 , . . . , bq } (fi′ = min{f1 , . . . , fq } respectively) for i ∈ S. All the other parameters remain equal
to those in the base class.
When the bi are varied (compare classes with u = 0 and u = 1 in Table 4) the optimal solutions are

19

slightly different. However, when the fi vary (compare classes with u = 0 and u = 3) the two optimal
solutions drastically differ from each other: there are three discs selected instead of two.

6

Conclusions and future work

In this paper we introduced and addressed the problem of covering a single line segment with radar
sensors having a circular field of view. When the sensors are required to have identical radius, a simple
polynomial search solves for optimal radius and number of sensors. When the sensors are modeled with
variable diameter discs the problems becomes hard. We provided an exact solution algorithm which is
based on a Lagrangean relaxation and a subgradient algorithm to find a lower bound (see Figure 2).
A feasible solution is provided by the heuristic summarized in Figure 3. These bounds were exploited
to design a branch-and-bound algorithm. Extensive computational testing, based on approximately 400
experiments, showed that the developed heuristic performs very well; the upper bounds were always equal
to the optimal solution whenever the latter was known (see Table 2). The experiments also show that
setup costs play a crucial role both in computational effort and attainment of the optimal solution set.
Several directions for future work are being pursued. The two-arc network and planar tree network
cases are being investigated (both for single and multiple discs types, for fixed and variable radius). Since
discs can be located both on the arcs and on the plane, these are mixed network–planar problems and
the development of locational models and algorithms is indeed very challenging.

Acknowledgments
The authors wish to acknowledge the support of the ATLAS Center at the University of Arizona where
most of this research was conducted and the support of Waveband Inc. that partially funded this effort
through its SBIR Contract ARMY03-T18 with the US Army.
The authors also gratefully acknowledge the helpful comments and constructive suggestions of the two
anonymous referees.

20

References
[1] H. Alt, E. M. Arkin, H. Brönnimann, J. Erickson, S. P. Fekete, C. Knauer, J. Lenchner, J. S. B.
Mitchell, and K. Whittlesey. Minimum-cost coverage of point sets by disks. In Proc. 22nd Annual
ACM Symposium on Computational Geometry, pages 449–458, June, 5–7 2006.
[2] H. Brönnimann and M. T. Goodrich. Almost optimal set covers in finite VC-dimension. Discrete
Computational Geometry, 14:463–479, 1995.
[3] V. Chvátal. A combinatorial theorem in plane geometry. Journal of Combinatorial Theory, 18:39–41,
1975.
[4] M. Franceschetti, M. Cook, and J. Bruck. A geometric theorem for approximate disk covering
algorithms. Technical report, California Institute of Technology, 2001.
[5] M. Franceschetti, M. Cook, and J. Bruck. A geometric theorem for network design. In IEEE
Transactions on Computers, volume 53, pages 483–489, 2004.
[6] M. Galota, C. Glaßer, S. Reith, and H. Vollmer. A polynomial-time approximation scheme for base
station positioning in UMTS networks. In Proceedings of the 5th international workshop on Discrete
algorithms and methods for mobile computing and communications, pages 52–59, 2001.
[7] A. Ghosh and G. Rushton. Spatial Analysis and Allocation-location Moulding. Van Nost. Reinhold
Company, New York, 1987.
[8] E. Grande. Localizzazione di radar per il monitoraggio di bacini fluviali (english translation: Radar
locations for river monitoring). Master’s thesis, University of Rome “Tor Vergata”, Italy, 2005.
[9] H. Hamacher, A. Liebers, A. Schbel, D. Wagner, and F. Wagner. Locating new stops in a railway
network. Electronic Notes in Theoretical Comnputer Science, 50:11 pages, 2001.
[10] D. S. Hochbaum and W. Maas. Approximation schemes for covering and packing problems in image
processing and vlsi. Journal of the ACM, 32(1):130–136, January 1985.
[11] F. Hoffmann, M. Kaufmann, and K. Kriegel. The art gallery theorem for polygons with holes. In
32nd Annual Symposium onmFoundations of Computer Science, pages 39–48, San Juan, Puerto Rico,
October 1991.
[12] C.-F. Huang and Y.-C. Tseng. A survey of solutions to the coverage problems in wireless sensor
networks. Journal of Internet Technology, 6:1–8, 2005.
21

[13] A. Kolen and A. Tamir. Discrete Location Theory, chapter 6: “Covering Problems”, pages 263–304.
John Wiley & Sons, Inc., New York, 1990.
[14] X.-Y. Li, P.-J. Wan, and O. Frieder. Coverage in wireless ad hoc sensor networks. In IEEE Transactions on Computers, volume 52, pages 753–763, 2003.
[15] R. F. Love, J. G. Morris, and G. O. Wesolowsky. Facility Location: Models and Methods. NorthHolland Publishing Company, New York, 1988.
[16] M. F. Mammana, S. Mecke, and D. Wagner. The station location problem on two intersecting lines.
Electronic Notes in Theoretical Comnputer Science, 92(1):12 pages, 2003.
[17] S. Meguerdichian, F. Koushanfar, M. Potkonjak, and M. B. Srivastava. Coverage problems in wireless ad-hoc sensor networks. In INFOCOM 2001. Twentieth Annual Joint Conference of the IEEE
Computer and Communications Societies, volume 3, pages 1380–1387, Anchorage, AK, USA, 2001.
[18] P. B. Mirchandani and R. L. Francis. Discrete Location Theory. John Wiley & Sons, Inc., New York,
1990.
[19] J. O’Rourke. Art Gallery Theorems and Algorithms. Oxford University Press, 1987.
[20] A. Pacifici, P. Mirchandani, M. Mecoli, and A. Agnetis. Locational decisions for barge-tracking
radars. Technical report, The A.T.L.A.S. research center, 2004.
[21] B. Wang. A survey on coverage problems in wireless sensor networks. Technical report, ECE Dept.,
National University of Singapore, 2006.
[22] B. Xiao, Q. Zhuge, Y. Zhang, and E. H.-M. Sha. Algorithms for disk covering problems with the
most points. In Proc. IASTED International Conference on Parallel and Distributed Computing and
Systems (IASTED PDCS), pages 541–546, Marina del Ray, CA, November 2003.

22

SCHEDULING WITH SETUPS ON A TWO-MACHINE FMS

Eng-Joo Lee and P i t u B. Mirchandani

E l e c t r i c a l , Computer,andSystemsEngineeringDepartment
RensselaerPolytechnicInstitute
Troy, New York 12180
p h y s i c a l l yo rl o g i c a l l y ,
forms a f l e x i b l e manufact u r i n gc e l l
( F M C )L. i n k i n g
a g r o u po f
FMCs
t o g e t h e r by a s o p h i s t i c a t e d m a t e r i a l h a n d l i n g s y s The t y p e so fa u t o m a t e do p e r a t i o n s
a flexible
temand
a c o m p u t e rc o n t r o ls y s t e mr e s u l t si n
a
m a n u f a c t u r i n gm a c h i n ec a np e r f o r md e p e n do nt h e
flexible manufacturing system
(FMS).
t o o l sa v a i l a b l ei n
i t s t o om
l a g a z i n e S. i n c e
FMSs a r e b e l i e v e d t o h o l d t h e p o t e n t i a l f o r
magazinesetupsareusuallynon-automated,thetime
s o l v i n gt h em i d - v o l u m ep r o d u c t i v i t yp r o b l e m s
is n o tn e g l i g i b l e
and e f f o r tc o s tf o rs u c hs e t u p s
c r e a t e d by t h e i n f l e x i b i l i t i e s ofconventionalsysf o rs c h e d u l i n gp u r p o s e s .T h i sp a p e rc o n s i d e r st h e
t e m sa n dt h en e wa n dr a p i d l yc h a n g i n gm a r k e t
s c h e d u l i n gp r o b l e mo fm i n i m i z i n gt h ec o m p l e t i o n
e n v i r o n m e n tT
. h eo b j e c t i v eo af n
FMS i s t o
time o f a j o b l i s t ,w h e r ee a c hj o br e q u i r e s
two
" a c h i e v et h ee f f i c i e n c yo fa u t o m a t e d
massproduco p e r a t i o n sw i t ht h e
same p r e c e d e n c e o r d e r , o n
two
tionwhileutilizingtheflexibilityof
a manual
machines each capable of performing both operation
j ob s h o p "( S t e c k e ,
1983). However, t h ei n s t a l l a t y p e sb u tr e q u i r i n g
a m a g a z i n es e t u pi fo n eo p e r a t i o no f
a FMS i n v o l v e sv e r yh i g hc a p i t a l
t i o nt y p e
i s t ob ef o l l o w e db yt h eo t h e r .
The
i n v e s t m e n t . As such, i t shouldbeconsideredonly
paper shows t h a t i n a n o p t i m a l s c h e d u l e , a t m o s t
its costof
ifthepotentialbenefitscanjustify
o n es e t u pi sr e q u i r e d
oneachofthe
two machines.
i n s t a l l a t i o n and o p e r a t i o n .
H e u r i s t i c sa r ed e v e l o p e df o rs c h e d u l i n g
a joblist
o nt h i st w o - m a c h i n ef l e x i b l em a n u f a c t u r i n gs y s t e m
2. SETUP
ISSUES
IN FMS
SCHEDULIW
(FMS). For anempiricalevaluation,randomlygene r a t e dj o b l i s t sa r es c h e d u l e du s i n gt h e s e
The ' f l e x i b i l i t y ' commonly c o n s i d e r e di n a FMS
h e u r i s t i c s . A s would b ee x p e c t e d ,s c h e d u l e sw i t h
i s " t h ea b i l i t yo ft h es y s t e mt op r o c e s s
a wide
z e r os e t u p sa r eb e t t e r
when t h es e t u p
time i s
v a r i e t yo fp a r t so ra s s e m b l i e sw i t h o u ti n t e r v e n t i o n
l a r g e ;f o rs m a l ls e t u pt i m e ss c h e d u l e sw i t ho n e
and
f r o mo u t s i d et oc h a n g et h es y s t e m "a n dt h e
two s e t u p s become c o m p e t i t i v e .
" c a p a c i t yt or e s p o n dt oc h a n g e
i s containedwithin
thesystem"(Buzacott,
1982). T h i sf l e x i b i l i t y
is
1. INTRODUCTION
made p o s s i b l eb y ,
among o t h e r f a c t o r s , t h e v e r s a t i l i t y of e a c hi n d i v i d u a l
FMM. U n f o r t u n a t e l y ,i n
I nc o n v e n t i o n a lm a n u f a c t u r i n go fd i s c r e t e
t h es c h e d u l i n go f
FMS, t h i s machine v e r s a t i l i t y h a s
p a r t s f o r mid-volume production, dedicated machines
notbeenwellunderstoodin
i t s influenceonsystem
a r eu s e di n
a j o bs h o p - l i k ee n v i r o n m e n t E
. ach
e s p e c i a l l yw i t hr e g a r dt os e t u p
performance
machine i n t h e p r o d u c t i o n s y s t e m
i s u s u a l l yc a p a b l e
issues.
o fp e r f o r m i n go n l yo n ep a r t i c u l a ro p e r a t i o n .
G e n e r a l l y ,t h e r ea r e
two t y p e s o f s e t u p s :
S t a t i s t i c sr e v e a lt h a ts u c hs y s t e m sa r eg e n e r a l l y
&YX&XLM&L~E and mibs;hhn-sn~ugs. I n a s y s t e m
i n e f f i c i e n t ,h a v i n ga v e r a g em a c h i n eu t i l i z a t i o n
s e t u p , w e d e t e r m i n et h ep a r tt y p e st ob e
produced
r a t eo fo n l y
6% ( D u p o n t - G a t e l m a n d , 1982).
Also,
i nt h en e x tp r o d u c t i o nc y c l e
and l o a d o n t o t h e
FMS
this type of
mid-volume p r o d u c t i o n o f t e n e n c o u n t e r s
t h e n e e d e d numberandtypesof
j i g s and f i x t u r e s ,
e x c e s s i v ew o r k - i n - p r o c e s si n v e n t o r i e s
and l a r g e
and t h e
t h er e q u i r e d s e t oftoolsforeachmachine,
non-productivesetup
times.
software programs.
However, a q u i e t r e v o l u t i o n h a s b e e n g o i n g o n
W i t hr e g a r dt om a c h i n es e t u p s ,t h e r ea r et w o
i nt h em a n u f a c t u r i n gw o r l dt h a t
i s c h a n g i n gt h e
k i n d so fs u c hs e t u p s .
The f i r s t , which we s h a l l
mode of mid-volume productionmethods.Computers
maeazine s e t u p , o c c u r s when we d e t e r refertoas
a r eb e i n gu s e df o rc o n t r o l l i n g
and monitoringthe
m i n ea n dl o a do n t ot h e
FMM t h es e to ft o o l st h a t
p r o c e s s e s and t h eh i g hd e g r e eo fa u t o m a t i o nt h a t
i t s toolmagazine.
aretobeheldin
u n t i l r e c e n t l y was r e s e r v e df o r mass p r o d u c t i o ni n
The secondmachinesetup,which
we s h a l l r e f e r
a s s e m b l yl i n e sc a n
now b e a p p l i e da l s ot om i d t oa st o o l - c h a r ? g e s a & p ,o c c u r sb e t w e e nt w oc o n volumeproduction.
FMM. This i s t h ec a s e ,f o r
s e c u t i v et a s k sb yt h e
Over t h ep a s tt h r e ed e c a d e st e c h n o l o g i c a l l y
i n s t a n c e , when a r o b o ta u t o m a g . i c a l L yp i c k su pt h e
s o p h i s t i c a t e dp r o g r a m m a b l em a c h i n e sh a v eb e e n
r i g h t t o o l from t h e t o o l magazine and s e t s i t upon
developed t h a t a r e c a p a b l e o f p e r f o r m i n g
a wide
t h e machine t o o l - b i t h o l d e r .
v a r i e t yo fo p e r a t i o nt y p e s .E a c hs u c hm a c h i n e
Intheanalysis
o f FMS scheduling,onemust
c a r r i e s w i t h i t a t o o lm a g a z i n et h a tc a nh o l d
c a r e f u l l y examine how eachtypeofsetupinfluences
s e v e r a lt o o l s .
When a machineof
t h i st y p e i s inthesystemperformance.
To b e s tu t i l i z et h ep o t e n t e g r a t e d w i t h a tool-changer, a p a l l e t c h a n g e r o r
a
t i a lp r o d u c t i o nc a p a c i t y ,
a c a r e f u l gy.p&m-s&;l?p
r o b o t , a f l e x i b l em a n u f a c t u r i n gm o d u l e
(FMM)
must be performed before production begins (Stecke,
r e s u l t sG
. r o u p i n gs e v e r a l
FMMs t o g e t h e r ,e i t h e r

4llsI-m

--

1483

CH2282-2/86/0000/1483$01.000 1986 IEEE

1 9 8 3 ) .I nt h el i t e r a t u r e
on FMS s c h e d u l i n g ,t h i s
i s commonlyknown
a s t h e m l o a d i n e q m u and
h a sb e e nr e c e n t l ys t u d i e d
by S t e c k ea n dS o l b e r g
( 1 9 8 1 ) , S t e c k e (1983), Kusiak(19831,
and Berrada
and Stecke(1984),
among o t h e r s .
I n g e n e r a l , machine s e t u p s a r e r e q u i r e d during
ductim. In
thecaseoftool-changesetups,the
technologicalsophisticationofexistingautomatic
t o o l - c h a n g i n gd e v i c e sv i r t u a l l ye l i m i n a t e st h e
s e t u p time fortool-change.
I t i s t h i sf e a t u r eo f
FMS t h a t p r o m i s e s p r o d u c t i v i t y i n t h e f a c e o f r a p i d
c h a n g e si n
d e m a n da n dd e s i g no fm i d - v o l u m e
products.
FMS s c h e d u l i n gm e t h o d sh a v e ,q u i t ea p times.
p r o p r i a t e l y ,n e g l e c t e dt o o l - c h a n g es e t u p
However, it i s t h e " m a g a z i n es e t u p " ,t h a th a s
its influence
b e e n l e a s t understoodwithregardto
i n FMS scheduling.
To i l l u s t r a t e , we s h a l lc o n s i d e r anoperationtobe
made upof a set ofsimple
rashs which t h e FMM p e r f o r m s o n t h e j o b i n
a single
p a s s .E a c hs i m p l et a s kr e q u i r e so n ep a r t i c u l a r
tool,resultingintheoperationrequiring
a number
o ft o o l s .
W
e s h a l lr e f e rt o
a no p e r a t i o nt h a tc a n
a Type X
beperformed by a s e t ( s a y ) X o f t o o l s a s
operation.
Each FMM canperform a wide v a r i e t yo f
o p e r a t i o nt y p e s .I d e a l l y ,f o r
a FMM t o b e a b l e t o
p e r f oor p
me r a t itoynptrhe eq
, u i rt eodo l
setsforeachoperationtypemustbe
made a v a i l a b l e
t o t h e FMM a t a l l times. However, t h i s i s n o ta l ways p o s s i b l ed u et ot h el i m i t e dc a p a c i t yo ft h e
t o o lm a g a z i n e ;t h es e t
of t o o l s i n t h e
magazine a t
any p a r t i c u l a r t i m e n e c e s s a r i l y d i c t a t e s t h e
number
o fa n dt h ec h o i c eo fo p e r a t i o nt y p e st h a te a c h
FMM
canperform a t t h a t time.Withoutmagazinesetups,
each FMM is r e s t r i c t e d t o p e r f o r m o n l y t h o s e o p e r a t i o nt y p e s' l o a d e d p
' r i o rt op r o d u c t i o n .T h i si n
turn restricts the
number o f a v a i l a b l e a l t e r n a t i v e
FMMs through which each part
may b e r o u t e d .
By p e r m i t t i n gn o n - a u t o m a t e dm a g a z i n es e t u p s
d u r i n g a p r o d u c t i o nc y c l e ,t h ei n i t i a l l y' l o a d e d '
s e to ft o o l sa n do p e r a t i o nt y p e si nt h et o o l
magazineof
a FMM can then be replaced
by a new s e t
o ft o o l s
a n do p e r a t i o nt y p e s .T h i se n a b l e st h e
f u l lr e a l i z a t i o no ft h em a c h i n ev e r s a t i l i t yf o r
e a c h FMM and i n t r o d u c e s f u r t h e r f l e x i b i l i t y i n t h e
operational scheduling of
FMS.
T e c h n i c a l l y ,w h i l e
i t i s s t i l l e s s e n t i a lt o
FMM
firstperformanpff-lineleahingforeach
( d u r i n gt h e
FMS l o a d i n gp r o c e s sp r i o rt o
p r o d u c t i o n ) , it c l e a r l y is a l s oi m p o r t a n tt oa l l o w
of each FMM by magazine setups
p n - l i n e 'rg&adbg'
~ b ~ e r ~ a r u a r ;The
r . u s e o nf o n - a u t o m a t e d
w i l l inevitably
m a g a z i n es e t u pd u r i n gp r o d u c t i o n
i n c u r added c o s tt ot h er u n n i n go ft h e
FMS i n terms
o ft i m ea n dl a b o r .
I t i s t h e r e f o r ee s s e n t i a lt o
c o n s i d e r how and when t o p e r f o r m m a g a z i n e s e t u p s
f o r e a c h FMM.
Inparticular,for
a FMS c o n s i s t i n g o f s e v e r a l
is
i d e n t i c a l FMMs, animportantschedulingproblem
t os c h e d u l ej o b s
and s e t u p s f o r t h i s
FMS t o maxim i z e a m e a s u r eo fp r o d u c t i v i t y .I nt h e
problem
a d d r e s s e di nt h i sp a p e r ,
we focusonminimizingthe
m a k e s p a n( i . e .t h ec o m p l e t i o nt i m e )o f
a given
j o b l i s it n
a FMS c o n s i s t i n g of
i d e n t i c a l FMMs,
e a c hj o br e q u i r i n go n l y
two o p e r a t i o n s .
A more
is g i v e ni nt h e
f o r m a ld e f i n i t i o no ft h ep r o b l e m
n e x ts e c t i o n .
As f a r as we know, i n t h e l i t e r a t u r e o n
FMS
s c h e d u l i n g ,o n l y
Tang (1985) h a sc o n s i d e r e dt h e
i s s u eo f . m a g a z i n es e t u p sd u r i n gp r o d u c t i o n I. n

p a r t i c u l a r , T a n gc o n s i d e r st h er e l a t e dp r o b l e mo f
sequencingjobson
a s i n g l e FMM o r s e v e r a l FMMs i n
s e r i e s ,e a c hj o br e q u i r i n gm u l t i p l eo p e r a t i o n s ,t o
minimizethetotal
number o f m a g a z i n e s e t u p s o r t h e
number of t o o l s changed i n t h e magazine.

3.

-uumma@aA
pETIMAL SCHEDULE

The s c h e d u l i n g p r o b l e m i n v e s t i g a t e d i n t h i s
p a p e rc a nb ed e s c r i b e d
by thefollowingshop/job
c h a r a c t e r i s t i c s , and t h e o p t i m a l i t y c r i t e r i o n :
ShQLGhCharacterlstlcs
e The s h o p c o n s i s t s o f
two machines, P and Q.
E a c hm a c h i n ec a np e r f o r m
two o p e r a t i o n
t y p e s , Type 1 and Type 2 .
0 The f i n i t e c a p a c i t y o f
i t s t o o lm a g a z i n e
permitseachmachine
t oc a r r ye n o u g ht o o l s
Q ~ o
Ift h e s eo p e r a t i o n
t op e r f o r mo n l y
types.
0 A magazine setup, which replaces the current
i s r e q u i r e d when
s e t of t o o l s w i t h a n o t h e r ,
t h em a c h i n es w i t c h e st oa n o t h e ro p e r a t i o n
type.
0 E a c hs e t u p
from Type 1 o p e r a t i o nt o Type 2
o p e r a t i o n ,o rv i c ev e r s a ,r e q u i r e s
a &n i f i c a a ( i . e .n o n - n e g l i g i b l e )b u t
a q u
amount oftime.
0 T o o l - c h a n g e times a n dt r a n s p o r tt i m e so f
p a r t s fromonemachine
totheotherare
negligible.
Job Charac-t
o Each j o b r e q u i r e s b o t h o p e r a t i o n s .
o The o p e r a t i o n s on a j o b f o l l o w a
prher t h a t r e q u i r e s Type 1 o p e r a t i o n t o b e
completed before Type 2 commences.
0 The j o b s t o b e d o n e i n
a p r o d u c t i o nc y c l e
a r e g i v e n i n a j o b l i s t and can be begun any
timeaftertheproductioncycle
commences.
r l t w
0 To m i n i m i z e t h e m a k e s p a n f o r t h e j o b l i s t .
The p r o c e s s i n g times o f t h e Type 1 andType
2
operations.ofanyjob
J w i l l bedenoted by J and
J
respectively.
The sums of
the
processing
times
T y p e 1 andType
2 o p e r a t i o n sf o rt h eg i v e n
j o b l i s t w i l l bedenoted by T~ and T ~ r, e s p e c t i v e l y .
The magazinesetup time w i l l bedenoted by t
A t any p a r t i c u l a r t i m e , i f t h e t o o l m z g a z i n e
ofmachine M c a r r i e s t o o l s t h a t a l l o w
i t t o perform
1 o p e r a t i o nt h e n w e w i l l r e f e r t o t h e
onlyType
s t a t eo ft h i sm a c h i n ea s
M 1 ; i f it performsonly
i t s s t a t e i s M2. The svstem
Type 2 o p e r a t i o n ,t h e n
&&&;a a t any p a r t i c u l a rt i m e
i s d e f i n e d by t h e
s t a t eo ft h em a c h i n e si nt h es h o p .
F o r two
m a c h i n e s , P and Q , a l l t h ep o s s i b l es y s t e ms t a t e s
a r e( P I B Q l ) ,( P l , Q 2 ) ,( P 2 , Q 1 ) ,
and (P2,QZ).
Any f e a s i b l es c h e d u l et h a ti n c o r p o r a t e s
nona u t o m a t e ds e t u p sm u s tp o s s e s st h ef o l l o w i n g
characteristics:
( a ) A v a l i d initial system s t a t e ,
( b ) A v a l i d firaal s y s t e m s t a t e , and
( c ) Ean=nydap*
o fo p e r a t i o n sf o re a c h
job.
T h e s ec h a r a c t e r i s t i c sr e s u l tf r o mt h eo r d e r
p r e c e d e n c e o f t h eo p e r a t i o n sf o re a c hj o b .T h i s
r e q u i r e s t h a tt h ef i r s to p e r a t i o ni n
a feasible

. .

*

.

.

05'

.

" U n l e s so t h e r w i s es t a t e d ,f r o mh e r eo n
w i l l r e f e r to a non-automatedmagazine

1484

a "setup"
setup.

2 t h e n t h e r e m u s tb ef o rt h i ss c h e d u l e
a
-setupsand
& ~ - m i r ao f j o b s e t s f o r
(see Figure 2a).

scheduletobeof
Type 1 and t h e l a s t o p e r a t i o n t o
beof
Type 2 .C o n s e q u e n t l y ,a tt h eb e g i n n i n go f
theschedule,atleastoneofthemachines
must b e
i n s t a t e M 1 ; and a t t h ee n do ft h es c h e d u l e ,
at
l e a s t o n eo ft h em a c h i n e sm u s tb ei ns t a t e
M2.
are
Hence , p o s s i b 1e y a l i , & i & i a l a u g m - 3 L w
(Pl,Ql),(Pl,Q2)
a n d( Q l , P 2 ) ,w h i l ep o s s i b l e
-flnalm-ar,a&a
a r e ( P l , Q 2 ) , (P2,Ql) , and
( P 2 , Q 2 ) .T h u s ,t h e r ea r en i n ep o s s i b l ec a s e s
(3
possibleinitialstates
x 3 possible final states)
for which we h a v e f e a s i b l e s c h e d u l e s .
I f we r e s t r i c t t h a t a j o b may n o t h a v e b o t h
o p e r a t i o n sp e r f o r m e ds i m u l t a n e o u s l yo nt w o
w i l l b e no
machines, then w e w i l l e n s u r e t h a t t h e r e
o v e r l a p p i n go fo p e r a t i o n s .
However, t h i sw a r r a n t s
t h a t t h e c o m p l e t i o n time o f t h e Type 1 operation of
a jobmustnecessarilybeearlierthan
its s t a r t
time f o rt h e
Type 2 o p e r a t i o n .F i g u r e
1 ill u s t r a t e s by a G a n t t c h a r t how some j o b 5 may be
s c h e d u l e di n a f e a s i b l es c h e d u l e .

,

. .

i d l ep e r i o d

-

(a)

minimumnf
machine P

-i,
dle period

r-

F i g u r e2 .G a n t tc h a r tf o r( a )t h eo r i g i n a lt h r e e
s e t u p sa n d( b )
when j o b s e t s 152 and 251
a r ei n t e r c h a n g e d .
The proofbelow i s c a r r i e d o u t by mathematical
i n d u c t i o no n
k. We s h a l l f i r s t show t h a t i t i s
possible to rearrange the job sequence on machine
P
f o r which t h e r e a r e 3 s e t u p s t o o n e f o r
which t h e r e
is only 1 setup.
Themathematicalinductionthen
assumes t h a t Lemma 1 h o l d s f o r k=m s e t u p s (m > 3 1 ,
a n ds h o w st h a tt h i si m p l i e s
Lemma 1 a l s oh o l d sf o r
k=m+2 s e t u p s .
k r l - a g ~ n g a i R e f e r r i n gt oF i g u r e2 a ,
we
p r o c e e d t o r e a r r a n g et h ej o bs e q u e n c eb yf i r s t
s i m p l y i n t e r c h a n g i n g two j o b s e t s , 2 5 1 ( t h e
second
j o b s e to fT y p e
1 o p e r a t i o n ) , and152
(thefirst
j o b s e to fT y p e
2 operation).
The s c h e d u l eo f
F i g u r e2 br e s u l t s ,w h i c hs h o w st h a tt w oo ft h e
o r i g i n a ls e t u p s now becomeredundant.Theseare
r e p l a c e d by two i d l e t i m e s l o t s (now r e p r e s e n t e d by
t h er e s p e c t i v es i n g l ec r o s s - h a t c h e dr e g i o n s ) .
The
f i n a ls c h e d u l eh a so n l y
1 s e t u po nm a c h i n eP ,a n d
two
j o b s e t s , S1o p( o
e rf a t i o n
Type 11,
and S2 ( o f o p e r a t i o n Type 2 ) .
We a l s o n o t e t h a t t h i s
new s c h e d u l e was obt a i n e dw i t h o u ta f f e c t i n gt h ej o bs e q u e n c eo n
m a c h i n e Q.
S i n c et h ec o m p l e t i o n
time ofmachine P
is not
remainsthe same, t h es h o pc o m p l e t i o nt i m e
increased.
To c h e c k t h e f e a s i b i l i t y o f t h e
new s c h e d u l e ,
we n e e do n l yt oc h e c kt h a tn os i n g l ej o b
is
operatedsimultaneously by b o t hm a c h i n e s ;t h a t
is,
i t s two o p e r a t i o n sd on o to v e r l a p .
To b e g i n , we
shall classify each job on
machine P as Type a j o b
ifthejobhasonly
Type 1 operationperformedon
m a c h i n eP ,a sT y p e
6 j o b i f i t h a so n l yT y p e
2
o p e r a t i o n p e r f o r m e d onmachineP,
o r as Type 11, j o b
i f i t has both operations performed on machine
P.
Considerjobsof
Type a. The only Type a j o b s
t h a t havebeenrearrangedinthe
new s e q u e n c e a r e
t h o s ei nj o b s e t2 5 1 .
From F i g u r e 2b i t i s c l e a r
1 o p e r a t i o n i s now
t h a tf o rt h e s ej o b st h eT y p e
c o m p l e t e de a r l i e r .S i n c et h e
times o ft h e i r Type 2
operations,which are performedonmachine
Q, have
n o t c h a n g e d , we h a v en oo p e r a t i o no v e r l a p
and no
increaseincompletion
time of Type a j o b s .
I t f o l l o w sf r o m
C o n s i d e rj o b so f
Type 6 .
s i m i l a ra r g u m e n t sa sa b o v ef o r
Type a j o b s t h a t n o
o p e r a t i o no v e r l a pa n dn oi n c r e a s eo fc o m p l e t i o n
t i m eo c c u r sf o rt h e s ej o b s .
L a s t l y ,c o n s i d e rj o b so fT y p e
9 . S i n c et h e
o r i g i n a l s c h e d u l e was f e a s i b l e , i t i s n o t p o s s i b l e
t h a t t h e r e i s any j o b o f Type JI f o r whichoperation
Type 1 i s i n j o b s e t 2 5 1
a n do p e r a t i o nT y p e
2 in
j o b s e t1 5 2 .F o r
a Type 11, j o bi nj o b s e t s
1J1 and
2 5 2 ,t h e r e
i s no c h a n g ei nj o bs e q u e n c ea n dh e n c e
n oo p e r a t i o no v e r l a po c c u r s .F o r
a Type J, j o b i n
j o b s e t s 1J1 and 152,only
i t s Type 2 o p e r a t i o n i s
a f f e c t e d .A l t h o u g ht h e
new completiontimefor
its

Machina P

F i g u r e 1. P o s s i b l es c h e d u l ef o rj o b
5, ( a )w h e n
bothoperationsare
onmachineP,and(b)
when Type 1 o p e r a t i o n i s onmachine P and
Type 2 onmachine Q.
LENMA 1 1 I n a f e a s i b l es c h e d u l et h a tr e q u i r e s
machine P t o have k , k 2 2 , s e t u p s , a new j ob
s e q u e n c ef o rm a c h i n e
P may b eo b t a i n e ds u c h
that
( a )T h e new s c h e d u l e f o r t h e j o b l i s t
is s t i l l
s

s( ebt)u p
i s required
machine
on P,
Q is
( c )T h ej o bs e q u e n c eo nm a c h i n e
and remainsthe same, and
( d ) The new completion time f o r t h e j o b l i s t is
xwt increased..
EEeQf: To prove Lemma 1, w e s h a l lu s em a t h e m a t i c a li n d u c t i o nt of i r s tc o n s i d e ro n eo ft h e s e
c a s e s s, a yC a s e
1.
We s h a l lt h e n
show t h a tt h e
o t h e re i g h tc a s e sc a nb ee a s i l y" t r a n s f o r m e d "t o
Case 1, so t h a t t h e p r o o f f o r C a s e
1 w i l l still
holdfortheothercases.
I n i t i a ls t a t eo f
machine P i s P1and
f i n a l s t a t e i s P2 ( n o t e t h a t i n s u c h
a feasible
s c h e d u l e , machine Q c a n h a v e a n y o f t h e p o s s i b l e
i n i t i a l and f i n a l machine s t a t e s . )
W
e s h a l lr e p r e s e n tt h es c h e d u l eo n
a machine
by t h e G a n t t c h a r t
shown i n F i g u r e 2 .
Each j.dUE.L,
c o n s i s t i n go fj o b st h a th a v et h e
p e r f o r m e d c o n s e c u t i v e l y on t h e -ne,
i s r e p r e s e n t e d by a b a r whose l e n g t h c o r r e s p o n d s t o
t h et o t a lp r o c e s s i n g
time o ft h ej o b s e t .F i g u r e
2
shows t h ej o b s e t st h a tm a c h i n e
P p r o c e s s e s .E a c h
d o u b l ec r o s s - h a t c h e dr e g i o nr e p r e s e n t st h e
time
duringwhich a s e t u p i s performedbetweentwojobs e t s o fd i f f e r e n to p e r a t i o nt y p e s .
I t shouldbe
k e p ti n mind t h a t i d l e t i m e s
may e x i s t wi.Lhin-a

Case.

aame=Liinn

iobsetI n.o r d e r f o r

machine P t o h a v e i n i t i a l s t a t e
P1andfinalstateP2,
k must b e pdd and s i n c e k 1

1485

Type 2 o p e r a t i o n i s now l a t e r , n oo v e r l a po c c u r s
s i n c e m a c h i n e P p e r f o r m st h eo p e r a t i o n si nt h er e q u i r e do r d e r S
. i m i l a r l y f, o rT y p e
d, j o b si n
1 o p e r a t i o n i s now
j o b s e t s2 5 1a n d2 5 2 ,t h eT y p e
f i n i s h e de a r l i e rb u t
no o v e r l a po c c u r s .T h e r e f o r e
t h ei n t e r c h a n g eo fj o b s e t s
152 and 251 r e s u l t s i n a
f e a s i b l es c h e d u l ew i t h o u ti n c r e a s i n gt h ec o m p l e t i o n
timeof Type C j o b s .
S i n c e any jobonmachine
P can be classified
i n t oo n eo ft h et h r e ej o bt y p e sa b o v e ,
we canconc l u d et h a tf o rk = 3j o b s e t s1 5 2a n d2 5 1c a nb e
i n t e r c h a n g e dt oo b t a i n
a f e a s i b l es c h e d u l et h a tr e q u i r e so n l yo n es e t u p( i . e .
making k = l )w i t h o u t any
i n c r e a s ei nt h e
makespan.
Thisproves
Lemma 1 f o r
k=3setups.
k~~~a_sg&ps_
(m > 3): W
e now assume t h a t Lemma
1 h o l d sf o r m s e t u p s ,w h e r e
m i s odd,and
m > 3.
This means t h a t a new schedule can be obtained such
t h a t t h e n u m b e ro fs e t u p so nm a c h i n e
P c a nb e
r e d u c e df r o m
m t o 1, w i t h o u t a n yi n c r e a s ei nt h e
makespan.
krm+a-seLnas: F i g u r e3 ar e p r e s e n t st h e
From t h e
schedule when machine P has m+2 s e t u p s .
a s s u m p t i o n t h a t Lemma 1 h o l d s f o r m s e t u p s , we can
r e s c h e d u l et h ej o b s e t sb e f o r et h e( m + l ) t hs e t u pt o
obtainthescheduleofFigure
3b which c o n s i s t s o f
only 3 s e t u p s .S i n c e
we h a v ep r o v e nt h a t
we can
r e d u c e a s c h e d u l e w i t h 3 s e t u p s t o a new schedule
1 s e t u p ,t h eF i g u r e3 bs c h e d u l ec a nb e
withonly
c h a n g e dt ot h a to fF i g u r e3 cw i t h o u ti n c r e a s i n g
c o m p l e t i o nt i m e so ft h eg i v e nj o b s H
. ence
a
s c h e d u l e r e q u i r i n g m+2 setupscanbere-sequenced
so t h a to n l y 1 s e t u p w i l l berequired.Thus
Lemma
1 h o l d s f o r k=m+2.
S i n c e we haveproven
Lemma 1 h o l d s f o r k = 3 ,
and t h a t i f i t h o l d sf o r k=m t h e n i t must a l s o hold
f o r k=m+2, by mathematicalinduction
Lemma 1 h o l d s
forallfeasiblevaluesof
k.
m setups
2 setups

F i g u r e4 .T r a n s f o r m i n g
a s c h e d u l e( a )w i t ht w o
S e t u p s ,( b )t oo n ew i t ht h r e es e t u p s
and
a dummy j o b s e t , ( c ) t o o n e w i t h o n e s e t u p
and a dummy j o b s e t a n d( d )t oo n ew i t h
onlyonesetup.
In a s i m i l a rf a s h i o n , any o f t h e o t h e r e i g h t
casescanbetransformed
and shown t o b e e q u i v a l e n t
t o Case 1. C o n s e q u e n t l y , Lemma 1 h o l d sf o ra n y
f e a s i b l es c h e d u l e .
As a c o r o l l a r y we havethefollowing
lemma.
LEMMA 2:In
a f e a s i b l es c h e d u l et h a tr e q u i r e s
machine Q t o havek, k 2 2 s e t u p s , a new j o b
Q may beobtainedsuch
s e q u e n c ef o rm a c h i n e
that
( a ) The new s c h e d u l e f o r t h e j o b l i s t
is s t i l l
feasible;
( b ) Only QIL~.s e t u p i s requiredonmachine
Q;
( c )T h ej o bs e q u e n c eo nm a c h i n e
P is
y n a f f e c t e d and remainsthe
same; and
( d ) The new c o m p l e t i o n t i m e f o r t h e j o b l i s t
is
wt i n c r e a s e d .
F i n a l l y a s a consequenceof Lemmas 1 and 2 we
havethefollowingtheorem.
THEOREM L: For a f e a s i b l es c h e d u l er e q u i r i n g
x , x > 0 s e t u p sf o r machine P and y ,
y > 0,
s e t u p sf o rm a c h i n e
Q , a new s c h e d u l e c a n b e
o b t a i n e ds u c ht h a t
( a ) The new s c h e d u l e f o r t h e j o b l i s t
is s t i l l
feasible,
( b ) &-M&&-QR~
s e t u p i s r e q u i r e do n
each
mac h i n e , and
( c ) The new c o m p l e t i o n t i m e f o r t h e j o b l i s t
is
not L n c r d .
EEnef: From Lemmas 1 and 2 , i t f o l l o w st h a t
t h er e a r r a n g e m e n to fj o b si ne a c hm a c h i n e
is indep e n d e n to ft h ej o bs e q u e n c ei nt h eo t h e rm a c h i n e ,
p r o v i d e dt h eo r i g i n a ls c h e d u l e
was f e a s i b l e .
C o n s e q u e n t l y ,t h ef i n a ls c h e d u l e
w i l l b eo n ew i t h
z e x ~s e t u p ( F i g u r e S a ) ,
ppe s e t u p ( F i g u r e 5 b ) , o r
a s e t u p s ( F i g u r e 5 c ) . II

-

A

(a)

I

(C)

F i g u r e3 .G a n t tc h a r tf o r( a )t h eo r i g i n a l
m+2
s e t u p s ,( b )t h er e s e q u e n c i n gt o
2 setups,
and ( c )f i n a ls e q u e n c ew i t h
1 setup.

4.

S.HEURISTICS

We k n o wf r o mT h e o r e m
1 t h a ta no p t i m a l
s c h e d u l e on two f l e x i b l e m a c h i n e s musthave
s .o w e v e r ,
it is
s e t u p , ~e s e t usoper,t u pH
n o te a s yt of i n do u te x a c t l y
how
many
s e t u p st h e
optimal schedule w i l l have; and even i f we knowhow
many, it i s g e n e r a l l y n o t e a s y t o o b t a i n
an o p t i m a l
schedule
e x c e p tf o rt h ez e r os e t - u pc a s ew h e r e
J o h n s o n ' s( 1 9 5 4 )a l g o r i t h mg i v e st h eo p t i m a l
schedule. It is r q l a t i v e l ys t r a i g h t f o r w a r dt o
show
t h a t ,i ng ' e n e r a l ,t h i ss c h e d u l i n g
problem is NPhardT
. h i ss e c t i o nd e v e l o p sh e u r i s t i c sf o rt h e .
o t h e r two cases:
one-setup
and two-setup.
Section
5 g i v e sa ne m p i r i c a lc o m p a r i s o no ft h es c h e d u l e s
o b t a i n e db yJ o h n s o n ' sa l g o r i t h ma n dt h e s e
heuristics

The-QXherz-EigLfhxes:

So f a r we h a v e shown
t h a t Lemma 1 i s t r u ef o r Case 1. By using "dummy"
j o b s a n ds e t u p s ,t h eo t h e rc a s e sc a ne a s i l yb e
t r a n s f o r m e da n ds h o w nt ob ee q u i v a l e n tt oC a s e
1.
To i l l u s t r a t e ,c o n s i d e rt h ec a s e
when t h e i n i t i a l
and f i n a l s t a t e s ofmachine P a r e b o t h P1, as shown
i nF i g u r e4 a .
By i m a g i n i n g a hnnmy j o b s e t o f
o p e r a t i o n Type 2 and a
s e t u p appended t toh i s
schedule, we t r a n s f o r mt h es c h e d u l et ot h a to fC a s e
1 ( F i g u r e4 b ) .
As b e f o r e ,t h ej o b sc a nt h e nb e
rescheduledtothescheduleofFigure4cwhichinc l u d e so n l yo n es e t u p( t h e
dummy s e t u p becomes i d l e
time now). By e l i m i n a t i n gt h e dummy j o b s e t ,F i g u r e
4d r e s u l t s which s a t i f i e s Lemma 1.

--

.

1486

P

I

TM.

I

1

P
9
( C )

.

F i g u r e 5. P o s s i b l eo p t i m a ls c h e d u l e s( a )w i t hz e r o
s e t u p ,( b )w i t ho n es e t u p ,a n d( c )w i t h
two s e t u p s .

4.1 T h e Z e r e S e t u g - Gasc

Fs,

The c a s eo fz e r os e t u ps c h e d u l ec o r r e s p o n d st o
t h et w o - m a c h i n e
f l o w s h o pp r o b l e mJ. o h n s o n ' s
Algorithmgivestheoptimalsequence.
4.2 The One-Sa tup
F i g u r e 6 shows two d i f f e r e n t s i t u a t i o n s when
a no p t i m a ls c h e d u l eh a so n es e t u p .G i v e ns u c h
a
s c h e d u l e we c a n o b s e r v e t h a t t h e r e a r e
two c l a s s e s
of j o b si nt h i ss c h e d u l e .
The f i r s t c l a s s c o n s i s t s
of '2-machine'
j o b s t h a t mustbeprocessedbyboth
m a c h i n e s -- o n eo p e r a t i o no ne a c hm a c h i n e .
The
j o b s t h a t have
second c l a s s c o n s i s t s of 2=~&
b o t ho ft h e i ro p e r a t i o n sp r o c e s s e do n
a single
m a c h i n eT. h i m
s a c h i n ei,n c i d e n t a l l y ,
is the
' i s performed; we s h a l l
m a c h i n eo nw h i c ht h es e t u p
refertothis
machineasthesetup

u
r
n
.

'1-machlne' 105s

I

P

-

Q

Type 1

i:

4 - 3 The TWOThe h e u r i s t i cd e v e l o p e df o rt h et w o - s e t u p
s c h e d u l ec o n s i s t so f
two s t e p s .F i r s t ,
it treats
a l lj o b sa s1 - m a c h i n ej o b s
so. t h a t when a j o b i s
i t s operations w i l l
scheduled on a machine,bothof
beperformedonthatmachine.
The f i r s t s t e p i s t o
s o t h a tt h et o t a lr e s u l t a n t
partitionthejobs
p r o c e s s i n gt i m eo ne a c hm a c h i n e
i s a se q u a la s
possible.
T h es e c o n ds t e pt h e nt r i e st ob a l a n c e
t h e workload by r e f i n i n g t h e o b t a i n e d s c h e d u l e a n d
i s p e r f o r m e do n l yi f
i t i s p o s s i b l et of u r t h e r
decreasethedifferencebetweenthetotalprocessi n gt i m e so nt h et w om a c h i n e s .T h i si sa c h i e v e d
t h r o u g hi d e n t i f y i n gw h i c hj o b sc a na n ds h o u l db e
c h a n g e df r o mb e i n g1 - m a c h i n ej o b st ob e c o m i n g
2m a c h i n ej o b sb yh a v i n gt h e i rt w or e s p e c t i v e

Type 2

IQ

IP

Type 1

P.
QI'

t a n e o u s l ym i n i m i z e st h e s ei d l et i m ep e r i o d sa n d
u s e so n eo ft h e s ep e r i o d st oc o m p l e t et h es e to f
1machine j o b s .T h e r e f o r e ,t oo b t a i nt h eo p t i m a l
o n e - s e t u ps c h e d u l e ,
i t is n e c e s s a r yt ob o t hi d e n t i f y t h es e t u pm a c h i n ea n dt h es e t so f1 - m a c h i n e
and2-machinejobs.
We may d o t h i s by anenumerat i o nm e t h o d ,b u tt h ec o m p u t a t i o n a le f f o r tg r o w s
e x p o n e n t i a l l yw i t ht h e
number o fj o b s .
The h e u r i s t i cg i v e nb e l o wa p p e a r st og i v e" r e a s o n a b l e "
schedules.
The h e u r i s t i c b r e a k s t h e o n e - s e t u p s c h e d u l i n g
it i d e n t i f i e st h e
p r o c e s si n t ot h r e es t e p s :f i r s t ,
i t i d e n t i f i e st h e1 - m a c h i n e
setupmachine;second,
two c l a s s e so f
j o b s ; and t h i r d , i t s c h e d u l e st h e
jobs.
EEl!MST_IU ( One-Setup Scheduling)
machine)
STEP 1: (To i d e n t i f yt h es e t u p
S e q u e n c ea l lt h ej o b su s i n gJ o h n s o n ' s
Algorithm. L e t I Pb et h et o t a li d l e
time
f o r machineP,
and IQ t h e t o t a l i d l e
time
f o r machine Q. The setupmachine,say
M,
c o r r e s p o n d st ot h e. m a c h i n ew i t ht h e
l a r g e rt o t a li d l et i m e ;t h a t
is
I M = max( IP ,IQ)
STEP 2 : ( T oi d e n t i f yt h es e t
of 1-machine
jobs)
time I M i s l e s s t h a nt h es e t u p
I fi d l e
time,
t h e n STOP.
Otherwise, l e t T d e n o t et h e" d e s i r e d "t o t a lp r o c e s s i n gt i m eo f1 - m a c h i n ej o b s
with
T
( IM-ts)/2.
I nt h eJ o h n s o n G ss c h e d u l eo b t a i n e di n
STEP 1, s e l e c tf r o mt h eo p e r a t i o n s
on
t h en o n - s e t u pm a c h i n et h es e to fj o b s
w h o s ec o m b i n e dp r o c e s s i n gt i m e sa tt h i s
machine i s' c l o s e s t 't o
T. We l e t t h e s e
s e t of1-machine
j o b s ;t h e
j o b sf o r mt h e
rest are the
2-machine j o b s .
STEP 3 : (To obtaintheone-setupschedule)
UsingJohnson'sAlgorithmschedulethe
2m a c h i n ej o b s M
. o d i f yt h i ss c h e d u l e
by
sequencingthe 1-machine j o b s i n t h e i d l e
timeperiodofthesetup
machine so t h a t
Type 1 o p e r a t i o n so ft h e s ej o b sa r ep e r formed f i r s t , followed by a s e t u p and t h e
Type 2 o p e r a t i o n s .

IQ

I

I

Tvpe 2

I

'1-machine' jobs

Figure 5 . Scheduleswith

one s e t u p .

The o n e - s e t u ps c h e d u l i n gp r o c e s sc a nt h e nb e
viewed a st h es i m u l t a n e o u ss c h e d u l i n go ft h e s et w o
c l a s s e so fj o b s
s o as t os a t i s f yt h eo p t i m a l i t y
c r i t e r i o n . The optimalschedulingofthe2-machine
jobs,sequencedthroughmachines
P and Q s a t i s f y i n g
p r e c e d e n c ec o n s t r a i n t s , w i l l . i n e v i t a b l y i n t r o d u c e
a ni d l et i m ep e r i o df o re a c h
machine.
To minimize
t h e makespan, t h es e t u pm a c h i n em u s t
make u s e o f
i t s i d l e t i m e p e r i o dt op r o c e s st h es e to f
1machine j o b s
whichincludesperforming
a setup.
T h eo p t i m a lo n e - s e t u ps c h e d u l e ,t h u s ,s i m u l -

*We c a nu s e a k n a p s a c k h e u r i s t i c f o r t h i s , w h e r e
T
i s t h e" c a p a c i t y "o ft h ek n a p s a c kt ob e
packed
( s e e , e.g., Hu, 1982).

--

1487

B r i e f l y ,t h eo n e - s e t u ps c h e d u l ew a so b t a i n e d
( u s i n gH e u r i s t i c
1) asfollows:
time f o r P a s 1
STEP 1: F i g u r e7 ag i v e si d l e
time u n i t and f o r Q a s 8 t i m e u n i t s .
Hence,machine
Q i s s e l e c t e da st h e
setup-machine M, w i t h IM=8.
STEP 2:Since
I M > ts = 2 , T=( I M - t ) / 2 = 3.
we
From t h e o p e r a t i o n s a s s i g n e t o n P ,
f i n dt h a t A , Type 1 o p e r a t i o nf o r
j o b A, i s " c l o s e s t " t o T.
STEP 3 : UsingJohnson's
A l g o r i t h mo nt h e
2{B,C,D,E)
we g e tt h e
m a c h i n ej o b s
s c h e d u l eo fF i g u r e
8, w i t h i d l e t i m e
o f 8 t i m eu n i t so nm a c h i n e
Q.
P a c k i n gt h eo p e r a t i o n so n
Q t ot h e
rightgivesus
9 time u n i t s t o p e r form o p e r a t i o n so nt h e" 1 - m a c h i n e "
P e r f o r m i n g A1, a s e t u p , and
j o b A.

o p e r a t i o n s " s p l i t up" and b e performedon
separate
machines
EEUUSTIC 2 (Two-Setup Scheduling)
two j o bs e t s )
STEP 1: (To p a r t i t i o n j o b s i n t o
a binpacking
T h i ss t e pc o r r e s p o n d st o
p r o b l e m ,w h i c h
i s known t o b e NP-hard
( G a r e ya n dJ o h n s o n1, 9 7 9 ) .
However, a
good h e u r i s t i c may b e u s e d h e r e , f o r e x a m p l e ,t h ef i r s t - f i td e c r e a s i n g
binpackingalgorithm(e.g.,
Hu, 1982).
STEP 2:(Tobalanceworkload)
Check t h e d i f f e r e n c e b e t w e e n t h e c o m p l e t i o n times o f t h e
twomachinesobtained
i n STEP 1. I ft h i sd i f f e r e n c e ,s a y
T',
i s l e s st h a nt w i c et h e
smallest processi n g t i m e i nt h e
s h o p , t h e n STOP.
O t h e r w i s e , s e l e c t from the machine with
t h el a r g e rt o t a lp r o c e s s i n g
time, t h o s e
operationswhich come " c l o s e s t " t o t o t a l i n g T'/2 ( w ec a na g a i nu s e
a knapsack
h e u r i s t i c h e r e ) and scheduletheseoperat i o n so nt h eo t h e rm a c h i n ew i t h o u t
v i o l a t i n gt h ep r e c e d e n c eo r d e r N
. ote
t h a t when t h e o p e r a t i o n s a r e s c h e d u l e d o n
t h e o t h e r machine t h ec o r r e s p o n d i n gj o b s
are " s p l i t " i n t h e s e n s e t h a t e a c h o p e r a t i o n i s performedon a d i f f e r e n t machine.

.

t h e n A i nt h i si d l ep e r i o dg i v e st h e
schedule of Figure 7b.

2

0
0

2
2

5

13

18

25

Macnine P
Machine Q
12 13

18

2 5 26

20

15

Machine P

0

3

15

5

8

11

20

18

13

22

13

15

17

22 23

WJBICAL TESTS

J o h n s o n ' sA l g o r i t h m
and t h e above h e u r i s t i c s
were computercodedandappliedon
random j o b l i s t s .
Ten d i f f e r e n t j o b l i s t s were used. The v a l u e sf o r
t h en u m b e r so fj o b so ne a c h
j ob l i s t , a n dt h e
p r o c e s s i n g times f o r t h e t w ot y p e so fo p e r a t i o n s
f o re a c hj o b
wererandomly
generated.
Numbers o f
j o b sr a n g e df r o m
5 t o 10 and t h ep r o c e s s i n g times
from 1 t o 10 time u n i t s .
times were used: 1-8, 10,
Ten d i f f e r e n ts e t u p
12.Foreachsetup
time, a s c h e d u l e was g e n e r a t e d
foreachofthecases:zero-,
one- and two-setups.
The s c h e d u l e w i t h t h e
minimum makespan was t h e n
d e s i g n a t e d as the"best"schedule.
When t h e r e was
a t i e f o r minimum m a k e s p a n ,t h ec o r r e s p o n d i n g

2 2 23
22

B

5.

22

Machine Q
0

2

15

2 setups.
F i g u r e 9. I n i t i a l s c h e d u l e w i t h
STEP 2:The
d i f f e r e n c eb e t w e e nt h et o t a l
p r o c e s s i n gt i m e so ft h e
two m a c h i n e s
(T') i s g r e a t e rt h a nt w i c et h e
small e s t p r o c e s s i n g time ( i . e . 3 > 2 c 2 =
2 ) . The Type 2 o p e r a t i o n of j o b B is
s e l e c t e dt ob e
now p e r f o r m e do n
machine P and thescheduleofFigure
7c r e s u l t s .
We r e m a r kt h a te n u m e r a t i o nr e v e a l e dt h a te a c h
of t sh ce h e d u lFienisg u r e
7 is
f tohr e
numberofsetups.
However, theone-setupschedule
g i v e st h es h o r t e s tc o m p l e t i o nt i m e
and hence i s optimal f o r t h e j o b l i s t c o n s i d e r e d .

times f o rt h ei l l u s t r a t i v e

is 2 time u n i t s . Assuming zeroSuppose setuptime
s e t u pa n du s i n gJ o h n s o n ' sA l g o r i t h mg i v e st h e
scheduleofFigure7awiththecompletion
time for
7b and 7c
t h e 5 j o b s b e i n g 26 time u n i t s .F i g u r e s
g i v et h es c h e d u l e sf r o mt h eo n e -a n dt w o - s e t u p
heuristics developed above.
0

0

10

F i g u r e 8 . J o h n s o n ' ss c h e d u l e
f o r t h e '2-machipe'
jobs.
B r i e f l y ,t h e
two-setup s c h e d u l e was o b t a i n e d
( u s i n gH e u r i s t i c2 )
as follows:
STEP 1: The f i r s t - f i td e c r e a s i n gb i n p a c k i n g
a l g o r i t h mp r o d u c e st h es c h e d u l eo f
F i g u r e 9.

S u p p o s et h es h o ph a st oc o m p l e t e
5 jobs, A to
E , h a v i n gt h ep r o c e s s i n g
times a s shown i n T a b l e 1
below.

Jobprocessing
example

2

Xachlne Q

4.4

Table 1:

0

Xachrne P

24

UchLne P
Nachine Q

F i g u r e 7. ( a ) A z e r o - s e t u ps c h e d u l e ,( b )
a ones e t u ps c h e d u l e , 'a n d( c )
a two-setup
s c h e d u l e ,w i t hp r o c e s s i n g
times 2 6 , 23,
and 2 4 , r e s p e c t i v e l y

.

I488

c a nb ec r u c i a la sf a ra sm i n i m i z i n g
job completion
times and increasingproductivi.ty
i s concerned.
When e a c hj o br e q u i r e so n l yt w oo p e r a t i o n
t y p e s , we have shown t h a t a maximum o f t w o s e t u p s
arerequiredtominimizethe
makespanof
a joblist
on a two-machine FMS.
When
n os e t u p
is required,
J o h n s o n ' sA l g o r i t h mg i v e st h eo p t i m a ls c h e d u l e .
T h i sp a p e rp r e s e n t e dh e u r i s t i c st os c h e d u l et h e
j o b l i s tw i t h one- and two-setupschedules.
Our emp i r i c a l t e s t s show t h a ts c h e d u l e sw i t hs e t u p s
a s t h es e t u p
time
b e c o m em o r ec o m p e t i t i v e
decreases.

schedulewiththeleast
number of setups was d e s i g nated"best".
T a b l e 2 summarizestheresultsofourempiric a l tests. These r e s u l t sr e v e a lt h a tt h eu s eo f
s e t u p s may o r may n o t b e d e s i r a b l e d e p e n d i n g o n t h e
magnitudeofthesetup
time. When t h es e t u pt i m e
i s s m a l l ,t h es c h e d u l e sw i t hs e t u p st e n dt oh a v e
s h o r t e rc o m p l e t i o n
t i m e s t h a nt h ez e r o - s e t u p
s c h e d u l e s . A s t h es e t u pt i m ei n c r e a s e st h er e v e r s e
o c c u r s ;t h ez e r o - s e t u ps c h e d u l e st e n dt ob eb e s t .
T h i sr e s u l ta g r e e sw i t ho n e ' si n t u i t i o n :a st h e
s e t u pt i m ei n c r e a s e s ,s e t u p sa r el e s sa n d
less
desirable.

REFERENCES
S t e c k e( 1 9 8 4 ) , "A B r a n c h a n d - B o u n dA p p r o a c ht oM a c h i n eL o a d i n gi n
FMS", Working Paper#329-b,GraduateSchool
o fB u s i n e s sA d m i n i s t r a t i o n ,U n i v e r s i t yo f
Michigan, Ann Arbor, M I .
J . A . B u z a c o t t( 1 9 8 2 ) , " T h eF u n d a m e n t a l
P r i n c i p l e so fF l e x i b i l i t yi nM a n u f a c t u r i n g
S y s t e m s " , EKQrggBiaga_Qf-€he_Eirs+
ZnSemationaGS;nn&renr;e-Qn-EHS, B r i g h t o nI
United Kingdom, pp. 13-22.
C . D u p o n t - G a t e l m a n d( 1 9 8 2 1 ,
"A S u r v e yo f
F l e x i b l eM a n u f a c t u r i n gS y s t e m s " ,
M a l l u f a c & ; ~ ~ . & ~1 ~s , PP. 1-16.
M.R. Gareyand D.S. Johnson (19791, C O U I Q U ~ ~ E
and I o t r a f l a b - G u i d e _ T P - T h e - I % . e a r ~ - e f
N P - C o p l p l g w , San Francisco, W .H. Freeman
& Company, P u b l i s h e r s .
T.C. Hu ( 1 9 8 2 ) , G ~ a ~ k i n a t P E F a l A l g ~ L ,
Addison-Wesley, NY.
S.M. Johnson(1954)
"Optimal Two- and ThreeStageProductionScheduleswithSetupTimes
Included", -rch
L-s
Q u a r trlr
1, pp. 61-68.
A. Kusiak (19841, "Loading Models i n F l e x i b l e
L
Manufacturing Sys terns" , ~
M. Berrada and K.

*F o r e a c h s e t u p t i m e

, 10 j o b l i s t s werescheduled
numbers a r e from 10 tests.

a n d ,t h u s ,t h e s e
Table 2 .

tests

Summary o ft h ee m p i r i c a l

Our p r e l i m i n a r yf i n d i n g sa l s os u g g e s t e da ni n t e r e s t i n g c o r r e l a t i o n b e t w e e n "the d i f f e r e n c e of
t h e two t o t a lp r o c e s s i n gt i m e so ft h e
two o p e r a t i o nt y t e s "
and thecorresponding number o fs e t u p s
i nt h eb e s ts' c h e d u l eT. a b l e
3 i l l u s t r a t e st h i s
r e l a t i o n s h i p . A s t h ed i f f e r e n c ei n c r e a s e s ,
so does
t h e i d l e time p e r i o dt h a t is o b t a i n e d i n t h e z e r o time p e r i o d sa r e
s e t u ps c h e d u l e .S i n c et h ei d l e
e s s e n t i a l l y t h e means to reduce completion time via
setups,scheduleswithsetupsappeartogivebetter
results.
In Table 3 we o b s e r v e a g r a d u a l d e c r e a s e
times thezero-setupschedule
is
i n t h e numberof
t h e" b e s t " ,a st h et o t a lp r o c e s s i n g
times d i f f e r e n c e , and hencetheidle-time,increases.

,

. .

i n H L a x i k l ~ a c m ~ ~ e m ~ A l l i e d
U,
N o r t h - H o l l a n d ,T h eN e t h e r l a n d s( t o

appear).
K.E. Stecke(19831,"Formulation
and S o l u t i o n
o fN o n l i n e a rI n t e g e rP r o d u c t i o nP l a n n i n g
Problems forFlexibleManufacturingSystems",
- L & i e ~ ~ s
2 s PP. 273-288.
K.E. Stecke and J.T.Solberg(1981)
, "Loading
a n dC o n t r o lP o l i c i e sf o r
a Flexible
ManufacturingSystem",
~LJQLIXM~
~ € J k & ~ ! A ~ ~ % a e a r c hs_pp
9 481-490 *
K.E.
S t e c k ea n d
J . T . S o l b e r g( 1 9 8 2 ) , "The
O p t i m a l i t yo fU n b a l a n c e dW o r k l o a d sa n d
M a c h i n eG r o u pS i z e sf o rF l e x i b l e
M a n u f a c t u r i n gS y s t e m s " ,W o r k i n gP a p e r2 9 0 ,
GraduateSchool of B u s i n e s s A d m i n i s t r a t i o n ,
The University of Michigan,
Ann Arbor, M I .
C.S. Tang (1985) , "A JobScheduling Model f o r
a F l e x i b l eM a n u f a c t u r i n gM a c h i n e " ,
Working
Paper 2/85, Y a l e U n i v e r s i t y , New Haven, CT.

3
4
6

a
8
10

2

0
7
2

*Maximum

i d l e time I M obtainedfromJohnson'salgor i thm.
x*
F o re a c hj o b l i s t
we c o n s i d e r e d 10 S e t u p times
and,thus,these
numbers a r e from 10 tests.
Table 3.

Relationshipbetween maximum i d l et i m e ,
d i f f e r e n c eo ft h e
two t o t a l p r o c e s s i n g
times, a n dt h e number o fs e t u p si nt h e
"best"schedule.
6*

S

~

~

L

!

I

R

J

~

~

F l e x i b l e NC machines and r o b o t s a r e b e i n g u s e d
i n c r e a s i n g l yf o rm u l t i - t a s k i n gi n
FMS. Sincethese
i n v o l v eh i g hc a p i t a li n v e s t m e n t s ,e f f o r t s
must be
made t o f u l l y u t i l i z e t h e e q u i p m e n t s ' c a p a b i l i t i e s .
As shown i n t h i s p a p e r , u s e o f
non-automated s e t u p s

1489

Public Transp (2010) 2: 159–172
DOI 10.1007/s12469-010-0028-3
O R I G I N A L PA P E R

A macroscopic model for integrating bus signal priority
with vehicle rescheduling
Pitu B. Mirchandani · Jing-Quan Li ·
Mark Hickman

Published online: 24 September 2010
© Springer-Verlag 2010

Abstract When a bus breaks down on a scheduled trip, one or more vehicles need to
be rescheduled to serve that trip and other scheduled trips. A bus breakdown certainly
delays the trip being served by the disabled bus and possibly delays or cancels other
trips. The vehicle rescheduling problem (VRSP) is to reassign and reschedule the
bus fleet to minimize the sum of operating costs, delay costs, schedule disruption
costs, and trip cancellation costs. Bus operations may also be improved by bus signal
priority (BSP), which can reduce bus delays at signalized intersections. If BSP is
provided to the backup bus that travels to service the disabled bus’ passengers, it
may reach the breakdown point more quickly. However, other buses that also pass
through the corresponding intersections may be affected by signal priority. Therefore,
a tradeoff must be made so that the backup bus can travel faster while other buses are
not significantly delayed. A macroscopic model that integrates bus signal priority
with bus rescheduling is proposed in this paper. Computational results show that the
combination of BSP and VRSP effectively reduces the delay of the backup bus and
decreases the delay costs.
Keywords Bus signal priority · Preemption · Vehicle scheduling · Rescheduling
P.B. Mirchandani ()
School of Computing, Informatics, and Decision Systems Engineering, Arizona State University,
Tempe, AZ 85287, USA
e-mail: pitu@asu.edu
J.-Q. Li
California PATH, University of California, Berkeley, Richmond, CA 94804, USA
e-mail: jingquan@path.berkeley.edu
M. Hickman
Department of Civil Engineering and Engineering Mechanics, The University of Arizona, Tucson,
AZ 85721, USA
e-mail: mhickman@email.arizona.edu

160

P.B. Mirchandani et al.

1 Introduction
This paper proposes an approach to integrate to two transport operational strategies,
bus signal priority and bus rescheduling, to provide better service in case of a bus
breakdown.
The bus rescheduling problem arises when a previously scheduled trip is disrupted,
and the underlying system suffers unexpected costs and delays. Bus breakdowns,
traffic delays and accidents, depot overload and road work are the examples that
demand the rescheduling of vehicles. For example, a regional public transportation
system in Arizona has 37 fixed routes and a fleet of 189 buses. In June 2005, the total
miles traveled in the system were 622,198. On the average, failures were reported
approximately every 5000 miles resulting in over 100 repair calls for that month (Sun
Tran 2005). Recuperation from some failures can be done quickly, but some serious
failures lead to moving the disabled bus for long-term maintenance and reassignment
and rescheduling of the bus fleet.
Bus breakdowns may significantly affect the system, since they require picking up
the passengers from the disabled bus. In such situations, the current planned schedule may result in serious delays or may even become infeasible. Therefore, the fleet
schedule needs to be adjusted in real-time, the adjustment depending on the current
state of the system, which is certainly a dynamic system.
In some sense, the bus rescheduling problem can be approached as a dynamic version of the classical vehicle scheduling problem (VSP) where assignments are generated dynamically. Li et al. (2009) define the vehicle rescheduling problem (VRSP),
give a linear integer formulation, and propose a mathematical programming based
heuristic to solve the problem quickly.
Bus signal priority (BSP), also known as transit signal priority (TSP), is a much
used strategy that facilitates the movement of buses through signal controlled intersections (see, e.g., Dion et al. 2004; ITS America 2002) where the major goal is to
improve bus operations and, perhaps, increase bus ridership from improved schedule
reliability. The BSP can be implemented in a variety of ways. Conventional BSP for
cycle-time-based signal timing includes strategies referred to as (a) passive priority,
(b) early green, (c) green extension, (d) actuated transit phase, (e) phase insertion,
and (f) phase rotation, each being performed within a currently fixed cycle time (see,
e.g., ITS America 2002; Mirchandani et al. 2001). A more flexible method, and more
efficient in the sense there is less disruption to non-transit traffic, is BSP with realtime traffic-adaptive signal control where the cycle time may vary from cycle to cycle
(Mirchandani et al. 2001). Another advantage of adaptive cycle-time-based BSP is
that the additional delay time imposed on non-transit traffic is minimized.
Related BSP studies include sensitivity analysis of BSP operations (Rakha and
Zhang 2004), integration of BSP with emergency preemption (Mirchandani and Lucas 2004), transit headway control using BSP (Ling and Shalaby 2003), and location
of bus stops for BSP (Kim and Rilett 2005).
Returning to the bus rescheduling problem, note that there is the “backup” bus
that services the passengers (and possibly cargo) of the disabled bus. If BSP is employed for the backup bus, its travel time to the breakdown point can be reduced. The
reduction of the travel time leads to the decrease of delay costs, since the passengers from the breakdown bus may wait less time to be picked up. Furthermore, the

A macroscopic model for integrating bus signal priority with vehicle

161

backup bus can have the opportunity to serve more subsequent trips if it can reach the
breakdown point earlier. However, other buses and non-transit vehicles that also pass
through the intersections used by the backup bus may be affected by the signal priority being provided to the backup bus. Therefore, tradeoffs need to be made so that the
backup bus can pass the intersections quickly, while simultaneously, delays to other
buses and non-transit vehicles are not significantly increased. An optimization model
is proposed to address this problem.
The general idea behind the model presented in this paper is as follows. Since
there may exist more than one backup-bus candidate in the entire network, for each
of the candidates, we solve a corresponding optimization problem to determine the
intersections where the BSP is applied for the backup bus. After the BSP problems are
solved, the times when the backup buses reach the breakdown point are known and
the corresponding underlying networks can be constructed. (For solving the VRSP,
an underlying network is constructed for each candidate backup vehicle where nodes
correspond to scheduled bus trips/tasks, and directed arcs from a node correspond to
traveling to possible next trips/tasks from a completed task/trip; see Li et al. 2007.)
Then, the bus rescheduling algorithm is applied for each underlying network.
The major contributions of the paper are (1) the concept of integrating BSP and
real-time bus rescheduling to provide better service, (2) the development of the BSP
optimization model which determines, for a candidate backup-bus, the signals to be
activated through transit-priority, and the resulting travel time for the backup-bus,
and (3) the development of a two-stage procedure that computes the travel time for
each backup- bus using BSP optimization (stage 1) and for that backup-bus the a new
assignment (and new schedule if allowed) for all the buses (stage 2). Conducting stage
1 and stage 2 for each candidate bus allows the selection of the optimal backup-bus
and a new assignment.
This paper is organized as follows. Section 2 briefly reviews our vehicle rescheduling approach. A macroscopic model for the BSP is given in Sect. 3. Section 4 presents
computational experiments to compare performance of the approaches with and without using BSP. A summary of results and areas of future research are discussed in
Sect. 5.

2 Background of the vehicle rescheduling approach
One of crucial decisions in the vehicle rescheduling problem (VRSP) is regarding
which bus should backup the disrupted trip. The selection of the backup bus involves
several factors such as the time when the trip was disrupted, the position of the currently operating buses, the available capacities of potential backup buses, and the
compatibilities of itineraries among the bus trips. A procedure is developed by Li et
al. (2007) to define a set of backup vehicle candidates to service the disrupted trip.
Since the original schedule is disturbed by the vehicle breakdown, the new schedule might differ considerably from the initial one. These changes may make the associated crew rescheduling problem difficult, since it is essential that all crews know
the itinerary of each new trip. Note, however, a schedule change may not be a major
issue in some applications. For example, each crew may know all itineraries utilized

162

P.B. Mirchandani et al.

in a small transit agency. Yet, minimizing the number of changes is crucial in many
applications. Although it is almost impossible to obtain a solution for the VRSP without affecting the current planned schedule, it is possible to decrease the number of
possible changes from this initial schedule.
In general, there exist two kinds of methods for mitigating the degree of changes in
the new schedule. The first approach is to add a constraint for each operating vehicle,
such that the number of new trips that the vehicle needs to serve is less than or equal
to a pre-specified number. This hard constraint, based on a given number of buses,
can always limit the degree of schedule disruptions; however, it may be difficult to
pre-specify an appropriate number. If the given number is too small, the problem
may be infeasible. If the given number is too large, a large number of trips will be
rescheduled. An alternative approach is to make this constraint softer by including in
the objective function, along with usual operating and fixed vehicle costs, a penalty
cost for each reassignment of a trip to a new vehicle.
In the vehicle scheduling problem, every regular trip needs to be served. This requirement, however, may be not satisfiable in some vehicle rescheduling problems.
In some cases, the vehicle breakdown may delay not only the disrupted trip but other
trips. For example, this happens when there is no extra vehicle at the depot, or when
the trips that the breakdown vehicle is scheduled to cover are at a considerable distance from the depot as well as from other operating vehicles. Therefore, some trips
may have to be cancelled or delayed considerably.
Without a formal optimization approach, a human scheduler often cancels the trips
that are initially scheduled to be covered by the disabled bus when there is no extra
bus at the depot. If an extra bus is available at the depot, often the easiest and quickest
approach of the human scheduler is to allocate the vehicle from the depot to serve the
trips that the disabled bus is initially scheduled to cover. This manual approach may
yield a poor solution. Li et al. (2009) propose an optimization based heuristic to
assure that a good reassignment is obtained.
The single depot vehicle rescheduling problem (SDVRSP) defined in Li et al.
(2009) is as follows:
Given a depot and a series of trips with fixed starting and ending times, given
the travel times between all pairs of locations, and given a disrupted trip with
the vehicle breakdown time and place, find a feasible reschedule with the minimum weighted sum of operating, fixed vehicle, delay, trip cancellation and
schedule disruption costs, in which (i) each vehicle performs a feasible sequence of trips, and (ii) a trip is either served, or cancelled when it is impossible
to reach the starting point in time, resulting in a large trip cancellation cost.
Li et al. (2009) proposed a heuristic incorporating column generation, Lagrangian
relaxation, subgradient search and an insertion-based primal heuristic. Computational
experiments on randomly generated problems were reported. The results showed that
the Lagrangian heuristic performs very well for solving the SDVRSP, referred to as
VRSP in the rest of this paper.

A macroscopic model for integrating bus signal priority with vehicle

163

3 Macroscopic model for BSP
Our concept combines BSP and vehicle rescheduling operations when the associated agencies/departments cooperate in managing traffic and transit operations. (In
the US, many cities have transit operations and traffic management administered by
a single department of transportation.) Since many current intersection signal controllers are actuated and/or coordinated, to calculate exact effects of BSP for each
controller for each rescheduling solution, we need to embed a BSP operation (for
each intersection) into a microscopic simulation model, interface it with the VRSP
algorithm that considers the status of each intersection from the time of breakdown,
and iteratively simulate and optimize the schedule for each backup candidate. This
approach is very time consuming and, furthermore, not appropriate in the eventual
application since we do not envision that the exact status of each controller will be
considered in the rescheduling method. Therefore, a macroscopic model was used
that is described below.
In this macroscopic model, if the times between (i) when the candidate backup bus
approaches an intersection and (ii) the times when other buses are approaching this
intersection are outside a given time interval, say D, the interactions between corresponding BSP operations may be negligible (this is especially so if traffic-adaptive
BSP is employed), the backup bus can gain the advantage of BSP and all the travel
times may be reduced. In this case, the backup bus receives priority treatment, and
this priority does not interfere with other bus operations. However, if the time difference between bus priority requests at an intersection is within the given time interval
D and the intersection controller gives signal priority to the backup bus, other buses
approaching this intersection at this time cannot take the advantage of BSP and, in
fact, may be slightly delayed. For example, at intersection 1 of Fig. 1, if the times
when two buses are approaching the intersection are very close, BSP can be provided
to only one bus.
The overall proposed integrated VRSP-BSP approach is as follows. First determine all backup-bus candidates by using the simple procedure given in Li et al.
(2007). Then select the best backup candidate using the following two-stage optimization:
Stage 1: For each backup-bus candidate, solve a BSP problem in order to reduce the
travel time of the backup bus to the breakdown point.
Stage 2: Based on the estimated new travel times, construct the underlying network
and apply the VRSP algorithm in Li et al. (2009) to obtain a good rescheduling solution.
Fig. 1 Example of a bus signal
priority conflict

164

P.B. Mirchandani et al.

3.1 Model formulation
We make the following assumptions for the macroscopic BSP model for each intersection:
• the travel time between two intersections is given
• the average waiting times with and without BSP at each intersection is known
• right-turn on red is allowed so the right-turn movement is not affected by the signal
timing but has a slight delay time (also given) due to gap-acceptance; and
• the times when other buses approach an intersection are known.
Since we use the same procedure to solve the BSP problem for all of the candidate
backup buses, we consider a generic backup-bus candidate in the following notation.
• I = {1, 2, . . . , L}: the set of signalized intersections that the backup bus needs to
pass through, not including the intersections where the backup bus needs to make
a right turn.
• Tij : the travel time from the intersection i to j . T01 is the travel time from the
rescheduled position of the backup bus to the to the first intersection in set I .
• Wi : the average waiting time at intersection i.
• Ri : the average waiting time reduction at intersection i if BSP is applied.
• t0 : the time of the vehicle breakdown, when one performs rescheduling.
• D: a given time interval. If the time difference between the arrivals of the backup
bus and another bus is within D, either the backup bus or the other bus can take
advantage of BSP, otherwise both can.
• A(i) and Sik : A(i) is the set of buses (not including the backup bus) which are
approaching the intersection i. Sik is the time when bus k, ∀k ∈ A(i) is scheduled
to reach intersection i.
3.2 Decision variables

1
xi =
0

1
yik =
0

if BSP is provided to the backup bus at intersection i
otherwise
BSP is provided to the bus k ∈ A(i) at intersection i
otherwise

∀i ∈ I
∀k ∈ A(i), ∀i ∈ I

ti is the time when the backup bus leaves intersection i, ∀i ∈ I .
3.3 Objective function
Our purpose is to find a tradeoff which attempts to reduce the delay time of the backup
bus and simultaneously not delay other buses significantly. As a consequence, the
weighted sum of delay times for both the backup bus and other buses is chosen as
the objective function. If we have a higher priority for the backup bus, we can use a
larger weight for its delay time; a smaller weight for the backup bus makes other bus
travel times more important.

A macroscopic model for integrating bus signal priority with vehicle

165


 
The objective function we used is Z = (tL − t0 − L−1
i∈I
k∈A(i) ×
i=0 Ti,i+1 ) +
L−1
k
k
βi (Wi − Ri yi ), where (tL − t0 − i=0 Ti,i+1 ) is the time for the backup bus to reach
 
the last signalized intersection on its route, i∈I k∈A(i) (Wi − yik Ri ) is the total
delay times of other buses at these intersections, and βik is the priority weight of bus
k at intersection i, when the weight for the backup bus is 1.
We note that the objective function does not include the delays to non-transit vehicles in the network when BSP is implemented. Mirchandani et al. (2001) have
studied this problem using microscopic simulation models and observed that delays
to non-transit vehicles occur mostly for cross streets where BSP triggers, and noted
that adaptive traffic control with BSP significantly reduces these delays. In real-life
operations we may include in the above objective function non-transit delays if detector information is available to estimate traffic flows. In this paper, we only study the
improvements in transit rescheduling when we have BSP. We envision similar effects
to non-transit vehicles as discovered by Mirchandani et al. (2001), with cycle-based
BSP and traffic-adaptive BSP.
3.4 Constraints
The time when the backup bus leaves intersection i is ti = ti−1 + Ti−1,i + Wi −
Ri xi , ∀i ∈ I , which equals to the time of leaving the previous intersection, i − 1, plus
the travel time, plus the average waiting time, minus the possible time reduction from
the BSP.
The relationship between xi and yik , ∀k ∈ A(i), ∀i ∈ I is as follows: When |ti−1 +
Ti−1,i − Sik | ≤ D, either the backup bus or bus k ∈ A(i)can take the advantage of
BSP, hence xi + yik = 1.
When |ti−1 + Ti−1,i − Sik | > D, bus k ∈ A(i) can take the advantage from BSP.
Hence, yik = 1. However, xi can still be 0 since it may be influenced by other buses
that are approaching this intersection. We use the following constraints to represent
this logic.
(xi + yik − 2)M ≤ |ti−1 + Ti−1,i − Sik | − D ≤ yik M
(xi + yik ) ≥ 1
where M is a large number.
Note that |ti−1 + Ti−1,i − Sik | is nonlinear. In order to linearize it, a binary variable
zik is introduced. If ti−1 + Ti−1,i − Sik ≥ 0, zik = 1. Otherwise, zik = 0. We then have
the following constraint:
(zik − 1)M ≤ ti−1 + Ti−1,i − Sik ≤ zik M.
Therefore,
|ti−1 + Ti−1,i − Sik | = (ti−1 + Ti−1,i − Sik )zik + (Sik − ti−1 − Ti−1,i )(1 − zik )
= 2ti−1 zik − ti−1 + (Sik − Ti−1,i )(1 − 2zik )

166

P.B. Mirchandani et al.

Since ti−1 zik is nonlinear, a continuous variable fik = ti−1 zik is introduced and included in the constraints:
0 ≤ fik ≤ ti−1
ti−1 + (zik − 1)M ≤ fik ≤ zik M.
The above two constraints insure that fik = ti−1 when zik = 1 and fik = 0 when
zik = 0.
In summary, we obtain the following linear constraints for each i and k to insure
that only the backup bus or another closely arriving bus can be provided BSP at each
intersection:
(xi + yik ) ≥ 1
(zik − 1)M ≤ ti−1 + Ti−1,i − Sik ≤ zik M
(xi + yik − 2)M ≤ 2fik − ti−1 + (Sik − Ti−1,i )(1 − 2zik ) − D ≤ yik M
0 ≤ fik ≤ ti−1
ti−1 + (zik − 1)M ≤ fik ≤ zik M.
3.5 Overall BSP optimization
For a given backup bus, the BSP problem may be formulated as a mixed integer linear
program as follows:

  
L−1

min tL − t0 −
Ti,i+1 +
βik (Wi − Ri yik )
i=0

i∈I k∈A(i)

such that
ti = ti−1 + Ti−1,i + Wi − Ri xi
(xi + yik ) ≥ 1
(zik − 1)M ≤ ti−1 + Ti−1,i − Sik ≤ zik M
(xi + yik − 2)M ≤ 2fik − ti−1 + (Sik − Ti−1,i )(1 − 2zik ) − D ≤ yik M
0 ≤ fik ≤ ti−1
ti−1 + (zik − 1)M ≤ fik ≤ zik M
where zik , xi , yik are binary variables, and the fik are continuous variables, ∀k ∈ A(i),
∀i ∈ I .
This BSP model was used in the computational experiments discussed in the next
section. As a preview, when BSP was used there was an average 11.77% decrease in
the travel time to reach stranded passengers when compared to the case when there
was no BSP. For example, examine rows 18 and 19 in Table 2: the delay time (D)

A macroscopic model for integrating bus signal priority with vehicle

167

for the disrupted trip without BSP (case indicated by P0) is 16.2 min and with BSP
(case indicated by BS0) is 13.2 minutes, about 18% improvement for the scenario
corresponding to those rows. Further analyses of this model are given after the results
are listed in Tables 2 and 3.

4 Computational experiments
The main objectives of computational experiments were to investigate the influence
of the BSP operations on the reduction of travel times and then to examine the impact
of smaller travel times on the vehicle rescheduling for bus operations.
4.1 Experimental configuration for vehicle rescheduling
First, we generated several vehicle scheduling problems using the random data generation method proposed in Carpaneto et al. (1989) and solved them. The BSP model
requires the knowledge of deployment at physical intersections. We considered a
two-dimensional grid network, where each arc represents a travel link with one-unit
length, and each node represents an intersection that is controlled by a traffic signal with BSP. We assume, without loss of generality, that when a bus travels from a
point ρa towards a point ρb , its route is designed to travel vertically first then horizontally. Given these routes, we can determine if some buses will meet at any specific
intersection. The total travel time between two points equals the average travel time
on the links on the route plus the average waiting times at the intersections within the
route. We assume that the average travel time on a unit link is 30 seconds and the average waiting time at an intersection is also 30 seconds. Thus, the travel time (θρa ,ρb )
in seconds between two link mid-points, ρa and ρb , is θρa ,ρb = 30L + 30I , where L
is the number of travel links between ρa and ρb and I is the number of intersections
between ρa and ρb .
A disruption is introduced so that an early trip is the disrupted trip (trip Tb ). We
select the models and algorithms discussed by Li et al. (2009) as our approach for the
VRSP. The greedy heuristic P 0 with a trip-reassignment penalty cost of 500 was used
to solve the problem since it demonstrated a good performance in Li et al. (2009). The
fixed trip-cancellation cost, C, was set to 2000. In order to investigate the impact of
different breakdown times on the rescheduling, we examined the situations where the
bus breaks down at 20%, 50% and 80% into the disrupted trip, in time and distance,
in each case at link mid-points.
In real-life situations, the determination of backup vehicles requires the knowledge
of the anticipated vehicle capacities in the operating buses and the common itineraries
among bus routes. However, in the simulation of scenarios in the computational experiments, breakdowns were generated only by distances and travel times and it was
assumed that only one backup vehicle, which had sufficient capacity, picked up the
stranded passengers. We also assumed that the maximal delay that we may incur to
backup the disrupted trip was 25 minutes; and hence if an operating bus was selected
as a backup candidate, its arrival time to the breakdown point had to be less than or
equal to 25 minutes.

168

P.B. Mirchandani et al.

4.2 Experimental configuration for bus signal priority
The BSP model was applied for each backup candidate. The time interval D was set
to 60 seconds. The average reduction in waiting time due to BSP at intersection i,
Ri , was set to 8 seconds, that is about 27% reduction given that the average waiting
time at each intersection is 30 seconds. The weight parameter for the backup bus was
set to 1.0 as default, while the weight parameter βik for other buses was set to 0.8 in
order to give higher priority to the backup bus.
A(i) can be determined as follows. Let the earliest time when the backup bus
reaches intersection i be denoted by Ei if the backup bus takes advantage of BSP at
all signalized intersections to i, while the latest time when the backup bus reaches
intersection i be denoted by Li if the backup bus does not take the advantage of
BSP in any signalized intersection to i. If the time when other buses approach the
intersection i is in the interval [Ei − D, Li + D], these buses are included in A(i).
After the BSP model is solved (Stage 1) and the new travel time of the backup bus
from the rescheduled position to the breakdown point is determined, the underlying
network is constructed. Then the algorithm for the VRSP is executed (Stage 2).
The BSP model was solved using CPLEX 7.0. The VRSP algorithm was implemented in C++. Both were executed on Sun-Fire-880 Workstations, each having 2
UltraSPARC III processors at 900 MHz, 4 GB of RAM and a Solaris 9 operating
system.
4.3 Results
Different numbers of iterations were performed based on problem sizes; for the
smaller sized problems, we went through more iterations. Table 1 gives the information on the number of iterations and problem sizes, where the problem size is the
number of originally scheduled trips. Table 2 compares the performance of the VRSP
approach for 10 instances of each problem with the number of trips 100, 300 and 500,
in the case there is not a backup vehicle at the depot. Table 3 presents similar results
when there is a backup vehicle at the depot. Three approaches are used to solve the
problem: the manual recovery approach (M), the Lagrangian heuristic (P0) with the
greedy insertion and penalty cost of 500, and the combination of the BSP and the Lagrangian heuristic with greedy insertion (referred to as BP0 in the table). The details
of the Lagrangian heuristics can be seen in Li et al. (2009).
The first five columns in Table 2 give the number of original trips (Trips), the average original number of vehicles (Veh), the breakdown time (BT), the average number of remaining trips (NRT) at breakdown, and the different algorithm approaches
(Alg), respectively. Columns six to thirteen provide the average delay in minutes for
the disrupted trip (D), the average number of cancelled trips (CT), the average trip
cancellation cost (CC), the average rescheduled number of trips (RT), the average operating cost (OC), the total cost (UB), the performance gap (G), and the CPU seconds
respectively, when there is no backup vehicle from the depot.
Table 1 Numbers of iterations
and original trips

Original trips

100

300

500

# of iterations

100

100

80

A macroscopic model for integrating bus signal priority with vehicle

169

Table 2 Computational results—without an extra backup bus at the depot
Trips

100

Veh

30.2

BT

20

50

80

300

79.2

20

50

80

500

125.2

20

50

80

NRT

99.2

98.5

95.4

297.3

289.9

280.6

493.4

477.9

460.5

Alg

D

CT

CC

RT

OC

M

25.0

3.9

12145

0.0

81113

P0

20.3

2.1

6180

3.6

BP0

19.5

2.1

6249

3.4

M

25.0

3.9

12145

P0

16.2

1.8

UB

G
(%)

CPU

93258

N/A

N/A

81367

89347

1.59

0.58

81404

89353

1.70

0.58

0.0

79744

91889

N/A

N/A

4965

5.0

80273

87738

1.76

0.54
0.54

BP0

14.9

1.9

5445

4.2

80219

87765

1.83

M

25.0

3.9

12145

0.0

78511

90656

N/A

N/A

P0

13.7

1.6

4623

4.6

79075

85998

1.65

0.49
0.49

BP0

12.1

1.6

4603

4.7

78994

85948

1.65

M

25.0

4.6

13698

0.0

212023

225721

N/A

N/A

P0

22.8

2.5

7790

3.3

212669

222109

2.02

13.17
13.07

BP0

16.4

2.2

6744

4.1

212713

221507

1.52

M

25.0

4.6

13698

0.0

207892

221590

N/A

N/A

P0

19.9

1.9

5982

4.9

209081

217513

1.51

11.33
11.33

BP0

15.8

1.9

5901

4.3

209081

217132

1.57

M

25.0

4.6

13698

0.0

204978

218676

N/A

N/A

P0

16.1

1.8

5280

4.2

206137

213517

1.47

9.61
9.64

BP0

13.2

1.4

4052

5.8

206038

212991

1.17

M

25.0

3.9

12417

0.0

332315

344732

N/A

N/A

P0

18.1

2.5

7766

2.9

332724

341940

1.42

43.34
43.60

BP0

15.1

2.6

8209

2.9

332518

342177

1.69

M

25.0

3.9

12417

0.0

327179

339596

N/A

N/A

P0

17.2

2.2

6733

3.1

327956

336239

1.30

37.44
37.29

BP0

12.5

2.1

6428

3.5

327749

335927

1.18

M

25.0

3.9

12417

0.0

323544

335961

N/A

N/A

P0

16.2

2.0

6312

3.6

324106

332218

1.41

31.92

BP0

16.2

2.2

6953

2.6

323770

332023

1.49

32.09

Columns in Table 3 present the results in a similar way with the two additional
performance gaps, G1 and G2, when there is a backup vehicle available at the depot. The gaps are due to two different situations: (1) we always use an extra backup
vehicle from the depot; and (2) we may or may not use an extra backup bus from
the depot. Two situations generate different lower bounds. Therefore, we computed
two lower bounds: the first lower bound is LB1, which is obtained for situation 1;
and LB2, which is obtained for situation 2. The performance gap (G1) corresponds to
the lower bound LB1, and the performance gap (G2) corresponds to the lower bound
LB2.
For example, if the number of original trips is 500, the average number of vehicles
needed for the original VSP is 125.2 over 10 instances (see row 20, column 2 in
Table 2). If the vehicle breakdown happens at 50% into the disrupted trip, the number
of remaining trips is 477.9 on average (see row 23, column 4 in Table 2). When there

170

P.B. Mirchandani et al.

Table 3 Computational results—with an extra backup bus at the depot
Trips Veh

100

BT NRT

30.2 20

50

80

Alg

79.2 20

50

80

CT CC

125.2 20

50

80

UB

G1
(%)

G2
(%)

CPU

24.0 0.9 2999

0.0

86200

89199

N/A

N/A

N/A

P0

20.6 0.8 2330

0.6

86166

88796

2.70

0.01

0.62

BP0 19.0 0.8 2330

0.7

86112

88792

2.74

0.01

0.61

98.5 M

24.1 1.2 3951

0.0

84758

88709

N/A

N/A

N/A

P0

18.7 0.5 1520

2.1

84900

87470

3.10

0.27

0.57

BP0 16.3 0.5 1520

0.57

2.1

84849

87419

3.04

0.22

23.3 1.1 3643

0.0

83487

87130

N/A

N/A

N/A

14.4 0.3

980

2.2

83392

85472

2.96

0.06

0.52

BP0 12.0 0.3

980

2.1

0.52

95.4 M

83448

85478

3.04

0.08

297.3 M

24.5 1.0 3409

0.0 217232

220641

N/A

N/A

N/A

P0

22.3 0.8 2660

0.8 217156

220216

1.11

0.07

13.07

BP0 20.3 0.8 2650

13.16

0.8 217235

220286

1.17

0.11

289.9 M

25.0 1.0 3501

0.0 213048

216549

N/A

N/A

N/A

P0

20.2 0.5 1582

2.4 212931

215713

1.26

0.13

11.54

BP0 20.0 0.5 1495

11.55

1.9 213206

215651

1.25

0.12

280.6 M

25.0 1.4 4720

0.0 210195

214915

N/A

N/A

N/A

P0

15.9 0.4 1163

2.4 210286

212649

1.51

0.33

9.85
9.74

BP0 12.8 0.2
500

RT OC

99.2 M

P0
300

D

516

2.4 210468

212184

1.23

0.07

493.4 M

24.4 1.0 3413

0.0 337313

340726

N/A

N/A

N/A

P0

16.8 0.9 2659

1.2 336981

340240

0.86

0.13

43.31

BP0 16.8 0.9 2775

43.77

0.9 337011

340236

0.98

0.22

477.9 M

23.5 1.2 4216

0.0 332101

336317

N/A

N/A

N/A

P0

17.4 0.5 1431

2.2 331866

334397

0.88

0.16

37.54

BP0 16.5 0.6 1807

37.61

1.3 332307

334764

1.03

0.28

25.0 1.8 6048

0.0 328302

334350

N/A

N/A

N/A

15.5 0.3

827

3.0 329127

331454

1.21

0.38

31.95

BP0 14.6 0.3

896

2.5 328891

331037

1.20

0.36

32.02

460.5 M
P0

is no backup bus at the depot, and the algorithm P0 is used, the average delay times
are 17.2 minutes, 2.2 trips on average are cancelled, the trip cancellation cost is 6733,
3.1 trips on average are rescheduled, the operating cost is 327956, the total cost is
336239, G is 1.30%, and CPU second is 37.44 (see row 24 in Table 2).
Since the maximum delay is set to 25 minutes, the distance from the rescheduled
position of the backup bus to the breakdown point is not very long and the number of
intersections that a backup bus needs to pass through is limited. Thus, the BSP model
was solved very quickly using CPLEX (though not presented in the tables, CPU time
was generally less than 1 second). The models with the BSP and without the BSP
lead to similar CPU times and performance gaps.
The use of the bus signal priority fairly reduces the delay time serving the disrupted trip. For example, the delay time using P0 and BP0 is 18.1 and 15.1 seconds
(see row 21 to 22, column 6 in Table 2), when the number of original trips is 500,

A macroscopic model for integrating bus signal priority with vehicle

171

the vehicle breakdown happens at 50% into the disrupted trip, and there is no backup
bus at the depot. On average, in contrast with the vehicle rescheduling without BSP
operations, the combination of the BSP and vehicle rescheduling reduces the travel
time to reach the stranded passengers by 11.77%.
The number of cancelled trips, the trip cancellation cost, and the total cost are very
slightly reduced using the VRSP-BSP model. This is quite normal, since the costs
involving the disrupted trip are very small in comparison with the total operating
costs of the system on the entire network.

5 Conclusions and future research
Bus signal priority (BSP) is an effective strategy to facilitate bus movement through
signalized intersections. If BSP is integrated with the vehicle rescheduling operations, the travel time of the backup bus to the stranded passengers can be reduced.
Furthermore, in order not to significantly delay other buses that pass through the corresponding intersections, an optimization model is proposed to find a balanced BSP
setting so that the backup bus can travel quickly while, simultaneously, other buses
are not delayed significantly.
The computational experiments show that the integration of BSP and vehicle
rescheduling effectively reduces the delay of the backup bus to reach the breakdown
point and decreases the delay costs. On average, the travel time is reduced by 11.77%
when the BSP is incorporated into the VRSP. The total cost is decreased slightly since
the cost involving the disrupted trip is only a small portion of the total operations cost
of the system on the entire network.
Currently, the BSP model is solved by CPLEX directly. In order to improve the
computational performance for the large-scale problem, a future study should address
the complexity of the BSP problem and design algorithms considering the problem’s
special structure. Of course, the ultimate future study would be to conduct an operational field test for vehicle rescheduling with and without BSP.

References
Carpaneto G, Dell’Amico M, Fischetti M, Toth P (1989) A branch and bound algorithm for the multiple
depot vehicle scheduling problem. Networks 19:531–548
Dion F, Rakha H, Zhang YH (2004) Evaluation of potential transit signal priority benefits along a fixedtime signalized arterial. J Transp Eng 130:294–303
ITS America (2002) An overview of transit signal priority
Kim W, Rilett LR (2005) Improved transit signal priority system for networks with nearside bus stops.
Transp Res Rec 1925:205–214
Li J-Q, Mirchandani PB, Borenstein D (2007) Vehicle rescheduling problem: model and algorithms. Networks 50:211–229
Li J-Q, Mirchandani PB, Borenstein D (2009) A vehicle rescheduling problem with real-time vehicle
reassignments and trip cancellations. Transp Res, Part E Logist Trans Rev 45:419–433
Ling K, Shalaby A (2003) Automated transit headway control via adaptive signal priority. J Adv Transp
38:45–67
Mirchandani P, Knyazyan A, Head L, Wu W (2001) An approach towards the integration of bus priority, traffic adaptive signal control, and bus information/scheduling systems. In: Voß S et al (eds)
Computer-aided scheduling of public transport. Selected papers of the 8th international conference,

172

P.B. Mirchandani et al.

CASPT 2000, Berlin, Germany, June 21–23, 2000. Lect notes econ math syst, vol 505. Springer,
Berlin, pp 319–334
Mirchandani PB, Lucas DE (2004) Integrated transit priority and rail/emergency preemption in real-time
traffic adaptive signal control. ITS J 8:101–115
Rakha H, Zhang YH (2004) Sensitivity analysis of transit signal priority impacts on operation of a signalized intersection. J Transp Eng 130:796–804
Sun Tran (2005) Sun Tran Monthly Operations Report, Tucson

Computers & Operations Research 34 (2007) 1585 – 1600
www.elsevier.com/locate/cor

Delivery itineraries and distribution capacity of a freight network
with time slots
M. Caramiaa,∗ , P. Dell’Olmob , M. Gentilic , P.B. Mirchandanid
a Istituto per le Applicazioni del Calcolo “M. Picone”, C.N.R., Viale del Policlinico, 137 - 00161 Roma, Italy
b Dipartimento di Statistica, Probabilità e Statistiche Applicate, Università di Roma “La Sapienza”, Piazzale Aldo Moro,

5 - 00185 Roma, Italy
c Dipartimento di Informatica ed Applicazioni, Università di Salerno, Via Ponte Don Melillo - 84084 Fisciano (Salerno), Italy
d Department of Systems and Industrial Engineering, College of Engineering, University of Arizona, 85721-0020 Tucson, AZ, USA

Available online 29 August 2005

Abstract
The paper focuses on the distribution problem of delivering goods to medium size stores in a Central Business
District (CBD) having limited off-street parking which can accommodate only restricted space and time for parking, loading/unloading operations. In this scenario, freight distribution can be addressed from two perspectives:
(i) from the viewpoint of delivery/pick-up ﬁrms, delivery itineraries need to be coordinated with consideration of
the delivery capacities and times at store sites for parking, and loading/unloading operations; (ii) from the viewpoint of transportation and city planners, the “distribution capacity” in the CBD must be determined, including the
average cost of distribution routes, the maximum number of routes that can be simultaneously coordinated, the total
number of stores that can be served, etc., much in the way trafﬁc engineers are interested in the “trafﬁc capacity”
of a transportation network under which the vehicles move efﬁciently.
Both the above viewpoints are addressed in this paper by solving the following problem: what delivery itineraries
are available so that parking loading/unloading capacities and associated time windows are respected and the
itineraries are “balanced” in a way that costs and number of deliveries fall in given ranges. This problem is studied
and a mathematical programming formulation is developed. To evaluate exactly the freight distribution capacity, a
branch-and-bound approach is developed, where the relaxation of the formulation provides good bounds. Subsequently, a heuristic is presented that is useful from an operational point of view. In fact, the latter algorithm exploits
the results provided by the exact approach and maximizes the efﬁciency of the system.
䉷 2005 Elsevier Ltd. All rights reserved.
∗ Corresponding author. Tel.: +39 06 88470222; fax: +39 06 4404306.

E-mail addresses: m.caramia@iac.cnr.it (M. Caramia), paolo.dellolmo@uniroma1.it (P. Dell’Olmo), mgentili@unisa.it
(M. Gentili), pitu@sie.arizona.edu (P.B. Mirchandani).
0305-0548/$ - see front matter 䉷 2005 Elsevier Ltd. All rights reserved.
doi:10.1016/j.cor.2005.07.013

1586

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

1. Introduction
Freight distribution problem in a congested urban network is characterized by, among other factors,
(i) the transportation network including trafﬁc characteristics, parking capacity, delivery and pick-up
facilities, (ii) type of clients being served (neighborhood grocery stores, department stores, distribution
centers, warehouses, etc.), and (iii) the type of goods being picked-up or delivered. In this paper, we focus,
in particular, on the distribution problem involving medium-sized stores (e.g., neighborhood grocery
stores). Freight transportation in such a context is inﬂuenced not only by the location of the stores, but
also by the size of the network links and the availability of parking areas for the freight vehicles. Indeed,
medium size stores in old European cities like Rome are spread out in the Central Business District
(CBD) having narrow streets and with limited off-street parking which can hardly accommodate one or
two trucks at a time for parking, loading and unloading operations, and even then the trucks may obstruct
the street trafﬁc. In fact in such scenarios, some cities, for example, London and Singapore, have started
to impose congestion pricing in the CBD during peak hours so that there is less pollution and more
smooth trafﬁc ﬂows. Invariably, this will require the delivery and pick-up trucks to make their trips more
efﬁciently through the CBD.
These location/transport characteristics have a strong inﬂuence on ﬁnding practical solutions to this
problem. Each client requires different types of goods during the day, which usually are shipped by
different trucks (e.g., frozen food, fruits, detergents) that cannot be unloaded simultaneously by them
due to the shortage of parking area. Yet, the preferred periods for the delivery are quite short and they
are often during the same periods of the day. Therefore, these deliveries have to be scheduled according
to multiple slots contained in just a few time windows for each customer. Moreover, since the narrow
streets of the CBD have limited capacity, the travel times to move from one customer to the next one in
the distribution path are not negligible.
The ﬂeet involved to serve this type of demand is generally composed of vehicles that depart either
from plants or distribution centers external to the CBD, possibly located in the hinterlands. Another
important relevant factor is that often in these cities it is difﬁcult to obtain logistical support for intermodal
distribution, where freight from large trucks is allocated to medium size vehicles more suitable for the
movement in the city center.
The freight distribution concerns become more relevant during high demand periods (e.g., during
Christmas), when the congestion in the area and/or the amount of requests make the limited time and size
available for unloading/loading operations result in major bottlenecks of the system. In such a context,
both the knowledge of the effective freight distribution capacity of the network and the coordination and
planning of distribution routes, might alleviate the effects of the bottlenecks.
In such scenarios, there are two perspectives on these freight distribution concerns. On the one hand,
from the viewpoint of the delivery/pick-up ﬁrms, one needs to develop delivery itineraries so that deliveries
are coordinated with consideration of the delivery capacities and times at the customer sites for parking,
loading/unloading operations; indeed, the available time windows for the delivery of service play a
key role in ﬁnding the routes for the delivery/pick-up vehicles. On the other hand, from the viewpoint
of transportation and city planners, there is an interest in determining the “distribution capacity” in the
CBD, much in the same way the trafﬁc engineers are interested in the “trafﬁc capacity” of a transportation
network under which the vehicles move efﬁciently. That is, the planners should be interested in the
evaluation of the maximum freight distribution capacity of the CBDs facilities including the average cost
of distribution routes, the maximum number of routes that can be simultaneously coordinated, the total

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

1587

number of stores that can be served, etc., with minimum disruption of other vehicular trafﬁc; this could
also assist them in setting congestion pricing schemes and other policies to enhance commerce.
Both the above viewpoints are addressed in this paper by solving the following problem: what delivery
itineraries, from the distribution starting points (herein referred to as the “depots”) to the customers, are
available so that parking loading/unloading capacities and associated time windows are respected and
the itineraries are “balanced” in a way that costs and number of deliveries fall in given ranges. In this
paper, we present the “delivery-only” version of the problem. It is easily applicable to the cases where
precedence constraints, such as single pick-up and then single delivery, or multiple pick-ups and then
single delivery, are included.
A slightly similar problem, motivated from a practical planning need for City of Rome’s Great Jubilee
of 2000, was addressed in [1]. A model was developed to ﬁnd different itineraries for pilgrims to visit a set
of given churches, considering temporal restrictions regarding the overall length of the itinerary and the
time spent for each visit. Moreover, relevant literature review indicates many freight distribution models
for problems on a national level, including multimodal transportation (e.g., see [2,3]). For distribution
of deliveries to small and medium-sized customers in urban areas, models focus on the vehicle routing
problem (VRP), and all its variants, and try to design routes that minimize either the number of vehicles or
the total travelled distance (e.g., see [4,5]). When time-window constraints are also considered, reported
research applies classical VRP models to address the distribution problems (e.g., see [6–8]).
As far as we know, the problem of analyzing the freight distribution capacity of an urban network
and associated facilities has not been studied. This is the focus of the research reported in the paper. We
study the problem and provide a mathematical programming formulation. To evaluate exactly the freight
distribution capacity, we use a branch-and-bound approach, where the relaxation of the formulation
provides good bounds. Subsequently, we propose a heuristic that is useful from an operational point of
view, since it looks for high-quality delivery routes (in terms of average waiting time and costs).
The paper is organized as follows. Section 2 contains a formal description of the problem and its
mathematical programming formulation. The branch-and-bound algorithm is described in Section 3 where
computational results, obtained by running the algorithm on randomly generated instances, are given.
Section 4 describes the proposed heuristic approach and the computational results obtained on the same
test instances. Conclusions and areas of further research are discussed in Section 5.

2. Problem description
We are given a complete graph G = (V , E), with node set V and edge set E, and a weight function
w : E → R + which assigns a distance w(e) with each e ∈ E. With each node v ∈ V is assigned a multiple
time window tw(v, i) = [s(v, i), f (v, i)], i = 1, . . . , n(v), where s(v, i) and f (v, i) are, respectively,
the starting and the ending time of the ith time window of node v, and, n(v) is the total number of time
windows associated with v. The length of each time window is equal to the service time. Let us deﬁne
a service (v, i) to be the couple (v, tw(v, i)). For brevity of notation and when no confusion may arise,
we denote a service simply by .
A path  of length m is a sequence of m services, 1 , . . . , m , such that
f (k ) + w(k , k+1 )  s(k+1 ),

k = 1, . . . , m − 1,

(1)

1588

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600
7AM -7:30AM
8AM -8:20AM

10

1

10AM -10:30AM

12PM -12:30PM

2

13PM -13:30PM

5

20
10

10
9AM -9:20AM

11AM -11:20AM
12PM -12:30PM

3

30

15PM -15:30PM

4

10AM -10:15AM
12AM -12:30AM

Fig. 1. A network with multiple time windows at nodes.

where s(k ) and f (k ) are, respectively, the starting and the ending time of the time window associated
with service k , while w(k , k+1 ) is the weight of the arc connecting the two nodes that are associated
with services k and k+1 .
The duration of a path is the sum of (i) the weights of its edges, (ii) the service times at each node,
and, (iii) the waiting times (i.e., s(k+1 ) − (f (k ) + w(k , k+1 ))). Two paths i and j are incompatible
if they share the same service.
A path  is feasible if the following conditions hold:
(a)
(b)
(c)
(d)

its duration is not greater than a given threshold Tmax ;
it does not visit more than one time window for each node;
it includes kmin or more time windows;
it does not contain more than kmax time windows.

In the following, unless otherwise stated, we refer to a set of paths as a set of compatible and feasible
paths.
Consider for example the simple network of four nodes in Fig. 1. The label on each arc is its weight.
Node 1 has two time windows while node 2, 3 and 4 have three time windows each. In total, there are
11 services on the network. For example, service (1, tw(1, 1)) is associated with the ﬁrst time window
tw(1, 1) = (8AM.8: 20AM) of node 1. Let Tmax = 400 min, kmin = 2, kmax = 4 and consider the path
1 = {(1, tw(1, 1)), (4, tw(4, 1)), (3, tw(3, 1))}, that satisﬁes (1) and uses three services; it visits the
ﬁrst time window of node 1, the ﬁrst time window of node 4, and the ﬁrst time window of node 3. The
waiting time at node 4 is equal to 30 min, and the waiting time at node 3 is equal to 1 h and 10 min. The
duration of this path is given by the sum of the weights of its arcs, the service times and the waiting times
at each nodes, that is: 10 + 30 + 20 + 20 + 20 + 30 + 70 = 200 min.
Path 2 ={(2, tw(2, 1)), (1, tw(1, 1)), (2, tw(2, 2))} is not feasible since it does not respect condition
(b). Path 1 and path 3 = {(2, tw(2, 1)), (1, tw(1, 1))} are not compatible since they share service
(1, tw(1, 1)), while 1 is compatible with path 4 = {(4, tw(4, 2)), (3, tw(3, 2)), (2, tw(2, 3))}.
Given a set of paths, we deﬁne the distribution capacity of the network as the total number of services
visited by those paths. We look for a set of paths such that the distribution capacity is maximum.

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

1589

8AM - 9AM
1PM -1:30PM
5:30PM -6PM

1

40

2

9:30PM - 9:45PM
12PM -12:30PM
4PM - 5PM

Fig. 2. The original network.

Fig. 3. The reduced network in the case of one path only.

2.1. Mathematical formulation
In this section we provide a mathematical programming formulation for the problem. In order to do
that, we deﬁne a new graph G = (V  , E  ) as follows.
The new graph G : The node set of G is V  ∪ {1 , . . . , q } ∪ {1 , . . . , q }, where q is an upper bound
on the total number of feasible and compatible paths, each i ∈ V  is associated with a service in G,
and, 
1 , . . . , q , 1 , . . . , q are additional dummy nodes. Note that a trivial upper bound of parameter
q is v∈V n(v)/kmin . There is a (directed) arc (i, j ) between two nodes i, j ∈ V  if and only if the
corresponding services satisfy constraint (1) and are associated with different nodes in G. The weight of
any arc (i, j ) ∈ E  , whose end points are the nodes associated with services i and j, is equal to the weight
of the edge in G. E  also contains zero weighted arcs between each h , h = 1, . . . , q, and each i ∈ V  ,
and, zero weighted arcs between each i ∈ V  and h , h = 1, . . . , q.
A solution of the original problem described above is a set of paths 1 , . . . , q , with origins in
{1 , . . . , q } and destinations in {1 , . . . , q }.
Consider the network in Fig. 2, with two nodes, one arc whose weight is equal to 40 and a total number
of services equal to 6. Let q = 1. The corresponding new graph G is depicted in Fig. 3. There are eight
nodes, six of them correspond to the services in the original network G and there are two additional
dummy nodes 1 and 1 . Dotted arcs in G are the zero weighted arcs; all the other arcs have weight equal
to 40. Note that there is no arc among nodes 1 and 2, or among nodes 3, 4, 5, 6 since they correspond to
services associated with the same node in G.

1590

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

We are ready now to give the mathematical formulation of the problem. Let  = {1 , . . . , q } and
 = {1 , . . . , q }. Moreover, let xih be a binary variable equal to 1 if node i is in path h, and 0 otherwise.

Similarly, let yijh be a binary variable equal to 1 if arc (i, j ) is in path h, and 0 otherwise. Furthermore, let
(i) be the set of nodes reachable from i, and −1 (i) the set of nodes that reach i, s(i) the starting time
of the service associated with node i ∈ V  , and f (i) its ending time, and, let Vj ⊆ V  be the subset of
nodes in V  corresponding to services of the original network G associated with the same node j ∈ V .
The optimization problem may be written as

max

q
 

z=

i∈V 

s.t.

xih 

j ∈(i)



i∈V 

yijh ,

(2)
∀i ∈ V  , h = 1, . . . , q,

(3)

xih  1,

h = 1, . . . , q, ∀j ∈ V ,

(4)

xih  1,

h = 1, . . . , q,

(5)

i∈Vj



h=1



xih



i∈−1 (j )



j ∈(i)


w∈(j )

yjhw ,

∀j ∈ V  , h = 1, . . . , q,

yijh  1 ∀i ∈ , h = 1, . . . , q,



i∈−1 (j )

kmin 

yijh =

yijh  1 ∀j ∈ , h = 1, . . . , q,



i∈V 

xih  kmax ,

h = 1, . . . , q,

xjh f (j ) − xih s(i)  Tmax ,

∀i, j ∈ V  , h = 1, . . . , q,

(6)

(7)
(8)

(9)
(10)

xih ∈ {0, 1},

∀i ∈ V  , h = 1, . . . , q,

(11)

yijh ∈ {0, 1},

∀i, j ∈ V  ∪  ∪ , h = 1, . . . , q.

(12)

The objective function requires us to maximize the number of services covered by the paths. Constraints (3) assure that, given node i and path h, if there is no arc outgoing from i in that path then the
corresponding service i is not visited (i.e., xih must be set to 0); otherwise, since we are maximizing, if
there is at least one arc outgoing from i, then xih must be set to 1. Constraints (4) impose that in each
subset of nodes Vj at most one service can belong to a path h. Constraints (5) say that a service can
belong to at most one path. Constraints (6)–(8) are classical relations to deﬁne a path. Constraints (9)

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

1591

allow paths to contain at least kmin services and at most kmax services. Constraints (10) limit the duration
of each path to be at most Tmax . Finally, we have integrality constraints on xih and yijh variables.
3. An exact approach
In this section we describe a branch-and-bound algorithm to ﬁnd an exact solution of the problem.
Branch-and-bound tree: The algorithm starts with a root node whose associated subproblem is the
relaxation of the integer program presented in the previous section. If the relaxation happened to have
an integer solution, then it would provide an optimal solution to the integer variables. In general, this
solution provides an upper bound on the optimal solution.
The search tree of the branch- and -bound is formed by at most |V  ∪  ∪ | levels, and each level j of
the search tree is formed by j · |V  ∪  ∪ | nodes. Nodes in  and  are used, respectively, to open a
new path, or to close one in the search tree.
Using a depth ﬁrst search, one moves from a level to a subsequent level choosing the leftmost feasible
service not yet chosen, i.e., a service that satisﬁes (1), and path feasible conditions (a) and (d) (kmax and
Tmax ). If at a certain level k we have  paths in the current partial solution and the only choice is +1 (that
is the current path +1 has to be closed), we check whether the current subpath +1 has less than kmin
services. If this is the case, we cannot consider subpath +1 in the current solution. Otherwise (i.e., the
current subpath has at least kmin services) we can insert path +1 in the current solution. In both cases
we go on +2 on the next level (k + 1) to start a new subpath.
Once a subpath, say  , is found, we have to check whether it contains services of the same node. In
this occurrence, we can retrieve feasibility by trying to split this subpath  into two subpaths (note that
the total number of visited services is the same). This is possible if and only if 2 · kmin  | |, where | |
is the length of the current subpath  . If this condition is not satisﬁed then we cannot consider subpath
 in the current solution, and, as above, we go on to the next level and start a new subpath.
Pruning rules. The following pruning rules have been implemented.
Rule 1: Order arcs in E  starting with the cheapest one, so if one takes the ﬁrst k arcs from the list we
have a lower bound on the duration of a path of length k. Dynamically maintain this list so that when an arc
is put in the current solution it is deleted from the list. Now, in the current subpath  , r = kmin − (| | − 1),
i.e., r is the difference between kmin and the number of arcs in the current subpath. If r > 0 do as follows:
if the difference between Tmax and the current subpath duration is lower than the sum of the r cheapest
arcs in the list (which do not belong to any subpaths 1 , . . . , −1 in the current solution), then the subpath
can be pruned.
Rule 2: Similarly, one can use a pruning rule at a node of the search tree as follows. Let t be the
difference between the total number of nodes and the number of nodes considered in the current solutions
(including those discarded by some of the above rules). If the sum of the current number of services plus
t is smaller than the current upper bound value then the search tree can be pruned.
3.1. Experimental results
Experiments were conducted on a PC Pentium III with 700 MHz and 256 MB RAM. The codes have
been implemented in the C language, while the linear relaxation has been solved with CPLEX version
8.1.0. Results are reported in Tables 1–3. We carried out our experiments on several scenarios characterized

1592

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

Table 1
Results of the exact algorithm with Tmax = 100 min, upper bound on arc cost equal to 20 min, and average service time equal to
10 min
Nodes

Number
of services

kmin

kmax

Covered
services (%)

Covered
nodes (%)

Path duration
(min)

Number
of paths

Number of
services in a path

Waiting time
(min)

100
100
100
100
100
100

248.2
248.2
248.2
248.2
248.2
248.2

3
3
3
5
5
5

8
5
3
8
7
5

98.2
98.2
98.2
65.2
65.2
65.2

100.0
100.0
100.0
92.3
92.3
92.3

95.7
82.9
79.2
99.4
97.7
95.9

46.9
62.5
82.2
27.9
28.9
32.4

5.2
3.9
3.0
5.8
5.6
5.0

10.2
14.9
21.2
9.8
12.9
18.2

500
500
500
500
500
500

1278.3
1278.3
1278.3
1278.3
1278.3
1278.3

3
3
3
5
5
5

8
5
3
8
7
5

92.2
92.2
92.2
61.3
61.3
61.3

100.0
100.0
100.0
92.0
92.0
92.0

94.3
91.2
87.1
98.3
96.5
94.5

226.6
318.5
392.9
132.8
142.5
156.7

5.2
3.7
3.0
5.9
5.5
5.0

12.5
17.2
25.9
10.8
13.7
19.5

1000
1000
1000
1000
1000
1000

2598.9
2598.9
2598.9
2598.9
2598.9
2598.9

3
3
3
5
5
5

8
5
3
8
7
5

89.2
89.2
89.2
56.6
56.6
56.6

100.0
100.0
100.0
89.6
89.6
89.6

95.7
92.6
88.4
99.7
97.9
95.9

482.9
662.3
772.7
267.5
272.4
294.2

4.8
3.5
3.0
5.5
5.4
5.0

12.6
17.8
26.0
10.9
13.9
19.7

All statistics are averages of 10 test problems.

by different network sizes and different values of the design parameters Tmax , kmin and kmax . Indeed, from
a planning point of view, it is important to understand how to manage these parameters in order to reach
the desired performance of the system.
We started testing our branch-and-bound algorithm on networks with 100, 500 and 1000 nodes, with
kmin = 3 and kmax = 3, 5, 8, and kmin = 5 and kmax = 5, 7, 8. Moreover, we deﬁned the service time as a
Gaussian variable with mean value equal to 10 min. We assigned a weight to each arc uniformly drawn at
random from 1 to 20 min. Either two or three time windows have been assigned to each node at random.
Time windows have been generated from 7 AM to 11 AM. Furthermore, Tmax was set to 100 min.
In Table 1 we report, using average values of 10 test problems for each scenario, the percentage of
covered services, the percentage of covered nodes, the average path duration, the average number of
paths, the average number of services in a path, the average waiting time of the paths.
Let us examine ﬁrst the effect of the difference kmax − kmin on the set of instances. As it can be seen in
column 5 the number of covered services (in percentage) is deeply effected by kmin . Indeed, this parameter
determines the distribution capacity (i.e., the percentage of covered services) independently of the value
of kmax . For example, on graph with 100 nodes this percentage remains 98.2% when kmin = 3, and, 65.2%
when kmin = 5. However, the number of paths found increases (for 500 nodes and kmin = 3 it goes from
226.6 to 392.9, and, from 132.8 to 156.7 when kmin = 5). That is, we can reach the same performance of
the system (e.g., the distribution capacity) by means of different kinds of paths, as it will be clearer by
examining the charts on Fig. 4. This is because it is possible to cover remaining services at the low levels

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

1593

Table 2
Performance of the exact algorithm with Tmax = 100 min, upper bound on arc cost equal to 20 min, and average service time
equal to 10 min
Nodes

Number
of services

kmin

kmax

Covered services (%)
(LP relaxation at root)

Number of times
a pruning is executed

CPU time
(s)

SI

Branches

100
100
100
100
100
100

248.2
248.2
248.2
248.2
248.2
248.2

3
3
3
5
5
5

8
5
3
8
7
5

99.6
99.6
99.6
68.8
68.8
68.8

1243.4
1423.9
802.1
1429.9
1912.0
92.2

1121.2
1102.3
983.2
1724.9
1723.4
1598.2

1805.2
1390.4
1460.5
1542.6
1576.8
1923.9

10,423.2
15,253.1
7823.0
12,032.4
17,142.6
10,243.7

500
500
500
500
500
500

1278.3
1278.3
1278.3
1278.3
1278.3
1278.3

3
3
3
5
5
5

8
5
3
8
7
5

95.7
95.7
95.7
68.6
68.6
68.6

29,998.4
55,775.3
27,685.1
40,142.7
60,823.8
35,910.9

2512.8
2510.1
2429.5
2772.6
2789.2
2699.1

57,760.0
44,480.1
46,720.4
49,344.6
50,432.7
61,536.1

333,536.1
488,096.4
250,336.2
385,024.7
548,544.9
327,776.3

1000
1000
1000
1000
1000
1000

2598.9
2598.9
2598.9
2598.9
2598.9
2598.9

3
3
3
5
5
5

8
5
3
8
7
5

93.3
93.3
93.3
67.9
67.9
67.9

989,002.2
1,512,002.7
901,203.7
1,512,970.0
2,078,223.5
1,122,445.9

7234.9
7129.0
7012.3
7457.6
7435.1
7199.4

1,805,124.0
1,390,256.2
1,462,783.3
1,542,894.8
1,576,998.0
1,923,354.1

10,673,152.1
15,619,072.2
8,010,752.5
12,320,768.0
17,553,408.7
10,488,832.2

All statistics are averages of 10 test problems.

of the search tree by several numbers of short feasible paths. On the other hand, kmax affects the quality of
the paths. Observe the values of the average path duration (column 7 in Table 1) and the average waiting
time (column 9) in relation to kmax . It can be noticed that with large values of kmax we have paths of longer
average duration but shorter waiting time. In particular, waiting time is cut by a half in the instances with
1000 nodes when we move from instances with kmax = 3 to instances with kmax = 8.
Finally, for ﬁxed values of kmin and kmax , the percentage of visited services of the network decreases
as the size of the graph increases. For instance, with kmin = 3 and kmax = 8 it decreases from a maximum
of 98.2% to a minimum of 89.2%, respectively. This is due to the incompatibilities among time windows.
Indeed, we generated time windows, as in real scenarios, to be concentrated in the same morning time
intervals; therefore, the greater the size of the network, the more incompatibilities among services (i.e.,
the number of time windows that do not satisfy (1) increases). This behavior will be more evident looking
at the results in Table 3, obtained by varying the average service time from 5 to 30 min.
Let us examine now Table 2 whose ﬁrst four columns are the same as in Table 1. In column 5, we report
the average optimal solutions of the linear relaxation of the formulation given in the previous section
(which provide upper bounds on the optimal integer solutions) computed at the root of the branch-andbound tree (again as average percentage values of covered services). The subsequent columns show the
average number of times the pruning rules discussed in the previous section occur in the search tree,
the average CPU time (in seconds), the average number of simplex iterations (SI) at the root to solve the
linear program (LP), and the average number of branches in the search tree (Branches).

1594

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

Table 3
Results of the exact algorithm with Tmax = 100 min, upper bound on arc cost equal to 20 min, and average service time varying
in {5, 10, 15, 20, 25, 30} min
kmin

kmax

Service time (min)

Covered services (%)

100
100
100
100
100
100
100
100
100
100
100
100

3
3
3
3
3
3
5
5
5
5
5
5

6
6
6
6
6
6
8
8
8
8
8
8

5
10
15
20
25
30
5
10
15
20
25
30

99.5
98.2
92.5
90.9
85.9
40.7
80.4
65.2
50.5
45.1
15.2
6.8

500
500
500
500
500
500
500
500
500
500
500
500

3
3
3
3
3
3
5
5
5
5
5
5

6
6
6
6
6
6
8
8
8
8
8
8

5
10
15
20
25
30
5
10
15
20
25
30

94.8
93.5
88.1
86.6
81.8
38.8
76.6
62.1
48.1
43.0
14.5
6.5

1000
1000
1000
1000
1000
1000
1000
1000
1000
1000
1000
1000

3
3
3
3
3
3
5
5
5
5
5
5

6
6
6
6
6
6
8
8
8
8
8
8

5
10
15
20
25
30
5
10
15
20
25
30

90.2
89.1
83.9
82.4
77.9
36.9
72.9
59.1
45.8
40.9
13.8
6.2

Nodes

All statistics are averages of 10 test problems.

Note that LP values follow the trend of the exact solution values, and exhibit the stability of the gap
with respect to the different scenarios. The LP formulation is stable also from the computational point
of view (observe the number of pivots in column 8 which grows linearly with the size of the problem
instance).

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

1595

100
90

Average covered services (%)

90
80
70
60
50
40
30
20

80
70
60
50
40
30
20
10

10

50

0

0
2

100
3

4

5

k min

6

7

8

150
9

10

ma
x

2

T

Average covered services (%)

100

150

4
6

k min

100

8
10

50

T max

Fig. 4. Results of the exact algorithm: percentage of services covered for different values of Tmax , kmin and kmax = kmin + 2 on
networks with 100 nodes (rear view and front view of the same chart).

As far as the behavior of the branch-and-bound algorithm is concerned, let us examine the last column
of the table (Branches). It appears that more constrained instances require less branches (see, for example,
those with kmin =kmax =3). This is consistent also with the number of times prunings are executed (column
6) which follows the same criterion. Moreover, comparing the number of branches and the running times
for instances with kmax =7 and 8, we note that when kmax =7 the number of branches is always larger than
the latter case, while the running time is basically the same. In particular, we notice that for instances with
1000 nodes, the difference between the number of branches for kmax = 7 and 8 is greater than 5,000,000
while the CPU time is almost the same. However, this is not surprising and the reason for this behavior
can be discovered by analyzing the number of times prunings are executed (column 6); this is always
greater for kmax = 7 than for kmax = 8. Indeed, the fact that the computation in both cases gave very similar
CPU times, means that a single branch has a higher cost when kmax = 7 than when kmax = 8, as one would
expect: that is, the greater the number of executed prunings, the lower the cost of each branch.
Table 3, as already mentioned, shows the effect of the conﬂicts due to overlapping time windows on
the distribution capacity of the system. With larger time windows the percentage of covered services
decreases. Note that the gap between the minimum value (when average service time is equal to 5 min)
and the maximum value (when average service time is equal to 30 min) depends also on the value of
parameter Tmax = 100 min. The impact of different parameters settings is better visualized by the chart
on Fig. 4 where the performance of the exact algorithm on instances with 100 nodes for different values
of kmin , kmax = kmin + 2, and, Tmax is plotted.
Indeed, from the planning perspective, it is useful to capture the effects of the combination of the
different parameters (minimum path length, Tmax , time windows) on the distribution capacity. The chart
has the objective of giving a synthetic view of the system performance. From the shape of the highest
level of the surface (see Fig. 4), one can realize that the same level of capacity (say around 100%) can be

1596

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

obtained with several alternative setting of parameters. For instance, if we want to avoid that paths are
too short (i.e., kmin > 2) we need to set a larger value for Tmax in order to have the same capacity (see
kmin = 2 and Tmax = 110 min, and, kmin = 4 and Tmax = 140 min). On the other hand, not too different
parameter settings decrease capacity substantially. As an example, there is a decrement from 45% (of
covered services) to 10% by moving from kmin =4, Tmax =60 min, to kmin =4, Tmax =40 min. Obviously,
different parameter settings correspond to different types of paths, even if the overall capacity is the same.
Therefore, as we already observed by analyzing Table 1, from a planning point of view, we can try to
achieve the same system performance by requiring paths of better quality: both not too short (to keep low
the effects of ﬁxed transportation costs) and with small waiting time (to keep low idle times).
The above observations motivate the development of a heuristic to ﬁnd a solution that also focuses
on the quality of the paths. Our proposed heuristic and some experimental results on the same problem
instances are discussed in the next section.

4. A heuristic approach to choose high-quality paths
The key point to use an exact algorithm is that it provides the planner with exact information on strategic
parameters such as the capacity of the network, the average waiting time, and the average duration of a
path, which cannot be achieved with a guaranteed precision if one used heuristics. However, based on
such results, the planner ﬁnds high-quality paths by means of heuristics knowing the best performance
achievable. In fact, even though the exact algorithm provides an exact solution for a given scenario, we
can have the following shortcomings:
• It provides one solution out of many possible optimal ones, and we do not know whether this one is
good in terms of other measures, such as average total waiting time and balanced path durations.
• There could exist other solutions which, on the one hand, are worse than the optimal (say 1–2%), but,
on the other hand, have a considerable smaller average total waiting time.
Therefore, we propose a heuristic which uses results of the exact algorithm, and tries to ﬁnd the best
paths in terms of minimum average total waiting time and minimum differences between path durations,
by imposing, in a certain way, that paths must guarantee to have similar characteristics to those found by
the exact algorithm.
A greedy-type heuristic is proposed using a depth ﬁrst visit of the graph, choosing the next node to be
explored according to the minimum waiting time from current node. The algorithm ﬁrst builds a set of
paths of length at least kmin , then it performs a local search to improve the solution so found; and, after
a certain number of iterations it removes some of the paths which are not “good” and holds the others.
Then, it restarts to build paths using the nodes exclusively belonging to removed paths. A more detailed
description of the heuristic is given in Table 4. We tested the heuristic on the same scenarios presented in
the previous section; the results are given in Tables 5 and 6.
Computing times of a few seconds are required by the heuristic on networks of 100 and 500 nodes,
while on networks with 1000 nodes it runs in about 15 min. After several runs made by varying , 	 ∈
{0.75, 0.8, 0.85, 0.9, 0.95}, we set  = 0.85 and 	 = 0.85 for which we obtained the best results that are
shown in Table 5.

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

1597

Table 4
The heuristic algorithm
Step 1. Select a node v from V  at random; ﬁnd a path  starting from v, by adding each time a node with the smallest waiting
time and which respects constraint (4), until either kmax is reached, or Tmax is exceeded
Step 2. If  has at least kmin services then remove the services of  from V 
Step 3. Repeat Step 1 and Step 2 until no more paths can be found
Step 4. Let desired_length =  · ave_length, with 0 <  < 1, be a percentage of the average path length, say ave_length, found
by the exact algorithm
Step 5. Let desired_wait = 	 · ave_waiting, with 0 < 	 < 1, be a percentage of the average waiting time, say ave_waiting, found
by the exact algorithm
Step 6. Try to improve the found paths as follows. For each path, try to replace a node with two available nodes, respecting
constraints (4) and kmax , either if the total waiting time of that path is reduced or the total waiting time is less than desired_wait
Step 7. Repeat Step 6 until no more improvement is possible
Step 8. Starting from the solution found, delete all the paths whose length is less than desired_length, while hold all the others.
Restart from Step 1, where V  isV  minus the set of nodes in the held paths, allowing the repetition of this restart until no more
improvement is possible

Table 5
Results of the heuristic algorithm with Tmax = 100 min, upper bound on arc cost is 20 min, and the average service time is 10 min
Nodes

Number
of services

kmin

kmax

Covered
services (%)

Covered
nodes (%)

Path duration
(min)

Number
of paths

Number of
services in a path

Waiting time
(min)

100
100
100
100
100
100

248.2
248.2
248.2
248.2
248.2
248.2

3
3
3
5
5
5

8
5
3
8
7
5

95.4
94.8
92.4
63.5
62.8
61.2

100.0
100.0
99.8
92.2
92.1
91.9

96.2
90.2
85.4
99.5
98.7
97.9

34.8
51.2
76.4
24.2
24.7
30.4

6.8
4.6
3.0
6.5
6.3
5.0

5.2
6.9
15.2
5.8
7.9
14.2

500
500
500
500
500
500

1278.3
1278.3
1278.3
1278.3
1278.3
1278.3

3
3
3
5
5
5

8
5
3
8
7
5

89.9
87.2
86.8
58.1
57.9
57.3

100.0
100.0
98.2
91.3
91.1
87.5

95.1
93.4
89.2
98.7
96.6
94.8

185.3
237.2
369.9
109.2
125.4
146.5

6.2
4.7
3.0
6.8
5.9
5.0

10.2
12.1
19.9
8.2
9.1
14.5

1000
1000
1000
1000
1000
1000

2598.9
2598.9
2598.9
2598.9
2598.9
2598.9

3
3
3
5
5
5

8
5
3
8
7
5

85.4
83.7
83.4
52.9
52.1
51.5

100.0
100.0
98.1
89.6
89.2
89.2

96.2
93.5
91.1
99.8
98.2
96.9

389.4
494.4
722.5
211.5
229.5
267.7

5.7
4.4
3.0
6.5
5.9
5.0

9.8
11.8
17.2
8.9
9.7
11.2

All statistics are averages of 10 test problems.

Table 6 compares the results of the heuristic with those of the exact approach. It shows the percentage
differences between the values achieved by the exact and the heuristic for: the average number of visited
services, the average number of paths found, the average number of services in a path, the average path

1598

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

Table 6
Comparison between the heuristic results and the exact approach results
kmin

kmax

Covered services
(decrement %)

Number of paths
(decrement %)

Services in a path
(increment %)

Path duration
(increment %)

Waiting time
(decrement %)

100
100
100
100
100
100

3
3
3
5
5
5

8
5
3
8
7
5

2.9
3.5
5.9
2.6
3.7
6.1

25.8
18.1
7.0
13.2
14.5
6.2

30.8
17.9
0.0
12.1
17.9
0.0

0.5
8.8
7.8
0.1
1.0
2.1

49.0
53.7
28.3
40.8
38.8
22.0

500
500
500
500
500
500

3
3
3
5
5
5

8
5
3
8
7
5

2.5
5.4
5.9
5.2
5.5
6.5

18.2
25.5
5.8
17.8
12.0
6.5

19.2
27.0
0.0
15.2
7.3
0.0

0.8
2.4
2.4
0.4
0.1
0.3

18.4
29.7
23.2
24.1
33.6
25.6

1000
1000
1000
1000
1000
1000

3
3
3
5
5
5

8
5
3
8
7
5

4.3
6.2
6.5
6.5
8.0
9.0

19.3
25.3
6.5
20.9
15.7
9.0

19.1
25.7
0.0
18.2
9.3
0.0

0.5
1.0
3.1
0.1
0.3
1.0

22.2
33.7
33.8
18.3
30.2
43.1

Nodes

All statistics are averages of 10 test problems.

duration, and the average waiting time. In Fig. 5, we plot the performance of the heuristic on instances
with 100 nodes for different values of kmin and kmax = kmin + 2 and different values of Tmax , when the
average service time is 10 min.
Refer now to Tables 5 and 6. The trend of the percentage of the visited services decreases when the
size of the network increases, as observed also for the exact algorithm in Table 1. Parameter kmax slightly
inﬂuences the solution of the heuristic for a given network size and a given kmin value (on the contrary,
recall that we observed in Table 1 that the percentage of visited services does not change when kmax
changes for the exact algorithm).
The main differences between the heuristic and the exact algorithm are to do with the solution quality.
Indeed, from the average waiting time (see column 10 in Table 5) it appears that heuristic solutions have
a waiting time shorter that the exact solutions. The percentage decrement of the waiting time ranges from
a minimum of 18% to a maximum of 54% (see column 8 in Table 6).
The decrement of the percentage of covered services is at most 9% (see column 4 in Table 6). This
difference increases when the network size increases. For networks with 100 nodes the heuristic objective
function value is at most 6% less that the optimum, for networks with 500 nodes is at most 7%, and, for
1000 nodes is 9%.
The number of paths found by the heuristic is always lower than the number of paths found by the exact
approach, and this decrement ranges from 5.8% to 25.8% (see column 5 in Table 6). This phenomenon
is due to an increase of the average number of services in a path which (see column 6 in Table 6), when
kmin = kmax ranges from 7.3% to 30.8%.

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

100

Average services covered (%)

Average services covered (%)

100
90
80
70
60
50
40
30
20
50

10
0
2

1599

100
4

6

k min

150
8

10

T

m

ax

90
80
70
60
50
40
30
20
10
0
2

150
4

6

k min

100
8

10

50

T

ma

x

Fig. 5. Results of the heuristic algorithm: percentage of services covered for different values of Tmax and kmin and kmax =kmin +2
(rear view and front view of the same chart).

Indeed, the reason for a decrement of the number of paths is twofold: there is an increment of the number
of services per path as just mentioned above, and/or there is a decrement of the covered services. This
second reason can be observed comparing those instances with kmin = kmax , where the number of services
per path is the same for both the exact and the heuristic algorithm. Moreover, from the experiments it turns
out that in these cases there is a maximum decrement of the covered services between the two algorithms.
Summing up, the heuristic seems to respect the design requirements, that is, producing better quality
paths with a limited decrement of distribution capacity. Moreover, by examining the chart on Fig. 5 one
can easily compare the percentage of covered services with respect to the exact one (which was able
to reach 100% in several cases). The main difference is observed between the parameter settings that
allowed the coverage of all the services in the exact solutions, and allowed the coverage of a percentage
of services ranging from 85% to 95% in the heuristic solutions.

5. Conclusions
We analyzed a new problem concerning distribution of goods to medium size stores in a Central
Business District. Objective of this problem is to plan and coordinate distribution routes, for example,
in old European cities as in Rome, so as not to worsen the trafﬁc congestion in the system. Actually,
the problem can be addressed from two perspectives: (i) from the viewpoint of delivery/pick-up ﬁrms,
delivery itineraries need to be coordinated by considering the restrictions in space and time of the CBD;
(ii) from the viewpoint of transportation and city planners, the “distribution capacity” in the CBD must
be determined, including the average cost of distribution routes, the maximum number of routes that can
be simultaneously coordinated, the total number of stores that can be served, etc.

1600

M. Caramia et al. / Computers & Operations Research 34 (2007) 1585 – 1600

We analyzed the problem and proposed a mathematical programming formulation. To evaluate exactly
strategic parameters of the network we propose a branch-and-bound solution approach for which a
relaxation of the mathematical formulation can provide good bounds. We observed, however, that the
exact approach provides one of the possible optimum solutions and that the quality of the found paths in
the solution is not taken into account. This requirement is indeed very important from an operational point
of view since, obviously, between two paths visiting the same number of services it is preferable to use
the one with less waiting time. Therefore, we proposed also a heuristic approach that focuses in ﬁnding
“good” paths (in terms of average waiting time and average path duration) such that the total performance
of the system is not too different from the exact solution provided by the branch-and-bound approach. We
evaluated both the approaches on several instances. The results show the effectiveness of the proposed
heuristic in satisfying both system requirements vis-a-vis the exact solution and quality requirements of
the distribution routes.
We ﬁnally remark that the analysis and the results presented can be applied by a central controlling
or coordinating body that grants pick-up and delivery time windows. Such a body may be able to save
waiting costs and travelling costs for many suppliers. Thus, an interesting development of this research
is the analysis of both the amount of time and money saved for carries by such a coordinating body that
plans routes according to our approach.
References
[1] Gentili M. Visiting a network of services with time constraints. Computer and Operations Research 2003;30:1187–217.
[2] Crainic TG. Service network design in freight transportation. European Journal of Operational Research 2000;122:272–88.
[3] Crainic TG, Laporte G. Planning models for freight transportation. European Journal of Operational Research 1997;97:
409–38.
[4] Bodin LD, Golden BL, Assad AA, Ball MO. Routing and scheduling of vehicles and crews. The state of the art. Computers
and Operation Research 1983;10.
[5] Laporte G, Gendreau M, Potvin J, Semet F. Classical and modern heuristics for the vehicle routing problem. International
Transport in Operation Research 2000;7:285–300.
[6] Friesz TL, Harker PT. Freight network equilibrium: a review of the state of the art. In: Daughety AF, editor. Analytical
studies in transport economics. Cambridge; 1986 [chapter 7].
[7] Levner EV. Application of models and methods in scheduling theory to problems of optimal scheduling of freight
transportation. Automation and Remote Control 1989;50(1 part 1):1–56.
[8] Panishev AV, Zhuravok AG. An efﬁcient algorithm for the scheduling of continuously executed two-stage jobs in the control
of the freight transportation process. Cybernetics and Systems Analysis 1997;33(1):77–84.

