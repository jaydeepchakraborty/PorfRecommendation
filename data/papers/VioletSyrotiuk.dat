2004 IEEE International Conference on Mobile Ad-hoc and Sensor Systems

Scheduled Persistence for Medium Access
Control in Sensor Networks
Charles J. Colboum and Vtolet R. Syrotiuk
Computer Science & Engineering
Arizona State University
P.O. Box 878809
Tempe, AZ 85287-8809
e-mail: {colbourn,syrotiuk}@asu. edu

AbsIracI-For sensor networks, throughput may not
be the most important metric to optimize in medium
access control. For many applications, periodic reports are
desirable suggesting the need for a time division (TDMA)
access scheme. However for many reasons, including nonuniformity of deployment and the large number of sensor
nodes anticipated, TDMA is impractical. In this paper, we
explore scheduled persirlence for medium access control
in sensor networks. A continuum of approaches from
simple randomized -persistent schedules at one extreme
to topology-transparent schedules based on Steiner systems
at the other are considered. We investigate the prohahility of obtaining a collision-free slot before a specified
time (numher of slots) and show that while the expected
thmughput of these approaches is the same, their variance
is strikingly different. The schemes are also remarkably
robust to high density. Furthermore, when schedules are
chosen at random for each frame, scheduled persistence
offers an interesting alternative for medium access control
in sensor networks.

I. INTRODUCTION
Advances in wireless communications, micro-electromechanical systems (MEMS) technology, and digital
electronics have contributed to the development of small,
low-power sensor nodes. A sensor node consists of a
sensor with data processing and communications capabilities. A sensor network is collection of sensor nodes
that may be used to communicate what is sensed continuously, or to detect specific events. Since the position
of the sensor nodes may not be known in advance, there
is a need for the network to coordinate in a distributed
manner, similar to the self-organizing capabilities of a
mohile ad hoc network (MANET).
Sensors come in many types (e.g.. thermal, infrared,
acoustic) and can monitor a wide variety of conditions
(e.g., temperature. humidity, pressure). The variety in
types of sensors and in their usage has precipitated
applications for sensor networks that span a range of
personal, corporate, and national interests [I]. As a
result, research on sensor networks has grown rapidly in

0-7803-8815-1/04/$20.00 0 2 0 0 4 E E E

264

order to support the implementation of these emerging
applications.
There are several differences between sensor networks
and MANETs [2]. In particular, the number of sensor
nodes deployed in a sensor network is expected to be
several orders of magnitude higher than the number of
nodes in a typical MANET. While sensor nodes may
be more densely deployed, they are also limited in
power, computational capability, and memory capacity.
Since sensor nodes are prone to failure, destruction, and
energy depletion, the topology of the network changes
frequently for these reasons rather than from node mobility. Sensor nodes may not have global identifiers because
of the amount of overhead assigning such identifiers for
a large numbers of sensors. Furthermore, the network
tends to operate as a collective structure, addressed by
attribute, rather than supporting many independent pointto-point flows. Traffic tends to be variable and highly
correlated.
The protocols designed for MANETs are not directly
useable in sensor networks due to these differences. In
this paper, our focus is on the medium access control
(MAC) protocol. The MAC protocol is fundamental in
any network whose basis is a broadcast channel, since it
determines usage of the communication resources. Not
only is it important that the channel be shared efficiently,
it should also he shared fairly and conserve energy.
There are a number of power-aware contention-based
MAC protocols for mobile ad hoc networks [31, [41
that utilize techniques including power control, powering
nodes off, and adaptive transmission rate control to
conserve energy. In general, contention-based protocols
are less satisfactory when the traffic is not independent.
Furthermore, the overhead of control packets can be
considerable (as high as 40% [ 5 ] ) in sensor networks
where the data packets are not very large. Furthermore,
the channel must be monitored continuously throughout
the handshake. which is expensive for the low radio

ranges of interest in sensor networks, where transmission
and reception have an energy cost OF the same order of
magnitude.
Of the approaches to organized access, topology.
dependent and topology-transparent strategies have been
developed for mobile ad hoc networks. In a topologydependent strategy, the protocol alternates between a
contention phase and an allocation phase. In the contention phase, nodes collect neighbour information from
which schedules are computed for use in the allocation
phase (see 161, [7] as examples). Recently, such a protocol has also been proposed for use in sensor net.works,
where traffic information specifying which nodes intend
to transmit to what destinations is also collected in
the contention phase [XI. This allows the schedules
computed to considcr the traffic flow and permit inactive
nodes to transition into a sleep state to conserve energy.
For attribute based addressing and correlated traffic it is
unclear how easy it is to provide such traffic information.
All topology-dependent schemes are sensitive to the
frequency with which the contention phase is run, and
may suffer instability if the changes in traffic or topology
occur too rapidly.
In a topology-transparent strategy, neighbour information is not used. The existing protocols construct
schedules that depend on two design parameters: N , the
number of nodes in the network, and D ,the maximum
active node degree. If the hound on D is satisfied, the
schedule guarantees at least one collision-free transmission to each neighbour [ 9 ] , [IO]. In [ I l l the existing
topology-transparent MAC protocols were generalized
by observing that their schedules correspond to an orthogonal array. The largest number of nodes for a given
frame length is supported by a Steincr system [12].
Both orthogonal arrays and Steiner systems are special
cases of combinatorial objects called cover-free families
[13]. Such combinatorial designs arise in many other
applications in networking [ 141.
The rest of this paper is organized as follows. Section II briefly reviews ypersistent CSMA protocols.
In Section I11 a frame structure is introduced, and
three generic schemes for choosing schedules within
this frame structure are developed. The fixed schedule scheme is shown to encompass known topologytransparent scheduling. Section IV compares persistence
with these scheduled schcmes, and establishes that while
expected throughput remains unchanged o r slightly improves with the scheduled schemes, the distribution of
slots in which success is achieved changes dramatically.
Each of the scheduled schemes has much less variance in
the times between successful transmissions. We discuss
consequences of this for quality of service and an
application in sensor networks. In Section V, we describe

265

briefly how scheduled schemes can he run in multiple
frames so as to achieve the performance described. The
analysis until this point makes homogeneity assumptions
to enable us to restrict to a known optimal transmission
probability. In Section VI, we develop adaptive versions
of the approaches discussed. In Section VII, we describe
derandomization of randomized algorithms in general
terms, and then discuss an interpretation of the scheduled
approaches as derandomized variants of persistence at
the frame level. Section VIII makes final observations on
these avenues connecting contention-based approaches
and scheduled ones.
11. PERSISTENT CSMA
There are several versions of carrier sense multiple
access (CSMA) protocols, with many analyzed in detail
by Kleinrock and Tobagi [I51 nearly 30 years ago. A
characteristic of all CSMA protocols is that when a node
bscomes ready to transmit, it scnses the channel hefore
making a decision to transmit. If time is continuous,
sensing is triggered by packet arrival whereas if time
is discrete (divided into fixed intervals or slots), sensing
occurs in the next slot after packet arrival.
In p-persistent CSMA, time is discrete. If the channcl
is sensed idle, the node transmits with probability p.
Therefore, with a probability q = 1 - p , the node defers
until the next slot. If that slot is also idle, the node either
transmits or defers again, with probabilities p and q. This
process is repeated until eithcr the node transmits the
packet, or another node bcgins transmitting. In the latter
case, the node acts as if a collision occurred, specifically,
it waits a random number of slots and starts the process
again. If the node senses the channel busy, it waits and
applies the algorithm in the next slot.
What probability p should be used? The value should
be related to the contention for the channel. If there
are m contenders, then the probability that one node
successfully acquires the channel in a given slot is
mpqm-'. The optimal value of p is $. Substituting
p = back into the equation, we get:

6

Pr[success with optimal p ] =

-

For small numbers of contenders the chances of snccessfully acquiring the channel are quite good. However
very quickly, the probability drops close to its asymptotic
value of 1.
When a node has m active neighbours among v nodes
in the network, we write k = ;;, and ohserve that
optimal performance is then obtained by transmission
(on average) in k out of every v opportunities. The basic
idea that we explore is to choose a value of U to construct
a frame of slots. Then within each frame, exactly k slots

are chosen for transmission attempts. We state this more
formally next.
111. SCHEDULING
PERSISTENT
CSMA

In this section we investigate scheduled p-persistent
CSMA. Suppose that the probability p of transmission
is b . One way to interpret this probability is that within
a slots, we expect to transmit at k opportunities. This is a
statement about expected behaviour, but we will examine
a stricter interpretation.
A scheduled randomized scheme, random ( k , a)scheduled, operates as follows. Choose a random set S of
size k from'u. S is a subset of the slots {O? 1 , . . . , w - l }
and corresponds to the positions in the next U slots
in which to transmit. Although this is still a random
approach, it introduces the notion of a frame of length
'U.The set S gives a transmission schedule for the next
frame. The difference between &-persistence and random
( k : v)-scheduled is that with the former we may transmit
in fewer or in more than k slots of the next a , while in the
latter scheme we choose exacrly k in which to transmit.
Imposing a frame structure on persistence in this way
actually permits a more flexible approach. It appears to
he natural to choose from among all possible k-subsets
of a o-set. However, as we shall see later, judiciously
selecting the k-subsets from which schedules are chosen
incorporates some previously studied scheduled access
schemes. In general, then, choose a subset S of the ( k )
subsets of size k from a set of size u. Based on S, there
are three natural variants to consider:
fixed S-scheduled: Assign each network node a
distinct schedule from S, to he used in every
successive frame. (This is what one typically refers
to as a scheduled scheme.)
random S-scheduled: For each frame, assign each
network node a subset (schedule) chosen uniformly
at random from S.
random distinct S-scheduled: For each frame, assign each network node a distinct subset (schedule)
chosen uniformly at random from S.
These generalize the random ( k , v)-scheduled scheme,
since taking S to he the set of all k-sets from a wset we
have that random S-scheduled yields the.random ( k , U ) scheme. However the framework encompasses not just
the randomized schemes, but also deterministic schemes.
We explore this next.
A t-design with order a, blocksize I;, and index A,
or t - ( u : k;A) design, is a pair (V,U). V is a set of v
elements, and U is a collection of k-subsets (blocks) of
V with the property that every t-subset of V appears as
a subset of exactly X blocks in U. A t-design of index
X = 1 is a Steiner system S ( t :k , a). Following initial
work by Chlamtac and Farag6 [SI and Ju and Li [IO],

-

266

Steiner systems are identified in [11]-[ 131 as the basis
for optimal topology-transparent scheduling. Choosing
S to he the blocks of a Steiner system, and cmploying
a fixed S-scheduled approach, such topology-transparent
schemes fall into the same general framework.
In this way, we find a continuum of approaches with
the simple randomized approach of p-persistence at one
extreme, and the topology-transparent scheduling based
on Steiner systems at the other. This enables us to
explore the effect of derandomization.
A N D DELAY
Iv. THROUGHPUT

We first treat the easier case of throughput under the
schemes discussed, and then turn to delay. For both.
we are concerned with expected performance and with
worst-case performance. We assume that all nodes have
data to transmit. In such a situation, interference can
result from any neighbour, if it chooses to transmit in
a specific slot. Viewing this from the standpoint of a
potential receiver, it can have a successful reception if
among the nodes in its closed neighbourhood (including
itself), exactly one is a transmitter in this slot. Let us
suppose then that each node has D neighbours. We
assume throughout that with respect to medium acccss
control, the node has no a priori information about the
identity of its neighbours or their transmission status in
the next slot.
In a (k/a)-persistent scheme, a successful transmission requires that one node transmit (with probability
klu), and that D nodes do not (each independently with
Can we achieve the same expected
probability A).
throughput with an S-scheduled scheme? For each element x of the U, define S, to be the sets containing x.
Now if, for every x,we have that
= b , then in each
slot, the probability of obtaining a successful transmission remains unchanged. Now a t-(a, k , A) design with
t 2 2 is also a ( t l)-(w, k, A d ) design, and hence

#/

~

inductively is a

]-(U,

k,X

Hi

:sign.

6

It follows that

every element occurs in X
u of the X u blocks of
-')
0
the design, and hence that t e ratio for every element is
indeed k / u . Thus t-designs can be seen as the natural
scheduled analogues of (k/a)-persistence.
This simple observation provides the basis for comparing randomized schemes with deterministic scheduled schemes. Although it demonstrates that expected
throughput is a function of frequency of transmission and
size of neighbourhood, it tells us little about variations
in worst-case throughput and in delay.
Expected throughput fails to capture two important
figures of merit for transmission scheduling. The first
is fairness. Although high expected throughput ensures
that some nodes are successful, it does not address the

issue of nodes being denied service or receiving reduced point of a receiver as neighbourhoods grow. Chlamtac,
service. The second is worst-case throughput.
Farag6, and Zhang [161 suggest a method to interleave
Within a slot, in general many neighbouring nodes solutions with’ different degree hounds, to extend the
can choose to, or be scheduled to, transmit. Hence in guarantee on throughput. However, their approach causes
the absence of information on identity of neighbours, the a substantial reduction in expected throughput in order
only guarantee can arise if there is only one transmitter to achieve the guarantee.
Now let us turn to delay. The figure of merit that we
among the w nodes, as for example in time-division
examine
here is the probability of obtaining a collisionmultiple access. Any guarantee on throughput must, as a
consequence, arise from the consideration of successive free slot prior to a specified time T , with time measured
slots in a frame. Immediately one sees that any approach in slots. One might anticipate small variation among the
that permits two nodes to be assigned the same trans- schemes, since the expected throughput is the same for
mission schedule (subset in S) cannot guarantee any all. To see that this is not the case, we consider each
successes within a frame, even if nodes have at most of the schemes when k = and w = 121. Specifically,
two neighbours. Consider as a first step the schemes in we consider ( /12l)-persistence (“Persist”), the random
which distinct subsets of S are assigned to nodes. In this ( ,121)-scheduled scheme (‘All”), and for S the 484
scenario, no one neighbour can block, all transmission blocks of a Steiner system S(2, ,121), the random Sopportunities within a frame. Indeed, suppose that any scheduled scheme (“Steiner-r”) and the random distinct
two sets in S intersect in at most e elements. Then for S-scheduled scheme (“Steiner”). Within a frame, this
a node with D neighbours, a collision-free slot within runs the gamut from a true contention-based scheme to
a frame is ensured provided that k > tD. Now asking a topology transparent scheme. In Table I, we consider
that every two k-sets intersect in at most e elements is a situation in which a receiver, in addition to the transequivalent to requiring that no l f l - s e t occur as a suhset mitter from which reception is desired, has one other
of more than one set in S. This leads naturally to Steiner active transmitter in its neighbourhood. We tabulate the
systems. An S(t:k , U ) provides the largest size of set S probability of obtaining a given number of collision-frec
for which no t-set appears in more than one of the sets. slots among the first U = 121 slots for each of the four
schemes. (0 is identically equal to zero.)
Under the restriction that no node have more than D
neighbours, choosing S to be the blocks of a Steiner
TABLE I
system S ( t ,k, U ) with k > (t - l)D provides a worstSUCCESS WITH O N E NHICHllOUK
case finite lower hound on throughput. This is explored
Free Slots
Pcrsist
All
Steiner-r
Steiner
i n [12], [13]. The main observation here is that none of
0 .002905 .000000
.002066
0
the expected throughput is sacrificed in order to achieve
I
.017387
.000000
0
0
the worst case guarantee. The observation is based on
2
.051595
.000026
0
0
the assumption, in both cases, that in each collision-free
3 ,101223 .WIZ85
0
0
slot, we succeed in delivering a packet.
4 ,147688 .02698?
0
0
As noted in [9], worst-case throughput drops to zero
5 .I70925 .239599
.359504 ,360248
when k 5 (t - 1)D; thus when the degree bound is
6 .I63439
,638430 ,639752
.73?108
violated, no guarantee on throughput is obtained. While
7 .I32800
0
0
0
expected throughput remains competitive with that of
8 ,093596
0
0
0
(k/v)-persistence, the behaviour is markedly difkerent.
.OF3122
9
n
0
0
With persistence, every transmitter-receiver pair has an
10 .032196
0
0
0
equal opportunity to succeed, and the consequence of
II
.016068
0
0
0
a larger neighbourhood is that each sees a large hut
12
.007285
0
0
0
similar degradation in success probability. Using a fixed
13 .003021
0
0
0
S-schedule, once the degree bound is exceeded, a suc14
0
.001153
0
0
cessful transmitter-receiver pair will remain successful
0
15 .000407
n
0
i n the next (and all subsequent) frames. However a pair
encountering a collision will encounter the same set of
Except for ( /121)-persistence, the schemes are limcollisions in each subsequent frame, until the topology ited to success in at most six slots since each attempts
changes or the traffic demands change. This is a striking transmission in exactly six. An optimist would ohserve
difference; while fixed topology-transparent schedules that persistence obtains seven or more free slots at least
offer valuable guarantees when the degree bound is met, 32% of the time, and hence that persistence can perform
and maintain competitive throughput when it is not met, much better than the scheduled schemes. However when
they do not exhibit similar degradation from the stand- considering quality of service, the value at issue is

261

~

the probability with which no collision-free slots arise
among the IJ. Persistence fares the worst of the four
here. This is as cxpccted. If we were to sum these
probabilities, weighted by the number of free slots, we
calculate expected throughput. The fact that persistence
obtains much of this throughput from situations with
many free slots necessitates a commensurate increase in
the probability of having few free slots. Put in other
words, the distribution of free slots for persistence has
much larger variation for random k-of-v, which in turn
has much larger variance than the schemes from a Steiner
system.
Active neighbours need not interfere in a manner that
is independent, so it is of interest to examine the same
distribution when more neighbours can collide with the
desired transmission. In Table 11, we examine the case
of five active transmitters in addition to the one desired.

number of nodes; it cannot exceed the number of sets
available. In addition, the use of such a scheme in
consecutive framcs is a difficult problem (see Section V).
However, a main deficiency of this scheme concerns its
behaviour when the degree bound of k - 1 is exceeded.
Table 111 therefore examines the situation with fifteen
active transmitters in the neighbourhood.
TABLE 111
FIFTEENNFIGHBOUKS

SUCCESS WITH

Free Slots

I
2
3
4

5

TABLE II
NE~GHIIOURS

6
7
8
9

SUCCESS WITH FIVE

Free Slots
0

Penirt

All

Steiner

6
7
8
9

.008698
,042091
,100994
,160206
.I88998
,176860
,136740
,089836
.OS I195
,023705

10

.011S13

0

0

0

II

.WI646
.001703
.000571

0

n

n

0

0

0

0

0
0

.noom
.noooso

0

0

0

n

0

0

I
2

3
J
5

12
I3
I4
15

.noons4
.002097
,020672
103679
,279344
,383806

Steiner-r
,010288

.210318
0
0

0

Penist
.058966
,168888
239863
,225218
,157267
.n87110
.n39865

0

Two things are striking. The first is that, among the
four schemes, only the Steiner system without repetition
ensures that a free slot is seen within the first U slots.
This is precisely what one expects, since the fact that
k = ensures a free slot whenever a node has at most
five neighbours; the randomization in each of the other
schemes docs not allow this. The second is that the
random ( ,121)-scheduled approach is approximately
one hundred times less likely to have zero free slots
than is ( /12l)-persistence. Again persistence pays a
price for providing many free slots in some cases by
providing very few in others.
The selection of five neighbours shows the Steiner
scheme without repetition at its best. Among all of the
schemes discussed. the Steiner scheme without repetition
is the only one that puts an absolute limit on the total

268

,313511

,202270
,067993
,009303

Steiner-r

steiner
,011861
.nxnoss ,095097
.255158 .269234
.335922 345749
,212286 ,212736
.061ns4 .059443

.MI294

.on6232 .005880

.nis5m

0

0

0

,005229

n

n

n

.001554

0

0

0
0

n
n

0
0

0
0

0
0

0

10
11
12
13

.oooJ12

14

.ooonni

0
0
0
0
0
0

15

.OOWOO

n

0
.WO180
.W761I

.OM)174
,007415
,079243 .080888
,298360 ,302800
,420497 ,424132
184389
184022
0
n
n
0
0
0

All

.0214n4
.I18495
,267024

.non098
.00002I

.non004

0

Again ( /121)-persistence exhibits the worst probability of any success within the first U = 121 slots,
but in compcnsation also exhibits the best probability of
numerous successes. What is striking is the similarity of
the Steiner and Steiner-r schemes. The Steiner-r scheme
exhibits similar performance with no limitation on total
number of nodes and simple use in repeated frames. Nevertheless, the Steiner scheme without repetition exhibits
the best probability of achieving a collision-free slot,
despite the fact that the degree limitation is dramatically
exceeded. We illustrate this in an “extreme” case with
forty active neighbours in Figure I .

.*0.035

1 ..,

Gain in Success Over Time

”.

’..

FIE. 1.

Probability of a Collision-Free Slot

~

This demonstrates the improvement from using a
Steiner system without repetition (the highest curve),
the random ( 121)-scheduled scheme (middle curve),
and a Steiner system with repetition (lowest curve). Each
shows the difference between the scheme and ( j l 2 1 ) persistence. The earlier tables show behaviour restricted
to the first z' = 121 slots. In this figure, each scheme operates randomly from frame to frame, and the behaviour
is shown over the first sixteen frames. The decay in the
improvements exhibited is a natural consequence of the
fact that ( /Ill)-persistence is progressively more likely
to obtain a free slot as time passes. After eight frames in
this example, the probability of success with persistence
is already ,998159; after twelve it is ,999921. Naturally
this severely limits the scope for improvement.
Now we turn to a different question. Given a probability of transmission of, say 1 in IO, one solution is to employ (lll0)-persistence, and another is to employ random
(l,lO)-scheduled. There are other options as well. Indeed
for any positive integer a,one could employ a random
( a :lOa)-scheduled method. In Figure 2, we compare
the difference between the probabilities of success for
solutions with cy = 2,3, , and the random (],IO)scheduled scheme. This data is for 35 active neighbours
(more than the scheme is really designed to support)
and for each curve plotted, the difference is calculated
only for numbers of slots that are multiples of loa. Four
curves arc shown. From lowest to highest they graph the
improvements obtained for a = 2 , 3 , , .

Gain in Success
mess Over l i m e

~

Gain in Success Over Time

n

.-..

0.001

Fig. 3. Improvements for Larger Framer

badly compared to the iterated random (l,lO)-scheduled
scheme, unril the end of the frame approaches when it
overtakes it. Some simple intuition may help to explain
this. In a random (1,lO)-scheduledscheme iteratcd twice,
with one neighbour a node has probability 9/10 of succeeding within the first ten slots, and 99/lOO within the
first 20. On the other hand, a random (2,20)-scheduled
scheme has probability 1- 1/
of succeeding within
20 slots. The (2,20) selection is better after 20 slots. But
a node in the
after ten slots, with probability (?)/(':),
(2,20)scheme has not even attempted a transmission let
alone succecded! This underlies the sawtooth pattem.
Indeed this sawtooth rcveals more. Within the first
loa slots, the random (1.10)-scheduled scheme is better,
as shown by the negative differences obtained. This
suggests that the appropriate value of cy to choose is
dictated primarily by the time at which a response is
desired.
To explore this furthcr, we consider situations with
fewer active neighbours as well. Figure 4 is computed
for the same schemes but with 20 active neighbours.

(y)

r

".. .... .,

.-

.-

Fig. 2. Improvements for Larger Frames

Figure 2 is quite deceptive! It only makes a comparison when the larger scheme has completed a frame.
To overcome this limitation, we calculated the exact
probability, for a random (k,U)-scheduled frame, that
success is achieved within the first y slots. This enables
us to make a finer comparison. Figure 3 is the same
as Figure 2, but with points determined every I O slots
instead of every l O c y slots.
A striking pattem emerges. Within a frame of 1 0 a
slots, the random ( a ,lOcy)-scheme appears to perform

269

!I

4.006

Fig. 4. Larger Frames: 20 Neighbours

The pattern seen for 35 neighbours is repeated here.
Improvements-are increased (note the change in vertical
scale), but the initial penalty before a frame of the larger
scheme completes has increased more dramatically. In
addition, the time elapsed until all schemes approach the

same success probability (approaching I ) has reduced.
Figures 3 and 4 are relevant because they address the
environment in which a node is confronted with more
active neighbours than the scheme was designed for.
Such a scheme is designed with 10 active neighbours
in mind, so in Figure 5 we examine the case with ten
neighbours.
0.01 7

Gain in Success Over Time

Fig. 5 . h g e r Frames: IO Neighboun

We have focussed on the first 250 slots, so the horizontal scale has changed. Nevertheless, the same trends
continue. Improvements have again increased, and again
the penalty within the first frame has increased even
more. To emphasize this, we examine a lightly loaded
case with only 5 active neighbours in Figure 6.
Gain in Success Over Time

Fig. 6 . Larger Frames: 5 Neighboun

One might conclude from Figures 5 and 6 that small
improvements later come at a large price initially. However, we emphasize that success probability when a node
has few neighbours is quite acceptable in all of the
schemes. Only when the number of active neighbours
is large are we concerned with'lengthy delays. Indeed it
is also important that the improvements depicted appear
to become smaller, but i n truth the dominant feature is
that the penalty initially becomes much more substantial
for fewer neighbours.
Scheduling persistence appears to be particularly well
suited to sensor networks for a number of reasons, which
we explore next. Imagine a large number of sensor nodes
deployed in a hazardous environment, such as structure

270

on fire. Their mission is data collection on ambient
conditions within the structure, including temperature,
chemical composition of the atmosphere, position of
the sensor, and the like. The environment within is
largely unknown, and sensors travel - sometimes quickly
- due to thermal currents, building collapse, and flow
in water and other extinguishing agents. Currency of
information about the environmental status is critical to
the safety of emergency personnel. These sensors are
to organize in an ad hoc network to collect and report
this information to an environmentally safe set of control
centers. Unlike typical systems whose task is to deliver
large volumes of data, these networks are concerned
primarily with maintaining current information. At the
same time, we expect a very large number of sensor
nodes to be deployed, and the density of deployment to
be very non-uniform.
Put simply, our .concern is not throughput. A sensor
transmitting multiple status reports in close temporal
proximity can expect close spatial proximity as well, and
indeed similarity in all of the status data. With this in
mind, a better solution is one that makes periodic reports.
Therefore one might hope to use a simple scheme such
as time-division multiple access (TDMA). However, the
environment dictates that the ability to deploy additional
sensors during monitoring be accommodated to address
the inevitable destruction of many of the sensor nodes.
At the same time, the delay imposed by using very many
sensors makes TDMA unattractive.
A random S-scheduled approach offers an interesting
alternative here. By choosing the ratio of k to v, one can
ensure that no sensor is burdened by transmitting too
often, reporting observations so often that it consumes
energy needlessly. More importantly, in regions in which
sensors have accumulated sparsely, we can choose the
set S of allowed schedules so as to ensure that success
is achieved within the v slots. One might argue that in
regions of denser sensor accumulation, loss of data is
less critical, and hence the guaranlee is not needed in any
event. However, this does not address a crucial point. In
such regions, the sensors collectively swamp the channel
and both reduce throughput and increase delay.

V. THEEXTENSION
TO MULTIPLE FRAMES
Random S-scheduled schcmes extend from one frame
to many in a straightforward manner. However, schemes
requiring the distribution of schedules so that no two
nodes have the same schedule pose some challenges.
This question is addressed briefly in [131. There the
concern is to extend the guarantee on delay to larger
neighbourhoods, but here the concern is simply to provide equal access to the channel for each transmittedreceiver pair, at least over the long term. While fixed

schemes are effective when neighbourhoods are within
the degree bound, if used repeatedly in each frame any
failure within a frame will repeat in the next unless
traffic conditions or node positions change. This is
the fundamental difference between fixed S-scheduled
and random distinct S-scheduled schemes. The latter
guarantee success within a frame if the neighbourhood
is not too large, but in addition provide equal chance
for every transmitter-receiver pair when it is too large to
ensure success within a frame. Thus one might naively
expect to use a random S-scheduled scheme, choosing
S to be the blocks of a Steiner system, for example. As
remarked in 1131. this appears to require a coordination
to ensure that no two nodes select the same schedule
in a frame, and this does not appear to he practical.
However, in a practical setting, one can reproduce similar
behaviour by having each node use a pseudo-random
number generator (the same for each node) to generate
a (pseudo-)random permutation of the sets in S. While
the periodicity of the pseudo-random number generator
prevents truly random behaviour, nevertheless on the
time scale of interest the randomization of schedules
will reasonably approximate the random S-scheduled
scheme.
It remains natural to ask whether a more appropriate
manner of changing selection of schedulcs from frame to
frame yields better delay guarantees, but from the standpoint of capturing the delay guarantees of the topology
transparent schemes while dealing with neighbourhoods
larger than the degree bound, this is a reasonable solution.

SCHEDULING
VI.’ ADAPTIVE
The much larger issue deals with adaptation to the
neighbourhood sire. Having p-persistence serve as the
model of contention-based MAC protocols is not representative of current practice. Indeed, one benefit of
contention is the ease with which adaptation to traffic
and topology can be effected. Schemes such as 802.11
adapt by varying the probability with which transmission
is attempted, based on recent history of success. In
general, success results in an acceleration of transmission
requests, while failures cause a backoff.
Adaptation in scheduled schemes poses different prohlems. We outline two strategies here, which are the
subject of current research. Suppose that a random Sscheduled scheme is being employed, where S is the set
of all k-subsets of a u-set. Given the size of the active
neighbourhood, a node can calculate the expected number of slots in a frame in which it succeeds. Suppose that
upon completion of each frame, it determines the number
of slots in which it actually succeeds. If the actual
number exceeds the expected number, the node might

27 1

conclude that it has overestimated the number of active
neighbours, and increase the value of k; conversely,
if the actual number is lower than expected, it could
anticipate that the number of active neighbours has been
underestimated, and decrease its choice for k. Unlike
binary exponential backoff, such an inductive approach
adapts more slowly to changes in neighbourhood and
traffic conditions. It suffers potentially from the variation
in successes, which we have seen can remain quite large.
Hence a scheme that employs a weighted history, for
example by averaging the current value of k with an
anticipated number of successes in the next frame, can
he used to dampen response to statistical variation in
the success rate. There remains, however, the question
of computing the anticipated number of successes in the
next frame. To calculate this, we can use the techniques
described earlier to determine the probability that the
number of active neighbours is at least (at most) a
specified value based on the actual number of successes
achieved. Our estimate can then be set to the value that
maximizes our expected number of successes in the next
frame.
We do not discuss the details here. However, it is
reasonable to expect that in a network with periodic
traffic, the appropriate number of attempts can be leamed
by observation of the channel. Nevertheless, experiments
(currently underway) are ncedcd to validate this expectation.
In sensor networks of the type described, one could
also adapt by topology control. Since sensors in similar
positions can be expected to make similar observations,
and to have a similar neighbourhood. we can potentially
exploit the redundancy of nodes in proximate locations.
If a node “consistently” ohserves that it is in a densely
populated region (by, for example, lowering its transmission rate below a threshold). it could. advisc its
neighbours of its request to sleep (or doze) and wait
for a predetermined (randomly distributed) period of
time before rejoining the network. This advice to its
neighbours is simply to alleviate problems arising from
entire sets of nodes in a common region determining that
all can sleep.
In this paper, we do not explore either of these adaptation schemes, and outline them here simply to suggest
that mechanisms to replace contention by scheduled
approaches need not imply that adaptation is not permitted. We would emphasize, however, that the methods
proposed here are meant to address adaptation with
random (k. w)-scheduled approaches, and the effect of
changing k in the Steiner schemes poses challenging
combinatorial questions.

VII. DERANDOMIZATION
A theme running through these investigations is the
relationship between contention-based methods (?andomized methods") and scheduled variant in which some
or all of the randomness has been removed (in the fixed
S-scheduled methods, the methods are deterministic).
In this way, the process of scheduling contention-based
schemes can he viewed as one of derandomization. The
problem of derandomization of an algorithm is to replace
the randomized algorithm by a deterministic one with
as small a decrease of efficiency as possible. Luby [17],
[I81 pioneered the idea of derandomization using limited
independence to lead to a deterministic algorithm for a
problem in parallel algorithms.
The success of removing randomization from a randomized algorithm depends on a number of issues of
the problem being solved, most importantly the issue
of uniformity in computation. (In complexity theory,
algorithms may be classified as uniform or non-uniform;
see Section 2.3 of [I91 for more details.) In general,
the approach to derandomization is to find a method for
searching the associated sample space for a good point
with respect to a given instance of the input. There are
two general methods for searching the sample space.
The niethod of conditional probabilities starts with a
(uniform) sample space and searches it in a non-trivial
way because the sample space is usually exponential in
size. The other is the method of small sample spaces.
This method first tries to design a small sample space
that can he searched exhaustively. Chapter 26 of [ZO]
provides some examplcs of applying these two methods
towards derandomizing probabilistic proofs.
The replaccment of (k/u)-persistence by random
(k,v)-scheduled schemes reduces the size of the sample space by reducing the number of possible sets of
transmissions within a frame. The use of Steiner systems
reduces it further, indeed replacing an exponentially
large sample space by one of polynomial size. In our
application, at least within a frame and under restrictive
assumptions on the number of active neighbours, this
replacement enables us to obtain a guarantee on the presence of free slots, replacing the probabilisric guarantee
of persistence. This suggests the intriguing possibility
of using the scheduling to derandomize probabilistic
guarantees i,nto absolute ones. As developed here, the
deterministic guarantee survives only for a single frame,
but the framework of derandomization appears to he
a useful one for understanding the relation between
random and scheduled channel access.
VIII. CONCLUSIONS
Contention and scheduled access each provide some
desirable qualities for mcdium access control. By ex-

272

amining a spectrum of approaches between persistence
and known topology-transparent methods, we have observed that while expectcd throughput remains relatively
unchanged, the distribution of time to wait for the next
success shows wide variation. Indeed the scheduled
approaches offer in general a tighter distribution (smaller
variance) in time to success, and this improves our
chances of succeeding in delivery within a specified
time limit. At the extreme, under strong assumptions on
the neighbourhood sizes and total number of network
nodes, we recover in addition the benefits of topology
transparency. In sensor networks, the tightened variance
in time to success offers an attractive alternative.
Contention-based schemes offer simple schemes for
adaptation, and at this time the scheduled schemes do
not. Despite this. we advance two ideas for adaptation
that appear promising. The results shown here suggest
that scheduling offers a viable alternative to contention,
and indeed provides better service guarantees in a wide
variety of situations. This underlies the need for a
more thorough investigation of the relationship between
contention and scheduling, most particularly to capture
the adaptation provided by contention-based schemes in
scheduled ones.
ACKNOWLEDGMENTS
This work was supported in part by ARO grant DAAD
19-01-1-0406, and by NSF grant ANI-0105985. The
authors thank Wensong Chu for helpful discussions on
adaptation. .
REFERENCES
[I] 1. F. Akyildiz. W. Su, Y. Sankarasub-uniam.
and E. Cayirci,
"Wireless sensor networks: A survey," C m p s r e r Nework~.

vol. 38, pp. 393422, 2M12.
[21

C. E.

Perkins,

Ed., Ad

Ifoc Nelworkr

Addison-Wesley, Inc.,

2000.
[3] S . Singh and C. S. Rahavendn. "PAMAS
power aware
multi-access protocol with signdling for ad hoc networks," ACM
Comppurer Cmmunicatim Review pp. 5-26, July 1998.
[4] J. P. Monks, V. Bharghavan. and W.-M. W. Hwu, "A power
controlled multiple access protocol for wireless packet networks:'
in Proceedings q f l E E E Infi,com, 2001, pp. 1-1 I
151
. . A. W w and D. E. Culler. "A transmission control scheme
for media access in sensor networks:. in Pmceedings of 4CM
~

MobiCom, July 2001, pp. 221-235.
161 I. CNamlac and S . S . Pinter, "Distributed node organization algorithm far channel access in a multihop dynamic radio network."
IEEE Traransaclimrs on C,myx".r, vol. 36, pp. 728-737, June

1987.
[7] C. Zhu and S . Conon. "A five-phase reservation protocol (FPRP)
for mobile ad hoc networks," in Pmceedingz of IEEE bzfocom,
1998, pp. 322-331.
[8] V. Rajendran, K. Obraczka. and I. J. Garcia-Luna-Aceves.
"Energy-efficient. collision-free medium access conlml for wireless sensor networks," in Proceeding.v of ACM SenSys'03, 2003.
[9] 1. Chlamtvc and A. F m g Q "Making trmsmission schedules immune to topology changes in multi-hop packer radio networks,"
IEEWACM Transactions on Networking, vol. 2, no. I, pp. 13-29.
Fehruiuy 1994.

[IO] J:H.

lu and V. 0.K. Li, “An o p t i d topology-transparent
scheduling method in multihop packet radio networks:’
IEEWACM Traionsoctiony on Neworking. vol. 6. no. 3. pp. 298306. June 1998.
[ I l l V. K. Symtiuk. C. I. Colboum, and A. C. H. Ling, “Topology
transparent scheduling for MANETs using orthogonal anays,” in
Proceedings DIAL-M/POMC Joint Workvhop o n Foundations of
Mobile Computing, Septemkr 2003, pp. 43-49.
[I21 C. I. Colboum. V. K. Syrotiuk, and A. C. H. Ling, “Steiner
systems for topology-transparent access control in MANETS,” in
Pmceedinp of the Second Inremalional Conference on Ad Hoc
N e ~ ~ and
r bWreless (AdHoc Nowd03). 2003, pp. 247-258.
1131 C. 1. Colboum, A. C. H. Ling. and V. R. Syrotiuk. ’Coverfree families and topolocy-mnspacnt scheduling for MANETS:’
Designs, Codes, and C,yptography, vol. 32, no. 1-3, pp. 3 5 4 5 .
May-July 2004.
1141 C. J. Colboum, I. H. Dinitz, and D. R. Stinson. “Applications
of combinatorial designs to communications, cryptography, and
networking:’ in Stcmyr in Combinotoricr. J. D. Lamb and D.A.
Preece, Eds. London Mathematical Society, L e c t w Note Series
267, 1999, pp. 37-100.

273

I151 L.Kleinmck and E Tubagi, “Random access techniques fat data
transmission over packet-switched n d i a channels:’ in Pmceedingr o f t h e Nrrtionnl Computer Conference, 1975, pp. 187-201.
(161 I. CNamtac. A. Farag6. and H. Zhang. “Time-spread multipleaccess (TSMA) protocols for multihop mobile radio networks,”
IEEWACM Transactions on Nemorkiinp. vol. 5 , no. 6. pp. 804812, December 1997.
1171 M. Luby, “ A simple parallel algorithm for the marimd indspendent set.” SIAM Juumol on Computing. vol. 15, pp. 1036-1053,
1986.
“Removing randomness in panllel computation without
1181
a pmccssor penalty:’ in Promedings of the 29th Annuul IEEE
Symposium on Foundorionr of Computer Science (FOCS’881,
October 1988, pp. 162-173.
[I91 K. Motwani and P. Raghavan, Randomized Algorithms. Canbridge University Press, 1995.
[20] S. lukna, Errrema1 Combimilorics. Springer-Verlaz, hc.,2001.

-.

OpenFlow versus Commercial Load Balancers
in a Campus Network
(Invited Paper)
Ashkan Ghaffarinejad and Violet R. Syrotiuk
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University, Tempe, Arizona, U.S.A. 85281-8809
e-mail: {ashkan,syrotiuk}@asu.edu

Abstract—The production network at Arizona State University
uses a commercial load balancer for syslog messages from the
firewalls at the data center perimeter. The logs are carried in UDP
packets and the load balancer divides the load among servers
based on the source IP address. This may cause a server to be
overwhelmed due to the high incoming data rate, and create log
files unequal in size. These logs are processed by splunk, an
application for analyzing the massive streams of data generated
by IT systems. In a testbed with an OpenFlow switch and three
rsyslog servers, fed by a mirror of the firewall syslog traffic,
we study controllers implementing round-robin, random, and
load-based load balancing policies. All policies achieve delivery
ratios comparable with the commercial load balancer. When
servers fail or go down for maintenance, the load-based policy
produces log files the most balanced in size. The results suggest
that an OpenFlow load balancer has performance competitive
with a commercial load balancer, and can equalize the log file
size at servers which improves the efficiency of splunk.

I. I NTRODUCTION
Today, commercial load balancers are often in use in
enterprise networks. For example, the production network
at Arizona State University (ASU) uses a Citrix NetScaler
[1] load balancer. This load balancer processes standardized
syslog [2] messages that come from Palo Alto Networks
firewalls [3] located at the perimeter of the data center.
The syslog messages record the status of the network and
include information such as device failures, security threats,
performance, and the state of network connections.
The syslog messages are carried in UDP packets and the
NetScaler divides the load among rsyslog servers based on
the source IP address. This may cause anrsyslog server to
be overwhelmed due to the high incoming data rate, which is
on the order of hundreds of megabits per second, and the log
files to be unequal in size. These server logs are processed
by splunk [4], an application for searching, analyzing, and
visualizing the massive streams of data generated by IT
systems and technology infrastructure.
Load balancing in enterprise networks is one potential
application of OpenFlow. The University Technology Office
(UTO) at ASU was interested in whether a software defined
networking (SDN) based load balancing solution would be
competitive with the commercial load balancer in the campus network. A testbed with an OpenFlow switch and three
rsyslog servers, fed by a mirror of the firewall syslog

traffic was set up.1 Two performance metrics were identified:
The data delivery ratio, computed by dividing number of
syslog messages stored on the testbed rsyslog servers by
the number of syslog messages stored on ASU’s rsyslog
servers, indicates the reliability of the SDN-based solution.
The split ratio, computed by dividing the smallest log file size
by the largest one stored on the testbed, indicates the extent
to which a load balancer can equalize the log file size among
servers; this improves the efficiency of splunk processing.
Some existing SDN-based load balancers are similar to
the commercial solution in that they divide incoming load
based on source IP address [5], [6]. Plug’n Serve addresses
the question of whether it is possible to devise a general
load balancing solution for unstructured networks [7]. Aster*x
advances Plug’n Serve by performing load balancing on a
larger scale network, in particular, over a wide area network
(WAN) [8]. From these solutions we make use the idea of
having one alias IP address to refer to a server pool and locate
an OpenFlow controller in front of the server pool to act as a
proxy, and select the server to receive the load.
We study three controllers implementing round-robin, random, and load-based load balancing policies. The round robin
policy cyclically rotates through the rsyslog servers. The
random policy selects an rsyslog server at random. The
load-based policy selects a server based on the number of
bytes the switch has sent out on each port; the server that
has received the fewest bytes is selected. Each policy was
evaluated over two five day periods: one in which no servers
failed, and another in which server failures were induced.
All three policies achieved average delivery ratios over 99%
comparable with the commercial load balancer in both periods.
When servers fail or go down for maintenance, the load-based
policy produces the highest split ratio. The results suggest that
OpenFlow load balancers have performance competitive with
a commercial load balancer, and can equalize the log file sizes
to the benefit of an application such as splunk.
The rest of this paper is organized as follows. In §II we
describe the testbed set-up and controller design. §III describes
the experiments conducted, the data collected, and an analysis
of the results. We conclude and propose future work in §IV.
1 Permission for this traffic mirror was granted by the Research Administration Office of the Arizona Board of Regents for, and on behalf of, ASU.

978-1-4799-8091-8/15/$31.00 ©2015 IEEE

II. T ESTBED A RCHITECTURE
A. The Testbed
Figure 1 shows a representation of the testbed. It includes
a physical Dell server with 32 GB of RAM and 32 Intel
Xeon E5-2640 v2 processors, each running at 2.00 GHz.
Citrix XenServer [9], version 6.2, is installed on the Dell
and used for server virtualization. Open vSwitch (OVS) [10],
a virtual switch that implements standard management interfaces and protocols including OpenFlow, is installed on the
XenServer. Four virtual machines (VMs) are also installed on
the XenServer, with each allocated 4 Xeon CPUs. The first
VM is allocated 4 GB of RAM and is configured to run a
controller. The other three VMs are each allocated 8 GB of
RAM and are set up as rsyslog servers. Our virtual switch
is connected to the controller and the three other VMs.

C. Configuring the Testbed
The XenServer manages four network interfaces on the
Dell server, eth0, . . ., eth3, through OVS. Four bridges,
xenbr0, . . ., xenbr3, are created and a one-to-one mapping between each interface and bridge established.
Three networks are configured: one for data, one for
management, and one for probing. The data network is for
processing the syslog packets forwarded by the Palo Altos
via eth0. The management network allows access to the
XenServer via eth1 using Citrix XenCenter [12] to remotely
to set up the VMs, configure their attributes, and control them.
We use it to set up the VMs running the rsyslog servers so
that they can interact using a controller by adding their virtual
interfaces to xenbr0. The probing network is an OpenFlow
disabled network connected via xenbr3; see Figure 2. As
we will see in §II-D, the controller in the load-based load
balancing policy uses this network to probe statistics of each
of the rsyslog servers.

Fig. 2: The probing network.
Finally, we must configure xenbr0 on OVS to connect
it to the controller. The controller must communicate with a
switch on a non-OpenFlow network. Therefore, we configure
the VM1 networking interface to have a different network
address than the data network. For additional details on the
testbed configuration, including the configuration file format,
see [13].

Fig. 1: The testbed topology.

B. The Data Feed
The testbed is fed by a mirror of the traffic output by the
Palo Alto firewalls. The firewalls at ASU use the UDP protocol
[11] to transmit data in syslog format [2]. However, the path
from the Palo Altos through the data center to the testbed,
and to ASU’s production rsyslog servers, is not the same.
Because UDP is unreliable, and the paths are different, there
is no guarantee that each set of rsyslog servers receive
identical traffic. This explains why, as we will see in §III,
the delivery ratio is over 100% on occasion.

D. Controller Design
The controller is responsible for making all the forwarding
decisions in our data network. We develop three load balancing
policies: round robin, random, and load-based. We develop our
controllers using OpenDaylight [14]. The bundle runs in two
modes: initialization and post-initialization. In initialization
mode, all packets except TCP and UDP packets are broadcast.
In addition, ARP packets are processed to learn the network
topology, server MAC addresses, and port correspondence.
Once this information is known, the bundle transitions to its
post-initialization mode. In this mode, the controller stops
broadcasting all packets except ARP packets, and only handles
UDP packets destined for our alias rsyslog IP address.
We first probe port 514 (default port to receive syslog
messages) using TCP on all servers. If a server sends the SYNACK in response to our SYN it is up. Each policy only selects

from active servers. (A server can be selected repeatedly only
a bounded number of times to prevent overwhelming it.) In
addition, the load-based policy uses statistics on the number
of bytes the switch has sent out on each port. To obtain such
statistics we query the OpenDaylight controller on port 8080,
where it runs a web server for this purpose.
In order to create a matching rule, we match a packet based
on following fields: EtherType, network protocol, network
destination address, and destination port address. EtherType
is a two-byte field that shows which protocol is encapsulated
inside an Ethernet frame. For those packets going to the
rsyslog server this value is 0x0800 which indicates that
the Ethernet frame contains an IPv4 payload. The network
protocol is a one byte field indicating the protocol encapsulated
in the IPv4 frame. If this field is equal to 17, the IPv4
packet encapsulates a UDP packet. The network destination
address is the destination IP address which is represented as
an integer. The packets that we are interested in forwarding
have a destination IP address set to the alias rsyslog server.
The destination port address is represented in a short type,
indicating the destination port where packets are destined. By
default, rsyslog listens on port 514.
We now make a list of actions to be taken on the packets
that have the same fields as our match. These actions are to
rewrite the destination MAC address of the packet with the
destination MAC address of the selected server, rewrite the
destination IP address of the packet with the destination IP
address of the selected server, and to forward this packet on
the outgoing port that reaches the selected server.
Now we write this flow on the switch. A hard timeout
defines the expiration time of the flow after the flow is
installed. The hard timeout is set by the user in a configuration
file placed on the controller (we used 8 seconds).
We must also forward the current packet to the selected
server as otherwise we lose packets forwarded to the controller.
Before doing so we must rewrite the checksum in the UDP
packet to reflect the IP address of the selected server [11].
Periodically, the current flow is updated proactively in order
not to lose packets due to the high incoming data rate. The
period is relative to the hard timeout for the flow.

Therefore we perform the same filtering before counting the
number of lines in the log files on the testbed rsyslog
servers.
The columns in Tables I, II, and III give the date of the
experiment, the total number t of syslog messages in the
log files of the testbed rsyslog servers at the end of the
day, the same number s but in ASU’s splunk database at
the end of the day, the difference between them (s − t), and
the delivery ratio ( st ), for the round-robin, random, and loadbased load balancing policies, respectively.
1) Round-Robin Policy: While the difference in line count
in Table I is several hundred thousand, the data delivery ratio
for the round-robin policy when no servers fail is still over
99%. When servers fail, the difference in line count varies
more widely, from tens of thousands to millions. Nevertheless,
average delivery ratio over this period is still over 99%. (On
12/21/2014 the testbed received more messages than splunk
indexed; see §II-B.)
TABLE I: Round-robin policy.
Date
11/24/2014
11/25/2014
11/26/2014
11/27/2014
11/28/2014

Testbed
192664117
193478076
173037862
145913198
154588059

12/18/2014
12/19/2014
12/20/2014
12/21/2014
12/22/2014

61450166
46629441
35155013
40500742
50886551

A. Reliability: Data Delivery Results
To evaluate the reliability of the SDN-based load balancing
policies we use the data delivery ratio. This is the ratio of
line count of the log files stored on the testbed rsyslog
servers, and the line count of syslog messages that splunk
indexes in its database. Line count is accurate because each
line in a log file corresponds to a syslog message as defined
by the standard [2]. However, ASU performs filtering based
on IP addresses before indexing into the splunk database.

Delivery ratio
0.9974
0.9948
0.9978
0.9980
0.9962
0.9915
0.8489
0.9983
1.1528
0.9699

2) Random Policy: Table II shows that the random policy
performs very well with no server failures, having an average
delivery ratio of over 99%. However, the variance in the line
count difference is higher than the round-robin policy for this
case. Interestingly, the random policy performed very well
with server failures (see Table II), with an average delivery
ratio of over 100%; see §II-B. However, in all cases, the line
count differences are in the millions.
TABLE II: Random policy.

III. E VALUATION OF SDN L OAD -BALANCING P OLICIES
We set up two experiments running each policy for five
consecutive days (24 hours). In the first experiment there are
no server failures. In the second, we introduce server failures
at random for an average of two hours on each day.

No server failures
splunk
Difference
193157905
493788
194470616
992540
173405381
367519
146199972
286774
155168922
580863
Server failures
61974048
523882
54922906
8293465
35214334
59321
35132478
-5368264
52465403
1578852

Date
12/01/2014
12/02/2014
12/03/2014
12/04/2014
12/05/2014

Testbed
216021445
220307032
213855086
217260686
189661407

01/05/2015
01/06/2015
01/07/2015
01/08/2015
01/09/2015

73188622
74993873
70052433
77290725
110467859

No server failures
splunk
Difference
216497873
476428
221506328
1199296
214371744
516658
218149382
888696
189555048
-106359
Server failures
68323257
-4865365
70059638
-4934235
75863551
5811118
69014981
-8275744
106417245
-4050614

Delivery ratio
0.9977
0.9945
0.9975
0.9959
1.0005
1.0712
1.0704
0.9234
1.1199
1.0380

3) Load-based Policy: The load-based policy also has an
excellent delivery ratio, over 100% in both experiments (see
Table III). It is somewhat surprising that the line count

difference for the load-based policy are higher than for the
round-robin policy for both experiments.
TABLE III: Load-based policy.
Date
12/25/2014
12/26/2014
12/27/2014
12/28/2014
12/29/2014

Testbed
37444009
41644757
39752694
56260329
56928490

12/31/2014
01/01/2015
01/02/2015
01/03/2015
01/04/2015

48887055
46580918
51567124
47356854
47786448

No server failures
splunk
Difference
37101507
-342502
37871078
-3773679
41029295
1276601
51003489
-5256840
58358202
1429712
Server failures
50388054
1500999
45021297
-1559621
53219385
1652261
45434582
-1922272
47741711
-44737

Delivery ratio
1.0092
1.0996
0.9688
1.1030
0.9755
0.9702
1.0346
0.9689
1.0423
1.0009

4) Delivery Ratio Summary: In summary, all of the SDNbased load balancing policies have delivery ratios higher than
99% even when servers may fail. All are competitive with the
commercial load balancer.
B. Load Balancing Results
We use the split ratio as an indicator of how well each policy
distributed the load — here syslog messages — among the
rsyslog servers on a daily basis. (rsyslog can separate
incoming logs based on the server’s local time. At ASU,
rsyslog is configured to splits the logs on a day to day
basis.) We measure this ratio in bytes because when we probe
the switch for statistics, it returns the number of bytes the
switch has sent out each port (and hence to the corresponding
server). We were not able to measure this metric on ASU’s
production network, hence we only compare the three load
balancing policies in two experiments, each for five days: one
with no server failures, and one with server failures.
1) No Server Failures: Table IV shows the log file size
for each rsyslog server at the end of the day, for each
day of the experiment, and for each load balancing policy.
The round-robin policy has the highest average split ratio of
99%, followed closely by the load-based policy at 98%, and
then the random policy at 96%. It is expected that the roundrobin and load-based policies should equalize the files sizes
the best; perhaps the difference is due to variations in the size
of syslog messages.
2) Server Failures: We simulate the condition of rsyslog
servers failing by shutting them down using the XenCenter.
The number of servers to fail (one or two) is selected at
random as is the time of failure. On average we lost one server
a day for about two hours.
Figures 3a, 4a, and 5a plot the log file size in GB on the
rsyslog servers immediately after the servers are brought
back up for the round-robin, random, and load-based policy,
respectively, for each day of the experiment. Figures 3b, 4b,
and 5b plot the size of the same log files in GB at the end
of the day, i.e., midnight. (Table V summarizes the results at
the end of the day for each load balancing policy.) This gives
some idea of how well each policy is able to equalize the log
file sizes after the servers recover.

TABLE IV: End of day syslog file sizes, no server failures.

Date
11/24/2014
11/25/2014
11/26/2014
11/27/2014
11/28/2014
12/01/2014
12/02/2014
12/03/2014
12/04/2014
12/05/2014
12/25/2014
12/26/2014
12/27/2014
12/28/2014
12/29/2014

Round-robin policy
Server 1
Server 2
Server 3
25.38 GB
25.13 GB
25.15 GB
25.26 GB
25.06 GB
25.03 GB
22.63 GB
22.45 GB
22.51 GB
19.42 GB
19.26 GB
19.32 GB
20.85 GB
20.62 GB
20.68 GB
Random policy
28.19 GB
28.19 GB
28.04 GB
28.91 GB
29.24 GB
28.73 GB
28.54 GB
27.51 GB
27.96 GB
29.24 GB
27.73 GB
27.84 GB
24.78 GB
24.98 GB
23.94 GB
Load-based policy
33.70 GB
33.07 GB
33.03 GB
24.76 GB
24.39 GB
24.38 GB
31.49 GB
30.95 GB
30.97 GB
39.81 GB
39.03 GB
39.18 GB
38.22 GB
37.48 GB
37.34 GB

Split ratio
0.9899
0.9907
0.9918
0.9917
0.9889
0.9945
0.9826
0.9641
0.9483
0.9583
0.9800
0.9846
0.9829
0.9802
0.9767

In comparing Figures 3a and 3b, we see that the round-robin
policy does not close the gap created due to server failure; the
histogram pattern does not change on any day. The smallest
and the largest split ratios are 75% and 90%, respectively, with
an average of 82%.

(a) After server recovery

(b) End of day

Fig. 3: Log file sizes for round-robin policy.
The split ratio for the random load balancing policy ranges
from a low of 80% to a high of 97%, with an average of
88% (all higher than the round-robin policy). In examining
Figures 4a and 4b, after the server recovers, in some cases
histogram pattern for the day is the same, but on other days
(notably, the last two days of the experiment) the histogram
pattern changes. That is, in some cases, the random policy is
able to close the gap between the log file size of the rsyslog
server that went down with those that did not fail.
The size of the log files for the load-based policy in
Figure 5b are striking when compared the state of the log files
immediately following server recovery; it clearly shows that
the load-based policy is able to best equalize the split ratio of
all the load balancing policies implemented. Specifically, the
split ratio ranges from 97% to 98%, with an average of almost
98%. Even though the number of times a server can be selected
consecutively is bounded (a parameter in the configuration file;
we used a value of 3), the load-based policy is able to close
the gap between the log file at the server that failed.

(a) After server recovery

(b) End of day

Fig. 4: Log file sizes for random policy.

(a) After server recovery

(b) End of day

Fig. 5: Log file sizes for load-based policy.

3) Split Ratio Summary: When the rsyslog servers do
not fail, the split ratio of load balancing policies are almost
indistinguishable. However the situation is different when
servers fail. The round-robin policy is oblivious to the failure
and does not act to improve the split ratio when the server
returns to service. While the random policy does, in some
cases, achieve a higher split ratio than the round-robin policy,
it is not suitable when servers fail simply because the results
are not predictable. The load-based policy shines when servers
fail, and is able to achieve a remarkably high split ratio. We
conclude that the load-based policy is the most appropriate for
a network where servers may fail.
TABLE V: End of day syslog file sizes with server failures.

Date
12/18/2014
12/19/2014
12/20/2014
12/21/2014
12/22/2014
01/05/2015
01/06/2015
01/07/2015
01/08/2015
01/09/2015
12/31/2014
01/01/2015
01/02/2015
01/03/2015
01/04/2015

Round-robin policy
Server 1
Server 2
Server 3
30.23 GB
26.68 GB
30.02 GB
21.82 GB
25.98 GB
25.94 GB
25.57 GB
19.54 GB
25.04 GB
32.50 GB
35.95 GB
35.71 GB
34.47 GB
26.12 GB
33.87 GB
Random policy
39.07 GB
45.23 GB
45.18 GB
43.16 GB
34.70 GB
41.95 GB
25.40 GB
28.57 GB
28.59 GB
34.98 GB
37.37 GB
32.44 GB
36.96 GB
35.89 GB
36.03 GB
Load-based policy
29.00 GB
28.48 GB
28.60 GB
35.55 GB
34.92 GB
34.52 GB
28.47 GB
28.02 GB
27.96 GB
22.04 GB
21.64 GB
21.67 GB
31.07 GB
30.48 GB
30.48 GB

Split ratio
0.8826
0.8400
0.7642
0.9042
0.7578
0.8639
0.8040
0.8885
0.8682
0.9708
0.9822
0.9708
0.9821
0.9817
0.9810

IV. C ONCLUSIONS AND F UTURE W ORK
In this paper, we compared the performance of a transportlevel commercial load balancer to that of an SDN load
balancing solution over UDP packets. We implemented three
load balancing policies in OpenFlow controllers and evaluated
them in experiments in a physical testbed with a data feed
from our campus production network. The results of these
experiments suggest that the data delivery ratios of the SDN
load balancing policies are as good as the commercial solution,
and hence could be used in a real production network with an
input data rate of 100s of Mbps even when servers can fail.
Because our servers store syslog messages processed by
the splunk application, we were interested to equalize the
log file sizes on each server. While the round-robin policy
had a slight edge over other policies when servers did not
fail, the results were quite different when failures occurred.
Specifically, only the load-based policy had the potential to
equalize log file sizes after server failures.
Future work could use an OpenFlow enabled hardware
switch to perform the load balancing. This should only improve our results, which already suggest that an SDN-based
load balancing solution is competitive with a commercial
load balancer, because switching rates are faster on physical
hardware and would allow us to handle input at an even faster
data rate.
ACKNOWLEDGMENTS
Thanks to Jay Steed for supporting this project, Jack Hsu for
defining the problem, Pat Schneider for managing the project,
and Chris Kurts, ASU’s “Splunk Guy,” for answering endless
questions.
R EFERENCES
[1] Citrix
NetScaler,
http://www.citrix.com/products/
netscaler-application-delivery-controller/overview.html.
[2] R. Gerhards, “The syslog protocol,” Internet Request for Comments,
Internet Engineering Task Force, RFC 5424, March 2009. [Online].
Available: https://tools.ietf.org/html/rfc5424
[3] Palo Alto Networks, https://www.paloaltonetworks.com/.
[4] Splunk, http://www.splunk.com/resources.
[5] H. Uppal and D. Brandon, “OpenFlow based load balancing,”
2010. [Online]. Available: http://courses.cs.washington.edu/courses/
cse561/10sp/project files/cse561 openflow project report
[6] R. Wang, D. Butnariu, and J. Rexford, “OpenFlow-based server load
balancing gone wild,” in Proceedings of USENIX, 2011.
[7] N. Handigol, S. Seetharaman, M. Flajslik, N. McKeown, and R. Johari,
“Plug-n-serve: Load-balancing web traffic using OpenFlow,” SIGCOMM
Demonstration, 2009.
[8] N. Handigol, M. Flajslik, S. Seetharaman, N. McKeown, and R. Johari,
“Aster*x: Load-balancing as a network primitive,” in Architectural
Concerns in Large Datacenters (ACLD’10), 2010.
[9] Citrix XenServer, http://www.xenserver.org.
[10] Open vSwitch, http://www.openvswitch.org.
[11] J. Postel, “User datagram protocol,” Internet Request for Comments,
Internet Engineering Task Force, RFC 768, August 1980. [Online].
Available: https://tools.ietf.org/html/rfc768
[12] Citrix
XenCenter,
http://xenserver.org/
open-source-virtualization-download.html.
[13] A. Ghaffarinejad, “Comparing a commercial and an SDN-based load
balancer in a campus network,” Master’s thesis, Arizona State University,
2015.
[14] The
Linux
Foundation,
“OpenDaylight
Controller,”
http://www.opendaylight.org/announcements/2013/04/
industry-leaders-collaborate-opendaylight-project-donate-key-technologies.

Adaptive Overhead Reduction via MEWMA Control Charts
Kahkashan Shaukat, Douglas C. Montgomery, and Violet R. Syrotiuk
CIDSE, Arizona State University, Tempe, AZ

85287-8809

{kshaukat,doug.montgomery,syrotiuk}@asu.edu

ABSTRACT

Link-state routing protocols have also been developed for
mobile ad hoc networks (MANETs). A MANET is a collection of mobile wireless nodes that self-organize with no
centralized control or fixed infrastructure. The OLSR, or
optimized link-state routing protocol [1] uses multi-point relay (MPR) sets to implement the broadcast efficiently. An
MPR set for a node is a subset of its one-hop neighbours
that reaches all its two-hop neighbours.
MPRs are selected through the exchange of HELLO messages, which provide each node a view of its two-hop neighbourhood. MPRs also forward topology control (TC) messages; these provide each node with sufficient topology information to compute shortest path routes to all destinations.
OLSR is proactive, transmitting control information periodically. Because it is unlikely that the network conditions
are identical at every node, it is unnecessary for each node to
use the same period of transmission. A large period results
in a poor packet delivery ratio; a large number of packets are
dropped due to out-of-date routes. A small period transmits
too frequently consuming bandwidth that can otherwise be
used for data. Instead, the transmission of a control message should depend on the network conditions experienced
at a node. When conditions change rapidly more frequent
transmission may be necessary; when they change slowly less
frequent transmissions may suffice.
In this paper, we explore such an adaptive approach for
the transmission of control information with the goal of reducing overhead of the protocol. Statistical process control
(SPC) is used to monitor a characteristic so that corrective
measures can be taken when performance degrades. Most
often process performance depends on multiple characteristics. A MANET may be viewed as a process and we measure
its performance by the packet delivery ratio.
To monitor small shifts in one or more characteristics, exponentially weighted moving average (EWMA) or multivariate EWMA (MEWMA) charts are used [2]. These charts
work well when the monitored characteristics are independently distributed; otherwise they may generate too many
false alarms. To effectively use the control charts, autocorrelation is removed using time series analysis (TSA) [3].
We propose Time Series OLSR (TS-OLSR) to jointly monitor the number of edges in the two-hop neighbourhood and
topological graphs at each node. An MEWMA control chart
is used to decide when to transmit the corresponding HELLO
and TC messages. An inherent difficulty with MEWMA
charts is how to interpret an out-of-control signal because an
MEWMA may generate a signal even when the individual

In an effort to reduce overhead in proactive protocols, rather
than use a global period for transmission of control information, we propose to transmit based on changes in a node’s
local conditions. For OLSR, a proactive link-state routing protocol, we use a significant change in the number of
edges in a node’s two-hop neighbourhood and topological
graph as indicators of topology change warranting an update. When the associated exponentially weighted moving
average (EWMA) charts and multivariate EWMA chart signal out-of-control, a node transmits a HELLO, a topology
control (TC), or both HELLO and TC messages. We use ns2 simulations to compare OLSR to our TS-OLSR, and other
variants of OLSR. We find that TS-OLSR obtains a statistically significant reduction in overhead compared to the other
protocols while maintaining the packet delivery ratio. The
approach is general and may find use in other applications
requiring response to changes in local conditions.

Categories and Subject Descriptors
C.2.2 [Network Protocols]: Routing Protocols.

General Terms
Performance, Measurement, Experimentation.

Keywords
Control overhead, statistical process control, EWMA charts.

1.

INTRODUCTION

Most protocols for computer networks incur control overhead in their operation. This includes negotiation, such as a
handshake in IEEE 802.11 to arbitrate access to the medium,
for channel or rate selection, among others. It also includes
the distribution of information, such as the broadcast of linkstate in the Internet’s OSPF routing protocol.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
MSWiM’11, October 31–November 4, 2011, Miami, FL, USA.
Copyright 2011 ACM 978-1-4503-0898-4/11/10 ...$10.00.

205

EWMA charts do not. Therefore individual EWMA charts
are also used.
ns-2 simulations are conducted to compare the performance of TS-OLSR to OLSR [1], and other variants that
seek to reduce control overhead including A-OLSR [4] and
Adaptive OLSR [5]. TS-OLSR obtains a statistically significant reduction in control overhead compared to the other
protocols. It transmits 29.55–54.80% less control overhead
compared to OLSR.
The sequel is organized as follows. §2 summarizes previous work on reducing control overhead in OLSR, and defines EWMA and MEWMA charts for statistical process
control. §3 provides an overview of ARIMA models using
the Box-Jenkins method while §4 describes the construction
of ARIMA models in TS-OLSR. §5 presents the simulation
results. Conclusions and future directions are in §6.

2.

eters λ and K can be tuned to achieve a specific in-control
average run length (ARL) [9,10]. When the monitored characteristic falls between the control region bounded by the
CLs, the process is in-control. Otherwise it is out-of-control
and corrective measures are required.
A multivariate EWMA (MEWMA) chart [11] is an extension of the EWMA chart and defines vectors of EWMAs.
The design of MEWMA charts is a generalization of the
approach to design EWMA charts [9, 10].

3. MODEL BUILDING METHODOLOGY
One assumption underlying control chart use is that the
observations are independent. The charts are not effective if
the monitored characteristic exhibits even low levels of correlation. They may signal too many false alarms if the data
are positively correlated; they may not signal at all if the
data are negatively correlated. We therefore first describe
the methodology for removing correlation in modelling.

RELATED WORK

3.1 Definitions

2.1 Reducing Control Overhead in OLSR
Several ideas to reduce control overhead in OLSR have
been proposed. In Clustered OLSR (C-OLSR) [6], overhead
is reduced by partitioning the network into clusters and restricting the propagation of TC messages to a cluster. MPRs
at the cluster level generate and forward inter-cluster topology information. In Hierarchical OLSR (HOLSR) [7], nodes
use a “fisheye” technique where TC messages from nodes
further away are received at larger intervals.
Some approaches to reduce overhead in OLSR incorporate
the use of local conditions. In the Fast-OLSR protocol [8], a
node switches from default to fast-OLSR mode when changes
in its neighbourhood exceed a threshold. Fast-OLSR nodes
send Fast-HELLO messages at a higher frequency to help
maintain network connectivity. Adaptive OLSR [5] extends
Fast-OLSR by the addition of a fast-response mode. A node
switches from default to fast-response mode on the receipt of
a Fast-HELLO message; Fast-response nodes also send FastHELLO messages. Generally, a fast-OSLR or default node is
not selected as an MPR. A fast-OLSR node restricts the size
of its MPR set to two. Adaptive OLSR (A-OLSR) [4] takes
a different approach; it monitors betweenness (a centrality
measure) of the two-hop neighbourhood of a node using a
Shewhart control chart. An out-of-control signal reflects a
change in the topology causing a TC message to be sent.

3.1.1 Autocorrelation Function (ACF)
Given a series x1 , x2 , . . . , xn , the autocorrelation between
observations k intervals apart is measured by the lag k sample autocorrelation coefficient (k < n) [3]:
Pn−k
i=1 (xi − x̄)(xi+k − x̄)
; r0 = 1.
(2)
rk =
Pn
2
i=1 (xi − x̄)

Here, xi and xi+k are the observations at time i and i + k,
and x̄ is the mean of the n values. The autocorrelation
coefficients are plotted against the lags. If more than 5%
of them fall outside the 95% confidence interval, the data is
serially correlated, and the correlation needs to be removed.

3.1.2 Partial Autocorrelation Function (PACF)
The partial autocorrelation function, φkk for a stationary
process is defined as a function of the autocorrelations rk of
the process [3] and has the distinctive feature that φkk = 0
for k > p in an autoregressive process of order p. φkj denotes
the jth coefficient in an autoregressive process of order k, so
that φkk is the last coefficient in
φk1 rj−1 + φk2 rj−2 + . . . + φkk rj−k = rj .

3.2 ARIMA Models

2.2 Statistical Process Control

A general autoregressive integrated moving average model
of order (p, d, q), or ARIM A(p, d, q), has three parts: the autoregressive (AR), integrated (I), and moving average (MA)
models. The order of the model specifies how far back in
time to look. The integrated model is used when the series
is non-stationary, i.e, it has no constant mean or standard
deviation. The ACF and PACF are used in conjunction with
the time series to find the order of the autoregressive and
moving average models. The objective is to find a model
that adequately describes the time series yet contains relatively few parameters [3].
An ARIM A(p, d, q) is given by Φp (B)∇d xt = Θq (B)ǫt .
Here, Φp (B), ∇d , and Θq (B) is the AR, I, and MA model,
respectively; B is the backward shift operator defined as
Bxt = xt−1 .
Φp (B), an autoregressive model of order p, is given by:

Statistical process control (SPC) is a collection of statistical techniques to monitor the performance of a process to
determine if it has shifted away from some nominal operating state (the in-control state).
Control charts are the basic tools used in monitoring. To
detect small deviations from the in-control state, an exponentially weighted moving average (EWMA) control chart is
used. An EWMA chart is defined as:
zt

=

CL

=

λxt + (1 − λ)zt−1 , where z0 = 0
r
λ σ0
√
µ0 ± K
2−λ n

(3)

(1)

where xt is the characteristic being monitored, 0 < λ ≤ 1 is
a smoothing constant, and n is the number of samples. The
computation of the upper and lower control limit (CL) use µ0
and σ0 , the mean and standard deviation of xt . The param-

xt = ξ + φ1 xt−1 + φ2 xt−2 + . . . + φp xt−p + ǫt .

206

(4)

The current observation xt is regressed on p previous observations of the time series with coefficients φ1 , φ2 . . . , φp . ξ
is a constant coefficient, and ǫt is a random error at time t.
Using the backward shift operator, Eqn. (4) can be written
as Φp (B)xt = ξ + ǫt .
Θq (B), a moving average model of order q, is given by:
xt = µ + ǫt − θ1 ǫt−1 − θ2 ǫt−2 − . . . − θq ǫt−q .

We start by studying two time series at each node. The
first series, computed every HELLO INTERVAL (2 s), is the
number of edges in a node’s two-hop neighbourhood graph.
The second series is the number of edges in the topological
graph derived from a node’s routing table, computed every
TC INTERVAL (4 s instead of the default 5 s so that the
characteristics coincide more often). Each routing table entry at node i is a tuple (d, j) specifying the next-hop neighbour j to forward the packet to reach destination d. The
topological graph contains the edges (i, j), and edge (j, d)
indicating that d is reachable through j for the entry.
We divide the model building process into an off-line part
to obtain an initial ARIMA model, and an online part to
tune the model. Once tuned, the models may be used to
control the transmission of HELLO and TC messages.

(5)

Similarly, using the backward shift operator, Eqn. (5) can
be written as xt = µ + Θq (B)ǫt .
∇d is the dth difference, i.e., taking d successive differences
of the characteristic being modelled. The first difference
(∇1 ) is ∇xt = xt − xt−1 , the second difference is ∇2 xt =
xt − 2xt−1 + xt−2 , and so on.
Once the order (p, d, q) of the ARIM A model is identified,
and model checking finds the model adequate, the residuals
obtained after fitting the model are independent and random. The residuals may then be used with SPC techniques
to monitor the process.

4.1 Off-line Model Building
Off-line model building is used to determine an adequate
model and to remove non-stationarity and serial correlation.
We proceed using the Box-Jenkins method. Simulations of
OLSR are carried out in ns-2 [14] using the parameters in
Table 3. Figure 1 shows a representative time series for the
number of links in the two-hop neighbourhood and topological graphs of a node moving 2 m/s.
Both time series are non-stationary; they show a large
number of successive increases and decreases. Figure 2 shows
the ACF for the two-hop neighbourhood and topological
links time series; values exceeding the 95 % confidence interval are enclosed in a dotted ellipse. Figure 2(a) decays
very slowly. Thus, the series is serially correlated and the
correlative structure needs to be removed. The differenced
series has a high standard deviation of 12.29 (see Figure
3(a)). The corresponding ACF in Figure 3(b) tails-off and
then becomes larger at higher lags. Thus, the correlative
structure needs to be removed further.
Figure 4(a) shows the second differenced time series for
the two-hop neighbourhood links and Figure 4(b) shows the
corresponding ACF. The standard deviation reduces to 8.32.
The third differencing increases the standard deviation to
15.97 so further differencing is not necessary. The ACF in
Figure 4(b) tails-off after lag two, indicating an autoregressive model of order 2. To decide the order of the autoregressive moving average model, the PACF of the second difference of two-hop neighbourhood links is studied.
A similar study of the successive differences of the topological links shows that a single differencing provides a stationary series; the ACF cuts-off at lag one (see Figure 5).
The partial autocorrelation functions for the second difference of two-hop neighbourhood links and first difference
of topological links is given in Figures 6(a) and (b), respectively. Considering the value at lag 4 as an outlier, the PACF
for two-hop neighbourhood links cuts-off after lag 1 while
the PACF for topological links tails-off. Thus, the ARIMA
model for two-hop neighbourhood links has no moving average part whereas the ARIMA model for the topological
links has a moving average part of order 1.
To summarize, for the two-hop neighbourhood links, second differencing achieves stationarity; the I part of the ARIMA
has order 2. The ACF tails-off after lag 2 indicating an AR
part of order 2. But, the PACF cuts-off after lag 1 which
means that the ARIMA has no MA part; the order of the AR
part is 1 (see Table 1). The ARIMA model for the two-hop
neighbourhood links is of order (1,2,0). Single differencing

3.3 The Box-Jenkins Method
The Box-Jenkins method [3] is a modelling technique for
time series; the output of the obtained model may be used
in monitoring. Finding an adequate ARIMA model using
the Box-Jenkins method is an iterative four step process: 1)
detect stationarity, 2) determine the order of the model, 3)
estimate parameters, and 4) check the model.
Stationarity can be assessed from a run sequence plot that
displays data in a time sequence. Long runs of increases and
decreases in the series indicate non-stationarity. To remove
non-stationarity, a new series comprised of differences from
the first series is computed. Successive differencing may be
required. ACF and PACF plots are also useful in eliminating
non-stationarity.
Once a stationary time series is obtained, the order of the
ARIM A(p, d, q) is determined. The ACF and PACF are
used to estimate the values of p and q. The ACF and PACF
are plotted to identify a tentative model by comparing the
observed patterns with known patterns [3] in Table 1.
Table 1: Behaviour for stationary models [12].
Model
ACF
PACF
AR(p)
Tails-off
Cuts-off after lag p
MA(q)
Cuts-off after lag q
Tails-off
ARMA(p,q)
Tails-off
Tails-off
Once the order of the ARIMA process is determined, estimation methods such as maximum likelihood or ordinary
least squares are used to estimate the model parameters. We
use Minitab [13] to estimate the models using ordinary least
squares estimation and also for model checking.
In case the model is not adequate, the method iterates. If
multiple models are built with similar adequacy, the model
with lower order is selected.

4.

ARIMA MODELS FOR OLSR

OLSR transmits overhead in the form of HELLO and TC
messages consisting of two-hop neighbourhood and topological information, respectively. Since our goal is to reduce the
control overhead in OLSR, we are interested to determine
when each of these message types need to be transmitted.

207

Figure 1: Time series of 2-hop neighbourhood and topological links of a representative node moving 2 m/s.

(a) Two-hop neighbourhood links

(b) Topological links

Figure 2: ACF of 2-hop neighbourhood and topological links of a representative node moving 2 m/s; the
dotted ellipses show values exceeding the 95 % confidence interval.

(a) ACF of 2-hop neighbourhood links

(b) ACF of topological links

Figure 3: ∇1 and ACF of ∇1 of the 2-hop neighbourhood links of a representative node moving 2 m/s.

(a) ∇1 of 2-hop neighbourhood links

(b) ACF of ∇1 of 2-hop neighbourhood
links

Figure 4: ∇2 and ACF of = ∇2 of the 2-hop neighbourhood links of a representative node moving 2 m/s.

(a) ∇2 of 2-hop neighbourhood links

(b) ACF of ∇2 of 2-hop neighbourhood
links

208

Figure 5: ∇1 and ACF of ∇1 of the topological links of a representative node moving 2 m/s.

(a) ∇1 of topological links

(b) ACF of topological links

Figure 6: PACF of 2-hop neighbourhood and topological links of a representative node moving 2 m/s.

(a) PACF of 2-hop neighbourhood links

(b) PACF of topological links

obtains a stationary time series for the topological links; the
ACF cuts-off at lag 1, and the PACF tails-off. Thus, the
ARIMA model for the topological links is of order (0,1,1).
Minitab [13] is used to estimate the ξ and φ parameters
for the two-hop neighbourhood links, and the θ parameter
for the topological links. The ARIMA(1,2,0) model for the
two-hop neighbourhood links is xt = 0.079 + 1.457xt−1 +
0.086xt−2 −0.543xt−3 +ǫt , and the ARIMA(0,1,1) model for
the topological links is xt − xt−1 = 1.827 + ǫt − 0.037ǫt−1 .
The residuals, ACF and PACF of the residuals, normal
plot of residuals, and the fitted values versus residuals of
the ARIMA(1,2,0) are shown in Figure 7. The residuals in
Figure 7(a) look random, i.e., the serial correlation has been
removed; since the ACF and PACF in Figures 7(b) and (c)
do not exceed the 95 % confidence interval, the residuals do
not show any correlation. The normal plot in Figure 7(c)
follows the normal curve closely, another indication that the
residuals are random. Even though the residuals versus the
fitted values in Figure 7(e) show high variance, the model
is acceptable. Similarly, the ARIMA(0,1,1) is an adequate
model for the topological links (figures not included).
The Ljung-Box test [15] is also performed on the residuals of the ARIMA(1,2,0) and ARIMA(0,1,1) models. The χ2
statistics together with the degrees of freedom and p-values
are presented in Table 2. For the ARIMA(1,2,0) model at
lag 12, the χ2 value is 2.8, and the corresponding p-value
of 0.904 indicates a 90.4% probability that the data is random; the model is adequate. The χ2 and p-values for the
ARIMA(0,1,1) model also indicate that it is adequate.
Simulation studies with node speeds 5, 10, 15 and 20 m/s
are also performed. Off-line modelling for each speed shows

Table 2: Ljung-Box statistics for selected models.
ARIMA(1,2,0)
Lag
12
24
36
48 8
χ2
2.8
10.9
22.1
29.0
Degrees of Freedom
9
21
33
45 5
p-Value
0.904 0.927 0.879 0.950
ARIMA(0,1,1)
Lag
12
24
36
48
χ2
3.7
8.1
16.2
21.3
Degrees of Freedom
9
21
33
45
p-Value
0.960 0.997 0.996 0.999

that second differencing and single differencing is required to
remove non-stationarity in the two-hop neighbourhood and
topological series, respectively. Off-line modelling for higher
speeds also shows that the order of the AR and MA models
may change though they never exceed two. In some cases,
both the ARIMA models have non-zero p and q values.

4.2 Online Model Building
gretl [16], a gnu open-source library, is used to perform
the time series analysis during online modelling. There are
six possible ARIMA models up to order 2 and each one is
built for each characteristic; the Ljung-Box statistics for 24
lags of each model is checked. The model that provides the
highest probability of the residuals being random is then
used in the simulation.
With serial dependence in the data removed, the residuals
are ready to be used with MEWMA and EWMA charts to

209

Figure 7: Time series plot of residuals, ACF and PACF of residuals, normal plot of residuals, and residuals
versus fitted values of 2-hop neighbourhood links of a representative node moving 2 m/s.

(a) Time series of residuals

(b) ACF

(d) Normal plot of residuals

(e) Residuals versus fitted values

the performance of TS-OLSR compared to OLSR, Adaptive
OLSR, and A-OLSR. Since gretl requires the sample size
to be at least 100 to perform the time series analysis, the
first 400 s of the simulation is used to collect the sample.
Data transmission starts at 400 s and continues to the end
of the simulation. The packet delivery ratio (PDR) and
total control overhead (CO), made up of TC and HELLO
messages, are measured during this time.

determine when to transmit control packets. The MEWMA
uses the average value of the two-hop neighbourhood links
collected in the last two time intervals as one of its control
characteristics; the other is the topological links. When the
MEWMA generates an out-of-control signal, both HELLO
and TC messages are transmitted. The simultaneous use
of EWMA charts together with the MEWMA chart is twofold: they help determine which characteristic generated the
signal, and generate network activity. In case the MEWMA
does not generate an out-of-control signal, the EWMA charts
help decide when to send appropriate control information.

Table 3: Simulation parameters.
Parameter
Values
Simulator
ns-2 version 2.29
OLSR implementation um-olsr-0.8.8
MAC protocol
IEEE 802.11b
Confidence interval
95%
Simulation area
1000 × 1000 m2
Nodes
50
Transmission range
250 m
Channel bandwidth
2 M bps
Simulation duration
800 s
Traffic type
Constant bit rate (CBR)
Packet arrival rate
10 pkts/s
Packet size
512 bytes
Mobility model
Stationary random waypoint
Node speed
2, 5, 10, 15, and 20 m/s
Number of flows
1, 2, 5 10
λ and r
0.05

4.2.1 Tuning EWMA and MEWMA parameters
In industrial processes, the in-control ARLs are large because false alarms are a major quality control issue; it requires stopping the process to take corrective action. In our
application, false alarms only generate the transmission of
control information. Indeed, to some extent false alarms are
beneficial because even when the system is in-control some
overhead is required to keep the routes up-to-date.
The values of K and h4 for the EWMA and MEWMA
chart, are tuned using the methodology in [9] and [17], respectively. Simulations are performed to find the in-control
ARL values for the EWMA and MEWMA charts when λ
and r equal 0.05. h4 = 0.93 corresponds to a MEWMA chart
with in-control ARL of 8, while K = 0.63 and K = 0.49 provide an in-control ARL of 8 and 5 for the two-hop neighbourhood and the topological links EWMA charts, respectively.

5.

(c) PACF

SIMULATION RESULTS

5.1 Simulation Set-up

5.2 Results

Simulations using the ns-2 network simulator [14] with
extensions for wireless mobility are performed to observe

An MEWMA chart using h4 = 0.93 and r = 0.05 to jointly
monitor the two-hop neighbourhood links and the topolog-

210

ical links is shown in Figure 8. When the Ti 2 values are
greater than 0.93 the MEWMA chart generates an out-ofcontrol signal. The signal implies that both the number of
two-hop neighbourhood and topological links has changed
such that corrective action is required. The corrective action is to transmit a HELLO and a TC message.

Table 4: Percentage difference between OLSR and
its variants for a single flow with 10 pkts/s arrival
rate for node speeds 2, 5, 10, 15, and 20 m/s.
Negative/positive values represent percentage decrease/increase.
OLSR
A-OLSR
Speed (m/s)
PDR
CO
PDR
CO
2
89.02
82090.90
+1.38 -27.75
5
68.85
88596.40
-1.15 -12.20
10
62.95
101679.40 +0.53 -22.48
15
48.83
112004.60
-1.80 -43.24
20
46.37
114815.80
-1.53 -47.67
Adaptive OLSR
TS-OLSR
Speed (m/s)
PDR
CO
PDR
CO
2
+0.75
-20.54
+1.51 -29.55
5
+3.37
-15.39
-0.29 -42.43
10
+7.17
-24.39
-1.92 -47.13
15
+14.20
-44.91
-1.30 -51.59
20
+13.04
-58.45
-2.06 -54.80

Figure 8: MEWMA: node speed 2 m/s, ARL = 8.

OLSR sends 36.95–43.37% less HELLO messages compared
to OLSR; the savings decrease with increase in speed.
Simulations with 2, 5, and 10 flows gave similar results
and are not provided here. An interesting aspect of the CO,
TC, and HELLO message plots (TC and HELLO message
plots not included here) for TS-OLSR is the flatness of the
curve. This is due to the fact that the serial correlation of
the data has been removed adequately and the usage of the
same in-control ARLs for all speeds. The A-OLSR EWMA
chart is tuned on node speed and Adaptive OLSR changes
its message transmission scheme based on mobility.

Because it is unclear which of the characteristics caused
the MEWMA chart to signal, EWMA charts are used for
this purpose. An EWMA chart for the residuals of the twohop neighbourhood and topological links is given in Figure 9.
When both the MEWMA and the EWMA charts signal at
the same time, only a message corresponding to the EWMA
chart is transmitted.
OLSR, Adaptive OLSR, A-OLSR, and TS-OLSR are simulated using the parameters in Table 3. The results are
presented in Figure 10 and Table 4. Figure 10(a) shows
the PDR; all three protocols perform better than OLSR at
speed 2 m/s. At higher speeds A-OLSR and TS-OLSR show
reduced performance by approximately 2%; the reduction is
not statistically significant. Adaptive OLSR shows an increase in PDR by 3.37–14.20% for higher speeds; its highest
achieved PDR is observed at 15 m/s speed.
Figure 10(b) shows the CO. TS-OLSR outperforms OLSR
by sending 29.55–54.80% less control overhead where the
savings increase as speed increases. A-OLSR shows a 12.20–
47.67% decrease in CO; its lowest savings occur at 5 m/s
which then increases as speed increases. Adaptive OLSR
shows a similar trend; its decrease ranges from 15.39–58.45%.
TS-OLSR outperforms all the other protocols up to speed
15 m/s; Adaptive OLSR has the highest CO reduction at
20 m/s but it achieves this reduction by restricting the size
of the MPR sets to two in Fast-OLSR mode.
Breaking out the total CO into TC and HELLO messages we find that TS-OLSR sends 27.25–56.83% fewer TC
messages than OLSR; while A-OLSR saves 14.07–48.29%.
Adaptive OLSR sends 24.74–82.74% fewer TC messages.
The large savings for Adaptive OLSR again comes from its
Fast-OLSR mode where it restricts its MPR set to two. The
trend is similar for these protocols to their corresponding
savings in CO.
Since A-OLSR uses betweenness to control the transmission of TC messages only, it has the same number of HELLO
messages as OLSR. Adaptive OLSR sends 4.69–155.3% more
HELLO messages compared to OLSR; the number of messages increase with speed. The number of HELLO messages
increase due to Adaptive OLSR’s sending Fast-HELLO messages at a higher frequency than the HELLO messages. TS-

6. CONCLUSIONS AND FUTURE WORK
Rather than transmitting HELLO and TC messages periodically as in OLSR, each node in TS-OLSR uses out-ofcontrol signals of the MEWMA and EWMA control charts
derived from the time series of the number of links in its twohop neighbourhood and topological graph to decide when to
transmit the corresponding control messages. By using control charts in this manner, TS-OLSR reduces control overhead by 29.55–54.80% compared to OLSR with an insignificant (0.29–2.06%) decrease in packet delivery ratio.
Adaptive OLSR saves slightly more control overhead than
TS-OLSR at 20 m/s; this may be attributed to Adaptive
OLSR restricting its MPR set to a size of two for higher mobility scenarios. Adaptive OLSR shows a significant increase
in packet delivery ratio but, unlike TS-OLSR, it changes the
protocol. This suggests that incorporating Fast-OLSR messages into TS-OLSR in high mobility scenarios may yield
even more gains.
Overall, our results indicate that the use of time series
analysis, ARIMA modelling, and control charts are effective
tools for the adaptive transmission of control overhead.
We have used an MEWMA chart to monitor the two-hop
neighbourhood and topological links. It may be interesting
to see how TS-OLSR behaves if two equivalent one-sided
MCUSUM charts are used to monitor positive and negative
deviations from the mean. Deviation on one side may have
a different meaning than deviation on the other side and appropriately tuned MCUSUMs may provide insight on what
actions are suitable when they generate signals.

211

Figure 9: EWMA chart (λ = 0.05) for residuals of 2-hop neighbourhood and topological links, respectively, of
a representative node moving 2 m/s.

(a) 2-hop neighbourhood residuals, K = 0.63

(b) Topological residuals, K = 0.49

Figure 10: Comparison of OLSR and its variants: one data flow with arrival rate of 10 pkts/s.
100

110000
Control Overhead (pkts)

Packet Delivery Ratio (%)

120000

OLSR
A-OLSR
TS-OLSR
Adaptive OLSR

90
80
70
60
50
40

100000
90000
80000
70000
60000
50000

30

40000
2

5

10
Speed

15

20

2

(a) Packet delivery ratio

7.

OLSR
A-OLSR
TS-OLSR
Adaptive OLSR

5

10
Speed

15

20

(b) Total control overhead

REFERENCES

[9] S. V. Crowder, “Design of Exponentially Weighted
Moving Average Schemes,” Journal of Quality
Technology, vol. 1, July 1989.
[10] J. M. Lucas and M. S. Saccucci, “Exponentially
Weighted Moving Average Control Schemes:
Properties and Enhancements,” Technometrics,
vol. 32, no. 1, pp. 1–12, 1990.
[11] C. A. Lowry, W. H. Woodall, C. W. Champ, and S. E.
Rigdon, “A Multivariate Exponentially Weighted
Moving Average Control Chart,” Technometrics,
vol. 34, no. 1, pp. 46–53, 1992.
[12] D. C. Montgomery, L. A. Johnson, and J. S. Gardiner,
Forecasting and Time Series Analysis. McGraw-Hill
Inc., 2nd ed., 1990.
[13] Minitab, “Minitab Software for Quality Improvement.”
http://www.minitab.com, 2011.
[14] The University of California, Berkeley, “The Network
Simulator – ns-2.”
[15] G. M. Ljung and G. E. P. Box, “On A Measure of
Lack of Fit in Time Series Models,” Biometrika,
vol. 65, no. 2, pp. 297–303, 1978.
[16] Gnu Regression, Econometrics and Time-series
Library. http://gretl.sourceforge.net/.
[17] S. E. Rigdon, “A Double-Integral Equation for the
Average Run Length of a Multivariate Exponentially
Weighted Moving Average Control Chart,” Statistics
& Probability Letters, vol. 24, no. 4, pp. 365–373, 1995.

[1] T. Clausen and P. Jacquet, “RFC 3626: Optimized
link state routing protocol,” October 2003.
[2] D. C. Montgomery, Introduction to Statistical Quality
Control. John Wiley & Sons, Inc., 6th ed., 2008.
[3] G. E. P. Box, G. M. Jenkins, and G. Reinsel, Time
Series Analysis: Forecasting & Control. Prentice Hall,
3rd ed., February 1994.
[4] K. Shaukat and V. R. Syrotiuk, “Using monitoring to
control a proactive routing protocol,” Ad Hoc & Sensor
Wireless Networks, vol. 6, no. 3–4, pp. 299–319, 2008.
[5] L. Qin and T. Kunz, “Adaptive MANET Routing: A
Case Study,” in Springer LNCS, vol. 5198, pp. 43–57,
September 2008.
[6] F. J. Ros and P. M. Ruiz, “Cluster-based OLSR
Extensions to Reduce Control Overhead in Mobile Ad
Hoc Networks,” in Proc. of the Int’l Conf. on Wireless
Communications and Mobile Computing, pp. 202–207,
2007.
[7] L. Ming, G. Zhao, G. Xie, and X. Kuang, “HOLSR: A
novel routing scheme of ad hoc wireless networks for
pervasive computing,” in Proc. of the 2nd Int’l Conf.
on Pervasive Computing and Applications
(ICPCA’07), pp. 661–666, July 2007.
[8] H. Badis and K. A. Agha, “Scalable Model for the
Simulation of OLSR and Fast-OLSR Protocols,” in
Proc. of the IFIP-TC6 Mediterranean Workshop on
Ad-Hoc Networks (MedHocNet’03), June 2003.

212

Wireless Netw (2006) 12:681–690
DOI 10.1007/s11276-006-6528-z

The effects of synchronization on topology-transparent scheduling
Wensong Chu · Charles J. Colbourn · Violet R. Syrotiuk

Published online: 19 May 2006
C Springer Science + Business Media, LLC 2006


Abstract Topology-transparent scheduling is an attractive
medium access control technique for mobile ad hoc networks (MANETs) and wireless sensor networks (WSNs).
The transmission schedule for each node is fixed and guarantees a bounded delay independent of which nodes are its
neighbours, as long as the active neighbourhood is not too
dense. Most of the existing work on topology-transparent
scheduling assumes that the nodes are synchronized on frame
boundaries. Synchronization is a challenging problem in
MANETs and in WSNs. Hence, we study the relationships
among topology-transparent schedules, expected delay, and
maximum delay, for successively weaker models of synchronization: frame-synchronized, slot-synchronized, and asynchronous transmission. For each synchronization model, we
give constructive proofs of existence of topology-transparent
schedules, and bound the least maximum delay. Perhaps surprisingly, the construction for the asynchronous model is a
simple variant of the slot synchronized model. While it is
foreseen that the maximum delay increases as the synchronization model is weakened, the bound is too pessimistic.
The results on expected delay show that topology-transparent
schedules are very robust to node density higher than the construction is designed to support, allowing the nodes to cope
well with mobility, and irregularities of their deployment.
Keywords Scheduling . Synchronization models . Ad hoc
networks

W. Chu · C. J. Colbourn · V. R. Syrotiuk ()
Department of Computer Science and Engineering, Arizona State
University, P.O. Box 878809, Tempe, Arizona, U.S.A.
85287-8809.
e-mail: {wensong.chu,colbourn,syrotiuk}@asu.edu

1. Introduction
A mobile ad hoc network (MANET) is a collection of mobile wireless nodes that self-organize without any centralized
control or any fixed infrastructure. A wireless sensor network
(WSN) is a collection of sensor nodes that may be used to
communicate what is sensed continuously, or to detect specific events. Since the position of the sensor nodes may not
be known in advance, there is a need for the network to coordinate in a distributed manner, similar to the self-organizing
capabilities of a MANET.
Since the nodes in both a MANET and a WSN communicate over a shared broadcast channel, a medium access
control (MAC) protocol is responsible for controlling access
to the channel. As a result, the MAC protocol is an essential
component of the network.
There are several differences between WSNs and
MANETs [19]. In particular, the number of sensor nodes
deployed in a WSN is expected to be several orders of magnitude higher than the number of nodes in a typical MANET.
While sensor nodes may be more densely deployed, they are
also more limited in power, computational capability, and
memory capacity. The topology of WSNs changes frequently
as a result of node failure or destruction, and energy depletion, while topology changes in MANETs are mostly due to
node mobility. Sensor nodes may not have global identifiers
because of the amount of overhead assigning such identifiers for a large numbers of sensors. Furthermore, the network tends to operate as a collective structure, addressed by
attribute, rather than supporting many independent point-topoint flows. Traffic tends to be variable and highly correlated
in WSNs.
Despite these differences, both contention and scheduled
MAC protocols exist for MANETs and WSNs. In a contention protocol, nodes share the channel in a manner that
Springer

682

can lead to conflicts. The use of IEEE 802.11 is prevalent
in MANETs due to its simplicity and lack of synchronization requirements [1]. While such contention based protocols
achieve high throughput with a reasonable expected delay, in
the worst-case the delay is very poor. For WSNs, the overhead of the control packets in the handshake can be as high
as 40% [24] since data packets are not very large. In addition,
channel sensing is required throughout the handshake; this is
expensive for the low radio ranges of interest in WSNs, where
the energy cost of transmission and reception is on the same
order of magnitude. As the interest in delay sensitive or continuous sensing applications and energy-awareness grows,
scheduled approaches to medium access control are gaining
renewed attention.
Of the scheduled approaches to access control, topologydependent and topology-transparent strategies have been
developed for MANETs. Topology-dependent protocols typically alternate between a contention phase and a scheduled
phase. In the contention phase, nodes collect neighbour information from which schedules are computed for use. TRAMA
is a topology-dependent protocol proposed for use in WSNs
[20]. Available topology-dependent schemes are sensitive to
the frequency with which the contention phase is run, and
may suffer instability if the changes in traffic or topology
occur too rapidly.
In a topology-transparent strategy, neighbour information
is not used. The existing protocols construct schedules that
depend on two design parameters: N , the number of nodes
in the network, and Dmax , the maximum active node degree.
If the bound on Dmax is satisfied, the schedule guarantees
at least one collision-free transmission to each neighbour
[3, 16]. In [21] the original topology-transparent MAC protocols were generalized by observing that their schedules correspond to an orthogonal array. The largest number of nodes
for a given frame length is supported by a Steiner system
[11]. Both orthogonal arrays and Steiner systems are special
cases of combinatorial objects called cover-free families [9].
Most scheduled access control protocols assume that the
nodes are frame-synchronized, i.e., all nodes start and end
frames on the same slot periodically. In this paper we investigate three synchronization models: frame-synchronized,
slot-synchronized, and asynchronous. We examine their impact on the existence of topology-transparent schedules and
delay. Zheng et al. [25] show that synchronization on slot
boundaries is simpler to achieve. While they consider the
problem of constructing wake-up schedules and need a certain intersection property of codewords, we instead need a
property of their union. However in both cases, to treat slotsynchronized networks, codes with a cyclic automorphism
group are required. We have demonstrated the existence
of topology-transparent schedules for this weaker form of
synchronization using cyclic superimposed codes [5]. Even
when no synchronization is possible, topology-transparent
Springer

Wireless Netw (2006) 12:681–690

scheduling remains feasible [4]. Our contribution in this
paper is for the asynchronous model, where we show that
topology-transparent schedules exist; indeed, it is somewhat
of a surprise that the construction for the asynchronous model
is achieved by a simple variant of the construction for the
slot synchronized model. The cost is that the delay doubles
over slot-synchronized networks. These results are derived
from properties of superimposed codes (which are equivalent to certain cover-free families), a form of combinatorial
design.
The rest of this paper is organized as follows. In Section 2,
we give our assumptions and describe our network model.
As well, we define three synchronization models (frameand slot-synchronized, and asynchronous). The notion of a
g-robust schedule is also defined for each synchronization
model. Section 3 defines the notions of superimposed codes
and cyclic superimposed codes and their correspondence
with frame- and slot-synchronized schedules. We also summarize results on existence and constructions of such schedules. The main results of this paper are given in Section 4.
Here, we explore the existence of g-robust asynchronous
schedules and discuss the tradeoff between synchronization
and delay. To supplement the small codes given to illustrate
the definitions, Section 5 provides a more realistic example of a slot-synchronized schedule (the asynchronous case
is similar). It also discusses the robustness of the schedule
and behaviour in the less pessimistic expected case. Section 6
outlines an acknowledgement scheme that allows the theoretical bounds on delay to be achieved with minimal overhead.
This, together with the ability to weaken the synchronization requirements, renews topology-transparent scheduling
for medium access control when delay is the principal objective. Section 7 concludes and outlines remaining challenges
for topology-transparency.

2. Models of synchronization
We formally model a network by an undirected graph G =
(V, E), where V is the set of nodes (vertices) and E is the
set of links (edges). The number of nodes in the network is
N = |V |. Let u, v ∈ V with u = v be two nodes. There is
an edge (u, v) ∈ E if and only if u is within the transmission
range of v and vice versa; u and v are neighbours of each
other since they are adjacent. The degree d(v) of a node v
is the size of its neighbourhood. The maximum degree in the
network is Dmax = maxv∈V d(v).
Since we examine scheduled approaches to channel access, we assume that time is divided into discrete intervals
called slots, with the slots grouped into frames. A frame is
represented as F = {0, 1, . . . , L − 1}, where L is the length
in slots of the frame. Each node maintains a local timer to

Wireless Netw (2006) 12:681–690

ensure that the length of a slot is fixed for all nodes of the
network.
A schedule of a node v ∈ V is given by a subset S(v) ⊆ F
and i ∈ S(v) means that node v can transmit in the ith slot
of a frame. Thus S(v) consists of the slots in which node v
can transmit. Each slot accommodates one packet and packet
transmission starts on a slot boundary. Each node uses the
same schedule in successive frames, i.e., it iterates through
its frame cyclically, though this need not be the case (see, for
example, [10]).
A node transmitting in a given slot cannot receive in the
same slot, i.e., the transceiver is half-duplex. In addition, a
node cannot receive more than one packet in a given slot.
Multiple transmissions cause a collision at the receiver resulting in all transmissions as unsuccessful. Collision is the
only event that causes packet loss; noise on the channel is not
considered. In general, a slot may contain zero, one, or more
packets, corresponding to an idle slot, a successful transmission, or a collision. The outcome of a slot is assumed to be
available to a node immediately after transmission. This acknowledgement scheme was assumed in [3, 16] in order to
simplify analysis; we discuss how to overcome this simplifying assumption in Section 6.
Three different models of synchronization are studied:
1. A network is slot-synchronized if there is a good method
to allow all nodes to align on a slot boundary.
2. A network is frame-synchronized if it is slot-synchronized
and there is a good method to allow all nodes to start and
end frames at the same slot periodically.
3. A network is asynchronous if it is neither frame nor slot
synchronized.
We discuss existence and construction of schedules in the
context of different synchronization models and compare the
corresponding performance. We begin with formal definitions of schedules under different synchronization models.
Let G = (V, E) be a frame-synchronized network and let
g be a positive integer. A g-robust frame-synchronized schedule of G is a schedule satisfying the following two conditions:
1. For each node v and for each neighbour u of v there are
at least g slots Sg = {s0 , s1 , . . . , sg−1 } ⊆ S(v), such that
Sg ∩ S(u) = ∅ and also Sg ∩ S(u  ) = ∅ for each neighbour u  of u, u  = v. This condition ensures that each
node has g collision-free slots for transmission to each of
its neighbours in every frame.
2. The schedule is only based on two global network parameters N and Dmax .
The original topology-transparent schedules are all g-robust
frame-synchronized schedules with g = 1 [3, 16].
Let G = (V, E) be a slot-synchronized (respectively,
asynchronous) network and let g be a positive integer. A
schedule S(v) of the node v is a g-robust slot-synchronized

683

schedule (respectively, g-robust asynchronous schedule) if
the following two conditions are satisfied:
1. For each node v and for each neighbour u of v, the node v
has at least g collision-free slots in each frame for transmitting packets to the node u, no matter at what slot (respectively, at what time) in the frame it starts.
2. The schedule is only based on two global network parameters N and Dmax .
Such g-robust slot-synchronized topology-transparent
schedules were first studied in [4], while the asynchronous
case was first introduced in the preliminary version of this
paper [5]. The requirements for g-robust asynchronous
schedules are stronger than the ones for slot-synchronized
schedules. Without slot-synchronization, two slots from
different nodes can overlap in time. Transmissions that
overlap in time constitute a collision at each transmitter
involved in the collision.
As expected, frame length increases as the model of
synchronization weakens. The shortest frames are obtained
when the network is frame-synchronized. Longer frames are
needed when the network is slot-synchronized, and even
longer frames in an asynchronous network. We discuss the
slot-synchronized case first.

3. Topology-transparent schedules via
superimposed codes
In [21], the known frame-synchronized topology-transparent
protocols were generalized by observing that their schedules
correspond to an orthogonal array. The largest number of
nodes for a given frame length is supported by a Steiner system [11]. Both orthogonal arrays and Steiner systems are
special cases of combinatorial objects called cover-free families [9]. Colbourn et al. [8] show that such combinatorial
designs arise in many applications in networking.
A d cover-free family is equivalent to a d disjunct matrix
and also to a superimposed code of order d. Hence there is
also an equivalence between the notation used in each representation: characteristic sets for cover-free families, matrices
for disjunct matrices, and sets of vectors for superimposed
codes. In this paper, we use the terminology and notation
of superimposed codes and cover-free families since they
are the most natural and the most compact for describing
topology-transparent schedules in the synchronization models considered.
Superimposed codes with g = 1 were introduced by Kautz
and Singleton [17] in 1964 and have been studied as an application of combinatorial group testing in communications.
Du and Hwang [12] provide a comprehensive treatment of
combinatorial group testing and its applications.
Springer

684

Wireless Netw (2006) 12:681–690

Table 1 A (9, 12, 2, 1)-SC, a
1-robust superimposed code of
order 2. This superimposed code
supports 12 nodes with a frame
length of 9

100100100100
010010010100
001001001100
100001010010
010100001010
001010100010
100010001001
010001100001
001100010001

Let x = [x1 , x2 , . . . , xn ]T and y = [y1 , y2 , . . . , yn ]T be
two binary n-dimensional vectors. The superposition sum of
x and y, denoted x ∨ y, is the bit-by-bit Boolean sum. That
is, x ∨ y = [x1 ∨ y1 , x2 ∨ y2 , . . . , xn ∨ yn ]T . In addition, x
is contained in y if x ∨ y = y.
Let M be a v × b binary matrix, and let g and d be two
positive integers. M is a g-robust superimposed code of order
d, denoted by (v, b, d, g)-SC, if for any d + 1 columns of M,
and one designated column C among them, there exist at least
g rows that intersect C in a one and with the other d columns
with all zeros.
Table 1 gives a small superimposed code. This code
supports a network with N = b = 12 frame-synchronized
nodes. Each node u has a frame of length v = 9 corresponding to a codeword (column) C in the code; the schedule for u
is given by S(u) = {i|C[i] = 1, 0 ≤ i ≤ v}. In this example,
even if each node has d = 2 actively transmitting neighbours
in addition to itself, it is guaranteed at least g = 1 collisionfree slots, independent of which two nodes are its neighbours.
For networks with slot-synchronization, nodes are aligned
only on slot boundaries so each node may start its frame at any
slot. Thus we need codes with a cyclic automorphism group
(see [7] for undefined mathematical terms). Effectively, every cyclic shift of the schedule S(v) is also a schedule for
node v. In [4], we propose a coding scheme of cyclic superimposed codes for the slot-synchronized model. To introduce
this scheme, we need some notation.
Let α = [a0 , a1 , . . . , an−1 ]T be a binary vector of length
n. Let
L k (α) = [ak , ak+1 , . . . , an−1 , a0 , . . . , ak−1 ]T
be the kth cyclic shift of α. Since the vector has length n,
L n (α) = α. Let
C(α) = {L (α)|0 ≤ k ≤ n − 1}
k

be the set of all possible cyclic shifts of α.
Springer

Any binary vector of length n can be represented as a
subset of Zn , the integers modulo n. This subset
supp(α) = { i |ai = 1}
is the support of α. Corresponding to C(α), we have its subset
representation
α Zn = {supp(α) + k|0 ≤ k ≤ n − 1}
where supp(α) + k = {i + k|ai = 1}. Then C(α) and α Zn are
different representations of the same object, the cyclic orbit
of the vector α under action of Zn , or just the cyclic orbit
of α.
Let M = [α1 , α2 , . . . , αb ] be a v × b binary matrix where
αi , 1 ≤ i ≤ b, is a column vector of length v. Then M is a
cyclic (v, b, d, g)-SC if
1. Any two columns αi and α j with i = j are cyclically
distinct: C(αi ) ∩ C(α j ) = ∅. In other terms, there is one
orbit representative from every orbit.
2. For any choice of γ1 , . . . , γb with γi ∈ C(αi ), the matrix
[γ1 , γ2 , . . . , γb ] is a (v, b, d, g)-SC.
Table 2 shows a matrix M that is the transpose of a cyclic
(63, 5, 3, 1)-SC. No matter how each row of M is cyclically
shifted, the result is always a (63, 5, 3, 1)-SC. Also shown
is the support of M. If we adjoin all cyclic shifts of each
row of M and form a 315 × 63 matrix, then its transpose is a
(63, 315, 3, 1)-SC. While 315 nodes can be supported with
a frame length of 63 by the superimposed code in a framesynchronized network, only 5 nodes are supported by the
cyclic superimposed code in a slot-synchronized network.
(This small example is for illustrative purposes only.)
In [4], a unified model for g-robust frame-synchronized
and slot-synchronized schedules is presented.
Theorem 3.1 ([4]). Let G = (V, E) be a network with N =
|V | nodes, and maximum degree Dmax . If there exists a
(v, b, d, g)-SC with b ≥ N and d ≥ Dmax , then there exists
a g-robust frame-synchronized schedule for the network G
with frame length v.
Table 2 The transpose of a cyclic (63, 5, 3, 1)-SC, and its support
representation
10000100000100000000000010000000· · ·0

{{0, 5, 11, 24},

10001000000000000000100000000010· · ·0

{0, 4, 20, 30},

10010000000000000000010000001000· · ·0

{0, 3, 21, 28},

10100000000000000100000000000100· · ·0

{0, 2, 17, 29},

11000000010000000000000100000000· · ·0

{0 ,1, 9, 23}}

Wireless Netw (2006) 12:681–690

The main constructions for g-robust frame-synchronized
schedules in [3, 11, 16, 21] can be summarized as follows:
Theorem 3.2 (([16])). For given global network parameters
N and Dmax , and for every positive integer g, there exist a
prime power q and positive integer t, such that there exists
a (q 2 , q t ,  q−g

, g)-SC, i.e., a g-robust frame-synchronized
t−1
schedule with N ≤ q t , Dmax ≤  q−g

, and frame length q 2 .
t−1
The existence of g-robust slot-synchronized schedules
was proved in [4] via cyclic superimposed codes; constructions of cyclic superimposed codes are also presented there.
Theorem 3.3 ([4]). Let G = (V, E) be a network with N =
|V | nodes, and maximum degree Dmax . If there exists a cyclic
(v, b, d, g)-SC with d ≥ Dmax and N ≤ b, then there exists a
g-robust slot-synchronized schedule for each node in G with
frame length v.
Theorem 3.4 ([4]). For any given global network parameters N and Dmax , and for any positive integer g, there
exist a prime p and positive integer t, such that there
exists a cyclic ( p 3 − p, p t ,  p−g

, g)-SC, i.e., a g-robust
t
slot-synchronized schedule with N ≤ p t ,Dmax ≤  p−g

, and
t
frame length p 3 − p.
Weakening from frame-synchronization to slotsynchronization with the same parameters (assuming
the prime power q is actually a prime p), the frame length
(maximum delay) is enlarged by a factor around p. Unlike
the frame-synchronized case where the densest cover-free
families are provided by Steiner systems [14], the densest
cyclic superimposed codes are not characterized. Such a
characterization would be very interesting but appears to be
quite difficult.
An interesting question is the existence of g-robust asynchronous schedules and the tradeoff between synchronization and delay. This is the main topic of the next section.

4. g-Robust asynchronous schedules
Slot-synchronization is stronger than no synchronization,
and hence any g-robust asynchronous schedule is a g-robust
slot-synchronized schedule. We first examine constructions
for cyclic superimposed codes. One efficient method is via
optical orthogonal codes (OOCs).
An (n, ω, λa , λc ) optical orthogonal code (O OC) C is a
family of binary sequences of length n and weight ω that satisfies the following two properties (where ⊕ denotes addition
modulo n):

685

1. Auto-correlation property:
n−1


xt xt⊕τ ≤ λa ,

t=0

for any x = {xt }n−1
t=0 ∈ C and every integer τ , τ ≡
0 (mod n).
2. Cross-correlation property:
n−1


xt yt⊕τ ≤ λc ,

t=0
n−1
for any x = {xt }n−1
t=0 ∈ C, y = {yt }t=0 ∈ C with x = y
and every integer τ .

For example, the codewords of a (13, 3, 1, 1)-OOC are:
{(1100100000000), (1010000010000)}
The weight ω = 3 because each codeword has three ones.
Any cyclic shift of a codeword xt⊕τ with itself xt covers at
most one position in the codeword since λa = 1, while any
cyclic shift of any other codeword yt⊕τ with xt covers at most
one position since λc = 1 also.
Theorem 4.1 ([4]). Let g ≥ 1 be an integer. If there exists a
(n, ω, λa , λc )-OOC with b codewords and ω − g ≥ λc , then
there exists a cyclic (n, b, d, g)-SC with d =  ω−g

.
λc
Lemma 4.1 ([2]). For any prime power q, there exists an
optimal (q 2 − 1, q, 1, 1)-OOC with one codeword.
The following is a general recursive construction that only
requires a certain prime factorization of integers.
Theorem 4.2 ([6]). Suppose there exists an (n, ω, λ, λ)OOC with T codewords. Let m = p1r1 p2r2 . . . ptrt be a positive
integer, where the pi ’s with 1 ≤ i ≤ t are primes not less
than ω. Then there exists an (mn, ω, λ, λ)-OOC with T m λ
codewords.
Theorem 4.3. For every prime p and every positive integer
t, there exists a (2 p 3 − 2 p, p, t, t)-OOC C having p t codewords with the following parity property: Let α and β be two
different codewords of C. For any h ∈ Z2 p3 −2 p , if there exists two elements a and b in supp(α) with b − a = h modulo
2 p 3 − 2 p, then there exists no pair of elements c and d in
supp(β) such that d − c = h + 1.
Proof: By Lemma 4.1, there exists a ( p 2 − 1, p, 1, 1)-OOC
with a single codeword. Take the support of this codeword and multiply each element by 2. Then we get a
Springer

686

(2 p 2 − 2, p, 1, 1)-OOC with a single codeword. Treat this
as a (2 p 2 − 2, p, t, t)-OOC with one codeword. This codeword has the following property: the difference of any two
elements in the support is an even number. Apply Theorem
4.2 with m = p and λ = t to get a (2 p 3 − 2 p, p, t, t)-OOC
C having p t codewords with the property that the difference
of any pair of elements from any two supports of codewords
is even (refer to the proof of the basic construction in [6]).
Since all possible differences are even, the parity property
holds.


Wireless Netw (2006) 12:681–690

Given Dmax and g, the function f (·) with

f ( p) =

p−g
Dmax



is a strictly increasing function with respect to prime p. In
addition, the function g(·) with g( p) =  lnln Np  is a strictly
decreasing function with respect to prime p. Thus the set



p| p a prime with

Now we claim the existence of a g-robust asynchronous
schedule.
Theorem 4.4. For any given global network parameters N
and Dmax , and for any positive integer g, there exist a prime p
and positive integer t, such that there exists a g-robust asynchronous schedule with N ≤ p t , Dmax ≤  p−g

, and frame
t
3
length 2 p − 2 p.
Proof: We have proved that there exists a (2 p 3 −
2 p, p t , t, t)-OOC with the parity property by Theorem
4.3; by Theorem 4.1, there exists a cyclic (2 p 3 −
2 p, p t ,  p−g

, g)-SC. Therefore there exists a g-robust slott
synchronized schedule with N ≤ p t and Dmax ≤  p−g

.
t
To prove the theorem, first we show that the parity property is sufficient to make a g-robust slot-synchronized schedule a g-robust asynchronous schedule. For any two different codewords of C, say α and β, we have  = |supp(α) ∩
supp(β)| ≤ t. We need to show that if the slots of α and
β are not perfectly aligned, the intersection number  does
not increase. Now  increases if and only if two elements
a and b in supp(α) are h apart and two elements c and d in
supp(β) are h + 1 apart. This is exactly the parity property
in Theorem 4.3.
Then the rest of proof is to show that for any N , Dmax
and g, we always can find p and t such that there exists the
desired schedule.
Fig. 1 Algorithm to find the
parameter t and p for a g-robust
asynchronous schedule from a
cyclic superimposed code

Springer

p−g
Dmax




≥

ln N
ln p



is an infinite subset of the natural numbers. Let p ∗ be the minimal element of this set and t ∗ =  lnln Np . Then we construct
the claimed OOC according to Theorem 4.3.

Based on this constructive proof, the algorithm in Fig. 1
finds appropriate parameters for the superimposed code. This
algorithm terminates since the inequality t ≤ s is satisfied
for L = 2N ; hence the algorithm is linear in N (but a simple
binary search gives time logarithmic in N ).
Weakening from slot-synchronization to asynchronous
communication once again enlarges the frame length, in this
case by a factor of two.

5. A practical example
We describe an example in the case of slot-synchronization;
the asynchronous case is similar. First we describe how
to produce a ( p 3 − p, p, t, t)-OOC, to demonstrate that
the process can often be easily carried out. We construct a ( p 2 − 1, p, 1, 1)-OOC with one codeword using
a construction of Bose [2]. Solutions are tabulated in
§ IV.14.6 of [7]. For example when p = 11, the length
of the codeword is 112 − 1 = 120, and its support is S =
{1, 3, 6, 44, 64, 70, 71, 79, 89, 93, 110}. This OOC has λa =
λc = 1, but we treat it as an OOC with λa = λc = t. Next we

Wireless Netw (2006) 12:681–690

choose a value of t so that the number of nodes N is at most
p t . For our example with p = 11, we choose t = 2, so that as
many as 121 nodes can be supported. Our next task is to produce a ( p 3 − p = 1320, p = 11, 2, 2)-OOC with p 2 = 121
codewords. Following [6], we form a 11 × 112 matrix D.
Rows of D are indexed by the integers modulo 11, Z11 .
Columns are indexed by pairs ( j, f a ) where j ∈ Z11 and f a is
a quadratic polynomial ax 2 with a ∈ Z11 . In a row indexed by
x and column indexed by ( j, f a ), the entry is the evaluation
of j x + f a (x) modulo 11. We produce p 2 = 121 codewords
as follows.
Write the elements of S as (s0 , . . . , s10 ). Let D have entries
di j for 0 ≤ i ≤ 11 and 0 ≤ j ≤ 112 . For each 0 ≤ j ≤ 112 ,
form a set B j = {si + (112 − 1) · di j : 0 ≤ i < 11}. The set
{B j : 0 ≤ j < 112 } contains the supports of 112 codewords
of a (11(112 − 1), 11, 2, 2)-OOC with 112 codewords. In the
language of superimposed codes, this provides a 1-robust
superimposed code for a network with 121 users, a maximum of 5 neighbours, and codeword length 1320, for a slotsynchronized system. We have seen that doubling the length,
and leaving the other parameters unchanged, supports asynchronous communication.
We have until this point concentrated on obtaining a delay
guarantee; while this example shows that such a guarantee
can be established using an SC that is easily generated, it is
perhaps discouraging that the guarantee of success appears
to require such lengthy codewords. Here we explore the more
practical use of such codes. While guaranteeing a finite delay
on the worst case, what is the expected throughput of these
codes? We outline this next, using the example code just developed. A specific node is given a codeword S enabling it
to transmit in 11 out of 1320 consecutive slots. In order to
establish the guarantee, we have made two pessimistic assumptions. First, the schedules of the node’s neighbours are
chosen to maximize the interference with S. Secondly, each
neighbour’s schedule is cyclically permuted to also maximize interference with S. We examine what happens when
neighbours and the cyclic shifts of their schedules are instead
selected at random. Of the 120 schedules different from S,
ten have 1199 cyclic shifts disjoint from S and the remaining
121 meeting S in a single position; 110 have 1204 shifts disjoint from S, 111 meeting it in one position, and 5 meeting
it in two.
While our worst-case analysis requires five neighbours
each to use a shift of their schedule in which two positions
of S are covered, and these pairs of positions are themselves
disjoint, the corresponding event is quite rare if nodes act
randomly. Indeed if we consider a single element (slot) in S,
the remaining 120 schedules each have the property that 1309
shifts do not cover this element, and only 11 do. Of the 55
pairs of elements in S, 110 schedules have no shift covering
this pair, while 10 have exactly 1 of the 1320 that does. By
construction, no schedule has a shift intersecting S in three

687

or more elements. In terms of our example, even if all 120
neighbours are active transmitters and in the neighbourhood
of the node using schedule S, there remains at least one slot
in S that is not covered with probability exceeding 99.3%.
While our guarantee is for at most five neighbours, expectation of success is high even for a fully connected topology
in which all nodes are transmitting. In a sense this is not
surprising, since within 1320 consecutive slots, if all nodes
attempt transmission there are only 1331 transmission attempts. What is surprising is that no frame-synchronization
is needed to achieve this, and when neighbourhoods are
(very) small the strong expectation of success becomes a
certainty.
Increasing the number of nodes while maintaining the
length degrades the guarantee. For example, choosing p =
11 and t = 3 so that 1331 users can be supported using an
OOC with codeword length 1320, guaranteed success occurs
only with three or fewer active neighbours. Nevertheless, the
expectation of success remains strong when a node has more
than one hundred neighbours, provided that each has the shift
of its schedule selected randomly; we leave this computation
to the reader. These observations support those in [9], where
for frame-synchronized environments expectation of success
is shown to be high for numbers of neighbours larger than the
Dmax specified. Here the effect is more pronounced, since random selection of the cyclic shifts exploit the fact that while a
neighbour’s schedule could interfere if appropriately shifted,
it rarely does.

6. A realistic acknowledgement model
Topology-transparent scheduling can support both a broadcast and a unicast MAC primitive. To implement a broadcast
when g = 1, a node v transmits the same packet in each slot
of its schedule S(v). By definition, by the end of the frame,
this guarantees that each neighbour receives a copy of the
packet. For unicast, the slot s ∈ S(v) in which there is a success to a specific neighbour is guaranteed, but depends on
which nodes are neighbours of v at the time it goes to transmit the packet. Hence, to implement unicast seems to require
feedback on the outcome of a slot. If the unicast is successful
to the intended neighbour, then the transmitter can advance
to the next enqueued packet for the next slot in its schedule,
otherwise it retransmits the same packet.
Chlamtac and Faragó [3] and Ju and Li [16] both assumed
that the outcome of the slot, either a success or a collision,
is available at the transmitter at the end of the slot. This
assumption simplified the analysis of throughput and maximum minimum delay for topology-transparent scheduling.
However this assumption is wrong for a MANET. Only the
receiver, and not the transmitter, can determine the outcome
of a transmission. Indeed there may be terminals hidden to the
Springer

688

Wireless Netw (2006) 12:681–690
14000
1–robust AS–schedule

L: Maximal Delay with g=1, Dmax=6

12000

10000

8000
1–robust SS–schedule
6000

4000

2000
1–robust FS–schedule
0
100

200

300

400

500

600

700

800

900

1000

N: Number of Total Nodes

Fig. 2 Maximum delay for each synchronization model: frame-synchronized (FS), slot-synchronized (SS), and asynchronous (AS)

transmitter. Hence if the transmitter is to know the outcome,
it must gain this knowledge from the receiver.
There are a variety of ways in which the receiver may
explicitly return feedback. These include classical backward
and forward error correction schemes. Both of these schemes
operate on a hop-by-hop basis at the data link layer.
In backward error correction (BEC), the next hop neighbour explicitly returns feedback to the source, either as a positive or negative acknowledgement. Well known techniques
include stop-and-wait where the window size is one, and
go back N and selective repeat with larger windows. These
techniques may require the source to wait an entire frame for
receipt of the feedback, even if both transmitter and receiver
have at most Dmax active neighbours. In the pathological case
loss of the acknowledgement is possible; this may result in
the transmitter stalling for many frames. Further, these BEC
techniques require window, buffer, and timer management,
not to mention that packets suffering collision need to be
retransmitted.
With forward error correction (FEC), the source includes
enough redundancy in the encoded packets to allow the destination to decode the message. Most FEC schemes, such as
Reed-Solomon and Tornado codes, require knowledge of the
loss rate on the channel. Though fast encoding and decoding
algorithms are known, in practice, an effective implementation of these algorithms does not exist. Moreover, the use of
FEC on a hop-by-hop basis requires reconstruction at each

Springer

intermediate node, impacting end-to-end delay negatively.
Finally, determining a suitable rate in practice is not at all
easy, especially in a wireless network. If the rate is chosen
conservatively to account both for collisions and for communication errors, as well as allowing for the maximum number
of permitted active neighbours, many additional packets are
sent containing redundant information when the design assumptions are pessimistic. Too low a rate decreases throughput, too high a rate fails to deliver enough information to decode. Worse yet, adapting at the transmitter to a more suitable
rate requires an agreement between transmitter and receiver
to change the FEC encoding in use.
Another idea for implementing an acknowledgement
scheme is to either extend each individual slot of the frame, or
the frame itself, to return feedback. Extending a slot can work
since if the transmission is successful, the feedback will also
be successful. However, this does not permit more than one
successful receiver to respond, i.e., it can only work for unicast traffic. Extending the frame raises many questions. By
how many slots should the frame be extended? How should
these slots be assigned to the receivers? Should contention be
used in this period? Frame extension raises more questions
than it answers.
We propose an acknowledgement scheme based on rateless FEC. Luby Transform (LT) codes [18] are rateless
erasure codes, i.e., they can accommodate variable packet
loss. This makes LT codes a very attractive technique for

Wireless Netw (2006) 12:681–690

use in wireless networks. Unlike the classical hop-by-hop
acknowledgement schemes, we eliminate the need for link
layer acknowledgements. Successive encoded symbols are
transmitted by the source until it receives an acknowledgement from the ultimate destination of the flow. A destination that wishes to reconstruct the data transmitted by the
source needs only collect enough of these encoded symbols.
In practice, 3–5% more than the original data is needed to
reconstruct an exact copy of data by the receiver [13]. It does
not matter which of the encoded symbols are received, or in
what order they are received. All the encoded symbols are of
equal value in reconstructing the original data.
In [22] we show that for both static and mobile ad hoc networks, the expected throughput using rateless FEC closely
matches the theoretical bound with assumed feedback availability. Furthermore, it can be achieved with minimal computational overhead.

7. Conclusions
With respect to different types of synchronization (framesynchronization, slot-synchronization and asynchronous
transmission), we have answered the questions of existence
of topology-transparent schedules and how to construct them.
To conclude this paper, we provide a comparison among
these three synchronization models. We consider an example. Let G = (V, E) be a network with N is ranging from 100
to 1000 and Dmax = 6. Choosing Dmax = 6 employs the distributed topology control algorithm in [15]. Figure 2 shows
a comparison of the maximum delays. The lowest delay as
expected is when frames are synchronized. A substantial loss
in the delay guarantee results when synchronization is on slot
boundaries; the figure illustrates the further doubling when
no synchronization of any kind is assumed.
Weakening from frame-synchronization to slotsynchronization impacts maximum delay in a significant
way. Weakening again from slot-synchronization to the
asynchronous case doubles the maximum delay again.
However pessimistic assumptions were made in order to
establish these guarantees. In spite of this, the expectation of
success is significantly better in both the slot-synchronized
and asynchronous models, similar to the frame-synchronized
model [9]. In addition, success is very robust to the number
of neighbours larger than the Dmax specified.
Given that there exists a realistic acknowledgement
scheme [23] to achieve the theoretical bounds on throughput
and delay, and we have been able to weaken the synchronization requirements, renews topology-transparent scheduling
for medium access control when delay is the principal objective. The challenge remaining relates to adaptation. While
[11, 21] provide some directions on what to do if the upper bound of Dmax is violated, what if the actual number of

689

neighbours is far less than Dmax ? Our current work seeks to
address how to be adaptive to the traffic and make use of
available bandwidth.
Acknowledgments The authors are grateful to the anonymous referees
for their helpful comments. This work was supported in part by ARO
grant DAAD 19-01-1-0406 and by NSF grant ANI-0105985.

References
1. IEEE standard 802.11: Wireless LAN medium access control and
physical layer specifications (1999).
2. R. C. Bose, An affine analogue of Singer’s theorem, Journal of the
Indian Mathematical Society 6 (1942) 1–5.
3. I. Chlamtac and A. Faragó, Making transmission schedules immune to topology changes in multi-hop packet radio networks,
IEEE/ACM Transactions on Networking 2(1) (1994) 23–29.
4. W. Chu, C. J. Colbourn and V. R. Syrotiuk, Slot synchronized
topology-transparent scheduling for sensor networks, Computer
Communications 29(4) (2006) 421–428.
5. W. Chu, C. J. Colbourn and V. R. Syrotiuk, Transparent scheduling, synchronization and maximum delay, in Proceedings of the
18th International Parallel and Distributed Processing Symposium
(IPDPS’04), (2004) pp. 223–228.
6. W. Chu and S. W. Golomb, A new recursive construction for optical
orthogonal codes, IEEE Transactions on Information Theory IT-49
(2003) 3072–3076.
7. C. J. Colbourn and J. H. Dinitz (editors) CRC Handbook of Combinatorial Designs (CRC Press 1996).
8. C. J. Colbourn, J. H. Dinitz and D. R. Stinson, Applications of combinatorial designs to communications, cryptography, and networking, in Surveys in Combinatorics, J. D. Lamb and D. A. Preece,
(Eds.), pp. 37–100. London Mathematical Society, Lecture Note
Series 267 (1999).
9. C. J. Colbourn, A. C. H. Ling and V. R. Syrotiuk, Cover-free families and topology-transparent scheduling for MANETs, Designs,
Codes, and Cryptography 32(1–3) (2004) 35–65.
10. C. J. Colbourn and V. R. Syrotiuk, Scheduled persistence for
medium access control in sensor networks, in Proceedings of the
First IEEE International Conference on Mobile Ad-hoc and Sensor
Systems (MASS’04), (2004) pp. 264–273.
11. C. J. Colbourn, V. R. Syrotiuk and A. C. H. Ling, Steiner systems for
topology-transparent access control in MANETs. in Proceedings
of the Second International Conference on Ad Hoc Networks and
Wireless (AdHoc Now’03) (2003) pp. 247–258.
12. D. -Z. Du and F. K. Hwang, Combinatorial Group Testing and Its
Applications, volume 12 of Series on Applied Mathematics. 2nd
edition (World Scientific, 2000).
13. Digital Fountain, Inc. Breakthrough reliable transport technology
for data and live streaming delivery over imperfect networks, Technology Licensing White Paper, (2004).
14. P. Erdós, P. Frankl and Z. Fúredi, Families of finite sets in which no
set is covered by the union others, Israel J. Math. 51 (1985) 79–89.
15. L. Hu, Topology control for multihop packet radio networks,
IEEE Transactions on Communications 41(10) (1993) 1471–
1481.
16. J.-H. Ju and V. O. K. Li, An optimal topology-transparent scheduling method in multihop packet radio networks, IEEE/ACM Transactions on Networking 6(3) (1998) 298–306.
17. W. H. Kautz and R. C. Singleton, Nonrandom binary superimposed
codes, IEEE Transactions on Information Theory IT-10 (1964) 363–
377.

Springer

690

Wireless Netw (2006) 12:681–690

18. M. G. Luby. LT Codes, in Proceedings of the 43rd Symposium on
Foundations of Computer Science (FOCS’02) (2002) pp. 271–280.
19. C. E. Perkins, (ed.), Ad Hoc Networks (Addison-Wesley, Reading,
MA, 2000).
20. V. Rajendran, K. Obraczka and J. J. Garcia-Luna-Aceves, Energyefficient, collision-free medium access control for wireless sensor
networks, in Proceedings of the 1st International ACM Conference
on Embedded Networked Sensor Systems (SenSys’03), (2003) pp.
181–192.
21. V. R. Syrotiuk, C. J. Colbourn and A. C. H. Ling, Topologytransparent scheduling for MANETs using orthogonal arrays, in
Proceedings of the 2003 Joint Workshop on Foundations of Mobile
Computing (DIAL-M/POMC’03) (2003) pp. 43–49.
22. V. R. Syrotiuk, C. J. Colbourn and S. Yellamraju, Rateless
forward error correction for topology-transparent scheduling.
Preprint.
23. P. J. Dukes, C. J. Colbourn and V. R. Syrotiuk, Topology-transparent
scheduling for energy limited ad hoc networks, in Proceedings of the
First IEEE Workshop on Foundations and Algorithms for Wireless
Networking (FAWN’06) (March 2006) pp. 85–90.
24. A. Woo and D. E. Culler, A transmission control scheme for media
access in sensor networks, in Proceedings of the 7th Annual International ACM Conference on Mobile Networking and Computing
(Mobicom’01) (2001) pp. 221–235.
25. R. Zheng, C.-J. Hou and L. Sha, Asynchronous wakeup for ad
hoc networks, in Proceedings of the 4th ACM International Symposium on Mobile Ad Hoc Networking and Computing (Mobihoc’03),
(2003) pp. 35–45.
Wensong Chu received his M.S. in Applied
Mathematics from Shanghai Jiao Tong University, China, in 1993; received his M.S. in
Computer Networks (Electrical Engineering)
from the University of Southern California in
2000; received his Ph.D. in Mathematics from
the University of Southern California in 2002.
He was with the Department of Computer Science and Engineering at Arizona State University as a post-doctoral fellow from 2002 to

Springer

2003. Currently he is doing research at the CMS Bondedge in California.
His research interests include sequence designs for communications,
combinatorial coding methods, mobile ad hoc networks and sensor
networks, financial engineering and combinatorial design theory.
Charles J. Colbourn was born in Toronto,
Canada in 1953. He completed his B.Sc. degree at the University of Toronto in 1976,
M.Math. at the University of Waterloo in 1978,
and Ph.D. at the University of Toronto in 1980,
all in computer science. He has held faculty
positions at the University of Saskatchewan,
the University of Waterloo, and the University
of Vermont, and is now Professor of Computer
Science and Engineering at Arizona State University. He is co-editor of the CRC Handbook of Combinatorial Designs
and author of Triple Systems and The Combinatorics of Network Reliability, both from Oxford University Press. He is editor-in-chief of the
Journal of Combinatorial Designs. His research concerns applications of
combinatorial designs in networking, computing, and communications.
Violet R. Syrotiuk earned the Ph.D. degree in Computer Science from the University of Waterloo (Canada) in 1992. She joined
Arizona State University in 2002 and is currently an Assistant Professor of Computer Science and Engineering. Dr. Syrotiuk’s research
is currently supported by three grants from the
National Science Foundation, and contracts
from Los Alamos National Laboratory, and
the Defence Science and Technology Organisation in Australia. She serves on the Editorial Board of Computer
Networks, and on the Technical Program Committee of several major
conferences including MobiCom and Infocom. Her research interests
include mobile ad hoc and sensor networks, in particular MAC protocols with an emphasis on adaptation, topology-transparency, and energy
efficiency, dynamic spectrum utilization, mobile network models, and
protocol interaction and cross-layer design. She is a member of the
ACM and the IEEE.

Topology-Transparent Duty Cycling for Wireless Sensor Networks
Yu Chen1 , Eric Fleury2 and Violet R. Syrotiuk3
1,2

ARES/INRIA
INSA de Lyon, France
1
Yu.Chen@inrialpes.fr, 2 Eric.Fleury@inria.fr

Abstract
Our goal is to save energy in wireless sensor networks
(WSNs) by periodic duty-cycling of sensor nodes. We schedule sensor nodes between active (transmit or receive) and
sleep modes while bounding packet latency in the presence
of collisions. In order to support a dynamic WSN topology,
we focus on topology-transparent approaches to scheduling; these are independent of detailed topology information. Much work has been done on topology-transparent
scheduling in which all nodes are active. In this work, we
examine the connection between topology-transparent dutycycling and such non-sleeping schedules. This suggests a
way to construct topology-transparent duty-cycling schedules. We analyse the performance of topology-transparent
schedules with a focus on throughput in the worst case.
A construction of topology-transparent duty-cycling schedules based on a topology-transparent non-sleeping schedule
is proposed. The constructed schedule achieves the maximum average throughput in the worst case if the given nonsleeping schedule satisfies certain properties.

1

Introduction

Wireless sensor networking has been a growing research
area for the last years. It has a wide range of potential applications, such as environment monitoring, smart
spaces, medical systems and robotic exploration. In sensor networks, sensor nodes are normally battery-operated
and energy efficiency has become one of the most important constraints on sensor networks [1, 12]. Studies
have identified that idle listening is a significant consumer
of power [17, 14, 24, 21, 26, 15]. Previous works (e.g.,
1,2 This work is partly supported by the European Commission, project
IST-15964. The views given herein represent those of the authors and may
not necessarily be representative of the views of the project consortium as
a whole.
c
1-4244-0910-1/07/$20.00 2007
IEEE.

3

Computer Science& Engineering
Arizona State University
syrotiuk@asu.edu

[24, 25, 4, 15]) show that, in networks where the traffic load
is light most of the time, energy efficiency can be achieved
by periodic duty cycling of sensor nodes, that is, scheduling
sensor nodes between active and sleep mode.
An efficient synchronization mechanism is required by
most duty cycling schemes (e.g., [24, 15]). Compared to
a TDMA scheme, duty cycling schemes require a much
looser synchronization. This low precision requirement enables us to save energy by reducing message exchanges for
synchronization. Efficient synchronization protocols have
been proposed for sensor networks (e.g., [8, 11, 20, 23, 10]);
in particular, works have been done on synchronization for
duty cycling (e.g., [23, 10]). In this work, we assume an efficient synchronization scheme is available and we describe
system behavior in terms of time slots.
Although light traffic networks are the scenarios for
which duty cycling schemes are primarily considered, it
does not mean collision is no longer a concern. Consider
a network in which each node is scheduled to be awake
in one of k slots. Since a node has to wait until the receiver wakes up before it can forward the packet, transmissions from neighbors, which were distributed in k slots, now
happen in one slot, making a collision very likely. In this
work, we aim to save energy by scheduling periodic nodes’
duty cycles while preserving communication connectivity
and bounding packet latency in the presence of collisions.
In order to handle dynamic topology, we focus on
topology-transparent approaches that are independent of
topology changes. Given a set of networks N , we say a
schedule is topology-transparent with respect to N if, for
any network in N , it allows each node to transmit without collisions to each neighbor node infinitely often; the
range of N represents the level of transparency. Such an
approach tolerates topology changes since for every possible topology, given the same topology-transparent schedule,
connectivity of each link is guaranteed. As existing works
on topology-transparent schedules [2, 13, 3, 6], our work
focuses on topology-transparency in networks where the
number of nodes and node degrees are no more than given

bounds. Research has been done on topology-transparent
schedules where no node is scheduled to sleep [2, 13, 3];
we refer to such schedules as non-sleeping schedules.
In this work, we consider duty cycling of sensor nodes
which aims to save energy by switching nodes between active and sleep mode. Letting αT and αR be parameters that
capture applications’ requirement on energy efficiency, we
focus on schedules in which the number of nodes that are allowed to transmit (receive resp.) per slot is no more than αT
(αR resp.); we call such a schedule an (αT , αR )-schedule.
Such schedules have been considered in [6], where the
requirements on topology-transparent (αT , αR )-schedules
are described by a general combinatorial model and a graph
construction algorithm is examined with the focus on a special type of schedules in which the number of nodes transmitting and receiving per slot are equal. Different from [6],
our work focuses on general schedules and has three main
contributions.
First, we examine in section 4 the connection between
topology-transparent (αT , αR )-schedules and non-sleeping
schedules. Our analysis indicates that, given bounds on
the number of nodes and node degrees, a necessary condition for the existence of a topology-transparent (αT , αR )schedule, for any αT and αR , is the existence of a topologytransparent non-sleeping schedule; furthermore, any construction of a topology-transparent (αT , αR )-schedule involves the construction of a topology-transparent nonsleeping schedule.
Secondly, we present our analyses in section 5 on schedules’ performance; as most works on topology-transparent
schedules (e.g., [13, 3]), we consider throughput in the
worst case, that is, each node has the maximum degree
and each neighbor has a packet to transmit. We show that
the average throughput in the worst case only depends on
the number of nodes that are allowed to transmit and receive per slot. An upper bound on the average throughput,
together with the optimal numbers of transmitters and receivers per slot to achieve this upper bound, is given for
both general schedules and (αT , αR )-schedules for given
αT and αR . Our analyses indicate that a necessary condition for the existence of a topology-transparent (αT , αR )schedule to achieve this upper bound is the existence of a
topology-transparent non-sleeping schedule that has certain
properties.
Thirdly, we investigate in section 6 whether a topologytransparent non-sleeping schedule (that has the appropriate properties) can be converted to a topology-transparent
(αT , αR )-schedule (that has good performance). This is
motivated by our observation in sections 4 and 5 that a necessary condition of the existence of a topology-transparent
(αT , αR )-schedule (that has good performance) is the existence of a non-sleeping topology-transparent schedule
(that satisfies certain properties), and any construction of a

topology-transparent (αT , αR )-schedule involves the construction of a topology-transparent non-sleeping schedule.
Our answer to this question is positive and we present a construction of an (αT , αR )-schedule based on a non-sleeping
schedule. Such a conversion is feasible since much work
has been done on the construction of topology-transparent
non-sleeping schedules (e.g. [2, 13, 22, 3]), and it has
been pointed out in [22, 3] that topology-transparent nonsleeping schedules can be constructed by cover-free families, which have been well investigated by numerous researchers (e.g., [9, 7, 16, 19, 18, 5]).
Our construction is very straightforward and it shows
good properties. We prove that given any topologytransparent non-sleeping schedule, a topology-transparent
(αT , αR )-schedule can be constructed by our approach for
any αT and αR . The performance of the constructed schedule depends on the number of transmitters per slot in the
non-sleeping schedule — given n and D, the constructed
schedule is optimal in terms of average worst-case throughput if the number of transmitters
 perslot in the non-sleeping
}, otherwise the larger
schedule is at least min{αT , n−D
D
is the minimum number of transmitters per slot, the better
average throughput can be achieved. We also give a lower
bound on the minimum throughput.

2 Related work
Research has been done on topology-transparent nonsleeping schedules [2, 13, 22, 3]. These works aim to guarantee communication between any pair of adjacent nodes in
the presence of collisions. It is pointed out in [22, 3] that
topology-transparent non-sleeping schedules can be constructed by a cover-free family, and the constructions in
[2, 13] are indeed to construct a cover-free family using
an orthogonal array. Cover-free families were first introduced in [9] and have been considered in different subjects
such as information theory, combinatorics and group testing by numerous researchers (e.g., [7, 16, 19, 18, 5]). All
these research results provide a strong base for the construction of a topology-transparent duty cycling based on
a topology-transparent non-sleeping schedule. The details
of how to construct non-sleeping schedules and cover-free
families are out of the scope of this paper; see [3, 5] for
more information.
Topology-transparent duty cycling which aims to
achieve energy efficiency by scheduling nodes to sleep was
first considered in [6], in which a general combinatorial
model is described. In [6], a graph construction algorithm
is examined with the focus on a special type of schedules in
which the number of nodes transmitting and receiving per
slot are equal. Note such schedules are optimal when the
cost to transmit and receive are the same order of magnitude; furthermore, the number of interferences is bounded

in the constructed schedules. In this work, we focus on general cases and a different construction is considered.
Throughput in the worst case has been investigated in
[13, 3] for topology-transparent non-sleeping schedules that
are constructed in certain ways. The focus in [13] is on
schedules constructed using polynomial functions of degree
k mod p; note polynomial function is only one of the standard constructions of cover-free family based on orthogonal arrays. The focus in [3] are on schedules based on
cover-free families constructed from orthogonal arrays and
Steiner systems. Different from these works, we consider
throughput for general schedules; by saying general schedules, we mean there is no constraint on how schedules are
constructed, schedules can be topology-transparent or not,
and schedules can be non-sleeping or not.

packet transmissions might fail due to many reasons. We
restrict our attention to failures caused by collisions — by
saying node x is guaranteed to successfully transmit to node
y in some slot, we mean in this slot y is eligible to receive
and x is the only node in y’s neighborhood that is allowed
to transmit. Given two adjacent nodes x and y, if there exist
slots in which node x is guaranteed to successfully transmit
to node y, we say the connectivity from node x to y is guaranteed. As most works on topology-transparency, given two
parameters n and D, 2 ≤ D ≤ n, we consider a class of
networks, denote by NnD , that consist of at most n nodes,
denoted by Vn , and in which node degrees are no more than
D.

3

In this section we consider the requirements on
topology-transparent schedules. Informally, a schedule is
topology-transparent if the connectivity between any pair
of adjacent nodes is guaranteed in any network where the
number of nodes and node degrees are bounded by given
values. The requirement on topology-transparent duty cycling has been proposed in [6]. Here we give an equivalent requirement which presents a connection between
topology-transparent (αT , αR )-schedules and non-sleeping
schedules. This connection implies that any construction of
a topology-transparent (αT , αR )-schedule involves the construction of a topology-transparent non-sleeping schedule.
It also suggests a way to construct a topology-transparent
(αT , αR )-schedule based on a topology-transparent nonsleeping schedule.
Since our construction is based on a topologytransparent non-sleeping schedule, we present in Requirement 1 the requirement proposed in [3] on topologytransparent non-sleeping schedules. Given a schedule
T, R, a node x and a set Y of nodes, we define a denotation to represent the set of slots in which node x is guaranteed to successfully transmit to a node y ∈ Y whose neighborhood is Y − {y} ∪ {x}. Intuitively, in each of these
slots, x is the only node that is allowed to transmit among
the neighbors of y.


System model

We assume time is structured into discrete units called
slots. A schedule of node activities is represented by a pair
T, R, where T and R are two disjoint arrays with the same
length, say L, such that ∀i ∈ [0, L − 1], T [i] ⊆ V and
R[i] ⊆ V ; T [i] and R[i] are the sets of nodes that are eligible to transmit and receive respectively in slots i + Ll,
l = 0, 1, . . ., while other nodes turn off their radio and stay
in sleep mode. We say T is the transmission schedule and
R is the reception schedule. We call the L continuous slots
lL, lL + 1, . . . , lL + L − 1, ∀l ≥ 0, a frame, and L is the
frame length. Given a schedule T, R and a node x, we
denote the set of slots in which x is allowed to transmit and
receive by tranT ,R (x) = {i ∈ [0, L − 1]|x ∈ T [i]} and
recvT ,R (x) = {i ∈ [0, L − 1]|x ∈ R[i]} respectively. The
subscript T, R is omitted when it is clear from context.
In this work, our goal is to design a schedule of nodes’
activities where nodes are put into sleep mode to meet applications’ requirement on energy saving. We use two parameters αT and αR to describe applications’ requirement on
energy efficiency: the maximum number of nodes that are
allowed to transmit and receive per slot are no more than
αT and αR respectively. Given αT and αR , we aim to design a schedule T, R that has the desirable property, that
is, ∀i ∈ [0, L − 1], |T [i]| ≤ αT and |R[i]| ≤ αR , where
L = |T | = |R|; we call such a schedule an (αT , αR )schedule. We say a schedule T, R is a non-sleeping schedule if all nodes are active in each slot, that is, ∀i ∈ [0, L−1],
T [i] ∪ R[i] = V . Since such a schedule can be completely
decided by T , we abbreviate the representation T, R to
T .
Our focus is on topology-transparent scheduling. Given
a set N of networks, a schedule is topology-transparent for
networks in N if it ensures that, for any network in N , each
node is guaranteed to successfully transmit a packet to each
adjacent node in at least one slot of each frame. In practice,

4 Requirements on topology-transparency

f reeSlotsT ,R (x, Y ) ≡ tranT ,R (x) −

tranT ,R (y)

y∈Y

Note given any two nodes x, y and any set S ⊆ Vn −
{x, y} of D − 1 nodes, there exists network in NnD such
that x and y are adjacent and y’s neighborhood is {x} ∪
S. Thus a topology-transparent schedule should guarantee ∀x, ∀y, ∀ S ⊆ Vn − {x, y} such that |S| = D − 1,
f reeSlots(x, S ∪ {y}) 	= ∅, which is equivalent to ∀x, ∀
Y ⊆Vn − {x} such that |Y | = D, f reeSlots(x, Y ) 	= ∅.
On the other hand, if this condition is true, for any network

in NnD , given any two adjacent nodes x and y, denoting y’s
neighborhood by S ∪ {x}, we have f reeSlots(x, S ∪ {y})
⊆ f reeSlots(x, Y ) 	= ∅, where Y is some set of D nodes
such that S ∪ {y} ⊆ Y , thus the connectivity from x to y is
guaranteed. This requirement is formally addressed below.
Requirement 1 [3] A non-sleeping schedule T  ensures a
successful transmission in each frame between any pair of
adjacent nodes in any network in NnD provided that
• ∀x ∈ Vn , ∀ set Y ⊆ Vn − {x} of D nodes,
f reeSlotsT  (x, Y ) = ∅

We give in Requirement 2 the requirements proposed in
[6] on topology-transparent schedules where nodes might
switch to sleep mode. Intuitively, σ(x, y) denotes the set of
slots in which node x can successfully transmit to node y.
It is required at least one slot in σ(x, y) is collision-free for
any two nodes x and y under any possible neighborhood of
y.
Requirement 2 [6] A schedule T, R ensures a successful
transmission in each frame between any pair of adjacent
nodes in any network in NnD provided that
• ∀x, y ∈ V , x = y, and ∀ set of d ≤ D − 1 nodes
{y1 , . . . , yd } ⊆ Vn − {x, y},
d


σT ,R (yi , y) ⊇ σT ,R (x, y)

i=1

where, letting L = |T | = |R|, we define
σT ,R (a, b)

≡

{j ∈ [0, L − 1]|a ∈ T [j] ∧ b ∈ R[j]}

=

tranT ,R (a) ∩ recvT ,R (b)

Since much work has been done on topology-transparent
non-sleeping schedule, here we examine the connection
between topology-transparent non-sleeping schedules and
duty cycling. We propose a requirement equivalent to Requirement 2. Intuitively, given any node x and any set Y of
D nodes, for any yk ∈ Y , condition (1) requires the existence of slots in which x is the only node in yk ’s neighborhood that is allowed to transmit and condition (2) requires
yk is eligible to receive in at least one of these slots. Note
condition (1) is implied by condition (2); we write it separately to emphasize that condition (1) states that the nonsleeping schedule T  should be topology-transparent.
Requirement 3 A schedule T, R ensures a successful
transmission in each frame between any pair of adjacent
nodes in any network in NnD provided that
• ∀ x ∈ Vn and ∀ set of D nodes Y = {y0 , . . . , yD−1 } ⊆
Vn − {x},
f reeSlotsT ,R (x, Y ) = ∅

(1)

∀k∈[0,D−1], recvT ,R (yk ) ∩ f reeSlotsT ,R (x, Y ) = ∅

(2)

Theorem 1 Requirement 2 and Requirement 3 are equivalent.

Proof. We first prove if a schedule satisfies Requirement 2,
then it satisfies Requirement 3; we only need to prove condition (2) of Requirement 3, which implies condition (1).
Assume in contradiction that condition (2) is not true, that
is, ∃ node x and D nodes y0 , . . . , yD−1 , and k ∈ [0, D − 1],
such that recv(yk ) ∩ f reeSlots(x, {y0 , . . . , yD−1 }) = ∅.
By the definition of f reeSlots,
we have recv(yk )

∩ tran(x) − ∪D−1
tran(y
)
=
∅, which implies
i
i=0
D−1
recv(yk ) ∩ tran(x) ⊆ ∪i=0 tran(yi ), that is, σ(x, yk )
⊆ ∪D−1
i=0 tran(yi ). Now for any t ∈ σ(x, yk ), we prove
∃k  ∈ [0, D−1], k  	= k, such that t ∈ σ(yk , yk ) as follows:
since σ(x, yk )∩tran(yk ) = tran(x)∩recv(yk )∩tran(yk )
= ∅ and σ(x, yk ) ⊆ ∪D−1
we have
i=0 tran(yi ),
∃k  ∈ [0, D − 1], k  	= k, such that t ∈ tran(yk );
since t ∈ recv(yk ), we have t ∈ σ(yk , yk ). Thus we
prove ∪D−1
i=k,i=0 σ(yi , yk ) ⊇ σ(x, yk ), which contradicts to
Requirement 2.
Now we prove if a schedule satisfies Requirement 3,
then it satisfies Requirement 2. Consider ∀x, y ∈ V ,
x 	= y, and d ≤ D − 1 nodes y1 , . . . , yd ∈ Vn −
{x, y}. By condition (2) of Requirement 3, we have
recv(y) ∩ f reeSlots(x, {y1 , . . . , yd }) 	= ∅, which implies
σ(x, y) ∩ (tran(x) − ∪di=1 tran(yi )) 	= ∅. Letting t be
a slot in σ(x, y) ∩ (tran(x) − ∪di=1 tran(yi )), we have
t 	∈ ∪di=1 tran(yi ). Thus ∀i ∈ [1, d], t 	∈ σ(yi , y) and we
prove ∪di=1 σ(yi , y) 	⊇ σ(x, y).
Given any topology-transparent schedule T, R, Requirement 3 states that the non-sleeping schedule T  is also
topology-transparent, which implies that any construction
of a topology-transparent (αT , αR )-schedule involves the
construction of a topology-transparent non-sleeping schedule. Furthermore, condition (2) of Requirement 3 indicates that given a non-sleeping schedule, as far as connectivity is concerned, it is not necessary to keep all the
non-transmitting nodes active; instead, nodes can be scheduled to sleep provided that they are active in at least one of
the free slots. Based on this observation, we consider constructing a topology-transparent schedule in two steps: we
first construct a topology-transparent non-sleeping schedule, and then reduce the numbers of nodes transmitting
and receiving per slot without violating the topologytransparency requirement. In the sequel, we discuss in section 5 the throughput achievable in networks with the number of nodes and node degrees less than given bounds; then
we propose our construction in section 6, with the focus on
the second step since much work has been done on constructing topology-transparent non-sleeping schedules,

5

Upper bounds on throughput in NnD

where

In this section, we discuss the throughput of general
schedules and general (αT , αR )-schedules for networks in
NnD . Our focus is on throughput in the worst case, that is,
each node has D neighbors and each neighbor has a packet
to transmit in each of the slots in which it is allowed to transmit. We first give the definitions of the minimum throughput
in the worst case and the average throughput in the worst
case, then we present our analyses on the average throughput. We give upper bounds on the average throughput that
can be achieved by general schedules and general (αT , αR )schedules in the worst case, as well as the condition for a
schedule to achieve the upper bound.
Given any pair of adjacent nodes x, y, we consider the
number of guaranteed successful transmissions from x to y.
Letting S be the set of y’s neighbors other than x, we define TT ,R (x, y, S) as the set of slots in which transmissions
from x to y are guaranteed to be successful under schedule
T, R:
TT ,R (x, y, S) ≡ recvT ,R (y) ∩ f reeSlotsT ,R (x, {y} ∪ S)

Note TT ,R (x, y, S) ⊇ TT ,R (x, y, S  ) if S ⊆ S  . Since
we focus on throughput in the worst case, in our definition
of the minimum throughput, we only need to consider S
such that |S| = D − 1.
Definition 1 Given a schedule T, R, its minimum worstmin
case throughput T hrT
in NnD is defined below, where
,R
L = |T | = |R|:


min
T hrT
≡
,R

|TT ,R (x, y, S)|

min

L

∀x,y∈Vn ,S⊆Vn −{x,y},|S|=D−1

It is easy to see the average value of |TT ,R (x, y, S  )|
over all the S  such that |S  | ≤ D−1 is no less than
the average value of |TT ,R (x, y, S)| over all S such that
|S| = D−1. So the number of guaranteed successful transmissions in each frame from x to y averaged over all the
possible y’s neighborhoods in NnD is at least:

txT ,R (x, y) ≡

S⊆Vn −{x,y},|S|=D−1
n−2
D−1





|TT ,R (x, y, S)|

	

	

|TT ,R (x, y, S)|

x,y∈Vn S⊆Vn −{x,y},|S|=D−1

Since our focus is on throughput in the worst case, in
the sequel we abbreviate “throughput in the worst case” to
min
“throughput” for presentation simplicity. Note T hrT
,R
ave
and T hrT ,R are not defined particularly for topologytransparent schedules. A schedule T, R is topologymin
transparent if and only if T hrT
>0. If a schedule T, R
,R
min
=0, that is,
is not topology-transparent, we have T hrT
,R
there exists two nodes x, y and y’s neighborhood S such
that no slot exists in which the transmissions from x to
y is guaranteed to be successful; the average throughput
ave
can still be computed according to Definition 2.
T hrT
,R
Requirements 2 and 3 show whether a schedule is
topology-transparent depends on how nodes are scheduled
to transmit and receive. The theorem below states that the
average throughput only depends on the number of transmitters and receivers per slot; furthermore, higher average throughput can be achieved by allowing more nodes
to receive. So if there is no constraint on the numbers
of receivers and transmitters, the maximum throughput is
achieved by a non-sleeping schedule. Note it is not necessary true if only specific topologes are considered, as shown
by an example presented later in section 5.2.
Theorem 2 Given a schedule T, R, we denote L = |T | =
ave
of T, R in net|R|. The average throughput T hrT
,R
D
works Nn is



L−1
n−|T [i]|−1
|T
[i]|
·
|R[i]|
D−1
i=0
ave
n−2 
=
T hrT
,R
n(n − 1) D−1 L
Proof. We define CT ,R (i) as the set of tuples x, y, S
such that i ∈ TT ,R (x, y, S), where x, y are two different
nodes and S is any set of D − 1 nodes other than x and y.
Formally,
CT ,R (i) ≡ {x, y, S

|i ∈ TT ,R (x, y, S), where x, y ∈ Vn ,
x = y, S ⊆ Vn − {x, y}, |S| = D − 1}

ave
We define the average worst-case throughput T hrT
,R
of a schedule T, R in NnD as the ratio of the average number of txT ,R (x, y) over all pairs of nodes x and y to the
frame length.

Definition 2 Given a schedule T, R, its average worstave
case throughput T hrT
in networks in NnD is defined be,R
low, where L = |T | = |R|:

txT ,R (x, y)
FT ,R
∀x,y∈Vn
ave
n−2 
=
T hrT ,R ≡
n(n − 1)L

FT ,R ≡

n(n − 1)

D−1

L



We have FT ,R = i∈[0,L−1] |CT ,R (i)|. Since given i,
for x,y and S such that i ∈ TT ,R (x, y, S), x can be any
node in T [i], y can be any node in R[i], and S can be any
D − 1 nodes of those other than

 nodes in T [i] and y, we


[i]|−1


and the theorem
have CT ,R (i) = |T [i]| · |R[i]| n−|T
D−1
is proved.
In the rest of this section, we examine the maximum average throughput in NnD that can be achieved by general
schedules and by general (αT , αR )-schedules for given αT

and αR . Before that, we present two properties of funcn−x
x
 for integer x. These properties will
tion gn,D (x) = D
n−1
n

Proof. Given any schedule T, R, we have |R[i]| ≤ n −
|T [i]|, ∀i ∈ [0, L − 1]. By Theorem 2, we have

D

be used in our proofs and x will represent the number of
nodes that are allowed to transmit in a slot. Intuitively,
gn,D (x) represents the throughput of a non-sleeping schedule in which the number of transmitters per slot is fixed at
x.

L−1
ave
T hrT
,R

≤

nD
(1) ∀x ∈ [0, n − 1], gn,D (x) ≤ (n−D)(D+1)
D+1 .

 n−D   n−D 
(2) ∃x0 ∈
, D+1 , such that gn,D (x0 ) ≥
D+1
gn,D (x), ∀ x ∈ [0, n−1].

Property (1) is true since gn,D (x) = x



(n−(D−1)−x)
1
x
x


n−(D−1)
1
n−D



n−D



≤ x 1−

=x 1−

 

x D
n

1−

n

1
n−D



≤

n−1




... 1 −

...

x
n−(D−1)



nD D
(n−D)(D+1)D+1

. Property
(2) can be proved by showing the following properties for
x ≤ n − (D − 1): (a) gn,D (x) is monotonically increasing
up to some point and then monotonically decreasing, and
(b) gn,D (x) ≥ gn,D (x + 1) if and only x ≥ n−D
D+1 since
gn,D (x)
gn,D (x+1)

5.1

=

x(n−x)
(x+1)(n−D−x) .

An upper bound on average throughput

In this section, we consider the average throughput that
can be achieved in networks in NnD by general schedules,
where there is no constraint on the numbers of transmitters
and receivers per slot. The theorem below presents an upper
bound on the average throughput, as well as the condition
for a schedule to achieve this upper bound: the number of
transmitters in each slot is about n−D
D+1 and the number of
receivers in each slot is about n − n−D
D+1 .
Theorem 3 (An Upper Bound on Average Throughput of
General Schedules in NnD ) Given any schedule T, R, letave
ting T hrT
be its average throughput in networks in NnD ,
,R
we have




T hrT ,R ≤
ave

where
αT =

n−αT
D

αT

n

n−1 

≤

D

nDD
(n − D)(D + 1)(D+1)




 
 
 n−D  n− n−D
 n−D  , if  n−D  n− n−D
D+1
D+1
≥
D+1

D+1

 n−D 
D+1

D+1

D

D

, otherwise

Furthermore, defining T hr



≡

α
T




n−α
T
D

n(n−1 )
D


, we have

= T hr if and only if T, R is a non-sleeping
schedule such that ∀i ∈ [0, L − 1], |T [i]| = αT and
|R[i]| = n − αT , where L = |T | = |R|.

ave
T hrT,R



i=0

n(n − 1)

L−1

D

(n−x) (n−1−x)
n
n−1

=

i=0

L−1
=

|T [i]||R[i]|

i=0




n−|T [i]|−1
D−1

n−2 
D−1

L




|T [i]|(n − |T [i]|)
n(n − 1)
|T [i]|

n




n−1 
D

n−2 
D−1

n−|T [i]|
D





n−|T [i]|−1
D−1

L

=

L



L−1
1	
gn,D (|T [i]|)
L
i=0

Note |T [i]| ∈ [1, n − 1]. By property of function gn,D (x),
ave
nD D
we have T hrT
≤ (n−D)(D+1)
In order to maxD+1 .
,R
ave
imize T hrT ,R , gn,D (|T [i]|) should be maximum for all
i ∈ [0, L − 1]. By property of gn,D (x),



 the maximum
.
gn,D (|T [i]|) is achieved when |T [i]|∈ n−D
, n−D
D+1
D+1
Theorem 3 indicates only schedules in which all the
nodes are active can achieve the proposed upper bound.
Since the number of transmitters and receivers might be
constrained due to energy efficiency, we consider in the next
section the throughput of schedules with bounded numbers
of transmitters and receivers.

5.2

An upper bound on average throughput of (αT , αR )-schedules

When only connectivity between any pair of adjacent
nodes is considered, Requirement 3 shows it is not necessary to keep all the nodes active. However, Theorem 2
indicates that, the performance is affected by putting nodes
into sleep mode if we focus on the average throughput between all pairs of nodes for all the networks in NnD . It is
worth pointing out that, if only a specific topology is considered, it is possible to save energy by scheduling nodes to
sleep while preserving the same throughput. An example is
given in Figure 1, where nodes are denoted by the numbers
in circles and arrays T and R are given. We consider two
schedules T  and T, R: schedule T  is a non-sleeping
schedule and in schedule T, R some nodes are scheduled
to sleep. It is easy to see these two schedules have the same
throughput.
ave
Now we consider the average throughput T hrT
,R
D
of an (αT , αR )-schedule T, R
in
N
.
By
Theon



ave
=
rem 2, we have T hrT
,R
n−1−|T [i]| 
L−1
|T [i]|
α
D−1

≤ R i=0 n−2
=
n(n−1)

D−1

L

L−1
i=0

|T [i]|·|R[i]|
n(n−1)

αR L−1
nL

i=0

n−|T [i]|−1

n−2D−1

D−1

L

gn−1,D−1 (|T [i]|).

ave
≤
By properties of gn−1,D−1 (x), we have T hrT
,R

αR
n

4
3

5

1

0

slots

0

T

{0}

R {1,2,3,4}

1

2

3

4

{1}

{2,5}

{3}

{4}

{0,5}

{0,1}

{0}

{0}

number of transmitters in each slot is at least αT . Our construction indicates such a condition is also a sufficient condition.

2

Figure 1. An example of networks in which
throughput can be preserved when nodes are
scheduled to sleep

(n−1)(D−1)D−1
,
(n−D)DD

and the maximum of gn−1,D−1 (|T [i]|) is

 n−D   n−D 
, D
. Since |T [i]|
achieved when |T [i]| ∈
D
is constrained by the requirement that |T [i]| ≤ αT , we
have the following theorem on the average throughput of
an (αT , αR )-schedule in NnD networks. This theorem implies, in order to achieve the best average throughput, the
number of receivers in each slot should be as large as possible, while the number of transmitters should be as close to
n−D
D as possible.
Theorem 4 (An Upper Bound on Average Throughput of
(αT , αR )-schedules in NnD ). Given any (αT , αR )-schedule
ave
be its average throughput in netT, R, letting T hrT
,R
D
works in Nn , we have

ave
T hrT
≤
,R

αR αT




n−α
T −1
D−1

n(n − 1)



n−2  ≤
D−1

αR (n − 1)(D − 1)D−1
n(n − D)DD

where αT = min{αT , α}, and





 n−D  n− n−D
−1
−1
 n−D   n−D  n− n−D
D 
D 
α≡  D 
 n−D
D

if

D

D−1

≥

D

D−1

otherwise

Furthermore, defining T hrα R ,αT ≡

αR ·α
T


n−α −1 
T
D−1

n(n−1)(n−2
D−1 )

6 Our construction of topology-transparent
(αT , αR )-schedules
In this section, we present our construction of topologytransparent (αT , αR )-schedules.
Given a topologytransparent non-sleeping schedule, our goal is to reduce the
number of nodes that are allowed to transmit and receive
in each slot, while preserving the connectivity between any
pair of adjacent nodes.
In our construction, we first compute the optimal number
αT of transmitters per slot, then we construct an (αT , αR )schedule by calling function Construct(αT , αR , T ). In
this function, for each slot i, we divide T [i] into subsets T [i] = T0 ∪ . . . ∪ TkT −1 and V − T [i] into subsets Vn − T [i] = R0 ∪ . . . ∪ RkR −1 . Note subsets in
{Ti |i ∈ [0, kT − 1]} (subsets in {Ri |i ∈ [0, kR − 1]}
resp.) are not necessarily disjoint. Instead, in order to
achieve maximal throughput, we require each |Ti | to be as
close to αT as possible, and each |Ri | to be as close to αR
as possible. In the constructed schedule T̄ , R̄, we add
kT kR entries to guarantee that each subset of T [i] transmits to each subset of Vn − T [i]; in particular, we require
∀it ∈ [0, kT − 1] and ∀ir ∈ [0, kR − 1], ∃k such that
T̄ [k] = Tit and R̄[k] ⊆ Rir . If |Rir | < αR , we add
nodes in Vn − Tit to R[k] to get |R̄[k]| = αR , which is
feasible since Tit ≤ αT and αT + αR ≤ n. Note the way
to divide T [i] (line 3) and R[i] (line 4) and the way to add
nodes in Vn − Tit to Rir (line 8) are not unique, and the
specific way they are computed will not affect the correctness, frame length and average worst-case throughput of the
constructed schedule, as we show in Theorem 6, Theorem 7
and Theorem 8 respectively. The code is given in Figure 2.

, we

ave
= T hrα R ,αT if and only if ∀i ∈ [0, L − 1],
have T hrT,R
|R[i]| = αR and |T [i]| = αT .

7 Correctness and performance analyses

Theorem 4 presents an upper bound on the throughput
that is achievable by an (αT , αR )-schedule in NnD networks. An interesting question is whether there exists a
topology-transparent (αT , αR )-schedule that achieves this
upper bound. Requirement 3 indicates, given any topologytransparent (αT , αR )-schedule T, R, T  is a topologytransparent non-sleeping schedule, and Theorem 4 states,
in order to achieve the maximum average throughput, it is
required |T [i]|=αT , ∀i ∈ [0, |T |−1]. Thus a necessary condition for the existence of a topology-transparent (αT , αR )schedule that achieves this upper bound is the existence of
a non-sleeping topology-transparent schedule such that the

In this section, we present correctness proofs and performance analyses of our construction. Given any topologytransparent non-sleeping schedule T , we first show the
correctness of the schedule constructed by the algorithm in
Figure 2. Then we discuss the frame length and throughput of the constructed schedule. We show that the constructed schedule is optimal in terms of average throughput
if the topology-transparent non-sleeping
schedule
 T  sat
.
isfies ∀i ∈ [0, L − 1], |T [i]| ≥ min αT , n−D
D
We first consider the correctness of our construction. In
the following lemma, we show that the constructed schedule
is topology-transparent.

Input: integers n, D, αT , αR , and schedule T , such that n ≥ D ≥ 2,
αT + αR ≤ n, and T  is topology-transparent for networks in NnD .
Output: An (αT , αR )-schedule T̄ , R̄ that is topology-transparent in
networks in NnD .
Main Program:
• Let αT be the optimal number of transmitters per slot computed as in
Theorem 4.
• T̄ , R̄=Construct (αT , αR , T ) ;
• return T̄ , R̄;
Function Construct (αT , αR , T )
Input: integers αT , αR and a non-sleeping schedule T 
Output: T̄ , R̄
1 k=0;
2 for i = 0; i < |T |; i + +
3

4





|T [i]|
subsets T [i] = T0 ∪ . . . ∪ TkT −1 ,
α
T

such that |Ti | = min{αT , |T [i]|}, ∀i ∈ [0, kT − 1];
|R[i]|
subsets R[i] = R0 ∪
Divide R[i] = V − T [i] into kR = α
R

Divide T [i] into kT =





. . .∪RkR −1 , such that |Ri | = min{αR , |R[i]|}, ∀i ∈ [0, kR −1];
for it = 0; it < kT ; it + +
for ir = 0; ir < kR ; ir + +
T̄ [k] = Tit , R̄[k] = Rir , k + +;
if |Rir |<αR then Add αR −|Rir | nodes in
Vn −T̄ [k] to R̄[k];
9
endfor
10
endfor
11 endfor
5
6
7
8

Figure 2. The code of constructing a
topology-transparent
(αT , αR )-schedule
based on a topology-transparent nonsleeping schedule

Lemma 5 If T  is a topology-transparent non-sleeping
schedule for networks in NnD , then the schedule T̄ , R̄ constructed by function Construct(T , αT , αR ) in Figure 2 is
a schedule that is topology-transparent for networks in NnD .
Proof. We consider any node x ∈ Vn and any set Y ⊆
Vn −{x} of D nodes y0 , . . ., yD−1 . Since T  is a topologytransparent non-sleeping schedule, there exists t ∈ [0, |T | −
1], such that t ∈ f reeSlotsT  (x, Y ). That is, x ∈ T [t] and
∀i ∈ [0, D − 1], yi 	∈ T [t].
We consider yk , ∀k ∈ [0, D − 1]. Let Tit be the subset of T [t] such that x ∈ Tit in line 3 of Figure 2, and
Rit be the subset of R[t] = V − T [t] such that yk ∈
Rit in line 4 of Figure 2. Let t be an index such that
T̄ [t ] = Tit and R̄[t ] ⊇ Rir . Given ∀i = [0, D − 1], since
yi 	∈ T [t] and T̄ [t ] = Tit ⊆ T [t], we have yi 	∈ T̄ [t ],
that is, t 	∈ tranT̄ ,R̄ (yi ). Since x ∈ Tit = T̄ [t ],
we have t ∈ tranT̄ ,R̄ (x). So t ∈ tranT̄ ,R̄ (x) −
D−1
Since
i=0 tranT̄ ,R̄ (yi ) = f reeSlotsT̄ ,R̄ (x, Y ).

yk ∈ Rir ⊆ R̄[t ], we have t ∈ recvT̄ ,R̄ (yk ).
So t ∈ recvT̄ ,R̄ (yk ) ∩ f reeSlotsT̄ ,R̄ (x, Y ), that is,
recvT̄ ,R̄ (yk ) ∩ f reeSlotsT̄ ,R̄ (x, Y ) 	= ∅. Thus by Requirement 3, we prove T̄ , R̄ is a topology-transparent
schedule for NnD .
It is easy to see the number of transmitters in each slot is
no more than αT ≤ αT and the number of receivers in each
slot is no more than αR . Thus we prove the correctness of
our construction.
Theorem 6 (Correctness). The schedule constructed by
the algorithm in Figure 2 is an (αT , αR )-schedule that is
topology-transparent for networks in NnD .
Our construction also indicates that, given any αT , αR ,
≤ n, if a topology-transparent non-sleeping schedule T  such that |T [i]| ≥ αT , ∀i ∈ [0, |T | − 1] is available,
then a topology-transparent schedule such that the number
of transmitters in each slot is exactly αT and the number of
receivers in each slot is exactly αR can be constructed by
calling function Construct(αT , αR , T ).
The frame length of the constructed schedule can be obtained directly from the code.
αT +αR

Theorem 7 (Frame Length). The frame length of the
schedule
constructed by the algorithm
2 is

  in Figure

L−1 
 |T [i]|   n−|T [i]| 
Max
n−Min
≤ α
L, where
i=0
α
αR
αR
T
T
L = |T |, Max = max{|T [i]|, ∀i ∈ [0, L − 1]} and Min =
min{|T [i]|, ∀i ∈ [0, L − 1]}.
In order to compare the average throughput of the constructed (αT , αR )-schedule in NnD networks to the maximum average throughput, we define function

r(x) ≡

x
αT

 D−1

i=1

n−i−x
n − i − αT



where αT is computed as in Theorem 4. Note αT ≈ min
{αT , n−D
D } only relies on n, D and αT . Given an (αT , αT )schedule T, R such that the number of receivers per slot is
αR , the optimality of T, R in terms of average throughput
can be represented as follows:
ave
T hrT
,R

T hrα
R ,αT

=

L−1
1 	
r(|T [i]|)
L
i=0

where T hrα R ,αT is the maximum average throughput that
is achievable by an (αT , αR )-schedule (see Theorem 4).
The average throughput of our construction can be computed by Theorem 2. We present below a lower bound on
the ratio of our average throughput to the maximum average throughput, which indicates the constructed schedule

is optimal in terms of average throughput if the number
of transmitters
per
in the non-sleeping schedule is at
 slot

, otherwise the larger is the minleast min αT , n−D
D
imum number of transmitters per slot, the better average
throughput can be achieved.
Theorem 8 (Average Throughput and Optimality). Consider the construction in Figure 2. We have the following lower bound on the ratio of the average throughput
T hrave
of T̄ , R̄ to the maximum average throughput
T̄ ,R̄

T hrαT ,αR that is achievable by (αT , αR )-schedules in NnD
(see Theorem 4).
T hr ave

T̄ ,R̄


T hrα
T ,αR

≥

r(Min )|A1 | + c|A2 |
|A1 | + c|A2 |

where
• Min = min{|T [i]|, i ∈ [0, L − 1]}, where L = |T |,

Theorem 9 (Minimum Throughput). Consider the construction in Figure 2. Denoting L = |T | and L̄ =
|T̄ | = |R̄|, we have the following relation on the minimum
min
of T  and the minimum throughput
throughput T hrT

min
T hrT̄ ,R̄ of T̄ , R̄ in networks in NnD :

• A1 = {i | |T [i]|<αT } and A2 = {i | |T [i]|≥αT },
 n 
−1
αm
 , where αm = max{αT , αR }.
• c =  n−M
in
αR

In particular, T hrT̄ ,R̄ = T hrα T ,αR if Min ≥ αT .
Proof. Given
 ∀k ∈ [0, L − 1], let Ik be the set of indices
n−|T [k]|
of the |Tα[k]|
entries in T̄ , R̄ that are computed

αR
T

in lines 5-10 of function Construct() in the k’th iteration of
the for-loop in lines 2-11 in Figure
L−1 2. Note Ik is disjoint for
different i and [0, L̄ − 1] = i=0 Ik , where L̄=|T̄ |=|R̄|.
Letting Ā1 =∪k∈A1 Ik and Ā2 =∪k∈A2 Ik , we have [0, L̄ −
1] = Ā1 ∪Ā2 . Denoting xk = |T [k]|, we have (1)
 ∀i ∈
T̄ [i] =
[0, L̄ − 1], R̄[i] = αR , (2) ∀k ∈A1 and
i
∈
I
,
k


xk , and (3) ∀k ∈ A2 and i ∈ Ik , T̄ [i] = αT . Thus ∀k ∈
A1, ∀i ∈ Ik , r(T̄ [i]) = r(xk ), and ∀k ∈ A2 , ∀i ∈ Ik ,
r(T̄ [i]) = 1. So we have
T hrave
T̄ ,R̄

T hrα
T ,αR

=
=
=



1
L̄


i∈Ik

k∈A1


k∈A1

L̄−1
i=0





r(T̄ [i])

 



r( T̄ [i] )+

|Ā1 |+|Ā2 |

r(xk )|Ik |+|Ā2 |

|Ā1 |+|Ā2 |



k∈A2

≥



i∈Ik



r( T̄ [i] )

r(Min )|Ā1 |+|Ā2 |

|Ā1 |+|Ā2 |

2|
The theorem can be proved if ||Ā2 || ≥ c |A
, which can be
|A1 |
1


 
in
|A1 |, since
shown because (1) we have Ā1  ≤ n−M
 
 αR

n−xk
n−Min
≤ αR ; and (2) we have
∀k ∈ A1 , |Ik | =
 αR
 
  
 n 
xk
Ā2  ≥
−
1
|A
|,
since
∀k
∈
A
,
|I
|
=
2
2
k
α
T
 αm  
  

n−xk
xk
n−xk
n
≥
≥
−
1.
αR
αm
αm
αm

Ā

We have shown in Section 5 that a necessary condition for the existence of a topology-transparent (αT , αR )schedule that achieves the maximum average throughput
T hrα R ,αT is the existence of a non-sleeping topologytransparent schedule such that the number of transmitters
in each slot is at least αT . Theorem 8 indicates such a condition is also a sufficient condition.
Now we discuss the minimum throughput. We give a
lower bound in Theorem 9 on the minimum throughput of
the (αT , αR )-schedule constructed by the algorithm in Figure 2. In our proof, we consider the number of slots in
which the transmissions from x to y are guaranteed successful for any pair of adjacent nodes x, y and any neighborhood
of y. We prove that the number of such slots in each frame
of the constructed schedule is no less than that of the original schedule. The degradation of the minimum throughput
is due to a smaller number of active nodes.

T hrmin
≥
T̄ ,R̄

min
T hrT
L
min
 
T hrT
≥ 


n−Min
Max
L̄
α
T

αR

where Max = max {|T [i]|, ∀i ∈ [0, L − 1]} and Min =
min {|T [i]|, ∀i ∈ [0, L − 1]}.
Proof. By Theorem 7 and Definition 9, the theorem can
be proved by showing that ∀x, y, ∀S ⊆ Vn − {x, y} such
that |S| = D − 1, |TT̄ ,R̄ (x, y, S)| ≥ |TT,R (x, y, S)|. Given
∀i ∈ TT,R (x, y, S), we have x ∈ T [i], y ∈ Vn − T [i] and
S ⊆ Vn − T [i]. Let Ii be the set of indices of the kTi · kRi
entries in T̄ and R̄ that are computed in lines 5-10 of the
ith iteration of the for-loop in lines 2-11 of Figure 2. Let
Tit be the subset of T [i] such that x ∈ Tit (line 3) and Rir
be the subset of Vn − T [i] such that y ∈ Rir (line 4). Let
t ∈ Ii such that T̄ [t ] = Tit and R̄[t ] ⊇ Rir . We have
S ⊆ Vn − T [i] ⊆ Vn − Tit . Thus t ∈ TT̄ ,R̄ (x, y, S).
Since Ii is disjoint for different i, we prove |TT̄ ,R̄ (x, y, S)|
≥ |TT,R (x, y, S)|.
In some scenarios, applications require balanced energy
consumption in the sense that (1) the same number of nodes
are active in each slot, and (2) the percentage of slots in
which node x is active is the same for all x ∈ Vn . It is
easy to verify that if energy consumption is balanced in the
non-sleeping schedule T , then these two properties can be
preserved in the constructed schedule by modifying the division of T [i] and R[i] (lines 3-4) to satisfy that the number
of subsets Ti (Ri resp.) such that node x ∈ Ti (x ∈ Ri
resp.) is the same for all x ∈ T [i] (x ∈ R[i] resp.); it is easy
to see such divisions exist.

8

Conclusion

We consider topology-transparent duty cycling in wireless sensor networks. The connection between topologytransparent duty cycling and non-sleeping schedules is investigated and analyses on throughput are presented. We
propose a construction of topology-transparent duty cycling
schedules based on a topology-transparent non-sleeping
schedule. The constructed schedule is optimal in terms
of average throughput if the non-sleeping schedule satisfies
certain conditions.

References
[1] I.F. Akyildiz, W. Su, Y. Sankarasubramaniam, and E. Cayirci.
Wireless sensor networks: a survey. Computer Networks,
38(4):393–422, 2002.
[2] I. Chlamtac and A. Faragò. Making transmission schedules
immune to topology changes in multi-hop packet radio networks. IEEE/ACM Trans. Netw., 2(1):23–29, 1994.
[3] C.J. Colbourn, A.C.H. Ling, and V.R. Syrotiuk. Cover-free
families and topology-transparent scheduling for MANETs.
Designs, Codes, and Cryptography, 32(1-3):35–65, 2004.
[4] O. Dousse, P. Mannersalo, and P. Thiran. Latency of wireless sensor networks with uncoordinated power saving mechanisms. In MobiHoc ’04: Proceedings of the 5th ACM international symposium on Mobile ad hoc networking & computing, 2004.
[5] D. Du and F. Hwang. Combinatorial Group Testing and its
Applications. World Scientific Publishing Co. Pte. Ltd., second edition, 2000.
[6] P.J. Dukes, C.J. Colbourn, and V.R. Syrotiuk. Topologytransparent schedules for energy limited ad hoc networks. In
Proc. the IEEE International Workshop on Foundations and
Algorithms for Wireless Networking (FAWN’06), 2006.
[7] A. D’yachkov, V. Rykov, and A. Rashad. Superimposed
distance codes. Problems Control and Information Theory,
18(1989):237–250, 1989.
[8] J. Elson, L. Girod, and D. Estrin. Fine-grained network time
synchronization using reference broadcasts. In Proceedings
of the fifth symposium on operating systems design and implementation (OSDI), 2002.
[9] P. Erdos, P. Frankl, and Z. Furedi. Families of finite sets in
which no set is covered by the union of r others. Isreal Journal
of Mathematics, 51:75–89, 1985.
[10] S. Ganeriwal, D. Ganesan, H. Shim, V. Tsiatsis, and
M.B. Srivastava. Estimating clock uncertainty for efficient
duty-cycling in sensor networks. In ACM Sensys, 2005.
[11] S. Ganeriwal, R. Kumar, and M. Srivastava. Timing sync
protocol for sensor networks. In ACM Sensys, 2003.
[12] C.E. Jones, K.M. Sivalingam, P. Agrawal, and J. Chen. A
survey of energy efficient network protocols for wireless networks. Wireless Networks, 7(4):343–358, 2001.
[13] J.H. Ju and V.O.K. Li. An optimal topology-transparent
scheduling method in multihop packet radio networks.
IEEE/ACM Trans. Netw., 6(3):298–306, 1998.

[14] E.S. Jung and N.H. Vaidya. An energy efficient MAC protocol for wireless LANs. In Proc. IEEE INFOCOM. 2002.
[15] G. Lu, N. Sadagopan, B. Krishnamachari, and A. Goel. Delay efficient sleep scheduling in wireless sensor networks. In
Proc. IEEE INFOCOM, 2005.
[16] M. Ruszinko. The upper bound of the size of r-cover-free
families. J. Comb. Theory, Ser. A, 66:302–310, 1994.
[17] S. Singh and C.S. Raghavendra. PAMAS: Power aware
multi-access protocol with signaling for ad hoc networks.
SIGCOMM Comput. Commun. Rev., 28(3):5–26, 1998.
[18] J. Staddon, D. Stinson, and R. Wei. Combinatorial properties
of frameproof and traceability codes. IEEE Tran. Information
Theory, 47:1042–1049, 2000.
[19] D.R. Stinson and R. Wei. Combinatorial properties and
constructions of traceability schemes and frameproof codes.
SIAM Journal on Discrete Mathematics, 11(1):41–53, 1998.
[20] W. Su and I.F. Akyildiz. Time-diffusion synchronization protocol for wireless sensor networks. IEEE/ACM Trans. Netw.,
13(2):384–397, 2005.
[21] T.van Dam and K. Langendoen. An adaptive energy-efficient
MAC protocol for wireless sensor networks. In ACM Sensys,
2003.
[22] V.R. Syrotiuk, C.J. Colbourn, and A.C.H. Ling. Topologytransparent scheduling in MANETs using orthogonal arrays.
In Proc. of the DIALM-POMC Joint Workshop on Foundations of Mobile Computing, 2003.
[23] G. Werner-Allen, G. Tewari, A. Patel, M. Welsh, and R. Nagpal. Firefly-inspired sensor network synchronicity with realistic radio effects. In ACM Sensys, 2005.
[24] W. Ye, J. Heidemann, and D. Estrin. An energy-efficient
MAC protocol for wireless sensor networks. In Proc. IEEE
INFOCOM. 2002.
[25] W. Ye, J. Heidemann, and D. Estrin. Medium access control with coordinated, adaptive sleeping for wireless sensor
networks. Technical Report ISI-TR-567, USC, Jan. 2003.
[26] R. Zheng, J.C. Hou, and L. Sha. Asynchronous wakeup for
ad hoc networks. In MobiHoc ’03: Proceedings of the 4th
ACM international symposium on Mobile ad hoc networking
computing, 2003.

MERIT: A Unified Framework for Routing Protocol
Assessment in Mobile Ad Hoc Networks
András Faragó

Violet R. Syrotiuk

Department of Computer Science
University of Texas at Dallas
Richardson, Texas 75083-0688

Department of Computer Science
University of Texas at Dallas
Richardson, Texas 75083-0688

farago@utdallas.edu

syrotiuk@utdallas.edu
In this paper we focus on the assessment of routing protocols in mobile ad hoc networks (manets). A manet is a
self-organizing collection of mobile wireless nodes without
supporting infrastructure. The study of these networks is
already mature, dating back to as early as the 1970's. The
fundamental problem of routing in a manet has received substantial attention resulting in numerous protocols (some of
which appear in the recent book [12]) with many more protocols in the literature. The research has been vibrant, yielding protocols that span the range of pro-active to reactive,

at to hierarchical, geographic to non-geographic, and hybrids inbetween.

ABSTRACT

MERIT is a framework to assess routing protocols in mobile
ad hoc networks (manets). It is based on the novel concept
of a shortest mobile path (SMP) in a mobile graph, generalizing the traditional shortest path concept for the mobile
environment. As a standard measure for routing protocols in
a manet, the MERIT framework proposes the mean ratio of
the cost of the actually used route to the cost of the optimal
mobile path, under the same history of link metrics in the
changing network topology. The MERIT spectrum takes the
MERIT ratio as a function of parameters of interest yielding a multi-faceted representation of protocol eectiveness.
This Mean Real vs. Ideal cosT (MERIT) framework is unifying in that it provides a measure that allows a protocol to
be assessed independently of other protocols, within its own
environment. We show that there is an eÆcient algorithm
to solve the underlying SMP problem for important cases,
making the approach practically feasible. We also investigate generalizations of and extensions within the MERIT
framework.

1.

Yet, looming over all this work remains the question of how
to compare manet routing protocols to each other. This
problem, too, has received much debate. Corson and Macker
[2] summarize several qualitative and quantitative metrics
for protocol performance generally agreed upon. The desirable qualitative properties of manet routing protocols include: distributed operation of the protocol, freedom from
loops, aspects of both reactive and proactive operation, security, sleep period operation, and support for unidirectional links. The quantitative metrics include: end-to-end
throughput and delay, route aquisition time, percentage of
out-of-order delivery, and protocol eÆciency that takes into
account control overhead. Royer and Toh [15] survey several
protocols using qualitative measures, and it is commonplace
to nd quantitative comparisons (see, for example, Broch
et al. [1]) since \standard" manet simulation environments
such as ns-2, CPT, OPNET, and GloMoSim [9, 3, 10, 7] are
being widely used.

INTRODUCTION

History shows that dening a standard measure to make
things numerically comparable is no easy task, even in apparently simple situations. In 1266, during the reign of
Henry III in England, an act established that the amount of
gold to make a penny should weigh the same as 32 grains of
wheat. The act, however, did not specify how to guarantee
the same amount of gold in pennies made at dierent locations without access to the exact same 32 grains of wheat
at each location.

While suc h qualitative and quantitative measures are useful and important they still do not provide a satisfactory
framework for a systematic, unied comparison. In particular, the quantitative measures are incomparable unless
protocols are ported to the same platform and run under
the same parameters. That would be generally impractical,
however, just like insisting that the exact same 32 grains of
wheat be used to mint each gold coin. Thus, we feel that it
is timely to introduce a systematic and general framework
for the assessment of manet routing protocols based on past
lessons learned.

In routing protocols a similar, but much more diÆcult, comparability problem arises: they are usually tested in dierent environments, using dierent modeling assumptions on
dierent platforms, giving rise to a situation that does not
support easy comparison at all.
Permission to make digital or hard copies of part or all of this work or
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers, or to redistribute to lists, requires prior
specific permission and/or a fee.
ACM SIGMOBILE 7/01 Rome, Italy
© 2001 ACM ISBN 1-58113-422-3/01/07…$5.OO

Similar in spirit to the order notation in algorithmic complexity analysis, we aim for a mathematical model at a level
of abstraction that allows dierent routing protocols to be

53

view every manet routing protocol as ultimately generating a sequence of paths, as the changing network topology
can force the path to change. We refer to this sequence of
paths as a mobile path. Due to the distributed operation
of manet routing protocols the mobile path may not be explicitly presented when the protocol runs in a real network.
That is, individual nodes may not be aware of the path a
packet traverses, as may occur when a routing table consists of next-hop neighbours as in the DSDV and AODV
protocols [13, 14]. In other cases the path may be explicit,
such as a source route obtained through a route discovery
procedure in DSR [8]. However, even when explicit, such a
route may not re
ect the actual packet trace since the route
may break while it is being traversed due to node mobility which may then require route maintenance procedures
to re-establish the path. Nevertheless, whether explicit or
implicit, the mobile path (i.e., the sequence of static paths)
can always be recorded from packet traces in a simulation
of a protocol.

comparable and yet allows denition of a metric that is independent of platform and the specic details of the network.
Our MERIT framework achieves this by providing a way to
rank any given ad hoc routing protocol by comparing it to a
theoretical, yet eÆciently computable, optimum rather than
to a competing protocol. This approach is unifying in the
sense that the MERIT framework provides a benchmark relative to which all protocols can be compared, independent
of implementation.
The idea of measuring performance relative to a theoretical
optimum has been successfully used in a number of other
situations. For example, in approximation algorithms for
NP-complete problems the approximative solution is compared to the (algorithmically infeasible) NP-complete optimum, usually in terms of an approximation ratio. Another
example is competitive analysis of on-line algorithms, where
the on-line performance is compared asymptotically to the
best possible o-line performance, with the online input set
by a hypothetical adversary that can enforce the worst case.
In MAC protocols when we speak about throughput, then
we essentially compare the actual performance to the ideal
(but infeasible) case when each slot is successfully used for
a packet. In load balancing it is often measured how much
the load distribution deviates from the ideal uniform distribution.

Our proposed way to evaluate the quality of a given protocol (under some given cost model) is to compare the generated (or \real") mobile path with the best possible (or
\ideal") mobile path, that is, with the benchmark path sequence that would have been the best for the same history
of network topology changes. In this way we can compare
protocols in terms of how far they are from being \perfect,"
under the given operating conditions. This is the basis of
our approach: the characterization is based on the ratio of
the MEan \Real" to the \Ideal" cosT, or MERIT, of the
protocol, and we call the measure the MERIT ratio.

In all these examples the common concept is that a solution
(algorithm, protocol, etc.) is compared to a theoretical optimum in its own framework. That is, we measure how much
the actual result is worse than the ideal optimum under the
same conditions. In this way each protocol is measured on
its own ground, which can be done for each solution independently, without forcing them to work in the same system.
Of course, the key question is whether the theoretical optimum can be meaningfully dened and computed eÆciently.
We show that the answer is aÆrmative for manet routing
protocols.

We expect the MERIT ratio to be a stable and robust assessment measure for manet routing protocols. Since it relates
a path to the optimum under the same circumstances, we
believe that some of the dependencies of the platform and
network details will cancel out yielding an implementation
independent measure.
We note that while we present the MERIT framework for
assessing routing protocols in a manet, we believe the framework has a wider and more general applicability than what is
presented here. In particular, network dynamics arise from
more than just node mobility, and structures other than
paths can also be used as a basis for comparison. We plan
to explore these issues in forthcoming papers.

In [1], Broch et al. took a step in this direction when they
dened a notion of path optimality as the dierence in hop
count between the actual path taken by the packet to the
destination, and the shortest path that physically existed
through the network at the time the packet was originated.
This approach represents a \packet level" view in which




the optimal path ignores the possibility that the network topology may change while the packet is being
routed, and

2.
2.1

the optimal path may coincide with something other
than the shortest path in a static network when routing
overhead is taken into account. (Indeed, Section 2.2.1
presents such an example.)

THE MERIT FRAMEWORK
Basic Definitions

In the MERIT framework, we model a manet at two time
scales to capture the dening characteristic of mobility. The
instantaneous model of the network is a graph G = (V; E )
where the vertex set V corresponds to the nodes in the network. A directed edge in the edge set E exists whenever a
transmission from one node to another is possible according
to the physical layer protocol, which may depend on many
variables such as free space and ground re
ection propagation, transmission power, antenna gain, receiver sensitivity,
propagation delay, capture eect, etc. Indeed, unidirectional
wireless links often arise in such networks however the ability to use these links for routing may also depend on the
MAC (medium access control) protocol.

The essential dierence between our work and that in [1] is
that we distinguish a mobile network from one that is static.
In fact, we consider the packet level view in [4], however in
this paper, we consider a \
ow level" view since it raises a
more diÆcult algorithmic problem.
Thus, we seek to capture the fact that the network is mobile in our model. For a given source and destination, we

54

14] each node maintains a next-hop neighbour table, DSR
[8] caches complete source-destination routes, and TORA
[11] establishes a directed acyclic graph rooted at the destination. Most protocols attempt to localize the eect of a
topology change in an attempt to reduce routing overhead.

Over a longer time horizon we model a manet by a graph
sequence that we call a mobile graph. Thus a mobile graph
G is dened as

G=G G
1

2

: : : GT

via any sequence Gi ; i = 1; : : : ; T; of graphs where the successive graphs represent a history of the network topology
changes over some time horizon T . For simplicity it is assumed that all the graphs are dened on the same vertex
set, but this assumption is not essential.

Initially, we consider a simple 2-valued transition cost function where
ctrans(Pi ; Pi+1 )

In a mobile graph we dene a mobile path between a sourcedestination pair as a path sequence
2 : : : PT

where Pi is a (conventional, static) path in
same source-destination pair.

Gi

between the

Underlying every routing protocol is a cost model that can
be expressed as a weight function in each graph.1 The weight
function wi(u; v) for graph Gi is a function of vertex pairs
(u; v) that takes on the value of innity if no direct transmission is possible from u to v (i.e., the corresponding edge
is missing from the graph) and equals the value of the link
metric on the edge otherwise. Note that in this way the
weight function wi actually fully denes the graph Gi .



some cost of transition ctrans(Pi ; Pi+1 ) incurred by the
protocol whenever there is a change in the path sequence.

Thus, the weight (cost) of a mobile path

P) =

w(

T
X
i=1

wi(Pi ) +

TX1
i=1

G

(2)

P

the weight

P) =

w(

T
X
i=1

wi(Pi ) +

TX1
i=1

ctrans(Pi ; Pi+1 )

of the mobile path is minimum.
Note that the traditional static shortest path problem is included as a direct special case when T = 1: In the mobile
case the naive solution when each Pi is simply a static shortest path in the corresponding Gi may be far from optimal
due to the transition costs.
Now it is clear that any routing algorithm ultimately nds a
path: either a static or a mobile path. Given an underlying
cost model, it is natural and reasonable to select a shortest
path. However, while this is well established in xed networks, it is less clear how one can nd a shortest mobile
path.

P is dened as

ctrans(Pi ; Pi+1 ):

if Pi = Pi+1
if Pi 6= Pi+1 :

Shortest Mobile Path (SMP) Problem: Given a mobile
graph = G1 : : : GT and a specied source-destination pair
(s; t), nd a mobile path = P1 : : : PT from s to t, such that

Now we dene the weight (cost) of a mobile path, as part
of the MERIT framework. It is reasonable to include two
basic components in the weight of a mobile path:
the individual weights wi (Pi ) of the static paths in the
sequence, and

cupdate

Thus, the MERIT framework denes the notions of a mobile
graph, a mobile path, and the weight of a mobile path, including transition costs. Now, assuming a given cost model,
we can dene the shortest mobile path problem within the
framework as follows.

The weight of a (static) path Pi in Gi is denoted by wi(Pi ).
The most commonly used variant is the additive path weight,
dened as simply the sum of the link weights along the path.
Some examples of additive path weights include hop count
(which is overwhelmingly the most common metric used),
delay, and delay jitter. (Other possibilities and generalizations will be addressed in Section 3.)



0

That is, the transition cost is zero if there is no change in the
path in successive graphs and is a constant cupdate if the path
has changed. We believe this transition cost is reasonable
for the existing routing protocols since, for example, when
data structures are updated the cost of the update is often
insensitive to how much they are dierent from the previous
ones. (The possibility of a more complex transition cost
structure will be addressed in Section 3.)

P=P P
1

=



(1)

Observe that the shortest mobile path can only be computed
retrospectively, with a known history of network changes.
Thus, we do not propose the approach as another routing
protocol. On the contrary, we use it as a framework within
which to dene a measure for comparison of existing routing
protocols.

The transition cost between paths is a cost function associated with having to update from one path to another in
the routing protocol | in general, it is the overhead associated with updating the routing state to re
ect the change
in the path. For example, routing state is maintained quite
dierently by dierent protocols. In DSDV and AODV [13,

For a given mobile graph G = G1 : : : GT , let Preal be the
actual or \real" mobile path generated according to a manet
routing protocol. Similarly, let Pideal be the shortest mobile
path for G , i.e., the optimum or \ideal" mobile path which
will serve as a benchmark for comparison. Then, we dene

Even when no explicit cost model is available, one can efciently construct a best approximation of the cost model
by observing the choices of the protocol. This \inverse optimization" approach is analyzed in [5], but for the present
paper we assume for simplicity that the costs are known.
1

55

the MERIT ratio as:
MERIT ratio = E



Preal)
Pideal)

w(
w(

1; j ] does not necessarily hold, since path[i + 1; j ] is not necessarily a subsequence of path[i; j ]. Similarly, it may not be
true that f irst[i; j ] = f irst[i; j + 1]:



Informally, for all 1  i  j  T , we rst initialize path[i; j ]
and cost[i; j ] in Step 1 to values for the case where there
is no transition cost in the subsequence Pi : : : Pj . Thus, all
j
i + 1 paths in the subsequence are the same and the
cost of the path subsequence is simply the sum of the path
weights. This is equivalent to nding the shortest path in a
graph formed by taking the intersection of the graphs of the
subsequence Gi : : : Gj and assigning the weight of the edges
as the sum of the edge weights.

which is the expected value of the cost ratio of the generated mobile path to the shortest mobile path taken over a
suÆciently large number of source-destination pairs.
In order to understand the eectiveness of a protocol, the
MERIT ratio must be taken as a function of parameters of
interest, e.g., node mobility rate, packet arrival rate, transmit power levels, etc. This denes the MERIT spectrum of
a protocol. By comparing the MERIT spectra of protocols,
we can identify those scenarios that represent the strengths
of the protocol. As well, the spectrum can be used by the
designers of protocols to determine whether a protocol meets
a specied objective, or to ne tune a protocol.

In Steps 2 and 3, the algorithm then computes the values in
the upper triangle of the cost and path matrix, diagonal by
diagonal from the main diagonal to the upper right corner
of the matrix, i.e., to position cost[1; T ] and path[1; T ]. For
each subsequence Pi : : : Pj , of length j i + 1, the algorithm
now computes the cost of the path by considering all possible ways k; i  k < j , that the subsequence can be split.
Each such split uses a shorter, and hence already computed
SMP, and considers the transition cost incurred by splitting
the sequence at this point. The minimum cost of all such
splits is compared to the value computed at Step 1, with the
minimum overall stored.

Our framework and the assessment measure dened within
it derive their name based on this denition: MEan Real vs.
Ideal cosT, or MERIT.

2.2

Finding the Shortest Mobile Path

We now show that the shortest mobile path (SMP) problem
can be solved eÆciently. The algorithm computes the SMP
in subsequences Gi : : : Gj of the mobile graph G = G1 : : : GT
recursively, in a dynamic programming manner. To describe
the algorithm let us rst introduce some notation.



path[i; j ] is a
Gi : : : Gj . At



cost[i; j ] is the cost of the current path sequence in
path[i; j ], is as dened by (1) with appropriately mod-

Now we present the algorithm to compute the SMP more
formally. To avoid trivial cases we assume T  2.

path sequence in the graph sequence
the end of the algorithm path[i; j ] will
contain the SMP for the sequence Gi : : : Gj .

Algorithm

Step 1 Initialization.
For all 1  i  j  T compute a (static) shortest path
in the graph G(ij) = Gi \ : : : \ Gj with respect to the
weight function w = wi + : : : + wj ; i.e., the weight of
any edge (u; v) is w(u; v) = wi(u; v) + : : : + wj (u; v).
Denote the obtained shortest path by P (ij) and set

ied indices, i.e.,
cost[i; j ]

=
=




f irst[i; j ] is
path[i; j ].
last[i; j ] is
path[i; j ].

w(Pi : : : Pj )

j
X
k=i

wk (Pk ) +

j 1
X
k=i

Shortest Mobile Path (SMP)

ctrans(Pk ; Pk+1 ):

path[i; j ]

the rst path in the current path sequence

=

ij) : : : P (ij)
{z
}
j i+1 identical paths
P
|

(

and
cost[i; j ] = w(P

the last path in the current path sequence

ij)):

(

Set r := 1.
Step 2 Sequence Split.
For all 1  i < j 
following update.

Note that the variables cost[i; j ], f irst[i; j ], and last[i; j ]
always refer to the latest value of path[i; j ]. In order to keep
the description of the algorithm simple we assume that this
property is automatically maintained, so in the description
no explicit update is included for cost[i; j ], f irst[i; j ], and
last[i; j ]. In a software implementation, of course, one has to
make sure they are properly updated to re
ect the changes
in path[i; j ].

newcost :=

min



ik<j

T

with

r

=

j

i

perform the

cost[i; k] + cost[k + 1; j ]+

ctrans last[i; k]; f irst[k + 1; j ]



if newcost < cost[i; j ] then
path[i; j ]

:= path[i; k0 ]path[k0 + 1; j ]

where k0 is the minimizing value of the index k in the
computation of newcost (if k0 is not unique, choose
any of the minimizing indices).

We use the simple product notation for the concatenation of
sequences: path[i; k]path[k + 1; j ] means the concatenation
of the two sequences. For example, by denition it is always
true that f irst[i; i + 1]last[i; i + 1] = path[i; i + 1]: On the
other hand, the relationship path[i; j ] = f irst[i; j ]path[i +

Step 3 Lengthen Sequence.
If r < T 1 then set r := r + 1 and go to Step 2. Else

56

, the shortest mobile path is in
cost is in cost[1; T ].

stop

path[1; T ]

and its

Since it is well known that a static shortest path can be
found in polynomial time, therefore, an immediate consequence of Theorem 1 is that our shortest mobile path algorithm also works in polynomial time. For example, if we
use Dijkstra's O(n2 ) algorithm to nd the static shortest
paths, then a complexity of O n2 T 2 + T 3 is obtained for
the shortest mobile path.

Having presented the algorithm, now we analyze its fundamental properties: its correctness and complexity.
Theorem 1. The algorithm Shortest Mobile Path always
correctly nds the shortest mobile path in any mobile graph.
If the mobile graph has n nodes and its time horizon is T,
then the time complexity of the algorithm is O S (n)T 2 + T 3
where S (n) is the time required to nd a (static) shortest
path in a graph on n vertices.

2.2.1 Example of the Shortest Mobile Path Algorithm
Figure 1 shows a mobile graph G = G1 G2 G3 G4 for a manet
with six nodes. In this example we consider computing the
shortest mobile path for the source-destination pair (1; 5).
Assuming hop count as the static path metric, the (static)
shortest path is indicated by the darker edges in each graph
in the gure.

Let Pi : : : Pj be an optimal path sequence for
with cost cost [i; j ]. We want to show that cost[i; j ]
of the path sequence Pi : : : Pj computed by the algorithm
equals the cost of the optimal path sequence, i.e., cost[i; j ] =
cost [i; j ]. This will prove that we nd the shortest mobile
path for each Gi : : : Gj .
Proof.

Gi : : : Gj

G1
2

5

G3

4
2

4

3

3
2

1

6

5

6

5
1

By induction, we can use that we already know that the algorithm gives the optimal result for shorter sequences. (Notice
that the computation of path[i; j ] in Step 2 of the algorithm
uses only shorter subsequences.) This yields
cost[k + 1; j ]

5

G4






4
6

cost [i; j ] = cost [i; k] + cost [k + 1; j ] + cupdate :

cost[i; k]

3

1

6

The second case occurs when not all paths in the optimal
path sequence are equal. Then there is a k, i  k < j such
that Pk 6= Pk+1 . Now,



2

3
4

1

There are two cases to consider. The rst case is when all
paths in the optimal path sequence are equal, i.e., Pi =
: : : = Pj . In this case, such a sequence is already generated by the algorithm in Step 1 with cost[i; j ] equal to the
sum of the weights of each path. In Step 2 of the algorithm path[i; j ] cannot change in this case, since that could
only decrease its cost, contradicting the assumed optimality.
Thus, cost[i; j ] = cost [i; j ] must hold.



G2

G=G G G G .
Figure 2 shows the graphs G ij = Gi \ : : : \ Gj , 1  i 
j  T = 4, formed in Step 1 of the SMP algorithm. If the
Figure 1: A graph sequence
(


and

cost [k + 1; j ]
cost [i; k];

1

2

3

4

)

intersection of graphs has no path between (1; 5) then there
is no common path in each of Gi : : : Gj from node 1 to node
5, thus the link and hence the path cost is innite. Note that
G(ii) = Gi and so these graphs are not shown separately.

Note that while Pi : : : Pj is optimal by assumption, this

may not carry over to its subsequences, which is why we
write inequalities. Thus the cost of path sequence Pi : : : Pj
obtained by Step 2 of the algorithm satises
cost[i; j ]  cost[i; k] + cost[k + 1; j ] + cupdate
 cost [i; k] + cost [k + 1; j ] + cupdate
= cost [i; j ]
Since cost[i; j ]  cost [i; j ] holds by the assumed optimality of Pi : : : Pj, therefore, we obtain cost[i; j ] = cost [i; j ],
which proves the correctness of the Shortest Mobile Path
algorithm.

Table 1 shows the values of the cost matrix computed by
the SMP algorithm in Step 1 (Initialize), and in the subsequent iterations of the algorithm (r = 1; : : : ; 3). Notice that
ctrans(P1 ; P2 ) = 0, and ctrans (P3; P4 ) = 0, since P1 = P2
and P3 = P4 , respectively. Since P2 6= P3, ctrans (P2; P3 ) =
cupdate; let us assume that cupdate = 2.
For example, when optimizing the path sequence P1 P2 P3 P4 ,
there are 3 ways to split the path sequence. For the split after the rst path P1 jP2P3 P4 , into the two path sequences P1
and P2 P3 P4 , the cost is cost[1; 1]+cost[2; 4]+ctrans(P1; P2 ) =
3+8+0 = 11: For the split after the second path P1 P2jP3 P4 ,
into the two path sequences P1 P2 and P3 P4 , the cost is
cost[1; 2] + cost[3; 4] + ctrans (P2; P3 ) = 6 + 4 + 2 = 12: Finally, for the split after the third path P1 P2 P3jP4 , into the
two path sequences P1 P2 P3 and P4 , the cost is cost[1; 3] +
cost[4; 4] + ctrans (P3 ; P4) = 9 + 2 + 0 = 11: In this case, the

Regarding the complexity, we run O(T 2 ) static shortest path
computations in Step 1, one for each subsequence Gi : : : Gj :
In the rest of the algorithm each path[i; j ] is computed once
and there are O(T 2 ) of them. Each minimization to compute newcost uses O(T ) already computed values, so it takes
O(T ) time, thus altogether the Shortest Mobile Path algorithm has O S (n)T 2 + T 3 time complexity.

57

minimum (11) happens to correspond to the rst and the
third way that the sequence is split, and since this value is
less than the value computed by Step 1 (1), cost[1; 4] is set
to the value 11.

3.1

Notice that in this case, the shortest mobile path does not
correspond to simply selecting the (static) shortest path in
each graph of the graph sequence G1 : : : G4 . A possible realization of the SMP is P P P Q, where P is the path 1 4 3 5
and Q is the path 1 6 5. Thus, rather than incur the
transition cost for ctrans (P2; P3 ) it is more cost eective to
retain the path until G4 .
G

(12)

G
2
2

1

2
2

2

4

In general, it is possible that each link is characterized by
more than one parameter and the path metric can be a nonlinear function of the link parameters. This is the situation
in QoS routing. An example path metric is given below. Assume each link i is characterized by a delay i , an available
bandwidth Bi and the probability pi that the link will remain available for the next minute. A possible path metric
weight is dened by

(23)

3

2

3
2

2

5

2

1

5

2

2

2

2

4

6

6

Extension to General Path Metrics

Until now, we have assumed that the path metric is additive.
In a number of situations, however, dierent rules are used
to compute the path metric. For example to model available
bandwidth, the path weight should be the minimum of the
link weights along the path, rather than the sum since the
available bandwidth along the route acts as a \bottleneck."
In other situations the product of link weights is the most
appropriate, such as in case of link availability probabilities (although this can be transformed into a sum by taking
logarithms).

w(P ) =
(34)

G

G
4

2
1

G

3
2

2
2

6

4

2

3

6

5

6

4

3
4

4

5

4

1

6

5

Figure 2: Graphs formed in Step 1.

1
1
2
3
4

3

1
2
3
4

3

2

3

4

1

2

6
3

1 1
6 1

3

6
3

Initialize

r

6
3

2

=2
9
6
2

4
2

1
8
4
2

3

r

r

6
3

3
=1

4

2

4
2

1 1
6 1

3.

X

i   and min Bi  B
i2P
i2P
i2P
min Bi otherwise, B0 a constant
i2P
pi

if

Theorem 2. For any set wi (P ) of static path metrics,
Algorithm Shortest Mobile Path always correctly nds the
shortest mobile path in any mobile graph. If the mobile graph
has n nodes and its time horizon is T , then
the time com
plexity of the algorithm is O S (n)T 2 + T 3 where S (n) is the
worst case time required to nd a static shortest path, according to the path metric w(P ) = wi (P ) + : : : + wj (P ); 1  i 
j  T , in a graph on n vertices.

=3
9 11
6 8
2 4
2

Table 1: The cost[i; j ] matrix, i

>
: B0

Y

One can naturally ask how such more complex path metrics
can be handled in our framework. We can directly generalize the mobile path metric by replacing the wi (Pi) terms in
(1) by the new static path metrics. The transition cost function is assumed to remain the same. Now the good news is
that all the generalized path metrics t into the framework
because the shortest mobile path algorithm uses the static
shortest path computation as a \black box" and the proof of
correctness and complexity carry over without any change.
Let us record this simple but important observation in the
following theorem. Recall that the static shortest path algorithm is only used in Step 1 of the SMP algorithm, where the
path is the same in each graph of the subsequence. Thus,
ctrans = 0 for all transitions between paths and hence equation (1) reduces to the sum of the weights along the paths
of the subsequence.

(14)

3
3

3

3

1

G

2

3

3

5

1

This metric re
ects the intent that we are looking for the
most reliable path, but only among those that have delay at
most  and available bandwidth at least B . If no such path
exists, then we would like to choose one with highest remaining bandwidth among all paths, disregarding the other
parameters.

3

2
2

3

4

2

(24)

1

(13)

8
>
<

 j  4.

Note that Theorem 2 implies the polynomial time solvability
of the shortest mobile path problem whenever the underlying static shortest path can be found in polynomial time.
Even for those static path metrics for which the static prob-

GENERALIZATIONS OF THE FRAMEWORK

58

Assume now there is a mobile path P = P1 P2 from s to
t in G = G1 G2 with w(P )  M=2. Then we must have
ctrans(P1 ; P2 ) = 0, since otherwise w(P )  M would hold.
It follows from ctrans(P1 ; P2 ) = 0 that P1 ; P2 have no common edge and w1(P1 ) = w2 (P2 ). Set A = f1; : : : ; mg and
let A1  A be the set of indices i for whichP
ei 2 P1 holds.
Then the weight assignment yields w1 (P1 ) = i2A1 ai ; since
for i 2= A1 the path P1 must use the parallel edge fi with
w
P1 (fi ) = 0. By jP1 \ P2 j = 0 we similarly have w2 (P2 ) =
P1 ) = w2 (P2 ), it follows that we
j2A A1 aj : Knowing w1(P
P
have obtained a partition i2A1 ai = j2A A1 aj ; providing a solution to the partition problem. Conversely, from
any solution of partition one can directly generate the corresponding paths with ctrans (P1 ; PP
2 ) = 0, thus satisfying
w(P ) = w1 (P1 ) + w2 (P2 ) + 0 =
i2A ai = M=2, which
proves the theorem.

lem is NP-complete (see [16] for examples), Theorem 2 is still
true, just S (n) is not polynomially bounded in that case.

3.2

Extension to a More Complex Transition
Cost Structure

It is clear that the transition cost for changing paths plays an
important role in the shortest mobile path problem. So far
we have assumed the simple 2-valued transition cost model
dened by (2). This model is insensitive to the extent of path
change: whenever there is a change, a constant update cost
is incurred. While this is a reasonable assumption in many
practical networking situations, nevertheless, it is reasonable
to investigate what happens if a more general transition cost
function is applied.
Now we show that if the transition cost ctrans(Pi ; Pi+1 ) is
allowed to be a general function of the consecutive paths,
then the problem becomes more diÆcult. More precisely, we
show that there is a choice of ctrans(Pi ; Pi+1 ) which makes
the shortest mobile path problem NP-complete, even if the
static path metric remains the simple additive metric.

4.

Theorem 3. Assume that each static path metric wi (Pi )
is additive in a mobile graph G = G1 : : : GT . Then the transition cost function ctrans(Pi ; Pi+1 ) can be chosen such that
it becomes NP-complete to decide whether a mobile path P
exists between two specied nodes in G such that w(P )  C
holds for a given value of C .

Proof.

Since it is often the case that the link weights are not known
precisely, they can be naturally modeled by random variables. Extending the MERIT framework for the stochastic
case would be interesting.

Let us dene the transition cost function by

j)
where M is the sum of all edge weights in all the Gi , and jPi \
Pi j is the number of common edges on the paths Pi; Pi .
ctrans (Pi; Pi+1 ) = M

 (jPi \ Pi j + jwi (Pi)

+1

+1

OPEN PROBLEMS

We consider the MERIT framework a \work in progress,"
with many unresolved questions and extensions. Among the
obvious open questions is that there is a gap between where
the complexity of the SMP problem is solvable in polynomial
time to where it is NP-complete. It would be interesting
to determine the most general transition cost function for
which the problem still remains tractable. It would also be
of interest to precisely characterize the achiveable approximation ratios for cases when the problem is NP-complete.

wi+1 (Pi+1 )

While we are in the process of computing our rst MERIT
spectra, the protocols are currently implemented in ns-2.
Of course, investigating the stability and robustness of the
MERIT ratio in other simulation environments is necessary.

+1

We show that with this choice the known NP-complete problem partition [6] can be reduced to our task. In partition
the input consists of nonnegative integers a1 ; : : : ; am and the
question is whether this set of numbers can be partitioned
into two subsets with equal sum.

5.

CONCLUSION

In this paper we have presented the MERIT framework for
the systematic assessment of routing protocols in a mobile
ad hoc network (manet). The framework denes a mobile
graph, a mobile path, and the cost of a mobile path, all natural extensions of the corresponding concepts in the static
network. We dene the shortest mobile path (SMP) problem
and provide an eÆcient dynamic programming algorithm to
solve the problem in practical situations. Moreover, we introduce the MERIT ratio and spectrum as a unifying measure of manet routing protocols since it compares to a theoretical optimum rather than to other protocols. Some generalizations of the framework are explored, examining the case
for more general path metrics and more complex transition
cost structure. The framework is rich, with much wider generality and potential applicability than routing alone.

Let us construct a mobile graph with T = 2, using the input
a1 ; : : : ; am of partition. Let both graphs G1 ; G2 be the
same simple path from a node s to another node t with edges
e1 ; : : : ; em and to each edge ei let us add a parallel edge fi .
Set the edge weights in both graphs to w1 (ei ) = w2 (ei ) = ai
and w1 (fi) = w2(fi ) = 0; i = 1; : : : ; m:2
Now we show that there is a mobile path P = P1 P2 from
s to t in G = G1 G2 with w(P )  M=2 if and only if the
answer is \yes" to the question of the partition problem.
By denition M = 2 m
i=1 ai , as M is the sum of all weights
in G1 ; G2 : It follows from the denition of the transition cost
function that ctrans (P1 ; P2) = 0 if and only if P1 and P2 has
no common edge and w1(P1 ) = w2 (P2 ). In every other case
ctrans (P1; P2 )  M , since then with integer weights we have
jP1 \ P2 j + jw1(P1 ) w2 (P2)j  1:
P

Acknowledgments

The authors are grateful to Laszlo Babai and Jon Kleinberg
for helpful comments and suggestions when the problem was
informally discussed at the STOC'98 conference in Dallas,
Texas. We also thank the reviewers for their useful comments.

Note that if we want to avoid parallel edges then it can be
easily achieved by subdividing each edge by a new vertex and
dividing the edge weight equally between the two \halves."
2

59

6.

[14] C.E. Perkins and E.M. Royer. Ad-hoc On-Demand
Distance Vector Routing. In Proceedings of the Second
Annual IEEE Workshop on Mobile Computing
Systems and Applications, pages 90{100. February
1999.

REFERENCES

[1] J. Broch, D.A. Maltz, D.B. Johnson, Y.-C. Hu, and J.
Jetcheva. A Performance Comparison of Multi-Hop
Wireless Ad Hoc Network Routing Protocols. In
Proceedings of the Fourth Annual ACM/IEEE
International Conference on Mobile Computing and
Networking (Mobicom'98), pages 85{97. October 1998.

[15] E.M. Royer and C.-K. Toh. A Review of Current
Routing Protocols for Ad Hoc Mobile Wireless
Networks. In IEEE Personal Communications, pages
46{55. April 1999.

[2] M.S. Corson and J. Macker. Mobile Ad hoc
Networking (manet): Routing Protocol Performance
Issues and Evaluation Considerations. In Network
Working Group, RFC 2501. January 1999.

[16] Z. Wang. On the Complexity of Quality of Service
Routing. In Information Processing Letters,
69:111{114, 1999.

http://www.ieft.org/rfc/rfc2501.txt

[3] The C++ Protocol Toolkit (CPT). Rooftop
Communications Corp. (Now Nokia Rooftop.)
http://www.rooftop.com

[4] A. Farago and V.R. Syrotiuk. Transport Layer
Routing Assessment in Mobile Ad Hoc Networks.
Submitted to Symposium on Ad Hoc Wireless
Networks, IEEE Global Communications Conference
(Globecom'01).
 Szentesi, and B. Szviatovszki. Inverse
[5] A. Farago, A.
Optimization in High Speed Networks. Submitted to
Discrete Applied Mathematics, Special Issue on
Telecommunications.
[6] M.R. Garey and D.S. Johnson. Computers and
Intractability. W.H. Freeman and Co., San Francisco,
California, 1983.
[7] GloMoSim: Global Mobile Information Systems
Simulation Library. The University of California, Los
Angeles.
http://pcl.cs.ucla.edu/projects/glomosim/

[8] D.B. Johnson. Routing in Ad Hoc Networks of Mobile
Hosts, In IEEE Workshop on Mobile Computing
Systems and Applications, pages 158{163. December
1994.
[9] The Network Simulator | ns-2. The University of
California, Berkeley.
http://www.isi.edu/nsname/ns/

[10] OPNET: Optimum Network Performance. OPNET
Technologies, Inc.
http://www.mil3.com

[11] V.D. Park and M.S. Corson. A Highly Adaptive
Distributed Routing Algorithm for Mobile Wireless
Networks. In Proceedings of the Sixteenth Annual
Joint Conference of the IEEE Computer and
Communications Societies (Infocom'97), pages
1405{1413. April 1997.
[12] C.E. Perkins, ed. Ad Hoc Networking, Addison-Wesley
Inc., 2001.
[13] C.E. Perkins and P. Bhagwat. DSDV Routing over a
Multihop Wireless Network of Mobile Computers. In
T. Imielinski and H.F. Korth, editors, Mobile
Computing, pages 183{206. Kluwer Inc., 1996.

60

Adapting Sensing and Transmission Times to Improve Throughput
in Cognitive Radios Ad Hoc Networks
Namrata Bapat and Violet R. Syrotiuk
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University
Tempe, AZ 85287-8809, U.S.A.
{nbapat,syrotiuk}@asu.edu

Abstract—Cognitive radios (CRs) can dynamically reconfigure their transmission and/or reception parameters. In a
cognitive radio ad hoc network (CRAHN) setting, such reconfiguration is challenging due to the lack of centralized control
and fixed infrastructure. In this paper, we propose a method to
improve the throughput of secondary users (SUs) in a CRAHN
by dynamically adapting their sensing and transmission times.
First, we conduct a designed experiment on five CR parameters
in the ns-2 network simulator with extensions to support
CRAHNs. A statistical analysis of the resulting data attributes
the contribution of each parameter, and interactions among
them, to SU throughput. Based on these results, we propose
for each SU to measure its instantaneous throughput and adapt
its sensing and transmission times according to the predicted
throughput. Simulation results demonstrate that SUs achieve
higher throughput by adapting their sensing and transmission
times than by using default static values for these parameters.
Keywords-Cognitive Radios, Data Analysis, Adaptation.

I. I NTRODUCTION
With the rapid deployment of wireless networks, the
industrial, scientific and medical (ISM) band has become
heavily congested. On the other hand, spectrum allocated to
licensed users is often used intermittently. This has brought
to light the uneven utilization of radio frequencies. Cognitive
radio (CR) technology is envisioned to overcome scarcity
in underutilized frequencies by opportunistic use of the
available spectrum.
A cognitive radio network (CRN) contains primary users
(PUs) and secondary users (SUs). The PUs are users licensed to operate in a specific frequency range; SUs are
nodes with cognitive capabilities. Basic functionalities of
SUs include PU detection, and spectrum-sensing, spectrummobility, spectrum-decision, and spectrum-sharing [1]. An
SU first senses for available spectrum, then decides on
and switches to an available channel where it establishes
a connection with another SU. Sensing and transmission
cycles must repeat. During a sensing cycle, an SU cannot
transmit data. On detecting any PU activity, an SU must
either share the spectrum with the PUs in a way that
does not interfere with them, or it can execute a spectrum
hand-off, switching to another available channel. Spectrum
c
978-1-4673-1239-4/12/$31.00
2012IEEE

management is therefore crucial in CRNs. Spectrum sensing and transmission times are important to maximize the
throughput of the SU. Infrequent sensing by SUs leads to PU
misdetection, causing SUs to interfere with PUs. Whereas
too frequent sensing results in less data transmission by SUs
affecting their throughput.
The remainder of the paper is structured as follows. In §II
we examine related work on techniques to adapt sensing and
transmission times. We then propose a method for SUs in
a CRAHN, a cognitive radio ad hoc network, to adapt their
sensing and transmission times to improve their throughput.
It is based on the results of a screening experiment of five CR
parameters on the response variable of SU throughput. The
experiment is conducted using the ns-2 network simulator
with extensions to support CRAHNs (see §III). A statistical
analysis of the data collected is provided in §IV. It identifies
the parameters and interactions among the parameters that
most influence the SU throughput. §V describes our proposed adaptive protocol that exploits the interactions found
among the parameters studied. We evaluate the performance
of our protocol in §VI, and summarize conclusions in §VII.
II. R ELATED W ORK
Many schemes have been proposed to increase the
throughput of the SUs in a CRN. Given the trade-off
between SU throughput and sensing time, some research
focusses on optimizing the spectrum sensing techniques [2].
Various parameters such as PU detection, cooperation, and
sensing control, are considered to develop new spectrum
sensing algorithms [1]. Some research suggests techniques
that implement energy detection for spectrum sensing [3].
Channel monitoring is performed by detecting the energy of
the licensed user. Spectrum sensing and sharing techniques
have to be implemented carefully, so as to not interfere with
the PU. Another method suggests using an optimal fusion
rule to calculate the error probability [4]. This technique
calls for cooperation between the cognitive radios (SUs)
within the network to perform spectrum sensing.
Most research concentrates on spectrum sensing and sharing algorithms [5]. Not many ideas have been proposed

for adaptive transmission time. There are proposed techniques that determine the transmission power based on the
interference temperature [6]. Though the method depends
on spectrum sensing algorithms, it does suggest adaptive
transmission power using modulation and coding. In this
paper, we propose a method of dynamically adapting the
sensing and transmission time based on the results of a
statistical analysis of a designed experiment.
III. CRAHN S IMULATOR M ODEL
To perform the simulations, we use the ns-2 network
simulator [7] with extensions to support CRAHNs [8]. It
uses a multi-radio, multi-channel system model. Each SU
has three radio interfaces: A control interface, a receiving
interface, and a switchable interface. The control interface
is tuned to the common control channel. The receiving
interface is tuned to the data channel and the switchable
interface has CR capabilities.
The primary user model determines the PU behaviour.
The activity of each PU depends on the channel the PU uses,
its location, transmission range, the location of the receiving
interface, PU on time (α) and PU off time (β). PU on and
off time use an exponential model [9] to determine busy and
idle states of the PU on the channel [8].
The secondary user model implements the CR capabilities. This includes the spectrum sensing module which
implements PU detection. For simplicity the probability of
misdetection is calculated based on the value of sensing
time. The lower the sensing time, the higher the probability
of misdetection. The spectrum decision module decides
whether to stay on or leave the channel if a PU is detected.
If the decision is to leave then it also decides the next
channel to use based on the switching policies specified in
the channel module. The spectrum mobility module is used
to perform spectrum hand-off. This module performs all the
channel switching operations. The CR node loads the new
channel characteristics and reconfigures its interfaces.
A cross-layer repository maintains the state of all the
channels being used by each node.
The channel model provides information about each channel including its bandwidth, packet error rate, and an identifier given to each channel. Two channel switching policies
and two spectrum allocation policies are implemented.
In the MAC layer model each radio implements the IEEE
802.11 DCF protocol. The switchable interface switches between the available channels. This module includes channel
allocations performed at the MAC layer [10].
IV. E XPERIMENTAL D ESIGN AND A NALYSIS
To design and analyse the experiment, we use Design
Expert 8 [11]. We conduct a 25 screening experiment
using the extremal values of the five parameters in Table I,
measuring the SU throughput as our response variable. 50
replicates of each scenario in the experiment are run.

Each simulation scenario is a CRAHN consisting of ten
pairs of PUs and one pair of SUs on a number of data
channels that depends on the term E; in addition, there is one
control channel. The primary user model assigns each pair
of PUs to one of the data channels with equal probability,
and determines the traffic activity of each PU depending
on the PU on time α (term C) and the PU off time β
(term D) according to an exponential distribution. The SUs
are configured with sensing time (term A), transmission
time (term B), and other parameters. The spectrum manager
module initializes the cross-layer repository with the channel
characteristics and channel assignment of PUs, among other
information. The source SU then begins spectrum sensing,
looking for an available channel; if it finds that a PU is
transmitting, it makes a spectrum decision. We use the
“always switch” channel switching policy, where the SU
pair vacates the channel immediately on PU detection. The
source SU uses the “round robin” channel allocation policy
to select the next available channel. After spectrum handoff,
the SUs work together to (re)establish the connection and
transmit data.
Table I
C OGNITIVE RADIO PARAMETERS
Term
A
B
C
D
E

Parameter
Sensing Time
Transmission Time
PU On Time (α)
PU Off Time (β)
No. of Data Channels

# Values
11
5
7
7
4

Values
0.025–0.275, by 0.025
0.20–1.00, by 0.20
0.50–2.00, by 0.50
0.50–2.00, by 0.50
4–10, by 2

The average of SU throughput across all 50 replicates
is used in the statistical analysis. The natural log transformation, suggested by Design Expert, is performed
to better fit the data. Post transformation, the percentage
contribution of each term on average SU throughput is
obtained. All terms with a contribution of 2% or more are
selected. Interestingly, these include all main effects except
E (i.e., the number of data channels is not significant), all
two-way interactions among A, B, C, and D except BC and
CD, and only one three-way interaction among A, B, and
D. Table II shows the resulting effects table.
Table II
T ERMS CONTRIBUTING 2% OR MORE TO AVERAGE SU THROUGHPUT
Term
A
B
C
D
AB
AC
AD
BD
ABD

Effect
-0.68934
0.54414
1.16147
-1.82089
0.72294
-0.46516
0.69405
-0.49362
-0.58043

Sum of Squares
3.80157
2.36877
10.79218
26.52530
4.18125
1.73100
3.85371
1.94930
2.69525

% Contribution
6.39835
3.98683
18.16410
44.64419
7.03737
2.91341
6.48610
3.28084
4.53632

Table III shows the results of an analysis of variance
(ANOVA). The model F-value of 93.32 implies that the

model is significant. There is only a 0.01% chance that a
model F-Value this large could occur due to noise. Values
of “Prob. > F” less than 0.0500 indicate model terms that
are significant. Our aim is to understand and exploit the
interactions among terms to improve SU throughput.
Table III
ANOVA OF THE SCREENING EXPERIMENT
Source
Model
A
B
C
D
AB
AC
AD
BD
ABD
Residual
Cor Total

Sum of
Squares
57.90
3.80
2.37
10.79
26.53
4.18
1.73
3.85
1.95
2.70
1.52
59.41

Degrees of
Freedom
9
1
1
1
1
1
1
1
1
1
22
31

Mean
Square
6.43
3.80
2.37
10.79
26.53
4.18
1.73
3.85
1.95
2.70
0.069

FValue
93.32
55.15
34.36
156.56
384.80
60.66
25.11
55.91
28.28
39.10

p-value
Prob. > F
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001
< 0.0001

An interaction graph shows how a change in the value
of one parameter affects the other parameter with respect to
the response variable [12]. Figure 1 shows the interaction
graph for sensing time (A) and transmission time (B) on
SU throughput. The red line indicates the average SU
throughput behaviour when the transmission time is 1.00s
while the black line is for a transmission time of 0.2s.
We can see a significant decrease in SU throughput as the
sensing time increases when the transmission time is 0.2s.
For the higher value of transmission time however, the SU
throughput is high and consistent over all values of sensing
time. This shows that for the higher sensing time, if the
transmission time is also high then SU throughput does not
fall considerably. Also, as the sensing time value approaches
transmission time, SU throughput falls. Sensing time higher
than transmission time is not favourable for SU throughput.
In all cases, a higher value of sensing time affected the SU
throughput negatively.
To better understand the three-way interaction ABD (sensing time, transmission time, and PU off time β), a cube plot
in Figure 2 is used. A cube plot shows the predicted values
of the three parameters selected using the following model
for average SU throughput (T ):

Figure 1.

negatively. For higher values of β and transmission time,
throughput increases because β has a larger effect on the
performance than transmission time. Similarly, in the case
of smaller values of β and sensing time, SU throughput
increases because β affects it more than the other two
parameters. For any value of β, as the sensing time increases,
SU throughput starts decreasing. On the other hand, for
higher value of β the throughput starts rising for higher
sensing and transmission times.

Figure 2.

ln(T )

=

Cube plot of A, B, and β for average SU throughput.

12.744 − 14.425A − 0.827B + 1.146C

− 1.972D + 16.903AB − 2.481AC
+

Interaction graph of A and B on average SU throughput.

8.345AD + 0.338BD − 7.739ABD

(1)

We verified that this model for average SU throughput is
an accurate predictor for the intermediate values of all the
parameters, not just the extremal values of the parameters.
In Figure 2, for smaller values of PU off time β, if
the difference between the values of sensing time and
transmission time is high then the SU throughput is affected

V. D ESIGN OF THE A DAPTIVE A LGORITHM
The analysis of the data identifies the terms that affect
average SU throughput in CRAHNs. According to the effects
table (Table II), among the main effects, PU off time β (D)
is the parameter with the highest impact followed by PU
on time α (C); this makes sense because the activity of the
PUs affects SU throughput. This is followed by sensing time
(A), and transmission time (B). Even though β makes the

strongest contribution to throughput, α and β are parameters
associated with PUs and hence an SU cannot change these
values. However, an SU can adapt its sensing time (A) and
transmission time (B). We modify the CRAHN extension in
ns-2 to exploit the findings of the data analysis.
The default CRAHN model uses fixed values of sensing
and transmission times for the duration of the scenario. An
adaptive SU can reconfigure its sensing and transmission
times based on the radio environment to maximize its
throughput. To implement this idea, each SU measures its
instantaneous throughput during data transmission.
To measure instantaneous throughput, the simulation time
is divided into intervals. After every interval, a timer interrupt is generated and throughput for the interval is measured,
i.e., counting successful transmission of data packets in
the interval. Intervals ranging from 10000µs to 100000µs
are used. The throughput of the current time interval i is
compared to that of the previous interval i-1. Based on
the difference, the sensing time and the transmission time
are modified. We use the interpretation of the cube plot in
Figure 2 to determine a combination of sensing time and
transmission times as follows.
A. Adapting Sensing Time
Using the patterns observed during the data analysis, we
modified the sensing time relative to the transmission time.
It is clear from the analysis that high sensing time does not
yield high SU throughput. At the same time, we do not want
the sensing time to be too low to avoid PU misdetection.
Also, we saw that a large difference between sensing and
transmission times has a negative effect on SU throughput.
When sensing time is greater than, equal to, or very close
to transmission time again SU throughput decreases. During
the analysis, we observed that for some combinations of
sensing and transmission times, SU throughput was relatively high. We therefore vary the sensing time from 5% to
30% of the transmission time and denote this percentage as
Ps . The goal is to keep a sufficient difference between the
value of sensing and transmission time, while at the same
time not letting them fall or rise to their extreme values. So
every time the transmission time changes, sensing time also
changes relative to the transmission time.
B. Adapting Transmission Time
During the data analysis, we observe that for higher
transmission time SU throughput is also high. Thus we
should allow the transmission time to adapt and rise. But a
sudden, large change in transmission time negatively impacts
SU throughput. Therefore, the transmission time of the SU is
modified gradually if there is a change in the throughput in
the current interval. We vary the transmission time in small
steps of 0.05s or 0.10s and denote this time step as Tx . If the
current throughput is less than that in the previous interval,
this indicates that the PU activity has increased, incorrect

congestion detection due to spectrum hand-off, very low
sensing time, or the transmission time was relatively high.
In such cases the transmission time is decremented by Tx .
If the current throughput is higher than that in the previous
interval then the transmission time is increased by Tx . The
increase in throughput indicates that the model is working
well and a slight increase in transmission time helps boost
SU throughput. But if incrementing the transmission time
by Tx affects the throughput negatively, it means that the
transmission time is set too high. We then fall back and
reduce the transmission time. As Table I shows, transmission
times are at an interval of 0.2s. We, therefore choose two
values of Tx : 0.05s and 0.10s. The implementation did not
allow the transmit time to fall below 0.2s or exceed 1.0s.
Algorithm 1 summarizes the adaptation of sensing and
transmission times on a timeout.
Algorithm 1 Algorithm for Adapting Sensing Time and
Transmission Time based on the Cube Plot
if currP acketCount ≥ prevP acketCount then
transmission time ← transmission time + Tx
if transmission time ≥ 1 then
transmission time ← 1
end if
else
transmission time ← transmission time − Tx
if transmission time ≤ 0.2 then
transmission time ← 0.2
end if
end if
sensing time ← Ps ∗ transmission time

VI. P ERFORMANCE E VALUATION
In this section, we evaluate the performance of our
adaptive algorithm and compare it with the algorithm in the
default CRAHN extension. Before we present the results,
we describe the simulation set-up. The number of PUs, SUs,
and channels is same as in §IV. To generate traffic, we use
TCP-FTP [13]. The transmission range is set to 500m and
bandwidth of each channel is 2Mbps. Packet size is set to
1000bytes. Sensing time, transmission time, PU on time α
and PU off time β vary taking the values given in Table I.
The value used for the timer interval is 10000µs–50000µs
in increments of 10000µs. During the simulation, sensing
time and transmission time of each SU is adapted according
to Algorithm 1. Five replicates of each scenario are run.
A. Sensing Time Analysis
We performed simulations for the eleven values of sensing
time, and six values of Ps , from 5% to 30% in increments
of 5%. Figure 3 shows the average SU throughput for each
value of sensing time. The adaptive algorithm works well
for sensing times of 0.05s and more. Except for a sensing

time of 0.025s, the adaptive algorithm outperforms the
default implementation. However we observe a gradual fall
in the overall throughput as the sensing time increases. This
confirms our observations in the analysis that SU throughput
decreases with higher sensing time. Thus we can infer that
for comparatively higher SU throughput in the adaptive
algorithm, sensing times of 0.05s to 0.175s work well.
The SU throughput for the adaptive implementation is, on
average, 9.5% higher than that of the default implementation.
Even though the adaptive algorithm performs better for
sensing times greater than 0.175s, the overall throughput of
the network starts declining. So we consider a sensing time
of 0.175s as an upper threshold.

Figure 3.

B. Transmission Time Analysis
For transmission time analysis, we performed simulations
for the five parameters given in Table I. The adaptive
algorithm modifies the value of transmission time by steps
of 0.05s or 0.10s. The average SU throughput across all
scenarios for each step shows that Tx of 0.05s performs
better than 0.10s. Figure 5 plots average SU throughput
across all simulations as a function of transmission time. The
step Tx was fixed for an entire run of all combinations of
the parameters. Figure 5 shows that with higher transmission
time SU throughput keeps increasing. This agrees with the
analysis drawn from the cube plot and interaction graph.
The adaptive algorithm shows better results compared to the
default for all values of transmission time. The throughput
rose by nearly 14% for all levels of transmission time.
Transmission time analysis for all values of Tx and Ps also
show that the adaptive algorithm works better for a sensing
time 15% or less of the transmission time. The throughput
starts falling for values of Ps of 20% and more.

SU throughput as a function of sensing time.

Figure 4 plots SU throughput for sensing time based in
each simulation run for given values of Tx and Ps . The SU
throughput improves when sensing time is 15% or less of
the transmission time. This clearly shows that higher values
of sensing time relative to the transmission time have a
negative impact on SU throughput. The throughput of the
adaptive algorithm starts falling for Ps of 20% and more.
These results are in accordance with analysis of the cube
plot in Figure 2 as well as the interaction graph in Figure
1; both show that as sensing time increases and its value
approaches transmission time, the throughput of the network
starts decreasing.

Figure 5.

SU throughput as a function of transmission time.

We also generated plots for average throughput over all
percentages and step values. Figure 6 shows the average SU
throughput as a function of Tx and Ps . The adaptive algorithm works better for sensing times of 15% or less. Also,
for step Tx the value of 0.05s is better for SU throughput.
These results support the data analysis performed in §IV.
C. Overall SU Throughput

Figure 4.

SU throughput for sensing relative to transmission time.

In analyzing the results of the default algorithm, we
observed high variance in SU throughput. As a result,
we implemented the adaptive algorithm to stabilize the
throughput. Since the changes in sensing and transmission
times are done in small steps, the variance in throughput is
reduced. The overall results of the adaptive algorithm are
significantly better than that using static values for sensing
and transmission times. The SU throughput, after using the
adaptive algorithm is up to 15.9% higher than the default
algorithm. The highest percent increase in throughput is
recorded for the 10000µs time interval.

Figure 6.

Average SU throughput as a function of Tx and Ps .

VII. C ONCLUSION
In this paper, we proposed a method to improve the
throughput of SUs in a CRAHN by dynamically adapting
their sensing time and transmission times. The algorithm
is based on the results of a statistical analysis of the data
collected from a designed experiment. The adaptive algorithm changes the sensing time and transmission time on the
fly depending on the instantaneous throughput. Simulation
results show that the adaptive algorithm yields higher SU
throughput than the default algorithm, validating the analysis. The results also show that there is a relation between
proportion of sensing time to transmission time in order to
improve the SU throughput. In this paper we dealt with
SU parameters because PU behaviour cannot be controlled
by the SU. Future work in this direction could involve PU
arrival time and departure time predictions.
ACKNOWLEDGMENT

[4] W. Zhang, R. Mallik, and K. Ben Letaief, “Cooperative
spectrum sensing optimization in cognitive radio networks,”
in IEEE ICC, May 2008, pp. 3411–3415.
[5] D. Cabric, S. Mishra, and R. Brodersen, “Implementation
issues in spectrum sensing for cognitive radios,” in Signals,
Systems and Computers, 2004. Conference Record of the
Thirty-Eighth Asilomar Conference on, vol. 1, Nov. 2004, pp.
772–776.
[6] M. Hong, J. Kim, H. Kim, and Y. Shin, “An adaptive
transmission scheme for cognitive radio systems based on
interference temperature model,” in IEEE CCNC, Jan. 2008,
pp. 69–73.
[7] “Network Simulator Version
http://www.isi.edu/nsnam/ns/

2.”

[Online].

Available:

[8] M. Di Felice, K. R. Chowdhury, W. Kim, A. Kassler, and
L. Bononi, “End-to-end protocols for cognitive radio ad
hoc networks: An evaluation study,” Performance Evaluation,
vol. 68, pp. 859–875, September 2011.

We thank M. Di Felice for sharing his CRAHN extension
to the ns-2 simulator, and D. Montgomery for his help with
the data analysis.

[9] W.-Y. Lee and I. Akyildiz, “Optimal spectrum sensing framework for cognitive radio networks,” IEEE Transactions on
Wireless Communications, vol. 7, no. 10, pp. 3845–3857,
October 2008.

R EFERENCES

[10] P. Kyasanur and N. H. Vaidya, “Routing and link-layer protocols for multi-channel multi-interface ad hoc wireless networks,” SIGMOBILE Mob. Comput. Commun. Rev., vol. 10,
pp. 31–43, January 2006.

[1] I. F. Akyildiz, W.-Y. Lee, and K. R. Chowdhury, “CRAHNs:
Cognitive radio ad hoc networks,” Ad Hoc Networks, vol. 7,
no. 5, pp. 810–836, January 2009.
[2] Y.-C. Liang, Y. Zeng, E. Peh, and A. T. Hoang, “Sensingthroughput tradeoff for cognitive radio networks,” Wireless
Communications, IEEE Transactions on, vol. 7, no. 4, pp.
1326 –1337, April 2008.
[3] A. Ghasemi and E. S. Sousa, “Optimization of spectrum
sensing for opportunistic spectrum access in cognitive radio
networks,” in IEEE CCNC, Jan. 2007, pp. 1022–1026.

[11] “Design
Expert
8.”
[Online].
http://www.statease.com/dx8descr.html

Available:

[12] D. C. Montgomery, Design and Analysis of Experiments,
8th ed. John Wiley & Sons, Inc., 2012.
[13] K. R. Chowdhury, M. Di Felice, and I. F. Akyildiz, “TPCRAHN: A transport protocol for cognitive radio ad-hoc
networks,” in IEEE INFOCOM, April 2009, pp. 2482–2490.

Lower Bounds for Two-Period Grooming via Linear
Programming Duality

Charles J. Colbourn
Computer Science and Engineering, Arizona State University, Tempe, Arizona 85287-8809
Gaetano Quattrocchi
Dipartimento di Matematica e Informatica, Università di Catania, viale A. Doria 6, Catania 95125, Italy
Violet R. Syrotiuk
Computer Science and Engineering, Arizona State University, Tempe, Arizona 85287-8809

In a problem arising in grooming for two-period optical
networks, it is required to decompose the complete graph
on n vertices into subgraphs each containing at most C
edges, so that the induced subgraphs on a speciﬁed set
of v ≤ n vertices each contain at most C  < C edges.
The cost of the grooming is the sum, over all subgraphs,
of the number of vertices of nonzero degree in the subgraph. The optimum grooming is the one of lowest cost.
An integer linear programming formulation is used to
determine precise lower bounds on this minimum cost
for all choices of n and v when 1 ≤ C  < C ≤ 3. In most
cases, this approach determines not only the bound but
also the speciﬁc structure of any grooming that could
realize the bound. © 2008 Wiley Periodicals, Inc. NETWORKS,
Vol. 52(4), 299–306 2008

Keywords: optical networks; trafﬁc grooming; graph decomposition; combinatorial designs; linear programming duality

1. INTRODUCTION
A graph decomposition (X, B) of the complete graph Kn
on the n vertices of X is a partition of the edges of Kn into
b edge-disjoint subgraphs B = {Gi : 0 ≤ i < b}. The cost
of a decomposition (X, B) is the sum, over all graphs in B,
of the number of vertices of nonzero degree in the graph.
N(n, C) denotes a graph decomposition in which every graph
B ∈ B contains no more than C edges. ON (n, C) denotes an
N(n, C) whose cost is minimum. This deﬁnition of cost arises
in a problem of assigning network trafﬁc in unidirectional
Received May 2005; accepted January 2008
Correspondence to: C. J. Colbourn; e-mail: charles.colbourn@asu.edu
Contract grant sponsor: NSF; Contract grant number: ANI-0240524 (to
V.R.S.).
Contract grant sponsor: MIUR-Italy (to G.Q.).
DOI 10.1002/net.20251
Published online 3 June 2008 in Wiley InterScience (www.interscience.
wiley.com).
© 2008 Wiley Periodicals, Inc.

NETWORKS—2008—DOI 10.1002/net

optical rings to wavelengths (grooming; see [11, 13, 15], for
example), where it is known as the drop cost of the grooming
[4, 16]. Indeed cost ON (n, C) has been determined precisely
when C = 3 [1], C = 4 [4, 12], C = 5 [3], and with ﬁnitely
many exceptions when C = 6 [2]. However, graph decompositions have been extensively studied for other reasons as
well. See [5] for an excellent survey, [9] for relevant material
on designs with blocksize three, and [6] for terminology in
design theory.
We state two of the relevant results on grooming:
Theorem 1.1 ([4, 12]). For every positive integer n,
cost ON (n, 2) = 3n(n−1)+δ
, where δ = 0 if n ≡ 0, 1
4
(mod 4) and δ = 2 if n ≡ 2, 3 (mod 4).
Theorem 1.2 ([1]).

Suppose n is a positive integer.


1. When n is odd, cost ON (n, 3) = n2 + δ, where δ = 0 if
n ≡ 1, 3 (mod 6) and δ = 2 if n ≡ 5 (mod 6).
2. When n is even, cost ON (n, 3) = n2 +  n4  + δ, where
δ = 1 if n ≡ 8 (mod 12) and δ = 0 otherwise.

Let V ⊆ X. The graph decomposition (X, B) embeds the
graph decomposition (V , D) if there is a mapping f : D → B
such that D is a subgraph of f (D) for every D ∈ D. If f
is injective (i.e., one-to-one), then (X, B) faithfully embeds
(V , D). This concept has been explored in [7, 14], for example. N(n, v; C, C  ) denotes an N(n, C) that faithfully embeds
an N(v, C  ). We use the notation ON (n, v; C, C  ) to denote an
N(n, v; C, C  ) of minimum cost. In [8], we describe a grooming problem in optical networking in which there are two
time periods with different trafﬁc requirements. Remarkably
cost ON (n, v; C, C  ) turns out to be precisely the drop cost
of such a grooming; this underlies our motivation.
Generally we have cost ON (n, v; C, C  ) ≥ cost ON (n, C).
Of particular interest is the case when cost ON (n, v; C, C  ) =

cost ON (n, C). For every triple (n, C, C  ) denote by
ℵ(n, C, C  ) the set of integers v for which cost ON
(n, v; C, C  ) = cost ON (n, C). Evidently 1 ∈ ℵ(n, C, C  )
for every positive integer n.
We shall be interested in ON (n, v; C, C  ) when C ≤ 3
and 1 ≤ C  < C. In particular, we establish lower bounds
on cost ON (n, v; C, C  ) using an integer programming formulation. More precisely, a linear programming relaxation
of this integer program and its dual linear program are used.
This has typically not been the approach taken in the derivation of lower bounds for graph decompositions; rather, clever
combinatorial arguments have been the standard. However,
we are faced with a large number of linear inequalities in
which the coefﬁcients are known; this is a bread-and-butter
application for integer linear programming and these techniques provide detailed information about structure of the
graph decomposition, as we shall see.

than or equal to a speciﬁed value. In our case these values are
functions of v and w = n − v. In addition to the constraints
developed, in the integer linear program (ILP) we require
nonnegativity and integrality of each variable. To begin, we
determine three equations, by counting edges with both ends
in V ; one end in V and one in W ; and both in W . Each equation
can then be converted into two valid (“greater than”) inequalities to form an ILP. Integer solutions to this ILP minimization
problem do not necessarily correspond to decompositions, so
combinatorial inequalities are adjoined as needed.
Our strategy in each case is to
1. Set all variables for graphs that cannot arise in an
N(n, v; C, C  ) to zero (equivalently, delete all such variables).
2. Drop integrality constraints and (perhaps) some of the
six inequalities (i.e., the two from each equality) to
form a linear programming (LP) relaxation, but maintain
nonnegativity constraints.
3. Tighten the LP relaxation by adjoining additional linear
inequalities implied by integrality or by combinatorial
structure. Let L be the resulting LP, and let zL be its
optimal
value.

objective function

 


 

4. Now ( 2i=0 αi ) + 2( 2i=0 1j=0 τji ) + 3( 3i=0 1j=0 µji






+ 9i=0 ρi + 3i=0 i ) = v+w
by counting all pairs in
2
two ways. Choose a value νC,C  and subtract νC,C  times
the given equality from the objective function of L to
obtain a modiﬁed LP M. Let zM be its optimal objective
function value. Then zM + νC,C  v+w
= zL .
2
5. Form the (maximization) LP dual D of M and a feasible
solution S to D. Let zD (S) be its dual objective function
value.

2. THE INTEGER LINEAR PROGRAM AND
ITS RELAXATIONS
Consider an arbitrary decomposition D on KV ∪W (with
|V | = v, |W | = w, and |V ∪ W | = n = v + w) into connected
subgraphs on at most three edges. The number of P2 s in D
having i vertices in V is denoted by αi (i ∈ {0, 1, 2}). The
number of P3 s in D having the central vertex in V and i other
vertices in V is denoted by τ1i (i ∈ {0, 1, 2}). The number of
P3 s in D having the central vertex in W and i vertices in V is
denoted by τ0i (i ∈ {0, 1, 2}). The number of K1,3 s in D having
the central vertex in V and i other vertices in V is denoted
by µ1i (i ∈ {0, 1, 2, 3}). The number of K1,3 s in D having the
central vertex in W and i vertices in V is denoted by µ0i (i ∈
{0, 1, 2, 3}). There are 10 different patterns of membership of
the vertices of a P4 in V or W . Listed in {V,W}4 to indicate
the membership of the four vertices on the path in sequence,
they are VVVV, VVVW, VVWW, VVWV, VWVW, VWWV,
VWWW, WVVW, WVWW, and WWWW; the remaining six
are reversals of those given. Index these from 0 to 9 in the
order given, and denote by ρi the number of occurrences of
the ith in D. Finally, let i be the number of triangles in
D meeting V in i vertices for i ∈ {0, 1, 2, 3}. Disconnected
graphs need not be considered, as their cost is the sum of the
costs of their components.
The objective function is the cost

2

 2

i=0





αi + 3 

1
2 

i=0 j=0

τji +

3



i 

i=0



1
3 
9


+ 4
µji +
ρi  ,
i=0 j=0

i=0

which is to be minimized. Three variables (µ13 , ρ0 , and 3 )
cannot arise in an N(n, v; C, C  ) with 1 ≤ C  < C ≤ 3, and
are eliminated. Linear combinations of the variables lead to
inequalities asserting that this linear combination is greater

300

NETWORKS—2008—DOI 10.1002/net

 
For every dual feasible solution S, zD (S) + νC,C  v+w
≤
2
v+w
zM + νC,C  2 = zL ≤ zL  ≤ cost ON (n, v; C, C  ). The
inequality zD (S) ≤ zM follows from linear programming
duality. The inequality zL  ≤ cost ON (n, v; C, C  ) follows
from the fact that every decomposition corresponds to some
integer feasible solution of L, and the objective function of L
is the drop cost.
3. COST ON (n, v ; 2, 1)
We consider only those variables that are permitted to be
nonzero in an N(n, v; 2, 1). We employ only two inequalities,
but retain nonnegativity of each variable, to relax the linear
program. A simple linear program L results, shown in table
form with the ﬁrst row giving the coefﬁcients of the objective
function, and later rows giving the constraints:

α0

α1

α2

τ10

τ11

τ00

τ01

τ02

2

2

2

3

3

3

3

3

0
0

0
−1

1
0

0
−2

1
−1

0
0

0
−1

0
−2

v 
2

−vw

Set ν2,1 =

3
2

α0

α1

α2

τ10

τ11

τ00

τ01

τ02

1
2

1
2

1
2

0

0

0

0

0

0
0

0
−1

1
0

0
−2

1
−1

0
0

0
−1

0
−2

to obtain the modiﬁed LP M:

v 
2

−vw

Form the dual linear program and remove dominated
inequalities to obtain y1 ≤ 21 , y1 − y2 ≤ 0, and −y2 ≤ 0.

Maximize 2v y1 − vwy2 subject to these constraints and
nonnegativity.
Lemma 3.1.
ON
 vcost

  (v + w, v; 2, 1) ≥ zL  ≥
3 w
max{ 23 v+w
,
2
+
2 2 + vw}. Equivalently, cost ON
2
2
(n, v; 2, 1) ≥ max{cost ON (n, 2), cost ON (n − v, 2)
+ v(n − 1)}.

Proof. Rewriting, zM ≥ max{0, 21 2v − 21 vw} is required.
Taking the dual feasible solution S = {y1 = y2 = 0} yields
zD (S) = 0. Taking instead S = {y1 = y2 = 21 } yields

zD (S) = 21 2v − 21 vw. Both provide lower bounds, and the
cost is integral.
■
For every integer n ≥ 6 let
 2n
if n ≡ 0 (mod 3)
3
ϑ2 (n) = 2n+1
if n ≡ 1 (mod 3)
3
 2n−1
if n ≡ 2 (mod 3)
3
Corollary 3.2. When v + w ≥  6 and v > ϑ2 (v + w),
cost ON (v + w, v; 2, 1) >  23 v+w
2 .
Proof. Let v > ϑ2 (v + w) = 2(v+w)+σ
where σ =
3
0, 1, −1 if v + w ≡ 0, 1, 2 (mod 3), respectively. It follows
that v > 2w + σ , and hence v + w > 3w + σ , and v + w ≥
3w + 3 + σ ≥ 3w + 2. Therefore v > 2w + 1. Then 2 2v +
 
  1 v  1
3 w
3 v+w
= 2 2 − 2 vw = 41 v(v − 1 − 2w) ≥ 1
2 2 + vw − 2 2
■
and the result follows.
 
Lemma 3.1 improves upon the trivial bound of  23 v+w
2 
only when v > ϑ2 (v + w). One does not need LP to obtain
these bounds. Indeed one could argue that LP complicates
them unnecessarily. However, even for such a simple situation, the linear program reveals useful information that a
case-by-case combinatorial analysis
may

  not. Suppose that
cost ON (v + w, v; 2, 1) = 2 2v + 23 w2 + vw. In the dual
feasible solution {y1 = y2 = 21 }, the dual constraints for α2 ,
τ11 , and τ00 are met with equality (i.e., are binding), while
those for α0 , α1 , τ10 , τ01 , and τ02 are not. Complementary
slackness (see [10], for example)

 ensures that in a primal feasible solution of cost 2 2v + 23 w2 + vw, it must happen that
α0 = α1 = τ10 = τ01 = τ02 = 0, and hence that all graphs
in an optimal decomposition are counted by α2 , τ11 , and τ00 .

Indeed we can solve the primal to obtain α2 = 21 v(v−1−2w)
and τ11 = vw (and hence τ00 = 41 w(w − 1)). Moreover, this
leads to the only way to meet the bound. This simpliﬁes the
development of a corresponding construction.

 
This relies on strict equality, but 2 2v + 23 w2 + vw need
not be integral. Nevertheless it points us in the right direction.
Suppose that φ = α0 + α1 + τ10 + τ02 . Now φ ≥ 0
and φ is integral. So suppose (to the contrary) that φ ≥ 1.
Adjoin this inequality to M and let y3 be its dual variable. The
dual feasible solution {y1 = y2 = 21 , y3 = 1} provides the

lower bound 21 2v − 21 vw + 1, and hence the cost exceeds


v 
2 2 + 23 w2 + vw, a contradiction. So φ = 0 whenever

 
cost ON (v + w, v; 2, 1) = 2 2v + 23 w2 + vw, eliminating
four of the eight graphs from consideration. This points to
τ01 as the count of graphs arising in the case when the basic
LP bound is fractional. How large can τ01 be? We claim that
τ01 < 2. Suppose (to the contrary) that τ01 ≥ 2. Adjoin this
inequality to M and call the corresponding dual variable y4 .
Then {y1 = y2 = y4 = 21 } is dual feasible, and leads to
an increase of 1 in the bound and hence a contradiction. We
conclude that τ01 ∈ {0, 1}. When τ01 = 0, this is the case
of strict equality seen before. When τ01 = 1, we compute in
addition α2 = 21 (v(v − 1 − 2w) + 2), τ11 = vw − 1, and
τ00 = 41 (w(w − 1) − 2).
This completely determines the types and numbers of subgraphs
  in any
 decomposition whose cost meets the bound
2 2v + 23 w2 + vw, and (in this case) establishes uniqueness of the selection of these types and numbers. This could
equally well be established by translating step-by-step the
arguments using linear programming duality into straightforward combinatorial arguments, but in general this is not
desirable. As the number of primal variables increases, cases
are typically amalgamated by grouping many individual
subgraphs together. The demerit is that one often loses information about the speciﬁc structure that a primal solution must
exhibit. However, lower bounds can (and should) be used to
guide the search for constructions for matching upper bounds
by informing us about potential values for the primal variables
in a detailed manner.
Until this point, by focussing on N(v + w, w; 2, 1) decompositions, we have been considering “toy” examples. Now we
extend this to more substantial problems in which the answer
is far less obvious.

4. COST ON (N , V ; 3, C  )
The linear program M of Table 1 considers graphs of a
decomposition N(v + w, w; 3, 2). To the extent possible, we
treat cases with C  ∈ {1, 2} together. To obtain the LP for
N(v + w, w; 3, 1), set τ12 = µ12 = ρ1 = 0 (delete the three
variables and drop the corresponding three dual inequalities
from D). Two inequalities from the ILP are retained (shown
as the ﬁrst and second), and the objective function is modiﬁed
using ν3,C  = 1 to form the LP M. In the process, integrality constraints are replaced by nonnegativity constraints,

NETWORKS—2008—DOI 10.1002/net

301

TABLE 1.

The linear program and dual feasible solutions.

α0 α1 α2 τ10 τ11 τ12 τ00 τ01 τ02 µ10 µ11 µ12 µ00 µ01 µ02 µ03 ρ1 ρ2 ρ3 ρ4 ρ5 ρ6 ρ7 ρ8 ρ9 0 1 2
1

1 1

1

1 1 1

1

1

1

1

1

1

1

1

1

1

1

1

1

1

1

1

1 1 0

0

0

0 0 1 0 1 2 0 0 0 0 1 2
0 −1 0 −2 −1 0 0 −1 −2 −3 −2 −1
0 1 2 0 1 2 0 1 2 1 2 3
2 1 0 2 1 0 2 1 0 3 2 1
2 0 0 0 0 0 2 2 0 0 0 0
2 2 2 1 1 1 1 1 1 0 0 0
1 1 1 2 2 2 2 2 2 3 3 3
1 0 0 0 0 0 2 1 0 0 0 0
0 0 0 0 0 0 0 0 −2 0 0 0
0 0 1 0 1 2 0 0 0 0 1 2

0 0 0 0 2 1 1 0 0 0 1 0 0 0 0 1
0 −1 −2 −3 −1 −1 −2 −3 −2 −1 −2 −2 0 0 −2 −2
0 1 2 3 1 1 2 1 2 1 0 0 0 0 0 0
4 3 2 1 1 1 0 1 0 1 2 2 2 0 0 0
4 2 2 0 0 2 0 0 2 2 0 2 2 0 2 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0
3 2 1 0 0 1 0 0 1 2 0 1 0 0 1 0
0 0 −2 −2 0 0 −2 −2 0 0 0 0 0 0 0 −2
0 0 0 0 2 1 1 0 0 0 1 0 0 0 0 0

Assignment

S

A1
A2
A3
A4
B1
B2
B3
B4
C1
C2
C3
C4
C5
C6

∅
{y3 = y4 = 41 }
{y3 = y4 = 41 , y6 = 41 }
{y6 = 13 , y7 = 13 }
{y1 = 1, y2 = 21 }
{y1 = 1, y2 = 21 , y5 = 41 }
{y1 = 1, y2 = 21 , y8 = 13 }
{y1 = 1, y9 = 21 }
{y1 = 21 , y2 = 41 }
{y1 = 21 , y2 = 41 , y5 = 41 }
{y1 = 21 , y2 = 41 , y8 = 13 }
{y1 = 21 , y9 = 41 }
{y10 = 38 , y4 = 41 }
6
3
2
1
{y1 = 16
, y2 = 16
, y3 = 16
, y4 = 16
, y5 =

NETWORKS—2008—DOI 10.1002/net

v 
2

−vw
v
v + w even
w
v + w even
w
w even
2
v + w ≡ 2 (mod 3)
4
v + w ≡ 5 (mod 6)
4
w ≡ 5 (mod 6)
−w(v − 1) v odd
1
2 (v − 1)(v − w) v odd

zD (S)

Condition

0
v+w
4
v+w+2
4

2
− 1 − w)
1
w
2 v(v − 1 − w) + 4
4
1
+
v(v
−
1
−
w)
3
2
1
2 (v − 1)(v − w)
1
4 v(v − 1 − w)
1
4 (v − 1)(v − w)
4
1
3 + 4 v(v − 1 − w)
1
(v
− 1)(v − w)
4
3
w
16 (v − 1)(v − w) + 4
3
1
1
v(v
−
1
−
w)
+
v
+
16
8
4w

v + w even
v + w ≡ 2 (mod 6)
v + w ≡ 5 (mod 6)

1
2 v(v

3
16 }

and inequalities have been adjoined. We justify the adjoined
inequalities next.
When v + w is even, in the decomposition every vertex in
V must appear as an odd degree vertex in at least one subgraph
(this is the third inequality); the same is true for every vertex
of W , leading to the fourth inequality. By the same token, the
ﬁfth arises by considering the decomposition induced on W —
again when w is even, every vertex of W must occur with odd
degree at least once in the decomposition induced on W . We
derive two inequalities based on the congruence modulo 3 of
the number of edges. The total number of edges is 0 (mod 3)
when v + w ≡ 0, 1 (mod 3), and 1 (mod 3) when v + w ≡ 2
(mod 3). Hence the sixth inequality states that either at least
one 1-edge graph or at least two 2-edge graphs must appear in
a decomposition when v+w ≡ 2 (mod 3). When v + w ≡ 5
(mod 6), the number of edges not appearing in triangles is at
least four (the maximum packing leaves at least four edges);
hence the seventh inequality. The eighth is obtained in the
same manner considering the decomposition restricted to W .
The ninth inequality employs the observation that, when v
is odd, for every vertex of W the number of graphs in which
it appears with at least two neighbours in V is at most v−1
2 ;
summing over all vertices in W yields the inequality. For the
tenth inequality, edges with both ends in V not appearing in
triangles counted by 2 must number at least 21 (v−1)(v−w).
We compute lower bounds on zM via feasible solutions of
D. Assignments to the dual variables are given in the second

302

Condition

w even
w ≡ 5 (mod 6)
v odd
w even
w ≡ 5 (mod 6)
v odd
v odd, w odd
v even, w even

part of Table 1; each is represented by a set of equalities for
dual variables and any dual variable not represented in the
set takes the value 0. In addition, the dual objective function
value is given, along with conditions on v, w, and v + w under
which this assignment is to be employed.
Dual assignments A1–A4 and C1–C6 are dual feasible
for the LP of Table 1 and hence, when the stated conditions
apply, each provides a lower bound on the value of a feasible solution. When the LP is restricted to N(v + w, v; 3, 1)
decompositions, the dual assignments B1–B4 are also dual
feasible (and hence all of those listed are).
4.1. cost ON (n, v; 3, 1)
We now derive lower bounds for cost ON (n, v; 3, 1).
Lemma 4.1.
1. For all v and w, cost ON (v + w, v; 3, 1) ≥ max
{cost ON (v + w, 3), 2 2v + cost ON (w, 3) + 21 vw}.
2. When v is odd, cost ON
 (v + w, v; 3, 1) ≥
max{cost ON (v + w, 3), 2 2v + w2 + 21 (v + 1)w}.

Proof. For both statements use dual feasible solutions
A1 when v + w ≡ 1, 3 (mod 6), A4 when v + w ≡ 5
(mod 6), A2 when v + w ≡ 0, 4 (mod 6), and A3 when
v + w ≡ 2 (mod 6). (The use of A3 results in a bound that
exceeds the integer ceiling of the bound of A2 only when

v + w ≡ 8 (mod 12), as when v + w ≡ 2 (mod 4) the bound
from A2 is half-integral.) For the second statement also use
B4. For the ﬁrst statement also use dual feasible solutions B1
when w ≡ 1, 3 (mod 6), B3 when w ≡ 5 (mod 6), and B2
when w ≡ 0 (mod 2). When v and w are even, and B2 is met
with equality, the bound must be improved by 1 when w ≡ 8
(mod 12). The only nonzero primal variables are α2 , µ00 , ρ2 ,
0 , and 2 . If ρ2 ≥ 1, consider such a path in the decomposition, and examine the unique vertex in W that has degree
two on this path. Consider its neighbours in V ; because every
triangle counted by 2 accounts for an even number of them,
the vertex must lie on two paths. Then 2ρ2 + 4µ00 ≥ w + 1.
Using this to tighten the ﬁfth inequality of the primal, B2
leads to the desired result. It remains
  to treat the case when
ρ2 = 0. Then 3(µ00 + 0 ) = w2 , counting edges on W in
 
two ways. But when w ≡ 8 (mod 12), w2 ≡ 1 (mod 3), so
this cannot occur.
■
For every integer n ≥ 6 let
 n−1
if n ≡ 1 (mod 4)
 2
if n ≡ 0 (mod 2)
ϑ3 (n) = n2
 n+1
if n ≡ 3 (mod 4)
2
Corollary 4.2. When v > ϑ3 (n), cost ON (n, v; 3, 1) >
cost ON (n, 3).
Proof. Apply Lemma 4.1(1) to compute lower bounds
on cost ON (v + w, v; 3, 1) − cost ON (v + w, 3) for all v, and
Lemma 4.1(2) to compute a second lower bound for odd values of v, taking the maximum. We tabulate these differences
next, classifying by the congruence classes of w and v + w.
Let χ = 21 v(v − 1 − w).
w −→
v+w↓

1, 3
(mod 6)

5
(mod 6)

1, 3 (mod 6)
χ
χ +2
5
(mod 6)
χ −2
χ
0, 4 (mod 12) χ + w−v+2
χ + w−v+2
4
4
8
(mod 12) χ + w−v−2
χ + w−v−2
4
4
2
(mod 4) χ + w−v
χ + w−v
4
4

0, 4
(mod 12)

8
(mod 12)

2
(mod 4)

χ + w2
χ + w−4
2
χ − 4v
v+4
χ− 4
χ − v+2
4

χ + w2
χ + w−4
2
χ + 4−v
4
χ − 4v
χ + 6−v
4

χ + w2
χ + w−4
2
χ − v−2
4
v+2
χ− 4
χ − 4v

When w < v − 1, χ ≥ 2v and hence the difference tabulated
is always at least 1. When w = v − 1, χ = 0. Then v + w ≡ 5
(mod 6) if and only if w ≡ 2 (mod 3). Thus when w > 2
is even, the difference is at least 1. Moreover when w is odd
(2w + 1 ≡ 3 (mod 4)) the difference is 0. When w ≥ v,
χ ≤ − 2v and the tabulated difference is never positive.
■
This proof demonstrates that the lower bounds of Lemma
4.1 agree with cost ON (v + w, v; 3, 1) exactly when v ≤
ϑ3 (v + w). To summarize, we have proved:
Theorem 4.3.
1. When v ≤ ϑ3 (v + w), cost ON (v + w, v; 3, 1) ≥
cost ON (v + w, 3).

2. When v is even
  and v > ϑ3 (v + w), cost ON (v +
w, v; 3, 1) ≥ 2 2v + cost ON (w, 3) + 21 vw.
3. When v is odd
 and v > ϑ3 (v + w), cost ON (v +
w, v; 3, 1) ≥ 2 2v + w2 + 21 (v + 1)w.

By treating cases with equality, we can again determine the
types and numbers of subgraphs to be employed in an optimal
decomposition in each case. In Table 2, for each dual feasible solution in Table 1 and each primal variable, we report
one of three situations. X denotes that the dual inequality is
violated (this occurs for three primal variables for B1–B4, as
expected). B denotes that the dual inequality is binding, and
hence that graphs counted by the primal variable may occur
in a primal solution meeting the bound. A number indicates
that the dual inequality is not binding; further it speciﬁes the
increase in the dual objective function that is incurred by each
unit increase in the primal variable. From this, we can “read
off” the types of graphs in any decomposition that meets the
bound, and ones that realize its integer ceiling. In the latter
case one can also immediately read off an upper bound on
the number of such graphs when the dual inequality is not
binding.
4.2. cost ON (n, v; 3, 2)
Now we turn to the most involved situation, that for
N(v + w, v; 3, 2) decompositions. The strategy is similar, but
here the LP relaxation leads, in certain cases, to fractional
solutions that do not yield the tightest lower bound. This
necessitates the introduction of further inequalities to enforce
integrality.
Lemma 4.4.
1. When v is even,
 cost ON (v+w, v; 3, 2) ≥ max{cost ON
(v + w, 3), 23 2v + 43 vw + cost ON (w, 3)}.
2. When v is odd,
 cost ON (v + w, v; 3, 2) ≥ max{cost ON
(v + w, 3), 23 2v + 43 vw + w2 + w4 }.
3. When
w are both odd, cost ON (v + w, v; 3, 2) ≥
v+w v and
3
(v − 1)(v − w) + 41 w.
+ 16
2
4. When
w are both even, cost ON (v + w, v; 3, 2) ≥
v+w v and
3
+
v(v
− 1 − w) + 18 v + 41 w.
16
2

Proof. For the ﬁrst two statements use dual feasible solutions A1 when v + w ≡ 1, 3 (mod 6), A4 when v + w ≡ 5
(mod 6), A2 when v + w ≡ 0, 4 (mod 6), and A3 when
v + w ≡ 2 (mod 6). For the ﬁrst statement also use dual
feasible solutions C1 when w ≡ 1, 3 (mod 6), C3 when
w ≡ 5 (mod 6), and C2 (subject to improvement below)
when w ≡ 0 (mod 2). For the second statement also use C4;
for the third use C5; and for the fourth use C6.
The bound from C2 must be increased by 1 when w ≡ 8
(mod 12). If one adjoins the inequality −22 ≥ −vw + 3 to
the linear program as the eleventh inequality, the dual solution
{y1 = 21 , y5 = y11 = 41 } increases the bound by at least 43 .
Hence 22 ∈ {vw − 2, vw}. Then 1 ≤ 1, but if 1 = 1 then
two vertices of W must participate in v−1
2 triples counted by
2 . Because v−1
is
not
integral,

=
0.
1
2

NETWORKS—2008—DOI 10.1002/net

303

TABLE 2.

Dual slackness of primal variables (B = binding, X = not permitted).

Variable

A1

A2

A3

A4

B1

B2

B3

B4

C1

C2

C3

C4

C5

C6

α0
α1
α2
τ10
τ11

1
1

B
B

B
B

1

1
2
3
2

2
3
3
2

1
1

1

B
B
B

B
2

B
2

B
2

1
2

1
2

1
2

B
1
B

2
3
5
4
1
2
3
2
3
4

1
1

B

1
2
5
4
1
2
3
2
3
4

1
1
1
1
1

B
B
B
B
B

X
1

X

X

B

B

1
2

1
3
7
6

1
2
3
4
3
2
7
4

1
3
11
12
3
2
7
4

B
1
1

1
2
3
4
5
8
1
2
3
8
1
4
1
2
3
4

1
2

3
2

τ12
τ00
τ01
τ02
µ10

1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2

3
2

1

1

1
4
1
8

1
2
5
8
9
8
5
4
5
8

µ11
µ12

1
1
1

B

1
4
1
4
1
4
1
4
1
4
1
4

B

3
2

2

1
2

2

5
2

5
2

5
2

X
1
1
2
1

5
4
1
2
3
2
3
4

B
1
5
4
3
2
7
4

1
2

1
1
2

1
3
8
5
4
5
8

B

1
1
1

B
B
B

B
B
B

B
B
B

1
X
1

1
X
B

1
X
B

B
X
1

1

1

1

1
2

1
4

1
4

1
4

1

B

B

B
1

B
B

B
B

1
1

B
B

B
B

B
B

3
2

1

2

1
1

B

B

5
2

X

X

X

B

B

ρ2
ρ3
ρ4

1
1

1
2

B
1

1
6

7
4
1
4
1
4

7
12
7
6
7
4
1
4
5
12

1
4
1
2
3
4

1
2

3
8
5
8
3
4

1
1
1
B

1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2

5
4
3
2
7
4
1
4
3
4

3
2
3
2

1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2
1
2

B
B

1
2
2
X

1

µ03
ρ1

5
6
5
3
5
2

3
4

3
2
5
2

3
4
1
8
1
2
1
2

1
2
5
8
9
8
1
4
1
4
3
4
11
8
9
16
5
8
7
8
7
8
1
2

B

B
B

B
B

µ00
µ01
µ02

ρ5
ρ6
ρ7
ρ8
ρ9
0
1
2

1
1
1

B
B

1

B
B
B

5
2
3
2
3
2

B

B
B
B
B

1
2
1
B

B
B

B
B

1
B

5
2

1
1

304

NETWORKS—2008—DOI 10.1002/net

1

B
1

1

1

1

1

5
2
7
6
5
6

2
1
1

7
4
5
4
5
4

7
4
3
4
3
4

7
4
11
12
7
12

3
2

1
1

1
1

1

1
2

7
6

1
2

1
B

1
1
B

B

B

B
B

B
B

B
B

1

1

3
2
1
2

5
3

B

1
B

1
2

2
3

B

B

Consider the bound of C2, the binding variables are τ12 ,
µ00 , 0 , 1 and 2 ; µ12 , ρ1 , and ρ2 have slackness 41 ; and
α0 , α2 , τ00 , and ρ9 with slackness 21 . All other variables have
larger slackness and can be ignored.
 0 + µ00 +
  Now 3(
ρ9 ) + 2τ00 + 1 + α0 + ρ2 = w2 and w2 ≡ 1 (mod 3),
but 1 = 0. Therefore 21 τ00 + α0 + ρ2 ≥ 1, increasing the
0
dual objective function by at least τ00 +α
+ ρ42 . When v ≡ 0
2
(mod 4), the bound from C2 is integral, and hence this case
is complete. When v ≡ 2 (mod 4), if τ00 > 0 then either
τ00 > 1 or α0 +ρ2 ≥ 1, in either case increasing the bound by
at least 43 . To limit the increase in the dual objective function
to at most 21 , τ00 = 0 and (α0 , ρ2 ) ∈ {(1, 0), (0, 1), (0, 2)}.
 
But α0 + ρ2 ≡ w2 (mod 3), so ρ2  = 2. If 22 = vw − 2
and ρ2 = 0 then µ12 + ρ1 = 2, increasing the dual objective
function by a further 21 and exceeding the bound. It remains
to treat cases when 22 = vw and µ12 = ρ1 = ρ2 = 0; and
when 22 = vw − 2 and ρ2 = 1 = µ12 + ρ1 . Among the
pairs on V , consider those not counted by 2 , µ00 , ρ1 , and
ρ2 ; in the ﬁrst case these number 21 v(v − 1 − w), and in the
second, 21 v(v − 1 − w) − 2. As v ≡ 2 (mod 4), this number is
odd and hence α2 ≥ 1. This increases the objective function
by a further 21 .
■

1

B
1
1
B
B
B

1
3
2

1
B
1
2

B

B
B
B

1
6

B

1

As with N(v + w, v; 3, 1) decompositions we can determine when the cost must exceed that of a decomposition into
subgraphs on at most three edges:
Corollary 4.5. When v > ϑ3 (n), cost ON (n, v; 3, 2) >
cost ON (n, 3).
Now we treat three cases in which the bound of Lemma
4.4 can be improved.
Lemma 4.6. If v is odd, and
 w = v− 1 or w ≤ v − 3, then
cost ON (v + w, v; 3, 2) ≥ 23 2v + w2 + 43 vw + w4 + δ, where
δ = 21 if w ≡ 4 (mod 6) and δ = 1 if w ≡ 5 (mod 6).
Proof. Consider the dual feasible solution C4. By Table
2, if any variable other than τ12 , µ12 , ρ1 , 0 , 1 , or 2
is nonzero, the bound increases by at least 21 (and hence the
bound on the cost increases by at least 1 when w ≡ 5 (mod 6)
as 41 (v − 1)(v − w) is integral). Among the remaining graphs,
only 0 and 1 count graphs
employing edges induced on
 
W ; hence 30 + 1 = w2 .
When w ≡ 4 (mod 6), 0 ≤ w(w−2)−2
because the tri6
angles induced on W form a packing by triples on w vertices.

Hence 1 ≥ w2 + 1. Adjoin this inequality and set its dual
variable to 21 . Together with C1, we obtain a dual feasible
solution whose dual objective function value exceeds the
bound from C4 by 21 .
When w ≡ 5 (mod 6), 0 ≤ w(w−1)−8
because the
6
triangles induced on W form a packing by triples on w vertices. Hence 1 ≥ 4. Every vertex of W can participate
in at most v−3
2 triples counted by 2 , and hence −22 ≥
−w(v − 1) + 8. Adjoin this inequality and set its dual variable equal to 41 . Further setting y1 = 21 increases the lower
■
bound by 2.
Lemma 4.7. If v ≡ 11, 17 (mod 24) then cost ON (2v −
2, v; 3, 2) ≥ 2v−2
+  5v−7
8  + 1.
2
Proof. Consider the dual feasible solution C5. All
graphs for which the dual inequalities are binding have three
edges but 2v − 2 ≡ 2 (mod 3), so either one graph with
one edge or two graphs with two edges are needed. Then by
1
Table 2, the optimal solution has cost at least 5v−7
8 + 2 , but
5v−7
1
5v−7
■
8 + 2 >  8 .
Lemma
When v is even, cost ON (2v − 2, v; 3, 2) ≥
2v−2 4.8.
9
1
+

v
−
16
2 + σ , where
2

0 if v ≡ 0 (mod 24)


1



24 if v ≡ 2 (mod 24)

1
σ = 8 if v ≡ 4, 6 (mod 24)


1

if v ≡ 8, 16 (mod 24)


6


1
otherwise
4


9v
Equivalently, cost ON (2v − 2, v; 3, 2) ≥ 2v−2
+  16
−
2
1
2  + δ, where δ = 1 if v ≡ 8, 22, 38, 40 (mod 48) and δ = 0
otherwise.
Proof. Among the graphs of a decomposition meeting
the bound with equality, the only ones inducing edges on W
are counted by 1 , 0 , and µ00 . All others have slackness
 
at least 41 . Thus to meet the bound within 41 , 1 ≡ v−2
 2 
(mod 3). Let 1 and 1 be integers congruent to v−2
2
(mod 3), with 1 ≤ 8v ≤ 1 , and either 1 = 8v = 1
 
(mod 3), 1 canor 1 + 3 = 1 . Because 1 ≡ v−2
3
not lie strictly between 1 and 1 ; hence either 1 ≥ 1
or −1 ≥ −1 . Adjoining the ﬁrst with dual variable set
14
7
, y2 = 32
, y3 =
to 41 and the remaining ones as {y1 = 32
2
5
3
32 , y4 = 32 , y5 = 32 } increases the dual objective function
by 41 (1 − 8v ). Instead adjoining the second with dual vari8
able set to 16 and the remaining as {y1 = 16
48 , y2 = 48 , y3 =
8
12
48 , y5 = 48 } increases the dual objective function value by
1 v
6 ( 8 − 1 ). Treating each case for v modulo 48 by taking the
minimum of the two choices establishes the result.
■
Next we collect the bounds in a form that is more useful
in the determination of corresponding upper bounds.

Theorem 4.9.
1. Suppose v is even.
a. If w ≥ v−1 (i.e., v ≤ ϑ3 (v+w)) then cost ON (v+
w, v; 3, 2) ≥ cost ON (v + w, 3).
b. If
w = v − 2 then cost ON (2v − 2, v; 3, 2) ≥
2v−2
9
v − 21  + δ, where δ = 1 if v ≡
+  16
2
8, 22, 38, 40 (mod 48) and δ = 0 otherwise.  
c. If w ≤ v−3 then cost ON (v+w, v; 3, 2) ≥ 23 2v +
cost ON (w, 3) + 43 vw.
2. Suppose v is odd.
a. If w ≥ v (i.e., v ≤ ϑ3 (v + w)) then cost ON (v +
w, v; 3, 2) ≥ cost ON (v + w, 3).
b. If
w = v − 2 then cost ON (2v − 2, v; 3, 2) ≥
2v−2
+  5v−7
2
8  + δ, where δ = 1 if v ≡ 11, 17
(mod 24) and δ = 0 otherwise.
c. If w = v − 1 or w ≤ v − 3 then cost ON (v +
w, v; 3, 2) ≥ 23 2v + w2 + 43 vw+ w4 +δ, where δ = 21
if w ≡ 4 (mod 6); δ = 1 if w ≡ 5 (mod 6); and
δ = 0 otherwise.

Proof.

This follows from Lemmas 4.4, 4.6, 4.7, and 4.8.
■

These bounds do not consider whether the subgraphs chosen can be combined to form a suitable decomposition, and
hence it is somewhat surprising that they turn out to be sufﬁcient. In the proof of sufﬁciency in [8], the determination of
cost ON (2v − 2, v; 3, 2) when v is odd is the most involved.
We again employ information from the dual to determine the
structure of a decomposition meeting the bound; we consider here only one case, when
(mod 48). Then
 v ≡ 24
9
1
cost ON (2v − 2, v; 3, 2) = 2v−2
v
+
16 − 2 is permit2
ted, as the bound is itself integral. By Table 2, the only
nonzero primal variables can be τ12 , µ12 , µ00 , 0 , 1 , and
2 . Hence at most six different types of graphs arise in an
optimal decomposition. Solve the primal to determine that
3v
τ12 = 8v , µ12 = 4v , µ00 = 16
− 21 , and 1 = 8v . Then deter 
1 v−2
3v
1
mine 0 = 3 ( 2 − 3( 16 − 21 ) − 8v ) = 48
(8v2 − 51v + 72)
and 2 = 41 (v2 − 5v). Because every vertex degree in W is
3v
odd, the 16
− 21 K1,3 s and 8v K2 s are all disjoint. Similarly, the
sets of three vertices for each K1,3 on V counted by µ12 and
the sets of endvertices in each path on two edges counted by
τ12 are all pairwise disjoint (as 3 4v + 2 8v = v, and all vertices
have odd degree). Some ﬂexibility remains, because the central vertex of a path counted by τ12 must appear also in a K1,3
or as an endvertex of a different path on two edges.
The linear programming approach also provides substantial guidance in what cannot work. For example, the edges
induced on V not appearing in triples counted by 2 , cannot
contain a 1-factor. Indeed the K1,3 s counted by µ12 induce
on V 4v disjoint paths on two edges (i.e., 4v disjoint nontrivial odd components). Any path of length two counted by τ12
contains at most one vertex (the central one) in an existing
component, and hence its addition does not decrease the number of odd components; adding each such path in turn results
in a graph having at least 4v odd components. This scuttles

NETWORKS—2008—DOI 10.1002/net

305

any chance for a wide variety of constructions that start with
a cycle decomposition on V , necessarily leaving a 1-factor.
5. CONCLUSIONS
To quote Sherlock Holmes from The Sign of Four, “How
often have I said to you that when you have eliminated the
impossible, whatever remains, however improbable, must be
the truth?”
Linear programming, and LP duality in particular, can tell
us how to eliminate the impossible—not just by providing a
lower bound, but by prescribing what must be true in order
for that bound to be met. Of course, linear programming has
been used very extensively for precisely this purpose in many,
many areas. For graph decompositions, current practice has
favored combinatorial arguments. Often these are remarkably
clever. Often they are as succinct as the linear programming
approach, and on occasion they are also simpler. However,
they can suffer from the need to include many similar cases
(or exclude them and ask the reader to accept that they are
similar). The LP approach amalgamates similar cases in a
natural way. Ultimately the strength of the lower bounds
derived is the principal concern, and so we end by referring
to [8] for the constructions that realize these lower bounds.
Naturally these are guided by the remarkable precision with
which the LP approach speciﬁes the graphs to be used in each
case.

[3]

[4]

[5]
[6]

[7]

[8]

[9]
[10]

[11]
[12]

[13]

REFERENCES
J.-C. Bermond and S. Ceroi, Minimizing SONET ADMs in
unidirectional WDM rings with grooming ratio 3, Networks
41 (2003), 83–86.
[2] J.-C. Bermond, C.J. Colbourn, D. Coudert, G. Ge, A.C.H.
Ling, and X. Muñoz, Trafﬁc grooming in unidirectional
WDM rings with grooming ratio C = 6, SIAM J Discrete
Math 19 (2005), 523–542.

[14]

[1]

306

NETWORKS—2008—DOI 10.1002/net

[15]

[16]

J.-C. Bermond, C.J. Colbourn, A.C.H. Ling, and M.L. Yu,
Grooming in unidirectional rings: K4 − e designs, Discrete
Math 284 (2004), 67–72.
J.-C. Bermond and D. Coudert, Trafﬁc grooming in unidirectional WDM ring networks using design theory, Proc IEEE
Conf Commun (ICC’03), IEEE, Vol. 2, Los Alamitos, CA,
2003, pp. 1402–1406.
D. Bryant, P. Adams, and M. Buchanan, A survey on the
existence of G-designs, J Combin Des; in press.
C.J. Colbourn and J.H. Dinitz, Handbook of combinatorial
designs, 2nd edition, CRC/Chapman and Hall, Boca Raton,
FL, 2007.
C.J. Colbourn, A.C.H. Ling, and G. Quattrocchi, Minimum
embedding of P3 -designs into (K4 − e)-designs, J Combin
Des 11 (2003), 352–366.
C.J. Colbourn, G. Quattrocchi, and V.R. Syrotiuk, Grooming
for two-period optical networks, Networks 52 (2008), 307–
324.
C.J. Colbourn and A. Rosa, Triple systems, Oxford University Press, Oxford, 1999.
W.J. Cook, W.H. Cunningham, W.R. Pulleyblank, and A.
Schrijver, Combinatorial optimization, Wiley, New York,
1998.
R. Dutta and G.N. Rouskas, Trafﬁc grooming in WDM
networks: Past and future, IEEE Network (2002), pp. 46–56.
J.Q. Hu, Optimal trafﬁc grooming for wavelength-division
multiplexing rings with all-to-all uniform trafﬁc, J Opt
Networks 1 (2002), 32–42.
E. Modiano and P. Lin, Trafﬁc grooming in WDM networks,
IEEE Commun 39 (2001), 124–129.
G. Quattrocchi, Embedding path designs in 4-cycle systems,
Discrete Math 255 (2002), 349–356.
J. Simmons, E. Goldstein, and A. Saleh, Quantifying the
beneﬁt of wavelength add-drop in WDM rings with distanceindependent and dependent trafﬁc, IEEE/OSA J Lightwave
Technol 17 (1999), 48–57.
P.-J. Wan, Multichannel optical networks, Kluwer Academic,
Norwell, MA, 2000.

Topology Control for MANETs
Prabhanjan C. Gurumohan

Thomas J. Taylor

Violet R. Syrotiuk

Department of Electrical Engineering
Arizona State University
e-mail: gpj@asu.edu

Mathematics & Statistics
Arizona State University
e-mail: tom.taylor@asu.edu

Computer Science & Engineering
Arizona State University
e-mail: syrotiuk@asu.edu

Abstract— We deal with the problem of topology control for
mobile ad hoc networks. Based on an asymptotic result on kconnectivity, a simple scheme for topology control is proposed.
The scheme is used to generate several topologies under highly
mobile conditions. Through simulation and analysis we show
that this scheme results in high connectivity even under mobile
conditions as the number of nodes increase. We also show that
even though the scheme uses varying transmit power, the overall
power consumption in the network remains relatively the same,
and is less than using constant transmit power as the number of
nodes increases. In order to use the scheme, the nodes need to be
uniformly distributed. We prove that under periodic boundary
conditions the stationary distribution of nodes, moving according
to (a variant of) the random waypoint model, is uniform.

I. I NTRODUCTION
Connectivity in a mobile ad hoc network (MANET) is
difficult to achieve. Due to the inherent nature of node mobility
and power restrictions, designing and maintaining a highly
connected network topology is complex. Topology control
schemes for MANETs have been proposed for achieving
specific objectives such as minimizing power utilization and
increasing network lifetime. Little work has been done in order
to maintain a good topology of the MANET consistently over
the lifespan of the network.
Most of the work on topology creation has dealt with
achieving connectivity with node selection as a secondary
problem. The primary problem usually attempts to find topologies to minimize power consumed. Rodoplu and Meng [1]
concentrate on achieving a minimum energy network by
making local decisions at each node. Minimum power paths
from each node to a master node are found by choosing nodes
that are within the transmit power range of d1n . The scheme
provided is for a network with static nodes; they do not deal
with connectivity and mobility issues.
Li et al. [2] develops an algorithm that increases network
longevity (reduces power consumption). Their algorithm selects a certain number of nodes that results in increased
longevity and reduced node degree. They also prove that nodes
chosen within cones having 2π
3 angle result in a minimum energy network. Insufficient analysis is provided on connectivity
and how to sustain it in a mobile environment.
Betstetter [3] models the neighbouring node distribution by
nearest neighbour methods known from analysis of spatial
data. The spatial distribution used has a normal form. The
work provides little evidence to show how randomly distributed nodes in a MANET can be modelled using such a

WCNC 2004 / IEEE Communications Society

distribution. Moreover, most of the work deals with randomly
distributed static nodes. The impact of mobility is analyzed
using techniques similar to those in [4].
The work in this paper is related to that of Ramanathan et al.
[5]. The topology scheme uses the idea of logarithmic change
in power depending on the number of neighbours as proposed
in [5]. The main difference is that our scheme proactively
chooses from the set of available neighbouring nodes when
there are more than k neighbours. This is an important
difference because the number of times the transmit power
changes is reduced. With fewer neighbours, the number of
link updates decreases resulting in lower power consumption.
Moreover their work lacks analysis of the connectivity.
Our scheme achieves a MANET topology that attains high
connectivity over the network lifespan. The scheme is developed using a result from Cooper et al. [4]. The basic idea of the
result is that in a completely connected graph, if k ≥ 3 nearest
neighbour links from each node are chosen to form a subgraph,
then the subgraph is k-connected with high probability as
number of nodes n → ∞. A similar result on the asymptotic
connectivity in wireless network was presented in Gupta et al.
[6]. It was mainly intended for ad hoc wireless network with
static nodes distributed in a unit radius. It was difficult to use
this result to implement a practical topology control scheme.
In order to use the transmit power change relation from
[5], the nodes must be uniform randomly distributed. Navidi
and Camp [7] claim that the stationary distribution for the
random waypoint mobility model is not uniform. On the
other hand with some simple assumptions such as periodic
boundary conditions and a Markov state model representation
of movement, we show that the stationary distribution of
nodes is indeed uniform. Further we propose a topology
creation scheme that actively manages the uniform number of
neighbouring nodes. We measure and analyze the connectivity
of such topologies with increasing numbers of nodes. We also
provide insight into power consumption in such networks. All
of our analysis and experiments are done considering mobile
nodes.
The rest of this paper is organized as follows. We present
basic definitions and models used in this work in section II.
We describe the topology control scheme and related issues in
Section III. In Section IV we provide simulation results and
analysis. A conclusion is provided in section V.

599

0-7803-8344-3/04/$20.00 © 2004 IEEE

II. D EFINITIONS AND M ODELS
A. Connectivity
We define the terms related to connectivity that are used in
this work. For k ≥ 2, a graph G is k-connected if either G
is a complete graph Kk+1 , or it has at least k + 2 vertices
and no set of k − 1 vertices separates the graph. Similarly,
for k ≥ 2, a graph G is k edge-connected if it has at least
two vertices and no set of at most k − 1 edges separates G.
A connected graph is 1-connected and 1 edge-connected. The
maximal value of k for which a connected graph is k edgeconnected is the edge-connectivity of G. The term connectivity
is used to mean edge-connectivity in this work.
The average connectivity of the topologies generated by our
scheme are measured using Mengers theorem [8]. The minimal
number of edges separating the source from the destination
is equal to the maximal number of edge-disjoint sourcedestination paths. Using this result we define the average
connectivity as the average number of edge disjoint paths
between any two nodes. The degree of a node u, d(u), is
the number of nodes adjacent to u. The pairwise degree of a
pair of nodes u and v is the minimum degree among the pair;
minu,v∈V (d(u), d(v)).
B. Mobility Model
One of the key characteristics of a wireless node is its
mobility. Mobility measurements could be used, but are not
a good choice for fast results and often require extensive
preparation. Traces of mobile terminal movements in realworld scenarios are able to capture only certain aspects within
the respective scenarios and are thus also limited in their
application. Therefore, the utilization of a mobility model is
necessary.
Several different mobility models for wireless nodes have
been developed. A good overview is provided by Boleng
et al. [9]. These models are based on either the mobility
of a single node or a group of nodes. For our work, we
consider the single wireless node movement models without
group mobility aspects. We choose a Markovian variant of the
random waypoint model as the underlying mobility model.
Although there are some well-known drawbacks in this model,
it was chosen because of its extensive use in MANET system
design (MAC, routing design etc.) and simulation tools.
The random waypoint model was developed to provide a
more realistic model than Brownian motion. The difference is
the inclusion of pause time in the random waypoint model.
The model itself was first used in [10]. Initially, each node is
placed at a random position within the simulation area. Each
node then chooses a destination at random and moves towards
it at a specified speed. Once the node reaches the destination
it pauses (remains in that position) for the pause time. This
sequence of selecting a destination at random, moving to the
destination, and pausing is repeated for the duration of the
simulation. Shortcomings of the random waypoint model have
been pointed out in Yoon et al. [11].
Our mobility model uses periodic boundary conditions on
the position of the nodes. This choice was made to facilitate

WCNC 2004 / IEEE Communications Society

analysis, but is also a reasonable approximation of node
mobility in a situation where the number of nodes entering
and leaving a region should be balanced.
C. Stationary Distribution of Mobility Model
Let s(t) be the speed of a node, θ the heading of a node,
and x(t) represent the position of the node. Each mobile node
is either in motion with speed s in direction θ (state 0), or in
a state of rest (state 1), i.e., it has paused. This is illustrated
in the state diagram below.
PQRS
WVUT
state0 l

λ2

-

PQRS
WVUT
state1

λ1 (θ,s)

The transition probability matrix for the above model in
shorthand form is as follows:


λ2 µ(θ, s)
−λ2
;
P=
λ1 µ(θ, s) −λ1(θ, s)
where the rate of transition out of the rest state is λ2 , the rate
of transition into the moving state with speed s and direction
θ is λ2 µ(θ, s), where µ(θ, s) ≥ 0 and µ(θ, s)dθds = 1, and
the rate of transition out of the moving state with speed s and
direction θ and into the rest state is λ1 (θ, s).
This shorthand represents the following system of
differential/partial differential/integral equations (ChapmanKolmogorov Equation) [12]. Taking account of the rates of
transition into and out of the state with zero velocity, we
obtain the following equation for the probability density of
being in zero speed state at the position x:
d
p(x, 0, t) = −λ2 p(x, 0, t) +
dt


λ1 (θ, s)p(x, θ, s, t)dθds

Similarly, taking account of the rates of transition into and
out of the state, with the node travelling at a speed s and in
direction θ at time t, and also taking account the conservation
of probability mass due to the node leaving the position
x with speed s and direction θ, the Chapman-Kolmogorov
equation is given by:
d
p(x, θ, s, t) = λ2 µ(θ, s)p(x, 0, t) − λ1 (θ, s)p(x, θ, s, t)
dt
+(s cos θ, s sin θ).∇x p(x, θ, s, t)
We claim that there is a stationary density for this Markov
process, p(x, θ, s), that is independent of x (i.e., p(x, θ, s) =
p(θ, s)). For nonzero velocities this is equal to
p(θ, s) =

λ2 p(0)µ(θ, s)
,
λ1 (θ, s)

and for zero speed is equal to

600

p(0) =

1 + λ2



1
µ(θ,s)
λ1 (θ,s) dθs.

.

0-7803-8344-3/04/$20.00 © 2004 IEEE

Indeed, for nonzero speed, and under the assumption of
independence of x, the equation
d
p(x, θ, s, t) = 0,
dt
implies that λ2 µ(θ, s)p(0) − λ1 (θ, s)p(θ, s) = 0, hence that
p(θ, s) =

λ2 p(0)µ(θ, s)
.
λ1 (θ, s)

d
Then the equation dt
p(x, θ, 0, t) = 0 and the constraint
p(0) + p(θ, s)dθds imply the result for p(0).
We have constructed a stationary distribution that is independent of x. It follows that the marginal distribution on
position of nodes is uniformly distributed with respect to
position. Under this model, the velocity of nodes is a Markov
process in its own right, which must have as stationary
distribution — the density p(θ, s) given above. It follows that
the only stationary distribution for the joint velocity/position
process is also as given above.

III. T OPOLOGY C ONTROL S CHEME
It has been shown in the literature that more shorter hops
for communication in a MANET is advantageous compared
to fewer longer hops. The main advantages of having shorter
hops are:
1) The overall power consumption in the network is reduced.
2) Better link budgeting can be achieved leading to better
transceiver design.
Another important property that results by connecting to
closest neighbours is high connectivity. This is proved by
Cooper et al. [4] for the following model: Consider the
complete graph Kn on n vertices in which edge e is assigned
a length Le . Let k shortest edges incident with each vertex
be coloured green and the rest blue. The graph with green
edges only is called the kth nearest neighbour graph. Le
are independent uniform [0, 1] random variables. This random
model is called Ok .
The main result from [4] is:
Theorem 1: If k ≥ 3 is fixed, then limn→∞ Pr (Ok is
k−connected) = 1.
Our topology control scheme is based on the idea of
connecting to the k closest neighbours. We assume that
the antenna used by the mobile nodes are omnidirectional.
Therefore, discovering the closest neighbours is not selective.
Instead, all of the neighbours in the transmission range of a
node with an initial power p0 are discovered. If the number of
neighbours is less than the required number of neighbouring
nodes k, then the transmission power is increased. If the
number of neighbours is greater than the required number of
neighbouring nodes k, the closest k neighbours are retained as
the neighbouring nodes and the rest purged from the neighbour
list. Hence each node is forced to maintain k neighbours. The
steps of the topology control scheme are:
S1 Find all neighbouring nodes U using power p0 .
WCNC 2004 / IEEE Communications Society

S2 If the number of neighbours is less than k, |U | < k,
then increase the transmission power.
S3 If the number of neighbours is greater than k, |U | > k,
• Choose the k nearest neighbours from the set of
neighbouring nodes U and delete the rest.
• Decrease the transmission power.
S4 Repeat these steps at regular intervals.
The change in transmit power is achieved by using the
logarithmic increase and decrease of power depending on the
number of neighbours. The relation is:
k
)
(1)
dc
where pt is the transmit power, pc is the current used power
and dc is the current node degree. k is the desired number of
neighbours. This relation is based on propagation loss function
that varies as some  power of distance. The value of 
is usually between 2 and 5, depending on the environment.
More details about the equation is provided in [5]. Of course,
the increase in the power is limited by the maximum power
specified by the transceiver used by the nodes.
The network structure generated by applying the topology
control scheme has more edges relative to network structure
generated without the scheme. This helps in maintaining high
connectivity even when the nodes are sparse, however the price
is higher power consumption.
pt = pc − 5 ·  · log(

IV. P ERFORMANCE E VALUATION
The topology control scheme proposed achieves better connectivity than an unmodified MANET. As already shown, the
connectivity improves with the number of nodes or higher
node density. Also, maintaining a small and uniform number of
neighbouring nodes has major advantages. It leads to reduced
computation and fewer changes in transmission power. This
leads to lower power consumption over the entire network. In
fact, as the number of nodes increase the power consumed to
maintain a fixed number of neighbours is less. Consequently
a topology control scheme leads to less power consumption
than otherwise. As we see, both connectivity improvements
and power consumption are substantiated by the simulation
results.
A. Connectivity
Experiments were conducted using the ns-2 network simulator [13]. Ns-2 uses the random waypoint model as the
mobility model. The connectivity experiments were conducted
using 25, 50, 100, and 200 nodes randomly distributed in an
area of 500 × 500m. All simulations were performed with
nodes in constant motion (i.e., zero pause time). These nodes
have a uniform stationery distribution as proved in section
III. A model of a AT&T WaveLAN PCMCIA card is used
as the transceiver by each node. The card has a minimum
transmission radius of 40m (each node can cover 8% of the
total area) and a maximum radius of 250m. Transmission
power required for the minimum transmission radius 40m is
used in order to reduce the power consumption.

601

0-7803-8344-3/04/$20.00 © 2004 IEEE

Pairwise Degree

The topology control scheme is implemented using the
neighbour management functions available in the AODV [14]
routing protocol. The topology control scheme is run every
1 second (at every HELLO INTERVAL, when the neighbour
management sends a hello message) generating approximately
200 different topologies over a simulation period of 200
seconds. The initial two and final one topologies are discarded.
This is due to partial topologies generated due to initial
conditions and the end of the simulation.
The connectivity is measured using the definitions given in
section II. The pairwise degree is considered the upper bound
on node degree; this is easily shown. The maximum pairwise
degree value is equal to k if all nodes have uniform node
degree. Although we try to maintain a uniform number of
neighbours, it does not guarantee uniform node degree. This
is because many nodes may have one single node as their
neighbour, even though all of them have same number of
neighbours. Few heuristic mechanisms could be developed to
force uniform node degree. Most of these techniques require
exchange of a neighbour list and could result in high control
signal traffic reducing the throughput drastically. One of our
future works is to develop a mechanism to force uniform
node degree without degrading the throughput. However, for
improving connectivity the proposed scheme is sufficient. The
pairwise degree for each node averaged over approximately
200 topologies for different values of n with and without the
topology control scheme is presented in Figure 1.
Figure 2 shows the average connectivity for each node
pair averaged over approximately 200 topologies for different
values of n with and without the topology control scheme.
It is easily deduced that the topology control mechanism
achieves high connectivity. Another important observation is
that connectivity increases with the increase in the number of
nodes.
B. Power Consumption
The power consumed by each transmission and reception by
each node was measured. From this data, the average power
consumed by each node over time is computed. This average
power is normalized with transceiver power. This value is
defined as the average power expenditure per node. This
experiment is conducted for topologies using 25, 50, 100 and
200 nodes. The experiment was repeated with and without the
topology control algorithm. The AT&T WaveLAN card was
set to 0.858mw constant transmit and receive power when
used without the topology control scheme. With the topology
control scheme the transmit and receive power varied using
equation (1). We use k = 6 neighbouring nodes in each case.
The antenna gain is set to 0db. The initial transceiver energy
is set to 10.0 Joules.
Figure 3, 4, and 5 show the average energy expenditure per
node for a network with 25, 50, and 100 nodes, respectively.
The graphs show that use of the topology control scheme
does not result in an increase in power consumption. On
the contrary, as the number of nodes n increases, the use
of the topology control scheme results in reduced power

WCNC 2004 / IEEE Communications Society

7
Topology control
Without Topology control
6

5

Degree

4

3

2

1

0
20

40

60

80

100

120

140

160

180

200

180

200

Number of Nodes

Fig. 1.

Average Pairwise Degree
Average Edge Connectivity

7

Topology control
Without Topology control

Average number of edge disjoint paths

6

5

4

3

2

1

0
20

40

60

80

100

120

140

160

Number of Nodes

Fig. 2.

Average Edge Connectivity

consumption. As mentioned earlier, this is due to a combination of reasons such as low transmit and receive power,
choosing closest neighbours, and selecting a fixed number of
neighbours.
V. C ONCLUSION
A topology control scheme for a mobile ad hoc wireless
network was presented. The scheme was based on the idea
of adjusting the transmission power of each node to reach
its k closest neighbours, where k ≥ 3. We also proved that
the stationary distribution of mobile nodes under a variant of
the random waypoint mobility model is uniform. As a result,
we were able to use the power adjustment scheme which
requires that the nodes to be uniformly distributed. Finally,
we proved that such a scheme results in better connectivity,
while consuming low power.

602

R EFERENCES
[1] V. Rodoplu and T. H. Meng, “Minimum energy mobile wireless network,” IEEE JSAC, vol. 17, p. 1333, August 1999.
[2] R.Wattenhofer, L.Li, P. Bahl, and Y.-M.Wang, “Distributed topology
control for power efficient operation in multihop wireless ad hoc
networks,” in Proceedings of IEEE Infocom, April 2001.

0-7803-8344-3/04/$20.00 © 2004 IEEE

Average Energy Expenditure

[5] R. Ramnathan and R. Rosales-Hain, “Topology control of multihop radio
networks using transmit power adjustment,” in Proceedings of IEEE
Infocom, pp. 404–413, March 2002.
[6] P. Gupta and P. R. Kumar, “Critical power for asymptotic connectivity
in wireless networks,” Stochastic Analysis, Control, Optimization and
Applications: A Volume in Honor of W.H. Fleming, W. M. McEneaney,
G. Yin, and Q. Zhang (Eds.), 1998.
[7] W. Navidi and T. Camp, “Stationery distributions for the random way
point mobility model,” Tech. Rep. MCS-03-04, The Colarado School of
Mines, April 2003.
[8] B. Bollobas, Modern Graph Theory, ch. 3, p. 75. Springer, 1998.
[9] T. Camp, J. Boleng, and V. Davies, “A survey of models for ad hoc
network research,” Wireless Communication and Mobile Computing,
vol. 2, no. 5, pp. 483–502, 2002.
[10] D. B. Johnson and D. A. Maltz, Dynamic Source Routing in Ad Hoc
Wireless Networks, ch. 5, pp. 153–181. Kluwer Academic Publishers,
1996.
[11] J. Yoon, M. Liu, and B. Noble, “Random waypoint considered harmful,”
in Proceedings of IEEE Infocom, April 2003.
[12] S. M. Ross, Introduction to probability models, ch. 4, p. 185. Academic
Press, 8 ed., 2003.
[13] “The network simulator-ns-2.” http://www.isi.edu/nsnam/ns/.
[14] C. Perkins and E. M. Royer, “Ad hoc on demand distance vector
routing,” in Proceedings of the 2nd IEEE WMCSA, ‘1999.

Average energy expenditure per node/Transceiver power

18
Without Topology control
Topology control

16

14

12

10

8

6

4

n=25 nodes

2

0

0

20

40

60

80

100

120

140

160

180

200

Time in seconds

Fig. 3.

Average Energy Expenditure/Node for 25 Nodes Topology
Average energy expenditure

Average energy expenditure per node/Transceiver power

80

Without Topology control
Topology control

70

60

50

40

30

20

10

n=50 nodes
0

0

20

40

60

80

100

120

140

160

180

200

Time in seconds

Fig. 4.

Average Energy Expenditure/Node for 50 Nodes Topology
Average energy expenditure

Average engergy expenditure per node/Transceiver power

90
Without Topology control
Topology contorl

80

70

60

50

40

30

20

10

n=100 nodes
0

0

20

40

60

80

100

120

140

160

180

200

Time in seconds

Fig. 5.

Average Energy Expenditure/Node for 100 Nodes Topology

[3] C. Bettstetter, “On the minimum node degree and connectivity of a
wireless multihop network,” in Proceedings of ACM Mobihoc, pp. 80–
91, June 2002.
[4] C. Cooper and A. Frieze, “On the connectivity of random k-th nearest
neighbor graphs,” Combinatorics, Probability and Computing, vol. 4,
no. 343, 1996.

WCNC 2004 / IEEE Communications Society

603

0-7803-8344-3/04/$20.00 © 2004 IEEE

Steepest-Ascent Constrained Simultaneous
Perturbation for Multiobjective Optimization
DANIEL W. MCCLARY and VIOLET R. SYROTIUK
Arizona State University, Tempe
and
MURAT KULAHCI
Technical University of Denmark, Lyngby

The simultaneous optimization of multiple responses in a dynamic system is challenging. When
a response has a known gradient, it is often easily improved along the path of steepest ascent.
On the contrary, a stochastic approximation technique may be used when the gradient is unknown or costly to obtain. We consider the problem of optimizing multiple responses in which the
gradient is known for only one response. We propose a hybrid approach for this problem, called
simultaneous perturbation stochastic approximation steepest ascent, SPSA-SA or SP(SA)2 for short.
SP(SA)2 is an SPSA technique that leverages information about the known gradient to constrain
the perturbations used to approximate the others. We apply SP(SA)2 to the cross-layer optimization of throughput, packet loss, and end-to-end delay in a mobile ad hoc network (MANET), a selforganizing wireless network. The results show that SP(SA)2 achieves higher throughput and lower
packet loss and end-to-end delay than the steepest ascent, SPSA, and the Nelder–Mead stochastic
approximation approaches. It also reduces the cost in the number of iterations to perform the
optimization.
Categories and Subject Descriptors: G.1.6 [Numerical Analysis]: Optimization; G.3 [Mathematics of Computing]: Probability and Statistics—Stochastic processes; C.2.1 [Computer Communication Networks]: Network Architecture and Design—Wireless communication
General Terms: Performance
Additional Key Words and Phrases: Multiobjective optimization, nongradient optimization,
stochastic approximation, mobile ad hoc networks, cross-layer optimization

The work of V. R. Syrotiuk was supported in part by ONR N00014-08-1-1970. Any opinions,
findings, conclusions, or recommendations expressed in this article are those of the authors and
do not necessarily reflect the views of the Office of Naval Research. The work of M. Külahçi was
supported in part by the Danish Agency for Science, Technology and Innovation grant 274-080280.
Authors’ Addresses: D. W. McClary and V. R. Syrotiuk, School of Computing, Informatics and
Decision Systems Engineering, Arizona State University, P.O. Box 878809, Tempe, AZ 852878809, USA; email: {fDaniel.McClary,syrotiukg}@asu.edu; M. Kulahci, DTU Informatics Richard
Petersens Plads, building 321, DK-2800 Lyngby, Denmark, email: mk@imm.dtu.dk.
Permission to make digital or hard copies of part or all of this work for personal or classroom use
is granted without fee provided that copies are not made or distributed for profit or commercial
advantage and that copies show this notice on the first page or initial screen of a display along
with the full citation. Copyrights for components of this work owned by others than ACM must be
honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers,
to redistribute to lists, or to use any component of this work in other works requires prior specific
permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn
Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org.

C 2010 ACM 1049-3301/2010/12-ART2 $10.00
DOI 10.1145/1870085.1870087 http://doi.acm.org/10.1145/1870085.1870087
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2

2:2

•

D. W. McClary et al.

ACM Reference Format:
McClary, D. W., Syrotiuk, V. R., and Kulahci, M. 2010. Steepest-ascent constrained simultaneous
perturbation for multiobjective optimization. ACM Trans. Model. Comput. Simul. 21, 1, Article 2
(December 2010), 22 pages.
DOI = 10.1145/1870085.1870087 http://doi.acm.org/10.1145/1870085.1870087

1. INTRODUCTION
Due to its complexity, the optimization of a dynamic system often considers
multiple responses simultaneously. Some challenges arise from the dynamics
of the system itself; as the conditions of the system change, the optimized responses achievable may also change. Other challenges arise from the objective
involving multiple responses; a technique that optimizes only one response of
the system may adversely affect the others. An approach to a solution to these
and other challenges may depend on the amount of information known about
the system.
When a response has a known gradient, following the path of steepest ascent
(descent) finds an optimization with little experimental overhead. Response
surface methodology (RSM) utilizes a collection of statistical and mathematical techniques to develop a gradient and optimize a response in a stepwise
fashion [Box and Wilson 1951; Myers and Montgomery 2002]. In the case of
multiple responses, RSM resorts to nonlinear programming or the visual inspection of a series of overlays produced by superimposing contour plots of
each response; these techniques are limited when a model of a response is
unavailable. This may occur because a model may be prohibitively difficult or
costly to obtain. Methods for nongradient-based optimization [Andersson 2000;
Swisher et al. 2000] have been developed for such a situation. These include
gradient-free methods such as simulated annealing [Eglese 1990] and genetic
algorithms [Liepins and Hilliard 1989], as well as approaches to approximate
the unknown gradient such as, for example, finite-difference stochastic approximation (FDSA) [Kiefer and Wolfowitz 1952] and simultaneous perturbation
stochastic approximation (SPSA) [Spall 1998b]. While useful when models are
unavailable, nongradient methods of optimization often have a higher computational cost than their gradient-based counterparts. Another approach in
some multiple responses is to optimize one single response while keeping the
other responses at a certain target [Kleijnen et al. 2010].
We consider the problem P of optimizing multiple responses {R1 , R2 , . . . , Rk}
in which the gradient is known for only one response. Without loss of generality,
we assume that a model is known for R1 and that the objective is to maximize
R1 . Applying steepest-ascent optimization to R1 may substantially degrade
the other responses. Similarly, the application of a stochastic approximation
technique discards the useful model known for R1 . We therefore propose a
hybrid approach for the problem P called simultaneous perturbation stochastic
approximation steepest ascent, SPSA-SA or SP(SA)2 for short. SP(SA)2 is an
SPSA technique that leverages information about the known gradient R1 to
constrain the perturbations used to approximate the others.
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:3

We apply SP(SA)2 to multiple response optimization in a specific dynamic
system: a mobile ad hoc network (MANET). A MANET is a collection of mobile
wireless nodes that self-organize without supporting infrastructure or centralized control. As with most networks, the architecture of a MANET is layered.
Numerous protocols have been proposed for each layer, and significant effort
has been invested to optimize the protocols at each layer individually. More
recently, research has focussed on optimizing interactions within (intra-layer)
and among (inter- or cross-layer) protocols [Srivastava and Motani 2007].
Specifically, we apply SP(SA)2 to the optimization of throughput, packet loss,
and end-to-end delay in a MANET. We have a model for one of the responses—
throughput—developed over a wide range of MANET conditions [McClary et al.
2010], but do not have models for the other two responses. As we will see, the
model for throughput has several interaction terms, most of which are intralayer while others are cross-layer. This suggests that the interactions within
and between the routing and medium access control (MAC) protocols should
be considered to optimize throughput. The gradient of throughput constrains
how perturbations in SP(SA)2 are used to approximate the gradient of endto-end delay and packet loss, and are used to determine settings for protocol
parameters that are involved in intra- and cross-layer interactions. The results
show that SP(SA)2 achieves higher throughput and lower packet loss and endto-end delay than the steepest-ascent, SPSA, and the Nelder–Mead stochastic
approximation approaches. It also reduces the cost in the number of iterations
to perform the optimization.
The rest of this article is organized as follows. Section 2 presents the model of
throughput developed earlier, and motivates both the need for intra- and crosslayer optimization and our hybrid approach to optimize multiple responses.
Section 3 discusses cross-layer optimization in MANETs as well as shortcomings in standard approaches to multiple response optimization. Section 4 introduces the hybrid SP(SA)2 approach and describes the conditions under which
it is applicable. Section 5 presents the results of applying SP(SA)2 to our multiple response optimization problem in MANETs and compares its performance
with steepest-ascent, SPSA, and the Nelder–Mead stochastic approximation
approaches. Finally, Section 6 summarizes our contributions and concludes.
2. CASE STUDY: PROFILE-DRIVEN REGRESSION
AND CROSS-LAYER OPTIMIZATION
We use a model of throughput for a MANET developed using profile-driven
regression (PDR) [McClary et al. 2010]. At a high level of abstraction, PDR
consists of four steps. First, it characterizes the effect of each factor and twoway interactions between factors on a response. Second, an intermediate model
is fit to each resulting profile. Third, an overall model of the response is fit in
terms of all the factors. Fourth, an analysis of the fit of the overall model is
conducted.
We apply PDR to model throughput in a layered MANET architecture: applications transmit constant bit rate (CBR) flows using the user datagram protocol
(UDP) at the transport layer, over the ad hoc on-demand distance vector (AODV)
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:4

•

D. W. McClary et al.
Table I. The Factors Considered in Developing a Model of
Throughput (T ) using PDR.
Factor
MY ROUTE TIMEOUT
ACTIVE ROUTE TIMEOUT
MAX RREQ TIMEOUT
RREQ RETRIES
REV ROUTE LIFE
BCAST ID SAVE
Short Retry Limit
Long Retry Limit
Data Rate
Mean Node Speed

Default Value

Variable Name

10 ≡ 100 s
10 ≡ 50 s
10 ≡ 10 s
3 retries
6 ≡ 5s
6 ≡ 3s
7 retries
4 retries
1 Kbps
m/s (varies)

A
B
C
D
E
F
G
H
J
K

Fig. 1. The regression model for average throughput T projected onto node speed (K) and data
rate (J) [McClary et al. 2010].

routing protocol at the network layer [Perkins and Royer 1999], over the IEEE
802.11b protocol [802.11 1999] at the medium access control (MAC) sublayer,
running over an 11 Mbps channel using a two-ray ground propagation model.
We restrict our attention to ten factors based on earlier work and in order to
bound the study [Mullen et al. 2004; Vadde and Syrotiuk 2004a; Vadde and
Syrotiuk 2004b; Vadde et al. 2006]. The factors include six timer-value parameters from AODV, two retry counter parameters from IEEE 802.11b, data rate,
and node speed. The factors and their levels are given in Table I.
The resulting model of throughput (T ) produced by PDR is given in Eq. (1).
The terms δ and ω represent the distinct changes in significant terms at specific
node speeds evident in Figure 1, a projection of the model in three dimensions.
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:5

Eqs. (2) and (3) give δ and ω as step functions, respectively.
T = 1.833 − 0.008K + Jω − 0.1Aδ − 0.049Bδ + 0.108C − 0.06C K
+ 0.002C K2 − 0.51Dδ − 0.79Eδ − 0.21Fδ + 0.08Gδ + 0.38ABδ
− 0.51AEδ + 0.23AFδ + 0.13BDδ + 0.23BFδ + 0.51BGδ − 0.2C Dδ
+ 0.14C Eδ − 0.2DEδ + 0.23DFδ.

δ =

1 if 10 m/s < K < 20 m/s,
0 otherwise.

⎧
⎨ −1.22
−0.18
ω =
⎩
−1.23

if K ≤ 10 m/s
if 10 m/s < K < 20 m/s
if K ≥ 20 m/s.

(1)
(2)

(3)

In examining the model for node speeds between 10 m/s and 20 m/s, the
throughput is influenced by pairwise interactions between protocol factors
(i.e., the terms AB, AE, AF, BD, BF, BG, C D, C K, DE, DF). These factors come
from the AODV routing protocol and the IEEE 802.11b MAC protocol and
suggest that the interactions, both intra-layer and inter- or cross-layer, are
important to consider in order to optimize throughput at these node speeds.
The partial derivatives from which the model for T was constructed are
given in Eq. (4). These models may also be used locally by each node to optimize controllable factors at runtime in terms of its measured node speed. Such a
runtime optimization resulted in throughput as much as six times higher than
that achieved with the factors at their default levels at most node speeds between 0 and 30 m/s, but showed much weaker performance at 15 m/s [McClary
et al. 2010].
A = −0.1δ

(4)

B = −0.49δ
C = 0.108
D = −0.51δ
E = −0.79δ
F = −0.21δ
G = 0.08δ
J = ω
Examining the model of throughput in conjunction with the partial derivatives
suggests that a weaker gain in performance at node speeds between 10 m/s
and 20 m/s is perhaps due to a failure to consider interactions in the runtime
optimization. Because PDR iteratively de-aliases effects on the response one
factor at a time, the partial derivatives suggest how to set the various protocol
parameters, but do not take factors other than node speed (K) into account.
The partial derivative of T with respect to a factor F gives the effect of
F on throughput. We conduct a runtime optimization of throughput where
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:6

•

D. W. McClary et al.

each node uses Eq. (5) to optimize each controllable factor as a function of its
measured node speed rather than Eq. (4). Though negligibly higher throughput
was obtained, a 17% decrease in packet loss at 15 m/s was obtained.
∂ T /∂ A = −0.1δ + 0.38Bδ − 0.51Eδ + 0.23Fδ,
∂ T /∂ B = −0.49δ + 0.38Aδ + 0.13Dδ + 0.23Fδ + 0.51Gδ,

(5)

∂ T /∂C = 0.108 − 0.056K − 0.2Dδ + 0.14Eδ,
∂ T /∂ D = −0.51δ + 0.13Bδ − 0.2Cδ − 0.2Eδ + 0.23Fδ,
∂ T /∂ E = −0.79δ − 0.51Aδ + 0.14Cδ − 0.2Dδ,
∂ T /∂ F = −0.21δ + 0.23Aδ + 0.23Bδ + 0.23Dδ,
∂ T /∂G = 0.08δ + 0.51Bδ,
∂ T /∂ J = ω.
The value of considering the interactions motivated us to consider further runtime maximization of throughput while simultaneously minimizing end-to-end
delay and packet loss. Neither the model of T , nor its partial derivatives, provide any information about the behavior of end-to-end delay or packet loss.
A simple application of steepest-ascent optimization to throughput may increase either of these responses substantially. If there is no model available for
throughput, optimization of any of the three responses may be accomplished
via any number of stochastic approximation approaches. Yet the application
of a stochastic approximation technique to optimizing throughput discards the
useful model developed for T , and stochastic approaches to optimizing either
end-to-end delay or packet loss could lead to a significant decrease in throughput.
For the problem of multiple response optimization in which the gradient is
known for only one response, we propose simultaneous perturbation stochastic approximation-steepest ascent (SP(SA)2 ), a hybrid approach that uses the
gradient for the modeled response to improve stochastic approaches to optimization for responses that lack pre-existing gradients. In the next section,
we review related work on cross-layer optimization in MANETs as well as explore the shortcomings of steepest-ascent and perturbation-based stochastic
approximation techniques.
3. RELATED WORK
3.1 Optimization in MANETs
Network optimization is not a new problem, and the approaches taken are
varied. Perhaps the best-studied approach is linear programming (see Pióro
and Medhi [2004] for a summary). Linear programming optimizations have
applications in MANETs as well, such as the resource optimization of spatial
TDMA studied by Bjorklund et al. [2003].
While efforts have been made to optimize the AODV and the IEEE 802.11
protocols individually [Boroni et al. 2004; Zhong et al. 2003], cross-layer optimization has been advocated for MANETs [Goldsmith and Wicker 2002;
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:7

Setton et al. 2005]. Conti et al. [2004, 2005] propose a cross-layer design of
their MinuteMan protocol, and present a cross-layer optimization of gnutella
in MANETs. Toumpis and Goldsmith [2003a, 2003b] produce an efficient crosslayer design of contention periods in MAC protocols. Wu et al. [2005] examine
an iterative cross-layer approach in wireless ad hoc networks that minimizes
energy consumption and aggregate congestion. Slavik et al. [2008] propose a
cross-layer design for cognitive networks. Zhao et al. [2009] examine the changing influence of factors on responses in a game-theoretic evaluation of cognitive
radios. Barrett et al. [2002], and Vadde and Syrotiuk examine routing and MAC
protocol interactions, and AODV timer interactions, on MANET performance
[2004a, 2004b]. Vadde et al. [2006] and Mullen et al. [2004] use response surface methodology to optimize MANETs at fixed node speeds. Mullen et al. focus
on optimizing route request and reply messages, while Vadde et al. consider
AODV routing timer and MAC retransmission parameters.
Runtime optimization may be viewed as a form of adaptation. There has
been much work on adaptation in MANET protocols. The simplest of these
is a threshold-based adaptation, as in the work of Singh et al. [1998] on the
adaptive, power-aware MAC protocol PAMAS. Table-lookup algorithms are popular, particularly in routing. The SSA routing protocol proposed by Dube et al.
[1997] is an example of such a method. More integrated forms of adaptation
have also been investigated, as in AdaptNet [Akyildiz et al. 2004], an adaptive
protocol suite that utilizes cross-layer principles to improve application performance such as video streaming. Sachs et al. [2005] develop GRACE similarly,
a framework that performs both global and application-specific cross-layer optimizations. Machine-learning techniques have been applied to the problem of
adaptation. Faragó et al. [2000] apply machine learning in their meta-MAC
scheme to adaptively choose an optimal MAC-layer policy. Colagrosso [2005]
employs classification algorithms to adapt broadcast policies in MANETs, while
Benaissa et al. [2004] utilize decision tree learning to adaptively improve voice
transmissions over MANETs.
3.2 Steepest-Ascent and Simultaneous Perturbation
RSM is a standard approach for many industrial process optimization efforts.
RSM excels in simple process improvement when statistical techniques yield
first- and second-order linear models of responses. In a typical RSM study, a
first-order linear model is constructed using statistically designed experiments
[Montgomery 2009], after which the process is improved by incrementing factor
values along the gradient path of steepest ascent until a response is roughly
maximized. (In the sequel, our discussion assumes that maximizing the response is required, and hence the path of steepest ascent is followed; if a
minimum response is required, then the path of steepest descent is followed.)
For linear models of the form ŷ = β X with coefficients β = {β0 , β1 , . . . βk} and
which produces
factors X = {1, x1 , . . . xk}, the path of steepest ascent
kis that
xi2 = r 2 , where r is
the maximum response, subject to the constraint i=1
a fixed distance from the point at which the model is developed [Myers and
Montgomery 2002]. Computing the Lagrange multiplier with respect to this
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:8

•

D. W. McClary et al.

Table II. Throughput (Kbps) as Maximized by Steepest Ascent, and at Minimum
End-to-End Delay by SPSA
Optimization
Technique

Steepest Ascent

0.25λ
0.50λ
0.75λ
1.00λ
1.25λ

SPSA

1
1.01
1.01
1.01
1.01
1.01
1.02

5
1.09
1.09
1.09
1.09
1.12
1.10

10
2.14
2.17
2.17
2.18
2.19
2.14

Node Speed in m/s
15
20
25
4.46
5.50
5.50
4.44
5.58
5.52
4.48
5.48
5.50
4.07
5.51
5.50
4.07
5.54
5.50
1.24
4.39
5.47

5–25
6.56
6.51
6.50
6.51
6.51
5.44

0–30
6.55
6.55
6.55
6.55
6.55
6.50

Table III. End-to-End Delay (s) for Maximum T by Steepest Ascent, and as Minimized by
SPSA
Optimization
Technique

Steepest Ascent

SPSA

0.25λ
0.50λ
0.75λ
1.00λ
1.25λ

1
0.01
0.01
0.01
0.01
0.01
0.01

5
0.03
0.03
0.03
0.03
0.03
0.01

10
0.01
0.02
0.02
0.02
0.02
0.02

Node Speed in m/s
15
20
25
0.04
0.05
0.03
0.04
0.05
0.05
0.05
0.03
0.03
0.04
0.02
0.03
0.04
0.04
0.03
0.07
0.03
0.03

5–25
0.03
0.02
0.02
0.01
0.01
0.03

0–30
0.04
0.04
0.04
0.04
0.04
0.02

constraint yields a “step-size” used to iteratively proceed in the direction of
steepest ascent.
Because the model of T in Eq. (1) was derived via a statistically designed
experiment, improvement via steepest ascent is a natural method to apply to
optimize throughput. However, an exploration of throughput results over a
wide range of conditions illustrates that steepest-ascent optimization strategies may not be appropriate. Table II catalogues deterministic results of several
small steps along the path of steepest ascent for the model of T ; the maximum
throughput is indicated in boldface type. The experimental conditions for these
trials are the same as those outlined in Section 5.1. λ is a scaling vector consistent with one “step size” in the largest coefficient. If βi is the maximum
coefficient in β, then λi = βi /4 and λ j = β j /(βi λi ), 1 ≤ j ≤ k, i = j. Interestingly, we find that different step sizes improve performance for different node
speeds.
A further problem arises when we apply steepest ascent on other responses.
Table III catalogues end-to-end delay for the same steepest ascent trials on
throughput. As with the results on throughput, we find that the end-to-end
delay is most improved at different step sizes along the path of steepest ascent. Moreover, steps on the path of steepest ascent that maximize throughput
occasionally have adverse effects on end-to-end delay, as in the trials for 20
and 25 m/s. Multiple response optimization, considering both throughput and
end-to-end delay via more advanced RSM techniques, is impossible in this case
because there is no gradient available for end-to-end delay.
Whereas well-known stochastic techniques such as Robbins–Monro Stochastic Approximation [1951] might allow us to leverage the known gradient to
find a point at which throughput is optimized for all conditions, the class of
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:9

gradient-free stochastic approximation techniques is well suited to optimizing
responses for which we lack models. The principal advantage of gradient-free
stochastic approximation techniques is that only response measurements are
required to determine a direction for optimization. This is useful when modeling a response is costly, as is the case with the profile-driven regression which
yielded the model T .
One of the oldest approaches to gradient-free stochastic approximation is
the Kiefer–Wolfowitz finite difference stochastic approximation (FDSA) [1952].
FDSA uses perturbations of individual parameters within a parameter vector
θ to generate an approximation of the response gradient. This approximation
is then used to set the direction and magnitude of the next point in the optimization study. A drawback to FDSA is the number of samples necessary to
obtain a gradient approximation. For a parameter vector θ of length k, a measurement for each parameter is necessary. In response to this potentially costly
method, Spall [1992] proposes simultaneous perturbation stochastic approximation (SPSA). By perturbing all of the components of the parameter vector
θ simultaneously, SPSA reduces the number of perturbations necessary for
gradient approximation to one. As with FDSA, SPSA converges stochastically
under the proper conditions [Fabian 1971; Kushner and Yin 1997], and has
been used extensively for optimization tasks when gradients are unavailable
[Spall 1998b]. Multiple response optimization with SPSA often requires many
more iterations than does the single-response case.
To explore the use of stochastic approximation to our multiple response
optimization problem in MANETs, we apply a simple SPSA optimization to
minimize the end-to-end delay. The SPSA algorithm applied is identical to the
one described in Spall [1998a]; our trials converge in about 100 iterations. As
for the trials using steepest ascent, the experimental conditions are the same
as those described in Section 5.1. Notably, though we apply SPSA to the single
response of end-to-end delay; we also measure the throughput achieved when
delay is minimized. The final lines of Tables II and III indicate that while SPSA
manages to reduce delay for some of the node speeds considered (5 m/s and over
the range 0–30 m/s), except at 1 m/s the throughput is always lower, sometimes
significantly so, than in any of the trials using steepest ascent. This is likely
due to SPSA choosing an optimization path that is not on the gradient path of
steepest ascent for throughput.
Considering the results of applying both steepest ascent and SPSA separately, the need for a solution that incorporates the strengths of each technique
is clear. Our challenge is to leverage the inherent benefit of the known gradient path of steepest ascent while optimizing the remaining responses without
knowledge of their gradients. In the next sections, we tackle this challenge
and describe our application of SP(SA)2 to the multiple response optimization
problem in MANETs.
4. SP(SA)2 : SIMULTANEOUS PERTURBATION STOCHASTIC
APPROXIMATION-STEEPEST ASCENT
We develop SP(SA)2 to allow for the simultaneous perturbation of responses for
which gradients are unavailable within a region that almost certainly contains
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:10

•

D. W. McClary et al.

Fig. 2. A surface plot and a contour plot of y = −x12 + 5x2 + 20.

the gradient path of steepest ascent for the modeled response. At a high level
of abstraction, SP(SA)2 simply conducts an SPSA optimization of unmodeled
responses within the 95% confidence region that surrounds the gradient path
of steepest ascent for the modeled response.
Consider the two-dimensional function y = −x12 + 5x2 + 20 whose surface
plot is given in Figure 2(a). The path of steepest ascent is evident visually
and confirmed easily by examination of the contour plot given in Figure 2(b).
If a stochastic model of the surface is available, it is well-understood that a
confidence interval for it exists. There is a (100−α)% certainty that the modeled
response lies within this interval for a given set of input values. Similarly, there
is a confidence region that begins at the point of model construction and widens
naturally along the gradient path of steepest ascent. This region is the key
constraint in SP(SA)2 ; it contains all input values X = {x1 , x2 , . . . , xk} such that
	2

k
k

i=1 bi xi
bi2 −
≤ Fα,k−1,vb ,
(6)
k
(k − 1) i=1
xi
i=1
where b is the vector of model coefficients, Fα,k−1,vb the F-statistic for a (100 −
α)% confidence interval with k − 1 degrees of freedom in the numerator and
vb degrees of freedom in the denominator [Myers and Montgomery 2002]. vb
decreases as the distance from the point at which the model was constructed
increases, giving the confidence region its wedge-like shape. Figure 2(b) illustrates such a confidence region on the gradient path of steepest ascent.
Using a single response, we illustrate how the SPSA optimization approach
can be constrained by the confidence region for an existing path of steepest
ascent. Figure 3(a) superimposes a sample SPSA path for the example function
y over its contour plot and path of steepest ascent. Because SPSA chooses
perturbations at random, initial iterations may depart significantly from the
path of steepest ascent. While SPSA converges to an optimum given enough
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:11

Fig. 3. Example paths for SPSA and SP(SA)2 . The SPSA path is allowed to move opposite the
direction of steepest ascent, while the SP(SA)2 confines its search to the confidence region for the
path of steepest ascent.

Algorithm 1. The SP(SA)2 Algorithm
Require: a, c, A, α, and γ as outlined in [Spall 1998a]
for k = 1 to n do
a
ak = (k+A)
α
c
ck = kγ
repeat
	 = a randomly selected Bernoulli-distributed vector of {-1,1}
until admission test(	, θ, ak) is true
θ + = θ + ck	
θ − = θ − ck	
y+ = response measurement(θ + )
y− = response measurement(θ − )
+
−
ĝ = y 2c−yk 	
θ = θ + ak ĝ {For gradient descent: θ − ak ĝ, for ascent: θ + ak ĝ}
end for
return θ

iterations, constraining the vector selection to a specific region as in Figure 3(b)
provides certain advantages.
Constraining SPSA to a confidence region reduces the number of possible
perturbations, likely reducing the number of iterations necessary to reach the
optimum [Spall 1992]. In a single-response scenario with a known gradient, the
probability of convergence is not reduced significantly, and improvements may
be located that are not on the path of steepest ascent estimated from a statistical
model. In the case of multiple responses, the benefits of SP(SA)2 are different.
As in the single response case, optima not on the estimated path of steepest
ascent can be located, as can points that optimize all responses. There is a possibility that no admissible perturbations produce improvement in responses
that lack gradient models. When convergence cannot be obtained, exhausting
the possible perturbations provides valuable information. If no admissible vectors produce an improvement in nongradient responses, the optimization goals
may need to be reassessed or further modeling efforts may be necessary.
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:12

•

D. W. McClary et al.

Algorithm 2. The SP(SA)2 Perturbation Admission Test
Require: ak from Algorithm 1
v ⇐the candidate vector
b ⇐ the vector of model coefficients
x ⇐ the vector of factor values
s ⇐ a vector of parameter increments for one step in the direction of steepest ascent
along a known gradient
ak ⇐ the SPSA gradient gain parameter
vb ⇐ the original error degrees of freedom for the known model
sb2 ⇐ the model variance
k ⇐ the number of terms in x
while u < v and vb > 1 do
u = u+ s
vb = vb − 1
end while
	
k
k
( i=1
bi xi )2
2

b
−
score = ak
k
i
i=1
(k−1)
x
i=1 i

if vb == 1 then
return false
else if score ≤ sb2 Fα,k−1,vb then
return true
else
return false
end if

Algorithm 1 provides the basic SP(SA)2 algorithm. The algorithm is identical to that proposed by Spall [1998a], with one exception: a check on the
admissibility of the perturbation vector 	. a and c serve as the initial gains for
the gain sequences ak (which assures convergence) and ck (which guarantees
asymptotic normality), respectively. The α , γ , and A are fixed parameters that
are also necessary to maintain normality and assure convergence. Suggested
values for these parameters are given in Spall [1998a]; the values utilized in
our application of SP(SA)2 in Section 5 are given in the latter half of Table IV.
The procedure for testing the admissibility of a perturbation is given in Algorithm 2. The admissibility test computes the inequality given in Eq. (6) with
scaling appropriate to the current SPSA gradient gain ak.

5. EXPERIMENTAL TRIALS AND RESULTS
5.1 Experimental Methodology
To test the optimization capability of SP(SA)2 we return to the model of throughput in Eq. (1) and the partial derivatives given in Eq. (5). We modify the AODV
and IEEE 802.11b protocols in the network simulator ns-2 [University of California, Berkeley ] to compute the values of parameters given in Table I using
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:13

Table IV. Other Simulation Parameters
Simulation Parameter
Interface queue
Interface queue length
Antenna model
802.11b bandwidth
802.11b minimum contention window size
802.11b maximum contention window size
802.11b slot time
802.11b preamble length
Node traffic type
UDP packet payload size
SPSA Parameter
K (Maximum Allowable Iterations
γ
α
c
A
a
Convergence Threshold
SP(SA)2 Parameter
K (Maximum Allowable Iterations)
γ
α
c
A
a
Convergence Threshold

Value
DropFront priority queue
30
Omnidirectional
11 Mb/s
32
1024
20 μs
144 bits
Constant bit rate (CBR)
320 bytes
Value
1000
0.101
0.602
0.01
100
0.16
0.001
Value
100
0.101
0.602
0.01
10
0.16
0.001

the partial derivatives in Eq. (5). To optimize the coefficients of the model T ,
and thus the partial derivatives, we consider the coefficients of T to be a vector
of changeable values x and the default parameter values from ns-2 to be a vector of coefficients b. Using this formulation, we conduct several SP(SA)2 trials
to gauge the effectiveness of the approach, its convergence properties, and the
overall optimization obtained in three responses of interest: average throughput (Kbps), end-to-end delay (s), and average packet loss (% loss). We examine
SP(SA)2 performance under the conditions that the models in [McClary et al.
2010] were developed, as well as two other MANET deployments: a MANET
of 25 nodes with a single end-to-end flow and a 50-node deployment with 4
end-to-end flows, each transmitting CBR flows over UDP. The flow under study
transmits data at a rate scaled by the optimized partial derivatives, while
the remaining flows transmit data at 1Kbps. We compare the performance of
SP(SA)2 optimized coefficients against the original partial derivatives as well
as optimizations via RSM, SPSA, and the Nelder–Mead [1965] simplex method
for nonlinear optimization.
For each step of the SP(SA)2 approach, simulations are conducted at node
speeds of 1, 5, 10, 15, 20, and 25 m/s as well as under conditions in which node
speeds vary between both 5 and 25 m/s and 0 and 30 m/s. Node speed variance
for the single-speed trials is 1 m/s. This corresponds to a range of node speeds,
from walking (1 m/s = 3.6 kph) to driving (25 m/s = 90 kph), representative of the
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:14

•

D. W. McClary et al.

mobility in most ad hoc networking scenarios. Node speed is measured locally
at the optimized node, and may be different for other nodes in the simulations
which span a range of speeds. The remaining factor values are measured by
their respective protocols and accessed using a static object shared by all protocol layers. Progression of the simultaneous perturbation is constrained as in
Algorithm 2, and the SP(SA)2 attempts to minimize packet-loss percentage and
packet end-to-end while increasing throughput over the set of speed trials. Following the SP(SA)2 optimization, we conduct 20 replicate runs using the partial
derivatives in Eq. (5), similar partial derivatives obtained after one step along
the path of steepest ascent for the throughput model in Eq. (1), and models
obtained from the SP(SA)2 optimization. These replicated runs are subjected to
a simple t-test on the means of throughput, delay, and packet-loss percentage.
The results of these tests are given in Section 5.2.
In each trial, 50 nodes are placed randomly in an area of 1000 m× 1000 m with
one sender and one receiver. Nodes are distributed at random from a normal
distribution centered at (500, 500). Node mobility follows the steady-state random waypoint model given by Navidi et al. [2004]. This models individual node
movements rather than groups of nodes. Radio transmission range is 250 m, using a two-ray ground propagation model and a channel rate of 11 Mbps. Trials
are simulated using the ns-2 [University of California, Berkeley ] network simulator, and statistical analyses are performed using the statistical language R
[R Project for Statistical Computing ]. All trials in the SP(SA)2 optimization are
conducted for 500 s of simulated time. Other simulation parameters are given
in Table IV and all remaining parameters are set to their default values in ns-2.
5.1.1 Nelder–Mead Method for Optimization. The Nelder–Mead method
employs a polytrope with n + 1 vertices (or simplex) to iteratively search an
n-dimensional objective space. The poorest point in the initial polytrope is reflected through the centroid of the n other points. If the new point is an improvement, the method stretches the polytrope exponentially along this axis.
However, if the new point is not an improvement, the simplex is contracted or
shrunk.
We choose to include the Nelder–Mead method in our comparisons for several reasons. Our principal interest in including the Nelder–Mead method in
our comparison is that it is an example of nongradient optimization. Further,
the iterations of the Nelder–Mead method can roughly follow the gradient of
an objective function if stagnation is avoided and a sufficient decrease condition is provided [Kelly 1999]. This provides a basis for comparison with SPSA
and SP(SA)2 . Finally, implementations of the Nelder–Mead method are widely
available. For the purposes of our trials, we use the implementation provided
by the GNU Scientific Library (GSL) [Galassi et al. 2009].
5.2 Results
Figure 4 summarizes throughput performance of our t-test evaluation of
SP(SA)2 for the MANET deployment used in [McClary et al. 2010]. Notably,
while the partial derivatives in Eq. (5) perform well at most node speeds, both
steepest ascent and SP(SA)2 far outperform them at 15 m/s and 20 m/s. This
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:15

Fig. 4. Collected throughput optimizations for the default runtime optimization, steepest-ascent
SPSA, SP(SA)2 , and the Nelder–Mead method. SP(SA)2 produces throughput performance comparable to steepest ascent.

result is important as it illustrates that gains possible using steepest ascent are
obtainable using SP(SA)2 . Figures 5 and 6 depict similar summaries for packet
end-to-end delay and packet-loss percentage respectively. While throughput
performance from the SP(SA)2 optimization is commensurate with the steepest ascent optimization, both packet-loss and delay are significantly reduced.
These results suggest that SP(SA)2 achieves its goal of maximizing throughput
while minimizing end-to-end delay and packet loss with and without known
gradients.
Closer inspections of the delay and loss optimizations at 15 and 20 m/s are
given in Figures 7 and 8. SP(SA)2 produces statistically significant reductions
in packet-loss percentage in both cases. At 15 m/s, SP(SA)2 reduces delay by
approximately 30% and loss by 55% over the partial derivatives. At 20 m/s,
the reduction in average delay is 33% and loss is reduced by 10%. While we
cannot say that end-to-end delay improvements are statistically significant,
the variance in end-to-end delay is markedly reduced for both cases. Perhaps
more interesting than the optimizations themselves are the node speeds at
which they occur. Because the model of T is largely governed by intra- and
cross-layer interactions between 15 and 20 m/s, these results suggest that such
interactions between routing and medium access protocols are highly important
under certain MANET conditions.
We also gauge the performance of SP(SA)2 for two other MANET deployments. Figure 9 inspects packet end-to-end delay at 10 and 20 m/s for the
MANET deployment with 50 nodes and four competing flows. Figure 9(b) suggests that an optimization of as much as 29% is achieved using SP(SA)2 , although we cannot say this with 95% certainty. As illustrated in Figure 9(a),
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:16

•

D. W. McClary et al.

Fig. 5. Collected delay optimizations for the default runtime optimization, steepest-ascent SPSA,
SP(SA)2 , and the Nelder–Mead method. SP(SA)2 produces lower delay in the region of greatest
cross-layer interaction.

Fig. 6. Collected loss optimization results for the default runtime optimization, steepest-ascent
SPSA, SP(SA)2 , and the Nelder–Mead method. SP(SA)2 achieves statistically significant loss reductions in the region of greatest cross-layer interaction.
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:17

Fig. 7. Delay and loss results for the considered approaches at 15 m/s. SP(SA)2 produces reduced
loss while minimizing the variance in end-to-end delay.

Fig. 8. Delay and loss results for the considered approaches at 20 m/s. SP(SA)2 produces significant
reductions in both loss and end-to-end delay.

no technique attains a decisive optimum at 10 m/s. Average throughput,
packet-loss percentage and packet end-to-end delay measurements for other
node speed values are approximately equal to those produced by the partial
derivatives in the 50-node, single-flow deployment. This may suggest that the
coefficient vector provided by the partial derivatives was already at or near an
optimum point, or that the factors responsible for further optimization are not
present in the model (e.g., the traffic load due to other flows). Figure 10 shows
a 20% delay improvement found at 15 m/s for the MANET deployment with 25
nodes and a single data flow. Average throughput and packet-loss percentage
were commensurate with the partial derivatives. The Nelder–Mead method
produces a greater optimization of delay than does SP(SA)2 , although as Figure
11 illustrates, the cost of obtaining this optimization is much greater than that
of SP(SA)2 .
In assessing the overall performance of SP(SA)2 , we find that optimizations
are often produced for objectives for which we lack gradients while achieving
optimization along a known gradient path of steepest ascent. However, there
are two further points to be made. First, while none of the techniques examACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:18

•

D. W. McClary et al.

Fig. 9. Collected delay optimization results for the default runtime optimization, steepest ascent,
SPSA, SP(SA)2 , and the Nelder–Mead method in a 50-node deployment with 4 competing flows.
SP(SA)2 acheives a probable delay reduction.

Fig. 10. Collected delay optimization results for the default runtime optimization, steepest ascent,
SPSA, SP(SA)2 , and the Nelder–Mead method at 15 m/s in a 25-node deployment.

ined achieved clear optimizations under certain conditions, the overall cost in
applying SP(SA)2 is lower than both SPSA and the Nelder–Mead approach. Figure 11 illustrates the approximate costs incurred by the three search methods.
The SP(SA)2 trials in our study need approximately 480 simulation runs to
converge to an optimum, while SPSA and the Nelder–Mead method required
1600 and 976 simulations, respectively. Second, it is worth noting that average
throughput, packet loss, and end-to-end delay are often highly correlated in
MANETs. This correlation certainly works to the advantage of SP(SA)2 optima
for the three responses are more likely to lie in similar directions.
6. CONCLUSIONS AND FUTURE WORK
To address the challenging problem of multiple response optimization when
gradients are known only for certain responses, this article introduces SP(SA)2 .
This hybridized approach constrains a simultaneous perturbation stochastic
approximation (SPSA) optimization within the confidence region of known
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:19

Fig. 11. Approximate simulation costs for SPSA, SP(SA)2 , and the Nelder–Mead method. SP(SA)2
costs substantially less than the competing methods.

gradients. This allows for more assured improvements in modeled responses
while searching for optimizations in responses of unknown gradients.
We apply SP(SA)2 to a cross-layer runtime optimization in MANETs with
three responses: average throughput, end-to-end packet delay, and packet-loss
percentage. An accurate gradient considering cross-layer interaction is available for average throughput, but no such information exists for end-to-end
delay or packet loss. In experimental trials SP(SA)2 obtains optimizations for
delay and loss, which steepest ascent cannot. Moreover, SP(SA)2 optimization
produces average throughput commensurate with those possible with steepest
ascent, but not possible under a SPSA of packet loss.
SP(SA)2 also obtains convergence in fewer iterations than SPSA. In our optimization problem, standard SPSA converged all parameters within a tolerance
of 0.001 in approximately 100 iterations, while SP(SA)2 converged in 30 or fewer.
Of particular significance, SP(SA)2 obtained improvements in throughput, delay, and loss at node speeds between 15 and 20 m/s, an area which the existing
throughput model suggests is dominated by cross-layer interactions.
While SP(SA)2 performs well with a single known gradient, generalization
of the method to an arbitrary number of surfaces may prove challenging. For
cases in which all models are of the same dimension, contain the same factors,
and confidence regions overlap, it is likely that a one or more bounded hyperregions can be defined for stochastic approximation. However, for cases in which
gradients fail to overlap or contain different factor sets, defining a singular
region for approximation may not be possible. In such cases, practitioners are
advised to choose one model as the bounding confidence region. The choice of
this model may depend on the factors involved, the size of the region, or any
number of other criteria.
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:20

•

D. W. McClary et al.

While SP(SA)2 is a promising hybrid optimization approach, many questions
remain regarding its applicability and performance. Response correlation may
significantly affect convergence and the overall optimization with SP(SA)2 , and
should be investigated. Similarly, we have not yet experimentally examined
the performance of SP(SA)2 when multiple gradients are known. Explorations
of SP(SA)2 performance in a confidence region shared by multiple gradients
is necessary and may be quite challenging. Future work seeks to address the
above issues and to further determine the models and responses for which
SP(SA)2 is best suited.
REFERENCES
802.11 1999. IEEE standard 802.11: W-LAN medium access control and physical layer specifications.
AKYILDIZ, I., ALTUNBASAK, Y., FEKRI, F., AND SIVAKUMAR, R. 2004. AdaptNet: An adaptive protocol
suite for the next-generation wireless internet. IEEE Comm. Mag. 42, 3, 128–136.
ANDERSSON, J. 2000. A survey of multiobjective optimization in engineering design. Tech. rep.
LiTH-IKP-R-1097, Dep. of Mechanical Engineering, Linköping University.
BARRETT, C., MARATHE, A., MARATHE, M., AND DROZDA, M. 2002. Characterizing the interaction
between routing and MAC protocols in ad-hoc networks. In Proceedings of the 3rd ACM International Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc’02). ACM, New
York, 92–103.
BENAISSA, M., LECUIRE, V., MCCLARY, D. W., AND SYROTIUK, V. R. 2004. ANOVA-informed decision
trees for voice applications over MANETs. In Proceedings of the 6th IEEE International Conference on Mobile and Wireless Communication Networks (MWCN’04). IEEE, Los Alamitos, CA,
143–154.
BJORKLUND, P., VARBRAND, P., AND DI, Y. 2003. Resource optimization of spatial TDMA in ad
hoc radio networks: A column generation approach. In Proceedings of the 2nd Annual Joint
Conference of the IEEE Computer and Communications Societies (INFOCOM’03). Vol. 2, 818–
824.
BORONI, L., CONTI, M., AND GREGORI, E. 2004. Runtime optimization of IEEE 802.11 wireless
LANs performance. IEEE Trans. Paral. Distrib. Syst. 15, 66–80.
BOX, G. E. P. AND WILSON, K. B. 1951. On the experimental attainment of optimum conditions. J.
Royal Statist. Soc. B 13, 1–45.
COLAGROSSO, M. D. 2005. A classification approach to broadcasting in mobile ad hoc network. In
Proceedings of the IEEE Conference on Communications (ICC’05). Vol. 2, 1112–1117.
CONTI, M., GREGORI, E., AND TURI, G. 2005. A cross-layer optimization of gnutella for mobile
ad hoc networks. In Proceedings of the 6th ACM International Symposium on Mobile Ad Hoc
Networking. ACM, New York, 343–354.
CONTI, M., MASELLI, G., TURI, G., AND GIORDANO, S. 2004. Cross-layering in mobile ad hoc network
design. Computer 37, 48–51.
DUBE, R., RAIS, C. D., WANG, K.-Y., AND TRIPATHI, S. K. 1997. Signal stability-based adaptive
routing (SSA) for ad hoc mobile networks. IEEE Personal Comm. 4, 36–45.
EGLESE, R. W. 1990. Simulated annealing: a tool for operational research. European J. Oper.
Res. 46, 271–281.
FABIAN, V. 1971. Stochastic approximation. In Optimizing Methods in Statistics, J. J. Rustig, Ed.
Academic Press, New York, 430–470.
FARAGÓ, A., MYERS, A. D., SYROTIUK, V. R., AND ZÀRUBA, G. V. 2000. Meta-MAC protocols: Automatic
combination of MAC protocols to optimize performance for unknown conditions. IEEE J. Select.
Areas Comm. 18, 1670–1681.
GALASSI, M., DAVIES, J., THEILER, J., GOUGH, B., JUNGMAN, G., ALKEN, P., BOOTH, M., AND ROSSI, F. 2009.
GNU Scientific Library Reference Manual 3rd Ed. GNU Project.
GOLDSMITH, A. J. AND WICKER, S. B. 2002. Design challenges for energy-constrained ad hoc wireless
networks. IEEE Wirel. Comm. 9, 8–27.
ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

Steepest-Ascent Constrained Simultaneous Perturbation

•

2:21

KELLY, C. T. 1999. Iterative Methods for Optimization. Society for Industrial and Applied Mathematics (SIAM).
KIEFER, J. AND WOLFOWITZ, J. 1952. Stochastic estimation of a regression function. Ann. Math.
Stat. 23, 462–466.
KLEIJNEN, J. P. C., VAN BEERS, W., AND VAN NIEUWENHUYSE, I. 2010. Constrained optimization in
simulation: A novel approach. European J. Oper. Res.. In press.
KUSHNER, H. J. AND YIN, G. G. 1997. Stochastic Approximation Algorithms and Applications.
Springer, Berlin.
LIEPINS, G. E. AND HILLIARD, M. R. 1989. Genetic algorithms: Foundations and applications. Ann.
Oper. Res. 21, 31–58.
MCCLARY, D. W., SYROTIUK, V. R., AND KULAHCI, M. 2010. Profile-driven regression for modeling
and run-time optimization of mobile networks. ACM Trans. Model. Comput. Simul..
MONTGOMERY, D. C. 2009. Design and Analysis of Experiments 7th Ed. Wiley, New York.
MULLEN, J., MATIS, T., ADAMS, K., AND RANGAN, S. 2004. Achieving robust protocols for mobile ad
hoc networks. In Proceedings of the Industrial Engineering Research Conference (IERC’04).
MYERS, R. H. AND MONTGOMERY, D. C. 2002. Response Surface Methodology: Process and Product
Optimization Using Designed Experiments 2nd Ed. Wiley, New York.
NAVIDI, W., CAMP, T., AND BAUER, N. 2004. Improving the accuracy of random waypoint simulations through steady-state initialization. In Proceedings of the 15th International Conference on
Modeling and Simulation (MS’04). 319–326.
NELDER, J. A. AND MEAD, R. 1965. A simplex method for function minimization. Comput. J. 7,
308–313.
PERKINS, C. E. AND ROYER, E. M. 1999. Ad hoc on-demand distance vector routing. In Proceedings
of the 2nd IEEE Workshop on Mobile Computing Systems and Applications. IEEE, Los Alamitos,
CA, 90–100.
PIÓRO, M. AND MEDHI, D. 2004. Routing, Flow, and Capacity Design in Communication and
Computer Networks. Morgan Kaufmann.
R Project. R Project for Statistical Computing. http://www.r-project.org.
ROBBINS, H. AND MONRO, S. 1951. A stochastic approximation method. Ann. Math. Stat. 29, 400–
407.
SACHS, D. G., YUAN, W., HUGHES, C. J., HARRIS, A., ADVE, S. V., JONES, D. L., KRAVETS, R. H., AND NAHRSTEDT, K. 2005.
Grace: A hierarchical adaptation framework for saving energy. UIUCDCS-R2004-2409, 2400–2409.
SETTON, E., TAESANG, Y., XIAOQING, Z., GOLDSMITH, A., AND GIROD, B. 2005. Cross-layer design of ad
hoc networks for real-time video streaming. IEEE Wirel. Comm. 12, 59–65.
SINGH, S., WOO, M., AND RAGHAVENDRA, C. S. 1998. Power-aware routing in mobile ad hoc networks.
In Proceedings of the 4th Annual ACM/IEEE Conference on Mobile Computing and Networking.
ACM, New York, 181–190.
SLAVIK, M., MAHGOUB, I., AND BADI, A. 2008. Cross-layer design for wireless networks with cognitive controllers. In Proceedings of the IEEE Wireless Telecomunications Symposium WTS’08.
273–277.
SPALL, J. 1992. Multivariate stochastic approximation using a simultaneous perturbation gradient approximation. IEEE Trans. Auto. Control 37, 3, 332–341.
SPALL, J. 1998a. Implementation of the simultaneous perturbation algorithm for stochastic optimization. IEEE Trans. Aerospace Electron. Syst. 34, 3, 817–823.
SPALL, J. 1998b. An overview of the simultaneous perturbation method for efficient optimization.
Johns Hopkins APL Tech. Digest 19, 482–492.
SRIVASTAVA, V. AND MOTANI, M. 2007. Cross-layer design and optimization in wireless networks.
In Cognitive Networks: Towards Self-Aware Networks, Q. H. Mahmoud, Ed. Wiley, New York,
Ch. 6, 121–146.
SWISHER, J., HYDEN, P., JACOBSON, S., AND SCHRUBEN, L. 2000. Simulation optimization: A survey of simulation optimization techniques and procedures. In Proceedings of the 32nd Winter
Simulation Conference. 119–128.
TOUMPIS, S. AND GOLDSMITH, A. J. 2003a. Design challenges for energy-constrained ad hoc wireless
networks. IEEE Trans. Wirel. Comm. 2, 736–748.

ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

2:22

•

D. W. McClary et al.

TOUMPIS, S. AND GOLDSMITH, A. J. 2003b. Performance, optimization, and cross-layer design
of media access protocols for wireless ad hoc networks. In Proceedings of the IEEE International Conference on Communications (ICC’03). Vol. 3. IEEE, Los Alamitos, CA, 2234–
2240.
University of California, Berkeley. The network simulator—ns-2. http://www.isi.edu/nsname/ns/.
VADDE, K. K. AND SYROTIUK, V. R. 2004a. Factor interaction on service delivery in mobile ad hoc
networks. IEEE J. Select. Areas Comm. 22, 1335–1346.
VADDE, K. K. AND SYROTIUK, V. R. 2004b. On timers of routing protocols in MANETs. In Proceedings of the 3rd International Conference on Ad Hoc Networks and Wireless (AdHoc Now’04).
330–335.
VADDE, K. K., SYROTIUK, V. R., AND MONTGOMERY, D. C. 2006. Optimizing protocol interaction using
response surface methodology. IEEE Trans. Mobile Comput. 5, 6, 627–639.
WU, Y., CHOU, P. A., QIAN, Z., JAIN, K., WENWU, Z., AND SUN-YUAN, K. 2005. Network planning in
wireless ad hoc networks: a cross-layer approach. IEEE J. Select. Areas Comm. 23, 136–150.
ZHAO, Y., MAO, S., NEEL, J. O., AND REED, J. H. 2009. Performance evaluation of cognitive radios:
Metrics utility functions, and methodology. Proc. IEEE 97, 4, 642–659.
ZHONG, X., MEI, S., WANG, Y., AND WANG, J. 2003. Stable enhancement for AODV routing protocol.
In Proceedings of the 14th IEEE Conference on Personal, Indoor and Mobile Radio Communications. Vol. 1. 201–205.
Received June 2009; revised September 2009; accepted October 2009

ACM Transactions on Modeling and Computer Simulation, Vol. 21, No. 1, Article 2, Pub. date: December 2010.

1598

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 12,

NO. 8,

AUGUST 2013

Topological Persistence for
Medium Access Control
Jonathan Lutz, Charles J. Colbourn, and Violet R. Syrotiuk
Abstract—The primary function of the medium access control (MAC) protocol is managing access to the shared communication
channel. From the viewpoint of the transmitters, the MAC protocol determines each transmitter’s channel occupancy, the fraction of
time that it spends transmitting over the channel. In this paper, we define a set of topological persistences that conform to both network
topology and traffic load. We employ these persistences as target occupancies for the MAC layer protocol. A centralized algorithm is
developed for calculating topological persistences and its correctness is established. A distributed algorithm and implementation are
developed that can operate within scheduled and contention-based MAC protocols. In the distributed algorithm, network resources are
allocated through auctions at each receiver in which transmitters participate as bidders to converge on the topological allocation. Very
low overhead is achieved by piggybacking auction and bidder communication on existing data packets. The practicality of the
distributed algorithm is demonstrated in a wireless network via simulation using the ns-2 network simulator. Simulation results show
fast convergence to the topological solution and, once operating with topological persistences, improved performance compared to
IEEE 802.11 in delay, throughput, and drop rate.
Index Terms—Wireless networks, medium access control

Ç
1

INTRODUCTION

T

HE medium access control (MAC) protocol is responsible for managing access to the shared communication
channel. From the perspective of a transmitter, this entails
answering the question: When can I transmit next? The
time at which the next transmission can occur depends on
the specifics of the MAC protocol, so we focus on three
relevant metrics. The demand of the transmitter is the
fraction of time that it would spend transmitting in the
absence of other transmitters. Its occupancy is the fraction
of time it actually transmits. Its persistence is the fraction of
time that it is permitted to transmit. Demands result from
network traffic delivered to the MAC layer by higher
layers in the protocol stack, and occupancies are observed
results of employing a specific MAC protocol to handle
this network traffic. What are persistences? We claim that
every MAC protocol, either explicitly or implicitly, dictates
each node’s persistence. To make this precise, we examine
observed behavior under the protocol. The instantaneous
occupancy for a single packet transmission is

Transmit Time
;
Idle Time þ MAC Latency þ Transmit Time
where Transmit Time is the time required to transmit the
packet, MAC Latency is the time the packet spends queued
for transmission at the MAC layer, and Idle Time is the time
spent waiting for a packet to transmit. Then occupancy is a
(long-term) average of these instantaneous occupancies.
. The authors are with the Department of Computer Science and Engineering,
School of Computing, Informatics, and Decision Systems Engineering,
Arizona State University, PO Box 878809, Tempe, AZ 85287-8809.
E-mail: {Jonathan.Lutz, Charles.Colbourn, syrotiuk}@asu.edu.
Manuscript received 23 June 2011; revised 9 Dec. 2011; accepted 18 May
2012; published online 31 May 2012.
For information on obtaining reprints of this article, please send e-mail to:
tmc@computer.org, and reference IEEECS Log Number TMC-2011-06-0337.
Digital Object Identifier no. 10.1109/TMC.2012.134.
1536-1233/13/$31.00 ß 2013 IEEE

Because a node need not have packets queued at all times,
occupancy is a lower bound on persistence. When every
node always has packets queued for transmission and
employs each transmission opportunity, occupancy is
persistence. If permission to transmit is granted only when
the transmitter has a packet to transmit, persistence is
occupancy. In one way, this makes occupancy and
persistence synonymous. Nevertheless, there remains a
very important distinction: occupancies address how
frequently transmitters do access the channel, while
persistences address how frequently they should.
The MAC protocol directly influences persistences,
regardless of whether it is contention-based, schedulebased, randomized, or deterministic. Persistences have an
impact on network performance. The channel may be
underutilized when persistences are too low. Numerous
collisions can result if persistences are too high. Even when
long-term persistences are appropriate, high variation in
instantaneous occupancies can degrade the quality of
service by increasing the maximum packet delay. The
MAC protocol should increase persistences when possible,
but avoid overprovisioning. This paper addresses the
selection of transmitter persistences: At what persistences
should the transmitters be permitted to access the channel?
Every MAC protocol, in operation, yields observed occupancies; only some explicitly compute persistences to
support these occupancies. The protocols outlined in Section
2 offer a representative set of approaches to MAC. Most treat
specific MAC challenges such as collision avoidance, spatial
reuse, or minimization of delay. Some target persistences
without regard to network topology. We take a different
approach. We start by identifying ideal persistences for a
given topology and traffic loading, and only then proceed to
the design of the MAC protocol. These topological persistences can be supplied as input to MAC protocols, both
contention- and schedule-based, to improve performance.
First we present our network model and notation. Label
the nodes with f1; . . . ; Ng. For all node pairs i and j, if j is
Published by the IEEE CS, CASS, ComSoc, IES, & SPS

LUTZ ET AL.: TOPOLOGICAL PERSISTENCE FOR MEDIUM ACCESS CONTROL

within the transmission range of i, let Dj contain i and Ri
contain j. A node is always within transmission range of
itself, so j 2 Dj and i 2 Ri . Transmissions by node i access
the channel at all nodes in Ri , regardless of the intended
recipient. Let s ¼ ðs1 ; . . . ; sN Þ be the channel allocation,
where si , 1  i  N, is the persistence assigned to i.
To maximize persistences across the network, the
allocation should satisfy the following properties:
The allocation s is feasible.
No transmitter is allocated more than it can use.
No transmitter is permitted to monopolize the
channel.
4. Each transmitter’s allocation is maximized subject to
the first three properties.
The allocation satisfying all four properties is the
topological allocation. We develop a precise definition next.
Let R be a set of N resources, with capacity c ¼ ðc1 ; . . . ; cN Þ.
Let D be a set of M demands, with magnitudes w ¼ ðw1 ; . . . ;
wM Þ. Resource j 2 R is required by demands Dj  D. Each
demand i utilizes the capacity of all resources in Ri equally
and simultaneously. A resource allocation is a vector
sP¼ ðs1 ; . . . ; sM Þ, with si  0 for 1  i  M. It is feasible if
i2Dj si  cj for all j 2 R and si  wi for all i 2 D. Demand
iP2 D is satisfied if si  wi . Resource j 2 R is saturated if
i2Dj si  cj .
Let x ¼ ðx1 ; x2 ; . . . ; xn Þ satisfy x1  x2      xn , and
y ¼ ðy1 ; y2 ; . . . ; yn Þ satisfy y1  y2      yn . Then x is
lexicographically greater than y if there exists an index k,
1  k  n, such that xi ¼ yi for all 1  i < k and xk > yk . An
allocation s ¼ ðs1 ; . . . ; sM Þ is lexicographically max-min if the
vector is lexicographically greatest among all feasible
allocations when each is sorted in nondecreasing order.
Equivalently, by Pióro and Medhi [22],
1.
2.
3.

Definition 1.1. A feasible allocation s is lexicographically
max-min if, for every demand i 2 D, either the demand is
satisfied, or there exists a saturated resource j with i 2 Dj
where si ¼ maxfsk : k 2 Dj g.
For MAC channel allocation, each transmitter is a
demand, and each receiver j is a resource required by
demands in Dj , and no others. Transmitters in Dj are
precisely the demands contending for access at receiver j.
When nodes are identical, receiver capacities can be
normalized to a unit value so that ci ¼ 1, 1  i  N. The
lexicographic max-min solution, when applied to transmitter persistences, defines the topological allocation ensuring
that no receiver is overrun, no transmitter is overprovisioned, and every unsatisfied transmitter has been allocated
the largest share at a saturated receiver. This model reflects
desirable properties for channel access, without limiting the
MAC protocol employed. The computation and evaluation
of the topological allocation is the prime focus of this paper.
The primary contributions of this paper are as follows:
1.

2.

The topological allocation to transmitter persistences, defined in terms of topology and traffic
loading, is described as a target allocation goal
(Section 1).
A centralized and a distributed algorithm are
developed to compute topological persistences, and
their correctness is established (Sections 3 and 4).

1599

The distributed algorithm is integrated into a
scheduled MAC protocol and applied to wireless
networks simulated using ns-2 [21] (Section 5).
4. Expectation and variation in delay, throughput, and
drop rate reveal potential merits of the topological
allocation (Section 6).
In addition, the distributed algorithm is considered for
use in networks with dynamic topologies and changing
traffic demands; next steps toward a fully adaptive solution
are outlined (Section 7). Use of the distributed algorithm to
compute fair allocations and enable quality of service are
discussed (Section 7).
3.

2

RELATED WORK

Many MAC protocols have been proposed; a few have seen
widespread use. One is IEEE 802.11 [15], a contention-based
protocol that transmits messages whenever there is one to
send. If unsuccessful, an attempt to retransmit is made
again at a time selected randomly within a contention
window. The size of the contention window is determined
by the binary exponential back-off (BEB) algorithm, which
doubles the window size upon transmission failures and
resets it following a successful transmission.
Proposed improvements to IEEE 802.11 add or replace
control messages in the RTS/CTS-based collision avoidance
scheme. Among those are MACAW [2], MACA-BI [26],
RIMA-SP, and RIMA-DP [10], and the use of negative
acknowledgments [24]. Others attempt to improve the
underlying back-off algorithm. BEB was used in Ethernet
[14] and then adapted for wireless networks by MACA [18].
It suffers from severe short-term unfairness [2] and
instability [12], and hence alternate back-off schemes have
been considered in, for example, MILD [2], LMILD [7], SBA
[11], and FAMA-NTR [9].
A class of topology independent MAC protocols
operate with a fixed persistence, dividing time into slots
and transmitting in a fixed percentage of them. An
example is persistent CSMA [27], which transmits in a
given slot with probability p and defers with probability
1  p. When slots are grouped into frames, examples
include TDMA, and topology transparent schemes [3],
[17], [25] that offer more than one transmission opportunity to a node per frame. Random scheduled schemes [6],
[19] also operate at a fixed persistence.
Other protocols negotiate both persistences and schedules realizing them, usually with the objective to maximize
spatial reuse, or minimize average or maximum delay. The
cost is gathering current information about one- or two-hop
neighborhoods to compute a schedule dependent on
topology. In some cases, adaptation occurs when a change
in the neighborhood is observed such as in TDMA spatial
reuse [4], [5] or by alternating between contention and
scheduled phases such as in FPRP [32], CATA [28], and
SEEDEX [23]. These are perhaps the only protocols that
determine transmitter persistences explicitly based on
network topology or demands.

3

CENTRALIZED COMPUTATION OF TOPOLOGICAL
PERSISTENCES

Algorithm 1 gives a centralized algorithm to compute
topological persistences. The set V contains all nodes in the

1600

IEEE TRANSACTIONS ON MOBILE COMPUTING,

network, while set Vactive contains only the nodes whose
persistences have yet to be finalized. Initially, Vactive ¼ V
and the capacity vector c ¼ ð1; . . . ; 1Þ. The matrix T ¼ ½ti;j  is
the adjacency matrix of the neighborhood graph. Then
Dj ¼ fi : ti;j ¼ 1g. At each recursive step a small, nonzero
increment to allocation, , is granted to each node in Vactive
and the capacity vector is updated to reflect this allocation.
Nodes that have either reached their desired persistence
(i.e., si  wi ) or have been bottlenecked by a saturated
resource are removed from Vactive . The procedure continues
until Vactive is empty.
Algorithm 1. A centralized algorithm to compute
topological persistences in a wireless network.
1: procedure COMPUTETOPOLOGICALP ðV ; c; Vactive ; w; T Þ
2:
Inputs:
3:
- Set of nodes V ; N ¼ jV j
4:
- Capacity vector c ¼ ðc1 ; . . . ; cN Þ
5:
- Active nodes Vactive  V
6:
- Desired persistences w ¼ ðw1 ; . . . ; wN Þ
7:
- N  N adjacency matrix T ¼ ½ti;j 
8:
Result:
9:
- Topological persistences s ¼ ðs1 ; . . . ; sN Þ
10:
s
ð0; . . . ; 0Þ
11:
//Select largest possible non-zero  to be allocated
12:
//to all demands in Vactive .
13:

1;
14:
for all j 2 V do
15:
if (ti;j ¼ 1 for some i 2 Vactive ) then
c
16:

minð; jfi:i2Vactivej ;ti;j ¼1gjÞ
17:
for all i 2 Vactive do
18:

minð; wi Þ
19:
//Increase persistence of all nodes in Vactive .
20:
//Remove satisfied demands from Vactive .
21:
for all i 2 Vactive do
22:
si

23:
wi
wi  
Vactive n i
24:
if ðwi ¼ 0Þ then Vactive
25:
for all j 2 V do
cj  
26:
if ðti;j ¼ 1Þ then cj
27:
for all j 2 V , i 2 Vactive do
Vactive n i
28:
if ðcj ¼ 0 and ti;j ¼ 1Þ then Vactive
29:
//Recurse until Vactive is empty.
30:
if ðVactive 6¼ ;Þ then
31:
s s þCOMPUTETOPOLOGICALPðV; c; Vactive ; w; T Þ
32:
return s
33: end procedure
To reduce the number of recursive steps,  is selected to
be the smaller of


cj
min
: j not saturated
jVactive \ Dj j
and minfwi : i 2 Vactive g. The first limits  to allocate remaining capacity at node j among its unsatisfied neighbors, while
the second limits  so that no transmitter is overprovisioned.
A larger value for  generates an infeasible allocation.
Lemma 3.1 and Theorem 3.2 demonstrate the correctness
of Algorithm 1.
Lemma 3.1. Algorithm 1 terminates in a finite number of
recursive steps.

VOL. 12,

NO. 8,

AUGUST 2013

c

Proof.  is the smaller of minfjVactivej\Dj j : j not saturatedg and
minfwi : i 2 Vactive g. If


cj
: j not saturated ;
 ¼ min
jVactive \ Dj j
choose i so that  ¼ ci =jVi j and let Vi ¼ fj 2 Vactive \ Di g.
Then  ¼ ci =jVi j is allocated to each of the jVi j nodes in Vi ,
consuming capacity ðci =jVi jÞ  jVi j ¼ ci . As a result, node i
is saturated, and all nodes in Vi are removed from Vactive .
If  ¼ minfwi : i 2 Vactive g, choose i so that  ¼ wi ; then  is
allocated to all nodes in Vactive including node i. wi is
reduced to zero and node i is removed from Vactive .
Because Vactive is finite, and at least one node is removed
from Vactive in each step, Vactive ¼ ; within a finite number
of steps.
u
t
Theorem 3.2. Algorithm 1 generates the topological allocation.
Proof. It is sufficient to show that Algorithm 1 generates
transmitter persistences that are lexicographically maxmin. By Lemma 3.1, Algorithm 1 terminates with Vactive
empty. We show that allocation s is lexicographically
max-min at the time each node is removed from Vactive .
Consider when node i is removed from Vactive . Node i
is removed because either it has reached its desired
demand, or there exists a saturated node within its range.
In the first case, the demand of node i is satisfied and so
satisfies the constraints of Definition 1.1. For the second
case, we must show that si is maximal among nodes
contending for the channel at the saturated node. Because
channel access is allocated to nodes in Vactive equally at
each step, node i is allocated more capacity than any
node removed from Vactive at an earlier step. Furthermore,
any node i0 still contending for channel access at the
bottleneck is removed concurrently with i from Vactive ,
and hence has si0 ¼ si . By Definition 1.1, s is lexicographically max-min and is the topological allocation.
u
t
The correctness of Algorithm 1 does not require that the
adjacency matrix T be symmetric, so different transmission
ranges are, in principle, treated correctly.

4

DISTRIBUTED COMPUTATION OF TOPOLOGICAL
PERSISTENCES

To compute the persistences s in a decentralized manner,
each receiver accumulates the required information locally
to decide when its available capacity is allocated, either by
becoming saturated or by having no remaining demands; a
transmitter does not increase its persistence if it is satisfied
or if it has a saturated receiver within range. Decentralization is accomplished by treating each receiver as an
auctioneer, and each transmitter as a bidder. Auctioneer j
holds an auction for channel access at node j, making offers
to all bidders in Dj . Bidder i claims channel access offered
by auctioneers in Ri . The adjacency matrix of Algorithm 1
defines the collection of bidders in attendance of each
auction and, conversely, the collection of auctions attended
by each bidder. The auctioneer at node j requires knowledge of, and communication with, a localized set of bidders

LUTZ ET AL.: TOPOLOGICAL PERSISTENCE FOR MEDIUM ACCESS CONTROL

in Dj . Similarly, the bidder at node i requires knowledge of,
and communication with, auctioneers in Ri . Each bidder
derives the topological persistence for its host node.
The auctioneers start out with an initial offer to which
neighboring bidders respond with claims. If a bidder claims
its desired persistence, it terminates. The auctioneers
respond to claims by either closing their auctions or
increasing their offering. Auctioneers and bidders are
loosely synchronized in that a bidder does not respond
with a claim until it has heard from all its auctioneers.
Likewise, an auctioneer does not send out subsequent offers
until it has heard from all its bidders. This process is
repeated until all bidders have claimed their desired
persistence or have been limited at an auction whose
capacity has been completely allocated. Upon termination,
the final claim made by each bidder is the topological
persistence for the associated node. Algorithms 2 and 3 give
the auctioneer and bidder algorithms which run independently on each network node. Each auctionMsg½r contains
the originating auctioneer’s offer and closed status for round
r; each bidderMsg½r contains the originating bidder’s claim
and finished status for round r.
Algorithm 2. Auctioneer for Node j.
1: initialization
2:
round
1
3:
B
fi : i 2 V ; ti;j ¼ 1g
B
4:
Bactive
;
5:
Brecvd
6:
auctionMsg½round:closed
False
7:
auctionMsg½round:offer
ð1=jBactive jÞ
8:
send h auctionMsg½roundii to bidders in Bactive
9: end initialization
10: upon receiving hbidderMsg½roundii from bidder i
11:
claims½i
bidderMsg½round:claim
Brecvd [ i
12:
Brecvd
13:
//If this bidder is finished, remove its index from Bactive .
14:
if ðbidderMsg½round:finished ¼ TrueÞ then
Bactive n i
15:
Bactive
16:
//If a message has been received from every bidder in
17:
//Bactive , respond with another offer.
18:
if ðBrecvd 	 Bactive Þ then
;
19:
Brecvd
20:
round
round þ 1
21:
if ðBactive ¼ ;Þ then
22:
terminate
23:
//Compute
 Xthe next offer.
claims½i
24:
X
i2B;i62Bactive

25:
26:

1X
auctionMsg½round:offer
X
jBactive j
claimed
claims½i
i2B

27:
28:
29:
30:
31:
32:
33: end

if ðclaimed ¼ 1Þ then
auctionMsg½round:closed
True
send h auctionMsg½roundii to bidders in Bactive
terminate
auctionMsg½round:closed
False
send h auctionMsg½roundii to all bidders in Bactive
upon

1601

Algorithm 3. Bidder for Node i.
1: initialization
2:
round
1
3:
A
fj : j 2 V ; ti;j ¼ 1g;
;;
4:
Arecvd
5:
bottlenecked
False;
6:
maxClaim
wi ;
7: end initialization
8: upon receiving h auctionMsg½roundii from auctioneer j
9:
offers½j
auctionMsg½round:offer
Arecvd [ j
10:
Arecvd
11:
//if the auction is closed, it is a bottleneck.
12:
if ðauctionMsg½round:closed ¼ TrueÞ then
13:
bottlenecked
True
14:
//if a message has been received from all auctioneers in
15:
//A, it is time to respond with a claim.
16:
if ðArecvd ¼ AÞ then
;
17:
Arecvd
18:
claim
minðfoffers½j : j 2 Ag [ maxClaimÞ
19:
bidderMsg½round:claim
claim
20:
if ðbottlenecked ¼ True or claim ¼ maxClaimÞ then
21:
bidderMsg½round:finished
True
22:
send h bidderMsg½roundii to all auctions in A
23:
terminate
24:
bidderMsg½round:finished
False
25:
send hbidderMsg½roundii to all auctions in A
26:
round
round þ 1;
27: end upon
We assume throughout that a node with a message to
send does not delay indefinitely in sending it, and that
there is no indefinite delay until successful receipt. That is,
we assume reliable message delivery within finite time.
Lemma 4.1 and Theorem 4.2 establish eventual termination
and correctness.
Lemma 4.1. All auctioneers and bidders in Algorithms 2 and 3
terminate within a finite amount of time.
Proof. First, we show that all auctioneers and bidders
continue to send messages until they terminate. Second,
we show that all auctioneers and bidders eventually
send their final message and terminate.
Consider an auctioneer or bidder that has not terminated, but is unable to send its next message. If it is an
auctioneer, it is waiting on one or more (necessarily active)
bidders to submit their bids. If it is a bidder, it is waiting for
one or more (necessarily open) auctioneers to announce
the next offers. Form a directed graph G with a vertex for
each auctioneer and a vertex for each bidder, and add a
directed edge from node x to node y if x is waiting on y.
To ensure that each node can send its next message
eventually, it suffices to ensure that G has no directed
cycle. Suppose to the contrary that G contains a directed
cycle on nodes ðuð0Þ; . . . ; uðL1Þ Þ. Because bidders and
auctioneers alternate, L is even and without loss of
generality uð0Þ is an auctioneer waiting on bidderMsg½k
from uð1Þ . For 0  i < L2 , auctioneer uð2iÞ is then waiting
for bidderMsg½k  i from uð2iþ1Þ, while bidder uð2iþ1Þ is
waiting for auctionMsg½k ði þ 1Þ from uð2iþ2Þ, arithmetic
modulo L. Then, uðL1Þ is waiting for auctionMsg½k  L2 

1602

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 12,

NO. 8,

AUGUST 2013

the resources of bottleneck nodes 2, 4, 5, 7, and 8 are
saturated. Furthermore, while the demands of nodes 1, 2, 4,
7, and 8 are satisfied, those of nodes 3, 5, 6, 9, and 10 are not.
To cope with an asymmetric adjacency matrix, response
messages generated by an auctioneer can be forwarded on
to any bidders that lie outside the transmission range of
the auctioneer. This raises questions about the effective
implementation of the algorithm, so we turn to these
issues next.

5
Fig. 1. Example network and topological allocation. Bottleneck nodes
are identified by double-lined circles.

from uð0Þ, but uð0Þ has already transmitted auctionMsg
½k  L2 , because it is waiting for bidderMsg½k from uð1Þ .
Therefore, there is no directed cycle in G.
It remains to show that the number of messages is finite.
Partition all messages into subsets, where subset Mk
contains every message of the form auctionMsg½k or
bidderMsg½k. Then Mk contains one message for each
active bidder and each open auction, and hence is finite.
Let auctioneer j have the smallest offer among all
auctioneers with messages in Mk . This offer is equal to
the previous offer made by auctioneer j plus the remaining
unclaimed channel resources divided by jBactive j. Either
there exists a bidder in Bactive who claims its maxClaim, or
all bidders in Bactive claim the full amount offered by
auctioneer j. In the first case, a bidder that claims its
maxClaim terminates immediately. In the second case, the
auction’s capacity is fully allocated causing the termination of all bidders in Bactive . In either case, jMkþ1 j < jMk j,
and the total number of messages sent is finite.
u
t
The argument behind the proof of Lemma 4.1 also sets
an upper bound on the number of rounds required for
algorithm termination. One or more bidders finish during
each round, limiting the number of rounds to be less than
or equal to N. In practice, bidders tend to finish concurrently and the number of rounds is much smaller than N;
see Section 6.
Theorem 4.2. Algorithms 2 and 3 compute the topological
allocation for all nodes in the network.
Proof. It is sufficient to show that Algorithms 2 and 3
compute lexicographically max-min transmitter persistences. Bidder i makes a final claim for one of two
reasons: Either i claims its maxClaim value, or one of the
auctions, j, in which i participates closes. For auction j to
close, it must be saturated and all of its bidders in Bactive ,
including bidder i, claimed the full amount offered by
auctioneer j. Because no bidder can claim more than is
offered, the final claim of node i is maximal among all
claims made in auction j. By Definition 1.1, the allocation
containing all final bidder claims is lexicographically
max-min and is, therefore, the topological allocation. t
u
Fig. 1 shows an example network topology of 10 nodes,
each labeled with desired persistence wi and topological
persistence si . It can be verified that s is feasible, and that

EFFICIENT IMPLEMENTATION OF THE DISTRIBUTED
ALGORITHM AT THE MAC LAYER

Several implementation details must be addressed before
the distributed algorithm can operate in a real wireless
network. Next, we describe an efficient and reliable
implementation.

5.1 Unreliable Communication
As written, the algorithm assumes lossless communication.
One convenient feature of the distributed algorithm is the
built-in acknowledgment system. Effectively, an auctionMsg
acknowledges receipt of a bidderMsg and vice versa
precluding the necessity of an additional acknowledgment
scheme. Reliable interprocess communication can be
achieved by retransmitting bidderMsg and auctionMsg
messages repeatedly until the appropriate acknowledgments are received.
5.2 Message Size and Content
Auctioneer messages contain a current offer. Bidder
messages contain a current claim. The number of bits
required to encode them depends on the desired precision.
A 10-bit encoding, supporting 1,024 unique persistences,
may be sufficient for most applications. Auctioneer and
bidder messages must indicate whether the auction is
closed, and whether the bidder has finished. One bit for
each suffices. Because message retransmissions can occur,
round information is required. The least significant bit of
the round count is sufficient to detect the change in round.
5.3 Message Delivery
A primary concern is the mechanism by which auctioneer
and bidder messages are delivered. Auctioneer and bidder
communication can be piggybacked on existing traffic, or
implemented with additional control packets. With a
precision of 10 bits for claims/offers, only 12 additional
bits of information are required, making the sizes of the
auctioneer and bidder messages smaller than typical control
packets. If piggybacked on existing traffic by embedding
auctioneer and bidder information in the MAC header, the
additional 24 bits translates to an overhead of 0.3 percent
for 1,000 byte packets.

6

SIMULATION RESULTS

In this section, we evaluate the convergence time, accuracy,
and performance of the scheduled topological-persistence
MAC, a schedule-based MAC protocol in which persistences are defined by the distributed algorithm of Section 4.
First, we describe the simulation setup. All simulations
are performed using the ns-2 [21] network simulator.

LUTZ ET AL.: TOPOLOGICAL PERSISTENCE FOR MEDIUM ACCESS CONTROL

Nodes are configured with omnidirectional wireless antennas with physical parameters chosen to match those of the
914-MHz Lucent WaveLAN DSS unicast radios. The data
rate is 11 Mbps. UDP provides network layer services and
traffic is created by the ns-2 constant bit rate (CBR)
generators. All topologies consist of N ¼ 50 static nodes
randomly placed in a 1,500 m by 300 m area with both the
transmission and carrier sense ranges for the radios set to
250 m. The payload size for all generated packets is 900 bytes.
Each simulated network is loaded with one of four traffic
loadings: a few small demands, many small demands, a few large
demands, or many large demands. Traffic loadings with a few
demands insert traffic at 10 nodes randomly selected from
the 50 nodes in the network. Traffic loadings with many
demands insert traffic at all 50 nodes. Small demands
generate traffic at a randomly selected rate of 75 
 50 pkts/s
(an effective persistence of 0:06 
 0:04) while large
demands generate traffic at a randomly selected rate of
800 
 50 pkts/s (an effective persistence of 0:64 
 0:04).
Both control and knowledge of per-node demands are
essential to the evaluation of the distributed algorithm. Our
objective is an improved understanding of the distributed
algorithm and associated topological allocation. To this
end, traffic is constrained to be single hop to avoid
complexity introduced by upper network layers and to
provide precise control of the traffic demands at all nodes.
By changing the number of loaded nodes, varying the
magnitude of the demands, and by randomizing demand
placement, a wide variety of traffic loadings are simulated.
Two MAC protocols are simulated: IEEE 802.11, due to
its ubiquitous use, and scheduled topological-persistence.
In the latter, time is divided into frames, which are divided
into v slots. At the start of every frame, each node
independently and randomly selects a number of slots
for transmission. The number selected by a node is derived
from the current claim made by its bidder. Let pclaim be the
current claim at node i; then node i selects bpclaim  vc þ 1
slots with probability i and bpclaim  vc slots with probability 1  i where i ¼ ðpclaim  v  bpclaim  vcÞ. Over time,
the effective persistence of node i approaches pclaim . Each
node updates its schedule immediately—mid-frame if
necessary—upon any change to its bidder’s claim. Traffic
demands are converted to equivalent persistences to define
w ¼ ðw1 ; . . . ; wM Þ. Auctioneer offers and bidder claims are
embedded into the MAC header and piggybacked over
existing network traffic. Scheduled topological-persistence
implements acknowledgments similar to those of IEEE
802.11. The slot length is set to 0.0008 s, making room for
900 bytes of payload, 72 bytes of MAC header, turn around
time for the receiver, and transmission of the return
acknowledgment. The retry count is set to 10. Unless
specified otherwise, the frame length is 100 slots.
Packets created by the CBR generators do not account for
all traffic in the network. For instance, the address resolution
protocol (ARP) [1] requires communication between source
and destination nodes during address resolution. Clearly, a
node with a persistence of zero cannot send packets to
neighboring nodes. But, this inability suppresses responses
to ARP requests, thereby preventing the node from receiving packets as well. A similar problem arises with the

1603

Fig. 2. Convergence in time and number of rounds for scheduled
topological-persistence with minimum persistence of 0.002.

distributed algorithm of Section 4 where a persistence of
zero prevents auctioneer and bidder communication. This
does not hinder bidders who desire a persistence of zero. For
auctioneers, a persistence of zero is fatal; they must respond
to the claims of neighboring bidders. To resolve this,
scheduled topological-persistence employs a network-wide
minimum persistence. If a node encounters a transmission
slot, but does not have a packet to transmit, it creates a
dummy packet (empty payload, valid auctioneer/bidder
information) and transmits it. These packets are considered
MAC overhead and are not included in the delay,
throughput, or drop rate reported. (The choice of minimum
persistence is discussed in Section 6.2.)
For simulations of IEEE 802.11, the maximum packet
retry count is set to seven for RTS, CTS, and ACKs and
reduced to four for data packets per [15]. The minimum
and maximum contention window sizes are set to 32 and
1,024 slots, respectively, with the slot length set to 20 s.

6.1 Convergence Time
Fig. 2 plots the expected convergence time and the number
of rounds for simulations of 400 random topologies (100 of
each traffic loading) running scheduled topological-persistence with a minimum persistence of 0.002. The expected
convergence times for scenarios with many demands (1.29 s
for many small demands and 1.37 s for many large
demands) are significantly smaller than those for scenarios
with just a few demands (2.07 s for a few small demands
and 8.95 s for a few large demands).
The convergence time for networks with a few demands,
small or large, is explained by the small minimum
persistence employed by the unloaded nodes. A node
operating with a persistence of 0.002 is expected to transmit
once every 0.4 s (assuming a slot length of 0.0008 s).
Considering the infrequent communication between nodes,
the convergence times are understandable. Scenarios with a
few large demands take longer to converge because nodes
operating at the minimum persistence must compete with
neighbors transmitting at much higher persistences. In
contrast, nonloaded nodes in networks with only a few
small demands operate in lightly loaded neighborhoods
with very little contention. The nodes may not transmit often;
when they do transmit, their communications are more likely
to succeed. For scenarios with many demands, all nodes

1604

IEEE TRANSACTIONS ON MOBILE COMPUTING,

Fig. 3. Per-node persistence and per-node persistence error for nodes
running scheduled topological-persistence with a minimum persistence
of 0.002.

operate with persistences much greater than the minimum
persistence, enabling the protocol to converge quickly.
Fig. 2 shows the number of rounds for protocol
termination to be smallest for networks with a few small
demands, larger for many small demands, larger still for a
few large demands, and largest for many large demands.
The number of rounds is influenced by the number of
saturated resources (i.e., bottlenecked auctions) that must
be discovered. For networks loaded with a few small
demands, it is probable that all resources remain unsaturated, allowing most bidders to become satisfied by their
auctioneers’ initial offers. If a bidder is not satisfied in the
first round, it is almost certainly satisfied by the increased
offers of the second round. Of the 100 simulated networks
with a few small demands, all 100 terminated in exactly two
rounds. Networks with many small demands are more
heavily loaded and, in dense areas, may saturate resources.
Networks with a few large demands are even more likely to
saturate resources—any two can saturate a resource. The
heavy load of networks with many large demands results in
the greatest number of saturated resources, and consequently, the distributed algorithm requires the greatest
number of rounds to terminate under this traffic loading.
There is an apparent disconnect between expected
convergence time and the number of rounds required for
protocol termination. The time required for convergence is
influenced more by small persistences than it is by the
number of rounds.
Fig. 3 shows observed persistences and persistence
errors for nodes in a network loaded with a few large
demands. Persistence error for node i is ðsi  pi Þ where si
and pi represent the topological allocation and the measured persistence of node i, respectively. Most of the
persistence error represents a deficit relative to the
topological allocation occurring in the first two seconds.
The topological persistences, ð0:16; 0:16; 0:16; 0:16; 0:16;
0:16; 0:24; 0:24; 0:50; 0:67Þ, are evident in Fig. 3. Plateaus
represent periods of time when a bidder is waiting to hear
from auctioneers; abrupt changes identify updated claims
by bidders. Although the last node converges at 6.86 s, most
nodes have converged on the topological allocation long
before then. This time lag suggests the need for a metric that
accounts for the magnitude of persistence error.

VOL. 12,

NO. 8,

AUGUST 2013

Fig. 4. Expected persistence error relative to the topological allocation.

A node’s relative persistence error, defined as the ratio
of persistence error to topological persistence, measures
the fraction of the topological allocation realized by the
node. By computing the geometric average, we characterize a node’s expected error during execution of the
distributed algorithm.
Fig. 4 shows expected relative persistence error (for the
simulations of Fig. 2) in three parts: error due to
persistences greater than the topological allocation, error
due to persistences smaller than the topological allocation,
and total error due to persistences above and below the
topological allocation. Persistence errors for nodes operating at the minimum persistence are not included in the
geometric average. The results show an expected 38 percent
error in networks with a few small demands and between
23 and 25 percent error for networks loaded with the other
three traffic loadings. The higher percentage error for
networks with few small demands is a consequence of the
small number of rounds required to reach the topological
allocation. With an expectation of two rounds (see Fig. 2),
these nodes are more likely to converge on their final
persistences during the last round close to protocol
termination, driving up the expected relative persistence
error. The other traffic loadings tend to require a greater
number of rounds and, in consequence, a smaller proportion of the nodes finalize their persistence during the last
round. As a result, nodes have a tendency to reach their
final persistence earlier relative to network-wide convergence, reducing the expected relative persistence error.

6.2

Convergence Time with Larger Minimum
Persistences
Intuitively, a larger minimum persistence drives down the
convergence time by allowing auctioneers running at
nonloaded nodes to respond more quickly to the claims
made by neighboring bidders. This improvement comes at a
cost. The larger minimum persistence must be reserved by
nodes with no packets to send at the expense of nodes with
packets to send. The result is an overall degradation in
system-wide throughput.
Fig. 5 shows the relationship between minimum persistence, convergence time, and throughput. The statistics are
taken from a set of 10 topologies loaded with a few large
demands, each topology simulated 30 times with a different
minimum persistence ranging from 0.001 to 0.030 in
increments of 0.001. Convergence times are measured from

LUTZ ET AL.: TOPOLOGICAL PERSISTENCE FOR MEDIUM ACCESS CONTROL

1605

Fig. 5. Influence of minimum persistence on convergence and
throughput for topologies loaded with a few large demands.

Fig. 6. Convergence in time and in number of rounds for scheduled
topological-persistence with a larger minimum persistence of 0.01.

time zero to the time the last bidder arrives at the
topological allocation. Throughput measurements are taken
for 75 s after convergence. The average per-node throughput is computed for nodes loaded with large demands;
nodes operating at the minimum persistence are excluded
from the calculation.
The simultaneous drop-off in convergence time and
gradual contraction in throughput is unique to networks
with few large demands. Networks loaded with many
demands are not affected by the change to minimum
persistence; all nodes in these networks operate above the
minimum persistence. For networks with few small
demands, a larger minimum persistence reduces the
convergence time, but leaves throughput unchanged
because allocation to minimum persistences is not made
at the expense of other nodes.
The degree that throughput suffers from allocations
made to nonloaded nodes is also a function of the network’s
expected neighborhood size. Larger neighborhoods tend to
have more nonloaded nodes contending for access to the
channel, thereby reducing the allocation available to the
remaining nodes. We simulate fairly dense topologies,
accentuating this behavior.
From the results in Fig. 5, we conclude that a minimum
persistence of 0.01 is expected to reduce the average
convergence time to 2.48 s while keeping expected
throughput at 132 pkts/s (a drop of 21 pkts/s from its
peak). To verify this, the 400 topologies used in the
simulations of Fig. 2 are simulated again, this time with a
minimum persistence of 0.01. All other MAC parameters
are held constant. Results are shown in Fig. 6. While the
expected number of rounds does not change, the convergence time is reduced from 2.07 to 0.80 s for networks with
few small demands and from 8.95 to 2.65 s for networks
with few large demands. As expected, convergence times
for networks with many demands did not change.

negotiation persistences which are determined according to
neighborhood size and are used only during execution of
the distributed algorithm. The negotiation persistence of
node i is 1=X where X is the size of the largest
neighborhood in which i participates. Each node starts
with its negotiation persistence and then transitions to its
topological persistence when 1) it has determined its own
topological persistence and 2) all nodes within its one-hop
neighborhood have determined their topological persistences. Upon termination of the distributed algorithm, the
topological allocation must maintain a network-wide minimum persistence in support of network functions such as
ARP. Use of negotiation persistences permits a smaller
minimum persistence without degrading the distributed
algorithm’s time to convergence.
Fig. 7 shows the expected convergence times for the
distributed algorithm when configured to use negotiation
persistences and run on the 400 topologies and traffic
loadings of Fig. 2. The minimum persistence is 0.002. The
expected number of rounds remains unchanged. Expected
convergence times are consistently small (0.60 s for a few
small demands, 1.05 s for many small demands, 1.07 s for a
few large demands, and 1.33 s for many large demands).
The traces in Fig. 8 show persistence, persistence error,
and neighborhood overallocation for scheduled topologicalpersistence when configured to use negotiation persistences. The topologies and traffic loadings of Fig. 3 are
reused. The minimum persistence is 0.002. The negotiation

6.3

Convergence Time with Larger Negotiation
Persistences
The communication needs of the distributed algorithm
constitute a set of demands that are not represented in the
desired persistences passed down to the MAC layer. While
an increased minimum persistence meets these demands
indirectly, the demands are temporary, resulting in a longterm waste of the channel. Here, we examine the use of

Fig. 7. Convergence in time and in number of rounds for scheduled
topological-persistence configured to use negotiation persistences.

1606

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 12,

NO. 8,

AUGUST 2013

Fig. 9. Expected persistence error relative to the topological
allocation for scheduled topological-persistence configured to use
negotiation persistences.

Fig. 8. Per-node persistence, persistence error, and overallocation
for scheduled topological-persistence configured to use negotiation
persistences.

persistences are clearly visible during the first second of
simulation in the persistence and persistence error traces.
While some of the negotiation persistences are smaller than
their corresponding topological persistences, they are much
larger than the minimum persistence and show up as excess
persistence in the persistence error trace. The excess in
persistence resolves itself by the time the topological
solution is reached at 1.39 s.
The transition from negotiation persistences to topological persistences is only loosely synchronized; neighboring
nodes may not transition to their topological persistences at
the exact same time. During the transition, overallocation of
the channel is possible as is evident in the overallocation
trace of Fig. 8 during the interval starting at approximately
0.8 s through 1.39 s. The bidder claims are designed to
prevent overallocation; therefore, overallocation only occurs
when negotiation persistences are used.
Expected relative persistence error for the simulations of
Fig. 7 is shown in Fig. 9. Negotiation persistences drive up
relative persistence error for networks with a few large
demands. While these persistences are large compared to
the minimum persistence, they are small compared to the
large allocations that are common in networks with only a
few large demands. The amplified difference between the
negotiation persistences and the topological persistences
under this traffic loading exacerbates the measured error.
Topological persistences for the other three traffic loadings
are smaller and therefore more similar to the negotiation
persistences; the result is a smaller relative persistence error.

6.4 Accuracy of Distributed Algorithm
To validate the accuracy of the distributed algorithm,
calculated persistences are compared against values generated by the centralized algorithm. Absolute error is jpdist 
pcntrl j where pcntrl and pdist are the persistences derived from
the centralized and distributed algorithms, respectively.
Table 1 reports observed errors for precision levels ranging

from 5 to 30 bits. The data in the table are taken from
simulations of 400 random topologies—100 of each traffic
loading—running scheduled topological-persistence with a
minimum persistence of 0.01.
The accuracy of the distributed algorithm improves as
bits are added to the persistence representation. The realvalued auctioneer offers are mapped into the persistence
representation rounding their offers up. The expected
rounding error for a single mapping from a real-valued
persistence into a -bit discrete persistence representation is
one half of 1=2 . The expected rounding error is shown in
column 3 of Table 1 to be compared against the average
errors in column 4. The average absolute error tracks the
theoretical expected rounding error, staying within an order
of magnitude.
The large maximum errors shown in column 6 can be
explained through a simple, yet extreme, example. Consider
an auction with b bidders. One bidder has a demand of 1;
the remaining bidders have demands less than 1=b. During
the first round, the auctioneer offers an allocation of 1=b,
rounded up to the nearest persistence level in the
representation. The b  1 bidders with small demands
become satisfied immediately and their first and final
claims assume the rounding error introduced by the
auctioneer, claiming a maximum of 1=2 more than their
topological allocation. To prevent overallocation of the
channel, the auctioneer reduces subsequent offers, so the
final offer made to the one remaining bidder is ðb  1Þ=2
smaller than its topological allocation. With 50 nodes, the
theoretical maximum for absolute error is bounded by
49=2 . These numbers are included in column 5 to compare
to the maximum observed errors of column 6.
The final two columns of Table 1 show the observed
convergence times and expected number of rounds to
protocol termination. For representations with 10 or more
bits of precision, the convergence time and rounds to
protocol termination remain relatively unaffected. For
representations with 9 and fewer bits, a marked decrease
is observed for both measurements. Offers that are close to,
but not exactly, equal are mapped to the same level in the
persistence representation, simplifying the computation
and reducing the number of rounds. Fewer rounds means
shorter convergence time.

LUTZ ET AL.: TOPOLOGICAL PERSISTENCE FOR MEDIUM ACCESS CONTROL

1607

TABLE 1
Accuracy of Distributed Implementation

At 10 bits of precision, the average observed rounding
error is 0.0008 with a maximum observed error of 0.0274.
For the purposes of channel allocation, these errors are
acceptable. All simulations, except those of Table 1, use a
10-bit representation for persistences.

length, the observed persistences of the scheduled topological-persistence MAC are far less variable than those of
IEEE 802.11.

6.5 Frame Length and Persistence Stability
Fig. 10 demonstrates the relationship between frame length
and variation in persistence, corroborating the analytical
results reported in [6]. Persistence traces are shown from
four simulations of the same topology and traffic loading.
The top three traces show persistence for the scheduled
topological-persistence MAC with frame lengths of 25, 100,
and 400 slots. The bottom trace shows persistences for the
IEEE 802.11 MAC. Persistences are estimated over 0.1 s
intervals. A notable increase in persistence variation is seen
when running with the longer frame lengths. At a frame
length of 25, the observed persistences vary only slightly; at
a frame length of 400, variation increases allowing the
measured persistences to run together. Regardless of frame

6.6 Comparison with IEEE 802.11
When compared to IEEE 802.11, scheduled topologicalpersistence performs surprisingly well, especially considering the added overhead of a network wide minimum
persistence of 0.01. Fig. 11 shows delay, throughput, and
drop rate for scheduled topological-persistence compared
to IEEE 802.11. Measurements are taken from simulations
of 120 different networks, each with a randomly generated
topology and traffic loading—30 of each traffic loading.
Each network is simulated once using scheduled topological-persistence and then using IEEE 802.11. Delay,
throughput, and drop rate measurements are taken over
20 s following a 5 s network warm-up period. The warmup period begins at time zero for simulations of IEEE
802.11 and at convergence to the topological allocation for
scheduled topological-persistence.

Fig. 10. Persistences for scheduled topological-persistence and 802.11.

6.6.1 Comparing Delay
Two forms of delay are reported in Fig. 11. The first
measures delay for successful packet transmissions only.
Measuring delay in this manner underestimates delay in
networks with a significant packet drop rate. The second
form of delay accounts for dropped packets by including
delay for successful and unsuccessful packet transmissions.
Delay for an unsuccessful packet transmission is arbitrarily
defined to be the time the packet spends queued for
transmission at the MAC layer before being dropped.
We start with a discussion of delay calculated over
successful packet transmissions. For networks with only a
few small demands, scheduled topological-persistence has
an expected delay of 0.0173 s for successful packets, nearly
three times that of IEEE 802.11. Lightly loaded networks
lend themselves to the greedy approach of IEEE 802.11. With
only a few small demands spread out over the network,
collisions are unlikely and most packets are transmitted
immediately upon receipt from the network layer. In
contrast, scheduled topological-persistence waits until the
next transmission slot to transmit a packet. Assuming a
persistence of 0.06 and a slot length of 0.0008 s, the expected

1608

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 12,

NO. 8,

AUGUST 2013

Fig. 11. Comparing scheduled topological-persistence (frame length of 100 and minimum persistence of 0.01) with IEEE 802.11.

time between transmission slots is 0.013 s, accounting for
nearly all of the packet delay measured.
Both MAC protocols exhibit higher delay when loaded
with many small demands. The added congestion increases
the likelihood of collisions, driving up the number of
retransmissions necessary for successful packet delivery.
Retransmissions mean added delay. Scheduled topologicalpersistence has an expected delay of 0.0356 s for successful
packets—29 percent greater than IEEE 802.11. While the
average MAC layer delay for successful transmissions for
scheduled topological-persistence is longer than that of
IEEE 802.11, it has a 64 percent smaller variation in delay,
which is striking.
For networks loaded with few large demands, scheduled
topological-persistence has an expected delay of 0.0071 s, 15
percent larger than the 0.0062 s measured for IEEE 802.11.
The larger demands result in larger topological persistences
and a marked drop in delay compared to networks with
few small demands. The standard deviation in the delay
measurements for the scheduled topological-persistence
MAC is 0.0089 s, roughly 43 percent that of IEEE 802.11.
Finally, when loaded with many large demands,
scheduled topological-persistence has an expected delay
of 0.0321 s, 15 percent larger than the delay of IEEE 802.11;
standard deviation in delay for scheduled topologicalpersistence is 0.0343 s, 63 percent smaller than it is for
IEEE 802.11.
The two forms of delay when measured over simulations
of scheduled topological-persistence are almost identical,
suggesting a high success probability for MAC layer
communication. In contrast, inclusion of unsuccessful
packets in the delay calculation for IEEE 802.11 reveals a

marked increase in both delay expectation and variation in
delay for all four traffic loadings. For three of the network
loadings (all but a few small demands), the expected delay
for all packets is larger for IEEE 802.11 than for scheduled
topological-persistence, reflecting a tendency a IEEE 802.11
to drop packets.

6.6.2 Comparing Throughput
Scheduled topological-persistence shows a distinct advantage over IEEE 802.11 with higher throughput rates
reported for all but one of the four traffic loadings. As
was seen with delay, IEEE 802.11 performs very well on
lightly loaded networks with few small demands; its
expected per-node throughput is 77.88 pkts/s, a 34 percent
improvement over that of scheduled topological-persistence. The smaller throughput achieved by scheduled
topological-persistence comes from scheduled channel
access, where each node maintains its target persistence
without regard to the number of retransmissions necessary
to deliver a packet. When the magnitude of a node’s traffic
demand matches the persistence of the MAC layer, a packet
retransmission by scheduled topological-persistence consumes a transmission slot “intended” for another packet.
Because the MAC protocol does not increase its persistence
to make up for the lost transmission opportunity, the packet
retransmission represents a loss in overall throughput. The
inherent flexibility of IEEE 802.11 allows it to dynamically
increase its persistence to accommodate packet retransmissions, minimizing loss of throughput due to collisions in
lightly loaded networks.
Scheduled topological-persistence fares better in terms of
expected per-node throughput for the other three traffic

LUTZ ET AL.: TOPOLOGICAL PERSISTENCE FOR MEDIUM ACCESS CONTROL

1609

Fig. 12. Delays for scheduled topological-persistence and IEEE 802.11.

Fig. 13. Throughputs for scheduled topological-persistence and 802.11.

loadings with an improvement of 25 percent over IEEE
802.11 for networks with many small demands, 13 percent
for a few large demands, and 38 percent for many large
demands. When compared to IEEE 802.11, the standard
deviation in throughput is reduced to 43 percent when
loaded with a few small demands, 48 percent for many small
demands, 97 percent for a few large demands; and 74 percent
for many large demands. The large variation in throughput
for scheduled topological-persistence in networks with a few
large demands is an artifact of the traffic loading. It is
possible for some neighborhoods to contain a single loaded
node while others contain several loaded nodes; neighborhoods with a single loaded node assign the greater portion of
channel capacity to that one node; neighborhoods with
several loaded nodes must divide the channel capacity
equally among contending nodes. The result is a large
variation in persistence within the topological allocation.
IEEE 802.11 has no notion of topological persistence; its
variation in throughput comes from dynamically changing
per-node persistences (see Fig. 10).

(x-coordinate) and variation (y-coordinate) in delay for
exactly one node. Scheduled topological-persistence demonstrates a remarkable ability to control variation in delay for
packets sent from a common node. The largest reported
variation in delay is 0.0031 s2 , nearly two orders of
magnitude smaller than the maximum 0.106 s2 reported
for IEEE 802.11.
Fig. 13 shows a similar scatter plot for throughput by
transmitting node. Each data point identifies expectation
(x-coordinate) and variation (y-coordinate) for throughput
at a single node. Throughput is estimated over 0.1 s
intervals. As seen with delay, scheduled topologicalpersistence proves adept in the control of variation in
throughput achieved by each node. The maximum
variation in throughput for scheduled topological-persistence is 2,200 packets2 =s2 , less than 6 percent of the
29,000 packets2 =s2 measured for IEEE 802.11.

6.6.3 Comparing Drop Rate
Perhaps the most dramatic improvement in scheduled
topological-persistence is the drastically reduced packet
drop rate. Compared to IEEE 802.11, scheduled topologicalpersistence rarely drops packets. Networks with a few large
demands result in the highest expected drop rate of
0.171 pkts/s, roughly 10 percent that of IEEE 802.11. It also
cuts variation in drop rate by a minimum of 67 percent and
as much as 94 percent for networks with few small
demands where IEEE 802.11 favors some nodes at the
expense of others, resulting in an exaggerated drop rate. To
put this in context, consider a drop rate of 4.5 pkts/s (i.e.,
expected drop rate plus one standard deviation). For a node
loaded with 75 pkts/s, an expected 6 percent of packets
queued for transmission are lost.
6.6.4 Variation in Delay and Throughput
The delays reported in Fig. 11 are organized by MAC
protocol and traffic loading, masking the behavior of
individual nodes by combining delay measurements for
packets sent by nodes from 30 different networks. Fig. 12
plots delays for the same set of simulations, but with packet
delays organized by transmitting node. The result is a scatter
plot where each data point communicates expectation

7

DISCUSSION

The simulation results in Section 6 show the distributed
algorithm to be well suited for use in homogeneous networks
with fixed topologies. The decentralized nature and minimal
overhead make it feasible to compute topological persistences for any network topology or traffic loading. Here, we
discuss consequences and remaining concerns.

7.1 Obstacles to Adaptation
There are several obstacles to the distributed algorithm’s
deployment in real-world wireless networks. One is its
requirement for nodes to have a priori knowledge of their
neighbors. In practice, a method must be provided for
neighbor discovery. A second obstacle is the distributed
algorithm’s reliance on round synchronization. The distributed algorithm provides its own synchronization, but it
assumes that all auctioneers and bidders are started
simultaneously. In an implementation, either the algorithm’s synchronization requirements must be weakened, or
a method provided to synchronize. A third obstacle is the
distributed algorithm’s assumption of a static topology.
Once initialized, each auctioneer assumes a fixed set of
bidders and each bidder a fixed set of auctioneers. Changes
occurring after algorithm initialization are ignored, resulting
in a channel allocation that may not match the topological
allocation defined for the new topology. In practice, the
algorithm must accommodate topology changes. A fourth

1610

IEEE TRANSACTIONS ON MOBILE COMPUTING,

obstacle is the distributed algorithm’s assumption of static
desired persistences, determined for all time prior to
algorithm execution. In an actual wireless network, the
desired persistences change throughout the life of the
network; the algorithm must accommodate these changes.
These obstacles suggest potential next steps for the
design of an adaptive algorithm capable of operating in
networks with dynamic topologies and traffic loadings.
The distributed algorithm should be modified to
perform neighbor discovery for itself, detecting both
new and lost neighbors.
2. The synchronization requirement imposed by the
distributed algorithm should be weakened. A fully
asynchronous approach would obviate the need for
synchronization.
3. The distributed algorithm should adjust to changes
in both topology and traffic loading, automatically
converging toward the latest topological allocation.
The impact of any network change should be limited
to nodes whose persistences need updating to match
the topological allocation. Ideally, other nodes
should remain unaffected.
4. The convergence time for the distributed algorithm
should be further reduced. Faster convergence
improves the algorithm’s responsiveness to network
changes, making it relevant to networks with high
mobility or bursty traffic.
Considering the obstacles outlined, the distributed
algorithm should not at this time be viewed as a full
solution to the challenge of distributed computation of the
topological allocation in mobile wireless networks; rather, it
is an important and useful step toward such a solution. The
already fast convergence time, intuitive structure, computational simplicity, and minimal communication overhead
make the distributed algorithm a promising place to start in
the design of a fully adaptive solution.
1.

7.2 The Topological Allocation and Fairness
The topological allocation is lexicographically max-min to
transmitters of the network. Such an allocation has been
extensively explored as a fairness metric for single-hop and
end-to-end flows; its use as a MAC allocation strategy
represents a new approach to wireless channel access. To
the best of our knowledge, the only application of this
definition to persistences is in our preliminary work [19].
Perhaps most closely related is single-hop flow-fairness
that concerns fair allocation of the channel to flows defined
at the MAC layer traversing a single hop. Modeling singlehop flows as edges in an undirected multigraph enables one
to determine a flow contention graph, whose cliques
represent regions of possible contention [13], [16], [20].
These do not take into account the asymmetry of flows.
Max-min fair allocation to directed flows is treated in [29],
[30], and [31].
7.3 Achieving Single-Hop Flow-Fairness
The difference between single-hop flow-fairness and the
topological allocation results from a fundamental distinction: Are transmitters or single-hop flows to be treated
equally? In focussing on the MAC problem, the topological

VOL. 12,

NO. 8,

AUGUST 2013

allocation ensures the equal treatment of transmitters. But,
the distributed algorithm is not limited to the implementation of the topological allocation. It is a distributed method
capable of solving a general lexicographic max-min
optimization problem. Consider the application to singlehop flow-fairness, defined as follows: The resources are the
receivers at each node. The demands are the single-hop
flows. Auctioneers manage the allocation offered by
receivers; bidders manage the allocation claimed for
single-hop flows. The resulting allocation is lexicographically max-min to single-hop flows.

7.4

Single-Hop Flow-Fairness as a MAC Allocation
Scheme
On one hand, once traffic is offered and admission control,
flow control, and routing decisions are made, it may be
desirable to provide fair access for each single-hop flow. On
the other hand, each of these higher layer decisions is
impacted by the access of each transmitter to the channel; in
making these decisions, it is desirable to know what
persistence each transmitter is permitted, in addition to
knowing what traffic is routed from or through it. This
circularity, with flows depending on persistences and
persistences depending on flows, creates a challenging
cross-layer optimization problem not easily solved by
treating any layer in isolation.
Imposing persistences based on single-hop flow-fairness
may fail to lead to fairness for applications, because some
may set up many end-to-end flows while others use one;
by routing through a congested node, it may adversely
impact the total channel utilization; and when flows are
bursty, they require frequent changes in the persistences.
Persistences based on transmitter-fairness can inform
higher layers of the opportunities to transmit, thereby
supporting routing, flow control, and admission decisions.
Indeed, setting all demand magnitudes to 1, transmitterfairness becomes a function of topology alone, and serves
as a measure of network capacity.
Our objective is the effective determination of persistences that permit each transmitter an amount of channel
access that does not disadvantage any of its neighbors, which
may diverge substantially from single-hop flow-fairness.
7.5 Fairness and Quality of Service
In practice, it may be desirable to allow nodes to have
different entitlements to channel access, so that a node
carrying more flows has more right to channel access. This
is accommodated by a weighted topological allocation: each
transmitter is assigned a weight, ð1 ; 2 ; . . . ; M Þ, and the
allocation vector is chosen so that ð1 s1 ; 2 s2 ; . . . ; M sM Þ is
lexicographically max-min. If we denote by ni the number
of single hop flows initiated at transmitter i and set
i ¼ 1=ni , the allocation is single-hop flow-fair.
The weighted topological allocation is not limited to
weighting by the number or total demand of flows initiated
at a transmitter. Indeed, the upper layers of the network
stack are free to select the weights according to topological
properties such as neighborhood size and node betweenness [8], or they can be driven in response to differentiated
traffic in support of quality of service. Accommodating
extensions to the weighted topological allocation in the

LUTZ ET AL.: TOPOLOGICAL PERSISTENCE FOR MEDIUM ACCESS CONTROL

auction algorithms is straightforward, and may provide a
mechanism for accommodating both standard fairness
requirements and differentiated traffic.
The dramatically reduced variation in packet delay and
throughput for scheduled topological-persistence motivates
its use in both delay sensitive and resource constrained
networks. In delay sensitive networks, packets with a large
delay may be unusable by the application; example
applications include voice, video, and other real-time
constrained communications. In resource constrained networks, nodes may have insufficient buffer space to handle
spikes in throughput resulting in packet loss due to buffer
overruns. In either case, low variation in delay and
throughput increases the percentage of usable packets.
The consistency offered by scheduled topologicalpersistence also enables prediction of future behavior with
greater accuracy. Even if throughput and delay vary from
node to node, consistent behavior of individual nodes
allows the network to better characterize its path delays
and localized capacity. This information can be passed up
the network stack and used by routing, admission control,
and resource reservation protocols. To be useful, this
information must be accurate. The high variation in delay
and throughput experienced at nodes running IEEE 802.11
make it impossible to accurately predict delay or throughput. Scheduled topological-persistence, on the other hand,
maintains predictable delay and throughput characteristics, enabling the use of MAC layer performance measurements by higher layer functions.

7.6 MAC Protocol Design
We have argued that topological persistences set target
occupancies for transmitters. Naturally, the question is how
to use these persistences, once computed. We have used
them in scheduled topological-persistence. Certainly any
MAC protocol that that employs explicit persistences can
employ the topological allocation directly. There remain
protocols that do neither, for example contention-based
schemes with a back-off mechanism. Even for these,
topological persistences determine how long to wait on
average, and may provide a useful tool in tuning the backoff mechanism.

8

CONCLUSION

Prior work on MAC protocol design has focussed on
specific challenges such as collision avoidance, minimization of delay, and spatial reuse. Observing that all MAC
protocols, regardless of end goal or underlying strategy,
determine the operating persistences of transmitters, we
argue that persistences should follow the topological
allocation, a lexicographically max-min allocation that treats
transmitters as demands and receivers as resources. With
this in mind, a straightforward centralized algorithm is
used to devise an auction-based distributed algorithm for
computing topological persistences, and correctness of both
algorithms is established. The auction-based technique can
be implemented with minimal communication that can be
piggybacked on existing traffic; and simulation results
demonstrate that such an implementation succeeds in
finding topological persistences in a reasonable period of

1611

time. When equipped with these persistences, a simple
persistence-based MAC protocol operating with topological
persistences can outperform IEEE 802.11. As developed
here, the determination of topological persistences is
undertaken only once, and applies only as long as the
topology and demands remain unchanged. Adaptation to
changing topology and changing demands is a subject of
our current research.

ACKNOWLEDGMENTS
The authors appreciate the comments provided by the
anonymous reviewers.

REFERENCES
[1]
[2]
[3]

[4]
[5]

[6]
[7]

[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]

D. Plummer, “Ethernet Address Resolution Protocol,” IETF RFC
826, 1982.
V. Bharghavan, A. Demers, S. Shenker, and L. Zhang, “MACAW:
A Medium Access Protocol for Wireless LANs,” Proc. ACM
SIGCOMM, pp. 212-225, 1994.
I. Chlamtac and A. Faragó, “Making Transmission Schedules
Immune to Topology Changes in Multi-Hop Packet Radio
Networks,” IEEE/ACM Trans. Networking, vol. 2, no. 1, pp. 23-29,
Feb. 1994.
I. Chlamtac and S. Kutten, “A Spatial-Reuse TDMA/FDMA for
Mobile Multi-Hop Radio Networks,” Proc. IEEE INFOCOM,
pp. 389-393, 1985.
I. Chlamtac and S.S. Pinter, “Distributed Nodes Organization
Algorithm for Channel Access in a Multihop Dynamic Radio
Network,” IEEE Trans. Computers, vol. 36, no. 6, pp. 728-737, June
1987.
C.J. Colbourn and V.R. Syrotiuk, “Scheduled Persistence for
Medium Access Control in Sensor Networks,” Proc. IEEE Int’l
Conf. Mobile Ad-Hoc and Sensor Systems (MASS), pp. 264-273, 2004.
J. Deng, P.K. Varshney, and J. Haas, “A New Backoff Algorithm
for the IEEE 802.11 Distributed Coordination Function,” Proc.
Comm. Networks and Distributed Systems Modeling and Simulation
Conf. (CNDS), 2004.
L.C. Freeman, “A Set of Measures of Centrality Based on
Betweenness,” Sociometry, vol. 40, no. 1, pp. 35-41, 1977.
C.L. Fullmer and J. Garcia-Luna-Aceves, “Floor Acquisition
Multiple Access (FAMA) for Packet-Radio Networks,” Proc.
ACM SIGCOMM, vol. 25, pp. 262-273, 1995.
J. Garcia-Luna-Aceves and A. Tzamaloukas, “Receiver-Initiated
Collision Avoidance in Wireless Networks,” Wireless Networks,
vol. 8, pp. 249-263, 2002.
Z. Haas and J. Deng, “On Optimizing the Backoff Interval for
Random Access Schemes,” IEEE Trans. Comm., vol. 51, no. 12,
pp. 2081-2090, Dec. 2003.
J. Hastad, T. Leighton, and B. Rogoff, “Analysis of Backoff
Protocols for Multiple Access Channels,” Proc. ACM 19th Ann.
Symp. Theory of Computing (STOC), pp. 740-744, 1987.
X.L. Huang and B. Bensaou, “On Max-Min Fairness and
Scheduling in Wireless Ad-Hoc Networks: Analytical Framework
and Implementation,” Proc. ACM MobiHoc, pp. 221-231, 2001.
IEEE 802.3, CSMA/CD Ethernet Access Method, IEEE, 1983.
IEEE 802.11, Wireless LAN Medium Access Control (MAC) and
Physical Layer (PHY) Specifications, IEEE, 1997.
L.B. Jiang and S.C. Liew, “Proportional Fairness in Wireless LANs
and Ad Hoc Networks,” Proc. IEEE Wireless Comm. and Networking
Conf. (WCNC), vol. 3, pp. 1551-1556.
J. Ju and V.O.K. Li, “An Optimal Topology-Transparent Scheduling Method in Multihop Packet Radio Networks,” IEEE/ACM
Trans. Networking, vol. 6, no. 3, pp. 298-305, June 1998.
P. Karn, “MACA - A New Channel Access Method for Packet
Radio,” Proc. ARRL/CRRL Amateur Radio ninth Computer Networking Conf., pp. 134-140, 1990.
J. Lutz, C.J. Colbourn, and V.R. Syrotiuk, “Apples and Oranges:
Comparing Schedule- and Contention-Based Medium Access
Control,” Proc. 13th ACM Int’l Conf. Modeling, Analysis, and
Simulation of Wireless and Mobile Systems (MSWiM), pp. 319-326,
2010.

1612

IEEE TRANSACTIONS ON MOBILE COMPUTING,

[20] T. Nandagopal, T.-E. Kim, X. Gao, and V. Bharghavan, “Achieving
MAC Layer Fairness in Wireless Packet Networks,” Proc. ACM
MobiCom, pp. 87-98, 2000.
[21] The Network Simulator ns-2, http://www.isi.edu/nsnam/ns/,
2013.
[22] M. Pióro and D. Medhi, Routing, Flow, and Capacity Design in
Communication and Computer Networks. Elsevier, 2004.
[23] R. Rozovsky and P.R. Kumar, “SEEDEX: A MAC Protocol for
Ad Hoc Networks,” Proc. ACM MobiHoc, pp. 67-75, 2001.
[24] J.L. Sobrinho and A.S. Krishnakumar, “Distributed Multiple
Access Procedures to Provide Voice Communications over IEEE
802.11 Wireless Networks,” Proc. Global Telecomm. Conf. (GlobeCom), vol. 3, pp. 1689-1694, 1996.
[25] V.R. Syrotiuk, C.J. Colbourn, and S. Yellamraju, “Rateless Forward
Error Correction for Topology-Transparent Scheduling,” IEEE/
ACM Trans. Networking, vol. 16, no. 2, pp. 464-472, Apr. 2008.
[26] F. Talucci, M. Gerla, and L. Fratta, “MACA-BI (MACA by
Invitation) - A Receiver Oriented Access Protocol for Wireless
Multihop Networks,” Proc. IEEE Int’l Conf. Universal Personal
Comm. (ICUPC), vol. 2, pp. 913-917, 1997.
[27] A.S. Tanenbaum and D.J. Wetherall, Computer Networks. Prentice
Hall, 2003.
[28] Z. Tang and J. Garcia-Luna-Aceves, “A Protocol for TopologyDependent Transmission Scheduling in Wireless Networks,” Proc.
IEEE Wireless Comm. and Networking Conf. (WCNC), pp. 1333-1337,
1999.
[29] L. Tassiulas and S. Sarkar, “Maxmin Fair Scheduling in Wireless
Networks,” Proc. IEEE INFOCOM, pp. 763-772, 2002.
[30] X. Wang and K. Kar, “Distributed Algorithms for Max-Min Fair
Rate Allocation in ALOHA Networks,” Proc. 42nd Ann. Allerton
Conf. Comm., Control, and Computing, 2004.
[31] X. Wang, K. Kar, and J.-S. Pang, “Lexicographic Max-Min Fairness
in a Wireless Ad Hoc Network with Random Access,” Proc. IEEE
Conf. Decision and Control (CDC), pp. 1284-1300, 2006.
[32] C. Zhu and M.S. Corson, “A Five-Phase Reservation Protocol
(FPRP) for Mobile Ad Hoc Networks,” Wireless Networks, vol. 7,
no. 4, pp. 371-384, 2001.

VOL. 12,

NO. 8,

AUGUST 2013

Jonathan Lutz received the BS degree in
electrical engineering from Arizona State University, Tempe, in 2000 and the MS degree in
computer engineering from the University of
Waterloo, Canada, in 2003. He is currently
working toward the PhD degree in computer
science at Arizona State University. His research interests include medium access control
in mobile ad hoc networks.

Charles J. Colbourn received the PhD degree
from the University of Toronto, Ontario, Canada,
in 1980. He is a professor of computer science
and engineering at Arizona State University,
Tempe. He is the author of The Combinatorics of
Network Reliability (Oxford), Triple Systems
(Oxford), and 320 refereed journal papers
focussing on combinatorial designs and graphs
with applications in networking, computing, and
communications. In 2004, he was awarded the
Euler Medal for Lifetime Research Achievement by the Institute for
Combinatorics and its Applications.
Violet R. Syrotiuk received the PhD degree in
computer science from the University of Waterloo, Canada. She joined Arizona State University in 2002 and is an associate professor of
computer science and engineering. Her research has been supported by grants from the
US National Science Foundation, ONR, DSTO
(Australia), and contracts with LANL, Raytheon,
General Dynamics, and ATC. She serves on the
editorial boards of Computer Networks, Computer Communications, and the International Journal of Communication
Systems, as well as on the technical program and organizing
committees of several major conferences sponsored by ACM and IEEE.

. For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

2012 IEEE International Conference on Multimedia and Expo Workshops

Minimizing Video Retransmission Delay and Energy Consumption with Caching
Routers
Michael P. McGarry∗ , Jesus Hernandez∗ , Rony Ferzli† and Violet R. Syrotiuk‡
∗ Dept. of Electrical and Computer Engineering
University of Texas at El Paso, El Paso, TX 79968
Email: mpmcgarry@utep.edu
† Uniﬁed Communications Group
Microsoft, Redmond, WA 98052
Email: rferzli@ieee.org
‡ School of Computing, Informatics, and Decision Systems Engineering
Arizona State University, Tempe, AZ 85287-8809
Email: syrotiuk@asu.edu

bandwidth constrained wireless networks. The small endto-end delay requirement of real-time video suggests that
ARQ (i.e., retransmissions) may not be appropriate for realtime video in wired or wireless networks. In loss prone
wireless networks error concealment [8], [9] techniques
may be insufﬁcient to maintain acceptable levels of video
quality. Further, error propagation due to frame dependencies
magniﬁes the effect of the lost information [10]. Thereby,
making it even more difﬁcult for error concealment to be
an effective error recovery mechanism. Wireless networks
provide the most compelling case for the use of error
recovery but wired networks would also beneﬁt signiﬁcantly
by the use of error recovery. We wish to make it clear that
a holistic error recovery strategy for video will likely take
the form of Unequal Error Protection (UEP) that will apply
FEC, ARQ, and error concealment differently for the various
video frame types. In this work we reduce the delay expense
of ARQ by means of caching; thereby making ARQ a
more attractive error recovery mechanism for delay sensitive
video.
An important consideration in wireless networks is often
energy consumption due to the use of battery power sources.
FEC consumes additional energy due to a larger transmitted workload. ARQ consumes additional energy through
repeated transmissions. In energy constrained wireless networks, it is highly desirable to utilize energy sensitive error
recovery mechanisms. Again, wireless networks provide the
most compelling case for energy sensitive error recovery but
wired networks would also beneﬁt signiﬁcantly. In this work
we reduce the energy expense of ARQ by means of caching.
Caching video packets at intermediary routers has formerly been proposed in the literature to reduce retransmission delay to make retransmission requests feasible for real
time video [11], [12], [13], [14], [15]. When packets containing video are lost in the network, retransmission requests can
be serviced by intermediary caching routers rather than the

Abstract—We investigated the use of caching of packets
containing video at intermediary routers to reduce the delay
and energy consumption of Automatic Repeat reQuest (ARQ)
error recovery. We modeled the two mathematical programs
that select the optimal set of routers to have caching ability,
one to minimize energy consumption and the other to minimize
retransmission delay. Both of these mathematical programs
have identical structure. We then solve these mathematical programs with a dynamic programming solution whose execution
time growth is polynomial in the size of the input parameters.
Our performance analysis indicates that the optimal solution
signiﬁcantly outperforms several heuristic solutions.
Keywords-Multimedia networking; Caching; Retransmission
delay; Combinatorial optimization; Dynamic programming;

I. I NTRODUCTION
Video is projected to represent a very signiﬁcant majority
of communication trafﬁc in packet switched networks in
the very near future [1]. The continued success of packet
switched networks will be determined by their ability to
provide video information transfer that meets requirements
for timely playback and low information loss.
Small end-to-end delays [2] are a strict requirement for
video information that will be consumed in real time. Additionally, low loss is required for high playback quality at the
receiver. Error recovery can be used to mitigate the effects of
information loss. However, error recovery mechanisms are
used at the expense of:
∙ increased bandwidth consumption for Forward Error
Correction (FEC) [3], [4], [5]
∙ increased delay for Automatic Repeat reQuest
(ARQ) [5]
∙ decreased visual quality for Error Concealment [6], [3],
[7]
FEC can have a signiﬁcant impact toward reducing information loss in loss prone wireless networks. However,
this comes at the expense of increased bandwidth in already
978-0-7695-4729-9/12 $26.00 © 2012 IEEE
DOI 10.1109/ICMEW.2012.25

101

and 𝛾𝑖 be the probability a packet is dropped at router 𝑖. With
independent 𝜌𝑖 random variables,
{ 𝑖−1
}
∩
∩
{𝜌𝑘 = 0} {𝜌𝑖 = 1}
(1)
𝛾𝑖 = 𝑃 𝑟𝑜𝑏

source node, thereby reducing the retransmission delay and
retransmission distance (and therefore energy consumption).
In this article, we investigate the use of routers with
caching ability to reduce the delay and energy consumption of ARQ (i.e., retransmissions) for video. Speciﬁcally,
we formulate mathematical programs to minimize average
retransmission delay and average energy consumption. We
ﬁnd a single dynamic programming solution that solves both
mathematical programs.

𝑘=1

becomes,
𝛾𝑖 =

[ 𝑖−1
∏

]
(1 − Φ𝑘 ) Φ𝑖

(2)

𝑘=1

A. Related Work

C. Average Retransmission Delay

The idea of caching packets containing video was ﬁrst
proposed in [11], [12]. The authors developed a model that
represents the video quality improvements gained through
caching [11]. Additionally, the authors investigated the optimal selection of packets to cache w.r.t. distortion minimization. This optimization problem is complementary to our
investigation of the optimal placement of caching routers.
Details of how packets can be cached inside routers
including a new protocol layer above the network layer can
be found in [13], [14]. Peer assisted retransmission in an
IPTV network was explored in [15]. The optimal placement
of caching routers was not discussed in this literature.
Many authors have investigated the optimal selection of
videos to be cached at web caches to minimize network
bandwidth usage and minimize packet delay [16], [17], [18],
[19]. The caching of entire videos at web caches is only
applicable to pre-recorded video and aims to shorten the
path of the video through the network. This path shortening
is complementary to caching packets containing video at
intermediate routers to minimize average retransmission
delay and retransmission distance.

Our analysis of retransmission delay applies to both wired
and wireless networks. Let 𝑑𝑖 be the retransmission delay for
a packet when it is dropped at router 𝑖, 𝔼𝑑 be the average
retransmission delay, 𝜂𝑖 be a binary variable that is 1 if
router 𝑖 has caching abilities and 0 if router 𝑖 does not have
caching abilities, and 𝛽𝑖 be the upstream caching router that
would be able to retransmit a packet that was dropped at
router 𝑖 and is closest to the destination. 𝑑𝑖 depends on the
round trip delay to the nearest upstream caching router, 𝛽𝑖 .
A router 𝑗 has caching capability if 𝜂𝑗 = 1 and is upstream
from router 𝑖 if 𝑗 < 𝑖. Therefore,
𝛽𝑖 = max{𝑗 : 𝑗 < 𝑖, 𝜂𝑗 = 1}

(3)

If we assume symmetric packet transmission delays and
only consider single retransmissions, then
𝑑𝑖 = 2 ⋅

𝑀
∑

𝜏𝑘

(4)

𝑘=𝛽𝑖

Using the expectation of a discrete random variable, we
obtain

II. O PTIMAL C ACHING ROUTER P LACEMENT
A. Network Structure
We analyze a path of a stream of video packets from
its source through several routers (wired or wireless) to its
destination representing a typical path of video through an
existing network. Due to a static caching router placement,
we use typical packet loss rates and average delays. Let 𝑀
be the total number of routers in the path of a video stream,
𝑁 be the number of routers with packet caching ability, 𝜏𝑖 be
the average packet transmission delay (including queueing,
transmission, propagation, and processing delays) between
router 𝑖 and router 𝑖 + 1, router 0 is the video trafﬁc source,
and 𝑥𝑖 be the distance between router 𝑖 and router 𝑖 + 1.
Figure 1 illustrates a video stream path through eight routers
with caching enabled at routers 3 and 6.

𝔼𝑑 =

𝑀
∑

(𝑑𝑖 𝛾𝑖 )

(5)

𝑖=1

D. Average Energy Consumption
Our analysis of energy consumption applies to wireless
networks. Let 𝐸𝑖 be the energy consumed transmitting one
bit from router 𝑖 to router 𝑖 + 1, 𝑒𝑖 be the energy consumed
for a retransmission of a bit of a packet that was dropped
at router 𝑖, and 𝔼𝑒 be the average energy consumption of a
retransmitted bit.
𝐸𝑖 is composed of two parts [20]: 𝑒𝑐𝑖𝑟𝑐 , the energy consumed by one bit in the electronic circuitry of a transmitter
or receiver and has the units Joules/bit, and 𝑒𝑎𝑚𝑝 , the energy
consumed by one bit in the ampliﬁer of a transmitter and
has the units Joules/bit/𝑚2 . For our analysis, both 𝑒𝑐𝑖𝑟𝑐 , and
𝑒𝑎𝑚𝑝 can be considered arbitrary constants. For transmission
in free space the energy used to transmit a bit at the near
end transmitter and receive that bit at the far end receiver
is [20]:

B. Loss/Error Probability
Let 𝜌𝑖 be a binary random variable that is 1 when a packet
is dropped at router 𝑖 due to congestion or it being received
severely errored and 0 otherwise, Φ𝑖 be the probability that
𝜌𝑖 = 1 (𝑃 𝑟𝑜𝑏{𝜌𝑖 = 1} = Φ𝑖 and 𝑃 𝑟𝑜𝑏{𝜌𝑖 = 0} = (1−Φ𝑖 )),

102

C

C

Video
Source

Video
Sink

R1

R2

R3

τ1

τ0

τ2

R4
τ3

R5
τ4

R6
τ5

R7

R8

τ6

τ7

τ8

Figure 1. Illustration of a network path with video packet caching routers. There are eight routers (i.e., 𝑀 = 8) in the illustrated path. Two routers, 3
and 6, have packet caching abilities (i.e., 𝑁 = 2).

𝐸𝑖 = 2𝑒𝑐𝑖𝑟𝑐 + 𝑥2𝑖 𝑒𝑎𝑚𝑝

since 𝐸𝑖 only depends on the square of the distance between
router 𝑖 and 𝑖 − 1, minimizing 𝑥𝑖 will also minimize 𝑥2𝑖 .
Taking advantage of this and ignoring constants, 𝐸𝑖 can be
replaced by 𝑥𝑖 so that 𝑒𝑖 becomes,

(6)

Accounting for the round trip transmission, 𝑒𝑖 is:
𝑒𝑖 = 2 ⋅

𝑀
∑

𝐸𝑘

(7)

𝑒𝑖 = 2 ⋅

𝑘=𝛽𝑖

𝔼𝑒 =

(𝑒𝑖 𝛾𝑖 )

(9)

𝑖=1

𝑓𝑒 (𝜼) = 𝔼𝑒/2 =

E. Minimizing Average Retransmission Delay and Average
Energy Consumption

𝑓 (𝜼) =

𝑀
∑
𝑖=1

subject to

𝑀
∑

𝜏𝑘

⎝⎝

𝑀
∑

⎞

⎞

𝑥 𝑘 ⎠ 𝛾𝑖 ⎠

(13)

𝑘=𝛽𝑖

F. Alternative Mathematical Programs
The problem, as stated, is the minimization of the retransmission delay incurred under the caching scheme. In the
following claim, we write the mathematical program in two
alternative forms, both of which maximize the time saved
as compared to the delay without caching.
∑𝑗−1
Claim 1. Deﬁne 𝒯𝑗 =
𝑘=0 𝜏𝑘 . Then the mathematical
program in Eq. (11) and either of the following two mathematical programs are equivalent.

𝑘=𝛽𝑖

𝛾𝑖

⎛⎛

Looking at Eqs. (10) and (13) it is clear that a solution
method for one will work for the other. Going forward
we only consider the problem of minimizing the average
retransmission delay.

The mathematical program with constraints is,

minimize

𝑀
∑
𝑖=1

The decision variables are the 𝜂𝑖 , 𝑖 = 1 . . . 𝑀 . The
constraints are that the decision variables are binary and the
number of caching routers is ﬁxed to 𝑁 . Our ﬁrst objective
is to minimize the average retransmission delay.
We use Eq. (5) to derive our retransmission delay objective function as,
⎛⎛
⎞ ⎞
𝑀
𝑀
∑
∑
⎝⎝
(10)
𝜏𝑘 ⎠ 𝛾𝑖 ⎠
𝑓 (𝜼) = 𝔼𝑑/2 =
𝑖=1

(12)

This equation is identical in form to Eq. (4) whereby the
delay between routers is replaced by the distance between
the routers. If we do not consider average transmission
and average queueing delays then these values are directly
related.

𝑖=1
𝑀
∑

𝑥𝑘

𝑘=𝛽𝑖

Using the expectation of a discrete random variable, we
obtain
)
(
𝑀
𝑀
∑
∑
(8)
(𝑒𝑖 𝛾𝑖 ) + 0 1 −
𝛾𝑖
𝔼𝑒 =
𝑖=1

𝑀
∑

(11)

𝑘=𝛽𝑖

𝜂𝑗 ∈ {0, 1}, 𝑗 = 1, ⋅ ⋅ ⋅ , 𝑀
∑𝑀
𝜂𝑗 = 𝑁

maximize

𝑗=1

subject to

The mathematical program above is a binary integer
program (BIP) with a non-linear objective function. A BIP
is NP-hard in general [21]. However, certain types of BIPs
can be solved optimally with polynomial time algorithms;
an example is the assignment problem [21].
Our second objective is to minimize the average energy
consumption for retransmission. We use Eq. (9) to derive
our energy consumption objective function. We notice that

𝑀
∑

𝛾𝑖 max 𝒯𝑗 𝜂𝑗

(14)

𝑗<𝑖

𝑖=1

𝜂𝑗 ∈ {0, 1}, 𝑗 = 1, ⋅ ⋅ ⋅ , 𝑀
∑𝑀
𝜂𝑗 = 𝑁
𝑗=1

maximize
subject to

103

𝑁
∑
𝑘=1

(

)

𝑖𝑘+1

∑

𝑖=𝑖𝑘 +1

𝛾𝑖

𝒯𝑖𝑘

1 ≤ 𝑖1 < ⋅ ⋅ ⋅ < 𝑖𝑁 < 𝑖𝑁 +1 ≡ 𝑀

(15)

Proof: First let’s prove the claim for (14). Denote the
original objective function to minimize 𝑓 (𝜼), that is:
𝑓 (𝜼) =

𝑀
∑
𝑖=1

𝛾𝑖

𝑀
∑

follow, take the domain of deﬁnition to be implicitly given
by the range of its arguments.
As 𝑘 varies from 1 to 𝑁 , construct the following forward
recursion:
)
( 𝑖𝑘+1
∑
𝛾𝑖 𝒯𝑖𝑘 .
𝐽𝑘 (𝑖𝑘 , 𝑖𝑘+1 ) = max 𝐽𝑘−1 (𝑖𝑘−1 , 𝑖𝑘 ) +

𝜏𝑘 .

𝑘=𝛽𝑖

𝑖𝑘−1

Minimizing 𝑓 (𝜼) is equivalent to maximizing 𝑔(𝜼), deﬁned as follows:
𝑔(𝜼) =

𝑀
∑
𝑖=1

𝛾𝑖

𝑀
∑

𝜏𝑘 − 𝑓 (𝜼) =

𝑘=0

𝑀
∑
𝑖=1

𝛾𝑖

𝛽∑
𝑖 −1

(16)
Then 𝐽 ★ = max𝑖𝑁 𝐽𝑁 (𝑖𝑁 , 𝑖𝑁 +1 ) is the optimal value of
(14) and (15). Furthermore, the optimal choice of 𝑖1 , ⋅ ⋅ ⋅ , 𝑖𝑁
can be obtained using the following backward recursion,
with 𝑖★𝑁 +1 = 𝑀 :

𝜏𝑘 .

𝑘=0

Recall that 𝛽𝑖 = max{𝑗 : 𝑗 < 𝑖, 𝜂𝑗 = 1}. Therefore, we
can write the following:
𝛽∑
𝑖 −1

𝑖★𝑘 = arg max 𝐽𝑘 (𝑖𝑘 , 𝑖★𝑘+1 ).
𝑖𝑘

Proof: The claim is a straightforward dynamic programming decomposition of (15), using the separation property
that given a speciﬁc placement of 𝑖𝑘 , the sub-problem of
optimizing the placements of 𝑖1 ⋅ ⋅ ⋅ , 𝑖𝑘−1 is independent of
𝑖𝑘+1 , ⋅ ⋅ ⋅ , 𝑖𝑁 .
In particular 𝐽𝑘 (𝑖𝑘 , 𝑖𝑘+1 ) represents the contribution to
the objective function due to the optimal placement of
𝑖1 ⋅ ⋅ ⋅ , 𝑖𝑘−1 , given the speciﬁc placement of 𝑖𝑘 , in addition
to the contribution due to 𝑖𝑘 , given the placement of 𝑖𝑘+1 .
Using separation, we obtain the recursive construction in
(16).
The ﬁrst step of the recursion factors in only the contribution of 𝑖1 given the placement of 𝑖2 . The second step of
the recursion then optimizes 𝑖1 for each choice of 𝑖2 , and
adds to it the contribution of 𝑖2 for each choice of 𝑖3 , and so
on. 𝐽 ★ is the optimal value because it represents the optimal
placement of all of 𝑖1 , ⋅ ⋅ ⋅ , 𝑖𝑁 , which can then be recovered
by tracing backward all the choices made in the forward
recursion.
Finally, we elucidate that the range of variation of each
𝑖𝑘 is between 𝑘 and 𝑀 − 𝑁 + 𝑘 − 1, because of the strict
inequalities in the constraints of (15), forcing at least 𝑘 −
1 positions before 𝑖𝑘 , and 𝑁 − 𝑘 positions after 𝑖𝑘 , to be
occupied.

𝜏𝑘 = 𝒯𝛽𝑖 = 𝒯max{𝑗:𝑗<𝑖,𝜂𝑗 =1} = max 𝒯𝑗 𝜂𝑗 ,

𝑘=0

𝑖=𝑖𝑘 +1

𝑗<𝑖

where the last substitution follows from the fact that 𝒯𝑗 is
non-decreasing in 𝑗, and therefore the largest value of 𝒯𝑗 𝜂𝑗
is precisely at the last 𝑗 where 𝜂𝑗 = 1. The substitution of
this expression in that of 𝑔(𝜼) establishes (14).
To derive (15), identify 𝑖1 , ⋅ ⋅ ⋅ , 𝑖𝑁 as exactly the points
𝑖 where 𝜂𝑖 = 1. Note that 𝑔(𝜼) quantizes 𝒯 into 𝑁
distinct values: 𝒯𝑖1 , ⋅ ⋅ ⋅ , 𝒯𝑖𝑁 , to each of which it associates
the values of 𝛾𝑖 with 𝑖 ranging respectively in {𝑖1 +
1, ⋅ ⋅ ⋅ , 𝑖2 }, ⋅ ⋅ ⋅ , {𝑖𝑁 + 1, ⋅ ⋅ ⋅ , 𝑀 }. Therefore the objective
function of (15) is the same as that of (14), and since this
association between 𝜼 and (𝑖1 , ⋅ ⋅ ⋅ , 𝑖𝑁 ) is a bijection, the
two mathematical programs are equivalent.
It is worth noting that 𝑖𝑁 = 𝑀 is never part of the
solution, because 𝜂𝑀 never appears in the objective function.
Concretely, this is because in our model the video sink never
drops packets, and therefore there’s no point in caching at
router 𝑀 .
G. Dynamic Programming Solution
We now desire to solve these optimization problems. The
brute force approach would enumerate all feasible choices of
𝜂1 , ⋅ ⋅ ⋅ , 𝜂𝑀 or 𝑖1 , ⋅ ⋅ ⋅ , 𝑖𝑁 , and becomes intractable as either
𝑀 or 𝑁 grows. One is then tempted to relax the problem,
by letting 𝜂𝑗 ∈ [0, 1] (i.e., linear programming relaxation).
In this case, observe that the objective function is convex,
and therefore the problem reduces to the maximization of
a convex function over a convex set, with solutions on the
boundary of the feasible set. This is a global optimization
problem, and can also be intractable in general. However,
our problem falls into a tractable class. In particular, the
following dynamic programming algorithm ﬁnds the solution in time polynomial in both 𝑀 and 𝑁 .

III. P ERFORMANCE A NALYSIS
We conducted a numerical analysis to characterize the
performance of the optimal placement (i.e., best placement)
by comparing it to the worst placement, the average of all
placements, and several intuitive placements. Speciﬁcally,
we compare the best, worst and average placements to the
following intuitive (heuristic) placements: lumped upstream,
lumped downstream, spread uniformly.
We consider the following parameter settings: 𝑀 =
{8, 16}, Φ = {0.01, 0.1, 0.2}, The delay parameters were
set to model a network in which there is no particular
congestion point so the delay is dominated primarily by the
propagation delay (i.e., dependent on distance). Further, the
path is characterized by short hops on the edges with much
larger hops in the core.

Claim 2. For each 𝑘 = 1, ⋅ ⋅ ⋅ , 𝑁 , let 𝑖𝑘 vary from 𝑘 to
𝑀 − 𝑁 + 𝑘 − 1, and let 𝑖𝑁 +1 ≡ 𝑀 . Deﬁne 𝐽0 to be a
function that is identically zero, and use the convention that
an empty sum evaluates to zero. For each of the functions to

104

Figure 2 shows the average retransmission delay for each
of the caching router placements for each combination of 𝑀
and Φ. The 𝑀 parameter is varied horizontally and the Φ
parameter is varied vertically among the subplots in Figure
2.
With sixteen total routers, two caching routers, and 1%
packet drop probabilities at each router, the difference
between the best placement of caching routers reduces
the average retransmission delay by 50% compared to the
worst placement. The best performing heuristic is uniform
placement. The best placement reduces the delay by 10
% compared to the uniform placement heuristic. The best
placement reduces the average retransmission delay 16
% compared to the average over all possible placements.
Clearly, the best placement results in signiﬁcantly smaller
average retransmission delay than the heuristics.
As the drop probabilities increases to 80 %, we can see
in Figure 2 that, the lumped upstream heuristic matches the
best placement. With very high independent packet drop
probabilities, Φ, the probability that a packet is dropped at
a router very close to the source is very high. As a result,
lumping the caching routers upstream will provide the best
solution.

54

worst placement
lumped downstream
lumped upstream
uniform
average arbitrary
best placement

52

delay (microseconds)

50

48

46

44

42

40

38

36
2

2.5

3.5

4

4.5

5

5.5

6

6.5

7

number of caching routers, N

a) Φ = 0.01
400
worst placement
lumped downstream
lumped upstream
uniform
average arbitrary
best placement

delay (microseconds)

380

360

340

320

300

IV. C ONCLUSION

2

We have investigated the use of caching of packets containing video at intermediary routers to reduce the delay and
energy consumption of Automatic Repeat reQuest (ARQ)
error recovery. We modeled the two mathematical programs
that select the optimal set of routers to have caching ability,
one to minimize energy consumption and the other to
minimize retransmission delay. Both of these mathematical
programs have identical structure. We then solve these mathematical programs with a dynamic programming solution
whose execution time growth is polynomial in the size of
the input parameters.
Our performance analysis illustrates that the optimal
caching router placement signiﬁcantly outperforms several
heuristic solution. An avenue for future work is to analyze
multicast video and a joint optimization of multiple paths of
video.

2.5

3

3.5

4

4.5

5

5.5

6

6.5

7

number of caching routers, N

b) Φ = 0.1
worst placement
lumped downstream
lumped upstream
uniform
average arbitrary
best placement

719.5

delay (microseconds)

719
718.5
718
717.5
717
716.5
716
715.5
715
2

2.5

3

3.5

4

4.5

5

5.5

6

6.5

7

number of caching routers, N

c) Φ = 0.8
Figure 2. Average retransmission delay for 𝑀 = 8 with a delay pattern
of 10 times larger delay in the core than the edge.

R EFERENCES
[1] Cisco, “Approaching the zettabyte era,”
Networking Index, 2008.

3

Cisco Visual
[4] S.H. Chan, X. Zheng, Q. Zhang, W. Zhu, and Y.Q. Zhang,
“Video Loss Recovery with FEC and Stream Replication,”
IEEE Transactions on Multimedia, vol. 8, no. 2, pp. 370–
381, April 2006.

[2] L. Zhou, H.C. Chao, and A.V. Vasilakos, “Joint forensicsscheduling strategy for delay-sensitive multimedia applications over heterogeneous networks,” IEEE Journal on Selected Areas in Communications, vol. 29, no. 7, pp. 1358–
1367, July 2011.

[5] I.V. Bajic, “Efﬁcient cross-layer error control for wireless
video multicast,” IEEE Transactions on Broadcasting, vol.
53, no. 1, pp. 276–285, Mar 2007.

[3] Y. Wang, J. Ostermann, and Y.Q. Zhang, Video Processing
and Communications, Prentice Hall, 2001.

[6] Y. Wang and Q.F. Zhu, “Error control and concealment for

105

220

delay (microseconds)

Cross-layer Optimized Wireless Multimedia Communications,
Hindawi Publishing, 2007.

worst placement
lumped downstream
lumped upstream
uniform
average arbitrary
best placement

230

[9] J. Huang, Z. Li, M. Chiang, and A.K. Katsaggelos, “Joint
Source Adaptation and Resource Pricing for Multi-User Wireless Video Streaming,” IEEE Transactions on Circuits and
Systems for Video Technology, vol. 18, no. 5, pp. 582–595,
May 2008.

210

200

190

180

170

[10] P. Seeling, M. Reisslein, and B. Kulapala, “Network performance evaluation using frame size and quality traces of
single-layer and two-layer video: A tutorial,” IEEE Communications Surveys and Tutorials, vol. 6, no. 2, pp. 58 – 78,
Third Quarter 2004.

160

150

140
2

4

6

8

10

12

14

number of caching routers, N

[11] I. Bouazizi and M. Gunes, “Selective proxy caching for robust
video transmission over lossy networks,” in International
Conference on Information Technology: Research and Education (ITRE), August 2003, pp. 69–73.

a) Φ = 0.01
worst placement
lumped downstream
lumped upstream
uniform
average arbitrary
best placement

delay (microseconds)

1250

[12] I. Bouazizi, “Size-distortion optimized proxy caching for
robust transmission of mpeg-4 video,” in International
Workshop on Multimedia Interactive Protocols and Systems,
November 2003, number 2899, pp. 131–142.

1200

1150

1100

[13] T.P. Van, “Proactive adhoc nodes for real-time video,” in
IEEE Singapore International Conference on Communication
Systems (ICCS), October 2006, pp. 1–5.

1050

1000

2

4

6

8

10

12

[14] T.P. Van, “Efﬁcient relaying of video packets over wireless
ad hoc devices,” in IEEE Annual Wireless and Microwave
Technology Conference (WAMICON), December 2006, pp. 1–
5.

14

number of caching routers, N

b) Φ = 0.1
worst placement
lumped downstream
lumped upstream
uniform
average arbitrary
best placement

1599.5

delay (microseconds)

1599

[15] Z. Li, X. Zhu, A.C. Begen, and B. Girod, “Peer-assisted
packet loss repair for iptv video multicast,” in ACM International Conference on Multimedia, October 2009, pp. 401–410.

1598.5

[16] Z. Miao and A. Ortega, “Proxy caching for efﬁcient video
services over the internet,” in International Packet Video
Workshop (PVW ’99), April 1999.

1598

1597.5

1597

[17] R. Rejaie, H. Yu, M. Handley, and D. Estrin, “Multimedia
proxy caching mechanism for quality adaptive streaming
applications in the internet,” in IEEE INFOCOM, March
2000, vol. 2, pp. 980–989.

1596.5

1596

1595.5

1595
2

4

6

8

10

12

[18] F. Yu, Q. Zhang, W. Zhu, and Y.Q. Zhang, “Qos-adaptive
proxy caching for multimedia streaming over the internet,”
IEEE Transactions on Circuit and System for Video Technology, vol. 13, no. 3, pp. 257 – 269, March 2003.

14

number of caching routers, N

c) Φ = 0.8
Figure 3. Average retransmission delay for 𝑀 = 16 with a delay pattern
of 10 times larger delay in the core than the edge.

[19] Q. Zhang, Z. Xiang, W. Zhu, and L. Gao, “Cost-based cache
replacement and server selection for multimedia proxy across
wireless internet,” IEEE Transactions on Multimedia, vol. 6,
no. 4, pp. 587 – 598, August 2004.

video communication: A review,” Proceedings of the IEEE,
vol. 86, no. 5, pp. 974–997, May 1998.

[20] X. Zhang and N.F. Maxemchuk, “A generalized energy
consumption analysis in multihop wireless networks,” 2004
IEEE Wireless Communications and Networking Conference
(WCNC), vol. 3, no. 1, pp. 1476–1481, March 2004.

[7] Q. Ma, F. Wu, and M.T. Sun, “Error concealment for
spatially scalable video coding using hallucination,” in IEEE
International Symposium on Circuits and Systems (ISCAS),
May 2009, pp. 129–132.

[21] C.H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algorithms and Complexity, Prentice Hall, 1998.

[8] H. Wang, J. Huang, M. Van der Schaar, D.O. Wu, and Z. Han,

106

IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 53, NO. 8, AUGUST 2007

2791

Ternary Schedules for Energy-Limited
Sensor Networks
Peter J. Dukes, Violet R. Syrotiuk, Member, IEEE, and Charles J. Colbourn

Abstract—Medium access control for multihop wireless sensor
networks (WSNs) must be energy efficient because the battery-operated nodes are not practical to recharge. We give constructions
for ternary schedules in which each node is in one of three states:
transmitting, receiving, or asleep. For each hop (vi ; vj ), communication is effective only when vi is transmitting, vj is receiving,
and no other node in proximity of vj is also transmitting. Since
sensor nodes are prone to failure, the schedules should be independent of the detailed topology while supporting spatial reuse. We use
~ n into
arc-decompositions of the complete -fold directed graph K
~
directed complete bipartite subgraphs Ka;b as a model for ternary
~ n with the nodes
scheduling in WSNs. We associate the vertices of K
~ a;b s (blocks) in the decomposiof the WSN, and occurrences of K
tion with time slots in the schedule. A block with out-vertices A
and in-vertices B corresponds to a slot in which the a nodes in A
are transmitting, the b in B are receiving, and all others are asleep.
~ n guarantees that every ordered pair
Such a decomposition of K
of nodes in the WSN can communicate in  time slots.
Index Terms—Direct combinatorial constructions, ternary
schedules, wireless sensor networks.

I. INTRODUCTION

W

IRELESS sensor networks (WSNs) have emerged as an
important new class of computation that embeds computing in the physical world. Each sensor node is a microelectronic device with a limited power source. In some applications
it may not be possible to replenish the power, making the lifetime of a sensor node strongly dependent on the lifetime of
its battery. Furthermore, WSN architectures are multihop. This
means that each node is both a source of data and a router forwarding packets to the sink. Significant changes to the network
topology may occur because the nodes are prone to failure [1];
indeed, changes may also result from node mobility, or from
changes in environmental conditions. Each may require reorganization of the network to support its continued operation.
These individual and collective demands on power have driven
research on power-aware protocols for WSNs.
The medium access control (MAC) protocol is fundamental
in WSNs since it controls access to the communication reManuscript received November 24, 2004; revised September 8, 2006. The
work of C. J. Colbourn and V. R. Syrotiuk is supported, in part, by LANL
under Contract 13638-001 and the National Science Foundation (NSF) under
Grant ANI-0105985. Any opinions, findings, conclusions, or recommendations
expressed are those of the authors and do not necessarily reflect the views of
LANL or NSF.
P. J. Dukes is with the Department of Mathematics and Statistics, University
of Victoria, Victoria, BC V8W 3P4, Canada (e-mail: dukes@math.uvic.ca).
V. R. Syrotiuk and C. J. Colbourn are with the Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85287-8809 USA
(e-mail: syrotiuk@asu.edu; colbourn@asu.edu).
Communicated by G. Sasaki, Associate Editor for Communication Networks.
Digital Object Identifier 10.1109/TIT.2007.901156

sources—the shared radio broadcast channel. While a sensor
node consumes power in sensing, communication, and data
processing, most of its energy is expended in data communication [1]. Consider the commonly used Mica2 sensor node.
It draws 27 mA to transmit at maximum power, 10 mA to
receive, and less than 1 A to sleep [2]. Listening is expensive!
This proportion of power usage, typical of wireless nodes [3],
creates unique challenges for power-aware MAC protocols.
In some contention-based MAC protocols for WSNs, such
as sensor-MAC (S-MAC) [4], a node puts itself to sleep to
avoid overhearing a packet for which it is not the destination.
Such protocols also use low-power listening (essentially, carrier
sensing) and may suffer from packet collisions, both of which
appear to use higher energy consumption than reservation or
scheduling [3]. These observations argue that scheduling sleep
has the potential to reduce energy consumption.
One class of schemes to design schedules in WSNs uses information about the network topology. In the TRaffic Adaptive
Medium Access (TRAMA) protocol [6], time is organized into
random- and scheduled-access periods. Neighbor and schedule
information are exchanged in the random-access period in order
to compute a conflict-free schedule among nodes in a two-hop
neighborhood. Information about traffic is also exchanged and
used to put nodes to sleep. The performance of such topologydependent scheduling depends not only on how often the
schedule is recomputed, but also on the length of the randomaccess period. Significant overhead is incurred in the information
exchange not to mention that this period runs in contention mode.
Another class of schemes to design schedules is independent of the detailed network topology. Such topology-transparent schedules were introduced for mobile ad hoc networks
(MANETs) in [7], [8] and generalized in [9]. These schedules
depend on two design parameters: the number of nodes in the
network and the maximum active node degree . A schedule for
node may be treated as a subset on
, where
is the number of slots. Now, each node is given a subset
with the property that the union of or fewer other subsets cannot
are
contain . Expressed mathematically, if
the schedules of neighbors of
, then we require that

This is precisely a cover-free family. These are equivalent to
disjunct matrices [10] and to certain superimposed codes [11];
see [12].
has
From the point of view of scheduling, if each node
guarantees a collision-free
at most neighbors its schedule
transmission to each neighbor. More importantly, this is true
regardless of which nodes are its neighbors. So even if the

0018-9448/$25.00 © 2007 IEEE

2792

IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 53, NO. 8, AUGUST 2007

topology changes, the schedules give a guarantee as long as
the degree constraint is met. The robustness of the delay and
the throughput of topology-transparent schedules to node mobility, degree constraints, and forms of synchronization has been
studied extensively in MANETs [9], [13].
In this paper, we extend topology-transparent scheduling on
two states (transmit and receive) to three states (adding sleep)
for WSNs. Indeed, the large number of nodes in WSNs allows
more flexibility in the schedule construction. In MANETs, one
method to handle large numbers of active neighbors is to control the topology (see, e.g., [14]). In WSNs, scheduling sleep
is a way to effect topology control, by selecting in each time
slot a subset of the nodes to participate. Thus, it is a means to
limit the number of active neighbors, and at least potentially enable topology-transparent schemes to function in a neighborhood that is too dense if all nodes are awake.
One representation of schedules of this type is afforded by representing each node schedule as a ternary codeword over the al. The requirement that each codeword contain
phabet
entries equal to , equal to , and equal to asks that the
set of codewords form a constant composition code. These have
been studied to maximize the Hamming distance between codewords (see, e.g., [15], [16]). In our application, the Hamming distance is not the one of interest; for example, there is no conflict
in having two nodes sleep in the same slot. By the same token,
the superimposed codes introduced by Kautz and Singleton [17]
form precisely the (binary) characteristic vectors of a cover-free
family (see [10]). Therefore, the ternary code we seek could be
viewed as a ternary analog of superimposed codes.
The rest of this paper is organized as follows. Section II provides assumptions underlying our WSN model and explains why
the combinatorial requirements change from a single covercover-free families for three
free family to a family of
node states. Rather than using the codes directly, in Section III
we pursue a graph-theoretic formulation for schedule design. We
use arc-decompositions of the complete -fold directed graph
into directed complete bipartite subgraphs
as a model
for ternary scheduling in WSNs. We associate the vertices of
with the nodes of the WSN, and occurrences of
s (blocks) in
the decomposition with time slots in the schedule. A block with
out-vertices and in-vertices corresponds to a slot in which
the nodes in are transmitting, the in are receiving, and
all others are asleep. In Section IV, we describe constructions of
-designs. Our direct construction techniques include addition sets, resolvable designs, and computation. While we provide
many examples of schedules with small , these can be used as
building blocks for larger parameters. Finally, in Section V, we
summarize our contribution and propose future work.
II. THE COMBINATORIAL REQUIREMENTS OF
TERNARY SCHEDULING
A. A Graph Model for a WSN
We model a WSN by a graph
where the vertex
set represents the sensor nodes, and the edge set represents
is the number of nodes in the
the communication links;
WSN.

Each node is equipped with an omnidirectional antenna with
its transmission range modeled by a circle of radius . There
if the distance separating the nodes is
is an edge
within the transmission range, i.e., if
. If is
adjacent to then is a (one-hop) neighbor of . The degree
of a vertex corresponds to its neighborhood size. The
. The
maximum node degree of a WSN is
active neighborhood—those neighbors with at least one packet
queued for transmission—is bounded above by .
The transceiver at each node is half-duplex; it is impossible
to both transmit and receive at the same time. This introduces
problems such as the well-studied hidden terminal problem
[18]. Two or more overlapping transmissions to a receiver result
in a collision with none of the overlapping packets correctly
received.
We assume that time is divided into discrete units called slots.
Each node in the network is assigned a unique schedule that it
uses in a cyclically repeated way. The nodes are synchronized
on frame boundaries.
B. The Combinatorial Requirements
Let the nodes of the network be
. Let the time
. For each time slot in , a
slots be denoted by
slot schedule is to be determined. A slot schedule is represented
of . In plain terms, nodes in can
as a partition
transmit, nodes in are eligible to receive, and the remaining
nodes in are in a sleep state. A frame schedule is a set of slot
schedules. By a frame, we mean one pass through the frame
, where
schedule. Consider a frame schedule
is a slot schedule. Table I
for
gives an example of a frame schedule for 13 nodes. Rows indicate the schedule for each node, while columns indicate the state
within each time slot. In this example, the length of the frame
schedule also happens to be . In
and
.
We now consider when a frame schedule provides guarantees
of transmission opportunities. Given a frame schedule and an
, define
ordered pair of distinct nodes
and
. For
, let
denote the family
(multiset) of sets
.
contains those slots
in which node
In words,
can transmit and node can receive. For a given node
is a
collection that contains, for each node other than , the set of slots
in which this node can transmit and can receive. For Table I

Here,
contains the sets
and
, three times
each.
Suppose that a packet is to be sent from node 12 to node 5
in one hop. In the small frame schedule of Table I, there is a
in which that packet exchange can
unique slot
happen (marked in boxes). Nevertheless it can only happen if
nodes 12 and 5 are neighbors, and the other transmitters in ,
nodes 3 and 8, are not active neighbors of the receiver. So in

DUKES et al.: TERNARY SCHEDULES FOR ENERGY-LIMITED SENSOR NETWORKS

2793

TABLE I
EXAMPLE FRAME SCHEDULE

Fig. 2. Using the frame schedule with designed d = 1 in Table I nevertheless
allows successful transmissions in this dense topology.

Fig. 1. Possible/impossible (solid/dashed) transmissions in slot j .

this example,
. This example is purely for purposes of
illustration; we treat more active neighbors than just one.
Evidently, a necessary condition for a transmitter to reach
be nonempty; that is, there
a particular receiver is that
exists some time slot in which is scheduled to transmit and
is scheduled to receive. However, the set of nodes
is also transmitting in time slot . So may fail to receive the
transmission correctly if a node in is within its range. Indeed,
we require that in some slot with receiving, the only transmitting node within range is . Fig. 1 shows these conditions
pictorially. Our environment is topology transparent, and hence,
without further assumptions the only solution is to have a single
transmitter active in each slot.
Although the neighborhoods are dynamic, suppose that they
remain unchanged during the course of a single frame. In addition, assume that every node has at most neighbors. With
these assumptions, we can ensure a successful transmission in
some frame between any pair of nodes provided that for all
and any
nodes

When there are no sleeping nodes,
for each , the requirement given is similar to the topology-transparent schedules
with two states [7]–[9]. To see this, suppose that nodes do not
sleep and consider a potential transmitter and receiver . Treat
the situation from the viewpoint of the receiver. It has at most
active neighbors, including . Hence, at most
other active
transmitters are within range, and therefore able to collide with
a packet from to . Despite this, the node must itself be eligible to receive; to ensure this it must be ineligible to transmit.
Node can receive a packet from node only if there is some
slot not included in the union of transmission slots assigned to
other potential transmitters or to itself. Thus,
any of the

when the sets of transmission slots assigned to all nodes form
a -cover-free family, the existence of a collision-free slot for
to receive from is ensured, for each choice of and .
When sleeping is permitted, this analysis from [9] is not sufficient. Indeed, if transmission opportunities are allocated using
a -cover-free family, we can find that the intended receiver is
sleeping when has a collision-free transmission opportunity.
In the simpler case, when all nodes are awake, node was ready
for reception except when transmitting, and we could therefore
treat simply as another potential transmitter in its own neighborhood. When nodes sleep, we must ensure that we restrict our
attention to slots in which can receive. To accommodate this,
to contain only those slots in
we restrict the members of
which is a receiver; hence, the intended receiver is excluded
as a possible transmitter, and we need only be concerned about
possible active neighbors other than the desired
at most
transmitter . Then it is required that for each , the family
forms a
-cover-free family of
.
The requirement that each receiver has an associated
cover-free family reduces, when nodes do not sleep, to the requirement that the set of all transmission opportunities form a
-cover-free family. To see this, when the transmission schedule
sets to form
of the receiver is incorporated in the union of
a union of sets, slots remain conflict-free exactly when the
intended receiver is prohibited from transmitting—and hence, in
this case, eligible to receive. When nodes can sleep, this eligibility
to receive therefore requires us to distinguish “receivers” from
nontransmitters, complicating to an extent the requirements.
In order to illustrate some of the ideas further, we provide another small example in Table II. This is a schedule for 17 nodes
with frame length ; in each slot, four nodes can transmit and
four nodes can receive. Rows give the status of a node in each slot,
columns give the status of all nodes in a specific slot. We have
marked in boxes the two opportunities for node 1 to receive from
node 10. Checking the status of other nodes in these two slots, we
find that no single transmitter can interfere with both slots; indeed
is a -cover-free family of
, the
slots in which node 1 can receive, so every node has a collision. We leave to the reader the
free slot to node 1 even when
verification that this holds for each node.
does not limit the network
To emphasize that small
sensor nodes. Here,
topology, consider Fig. 2 for
the maximum node degree is ; the average is . When the

2794

IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 53, NO. 8, AUGUST 2007

TABLE II
A SCHEDULE PERMITTING TWO ACTIVE NEIGHBORS

frame schedule in Table I is used in this WSN it yields spatial
reuse, even when all awake neighbors are active. For example,
and
recall that in
. In slot schedule , three transmissions
are successful: from node 1 to node 13, from 5 to node 12, and
from node 9 to node 11. Indeed, in all but one slot schedule
there is at least one successful transmission despite a designed
for this small frame schedule. The number
maximum of
for this
of successful transmissions per slot on average is
WSN topology.
III. A GRAPH-THEORETIC MODEL FOR TERNARY SCHEDULES
Here, we propose a model for designing frame schedules
be an -set representing sensor
using directed graphs. Let
. An arc (directed edge) from to
nodes, and let
indicates an opportunity for node to transmit and node
to receive. Now consider one slot schedule
within a
frame schedule. This slot schedule is associated with a directed
graph having an arc from every node in to every node in .
Our goal is to select such directed bipartite graphs to form a
frame schedule. A natural requirement for the frame schedule is
that every arc (transmission opportunity) appear equally often,
say times.
denote the directed graph with vertex set
Let
, having every possible directed arc times. This graph has
arcs. Let
be the directed complete bipartite graph
with
in which the vertex set is a disjoint union
and
, and an arc is directed from each vertex of to
each vertex of . The vertices in and are out-vertices and
of
in-vertices, respectively. A particular subgraph
can be described by the ordered pair
of out-vertices and
in-vertices.
Now let be any directed graph. A -design [covering] of
order and index is a collection of copies of (called blocks)
, the arc
with vertices in and such that for any distinct
appears in exactly [at least] blocks. Loosely speaking,
this is an arc decomposition of a complete multigraph on vertices into copies of . Although certain coverings are consid-designs. Some divisibility
ered, our primary focus is on
conditions are immediate.

-design of order

Proposition 3.1: If there exists a
index , then

and

and
It is easy to see that these necessary conditions are sufficient
or
. More generally, for fixed
and , the
for
conditions of Proposition 3.1 are sufficient asymptotically in
[19]. In light of the application, we are particularly interested in
-designs for certain values of . If
and
constructing
, any
-design of order and index yields a frame
schedule for nodes with exactly transmission opportunities
for any ordered pair of nodes. Such a frame schedule has
slots, the number of blocks. (For example, the schedule in
Table II corresponds to a
-design of order
and index ,
interpreting each column as one of the 34 blocks in the design.)
-design model focuses on finding examples in
This
which appearances of arcs are equal in number. This is too
stringent a requirement in practice; one desires small variation in the numbers of occurrences and, as we justify shortly,
equality is the ideal but not essential situation. For this reason,
generalizations that use coverings rather than designs provide
constructions that also serve to produce viable schedules.
In order to avoid collisions, we require additional
-designs or coverings. For blocks
properties of
of a
-covering of index , define
and
as in Section I. We consider the following
two possibilities.
is a -cover-free
• COVER-FREE CONDITION: for all
family;
• INTERSECTION CONDITION: for all and
.
The intersection condition implies the cover-free condition
. So we regard the cover-free condition as a true
for
global measure of interference at node ; however, in what follows we often choose to operate with the intersection condition
due to its more localized nature. When transmitter and receiver
are to communicate in slot , as indicated by the presence of
arc
in the
for slot , they are prevented by doing so
exactly when another active transmitter, , appears among the
transmitters in that
. Now the number of slots in which
can interfere with the
communication is equal to the

DUKES et al.: TERNARY SCHEDULES FOR ENERGY-LIMITED SENSOR NETWORKS

number of times the
with bipartition
appears
-design. In meeting the intersection conin a block of the
dition, then, our goal is to minimize the number of occurrences
. For this purpose, we define a parameter of
of any specific
-designs.
Definition 3.2: For a
-covering (any collection of
s),
-replication number, denoted by
, is the maximum
its
as a subgraph.
number of blocks containing a given
By counting in two ways the ordered pairs
, where
is a
contained in the block
, we have the following
lower bound on the
-replication number.
Proposition 3.3: In a

-covering of order with

blocks

For the intersection condition, we seek to minimize
, and
therefore desire equality in the bound of Proposition 3.3.
-deIn some cases, it is convenient to consider cyclic
; these are designs such that
is a block
signs on
is a block for all
. The collecimplies
-design can be partitioned into
tion of blocks of a cyclic
. When every orbit is full (that is, when there
orbits under
are distinct images of each block) the number of blocks is a
in this case. One advantage
multiple of . Thus,
of a cyclic automorphism is in simplifying computer search for
graph designs. Cyclic designs often have nice algebraic structure as well. The following easy construction (from which the
schedule in Table II arises) is essentially taken from [20]. The
reader is referred there for some related results.
Example 3.4: Let
block

form a cyclic

. Translates in

-design of order

of the base

and index .

We may wish to create schedules with
and with
higher index. For instance, suppose
, where
.
-design of
We can use the base bipartitions above to form a
index . First choose a collection of -sets on the set , say
-design. Now replace each block
the blocks of some
by copies of
with partition
, for each
.
The result of this “breaking up blocks” procedure is a collection
; every directed edge from an element
of copies of
to an element of appears exactly as often as appears in a set
, and every
with out-vertices
occurs in the
result exactly times. Thus Example 3.4 can, more generally,
-designs with index
be used to construct
and
. Arbitrarily large (the active neighborhood size)
can therefore be achieved in this way. See [21] for more on this
and related recursive constructions.
We close this section with a discussion of the practical values
and for our application under the typical proportion
of
of power usage [2], [3]. Suppose that every node has neighbors on average. It is optimal to maximize the number of

2795

-sets of nodes with exactly one transmitter, one receiver, and
the rest sleeping. More precisely, it is not important whether
more neighbors are receiving; however, for energy conservation,
the sleep state is preferred for these neighbors. This quantity is

a function of two variables and . With some elementary calis maximized for
. This
culations,
justifies making the simplifying assumption that the number of
, and
nodes transmitting and receiving per slot are equal
that this common number is chosen depending on the expected
neighborhood size. For this reason, we focus on the existence of
-designs. On the other hand, with the primary aim of minimizing power consumption per time slot, it may be convenient
in some ratio according to the costs of transmitto choose
ting and receiving. Many of our examples in Section IV also
-designs for
.
apply to
In the remainder of this paper, we describe some constructions of the relevant designs (via addition sets, resolvable designs, packings, and nets) and analyze the intersection condition
for each. Recursive and indirect methods are also available; see
[21]. Optimized schedules for large WSNs are likely to require
our methods in conjunction with these recursive techniques.
IV. DIRECT CONSTRUCTIONS OF TERNARY SCHEDULES
A. Addition Sets
An addition set [22] with parameters
is a subset
of , together with a multiplier
such that
run over all nonzero elements of exactly
the sums
times. When
, this is a difference set. For now, we also
for any
, so that
is
assume that
necessary.
The following theorem connects addition sets with cyclic
-designs.
Theorem 4.1: Let
. Suppose there exists an
addition set with parameters
. Then the copies of
with vertex partitions
form a
-design of order and index .
cyclic
We now examine various classical addition sets in [22], [23].
As we will see, the schedules resulting from these designs are
in many cases limited to handle networks with very small active neighborhood. However, the “breaking up blocks” procedure discussed in the previous section can take addition sets as
ingredients in more robust schedules. Also, the cyclic automorphism enjoyed by these designs is potentially favorable in various applications. A further study of addition sets with favorable
intersection condition is of some interest.
The shifted Ryser family of addition sets are the first non. Although these yield detrivial examples with
signs which are a special case of Theorem 3.4, we include their
construction for completeness. Let be an even positive integer.
is an addition set
Then
. Here,
denotes the
with parameters
multiplicative inverse of
modulo
, which exists since
.

2796

IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 53, NO. 8, AUGUST 2007

TABLE III
DEVIATION FROM BURGESS’S ESTIMATE

Example 4.2: Let

. We have
,
. Multiplying elements of by yields
. It follows that
ex. So the cyclic shifts of
hausts all nonzero elements of
form a
-design of order
and index . However, we can conclude more. The 17 cyclic
shifts of
, consisting of the
s
obtained by reversing all arcs in the original 17, also form a
-design of order
and index . The union of these two
s, that together do not contain any
consists of 34
more than once. As a result, we obtain a
-design of order
and index with
(see Table II). The resulting
schedule obeys the intersection condition supporting
active neighbors.
so

We next recall the negative quadratic residue family. Let
be prime and
be the sets of nonzero quadratic
residues and nonresidues in , respectively. Then is an addi, where is any element
tion set with parameters
is a quadratic residue, so
in . (In this case,
for
.)
Example 4.3: Let
are
in
given any nonzero
lutions are
solutions for any other
by . Solutions for
blocks
and index .

and

. The quadratic residues
. Let
. Then
, there are exactly four solutions
. For instance, when
, the soand
. The
are obtained by multiplying these
are obtained in a similar manner. The
form a
-design of order

We now analyze the intersection condition for the negative
quadratic residue type addition sets. Given
and
, we want an upper bound
on

By an estimate of Burgess [24], this value is bounded above by
. The intersection and cover-free conditions are
therefore guaranteed to be satisfied (at least asymptotically) for
. For
a prime, let
denote the maximum
, over
. Table III shows
value of
calculated for small prime values of and gives a comparison with the asymptotic bound so that the constant factor mulcan be determined precisely for small examples.
tiplying
Using the estimate above, we have the following result.
Theorem 4.4: Let
and suppose
-design of order and index
There exists a
for some independent of .

is prime.
with

The negative biquadratic residue family of addition sets has
parameters
(a prime),
, and
. In

this family, is the set of nonzero fourth powers in , and the
multiplier is the square of some generator of the multiplicative group . In [23], an analog of the above is given for sixth
powers.
with
It should be noted that addition sets
(that is, with
having no solutions in ) are
somewhat rare. However, one can often obtain a
-covering
by using other addition sets. We merely present
with index
an example.
Example 4.5: Let

and

in . (These are the fourth powers modulo .) Now is an
, and multiplier
. But
addition set with
has (only) the solution
. Let
. Therefore, for nonzero
, the equation
has either four or five solutions
in
.
is a
-covering of order
So
and index .
B. Resolvable Designs and Packings
An
design is an -set , together with a collection
of -subsets of , or blocks, such that every pair of distinct
elements of is contained in exactly blocks. Observe that an
design is, in the terminology of Section III, equivalent
to a
-design of order and index .
Such a design is resolvable if the collection of blocks can be
partitioned into parallel classes, each of which is a partition of
. We must have
for the existence of a resolvable design
parallel classes. For
with these parameters. There are
and
, resolvable designs (Kirkman triple systems) are
. The affine planes are
known to exist for all
and
, and are known to exist
examples with
whenever is a prime power [25].
Theorem 4.6: Suppose there exists a resolvable
design. Then there exists a
-design of order and index
with
replication number
.
be the blocks and
the parallel
Proof: Let
design, where
.
classes of a resolvable
For
, let
be the set of all
with biparti, where
are distinct blocks in . Let
tions
. We claim is a set of subgraphs for the required
-design. Consider a pair
of distinct points. They occur
together in exactly blocks of , but also and occur in
parallel
different blocks of the remaining
appears as an arc in exactly
subclasses. Thus,
graphs in . This proves the design property. The bound on
follows from the fact that
and
are arcs in the same
is contained in a block of .
member of only when

DUKES et al.: TERNARY SCHEDULES FOR ENERGY-LIMITED SENSOR NETWORKS

Example 4.7: The blocks of the (unique) resolvable
design, arising from the affine plane of order , are given below.
Parallel classes are shown as columns.

The

copies of
with bipartitions
are chosen from the same column, form a
with bipartition
of order and index . The
appears zero times in this design, while
pears once.

2797

A

K~

TABLE IV
-COVERING OF ORDER 10 AND INDEX 2 WITH

r

=1

, where
-design
, say, ap-

Since resolvable designs may not exist for the parameters of
interest, a more general construction is worthwhile. An
resolvable packing is a collection of -subsets (blocks) of an
-set that admit a partition into parallel classes and such that
every pair of points belongs to at most blocks. Theorem 4.6
applies more generally to resolvable packings with parallel
s is only nearly
classes; however, the resulting collection of
pairwise balanced.
Proposition 4.8: If there exists an
resolvable
packing with parallel classes, then there exists a
-covering of order and index
. (In fact, the number of blocks
and .) Moreover,
containing an arc is between
for this covering.
Such a system is still very useful for frame schedule construction, since the intersection condition can still be met with the
replications. Specific examples arise in
same bound on
a geometric setting. An
resolvable packing with
blocks and parallel classes is an
-net [26]. Nets can be
formed by selecting some parallel classes from an affine plane
even
of order (when one exists), but nets exist with
when the affine plane of that order does not exist; indeed, they
mutually orthogonal latin squares
correspond to sets of
-net yields a
of order (see [25]). By Proposition 4.8, an
s in
with every arc appearing or
collection of
times, and with
.
Example 4.9: The five mutually orthogonal latin squares of
order give a
-net, and hence a
-covering of order
and index such that no
appears in more than one bipartition. The resulting frame schedule is resistant to collisions
provided every node has at most six active neighbors.
C. Computer Search
While addition sets and resolvable packings provide some
-designs, we expect these
valuable direct constructions for
techniques to give relatively few examples for small parameters.
In many situations, we must resort to computational methods.
Indeed, the combinatorial constructions given are most effective
when certain divisibility conditions hold, and hence they are
limited in their ability to produce schedules for some parameters
of interest. We therefore mention here a few possible approaches
to construction of frame schedules that satisfy the intersection
condition.

Suppose we wish to find a
-covering of order , index ,
-replication number . Let the blocks be
and
. A refinement of Proposition 3.3 gives

For small examples, we have found some success applying a
max-clique algorithm to the (undirected) graph whose vertices
s on points, and with edges representing
are all possible
have intersection containing a
. A collection
that two
of blocks corresponding to a clique in this graph automatically
bound, and the design (covering) condition
satisfies the
can then be checked on several possible cliques.
and
, the bound
Example 4.10: For
. There are
distinct
above asserts that
s on 10 vertices. Form a graph on 4200 vertices, with each
s. Make two vertices adjacent
vertex representing one of the
.A
when the corresponding bipartite graphs do not share a
s in which no
appears more
clique consists of a set of
than once. In this graph, several cliques of size
were found
rapidly by computer search. After testing the pairwise balanced
property, the (maximum) collection of blocks given in Table IV
has the property that every pair of nodes is covered by between
two and four blocks, with 52 of 90 pairs covered by exactly three
blocks.
s is quite large, it is more
When the set of all possible
practical to use a hill-climbing strategy (see [25, Sec. VI.9.3]) to
construct small schedules. A random block is added if possible,
swapped with a single conflicting block, and not added if more
than one block is in conflict. This algorithm works well on cyclic
designs, operating on entire orbits of blocks.
Example 4.11: Below are orbit representative blocks of a
-design on
with index and
. This decyclic
sign was found using hill-climbing

V. CONCLUSION
Ensuring transmission opportunities in a wireless sensor network with nodes capable of transmission, reception, and sleep
requires that, for the time slots assigned to each receiver, the
sets of transmitters form a cover-free family. The construction
of such transmission schedules can therefore be modeled as

2798

IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 53, NO. 8, AUGUST 2007

a directed graph decomposition problem, with additional constraints. The cover-free condition on a decomposition translates
the schedule requirement to a graph-theoretic one. Here we have
adopted a simpler intersection condition that implies the coverfree condition. This graph-theoretic model leads to three direct
constructions for decompositions, and hence schedules, that appear to be promising for reducing energy utilization in wireless
sensor networks.
In [21], complementary indirect and recursive constructions
are developed to expand the repertoire of available decompositions, and in particular to develop flexible decompositions from
the direct examples constructed in this paper. At this time, the
construction from resolvable designs and packings provides a
general and useful technique for the ternary scheduling problem;
using the directed graph decomposition model affords a combinatorial tool to capture the twin goals of supporting many transmission opportunities with minimal interference from collision,
and we expect that this model will provide a powerful vehicle for
establishing further schedule constructions.
While this model is very flexible, the selection of a suitable frame schedule to achieve the tradeoff among energy,
throughput, and delay effectively is challenging. While
topology-transparent scheduling for two-node states (transmit
and receive) is effective in mobile ad hoc networks, studying
these tradeoffs using topology-transparent scheduling for three
node states in wireless sensor networks is an important next step.
ACKNOWLEDGMENT
We thank the anonymous referees for their careful reading
and many helpful suggestions.
REFERENCES
[1] I. F. Akyildiz, W. Su, Y. Sankarasubramaniam, and E. Cayirci, “Wireless sensor networks: A survey,” Comp. Networks, vol. 38, pp. 393–422,
2002.
[2] Crossbow Technology, Inc., “Mica2 wireless measurement data sheet,”
[Online]. Available: http:www.xbow.com/products/
[3] S. Singh and C. S. Rahavendra, “PAMAS—Power aware multi-access
protocol with signalling for ad hoc networks,” ACM Comp. Commun.
Rev., pp. 5–26, Jul. 1998.
[4] W. Ye, J. Heidemann, and D. Estrin, “Medium access control with coordinated adaptive sleeping for wireless sensor networks,” IEEE/ACM
Trans. Netw., vol. 12, no. 3, pp. 493–506, Jun. 2004.
[5] C. E. Jones, K. M. Sivalingam, P. Agarwal, and J.-C. Chen, “A
survey of energy efficient network protocols for wireless and mobile
networks,” ACM/Baltzer J. Wireless Netw., vol. 7, pp. 343–358, 2001.

[6] V. Rajendran, K. Obraczka, and J. J. Garcia-Luna-Aceves, “Energy-efficient, collision-free medium access control for wireless sensor networks,” in Proc. 1st ACM Int. Conf. Embedded Networked Sensor Systems (SenSys’03), Los Angeles, CA, Nov. 2003, pp. 181–192.
[7] I. Chlamtac and A. Faragó, “Making transmission schedules immune
to topology changes in multihop packet radio networks,” IEEE/ACM
Trans. Netw., vol. 2, no. 1, pp. 23–29, Feb. 1994.
[8] J.-H. Ju and V. O. K. Li, “An optimal topology-transparent scheduling
method in multihop packet radio networks,” IEEE/ACM Trans. Netw.,
vol. 6, no. 3, pp. 298–306, Jun. 1998.
[9] C. J. Colbourn, A. C. H. Ling, and V. R. Syrotiuk, “Cover-free families and topology-transparent scheduling for MANETs,” Des., Codes,
Cryptogr., vol. 32, no. 1–3, pp. 35–65, May–Jul. 2004.
[10] D.-Z. Du and F. K. Hwang, Combinatorial Group Testing and Its Applications, ser. Series on Applied Mathematics, 2nd ed. Singapore:
World Scientific, 2000, vol. 12.
[11] A. D’yachkov, V. Rykov, and A. M. Rashad, “Superimposed distance
codes,” Probl. Contr. Inf. Theory, vol. 18, pp. 237–250, 1989.
[12] C. J. Colbourn, J. H. Dinitz, and D. R. Stinson, , J. D. Lamb and D. A.
Preece, Eds., “Applications of combinatorial designs to communications, cryptography, and networking,” in Surveys in Combinatorics, ser.
Lecture Note Series 267. London, U.K.: London Math. Soc., 1999,
pp. 37–100.
[13] W. Chu, C. J. Colbourn, and V. R. Syrotiuk, “The effects of synchronization on topology-transparent scheduling,” ACM/Baltzer J. Wireless
Netw., vol. 12, pp. 681–690, 2006.
[14] L. Hu, “Topology control for multihop packet radio networks,” IEEE
Trans. Commun., vol. 41, no. 10, pp. 1471–1481, Oct. 1993.
[15] M. Svanström, P. R. J. Östergard, and G. T. Bogdanova, “Bounds and
constructions for ternary constant-composition codes,” IEEE Trans.
Inf. Theory, vol. 48, no. 1, pp. 101–111, Jan. 2002.
[16] W. Chu, C. J. Colbourn, and P. J. Dukes, “On constant composition
codes,” Discr. Appl. Math., vol. 154, pp. 912–929, 2006.
[17] W. H. Kautz and R. C. Singleton, “Nonrandom binary superimposed
codes,” IEEE Trans. Inf. Theory, vol. IT-10, no. 4, pp. 363–377, Oct.
1964.
[18] P. Karn, “MACA—a new channel access method for packet radio,” in
Proc. 9th ARRL/CRRL Amateur Radio Computer Networking Conf.,
London, ON, Canada, Sep. 1990, pp. 134–140.
[19] E. R. Lamken and R. M. Wilson, “Decompositions of edge-colored
complete graphs,” J. Comb. Theory, Ser. A, vol. 89, pp. 149–200, 2000.
[20] D. de Caen, D. A. Gregory, I. G. Hughes, and D. L. Kreher, “Nearfactors of finite groups,” Ars Combinatoria, vol. 29, pp. 53–63, 1990.
[21] P. J. Dukes, C. J. Colbourn, and V. R. Syrotiuk, “Directed complete
bipartite graph decompositions: Indirect constructions,” Discr. Math.,
DOI: 10.1016/j.disc.2006.11.050, to be published.
[22] C. W. H. Lam, “A generalization of cyclic difference sets I,” J. Comb.
Theory, Ser. A, vol. 19, pp. 51–65, 1975.
[23] C. W. H. Lam, “ th power residue addition sets,” J. Comb. Theory,
Ser. A, vol. 20, pp. 20–33, 1975.
[24] D. A. Burgess, “On character sums and primitive roots,” Proc. London
Math. Soc., vol. 3, no. 12, pp. 179–192, 1962.
[25] C. J. Colbourn and J. H. Dinitz, Eds., Handbook of Combinatorial Designs, 2nd ed. London, U.K.: Chapman & Hall/CRC, 2007.
[26] T. Beth, D. Jungnickel, and H. Lenz, Design Theory. Cambridge,
U.K.: Cambridge Univ. Press, 1986.

N

Securing Dynamic Spectrum Use
Minghao Cui, Violet R. Syrotiuk and Charles J. Colbourn
Department of Computer Science and Engineering
Arizona State University
Tempe, Arizona 85287-8809
e-mail: {minghao.cui,syrotiuk,colbourn}@asu.edu

Abstract— We consider the problem of securely utilizing the
dynamic temporal and spatial “holes” in spectrum for communications. Given a model of spectral availability, we consider
the problems of secure link establishment, authentication, and a
secure method to employ the holes. In a tactical environment,
evading interception and detection (LPI/LPD) is critical; hence
coding techniques are applied. A simulation study shows that our
approach can interoperate within an existing architecture.

I. I NTRODUCTION
Spectrum is a scarce resource. The military has seen a
significant amount of its spectrum reallocated to the commercial sector over the past decade. Adding to the concern
are estimates from the Department of Defense (DoD) that its
spectrum requirements are growing annually by 25%. At the
same time, a DoD study estimates that temporal and spatial use
of the spectrum by its emitters is much less than 1%. Thus
the Defense Advanced Research Projects Agency (DARPA)
launched the NeXt Generation Communications (XG) program
[3], [4] to improve spectrum utilization.
Related to spectrum utilization is the requirement for rapid
deployment of military assets. Every new, and potentially hostile, environment poses numerous communications challenges.
Available spectrum varies dramatically with geographic location and with local communication traffic patterns.
Given a model of spectral availability, our interest is to securely utilize the temporal and spatial holes in the spectrum. A
hole is a time span over which a given frequency goes unused.
We improve spectrum utilization by using the holes for transmission, interoperating with existing network architectures. At
the same time, the rapid deployment of assets is facilitated
through communications equipment that can automatically
find and use spectrum without reprogramming. In a combat
mission it is also necessary that the communications have a
low probability of detection (LPD) and a low probability of
interception (LPI).
The main problems that arise in supporting secure dynamic
spectrum utilization include: (1) modelling available spectrum;
(2) link establishment; (3) employing holes in space-time; (4)
LPD by steganographic utilization of holes; (5) fingerprinting
packets for authentication; and (6) erasure coding to accommodate for variable packet loss and LPI. There are significant
challenges in combining solutions to these problems.
In this paper, we explore a design for securely utilizing
holes that interoperates with existing nodes in the network.
Due to the dynamic nature of the environment, packets will
0-7803-8521-7/04/$20.00 © 2004 IEEE

be lost through collision and through inaccuracy of modelling
of holes. Moreover, packets may be intercepted by unintended
recipients. We address these problems by employing erasure
codes. These codes have the property that a fraction of the
packets transmitted suffice to recover the original message,
but each single packet or a small fraction of packets do not
reveal any useful information of the original message.
Fingerprinting for authentication of packets is needed so that
intended recipients can distinguish them from normal ambient
traffic, while unintended recipients can not distinguish them.
In common practice, when two nodes communicate, the source
S appends to the message a value called an authentication tag
computed by some function of the transmitted information and
a shared secret key. On reception, the receiver R recomputes
the authentication tag on the received message using the same
mechanism and key and checks the value obtained with the
tag in the received message. Only if the value at R matches
is the message considered to be from S.
Two existing headers of the IP Security Protocol (IPsec)
(described in [5], [6], [7], among others), are the Authentication Header (AH) and the Encapsulating Security Payload
(ESP). These headers are designed to provide a mix of
security services in IPv4 and IPv6. AH provides integrity
checking and anti-replay security but not secrecy (i.e., no data
encryption), while ESP handles secrecy and integrity checking.
The drawback is that the encryption in ESP is expensive. In our
design, by employing both erasure codes and authentication we
provide both integrity checking and secrecy similar to ESP, but
pay a small computational cost as in AH.
The remainder of the paper is organized as follows. We
first describe each of the components of our XG network
architecture in section II. In section III a simulation study
shows that our approach can interoperate within an existing
architecture, and improve utilization of the channel. The
authentication is shown to minimally impact the throughput.
Section IV presents conclusions and discusses directions for
future work.
II. XG N ETWORK A RCHITECTURE OVERVIEW
Consider a legacy wireless network architecture. Introducing
wireless XG nodes into the network cannot require a change
to the legacy protocol stack. Indeed, the goal is for the legacy
nodes to be unaware of the XG nodes. The XG nodes seek
opportunities to use the spectrum left unused by the legacy
nodes, and with limited interference to them.

1153

0-7803-8521-7/04/$20.00 (C) 2004 IEEE

Figure 1 shows the protocol stack used for communication
between peer legacy nodes and the proposed design for
communication between peer XG nodes. In the XG stack,
the medium access control (MAC) layer is expanded into two
sublayers: modelling available spectrum and a MAC protocol
for hole utilization. The network layer is expanded to include
LT coding (a specific erasure code) with authentication. We
add LT coding with authentication under the transport layer
but above the network layer because it is generally agreed
that real security cannot be achieved unless it is end-to-end;
this positioning also leaves the application unchanged.

An encoding process is deployed at each XG sender. The
input symbols are obtained by dividing the message into
an arbitrary number n of equal sized blocks. The encoding
process for LT codes proceeds as follows:
1) Randomly choose a degree d of the encoding symbol
from a degree distribution.
2) Choose uniformly at random d distinct input symbols as
neighbours of the encoding symbol.
3) The value of the encoding symbol is the exclusive-or
(XOR) of the d neighbours.
Figure 2 shows an example of the LT encoding process with
n = 6. Each node in upper row represents an input symbol
(denoted by nodes A, B, C, D, E, and F ), while each node in
lower row represents an encoding symbol (denoted by nodes
a, b, c, d, e, and f ). As shown by the edges, the first encoding
symbol (node a) has degree two, and its value is the XOR of
the second and sixth input symbol (nodes B and F ).

Fig. 2.
Fig. 1.

An example of the LT encoding process.

Protocol stack for legacy nodes (left) and XG nodes (right).

A. The LT Process
The design for utilizing temporal holes is to use a Luby
Transform (LT) code, an erasure code. Traditional erasure
codes are block codes with a fixed rate. Luby [9] developed
LT codes to solve the problems associated with Reed-Solomon
and Tornado codes, namely the inefficient encoding and decoding algorithms, and the inability to accommodate variable
packet loss. LT codes are rateless, meaning the number of
encoding symbols that can be generated from the data is
potentially unlimited. The encoding symbols can be generated
dynamically, generating as few or as many as needed. From
a nearly minimal set of encoded symbols, the decoder can
recover the original data. Symbols can be encoded and transmitted over the channel until a sufficient number have arrived
at the decoder for it to recover the data. All of these properties
are particularly suitable for XG communication because:
1) The loss rate can vary arbitrarily on a wireless channel.
Since an unlimited number of encoding symbols can be
generated, decoding can succeed as long as the decoder
receives a sufficient number of symbols.
2) No retransmission is required, since neither order nor
content of the symbols affect the result.
3) Feedback is minimal. Each message, rather than each
individual packet, is acknowledged.
0-7803-8521-7/04/$20.00 © 2004 IEEE

The efficiency of the LT process depends on a proper
degree distribution. In our design we employ the robust soliton
distribution used in [9]. The LT encoding process is very fast.
Each encoding symbol can be generated in near linear time.
The decoding process at the receiver side is as follows:
1) Each encoding symbol with degree one is released;
i.e., this encoding symbol is removed from the list
of encoding symbols, and all of its neighbours are
XORed with the value of this encoding symbol. These
neighbours are then called recovered.
2) A ripple is the set of recovered but unprocessed input
symbols.
3) One symbol from the ripple is processed, i.e., this input
symbol is decoded and removed from the list of input
symbols, and all of its neighbours are XORed with the
value of this input symbol. Go to step (1) if the ripple
has size larger than 0.
4) If all inputs are recovered, the decoding succeeds. Otherwise, the decoding fails.
In the case of Figure 2, if the receiver receives all six
encoding symbols, the inputs are decoded as follows: encoding
symbols c, e and f are released first since each has degree one.
This allows input nodes C, E and B to be recovered, respectively. Next, node a is released; node F is recovered; node
d is released, node D is recovered; node B is released, and

1154

0-7803-8521-7/04/$20.00 (C) 2004 IEEE

node A is consequently recovered. With ten XOR operations,
all six inputs symbols are decoded.
After the receiver decodes the entire message successfully,
an acknowledgement is sent to the source.
B. Authentication
The XG nodes sense all transmissions on the channel and
authenticate XG traffic using a fingerprint. In our design, we
use a computationally efficient authentication process together
with the LT process to provide both protection of integrity
and secrecy. In our design, we assume that the XG source
and receiver agree on a shared key before setting up the
communication. The key for authentication can be of any
length. A hash over the packet plus a shared key is computed
as a fingerprint of the message. The hash function we use is
HMAC [1], [2], [8], which is also used in IPsec. Figure 3
shows the format of packets in our XG architecture.
Part of the IP header, such as the source address, can also be
included in the hash check, making it difficult for an intruder
to falsify the origin of a packet.

Fig. 3.

Figure 4 shows a snapshot in time over which a predictor
is running in peer XG nodes. The lower edge of the square
wave represents a sensed transmission in the channel, while the
high edge represents a hole. As each source node uses a CBR
traffic generator, the transmissions on the channel are periodic.
In this case the dashed and dotted square waves represent the
prediction of peer XG nodes. The holes predicted by two nodes
may not coincide (since they are in different positions in the
network), but do overlap in this example. The solid square
wave shows the intersection of the holes predicted by the peers,
showing a chance for a successful XG communication.

XG packet format.

C. The XG MAC Layer
The XG MAC layer consists of two components: a predictor
module and a hole utilization module. The predictor is designed to monitor spectrum utilization and offer approximate
predictions of future spectrum usage. While modelling the
available spectrum is not a focus of our study, we devise
a straightforward algorithm to predict temporal holes given
simple, but realistic traffic between legacy nodes in a single
channel in order to evaluate our utilization scheme. Multiple
channels may be modelled by treating each channel separately.
The predictor at an XG node divides time into fixed sized
intervals. It senses the channel in the current interval to predict
the holes for the next interval. Based on the predictions,
transmission can be carried out in the anticipated holes. Any
hole of size less than a threshold T h is too small to hold a
control packet and is therefore discarded. The output from the
predictor is a set of pairs, (t, d), where t indicates the starting
time and d the duration of a predicted hole.
The hole prediction process is as follows:
1) Monitor transmissions in the current interval.
2) Analyze and approximate periods of transmission.
3) Predict holes in the next interval.
4) Discard holes less than threshhold size T h.
In our design and simulations, we assume that each source
node uses constant bit rate (CBR) traffic at the transport layer.
With this simplifying assumption, we can model the traffic on
the channel as periodic or approximately periodic.
0-7803-8521-7/04/$20.00 © 2004 IEEE

Fig. 4.

Holes predicted by peer XG nodes, and their intersection.

The predicted holes are utilized as follows: The next hole
(a time, duration (t, d) pair) is obtained from the predictor. A
packet of appropriate size (d) is scheduled for transmission
at time t. In our simulations, we attempt transmission in
each predicted hole for simplicity. However, transmission into
predicted holes can be randomized to improve LPD. In a
system with multiple channels, frequency hopping techniques
can be included, also contributing to both LPI and LPD.
Since the predictors in each XG node are designed in the
same way, there is a chance that for a pair of XG nodes their
hole set may overlap, as shown in Figure 4. In this situation,
encoding symbols and acknowledgements may be scheduled
into the same hole, causing a collision. We solve this problem
by synchronizing the holes between XG peers. In each hole
pair (t, d), t is synchronized based on a fixed period. We also
partition each hole into two parts. The first part is for data
(i.e., for encoding symbols), while the second part is for an
acknowledgement. Bandwidth is wasted if no acknowledgment
is scheduled.
Unlike the traditional scheduling based or contention based
MAC protocols, our approach has the nice property of concealing the XG transmission. In scheduling based schemes
like TDMA, each node transmits in its own slot, which
is pre-determined at the beginning of each schedule cycle.
In contention based schemes, all the nodes involved in the

1155

0-7803-8521-7/04/$20.00 (C) 2004 IEEE

contention period will know candidate transmission nodes
and even the transmission time of the next transmission in
the channel. In our approach, the XG transmission is not
predictable by the legacy nodes, making it difficult for legacy
nodes to detect the transmission.

The proposed system is implemented in version 2.26 of
ns-2 [10] and its wireless extensions developed at Carnegie
Mellon University [11]. The legacy network consists of nodes
using a CBR traffic generator to create UDP traffic at the
transport layer of each source node. The CBR packet size
is 1000 bytes. Currently, the network is static; hence static
routing tables are used at the network layer. IEEE 802.11 is
the MAC protocol. The nodes are configured to use omnidirectional antennas with a transmission range of 250m, and
share a 1Mbps radio channel using a two-ray ground reflection
model. The XG nodes within the network are configured the
same as the legacy nodes except as described in Section II. A
simple error model using packet error rate is used to simulate
packet losses on the wireless channel.
In our simulations, two scenarios are designed to test the
spectrum utilization and security aspects of the proposed
architecture. Figure 5 shows a full connected topology with
two legacy nodes and two XG nodes. The purpose of this
scenario is to test the spectrum utilization by introducing XG
nodes into the legacy architecture. There is one flow between
legacy nodes (0 → 1), and one flow between XG nodes
(2 → 3) on the channel. In this topology, each XG node sees
the same traffic on the channel. Without the XG flow running,
the legacy flow achieves almost 100% of its offered load.

0.25

Throughput (mbps)

III. S IMULATION S ET- UP AND R ESULTS

0.3

0.2

0.15

0.1

0.05
LT
node 0&1
0
0.1

Fig. 6.

0.15

0.2

0.25

0.3
Non−XG Load

0.35

0.4

0.45

0.5

Throughput as a function of legacy load for scenario 1.

the channel as another legacy flow or an XG flow. Figure 7
shows a topology with five legacy nodes and two XG nodes.
We introduce three flows between legacy nodes: 0 → 1, 1 → 6,
and 4 → 5. Flow 4 → 5 creates an asymmetry of traffic on the
channel seen by XG nodes 2 and 3. Flow 1 → 6 competes with
flow 0 → 1 for the channel. A flow is also established between
the XG nodes, from 2 → 3. Without XG nodes running, each
of the three legacy flows achieve more than 90% of its offered
load until the load of each reaches 0.4 Mbps. At that point,
the performance of the flow from node 0 starts to suffer.
0

0
3

2

4

5

3

2

1

1
Fig. 5.

Traffic sensed by XG nodes in this topology is the same.

Figure 6 shows the the throughput of the system when
the XG flow also runs. The throughput of the XG flow
remains quite stable with increasing load on legacy nodes. The
throughput of the legacy nodes tends to increase linearly until
the load reaches 0.4Mbps. After that, the throughput levels
out. At the point where the non-XG load reaches 0.4Mbps,
the total throughput of all the flows is around 0.6Mbps. Both
of the legacy flow and XG flow achieve as much as 6070% of offered loads. This is about the best throughput that
can be achieved on a 1Mbps channel, considering all the
control packet overhead, including the overhead we introduce
by partitioning the holes.
We present a second scenario whose purpose is to examine
whether the legacy nodes can distinguish the competition for
0-7803-8521-7/04/$20.00 © 2004 IEEE

6
Fig. 7.

Traffic sensed by XG nodes in this topology is different.

Figure 8 shows the throughput of the XG nodes and legacy
nodes for increasing load on the legacy nodes. The throughput
of the XG nodes increases slightly with increasing load on the
legacy nodes and remains stable after the legacy load reaches
0.25 Mbps. The XG flow again achieves 60% of offered load.
The throughput of the legacy flows tends to level out rather
than drop, but has decreased due to the competition for the
channel with the XG nodes. However the legacy nodes can not
distinguish whether this decrease is caused by competition for
the channel by another legacy flow or an XG flow.

1156

0-7803-8521-7/04/$20.00 (C) 2004 IEEE

However there is some interference to the legacy traffic.
In our implementation, we use the next available hole in the
hole set to schedule each transmission, However the system
can be less obtrusive to the legacy nodes if the predictor is
more conservative about what it classifies as a hole or is more
strategic in selecting holes in which to transmit.
While the ideas behind the scenario design are sound, i.e.,
to create differing spectrum availability for the XG nodes by
location, and to distinguish competing legacy flows from XG
flows competing with legacy traffic, the results are insufficient
to draw firm conclusions. More simulation on the existing
and new scenarios is required in order to verify that injected
XG traffic exhibits characteristics of the ambient traffic. In
addition, expanding the study to include attacks on the XG
communications are required. Our study has proven to be a
useful first step towards the implementation of the XG vision.

0.25

Percentage

0.2

0.15

0.1

0.05
LT
node 0&1
node 4&5
node 1&6
0
0.15

0.2

0.25

0.3

0.35

0.4

Non−XG Load

Fig. 8.

ACKNOWLEDGEMENTS

Throughput as a function of legacy load for scenario 2.

We also run the simulations to determine the overhead of
introducing authentication into the system. Figure 9 shows the
throughput of the XG flow using fingerprinting compared to
a naive scheme (where the source node is identified by the
simulator). The throughput is shown for a low loss rate (less
than 10%). The throughput of the XG flow does decrease a
little when fingerprinting is added, because a hash is added to
the header of each packet. But this decrease is tiny, especially
for the high loss rates. This illustrates that the authentication
scheme does not impact throughput.
0.18
LT w/o FP
LT with FP
0.16

0.14

Throughput

0.12

0.1

0.08

0.06

0.04

0.02

0
0.01

0.02

Fig. 9.

0.03

0.04

0.05
0.06
Loss rate

0.07

0.08

0.09

This research is supported in part by a DARPA XG subcontract from Raytheon Co. and by the ARO under grant DAAD
19-01-1-0406.
R EFERENCES
[1] M. Bellare, R. Canetti, and H. Krawcyk, “Keying Hash Functions for
Message Authentication,” in Lecture Notes in Computer Science, N.
Koblitz, ed. Vol. 1109, 1996.
[2] M. Bellare, R. Canetti, and H. Krawcyk, “Message Authentication
using Hash Functions: The HMAC Construction,” RSA Laboratories’
CryptoBytes, Vol. 2, No. 1, Spring 1996.
[3] BBN Technologies, “The XG Vision,” Request for Comments, Version
1.0.
www.darpa.mil/ato/programs/XG/rfc vision.pdf
[4] Defense Advanced Research Projects Agency (DARPA), Advanced
Technology Office (ATO), Next Generation (XG) Communications Program.
http://www.darpa.mil/ato/programs/xg.htm
[5] S. Kent and R. Atkinson, “Security Architecture for the Internet Protocol,” Internet RFC 2401, 1998.
[6] S. Kent and R. Atkinson, “IP Authentication Header,” Internet RFC
2402, 1998.
[7] S. Kent and R. Atkinson, “IP Encapsulating Security Payload (ESP),”
Internet RFC 2406, 1998.
[8] H. Krawczyk, M. Bellare, and R. Canetti, “HMAC: Keyed-Hashing for
Message Authentication,” Internet RFC 2104, February 1997.
[9] M. Luby, “LT Codes,” Proceedings of the 43rd Annual IEEE Symposium
on Foundations of Computer Science (FOCS’02), November 2002, pp.
271–282.
[10] Network Simulator, ns-2. The VINT Project.
http://www.isi.edu/nsnam/ns/
[11] Wireless and Mobility Extensions to ns-2. Carnegie Mellon University,
Monarch (Mobile Networking Architectures) Project.
http://www.monarch.cs.cmu.edu

0.1

Trade-off in throughput for low packet loss rates.

IV. C ONCLUSIONS AND F URTHER W ORK
In this paper we proposed a design for an adaptive wireless
system capable of secure dynamic spectral use. Based on
predictive modelling of spectrum and LT coding with authentication, the system is capable of utilizing the predicted holes.
0-7803-8521-7/04/$20.00 © 2004 IEEE

1157

0-7803-8521-7/04/$20.00 (C) 2004 IEEE

Application of a Network Dynamics Analysis Tool
to Mobile Ad Hoc Networks
V.R. Syrotiuk, K. Shaukat and Y.J. Kwon

M. Kraetzl and J. Arnold

Department of Computer Science & Engineering
Arizona State University
P.O. Box 878809
Tempe, Arizona, U.S.A. 85287-8809

Communications Analysis Group
Defence Science and Technology Organisation
P.O. Box 1500
Edinburgh SA 5111, Australia

{syrotiuk,kshaukat,yjkwon}@asu.edu

{miro.kraetzl,jon.arnold}@dsto.defence.gov.au

ABSTRACT
We present an application of the Redback network dynamics analysis tool to mobile ad hoc networks. Our goal is to understand the
network properties that arise from different mobility models and to
quantify how these differences impact communications. We generate input for Redback as a graph series for varying node density
and speed in the random waypoint, reference point group, freeway,
and Manhattan mobility models by sampling network topology in
the ns-2 network simulator. The graph series are analyzed using
several distance and metric measures in the Redback tool and visualized as a time series, one of the Redback output displays. We
find measurable differences among mobility models that may impact mobile communications and influence protocol design.

Categories and Subject Descriptors
C.2.3 [Computer Communication Networks]: Network operations—Network management, Network monitoring; C.2.1 [Computer
Communication Networks]: Network architecture and design—
Wireless communication, Network topology

General Terms
Measurement, Management

Keywords
Network analysis, Mobile ad hoc networks, Time series

1.

INTRODUCTION

All networks, even those with a fixed wired infrastructure, are
highly dynamic systems. The dynamics may arise from the bandwidth or quality-of-service requirements of the traffic carried by the
network. In wireless networks, node mobility as well as the characteristics of the wireless medium itself add dynamics. Coping with
the complexity of network dynamics gives rise to many challenging
research problems.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
MSWiM’06, October 2–6, 2006, Torremolinos, Malaga, Spain.
Copyright 2006 ACM 1-59593-477-4/06/0010 ...$5.00.

36

Changes in the network may indicate anomalies or may represent conditions to which the protocols must adapt to maintain performance. For example, a change in the use of the network may
correspond to a breach in security such as an intrusion or a denialof-service attack. It may indicate a fault in the network such as
a router that is configured incorrectly, or traffic anomalies such as
broadcast storms or paging across the network. A change in the
structure of the network, such as to the topology of a mobile ad
hoc network, may cause a route to fail indicating the need for its
repair or replacement. Techniques to detect change are therefore
important for the security and performance of networks.
Change or anomaly detection is the process of determining when
network behaviour deviates from the norm. Existing methods for
change detection fall into two major categories. Signature (or rule)
based approaches detect changes that have been observed in the
past. When an anomaly is identified, a signature for it is defined
and stored. While useful to identify known anomalies, signature
approaches are unable to detect new anomalies [18]. The work in
this area is based on expert systems, case based reasoning [20], and
adaptive learning techniques.
Statistical approaches to change detection [4] include auto regressive processes [7], neural networks, hidden Markov models
[13], wavelets, change point detection [25], and Bayesian networks
[14]. These methods are capable of detecting network anomalies
that have not been observed in the past, and can continuously update their model of normal behaviour without recalibration or retraining. However a larger number of anomalies may be generated
and the anomaly type may not be identified.
Tools to identify change are still immature. While there are active monitoring techniques that inject test traffic into the network,
such as ping and traceroute [1], our focus is on passive monitoring techniques. These are node oriented techniques that do not
disrupt the traffic flow in or add traffic to the network.
Redback is a JAVA-based network analysis tool that consolidates some research on change detection into a single interface [10,
17]. Redback assumes passive monitoring and transforms the data
collected into metrics that capture information about the network
behaviour. The metrics are then assessed to determine anomalies.
The rest of this paper is organized as follows. In §2 we overview
Redback describing the input formats, filters and transforms, and
output display formats that highlight change detection. The remainder of the paper is devoted to an application of Redback to mobile
ad hoc networks (MANETs). These are networks in which a collection of mobile wireless nodes self-organize without the aid of
any fixed infrastructure or centralized control. MANETs continue
to be studied primarily in simulation [6] as test-beds are just emerging [9]. Our goal is to understand the network properties that arise

Figure 1: Redback GUI main screen.
Sampling tools allow a subset of representative measures to be selected that allow accurate estimates of the properties of the entire
series to be made. Filtering allows measures that are not of interest
to be removed from the series. Nodes with self-loops and orphan
vertices are examples of edge and vertex filters, respectively. Time
series transforms perform operations on a series of numbers such
as to find the moving average.
Several distance measures are available for a graph series. They
are distances in the sense that all distance measures d(Gi , Gj ) are
symmetric, d(Gi , Gj ) = d(Gj , Gi ), and satisfy the triangle inequality, d(Gi , Gk ) ≤ d(Gi , Gj ) + d(Gj , Gk ). In Figure 1, the
maximum common subgraph (MCS) edge and vertex distance are
the distance measures selected in the processing step list. These
measure the number of edges (vertices) the graphs have in common
as a fraction of the number of edges (vertices) in the graph with the
largest number of edges (vertices). Each takes as input a graph series and produces as output a series d(Gi , Gi+1 ), i = 1, . . . , T −1.
Metric measures also operate on a graph series but do not satisfy the distance property; these measures operate on an individual
graph. §3.2 describes some of the distance and metric measures.
The output of the network analysis can be displayed using a number of different visualizations. Figure 2 is the series chart display
of Redback for the processing step list in Figure 1. Here, the graph
series represents 102 days of aggregated network probe data collected from an actual large wired network. The series chart shows
the MCS edge and vertex distance on a daily basis. Network administrators identified four days (22, 64, 89, and 101) on which
the network behaved abherrantly. Only on day 64 was a reason
suggested: the introduction of a web-based personnel management
system. The peaks in the series chart correspond to significant network changes and agree with observations of the administrators.

from different mobility models and to quantify how these differences impact communications. We generate input for Redback as
a graph series for varying node density and speed in the random
waypoint, reference point group, freeway, and Manhattan mobility
models by sampling network topology in the ns-2 network simulator. The mobility models used in our study are described in §3.1.
The graph series are analyzed using measures in the tool. The distance measure of diameter, and the metric measures of characteristic path length, clustering coefficient, and edge count are described
in §3.2. The measures are visualized as series charts in §3.3 and
analyzed. We find measurable differences among mobility models that may impact mobile communications and influence protocol
design. Finally, we conclude and propose future work in §4.

2.

THE REDBACK TOOL

Figure 1 shows a screen-shot of the Redback GUI, where a processing step list is constructed from a list of available steps. In
the example, the first processing step loads a series of graphs. Formally, a graph series G is defined as G = G1 G2 . . . GT as any
sequence Gi , i = 1, . . . , T, of directed weighted graphs. Successive graphs in the series represent a history of the network topology
and link weight changes over time T . The network is sampled over
T to obtain the series. If there are simultaneous changes in the
topology or weights they are all incorporated into the next graph.
Of course, the time between measurements (or polling rate) affects
the types of changes that can be detected.
Once the input is specified, processing steps typically follow.
These may be selected from a suite of filtering tools, time series
transforms, and other algorithms for network analysis. Sampling
and filtering are techniques to reduce the volume of data processed.

37

Figure 2: Redback series chart display.

To further investigate these changes, the graph inspector display
may be used. The view is generated based on a distance measure
between two successive graphs in time. The graph inspector can
generate views for either graph, their common subgraph, or their
symmetric difference. In Figure 3 the first major change (day 22)
is selected for viewing by positioning the grey bar on the series
trace of the display. The vertex with the largest change is selected
for viewing; this is the dark blue column in the histogram view
representing the edge count.
There are three other output displays currently available in Redback. Figure 4 shows a three day sequence from the animated
graph viewer. This display creates an animation from a graph series G. An n × n array of pixels (or frame) corresponds to each
graph in the series, where n = maxGi ∈G |Vi |. For each frame
1 ≤ f ≤ T , if edge (vi , vj ) exists in Gf then the pixel at position
(i, j) is turned on in frame f , otherwise it is turned off; the frames
are then animated.
Figure 5 illustrates vertex importance. This display ranks the
vertices in each graph and displays a chart of the importance of
each vertex over the whole time series.
Figure 6 shows an example of the 2D viewer display. The edit
distance between all pairs of graphs is computed and displayed in a
square grid. The intensity of each point is governed by the relative
values of the calculation. The darkest value is equivalent to the
minimum distance and the brightest value is the maximum distance,
with the remaining values scaled linearly in between. To view the
edit distance of a graph compared to all other graphs, it is selected
by positioning the grey bar on the series trace of the display. The
appropriate row in the 2D viewer is then highlighted.

3.

Figure 3: Redback graph inspector display.

Figure 4: Redback animated graph viewer display.

APPLYING REDBACK TO MANETS

3.1 Graph Series Input to Redback
The first step is to generate graph series input for Redback. We
consider three factors and four levels for each factor:
Factor
Mobility model
Number of nodes
Maximum node speed

Levels of Factor
RWP, RPG, FW, and MH
50, 100, 150, and 200
5, 10, 15, and 20 m/s

Figure 5: Redback vertex importance display.

38

3.1.1 Random Waypoint Mobility Model
RWP was introduced by Johnson et al. [16]. It takes two parameters, a maximum speed v and a pause time d, and uses them to
model individual node movement. Each node ni , 1 ≤ i ≤ |V |,
at position (xi , yi ) chooses a destination (xi , yi ) uniformly at random and moves along a straight line from (xi , yi ) to (xi , yi ) at a
velocity chosen uniformly at random from [0, v]. When ni reaches
its destination it pauses (stops) at that location for a time d. The
node repeats these steps until the simulation ends.
The original RWP mobility model fails to provide a steady state
in that the average node speed consistently decreases over time [21,
24]. However, there is a simple modification, which we use, that
ensures the nodes are initialized in and remain in a steady state [22].

3.1.2 Reference Point Group Mobility Model
The RPG mobility model, introduced by Hong et al. [12], is used
to model the movement of groups such as battalions of troops on
a battlefield. Each group has one leader and zero or more other
members initially uniformly distributed in the neighbourhood of
the leader. Each group member has a speed and direction that is
a random deviation of that of the leader. See [12] for a precise
characterization of the node movement. The mobility pattern is
expected to have high spatial dependence for small deviation values
[2]. In RPG we generate groups of 10 nodes including the leader.

3.1.3 Freeway Mobility Model
Bai et al. proposed the FW mobility model [2]. It models the
motion of vehicles on a freeway; as vehicular ad hoc networks
(VANETs) are developing, such mobility models are of interest.
A map of the freeway is input; it may have several freeways and
each freeway has lanes in both directions. Each node is positioned
at random in a lane on a freeway. The node is restricted to travelling in that lane and in the direction of the lane. Two nodes in the
same lane must maintain a safe distance apart. If a node catches up
to a node in the same lane, it cannot overtake the slower node or
change lanes. The inter-node and intra-node relationships are defined in [2]. The FW model is expected to have spatial and temporal
dependence [2].
Figure 7 shows the map based on the major freeways in the city
of Tempe that was used as input to the freeway mobility model.

Figure 6: Redback 2dviewer display.

A mobility model defines when and how nodes move in a simulation of a mobile network. For MANETs, several mobility models
have been developed over the years; see [8] for a survey. Indeed,
mobility modelling remains an active research area [5, 15, 19].
We consider models of individual node movement – random
waypoint (RWP), nodes moving in groups – reference point group
(RPG), nodes moving on freeways –freeway (FW), and nodes moving on city streets – Manhattan (MH). RWP is part of the standard
distribution of the ns-2 network simulator and generates mobility
trace files using the setdest tool. We use a mobility generator
tool developed by Bai et al. [3] for the other mobility models.
We model the network by a graph G = (V, E) where the vertex
set V represents the nodes, each positioned uniformly at random in
a simulation area of 600 × 3000 m. Each node is equipped with
an omnidirectional antenna with transmission range modelled by a
circle of radius 250 m. There is an edge (vi , vj ) ∈ E representing
a communication link between nodes vi and vj if the nodes are
within transmission range of one another.
The number of nodes ranges from a relatively sparse node density of about 27 nodes/km2 to about 111 nodes/km2 . The node
speeds considered range from a bicycle speed of 5 m/s = 18 km/hr
to a vehicle speed of 20 m/s = 72 km/hr.
Given 64 mobility trace files, three replicates for each are produced. Thus there is a total of 192 mobility trace files. An ns-2
simulation is run for 700 s on each trace file. As the simulation
runs, snapshots of the graph topology are taken periodically. The
polling rate is dependent on node speed and transmission range because when nodes move faster, the polling rate must be higher since
the topology changes faster. 100 samples are taken over the time it
takes for a node to travel a distance equal to its transmission range.
Since the results of the Redback analysis depend on the mobility
model, we briefly overview each one used.

Figure 7: Tempe map and corresponding freeway map.

3.1.4 Manhattan Mobility Model
Bai et al. also proposed the MH mobility model [2]. Similar to
the FW model it uses a map to model vehicle movement. The map
is made up of a number of horizontal and vertical streets and avenues in an urban area. Each street and avenue has two lanes, one
in each direction. A node is allowed to move along the direction of
the street or avenue. However, when a node reaches an intersection

39

in N (v). Use k(v) and e(v) to denote the numbers of vertices and
edges in N (v). The clustering coefficient γv of v is:

it can turn or continue moving in the same direction. This choice is
probabilistic, with the probability of turning left or right each equal
to 0.25 and the probability of moving in the same direction equal
to 0.5. As in the FW mobility model, nodes are not allowed to
change lanes and are limited by the same inter- and intra-node relationships. However, nodes can change direction. The MH mobility
model is also expected to have spatial and temporal dependence
[2]. The map used as input to the MH model is a 6 × 30 grid of
streets and avenues.

e(v)
γv = `k(v)´ =
2

In words, γv is the number of edges between neighbours of v divided by the maximum possible number of edges. The clustering
coefficient (CC) of a graph G is the mean of the clustering coefficient of all vertices of G and is denoted γ(G).
For the graph Gi+1 in Figure 8, γ(Gi+1 ) = 0.12.

3.2 Processing Steps in Redback
We describe the distance and metric measures studied in Redback that appear useful for MANETs.

3.2.4 Edge Count Metric Measure
The edge count e(G) of a graph G = (V, E) is simply e(G) =
|E|. For the graphs in Figure 8, e(Gi ) = 7 and e(Gi+1 ) = 8.

3.2.1 Graph Diameter Distance Measure
For G = (V, E), let d(u, v), denote the length of the shortest path from u to v. The eccentricity of a vertex u, (u), is
the longest shortest path from u to any other vertex in the graph,
maxv∈V d(u, v). The graph theoretic definition of diameter is the
maximum of the vertex eccentricities, maxu,v∈V d(u, v) [23].
In Redback, the macroscopic structure of the graph is of interest. Hence, the diameterPis defined as the average over all vertex
eccentricities: D(G) = v∈V (v)/|V |.
Figure 8 shows two graphs Gi and Gi+1 in a graph series. D(Gi ) =
3.28. In graph Gi+1 , vertex 7 has degree 2 reducing the eccentricity with a resulting decrease in D(Gi+1 ) to 3. Since graph diameter
is a distance measure |D(Gi ) − D(Gi+1 )| = 0.28.
1

1

2

6

3

5

2

6

7

5

3
7

4

4

Figure 8: Example for diameter, CC, EC measures.

7

3.3.1 Graph Diameter
Gaston et al. [11] discuss some theoretical properties of the graph
diameter measure and some sensitivities it has for detecting change
in networks. One observation made is that graph diameter is sensitive to small changes in sparse graphs and less sensitive for small
changes in near complete graphs.
Figure 10 shows the series charts for the RWP mobility model.
In agreement with [11], the sparse scenarios have larger changes in
diameter (more than 7 for 5 m/s) and exhibit more variance in the
diameter value. In the denser scenarios the change in the diameter
is greatly reduced (less than 1 in all cases). The changes in diameter
decrease with increasing node speed.

3.3.3 Clustering Coefficient
CC for a vertex is the proportion of edges between the vertices
within its neighbourhood divided by the number of edges that could
possibly exist between them.2
For the RPG mobility model, Figure 12 shows that the CC oscillates in value for the sparse and slow scenario. When more nodes
are added this behaviour disappears and the mean value shows no
significant variance over the course of the simulation. Indeed, this
metric exhibits the lowest variance of all measures studied. At high
density, both series charts show only a gradual change in value with
the mean value independent of node speed.

4

3

We now present a very small sample of the series charts for
the graph series collected and then processed in Redback. For
each measure we select a representative example from one mobility
model.1 Each figure shows four series charts arranged in two rows;
the first row has 50 nodes while the second row has 200 nodes in
the scenario. The left column has node speed 5 m/s and the right
column has node speed 20 m/s.

CPL is a measure of node connectivity. Figure 11 shows that for
the FW mobility model the variance in the CPL for the low density
scenario is quite high independent of node speed. At both speeds,
the mean value of CPL is similar. At higher density, the variance
in the CPL is greatly reduced and, again, has about the same mean
value independent of node speed.

Let d(u) denote the mean value of d(u, v) over all vertices v connected to, but not adjacent to, u, i.e., all vertices v where d(u, v) ≥
2. Then, the characteristic path length (CPL) L(G) of a graph G
is the median of d(u) over all vertices u ∈ V .
As an example, the characteristic path length for the graph G in
Figure 9 is L(G) = 2.25.

1

3.3 Analysis of Redback Series Charts

3.3.2 Characteristic Path Length

3.2.2 Characteristic Path Length Metric Measure

2

2 · e(v)
.
k(v) · (k(v) − 1)

5

6

Figure 9: Graph for CPL example.

3.3.4 Edge Count
3.2.3 Clustering Coefficient Metric Measure

1
Due to space constraints, the series charts for the other mobility
models are available on request.
2
Redback does not distinguish undirected and directed graphs in
the clustering coefficient computation, hence 0 ≤ γ(G) ≤ 2.

The neighbourhood N (v) of a vertex v consists of all the vertices
adjacent to v. The graph generated by N (v), N (v) has vertex set
N (v) and its edges are all edges of the graph with both endpoints

40

Figure 10: Graph diameter for the RWP mobility model.

4. CONCLUSIONS

At low node density, the RPG mobility model has nearly twice
as many edges than any of the other mobility models (not shown).
The mean value increases as a function of node speed, and increases
significantly as a function of node density (as much as ten times).
However at high density, the mean value decreases as a function of
speed. Regardless of density, the variance in edge count is high.
The MH mobility model has the lowest mean value of edges
counts. The mean value of edge count is independent of node speed
and node density, however the variance is very high.

We presented an application of the Redback network dynamics
analysis tool to MANETs. Our goal was to understand the network
properties that arise from different mobility models, node densities and node speeds, and to quantify how these differences impact
communications. We find measurable differences among the models evaluated that may impact mobile communications and influence protocol design. However, our work raises more questions
than it answers, providing many avenues for future research.

3.3.5 Discussion

Acknowledgments

From the results in §3.3, it is evident that there are measurable
differences among mobility models. Such offline processing of
these and similar metrics using Redback could be extremely valuable to understand before protocols are designed. It may also be
used to validate the theoretical properties of mobility models.
While offline processing is certainly useful, a graph series could
also be constructed online for the purpose of adaptation. In MANETs,
many network layer protocols already collect one-hop or even twohop neighbourhood information. Such a neighbourhood is nothing
more than a subgraph of the graph that corresponds to the network
topology. Maintaining a finite length neighbourhood graph series
and analyzing it for changes could indicate when and where adaptation in the network is required. In addition to topology information,
queue lengths and edge weights representing flow identifiers and
requirements could even be useful in support of quality-of-service.
Most of the current metrics studied for change detection observe
traffic or topology changes at the network level. If techniques for
change detection are to be used in an online fashion, measures that
can be computed in a distributed manner and that capture information about the behaviour of the network are required. Our continuing research pursues some of these directions.

V.R. Syrotiuk is supported in part by DSTO contract 4500496906
and NSF grant ITR-0220001.

5. REFERENCES
[1] Cooperative association for internet data analysis.
http://www.caida.org/Tools.
[2] F. Bai, N. Sadagopan, and A. Helmy. IMPORTANT: A framework to
systematically analyze the impact of mobility on performance of
routing protocols for adhoc networks. Ad Hoc Networks,
1(4):383–403, November 2003.
[3] F. Bai, N. Sadagopan, and A. Helmy. User Manual for IMPORTANT
Mobility Tool Generators in ns-2 Simulator. University of Southern
California, February 2004.
http://nile.usc.edu/important/software.htm.
[4] P. Barford and D. Plonka. Characteristics of network traffic flow
anomalies. In Proceedings of the 1st ACM SIGCOMM Workshop on
Internet Measurement, pages 69–73, 2001.
[5] C. Bettstetter, H. Hartenstein, and X. Perez-Costa. Stochastic
properties of the random waypoint mobility model: Epoch length,
direction distribution, and cell change rate. In Proceedings of the
ACM International Workshop on Modeling, Analysis, and Simulation

41

Figure 11: Characteristic path length for FW mobility model.

Figure 12: Clustering coefficient for RPG mobility model.

42

Figure 13: Edge count for MH mobility model.

[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]
[15]

of Wireless and Mobile Systems (MSWiM’02), pages 7–14,
September 2002.
A. Boukerche and L. Bononi. Simulation and modeling of wireless,
mobile, and ad hoc networks. In S. Basagni, M. Conti, S. Giordano,
and I. Stojmenovic, editors, Mobile Ad Hoc Networking, chapter 14,
pages 373–410. IEEE Press and John Wiley & Sons, Inc., 2004.
J. B. D. Cabrera, L. Lewis, X. Qin, W. Lee, R. K. Prasanth,
B. Ravichandran, and R. K. Mehra. Proactive detection of distributed
denial of service attacks using MIB traffic variables – a feasibility
study. In Proceedings of the IEEE/IFIP International Symposium on
Integrated Network Management, May 2001.
T. Camp, J. Boleng, and V. Davies. A survey of mobility models for
ad hoc network research. Wireless Communications and Mobile
Computing, 2(5):483–502, 2002.
K. Chin, J. Judge, A. Williams, and R. Kermode. Implementation
experience with MANET routing protocols. ACM Computer
Communications Review, 32:49–59, November 2002.
P. J. Dickinson, M. Kraetzl, H. Bunke, M. Neuhaus, and A. Dadej.
Similarity measures for hierarchical representations of graphs with
unique node labels. International Journal on Pattern Recognition
and Artificial Intelligence, 18(3):425–442, 2004.
M. E. Gaston, M. Kraetzl, and W. D. Wallis. Using graph diameter
for change detection in dynamic networks. Australasian Journal of
Combinatorics, 35:299–311, 2006.
X. Hong, M. Gerla, G. Pei, and C.-C. Chiang. A group mobility
model for ad hoc wireless networks. In Proceedings of the 2nd ACM
International Workshop on Modeling, Analysis and Simulation of
Wireless and Mobile Systems (MSWiM’99), pages 53–60, 1999.
C. S. Hood and C. Ji. Intelligent network monitoring. In Proceedings
of the IEEE Workshop on Neural Networks for Signal Processing,
pages 521–530, 1995.
C. S. Hood and C. Ji. Proactive network-fault detection. IEEE
Transactions on Reliability, 46(3):333–341, 1997.
A. Jardosh, E. M. Belding-Royer, K. C. Almeroth, and S. Suri.
Towards realistic mobility models for mobile ad hoc networks. In
Proceedings of the 9th Annual ACM International Conference on

[16]

[17]

[18]

[19]

[20]

[21]

[22]
[23]
[24]

[25]

43

Mobile Computing and Networking (Mobicom’03), pages 217–229,
September 2003.
D. B. Johnson and D. A. Maltz. Dynamic source routing in ad hoc
wireless networks. In T. Imielinski and H. Korth, editors, Mobile
Computing, chapter 5, pages 153–181. Kluwer Academic
Publishers, 1996.
M. Johnson, A. Y. Zomaya, and M. Kraetzl. Modelling external
network behaviour using internal measurements. Journal of Parallel
and Distributed Computing, 64:1345–1359, 2004.
A. Lazar, W. Wang, and R. Deng. Models and algorithms for
network fault detection and identification. In Proceedings of the
IEEE International Conference on Communications (ICC’92), pages
999–1003, November 1992.
J.-Y. Le Boudec and M. Vojnovic. Perfect simulation and stationarity
of a class of mobility models. In Proceedings of the 24th Annual
Joint Conference of the IEEE Computer and Communications
Societies (Infocom’05), volume 4, pages 2743–2754, 2005.
L. Lewis. A case based reasoning approach to the management of
faults in communications networks. In Proceedings of the 12th
Annual Joint Conference of the IEEE Computer and
Communications Societies (Infocom’93), volume 3, pages
1422–1429, March 1993.
W. Navidi and T. Camp. Stationary distributions for the random
waypoint mobility model. IEEE Transactions on Mobile Computing,
3(1):99–108, January-March 2004.
Toilers. Random waypoint steady state ns-2 code.
http://toilers.mines.edu/Public/CodeList.
D. B. West. Introduction to Graph Theory. Prentice Hall, Inc., 2
edition, 2001.
J. Yoon, M. Liu, and B. Noble. Random waypoint considered
harmful. In Proceedings of the 22nd Annual Joint Conference of the
IEEE Computer and Communications Societies (Infocom’03), pages
1312–1321, April 2003.
F. Zhang and J. L. Hellerstein. An approach to on-line predictive
detection. In Proceedings of the 8th International Symposium on
Modeling, Analysis, and Simulation of Computer and
Telecommunications Systems, pages 549–556, 2000.

Network Innovators Community Event (GENI NICE 2016)
Mark Berman

Ibrahim Matta

Violet R. Syrotiuk

Vicraj Thomas

Raytheon BBN Technologies
10 Moulton Street
Cambridge, MA 02138
+1 (617) 873-3675

Boston University
111 Cummington Mall
Boston, MA 02215
+1 (617) 358-1062

Arizona State University
P.O. Box 878809
Tempe, AZ 85287
+1 (480) 965-7034

mberman@bbn.com

matta@bu.edu

syrotiuk@asu.edu

Raytheon BBN Technologies
Park Place East, Ste. 630
5775 Wayzata Blvd.
St. Louis Park, MN 55416
+1 (952) 545-5713

vthomas@bbn.com

ABSTRACT
The Network Innovators Community Event (GENI NICE) is the
premier event for researchers to demonstrate and present research
results and to discuss work in progress related to the NSF’s
Global Environment for Network Innovations (GENI) and related
advanced cyberinfrastructure testbeds.

2. The NICE Agenda
This year’s event, NICE 2016, takes place at a particularly
exciting time for this community. As the GENI project begins its
transition to a broader management paradigm, a new, researchdriven consortium is forming to play a key role both in GENI
oversight and in driving the vision of new cyberinfrastructure
research.

Growing out of the strong experiment- and demonstration-driven
tradition of the GENI Engineering Conferences (GECs), NICE
specializes in direct experimenter-to-experimenter interaction and
information exchange. NICE 2016 represents the second year of
NICE, and its first year being held in conjunction with CoNEXT.

This is also a time of great potential for new developments in
advanced research cyberinfrastructure testbeds, as researchers and
sponsors are increasingly converging on key areas to pursue. As
an example, the recent “Looking Beyond the Internet” report [1]
identifies several promising areas for research testbed investment.
One of these areas, city-scale wireless research testbeds, is
addressed in a recently announced White House initiative,
spearheaded by the NSF.

Keywords
GENI; Future Internet; Next generation networking; Future
Internet testbeds; Distributed cloud computing, Edge cloud, Edge
computing; Cellular research networks; Software-defined
exchanges; Software-defined infrastructure.

The NICE community is ideally positioned both to provide input
to and to derive benefit from these important developments, and
this year’s event agenda draws heavily on these topics.

1. The NICE Community
The Network Innovators Community Event (GENI NICE)
provides a venue for a free and rapid exchange of information
among researchers, educators, system builders, and IT
professionals who make, sustain, and use advanced research
cyberinfrastructure testbed environments. These include the
Global Environment for Network Innovations (GENI), as well as
related future Internet and distributed cloud (FIDC) testbeds and
research infrastructures.

Sessions for NICE 2016 include the following.
Opening Session: In addition to the keynote presentation, this
session includes an update on the Future Cyberinfrastructure
Consortium, including the consortium’s mission and goals, as well
as how the community can participate in the consortium.
Session chair: Mark Berman (GENI project office).

NICE brings together multiple interconnected segments of this
dynamic and growing community. In an environment of shared,
distributed cyberinfrastructure, effective and collaborative
interaction among these groups is vital to sustaining rapid
research progress.

Software-Defined Exchanges: This session explores recent
developments and upcoming research in software-defined
exchanges (SDXs) and software-defined infrastructure (SDI).
These interrelated approaches apply software-defined networking
concepts and technology to facilitate the sharing and exchange of
networking and heterogeneous cyberinfrastructure resources.

End users: Researchers and educators who use advanced research
cyberinfrastructure testbeds in their work.

Session chairs: Russ Clark (Georgia Institute of Technology) and
Tom Lehman (University of Maryland).

Testbed builders: Systems researchers and builders who design
and develop new research cyberinfrastructure concepts.

Non-IP Experiments: One of the motivations of Future Internet
and Distributed Cloud (FIDC) testbeds is the ability to conduct
experiments using network protocols that are not compatible with
the standard Internet protocol (IP) or transmission control protocol
(TCP). This session reports on experiments in future Internet
architectures and other research that explore this research space.

Infrastructure owners and operators: Chief information
officers (CIOs) and information technology professionals who
own and operate research cyberinfrastructure on behalf of end
users.

Session chairs: Nirmala Shenoy (Rochester Institute
Technology) and Ibrahim Matta (Boston University).

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for third-party components of this
work must be honored. For all other uses, contact the Owner/Author.
Copyright is held by the owner/author(s).
CoNEXT '16, December 12-15, 2016, Irvine, CA, USA
ACM 978-1-4503-4292-6/16/12.
DOI: http://dx.doi.org/10.1145/2999572.3004860

of

Wireless Experiments: This session addresses recent application
work at campuses using 4G LTE technology. Areas addressed

505

include heterogeneous vehicular networking, cloud-based radio
processing and voice over LTE (VO-LTE) for public safety.

matches the experiment- and demonstration-driven culture of the
NICE community. (See Figure 1.)

Session chairs: Abhimanyu Gosain (GENI project office) and Ivan
Seskar (Rutgers University).

3. ACKNOWLEDGMENTS
GENI and NICE are supported by the National Science
Foundation and the GENI Project Office. Any opinions, findings,
conclusions or recommendations expressed in this material are the
authors’ and do not necessarily reflect the views of the NSF.

Joint Panel Session “Picking the Right Testbed for Your
Experiment”: This joint panel brings together participants from
the NICE community as well as the co-located Cloud-Assisted
Networking (CAN) workshop and CoNEXT student workshop to
discuss the relative benefits of different advanced
cyberinfrastructure research testbeds and comparable commercial
offerings.

Our thanks to the organizers of CoNEXT 2016 for welcoming
NICE to the CoNEXT community.

4. REFERENCES
[1] NSF CISE Looking Beyond the Internet Steering Group.
2016. “Final Report: Looking Beyond the Internet.”

Session chairs: Mike Zink (University of Massachusetts, Amherst)
and Murat Yuksel (University of Central Florida).
Evening demo session: The demo session is a longstanding
tradition extended from the GECs to NICE. It provides an
informal opportunity for information exchange in a style that

Figure 1: Demo Session at NICE 2015

506

Designs, Codes and Cryptography, 32, 65–95, 2004
# 2004 Kluwer Academic Publishers. Manufactured in The Netherlands.

Cover-Free Families and Topology-Transparent
Scheduling for MANETs
CHARLES J. COLBOURN
colbourn@asu.edu
Computer Science and Engineering, Arizona State University, Tempe, AZ 85287-8809, U.S.A.
ALAN C. H. LING
Computer Science, University of Vermont, Burlington, VT 05405, U.S.A.

aling@emba.uvm.edu

VIOLET R. SYROTIUK
syrotiuk@asu.edu
Computer Science and Engineering, Arizona State University, Tempe, AZ 85287-8809, U.S.A.
Abstract. We examine the combinatorial requirements of topology-transparent transmission schedules in
a mobile ad hoc network (MANET). Speciﬁcally, if each of the N nodes has at most D active neighbors, we
require the schedule to guarantee a collision-free transmission to each neighbor. This requirement is met
by a cover-free family. We show that existing constructions for topology-transparent schedules correspond
to an orthogonal array. Moreover, we show that Steiner systems support the largest number of nodes for a
given schedule length. Both of these combinatorial objects are special cases of cover-free families.
Analytically and numerically, we examine slot guarantees, expected throughput, and normalized expected
throughput for systems of small strength, exploring the sensitivity of the response to D. Expected
throughput provides a better performance metric than the minimum throughput results obtained earlier.
The impact of a more realistic model of acknowledgments is also examined. The extension of the schedule
to multiple frames returns us to the orthogonal arrays. The very density of Steiner systems that afforded an
improvement over orthogonal arrays in one frame impedes the best extension to more frames.
Keywords: orthogonal array, Steiner system, cover-free family, disjunct matrix, topology-transparency,
mobile ad hoc network

1. Introduction
A mobile ad hoc network (MANET) is a collection of mobile wireless nodes that
self-organize without the aid of any centralized control or any ﬁxed infrastructure.
Since the nodes communicate over a shared broadcast channel, a medium access
control (MAC) protocol is responsible for controlling access to the communication
resources. As a result, the MAC protocol is essential to the overall performance of
the network.
In a MANET, the radio transmission range of each node is limited since the nodes
are battery-operated. While this may require a packet to be forwarded over multiple

66

COLBOURN ET AL.

hops for it to reach its destination, this limitation also allows for the possibility of
spatial reuse. This means that nodes sufﬁciently far enough apart may transmit
concurrently because their transmissions do not propagate far enough to interfere.
Most MAC protocols for MANETs attempt to exploit the potential for spatial reuse
in order to satisfy two primary objectives: minimizing delay and maximizing
throughput on a per hop basis.
A spectrum of MAC protocols exists in an effort to meet these objectives [23]. In
general, the type of protocol can be categorized as either contention or allocation. In
a contention based protocol, nodes share the channel in a manner than can lead to
conﬂicts. In an allocation based protocol the competition for the channel is resolved
without collision (two or more overlapping transmissions).
The general conclusion is that higher throughput may be obtained at the cost of
poorer guarantees on delay. Contention based approaches, such as IEEE 802.11 [1],
are prevalent in MANETs due to their simplicity and lack of synchronization
requirements. While such protocols achieve high throughput with a reasonable
expected delay, in the worst-case the delay is very poor. As the interest in delay
sensitive applications such as voice and video grows, the MAC protocol must be
quality-of-service (QoS) aware, that is, it must provide a delay guarantee to real-time
trafﬁc. As a result, a number of ideas to support both real-time and best-effort trafﬁc
in IEEE 802.11 have emerged; however, in each case [5,18,20], the delay guarantee
remains probabilistic. The fact is that to obtain a deterministic delay guarantee, an
allocation approach is necessary.
The simplest solution, a time division multiple access (TDMA) protocol, gives
every node in the network the entire bandwidth for a short time. While TDMA
provides a delay bound, it does not meet a reasonable throughput objective because
it does not take advantage of the potential for spatial reuse. There are two
approaches to take advantage of this potential, resulting in hybrid protocols that
combine contention with allocation. Topology-dependent hybrids alternate between
a contention phase in which neighbor information is collected, and an allocation
phase in which nodes transmit according to a schedule constructed using the
neighbor information (see, as examples, Chlamtac and Pinter [8] and Zhu and
Corson [26]). These topology-dependent MAC protocols can be unstable under high
load or mobility conditions, becoming unable to converge on a new schedule, and as
a result lose their delay guarantee and ability to deliver packets. Myers et al. [17]
propose a scheme to utilize slots in TDMA assigned to others without interfering
with the guaranteed slot allocation; however, the cost is a lengthening of the basic
time slot.
Alternatively, topology-transparent hybrids do not use any neighbor information.
The existing topology-transparent access protocols [6,16] depend on two design
parameters: N, the number of nodes in the network, and D, the maximum active
node degree and construct a schedule to guarantee at least one collision-free
transmission to each neighbor. This creates complex trade-offs between the design
parameters and the delay and throughput characteristics of the resulting schedules.
While it is often possible to construct schedules that are signiﬁcantly shorter than
TDMA, if the actual node degree exceeds D, contention among the assigned slots

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

67

results in too many collisions and consequently the loss of the delay guarantee (as we
shall see, it becomes probabilistic rather than deterministic).
In this paper we examine the combinatorial requirements of topology-transparent
transmission schedules. The solution to the combinatorial question is a cover-free
family.
We generalize the known topology-transparent MAC protocols by observing that
their transmission schedule corresponds to an orthogonal array. We then show that a
Steiner system supports the largest number of nodes for a given frame length. Both
orthogonal arrays and Steiner systems are speciﬁc types of cover-free families.
Combinatorial designs arise in many networking applications [10]; indeed they arise
in other problems within mobile ad hoc networking [25].
For orthogonal arrays and Steiner systems of small strength, we provide a
frame by frame analysis in which we compute slot guarantees and expected
throughput. Perhaps unexpectedly, we also show that for schedules that arise from
orthogonal arrays of strength two and three, the expected throughput is
independent of the number of subframes. For Steiner systems, we propose a
more realistic model for acknowledgments, i.e., frame acknowledgments, and
investigate the effect on expected throughput. Overall, expected throughput
provides a more meaningful metric of performance than the minimum throughput
computed earlier. We also discuss how to extend the analysis to systems of higher
strength.
The analytical results are explored computationally, for selected orthogonal arrays
and Steiner systems, in order to identify trade-offs for topology-transparent
protocols. In particular, the degradation of throughput is investigated as the active
node degree exceeds the design parameter D.
The question of what should be done if the protocol fails is important. In
Chlamtac et al. [7] protocol threading is proposed to address such failures
however the delay bound of the resulting schedule exceeds TDMA and is
therefore ineffective. We extend the schedule to multiple frames and ﬁnd that this
returns us to orthogonal arrays. The density of Steiner systems that afforded an
improvement over orthogonal arrays in a single frame impedes the best extension
to more frames.
The rest of this paper is organized as follows. Section 2 ﬁrst examines the
combinatorial requirements of a topology-transparent transmission schedule,
and shows that cover-free families, including orthogonal arrays and Steiner
systems, satisfy the requirements. In Section 3 we derive analytical expressions
for the probability of a successful transmission in a frame, and for the
expected throughput. Corresponding numerical results are presented in Section
4, noting the sensitivity of the actual node degree to the design parameter D.
For Steiner systems, we also consider both minimum and expected throughput
using a more realistic acknowledgment model. An extension to multiple
frames for the case when D is exceeded is discussed in Section 5. Lastly, in
Section 6, we summarize our results, outline continuing research, and
conclude.

68

COLBOURN ET AL.

2. Cover-Free Families, Orthogonal Arrays, and Steiner Systems
2.1.

The Network Model

In this paper, the MANET is modeled by a graph g ¼ ðV; eÞ where the vertex set V
represents the nodes, and the edge set e represents the communication links. We use
N to denote the number of nodes in the network, that is, N ¼ jVj.
Each node is equipped with an omnidirectional antenna with transmission
modeled by a circle of radius r. There is an edge ðvi ; vj Þ [ e between nodes vi and vj if
the distance separating the nodes is within the transmission range, that is, if
distðvi ; vj Þ  r. (In this work, we do not consider unidirectional links.) If vi is adjacent
to vj then vj is a (one-hop) neighbor of vi . The degree dðvi Þ of a vertex vi corresponds
to its neighborhood size. The maximum node degree of the MANET g is
D ¼ maxN1
i¼0 dðvi Þ.
The transceiver at each node is half-duplex, meaning that it is not possible to both
transmit and receive concurrently. This introduces new problems such as the hidden
terminal problem. The hidden terminal problem occurs when the destination vj of a
transmitting node vi suffers a collision because of an interfering transmission from
another node vk not in the transmission range of vi . Node vk is hidden to vi ; as a
result, some strategy is required to inform vi of the outcome of its transmission.
We also assume that two or more overlapping transmissions to a receiver result in
a collision. In other words, none of the overlapping packets are correctly received, or
captured; that is, no capture effect is modeled.
We assume that time is divided into discrete units called slots. A schedule (or
frame) S is described by a binary vector s0 s1 . . . sn1 with one element for each slot in
the frame (i.e., the frame length is n). Typically, each node in the network is assigned
a unique schedule that it uses in a cyclically repeated way. That is, the nodes are
synchronized on frame boundaries, and if si ¼ 1 then the node may transmit in slot
k, where k:ði mod nÞ; otherwise the node is silent (and could receive).

2.2.

Combinatorial Requirements

Rather than starting with existing constructions for topology-transparent transmission schedules, let us instead begin anew by turning the problem of generating a
topology-transparent transmission schedule into a combinatorial question.
In designing a topology-transparent transmission schedule with design parameters
N, the number of nodes in the network and D, the maximum node degree, we are
interested in the following combinatorial property. For each node, we want to
guarantee that if a node vi has at most D neighbors its schedule Si guarantees a
collision-free transmission to each neighbor.
Let us treat each schedule Si as a subset Ti on f0; 1; . . . ; n  1g by assigning the
elements of the subset to correspond to the positions in the schedule, that is, j [ Ti if
sj ¼ 1 in Si ; j ¼ 0; . . . ; n  1 (in essence, Si is the characteristic vector of the set Ti ).
Now, the combinatorial problem to ask is for each node vi to be given a subset Ti

69

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

with the property that the union of D or fewer other subsets cannot contain Ti .
Expressed mathematically, if Tj ; j ¼ 1; . . . ; D, are D neighbors of vi ðTj 6¼ Ti Þ, then
we require that
[D

T
6 Ti :
j
j¼1
This is precisely a D cover-free family. These are equivalent to disjunct matrices [12]
and to certain superimposed codes [13]; see Colbourn et al. [10].
The existing constructions for topology-transparent transmission schedules [6,16],
as we showed in Syrotiuk et al. [22], correspond to an orthogonal array; indeed, they
correspond to a cover-free family.

2.3.

An Orthogonal Array gives a Cover-Free Family

The theory of orthogonal arrays relates combinatorics, ﬁnite ﬁelds, geometry and
error-correcting codes. The prominent role of orthogonal arrays as been in the
design of experiments, for example in medical applications such as pharmaceutical
companies investigating the stability and shelf-life of drugs, drug interaction, and in
clinical trials to study how drugs are absorbed, metabolized, and eliminated from the
body.
Let V be a set of v symbols, usually denoted by 0; 1; . . . ; v  1.
Deﬁnition 2.1. A k6vt array A with entries from V is an orthogonal array with v
levels and strength t (for some t in the range 0  t  k) if every t6vt subarray of A
contains each t-tuple based on V exactly once (we assume the index l ¼ 1) as a
column. We denote such an array by OAðt; k; vÞ.
Table 1 shows an example from Hedayat et al. [15] of an orthogonal array
OAð2; 4; 4Þ of strength two with v ¼ 4 levels, that is, V ¼ f0; 1; 2; 3g. Select any two
rows, say the third and the fourth. Each of the sixteen ordered pairs ðx; yÞ; x; y [ V
appears the same number of times, once in this case.
Each column, called a codeword, gives rise to a transmission schedule. In our
application, that of assigning transmission schedules to nodes, the number of
columns in the orthogonal array is an upper bound on the number of nodes in the
network. Each codeword intersects every other in fewer than t positions. For
example, the ﬁrst and the eighth column intersect in no positions, while the ﬁrst and
the second column intersect in a zero in the ﬁrst position (row).
Table 1. Orthogonal array OAð2; 4; 4Þ.
0
0
0
0

0
1
1
1

0
2
2
3

0
3
3
2

1
0
1
3

1
1
0
2

1
2
3
0

1
3
2
1

2
0
2
2

2
1
3
3

2
2
0
1

2
3
1
0

3
0
3
1

3
1
2
0

3
2
1
2

3
3
0
3

70

COLBOURN ET AL.

The importance of this intersection property is as follows. Select any column.
Since any of the other columns can intersect it in at most t  1 positions, any
collection of D other columns has the property that our given column differs from all
of these D in at least k  Dðt  1Þ positions. Provided this difference is positive, the
column therefore contains at least one symbol appearing in that position, not
occurring in any of the D columns in the same position. In our application this
means that at least one collision-free slot to each neighbor exists when a node has at
most D neighbors. Thus, as long as the number of neighbors is bounded by D, the
delay to reach each neighbor is bounded, even when each neighbor is transmitting.
Clearly, the orthogonal array gives a D cover-free family.

2.3.1.

Construction of Schedules using OAs

A large number of techniques are known for constructing orthogonal arrays, usually
classiﬁed by the essential ideas that underlie them. There is a classic construction
based on Galois ﬁelds and ﬁnite geometries; both Chlamtac and Faragó [6] and Ju
and Li [16] use this construction implicitly though neither observed that what they
were constructing was an orthogonal array.
Given a codeword W,that is, a column of length k from the orthogonal array, the
corresponding schedule is constructed as follows. Each symbol wi in W ¼
w0 w1 . . . wk1 gives rise to a binary subframe Fi of length v (since each symbol is
from the set V). Speciﬁcally, Fi ½wi  ¼ 1 for i ¼ 0; . . . ; v  1 and Fi ½ j ¼ 0 otherwise.
The schedule S is a k ? v binary array made up of the concatenated subframes, i.e.,
S ¼ F0 F1 . . . Fk1 (in Chlamtac and Faragó [6] and Ju and Li [16], k ¼ v so jSj ¼ v2 ).
Figure 1 shows an example of a schedule constructed from a codeword.
We observe an important point: The resulting transmission schedules do not
depend on the construction of the orthogonal array. We are just exploiting the
combinatorial properties of the orthogonal array itself. We explore this observation
in the following section.

2.3.2.

Properties of Orthogonal Arrays

By deﬁnition, if we look along t rows of an orthogonal array, every t-tuple is found
exactly once. However, for our application, what is important is that when we pick

Figure 1. Construction of schedule from codeword 1230.

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

71

any t columns, they cannot agree in any more than t  1 rows. It is the absence of
agreement that we exploit.
There is a substantial body of knowledge on the existence of orthogonal arrays
[9,15]. Among the classical results in the area is that whenever an OAðt; k; vÞ exists,
an OAðt; k  1; vÞ exists (simply omit a row). More interesting, if an OAð2; v; vÞ exists
then there is an OAð2; v þ 1; vÞ. This is interesting because the published schemes
[6,16] both employ OAðt; v; vÞs in their construction. This result immediately gives
rise to an orthogonal array with codewords of length v þ 1 from which schedules of
length vðv þ 1Þ are constructed. This immediately enhances the guarantee on
minimum throughput of Ju and Li [16].
Both Chlamtac and Faragó [6] and Ju and Li [16] employ OAðt; v; vÞs when v is a
prime power. They therefore restrict attention to the case when k ¼ v (forcing all
frame lengths to be v2 unnecessarily), and indeed by not permitting that k > v they
do not obtain the best delay guarantees. The restriction of v to prime powers is also
not required, as orthogonal arrays exist for these cases, for example, OAð2; 7; 12Þ,
but k is not as large in general.
In the same way that allowing different parameters for orthogonal arrays allows
more ﬂexibility in the corresponding schedules, relaxing the parameters further and
asking for a cover-free family allows more ﬂexibility yet.

2.4.

Steiner Systems

Cover-free families have been studied extensively, most frequently with the objective
of maximizing the number of sets in the family. In our application, this corresponds
to maximizing the number of nodes, so this is certainly a parameter of interest.
There is a celebrated result of Erdös et al. [14] that established bounds on the size
of a cover-free family (see also, Ruszinkó [19] and Stinson et al. [21] and Theorem
7.3.9 in Du and Hwang [12]). Speciﬁcally, they established that the extreme value on
the size, if achievable, is realized by a Steiner system. Hence in terms of the
application, for a given number of nodes and a given maximum number of
neighbors, Steiner systems achieve the shortest frame length of all cover-free families.
Thus, they provide not only a solution to our problem, but indeed the best solution
in terms of frame length.
Deﬁnition 2.2. Given three integers t; k; v such that 2  t < k < v, a Steiner system
Sðt; k; vÞ is a v-set V together with a family b of k-subsets of V (blocks) with the
property that every t-subset of V is contained in exactly one block.
Table 2 shows an example from Colbourn and Dinitz [9] of a Steiner system on the
13-set V ¼ f0; 1; . . . ; 9; a; b; cg together with a family of vðv  1Þ=kðk  1Þ ¼
13 ? 12=4 ? 3 ¼ 13, 4-subsets of V (the columns). This Steiner system has the property
that every 2-subset of V; fx; yg; x; y [ V; x 6¼ y is contained in exactly one column.

72

COLBOURN ET AL.

Table 2. Steiner system Sð2; 4; 13Þ.
0
1
3
9

0
2
8
c

0
4
5
7

0
6
a
b

1
2
4
a

1
5
6
8

1
7
b
c

2
3
5
b

2
6
7
9

3
4
6
c

3
7
8
a

4
8
9
b

5
9
a
c

While a substantial amount is known about the existence of Steiner systems, in
general their existence is not settled [9]. As with orthogonal arrays, there are
constructions from ﬁnite ﬁelds.
Reasons that Steiner systems are of interest for constructing topology-transparent
transmission schedules include:
1. Steiner systems admit shorter schedules than orthogonal arrays. This is important
since in addition to achieving high throughput, the delay bound is improved. We
discuss this issue at length in Section 3.
2. Steiner systems are denser than orthogonal arrays. They can support a larger
number of nodes for a given schedule (frame) length.
In a similar way, since orthogonal arrays have the property of balanced occurrences
of t-tuples, this also forces the intersections of codewords to be balanced. We
demonstrate this next and then exploit it to examine the success probability within a
frame and expected throughput.

3. Covering Functions
The essential difference between the Chlamtac and Faragó [6] and the Ju and Li [16]
papers is in the selection of parameters. In Chlamtac and Faragó [6], the focus is on
frame length while in Ju and Li [16] the focus is on throughput.
More speciﬁcally, in Chlamtac and Faragó [6], the ﬁrst vt  N; t  2 is found,
where v is a prime power. In the paper, the interest is in minimizing the frame (or
schedule) length in order to minimize delay. The parameters are selected to ﬁnd a
schedule provably shorter than TDMA.
In Ju and Li [16], it is argued that the parameters chosen satisfy the condition on
delay, but do not maximize minimum throughput. In particular, it is possible to
achieve higher minimum
throughput at the expense
pﬃﬃﬃﬃ
pﬃﬃﬃﬃof longer frame length. They
select v ¼ 2ðt  1ÞD if t N  2ðt  1ÞD, and v ¼ t N otherwise. Intuitively, while
Chlamtac and Faragó [6] strive to get one free slot per frame, Ju and Li [16] aim to
get many free slots per frame.
In this section we investigate two questions:
1. What is the probability of a successful transmission in a frame?

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

73

2. What is the expected throughput? Neither Chlamtac and Faragó [6] nor Ju and Li
[16] discuss expected throughput, only maximizing minimum throughput.
The answers to both questions are functions of the number of active transmitters
among the neighbors of a node. We assume that the neighbors of a node are chosen
uniformly at random.

3.1.

Covering Functions for Orthogonal Arrays

Consider a situation with sender s and receiver r. Let S be a schedule for sender s
and S1 ; . . . ; SD1 be the schedules of the other active neighbors of r (here, we
assume the worst case, when all neighbors have a packet to transmit). Let SD be the
schedule for r, and assume that r is also active.
To make our questions precise, the probability of successful transmission within a
frame is just the probability that S has a slot that does not appear in S1 ; . . . ; SD
(more exactly, S1 þ S2 þ    þ SD , where the addition operator denotes the binary
‘‘or’’ operation). Expected throughput then, is simply the expected number of such
slots. We employ an ordinary generating function to enumerate and classify the
selections of D neighbors.
For an OAðt; k; vÞ let

fðw; t; k; vÞ ¼

vt 1
X

ðwÞ

Ci xi ;

i¼0
ðwÞ

where Ci denotes the number of ways for a given codeword W to select i other
codewords whose union intersects W in precisely w speciﬁc positions. We call this the
w-covering function.
If we can calculate the w-covering functions, then
"

ðkÞ

Ci

1  vt 1

#

i

is the probability that if a node has i neighbors, then it retains at least one free slot
(calculated
as 1  Pr[no free slot]). If w entries are covered then k  w are free. There
 
are wk ways to choose the w covered. The frame length is kv so with i neighbors,
expected throughput is
k
X
w¼0

k
ðk  wÞ ?

ðwÞ

?C
vt 1i

w

i

?

1
:
kv

74

COLBOURN ET AL.

3.1.1.

Covering Functions for OAð2; k; vÞ

THEOREM 3.1. For an OAð2; k; vÞ, the w-covering function fðw; 2; k; vÞ for w covered
slots in a frame is
fðw; 2; k; vÞ ¼ ½ðx þ 1Þv1  1w ? ½x þ 1ðv1Þðvþ1kÞ :
Proof. In order to calculate fðw; t; k; vÞ for t ¼ 2, i.e., for an OAð2; k; vÞ, we
consider a ﬁxed codeword W and we partition the remaining set of codewords into
three different sets according to their intersection with W. To deﬁne this partition,
we ﬁrst collect some observations.
. Every other codeword intersects W in zero or in one position (it cannot be more
since t ¼ 2).
. The number of codewords intersecting in a speciﬁc position of W is v  1.
. The number of codewords intersecting W in exactly one position is kðv  1Þ, since
no codeword intersects W in two or more positions.
Therefore, the number of codewords disjoint from W is
v2  1  kðv  1Þ ¼ ðv  1Þðv þ 1  kÞ:
Now, consider w speciﬁc positions of W. We partition the codewords other than
W into three different sets:
1. codewords intersecting W in one of the w speciﬁed positions;
2. codewords intersecting W in one of the remaining k  w positions; and
3. codewords not intersecting W.
There are wðv  1Þ codewords in the ﬁrst class, ðk  wÞðv  1Þ codewords in the
second, and ðv  1Þðv þ 1  kÞ in the third.
We ﬁrst determine simpler generating functions for each class. We use x here as a
single indicator function, where x indicates a selection of a codeword and 1 its
omission; hence the exponent of x indicates the number of codewords selected while
the coefﬁcient indicates the number of ways to make this selection.
1. Each of the w positions must be covered. For each single position to be covered,
we obtain
ðx þ 1Þv1  1:
In essence this says that we can select any codeword or omit it, but we cannot
choose to omit all of them—hence the  1 term. For w positions to be covered, we

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

75

therefore obtain
½ðx þ 1Þv1  1w :
2. Each of the other k  w positions are not covered; we obtain
ð1ðv1Þ ÞðkwÞ ¼ 1:
3. Each disjoint block can be chosen or not:
ðx þ 1Þðv1Þðvþ1kÞ :
Multiplying these expressions for each class, we obtain the w-covering function for
k ¼ 2:
fðx; 2; k; vÞ ¼ ½ðx þ 1Þv1  1w ? ½x þ 1ðv1Þðvþ1kÞ :

3.1.2.

j

Covering Functions for OAð3; k; vÞ

In order to calculate fðw; t; k; vÞ for t ¼ 3, the same type of decomposition as for
t ¼ 2 is used. Consider a ﬁxed codeword W. Every other codeword intersects in zero,
one, or in two positions (points):
1. The number that intersect W in
 two speciﬁc positions is v  1, so the number that
intersect in two positions is k2 ðv  1Þ. The number that intersect in two positions
of which one is ﬁxed is ðk  1Þðv  1Þ.
2. The number that intersect W in a speciﬁc position must be v2  1 in total but this
includes those intersecting in two positions, so the number intersecting in exactly
this speciﬁc position is
v2  1  ðk  1Þðv  1Þ ¼ ðv  1Þðv þ 2  kÞ:
Therefore, the number that intersect W in exactly one (unspeciﬁed) position is
kðv  1Þðv þ 2  kÞ.
3. The number disjoint from W is then
v3  1  kðv  1Þðv þ 2  kÞ 

 
k
ðv  1Þ:
2

76

COLBOURN ET AL.

Figure 2. Initial partition of codeword W.

In order to calculate the covering function, we develop a recurrence using an
auxiliary generating function. Consider a ﬁxed codeword. We partition its k points
into four classes (see Figure 2), according to the coverage of the point by codewords
already considered:
completed: c of the points (shown as black circles) are covered, and all codewords
containing one or more of these points have been considered;
open: y points remain to be covered (shown as white squares), and no codeword
containing these has been considered;
shadowed: s of the points (shown as black squares) are covered, and all codewords
containing one of these points and not one of the y points yet to cover have been
considered; and
exterior: u points are not to be covered (shown as white circles).
In developing the recurrence for the covering function, we reﬁne the class of open
points, until no open points remain. In a partition with no open points, all shadowed
points are completed as well, and we have treated all codewords. Now codewords
containing exterior points can never be selected and hence we can treat all such
codewords as having been considered; thus, while completed and exterior points
serve a different role, we need not distinguish them in the parameters for the
recurrence. Hence we deﬁne cðs; y; t; k; vÞ to be the generating function in the
variable x in which the coefﬁcient of xi is the number of ways to select i codewords to
cover s þ y speciﬁc points in W, when the codewords available consist of all of those
involving at least one of the y open points, and none of the completed or exterior
points.
It follows that the w-covering function fðw; 3; k; vÞ satisﬁes:
fðw; 3; k; vÞ ¼ ðx þ 1Þv

3

1kðv1Þðvþ2kÞðk2Þðv1Þ

?

 
k
? cð0; w; 3; k; vÞ:
w

This results from (1) allowing all codewords disjoint from W to be selected or not;
(2) selecting w of the points to be covered; and (3) prohibiting any codeword meeting
the k  w open points from being selected. Then in the auxiliary function c; k  w
points are exterior, w are open, and none are shadowed or completed.
Next we treat some boundary cases for cðs; y; 3; k; vÞ. When y ¼ 0, no codewords
remain to be considered, and so cðs; 0; 3; k; vÞ ¼ 1. When y ¼ 1, there is a single open

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

77

Figure 3. Reﬁning partition of codeword.

point. Codewords meeting W only in this point must be considered, and codewords
meeting W in this point and one other point that is shadowed must also be
considered. The open point must be covered by one of these, and so
cðs; 1; 3; k; vÞ ¼ ðx þ 1Þsðv1Þþðvþ2kÞðv1Þ  1.
Now we develop the recurrence for c when the number of open points exceeds
one. Our strategy is to examine one speciﬁc open point p in W, and to make it
completed. In the process, we treat all codewords containing p that remain to be
considered; more precisely, we examine all codewords that contain p but do not
contain a completed or exterior point.
In handling these codewords, it may happen that we shadow further open points.
We therefore partition the cases that remain according to the number z of points that
remain open after treating the codewords containing p. We ﬁrst treat the case when
at least one further point becomes shadowed. There are y1
ways to partition the y
z
open points into one to complete, m ¼ y  1  z to shadow, and z to remain open. It
must happen that y  1  z ¼ m previously open points become shadowed in
treating these codewords. Now for a speciﬁc open point to become shadowed in this
process, one of the v  1 codewords containing it together with p must be selected,
contributing ðx þ 1Þðv1Þ  1; extending this to all points that become shadowed, we
have ððx þ 1Þðv1Þ  1Þy1z .
Since some codeword containing p is selected among the codewords shadowing
other open points, we are free to select or not any codeword containing exactly one
point in W from the one point becoming completed, and the y  1  z becoming
shadowed. This contributes ðx þ 1ÞðyzÞðvþ2kÞðv1Þ . All codewords meeting W both in
a previously shadowed point and in either p or a newly shadowed point, must now be
considered; these can be selected or not, contributing ðx þ 1ÞsðyzÞðv1Þ . All
codewords meeting W
in two newly shadowed points can be selected or not,
y1z
contributing ðx þ 1Þð 2 Þ . At this point, all codewords that do not contain one of
the z points left open have been considered, and all codewords containing p have
been considered. So to treat the rest of the codewords, we recurse by calculating
cðs þ m; z; 3; k; vÞ.
When z ¼ y  1, no new point becomes shadowed, and hence p must be covered
by a codeword intersecting W only in p, or one intersecting in p and a previously
shadowed point. Hence when z ¼ y  1 we calculate


ðx þ 1Þsðv1Þþðvþ2kÞðv1Þ  1 cðs; y  1; 3; k; vÞ:

78

COLBOURN ET AL.

Now we combine these calculations to obtain the recurrence


cðs; y; 3; k; vÞ ¼ ðx þ 1Þsðv1Þþðvþ2kÞðv1Þ  1 cðs; y  1; 3; k; vÞ

y2 
X
y1
þ
ððx þ 1Þðv1Þ  1Þy1z cðs þ y  1  z; z; 3; k; vÞ
z
z¼0
ðx þ 1ÞðyzÞðvþ2kÞðv1ÞþsðyzÞðv1Þþð

Þ:

y1z
2

This generating function recurrence can now be solved for any speciﬁc parameters
of interest, to obtain the w-covering functions.

3.2.

Covering Functions for Steiner Systems

In this section, we adapt the analysis of covering functions from orthogonal arrays to
Steiner systems. We denote by mðw; t; k; vÞ the function of x in which the coefﬁcient
of xi is the number of selections of i blocks other than a speciﬁed block B in an
Sðt; k; vÞ, whose union intersects B in precisely w positions. As with orthogonal
arrays, computing this function when t ¼ 2 is straightforward. Indeed we calculate
ðv  kÞ=ðk  1Þ as the number of blocks meeting B in exactly one speciﬁed point, and
therefore kðv  kÞ=ðk  1Þ as the number meeting B in a single point (since no block
other than B meets B in more than one point). Then vðv  1Þ=ðkðk  1ÞÞ
kðv  kÞ=ðk  1Þ  1 ¼ w is the number of blocks not meeting B at all. We conclude
that
LEMMA 3.2.

mðw; 2; k; vÞ ¼

k
w

ððx þ 1ÞðvkÞ=ðk1Þ  1Þw ðx þ 1Þw .

Turning to t ¼ 3, we compute the number of blocks meeting B in exactly two
speciﬁed points as ðv  kÞ=ðk  2Þ, and hence those meeting B in one speciﬁed and
one arbitrary point as ðk  1Þðv  kÞ=ðk  2Þ, and those meeting B in two arbitrary
points as kðk  1Þðv  kÞ=2ðk  2Þ. Then the number of blocks meeting B in exactly
one speciﬁed point is ðv  1Þðv  2Þ=ððk  1Þðk  2ÞÞ  ðk  1Þðv  kÞ=ðk  2Þ  1;
multiplying by k gives the number meeting B in a single point. The number of blocks
disjoint from B can now be calculated.
These underlie the recursive deﬁnition of the generating function in precisely the
same manner as was done for orthogonal arrays of strength three, and we omit the
details.

3.3.

Extensions to Higher Strength

In these sections, we have treated only the cases when t [ f2; 3g. However, the
techniques developed here extend naturally to higher values of t, at the expense of
treating many more cases. In particular, when we take an open point and make it

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

79

completed, we must allow for each new block to shadow any number of additional
points from 0 to t  2. This in turn requires bookkeeping on intersections among the
points being shadowed by different blocks, and so we do not treat cases with t  4
here.
The covering functions that we have calculated exploit in a critical way the balance
and regularity of orthogonal arrays and Steiner systems. While it remains relatively
easy in principle to calculate covering functions for cover-free families in which no
two blocks intersect in more than one point, the covering functions themselves are
not in general independent of the block chosen, and the calculation itself can require
the examination of a number of cases that is exponential in v.

4. Computational Results
The results in this section were obtained using Maple [24], a mathematical software
package.

4.1.

Computational Results on OAs

Figure 4 shows the probability that there is at least one free slot in a frame for two
orthogonal arrays of strength two as a function of the number of neighbors. The
OAð2; k; 17Þ in Figure 4(a) supports N ¼ 289 nodes with a frame length of 17k for
k ¼ 1; 2; . . . ; 18. The OAð2; k; 25Þ in Figure 4(b) supports 625 nodes with a frame
length of 25k for k ¼ 1; 2; . . . ; 26. Each ﬁgure shows a family of curves, starting
leftmost with k ¼ 1, and increasing k by one for each successive curve to the right.
Both curves are shown up to 80 neighbors to illustrate how the parameters affect the
probability.
The ﬁgures have a structural similarity, resembling an inverse ‘‘s’’ shape that drops
more gradually as k increases. This makes sense since for larger k the frame length is

Figure 4. Probability of  1 free slot in a frame for (a) OAð2; k; 17Þ (289 nodes) and (b) OAð2; k; 25Þ (625
nodes).

80

COLBOURN ET AL.

longer, and hence the probability that there is a free slot in the frame increases. It is
possible to use very short frames yet still have a reasonable chance of success even
when the actual number of neighbors exceeds the design parameters. The longer
frames of the OAð2; k; 25Þ supports a larger number of neighbors than the schedules
generated from the OAð2; k; 17Þ. Finally, TDMA outperforms the OAð2; k; 17Þ for
k ¼ 17; 18. For k ¼ 17, TDMA has the identical frame length but has, with certainty,
a free slot in the frame. Similarly for OAð2; k; 25Þ for k ¼ 25; 26.
These ﬁgures disguise to a degree that the guarantee of a free slot extends only to
k  1 neighbors. Until that point, the curve is identically equal to 1; thereafter,
however, one can see only that it remains very close to 1 and is hard to distinguish
visually.
Figure 5 shows the probability that at least one slot in the frame is free for two
different strength three orthogonal arrays. The OAð3; k; 8Þ in Figure 5(a) supports
256 nodes with a frame length of 8k for k ¼ 1; 2; . . . ; 10 (since v ¼ 8 ¼ 23 ; k can be as
large as v þ 2 [15]). Figure 5(b) shows an OAð3; k; 11Þ that supports 1331 nodes with
a frame length of 11k for k ¼ 1; 2; . . . ; 12. These curves have the same overall
structure as those in Figure 4, however their slope is much steeper. It is not too
surprising that the probability of a success drops more rapidly as the frame lengths
of the schedules that arise from these higher strength orthogonal arrays are much
shorter. On the other hand, they support more neighbors for the same frame
length.
It is worth comparing the OAð2; k; 17Þ that supports 289 nodes in Figure 4(a) to
the OAð3; k; 8Þ that supports close to the same number of nodes (256) in Figure 5(a).
If the actual node degree is very small, it is much better to use the shorter frame
length schedules of the OAð3; k; 8Þ. The schedules from the OAð2; k; 17Þ can tolerate
higher variance in the node degree. Thus, if node degree can be controlled through,
say, a topology control protocol, or the network topology is controlled when the
network is established (as it might be for a sensor network) then a higher strength
code is the better choice.

Figure 5. Probability of  1 free slot in a frame for (a) OAð3; k; 8Þ (256 nodes) and (b) OAð3; k; 11Þ (1331
nodes).

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

81

Figure 6. Expected throughput for (a) OAð2; k; vÞ and (b) OAð3; k; vÞ for v a prime power from 3; . . . ; 27.

Figure 6 plots expected throughput for an OAð2; k; vÞ and an OAð3; k; vÞ for v a
prime power from three up to 27 as a function of the number of neighbors. Again,
both ﬁgures show a similar structure. The y-intercept of each curve is 1/v for a given
v. The curve corresponding to v ¼ 3 has the highest y-intercept. Decreasing yintercepts correspond to curves with successive increasing values of v. The expected
throughput drops rapidly to zero (not asymptotically zero, but equal to zero) for
smaller values of v. For the strength three orthogonal array, the drop is not as sharp
as for the strength two array, though this is less noticeable as v increases.
Throughput is independent of the number of subframes, thus expected throughput
is computed on a subframe basis. This merits a brief discussion. In employing the
evaluation of the generating function f to calculate expected throughput, we noted
in the computational results this apparent independence. Indeed, it is easy to
establish that expected throughput does not depend upon the number of subframes.
This is in stark contrast to the minimum throughput.
Figure 7 plots the ratio of the expected throughput of an OAð2; k; vÞ and an
OAð3; k; vÞ to TDMA as a function of the number of neighbors, assuming k ¼ v (i.e.,
the TDMA frame length is v2 ). In Figure 7(a) for the OAð2; k; vÞ, the y-intercept
corresponds to the prime powers. Here we see that the expected throughput is at

Figure 7. Ratio of expected throughput of (a) OAð2; k; vÞ and (b) OAð3; k; vÞ to TDMA, assuming k ¼ v.

82

COLBOURN ET AL.

most v times that of TDMA. For the strength three OAð3; k; vÞ in Figure 7(b), we see
a dramatic difference in expected throughput since it can be as much as v2 times that
of TDMA (albeit under rare circumstances). It remains proportionally higher as the
number of neighbors increases. In Chlamtac and Faragó [16] it is suggested to use a
larger prime than the minimal choice in order to obtain the best minimum
throughput. Our results indicate that the same is true for expected throughput.
Finally, Figure 8 compares several functions for 729 nodes. The reason this value
for N was selected is because 729 ¼ ð32 Þ3 ¼ ð33 Þ2 , that is, both OAs of strength two
and three exist for this value of N. The straight line at the bottom of the ﬁgure shows
the expected throughput of TDMA (1/729). For the OAð2; k; 27Þ we plot both the
minimum and the expected throughput. These are the two less steep curves, with the
minimum throughput below expected throughput. For the OAð3; k; 9Þ we also plot
both the minimum and expected throughput. These are the two steep curves, with the
minimum below the expected throughput. The frame length of schedules derived
from the OAð2; k; 27Þ is 27k, while for the OAð3; k; 9Þ it is 9k.
The ﬁrst observation is that both the strength two and three orthogonal arrays
outperform the expected throughput of TDMA to about 30 neighbors for the
OAð3; k; 9Þ and about 85 neighbors for the OAð2; k; 27Þ (though this is not a
guarantee). The expected throughput for the strength two array degrades slower
than the strength three array, and tolerates a larger number of neighbors. In both
cases, the expected throughput is signiﬁcantly better than the minimum. Neither
Chlamtac and Faragó [6] nor Ju and Li [16] discussed expected throughput. This
metric is considerably more informative with respect to throughput than the
minimum (or the maximum), although minimum throughput is an essential metric
for QoS.

Figure 8. Comparison of minimum and expected throughput for OAð2; k; 27Þ and OAð3; k; 9Þ to TDMA.

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

4.2.
4.2.1.

83

Computational Results for Steiner Systems
Acknowledgment Models

The essential difference between the two known constructions of topologytransparent schedules lies in the selection of parameters. In Chlamtac and
Faragó [6], the focus is on frame length while in Ju and Li [16] the focus is on
throughput.
In both studies, however, the ﬁgure of merit is minimum throughput measured as
number of free slots within a frame divided by frame length. To employ such an
analysis, a transmitting node must be able to transmit multiple different packets
within a frame. How does it decide to transmit a ‘‘new’’ packet? In this environment,
it is expected that collisions occur, and topology-transparency dictates that the
collisions cannot be anticipated. Hence an acknowledgment scheme is needed. Both
schemes based on orthogonal arrays can transmit in two consecutive slots, and
indeed must send different packets in these slots to achieve the minimum throughput
in their analyzes. Both propose an acknowledgment scheme that involves
instantaneous acknowledgment of successful receipt without lengthening the slot.
Naturally, this is an optimistic assumption to facilitate the analysis. However, the
analysis can be misleading if it leads us to seek many free slots in a frame without an
acceptable (realistic) acknowledgment scheme. For purposes of comparison, we
consider the throughput measures employed in Chlamtac and Faragó [6], Ju and Li
[16], and Syrotiuk et al. [22]. We also adopt a more conservative approach.
We consider a more realistic model for acknowledgments. Rather than a slot by
slot acknowledgment, we assume we can piggyback an acknowledgment onto a
packet sent from the destination. In the worst case, this might require that the sender
wait an entire frame. Hence we deﬁne frame throughput as the throughput
achievable on a per frame basis. This properly incorporates the length of the
schedule in the throughput calculation.
In this section we investigate three questions:
1. What is the probability of a successful transmission in a frame?
2. What is the expected throughput?
3. What is the expected frame throughput?
All are functions of the number of active transmitters among the neighbors of a
node.
The frame throughput is the expected number of slots over the frame length. This
effectively normalizes the expected throughput by frame length allowing easier
comparison between Steiner systems.
We derive these measures analytically. The most complex derivation is for
expected throughput. We did this for schedules that correspond to orthogonal arrays
in Syrotiuk et al. [22]. This formulation may be used as a basis to derive expected
throughput for schedules that correspond to Steiner systems.

84

COLBOURN ET AL.

Figure 9. Expected throughput for (a) Sð2; k; vÞ and (b) versus TDMA, for k ¼ 3; 6; 9; 12.

4.2.2.

Results on Steiner Systems

Figure 9(a) plots the expected throughput for Sð2; k; vÞ for k ¼ 3; 6; 9; 12 as a
function of the number of neighbors. In each of the following cases,
N ¼ vðv  1Þ=kðk  1Þ. For k ¼ 3; v ¼ 7; 13; 19; 25 are considered for N ¼
7; 26; 57; 100 number of nodes, respectively. For k ¼ 6; v ¼ 31; 61; 91; 121 are
considered for N ¼ 31; 122; 273; 484 number of nodes, respectively. For k ¼ 9; v ¼
73; 145; 217; 289 are considered for N ¼ 73; 290; 651; 1156 number of nodes,
respectively. Finally, for k ¼ 12; v ¼ 133; 265; 397; 529 are considered for N ¼
133; 530; 1191; 2116 number of nodes, respectively. In the ﬁgure, the y-intercept is
given by k/v, and so the curve with the highest y-intercept has the shortest frame
length ðk ¼ 3; v ¼ 7Þ. Successive curves with lower y-intercept have successively
longer frame length. The shorter the frame, the faster the expected throughput drops
to zero. As well, the expected throughput is much more sensitive to changes in
neighborhood size.
In Figure 9(b), we plot the expected throughput for Sð2; k; vÞ for k ¼ 3; 6; 9; 12
over the throughput of TDMA with the same frame length, as a function of the
number of neighbors. For example, now the curve with the highest y-intercept is
k ¼ 12; v ¼ 529. This Steiner system supports 2116 nodes, so the expected frame
throughput is ðk=vÞ=ð1=NÞ ¼ ð12=529Þ ? 2116 ¼ 48. In other words, in the best case,
this Steiner system has expected throughput that is 48 times that of TDMA with the
same frame length. When the ratio of expected throughput to the corresponding
TDMA is taken, the curve in Figure 9(a) essentially inverts position in Figure 9(b).
This means that longer frames with more opportunities to transmit are better than
shorter frames with fewer opportunities to transmit from the perspective of
throughput.
Figure 10(a) plots the more conservative frame throughput for Sð2; k; vÞ for k ¼
3; 6; 9; 12 as a function of neighborhood size, for the same v’s as in the previous
ﬁgure. Now, the y-intercepts correspond to 1=v rather than k=v. Again, the curves
with a shorter frame length have a more pronounced drop than curves with longer

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

85

Figure 10. Frame throughput for (a) Sð2; k; vÞ and (b) versus TDMA, for k ¼ 3; 6; 9; 12.

frame length. As well, curves with the same k value now show a guarantee (i.e., are
horizontal) for up to k neighbors, after which the guarantee degrades.
In Figure 10(b), we plot the ratio of frame throughput for Sð2; k; vÞ for k ¼
3; 6; 9; 12 over the throughput of TDMA for the same frame length as a function of
neighborhood size, for the same v’s as given earlier. Now, we see that the best
possible throughput is ð1=vÞ=ð1=NÞ ¼ N=v which is 4, 3, 2, 1 for increasing values of
v. Again, the slot guarantee is observed. That is, the curves are horizontal for
neighborhood sizes less than or equal to k and degrade as the neighborhood
increases. The degradation is slower for the longer frames. The curves whose
maximum expected frame throughput equals one correspond to orthogonal arrays
OAð2; v; vÞ. Hence it is plainly evident that schedules constructed from Steiner
systems are much denser than those constructed from orthogonal arrays, with the
potential to yield much higher throughput.
Figure 11(a) plots minimum throughput for Sð2; k; vÞ for k ¼ 3; 6; 9; 12 as a
function of neighborhood size for the same values of v as given earlier. Here, the yintercept is k=v (the same as in Figure 9), however now the x-intercept is k and is the
same for each value of v. This results in the curves dropping to zero much more

Figure 11. Minimum throughput for (a) Sð2; k; vÞ and (b) versus TDMA, for k ¼ 3; 6; 9; 12.

86

COLBOURN ET AL.

quickly than in Figure 9. A curiosity is that the four segments that correspond to the
maximum minimum throughput correspond to Sð2; k; vÞ where the smallest frame
length v for the given k provides a range of neighbors over which it provides the best
minimum throughput. That is, Sð2; 3; 7Þ and Sð2; 12; 133Þ are better over a larger
range of neighbors than are Sð2; 6; 31Þ and Sð2; 9; 73Þ.
Figure 11(b) plots the ratio of minimum throughput for Sð2; k; vÞ for k ¼ 3; 6; 9; 12
over TDMA with the same frame length as a function of neighborhood size for the
same v’s. Here the curves invert order when the ratio is considered. Speciﬁcally, the
curve with the highest y-intercept is Sð2; 12; 529Þ since this is given by ðk=vÞ=ð1=NÞ as
in Figure 9. However the x-intercept now corresponds to k as in Figure 11(a). Now,
the largest v for each k provides the best minimum throughput relative to TDMA.
Again, we look at frame throughput, this time the minimum value, in Figure 12
(for the same k’s and v’s). Not surprisingly, the minimum frame throughput is lower
than when using the more optimistic acknowledgment model. The main difference
between this ﬁgure and Figure 10 is the x-intercepts. Here, they correspond to k,
clearly showing that with minimum frame throughput, once the neighborhood
exceeds the design parameter, all guarantees are lost immediately. This is also true
for the ratio of minimum frame throughput over TDMA with the same frame length
Figure 12(b). This ﬁgure also shows that the minimum frame throughput is
essentially constant for each k as long as the design parameter is satisﬁed.
Figure 12 shows us something very important, in addition. Larger Steiner systems
give us a minimum frame throughput substantially better than TDMA when the
neighborhood is within the bound. This is in stark contrast with the schemes in
Chlamtac and Faragó [6] and Ju and Li [16]; they never outperform TDMA on
minimum frame throughput when orthogonal arrays of strength two are used.
Figure 13 is different from all other ﬁgures presented in that it plots expected
throughput versus density of the neighborhood. That is, the x-axis is the percentage
of nodes that are neighbors—these are not absolute values, and represent much
larger neighborhood sizes in general. The reason that the curves are jagged is that
the closest integer value is taken as the percentage of neighbors, that is, we do not

Figure 12. Minimum frame throughput for (a) Sð2; k; vÞ and (b) versus TDMA, for k ¼ 3; 6; 9; 12.

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

87

Figure 13. Expected throughput versus density for (a) Sð2; k; vÞ and (b) versus TDMA, for k ¼ 3; 6; 9; 12.

consider fractional numbers of neighbors. While the ﬁgure shows Sð2; k; vÞ for
k ¼ 3; 6; 9; 12, only the ﬁrst three values of v for each k are shown since the
computations are highly memory and compute intensive. The y-intercepts are the
same as in Figure 9. As a function of neighborhood density, the expected throughput
(a) is more well-behaved than as a function of neighborhood size. When the ratio of
expected throughput to TDMA throughput is considered versus neighborhood
density (b) the curves drop more rapidly as the density increases more rapidly than a
linear function.
Finally, Figure 14 once again plots expected throughput versus neighborhood size
for three Steiner systems that support the same number of nodes, namely N ¼ 651
and one orthogonal array that supports a number very close to that (625).
Speciﬁcally from the top down, the curves correspond to Sð2; 3; 63Þ; Sð2; 9; 217Þ;
Sð2; 26; 651Þ and OAð2; 26; 25Þ. First, we see that the last two curves are essentially
indistinguishable from each other. That is, for all intents and purposes, the
Sð2; 26; 651Þ and OAð2; 26; 25Þ give the same performance but the Steiner system

Figure 14. Expected throughput for cover-free families for 600–700 nodes.

88

COLBOURN ET AL.

supports more nodes. The Steiner system with shorter frame length gives better expected throughput until the neighborhood is about 20, at which point the curves all
cross. Its performance also degrades more rapidly with increasing neighborhood size.

5. Handling the Degree Limitation
Our analysis has focussed on a single frame; while this is a reasonable view for
studying minimum throughput, it ignores what happens when the neighborhood
limitation is exceeded. Ju and Li [16] argue that by selecting a larger v, their choice is
(relatively) insensitive to the degree limitation; essentially they ‘‘over-engineer’’ the
system to permit more neighbors than the design criteria stipulate. Nevertheless,
their scheme can fail totally when the number of neighbors exceeds the capacity of
their chosen scheme, despite its continued operation for some numbers of neighbors
larger than the stipulated number.
Chlamtac et al. [7] propose a different solution, interleaving or ‘‘threading’’
different schemes each supporting a different degree limitation; however, this incurs
a dramatic slowdown in the initial scheme and hence a substantial penalty is paid
whether or not the degree limit is exceeded. What is needed is a scheme that, if the
degree limitation might be exceeded, degrades gracefully rather than failing
completely (as in Ju and Li [16]) or imposing a large slowdown factor (as in
Chlamtac and Faragó [6]). Ju and Li’s [16] approach fails to provide a guarantee
when the number of neighbors is too large. This in itself is reasonable. However,
their scheme repeatedly uses the same frame schedule in each subsequent frame.
Thus loss of transmission opportunity within one frame is extended to all subsequent
frames unless and until transmitting nodes move or cease transmission. Of course,
this does not impact the expected throughput. But when the degree limit is exceeded,
it can result in a denial of service to some nodes.
Our results demonstrate, however, that expected throughput can remain quite
acceptable when the degree limitation is exceeded. Our task, then, is to ensure that a
situation resulting in catastrophic collisions in one frame is not automatically
repeated in the next frame by simply repeating the schedule. Two methods suggest
themselves. The ﬁrst is to allow nodes to remain silent throughout a frame despite
having a pending transmission, that is, ‘‘backing off’’ when it is detected that the
degree limit is exceeded. When the degree limit is satisﬁed, such a scheme ensures
nonzero minimum throughput; when exceeded, the scheme employs contention.
A second method is suggested by the results on expected throughput. If the
number of neighbors exceeds the degree limit, the expected throughput tells us the
likelihood that we fail. The combinatorial properties of the scheme explain why we
could fail: our neighbors interfere with each of our transmission slots. So while
minimum throughput tells us that we could fail, expected throughput tells us how
likely we are to be unlucky enough to have neighbors that cause us to fail. Now we
cannot choose our neighbors, but we can do something equivalent. By distributing
codewords to nodes at random in each frame, the expectation within one frame does
not depend on the outcome of another (unlike Chlamtac and Faragó [6] and Ju and

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

89

Li [16] where it is the same outcome). Obviously this poses insurmountable practical
problems, so we propose selecting a ﬁxed number of frames f, and making f random
distributions of the codewords to be used in f successive frames, repeatedly.
In this way, denial of service can be held to any speciﬁed probability tolerance,
while ensuring that when the degree limit is met, there is provably no denial of
service.

5.1.

Extension to Multiple Frames

Until this point, we have concentrated on the schedule for one frame. However, if we
simply repeat the schedule in each frame, then unsuccessful transmissions in one
frame simply repeat in the next, unless nodes move or cease transmission. Hence we
consider a combinatorial question arising from the decision of the schedule to be
used in successive frames.
Let us consider an ideal situation. Suppose that b and c are two Sð2; k; vÞ designs;
the blocks of b are called B1 ; B2 ; . . . ; Bb and those of c are C1 ; C2 ; . . . ; Cb . Imagine
that, whenever Bi and Bj intersect, Ci and Cj do not intersect. If two such Steiner
systems exist then we can use one Steiner system in the odd numbered frames, and
the other in the even numbered frames. This would improve the ability to handle
neighbors from k  1 to 2k  1 (at the end of a pair of frames).
However, two such Steiner systems with v > k cannot exist. To see this, label the
points in B as V6f0g and label the points in C as V6f1g. Then construct blocks
Di ¼ Bi [ Ci . By the requirement on B and C, no pair of points in V6f0; 1g appears
twice in the blocks Di . Furthermore, every block Di covers k2 pairs of type ðx0 ; y1 Þ
(i.e., cross pairs) for some x; y [ V. Since there are at most v2 cross pairs, it must be
the case that bk2  v2 . Hence, b  ðv=kÞ2 . However, in a Steiner system Sð2; k; vÞ; b ¼
vðv  1Þ=kðk  1Þ which gives a contradiction. Indeed this can be improved upon
slightly to obtain:
j v j v kk
b
:
k k
This follows since every point xi can have at most v neighbors of the form y1i .
Therefore, every point appears in at most bv=kc blocks. Since bk ¼ rv and b is an
integer, the bound is obtained.
We examine the following question. When k ¼ 2, what is the largest value of b
when v is given? We denote a design realizing this maximum as a maximum cross
pair design of order v, MCPðvÞ.
In the case when k ¼ 2 and v is even, b ¼ ðv=2Þ2 . An MCPðvÞ can be constructed
from a transversal design TDð4; v=2Þ as follows: use two groups to deﬁne V6f0g
and the remaining two groups to deﬁne V6f1g.
The case when v is odd requires more effort. Suppose that v ¼ 4m þ 1. Then
b ¼ mð4m þ 1Þ. In addition, the cross pairs that are not covered form a 1-factor on
V6f0; 1g.

90

COLBOURN ET AL.

We recall some deﬁnitions from combinatorial design theory. Let K and G be sets
of positive integers. A group divisible design of order v (K-GDD) is a triple
ðV; g; bÞ, where V is a ﬁnite set of cardinality ðvÞ; g is a partition of V into parts
(groups) whose sizes lie in G, and b is a family of subsets (blocks) of V satisfying the
properties:
1. If B [ b, then jBj [ K.
2. Every pair of distinct elements of V occurs in exactly one block or one group, but
not both.
If v ¼ a1 g1 þ a2 g2 þ    þ as gs , and if there are ai groups of size gi , then the KGDD is of type ga11 ga22 . . . gsas . If K ¼ fkg, then the K-GDD is a k-GDD.
A K-GDD of order v and type 1v is a K-pairwise balanced design (K-PBD) of
order v. A K-GDD of type vk and block size k is a transversal design TDðk; vÞ. We
employ holey transversal designs (HTDs) in the following, and refer to Abel et al. [2]
for relevant deﬁnitions and results.
We form some small MCPs.
LEMMA 5.1.

There exists an MCPðvÞ for v [ f5; 9; 13; 17; 29; 33g.

Proof. The designs are constructed on Z6f0; 1g.
v ¼ 5 fð0; 0Þ; ð1; 0Þ; ð0; 1Þ; ð2; 1Þg:
v ¼ 9 fð0; 0Þ; ð1; 0Þ; ð0; 1Þ; ð2; 1Þg; fð0; 0Þ; ð2; 0Þ; ð5; 1Þ; ð6; 1Þg:
v ¼ 13 fð0; 0Þ; ð1; 0Þ; ð0; 1Þ; ð3; 1Þg; fð0; 0Þ; ð2; 0Þ; ð6; 1Þ; ð11; 1Þg;
fð0; 0Þ; ð3; 0Þ; ð8; 1Þ; ð10; 1Þg:
v ¼ 17 fð0; 0Þ; ð1; 0Þ; ð0; 1Þ; ð2; 1Þg; fð0; 0Þ; ð2; 0Þ; ð5; 1Þ; ð8; 1Þg;
fð0; 0Þ; ð3; 0Þ; ð7; 1Þ; ð12; 1Þg; fð0; 0Þ; ð4; 0Þ; ð14; 1Þ; ð15; 1Þg:
v ¼ 29 fð0; 0Þ; ð1; 0Þ; ð0; 1Þ; ð2; 1Þg; fð0; 0Þ; ð2; 0Þ; ð5; 1Þ; ð6; 1Þg;
fð0; 0Þ; ð3; 0Þ; ð10; 1Þ; ð14; 1Þg; fð0; 0Þ; ð4; 0Þ; ð12; 1Þ; ð23; 1Þg;
fð0; 0Þ; ð5; 0Þ; ð18; 1Þ; ð26; 1Þg; fð0; 0Þ; ð6; 0Þ; ð15; 1Þ; ð22; 1Þg;
fð0; 0Þ; ð7; 0Þ; ð24; 1Þ; ð27; 1Þg:
v ¼ 33 fð0; 0Þ; ð1; 0Þ; ð0; 1Þ; ð2; 1Þg; fð0; 0Þ; ð2; 0Þ; ð5; 1Þ; ð6; 1Þg;
fð0; 0Þ; ð3; 0Þ; ð10; 1Þ; ð14; 1Þg; fð0; 0Þ; ð4; 0Þ; ð12; 1Þ; ð17; 1Þg;
fð0; 0Þ; ð5; 0Þ; ð21; 1Þ; ð28; 1Þg; fð0; 0Þ; ð6; 0Þ; ð15; 1Þ; ð26; 1Þg;
fð0; 0Þ; ð7; 0Þ; ð25; 1Þ; ð31; 1Þg; fð0; 0Þ; ð8; 0Þ; ð27; 1Þ; ð30; 1Þg:
THEOREM 5.2.

An MCP(v) exists whenever v:1 ðmod4Þ.

j

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

91

Proof. When v [ f5; 9; 13; 17; 29; 33g, use Lemma 5.1. For other values of v, there
exists a f5; 9; 13g-PBD of order v [3,4]. So let V be a v-set, and construct an MCPðvÞ
on V6f0; 1g, by placing for each block B of the PBD, an MCPðjBjÞ on B6f0; 1g,
aligning the missing one factor on the pairs fx0 ; x1 g for x [ B.
&
Next we settle the problem when v:3ðmod 4Þ. Let G be a set of positive integers.
A MCP-GDD of order v is a triple ðV; g; bÞ, where V is a ﬁnite set of cardinality v;
g is a partition of V into parts (groups) whose sizes lie in G, and b is a family of
subsets (blocks) of V6f0; 1g such that for every block B [ b; jB \ V6
f0gj ¼ jB \ V6f1gj ¼ 2, and for every pair of points ðx; 0Þ; ðy; 1Þ where x; y [ V,
either there is a block B [ b containing the pair, or x; y [ Gi for some i. We permit
that x and y be equal in the deﬁnition. As usual, we use the exponential notation to
denote the group type of the MCP-GDD.
THEOREM 5.3.
If there exists a 4-HTD of type gn u1 , then there exists a MCPn
GDD of type ð2gÞ ð2uÞ1 .
Proof. Let the four groups of the HTD be X0 ; Y0 ; X1 and Y1 where X and Y are
disjoint sets of gn þ u points. Let V ¼ X [ Y.
&
LEMMA 5.4.

There exists a MCP(v) when v ¼ 3; 7.

Proof. When v ¼ 3, the MCP(3) has only one block. Let V ¼ f0; 1; 2g. The MCP(3)
has one block of the form fð0; 0Þ; ð1; 0Þ; ð0; 1Þ; ð1; 1Þg. When v ¼ 7, let
V ¼ f0; 1; . . . ; 6g. The MCP(7) has 10 blocks of the form
fð0; 0Þ; ð1; 0Þ; ð0; 1Þ; ð1; 1Þg; fð0; 0Þ; ð2; 0Þ; ð2; 1Þ; ð3; 1Þg;
fð0; 0Þ; ð3; 0Þ; ð4; 1Þ; ð5; 1Þg; fð1; 0Þ; ð2; 0Þ; ð4; 1Þ; ð6; 1Þg;
fð1; 0Þ; ð4; 0Þ; ð2; 1Þ; ð5; 1Þg; fð2; 0Þ; ð5; 0Þ; ð0; 1Þ; ð5; 1Þg;
fð3; 0Þ; ð4; 0Þ; ð0; 1Þ; ð3; 1Þg; fð3; 0Þ; ð5; 0Þ; ð1; 1Þ; ð2; 1Þg;
fð4; 0Þ; ð6; 0Þ; ð1; 1Þ; ð4; 1Þg; fð5; 0Þ; ð6; 0Þ; ð3; 1Þ; ð6; 1Þg:
LEMMA 5.5.
1n 31 .

j

For n [ f8; 12; 16; 20; 24; 28g, there exists an MCP-GDD of type

Proof. The designs are constructed on Zn=2 6f0; 1; 2; 3g. Without loss of generality,
we label V6f0g ¼ Zn=2 6f0; 1g [ fx0 ; y0 ; z0 g and V6f1g ¼ Zn=2 6f2; 3g
[fx1 ; y1 ; z1 g. The ﬁrst base block listed below for each design is a short orbit of
length n=4.

92

COLBOURN ET AL.

n ¼ 8fð0; 0Þ; ð0; 2Þ; ð2; 0Þ; ð2; 2Þg; fðx0 ; ð0; 0Þ; ð1; 2Þ; ð0; 3Þg;
fy0 ; ð0; 0Þ; ð0; 1Þ; ð3; 2Þg; fz0 ; ð0; 0Þ; ð1; 1Þ; ð2; 3Þg;
fx1 ; ð0; 0Þ; ð2; 1Þ; ð1; 3Þg; fy1 ; ð0; 1Þ; ð0; 2Þ; ð0; 3Þg;
fz1 ; ð0; 1Þ; ð1; 2Þ; ð2; 3Þg:
n ¼ 12fð0; 0Þ; ð0; 3Þ; ð2; 0Þ; ð2; 3Þg; fð0; 0Þ; ð1; 0Þ; ð2; 2Þ; ð0; 3Þg;
fð0; 1Þ; ð1; 1Þ; ð1; 2Þ; ð2; 3Þg; fx0 ; ð0; 0Þ; ð4; 2Þ; ð1; 3Þg;
fy0 ; ð0; 0Þ; ð0; 1Þ; ð5; 2Þg; fz0 ; ð0; 0Þ; ð1; 1Þ; ð4; 3Þg;
fx1 ð0; 0Þ; ð2; 1Þ; ð2; 3Þg; fy1 ; ð0; 1Þ; ð3; 2Þ; ð5; 3Þg;
fz1 ; ð0; 1Þ; ð4; 2Þ; ð4; 3Þg:
n ¼ 16fð0; 0Þ; ð0; 4Þ; ð2; 0Þ; ð2; 4Þg; fð0; 0Þ; ð0; 1Þ; ð1; 2Þ; ð0; 3Þg;
fð0; 0Þ; ð1; 1Þ; ð5; 2Þ; ð2; 3Þg; fð0; 0Þ; ð1; 0Þ; ð7; 2Þ; ð5; 3Þg;
fð0; 1Þ; ð1; 1Þ; ð3; 2Þ; ð5; 3Þg; fx0 ; ð0; 0Þ; ð2; 2Þ; ð6; 3Þg;
fy0 ; ð0; 0Þ; ð3; 1Þ; ð3; 2Þg; fz0 ; ð0; 0Þ; ð4; 1Þ; ð7; 3Þg;
fx1 ; ð0; 0Þ; ð5; 1Þ; ð3; 3Þg; fy1 ; ð0; 1Þ; ð6; 2Þ; ð7; 3Þg;
fz1 ; ð0; 1Þ; ð7; 2Þ; ð2; 3Þg:
n ¼ 20fð0; 0Þ; ð0; 5Þ; ð2; 0Þ; ð2; 5Þg; fð0; 0Þ; ð0; 1Þ; ð1; 2Þ; ð0; 3Þg;
fð0; 0Þ; ð1; 1Þ; ð3; 2Þ; ð3; 3Þg; fð0; 0Þ; ð2; 1Þ; ð2; 2Þ; ð5; 3Þg;
fð0; 0Þ; ð3; 1Þ; ð6; 2Þ; ð7; 3Þg; fð0; 0Þ; ð1; 0Þ; ð8; 2Þ; ð2; 3Þg;
fð0; 1Þ; ð2; 1Þ; ð7; 2Þ; ð9; 3Þg; fx0 ; ð0; 0Þ; ð4; 2Þ; ð9; 3Þg;
fy0 ; ð0; 0Þ; ð5; 1Þ; ð9; 2Þg; fz0 ; ð0; 0Þ; ð6; 1Þ; ð4; 3Þg;
fx1 ; ð0; 0Þ; ð7; 1Þ; ð8; 3Þg; fy1 ; ð0; 1Þ; ð8; 2Þ; ð6; 3Þg;
fz1 ; ð0; 1Þ; ð9; 2Þ; ð5; 3Þg:
n ¼ 24fð0; 0Þ; ð0; 6Þ; ð2; 0Þ; ð2; 6Þg; fð0; 0Þ; ð0; 1Þ; ð1; 2Þ; ð0; 3Þg;
fð0; 0Þ; ð1; 1Þ; ð3; 2Þ; ð3; 3Þg; fð0; 0Þ; ð2; 1Þ; ð2; 2Þ; ð5; 3Þg;
fð0; 0Þ; ð3; 1Þ; ð7; 2Þ; ð1; 3Þg; fð0; 0Þ; ð4; 1Þ; ð8; 3Þ; ð9; 3Þg;
fð0; 0Þ; ð5; 1Þ; ð4; 2Þ; ð8; 2Þg; fð0; 0Þ; ð1; 0Þ; ð10; 2Þ; ð7; 3Þg;
fð0; 1Þ; ð1; 1Þ; ð6; 2Þ; ð7; 3Þg; fx0 ; ð0; 0Þ; ð11; 2Þ; ð4; 3Þg;
fy0 ; ð0; 0Þ; ð7; 1Þ; ð5; 2Þg; fz0 ; ð0; 0Þ; ð6; 1Þ; ð2; 3Þg;
fx1 ; ð0; 0Þ; ð11; 1Þ; ð10; 3Þg; fy1 ; ð0; 1Þ; ð7; 2Þ; ð9; 3Þg;
fz1 ; ð0; 1Þ; ð9; 2Þ; ð1; 3Þg:
n ¼ 28fð0; 0Þ; ð0; 7Þ; ð2; 0Þ; ð2; 7Þg; fð0; 0Þ; ð0; 1Þð1; 2Þ; ð0; 3Þg;
fð0; 0Þ; ð1; 1Þð3; 2Þ; ð3; 3Þg; fð0; 0Þ; ð2; 1Þð2; 2Þ; ð5; 3Þg;
fð0; 0Þ; ð3; 1Þð6; 2Þ; ð1; 3Þg; fð0; 0Þ; ð4; 1Þð8; 2Þ; ð9; 3Þg;
fð0; 0Þ; ð5; 1Þð4; 2Þ; ð2; 3Þg; fð0; 0Þ; ð6; 1Þð7; 3Þ; ð10; 3Þg;

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

93

fð0; 0Þ; ð7; 1Þð5; 2Þ; ð13; 2Þg; fð0; 0Þ; ð1; 0Þð11; 2Þ; ð13; 3Þg;
fð0; 1Þ; ð1; 1Þð10; 2Þ; ð7; 3Þg; fx0 ; ð0; 0Þ; ð12; 2Þ; ð6; 3Þg;
fy0 ; ð0; 0Þ; ð12; 1Þ; ð9; 2Þg; fz0 ; ð0; 0Þ; ð10; 1Þ; ð4; 3Þg;
fx1 ; ð0; 0Þ; ð13; 1Þ; ð8; 3Þg; fy1 ; ð0; 1Þ; ð5; 2Þ; ð10; 3Þg;
fz1 ; ð0; 1Þ; ð7; 2Þ; ð13; 3Þg:
LEMMA 5.6.

j

For every v:3 ðmod4Þ, there exists an MCP(v).

Proof. An MCP(3) and an MCP(7) are constructed in Lemma 5.4. When
v [ f11; 19; 27g, take a MCP-GDD of type 1v3 31 from Lemma 5.5 and ﬁll in the
group of size 3 using a MCP(3) to obtain the result. When v:3 (mod 8) and v  35,
write v ¼ 8t þ 3 where t  4. Use Theorem 5.3 to obtain a MCP-GDD of type 8t ,
and add 3 points. Fill with an MCP-GDD of type 18 31 to obtain an MCP-GDD of
type 18t 31 . When v [ f15; 23; 31g, take an MCP-GDD of type 1v3 31 from Lemma 5.5
and ﬁll in the group of size 3 using an MCP(3) to obtain the result. When v:7 (mod
8) and v  39, write v ¼ 8t þ 7 where t  4. Using Theorem 5.3 to obtain an MCPGDD of type 8t 41 ; add 3 points and ﬁll in the holes with a MCP-GDD of type 18 31
to obtain an MCP-GDD of type 18t 71 . Fill in the hole of size 7 with a MCP(7) to
obtain the desired result.
&
While it may be of interest to treat analogs for larger values of k, what is striking is
that the extension to multiple frames returns us to orthogonal arrays. The very
density of Steiner systems that afforded an improvement in one frame impedes the
best extension to more frames.

6. Conclusions
The combinatorial properties of topology-transparent schedules correspond
precisely to D cover-free families, where D is a design parameter indicating
maximum number of neighbors. Studies of several Steiner systems illustrate the
following general trends. Steiner systems admit shorter schedules (frames) than
previous constructions based on orthogonal arrays.This is signiﬁcant for delay
sensitive applications such as multi-media. Since Steiner systems are also denser, they
support more nodes for a given frame length and hence achieve higher throughput.
While shorter schedules give the best minimum and expected throughput, they also
degrade faster as the design parameter D is exceeded. That is, longer schedules are
more robust to changes in neighborhood size. Another general observation is that
the Steiner systems that yield longer schedules achieve higher ratios on minimum and
expected throughput when compared to TDMA schedules of the same length.
We have characterized the types of solutions topology-transparent transmission
schedules require as cover-free families. Using this, along with a more realistic
acknowledgment model, we are investigating the issue of what to do when the
schedule fails due to node mobility causing the design parameter on neighborhood

94

COLBOURN ET AL.

size to be exceeded. Simulations using mobility models are also required to determine
how such scheduled topology-transparent protocols compare to contention based
protocols.
Using the interpretation of existing schemes as orthogonal arrays, we also gave
analytical expressions for the probability of a successful transmission in a frame, as
well as for the expected throughput. After running experiments on strength two and
strength three OAs using Maple [24], we employed the results to examine the
sensitivity of the schedules to the actual node degree.
The underlying combinatorial interpretation provides analytic tools for existing
topology-transparent schemes, and design tools for variations on them. These tools
establish that, while denser solutions are preferred within a single frame, the
extension to multiple frames favors sparser solutions. Combinatorial properties of
schedules spanning many frames remain an intriguing problem in general.

Acknowledgments
Thanks to Wensong Chu for helpful discussions. The research of Colbourn and Ling
was supported in part by ARO grant DAAD 19-01-1-0406, and the research of
Syrotiuk was supported in part by NSF grant ANI-0105985.

References
1.
2.
3.
4.
5.

6.

7.

8.
9.
10.

IEEE Standard 802.11: Wireless LAN Medium Access Control and Physical Layer Speciﬁcations,
December (1999).
R. J. R. Abel, F. E. Bennett and G. Ge, The existence of four HMOLS with equal sized holes, Des.
Codes Crypt., Vol. 26 (2002) pp. 7–31.
R. J. R. Abel and A. C. H. Ling, Some new constructions for (v, 5, w , 1) PBDs, J. Combin. Math.
Combin. Comput., Vol. 32 (2000) pp. 97–102.
F. E. Bennett, C. J. Colbourn and R. C. Mullin, Quintessential pairwise balanced designs, J. Stat.
Plann. Infer., Vol. 72 (1998) pp. 15–66.
M. Benveniste, G. Chesson, M. Hoeben, A. Singla, H. Teunissen and M. Wentink, Enhanced
distributed coordination function (EDCF), In IEEE Working Document 802.11-01/131r1, March
(2001).
I. Chlamtac and A. Faragó, Making transmission schedules immune to topology changes in multihop packet radio networks, IEEE/ACM Transactions on Networking, Vol. 2, No. 1, February (1994)
pp. 23–29.
I. Chlamtac, A. Faragó and H. Zhang, Time-spread multiple-access (TSMA) protocols for multihop
mobile radio networks, IEEE/ACM Transactions on Networking, Vol. 5, No. 6, December (1997)
pp. 804–812.
I. Chlamtac and S. Pinter, Distributed node organization algorithm for channel access in a multi-hop
packet radio network, IEEE Transactions on Computers, Vol. 36, No. 6 (1987) pp. 728–737.
C. J. Colbourn and J. H. Dinitz, (eds), The CRC Handbook of Combinatorial Designs, CRC Press,
Inc., Boca Raton, FL (1996).
C. J. Colbourn, J. H. Dinitz and D. R. Stinson, Applications of combinatorial designs to
communications, cryptography, and networking. In J. D. Lamb and D. A. Preece (eds.), Surveys in
Combinatorics, 1999, London Mathematical Society, Lecture Note Series 267, Cambridge University
Press (1999) pp. 37–100.

COVER-FREE FAMILIES AND TOPOLOGY-TRANSPARENT SCHEDULING

95

11. C. J. Colbourn, V. R. Syrotiuk and A. C. H. Ling, Steiner systems for topology-transparent access
control in MANETs. In Proceedings of the Second International Conference on Ad Hoc Networks and
Wireless (AdHoc Now’03), Montreal, Quebec (2003) pp. 247–258.
12. D.-Z. Du and F. K. Hwang, Combinatorial Group Testing and its Applications, World Scientiﬁc
Publishing Co. Pte. Ltd., second edition (2000).
13. A. D’yachkov, V. Rykov and A. M. Rashad, Superimposed distance codes, Problems Control and
Information Theory, Vol. 18 (1989) pp. 237–250.
14. P. Erdös, P. Frankl and Z. Füredi, Families of ﬁnite sets in which no set is covered by the union of r
others, Israel J. Math., Vol. 51 (1985) pp. 79–89.
15. A. S. Hedayat, N. J. A. Sloane and J. Stufken, Orthogonal Arrays, Theory and Applications, SpringerVerlag, Inc., New York, NY (1999).
16. J.-H. Ju and V. O. K. Li, An optimal topology-transparent scheduling method in multihop packet
radio networks, IEEE/ACM Transactions on Networking, Vol. 6, No. 3, June (1998) pp. 298–306.
17. A. D. Myers, V. R. Syrotiuk and G. Záruba, An adaptive generalized transmission protocol for
mobile ad hoc networks, ACM/Kluwer Journal on Mobile Networks and Applications (MONET),
Vol. 7 (2002) pp. 493–502.
18. L. Romdhani, Q. Ni and T. Turletti, AEDCF: Enhanced service differentiation for IEEE 802.11
wireless ad-hoc networks, Technical Report 4544, INRIA (2002).
19. M. Ruszinkó, On the upper bound of the size of the r-cover-free families, Journal of Combinatorial
Theory, Series A, Vol. 66 (1994) pp. 302–310.
20. J. L. Sobrinho and A. S. Krishnakumar, Quality-of-service in ad hoc carrier sense multiple access
wireless networks, IEEE Journal on Selected Areas in Communications, Vol. 17, No. 8, August (1999)
pp. 1352–1368.
21. D. R. Stinson, R. Wei and L. Zhu, Some new bounds for cover-free families, Journal of
Combinatorial Theory, Series A, Vol. 90 (2000) pp. 224–234.
22. V. R. Syrotiuk, C. J. Colbourn and A. C. H. Ling, Topology-transparent scheduling in MANETs
using orthogonal arrays, In Proceedings of the DIALM-POMC Joint Workshop on Foundations of
Mobile Computing, San Diego, CA (2003) pp. 43–49.
23. V. R. Syrotiuk, Wireless medium access control protocols, In (A. Boukerche and I. Chlamtac, eds.),
Handbook on Algorithmic Aspects of Wireless Networks, CRC Press, (to appear).
24. Waterloo Maple Inc., Maple 8. http://www.maplesoft.com/main.html
25. R. Zheng, C.-J. Hou and L. Sha, Asynchronous wakeup for ad hoc networks, Proceedings of the
Fourth International Conference on Mobile Ad Hoc Networking & Computing (Mobihoc03),
Annapolis, MD, June 1–3 (2003) pp. 35–45.
26. C. Zhu and S. Corson, A ﬁve-phase reservation protocol (FPRP) for mobile ad hoc networks, In
Proceedings of 17th Annual Joint Conference of the IEEE Computer and Communication Societies
(INFOCOM’98), San Francisco, CA, March 29–April 2 (1998) pp. 315–321.

Access Control in Heterogeneous Multichannel
Wireless Networks
Michael P. McGarry and Martin Reisslein

Violet R. Syrotiuk

Department of Electrical Engineering
Arizona State University
Tempe, Arizona 85287
Email: {michael.mcgarry,reisslein}@asu.edu
Phone: +1-480-965-8593

Department of Computer Science and Engineering
Arizona State University
Tempe, Arizona 85287
Email: syrotiuk@asu.edu
Phone: +1-480-965-7034

Abstract— We propose a multichannel wireless network architecture that supports nodes with differing multichannel capabilities. Both contention and contention-free medium access
control (MAC) protocols are proposed for this heterogeneous
multichannel network. In the contention MAC protocol, a new
LRN control packet is defined that allows a pair of nodes to
re-negotiate channel selection. This relaxes the assumption that
nodes can sense the carrier on all supported channels in a
short period of time. We model the scheduling problem for our
contention-free MAC protocol as a weighted bipartite matching
problem that minimizes the sum of the completion times with
polynomial time complexity. We close with an illustration showing
how the weighted bipartite matching generates a transmission
schedule.

I. I NTRODUCTION
Driving the need for more efficient use of available spectrum
are software defined radios (SDRs) [1] that allow for software
control of certain parameters of the transceiver operation in
the interest of dynamic reconfiguration (e.g., carrier frequency,
modulation scheme, etc.) [2], [3]. SDRs will be a key enabler
for networks with multichannel capabilities. This necessitates
the need for MAC protocols that can take advantage of capacity available across a wide spectrum such as that proposed in
DARPA’s Next Generation (XG) [4] vision. Another important
characteristic for future MAC protocols is the need to interoperate with legacy (i.e., non-multichannel) nodes with such
emerging multichannel nodes. These multichannel networks
can provide a significant increase in available bandwidth as
compared to single channel networks that are constrained to
the bandwidth available on a single communication channel.
Multichannel networks can also provide benefits beyond
additional bandwidth. For networks employing a contention
medium access control (MAC) protocol, multiple channels
can reduce the probability of collisions and thereby improve
throughput as a result of fewer back-offs and reduced interference [5], [6]. This is true even if the aggregate capacity
of the multiple channels is the same as the capacity of the
single channel network. Multiple channels can also aid in
providing Quality of Service (QoS). Channels can be allocated
for certain traffic classes. As well, admission control can
be implemented on some channels, while other channels are
allocated for best effort traffic. Further, a contention MAC

protocol could operate on some channels, while others operate
via a contention-free MAC protocol.
In this paper, we describe a multichannel wireless network
where nodes are heterogeneous with regard to their multichannel support (e.g., multichannel capable as well as legacy
single channel nodes). In other words, each node has its own
set of the multiple channels that it supports. We then propose
multichannel MAC protocols for this network. In our proposed
MAC protocols we assume symmetric channel support (i.e., if
a channel is supported then it is supported for both reception
and transmission). However, minor extensions to the protocols
can be made to provide asymmetric channel support.
To our knowledge, our protocol is the only multichannel
MAC protocol to support a heterogeneous multichannel environment. This flexibility allows for nodes to have different
transceiver capabilities.
This paper is organized as follows. In Section II we discuss
related work. Section III describes our proposed architecture.
In Sections IV and V we propose contention and contentionfree media access protocols, respectively. Finally, Section VI
concludes our work with a discussion of future research
directions.
II. R ELATED W ORK
We will now outline the existing research work related to
multichannel wireless networks.
Jung et al. [7] do not make the assumption that all nodes can
always listen to the control channel. Therefore, a multichannel
hidden terminal problem arises. To deal with this all nodes
are forced to use the control channel during a special window,
modeled after the Power Saving Mode (PSM) of 802.11; this
requires node synchronization.
The multichannel hidden terminal problem is illustrated in
Figure 1. We can see that because nodes X and Y are tuned
to channel 2 for their data transmission, they did not hear
the Request to Send (RTS) and Clear to Send (CTS) message
exchange between nodes Z and W on the control channel.
This results in a collision on channel 2.
In [9], Choi et el. propose another solution to the multichannel hidden terminal problem. They propose setting a maximum
transmission time (MTT) on each channel. This guarantees

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or
distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on
servers or to redistribute to lists, requires prior specific permission and/or a fee.
InterSense '06. Proceedings of the First International Conference on Integrated Internet Ad hoc and Sensor Networks, May 30-May 31 2006, Nice, France
©2006 ACM 1-59593-427-8/06/05...$5.00

Fig. 1.

Multichannel Hidden Terminal Problem [8]

that a data channel is not busy for longer than this MTT. Thus
allowing nodes to estimate the free time of a channel for which
they have no up to date Network Allocation Vector (NAV) due
to the multichannel hidden terminal problem. Setting MTTs of
unique values for each channel has the added benefit of aiding
QoS support. Channels allocated for delay sensitive traffic can
have MTTs set to small values to guarantee a channel is not
blocked for long periods of time. Channels allocated for best
effort data traffic can have very large MTT values, so as to
not cause fragmentation for large packets.
In our proposed MAC protocols we avoid the multichannel
hidden terminal problem by requiring that all nodes support
a “base” channel that is used as the sole control channel
and further that this control channel can be continuously
monitored. In our conclusion we discuss briefly how we
can augment our proposal to support a network where the
multichannel hidden terminal problem arises.
Nasipuri et al. [10] propose a contention MAC for a
multichannel network with one control channel and N data
channels. All nodes continuously monitor the control channel,
eliminating the multichannel hidden terminal problem. The
protocol selects the idle channel (assuming it can sense carrier
on all channels quickly) that has been used most recently.
An extension to the above work is proposed in [11] where
the channel selection is now performed at the receiver as well.
A free channel in common between transmitter and receiver
is selected.
Wu et al. [12] also propose a multichannel MAC that performs channel selection at both the receiver and the transmitter.
Garces and Garcia-Luna-Aceves propose a multichannel
network in which each node has its own receiving channel
within a two-hop neighborhood [13]. Time is then divided
into reception and transmission periods. Nodes compete using
RTS packets with a tree-splitting back-off algorithm to avoid
collisions. This architecture does not scale well because each
node in a two-hop neighborhood must have a unique channel.
As well, since a channel is fixed to a node this protocol can
not take advantage of statistical multiplexing across nodes.
Two thorough surveys on multichannel MACs for wireless
networks are available [6], [8].
All of the multichannel MAC protocols proposed in the
research literature assume all nodes support the same set
of channels (homogeneous multichannel environment). We

propose an architecture that, to our knowledge, is the only
multichannel MAC protocol to support a heterogeneous multichannel environment.
III. H ETEROGENEOUS M ULTICHANNEL W IRELESS
N ETWORK A RCHITECTURE
We propose a multichannel wireless network that supports
heterogeneity with regard to each node’s support of multiple
channels. We envision a heterogeneous network consisting of
single channel legacy nodes along with new emerging multichannel nodes. The emerging multichannel nodes will have
a diverse set of multichannel transceivers. Some multichannel
nodes can be implemented with a single transceiver, utilizing
Software Defined Radio (SDR) technology, thereby enabling
the node to “tune” to any of a set of multiple channels by
changing some “soft” parameters in the transceiver. Existing
alongside these can be nodes that support multiple channels by
having transceiver arrays that are made possible by RF circuit
integration advances.
This heterogeneous multichannel network will not impose
any particular multichannel transceiver architecture on any
node. The only requirement in our heterogeneous network
architecture is that all nodes support a “base” channel that acts
as the control channel and default data channel. This channel
can be thought of as a “lobby” where nodes meet by default
to negotiate a place to conduct their transmission. All nodes
must be able to continuously monitor this channel to avoid
the multichannel hidden terminal problem. For legacy single
channel nodes, the “base” channel would be the only channel
supported.
A method is needed to enumerate the channels. This enumeration scheme needs to be known by all nodes, so a standard
should be developed. A detailed discussion of this is outside
the scope of this paper. We simply assume that a common
enumeration scheme exists.
IV. C ONTENTION MAC P ROTOCOL
In this section we propose a contention MAC protocol for
the heterogeneous multichannel wireless network described in
the previous section.
We now detail our proposed method of access arbitration.
We provide two modes of operation for access arbitration,
brute-force and negotiation-based channel selection. Bruteforce channel selection is for networks whose nodes can

sense the carrier on all supported channels reasonably fast.
The negotiation-based channel selection only requires one
supported channel to be sensed at a time. The negotiationbased approach can take much longer to arbitrate access but
can statistically provide faster arbitration since nodes do not
have to wait until they have sensed all channels. We now detail
these two approaches.
A. Brute-Force Channel Selection
The brute-force channel selection scheme works as follows.
When a node has a packet to transmit to another node, it
transmits an RTS packet on the “base” channel. In this RTS
packet it sends a proposed list of channels for communication.
This list is the set of channels supported by this node that are
available for transmission (i.e., sensed as clear through clear
channel assessment), sorted in the order of the sensed level of
clarity.
Upon receipt of the RTS packet by the intended receiver,
a channel is selected from the proposed list from the sender,
and that is supported by and sensed as clear at the receiver.
If there is no channel matching this criteria then the receiver
does not respond with a CTS, otherwise the receiver sends a
CTS with the selected channel noted.
When the sender receives the CTS it transmits its data on the
channel specified. All other listening nodes mark this channel
unavailable for the time specified in the CTS. Once the data is
received by the receiving node, this node will return an ACK
to the sender.
B. Negotiation-based Channel Selection
For nodes where sensing all the supported channels is not
possible in a reasonable amount of time, another approach can
be followed. Instead of preparing a list of channels to go in the
RTS, the sender can send a single “proposed” channel that has
been sensed as clear. If the receiver agrees with this proposal
(i.e., the channel is supported and clear at the receiver), it sends
a CTS to acknowledge its agreement and data transmission
occurs on the selected channel.
However, if the receiver either does not support the channel
or it is not free at the receiver, instead of responding with a
CTS the receiver responds with the new LRN (“Let’s ReNegotiate”) packet that signals a re-negotiation of the channel.
The receiver selects a channel that it supports and is currently
free at the receiver and inserts it in this LRN packet. When the
sender receives this LRN packet it determines if the channel
selected is supported and if it is free at the sender. If so, it
sends a new RTS with this channel, otherwise it selects a
different channel and inserts this in the new RTS. When the
receiver node receives this new RTS, if it contains the channel
it proposed in the LRN and that channel is still free at the
receiver it sends a CTS and the data transmission occurs on
the selected channel.
If the originally proposed channel is no longer free or the
RTS contains a channel other than the one in the LRN, the
receiver goes back to renegotiate. (A finite limit must be set
on the number of re-negotiations before the two nodes give.)

Sender

Receiver
RTS

channel not supported,
propose other channel

LRN

proposal
OK

new R

TS

Channel still clear
CTS
Data

ACK

Fig. 2.

Illustration of Channel Selection Process

Figure 2 illustrates the channel selection process using the
new LRN control packet.
V. C ONTENTION -F REE MAC P ROTOCOL
In a contention-free MAC protocol we have the problem of
generating a transmission schedule based on requirements of
the nodes in the network. This transmission schedule would
be generated by a central node that arbitrates access for all
transmissions within its range. The arbitration mechanism
can mirror that already proposed for Ethernet Passive Optical
Networks [14], where the central node, called the Optical Line
Terminal, implements a polling MAC protocol, where nodes,
called Optical Network Units would be polled for both their
transmission requirements and to grant exclusive access to the
shared medium. For our wireless network equivalent, upon
polling all nodes in its range to obtain information regarding
all requested transmissions, as well as having prior information about each nodes multichannel transceiver capabilities
(provided by some means of network registration), the central
node, will produce the schedule and send messages to grant
each transmitting node a certain time of exclusive access to
a specified channel. We will now explore algorithms for the
transmission scheduling.
For a homogeneous multichannel network some scheduling
algorithms have been proposed [15]. These scheduling algorithms require nodes to support all channels. In this section we
propose scheduling algorithms using results from scheduling
theory [16] that allow for nodes to support different channels.
The multichannel scheduling problem can be formulated
using the scheduling notation defined in [16]. In scheduling
notation, a scheduling problem is defined by a triple α|β|γ,

where α describes the machine environment (e.g., single
machine, parallel machines, etc.), β describes the processing
characteristics and constraints, and γ describes the objective
to be minimized.
Mapping our problem to a problem in scheduling theory,
transmissions from nodes correspond to jobs, their transmission slot requirements correspond to processing times, and the
channels used for transmission correspond to the machines.
In scheduling notation the formulation for our scheduling
problem is:

wj Cj
P |Mj |
j

or
P |Mj |Cmax
. In the above model, P refers to the P identical parallel machines (channels) that defines our machine environment. Our
only processing characteristic or constraint is the Mj which
refers to machine (channel) eligibility constraints. Specifically,
Mj is the set of machines (channels) that job (node) j can
be executed (transmitted) on. This is required because each
node has its own subset of supported channels. If all nodes
supported transmission on all channels we could remove
the

machine eligibility constraint to obtain models P || j wj Cj
or P ||Cmax , where the β part of the scheduling notation triple
is omitted since we have no processing constraints. Finally,
we

w
Cj
have two possible objectives to minimize: 1) the
j
j
is the sum of the weighted completion times of jobs and 2)
the Cmax is the make-span of the schedule. The completion
time, Cj , is the time at which the transmission for node j is
complete. The make-span, Cmax , is the maximum completion
time or the length of the schedule produced. Minimizing the
make-span, maximizes the load balancing. Maximizing the
load balance would allow the network to more efficiently
utilize the transmission resources, this will indirectly lower
queueing delays.
If all nodes support transmission on all channels we can
remove the machine eligibility constraints and obtain the
following models.
P ||Cmax is NP-hard [16], however LPT (longest processing
time first) rule provides a good upper bound on performance.
It is 4/3 − 1/3m competitive with the optimal, where m is
the number of machines. For an algorithm to be ρ competitive
means in the worst case this algorithm is ρ times worse than
optimal.

P || j Cj is solved to optimality by SPT (shortest processing time first) rule. However, when we add the weights,
the problem can only be solved by the heuristic WSPT
(weighted shortest
processing time first) rule. This heuristic
√
is 1/2(1 + 2) competitive with the optimal.
If we include the machine eligibility constraints, Least
Flexible Job (LFJ)
first scheduling is proven optimal for

P |Mj , pj = 1| j Cj and P |Mj , pj = 1|Cmax if the Mj have
a special nesting structure that may not be the case in our
network. The special nesting structure between the machine

eligibility constraints for 2 nodes holds if one and only one
of the following relationships holds for nodes j and k:
• Mj is equal to Mk
• Mj is a subset of Mk
• Mk is a subset of Mj
• Mj and Mk do not overlap
The pj = 1 (processing time for job j equals 1) component
means that the slot requirements of all the nodes would have
to be equal, or we would have to schedule individual slots
separately. This could produce unwanted fragmentation if the
individual slots are not scheduled consecutively (this opens the
possibility of them being scheduled during the same time but
on different channels; this concurrent transmission on multiple
channels may not be feasible). If we remove the pj = 1
requirement and/or the nesting structure of Mj , then LFJ is
simply a heuristic for the problem. We can augment the LFJ
heuristic by breaking ties with SPT for minimizing the sum of
completion times and with LPT for minimizing the make-span.
We refer to
 these heuristics as LFJ-SPT and LFJ-LPT.
P
|Mj | j wj Cj can be viewed as a special case of
R|| j wj Cj , where R refers to unrelated machines (machines
that have differing processing speeds that depend on the
individual job). So, processing time pj is now extended to
pij , since the processing time depends on the job j and the
machine i it is executed on. Accordingly, P |Mj |Cmax can
also be viewed as a special case of R||Cmax . For machines
that are in Mj we set the execution time multiplier on these
machines to 1, for machines not in Mj , we set the execution
time multiplier
on these machines to ∞.

R|| j wj Cj is strongly NP-Hard [16] and can be formulated as an integer program solvable by branch-and-price
methods (a form of branch-and-bound) [17], [18].
If we do not
require priority weighting, we can reduce the
above to R|| j Cj . This problem can be formulated as an
integer program with a special structure that yields an integer
solution under LP-relaxation. A common method used to solve
this problem is the weighted bipartite matching. A weighted
bipartite matching problem in which the number of jobs and
number of machines is equal is an assignment problem. The
time complexity of Weighted Bipartite Matching is O(n(m +
nlogn)). Where in our case, m is the number of channels and
n is the number of nodes.
n 
n
m 

kpij xikj
minimize
i=1 j=1 k=1

subject to

n
m 


xikj = 1, ∀j

i=1 k=1
n


xikj ≤ 1, ∀i , ∀k

j=1

where k is the scheduling position, pij is the number of slots
to be transmitted for transmission pair j on channel i, xikj
are binary variables representing whether or not position k

TABLE I

Tx−>Rx

Channel,Position

TABLE OF S UPPORTED C HANNELS
Node
1
2
3
4

1, 1

Supported Channels
1, 2
1
3
1, 2, 3

1−> 2

1, 2
1, 3

TABLE II

1, 4

T RANSMISSION S CHEDULE
Tx Node
1
2
2
3
4

Rx Node
2
1
4
4
1

Number of Slots
2
1
3
5
2

pij
2, ∞, ∞
1, ∞, ∞
3, ∞, ∞
∞, ∞, 5
2, 2, ∞

on machine (channel) i is selected for job (node) j, m is the
number of machines (channels) and n is the number of jobs
(nodes).
R||Cmax is NP-complete [16] and can be solved by a few
heuristics proposed by Davis and Jaffe [19]. We have already
identified a heuristic for minimizing the make-span, namely
LFJ-LPT, so we do not pursue this model any further.
If we do not
require priority weighting the most promising
model is R|| j Cj . Minimizing the sum of the completion
times helps to minimize the make-span as well. This in turn
minimizes the number of wasted slots.
For channels that are supported by both sender and receiver,
we set the processing time per slot of this channel (machine, in
our scheduling notation) to 1. For channels that are either not
supported by the receiver or the transmitter or both we set the
processing time per slot of this channel to ∞; this effectively
keeps the weighted bipartite matching algorithm from making
a match using this arc.
Figure 3 shows the weighted bipartite graph representing
the scheduling problem. The scheduling algorithm needs to
know the number of slots required for each sender-receiver
pair. There is a node on the left-hand side of the weighted
bipartite graph for each of these sender-receiver pairs. On
the right-hand side of that graph, there is a node for each
position on each channel. There are as many positions as
there are transmission pairs; this is for the possibility that
all transmissions are assigned to a single channel. The nodes
are connected by arcs with a certain weight. These weights
are determined by whether a channel is supported as well as
the number of slots to be assigned multiplied by the position
number.
The weighted bipartite matching algorithm then matches all
nodes from the left to a unique node on the right that produces
the smallest sum of weights.
We now illustrate this scheduling algorithm using a four
node three channel network. Table I shows the list of supported
channels for each of the four nodes. Table II shows the
transmissions to take place in the next scheduling round.
Referring back to figure 3, the selected arcs that produce

2−> 1

1, 5
2, 1

2−> 4

2, 2
2, 3
2, 4

3−> 4

2, 5
3, 1
3, 2

4−> 1

3, 3
3, 4
3, 5

Fig. 3. Illustration of Weighted Bipartite Matching, transmission pairs on
left are being matched to scheduling positions on the channels to the right.
The matchings produced are indicated by the bold lines.

a match for every node on the left with the minimum total
weight are highlighted. Arcs with infinite weight are infeasible
and left out of the figure. The weight of each arc is kpij , where
pij is the number of slots to be transmitted for transmission
pair i on channel j multiplied by either 1 or ∞ depending
on whether the channel is supported by both nodes in the
transmission pair or not. Finally, k is the position of the
transmission on the channel with respect to other transmissions
scheduled on the channel.
Figure 4 shows the schedule produced from the weighted
bipartite matching.
VI. C ONCLUSION
In conclusion, we have proposed both contention and
contention-free MAC protocols for heterogeneous multichannel wireless networks. In our contention MAC protocol we
have defined a new control packet, LRN, that allows a pair
of nodes to re-negotiate channel selection. This relaxes the
assumption that nodes can sense the carrier on all supported

Chnl 1
Chnl 2
Chnl 3

Fig. 4.

2−> 4

1−> 2

2−> 1

4−> 1
3−> 4

Schedule Output from Weighted Bipartite Matching

channels in a short period of time. We modeled the scheduling
problem for our contention-free MAC protocol as a weighted
bipartite matching problem that minimizes the sum of the
completion times in polynomial time.
For future research we can extend our protocols to incorporate methods for dealing with the following:
•

•
•

•

•
•
•

Add priority weighting into our schedule generation.
Priority weights would require the use of branch and price
methods to solve.
Support tunable transceivers. Tuning time can be factored
in when deriving schedules.
Support networks where multichannel hidden terminal is
an issue. (We could probably augment our solution with
the solution in [7].)
Allow for asymmetric channel support (i.e., channels
are not necessarily supported for both transmission and
reception).
Support nodes that cannot concurrently transmit on multiple channels.
Update scheduling algorithm to deal with multi-hop networks.
Investigate more intelligent channel selection schemes for
our contention MAC protocol.
R EFERENCES

[1] “Software defined radio forum,” http://www.sdrforum.org.
[2] W. H. W. Tuttlebee, “Software-defined radio: Facets of a developing
technology,” IEEE Personal Communications, vol. 6, no. 2, pp. 38–44,
April 1999.
[3] ——, “Advances in software-defined radio,” IEE Electronic Systems and
Software, vol. 1, no. 1, pp. 26–31, February 2003.
[4] “DARPA’s XG program,” http://www.darpa.mil/ato/programs/xg/.
[5] M. A. Marsan and D. Roffinella, “Multichannel local area network
protocols,” IEEE Journal on Selected Areas of Communications, vol. 1,
no. 5, pp. 885–897, November 1983.
[6] A. Nasipuri and S. Das, “Chapter 6: Multichannel MAC Protocols for
Mobile Ad Hoc Networks,” in Handbook of Algorithms for Wireless
Networking and Mobile Computing, A. Boukerche, Ed. Chapman &
Hall/CRC, 2006, pp. 99–122.
[7] J. So and N. Vaidya, “Multi-channel MAC for ad hoc networks:
Handling multi-channel hidden terminals using a single transceiver,” in
Proceedings of MobiHoc, May 2004, pp. 222–233, roppongi, Japan.
[8] A. Rangnekar, C. Wang, K. Sivalingam, and B. Li, “Chapter 5: Multiple
Access Protocols and Scheduling Algorithms for Multiple Channel
Wireless Networks,” in Handbook of Algorithms for Wireless Networking
and Mobile Computing, A. Boukerche, Ed. Chapman & Hall/CRC,
2006, pp. 77–98.

[9] N. Choi, Y. Seok, and Y. Choi, “Multi-channel MAC protocol for
mobile ad hoc networks,” in Proceedings of IEEE Vehicular Technology
Conference, October 2003, pp. 1379–1382.
[10] A. Nasipuri and S. Das, “A multichannel CSMA MAC protocol for
multihop wireless networks,” in Proceedings of IEEE WCNC, September
1999, pp. 1402–1406, new Orleans, LA.
[11] N. Jain, A. Nasipuri, and S. Das, “A multichannel CSMA MAC protocol
with receiver-based channel selection for multihop wireless networks,”
in Proceedings of IEEE International Conference on Computer Communication and Networks, October 2001, pp. 432–439, phoenix, AZ.
[12] S. Wu, C. Lin, Y. Tseng, and J. Sheu, “A new multichannel MAC
protocol with on-demand channel assignment for multi-hop mobile ad
hoc networks,” in Proceedings of IEEE Wireless Communications and
Networking Conference (WCNC 2000), September 2000, pp. 232–237.
[13] R. Garces and J. Garcia-Luna-Aceves, “Collision avoidance and resolution multiple access for multichannel wireless networks,” in Proceedings
of IEEE INFOCOM, 2000, pp. 595–602.
[14] M. McGarry, M. Maier, and M. Reisslein, “Ethernet PONs: A survey
of dynamic bandwidth allocation (DBA) algorithms,” IEEE Communications Magazine, vol. 42, no. 8, pp. S8–S15, August 2004.
[15] S. Damodaran and K. Sivalingam, “Scheduling algorithms for multiple channel wireless local area networks,” Computer Communications,
vol. 25, no. 14, pp. 1305–1314, 2002.
[16] M. Pinedo, Scheduling: Theory, Algorithms, and Systems, 2nd ed.
Prentice Hall, 2002.
[17] Z. Chen and W. Powell, “Solving parallel machine scheduling problems
by column generation,” INFORMS Journal on Computing, vol. 11, no. 1,
pp. 78–94, Winter 1999.
[18] J. Van Den Akker, J. Hoogeveen, and S. Van De Velde, “Parallel machine
scheduling by column generation,” Operations Research, vol. 47, no. 6,
pp. 862–872, Nov/Dec 1999.
[19] E. Davis and J. Jaffe, “Algorithms for scheduling tasks on unrelated processors,” Journal of the Association of Computing Machinery, vol. 28,
pp. 721–736, 1981.

2016 IEEE INFOCOM International Workshop on Computer and Networking Experimental Research Using Testbeds

Screening Interacting Factors in a Wireless Network
Testbed Using Locating Arrays
Randy Compton∗ , Michael T. Mehari† , Charles J. Colbourn∗ , Eli De Poorter† , Violet R. Syrotiuk∗
∗

School of Computing, Informatics, and Decision Systems Engineering
Arizona State University, Tempe, AZ, USA 85287-8809
† Ghent University - iMinds
Department of Information Technology (INTEC)
Gaston Crommenlaan 8 (Bus 201), B-9050 Ghent, Belgium
{randy.compton,colbourn,syrotiuk}@asu.edu, {eli.depoorter,mmehari}@intec.ugent.be

Abstract—Wireless systems exhibit a wide range of configurable parameters (factors), each with a number of values
(levels), that may influence performance. Exhaustively analyzing
all factor interactions is typically not feasible in experimental
systems due to the large design space. We propose a method
for determining which factors play a significant role in wireless
network performance with multiple performance metrics (response variables). Such screening can be used to reduce the set of
factors in subsequent experimental testing, whether for modelling
or optimization. Our method accounts for pairwise interactions
between the factors when deciding significance, because interactions play a significant role in real-world systems. We utilize
locating arrays to design the experiment because they guarantee
that each pairwise interaction impacts a distinct set of tests.
We formulate the analysis as a problem in compressive sensing
that we solve using a variation of orthogonal matching pursuit,
together with statistical methods to determine which factors are
significant. We evaluate the method using data collected from
the w-iLab.t Zwijnaarde wireless network testbed and construct
a new experiment based on the first analysis to validate the
results. We find that the analysis exhibits robustness to noise
and to missing data.

I. I NTRODUCTION
An experiment is a series of tests in which purposeful
changes are made to the parameters (factors) of a system in
order to observe and identify the reasons for changes observed
in an output response. Each test consists of a choice of value
(level) for each factor. In general, experiments are used to
study the performance of systems.
In this paper, the system studied is the w-iLab.t Zwijnaarde
wireless network testbed [1]. The aim is to screen the measured responses of mean opinion score (MOS) [2] and the
transmission exposure in a Wi-Fi audio broadcast, i.e., to
identify the factors and low order interactions that influence
these two measured responses.
Methods for planning experiments seek to reduce the number of tests required to screen because the exhaustive fullfactorial design [3], [4] is too large. For k factors each with
two levels there are 2k tests in the design. An analysis of
variance (ANOVA) is readily calculated from such an experiment as it measures each factor and each t-way interaction,
2 ≤ t ≤ k. From this, the important factors and interactions
may be identified.

978-1-4673-9955-5/16/$31.00 ©2016 IEEE

A fractional factorial design 2k−p is a 21p fraction of a full
factorial design with k two-level factors. A fractional factorial
design is saturated when it investigates k = N −1 factors in N
tests [4]. In a supersaturated design, the number of factors k >
N −1; these designs contain more factors than tests. However,
a supersaturated design is not large enough to estimate all the
factors, let alone any interactions [4]–[6].
A D-optimal design is one of the most popular experimental
designs among those using optimality criteria. A model to fit,
along with a bound on the number of tests, is specified a priori;
this restricts the factors to be analyzed to those in the model.
Multi-objective optimizers have been proposed to optimize
multiple, often competing, responses in wireless networks [7],
[8]. The SUMO toolbox contains techniques for experiment
generation, and the solution of such optimization problems.
In [2], the toolbox was applied to a problem in a wireless
network testbed using an exhaustive experiment. Necessarily,
the number of factors was small. Our interest is not to
eliminate factors from experimentation a priori. Instead, an
automatic and objective approach to screening is sought.
Reducing the number of tests required therefore relies on
a sparsity of effects assumption, that interactions of interest
involve at most a small, known number t of interacting factors.
As one means of reduction, locating arrays (LAs) have been
defined [9]. For a set of factors each taking on a number of
levels, an LA permits the identification of a small number of
significant interactions among few (factor, level) combinations.
Locating arrays have been applied to screen factors and
interactions in a simulated wireless network [10]. To the best
of our knowledge, our work is the first to apply locating arrays
for screening using data obtained from experimentation on a
real system, a wireless network testbed.
A locating array is constructed to provide the screening
experiment for a Wi-Fi audio broadcast with 24 factors having
2 to 5 levels each. An exhaustive experiment would contain
over 23 trillion tests, but the locating array has only 109
tests. Each test is run on the testbed. A compressive sensing
technique, orthogonal matching pursuit [11], is used to analyze
the results. It recovers a preliminary model and then uses that
model to decide which factors and levels, and which pairwise
interactions between them, are important.

We then construct a second locating array using factors
and levels deemed significant by the analysis of the first
experiment. The resulting locating array for 8 factors has 94
tests but has higher coverage. The analysis for the second
experiment differs both statistically and in terms of the constructed model from the first, so we repeated both experiments.
The analyses of these later experiments resemble those of the
second experiment. Indeed the later experiment with 109 tests
indicates no significant factors that the first one missed, so the
locating array with 94 tests remains appropriate. The analysis
seems robust to high levels of noise, and also to holding
constant the factors previously deemed insignificant.
II. L OCATING ARRAYS
A t-way interaction is a set of t of the factors, and an
admissible level for each. A (d, t)-locating array [9] on k
factors is an N × k array such that, for every set of d
distinct t-way interactions, the set of tests containing at least
one of those interactions is not the same as the set of tests
obtained from a different set of d distinct t-way interactions.
Interactions may appear in different numbers of tests; an
interaction has higher coverage if it appears in more tests.
Suppose the response measured in each test is pass or fail.
A locating array permits locating the set of t-way interactions
that cause the response of pass, provided there are at most d
of them. A (d, t)-detecting array [9] is similar, but requires
that the responses for a set of d t-way interactions rule out
each t-way interaction not in the set of d. Reconstruction of
the set of t-way interactions yielding a given set of responses
is not known to be polynomial-time computable using locating
arrays; when detecting arrays are used, efficient reconstruction
is possible.
As we might expect, the responses measured in a real
system, such as a wireless network testbed, have continuous
values. However, significant interactions may not all have
effects of the same magnitude. Therefore weak interactions
may be indistinguishable from noise, so we seek to recover d
or fewer most significant interactions above the noise floor.
Locating arrays were not introduced to handle continuous
responses, but even a (1, 2)-locating array should suffice when
the separation between effect magnitudes is large enough.
Indeed the largest factor or interaction can be determined and
its effect subtracted, leaving a similar problem for the remaining interactions. This suggests a “heavy hitters” approach for
sparse model recovery.
III. S CREENING ALGORITHM
A. Sparse model recovery
As in the field of compressive sensing, our objective is
to determine a sparse representation of experimental data;
in particular, we seek to minimize the `0 norm, the number
of nonzero terms in the representation. Unfortunately minimizing using the `0 norm is NP-hard. Using the `2 norm
permits solution via linear least squares regression, but it tends
to produce representations with many more nonzero terms
than necessary [12]. Nevertheless, there exist computationally

tractable methods of better approximating the `0 norm, among
them orthogonal matching pursuit (OMP) [11]. We utilize
OMP because it iteratively identifies one term at a time to
add to the representation.
Assuming sparsity of effects, because we screen for a small
number of significant factors and low order interactions within
a large number of possible ones, our problem can be cast in
terms of sparse signal recovery. To turn a locating array into a
compressive sensing matrix, we treat the factors as categorical
and replace each test of the locating array with the 1-ary
through t-ary combinations of the factor settings from that
test, so that each way of setting the levels of factors involved
in an interaction gets its own index and is thus available to be
chosen separately in the sparse reconstruction. The resulting
matrix provides multiple ways of representing some models.
B. Orthogonal matching pursuit
We modify orthogonal matching pursuit to solve our sparse
recovery problem. Orthogonal matching pursuit incrementally
builds a linear model of the data by choosing at each step the
factor or interaction that best explains the residuals remaining
from the previously-constructed model, then adds the chosen
term to the model and recomputes the model coefficients.
It uses the dot product of each candidate term with the
residuals to select a term, because the term with the highest
dot product is the closest to being orthogonal to the residuals.
Then the chosen term is added to the model, the coefficients
are recomputed via linear least-squares regression, and the
residuals are recomputed as the difference between the original
data and the new model’s predictions [11].
We modify OMP to use Welch’s unequal-variances t-test
[13] instead of the dot product in term selection: We choose the
term with the t-value of largest magnitude, because its explanation of some of the remaining variance is more statistically
significant than that of any other term. If noise is (close to)
normally-distributed, terms with higher coverage have lower
expected variance; the variance is least when half the tests
are selected by that term. Therefore the t-test automatically
handles the effects of differing coverage. Because the modelbuilding portion of OMP is unchanged, the residuals at each
step are in a subspace orthogonal to all chosen terms, ensuring
that the model explains as much of the data as possible for a
linear model.
C. Significant factor identification
To avoid overfitting and to obtain a smaller model for
screening, we sort the coefficients by decreasing absolute
value, then take the largest coefficients prior to a cutoff. This
cutoff is determined based on the R2 value for the model built
on just those coefficients — when it first crosses some prespecified threshold or when its increase upon adding the next
term to the model becomes sufficiently small. R2 measures
how much of the original variance remains after accounting for
a model: 1−R2 equals the sum of squares of residuals divided
by sum of squares of the original data after subtracting the
mean, resulting in a range from 0 (no correlation) to 1 (perfect

reproduction of data points) [14]. Were the full computation
too expensive, one could stop OMP early, but this could miss
an important factor to be discovered later.
For screening, we retain factors appearing before the cutoff,
whether alone or in an interaction with another factor, as significant. To determine levels to retain, we keep both extremes
of each retained factor with an ordinal interpretation and each
level chosen at least once before the cutoff for every type
of factor. If only one level is not chosen, we also retain it,
because the other levels must have been deemed significant in
their contrast with it. For categorical factors, it is necessary to
retain all levels due to lack of “extreme” value(s) for contrast.
When there are multiple responses but a single set of factors
is desired, we can consider the pre-cutoff terms from all
responses together to determine which factors and levels may
be significant to the whole system.
IV. E XPERIMENTAL SETUP
A. The w-iLab.t testbed
Due to the increasing prevalence of network testbed facilities [15], [16], complex experimentation in wireless networks
is now possible. The advantage of such facilities compared
to simulation is that they correctly include the propagation
and behaviour effects from the underlying physical layer and
hardware. The iMinds w-iLab.t [1] at Zwijnaarde is one testbed
that is used to perform heterogeneous wireless experimentation. The iMinds w-iLab.t testbed is pseudo-shielded from
external interference and is equipped with various wireless
technologies, including IEEE 802.11, IEEE 802.15.4, Bluetooth dongles, Software Defined Radios (SDRs), LTE femto
cells, and others. The w-iLab.t testbed is part of Emulab and is
controlled by the cOntrol Managment Framework (OMF) used
for resource allocation, hardware and software configuration,
and the orchestration of experiments. Finally, measurement
data from each test is collected and stored in a central database
over a wired control network for further processing.
B. Scenario

3.6m

20.5m
6m

66m

Fig. 1. High-level overview of the experiment scenario, as mapped to the
wireless testbed. Listener nodes are in the first 4 rows (nodes 1-20, 22-31,
and 33-42) and the speaker node is positioned at the bottom center (node 55).

A high-level representation of the Wi-Fi conferencing scenario created in the w-iLab.t testbed is shown in Fig. 1. It is
composed of a speaker node broadcasting voice traffic over a

Wi-Fi network and listener nodes receiving and playing the
transmitted packets. The speaker can configure 24 different
factors (described in §IV-C) that influence the transmissions.
The listeners continuously calculate audio quality and transmission exposure.
The audio quality is quantified using an aggregate MOS [17]
metric over the complete audio transmit path. During raw
audio encoding at the speaker side, the transmission bitrate
is reduced relative to the source material. The audio quality is
expected to be further reduced when transmitted over the air
because MOS is computed from packet loss, jitter, and latency.
Transmission exposure calculates the electromagnetic energy absorbed by a human body due to uplink and downlink
wireless transmissions [2].
To orchestrate the experiment, an OMF script was written
to process the experiment given by the locating array. The
OMF script allocates resources and iteratively executes each
test. During execution, the system is first brought to a known
state by resetting all wireless interfaces and caches of each
node, followed by configuration of the factors as specified
by the test. After a warm-up period to avoid transient effects,
measurements are collected. Table I shows the list of resources
used for the Wi-Fi conferencing scenario.
TABLE I
E XPERIMENT RESOURCE DESCRIPTION .
Resource
Wi-Fi chipset
Wi-Fi driver
OS
kernel
AP authenticator
Client supplicant

Description
Atheros Sparklan WPEA-110N/E/11n
ath9k
Ubuntu 14.04 LTS
Linux 3.13.0-33-generic
hostpad 2.3
wpa supplicant 2.3

C. Selected factors and levels
Table II gives the factors and levels used in experimentation.
We chose factors based on whether they could be set when a
test was run and had potential relevance to our networking
scenario, even if we expected an effect to be unlikely. (Recall
that our goal is an automatic and objective approach to screening.) We selected 24 factors that may affect the Wi-Fi card,
the IP and UDP stacks, and the audio codec. Except for the
audio codec parameters, these were found from examination
of the Ubuntu online documentation. In the end, sensing and
ROHC were not implemented.
For the categorical (e.g., qdisc) and ordinal factors, we
selected up to 5 levels. We excluded the maximum Wi-Fi
bitrate supported by both bands (54 Mbps) because the failure
rate was too high to get useful data. For continuous factors
other than percentages, we chose up to 5 exponentially-spaced
levels to avoid privileging any particular scale, ensuring that
the default (if any) was present while adding lower values
under the assumption that the defaults are conservative. For
percentages we chose 3 to 5 evenly spaced levels, except that
if there is a default it is included.

TABLE II
FACTORS AND LEVELS USED IN EXPERIMENTATION ( DEFAULT LEVELS FROM U BUNTU IN BOLD ).
Factor
Band
Channel
Wi-Fi bitrate
Transmit power
MTU
Transmit queue length
Queuing discipline
IP fragment low threshold
IP fragment high threshold
UDP receive buffer minimum
UDP receive buffer default
UDP receive buffer maximum
UDP transmit buffer minimum
UDP transmit buffer default
UDP transmit buffer maximum
UDP global buffer minimum
UDP global buffer pressure
UDP global buffer maximum
Robust header compression
Audio codec
Audio codec bitrate
Frame length aggregation
Interference channel occupancy
Sensing

Identifier
band
channel
bitrate
txpower
mtu
txqueuelen
qdisc
ipfrag low thresh
ipfrag high thresh
udp rmem min
rmem default
rmem max
udp wmem min
wmem default
wmem max
udp mem min
udp mem pressure
udp mem max
ROHC
codec
codecBitrate
frameLen
intCOR
sensing

Levels
2.4, 5 GHz
1, 6, 11 (2.4 GHz); 36, 40, 44 (5 GHz)
6, 9, 12, 24, 36 Mbps
1, 2, 5, 10, 20 dBm
256, 512, 1024, 1280, 1500 bytes
10, 50, 100, 500, 1000 packets
pfifo, bfifo, pfifo fast
25%, 50%, 75%, 100% of high threshold
16384, 65536, 262144, 1048576, 4194304 bytes
1.9231%, 10%, 50% of maximum
0%, 25%, 50%, 75%, 100% from minimum to maximum
2304, 10418, 47105, 212992 bytes
1.9231%, 10%, 50% of maximum
0%, 25%, 50%, 75%, 100% from minimum to maximum
4608, 16537, 59349, 212992 bytes
25%, 50%, 75% from minimum to maximum
0%, 33.338%, 50%, 75%, 100% from minimum to maximum
95, 949, 9490, 94896 pages
off, on (unimplemented but present as a factor)
Opus, Speex
7600, 16800, 24000, 34000 bit/s (or nearest allowed by codec)
20, 40, 60
10%, 25%, 50%, 75%, 90%
off, on (unimplemented but present as a factor)

D. The locating array
The locating array constructed for our Wi-Fi scenario is a
(d = 1, t = 2)-locating array, meaning it only guarantees to
be able to locate (identify) at most one (d = 1) one-way or
two-way (i.e., up to t = 2-way) interaction in each iteration of
the screening algorithm. It is remarkable that it distinguishes
all one-way (i.e., all (factor, level) combinations) and all twoway interactions (i.e., all pairs of (factor, level) combinations)
in only 109 tests.
V. A NALYSIS
A. Post-processing of measured responses
A complete set of responses was obtained for 25 different
listeners in the experiment. The other 15 listeners failed to
send any data to the controlling node for at least one test.
These 15 were excluded from analysis, because sub-arrays of
a locating array may not preserve the locating property, so a
partial data set may fail to have an unambiguous interpretation.
Determining values for the failed cases is problematic. We
attempted to determine causes of the failures by treating each
response as pass/fail and making use of the locating property
of the array, but the failures appear not to be caused by a
single level of a factor or 2-way interaction, which is all our
array guarantees to locate. It is also possible that the failures
could be intermittent, frustrating efforts to locate them.
We grouped the listening nodes’ responses using hierarchical agglomerative clustering [18] to create an additional factor
for location, which resulted in 3 levels of roughly equallysized clusters. This factor was added because locations of the
nodes across the testbed might have non-negligible effects on
their performance due to metal objects, walls, other devices

not participating in our experiment, and the like. The locating
array remains (1, 2)-locating with the added factor.
Exposure measurements at the listeners yielded values much
smaller than at the speaker, so we used just the exposure data
from the speaker node, while MOS was available only at the
listeners. Although our method could separately handle packet
loss, jitter, and latency, we exclude them for brevity as their
effects are already included in MOS. Computations for postprocessing and analysis were performed using Octave [19].
To determine appropriate transformations to apply to the
data, we produced probability plots for MOS and exposure.
A straight line on a probability plot indicates the data fits the
chosen probability distribution. For the first data set, MOS
appears not to be uniformly or normally distributed, but it
does appear closer to uniformly distributed after taking the
exponential (see Fig. 2), so later analysis used the exponentials
of the MOS values. Exposure, on the other hand, appears to
be log-normally distributed (see Fig. 3), so the logarithms of
the exposure values were used. As validation of our choice
of transformation in the case of MOS, the total R2 achieved
by letting OMP execute until it the model has as many
terms as there are runs is about 0.70 with the exponential
transformation, while the untransformed data yields a final
R2 of approximately 0.35. This suggests that the exponential
transformation allows the model to account for about twice as
much of the variance in the data.
B. Results and confirmation experiments
The top factors and interactions for both responses for the
first data set are given in Tables III and IV, along with the
R2 value for the model so far. Only the signs of the terms are
shown because their model coefficients change as more terms
are added to the model. The OMP rank denotes the order in

which the terms were selected by OMP prior to being sorted
by coefficient. The cutoffs are shown when R2 changes by a
negligible amount, here taken to be less than 0.01.

5

MOS

4

TABLE III
T OP TERMS IN EXP (MOS) MODEL ; CUTOFF AFTER SECOND ROW.
Rank OMP Rank
1
1
2
2
3
15
4
11
5
18
6
37
7
5
8
34
9
23
10
27

3

2

1
0

20

40

60
Rank

80

100

R2
0.474
0.551
0.555
0.561
0.571
0.571
0.592
0.592
0.596
0.596

TABLE IV
T OP TERMS IN LOG ( EXPOSURE ) MODEL ; CUTOFF AFTER SIXTH ROW.

80

exp(MOS)

Factor(s)
codecBitrate=7600/7750
codecBitrate=16800
codec=opus×codecBitrate=16800
channel=11/44
ipfrag low thresh=1×udp rmem min=0.1
channel=11/44×udp mem min=0.75
intCOR=0.9
sensing=1
channel=6/40×codec=speex
udp rmem min=0.1×wmem max=59349

120

100

Rank OMP Rank
1
1
2
3
3
4
4
6
5
2
6
5
7
10
8
20
9
11
10
8

60

40

20

0
0

20

40

60
Rank

80

100

120

Fig. 2. Uniform (top) and exponential-uniform (bottom) distribution plots for
MOS for all listener nodes that reported measurements in each test.

2

1

log(exposure)

Sign
−
−
+
−
−
+
−
+
−
+

0

-1

-2

-3
-3

-2

-1
0
1
Standard deviations

2

Fig. 3. Log-normal distribution plot for exposure at speaker node.

3

Sign
−
+
+
+
−
+
+
−
+
+

Factor(s)
rate=36
frameLen=20
band=5×channel=11/44
rate=6
rate=24
codecBitrate=34000/34200
frameLen=40
band=2.4×intCOR=0.5
rate=9
band=2.4×channel=1/36

R2
0.350
0.432
0.545
0.695
0.838
0.882
0.884
0.886
0.895
0.906

In order to confirm the screening results, a follow-up experiment is conducted. For this experiment, we generated another
locating array on the 8 significant factors screened by the
first locating array: band, channel, Wi-Fi bitrate, codec, codec
bitrate, frame length aggregation, and interference channel
occupancy. The last factor has just the 10%, 50%, and 90%
levels retained and the others have all their original levels. All
other factors are held constant at their defaults. This locating
array is a (2, 2)-locating array with 94 tests; we increased the
locating ability because we have fewer factors.
The experiment using this locating array resulted in a second
data set, in which 28 of the 35 available listener nodes
reported measurements in all tests. The MOS distribution
for this experiment has similar shape to the first experiment.
The exposure measurements appear log-uniformly rather than
log-normally distributed and also cover a different range.
The cause of this difference is unknown, so we re-ran both
experiments again, for which 36 listener nodes were available.
Of these 27 reported in all tests of the experiment with 109
tests and 28 reported in all tests of the experiment with 94
tests. The data set from the repeated experiment with 109 tests
has similar MOS distributions to the others, and the exposure
measurements resemble the second data set, so it appears that
whatever changed between the first and second experiments
remained the same thereafter.
The data set from the repeated experiment with 109 tests
agrees with the second experiment. We find that it selected

a subset of the factors and levels that the first experiment
selected, so the tests used in the second experiment are still
justified. For MOS for all data sets, the location factor we
added did not appear significant either in isolation or in
interactions, although including it did change the full model
and its R2 value slightly.
For further justification of our analysis, we compared the
data sets pairwise using an additional “set” factor to denote
which set each data point came from. The intuition is that, if
the “set” factor is considered significant, we have reason to
suspect it has some model-relevant difference. We also used
the Kolmogorov-Smirnov test [20] to compare the statistical
distributions of the data sets for reference. We find perfect
agreement between whether the “set” factor was selected
before R2 ≥ 0.9 and whether the Kolmogorov-Smirnov test
would reject the distributions’ equality at the 0.05 significance
level, providing a consistency check of our analysis. Although
the MOS distributions of both 109 test experiments differ from
each other and from both 94 test experiments, the data sets all
select just the codec bitrate as significant, except the second
data set that also selects codec type. This suggests that our
method has some robustness to noise.
We also analyzed each data set including the nodes with
missing data points, adding a factor to distinguish them from
those with all values present. Each found no significance in
whether all data points were present, so our choice to exclude
data from incomplete nodes does not affect the conclusions.
VI. C ONCLUSIONS AND F UTURE W ORK
To the best of our knowledge, this paper is the first to
present results of screening using locating arrays in a physical
system that is likely to have non-negligible interactions. A
simulation might lack interactions that appear in real systems
or include spurious interactions due to aspects of the hardware
that are not well-modelled. Indeed the method could be used
to compare the results of experimentation in a simulated to a
physical wireless network.
Our analysis method applied to the results of tests selected
by a locating array is able to rule out most insignificant
factors and levels, which can in turn significantly reduce the
number of runs required in later experimentation. Responses
are relatively consistent across experiments using different
locating arrays, suggesting its validity even in the absence of
a formal proof of locating arrays’ sufficiency for continuousvalued outcomes. Future work may verify this or find another
design that combines the locating property with the highconfidence reconstruction guarantees of compressive sensing.
In some systems there may be factors that contribute significantly to the outcome but cannot be controlled, such as
ambient temperature. More work is necessary to determine
how to detect and handle uncontrollable factors, and in cases
when they cannot even be observed, to detect their existence
and influence indirectly.
Screening is just the first step in model building and optimization. Determining the levels of the factors screened by our
method that maximize MOS while minimizing transmission

exposure is the next step in experimentation. Validation by
other methods, such as those used in SUMO [2], is of interest.
VII. ACKNOWLEDGEMENTS
We thank Ingrid Moerman for her support. This work is
supported in part by the National Science Foundation under
Grant No. 142105, by the IWT project “SAMURAI: Software
Architecture and Modules for Unified RAdIo control,” and by
the European Commission Horizon 2020 Programme under
grant agreement n 688116 (eWINE).
R EFERENCES
[1] S. Bouckaert, W. Vandenberghe, B. Jooris, I. Moerman, and P. Demeester, “The w-ilab.t testbed,” in Testbeds and Research Infrastructures. Development of Networks and Communities, T. Magedanz,
A. Gavras, N. H. Thanh, and J. S. Chase, Eds.
Springer Berlin
Heidelberg, 2011, pp. 145–154.
[2] M. T. Mehari, E. De Poorter, I. Couckuyt, D. Deschrijver, J. V.V. Gerwen, D. Pareit, T. Dhaene, and I. Moerman, “Efficient global
optimization of multi-parameter network problems on wireless testbeds,”
Ad Hoc Networks, vol. 29, pp. 15–31, 2015.
[3] C. Croarkin, P. Tobias, J. J. Filliben, B. Hembree, W. Guthrie, L. Trutna,
and J. Prins, Eds., NIST/SEMATECH e-Handbook of Statistical Methods.
NIST/SEMATECH, April 2012.
[4] D. C. Montgomery, Design and Analysis of Experiments, 7th ed. John
Wiley and Sons, Inc., 2009.
[5] S. Gilmour, “Factor screening via supersaturated designs,” in Screening,
A. Dean and S. Lewis, Eds. Springer New York, 2006, pp. 169–190.
[6] R. Li and D. K. J. Lin, “Analysis methods for supersaturated designs:
Some comparisons,” Journal of Data Science, pp. 249–260, 2003.
[7] K. Navaie and T. A. Le, “Fundamental performance trade-offs in
coexisting wireless networks,” in 5G for Ubiquitous Connectivity (5GU),
2014 1st International Conference on, November 2014, pp. 246–251.
[8] R. Annauth and H. C. Rughooputh, “OFDM systems resource allocation using multi-objective particle swarm optimization,” International
Journal of Computer Networks and Communications, vol. 4, no. 4, pp.
291–306, July 2012.
[9] C. J. Colbourn and D. W. McClary, “Locating and detecting arrays for
interaction faults.” J. Comb. Optim., vol. 15, no. 1, pp. 17–48, 2008.
[10] A. N. Aldaco, C. J. Colbourn, and V. R. Syrotiuk, “Locating arrays: A
new experimental design for screening complex engineered systems,”
SIGOPS Operating Systems Review, vol. 49, no. 1, pp. 31–40, January
2015.
[11] J. A. Tropp and A. C. Gilbert, “Signal recovery from random measurements via orthogonal matching pursuit,” IEEE Transactions on
Information Theory, vol. 53, no. 12, pp. 4655–4666, December 2007.
[12] E. Candès and M. Wakin, “An introduction to compressive sampling,”
IEEE Signal Processing Magazine, vol. 25, no. 2, pp. 21–30, 2008.
[13] B. L. Welch, “The generalization of ‘student’s’ problem when several
different population variances are involved,” Biometrika, vol. 34, no. 1/2,
pp. 28–35, 1947.
[14] N. R. Draper and H. Smith, Applied Regression Analysis (3rd Edition).
Somerset, NJ, USA: Wiley, 2014.
[15] “GENI:
Global
Environment
for
Network
Innovations,”
https://www.geni.net/.
[16] “FIRE: Future Internet Research & Experimentation,” http://www.ictfire.eu/home.html.
[17] M. T. Mehari, E. De Poorter, I. Couckuyt, D. Deschrijver, G. Vermeeren,
D. Plets, W. Joseph, L. Martens, T. Dhaene, and I. Moerman, “Efficient
identification of a multi-objective pareto front on a wireless experimentation facility,” IEEE Transactions on Wireless Communications, under
review.
[18] C. D. Manning, P. Raghavan, and H. Schütze, Introduction to Information Retrieval. New York, NY, USA: Cambridge University Press,
2008.
[19] J. W. Eaton, D. Bateman, S. Hauberg, and R. Wehbring, GNU Octave
version 3.8.1 manual: a high-level interactive language for numerical
computations. CreateSpace Independent Publishing Platform, 2014.
[20] I. M. Chakravarti, R. G. Laha, and J. Roy, Handbook of Methods of
Applied Statistics. John Wiley and Sons, 1967, vol. I.

Computer Networks 56 (2012) 762–779

Contents lists available at SciVerse ScienceDirect

Computer Networks
journal homepage: www.elsevier.com/locate/comnet

Cross-layer opportunistic adaptation for voice over ad hoc networks
Suhaib A. Obeidat a, Abraham N. Aldaco b, Violet R. Syrotiuk b,⇑
a
b

Bennett College for Women, Greensboro, NC 27401, United States
Arizona State University, Tempe, AZ 85287-8809, United States

a r t i c l e

i n f o

Article history:
Received 8 June 2011
Received in revised form 3 November 2011
Accepted 6 November 2011
Available online 13 November 2011
Keywords:
Cross-layer design
Opportunistic protocol
Adaptation
Voice
Ad hoc networks
Performance

a b s t r a c t
The support of voice communication is fundamental in the deployment of an ad hoc network for the battleﬁeld or emergency response. We use the QoS requirements of voice
to identify factors inﬂuencing its communication, and validate their signiﬁcance through
statistical analysis. Based on the results, we propose an opportunistic protocol within a
cross-layer framework that adapts these factors at different time scales. Hop-by-hop adaptation exploits the PHY/MAC interaction to improve the use of the spectral resources
through opportunistic rate-control and packet bursts, while end-to-end adaptation
exploits the LLC/application interaction to control the demand per call through voice coding and packet size selection. Our objective is to maximize the number of calls admitted
while minimizing loss of quality. We evaluate the performance of the protocol in simulation with real audio traces using both quantitative and mean opinion score (MOS) audio
quality metrics, comparing to several standard voice codecs. The results indicate that: (i)
compression and packet-size selection play a critical role in supporting QoS over ad hoc
networks; (ii) header compression is needed to limit the overhead per packet especially
over longer paths; (iii) good voice quality is achieved even in strenuous network
conditions.
Ó 2011 Elsevier B.V. All rights reserved.

1. Introduction
Voice over IP (VoIP) is one of the fastest growing applications in networking [1]. The rate at which wireless access
points are spreading only increases the importance of VoIP
over wireless [2]. Supporting voice over ad hoc networks is
part of realizing an all-IP goal.
The wireless channel introduces many challenges for
supporting voice. These include the inherent broadcast
nature of the channel, temporal response variability due
to fading and absorption, and sensitivity to noise and interference. Ad hoc networks also suffer from a scarcity of
resources and a lack of centralized control. When combined, these challenges make supporting voice in these
networks a formidable task. Our interest is in supporting
voice in the battleﬁeld, or in emergency situations;
⇑ Corresponding author.
E-mail addresses: sobeidat@bennett.edu (S.A. Obeidat), aaldacog@
asu.edu (A.N. Aldaco), syrotiuk@asu.edu (V.R. Syrotiuk).
1389-1286/$ - see front matter Ó 2011 Elsevier B.V. All rights reserved.
doi:10.1016/j.comnet.2011.11.002

therefore, our focus is on call admittance and survival with
acceptable quality as opposed to providing the quality we
have come to expect in wireline telephony.
Experience in cellular networks has shown that
adaptive applications are resilient and robust [3–5]. In
addition, cross-layer design, where performance gains are
accomplished through exploiting the dependence between
protocol layers, gives better performance compared to traditional approaches [6]. However, increasing the number
of layers involved in a cross-layer design does not always
translate into better performance. Kawadia and Kumar
show that, if not used carefully, unintended cross-layer
interactions may have undesirable consequences on overall system performance [7].
Combining the merits of both adaptation and cross-layer
design, while cognizant of the care required, we propose an
opportunistic adaptive protocol within a cross-layer framework for supporting VoIP over ad hoc networks. We
incorporate three of the seven approaches to cross-layer
design identiﬁed by Srivastava and Motani [8]: explicit

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

notiﬁcation from one layer to another, directly setting a
parameter of a different layer, and vertical calibration
across different layers of the protocol stack.
We tackle the time-variant channel quality and capacity
by introducing adaptive modulation to maximize channel
utilization. We also minimize the amount of real-time trafﬁc introduced in the network by using adaptive voice compression. A side effect of using adaptive compression is to
also vary the audio packet size used.
Adaptation of three factors, namely modulation, compression, and packet size, requires collaboration of three
layers of the protocol stack: the physical, link, and application layers. In terms of time scale, adaptation of modulation
occurs on a hop-by-hop basis as channel quality varies from
one hop to another and occurs at a fast pace. Adaptation of
compression and packet size, on the other hand, occur on an
end-to-end basis as this depends on the path quality and
therefore occurs on a longer time scale. Having the protocol
work at two different time scales combines the beneﬁts of
having an accurate picture of both local and end-to-end
conditions, and reduces protocol overhead.
This paper makes the following contributions:
 A cross-layer architecture for voice over ad hoc networks is presented that combines the use of modulation,
compression, and packet size spanning three layers of
the protocol stack: physical, link, and application.
 An adaptive protocol is proposed that operates at two
time scales, on a hop-by-hop basis and an end-to-end
basis, capturing local channel quality and end-to-end
network statistics, respectively.
 A high ﬁdelity simulation model is used that includes
the simulation of packetization delay and physical layer
details, playout buffers, among others.
 Both quantitative and mean opinion score (MOS) audio
quality metrics are evaluated using real audio traces,
with comparisons to several standard voice codecs.
The rest of this paper is organized as follows. We identify the factors whose adaptation is important in providing
acceptable voice quality in Section 2. Using the selected factors, we propose an opportunistic adaptive protocol in Section 3. In Section 4 we describe the simulation set-up, and
deﬁne the quantitative degradation in voice quality (DVQ)
and the qualitative subjective mean opinion score (MOS)
performance metrics. Through simulation with real audio
traces the performance of our protocol is evaluated for both
static topologies and mobile scenarios in Section 5 comparing to non-adaptive protocols using standard voice codecs.
An analysis bounding the maximum voice capacity for our
protocol is presented in Section 6. In Section 7 we overview
related work and contrast our contributions. Finally, we
conclude and propose future work in Section 8.

2. Factors inﬂuencing voice
The quality-of-service (QoS) requirements of voice are:
(1) A 0–150 ms end-to-end delay is acceptable for most
applications [9].

763

(2) Voice can tolerate a packet loss on the order of 102–
104 [10].
(3) Delay variations of less than 75 ms give good quality
[11].
End-to-end delay is the time from when a frame is
generated at the caller until it is played at the callee. There
are ﬁve components to end-to-end delay: (1) Packetization
delay is the delay at the caller to collect all bits that compose a packet. (2) Queuing delay is the time a packet spends
waiting to be forwarded. (3) Transmission delay is the time
it takes to ﬁrst transmit a packet, while (4) propagation
delay is the time for it to propagate through a link. Finally,
(5) play-out delay is the time a packet spends in the buffer
of the callee for smooth play out. The delay budget refers to
the total end-to-end delay beyond which packets are considered stale.
For one-way transmission time the ITU-T G.114 recommendation is that a 0–150 ms delay is acceptable for most
applications but a delay above 400 ms is unacceptable [9].
For highly interactive tasks, quality may suffer at a delay of
100 ms.
Voice can tolerate a small amount of packet discard.
Either the decoder uses sequence numbers to interpolate
for lost packets, or the encoder adds redundancy in the
sent packets [12]. These techniques work well when the
losses are isolated. For compressed voice, packet loss concealment is used by most codecs and involves the callee
producing a replacement for a lost packet. This is possible
because of the short-term self-similarity in audio data [13].
If bursty losses take place then gaps occur and the quality
of voice suffers.
Delay variation (or jitter) is the difference between the
minimum and the maximum delay that packets encounter in a single session, and it results from variable queueing delays. It is important for voice trafﬁc to be played at
the callee at a rate matching the rate generated at the
caller [14]. Buffering is used to overcome jitter. Once
the callee starts receiving packets, it buffers them for a
time equal to the delay variation, and then starts playing
them out. When packets arrive late some packets in the
buffer are consumed, while early arrival results in the
buffer growing.
From these QoS requirements, we see that delay is the
key quality impairment for voice. Fraleigh et al. have
shown that the availability of bandwidth can limit the
impact of delay [15]. This suggests that we should choose
factors that control the ratio of offered load to the available
bandwidth in our study. One way to increase the available
bandwidth is by introducing adaptive modulation where
the spectral efﬁciency changes depending on the current
channel conditions. Another is to control the real-time trafﬁc within the network. Adaptive voice compression compresses a real-time stream in light of the current channel
and network conditions.
In VoIP over wireless, a packet has substantial overhead
consisting of headers from four protocols: the real-time
protocol (RTP), the user datagram protocol (UDP), the internet protocol (IP), and the medium access control (MAC)
protocol. While it is important to maximize the payload
per packet, a large payload results in high packetization

764

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

delay which may impact the perceived quality at the
callee. This suggests that for adaptive compression to be
beneﬁcial, the level of compression has to be selected
jointly with packet size.
Together, these motivate our selection of three factors
for our study: modulation, compression, and packet size.
There are many trade-offs to consider in their adaptation.
We have used statistically designed screening experiments
to validate that these factors and interactions among them
are inﬂuential on delay. See [16] for a complete description
of the experiments and the associated results.

3. Adaptation architecture and protocol
Reinforced by the results of the statistical analysis, we
design a cross-layer opportunistic protocol; Fig. 1 shows
the architecture of the adaptive protocol. The protocol
combines hop-by-hop and end-to-end adaptation each
working at a different time scale. Cross communication between the physical (PHY) and medium access control (MAC)
layers takes place at every hop along the path from the
caller to the callee and enables adaptive modulation. While
we use the opportunistic auto rate (OAR) protocol over IEEE
802.11b to make use of the multi-rate capability of the PHY
layer [17], the architecture we propose is generic and can
work with any multi-rate PHY/MAC. Cross communication
between the logical link control and application (LLC/APP)
layers, on the other hand, takes place only at the caller
and enables adaptive selection of compression rate and
packet size.
The dynamics of the cross-layer communication
between the PHY/MAC layers is as follows: At every hop,
when a node receives a request-to-send (RTS) packet, it
analyzes the signal quality and extracts the signal-to-noise
ratio (SNR) information to select the transmission rate. The
decision involves determining the highest achievable
transmission rate from the current channel conditions;

Fig. 1. System architecture: hop-by-hop and end-to-end adaptation.

higher transmission rates require a stronger received
signal [17]. Once the receiver chooses the most suitable
modulation for the packet transmission, it piggybacks its
decision in the clear-to-send (CTS) packet. Upon receiving
the CTS, this information is extracted and communicated
to the PHY layer.
Compression and packet size selection depend on the
end-to-end feedback regarding the network conditions
expressed in terms of the packet loss ratio and average
packet delay. Fig. 2 shows the end-to-end protocol dynamics at a high level. An epoch-length is the duration of time
the callee waits before sending feedback to the caller.
Whenever it receives a packet, the callee updates its statistics for packet loss and average packet delay for the current
epoch. Average delay is ﬁrst calculated by subtracting the
time stamp of every arriving packet from its arrival time.
The total delay of all packets arriving within an epoch is
then divided by their number. Packet loss is calculated by
monitoring the packet identiﬁers and logging the number
missing.
At the end of every epoch the callee sends a 12 byte
statistics report, containing 6 byte ﬁelds of loss and delay
statistics, to the caller. On receipt of the statistics report,

Fig. 2. The end-to-end protocol dynamics.

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

the caller invokes the adaptive protocol to calculate both
the packet size and the compression level.
3.1. Packetization delay, packet size, and compression level
calculations
The adaptive protocol selects the packet size to maximize the payload per packet and limit the overhead per
packet, and minimize the contribution of packetization
delay to the total end-to-end delay to improve the voice
quality experienced.
When the network is lightly loaded and end-to-end
delay is low, most of the delay budget is directed to the
packetization delay component maximizing packet size
without compromising quality experienced by the user.
When load conditions are high, the maximum packetization delay that can be allocated without contributing to
end-to-end delay is equal to the time the packet has to
wait in the local LLC buffer before getting transmitted over
the channel. A pipelining opportunity is created where
packet size is maximized without contributing to end-toend delay.
The protocol starts by querying the LLC layer regarding
the average delay in the local buffer. Using both the local
buffer delay and the end-to-end delay and loss statistics,
the protocol starts by calculating the packetization budget.
This is the greater of the local delay, and the delay budget
minus the end-to-end delay. This way, the contribution of
packetization delay to the accrued end-to-end delay is
minimized.
For example, consider a network experiencing light load
conditions with a network delay of 70 ms. If the delay budget for our application is 150 ms then there is up to
150  70 = 80 ms that can be used toward packetization.
This way, with high likelihood, the packet reaches the callee on time while the payload is maximized. However,
since the network delay is an average value, a safetymargin is used. In our experiments, we assume a ﬁxed value of 20 ms for the safety-margin.
On the other hand, consider a network experiencing
heavy load conditions with an average delay of 140 ms. If
the delay budget is 150 ms then the remainder of the delay
budget is too small to use for packetization. However, if the
average delay of the local buffer is 30 ms then we can use
this value for packetization as producing a packet any
earlier than 30 ms does not reduce the end-to-end delay.
This is because the packet must wait 30 ms in the local buffer. This way, the protocol does not add to the total delay
while, at the same time, the packet size is maximized.
One more factor that contributes to the packetization
delay, and hence the packet size to select, is the current
loss ratio. If the loss ratio crosses a maximum threshold,
the protocol cuts the packetization budget by a predeﬁned
percentage. The reason is to avoid sending packets with a
large payload because losing large packets has a great
impact on quality.
Following the approach of Chen et al. [18], in our experiments we assume that half of the losses are due to channel
errors, since there is currently no way to differentiate loss
due to congestion from one due to channel noise in
wireless networks.

765

The protocol then calculates the compression rate to
use. If the loss ratio is higher than a maximum threshold,
the compression rate is cut to half of the current value. If
the current average delay crossed a maximum threshold,
the protocol again cuts the compression rate by half. If neither of these two conditions is true and both the loss ratio
and average delay are less than some predeﬁned minimum
thresholds, the protocol increases the compression rate to
the next rate within the available set of compression rates.
In this approach, the protocol reacts quickly to ‘‘bad news’’
and conservatively to ‘‘good news.’’
Next, the protocol makes sure that the compression rate
and the packetization delay calculated do not fall outside
the allowed ranges. The protocol also ensures that packetization delay is within the limits of the minimum and
maximum thresholds to prevent sending very small or very
large payloads. As a last step, the protocol calculates the
packet size based on the packetization budget and the chosen compression rate. It then ensures that the calculated
packet size is an integer multiple of the frame size of the
given compression rate.
In cases where the caller fails to receive a statistics report for a number of epochs equal to feedback-timer-length,
the protocol reacts as follows. To start, the protocol cuts
the compression rate in half as a way of mitigating any network congestion that may be preventing the arrival of
feedback from the callee. Next, the protocol queries the
LLC layer for the local buffer delay and uses this value as
the packetization delay. As before, the protocol makes sure
that the compression rate and the packetization delay calculated do not fall outside the allowed ranges, calculates
the packet size based on the packetization budget and
the chosen compression rate, and makes sure the calculated packet size is an integer multiple of the frame size
of the given compression rate.
The thresholds that the protocol uses depend on the
application. If the application requires stringent quality
requirements, the thresholds may be adjusted to produce
high quality. Likewise, if the main goal is to communicate
even if quality is reduced, thresholds may be relaxed to
produce acceptable quality.
4. Simulation set-up
We use the ns-2 network simulator [19] release
2.1b7a to evaluate the performance of our opportunistic
adaptive protocol. We move from simple to more sophisticated static topologies in order to attribute cause to observations, and then consider mobile scenarios.
4.1. Static topologies
We start with a line topology with i hops, 1 6 i 6 5,
where node 1 is the caller and node i + 1 is the callee. This
topology minimizes MAC-layer contention and physicallayer co-channel interference and thus gives an idea about
the upper-bound performance of our protocol. The
distance between nodes is set to 150 m for two reasons.
The ﬁrst is to allow the different modulation schemes to
be used whenever channel conditions allow. The second

766

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

Five-hop
Four-hop
Three-hop
Two-hop
One-hop
20

0

1

m

150 m
0

20

150 m

150 m

150 m

m

3

4

5

6

7

2
Fig. 3. Variant of the line topology.

Fig. 4. Grid topology.

is that when nodes are closer the interference effect on one
another is higher.
To consider the impact of MAC layer contention, we
next use a variant of the line topology shown in Fig. 3.
The total load generated is divided between callers 1 and
2 and is communicated to the callee. In addition to the
added contention, node 3 is a bottleneck as both nodes 1

and 2 need to pass their trafﬁc through 3 to the rest of
the network; this is ensured by placing nodes 1 and 2 a distance of 200 m away from node 3.
We then consider a 5  5 grid topology shown in Fig. 4.
The distance between a node and each of its horizontal and
vertical neighbours is 150 m. We consider two concurrent
ﬂows to introduce co-channel interference. We vary the

767

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779
Table 1
Characteristics of group applications and mobility model parameters.
Application and model

Characteristics

N

 ðsÞ
p

Dp (s)

Event, nomadic

Walking speed
Long pauses
Walking speed
No pauses
Vehicle high speed
No pauses

40

0.5

0.5

60

60

0

10

50

1.0

1.0

0

0

10

5

10

20.0

10.0

0

0

0

5

March, column
Pursuit, pursuit

s ðm=sÞ

intensity of interference by varying the distance between
the two ﬂows. We start with a low-interference trafﬁc
pattern with ﬂow1 from caller node 3 to callee node 11
and ﬂow2 from caller node 15 to callee 23. For the highinterference trafﬁc pattern, we move the caller of ﬂow2 to
node 8 and its callee to node 16. The distance between
the two ﬂows results in co-channel interference and may
cause packets not to be routed on the direct 2-hop path
(we observed many different 3-hop paths taken).
Following the approach of Singh et al. [20], we then
introduce irregularity in the grid topology by uniformly
varying the placement of each node within a square of side
40 m centered at the grid point. This way, the network
remains connected while at the same time link quality
depends on the distance between nodes. We vary the
placement of nodes from one simulation run to another.
For the irregular-grid, the low-interference trafﬁc pattern
consists of two concurrent ﬂows, while the high-interference trafﬁc pattern selects four concurrent ﬂows, with
caller–callee pairs selected at random. Similar to the grid,
a route in the irregular-grid may use a variable number
of hops.
Even though the topologies described so far are static,
we use the Ad hoc On-demand Distance Vector (AODV)
routing protocol [13] to establish the caller–callee paths
because routes may vary over time due to interference
and other physical layer effects.
4.2. Mobile scenarios
We also study the impact of mobility on the performance of our protocol. The scenarios where we envision
our protocol to be employed involve team work where a
group is coordinating its actions in the battleﬁeld or an
emergency situation. Therefore, we focus on three group
applications: an event, a march, and a pursuit modelled
by a nomadic, a column, and a pursuit mobility model,
respectively. Table 1 summarizes these applications, their
characteristics, and the parameters used to model them. s
refers to the average speed of a node, Ds is the range in
 refers to the average pause time
which speed changes, p
of a node, and Dp is the range in which pause time
changes.
A nomadic mobility model captures the collective
movement of a group of nodes from one point to another.
Nodes within a group follow a reference point around
which they move freely. When the reference point moves,
all nodes move to the new location where they move freely
again. In a column mobility model nodes move around a
certain line which is moving ahead. A pursuit mobility

Ds (m/s)

r (m)

Dr (m)

model captures the movement of a group of nodes chasing
a target.
To derive the movement pattern for each of these
mobility models, we use the implementation of the reference point group mobility (RPGM) generic model [21]. The
three mobility models can be derived from this model by
varying two parameters: r, the reference point separation,
and Dr, the node separation from the reference point. The
reference point separation refers to the pace at which the
group center moves while node separation from the reference point deﬁnes the coupling of the group, i.e., how far
nodes are from their reference point. For these parameters,
we use the values summarized in Table 1 which are taken
from [22] and are chosen because the movement traces
they represent are appropriate for our applications. N is
the number of nodes in the group.
We consider two, four, and eight concurrent ﬂows for
event and march applications, and up to three concurrent
ﬂows for the pursuit application.
4.3. Wireless channel model
We use a Ricean fading model of the wireless channel.
The ns-2 wireless extensions of fading [23] are based on
a simple and efﬁcient approach ﬁrst proposed by Punnoose
et al. [24]. Even though the channel modelling extensions
accurately simulate the wireless channel for each individual ﬂow, fading components of channels for different ﬂows
are identical, which is unrealistic. A way to solve this problem was suggested in [17]. We use the modiﬁed model in
our simulations.
4.4. Simulation parameters
Table 2 summarizes the simulation parameters. We
consider two delay budgets to account for a spectrum of
applications. For applications that require a high level of
interaction, we use a delay budget of 150 ms. For more
elastic applications, we use a delay budget of 300 ms.
Any packet arriving at the callee past its delay budget is
considered late and is counted as stale.
Each packet consists of headers, and a payload segment
consisting of an integral number of audio frames. The
headers total 56 bytes. Thus if the payload is 100 bytes,
what is transmitted is a 156 byte packet. To make sure that
there is a reasonable number of voice frames in a packet,
we do not transmit a packet with less than 50 ms of voice.
As a way of mitigating the high overhead per packet, we
use the robust header compression (ROHC) protocol [26].
Rein et al. [27] show that communicating GSM speech with

768

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

Table 2
Simulation and adaptive protocol parameters.
Simulation
parameter

Value

Simulator
Simulation hardware

ns-2.1b7a
Intel Core 2 Quad CPU Q9550 at 2.83 GHz,
8 GB RAM
1000 s
500 s

Simulation time
Simulation warm-up
time
Audio stream
Audio stream
compression

audio book in mono, WAVE format
8000 samples/s, quantized at 16 bits
Speex [25]

Static topologies
Mobile scenarios

Line, line-variant, grid, and irregular-grid
See Table 1

Transmission Range
Channel rates
Fading model

250 m
2, 5.5, and 11 Mbps
Ricean with K = 10 dB with ﬂow dependent
fading [17]

Protocol parameter

Value

Routing protocol
MAC protocol
Compression levels
ROHC
Overhead per packet

AODV [13]
OAR over IEEE 802.11b [17]
3, 5, 7, 8, 12, 16, 24, and 32 Kbps
enabled and disabled
56 bytes (ROHC disabled), 32 bytes (ROHC
enabled)
100 packets, drop-tail queueing policy
150 ms and 300 ms

Buffer size
Delay budget
epoch-length
feedback-timerlength

1s
3s

min-loss-thresh
max-loss-thresh
perc-chnl-contrib

1%
10%
50%

min-pack-delay
max-pack-delay
min-delay-budget
max-delay-budget
Safety margin

50 ms
100 ms
50 ms
130 ms
20 ms

Statistics report size

12 bytes

the optimistic variant of ROHC results in an average header
size of 6 bytes. If the UDP checksum is turned off, the average header size is reduced further to 4 bytes. In a separate
study, Seeling et al. show similar performance results
when communicating high quality video with optimistic
ROHC enabled [28]. We adopt these results compressing
the UDP/IP header from 28 to 4 bytes. Each experiment is
run with ROHC disabled and then enabled.
In all cases, we run at least 50 replicates of each
experiment.
4.5. Quantitative degradation in voice quality (DVQ) metric
We gather both quantitative and qualitative metrics of
voice quality. The degradation in voice quality (DVQ) is a
quantitative metric [29] deﬁned as:

DVQ ¼

plost þ plate
;
ptotal

where plost is the number of packets lost, plate is the number
of packets arriving after their delay budget, and ptotal is the

total number of packets sent. As a result, 0 6 DVQ 6 1 and
gives the percentage of lost and late packets.
Since adaptive compression and packet size selection
are used, measuring the amount of speech by counting
the number of packets is inaccurate because the amount of
speech per packet depends on the compression level. This is
because packets that are the same size may carry different
amounts of voice payload. Therefore, in the computation of
DVQ, rather than counting packets, we extract the amount
of speech per packet.
4.6. Qualitative mean opinion score (MOS) metric
While the smaller the DVQ the better, how DVQ correlates to perceived voice quality is unclear. To this end we
use a subjective metric, the mean opinion score (MOS)
[30]. MOS is expressed by the scale shown in Table 3 with
range from 1 (bad) to 5 (excellent), providing a numerical
indication of the listening quality of the received audio
stream.
All our simulations use real voice traces as input to the
simulation. Raw recorded speech, in the form of audio
books stored in mono, WAVE-format, serves as input to
the simulation. The audio book consists of 8000 samples/s
with each sample quantized at 16 bits. This stream is then
modiﬁed according to the dynamics of the adaptive
protocol.
The audio stream compression is achieved using the
Speex open source audio compression format [25]. Speex
is part of the GNU project and is based on code excited linear prediction (CELP). It has the capability to compress
voice at bit rates ranging from 2 to 44 Kbps. The coder
has many functionalities including voice activity detection,
packet loss concealment, echo cancelation, and noise
suppression.
The received stream is compared with the original
audio stream of the same duration (no larger than 2 min)
using the methodology in [31]. The perceptual evaluation
of speech quality (PESQ) [32] algorithm measures speech
quality comparing an original speech reference with the
callee’s version, which has a known correlation to MOS.
4.7. Non-adaptive protocols used for comparison
We compare our adaptive protocol to non-adaptive versions of the protocol in which the modulation and packet
size are ﬁxed to standard settings of voice codecs, and
the MAC protocol is IEEE 802.11b DCF used at a ﬁxed data
rate of 2 Mbps. We also experimented with a data rate of
11 Mbps but because all of the results show a similar trend
to the results at 2 Mbps we do not present them here.
Table 4 shows the codecs, and their ITU-T or ETSI standard
settings.
5. Simulation results
We ﬁrst present simulation results for the static topologies and then for the mobile scenarios. We plot the DVQ
and the MOS as a function of the number of calls per ﬂow,
however when we tabulate the number of calls supported

769

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779
Table 3
MOS listening-quality scale.
Quality of speech

Score

Excellent
Good
Fair
Poor
Bad

5
4
3
2
1

Table 4
Standard audio/voice codec attributes.
Codec

Bit rate
(Kbps)

Payload
(bytes)

Framing interval
(ms)

G.711 [33]

64

G.729 [34]

8

G.723 [35]

6.3

GSM-EFR 6.60
[36]
GSM-FR 6.10
[37]

12.4

80
160
240
10
20
30
8
16
24
31

10
20
30
10
20
30
10
20
30
20

13.2

33

20

per ﬂow we only count calls in which the listening quality
is at least fair, i.e., the MOS P 3. If MOS < 3, we consider
the quality of the voice to be too poor for our applications
of interest, i.e., voice communication in the battleﬁeld or
for emergency response.
5.1. Results for line and line-variant topologies
Fig. 5 shows the DVQ and MOS for our adaptive protocol
as a function of number of calls for line topologies with

1 6 i 6 5 hops, with a delay budget of 150 ms, and no header compression employed; all results are summarized in
Table 5. The DVQ and MOS almost appear as mirror images
of each other. Overall, longer line topologies support fewer
voice calls with fair listening quality. This is expected as
longer paths result in longer delay due to more queueing
at intermediate hops, resulting in more lost and late packets. The delay also increases because a node cannot both
send and receive at the same time with a half-duplex
transceiver. For example, in a four-hop path, node 3 cannot
receive from node 2 and send to node 4 concurrently.
We repeat the experiment with a relaxed delay budget
of 300 ms and with header compression enabled. These results are given in Fig. 6. Not surprisingly, more calls with
fair quality can be supported with a less stringent delay
budget. Since this is true for all topologies we considered,
henceforth we only present our results for the stricter delay budget of 150 ms.
Now, we repeat the experiments for the line topologies
using the non-adaptive protocol with standard voice
codecs; all of these results are included in Table 5. Fig. 7
shows the DVQ and MOS as a function of the number of
calls per ﬂow for the settings yielding the highest performance; this occurs when the framing interval is the longest.
Interestingly, when the DVQ is zero the corresponding MOS
for each codec is different; this conﬁrms prior observations
[38]. The highest MOS of 4.19 is achieved by the G.711
codec with a framing interval of 30 ms while the G.723 obtains the lowest MOS of 3.27 with the same framing interval. The highest MOS does not correspond to the highest
voice capacity of 16 calls; this is achieved by the G.723 with
a 20 ms framing interval. In all cases, the adaptive protocol
outperforms the non-adaptive protocol, often supporting at
least ﬁve times the number of calls.
The line variant topologies introduce MAC layer contention between the two callers. Fig. 8 shows the DVQ and

1
1 Hop
2 Hops
3 Hops
4 Hops
5 Hops

0.8

DVQ

0.6
Scenario 2
0.4

Scenario 1

0.2

0
5

MOS

4
3
2
1
0
10

20

30

40

50

60

70

Number of Calls
Fig. 5. DVQ and MOS as a function of number of calls per ﬂow for line topologies using the adaptive protocol (150 ms delay budget, no ROHC).

770

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

Table 5
Number of calls supported per ﬂow with at least fair MOS (i.e., MOS P 3) by line and line-variant topologies for a 150 ms delay budget and no ROHC. Linear
topologies establish one ﬂow, while line-variant topologies establish two ﬂows. The calls are multiplexed over the ﬂows.
Number of calls per ﬂow
1-Hop

2-Hops

3-Hops

4-Hops

5-Hops

10 ms
20 ms
30 ms

64
4
8
10

27
2
4
5

14
1
2
3

11
1
2
2

10
1
2
2

Non-adaptive G.729

10 ms
20 ms
30 ms

5
10
15

2
5
8

1
3
5

1
3
4

1
2
4

Non-adaptive G.723

10 ms
20 ms
30 ms

5
10
16

3
5
8

1
3
5

1
3
4

1
2
4

Non-adaptive GSM-EFR 6.60
Non-adaptive GSM-FR 6.10

20 ms
20 ms

10
10

5
5

3
3

2
2

2
2

Line-variant
Adaptive protocol
Non-adaptive G.711
Non-adaptive G.729
Non-adaptive G.723
Non-adaptive GSM-FR 6.10

30 ms
30 ms
30 ms
20 ms

19
5
5
7
5

9
2
4
4
2

5
1
2
2
1

4
1
1
2
1

4
1
1
2
1

Line
Adaptive protocol
Non-adaptive G.711

1
1 Hop
2 Hops
3 Hops
4 Hops
5 Hops

DVQ

0.8

0.6

0.4

0.2

0
5

MOS

4
3
2
1
0
10

20

30

40

50

60

70

80

Number of Calls
Fig. 6. DVQ and MOS as a function of number of calls per ﬂow in line topologies using the adaptive protocol (300 ms delay budget, ROHC).

MOS as a function of the number of calls per ﬂow achieved
by the adaptive protocol in the line-variant topologies
using a 150 ms delay budget and no ROHC. The results
are tabulated in Table 5 on a per ﬂow basis. Because each
caller establishes a ﬂow, the total number of calls is twice
that tabulated. Hence, between the channel contention and
the bottleneck node, the number of calls supported in the
line-variant topologies ranges from about 59% to 80% of
the corresponding line topologies. The non-adaptive protocol, using the settings yielding the highest performance per

codec, supports approximately 20–50% of voice capacity of
the adaptive protocol.
5.1.1. Changes in compression over call lifetime
In order to better understand the behaviour of the adaptive protocol in terms of the speed of adaptation and the
quality experienced over the lifetime of a call we show
the changes in compression rate of a call for two different
scenarios in Fig. 9. We select scenarios 1 and 2 of Fig. 5 to
focus on the details of a call’s behaviour. Scenario 2 is one

771

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779
1
G.723 6.3Kbps 30ms
G.729 8Kbps 30ms
G.711 64Kbps 30ms
GSM6.10 13.2Kbps 20ms

DVQ

0.8

0.6

0.4

0.2

0
5

MOS

4
3
2
1
0
0

2

4

6

8

10

12

14

16

18

Number of Calls
Fig. 7. DVQ and MOS as a function of number of calls per ﬂow in line topologies for the non-adaptive protocol using standard voice codecs (150 ms delay
budget, no ROHC).

1
1 Hop
2 Hops
3 Hops
4 Hops
5 Hops

DVQ

0.8

0.6

0.4

0.2

0
5

MOS

4
3
2
1
0
5

10

15

20

25

30

35

40

Number of Calls
Fig. 8. DVQ and MOS as a function of number of calls per ﬂow in line-variant topologies using the adaptive protocol (150 ms delay budget, no ROHC).

call out of 69 multiplexed calls over a one-hop path and
has a MOS = 2.19. Scenario 1 is a better situation of one call
out of 60 multiplexed calls; this call has a MOS = 3.78. As
Fig. 9 shows, scenario 2 experiences more frequent ﬂuctuations in compression as it keeps adjusting its rate in
response to the changes in network load and channel

conditions. Scenario 1 only adjusts its rate a few times.
When conditions are stable and fewer calls are multiplexed
in a ﬂow, callers experience good listening quality. When
trying to support more calls and conditions ﬂuctuate, the
protocol keeps looking for the current best achievable
quality which may result in poor listening quality.

772

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779
8

Copmression Level

7
6
5
4
3
2
400

600

800

1000 1200 1400 1600 1800 2000 2200 2400 2600

Packet Identifier

Fig. 9. Changes in compression over the call lifetime.

1
Low-interference Traffic Pattern
High-interference Traffic Pattern

DVQ

0.8

0.6

0.4

0.2

0
5

MOS

4
3
2
1
0
5

10

15

20

25

Number of Calls
Fig. 10. DVQ and MOS as a function of number of calls per ﬂow in grid topologies using the adaptive protocol (150 ms delay budget, no ROHC).

5.2. Results for grid and irregular-grid topologies
We next study the performance of our adaptive protocol for the grid topologies. This topology introduces cochannel interference in the low-interference trafﬁc pattern,
and heavy contention in the high-interference trafﬁc pattern
because the caller, intermediate, and callee nodes are within the transmission range of their counterparts in the other
ﬂow.
Using a 150 ms delay budget and no header compression, we plot the DVQ and MOS for grid topologies in
Fig. 10 as a function of the number of calls per ﬂow. Unlike
the linear topologies, there is some oscillation in the DVQ
(and hence MOS) in the grid topologies. Therefore, when
we tabulate the results in Table 6, we ﬁnd the number of
calls supported by the ﬁrst MOS value below 3, and then
ﬁnd the number of calls supported for last MOS value
above 3. This gives us a range on the number of calls

supported. Using this method, our adaptive protocol supports from [0–10] calls per ﬂow in the low-interference
trafﬁc pattern and from [0–5] calls per ﬂow in the highinterference trafﬁc pattern with fair listening quality.
We compare the performance of grid topologies and the
line-variant topologies with two and three-hop paths as
both of these topologies have two competing ﬂows. The
number of calls per ﬂow supported in each topology is
comparable; see Tables 5 and 6.
The ﬁnal static scenarios that we consider are the irregular-grid topologies. Using a delay budget of 150 ms and
no header compression, we present the number of calls
supported per ﬂow in a low-interference trafﬁc pattern
(two ﬂows), and in a high-interference trafﬁc pattern (four
ﬂows) in Fig. 11. The variance of the results is high because
in the irregular-grid topologies the caller–callee pairs are
selected at random. Table 6 shows that from [0–3] calls
per ﬂow are supported in the low-interference trafﬁc

773

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779
Table 6
Number of calls supported per ﬂow for grid topologies with at least fair
MOS (i.e., MOS P 3.0) for a 150 ms delay budget and no ROHC. In the grid
topology, the low interference (LI) and high interference (HI) trafﬁc
patterns each have two ﬂows. In the irregular-grid topology, the LI trafﬁc
pattern has two ﬂows while the HI trafﬁc pattern has four ﬂows.
Number of calls per ﬂow
LI Pattern

HI Pattern

Grid
Adaptive protocol
Non-adaptive G.711 (30 ms)
Non-adaptive G.729 (30 ms)
Non-adaptive G.723 (30 ms)
Non-adaptive GSM-FR 6.10 (20 ms)

[0–10]
[0–3]
[0–4]
[0–4]
[0–3]

[0–5]
[0–2]
[0–3]
[0–3]
[0–2]

Irregular-grid
Adaptive protocol
Non-adaptive G.711 (30 ms)
Non-adaptive G.729 (30 ms)
Non-adaptive G.723 (30 ms)
Non-adaptive GSM-FR 6.10 (20 ms)

[0–3]
[0–1]
0
0
[0–1]

0
0
[0–1]
0
[0–1]

pursuit applications using the nomadic, column, and pursuit
mobility models, respectively. In these mobile scenarios,
the node separation is very small (610 m) compared to
the node separation in the static topologies (P150 m). As
a result, the signal power is very strong and the ﬂows are
able to tolerate more interference and are consequently
able to support a higher number of calls per ﬂow in the
adaptive protocol. Even though the presence of mobility affects performance, since the nodes are moving as a group
and are relatively close to each other, high performance
is achieved. The results depend on the trafﬁc pattern (reﬂected by large error bars in each of the ﬁgures). The adaptive protocol supports at least ﬁve times more calls when
compared to any non-adaptive approach.

6. Performance bounds

pattern, but no calls of fair listening quality are supported
in the high-interference trafﬁc pattern.
Our adaptive protocol supports roughly twice the number of calls for each interference pattern in grid topologies
compared to any of the non-adaptive protocols. The same
is true for irregular-grid topologies, but only for the lowinterference pattern. For the high interference pattern,
the adaptive protocol does not support any calls with
MOS P 3 while the G.729 and GSM-FR 6.10 occasionally
support one call.
5.3. Results for mobile scenarios
Table 7 tabulates the number of calls per ﬂow supported by the adaptive protocol for the event, march, and

To gain an understanding of how the performance of
our protocol compares to an upper bound, we quantify
the theoretical maximum number of concurrent calls that
can be supported on a single-hop IEEE 802.11b access
point (AP) for the compression rates and packet sizes we
have used in our simulations. We assume that the trafﬁc
is saturated and that no time is wasted in contention.
The transmission of a voice packet over an IEEE 802.11b
network triggers the following steps. RTP, UDP, and IP
headers totalling 40 bytes are added to the voice packet.
As well, a 6 byte LLC sub-network access protocol (SNAP)
header is included to reﬂect the transported network-layer
protocol [39]. A 24 byte MAC header is required, together
with a 4 byte Frame Check Sequence (FCS) calculated over
the entire frame. The channel is sensed to see if it is clear
for a distributed inter-frame space (DIFS) duration. If so, a
physical layer convergence protocol (PLCP) preamble is

1
Low-interference Traffic Pattern
High-interference Traffic Pattern

DVQ

0.8

0.6

0.4

0.2

0
5

MOS

4
3
2
1
0
2

4

6

8

10

12

14

Number of Calls
Fig. 11. DVQ and MOS as a function of number of calls per ﬂow in irregular-grid topologies using the adaptive protocol (150 ms delay budget, no ROHC).

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

Table 7
Number of calls supported per ﬂow for mobile scenarios with at least fair
MOS (i.e., MOS P 3.0) for a 150 ms delay budget and no ROHC. The event,
march, and pursuit applications use the nomadic, column, and pursuit
mobility models, respectively. Two, four, and eight concurrent ﬂows are
considered in the event and march applications, while up to three
concurrent ﬂows are considered for the pursuit application.
Number of calls per ﬂow

Event application
Adaptive protocol
Non-adaptive G.711 (30 ms)
Non-adaptive G.729 (30 ms)
Non-adaptive G.723 (30 ms)
Non-adaptive GSM-FR 6.10 (20 ms)
March application
Adaptive protocol
Non-adaptive G.711 (30 ms)
Non-adaptive G.729 (30 ms)
Non-adaptive G.723 (30 ms)
Non-adaptive GSM-FR 6.10 (20 ms)

Pursuit application
Adaptive protocol
Non-adaptive G.711 (30 ms)
Non-adaptive G.729 (30 ms)
Non-adaptive G.723 (30 ms)
Non-adaptive GSM-FR 6.10 (20 ms)

2-Flows

4-Flows

46
5
8
8
5

21
2
4
4
2

Upper bound at 2Mbps
Upper bound at 11Mbps

250

200

Calls

774

150

8-Flows
100

9
1
2
2
1

50

0

3

5

8

12

16

24

32

Compression Rate (Kbps)
46
5
8
8
5

21
2
4
4
2

8
1
2
2
1

1-Flow

2-Flows

3-Flows

96
10
15
16
10

46
5
8
8
5

29
3
5
5
3

Fig. 12. Bounds on the number of calls supported as a function of
compression rate.

The packet transmission time (PTT), in ls, of a voice
packet is calculated as:
PTT ¼ DIFS þ SIFS þ 2  ðPLCP Preamble þ PLCP HeaderÞ
þ

ðRTP=UDP=IP=LLC=MAC Headers þ Payload þ ACKÞ  8
data rate

The number of packets per a voice call (PPVC) per second
is equal to:

Table 8
Default parameter values per frame sent by IEEE 802.11b DCF.
Parameter

Value

Distributed Inter-Frame Space (DIFS)
Short Inter-Frame Space (SIFS)
RTP/UDP/IP headers
LLC/MAC headers
Payload
Long PLCP (preamble and header), 192 bits
Frame Check Sequence (FCS)
Acknowledgement (ACK) at 2 Mbps
SlotTime
CWmin, CWmax

50 ls
10 ls
40 bytes
34 bytes
Codec dependent
192 ls
4 bytes
14 bytes
20 ls
32 slots, 1024 slots

added. The short frame format requires 72 bits of the PLCP
preamble to be transmitted at a required rate of 1 Mbps
and 48 bits of the PLCP header to be transmitted at a
required rate of 2 Mbps. The frame is then transmitted by
the caller at the IEEE 802.11 data rate in use (one of 2,
5.5, or 11 Mbps). After waiting a short inter-frame space
(SIFS) duration, the callee creates a 14 byte acknowledgment (ACK) frame, and adds a PLCP preamble and header
to be transmitted at the required rates of 1 and 2 Mbps,
respectively. The callee transmits an ACK at the IEEE
802.11b data rate.
Since IEEE 802.11b supports three transmission rates,
the time needed to transmit a packet depends on the rate
used. However, regardless of the data rate in use by the
adaptive protocol, some ﬁelds are transmitted at a ﬁxed
rate as speciﬁed by the standard [40]. The default parameter values for IEEE 80211b DCF are shown in Table 8.

PPVC ¼



Compression Rate ðbpsÞ
 2:
Payload  8

The multiplication by two is to account for the bidirectional nature of a call. Given the equations for PTT and
PPVC, the maximum number of concurrent calls that are
supported is given by:

$
Maximum Number of Calls ¼

%
106
:
PTT  PPVC

Fig. 12 uses these equations to plot the maximum number of calls supported as a function of the compression rate
for data rates of 2 Mbps and 11 Mbps with the minimum
and maximum payload, respectively. Since the analysis is
done for a single-hop IEEE 802.11b access point, it bounds
the results for the single-hop line topology most closely.
The adaptive protocol supports 64 calls in this case, which
lies between the two bounds. The analysis does not take
into account that the adaptive protocol varies the modulation, compression, and packet size, over the call lifetime
and is therefore only a loose bound on performance.

7. Related work
We now overview work on voice over IP in ad hoc
networks, wireless local areas networks (WLANs), and also
in related wireless mesh networks (WMNs). It is difﬁcult to
compare directly the voice capacity of our protocol to
those discussed since the details of the experimentation
are not fully known. Nevertheless, we attempt a comparison and also indicate avenues of future research.

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

7.1. VoIP over ad hoc networks and wireless LANs
Specialized protocols that focus on voice support over
ad hoc networks have been proposed. Wang et al. [1] propose the combined use of multicasting and multiplexing of
multiple voice packets into one packet as a way of reducing
the per-packet overhead. As a result, the protocol shows an
increase in the network capacity and a decrease in the
delay experienced by voice calls. Priority queuing is
employed as a way of preventing competing TCP trafﬁc
from starving voice trafﬁc of resources. The analysis for ordinary VoIP capacity for ETSI Global System for Mobile
(GSM) communications 06.10 Full Rate (FR) speech coder
[37], ITU G.711, G.729, and G.723 voice codecs using IEEE
802.11b DCF access scheme at 11 Mbps shows voice capacities similar to our experimental and analytical results for
the non-adaptive protocol. The small difference between
our results may be due to the use of a packet-loss rate below 1% compared to our 10%. The voice capacity of the
multicast scheme, which improves the ordinary VoIP
capacity by close to 100%, is less than that achieved by
our adaptive protocol.
A modiﬁcation of IEEE 802.11 is proposed in Dong et al.
[41] in which the cyclic redundancy codes are computed
only over those parts of the voice frame that have a high
impact on the perceived quality rather than over the entire
frame. In this way, less bandwidth is wasted in retransmission and less delay is introduced. In [42], the use of new
speech coding techniques for supporting voice over ad
hoc networks is proposed. One such technique is multiple
description coding. It involves creating more than one bit
stream from the source signal. Each independent stream
represents a coarse description of the transmitted signal.
If more than one description is received, a reﬁned signal
is reconstructed. Another technique is scalable speech coding, which consists of sending a base stream at a minimum
rate and one or more enhancement streams. Our work
computes the FCS over the entire frame and does not make
use of these speech coding techniques.
Obeidat and Syrotiuk [43] study the performance of
adaptive voice communications over multi-hop wireless
networks; this work extends that work signiﬁcantly. In
particular, a statistically designed experiment is used to
quantify signiﬁcant factors and their interactions on voice
quality. This motivated the integration of end-to-end adaptation. In addition, the use of real audio traces allows the
evaluation of audio quality metrics. We also consider more
complex topologies and scenarios integrating mobility in
studying the protocol to better understand how it performs
in situations more representative of battleﬁeld and emergency scenarios.
Fasolo et al. [44] present a cloud of nodes that communicate with one gateway by means of multi-hop ad hoc
connections to study the effect of multi-rate on voice
capacity. They assessed their analysis through ns-2 simulations using IEEE 802.11b DCF access scheme at 11 Mbps
and ETSI GSM 06.60 Enhanced Full Rate (EFR) voice codec
[36]. Their results for a delay budget of 100 ms and less
than 1% loss probability show a maximum of 6 and 3
concurrent voice connections for single-hop and multihop scenarios, respectively. Our adaptive protocol achieves

775

higher voice capacity perhaps due to differences in the delay budget and loss probability. Moreover, our evaluation
considers more extensive multi-hop and mobile scenarios.
A number of works consider voice capacity of WLANs.
Adaptive modulation and adaptive compression have been
applied separately in VoIP-based wireless and wired networks [45–48]. Supporting packet voice over IEEE 802.11
has been investigated for both the DCF and PCF, however
the performance is poor [49,50].
Garg and Kappes [51] analyze the number of simultaneous VoIP calls a single AP running the IEEE 802.11b
DCF can support. Their experimentation uses an ITU
G.711 a-Law codec with 10 ms of voice data. At 11 Mbps,
6 calls are supported by the AP with acceptable quality.
An analytical model is developed for three standard codecs
(ITU G.711 a-Law [33], G.723 [35], and G.729 [34]) considering DCF compliance and data transmission rates of the
AP varying from 1 Mbps to 11 Mbps to validate the experimental results. Our model in Section 6 is similar and reports essentially the same number of VoIP calls
supported for these standard codecs.
Hole and Tobagi [52] quantify the capacity of a wireless
LAN using IEEE 802.11b at 11 Mbps carrying VoIP calls
using analysis and simulation. The analytic upper bound
matches the simulation results when channel quality is
good. The capacity of the network is found to be highly
dependent on the delay constraints of the carried voice. Given a delay budget constraint and non-ideal channel conditions they offer a means to select the voice data packet size
(in ms) for the ITU G.711 and G.729 codecs. Our work on the
non-adaptive protocols shows close results for the VoIP
calls supported for the same standard codecs. We agree that
the combined effects of delay and packet loss must be taken
into consideration on the quality of the voice, hence we go
beyond ﬁxed codec attributes and offer a protocol that
opportunistically adapts modulation, compression, and
packet size to maximize call capacity and quality.
Along the same lines of research, Anjum et al. [53] investigate the capacity of wireless LANs for VoIP trafﬁc and as a
result suggest the use of controlled back-off and priority
queuing at the AP when voice and data trafﬁc co-exist.
7.2. VoIP over wireless mesh networks
The advantage of using multiple radios on voice capacity has been investigated in [54,55]. Kim et al. [54] propose
a model to accurately infer network capacity of VoIP calls
in multi-channel multi-radio (MCMR) WMNs. This is needed
since accurate connection admission and control depend
on accurate estimation of call capacity. Coordination of
radios and channels is accomplished using the hybrid multi-channel protocol (HMCP). The model is validated through
both test bed measurements and ns-2 simulations, accurately estimating capacity to within 6% of actual measurements and simulations. With speech compressed at 8 Kbps,
up to 80 calls can be supported over a 5-hop line topology.
Bayer et al. [55] investigate the feasibility of VoIP over
WMNs through measurements from a designed test bed.
The use of dual radios is shown to provide signiﬁcantly
better performance than single radios. However, such
improvements are seen only for large packet sizes. As a

776

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

result, a hop-to-hop aggregation algorithm is proposed.
Packets are held at intermediate nodes until there are
enough packets to make a preset minimum size. However,
the holding of packets is done as long as their delay has not
reached a certain threshold. The network simulator is used
to investigate the performance of the aggregation algorithm over an 802.11a with a basic rate of 6 Mbps, a data
rate of 24 Mbps and a node separation of 45 m. With
speech encoded using G.729a with voice activity detection,
results show that around 350 calls can be supported with a
MOS of 3.5.
While the use of multiple radios and the proper assignment of channels can result in an increase in network
capacity, it requires the use of such conﬁgurations with
corresponding changes in the protocol stack. Our focus in
this work is on the more common single-radio end
systems.
Kamoun et al. [56] propose a packet scheduling algorithm that takes into account wireless channel conditions,
class of service of data carried, and whether a connection is
new or handoff. A handoff occurs as the source of an ongoing multimedia session moves from the range of one wireless mesh router to that of another. The scheme favours
handoff calls over new calls, and realtime trafﬁc over
non-realtime trafﬁc. The algorithm successfully limits the
delay of realtime trafﬁc to 135 ms. The rate at which
speech is compressed, and the protocol overhead is considered, but the mobility pattern considered is not described
making it is hard to relate to their results. We plan to augment our work with scheduling and drop policies that take
into account the nature of voice and possibly packet size.
The channel-aware nature of this scheduling algorithm
makes it a particularly good candidate as it gives a shortterm prediction of network conditions.
El-Hennawey et al. [57] study the performance of VoIP
over a WMN running IEEE 802.11e for QoS provisioning.
Both call quality and throughput are quantiﬁed. Using a
static line topology, results show that over a single-hop
up to 8 calls are supported, over 2-hops up to 6 calls, over
3-hops up to 4 calls, and over 4-hops up to 2 calls. A call
is considered supported if it meets a MOS of 3.1. Fairness
is also quantiﬁed to determine whether the network treats
calls with identical QoS requirements fairly. Results show
that a high degree of fairness is exhibited. Another aspect
that is quantiﬁed is whether non-overlapping background
trafﬁc has an effect on call quality. A 3-hop call is separated
from background trafﬁc by 2-hops, 1-hop, and no-hops.
The results show that the smaller the separation, the higher the impact on quality. The study does not consider the
effect of mobility or frame bursting. While we do not
investigate fairness or separation of background trafﬁc,
comparison with their results for line topologies reﬂects
that our protocol shows superior performance.
Siddique and Kamruzzaman [58] estimate the VoIP call
capacity of a single-hop WMN using analytic modelling.
Network capacity is modelled as a maximization problem
governed by quality constraints involving network parameters. The model can be expanded to multi-hop networks
and to other types of realtime trafﬁc. The main contribution is in the detailed modelling of delay and loss sources
to capture impairment factors contributing to quality

compromise. The model is solved numerically and its results are veriﬁed by simulations using ns-2. The results
show that increasing the number of voice frames per packet results in an overall increase in network capacity but
only to a certain degree beyond which packetization delay
results in call quality degradation. In addition, lower data
rate coders, those more aggressive in compressing speech,
result in a higher capacity, even though the coder’s impairment factor can affect such a trend. The results also demonstrate the effect of increasing the data rate from
11 Mbps to 54 Mbps. The increase in network capacity is
not matched by a comparable increase in call capacity.
Further, higher data rate coders such as G.711 result in relatively higher gains in capacity than higher compression
coders such as G.729a. This is because G.711 generates
larger packets with less per-packet overhead. Lastly,
employment of RTS/CTS is found to negatively affect the
number of calls supported. Simulation results are solely
of one-hop network with no mobility and are similar or
inferior to the results of our protocol.
Kulkarni and Devetsikiotis [59] propose a cross-layer
design for increasing the VoIP call capacity of a WMN.
The study identiﬁes parameters deemed crucial across
three layers, MAC data rate, routing approach, and voice
packetization interval. Four different MAC data rates are
considered as provided by the IEEE 802.11b standard.
Two routing approaches are investigated: hop-count and
link-rate aware routing. Using G.711 for encoding speech,
ten different packetization rates and corresponding packet
sizes are considered. Simulations in ns-2 are used to generate responses to variations of the parameters. An n-factorial analysis and linear regression ﬁtting are used to derive
algebraic equations for the call capacity. Fitting equations
are found using the SAS GLM procedure. In plotting these
functions, parameter-combinations that provide the highest capacity are found. As for the goodness of ﬁt, an analysis
of variance (ANOVA) R2 greater than 70 is considered an
indicator of acceptable call quality. Results show the
positive effect of using link rate-aware routing. Packetization has an effect on capacity but only to a certain degree
beyond which it becomes negligible. We only consider
hop-count as a link metric in our routing protocol. However, link-rate aware routing is shown to give a substantial
improvement and appears to be worthwhile to consider.
Packet aggregation is proposed by many studies as a
way of mitigating the per-packet overhead of inherently
small voice packets [60–62]. Hasegawa et al. [60] propose
the use of bidirectional packet aggregation and network
coding for the support of VoIP over WMN. The proposed
protocol is implemented in a test bed and is also veriﬁed
through simulations. Using a line topology, bidirectional
trafﬁc is aggregated then network-coded using an XOR
operation. Aggregation opportunities are increased by having intermediate routers hold packets for a time period
equal to their queuing delay share of the total delay
budget. With node separation of 100 m and a number of
hops varying between 2 and 7, the protocol is shown to
support around 23 calls of speech compressed using
G.711 over a 7-hop connection. A call is considered
supported if its network delay is limited to 150 ms and
its loss rate is within 5%.

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

Kurien et al. [61] propose a dynamic approach to packet
aggregation to increase VoIP call capacity in WMNs. Aggregation is performed only on packets going to the same next
hop. The optimal aggregation size is chosen based on the
signal-to-noise and interference ratio (SNIR) of the outgoing
link. Knowledge of the receiving MAC of the SNIR is used to
compute bit error rate (BER) for the employed modulation
technique. BER is then used to compute the frame error rate
(FER). The algorithm then chooses an aggregation size that
limits FER to less than 0.1%. This value is chosen so that the
end-to-end error rate is small. Nodes maintain a queue for
each outgoing link. Aggregation takes place whenever a
queue grows past certain threshold or when oldest packet
has crossed certain delay threshold. Performance is investigated using the network simulator ns-2 and is compared
against non-dynamic aggregation and plain 802.11. Using a
static line topology, the approach is shown to have superior performance in terms of all network parameters and
in call capacity. However, it is not obvious what is considered acceptable call quality.
Kim and Hong [62] propose a scheme integrating packet
aggregation and header compression to limit overhead and
maximize VoIP capacity of a WMN. Aggregation takes place
both end-to-end and hop-to-hop with the ﬁrst contributing
to the end-to-end delay and the latter working within the
MAC delay. End-to-end aggregation is applied intra-ﬂow,
to packets coming from the same ﬂow, while hop-to-hop
aggregation is applied between ﬂows. Since end-to-end
aggregation is applied intra-ﬂow, the scheme is augmented
with header elimination of the second to the last packets of
an aggregated packet. Simulations using the network simulator show that using G.729a speech, the scheme can result
in supporting more than 10 calls over 4 to 8 hops of a line
topology. While our results using the same coder show a call
capacity of 10 calls over one hop, the use of aggregation and
header elimination enables their scheme to support 7 times
as much (a line topology provides an ideal scenario for
aggregation). Many studies reach to the same conclusion
regarding the merit of aggregation and we intend to incorporate it into our future work.
Aggregation-aware routing is investigated in [63,64].
Liwlompaisan and Phonphoem [63] propose a routing
scheme that combines packet aggregation, multi-path
routing, utilization awareness, and event-triggered rerouting. A link that can be part of many paths allows for higher
chances of aggregation, and hence is more attractive in
route discovery. This, however, may result in hot spot routing behaviour. As a result, the saturated utilization is taken
into account in the cost so that routes go around such
spots. As an additional measure to limit the hot spot effect,
backward trafﬁc is sent on a path different from forward
trafﬁc. Also, an intermediate hot spot node sensing high
medium utilization may request certain source nodes to
reroute their trafﬁc. Simulations are conducted using the
network simulator ns-3 of an 802.11a WMN with speech
encoded at a rate of 64 Kbps. Quality constraints are
300 ms of delay budget and loss rate of 10%. The results
show an increase in the number of supported calls over
longer paths (4–9 hops). The delay behaviour is not improved but is not aggravated in comparison with similar
protocols.

777

Along the same lines, Ramprashad et al. [64] use a theoretical framework to investigate the joint effect of routing
and admission with packet aggregation, bursting, and rate
adaptation of multiple packets in a single transmission
opportunity on VoIP call capacity of a multi-hop 802.11
network. Analytic results are veriﬁed through simulation
of a 2-hop scenario using the ns-2 network simulator.
Results show that the analytical framework provides a
tight upper-bound when compared with simulation. In
the presence of channel errors, around 22 calls can be supported. As for rate adaptation, the results show that joint
optimization of other factors is only of interest in a
2–3 dB SNR region between rate switches. Our cross-layer
framework does not include the routing layer. Incorporating more layers involves a tradeoff between performance
and protocol complexity.
8. Conclusions and future work
Adaptation and cross-layer design are two approaches
to address the challenges of supporting voice over ad hoc
networks. We identiﬁed the factors of compression, modulation, and packet size to adapt based on the QoS requirements of voice. Our resulting opportunistic protocol
combines adaptation on two time scales: hop-by-hop and
end-to-end. The performance of our protocol was evaluated through simulations in static and mobile scenarios,
carrying real-time audio trafﬁc using both quantitative
(DVQ) and qualitative (MOS) audio metrics.
Our work may be extended in several ways. The protocol
may be combined with a multi-path diversity approach
where multiple paths are used between a caller–callee pair.
Different paths may carry voice packetized, compressed,
and modulated differently to optimize network performance and call quality. In general, QoS-aware routing,
which takes interference of the ﬂows into account, rather
than following the shortest hop-count path may be useful.
The use of forward error correction (FEC) is another avenue of work. Even though the use of FEC introduces extra
overhead, it can curb the rate of lost and late packets. A
node can decide whether to use no compression and experience a high loss rate or consider aggressive compression
while applying FEC.
The impact of trafﬁc heterogeneity, where voice, data,
and video are supported concurrently, is another important
study. Unlike real-time applications which are particular
about delay but more resilient to losses, data applications
are bandwidth-greedy, delay-elastic, and intolerant to loss.
Employing special measures, such as the use of priority
queuing, may be needed to ensure appropriate support
for voice applications.
Finally, experiments using human subjects to obtain
MOS results in battleﬁeld or emergency situations would
be useful for future work on supporting voice in these types
of scenarios.
Acknowledgments
We are grateful to area editor, and to the anonymous
referees, whose thoughtful comments led us to signiﬁcantly improve the results of our paper.

778

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779

References
[1] W. Wang, S.C. Liew, V.O.K. Li, Solutions to performance problems in
VoIP over a 802.11 wireless LAN, IEEE Transactions on Vehicular
Technology 54 (1) (2005) 366–384.
[2] R.Y.W. Lam, V.C.M. Leung, H.C.B. Chan, Polling-based protocols for
packet voice transport over IEEE 802.11 wireless local area networks,
IEEE Wireless Communications Magazine 13 (1) (2006) 22–29.
[3] S.B. Lee, A.T. Campbell, INSIGNIA: An IP-based quality of service
framework for mobile ad hoc networks, Journal of Parallel and
Distributed Computing 60 (4) (2000) 374–406.
[4] A. Goldsmith, S.B. Wicker, Design challenges for energy-constrained
ad hoc wireless networks, IEEE Wireless Communications Magazine
9 (4) (2002) 8–27.
[5] A. Goldsmith, Wireless Communications, Cambridge University
Press, 2005.
[6] B. Raman, P. Bhagwat, S. Seshan, Arguments for cross-layer
optimizations in bluetooth scatternets, in: Proceedings of the IEEE
2001 Symposium on Applications and the Internet, 2001, pp. 176–
184.
[7] V. Kawadia, P.R. Kumar, A cautionary perspective on cross layer
design, IEEE Wireless Communications Magazine 12 (1) (2005) 3–11.
[8] V. Srivastava, M. Motani, Cross-layer design: a survey and the road
ahead, IEEE Communications Magazine 43 (12) (2005) 112–119.
[9] ITU-T Recommendation G.114, One-way transmission time,
International Telecommunication Union, Geneva, 1996.
[10] K. Sriram, M.H. Sherif, Voice packetization and compression in
broadband ATM networks, IEEE Journal on Selected Areas in
Communications 9 (3) (1991) 294–304.
[11] D. Miras, A survey of network QoS needs of advanced internet
applications, Internet2 QoS Working Group, Working Document,
December 2002.
[12] D.E. McDysan, D. Spohn, ATM Theory and Applications, McGraw-Hill,
1999.
[13] C. Perkins, O. Hodson, V. Hardman, A survey of packet loss recovery
techniques for streaming audio, in: IEEE Network Magazine, 1998,
pp. 40–48.
[14] W. Stallings, High Speed Networks: TCP/IP and ATM Design
Principles, Prentice Hall, 1998.
[15] C. Fraleigh, F. Tobagi, C. Diot, Provisioning IP backbone networks to
support latency sensitive trafﬁc, in: Proceedings of the 22nd Annual
Joint Conference of the IEEE Computer and Communications
Societies (Infocom’03), 2003, pp. 375–385.
[16] S.A. Obeidat, Cross-layer opportunistic adaptation for voice over
wireless ad hoc networks, Ph.D. Thesis, Arizona State University,
Tempe, AZ, May 2008.
[17] B. Sadeghi, V. Kanodia, A. Sabharwal, E. Knightly, Opportunistic
media access for multirate ad hoc networks, in: Proceedings of the
8th Annual International ACM Conference on Mobile Computing and
Networking (MobiCom’02), 2002, pp. 24–35.
[18] T. Chen, M. Kazantzidis, M. Gerla, I. Slain, Experiments on QoS
adaptation for improving end user speech perception over multihop
wireless networks, in: Proceedings of the IEEE International
Conference on Communications (ICC’99), 1999, pp. 708–715.
[19] The Network Simulator — ns-2. <http://www.isi.edu/nsnam/ns>.
[20] S. Singh, P.A. Acharya, U. Madhow, E.M. Belding-Royer, Sticky CSMA/
CA: Implicit synchronization and real-time QoS in mesh networks,
Ad Hoc Networks 5 (6) (2007) 744–768.
[21] T. Camp, J. Boleng, V. Davies, A survey of mobility models for ad hoc
network research, Wireless Communications and Mobile Computing
2 (5) (2002) 483–502 (special issue on Mobile Ad hoc Networking:
Research, Trends and Applications).
[22] M.M. El Saoud, MANET reference conﬁgurations and evaluation of
service location protocol for MANET, Masters Thesis, Carleton
University, 2005.
[23] The Monarch Group, The Monarch Project: Wireless and Mobility
Extensions to ns-2. <http://www.monarch.cs.rice.edu/cmu-ns.html>.
[24] R. Punnoose, P. Nikitin, D. Stancil, Efﬁcient simulation of Ricean
fading within a packet simulator, in: Proceedings of the IEEE
Vehicular Technology Conference (VTC’00), 2000, pp. 764–767.
[25] Speex: A Free Codec for Free Speech. <http://www.speex.org>.
[26] C. Bormann, C. Burmeister, M. Degermark, H. Fukushima, H. Hannu,
L. Jonsson, R. Hakenberg, T. Koren, K. Le, Z. Liu, A. Martensson, A.
Miyazaki, K. Svanbro, T. Wiebke, T. Yoshimura, H. Zheng, Robust
header compression (ROHC): Framework and four proﬁles: RTP,
UDP, ESP, and uncompressed, IETF RFC 3095, 2001.
[27] S. Rein, F. Fitzek, M. Reisslein, Voice quality evaluation for wireless
packet voice: A tutorial and performance results for ROHC, IEEE
Wireless Communications Magazine 12 (2005) 60–76.

[28] P. Seeling, M. Reisslein, F.H.P. Fitzek, S. Hendrata, Video quality
evaluation for wireless transmission with robust header
compression, in: Proceedings of the 4th International Conference
on Information, Communications and Signal Processing (ICICS’03),
vol. 3, 2003, pp. 1346–1350.
[29] R. Jain, S. Munir, J. Iyer, Performance of VBR voice over ATM: Effect of
scheduling and drop policies, ATM Forum/97-0608, 1997.
[30] ITU-T Recommendation P.800, Methods for subjective determination
of transmission quality, International Telecommunication Union,
Geneva, 1996.
[31] ITU-T Recommendation P.862, Perceptual evaluation of speech
quality (PESQ): an objective method for end-to-end speech quality
assessment of narrow-band telephone networks and speech codecs,
International Telecommunication Union, Geneva, 2001.
[32] ITU-T Recommendation G.728, Implementors guide for ITU-T
recommendation G.728: coding of speech at 16 kbits/sec using
low-delay
code
excited
linear
prediction,
International
Telecommunication Union, Geneva, 1992.
[33] ITU-T Recommendation G.711.1, Wideband embedded extension for
G.711 pulse code modulation, International Telecommunication
Union, Telecommunication Standardization Sector, 2008.
[34] ITU-T Recommendation G.729, Coding of speech at 8 kbit/s using
conjugate-structure algebraic-code-excited linear prediction (CSACELP), International Telecommunication Union, Telecommunication Standardization Sector, 2007.
[35] ITU-T Recommendation G.723.1, Dual rate speech coder for
multimedia communications transmitting at 5.3 and 6.3 kbit/s,
International Telecommunication Union, Telecommunication Standardization Sector, 2006.
[36] ETSI European Telecommunications Standards Institute, Enhanced
full rate (EFR) speech transcoding (GSM 06.60 version 8.0.1), ETSI
Digital Cellular Telecommunications System (Phase2+), 1999.
[37] ETSI European Telecommunications Standards Institute, Full rate
speech, transcoding (GSM 06.10 version 8.2.0), ETSI Digital Cellular
Telecommunications System (Phase2+), 2005–2006.
[38] ITU-T Recommendation P.830, Subjective performance assessment
of telephone-band and wideband digital codecs, International
Telecommunication Union, Telecommunication Standardization
Sector, 1996.
[39] M. Gast, 802.11 Wireless Networks: The Deﬁnitive Guide, second ed.,
O’Reilly Media, Inc., 2005.
[40] IEEE standard 802.11: W-LAN medium access control and physical
layer speciﬁcations, December 1999.
[41] H. Dong, I.D. Chakares, C.-H. Lin, A. Gersho, E. Belding-Royer, U.
Madhow, J.D. Gibson, Selective bit-error checking at the MAC layer
for voice over mobile ad hoc networks with IEEE 802.11, in:
Proceedings of the IEEE Wireless Communications and Networking
Conference (WCNC’04), 2004, pp. 1240–1245.
[42] H. Dong, I.D. Chakares, C.-H. Lin, A. Gersho, E. Belding-Royer, U.
Madhow, J.D. Gibson, Speech coding for mobile ad hoc networks, in:
Proceedings of the Asilomar Conference on Signals, Systems, and
Computers (ACSSC’03), vol. 1, 2003, pp. 280–284.
[43] S.A. Obeidat, V.R. Syrotiuk, An opportunistic cross-layer architecture
for voice in multi-hop wireless LANs, International Journal of
Communications Systems 22 (4) (2009) 419–439.
[44] E. Fasolo, F. Maguolo, A. Zanella, M. Zorzi, S. Rufﬁno, P. Stupar, VoIP
communications in wireless ad-hoc network with gateways, in:
Proceedings of the 12th IEEE Symposium on Computers and
Communications (ISCC’07), 2007, pp. 69–74.
[45] A. Barberis, C. Casetti, J.C. De Martin, M. Meo, A simulation study of
adaptive voice communications on IP networks, in: Proceedings of the
International Symposium on Performance Evaluation of Computer
and Telecommunication Systems (SPECTS’00), 2000, pp. 531–542.
[46] S. Shenker, Fundamental design issues for the future interent, IEEE
Journal on Selected Areas in Communications 13 (7) (1995) 1176–1188.
[47] K. Balachandran, S.R. Kadaba, S. Nanda, Channel quality estimation
and rate adaptation for cellular mobile radio, IEEE Journal on
Selected Areas in Communications 17 (7) (1999) 1244–1256.
[48] T. Ue, S. Sampei, N. Morinaga, K. Hamaguchi, Symbol rate and
modulation level-controlled adaptive modulation/TDMA/TDD
system for high-bit-rate wireless data transmission, IEEE
Transactions on Vehicular Technology 47 (4) (1999) 1134–1147.
[49] M.A. Visser, M. El Zarki, Voice and data transmission over an 802.11
wireless network, in: Proceedings of the IEEE International
Symposium
on
Personal,
Indoor,
and
Mobile
Radio
Communications (PIMRC’95), 1995, pp. 648–652.
[50] E. Ziouva, T. Antonakopoulos, CBR packetized voice transmission in
IEEE 802.11 networks, in: Proceedings of the IEEE Symposium on
Computers and Communications, 2001, pp. 392–398.

S.A. Obeidat et al. / Computer Networks 56 (2012) 762–779
[51] S. Garg, M. Kappes, Can I add a VoIP call? in: Proceedings of the IEEE
International Conference on Communications (ICC’03), vol. 2, 2003,
pp. 779–783.
[52] D. Hole, F.A. Tobagi, Capacity of an IEEE 802.11b wireless LAN
supporting VoIP, in: Proceedings of IEEE International Conference on
Communications (ICC’04), vol. 1, 2004, pp. 196–201.
[53] F. Anjum, M. Elaoud, D. Famolari, A. Ghosh, R. Vaidyanathan, A.
Dutta, P. Agrawal, T. Kodama, Y. Katsube, Voice performance in
WLAN networks - an experimental study, IEEE Global
Telecommunications Conference (Globecom’03) 6 (2003) 3504–
3508.
[54] S. Kim, M. Ji, J. Ma, Voice call capacity model for hybrid multichannel protocol over multi-hop multi-channel multi-radio wireless
mesh networks, in: Proceedings of the International Conference on
Advanced Communication Technology (ICACT’11), 2011, pp. 1239–
1244.
[55] N. Bayer, M.C. de Castro, P. Dely, A. Kassler, Y. Koucheryavy, P.
Mitoraj, D. Staehle, VoIP service performance optimization in preIEEE 802.11s wireless mesh networks, in: Proceedings of the IEEE
International Conference on Circuits and Systems for Multimedia
Wireless Communications (ICCSC’08), 2008, pp. 75–79.
[56] W. Mansouri, F. Zarai, K. Mnif, L. Kamoun, New scheduling algorithm
for wireless mesh, in: Proceedings of the International Conference on
Multimedia Computing and Systems (ICMCS’11), 2011, pp. 391–396.
[57] D.V. Geyn, H. Hassanein, M.S. El-Hennawey, Voice call quality using
802.11e on a wireless mesh network, in: Proceedings of the IEEE
34th Conference on Local Computer Networks (LCN’09), 2009, pp.
792–799.
[58] M.A. Siddique, J. Kamruzzaman, VoIP call capacity over wireless
mesh networks, in: Proceedings of the IEEE Global Communications
Conference (Globecom’08), 2008, pp. 601–611.
[59] V. Kulkarni, M. Devetsikiotis, Cross-layer response surface
methodology applied to wireless mesh network VoIP call capacity,
in: Proceedings of the 41st Annual Simulation Symposium, 2008, pp.
15–22.
[60] J. Hasegawa, H. Yomo, Y. Kondo, P. Davis, R. Suzuki, S. Obana, K.
Sakakibara, Bidirectional packet aggregation and coding for VoIP
transmission in wireless multi-hop networks, in: Proceedings of the
International Conference on Communications (ICC’09), 2009, pp.
113–118.
[61] J.M. Okech, Y. Hamam, A. Kurien, A cross-layer adaptation for VoIP
over infrastructure mesh network, in: Proceedings of the 3rd
International
Conference
on
Broadband
Communications,
Information
Technology
and
Biomedical
Applications
(BroadCom’08), 2008, pp. 97–102.
[62] K. Kim, S. Hong, VoMESH: voice over wireless mesh networks, in:
Proceedings of the IEEE Wireless Communications and Networking
Conference (WCNC’06), 2006, pp. 193–198.
[63] W. Liwlompaisan, A. Phonphoem, Call capacity improvement
techniques for VoIP over wireless mesh networks, in: Proceedings
of the International Conference on Electrical Engineering/
Electronics, Computer, Telecommunications and Information
Technology (ECTI-CON’09), 2009, pp. 902–904.
[64] S.A. Ramprashad, D. Li, U.C. Kozat, C. Pepin, An analysis of joint
aggregation, bursting, routing, and rate adaptation for increasing

779

VoIP capacity in multi-hop 802.11 networks, IEEE Transactions on
Wireless Communications 7 (8) (2008) 3128–3139.

Suhaib A. Obeidat completed his Ph.D at
Arizona State University in 2008. Currently, he
is an Assistant Professor of Computer Science
at Bennett College, Greensboro, NC. His
research interests include wireless and mobile
ad hoc networks, and adaptive and cross-layer
multimedia communications over wireless.

Abraham N. Aldaco earned his M.S. in Computer Science and B.S. in Systems and Electronics
from
Monterrey
Institute
of
Technology (ITESM), Mexico, in 2000 and
1988, respectively. Currently he is a graduate
student pursuing a Ph.D. in Computer Science
at the School of Computing, Informatics and
Decision Systems Engineering, Arizona State
University, Tempe, AZ. His current research
interest include mobile ad hoc networks,
cognitive radio networks, and wireless sensor
networks.

Violet R. Syrotiuk earned her Ph.D. in Computer Science from the University of Waterloo
(Canada). She is currently an Associate Professor of Computer Science and Engineering in
the School of Computing, Informatics, and
Decision Systems Engineering at Arizona State
University. Dr. Syrotiuk’s research has been
supported by grants from NSF, DSTO (Australia), ONR, DoD, and contracts with LANL,
Raytheon Co., General Dynamics, and ATC
Corp. She serves on the editorial boards of
Computer Networks, Computer Communications, and the International Journal of Communication Systems and on the
technical program and organizing committees of several major conferences including IEEE Infocom, ACM Mobicom, and ACM MSWiM, among
many others. Her research interests include MAC and higher layer protocols for multi-hop wireless networks.

Locating Arrays: A New Experimental Design for
Screening Complex Engineered Systems
Abraham N. Aldaco, Charles J. Colbourn, and Violet R. Syrotiuk
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University, Tempe, AZ, U.S.A. 85287-8809

{aaldacog, colbourn, syrotiuk}@asu.edu
ABSTRACT

Screening: Which factors and interactions are most inﬂuential on
a response?

The purpose of a screening experiment is to identify signiﬁcant factors and interactions on a response for a system. Engineered systems are complex in part due to their size. To apply traditional
experimental designs for screening in complex engineered systems
requires either restricting the factors considered, which automatically restricts the interactions to those in the set, or restricting interest to main effects, which fails to consider any possible interactions. To address this problem we propose a locating array (LA) as
a screening design. Locating arrays exhibit logarithmic growth in
the number of factors because their focus is on identiﬁcation rather
than on measurement. This makes practical the consideration of an
order of magnitude more factors in experimentation than traditional
screening designs. We present preliminary results applying an LA
for screening the response of TCP throughput in a simulation model
of a mobile wireless network. The full-factorial design for this system is infeasible (over 1043 design points!) yet an LA has only 421
design points. We validate the signiﬁcance of the identiﬁed factors
and interactions independently using the statistical software JMP.
Screening using locating arrays is viable and yields useful models.

Conﬁrmation: Is the system currently performing in the same way
as it did in the past?
Discovery: What happens when new operating conditions, materials, factors, etc., are explored?
Robustness: Under what conditions does a response degrade?
Stability: How can variability in a response be reduced?
Our focus is on screening using techniques from statistical design
of experiments (DoE). DoE refers to the process of planning an
experiment so that appropriate data are collected and analyzed by
statistical methods, in order to result in valid and objective conclusions. Hence any experimental problem includes both the design of
the experiment and the statistical analysis of the data.
Suppose that there are k factors, F1 , . . . , Fk , and that each factor
Fj has a set Lj = {vj,1 , . . . , vj,j }, of j possible levels (or values). A design point is an assignment of a level from Lj to Fj ,
for each factor j = 1, . . . , k. An experimental design is a collection of design points. When a design has N design points, it
can be represented by an N × k array A = (ai,j ) in which each
row i corresponds to a design point and each column j to a factor;
the entry ai,j gives the level assigned to factor j in the ith design
point. When run, a design point results in one or more observable
responses.

Categories and Subject Descriptors
General and reference [Cross-computing tools and techniques]:
Experimentation; Mathematics of computing [Discrete mathematics]: Combinatorics

General Terms
Experimentation

A t-way interaction (or interaction of strength t) in A is a choice
of t columns i1 , . . . , it , and the selection of a level νij ∈ Lij for
1 ≤ j ≤ t, represented as T = {(ij , νij ) : 1 ≤ j ≤ t}. Every
 
design point in A covers kt interactions of strength t.

Keywords
Screening experiments, Locating arrays

1.

INTRODUCTION

Computer and networked systems are examples of complex engineered systems (CESs). The complexity of an engineered system is
not just due to its size, but also arises from its structure, operation
(including control and management), evolution over time, and that
people are involved in its design and operation [35].

When the objective of experimentation is screening, it is often recommended to keep the number of factors low. It has been considered impractical to experiment with “many” factors; about ten
factors is a suggested maximum [23, 31]. Generally, two levels for
each factor is considered to work well in screening experiments.

Experimentation is often used to study the performance of CESs.
At its most basic, a system may be viewed as transforming some
input variables, or factors, into one or more observable output variables, or responses. Some factors of a system are controllable,
whereas others are not.

Methods for screening seek to reduce the number of design points
required because the exhaustive full-factorial design [9, 31] is too
large. For k factors each with two levels it has 2k design points.
An analysis of variance (ANOVA) allows the signiﬁcant factors
and interactions on the response to be identiﬁed.

Objectives of experimentation include:

A fractional factorial design 2k−p
is a 21p fraction of a full factoR
rial design with k two-level factors. The design is described by p

Copyright is held by the authors.

31

tential to transform experimentation in huge factor spaces such as
those found in CESs.

generators, expressions of factors that are confounded; the generators determine the alias structure. A design is of resolution R if no
m-factor effect is aliased with another effect containing fewer than
R − m factors.

The rest of this paper is organized as follows. §2 deﬁnes a locating
array, and gives an example of how a design is used for location.
§3 presents preliminary results applying an LA for screening the response of TCP throughput in a simulation model of a mobile wireless network. The full-factorial design for this system is infeasible
— it has over 1043 design points! Yet there is an LA with only 421
design points. We develop an algorithm using the LA to identify
the signiﬁcant factors and interactions from the data collected, providing a small example. In §4 we validate the signiﬁcance of the
identiﬁed factors and interactions independently using the statistical software JMP. Finally, in §5 we summarize, discuss potential
threats to our approach, directions for this research, and conclude.

A D-optimal design is a popular experimental design among those
using optimality criteria. A model to ﬁt, and a bound N on the
number of design points, must be speciﬁed a priori; this restricts
the factors to be analyzed to those in the model. The size of a Doptimal design is bounded by the size of a full-factorial design.
Some designs aggregate the factors into groups, e.g., sequential bifurcation [24], to improve design efﬁciency. Grouping requires care
to ensure that factor effects do not cancel. This presents a “chicken
and egg” problem: we need to know how to group in order to group.
Often, a domain expert is expected to make such grouping decisions. While such experts may have considerable knowledge, it
is doubtful whether an expert knows the importance of a speciﬁc
factor or interaction in a CES.

2.

An interaction graph depicts how a change in the level of one factor
affects the other factor with respect to a response. Figure 1 shows
an interaction graph for the factors of routing and medium access
control (MAC) protocol on average delay in a network. The choice
of MAC protocol (EDCF or IEEE 802.11) has little impact on the
average delay in the AODV routing protocol, while for the DSR
routing protocol the impact is very large; see [53]. If MAC protocols were aggregated, this signiﬁcant interaction would be lost.

LAs differ from standard designed experiments, which are used to
measure interactions and to develop a model for the response as a
function of these [31]. “Search designs” [17, 48, 49] also attempt
to locate interactions of higher strength, but their focus remains on
measurement and hence on balanced designs. Rao [20] shows that
the number of design points in a balanced design must be at least
as large as the number of interactions considered. Thus if t-way
interactions among k factors each having v levels are to be examined, balanced designs only reduce the v k exhaustive design points
to O(kt ). The selection of few factors from hundreds of candidates by this reduction is not viable. By lessening the requirement
from measurement to identiﬁcation, LAs are not subject to the Rao
bound.

Log10(Average delay)

-0.2
-0.3
-0.4
-0.5
-0.6
-0.7
-0.8
-0.9

LOCATING ARRAYS

Reducing the number of design points required relies on a sparsity
of effects assumption, that interactions of interest involve at most
a small, known number t of interacting factors. As one means of
reduction, we deﬁne locating arrays (LAs) [8]. For a set of factors
each taking on a number of levels, an LA permits the identiﬁcation
of a small number of signiﬁcant interactions among small sets of
(factor, level) combinations.

EDCF
IEEE 802.11

Fortunately LAs behave more like covering arrays, experimental
designs in which every t-way interaction among factors appears in
at least one design point. Unlike designed experiments, the number
of design points in a covering array for k factors grows as a logarithmic function of k (see [43], for example). In [8], a construction
of LAs using covering arrays of higher strength is given, and hence
LAs also exhibit this logarithmic growth, making them asymptotically much more efﬁcient than balanced designs. This motivates
the consideration of covering arrays, which have been the subject
of extensive study [4, 5, 19, 36]. They are used in testing software
[10,13,25,26], hardware [46,50], composite materials [3], biological networks [44, 47], and others. Their use to facilitate location of
interactions is examined in [29, 56], and measurement in [21, 22].
Covering arrays form the basis for combinatorial methods to learn
an unknown classiﬁcation function using few evaluations — these
arise in computational learning and classiﬁcation, and hinge on locating the relevant attributes (factors) [11]. Algorithms for generating covering arrays range from greedy (e.g., [2, 16]) through
heuristic search (e.g., [38, 52]). However, combinatorial constructions (see [5]) provide the only available deterministic means of
producing covering arrays with more than a few hundred factors.

-1
AODV
DSR
Routing protocol

Figure 1: Interaction of routing and MAC protocols on delay [53].
A fractional factorial design is saturated when it investigates k =
N − 1 factors in N design points [31]. In a supersaturated design,
the number of factors k > N − 1; such designs contain more factors than design points. These designs are only able to estimate a
main effects model [27, 31]. Thus they cannot consider possible
interactions at all.
Even with substantial and detailed domain knowledge, it is imperative not to eliminate or aggregate factors a priori. Our goal,
therefore, is an automatic and objective approach to screening. To
address this problem we have formulated the deﬁnition of a locating array (LA) [8]. Locating arrays exhibit logarithmic growth in
the number of factors because their focus is on identiﬁcation rather
than on measurement. This makes practical the consideration of an
order of magnitude more factors in experimentation, removing the
need for the elimination of factors. As a result, LAs have the po-

A design point, when run, yields one or more responses. For ease
of exposition, we classify the responses in two groups, those that

32

exceed a speciﬁed threshold and those that do not. So we suppose
that the outcome of a run of a design point is a single binary response (“pass” or “fail”). A fault is caused by one or more t-way
interactions, and is evidenced by a run failing.

uous, we can select a threshold on the responses so as to limit the
number of design points yielding a “fail” outcome to locate those
that make the most substantial contribution to the response. We
exploit this fact later in §3.2.

Given an experimental design and the set of interactions that cause
faults, the outcomes can be easily calculated: A run fails exactly
when it contains one or more of the faulty interactions, and does
not fail otherwise. In order to observe a fault, the interaction must
be covered by at least one design point. With no restriction on the
interactions that can cause faults, every interaction
 must be covered. Then the best one can do is to form all kj=1 j possible
design points, the exhaustive design. Using sparsity of effects, an
upper bound t is placed on the strength of interactions that may be
faulty. Then we require that every t-way interaction be covered; in
other words, the design is a covering array of strength t.

2.1

A Small Example

An example is provided to demonstrate fault location, and show
the limitations of covering arrays for this purpose. Suppose that
we use the experimental design for ﬁve binaryfactors
in Table 1.

It is a covering array in which each of the 22 52 = 40 two-way
interactions is covered. A response for each design point run is
listed in the adjacent column.
Table 1: Experimental design and response for each run.

Let A = (ai,j ) be an experimental design, an N × k array where in
each row i, levels in the jth column are chosen from a set Lj of size
j . For array A and t-way interaction T = {(ij , νij ) : 1 ≤ j ≤ t},
deﬁne ρ(A, T ) = {r : ar,ij = νij , 1 ≤ j ≤ t} as the set of
rows of A in which T is covered. For a set T of interactions,
ρ(A, T ) = ∪T ∈T ρ(A, T ). Locating faults requires that T be
recovered from ρ(A, T ), whenever T is a possible set of faults.

Design Points

1
2
3
4
5
6

1
0
1
0
1
0
1

2
1
0
1
0
0
1

Factors
3 4
1 1
1 0
0 0
0 1
0 0
0 1

5
1
0
0
1
1
0

Response
Fail
Pass
Fail
Pass
Pass
Pass

First, let us locate faults due to main effects (i.e., the individual factors or one-way interactions). The second design point run passes,
so all (factor, level) pairs in it are known not to be faulty. Therefore
in Table 2(a), that considers only the second design point, when
factor 1 is set to one, the run is not faulty. Similarly, for factors
2, 3, 4, and 5 set to zero, one, zero, and zero, respectively. This
is indicated by a check-mark () in the table. Repeating to check
coverage of each one-way interaction for each successful run, no
single (factor, level) error accounts for the faults; see Table 2(b).

Let It be the set of all t-way interactions for an array, and let It
be the set of all interactions of strength at most t. Consider an
interaction T ∈ It of strength less than t. Any interaction T 
of strength t that contains T necessarily has ρ(A, T  ) ⊆ ρ(A, T ).
In this case, when T is faulty we are unable to determine whether
or not T  is also faulty. Call a subset T  of interactions in It
independent if there do not exist T, T  ∈ T  with T ⊆ T  . In
general, some interactions in It (or perhaps It ) are believed to
be faulty, but their number and identity are unknown. The faulty
interactions cannot be identiﬁed precisely from the outcomes, even
if the full factorial design is employed, without some restriction
on their number. (Consider the situation in which every design
point run fails.) We therefore suppose that a maximum number d
of faulty interactions is speciﬁed.

Table 2: Locating faults due to main effects.
(a) Run 2
Factors 0
1
1

2

3

4

5


D EFINITION 2.1 ( [8]). An array A is (d, t)-locating if whenever T1 , T2 ⊆ It and T1 ∪ T2 is independent, |T1 | ≤ d, and
|T2 | ≤ d, it holds that ρ(A, T1 ) = ρ(A, T2 ) ⇔ T1 = T2 .

(b) All Runs
Factors 0
1
1
 
2
 
3
 
4
 
5
 

Computing ρ(T ) for every one-way interaction, we obtain the sets
in Table 3. Because no two sets are equal, the array is (1, 1)locating and when there is a single faulty one-way interaction it can
be located. However, because {1, 3, 5} ∪ {2, 3, 5} = {1, 3, 5} ∪
{1, 2}, when rows 1, 3, and 5 fail and 2, 4, and 6 pass, we cannot determine the two faulty interactions — the array is not (2, 1)locating.

If there is any set of d interactions of strength t that produce exactly the outcomes obtained when using a (d, t)-locating array A
to conduct experiments, then there is exactly one such set of interactions. To avoid enumeration of all sets of d interactions of
strength t, one can employ a stronger condition that for every interaction T of strength at most T and every set T1 ⊆ It that does
not contain T and for which T1 ∪ {T } is independent, it holds that
ρ(A, T ) = ρ(A, T1 ) ⇔ T ∈ T1 . A locating array meeting this
stronger condition is termed a detecting array in [8]. When using
a detecting array, if there are at most d independent faulty interactions each of strength at most t, they are characterized precisely
as the interactions that appear in no run that passes. We typically
employ the term locating array to refer to both, but for reasons of
computational efﬁciency the locating arrays that we use are, in fact,
detecting arrays.

Table 3: ρ(T ) for one-way interactions T = {(c, ν)}.
ν↓c→
0
1

1
{1,3,5}
{2,4,6}

2
{2,4,5}
{1,3,6}

3
{3,4,5,6}
{1,2}

4
{2,3,5}
{1,4,6}

5
{2,3,6}
{1,4,6}

Now, let us try to locate faults due to two-way interactions. Because the second design point run passes, all two-way interactions
in it are known not to be faulty; Table 4(a) records the results. Repeating to check for coverage of each two-way interaction for each
successful run, those interactions not found to pass in this way in

In practice, one does not know a priori how many interactions are
faulty, or their strengths. Nevertheless, when responses are contin-

33

Table 4: Locating faults due to two-way interactions.

Factors
1, 2
1, 3
1, 4
1, 5
2, 3
2, 4
2, 5
3, 4
3, 5
4, 5

(a) Run 2
00 01 10














11


Factors
1, 2
1, 3
1, 4
1, 5
2, 3
2, 4
2, 5
3, 4
3, 5
4, 5

(b) All Runs
00 01 10






 
  
 
  
  
  
  

of levels for each factor to the desired number, eliminating rows in
the process and forming an array C with 143 design points. The
resulting array provides coverage of two-way interactions but does
not support location. When T and T  are interactions, to distinguish them we require that ρ(T ) = ρ(T  ), but we ask for more,
namely that |ρ(T ) \ ρ(T  )| ≥ 2 and |ρ(T  ) \ ρ(T )| ≥ 2; this ensures that for every two interactions of interest, there are at least
two design points containing one but not the other. To accomplish
this, we formed three copies of C, randomly permuted their symbols within each column, and formed their union (so that every
two-way interaction is covered at least three times). The resulting
array B with 429 rows turned out to be (1, 2)-detecting. Three rows
were selected by a greedy method to ensure the stronger condition
that |ρ(T ) \ ρ(T  )| ≥ 2 for every pair T, T  of interactions; then
eleven rows were deleted by a greedy algorithm to remove redundant rows, ultimately producing a design with 421 rows. Appendix
A gives a pointer to the locating array used as the experimental
design. Our objective was not to ﬁnd the smallest possible array,
because a fair evaluation of the efﬁcacy of locating arrays should
not rely on substantial additional structure being present.

11








Table 4(b) form a set of candidate faults. In this example, there are
nine interactions in the set of candidate faults. Now for the twoway interaction {(1, 0), (2, 1)}, ρ({(1, 0), (2, 1)}) = {1, 3}, and
it is the only two-way interaction for which this holds; and, no oneway interaction T has ρ(T ) = {1, 3}. Hence if there is a single
fault, it must be {(1, 0), (2, 1)}, and we have located the fault.

Ten replicates of each design point in the LA are run in ns-2;
for each a response of TCP throughput is measured. These are
averaged for each design point resulting in a vector with 421 entries
of observed average TCP throughput obsT h.

Our success for one response is not sufﬁcient, however. Because
ρ({(1, 0), (2, 1)}) = {1} = ρ({(2, 1), (3, 1)}), if only run 1 fails,
there are at least two equally plausible explanations using only a
single two-way interaction. Indeed A is not (1, 2)-locating. Thus
the ability to locate is more than simply coverage!

3.

3.2

SCREENING AN ENGINEERED SYSTEM

We now apply locating arrays for screening in a complex engineered system. One example of a CES for which it has been particularly difﬁcult to develop models is a mobile ad hoc network
(MANET). A MANET is a collection of mobile wireless nodes that
self-organize without the use of any ﬁxed infrastructure or centralized control. We seek to use a locating array to screen for the inﬂuential factors and interactions on average transport control protocol
(TCP) throughput in a simulation model of a MANET.

3.1

Screening Algorithm

We describe an algorithm for screening at a high level to facilitate
understanding. In each iteration of the algorithm the most signiﬁcant main effect or two-way interaction is identiﬁed. These terms
are accumulated in a screening model of average TCP throughput. However, this screening model is not intended as a predictive
model; the quality of its current estimate allows the algorithm to
select the next most signiﬁcant term. The screening model is used
only to identify inﬂuential main effects and two-way interactions.
With its output, a predictive model can be built; see §4.
Initially, the screening model has no terms. With no other information, it should estimate the average TCP throughput to be the
average of the vector of observed average throughput. This is unlikely to be a very good estimation!

Designing the Experiment

We use the ns-2 simulator [37], version 2.34, for our experimentation. Since our response of interest is average TCP throughput,
we select the ﬁle transfer protocol (FTP) as our application because
it uses TCP for reliability. We select the internet protocol (IP), the
Ad hoc On-demand Distance Vector routing protocol (AODV) [42],
and IEEE 802.11b direct sequence spread spectrum (DSSS) as protocols at the network, data link, and physical layers of the protocol
stack. We also use the mobility, energy, error, and propagation
models in ns-2. From these protocols and models we identify
75 controllable factors. The region of interest for each factor, i.e.,
the range over which the factor is varied, ranges from two to ten
levels, with some set according to recommendations in [33]. See
Appendix A for a pointer to details of the factors and their levels.

Our strategy to identify the most signiﬁcant factor or interaction
as the term to add to the screening model is as follows. Suppose
that factor Fj , 1 ≤ k ≤ 75, has j levels Lj = {vj,1 , . . . vj,j }.
For each level , 1 ≤  ≤ j , of factor Fj iterate through each
of the 421 design points of the locating array A. For each design
point i, 1 ≤ i ≤ 421, partition the contribution of the (factor Fj ,
level vj, ) combination into one of two sets: S or S. If the design
point has the factor Fj set to level , i.e., ai,j = vj, , then add
the throughput measured for design point i, obsT h[i], to S; otherwise add obsT h[i] to S. Then, compute the (absolute) difference
of the average of sets S and S. (Of course, metrics other than the
difference of averages could be used.) Either the difference is zero
(i.e., the average TCP throughput collected in the sets S and S is
the same), or it is non-zero. If the difference is non-zero, then one
possible explanation is that the (factor Fj , level vj, ) combination
is responsible for the difference.

The full-factorial design for this factor space is infeasible; it has
over 1043 design points! In contrast, the locating array constructed
and checked manually has only 421 design points. Except for small
locating arrays [51], no general construction methods have been
published. We adopted a heuristic approach to construct the LA.

Our hypothesis is that the (factor Fj , level vj, ) combination over
all combinations for which the difference between the sets is the
greatest is the most signiﬁcant one. If this is correct, then a term
of the form c · (Fj , vj, ) is added to the screening model. The

Initially we selected a covering array with 75 factors and 10 levels
per factor, constructed using a standard product construction [7].
We applied a post-optimization method [34] to reduce the number

34

coefﬁcient c is equal to the difference in average TCP throughput
of each set. When this term is added to the screening model, it
makes the same estimation for average TCP throughput for sets S
and S.

design point with this initial ﬁtted value.
Now, we iterate over each (factor,level) combination. Factor
1 is set

to its low level in design points 1–4. Therefore S = 14 41 resT h[i] =

−134347
= −33586 and S = 14 85 resT h[i] = 134344
= 33586.
4
4
The absolute difference, |S − S| = |-33586 − 33586| = 67172.

In the ﬁrst iteration of this algorithm, the estimate (i.e., the average
of the vector of observed average TCP throughput) is used to determine deviations from each entry in the vector obsT h. We now
have a screening model that apparently includes the most signiﬁcant factor. It is now used to produce a new estimate of average
TCP throughput and update the vector of residual throughput. The
algorithm can be applied repeatedly to the residuals to identify the
next most important factor or interaction.

Repeating for each (factor, level) combination, as well as all twoway interactions, we ﬁnd that it is a main effect that has highest
absolute difference with a value of 131255. It occurs when factor
3 is set to its lowest level, namely when the number of ﬂows at
the application layer is only one. Hence we attribute this as the
explanation for the largest difference and add the term c · (F3 , v3,0 )
to the model. The method of ordinary least squares (OLS) is used
to ﬁt the intercept and coefﬁcient c of the new term. This results
in an updated model of T = 12410 + 131255 · (F3 , v3,0 ). Its
coefﬁcient of determination is R2 = 0.33.

While this algorithm is described for (factor, level) combinations,
we actually iterate over all one-way (i.e., all (factor, level) combinations) and all two-way interactions (i.e., all pairs of (factor, level)
combinations) to identify the main effect or two-way interaction of
highest signiﬁcance. Any number of stopping conditions may be
used to decide when to terminate the model development. We use
the R2 , the coefﬁcient of determination, indicating how well data
ﬁts a line or curve; when it shows marginal improvement, we stop.

Using this updated model, the residuals can be recomputed as input
to the next iteration of the algorithm.
Next, we describe some of the obstacles arising in the practical
application of the screening algorithm.

The locating array constructed for our CES is a (d = 1, t = 2)locating array, meaning it only guarantees to be able to locate (identify) at most one (d = 1) main effect or two-way (i.e., up to t = 2way) interaction. It is interesting that the LA may be used iteratively to identify subsequent signiﬁcant main effects or interactions. In this sense, the algorithm uses a “heavy-hitters” approach
as in compressive sensing [6].

Applying the Screening Algorithm

In applying the screening algorithm to our CES, several obstacles
arose. The ﬁrst is that the measured average TCP throughput is not
normally distributed, as Figure 2 shows; this is not uncommon in
systems experimentation [12]. The best transformation of the data
is a natural logarithm (Figure 3a). From the normal probability plot
(Figure 3b), we ﬁnd that the transformed data are still not normally
distributed; nevertheless, we work with this transformation of the
data.

Example of the Screening Algorithm

A small example is provided to step through one iteration of the
screening algorithm. Suppose that we use the experimental design for four binary factors in Table 5. It is a covering array of
strength three and therefore also a (2, 1)-detecting array. Factor 1
corresponds to the distribution function used for introducing errors
(uniformly or exponentially distributed), factor 2 to the error rate
(10−7 or 10−5 ), factor 3 to the number of ﬂows at the application
layer (1 or 18), and factor 4 to the TCP packet size (64 or 2048);
the levels are taken as “binary” for this example. All remaining factors are set to their default levels for experimentation. A response
of observed TCP throughput for each design point, averaged over
ten replicates, is listed in the column obsT h. (All measures are
truncated to integers for simplicity.)

72%

0.985

300

0.94
250

0.88
Normal Probability

3.3

3.4

Frequency

200

150

0.75

0.5

0.25
0.12

100

0.06
18%

0.015

50
5%
2%

0

50,000

0.003
1%

100,000
obsTH1

1%

0%

150,000

0%

0%

200,000

(a) Throughput distribution.

0%

0

50,000

100,000

150,000

200,000

250,000

250,00

obsTH1

(b) Normal probability plot.

Design Points

Table 5: Experimental design and average TCP throughput.

1
2
3
4
5
6
7
8

1
0
0
0
0
1
1
1
1

Factors
2 3
0 0
0 1
1 0
1 1
0 0
0 1
1 0
1 1

Figure 2: Distribution of the original observed average throughput,
and corresponding normal probability plot.
4
0
1
1
0
1
0
0
1

obsT h
63339
29860
80801
3804
373866
3879
56656
12095

resT h
-14699
-48178
2764
-74234
295828
-74159
-21382
-65943

A much larger problem arises from the fact that the LA does not
cover each main effect and two-way interaction the same number
of times. Indeed, binary factors are covered much more frequently
(some as many as two hundred times in the 421 row LA) compared
to two-way interactions of factors with ten levels (only a handful
of times). This is unavoidable when one-way and two-way interactions are compared, and when factors have a different numbers of
levels.

The overall mean of the obsT h is 78038. Therefore, the screening
model initially estimates this value for average TCP throughput,
i.e., T = 78038. The residuals (resT h) are computed in Table 5 by
taking the difference of the observed average throughput for each

Consider the behaviour of the screening algorithm. For a binary
factor the sets S and S have the same or nearly the same size and,
as a result, the average of each set has small variance. In the example in §3.3, each (factor, level) combination is covered four times

35

0.985

26%

0.985

24%

100

100

0.94

0.94
21%

0.88

0.88
80

Normal Probability

14%

18%

0.75
Frequency

60

Normal Probability

Frequency

80

0.5

60
13%
12%

0.25
40

40

0.12

8%

0.75

0.5

0.25
0.12

9%

8%
7%

0.06
5%

20

5%

20

0.015

4%

1%

1%

1%

4

6
8
ln(obsTH1)

10

(a) ln transformation.

0.015

0.003

1%

2
2

0.06

6%

6%
5%

4

6

8

10

1%

1%

0%

12

ln(obsTH1

-4
-2
0
2
Residuals of TCP throughput after iteration 1

-4

-2

0

2

4

4

(a) Distribution of ﬁrst residual.

(b) Normal probability plot.

0.003
-6

-6

12

Residuals of TCP throughput after iteration 1

(b) Normal probability plot.

Figure 3: Natural logarithm transformation of the original observed
throughput, and corresponding normal probability plot.

Figure 4: Distribution of residuals after the ﬁrst iteration of the
screening algorithm, and corresponding normal probability plot.

(each column of the array has four zeros and four ones). However
in general, as the number of levels for a factor increases, the size of
the sets S and S may become markedly different, and the variance
of the average of each set may increase greatly. Returning to the
example in §3.3, the two-way interactions are not covered equally.
Consider the two-way interaction {(1, 0), (2, 0)}. It is covered in
only two rows of the array, namely |ρ({(1, 0), (2, 0)})| = |{1, 2}| =
2 (this is true for all two-way interactions in this example). Even
in this small array, the coverage of two-way interactions is unbalanced resulting in S accumulating two values and S accumulating
six values. This makes any direct comparison among (factor, level)
combinations and/or two-way interactions impossible.

intercept and βi is the coefﬁcient of term i, 1 ≤ i ≤ 12.
Table 6: Screening model with twelve terms.

To address this problem, factors are grouped according to the number of times each level is covered in the LA; see Appendix A for
a pointer to the details on how groups are formed. Now, in each
iteration of the screening algorithm, the ﬁrst step is to select the
most signiﬁcant factor or interaction from each group. Then from
these candidates, the most signiﬁcant factor or interaction overall
is selected.
The Figure 4 shows the graphical tests for normality of the residuals after the ﬁrst iteration of the screening algorithm. (Similar behaviour of the residuals is observed after each iteration.) While the
ﬁgures indicate that the residuals are close to normally distributed,
we check using the non-parametric Shapiro-Wilk test. This test indicates that the residuals are still not normally distributed. Hence,
we use the Wilcoxon rank sum test and the Mann-Whitney U test [14, 28, 54] to select the most signiﬁcant factor or two-way
interaction within each group. Then, to select the most signiﬁcant factor or interaction over all groups, the Akaike information
criterion (AICC ) [1] is used.

βi
5.6
4.4
4.0
-4.7

-11.8
-12.1
-9.3
6.5

-1.6
-1.5
-1.2
0.9

6.6
8.4

0.7
1.1

6.3

1.1

5.5
5.2

0.7
0.5

Factor or interaction, and level(s)
ErrorModel_ranvar_ U nif orm
ErrorModel_unit_ pkt)
(ErrorModel_ranvar_ U nif orm) *
(ErrorModel_unit_ pkt)
TCP_packetSize_ 64
MAC_RTSThreshold_ 0
TCP_packetSize_ 128
(TCP_RTTvar_exp_ 2) *
(TCP_min_max_RTO_ 0.1)
TCP_min_max_RTO_ 0.2
(ErrorModel_unit_ pkt ) *
(ErrorModel_rate_ 1.0E-07)
(ErrorModel_ranvar_ U nif orm) *
(MAC_RTSThreshold_ 0)
APP_flows_ 1
RWP_Area_ 8

The ﬁrst notable observation about this screening model is that it
contains both main effects and two-way interactions. Moreover, it
contains factors from across the layers of the protocol stack (application, transport, and MAC) and not just the transport layer; in
addition, it includes factors from the error model and the mobility model. Aside from these differences with other models of TCP
throughput (such as [15, 18, 30, 39–41, 55, 57, 58]), the screening
model includes not just which factors or two-way interactions are
signiﬁcant, but the level at which each is signiﬁcant.

We still need to ﬁt the intercept and the coefﬁcients of the terms.
For a linear model with the assumptions of expected error of zero
and expected variance in the error to be equal, the method of ordinary least squares (OLS) is used. However, if the expected variance
in the error is unequal, OLS is no longer appropriate [32]. In this
case, the method of weighted least squares (WLS) is used to ﬁt the
intercept and coefﬁcients of the terms in the screening model.

3.4.1

t-Test
52.6
34.5
32.8
-29.1

From the statistical point of view, Table 7 shows a strong correlation among the regressors and the response of average TCP
throughput. The F statistic indicates that the model is signiﬁcant
to the response.
Table 7: Summary statistics of the screening model in Table 6.
R2 and Adjusted R2 : 0.84
Standard deviation: 0.92
F statistic: 180.6 on 12 and 408 df, p-value < 7.89e-155

The Resulting Screening Model

Table 6 gives the screening model for average TCP throughput developed in twelve iterations of the screening algorithm; Table 8 lists
its unique factors. A Student’s t-test was run on each term in the
screening model and each was found to be signiﬁcant; β0 is the

We are encouraged by the factors and interactions identiﬁed. This
includes how and into what unit errors are introduced (using a uni-

36

Table 9: Partial results of a 29 full-factorial screening experiment
using JMP 11.0 on the nine factors in Table 8.

form distribution into packets rather than bit errors), and their interaction. Smaller sized packets (64 and 128 bytes) tend to reduce
throughput. When RTS/CTS is always on (i.e., the threshold is
zero bytes), there is a negative impact on throughput compared to
when it is conﬁgured to 1500 or 3000 bytes (always off). The retransmission timeout (RTO) and round trip time (RTT) are part of
TCP’s congestion control mechanism; the RTO infers packet loss
by observing duplicate acknowledgements and the RTT is related
to the propagation delay. The RTO is signiﬁcant by itself, and in
its interaction with the RTT as they work to correct and prevent
network congestion. The synthetic error model of the simulator
drops packets comparing them with data from an uniform distribution at a steady-state loss event rate of 1.0E-07; this is the lowest
error rate used and naturally it corresponds with higher throughput. Smaller simulation areas also result in higher throughput; a
larger area has longer average shortest-hop path lengths and average higher network partition rates both of which negatively affect
throughput. The throughput response is higher with fewer ﬂows
because increasing the number of ﬂows not only may overload the
network but more ﬂows are more challenging to route in a MANET.

4.

Term
ErrorModel_ranvar_*ErrorModel_unit_
ErrorModel_ranvar_
ErrorModel_unit_
TCP_packetSize_
APP_ﬂows_
TCP_min_max_RTO_
RWP_Area_
MAC_RTSThreshold_
ErrorModel_unit_*TCP_packetSize_
ErrorModel_rate_
ErrorModel_ranvar_*MAC_RTSThreshold_
APP_ﬂows_*RWP_Area_
ErrorModel_unit_*ErrorModel_rate_
TCP_packetSize_*ErrorModel_rate_
ErrorModel_unit_*MAC_RTSThreshold_
ErrorModel_ranvar_*APP_ﬂows_
APP_ﬂows_*TCP_min_max_RTO_
ErrorModel_unit_*APP_ﬂows_
ErrorModel_ranvar_*TCP_min_max_RTO_
ErrorModel_ranvar_*TCP_packetSize_
TCP_packetSize_*APP_ﬂows_
TCP_min_max_RTO_*RWP_Area_
ErrorModel_ranvar_*RWP_Area_
MAC_RTSThreshold_*ErrorModel_rate_
TCP_min_max_RTO_*ErrorModel_rate_
TCP_min_max_RTO_*TCP_rttvar_exp_
ErrorModel_unit_*TCP_min_max_RTO_
APP_ﬂows_*ErrorModel_rate_
RWP_Area_*MAC_RTSThreshold_
ErrorModel_unit_*RWP_Area_
TCP_rttvar_exp_
TCP_packetSize_*RWP_Area_
APP_ﬂows_*MAC_RTSThreshold_
RWP_Area_*ErrorModel_rate_
ErrorModel_ranvar_*TCP_rttvar_exp_

VALIDATION AND VERIFICATION

From the 75 controllable factors used in experimentation, nine unique
factors are present in the twelve terms in the screening model in Table 6; these are listed in Table 8.
Table 8: Unique factors in the screening model in Table 6.
Level
Factor
TCP_RTTvar_exp_
ErrorModel_ranvar_
ErrorModel_unit_
MAC_RTSThreshold_
ErrorModel_rate_
RWP_Area_
TCP_min_max_RTO_
APP_flows_
TCP_packetSize_

Minimum
2
U nif orm
pkt
0
1.0E-07
8
0.1
1
64

Maximum
4
Exponential
bit
3000
1.0E-05
40
40
18
2048

In order to validate the factors and interactions identiﬁed, we ﬁrst
conduct a full-factorial experiment for these nine factors using the
extremes of their region of interest, using the statistical software
JMP to analyze the results. From this, we produce a predictive
model of average TCP throughput. We then examine the quality
of this predictive model by comparing how it performs on random
design points (i.e., a design point in which the level of each factor
is selected at random).

in Table 6. Indeed, both models have the same four most signiﬁcant
terms (though in a different order), and all factors and interactions
in Table 6 are a subset of the terms in Table 9. Appendix A gives
a pointer to the details of the predictive model for average TCP
throughput that was ﬁt using a subset of the signiﬁcant terms in
Table 9.
Figure 5 shows the results of evaluating the JMP predictive model
as a function of the TCP packet size, for the three levels of error
rate. As in the experimentation, all remaining factors are ﬁxed at
their default levels. As expected, the results show that the highest
TCP throughput is achieved when the error rate is at the lowest level
(1.0E-07). For a given error rate the TCP throughput increases as
a function of packet size, after which it decreases. An exception
is for packet size 1024. Aside from this exception, these results
also conﬁrm our intuition of TCP throughput behaviour. The reason for this exception deserves further study but may be related to
the default settings used for the other 66 factors not varied in this
screening experiment.

We present our validation results next.

4.1

p-Value
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
<.0001*
0.0001
0.0001
0.0003
0.0006
0.001
0.0012
0.002
0.0116
0.0444
0.0515

Full-Factorial Screening in JMP

We conduct an independent 29 full-factorial experiment on the nine
factors in Table 8. All remaining 75 − 9 = 66 factors are ﬁxed to
their default levels. Ten replicates of each of the 29 design points is
run, and TCP throughput measured. The results of the experimentation are input to the JMP statistical software, version 11.0 [45].
The results from the full-factorial screening experiment are given in
Table 9. It includes only the main effects and two-way interactions
sorted in increasing order by the p-value. The results indicate high
commonality with the main effects and two-factor interactions selected by the screening algorithm that formed the screening model

We now examine the predictive accuracy of the JMP model for random design points.

37

120000

TCP throughput (bps)

factors and two-way interactions, the screening model developed
also reﬂects the actual behaviour well.

JMP 1.0e-7
JMP 1.0e-6
JMP 1.0e-5

100000

80000

Despite this, the method aims only to deal with many factors and
their interactions to identify the signiﬁcant ones. We advocate that
further experimentation is necessary after the screening is completed, both to conﬁrm the screening results and to build a predictive model. One must be cautious not to over-ﬁt the experimental results and claim unwarranted conﬁdence; conﬁrmation is
needed. This is particularly a concern if the stopping criterion chosen locates too many or too few signiﬁcant interactions; while our
choice of R2 appears to have worked well, future effort should address the impact of different stopping criteria. A second concern is
the selection criterion for the next factor or interaction to include.
Subsequent selections depend upon selections already made, so our
method could in principle be misdirected by a bad selection. Our
criterion of using the differences between responses for S and those
for S has also worked well, but we cannot be certain that such a
simple selection sufﬁces in general. Finally, we have employed
only a few locating arrays; while they have worked well in our
analyses, constructing a suitable locating array remains a challenging problem that merits further research.

60000

40000

20000

0
64 128

256

512

768

1024

1280

1536

1792

2048

Packet size (bytes)

Figure 5: TCP throughput as a function of packet size as predicted
the by JMP model; all other factors are at their default levels.

4.2

Predictive Accuracy of JMP Model

In order to test the predictive accuracy of the JMP model, a new
experimental design of one hundred random design points is constructed. In constructing each design point, for each of factor Fj ,
1 ≤ j ≤ 75, a random level from Lj is selected. New mobility
scenarios are also generated. Ten replicates of each of the random
design points are run in the ns-2 simulator, and the TCP throughput measured. In addition, for each experiment in the design, the
JMP model is evaluated generating a new data set of ﬁtted TCP
throughput.

Certainly further experimentation is needed to assess the merit of
screening using LAs, in particular on physical not just simulated
complex engineered systems, and draw ﬁrm conclusions. What we
can conclude is that in a challenging CES arising from a MANET,
screening using locating arrays is viable and yields useful models.

Figure 6 shows the average TCP throughput from simulation, and
the ﬁtted throughput from the JMP model corresponding to this
random design. The mean TCP throughput from the simulations is
20,892 bps whereas the mean from the JMP model is lower, only
13,946 bps. However, the standard deviation of the results from the
JMP model is smaller than the standard deviation from the simulations. Both models exhibit a few outliers. Approximately 94%
of the results predicted for TCP throughput from the JMP model
are in one standard deviation of the simulation results. Considering
the size of the factor space, we conclude that the predicted average
TCP throughput of the JMP model is similar to the average TCP
throughput measured in simulation.

4.3

Acknowledgment
Thanks to Doug Montgomery for his advice on all things statistical.
This material is based in part upon work supported by the National
Science Foundation under Grant No. 1421058.

6.

Predictive Accuracy of Screening Model

While the model developed in applying the screening algorithm
based on the LA (Table 6) is not intended to be used as a predictive
model, we were curious about its predictive accuracy. Appendix
A gives a pointer to a summary of results similar to those in this
section for the screening model. To our surprise, the predictive accuracy of the screening model is reasonably good. The screening
model does appear to have more variability than the model developed in JMP.

5.

REFERENCES

[1] H. Akaike. A new look at the statistical model identiﬁcation.
IEEE Transactions on Automatic Control, 19(6):716–723,
1974.
[2] R. C. Bryce and C. J. Colbourn. A density-based greedy
algorithm for higher strength covering arrays. Software
Testing, Veriﬁcation, and Reliability, 19:37–53, 2009.
[3] J. N. Cawse. Experimental design for combinatorial and high
throughput materials development. GE Global Research
Technical Report, 29(9):769–781, 2002.
[4] C. J. Colbourn. Combinatorial aspects of covering arrays. Le
Matematiche (Catania), 58:121–167, 2004.
[5] C. J. Colbourn. Covering arrays and hash families. In
Information Security and Related Combinatorics, NATO
Peace and Information Security, pages 99–136. IOS Press,
2011.
[6] C. J. Colbourn, D. Horsley, and V. R. Syrotiuk. Frameproof
codes and compressive sensing. In Proc. 48th Annual
Allerton Conference on Communication, Control, and
Computing, 2010.
[7] C. J. Colbourn, S. S. Martirosyan, G. L. Mullen, D. E.
Shasha, G. B. Sherwood, and J. L. Yucas. Products of mixed
covering arrays of strength two. Journal of Combinatorial
Designs, 14(2):124–138, 2006.
[8] C. J. Colbourn and D. W. McClary. Locating and detecting
arrays for interaction faults. Journal of Combinatorial
Optimization, 15:17–48, 2008.
[9] C. Croarkin, P. Tobias, J. J. Filliben, B. Hembree,

CONCLUSIONS

Locating arrays capture the intuition that in order to see the effect of
a main effect or interaction, some design point must cover it; and in
order to distinguish it, the responses for the set of design points that
cover it must not be equally explained by another small set of main
effects or interactions. In a complex engineered system, many main
effects and interactions may be signiﬁcant, but our method identiﬁes them one at a time, iteratively improving a screening model. In
this way, an experimental design must be able to repeatedly locate
a single “most signiﬁcant” main effect or interaction. Our results
show that using locating arrays for screening appears promising.
Indeed while the screening targeted the identiﬁcation of signiﬁcant

38

160000
Fitted JMP model
Mean fitted JMP model

140000

TCP throughput (bps)

120000
100000
80000
60000
40000
+StDev Fitted JMP model

20000
0

-StDev Fitted JMP model

0

10

20

30

40

50

60

70

80

90

100

60

70

80

90

100

Random tests

(a) Predictions by JMP.
160000
Simulated
Mean Simulated

140000

TCP throughput (bps)

120000
100000
80000
60000
+StDev Simulated

40000
20000
0
-StDev Simulated

0

10

20

30

40

50
Random tests

(b) Simulation results.

Figure 6: Predictions by the JMP model and simulation results for random design points.

[10]

[11]

[12]

[13]

[14]

[15]

[16]

W. Guthrie, L. Trutna, and J. Prins, editors.
NIST/SEMATECH e-Handbook of Statistical Methods.
NIST/SEMATECH, 2012.
S. R. Dalal, A. J. N. Karunanithi, J. M. L. Leaton, G. C. P.
Patton, and B. M. Horowitz. Model-based testing in practice.
In Proc. Intl. Conf. on Software Engineering (ICSE ’99),
pages 285–294, 1999.
P. Damaschke. Adaptive versus nonadaptive
attribute-efﬁcient learning. Machine Learning, 41:197–215,
2000.
A. B. de Oliveira, S. Fischmeister, A. Diwan, M. Hauswirth,
and P. F. Sweeney. Why you should care about quantile
regression. In Proc. of the ACM Conf. on Architectural
Support for Programming Languages and Operating Systems
(ASPLOS), March 2013.
S. Dunietz, W. K. Ehrlich, B. D. Szablak, C. L. Mallows, and
A. Iannino. Applying design of experiments to software
testing. In Proc. Intl. Conf. on Software Engineering (ICSE
’97), pages 205–215, Los Alamitos, CA, 1997. IEEE.
M. Fay and M. Proschan. Wilcoxon-Mann-Whitney or t-test?
On assumptions for hypothesis tests and multiple
interpretations of decision rules. Statistics Surveys, 4:1–39,
2010.
S. Floyd, M. Handley, J. Padhye, and J. Widmer.
Equation-based congestion control for unicast applications:
The extended version. SIGCOMM Computing
Communications Review, 30:43–56, 2000.
M. Forbes, J. Lawrence, Y. Lei, R. N. Kacker, and D. R.

[17]

[18]

[19]

[20]
[21]

[22]

[23]

[24]

39

Kuhn. Reﬁning the in-parameter-order strategy for
constructing covering arrays. J. Res. Nat. Inst. Stand. Tech.,
113:287–297, 2008.
S. Ghosh and C. Burns. Comparison of four new general
classes of search designs. Austral. New Zealand J. Stat.,
44:357–366, 2002.
K.-J. Grinnemo and A. Brunstrom. A simulation based
performance analysis of a TCP extension for best-effort
multimedia applications. In Proceedings of the 35th Annual
Simulation Symposium, 2002.
A. Hartman. Software and hardware testing using
combinatorial covering suites. In M. C. Golumbic and
I. B.-A. Hartman, editors, Interdisciplinary Applications of
Graph Theory, Combinatorics, and Algorithms, pages
237–266. Springer, Norwell, MA, 2005.
A. S. Hedayat, N. J. A. Sloane, and J. Stufken. Orthogonal
Arrays. Springer-Verlag, New York, 1999.
D. S. Hoskins, C. J. Colbourn, and M. Kulahci. Truncated
D-optimal designs for screening experiments. American
Journal of Mathematical and Management Sciences,
28:359–383, 2008.
D. S. Hoskins, C. J. Colbourn, and D. C. Montgomery.
D-optimal designs with interaction coverage. Journal of
Statistical Theory and Practice, 3:817–830, 2009.
J. P. C. Kleijnen. An overview of the design and analysis of
simulation experiments for sensitivity analysis. European
Journal of Operational Research, 164:287–300, 2005.
J. P. C. Kleijnen, B. Bettonvil, and F. Persson. Screening for

[25]

[26]

[27]

[28]

[29]

[30]

[31]
[32]

[33]

[34]

[35]

[36]
[37]
[38]

[39]

[40]

[41]

[42]

[43]

the important factors in large discrete-even simulation
models: Sequential bifurcation and its applications. In A. M.
Dean and S. M. Lewis, editors, Screening: Methods for
Experimentation in Industry, Drug Discovery and Genetics,
chapter 13, pages 287–307. Springer-Verlag, 2006.
D. Kuhn and M. Reilly. An investigation of the applicability
of design of experiments to software testing. In Proc. 27th
Annual NASA Goddard/IEEE Software Engineering
Workshop, pages 91–95, Los Alamitos, CA, 2002. IEEE.
D. R. Kuhn, D. R. Wallace, and A. M. Gallo. Software fault
interactions and implications for software testing. IEEE
Trans. Software Engineering, 30(6):418–421, 2004.
R. Li and D. K. J. Lin. Analysis methods for supersaturated
designs: Some comparisons. Journal of Data Science, pages
249–260, 2003.
H. B. Mann and D. R. Whitney. On a test of whether one of
two random variables is stochastically larger than the other.
Annals of Mathematical Statistics, 18:50–60, 1947.
C. Martínez, L. Moura, D. Panario, and B. Stevens. Locating
errors using ELAs, covering arrays, and adaptive testing
algorithms. SIAM J. Discrete Math., 23:1776–1799, 2009/10.
M. Mathis, J. Semke, J. Mahdavi, and T. Ott. The
macroscopic behavior of the TCP congestion avoidance
algorithm. SIGCOMM Comput. Commun. Rev., 27:67–82,
1997.
D. C. Montgomery. Design and Analysis of Experiments.
John Wiley & Sons, Inc., 8 edition, 2012.
D. C. Montgomery, E. A. Peck, and C. G. Vining.
Introduction to Linear Regression Analysis. John Wiley &
Sons, Inc., 4th edition, 2006.
A. Munjal, T. Camp, and W. Navidi. Constructing rigorous
MANET simulation scenarios with realistic mobility. In
European Wireless Conference (EW), pages 817–824, 2010.
P. Nayeri, C. J. Colbourn, and G. Konjevod. Randomized
postoptimization of covering arrays. European Journal of
Combinatorics, 34:91–103, 2013.
Networking and information technology research and
development (NITRD) large scale networking (LSN)
workshop report on complex engineered networks, 2012.
C. Nie and H. Leung. A survey of combinatorial testing.
ACM Computing Surveys, 43, 2011.
The Network Simulator - ns-2.
http://www.isi.edu/nsnam/ns.
K. Nurmela. Upper bounds for covering arrays by tabu
search. Discrete Applied Mathematics, 138(9):143–152,
2004.
J. Padhye, V. Firoiu, D. Towsley, and J. Kurose. Modeling
TCP throughput: a simple model and its empirical validation.
SIGCOMM Computing Communications Review,
28:303–314, 1998.
J. Padhye, V. Firoiu, D. F. Towsley, and J. F. Kurose.
Modeling TCP Reno performance: A simple model and its
empirical validation. IEEE/ACM Transactions on
Networking, 8:133–145, 2000.
N. Parvez, A. Mahanti, and C. Williamson. An analytic
throughput model for TCP NewReno. IEEE/ACM
Transactions on Networking, 18:448–461, 2010.
C. E. Perkins and E. M. Royer. Ad hoc on-demand distance
vector routing. In Proc. Second IEEE Workshop on Mobile
Computing Systems and Applications, pages 90–100, 1999.
S. Poljak, A. Pultr, and V. Rödl. On qualitatively independent

[44]

[45]
[46]

[47]

[48]

[49]

[50]

[51]

[52]

[53]

[54]
[55]

[56]

[57]

[58]

partitions and related problems. Discrete Applied Math.,
6:193–205, 1983.
A. H. Ronneseth and C. J. Colbourn. Merging covering
arrays and compressing multiple sequence alignments.
Discrete Applied Mathematics, 157:2177–2190, 2009.
JMP statistical software from SAS.
http://www.jmp.com.
G. Seroussi and N. H. Bshouty. Vector sets for exhaustive
testing of logic circuits. IEEE Transactions on Information
Theory, 34:513–522, 1988.
D. E. Shasha, A. Y. Kouranov, L. V. Lejay, M. F. Chou, and
G. M. Coruzzi. Using combinatorial design to study
regulation by multiple input signals: A tool for parsimony in
the post-genomics era. Plant Physiology, 127:1590–1594,
2001.
T. Shirakura, T. Takahashi, and J. N. Srivastava. Searching
probabilities for nonzero effects in search designs for the
noisy case. Ann. Statist., 24:2560–2568, 1996.
J. N. Srivastava. Designs for searching non-negligible effects.
In J. N. Srivastava, editor, A Survey of Statistical Design and
Linear Models, pages 507–519. North–Holland, 1975.
D. T. Tang and C. L. Chen. Iterative exhaustive pattern
generation for logic testing. IBM Journal Research and
Development, 28:212–219, 1984.
Y. Tang, C. J. Colbourn, and J. Yin. Optimality and
constructions of locating arrays. J. Stat. Theory Pract.,
6(1):20–29, 2012.
J. Torres-Jimenez and E. Rodriguez-Tello. New upper
bounds for binary covering arrays using simulated annealing.
Information Sciences, 185:137–152, 2012.
K. K. Vadde and V. R. Syrotiuk. Factor interaction on service
delivery in mobile ad hoc networks. IEEE Journal on
Selected Areas in Communications, 22:1335–1346, 2004.
F. Wilcoxon. Individual comparisons by ranking methods.
Biometrics Bulletin, 1:80–83, 1945.
I. Yeom and A. L. N. Reddy. Modeling TCP behavior in a
differentiated services network. IEEE/ACM Transactions on
Networking, 9:31–46, 1999.
C. Yilmaz, M. B. Cohen, and A. Porter. Covering arrays for
efﬁcient fault characterization in complex conﬁguration
spaces. IEEE Transactions on Software Engineering,
31:20–34, 2006.
B. Zhou, C. P. Fu, D.-M. Chiu, C. T. Lau, and L. H. Ngoh. A
simple throughput model for TCP Reno. In Proceedings of
the IEEE International Communications Conference
(ICC’06), 2006.
M. Zorzi, A. Chockalingam, and R. R. Rao. Throughput
analysis of TCP on channels with memory. IEEE Journal on
Selected Areas in Communications, 18:1289–1300, 2000.

APPENDIX
A. GITHUB REPOSITORY
A GitHub repository provides supplementary material at:
https://github.com/locatingarray/screening.git
Speciﬁcally, it includes the 75 controllable factors in the ns-2 simulator used in experimentation and their levels (§3.1), the 421 × 75
LA used as the experimental design (§3.1), a description of how
factors are grouped (§3.4), the JMP model for TCP throughput,
along with some statistical analysis (§4.1), and some analysis of
the predictive capability of the screening model (§4.3).

40

Available online at www.sciencedirect.com

Ad Hoc Networks 6 (2008) 524–538
www.elsevier.com/locate/adhoc

Adaptive audio streaming in mobile ad hoc networks
using neural networks
Daniel W. McClary a, Violet R. Syrotiuk

a,*

, Vincent Lecuire

b

a

b

Department of Computer Science and Engineering, Arizona State University, Brickyard Suite 523, 699 South Mill Avenue,
Tempe, AZ 85281, United States
Centre de Recherche en Automatique de Nancy (CRAN UMR 7039), Nancy-Université, CNRS Faculté des Sciences et Techniques,
BP 239, F-54506 Vandoeuvre-lés-Nancy Cedex, France
Received 24 July 2006; received in revised form 10 January 2007; accepted 19 April 2007
Available online 22 May 2007

Abstract
We design a transport protocol that uses artiﬁcial neural networks (ANNs) to adapt the audio transmission rate to
changing conditions in a mobile ad hoc network. The response variables of throughput, end-to-end delay, and jitter are
examined. For each, statistically signiﬁcant factors and interactions are identiﬁed and used in the ANN design. The eﬃcacy
of diﬀerent ANN topologies are evaluated for their predictive accuracy. The Audio Rate Cognition (ARC) protocol incorporates the ANN topology that appears to be the most eﬀective into the end-points of a (multi-hop) ﬂow, using it to adapt
its transmission rate. Compared to competing protocols for media streaming, ARC achieves a signiﬁcant reduction in
packet loss and increased goodput while satisfying the requirements of end-to-end delay and jitter. While the average
throughput of ARC is less than that of TFRC, its average goodput is much higher. As a result, ARC transmits higher
quality audio, minimizing root mean square and Itakura–Saito spectral distances, as well as several parametric distance
measures. In particular, ARC minimizes linear predictive coding cepstral (sic) distance, which closely correlates to subjective audio measures.
 2007 Elsevier B.V. All rights reserved.
Keywords: Adaptation; Transport protocols; Neural networks; Mobile ad hoc networks

1. Introduction
Streaming audio and video over computer networks poses numerous challenges, yet oﬀers great
potential. The promised beneﬁts of voice over IP
(VoIP), entertainment, telemedicine, and other
applications drive research in robust media stream*
Corresponding author. Tel.: +1 480 965 7034; fax: +1 480 965
2751.
E-mail address: syrotiuk@asu.edu (V.R. Syrotiuk).

ing. In mobile ad hoc networks (MANETs), the challenges are more pronounced because the quality
constraints must be satisﬁed under rapidly changing
network conditions.
Our focus is on an adaptive transport protocol
for media streaming. Perhaps the most common
approach to adaptation is to have the destination
of the ﬂow explicitly return feedback to the source.
Consider the TCP-Friendly Rate Control (TFRC)
protocol [1], designed for applications that vary
their transmission rate in response to congestion.

1570-8705/$ - see front matter  2007 Elsevier B.V. All rights reserved.
doi:10.1016/j.adhoc.2007.04.005

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

In the congestion control mechanism of TFRC, the
destination measures the loss event rate and feeds it
back to the source. The source also uses this feedback to measure the round-trip time (RTT). The loss
event rate and RTT are used as input to TFRC’s
throughput equation, to calculate the acceptable
transmission rate. The source then adjusts its transmission rate to match the calculated rate.
The throughput equation used by TFRC is a simpliﬁcation of that used in TCP Reno [2]. It is a function of the factors of transmission rate, packet size,
RTT, and the loss event rate. TFRC was designed
for ﬂows operating in an Internet environment
and, as such, has shortcomings in its adaptation in
mobile wireless networks [3].
Our ﬁrst goal is to identify those factors and
interactions that contribute most to the response
variables of throughput, end-to-end delay, and jitter
in MANETs. The factors considered are similar to
those used in TFRC, with the addition of node
speed. The mathematical and statistical techniques
of Design of experiments (DoE) are used for screening the factors [4].
The regression equations obtained allow the
characterization of average throughput, end-to-end
delay, and jitter. Experimentation shows that while
the terms in the equation deﬁning the response surface do not change with network conditions, the
coeﬃcients of the terms do change. This motivates
the use of machine learning to approximate the
function with changing network conditions. We
select a simple machine learning approach that is
suﬃcient – an artiﬁcial neural network (ANN) –
since it can approximate any continuous function
[5].
We consider three topologies for the ANN. The
ﬁrst ANN topology has an input for each main
eﬀect, each interaction term, and intercept. It has
no hidden layers and a single output neuron, thus
it computes a linear function of its input [6, Chapter
4]. This topology corresponds most closely to the
linear model derived from regression analysis in
the factor study.
In the second topology, only the main eﬀects are
provided as input. One hidden layer with a single
neuron is used, hence the ANN is capable of computing linear and nonlinear functions of the input
[6, Chapter 4]. The topology of the third ANN is
identical to the second except that the input is augmented to include the interaction terms and intercept. This topology computes a nonlinear function
of the main eﬀects and factor interactions.

525

The Audio Rate Cognition (ARC) transport protocol includes an audio streaming rate control
mechanism driven by ANNs, with one ANN for
each response variable. Using ANNs at the source
and the destination of a multi-hop audio stream,
we adjust streaming rates among discrete values.
In simulation, we ﬁrst compare the predictive accuracy of the three ANN topologies and ﬁnd the third
topology to be the most accurate.
Using simulation, we compare the ARC transport protocol using the third ANN topology to
three well-known protocols: the user datagram
protocol (UDP), the real-time transport protocol
(RTP) without a control protocol, and a discrete
variant of TFRC. In mobile ad hoc networks with
several sources, ARC wastes signiﬁcantly less bandwidth by reducing loss between 55% and 95% while
satisfying requirements on end-to-end delay and jitter. As a result, ARC transmits higher quality
audio, minimizing root mean square and Itakura–
Saito spectral distances, as well as several parametric distance measures. In particular, ARC minimizes
linear predictive coding cepstral (sic) distance, which
closely correlates to subjective audio measures.
In summary, we make three contributions:
1. A screening experiment is used to quantify the
contribution of factors and their interactions on
the response variables of throughput, end-toend delay, and jitter.
2. Machine learning is used to approximate these
response variables as a function of the factors
and interactions and use them to adapt the transmission rate. We select a simple approach that is
suﬃcient, artiﬁcial neural networks (ANNs).
Three ANN topologies are evaluated for predictive accuracy.
3. The ARC protocol equipped with the ANN
topology that appears to be the most accurate
is compared in simulation to competing protocols. ARC shows signiﬁcant reduction in packet
loss and increase in goodput, resulting in high
quality audio transmissions.
The rest of the paper is organized as follows.
Section 2 describes the factor study conducted. In
Section 3 we describe the ARC protocol, focussing
on the design of three ANNs topologies motivated
by the factor study. An evaluation of the topologies
is performed in Section 4. We provide the results of
performance comparisons among ARC, UDP,
RTP, and a discrete variant of TFRC in Section 5.

526

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

In Section 6 we discuss the robustness and stability
of ARC. This is followed by a discussion of related
work in MANETs in Section 7. Finally, Section 8
provides conclusions and directions for future work.
2. Factor screening
Design of experiments (DoE) is used for factor
screening [4]. When the pool of factors is large,
screening experiments allow those factors that
contribute the most to a response variable to be
identiﬁed using a minimal number of experiments.
For completeness, we deﬁne the DoE terminology
we use:
• Response variable: A variable in the system whose
performance is of interest.
• Factor: A variable in an experiment believed to
have some eﬀect on the observed value of a
response variable.
• Levels of a factor: The set of discrete values
assigned to a factor.
• Interaction: The failure of one factor to produce
the same eﬀect on the response variable at diﬀerent levels of another factor.
2.1. Response variables and factors for screening
In the screening experiment, we measure three
response variables of interest in media streaming:
• Average throughput: The total number of packets
received divided by the simulation time.
• End-to-end delay: The mean time taken from generation of a packet in the ARC protocol layer to
its reception at the ARC protocol layer of the
destination.
• Jitter: The mean of diﬀerences in delay measured
at the destination.
While there are numerous factors from which to
select that may contribute to our response variables,
we consider the following ﬁve factors:
1.
2.
3.
4.
5.

the
the
the
the
the

node speed,
data rate of each ﬂow,
number of end-to-end ﬂows,
audio codec, and
routing protocol.

Critical to the selection of the quantitative factors is that they can be measured locally. This is

important in MANETs because we seek to design
a transport protocol that does not introduce a large
amount of overhead for adaptation. Additional factors could be explored but we select these to bound
our study.
Both low and high load scenarios are introduced
by varying the number of ﬂows and the data rate of
each ﬂow. The node speeds considered correspond
to slow and fast walking speeds. We use two common pulse-code modulation codecs: pulse-code
modulation (PCM) and adaptive diﬀerential PCM
(ADPCM). Both are widely used and suitable for
medium to high bit-rate audio. Similarly, we select
two well-studied on-demand routing protocols for
MANETs: Ad hoc On-Demand Distance Vector (AODV) [7] and Dynamic Source Routing
(DSR) [8]. AODV is a link-state routing protocol
while DSR uses source routing. Table 1 summarizes
the factors and their levels for the screening
experiment.
2.2. Simulation scenarios
For the screening experiment, we use the ns-2
network simulator due to its extensive support for
MANETs. We generate scenarios with 50 mobile
nodes distributed over a 1500 · 750 m area. We distribute the nodes, each with a transmission range of
250 m, according to the stationary distribution of the
random waypoint mobility model [9]. This ensures
that the distribution of the nodes remains stationary
from the start of the simulation. Nodes are connected to their peers via a shared 11 Mbps interface.
Each ﬂow established from a source to a destination
is constant bit rate (CBR) using the user datagram
protocol (UDP) for transport. These and additional
simulation parameters are listed in Table 2.
An initial model relating responses to factors is
obtained using factorial designs, commonly used
in screening experiments. A 2k factorial design varies each of the k factors at two diﬀerent levels. We
design replicated 23 and 22 factorial experiments
Table 1
Factors and their levels for the screening experiment
Factor

Low level

High level

Node speed (S)
Data rate (D)
Number of ﬂows (F)
Audio codec (C)
Routing protocol (R)

1 m/s
50 Kbps
1
PCM
AODV

8 m/s
600 Kbps
5
ADPCM
DSR

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538
Table 2
Simulation parameters for screening experiments
Simulation parameter

Value

Simulator
Simulation area
Number of nodes
Mobility model

ns-2 version 2.30
1500 · 750 m
50
Steady state initialized random
waypoint [9]
IEEE 802.11b

Medium access control
(MAC) protocol
Transmission range
Wireless interface
Routing protocol
Audio codec
Propagation model
Simulation time
Simulation hardware

250 m
11 Mbps
AODV
PCM
Two ray ground
500 s (for each run)
Linux PC, 2GB RAM, Pentium IV
2.4 GHz processor

considering the quantitative {S, F, D} and categorical {C, R} factors, respectively. We ﬁnd that the
gross eﬀect of codec and routing protocol is limited,
i.e., they contribute much lower orders of magnitude for each response compared to the factors of
the 23 factorial experiment. Therefore we focus on
and describe the results involving the quantitative
factors next.
2.3. Statistical analysis of the screening experiment
An analysis of variance (ANOVA) shows the statistical signiﬁcance of factors contributing to the
response variables through the F-test. The ANOVA
results for end-to-end delay are shown in Table 3.
Three terms are responsible for 98.75% of the
response of end-to-end delay: the main eﬀect D,
the 2-way interaction term SF, and the 3-way interaction term SFD. The other terms (S, F, SD, and
FD) are not signiﬁcant and so are not included in
the table. Similar tables for throughput and jitter
show that all terms are signiﬁcant for these
responses.

527

A response variable y can be modelled as a function of the factors xi, 1 6 i 6 k, y = f(xi). The goal is
to approximate the function f. This may be a linear
or quadratic function, or involve higher order terms
of the factors. Factor screening culminates in the
identiﬁcation of the most important factors and a
simple linear model relating the response variables
and the design factors:
y ¼ w0 þ

k
X

wi xi þ

i¼1

k X
k
X
i¼1

wij xi xj þ :

ð1Þ

j¼2

Here, the wi denote the coeﬃcients of the main
eﬀects in the regression model and wij the coeﬃcient
for the interaction between the ith and jth factors.
Random error stemming from the inaccuracy of
the model is denoted . The regression coeﬃcients
are estimated using the least-squares method [4].
We ﬁnd statistically signiﬁcant regression equations with a hierarchical ordering of factors for
throughput and jitter. For delay, a statistically signiﬁcant non-hierarchical equation is found:
throughputðS;F ;DÞ ¼ wt0 þ wt1 S þ wt2 F þ wt3 D þ wt12 SF
þ wt13 SD þ wt23 FD þ wt123 SFD;
ð2Þ
jitterðS;F ;DÞ ¼ wj0 þ wj1 S þ wj2 F þ wj3 D þ wj12 SF
þ wj13 SD þ wj23 FD þ wj123 SFD;
delayðS; F ;DÞ ¼ wd0 þ wd3 D þ wd12 SF þ wd123 SFD:

ð3Þ
ð4Þ

The response surface for the end-to-end delay at
each node speed of 1, 4, and 8 m/s is shown in
Fig. 1. Analysis of several experiments under diﬀerent conditions consistently yields the same signiﬁcant factors but the coeﬃcients of the main eﬀects
and interactions vary with node speed. This motivates the use of machine learning to approximate
a response variable as a function of its signiﬁcant
factors (see Eqs. (2)–(4)). While there are several
machine learning models, we select artiﬁcial neural

Table 3
ANOVA of end-to-end delay in the screening experiment
Source

Sum of square

Degrees of freedom

Mean square

F

Prob. >F

% Contrib.

Model
D
SF
SFD
Error

0.0150319
0.0050810
0.0044156
0.0055353
0.0001942

3.0000000
1.0000000
1.0000000
1.0000000
4.0000000

0.0050106
0.0050810
0.0044156
0.0055353
0.0000485

103.2176920
104.6678203
90.9593243
114.0259316

0.0003
0.0005
0.0007
0.0004

98.75
33.4
29
36.4

Total

0.0152261

7

528

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538
Delay as a Regression Surface
Delay in s

Delay at 1m/s
Delay at 4m/s
Delay at 8m/s

700
600
500
400
300
200
100
0

1
Number of senders

600
5

50

Data Rate in Kbps

Fig. 1. Regression surface for end-to-end delay at node speeds of 1, 4, and 8 m/s.

networks (ANNs) because they are simple and suﬃcient for the problem [5,10].
3. ARC protocol design
The central component of our Audio Rate Cognition (ARC) protocol is a set of fully connected
feed-forward neural networks, one for each of the
response variables of throughput, end-to-end delay,
and jitter. These ANNs modify their internal values
via the propagation of measured response variables
‘‘backwards’’ from output to input, adjusting internal weights based on the relative error in the predicted and the measured response variables. We
embed these neural networks in the ARC source
and destination, though future directions may place
ANNs at all nodes.
An ANN is a collection of computational neurons arranged into layers. We use fully connected
feed-forward ANNs consisting of a layer of input
neurons, a layer of output neurons, and some number of hidden layers. In order to construct an ANN,
three questions require an answer:

3.1. Neuron and ANN topology
A neuron is deﬁned as a set of input edges
{x0, x1, . . . , xn} and its associated set of weights
{w0, w1, . . . , wn}, an output
Pnedge y, and an activation
function r(‘) where ‘ ¼ i¼1 wi xi . Fig. 2 shows the
logical structure of a neuron in an ANN. It is fed
by a number of weighted inputs, whose linear combination serves as input to the activation function r.
The output value r(‘) of the neuron becomes input
to the next layer of neurons.
We utilize one of the most common neural network activation functions, the sigmoid [5]. The general sigmoid equation is
rð‘Þ ¼

1
:
1 þ e‘

There are no simple rules for determining the optimal topology for a multilayer ANN. Studies have
optimized ANN topologies using heuristic search
algorithms [11,12]. We consider three topologies

1. Which ANN topology approximates the function
most accurately?
2. From where does the input data for the ANN
come?
3. From where is training data for the ANN
acquired?
We answer each of these questions next.

ð5Þ

Fig. 2. Logical structure of an artiﬁcial neuron.

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

and use simulation to determine the topology with
the best performance in Section 4.
An ANN with no hidden layers can approximate
any continuous linear function [6, Chapter 4]. If our
factor study completely captures the behaviour of
the responses, then the ANN topology with an input
for each factor, interaction term, and intercept, no
hidden layers, and a single output neuron should
accurately compute each response. This is the topology labelled Simple Linear ANN in Fig. 3.
For the second topology, we consider the case in
which the response is a nonlinear function of the
main eﬀects, i.e., the factor interactions are insignificant. This may be possible as nonlinear functions
can be roughly be approximated as linear functions
when evaluated at ﬁxed levels of the nonlinear factors [13, Chapter 6]. This topology therefore has
input neurons for each of the factors, a hidden layer
consisting of a single neuron, and a single output
neuron; see the topology labelled Simple Nonlinear
ANN in Fig. 3.
As a third alternative, we consider the case in
which the function may be nonlinear in the signiﬁcant factors and interactions. In this case, the topology consists of inputs for each factor, interaction
term, and intercept, a single hidden neuron, and
an output neuron; this topology is labelled Interaction Nonlinear ANN in Fig. 3.
3.2. Input to the ANN
Collecting input data for an ANN requires a
means to determine the node speed S, the data rate
D, and the number of end-to-end ﬂows F that exist
at any given time. In a MANET, the limited perspective of a mobile node makes a global deduction
of such data costly or impractical. Our interest is in
factors whose values can be collected locally with
little overhead. Indeed, an average value of the

Fig. 3. The three candidate ANN topologies.

529

entire network is not desired since adaptation
should be in response to local network conditions.
The data rate can be determined by counting the
number of data packets arriving at the MAC layer
over a certain interval, be they forwarded by or
terminating at the node. Likewise, the number of
end-to-end ﬂows can be approximated by examining
the source and destination addresses in arriving IP
packet headers and counting each unique pair.
Clearly, node speed is the most diﬃcult to ascertain. Tickoo et al. [14] show that variations in reception energies for incoming packets can be used to
deduce relative node speed. However, in simulation
this technique requires complicated power models
and so we resort to averaging the node speed of each
neighbour maintained internally by the simulator.
3.3. Neural network learning
Traditionally, ANNs are a form of supervised
learning, utilizing ‘‘training’’ and ‘‘testing’’ datasets
in the learning process. Because the mobile environment is so variable, we do not provide any training
data. Instead we use the simulation to train itself.
On reception of an ARC packet by the destination
of the ﬂow, it measures the current average throughput, end-to-end delay, and jitter and feeds them
back to the source. The feedback can be conﬁgured
to be sent after the receipt of any number of packets. This feedback provides on-the-ﬂy data for the
ANNs to train and forms a feedback loop by which
the ARC source can detect conditions indicating
heavy congestion or a link-break. This loop causes
ARC to resemble TFRC in structure.
The quality of service (QoS) evaluation within the
ARC protocol is based on predicted throughput and
is regulated by predicted end-to-end delay and jitter.
Predictions are made by forward-propagating the
ANNs using a feed-forward algorithm [6]. If predicted throughput increases above the current
service rate, the transmission rate is increased to
the next rate-level provided the delay and jitter
bounds are not exceeded. Similarly, the transmission rate is decreased if predicted throughput drops
below the current level or above the delay or jitter
bounds. The bounds for delay and jitter are 25 ms
and 5 ms, respectively, such that jitter does not
reach noticeable levels for users. Finally, if the feedback delay exceeds ﬁve times the predicted delay
value, the protocol assumes that either a link-break
or heavy congestion exists and ceases transmission
until the feedback is re-detected.

530

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

The three ANNs maintained by the audio source
are tuned every 50 feedback packets using a backpropagation algorithm [6, Chapter 4]. The learning
rate a moderates the degree to which node-weights
are revised in each iteration of back-propagation.
The addition of momentum r to back-propagation
allows the ANN to avoid converging to small local
optima when the correct solution is a global optimum. We set a = 0.5 and r = 0.8 for ARC in all trials. If the bounded-iteration ANNs have not
reached an error percentage c = 0.0001% of the latest feedback in 50,000 iterations, back-propagation
ceases.
Symmetric with the ANNs of the source, the
destination sends feedback at every reception. If
the link-break/congestion bound is exceeded,
feedback is sent at each subsequent link-break
evaluation interval until a new data packet is
received.
4. Evaluation of ANN topologies in ARC
Before comparing ARC with other MANET
transport schemes, we ﬁrst determine which neural
network topology best approximates the responses
variables over the lifetime of the simulation.
4.1. Experimental set-up
We use the same simulation set-up as described
for the screening experiments in Section 2.2 with
the following changes:
• The simulation time is increased to 1500 s.
• We use the predictive measures to drive a 5-rate
scale for delivering CBR data. The rates are modelled on common quality levels for streaming
audio: 64 Kbps, 128 Kbps, 256 Kbps, 512 Kbps,
and 1 Mbps [15]. Each ﬂow starts sending CBR
data at the lowest rate.
• Nodes move at average speeds of 2, 5, and 10 m/s.
We conduct additional simulations with randomly varying speed (‘‘var’’ in ﬁgure legends).
In these simulations, nodes have average speed
of 6 m/s with independent variation of ±4 m/s.
This choice of node speeds is outside the
predictive region of the initial screening experiment. However, as we seek to demonstrate that
ANNs provide a robust and adaptive means of
approximating responses, we test their performance both inside and outside the predictive
region.

• In addition to the audio ﬂows, we establish eight
additional CBR ﬂows to provide background
traﬃc. Two background ﬂows are started at each
of times 0, 50, 100, and 150 s, with data rates
between 12.5 Kbps and 50 Kbps, and run until
the end of the simulation. This creates a highly
dynamic environment with variable levels of
background load during the simulations.
While ANNs are typically evaluated in terms of
predictive accuracy against a set of training conditions, our training uses an on-going feedback loop.
As such, we evaluate the accuracy of each of the
ANNs over the course of its run. Likewise, because
the predictive accuracies necessary for making good
decisions over the course of a transmission may not
need to be as high as those in typical machine learning trials we loosen the notion of successful prediction. While the relative error of the ANNs when
dealing with outputs of eight signiﬁcant ﬁgures
may be very high, most audio quality is evaluated
on the order of milliseconds. Thus we deﬁne the
predictive accuracy as how often a prediction is
within 1 ms of the actual response value expressed
as a percentage. In the case of accuracy in throughput predictions, we deﬁne a correct prediction as
one that is within 1 Kbps of the actual response.
We also measure the response variables of
throughput, end-to-end delay, and jitter (deﬁned
in Section 2.2) and two additional responses:
• Goodput: The number of packets successfully
received divided by the total number of packets
transmitted.
• Loss rate: The number of packets dropped before
reaching the receiver.
4.2. Accuracy of the ANN topologies
Fig. 4 shows that the two topologies with a
hidden neuron display similar accuracies. However,
the Interaction Nonlinear topology displays lower
variance; speciﬁcally, Interaction Nonlinear displays
a variance of ±4.59% and ±4.9% in delay and jitter
accuracies, respectively, versus ±8.43% and ±9.63%
for Simple Nonlinear. Interestingly, the strictly linear topology is more accurate at predicting jitter,
but is far less accurate with respect to delay and
throughput.
While predictive accuracy is a useful metric for
determining which topology to use, improving
network performance is our chief aim. Figs. 5 and

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

a 80

Linear ANN
Simple Nonlinear
Interaction Nonlinear

70

60

Percentage Accuracy

Percentage Accuracy

Linear ANN
Simple Nonlinear
Interaction Nonlinear

70

60
50
40
30

50
40
30

20

20

10

10

0

ARC Variants: Compared Jitter Accuracy Percentage

b 80

ARC Variants: Compared Delay Accuracy Percentage

531

2

5

10

0

var

c

2

5

10

var

Node speed in m/s

Node speed in m/s

ARC Variants: Compared Throughput Accuracy Percentage

100
90

Percentage Accuracy

80

Linear ANN
Simple Nonlinear

70

Interaction Nonlinear

60
50
40
30
20
10
0

2

5

10

var

Node speed in m/s

Fig. 4. Accuracy in (a) delay, (b) jitter and (c) throughput.

6 show that the end-to-end delay, loss rate, and
goodput for the three topologies are essentially
equal. Interestingly, Fig. 7 indicates that while the
Simple Linear topology predicts jitter more accuARC Varients: Compared End- To - End Delay
Linear AAN

0.045

Simple Nonlinear

0.04

Interection Nonlinear

Delay in s

0.035
0.03

rately, its average jitter is no lower than either of
the nonlinear topologies.
The greatest diﬀerence between the three topologies lies in average throughput. As Fig. 7 shows, the
Interaction Nonlinear topology outperforms other
topologies at 2 m/s and 5 m/s while remaining competitive with the other topologies at 10 m/s.
As a result, we select the Interaction Nonlinear
ANN topology to control transmission rate in the
ARC protocol. We compare it to existing transport
protocols next.

0.025

5. Evaluation of ARC with other media-streaming
protocols

0.02
0.015
0.01
0.005
0

2

5

10

var

Node speed in m/s

Fig. 5. End-to-end delay of each ANN topology.

In order to evaluate the eﬀectiveness of ARC, we
evaluate both traditional network performance metrics and audio speciﬁc metrics. The network performance metrics we measure are deﬁned in Sections
2.2 and 4.1.

532

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

a

ARC Variants: Compared Loss

0.5
0.45

ARC Variants: Compared Goodput

b 1.4

Linear ANN
Simple Nonlinear
Interaction Nonlinear

Linear ANN
Simple Nonlinear
Interaction Nonlinear

1.2

Goodput percentage/100

Loss percentage/100

0.4
0.35
0.3
0.25
0.2
0.15

1

0.8

0.6

0.4

0.1
0.2
0.05
0

2

5

10

0

var

2

5

Node speed in m/s

10

var

Node speed in m/s

Fig. 6. (a) Packet loss and (b) goodput of each ANN topology.

a 1.5

ARC Variants: Compared Arrival Jitter

ARC Variants: Compared Average Throughput

b 16

Linear ANN
Simple Nonlinear
Interaction Nonlinear

Linear ANN
Simple Nonlinear
Interaction Nonlinear

14

Throughput in kbps

Arrival Jitter in s

12
1

0.5

10
8
6
4
2

0

2

5

10

var

Node speed in m/s

0
2

5

10

var

Node speed in m/s

Fig. 7. (a) Jitter and (b) throughput of each ANN topology.

To measure the quality of the audio, we stream a
speech sample logging both what is transmitted and
received. These two audio streams are compared
using the metrics and methodology outlined by Rein
et al. [16], which provides a set of objective measures
for speech quality and their rates of correlation to
subjective mean opinion scores (MOSs). We measure
both segmental and signal-to-noise (SNR) ratio, root
mean square (RMS), and Itakura–Saito spectral distances, as well as three classes of parametric distance:
log area ratio, energy ratio, log likelihood, and linear
predictive coding (LPC) cepstral (sic) distance.
5.1. Results of performance metrics
We compare the performance of ARC against
the user datagram protocol (UDP) [17], the real-time
transport protocol (RTP) [18], and the TCP friendly

rate control (TFRC) [1]. UDP transmits packets at a
constant rate without regard to network conditions;
it has no acknowledgment scheme and represents
the most naive approach for audio streaming.
RTP is designed for media streaming, and includes
protection against out-of-order delivery and
decreased sensitivity to loss, but provides no control
for QoS. While RTP is typically paired with a QoS
control scheme, our experimentation makes no such
pairing. Though RTP without a control scheme is
much like UDP, we ﬁnd its performance to be diﬀerent enough to warrant discussion.
TFRC is typically used in a transport protocol.
Our implementation uses TCP, which has an
acknowledgment scheme and uses a throughput
equation to adapt its transmission rate. Our comparison uses a variant of TFRC that classiﬁes the
transmission rate into the ﬁve levels used by ARC.

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

That is, the rate is set to the least rate greater than
that determined by the native mechanism of TFRC.
Experimental results for ARC show signiﬁcant
improvements in network performance. As Figs. 8
and 9 show, the loss rate of ARC is reduced 70–
90% and its goodput is between 75% and 83%
higher than all protocols in the comparison. ARC
achieves competitive measures of delay and jitter,
while typically increasing throughput. Fig. 10 shows
the similarity in latency for all compared protocols.
While the throughput of ARC is lower than TFRC,
the decreases in loss rate are so dramatic as to oﬀset
this measure.
Of all the protocols compared, it is not surprising
that UDP performs the worst; streaming audio via
UDP is a poor choice for a mobile network. The
ﬁxed rate and connectionless nature of UDP

Average Loss Percentage

533

streaming ensures that packet losses are extremely
high, occasionally reaching 95% of the total number
of packets transmitted. Fig. 8 shows ARC, at less
than 20% loss, is a marked improvement over
UDP at all speeds.
While RTP is designed for streaming media, it is
insuﬃcient in its base form for such tasks. Given the
non-adaptive nature of base RTP implementations,
the results for average throughput, packet loss, and
end-to-end delay are very similar to UDP. As with
UDP, the performance of RTP is inferior to ARC,
particularly in networks in which average node
speed is less than 10 m/s. Notably, jitter in RTP is
signiﬁcantly smaller than UDP at higher speeds.
Fig. 10 shows that end-to-end delay and jitter for
TFRC are comparable with ARC. TFRC does outperform ARC in terms of raw average throughput.
However, as illustrated in Figs. 8 and 9 the loss rate
and goodput are far inferior to ARC. This impacts
the audio quality metrics, as we see next.

1.2
ARC

5.2. Results of audio quality metrics

TFRC

1

RTP

For comparisons in audio quality, each protocol
transmits a 16 kHz mono sample of the original
BBC radio broadcast of The Hitchhiker’s Guide to
the Galaxy [19]. This sample is mainly speech and
approximately thirty minutes in length, allowing
us to examine speech quality over the lifetime of
the simulation.
Comparisons of audio quality at selected speeds
ﬁnd ARC transmissions to be far more clear than
any of the competing protocols. This is likely due
to the decreased loss rate and high goodput ARC

0.8

0.6

0.4

0.2

0

2

5

10

var

Node speed in m/s

Fig. 8. Loss rate for each transport protocol.

a

b 1.4

Average Throughput
40
ARC
TFRC
UDP
RTP

35

Average Goodput

1.2
ARC

Goodput percentage/100

30

Throughput in kbps

Loss percentage/100

UDP

25
20
15
10

UDP
RTP

0.8

0.6

0.4

0.2

5
0

TFRC

1

0
2

5

10

Node speed in m/s

var

2

5

10

Node speed in m/s

Fig. 9. (a) Throughput and (b) goodput of each transport protocol.

var

534

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

a

Average End-to-End Delay

Average Arrival Jitter

b

0.18

ARC
TFRC
UDP
RTP

0.16
1

ARC

0.14

TFRC

Delay in s

RTP

0.1
0.08
0.06

Arrival Jitter in s

UDP

0.12

0.8

0.6

0.4

0.04
0.2
0.02
0

0
2

5

10

var

2

Node Speed in m/s

5

10

var

Node Speed in m/s

Fig. 10. (a) Delay and (b) jitter of each transport protocol.

Table 4
Signal-to-noise and spectral distance measures

Table 5
Parametric distance measures

Protocol

log10
Segmental
SNR

log10
SNR

Itakura–Saito

RMS
spectral

ARC 2 m/s
TFRC 2 m/s
UDP 2 m/s
RTP 2 m/s

6.33
2.34
0.54
1.02

2.96
1.92
0.33
0.52

6.74
46.58
46.51
55.81

0.03
0.18
0.11
0.2

ARC 5 m/s
TFRC 5 m/s
UDP 5 m/s
RTP 5 m/s

6.63
0
0.63
1.24

2.97
0
0.34
0.79

8.58
61.86
45.71
56.21

0.03
0.22
0.11
0.21

ARC 10 m/s
TFRC 10 m/s
UDP 10 m/s
RTP 10 m/s

4.29
2.03
0.91
0

2.17
0.99
0.73
0

12.27
48.38
43.81
11.3

0.03
0.26
0.1
0.24

achieves. As Table 4 shows, ARC minimizes all
SNR and spectral distance measures, with the
exception of the Itakura–Saito distance at 10 ms;
these metrics measure the distortion in frequency
amplitudes. The minimum values are highlighted
in bold in the table.
Table 5 shows that ARC minimizes all parametric distance measures, with the exception of the likelihood ratio at 2 m/s. In particular, the LPC cepstral
distance is minimized; this corresponds very highly
to perceived voice quality [20]. Since the ns-2 simulator does not introduce bit error in its transmissions, all errors in the audio streams are due to
packet loss. The result is that the received streams
frequently ‘‘skip’’ and sound ‘‘choppy.’’
In summary, ARC achieves signiﬁcantly lower
packet loss and higher goodput than TFRC,

Protocol

Energy
ratio

Log
likelihood

Log
area

LPC
cepstral

ARC 2 m/s
TFRC 2 m/s
UDP 2 m/s
RTP 2 m/s

1.44
46.58
2.34
2.39

13.42
0.18
32.4
32.64

0.39
2.18
1.34
2.42

0.38
2.21
1.5
2.53

ARC 5 m/s
TFRC 5 m/s
UDP 5 m/s
RTP 5 m/s

1.48
2.53
2.32
2.38

14.1
35.59
31.93
32.48

0.39
2.54
1.27
2.53

0.38
2.76
1.41
2.65

ARC 10 m/s
TFRC 10 m/s
UDP 10 m/s
RTP 10 m/s

1.6
2.23
2.27
1.86

16.88
29.35
30.8
24.62

0.4
3.23
1.19
2.49

0.41
3.28
1.3
4.03

UDP, and RTP while maintaining competitive
end-to-end delay and jitter. The adaptive ratescaling employed by ARC consistently produces
higher throughput than ﬁxed rate protocols, while
maintaining greater than 90% goodput. This high
goodput is likely responsible for the higher quality
audio transmissions of ARC. ARC minimizes both
frequency amplitude distortions and parametric
distances, implying higher perceived audio quality.
Of course, since TFRC obtains higher average
throughput, it transmits more audio, but its quality
is much lower.
6. Convergence, stability, and robustness
More factors could be considered in the screening
experiments and in the design of ARC. Yet, with

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

increased speciﬁcity in a regression model comes a
decrease in its ability to approximate responses
under diﬀerent conditions [4], thus decreasing the
robustness of the model. Likewise, there may be
concern as to the accuracy of the model outside
the region in which the screening experiments were
conducted. However, by using the ANNs to approximate the functions continuously, the predictive
validity of the original model relies only on the continued signiﬁcances of the factors involved. As such
the predictive accuracy of the model remains intact
in the experimental region considered.
Questions about the stability and convergence of
the ARC protocol remain. The answers depend on
the stability and convergence of the embedded
ANNs. Hornik et al. showed that ANNs with a
one or more hidden layers are universal approximators, and will converge [10]. Given the dynamic nature of a MANET conditions change quickly and the
ANNs must re-converge to new solutions. Thus, the
stability of any given ANN depends on the size of
ﬂuctuations in the measured value the ANN is using
to tune itself. This is a matter of error measurement.
If an absolute measure of error is used, ANNs
approximating small-valued measures (such as
jitter) require more tuning over time and are less
stable. On the other hand, ANNs approximating
large-valued measures (such as throughput) converge quickly and must tune much less frequently.
We ﬁnd ARC to be robust and stable in the
experimental scenarios considered.
7. Related work
The work on media streaming in wired domains
is extensive and long-standing, and includes scalable, adaptive solutions. Banerjee et al. [21] examined overlay protocols for adaptive streaming.
Protocols such as TCP-Friendly Streaming Protocol
[1] and the combination of Real-Time Streaming
Protocol and its transport mechanism RTP [18]
provide a consistent framework for media streaming
under a variety of conditions.
While no deﬁnitive solutions for media streaming
in MANETs exist, much work has been done. Kim
et al. [22] examine factors that impact VoIP service
in MANETs and suggest a routing protocol may be
most important in very small MANETs. Toh et al.
[23] investigate the eﬀects of multi-hop wireless links
on audio quality ﬁnding that packet loss and jitter
have the greatest eﬀect on audio quality. Benaissa

535

et al. [24] examine MANET factors aﬀecting delay
and playout jitter focussing on the eﬀect of routing
protocol and audio codec choices. Kazantzidis [25]
focusses on adaptive mechanisms for multimedia
transmission at the MAC layer, ﬁnding improvements in both transport-layer performance and
scalability. Mao et al. [26] proposed a transportlayer modiﬁcation of RTP for mobile networks,
MRTP, that centers on the concept of path diversity. TFRC has been the focus of multiple inquiries
into audio streaming in MANETs, with Velev et al.
[27] observing improvements in video transmissions
under the protocol. Fu et al. [28] propose ADTFRC
using a multi-metric approach to TFRC’s rate control. While TFRC appears to be a promising protocol for media streaming in MANETs, Chen and
Nahrstedt [3] ﬁnd that there remain signiﬁcant
shortcomings in its adaptation and throughput prediction equation in mobile networks.
Statistical design of experiments is outlined in
detail in Montgomery [4]. Statistically designed
experiments have been used to characterize and
optimize systems since the 1920s. There have been
extensive applications of designed experiments in
ﬁelds as diverse as agricultural ﬁeld trials and design
of mechanical systems. Designed experiments have
been widely used to study simulation models of
systems in situations where direct experimentation
with the system is inconvenient or impossible.
For examples and discussion, see Myers et al. [29],
Hood and Welch [30], and Myers and Montgomery
[31].
More recently in the domain of MANETs, Perkins et al. [32] study the impact of the factors of node
speed, pause time, network size, number of traﬃc
sources, and routing protocol on average throughput, routing overhead, and power consumption.
The conclusion is that number of traﬃc sources
has the most impact followed by network size and
then node speed. Barrett et al. [33] study whether
routing and MAC protocols interact with each other
in a signiﬁcant way under diﬀerent network loads
and node mobility models. Based on the ANOVA
no single combination of routing and MAC protocol
was found to dominate other combinations over all
mobility models. Vadde and Syrotiuk [34] used similar techniques to study the impact of QoS architectures, routing protocols, and MAC protocols on
service delivery in MANETs.
ANNs are among the oldest techniques in
machine learning, with initial study into their

536

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

eﬀectiveness dating to Minksy and Papert [35] in the
late 1960s. ANNs are a robust means of
approximating real-valued target functions [6].
Beginning with Werbos [36] in 1974, the ﬁeld of
ANNs developed into a rich set of learning mechanisms well-suited to solving complex real-valued
systems. Further work in the 1980s, including that
of Cybenko [5], clariﬁed the situations in which
ANNs are eﬀective, as well as the abilities of various
neuron constructions.
Within MANETs, machine learning has been
used for adaptation. Faragó et al. [37] and Benaissa
et al. [38] have examined potential applications for
medium access control and the transport of voice,
respectively. Dowling et al. [39] have applied reinforcement learning and some elements of ant colony
optimization to multi-hop routing in MANETs.
Similarly, Chang et al. [40] have applied a type of
reinforcement learning, Q-learning, to MANET
routing. Additionally, Colagrosso has applied
Bayesian classiﬁers to MANET broadcasting, targeting both packet construction and rebroadcasting
[41,42].
8. Conclusions and future work
Using design of experiments we have quantiﬁed
factors and interactions that signiﬁcantly aﬀect the
throughput, end-to-end delay, and jitter of audio
streams in MANETs. The ARC transport protocol
was introduced utilizing a trio of ANNs to continuously approximate the functions describing the
response surfaces. These ANNs are used by ARC
to adapt the transmission rate to changing network
conditions.
Examining the performance of three ANN topologies, we ﬁnd the best predictive accuracy appears
to occur when the ANNs include the main eﬀects
and interaction terms as input and have a hidden
layer. This suggests that while our factor study highlights some key factors and interactions, the true
models for the responses likely contain either more
factors or at least some nonlinear elements.
Compared to UDP, RTP without a control protocol, and a discrete variant of TFRC, ARC
achieves signiﬁcant reductions in packet loss and
increased goodput while satisfying the requirements
of end-to-end delay and jitter. While the average
throughput of ARC is consistently less than that of
TFRC, its average goodput is much higher. This is
likely the reason that ARC transmits higher quality
audio than the other protocols examined. ARC min-

imizes RMS and Itakura–Saito spectral distances, as
well as several parametric distance measures in most
of the scenarios considered. In particular, ARC minimizes LPC cepstral distance, which closely correlates to subjective audio measures.
While the performance of ARC is encouraging,
there remains much to be examined in machine
learning-driven adaptation mechanisms for mobile
networks. Future work with ARC may include:
larger screening experiments and the use of nonlinear modelling; an analysis of fairness for competing
ARC ﬂows; how to enable all nodes in a ﬂow with
ANNs rather than just the source and destination,
and the propagation of intelligent mechanisms to
multiple layers of the network stack.
Acknowledgements
We thank the anonymous referees for their valuable suggestions that have greatly improved our
paper – speciﬁcally, to explore ANNs with diﬀerent
topologies, and to compare the quality of the transported audio. We are also grateful to Sergio Palazzo, Giacomo Morabito, and Laura Galluccio of the
University of Catania for helpful discussions.
The research of V.R. Syrotiuk is supported in
part by National Science Foundation grant ANI0240524. Any opinions, ﬁndings, conclusions or
recommendations expressed in this paper are those
of the authors and do not necessarily reﬂect the
views of NSF.
References
[1] M. Handley, S. Floyd, J. Padhye, J. Widmer, TCP friendly
rate control (TFRC): Protocol speciﬁcation, RFC 3448,
January 2003.
[2] J. Padhye, V. Firoiu, D. Towsley, J. Kurose, Modeling TCP
throughput: a simple model and its empirical validation, in:
Proceedings of the ACM Conference on Applications,
Technologies, Architectures, and Protocols for Computer
Communication (SIGCOMM’98), 1998, pp. 303–314.
[3] K. Chen, K. Nahrstedt, Limitations of equation-based
congestion control in mobile ad hoc networks, in: Proceedings of the 24th International Conference on Distributed
Computing Systems Workshops (ICDCSW’04), 2004, pp.
756–761.
[4] D.C. Montgomery, Design and Analysis of Experiments,
sixth ed., John Wiley and Sons, Inc., 2005.
[5] G. Cybenko, Approximation by superpositions of a sigmoidal function, Mathematics of Control, Signals, and Systems
2 (1989) 303–314.
[6] T. Mitchell, Machine Learning, WBC/McGraw-Hill, 1997.
[7] C.E. Perkins, E.M. Royer, Ad hoc on-demand distance
vector routing, in: Proceedings of the 2nd IEEE Workshop

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538

[8]

[9]

[10]

[11]

[12]
[13]
[14]

[15]

[16]

[17]
[18]

[19]
[20]

[21]

[22]

[23]

[24]

[25]

[26]

on Mobile Computing Systems and Applications, 1999, pp.
90–100.
D.B. Johnson, Routing in ad hoc networks of mobile hosts,
in: Proceedings of the Workshop on Mobile Computing
Systems and Applications, 1994, pp. 158–163.
W. Navidi, T. Camp, Stationary distributions for the
random waypoint mobility model, IEEE Transactions on
Mobile Computing 3 (1) (2004) 99–108.
K. Hornik, M. Stinchcombe, H. White, Multilayer feedforward networks are universal approximators, Neural Networks 2 (1989) 359–366.
V. Maniezzo, Genetic evolution of the topology and weight
distribution of neural networks, IEEE Transactions on
Neural Networks 5 (1994) 39–53.
X. Yao, Evolving artiﬁcial neural networks, Proceedings of
the IEEE 87 (1999) 1423–1447.
D. Bates, D. Watts, Nonlinear Regression Analysis and Its
Applications, John Wiley and Sons, Inc., 1988.
O. Tickoo, S. Raghunath, S. Kalyanaraman, Route fragility:
a novel metric for route selection in mobile ad hoc networks,
in: Proceedings of the IEEE International Conference on
Networks (ICON’03), 2003, pp. 537–542.
Moving Picture Experts Group, Short MPEG-2 description. <http://www.chiariglione.org/mpeg/standards/mpeg-2/
mpeg-2.htm>.
S. Rein, F. Fitzek, M. Reisslein, Voice quality evaluation
for wireless packet voice: a tutorial and performance results
for ROHC, IEEE Wireless Communications 12 (2005)
60–76.
J. Postel, User Datagram Protocol, RFC 768, August 1980.
H. Schulzrinne, S.L. Casner, R. Frederick, V. Jacobson,
RTP: a transport protocol for real-time applications, RFC
3550, July 2003.
D. Adams, The Hitchhiker’s Guide to the Galaxy, BBC
Radio 4, Fit #1, March 1978.
S. Wu, L. Pols, A distance measure for objective quality
evaluation of speech communication channels using also
dynamic spectral features, in: Proceedings of the Institute of
Phonetic Science Amsterdam, vol. 20, 1996, pp. 27–42.
S. Banerjee, S. Lee, R. Braud, B. Bhattacharjee, A. Srinivasan, Scalable resilient media streaming, in: International
Workshop on Network and Operating System Support for
Digital Audio and Video (NOSSDAV’04), 2004, pp. 4–9.
J. Kim, D. Choi, J. Park, Y.-K. Kim, I. Chong, H.-K.
Kahng, Performance of voice traﬃc over mobile ad hoc
networks, in: The International Conference on Information
Networking (ICOIN’04), 2004, pp. 241–248.
C.-K. Toh, W.K. Tsai, V.O.K. Li, G. Guichal, Transporting
audio over wireless ad hoc networks: experiments and new
insights, in: IEEE International Symposium on Personal,
Indoor and Mobile Radio Communications (PIMRC’03),
2003, pp. 772–777.
M. Benaissa, V. Lecuire, F. Lepage, A. Schaﬀ, Analysing
end-to-end delay and loss in mobile ad hoc networks for
interactive audio applications, in: Workshop on Mobile Ad
Hoc Networking and Computing (MADNET’03), 2003, pp.
27–33.
M.I. Kazantzidis, MAC intelligence for adaptive multimedia
in 802.11 networks, IEEE Journal on Selected Areas in
Communications 23 (2005) 357–368.
S. Mao, D. Bushmitch, S. Narayanan, S.S. Panwar, MRTP:
a multi-ﬂow realtime transport protocol for ad hoc net-

[27]

[28]

[29]

[30]

[31]
[32]

[33]

[34]

[35]
[36]

[37]

[38]

[39]

[40]

[41]

[42]

537

works, in: Proceedings of the IEEE Semiannual Vehicular
Technology Conference (VTC’03-Fall), 2003, pp. 2629–2634.
G. Velev, R. Hakenberg, J. Rey, M. Zink, TCP-friendly
streaming in next generation wireless networks, in: Proceedings of the Consumer Communications and Networking
Conference (CCNC’05), 2005, pp. 181–186.
Z. Fu, X. Meng, S. Lu, A transport protocol for supporting
multimedia streaming in mobile ad hoc networks, IEEE
Journal on Selected Areas in Communications 21 (2003)
1615–1626.
R.H. Myers, A.J. Khuri, W.H. Carter, Response surface
methodology: 1966–1988, Technometrics 31 (1989) 137–
157.
S.J. Hood, P.D. Welch, Response surface methodology and
its application in simulation, in: Proceedings of the Winter
Simulation Conference, 1993, pp. 115–122.
R.H. Myers, D.C. Montgomery, Response Surface Methodology, John Wiley and Sons, Inc., 2002.
D.D. Perkins, H.D. Hughes, C.B. Owen, Factors aﬀecting
the performance of ad hoc networks, in: Proceedings of the
IEEE International Conference on Communications
(ICC’02), vol. 4, 2002, pp. 2048–2052.
C.L. Barrett, A. Marathe, M.V. Marathe, M. Drozda,
Characterizing the interaction between routing and MAC
protocols in ad-hoc networks, in: Proceedings of the Third
ACM International Symposium on Mobile Ad Hoc
Networking and Computing (MobiHoc’02), 2002, pp. 92–103.
K.K. Vadde, V.R. Syrotiuk, Factor interaction on service
delivery in mobile ad hoc networks, IEEE Journal on
Selected Areas in Communications 22 (2004) 1335–1346.
M. Minsky, S. Papert, Perceptrons, MIT Press, 1969.
P. Werbos, Beyond regression: new tools for prediction and
analysis in the behavioral sciences, Ph.D. thesis, Harvard
University, 1974.
A. Faragó, A.D. Myers, V.R. Syrotiuk, G.V. Zàruba, MetaMAC protocols: Automatic combination of MAC protocols
to optimize performance for unknown conditions, IEEE
Journal on Selected Areas in Communication 18 (2000)
1670–1681.
M. Benaissa, V. Lecuire, D.W. McClary, V.R. Syrotiuk,
ANOVA-informed decision trees for voice applications over
MANETs, in: Proceedings of the 6th IEEE International
Conference on Mobile and Wireless Communication Networks, (MWCN’04), 2004, pp. 143–154.
J. Dowling, E. Curran, R. Cunningham, V. Cahill, Using
feedback in collaborative reinforcement learning to adaptively optimise MANET routing, IEEE Transactions on
Systems, Man and Cybernetics (Part A), Special Issue on
Engineering Self-Orangized Distributed Systems 35 (2005)
360–372.
Y.-H., T. Ho, L.P. Kaelbling, Mobilized ad-hoc networks: a
reinforcement learning approach, in: Proceedings of the
IEEE International Conference on Autonomic Computing
(ICAC’04), 2004, pp. 240–247.
M.D. Colagrosso, A classiﬁcation approach to broadcasting
in mobile ad hoc network, in: Proceedings of the 2005 IEEE
Conference on Communications (ICC’05), vol. 2, 2005, pp.
1112–1117.
M.D. Colagrosso, Intelligent broadcasting in mobile ad hoc
networks: three classes of adaptive protocols, EURASIP
Journal on Wireless Communications and Networking 2007
(2007), Article ID 10216.

538

D.W. McClary et al. / Ad Hoc Networks 6 (2008) 524–538
Daniel W. McClary completed his M.S.
in Computer Science at Arizona State
University in 2004. He is currently
completing his Ph.D. studies at Arizona
State University. His research focuses on
adaptation and adaptive optimization in
mobile ad hoc networks. Principally, the
work considers both machine learning
and statistical analysis techniques as a
basis for adaptive optimization in any
system.

Violet R. Syrotiuk earned her Ph.D. in
Computer Science from the University of
Waterloo (Canada) in 1992. She joined
Arizona State University in 2002 and is
currently an Associate Professor of
Computer Science and Engineering. Her
research is currently supported by three
grants from NSF, and a contract with
Los Alamos National Laboratories, and
Defence Science and Technology Organisation in Australia. She serves on the
Editorial Board of Computer Networks, and on the Technical

Program Committee of several major conferences including
MobiCom and Infocom. Her research interests include mobile ad
hoc and sensor networks, in particular MAC protocols with an
emphasis on adaptation,topology-transparency, and energy eﬃciency, dynamic spectrum utilization, mobile network models,and
protocol interaction and cross-layer design. She is a member of
the ACM and the IEEE.

Vincent Lecuire received his Ph.D. in
Computer Science from the University of
Nancy (France) in 1994. He is currently
Associate Professor at the Department
of Networks and Telecommunications,
University of Nancy, and member of the
research center for automatic control
(CRAN), CNRS. His current research
topics concern adaptive error and ﬂow
controls for image based applications
over large-scale IP networks, mobile ad
hoc networks and wireless sensor networks.

INTERNATIONAL JOURNAL OF COMMUNICATION SYSTEMS
Int. J. Commun. Syst. 2009; 22:419–439
Published online 13 November 2008 in Wiley InterScience (www.interscience.wiley.com). DOI: 10.1002/dac.975

An opportunistic cross-layer architecture for voice in multi-hop
wireless LANs
Suhaib A. Obeidat and Violet R. Syrotiuk∗, †
Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85287-8809, U.S.A.

SUMMARY
We propose an opportunistic cross-layer architecture for adaptive support of Voice over IP in multi-hop
wireless LANs. As opposed to providing high call quality, we target emergencies where it is important
to communicate, even if at low quality, no matter the harshness of the network conditions.
With the importance of delay on voice quality in mind, we select adaptation parameters that control the
ratio of real-time traffic load to available bandwidth. This is achieved in two ways: minimizing the load
and maximizing the bandwidth. The PHY/MAC interaction improves the use of the spectral resources by
opportunistically exploiting rate-control and packet bursts, while the MAC/application interaction controls
the demand per source through voice compression. The objective is to maximize the number of calls
admitted that satisfy the end-to-end delay budget.
The performance of the protocol is studied extensively in the ns-2 network simulator. Results indicate
that call quality degrades as load increases and overlonger paths, and a larger packet size improves
performance. For long paths having low-quality channels, forward error correction, header compression,
and relaxing the delay budget of the system are required to maintain call admission and quality. The
proposed adaptive protocol achieves high performance improvements over the traditional, non-adaptive
approach. Copyright q 2008 John Wiley & Sons, Ltd.
Received 31 January 2008; Revised 3 July 2008; Accepted 9 September 2008
KEY WORDS:

simulation; cross-layer; opportunistic; QoS

1. INTRODUCTION
The integration of voice and data networks is driving the emergence of new applications. A single
hand-held device may be used for voice communication, as an on-demand-video player, and as a
personal digital assistant. Such varied services must be provided irrespective of the nature of the

∗ Correspondence

to: Violet R. Syrotiuk, Department of Computer Science and Engineering, Arizona State University,
P.O. Box 878809, Tempe, AZ 85287-8809, U.S.A.
†
E-mail: syrotiuk@asu.edu

Copyright q

2008 John Wiley & Sons, Ltd.

420

Quality Impairment Percentage

S. A. OBEIDAT AND V. R. SYROTIUK

55

8 kbps
6.3 kbps

50
45
40
35
30
25
20
15
10

0

2

4

6

8

10

12

14

16

Packet Loss Ratio

Figure 1. Effect of packet loss on quality for two voice coders.

network. Due to its ubiquity, the application of voice in wireless networks has received significant
attention. While many studies examine voice over IP (VoIP) over wireless LANs, wireless local
loops, and cellular networks (see, as examples, [1–4]), few focus on packet voice over multi-hop
wireless or ad hoc networks.
In general, stateless and stateful approaches exist for supporting delay-sensitive, real-time traffic.
In a stateful approach, the network is designed with quality of service (QoS) requirements in
mind. Information about the state, e.g. bandwidth requirements, is exchanged and maintained
among network nodes. A stateless approach requires the application to be elastic to survive under
conditions when the network resources are scarce or when the traffic load is high. In a highly
dynamic and resource-constrained network such as an ad hoc network, stateless approaches to
supporting QoS are more effective [5, 6].
Since voice has stringent delay requirements and violating these requirements can impact quality
significantly [7], the availability of bandwidth can limit the impact of delay [8]. Bandwidth of
a wireless channel, however, is controlled by regulatory agencies, which means it cannot be
increased arbitrarily. Maximizing the spectral efficiency of the available bandwidth, by using
adaptive modulation, can help in increasing the bandwidth applications experience. After getting
the most out of the channel, one can limit the need for bandwidth by minimizing the real-time
load injected into the network by using voice compression.
The use of voice compression introduces trade-offs in designing an adaptive algorithm. As a
general trend, the higher the compression level used, the larger the effect on voice quality. The
ITU-T impairment factor (Ie) is a percentage value that characterizes the effect of coding on
quality. The higher the Ie, the higher the impact on perceived quality [9]. Figure 1, which is based
on values from ITU-T standards [10], shows this relation for two example coders.
The figure also shows another important trend: for a fixed packet size, the higher the compression
used, the higher the impact of loss on perceived quality due to the loss of more voice frames. For
example, a 200 byte packet using a 32 kbps compression scheme carries 50 ms of speech while for
an 8 kbps compression scheme it carries 200 ms of speech.
In addition to the general impact on quality and increased susceptibility to packet loss, compression introduces another trade-off involving delay. The higher the compression level, the longer the
packetization delay introduced. Figure 2 shows the relation between packetization delay and voice
coder for three packet sizes. As a general trend, with the increase in compression, larger packet
sizes result in a substantial increase in packetization delay.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

Packetization Delay in ms

350

421

Packet Size = 50
Packet Size = 100
Packet Size = 200

300
250
200
150
100
50
0

0

10

20

30

40

50

60

70

Coding Rate in kbps

Figure 2. Effect of packet size on packetization delay for different compression rates.

Taking these factors into consideration, we propose an opportunistic cross-layer architecture
for voice over ad hoc wireless LANs, which adapts the parameters of voice compression and
modulation based on the feedback of the channel conditions at the next-hop receiver. Our objective
is to maximize the number of calls admitted that satisfy the end-to-end (E2E) delay budget.
To provide consistent voice quality, during times when the channel quality is good we use high
voice compression limiting the bandwidth needs of a call. When the channel quality degrades, we
decrease the compression ratio used to avoid losing packets with a large payload. It may seem
counter-intuitive to decrease the compression ratio (i.e. increase the data rate) during poor channel
conditions. However, there is more redundancy in packets transmitted at a lower compression
ratio.
When the quality of the channel is good, we use dense-constellation modulation to increase the
spectral bandwidth. When deep fading conditions are experienced, a sparse modulation scheme
is used. Since the modulation scheme used in the physical layer affects parameters at the MAC
layer, the MAC protocol cannot be oblivious to changes in modulation used at the physical layer.
The paper makes the following contributions:
• A cross-layer architecture for voice support over ad hoc networks, which combines the use
of modulation and compression. Unlike most cross-layer designs, which involve two adjacent
layers of the protocol stack, ours considers three layers: PHY, MAC, and application.
• A high-fidelity simulation model that makes it easy for future studies to adopt to produce more
accurate results. This includes simulation of both end-point parameters such as packetization
delay and network parameters such as physical-layer details. Many of these parameters are
often neglected rendering results questionable.
• Showing the importance of packet size as an adaptation parameter, which is usually chosen
as a fixed value that trades one quality aspect for another.
The remainder of this paper is organized as follows. Section 2 overviews related work. Section 3
provides background on packet voice, QoS requirements for voice, modulation, and fading models;
this section can be skipped by those familiar with these concepts. Section 4 presents the system
architecture and describes the proposed opportunistic cross-layer protocol in detail. Section 5
describes the models and parameters used in the simulations while Section 6 presents the simulation
results. Finally, we conclude in Section 7.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

422

S. A. OBEIDAT AND V. R. SYROTIUK

2. RELATED WORK
Adaptive modulation and adaptive compression have been applied separately in VoIP-based
networks (wireless and wired). Barberis et al. [12] propose an adaptive compression scheme
for VoIP that reacts well to network congestion and therefore supports a larger number of
calls. Shenker [13] studies several approaches to adaptation. Rate-adaptive schemes are found
to out-perform delay-adaptive ones, i.e. those that change their delay requirements over time.
Adaptive modulation has also been studied extensively and applied in cellular, wireless LANs and
wireless ad hoc networks (see, as examples, [14, 15]).
Supporting packet voice over IEEE 802.11 has been investigated for both the distributed and
the point coordination functions (DCF and PCF, respectively); however, the performance is very
poor [16, 17]. The DCF was not designed to support QoS because it uses a contention-based
approach with randomized binary exponential back-off. This motivated work on an enhanced DCF
(EDCF) [18], which addresses service prioritization by shortening inter-frame spaces and having
the upper bound on the contention window depend on the priority class [19]. Wietholter et al. [20]
find that EDCF can support more calls when contention-free bursting is used, i.e. where multiple
back-to-back packets are transmitted after a single handshake.
Specialized schemes that focus on voice support over ad hoc networks have also been proposed.
A modification of IEEE 802.11 is proposed in [4] in which the cyclic redundancy codes are computed
only over those parts of the voice frame that have a high impact on the perceived quality and are
necessary for reconstruction rather than over the entire frame. In this way, less bandwidth is wasted
in retransmission and less delay is introduced. The approach improves the performance of the
network and also the perceived voice quality. The protocol requires the MAC layer to be aware of
application-layer details (i.e. the structure of a voice packet) compromising the layered architecture.
Sobrinho and Krishnikumar [21] propose a distributed multiple access protocol for voice. Voice
nodes compete for the channel by transmitting black bursts or pulses of energy. The length of a
black burst is proportional to the time a node has been waiting to transmit. After sending its black
burst, a node senses the channel. If it is idle then the node has been waiting the longest and is
granted access to the channel to transmit its packet. This protocol wastes a considerable amount
of bandwidth for channel access [22].
In Dong et al. [3], the use of new speech coding techniques for supporting voice over ad hoc
networks is proposed. One such technique is multiple description coding. It involves creating
more than one bit stream from the source signal. Each independent stream represents a coarse
description of the transmitted signal. If more than one description is received, a refined signal
is reconstructed. Another technique is scalable speech coding, which consists of sending a base
stream at a minimum rate and one or more enhancement streams. Since these coding schemes are
still under research, the study has no experiments to quantify the performance or to determine
which approach is more significant and how significant.
Chen et al. [2] propose an adaptive model for audio streaming over ad hoc networks. Feedback
about the delay and loss is periodically communicated from the audio client to the audio server.
Based on this feedback the server changes the compression rate. When the network conditions are
extremely severe, the server switches to a mode in which voice recognition is used at the sender,
i.e. the words are recognized and transmitted as text, and at the receiver the text is verbalized
using speech synthesis. The protocol relies on E2E feedback, which adds to the complexity of the
design and introduces more overhead.

Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

423

Gupta and Obeidat [23] study the performance of adaptive voice communications over wireless
links. They use a simple two-state Gilbert–Elliot model [24, 25] to capture channel errors. In
Obeidat and Gupta [26] a more elaborate N -state finite-state Markov channel is used to capture
the multi-path fading dynamics better, and to allow the use of more levels of compression and
modulation. Even though the ultimate goal is voice support over ad hoc networks, both of these
studies focussed on communication over a single hop.
Unlike the previous work, this paper introduces a cross-layer scheme that combines both adaptive
modulation and compression in order to improve the support of voice over multi-hop wireless
networks while at the same time avoids E2E feedback to minimize the complexity and overhead
introduced.

3. BACKGROUND AND TERMINOLOGY
3.1. Packet voice
Voice digitization refers to the conversion of the analog voice signal into a digital signal. Pulse
code modulation (PCM) is a digital representation of the analog signal where the signal magnitude
is sampled at uniform intervals and quantized. Since speech signals do not change rapidly, the
samples tend to have a high degree of redundancy. Speech coding is the process of compressing
speech by applying psychoacoustics to transmit only data that are relevant to the human auditory
system. This process, however, results in some loss in the quality of the reconstructed signal.
In processing speech samples, coders operate on blocks of samples called frames. A speech
coder does not start operating until it has collected at least enough samples to make up a frame.
3.2. QoS requirements for voice
Delay is the key quality impairment for voice. For one-way transmission time the ITU-T G.114
recommendation [7] is that a 0–150 ms delay is acceptable for most applications but a delay above
400 ms is unacceptable. For highly interactive tasks, quality may suffer at a delay of 100 ms.
E2E delay is the time from when a frame is generated at the source until it is played at the
destination. It consists of packetization, queueing, transmission and propagation, and play-out
delay. Packetization delay is the delay at the source node to collect all bits that compose a packet.
Queuing delay is the time packets spend waiting to be forwarded. Transmission and propagation
delay is the time it takes to first transmit a packet and then for it to propagate through a link.
Finally, play-out delay is the time packets spend in the buffer of the destination for smooth play
out. The delay budget refers to the total E2E delay beyond which packets are considered stale.
Voice can tolerate a small amount of packet discard. Either the decoder uses sequence numbers
to interpolate for lost packets or the encoder adds redundancy in the sent packets [27]. These
techniques work well when the losses are isolated. For compressed voice, packet loss concealment
(PLC) is employed by most codecs. PLC involves the receiver producing a replacement for a lost
packet. This is possible because of the short-term self-similarity in audio data [4].
Delay variation is the difference between the minimum and the maximum delay that packets
encounter in a single session, and it results from variable queueing delays. Buffering is used
to overcome delay variation. Figure 3 shows a play-out buffer [28]. Once the destination starts
receiving packets, it buffers them for a time equal to the delay variation, and then starts playing

Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

424

S. A. OBEIDAT AND V. R. SYROTIUK

Input from network
at a variable bit rate

FIFO Buffer

Effect of early arrival

Output at a
constant bit rate

Effect of late arrival
Defined level
before output starts

Figure 3. Play-out buffer at the destination [28].

Figure 4. SNR vs BER for several modulation schemes [29].

them out. When packets arrive late some packets in the buffer are consumed, while early arrival
results in the buffer length growing.
3.3. Modulation
Modulation is the process of changing a data stream to a form suitable for transmission over the
physical medium. In digital modulation, this involves mapping k bits into one symbol. The more
bits per symbol, the denser the modulation and the higher the data rate achieved for a given channel
bandwidth, however, the lower the ability to cope with bit errors. Denser modulation techniques
are used when the signal-to-noise ratio (SNR) is relatively high so that transmission quality is not
compromised.
Figure 4 shows the trade-off in the bit-error rate (BER) and SNR for five digital modulation
schemes: binary phase shift keying (BPSK), quadrature phase shift keying (QPSK), and quadrature amplitude modulation with k ∈ {4, 6, 8} bits per symbol. For example, while QPSK allows a
communication bandwidth twice the channel bandwidth, it requires an average SNR of 7 dB to
achieve a BER of 10−3 . At this SNR (i.e. 7 dB), BPSK, which allows a bit per symbol transmission,
has a BER performance of 10−5 .
The state of the wireless channel changes dynamically. It experiences variations in quality
resulting from exposure of the signal to absorption, scattering, interference, and multi-path fading.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

425

As a result, the choice of modulation is made to meet the worst case rather than the average
channel behaviour. Adaptive modulation techniques [29] therefore use a dense modulation scheme
when the channel conditions are good and a sparse modulation scheme when they are poor.
3.4. Fading distributions
Multi-path fading is when the signal quality depends on the multi-path propagation. When a signal
is transmitted, multiple versions of the same signal may take different paths to the receiver. The first
to arrive at the receiver is the line of sight (LOS) component. Other, delayed versions follow other
paths resulting from obstacles that may be mobile; these delayed copies either add constructively
or destructively depending on the amplitude, phase, and angle of arrival of the signals.
The existence or absence of an LOS component defines the distribution of the fading. Rayleigh
fading refers to conditions where there is no LOS component. When there is a LOS component the
fading phenomenon follows a Rice distribution with a parameter k, where k defines the strength
of the LOS component compared with the other components. Raleigh fading is a special case of
Ricean fading when k = 0.

4. SYSTEM ARCHITECTURE
Figure 5 shows the architecture of our opportunistic cross-layer protocol. The physical layer selects
the modulation scheme based on input from the MAC layer; this choice is made at every hop
along the path. Similarly, the application layer selects the voice encoding scheme and packet size
based on the feedback from the MAC layer; this choice is made only at the source node.
Our proposed architecture is general, appropriate for any real-time application and any MAC
protocol capable of supporting multiple rates. A multi-rate MAC is required because adaptive
modulation affects the time it takes for a packet to be transmitted over the channel and hence a

Application Layer
Adaptive Voice Coding and Packet Size

At Source Node Only

MAC Sub-Layer
OAR Over IEEE 802.11

Physical Layer
Adaptive Modulation

At Every Hop

Figure 5. The system architecture.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

426

S. A. OBEIDAT AND V. R. SYROTIUK

Receiver

Sender
Send RTS

Extract SNR Info

Determine Best
Transmission Rate

MAC Informs
Application Layer of
Decision

Application Layer
Chooses Sampling Rate

Send Feedback
Piggybacked in CTS

Application Layer
Chooses Packet Size

MAC Calculates No. of
back-to-back Packets

Inform PHY what rate to
send packet at

Actual Packet
Transmission

Figure 6. The dynamics of the protocol.

way is needed to modify the MAC-layer scheduling and back-off to be aware of this duration. We
instantiate the architecture with VoIP as the application and the opportunistic auto rate (OAR)
protocol over IEEE 802.11 [11] as the MAC protocol.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

427

Figure 6 shows the details of the protocol dynamics. OAR uses physical-layer analysis of the
request-to-send packet performed at the receiver to decide the rate. This involves measuring the
SNR and opportunistically selecting the highest transmission rate for the given conditions. This
decision is then conveyed back to the sender in the clear-to-send packet. Since the handshake
immediately precedes the data transmission, it provides an accurate estimation of the channel.
The standard requires the handshake to be sent at the base rate so that all nodes can overhear
it; all overhearing nodes modify their network allocation vector (NAV) to reflect any change in
transmission time for the packet.‡ In addition to using the most spectrally efficient modulation,
OAR allows a node to transmit many back-to-back packets (i.e. packet bursts). This way, it reduces
the need to compete for the channel for every packet. The number of packets transmitted is equal
to the ratio of the current rate to the base rate.
The protocol is cross-layer in that the MAC protocol at the sender communicates the rate selected
by the receiver to both the physical layer to use to select the rate (PHY/MAC interaction), and
to the application layer to choose the voice coding scheme (MAC/application interaction). The
application layer codes the analog signal using the chosen rate and packetizes it accordingly. The
choice of the packet size is matched to the chosen coding scheme: with a higher compression
scheme a smaller packet size is used while with lower compression larger packets are used to
diminish the overhead introduced.
In addition to inheriting the opportunistic behaviour of OAR, our protocol is opportunistic in
making use of high-quality channels. By transmitting highly compressed voiceover high quality
channels, the packet is more likely to arrive at the receiver error free.

5. SIMULATION SET-UP
5.1. The evaluation methodology
We use the ns-2 network simulator [30] to evaluate the performance of the proposed opportunistic
cross-layer adaptive protocol using rates of 2, 5.5, and 11 Mbps, and compare it with a non-adaptive
approach using a single voice coding scheme (non-compressed PCM at 64 kbps) over the IEEE
802.11 standard rate of 2 Mbps.
The performance of each protocol is measured by the multiplexing gain and the perceived voice
quality. The multiplexing gain is the number of simultaneous calls supported. Voice quality is
measured using the degradation in voice quality (DVQ) metric [31] defined as the ratio:
DVQ =

plost + pstale
ptotal

where plost is the number of packets lost, pstale is the number of packets above the delay threshold,
and ptotal is the total number of packets sent. It is known that delay variations less than 75 ms result
in good quality [32]. Even though we are not accounting for delay jitter explicitly, we have chosen
a stringent delay threshold to allow for enough buffering at the destination without compromising
the perceived quality.
Since adaptive compression is used, we emphasize that simply counting the number of packets is
inaccurate because the amount of speech per packet depends on the level of compression. Therefore,
‡

802.11 nodes use the NAV to keep track of transmission schedules of other nodes as part of virtual carrier sensing.

Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

428

S. A. OBEIDAT AND V. R. SYROTIUK

A Talks and B is Silent

State 7
Short Silence Gap
While
A Talks, B Silent

A and B are both Talking

State 2
Double Talk
A is interrupted
State 1
A Talks, B Silent

State 3
Double Talk
B is interrupted

State 4
Mutual Silence
State 6

A Spoke Last

B Talks, A Silent
State 5
Mutual Silence

State 8
Short Silence Gap
While
B Talks, A Silent

B Spoke Last

A and B are both Silent

B Talks and A is Silent

Figure 7. The eight-state voice generation model [36].

in the computation of DVQ, rather than counting packets we count the amount of speech per
packet.
5.2. The voice model
The models for representing a voice communication can be broadly classified as one way or two
way [33]. One-way models represent a call by an on–off Markov chain. The on state corresponds
to a talk-spurt, while the off state corresponds to silence.
To capture additional events such as mutual silence and double talk, Brady [34] proposed a
two-way model with six states. This model ignores silence shorter than 200 ms, considering it as
part of the corresponding talk-spurt. Figure 7 shows the eight-state model that takes these silent
periods into account. This model, proposed by Stern et al. [35], results in talk-spurts 33.2% of
the time and silence the remaining 66.8% of the time. We use this model as it allows protocols to
achieve higher bandwidth efficiency by exploiting these gaps of silence.
5.3. The fading model
Punnoose et al. [36] propose a simple and efficient approach for modelling small-scale Rice and
Rayleigh fading based on the method in [37]; this is part of the ns-2 wireless extensions. The
method involves using a pre-computed table of the fading envelope. This lookup-table can be
used to model a wide range of fading environments by adjusting the transmission power, Ricean
k-factor, and the Doppler frequency. Since the table represents a limited-length time sequence, it
can be used over and over for long simulations. The table is set up in a way that does not result
in discontinuities when the sequence repeats.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

429

Table I. Parameters of the simulated voice codecs.
Codec
type
ADPCM
LD-CELP
LD-CELP

Rate
(kbps)

Frame size
(ms)

Codec-introduced
delay (ms)

Ie
value (%)

40
16
12.8

0.125
0.625
0.625

0.375
1.875
1.875

2
7
20

Even though the channel modelling extensions accurately simulate the wireless channel for
each individual flow, the fading components of channels for different flows are identical. This is
unrealistic and happens because the index into the pre-computed table is the current simulation
time, which is identical for all flows. A way to solve this problem involves making the index into
the table a combination of the current simulation time and the flow identifier [11]; we use this
model in our simulations.
5.4. The simulation parameters
Since IEEE 802.11b supports three rates (2, 5.5, and 11 Mbps), we have three levels of rate
adaptation.
We select compression schemes that balance processing delay and the quality impairment they
introduce. The three compression schemes used are summarized in Table I: adaptive differential
pulse code modulation (ADPCM) [38], low delay-code excited linear prediction (LD-CELP) at
16 kbps and at 12.8 kbps [39]. The codec-introduced delay field in the table specifies the processing
delay introduced by the coder. As the table shows, the lower the rate the higher the impairment
factor and the higher the packetization delay introduced.
Since delays of more than 150 ms contribute to quality impairment, we choose 150 ms as our
target E2E delay. Any packet taking longer than 150 ms to reach the destination is late and is
counted as stale.
For example, consider a 50 byte data packet. Using the highest-compression coder (the LDCELP 12.8 kbps), about 32 ms(50∗8/12800 = 0.03125 s) is consumed just for packetization. To
this we add a lookahead delay of 1.875 ms, which results in a total coding delay of 33.125 ms.
This means that the delay threshold should be set to 150−33.125  117 ms, i.e. all packets arriving
after only 117 ms are stale.
Since we are considering a VoIP set-up and the heavy overhead of TCP is not suitable for
real-time applications, UDP serves as our transport protocol. By the time an audio service data
unit is ready for transmission at the physical layer, it has UDP/IP/MAC headers appended to it
totaling 56 bytes. Thus, if the actual payload is 50 bytes, what is actually transmitted is 106 bytes.
The rest of the simulation parameters used are summarized in Table II.

6. SIMULATION RESULTS
6.1. A line topology
Initially, we consider the line topology in Figure 8, with i hops, where 1i4. The first node
in the line represents the caller and the last node represents the callee. This topology minimizes
MAC-layer contention and physical-layer co-channel interference. Even though this topology is
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

430

S. A. OBEIDAT AND V. R. SYROTIUK

Table II. Simulation parameters.
Simulation time
Simulation warm-up time

250 s
50 s
eight-state model [35]
UDP
AODV [40]
Rayleigh, Rice with
k = {15, 30} dB [11]
200 packets
{50, 125, 200, 300} bytes
{2, 5.5, 11} Mbps
ADPCM, LD-CELP at
{16, 12.8} kbps
{150, 300} ms

Voice generation model
Transport protocol
Routing protocol
Fading model
Buffer size
Packet size
Channel rates
Compression schemes
Delay threshold

Three–hop

Four–hop

Two–hop
One–hop

A

B

C

D

E

Figure 8. A line topology with i hops, 1i4.

static, we use the ad hoc on demand distance vector (AODV) routing protocol [40] to establish
the routes at the beginning of the simulation.
The number of calls initiated between the caller and the callee is increased to see the impact
on performance. By having a fixed topology irrespective of the number of calls, we can attribute
the change in performance solely to the change in load. This allows us to investigate the effect of
both hop count and load on performance.
As a starting point, we investigate whether the opportunistic cross-layer adaptive protocol has
any benefit over the non-adaptive approach. To do that, we compare the performance of both in
terms of the percentage of late packets, the percentage of lost packets, and DVQ over one-hop
communication with a packet size of 50 bytes.
Figure 9 shows the percentage of packets arriving after the delay threshold. While in the adaptive
case the percentage of late packets is close to 0% for up to 12 calls (under Ricean fading), the
non-adaptive scenario results in a percentage as high as 30%.
The figure also shows that in the non-adaptive case, the ratio of late packets to the total number
of packets decreases after a certain load level. To understand this behaviour, we plot the absolute
number of packets to exceed the delay threshold in Figure 10. Initially, as the load increases, so
does the percentage of late packets. However, it stabilizes when the number of sources equals 10.
This indicates the condition when the buffer saturates. At such a point, no matter how much
more traffic is introduced, most of this traffic is dropped due to the buffer being full, and the rest
is served. Out of this constant rate being served, a fixed percentage is always late. Plotting the
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

431

0.6

Late Packets Ratio

0.5
0.4
0.3
0.2

Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh
Non_Adaptive_Rice30
Non_Adaptive_Rice15
Non_adaptive_Rayleigh

0.1
0

2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 9. Percentage late with a 50 byte packet (one-hop scenario).

Number of Late Packets

600000

Late_Rice_30
Late_Rice_15
Late_Rayleigh

500000
400000
300000
200000
100000
0

2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 10. The number of late packets with a 50 byte packet (one-hop scenario).

0.8

Lost Packets Ratio

0.7
0.6
0.5
Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh
Non_Adaptive_Rice30
Non_Adaptive_Rice15
Non_adaptive_Rayleigh

0.4
0.3
0.2
0.1
0
2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 11. Percentage lost with a 50 byte packet (one-hop scenario).

percentage in Figure 9 shows a decrease in the late packets ratio. This is because the number of
late packets is roughly constant and the amount of load is constantly increasing.
The loss behaviour follows the same trend. Figure 11 shows that the adaptive approach supports
14 calls with a percentage of loss less than 5%, while the non-adaptive one results in losses greater
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

432

S. A. OBEIDAT AND V. R. SYROTIUK

1

Adaptive_Rice30
Adaptive_Rice_15
Adaptive_Rayleigh
Non_Adaptive_Rice30
Non_Adaptive_Rice15
Non_adaptive_Rayleigh

DVQ

0.8

0.6

0.4

0.2

0
2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 12. DVQ with a 50 byte packet size (one-hop scenario).

than 50%. There is an initial decrease in the loss ratio in Figure 11. As the load increases, a higher
share of the traffic is serviced when the channel quality is good, which results in an overall drop in
the loss ratio. That is, since the advantage of using adaptive modulation over OAR is manifested
in sending multiple back-to-back packets, a relatively high load is needed to take advantage of that
capability. However, as the load increases beyond a certain limit, more losses occur due to packet
drops. This more than offsets the advantage of better bandwidth usage resulting in an overall
increase in the loss percentage.
The combined effect of these two parameters is quantified by the DVQ in Figure 12. While
the adaptive protocol allows up to 12 calls (under Ricean fading) and 8 calls (under Rayleigh
fading), the non-adaptive protocol reaches a degradation level of 45% with only 4 calls rendering
the communication useless for most practical situations.
The results show that adaptation is not only significant but also gives a substantial performance
improvement when compared with the non-adaptive approach in terms of both late and lost packet
ratios. The rest of the results are presented only in terms of DVQ since it captures both lost and
late packets.
We now study the impact of packet size on performance, repeating the experiment with a
125 byte packet size while all other parameters are fixed. Figure 13 shows that the DVQ of the
adaptive approach is very promising. Even under Rayleigh fading conditions, all 20 sources can
be supported with 16% loss in quality. The non-adaptive approach suffers a 40% loss in quality
with only 6 sources.
Compared with Figures 12 and 13 shows better performance. This is because with the larger
packet size less overhead is introduced (in the case of 50 byte packets, the overhead accounts for
more than 50% of the traffic).
We have now established the superiority of the adaptive approach over the non-adaptive one.
The remaining graphs focus only on the performance of the adaptive approach.
Using the same packet size (125 bytes), we perform the experiment increasing the hop count
to 2 from 1 to see the impact of hop count on performance. Figure 14 shows that we still can
support up to 14 calls with good quality under Rice fading, and 8 calls under Rayleigh fading.
As expected, with the increase in hop count, the number of calls supported decreases. This is
attributed to different factors, such as higher chances of loss in communication, higher co-channel
interference, and longer delay in intermediate nodes.
Given the relatively lower performance of communication over two hops, we expect it to reduce
even more as the hop count increases. Hence, for longer routes (scenarios with three and four
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

433

1
0.9
0.8

DVQ

0.7
0.6
0.5
0.4

Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh
Non_Adaptive_Rice30
Non_Adaptive_Rice15
Non_adaptive_Rayleigh

0.3
0.2
0.1
0
2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 13. DVQ with a 125 byte packet (one-hop scenario).

0.6
0.5

Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh

DVQ

0.4
0.3
0.2
0.1
0
2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 14. DVQ with a 125 byte packet (two-hop scenario).

hops), we employ the robust header compression (ROHC) protocol [41]. This allows the UPD/IP
header to be compressed from 28 bytes down to only 4 bytes. This is possible by exploiting the
redundancy from one packet to another.
The performance (not shown) of the adaptive approach for 125 byte packets over a three-hop
path with ROHC enabled is very poor even for 10 sources. Since a 125 byte packet improved
performance over a 50 byte packet, we increase the packet size again to see if we can enhance
the performance any further. Repeating the experiment with a 200 byte packet, however, did not
improve the performance markedly (see Figure 15).
Since we cannot increase the packet size any further without consuming most, if not all, of the
delay budget in packetization, we were forced to relax the delay budget, doubling it from 150 to
300 ms. Now that the delay budget is not as tight, we can consider larger packet sizes. Figure 16
shows the performance using a 300 byte packet. Performance has enhanced to allow most sources
to be supported with a quality degradation less than 5% even under Rayleigh fading.
As a general trend, the use of larger packets improves performance overall. This is because
larger packets result in less contention for transmission by the MAC protocol (i.e. fewer handshakes
and fewer back-off delays) and less overhead per packet. If kept within delay budget limitations,
packet size can be crucial in providing high-quality communication over long routes.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

434

S. A. OBEIDAT AND V. R. SYROTIUK

1
0.9
0.8

DVQ

0.7
0.6
0.5
0.4
0.3
Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh

0.2
0.1
0

2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 15. DVQ with a 200 byte packet (three-hop scenario with ROHC).

0.35

Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh

0.3

DVQ

0.25
0.2
0.15
0.1
0.05
0
2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 16. DVQ with a 300 byte packet (three hops, 300 ms delay threshold with ROHC).

0.7

Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh

0.6

DVQ

0.5
0.4
0.3
0.2
0.1
0

2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 17. DVQ with a 300 byte packet size (four-hop scenario, 300 ms delay threshold with ROHC).

Using these parameters, we studied the performance for four-hop paths in Figure 17. All sources
can be supported with a degradation less than 20% under Rice fading and 10 sources under
Rayleigh fading.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

435

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

These results show that the increase in hop count reflects on performance. As a way of mitigating
this adverse effect of hop count, measures such as using ROHC and increasing the packet size
(which may be possible only if we can relax the delay budget) can be employed.
6.2. A variant of line topology
We now consider a variant of the line topology in which contention is introduced at the head
of the line; this is similar to the topology used in [4]. In this topology, shown in Figure 18, the
number of calls generated is divided between nodes A and B to determine the effect of MAC-layer
contention on the performance.
Figure 19 shows the performance over one hop using a 125 byte packet with a 150 ms delay
threshold (ROHC is disabled). Since we have seen that a 125 byte packet gives better performance
than a 50 byte packet, we do not show the performance in this case.
As the figure shows, all 20 sources can be supported with a degradation in quality of less than
10%. The performance is very similar to that plotted in Figure 13. However, because the load

Four–hop
Three–hop
Two–hop
One–hop

A

C

E

D

F

B

Figure 18. Line topology with contention at the head of the line.

0.12
0.1

Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh

DVQ

0.08
0.06
0.04
0.02
0
2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 19. DVQ with a 125 byte packet (one-hop scenario).
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

436

S. A. OBEIDAT AND V. R. SYROTIUK

0.6
0.5

DVQ

0.4
0.3
0.2
Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh

0.1
0

2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 20. DVQ with a 125 byte packet size (two-hop scenario).

0.4
0.35

Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh

0.3

DVQ

0.25
0.2
0.15
0.1
0.05
0

2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 21. DVQ with a 300 byte packet size (three-hop scenario, 300 ms delay threshold with ROHC).

is divided between two nodes, each with its own buffer, it results in a slight enhancement in
quality. This is possible because the load is not high enough to strain the network. As expected,
the performance of this topology is always worse than that of the line topology.
We repeat the experiment for a two-hop path and plot DVQ in Figure 20. Up to 12 sources
can be supported under Rice fading. Increasing the load beyond 12 results in a quality that is
unacceptable. Under Rayleigh fading, on the other hand, the performance is poor even for very low
load levels. For the Rayleigh case, one can either relax the delay threshold constraint, introduce
forward error correction (FEC), ROHC or a combination of the two.
When plotting the performance for a three-hop path using a 125 byte and 200 byte packet (not
shown), the same trend as in the line topology is observed: increasing the packet size results in
an improvement in quality.
We next study the performance over a three-hop path using a 300 byte packet, a 300 ms delay
threshold, and ROHC enabled. Figure 21 shows that this allows 16 sources to be supported with
close to no degradation in quality. Under Rayleigh fading, however, barely 10 sources can be
supported with a 20% degradation.
Using these same parameters, we plot the performance for a four-hop path in Figure 22. Up
to 12 sources can be supported with good quality under Ricean fading, while quality suffers even
for very low load conditions under Rayleigh fading. Having a four-hop path with all links deeply
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

0.5

437

Adaptive_Rice30
Adaptive_Rice15
Adaptive_Rayleigh

0.45
0.4

DVQ

0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

2

4

6

8

10

12

14

16

18

20

Number of Calls

Figure 22. DVQ with a 300 byte packet size (four-hop scenario, 300 ms delay threshold with ROHC).

faded is a very severe condition. Normally, we would expect some of the links to be in deep fade
while others provide good quality. In addition, as we mentioned earlier, this can be mitigated if a
FEC scheme is employed to decrease the channel-induced losses.
In general, the trends in performance for the line topology with contention at the head of the
line are similar to those found for the line topology. As the hop count increases the performance
suffers. In addition, increasing the packet size enhances the quality. The performance is not as
high as in the line topology due to the additional contention for the channel.

7. CONCLUSIONS
We proposed an opportunistic cross-layer adaptive protocol for supporting real-time voice over
severely constrained multi-hop wireless LANs. The protocol takes into account modulation, voice
coding, and packet size as parameters for adaptation.
In simulation, we investigated the performance of the adaptive protocol under different fading
schemes, topologies, path lengths, and packet sizes, comparing it with a non-adaptive approach.
The results show a significant benefit of adaptation. In general, performance degrades as load
increases. Over short paths, good to excellent quality is achieved. As the hop count increases,
extra measures have to be incorporated into the system to enhance the quality of the communication. This includes ROHC and relaxing the delay constraints. For even longer paths and
under extreme Rayleigh conditions, other measures may need to be introduced (e.g. FEC). In
investigating the effect of packet size, the results show that over longer paths larger packets are
needed.
REFERENCES
1. Chen D-Y, Garg S, Kappes M, Trivedi KS. Supporting VBR VoIP traffic with IEEE 802.11 WLAN in PCF
mode. Proceedings of the OPNETWork 2002, Washington, DC, 2002.
2. Chen T, Kazantzidis M, Gerla M, Slain I. Experiments on QoS adaptation for improving end user speech perception
over multihop wireless networks. IEEE International Conference on Communications (ICC’99), Vancouver, BC,
Canada, 1999; 708–715.
3. Dong H, Chakares ID, Lin C-H, Gersho A, Belding-Royer E, Madhow U, Gibson JD. Speech coding for mobile
ad hoc networks. Asilomar Conference on Signals, Systems, and Computers (ACSSC’03), Pacific Grove, CA,
vol. 1, 2003; 280–284.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

438

S. A. OBEIDAT AND V. R. SYROTIUK

4. Dong H, Chakares ID, Lin C-H, Gersho A, Belding-Royer E, Madhow U, Gibson JD. Selective bit-error checking
at the MAC layer for voice over mobile ad hoc networks with IEEE 802.11. IEEE Wireless Communications
and Networking Conference (WCNC’04), Atlanta, GA, 2004; 1240–1245.
5. Karp B, Kung HT. GPSR: greedy perimeter stateless routing for wireless networks. IEEE International Conference
on Mobile Computing and Networking (Mobicom’00), Boston, MA, 2000; 243–254.
6. Ahn G-S, Campbell AT, Veres A, Sun L-H. SWAN: service differentiation in stateless wireless ad hoc networks.
IEEE Conference on Computer Communications (Infocom’02), New York, NY, vol. 2, 2002; 457–466.
7. ITU-T. One-way transmission time. ITU Recommendation G.114, 1996.
8. Fraleigh C, Tobagi F, Diot C. Provisioning IP backbone networks to support latency sensitive traffic. IEEE
Conference on Computer Communications (Infocom’03), San Francisco, CA, 2003; 375–385.
9. ITU-T. The Emodel, a computational model for use in transmission planning. ITU-T Recommendation G.107, 1998.
10. ITU-T. Transmission impairments due to speech processing. ITU-T Recommendation G.113, 2001.
11. Sadeghi B, Kanodia V, Sabharwal A, Knighlty E. Opportunistic media access for multirate ad hoc networks.
International Conference on Mobile Computing and Networking (MobiCom’02), Atlanta, GA, 2002; 24–35.
12. Barberis A, Casetti C, De Martin JC, Meo M. A simulation study of adaptive voice communications on IP
networks. International Symposium on Performance Evaluation of Computer and Telecommunication Systems
(SPECTS’00), Vancouver, BC, Canada, 2000; 531–542.
13. Shenker S. Fundamental design issues for the future internet. IEEE Journal on Selected Areas in Communications
1995; 13(7):1176–1188.
14. Balachandran K, Kadaba SR, Nanda S. Channel quality estimation and rate adaptation for cellular mobile radio.
IEEE Journal on Selected Areas in Communications 1999; 17(7):1244–1256.
15. Ue T, Sampei S, Morinaga N, Hamaguchi K. Symbol rate and modulation level-controlled adaptive
modulation/TDMA/TDD system for high-bit-rate wireless data transmission. IEEE Transactions on Vehicular
Technology 1999; 47(4):1134–1147.
16. Visser MA, Zarki ME. Voice and data transmission over an 802.11 wireless network. IEEE International
Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC’95), Toronto, Canada, 1995;
648–652.
17. Ziouva E, Antonakopoulos T. CBR packetized voice transmission in IEEE 802.11 networks. IEEE Symposium
on Computers and Communications, Hammamet, Tunisia, 2001; 392–398.
18. IEEE. IEEE 802.11 wg. draft supplement to IEEE standard 802.11-1999: medium access control (MAC)
enhancements for quality of service (QoS). IEEE 802.11e/D5.0, 2003.
19. Choi S, DelPrado J, Shankar S, Mangold S. IEEE 802.11e contention-based channel access (EDCF) performance
evaluation. IEEE International Conference on Communications (ICC’03), Anchorage, AK, vol. 2, 2003; 1151–
1156.
20. Wietholter S, Hoene C, Wolisz A. Perceptual quality of internet telephony over IEEE 802.11e supporting
enhanced DCF and contention free bursting. Technical Report TKN-04-011, Telecommunication Networks Group,
Technische Universität Berlin, 2004.
21. Sobrinho JL, Krishnikumar AS. Distributed multiple access procedures to provide voice communications over
IEEE 802.11 wireless networks. Global Telecommunications Conference (GLOBECOM’96), London, U.K., vol. 3,
1996; 1689–1694.
22. Sheu S-T, Sheu T-F. A bandwidth allocation/sharing/extension protocol for multimedia over IEEE 802.11
ad hoc wireless LANs. IEEE Journal on Selected Areas in Communications 2001; 19(10):2065–2080.
23. Gupta S, Obeidat S. A framework for adaptive voice communication over wireless channels. Wireless
Communications and Networking Conference (WCNC’03), New Orleans, LA, vol. 2, 2003; 1096–1101.
24. Gilbert EN. Capacity of a burst-noise channel. Bell Systems Technical Journal 1960; 39:1253–1266.
25. Elliot EO. Estimates of error rates for codes on burst-error channels. Bell Systems Technical Journal 1963;
42:1977–1997.
26. Obeidat SA, Gupta S. Towards voice over ad hoc networks: an adaptive scheme for packet voice communications
over wireless links. IEEE International Conference on Wireless and Mobile Computing, Networking and
Communications (WiMob’05), Montreal, Canada, 2005; 245–252.
27. McDysan DE, Spohn D. ATM Theory and Applications. McGraw-Hill: New York, 1999.
28. Halsall F. Multimedia Communications. Addison-Wesley: Reading, MA, 2001.
29. Torrance JM, Hanzo L. Adaptive modulation in a slow Rayleigh fading channel. IEEE International Symposium
on Personal, Indoor and Mobile Radio Communications (PIMRC’96), vol. 2, 1996; 497–501.
30. The network simulator—ns-2. http://www.isi.edu/nsnam/ns/, 2007.
Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

AN OPPORTUNISTIC CROSS-LAYER ARCHITECTURE

439

31. Jain R, Munir S, Iyer J. Performance of VBR voice over ATM: effect of scheduling and drop policies. ATM
Forum/97-0608, 1997.
32. Miras D. A survey of network QoS needs of advanced internet applications. Working Document, Internet2 QoS
Working Group, December 2002.
33. Minoli D, Minoli E. Delivering Voice over IP Networks. Wiley Computer Publishing: New York, 1998.
34. Brady PT. A model for generating on–off speech patterns in two-way conversation. Bell Systems Technical
Journal 1969; 48(9):2445–2472.
35. Stern HP, Mahmoud SA, Wong K-K. A comprehensive model for voice activity in conversational speech
development and application to performance analysis of new-generation wireless communication systems. Wireless
Networks 1996; 4(2):359–367.
36. Punnoose R, Nikitin P, Stancil D. Efficient simulation of Ricean fading within a packet simulator. IEEE Vehicular
Technology Conference (VTC’00), Boston, MA, 2000; 764–767.
37. Rappaport TS. Wireless Communications (1st edn). Prentice-Hall: Upper Saddle River, NJ, 1996.
38. ITU-T. 40, 32, 24, 16 kbit/s adaptive differential pulse code modulation (ADPCM). ITU Recommendation
G.726, 1990.
39. ITU-T. Implementors guide for ITU-T recommendation g.728: coding of speech at 16 kbits/sec using low-delay
code excited linear prediction. ITU Recommendation G.728, 1992.
40. Perkins C, Hodson O, Hardman V. A survey of packet loss recovery techniques for streaming audio. IEEE
Network 1998; 12(5):40–48.
41. Bormann C, Burmeister C, Degermark M, Fukushima H, Hannu H, Jonsson L, Hakenberg R, Koren T, Le K,
Liu Z, Martensson A, Miyazaki A, Svanbro K, Wiebke T, Yoshimura T, Zheng H. Robust header compression
(ROHC): framework and four profiles: RTP, UDP, ESP, and uncompressed. IETF RFC 3095, 2001.

AUTHORS’ BIOGRAPHIES

Suhaib A. Obeidat completed his PhD in Computer Science from the Arizona State
University in 2008. His research focus is on adaptation and cross-layer communication
for multimedia applications over wireless and mobile networks.

Violet R. Syrotiuk received her PhD in Computer Science from the University of
Waterloo (Canada) in 1992. She joined the Arizona State University in 2002 and is
currently an Associate Professor of Computer Science and Engineering. Dr Syrotiuk’s
research is currently supported by a grants from NSF, and two grants from the Office of
Naval Research. She serves on the Editorial Board of Computer Network and the International Journal of Communication Systems, and on the Technical Program Committee
of several major conferences including Mobicom, Mobihoc, and Infocom. Her research
interests include MAC and higher layer protocols for multi-hop wireless networks.

Copyright q

2008 John Wiley & Sons, Ltd.

Int. J. Commun. Syst. 2009; 22:419–439
DOI: 10.1002/dac

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 13,

NO. 10,

OCTOBER 2014

2255

ATLAS: Adaptive Topology- and
Load-Aware Scheduling
Jonathan Lutz, Charles J. Colbourn, and Violet R. Syrotiuk
Abstract—The largest strength of contention-based MAC protocols is simultaneously the largest weakness of their scheduled
counterparts: the ability to adapt to changes in network conditions. For scheduling to be competitive in mobile wireless networks,
continuous adaptation must be addressed. We propose ATLAS, an Adaptive Topology- and Load-Aware Scheduling protocol to address
this problem. In ATLAS, each node employs a random schedule achieving its persistence, the fraction of time a node is permitted to
transmit, that is computed in a topology and load dependent manner. A distributed auction (REACT) piggybacks offers and claims onto
existing network traffic to compute a lexicographic max-min channel allocation. A node’s persistence p is related to its allocation. Its
schedule achieving p is updated where and when needed, without waiting for a frame boundary. We study how ATLAS adapts to
controlled changes in topology and load. Our results show that ATLAS adapts to most network changes in less than 0.1s, with about
20 percent relative error, scaling with network size. We further study ATLAS in more dynamic networks showing that it keeps up with
changes in topology and load sufficient for TCP to sustain multi-hop flows, a struggle in IEEE 802.11 networks. The stable performance of
ATLAS supports the design of higher-layer services that inform, and are informed by, the underlying communication network.
Index Terms—Wireless networks, medium access control, adaptation

Ç
1

INTRODUCTION

D

ESPITE the well known shortcomings of IEEE 802.11
and other contention-based MAC protocols for mobile
wireless networks—such as probabilistic delay guarantees,
severe short-term unfairness, and poor performance at high
load—they remain the access method of choice. The primary reason is their ease in adapting to changes in network
conditions, specifically to changes in topology and in load.
The lack of timely adaptation is the most serious limitation
facing scheduled MAC protocols. For scheduling to be competitive, continuous adaptation is required.
Topology-dependent approaches to adaptation in scheduling alternate a contention phase with a scheduled phase. In
the contention phase, nodes exchange topology information
used to compute a conflict-free schedule that is followed in
the subsequent scheduled phase (see, as examples, [5], [30]).
However, changes in topology and load do not always align
with the phases of the algorithm resulting in a schedule that
often lags behind the network state.
In contrast, the idea behind topology-transparent scheduling is to design schedules independent of the detailed network topology [3], [15]. Specifically, the schedules do not
depend on the identity of a node’s neighbours, but rather
on how many of them are transmitting. Even if a node’s
neighbours change, its schedule does not; if the number of
neighbours does not exceed the design bound then the
schedule guarantees success. Though such schedules are
robust to network conditions that deviate from the design



The authors are with the Department of Computer Science and Engineering, Arizona State University, 699 S Mill Avenue, Suite 553, Tempe, AZ
85281. Email: {jlutz, colbourn, syrotiuk}@asu.edu.

Manuscript received 17 Mar. 2013; revised 7 Dec. 2013; accepted 12 Dec.
2013. Date of publication 22 Dec. 2013; date of current version 26 Aug. 2014.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identifier below.
Digital Object Identifier no. 10.1109/TMC.2013.2296040

parameters [27], because the schedules do not adapt, the
technique remains a theoretical curiosity.
In contention-based schemes, such as IEEE 802.11, a node
computes implicitly when to access the channel, basing its
decisions on perceived channel contention. We instead compute a node’s persistence—the fraction of time it is permitted
to transmit—explicitly in a way that tracks the current topology and load. To achieve this, we propose ATLAS, an
Adaptive Topology- and Load-Aware Scheduling protocol.
Channel allocation is a resource allocation problem where
the demands correspond to transmitters, and the resources
to receivers. ATLAS implements the REsource AlloCaTion
computed by REACT, a distributed auction that runs continuously. REACT piggybacks offers and claims onto existing
network traffic to compute the lexicographic max-min allocation to transmitters which we call the TLA allocation,
emphasizing that it is both topology- and load-aware. Each
node’s random schedule, achieving a persistence informed
by its allocation, is updated whenever a change in topology
or load results in a change in allocation. While the slots of
the schedule are grouped into frames, this is done only to
reduce the variance in delay [6]; there is no need to wait for
a frame boundary to update the schedule. Even though the
random schedules may not be conflict-free, ATLAS is not
contention-based; it does not select persistences or make
scheduling decisions based on perceived channel contention—its decisions are based solely on topology and load.
We study how ATLAS adapts to controlled changes in
topology and load, measuring convergence time, relative
error, and scalability. We also assess the ability of ATLAS to
adapt in more dynamic network conditions.
To the best of our knowledge, ATLAS is the first
scheduled MAC protocol able to adapt to changes in
topology and load that is competitive with contentionbased protocols in throughput and delay while realizing

1536-1233 ß 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.

2256

IEEE TRANSACTIONS ON MOBILE COMPUTING,

superior delay variance. It achieves this through the continuous computation of the TLA allocation, and updating
the schedule on-the-fly. These updates occur only where
and when needed. By not requiring phases of execution
and by computing persistences rather than conflict-free
schedules, ATLAS eliminates the complexity of, and lag
inherent in, topology-dependent approaches. By not
being dependent on the identity of neighbours, ATLAS
shares the best of topology-transparent schemes (and
also their potential for collisions) yet overcomes their
weakness by being adaptive. By not forcing updates to
be frame synchronized, ATLAS shares the critical features of continuous adaptation with contention-based
protocols. As a result, ATLAS achieves predictable
throughput and delay characteristics. Such characteristics
and information about localized capacity at the MAC
layer may be used to inform higher layers, while end-toend characteristics at higher layers may be used to
inform ATLAS. This may support the development of an
agile, higher performing protocol stack.
The primary contributions of this paper are twofold:
(1) The REACT algorithm, an asynchronous, adaptive,
and distributed auction that solves a general resource
allocation problem to produce the TLA allocation.
(2) ATLAS, a MAC protocol that uses REACT to solve
the specific problem of channel allocation in a wireless
network where each node produces a random schedule
with the number of transmission slots determined by its
allocation.
The sequel is organized as follows: Section 2 defines a
general resource allocation problem and presents the
REACT algorithm, proving its correctness. Section 3
expresses channel allocation as a resource allocation problem and defines ATLAS. Related work is described in
Section 4. After describing the simulation set-up in Section 5,
Section 6 studies how ATLAS adapts to controlled changes
in topology and load, and to dynamic network conditions.
In Section 7, we discuss open issues and potential applications of REACT, including the design of higher-layer services that inform, and are informed by, the underlying
communication channel.

DISTRIBUTED RESOURCE
ALLOCATION—REACT

We consider a general resource allocation problem. Let R be
a set of N resources with capacity c ¼ ðc1 ; . . . ; cN Þ. Let D be a
set of M demands with magnitudes w ¼ ðw1 ; . . . ; wM Þ.
Resource j 2 R is required by demands Dj  D. Demand
i 2 D consumes capacity at all resources in Ri  R simultaneously. The resource allocation s ¼ ðs1 ; . . . ; sM Þ, si  0
defines the capacity reserved for the demands. Resource
P
allocation s is feasible if
i2Dj si  cj for all j 2 R and
si  wi for all i 2 D. Demand i is satisfied if si  wi . Resource
P
j is saturated if i2Dj si  cj . Throughout, capacity refers to
the magnitude of a resource.
Definition 1. [22] A feasible allocation s is lexicographically
max-min if, for every demand i 2 D, either i is satisfied, or
there exists a saturated resource j with i 2 Dj where
si ¼ maxðsk : k 2 Dj Þ.

NO. 10,

OCTOBER 2014

We now describe REACT, a distributed auction that
computes the lexicographic max-min allocation. In it,
resources are represented by auctioneers and demands
by bidders. Each auctioneer maintains an offer—the maximum capacity consumed by any adjacent bidder—and
each bidder maintains a claim—the capacity the bidder
intends to consume at adjacent auctions. The final claim
of bidder i defines allocation si . Auctioneer j satisfies
Defintion 1 locally by increasing its offer in an attempt
to become saturated while maintaining a feasible allocation. Bidder i satisfies Definition 1 locally for demand i
by increasing its claim until it is satisfied or has a maximal claim at an adjacent auction. Through continuous
updates of offers and claims, the auctioneers and bidders
eventually converge on the lexicographic max-min allocation. We give precise definitions of auction and bidder
behaviour next.
Bidder i knows wi and maintains set Ri . Offers are
stored in offers½ ; offers½j holds the offer last received
from auctioneer j. Bidder i constrains its claim to be
no larger than wi or the smallest offer from auctioneers
in Ri ,
claim ¼ minðfoffers½j : j 2 Ri g; wi Þ:

(1)

Auctioneer j knows cj and maintains set Dj . Bidder
claims are stored in claims[]; claims[i] holds the claim
last received from bidder i. Auctioneer j identifies set
Dj  Dj containing bidders with claims strictly smaller
than its offer,
Dj ¼ fb : b 2 Dj ; claims½b < offerg:

(2)

Bidders in Dj are either satisfied or are constrained by
another auction and cannot increase their claims in response
to a larger offer from auctioneer j. Bidders in Dj n Dj are
constrained by auction j. They may increase their claims in
response to a larger offer. Resources left unclaimed by bidders in Dj ,

Aj ¼ cj 

2

VOL. 13,

P

i2Dj


claims½i ;

(3)

remain available to be offered in equal portions to bidders in Dj n Dj . If claims of all bidders in Dj are smaller
than the offer (i.e., Dj ¼ Dj ), there are no bidders to
share the available resources in Aj . The auctioneer sets
its offer to Aj plus the largest claim, ensuring that any
bidder in Dj can increase its claim to consume resources
in Aj :

offer ¼

Aj =jDj n Dj j;


Aj þ max claims½i : i 2 Dj ;

if Dj 6¼ Dj ;
(4)
otherwise:

Algorithms 1 and 2 describe actions taken by the bidders
and auctioneers of REACT in response to externally triggered events. Collectively, auctioneers and bidders know
the inputs to the allocation problem and bidder claims converge on the lexicographic max-min allocation; the claim of
bidder i converges on si .

LUTZ ET AL.: ATLAS: ADAPTIVE TOPOLOGY- AND LOAD-AWARE SCHEDULING

2257

Therefore, offers equal to omin remain smaller than offers
not from Astable .

The correctness of Algorithms 1 and 2 is established in two
steps: Lemma 1 establishes forward progress on the number
of auctioneers to have converged on their final offer.
Theorem 1 employs Lemma 1 to show eventual convergence to the lexicographic max-min allocation. Let claim i
denote the claim of bidder i and offer j the offer of auctioneer j. Assume that the resource allocation remains constant
for the period of analysis, that bidder i knows Ri and wi ,
and that auctioneer j knows Dj and cj . Further assume communication between adjacent auctioneers and bidders is not
delayed indefinitely. A claim or offer is stable if it has converged
on its final value. Denote by Astable the set of auctioneers whose
offers are stable and remain the smallest among all offers.
Lemma 1. Suppose Astable contains k auctioneers, 0  k < N.
Then, within finite time, at least one auctioneer converges on
the next smallest offer omin . Offers equal to omin are stable and
remain smaller than all other offers not in Astable .
Proof. Wait sufficient time for every bidder i to send a new
claim to auctioneers in Ri and for every auctioneer j to
send a new offer to bidders in Dj . Let omin be the smallest
offer of an auctioneer not in Astable . Assume to the con= Astable is the first to become
trary that offer x for some x 2
smaller than omin . By Eqs. (2) and (4), a decrease to offer x
can only occur after a bidder y at auction x with
claim y < offer x increases its claim. By Eq. (1), claimy can
increase only after its limiting constraint starts out
smaller than offer x and increases. Constraints in the system smaller than offer x are maximum claims, offers from
Astable , and offers equal to omin . Maximum claims and
offers from Astable do not change, leaving some x0 with
offer x0 ¼ omin as the only potential limiting constraint for
claim y . By Eqs. (2) and (4), offer x0 can increase only after
one of its bidders y0 reduces its claim to be smaller than
offer x0 . By Eq. (1), claim y0 can get smaller only after one of
its auctioneers, say x00 , reduces its offer to be
offer x00 < omin ¼ offer x0 contradicting the assumption
that offer x is the first to become smaller than omin .

By Eqs. (2) and (4), any j offering omin can change only
after a bidder i at auction j with claim i  omin changes.
By Eq. (1), claimi only changes if its limiting constraint
changes. Potential limiting constraints include wi , offers
from Astable , and offers equal to omin . These constraints
u
t
are stable; therefore, offers equal to omin are stable.
Theorem 1. Bidders and auctioneers of Algorithms 1 and 2 compute the lexicographic max-min allocation.
Proof. We apply Lemma 1 to show by induction that every
auctioneer eventually computes a stable offer.
Base Case: Consider an allocation problem with arbitrary wi , cj , Ri , and Dj for 1  i  M, 1  j  N. Let
jAstable j ¼ 0. By Lemma 1, at least one auctioneer eventually converges on a smallest offer omin . Offers equal to
omin are stable and remain smallest among all offers. Add
auctioneers offering omin to Astable ; jAstable j  1.
Inductive Step: Let jAstable j ¼ k, 1  k < N. Then, by
Lemma 1 a non-empty set of auctioneers Aþ with
Aþ \ Astable ¼ ; eventually converge on the next smallest

2258

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 13,

NO. 10,

OCTOBER 2014

Fig. 1. Example transmissions in ATLAS of two packets in a network of
three fully connected nodes. The first packet is sent from node A to
node C. The second packet is sent from node C to node B. Transmissions are colored white and receptions are shaded grey. The frame
structure is shown for a data packet and an acknowledgement.

offer. Offers from Aþ remain smaller than offers not from
Aþ or Astable and are stable. Add Aþ to Astable ; jAstable j 
k þ 1.
By induction, all auctioneers are eventually added to
Astable . Wait for auctioneers to send their offers to adjacent bidders. Bidder claims are now stable. By Eq. 1, bidder i is either satisfied with its claim (claimi ¼ wi ) or its
claim is maximal at an auction in Ri . By Definition 1, the
claims are lexicographic max-min.
u
t

3

THE ATLAS MAC PROTOCOL

Channel allocation in wireless networks can be expressed as
a resource allocation problem. In this context, transmitters
correspond to the demands in D and receivers to the resources in R. Label transmitters f1; . . . ; Mg and receivers
f1; . . . ; Ng. A transmitter with a non-zero demand magnitude is active. Receiver j is in Ri if it is within transmission
range of transmitter i and transmitter i is active. Dj contains
the active transmitters for which receiver j is within transmission range. Receiver j is adjacent to transmitter i if j 2 Ri
and i 2 Dj . The sets Dj and Ri capture the network topology for active transmitters. For load, wi is set to the percentage of slots required to support the demand at transmitter i.
Transmitters with no demand (i.e., wi ¼ 0) receive an allocation of zero slots: they are not active. Receiver capacities are
set to one, targeting 100 percent channel allocation. The lexicographic max-min solution s ¼ ðs1 ; . . . ; sM Þ for a given
topology and traffic load is the TLA allocation.
To apply REACT to channel allocation, we integrate it
into ATLAS, a simple random scheduled MAC protocol.
Although REACT could instead augment contention-based
schemes, we choose to work within a scheduled environment, a traditionally difficult setting for adaptation. In
ATLAS, each node runs a REACT bidder (Algorithm 1) and
a REACT auctioneer (Algorithm 2) continuously. Auctioneers and bidders discover each other as they hear from one
another and rely on the host node to detect lost adjacencies.
The network topology is implicit in the sets Ri and Dj . Each
node updates its bidder’s demand magnitude to accurately
reflect its traffic load. Offers and claims are encoded using
eight bits each and are embedded within the MAC header
of all transmissions to be piggybacked on existing network
traffic. The encoding supports a total of 256 values for
offers, claims, and persistences uniformly distributed
between 0 and 1; the error in the representation does not
exceed 0.004. Adding fields for an offer and claim to data

Fig. 2. Example network showing the TLA allocation computed by
REACT before and after an added link in the topology. wi identifies a
node’s demand, si its initial TLA allocation, and si its TLA allocation after
the added link. Resource capacities are set to one. Double-lined circles
identify nodes with saturated resources.

packets and acknowledgements results in a communication
overhead of four bytes per packet. For the slot size and data
rate simulated in Section 6, the overhead is 0.36 percent. A
node’s offer and claim are eventually received by all singlehop neighbours reaching the bidders and auctioneers that
need to know the offer and claim. In time, the bidder claims
in REACT converge on the TLA allocation s .
Packets are acknowledged within the slot they are transmitted and slots are sized accordingly. Unacknowledged
MAC packets are retransmitted up to ten times before they
are dropped by the sender. Fig. 1 shows that collisions are
possible in ATLAS, and that successful transmissions are
acknowledged in the same slot. The transmissions collide in
slot x; they are repeated (successfully) in slots x þ 2 and
x þ 3. Fig. 1 also shows the frame structure.
The TLA allocation can be interpreted directly as a set of
persistences in a p-persistent MAC [28]. However, we
achieve lower variation in delay by introducing the notion
of a frame [6]. Specifically, ATLAS divides time into slots
which are organized into frames of v slots. Node i operates
at persistence pi ¼ si . At the start of every frame and upon
any change to pi , node i computes ki ¼ bpi vc þ 1 with probability pi and ki ¼ bpi vc with probability 1  pi where
pi ¼ pi v  bpi vc. Node i constructs a transmission schedule
of ki slots selected uniformly at random. Over many frames,
E½ki =v equals pi where E½ki  is the expectation for ki .
Fig. 2 shows the TLA allocation in a small example network before and after a change in topology. Node 7 starts
out disconnected from the other nodes and moves within
range of node 3. In REACT, node 3 starts out offering 0.25
which is claimed by the bidders of nodes 1, 2, 3, and 4. With
the claims of node 3 and 4 limited by the offer of node 3 and
the claim of node 6 limited by its demand, the auctioneer at
node 4 is free to offer 0.45, which is claimed by node 5.
Upon detecting node 7 as a neighbour, the auctioneer at
node 3 decreases its offer to 0.20. The bidders at nodes 1, 2,
3, 4, and 7 respond by reducing their claims accordingly.
The smaller claims of the bidders at nodes 3 and 4 allow the
auctioneer at node 4 to increase its offer to 0.55. The bidder
at node 5 responds by increasing its claim to 0.55. It can be

LUTZ ET AL.: ATLAS: ADAPTIVE TOPOLOGY- AND LOAD-AWARE SCHEDULING

verified that, before and after the topology change, the
claims of the bidders (i.e., the values of si and si ) are lexicographically max-min; that is, every claim is satisfied or is
maximal at an adjacent auction. Consider the topology with
node 3 and node 7 connected. The bidder at node 6 is satisfied. The bidders at nodes 1, 2, 3, 4, and 7 are maximal at the
auction of node 3. The bidder at node 5 is maximal at the
auction of node 4.
There are many implementation choices to be made in
applying REACT to channel allocation. We identify three
binary choices—lazy or eager persistences, physical layer or
MAC layer receivers, and weighted or non-weighted bidders—and three configurable parameters—pmin , pdefault , and
tlostNbr . The choices are described here; they are evaluated in
Section 6.

3.1 Lazy or Eager Persistences
A lazy approach sets persistence pi equal to the claim of bidder i. Once converged, pi matches the TLA allocation interpreted as a persistence. There is a potential disadvantage
with being lazy. For many applications, nodes cannot predict future demand for the channel; they can only estimate
demand based on past events, i.e., packet arrival rate or
queue depth. As a consequence, wi lags the true magnitude
of the demand at node i. If wi is the limiting constraint for
the claim of bidder i, pi can be sluggish in response to
increases in demand. Alternatively, an eager approach sets
persistence pi ¼ minðoffers½j : j 2 Ri Þ, breaking the direct
dependence on wi . Under stable conditions, a node’s channel occupancy, the fraction of time it spends transmitting,
matches its TLA allocation; its occupancy is limited by the
availability of packets to transmit which is no larger than
wi , even when pi > wi . By allowing pi > wi , the persistence
is made more responsive to sudden increases in demand.
3.2 Physical Layer or MAC Layer Receivers
A central objective of the TLA allocation is to ensure that no
receiver is overrun. In a wireless network, receivers can be
defined in terms of physical layer or MAC layer communication. At the physical layer, every node is a receiver. At the
MAC layer, packets are filtered by destination address; a
node is only a receiver if one of its neighbours has MAC
packets destined to it. MAC layer receivers can increase
channel allocation by over-allocating at non-receiving
nodes. However, the overallocation can slow detection of
new receivers. Physical receivers prevent overallocation at
any receiver, making the allocation more responsive to
changes in traffic where nodes become receivers.
3.3 Weighted or Non-Weighted Bidders
We have described a MAC protocol where transmitters are
represented by equally weighted bidders. For applications
requiring multiple demands per transmitter, i.e., nodes servicing more than one traffic flow, we propose the weighted
TLA allocation. The demands of weighted bidders are comprised of one or more demand fragments; the number of fragments accumulated into a demand is the demand’s weight.
Let g i be the weight for demand i. Demand fragments in
demand i have magnitude wi =g i . The weighted TLA allocation defines the lexicographically max-min vector

2259

u ¼ ðu1 ; . . . ; uN Þ where ui is the allocation to each demand
fragment in demand i for a total allocation of ui g i to
demand i. REACT can be extended to compute the
weighted TLA allocation. To do this, each bidder must
inform adjacent auctions of its weight.

3.4 Minimum Persistence pmin
A node can maintain a persistence of zero without impacting the communication requirements of its bidder. For auctioneers, a persistence of zero is problematic. If a receiver
becomes overwhelmed by neighbouring transmitters, a
non-zero persistence is needed to quiet the neighbours. To
accomplish this, the node enforces a minimum persistence
pmin , creating dummy packets if necessary, whenever the
sum of claims from adjacent bidders exceeds the auction
capacity.
3.5 Overriding the TLA Allocation with pdefault
There are two conditions where a node constrains its persistence to be no larger than pdefault . The first is when it has no
neighbours. While the TLA allocation permits an isolated
node to consume 100 percent of the channel, it cannot discover new neighbours if it does so. The second time a node
employs pdefault is for a short period after the discovery of a
new neighbour. It is possible for several nodes operating
with large persistences to join a neighbourhood at about the
same time. If the persistences are large enough, neighbour
discovery can be hindered. For both scenarios, limiting the
persistence to pdefault facilitates efficient neighbour
discovery.
3.6 Adaptation to Topology Changes and tlostNbr
Changes in network topology are detected externally to
REACT. In ATLAS, neighbour discovery is performed independently by each node. If a node hears from a new neighbour, then the node notifies its bidder of the new auction
and its auctioneer of the new bidder. Conversely, if a node
has not heard from a neighbour in more than tlostNbr seconds, it presumes the node is no longer a neighbour and
informs its auctioneer and bidder accordingly.

4

RELATED WORK

This paper focuses on the TLA allocation, its continuous distributed computation, and its application to setting transmitter persistences. In this section, we review a
representative set of scheduled MAC protocols, observing
how each selects a node’s persistence and adapts to topology and load.
Any finite schedule used in a cyclically repeated way can
be generalized as a ðk; vÞ-schedule with k transmission slots
per frame of v slots, producing an effective persistence of
p ¼ k=v. Examples include the random schedules of [6], [18]
where each node selects its k transmission slots randomly
from the set of v slots in the frame. Topology transparent
schemes [3], [15], [27] also implement ðk; vÞ-schedules.
These schedules rely on only two design parameters: N, the
number of nodes in the network, and Dmax , the maximum
supported neighbourhood size. These schedules guarantee
each node a collision-free transmission opportunity from
each of its neighbours at least once per frame, provided the

2260

IEEE TRANSACTIONS ON MOBILE COMPUTING,

node’s neighbourhood size does not exceed Dmax .
ðk; vÞ-schedules do not adapt to variations in neighbourhood size or traffic load. The combinatorial requirements
for variable-weight topology transparent schedules (variable k) are explored in [19], but no construction nor protocol
using them is given.
A class of topology-dependent scheduled protocols compute distance-2 vertex colorings of the network graph to
achieve TDMA schedules with spatial reuse. The colorings
assign one transmission slot to each node and do not adapt
to traffic load. One of the first distributed protocols to
bound the number of colors is proposed in [5]. DistributedRAND (DRAND) [25] is a distributed implementation of
RAND (a centralized algorithm for distance-2 coloring [23]).
DRAND runs a series of loosely synchronized rounds. A
color is assigned in each round to one or more nodes in different two-hop neighbourhoods. DRAND is employed by
Zebra-MAC (Z-MAC) [24] to compute schedules over which
to run CSMA/CA. Nodes are given priority access to their
own slot, but also allowed to contend for access in other
unused slots, as is done in [4]. Due to the complexity of
DRAND, schedules are only computed once during network initialization.
Other topology-dependent schemes support variable
persistences. The periodic slot chains proposed in [14] are
not limited to the structure of a fixed length frame and can
support variable and arbitrarily precise persistences. A slot
chain is defined by its starting transmission slot and period
between its consecutive transmission slots. By combining
multiple slot chains with different periods, schedules are
constructed targeting any rational persistence in the range
½0; 1. The computation of slot chains provided in [14] is centralized; a distributed mechanism to adaptively compute
the slot chains remains an open problem. In [30], a five
phase reservation protocol (FPRP) computes conflict-free
schedules where a node can reserve one or more transmission slots in the frame to achieve variable persistences. Reservation frames are run periodically rather than on a
demand basis and, therefore, may not accommodate the
current topology and traffic load.
In SEEDEX [26], nodes do not attempt to derive conflictfree schedules. They learn the identities of their two-hop
neighbours and adjust transmission probabilities (i.e., persistences) to improve the likelihood of collision-free transmissions. The transmission probabilities accommodate the
number and identity of neighbours, but not traffic load.
In our earlier work [20], a distributed algorithm for computing the TLA allocation is provided; however, the algorithm assumes a fixed topology and does not adapt to
changes in the network. REACT solves these limitations by
asynchronously adapting to changes in both topology and
traffic demand.

5

SIMULATION SET-UP

We now describe the simulations used to produce the
experimental results presented in Section 6. Table 1 lists the
four ATLAS configurations simulated. The Nominal configuration employs eager persistences, defines receivers in
terms of MAC layer communication, and operates with
unweighted bidders. The other three configurations differ

VOL. 13,

NO. 10,

OCTOBER 2014

TABLE 1
ATLAS Configurations Selected for Simulation

from the Nominal case by a single choice and are named
accordingly.

5.1 Scenario Details
Unless otherwise noted, all four configurations run with
pdefault ¼ 0:05, tlostNbr ¼ 0:5s, and pmin ¼ 0:01. The selection
of pdefault and tlostNbr are justified by results in Figs. 5, 11a,
and 11b. The selection of pmin is based on [20]. Frames contain v ¼ 100 slots of length 800 ms (1,100 bytes per slot). Simulations are run using the ns-2 simulator [21]. Each
wireless node is equipped with a single half-duplex transceiver and omni-directional antenna whose physical properties match those of the 914 MHz Lucent WaveLAN DSS
radio. The data rate for all simulations is 11 Mbps. The
transmission and carrier sense ranges are 250 m.
Each simulation runs a network scenario composed of a
randomly generated topology and a randomly generated
traffic load. Unless specified otherwise, topologies contain
50 randomly placed nodes constrained to a 300 	 1500m2
area. With the exception of the multi-hop TCP flows in Section 6.6, each traffic load consists of single-hop constant rate
traffic. Four traffic loads are simulated: 20 and 80 percent of
nodes loaded with small demands (75 
 50 pkts/s), 20
and 80 percent of nodes loaded with large demands
(500 
 50 pkts/s). Nodes loaded with traffic are selected at
random and the demand magnitudes are selected uniformly
at random from the specified range. The packet destination
is selected dynamically from the set of neighbouring nodes
as the packet is passed down to the MAC layer. For the
Weighted Bidders configuration, each demand is assigned a
random integer weight between one and five. Traffic is generated by constant bit rate generators and transported over
UDP; packets are 900 bytes in length, leaving room in each
slot for header bytes and a MAC layer acknowledgement.
Combined with the random placement of nodes and the
addition of mobility, these four traffic loads enable simulation of a wide variety of network conditions.
5.2 Relative Error
A metric of interest is the average relative error for a node’s
persistence with respect to the TLA allocation. Error is
reported in two parts: relative excess and deficit persistence
error. Errors are measured per node over 80 ms consecutive
intervals in time (equal to the length of one MAC frame).
We compute the average relative excess error and average
relative deficit error for a given sample set of persistence
measurements. The relative errors are ratios, requiring use
of the geometric rather than arithmetic mean. But, the errors
are often zero, preventing direct use of their mean. Instead,
we convert errors into accuracies eliminating zeros from the
data set for a more meaningful geometric average. The average relative accuracies are converted back to relative errors.

LUTZ ET AL.: ATLAS: ADAPTIVE TOPOLOGY- AND LOAD-AWARE SCHEDULING

2261

Fig. 3. Convergence time following network initialization.
Fig. 5. Convergence times when run with varying default persistences.

6

EVALUATION OF ATLAS

Results from [20] show the TLA allocation applied in a static
network to maintain expected delay and throughput compared to IEEE 802.11, while reducing the variance for both
metrics. The TLA allocation nearly eliminates packets
dropped by the MAC layer. In this section, we build on
these results, focusing on the efficient distributed computation of the TLA allocation in the face of changes in topology
and load. The results presented here work to answer four
questions:
1.
2.
3.

Can ATLAS converge quickly on the TLA allocation?
Can ATLAS scale to larger networks?
Can ATLAS keep up with changes in a mobile
network?
4. Can ATLAS adapt to multi-hop traffic flows?
The first question is addressed Sections 6.1, 6.2, and 6.3.
The second is addressed in Section 6.4. The third and fourth
questions are addressed in Sections 6.5 and 6.6, respectively.
Continuing the focus on adaptation, Section 6.7 provides
comparisons with several scheduled protocols.

6.1 Convergence After Network Initialization
Fig. 3 reports average convergence times for all four ATLAS
configurations. Error bars denote the arithmetic standard
deviation from the mean for each sample set. Convergence
is measured from network initialization (time ¼ 0) to the
time ATLAS converges on the TLA allocation. Times are
collected from simulations of 1,000 network scenarios simulated four times each, once per configuration. There are 250
scenarios for each traffic load.

Fig. 4. Relative persistence error for ATLAS.

The physical receivers configuration converges fastest, in
less than 0.4 s on average for networks with 40 large
demands and faster for other traffic loads. The extra step of
detecting MAC receivers slows convergence. The lazy persistences configuration is the slowest with an average convergence time of 0.67 s for networks with 40 large demands.
The strict limit on persistences enforced by this configuration slows convergence compared to the others.
Fig. 4a shows average excess and deficit relative persistence errors for all four configurations. The averages are
computed for nodes with a non-zero TLA allocation and
only during convergence. Nodes are observed to operate
within approximately 20 percent of their TLA allocation
regardless of configuration. Deficit errors are larger than
excess errors reflecting a tendency to converge from below,
rather than above, the TLA allocation. In Fig. 4b, each data
point reflects the convergence time (x-coordinate) and total
relative persistence error (y-coordinate) for one simulation
of the nominal configuration. The data shows relative persistence error to be fairly consistent from network to network with a maximum observed error of 27 percent.
Fig. 5 reports convergence time for the Nominal configuration while varying pdefault . Convergence is measured
for simulations of 1,000 network scenarios, 250 of each
traffic load. The scenarios are simulated eight times each,
once per default persistence: 0.001, 0.005, 0.01, 0.05, 0.1,
0.2, 0.3, and 0.4. Small default persistences (pdefault  0:01)
limit a node’s ability to communicate during neighbour
discovery, slowing convergence. Large default persistences (pdefault  0:3) permit nodes to transmit with large

2262

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 13,

NO. 10,

OCTOBER 2014

Fig. 6. Convergence time and relative persistence error during convergence following a single demand change.

persistences before they discover their neighbours. In networks with 40 large demands, the large persistences can
overwhelm the channel preventing neighbour discovery
and delaying convergence. ATLAS is robust to the selection of pdefault with a suitable range of ½0:05–0:2. For the
remaining simulations, pdefault is 0.05.

6.2 Convergence After a Change in Demand
Fig. 6 reports convergence times and relative persistence
errors for the Nominal configuration following a change
to a single demand magnitude. Four types of demand are
simulated: a new small demand, a new large demand, a
removed small demand, and a removed large demand.
New demands start with magnitude zero and change to
75 
 50 pkts/s for small demands and to 500 
 50 pkts/s
for large demands. Removed small demands and
removed large demands start at 75 
 50 pkts/s and at
500 
 50 pkts/s, respectively; both change to zero. The
four demand change types are simulated under the four
traffic loads. REACT is allowed to converge on the initial
TLA allocation prior to the demand change. Convergence
times and error measurements are taken from simulations
of 4,000 network scenarios, 250 for each of the 16 demand
change and traffic load combinations.
Fig. 6a reports convergence times measured from the
time of the change to the time of convergence on the
new TLA allocation. The largest convergence times of
approximately 0.175 s are found in networks loaded
with 40 demands. The average convergence time for the

other scenarios is 0.125 s or smaller. Fig. 6b shows relative persistence errors measured during convergence at
nodes whose TLA allocation are affected by the demand
change. Persistences are observed to be within 10 percent
of the TLA allocation.

6.3 Convergence After a Change in Topology
Fig. 7 reports convergence time and relative persistence
error following two types of topology change: the creation
of a link and the removal of a link between a pair of nodes.
Simulations are run on 2,000 network scenarios, 250 for
each topology change type and traffic load combination.
Networks that lose a link are simulated once per neighbour
timeout tlostNbr of 0.5, 2.0 and 5.0 s.
Network topologies are generated as follows. A first
node is placed at a random location in the simulation area.
For topologies gaining a link, a second node is placed just
outside the transmission range of the first node with a trajectory toward the first node. For topologies losing a link, the
second node is placed just inside the transmission range of
the first node with a trajectory away from the first node. The
remaining 48 nodes are placed at random locations in the
simulation area. The distance travelled by the second node
is constrained to avoid unintentional topology changes.
The expected convergence time following the addition
of a new link is 0.025 s. For tlostNbr ¼ 0.5 s, convergence is
reached in less than 0.13 s on average. For tlostNbr ¼ 2.0 s
and tlostNbr ¼ 5.0 s, the large convergence times are dominated by tlostNbr . Except for the simulations of Fig. 11, all

Fig. 7. Convergence time and relative persistence error following a single topology change.

LUTZ ET AL.: ATLAS: ADAPTIVE TOPOLOGY- AND LOAD-AWARE SCHEDULING

2263

Fig. 8. Convergence times as the width of the network grows.

Fig. 9. Average range of impact for a demand or topology change.

others configure ATLAS with tlostNbr ¼ 0.5 s. During convergence, nodes affected by the topology change are
observed to operate within 4 percent of their TLA allocation on average. These numbers are striking. The small
convergence times stem from a counterintuitive feature
of the TLA allocation: the majority of topology changes
do not affect the TLA allocation. A new link only has an
effect if the link connects a bidder with an auction that
lacks the capacity to support the bidder’s claim. Even in
heavily loaded networks, many auctions have spare
capacity to support a new bidder. For these scenarios,
convergence is instantaneous.

response. Distances are reported in hops. A node that
changes its demand or gains/loses a neighbour has distance
zero. Neighbours of this node have distance one, and so on.
Range of impact is reported for the six types of change evaluated in Sections 6.2 and 6.3. Each type of change is simulated in 1,000 network scenarios, 250 of each traffic load.
The range of impact is less than 1.75 hops on average.

6.4 Scalability to Large Networks
We now turn to results demonstrating ATLAS’s scalability.
We simulate 10 network sizes with the x-dimension ranging
from 600 m (2.4 hops) to 6,000 m (24 hops) in 600 m increments; the y-dimension is held constant at 300 m. The number of nodes is selected to keep the average neighbourhood
density constant across all network sizes. Fig. 8 reports convergence times for 4,000 network scenarios, 100 of each traffic load and network size combination. The convergence
time of ATLAS in large networks is striking with a mere
40 percent increase for networks spanning 24 hops compared those spanning only 4.8 hops.
The impressive convergence times, particularly those of
networks spanning 12 or more hops, suggest that convergence happens locally, allowing distant neighbourhoods to
converge in parallel. This local behaviour is captured in
Fig. 9 which reports the average distance between a network
change and a node whose bidder changes its claim in

6.5 Performance with Node Mobility
Section 6.3 addresses the robustness of ATLAS to single
topology changes. We now evaluate its performance in networks with continuous mobility which may not have the
opportunity to converge on the TLA allocation.
Fig. 10a reports persistence error for node speeds ranging
from 0 to 120 m/s with 200 scenarios simulated for each
node speed, 50 of each traffic load. Node movements are
generated using the steady-state mobility model generator
of [13] with a pause time of zero. Simulations are run for
20 s. As node speeds increase, so do deficit persistence
errors. The larger deficit errors are an artifact of lost neighbour detection which is delayed by tlostNbr ¼ 0:5 s. As a
result, nodes tend to think their neighbourhoods are more
crowded than they are, a tendency that gets worse as node
speeds increase. In terms of REACT, auctioneers and bidders unnecessarily constrain their offers and claims to
accommodate lost neighbours. The deficit persistences
translate to degraded throughput. Fig. 10b reports MAC
throughput for the simulations of Fig. 10 a. Even with node
speeds of 120 m/s where a node travels its transmission
range in 2.1 s, throughput degrades modestly, decreasing
by less than 20 percent compared to static networks.

Fig. 10. Relative persistence error and total MAC throughput for varying levels of node mobility.

2264

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 13,

NO. 10,

OCTOBER 2014

Fig. 11. Relative persistence error and total MAC throughput for varying neighbour timeouts.

Fig. 11 shows that a large tlostNbr exacerbates deficit persistence error and further degrades throughput. Data is collected from 200 scenarios, 50 of each traffic load. Each
scenario is simulated five times with neighbour timeouts
ranging from 0.1 to 15.0 s. Node speeds are fixed at 30 m/s.
Degraded performance is observed for large timeouts,
tlostNbr  0:5 s, but also for small timeouts, tlostNbr ¼ 0:1 s. In
networks loaded with 10 large demands, tlostNbr ¼ 0:1 s
causes nodes to falsely identify lost neighbours that must be
rediscovered. The remaining simulations are run with
tlostNbr ¼ 0:5 s.
Fig. 12 reports packet delay for ATLAS and IEEE 802.11
for the 200 network scenarios of Fig. 10 with node speeds
equal to 30 m/s. IEEE 802.11 is configured with a maximum
packet retry count of seven for RTS, CTS, and ACKs and
four for data packets [11], a mini-slot length of 20 ms, and
minimum and maximum contention window sizes of 32
and 1,024 slots, respectively. Each point in the scatter plot
reports the average packet delay (x-coordinate) and variation in packet delay (y-coordinate) for a single node. The
largest reported average delay is 0.047 s for ATLAS and
0.058 s for IEEE 802.11. The largest reported variation in
delay for ATLAS is 0.0016 s2 , just 3.6 percent of the 0.0444 s2
reported for IEEE 802.11. This impressive reduction in
delay variance is crucial to the support of TCP, which we
evaluate next.

6.6 Multi-Hop TCP Flows
To this point, we have used MAC layer traffic to simulate a
diverse set of network scenarios. We now evaluate the performance of ATLAS using multi-hop TCP flows. To accommodate the dynamic nature of these flows, each node
estimates its own demand by monitoring queue behaviour.

Fig. 12. Delays for ATLAS and IEEE 802.11 with node speeds of 30 m/s.

Demand is estimated as the sum of two parts: wenqueue and
wlevel . wenqueue is the percentage of channel required to keep
up with the current enqueue packet rate, wenqueue ¼
ðpacket enqueue rateÞ 	 ðslot lengthÞ. wlevel is the percentage
of channel required to transmit all packets in the queue
within 0.2 s (i.e., 25 slots), wlevel ¼ ½ð# packets in queueÞ=
0:02s 	 ðslot lengthÞ.
To avoid cross-layer interactions between the MAC and
routing protocols, Dijkstra’s shortest path algorithm [28]
using accurate knowledge of the global topology computes
the next hop address for all packet transmissions. FTP
agents emulate transfer of infinite size files to create flows
with throughput limited only by the performance of the network. Transfers start at time zero and run for 20 s. Nodes
are statically placed at random locations in a 300 	 1500m2
simulation area. The source and destination nodes for each
file transfer are selected at random. TCP Reno is configured
for selective acknowledgements, the extensions of RFC 1323
[1], 900 byte TCP segments, and a maximum congestion
window size of 32 packets. ACKs are not combined with
each other or with other data packets. Consequently, the
transmission of a single 40-byte TCP ACK consumes an
entire slot in ATLAS. Network scenarios are simulated for
three traffic loads: networks with 2, 8, and 25 TCP flows.
The number of replicates per traffic load are chosen so that
3000 TCP flows are simulated for each. Fifteen hundred scenarios are simulated with two TCP flows, 375 with eight
TCP flows, and 120 with 25 TCP flows.
We simulate TCP traffic on five MAC protocols: the four
configurations of ATLAS and IEEE 802.11. The configurations of ATLAS use pdefault ¼ 0:05, tlostNbr ¼ 0:5 s, and
pmin ¼ 0:01. IEEE 802.11 parameters match those described
in Section 6.5. Each node dynamically sets its bidder weight
to one or the number of outgoing TCP flows it services,
whichever is larger.
The 15 sub-plots in Fig. 13 show the percentage of flows
(y-axis) achieving a minimum throughput (x-axis). The distinguishing characteristics of the three unweighted ATLAS
configurations are seen in the throughput curves for networks with two flows. These networks are loaded lightly
enough for the auctions at non-receiver nodes to make a difference in the allocation, improving throughput for 2- and
4-hop flows. These networks also demonstrate how the longer initial packet delays of the lazy persistences configuration increase round trip time for 4- and 5-hop flows,
limiting TCP throughput.

LUTZ ET AL.: ATLAS: ADAPTIVE TOPOLOGY- AND LOAD-AWARE SCHEDULING

2265

Fig. 13. Percent of TCP flows (y-axis) achieving a minimum throughput (x-axis). Plots in the left, center, and right columns report on flows from simulations of 2, 8, and 25 flows, respectively. The plots in the top row report on all flows, regardless of hop count. Plots in the second, third, and fourth
rows report on 1-hop, 2-hop, and 3-hop flows, respectively. Plots in the fifth row report on 4- and 5-hop flows.

The weighted bidders configuration performs well for
multi-hop flows in networks with eight and 25 flows by
allocating more to multi-hop flows at the expense of single-hop flows. Because one-hop flows tend to achieve
higher throughput, the configuration maintains a tighter
variation in flow throughputs as indicated by the steeper
slope of the weighted bidders curve in the top right plot
of Fig. 13.
Regardless of configuration, ATLAS surpasses IEEE
802.11 in support of concurrent multi-hop flows. The
interaction between the IEEE 802.11 back-off algorithm
and TCP’s congestion control is well known [9]. In testbed
experiments, a single TCP flow with no competition has
difficulty reaching a destination four hops away [16]. Our
simulations corroborate these findings, as approximately
50 percent of the 4- and 5-hop flows report a throughput

of zero. For networks with 25 demands, nearly 75 percent
of 2-hop flows are non-functional; 3-, 4-, and 5-hop flows
are almost completely shut out. ATLAS throughput is
achieved, even though each 40-byte TCP ACK consumes
its own slot.

6.7 Comparison with Other Scheduled MAC
Protocols
Here, we compare the adaptation of ATLAS with several
other scheduled protocols including DRAND, Z-MAC,
FPRP, and SEEDEX. Although the first three compute conflict-free schedules, an NP-hard problem [7], a comparison
highlights the agility of ATLAS. Table 2 summarizes our
comparison, illustrating how the adaptation of ATLAS is
closer in kind to a contention-based protocol than to its
scheduled counterparts.

2266

IEEE TRANSACTIONS ON MOBILE COMPUTING,

TABLE 2
MAC Protocol Adaptive Capabilities

VOL. 13,

NO. 10,

OCTOBER 2014

required to trigger the schedule update. This coordination,
by itself, is a challenge in an ad hoc network. In contrast,
ATLAS does not employ a schedule computation (or a
neighbour discovery) phase and adapts continuously to
changes in both topology and traffic load.

7

DISCUSSION

In this section we discuss open issues and suggest potential
applications for REACT and ATLAS.

6.7.1 Adaptation to Topology Changes
For the simulations of Section 6.5, the number of neighbour
changes (i.e., gained or lost neighbours) per second experienced by a node is correlated to the node speed. When the
nodes move at 30 m/s, each node is expected to gain, or
lose, a neighbour 2.21 times per second; within 6.3 s, the
number of neighbour changes is expected to exceed the
neighbourhood size.
Based on the run times reported in [25] Fig. 10], we estimate DRAND to compute schedules for the networks in
Section 6.5 in approximately 4.9 s (adjusting for data rate
and a two-hop neighbourhood size of 27). In this time, the
topology changes caused by nodes moving at 30 m/s are
expected to invalidate the computed schedule. Z-MAC has
the same limitation and, although it compensates by running CSMA/CA to resolve collisions, it does not benefit
from its TDMA schedule when nodes are mobile. In [25],
the run times reported for FPRP schedule generation are
comparable to DRAND. For SEEDEX, nodes discover their
two-hop neighbours using a fan-in/fan-out procedure
described in [26]. However, a practical integration of the
procedure into the MAC protocol is not described or evaluated, preventing a comparison of its agility with other MAC
protocols. In contrast to the slow schedule computation
times of DRAND, Z-MAC, and FPRP, ATLAS is shown to
handle node speeds of up to 120 m/s with only moderate
degradation to MAC throughput.
6.7.2 Adaptation to Changes in Traffic Load
The persistences achieved by DRAND and SEEDEX are
dependent on topology alone; neither adapts to traffic load.
Although Z-MAC adapts to load, it does so by deviating
from its underlying schedule, which does not adapt. FPRP
can adapt to load by scheduling a variable number of slots
per node; this is done at the expense of both longer frame
lengths and longer run times for schedule computation. In
contrast, ATLAS adapts to traffic load, responding quickly
enough to establish and maintain multi-hop TCP flows.
6.7.3 Continuous Adaptation
Common to the scheduled schemes mentioned here is the
use of a distinct phase for schedule computation (or neighbour discovery for SEEDEX). The schedules must be
updated in order for the MAC to adapt. Any fixed period
between schedule updates must be selected a priori; it cannot be adjusted for variations in network mobility. If schedules are to be updated when needed, a mechanism is

7.1 Improved Reliable Transport
TCP’s congestion control algorithm is known to suffer crosslayer interactions with binary exponential back-off (BEB)
employed by IEEE 802.11 [9]. BEB is short term unfair,
allowing a single node to capture the channel at the expense
of its neighbours [2], [10] causing high variation in packet
delay and making it difficult for TCP to estimate round-trip
delay. Many TCP modifications have been proposed to
improve performance over wireless networks [17]. An alternative is to minimize packet loss and control variation in
packet delay at the MAC layer. ATLAS demonstrates a
remarkable control of variation in delay (Fig. 12) enabling
TCP to reliably support 3-, 4-, and 5-hop flows over heavily
loaded networks (Fig. 13). However, TCP throughput still
degrades considerably as the number of hops grows. Potential areas for future work include the integration of ATLAS
into a cross-layer solution for reliable transport over wireless networks and the use of REACT to inform TCP’s congestion window size.
7.2 Selection of Configurable Parameters
ATLAS has three configurable parameters: pdefault , tlostNbr ,
and pmin . Based on our simulations, [0.01-0.2] is an acceptable range for pdefault (Fig. 5) and [0.1-2 s] is an acceptable
range for tlostNbr (Figs. 11a and 11b). In [20], pmin ¼ 0.1s is
found to be acceptable for a protocol that enforces pmin at all
nodes and at all times. Because ATLAS employs pmin temporarily, and only when needed, it is less sensitive to the selection of pmin . Although results show ATLAS to be robust to
parameter selection, tuning may be required in other scenarios or in a hardware implementation.
7.3 Dynamic Selection of Auction Capacity
ATLAS targets 100 percent channel allocation by setting auction capacities in REACT to one. Although simulation results
show this to be an adequate choice, it is not clear whether
performance can be improved by under- or over-allocating
the channel. Indeed, optimal auction capacities (however
optimal is defined) are dependent on network topology and
quality of the communication channel. We leave a thorough
analysis of auction capacity selection to future work, pointing out here that REACT adapts continuously, allowing auction capacities to be adjusted dynamically, if necessary.
7.4 Potential Applications for REACT
The weighted TLA allocation opens doors for several potential uses. In the simulations of Section 6.6, a bidder’s weight
is set according to the number of flows it services. It may be
desirable to set weights according to queue levels, demand
magnitudes, neighbourhood sizes, node betweenness [8],

LUTZ ET AL.: ATLAS: ADAPTIVE TOPOLOGY- AND LOAD-AWARE SCHEDULING

position in a multicast/broadcast tree, or path hop count.
The key observation is that ATLAS maintains flexibility by
allowing nodes to define bidder weights arbitrarily to suit
the needs of the network.
While computation of persistences is the primary motivation for this work, REACT is not limited to this purpose. Consider the physical receivers configuration with
node demands set to one. The resulting allocation is independent of actions taken by the upper network layers
and, therefore, can inform decisions made by those layers.
It can serve as a measure of potential network congestion—small allocations are assigned in dense neighbourhoods containing many potentially active neighbours. The
routing protocol can use the allocation to discover alternate routes around congestion.
An intriguing application is the implementation of differentiated service at the MAC layer. IEEE 802.11e [12] enhances the distributed coordination function by implementing
four access categories; an instance of the back-off algorithm
is run per access category, each with its own queue. The
probability of transmission of each access category is manipulated independently through selection of contention window size and inter-frame space. This permits higher priority
traffic to capture the channel from lower priority traffic.
Similar results can be achieved by four instances of
REACT, each computing the allocation for a single access
category. Prioritization is achieved through dynamic coordination of the four auction capacities at each node. A
potential strategy sets the capacity for each access category
equal to one minus the allocation to higher priority access
categories. As a result, higher priority auctions are permitted to starve lower priority auctions of capacity, effectively
distributing channel access to high priority traffic. Alternatively, auction capacities can be selected to ensure a minimum or maximum percentage of the channel is offered to
an access category.
A network can run multiple instances of REACT. For
example, an instance of the physical receivers configuration
with all demands set to one can be run concurrently with
instances configured to support differentiated service.
Alternatively, multiple instances of REACT can be used to
allocate more than one set of resources concurrently.

7.5 Assumptions Made by ATLAS
Two key assumptions are made by ATLAS in its computation of the TLA allocation using REACT: (1) The offers and
claims received by a node are accurate. (2) The offers and
claims of a node are eventually received by all neighbouring
nodes. The first assumption is reasonable, provided
received packets are checked for errors by the link layer.
The second is almost certainly invalid; asymmetric communication, interference beyond the range of transmission, and
signal fading are common and can prevent the delivery of
offers and claims. Under realistic conditions, REACT may
not converge on the TLA allocation, risking over-allocation
of the channel. In practice, auctions can adjust their capacities to mitigate the over-allocation. Every node knows the
persistences of its neighbours (from bidder claims) and can
compute the expectation for collisions on the channel. Significant deviations above this expectation can trigger the
auction to lower its capacity. An evaluation in a testbed of

2267

real radios is necessary to understand the sensitivity to
anomalies on the wireless channel and the effectiveness of
adjusting auction capacities to accommodate channel conditions. Many technical details of the testbed are critical to the
understanding of the results produced. Omitting such
details make the results difficult to reproduce.
The evaluation of ATLAS in Section 6 assumes both slot
and frame synchronization; ATLAS requires neither. The
computation of the TLA allocation by REACT does not rely
on a frame structure and the expected performance of the
random schedules is not affected by loss of frame synchronization. Even without slot synchronization, REACT can
compute the TLA allocation; however, loss of slot synchronization may reduce channel capacity by 50 percent (see
Aloha versus slotted Aloha in [28]). ATLAS can accommodate the lower channel capacity by using a lower auction
capacity, potentially allowing ATLAS to run on commodity
IEEE 802.11 hardware [29] that lacks native support for slot
synchronization. This is a subject of our current research.

7.6 Enhancing Existing MAC Protocols
We have used REACT to compute persistences to be
employed within ATLAS, a slotted MAC protocol. Alternatively, REACT can be run on top of the IEEE 802.11 MAC by
embedding claims and offers in the headers of existing control and data messages. The TLA allocation can be used to
inform the selection of contention window sizes, eliminating the need for (and negative side effects of) binary exponential back off. We are currently working to integrate
REACT into IEEE 802.11. Another alternative (and more
ambitious) approach is to implement TLA persistences in a
topology-dependent MAC that computes conflict-free
schedules. Only a few topology-dependent schemes allow a
node to reserve more than one slot in a frame (i.e., [14],
[30]), and those do not define how many slots a node should
reserve. The TLA allocation can establish a permissible
number of slots to be reserved by each node, given the current topology and traffic load.

8

CONCLUSION

We have proposed REACT, a distributed auction that converges continuously on the TLA allocation, adapting to
changes in both topology and traffic load. The utility of
REACT is demonstrated through integration into the
ATLAS MAC protocol which we simulate under a wide
variety of network scenarios. The results suggest that
REACT can effectively inform the selection of transmitter
persistences, and that ATLAS can provide robust, reliable,
and scalable services. REACT has potential beyond the computation of transmitter persistences; it can inform routing
and admission control decisions, enable differentiation of
service at the MAC layer, and even allocate other node
resources. In this context, the REACT algorithm provides a
potential solution to the immediate challenge of medium
access control, but also shows promise as a tool for use in
network protocol design in general.

ACKNOWLEDGMENTS
The authors appreciate the useful comments provided by
the anonymous reviewers.

2268

IEEE TRANSACTIONS ON MOBILE COMPUTING,

REFERENCES
[1]
[2]
[3]

[4]

[5]

[6]

[7]
[8]
[9]

[10]
[11]
[12]
[13]
[14]
[15]

[16]

[17]

[18]

[19]
[20]
[21]
[22]
[23]

RFC 1323: TCP Extensions for High Performance, Internet Engineering Task Force (IETF). 1992.
V. Bharghavan, A. Demers, S. Shenker, and L. Zhang, “MACAW:
A Medium Access Protocol for Wireless LANs,” Proc. ACM
SIGCOMM ’94, pp. 212-225, 1994..
I. Chlamtac and A. Farag
o, “Making Transmission Schedules
Immune to Topology Changes in Multi-Hop Packet Radio
Networks,” IEEE/ACM Trans. Networking, vol. 2, no. 1, pp. 23-29,
Feb. 1994.
I. Chlamtac, A. Farag
o, A.D. Myers, V.R. Syrotiuk, and G. Z
aruba,
“ADAPT: A Dynamically Self-Adjusting Media Access Control
Protocol for Ad Hoc Networks.” Proc. IEEE GLOBECOM ’99,
pp. 11-15, 1999.
I. Chlamtac and S.S. Pinter, “Distributed Nodes Organization
Algorithm for Channel Access in a Multihop Dynamic Radio
Network,” IEEE Trans. Computers, vol. C-36, no. 6, pp. 728-737,
June 1987.
C.J. Colbourn and V.R. Syrotiuk, “Scheduled Persistence for
Medium Access Control in Sensor Networks,” Proc. IEEE First
Int’l Conf. Mobile Ad Hoc and Sensor Systems (MASS ’04), pp. 264273, 2004.
S. Even, O. Goldreich, S. Moran, and P. Tong, “On the NP-Completeness of Certain Network Testing Problems,” Networks,
vol. 14, no. 1, pp. 1-24, 1984.
L.C. Freeman, “A Set of Measures of Centrality Based on
Betweenness,” Sociometry, vol. 40, no. 1, pp. 35-41, 1977.
M. Gerla, R. Bagrodia, L. Zhang, K. Tang, and L. Wang, “TCP
over Wireless Multi-Hop Protocols: Simulation and
Experiments,” Proc. IEEE Int’l Conf. Comm. (ICC ’99), pp. 10891094, 1999.
J. Hastad, T. Leighton, and B. Rogoff, “Analysis of Backoff Protocols for Multiple Access Channels,” Proc. 19th Ann. ACM Symp.
Theory of Computing (STOC ’87), pp. 740-744, 1987.
IEEE 802.11, Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications, IEEE, 1997.
IEEE 802.11e, Enhancements: QoS, Including Packet Bursting, IEEE,
2007.
J. Boleng, N. Bauer, T. Camp, and W. Navidi, “Random Waypoint
Steady State Mobility Generator (mobgen-ss),” http://toilers.
mines.edu/, 2014.
G. Jakllari, M. Neufeld, and R. Ramanathan, “A Framework for
Frameless TDMA Using Slot Chains,” Proc. IEEE Ninth Int’l Conf.
Mobile Ad Hoc and Sensor Systems (MASS ’12), 2012.
J. Ju and V.O.K. Li, “An Optimal Topology-Transparent
Scheduling Method in Multihop Packet Radio Networks,”
IEEE/ACM Trans. Networking, vol. 6, no. 3, pp. 298-305, June
1998.
D. Koutsonikolas, J. Dyaberi, P. Garimella, S. Fahmy, and Y.C. Hu,
“On TCP Throughput and Window Size in a Multihop Wireless
Network Testbed,” Proc. ACM Second Int’l Workshop Wireless Network Testbeds, Experimental Evaluation and Characterization
(WiNTECH ’07), 2007.
K. Leung and V.O.K. Li, “Transmission Control Protocol (TCP) in
Wireless Networks: Issues, Approaches, and Challenges,” IEEE
Comm. Surveys & Tutorials, vol. 8, no. 4, pp. 64-79, Fourth quarter
2006.
J. Lutz, C.J. Colbourn, and V.R. Syrotiuk, “Apples and Oranges:
Comparing Schedule- and Contention-Based Medium Access
Control,” Proc. 13th ACM Int’l Conf. Modeling, Analysis and Simulation of Wireless and Mobile Systems (MSWiM ’10), pp. 319-326, 2010.
J. Lutz, C.J. Colbourn, and V.R. Syrotiuk, “Variable Weight
Sequences for Adaptive Scheduled Access in MANETs,” Proc.
Sequences and Their Applications (SETA ’12), pp. 53-64, 2012.
J. Lutz, C.J. Colbourn, and V.R. Syrotiuk, “Topological Persistence
for Medium Access Control,” IEEE Trans. Mobile Computing,
vol. 12, no. 8, pp. 1598-1612, Aug. 2013.
The Network Simulator ns-2. http://www.isi.edu/nsnam/ns/,
2014.
M. Pi
oro and D. Medhi, Routing, Flow, and Capacity Design in Communication and Computer Networks. Elsevier, 2004.
R. Ramanathan, “A Unified Framework and Algorithm for (T/F/C)
DMA Channel Assignment in Wireless Networks,” Proc. IEEE INFOCOM ’97, pp. 900-907, 1997.

VOL. 13,

NO. 10,

OCTOBER 2014

[24] I. Rhee, A. Warrier, M. Aia, J. Min, and M.L. Sichitiu, “Z-MAC: A
Hybrid MAC for Wireless Sensor Networks,” IEEE Trans. Networking, vol. 16, no. 3, pp. 511-524, June 2008.
[25] I. Rhee, A. Warrier, J. Min, and L. Xu, “DRAND: Distributed Randomized TDMA Scheduling for Wireless Ad-Hoc Networks,”
IEEE Trans. Mobile Computing, vol. 8, no. 10, pp. 1384-1396, Oct.
2009.
[26] R. Rozovsky and P.R. Kumar, “SEEDEX: A MAC Protocol for
Ad Hoc Networks,” Proc. ACM MOBIHOC ’01, pp. 67-75, 2001.
[27] V.R. Syrotiuk, C.J. Colbourn, and S. Yellamraju, “Rateless Forward Error Correction for Topology-Transparent Scheduling,”
IEEE/ACM Trans. Networking, vol. 16, no. 2, pp. 464-472, Apr. 2008.
[28] A.S. Tanenbaum, Computer Networks, fourth ed., McGraw Hill,
2003.
[29] I. Tinnirello, G. Bianchi, P. Gallo, D. Garlisi, F. Giuliano, and
F. Gringoli, “Wireless MAC Processors: Programming MAC Protocols on Commodity Hardware,” Proc. IEEE INFOCOM ’12,
pp. 1269-1277, 2012.
[30] C. Zhu and M.S. Corson, “A Five-Phase Reservation Protocol
(FPRP) for Mobile Ad Hoc Networks,” Wireless Networks, vol. 7,
no. 4, pp. 371-384, 2001.
Jonathan Lutz recieved the BS degree in electrical engineering from Arizona State University,
Tempe, Arizona, in 2000, the MS degree in computer engineering from the University of Waterloo,
Waterloo, Canada, in 2003, and the PhD degree in
computer science from Arizona State University, in
2013. His research interests include medium
access control in mobile ad hoc networks.

Charles J. Colbourn received the PhD degree
in 1980 from the University of Toronto, and is
a professor of computer science and engineering at Arizona State University. He is the
author of The Combinatorics of Network Reliability (Oxford), Triple Systems (Oxford), and
320 refereed journal papers focussing on combinatorial designs and graphs with applications
in networking, computing, and communications. In 2004, he was awarded the Euler
Medal for Lifetime Research Achievement by
the Institute for Combinatorics and its Applications.
Violet R. Syrotiuk received the PhD degree in
computer science from the University of Waterloo
(Canada). She is an associate professor of computer science and engineering at Arizona State
University. She serves on the editorial boards of
Computer Networks and Computer Communications, as well as on the technical program and
organizing committees of several major conferences sponsored by the ACM and the IEEE.

" For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

Demo - MAC Learning: Enabling Automatic Combination of
Elementary Protocol Components
Ilenia Tinnirello,
Domenico Garlisi,
Fabrizio Giuliano

Violet R. Syrotiuk

Giuseppe Bianchi

Arizona State University,
Tempe, AZ, USA

Universitá degli Studi di Roma
- Tor Vergata, Italy
giuseppe.bianchi@uniroma2.it

Universitá degli Studi di
Palermo, Italy
ilenia.tinnirello@tti.unipa.it

ABSTRACT
P2
P3

T I R BR E AB I I R

1
1

Protocol
Combination

t-7

t

w1 w2 w3 w4
P4 p p p

Upper-level
services
DATA

Protocol
Decision P(t+1)

Feedback y(t-7), y(t-6), .. y(t)

Wireless MAC Processor
Bytecode P1
Bytecode P2

XFSM ENGINE
DATA

1.

Meta-MAC
P1 1

y(t)={
Packet queue Q,
Transmitted A,
Transmitted Success T,
Transmit Other R,
Bad Reception E,
Busy slot B/I}

TX/RX DATA QUEUES

Cognition as a way to deal with the challenges of future
wireless networks has been largely considered by the recent
literature, with a main focus on physical layer adaptability
and dynamic spectrum access. In this demo, we show how a
simple cognition mechanism can be also applied at the MAC
layer, by exploiting the emerging paradigm of programmable
wireless cards. The idea is using the formal definition of
simple MAC protocol components and platform-independent
representation of channel events gathered from the wireless node, for emulating the behavior of protocols which are
not currently running on the network, learning about their
expected performance, and dynamically reconfiguring the
wireless node. We demonstrate that programmable nodes,
employing our cognition scheme, can find in a distributed
way a con-conflicting schedule with other neighbor nodes
and can switch from contention-based to scheduled-based
protocols as a function of the network load.

Channel

2,2ms

Figure 1: Implementation of Meta-MAC on top of
the WMP architecture

INTRODUCTION

MAC protocol adaptations have been largely considered
in the recent literature and emerging wireless standards, in
order to cope with changes in network topology and traffic load. The usual approach is including multiple operation mechanisms in the same protocol and enabling or disenabling these mechanisms by exploiting time division (i.e.,
by executing different access schemes in different time intervals) or explicit messages between the stations. For example,
in the Wi-Fi standard, a contention-based and a pollingbased access scheme are both included, while several advanced features, such as the direct or reverse link, can be
activated upon request. Usually, the activation of a specific
protocol feature is decided by the network administrators
or by the users, without automatic mechanisms for changing decisions under time-varying network conditions. Some
examples of implicit adaptations of MAC protocols exist.
Slotted p-persistence with dynamically adjusted retransmission probabilities p may be regarded as one. A more explicit

combination of protocols is the idea of protocol threading [1].
Here, the basic idea is to interleave several different schedules (lengths and persistence) on a time sharing basis.
A different approach for adaptation was proposed in the
meta-MAC framework [2]. It introduced a method to combine any set of existing protocols into a single MAC protocol.
The approach has been validated only in simulations, because its implementation poses several challenges. Indeed,
MAC protocols are usually hard-coded into the cards and
cannot be easily modified. Even assuming that it is possible
to access the firmware, any modification cannot be updated
at run time without writing and loading a new firmware.
In this demo we show how recent advances in programmable
radio platforms, and in particular the wireless MAC processor (WMP) [3] architecture, can make the implementation of
meta-MAC feasible on commercial wireless cards [4]. Indeed,
the WMP architecture allows to easily reprogram the card
behavior by loading a firmware configuration table which
codes a MAC protocol state machine, to trace channel and
hardware events directly at the firmware level, and to switch
from one protocol to another in a few microseconds. Our
demo shows how these features have been exploited for implementing the meta-MAC protocol and which performance
benefits can be achieved in real networks.

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).

WiNTECH’16 October 03-07 2016, New York City, NY, USA
c 2016 Copyright held by the owner/author(s).


2.

ACM ISBN 978-1-4503-4252-0/16/10.

THE META-MAC PROTOCOL

The basic idea of the Meta-MAC protocol is performing

DOI: http://dx.doi.org/10.1145/2980159.2980174

89

Throughput

thr [Mbps]

5

slot−Aloha

0

20

40

60
time [s]

80

100

120

Figure 2: Example of performance benefits achieved
under Meta-MAC.
channel access decisions by combining together the decisions
taken by multiple available protocols, which may include
completely different protocols or multiple instantiations of
the same protocol with different configuration parameters.
In the original version [2], the combined decision is given
by a weighted sum of the decisions taken by each protocol
component, which is randomly rounded to a transmit / nottransmit decision. A different solution, considered in this
demo, is considering the decision of the protocol which is
expected to give the best performance.
The protocol works as follows. Each node runs locally a
specific protocol Pi in the programmable wireless card, and
simulates the execution of all the other available protocols in
the card host. For simplicity, we consider a slotted channel.
Protocol simulation is based on the formal description of the
MAC protocols to be combined and on the channel feedback
provided by the wireless card. The same channel feedback
is then used, at the end of each slot, for updating the weight
of each protocol component as a function of its right/wrong
decision. While for protocol simulation the channel feedback
has to specify many different events (such as the reception
of a specific frame), for estimating the correctness of the
protocol decisions is generally enough to consider a ternary
feedback (transmission occurred, collision occurred, or idle
slot). Being Di,t the decision taken by the generic protocol
Pj and zt the correct decision (available a posteriori at the
end of the slot), the weights of each virtual protocol are
updated as wj,t+1 = wj,t · e−η|Dj,t −zt | . The constant η > 0
controls how fast the weights change. In case the weight of a
generic protocol Pj is higher than the running protocol one,
a protocol switching command is sent to the card.
Fig. 2 summarizes our Meta-MAC implementation on top
of the WMP architecture for wireless cards. At the end of
each slot, the WMP firmware saves six binary feedback variables (summarized in the top right corner of the figure) that
collectively describe the state of the transmission queue, the
protocol decision, the transmission outcome, and the slot
state. Meta-MAC is implemented in an host-level module,
responsible for retrieving and processing the feedback provided by the card and selecting the MAC component protocol to be activated.

3.

TDMA(1)
alix2

TDMA(2)

TDMA(3)

0.5

protocol weights

0

TDMA(0)

1

ALOHA
METAMAC

0
124.5

125

125.5

126

126.5

127

126

126.5

127

126

126.5

127

126

126.5

127

alix5

1
0.5
0
124.5

125

125.5
alix14

1
0.5
0
124.5

125

125.5
alix15

1
0.5
0
124.5

125

125.5
time [s]

Figure 3: Dynamic updates of each protocol weight
during the switch from Aloha to TDMA.
in a frame of configurable lengths.
For demonstrating the performance benefits in more general and realistic scenarios, we will run a remote demo in
our laboratory at the University of Palermo, where multiple
wireless nodes in radio visibility will run Meta-MAC. Starting from a slotted aloha protocol, we will show how the
nodes switch to TDMA protocols with non-conflicting assignments as the source rates increase to saturated network
conditions. Fig. 2 depicts the throughput results obtained
in an experiment example, where four nodes transmitted at
6 Mbps are loaded with traffic sources whose rate increases
every 30s. The figure compares the results achieved when all
the nodes statically run a p-persistent aloha protocol (blue
curve), and meta-MAC (red curve). Mete-MAC is able to
always achieve the best performance, switching to TDMA
in case of saturated traffic. The dynamic updates of the
protocol weights during the switching interval (that is not
synchronized among all the stations) are shown in Fig. 3.
In the future, it may be worth investigating how the metaMAC model can be generalized to non-slotted time.

Acknowledgments
This work is supported in part by the EU H2020 WiSHFUL
project, Grant No. 645274, and in part by the National
Science Foundation under Grant No. 142105.

4.

REFERENCES

[1] I. Chlamtac, A. Faragó, and H. Zhang, “Time-spread
multiple-access (TSMA) protocols for multihop
networks,” IEEE/ACM Transactions on Networking,
vol. 5, no. 6, pp. 804–812, 1997.
[2] A. Faragó, A. D. Myers, V. R. Syrotiuk, and
G. Záruba, “Meta-MAC protocols: Automatic
combination of MAC protocols to optimize performance
for unknown conditions,” IEEE Journal on Selected
Areas in Communications, vol. 18, pp. 1670–1681,
September 2000.
[3] I. Tinnirello, G. Bianchi, P. Gallo, D. Garlisi,
F. Giuliano, and F. Gringoli, “Wireless MAC
processors: programming MAC protocols on
commodity hardware,” in INFOCOM, 2012 Proceedings
IEEE, pp. 1269–1277, IEEE, 2012.
[4] N. Flick, D. Garlisi, V. Syrotiuk, and I. Tinnirello,
“Testbed implementation of the meta-mac protocol,” in
CNERT 2016, April 2016.

DEMONSTRATION DESCRIPTION

Our demonstration has two main goals: (a) validating the
general approach proposed in our Meta-MAC implementation, based on the simulation of the protocols not running
on the card, (b) showing the performance benefits of MetaMAC under dynamic network conditions.
For demonstrating the effectiveness of the general MetaMAC framework, we will generate a configurable channel
occupancy pattern and show how a Meta-MAC node is able
to automatically find a TDMA schedule, which transmits
only in the available idle slots. The channel occupancy pattern will be generated by a single wireless node, which can
be interactively programmed to transmit for multiple slots

90

2015 IEEE 35th International Conference on Distributed Computing Systems Workshops

Making WiFi Work in Multi-Hop Topologies:
Automatic Negotiation and Allocation of Airtime
Domenico Garlisi∗ , Fabrizio Giuliano∗ , Alice Lo Valvo∗ , Jonathan Lutz† , Violet R. Syrotiuk† , and Ilenia Tinnirello∗
∗

†

Department of Electrical Engineering, University of Palermo, Italy
School of Computing, Informatics and Decision Systems Engineering, Arizona State University, U.S.A.

in order to control the congestion level of multi-hop WiFi
networks. A distributed protocol, based on the REACT auction
scheme [13], is deﬁned for negotiating airtime allocations
among the nodes on the basis of the speciﬁc trafﬁc requirements and local views of the network. The negotiation protocol
also allows reservation of channel resources for control and
management operations easily. In order to prevent each node
from holding the channel for more than its allocated airtime,
we also deﬁne a mechanism for dynamically tuning the
contention window of each node. Both the negotiation protocol
and the contention window scheme are compatible with the
802.11 standard [14] and have been implemented on legacy
devices. Simulation results and extensive experimentation in
the CREW European testbed [15] show that the approach is
promising for real-world applications.
The rest of this paper is organized as follows. In §II we
present the protocol used to negotiate channel airtime. §III
explains how a node’s contention window is tuned according
to its airtime. §IV discusses the implementation of the negotiation and the contention window tuning in legacy commercial
WiFi cards. The results of our experimentation in the CREW
European testbed are presented in §V. Finally, we summarize
and conclude in §VI.

Abstract—We propose a solution for mitigating the performance impairments of CSMA/CA protocols in multi-hop topologies based on the dynamic adaptation of the contention process
experienced by nodes in a wireless network. A distributed
protocol is used to negotiate the channel airtime for a node as a
function of the trafﬁc requirements of its neighbourhood, taking
into account bandwidth reserved for the control operations. A
mechanism is provided for a node to tune its contention window
depending on its allocated airtime. Different from previous
schemes, a node’s contention window is ﬁxed in size unless the
trafﬁc requirements of its neighbourhood change. The scheme
is implemented on legacy commercial 802.11 devices. Extensive
experimental results, performed on the CREW European testbed,
demonstrate the effectiveness of the approach.

I. I NTRODUCTION
In recent years, it has clearly emerged that WiFi network
performance can dramatically degrade in multi-hop connected
topologies and in high node density scenarios. These conditions are likely to occur when multiple networks coexist
[1], [2] or large access infrastructure is deployed [3], [4].
The main reasons for the degradation include the starvation
and unfairness phenomena of CSMA-based protocols due to
a mismatch in the local views of the wireless medium among
the nodes, and due to the high level of contention when the
network is congested [5].
To mitigate these problems, different approaches have been
proposed, such as the adoption of rate limiters deployed on
each network node [6], [7], the utilization of multi-hop reservations and different access priorities for data and control trafﬁc
[8], [9], and the exploitation of admission control mechanisms
[10]. The main goal of these approaches is to avoid consuming
the whole channel capacity in different network links, thus
reducing the collision probability and leaving resources for
network management operations.
For measuring the amount of channel resources allocated
in the network links, also taking into account the channel
waste due to retransmissions, we make use of the concept
of airtime. It is the channel time in which the link is sensed
busy because of frame transmissions. Airtime measurements
are position-dependent, because channel attenuation differs
for each transmitter-receiver pair. Airtime metrics have been
effectively included in multi-hop routing schemes [6], [11],
and in admission control mechanisms [12].
In this paper we propose to use airtime metrics to measure
the channel resources allocated to each node in the network,
978-1-4673-7303-6/15 $31.00 © 2015 IEEE
DOI 10.1109/ICDCSW.2015.20

II. A IRTIME N EGOTIATION
Channel allocation in wireless networks can be viewed as a
resource allocation problem where transmitters correspond to
demands and receivers to resources. In [13], we proposed an
asynchronous event-driven distributed protocol named REACT
to negotiate an allocation of the channel airtime in an auction.
Each node runs an auctioneer that maintains an offer, the
maximum airtime consumed by any adjacent bidder. Similarly,
each node also runs a bidder that maintains a claim, the
airtime the bidder intends to consume at adjacent auctions.
Through updates of offers and claims, the auctioneers and
bidders converge on an allocation of airtime.
Speciﬁcally, bidder i knows di the airtime demanded by i,
and maintains its neighbouring receivers Ri ; offers[j] holds
the offer last received from auctioneer j. Bidder i constrains
its claim for airtime to be no larger than di or the smallest
offer from auctioneers in Ri , i.e.,
claim = min ({offers[j] : j ∈ Ri }, di ) .
Auctioneer j knows the channel capacity cj (if 100% channel
48



	



	



	








	















III. A IRTIME A LLOCATION IN W I F I N ETWORKS
Consider Fig. 1 depicting a sequence of channel accesses
performed by node i in the channel observation interval C.
The airtime of node i is coloured blue. It includes RTS,
CTS, DATA, and ACK transmissions, as well as the interframe spaces between the frames sent in the same channel
access (also called transmission opportunity). The channel
time C is divided into sub-intervals c(1), . . . , c(k) delimited
by the start of a transmission opportunity granted to node i.
Each interval c(k) includes the airtime of node i and also its
backoff expiration time, which in turns depends on the initial
backoff value and on the time the backoff is frozen due to the
transmission of other nodes. These intervals f (k), in which
backoff is frozen (coloured in gray), the backoff counter is
not decremented. Such freezing of the backoff countdown can
be triggered by the physical carrier sense, as well as by the
virtual carrier sense mechanism enabled by the reception of
CTS frames.
Assume that channel accesses are managed by means of a 4way handshake. Let tx , x ∈ {RTS, CTS, DATA, ACK} be the
time to transmit x. The airtime in an access interval depends
on the outcome of the RTS and DATA transmissions. It can
vary from a minimum of tRT S + DIF S when the RTS fails,
to a maximum of tRT S + SIF S + tCT S + SIF S + tDAT A +
SIF S + tACK + DIF S when the transmission is successful.
From renewal theory, the portion of channel resources
allocated to node i may be expressed as:


 





 



Fig. 1.

Successive channel accesses by a tagged node i.

allocation is the target then cj = 1) and maintains its
neighbouring transmitters Dj ; claims[i] holds the claim last
received from bidder i. Auctioneer j computes Dj∗ ⊆ Dj ,
bidders whose claims are strictly smaller than their offer, i.e.,
Dj∗ = {i : i ∈ Dj , claims[i] < offer}.
Bidders in Dj∗ are either satisﬁed or are constrained by another
auction and cannot increase their claims in response to a larger
offer from auctioneer j. Bidders in Dj \ Dj∗ are constrained
by auction j. They may increase their claims in response to a
larger offer. Resources left unclaimed by bidders in Dj∗ ,


A j = cj −
i∈D ∗ claims[i] ,
j

remain available to be offered in equal portions to bidders in
Dj \ Dj∗ . If claims of all bidders in Dj are smaller than the
offer then there are no bidders to share the resources available
in Aj . The auctioneer sets its offer to Aj plus the largest
claim, ensuring that any bidder in Dj can increase its claim
to consume resources in Aj :

Aj /|Dj \ Dj∗ |,
if Dj = Dj∗ ,
offer =
Aj + max (claims[i] : i ∈ Dj ) , otherwise.

si =

E[a]
E[a]
=
E[c]
E[a] + E[f ] + E[W ]/2 · σ

where E[a] is the average airtime and E[c] is the average
channel access interval. This interval E[c] can be expressed
as a sum of E[a], the average time the backoff is frozen E[f ],
and the average initial backoff value E[W ] in slots multiplied
by σ, the length in time of a backoff slot.
The average airtime E[a] can be computed by considering
the probability pRT S of a successful RTS transmission, and
the probability pDAT A of a successful DATA transmission as

When the negotiation converges, allocation of airtimes s =
{s1 , . . . , sN }, for a network with N nodes, corresponds to the
claims of each node. See [13] for the bidder and auctioneer
algorithms, along with proofs of correctness and convergence.

tRT S

+
+

pRT S · (tCT S + tDAT A + 2 · SIF S)
pDAT A · tACK + DIF S.

In general, after a successful handshake, it is assumed that data
packets are protected by the virtual carrier sense. However, in
multi-hop scenarios, it may happen that one of the receiver’s
neighbours experiences a collision on the reception of a CTS
due to a transmission originated by a node hidden to the
receiver; in turn, it may interfere with the DATA reception.
The average time the backoff is frozen depends on the
number of neighbours and on their trafﬁc, while the average
backoff value depends on the contention window settings.

There are at least two ways the airtime allocation computed
by REACT could be used in a medium access control (MAC)
protocol. One way is in a slotted MAC protocol where a
node’s airtime allocation could be interpreted as the percentage
of slots in the frame the node is allowed to transmit. The
synchronous ATLAS protocol in [13] uses this interpretation;
the evaluation of ATLAS was performed in simulation. Our
interest here is to develop a protocol that can be implemented
on real WiFi networks. Because it is difﬁcult to guarantee slot
synchronization and implement slotted protocols in a testbed,
we instead chose the second way: to integrate the airtime
allocation into a contention-based MAC protocol. Next, we
show how the airtime allocation can be used to tune the
contention window in a CSMA/CA protocol.

A. Contention Window Tuning in WiFi Networks
The channel access probability depends on the average
contention window value [16] rather than on the speciﬁc
backoff algorithm. Let Wi be the contention window value
of node i conﬁgured during an observation interval C.

49

Observation. Legacy WiFi nodes can estimate the current
allocated rate sˆi as a function of the total number of channel
accesses n, the total time that the backoff is frozen F , and the
total airtime A observed in interval C:
n
a(k)
nk=1
sˆi = n
k=1 a(k) +
k=1 f (k) + Wi /2 · σ · n
A
=
A + F + Wi /2 · σ · n
A
=
C
where Wi /2·σ·n is an approximation of the total time required
for the backoff countdown.
Prediction. Let Wi+ be a new setting of the contention
window, and let E[a]+ and F + , respectively, be the prediction
of the average airtime and total time the backoff is frozen
experienced under the new setting of the contention window
in a new channel observation interval C + . If the other nodes
use ﬁxed contention windows, then the dynamic tuning of Wi+
does not affect the collision probability experienced by the
target node. Indeed, the collision probability is given by the
probability that at least one interfering node is transmitting,
given that the target is also transmitting.
For example, the probability of a transmission interfering
with RTS frames only depends on the access probability of
other nodes. Therefore, changing the channel access probability of station i affects the total number of collisions, but not
the collision rate of RTS frames.
It follows that the new Wi+ value has an impact on the
channel access probability of station i but not on the average
airtime in each channel access (i.e., E[a]+ = A/n), which
only depends on the collision probability experienced by RTS
and DATA frames. Similarly, we can assume that the fraction
of channel time not allocated to node i that is sensed as busy
is not affected by the contention window tuning and therefore
F
equals to the previously experienced one, i.e., to C−A
. The
+
total time the backoff is frozen F is obtained as the product
between this ratio and the total time not spent in transmission
during the interval C + .
Tuning. To obtain the desired rate s∗i in the next tuning
interval C + , it is required to achieve a number of channel
accesses equal to
n∗ = s∗i ·





Fig. 2.



Chain topology with three nodes.

0.8
ALL REACT
0.7

F/(C-A)

0.6

Node B REACT
0.8

0.7

C’=0.3s
C’=1s
C’=10s

0.6
2

Fig. 3.

3

4

5

6
7
Update Interval

8

9

10

Ratio of F/(C − A) for successive observation windows.

the ns-2 network simulator. We altered the binary exponential
backoff algorithm of 802.11, setting CWmin = CWmax and
dynamically tuning CWmin according to equation (1). The
desired airtime s∗i for each node is speciﬁed initially as a node
conﬁguration parameter.
The channel time is segmented at the occurrence of the
ﬁrst successful or failed transmission observed after a given
interval C  from the start of the previous observation interval
(to guarantee that the segments include an integral number
of channel accesses). Each station measures the duration of
the observation interval C, the busy time intervals in which
the receiver is busy handling collisions or receiving frames
addressed to it, and the vbusy time interval in which the
network allocation vector (NAV) is active. In the same interval,
it counts the number data and rts of transmitted DATA and
RTS frames, and the number ack of received ACK frames.
Equation (1) is then applied to tune the contention window
value used in the next observation interval, with the total
airtime A is
A

+

C
n
= s∗i · C + · .
E[a]+
A

Therefore, the total time spent for n∗ countdowns of the
backoff has to equalize the difference between the channel
time not allocated to node i, i.e., C + (1 − s∗i ), and the time
the backoff is frozen. It follows that the contention window
can be tuned as:


2 A(1 − s∗i )
F
.
(1)
·
1
−
Wi∗ = ·
σ
n · s∗i
C −A

=

rts · (tRT S + DIF S)
+ data · (SIF S + tCT S + SIF S + tDAT A )
+ ack · (SIF S + tACK ),

the total time the backoff is frozen F = busy + vbusy, and
the number of channel accesses performed during interval C
is set to rts.
Results. We consider a simple network topology with a
chain of three nodes, labelled as nodes A, B, and C, with three
greedy trafﬁc ﬂows conﬁgured as shown in Fig. 2. The lower
set of lines in Fig. 3 show the ratio of the time the backoff
F
is frozen over the total backoff time (C−A)
experienced by
node B, when node B is the only node running REACT (with
s∗B = 0.26) with an initial window size set to 1024, and nodes
A and C are conﬁgured with a ﬁxed window size equal to

B. Validation in ns-2
Before implementing REACT and the contention window
tuning mechanism on real nodes, we performed a validation in

50

800

0.2
600

500

0
DCF
0.6

All REACT

400

0.4
Node B REACT

300

0.2
0

200
4

Fig. 4.

node A
node B
node C

0.4

airtime [%]

Contention Window

700

REACT

0.6

C’=0.3
C’=1
C’=10

6

8
10
Update Interval

12

0

14

Fig. 5.

Contention window for successive observation windows.

20

40

60

80
Time [s]


**
	


**

"

120

140

Normalized airtime as a function of time.



&
 ""

,!+ !! -

&




256. We consider three values for the observation interval C  .
Each point represents the estimate performed at the end of
the update interval C. The ratio is almost constant despite the
fact that the window size values used in the second and third
update intervals are very different (namely, 1024 and about
256). The statistical variability of the curves is due to the
random access process (and is more evident for C  = 0.3s).
In the lower set of lines of Fig. 4 we see that, after the ﬁrst
update interval, the contention window size values employed
by node B oscillate in limited intervals (namely, in the interval
[241, 320], [256, 297], and [270, 280] for the case of C  = 0.3,
C  = 1, and C  = 10, respectively).
The higher set of curves of Fig. 3 show again the fraction
of backoff time in which the counter is frozen, when all
the nodes employ the REACT scheme (with s∗ = 0.26).
In this case, all the curves have a transient phase of about
8 intervals before reaching an almost constant value (with
limited statistical ﬂuctuations). Although during the transient
phase the prediction of F used for tuning Wi has some errors
(because all nodes adjust their contention window size values),
Fig. 4 shows that in a few update intervals the tuning of the
contention window size is limited to a range of values. The
value of C does not appear to affect the convergence speed,
only the statistical ﬂuctuations of the estimated parameters and
relevant Wi values.
Fig. 5 shows the normalized airtime A/C measured when
the three nodes employ REACT with C  = 1 and s∗ = 0.26
compared to when the three nodes employ the standard distributed coordination function (DCF). It is evident that under
the standard DCF there are serious problems of unfairness
because there are times when node B is prevented from
accessing the channel for long time intervals, while at other
times its success probability is much higher than nodes A and
C (i.e., its average contention window is smaller). We return
to this issue in §V.

100

(
(
 (
 (



%
)$" 








	




"

Fig. 6. Software architecture for the implementation of airtime negotiation
and allocation schemes.

for which the driver-level functionalities are supported in the
common mac80211 and cfg80211 modules of the operating
system, and in the chipset-speciﬁc adaptation module ath9k.
Fig. 6 shows the software architecture used for our implementation and the interactions between the software modules,
the node queues, and the hardware NIC. The airtime negotiation protocol, as well as the decisions for the tuning of the
contention window, are implemented at the application level,
while the collection of the statistics is implemented by exploiting the driver-level functionalities devised to monitor and
conﬁgure the NIC. Statistics collection has been implemented
exactly as described for the ns-2 implementation in §III-B.
In more detail, we deﬁned a control protocol for notifying
the airtime offers and claims of the nodes as a node application
working on customized packets. The negotiation packets are
enqueued as priority frames (speciﬁcally, with VO access
priority) and separated by the data frames for improving the
protocol responsiveness. Indeed, data queues can be saturated
when the airtime auction reaches the capacity limit of the links;
in this condition, negotiation packets enqueued in the same
queue could experience long transmissions delays, which may
be detrimental for the timely detection of trafﬁc and topology
changes and even for the convergence of the negotiation.
A. Airtime Negotiation Protocol

IV. I MPLEMENTATION ON C OMMERCIAL 802.11 D EVICES

The airtime negotiation protocol is based on broadcast hello
messages, in which each node notiﬁes the airtime claim and
offer, as well as its presence (the IP address). The convergence
of the negotiation is determined by means of ﬁnished and

We implemented the REACT protocol for the airtime negotiation, and the tuning of the contention window for legacy
commercial WiFi cards. Speciﬁcally, we used Atheros cards

51

closed ﬂags. To simplify the implementation, all the protocol
parameters (including the ﬂags) are coded into a 1 byte ﬁeld
of the message. The message transmissions are scheduled at
ﬁxed time intervals (that in our experiments is conﬁgured
to 0.5s). The reception of a message sent by a neighbour
node triggers the update of the protocol’s internal parameters.
These parameters are organized into a table (node table), in
which each row codes the address and the protocol parameters
corresponding to each visible node.
After the convergence of the scheme, when all the neighbours are satisﬁed, the protocol parameters are not updated
unless a new neighbour (i.e., a topology change) or a new
application request (i.e., a change in load) is identiﬁed by the
negotiation protocol. In the current implementation, the negotiation protocol exposes a conﬁguration interface that allows the
normalized application request (REQUEST) and the maximum
negotiable fraction of channel time (MAX_CAPACITY) to be
speciﬁed; both parameters are expressed in the range [0, 1].
The main routines of the protocol, according to which
claims and offers are updated, are represented in pseudo-code
in Listings 1 and 2.

void update_offer() {
active = 1 - finished;
allocated = claim * finished;
sum_claim = 0;
// Look if at least one node is active
// and computes current allocations
for ( i=0; i<N; i++ ) {
if ( node_table[i].finished == 0) {
active++;
}
if (state_table[i].finished == 1) {
allocated = allocated + node_table[i].claim;
}
sum_claim = sum_claim + node_table[i].claim;
}
if( active > 0 ) {
offer = (MAX_CAPACITY-allocated)/active;
if ( sum_claim == MAX_CAPACITY )
closed = 1;
else
closed = 0;
}
}
Listing 2.

void update_claim() {
min_offer = MAX_CAPACITY;
bottlenecked = 0;
// Get minimum offer
min_offer = get_min_offer(node_table);
// Set claim
claim = min(REQUEST, min_offer);
// Check if all resources are allocated
for ( i=0; i<N; i++ ) {
if ( node_table[i].closed == 1) {
bottlenecked = 1;
break;
}
}
// Check if finished
if( claim == REQUEST || bottlenecked )
finished = 1;
else
finished = 0;
}
}
Listing 1.

Pseudo-code to update the offer.

V. E XPERIMENTAL R ESULTS
We run several experiments on the European CREW testbed
[15], for characterizing the performance of the proposed
airtime allocation scheme. The CREW testbed offers various
facilities, available in different European sites, for running
experiments on wireless networks. Speciﬁcally, we worked on
the Zwijnaarde site, whose testbed consists of 70 embedded
PCs, 15 of which are mobile, located in a pseudo-shielded
environment of size 66 × 20 meters. These PCs have various
radio equipment attached, among which are two WiFi cards
based on the Atheros chipsets, able to work at 2.4–2.5 and 4.9–
5.85 GHz. Each node is also wired to an independent Ethernet
network, which is used for controlling the experiments on the
basis of the so called cOntrol Management Framework (OMF).
By programming a centralized experiment controller, it is
possible to conﬁgure each node involved in the experiment,
specify the experiment events, such as the activation of trafﬁc
ﬂows or the shut down of a wireless interface, and collect the
desired node statistics.

Pseudo-code to update the claim.

B. CW Tuning

A. Network Topology

When the negotiation protocol converges and the ﬁnal claim
is computed, another process is scheduled at regular time intervals C for the dynamic tuning of the contention window. In
the current implementation C is set to 1s. The process exploits
an interface in the driver for reading the busy and vbusy time
intervals, the number of DATA and RTS packets (data and
rts) transmitted, and the number of ACKs (ack) received; the
same interface is used for specifying the contention window
value used in the next interval. The contention window can
be conﬁgured to any value in the range [8, 1024] according to
equation (1).

Conﬁguring a multi-hop wireless topology in an indoor
controlled environment is important for benchmarking and for
the reproducibility of the results. However, it is not a trivial
task, because the distance at which nodes are visible (i.e.,
are able to interfere each other) can be much farther than the
transmission range. In order to limit the physical visibility
of the nodes, we work on the 802.11a PHY, at the central
frequency of 5180 MHz.
Tests are conducted to identify six nodes among the 70
available to match the logical topology in Fig. 7. Each node
is programmed to send broadcast pings at a minimum rate of

52

1




nodeA
nodeB
nodeC
nodeD
nodeE
nodeF

0.8
0.6




prts



0.4




0.2
0

0

10

20

30
time [s]

40

50

60

(a) DCF
1
nodeA
nodeB
nodeC
nodeD
nodeE
nodeF

0.8

prts

0.6

Fig. 7. Logical (top) and physical (bottom) network topology used for the
experiments.

0.4
0.2

1000

CW[slots]

0

nodeA
nodeB
nodeC
nodeD
nodeE
nodeF

800
600
400

0

10

20

30
time [s]

40

50

60

(b) REACT
Fig. 9.

RTS/CTS handshake success probability.

200
0

0

10

Fig. 8.

20

30
time [s]

40

50

starts the dynamic tuning once the ﬁnished ﬂag is set to 1; this
condition is veriﬁed after a time interval varying from 6 to 8
seconds. In a few update intervals (i.e., in a few seconds), the
contention window tunings stabilize into limited ranges. The
average value used by each node varies according to its local
view of channel occupancy intervals (node E experiences the
shortest interval in which the backoff is frozen whereas node
C experiences the longest one).

60

REACT Contention Window Tuning

6 Mbps, and for different values of the transmission power, in
a dedicated time interval when all the other nodes are silent.
The messages notify neighbours in the transmission of a node’s
presence. We also collected the measurements of the busy time
intervals detected by all the nodes, to identify the nodes that
can be interfered with by the node under test (including the
ones which cannot decode the ping packets). At the end of
these tests, we were able to build the network topology shown
in the ﬁgure, in which transmission ranges and interference
ranges coincide. The physical location of the nodes is shown
in the bottom part of Fig. 7: central nodes (nodes 24 and 29)
are conﬁgured with a transmission power of 4 dBm, while all
the other nodes are conﬁgured with a transmission power of
only 1 dBm.

TABLE I
AVERAGE ( STANDARD DEVIATION ) AIRTIME (%)

DCF
REACT

A
21(1)
20(3)

B
24(2)
20(2)

C
23(2)
20(3)

D
22(2)
20(2)

E
30(3)
20(2)

F
28(2)
20(3)

TABLE II
AVERAGE THROUGHPUT ( PKTS / S )

DCF
REACT

B. Static Scenarios
A ﬁrst set of experiments is programmed to test the airtime
allocation scheme in static load conditions. The scheme is
initialized by setting MAX_CAPACITY = 0.8, REQUEST = 1,
C = 1 and the initial value of the contention window equal to
1024 for all the nodes. Six greedy trafﬁc ﬂows are activated by
the experiment controller at the beginning of the experiment,
according to the conﬁgurations shown in Fig. 7. Each ﬂow is
implemented by using the iperf trafﬁc generator with a UDP
transport protocol and packets of 1470 bytes. The data rate of
all the nodes is set to 6 Mbps.
Fig. 8 shows the temporal behaviour of the contention
window tuning for all the nodes in the network. Each node

A
98.0
88.4

B
88.7
80.0

C
30.5
75.0

D
84.2
86.1

E
127.0
86.7

F
94.1
83.9

Table I shows the normalized airtime by each node using the
REACT negotiation scheme and the proposed window tuning.
For sake of comparison, the table also shows the airtimes
under standard DCF. We see that the REACT scheme is able to
support fair allocations of the channel holding times, leaving
a residual channel capacity (namely, 1 − MAX_CAPACITY)
for control and management operations. This capacity, in real
networks, can be important for speeding up the association
of new nodes. Table II quantiﬁes the efﬁciency of airtime
utilization in terms of data throughput (in packets/s). While

53

TABLE III
AVERAGE ( STDEV ) AIRTIME BEFORE / AFTER NODE F ACTIVATION (%)

1000
nodeA
nodeB
nodeC
nodeD
nodeE
nodeF

CW[slots]

800
600
400

Before
After

200
0

0

10

20

30

40
time [s]

50

60

70

B
15(2)
21(2)

D
15(2)
20(2)

E
48(3)
20(3)

F
0(0)
20(2)

1000

CW[slots]

800

1000
nodeA
nodeB
nodeC
nodeD
nodeE
nodeF

800
600
400

600
400
200
0

0

20

40

60

80
100
time [s]

120

140

160

0

20

40

60

80
100
time [s]

120

140

160

200
100

0

10

20

30

40
time [s]

50

60

70

80

80
airtime[%]

0

C
16(3)
21(3)

80

(a) Testbed.

CW[slots]

A
32(4)
20(2)

(b) Simulation.
Fig. 10.

Adaptation of contention windows.

60
40
20
0

under standard DCF the throughput can vary from 127 to
30.5 packets/s (without any residual channel capacity), under
REACT the throughput variability among the nodes is significantly reduced. Despite airtime allocations being the same
among nodes, the variations in throughput results are due to
the different collision rates experienced by the nodes. Fig. 9
shows the probability of a successful RTS/CTS handshake in
both the cases of standard DCF and REACT. It is evident that
the probability of successful channel reservations increases for
all nodes by using REACT.

nodeA

nodeB

nodeC

nodeD

nodeE

nodeF

Fig. 11. REACT topology change: sequential node activation in the testbed.

remain constant for about 5s, until all the nodes complete
the negotiation. Apart from the delay required for the airtime
negotiation, the contention window tuning in simulation and
in the real experiment agree.
The average airtimes obtained in the real experiment before
and after the activation of node F are summarized in Table III.
They are perfectly in agreement with the REACT allocations
and with the simulation results (not shown). However, there
is a difference in the standard deviation of the results: in
simulation, the airtime deviation is smaller. In real experiments
the time intervals where the backoff is frozen exhibit higher
ﬂuctuations than in simulation: this phenomenon occurs because of capture effect not modelled in simulation.

C. Dynamic Scenarios
A second set of experiments is programmed to test the
airtime allocation scheme in dynamic network conditions.
We run experiments considering both variations in the load
conditions and in the network topology. The initialization
parameters are set to the same values indicated in §V-B.
To program a variation in the network load conditions,
we conﬁgured the experiment controller to activate the trafﬁc ﬂow on node F after 30 seconds from the start of
the experiment. The airtime allocations computed by REACT start with [0.32, 0.15, 0.15, 0.15, 0.48, 0] and switch to
[0.2, 0.2, 0.2, 0.2, 0.2, 0.2] after the activation of the trafﬁc ﬂow
on node F. Fig. 10(a) shows the adaptation of the contention
windows observed in the real experiment, while Fig. 10(b)
shows the results from the ns-2 simulation. Recall that in
the ns-2 simulation the negotiation protocol and the airtime
allocations are speciﬁed as node conﬁguration parameters; a
simulator event changing the airtime settings is scheduled
exactly after 30s. This justiﬁes the behaviour of the experimental results, where after the detection of the load change
the REACT scheme is reset and the contention windows

Finally, to experiment with a variation in the network
topology, we switched on each network node sequentially
at regular intervals of 30s. This causes the REACT negotiation protocol to restart on each node activation. Now, nodes
active in consecutive intervals share the channel capacity
(MAX_CAPACITY = 0.8) with one more node. Fig. 11 shows
the contention window tuning and the airtime experienced by
each node during the experiment. Each node starts with a
contention window set to 1024 and reduces the contention
window to a stable value after the convergence of REACT.
The ﬁnal airtime allocations and average contention window
values, when all the nodes are active, are in agreement with
the initial experiment.

54

[5] M. Garetto, T. Salonidis, and E. Knightly, “Modeling per-ﬂow throughput and capturing starvation in CSMA multi-hop wireless networks,”
IEEE/ACM Transactions on Networking, vol. 16, no. 4, pp. 864–877,
August 2008.
[6] J. Camp, J. Robinson, C. Steger, and E. Knightly, “Measurement
driven deployment of a two-tier urban mesh access network,” in
Proceedings of the 4th ACM International Conference on Mobile
Systems, Applications and Services (MobiSys’06), 2006, pp. 96–109.
[Online]. Available: http://doi.acm.org/10.1145/1134680.1134691
[7] N. Blefari-Melazzi, A. Detti, I. Habib, A. Ordine, and S. Salsano, “TCP
fairness issues in IEEE 802.11 networks: Problem analysis and solutions
based on rate control,” IEEE Transactions on Wireless Communications,
vol. 6, no. 4, pp. 1346–1355, April 2007.
[8] T. Imboden, K. Akkaya, and Z. Moore, “Performance evaluation of
wireless mesh networks using IEEE 802.11s and IEEE 802.11n,” in
Proceedings of the IEEE International Conference on Communications
(ICC’12), June 2012, pp. 5675–5679.
[9] E. Carlson, C. Prehofer, C. Bettstetter, H. Karl, and A. Wolisz, “A distributed end-to-end reservation protocol for IEEE 802.11-based wireless
mesh networks,” IEEE Journal on Selected Areas in Communications,
vol. 24, no. 11, pp. 2018–2027, November 2006.
[10] Q. Shen, X. Fang, P. Li, and Y. Fang, “Admission control based
on available bandwidth estimation for wireless mesh networks,” IEEE
Transactions on Vehicular Technology, vol. 58, no. 5, pp. 2519–2528,
June 2009.
[11] R. Carrano, L. Magalhaes, D. Saade, and C. Albuquerque, “IEEE
802.11s multihop MAC: A tutorial,” IEEE Communications Surveys
andTutorials, vol. 13, no. 1, pp. 52–67, January 2011.
[12] K. Kosek-Szott, M. Natkaniec, S. Szott, A. Krasilov, A. Lyakhov,
A. Safonov, and I. Tinnirello, “What’s new for QoS in IEEE 802.11?”
IEEE Network, vol. 27, no. 6, pp. 95–104, November 2013.
[13] J. Lutz, C. J. Colbourn, and V. R. Syrotiuk, “ATLAS: Adaptive
topology- and load-aware scheduling,” IEEE Transactions on Mobile
Computing, vol. 13, no. 10, pp. 2255–2268, October 2014. [Online].
Available: http://arxiv.org/abs/1305.4897
[14] “IEEE standard 802.11: W-LAN medium access control & physical layer
speciﬁcations,” December 1999.
[15] “The CREW project,” http://www.crew-project.eu/testbeds.
[16] G. Bianchi and I. Tinnirello, “Remarks on IEEE 802.11 DCF performance analysis,” IEEE Communications Letters, vol. 9, no. 8, pp. 765–
767, August 2005.

VI. C ONCLUSIONS
In this paper, we proposed a distributed mechanism for
negotiating and allocating airtimes among WiFi nodes in
multi-hop network topologies. The negotiation scheme is able
to react to changes both in topology and in trafﬁc load.
The utility of the scheme is demonstrated through a real
implementation on legacy WiFi devices, and has been tested
on a wide variety of network scenarios. The results suggest
that the scheme can effectively mitigate the starvation and
unfairness phenomena, thus enabling the possibility to provide
robust and reliable services in large-scale WiFi networks.
ACKNOWLEDGEMENTS
Violet Syrotiuk thanks Mark Berman and Chip Elliott at
the GENI Project Ofﬁce (GPO) for supporting her travel to
Palermo to encourage this collaboration.
R EFERENCES
[1] M. A. Ergin, K. Ramachandran, and M. Gruteser, “An experimental study of inter-cell interference effects on system performance in
unplanned wireless LAN deployments,” Computer Networks, vol. 52,
no. 14, pp. 2728–2744, October 2008.
[2] K. Papagiannaki, M. Yarvis, and W. Conner, “Experimental characterization of home wireless networks and design implications,” in
Proceedings of the 25th IEEE International Conference on Computer
Communications (INFOCOM’06), April 2006, pp. 1–13.
[3] J. Bicket, D. Aguayo, S. Biswas, and R. Morris, “Architecture and
evaluation of an unplanned 802.11b mesh network,” in Proceedings of
the 11th Annual ACM International Conference on Mobile Computing
and Networking (Mobicom’05), 2005, pp. 31–42. [Online]. Available:
http://doi.acm.org/10.1145/1080829.1080833
[4] A. P. Jardosh, K. Mittal, K. N. Ramachandran, E. M. Belding, and K. C.
Almeroth, “IQU: practical queue-based user association management
for WLANs,” in Proceedings of the 12th ACM Annual International
Conference on Mobile Computing and Networking (Mobicom’06), 2006,
pp. 158–169.

55

Topology-Transparent Scheduling for MANETs
using Orthogonal Arrays
Violet R. Syrotiuk

Charles J. Colbourn

Alan C.H. Ling

Computer Science &
Engineering
Arizona State University
Tempe, AZ 85287-5406

Computer Science &
Engineering
Arizona State University
Tempe, AZ 85287-5406

Computer Science
University of Vermont
Burlington, VT 05406

syrotiuk@asu.edu

colbourn@asu.edu

ABSTRACT

aling@emba.uvm.edu

wireless nodes that self-organize without the aid of any centralized control or any ﬁxed infrastructure. As a result of
the limited radio transmission range of each node, it may be
necessary to forward a packet over multiple hops for it to
reach its destination. However this limitation also allows for
the possibility of spatial reuse, wherein nodes that are sufﬁciently far enough apart may transmit concurrently. Most
medium access control (MAC) protocols for MANETs attempt to exploit the potential for spatial reuse in order to
satisfy two primary objectives: minimizing delay and maximizing throughput on a per hop basis.
A spectrum of medium access control protocols exist in
an eﬀort to meet these objectives. The general conclusion
is that higher throughput may be obtained at the cost of
poorer guarantees on delay. Contention based approaches
are more prevalent than scheduled approaches since they
achieve high throughput with a reasonable expected delay
(but poor worst-case delay). However, as the interest in delay sensitive applications grows, it is clear that the MAC
protocol must also be made quality-of-service (QoS) aware,
i.e., it must provide a delay guarantee. There are a number of ideas to support packet classes in IEEE 802.11 [1],
however in each case [2, 9, 10], the delay guarantee remains
probabilistic. The fact is, to obtain a delay guarantee, a
scheduled approach is necessary.
TDMA is the simplest example of scheduled access control. While it provides a delay bound, it does not meet a
reasonable throughput objective. One reason is that the
nodes in a MANET are not often fully connected. There
are two approaches to take advantage of spatial reuse using
scheduling. One approach uses a hybrid topology-dependent
access scheme that alternates between a contention phase in
which neighbour information is collected, and a collision-free
phase in which nodes transmit according to a schedule constructed using the neighbour information (see, as examples,
[5, 12]). These types of protocols can be unstable under high
load or mobility conditions, becoming unable to converge on
a new schedule, and as a result lose their delay guarantee.
Alternatively, a topology-transparent approach does not
use any information about who is a neighbour of whom. The
schedules for topology-transparent access protocols [3, 8] depend on two design parameters: N , the number of nodes in
the network, and Dmax , the maximum node degree. While
it is often possible to construct schedules that are signiﬁcantly shorter than TDMA, if the actual node degree exceeds Dmax , the delay guarantee is lost (as we shall see,

In this paper, we generalize the known topology-transparent
medium access control protocols for mobile ad hoc networks
by observing that their transmission schedule corresponds
to an orthogonal array. Some new results on throughput
are obtained as a consequence. We also show how to compute the probability of successful transmission if the actual
node degree in the network exceeds the design parameter
related to maximum node degree, showing the sensitivity of
the schedule to this parameter. The selection of orthogonal array to provide the best throughput is also examined,
and combinatorial generalizations are explored. Finally we
outline schemes that combine the delay guarantees of current approaches to handle exceeding the stipulated maximum node degree.

Categories and Subject Descriptors
C.2.1 [Network Architecture and Design]: Wireless
Communication; C.4 [Performance of Systems]: Modeling Techniques; G.2.1 [Combinatorics]: Generating Functions; C.2.2 [Network Protocols]

General Terms
Algorithms, Performance

Keywords
Mobile ad hoc networks, Medium access control, Topologytransparency, Scheduling, Orthogonal array

1. INTRODUCTION
Controlling access to the shared broadcast channel is critical to ensure successful communication in a mobile ad hoc
network (MANET). A MANET is a collection of mobile

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
DIALM–POMC’03, September 19, 2003, San Diego, California, USA.
Copyright 2003 ACM 1-58113-765-6/03/0009 ...$5.00.

43

it becomes probabilistic rather than deterministic). The
question is what should be done if the protocol fails? In
[4] protocol threading is proposed to address such failures
however the delay bound of the resulting schedule exceeds
TDMA and is therefore ineﬀective. We suggest two alternatives here.
The results of this paper are as follows. We generalize
the known topology-transparent medium access control protocols by observing that their transmission schedule corresponds to an orthogonal array. We investigate the degradation of throughput as the actual node degree exceeds the
design parameter Dmax . We provide a frame by frame analysis in which we compute expected throughput. Perhaps unexpectedly, we also show that for schedules that arise from
orthogonal arrays of strength two and three, the expected
throughput is independent of the number of subframes. We
discuss parameter selection for the orthogonal array in order
to achieve a speciﬁc performance objective from the corresponding schedule.
The rest of this paper is organized as follows. Section
2 deﬁnes an orthogonal array and explains how it may be
used to produce a topology-transparent transmission schedule. It also shows how the schedules constructed in [3] and
in [8] correspond to orthogonal arrays. In Section 3 we derive analytical expressions for the probability of a successful
transmission in a frame, and for the expected throughput.
In Section 4, we study the selection of parameters of the orthogonal array to provide the best throughput, with special
attention to the sensitivity of the actual node degree to the
design parameter Dmax . Lastly, in Section 5, we summarize
our results, discuss combinatorial generalizations we are exploring, suggest schemes to handle exceeding the maximum
node degree, and conclude.

0
0
0
0

Table
0 0
2 3
2 3
3 2

1: Orthogonal array
1 1 1 1 2 2
0 1 2 3 0 1
1 0 3 2 2 3
3 2 0 1 2 3

OA(2, 4, 4).
2 2 3 3
2 3 0 1
0 1 3 2
1 0 1 0

3
2
1
2

3
3
0
3

and the eighth column intersect in no positions, while the
ﬁrst and the second column intersect in a zero in the ﬁrst
position (row).
The importance of this intersection property is as follows.
Select any codeword. Since any of the other codewords can
intersect it in at most t − 1 positions, any collection of D
other codewords has the property that our given codeword
diﬀers from all of these D in at least k − D(t − 1) positions.
Provided this diﬀerence is positive, the codeword therefore
contains at least one symbol appearing in a position, not occurring in any of the D codewords in the same position. In
our application this means that at least one collision-free slot
to each neighbour exists when a node has at most D neighbours. Thus, so long as the number of neighbours is bounded
by D, the delay to reach each neighbour is bounded, even
when each neighbour is transmitting.

2.1

Constructions of Schedules using OAs

A large number of techniques are known for constructing
orthogonal arrays, usually classiﬁed by the essential ideas
that underlie them. There is a classic construction based
on Galois ﬁelds and ﬁnite geometries; both Chlamtac and
Faragó [3] and Ju and Li [8] use this construction implicitly
though neither observed that what they were constructing
was an orthogonal array. They both employ OA(t, v, v)’s
when v is a prime power. They therefore restrict attention
to the case when k = v (forcing all frame lengths to be v 2
unnecessarily), and indeed by not permitting that k > v
they do not obtain the best delay guarantees. The restriction of v to prime powers is also not required, as orthogonal
arrays exist for these cases, e.g., OA(2, 7, 12), but k is not
as large in general.
The essential diﬀerence between the Chlamtac and Faragó
[3] and the Ju and Li [8] papers is in the selection of parameters. In [3], the focus is on frame length while in [8] the
focus is on throughput.
More speciﬁcally, in [3], the ﬁrst v t ≥ N , t ≥ 2 is found,
where v is a prime power. In the paper, the interest is in
minimizing the frame (or schedule) length in order to minimize delay. The parameters are selected to ﬁnd a schedule
provably shorter than TDMA.
In [8], it is argued that the parameters chosen satisfy the
condition on delay but do not maximize minimum throughput. In particular, it is possible to achieve higher minimum
throughput at the expense
√ of longer frame length. They√select v = 2(t − 1)Dmax if t N ≤ 2(t − 1)Dmax , and v = t N
otherwise. Intuitively, while Chlamtac and Faragó [3] strive
to get one free slot per frame, Ju and Li [8] aim to get many
free slots per frame.
In the following, we assume that radios in the MANET use
half-duplex communication, i.e., nodes cannot both transmit
and receive at the same time. As well, two or more simultaneous transmissions to a receiver result in a collision, i.e., no
capture eﬀect is modelled — none of the transmitted packets
is received correctly.

2. ORTHOGONAL ARRAYS
The theory of orthogonal arrays relates combinatorics, ﬁnite ﬁelds, geometry and error-correcting codes. The prominent role of orthogonal arrays as been in the design of experiments, for example in medical applications such as pharmaceutical companies investigating the stability and shelf-life
of drugs, drug interaction, and in clinical trials to study how
drugs are absorbed, metabolized, and eliminated from the
body.
Let V be a set of v symbols denoted by 0, 1, . . . , v − 1.
Deﬁnition 1. A k × v t array A with entries from V is an
orthogonal array with v levels and strength t (for some t in
the range 0 ≤ t ≤ k) if every t × v t subarray of A contains
each t-tuple based on V exactly once1 as a column. We
denote such an array by OA(t, k, v).
Table 1 shows OA(2, 4, 4), an example of an orthogonal
array of strength t = 2 with v = 4 levels, i.e., V = {0, 1, 2, 3}.
Pick any two rows, say the third and the fourth. Each of
the sixteen ordered pairs (x, y), x, y ∈ V appears the same
number of times, once in this case.
In our application, that of assigning transmission schedules to nodes, the number of columns in the orthogonal array is an upper bound on the number of nodes in the network. Each column, which is called a codeword, gives rise
to a transmission schedule. Each codeword intersects every other in fewer than t positions. For example, the ﬁrst
1

0
1
1
1

In this paper, we assume the index λ = 1.

44

has a slot that does not appear in S1 , . . . , SD (more exactly,
S1 + S2 + . . . + SD , where the addition operator denotes
the binary “or” operation). Expected throughput then, is
simply the expected number of such slots. We employ an
ordinary generating function to enumerate and classify the
selections of D neighbours.
For an OA(t, k, v) let

We assume that time is divided into discrete units called
slots. Slots are organized into a sequence called a frame. A
schedule S for a frame consists of a binary vector s1 s2 . . . sn
with one element for each slot. Typically, each node in the
network is assigned a schedule that it uses in a cyclically
repeated way for transmission. If si = 1 then the node may
transmit in the slot, otherwise it is silent (and could receive).
Given a codeword W , i.e., a column of length k from the
orthogonal array, the corresponding schedule is constructed
as follows. Each symbol wi in W = w0 w1 . . . wk−1 gives rise
to a binary subframe F of length v (since each symbol is
from the set V ). Speciﬁcally, F [i] = 1 if and only if wi = i,
for i = 0, . . . , v − 1 and F [i] = 0 otherwise. The schedule
S is a k × v binary vector made up of the concatenated
subframes, i.e., S = F0 F1 . . . Fk−1 (recall that in [3, 8], k = v
so |S| = v 2 ).
We observe an important point: The resulting transmission schedules do not depend on the construction of the
orthogonal array. We are just exploiting the combinatorial
properties of the orthogonal array itself. We explore this
observation in the following section.

φ(w; t, k, v) =

t
v
−1

(w) i

Ci

x

i=0
(w)

where Ci denotes the number of ways for a given codeword
W to select i other codewords whose union intersects W in
precisely w speciﬁc positions. We call this the w-covering
function.
If we can calculate the w-covering functions, then


(k)
C
1 − vti−1
i

is the probability that if a node has i neighbours, then it retains at least one free slot (calculated as 1−P r[no free slot]).
k
If w entries are covered then k − w are free. There are w
ways to choose the w covered. The frame length is kv so
with i neighbours, expected throughput is
k
(w)
k

·C
1
(k − w) · wvt −1i ·
.
kv
w=0

2.2 Properties of Orthogonal Arrays
By deﬁnition, if we look along t rows of an orthogonal
array, every t-tuple is found exactly once. However, for our
application, what is important is that when we pick any t
columns, they cannot agree in any more than t − 1 rows. It
is the absence of agreement that we exploit.
There is a substantial body of knowledge on the existence
of orthogonal arrays [7, 6]. Among the classical results in the
area is that whenever an OA(t, k, v) exists, an OA(t, k−1, v)
exists (simply omit a row).
More interesting, if an OA(2, v, v) exists then there is an
OA(2, v + 1, v). This is interesting because the published
schemes [3, 8] both employ OA(t, v, v)’s in their construction. This result immediately gives rise to an orthogonal
array with codewords of length v + 1 from which schedules
of length v(v + 1) are constructed. This immediately enhances the guarantee on minimum throughput of Ju and Li
[8].
In a similar way, since orthogonal arrays have the property
of balanced occurrences of t-tuples, this also forces the intersections of codewords to be balanced. We demonstrate this
next and then exploit it to examine the success probability
within a frame and expected throughput.

i

3.1

Strength Two Orthogonal Arrays

Theorem 1. For an OA(2, k, v), the w-covering function
φ(w; 2, k, v) for w covered slots in a frame is
w

φ(w; 2, k, v) = [(x + 1)v−1 − 1] · [x + 1](v−1)(v+1−k) .
Proof. In order to calculate φ(w; t, k, v) for t = 2, i.e.,
for an OA(2, k, v), we consider a ﬁxed codeword W and we
partition the remaining set of codewords into three diﬀerent
sets according to their intersection with W . To deﬁne this
partition, we ﬁrst collect some observations.
1. Every other codeword intersects W in zero or in one
position (it cannot be more since t = 2).
2. The number of codewords intersecting in a speciﬁc position of W is v − 1.

3. ORTHOGONAL ARRAY SELECTION

3. The number of codewords intersecting W in exactly
one position is k(v − 1), since no codeword intersects
W in two or more positions.

In this section we investigate two questions:
1. What is the probability of a successful transmission in
a frame?

Therefore, the number of codewords disjoint from W is
v 2 − 1 − k(v − 1)

2. What is the expected throughput?
=
=

Both are functions of the number of active transmitters
among the neighbours of a node. We assume that the neighbours of a node are chosen uniformly at random.
Consider a situation with sender S and receiver R. Let S
be a schedule for sender S and S1 , . . . , SD−1 be the schedules
of the other active neighbours of R (here, we assume the
worst case, when all neighbours are transmitting). Let SD
be the schedule for R, and assume that R is also active.
To make our questions precise, the probability of successful transmission within a frame is just the probability that S

(v − 1)(v + 1) − k(v − 1)
(v − 1)(v + 1 − k).

Now, consider w speciﬁc positions of W . We partition the
codewords other than W into three diﬀerent sets:
1. Codewords intersecting W in one of the w speciﬁed
positions;
2. codewords intersecting W in one of the remaining k−w
positions; and,

45

3. codewords not intersecting W.

1

Probability >= 1 Slot

There are w(v −1) codewords in the ﬁrst class, (k −w)(v −1)
codewords in the second, and (v − 1)(v + 1 − k) in the third.
We ﬁrst determine simpler generating functions for each
class. We use x here as a single indicator function, where
x indicates a selection of a codeword and 1 its omission;
hence the exponent of x indicates the number of codewords
selected while the coeﬃcient indicates the number of ways
to make this selection.
1. Each of the w positions must be covered. For each
single position to be covered, we obtain
v−1

(x + 1)

[(x + 1)

0.6
0.4
0.2
0

− 1] .

(k−w)

20
40
60
Size of Neighbourhood

80

Figure 1: Probability of ≥ 1 free slot in a frame for
OA(2, k, 17) (289 nodes).

w

2. Each of the other k − w positions are not covered; we
obtain
(1(v−1) )

0.8

− 1.

In essence this says that we can select any codeword
or omit it, but we cannot choose to omit all of them
— hence the −1 term. For w positions to be covered,
we therefore obtain
v−1

OA(2,k,17) Slot Guarantee

4.

NUMERICAL RESULTS

The results in this section were obtained using Maple [11],
a mathematical software package. Figures 1 and 2 show the
probability that there is at least one free slot in a frame
for two orthogonal arrays of strength two as a function of
the number of neighbours. The OA(2, k, 17) in Figure 1
supports N = 289 nodes with a frame length of 17k for
k = 1, 2, . . . , 18. The OA(2, k, 25) in Figure 2 supports 625
nodes with a frame length of 25k for k = 1, 2, . . . , 26. Each
ﬁgure shows a family of curves, starting leftmost with k = 1,
and increasing by one for each successive curve to the right.
Both curves are shown up to 80 neighbours to show how the
parameters aﬀect the probability.
The ﬁgures have a structural similarity, having a resemblance to an inverse “s” shape that drops more gradually as
k increases. This makes sense since for larger k the frame
length is longer, and hence the probability that there is a
free slot in the frame increases. It is possible to use very
short frames yet still have a reasonable chance of success
even when the actual number of neighbours exceeds the design parameters. The longer frames of the OA(2, k, 25) supports a larger number of neighbours than the schedules generated from the OA(2, k, 17). Finally, TDMA outperforms
the OA(2, k, 17) for k = 17, 18. For k = 17, TDMA has the
identical frame length but has, with certainty, a free slot in
the frame. Similarly for OA(2, k, 25) for k = 25, 26.
These ﬁgures disguise to a degree that the guarantee of a
free slot extends only to k − 1 neighbours. Until that point,
the curve is identically equal to 1; thereafter, however, one
can see only that it remains very close to 1 and is hard to
distinguish visually.
Figures 3 and 4 show the probability that at least one slot
in the frame is free for two diﬀerent strength three orthogonal arrays. The OA(3, k, 8) in Figure 3 that supports 256
nodes with a frame length of 8k for k = 1, 2, . . . , 10 (since
v = 8 = 23 , k can be as large as v +2 [7]). Figure 4 shows an
OA(3, k, 11) that supports 1331 nodes with a frame length
of 11k for k = 1, 2, . . . , 12. These curves have the same overall structure as those in Figures 1 and 2, however their slope
is much steeper. It is not too surprising that the probability
of a success drops more rapidly as the frame lengths of the
schedules that arise from these higher strength orthogonal

= 1.

3. Each disjoint block can be chosen or not:
(x + 1)(v−1)(v+1−k) .
Multiplying these expressions for each class, we obtain the
w-covering function for k = 2:
w

φ(x; 2, k, v) = [(x + 1)v−1 − 1] · [x + 1](v−1)(v+1−k) .

3.2 Strength Three Orthogonal Arrays
In order to calculate φ(w; t, k, v) for t = 3, the same type
of decomposition as for t = 2 is used. Consider a ﬁxed
codeword W. Every other codeword intersects in zero, one,
or in two positions:
1. The number that intersect W in two speciﬁc positions
is
kv −1, so the number that intersect in two positions is
(v − 1). The number that intersect in two positions
2
of which one is ﬁxed is (k − 1)(v − 1).
2. The number that intersect W in a speciﬁc position
must be v 2 − 1 in total but this includes those intersecting in two positions, so the number intersecting in
exactly this speciﬁc position is
v 2 − 1 − (k − 1)(v − 1) = (v − 1)(v + 2 − k).
Therefore, the number that intersect W in exactly one
(unspeciﬁed) position is k(v − 1)(v + 2 − k).
3. The number disjoint from W is then
 
k
3
v − 1 − k(v − 1)(v + 2 − k) −
(v − 1).
2
Using an auxiliary generating function, and a careful decomposition of the codewords we again produce an explicit
generating function. Due to the complexity of the derivation
we do not present the details here.

46

OA(2,k,25) Slot Guarantee

1

0.8

Probability >= 1 Slot

Probability >= 1 Slot

1

0.6
0.4
0.2

0

20
40
60
Size of Neighbourhood

0.8
0.6
0.4
0.2
0

80

OA(3,k,11) Slot Guarantee

20
40
60
Size of Neighbourhood

80

Figure 4: Probability of ≥ 1 free slot in a frame for
OA(3, k, 11) (1331 nodes).

Figure 2: Probability of ≥ 1 free slot in a frame for
OA(2, k, 25) (625 nodes).

OA(2,k,v) Throughput

OA(3,k,8) Slot Guarantee
1
Expected Throughput

Probability >= 1 Slot

0.3

0.8
0.6
0.4
0.2
0

0.25
0.2
0.15
0.1
0.05
0

20
40
60
Size of Neighbourhood

80

10
20
30
Size of Neighbourhood

40

Figure 5: Expected throughput for OA(2, k, v) for v
a prime power from 3, . . . , 27.

Figure 3: Probability of ≥ 1 free slot in a frame for
OA(3, k, 8) (256 nodes).

(not asymptotically zero, but equal to zero) in the ﬁgure
for smaller values of v. For the strength three orthogonal
array, the drop is not as sharp as for the strength two array,
though this is less noticeable as k increases.
Throughput is independent of the number of subframes,
thus expected throughput is computed on a subframe basis.
This merits a brief discussion. In employing the evaluation
of the generating function φ to calculate expected throughput, we noted in the computational results this apparent
independence. Indeed, it is easy to establish that expected
throughput does not depend upon the number of subframes.
This is in stark contrast to the minimum throughput.
Figures 7 and 8 plot, respectively, the ratio of the expected
throughput of an OA(2, k, v) and an OA(3, k, v) to TDMA
as a function of the number of neighbours, assuming k = v
(i.e., the TDMA frame length is v 2 ). In Figure 7 for the
OA(2, k, v), the y-intercept corresponds to the prime powers. Here we see that the expected throughput is at most v
times that of TDMA. For the strength three OA(3, k, v) in
Figure 8, we see a dramatic diﬀerence in expected throughput since it can be as much as v 2 times that of TDMA (albeit
under rare circumstances). It remains proportionally higher

arrays are much shorter. On the other hand, they support
more neighbours for the same frame length.
It is worth comparing the OA(2, k, 17) that supports 289
nodes in Figure 1 to the OA(3, k, 8) that supports close to
the same number of nodes (256) in Figure 3. If the actual
node degree is very small, it is much better to use the shorter
frame length schedules of the OA(3, k, 8). The schedules
from the OA(2, k, 17) can tolerate higher variance in the
node degree. Thus, if node degree can be controlled through,
say, a topology control protocol, or the network topology is
controlled when the network is established (as it might be for
a sensor network) then a higher strength code is the better
choice.
Figures 5 and 6 plot, respectively, the expected throughput for an OA(2, k, v) and an OA(3, k, v) for v a prime power
from three up to 27 as a function of the number of neighbours. Again, both ﬁgures show a similar structure. The
y-intercept of each curve is 1/v for a given v. The curve
corresponding to v = 3 has the highest y-intercept. The
curves down from it correspond to successive increasing values of v. The expected throughput drops rapidly to zero

47

OA(3,k,v) Throughput

OA(3,v,v) vs. TDMA
700
Ratio to TDMA Throughput

Expected Throughput

0.3
0.25
0.2
0.15
0.1
0.05
0

10
20
30
Size of Neighbourhood

600
500
400
300
200
100
0

40

Figure 6: Expected throughput for OA(3, k, v) for v
a prime power from 3, . . . , 27.

10
20
30
Size of Neighbourhood

40

Figure 8: Ratio of expected throughput of OA(3, k, v)
to TDMA, assuming k = v.

OA(2,v,v) vs. TDMA

15

tolerates a larger number of neighbours. In both cases, the
expected throughput is signiﬁcantly better than the minimum. Neither [3] nor [8] discussed expected throughput.
This metric is considerably more informative with respect to
throughput than the minimum (or the maximum), although
minimum throughput is an essential metric for quality-ofservice.

10

5.

Ratio to TDMA Throughput

25
20

5
0

10
20
30
Size of Neighbourhood

SUMMARY AND FUTURE WORK

In this paper, we showed that the topology-transparent
medium access control protocols known correspond to an
orthogonal array. As a result of this observation, we showed
some new results on throughput. We gave analytical expressions for the probability of a successful transmission in
a frame, as well as for the expected throughput. After running a number of experiments on strength two and strength
three OAs using Maple [11], we interpreted the results, emphasizing the sensitivity of the schedules to the actual node
degree.
Our analysis has focussed on a single frame; while this
is a reasonable view for studying minimum throughput, it
ignores what happens when the neighbourhood limitation is
exceeded. Ju and Li [8] argue that by selecting a larger v,
their choice is (relatively) insensitive to the degree limitation; essentially they “over-engineer” the system to permit
more neighbours than the design criteria stipulate. Nevertheless, their scheme can fail totally when the number of
neighbours exceeds the capacity of their chosen scheme, despite its continued operation for some numbers of neighbours
larger than the stipulated number.
Chlamtac, Faragó and Zhang [4] propose a diﬀerent solution, interleaving or “threading” diﬀerent schemes each
supporting a diﬀerent degree limitation; however, this incurs a dramatic slowdown in the initial scheme and hence a
substantial penalty is paid whether or not the degree limit is
exceeded. What is needed is a scheme that, if the degree limitation might be exceeded, degrades gracefully rather than
failing completely (as in [8]) or imposing a large slowdown
factor (as in [3]). Ju and Li’s approach fails to provide a
guarantee when the number of neighbours is too large. This
in itself is reasonable. However, their scheme repeatedly uses
the same frame schedule in each subsequent frame. Thus loss

40

Figure 7: Ratio of expected throughput of OA(2, k, v)
to TDMA, assuming k = v.
as the number of neighbours increases. In [8] it is suggested
to use a larger prime than the minimal choice in order to
obtain the best minimum throughput. Our results indicate
that the same is true for expected throughput.
Finally, Figure 9 compares several functions for 729 nodes.
The reason this value for N was selected is because 729 =
3
2
(32 ) = (33 ) . The straight line at the bottom of the ﬁgure
shows the expected throughput of TDMA (1/729). For the
OA(2, k, 27) we plot both the minimum and the expected
throughput. These are the two less steep curves, with the
minimum throughput below expected throughput. For the
OA(3, k, 9) we also plot both the minimum and expected
throughput. These are the two steep curves, with the minimum below the expected throughput. The frame length of
schedules derived from the OA(2, k, 27) is 27k, while for the
OA(3, k, 9) it is 9k.
The ﬁrst observation is that both the strength two and
three orthogonal arrays outperform the expected throughput of TDMA to about 30 neighbours for the OA(3, k, 9)
and about 85 neighbours for the OA(2, k, 27) (though this is
not a guarantee). The expected throughput for the strength
two array degrades slower than the strength three array, and

48

729 Nodes

In this way, denial of service can be held to any speciﬁed
probability tolerance, while ensuring that when the degree
limit is met, there is provably no denial of service.
In our future work, we plan to explore these two methods
for coping with the design parameter of maximum degree
being exceeded, through mobility, power control, or otherwise.

0.1

Throughput

0.08
0.06

6.
0.04
0.02
0

20
40
60
80
Size of Neighbourhood

REFERENCES

[1] IEEE standard 802.11: Wireless LAN medium access
control and physical layer speciﬁcations, December
1999.
[2] M. Benveniste, G. Chesson, M. Hoeben, A. Singla,
H. Teunissen, and M. Wentink. Enhanced distributed
coordination function (EDCF). In IEEE Working
Document 802.11-01/131r1, March 2001.
[3] I. Chlamtac and A. Faragó. Making transmission
schedules immune to topology changes in multi-hop
packet radio networks. IEEE/ACM Transactions on
Networking, 2(1):23–29, February 1994.
[4] I. Chlamtac, A. Faragó, and H. Zhang. Time-spread
multiple-access (TSMA) protocols for multihop mobile
radio networks. IEEE/ACM Transactions on
Networking, 5(6):804–812, December 1997.
[5] I. Chlamtac and S. Pinter. Distributed node
organization algorithm for channel access in a
multi-hop packet radio network. IEEE Transactions
on Computers, 36(6):728–737, 1987.
[6] C. J. Colbourn and J. H. Dinitz, editors. The CRC
Handbook of Combinatorial Designs. CRC Press, Inc.,
Boca Raton, FL, 1996.
[7] A. S. Hedayat, N. J. A. Sloane, and J. Stufken.
Orthogonal Arrays, Theory and Applications.
Springer-Verlag, Inc., New York, NY, 1999.
[8] J.-H. Ju and V. O. K. Li. An optimal
topology-transparent scheduling method in multihop
packet radio networks. IEEE/ACM Transactions on
Networking, 6(3):298–306, June 1998.
[9] L. Romdhani, Q. Ni, and T. Turletti. AEDCF:
Enhanced service diﬀerentiation for IEEE 802.11
wireless ad-hoc networks. Technical Report 4544,
INRIA, 2002.
[10] J. L. Sobrinho and A. S. Krishnakumar.
Quality-of-service in ad hoc carrier sense multiple
access wireless networks. IEEE Journal on Selected
Areas in Communications, 17(8):1352–1368, August
1999.
[11] Waterloo Maple, Inc. Maple 8.
http://www.maplesoft.com/main.html.
[12] C. Zhu and S. Corson. A ﬁve-phase reservation
protocol (FPRP) for mobile ad hoc networks. In
Proceedings of 17th Annual Joint Conference of the
IEEE Computer and Communication Societies
(INFOCOM’98), (San Francisco, CA, March 29-April
2, 1998), pages 315–321, 1998.

100

TDMA
OA(2,k,27) expected
OA(2,28,27) minimum
OA(3,k,9) expected
OA(3,10,9) minimum
Figure 9: Comparison of minimum and expected
throughput for OA(2, k, 27) and OA(3, k, 9) to TDMA.
of transmission opportunity within one frame is extended to
all subsequent frames unless and until transmitting nodes
move or cease transmission. Of course, this does not impact the expected throughput. But when the degree limit is
exceeded, it can result in a denial of service to some nodes.
Our results demonstrate, however, that expected throughput can remain quite acceptable when the degree limitation
is exceeded. Our task, then, is to ensure that a situation
resulting in catastrophic collisions in one frame is not automatically repeated in the next frame by simply repeating
the schedule. Two methods suggest themselves. The ﬁrst is
to allow nodes to remain silent throughout a frame despite
having a pending transmission, i.e., “backing oﬀ” when it is
detected that the degree limit is exceeded. When the degree
limit is satisﬁed, such a scheme ensures nonzero minimum
throughput; when exceeded, the scheme employs contention.
A second method is suggested by the results on expected
throughput. If the number of neighbours exceeds the degree
limit, the expected throughput tells us the likelihood that we
will fail. The combinatorial properties of the scheme explain
why we could fail: our neighbours interfere with each of our
transmission slots. So while minimum throughput tells us
that we could fail, expected throughput tells us how likely
we are to be unlucky enough to have neighbours that cause
us to fail. Now we cannot choose our neighbours, but we
can do something equivalent. By distributing codewords to
nodes at random in each frame, the expectation within one
frame does not depend on the outcome of another (unlike
[3, 8] where it is the same outcome). Obviously this poses
insurmountable practical problems, so we propose selecting
a ﬁxed number of frames f , and making f random distributions of the codewords to be used in f successive frames,
repeatedly.

49

Theory Comput. Systems30, 145-163 (1997)

Theory of
Computing
Systems
© 1997 Springer-Verlag
New York Inc.

Wang Tilings and Distributed Verification
on Anonymous Torus Networks
V. R. Syrotiuk, I C. J. Colbourn, 2 and J. Pachl 3
i Computer Science Program, Mail Station EC 3.1,
University of Texas at Dallas,
Richardson, TX 75083-0688, USA
syrotiuk@utdallas.edu
2Department of Combinatorics and Optimization,
University of Waterloo,
Waterloo. Ontario, Canada N2L 3G 1
3 Department of Computer Science,
University of Waterloo,
Waterloo, Ontario, Canada N2L 3G 1

Abstract. Consider n2 processors arranged in an n x n torus network in which each
processor is connected by direct communication channels with its four neighbours.
This paper studies the following verification problem on anonymous n × n torus
networks: verify whether the network is oriented; that is, verify whether there is an
agreement, among all processors, on a consistent channel labelling. The problem is
to be solved by a distributed algorithm executed by the processors themselves.
If processors can label their channels arbitrarily, then there are network labellings that are not oriented but, to the processors, are indistinguishable from ones
that are oriented. Hence there is no deterministic distributed verification algorithm.
However, a verification algorithm does exist if the initial labellings are suitably restricted. We describe the restrictions placed on the initial labellings by subsets o f
the permutation group $4.
We show that the existence of an algorithm for verification is equivalent to the
existence o f certain tilings of the torus with Wang tiles. Using this equivalence, we
have determined the existence of a distributed algorithm for the verification problem
for all n × n toms networks for an important class o f restrictions, the subgroups
o f $4.

146

1.

V.R. Syrotiuk,C. J. Colbourn, and J. Pachl

Introduction

Some classes of networks are represented as graphs that can be oriented; that is, the
network channels (graph edges) can be assigned labels that are in some sense consistent
throughout the network. Research on distributed algorithms often assumes that all processors in the network initially agree on a global orientation. Santoro [ 11] first observed
that the communication complexity of computations decreases in oriented networks.
This observation has been supported by results on numerous important problems on a
variety of network topologies including rings, meshes, toil, hypercubes, and cliques [1],
[2], [7], [6], [9].
While the importance of orientations is well established, the problems of finding
distributed algorithms to construct orientations and to verify whether a network labelling
is an orientation have not been studied extensively. We studied the orientation problem
on anonymous n x n torus networks in [13]. In this paper we study the verification
problem on anonymous n x n torus networks. Tel [15] studied network orientation on
cliques, hypercubes, and tori under different definitions and models.
In the terminology of Attiya et al. [1], a network is a n o n y m o u s if processors are
indistinguishable from each other, and all execute the same deterministic program. We
also assume that the configuration is asynchronous, that communication channels are
FIFO, and that processors know the network topology. The remainder of Section 1
discusses these model characteristics in more detail.
Section 2 provides definitions for three classes of network labellings and describes
the relationship between classes. The class of orientations is defined relative to a fixed
reference labelling. Quasi-orientations are a class of network labellings that satisfy label
pairs. Pseudo-orientations are quasi-orientations that satisfy label pairs of a special form.
The label pairs are those that make the network labellings in this class indistinguishable
from orientations to processors in an anonymous network. This class of labellings does
not arise in all network topologies. For example, pseudo-orientations do not arise in
ring networks. Thus the question of whether there are pseudo-orientations that are not
orientations is important in solving the verification problem.
In Section 3 we give a simple symmetry argument to show that no deterministic
distributed algorithm can verify whether an arbitrary initial channel labelling of an n x n
torus network is an orientation. However, an algorithm to verify orientation does exist
if the initial labellings are suitably restricted; in other words, if processors have enough
additional information about how channels are labelled. The restrictions placed on
the initial labellings are described by an orientation model, a subset of the permutation group $4. This paper is a systematic study of the existence of distributed
algorithms under such additional restrictions. The existence of a distributed algorithm
is dependent on the classes of labellings that arise for a given orientation model and
torus size.
Section 4 shows that the existence of an algorithm for verifying torus orientation is
equivalent to the existence of certain torus tilings. Using automated tools [ 10], we have
settled the question of existence of such tilings for many interesting subsets of $4; the
detailed results are reported in [ 12]. In this paper we report nearly complete results for
all torus sizes for the subgroups of $4, an important class of restrictions. Our results on
subgroups are summarized in Figure 5 on page 156.

Wang Tilings and Distributed Verification on AnonymousTorus Networks

147

1.1. Anonymous Networks
An anonymous network is a computer network in which processors are indistinguishable
from one another. Therefore, the processors do not have identifiers, and every processor
executes the same program.
Each processor in an anonymous network is given the topology of the network
modelled by an unlabelled graph G = (V, E) where vertices and edges correspond to
processors and communication channels, respectively.
To simplify the presentation in discussions that follow, the processors may be assigned identifiers. However, these identifiers are not available to the processors.

1.2. Communication by Message Passing
Processors in a network communicate by exchanging messages through the communication channels. Each processor can discriminate between its channels:
• Upon receipt of a message, a processor can determine the label of the channel on
which it arrived.
• A processor specifies the label of the channel on which a message is to be transmitted.
Thus, the channels incident with each processor u are assumed to be labelled locally by
u. If there are k channels incident with processor u, then the channels of u are labelled
by the label set L = {1, 2 . . . . . k}. Such a labelling is a channel labelling at u and is
denoted by ;~[u]. A = {(~.[u]), u ~ V} is a network labelling.
The communication channel connecting processors u and v therefore has two labels;
label,(u, v) is the label of the end incident with u and labelv(u, v) is the label of the end
incident with v.
1.3.

The View of a Processor

The view of a processor u represents the set of all labelled paths from processor u
in a network with network labelling A. Its view is the most information about the
network labelling that a processor can compute. Views were first defined by Yamashita
and Kameda [17]; they are a generalization of the notion o f a neighbourhood in ring
networks used by Attiya et al. [1].
Formally, a view ~^(u) for a processor u in a network with network labelling A is
an infinite, rooted tree with labelled edges defined recursively as follows. The root node
of V^(u) is u. For each vertex v adjacent to u in the network, VA(u) has a child node
v and an edge (u, v). The edge (u, v) in the view has two labels, one on each end, that
equal the labels on edge (u, v) in A. Specifically, the label of the endpoint at u of edge
(u, v) is label, (u, v) and the label of the endpoint at v of edge (u, v) is labelv (u, v). The
subtree of V^ (u) rooted at v is identical to VA (v).
For any positive integer d, Vd (u) denotes the view of processor u in A truncated to
the depth d; that is, the leaf nodes of "l)d(u) are the vertices to which there is a walk of
length d away from the root node u.
The views of two processors u and v are similar, denoted I'A (U) ~ ~)^ (V), if they
are isomorphic when the root of l;^ (u) is mapped to the root of );A (V) with the additional

148

v.R. Syrotiuk, C. J. Colbourn, and J. Pachl

requirement that the labels along edges match. If the views o f two processors are similar
to a sufficient depth, then they are similar everywhere. Norris [8] shows that a depth IV]
is sufficient, improving the bound by Yamashita and K a m e d a [17] by a factor o f IV].

2.

Torus Network Labellings

In this section we first define a reference labelling for an n x n torus network which in turn
simplifies other definitions. Several classes o f network labellings are defined, followed
by properties o f labellings in these classes. We conclude with a formal statement of the
verification problem.

2.1.

The Reference Labelling

Let G = (V, E ) , defined as the Cartesian graph product [5] o f two identical n-cycles,
model an n x n toms network. (We assume n > 2 throughout this paper so that G is a
simple graph.) Since a toms is 4-regular, the label set L = { 1, 2, 3, 4} is used to label
the channels incident to each vertex.
At every processor modelled by vertex u -----(i, j ) let

1.
2.
3.
4.

label~ (u,
labelu(u,
label,(u,
labelu(u,

v)
v)
v)
v)

=
=
=
=

1 for
2 for
3 for
4 for

v
v
v
v

=
=
=
=

(i, j
(i +
(i, j
(i -

+
1,
1,

1),
j),
1), and
j),

arithmetic modulo n. This assignment o f labels to the endpoints o f each edge defines the
reference channel labelling ~.0[u] at processor u. A0 = {(~.0[u]), u ~ V} is the reference
labelling of an n × n toms network. Figure 1 shows an n × n torus with the reference
labelling.
2.2.

Orientation Models

The channel labelling at a processor u is now defined as a permutation o f the reference
channel labelling. That is, ~[u] = pu o ~o[u] for p , ~ $4, the symmetric permutation
group on the label set L. Table 1 lists each permutation o f L and assigns it a name. To
distinguish the names of the permutations in $4 from variables we set them in typewriter
type as 7-, a , b , c . . . . , y. (The permutation names are the same as those used by
Budden [3].)
An algorithm to verify orientation exists if the initial labellings are suitably restricted;
in other words, if processors have enough additional information. A n orientation model
A4 describes which channel labellings m a y occur and corresponds to a subset of $4 at
each processor in the toms network. Since the network is anonymous we assume that
the set .A4 is the same at each processor in the network.
In addition to knowing the network topology, processors also know .A4. In a network
labelling in orientation model A/l, the channel labelling at each processor in the network
must be from A//; that is, A ----{~.[u] = p , o ~.0[u], u E V} where p~ c .A//. The fact that
the channel labelling )~[u] at u is described relative to the reference channel labelling
does not compromise anonymity. Processor u does not know pu, only that p~ 6 .A4.

Wang Tilings and Distributed Verification on Anonymous Torus Networks

149

]

1

>

1

1

2

>
J

i

>
Fig. 1.

Reference labelling of an n x n torus.

Table 1.
Name

Linear form

z
a
b
c
d
f
g
h
5_
j
k
1

(1234)
(1243)
(1324)
(1342)
(1423)
(1432)
(2134)
(2143)
(2314)
(2341)
(2413)
(2431)

$4, the symmetric permutation group on L = {1,2, 3, 4}.
Canonical form
(4)(3)(2)(1)
(34)(2)(1)
(4)(23)(1)
(234)(1)
(243)(1)
(3)(24)(1)
(4)(3)(12)
(34)(12)
(4)(123)
(1234)
(1243)
(3)(124)

Name

Linear form

ra
n
p
q
r
s
t
u
v
w
x
y

(3124)
(3142)
(3214)
(3241)
(3412)
(3421)
(4123)
(4132)
(4213)
(4231)
(43t2)
(4321)

Canonical form
(4)(132)
(1342)
(4)(2)(13)
(2)(134)
(24)(13)
(1324)
(1432)
(3)(142)
(2)(143)
(3)(2)(14)
(1423)
(23)(14)

150
2.3.

W.R. Syrotiuk, C. J. Colbourn, and J. Pachl

Generalizing Definitions

The definitions of orientation and quasi-orientation for anonymous ring networks as
given by Attiya et al. [1] are generalized to the torus as follows.
Let A be a network labelling of an n × n torus network. A is an orientation if
the channel labelling at each processor is identical; that is, Z[u] = p o ~.0[u], for every
processor u in the network. (In what follows, we abbreviate ~.[u ] = po)~0[u] as )~[u] = p.)
A is a quasi-orientation if all processors in the network have similar views; that is,
~A (u) ~ ~^ (v) for all processors u and v in the network.
2.4.

Properties of Labellings

In the following let A be a network labelling of an n × n torus network. (The lemmas in
this section are given without proof; full proofs are available in [ 12].)
L e m m a 1.

If A is an orientation, then A is also a quasi-orientation.

An orientation is simply a quasi-orientation in which every processor has the same
channel labelling.
2.4.1. Pseudo-Orientations. Some network labellings have the property that each label
coexists with only one label at the opposite end of any edge. In other words, there exists
a permutation P 6 $4 such that

labelu(u, v) = P(label~(u, v))
for every edge (u, v). When a network labelling A has this property, we say that A

satisfies label pairs P.
An arbitrary network labelling A is a quasi-orientation if and only if it
satisfies label pairs.
L e m m a 2.

It follows that every orientation satisfies label pairs. Moreover, the label pairs P
satisfied by an orientation are of a special form: P is one of the permutations

Pc12) = (12)(34),
P~13) = (13)(24),

or

P~14) = (14)(23).
For a given orientation model A/l, let T'(.A.4) ~ {Po2), P~13~, P~14)} be the set of label
pairs that the orientations in M satisfy. Pseudo-orientations of M are quasi-orientations
of.A.'l that satisfy P 6 7-9(.M).
Figure 2 shows the inclusions among the classes o f all network labellings, quasiorientations, pseudo-orientations, and orientations. In some orientation models the class
of pseudo-orientations and orientations is the same, while in others there are pseudoorientations that are not orientations: An orientation model .M is verifiable for n if,
for an n × n toms, every pseudo-orientation of .A// is an orientation. This property of
network labellings in AA is the key to the existence of a distributed verification algorithm
in orientation model AA.

Wang Tilings and Distributed Verification on AnonymousTorus Networks

151

all network labeUings
~ ~ / q

uasi-°fi.entati°n ~ ' x ~ x

Fig. 2. Inclusionsamong the classes of network labellings in $4.

2.5.

The Verification Problem on the n x n Torus

Our goal is to find a distributed algorithm to solve the verification problem on n x n
toms networks.

Verification Problem. Verify whether a network labelling A of an n x n torus network
in orientation model A4 is an orientation.
Formally, each processor u computes a Boolean value as output such that the value
is True if A is an orientation and False otherwise.

3.

Distributed Verification

In this section we give a distributed algorithm to solve the verification problem. The
existence of the algorithm is related to the classes of labellings that arise for a given
orientation model .A4 and a torus of size n × n.

Theorem 3.

.A4 is verifiable f o r n i f and only i f there is a distributed algorithm to solve
the verification problem on an n x n torus network in Ad.

Proof. (=¢,) Suppose that A4 is verifiable for n. Let A be a network labelling o f an n x n
torus in .h4. A sketch of an algorithm ,A for solving the verification problem follows. By
Lemma 4.1 in [17], each processor u can construct V d ( u ) for any finite depth d > 0.
Thus on each processor u, algorithm ,,4 constructs Vd (u) to depth d = 2Ln/2J + 1 (the
diameter o f an n x n torus plus one) from messages exchanged with other processors.
This depth ensures that every edge is represented at least once in the view.
If the label pairs on edges in VA
d (u) do not satisfy label pairs P c 79(A4), then A is
not an orientation and u produces False as output. Otherwise, A is a pseudo-orientation.
Since .A4 is verifiable for n, every pseudo-orientation is an orientation; thus A is an
orientation and processor u produces True as output.

! 52

v.R. Syrotiuk, C. J. Cotbourn. and J. Pachl

(¢=) Assume that.4 is a verification algorithm and that.A4 is unverifiable for n. Then
for some P E T'(.A4) there is both an orientation Al 6 .A4 and a pseudo-orientation
A2 6 M that is not an orientation, such that both A~ and Az satisfy P. Run the
verification algorithm .,4 on each of the network labellings A~ and A2..,4 produces the
same output for A 1 and for A2 since all processors have the same view in both network
labellings. This yields a contradiction: .,4 cannot be a verification algorithm since it does
not distinguish between A1 and A2.
[]
To construct a view to a depth of d = 2 Ln/2] + 1 requires each processor to send
4d messages. Since there are n 2 processors, a total o f 4n2(2 [.n/2] + 1) messages are
exchanged. Once a processor computes its view to depth d, the rest of the computation
is done locally with no further message exchanges. Thus, the verification algorithm
requires O(n 3) messages.

4.

The Correspondence Between Labellings and Tilings

This section describes a correspondence between the class of quasi-orientations of network labellings of an n x n torus network and tilings o f n × n tori with Wang tiles. As an
application of this correspondence, the problem of determining whether an orientation
model M is verifiable for n is translated into a tiling problem. In Section 5 we then study
the verifiability of orientation models that are subgroups as tiling problems.

4.1.

Wang Prototiles and Tilings

A Wang prototile is a unit square whose edges are coloured [4]. A Wang tile is a Wang
prototile positioned in the xy-plane so that its bottom edge is parallel to the x-axis, the
x-coordinate increases from left to right, and the y-coordinate increases from bottom to
top. Thus any two tiles obtained from the same Wang prototile are translations o f one
another. (Formally, a Wang tile is a prototile together with the coordinates of its bottom
left corner.)
When T is a set of Wang prototiles, a tiling of the plane admitted by T is a set of
Wang tiles covering the plane such that
• each tile in the tiling is obtained from a prototile in T;
• the corners of the tiles are at points with integer coordinates; and
• the interiors of the tiles do not intersect.
As a result of these properties, the tiles in a tiling are arranged in rows and columns.
A tiling is a Wang tiling if
• when two tiles share an edge, that edge has the same colour in both tiles.

A Wang tiling of an n x n block admitted by T is a set of Wang tiles that covers the
square {(x, y)10 < x, y < n } and satisfies the four properties above. If the colours of the
edges on the left side of the block match those on the right and the colours of the edges
along the top match those along the bottom, then the block is a torus [16].
In a monohedral tiling all the tiles are obtained from the same prototile. A multihedral
tiling is one that is not monohedral.

Wang Tilings and Distributed Verification on Anonymous Torus Networks

153

Fig. 3. The $4 Wang prototiles.

4.2.

Models and Prototiles

The channel labelling at a processor u corresponds to a Wang prototile, where each
channel incident with u corresponds to an edge of the prototile. The label set L is now
interpreted as the colours available to colour prototile edges.
In this relationship an orientation model corresponds to a set of prototiles. Since
orientation models are subsets of $4, every prototile set is a subset of the $4 Wang prototiles. This prototile set is constructed as follows. First construct the "identity prototile":
starting at the top edge, "colour" the edges in the clockwise direction 1,2, 3, 4, in that
order. Now, for every permutation p in $4, permute the colours of the identity prototile
by permutation p to obtain the prototile corresponding to p (denoted by [~]). Figure 3
shows the $4 Wang prototiles that result from this construction.
The set of Wang prototiles that corresponds to the orientation model .A4 = {p~, P2,
. . . . pn} is T = {[-~--], [ ~ ] . . . . . [ ~ ] } , where Pi is a permutation in $4 and [~--] is the
$4 Wang prototile constructed from Pi, for i = 1,2 . . . . . n.
4.3.

LabeUings and Arrangements

Let T be the set of $4 Wang prototiles that corresponds to orientation model .h4. Given
a network labelling A of an n x n toms in .A4, there is an n x n arrangement 7" of Wang
tiles from T that corresponds to A. For each processor u = (i, j ) , )~[u] = p if and only
if the bottom left comer of tile [ ~ ] is positioned at coordinates (i, j).
As an example, Figure 4 shows a network labelling of a 3 × 3 torus network from
orientation model .M = {'r, b, £} and the corresponding 3 x 3 arrangement of Wang
tiles from T = {[~], [~], [ ~ } .
4.4.

Labels and Colours

Suppose that processors u and v are neighbours and that ~.[u] = p and ~.[v] = p' in A.
Then if T corresponds to A, then [ ]

is adjacent to the tile [ p ' ] in T. For example, this

implies that the [ ] tile in the bottom right comer is adjacent to the four shaded tiles in
Figure 4.
Furthermore, if labe lu ( u, v) = £ ~and labe lv ( u, v) = g2 in A, then the edge coloured

154

V.R. Syrotiuk, C. J. Colbourn, and J. Pachl

Fig. 4. A and 7- correspond.

1 of tile [ ] is adjacent to the edge coloured 6 2 o f l p ' Iin 7-. That is, the labels at opposite
ends of (u, v) in A correspond to the colours of edges of adjacent tiles in 7-.
4.5.

Quasi-Orientations and Tori

One property of a Wang tiling specifies that when two tiles share an edge, that edge has
the same colour in both tiles. This standard contact law for Wang tiles may be generalized
as follows.
Let t and t' be two tiles in a tiling. If t and t' share an edge, denote by colourt (t, t')
the colour of the edge in t.
A contact law is a permutation C 6 $4 such that C = C -l (that is, C o C is the
identity).
A tiling of the plane satisfies the contact law C if colourt (t, t') = C(colourt, (t, t'))
for each pair of tiles t and t' in the tiling that share an edge.
Thus if a tiling satisfies a contact law, then each colour coexists with only one colour
at the shared edge of an adjacent tile in the tiling (because C = C - l ) .
By the definition in Section 4.1, a tiling is a Wang tiling if and only if it satisfies the
identity contact law (that is, the contact law C where C is the identity permutation).
A tiling of an n × n block that satisfies the contact law C is defined similarly.
In the following theorems, let .A//be an orientation model with T its corresponding
Wang prototile set, and let A correspond to 7-.
T h e o r e m 4. A is a quasi-orientation if and only if there exists a contact law C such
that 7- satisfies C.

Proof.

(=*) Suppose that A is a quasi-orientation. By Lemma 2, A satisfies some
channel label pairs P.
If processors u and v are neighbours, then the files that correspond to u and v
in 7- are adjacent. By the definition of a network labelling that satisfies channel label
pairs, for every edge (u, v), there exists a permutation P E $4 such that labelu (u, v) =
P (labelv (u, v)). Thus for all adjacent tiles in 7- the colours at the shared edge are given
by P. Hence 7" is a tiling of an n x n torus that satisfies contact law C = P.

Wang Tilings and Distributed Verification on AnonymousTorus Networks

155

(¢=) Suppose that T is a tiling of an n x n torus that satisfies contact law C. By
the definition of a tiling that satisfies contact law C, for every pair of adjacent tiles
t and t', colourt(t, t') = C(colourt,(t, t')). Thus for all edges (u, v), labelu(u, v) =
C(labelv(u, v)). Hence A satisfies channel label pairs P = C. By Lemma 2, A is a
quasi-orientation.
[]
Theorem 4 suggests a way to determine whether .A/I is verifiable for n.

Theorem 5. .A// is verifiable for n if and only if.for each P E 79(A4), T admits no
multihedral tilings of an n × n torus that satisfy P.
Proof

A4 is verifiable if and only if every pseudo-orientation satisfying P E 79(A/[)
is an orientation if and only if every tiling T satisfying P 6 T'(A4) is monohedral. []

5.

Verifiability of Subgroup Orientation Models

The subgroups of $4 are an important class of orientation models for n × n torus networks.
The primary reason is that if A is a network labelling in subgroup ,A/l, then for any
p E .M we have p o ~.[u] c A//. Another reason is that some subgroups have a practical
geometrical interpretation as rotations and reflections. These subgroups represent more
natural restrictions of the channel labellings than arbitrary subsets.
We have answered the question
"Is the orientation model A/f verifiable for n?"
for all n, and all subgroups .M of $4, except one subgroup--the alternating group A4.
Figure 5 shows the subgroup lattice for $4 and summarizes these results. What we know
about A4 is that it is unverifiable for n when 2In and 5In, and is verifiable (by exhaustive
generation) for each n E {3, 7, 9, 11, 13, 17, 19, 21, 23}. These results were obtained as
an application of Theorem 5 and are summarized in the following sections.

5.1.

Unverifiable Subgroups of Size 2

Lemma 6.

The subgroup

of the $4 Wang prototiles is unverifiable for all n > 2.
Proof. T~({[-~, [~]}) = P03). Figure 6 shows how to construct a dihedral tiling of an
n x n torus admitted by T that satisfies contact law P~13) for any n > 2; namely by
positioning [ ] tiles in row zero and positioning [ ] tiles in the remaining n - 1 rows.
Thus, T is unverifiable for all n > 2.
[]
A similar construction shows that:

V. R. Syrotiuk,C. J. Colbourn,and J. Pachl

156

[ l,a,b,c,d,f,g,h,ij,kJan,a,poq.r,,,t,u,v,w,x,y
J

I,c,d,h.iJ ,m,q.t,u,v,y

Legcad:

~ x ~

[mml unveti[iable for all tl > 2
vccifi~le for AI!n > 2
L~

verifiable for odd n > 2, unverifiable for e v m n • 2

Fig. 5. The subgrouplattice of $4.
Lemma 7.

The subgroup

of the $4 Wang prototiles is unverifiable for all n > 2.
Lemmas 6 and 7 immediately yield the following results:
Corollary 8. Any set T of the $4 Wang prototiles that contains either {[z-'I,IT]} or
{[-£1,[~]1 as a proper subset is unverifiable for all n > 2.
Corollary 9.

The orientation model $4 is unverifiable for all n > 2.

Corollary 10. Each of the subgroups {[], V~, V~, V~}, {V~, [ ] , V~, [ ] , [ ] , []},

IVY,D, V~,V~,[], []J, IVY,V~,V~,V~,[], DI, ~V~,B [], D, [], []~,and
{FI-], V~], @ , D , V~, ~ ] , ~ ] , Fy-]} is unverifiablefor alln > 2.

Wang Tilings and Distributed Verification on A n o n y m o u s Torus Networks

I

L

t4

157

]

1
3

3
[

t

I

I
1

4

I

24

I

2

f

1

42

f
3

3
Fig. 6.

----- ~ 3~

3

3
1

A multihedral tiling of an n x n torus admitted by {[-I-], IT]}, n > 2.

Unverifiable Subsets of Size 3

5.2.

The set

11.

Lemma

of the S4 Wang prototiles is unverifiable for all n > 2.

Proof.

79({[-I-],['Z], I-g-I}) = {P03), P(14)}. Figure 7 shows how to construct a trihedral
tiling of an n × n torus admitted by T that satisfies P~13) for any n > 2. Position a [ ]

at coordinate (0, 0), an [~] at coordinate (1,0), and [ ] in all the remaining coordinates
of row zero. Position tiles in row j = 1 . . . . . n - 1 such that the tiles in row j are a
cyclic shift to the left by one position of the tiles in the previous row, j - 1. Thus, T is
unverifiable for all n > 2.
[]

1 t 211
I

4

g

3

3

13

a
4
I

. . . .

3

4

I
II
f
t

I
4- . . . . . . .
t
I
I

--

211]i 1

a
4
2
g
3

Fig. 7.

~.

I
3
1

I
3
1

2

3

a
4

I
3

2

,

I

g

I

3

A multihedral tiling of an n x n torus admitted by {IT], [-a'], D } , n > 2.

158

V.R. Syrotiuk, C. J. Colbourn, and J. Pachl

A similar construction shows:

Lemma 12.

The set

of the $4 Wang prototiles is unverifiable for all n > 2.
Lemmas 11 and 12 give the following result:

Corollary 13.

Any set T of the $4 Wang prototiles containing either {F~, [ ~ , ~]} or

{[-I-~,I-b], ~w-]}as a proper subset is unverifiable for all n > 2.
Corollary14.

Each

of

the

subgroups

{~,[~,~,[-fi-]},

{[-I-],[~,Vw],[-y-]},

{~-I-],[a-I, [~], ~-], [-r], ~ ] , [-x-I, [-y-]}, and {I-I-I, V-b], [-h-], I-k], V-n-I,I--r-I,[-w], I-y--I}is unverifiable for all n > 2.
5.3.

Verifiability of the Remaining Subgroup Models

The verifiability of the remaining subgroup orientation models is obtained using a very
different technique. This technique, developed by Syrotiuk et al. [12], [14] is briefly
summarized in the next section.

5.3.1. Characterizing Wang ~lings Using Finite Automata. A characterization oftilings
of the plane admitted by a set of Wang prototiles T satisfying contact law C is developed
using techniques from formal language theory. In this characterization, an important set
of words--the limit row set--is expressed as the intersection of an infinite sequence of
regular sets. Define the limit row set of T as
p = N p(i)
i=O

where a row belongs to p(i) if and only if it occurs as a middle row in a tiled strip that is
2i + 1 rows high. The limit row set is the set of all rows that occur in tilings of the plane
admitted by T satisfying C.
A process to compute the limit row set is as follows: Construct a finite automaton
(FA) that describes all filings of the initial row set p(0), admitted by T satisfying C.
Usually, only some subset of the row tilings appears in filings of the plane. Using
operations on finite automata we iteratively refine the set of rows, eliminating rows
that cannot occur in tilings of the plane.
In many cases the infinite intersection can be replaced by a finite one; that is, the
computational process stabilizes (converges) after finitely many steps. The result is a
stable row FA of T satisfying C.
In some cases the process does not stabilize even when the intersection of the infinite
sequence is regular. In other cases the intersection is not regular, so that no matter how it
is expressed in terms of an infinite sequence of regular sets, the process does not stabilize.

Wang Tilings and Distributed Verification on AnonymousTorus Networks

159

Table 2. Subgroup models verifiable for all n.
Tilings admitted by T that satisfy
T

P02)

Only monohedral

Only monohedral

~E

Only monohedral
Only monohedral
Only monohedral
Only monohedral

G,171,½,U)

P(t3)
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral
Only monohedral

P(14)
Only monohedral
Only monobedral

Only monohedral
Only monohedral
Only monohedral
Only monohedral

For all remaining subgroups of $4, except A4, the process to compute the limit
row set stabilizes. The verifiability of each subgroup for all n is derived directly from
its corresponding stable row FA. The sequence of finite automata were obtained using
a r a i 1 [ 10], an environment in which different types o f languages and abstract machines
can be studied.
5.3.2.

The Remaining Subgroup Orientation Models

~), ~[~,1-+--II,(@, I~),
G ' l-Zl),g-~,D)' ID, ~), G I-+I,DI, g-q,D, D , ~ , ~, ~), (D, I~' ~)'

Lemma

IS. each oS,he subgroups Q ) , t~, l-&-l),tD,

{F£],r~, FE],[]}, and {[], ~ , [], ~q} is verifiablefor all n.
Proof

Table 2 summarizes the form of the tilings admitted by each subgroup T listed
in the lemma for each P 6 T'(T). A blank entry in the table means that P ¢ P ( T ) . The
entries in Table 2 were obtained as follows: For each subgroup T listed in the lemma,
construct the stable row FA for each 79(T). In each case the stable row FA consists of
unconnected components, each of which has a single state and transition. Thus the stable
row FA gives rise to monohedral tilings only.
For each subgroup T listed in the lemma, Table 2 shows, for each contact law
P 6 79(T), that T admits only monohedral tilings of an n x n torus that satisfy P for all
n. Thus, each subgroup T is verifiable for all n.
[]
Now, several examples are given to illustrate how Table 2 was derived from the
stable row FA.
For the subgroup T = {[-£], [~]}, 79(T) = {P(13), P(14)}. Figure 8 shows that T
admits only monohedral tilings of the n x n torus with [ ] that satisfy P(13) for all n, and

160

V. R. Syrotiuk,C. J. Colbourn, and J. Pachl
I

Fig.

a

8. The stable row FA for {[-I-I.....['a-]/for(a) P03) and (b) ?.4~-

only monohedral filings with [ ~ that satisfy P04) for all n. Thus {[I-], I-a-I} is verifiable
for all n. A similar argument shows that {~], [~]}, {[T], I-g-I}, {[-i-], [-}-]}, {I-i-], I-if]} are
verifiable for all n.
For the subgroup T = {I-f], rh-]}, 7~(T) = {Po3)}. Figure 9 shows that T admits
only monohedral filings of the n × n toms with [ ] or [ ~ that satisfy/'(13) for all n. Thus
{[!], [~} is verifiable for all n. A similar argument shows that {[~], [-~} is verifiable for
all n.
For the subgroup T = {[I-I, [ ~ , [-d-I}, 79(T) -----{Po2), P(13), P(I4)}. Figure 10 shows
that T admits only monohedral tilings of the n × n toms with [-~, [i-], and [ ] that
satisfy P(12), P(13), and P(14), respectively, for all n. Thus if-f], I-c-I, [~]} is verifiable for
all n. A similar argument shows that {[~, [-~, I-if]}, {[-I], I-f], [-6-]}, and {I--i-I,@ , I-if-I}are
verifiable for all n.
For the subgroup T = {[-~,[-h-],[-~,[-~-]}, T'(T) = {P(x3)}. Figure 11 shows
that T admits only monohedral filings of the n x n toms that satisfy P(13). Thus
{[T], I-if], [-~-], I-Y-I}is verifiable for all n. A similar argument shows that {I-I], [j-I, [Z], [Z]}
is verifiable for all n.
L e m m a 16. Eachofthe subgroups {[I-], ~h--],[~, I-x-I} and {I--I-],[-~, [--£-],[-y]} isverifiable for odd n and unverifiable for even n.
Proof For each subgroup T listed in the lemma, Table 3 shows, for each contact law
P e T~(T), that T admits only monohedral tilings of an n x n toms that satisfy P when
n is odd, but admits both monohedral and multihedral tilings of an n x n toms when n
is even. The entries in Table 3 were obtained by first constructing the stable row FA for
each T for each P e 79(T). In each case the .stable row FA consists of three unconnected
components. Two components, each consisting of a single state and transition give rise
to monohedral tilings only. The component consisting of two states and transitions gives
rise to dihedral tilings of even-sized toil. Since there is no closed walk of odd length in
this component, there are no multihedral tilings of odd size. Thus, each subgroup T is
verifiable for odd n and unverifiable for even n.
[]

For the subgroup T = {[~], [-~, ms-], [~}, T~(T) = {P(,3), P(14)}. Figure 12 shows,
for each P E T'(T), that T admits monohedral tilings of the n x n toms for all n as well
as dihedral tilings of the n x n toms for even n. Thus, {[!], [-h-I, [s], [-~} is verifiable for
odd n and unverifiable for even n. A similar argument shows that {Vi-], [-k-I, [-fi-],I-Y--I}is
verifiable for odd n and unverifiable for even n.

Wang Tilings and Distributed Verification on Anonymous Torus Networks

I

161

h

The stable row FA for {[-~, [ ~ } for P(,3).

Fig. 9.

d

I

The stable row FA for {I-z], l--c-I,~-~} for (a) P(12), (b) P(13), and (c) P~r4).

Fig. 10.

I

h

Fig. 11.

c

r

Y

The stable row FA for {[-~, [-~, F ] , [Y-I} for P(13).

I

h

S

(a)

X

(b)
s

Fig. 12.

The stable row FA for {['T], [ ~ , ['7], Ix"]} for (a) P(13) and (b) P(14)-

Table 3.

Subgroup models verifiable for odd n, unverifiable for even n.
Tilings admitted by T that satisfy

T

n
Odd
Even
Odd
Even

P(12)

P(13)

Only monohedral
Mono, multihedral

Only monohedral
Mono, multihedral
Only monohedral
Mono, multihedral

P(14)
Only monohedral
Mono, multihedral

162

v.R. Syrotiuk, C. J. Colbourn, and J. Pachl

5.3.3. A4: The "Quint"essential Subgroup.

O f all subgroups in Figure 5, A4 :=
{[-~, F ] , [ ~ , [-h-I, [-~, ELI, l-m-I,[-q-I, [-~, [~], [-~, l--v-I}, the alternating subgroup, is the
only one for which our computational process does not stabilize.
In the computation o f p"), we have observed that with every intersection operation
the number of states in the FA grows cubically. Even when the states of the initial row
FA are collapsed using the two-, three-, and fourfold symmetry in A4 the iterates remain
very large. Many other strategies have been applied to A4 yet it remains impenetrable.

Open Problem.

Is the orientation model A4 (the alternating group) unverifiable for n
if and only if2]n and 5In?

6.

Conclusions

This paper has studied the verification problem on anonymous n x n torus networks. Since
the orientation model $4 is unverifiable, there is no deterministic distributed verification
algorithm when processors can label their channels arbitrarily. However, a verification
algorithm does exist for an n × n torus network for restricted orientation models.
We developed a correspondence between an orientation model A4 and a subset T
of the $4 Wang prototiles. The correspondence is further developed to show that the
existence of an algorithm for verification of an n x n torus network in .A4 is equivalent
to T admitting no multihedral tilings of an n x n torus satisfying certain contact laws.
Using this equivalence, we have answered the question "is the orientation model M
verifiable for n" for all n and all subgroups .A//of $4 except A4.

Acknowledgments
The authors wish to thank the referees for their useful comments that have greatly improved the clarity of our
results.

References
[1] Attiya, H., Snir, M., Warmuth, M., Computing on an Anonymous Ring, Journal of the ACM, Vol. 35,
No. 4 (1988), pp. 845-875.
[2] Beame,P. W., Bodlaender, H. L., Computing on Transitive Networks: The Torus, in Monien, B., Cori,
R., editors, Proceedings of the Sixth Annual Symposium on Theoretical Aspects of Computer Science,
(1989), pp. 294-303.
[3] E J. Budden, The Fascination of Groups, Cambridge University Press, Cambridge, 1972.
[4] Grtinbaum, B., Shephard, G. C., Tilings and Patterns, Freeman, San Francisco, CA, 1987.
15] Harary,F., Wilcox, G. W., Boolean Operations on Graphs, Mathematica Scandinavica, Vol. 20 (1967),
pp. 41-51.
[6] Korach,E., Moran, S., Zaks, S., Tight Upper and Lower Bounds for Some Distributed Algorithms
for a Complete Network of Processors, Technical Report TR-423, Department of Computer Science,
Technion, July 1986.
[7] Kranakis, E., Krizanc, D., Distributed Computing on Anonymous Hypercube Networks, Proceedings
of the Third 1EEE Symposium on Parallel and Distributed Processing ( 199 l), pp. 722-729.
[8] Norris, N., Universal Covers of Edge-Labelled Digraphs: Isomorphism to Depth n - 1 Implies Isomorphism to all Depths, Discrete Applied Mathematics, Vol. 56, No. 1 (January 1995), pp. 61-74.

Wang Tilings and Distributed Verification on Anonymous Torus Networks
[9]
[10]
[11]
[12]
[13]

[ 14]
[15]
[ 16]
[ 17]

163

Peterson, G. L., Efficient Algorithms for Elections in Meshes and Complete Networks, Technical
Report TR- 140, Department of Computer Science, University of Rochester, July 1985.
Raymond, D. R., Wood, D., G r a i l : Engineering Automata in C++, Technical Report CS-93-01,
Department of Computer Science, University of Waterloo, January 1993.
Santoro, N., Sense of Direction, Topological Awareness and Communication Complexity, SIGACT
News, Vol. 16, No. 2 (Summer 1984), pp. 50-56.
Syrotiuk, V. R., Wang Tilings and Distributed Orientation on Anonymous Torus Networks, Ph.D.
Thesis, Department of Computer Science, University of Waterloo, 1992.
Syrotiuk, V. R., Colbourn, C. J., Pachl, J., Wang Tilings and Distributed Orientation on Anonymous
Torus Networks, Proceedings of the Seventh International Workshop on Distributed Algorithms (1993),
pp. 264-278.
Syrotiuk, V. R., Colbourn, C. J., Klarner, D. A., Pachl, J., Characterizing Tilings Using Finite Automata,
Proceedings of the Third International Workshop on Polyominoes and Tilings (1994), pp. 11-30.
Tel, G., Network Orientation, Technical Report RUU-CS-91-8, Department of Computer Science,
Utrecht University, March 1991.
Wang, H., Notes on a Class of Tiling Problems, Fundamenta Mathematicae, Vol. 82 (1975), pp. 295305.
Yamashita, M., Kameda, T., Computing on an Anonymous Network: Part I--Characterizing the Solvable Cases. Part II--Decision and Membership Problems. IEEE Transactions on Parallel and Distributed Systems, Vol. 7, No. l (January 1996), pp. 69-96.

Received December 1994, and in final form December 1995.

A New Approach to MAC Protocol Optimization
A. Faragb, A. D. Myers, V. R. Syrotiuk, and G. V. Zhuba
Erik Jonsson School of Engineering and Computer Science
Center for Advanced Telecommunications Systems and Services (CATSS)
The University of Texas at Dallas
{farago, amyers, syrotiuk, zaruba} @utdallas.edu
A b s t r a c t 4 systematic and automatic method for dynamically optimizing medium access control (MAC) protocol parameters is presented. Our
meta-protocol approach is capable of performing on-line optimization of
critical MAC parameters without knowing in advance what network conditions will arise or how they may fluctuate over time. Furthermore, this
dynamic optimization is achieved without any centralized control or exchange of control messages between nodes. The power of the new technique is demonstrated by two examples. In a LAN environment, it outperforms traditional contention based MAC protocols that adjust retransmission probabilities, e.g., employing binary exponential backoff. In a synchronous multi-hop environment, it automatically converges to the proper
transmission schedule assignments for the actual node density.

INTRODUCTION

A multiaccess medium is the foundation for communication
in a number of networks, such as local area networks (LANs),
metropolitan area networks (MANS), satellite networks, and
radio networks. The medium in these networks is a shared resource, and a medium access control (MAC) protocol coordinates all packet transmissions. Consequently, the performance
of the MAC protocol has an immediate and fundamental impact on the overall efficiency of a multiaccess network.
When the network conditions are unknown or changing, the
choice of the MAC protocol to use is not obvious. The usual
approach in this situation is to include some kind of adaptivity in order to adjust the protocol parameters to the actual network conditions. There are a number of well known adaptation
techniques, a few typical examples are briefly reviewed below.
While these techniques are capable of successfully adjusting
the parameters of the specific protocol for which they are designed, none of them extends into a general method that can be
applied in practically any situation. Our contribution in this paper is a principally new, systematic approach to achieve MAC
protocol adaptivity at a general level, not restricted to a specific
protocol.
One well known form of adaptation via parameter adjustment is the class of backoff algorithms used by contention protocols. Two characteristic backoff solutions are the pseudoBayesian algorithm and binary exponential backoff.
The pseudo-Bayesian algorithm dynamically manipulates

the transmission probability of each node by maintaining an
estimate of the number of backlogged nodes, i.e., nodes with
packets to send [2], [9]. An increase in the number of backlogged stations reduces the transmission probability, and vice
versa. Thus, the pseudo-Bayesian algorithm can adjust its operation to match the contention level in a multiaccess channel.
Unfortunately, each node must have an accurate estimate of
the overall arrival rate of incoming traffic which is generally
unknown and time varying. Each node must also know the
outcome of every network transmission which may not be possible in every type of multiaccess network. Nonetheless, the
pseudo-Bayesian algorithm is used in a number of MAC protocols (see [6], [lo], Ell] for examples).
Unlike the pseudo-Bayesian algorithm, the binary exponential backoff algorithm does not require global feedback or an
estimate of the network arrival rate. Instead, each node adjusts
its transmission probability based on the number of unsuccessful transmission attempts. However, exponential backoff was
proven unstable (infinitely growing delays) under quite general
modeling assumptions [l]. Furthermore, a large class of acknowledgment based backoff mechanisms were also proven to
be unstable [8]. Thus, finding the optimal dynamic adjustment
of the transmission probability is far from trivial.
Another important class of protocols is the family of spatial reuse TDMA protocols used in mobile multi-hop networks.
Here adaptivity can be achieved by dynamically recomputing
transmission schedules based on the local network topology
(see [4], [ l l ] for examples). One way to adjust in this situation
is that the nodes alternate between a contention protocol and a
TDMA allocation protocol. Nodes use the contention protocol
to determine the proper schedule length and slot assignments
through the exchange of small control packets. Once the schedules are fixed, the operation switches over to the TDMA protocol and the nodes use their computed schedules. When node
mobility results in a topology change, the contention protocol
must be run again. However, these spatial reuse TDMA protocols can become unstable if the rate of mobility outpaces the
rate at which the transmission schedules can be updated. More-

0-7803-6451-1/00/$10.00 Q 2000 IEEE

1742

over, scarce bandwidth resources are lost to the contention protocol.
In [ 5 ] , we proposed a principally new approach to create
adaptive and scalable MAC solutions. The novel approach, using a paradigm from computational learning theory [ 3 ] , develops a meta-protocolframework that implements a higher layer
of adaptivity on top of the existing MAC protocols. Specifically, we introduced a technique that automatically combines
any set of existing MAC protocols into a single protocol, resulting in an aggregated protocol that has provable optimality
properties, as shown in [ 5 ] . Thus, we assume that a number of
existing MAC protocols are available as components and our
“meta-MAC” protocol works on top of them, optimally combining their individual transmission decisions into a final decision. The combination is continually updated according to the
local feedback information available at each node.
In this paper, we show that our meta-protocol technique provides a general way to automatically optimize critical MAC
protocol parameters without any prior knowledge of the actual network conditions (e.g., traffic load or topology), or how
they will change over time. Furthermore, this optimization is
completely distributed and requires no control information to
be exchanged between nodes. In one of our examples we use
the approach to find the proper transmission probability for
nodes operating in a LAN, and demonstrate that our method
outperforms the more traditional techniques described above.
We also apply the meta-protocol approach to the scheduling
update problem of spatial reuse TDMA protocols, and show
that our method automatically finds near optimal transmission
schedules, without any exchange of control messages.
THEMETA-PROTOCOL
FRAMEWORK
To simplify our discussion, we restrict our attention to slotted time and assume immediate perfect feedback is available
at the end of each slot (preliminary results on the effect of imperfect channel feedback can be found in [5]). The actual way
of computing the combined transmission decision in each time
slot by our meta-MAC protocol is based on a weighted average
of the decisions made by each component protocol. The final
decision to transmit in a slot is then made using randomization
based on the weighted sum. Based on the channel feedback
available at the end of a slot, the individual component protocol weights are adjusted according to the outcome of the slot.
A component protocol that contributed to a wrong decision will
undergo a reduction in its weight. We call the method the Randomized Weighted Majority ( RWM)Meta-protocol.
Figure 1 illustrates M MAC protocols, P I , .. . , PM to be

Fig. 1. Meta-MAC protocol model

combined at all nodes. The final decision, f i t E (0, I},
whether to transmit in a slot is determined by appropriately
combining the decisions of the M component protocols.
Each protocol Pi runs independently, producing a decision
Di,t, 1 5 i 5 M , in each slot t. The value of Di,t is a real
number between 0 and 1, where Di,t = p is interpreted to
mean that protocol Pi would transmit in slot t with probability
p . No assumptions are made concerning how each component
protocol reaches its decision. Instead, the final decision Dt
is computed as a function of the weighted average of the Di,t
values:

The function F can be chosen in several ways. For this paper,
we chose F ( z ) = 2. In other words, Dt is simply the weighted
average of the Di,t values, which is then rounded, using randomization, to 0 or 1 to obtain the final binary decision f i t for
slot t.
The meta-protocol at each node maintains the weights used
in (1). The positive number wi,t is the weight of protocol Pi
for slot t. At the end of each slot the weights at the given node
are updated using the channel feedback. We do not restrict the
nature of the feedback, we only assume that from the feedback
we can conclude whether the decision was right or wrong. For
example, if collision occurs, then the decision to transmit was
wrong. On the other hand, a successful transmission implies
the decision was correct. The weight update algorithm works
as follows. Let yt denote the feedback at the end of slot t :
Yt={

1 if the decision in slot t was correct
if the decision in slot t was incorrect

0

Then the correct decision, zt, can be retrospectively computed
from the feedback as:

1743

Zt

= Dtyt

+ (1- & ) ( l - y t ) .

(2)

That is, zt = Dt if yt = 1; otherwise zt = 1 - Dt. Of course,
we cannot simply set the decision for slot t according to z t ,
since zt becomes known only at the end of the slot. Using
zt, the weights are updated according to the following simple
exponential rule:

(3)
The term IDi,t - ztl in the exponent represents the deviation
of protocol i from the correct decision. If this deviation is
zero, then the weight of Pi remains unchanged. Otherwise the
weight of Pi decreases with increasing deviation. Due to the
normalization in (l),the relative weight of those protocols that
made a correct decision will grow, while of those which made
a mistake will shrink. The constant 7 > 0 controls the rapidity
of the weight change and thus has a great influence on the stability and convergence speed of the meta-protocol. The effect
of 77 is still being studied, however some preliminary results are
published in [ 5 ] .
Note that the direct use of (3) can cause underflow in
the number representation, since the weights decrease monotonically. This problem is easily solved in practice, by renormalizing the weights after each update. One can also set
a minimum value below which no weight can drop. Renormalization does not change the relative sizes of the weights
and since they are only used in a normalized way in computing the combined value Dt by (l), therefore, only their relative
sizes matter.
Having introduced the needed concepts, we can now summarize our meta-protocol.
RWM Meta-protocol

Initialization: set all weights to 1.

For each slot t do:
At the beginning of slot t:
- Collect the component decisions D1, t , . . . , D M , ~ .
- If there is no packet to send, then set fit = 0; Else compute
Dt according to (1).
- Probabilistically generate the final binary decision dt,,
where Pr(bt = 1) = Dt and Pr(Dt = 0) = 1 - Dt.
- If f i t = 1, then transmit in slot t ; Otherwise refrain from
transmission.
At the end of slot t:

- Compute zt = f i t yt + (1 - bt)(1 - yt ) using the decision
Dt and the feedback yt.

- Update all of the weights according to (3).

EXAMPLES
OF MAC LAYEROPTIMIZATION
Although designed to combine different sets of MAC protocols, the meta-protocol can also combine several versions
of the same protocol using different parameters. In this way,
our meta-protocol framework is capable of automatically optimizing critical MAC protocol parameters. In this section, we
investigate the application of the meta-protocol framework to
MAC layer optimization. Specifically, we will find the optimal
transmission probability in a LAN using a combination of several p-persistent slotted Aloha protocols. In addition, we will
use our meta-protocol approach to find the optimal transmission schedules in a static multi-hop wireless network by combining a large number of simple TDMA transmission schedules.
Optimizing TransmissionProbabilities

In this example, each node combines the same M ppersistent slotted Aloha protocols, each with a different transmission probability. Thus, in a given slot t , each component
protocol Pi simply returns a decision Di,t equal to its transmission probability. The meta-protocol combines these decisions, and adjusts the relative weights based on the outcome of
slot t. Those component protocols whose transmission probabilities are far from the optimum will have their weights for
future contribution to the overall decision f i t reduced. Likewise, component protocols that have near-optimal transmission
probabilities will have their relative weights increased. In this
way, the meta-protocol should find the best transmission probability p for a given traffic load.
To validate this claim, we simulated a local area network
consisting of N = 100 nodes. When the network is saturated,
i.e., each node has always packets to send, the probability of
a successful transmission is given by p ( 1 - p ) N - l . In such a
scenario, the value ofp must be 1/N to obtain optimal throughput. Consequently, the number of component protocols should
be M > log(N). For this experiment, we combine M = 15 ppersistent slotted Aloha protocols where each protocol P
i has
transmission probability pi = 1/22, i = 1,. . . , M .
For comparison purposes, we also simulated the stabilized
slotted Aloha (SSA) protocol presented in [7]. The SSA protocol relies on a collision resolution technique similar to the
binary exponential backoff algorithm. However, the transmission probability of the SSA protocol is not reset to one when a
packet has been transmitted successfully. Instead, the transmission probability is multiplied and divided by a constant q > 0
whenever a collision or empty slot is detected, respectively. In
this way, the SSA protocol increases fairness and avoids insta-

1744

Fig. 4. Static multi-hop network topology.

4
0.2

0.6

04

0.8

1.2

protocol allows it to fine tune its transmission probability in
a much more continuous manner. Consequently, the metaprotocol can converge to the correct p o p t , giving rise to improved performance.
According to [7], the choice of q affects the best throughput the protocol can achieve, and how quickly it can converge
to that value. If q is very small, then the best throughput of
the SSA protocol will be that of the meta-protocol. The metaprotocol can adapt more quickly since the adaptation only depends on the Q value that, unlike q, does not introduce forced
granularity.
Thus when combining protocols of the same type with varied parameters, this example shows that the meta-protocol automatically selects the protocol with the best parameters for the
given network load.

OO

Arrival Rate [pkWslot]

Fig. 2. Throughput comparison of the meta-protocol and SSA in a LAN.

350

1

300 250 -

-1
:no0

-

2
!IS100 -

50-

0.2

0.4

0.6

08

I

1.2

Optimizing Transmission Schedules

Arrival Rate (pkls/slot]

Fig. 3. Access delay comparison of the meta-protocol and SSA in a LAN.

In this example, each node has the same combination of

M simple TDMA transmission schedules, each with different
bility at high loads. In our examples the multiplier constant is
set to q = 1/2.
For each protocol, we collected numerical data pertaining to
two key performance metria -- throughput and average access delay. The throughput measures how effectively the network transmits packets between nodes. The average access delay measures the average time needed to successfully transmit
a packet. The results are depicted in Figures 2 and 3 as a function of the overall arrival rate (i.e., traffic load).
As it can be observed, the meta-protocol outperforms the
SSA protocol. This can be attributed to the fact that the transmission probability of the SSA protocol is limited to powers
of 1/2. Specifically, this protocol “jumps” between probabilities 1/2i and 1/2if’ which may bound the optimal transmission probability,p o p t , for the current slot, i.e., 1/22 < popt <
1/2*+’. On the other hand, the weight distribution of the meta-

frame lengths (measured in slots) and slot assignments. The
goal of this experiment is to show that the meta-protocol will
automatically converge to the frame length closest to the density in each part of the network, and make non-conflictingslot
assignments to each node.
To validate this claim, we simulated a static multi-hop network consisting of 32 nodes using the topology illustrated in
Figure 4. Here, the small circles represent nodes (with the
given node identifier) and the lines connecting the circles represent bi-directional wireless links. The large circles represent
fully connected sub-networks of size 6 and 18, involvingnodes
8-1 3 and 14-3 1, respectively.
In this experiment, the frame lengths will be powers of two
since it is essential that the different schedules of neighboring
nodes interact correctly to achieve non-conflicting schedules,
using frame lengths that are powers of two ensures that smaller
frames can be embedded in larger ones. Thus, there are at most

1745

Node
Frame Size
AssignedSlot

0
4
2

1
4
3

2
4
0

3
4
1

4
4
2

5
4
3

7
4
2

6
4
0

8
8
5

TABLE I
FRAMELENGTH A N D SLOT ASSIGNMENTS M A D E BY

m = [Zog2N] different frame lengths employed. For each
TDMA frame length, L j , there are 2 3 distinct schedules, each
with a transmission right in a different slot. Thus, at each node
i, there is a total of M = Cy=l2j = 2m+1 - 1 = O ( N )
component TDMA protocols combined (i.e., in our example
there are 63 component protocols contending at each node).
Initially, each node is assigned all slots from each length
TDMA schedule, i.e., the weights for all component protocols are equal. The meta-protocol reaches a non-conflicting
schedule if there is exactly one component TDMA protocol
with a normalized weight nearly equal to one. This specific
component protocol represents the optimal TDMA transmission schedule for the given node.
Table I shows the TDMA frame length and slot assignment
determined by the meta-protocol for the network in Figure 4.
The meta-protocol converged to near optimal frame lengths
with no conflicts in the slot assignment. Since there are 18
nodes in the larger fully connected sub-network, some nodes
must be assigned a frame size of 32 rather than 16.
Thus, by combining TDMA protocols with different frame
sizes, the meta-protocol automatically converged to a nearoptimal TDMA transmission schedule for each node in the example multi-hop network.

META-MACPROTOCOL.

techniques. We also used our method in a synchronous multihop network, and showed that the meta-protocol found the opI timal collision-free transmission schedules for the actual node
density of the network. Thus, we conclude that our simple and
practical combination algorithm can be greatly used for MAC
protocol optimizations.
REFERENCES
[l]

[2]
[3]

[4]

[5]

[6]

[7]

CONCLUSIONS
This paper presented a systematic and automatic method for
dynamically optimizing MAC protocol parameters. By combining several versions of the same protocol, the meta-protocol
is capable of performing on-line optimization of critical MAC
parameters without advance knowledge of future network conditions or that of their fluctuation over time. Furthermore, this
dynamic optimization is achieved without any centralized control or message exchanges between nodes. We applied our
technique to the problem of finding the proper transmission
probability for nodes operating in a LAN, and demonstrated
the the resulting meta-protocol outperformed more traditional

THE

9 1 0 1 1 1 2 1 3 1 4 1 5
8
8
8
8
8 1632
3 22
1
2
6
4
0

[8]

[9]
[lo]

11I]

1746

D.Aldous. “Ultimate Stability of Exponential Backoff Protocol for Acknowledgement Based Transmission Control of Random Access Communication Channels,” IEEE Transactions on Information Theory, vol.
33, no. 2, 1987, pp. 219-223.
D. Bertsekas and R. Gallager. “Data Networks:’ Prentice Hall, Inc., 1992.
N. Cesa-Bianchi, Y. Freund, D. Helmbold, D. Haussler, R. Schapire and
M. Warmuth. “How to Use Expert Advice,” 25th Annual ACM Symposium on the Theory of Computing (STOC’93). San Diego, CA, May
1993.
I. Chlamtac and S. Pinter. “Distributed Node Organization Algorithm for
Channel Access in Multi-hop Packet Radio Networks,” IEEE Transactions on Computers, vol. 36, no. 6, 1987.
A. Farag6, A.D. Myers, V.R. Syrotiuk, and G.V. Z h b a . “Meta-MAC
Protocols: Automatic Combination of MAC Protocols to Optimize Performance for Unknown Conditions,” in press for IEEE Journal on Selected Areas in Communications, Special Issue on Analysis and Synthesis of MAC Protocols, September, 2000.
J. Frigon and V. L u n g . “A pseudo-Bayesian Aloha Algorithm with
Mixed Priorities for Wireless ATM,” Proceedings IEEE Personal, Indoor
and Mobile Radio Communications, vol. 1, 1998, pp. 45-49.
D. Jeong and W. Jeon. “Performance of an Exponential Backoff Scheme
for Slotted-ALOHA Protocol in Local Wireless Environment,” IEEE
Transactions on Vehicular Technology, Vol. 44. No. 3, 1995.
E Kelly. “Stochastic Models of Computer Communication Systems;’
Journal of the Royal Statistical Society, vol. 47, 1985, pp. 470-479.
R. Rivest. “Network Control by Bayesian Broadcast,” Report
MITLCSTTM-285, MIT Laboratory for Computer Science, 1985.
D. Sala, J. Limb, and S. Khaunte. “Adaptive Control Mechanism for Cable Modem MAC Protocols,” Proceedings of IEEE INFOCOM, vol. 3,
1998, pp. 1392-1399.
C. Zhu and S. Corson. “A Five-Phase Reservation Protocol (FPRP) for
Mobile Ad Hoc Networks,” Proceedings of IEEE INFOCOM, 1998.

Meta-Regression: A Framework for Robust Reactive Optimization
Daniel W. McClary and Violet R. Syrotiuk
Department of Computer Science & Engineering
Arizona State University
{Daniel.McClary,Syrotiuk}@asu.edu
Abstract
Maintaining optimal performance as the conditions
of a system change is a challenging problem. To solve
this problem, we present meta-regression, a general
methodology for alleviating traditional difficulties in
nonlinear regression modelling. Meta-regression allows
for reactive optimization, in which system components
self-organize to changing conditions in a manner that is
robust, or affected minimally by other sources of variability. Meta-regression extends profiling, providing a
methodology for model-building when there is incomplete knowledge of the mechanisms and interactions of
a nonlinear system.

1

Introduction

Solving optimization problems in a complex system
is often challenging. Typically a model is formulated,
and an objective function is identified that is to be optimized subject to some constraints. Optimum solutions may be fragile with respect to changes in the modelling assumptions or the environment of the real system. A great many modelling techniques exist for specific conditions, regression analysis among them. Ideally, individual components in a system should be able
to self-organize to changing conditions to maintain optimum performance. When self-organization of individual members of a system is a goal, the models employed
in optimization must both capture the behaviour of the
system and allow for practical use. By providing simple
mathematical models of system performance, regression
analysis meets both of these requirements.
Regression analysis is a collection of mathematical
and statistical techniques used to model and analyze
problems in which a response (or output variable) is influenced by several factors (or input variables). Regres-

Murat Kulahci
Department of Industrial Engineering
Arizona State University
Murat.Kulahci@asu.edu

sion analysis often proves useful in systems with a great
many factors, or in which the system dynamics are not
perfectly understood. In these cases only approximate
models and optimizations may be possible. Regression
models can take many forms, but process optimization
studies often focus on functions that accurately approximate system behaviour with a low-order polynomial. If
linear models of a system are possible, response surface
optimiztion (RSM) provides a methodology for finding
approximate optimums for linear regressions. The response surface formed by the regression model, captures
how a response varies with respect to significant factors
and allows for adjustment of factor levels to reach optimum response values. One of the chief benefits of RSM
studies is that they are not black-box processes. The experimenter learns about the dynamics of the system at
all stages of the process.
When dealing with nonlinear systems, nonlinear regression analysis is a preferred approach. In a nonlinear
regression, there are two critical issues which must be
addressed before a regression can be performed. Specifically, both the model form and the initial coefficients
must be identified a priori. Nonlinear model fitting requires a great deal of caution, as convergence is not guaranteed if errors are made in either of these choices. Often examination of system dynamics or visual inspection
of data provides the basis for model form and coefficient
choices. However, as the number of factors increase,
choosing an initial model can become difficult.
In this paper, we introduce meta-regression, a general methodology to alleviate difficulty in both choice of
a functional form and initial coefficient estimates. Metaregression provides models of both changes in factor relationship and the system itself. These models, along
with the overall regression model, allow for reactive optimization. In a reactive optimization, system components self-organize smoothly to changing conditions in
a manner that is robust, or affected minimally by other

First International Conference on Self-Adaptive and Self-Organizing Systems (SASO 2007)
0-7695-2906-2/07 $25.00 © 2007

sources of variability. Rather than finding the exact optimum for specific conditions, our goal is to provide an
improved response over a wide range of conditions.
At a high level of abstraction, meta-regression consists of two steps. First, profiling is employed to characterize the effect of each factor on the response as well
as their interactions with one another. Second a metamodel is constructed. This is a surface derived from the
set of profiles fitted to one another. It allows interpolation and extrapolation of factor levels in order to maximize the response as conditions change. The first step
of meta-regression is run offline, while the meta-model
is used online for on-the-fly optimization.
The rest of this paper is organized as follows. Metaregression is described in detail in §2. In §3 we provide an overview of the statistical foundations of metaregression. While our work on meta-regression is in its
infancy, it suggests many promising research directions.
We summarize and describe some of these in §4.

2

Meta-regression

The core of meta-regression is inspired by the method
of profiling [1]. The contribution of meta-regression is
that it is a complete modelling methodology. Here we
present the general methodology and a small example.
Profiling is often used to deduce information about
factor behaviour in a nonlinear system when the number
of factors is high or the function is unknown. Several
values of one factor are plotted against the response or
a chosen statistical measurement, while all other factors
are kept fixed. By repeating this process at different levels of the fixed factors, the behaviour of the factor being
profiled can be monitored over various conditions. Creating profiles for each factor in the system builds a sizable body of data from which the experimenter can draw
conclusions about the behaviour of the system.
For a system with k independent variables, the dependent variable y = f (x1 , x2 , . . . , xk ) +  is any function
f that relates the xi to y.  represents noise; this includes
the effects of all extraneous factors that are not included
in the model. For highly nonlinear systems, we propose
the following modelling strategy:

4. “Spot checks” are used to validate the model.
The experiments in step 1 are designed so that a profile
of the response y is obtained for each xi when the other
xj 6= xi are at fixed levels. Thus, two-dimensional plots
of these profiles are generated for the y against each xi .
Step 2 provides several estimates of the model parameters which in turn can be modelled in terms of the remaining independent variables using the same strategy.
The model obtained at the end of step 3 can be used
as the starting model in the nonlinear model fitting effort, with the parameter estimates used as starting values. An overall model is fit using nonlinear estimation
techniques. Once a final model has been fit, the spot
checks in step 4 evaluate accuracy at randomly selected
values of the independent variables and the value fit is
compared to the actual response. These spot checks are
performed within the experimental region or outside of
the original ranges of the independent variables.
In some systems, the number of factors may be very
large. In such situations it may be undesirable to conduct the number of experiments necessary to construct
Surface
of y vs x1,
x2
profiles for each
factor.Plot
A partitioned
approach
can be
employed to reduce the number of experiments; a full
discussion is beyond the scope of this work.

50

y

0

100
-50
0.0

50
1.5
x1

3.0

x2

0

4.5

Figure 1. Example response surface.
As an example, consider a system with two independent variables and assume that a set of designed experiments results in the apparently nonlinear response surface in Figure 1. It is difficult to come up with a candidate model to estimate. To apply our proposed approach we obtain the profiles for each independent variable; these are given in Figure 2 and 3 respectively.
A simple linear trend model is used to model the profile in Figure 2. x1 is selected to model the response
using ŷ = b0 + b1 x1 for each level of x2 . These models result in various estimates of b0 and b1 as given in
Table 1. We write b0 and b1 in terms of x2 and modify

Figure 1. Response Surface with two independent varia

The relationship between the response and the independent variables

1. Profile the system through experiments.

nonlinear. It is indeed hard to come up with a candidate model to est

2. Starting with one xi , a model is fit to each profile
with the other independent variables at fixed levels.

our proposed approach we first obtain the profiles for each independ

3. When the last set of parameters is modelled in the
last independent variable, an overall model is obtained in terms of all independent variables.

given in Figures 2 and 3.

Scatterplot of y vs x1
50

First International Conference on Self-Adaptive and Self-Organizing Systems (SASO 2007)
0-7695-2906-2/07 $25.00 © 2007
25

Scatterplot of y vs x
x2
0
20
40
60
80
100

50

25

50

0

nonlinear. It is indeed hard to come
to estimate. To apply
x 2up with ab candidate
bmodel
0
1
Furthermore Figures 4 reveals that b0 is more or less co
our proposed approach we first obtain
each independent variables as
0 the profiles
2.3013 for-5.0258
x 2 . In fact
a more thorough statistical analysis confirme
20
2.2981
5.852
given in Figures 2 and 3.
40
2.3161 9.8383
Scatterplot
Scatterplot of y vs x1
Scatterplot
of yof
vsb0
x2vs x2
60
2.3053 2.2242
80
2.2971 -7.9751
100
2.3124 -8.7001
100

50

1.5
x1

3.0

0

4.5 50

x2
0
20
40
60
80
100

25 2.310

y

y

25

10

x1
0.50
0.75
1.00
1.25
1.50
1.75
2.00
2.25
2.50
3.00
3.50
4.00
4.50
5.00

50 2.315

5

b1

0.0

x2

b0

-50

0
onse Surface with two independent variables
2.305
We can write b0 and b1 in terms of x 2 and modify
equation (2) as
response and the independent variables seems to be
-5
2.300
yˆ = b0 (x 2 )+ b1 (x 2 )x1
(3)
o come up with a candidate model to estimate. To apply
-10
2.295
0
20
0
20
40for various
60
80
Furthermore Figures 4 reveals that b0 is more or less
constant
values100of
x2
rst obtain the profiles for each independent variables as
x 2 . In factFigure
a moreProfile
thorough
analysis confirmed
this
assertion.b vs x .
forvalues
x1statistical
.
Figure
4.
Scatterplot
Figure
2 Profiles2.for
fixed
of x 2
Figure 3Figure
Profiles
for fixed of
values
4 Scatterplot
of0 b0 of
vs
Figure 5 S
2 xx
12
0

0

-25

-25

-50

-50

0

1

2

3

4

0

5

20

40

80

100

b1 vs x2
Figure 5 on theScatterplot
other ofhand
shows that b1 can be modele

Scatterplot
of yofvsb0
x2vs x2
Scatterplot
x1
0.50
0.75
1.00
1.25
1.50
1.75
2.00
2.25
2.50
3.00
3.50
4.00
4.50
5.00

50
2.315

10

At this point we need to pick one of the independent
variables to model the response
in x
25
2.310

2

5

at fixed levels of the other independent variable. The profiles in Figure 2 can be
0
2.305

b1 = b10 + b11 x 2 + b12 x 22 + b

b1

y
b0

x2
0
20
40
60
80
100

60

x2

x1

0

modeled with a simple linear trend model and hence x1 is picked to model the
The final model is given in Equation (5)
response first using the following model for each level of x 2
-25
2.300

5

-50
2.295
0

-5

0

20

20

40

60
x2 40

80
60

(

yˆ100= b0 + b1 x1

100
80

x2

)

yˆ = b0 + b10 + b11 x 2 + b12 x 22 + b13 x 23 x1

-10

0

20

40

60

(

80

(2)

100

x2
= 2.3050
+ ! 5.6691 + 1.1067 x 2 ! 0.024 x

3. Profile
for values
x2 . estimates
b1 as given
models
resulted
various
of b0 and Figure
in Table
11 vs x2 .
Figure
3 Figure
Profiles
forin
fixed
values of x 2 These
5. Scatterplot
xsignificant
Figure
4 Scatterplot
of b0 of
vs xx1 2 (The
Figure
5 Scatterplot
of bof0 bvs
coefficients
are statistically
at 95% con
2
b1 fitted
x2
Table 1. The estimates of b0 and
for various
levels
ofresiduals
The
and
the
are
given in Figures 6
b1 can
Figure
5 asonŷ =the
other
be
athethird
order
polynomial
the
equation
b0 (x
(x2 )x1shows
. Figure 4that
reveals
2 ) + b1hand
Themodeled
fittedvalue
valueby
and
residuals
are given
in Figure
that
b
is
more
or
less
constant
for
various
values
of
x
0
6 and 7 respectively. There might be some “signal” left
one of the independent
variables to model the response2
still
“signal”
left inthe
the residuals. H
(note
y axis scale). Figure 5 suggests to model b1 by there
in themight
residuals;
thisbe
cansome
be remedied
by applying
in xthe
2
a
third
order
polynomial
in
x
:
b
=
b
+
b
x
+
dependent variable. The profiles in Figure
2
1 2 can
10 be11 2
same modelling methodology to the residuals.
the same modeling methodology to the resi
b12 x2 2 + b13 x2 3 . The final model (with 95% confi- by applying
(4)
b = b + b x + b12 x 22 + b13 x 23
trend model and
hence
picked
model
dence)
is: ŷ =xb is
+ (b
+ b to
x +
b x 2the
+ b1 x 310)x 11 2
10

wing

10

11 2

12 2

13 2

1

where b0 = 2.3050, b10 = −5.6691, b11 = 1.1067,
The
final
givenThis
in Equation
(5)
= −0.024,
and
model is a polymodel forb12
each
levelmodel
of bx132 =is0.0001.
nomial because at each stage only polynomials are em2
yˆ =isbobtained
b11 x 2 +modb12
A nonlinear model
nonlinear
0 + b10if+
yˆ = bployed.
(2)x 2
0 + b1 x1
els are employed at any one of the modelling stages.

2.1

Applicability of meta-regression

Meta-regression can be successfully applied to any
highly3nonlinear system in which the functional form is
+unknown
b13 x 2 x1or coefficient estimates are needed. Partition(5)
2nonlinear factors
3 can significantly reingx of!linear
and
= 2.3050 + ! 5.6691 + 1.1067
0
.
024
x
+
0
.
0001
x
x
2 1
ious estimates of b0 and b1 as given in Table 1
duce2 the number 2of necessary experiments
and intermediate models. Dividing the input set allows the number
(The
are statistically
atexperiments
95% confidence
level).
Table 1. Estimates
of b0 and b1 significant of
necessary for
the linear factors to be subb1 coefficients
timates of b0 and
for
various
levels
ofb x 2
x2
b0
1
stantially reduced. Yet, even when partitioning is emThe fitted value
and the-5.0258
residuals are given in
Figures
andnumber
7. It ofcan
be argued
that
0
2.3013
ployed,
if the 6total
factors,
or of nonlinear
20 2.2981
5,852
factors, is very high, the sheer number of experiments
there might40still2.3161
be some
“signal” left in the may
residuals.
However
this canmeasurements
be remedied
9.8383
be impractical
when real-world
are
60 2.3053
2.2242
required. In these cases, meta-regression can still be sucby applying80the2.2971
same modeling
methodology
to the residuals.
-7.9751
cessfully applied to simulation studies, since many sim100 2.3124 -8.7001
ulation trials can reused.

(

(

First International Conference on Self-Adaptive and Self-Organizing Systems (SASO 2007)
0-7695-2906-2/07 $25.00 © 2007

)

)

Surface Plot of Fitted vs x2, x1

Surface Plot of Residuals vs x2, x1

50
25
Fitted

0
-25

100
0.0

50
1.5
x1

3.0

4.5

x2

0

Plot
of Residuals
vs x2,
x1
Figure 6.Surface
Surface
plot
of the fitted
model
vs. x1 and x2 .

Figure 6 Fitted Values

ysis should proceed. In 1962, Box and Hunter [2] introduced a model-building technique for dealing with
systems for which basic theoretical
models exist. Their
50
method provides experimenters a way to determine the
best way to “force” a model to25 fit a system using preResiduals This
existing domain knowledge.
contributed to the de0
velopment of profiling [1]. Profiling allows an experi-25
menter to construct several restricted
plots of the functions in a system so as to better
-50 understand their non0.0
1.5
linearity and interactions. Meta-regression
further
ex3.0
4.5
x1
tends profiling, providing a methodology for
classifying
and approximating nonlinearity when only incomplete
knowledge about a system’s mechanisms and interactions is known.

4

10
50

x2

0

Figure 7 Residuals

Summary and future work

This paper introduced meta-regression, a general

Indeed the proposed modeling
methodology
in this
case provided
methodology
for reactive optimization
that alleviates
50
25

traditional problems in modelling nonlinear systems.
Meta-regression allows system components to selforganize to changing conditions in a manner that is robust, or affected minimally by other sources of variability. This is achieved via a new profile-based nonlinear
modelling methodology that uses a stepwise process to
provide parameter scaling equations to yield an approximate model of the nonlinear system, that can be used as
the starting point for more traditional nonlinear regression techniques. The technique is applicable to complex
dynamic systems in which one or more factors inhibit
linear modelling techniques.

step-by-step approach to model the response surface given in Figure 1. I
Residuals

0

-25

100

noted that the final model is a polynomial because at each stage only pol
-50

0.0

50

1.5

x1

3.0

4.5

x2

0

employed.
complicated
nonlinear models can certainly be obtained
Figure 7.More
Surface plot
of the model residuals vs. x1 and x2 .

simple
nonlinear
models are employed at any one of the modeling stages
Figure
7 Residuals
3

Related work

Acknowledgments
ng methodology
inourthis
case provided
The root of
meta-regression
is the investigationa simple,
into the factors that significantly affect our chosen reSupported, in part, by NSF grant ANI-0240524.
sponses. To identify these significant factorsProposed
and model
Work
response surface given in Figure 1. It should
be on Monitoring
their effects, we employ design of experiments (DOE)
and response surface methodology (RSM) [3, 4].
While DOE and RSM provide a time-tested means of
finding optimizations for systems that exhibit linear behaviour, nonlinear systems present a significantly larger
challenge. Systems exhibiting nonlinear behaviour in
one or more dimensions cannot be effectively modelled
using the least-squares method key to analysis of variance (ANOVA). As such the field of nonlinear regression analysis has grown in importance; see the classic
text by Bates and Watts [1].
However, when the nonlinear aspects of a system are
not immediately identified as known function families
considerable difficulty emerges in both choosing initial
modelling parameters and the direction in which anal-

References

In Steps
and 2only
of the
proposed
research,
we discussed the issue
omial because
at each1 stage
polynomials
[1] D. Batesare
and D. Watts. Nonlinear Regression Analysis
and Its Applications. John Wiley and Sons, Inc., 1988.
[2] G. E. P. Box and W. Hunter. A useful method for model
collecting
through
carefullyifdesigned
experiments and fitting mode
near models
candata
certainly
be obtained
even
building. Technometrics, 4:301– 318, 1962.
[3] D. C. Montgomery. Design and Analysis of Experiments.
John Wiley and Sons, Inc., 6 edition, 2005.
[4] R. H. Myers and D. C. Montgomery. Response Surface
Methodology: Process and Product Optimization Using
Designed Experiments. John Wiley and Sons, Inc., 2 edition, 2002.

response
yed atpresumably
any one of nonlinear
the modeling
stages.surfaces in terms of the independent vari

efforts are considered as “off-line” efforts and are not expected to be rep

constantly
as this practice will soon be proven to be very inefficient. For
d Work
on Monitoring

statistical
monitoring
tools to allow for routine adjust
osed propose
research,toweemploy
discussed
the issues
of

operating
conditions
and amodels
“modeltoas
signed
experiments
and fitting
theneeded” approach.
First International Conference on Self-Adaptive and Self-Organizing Systems (SASO 2007)
0-7695-2906-2/07 $25.00 © 2007

effort,
one should
aces in termsInofany
the modeling
independent
variables.
Thesebe constantly reminded of the

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

A Cooperative Dual Access Multi-Channel MAC
Protocol for Ad Hoc Networks
Yuhan Moon and Violet R. Syrotiuk
School of Computing, Informatics, and Decision Systems Engineering, Arizona State University

Abstract—We present a multi-channel MAC protocol for ad
hoc networks, for nodes equipped with a single half-duplex
transceiver, combining the use of OFDMA and CDMA. To ease
OFDMA channel management the network is clustered. Channel
groups are defined by a resolvable balanced incomplete block
design (BIBD) to minimize interference. Unique CDMA codes
are assigned to each cluster. Clusterheads manage and assign
channel groups through an extended handshake. Idle nodes that
overhear the handshake cooperate to reduce the incidence of
the multi-channel hidden- and exposed-terminal problems, and
also the near-far problem of CDMA. Simulation results show
a significant improvement in average delivery ratio and delay,
especially in dense network topologies.

I. I NTRODUCTION
The use of multiple channels by medium access control
(MAC) protocols offers great potential to increase throughput
in wireless networks. Channel selection is complicated in ad
hoc networks by the lack of centralized control and fixed
infrastructure.
Different from some multi-channel MAC protocols for ad
hoc networks (e.g., [1], [2], [3]) we assume that each node
is equipped with a single half-duplex transceiver. A control
channel helps facilitate channel selection (used by, e.g., [4],
[5]), however it remains difficult to overcome the multichannel hidden- and exposed-terminal problems inherited from
single-channel systems. More sophisticated physical layer
technologies such as OFDMA and CDMA, and the use of
cooperation, have the potential to mitigate if not solve these
problems as well as increase throughput further.
In Orthogonal Frequency Division Multiple Access
(OFDMA) [6] a group of non-overlapping sub-carriers,
or sub-channels, is assigned to each user to enable
simultaneous transmission and reception. OFDMA also
supports differentiated quality-of-service by assigning a
different number of sub-channels to different users [7], [8].
In Code Division Multiple Access (CDMA) each user is
assigned a unique code that is pairwise orthogonal. When
two or more nodes transmit simultaneously, their signals add
linearly. To recover the transmission, the receiver must know
the sender’s code, computing their normalized inner product
(see [9] for details on CDMA).
There is a challenge to using each technology in ad hoc
networks. OFDMA requires channel synchronization to decode the signal. CDMA suffers the near-far problem [10]. In
cellular networks the base station solves these problems by
assigning well organized channel groups, and controlling the
transmission power, respectively.

As a result, OFDMA and CDMA are not yet widely used
in ad hoc networks. The Parallel Interaction Medium Access
(PIMA) [11] and OFDMA-based Reliable Multicast MAC
Protocol (OMMP) [12] protocols are proposed for ad hoc
networks based on OFDMA. CDMA-based protocols for ad
hoc networks are proposed using power control (and two
transceivers at each node) [13] and cooperation [14] to address
the near-far problem.
Cooperative mechanisms are becoming increasingly important in wireless networks with the potential to enhance system
performance. Our notion of cooperation in a MAC protocol
involves the use of idle nodes that overhear transmissions
participating in the protocol. Such a cooperating node may
help facilitate communication set-up between a pair of nodes.
For example, in the Cooperative Asynchronous Multi-channel
MAC (CAM-MAC) protocol [15], the sender and the receiver
obtain channel usage information from idle cooperating neighbours as part of the handshake.
In this paper we propose a new multi-channel MAC protocol
for ad hoc networks for nodes equipped with a single halfduplex transceiver. Our contributions include:
•

•

•
•
•
•

Two access technologies are combined: OFDMA enables
simultaneous transmission and reception, while CDMA
increases spatial channel re-use.
The channel synchronization problem of OFDMA is addressed by clustering the network. A resolvable balanced
incomplete block design (BIBD) is used to define channel
groups; this minimizes interference among groups used
in adjacent clusters. Clusterheads are responsible for
managing and assigning channel groups.
OFDMA supports a flexible channel group size; cooperating nodes help negotiate the channel group.
A unique CDMA code is assigned to each cluster.
The near-far problem of CDMA is mitigated by cooperating nodes facilitating communication set-up.
The multi-channel hidden- and exposed-terminal problems are solved when the communicating pair is affiliated
with the same cluster, and mitigated otherwise.

The results of simulations show that our proposed protocol
obtains significantly higher average delivery ratio, and reduced
delay, especially in dense network topologies.
The rest of this paper is organized as follows. §II introduces
our proposed multi-channel MAC protocol. The simulation
model and selected performance results are presented in §III.
Finally in §IV, we summarize and suggest future work.

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

II. A C OOPERATIVE D UAL ACCESS M ULTI -C HANNEL
MAC P ROTOCOL
A. Assumptions on Channel Management
We assume there are n sub-carriers of which a certain
fraction form a control channel group and the remaining form
several channel groups for data transmission. All sub-carriers
are orthogonal with respect to each other.
The network is clustered for the purpose of channel management, i.e., each node is affiliated with one cluster and is in
direct transmission range of its clusterhead. Each clusterhead
is responsible for managing the allocation of the OFDMA
channel groups to transmissions; this includes maintaining the
duration of each allocation. Furthermore, a unique CDMA
code is assigned to each cluster. Transmission on an OFDMA
channel group uses the CDMA code of the transmitter’s
cluster, while transmission on the control channel group uses
a common code permitting all overhearing nodes to decode
the transmission.
As we will see, a transmitter contacts its clusterhead to
obtain a channel group for communication. To ensure that subcarriers do not overlap when multiple transmitter/receiver pairs
affiliated with the same cluster communicate concurrently, a
resolvable balanced incomplete block design (BIBD) is used
to define the channel groups. A BIBD is a pair (V, B) where
V is a v-set and B is a collection of b k-subsets of V (blocks)
such that each element of V is contained in exactly r blocks
and any 2-subset of V is contained in exactly λ blocks [16].
A BIBD is resolvable if there exists a partition of its set of
blocks B into parallel classes, each of which in turn partitions
the set V . In the following example, each column is a parallel
class in a resolvable BIBD with v = 9, k = 3, and λ = 1:
{ 1, 2, 3 }
{ 4, 5, 6 }
{ 7, 8, 9 }

{ 1, 4, 7 }
{ 2, 5, 8 }
{ 3, 6, 9 }

{ 1, 5, 9 }
{ 2, 6, 7 }
{ 3, 4, 8 }

If a cooperating neighbour overhears the CAM and is
aware of channels in G that may experience interference,
it transmits a channel information message (CIM) to the
transmitter containing a list L of such channels on the data
channel group G. Importantly, OFDMA enables the transmitter
to decode the simultaneous transmission of the CFM and
CIM; these two control packets do not collide. If multiple
cooperating neighbours transmit a CIM, we take advantage
of the capture effect of CDMA to decode the strongest
signal of simultaneously transmitted CIMs [10]. Therefore, the
transmitter decodes the CIM from its closest cooperating node.
The transmitter removes sub-carriers experiencing interference from the group, i.e., it computes G = G \ L, and if G = ∅
it transmits a channel duration message (CDM) to inform both
the clusterhead and its receiver of G and the duration of the
data transmission; the receiver tunes its receiving channels to
those in G. If the data transmission is successful, the receiver
transmits an acknowledgement (ACK) on the same channel
group G to avoid possible interference with another handshake.

Fig. 1.

An example network topology.

{ 1, 6, 8 }
{ 2, 4, 9 }
{ 3, 5, 7 }

In our application, v corresponds to the number of subcarriers, k to channel group size, and r to the number of
clusters. Each parallel class corresponds to the channel groups
available for allocation in a cluster.
Using a resolvable BIBD (R-BIBD) minimizes the size of
the intersection of the channel groups when a transmitter and
receiver are affiliated with different clusters. In this example,
because λ = 1, the size of the intersection of two blocks from
different classes is at most one; this limits interference.
B. Channel Group Negotiation and Assignment
With two exceptions, the handshake takes place on the
control channel group and is used to obtain a channel group for
data transmission. A transmitter initiates the handshake with
a channel request message (CRM) to request a channel group
from its clusterhead. If there is one available, the clusterhead
responds with a channel assignment message (CAM) to assign
channel group G. If the receiver is affiliated with the same
cluster as the transmitter, it overhears the CAM and sends a
confirm message (CFM) to confirm the channel group selected.

Fig. 2. The handshake when transmitter A and receiver B are affiliated with
the same cluster CH (see Fig. 1); node D is a cooperating neighbour.

Fig. 1 shows an example network topology. Fig. 2 shows the
handshake when transmitter A and its receiver B are affiliated
with the same cluster CH; here D is a cooperating node.

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

interference G ∩ G  from each overheard assignment and sends
it in a CIM. Since OFDMA supports flexible channel group
sizes, the group remains usable with the sub-carriers removed.
Mitigating the near-far problem of CDMA is more challenging. The near-far problem occurs if a transmitter/receiver
pair T /R are separated by distance d, and another transmitter
d
of the receiver R, then communication
is within distance 2.78
between the pair is impossible [17]. We use a solution that
relies on the capability of cooperating nodes to estimate
distance based on signal strength; see Moon and Syrotiuk [14]
for a detailed description of this solution.
III. P ERFORMANCE E VALUATION
Fig. 3. The handshake when transmitter A and receiver E are affiliated with
different clusters (see Fig. 1); node D is a cooperating neighbour.

If the transmitter and receiver are affiliated with different
clusters then the handshake is extended with additional control
packets. As before, the transmitter starts with a CRM to
its clusterhead, which responds with a CAM containing an
available channel group G. From a bit in the packet header,
the transmitter deduces its receiver is out-of-range of its
clusterhead and did not overhear the CAM. So it sends a
request to send (RTS) to its receiver effectively forwarding
G. The receiver synchronizes to the transmitter’s code (found
in the packet header), and responds with a clear to send
(CTS) which performs same function as a CFM. In this case,
a cooperating node defers the transmission of a CIM to be
concurrent with the CTS instead of the CFM. The rest of the
handshake is unchanged.
Assuming the topology in Fig. 1, Fig. 3 shows the handshake when transmitter A and its receiver E are affiliated with
different clusters; again, D is a cooperating node.
If there is no channel group available at the clusterhead, or
the channel group is reduced to the empty set, the transmitter
backs off using the binary exponential backoff algorithm.
C. The Importance of Cooperation
Cooperation is used in two important ways in our protocol:
(1) to help negotiate the OFDMA channel group, and (2)
to help mitigate the near-far problem of CDMA. To enable
cooperation, each node maintains a channel status table containing information extracted from packet headers, such as
node identifiers, CDMA codes, channel groups, duration, etc.
When a transmitter/receiver pair is negotiating a channel
group G, a cooperating node checks its channel status table to
see if another pair has negotiated a channel group G  involving
a sub-carrier in G. Any such sub-carrier must necessarily
be from overhearing a channel group assignment in another
cluster because the blocks in the BIBD used within a cluster
are disjoint. Since we use BIBDs with parameter λ = 1 the
interference is limited to one sub-carrier (see §II-A). The cooperating node accumulates a list of sub-carriers experiencing

We use the ns-2 network simulator, version 2.29, with
extensions to support ad hoc networks to evaluate our protocol, using a total channel bandwidth of 2 M bps. For our
protocol, that bandwidth is divided into 64 sub-channels. Of
those 64 sub-channels, one quarter (16) are dedicated to the
transmission of control packets, while the remaining (48) are
used for the transmission of data.
The necessary conditions for the existence of a (v, k, λ)
resolvable BIBD are that λ(v − 1) ≡ 0 mod (k − 1) and
v ≡ 0 mod k [16]. The smallest R-BIBD with v ≥ 48 has
parameters (49, 7, 1). As a result, some channel groups have 6
sub-carriers, while others have 7, i.e., sub-carrier 48 is deleted
from all channel groups in which it occurs.
Our experiments use constant bit rate (CBR) traffic sources
sending 512 byte data packets at a rate of 4 pkts/s over the
user datagram protocol (UDP). Each flow is a single hop
communication. Each transmitter selects one of its neighbours
as its receiver uniformly at random. Table I summarizes these
and other simulation parameters.
TABLE I
S IMULATION PARAMETERS
Parameter
Simulation area
Number of nodes
Transmission range
Traffic type
Data packet size
Transport and routing protocol
Radio propagation model
Mobility model
Total channel bandwidth
Number of sub-carriers
Sub-carriers for control, data
Parameters of R-BIBD

Value
500 × 500 m2
{25, 65}
250 m
CBR with rate 4 pkt/s
512 bytes
UDP and AODV
Two ray ground
Random way-point 0-5 m/s, no pause
2 M bps
64, each 31.25 Kbps wide
64
= 16, 3×64
= 48
4
4
(v = 49, k = 7, λ = 1) R-BIBD

We begin with 25 nodes placed in a 500×500 m2 area, with
all nodes affiliated with the same cluster. Further experiments
increase the number of nodes, flows, and clusters. Then,
we introduce node mobility, using the steady-state initialized
random way-point model. Our primary interest is to investigate
how the node density and number of flows affect performance,
comparing to IEEE 802.11 using a 2 M bps channel.

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

A. A Single Cluster Scenario
For the single cluster scenario, we place 25 nodes in a 5 × 5
grid topology, with nodes separated by 85 m both horizontally
and vertically. The center node serves as the clusterhead and
all other nodes are affiliated with it.
Fig. 4 shows delivery ratio as a function of the number of
flows in the single cluster scenario. All metrics are averaged
over the number of flows, where each flow starts after all
protocols have initialized and runs to the end of the simulation
(300 s). Here, IEEE 802.11 has a slightly better delivery ratio
than our protocol until the number of flows reaches about ten.
This is because, in our protocol, the number of concurrent
flows in a single cluster is limited by the number of subchannel groups. However as the number of flows increases,
our protocol achieves up to a maximum of 15% better average
delivery ratio than IEEE 802.11.

Fig. 4.

the average delay. However since IEEE 802.11 uses a single
channel, as the number of flows increases the average delay
increases because of node contention.
B. A Multi-Cluster Scenario with and without Mobility
Now, we place 65 nodes in the 500 × 500 m2 area, arranged
in three non-overlapping clusters. Each node is affiliated with
one of the three clusterheads.
Fig. 6 shows the average delivery ratio in this static multicluster scenario. Now, the average delivery ratio of our protocol is always higher than IEEE 802.11. Specifically, the
delivery ratio of our protocol ranges from 1.05 to 5.00 times
better than IEEE 802.11. Some reasons for this include the
fact that our protocol takes advantage of using a multiple
channels assigned independently by each clusterhead, uses
the R-BIBD combinatorial object to minimize the channel
overlap (interference) of channel groups, and takes advantage
of the use of orthogonal CDMA codes assigned to each cluster.
These features in our protocol improve the channel and spatial
re-use ratio and thereby, in cases of high node density and
node traffic, our protocol performs more effectively than IEEE
802.11.

Delivery ratio as a function of number of flows in a single cluster.

Fig. 6. Delivery ratio as a function of number of flows in multiple clusters.

Fig. 5.

Delay as a function of number of flows in a single cluster.

Fig. 5 shows the result of the average delay as a function of
the number of flows. Again, IEEE 802.11 has better average
delay than our protocol until the number of flows reaches about
six as it uses the entire bandwidth for packet transmission.
However, as the number of flows increases, the average delay
of our protocol remains stable between 0.020 s and 0.022 s
while the average delay of IEEE 802.11 increases quickly to
approximately to 9.4 s. Since our protocol takes advantage
of using multiple channels, many communication pairs can
communicate simultaneously, and this effectively decreases

Fig. 7.

Delay as a function of number of flows in multiple clusters.

Fig. 8 shows the delivery ratio when node mobility is
introduced. For simplicity, in this model, we do not take the
handoff of nodes between clusters into account. The random

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE Globecom 2010 proceedings.

Fig. 8.

Delivery ratio in a mobile multi-cluster scenario.

CDMA. To ease OFDMA channel management the network
was assumed to be clustered. Channel groups were defined
by a resolvable balanced incomplete block design (BIBD)
to minimize interference and unique CDMA codes were
assigned to each cluster. Clusterheads managed and assigned
channel groups through an extended handshake. Idle nodes
that overhear the handshake participate in it; through such
cooperation the incidence of the multi-channel hidden- and
exposed-terminal problems, and also the near-far problem of
CDMA was reduced. As a result, our protocol achieves a
significantly higher delivery ratio as well as lower delay than
IEEE 802.11, in particular when node density and traffic load
are high.
For future work, we plan to study how to adopt different
levels of modulation in the physical layer to reduce data
transmission time and look for ways to reduce the control
packet overhead; both could improve concurrency in data
transmission leading to higher throughput. A comparison
to other multi-channel MAC protocols using OFDMA and
CDMA (i.e., [11], [13]) is also part of our ongoing work.
R EFERENCES

Fig. 9.

Delay in a mobile multi-cluster scenario.

way-point model is used for mobility, with node speed that is
uniformly between zero and 5 m/s with constant movement
(i.e., no pausing). In this case, while the average delivery
ratio of our protocol drops steadily, the average delivery ratio
of IEEE 802.11 drops sharply starting at about 10 flows.
Specifically, the average delivery ratio of our protocol ranges
from 1.0 to 8.5 times higher than IEEE 802.11. Thus our
protocol is less vulnerable to mobility than IEEE 802.11.
Fig. 7 and Fig. 9 show the average delay as a function of
increasing number of flows for the static and mobile multicluster scenario, respectively. In each figure, the delay for our
protocol remains stable between 0.02 s and 0.03 s at the higher
traffic loads, even with node mobility. However, when the
number of flows is less than or equal to three, the IEEE 802.11
protocol has a slightly better delay than our protocol, after
which the delay increases sharply. Specifically, the average
delay for IEEE 802.11 with node mobility is worse than the
static case. In the static case, the average delay is between
0.015 s and 4.900 s while the average delay with node mobility
is between 0.015 s and 6.600 s. The results show that our
protocol is stable with more nodes, flows, and even with node
mobility.
IV. S UMMARY AND F UTURE W ORK
In this paper we presented a multi-channel MAC protocol for ad hoc networks, for nodes equipped with a single
half-duplex transceiver, combining the use of OFDMA and

[1] N. Jain, S. R. Das, and A. Nasipuri, “A multichannel MAC protocol
with receiver based channel selection for multihop wireless networks,”
in Proceedings of IEEE ICCCN, October 2001, pp. 432–439.
[2] A. Nasipuri and S. R. Das, “Multichannel CSMA with single powerbased channel selection for multihop wireless networks,” in Proceedings
of IEEE VTC-Fall, vol. 1, September 2000, pp. 211–218.
[3] S. L. Wu, C. Y. Lin, Y. C. Tseng, and J. P. Sheu, “A new multi-channel
MAC protocol with on-demand channel assignment for multi-hop mobile
ad hoc networks,” in Proceedings of I-SPAN, 2000, pp. 232–237.
[4] J. Shi, T. Salonidis, and E. W. Knightly, “Starvation mitigation through
multi-channel coordination in CSMA multi-hop wireless networks,” in
Proceedings of ACM MobiHoc, May 2006, pp. 214–225.
[5] J. So and N. Vaidya, “Multi-channel MAC for ad-hoc networks:
Handling multi-channel hidden terminal using a single transceiver,” in
Proceedings of ACM MobiHoc, May 2004, pp. 222–233.
[6] K. Kivanc, L. Guoqing, and H. Liu, “Computationally efficient bandwidth allocation and power control for OFDMA,” IEEE Transactions on
Wireless Communications, vol. 2, pp. 1150–1158, 2001.
[7] Y. Hujun and A. Siavash, “OFDMA: A broadband wireless access
technology,” in IEEE Sarnoff Symposium, 2006, pp. 1–4.
[8] E. Lawrey, “Multiuser OFDM,” in Proceedings of ISSPA, vol. 2, August
1999, pp. 761–764.
[9] A. J. Viterbi, CDMA Principles of Spread Spectrum Communication.
Addison-Wesley, 1995.
[10] T. S. Rappaport, Wireless Communications : Principles and Practice.
Pearson Education, Inc., 2002.
[11] M. Veyseh and J. J. Garcia-Luna-Aceves, “Parallel interaction medium
access for wireless ad hoc networks,” in Proceedings the IEEE ICCCN’08, august 2008, pp. 1–6.
[12] S. Kim and B. Kim, “OFDMA-based reliable multicast MAC protocol
for wireless ad hoc networks,” ETRI Journal, vol. 31, no. 1, pp. 83–85,
Feburary 2009.
[13] A. Muqattash and M. Krunz, “CDMA-based MAC protocol for wireless
ad hoc networks,” in Proceedings of ACM MobiHoc, 2003, pp. 153–164.
[14] Y. Moon and V. R. Syrotiuk, “A cooperative CDMA-based multi-channel
MAC protocol for mobile ad hoc networks,” Computer Communications,
vol. 32, no. 17, pp. 1810–1819, November 2009.
[15] T. Luo, M. Motani, and V. Srinivasan, “CAM-MAC: A cooperative
asynchronous multi-channel MAC protocol for ad hoc networks,” in
Proceedings of BroadNets, October 2006, pp. 1–10.
[16] C. J. Colbourn and J. H. Dinitz, Eds., The CRC Handbook of Combinatorial Designs. CRC Press, 1996.
[17] P. G. W. Van Rooyen and H. C. Ferreira, “Capacity evaluation of spread
spectrum multiple access,” in Proceedings of IEEE COMSIG, August
1993, pp. 109–113.

978-1-4244-5638-3/10/$26.00 ©2010 IEEE

..—

A Distance Routing Effect Algorithm for Mobility (DREAM)*
Irnrich Chlamtac

Stefano B~agni

Violet R. Syrotiuk

Barry A. Woodward
Erik Jonsson School of Engineering
The University
Email:

{basagni,

chlatac,

and Computer

Science

of Texas at Dallas

syrotiuk,

woodward}~utdallas.

edu

Abstract
1
h this paper we introduce a new routing protocol for
ad hoc networks built around two novel observations.
One, called the distance eflect, usw the fmt that the
greater the distance separating two nodes, the slower
they appear to be moving with respect to each other.
Accor@gly, the location information in routing tables
can be updated as a function of the distance separating
nodes without compromising the routing accuracy. The
second idea is that of triggering the sending of location
updates by the moving nodes autonomously, based ody
on a node’s mobility rate. htuitively, it is clear that
in a direction
routing dgorithrn, routing information
about the slower moving nodes needs to be updated less
frequently than that about hig~y mobtie nodw. h this
way e~ node can optimize the frequency at which it
sends updates to the networks and correspondingly r~
duce the bandwidth and energy used, leading to a fully
distributed and self-optimizing system. B~ed on thwe
routing tablw, the proposed direction algorithm sends
messages in the “recorded dwectionn of the destination
node, guaranteeing detivery by following the direction
with a given probability. We show by detailed simdation that our protocol always delivers more than 80% of
the data messages by following the direction computed,
without using any recovery procedure. In addition, it
mintilzes the overhead used for maintaining routes using the two new principlw of update message frequency
and distance. Lastly, the dgorithrn is fully distributed,
provides loop-free paths, and is robust, since it suppfies
multiple routes.
This workw supported in part by the Army Rwearch Office
under contract No. DAAG55-97-1-0312.
●

Pemlissiontomakedigitalorhsrdcopiesof allorpartof this\vorkfor
personal or classroom use is granted without fee provided that copies
are not mzde or dis~.buted for prolit or commercial ad~arrtageand that
copies bcwrthis notice and the full citation on the first page. To copy
othm}tise, to republish, to post on senrers or to redistribute to lists,
requires prior specific permission an&’ora fee.
N1OBICON19SDallas Texas USA
Cop~”ghtAChl 1998 1-5S113435-ti9S/10...$00OO

_

—.

..

c.

...

Introduction

Rom a routing perspective, an ad hoc network is a
packet radio network in which the mobile nodes perform
the routing functions. Generdy, routing is multi-hop
since nodes may not be within the wireless transmission
range of one another and thus depend on each other
to forward packets to a given destination. Since the
topology of an ad hoc network changes frequently, a
routing protocol should be a distributed algorithm that
computes multiple, cycle free routes while keeping the
communication overhead to a minimum (see, e.g., [4]).
One way to classify routing protocols in ad-hoc networks is by when routes are determined. A proactiue
protocol maintains routes on a continuous basis. Thus
when a sender needs to send a message, the route to the
intended destination-generdly,
the next hop to it—is
rdready known and can be used immediately. On the
contrary, in a reactive approach, the sender determines
a route at the time it needs to send a message, i.e.,
a route dticove~ phase precedes the transmission of a
message.
Most of the proactive routing protocols are based on
shortest path algorithms adapted to the mobile environment. This includes, e.g., the protocols presented
in [2, 12], and, more recently, the Wireless Routing
Protocol (WRP) introduced in [9]. h these protocols,
routing tables are exchanged among neighboring nodes
each time a change occurs in the topology of the network. This impfies update overhead with each exchange
(routes have to be recomputed according to the new information) and, since these tables are possibly large, a
large part of the capacity of the network and the energy
of the node is spent in their transmission. As a result,
when the mobility rate of nodes is high, proactive pro
tocols are infeasible since they cannot keep up with the
changes in the topology.

76

-

.

-—

nation, because the movement of any node in the se
quence renders the path indd.
Thus, a new definition
of routing table entry is needed.

An attempt to overcome the tiltations
of proactive
protocols is instead to look for a route in an “ondemand” fashion, namely, only when it is needed to
de~ver a message. This is the basic idea of reactive pro
tocols, such as Johnson and Mdtz’s Dynamic Source
Routing (DSR) protocol [6], Park and Corson’s Temporally Ordered Routing Algorithm (TORA) [10], and
Perkins’ Ad Hoc On-Demand Distance Vector (AODV)
routing protocol [11]. b reactive protocols a control
message is sent to discover (possibly more than) a route
to a given destination. This kind of control message
is generally shorter than the control messages used in
proactive protocols, leaving more bandwidth available
for the transmission of data messages. However, since
a route has to be entirely discovered prior to the actual
transmission of the message, a sender may experience
a long delay in waiting for the route to be computed.
Furthermore, there is no guarantee that the route ob
tained is usable, since in the meanwhde some of the
nodes in the route may have moved out of transmission
range. Again, the problem becomes more pronounced
when the mobitity rate of nodes is high, since the route
discovery mechanism is not able to adapt to the variations of the speed of the nodes. Even route caching, or
stiar
techniques, used to reduce the delay are ineffective when the mobflty rate is high.

h this paper we present a routing protocol based on a
new definition of routing information. b our approach,
the routing table stored at each node contains location
information for any other node in the network (e.g., g%
ographic coordinates that can be obtained by the use
of GPS [7]). Our protocol can be considered proactive,
since we define a new mechanism for the dissemination
and updating of location information. When node A
wants to send a message m to node B, it uses the 1~
cation information for B to obtti B’s direction, and
then transmits m to dl its one hop neighbors in the
dwection of B. Each neighbor repeats the same proc~
dure, until B, if possible, is eventudy reached. Thus, a
route is sought in an on-demand f=hion, hke in reactive
approaches.
The probability of finding B in the computed direction,
rehes on how the location information is disseminated
through the network. b our model, each node transmits
control messages bearing its current location to dl the
other nodes. The frequency with which these control
messages are transmitted is determined by:

A protocol that combinw both a proactive and a r~
active approach has been introduced in [3]. Here, the
route discovery phase is divided into an intra zone discovery, which involves dl the nodes whose distance fi.e.,
number of hops) from the sender is < k fits zone) in a
proactive way, and an inter zone discovery, which operates between zones using a reactive approach. The ap
propriate choice of the zone radius k depends on the m~
bfity rate of the nodes and on the message arrid rate
(specficdly, the frequency of route requests). However,
this choice is static, and therefore there is no possibility
to adapt to changing network conditions. Moreover, the
inter zone route discovery messages may loop back into
zones aheady queried, =d this must be prevented, otherwise more overhead than flooding based approaches is
incurred [5].
Whether proactive or reactive, existing routing prot~
COISfor ad hoc networks store route information similar
to routing protocols for static networks+ssentidly,
the
route is stored as a sequence of nod=. h a proactive
protocol the sequence is not e~hcit; it corresponds to a
next hop table lookup at each node along the route. k
a reactive protocol the restit of a route discovery control message is the route given as an exTficit sequence
of nodes to foUow. However, in the randomly changing topology of ad hoc networks, storing a route x a
sequence of nodes is inadequate for reaching the desti-

●

considering what we cdl the distance effecti The
greater the distance separating two nodes, the
slower they appear to be moving with respect to
each other. Thus, nodes that are far apart, need to
update each others locations less frequently than
nodes closer together. This is refllzed by associating with each control message an “age’) which corresponds to how far from the sender that message
travels;

●

the mobility rate: The faster a node moves, the
more often it must communicate its location. This
allows each node to self optimize its dissemination
frequency, thus transmitting location information
only when needed and without sacrificing the route
accuracy.

Since distance and mobifity play a central role in our
protocol, we name it the Distance Routing Efect Algon.thm for Mobility (DREAM) protocol for ad hoc networks. Due to the new definition of routing information,
we do not have to exchange large amounts of control
information m in existing proactive protocols. At the
same time, since no route discovery is needed, we do not
suffer the associated delay typical of reactive solutions.
Furthermore, DREAM achieves the following desirable
properties:
77

-.

-.

.-i. ..,..>-

...

,S _,.

,.~.-”

-

●

2

it is bandwidth and energy eficienk Each control
message carries ordy the coordinates and the identfier of a node, thus being small compared to the
control messages used by proactive protocols (that
have to carry routing tabla) and to those used
by reactive protocols (that have to carry an entire
route). Most importantly:
a.

Consider an ad hoc network with n nodes. We assume
the etistence of a mechanism that flows each node
to be aware of its own location (given as coordinates)
with respect to a predefied positioning system (see,
e.g., Global Positioning System as in [7]). These coordinates are mchanged between nodes so that each node
constantly obtains location information about the other
nodes in the network for routing purposes. Specifically,
a Location Table (LT) is maintained at each node A
that records, for each node B, its location, from which
its direction B. and distance B, can be computed. By
direction we mean that Bo is the angle of the polar
coordinates of B on a system centered on the current
position of A ad by distance, we mean that Br is the
geographical distance separating A and B. The entry
related to a node B, LT(B), dso contains LT, (B), the
time at which the location information for B was last
updated.

The rate of control message generation is de
termined and optimized according to the m~
bfity rate of each node individu~y.

b. Due to the “distance effect” the number of
hops (radius from the moving node) it fl
be allowed to travel in the network before
being discarded wi~ only depend on the relative (geographic) distance between the moving node and the location tables being updated.
h this way the number of copies as well as the number of hops control messages W travel are both
optimized (minirni zeal) without sacrificing qutity.
This means that with respect to efisting protocols,
in D~AM more bandwidth and energy (required
for transmission in each mobde node) can be used
for the transmission of data messages;
●

it is inherently loop-free, since each data message
propagates away from its source in a spec%c direction;

●

it is rebut, meaning that the data message can
reach its intended destination by foUowing possibly
independent routes;

●

it is adaptive to mobility, since the frequency with
which the location information is disse&nated de
pends on the mobfity rate.

Dissemination of Location Information

Since our routing protocol is based on the location table
maintained at each node, care is required in order to r~
duce the eWense of disseminating location information
through the network. This is accomplished through the
following simple observation: the f~her two nodes are
sepaated the less often their location table entries need
updating. htuitively, when two nodes ae moving the
same speed, a closer node appems to be chmging more
rapidly than one that is far away. We refer to this ob
servation as the distance effect.
Each node, periodic~y broadcasts a control packet conttilng its own coordinates with respect to the specific
positioning system considered. To retilze the distance
effect, we assign each control packet a life time that is
breed on the geographicrd distance the packet has traveled from its sender. A majority of the packets, will
have a “short” fife time: these shod lived packets %e
sent at high frequency, and “die” after they have traveled through the network a short distance from their
sender. Other long lived packets, sent less frequently,
travel farther through the network, reatilng the most
distant nodes.2

h the nefi sections, we d~cribe the mechanism of dissemination of location information, a general model to
probabfisticrdly guarantee how to find a node in a given
direction, and the D~AM protocol in greater detti.
The paper concludes with simtiation results that show
the effectiveness of our method, namely, that the prot~
COIalways dehvers more than 80% of the data messages
by fo~owing the direction computed,l and that when
compared to a reactive protocol, the average end-t~end
delay decreases considerably.

When a control packet is received by a node A, the node
determines how far the packet has traveled by calculating the distance d between itself and the sender of the
packet. E d is greater than the fife time associated with
the packet, then the packet is no longer forwarded.

1 This percentage refersto the m=sages deHvereddi~tiy, i.e.,
to those mwsages that are delivered by sending them in the direction of the recipient node. H a mmage cannot be delivered
because its intended destination cannot be found in the expected
direction, our protocol providesa recoveryroutine that guarantees
that eventualy that mmage will be delivered.

2 For simplicity, we consider only two m~ximum “ages”for the
control pwkets.
78

——.——

—

... —

.>,

.. ....

..

._

.

,.—

The frequency with which a given node broadcasts control packets is a function of the node’s mobltity: the
more mobde the node, the more often it must disseminate its location information. The fact that most of
the pa&ets d be short hved clearly re&es the idea
that the nodes closest to A xe those most in need of
A’s location, while nodes farther away need A’s location
updated less ofien.

given probab%ty p, O < p <1, foUowing routm in that
direction.
RecW, that S knows the geographical distance& and
the angle & of node R (indicated by r and 0 in Figure 1, respectively), easily cdctiated from the location
information stored in its LT table at time LTr(R) = to.
Figure 1 shows the positions of S and Rat time to.
At some later time tl, tl > to,node S wants to send
a message m with node R as the recipient. S must
choose among dl its one hop neighbors those nodes A
whose direction A. lies within the range [0 – a, $ + a].
The angle a must be chosen in such a way that the
probabihty of fidmg R in the sector S is at least p, for a
given p. The sector S is a wedge centered about the Yie
segment connecting S and R, defied by [0 – a, # + a].

As a result, the firther away a destination and the
slower the rate of movement of the updating node, the
less often a copy of the control packet wifl be sent. We
cu therefore miniize the total number of control packets in the network, while maintaining the same probabtity of error per route. The dissemination method
described reflects the distance effect and thus maintains
the same probabtity of routing accuracy w~e distributing control packets proportionately to distance and rate
of movement.

It may be seen from Figure 1 that, in the time interval horn to to tl, node R, whose speed is v, cannot be
anywhere outside the circle C centered on its original
position with radius z = (tl – to)v. Here we consider
that R can move in any direction ~, uniforrrdy chosen
between Oand 2n at speed v. Therefore, we want to find
a minimum due for a such that the m-um
distance
z that R can travel in the time tl – to at velocity u is
within the sector S.

Overall, th~ dissemination method will therefore have
the fo~owing properties:

3

●

When no movement occurs no bandwidth is wasted
on control packets since control packets are initiated by moving nodes ody.

●

The update frequency can be optimaUy gauged
since the decision of the update frequency ties with
the moving node itse~.

●

The total number of control packets (and conse
quently related transmission energy) can be tilrnized since the aging of control packets captures
the relative distance between the moving node and
the location table updating node.

Clearly, a depends ofly on v (R’s speed). E either the
actual or the mtium
speed of R is known to S, the
due for Q that guarantees that R is in the direction
[0 – a, 0 + a] is immediately given by
Q = ~csin

V(tl – to)
T.

E the distance z that R travels is greater than the distance r separating S and R, then R can be in any direction. h this case, we must set a = x.

A Model for DREAM

E v is not known, and ody its probability density finction ~(v) is atiable,
we can find a specific E so that the
probab~lty of finding R in the direction [0 – E, 8 + E] is
> p, for a given p, O < p s 1. More formWy, we want
to determine E such that

The procws of dissemination of location information as
described in the previous section, Wows us to detie a
model from which we can derive a probabtistic guarantee of finding a node in a given direction. When a
node S needs to send a m~sage m to a recipient node
R, it refers to its LT in order to retrieve location information about R. Based on this information, S selects
from among its neighbors those nodes that are in the
direction of R wd forwards m to them. Each of these
nodes, in turn, do the same, forwarding the message
to those nodes in the direction of R until R, if possible, is reached. It is thus crucial to select the neighbors
of a given node in a certain dwection range in such a
way that it is guaranteed that R can be found with a

P(z

s (tl –

to)v) > p.

h this case, since

x
—=
sin a

T
sin(~ – a)

and, since when
@–a=~itisx=Tsina,
79

—

.-

..-.

- —----

.—.— ,

,

I

Figure h

s (tl – to)v) =
=

s

,’

z is the maximum dkance that the node R can travel in tl – to.

dmcription of the procedures Send(m) and Receive(m)
of DWAM executed at each node S to send or receivea
message m, respectively. We use the fo~owingnotation:

we want to find E so thati
P(z

,’

,’
,’

P(r Sins<

(tl – to)v)

‘(”’s)

●

m.sender, m.recipient, m.type and mid: are the
fieldsof the message m that contain the sender and
the recipient node ~s, the type of messagem (data
or ack) and m’s unique message identfier (at the
sender). A message of type ack has no addltiond
fields;

Once the integral is computed, the needed tiue

●

Timeo: returns the current value of the clock at
the node executing the procedure;

●

R is a temporal threshold value;

●

Recove~ (m): is a recovery procedur~

●

FindNeighbors (LT(R)): is a function that returns
a fist of the one hop neighbors of S whose direction
is in the range [ti-a, ti+a] that depends on LT(R).
U no neighbor is found in the given range the vrdue
returned is til. Here we sssume that the m=imum
velocity of each node is known to d nodes;

●

Ransmit(m, fist): is the procedure by which m is
sent to W the neighbors specified in lisfi

●

set/clear

●

my~: is the identifier of the node executing the
procedure.

for a

is e=fiy obtained.
FinWy, the same reasoning appfies when, given a, we
want to determine when the location information of a
node R which is & far from S has to be updated in
order to have a probabfistic guarantee to find R in the
direction defied by a (i.e., we look for a value of tl).
That is, we can determine the frequency at which to
disseminate location information.

4

Distace Routing Effect Algorithm for Mobility (DREAM)

k this section we describe our Distance Routing Effect
Ngorithm for Mobfity (D~AM)
b~ed on the use of
location information as informdy described in the pr+
vious section. The fo~owing is a high-level algorithmic

Time-out (i): sets/cleas a timer msociated with a message m with mid= i;

80

. ..

--—

—

----

men a node S wants to send a message m to a node
R, it cfls the procedure Send(m) below. It is assumed
that the fields of m are set on entry to the procedure.

The reception of a message m triggers the execution of
the procedure Receive(m).
procedwe
begin

procedwe
begin

Send(m)

if my~ = m.recipient
then if m.type = ack
then cle~ Time-out (mid)

R:= m.recipient;
if LT(R) = nil or Timeo –LT.(R) >7
then Recovery(m)
eke begin
Neighbors:= FindNeighbors (LT(R));
if Neighbors=

Receive(m)

else begin
reply .type := ack;
reply.id := mid;
reply. sender := my~;
reply .recipient := m.sendq

nil

then Remue~ (m)
eke

Send(repl~)

begin
if m.type = data

end
eke begin

then set Time-out (mid);
~ansmii(m, Neighbors)
end

R:= m.recipien~
if LT(R) #nil and Time{) –LT.(R)
then begin
Neighbors:=

end
en~

< ?

FindNeighbors (LT(R));

if Neighbors # nil
then Transmit(m, Neighbors)

The procedure Send(m) executed at node S starts by
looking in S’s location table to &d the current expected
direction of R. E no location information is atiable
for R findicated by LT(R) = til) or that information
cannot be considered tid
(based on LT.(R)), then a
recovery procedure must be executed in order to reach
R. Here, the tidity
of the location information of node
R is based on the time that has passed since LT(R) was
last updated: if this time ( Timeo –LTT(R)) is greater
than a certain threshold T then R’s location information
is considered obsolete. The choice of the value T is a
crucial one: in case of “slow” moving networks it may
be a constant; otherwise, it may be a function of the
geographical distance of R, LTr(R) (and, in this case,
it is stored in another field of the location table).

end
end
end;

Upon receiving a message m, a node A first checks to
see if it is the recipient of the message. H it is the intended recipient, it then looks at the message type. E
the message is an acknowledgement for a data message
previously sent, then the corresponding timer is cleared
(and thus if it has not expired, it til no longer be considered). Otherwise, if A h~ just received a data message, it sends an acknowledgement to the originator of
m.
HA is not the recipient of m, then it simply forwards m
to dl the nodes (if any) that, according to its LT, are “in
the direction” of R. Notice that if, for any reason, the

men the direction of R is vtid, S sets a timer r~
lated to the message m and then sends m to d the one
hop neighbors returned by the function Find_Neighbors.
Notice how, given the nature of the wireless channel,
the procedure Transmit is rewed as a single transmission of m to multiple recipients. These are the neighbors of S that are within a certain direction rage,
as defined in the previous section. Thus, the function
FindNeighbors (LT(R)) is assumed to implement the
method for choosing nodes in a given direction range
such that the probab~lty of finding R in a given direction is greater than or equal to a given p, O < p ~ 1. The
desired probabfity p can be either a constant local to
the function Find3eighbors or it may be passed to the
finction as a parameter. H Findfleighbors returns nil
~.e., if no one hop neighbor exists within the dwection
range specified) a recovery procedure is again in order.

location information is not up to date or if no neighbor
exists in the required direction, then no message is sent.
This allows the timer corresponding to the message to
expire which wotid trigger the recovery procedure.
Some comments are in order:
●

E A receives more than one copy of the same message m, then, for each copy, it sends an acknowledgement: this increases the possibility that the
sender receives an acknowledgement for m which
in turn, increases the robustness of the protocol;

●

The reception of an acknowledgement related to a
data message for which an acknowledgement has
already been received, or for which the timeout
triggered the recovery procedure, hm no effect;

81

—.

.. . ..

J-

-

x.

-----

..—

-

--—

I

●

and therefore their transmission is accordingly longer.
The rate of transmission of each node is considered uniform dl over the network.

The timeout mechanism and the use of acknowledgements are important: the sender has to know
if m has reached the recipient. hdeed, in our approach, it is possible that there is one (or even more
than one) route to the recipient but its location information does not Wow us to reach it. Thus, an
expKcit recovery procedure for this case has to be
provided.

The arrival rate, namely, the frequency with which each
node generates and transmits a data message, hm been
computed as fo~ows. Each rdm ticks of the simdation
clock each node picks a number p randomly and unifordy, O < p < 1. H p < A, then a data message m
is generated and queued for transmission. The destination for m is chosen randomly and uniformly among
dl the other nodes of the network. h our simdations,
each node has the same transmission range, which r~
mains fied at 40. This value guarantees good network
connectivity, i.e., fewer than 10% of the data messages
cannot be defivered to their bd destination due to the
lack of a physical connection (no route &sts between
the two nodes and therefore no routing protocol can
successfly de~ver messages in this case).

Recovery

Ha sender S has no location information either available
or up to date for a specific recipient, and dso whenever
a timer expires, an alternative method to defiver a message must be used. These situations are handed by
our Recove~ (m) procedure. Its actual implementation
may vary, depending on the characteristi~ of the network. For instance, the mwsage m cotid be partifly
flooded, or flooding can be used to determine a route (if
any) to the recipient.

5

Each rcm ticks of the simulation clock every node A
broadcasts a short lived control message with its current coordinates. This message is dehvered to dl those
nodes whose Euctidean distmce from A is less thm K
grid units. Fmdy, one long tived control message is
transmitted to d the nodes in the network for each p
short tived control messages.

Simulations Results

We have simulated our DREAM protocol using
M~~,
a discret~event simtiator developed at UCLA
[1], by placing n = 30 nodes randody on a grid of size
100 x 100. For each node A, the speed is given in grid
units per 100 ticks of the simdation clock (here we ~sume that each node has the same speed and we indicate
it by V), and the transmission range tZA is given in grid
units. Two nodes A and B in the network are neighbors
if the Euchdean distance d between their coordinates in
the grid is less than the minimum between their transtz~ }). At every
mission ratil (i.e., d(A, B) < fi{tZA,
tick of the simdation clock, each node determines its
direction randotiy, by choosing it unifordy between
O and 2r. Ea& node til then move in that direction
according to its current speed. When a node reaches
the grid bound~, it bounces back with an angle determined by the incoming direction. The find position of
the nodm is a function of its initial position and of its
current speed.

k dl the simulation results presented in this paper we
have chosen 0.05 < ~ S 0.4, Td~ = 300 and K = 40.
When the speed of a node A is 2, we have chosen Tcm =
125 and p = 10. Each time the speed of the nodes
increases by 2 units, we decrease rcm by 3070.
Figure 2 shows that always more than 80% of the data
messages de~vered have reached their find destination
without resorting to a recovery routine (here impl+
mented by flooding). The three curves correspond to
three different node speeds, nmnely, V =2,4 and 6.
b the following figures we compare DREAM with the
reactive DSR protocol incorporating route caching as
presented in [6]. Here, we have compared the two prot~
COISwith respect to the average end-to-end delag defined
x fo~ows: if M is the set of rdl the messages detivered,
and for each m ~ Jf, t~ and t~ correspond to the
time when m is generated at the sender and queued for
transmission, and received at the destination, respectively, then the average end-teend delay is computed
as follows:
.

We consider three kind of messages: control messages,
data messages, and acknowledgments (ack). Control
messages carry only the location information, namely,
the coordinates of the node that transmits them (here
they wfl be the coordinates on the grid) and its identifier. Hence, they have &ed length, and their time of
transmission is very short. The transmission time of an
ack is short = we~, since it carries no data. Data messages are considered two orders of magnitude larger than
control messages (with respect to their number of bits),

where IMI is the total number of messages transmitted.
Figures 3 and 4 show that the average end-t~end delay
of the DSR protocol is from 25% to 250% larger than
the delay obtained by DREAM protocol (the two figures
82

~ ...—

----

.

—.- -

---- .

... . ..—

id

V-4

..*—__

●.

6

-

w -

m -

70 -

m -

01

m
0

oG5

01

tils

02s

03

Us

0

a4

&2&b

Figure 2: Percentage of messagm defivered without r~
sorting to the recovery procedure, when the nodes have
three ~erent speeds.

0.G

0.1

0.15

J
025

w

03

0.4

A2h!4

Figure 4: Average delay vs. arrid rate for D~AM
md DSR when each node has speed V = 6

routing tables. Based on these routing (location) tables a probabilistic method for selecting the direction in
which a given node maybe found was proposed. Simulation resdts showed that with over 80% probability this
method can &d a route (if any etists) to a given node
in the direction computed by DMAM w~e the average end-t~end delays with respect to the DSR reactive
protocol are substantially lower. FinWy, the D~AM
protocol provides loopfree routes, and is robust in pr~
vidmg mdtiple routes to a given dwtination.

References
Figure 3: Average delay vs. arriti rate for D~AM
and DSR when each node has speed V = 2.

[1]BAGRODIA, R. L., AND LIAO, W.-T.
Maisie: a
language for the design of efficient discret~event
simdations. IEEE fiansactions on Software Engi-

neering 20, 4 (April 1994), 225–238.
correspond to two different node speeds, V = 2 and 6).
Furthermore, the average delay for D~AM
remains
essenti~y constant for W arrid rates.

[2] CHENG, C.,

RILEY, R., KUMAR, S. P. R.,
AND GARCIA-LUNA-ACEVES, J. J. A loopfiee
etiended be~an-ford
routing protocol without
bouncing effect. Computer Communication Review
19,4 (September 1989), 224-236.

The cofidence level of W our restits is 95%, and their
precision is within 5%.

6

[3] HAAS, Z. J. A new routing protocol for the reconfigurable wireless network. h Proceedings of the
1997 IEEE 6th International Conference on Uni-

Conclusions

versal Personal Communications, ICUPC’97

b this paper we have presented a new dwectiond routing protocol for ad hoc networks using a novel mechanism for the dissemination of location information. The
proposed solution can be used to minimize the amount
of bandwidth and transmission power used to maintain
routing tables without pentizing the accuracy of the

(San

Diego, CA, 12-16 October 1997), pp. 562-566.
[4] HAAS, Z. J. Panel report on ad hoc networks—
Mllcom’97.
Mobile Computing and Communications Review, MC2R, a publication of the ACM
SIGMOBILE 2, 1 (January 1998), 15-18.
83

———

.

..

—...,

-—c

.

-..——

[5] HAAS, Z. J., AND PEARLMAN, M. R. The zone
routing protocol (ZRP) for ad hoc networks. ~TERNET DRAFT-Mobile
Ad hoc Networking
(MANET) Working Group of the bternet Engineering Task Force (ETF), November 1997. To be
considered Work in Progress. See dso [8].
[6] JOHNSON, D., AND MALTZ, D. A. Dynamic
source routing in ad hoc wireless networks. h
Mobile Computing, T. tiefinski
and H. F. Korth,
Eds. Kluwer Academic PubUshers, Dordrecht, The
Netherlands, February 1996, ch. 5, pp. 153-181.
[7] KAPLAN, E. D., Ed. Understanding GPS: principles and applications. Artech House, Boston, MA,

1996.
[8] MACKER, J. P., AND CORSON, M. S. Mobfle ad
hoc networking and the ETF.
Mobile Computing
and Communications Review, MC2R1 a publication
of the ACM SIGMOBILE 2, 2 (Aprti 1998), 9–12.
[9] MURTHY, S., AND GARCIA-LUNA-ACEVES, J. J.
An efficient routing protocol for wireless networks.
ACM/Baltzer Journal on Mobile Networks and Applications, MANET 1,2 (October 1996), 183-197.

[10] PARK, V., ANDCORSON, M. S. A higMy adaptive
distributed algorithm for mobde wireless networks.
h Proceedings of the IEEE INFOCOM’97 (Kobej
Japan, 7-11 Aprti 1997).
[11] PERKINS, C. E. Ad hoc on-demand

distance vector

(AODV) routing. ~TERNET

DRAFT-Mobfle
Ad hoc Networking
(MANET) Working Group
of the bternet Engineering Task Force (~TF),
20 November 1997. To be considered Work in
Progress. See dso [8].
[12] PERKINS, C. E., AND BHAGWAT, P. HigMy dynamic destination-sequenced
dlstanc~vector
routing (DSDV) for mobde computers. Computer Communication Review 24, 4 (October 1994), 234–244.

84

u

-— -—

.—

-.. .

1

Hierarchical Recovery in Compressive Sensing
Charles J. Colbourn, Daniel Horsley, and Violet R. Syrotiuk, Senior Member, IEEE

arXiv:1403.1835v1 [cs.IT] 4 Mar 2014

Abstract
A combinatorial approach to compressive sensing based on a deterministic column replacement technique is proposed.
Informally, it takes as input a pattern matrix and ingredient measurement matrices, and results in a larger measurement matrix
by replacing elements of the pattern matrix with columns from the ingredient matrices. This hierarchical technique yields great
flexibility in sparse signal recovery. Specifically, recovery for the resulting measurement matrix does not depend on any fixed
algorithm but rather on the recovery scheme of each ingredient matrix. In this paper, we investigate certain trade-offs for signal
recovery, considering the computational investment required. Coping with noise in signal recovery requires additional conditions,
both on the pattern matrix and on the ingredient measurement matrices.
Index Terms
compressive sensing, hierarchical signal recovery, deterministic column replacement, hash families

I. I NTRODUCTION
Nyquist’s sampling theorem provides a sufficient condition for full recovery of a band-limited signal: sample the signal at a
rate that is twice the band-limit. However, there are cases when full recovery may be achieved with a sub-Nyquist sampling
rate. This occurs with signals that are sparse (or compressible) in some domain, such as those that arise in applications in
sensing, imaging, and communications, and has given rise to the field of compressive sensing [2], [6] (also called compressive
sampling).
Consider the following framework for compressive sensing. An admissible signal of dimension n is a vector in Rn that is
known a priori to be taken from a given set Φ ⊆ Rn . A measurement matrix A is a matrix from Rm×n . Sampling a signal
x ∈ Rn corresponds to computing the product Ax = b. Once sampled, recovery involves determining the unique signal x ∈ Φ
that satisfies Ax = b using only A and b. If Φ = Rn , recovery can be accomplished only if A has rank n, and hence m ≥ n.
However for more restrictive admissible sets Φ, recovery may be accomplished when m < n.
Given a measurement matrix A, an equivalence relation ≡A is defined so that for signals x, y ∈ Rn , we have x ≡A y
if and only if Ax = Ay. If for every equivalence class P under ≡A , the set P ∩ Φ contains at most one signal then in
principle recovery is possible. Because Ax = Ay ensures that A(x − y) = 0, this can be stated more simply: An equivalence
class P of ≡A can be represented as {x + y : y ∈ N (A)} for any x ∈ P , where N (A) is the null space of A, i.e., the set
{x ∈ Rn : Ax = 0}. Recoverability is therefore equivalent to requiring that, for every signal x ∈ Φ, there is no y ∈ N (A)\{0}
with x + y ∈ Φ.
In order to make use of these observations, a reasonable a priori restriction on the signals to be sampled is identified, suitable
measurement matrices with m ≪ n are formed, and a reasonably efficient computational strategy for recovering the signal is
provided. A signal is t-sparse if at most t of its n coordinates are nonzero. The recovery of t-sparse signals is the domain
of compressive sensing. An admissible set of signals Φ has sparsity t when every signal in Φ is t-sparse. An admissible set
of signals Φ is t-sparsifiable if there is a full rank matrix B ∈ Rn×n for which {Bx : x ∈ Φ} has sparsity t. We assume
throughout that when the signals are sparsifiable, a change of basis B is applied so that the admissible signals have sparsity t.
A measurement matrix has (ℓ0 , t)-recoverability when it permits exact recovery of all t-sparse signals. A basic problem is
to design measurement matrices with (ℓ0 , t)-recoverability where m ≪ n such that recovery can be accomplished efficiently.
Suppose that measurement matrix A has (ℓ0 , t)-recoverability. Then in principle, given A and b, recovery of the signal x can
be accomplished by solving the ℓ0 -minimization problem min{||x||0 : Ax = b}. To do so the possible supports of signals
from fewest nonzero entries to most are first listed. For each, reduce A to A′ and x to x′ by eliminating coordinates in the
signal assumed to be zero. Examine the now overdetermined system A′ x′ = b. When equality holds, a solution is found; we
are guaranteed to find one by considering all possible supports
with at most t nonzero entries. Such an enumerative strategy is

prohibitively time-consuming, examining as many as nt linear systems when the signal has sparsity t. Natarajan [27] showed
that we cannot expect to find a substantially more efficient solution, because the problem is NP-hard.
Instead of the ℓ0 -minimization problem, Chen, Donoho, Huo, and Saunders [11], [18] suggest considering the ℓ1 -minimization
problem min{||x||1 : Ax = b}. While this can be solved using standard linear programming techniques, to be effective it
is necessary that for each t-sparse signal x, the unique solution to min{||z||1 : Az = Ax} is x. This property is (ℓ1 , t)recoverability. A necessary and sufficient condition for (ℓ1 , t)-recoverability has been explored, beginning with Donoho and
Huo [18] and subsequently in [19]–[21], [24], [30], [31], [33].
C. J. Colbourn and V. R. Syrotiuk are with the School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe,
AZ, U.S.A., 85287-8809, {colbourn,syrotiuk}@asu.edu
D. Horsley is with the School of Mathematical Sciences, Monash University, Vic 3800, Australia, daniel.horsley@monash.edu

2

A measurement matrix A meets the (ℓ0 , t)-null space condition if and only if N (A) \ {0} contains no (2t)-sparse vector.
For y ∈ Rn and C ⊂ {1, . . . , n}, define y|C ∈ Rn to be the vector such that (y|C )γ = yγ if γ ∈ C and (y|C )γ = 0
otherwise. A measurement matrix A meets the (ℓ1 , t)-null space condition if and only if for every y ∈ N (A) \ {0} and every
C ⊂ {1, . . . , n} with |C| = t, ||y|C ||1 < 12 ||y||1 .
Lemma 1: ([13], for example) Measurement matrix A ∈ Rm×n has (ℓ0 , t)-recoverability if and only if A meets the (ℓ0 , t)null space condition.

Lemma 2: ([33], for example) Measurement matrix A ∈ Rm×n has (ℓ1 , t)-recoverability if and only if A meets the (ℓ1 , t)null space condition.

To establish (ℓ1 , t)-recoverability, and hence also (ℓ0 , t)-recoverability, Candès and Tao [7], [9] introduced the Restricted
Isometry Property (RIP). For A ∈ Rm×n , the dth RIP parameter of A, δd (A), is the smallest δ so that, for some constant R > 0,
(1 − δ)R(||x||2 )2 ≤ (||Ax||2 )2 ≤ (1 + δ)R(||x||2 )2 , for all x with ||x||0 ≤ d. The dth RIP parameter is better when δd (A)
is smaller as the bounds are tighter. The RIP parameters have been employed extensively to establish (ℓ1 , t)-recoverability,
particularly for randomly generated measurement
matrices [8]–[10], but also for those generated using deterministic con√
structions [12], [17]. Commonly, δ2t < 2 − 1 is required for (ℓ1 , t)-recoverability; see [7] for example. The property of
(ℓ1 , t)-recoverability in the presence of noise has also been considered. Conditions on the RIP parameters are sufficient but in
general not necessary for recoverability.
Combinatorial approaches to compressive sensing are detailed in [3], [16], [22], [23], [25], [26], [32]. We pursue a different
combinatorial approach here, using a deterministic column replacement technique based on hash families. The use of an
heterogeneous hash family provides an explicit hierarchical construction of a large measurement matrix from a library of
small ingredient matrices. Strengthening hash families provide a means to increase the level of sparsity supporte, allowing the
ingredient matrices to be designed for lower sparsity than the larger measurement matrix produced.
In this paper we show that the heterogeneity extends to signal recovery: it is interesting that the ingredient measurement
matrices need not all employ the same recovery algorithm. This enables hierarchical recovery for the large measurement matrix;
however, this can be computationally prohibitive. By restricting the hash family to be linear, recovery for the large measurement
matrix can be achieved in sublinear time even when computationally intensive methods are used for each ingredient matrix. To
be practical, recovery methods based on hash families must deal with noise in the signal effectively. Suitable restrictions on
the hash family and on each ingredient matrix used in the hierarchical method are shown to be sufficient to permit recovery
in the presence of noise.
The rest of this paper is organized as follows. The results on homogeneous hash families in Section II demonstrate that
a recovery scheme based on (ℓ0 , t)- or (ℓ1 , t)-recoverability can be ‘lifted’ from the ingredient measurement matrices to the
matrix resulting from column replacement. Section III considers a generalization of hash families to allow for ingredient
matrices with other recovery algorithms, and the computational investment to recover the signal. Signal recovery without noise
is considered first, and the conditions for a sublinear time recovery algorithm described. Section IV considers the recovery of
almost-sparse signals to deal with noise in the signal. Finally, Section V draws relevant conclusions.
II. H ASH FAMILIES

AND

C OMPRESSIVE S ENSING

A. Column Replacement and Hash Families for Compressive Sensing
Let A ∈ Rr×k , A = (aij ), be an ingredient matrix. Let P ∈ {1, . . . , k}m×n , P = (pij ), be a pattern matrix. The columns
of A are indexed by elements of P . For each row i of P , replace element pij with a copy of column pij of A. The result is
an rm × n matrix B, the column replacement of A into P . Fig. 1 gives an example of column replacement.


a11 a12 a13 a11




 a21 a22 a23 a21 
1231
a11 a12 a13

B=
P =
A=
 a13 a11 a12 a11 
a21 a22 a23
3121
a23 a21 a22 a21

Fig. 1.

B is the column replacement of A into P .

When the ingredient matrix A is a measurement matrix that meets one of the null space conditions for a given sparsity, our
interest is to ensure that the sparsity supported by B is at least that of A. Not every pattern matrix P suffices for this purpose.
Therefore, we examine the requirements on P .
Let m, n, and k be positive integers. An hash family HF(m; n, k), P = (pij ), is an m × n array, in which each cell contains
one symbol from a set of k symbols. An hash family is perfect of strength t, denoted PHF(m; n, k, t), if in every m × t

3

subarray of P at least one row consists of distinct symbols; see [1], [28]. Fig. 2 gives an example of a perfect hash family
PHF(6; 12, 3, 3). For example, for the 6 × 3 subarray involving columns 4, 5, and 6, only the fourth row consists of distinct
symbols.

→
Fig. 2.

0
0
1
2
2
2

1
2
0
0
0
0

↓
2
0
2
1
1
2

2
1
0
1
2
1

↓
1
2
2
2
2
1

↓
2
2
2
0
1
1

2
2
1
2
0
2

0
1
1
0
2
2

1
0
2
1
2
0

1
1
1
1
1
1

0
2
0
2
1
2

0
1
2
1
0
1

A perfect hash family PHF(6; 12, 3, 3).

A perfect hash family has at least one row that separates the t columns into t parts in every m × t subarray. A weaker
conditionP
separates the t columns into classes. A {w1 , . . . , ws }-separating hash family, denoted SHF(m; n, k, {w1 , . . . , ws }),
s
with t = i=1 wi , is an m × n array on k symbols in which for every m × t subarray, and every way to partition the t columns
into classes of sizes w1 , . . . , ws , there is at least one row in which no two classes contain the same symbol; see [4], [29]. A
W-separating hash family, denoted SHF(m; n, k, W), is a {w1 , . . . , ws }-separating hash family for each {w1 , . . . , ws } ∈ W.
Fig. 3 gives an example of a {1, 2}-separating hash family SHF(3; 16, 4, {1, 2}). For the 3 × 3 subarray consisting of columns
11, 15, and 16, for example, the last row separates columns {11, 16} from column {15}.

→
Fig. 3.

1
1
1

1
2
2

1
3
3

1
4
4

2
1
2

2
2
1

2
3
4

2
4
3

3
1
3

↓
3
3
1

3
2
4

3
4
2

4
1
4

4
2
3

↓
4
3
2

↓
4
4
1

A {1, 2}-separating hash family SHF(3; 16, 4, {1, 2}).

Ps
A distributing hash family DHF(m; n, k, t, s) is an SHF(m; n, k, W) with W = {{w1 , . . . , ws } : t = i=1 wi }. Fig. 4
gives an example of a DHF(10; 13, 9, 5, 2). For the 10 × 5 subarray consisting of columns 8 through 12, row 4 separates
columns {8, 9, 10, 11} from column {12} (a {1, 4}-separation), and row 5 separates columns {8, 9, 12} from columns {10, 11}
(a {2, 3}-separation).

a {1, 4}-separation →
a {2, 3}-separation →

Fig. 4.

6
3
8
0
0
1
1
1
0
0

7
1
5
2
0
1
0
1
0
0

8
1
1
0
2
2
1
0
3
0

3
7
4
2
1
2
2
1
0
0

4
2
2
2
1
2
0
0
1
0

0
6
3
0
1
0
0
4
0
1

2
8
2
0
2
1
2
2
0
0

↓
2
4
6
1
0
0
0
0
2
0

↓
3
3
7
1
0
0
0
2
4
1

↓
0
0
0
1
2
2
1
0
0
0

↓
5
2
1
1
2
1
2
1
0
0

↓
1
0
3
2
0
0
2
0
1
0

1
5
0
0
1
0
1
2
0
1

A distributing hash family DHF(10; 13, 9, 5, 2).

Now, we are in a position to state the requirements on a pattern matrix P that ensure that the sparsity supported by the
matrix B resulting from column replacement is at least that of A.
Theorem 1: [13] Suppose that A is an r × k measurement matrix that meets the (ℓ0 , t)-null space condition, that P is an
SHF(m; n, k, {1, t}), and that B is the column replacement of A into P . Then B is an rm × n measurement matrix that meets
the (ℓ0 , t)-null space condition.

Theorem 2: [13] Suppose that A is an r × k measurement matrix that meets the (ℓ1 , t)-null space condition, that P is a
DHF(m; n, k, t + 1, 2), and that B is the column replacement of A into P . Then B is an rm × n measurement matrix that
meets the (ℓ1 , t)-null space condition.

4

B. Exploiting Heterogeneity in Column Replacement
All the standard definitions of hash families may be generalized by replacing k by k = (k1 , . . . , km ), a tuple of positive
integers. Now, an heterogeneous hash family HF(m; n, k), P = (pij ), is an m × n array in which each cell from row i contains
one symbol from a set of ki symbols, 1 ≤ i ≤ m.
Column replacement may be extended to exploit heterogeneity in an hash family. Let P = (pij ) be an HF(m; n, k) and, for
1 ≤ i ≤ m, let Ai be an ri × ki ingredient matrix whose columns are indexed by the ki elements P
in row i of P . For each
row i of P , replace the element pij with a copy of column pij of Ai , 1 ≤ j ≤ n. The result is a ( m
i=1 ri ) × n matrix B,
the column replacement of A1 , . . . , Am into P . Fig. 5 gives an example of column replacement using an heterogeneous hash
family.

P =

Fig. 5.



132123
111222



A1 =



a111 a112 a113
a121 a122 a123

B is the column replacement of A1 , A2 into P .



A2 =



a211 a212
a221 a222




a111 a113 a112 a111 a112 a113
 a121 a123 a122 a121 a122 a123 

B=
 a211 a211 a211 a212 a212 a212 
a221 a221 a221 a222 a222 a222


An hierarchical method for compressive sensing is obtained using column replacement in an heterogeneous hash family.
Suppose that Ai is a measurement matrix for a signal of dimension ki supporting the recovery of sparsity qi , for 1 ≤ i ≤ m.
We now describe the properties the pattern matrix needs to satisfy to support recovery of signals of dimension n and sparsity
t.
In Section II-A, we saw that a perfect hash family separates t columns into t parts, and that a separating hash family
separates t columns into classes. We now define a particular type of separating hash family in which the number of symbols
used to accomplish the separations is restricted.
Let d = (d1 , . . . , dm ) be a tuple of positive integers, and let τ be a positive P
integer. Let W = {W1 , . . . , Wr }, where for
si
1 ≤ i ≤ r, Wi = {wi1 , . . . , wisi } is a multiset of nonnegative integers, and σi = j=1
wij . An SHF(m; n, k, W), P = (pij ),
is (d, τ )-strengthening if whenever 1 ≤ i ≤ r,
• C is a set of σi columns,
• C1 , . . . , Csi is a partition of C with |Cj | = wij for 1 ≤ j ≤ si , and
• T is a set of τ columns with |C ∩ T | = min(σi , τ ),
there exists a row ρ for which pρx 6= pρy whenever x ∈ Ce , y ∈ Cf and e 6= f and the multiset {pρx : x ∈ T } contains no
more than dρ different symbols. When τ = max{σi : 1 ≤ i ≤ r}, we omit τ and write d-strengthening. Because rows of P
can be arbitrarily permuted (while permuting the ingredient matrices in the same manner), the order of elements in k and d is
inconsequential. Hence we often use exponential notation, writing xu1 1 · · · xus s , with ui a non-negative integer for 1 ≤ i ≤ s,
Pℓ−1
Pℓ
Ps
for a vector (y1 , . . . , yPsj=1 uj ) in which yℓ = xj for j=1 uj < ℓ ≤ j=1 uj for 1 ≤ ℓ ≤ j=1 uj .
Fig. 6 gives a heterogeneous d-strengthening DHF(19; 13, k, 5, 2) with k = (56 41 312 ) and d = (46 313 ). This is equivalent
to a d-strengthening SHF(19; 13, k, {{1, 4}, {2, 3}}). Consider the separation of columns {1, 7} from columns {2, 6, 11}. Row
8 accomplishes the required separation because it uses no more than d8 = 3 symbols. Consider instead columns {1, . . . , 5}.
While the first row separates {1, 2, 3} from {4, 5}, it uses 5 symbols instead of d1 = 4 and so does not accomplish the required
separation; this separation is accomplished in row 3.
Next the properties are determined for an heterogeneous hash family to support recovery of signals of dimension n and
sparsity t using a column replacement technique.
Theorem 3: [14] Let k = (k1 , . . . , km ) and q = (q1 , . . . , qm ) be tuples of positive integers. Let d = (2q1 , . . . , 2qm ). For
1 ≤ i ≤ m, let Ai ∈ Rri ×ki be a measurement matrix that meets the (ℓ0 , qi )-null space condition. Let P be a (d, 2t)strengthening SHF(m; n, k, {1, t}), and let B be the column replacement of A1 , . . . , Am into P . Then B meets the (ℓ0 , t)-null
space condition.
Theorem 4: [14] Let k = (k1 , . . . , km ) and q = (q1 , . . . , qm ) be tuples of positive integers. For 1 ≤ i ≤ m, let Ai ∈ Rri ×ki
be a measurement matrix that meets the (ℓ1 , qi )-null space condition. Let P be a (q, t)-strengthening DHF(m; n, k, t + 1, 2),
and let B be the column replacement of A1 , . . . , Am into P . Then B meets the (ℓ1 , t)-null space condition.

Revisiting the d-strengthening DHF(19; 13, k, 5, 2) pattern matrix in Fig. 6, the results of Theorems 3 and 4 indicate that
the number of symbols in each row need not be the same. In general, there may be as many ingredient matrices Ai as there
are rows of the pattern matrix P . Moreover, the strength of each ingredient matrix Ai may be different! In this example, the

5

k1 = . . . = k6 = 5 symbols;
d1 = . . . = d6 = 4 used to separate

k2 = 4 symbols; d2 = 3 used to separate
→

k8 = . . . = k19 = 3 symbols;
d8 = . . . = d19 = 3 used to separate

Fig. 6.

⇓
4
0
0
2
2
3
0
0
1
0
0
0
2
2
0
1
1
2
0

↓
0
0
2
4
1
4
0
1
0
1
2
1
1
1
0
2
0
2
0

2
1
4
1
2
0
1
0
2
2
2
1
0
2
0
0
2
0
2

1
1
1
0
2
1
0
1
0
2
2
0
1
0
1
1
1
0
1

3
2
1
3
4
0
0
1
0
1
1
1
2
2
0
1
1
1
1

↓
3
3
2
0
0
3
2
2
2
2
2
2
0
2
1
1
0
2
0

⇓
0
1
0
3
0
2
2
0
1
1
0
1
1
0
1
2
0
1
1

0
3
1
1
4
4
0
2
1
0
0
0
2
0
2
2
2
0
2

1
2
2
1
0
2
0
0
0
0
1
0
0
1
0
0
0
0
0

4
4
3
4
1
1
1
0
2
0
1
2
2
0
1
0
0
1
2

↓
2
2
0
2
1
1
3
2
0
1
0
0
0
0
2
0
2
2
2

2
0
3
0
3
2
0
1
2
0
0
2
0
1
2
2
1
1
1

1
4
4
2
3
0
0
2
1
2
1
2
1
1
2
0
0
2
1

A heterogeneous d-strengthening DHF(19; 13, k, 5, 2) with k = (56 41 312 ) and d = (46 313 ).

first 6 rows use 4 symbols to separate, so the corresponding ingredient matrices must have strength at least 4. The remaining
rows use 3 symbols to separate, so the corresponding ingredient matrices must have strength at least 3.
In [14], we showed that heterogeneity gives great flexibility in construction of measurement matrices using column replacement. The hierarchical structure of the measurement matrices produced by column replacement can also aid in recovery, and
be used to support hybrid recovery schemes. We examine this problem next, considering a generalization of hash families that
removes the restriction to those strategies based only on (ℓ0 , t)- or (ℓ1 , t)-recoverability. We also consider the computational
investment required to recover the signal.
III. H ASH FAMILIES FOR R ECOVERY
In order to tackle signal recovery, we require another generalization of hash families. As before, let k = (k1 , . . . , km ) be a
tuple of positive integers. An HF◦ (m; n, k) is an m × n array, P = (pij ), in which each cell contains one symbol, and for each
row 1 ≤ i ≤ m, {pij : 1 ≤ j ≤ n} ⊆ {◦, 1, . . . , ki }. The symbol ◦, when present, is interpreted as representing a ‘missing’
entry. When the pattern matrix P = (pij ) is an HF◦ (m; n, k), and for 1 ≤ i ≤ m the ingredient matrix Ai is ri × ki with
columns indexed by the ki symbols in row i of P other than ◦, the column replacement of A1 , . . . , Am into P is as before,
except that when pij = ◦, it is replaced with an all zero column vector of length ri . As we will see, the separating properties
of the hash families we use allow us to locate the nonzero coordinates of the signal and hence perform the recovery.
The definition of a W-separating hash family encompasses perfect, {w1 , . . . , ws }-separating, and distributing hash families.
Therefore, we need only extend the definition of W-separating hash families to include the ◦ symbol. To do so, we allow
some of the elements of the multisets in W to be marked with a ◦ superscript to form a set of marked multisets W ′ ; the
multisets in W ′ are indexed. Then an HF◦ (m; n, k) is W ′ -separating if, for each {w1 , . . . , ws } ∈ W (with some elements
possibly marked),
Ps
• whenever C is a set of
i=1 wi columns, and
• C1 , . . . , Cs is an (indexed) partition of C with |Ci | = wi for 1 ≤ i ≤ s
then there exists a row that separates C1 , . . . , Cs in which, for 1 ≤ j ≤ s, if ◦ appears in a column in Cj then wj is marked.
As we will see, to recover the signal, the idea is to effect a separation where a significant coordinate of the signal is present
in one class such that any other class does not prevent its recovery.
A. Signal Recovery without Noise
Theorems 3 and 4 suggest that a recovery scheme based on (ℓ0 , t)- or (ℓ1 , t)-recoverability can be ‘lifted’ from the ingredient
measurement matrices A1 , . . . , Am to the larger measurement matrix B obtained from column replacement. However, such a
method appears to have two main drawbacks. First, it is restricted to recovery strategies based on (ℓ0 , t)- or (ℓ1 , t)-recoverability.
Secondly, and perhaps more importantly, it appears to necessitate a large computational investment to recover the signal, given
B.

6

In order to overcome these problems, we consider two cases. The positive case arises when the signal is known a priori to
be in Rn≥0 . The general case arises when the signal can be positive, negative, or zero. In each case we develop a recovery
scheme for the matrix B resulting from column replacement that does not depend on any fixed algorithm, but rather on the
recovery schemes for the ingredient matrices A1 , . . . , Am .
We suppose that P = (pij ) is an HF◦ (m; n, k). For each 1 ≤ i ≤ m, we suppose that Ai is an ri × ki measurement matrix
that has (ℓ0 , t)-recoverability, equipped with a recovery algorithm Ri that determines the unique t-sparse vector zi that solves
Ai zi = yi . We further suppose that B is the column replacement of A1 , . . . , Am into P , and that y is the result of sampling
an (unknown) t-sparse vector x = (x1 , . . . , xn ) using B.
For 1 ≤ i ≤ m, the ith row of P induces a partition {Si◦ , Si1 , . . . , Siki } of the column indices {1, . . . , n}, where Siσ =
{j : pij = σ, 1 ≤ j ≤ n} for σ ∈ {◦, 1, . . . , ki }. Assume that we have employed the recovery algorithms Ri to find solutions
zi . For 1 ≤ i ≤ m and σ ∈ {◦, 1, . . . , ki }, the partition class Siσ is discarded if σ = ◦, insignificant if σ 6= ◦ and ziσ = 0,
significant positive if ziσ > 0, and significant negative if ziσ
P< 0.
For 1 ≤ i ≤ m, let wi = (wi1 , . . . , wiki ) where wiσ = j∈Siσ xj . The vector wi can be considered as a projection of x
induced by the symbol pattern in row i of P . These facts follow:
i
• For 1 ≤ i ≤ m, by the definition of B and because Bi x = yi , zi = wi is a solution to A zi = yi .
i
• For 1 ≤ i ≤ m, because A has (ℓ0 , t)-recoverability and wi is t-sparse (because x is t-sparse), zi = wi is the unique
solution to Ai zi = yi , and so Ri returns wi .
We now consider the positive case and the general case for recovery in succession.
B. Signal Recovery: The Positive Case
We establish that in the positive case with t-sparse signals, it suffices to use a separating hash family of suitable strength,
along with suitable ingredient matrices. An SHF◦ (m; n, k, {1, t◦ }) separates t + 1 columns into two parts, one part of size one
that cannot include the symbol ◦, and the other of size t that may include ◦.
Theorem 5: Suppose that P is an SHF◦ (m; n, k, {1, t◦ }). For 1 ≤ i ≤ m, let Ai ∈ Rri ×ki be a measurement matrix that
has (ℓ0 , t)-recoverability equipped with a recovery algorithm Ri that determines the unique t-sparse vector zi that solves
Ai zi = yi . Further suppose that B is the column replacement of measurement matrices A1 , . . . , Am into P and that y is the
result of sampling an (unknown) t-sparse vector x = (x1 , . . . , xn ) ∈ Rn≥0 using B. Then the t-sparse solution x to Bx = y
can be recovered.

Proof: It suffices to determine whether xi is positive or zero for each 1 ≤ i ≤ n, because once this is accomplished we
can find the values of the positive xi by solving the overdetermined system that remains. For 1 ≤ i ≤ m, apply recovery
algorithm Ri to find the unique t-sparse vector zi such that Ai zi = yi . We claim that, for 1 ≤ ℓ ≤ n, xℓ is positive if and
only if for each i ∈ {1, . . . , m} the partition class that contains ℓ is either significant positive or discarded.
Suppose
P first that xℓ is positive. If Siσ is a partition class that contains ℓ, then either σ = ◦ and Siσ is insignificant or σ 6= ◦,
ziσ = j∈Siσ xj ≥ xℓ > 0, and Siσ is significant positive. Now suppose that xℓ = 0. Let C = {j : xj > 0, 1 ≤ j ≤ n};
|C| ≤ t. There must be a row ρ of P that separates C from {ℓ} such that pρℓ 6= ◦. Let σ = pρℓ . Then ℓ ∈ Sρσ and Sρσ ∩C = ∅,
so Sρσ is insignificant.
One useful application of Theorem 5 takes the pattern matrix P to be an SHF◦ (m; n, 1, {1, t◦ }), and each Ai to be a 1 × 1
matrix whose only element is 1; in this case, column replacement yields a matrix B isomorphic to P . In P for every column
γ and every set C of t columns with γ 6∈ C, there is a row in which all columns of C contain ◦, while column γ contains
1. Then the measurement matrices Ai have (ℓ0 , t)-recoverability and the recovery algorithms Ri are trivial. Hence in these
cases, a matrix isomorphic to P itself supports recovery.
Theorem 5 leads to a straightforward recovery algorithm. First, Ri is used to solve Ai zi = yi for 1 ≤ i ≤ m. Then the
classes Sij areP
classified as positive when zij > 0, discarded when j = ◦, and insignificant when j 6= ◦ and zij = 0; this can
m
be done in O( i=1 ki ) time. We need only compute, for each row, the complement of the union of the insignificant classes,
and then compute the intersection over all rows of these complements. However, without additional structure this appears to
require the examination of each coordinate; hence, this gives an Ω(n) lower bound.
It is not difficult, nevertheless, to obtain sublinear recovery times by restricting the hash family; we return to this problem
in Section III-D.
C. Signal Recovery: The General Case
When the signal takes on both positive and negative values, cancellation of positive and negative contributions can yield a
zero measurement despite the presence of a signal. Nevertheless, an additional requirement on the structure of the hash family

7

suffices to address this problem, as we show next.
Theorem 6: Suppose that P is an SHF◦ (m; n, k, {{τ, (t + 1 − τ )◦ } : 1 ≤ τ ≤ t}). For 1 ≤ i ≤ m, let Ai ∈ Rri ×ki be a
measurement matrix that has (ℓ0 , t)-recoverability equipped with a recovery algorithm Ri that determines the unique t-sparse
vector zi that solves Ai zi = yi . Further suppose that B is the column replacement of measurement matrices A1 , . . . , Am into
P and that y is the result of sampling an (unknown) t-sparse vector x = (x1 , . . . , xn ) using B. Then the t-sparse solution x
to Bx = y can be recovered.

Proof: As in the proof of Theorem 5, it suffices to determine whether xi is nonzero or zero for each 1 ≤ i ≤ n,
because once this is accomplished we can find the values of the nonzero xi by solving the overdetermined system that
remains. For 1 ≤ i ≤ m, apply recovery algorithm Ri to find the unique t-sparse vector zi such that Ai zi = yi . Let
−
z+
i = (max(0, zij ) : 1 ≤ j ≤ ki ) and zi = (min(0, zij ) : 1 ≤ j ≤ ki ).
+
′
A row i of P is maximum positive if ||z+
i ||1 ≥ ||zi′ ||1 for 1 ≤ i ≤ m. Let M ⊆ {1, . . . , m} index the maximum positive
rows. We claim that a coordinate xℓ is positive if and only if, for every ρ ∈ M , ℓ is in a significant positive class of the
partition induced by row ρ.
Suppose first that xℓ is positive and let ρ ∈ M . Because ρ indexes a maximum positive row, the partition class induced
by row ρ that contains ℓ is not discarded and does not contain the index of any negative variable. Thus it is in a significant
positive partition class.
Now suppose that xℓ ≤ 0. Because P is an SHF◦ (m; n, k, {{τ, (t + 1 − τ )◦ } : 1 ≤ τ ≤ t}) and x is t-sparse, there is a row
ρ of P that separates {j : xj > 0, 1 ≤ j ≤ n} from {j : xj < 0, 1 ≤ j ≤ n} ∪ {ℓ} in which the symbol ◦ only appears in a
subset of the columns indexed by {j : xj < 0, 1 ≤ j ≤ n} ∪ {ℓ}. It follows that ρ is a maximum positive row of P and that
the partition class induced by ρ containing ℓ does not contain the index of any positive coordinate. So ρ ∈ M , but ℓ is not in
a significant positive class of the partition induced by row ρ.
In the same manner, all negative coordinates can be identified using maximum negative rows.

Again a straightforward recovery algorithm is given by Theorem 6 but, as in the positive case, it naively involves examining
each of the n coordinates.
D. Sublinear Time Signal Recovery
Recovery can be accomplished in time that is sublinear in k when the hash family has suitable structure; we develop a
general approach, and one example, here. In each case, for some subset M of the rows of P , sets are identified that must
contain the indices of all positive coordinates (the indices of the negative coordinates, if they exist, can be located similarly).
Recall from Section III-A, that the positive case arises when the signal is known a priori to be in Rn≥0 and the general case
arises when the signal can be positive, negative, or zero. In the positive case, M contains all rows and for ρ ∈ M , the candidate
indices are Vρ+ = {ℓ : pρℓ = ◦, or xℓ ∈ Sρj and zρj > 0}. In the general case, M contains all rows that index maximum
positive rows, and for ρ ∈ M , the candidate indices are Vρ+ = {ℓ : xℓ ∈ Sρj and zρj > 0}. In both cases, we are to determine
T
+
we do not list the members of Vρ+ explicitly, but rather use
ρ∈M Vρ . In order to avoid the examination of each
T coordinate,
+
an implicit representation to list the members of ρ∈M Vρ .
First we give an implicit representation of an hash family HF(q + 1; q α , q), P , where q is a prime power and 2 ≤ α ≤ q.
Let {ω0 , . . . , ωq−1 } be the elements of the finite field of order q, Fq . Index the rows of P by {∞} ∪ {ω0 , . . . , ωq−1 }. Index
the columns of P by the q α polynomials of degree less than α in indeterminate x, with coefficients in Fq . Now the entry of
P with row index β and column indexed by polynomial f (x) is determined as f (β) when β ∈ {ω0 , . . . , ωq−1 }, and as the
coefficient of xα−1 in f (x) when β = ∞.
By deleting rows, we form an HF(m; q α , q) for some 1 ≤ m ≤ q + 1. An hash family is linear if it is obtained in this way.
The separation properties of such an hash family are crucial [1], [5]. For our purposes, the observation of interest is from [15]:
if m ≥ (α − 1)w1 w2 + 1, then a linear HF(m; n, q) is {w1 , w2 }-separating. (This can be established by a simple argument:
When two polynomials of degree less than α evaluate to the same value at α different points, they are the same polynomial.) In
some cases, fewer rows suffice to ensure separation. In particular, Blackburn and Wild [5] establish that when q is sufficiently
large, one needs at most α(w1 + w2 − 1) rows; and in [15] specific small separations are examined to determine the set of
prime powers for which various numbers of rows less than (α − 1)w1 w2 + 1 suffice. We proceed with the general statement
so as not to impose additional conditions.
When m ≥ (α − 1)t + 1, P is {1, t}-separating; in addition, every {1, t − 1}-separation is accomplished in at least α rows.
t+1
When m ≥ (α − 1)⌊ t+1
2 ⌋⌈ 2 ⌉+ 1, P is {w, t+ 1 − w}-separating for each 1 ≤ w ≤ t; in addition, every {w, t− w}-separation
t+1
t
t
t+1
is accomplished in at least α rows, because ⌊ t+1
2 ⌋⌈ 2 ⌉ = ⌊ 2 ⌋⌈ 2 ⌉ + ⌊ 2 ⌋. Thus in either case, M contains at least α rows
of P .

8

Q
Choose any α rows U = {ψ1 , . . . ψα } ⊆ M . Now consider the sets {Vψ+ : ψ ∈ U }. Define ψ∈U |Vψ+ | vectors V + =
{(g1 , . . . , gα ) : gi ∈ {pψi ℓ : ℓ ∈ Vψ+i } for 1 ≤ i ≤ α}. Each (g1 , . . . , gα ) ∈ V + defines a unique column of the hash family,
corresponding to the unique polynomial L of degree at most α − 1 satisfying L(ψi ) = gi for 1 ≤ i ≤ α. Any column that does
not arise in this way from a member of V + cannot be the column for a positive coordinate, because in the partition induced
by one of the selected maximum rows it is not in a significant positive class. However, columns arising from vectors in V +
need not arise from positive coordinates, because we may not have examined all of the rows of M . Nevertheless, we can now
generate each of the columns arising from vectors in V + , and check for each whether it occurs in positive classes for all rows
of M , not just the α selected.
Now |V + | is O(tα ), so when t is o(q), the size of V + is o(n) (because n = q α ). For concreteness, taking q = tβ for t a
prime power, we can permit α to be as large as tβ−2 . (For the positive case, we can permit α to be as large as tβ−1 . ) Hence,
by restricting the hash family to one that is linear, it is possible to obtain recovery of the signal in sublinear time.
In general, a hash family together with its ingredient matrices can be represented more concisely compared to a random
measurement matrix for signal recovery. Furthermore, the hash family is an integer matrix, not a matrix of real numbers,
and may therefore be easier to encode. When the hash family is linear an implicit representation of it may be used, further
compacting its representation.
The results of this section provide some evidence that column replacement enables recoverability conditions to be met. In
Section IV, we show that it also preserves the basic machinery to deal with noise in the signal.
E. Adding Strengthening
As the signal length increases, it is natural to support high sparsity. Yet the techniques developed until this point only
preserve sparsity. Strengthening hash families provide a means to increase the level of sparsity supported.
Theorem 7: Suppose that P is a d-strengthening SHF(m; n, k, {{τ, (t + 1 − τ )} : 1 ≤ τ ≤ t}). For each 1 ≤ i ≤ m, we
suppose that Ai is an ri × ki measurement matrix that has (ℓ1 , di )-recoverability, equipped with a recovery algorithm Ri , that
either determines the unique di -sparse vector zi that solves Ai zi = yi or indicates that no such vector exists. Further suppose
that B is the column replacement of A1 , . . . , Am into P , and that y is the result of sampling an (unknown) t-sparse vector
x = (x1 , . . . , xn ) using B. Then the t-sparse solution x to Bx = y can be recovered.

Proof: Again it suffices to locate the nonzero coordinates of x. For 1 ≤ i ≤ m, if recovery algorithm Ri returns a solution
zi such that ||zi ||1 ≥ ||z||1 for any solution z returned by an oracle Rj , then zi is a maximum solution, and row i of P is a
maximum row. Because P is a d-strengthening SHF(m; n, k, {{τ, (t + 1 − τ )} : 1 ≤ τ ≤ t}), and x is t-sparse, there is a row
ρ of P that separates {j : xj > 0, 1 ≤ j ≤ n} from {j : xj < 0, 1 ≤ j ≤ n} with the property that at most dρ symbols appear
in the columns indexed by {j : xj 6= 0, 1 ≤ j ≤ n}. So the projected vector wρ is dρ -sparse and it is the solution returned by
Rρ . By the definition of ρ, ||wρ ||1 = ||x||1 . It follows that the ℓ1 -norm of any maximum solution is at least ||x||1 .
We claim that if Ri returns a maximum solution zi , then zi = wi . Suppose otherwise. Then, because zi is a maximum
solution, we have ||zi ||1 ≥ ||x||1 . Further, it is clear from the definition of ||wi || that ||wi ||1 ≤ ||x||1 . Thus Ai zi = Ai wi , zi
is di -sparse, and ||zi ||1 ≥ ||wi ||1 , which is a contradiction to the fact that Ai has (ℓ1 , di )-recoverability.
Having established our claim, we can now use arguments similar to those used in the proof of Theorem 6 to show that
a coordinate xℓ is positive (negative) if and only if, for every maximum row in P , ℓ is in a significant positive (significant
negative) class of the partition induced by that row.
IV. R ECOVERY

WITH

N OISE

We now treat the recovery ofPsignals with noise. A signal (x1 , . . . , xn ) is (s, t)-almost sparse if there is a set T of at most
t coordinate indices such that i∈{1...,n}\T |xi | < s.

Theorem 8: Suppose that P is an SHF(m; n, k, {{τ, (t + 1 − τ )} : 1 ≤ τ ≤ t}). For each 1 ≤ i ≤ m, we suppose that Ai
is an ri × ki measurement matrix, equipped with recovery algorithm Ri , which, when applied to the sample obtained from an
(s, t)-almost sparse signal xi , returns a vector zi such that ||zi − xi ||1 < ǫ. Further suppose that B is the column replacement
of A1 , . . . , Am into P , and that y is the result of sampling an (unknown) (s, t)-almost sparse vector x = (x1 , . . . , xn ) using B.
Then, a (perfectly) t-sparse vector x∗ = (x∗1 , . . . , x∗n ) such that for 1 ≤ i ≤ n, |xi | < 2(s + ǫ) if x∗i = 0, and |xi − x∗i | < s + ǫ
if x∗i > 0, and such that Bx∗ = y, can be recovered.
Proof: We provide a sketch first, and then the details. The idea is to write each coordinate of z as a sum of the signal
coordinates in T that contribute to it, and of a noise term e that includes both the small contributions from coordinates outside
T and the error less than ǫ from the recovery algorithm. For each row ρ of P , we then split this sum into two parts: one part

9

containing terms with the same sign as the z coordinate to which they contribute (indexed by sets Tρ′ and Eρ′ ), and another part
containing terms with the opposite sign to the z coordinate to which they contribute (indexed by sets Tρ′′ and Eρ′′ ). The key
observation is that the sum of the terms with indices in Tρ′′ can be approximated by 12 (||x|| − ||zρ ||) and hence by 21 (q − ||zρ ||)
′′
because if Tρ′′ is empty then zρ has norm close to ||x||, and
Pevery term with index in T+ρ reduces ||zρ ||.
Let T be a set of at most t coordinate indices such that i∈{1...,n}\T |xi | < s. Let T = {i ∈ T : xi ≥ 0}, T − = {i ∈ T :
P
xi < 0} and q † = i∈T |xi |. For 1 ≤ i ≤ m, apply Ri to yi to find a vector zi such that ||zi − wi ||1 < ǫ. For i ∈ {1, . . . , m},
call ||zi ||1 the signature of row i of P and let q be the maximum signature of any row of P .
For 1 ≤ i ≤ n, we calculate upper and lower estimates u(i) and ℓ(i) for xi . For each row index ρ ∈ {1, . . . , m} and each
symbol σ ∈ {1, . . . , kρ } we define uρσ and ℓρσ as follows.
1
1
• If zρσ ≥ 0, then uρσ = |zρσ | + 2 (q − ||zρ ||1 ) and ℓρσ = − 2 (q − ||zρ ||1 ).
1
1
• If zρσ < 0, then uρσ = 2 (q − ||zρ ||1 ) and ℓρσ = −|zρσ | − 2 (q − ||zρ ||1 ).
For each i ∈ {1, . . . , n} define uρ (i) = uρπ and ℓρ (i) = ℓρπ , where π is the symbol in row ρ of P such that i ∈ Sρπ , and
define u(i) = min{uρ (i) : 1 ≤ ρ ≤ m} and ℓ(i) = max{ℓρ (i) : 1 ≤ ρ ≤ m}. By first examining a row of maximum signature,
we can immediately conclude for each i ∈ {1, . . . , n} either that u(i) = 0 or that ℓ(i) = 0. Define a vector x∗ = (x∗1 , . . . , x∗n )
by setting x∗i = 0 if |ui |, |ℓi | ≤ s + ǫ, and otherwise setting x∗i equal to whichever of u(i) or ℓ(i) has the greater absolute
value. We claim that x∗ satisfies the required conditions.
To establish this claim we prove that, for 1 ≤ j ≤ n,
(i) for each ρ ∈ {1, . . . , m}, ℓρ (j) − (s + ǫ) < xj < uρ (j) + (s + ǫ);
(ii) there is some ρ ∈ {1, . . . , m} such that ℓρ (j) > −(s + ǫ) if xj ≥ 0 and uρ (j) < s + ǫ if xj < 0; and
(iii) there is some ρ ∈ {1, . . . , m} such that uρ (j) − (s + ǫ) < xj if xj ≥ 0 and xj < ℓρ (j) + (s + ǫ) if xj < 0.
We begin with some observations used throughout the proof. Let ρ be a row of P . For 1 ≤ σ ≤ kρ , we have zρσ =
Pkρ
P
|eρσ | ≤ s + ǫ. Let Tρ′ = {i ∈ T + : zρpρi ≥ 0} ∪ {i ∈ T − : zρpρi < 0}
( i∈T ∩Sρσ |xi |) + eρσ for some eρσ . Note that σ=1
′′
′
′
and let Tρ = T \ Tρ . Further, let Eρ = {σ ∈ {1, . . . , kρ } : eρσ , zρσ ≥ 0 or eρσ , zρσ < 0} and let Eρ′′ = {1, . . . , kρ } \ Eρ′ . For
1 ≤ π ≤ kρ , we have that

 

X
X
|zρπ | = 
|xi | − 
|xi | + δρπ |eρπ |
(1)
i∈Tρ′ ∩Sρπ

i∈Tρ′′ ∩Sρπ

where δρπ = 1 if π ∈ Eρ′ and δρπ = −1 if π ∈ Eρ′′ . Summing over the symbols in row ρ of P , we see

 
 

X
X
X
||zρ ||1 = q † − 2 
|xi | + 
|eρσ | − 
|eρσ |
i∈Tρ′′

and it follows that
1 †
2 (q



− ||zρ ||1 ) = 

σ∈Eρ′

(2)

σ∈Eρ′′





X
X
1
1
|eρσ | + 
|eρσ | .
|xi | − 
2
2
′
′′
′′


X

σ∈Eρ

i∈Tρ

(3)

σ∈Eρ

Adding (1) to (3), we obtain


|zρπ | + 12 (q † − ||zρ ||1 ) = 

X

i∈Tρ′ ∩Sρπ





|xi | + 

X

i∈Tρ′′ \Sρπ



|xi | −



1
2

X

σ∈Eρ′



|eρσ | +



1
2

X

σ∈Eρ′′



|eρσ | + δρπ |eρπ |.

(4)

It follows from (2) that each row of P has signature less than q † + (s + ǫ) and that any row of P that separates T + from T −
has signature greater than q † − (s + ǫ). Thus, q † − (s + ǫ) < q < q † + (s + ǫ) and hence
1
2 (q

− ||zρ ||1 ) − 12 (s + ǫ) < 12 (q † − ||zρ ||1 ) < 12 (q − ||zρ ||1 ) + 12 (s + ǫ).

(5)

Let j ∈ {1, . . . , n}. We next show that (i), (ii) and (iii) hold in the case where xj ≥ 0. The proof in the case where xj < 0
is similar.
Proof of (i). Let ρ index any row of P and let Sρπ be the partition class induced by row ρ of P that contains j. Now
ℓρ (j) − (s + ǫ) < xjPbecause ℓρ (j) ≤ 0. If j ∈
/ T , then xj < s and xj < uρ (j) + (s + ǫ) because uρ (j) ≥ 0. If j ∈ T and
zρπ < 0, then xj ≤ i∈T ′′ |xi | and we see from (3) and (5) that xj < 21 (q − ||zρ ||1 ) + (s + ǫ). If j ∈ T and zρπ ≥ 0, then
ρ
P
xj ≤ i∈Tρ′ ∩Sρπ |xi | and we see from (4) and (5) that xj < |zρπ | + 12 (q − ||zρ ||1 ) + (s + ǫ).
−
Proof of (ii). Let ρ index a row of P that separates T + ∪ {j} from
induced by row
P T and let Sρπ be the partition class
ρ of P that contains j. If zρπ ≥ 0, then, for 1 ≤ σ ≤ kρ , either i∈T ′′ ∩Sρσ |xi | ≤ |eρσ | and σ ∈ Eρ′ or Tρ′′ ∩ Sρσ = ∅.
ρ
Using this, it follows from (3) and (5) that ℓρ (j)P= − 21 (q − ||zρ ||1 ) > −(s + ǫ). If zρπ < 0, then Tρ′ ∩ Sρπ = ∅ and π ∈ Eρ′ .
Furthermore, for σ ∈ {1, . . . , kρ } \ {π}, either i∈T ′′ ∩Sρσ |xi | < |eρσ | and σ ∈ Eρ′ or Tρ′′ ∩ Sρσ = ∅. Using these facts, it
ρ
follows from (4) and (5) that ℓρ (j) = −|zπρ | − 12 (q − ||zρ ||1 ) > −(s + ǫ).

10

Proof of (iii). Let ρ index a row of P thatP
separates T + \ {j} from T − ∪ {j} and let Sρπ be the partition class induced by
row ρ of P that contains j. If zρπ < 0, then i∈T ′′ ∩Sρπ |xi | ≤ xj . Furthermore, for each symbol σ ∈ {1, . . . , kρ } \ {π}, either
ρ
P
|eρσ | and σ ∈ Eρ′ or Tρ′′ ∩Sρσ = ∅. Then, it follows from (3) and (5) that uρ (j) = 21 (q−||zρ ||1 )−(s+ǫ) < xj .
i∈Tρ′′ ∩Sρσ |xi | ≤
P
P
If zρπ ≥ 0, then i∈T ′ ∩Sρπ |xi | ≤ xj . Furthermore, for each symbol σ ∈ {1, . . . , kρ } \ {π}, either i∈Tρ′′ ∩Sρσ |xi | ≤ |eρσ |
and σ ∈ Eρ′ or Tρ′′ ∩ Sρσ = ∅. Then, it follows from (4) and (5) that uρ (j) = |zπρ | + 12 (q − ||zρ ||1 ) − (s + ǫ) < xj .
V. C ONCLUSION
Hierarchical construction of measurement matrices by column replacement permits the explicit construction of large measurement matrices from small ones. The use of heterogeneous hash families supports the use of a library of smaller ingredient
matrices, while the use of strengthening hash families allows the ingredient matrices to be designed for lower sparsity than
the larger measurement matrix produced. Perhaps surprisingly, the ingredient measurement matrices need not all employ
the same recovery algorithm; rather recovery for the large measurement matrix can use arbitrary routines for recovery that
are provided with the ingredient matrices. In this way, computationally intensive recovery methods can be used for the
ingredient matrices, which permits the selection of smaller matrices in general, while still enabling recovery for the large
measurement matrix. Nevertheless, recovery using the large measurement matrix can be computationally prohibitive without
further restrictions. Therefore it is shown that using a standard construction of linear hash families over the finite field, recovery
for the large measurement matrix can be effected in sublinear time. Indeed sublinear recovery time can be obtained even when
computationally intensive methods are used for each ingredient matrix. A practical implementation of these recovery methods
requires that the methods deal effectively with noise in the signal. Suitable restrictions on the hash family and on each ingredient
matrix used in column replacement are shown to be sufficient to permit recovery even in the presence of such noise.
Measurement matrices that result from one column replacement have been studied here. Because recovery does not depend
on the method by which recovery is done for the ingredient matrices, it is possible that the ingredient matrices themselves
are constructed by column replacement from even smaller ingredient matrices. The merits and demerits of repeated column
replacement deserve further study.
ACKNOWLEDGEMENTS
The work of D. Horsley and C. J. Colbourn is supported in part by the Australian Research Council through grant
DP120103067.
R EFERENCES
[1] N. Alon. Explicit construction of exponential sized families of k-independent sets. Discrete Mathematics, 58:191–193, 1986.
[2] R. Baraniuk. Compressive sensing. IEEE Signal Processing Magazine, 24:227–234, 2007.
[3] R. Berinde, A. C. Gilbert, P. Indyk, H. Karloff, and M. J. Strauss. Combining geometry and combinatorics: A unified approach to sparse signal recovery.
In Proceedings of the 46th Annual Allerton Conference on Communication, Control, and Computing, pages 798–805, 2008.
[4] S. R. Blackburn, T. Etzion, D. R. Stinson, and G. M. Zaverucha. A bound on the size of separating hash families. Journal of Combinatorial Theory,
Series A, 115((7):1246–1256, 2008.
[5] S. R. Blackburn and P. R. Wild. Optimal linear perfect hash families. Journal of Combinatorial Theory, Series A, 83:233–250, 1998.
[6] E. J. Candès. Compressive sampling. In International Congress of Mathematicians, volume 3, pages 1433–1452, 2006.
[7] E. J. Candès. The restricted isometry property and its implications for compressed sensing. Compte Rendus de l’Academie des Sciences, Series I,
346:589–592, 2008.
[8] E. J. Candès, J. Romberg, and T. Tao. Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. IEEE
Transactions on Information Theory, 52:489–509, 2006.
[9] E. J. Candès and T. Tao. Decoding by linear programming. IEEE Transactions on Information Theory, 51:4203–4215, 2005.
[10] E. J. Candès and T. Tao. Near optimal signal recovery from random projections: Universal encoding strategies. IEEE Transactions on Information
Theory, 52:5406–5425, 2006.
[11] S. S. Chen, D. L. Donoho, and M. A. Saunders. Atomic decomposition by basis pursuit. SIAM Journal on Scientific Computing, 20(1):33–61, 1998.
[12] A. Cohen, W. Dahmen, and R. A. DeVore. Compressed sensing and best k-term approximation. Journal of the American Mathematical Society,
22:211–231, 2009.
[13] C. J. Colbourn, D. Horsley, and C. McLean. Compressive sensing matrices and hash families. IEEE Transactions on Communications, 59(7):1840–1845,
2011.
[14] C. J. Colbourn, D. Horsley, and V. R. Syrotiuk. Strengthening hash families and compressive sensing. Journal of Discrete Algorithms, 16:170–186,
2012.
[15] C. J. Colbourn and A. C. H. Ling. Linear hash families and forbidden configurations. Designs, Codes and Cryptography, 59:25–55, 2009.
[16] G. Cormode and S. Muthukrishnan. Combinatorial algorithms for compressed sensing. In Lecture Notes in Computer Science, volume 4056, pages
280–294, 2006.
[17] R. A. DeVore. Deterministic constructions of compressed sensing matrices. Journal of Complexity, 23:918–925, 2007.
[18] D. L. Donoho and X. Huo. Uncertainty principles and ideal atomic decomposition. IEEE Transactions on Information Theory, 47:2845–2862, 2001.
[19] M. Elad and A. M. Bruckstein. A generalized uncertainty principle and sparse representation in pairs of bases. IEEE Transactions on Information
Theory, 48:2558–2567, 2002.
[20] J. J. Fuchs. On sparse representations in arbitrary redundant bases. IEEE Transactions on Information Theory, 50:1341–1344, 2004.
[21] J. J. Fuchs. Recovery of exact sparse representations in the presence of bounded noise. IEEE Transactions on Information Theory, 51:3601–3608, 2005.
[22] A. C. Gilbert, M. A. Iwen, and M. J. Strauss. Group testing and sparse signal recovery. In Proceedings of the 42nd Asilomar Conference on Signals,
Systems, pages 1059–1063, 2008.
[23] A. C. Gilbert, M. J. Strauss, J. Tropp, and R. Vershynin. One sketch for all: Fast algorithms for compressed sensing. In Proceedings of the ACM
Symposium on Theory of Computing, pages 237–246, 2007.

11

[24] R. Gribonval and M. Nielsen. Sparse representations in unions of bases. IEEE Transactions on Information Theory, 49:3320–3325, 2003.
[25] M. A. Iwen. Combinatorial sublinear-time Fourier algorithms. Foundations of Computational Mathematics, 10:303–338, 2010.
[26] S. Jafarpour, W. Xu, B. Hassibi, and R. Calderbank. Efficient and robust compressed sensing using optimized expander graphs. IEEE Transactions on
Information Theory, 55:4299–4308, 2009.
[27] B. K. Natarajan. Sparse approximate solutions to linear systems. SIAM Journal on Computing, 24:227–234, 1995.
[28] D. R. Stinson, Tran Van Trung, and R. Wei. Secure frameproof codes, key distribution patterns, group testing algorithms and related structures. Journal
of Statistical Planning and Inference, 86:595–617, 2000.
[29] D. R. Stinson, R. Wei, and K. Chen. On generalized separating hash families. Journal of Combinatorial Theory, Series A, 115:105–120, 2008.
[30] M. Stojnic, W. Xu, and B. Hassibi. Compressed sensing-probabilistic analysis of a null-space characterization. In Proceedings of the International
Conference on Acoustics, Speech, and Signal Processing, pages 3377–3380, 2008.
[31] J. A. Tropp. Recovery of short, complex linear combinations via l1 minimization. IEEE Transactions on Information Theory, 51:1568–1570, 2005.
[32] W. Xu and B. Hassibi. Efficient compressive sensing with deterministic guarantees using expander graphs. In Proceedings of IEEE Information Theory
Workshop, 2007.
[33] Y. Zhang. On theory of compressive sensing via ℓ1 -minimization: Simple derivations and extensions. Technical Report Technical Report CAAM
TR08-11, Rice University, 2008.

Mobile Networks and Applications 8, 567–577, 2003
 2003 Kluwer Academic Publishers. Manufactured in The Netherlands.

MERIT: A Scalable Approach for Protocol Assessment
ANDRÁS FARAGÓ and VIOLET R. SYROTIUK ∗
Department of Computer Science, Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas, P.O. Box 830688,
MS EC 31, Richardson, TX 75083-0688, USA

Abstract. MERIT is a framework that can be used to assess routing protocols in mobile ad hoc networks (manets). It uses the novel concept
of a shortest mobile path (SMP) in a mobile graph, a generalization of the shortest path problem for mobile environments. As a measure for
routing protocol assessment, we propose the mean ratio of the cost of the route used by a protocol to the cost of the optimal mobile path for the
same network history. The cost reflects that the route used in a session can change over time because of network dynamics such as topology
changes. The aim is for the ratio to be an abstract, inherent measure of the protocol that is as implementation-independent as possible. The
MERIT spectrum, which is the ratio expressed as the function of some parameters of interest, is a characterization of protocol effectiveness.
MERIT, for MEan Real vs. Ideal cosT, provides a scalable assessment framework: rather than comparing performance measures of different
protocols directly, we compare a protocol to the optimal solution. That is, rather than forcing the comparison to be in the same system, it
is done once for each protocol in its own environment. Furthermore, we show that there is an efficient algorithm to solve the underlying
SMP problem for important cases, making the approach practically feasible. We also investigate generalizations of and extensions within
the MERIT framework. We show that the MERIT framework is rich, with much wider generality and potential applicability than assessing
routing protocols.
Keywords: protocol assessment framework, mobile ad hoc networks, scalability, routing protocols

1. Introduction
Every network designer faces the task of selecting the right
protocol for various networking functions under given circumstances. Given the large and continuously growing pool
of available protocols, how can the different candidates be
systematically compared so that the “best” is reliably selected? This question sheds light on a new dimension of the
scalability challenge: networks grow rapidly not only in size
and heterogeneity, but also in the number of available design
choices, which includes setting the parameters of a given protocol in addition to the selection of the protocol itself.
Our specific interest is in how to select the best routing
protocol for specified conditions in a manet. A manet is
a self-organizing collection of wireless mobile nodes without
any supporting infrastructure. The study of these networks is
already mature, dating back to as early as the 1970’s. The
problem of routing is fundamental since all nodes can act as
routers. Consequently, the research has been vibrant, yielding
protocols that span the range of proactive to reactive, and flat
to hierarchical, with hybrids of all variety in between. Some
protocols even take into account issues such as energy efficiency and how to effectively use geographic information.
Numerous protocols appear as drafts in the Internet Engineering Task Force (IETF) manet working group [8], with many
more protocols in the literature.
Several qualitative and quantitative metrics now dominate
performance evaluation of manet routing protocols [3]. The
desirable qualitative properties include distributed operation
of the protocol, loop freedom, aspects of both reactive and
∗ Corresponding author.

proactive operation, security, sleep period operation, and support for unidirectional links. The quantitative metrics include
end-to-end throughput and delay, route acquisition time, percentage of out-of-order delivery, and protocol efficiency that
takes into account control overhead. Royer and Toh [17] survey several protocols using qualitative measures, and it is
commonplace to find quantitative comparisons (see, for example, Broch et al. [1]) since “standard” simulation platforms
such as ns-2, OPNET, and QualNet [12,16,20] are in widespread use.
While such qualitative and quantitative measures are informative they still do not provide a satisfactory framework
for a systematic and unified comparison of routing protocols.
The primary difficulty is that the quantitative measures are
known to be incomparable unless protocols are ported to the
same platform and run using the same protocol suite under the
same parameters [19]. In addition, the process of porting or
reimplementing protocols is time-consuming and error-prone.
Hence protocols that may be competitive for certain network
conditions may be overlooked simply because they are implemented in another platform.
To address this incomparability problem we propose
MERIT, a way to rank any given manet routing protocol by
comparing it to a theoretical, yet efficiently computable, optimum rather than to a competing protocol. MERIT, first introduced in [5] and further elaborated and extended upon here, is
a systematic and general framework for protocol assessment.
The idea of measuring performance relative to a theoretical optimum under the same conditions has been successfully
used in a number of other situations. For example, in approximation algorithms for NP-complete problems the approximative solution is compared to the (algorithmically infeasible)

568

NP-complete optimum, usually in terms of an approximation
ratio. Another example is competitive analysis of on-line algorithms, where the on-line performance is compared asymptotically to the best possible off-line performance, with the
on-line input set by a hypothetical adversary that can enforce
the worst case. In medium access control (MAC) protocols
when we speak about throughput, then we essentially compare the actual performance to the ideal (but infeasible) case
when each slot is successfully used for a packet. In load balancing it is often measured how much the load distribution
deviates from the ideal uniform distribution, thus comparing
the actual distribution with an ideal one.
In all of these examples the common thread is that a solution (algorithm, protocol, etc.) is compared to a theoretical
optimum in its own framework. That is, we measure how
much the actual result is worse than the optimum under the
same conditions. In this way each protocol is measured on
its own ground, which can be done for each solution independently, without forcing them to work in the same system.
Since MERIT eliminates the bottleneck created by the current need for comparing all protocols in the same system, it
ensures the scalability of the approach in terms of the rapidly
growing number of protocols and protocol variants.
Following suit, we show that the theoretical optimum can
be meaningfully defined and computed efficiently for manet
routing protocols. In [1], Broch et al. took a step in this direction by defining path optimality as the difference in hop count
between the actual path taken by the packet to the destination, and the shortest path that physically existed through the
network at the time the packet was originated. However the
timescales of the two paths do not coincide. The timescale
of the actual path is the packet lifetime, whereas the shortest path is found within a snapshot of the topology. Instead,
we evaluate the quality of a given protocol (under some given
cost model) by comparing the actual mobile path with the optimal (shortest) mobile path for the same history of network
topology changes. Compared to [1], in MERIT we make the
timescales of the actual and optimal mobile paths coincide
and also take into account that over the lifetime of a session,
the source–destination paths adapt to topology changes induced by the node mobility.
In MERIT, we aim for a mathematical model at a level of
abstraction that allows different routing protocols to be comparable and yet allows definition of a measure that is as independent as possible of platform and the specific details of
the network. Our measure, called the MERIT ratio, characterizes the performance of a protocol by the ratio of the MEan
Real vs. Ideal cosT (MERIT). Since it relates a mobile path to
the optimum under the same circumstances, we believe that
some of the dependencies on the platform and network details will cancel out yielding an implementation-independent
measure. The MERIT spectrum is the MERIT ratio expressed
as a function of parameters of interest and yields a multifaceted representation of the protocol effectiveness. Now,
each protocol only needs to be evaluated once, with the resulting MERIT spectra then directly comparable to those of
other protocols regardless of their native implementation plat-

A. FARAGÓ AND V.R. SYROTIUK

form. This solves the scalability issue with respect to design
choices.
In section 2 we introduce the basic definitions that form the
foundation of the MERIT framework. This includes a definition of a mobile graph, and a mobile path and its weight. The
shortest mobile path (SMP) problem is a generalization of the
shortest path problem for mobile networks. In this section, we
focus on additive link metrics and a simple 2-valued transition
cost function because of its practical importance. In addition,
the MERIT assessment measures are defined. In section 3 we
show that there is an efficient algorithm for the SMP problem
for the practical case, prove its correctness and give an example of its operation. Section 4 presents several generalizations
of the MERIT framework, including an extension from additive to more general path metrics, the implications of more
complex transition cost structures, and an extension for more
general protocols and networks. This demonstrates the richness of the MERIT framework. Finally, in section 5 we draw
conclusions and discuss future work.

2. The MERIT framework
2.1. Basic definitions
In the MERIT framework, we model a network at two
timescales. The instantaneous model of the network is a
graph G = (V , E). For a manet, the vertex set V corresponds to the nodes in the network, and a directed edge
in the edge set E exists whenever a wireless transmission
from one node to another is possible according to the physical layer protocol. The existence of a link may depend on
many variables such as free space and ground reflection propagation, transmission power, antenna gain, receiver sensitivity, propagation delay, capture effect, etc. Indeed, unidirectional wireless links often arise in manets [4], however, the
ability to use these links for routing may also depend on the
medium access control (MAC) (e.g., protocols using requestto-send/clear-to-send (RTS/CTS) signaling assume a bidirectional link).
One of the defining dynamic characteristics of a manet is
mobility. To capture mobility we model the network over a
longer timescale by a sequence of graphs that we call a mobile graph. For simplicity it is assumed that all the graphs
are defined on the same vertex set, but this assumption is not
essential. The framework permits modeling of node recovery
and failure, as well as nodes joining or leaving the network.
Thus a mobile graph G is defined as G = G1 G2 . . . GT
as any sequence Gi , i = 1, . . . , T , of graphs where the
successive graphs represent a history of the network topology changes over some timescale T . Each time there is a
link change, i.e., a link either comes up or goes down, the
mobile graph G = G1 . . . GT is extended by a new instantaneous graph GT +1 to a longer sequence G1 . . . GT GT +1
that includes this topology change. If there are simultaneous
changes in the topology they are all incorporated into the next
instantaneous graph.

MERIT: SCALABLE APPROACH FOR PROTOCOL ASSESSMENT

In a mobile graph we define a mobile path between a
source–destination pair s–t as a sequence of paths P =
P1 P2 . . . PT where Pi is a static path in Gi = (Vi , Ei ) between the same source–destination pair s–t. That is, each static path Pi is a sequence v0 v1 . . . vk of vertices in Vi such that
s = v0 , t = vk and (vj −1 , vj ) ∈ Ei for j = 1, . . . , k. The
length of the path k may be different in each graph Gi . Since
a mobile path is defined for the same source–destination pair
s–t, the timescale of T most naturally corresponds to the duration of a session between s and t.
In our current model we do not consider that the graph Gi
changes while the path Pi is computed. We believe this is a
valid assumption since large numbers of packets of a session
can be routed on the same path between a source–destination
pair before a topology change requires the route to be repaired
or recomputed.
Underlying every routing protocol is a cost model that can
be expressed as a weight function in each graph.1 The weight
function wi (u, v) for graph Gi is a function of vertex pairs
(u, v) that equals the value of the link metric if u can transmit to v, and equals infinity otherwise (i.e., the corresponding
edge is missing from the graph). In this way, the weight function wi fully defines the graph Gi .
The weight of a static path Pi in Gi is denoted by wi (Pi ).
For additive path metrics the weight is defined as the sum of
the link weights along the path. Thus for a given source–
destination pair s–t, if Pi = v0 v1 . . . vk−1 vk is a path from
s = v0 to t = vk given as a sequence of vertices then
wi (Pi ) =

k


wi (vj −1 , vj ).

j =1

Some examples of additive path metrics include hop count
(which is overwhelmingly the most common metric used),
delay, and delay jitter. Other more general path metrics are
addressed in section 4.1.
As part of the MERIT framework, we define the weight of
a mobile path w(P). It is natural to include two basic components in the weight of a mobile path:
1 Even when no explicit cost model is available, one can efficiently construct

a best approximation of the cost model by observing the choices of the
protocol. This “inverse optimization” approach is analyzed in [6], but for
the present paper we assume for simplicity that the costs are known.

569

1. The weights wi (Pi ) of the individual static paths in the
sequence, and
2. Some cost ctrans (Pi , Pi+1 ) incurred by the protocol whenever there is a change in the path sequence.
Thus, the weight (cost) of a mobile path P is defined as
w(P) =

T

i=1

wi (Pi ) +

T
−1

ctrans (Pi , Pi+1 ).

(1)

i=1

The transition cost between paths is a cost function associated
with having to update from one path to another in the routing
protocol. In general, it is the overhead associated with updating the routing state to reflect the change in the path.
Routing state is maintained in varying ways by different
protocols. For example, the Ad hoc On-Demand Distance
Vector (AODV) routing protocol [15] maintains a table of
the number of hops to the destination and the node that is
the first hop to use to reach the destination. The Dynamic
Source Routing (DSR) protocol [10] caches complete source
routes, i.e., the complete sequence of hops that the packet is to
follow on its way to the destination. The Temporally-Ordered
Routing Algorithm (TORA) [13] establishes a directed acyclic
graph rooted at the destination. Such reactive protocols typically maintain state between actively communicating nodes,
and attempt to localize the effect of a topology change. The
Optimized Link State Routing (OLSR) protocol [9] on the
other hand, is an example of a proactive routing protocol.
It maintains routes for each known destination all the time
through efficient periodic link state transmissions.
Initially, we consider a simple 2-valued transition cost
function where

0,
if Pi = Pi+1 ,
ctrans (Pi , Pi+1 ) =
(2)
cupdate  0, if Pi = Pi+1 .
That is, no transition cost is incurred if there is no change
in the path in successive graphs, otherwise a constant cupdate
cost is incurred if the path has changed. For example,
figure 1 shows a three graph subsequence Gi−1 Gi Gi+1 in
a mobile graph for a session between source–destination
pair 4–5. For this subsequence, ctrans (Pi−1 , Pi ) = cupdate and
ctrans (Pi , Pi+1 ) = 0.
We believe this 2-valued transition cost is reasonable for
the existing reactive routing protocols since, for example,

Figure 1. Subsequence Gi−1 Gi Gi+1 of a mobile graph sequence for source–destination 4–5.

570

A. FARAGÓ AND V.R. SYROTIUK

when data structures are updated the cost of the update is often insensitive to how much they are different from the previous ones. As a constant, the value of cupdate is rather arbitrary,
hence we view that the MERIT spectrum should be expressed
as a function of cupdate. The possibility of a more complex
transition cost structure will be addressed in section 4.2.
Thus, the MERIT framework defines the notions of a mobile graph, a mobile path, and the weight of a mobile path, including transition costs. Now, assuming a given cost model,
we can define the shortest mobile path problem within the
framework as follows.
Shortest Mobile Path (SMP) problem. Given a mobile
graph G = G1 . . . GT and a specified source–destination
pair s–t, find a mobile path P = P1 . . . PT from s to t, such
that the weight
w(P) =

T


wi (Pi ) +

i=1

T
−1

ctrans (Pi , Pi+1 )

i=1

of the mobile path is minimum.
Note that the static shortest path problem is included as a
direct special case of the shortest mobile path problem when
T = 1.
Now it is clear that any routing protocol ultimately finds
a path: either a static or a mobile path. Given an underlying cost model, it is natural and reasonable to select a shortest
path. However, while this is well established in the static case,
it is less clear how one can find a shortest mobile path. The
naive solution when each Pi is simply the shortest path in the
corresponding Gi may be far from optimal due to the transition costs.
Observe that the shortest mobile path can only be computed retrospectively, with known history of network changes.
Thus, we do not propose the approach as another routing protocol. Instead, we use it as a theoretical optimum relative to
which existing routing protocols can be measured.
2.2. MERIT assessment measures
Suppose that we wish to assess a manet routing protocol R,
and that R has been implemented in a simulation environment. For any given simulation run we may produce a trace of
the network topology, i.e., the mobile graph, and at the same
time we may also trace the routing state for each session for a
source–destination pair.
For a given mobile graph G = G1 . . . GT and s–t pair,
let Preal be the actual mobile path generated by the manet

routing protocol R. The weight w(Preal ) of this actual mobile path is computed directly from the routing state trace for
the s–t path in each Gi . The paths generated in turn directly
fix the transition costs. Similarly, let Pideal be the shortest
mobile path for G, i.e., the mobile path which will serve as
a benchmark for comparison. Both the path Pideal and its
weight w(Pideal ) are computed by the S HORTEST M OBILE
PATH algorithm (section 3) run on this instance G of the mobile graph and source–destination pair s–t.
We define the MERIT ratio for routing protocol R as:


w(Preal )
MERIT ratio = E
w(Pideal )


 1,

which is the expected value of the cost ratio of the actual mobile path to the shortest mobile path. The ratio represents how
far the routes in protocol R deviate in cost from the theoretical optimum. We compute the mean of the ratio of a large
enough sample size of randomly drawn s–t sessions in order
to obtain a 95% confidence interval. The distribution of the
sample is implicit from the simulation parameters such as arrival rate and mobility model.
We expect the MERIT ratio to be a stable and robust assessment measure for manet routing protocols since it relates a path to the optimum under the same circumstances.
As a result, we believe that some of the dependencies on
the platform and network details will cancel out yielding an
implementation-independent measure.
The value of the MERIT ratio clearly depends on many
parameters, hence it becomes meaningful when expressed as
the function of a parameter of interest. The MERIT ratio expressed as the function of some independent parameter defines the MERIT spectrum of the protocol R. Some examples
of such parameters include the node velocity, the average actual path length, the average node density, and transmit power
levels and the related energy consumption, as well as the transition cost.
When spectra are combined they yield a multi-faceted
representation of protocol effectiveness. By comparing the
MERIT spectra of protocols, we can identify those scenarios
that represent the strengths of the protocol. As well, the spectrum can be used by the designers of protocols to determine
whether a protocol meets a specified objective, or to fine tune
the performance of a protocol for specific network conditions.
Figure 2 shows a high level block diagram of the tool currently under development based on the MERIT framework.
Our framework derives its name from how we define the
assessment measures: MEan Real vs. Ideal cosT, or MERIT.

Figure 2. The MERIT tool.

MERIT: SCALABLE APPROACH FOR PROTOCOL ASSESSMENT

3. Finding the shortest mobile path
In this section, we show that the shortest mobile path (SMP)
problem can be solved efficiently. We use the dynamic programming method which is typically applied to optimization
problems. Like divide-and-conquer, dynamic programming
solves problems by combining solutions to subproblems.
However, it avoids the recomputation of subproblems by solving every subproblem just once, saving the answer in a table,
and subsequently performing table lookups.
The algorithm computes the SMP in subsequences
Gi . . . Gj of the mobile graph G = G1 . . . GT , recursively.
To describe the algorithm let us first introduce some notation.
• path[i, j ] is a table that stores the path sequence Pi . . . Pj
in the graph sequence Gi . . . Gj . At the end of the algorithm path[i, j ] will contain the SMP for the sequence
Gi . . . Gj .
• cost[i, j ] is a table that stores the cost of the current path
sequence in path[i, j ] as defined by (1) with appropriately
modified indices, i.e.,
cost[i, j ] = w(Pi . . . Pj )
j
j −1


wk (Pk ) +
ctrans (Pk , Pk+1 ).
=
k=i

k=i

• first[i, j ] is the first path in the current path sequence
path[i, j ].
• last[i, j ] is the last path in the current path sequence
path[i, j ].
In order to simplify the description of the algorithm, we assume that the variables cost[i, j ], first[i, j ], and last[i, j ] always refer to the latest value of path[i, j ]. Of course, in a
software implementation of the algorithm, explicit updates
are required to reflect the changes in path[i, j ].
We use a simple product notation for the concatenation of
sequences: path[i, k]path[k + 1, j ] means the concatenation
of the two sequences. For example, by definition it is always
true that first[i, i + 1]last[i, i + 1] = path[i, i + 1]. On the
other hand, the relationship path[i, j ] = first[i, j ]path[i +
1, j ] does not necessarily hold, since path[i + 1, j ] is not
necessarily a subsequence of path[i, j ]. Similarly, it may not
be true that first[i, j ] = first[i, j + 1].
The algorithm to compute the SMP consists of three steps.
Informally, in step 1 of the algorithm, we initialize path[i, j ]
and cost[i, j ] to values for the case where the transition costs
are zero for the entire subsequence Pi . . . Pj . This occurs if
the same path exists in all j −i +1 graphs in the subsequence.
In this case, the cost of the path subsequence is simply the
sum of the individual static path weights:
cost[i, j ] = w(Pi . . . Pj )
j
j −1


wk (Pk ) +
ctrans(Pk , Pk+1 )
=
k=i

=

j

k=i

k=i

wk (Pk )

571

and because Pk = Pk+1 it must be that ctrans (Pk , Pk+1 ) = 0,
for all k = i, . . . , j − 1.
The simplest way to determine whether the same path exists in all graphs of a subsequence is to form a graph G(ij )
that is the intersection of all of the graphs of the subsequence
G(ij ) = Gi ∩ · · · ∩ Gj , assign the weight of the edges in G(ij )
as the sum of the edge weights, and then search for an s–t
path in the resulting graph G(ij ) . If there is no path from s
to t in G(ij ) then cost[i, j ] is initialized as infinity. The reason this works is because for an edge to be in the intersection
G(ij ) the edge must exist in all graphs of the subsequence
Gi . . . Gj . Since a path is simply a sequence of edges, then if
there is an s–t path in G(ij ) it must be the case that the path
exists in each graph in the subsequence Gi . . . Gj . Assigning
weights to the edges in G(ij ) as the sum of the edge weights
in the subsequence accounts for the compression of the subsequence into one graph.
In steps 2 and 3, the algorithm computes the values in the
upper triangle of the cost and path table, diagonal by diagonal starting from the main diagonal and working towards the
upper right corner of the table, i.e., to positions cost[1, T ]
and path[1, T ]. (The lower triangle of the table is unused
by the algorithm.) This effectively solves all subproblems
in increasing size of the subproblem. The main diagonal
contains T subproblems of size one, G(11) = G1 , G(22) =
G2 , . . . , G(T T ) = GT . The diagonal above it contains
T − 1 subproblems of size two, G(12) = G1 G2 , G(23) =
G2 G3 , . . . , G(T −1T ) = GT −1 GT . This continues until finally the T th diagonal is reached containing the one problem
of size T , G(1T ) = G1 . . . GT , whose solution we seek.
For each graph subsequence Gi . . . Gj there is a corresponding path subsequence Pi . . . Pj , of length j − i + 1, and
the algorithm computes the cost of the path by considering all
possible ways k, i  k < j that the subsequence can be split:

Pi |Pi+1 . . . Pj


Pi Pi+1 |Pi+2 . . . Pj  i  k < j ways
..
to split Pi . . . Pj .

.


Pi . . . Pj −1 |Pj
Each such split combines two shorter, and hence already computed SMPs, and considers the transition cost ctrans (Pk , Pk+1 )
incurred by splitting the sequence at this point k. The minimum cost over all such splits is compared to the value computed at step 1, with the minimum overall stored. Figure 3
shows an example of all the subproblems created for a graph
sequence G1 . . . G4 of length four. These subproblems are
generated recursively in a depth-first manner.
In figure 4 we present the algorithm to compute the SMP
more formally. To avoid trivial cases we assume T  2. An
on-line version of the algorithm can be found in [18].
Theorem 1. The algorithm S HORTEST M OBILE PATH always correctly finds the shortest mobile path in any mobile
graph. If the mobile graph has n nodes and its timescale is T ,
then the time complexity of the algorithm is O(S(n)T 2 + T 3 )
where S(n) is the time required to find a (static) shortest path
in a graph on n vertices.

572

A. FARAGÓ AND V.R. SYROTIUK

· · · = Pj∗ . In this case, such a sequence is already generated
by the algorithm in step 1 with cost[i, j ] equal to the sum of
the weights of each path. In step 2, path[i, j ] cannot change in
this case, since that could only decrease its cost, contradicting
the assumed optimality. Thus, cost[i, j ] = cost∗ [i, j ] must
hold.
The second case occurs when not all paths in the optimal
path sequence are equal. Then there is a k, i  k < j such
∗ . Now,
that Pk∗ = Pk+1
cost∗ [i, j ] = cost∗ [i, k] + cost∗ [k + 1, j ] + cupdate .

Figure 3. Recursive SMP computation for |G| = 4.

cost[i, k]  cost∗ [i, k],

A LGORITHM S HORTEST M OBILE PATH

path[i, j ] = 	P

and

cost[k + 1, j ]  cost∗ [k + 1, j ].

Step 1 Initialization.
For all 1  i  j  T compute a (static) shortest path in
the graph G(ij ) = Gi ∩ · · · ∩ Gj with respect to the weight
function w = wi + · · · + wj , i.e., the weight of any edge
(u, v) is w(u, v) = wi (u, v) + · · · + wj (u, v). Denote the
obtained shortest path by P (ij ) and set
(ij )

By induction, we can use that we already know that the algorithm gives the optimal result for shorter sequences. (Notice
that the computation of path[i, j ] in step 2 uses only shorter
subsequences.) This yields

(ij )

.

..P  ,

j −i+1 identical paths

and cost[i, j ] = w(P (ij ) ). Initialize seqlen := 2.
Step 2 Sequence Split.
For all 1  i < j  T with j − i + 1 = seqlen perform
the following update.

newcost := min cost[i, k] + cost[k + 1, j ]
ik<j



+ ctrans last[i, k], first[k + 1, j ]
if newcost < cost[i, j ] then
path[i, j ] := path[i, k0 ]path[k0 + 1, j ],
where k0 is any minimizing value of the index k in the
computation of newcost.
Step 3 Lengthen Sequence.
If seqlen < T − 1 then increment seqlen and go to step 2.
Else STOP, the shortest mobile path is in path[1, T ] and its
cost is in cost[1, T ].
Figure 4. Dynamic programming algorithm for the Shortest Mobile Path
problem.

Proof. Let Pi∗ . . . Pj∗ be an optimal path sequence for
Gi . . . Gj with cost cost∗ [i, j ]. We want to show that
cost[i, j ] of the path sequence Pi . . . Pj computed by the algorithm equals the cost of the optimal path sequence, i.e.,
cost[i, j ] = cost∗ [i, j ]. This will prove that we find the shortest mobile path for each Gi . . . Gj .
There are two cases to consider. The first case is when all
paths in the optimal path sequence are the same, i.e., Pi∗ =

Note that while Pi∗ . . . Pj∗ is optimal by assumption, this may
not carry over to its subsequences (that is why we write inequalities). Thus the cost of path sequence Pi . . . Pj obtained
by step 2 of the algorithm satisfies
cost[i, j ]  cost[i, k] + cost[k + 1, j ] + cupdate
 cost∗ [i, k] + cost∗ [k + 1, j ] + cupdate
= cost∗ [i, j ].
Since cost[i, j ]  cost∗ [i, j ] holds by the assumed optimality of Pi∗ . . . Pj∗ , therefore, we obtain cost[i, j ] = cost∗ [i, j ],
which proves the correctness of the S HORTEST M OBILE
PATH algorithm.
Regarding the complexity, we run O(T 2 ) static shortest path computations in step 1, one for each subsequence
Gi . . . Gj . In the rest of the algorithm each path[i, j ] is computed once and there are O(T 2 ) of them. Each minimization
to compute newcost uses O(T ) already computed values, so
it takes O(T ) time, thus altogether the S HORTEST M OBILE
PATH algorithm has O(S(n)T 2 + T 3 ) worst case time complexity.

Since it is well known that a static shortest path can be
found in polynomial time, therefore, an immediate consequence of theorem 1 is that our S HORTEST M OBILE PATH
algorithm also works in polynomial time. For example, if
we use Dijkstra’s O(n2 ) algorithm to find the static shortest
paths, then a complexity of O(n2 T 2 + T 3 ) is obtained for the
shortest mobile path.
3.1. Example of the SMP algorithm
Figure 5 shows a mobile graph G = G1 G2 G3 G4 for a manet
with six nodes. In this example we consider computing the
shortest mobile path for the source–destination pair 1–5. Assuming hop count as the path metric, the (static) shortest path
is indicated by the bold edges in each graph in the figure. In
this case, ctrans (P1 , P2 ) = 0, and ctrans (P3 , P4 ) = 0, since

MERIT: SCALABLE APPROACH FOR PROTOCOL ASSESSMENT

573

Figure 5. A graph sequence G = G1 G2 G3 G4 .
Table 1
The cost[i, j ] table, i  j  4.
seqlen = 1

Initialize

1
2
3
4

seqlen = 2

seqlen = 3

1

2

3

4

1

2

3

4

1

2

3

4

1

2

3

4

3

6
3

∞
6
2

∞
∞
4
2

3

6
3

∞
6
2

∞
∞
4
2

3

6
3

9
6
2

∞
8
4
2

3

6
3

9
6
2

11
8
4
2

Figure 6. Graph intersections for SMP initialization.

P1 = P2 and P3 = P4 , respectively. Since P2 = P3 ,
ctrans (P2 , P3 ) = cupdate; let us assume that cupdate = 2.
Table 1 shows the values of the cost table computed by the
SMP algorithm in step 1 (Initialize), and in the subsequent
iterations of the algorithm (seqlen = 2, . . . , 4). Step 1 of
the algorithm initializes the main diagonal of the cost table to
the shortest path in each individual graph, Gi = G(ii) , i =
1, . . . , 4. Figure 6 shows the graph intersections for the remaining subproblems. For the subsequence G(12) = G1 G2
of length two, the same path 1–4–3–5 of length three exists
in both G1 and G2 . Thus w(P (12) ) = 6 which is equivalent to the path 1–4–3–5 being followed in each graph with
no transition cost incurred. In this example, it happens that
the path in the graph intersection corresponds to the shortest
path between 4–5, however this need not be the case. The initialization of the subproblems G(23) and G(34) is similar. For
the subsequences G1 G2 G3 , G2 G3 G4 and G1 G2 G3 G4 there
is no path that exists from 1–5 in each graph in the sequence.
Thus the table entries for G(13), G(24) and G(14) are initialized
to infinity.
For example, when optimizing the path sequence
P1 P2 P3 P4 , there are 3 ways to split the path sequence. For
the split after the first path P1 |P2 P3 P4 , into the two path sequences P1 and P2 P3 P4 , the cost is cost[1, 1] + cost[2, 4] +
ctrans (P1 , P2 ) = 3 + 8 + 0 = 11. For the split after the second path P1 P2 |P3 P4 , into the two path sequences P1 P2 and
P3 P4 , the cost is cost[1, 2] + cost[3, 4] + ctrans(P2 , P3 ) =

6 + 4 + 2 = 12. Finally, for the split after the third path
P1 P2 P3 |P4 , into the two path sequences P1 P2 P3 and P4 , the
cost is cost[1, 3]+cost[4, 4]+ctrans(P3 , P4 ) = 9+2+0 = 11.
In this case, the minimum (11) happens to correspond to the
first and the third way that the sequence is split, cost[1, 4] is
set to the value 11.
Notice that in this case, the shortest mobile path does not
correspond to simply selecting the static shortest path in each
graph of the graph sequence G1 . . . G4 . A possible realization
of the SMP is P P P Q, where P is the path 1–4–3–5 and Q
is the path 1–6–5. Thus, rather than incur the transition cost
for ctrans (P2 , P3 ) it is more cost effective to retain the path
until G4 .

4. Generalizations of the MERIT framework
4.1. Extension to general path metrics
Until now, we have assumed that the path metric is additive.
In a number of situations, however, different rules are used
to compute the path metric. For example to model available
bandwidth, the path weight should be the minimum of the link
weights along the path, rather than the sum since the available
bandwidth along the route acts as a “bottleneck”. In other
situations the product of link weights is the most appropriate,
such as in case of link availability probabilities in computing

574

A. FARAGÓ AND V.R. SYROTIUK

the reliability of a path (although this can be transformed into
a sum by taking logarithms).
In general, it is possible that each link is characterized by
more than one parameter and the path metric can be a nonlinear function of the link parameters. This is the situation
in QoS routing. An example path metric is given below. Assume each link i is characterized by a delay τi , an available
bandwidth Bi and the probability pi that the link will stay
available for the next minute. A possible path metric weight
is defined by




pi ,
if
τi  τ and min Bi  B,
1 −
i∈P
w(P ) =
i∈P
i∈P

 B0 − min Bi , otherwise, B0 a constant.
i∈P

This metric reflects the intent that we are looking for the most
reliable path, but only among those that have delay at most
τ and available bandwidth at least B. If no such path exists, then we would like to choose one with highest remaining
bandwidth among all paths, disregarding the other parameters.
One can naturally ask how such more complex path metrics can be handled in our framework. We can directly generalize the mobile path metric by replacing the wi (Pi ) terms
in (1) by the new static path metrics. The transition cost function is assumed to remain the same. Now the good news is that
all the generalized path metrics fit into the framework because
the shortest mobile path algorithm uses the static shortest path
computation as a “black box” and the proof of correctness and
complexity carry over without any change. Let us record this
simple but important observation in the following theorem.
Recall that the static shortest path algorithm is only used in
step 1 of the S HORTEST M OBILE PATH algorithm, looking
for the same path in each graph of the subsequence. If such a
path exists, ctrans = 0 and hence equation (1) reduces to the
sum of the weights along the paths of the subsequence.
Theorem 2. For any set wi (P ) of static path metrics, S HORTEST M OBILE PATH A LGORITHM always correctly finds the
shortest mobile path in any mobile graph. If the mobile graph
has n nodes and its timescale is T , then the time complexity of
the algorithm is O(S(n)T 2 +T 3 ) where S(n) is the worst case
time required to find a static shortest path, according to the
path metric w(P ) = wi (P ) + · · · + wj (P ), 1  i  j  T ,
in a graph on n vertices.
Note that theorem 2 implies the polynomial time solvability of the shortest mobile path problem whenever the underlying static shortest path can be found in polynomial time.
Even for those static path metrics for which the static problem is NP-complete (see examples, e.g., in [21]), theorem 2 is
still true, just S(n) is not polynomially bounded in that case.
Another interesting consequence of theorem 2 is that it
gives us a way to deal with very long graph sequences. Given
a mobile graph G = G1 . . . GT , where each graph is triggered
by a link change, we can then view each graph as existing over
a duration of time. The graph sequence partitions the simula-

Figure 7. Partition of simulated time into time intervals.

tion time into T intervals with each graph Gi having duration
ti − ti−1 as shown in figure 7.
Let the weight function be defined as a static link cost,
wi = s. Now we weight the edges proportionally to the time
the graph exists, i.e., wi = (ti − ti−1 ) · s, i = 1, . . . , T . Theorem 2 applies, as it is for any set of static link metrics, and
the interpretation is as follows. For a given pair s–t, many of
the link changes may be remote to s and t, and therefore have
no impact on the path packets flow between them. Rather
than incurring the (static) path cost again and again, for each
graph in the sequence, the benefit now is that cost of a path is
weighted proportionally to the time the path was used without change. Therefore while the network may have undergone many link changes, if those changes were transparent
to the source–destination path then the cost contributed to the
mobile path is similarly transparent to the topology changes.
While there may have been many link changes, they are effectively compressed into one graph if the changes did not
impact the routing protocol.
4.2. Extension to a more complex transition cost structure
It is clear that the transition cost for changing paths plays an
important role in the shortest mobile path problem. So far
we have assumed the simple 2-valued transition cost model
defined by (1). This model is insensitive to the extent of path
change: whenever there is a change, a constant update cost
is incurred. While this is a reasonable assumption in many
practical networking situations, nevertheless, it is interesting
to investigate what happens if a more general transition cost
function is applied.
Now we show that if the transition cost ctrans (Pi , Pi+1 )
is allowed to be a general function of the consecutive paths,
then the problem becomes more difficult. More precisely, we
show that there is a choice of ctrans(Pi , Pi+1 ) which makes the
shortest mobile path problem NP-complete, even if the static
path metric remains the simple additive metric.
Theorem 3. Assume that each static path metric wi (Pi ) is
additive in a mobile graph G = G1 . . . GT . Then the transition cost function ctrans(Pi , Pi+1 ) can be chosen such that
it becomes NP-complete to decide whether a mobile path P
exists between two specified nodes in G such that w(P)  C
holds for a given value of C.
Proof. Let us define the transition cost function by
ctrans (Pi , Pi+1 )



= M |Pi ∩ Pi+1 | + wi (Pi ) − wi+1 (Pi+1 ) ,

(3)

where M is the sum of all edge weights in all the Gi , and
|Pi ∩ Pi+1 | is the number of common edges on the paths

MERIT: SCALABLE APPROACH FOR PROTOCOL ASSESSMENT

Pi , Pi+1 . We show that with this choice the known NPcomplete problem PARTITION [7] can be reduced to our
task. In PARTITION the input consists of nonnegative integers
a1 , . . . , am and the question is whether this set of numbers
can be partitioned into two subsets with equal sum.
Let us construct a mobile graph with T = 2, using the input a1 , . . . , am of PARTITION. Let both graphs G1 , G2 be the
same simple path from a node s to another node t with edges
e1 , . . . , em and to each edge ei let us add a parallel edge fi .
Set the edge weights in both graphs to w1 (ei ) = w2 (ei ) = ai
and w1 (fi ) = w2 (fi ) = 0, i = 1, . . . , m.2
Now we show that there is a mobile path P = P1 P2 from
s to t in G = G1 G2 with w(P)  M/2 if and only if the
answer is “yes” to the question
 of the PARTITION problem.
By definition M = 2 m
i=1 ai , as M is the sum of all
weights in G1 , G2 . It follows from (3) that ctrans (P1 , P2 ) = 0
if and only if P1 and P2 has no common edge and w1 (P1 ) =
w2 (P2 ). In every other case ctrans(P1 , P2 )  M, since
then with integer weights we have |P1 ∩ P2 | + |w1 (P1 ) −
w2 (P2 )|  1.
Assume now there is a mobile path P = P1 P2 from s to
t in G = G1 G2 with w(P)  M/2. Then we must have
ctrans (P1 , P2 ) = 0, since otherwise w(P)  M would hold.
It follows from ctrans (P1 , P2 ) = 0 that P1 , P2 have no common edge and w1 (P1 ) = w2 (P2 ). Set A = {1, . . . , m} and let
A1 ⊆ A be the set of indices i for which ei ∈
P1 holds. Then
the weight assignment yields w1 (P1 ) =
i∈A1 ai , since
for i ∈
/ A1 the path P1 must use the parallel edge fi with
w
1 (fi ) = 0. By |P1 ∩ P2 | = 0 we similarly have w2 (P2 ) =
1 ) = w2 (P
2 ), it follows that
j ∈A−A1 aj . Knowing w1 (P
we have obtained a partition i∈A1 ai = j ∈A−A1 aj , providing a solution to the PARTITION problem. Conversely,
from any solution of PARTITION one can directly generate the
corresponding paths with ctrans(P1 , P
2 ) = 0, thus satisfying
w(P) = w1 (P1 ) + w2 (P2 ) + 0 = i∈A ai = M/2, which
proves the theorem.

Clearly, there is a gap between where the complexity of the
SMP problem is solvable in polynomial time to where we can
prove its NP-completeness. It would be interesting to determine the most general transition cost function for which the
problem still remains tractable. It would also be of interest to
precisely characterize the achievable approximation ratios for
cases when the problem is NP-complete.
From a more practical point of view, while it may be difficult to capture the transition cost ctrans as a function of the
overhead associated with a protocol, it should be possible to
generate a trace of the overhead incurred (say, in terms of
bytes). That is, just as we trace routing state during protocol execution, we could trace the control overhead for each
graph in the mobile graph. Then, the amount of overhead in
the trace could be used to incorporate transition cost into the
algorithm.
2 Note that if we want to avoid parallel edges then it can be easily achieved

by subdividing each edge by a new vertex and dividing the edge weight
equally between the two “halves”.

575

4.3. A general extension of the MERIT framework
While this paper has explored the MERIT framework for the
assessment of routing protocols in a manet, it could be used
for assessing other protocols, as well. The key observation
for generalization is that we do not specifically use in the algorithm that each entry of the mobile path is actually a path.
The algorithm and its proof carries over for the case of any
other structure, such as a spanning tree, multicast tree, clustering, etc. The essential point is that for the graph sequence
we generate a corresponding sequence of structures (paths,
trees, clusters, etc.), so that the total static cost plus the total
transition cost is minimum. The algorithm does this in a way
that the static cost minimization is used as a subroutine, as a
“black box” that can be replaced by another one. Thus, our
algorithm forms a layer on top of the static problem, extending it to the mobile case, independently of the actual nature of
the static problem.
Let us illustrate the concept for clustering. The general
idea of a clustering protocol is to partition the network nodes
into subsets called clusters. One node of each cluster is distinguished as the clusterhead. Often, it is desired that the clusterheads form either a dominating set or an independent set depending on whether a backbone connecting the clusterheads
is required. Each ordinary node is affiliated with a clusterhead
which altogether form a cluster.
Now the node movement may impact the clustering in two
different ways. One on hand, an ordinary node may move
too far away from its cluster requiring it to affiliate with another cluster. On the other hand, if two clusters merge, then a
recomputation of the clusterhead is triggered.
Just as with routing, we use a mobile graph. However,
rather than computing paths in each Gi , we now compute a
clustering Ci . Given a cost model and an objective function
it is possible to compute an optimal or approximately optimal
clustering in Gi . This can be compared to the actual clustering found by the protocol in each Gi . We could introduce a
2-valued transition function such as:

0,
if Ci = Ci+1 ,
ctrans (Ci , Ci+1 ) =
(4)
cupdate  0, if Ci = Ci+1 ,
where cupdate is a constant. With some minor modifications,
the shortest mobile path algorithm could be used to compute
the optimal mobile clustering.
Figure 8 illustrates an example of an actual versus an optimal clustering of the network. Here, each node is labeled by
its (not necessarily unique) weight. Larger weight indicates
higher suitability for the role of clusterhead, e.g., having a
large battery reserve. The clustering satisfies the following
properties: no two clusterheads (denoted by squares) can be
neighbors, every ordinary node has at least a clusterhead as
a neighbor, and every ordinary node affiliates with the neighboring clusterhead with larger weight. In this example, for the
actual clustering Ci−1 = Ci but Ci = Ci+1 and so the first
transition incurs no update cost while the second does.
The MERIT framework can also be used to assess protocols in other types of networks. Consider the problem of

576

A. FARAGÓ AND V.R. SYROTIUK

Figure 8. An actual versus an optimal clustering of the manet.

routing in a wired network. While the nodes are no longer
mobile, there are other dynamics we can consider. For example, if the routing protocol uses delay and bandwidth as
metrics, we could view any change in the delay or bandwidth
by more than a given threshold as a new instantaneous model
of the network. Now over a longer timescale, we model the
network history as a sequence of graphs generated by the network dynamics. The rest of the framework remains. Thus,
MERIT shows promise as a general framework and scalable
approach for protocol assessment.

5. Conclusions and future work
In this paper we have presented the MERIT framework and
shown how to use it for the systematic assessment of routing
protocols in a manet. We defined a mobile graph, a mobile
path, and the cost of a mobile path, all natural extensions of
the corresponding concepts in a static network. We defined
the shortest mobile path (SMP) problem and provided an efficient algorithm to solve the problem in practical situations.
Moreover, we introduced the MERIT ratio and spectrum as
assessment measures since they compare to a theoretical optimum rather than to other protocols. This is a key novelty
of our solution – it is inherently scalable, as it makes possible that each protocol developer provides their own protocol
spectra, as a kind of “watermark”. In this way comparison becomes possible without porting and reimplementation, thus,
it does not become a bottleneck with the growing number of
protocols and parameter settings. Some generalizations of the
framework are explored, examining the case for more general
path metrics and more complex transition cost structure. We
show that the showing the solution carries over to other protocols in more networks.

The MERIT framework is still in the early stages of its
development. From the theoretical point of view, there are
many interesting open problems. We intend to close the
gap between where the complexity of the SMP problem is
solvable in polynomial time to where we can prove its NPcompleteness. We also plan to explore more general path metrics, such as those that arise in QoS routing, which may benefit from the application of network calculus [2,11]. From an
implementation point of view, we are developing the MERIT
tool first using the ns-2 simulator to generate the mobile graph
each time a topology change occurs, and taking route traces
for actual path generation for the routing protocols under consideration. The mobile graphs generated can be very long,
hence we may apply sampling techniques or the idea suggested in section 4.1 to handle long sequences. In order
to verify our assertion that our metrics are implementationindependent, we will need to use another simulation tool, such
as OPNET or QualNet and use it to generate the input (mobile
graphs and route traces) to the MERIT tool. Thus, MERIT offers many directions for future research.

Acknowledgements
The authors wish to thank Priya Narayan for her contributions
to the implementation of the MERIT tool, and László Babai
and Jon Kleinberg for helpful comments and suggestions
when the problem was informally discussed at the STOC’98
conference in Dallas, Texas. We also wish to thank the anonymous reviewers for their useful suggestions that have greatly
improved the readability of this paper, and specifically one
reviewer for suggesting the use of network calculus.

MERIT: SCALABLE APPROACH FOR PROTOCOL ASSESSMENT

References
[1] J. Broch, D.A. Maltz, D.B. Johnson, Y.-C. Hu and J. Jetcheva, A performance comparison of multi-hop wireless ad hoc network routing protocols, in: Proceedings of the Fourth Annual ACM/IEEE International
Conference on Mobile Computing and Networking (Mobicom’98) (October 1998) pp. 85–97.
[2] C.-S. Chang, Performance Guarantees in Communication Networks
(Springer, Berlin, 2000).
[3] M.S. Corson and J. Macker, Mobile ad hoc networking (manet): routing protocol performance issues and evaluation considerations, Network Working Group, RFC 2501 (January 1999), http://www.
ieft.org/rfc/rfc2501.txt
[4] Density- and Asymmetry Adaptive Wireless Networks (DAWN), BBN
Technologies, http://www.ir.bbn.com/projects/dawn/
dawn-index.html
[5] A. Faragó and V.R. Syrotiuk, MERIT: a unified framework for routing
protocol assessment in ad hoc networks, in: Proceedings of the Seventh
Annual International Conference on Mobile Computing and Networking (Mobicom’01) (July 2001) pp. 53–60.
[6] A. Faragó, Á. Szentesi and B. Szviatovszki, Inverse optimization in
high speed networks, Discrete Applied Mathematics, Special Issue on
Telecommunications, submitted.
[7] M.R. Garey and D.S. Johnson, Computers and Intractability (Freeman,
San Francisco, 1983).
[8] Internet Engineering Task Force (IETF), Mobile Ad Hoc Networking (manet) Working Group, http://www.ietf.org/html.
charters/manet-charter.html
[9] P. Jacquet, P. Muhlethaler, A. Qayyum, A. Laouiti, L. Viennot and
T. Clausen, Optimized link state routing protocol, Internet Draft, Internet Engineering Task Force (IETF), manet Working Group, work
in progress.
[10] D.B. Johnson, Routing in ad hoc networks of mobile hosts, in: IEEE
Workshop on Mobile Computing Systems and Applications (December
1994) pp. 158–163.
[11] J.Y. Le Boudec, Application of network calculus to guaranteed service
networks, IEEE Transactions on Information Theory 44 (1998) 1087–
1096.
[12] OPNET: Optimum Network Performance, OPNET Technologies, Inc.,
http://www.mil3.com
[13] V.D. Park and M.S. Corson, A highly adaptive distributed routing algorithm for mobile wireless networks, in: Proceedings of the Annual Joint
Conference of the IEEE Computer and Communications Societies INFOCOM’97 (April 1997).
[14] C.E. Perkins and P. Bhagwat, DSDV routing over a multihop wireless
network of mobile computers, in: Mobile Computing, eds. T. Imielinski
and H.F. Korth (Kluwer, Dordrecht, 1996) pp. 183–206.
[15] C.E. Perkins and E.M. Royer, Ad-hoc on-demand distance vector routing, in: Proceedings of the Second Annual IEEE Workshop on Mobile
Computing Systems and Applications (February 1999) pp. 90–100.
[16] QualNet, Scalable Network Technologies, http://www.scalable
-networks.com
[17] E.M. Royer and C.-K. Toh, A review of current routing protocols for ad
hoc mobile wireless networks, IEEE Personal Communications (April
1999) 46–55.

577

[18] V.R. Syrotiuk, An efficient on-line algorithm for the shortest mobile
path problem, in: Proceedings of the 13th International Conference on
Wireless Communications (Wireless 2001) (July 2001) pp. 154–160.
[19] M. Takai, J. Martin and R. Bagrodia, Effects of wireless physical layer
modeling in mobile ad hoc networks, in: Proceedings of the 2001 ACM
International Symposium on Mobile Ad Hoc Networking & Computing
(MobiHoc’01), Long Beach, CA (October 2001) pp. 87–94.
[20] The Network Simulator – ns-2, The University of California, Berkeley,
http://www.isi.edu/nsname/ns
[21] Z. Wang, On the complexity of quality of service routing, Information
Processing Letters 69 (1999) 111–114.

Andras Farago received the M.Sc. and Ph.D. in
electrical engineering from the Technical University of Budapest, Budapest, Hungary, in 1976 and
1981, respectively, and in 1996 he obtained the distinguished title Doctor of the Hungarian Academy
of Sciences. He joined the University of Texas at
Dallas as Professor of Computer Science in 1998.
Dr. Farago is currently the PI of an NSF Grant on
medium access control protocols and co-PI of another one on optical network reliability. Until 1997,
he was with the Department of Telecommunications and Telematics, Technical University of Budapest, where he was co-founder of the High Speed
Networks Laboratory, a leading telecommunication and networking research
laboratory in the region. He worked as a visiting Senior Research Fellow at
the University of Massachusetts at Amherst in 1991/1992. He spent a sabbatical year at Boston University in 1996. He is a member of the IFIP Working Group 6.3 Performance of Communication Systems and was a founding
member of the Hungarian Chapter of ACM. He serves as editor for the Journal Wireless Networks. His research focuses on algorithms, protocols, design
and analysis methods of communication networks and authored over a hundred papers in his research area.
E-mail: farago@utdallas.edu

Violet R. Syrotiuk received the Ph.D. degree in
computer science in 1992 from the University of Waterloo, Waterloo, Ontario, Canada. Dr. Syrotiuk is an
Assistant Professor in the Department of Computer
Science in the Erik Jonsson School of Engineering
and Computer Science at the University of Texas at
Dallas where she is the co-director of the NET Lab,
the scalable Network Engineering Techniques Laboratory. Dr. Syrotiuk’s research has been funded
by the Defense Advanced Research Projects Agency
(DARPA), and is currently supported by grants from the National Science
Foundation (NSF) and Raytheon Company. Her current research interests
include medium access control (MAC) protocols with special emphasis on
intelligent protocol adaptation to unknown or changing network conditions,
and network layer protocols with an emphasis on scalable design. She is a
member of the IEEE and the ACM.
E-mail: syrotiuk@utdallas.edu

Profile-Driven Regression for Modeling and
Runtime Optimization of Mobile Networks
DANIEL W. MCCLARY and VIOLET R. SYROTIUK
Arizona State University
and
MURAT KULAHCI
Technical University of Denmark

Computer networks often display nonlinear behavior when examined over a wide range of operating conditions. There are few strategies available for modeling such behavior and optimizing such
systems as they run. Profile-driven regression is developed and applied to modeling and runtime
optimization of throughput in a mobile ad hoc network, a self-organizing collection of mobile wireless nodes without any fixed infrastructure. The intermediate models generated in profile-driven
regression are used to fit an overall model of throughput, and are also used to optimize controllable
factors at runtime. Unlike others, the throughput model accounts for node speed. The resulting
optimization is very effective; locally optimizing the network factors at runtime results in
throughput as much as six times higher than that achieved with the factors at their default levels.
Categories and Subject Descriptors: I.6.5 [Simulation and Modeling]: Model Development—
Modeling methodologies; G.1.6 [Mathematics of Computing]: Optimization; C.2.1 [ComputerCommunication Networks]: Network Architecture and Design—Wireless communication
General Terms: Performance
Additional Key Words and Phrases: Mobile ad hoc networks, regression modeling, runtime optimization
ACM Reference Format:
McClary, D. W., Syrotiuk, V. R., and Kulahci, M. 2010. Profile-driven regression for modeling and
runtime optimization of mobile networks. ACM Trans. Model. Comput. Simul. 20, 3, Article 17
(September 2010), 24 pages.
DOI = 10.1145/1842713.1842720 http://doi.acm.org/10.1145/1842713.1842720
The work of V. R. Syrotiuk was supported in part by NSF ANI-0240524 and ONR N00014-08-11970. Any opinions, findings, conclusions, or recommendations expressed in this article are those
of the authors and do not necessarily reflect the views of the National Science Foundation or the
Office of Naval Research. The work of M. Külahçi was supported in part by Danish Agency for
Science, Technology and Innovation grant 274-08-0280.
Authors’ addresses: D. W. McClary, V. R. Syrotiuk, School of Computing, Informatics and Decision Systems Engineering, Arizona State University, P. O. Box 878809, Tempe, AZ 85287-8809;
email: {Daniel.McClary, syrotiuk}@asu.edu; M. Kulahci, DTU Informatics, Richard Petersens
Plads, building 321, DK-2800 Lyngby, Denmark; email: mk@imm.dtu.dk
Permission to make digital or hard copies of part or all of this work for personal or classroom use
is granted without fee provided that copies are not made or distributed for profit or commercial
advantage and that copies show this notice on the first page or initial screen of a display along
with the full citation. Copyrights for components of this work owned by others than ACM must be
honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers,
to redistribute to lists, or to use any component of this work in other works requires prior specific
permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn
Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org.

C 2010 ACM 1049-3301/2010/09-ART17 $10.00
DOI 10.1145/1842713.1842720 http://doi.acm.org/10.1145/1842713.1842720
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17

17:2

•

D. W. McClary et al.

1. INTRODUCTION
Dynamic systems present challenges for both modeling and optimization. Often
the dynamics of a system cause it to exhibit nonlinear behavior when examined
over a wide range of operating conditions. There are few strategies available
for modeling such behavior and optimizing such systems as they run. In particular, a model characterizing a system and an optimization of it for one set of
conditions is unlikely to characterize the system and optimize it over the full
range of its operating conditions [Wolpert and Macready 1997].
Regression analysis is one method for generating an approximate model for a
system with a level of statistical certainty. It provides a collection of statistical
techniques to develop numerical models relating one or more responses (or
output variables) to a set of factors (or input variables). Statistical optimization
of systems, however, often assumes that models are accurately approximated
by low-order polynomials. Response surface methodology (RSM), for example,
is adept at building a polynomial model and finding an approximate optimum
[Myers and Montgomery 2002]. The focus of RSM is on the analysis of variance
(ANOVA) and the development of linear models via ordinary least-squares; the
reliance on such models is often unsuitable for modeling nonlinear systems.
Nonlinear regression analysis is the preferred approach for developing regression models of nonlinear systems [Bates and Watts 1988]. The minimization of least-squares is an iterative process in nonlinear regression. It requires
both a model form and an initial vector of coefficients to be given a priori;
convergence in the minimization process is not guaranteed if there is a problem in either of these choices. Techniques for the optimization of nonlinear
systems include numerical methods for problems involving nondifferentiable
functions, semidefinite programming, metric regularity, and stability theory
of set-constrained systems [Ruszczynski 2006]. Nonlinear regression analysis
and nonlinear optimization increases in difficulty with the number of factors
in the system.
In this article, we develop profile-driven regression as a modeling approach
for nonlinear systems with a large number of factors. As the name indicates,
our approach uses a long-standing exploratory technique in nonlinear modeling
called profiling [Bates and Watts 1988]. At a high level of abstraction, profiledriven regression consists of four steps. It is first used to characterize the
effect of each factor and two-way interactions between factors on a response.
Secondly, an intermediate model is fit to each profile. Thirdly, an overall model
of the response is fit in terms of all the factors. Finally, an analysis of the fit of
the overall model is conducted.
The factors in any system are often divided into two categories: controllable
and uncontrollable. Therefore another goal is to generate intermediate models
for controllable factors in terms of uncontrollable ones such that the system can
optimize at runtime. In runtime optimization, a system measures the uncontrollable factors and uses the measurements to update the controllable factors
to optimize the response for the current operating conditions.
The dynamic system considered in this article is a mobile ad hoc network
(MANET). A MANET is a collection of mobile wireless nodes that self-organize
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

Profile-Driven Regression for Modeling and Runtime Optimization

•

17:3

without the aid of any fixed infrastructure or centralized control. As we demonstrate in short order, the factors that influence the achievable throughput in
a MANET differ dramatically in their contribution as a function of the node
speed. Such differences are indicative of a nonlinear system.
We apply profile-driven regression for modeling and runtime optimization
of throughput in a simulated MANET. The intermediate models generated
are used to fit an overall model of throughput. Unlike others, the resulting
throughput model accounts for node speed. The intermediate models are used
locally by each node to optimize controllable factors at runtime in terms of its
measured node speed. This results in throughput as much as six times higher
than that achieved with the factors at their default levels; the default levels
are optimized for a specific set of operating conditions.
The rest of this article is organized as follows. Section 2 presents results illustrating the nonlinear behavior of throughput in a MANET with respect to node
speed. Section 3 develops profile-driven regression together with an example.
Section 4 applies profile-driven regression to modeling and runtime optimization of throughput in a MANET. In Section 5, we provide a brief overview of the
work in statistics central to profile-driven regression as well as relevant work
in modeling, optimization, and adaptation in MANETs. Section 6 summarizes
our contributions and concludes.
2. MOTIVATION
Consider a MANET architecture in which the application transmits constant
bit rate (CBR) flows between sources and destinations, using the user datagram
protocol (UDP) at the transport layer, the ad hoc on-demand distance vector
(AODV) routing protocol at the network layer [Perkins and Royer 1999], the
IEEE 802.11b protocol at the medium access control (MAC) sublayer [802.11
1999], running over an 11 Mbps channel. (See Section 2.1 for futher details.)
A screening experiment [Montgomery 2005] is conducted in order to quantify the factors and interactions most influential on the response of average
throughput. While there are hundreds of potential factors, we restrict our attention to ten to bound the study; the selection is based on earlier work [Mullen
et al. 2004; Vadde and Syrotiuk 2004a, 2004b, Vadde et al. 2006]. The factors include six AODV timer values, two retry counters from IEEE 802.11b, data rate,
and node speed. The factors and their levels are shown in Table I. (The recommended default value for each timer and retry counter is given in Chatzmisios
et al. [2002] and Perkins and Belding-Royer [2003] and is used to find a suitable
range for experimentation.)
Analysis of variance (ANOVA), introduced in Fisher [1921], may be used to
determine the percentage contribution each factor and interaction term makes
to the measured response. Table II shows the significant factors and pairwise
interactions affecting average throughput in a simulated MANET, using the
variable names corresponding to the factors in Table I. The contributions are
quite different at each of the three node speeds.
At 1 m/s, throughput is dominated by a node’s data rate while other terms
contribute an insignificant amount. At higher node speeds, the role of data
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:4

•

D. W. McClary et al.
Table I. Factors and Their Levels for the Screening Experiments
Factor

Min

MY ROUTE TIMEOUT
ACTIVE ROUTE TIMEOUT
MAX RREQ TIMEOUT
RREQ RETRIES
REV ROUTE LIFE
BCAST ID SAVE
Short Retry Limit
Long Retry Limit
Data Rate
Mean Node Speed

Levels
Default

Max

6
10 ≡ 100 s
14
6
10 ≡ 50 s
14
6
10 ≡ 10 s
14
1
3 retries
5
2
6 ≡ 5s
10
2
6 ≡ 3s
10
5
7 retries
9
2
4 retries
6
0.33
1 pkt/s
1.66
1, 5, 10, 15, 20, 25 m/s

Variable Name
A
B
C
D
E
F
G
H
J
K

Table II. Factors and Pairwise Interactions Affecting Average Throughput

Term
J

(a) At 1 m/s
Sum of
Squares
%
47.45
95.25%

(b) At 15 m/s
Sum of
Term
Squares
%
C
4.86
9.56%
F
1.4
2.75%
H
1.24
2.45%
J
0.91
1.8%
AB
4.67
9.18%
AE
8.53
16.77%
AF
1.76
3.46%
BF
1.71
3.35%
BG
8.57
16.84%
CD
1.28
2.52%
DE
1.3
2.55%
DF
1.69
3.32%

(c) At 25 m/s
Sum of
Term
Squares
%
C
1.1
2%
J
46
83.8%

rate diminishes significantly. Instead, the system is influenced by pairwise
interactions of timers in AODV and retry counters of IEEE 802.11b. At 25 m/s,
throughput is dominated once again by data rate and also the value of the
MAX RREQ TIMEOUT (C). These results make intuitive sense: as the nodes
move faster, their relative positions change more quickly, causing more frequent
link failures that, in turn, cause route reconfiguration. As speeds increase,
timers governing expected route longevity are likely to be more significant. At
even higher speeds, node positions may change so rapidly that these timers
may become insignificant compared to the frequency of route breakage.
This substantial change in the terms contributing to a response is indicative
of a nonlinear or discontinuous system. Importantly, the terms contributing
significantly to the response at any given node speed are not necessarily significant at the others. Such a system cannot be optimized offline by designing
for a single node speed or a worst-case set of conditions [Wolpert and Macready
1997]. In order to model and optimize over a wide range of conditions, we must
capture the nonlinearity of the system. In Section 3 we develop profile-driven
regression for this purpose and then return to this problem as an application
of the approach.
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

Profile-Driven Regression for Modeling and Runtime Optimization

•

17:5

Fig. 1. An example of node distribution used in a trial of a screening experiment.

2.1 Screening Experiments
In the previous section we presented the results of our screening experiments.
The goal of screening is to “sift” through the factors using as few experiments as
possible to identify the significant factors and interaction terms for modeling
and optimization. Screening is the initial phase of any experimental effort
and can reduce the experimental cost associated with running and analyzing
experiments substantially. Because profiling over a large number of factors is
costly, screening plays a key role in our approach. Next, we provide details of
the screening experiments used to produce the results in Table II.
We perform a screening experiment at the node speeds of
1, 5, 10, 15, 20, and 25 m/s. This corresponds to a range of speeds, from
walking (1 m/s = 3.6 kph) to driving (25 m/s = 90 kph), representative of the
mobility in most ad hoc networking scenarios. Our screening experiments
are conducted using fractional factorial and D-optimal designs to limit the
number of trials. These designs examine the ten factors in a minimum number
of runs, identifying significant main effects and pairwise interactions. Average
throughput (t) measured in Kbps is selected as the response.
For each trial, 50 nodes are placed randomly in an area of 1000 m × 1000 m
with one sender and one receiver. Node positions are selected at random from a
normal distribution centered at (500, 500). Figure 1 illustrates an example node
distribution. Node mobility follows the steady-state random waypoint model
[Navidi et al. 2004]. This models the movement of individual nodes rather than
groups of nodes. The radio transmission range is 250 m, using a two-ray ground
propagation model and a channel rate of 11 Mbps. Each trial is simulated using
the ns-2 [ns-2 1995] network simulator and we perform our statistical analyses using both Design Expert [Stat Ease 1988] and the statistical language R
[R Project for Statistical Computing 1997]. All trials in the screening
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:6

•

D. W. McClary et al.
Table III. Other Simulation Parameters
Simulation Parameter
Interface queue
Interface queue length
Antenna model
802.11b bandwidth
802.11b minimum contention window size
802.11b maximum contention window size
802.11b slot time
802.11b preamble length
Node traffic type
UDP packet size

Value
DropFront priority queue
30 packets
Omnidirectional
11 Mb/s
32
1024
20 μs
144 bits
Constant bit rate (CBR)
320 bytes

experiments are conducted for 500 s of simulated time. Other simulation parameters are given in Table III and all remaining parameters are set to their
default values in ns-2.
2.1.1 Sources of Random Noise. While ns-2 is a discrete-event simulator,
there are points at which randomness is introduced to mimic measurement
error. The mobility patterns of nodes in our study are given both a mean speed,
as well as a variance of 1 m/s. Thus, node speeds fluctuate and vary from trial
to trial. Moreover, the ns-2 simulator induces randomness in events via a seed
value. In our trials, seed values are selected from a normally distributed set
of 232 − 2 integer values. These values seed the random number generator
MRG32k3a [L’Ecuyer 1999] used in ns-2. The generator provides normally, independently distributed random values between zero and one to the scheduling
of AODV broadcast transmissions, the backoff behavior of IEEE 802.11b, and
the underlying radio model. The variance in node speed and the use of random
seeds introduce a degree of noise suitable for regression modeling.
3. PROFILE-DRIVEN REGRESSION
Profile-driven regression is a complete modeling approach for nonlinear systems. The core of profile-driven regression is the method of profiling [Bates and
Watts 1988]. Traditionally, when modeling highly nonlinear systems (particularly those with a large number of factors) profiling is used to deduce information about factor behavior. In a profiling study, several values of one factor
are plotted against the response, or a chosen statistical measurement, while
all other factors are kept fixed. Repeating this process at different levels of the
fixed factors builds profiles that help characterize factor behavior over various
conditions. Creating profiles for each factor in the system builds a sizeable body
of data from which we can draw conclusions about the behavior of the system.
For a system with k independent variables, the dependent variable y =
f (x1 , x2 , . . . , xk) +  is modeled using a function f that relates the xi to y. The
term  represents noise; this includes the effects of all extraneous factors that
are not included in the model. Profile-driven regression consists of the following
four-step approach.
(1) Data Collection. Data is collected from the system through experiments.
These experiments are carefully designed so that profiles of the response y
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

Profile-Driven Regression for Modeling and Runtime Optimization

•

17:7

Fig. 2. The response surface for y as a function of x1 and x2 .

are obtained for each xi when the other x j , j = i, are at fixed levels. Thus,
two-dimensional plots of these profiles are generated for y against each xi .
(2) Modeling the Factors. Starting with one xi , a model is fit to each profile with
the other independent variables at fixed levels. This provides estimates
of the model parameters that can be modeled in terms of the remaining
independent variables using the same strategy.
(3) Fitting an Overall Model. When the last set of parameters is modeled in
the last independent variable, an overall model is obtained in terms of all
independent variables. The model may be used as the starting point in an
overall nonlinear model fitting effort, with the parameter estimates used
as starting values.
(4) Analysis of Fit. The overall model is validated through residual analysis and
spot-checks performed within the experimental region (interpolation) or
outside of the original ranges of the independent variables (extrapolation).
3.1 An Example of Profile-Driven Regression
We now step through an example of profile-driven regression. Consider a system with two independent variables and assume that a set of designed experiments results in the apparently nonlinear response surface in Figure 2.
To apply our profile-driven regression approach, we first obtain the profiles
for each independent variable from the data collection step. The plots of y versus
x1 and y versus x2 are shown in Figures 3(a) and 3(b), respectively. As the figures
show, we evaluate the response at five different settings of each input variable;
hence a 52 factorial design is used at this stage of the experimentation.
We choose to first model x1 because the profiles in Figure 3(b) appear more
likely to reflect nonlinear behavior and may prove more challenging to model.
In the modeling step, a second-order linear model is used for the profiles in
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:8

•

D. W. McClary et al.
Profile of y v. x1

Profile of y v. x2

110

110

x2=-2
x2=0.5
x2=3
x2=5.5
x2=8

100

x1=-5
x1=-2.5
x1=0
x1=2.5
x1=5

100

90

90

80

80

y

70

y

70
60

60

50

50

40

40

30

30

20

-2

0

4

2

6

8

20

-6

-4

x1

-2

0

2

4

6

x2
(b) profile of y versus x2

(a) profile of y versus x1

Fig. 3. A profile for each independent variable.
Table IV. Coefficient Estimates for
β0,1 , β1,1 , and β2,1 for Levels of x2
x2
−0.50
−0.25
0.00
0.25
0.50

β0,1
−0.43
0.23
−0.58
−0.84
0.03

β1,1
5.29
4.71
2.80
0.14
0.26

β2,1
1.22
1.01
1.21
1.49
1.10

Figure 3(a). x1 is selected to model the response using
ŷ = β0,1 + β1,1 x1 + β2,1 x12
for each level of x2 . These models result in estimates of β1,1 , and β2,1 with 95%
significance for various levels of x2 . The estimates of the coefficients are given
in Table IV. In the table, entries in italics are insignificant; all observations for
β0,1 are insignificant, and significant estimates are obtained for β1,1 in three of
the five levels of x2 .
Because all of the observations for β0,1 are insignificant, we do not model
it further and set β0,1 equal to 0. It may be helpful to reestimate significant
parameters once β0,1 is set equal to 0. In the case of this example, however, an
accurate model is found without reestimation. The remaining coefficients are
now modeled in terms of the remaining independent variables (here x2 ) using
the same strategy. We write β1,1 and β2,1 in terms of x2 and modify the equation
as
ŷ = β1,1 (x2 )x1 + β2,1 (x2 )x12 .
Figures 4(a) and 4(b) plot β1,1 and β2,1 as a function of x2 . Fitting a model to
β2,1 is straightforward because a constant model suffices. Since it is within a
95% confidence interval for each of the observed values of β2,1 , we choose
β2,1 = 1
which simplifies the approximation as
ŷ = β1,1 (x2 )x1 + x12 .
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

•

Profile-Driven Regression for Modeling and Runtime Optimization
Plot of B2v. x2

Plot of B1v. x2

6

17:9

1.5

B1

B2

1.45

5

1.4
1.35

4
B2

B1

1.3
3

1.25
1.2

2

1.15
1.1

1

1.05
0
-0.6

-0.4

-0.2

0
x2

0.2

0.4

1
-0.6

0.6

-0.4

(a) plot of β1, 1 versus x2
6

-0.2

0
x2

0.2

0.4

0.6

(b) plot of β2, 1 versus x2
Comparison of Model Fits With B1 v.2x
B1 v. x2
Nonlinear Fit
Linear Fit

5
4

B1

3
2
1
0
-1
-0.6

-0.4

-0.2

0
x2

0.2

0.4

0.6

(c) plots of nonlinear and linear fits for β1, 1

Fig. 4. Plots of β1,1 , β2,1 versus x2 . β2,1 appears constant, while β1,1 indicates a potentially nonlinear effect.

Modeling β1,1 however, requires either a polynomial expansion or a nonlinear
model fitting. Figure 4(c) shows both a linear and a nonlinear fit to β1,1 . The
1
plot of β1,1 resembles a “logistic curve” of the form a+b
cx [Daniel and Wood
1
1999]. We choose to fit a type of logistic curve of the form a+b
x because it
approximates the curve relatively well in the sampled region. Attempting to
fit an overparameterized function form may lead to nonconverging results in
1
a nonlinear regression. In this case, had we attempted to fit a+b
cx separate
1
estimates of b and c would be unattainable. However, the chosen form a+b
x does
converge. Replacing β1,1 with this model yields the final approximate model
ŷpdr =

1
x1 + x12
1.8 + (2.6 × 106 )x2

(Profile-Driven Regression)

(1)

which is plotted in Figure 5(b). For reference, the function y is repeated in
Figure 5(a). The resulting model is nonlinear because a nonlinear model was
used in modeling β1,1 . The resulting model would be a polynomial if at each
stage of modeling the factors only polynomials were employed.
As in any modeling effort, we must examine the residuals and fitted values for the model obtained using profile-driven regression. These are given in
Figures 6(a) and 6(b), respectively. Though the limited number of unique data
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:10

•

D. W. McClary et al.

Fig. 5. A comparison of the function y to the fit derived through profile-driven regression ŷpdr .

Fig. 6. The residual and actual values, respectively, versus the fitted values for profile-driven
regression.

points make it difficult to determine the normality of the residuals, Figures 6(a)
and 6(b) suggest that a majority of the signal is recovered by the approximation.
While profile-driven regression recovers much of the signal from the actual
function, it could be argued that this could also be accomplished via polynomial
expansion using x1 and x2 . In Appendix A.1 we fit the example function using a
Taylor series expansion with back-elimination and compare it to the fit obtained
by profile-driven regression. As shown in Appendix A.1, a considerably better
fit is obtained using the proposed approach compared to the polynomial model.
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

Profile-Driven Regression for Modeling and Runtime Optimization

•

17:11

4. APPLICATION OF PROFILE-DRIVEN REGRESSION TO MANETS
Profile-driven regression provides an approach for modeling systems that are
nonlinear. Moreover, the intermediate models produced in step 2 of the approach can be leveraged to perform optimization of the system during its
operation. Unlike traditional offline optimization, in runtime optimization a
system measures the uncontrollable factors and uses the measurements to update controllable factors to optimize the response for the measured operating
conditions.
Consider the example function from the previous section. Suppose that x1 is
a factor that is both measurable and controllable, while x2 is a factor that is
measurable but uncontrollable. If the system in question is to remain centered
around some target value and is subject to rapid changes in x2 , then x1 must be
modified for the system to remain on target. In the example, the intermediate
models of the effect of x2 on β1,1 can be used to choose appropriate settings for
x1 .
The model-building process of profile-driven regression is an offline process. If the intermediate models are to be used for runtime optimization, the
approach should model controllable factors in terms of factors that are uncontrollable but measurable. The intermediate models may then be used during
system operation in conjunction with measurements of the uncontrollable factors, to optimize the response online or at runtime.
The remainder of this section applies profile-driven regression to modeling
and runtime optimization of throughput of the simulated MANET described
in Section 2. We present the results of our profiling experiments and the offline model-building process. In the final iteration of the modeling effort, we
construct intermediate models in terms of node speed, an uncontrollable factor
because each node in a MANET is autonomous; that is, a node can control
its own speed, but not that of other nodes. This allows us to implement and
evaluate a runtime optimization. Unless otherwise noted, the parameters of
the trials are identical to those described in Section 2.1.
4.1 Profiling Results
Using the ANOVA results from the screening experiments in Section 2, we
identify factors to profile and incorporate into the model. Table V presents the
results of ANOVA for average throughput at 15 m/s. Only the significant pairwise interaction terms are presented. Notably, these are pairwise interactions
between AODV timers and retry counters of IEEE 802.11. A comparison of
Tables V and II reveal that the factors significant at 15 m/s are quite different
from those at 1 m/s and 25 m/s, which are dominated by data rate.
The first step in profile-driven regression is data collection for profiling the
significant factors. For each factor that is significant at one or more speeds, we
generate profiling data and use it to construct two-dimensional profile plots for
each factor.
Our objective is to maximize average throughput t, thus we create profiles for the factors affecting t. Figure 7(a) illustrates the effect of node speed
on t. Node speed appears to affect t in a manner that may be modelled as
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:12

•

D. W. McClary et al.
Table V. ANOVA for Throughput at 15 m/s Provides Candidate Factors
for the Profiling Process
Source
Model
A
B
C
D
E
F
G
H
J
AB
AE
BG
Curvature
Residual
Lack of Fit
Pure Error
Cor Total

Sum of
Squares
39.96
0.33
0.08
4.86
0.08
0.2
1.4
0.2
1.24
0.91
4.67
8.53
8.57
2.18
8.72
4.2
4.52
50.86

Degrees of
Freedom
19
1
1
1
1
1
1
1
1
1
1
1
1
1
15
12
3
35

Mean
Square
2.1
0.33
0.08
4.86
0.08
0.2
1.4
0.2
1.24
0.91
4.67
8.53
8.57
2.18
0.58
0.35
1.51

F
Value
3.62
0.57
0.13
8.36
0.14
0.34
2.4
0.34
2.14
1.57
8.02
14.66
14.73
3.75
0.23

Prob > F
0.0074
0.46
0.72
0.011
0.71
0.57
0.14
0.57
0.16
0.23
0.012
0.0001
0.0016
0.07
0.97

Significant Terms are Indicated in Bold.

either a second-order polynomial, or perhaps as exponential decay. Figure 7(b)
shows the effect of data rate on t at various node speeds and is very similar to
Figure 7(a). Figure 7(c) captures the effect of node speed on the coefficient values of multiple pairwise interactions contributing to t; it is interesting that
these manifest only at certain node speeds.
4.2 Building the Model Offline: Profile-Driven Regression
In step one of profile-driven regression, we profile the effect of node speed on the
default parameter values for AODV and IEEE 802.11b. Selected profiles and
effect plots are illustrated in Figure 7. In step two, we construct an approximate
model of the changes to the system as a function of node speed. To cope with
the large number of factors we model several linear factors at a time; see
A.2 of the Appendix for details on partitioning factors. Specifically, the factors
are partitioned into L = {A, B, C, D, E, F, G, J} and N = {K} to represent the
factors with seemingly linear effects on the response and the one with the
nonlinear effect, respectively. Because factor H, the IEEE 802.11b Long Retry
Limit, is neither significant nor involved in significant interactions, we exclude
it.
The order in which factors are incorporated into the model determines the
intermediate models generated. As such this ordering also affects the usefulness of the intermediate models for runtime optimization. For the purpose of
controlling factors, our intermediate models are most useful when they express
controllable factors in terms of measurable, uncontrollable factors. For example, node speed is not a controllable factor in MANETs, but it is measurable.
Adjusting factors to node speed is more logical than adjusting node speed to
any other factor, so node speed is ordered last in the model-building process.
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

Profile-Driven Regression for Modeling and Runtime Optimization

Intercept

Speed = 10
Speed = 15

1.84
Throughput (kbps)

1.82
1.8

Intercept

17:13

Profile of Data Rate v. Throughput at Various Node Speeds
3.5
Speed = 5

Node Speed v. Throughput Intercept
1.86

•

1.78
1.76
1.74
1.72

3
2.5
2
1.5

1.7
1.68

1

1.66
1.64

0

5

10

15
Speed (m/s)

20

25

0.5
0.2

(a) effect of node speed on intercept

0.4

0.6

1
1.2 1.4
Data Rate (kbps)

1.6

1.8

2

(b) effect of data rate on throughput

Node Speed v. Interaction Coefficents

0.6

AB
AE
AF
BD
BF
BG
CD
CE
DE
DF

0.4
Interaction Coefficients

0.8

0.2
0
-0.2
-0.4
-0.6

0

5

15
10
Speed (m/s)

20

25

(c) effect of node speed on AODV timer interaction coefficients

Fig. 7. Plots illustrating the effect of node speed on throughput, and the effect of node speed on
AODV timer interactions affecting throughout. Each timer interaction coefficient appears to take
on three specific values.

The intermediate models of the factors are as follows.
A = −0.1δ K
B = −0.49δ K
C = 0.108
D = −0.51δ K
E = −0.79δ K
F = −0.21δ K
G = 0.08δ K
J = ωK
The overall model for average throughput t is given in Eq. (2) and agrees well
with the majority of our spot checks. Figure 8 is a three-dimensional projection
of the model in Eq. (2). Since only node speed and data rate appear in the model
at all node speeds, these are chosen as axes, with the remaining factors held
at their default values. The terms δ and ω are used in Eq. (2) to represent the
distinct changes in significant terms at different speeds evident in Figure 7(c).
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:14

•

D. W. McClary et al.

Fig. 8. The approximate profile-driven regression model for throughput as projected on data rate
and speed.

Eqs. (3) and (4) give δ and ω as step functions, respectively.
t = 1.833 − 0.008K + Jω − 0.1Aδ − 0.049Bδ + 0.108C − 0.06CK
+ 0.002CK 2 − 0.51Dδ − 0.79Eδ − 0.21Fδ + 0.08Gδ + 0.38ABδ

(2)

− 0.51AEδ + 0.23AFδ + 0.13BDδ + 0.23BFδ + 0.51BGδ − 0.2C Dδ
+ 0.14C Eδ − 0.2DEδ + 0.23DFδ

δ =

1 if 10 m/s < K < 20 m/s
0 otherwise

⎧
⎨ −1.22 if K ≤ 10 m/s
−0.18 if 10 m/s < K < 20 m/s
ω =
⎩
−1.23 if K ≥ 20 m/s

(3)

(4)

4.3 Using the Model Online: Runtime Optimization
Following our spot checks, we are able to deploy the model for use at runtime.
In order to maximize average throughput t over the course of the simulation,
we utilize the intermediate models obtained in step two of the approach. Most
of these equations model the factor as a function of node speed, some of which
are visualized in Figure 9. Each equation provides a factor level for a measured
node speed, allowing each node to update its AODV timers and IEEE 802.11b
retry counter limits according to its measured node speed.
We compare the runtime optimization with the throughput obtained using
the default parameter values for AODV and IEEE 802.11. The default parameters are given in Table I and are the recommended values for each protocol
[Chatzmisios et al. 2002; Perkins and Belding-Royer 2003].
We employ the same simulation setup as in Section 2 except that data rates
for the runtime optimization are scaled in accordance with the model for J.
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

•

Profile-Driven Regression for Modeling and Runtime Optimization

17:15

AODV parameter values as a function of Node Speed
14

MY ROUTE TIMEOUT
REV ROUTE TIMEOUT
ACTIVE ROUTE TIMEOUT
BCAST ID SAVE

Parameter value

12
10
8
6
4
2
0

0

2

4

6

8
Speed (m/s)

10

12

14

Fig. 9. Scaling of selected AODV timers as a function of node speed.
Table VI. Improvement in t Using Runtime Optimization
Speed (m/s)
1
5
10
15
20
25
5–25
0–30

Using Default Parameters
Throughput (Kbps)
1.012527
1.038267
1.050077
1.118547
1.136227
1.099207
1.109597
1.026467

Using Runtime Optimization
Throughput (Kbps)
1.016407
1.101317
2.159957
1.248777
4.408777
5.525027
5.451104
6.464037

Improvement
Ratio
1.003000
1.060726
2.056951
1.116428
3.880191
5.026376
4.912689
6.297366

Twenty simulations are conducted at each of the speeds 1, 5, 10, 15, 20, and
25 m/s, with a 1 m/s variation in speed over the course of the simulation. This
allows us to evaluate the quality of the runtime optimization. We also conduct
twenty simulations where the node speed is allowed to vary over a much wider
range: between 5–25 m/s and 1–30 m/s.
Table VI catalogs average throughput measures for both the default parameter set and our runtime optimization. The performance improvement is very
good (up to a six times improvement), and in all cases the 95% confidence interval on the values in Table VI is approximately ±5.6 × 10−5 . Such a small
confidence interval suggests a statistically significant improvement.
At 1 m/s, 5 m/s, and 15 m/s, the runtime optimization is not better than the
default configuration. In Figure 7(c) the influence of pairwise interactions begins after 5 m/s and has established itself by 10 m/s. Similarly, the significance
of pairwise interactions is present at 15 m/s, but has diminished at 20 m/s.
Given the limited number of node speeds sampled, the precise way in which
these interactions come to bear on throughput is not understood completely.
Indeed, without experiments of a finer granularity and further refinement of
the model, variation at these transitionary points is to be expected.
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:16

•

D. W. McClary et al.

4.4 Discussion
One aim of the profiling process is to order the factors for the regression from
least to most nonlinear, or least to most difficult to model. However, profiles
need not serve as the basis for choosing the ordering in which each xi is modeled.
Cumulative energy of components [Jolliffe 1986] in ascending or descending order, for example, may serve as a useful ordering for the xi . As in our application,
when specific relationships are desired in the intermediate models, these needs
should drive the ordering.
While effective, the profile-driven regression approach presented and the
approximate model it generates raise questions of both robustness and accuracy. Indeed, a pertinent question is in what way incorrectly chosen functional
forms affect the resultant model. Generally, if the form chosen for a given profile is incorrect, overall model performance suffers outside the experimental
region. Thus, we cannot emphasize strongly enough the importance of both
interpolative and extrapolative “spot checks.” The model is only an estimation
of the actual nonlinear system. Whenever profiling can find an appropriate
functional form, traditional nonlinear regression modeling techniques should
be used.
While the benefits of profile-driven regression for modeling nonlinear systems are many, the potentially large number of experiments is a cost. As a
result, the approach is most appropriate for systems that can be simulated or
for those in which experimentation is not expensive. Alternatively, partitioning may be used to reduce the number of experiments. Perhaps more important
than the accuracy of the approximate model is the trade-off between accuracy
and robustness in regression modeling. Higher accuracy in the fit within the
experimental region can be obtained by adding more terms to the model (overfitting). This, however, often leads to poor predictive properties outside the
experimental region.
Profile-driven regression makes use of statistically designed experiments.
As such, there are certain requirements for the designs that should be met.
First, as with most statistically designed experiments, the designs must be
translatable from engineering units to a set of symbols (or coded units or levels)
that allow computation of linear contrasts. Secondly, the designs should have
pairwise coverage. Thirdly, for factors that are suspected to be nonlinear or
polynomials with curvature, the design should provide at least three levels for
the columns representing these factors. Indeed, more than three levels may be
desired to ease in choosing function forms from profiles.
Profile-driven regression relies on two-dimensional projections of the nonlinear function at combinations of the factors. One obvious effect of these projections is that the effect of interactions with other factors are aggregated
into estimations of the function defining the projection. However, the repeated
fitting of coefficient symbols in terms of subsequent projections deaggregates
these interaction effects.
For the purpose of approximating a robust model of the MANET system
under study, we opt for a less accurate model to guard against brittleness in
the predictive ability. For situations in which certain factors are significant but
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

Profile-Driven Regression for Modeling and Runtime Optimization

•

17:17

adaptation is difficult or even impossible, a robust parameter design [Myers and
Montgomery 2002] study can be conducted to improve the model generated by
our approach. Similarly, in the case that a more accurate model is desired for
a limited set of conditions, a standard nonlinear least-squares process can be
applied to the model produced by our approach. These, paired with a monitoring
process such as statistical process control [Montgomery 2004] to monitor the
performance of the model, can allow robust approximate models to provide
significant optimization over large regions.
5. RELATED WORK
Profile-driven regression alleviates some of the challenges in nonlinear regression modeling. Nonlinear regression modeling is a well-established field,
and much work has been done in developing strategies for handling nonlinear
systems. The classic text by Bates and Watts [1988] provides an excellent introduction to the field. Similarly Daniel and Wood [1999] examine computational
methods for fitting nonlinear models. Profile-driven regression also relies on
formal statistical design of experiments (DOE). Montgomery [2005] provides
a thorough introduction to the field, while Box and Lucas [1959] examine designs for nonlinear systems. DOE is a useful tool for the performance analysis
of computer systems, with Jain [1991] providing a well-known text.
Traditional nonlinear regression techniques and DOE provide a time-tested
means of modeling and optimizing systems. However, some nonlinear systems
continue to present significant challenges. When the nonlinear aspects of a system are not identified as known function forms, considerable difficulty emerges
in choosing initial modeling parameters. In 1962, Box and Hunter [1962] introduce a model-building technique for systems with basic theoretical models. The
method provides experimenters a way to determine how to “force” a model to
fit a system using pre-existing domain knowledge. Profiling [Bates and Watts
1988] allows an experimenter to construct several restricted plots of the functions in a system so as to better understand its nonlinearity and interactions.
Profile-driven regression uses profiling, providing an approach for classifying
and approximating nonlinearity when incomplete knowledge about a system’s
mechanisms and interactions is available.
Network optimization is not a new problem, and the approaches taken are
myriad. Linear programming is perhaps the best studied (see Pióro and Medhi
[2004] for a summary). Linear programming optimizations have applications in
MANETs as well, such as the resource optimizations for TDMA networks studied by Bjorklund et al. [2003]. Much has been done with respect to optimizing
AODV and IEEE 802.11 individually [Boroni et al. 2004; Zhong et al. 2003]. Response surface methodology (RSM)-based optimizations for MANETs at fixed
speeds have been conducted by Vadde et al. [2006] and Mullen et al. [2004].
Mullen et al. focuses on RSM optimization of route request and reply messages,
while Vadde et al. considers AODV routing timer and MAC retransmission parameters. Recent applications of nonlinear optimization strategies in MANETs
have been broadly applied. Doherty et al. [2001] and Biwas and Ye [2004]
apply semidefinite programming to localization problems in ad hoc sensor
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:18

•

D. W. McClary et al.

networks. Srinivasan et al. [2004] optimize sending rates with respect to network lifetime utilizing penalty functions derived from nonlinear programming
problems. Yuste et al. [2007] apply a genetic algorithm to improve gateway
discovery in hybrid MANETs.
Runtime optimization could be viewed as a form of adaptation. There has
been much work on adaptation in MANET protocols. The simplest of these is
threshold-based adaptation, as in the work of Singh et al. [1998] on the adaptive, power-aware MAC protocol PAMAS. Table-lookup algorithms have proved
popular, particularly in routing. The SSA routing protocol developed by Dube
et al. [1997] is an example of such a method. More recently, machine learning
techniques have been applied to the adaptation problem. Faragó et al. [2000]
apply machine learning in their meta-MAC scheme, that adaptively chooses optimal MAC-layer policies. Colagrosso [2005] employs classification algorithms
to adapt broadcast policies in MANETs, while Benaissa et al. [2004] utilize decision tree learning to adaptively improve voice transmissions over MANETs.
Recently Moursy et al. [2008] explore runtime optimization of MANET routing
protocols using a combination of linear regression models and artificial neural
networks.
6. CONCLUSIONS AND FUTURE WORK
This article introduces profile-driven regression, a general approach for alleviating traditional problems in modeling nonlinear systems, such as may arise
in a dynamic system. Built upon profiling, profile-driven regression allows for
characterization of the system for which a functional form and initial coefficient vector are unavailable. The resulting approximate model provides a
suitable starting point for a traditional nonlinear regression study. Moreover,
the intermediate models generated can be applied to optimize the system at
runtime.
As an application of profile-driven regression, we model and optimize at
runtime the average throughput in a simulated MANET. We find that node
speed is a nonlinear factor that significantly impacts AODV soft-state timer
values, IEEE 802.11b retry counter limits, and data rate and account for it in
the model. The resulting optimization is very effective; locally optimizing the
network factors at runtime results in throughput as much as six times higher
than that achieved with the factors at their default levels.
It should be noted that the model obtained in this work applies to the simulated MANET described in our experimental methodology. The model presented
here validates the efficacy of our approach and perhaps sheds light on the role
of factor interactions at certain speeds. However, it should not be taken as accurate for real-world deployments of MANETs. If experimental costs permit,
profile-driven regression can be employed to real-world deployments to build
an accurate model.
While the runtime optimization realized by the approximate model is excellent, questions of robustness, assessment, and monitoring of profile-driven
regression models remain. Future work seeks to provide methods for improving model robustness, exploring experimental designs for reducing the number
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

Profile-Driven Regression for Modeling and Runtime Optimization

•

17:19

Table VII. Data Collected from
the Example Surface Using a 52
Factorial Experimental Design
X1
−2
−1 −
0
1
2
−2 −
−1
0
1
2
−2 −
−1
0
1
2
−2
−1
0
1
2
−2
−1
0
1
2

X2
−0.50
0.25
0.00
0.25
0.50
0.50
−0.25
0.00
0.25
0.50
0.50
−0.25
0.00
0.25
0.50
−0.50
−0.25
0.00
0.25
0.50
−0.50
−0.25
0.00
0.25
0.50

Y
2.00063226
0.01747209
0.00000000
1.01747209
4.00063226
2.00063226
0.01747209
0.00000000
1.01747209
4.00063226
2.00063226
0.01747209
0.00000000
1.01747209
4.00063226
2.00063226
0.01747209
0.00000000
1.01747209
4.00063226
2.00063226
0.01747209
0.00000000
1.01747209
4.00063226

of offline experiments, assessing model quality, and monitoring and adapting
runtime optimization via statistical process control methods.
APPENDIX
A.1 Taylor Series Approximation
To illustrate the ineffectiveness of polynomial expansion, we fit a fifth-order
polynomial to data collected from sampling the surface according to a 52 factorial design and back-eliminate insignificant terms, yielding the following
second-order model.
ŷpe = −0.3779 + 2.6394x1 + 0.1360x2
−5.8548x1 x2 +

1.2061x12

+

0.4800x22

(5)
(Polynomial Expansion)

Notably, the polynomial model includes more terms than does the profile-driven
regression approximation. The data used to fit Eq. (5) is given in Table VII.
The function y and the polynomial expansion approximation of y is given in
Figure 10. The residuals and fitted values for the model obtained using polynomial expansion are shown in Figures 11(a) and 11(b), respectively. Perhaps
more signficantly, a comparison of the residuals in Figures 6(a) and 11(a) illustrates that the observed values of y are fit more closely by the profile-driven
regression model than by the polynomial approximation.
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

•

17:20

D. W. McClary et al.

6

6

4

4

2

0.4
0.2
0.0
2

0.0

0.2

1

0
x1

1
2

0.4
0.2

0

x2

0

2

1

0.4

(a) the function y

x2

y

y

2

0.2
0
x1

1
2

0.4

(b) a second-order polynomial
approximation of y

Fig. 10. A comparison of the function y to the fit derived through second-order polynomial approximation ŷpe .
Polynomial Expansion: Actual vs. Fitted Values

Polynomial Expansion: Residuals vs. Fitted Values
4

3

1.0

Actual Values

Standardized residuals

1.5

0.5
0.0

2

1
−0.5
0

−1.0
1

2

3

Fitted values

(a) residuals vs. fitted values for the
polynomial expansion

1

2

3

Fitted values

(b) actual vs. fitted values for the
polynomial expansion

Fig. 11. Residuals of polynomial expansion. In the polynomial model, much of the signal is lost.

For reference, the actual function and its general form are as follows.
1
x1 + x12
1 + (10 × 106 )x2
1
x + β2,1 x12
y =
(β3,2 x2 ) 1
β0,2 + β1,2

y =

(Actual function)
(General form)

(6)

A.2 Factor Partitioning
In some systems, the number of factors may be large. A partitioned approach
may be applied to reduce the number of experiments and correspondingly the
computational intensity of profile-driven regression. Suppose that each of the
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

•

Profile-Driven Regression for Modeling and Runtime Optimization

17:21

Plot of y-f(2) in the Partitioned Example
16

y-f(2) v. x 2

14
12

y

10
8
6
4
2
-0.6

-0.4

-0.2

0
x2

0.2

0.4

0.6

Fig. 12. Plot of y against x2 in the partitioned example. The relationship appears to be nonlinear.

factors F = {x1 , x2 , . . . , xk} falls into one of two sets: those factors that are
approximated by nonlinear functions, N ⊆ F, and those factors that can be
linearly approximated, L = F \ N , and do not interact with the factors in N .
Initially, N = L = ∅. One way to classify a factor xi , 1 ≤ i ≤ k, into N
or L is to examine its profile against the set of observations y. Put simply, if
the profiles of xi against y are translations of one another, with consideration
given to random noise, then xi may be linearly approximated and L = L ∪ {xi };
otherwise, N = N ∪{xi }. Alternatively, some of the factors in L may be identified
through screening or previous experiments.
By separating linear factors into their own partition, common experimental designs (e.g., factorials, central composite designs) and traditional linear
regression techniques, using standard least-squares estimation and smaller
designs, can be employed. Indeed, any two sets of factors that do not interact
may be partitioned, but separating the purely linear effects often does the most
to simplify modeling efforts.
A.2.1 An Example Partitioning. As an example, we partition the same
function with two factors F = {x1 , x2 } considered in Section 3.1. Examining
the profiles of x1 and x2 in Figure 3 we see that the profiles of x1 appear to be
translations of one another while those of x2 are not. Therefore we partition F
into L = {x1 } and N = {x2 }.
Suppose that we decide a priori that x1 is at most a second-order polynomial.
If we further decide that there is no likely interaction between x1 and x2 , they
can be modeled separately against y. This yields
ŷpart = 2.63x1 + 1.20x12 ,
with 95% significance, and leaves the relationship between x2 and y to be
modeled. Plotting y − f (x1 ) versus x2 yields Figure 12, that again suggests the
1
nonlinear function form a+b
cx .
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

•

17:22

D. W. McClary et al.

6
10
4

y

5

0.0
2

1

0.0
2

0.2
0
x1

1

0.2

1

0
x1

2 0.4

(a) the function y

1.5

0.4
0.2

0

x2

0.4
0.2

0

x2

y

2

1

2 0.4

(b) the partitioned profile-driven regression
approximation of y

●

Standardized residuals

1.0
●

0.5

0.0

−0.5

●
●
●

−1.0
0.5

1.0

1.5

2.0

2.5

3.0

Fitted values
(c) residuals for the partitioned approximate model

Fig. 13. Approximate models for the example surface using the partitioned approach.

Fitting a nonlinear model of this form to the levels of x2 at x1 = 2 yields
1
y − ˆf (x1 ) = 0.30+0.22
x2 , with 95% significance, and the final model
ŷ = 5.3x1 + 1.21x12 +

1
.
−0.76 + 0.72x2

Additional trials are necessary to obtain convergence in all coefficients.
The function y, the resulting response surface obtained through partitioning, and standardized residuals are given in Figure 13. Examining the plotted
residuals in Figure 13(c), the effect of assuming linearity is evident. Comparing
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

Profile-Driven Regression for Modeling and Runtime Optimization

•

17:23

Figure 13(c) with Figure 11(a) illustrates that partitioned approach captures
the overall behavior of the system as well as the polynomial approximation.
However, because the partitioned approach better captures the nonlinear behavior in x2 , the partitioned model is likely to be more accurate than the simple
Taylor series expansion. In a situation such as this, profile-driven regression
may be applied to the residuals to achieve a more accurate approximation, or
a new profile-driven regression study may begin using a mixed-level design.
ACKNOWLEDGMENTS

We thank Spencer Graves for his valuable comments on an earlier version of
this article.
REFERENCES
BATES, D. AND WATTS, D. 1988. Nonlinear Regression Analysis and Its Applications. John Wiley
and Sons.
BENAISSA, M., LECUIRE, V., MCCLARY, D. W., AND SYROTIUK, V. R. 2004. ANOVA-Informed decision trees for voice applications over MANETs. In Proceedings of the 6th IEEE International
Conference on Mobile and Wireless Communication Networks (MWCN’04). 143–154.
BISWAS, P. AND YE, Y. 2004. Semidefinite programming for ad hoc wireless sensor network localization. In Proceedings of the 3rd International Symposium on Information Processing in Sensor
Networks. 46–54.
BJORKLUND, P., VARBRAND, P., AND DI, Y. 2003. Resource optimization of spatial TDMA in ad
hoc radio networks: A column generation approach. In Proceedings of the 22nd Annual Joint
Conference of the IEEE Computer and Communications Societies (InfoCom’03). Vol. 2. 818–824.
BORONI, L., CONTI, M., AND GREGORI, E. 2004. Runtime optimization of IEEE 802.11 wireless
LANs performance. IEEE Trans. Parall. Distrib. Syst. 15, 66–80.
BOX, G. E. P. AND HUNTER, W. G. 1962. A useful method for model building. Technometrics 4,
301–318.
BOX, G. E. P. AND LUCAS, H. L. 1959. Design of experiments in nonlinear situations.
Biometrika 46, 1/2, 77–90.
CHATZMISIOS, P., VITAS, V., AND BOUCOUVALAS, A. C. 2002. Throughput and delay analysis of IEEE
802.11protocol. In Proceedings of the IEEE 5th International Workshop on Networked Appliances.
168–174.
COLAGROSSO, M. D. 2005. A classification approach to broadcasting in mobile ad hoc network. In
Proceedings of the IEEE Conference on Communications (ICC’05). Vol. 2. 1112–1117.
DANIEL, C. AND WOOD, F. S. 1999. Fitting Equations to Data: Computer Analysis of Multifactor
Data. John Wiley and Sons.
DOHERTY, L., GHAOUI, L. E., AND PISTER, K. S. J. 2001. Convex position estimation in wireless sensor
networks. In Proceedings of the IEEE Conference on Computer Communications Workshops
(InfoCom’01). Vol. 3. 1655–1663.
DUBE, R., RAIS, C. D., WANG, K.-Y., AND TRIPATHI, S. K. 1997. Signal stability-based adaptive
routing (SSA) for ad hoc mobile networks. IEEE Personal Comm. 4, 36–45.
FARAGÓ, A., MYERS, A. D., SYROTIUK, V. R., AND ZÀRUBA, G. V. 2000. Meta-MAC protocols: Automatic
combination of MAC protocols to optimize performance for unknown conditions. IEEE J. Select.
Areas Comm. 18, 1670–1681.
FISHER, R. A. 1921. Studies in crop variation. i. An examination of the yield of dressed grain
from Broadbalk. J. Agricult. Studies 11, 107–135.
IEEE. 802.11. 1999. W-LAN medium access control and physical layer specifications. IEEE
standard 802.11.
JAIN, R. 1991. The Art of Computer Systems Performance Analysis: Techniques for Experimental
Design, Measurement, Simulation, and Modeling. Wiley-Interscience.
JOLLIFFE, I. T. 1986. Principal Component Analysis. Springer.
ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

17:24

•

D. W. McClary et al.

L’ECUYER, P. 1999. Good parameters and implementations for combined multiple recursive random number generators. Oper. Res. 47, 159–164.
MONTGOMERY, D. C. 2004. Introduction to Statistical Process Control. 5th Ed. John Wiley and
Sons.
MONTGOMERY, D. C. 2005. Design and Analysis of Experiments. 6th Ed. John Wiley and Sons.
MOURSY, A., AJBAR, I., PERKINS, D., AND BAYOUMI, M. 2008. Empirical model-based adaptive control
of MANETs. In Proceedings of the IEEE Conference on Computer Communications Workshops,
(InfoCom’08). 1–6.
MULLEN, J., MATIS, T., ADAMS, K., AND RANGAN, S. 2004. Achieving robust protocols for mobile ad
hoc networks. In Proceedings of the Industrial Engineering Research Conference (IERC’04).
MYERS, R. H. AND MONTGOMERY, D. C. 2002. Response Surface Methodology: Process and Product
Optimization Using Designed Experiments, 2nd Ed. John Wiley and Sons.
NAVIDI, W., CAMP, T., AND BAUER, N. 2004. Improving the accuracy of random waypoint simulations through steady-state initialization. In Proceedings of the 15th International Conference on
Modeling and Simulation (MS’04). 319–326.
ns-2. 1995. The network simulator — ns-2. http://www.isi.edu/nsname/ns/.
PERKINS, C. E. AND BELDING-ROYER, E. M. 2003. Ad hoc on-demand distance vector (AODV) routing.
RFC 3561 (informational).
PERKINS, C. E. AND ROYER, E. M. 1999. Ad hoc on-demand distance vector routing. In Proceedings
of the 2nd IEEE Workshop on Mobile Computing Systems and Applications. 90–100.
PIÓRO, M. AND MEDHI, D. 2004. Routing, Flow, and Capacity Design in Communication and
Computer Networks. Morgan Kaufmann.
R PROJECT FOR STATISTICAL COMPUTING. 1997. R project for statistical computing.
http://www.r-project.org.
RUSZCZYNSKI, A. 2006. Nonlinear Optimization. Princeton University Press.
SINGH, S., WOO, M., AND RAGHAVENDRA, C. S. 1998. Power-Aware routing in mobile ad hoc networks.
In Proceedings of the 4th Annual ACM/IEEE Conference on Mobile Computing and Networking.
181–190.
SRINIVASAN, V., CHIASSERINI, C. F., NUGGEHALLI, P. S., AND RAO, R. R. 2004. Optimal rate allocation for energy-efficient multipath routing in wireless ad hoc networks. IEEE Trans. Wirel.
Commm. 3, 3, 891–899.
STAT EASE. 1988. Design expert. http://www.stat-ease.com.
VADDE, K. K. AND SYROTIUK, V. R. 2004a. Factor interaction on service delivery in mobile ad hoc
networks. IEEE J. Select. Areas Commm. 22, 1335–1346.
VADDE, K. K. AND SYROTIUK, V. R. 2004b. On timers of routing protocols in MANETs. In Proceedings of the 3rd International Conference on Ad Hoc Networks and Wireless (AdHoc Now’04).
330–335.
VADDE, K. K., SYROTIUK, V. R., AND MONTGOMERY, D. C. 2006. Optimizing protocol interaction using
response surface methodology. IEEE Trans. Mobile Comput. 5, 6, 627–639.
WOLPERT, D. H. AND MACREADY, W. G. 1997. No free lunch theorem for optimizations. IEEE Trans.
Evolut. Comput. 1, 67–82.
YUSTE, A. J., TRUJILLO, F. D., TRIVÑO, A., AND CASILARI, E. 2007. An adaptive gateway discovery
for mobile ad hoc networks. In Proceedings of the 5th ACM International Workshop on Mobility
Management and Wireless Access. 159–162.
ZHONG, X., MEI, S., WANG, Y., AND WANG, J. 2003. Stable enhancement for AODV routing protocol.
In Proceedings of the 14th IEEE on Personal, Indoor and Mobile Radio Communications. Vol. 1.
201–205.
Received November 2008; revised August 2009; accepted September 2009

ACM Transactions on Modeling and Computer Simulation, Vol. 20, No. 3, Article 17, Pub. date: September 2010.

1670

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 18, NO. 9, SEPTEMBER 2000

Meta-MAC Protocols: Automatic Combination
of MAC Protocols to Optimize Performance for
Unknown Conditions
András Faragó, Member, IEEE, Andrew D. Myers, Student Member, IEEE, Violet R. Syrotiuk, Member, IEEE, and
Gergely V. Záruba, Student Member, IEEE

Abstract—A systematic and automatic method to dynamically
combine any set of existing MAC protocols into a single higher
layer, or meta-MAC protocol, is presented. The new approach
makes it possible to always achieve the performance of the best
component protocol, without knowing in advance which protocol
will match the potentially changing and unpredictable network
conditions. Moreover, this dynamic optimization is entirely automatic and runs without any centralized control or any exchange
of messages, using only local network feedback information. We
describe the method and prove that the resulting meta-MAC
protocol achieves optimal performance in a well-defined sense.
Through simulation on different types of networks and with
different component MAC protocols, we demonstrate that our
simple and practical combination algorithm yields highly adaptive
and scalable MAC solutions.
Index Terms—Access protocols, adaptive systems, distributed algorithms, multiaccess communication, optimization methods.

I. INTRODUCTION

I

N ALL NETWORKS that have a broadcast channel as the
basis of communication, the medium access control (MAC)
protocol serves a vital role. It is the MAC protocol that is
directly responsible for controlling access to the communication resources. There are seemingly countless MAC protocols,
each optimized for specific network conditions. The network
designer naturally faces the question: which one to use? Even
if the network conditions are known precisely in advance, the
answer is very often not easy, due to the large number of competing protocols. In most cases, however, the designer does not
even know the exact network conditions and/or has to assume
that they may change during operation, usually with limited
predictability. For example, in mobile multihop networks, the
topology changes frequently, due to node movement. But even
in a fixed and fully connected network, the traffic pattern can
be very unpredictable and unstable.
The usual approach to handle unknown or changing conditions in most MAC protocols is to include some kind of adaptivity in order to adjust the operation to the actual network conditions. There are numerous ways known to make MAC protocols
Manuscript received October 7, 1999; revised March 1, 2000.
The authors are with the Department of Computer Science and Center for
Advanced Telecommunications Systems and Services (CATSS), University
of Texas at Dallas, Richardson, TX 75083-0688 USA (e-mail: farago@utdallas.edu; amyers@utdallas.edu; syrotiuk@utdallas.edu; zaruba@utdallas.edu).
Publisher Item Identifier S 0733-8716(00)07123-7.

Fig. 1. The meta-MAC protocol in a simplified protocol stack.

adaptive, including various handshake mechanisms to avoid collisions, monitoring traffic intensity in order to change strategies,
as well as many other ad hoc solutions.
We propose a principally new approach to create adaptive
and scalable MAC solutions. Our new approach is based on
a “meta-MAC” protocol framework that implements a higher
layer of adaptivity, on top of the existing MAC protocols.
Specifically, we introduce a method to systematically and automatically combine any set of existing protocols into a single
MAC protocol such that the resulting combined protocol has
provable optimality properties. Thus, we assume that a number
of existing MAC protocols are available as components at each
node in the network, and that our meta-MAC protocol works on
top of them (see Fig. 1), optimally combining their individual
transmission decisions into a final decision at the node each
time when such a decision has to be made. Then, according
to the local network feedback information, the combination
is updated. The resulting combination may not be identical at
each node of the network; this depends on whether or not each
node receives the same feedback.
It is important that the meta-protocol can combine any set of
component protocols automatically. Thus, we can select appropriate component protocols that are already fine-tuned for certain network conditions and may also have internal adaptivity

0733–8716/00$10.00 © 2000 IEEE

FARAGÓ et al.: META-MAC PROTOCOLS

properties. Each component may be a good candidate for certain situations. For example, a contention protocol is good for
low loads, due to its low delay, while a TDMA protocol is desirable for high loads, as it avoids the breakdown induced by
too many collisions. Then the meta-protocol will automatically
find combined decisions that dynamically represent the “best of
the team,” under the actual network conditions, without having
to know in advance which of the conditions will actually occur
and how they will change. Moreover, the optimization runs locally without any centralized control or any message exchanges.
Thus, what we present is not just another MAC protocol. On the
contrary, it is a methodology that allows the optimal aggregation
of several existing protocols in a unique, scalable way, so that
they complement each other and result in an overall increase in
network efficiency.
Our proposed combination principle is practical to implement
even in a mobile multihop wireless environment, which is normally considered a difficult scenario, due to the lack of full connectivity. For example, the radios in Raytheon Systems ASPEN
project [16] have the capability to simultaneously load multiple
MAC protocols and the ability to switch protocols and tune parameters on the fly. Our meta-protocol has very low complexity,
lending itself to implementation in hardware. In light of the performance gains that the meta-protocol achieves, we believe the
changes to the network equipment are both justified and practical to implement.
The rest of this paper is organized as follows. In Section II we
overview some precursors of protocol combination, including
dynamic parameter optimization as a simple form. Section III
describes our systematic meta-MAC protocol framework and
what claims can be made regarding its optimality. For clear presentation of the fundamental principle, in this paper we restrict
ourselves to slotted time and assume that perfect feedback is
available at the end of each slot. In Section IV some examples
of the principle for LANs and multihop networks are described,
supported by simulation results. We also illustrate how the principle can be used to optimize protocol parameters. Section V
concludes the paper.
II. PRECURSORS OF PROTOCOL COMBINATION
There are many examples of MAC protocols being combined
together to enhance adaptivity and performance. The combination in these protocols, however, is done in an ad hoc way
without systematic optimization. Sometimes, the combination
is “hidden,” i.e., without explicitly referring to component protocols. One such family of examples is the -persistent slotted
Aloha protocols where in each slot, whenever there is a packet
in the queue, the probability of transmission is a constant independently for each slot. If we dynamically change the value of
in any way, e.g., with binary exponential backoff (BEB), then
essentially we combine different -persistent slotted Aloha protocols that differ in their values. Thus, in each slot we decide
to use one of these component protocols, namely the one with
the appropriate .
In the above example, it is not an easy question which is
the best way of adjusting the retransmission probabilities. It is
proven that BEB results in an unstable protocol under certain

1671

modeling assumptions [1]. The existence of stable protocols
in this setting also depends on the type of feedback available
from the channel and on how the user population is modeled.
For acknowledgment-based protocols, a large class of backoff
schemes, including polynomial backoff1 is unstable [10]. In
contrast to this, for finite user population, any superlinear polynomial backoff protocol has been proven stable, while BEB still
remains unstable above a certain arrival rate [7]. Thus, it is far
from trivial to find the best combination.
In [12], a learning automata based random access protocol for
WDM passive star networks is introduced to optimize the transmission probability of each wavelength. This work is related
to our meta-protocol approach that we present in the next section; however, it solves only one specific parameter optimization
problem. Our approach is far more general and applicable to any
network that has a broadcast channel as the basis of communication.
In mobile multihop networks, spatial reuse TDMA protocols can adapt by periodically reassigning time slots and frame
lengths (see, among many others, [6] and [17]). In these protocols, the nodes alternate between a contention and a TDMA
protocol. The contention protocol is used by the nodes to create
TDMA schedules. Once the schedules are fixed, the operation
switches over to the TDMA protocol. When node mobility results in a topology change, the contention protocol runs again.
Another way of combining protocols is based on nodes
monitoring the traffic intensity of the medium locally, e.g., by
counting the number of idle slots in a frame. This measurement
can be used to determine the rate at which a node can transmit
packets [9], trigger the node to switch protocols in the next
frame [2], or otherwise decide to have nodes contend in some
slots [11].
A more explicit example of protocol combination is the idea
of protocol threading, first used with TSMA protocols in mobile multihop networks [4]. In this approach, several different
TSMA protocol frames are interleaved on a time sharing basis
to obtain a threaded TSMA protocol. In this solution, the transmission rights are assigned in different time slots according to
different TSMA protocols in a cyclically repeated way, realizing
a time sharing that yields a combined protocol with unique properties [4]. The advantage of this combination is that the component TSMA protocols are optimized for different densities of
the topology, and the threaded protocol can handle all situations
without knowing in advance which one will occur.
Another approach to combining protocols is the ADAPT protocol of [5] where, in principle, any allocation protocol can be
combined with any contention protocol, such that the allocation
protocol provides guaranteed access, while the contention protocol utilizes the unused slots to enhance performance.
III. THE META-MAC PROTOCOL
In this section we propose a systematic and automatic
principle to combine MAC protocols via a specific meta-MAC
protocol. The meta-MAC protocol is completely general in the
sense that it can be applied in any network that has a broadcast
1The backoff interval grows according to a polynomial function rather than
an exponential function.

1672

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 18, NO. 9, SEPTEMBER 2000

Fig. 2. Operation of the meta-MAC protocol.

channel as the basis of communication, and it can run on top
of any set of component protocols. For ease of presentation,
we restrict our attention to slotted time and assume that perfect
feedback is available at the end of a slot. The actual way of
computing the combined transmission decision in each time
slot is based on a weighted combination of the individual
decisions of the component protocols, with rounding the
weighted average at the end to obtain a binary decision, using
randomization. The weights are then appropriately adjusted
after each slot, based on the continuously updated “credit
history” of the individually running component protocols using
local network feedback information. We call the method the
randomized weighted majority (RWM) meta-MAC protocol.
After introducing the method, we prove that it optimizes the
performance of the combination, in a sense precisely defined
later. Although the simple and practical combination principle
has long been known in a number of fields, e.g., in artificial
intelligence and computational learning theory (see, e.g., [3],
from which we use mathematical results for the proof of
optimality), nevertheless, to the best of our knowledge, it is
fundamentally new in the context of MAC protocols.

means that
would transmit with probability 0.7
in slot . No assumptions about how each component protocol
reaches its decision are made—this is completely arbitrary.
The meta-protocol is an algorithm that runs locally at each
,
node and combines the component decisions
which is again a number in
to produce a combined result
The final binary
[0, 1], with the same interpretation as
is derived from
by drawing a random
decision
and the
binary value that takes the value 1 with probability
value 0 with probability
Remark: We could round
deterministically to 0 or 1, but
this would result in poorer performance when the value happens
to fall often around the middle of the interval [0, 1]. For example,
holds over a long sequence of slots, then deterif
ministic rounding would result in transmission in every slot, excluding success if there is a conflicting node that also wants to
transmit. On the other hand, in this example, random rounding
generates transmissions in about 51% of the slots randomly, still
allowing a chance for success.
is computed as a function of the weighted
The value of
values:
average of the

A. The Basic Model
MAC protocols
As Fig. 2 shows, at any given node,
have been selected to be combined.2 The final
decision whether or not to transmit at a given time is reached
by appropriately combining the proposed decisions of the
component protocols.
Each protocol runs locally and in each slot produces a de, where
is interpreted to mean
cision
would transmit in slot and
is interpreted to
that
mean that would not transmit in slot . We also allow intermethat are interpreted as probabilities,
diate values
to account for protocols that use randomization. For example,
2

M is unrelated to the number of network nodes.

(1)

can be chosen in several ways. One simple
The function
, that is,
is made equal to the weighted
choice is
. Another choice is a step function, which
average of the
rounds the result to 0 or 1 depending on whether the weighted
average is below 0.5 or not. It turns out, as shown in the next
subsection, that optimality is achieved by a function that is in
between these two choices. This function linearly grows from 0
and it is truncated to 0
to 1 in an interval

FARAGÓ et al.: META-MAC PROTOCOLS

1673

known at the end of the slot. Using , the weights are updated
according to the following simple exponential rule:

and 1 before and after the interval, respectively. Formally,
is defined as

(3)

if
(2)

if
if

.

that
The parameter depends on another parameter
controls the update of the weights. The following dependence
makes it possible to prove the optimality:
.
The meta-MAC protocol maintains the weights used in (1).
is the weight of protocol for slot .
The positive number
At the end of each slot, the weights are updated using the local
network feedback.
Let us remark that, in general, the feedback that is available
for a MAC protocol can have a serious impact on the performance. For example, in slotted Aloha type protocols, a common
feedback model is the ternary feedback that allows the user to
know whether a successful transmission occurred, a collision
occurred, or the channel remained idle in the slot. An interesting
consequence of this is that for a fully connected network with
infinite user population, no such protocol can achieve an average
throughput of more than 0.568 packets/slot, no matter what kind
of backoff mechanism is used [15]. In contrast to this, with more
refined feedback, consisting of the exact number of users that
transmitted in the slot, the throughput can be brought arbitrarily
close to 1 packet/slot, which is the theoretical limit for the fully
connected case [13].
In our model, in order to maintain general applicability, we
do not want to restrict ourselves to a specific type of feedback.
Rather, we only assume that enough information is available
from which the meta-protocol can conclude (or estimate) at the
end of the slot whether the decision for the slot was right or
wrong. We call this correctness feedback, and it can be realistically obtained in many cases. For example, from the ternary
feedback, we can easily conclude whether the decision was correct or not: if we decided to transmit and it was successful, then
the decision was right; on the other hand, if a collision occurred,
then it was a wrong decision. If there was a packet in the queue
but we decided not to transmit, then if the channel remained idle,
that implies the decision was wrong, since the slot was wasted.
If the channel did not remain idle, i.e., it was used by at least
one other node, then it was a right decision not to transmit. If
the queue was empty, then refraining from transmission was, of
course, right. We do not restrict ourselves regarding how this
correctness feedback is achieved, i.e., from what actual data it
is computed.
Having the above explained correctness feedback, the weight
update algorithm works as follows. Let denote the feedback:
if the decision in slot was correct
if the decision in slot was incorrect.
can be retrospectively computed
Then the correct decision
, that is,
if
as
, otherwise
. Of course we cannot simply set
the decision for slot according to , since only becomes

This weight update rule has an appealing interpretation. The
in the exponent represents the deviation of proterm
tocol from the correct decision. If this deviation is zero, then
the weight of remains unchanged. Otherwise it decreases the
such that with increasing deviation (i.e., errors)
weight of
the decrement grows. This means, due to the normalization in
(1), that after each slot the relative weight of those protocols
that made a correct decision will grow, while those which made
a mistake will lose relative weight. In this way, the weights essentially reflect the “credit history” of the component protocols.
controls how fast the weights can change.
The constant
Note that the direct use of (3) can cause underflow in the
number representation, since the weights decrease exponentially, but never grow. This problem is easily solved in practice,
by renormalizing the weights after each update. One can
also set a minimum value below which no weight can drop.
Renormalization does not change the relative sizes of the
weights, and since they are only used in a normalized way in
by (1), therefore, only their
computing the combined value
relative sizes matter.
Having introduced the needed concepts, we now summarize
our meta-MAC protocol.
RWM Meta-MAC Protocol:
Initialization: set all weights to 1.
In slot do:
• At the beginning of the slot:
.
Compute the component decisions
else
If there is no packet in the queue, then set
compute

Randomly round
to the final binary decision
,
and
according to
.
, then transmit the first packet in the queue,
If
otherwise refrain from transmission.
and the feed• At the end of the slot: Using the decision
and update
back compute
.
all weights according to
B. Optimality
Now, having defined the meta-MAC protocol, we prove that
it achieves optimal performance, in a well-defined sense, among
all other possible combinations of the same component protocols.
A key question is how we compare the performance of
different combinations of the same component protocols. The
first thing that may come to mind is to compare the average

1674

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 18, NO. 9, SEPTEMBER 2000

throughput per slot. Doing this directly, however, is not realistic, since without any further restriction a fully arbitrary
meta-protocol may use another “built in” MAC protocol and
this may achieve better throughput than any of the component
protocols, so finally the meta-protocol may end up not using
the component decisions at all. In this way, we would have
to assess the performance of all possible MAC protocols,
which finally would not tell anything about how good is the
combination. To avoid such problems and to guarantee that
we really compare the possible combinations of the same
component protocols, using the same feedback, we carefully
develop a formal framework for the comparison.
In each slot we measure the loss of the meta-protocol by
the probability that the decision is incorrect, which is
. The way we defined
,
, and implies that the loss
and ,
probability is equal to the absolute error between
. Now let
that is,
be a sequence of slots. The per slot loss of the protocol over
. By
this sequence is measured by
, this is the probability of incorrect
decision, averaged over the slots. In other words, we can use as
the (average) probability of wrong decision. For short, we refer
to this quantity as the loss of the protocol. To emphasize that
,
this loss depends on the feedback sequence
. Similarly, we can define the loss of
we use the notation
by using the same formulas but
each component protocol
distinguished by the index :

Now we can measure the quality of the combination by measuring how much loss is due purely to the meta-protocol. This
is obtained by comparing the loss of the combined protocol
to the loss of the best component protocol. To this end, we
.
define the combination loss by
The meaning of this is even clearer if, by rearranging, we write
which shows that the combination
loss is really the additional loss incurred over the best compo, then the
nent protocol, due to the combination. If
combination results in actual improvement over the best com, or
, but small, then we
ponent protocol. If
do not improve over the best component, but at least achieve or
approximate its performance. This is still remarkable, since we
do not know in advance which is the best protocol.
We capture the concept of optimal combination by looking
for the meta-protocol that minimizes the combination loss. This
is quite natural, since once the component protocols are given,
is a constant for a given , so minimum
the value of
overall loss is achieved for the given if the combination loss
is minimized.
Of course, all the above values depend on the feedback sequence that represents the behavior of the rest of the network. Since we neither know this sequence in advance nor do
we have any a priori probability distribution over the possible
feedback sequences, therefore, we measure the performance of
the meta-protocol by the worst-case combination loss, defined

as
where the
maximum is taken over all possible feedback sequences. Thus,
is a guaranteed upper bound on the actual combination loss
for any feedback sequence. In this way, it characterizes how
good the combination is, and it is natural to look for a protocol
to the smallest possible value.
that can lower
First, we show that the worst-case combination loss can never
be negative for any combination protocol, which is not obvious
from the definition. This implies that the ideal goal can only be
. Second, we prove that our RWM meta-MAC
to achieve
value asymptotically,
protocol in fact achieves the ideal
so in this sense it is asymptotically optimal among all other
possible protocols that combine the same components with the
same feedback.
Theorem 1: Let be any protocol that combines the compo, in the same framework as RWM,
nent protocols
but may arrive at the decision in an arbitrary different way. Let
. Then
the worst-case combination loss of be
always holds. Moreover, the RWM protocol is optimal in that
it asymptotically achieves the optimal 0 lower bound in the
and for any sufficiently large
following sense: for any
time horizon there exists a choice of the parameter such
the combinathat for any feedback sequence of length
of RWM is less than . Specifically, if
tion loss
where
and
, then
holds for any feedback sequence of length if the appropriate is used. Consequently,
also holds, where
is the worst-case
combination loss of the RWM meta-MAC protocol.
Proof: See the Appendix.
A few comments are pertinent here concerning the statement
of Theorem 1. In the worst case, no combination protocol in the
considered setting can outperform the best component protocol.
Of course, we do not know in advance which component protocol is best for the actual situation, so we cannot simply run
that protocol and ignore the rest. The RWM protocol asymptotically achieves this best possible performance, i.e., the resulting
loss automatically approaches the loss of the component protocol that is the best for the actual sequence, even though neither the sequence nor the identity of the best component protocol is known in advance. Moreover, the asymptotic optimality
of RWM is achieved without fully using the history of earlier decision and feedback values. The history is used only in a simple
. The decision
and very “condensed” way, via the weights
is also made by a simple rule. Although the theorem allows arbitrarily complicated algorithms for , it is interesting to note
that additional complexity cannot further improve the quality in
the stated sense.
C. Fairness, Stability, and Convergence
Fairness, both short term and long term, are important properties of a MAC protocol. In some sense, the meta-MAC protocol
“inherits” the fairness properties of its components, and, in particular, the current best protocol for the network conditions. The
meta-protocol has its own fairness properties and the characterization of its fairness remains to be completed.
In the experiments that follow, we only considered a network
load that was uniformly distributed over the entire network. In

FARAGÓ et al.: META-MAC PROTOCOLS

1675

order to understand the stability of the combination principle
and how fast the method converges, we need to consider nonuniform dynamic load conditions in our simulations. While it is
clear that the larger the value of the more rapidly the meta-protocol adapts to the feedback, it is still not well understood how
will interact under nonuniform load, noisy channels, and other
similar network characteristics.

IV. EXAMPLES OF THE META-MAC PROTOCOL
A. Examples of Protocol Combination
1) Combining Slotted Aloha and TDMA in a LAN: To see
how our meta-MAC protocol combines the advantages of two
complementary approaches in LANs, we selected a slotted
Aloha protocol and a TDMA protocol, and compare our results
to IEEE 802.3 [14].
Using a discrete event simulator, we modeled a 10 Mbits/s
nodes. Network traffic was introduced acLAN with
cording to a Poisson arrival process with a mean of packets per
slot uniformly distributed among the nodes, with fixed length
packets of 100 and 500 bytes. The meta-protocol used the value
in updating the weights at the end of a slot, and perof
fect channel feedback was assumed. Each data point represents
an average of many simulation runs, each of which simulated
600 s real time achieving a confidence interval of over 90%.
The slotted Aloha protocol we used is stable [8]: if a given
slot is idle (has a collision) then the node multiplies (divides) its
). The
transmission probability by a constant (we used
main difference between this backoff mechanism and binary exponential backoff (BEB) is that the backoff interval is not reset
to one on a successful transmission. In each slot, the protocol
returns a decision representing its transmission probability.
We used a simple TDMA protocol with a frame length of
. Each node has a unique identifier ,
,
which is used as its assigned slot in the frame. For node , the
protocol returns a binary decision depending on whether or not
it is ’s assigned transmission slot.
A main difference between IEEE 802.3, the component protocols and the resulting meta-protocol is that 802.3 uses an asynchronous approach with collision detection to transmit variable
length packets. Since the packet length for the meta-protocol is
fixed, we simplified our simulation of 802.3 to use fixed size
packets too. Our simulation results for meta-MAC, TDMA, and
slotted Aloha did not differ significantly for 100 and 500 bytes;
thus, for those protocols, we only show results for one packet
size.
For the considered protocols, we measured the average
number of successful packet transmissions per second
(throughput or, equivalently, channel utilization), and the
average time necessary to successfully access the channel (the
access delay).
Fig. 3 shows that at low loads the throughput of slotted Aloha,
TDMA, and the meta-protocol are all the same, almost matching
the arrival rate. As the load increases, the meta-protocol tracks
the throughput of TDMA consistently. Although 802.3 follows

Fig. 3.

Throughput, as a function of network load.

Fig. 4.

Access delay, as a function of network load.

the meta-MAC curve at low and middle loads, at high loads it
drops behind and remains constant.3
Fig. 4 shows that at low load, the delay of the meta-protocol corresponds to the delay of slotted Aloha; and as load
increases, its delay corresponds to that of TDMA. The small
“overshoot” in Figs. 4 and 5 for the meta-protocol occurs at the
network load at which the weights of the component protocols in
the meta-protocol are switching from slotted Aloha to TDMA.
Fig. 6 captures how the meta-protocol shifts its reliance on each
protocol as the load conditions in the LAN change. As can be
observed, 802.3 outperforms the meta-protocol at the middle
loads. At low and high loads, our meta-MAC has similar delay
characteristics or even outperforms 802.3.
Thus, when combining protocols of different types, this example shows that the meta-protocol is able to automatically adjust to the best protocol for the current network conditions. We
3802.3 does not break down since the number of nodes is 100 and the minimum backoff probability is 2 .

1676

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 18, NO. 9, SEPTEMBER 2000

Fig. 7. Throughput, as a function of network load (perfect channel, average
node degree of
4 and 8).

D=

Fig. 5. Throughput-delay characteristics.

Fig. 6.

Normalized average weights.

also see that under certain circumstances, the meta-MAC protocol can outperform a CSMA/CD based protocol even without
the powerful features of carrier sensing and collision detection.
2) Combining Slotted Aloha and TDMA in a Mobile Multihop Network: In this subsection, we adapt the meta-protocol
from the previous section to operate in a mobile multihop
wireless network, and compare its performance to that of IEEE
802.11 [18]. Moreover, we also consider the effects of noisy
feedback.
Obtaining channel feedback in a mobile multihop network is
more difficult than in a LAN. Because of hidden terminals, the
outcome is not always clear. As well, collision detection cannot
be used in a wireless environment since a wireless node cannot
transmit and receive simultaneously. Consequently, we enlarged
the slot to accommodate a 32-byte acknowledgment packet to
provide explicit feedback after a packet reception. The absence
of an acknowledgment is interpreted as a collision.
The IEEE 802.11 protocol is a pure contention protocol in
which the nodes directly compete for channel access using a

combination of carrier sensing and collision-avoidance handshakes. While the protocol has two methods of determining
channel access rights, we only implement the distributed coordination function because of the distributed nature of mobile
multihop networks.
Using a discrete event simulator, we modeled a mobile mulnodes operating in a twotihop network consisting of
dimensional plane. Each simulated node was equipped with a
wireless radio device capable of transmitting at a data rate of
10 Mbits/s to a distance of 300 m. For simplification, all communication was assumed to have taken place on a single channel,
and a free-space propagation model was employed without capture.
Node movement was simulated using a random graph model
in which the network connectivity was represented as an undi, where is the set of nodes and is
rected graph
the set of wireless links. Two nodes and are neighbors (i.e.,
can directly communicate with one another) if there is an edge
. This model was used because we were able to create
a connected topology with controlled node density. Movement
was simulated by creating a new random graph every 2 s. While
each node does not have perfect knowledge of the topology, it
does have perfect knowledge of its neighbors.
Network traffic was generated according to a Poisson arrival
process with a mean of packets per second, and uniformly
distributed among the operating nodes. Each packet contained a
payload of 2048 bytes of data, and was addressed to a random
neighbor.
Due to space limitations, we are only able to show results
for low node degrees. Each data point represents an average of
several simulation runs, each of which lasted 300 s real time, resulting in a confidence interval of over 90%. Figs. 7 and 8 show
the performance of the meta-MAC and 802.11 protocols using
a perfect channel model. Figs. 9 and 10 show the performance
of both protocols using a channel model which accommodates
, while Figs. 11 and 12
a bit error rate parameter of
compare the throughput delay characteristics of the perfect and
noisy channel.
As expected, the meta-protocol outperforms pure TDMA
(which has a maximum throughput of 610 packets/s and a
maximum average access delay of 0.052 s) with low traffic

FARAGÓ et al.: META-MAC PROTOCOLS

Fig. 8. Access delay, as a function of network load (perfect channel, average
4 and 8).
node degree of

D=

Fig. 9. Throughput, as a function of network load (noisy channel, average node
= 4 and 8).
degree of

D

load or nodal degree (see Figs. 7 and 8). When the average
nodal degree is greater than 4, the throughput performance
of the meta-protocol is better than that of the IEEE 802.11
protocol due to the control packet overhead and time needed
for collision resolution. On the other hand, the access delay of
the meta-protocol is always greater than that of IEEE 802.11
because the meta-protocol must wait until the beginning of a
slot to send a packet.4 Thus, the performance gap between the
meta-protocol and the IEEE 802.11 protocol will be reduced in
a more realistic simulation environment.
Comparing Figs. 7 and 8 to Figs. 9 and 10, we can clearly see
that the presence of noise in the channel has a much greater impact on the performance of the meta-protocol than that of IEEE
802.11. This is especially true at the lower average nodal degrees
when good channel feedback is critical to the success of the
slotted Aloha component protocol. Since there is an increased
number of lost packets and acknowledgments, the slotted Aloha
component protocol has degraded performance. The effect of
the noisy channel is mitigated when the nodal degree is higher
since the TDMA component protocol only returns a positive
transmission decision once per frame.
4Our simulations did not take into account the additional overhead needed to
achieve a synchronous protocol.

1677

Fig. 10. Access delay, as a function of network load (noisy channel, average
node degree of
= 4 and 8).

D

Fig. 11. Throughput-delay characteristics for perfect channel (average node
degree of
= 4, 8).

D

Fig. 12. Throughput-delay characteristics for noisy channel (average node
degree of
= 4, 8).

D

B. Examples of Parameter Optimization
While the meta-protocol can combine arbitrary different protocols, it can also combine the same protocol but using different
parameters, e.g., TDMA protocols with different frame lengths,
or -persistent slotted Aloha protocols with different values of
, etc. In this way, our aggregation approach provides a way to

1678

Fig. 13.

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 18, NO. 9, SEPTEMBER 2000

Throughput, when optimizing p-persistent slotted Aloha in a LAN.

Fig. 15. Throughput-delay characteristics when optimizing p-persistent
slotted Aloha in a LAN.

Fig. 16. Static multihop network topology for the TDMA based
meta-protocol.

Fig. 14.

Access delay, when optimizing p-persistent slotted Aloha in a LAN.

automatically optimize critical protocol parameters. In this subsection we investigate the application of the combination principle to parameter optimization.
1) Optimizing in -Persistent Slotted Aloha in LANs: In
this example, we combine -persistent slotted Aloha protocols,
each of which differs only in its transmission probability . A
-persistent protocol does not have a backoff mechanism; it relies solely on its transmission probability to decide in which
slot to transmit next.
At high load, when all nodes always have packets to send,
the probability of a successful transmission is given by
. The value of for optimal throughput is
, i.e.,
.
the number of component protocols should be
node LAN with the same simulation paramFor our
-persistent
eters as in Section IV-A-1, we combine
Aloha protocols where protocol has transmission probability
,
. At each node , each protocol ,
, returns a decision
,
,
representing its transmission probability.

Figs. 13–15 show the results. What is interesting is that the
meta-protocol outperforms the stable slotted Aloha protocol.
The reason is that the transmission probability of the stable
slotted Aloha protocol is limited to powers of 1/2 for its transmission probability. Specifically, this protocol “jumps” between
and
that bracket the optimal transprobabilities
,
for the curmission probability,
rent slot. In contrast, the meta-protocol can actually converge to
, which gives rise to its improved performance.
Thus the meta protocol dynamically adjusts its transmission
probability automatically according to the network conditions.
2) Optimizing TDMA Schedules in a Static Multihop Network: We give another example of the combination principle
for parameter optimization in a static (i.e., not mobile) multihop network combining protocols of the same type with different parameters. A discrete event simulator was used to implement the meta-protocol built on a static multihop network with
nodes. For our experiment, Fig. 16 shows the static
network used. Here, the small circles represent nodes (with the
given node identifier) and the lines connecting the circles represent bidirectional wireless links. The large circles represent
fully connected subnetworks of size 6 and 18, involving nodes
8–13 and 14–31, respectively.

FARAGÓ et al.: META-MAC PROTOCOLS

1679

TABLE I
FRAME LENGTH AND SLOT ASSIGNMENTS MADE BY THE META-MAC PROTOCOL

In this experiment, we use schedules with lengths that are
powers of two. This is essential since neighborhoods or neighboring nodes using different frame lengths must interwork with
each other resulting in a nonconflicting schedule. Thus, the
frames must be capable of being embedded in one another. To
ensure that there is at least one schedule for each node, we have
to take the worst-case bound of a simple global TDMA and
different TDMA frame lengths:
,
use
. For each such TDMA frame length ,
where
distinct schedules, each with a transmission right
there are
in a different slot. Thus, at each node , there are a total of
component TDMA protocols.
Initially, each node is assigned all slots from each length
protocols
TDMA schedule, i.e., the weights for all
are the same. The meta-protocol reaches a nonconflicting
schedule if during the run at each node there is one (and only
one) TDMA protocol with an assigned normalized weight of
almost one. This means that all protocol weights except one
must be infinitesimal. The TDMA component protocol with
the normalized weight of approximately 1 will determine the
frame length and assignment for the given node.
Some simple modular arithmetic on the frame size together
with a slot counter can be used to determine the decisions of
the individual protocols, i.e., at each node , each protocol ,
or
representing
returns a binary decision
whether or not the current slot is assigned to by .
Table I shows, for each node in the network, the TDMA
frame size and slot assignment in that frame size to which
the meta-protocol converged. The meta-protocol converged to
frame lengths that were very close to optimal with no conflicts
in the slot assignment. Since there are 18 nodes in the one fully
connected subnetwork, it is expected that some nodes must be
assigned a frame size of 32 rather than 16.
Thus, by combining TDMA protocols with different frame
sizes in a static network, the meta-protocol automatically converged to a near optimal frame size to match each node’s connectivity in the static multihop network. Moreover, a nonconflicting slot assignment was made.
V. CONCLUSION
This paper presented a systematic and automatic method to
combine any set of existing MAC protocols into a single higher
layer, or meta-MAC protocol. This approach guarantees that
the overall performance of the meta-MAC protocol matches
the performance of the best component protocol for the current
network conditions. This optimization is achieved without
knowing, a priori, which component protocol performs the best
in potentially highly dynamic network conditions. Moreover,

this optimization is automatic and runs entirely locally, i.e., it
requires no centralized control nor any message passing, using
only local network feedback information. We have outlined
the method, and proved that the resulting meta-MAC protocol
achieves optimal performance. Through extensive simulation
with different types of networks and component MAC protocols, we have shown the effectiveness of our combination
principle in a wide variety of situations.
APPENDIX A
holds for
Proof of Theorem 1: First we show that
any meta-protocol satisfying the conditions of the theorem.
be one of the component protocols. Since we consider
Let
the worst case with respect to the feedback sequence , we can
and
are
choose a “malicious” feedback sequence. Since
, and
is alconnected via
ready decided at the beginning of the slot, independently of the
feedback , then by choosing the value of , we can control
arbitrarily. So, let us set such that takes the value
if
if

.

, which implies
for this particular . If
is replaced
, then this term can only decrease, so
by
can only grow. Thus, we have
the difference in
for this chosen . Maximizing
with respect to can again only increase the value, so we have
, which
proves the first claim of the theorem.
Now we show that the RWM protocol asymptotically
achieves the 0 lower bound, which proves its (asymptotic)
optimality. This requires, however, a complicated proof, using
methods that have been used in a prediction model in the
context of computational learning theory by Cesa-Bianchi et
al. [3]. To help understand the main concept, first we show
how the proof works for a simplified case; and after that, we
consider the general case.
Thus, let us consider first the following simplified case. Ascan only be 0 or 1, that
sume that each component decision
is, intermediate values are not allowed. Further, let the combined
decision be simply the weighted majority of the component dedenote the sum of
cisions (i.e., deterministic rounding). Let
. Let
be the set of those
the weights in slot :
component protocols which made the right decision in slot ,
and set
. Thus,
that is,
is the error indicator: since now
, therefore,
it takes the value 1 if protocol made the wrong decision in slot
This ensures

1680

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 18, NO. 9, SEPTEMBER 2000

and 0 otherwise. Now let us consider the sum of the weights
, after the update. According to our update rule, we
in slot
. This can be
have
decomposed into two sums: one for those component protocols
), and one for
that made the right decision in slot (
). Using that
bethose that made a mistake (
for
or 1, respectively, we have
comes 1 or
(4)
Consider now the case when the meta-protocol made the wrong
decision in slot . Then at least half of the total weight had
and
to be on the wrong side, yielding
. Since for
the weight is multiplied
by a factor less than 1, therefore, the right-hand side of (4) is
is the
bounded from above by the value when the sum for
) and then the other sum is also
,
smallest possible (i.e.,
since it contains the rest of the weights. This may not be the actual distribution, but in this way we surely get an upper bound
on the right-hand side of (4). Thus, we have that if the meta-protocol made an error in slot , then
. Consider now the case when the meta-protocol makes errors over a slot sequence of length . Since,
according to the update rule, the weights can never grow and
whenever the meta-protocol errs decreases at least by a factor
, therefore, after errors
has to decrease at
of
least by the th power of the factor, so at the end of the slot se. Taking into account
quence we have
, we obtain
that the initial weight sum is
(5)
Now let be the index of the component protocol that performs
the best for the given sequence and assume it made errors.
Then, by the weight update rule, its weight was decreased
times by a factor of
. Given that initially each weight is 1,
. Since the total
we have at the end of the sequence
weight can never be smaller than any individual weight, theremust hold. This implies by (5) and
fore,
the following inequality:
. By rearranging this inequality, we obtain the following bound on the
number of meta-protocol errors in terms of the errors made by
the best component protocol:

, which implies
.
is a constant, these inequalities imply that for
Given that
and, consequently,
holds as
.
any ,
Now recall that this was a simplified case to show the principle of the proof. This simplified case does not cover the ac,
tual algorithm, since we excluded intermediate values for
ignored the randomization (thus allowed only 0-1 valued loss)
did not use the function (2) as well as the relationship of the parameter of the function with . These are needed for the general proof, which is substantially more complex. Fortunately,
however, we can use the results of [3], since our model can be
exactly mapped into their model. In [3] a prediction model is
“experts” predict a sequence of events
considered in which
with binary outcomes over time and these predictions are combined into a final prediction via a weighted combination, where
the weights are updated the same way as in the meta-MAC protocol. (Variants of such prediction models are used, for example,
to capture the situation when an investor wants to predict stock
market trends, using expert advice.) Our meta-MAC protocol
can be directly and exactly mapped in the prediction model, by
identifying the component protocols with the experts and the
feedback sequence with the outcome sequence in the prediction model, allocating one slot for each event. The prediction
model allows a class of functions for use in the combination formula (1), including our piecewise linear, sigmoid-type function
(2). The prediction model uses a parameter in the algorithm,
.
which can be directly mapped into our parameter by
In this way we can directly apply the following theorem from
[3] for the general case (reformulated with our notation): Let
be any sequence of outcomes of events. Furbe the accumulated absolute error of the combined
ther, let
, be the accumuprediction. Similarly, let
can be
lated absolute error of the th expert. Then
chosen such that
holds.
Using the above result, via the mapping between the prediction model and the meta-MAC protocol model, we obtain

As this holds for any , it also should hold for the one that max, yielding
imizes

(6)
Now one can show with lengthy calculations (see [3])
is chosen as
, where
that if
, then the estimation
can be obtained. Diand taking into account that
viding both sides by
, we have
. Since
the derivation of this bound did not depend on the choice
of the feedback sequence , then it should hold for any
such sequence, yielding

From

this

we

obtain,

via

solving

the

inequality
for , that
holds,

whenever

where

and

.

FARAGÓ et al.: META-MAC PROTOCOLS

REFERENCES
[1] D. Aldous, “Ultimate stability of exponential backoff protocol for acknowledgment based transmission control of random access communication channels,” IEEE Trans. Inform. Theory, vol. 33, pp. 219–223,
1987.
[2] R. E. Ahmea, “An adaptive multiple access protocol for broadcast
channels,” in Proc. IEEE Int. Conf. Performance, Computing Commun.,
1997, pp. 371–377.
[3] N. Cesa-Bianchi, Y. Freund, D. P. Helmbold, D. Haussler, R. E. Schapire,
and M. K. Warmuth, “How to use expert advice,” in Proc. 25th Annu.
ACM Symp. Theory Computing (STOC’93), San Diego, CA, May 1993,
pp. 382–391. (Univ. Calif. Computer Res. Lab., Santa Cruz, CA, Tech.
Rep. UCSC-CRL-94-33, 1994.).
[4] I. Chlamtac, A. Faragó, and H. Zhang, “Time-spread multiple-access
(TSMA) protocols for multihop networks,” IEEE/ACM Trans. Networking, vol. 5, no. 6, pp. 804–812, 1997.
[5] I. Chlamtac, A. Faragó, A. D. Myers, V. R. Syrotiuk, and G. Záruba,
“ADAPT: A dynamically self-adjusting media access control protocol
for ad hoc networks,” in Proc. IEEE Globecom General Conf., Rio de
Janiero, Brazil, Dec. 1999, pp. 11–15.
[6] I. Chlamtac and S. Pinter, “Distributed node organization algorithm for
channel access in multihop packet radio networks,” IEEE Trans. Computers, vol. 36, pp. 728–730, 1987.
[7] J. Håastad, F. T. Leighton, and B. Rogoff, “Analysis of backoff protocols
for multiple access channels,” in Proc. ACM Symp. Theory of Computing
(STOC’87), New York, NY, May 1987, pp. 241–253.
[8] D. G. Jeong and W. S. Jeon, “Performance of an exponential backoff
scheme for slotted-ALOHA protocol in local wireless environment,”
IEEE Trans. Veh. Technol., vol. 44, pp. 470–479, 1995.
[9] J. O. Limb, “Load-controlled scheduling of traffic on high-speed
metropolitan area networks,” IEEE Trans. Commun., vol. 37, pp.
1144–1150, 1989.
[10] F. P. Kelly, “Stochastic models of computer communication systems,” J.
Roy. Stat. Soc. (B), vol. 47, pp. 379–395, 1985.
[11] E. Kopsahilis, G. Papadopoulos, S. Koubias, and V. Christidis, “A simulation and measured performance of a new multiple access protocol,”
in Proc. 6th Eurotech. Conf., vol. 2, 1991, pp. 1105–1108.
[12] G. I. Papadimitriou and D. G. Maritsas, “Self-adaptive random-access
protocols for WDM passive star networks,” in IEE Proc.-Comput. Digit.
Tech., vol. 142, July 1995, pp. 306–312.
[13] N. Pippenger, “Bounds on the performance of protocols for a multiple
access broadcast channel,” IEEE Trans. Inform. Theory, vol. 27, pp.
145–151, 1981.
[14] A. Tanenbaum, Computer Networks. Englewood Cliffs, NJ: PrenticeHall, 1996.
[15] B. S. Tsybakov and N. B. Likhanov, “Upper bound on the capacity of a
random multiple access system,” Problemy Peredachi Informatsii, vol.
23, no. 3, pp. 64–87, 1987.
[16] G. Vardakas, W. Kishaba, and C. L. Fullmer, “QoS networking with
adaptive link control and tactical multi-channel software radios,” in
Proc. IEEE MILCOM’99.
[17] C. Zhu and S. Corson, “A five-phase reservation protocol (FPRP) for
mobile ad hoc networks,” in Proc. IEEE INFOCOM, 1998, pp. 322–331.
[18] Wireless Medium Access Control and Physical Layer WG, IEEE Draft
Standard P802.11 Wireless LAN, IEEE Standards Dep., Jan. 1996.

András Faragó (M’99) received the M.S. and Ph.D.
degrees in electrical engineering from the Technical
University of Budapest, Hungary, in 1976 and 1981,
respectively. In 1996 he received the distinguished
title “Doctor of Sciences” from the Hungarian
Academy of Sciences.
He joined the University of Texas at Dallas as
a Professor of Computer Science in 1998. Until
1997, he was with the Department of Telecommunications and Telematics, Technical University of
Budapest, where he was co-founder of the High
Speed Networks Laboratory, a leading telecom research laboratory in the
region. He worked as a visiting Senior Research Fellow at the University of
Massachusetts at Amherst in 1991–1992. He spent a sabbatical year at Boston
University in 1996. He serves as Editor for the journal Wireless Networks. His
research focuses on algorithms, protocols, design, and analysis methods of
communication networks, and has authored over 100 papers in the field.
Dr. Faragó is a member of IFIP Working Group 6.3 “Performance of Communication Systems” and was a founding member of the Hungarian Chapter of
ACM.

1681

Andrew D. Myers (S’98) received the B.S. degree
(with honors) and M.S. degree in computer science
from the University of Texas at Dallas, in 1997 and
1999, respectively. He is currently working towards
a Ph.D. degree in computer science at the University
of Texas at Dallas.
In 1997, he joined the Center for Advanced
Telecommunications Systems and Services (CATSS)
as a Research Assistant. From 1997 through 1999,
he was involved with the DARPA sponsored Global
Mobile Information (GloMo), developing and testing
signaling protocols for mobile ad hoc networks. He is currently working in the
areas of personal area networks (PANs) and mobile sensor networks.
Mr. Myers is a student member of the ACM.

Violet R. Syrotiuk (M’99) received the B.S. degree
in computer science from the University of Alberta in
1983, and the M.S. and Ph.D. degrees from the University of British Columbia and the University of Waterloo in 1984 and 1992, respectively.
She is an Assistant Professor in the Department
of Computer Science in the Erik Jonsson School of
Engineering and Computer Science. From 1997, she
was involved in a DARPA Global Mobile Information Systems project working to make the mobile environment a “first class citizen” in the defense information infrastructure. Her current research interests include medium access and
network layer protocols for wireless mobile networks, network simulation, and
distributed algorithms and systems.
Dr. Syrotiuk is a member of ACM, SIGMOBLE, and COMSOC.

Gergely V. Záruba (S’98) received the M.S. degree
in computer engineering in 1997 from the Technical
University of Budapest, Department of Telecommunications and Telematics, with excellent classification. Since 1997, he has been pursuing the Ph.D. degree.
From 1995 through 1999 he was a member of
Hungary’s leading telecom research laboratory, the
High Speed Networks Laboratory at the Technical
University of Budapest. In 1998, he joined the
Center for Advanced Telecommunications Systems
and Services (CATSS) at the University of Texas at Dallas, where he is
currently pursuing research on communication protocols for mobile multihop
networks as a Research Assistant. His research interests also include location
and tracking of mobile users and admission control in wireless networks.
Mr. Záruba is a student member of COMSOC.

Topology-Transparent Schedules for Energy Limited Ad hoc Networks
Peter J. Dukes
Department of Mathematics
University of Victoria
Victoria, B.C., Canada V8W 3P4
dukes@math.uvic.ca

Charles J. Colbourn and Violet R. Syrotiuk
Department of Computer Science & Engineering
Arizona State University
Tempe, AZ, U.S.A. 85287-8809
{colbourn,syrotiuk}@asu.edu

Abstract
In an ad hoc network, each node can be in one of three
states: asleep (powered down), listening, or transmitting.
Communication is effective only when the sender is transmitting, the destination is receiving, and no other nodes in
proximity to the receiver are also transmitting. Our strategy
makes no assumptions about knowledge of neighbours or
of geographical position; it is topology-transparent. A general combinatorial model for topology-transparent scheduling that treats energy conservation is described. As in the
two state (transmit and receive) case, the combinatorial requirements are met by a D cover-free family. Graph designs, where an arc from vertex x to y indicates an opportunity for x to transmit and y to receive, are proposed as a
model for schedule construction. In order to achieve reasonable throughput while obtaining a dramatic reduction
 a,a designs, where
in energy consumption, we focus on K
the number of nodes transmitting and receiving per slot is
equal to a. Patterned on constructions for resolvable designs, we examine a computational search method to meet
the required combinatorial conditions.

1. Introduction
Of the myriad of media access control (MAC) techniques
for ad hoc networks, our focus is on topology-transparent
approaches where the protocol acts independently of topology change. One class of protocols which may be viewed
as topology-transparent is the contention based MAC protocols.
TDMA is an example of a scheduled access control protocol that is trivially topology-transparent. More sophisticated schemes for generating topology-transparent transmission schedules [3, 12] depend on two design parameters:
N , the number of nodes in the network, and D, the maximum node degree. This creates complex trade-offs between
the design parameters and the delay and throughput charac-

teristics of the resulting schedules. While it is often possible to construct schedules that are signiﬁcantly shorter than
TDMA, if the actual node degree exceeds D, the delay guarantee is lost. More exactly, the delay becomes probabilistic
rather than deterministic. The question of what should be
done if the bound on the number of neighbours is not met is
important (see [4, 7]), but in this paper we assume that this
bound is enforced. By the same token, relaxing from frame
to slot synchronization introduces additional complexities
in topology-transparent schemes [5], but here we treat only
frame synchronized transmission.
The design of lightweight nodes, such as those that may
be used in sensor networks, places demands not only on
throughput and delay but also on energy consumption. Placing nodes in a doze or sleep state conserves energy. Indeed
in [16], statistics for two radios are given. For the ﬁrst, the
radio consumes 15 watts while transmitting and 11 watts
while receiving, but only 0.05 watts when idle. For the second radio, 5.76 watts are needed to transmit and 2.88 to
receive, but only 0.35 watts are needed to remain idle. Listening is expensive.
Running nodes on a duty cycle is one way to achieve energy savings. In S-MAC, contention is used in listen periods
to respond to events [18]. Some approaches also exploit the
redundancy provided by high density, using coordination
among nodes to decide which to put to sleep [13, 15, 2].
However contention appears to produce higher energy consumption than scheduling [11, 16, 17]. These observations
argue that scheduling idle times is a means to reduce energy consumption, but naturally it impacts throughput and
delay as well. In the middle ground is TRAMA, a topology
dependent protocol that exchanges trafﬁc information in a
contention phase in order to compute a schedule [14]. The
performance of such a hybrid is dependent on many parameters, such as the frequency at which the contention phase is
run. Zheng et al. [19] describe a combinatorial method for
minimizing energy consumption in an asynchronous environment when the goal is to maintain connectivity; their approach is not concerned with throughput and does not pro-

Proceedings of the Fourth Annual IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOMW’06)
0-7695-2520-2/06 $20.00 © 2006

IEEE

vide any delay guarantee.
We examine the scheduling of idle times in a way that
maintains a guarantee on delay, provided that a node does
not exceed a designed limit of number of active transmitting neighbours. It requires no coordination among nodes
and, in some sense, requires minimal information. Before
describing a general combinatorial model for scheduling
in this environment, we observe that topology-transparent
schemes can fail when the number of active neighbours becomes larger than the designed limit. One method to handle
large numbers of active neighbours is to control the topology (see [10, 1], for example). Scheduling idle times can
be seen as a way to effect topology control, by selecting in
each time slot a subset of the nodes to participate. Thus it
is a means to limit the number of active neighbours, and
at least potentially enable topology-transparent schemes to
function in a neighbourhood that is too dense if all nodes
are awake.
In our model, energy consumption is directly related to
the number of nodes permitted to transmit, permitted to receive, and required to sleep. We therefore distinguish the
case when a node is awake and permitted to transmit from
awake and permitted to receive. This provides a ﬁner measure than simply distinguishing asleep from awake.
The rest of this paper is organized as follows. In Section
2 the combinatorial requirements of schedules with three
node states are discussed. Section 3 proposes a model for
designing frame schedules using directed graphs. For more
general parameters, a computational method patterned on
constructions for resolvable designs are provided in Section
4. We conclude in Section 5.

2. The Combinatorial Requirements
Let the nodes of the network be V = {1, . . . , n} and let
the time slots be denoted by {1, . . . , m}. A slot schedule is
represented as a partition [T, R, S] of V , where the nodes in
T can transmit, nodes in R are eligible to receive, and the
remaining nodes in S are in a sleep state. A frame schedule
F = {S1 , . . . , Sm } is a set of slot schedules.
Table 1 gives an example frame schedule for 13 nodes.
Rows indicate the schedule for each node, while columns
indicate the state of each node within a time slot. Here,
the length of the frame schedule is also 13. In the ﬁrst
slot S1 the vertices are partitioned into transmitters T1 =
{1, 5, 9}, receivers R1 = {10, 11, 12, 13}, and sleepers
S1 = {2, 3, 4, 6, 7, 8}.
Given a frame schedule F and an ordered pair of distinct nodes (x, y) ∈ V × V , deﬁne σ(x, y) = {j : x ∈
Tj and y ∈ Rj }. That is, σ(x, y) contains those slots
j ∈ {1, . . . , m} in which node x can transmit and node y is
listening. For y ∈ V , let Σ(y) denote the family (multiset)
of sets {σ(x, y) : x ∈ V \ {y}}. For a given node y, Σ(y)

S1
T
S
S
S
T
S
S
S
T
R
R
R
R

S2
R
T
S
S
S
T
S
S
S
T
R
R
R

S3
R
R
T
S
S
S
T
S
S
S
T
R
R

S4
R
R
R
T
S
S
S
T
S
S
S
T
R

S5
R
R
R
R
T
S
S
S
T
S
S
S
T

S6
T
R
R
R
R
T
S
S
S
T
S
S
S

S7
S
T
R
R
R
R
T
S
S
S
T
S
S

S8
S
S
T
R
R
R
R
T
S
S
S
T
S

S9
S
S
S
T
R
R
R
R
T
S
S
S
T

S10
T
S
S
S
T
R
R
R
R
T
S
S
S

S11
S
T
S
S
S
T
R
R
R
R
T
S
S

S12
S
S
T
S
S
S
T
R
R
R
R
T
S

S13
S
S
S
T
S
S
S
T
R
R
R
R
T

Table 1. Example frame schedule
contains, for each node x = y, the set consisting of slots
in which x can transmit and y can receive. For the frame
schedule in Table 1, σ(2, 1) = σ(6, 1) = σ(10, 1) = {2};
σ(3, 1) = σ(7, 1) = σ(11, 1) = {3}; σ(4, 1) = σ(8, 1) =
σ(12, 1) = {4}; σ(5, 1) = σ(9, 1) = σ(13, 1) = {5}.
Hence, Σ(1) contains the sets {2}, {3}, {4}, and {5}, three
times each.
Suppose that a packet is to be sent from node 12 to node
5. In the frame schedule of Table 1, there is a unique slot
σ(12, 5) = {8} (marked in boxes) in which that packet
exchange can happen. Nevertheless it can only happen if
nodes 3 and 8 (also transmitters in S8 ) are not active neighbours of the receiver, node 5.
Evidently a necessary condition for a transmitter x to
reach a particular receiver y is that σ(x, y) be nonempty.
However, the set of nodes T = Tj \ {x} is also transmitting in time slot j. So y may fail to receive the transmission
correctly if a node in T is within its range. Indeed we require that in some slot with y receiving, the only transmitting node within range is x. Our environment is topologytransparent, and hence without further assumptions the only
solution is to have a single transmitter active in each slot.
Although the neighbourhoods are dynamic, suppose that
they remain unchanged during the course of a single frame.
In addition, assume every node has at most D neighbours.
With these assumptions, we can ensure a successful transmission in some frame between any pair of nodes provided
that for all x, y ∈ V , x = y, and any d ≤ D − 1 nodes
x1 , . . . , xd = x,
d


σ(xi , y) ⊃ σ(x, y).

i=1

When d = 0, this requires that the σ(x, y) are all nonempty
for x = y.

Proceedings of the Fourth Annual IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOMW’06)
0-7695-2520-2/06 $20.00 © 2006

IEEE

A collection of subsets {B1 , . . . , B } is a D-cover-freefamily if, for every set Bj with 1 ≤ j ≤ , there are no
other D sets in the collection whose union contains the set
Bj . When the number of sleepers Sj = ∅ for each j, the
requirement given is similar to the topology-transparent approaches with only two states (transmit and receive) introduced in [3, 12] and extended in [7]. To see this, suppose
that nodes do not sleep and consider a potential transmitter
x and receiver y (see Figure 1). Treat the situation from the
viewpoint of the receiver. It has at most D active neighbours, including x. Hence at most D − 1 other active transmitters are within range, and therefore able to collide with
a packet from x to y. Despite this, the node y must itself
be eligible to receive; to ensure this it must be ineligible to
transmit. Node y can receive a packet from node x only if
there is some slot not included in the union of transmission
slots assigned to any of the D − 1 other potential transmitters or to y itself. Thus when the sets of transmission
slots assigned to all nodes form a D-cover-free family, the
existence of a collision-free slot for y to receive from x is
ensured, for each choice of x and y.

i ∈ σ(x, y)
x

y

x

x ∈ Ti
y ∈ Ri
z ∈ Ti
Figure 1. Possible/impossible (solid/dashed)
transmissions in time slot i.
When sleeping is permitted, this analysis from [7] is not
sufﬁcient. Indeed if transmission opportunities are allocated
using a D-cover-free family, we can ﬁnd that the intended
receiver y is sleeping when x has a collision-free transmission opportunity. In the simpler case when all nodes are
awake, node y was ready for reception except when transmitting, and we could therefore treat y simply as another potential transmitter in its own neighbourhood. When nodes
sleep, we must ensure that we restrict our attention to slots
in which y can receive. To accommodate this, we restrict the
members of σ(x, y) to contain only those slots in which y is
a receiver; hence the intended receiver is excluded as a possible transmitter, and we need only be concerned about at
most D−1 possible active neighbours other than the desired
transmitter x. Then it is required that for each y, the family
Σ(y) forms a (D − 1)-cover-free family of {j : y ∈ Rj }.

When nodes do not sleep, it is straightforward to verify
that the requirement that each receiver have an associated
(D − 1)-cover-free family reduces to the requirement that
the set of all transmission opportunities form a D-coverfree family. To see this, when the transmission schedule of
the receiver is incorporated in the union of D − 1 sets to
form a union of D sets, slots remain conﬂict-free exactly
when the intended receiver is prohibited from transmitting
– and hence, in this case, eligible to receive. When nodes
can sleep, this eligibility to receive therefore requires us to
distinguish receivers from non-transmitters, complicating to
an extent the requirements.
This model is very ﬂexible, and the selection of a suitable
frame schedule is challenging. Let tj , rj , and sj be the
number of nodes scheduled in slot j to transmit, receive,
and sleep, respectively, so that tj + rj + sj = n. If we
attribute a cost of τ for a node to transmit in a slot, ρ for it
to receive, and ν for it to sleep, it follows that the energy
consumption per slot is
1 
(τ tj + ρrj + νsj ) .
m j=1
m

This quantity can be viewed as the energy budget per slot
(on average). In fact, this is a simpliﬁcation because powering up from a sleep state requires additional energy, so the
transitions among states could also be attributed a nonzero
cost. We do not pursue that extension here, except to mention that schedule design with many consecutive sleep states
per node is desirable.
Once the numbers of nodes transmitting, receiving, and
sleeping are known for each slot, the construction of a
schedule realizing or closely approximating the desired distribution must be constructed. In what follows, we restrict
our attention to schedule design for ﬁxed numbers t, r, s
with t + r + s = n of nodes transmitting, receiving, and
sleeping, so that for every slot j, tj = t, sj = s, and rj = r.
However, depending on what parameters are of importance,
small variations in these could be allowed, which increase
the ﬂexibility of the constructions.

3. Graph Designs for Schedule Construction
We propose a model for designing frame schedules using
directed graphs. Our goal is to represent the possible sets of
transmitter-receiver pairs in each slot, as subgraphs of the
set of all allowable transmitter-receiver communications. In
each case, an arc from x to y indicates an opportunity for
node x to transmit and node y to receive. We suppose in
advance that every choice of x as transmitter and y = x
as receiver is to occur some speciﬁed number λ of times
 n denote the λ-fold symmetin a frame schedule. Let λK
ric directed multigraph on n vertices: for any two distinct
vertices x and y, there are λ arcs directed from x to y.

Proceedings of the Fourth Annual IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOMW’06)
0-7695-2520-2/06 $20.00 © 2006

IEEE

 a,b be the complete bipartite directed graph in
Let K
which the vertex set is a disjoint union A ∪ B with |A| = a
and |B| = b, and an arc is directed from each vertex of A
to each vertex of B. The vertices in A and B are called outvertices and in-vertices, respectively. Now consider one slot
 t,r
schedule [T, R, S] within a frame schedule. Placing a K
on out-vertex set T , t = |T |, and in-vertex set R, r = |R|,
each arc represents a possible transmission in this slot.
Our goal is to select such directed bipartite graphs (slot
schedules) to form a frame schedule. A basic requirement
is that every arc (transmission opportunity) appear equally
often (λ times). Hence we are interested in speciﬁc sets of
complete bipartite directed graphs, with the property that
every arc appears in exactly λ of the chosen graphs. More
speciﬁcally, let G be an arbitrary directed multigraph. A Gdesign of order n and index λ is a partition of the edges of
 n into copies of G, called blocks.
λK
Viewing the vertices as nodes of an ad hoc network, a
frame schedule in which every pair of nodes has λ time slots
for transmission from x to y is equivalent to (some ordering
 t,r -design of order n and index λ. A
of the blocks of) a K
block having out-vertices A and in-vertices B may be denoted [A, B]. As before, for vertices x = y, deﬁne σ(x, y)
as the set of blocks (time slots) which cover an arc from x
to y so that x is transmitting and y is receiving. For x = y,
we have |σ(x, y)| = λ.
 t,r -design of order n yields a frame schedule for
Any K
n nodes using m slots, where m is the number of blocks
of the design. In order to avoid collisions, we require additional properties. If we wish to tolerate as many as D active
neighbours and ensure a free slot, we impose the
• G LOBAL C ONDITION : for all y, {σ(x, y) : x ∈ V \
{y}} is a (D − 1)-cover-free family.
Now suppose that node y has D active neighbours;
among these we are concerned with reception from a designated transmitter x. We ﬁrst insist that y be eligible
to receive, and then consider the opportunities in σ(x, y).
The global condition ensures that the remaining D − 1 active nodes in the neighbourhood of y cannot combine to
eliminate all opportunities in σ(x, y), and hence there is a
collision-free slot from x to y.
This global condition can be difﬁcult to check efﬁciently,
so we elect to use a more stringent condition that is more
easily veriﬁed, and sufﬁces to ensure that the global condition holds:
• L OCAL C ONDITION : for all y and x = x , |σ(x, y) ∩
σ(x , y)| < λ/(D − 1).
Here, we require that any active neighbour of y other
than x be responsible for collisions with fewer than λ/(D −
1) of the opportunities in σ(x, y). When this happens, the
global condition is met (fewer than (D − 1)λ/(D − 1) = λ

of the opportunities are covered), and there is at least one
collision-free slot for x to reach y. The D-cover-free families employed in [3, 4, 7, 12] meet a similar local condition, and it is shown in the simpler two-state (transmit and
receive) case that the largest cover-free families meet such
a strong local condition. In the three-state case examined
here, it is not known whether imposing the local condition
is more stringent than employing the global one.
The local condition implies the global condition for r <
λ/d. So we regard the global condition as a true measure of
interference at node y; however, in what follows we often
choose to operate with the local condition. When transmitter x and receiver y are to communicate in slot j, as indi a,b for slot j,
cated by the presence of arc (x, y) in the K
they are prevented by doing so exactly when another active transmitter, x , appears among the a transmitters in that
 a,b . Now the number of slots in which x can interfere
K
with the x → y communication is equal to the number of
 2,1 with bipartition [{x, x }, {y}] appears in a
times the K
 a,b -design. In meeting the local condition,
block of the K
then, our goal is to minimize the number of occurrences of
 2,1 . For this purpose, we deﬁne a parameter
any speciﬁc K
 a,b -designs.
of K
 a,b -covering (any collection of
Deﬁnition 3.1 For a K


Ka,b s), its K2,1 -replication number, denoted by r21 , is the
 2,1 as a
maximum number of blocks containing a given K
subgraph.
By counting in two ways the ordered pairs (H, [A, B]),
 2,1 contained in the block [A, B], we have
where H is a K
 2,1 -replication number.
the following lower bound on the K
 a,b -covering of order n with m
Proposition 3.2 In a K
blocks,
ma(a − 1)b
.
r21 ≥
n(n − 1)(n − 2)
For the local condition, we seek to minimize r21 , and
therefore desire equality in the bound of Proposition 3.2.
We close this section with a discussion of the practical
values of a, b, and n for our application. Suppose that every
node has D neighbours on average. It is optimal to maximize the number of (D + 1)-sets of nodes with exactly
one transmitter, one receiver, and the rest sleeping. More
precisely, it is not important whether more neighbours are
receiving; however, for energy conservation the sleep state
is preferred for these neighbours. This quantity is


n−a−b
f (a, b) = ab
,
D−1
a function of two variables a and b. With some elementary
calculations, f (a, b) is maximized for a = b = n/(D + 1).

Proceedings of the Fourth Annual IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOMW’06)
0-7695-2520-2/06 $20.00 © 2006

IEEE

This justiﬁes making the simplifying assumption that the
number of nodes transmitting and receiving per slot are
equal (a = b), and that this common number is chosen
depending on the expected neighbourhood size. For this
 a,a -designs.
reason, we focus on the existence of K

 a,a Designs
4. Constructing K
Evidently a necessary condition for the existence of a
 a,a design of order n and index λ is that a2 (the number
K
of directed edges in a block) evenly divides λn(n − 1) (the
total number of directed edges to be included). Moreover,
considering the number of directed edges with a speciﬁed
vertex x as the in-vertex of the edge, the number a appearing in a block must evenly divide the total, λ(n−1). Conse a,a designs can exist only for some of the paramquently, K
eters of interest. We therefore consider a general strategy
 a,a s on a set of size
for the construction of collections of K
n for which each directed edge appears in approximately
the same number of subgraphs of the collection.
Suppose that V is the set of n nodes, and that n = ρa for
some integer value ρ. Partition the set V into ρ classes, P =
{V1 , . . . , Vρ }, each containing a nodes. Then form ρ(ρ −
 a,a s as follows. For every distinct i and j with 1 ≤
1) K
i, j ≤ ρ, form a directed complete bipartite graph with Vi
as out-vertices and Vj as in-vertices. Consider the directed
edges covered in this way. If two vertices belong to the
same class in the partition, neither directed edge between
them is covered; two vertices not in the same class have
each directed edge between them covered in exactly one of
 a,a s produced.
the K
Repeating this process to form a second partition P  , we
can ask when every directed edge is covered at least once
 a,a s pro(and at most twice) in the union of the sets of K
duced. This is easily determined. Provided that no class
of one partition intersects a class of the other partition in
two or more vertices, every directed edge is covered at least
once.
Indeed forming s partitions P1 , . . . , Ps with the property
that, for 1 ≤ i < j ≤ s, no class of Pi intersects a class
of Pj in two or more vertices, we ﬁnd that every directed
 n occurs in either s − 1 or s of the sρ(ρ − 1)
edge of the λK
 a,a s produced. In such a set of partitions, no two nodes
K
can appear together in classes of more than one partition,
and hence s ≤ n−1
a−1 .
When s is required to be larger, we generalize by enforcing the requirement that for every pair of nodes, the number
of times they appear together in classes in the partitions is
either μ or μ + 1 for some integer μ. Then every directed
 a,a s
edge is covered either s − μ − 1 or s − μ times in the K
produced. In this way, ﬁnding suitable collections of subgraphs can be reduced to ﬁnding appropriate sets of parti-

tions of V .
To ﬁnd such sets of partitions, local optimization strategies such as hill-climbing and tabu search, or exact integer programming methods, can be applied. An heuristic
approach is to choose s random partitions. Then a simple
exchange selects, within a partition, elements from two different classes and swaps them. It is easy to calculate the average number of times that a pair of nodes occurs together
in a class (it is sρa(a−1)
n(n−1) ); the deﬁciency is the number of
pairs whose number of occurrences deviates from this average by at least 1. Simple exchanges are performed to reduce
the total deﬁciency.
We have not, until this point, mentioned the constraints
 2,1 s. A strength of the method proposed is that every
on K

K2,1 can arise in at most μ + 1 of the graphs, and hence the
local condition can be treated in a simpliﬁed manner without explicitly considering triples of nodes. The method can
be further improved by requiring that within the partitions
selected, every three nodes appear together in a class either
τ or τ + 1 times; then the number of occurrences of a spe 2,1 must be μ − τ − 1, μ − τ , or μ − τ + 1.
ciﬁc K
It is natural to ask whether partitions can be found that
 a,a designs, not just decompositions that are nearly
yield K
balanced. This can be done on occasion, using an important
class of combinatorial designs. We explore this next.

4.1. Resolvable Designs
A (n, k, μ) design is a n-set V , together with a collection
of k-subsets of V , or blocks, such that every pair of distinct
elements of V is contained in exactly μ blocks. Observe
that a (n, a, μ) design is, in the terminology of Section 3,
 a -design of order n and index μ.
equivalent to a K
Such a design is resolvable if the collection of blocks
can be partitioned into parallel classes, each of which is a
partition of V . We must have a | n for the existence of a
resolvable design with these parameters. There are μ n−1
a−1
parallel classes. For a = 3 and μ = 1, resolvable designs
(Kirkman triple systems) are known to exist for all n ≡ 3
(mod 6). The afﬁne planes are examples with μ = 1 and
n = a2 , and are known to exist whenever a is a prime-power
[6].
For example, the blocks of the (unique) resolvable
(9, 3, 1) design, arising from the afﬁne plane of order 3, are
given below. Parallel classes are shown as columns.
{0, 1, 2}
{3, 4, 5}
{6, 7, 8}

{0, 3, 6}
{1, 4, 7}
{2, 5, 8}

{0, 4, 8}
{1, 5, 6}
{2, 3, 7}

{0, 5, 7}
{1, 3, 8}
{2, 4, 6}

 3,3 with bipartitions [A, B],
The 4 · 3 · 2 = 24 copies of K
where A = B are chosen from the same column, form

Proceedings of the Fourth Annual IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOMW’06)
0-7695-2520-2/06 $20.00 © 2006

IEEE

 3,3 -design of order 9 and index 3. The K
 2,1 with biaK
partition [{0, 1}, {2}] appears 0 times in this design, while
[{0, 1}, {3}] appears once.
Resolvable designs are the subject of much study; however even when basic necessary conditions are met, their existence remains far from settled [6]; hence while they afford
very powerful constructions when they exist, the techniques
developed for approximate solutions are more general at
the cost of being “less balanced”. Other direct construction
techniques include the use of addition sets [9]. Various indirect (recursive) constructions that respect either the local
or the global constraint appear in [8].

5. Conclusions
In this paper, we have presented the combinatorial conditions for topology-transparent schedules in energy limited
ad hoc networks, i.e., those networks in which nodes may
be in one of three states (transmit, receive, and idle). In general, it is the combinatorial conditions that are interesting, as
they indicate what properties a schedule needs to have to be
effective. Depending on the parameters of importance (e.g.,
high or low proportion of active nodes), desired energy savings, etc., small variations in the conditions on the schedules
should be allowed in order to increase the ﬂexibility of the
constructions. Patterned on constructions for resolvable designs, we examine a computational search method to meet
the required combinatorial conditions.

[8]

[9]

[10]

[11]

[12]

[13]

[14]

[15]

References
[16]
[1] D. M. Blough, M. Leoncini, G. Resta, and P. Santi. The
k-neigh protocol for symmetric topology control in ad hoc
networks. In Proceedings of the 4th ACM International Symposium on Mobile Ad Hoc Networking & Computing (MobiHoc’03), pages 141–152, 2003.
[2] A. Cerpa and D. Estrin.
ASCENT: Adaptive SelfConﬁguring sEnsor Networks Topologies. IEEE Transactions on Mobile Computing, 3(3):272–285, July-September
2004.
[3] I. Chlamtac and A. Faragó. Making transmission schedules
immune to topology changes in multi-hop packet radio networks. IEEE/ACM Transactions on Networking, 2(1):23–
29, February 1994.
[4] I. Chlamtac, A. Faragó, and H. Zhang. Time-spread
multiple-access (TSMA) protocols for multihop mobile radio networks. IEEE/ACM Transactions on Networking,
5(6):804–812, December 1997.
[5] W. Chu, C. J. Colbourn, and V. R. Syrotiuk. Slot synchronized topology-transparent scheduling for sensor networks.
To appear in Computer Communications.
[6] C. J. Colbourn and J. H. Dinitz, editors. CRC Handbook of
Combinatorial Designs. CRC Press, 1996.
[7] C. J. Colbourn, A. C. H. Ling, and V. R. Syrotiuk. Cover-free
families and topology-transparent scheduling for MANETs.

[17]

[18]

[19]

Designs, Codes, and Cryptography, 32(1-3):35–65, May–
July 2004.
P. J. Dukes, C. J. Colbourn, and V. R. Syrotiuk. Directed
complete bipartite graph decompositions: Indirect constructions. To appear in Discrete Mathematics.
P. J. Dukes, V. R. Syrotiuk, and C. J. Colbourn. Directed
complete bipartite graph decompositions and energy-limited
sensor networks. Preprint.
L. Hu. Topology control for multihop packet radio networks.
IEEE Transactions on Communications, 41(10):1471–1481,
1993.
C. E. Jones, K. M. Sivalingam, P. Agarwal, and J.-C. Chen.
A survey of energy efﬁcient network protocols for wireless
and mobile networks. ACM/Baltzer Journal on Wireless Networks, 7:343–358, 2001.
J.-H. Ju and V. O. K. Li. An optimal topology-transparent
scheduling method in multihop packet radio networks.
IEEE/ACM Transactions on Networking, 6(3):298–306,
June 1998.
W. Rabiner Heinzelman, J. Kulik, and H. Balakrishnan.
Adaptive protocols for information dissemination in wireless sensor networks. In Proceedings of the ACM Annual International Conference on Mobile Computing and Networking (Mobicom’99), pages 174–185, 1999.
V. Rajendran, K. Obraczka, and J. J. Garcia-Luna-Aceves.
Energy-efﬁcient, collision-free medium access control for
wireless sensor networks. In Proceedings of the 1st ACM
Conference on Embedded Networked Sensor Systems (SenSys’03), pages 181–192, 2003.
C. Schurgers, V. Tsiatsis, S. Ganeriwal, and M. Srivastava.
Topology management for sensor networks: Exploiting latency and density. In Proceedings of the Third International
Symposium on Mobile Ad Hoc Networking and Computing
(MobiHoc’02), pages 135–145, 2002.
S. Singh and C. S. Rahavendra. PAMAS — power aware
multi-access protocol with signalling for ad hoc networks.
ACM Computer Communication Review, pages 5–26, July
1998.
A. Woo and D. E. Culler. A transmission control scheme
for media access in sensor networks. In Proceedings of the
7th Annual International ACM Conference on Mobile Computing & Networking (MobiCom’01), pages 221–235, July
2001.
W. Ye, J. Heidemann, and D. Estrin. An energy-efﬁcient
MAC protocol for wireless sensor networks. In Proceedings
of the 21st Annual Joint Conference of the IEEE Computer
and Communications Societies (Infocom’02), volume 3,
pages 1569–1576, 2002.
R. Zheng, C.-J. Hou, and L. Sha. Asynchronous wakeup for
ad hoc networks. In Proceedings of the International Conference on Mobile Ad Hoc Networking & Computing (Mobihoc’03), pages 35–45, 2003.

Proceedings of the Fourth Annual IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOMW’06)
0-7695-2520-2/06 $20.00 © 2006

IEEE

Ad Hoc Networks 11 (2013) 1782–1795

Contents lists available at SciVerse ScienceDirect

Ad Hoc Networks
journal homepage: www.elsevier.com/locate/adhoc

Using local conditions to reduce control overhead
Kahkashan Shaukat, Violet R. Syrotiuk ⇑
School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ 85287-8809, United States

a r t i c l e

i n f o

Article history:
Received 20 August 2012
Received in revised form 13 March 2013
Accepted 8 April 2013
Available online 17 April 2013
Keywords:
Control overhead
Local conditions
Control chart

a b s t r a c t
In this paper, we replace the periodic transmission of control information by transmissions
that depend on local network conditions. As a case study, we consider the proactive link
state routing protocol OLSR running in a wireless network without infrastructure. Each
node maintains a time series on its betweenness, a metric widely used in social network
analysis. We interpret an anomaly in a node’s time series as a change in its role and use
it to trigger the transmission of link state. In order to ensure throughput does not degrade
by the use of dated information, we use a keep-alive timer whose interval takes into
account other local conditions including the node speed, packet arrival rate, and number
of ﬂows served. We also measure the number of local link breaks and use it to trigger
the transmission of neighbour information. ns-2 simulations comparing our proposed
A+-OLSR to OLSR, A-OLSR, and Adaptive OLSR show a statistically signiﬁcant increase in
throughput and a decrease in control overhead. Our evaluation also considers packet losses
and the use of CRAWDAD wireless traces to drive node movement.
Ó 2013 Elsevier B.V. All rights reserved.

1. Introduction
Most protocols transmit control information as part of
their operation. Some examples include the negotiation
to access a broadcast channel in IEEE 802.11, and the handshakes used for connection management in TCP. The control information is overhead to protocol operation,
consuming bandwidth that could otherwise be used for
data. In some cases, control information is generated periodically. Our interest is to replace such periodic transmission by transmissions triggered by changes in local
network conditions, with the joint goal of reducing the
overhead of a protocol and improving its performance.
For this purpose we study a proactive link state routing
protocol in a mobile ad hoc network (MANET), a collection
of mobile wireless nodes that self-organize without the
aid of any ﬁxed infrastructure or centralized control.
Open Shortest Path First (OSPF) is a link state routing protocol widely used in the Internet. In OSPF, each node periodically exchanges link state and uses it for route computation.
⇑ Corresponding author.
E-mail addresses: kshaukat@asu.edu (K. Shaukat), syrotiuk@asu.edu
(V.R. Syrotiuk).
1570-8705/$ - see front matter Ó 2013 Elsevier B.V. All rights reserved.
http://dx.doi.org/10.1016/j.adhoc.2013.04.003

Link state routing protocols have also been developed for
MANETs. The Optimized Link State Routing (OLSR) [1] protocol is one such example and we use it for our study.
OLSR uses two control messages: HELLO and topology
control (TC) messages. A HELLO message contains a node’s
one-hop neighbours, and its multi-point relay (MPR) set.
Together, the MPR sets form a connected dominating set
(CDS) of the network that is used to implement an efﬁcient
network-wide broadcast of the link state [2,3]. A TC message contains the links between a node and its multi-point
relay selector set (MSS). An MSS for a node serving as an
MPR consists of those nodes that have selected it as an
MPR. TC messages provide sufﬁcient topology information
for route computation. By default, in OLSR every node
transmits a HELLO message every 2 s (the HELLO_Interval);
the default TC_Interval is 5 s.
Rather than transmitting control messages periodically,
we propose the A+-OLSR protocol that instead uses local
network conditions to make these transmission decisions.
Our hypothesis is that a transmission decision driven by
signiﬁcant changes in the local neighbourhood or topology
should lead to a reduction in control overhead and an increase in total throughput.

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795

Several ideas to reduce control overhead in OLSR have
been proposed. Ros and Ruiz [4] develop Clustered OLSR
(C-OLSR). C-OLSR reduces control overhead by partitioning
the network into clusters, and restricting the propagation
of TC messages to a cluster. In Hierarchical OLSR (HOLSR)
[5], nodes exchange TC messages with a frequency that depends on the distance, called a ‘‘ﬁsheye’’ technique [6].
Speciﬁcally, TC messages from nodes that are further away
are received less frequently forming a hierarchy based on
distance. We do not introduce clusters or hierarchy of
any form into our A+-OLSR protocol.
Qin and Kunz [7] present Adaptive OLSR in which each
node measures the number of link breaks it experiences in
the last 3 s. If the number is greater than a threshold, it
interprets the link breaks as due to high mobility and increases the rate at which HELLO messages are transmitted.
Adaptive OLSR also changes the computation of the MPR
set, restricting the number of nodes in the set to two nodes.
The result is the possibility that the MPR sets do not form a
CDS and hence may not implement a correct network-wide
broadcast. Our proposed A+-OLSR protocol incorporates
monitoring of the link breaks to decide the frequency of
HELLO messages but – importantly – does not change the
MPR computation.
Xue et al. [8] reduce overhead by changing the content
of the control messages and how they are sent. The HELLO
messages only advertise those neighbours that have changed during the HELLO_Interval. To reduce redundancy in
the transmission of TC messages, only one node sends a
TC message in scenarios where a group of nodes has chosen each other as MPRs. Our A+-OLSR protocol does not
use incremental messages, but does restrict the transmission of TC messages to those nodes actively forwarding
data.
In order to replace the periodic transmission of TC messages with transmissions triggered by changes in local network conditions, the ﬁrst step is to select a local metric to
monitor. (While our focus is on communication overhead,
there may also be a cost to instrumenting nodes to collect
such data and to process it.) Since TC messages are transmitted by MPRs, a metric that determines if a node is an
MPR at a given point in time is required. The literature
on social network analysis uses betweenness to identify
nodes that are ‘‘central’’ in the network (see e.g., [11]).
More precisely, in a graph G = (V, E), the betweenness of a
vertex v 2 V is the ratio of the number of shortest paths
from s to t that go through v, over the total number of
shortest paths from s to t, for all s, t 2 {Vnv}, s – t [10].
The larger the ratio, the more paths v lies on, increasing
v’s importance in routing As we will see in Section 4.1,
nodes that have high betweenness are selected as MPRs.
In general, computing the betweenness of v is expensive: O(jVj3) using the Floyd–Warshall all-pairs shortest
paths algorithm [12]. Because each node v running OLSR
already maintains its two-hop neighbourhood for MPR
computations, we can compute betweenness of v in the
two-hop neighbourhood graph without transmitting any
additional control information. Therefore, in our proposed
A+-OLSR protocol, we monitor betweenness of v in its twohop neighbourhood using an exponentially weighted moving
average (EWMA) control chart. This is different from the

1783

Shewhart chart used in our earlier work [9] because it is
better suited to detect small changes in the monitored
characteristic [13].
Each node keeps a time series of its betweenness and
monitors it using an EWMA control chart. An anomaly signalled by the control chart is interpreted as a change in the
network topology signiﬁcant enough to transmit a TC message to notify neighbours of the change. In A+-OLSR, TC
messages are transmitted only by MPRs with packets to
forward.
We also incorporate the use of other local network
conditions into A+-OLSR. Speciﬁcally, the interval of a
keep-alive timer, set each time the timer goes off, takes
into account a node’s current speed, packet arrival rate,
and the number of ﬂows that it serves. Response surface
methodology (RSM) [14], a collection of statistical design
and numerical optimization techniques, is used to optimize the timer interval.
We ﬁrst evaluate our A+-OLSR protocol using ns-2
simulations to establish the usefulness of local conditions
in reducing control overhead and improving throughput.
We then introduce realism in our simulations by modelling packet losses and using real wireless traces from the
Community Resource for Archiving Wireless Data At Dartmouth (CRAWDAD) [15] to model node mobility. Our
experimentation compares our A+-OLSR protocol to OLSR,
and to other approaches to reduce control overhead in
OLSR. The results show that A+-OLSR reduces the control
overhead by 21.43–44.28% and increases the throughput
by 0.74–17.63%; both measures are statistically signiﬁcant. A+-OLSR also outperforms the other protocols in
the presence of packet losses and in trace-driven
scenarios.
In summary, the contribution of this paper is a routing
protocol A+-OLSR for MANETs that uses local conditions
to make transmission decisions for control overhead. Speciﬁcally, A+-OLSR uses:
 the anomalies of a time series on betweenness to trigger
the transmission of TC messages instead of transmitting
them periodically,
 a keep-alive timer, whose interval is optimized considering local state, to refresh TC state, and
 the number of local link breaks to set the
HELLO_Interval.
Our results support our hypothesis, that the use of local
conditions to drive the transmission of control information
reduces the control overhead and improves throughput by
a margin that is statistically signiﬁcant.
The remainder of this paper is organized as follows. Section 2 describes the transmission of HELLO and TC messages in our proposed A+-OLSR protocol. The technical
details of the techniques of statistical process control and
response surface methodology used by A+-OLSR are described in Section 3. An empirical analysis of betweenness
and MPR selection, and other analyses that support our design decisions in A+-OLSR, is given in Section 4. An evaluation of the performance of A+-OLSR in simulation is
provided in Section 5. Finally, we conclude and propose future work in Section 6.

1784

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795

2. The A+-OLSR protocol
Identical to OLSR, the A+-OLSR protocol uses two control
messages: HELLO and topology control (TC) messages to
disseminate neighbourhood and topology information for
the computation of MPR sets and routes, respectively. Different from OLSR is the decision of when to transmit each
message. We start by describing the transmission of each
control message in A+-OLSR.

overhead in OLSR, Adaptive OLSR achieves the best known
gains in throughput. However as we shall see in Section 5,
in situations when nodes never transition out of the Default
state, any gain in throughput must come from reducing
other overhead. TC messages make up the majority of the
total control overhead, hence reducing the transmission
of TC messages appears to be the only option. We propose
using local conditions to decide when to transmit a TC
message next.

2.1. Transmission of HELLO messages in A+-OLSR

2.2. Transmission of TC messages in A+-OLSR

The transmission of a HELLO message in A+-OLSR follows
the Adaptive OLSR algorithm [7]. In it, each node is in one of
the three states based on the number of link breaks it experiences in the last 3 s: Default, Fast-Response, or Fast-OLSR.
Fig. 1 shows the transitions among these states.
Each node starts in the Default state where it transmits
HELLO messages as in OLSR. If it experiences a number of
link breaks greater than an upper threshold, it interprets
them as due to high mobility and transitions to the FastOLSR state. Nodes in this state transmit newly introduced
Fast-HELLO messages twice as fast as HELLO messages, i.e.,
every 1 s. On receipt of a Fast-HELLO message, a node in
the Default state transitions to the Fast-Response state,
responding with empty HELLO messages. Similar to a node
in the Default state, a node in the Fast-Response state can
transition to the Fast-OLSR state. When a node in the Fast-Response state has no Fast-OLSR neighbours, its transitions
back to the Default state. A node in the Fast-OLSR state transitions back to the Default when the number of link breaks
falls below a lower threshold.
Different from Adaptive OLSR, our proposed A+-OLSR
protocol follows OLSR [1] for MPR computation to ensure
that a connected dominating set (CDS) of the network is
constructed; this is required to ensure a correct networkwide broadcast of TC messages.
We incorporate Adaptive OLSR’s HELLO message transmission into A+-OLSR because, of efforts to reduce control

In A+-OLSR, each node uses an EWMA chart to monitor
the betweenness of its current two-hop neighbourhood,
sending a TC message only when an anomaly is signalled.
We restrict the transmission of TC messages in this manner
to only those nodes forwarding packets of a ﬂow. However,
this alone may result in poor throughput as now, too many
routes time-out causing packets to be dropped. In order to
reach a balance in reducing control overhead and achieving
high throughput, each node also keeps routes fresh by
using a keep-alive timer, sending TC messages at its expiration. These messages introduce network activity that result in updating the route calculation, which promotes
successful routing. The algorithm to transmit a TC message
is presented in Algorithm 1; the notation used in the algorithm is described in Table 1.
Table 1
Notation used in Algorithm 1.
TC_TIMER(v)
isForwardingNode(v)
isSignalEWMA(betweenness(v))

MSS(v)
KEEP_ALIVE_TIMER(v)

true if the TC timer at node v has
expired (every TC_Interval)
true if node v is generating or
forwarding data packets
true if the EWMA chart on
betweenness at v signals out-ofcontrol
the MPR selector set of node v
true if the keep-alive timer at node
v has expired

Fig. 1. Transition state diagram for adaptive OLSR HELLO message transmission (adapted from [7]).

1785

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795

Algorithm 1. A+-OLSR algorithm to transmit TC messages
at node v
1. if TC_TIMER(v) has expired then
2. set TC_TIMER(v)
3. calculate betweenness of v in two-hop
neighbourhood
4. if isForwardingNode(v) then
5.
if isSignalEWMA(betweenness(v)) then
6.
forall i 2 MSS(v) do
7.
transmit TC message
8.
end for
9.
end if
10. end if
11. end if
12. if KEEP_ALIVE_TIMER(v) has expired then
13. look-up KEEP_ALIVE_TIMER interval in table
14. set KEEP_ALIVE_TIMER(v)
15. if MSS(v) = ; then
16.
transmit empty TC message
17. else
18.
forall i 2 MSS(v) do
19.
transmit TC message
20.
end for
21. end if
22. end if

The details of the statistical process control underlying
the use of the EWMA chart (line 5), and the response surface methodology used to optimize the keep-alive timer
(line 13) in Algorithm 1, are now described.
3. Technical details of A+-OLSR
3.1. Statistical process control
Statistical process control (SPC) is a collection of statistical techniques to monitor the performance of a system or
process to determine if it has shifted away from some
nominal operating state (the in-control state); see [13,
Chapter 10] for details.
A control chart is the basic tool used in SPC for monitoring control characteristics. It plots the sample, and the corresponding upper and lower control limit (UCL and LCL), as a
function of time. When a sample is within the control limits, the system is assumed to be in-control and no action is
required. A sample that is outside the control limits is evidence that the system is out-of-control and corrective measures are required to return the system to a desirable
operating state.
A Shewhart chart monitors the sample mean over time
and is useful in detecting relatively large shifts in the
mean. To detect a small deviation from the in-control state,
an exponentially weighted moving average (EWMA) control
chart is more effective [13].
The sample zt at time t of an EWMA chart is deﬁned as
an exponential average of xt, the measured characteristic at
time t, weighted by 0 6 k < 1: zt = kxt + (1  k)zt1, t P 1;
z0 = x0. The upper and lower control limits of an EWMA

qﬃﬃﬃﬃﬃﬃ

qﬃﬃﬃﬃﬃﬃ

r0ﬃﬃ
r0ﬃﬃ
k p
k p
chart are deﬁned as l0 þ K 2k
and l0  K 2k
,
n
n
respectively, where l0 and r0 are the sample mean and
sample standard deviation of the characteristic being monitored, and n is the number of samples. The values of k and
K can be tuned to achieve a speciﬁc average run length
(ARL) [16,17]. The ARL is the average number of time steps
before a sample indicates an out-of-control condition.

3.1.1. Using an EWMA chart on betweenness
In A+-OLSR, each node computes the betweenness xt of
its two-hop neighbourhood every TC_Interval. From xt
the sample zt is obtained. However, rather than using all
samples, each node uses only the samples in a sliding window of size 20. The values of l0 and r0 are computed for
the samples in the window.
When used for quality control of an industrial system,
EWMA charts are tuned to have large in-control ARLs because a false alarm may be very costly if it requires stopping the process. In our experience, a MANET may be
monitored differently from an industrial system. In particular, a smaller ARL is not detrimental to the network. An
out-of-control signal, or anomaly, triggers the transmission
of TC messages which, in turn, update routes through the
network. The network does not need to be stopped when
an anomaly is detected because protocol parameters may
be updated on-the-ﬂy. A false alarm may even be beneﬁcial
because it causes routes to be refreshed; of course, the cost
is a network-wide broadcast of the TC message. We set k to
0.05 since this value detects small deviations [13]. We then
use Monte-Carlo simulations to ﬁnd suitable values of K given k using the methodology proposed by Crowder [16].
Table 2 shows the results of Crowder’s methodology to
tune K given k = 0.05 and the resulting in-control ARLs for
various node speeds. For example, at a node speed of 2 m/s,
we expect a signiﬁcant change in the topology every 15
samples, i.e., every 15  TC_Interval. The in-control ARLs
are smaller for lower node speeds and increase as speed increases, but start decreasing at a node speed of 20 m/s.
Though increasing values of the ARL for higher node speeds
is somewhat counter-intuitive, recall that the control limits depend on the mean and standard deviation of the samples. The control limits of the EWMA chart are farther apart
for higher node speeds; this explains why the ARLs are
increasing.
3.2. Response surface methodology
We use Response Surface Methodology (RSM) [14] to
optimize the keep-alive timer interval based on local network conditions. RSM is a collection of statistical design
and numerical optimization techniques.
3.2.1. Screening experiments for the keep-alive timer
Our interest is to ﬁnd out how the factors of node speed,
packet arrival rate, number of ﬂows serviced, and keepalive timer interval affect the performance metrics (or, responses) of throughput and TC overhead. We select these
factors because each one may be measured (or estimated)
locally at a node; of course, these are not the only factors,
locally measurable or otherwise, that may impact throughput and TC overhead.

1786

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795

Table 2
In-control ARL and corresponding K values for node speeds 2–20 m/s for
k = 0.05.
Node speed (m/s)

In-control ARL

K

2
5
10
15
20

15
18
30
36
33

0.9178
1.0000
1.2550
1.3500
1.3000

Table 3
Factors and their extremal values.
Factor

Factor name

Minimum

Maximum

A
B
C
D
E

Node speed
Packet arrival rate
Number of ﬂows
Keep-alive timer
Number of nodes

5 m/s
2 pkts/s
1
10 s
20

25 m/s
28 pkts/s
25
40 s
100

We use screening experiments [18] to determine how
the factors and their interactions affect the responses.
The Design Expert software [19] is used to create a
face-centered central composite design [14] for this purpose; this design has 52 experiments, and each is replicated with 10 different seeds. Table 3 lists the factors of
the screening experiment and their minimum and maximum values.
The simulations are carried out in ns-2 [20]; the
duration of each simulation is 500 s. Each simulation
consists of the design speciﬁed number of nodes uniformly distributed in a 1000  1000 m2 area. Each node
is equipped with an omni-directional antenna with a
transmission range of 250 m. The physical channel uses
the two-ray ground propagation model with a 2 Mbps
channel capacity. For these screening experiments, the
steady state random waypoint model [21] is used to gen-

erate the node movement patterns; pause-time is set to
zero for continuous node mobility. Source–destination
pairs, each establishing a ﬂow, are selected randomly;
their number depends on the design point. Each source
transmits 512 byte UDP packets at a constant bit rate
(CBR). The responses measured in the simulations are
provided as input to Design Expert, which is then used
to perform an analysis of variance (ANOVA), evaluating
the signiﬁcance of the terms to the response. Throughput
is the number of bits delivered successfully from a
source to a destination divided by the time taken in
transmission. TC overhead is the total number of TC
messages transmitted throughout the data transmission
period.
Table 4 gives the ANOVA results for each response; only
the signiﬁcant terms are listed. The R2 values for throughput and TC overhead are 0.8648 and 0.9568, respectively.
Factor A (node speed) has a very large (61.66%) contribution to throughput; factors B, C, and E contribute 9.46%,
8.27%, and 3.34%, respectively. Of interest, the keep-alive
timer interval (D) is not signiﬁcant for throughput. For TC
overhead, factor E (number of nodes) contributes 60.46%;
factors D, C, and A contribute 8.73%, 4.4% and 2.41%, respectively. Some two-way interactions of factors affect TC overhead but not throughput.
Design Expert also ﬁts a model for each response
using the method of least squares. It gives the following
models for throughput (T) and TC overhead (TCO):

T ¼ 82:73  0:86A þ 0:04B þ 0:37C þ 0:25E

ð1Þ

TCO ¼ 3907:67  1221:46A  2071:5C þ 677:72D
þ 1464E þ 84:79AC þ 41:53AE  42:58BC
þ 48:79BD þ 48:86CE  40:39DE

ð2Þ

We also investigated the performance of a quadratic model
for throughput also obtained from the Design Expert
software. However this model had an R2 of 0.69 and an

Table 4
ANOVA results for throughput and TC overhead; only the signiﬁcant terms are listed.
Source

Sum of squares

Degrees of freedom

Mean square

(a) Throughput
A
B
C
E
R2

34391.49
7807.75
6826.56
2760.14
0.8648

1
1
1
1

34391.49
7807.75
6826.56
2760.14

Adjusted R2

0.8546

(b) TC overhead
A
C
D
E
AC
AE
BC
BD
CE
DE
R2

4.06  1010
7.41  1010
1.47  1011
1.019  1012
1.66  1010
4.41  1010
7.06  109
1.45  1010
8.80  1010
9.40  1010
0.9568

1
1
1
1
1
1
1
1
1
1

4.06  1010
7.42  1010
1.47  1011
1.02  1012
1.66  1010
4.41  1010
7.06  109
1.45  1010
8.80  1010
9.4  1010

Adjusted R2

0.9538

F value

p-value Prob > F

Percentage contribution

669.36
151.96
132.86
53.72

<0.0001
<0.0001
<0.0001
<0.0001

61.66
9.46
8.27
3.34

95.38
174.00
345.51
2391.55
38.86
103.58
16.57
33.98
206.51
220.43

<0.0001
<0.0001
<0.0001
<0.0001
<0.0001
<0.0001
<0.0001
<0.0001
<0.0001
<0.0001

2.41
4.40
8.73
60.46
0.98
2.62
0.42
0.86
5.22
5.57

1787

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795
Table 5
Look up table for keep-alive timer intervals given node speed and number
of ﬂows serviced; optimized for a network with 50 nodes and a packet
arrival rate of 10 pkts/s. (See Section 5.3 for a robustness study.)
Node speed
(m/s)

1 Flow (s)

2 Flows (s)

5 Flows (s)

10 Flows (s)

2
5
10
15
20

14.65
13.20
11.49
10.50
12.12

16.27
15.01
12.95
12.50
15.20

17.82
16.03
14.26
14.50
16.80

19.21
18.16
16.90
17.10
18.65

adjusted R2 of 0.68, both lower than the linear model indicating that the lower order model is a better choice.
3.2.2. Optimization of the keep-alive timer
We use the method of Simultaneous Perturbation Stochastic Approximation Steepest Ascent (SP(SA)2) [22], a hybrid multi-objective optimization algorithm, to jointly
optimize throughput, TC overhead, and the packet loss ratio. SP(SA)2 works well when models exist for some responses but are unavailable for others. In this case, we
have empirical models for throughput and TC overhead
(Eqs. (1) and (2)) but not for the packet loss ratio.
Table 5 lists the results of applying the SP(SA)2 algorithm. It gives optimized keep-alive timer intervals for a given node speed and number of ﬂows, for 50 nodes in a
1000  1000 m2 area, and a packet arrival rate of 10 pkts/
s. The keep-alive timer decreases as node speed increases,
but starts increasing at speed 20 m/s; the timer value increases when more ﬂows are added. At higher speeds,
more TC messages need to be transmitted to maintain updated routes, thus the keep-alive timer interval is smaller
to keep up with changes in the topology. When more ﬂows
are added to the network, more nodes are actively serving
ﬂows and hence more nodes are transmitting TC messages
using the EWMA chart. As a result, a larger keep-alive
timer interval is able to keep the routes up-to-date. As
we will see in Section 5, the timer intervals are robust to
changes in the number of nodes and the area they occupy,
their mobility, and the packet arrival rate.
4. An empirical analysis of A+-OLSR
Before presenting our evaluation of the A+-OLSR protocol, we analyze aspects of its behaviour empirically and
show its effectiveness in reducing control overhead.
4.1. Betweenness and the role of MPR
For each node speed, we randomly choose ﬁve nodes
and trace their betweenness, whether they serve in the
role of an MPR, and the size of their MPR selector set
(MSS) over the simulation. A small sample of the results
for a node speed of 15 m/s is given in Table 6. The results
reveal that nodes with higher betweenness do serve as
MPRs. Consequently, these nodes also have an MPR selector set (MSS) of non-zero size. Since A+-OLSR chooses nodes
with high betweenness in their local neighbourhoods as
MPRs, and MPRs transmit TC messages, these results lend

Table 6
For each time, for ﬁve selected nodes, betweenness, whether the node
serves as an MPR, and its MPR selector set size are tabulated.
Time

Node ID

Betweenness

MPR?

194.7 s

7
13
25
39
43

0.467
0.182
1.920
0.155
0.183

Yes
No
Yes
No
No

MSS size
4
0
6
0
0

294.6 s

7
13
25
39
43

1.539
0.783
1.727
2.918
0.178

Yes
Yes
Yes
Yes
No

8
7
7
12
0

319.6 s

7
13
25
39
43

1.513
0.491
0.025
1.785
0.491

Yes
Yes
No
Yes
Yes

10
3
0
10
4

342.3 s

7
13
25
39
43

1.736
1.738
0.020
2.593
1.738

Yes
Yes
No
Yes
Yes

10
10
0
9
10

422.9 s

7
13
25
39
43

0.056
0.757
0.926
0.370
0.757

No
Yes
Yes
No
Yes

0
4
4
0
3

support to our strategy of monitoring betweenness to reduce control overhead.
4.2. TC message transmission in A+-OLSR
Fig. 2 shows EWMA charts on betweenness for nodes 13
and node 39 from Table 6. Node 13 has an average
betweenness of 0.60, is selected as an MPR 50.33% of the
simulation time, and has an average MSS size of 4.06.
Though the chart in Fig. 2a shows betweenness exceeding
the UCL for node 13, these anomalies do not trigger the
transmission of TC messages because node 13 does not forward any data packets during the simulation. On the other
hand, node 39 has an average betweenness of 1.03, is selected as an MPR 81.03% of the simulation time, and has
an average MSS size of 6.10. Unlike node 13, node 39 forwards data packets 25.50% of the simulation time. In particular, node 39 forwards data packets from time 288.3 s
to 390.1 s. The chart in Fig. 2b signals outside of this time
period, however TC messages are only transmitted when
the EWMA generates a signal during the period node 39
is actually forwarding data. Depending on the number of
ﬂows in the simulation, node 39 transmits TC messages
for around 8.00–19.40% of the data transmission period.
4.3. TC overhead
Table 7 shows the average size of TC messages transmitted by a node in OLSR, A+-OLSR, and Adaptive OLSR.
In the case of A+-OLSR, nodes transmit TC messages when
the EWMA chart signals and the node is forwarding data
(EWMA TC), and when the keep-alive timer expires

1788

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795
1.8

3.5

Betweenness

1.6

Betweenness
TC msg sent

3

Betweenness

Betweenness

1.4
1.2

UCL
1
0.8
0.6

2.5
2

UCL

1.5

End Data Fwd

1

Start Data Fwd

0.4
0.5

0.2

LCL

LCL
0
100

150

200

250

300

350

400

450

500

0
100

150

200

250

300

350

Time

Time

(a) Node 13.

(b) Node 39.

400

450

500

Fig. 2. EWMA charts on betweenness for two random nodes. Node 39 transmits TC messages only when the EWMA signals and the node has data to
forward. In this scenario, node 13 never has data to forward.

Table 7
The percentage difference (D) in the size in bytes of TC messages transmitted by A+-OLSR and Adaptive OLSR compared to OLSR. In A+-OLSR, the size of TC
messages is the sum of the keep-alive TC and EWMA TC messages.
Node Speed (m/s)

2
5
10
15
20

OLSR

A+-OLSR

TC (bytes)

Keep-alive TC (bytes)

EWMA TC

D (%)

TC (bytes)

D (%)

2576
2809
3080
3731
3306

852
888
1168
1284
996

106
112
64
44
108

62.81
64.40
60.00
64.40
66.61

2108
1932
2212
1704
1108

18.17
31.22
28.18
54.33
66.49

(keep-alive TC). We collect data from the trace ﬁles of at
least ﬁve random nodes in each simulation scenario. We
see that, on average, a node sends 60.00–66.61% fewer bytes in TC messages in A+-OLSR compared to OLSR. (Some of
these nodes forward data for only a tiny fraction of the
simulation time.) Moreover, the average size of their MSSs
are small and vary widely, impacting the number of bytes
transmitted as keep-alive TC and EWMA TC messages. The
smaller size of TC messages for Adaptive OLSR arises from
the restrictions imposed on the MPR set of a node by the
protocol [7]; in Fast-OLSR mode it can select only two
MPRs. Moreover, only a Fast-Response node can be chosen
as an MPR. Thus, at higher speeds, fewer nodes forward
TC messages, resulting in reduced TC overhead in Adaptive
OLSR compared to OLSR.
4.4. Modes of operation
We now collect data on the percentage of time a node
stays in each of the three different modes of operation
(Default, Fast-OLSR, and Fast-Response; recall Fig. 1) from
the trace ﬁles of at least ﬁve random nodes in each simulation scenario. Table 8 shows that number of link
breaks perceived by a node is directly related to its
speed. On average, at a node speed of 2 m/s, a node stays
in Fast-OLSR and Fast-Response modes at most 2.30% and
5.40% of the simulation time, respectively. As node speed
increases, the nodes transition to Fast-OLSR and Fast-Response modes more often. In Fast-OLSR mode, nodes

Adaptive OLSR

transmit Fast-HELLO messages to update the connectivity
information twice as frequently. As a result, MPR computation and route updates occur more often. As a side effect, the betweenness at each node reﬂects the new and
updated connectivity information, triggering the transmission of TC messages more accurately. Since the MPR
sets are refreshed, the forwarding of TC messages is also
more accurate.
5. Evaluation of A+-OLSR
The ns-2 network simulator [20] with extensions for
wireless mobility is used to evaluate the performance of
A+-OLSR and compare it with OLSR [1], A-OLSR [9], and
Adaptive OLSR [7]. Throughput, control overhead, TC overhead, control overhead per data packet, and the average
end-to-end delay are measured. Throughput and TC overhead are deﬁned in Section 3.2.1. Control overhead is the
total bandwidth consumed by sending HELLO and TC messages, while control overhead per data packet is the ratio of
the control overhead to the total number of data packets
transmitted successfully. End-to-end delay is the time taken for a packet to be transmitted from the source of the
ﬂow to its destination; this is averaged over all the data
packets transmitted successfully. We ﬁrst present simulation results run using the random waypoint mobility model, followed by the results considering packet loss, and
then the results using the real wireless mobility trace ﬁles
provided by CRAWDAD [15].

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795
Table 8
The percentage of time a node stays in each of the three modes Default,
Fast-OLSR, and Fast-Response during the simulation period for the given
node speed.
Node speed

Mode

Time in mode (%)

2 m/s

Default
Fast-OLSR
Fast-response

92.3–99.6
0.0–2.3
0.4–5.4

5 m/s

Default
Fast-OLSR
Fast-response

44.7–67.7
6.8–14.9
23.8–40.4

10 m/s

Default
Fast-OLSR
Fast-response

16.6–23.7
24.3–34.5
42.4–52.0

15 m/s

Default
Fast-OLSR
Fast-response

7.8–13.9
38.1–50.5
40.6–48.0

20 m/s

Default
Fast-OLSR
Fast-response

3.6–8.2
27.2–67.3
28.6–69.1

Table 9
Simulation parameters.
Parameters

Values

Simulator
OLSR implementation
MAC protocol
Conﬁdence interval
Simulation area
Nodes
Transmission range
Channel bandwidth
Simulation duration

ns-2 version 2.29
um-olsr-0.8.8
IEEE 802.11b
95%
1000  1000 m2
50
250 m
2 Mbps
500 s (100 s warm-up, 400 s data
collection for A+- and A-OLSR)
Stationary random waypoint,
CRAWDAD mobility trace ﬁles
Constant bit rate (CBR)
512 bytes
10 pkts/s for random waypoint,
100 pkts/s for CRAWDAD
2, 5, 10, 15, and 20 m/s
1, 2, 5, and 10
0%, 1%, 2%, and 5%
0.05

Mobility model
Trafﬁc type
Packet size
Packet arrival rate
Node speed
Number of ﬂows
Packet loss rates
k

5.1. Results for the random waypoint mobility model
For A+-OLSR and A-OLSR, the ﬁrst 100 s of the simulation is used to initialize the sliding window of the EWMA
and Shewhart control charts, respectively. No data is transmitted during this time. Each node uses a sliding window
with 20 samples to calculate the current zt (recall the discussion in Section 3.1.1). The samples are updated every
TC_Interval. For the remaining 400 s of the simulation each
ﬂow transmits data packets during which performance
metrics are collected. Table 9 gives the simulation parameters considered.
In A+-OLSR, each node performs a look-up in a table
similar to Table 5 to tune its keep-alive timer based on current node speed, packet arrival rate and the number of
ﬂows it services.
Fig. 3a plots the throughput for OLSR, A-OLSR, Adaptive
OLSR, and A+-OLSR. Compared to OLSR, the throughput for

1789

A-OLSR drops by 0.76–5.75%. The Shewhart chart for AOLSR is not tuned to a speciﬁc node speed and hence its
performance is poor and affects the transmission of data
packets due to routes being outdated. Adaptive OLSR
shows a remarkable increase in throughput for higher
speeds; its throughput increases by 1.96–12.42% compared
to OLSR. For lower speeds, throughput for Adaptive OLSR
decreases by as much as 1.00%. A+-OLSR outperforms all
the other protocols, increasing throughput by 0.74–
17.63% compared to OLSR. Both Adaptive and A+-OLSR
use Fast-HELLO and empty HELLO messages to keep the
network connectivity updated. Thus, their MPRs and routes
are fresher compared to OLSR and A-OLSR. Since, these two
protocols transmit fewer TC messages, there is less contention for and collision on the wireless channel, and more
data packets are transmitted successfully.
Fig. 3b plots control overhead. A-OLSR shows a 22.70–
33.80% decrease in control overhead from OLSR. Adaptive
OLSR shows an increase in control overhead for lower
speeds (2 and 5 m/s) by 0.44–2.66%; the decrease in control overhead is 7.67–49.62% for higher speeds. The increase is a result of the modes of operation. Even though,
nodes stay in Fast-OLSR and Fast-Response modes for
0.00–14.9% (see Table 8) of the time, they transmit FastHELLO and empty HELLO messages twice as frequently
and thus incur the extra overhead. Also, at lower speeds
the protocol is unable to take advantage of the restriction
on MPR sets. A+-OLSR outperforms all the protocols for
lower speeds (up to 5 m/s for A-OLSR and to 10 m/s for
Adaptive OLSR); it transmits 21.43–44.28% less control
overhead than OLSR. Adaptive OLSR has the highest savings in terms of control overhead at 20 m/s. Since it restricts its MPR set size to two for nodes in Fast-OLSR
mode and allows only Fast-Response nodes to be selected
as MPRs, many fewer TC messages are sent. A+-OLSR does
not impose this restriction and hence its control overhead
is larger than Adaptive OSLR for higher speeds. Even
though A+-OLSR sends more control overhead than A-OLSR
and Adaptive OLSR for higher speeds, its throughput is
higher.
Fig. 3c shows the TC overhead incurred for the four protocols under consideration. It shows the same trend as total control overhead because TC overhead contributes the
majority to the total. The TC overhead for A+-OLSR includes
both the keep-alive TC and EWMA TC messages. From Table 7 we see that A+-OLSR sends 60.00–66.61% fewer bytes
as messages.
Fig. 3d plots the number of control packets transmitted
for each successful data packet transmission. A-OLSR sends
22.82–36.86% less control overhead per data packet compared to OLSR. Adaptive OLSR shows an increase in control
overhead per data packet for lower speeds. Since control
overhead for Adaptive OLSR is higher for lower speeds,
its control overhead per data packet increases by 0.45–
1.25%. Adaptive OLSR reduces control overhead per data
packet by 8.65–54.29% for higher speeds. A+-OLSR outperforms all the protocols up to 15 m/s. Adaptive OLSR has the
best performance for 20 m/s speed as it reduces the control
overhead per data packet by 54.29%. At 20 m/s, nodes stay
in Fast-OLSR mode for almost 27.20–67.30% time. As a

1790

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795
40

Control Overhead (Kbps)

35

Throughput (Kbps)

160

OLSR
A-OLSR
A+-OLSR
Adaptive OLSR

30

25

20

15

10
5

10

15

100

80

60

20

2

5

10

15

Speed

Speed

(a) Throughput

(b) Control overhead
70

OLSR
A-OLSR
A+-OLSR
Adaptive OLSR

Control Packets per Data Packet

TC Overhead (Kbps)

120

120

40
2

140

140

OLSR
A-OLSR
A+-OLSR
Adaptive OLSR

100

80

60

40

20

60

20

OLSR
A-OLSR
A+-OLSR
Adaptive OLSR

50
40
30
20
10
0

2

5

10

15

20

2

5

10

15

20

Speed

Speed

(c) TC overhead

(d) Control packets per data packet

250

Delay (ms)

200

OLSR
A-OLSR
A+-OLSR
Adaptive OLSR

150

100

50

0

-50
2

5

10

15

20

Speed

(e) Average end-to-end delay
Fig. 3. Performance of A+-OLSR compared to OLSR, A-OLSR, and Adaptive OLSR: 1 data ﬂow with a packet arrival rate of 10 pkts/s using the random
waypoint mobility model (and no packet loss).

result, many more nodes take advantage of the restrictions
imposed on Fast-OLSR mode and send fewer TC messages.
Fig. 3e plots the average end-to-end delay. When compared to OLSR, A-OLSR reduces the delay 4.33–61.65% with
the highest saving at 10 m/s. In the case of Adaptive OLSR,
delay increases slightly for 2 m/s and shows a 34.81–

72.89% decrease for other speeds; it also has the highest
saving at 10 m/s. A+-OLSR has a 14.99–54.05% decrease in
delay; it is better than the other two protocols for lower
speed, but for higher speeds Adaptive OLSR performs the
best. Since fewer packets in Adaptive OLSR contend for
the wireless channel, there are fewer collisions due to

1791

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795

Table 10
Throughput (T) and control overhead (CO) of OLSR, and the percentage difference from OLSR for A-OLSR, Adaptive-OLSR, and A+-OLSR: 1 data ﬂow with a packet
arrival rate of 10 pkts/s using the random waypoint mobility model (no packet loss).
Node speed (m/s)

2
5
10
15
20

OLSR

A-OLSR

A+-OLSR

Adaptive OLSR

T (Kbps)

CO (Kbps)

DT

DCO (%)

DT (%)

DCO (%)

DT (%)

DCO (%)

37.43
30.18
24.65
20.83
16.72

103.53
116.28
133.16
149.07
156.11

3.44
0.76
5.16
1.24
5.75

26.07
24.10
22.70
28.92
33.80

0.06
1.00
+1.96
+12.42
+9.25

+0.44
+2.66
7.67
32.54
49.62

+0.74
+1.00
+4.67
+17.63
+15.89

44.28
35.31
21.43
30.07
41.28

Table 11
Throughput (T) and control overhead (CO) of OLSR with a packet loss rate of 0%, and the percentage difference from OLSR with OLSR, A-OLSR, Adaptive-OLSR,
and A+-OLSR each with a packet loss rate of 5%: 1 data ﬂow with a packet arrival rate of 10 pkts/s using the random waypoint mobility model.
Node speed (m/s)

2
5
10
15
20

OLSR (0% Loss)

OLSR (5% Loss)

A-OLSR (5%)

T (Kbps)

CO (Kbps)

DT

DCO

DT

37.43
30.18
24.65
20.83
16.72

103.53
116.28
133.16
149.07
156.11

12.09
10.34
12.58
9.03
12.31

+10.00
+8.78
+9.26
+9.33
+8.05

15.62
13.63
10.42
7.53
10.85

sending fewer TC messages; the data packets that reach
their destination do so very quickly.
The results for throughput and control overhead for
these simulations are summarized in Table 10.
We also conducted simulations with two, ﬁve, and ten
data ﬂows and found that the results follow the same
trends as those presented for a single data ﬂow, hence
we do not present them here.
5.2. Results with packet loss
When there is no packet loss, slowing down the frequency of TC message transmission may not have a negative impact on the performance of the protocols under
consideration. A side effect of packet loss is less redundancy in topology updates and this may have an adverse
affect on the performance. We run ns-2 simulations with
1%, 2%, and 5% packet loss rates for node speeds of 2, 5,
10, 15, and 20 m/s using the random waypoint mobility
model. Since the results with packet loss follow essentially
the same trend as in Fig. 3, we provide a summary of the
results for a 5% packet loss rate in Table 11.
5.3. Results with real wireless trace ﬁles based on human
movements
We also ran simulations on real wireless trace ﬁles obtained from the Community Resource for Archiving Wireless
Data at Dartmouth (CRAWDAD) [15]. The traces were collected from ﬁve different sites consisting of two university
campuses, North Carolina State University (NCSU) and Korea Advanced Institute of Science and Technology (KAIST),
New York City, Disney World at Orlando, and the North
Carolina State Fair. We use four of the ﬁve traces in our
simulations; we selected only one campus (NCSU). The
traces were collected using Garmin GPS 60CSx handheld

Adaptive OLSR (5%)

A+-OLSR (5%)

DCO

DT

DCO

DT

DCO

25.95
23.46
22.60
27.92
31.10

12.29
10.69
4.32
+0.10
2.40

+12.88
+6.07
20.58
30.85
49.88

12.48
8.07
3.42
+2.82
+7.35

49.18
40.99
28.41
35.39
45.32

receivers. These GPS receivers are capable of a position
accuracy better than three meters 95% of the time.
Each GPS receiver takes a reading of its current position
every 10 s. The time, and the x and y coordinates from a
reference point, are recorded into a daily track log. The
log may contain a discontinuity when the GPS bearer
moves indoors where the signal cannot be received. Each
ﬁle represents a daily trace from one participant; one participant can make multiple daily trace ﬁles. Since the data
is anonymized, we are unable to tell which ﬁles belong to
the same person and have thus treated them as ﬁles
belonging to different people. We convert the trace ﬁles
from the tuple htime, x, yi to the ns-2 compatible mobility
ﬁle format where each node starts from an initial location
(x0, y0) at time t0 = 0 and reaches (x1, y1) at time t1 with a
speciﬁc speed. The node speed is calculated based on the
distance the node travels from time t0 to t1. Every 10 s
these calculations are made and recorded in the ns-2 compatible mobility ﬁle.
The participants in NCSU campus [23] traces were randomly selected students who took courses in the Computer
Science department. Every week, two or three randomly
chosen students carried a GPS receiver for their regular
daily activities.
The New York City (NYC) [24] traces were obtained
from eight volunteers living in Manhattan and its vicinity.
Most of the participants were ofﬁce workers in Manhattan.
Their traces contain relatively long distance travels because of their long commutes. Their means of travel include subway trains, buses, and mostly walking.
The Disney World (DW) [25] traces were obtained from
four volunteers who spent their Thanksgiving or Christmas
holidays at Disney World. For our study, we use only traces
from inside of the theme park. The participants mainly
walked in the park and occasionally rode trolleys.
The North Carolina State Fair (NCSF) [26] traces were
collected from eight volunteers who visited a local state

1792

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795

Throughput (Kbps)

146

342

OLSR
A+-OLSR
A-OLSR
Adaptive OLSR

340
338

Throughput (Kbps)

148

144
142
140
138

OLSR
A+-OLSR
A-OLSR
Adaptive OLSR

336
334
332
330
328
326

136

324

134

322

(a) North Carolina State University (NCSU)
84

326

OLSR
A+-OLSR
A-OLSR
Adaptive OLSR

80

324
322

Throughput (Kbps)

Throughput (Kbps)

82

(b) New York City (NYC)

78
76
74
72

OLSR
A+*-OLSR
A-OLSR
Adaptive OLSR

320
318
316
314
312
310
308

70

306

68

304

(c) Disney World (DW)

(d) North Carolina State Fair (NCSF)

Fig. 4. Throughput comparison of OLSR and its variants for four CRAWDAD traces: 1 data ﬂow with a packet arrival rate of 100 pkts/s.

fair including many arcades, food stalls, and showcases.
The site is completely outdoors and is the smallest among
the four sites. Each participant in the NCSF scenario spent
less than 3 h at the site.
The simulation results are shown in Figs. 4 and 5 and
are tabulated in Table 12. A+-OLSR outperforms all the
other protocols by achieving higher throughput and lower
control overhead. This illustrates the robustness of the
control charts; they were tuned for 50 nodes moving using
the random waypoint mobility model in a 1000  1000 m2
area, and a packet arrival rate of 10 pkts/s. Yet, the control
charts are effective under the realistic mobility models and
a much higher packet arrival rate. For the NCSU trace ﬁle,
where 35 nodes move in an area of 14,629  9715 m2,
the A-OLSR and A+-OLSR protocols show a 4.82% and
5.41% increase in throughput, respectively, while Adaptive
OLSR shows a 1.80% decrease. Adaptive OLSR has the same
control overhead as OLSR while A-OLSR and A+-OLSR show
a decrease of 1.64% and 14.26%, respectively. In this scenario, the nodes move with speed 0.68–22.99 m/s; most
of the time the node speed was between 1 and 4 m/s. Since
the traces were sampled every 10 s, none of the nodes
switched to Fast-OLSR mode and Adaptive OLSR was not
able to beneﬁt. A+-OLSR transmits fewer TC messages due
to each node monitoring its betweenness using an EWMA
chart.

The NYC trace ﬁle consists of 39 nodes moving in an
area of 31,569  19,600 m2. When using this trace ﬁle AOLSR incurs 4.25% more overhead than OLSR while achieving 5.38% more throughput. Adaptive OLSR and A+-OLSR
reduce the control overhead by 1.03% and 7.29%, respectively; the increase in throughput is 0.22% and 5.40%,
respectively. Some nodes representing the buses and subways in this trace ﬁle move with an average speed of
7.68 or 12.52 m/s while others move around 0.96 to
3.56 m/s; parts of the network were partitioned and resulted in poor overall throughput. Since the traces were
collected every 10 s, Adaptive OLSR and A+-OLSR do not
change modes.
In the case of the DW trace ﬁle, there are 41 nodes that
move in an area of 15,423  17,935 m2. When compared to
OLSR, A-OLSR, Adaptive OLSR, and A+-OLSR increase
throughput by 12.38%, 6.53%, and 20.74%, respectively.
The savings in control overhead for A-OLSR and A+-OLSR
is 5.14% and 13.95%; Adaptive OLSR incurs 0.10% more
overhead compared to OLSR. The source and destination
nodes are approximately 3 hops away from each other;
A+-OLSR ﬁnds better paths for longer distances because
link state is correctly broadcast by the MPRs. The average
speed of the nodes is 4.14 m/s but some nodes move from
19.84 to 23.6 m/s; some parts of the network are disconnected and consequently do not contribute to successful

1793

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795
11.8

11.4

OLSR
A+-OLSR
A-OLSR
Adaptive OLSR

9.1

Control Overhead (Kbps)

11.6

Control Overhead (Kbps)

9.2

OLSR
A+-OLSR
A-OLSR
Adaptive OLSR

11.2
11
10.8
10.6
10.4
10.2

9
8.9
8.8
8.7
8.6

10
9.8

8.5

(a) North Carolina State University (NCSU)
OLSR
+
A -OLSR
A-OLSR
Adaptive OLSR

14.5

14

13.5

13

13.4

OLSR
+
A -OLSR
A-OLSR
Adaptive OLSR

13.2

Control Overhead (Kbps)

Control Overhead (Kbps)

15

(b) New York City (NYC)

13
12.8
12.6
12.4
12.2

12.5

12

(c) Disney World (DW)

(d) North Carolina State Fair (NCSF)

Fig. 5. Control overhead comparison of OLSR and its variants for four CRAWDAD traces: 1 data ﬂow with a packet arrival rate of 100 pkts/s.

Table 12
Throughput (T) and control overhead (CO) of OLSR, and percentage difference from OLSR for A-OLSR, Adaptive-OLSR, and A+-OLSR: 1 data ﬂow with a packet
arrival rate of 100 pkts/s for the four CRAWDAD mobility traces.
Trace

NCSU
NYC
DW
NCSF

OLSR

A-OLSR

A+-OLSR

Adaptive OLSR

T (Kbps)

CO (Kbps)

DT (%)

DCO (%)

DT (%)

DCO (%)

DT (%)

DCO (%)

139.69
324.11
68.34
314.23

11.56
9.18
14.56
13.23

+4.82
+5.38
+12.38
0.02

1.64
+4.25
5.14
8.96

1.80
+0.22
+6.53
2.76

0.00
1.03
+0.1
+0.18

+5.41
+5.40
+20.74
+3.24

14.26
7.29
13.90
5.82

data transmission. There is very little change in the modes
for the Adaptive OLSR and A+-OLSR protocols.
The NCSF trace ﬁle consists of 19 nodes in a
1045  1021 m2 area. Simulations using the NCSF trace ﬁle
shows that A+-OLSR increases the throughput by 3.24% and
saves 5.82% control overhead. While A-OLSR saves around
8.96% in control overhead, its throughput decreases by
0.02%. Adaptive OLSR performs the worst in this scenario;
its throughput decreases by 2.76% while its control overhead increases by 0.18%. The source–destination pair is
approximately 4 hops away from each other and the nodes
move relatively slowly. Once again, A+-OLSR performs better when the paths are longer.

6. Conclusions and future work
Rather than transmitting control information periodically as in OLSR, each node in A+-OLSR: (1) checks the frequency of its link breaks to decide when to transmit a
HELLO message; (2) monitors betweenness of its two-hop
neighbourhood graph using an EWMA chart to decide
when to transmit a TC message; and (3) uses a keep-alive
timer to keep routes updated. The number of link breaks
corresponds well to changes in mobility while changes in
betweenness correlate with changes in the MPR sets. Using
local conditions, A+-OLSR reduces the control overhead by
21.43–44.28% with an increase in throughput of

1794

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795

0.74–17.63%. The end-to-end delay is also reduced. We
introduce realism to the ns-2 simulations by modelling
packet losses and ﬁnd that A+-OLSR performs the best for
higher mobility scenarios. We also run simulations using
real wireless traces and ﬁnd that A+-OLSR outperforms
the other protocols especially in multi-hop routing.
It is interesting that the EWMA ARLs and the keep-alive
timer for A+-OLSR are tuned for the random waypoint model, yet they perform well without further tuning when used
with the real wireless traces. Perhaps k and K are not
dependent on the mobility model but rather on whether
the movement causes topological changes. A study of the
sensitivity of the ARLs would be interesting.
Adaptive OLSR has a slight edge over A+-OLSR for higher
node speeds. We conjecture that this is because it limits
the size of the MPR set to two. This might have important
consequences to the success of network-wide broadcast in
networks with a large number of nodes since a node’s twohop neighbourhood may no longer be reached through the
MPR set. This deserves more investigation under different
density and mobility scenarios, and networks of larger size
(area and number of nodes).
The use of local conditions could be incorporated into
other aspects of A+-OLSR. For example, the HELLO and
Fast-HELLO intervals are currently set globally. Indeed,
the use of local conditions to set parameters of operation
is a general idea from which many protocols could beneﬁt.
When checking for change in mobility, the number of
link breaks is compared to an arbitrary threshold. Instead,
the value of the threshold can be based on node speed.
One assumption is that the observations made with
control charts are independent. These charts do not work
as well if the monitored characteristic exhibits even low
levels of correlation. They may signal too many false
alarms if the data are positively correlated. Studying
whether the betweenness measure exhibits any auto-correlation is worthwhile. This may provide yet another
opportunity to decrease control overhead.
While the screening experiments (Section 3.2.1) were
performed for node speeds of 5, 10, 15, and 20 m/s, the results include simulations run at 2 m/s to ﬁnd out how the
protocol operates at lower speeds. It would be interesting
to perform additional simulations with higher speeds
(25 m/s and higher) to observe the extrapolative behaviour
of A+-OLSR.
We considered node speed, packet arrival rate, and
number of ﬂows serviced by a node while building empirical models. All these factors affect the network layer.
Since, there is a 21.43–44.28% decrease in the control overhead transmitted in A+-OLSR, one can expect that the freed
bandwidth can be used to route more data packets and
achieve a higher throughput. Though the increase in the
throughput is signiﬁcant for higher speeds, a question
arises as to whether there are some cross-layer interactions at work in protocol performance. The ANOVA results
in Section 3.2.1 do not suggest the factors considered interact to affect throughput. However, other factors than those
considered may be at work. More investigation is required
in this area to determine what cross-layer interactions may
have a signiﬁcant affect on throughput.

In general, our research shows the potential of using local conditions to make transmission decisions to reduce
control overhead and improve throughput. We believe
there are many opportunities to exploit such local conditions in network protocols.
Acknowledgments
We thank Doug Montgomery for his advice in applying
SPC, Martha Streenstrup for her careful editing, and the
anonymous referees whose reviews led to a deeper analysis of our results.
References
[1] T.H. Clausen, P. Jacquet, Optimized Link State Routing Protocol, RFC
3626,
October
2003.
<http://www.hipercom.inria.fr/olsr/
rfc3626.txt>.
[2] A. Qayyum, L. Viennot, A. Laouiti, Multipoint Relaying: An Efﬁcient
Technique for Flooding in Mobile Wireless Networks, Tech. Rep.
INRIA RR-3898, National Institute for Research in Computer Science
and Control, Rocquencourt, France, 2000.
[3] P. Jacquet, A. Laouiti, P. Minet, L. Viennot, Performance Analysis of
OLSR Multipoint Relay Flooding in Two Ad Hoc Wireless Network
Models, Tech. Rep, INRIA RR-4260, National Institute for Research in
Computer Science and Control, Rocquencourt, France, September
2001.
[4] F.J. Ros, P.M. Ruiz, Cluster-based OLSR extensions to reduce control
overhead in mobile ad hoc networks, in: Proceedings of the
International Conference on Wireless Communications and Mobile
Computing, 2007, pp. 202–207.
[5] L. Ming, G. Zhao, G. Xie, X. Kuang, HOLSR: a novel routing scheme of
ad hoc wireless networks for pervasive computing, in: Proceedings
of the 2nd International Conference on Pervasive Computing and
Applications (ICPCA’07), 2007, pp. 661–666.
[6] G. Pei, M. Gerla, T.-W. Chen, Fisheye state routing: a routing scheme
for ad hoc wireless networks, in: Proceedings of the IEEE
International Conference on Communications (ICC’00), 2000, pp.
70–74.
[7] L. Qin, T. Kunz, Adaptive MANET routing: a case study, in:
Proceedings of the 7th International Conference on Ad Hoc, Mobile
and Wireless Networks (AdHoc Now’08), Sophia-Antipolis, France,
September 10–12, 2008, Lecture Notes in Computer Science, vol.
5198/2008, Springer, 2008, pp. 43–57.
[8] Y. Xue, H. Jiang, H. Hu, Rough Sets and Knowledge Technology,
Springer Link, 2008.
[9] K. Shaukat, V.R. Syrotiuk, Using monitoring to control a proactive
routing protocol, Ad Hoc & Sensor Wireless Networks 6 (3–4) (2008)
299–319.
[10] L.C. Freeman, A set of measures of centrality based on betweenness,
Sociometry 40 (1) (1977) 35–41.
[11] B. Wellman, S.D. Berkowitz, Social Structures: A Network Approach,
Cambridge University Press, Cambridge, 1988.
[12] R.W. Floyd, Algorithm 97: shortest path, Communications of the
ACM 5 (6) (1962) 345.
[13] D.C. Montgomery, Introduction to Statistical Quality Control, sixth
ed., John Wiley & Sons, Inc., Hoboken, New Jersey, USA, 2008.
[14] R.H. Myers, D.C. Montgomery, C.M. Anderson-Cook, Response
Surface Methodology: Process and Product Optimization using
Designed Experiments, third ed., John Wiley & Sons, Inc., Hoboken,
New Jersey, USA, 2009.
[15] Dartmouth College, A Community Resource for Archiving Wireless
Data at Dartmouth. <http://www.crawdad.cs.dartmouth.edu/>.
[16] S.V. Crowder, Design of exponentially weighted moving average
schemes, Journal of Quality Technology 21 (3) (1989) 155–162.
[17] J.M. Lucas, M.S. Saccucci, Exponentially weighted moving average
control schemes: properties and enhancements, Technometrics 32
(1) (1990) 1–12.
[18] D.C. Montgomery, Design and Analysis of Experiments, seventh ed.,
John Wiley & Sons, Inc., Hoboken, New Jersey, USA, 2009.
[19] Stat Ease, Inc., Design-Expert Software, 2011. <http://
www.statease.com>.
[20] The University of California, Berkeley, The Network Simulator – ns-2.
<http://www.isi.edu/nsname/ns/>.

K. Shaukat, V.R. Syrotiuk / Ad Hoc Networks 11 (2013) 1782–1795
[21] W. Navidi, T. Camp, Stationary distributions for the random
waypoint model, IEEE Transactions on Mobile Computing 3 (1)
(2004) 99–108.
[22] D.W. McClary, V.R. Syrotiuk, M. Kulahci, Steepest-ascent constrained
simultaneous perturbation for multi-objective optimization,
Transactions on Modeling and Computer Simulation 21 (2011)
2:1–2:22.
[23] I. Rhee, M. Shin, S. Hong, K. Lee, S. Kim, S. Chong, CRAWDAD Trace
ncsu/mobilitymodels/GPS/NCSU
(v.
2009-07-23).
<http://
www.crawdad.cs.dartmouth.edu/ncsu/mobilitymodels/GPS/NCSU>.
[24] I. Rhee, M. Shin, S. Hong, K. Lee, S. Kim, S. Chong, CRAWDAD Trace
ncsu/mobilitymodels/GPS/NYC
(v.
2009-07-23).
<http://
www.crawdad.cs.dartmouth.edu/ncsu/mobilitymodels/GPS/NYC>.
[25] I. Rhee, M. Shin, S. Hong, K. Lee, S. Kim, S. Chong, CRAWDAD Trace
ncsu/mobilitymodels/GPS/Disney_World (v. 2009-07-23). <http://
www.crawdad.cs.dartmouth.edu/ncsu/mobilitymodels/GPS/
Disney_World>.
[26] I. Rhee, M. Shin, S. Hong, K. Lee, S. Kim, S. Chong, CRAWDAD Trace
ncsu/mobilitymodels/GPS/NC_State_Fair (v. 2009-07-23). <http://
www.crawdad.cs.dartmouth.edu/ncsu/mobilitymodels/GPS/
NC_State_Fair>.

Kahkashan Shaukat earned her B.S. in Computer Science from Bangladesh University of
Engineering and Technology in 2002, and her
M.S. and Ph.D. in Computer Science from
Arizona State University in 2005 and 2012,
respectively.
Her research interests include the use of timeseries analysis in mobile ad hoc networks.

1795

Violet R. Syrotiuk earned her Ph.D. in Computer Science from the University of Waterloo
(Canada). She joined Arizona State University
in 2002 and is an Associate Professor of
Computer Science and Engineering.
Her research has been supported by grants
from NSF, ONR, DSTO (Australia) and contracts with LANL, Raytheon, General Dynamics, and ATC.
She serves on the editorial boards of Computer Networks, Computer Communications,
and the International Journal of Communication Systems, as well as on the technical program and organizing committees of several major conferences sponsored by ACM and IEEE.

Journal of Discrete Algorithms 16 (2012) 170–186

Contents lists available at SciVerse ScienceDirect

Journal of Discrete Algorithms
www.elsevier.com/locate/jda

Strengthening hash families and compressive sensing ✩
Charles J. Colbourn a,∗ , Daniel Horsley b , Violet R. Syrotiuk a
a
b

Computing, Informatics, and Decision Systems Engineering, Arizona State University, P.O. Box 878809, Tempe, AZ 85287, USA
School of Mathematical Sciences, Monash University, Victoria 3800, Australia

a r t i c l e

i n f o

Article history:
Available online 3 April 2012
Keywords:
Compressive sensing
Hash family
Column replacement
Stein–Lovász–Johnson theorem
Lovász local lemma

a b s t r a c t
The deterministic construction of measurement matrices for compressive sensing is a challenging problem, for which a number of combinatorial techniques have been developed.
One of them employs a widely used column replacement technique based on hash families. It is effective at producing larger measurement matrices from smaller ones, but it
can only preserve the strength (level of sparsity supported), not increase it. Column replacement is extended here to produce measurement matrices with larger strength from
ingredient arrays with smaller strength. To do this, a new type of hash family, called a
strengthening hash family, is introduced. Using these hash families, column replacement is
shown to increase strength under two standard notions of recoverability. Then techniques
to construct strengthening hash families, both probabilistically and deterministically, are
developed. Using a variant of the Stein–Lovász–Johnson theorem, a deterministic, polynomial time algorithm for constructing a strengthening hash family of ﬁxed strength is
derived.
© 2012 Elsevier B.V. All rights reserved.

1. Introduction
Sparse measurement, testing, and location problems abound. Locating a small number of defectives in a large population (combinatorial group testing [31]), learning a function with few relevant attributes [27], locating a fault in a large
component-based software system (software interaction testing [49]), and recovering a sparse signal from a ‘small’ set of
samples (compressive sensing [2]) have much in common. In each case, many factors (coordinates, attributes) can each be
set to one of a set of values (levels) to form a test (sample). Selected tests can then be run to determine an outcome, or
measurement. From the resulting measurements, we are to ﬁnd signiﬁcant factors, and in some cases signiﬁcant interactions
among the factors. Of course, the details in each case mentioned vary substantially, but the basic framework is the same.
In each of the cases mentioned, we are to construct arrays in which each row is a test; arrays with the fewest rows for
the speciﬁed number of columns are always preferred. When the interactions to be found involve few of the factors (say
at most t), the tests must together only reveal interactions of size t or less; this is the strength of the array required. Now
when the strength is ﬁxed, in each of the problems mentioned, elementary probabilistic arguments show that the number
of tests needed grows as the logarithm of the number of factors. This underpins a substantial focus on sparsity in testing
and measurement.
While probabilistic techniques provide the correct asymptotics for each problem mentioned, actual problems require the
explicit construction of arrays of tests. Hence explicit, deterministic constructions are of interest. This has been best examined in the software interaction testing domain. There, while probabilistic techniques yield the best results asymptotically,

✩

*

A preliminary version of some of this paper appears in Colbourn (2011) [21].
Corresponding author.
E-mail addresses: colbourn@asu.edu (C.J. Colbourn), danhorsley@gmail.com (D. Horsley), syrotiuk@asu.edu (V.R. Syrotiuk).

1570-8667/$ – see front matter © 2012 Elsevier B.V. All rights reserved.
http://dx.doi.org/10.1016/j.jda.2012.04.004

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

171

a combination of computational methods, direct constructions using ﬁnite ﬁelds and ﬁnite groups, and recursive constructions, yields substantially smaller arrays when the number of factors is in the hundreds or thousands [20]. Computation
in that case is effective for tens or hundreds of factors, but the workhorses in producing the best known array sizes are
recursive constructions that make larger arrays from smaller ones.
A major recursive construction uses a pattern matrix P to select columns from a small array A (or more generally a
set { A i } of small arrays) to construct a larger array. For this column replacement technique (developed in more detail in
Section 3) to produce an array of tests that treats more factors, at the same strength, one needs to ensure that the pattern
matrix selects suitable sets of columns. Thus the pattern array must exhibit a certain combinatorial structure; fortunately,
the required structure is already well studied in the guise of hash families. Hash families and their variants have been
explored for numerous applications (see [20,26,52], for example), among them applications in hashing [45].
The application of column replacement is pervasive, being used in software interaction testing [20], hash families [5],
and even compressive sensing [22]. Presently the most serious limitation of column replacement techniques is that, from
ingredient arrays of strength t, the larger array produced is also of strength t. Thus, although the number of factors may
increase dramatically, the strength remains unchanged. Put another way, to employ column replacement to make an array
of large strength, one needs ingredient arrays of large strength. This is one main reason why arrays for software interaction
testing have been studied primarily for strengths of at most 6.
The main contribution of this paper is the extension of column replacement to make arrays of larger strength from arrays
with smaller strength. To do this, we extend the deﬁnitions of hash families to incorporate a strengthening requirement,
which – as one should expect – is precisely what is needed for column replacement to increase the strength. We select
compressive sensing to illustrate strengthening in the construction of measurement matrices, generalizing the previous
column replacement technique; similar illustrations can be found in the other problem domains. We establish the required
results on recoverability using two standard recovery schemes, and examine the effect of column replacement on the socalled ‘restricted isometry property’ (RIP) parameters.
For the method to be more than a curiosity, we must construct strengthening hash families. We establish that two
well known probabilistic techniques, the Lovász local lemma and the Stein–Lovász–Johnson method, produce both effective asymptotic results and probabilistic algorithms. A careful analysis of the Stein–Lovász–Johnson approach enables us
to develop an algorithm meeting the logarithmic bound on the number of tests whose running time is polynomial in the
number of factors, when the strength is ﬁxed. A small set of computational results demonstrate that the method developed
is effective.
The remainder of the paper is organized as follows. Section 2 formally deﬁnes a general notion of hash families, as well
as several variants including the extension to strengthening hash families. Section 3 develops the use of such hash families
in the construction of measurement matrices for compressive sensing. In particular, the basics of compressive sensing for
0 - and 1 -recovery are developed in Section 3.1; column replacement for measurement matrices using separating and
distributing hash families is introduced in Section 3.2; column replacement is extended to strengthening hash families in
Section 3.3; and the impact of column replacement on the RIP parameters is examined in Section 3.4. Because strengthening
hash families must be constructed in order to make these column replacement strategies effective, the remainder of the
paper treats their construction. The Lovász local lemma is used in Section 4 to develop asymptotic existence results, and
both deterministic and probabilistic methods for their construction. Section 5 instead applies the Stein–Lovász–Johnson
method to develop asymptotic existence results and a probabilistic algorithm. Section 6 then establishes that, for a wide
variety of types of hash families, including strengthening hash families of ﬁxed strength, the Stein–Lovász–Johnson method
can be implemented to run in polynomial time in the number of columns. Section 7 reports a limited set of computational
results on strengthening hash families from an implementation of this method. Finally, Section 8 draws relevant conclusions.
2. Strengthening hash families
Let N, k, and v be positive integers. A hash family HF( N ; k, v ), A = (ai j ), is an N × k array, in which each cell contains
one symbol from a set Σ of v symbols. We generalize this standard deﬁnition by replacing v by v = ( v 1 , . . . , v N ), a tuple
of positive integers. A hash family HF( N ; k, v), A = (ai j ), is an N × k array, in which each cell contains one symbol, and
for 1  ρ  N, |{aρ j : 1  j  k}|  v ρ . When v 1 = · · · = v N = v (i.e., the array is homogeneous), we recover the standard
deﬁnition.
Nevertheless, we permit heterogeneity, i.e., we allow that v i and v j are not necessarily equal when i = j, because it is
useful in certain applications of hash families in column replacement techniques [20,23,24], one of which we develop in
Section 3.
Many variants of hash families have been studied. An HF( N ; k, v), A = (ai j ), is
perfect of strength t: denoted PHF( N ; k, v, t ), when for every set C of at most t columns, there exists a row ρ for which
|{aρ c : c ∈ C }| = |C | (see [1,52], for example);
s
{ w 1 , w 2 , . . . , w s }-separating: denoted SHF( N ; k, v, { w 1 , w 2 , . . . , w s }), if whenever C is a set of
i =1 w i columns and
C 1 , C 2 , . . . , C s is a partition of C with |C i | = w i for 1  i  s, there exists a row ρ for which aρ x = aρ y whenever
x ∈ C i , y ∈ C j and i = j (see [6,53], for example).

172

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

→

↓

↓

↓

0
0
1
2
2

1
2
0
0
0

2
1
0
1
2

2
0
2
1
1

1
2
2
2
2

2
2
2
0
1

2
2
1
2
0

0
1
1
0
2

1
0
2
1
2

1
1
1
1
1

0
2
0
2
1

0
1
2
1
0

2

0

1

2

1

1

2

2

0

1

2

1

Fig. 1. A homogeneous perfect hash family PHF(6; 12, 3, 3).

↓

→

↓

↓

1
1

1
2

1
3

1
4

2
1

2
2

2
3

2
4

3
1

3
2

3
3

3
4

4
1

4
2

4
3

4
4

1

2

3

4

2

1

4

3

3

4

1

2

4

3

2

1

Fig. 2. A homogeneous {1, 2}-separating hash family SHF(3; 16, 4, (1, 2)).

→

↓

↓

↓

↓

6
3
8
0
0

7
1
5
2
0

8
1
1
0
2

3
7
4
2
1

4
2
2
2
1

0
6
3
0
1

2
8
2
0
2

2
4
6
1
0

3
3
7
1
0

↓
0
0
0
1
2

5
2
1
1
2

1
0
3
2
0

1
5
0
0
1

1
1
1
0
0

1
0
1
0

2
1
0
3

2
2
1
0

2
0
0
1

1
2
2
0

0
0
0
2

1
2
1
0











0
0
2
4
1

2
1
0
0



0
0
3
0
1





0
2
0
1
0

0
1
2
0
1

Fig. 3. A heterogeneous DHF(10; 13, v, 5, 2) with v = (93 34 41 51 21 ).

W -separating: denoted SHF( N ; k, v, W ) for W a set of multisets of nonnegative integers of the form { w 1 , w 2 , . . . , w s }, if
it is { w 1 , w 2 , . . . , w s }-separating for each { w 1 , w 2 , . . . , w s } ∈ W .
(t , s)-distributing: denoted
DHF( N ; k, v, t , s), if it is W -separating with W containing every multiset { w 1 , . . . , w s } of nons
negative integers with
i =1 w i = t.
An example of a homogeneous perfect hash family PHF(6; 12, 3, 3) is given in Fig. 1. It is a 6 × 12 array on the three
symbols {0, 1, 2} in which in every 6 × 3 subarray, at least one row consists of distinct symbols. For the 6 × 3 subarray
involving columns 8, 9, and 10, only the last row consists of distinct symbols.
Fig. 2 gives an example of a homogeneous {1, 2}-separating hash family SHF(3; 16, 4, {1, 2}). It is a 3 × 16 array on the
four symbols {1, 2, 3, 4}. For the 3 × 3 subarray consisting of columns 11, 15, and 16, only the last row accomplishes the
speciﬁc separation of columns {11, 16} from column {15}.
Fig. 3 gives an example of a heterogeneous DHF(10; 13, v, 5, 2) with v = (9, 9, 9, 3, 3, 3, 3, 4, 5, 2). We abbreviate repetition in such a tuple by using an exponential notation that indicates the repetition in the exponent v = (93 34 41 51 21 ). The
cells with the ‘’ are ‘ﬂexible’ positions, i.e., they can take on any symbol. The DHF is a 10 × 13 array on the nine symbols
{0, 1, . . . , 8}. Because t = 5 and s = 2 we must achieve both {1, 4}- and {2, 3}-separations. For the 10 × 5 subarray consisting
of columns ﬁve, six, ten, twelve, and thirteen, only row six separates columns {5, 10} from columns {6, 12, 13}; the  in the
last row could be ﬁlled to effect the separation again, but there is no need.
The deﬁnition of W -separating encompasses perfect, { w 1 , w 2 , . . . , w s }-separating, and (t , s)-distributing hash families,
so we can treat this general situation. On occasion, we wish to further restrict the choice of rows to provide the desired
separation. The choice can be deﬁned by a logical predicate.
Let d = (d1 , . . . , d N ) be a tuple of positive integers, and let τ be a positive
Let W = { W 1 , . . . , W r }, where for
sinteger.
i
1  i  r, W i = { w i1 , . . . , w isi } is a multiset of nonnegative integers, and σi =
w
.
Finally,
let  = (π1 , π2 , . . . , π N ) be
i
j
j =1
a tuple of predicates on multisets of τ values that evaluate to true or false.
An SHF( N ; k, v, W ), A = (ai j ), is

(d, τ )-: if whenever
1  i  r,
C is a set of σi columns,
C 1 , C 2 , . . . , C si is a partition of C with |C j | = w i j for 1  j  si , and
T is a set of τ columns with |C ∩ T | = min(σi , τ ),
there exists a row ρ for which
aρ x = aρ y whenever x ∈ C e , y ∈ C f and e = f and
the predicate πρ evaluates to true on multiset {aρ x : x ∈ T }.

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

→

173

↓

↓

↓

↓

4
0
0
2
2
3
0

0
0
2
4
1
4
0

2
1
4
1
2
0
1

1
1
1
0
2
1
0

3
2
1
3
4
0
0

3
3
2
0
0
3
2

0
1
0
3
0
2
2

0
3
1
1
4
4
0

1
2
2
1
0
2
0

4
4
3
4
1
1
1

2
2
0
2
1
1
3

2
0
3
0
3
2
0

1
4
4
2
3
0
0

0
1
0
0
0
2
2
0
1
1
2
0

1
0
1
2
1
1
1
0
2
0
2
0

0
2
2
2
1
0
2
0
0
2
0
2

1
0
2
2
0
1
0
1
1
1
0
1

1
0
1
1
1
2
2
0
1
1
1
1

2
2
2
2
2
0
2
1
1
0
2

0
1
1
0
1
1
0
1
2
0
1
1

2
1
0
0
0
2
0
2
2
2
0
2

0
0
0
1
0
0
1
0
0
0
0
0

0
2
0
1
2
2
0
1
0
0
1
2

2
0
1
0
0
0
0
2
0
2
2
2

1
2
0
0
2
0
1
2
2
1
1
1

2
1
2
1
2
1
1
2
0
0
2
1



↓

Fig. 4. A heterogeneous d-strengthening DHF(19; 13, v, 5, 2) with v = (56 41 312 ), d = (46 313 ).

There are at least two natural choices of predicate. An SHF( N ; k, v, W ), A = (ai j ), is

(d, τ )-scattering: The predicate π ρ evaluates to true if the multiset {aρ x : x ∈ T } contains no symbol more than dρ times,
and false otherwise.

(d, τ )-strengthening: The predicate π ρ evaluates to true if the multiset {aρ x : x ∈ T } contains no more than dρ different
symbols, and false otherwise.
When τ = max{σi : 1  i  r }, we omit τ from the notation and write d-scattering or d-strengthening. When d1 = · · · =
d N = d, we write d in place of d.
Fig. 4 depicts a heterogeneous d-strengthening DHF(19; 13, v, 5, 2) with v = (56 41 312 ) and d = (46 313 ). This is equivalent
to a d-strengthening SHF(19; 13, v, {{1, 4}, {2, 3}}). Consider the separation of columns {1, 7} from columns {2, 6, 11}. Row 8
accomplishes the required separation, and it satisﬁes predicate π8 because it uses d8 = 3 symbols in these ﬁve columns.
However, considering columns {1, 2, 3, 4, 5}, the ﬁrst row separates {1, 2, 3} from {4, 5}, but does not satisfy predicate π1
because it uses 5 symbols to separate and π1 only permits the use of d1 = 4 symbols. So this separation is required in
another row (in this case, row 3 is suﬃcient).
O’Brien [50] proposed the scattering requirement for a construction for a broadcast encryption scheme. In this paper,
we explore the need for strengthening hash families, by examining their application in the construction of measurement
matrices for compressive sensing.
Our concern throughout is to ﬁnd hash families with as few rows as possible, given the other parameters. How many
rows are necessary? While exact determinations are known in very few cases, a naive lower bound yields the ‘correct’
asymptotic growth rate. To avoid trivialities, a set W is binding if there exists a { w 1 , . . . , w s } ∈ W that contains at least two
positive entries. (When W is not binding, an SHF( N
; Nk, v, W ) may have N = 0.) When W is binding, an SHF( N ; k, v, W )
cannot have two identical columns, and hence k  i =1 v i . Treating the homogeneous case with v symbols, the number
of rows must be at least log v k	. This yields a logarithmic lower bound. More precise bounds are known in many cases (for
example, [3,6]), but all are Ω(log k) bounds on N. When d, v, and W are ﬁxed; v  d; and d  max{s: { w 1 , . . . , w s } ∈ W },
Theorem 5.4 given later establishes that there is an absolute constant c so that a d-strengthening SHF( N ; k, v, W ) exists
having N  
c log k. Hence the lower and upper bounds differ by a constant factor.
3. Column replacement for compressive sensing
3.1. Compressive sensing
Nyquist’s sampling theorem states that a bandlimited analog signal can be perfectly reconstructed if the sampling rate
is at least twice the highest frequency of the original signal. However, when the signal is sparse, far fewer samples than
the Nyquist rate are required. Compressive sensing [9,2] (also called compressive sampling) is a technique that captures and
represents such compressible signals, in a sense combining compression and sampling into a single step.
We begin by describing a speciﬁc framework. An admissible signal of dimension n is a vector in Rn which is known
a priori to be taken from a given set Φ ⊆ Rn . A measurement matrix A is a matrix from Rm×n . Sampling a signal x ∈ Rn is
computing the product Ax = b. Once sampled, recovery involves determining the unique signal x ∈ Φ that satisﬁes Ax = b
using only A and b. If Φ = Rn , recovery can be accomplished only if A has rank n, and hence m  n. However for more
restrictive admissible sets Φ , recovery can sometimes be accomplished when m < n. Given a measurement matrix A, deﬁne
an equivalence relation ≡ A so that for x, y ∈ Rn , we have x ≡ A y if and only if Ax = Ay. If, for every equivalence class P

174

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

under ≡ A , the set P ∩ Φ contains at most one signal, then recovery is possible in principle. Because Ax = Ay ensures that
A (x − y) = 0, this can be stated more simply. The null space of A, N ( A ), is the set {x ∈ Rn : Ax = 0}. An equivalence class P
of ≡ A can be represented as {x + y: y ∈ N ( A )} for any x ∈ P . Hence recoverability is equivalent to requiring that, for every
signal x ∈ Φ , there is no y ∈ N ( A ) \ {0} with x + y ∈ Φ .
To apply these observations, a reasonable a priori restriction on the signals to be sampled is identiﬁed, suitable measurement matrices with m  n are formed, and a reasonably eﬃcient computational strategy for recovering the signal is
provided. A signal is t-sparse if at most t of its n coordinates are nonzero. The recovery of t-sparse signals is the province
of compressive sensing. An admissible set of signals Φ has sparsity t when every signal in Φ is t-sparse. An admissible set of
signals Φ is t-sparsiﬁable if there is a full rank matrix B ∈ Rn×n for which { Bx: x ∈ Φ} has sparsity t. Sparse and sparsiﬁable
signals arise in numerous applications in sensing, imaging, and communications [2]. We assume throughout that when the
signals are sparsiﬁable, a change of basis B is applied so that the admissible signals have sparsity t.
A measurement matrix has (0 , t )-recoverability when it permits exact recovery of all t-sparse signals. A basic problem is
to design measurement matrices with (0 , t )-recoverability where m is small relative to n, but in such a way that recovery
can be accomplished eﬃciently. Suppose that matrix A has (0 , t )-recoverability. Then given A and b, recovery of the signal
x can be accomplished in principle by solving the 0 -minimization problem min{x0 : Ax = b}. An enumerative strategy
can be employed: List the possible supports of signals from fewest nonzero entries to most. For each, reduce A and x to A 
and x , respectively, by eliminating coordinates in the signal assumed to be zero. Examine the (now overdetermined) system
A  x = b. When equality holds, a solution is found; we are guaranteed to ﬁnd one by considering
nall possible supports with
at most t nonzero entries. This strategy is prohibitively time-consuming, examining as many as t linear systems when the
signal has sparsity t. Natarajan [47] showed that we cannot expect to ﬁnd a substantially more eﬃcient solution, because
the problem is NP-hard.
Chen, Donoho, and Saunders [15,30] instead suggest considering the 1 -minimization problem min{x1 : Ax = b}, which
can be solved using standard linear programming techniques. For this to be effective, it is necessary that for each t-sparse
signal x, x is the unique solution to min{z1 : Az = Ax}. This property is (1 , t )-recoverability. A necessary and suﬃcient
condition for (1 , t )-recoverability has been explored, beginning with Donoho and Huo [30] and subsequently in [54,57,32,
35,36,55,39].
For y ∈ Rn and C ⊂ {1, . . . , n}, deﬁne y|C ∈ Rn to be the vector such that ( y |C )γ = y γ if γ ∈ C and ( y |C )γ = 0 otherwise.
A matrix A meets the (0 , t )-null space condition if and only if N ( A ) \ {0} contains no (2t )-sparse vector. A matrix A meets
the (1 , t )-null space condition if and only if for every y ∈ N ( A ) \ {0} and every C ⊂ {1, . . . , n} with |C | = t, y|C 1 < 12 y1 .
Lemma 3.1. (See [22], for example.) Matrix A ∈ Rm×n has (0 , t )-recoverability if and only if A meets the (0 , t )-null space condition.
Lemma 3.2. (See [57], for example.) Matrix A ∈ Rm×n has (1 , t )-recoverability if and only if A meets the (1 , t )-null space condition.
To establish (1 , t )-recoverability (and hence also (0 , t )-recoverability), Candès and Tao [10,12] introduced the Restricted
Isometry Property (RIP). For A ∈ Rm×n , the dth RIP parameter of A, δd ( A ), is the smallest δ so that, for some R > 0,
(1 − δ) R (x2 )2  ( Ax2 )2  (1 + δ) R (x2 )2 , for all x with x0 = d. The smaller δd ( A ) is, the better the dth RIP parameter. The RIP parameters have been extensively employed to establish (1 , t )-recoverability, particularly for randomly
generated measurement matrices [11–13], but also for deterministic constructions [17,29]. Conditions
√ on the RIP parameters have been used to provide suﬃcient conditions for (1 , t )-recoverability; commonly δ2t < 2 − 1 is required for
(1 , t )-recoverability, see [10] for example. The property of (1 , t )-recoverability in the presence of noise has also been
considered. Conditions on the RIP parameters are suﬃcient, but in general not necessary, for recoverability.
Combinatorial methods [4,25,37,38,40,56,41] for compressive sensing have been examined using close relationships with
expander graphs. We pursue a different combinatorial approach here.
3.2. Column replacement: The basics
Let A ∈ Rr ×k , A = (ai j ), be a measurement matrix. Let P ∈ {1, . . . , k}m×n , P = ( p i j ), be a pattern matrix. The column
replacement of A into P is a matrix B ∈ Rrm×n , B = ( B i j ), so that b(β−1)r +s,γ = as, p β γ for 1  β  m, 1  γ  n, and
1  s  r. That is, B is obtained by replacing each symbol σ in P by the column of A indexed by σ . The matrix B can
be partitioned into m bands B 1 , . . . B
m , where band B β is the r × n matrix obtained by selecting all rows indexed from
(β − 1)r + 1 to β r. Evidently, N ( B ) = m
β=1 N ( B β ).
Fig. 5 illustrates the idea of column replacement. In it, A is 2 × 3 matrix with columns indexed by {1, . . . , 3}, P is 2 × 4
pattern matrix with symbols from {1, . . . , 3}, and B is the column replacement of A into P . B is a 4 × 4 matrix having
entries chosen from the set of entries of A. The two bands are separated by the line.
Theorem 3.3. (See [22].) Suppose that A is an r × k measurement matrix that meets the (0 , t )-null space condition, that P is an
SHF(m; n, k, (1, t )), and that B is the column replacement of A into P . Then B is an rm × n measurement matrix that meets the
(0 , t )-null space condition.
As expected, the more stringent (1 , t )-recoverability condition requires more.

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

⎡

P=

1231
3121




A=

aba
baa

175

⎤

abaa
⎢ baab ⎥
⎢
⎥
⎥
⎣ aaba ⎦
abab



B =⎢

Fig. 5. B is the column replacement of A into P .

⎡


P=

132123
111222




A1 =

aba
baa




A2 =

ab
ba



⎤
aababa
⎢ baabaa ⎥
⎢
⎥
B =⎢
⎥
⎣ aaabbb ⎦
bbbaaa

Fig. 6. B is the column replacement of A 1 , A 2 into P .

Theorem 3.4. (See [22].) Suppose that A is an r × k measurement matrix that meets the (1 , t )-null space condition, that P is a
DHF(m; n, k, t + 1, 2), and that B is the column replacement of A into P . Then B is an rm × n measurement matrix that meets the
(1 , t )-null space condition.
As discussed in [22], Theorems 3.3 and 3.4 enable one to restrict the entries of a measurement matrix to a predetermined set, rather than employing ‘random’ entries. In addition, the structure of the measurement matrices from column
replacement exhibit a hierarchical structure that can aid in recovery, and indeed support hybrid recovery schemes. However, they do not permit the construction of measurement matrices for larger strength from ones for smaller strength. It is
this shortcoming that we address next.
3.3. Strengthening with column replacement
We ﬁrst extend column replacement to exploit heterogeneity in the hash family. Let P = ( p i j ) be an HF(m; n, k) and, for
1  i  m, A
i be an r i × k i matrix. For each row i of P , replace the entry p i j by (a copy of) the p i j th column of A i . The

m
result is a ( i =1 r i ) × n matrix, which is the column replacement of A 1 , A 2 , . . . , A m into P . A small example is given in Fig. 6.
Theorem 3.5. Let k = (k1 , . . . , km ) and q = (q1 , . . . , qm ) be tuples of positive integers. Let d = (2q1 , . . . , 2qm ). For 1  i  m, let A i ∈
Rri ×ki be a measurement matrix that meets the (0 , qi )-null space condition. Let P be a (d, 2t )-strengthening SHF(m; n, k, (1, t )),
and let B be the column replacement of A 1 , A 2 , . . . , A m into P . Then B meets the (0 , t )-null space condition.
Proof. Suppose to the contrary that B does not meet the (0 , t )-null space condition, and that z ∈ N ( B ) \ {0} is a (2t )-sparse
vector. Let {ρ1 , . . . , ρs } = {γ : zγ > 0}, {ν1 , . . . , νs } = {γ : zγ < 0}, and C = {ρ1 , . . . , ρs } ∪ {ν1 , . . . , νs }. Then s + s  2t, and
without loss of generality we can take s  s so s  t. Then s  1 because z is nonzero.
Because P is (1, t )-separating and (d, 2t )-strengthening, it contains a row β such that p β ρi = p β ν1 for 1  i  s and

|{ p β γ : γ ∈ C }|  2qβ . Because Bz = 0, ( B β )z = 0. Form a vector w ∈ Rkβ by setting w σ = { zγ : p β γ = σ , 1  γ  n}
for 1  σ  kβ . The vector w can be considered as a projection of z onto Rkβ induced by the symbol pattern in row β
of P . Because B is the column replacement of A 1 , A 2 , . . . , A m into P , it follows from ( B β )z = 0 that A β w = 0. Because
|{ p β γ : γ ∈ C }|  2qβ , w is (2qβ )-sparse. Finally, w is nonzero because w p β ν1 < 0. So A β does not meet the (0 , qβ )-null
space condition, a contradiction. 2
Theorem 3.6. Let k = (k1 , . . . , km ) and q = (q1 , . . . , qm ) be tuples of positive integers. For 1  i  m, let A i ∈ Rri ×ki be a measurement matrix that meets the (1 , qi )-null space condition. Let P be a (q, t )-strengthening DHF(m; n, k, t + 1, 2), and let B be the
column replacement of A 1 , A 2 , . . . , A m into P . Then B meets the (1 , t )-null space condition.
Proof. Suppose to the contrary that B does not meet the (1 , t )-null space condition. Let z ∈ Rn , C = {γ1 , . . . , γt }, and
C = {1, . . . , n} \ C so that z ∈ N ( B ) \ {0} and z|C 1  z|C 1 . Let χ be an element of C such that | zχ |  | zγ | for each γ ∈ C .
Suppose without loss of generality that zχ  0. We shall obtain a contradiction by examining a band of B corresponding
to a row of P that, using few symbols, separates those indices in C ∪ {χ } for which z has nonnegative entries from those
indices in C ∪ {χ } for which z has negative entries.
Because P is (t + 1, 2)-distributing and (q, t )-strengthening, there is a row β of P such that



pβ γ :







γ ∈ C ∪ {χ }, zγ  0 ∩ p β γ : γ ∈ C ∪ {χ }, zγ < 0 = ∅

and |{ p β γ : γ ∈ C }|  qβ .

Because Bz = 0, ( B β )z = 0. Form a vector w ∈ Rkβ by setting w σ = { zγ : p β γ = σ , 1  γ  n} for 1  σ  kβ . The
kβ
vector w can be considered as a projection of z onto R induced by the symbol pattern in row β of P . Because B is the
column replacement of A 1 , A 2 , . . . , A m into P , it follows from ( B β )z = 0 that A β w = 0. We now show that w = 0.

176

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

For 1  σ  kβ , let




| z γ |: γ ∈ C , z γ > 0 , p β γ = σ ,


s−
| z γ |: γ ∈ C , z γ < 0 , p β γ = σ ,
σ =


s+
| z γ |: γ ∈ C , z γ > 0 , p β γ = σ ,
σ =


s−
| z γ |: γ ∈ C , z γ < 0 , p β γ = σ .
σ =
s+
σ =

Let D = { p β γ :



γ ∈ C } (note that | D |  qβ ) and let D = {1, . . . , kβ } \ D. Because z|C 1 − z|C 1  0,
  +

−
+
−
s+
sσ + s−
σ + sσ − sσ − sσ −
σ  0.

σ ∈D

(1)

σ ∈D

−
+
−
+
−
Now w σ = s+
σ − sσ + sσ − sσ for 1  σ  kβ . If σ ∈ D then our choice of β guarantees that either sσ = 0 or sσ = 0 and
+
−
+
−
+
−
+
−
hence | w σ |  sσ + sσ − sσ − sσ . If σ ∈ D then sσ = sσ = 0, so | w σ |  sσ + sσ . Then by (1),



|wσ | −

σ ∈D



| w σ |  0.

(2)

σ ∈D

However, because | D |  qβ , A β w = 0, and A β meets the (1 , qβ )-null space condition, either the left-hand side of (2) is
negative or w = 0. Thus w = 0. We now show that z = 0, which contradicts our assumptions.
−
+
−
+
−
+
−
Because | w σ |  s+
σ + sσ − sσ − sσ for each σ ∈ D, and w = 0, we have that sσ + sσ − sσ − sσ  0 for each σ ∈ D. So by
− = 0 for each σ ∈ D. Hence
(1), s+
+
s
σ
σ
−
s+
σ = sσ = 0 for each σ ∈ D .
−
+
−
Similarly by (1), s+
σ + sσ − sσ − sσ = 0 for each
follows that

−
s+
σ = sσ

τ

and

+
s−
σ = sσ

(3)
−
+
−
σ ∈ D. Combining this with s+
σ − sσ + sσ − sσ = w σ = 0 for 1  σ  kβ , it

for each σ ∈ D .

(4)

Let τ = p β χ . By our choice of β and because zχ  0, we have that s−
τ = 0. Thus, by (3) when τ ∈ D and by (4) when
+  z  0 and hence that z = 0. So, from the deﬁnition of χ ,
∈ D, s+
=
0.
Because
z

0
and
χ
∈
C
,
we
have
0
=
s
χ
χ
χ
τ
τ

zγ = 0 for each

γ ∈ C , and thus it follows from (4) that z = 0. 2

3.4. Column replacement and RIP parameters
For vectors a1 , . . . , as (of any dimensions) the vector a formed by concatenating a1 , . . . , as satisﬁes (a p ) p = (a1  p ) p +
· · · + (as  p ) p whenever p is a nonnegative real.
m
The binary expansion B ( P ) of an HF(m; k, v), P , is a ( i =1 v i ) × k array with entries from {0, 1}, obtained by taking the
column replacement of I v 1 , . . . , I v m into P , where I v i is the v i × v i identity matrix. Recall the deﬁnition of the dth RIP
parameter of a matrix from Section 3.1.
Lemma 3.7. Let A ∈ Rr ×k , A = (ai j ), be a measurement matrix, P ∈ {1, . . . , k}m×n , P = ( p i j ), be a pattern matrix, B ( P ) be the binary
expansion of P , and B be the column replacement of A into P . Then, for 1  t  r,

δt ( B ) 

δt ( A ) + δt ( B ( P ))
.
1 + δt ( A )δt ( B ( P ))


Proof. Let z ∈ Rn be a t-sparse vector. For 1  β  m, let wβ be the vector formed by setting ( w β )σ = { zγ : p β γ = σ ,
1  γ  n} for 1  σ  k (wβ can be considered as a projection of z onto Rk induced by the symbol pattern in row β of P ).
The vector Bz is the concatenation of the vectors Aw1 , . . . , Awm , and hence



 Bz2

2

2
2


=  Aw1 2 + · · · +  Awm 2 .

Using the RIP properties of A, for some R > 0 and for 1  β  m,



 

1 − δt ( A ) R wβ 2

2

2 
2

 
  Awβ 2  1 + δt ( A ) R wβ 2 .

Substituting into (5),



 

1 − δt ( A ) R w1 2

2

2  
2 
2
2 

 

  Bz2  1 + δt ( A ) R w1 2 + · · · + wm 2 .
+ · · · + wm 2

(5)

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

177

Now B ( P )z is the concatenation of the vectors w1 , . . . , wm and hence

 





 B ( P )z 2 = w1 2 2 + · · · + wm 2 2 .
2

Using the RIP properties of B ( P ), for some R  > 0





 

1 − δt B ( P ) R  z2

2

2
2 

2


 
 w1 2 + · · · + wm 2  1 + δt B ( P ) R  z2

and hence











1 − δt ( A ) 1 − δt B ( P ) R R  z2

2

2 


2



  Bz2  1 + δt ( A ) 1 + δt B ( P ) R R  z2 .

Finally, let R  = (1 + δt ( A )δt ( B ( P ))) R R  . Substituting for R R  in both the upper and lower bounds and simplifying,



1−





2 
2

2
δt ( A ) + δt ( B ( P ))
δt ( A ) + δt ( B ( P ))
R  z2   Bz2  1 +
R  z2
1 + δt ( A )δt ( B ( P ))
1 + δt ( A )δt ( B ( P ))

and the result follows.

2

RIP has been generalized to norms other than the 2 norm [4]. Let p be a positive integer. For a matrix A with real
entries, the t-th RIP-p parameter of A, denoted δ p ,t ( A ), is the smallest real number δ such that, for some real number R > 0,
(1 − δ) R (x p ) p  ( Ax p ) p  (1 + δ) R (x p ) p for all t-sparse vectors x. The case when p = 2 is the standard notion of
RIP. RIP-1 parameters are used in studying the adjacency matrices of expander graphs [4,41]. Matrix A is normalized for its
t-th RIP-p parameter if (1 − δ p ,t ( A ))(x p ) p  ( Ax p ) p  (1 + δ p ,t ( A ))(x p ) p for all t-sparse vectors x. Any matrix can be
normalized in this way by multiplying it by a scalar.
Lemma 3.8. For 1  i  m, let A i ∈ Rri ×ki be a measurement matrix that is normalized for its t-th RIP-p parameter, and let P = ( p i j )
be an m × n pattern matrix in which row β contains symbols from {1, . . . , kβ } for 1  β  m. Let B ( P ) be the binary expansion of P ,
and B be the column replacement of A 1 , . . . , A m into P . Then, for any positive integer p and for 1  t  r,

δmax + δ p ,t ( B ( P ))
,
1 + δmax δ p ,t ( B ( P ))

δ p ,t ( B ) 

where δmax = max(δ p ,t ( A 1 ), . . . , δ p ,t ( A m )).
The proof parallels that of Lemma 3.7 closely, and is omitted. These two lemmas provide some evidence that column
replacement enables us not just to meet recoverability conditions, but also to preserve the basic machinery to deal with
noise in the signal.
4. Strengthening hash families using the Lovász local lemma
The Lovász local lemma provides a powerful tool for establishing existence of combinatorial arrays; see [28] for applications to certain hash families. We use the following version (as usual, e is the base of the natural logarithm).
Theorem 4.1. (See [33].) Suppose that A 1 , . . . , A  are events in a probability space such that each event is mutually independent of a
set of at least  − b other events. If Pr[ A i ]  e(b1+1) for 1  i  , then



Pr






Ai

> 0.

i =1

To simplify the analysis we only consider homogeneous hash families in this section, and use certain notation throughout.
Let Wt ,s be the set of all s-element multisets whose entries are nonnegative integers that sum to t. For W =
{ w 1 , . . . , w s } ∈ Wt ,s , let U ( W ) be the total number of unordered partitions of a set of size t into sets of sizes w 1 , . . . , w s .
Then

U (W ) = 

1





t − w1

t

μ(i )! w 1

i ∈Z

w2



t − w1 − w2



w3



···

ws
ws


,

where μ(i ) is the multiplicity of i in the multiset W . Let S (t , s) be the number of unordered partitions of a set of size t
into s non-empty subsets. This is a Stirling number of the second kind and can be calculated as

S (t , s) =

s
1

s!

(−1)i

i =0

 
s
i

(s − i )t .

Let P v = {p = ( p 1 , . . . , p v ): p i ∈ R0 for 1  i  v and

v

i =1

p i = 1}.

178

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

Let d be a positive integer and let p = ( p 1 , . . . , p v ) ∈ P v . Suppose the vertices of a complete multipartite graph with
parts of sizes W = { w 1 , w 2 , . . . , w s } are coloured independently at random with colours from the set {1, . . . , v } so that
the probability of any speciﬁed vertex receiving colour i is p i for 1  i  v. The probability that this process results in a
proper d-colouring of the graph is denoted by π ( W , p, d, v ). For W ∈ Wt ,s , let πS ( W , d, v ) = maxp∈P v π ( W , p, d, v ). Let
πD (t , s, d, v ) = maxp∈Pv minW ∈Wt ,s π ( W , p, d, v ).
Theorem 4.2. Let w 1 , . . . , w s be nonnegative integers, and t =

s

i =1

w i . There exists

1. a d-strengthening SHF( N ; k, v , { w 1 , . . . , w s }) if

k

 
− k−t t ))
N
;
− log(1 − πS ( W , d, v ))
log(e · U ( W )(

t

2. a d-strengthening DHF( N ; k, v , t , s) if

k

N

 
− k−t t ))
.
− log(1 − πD (t , s, d, v ))

log(e · S (t , s)(

t

Proof.
Let K be a set of k column indices. Let A = {{ Z 1 , . . . , Z s }: Z i ⊂ K for 1  i  s, Z i ∩ Z j = ∅ for 1  i < j  s,

| is=1 Z i | = t }. For W = { w 1 , . . . , w s } let AW = {{ Z 1 , . . . , Z s } ∈ A: | Z i | = w i for 1  i  s}. In the remainder, the variables
have the following interpretations:

Variable

First statement

Second statement

Z

AW
U (W )
πS ( W , d , v )
p ∈ P v satisﬁes π ( W , p, d, v ) = f

A
S (t , s)
πD (t , s, d, v )
p ∈ P v satisﬁes min W ∈Wt ,s π ( W , p, d, v ) = f

C
f
p = ( p1 , . . . , p v )

Let H be an N × k matrix whose entries are chosen independently at random from the set {1, . . . , v } so that the probability of any speciﬁed entry being i is p i for i = 1, . . . , v. For { Z 1 , . . . , Z s } ∈ Z , let A { Z 1 ,..., Z s } be the event that there is no
row of H in which at most d distinct symbols occur in the columns in Z 1 ∪ · · · ∪ Z s and in which the sets of symbols in
the columns in Z 1 , . . . , Z s are pairwise disjoint. Array H is the required hash family if and only if none of the events in
{ A { Z 1 ,..., Z s } : { Z 1 , . . . , Z s } ∈ Z } occurs. It can be seen that Pr[ A { Z 1 ,..., Z s } ]  (1 − f )N .
An event A { Z 1 ,..., Z s } is mutually independent of all events in { A { Z  ,..., Z s } : { Z 1 , . . . , Z s } ∈ Z and ( Z 1 ∪ · · · ∪ Z s ) ∩ ( Z 1 ∪ · · · ∪
1
k
C
events
in { A { Z 1 ,..., Z s } : { Z 1 , . . . , Z s } ∈ Z }, by Theorem 4.1 the
t
t 
k−t 
k
required hash family exists if (1 − f ) N  e(b1+1) , where b = t C − t C − 1. Rearrange to produce the required results. 2

Z s ) = ∅}; there are

k−t 

C such events. Because there are

In order to develop deterministic, eﬃcient algorithms, we use a consequence of [14, Theorem 1.2], corresponding to the
special case of that result in which each event is mutually independent of a set of all but at most b other events. In the
1
.
notation of [14],  is arbitrarily close to 1 and the probability of each event is assigned the value b+
1
Theorem 4.3. (See [14].) Let X = { X 1 , . . . , X γ } be a collection of mutually independent discrete random variables each with a domain
of cardinality at most v. Let A = { A 1 , . . . , A  } be a collection of events such that each event is determined by at most r of the variables
in X and each event is mutually independent of a set of at least  − b other events. Suppose that time T is suﬃcient to compute the
conditional probability Pr[ A | X i = σi for each i ∈ I ] for any event A ∈ A, any I ⊆ {1, . . . , γ }, and any partial evaluation {σi }i ∈ I of the
variables in X . If Pr[ A ]  ( e(b1+1) )2 for all A ∈ A, then an evaluation of X 1 , . . . , X γ under which none of the events in A occurs can
be found by a deterministic algorithm running in time O ( T · r · M 4+δ ), where δ is any positive real number, and M = max(γ , , br ).

Theorem 4.4. Let v, w 1 , . . . , w s , and d be constant nonnegative integers. Let t =
in time O (k4t +δ ) for any positive real number δ to construct
1. a d-strengthening SHF( N ; k, v , { w 1 , . . . , w s }) where


N=

k

  
− k−t t ))
;
− log(1 − πS ( W , d, v ))

2 log(e · U ( W )(

t

s

i =1

w i . There are deterministic algorithms running

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

179

2. a d-strengthening DHF( N ; k, v , t , s) where


N=

k

  
− k−t t ))
.
− log(1 − πD (t , s, d, v ))

2 log(e · S (t , s)(

t

Proof. Let p, H , f , C , Z and the events { A { Z 1 ,..., Z s } : { Z 1 , . . . , Z s } ∈ Z } be as deﬁned in the proof of Theorem 4.2. Again, H is
the required hash family if and only if none of the events { A { Z 1 ,..., Z s } : { Z 1 , . . . , Z s } ∈ Z } occur. Once more, Pr[ A { Z 1 ,..., Z s } ] 

(1 − f )N for each event A { Z 1 ,..., Z s } ; there are
k−t 

k
t

C events in total; and each event is mutually independent of a set of at

least t C other events.
Applying Theorem 4.3, considering the entries of H to be discrete random variables, we can obtain a deterministic
k
k−t 
algorithm for constructing the required hash family provided that (1 − f ) N  ( e(b1+1) )2 , where b = t C − t C − 1. This
holds for the given value of N.
We now bound the run time. There are Nk entries in H , and each event depends on Nt entries of H . For suﬃciently
k
k
k
C = O (k log k). Thus M = O (kt ) and
large k we have Nk = O (k log k), t C = O (kt ) and, because b1 t C = O (k), we have Nt
b t
r = O ( N ) = O (log k), where M and r are as in Theorem 4.3.
Let { Z 1 , . . . , Z s } ∈ Z . Let H  be a partial evaluation of the entries of H . For a speciﬁc row β of H , it takes time O (1) to
compute the conditional probability, given the partial evaluation H  , that at most d distinct symbols occur in the columns in
Z 1 ∪ · · · ∪ Z s of row β and the sets of symbols in the columns in Z 1 , . . . , Z s of row β are pairwise disjoint (the computation
involves considering at most t entries each of which can take at most v values, and both are constant). Thus the conditional
probability of A { Z 1 ,..., Z s } given H  can be computed in time O ( N ). Thus T = O ( N ) = O (log k), where T is as in Theorem 4.3.
Combining these bounds yields the bound we require. 2
5. The Stein–Lovász–Johnson method
Next we examine a different probabilistic approach that yields a class of straightforward greedy construction methods
for which the size of the hash family produced meets the logarithmic bound. Indeed, after some substantial preliminaries,
we establish that it provides an eﬃcient algorithm for hash families of ﬁxed strength. To develop this, we detour into set
cover problems.
5.1. Set cover problems
Let X be a ﬁnite
 set of size n, and let D be a collection of subsets of X . A set cover for the set system ( X , D) is a collection
B ∈D  B = X . Finding the smallest set cover for a set system is NP-hard [43], and hence approximation
and heuristic techniques have been developed. Stein [51], Lovász [44], and Johnson [42] (see also [16]) analyze a greedy
algorithm and establish a useful upper bound on the sizes of set covers that it produces. At a high level, the algorithm
repeatedly selects one set for inclusion in the set cover which, once selected, is never removed. The selection of the set is
greedy, choosing one that covers the largest number of uncovered elements at that stage, and breaking ties arbitrarily. We
give (one version of) the algorithm in Algorithm 1.

D ⊆ D so that

Algorithm 1 The Greedy Algorithm
Greedy_Set_Cover( X , D ): (| X | = n; |D | = c)
Set r (x) = |{ B: x ∈ B ∈ D }| for x ∈ X
Set α = max{| B |: B ∈ D } and r = min{r (x) : x ∈ X }
Set M j = ∅ for 0  j  α
Set D0 = D and Y 0 = X
Set nα = | X |
Set L = ∅ and i = 0
while Y i = ∅ do
Set γi = |Di |; ρi = |Y i |; and αi = max{| B |: B ∈ Di }
If i > 0 and αi < αi −1 set nαi = |Y i |
Choose a set D i ∈ Di for which | D i | = αi
Set L = L ∪ { D i }
Set Mαi = Mαi ∪ { D i }
Set Y i +1 = Y i \ D i
Set Di +1 = { B \ D i : B ∈ Di , B  D i }
Set i = i + 1
Set n0 = 0
return L

The representation of a hash family as a set cover is straightforward: The sets are in one-to-one correspondence with the
possible rows, the elements consist of all required separations of columns, and a set contains an element precisely when

180

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

the corresponding row carries out the speciﬁed separation. A set cover is then a set of rows which together accomplish all
of the required separations. Hence Greedy_ Set_Cover provides an algorithm for producing hash families.
We use the notation introduced in Algorithm 1: n is the number of elements, c is the number of sets, α is the size of
the largest set, and r is the smallest number of sets to which an element belongs. The size of the set cover can beviewed
α
either as the smallest value of i for which no elements remain to be covered (Y i = ∅), or it can be viewed as
j =0  j ,
taking  j = |M j |. We consider the latter expression. First, n j −1 = n j − j  j , and hence  j = (n j − n j −1 )/ j. Because in each
set system considered when choosing the sets in M j , every element appears in at least r sets and every set has size at
most j, rn j  jc. Moreover,

=

α

j =1

j =

α

n j − n j −1

j

j =1

=

nα

α

+

n α −1

α (α − 1)

α

Combining these, we obtain   αn + cr (
Johnson [42]:

1
j =2 j ),

+

n α −2

(α − 1)(α − 2)

+ ··· +

n1
2·1

− n0 .

which yields the bound in the theorem of Stein [51], Lovász [44], and

Theorem 5.1 (Stein–Lovász–Johnson). Let ( X , D ) be a set system with | X | = n and |D | = c so that | B |  α for every B ∈ D and
|{ B: x ∈ B ∈ D}|  r for every x ∈ X . Then there is a collection D ⊆ D forming a set cover with  sets for some   αn + cr ln α 
c
(1 + ln α ).
r
A second analysis of Greedy_Set_Cover uses the fact that it terminates when Y i = ∅, or equivalently when ρi < 1. An
i −1
element x of Y i is not a member of
j =0 D j , and hence r (x) is unchanged by the deletion of the elements already covered.
Because r (x)  r for all x ∈ Y i , and
r i
n( c −
).
c

γi  c, the size of D i is at least

r ρi
c

. Then

We determine the smallest value of i for which
for every i > 0, ρi 
logarithms base c /(c − r ) of both sides, logc /(c −r ) n < i.
This establishes:

= ρi c−c r . Because this holds
< 1. Equivalently, n < ( c−c r )i . Taking

ρi+1  ρi −

r i
n( c −
)
c

r ρi
c

Theorem 5.2. Let ( X , D ) be a set system with | X | = n and |D | = c so that |{ B: x ∈ B ∈ D }|  r for every x ∈ X . Then there is a
log n
collection D  ⊆ D forming a set cover with  sets for some   1 + log(c /(c −r )) .
This improves the constant in the bound over that of the Stein–Lovász–Johnson theorem in some cases, but yields a
weaker bound in others. This apparent discrepancy is an artifact of the analyses, not the algorithm.
The Stein–Lovász–Johnson method has been applied in establishing upper bounds on the sizes of numerous combinatorial
arrays. In these contexts, however, the admissible sets D are often known implicitly rather than presented explicitly. Then
the size of the input is simply | X |, and the run time of the greedy algorithm may be exponential in | X |, because |D |
may be exponentially large with respect to | X |. This has limited the practical uses of such greedy methods for the actual
construction of the set covers needed to produce the corresponding combinatorial arrays.
Careful examination shows that the only operations in Algorithm 1 that consider all of the sets in Di are the ones to
select D i , and to remove all elements of D i from the sets in Di to form Di +1 . To obtain an algorithm whose running time
is polynomial in | X |, we cannot hope to examine (or even list) all sets in D . Our ﬁrst task, then, is to simplify the selection
of the set D i . In fact, we show that selecting a set of average size yields the same results. At the same time, we equip D
with a probability distribution, so that Pr[ B ] is the probability that set B ∈ D is selected.
Average_Set_Cover, shown in Algorithm 2, is essentially the same method – with one important difference. Each set selected is only required to cover the average number of as yet uncovered elements of X rather than the maximum. Moreover,
this average is weighted by the initial probability distribution selected on D .
The analyses of Greedy_Set_Cover carry through for the average method as well. For the ﬁrst, we employed the fact
that n j −1 = n j − j  j , and hence  j = (n j − n j −1 )/ j; and the fact that rn j  jc. For the average method, n j −1  n j − j  j , and
hence  j  (n j − n j −1 )/ j; and rn j  jc because j = 
holds for the average method as well.
Hence

rn j
c

	. For the second, we employed only the fact that | D i |  r ρc i , which

Theorem 5.3. Let ( X , D ) be a set system with | X | = n and |D | 
= c, for which Pr[ B ] is the probability that B ∈ D is selected. Let

r (x) = c



{ B ∈D : x∈ B } Pr[ B ] and r

= min{r (x): x ∈ X }. Let β = 

log n
with  sets, where   min r (1 + ln β), 1 + log(c /(c −r )) .
c

x∈ X

c

r (x)

	. Then Average_Set_Cover produces a set cover D ⊆ D

When the probability distribution is uniform (and in many other cases), β  α , and hence Theorem 5.3 improves on
Theorem 5.1. This may come as a surprise, because the original Stein–Lovász–Johnson method selects a largest set while
the average method may select a smaller one. Again, the discrepancy arises from the algorithm analyses, not from the
algorithms themselves. In practice, it is quite possible that selecting the maximum coverage yields a better result in the

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

181

Algorithm 2 The Average Algorithm
Average_Set_Cover( X , D ): (| X | = n; |D | = c)

Set r (x) = c { B ∈D: x∈ B } Pr[ B ] for x
∈X
Set r = min{r (x): x ∈ X } and
Set M j = ∅ for 0  j  α
Set D0 = D and Y 0 = X
Set nα = | X |
Set L = ∅ and i = 0
while Y i = ∅ do

α=

x∈ X

r ( x)

c



	

x∈Y

r ( x)

i
Set γi = |Di |; ρi = |Y i |; and αi = 
	
c
If i > 0 and αi < αi −1 set nαi = |Y i |
Choose a set D i ∈ Di for which | D i |  αi and Pr[ D i ] > 0
Set L = L ∪ { D i }
Set Mαi = Mαi ∪ { D i }
Set Y i +1 = Y i \ D i
Set Di +1 = { B \ D i : B ∈ Di , B  D i }
Set i = i + 1
Set n0 = 0
return L

end than does selecting the average coverage. Nevertheless, Theorem 5.3 shows that the conclusion of Theorem 5.1 can be
obtained by selecting sets with average coverage.
5.2. The application to hash families
Despite the exponential run time exhibited by Average_Set_Cover when applied directly to hash families, the Stein–
Lovász–Johnson paradigm has been used to develop methods whose run time is polynomial in | X |. One method is to list
only a small subset of the sets [18]. Another method employs an implicit representation of all of the sets; see, for example,
[7,8] for an application to the construction of ‘covering arrays.’ We ﬁrst outline the idea using perfect hash families, adapting
a method from [19].
We
 K construct a PHF( N ; k, v , t ) with entries chosen from an alphabet Σ . Take K to be a set of k column indices and
X = t . Form a set D of v k subsets of X , one for each k-tuple in Σ k . The set corresponding to the k-tuple (x1 , . . . , xk ) ∈ Σ k

contains element {γ1 , . . . , γt } exactly when |{xγi : 1  i  t }| = t. Then every element of X belongs to v k−t · v · ( v − 1) · · · · ·


( v − t + 1) sets in D . Every set in D covers at most kt elements of X , and hence by the Stein–Lovász–Johnson theorem


k
vt
we ﬁnd that N  1 + v ( v −1)···(
ln t . This yields an exponential time method. By showing that it suﬃces to ﬁnd a set
v −t +1)

that covers an average number of uncovered elements and developing a method of conditional expectations to ﬁnd such a
set, Colbourn [19] developed an eﬃcient (time polynomial in k for ﬁxed t) algorithm for the construction of perfect hash
families with a number of rows meeting the given bound.
Whether the sets are listed explicitly or not, one potential beneﬁt of selecting a set with average rather than maximum
coverage is that the average can often be easily computed or bounded, and then ﬁnding any set with at least that average
coverage suﬃces. We explore this next.
There is evidently a wide variety of possible conditions that might be imposed on the hash family to be constructed.
To treat these variants, we proceed as follows. Consider creating a HF( N ; k, v), where the symbols of row ρ are chosen
from an alphabet Σρ of size v ρ . We deﬁne a number of requirements R 1 , . . . , R q , each of which is a partition C 1 , . . . , C s
of a set C of at most t columns of the hash family. An assignment A to the requirement R for row ρ is an assignment
of symbols from Σρ to the columns associated with R. For 1  ρ  N, we deﬁne a constraint function P ρ which accepts a
requirement R and an assignment A to R and outputs a value in {true, false}. Any k-tuple x ∈ Σρk , representing a possible
row ρ , induces an assignment to a requirement R. We represent this assignment, along with the requirement, by A x, R . The
hash family satisﬁes a requirement R if P ρ ( A x, R ) = true for some 1  ρ  N, where x is the k-tuple representing row ρ of
the hash family. Thus, while the requirements for the hash family are ﬁxed at the outset, the constraints for meeting each
requirement may vary from row to row.
From Theorem 5.3, one can immediately deduce bounds on the sizes of hash families in a general setting. We suppose
that the candidate rows are selected uniformly at random, that the hash family needed is homogeneous with v symbols,
and that the constraint function is the same for each row. Take c = v k and r = μ v k in Theorem 5.3 to establish:
Theorem 5.4. An HF( N ; k, v ) satisfying q requirements exists whenever



N  min

1

μ

(1 + ln β), 1 +

log q
log 1/(1 − μ)



,

taking δ R to be the ratio of the number of assignments A to R that satisfy the constraint for R to the total number of assignments to R,
μ to be the minimum of δ R over all requirements R, and β to be the ceiling of the sum of δ R over all requirements R.

182

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

In Theorem 5.4, it may be puzzling that the bound does not appear to involve k. However, when requirements are placed
on all of the k columns, the number of requirements q must be a function of k, and β is a function of q. The quantities
in Theorem 5.4 can often easily be calculated; we give one example. Suppose that W = {{1, 4}, {2, 3}}, and our objective
is to produce a W -separating, 3-scattering, and 3-strengthening HF( N ; k, 6). Write K = k(k − 1)(k − 2)(k − 3)(k − 4). There
k k−1
k k−2
1
1
K requirements for the {1, 4} separation, and 2 3 = 12
K for the {2, 3} separation. Each has 65 = 7776
are 1 4 = 24
assignments. A {1, 4} separation R has 840 assignments that meet the constraint, so δ R =

assignments that meet the constraint, so δ R =

 1296

N  min

85

155K
(1 + ln 15552
), 1 +

K
8
1296
1211

log
log



85
,
1296

μ=

85
,
1296

and β =

155
K.
15 552

35
.
324

A {2, 3} separation R has 510

Then the hash family exists provided that

.

Following the paradigm of Average_Set_Cover, we proceed as follows. The set X is the set of all requirements, and N
is (an upper bound on) the number of rows permitted. Then Average_Hash_Family( X , N , { P ρ ( A , R )}), given in Algorithm 3,
produces the desired hash family, or may fail if N is too small. Provided that N satisﬁes the bound in Theorem 5.4, however,
the algorithm is guaranteed to succeed.
Algorithm 3 The Average Algorithm for Hash Families
Average_Hash_Family( X , N , { P ρ ( A , R )})
// { P ρ ( A , R )} provides a predicate for each row ρ , each R ∈ X ,
// and each assignment A to R
Set X 1 = X and L = ∅
for ρ from 1 to N do
y = Select_Average_Row(ρ , X ρ , { P ρ ( A , R )})
Set L = L ∪ {y}
Set X ρ +1 = X ρ \ { R ∈ X ρ : P ρ ( A y, R ) = true}
if X N +1 = ∅ return L else return fail

Average_Hash_Family requires that we repeatedly select a next row for inclusion. For a requirement R ∈ X ρ and a candidate row x = (x1 , . . . , xk ) ∈ Σρk , R is covered by the row exactly when P ρ ( A x, R ) = true. For this reason, Select_Average_Row
must ﬁnd a row x ∈ Σρk for which Pr[x] > 0 and |{ R ∈ X ρ : P ρ ( A x, R )}| is at least the average over all choices of row y.
Suppose that we simply selected the row x at random (according to the probability distribution) from Σρk . Then Pr[x] > 0,
and the expectation of |{ R ∈ X ρ : P ρ ( A x, R )}| is precisely the desired average,


x∈Σρk

Pr[x] ·


R ∈ Xρ


P ρ ( A x, R ) =


R ∈ Xρ


Pr[x] · P ρ ( A x, R ) ,

x∈Σρk

treating P ρ ( A x, R ) as a 0, 1-indicator variable. This yields a randomized algorithm for producing hash families.
6. Making the Stein–Lovász–Johnson method eﬃcient
Here we establish that Average_Hash_Family (from Algorithm 3) provides a deterministic, polynomial-time algorithm
when the maximum strength of the requirements is ﬁxed. Consider the operation of that algorithm. It suﬃces to calculate
the expectation of P ρ ( A x, R ) for each R ∈ X ρ in order to determine the average sought. Nevertheless, we must also ﬁnd a
row x ∈ Σρk that yields at least this average. To do this, we start with a row in which no entries have been chosen, and
repeatedly choose one coordinate whose entry is unspeciﬁed in which to choose an entry. Our objective is to ensure that
at each stage the expectation of ﬁnding a row that covers at least the average number of requirements does not decrease.
In other words, we want the conditional expectation, based on the selection of the entries already made, never to decrease.
Hence we employ the fundamental idea in the method of conditional expectations [34,46].
Consider constructing an HF( N ; k, v) in which the symbols in row ρ are selected from an alphabet Σρ of size v ρ . We
must deal with rows in which only some of the entries have been chosen. Suppose that (x1 , . . . , xk ) ∈ (Σρ ∪ {})k . We
interpret an entry in Σρ to mean that the entry has been chosen, while the entry  means that the entry has not yet been
chosen. A row ( y 1 , . . . , yk ) ∈ Σρk is a completion of (x1 , . . . , xk ) if xi = y i or xi =  for 1  i  k. A row with s  entries has
v ρs completions, and the
two rows x and y,
the probability that y occurs given that x
 set of these is denoted by Rx . For 
occurs, Pr[y|x], is 0 if
Pr
[
z
]
=
0;
otherwise
it
is
(
Pr
[
z
])/(
z∈Rx ∩Ry
z∈Rx ∩Ry
z∈Rx Pr d[z]). The expected coverage ec (x)
for a row x = (x1 , . . . , xk ) ∈ (Σρ ∪ {})k is



z∈Rx
k



Pr[z|x] · (

R ∈ Xρ

P ρ ( A z, R )).

For 1  j  k, a row ( y 1 , . . . , yk ) ∈ (Σρ ∪ {}) is a j-successor of (x1 , . . . , xk ) if it holds that x j =  and y j ∈ Σρ , and that
xi = y i for 1  i  k when i = j. A row having a  entry in the jth position has exactly v ρ j-successors.
 Letting χρ ( R , x) be the probability that P ρ ( A z, R ) = true for a randomly chosen completion z of x, we have ec (x) =
R ∈ X ρ χ ( R , x). The selection of a row is accomplished by Select_Average_Row in Algorithm 4, when furnished with a
routine Expected_Completions that calculates χρ ( R , x).

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

183

Algorithm 4 The Average Algorithm for Hash Families: Selecting a Row
Select_Average_Row(ρ , X ρ , { P ρ ( A , R )})
// { P ρ ( A , R )} gives a predicate for each R ∈ X and assignment A to R
Set r(0) = {}k
for i from 1 to k do
(i −1)

=
Choose a coordinate γ for which rγ
Set maxcov = 0 and choice = ∅
for σ ∈ Σρ
Let z be the γ -successor of r(i −1) with zγ = σ
if Pr[z|r(i −1) ] > 0
Set cov = 0
for R ∈ X ρ
cov = cov + Expected_ Completions(ρ , R , z)
if cov  maxcov{Set maxcov = cov; choice = z}
(
i)
Set r = choice
return r(k)
(i −1)
When r(i −1) has rγ
= , and y(1) , . . . , y( v ρ ) are its

γ -successors, ec (r(i−1) ) =

v ρ

Pr[y(i ) |x] · ec (y(i ) ). Hence ec (r(i −1) ) 
i =1
(
0)
 k. Now ec (r ) is the expected number of elements of X covered by a row selected at random from Σρk
according to the probability distribution. Moreover, ec (r(k) ) is the actual number of elements of X covered by the row r(k) ,

ec (r(i ) ) for 1  i

which therefore covers at least the expected number.
It remains to compute χρ ( R , x) by Expected_Completions for each row ρ , each requirement R, and an arbitrary x ∈
(Σρ ∪ {})k . While this can be carried out for various probability distributions, in Algorithm 5 we treat only the case when
the probability distribution is uniform.
Algorithm 5 The Average Algorithm: Expected Completions
Expected_Completions(ρ , R , x)
// For the uniform distribution
// R is the set C = {γ1 , . . . , γt } of columns and the partition C 1 , . . . , C s
Let F = {γ ∈ C : xγ = } and F = C \ F
Set count = 0
for each assignment A = {aγi }1i t with aγi = xγi for γi ∈ F
and aγi ∈ Σρ for γi ∈ F
if P ρ ( A , R ) = true then count = count + 1
return count · ( v ρ )−| F |

Expected_Completions relies on the fact that, for a completion z of x, whether P ρ ( A z, R ) = true depends only on the assignment to the coordinates C speciﬁed by R. Every completion is equally probable and, once the assignment to coordinates
of C is speciﬁed, either every completion satisﬁes the constraint or none does. Therefore we can just treat each assignment
to the coordinates of C .
The routines in Algorithms 3, 4, and 5 implement the method of Algorithm 2 for a wide variety of hash families, producing a hash family of size no larger than that produced by applying the average algorithm directly. The improvement
is that, by using a method of conditional expectations, the algorithm has running time polynomial in the number of requirements rather than the number of sets, when the strength t and the number of symbols v are ﬁxed. To see this,
Expected_Completions takes time O ( v t ) = O (1). Then when there are r requirements, Select_Average_Row takes time
O (k · v · r ), but r is bounded by (kv )t , so the time is O (kt +1 ). When N rows are produced, Average_Hash_Family takes
time O ( N · kt +1 ). By Theorem 5.4, N is O (log k) when t is ﬁxed, and hence the running time is indeed a polynomial in k.
A weaker runtime bound, which is still polynomial in k, is obtained when v is not ﬁxed but t remains ﬁxed because v  k
in the problems examined.
7. An illustration – some computational results
Surprisingly, the large constants suppressed in this analysis do not render the method impractical. Table 1 reports some
computational results for d-strengthening DHF( N ; 13, v , t , s). Whenever v   v, a d-strengthening DHF( N ; 13, v , t , s) is also
a d-strengthening DHF( N ; 13, v  , t , s); we have indicated in italics when the entry is implied in this way.
We outline the method brieﬂy here. For each s-class partition of the t columns, we identify a row pattern by choosing a
row that maximizes the number of t-sets of columns separated while using at most d symbols on the t columns, when no
separations have already been accomplished. This yields a number of row patterns, one for each partition. We only select
rows that have the same multiplicities of symbols as one of the row patterns. Restricting row patterns in this way (equivalently, selecting suitable probabilities for particular rows to be selected) accelerates the method and improves the sizes
obtained, sometimes dramatically. Indeed for a 3-strengthening DHF( N ; 13, 12, 6, 3), using this restriction of row selections,
the greedy method produced 482 rows; simply selecting rows uniformly at random leads to a bound in our computation of
1969 rows. This underscores the value of selecting rows from a suitable probability distribution.

184

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

Table 1
d-strengthening DHF( N ; 13, v , t , s).
s

2

3

4

5

6

d

t

2
2
2
2
2

2
3
4
5
6

3
3
3
3

3
4
5
6

4
4
4

4
5
6

5
5

5
6

6

6

3
3
3
3

3
4
5
6

4
4
4

4
5
6

5
5

5
6

6

6

4
4
4

4
5
6

5
5

5
6

6

6

5
5

5
6

6

6

6

6

Number of symbols v
2

3

4

5

6

7

8

9

10

11

12

4
9
19
50
106

3
9
19
50
106

2
9
19
50
106

2
9
19
50
106

2
9
19
50
106

2
9
19
50
106

2
9
19
50
106

2
9
19
50
106

2
9
19
50
106

2
9
19
50
106

2
9
19
50
106

5
10
24
53

4
10
24
53

3
10
24
53

3
10
24
53

3
10
24
53

3
10
24
53

3
10
24
53

2
10
24
53

2
10
24
53

2
10
24
53

7
14
30

5
14
30

5
14
30

4
14
30

4
14
30

4
14
30

3
14
30

3
14
30

3
14
30

9
18

7
15

6
15

6
15

5
15

4
15

3
15

3
15

13

10

8

6

6

4

4

7
30
124
426

5
27
124
426

4
27
124
426

3
27
124
426

3
27
124
426

3
27
124
426

3
27
124
426

2
27
124
426

2
27
124
426

2
27
124
426

13
38
117

8
31
117

6
31
117

5
31
117

5
31
117

4
31
117

3
31
117

3
31
117

3
31
117

20
54

12
38

9
33

7
33

6
33

5
33

3
33

3
33

27

16

13

10

6

5

4

9
63
445

6
54
440

5
54
440

5
54
440

4
54
440

3
54
440

3
54
440

3
54
440

28
110

14
69

9
56

7
56

6
56

5
56

3
56

3
56

42

20

13

9

6

5

4

14
120

9
98

7
98

6
98

5
98

3
98

3
98

44

20

13

10

6

5

4

45

19

13

9

6

5

4

16
86
484

30
200

Simply applying the greedy method results in the earlier rows separating many sets of columns, while later selections
separate fewer. Indeed many rows contain entries that have no use in effecting a separation that is needed. Nayeri [48] provides a method for exploiting such ‘ﬂexible’ positions to repeatedly change entries in the array, eliminating any unnecessary
rows that arise in the process. We applied his post-optimization techniques to the results of the greedy method to arrive
at the results in Table 1. This can be quite effective: In the case of 3-strengthening DHF( N ; 13, 12, 6, 3), the greedy method
produced 482 rows, which post-optimization reduced to 426.
We report post-optimized results in Table 1, because results of the greedy methods are particularly well suited to their
application. Moreover, in this way, one obtains a clearer picture of the effects of various separation and strengthening
conditions, and how they interact.
Because the algorithm selects one row at a time, it is an easy matter to change the permitted number of symbols in the
next row, and to change the strengthening requirement for the next row, as the algorithm progresses. Although the analysis
of this more general algorithm is unwieldy, its implementation is no more complicated than that of Average_Hash_Family.
This generalization was used, for example, to make the hash family in Fig. 4.
8. Conclusion
Column replacement techniques have enjoyed a wide range of applications in testing and measurement problems in
which sparsity arises. Compressive sensing has recently been added to the long list of such applications, which already
included software interaction testing, combinatorial cryptography, computational learning, combinatorial group testing, and
others. The basic column replacement technique was earlier extended to exploit heterogeneity to use many small ingredient
arrays rather than one. Despite this, its most severe limitation was that the small ingredients required the same strength

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

185

as the array to be produced. By introducing strengthening hash families, we have overcome that limitation here, at least in
principle.
In order to demonstrate this, column replacement for compressive sensing has been developed using two standard recovery techniques, to produce measurement matrices for larger strength from ingredients for smaller. This more general column
replacement supports recoverability, and has a predictable effect on the RIP parameters that assist with assessing ability to
cope with noise. Indeed it also supports eﬃcient recovery schemes using the hierarchical structure of the measurement
matrix produced; this substantial topic will be pursued elsewhere by the authors.
In practice, the method developed is only effective when strengthening hash families with ‘few’ rows can be produced;
real applications require that they be produced explicitly and eﬃciently. When the strength is ﬁxed, two probabilistic
methods have been shown to lead to the correct asymptotic bound. One, using the Lovász local lemma, is shown to admit
a deterministic, polynomial-time implementation. A second, using the Stein–Lovász–Johnson paradigm, is shown to yield a
deterministic, polynomial-time algorithm that is easy to implement, making greedy selections to choose one row at a time,
and greedy selections to determine each row one element at a time. In conjunction with a post-optimization technique, this
provides a practical method for making strengthening hash families.
Although both algorithms yield the correct asymptotic growth rate for the hash families used, we do not expect either to
produce arrays with the minimum number of rows, except in a very few cases. Therefore it remains of interest to develop
direct constructions using, for example, error-correcting codes. Strengthening hash families produced in this manner could
obviate the need for substantial computation.
Acknowledgements
Thanks to Chris McLean, Peyman Nayeri, and Devon O’Brien, for helpful discussions. This research is supported by ARC
DP120103067 (C.J.C., D.H.) and DE120100040 (D.H.).
References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]
[22]
[23]
[24]
[25]
[26]
[27]
[28]
[29]
[30]
[31]
[32]
[33]

N. Alon, Explicit construction of exponential sized families of k-independent sets, Discrete Math. 58 (1986) 191–193.
R. Baraniuk, Compressive sensing, IEEE Signal Process. Mag. 24 (2007) 227–234.
M. Bazrafshan, Tran van Trung, Bounds for separating hash families, J. Combin. Theory Ser. A 118 (3) (2011) 1129–1135.
R. Berinde, A.C. Gilbert, P. Indyk, H. Karloff, M.J. Strauss, Combining geometry and combinatorics: A uniﬁed approach to sparse signal recovery, in: Proc.
46th Annual Allerton Conference on Communication, Control, and Computing, 2008, pp. 798–805.
J. Bierbrauer, H. Schellwat, Almost independent and weakly biased arrays: eﬃcient constructions and cryptologic applications, Lecture Notes in Comput.
Sci. 1880 (2000) 533–543.
S.R. Blackburn, T. Etzion, D.R. Stinson, G.M. Zaverucha, A bound on the size of separating hash families, J. Combin. Theory Ser. A 115 (7) (2008)
1246–1256.
R.C. Bryce, C.J. Colbourn, The density algorithm for pairwise interaction testing, Softw. Test. Verif. Reliab. 17 (2007) 159–182.
R.C. Bryce, C.J. Colbourn, A density-based greedy algorithm for higher strength covering arrays, Softw. Test. Verif. Reliab. 19 (2009) 37–53.
E.J. Candès, Compressive sampling, in: Int. Congress of Mathematics, vol. 3, Madrid, Spain, 2006, pp. 1433–1452.
E.J. Candès, The restricted isometry property and its implications for compressed sensing, C. R. Acad. Sci., Ser. 1 Math. 346 (2008) 589–592.
E.J. Candès, J. Romberg, T. Tao, Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information, IEEE Trans.
Inform. Theory 52 (2006) 489–509.
E.J. Candès, T. Tao, Decoding by linear programming, IEEE Trans. Inform. Theory 51 (2005) 4203–4215.
E.J. Candès, T. Tao, Near optimal signal recovery from random projections: Universal encoding strategies, IEEE Trans. Inform. Theory 52 (2006) 5406–
5425.
K. Chandrasekaran, N. Goyal, B. Haeupler, Deterministic algorithms for the Lovász local lemma, in: Proc. ACM–SIAM Symposium on Discrete Algorithms
(SODA), 2010, pp. 992–1004.
S.S. Chen, D.L. Donoho, M.A. Saunders, Atomic decomposition by basis pursuit, SIAM J. Sci. Comput. 20 (1) (1998) 33–61.
V. Chvátal, A greedy heuristic for the set-covering problem, Math. Oper. Res. 4 (3) (1979) 233–235.
A. Cohen, W. Dahmen, R.A. DeVore, Compressed sensing and best k-term approximation, J. Amer. Math. Soc. 22 (2009) 211–231.
G. Cohen, S. Litsyn, G. Zémor, On greedy algorithms in coding theory, IEEE Trans. Inform. Theory 42 (1996) 2053–2057.
C.J. Colbourn, Constructing perfect hash families using a greedy algorithm, in: Y. Li, S. Zhang, S. Ling, H. Wang, C. Xing, H. Niederreiter (Eds.), Coding
and Cryptology, World Scientiﬁc, Singapore, 2008, pp. 109–118.
C.J. Colbourn, Covering arrays and hash families, in: Information Security and Related Combinatorics, in: NATO Peace Inform. Secur. Ser., IOS Press,
2011, pp. 99–136.
C.J. Colbourn, Eﬃcient conditional expectation algorithms for constructing hash families, Lecture Notes in Comput. Sci. 7056 (2011) 144–155.
C.J. Colbourn, D. Horsley, C. McLean, Compressive sensing matrices and hash families, IEEE Trans. Commun. 59 (2011) 1840–1845.
C.J. Colbourn, J. Torres-Jiménez, Heterogeneous hash families and covering arrays, Contemp. Math. 523 (2010) 3–15.
C.J. Colbourn, J. Zhou, Improving two recursive constructions for covering arrays, J. Statist. Theory Practice 6 (2012) 30–47.
G. Cormode, S. Muthukrishnan, Combinatorial algorithms for compressed sensing, Lecture Notes in Comput. Sci. 4056 (2006) 280–294.
Z.J. Czech, G. Havas, B.S. Majewski, Perfect hashing, Theoret. Comput. Sci. 182 (1997) 1–143.
P. Damaschke, Adaptive versus nonadaptive attribute-eﬃcient learning, Mach. Learn. 41 (2000) 197–215.
D. Deng, D.R. Stinson, R. Wei, The Lovász local lemma and its applications to some combinatorial arrays, Des. Codes Cryptogr. 32 (1–3) (2004) 121–134.
R.A. DeVore, Deterministic constructions of compressed sensing matrices, J. Complexity 23 (2007) 918–925.
D.L. Donoho, X. Huo, Uncertainty principles and ideal atomic decomposition, IEEE Trans. Inform. Theory 47 (2001) 2845–2862.
D.-Z. Du, F.K. Hwang, Combinatorial Group Testing and Its Applications, second edition, World Scientiﬁc Publishing Co. Inc., River Edge, NJ, 2000.
M. Elad, A.M. Bruckstein, A generalized uncertainty principle and sparse representation in pairs of bases, IEEE Trans. Inform. Theory 48 (2002) 2558–
2567.
P. Erdős, L. Lovász, Problems and results on 3-chromatic hypergraphs and some related questions, in: Inﬁnite and Finite Sets, vol. II, Colloq., Keszthely,
1973, in: Colloq. Math. Soc. János Bolyai, vol. 10, North-Holland, Amsterdam, 1975, pp. 609–627.

186

[34]
[35]
[36]
[37]
[38]
[39]
[40]
[41]
[42]
[43]
[44]
[45]
[46]
[47]
[48]
[49]
[50]
[51]
[52]
[53]
[54]
[55]
[56]
[57]

C.J. Colbourn et al. / Journal of Discrete Algorithms 16 (2012) 170–186

P. Erdős, J.L. Selfridge, On a combinatorial game, J. Combin. Theory Ser. A 14 (1973) 298–301.
J.-J. Fuchs, On sparse representations in arbitrary redundant bases, IEEE Trans. Inform. Theory 50 (2004) 1341–1344.
J.J. Fuchs, Recovery of exact sparse representations in the presence of bounded noise, IEEE Trans. Inform. Theory 51 (2005) 3601–3608.
A.C. Gilbert, M.A. Iwen, M.J. Strauss, Group testing and sparse signal recovery, in: 42nd Asilomar Conference on Signals, Systems, 2008, pp. 1059–1063.
A.C. Gilbert, M.J. Strauss, J. Tropp, R. Vershynin, One sketch for all: Fast algorithms for compressed sensing, in: ACM Symp. on Theory of Computing,
2007, pp. 237–246.
R. Gribonval, M. Nielsen, Sparse representations in unions of bases, IEEE Trans. Inform. Theory 49 (2003) 3320–3325.
M.A. Iwen, Combinatorial sublinear-time Fourier algorithms, Found. Comput. Math. 10 (2010) 303–338.
S. Jafarpour, W. Xu, B. Hassibi, R. Calderbank, Eﬃcient and robust compressed sensing using optimized expander graphs, IEEE Trans. Inform. Theory 55
(2009) 4299–4308.
D.S. Johnson, Approximation algorithms for combinatorial problems, J. Comput. System Sci. 9 (1974) 256–278.
R.M. Karp, Reducibility among combinatorial problems, in: Complexity of Computer Computations, Plenum, New York, 1972, pp. 85–103.
L. Lovász, On the ratio of optimal integral and fractional covers, Discrete Math. 13 (4) (1975) 383–390.
K. Mehlhorn, Data Structures and Algorithms 1: Sorting and Searching, Springer-Verlag, Berlin, 1984.
R. Motwani, P. Raghavan, Randomized Algorithms, Cambridge University Press, Cambridge, 1995.
B.K. Natarajan, Sparse approximate solutions to linear systems, SIAM J. Comput. 24 (1995) 227–234.
P. Nayeri, Post-Optimization: Necessity Analysis for Combinatorial Arrays, PhD thesis, Arizona State University, 2011.
C. Nie, H. Leung, A survey of combinatorial testing, ACM Comput. Surv. 43 (2) (2011), #11.
D.J. O’Brien, Exploring hash families and their applications to broadcast encryption, Master’s thesis, Arizona State University, 2011.
S.K. Stein, Two combinatorial covering theorems, J. Combin. Theory Ser. A 16 (1974) 391–397.
D.R. Stinson, Tran Van Trung, R. Wei, Secure frameproof codes, key distribution patterns, group testing algorithms and related structures, J. Statist.
Plann. Inference 86 (2000) 595–617.
D.R. Stinson, R. Wei, K. Chen, On generalized separating hash families, J. Combin. Theory Ser. A 115 (2008) 105–120.
M. Stojnic, W. Xu, B. Hassibi, Compressed sensing-probabilistic analysis of a null-space characterization, in: Int. Conf. Acoustics, Speech and Signal
Processing, 2008, pp. 3377–3380.
J.A. Tropp, Recovery of short, complex linear combinations via l1 minimization, IEEE Trans. Inform. Theory 51 (2005) 1568–1570.
W. Xu, B. Hassibi, Eﬃcient compressive sensing with deterministic guarantees using expander graphs, in: Proceedings of IEEE Information Theory
Workshop, 2007, pp. 414–419.
Y. Zhang, On theory of compressive sensing via 1 -minimization: Simple derivations and extensions, Technical Report CAAM TR08-11, Rice University,
2008.

ATLAS: Adaptive Topology- and Load-Aware
Scheduling

arXiv:1305.4897v2 [cs.NI] 4 Nov 2013

Jonathan Lutz, Charles J. Colbourn, and Violet R. Syrotiuk
CIDSE, Arizona State University, Tempe, AZ 85287-8809
Email: {jlutz, colbourn, syrotiuk}@asu.edu

Abstract—The largest strength of contention-based MAC protocols is simultaneously the largest weakness of their scheduled counterparts: the ability to adapt to changes in network
conditions. For scheduling to be competitive in mobile wireless
networks, continuous adaptation must be addressed. We propose
ATLAS, an Adaptive Topology- and Load-Aware Scheduling
protocol to address this problem. In ATLAS, each node employs a
random schedule achieving its persistence, the fraction of time a
node is permitted to transmit, that is computed in a topology
and load dependent manner. A distributed auction (REACT)
piggybacks offers and claims onto existing network traffic to
compute a lexicographic max-min channel allocation. A node’s
persistence p is related to its allocation. Its schedule achieving p
is updated where and when needed, without waiting for a frame
boundary. We study how ATLAS adapts to controlled changes
in topology and load. Our results show that ATLAS adapts to
most network changes in less than 0.1s, with about 20% relative
error, scaling with network size. We further study ATLAS in
more dynamic networks showing that it keeps up with changes
in topology and load sufficient for TCP to sustain multi-hop flows,
a struggle in IEEE 802.11 networks. The stable performance of
ATLAS supports the design of higher-layer services that inform,
and are informed by, the underlying communication network.
Index Terms—Wireless networks, medium access control,
adaptation.

I. I NTRODUCTION
Despite the well known shortcomings of IEEE 802.11
and other contention-based MAC protocols for mobile wireless networks—such as probabilistic delay guarantees, severe
short-term unfairness, and poor performance at high load—
they remain the access method of choice. The primary reason
is their ease in adapting to changes in network conditions,
specifically to changes in topology and in load. The lack
of timely adaptation is the most serious limitation facing
scheduled MAC protocols. For scheduling to be competitive,
continuous adaptation is required.
Topology-dependent approaches to adaptation in scheduling
alternate a contention phase with a scheduled phase. In the
contention phase, nodes exchange topology information used
to compute a conflict-free schedule that is followed in the
subsequent scheduled phase (see, as examples, [5], [30]).
However, changes in topology and load do not always align
with the phases of the algorithm resulting in a schedule that
often lags behind the network state.
In contrast, the idea behind topology-transparent scheduling
is to design schedules independent of the detailed network
topology [3], [15]. Specifically, the schedules do not depend
on the identity of a node’s neighbours, but rather on how many

of them are transmitting. Even if a node’s neighbours change,
its schedule does not; if the number of neighbours does not exceed the designed bound then the schedule guarantees success.
Though such schedules are robust to network conditions that
deviate from the design parameters [27], because the schedules
do not adapt, the technique remains a theoretical curiosity.
In contention-based schemes, such as IEEE 802.11, a node
computes implicitly when to access the channel, basing its decisions on perceived channel contention. We instead compute
a node’s persistence—the fraction of time it is permitted to
transmit—explicitly in a way that tracks the current topology
and load. To achieve this, we propose ATLAS, an Adaptive
Topology- and Load-Aware Scheduling protocol. Channel
allocation is a resource allocation problem where the demands
correspond to transmitters, and the resources to receivers.
ATLAS implements the REsource AlloCaTion computed by
REACT, a distributed auction that runs continuously. REACT
piggybacks offers and claims onto existing network traffic to
compute the lexicographic max-min allocation to transmitters
which we call the TLA allocation, emphasizing that it is
both topology- and load-aware. Each node’s random schedule,
achieving a persistence informed by its allocation, is updated
whenever a change in topology or load results in a change
in allocation. While the slots of the schedule are grouped
into frames, this is done only to reduce the variance in delay
[6]; there is no need to wait for a frame boundary to update
the schedule. Even though the random schedules may not be
conflict-free, ATLAS is not contention-based; it does not select
persistences or make scheduling decisions based on perceived
channel contention—its decisions are based solely on topology
and load. We study how ATLAS adapts to controlled changes
in topology and load, measuring convergence time, relative
error, and scalability. We also assess the ability of ATLAS to
adapt in more dynamic network conditions.
To the best of our knowledge, ATLAS is the first scheduled
MAC protocol able to adapt to changes in topology and
load that is competitive with contention-based protocols in
throughput and delay while realizing superior delay variance.
It achieves this through the continuous computation of the
TLA allocation, and updating the schedule on-the-fly. These
updates occur only where and when needed. By not requiring
phases of execution and by computing persistences rather
than conflict-free schedules, ATLAS eliminates the complexity
of, and lag inherent in, topology-dependent approaches. By
not being dependent on the identity of neighbours, ATLAS
shares the best of topology-transparent schemes (and also their

c
Submitted to IEEE Transactions on Mobile Computing – 
2013
IEEE

2

potential for collisions) yet overcomes its weakness by being
adaptive. By not forcing updates to be frame synchronized,
ATLAS shares the critical features of continuous adaptation
with contention-based protocols. As a result, ATLAS achieves
predictable throughput and delay characteristics. Such characteristics and information about localized capacity at the MAC
layer may be used to inform higher layers, while end-toend characteristics at higher layers may be used to inform
ATLAS. This may support the development of an agile, higher
performing protocol stack.
The primary contributions of this paper are twofold: (1) The
REACT algorithm, an asynchronous, adaptive, and distributed
auction that solves a general resource allocation problem to
produce the TLA allocation. (2) ATLAS, a MAC protocol
that uses REACT to solve the specific problem of channel
allocation in a wireless network where each node produces
a random schedule with the number of transmission slots
determined by its allocation.
The sequel is organized as follows: Section II defines a
general resource allocation problem and presents the REACT
algorithm, proving its correctness. Section III expresses channel allocation as a resource allocation problem and defines
ATLAS. Related work is described in Section IV. After
describing the simulation set-up in Section V, Section VI
studies how ATLAS adapts to controlled changes in topology
and load, and to dynamic network conditions. In Section VII,
we discuss open issues and potential applications of REACT,
including the design of higher-layer services that inform, and
are informed by, the underlying communication channel.
II. D ISTRIBUTED R ESOURCE A LLOCATION — REACT
We consider a general resource allocation problem. Let R
be a set of N resources with capacity c = (c1 , . . . , cN ). Let D
be a set of M demands with magnitudes w = (w1 , . . . , wM ).
Resource j ∈ R is required by demands Dj ⊆ D. Demand
i ∈ D consumes capacity at all resources in Ri ⊆ R
simultaneously. The resource allocation s = (s1 , . . . , sM ),
si ≥ 0 defines the capacity P
reserved for the demands. Resource
allocation s is feasible if i∈Dj si ≤ cj for all j ∈ R and
si ≤ wi for all i ∈ D. Demand
P i is satisfied if si ≥ wi .
Resource j is saturated if
i∈Dj si ≥ cj . Throughout,
capacity refers to the magnitude of a resource.
Definition 1: [22] A feasible allocation s is lexicographically max-min if, for every demand i ∈ D, either i is satisfied,
or there exists a saturated resource j with i ∈ Dj where
si = max(sk : k ∈ Dj ).
We now describe REACT, a distributed auction that computes the lexicographic max-min allocation. In it, resources
are represented by auctioneers and demands by bidders. Each
auctioneer maintains an offer—the maximum capacity consumed by any adjacent bidder—and each bidder maintains a
claim—the capacity the bidder intends to consume at adjacent
auctions. The final claim of bidder i defines allocation si .
Auctioneer j satisfies Def. 1 locally by increasing its offer in
an attempt to become saturated while maintaining a feasible
allocation. Bidder i satisfies Def. 1 locally for demand i by
increasing its claim until it is satisfied or has a maximal claim

Algorithm 1 REACT Bidder for Demand i.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:

upon initialization
Ri ← ∅
wi ← 0
U PDATE C LAIM ()
end upon
upon receiving a new demand magnitude wi
U PDATE C LAIM ()
end upon
upon receiving offer from auctioneer j
offers[j] ← offer // Remember the offer of auctioneer j.
U PDATE C LAIM ()
end upon
upon bidder i joining auction j
Ri ← Ri ∪ j // Resource j is now required by demand i.
U PDATE C LAIM ()
end upon
upon bidder i leaving auction j
Ri ← Ri \ j // Resource j is no longer required by demand i.
U PDATE C LAIM ()
end upon
procedure U PDATE C LAIM ()
// Select the claim to be no larger than the smallest offer or wi .
claim ← min ({offers[j] : j ∈ Ri }, wi )
send claim to all auctions in Ri
end procedure

at an adjacent auction. Through continuous updates of offers
and claims, the auctioneers and bidders eventually converge
on the lexicographic max-min allocation. We give precise
definitions of auction and bidder behaviour next.
Bidder i knows wi and maintains set Ri . Offers are stored in
offers[]; offers[j] holds the offer last received from auctioneer
j. Bidder i constrains its claim to be no larger than wi or the
smallest offer from auctioneers in Ri ,
claim = min ({offers[j] : j ∈ Ri }, wi ) .

(1)

Auctioneer j knows cj and maintains set Dj . Bidder claims
are stored in claims[]; claims[i] holds the claim last received
from bidder i. Auctioneer j identifies set Dj∗ ⊆ Dj containing
bidders with claims strictly smaller than its offer,
Dj∗ = {b : b ∈ Dj , claims[b] < offer}.

(2)

Bidders in Dj∗ are either satisfied or are constrained by another
auction and cannot increase their claims in response to a larger
offer from auctioneer j. Bidders in Dj \ Dj∗ are constrained
by auction j. They may increase their claims in response to a
larger offer. Resources left unclaimed by bidders in Dj∗ ,
P

Aj = cj −
(3)
i∈D ∗ claims[i] ,
j

remain available to be offered in equal portions to bidders in
Dj \Dj∗ . If claims of all bidders in Dj are smaller than the offer
(i.e., Dj = Dj∗ ), there are no bidders to share the available
resources in Aj . The auctioneer sets its offer to Aj plus the
largest claim, ensuring that any bidder in Dj can increase its
claim to consume resources in Aj :
(
Aj /|Dj \ Dj∗ |,
if Dj 6= Dj∗ ,
offer =
(4)
Aj + max (claims[i] : i ∈ Dj ) , otherwise.
Alg. 1 and Alg. 2 describe actions taken by the bidders
and auctioneers of REACT in response to externally triggered

3

Algorithm 2 REACT Auctioneer for Resource j.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:
43:
44:

upon initialization
Dj ← ∅
cj ← 0
U PDATE O FFER ()
end upon
upon receiving a new capacity of cj
U PDATE O FFER ()
end upon
upon receiving claim from bidder i
claims[i] ← claim // Remember the claim of bidder i.
U PDATE O FFER ()
end upon
upon bidder i joining auction j
Dj ← Dj ∪ i // Demand i now requires resource j.
U PDATE O FFER ()
end upon
upon bidder i leaving auction j
Dj ← Dj \ i // Demand i no longer requires resource j.
U PDATE O FFER ()
end upon
procedure U PDATE O FFER ()
Dj∗ ← ∅
Aj ← cj
done ← False
while ( done = False ) do
// If Dj∗ contains all bidders in Dj , then auction j does not
// constrain any of the bidders in Dj .
if ( Dj∗ = Dj ) then
done ← True
offer ← Aj + max ({claims[i] : i ∈ Dj })
// Otherwise, auction j constrains at least one bidder in Dj .
else
done ← True
// What remains available is offered in equal portions to the
// bidders constrained by auction j.
offer ← Aj /|Dj \ Dj∗ |
// Construct Dj∗ and compute Aj for the new offer.
for all b ∈ {Dj \ Dj∗ } do
if ( claims[b] < offer ) then
Dj∗ ← Dj∗ ∪ b
Aj ← Aj − claims[b]
done ← False
send offer to all bidders in Dj
end procedure

events. Collectively, auctioneers and bidders know the inputs
to the allocation problem and bidder claims converge on
the lexicographic max-min allocation; the claim of bidder i
converges on si .
The correctness of Alg. 1 and Alg. 2 is established in
two steps: Lemma 1 establishes forward progress on the
number of auctioneers to have converged on their final offer.
Theorem 1 employs Lemma 1 to show eventual convergence
to the lexicographic max-min allocation. Let claimi denote the
claim of bidder i and offerj the offer of auctioneer j. Assume
that the resource allocation remains constant for the period of
analysis, that bidder i knows Ri and wi , and that auctioneer
j knows Dj and cj . Further assume communication between
adjacent auctioneers and bidders is not delayed indefinitely. A
claim or offer is stable if it has converged on its final value.
Denote by Astable the set of auctioneers whose offers are stable
and remain the smallest among all offers.
Lemma 1: Suppose Astable contains k auctioneers, 0 ≤ k <
N . Then, within finite time, at least one auctioneer converges

on the next smallest offer omin . Offers equal to omin are stable
and remain smaller than all other offers not in Astable .
Proof: Wait sufficient time for every bidder i to send a
new claim to auctioneers in Ri and for every auctioneer j to
send a new offer to bidders in Dj . Let omin be the smallest
offer of an auctioneer not in Astable . Assume to the contrary that
offerx for some x ∈
/ Astable is the first to become smaller than
omin . By Eq. 2 and 4, a decrease to offerx can only occur after a
bidder y at auction x with claimy < offerx increases its claim.
By Eq. 1, claimy can increase only after its limiting constraint
starts out smaller than offerx and increases. Constraints in the
system smaller than offerx are maximum claims, offers from
Astable , and offers equal to omin . Maximum claims and offers
from Astable do not change, leaving some x0 with offerx0 = omin
as the only potential limiting constraint for claimy . By Eq. 2
and 4, offerx0 can increase only after one of its bidders y 0
reduces its claim to be smaller than offerx0 . By Eq. 1, claimy0
can get smaller only after one of its auctioneers, say x00 ,
reduces its offer to be offerx00 < omin = offerx0 contradicting
the assumption that offerx is the first to become smaller than
omin . Therefore, offers equal to omin remain smaller than offers
not from Astable .
By Eq. 2 and 4, any j offering omin can change only after
a bidder i at auction j with claimi ≤ omin changes. By Eq. 1,
claimi only changes if its limiting constraint changes. Potential
limiting constraints include wi , offers from Astable , and offers
equal to omin . These constraints are stable; therefore, offers
equal to omin are stable.
Theorem 1: Bidders and auctioneers of Alg. 1 and Alg. 2
compute the lexicographic max-min allocation.
Proof: We apply Lemma 1 to show by induction that
every auctioneer eventually computes a stable offer.
Base Case: Consider an allocation problem with arbitrary
wi , cj , Ri , and Dj for 1 ≤ i ≤ M , 1 ≤ j ≤ N . Let |Astable | =
0. By Lemma 1, at least one auctioneer eventually converges
on a smallest offer omin . Offers equal to omin are stable and
remain smallest among all offers. Add auctioneers offering
omin to Astable ; |Astable | ≥ 1.
Inductive Step: Let |Astable | = k, 1 ≤ k < N . Then, by
Lemma 1 a non-empty set of auctioneers A+ with A+ ∩
Astable = ∅ eventually converge on the next smallest offer.
Offers from A+ remain smaller than offers not from A+ or
Astable and are stable. Add A+ to Astable ; |Astable | ≥ k + 1.
By induction, all auctioneers are eventually added to Astable .
Wait for auctioneers to send their offers to adjacent bidders.
Bidder claims are now stable. By Eq. 1, bidder i is either
satisfied with its claim (claimi = wi ) or its claim is maximal at
an auction in Ri . By Definition 1, the claims are lexicographic
max-min.
III. T HE ATLAS MAC P ROTOCOL
Channel allocation in wireless networks can be expressed
as a resource allocation problem. In this context, transmitters
correspond to the demands in D and receivers to the resources
in R. Label transmitters {1, . . . , M } and receivers {1, . . . , N }.
A transmitter with a non-zero demand magnitude is active.
Receiver j is in Ri if it is within transmission range of

4

Slot x + 3

pkt #1

pkt #1

ack #1

pkt #2

ack #2

Node B

collision

pkt #1

ack #1

pkt #2

ack #2

Node C

pkt #2

pkt #1

ack #1

pkt #2

ack #2

Header
Fields

claim
offer

Slot x

MAC Header

Slot x + 1

MAC Payload

Header
Fields

claim
offer

Slot x + 2

Node A

Node # 1
w1 = 0.45
s1 = 0.25
s∗1 = 0.20

ACK
Fields

MAC Header

Fig. 1.
Example transmissions in ATLAS of two packets in a network of
three fully connected nodes. The first packet is sent from node A to node
C. The second packet is sent from node C to node B. Transmissions are
coloured white and receptions are shaded grey. The frame structure is shown
for a data packet and an acknowledgement.

Node # 7
w7 = 0.30
s7 = 0.30
s∗7 = 0.20

Node # 3
w3 = 0.50
s3 = 0.25
s∗3 = 0.20

Node # 2
w2 = 0.55
s2 = 0.25
s∗2 = 0.20

Node # 5
w5 = 0.75
s5 = 0.45
s∗5 = 0.55
Node # 4
w4 = 0.40
s4 = 0.25
s∗4 = 0.20

Bidirectional Link
New Bidirectional Link

transmitter i and transmitter i is active. Dj contains the active
transmitters for which receiver j is within transmission range.
Receiver j is adjacent to transmitter i if j ∈ Ri and i ∈ Dj .
The sets Dj and Ri capture the network topology for active
transmitters. For load, wi is set to the percentage of slots
required to support the demand at transmitter i. Transmitters
with no demand (i.e., wi = 0) receive an allocation of zero
slots: they are not active. Receiver capacities are set to one,
targeting 100% channel allocation. The lexicographic max-min
solution s = (s1 , . . . , sM ) for a given topology and traffic load
is the TLA allocation.
To apply REACT to channel allocation, we integrate it into
ATLAS, a simple random scheduled MAC protocol. Although
REACT could instead augment contention-based schemes, we
choose to work within a scheduled environment, a traditionally
difficult setting for adaptation. In ATLAS, each node runs a
REACT bidder (Alg. 1) and a REACT auctioneer (Alg. 2)
continuously. Auctioneers and bidders discover each other as
they hear from one another and rely on the host node to detect
lost adjacencies. The network topology is implicit in the sets
Ri and Dj . Each node updates its bidder’s demand magnitude
to accurately reflect its traffic load. Offers and claims are encoded using eight bits each and are embedded within the MAC
header of all transmissions to be piggybacked on existing
network traffic. The encoding supports a total of 256 values for
offers, claims, and persistences uniformly distributed between
0 and 1; the error in the representation does not exceed 0.004.
Adding fields for an offer and claim to data packets and
acknowledgements results in a communication overhead of
four bytes per packet. For the slot size and data rate simulated
in Section VI, the overhead is 0.36%. A node’s offer and claim
are eventually received by all single-hop neighbours reaching
the bidders and auctioneers that need to know the offer and
claim. In time, the bidder claims in REACT converge on the
TLA allocation s.
Packets are acknowledged within the slot they are transmitted and slots are sized accordingly. Unacknowledged MAC
packets are retransmitted up to ten times before they are
dropped by the sender. Fig. 1 shows that collisions are possible
in ATLAS, and that successful transmissions are acknowledged in the same slot. The transmissions collide in slot x;
they are repeated (successfully) in slots x + 2 and x + 3. Fig. 1
also shows the frame structure.
The TLA allocation can be interpreted directly as a set of

Node # 6
w6 = 0.05
s6 = 0.05
s∗6 = 0.05

Fig. 2. Example network showing the TLA allocation computed by REACT
before and after an added link in the topology. wi identifies a node’s demand,
si its initial TLA allocation, and s∗i its TLA allocation after the added link.
Resource capacities are set to one. Double-lined circles identify nodes with
saturated resources.

persistences in a p-persistent MAC [28]. However, we achieve
lower variation in delay by introducing the notion of a frame
[6]. Specifically, ATLAS divides time into slots which are
organized into frames of v slots. Node i operates at persistence
pi = si . At the start of every frame and upon any change to
pi , node i computes ki = bpi vc + 1 with probability πi and
ki = bpi vc with probability 1 − πi where πi = pi v − bpi vc.
Node i constructs a transmission schedule of ki slots selected
uniformly at random. Over many frames, E[ki ]/v equals pi
where E[ki ] is the expectation for ki .
Fig. 2 shows the TLA allocation in a small example network
before and after a change in topology. Node 7 starts out
disconnected from the other nodes and moves within range
of node 3. In REACT, node 3 starts out offering 0.25 which is
claimed by the bidders of nodes 1, 2, 3, and 4. With the claims
of node 3 and 4 limited by the offer of node 3 and the claim
of node 6 limited by its demand, the auctioneer at node 4 is
free to offer 0.45, which is claimed by node 5. Upon detecting
node 7 as a neighbour, the auctioneer at node 3 decreases its
offer to 0.20. The bidders at nodes 1, 2, 3, 4, and 7 respond
by reducing their claims accordingly. The smaller claims of
the bidders at nodes 3 and 4 allow the auctioneer at node 4
to increase its offer to 0.55. The bidder at node 5 responds by
increasing its claim to 0.55. It can be verified that, before and
after the topology change, the claims of the bidders (i.e., the
values of si and s∗i ) are lexicographically max-min; that is,
every claim is satisfied or is maximal at an adjacent auction.
Consider the topology with node 3 and node 7 connected. The
bidder at node 6 is satisfied. The bidders at nodes 1, 2, 3, 4,
and 7 are maximal at the auction of node 3. The bidder at
node 5 is maximal at the auction of node 4.
There are many implementation choices to be made in applying REACT to channel allocation. We identify three binary
choices—lazy or eager persistences, physical layer or MAC
layer receivers, and weighted or non-weighted bidders—and
three configurable parameters—pmin , pdefault , and tlostNbr . The
choices are described here; they are evaluated in Section VI.

5

A. Lazy or Eager Persistences
A lazy approach sets persistence pi equal to the claim of
bidder i. Once converged, pi matches the TLA allocation
interpreted as a persistence. There is a potential disadvantage
with being lazy. For many applications, nodes cannot predict
future demand for the channel; they can only estimate demand
based on past events, i.e., packet arrival rate or queue depth.
As a consequence, wi lags the true magnitude of the demand
at node i. If wi is the limiting constraint for the claim
of bidder i, pi can be sluggish in response to increases
in demand. Alternatively, an eager approach sets persistence
pi = min (offers[j] : j ∈ Ri ), breaking the direct dependence
on wi . Under stable conditions, a node’s channel occupancy,
the fraction of time it spends transmitting, matches its TLA
allocation; its occupancy is limited by the availability of
packets to transmit which is no larger than wi , even when
pi > wi . By allowing pi > wi , the persistence is made more
responsive to sudden increases in demand.

overwhelmed by neighbouring transmitters, a non-zero persistence is needed to quiet the neighbours. To accomplish this, the
node enforces a minimum persistence pmin , creating dummy
packets if necessary, whenever the sum of claims from adjacent
bidders exceeds the auction capacity.
E. Overriding the TLA Allocation with pdefault
There are two conditions where a node constrains its persistence to be no larger than pdefault . The first is when it has
no neighbours. While the TLA allocation permits an isolated
node to consume 100% of the channel, it cannot discover new
neighbours if it does so. The second time a node employs
pdefault is for a short period after the discovery of a new
neighbour. It is possible for several nodes operating with large
persistences to join a neighbourhood at about the same time. If
the persistences are large enough, neighbour discovery can be
hindered. For both scenarios, limiting the persistence to pdefault
facilitates efficient neighbour discovery.

B. Physical Layer or MAC Layer Receivers

F. Adaptation to Topology Changes and tlostNbr

A central objective of the TLA allocation is to ensure
that no receiver is overrun. In a wireless network, receivers
can be defined in terms of physical layer or MAC layer
communication. At the physical layer, every node is a receiver. At the MAC layer, packets are filtered by destination
address; a node is only a receiver if one of its neighbours
has MAC packets destined to it. MAC layer receivers can
increase channel allocation by over-allocating at non-receiving
nodes. However, the overallocation can slow detection of
new receivers. Physical receivers prevent overallocation at any
receiver, making the allocation more responsive to changes in
traffic where nodes become receivers.

Changes in network topology are detected externally to
REACT. In ATLAS, neighbour discovery is performed independently by each node. If a node hears from a new neighbour,
then the node notifies its bidder of the new auction and
its auctioneer of the new bidder. Conversely, if a node has
not heard from a neighbour in more than tlostNbr seconds, it
presumes the node is no longer a neighbour and informs its
auctioneer and bidder accordingly.

C. Weighted or Non-Weighted Bidders
We have described a MAC protocol where transmitters are
represented by equally weighted bidders. For applications requiring multiple demands per transmitter, i.e., nodes servicing
more than one traffic flow, we propose the weighted TLA
allocation. The demands of weighted bidders are comprised
of one or more demand fragments; the number of fragments
accumulated into a demand is the demand’s weight. Let γi
be the weight for demand i. Demand fragments in demand i
have magnitude wi /γi . The weighted TLA allocation defines
the lexicographically max-min vector u = (u1 , . . . , uN ) where
ui is the allocation to each demand fragment in demand i
for a total allocation of ui γi to demand i. REACT can be
extended to compute the weighted TLA allocation. To do
this, each bidder must inform adjacent auctions of its weight.
Sixteen unique weights (with a four-bit representation) may
be sufficient for many applications.
D. Minimum Persistence pmin
A node can maintain a persistence of zero without impacting
the communication requirements of its bidder. For auctioneers,
a persistence of zero is problematic. If a receiver becomes

IV. R ELATED W ORK
This paper focuses on the TLA allocation, its continuous
distributed computation, and its application to setting transmitter persistences. In this section, we review a representative
set of scheduled MAC protocols, observing how each selects
a node’s persistence and adapts to topology and load.
Any finite schedule used in a cyclically repeated way can
be generalized as a (k, v)-schedule with k transmission slots
per frame of v slots, producing an effective persistence of
p = k/v. Examples include the random schedules of [6], [18]
where each node selects its k transmission slots randomly
from the set of v slots in the frame. Topology transparent schemes [3], [15], [27] also implement (k, v)-schedules.
These schedules rely on only two design parameters: N , the
number of nodes in the network, and Dmax , the maximum
supported neighbourhood size. These schedules guarantee each
node a collision-free transmission opportunity from each of
its neighbours at least once per frame, provided the node’s
neighbourhood size does not exceed Dmax . (k, v)-schedules do
not adapt to variations in neighbourhood size or traffic load.
The combinatorial requirements for variable-weight topology
transparent schedules (variable k) are explored in [19], but no
construction nor protocol using them is given.
A class of topology-dependent scheduled protocols compute
distance-2 vertex colourings of the network graph to achieve
TDMA schedules with spatial reuse. The colourings assign
one transmission slot to each node and do not adapt to

6

TABLE I
ATLAS CONFIGURATIONS SELECTED FOR SIMULATION .
Configuration
Name
Nominal
Lazy Persistences
Physical Receivers
Weighted Bidders

Eager (0)
or Lazy (1)
0
1
0
0

MAC (0) or
Physical (1)
0
0
1
0

Unweighted (0)
or Weighted (1)
0
0
0
1

traffic load. One of the first distributed protocols to bound
the number of colours is proposed in [5]. Distributed-RAND
(DRAND) [25] is a distributed implementation of RAND (a
centralized algorithm for distance-2 colouring [23]). DRAND
runs a series of loosely synchronized rounds. A colour is
assigned in each round to one or more nodes in different
two-hop neighbourhoods. DRAND is employed by ZebraMAC (Z-MAC) [24] to compute schedules over which to run
CSMA/CA. Nodes are given priority access to their own slot,
but also allowed to contend for access in other unused slots, as
is done in [4]. Due to the complexity of DRAND, schedules
are only computed once during network initialization.
Other topology-dependent schemes support variable persistences. The periodic slot chains proposed in [14] are not
limited to the structure of a fixed length frame and can support
variable and arbitrarily precise persistences. A slot chain is
defined by its starting transmission slot and period between
its consecutive transmission slots. By combining multiple
slot chains with different periods, schedules are constructed
targeting any rational persistence in the range [0, 1]. The
computation of slot chains provided in [14] is centralized; a
distributed mechanism to adaptively compute the slot chains
remains an open problem. In [30], a five phase reservation
protocol (FPRP) computes conflict-free schedules where a
node can reserve one or more transmission slots in the frame
to achieve variable persistences. Reservation frames are run
periodically rather than on a demand basis and, therefore, may
not accommodate the current topology and traffic load.
In SEEDEX [26], nodes do not attempt to derive conflictfree schedules. They learn the identities of their two-hop
neighbours and adjust transmission probabilities (i.e., persistences) to improve the likelihood of collision-free transmissions. The transmission probabilities accommodate the number
and identity of neighbours, but not traffic load.
In our earlier work [20], a distributed algorithm for computing the TLA allocation is provided; however, the algorithm
assumes a fixed topology and does not adapt to changes in the
network. REACT solves these limitations by asynchronously
adapting to changes in both topology and traffic demand.

A. Scenario Details
Unless otherwise noted, all four configurations run with
pdefault = 0.05, tlostNbr = 0.5s, and pmin = 0.01. The selection
of pdefault and tlostNbr are justified by results in Figs. 5, 11a,
and 11b. The selection of pmin is based on [20]. Frames
contain v = 100 slots of length 800µs (1100 bytes per slot).
Simulations are run using the ns-2 simulator [21]. Each
wireless node is equipped with a single half-duplex transceiver
and omni-directional antenna whose physical properties match
those of the 914 MHz Lucent WaveLAN DSS radio. The data
rate for all simulations is 11 Mbps. The transmission and
carrier sense ranges are 250m.
Each simulation runs a network scenario composed of a
randomly generated topology and a randomly generated traffic
load. Unless specified otherwise, topologies contain 50 randomly placed nodes constrained to a 300 × 1500m2 area. With
the exception of the multi-hop TCP flows in Section VI-F,
each traffic load consists of single-hop constant rate traffic.
Four traffic loads are simulated: 20% and 80% of nodes loaded
with small demands (75 ± 50 pkts/s), 20% and 80% of nodes
loaded with large demands (500 ± 50 pkts/s). Nodes loaded
with traffic are selected at random and the demand magnitudes
are selected uniformly at random from the specified range.
The packet destination is selected dynamically from the set
of neighbouring nodes as the packet is passed down to the
MAC layer. For the Weighted Bidders configuration, each
demand is assigned a random integer weight between one
and five. Traffic is generated by constant bit rate generators
and transported over UDP; packets are 900 bytes in length,
leaving room in each slot for header bytes and a MAC layer
acknowledgement. Combined with the random placement of
nodes and the addition of mobility, these four traffic loads
enable simulation of a wide variety of network conditions.
B. Relative Error
A metric of interest is the average relative error for a
node’s persistence with respect to the TLA allocation. Error
is reported in two parts: relative excess and deficit persistence
error. Errors are measured per node over 80ms consecutive
intervals in time (equal to the length of one MAC frame).
We compute the average relative excess error and average
relative deficit error for a given sample set of persistence
measurements. The relative errors are ratios, requiring use of
the geometric rather than arithmetic mean. But, the errors are
often zero, preventing direct use of their mean. Instead, we
convert errors into accuracies eliminating zeros from the data
set for a more meaningful geometric average. The average
relative accuracies are converted back to relative errors.

V. S IMULATION S ET- UP
We now describe the simulations used to produce the experimental results presented in Section VI. Table I lists the four
ATLAS configurations simulated. The Nominal configuration
employs eager persistences, defines receivers in terms of MAC
layer communication, and operates with unweighted bidders.
The other three configurations differ from the Nominal case
by a single choice and are named accordingly.

VI. E VALUATION OF ATLAS
Results from [20] show the TLA allocation applied in a
static network to maintain expected delay and throughput
compared to IEEE 802.11, while reducing the variance for
both metrics. The TLA allocation nearly eliminates packets
dropped by the MAC layer. In this section, we build on these
results, focusing on the efficient distributed computation of the

7

Fig. 3.

Convergence time following network initialization.

simulations of 1000 network scenarios, 250 of each traffic
load. The scenarios are simulated eight times each, once per
default persistence: 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, and
0.4. Small default persistences (pdefault ≤ 0.01) limit a node’s
ability to communicate during neighbour discovery, slowing
convergence. Large default persistences (pdefault ≥ 0.3) permit
nodes to transmit with large persistences before they discover
their neighbours. In networks with 40 large demands, the large
persistences can overwhelm the channel preventing neighbour
discovery and delaying convergence. ATLAS is robust to the
selection of pdefault with a suitable range of [0.05–0.2]. For the
remaining simulations, pdefault is 0.05.
B. Convergence after a Change in Demand

TLA allocation in the face of changes in topology and load.
The results presented here work to answer four questions:
1) Can ATLAS converge quickly on the TLA allocation?
2) Can ATLAS scale to larger networks?
3) Can ATLAS keep up with changes in a mobile network?
4) Can ATLAS adapt to multi-hop traffic flows?
The first question is addressed Sections VI-A, VI-B, and VI-C.
The second is addressed in Section VI-D. The third and
fourth questions are addressed in Sections VI-E and VI-F,
respectively. Continuing the focus on adaptation, Section VI-G
provides comparisons with several scheduled protocols.
A. Convergence after Network Initialization
Fig. 3 reports average convergence times for all four ATLAS configurations. Error bars denote the arithmetic standard
deviation from the mean for each sample set. Convergence is
measured from network initialization (time = 0) to the time
ATLAS converges on the TLA allocation. Times are collected
from simulations of 1000 network scenarios simulated four
times each, once per configuration. There are 250 scenarios
for each traffic load.
The Physical Receivers configuration converges fastest in
less than 0.4s on average for networks with 40 large demands
and faster for other traffic loads. The extra step of detecting
MAC receivers slows convergence. The Lazy Persistences
configuration is the slowest with an average convergence time
of 0.67s for networks with 40 large demands. The strict
limit on persistences enforced by this configuration slows
convergence compared to the others.
Fig. 4a shows average excess and deficit relative persistence
errors for all four configurations. The averages are computed
for nodes with a non-zero TLA allocation and only during convergence. Nodes are observed to operate within approximately
20% of their TLA allocation regardless of configuration.
Deficit errors are larger than excess errors reflecting a tendency
to converge from below, rather than above, the TLA allocation.
In Fig. 4b, each data point reflects the convergence time (xcoordinate) and total relative persistence error (y-coordinate)
for one simulation of the nominal configuration. The data
shows relative persistence error to be fairly consistent from
network to network with a maximum observed error of 27%.
Fig. 5 reports convergence time for the Nominal configuration while varying pdefault . Convergence is measured for

Fig. 6 reports convergence times and relative persistence
errors for the Nominal configuration following a change to a
single demand magnitude. Four types of demand are simulated: a new small demand, a new large demand, a removed
small demand, and a removed large demand. New demands
start with magnitude zero and change to 75 ± 50 pkts/s for
small demands and to 500 ± 50 pkts/s for large demands.
Removed small demands and removed large demands start
at 75 ± 50 pkts/s and at 500 ± 50 pkts/s, respectively; both
change to zero. The four demand change types are simulated
under the four traffic loads. REACT is allowed to converge
on the initial TLA allocation prior to the demand change.
Convergence times and error measurements are taken from
simulations of 4000 network scenarios, 250 for each of the 16
demand change and traffic load combinations.
Fig. 6a reports convergence times measured from the time
of the change to the time of convergence on the new TLA
allocation. The largest convergence times of approximately
0.175s are found in networks loaded with 40 demands. The
average convergence time for the other scenarios is 0.125s
or smaller. Fig. 6b shows relative persistence errors measured
during convergence at nodes whose TLA allocation are affected by the demand change. Persistences are observed to be
within 10% of the TLA allocation.
C. Convergence after a Change in Topology
Fig. 7 reports convergence time and relative persistence
error following two types of topology change: the creation
of a link and the removal of a link between a pair of nodes.
Simulations are run on 2000 network scenarios, 250 for each
topology change type and traffic load combination. Networks
that lose a link are simulated once per neighbour timeout
tlostNbr of 0.5s, 2.0s and 5.0s.
Network topologies are generated as follows. A first node
is placed at a random location in the simulation area. For
topologies gaining a link, a second node is placed just outside
the transmission range of the first node with a trajectory
toward the first node. For topologies losing a link, the second
node is placed just inside the transmission range of the first
node with a trajectory away from the first node. The remaining
48 nodes are placed at random locations in the simulation area.
The distance travelled by the second node is constrained to
avoid unintentional topology changes.

8

(a) Relative excess and deficit persistence errors.
Fig. 4.

Fig. 5.

(b) Convergence time vs. error for the Nominal configuration.

Relative persistence error for ATLAS.

Convergence times when run with varying default persistences.

The expected convergence time following the addition of a
new link is 0.025s. For tlostNbr =0.5s, convergence is reached in
less than 0.13s on average. For tlostNbr =2.0s and tlostNbr =5.0s,
the large convergence times are dominated by tlostNbr . Except
for the simulations of Fig. 11, all others configure ATLAS
with tlostNbr =0.5s. During convergence, nodes affected by the
topology change are observed to operate within 4% of their
TLA allocation on average. These numbers are striking. The
small convergence times stem from a counterintuitive feature
of the TLA allocation: the majority of topology changes do
not affect the TLA allocation. A new link only has an effect
if the link connects a bidder with an auction that lacks the
capacity to support the bidder’s claim. Even in heavily loaded
networks, many auctions have spare capacity to support a new
bidder. For these scenarios, convergence is instantaneous.
D. Scalability to Large Networks
We now turn to results demonstrating ATLAS’s scalability.
We simulate 10 network sizes with the x-dimension ranging
from 600m (2.4 hops) to 6000m (24 hops) in 600m increments;
the y-dimension is held constant at 300m. The number of
nodes is selected to keep the average neighbourhood density
constant across all network sizes. Fig. 8 reports convergence
times for 4000 network scenarios, 100 of each traffic load
and network size combination. The convergence of ATLAS
in large networks is striking. In networks spanning 24 hops,

convergence is reached in an average of 0.89s, a mere 40%
increase compared to networks spanning 4.8 hops.
The impressive convergence times, particularly those of
networks spanning 12 or more hops, suggest that convergence
happens locally, allowing distant neighbourhoods to converge
in parallel. This local behaviour is captured in Fig. 9 which
reports the average distance between a network change and a
node whose bidder changes its claim in response. Distances
are reported in hops. A node that changes its demand or
gains/loses a neighbour has distance zero. Neighbours of this
node have distance one, and so on. Range of impact is reported
for the six types of change evaluated in Sections VI-B and
VI-C. Each type of change is simulated in 1000 network
scenarios, 250 of each traffic load. The range of impact is
less than 1.75 hops on average.
E. Performance with Node Mobility
Section VI-C addresses the robustness of ATLAS to single topology changes. We now evaluate its performance in
networks with continuous mobility which may not have the
opportunity to converge on the TLA allocation.
Fig. 10a reports persistence error for node speeds ranging
from 0 m/s to 120 m/s with 200 scenarios simulated for each
node speed, 50 of each traffic load. Node movements are
generated using the steady-state mobility model generator of
[13] with a pause time of zero. Simulations are run for 20s.
As node speeds increase, so do deficit persistence errors. The
larger deficit errors are an artifact of lost neighbour detection
which is delayed by tlostNbr = 0.5s. As a result, nodes tend to
think their neighbourhoods are more crowded than they are, a
tendency that gets worse as node speeds increase. In terms of
REACT, auctioneers and bidders unnecessarily constrain their
offers and claims to accommodate lost neighbours. The deficit
persistences translate to degraded throughput. Fig. 10b reports
MAC throughput for the simulations of Fig. 10a. Even with
node speeds of 120 m/s where a node travels its transmission
range in 2.1s, throughput degrades modestly, decreasing by
less than 20% compared to static networks.
Fig. 11 shows that a large tlostNbr exacerbates deficit persistence error and further degrades throughput. Data is collected
from 200 scenarios, 50 of each traffic load. Each scenario is
simulated five times with neighbour timeouts ranging from

9

(a) Convergence time after a demand change.
Fig. 6.

(a) Convergence time after a topology change.
Fig. 7.

Fig. 8.

(b) Relative persistence error after a demand change.

Convergence time and relative persistence error during convergence following a single demand change.

(b) Relative persistence error after a topology change.

Convergence time and relative persistence error following a single topology change.

Convergence times as the width of the network grows.

0.1s to 15.0s. Node speeds are fixed at 30 m/s. Degraded
performance is observed for large timeouts, tlostNbr ≥ 0.5s,
but also for small timeouts, tlostNbr = 0.1s. In networks
loaded with 10 large demands, tlostNbr = 0.1s causes nodes
to falsely identify lost neighbours that must be rediscovered.
The remaining simulations are run with tlostNbr = 0.5s.
Fig. 12 reports packet delay for ATLAS and IEEE 802.11
for the 200 network scenarios of Fig. 10 with node speeds
equal to 30 m/s. IEEE 802.11 is configured with a maximum
packet retry count of seven for RTS, CTS, and ACKs and four
for data packets [11], a mini-slot length of 20µs, and minimum
and maximum contention window sizes of 32 and 1024 slots,
respectively. Each point in the scatter plot reports the average
packet delay (x-coordinate) and variation in packet delay (ycoordinate) for a single node. The largest reported average
delay is 0.047s for ATLAS and 0.058s for IEEE 802.11. The
largest reported variation in delay for ATLAS is 0.0016s2 ,
just 3.6% of the 0.0444s2 reported for IEEE 802.11. This
impressive reduction in delay variance is crucial to the support
of TCP, which we evaluate next.
F. Multi-hop TCP Flows

Fig. 9.

Average range of impact (in hops) for a demand or topology change.

To this point, we have used MAC layer traffic to simulate
a diverse set of network scenarios. We now evaluate the
performance of ATLAS using multi-hop TCP flows. To accommodate the dynamic nature of these flows, each node estimates
its own demand by monitoring queue behaviour. Demand is
estimated as the sum of two parts: wenqueue and wlevel . wenqueue

10

(a) Relative persistence error.
Fig. 10.

(b) Total MAC throughput.

Relative persistence error and total MAC throughput for varying levels of node mobility.

(a) Relative persistence error.
Fig. 11.

Fig. 12.

(b) Total MAC throughput.

Relative persistence error and total MAC throughput for varying neighbour timeouts.

Delays for ATLAS and IEEE 802.11 with node speeds of 30 m/s.

is the percentage of channel required to keep up with the current enqueue packet rate, wenqueue = (packet enqueue rate) ×
(slot length). wlevel is the percentage of channel required to
transmit all packets in the queue within 0.2s (i.e., 25 slots),
wlevel = [(# packets in queue)/0.02s] × (slot length).
To avoid cross-layer interactions between the MAC and
routing protocols, Dijkstra’s shortest path algorithm [28] using
accurate knowledge of the global topology computes the next
hop address for all packet transmissions. FTP agents emulate
transfer of infinite size files to create flows with throughput
limited only by the performance of the network. Transfers start
at time zero and run for 20s. Nodes are statically placed at
random locations in a 300 × 1500m2 simulation area. The
source and destination nodes for each file transfer are selected

at random. Each FTP transfer is transported over TCP Reno
configured for selective acknowledgements, the extensions
of RFC 1323 [1], and 900 byte TCP segments. The return
ACKs are not combined with each other or with other data
packets. Consequently, the transmission of a single 40-byte
TCP ACK consumes an entire transmission slot in ATLAS.
The maximum congestion window size is 32 packets. Network
scenarios are simulated for three traffic loads: networks with
2, 8, and 25 TCP flows. The number of replicates per traffic
load are chosen so that 3000 TCP flows are simulated for each.
Fifteen hundred scenarios are simulated with two TCP flows,
375 with eight TCP flows, and 120 with 25 TCP flows.
We simulate TCP traffic on five MAC protocols: the four
configurations of ATLAS and IEEE 802.11. The configurations of ATLAS use pdefault = 0.05, tlostNbr = 0.5s, and
pmin = 0.01. IEEE 802.11 parameters match those described
in Section VI-E. Each node dynamically sets its bidder weight
to one or the number of outgoing TCP flows it services,
whichever is larger.
The 15 sub-plots in Fig. 13 show the percentage of flows
(y-axis) achieving a minimum throughput (x-axis). The distinguishing characteristics of the three unweighted ATLAS
configurations are seen in the throughput curves for networks
with two flows. These networks are loaded lightly enough for
the auctions at non-receiver nodes to make a difference in the
allocation, improving throughput for 2- and 4-hop flows. These
networks also demonstrate how the longer initial packet delays
of the Lazy Persistences configuration increase round trip time

11

Networks with 2 Flows

Networks with 8 Flows

Networks with 25 Flows

1-hop flows

y-axis shows % of TCP flows achieving minimum required throughput.

All flows
2-hop flows
3-hop flows
4- and 5-hop flows

x-axis shows minimum required throughput for TCP flows in packets/second.
Fig. 13. Percent of TCP flows (y-axis) achieving a minimum throughput (x-axis). Plots in the left, center, and right columns report on flows from simulations
of 2, 8, and 25 flows, respectively. The plots in the top row report on all flows, regardless of hop count. Plots in the second, third, and fourth rows report on
1-hop, 2-hop, and 3-hop flows, respectively. Plots in the fifth row report on 4- and 5-hop flows.

for 4- and 5-hop flows, preventing TCP from achieving its best
throughput.
The Weighted Bidders configuration performs well for
multi-hop flows in networks with eight and 25 flows by
allocating more to multi-hop flows at the expense of singlehop flows. Because one-hop flows tend to achieve higher
throughput, the configuration maintains a tighter variation in
flow throughputs as indicated by the steeper slope of the
Weighted Bidders curve in the top right plot of Fig. 13.
Regardless of configuration, ATLAS surpasses IEEE 802.11

in support of concurrent multi-hop flows. The interaction
between the IEEE 802.11 back-off algorithm and TCP’s congestion control is well known [9]. In testbed experiments, a
single TCP flow with no competition has difficulty reaching a
destination four hops away [16]. Our simulations corroborate
these findings, as approximately 50% of the 4- and 5-hop flows
report a throughput of zero. For networks with 25 demands,
nearly 75% of 2-hop flows are non-functional; 3-, 4-, and 5hop flows are almost completely shut out. The throughput of

12

ATLAS is achieved in spite of channel wasted transmitting 40
byte TCP ACKs in their own slots.

G. Comparison with other Scheduled MAC Protocols
Here, we compare the adaptation of ATLAS with several
other scheduled protocols including DRAND, Z-MAC, FPRP,
and SEEDEX. Although the first three compute conflict-free
schedules, an NP-hard problem [7], a comparison highlights
the agility of ATLAS.
1) Adaptation to Topology Changes: For the simulations of
Section VI-E, the number of neighbour changes (i.e., gained
or lost neighbours) per second experienced by a node is
correlated to the node speed. When the nodes move at 30 m/s,
each node is expected to gain, or lose, a neighbour 2.21 times
per second; within 6.3s, the number of neighbour changes is
expected to exceed the neighbourhood size.
Based on the run times reported in [25, Fig. 10], we
estimate DRAND to compute schedules for the networks in
Section VI-E in approximately 4.9s (adjusting for data rate
and a two-hop neighbourhood size of 27). In this time, the
topology changes caused by nodes moving at 30 m/s are
expected to invalidate the computed schedule. Z-MAC has
the same limitation and, although it compensates by running
CSMA/CA to resolve collisions, it does not benefit from its
TDMA schedule when nodes are mobile. In [25], the run
times reported for FPRP schedule generation are comparable
to DRAND. For SEEDEX, nodes discover their two-hop
neighbours using a fan-in/fan-out procedure described in [26].
However, a practical integration of the procedure into the MAC
protocol is not described or evaluated, preventing a comparison
of its agility with other MAC protocols. In contrast to the slow
schedule computation times of DRAND, Z-MAC, and FPRP,
ATLAS is shown to handle node speeds of up to 120 m/s with
only moderate degradation to MAC throughput.
2) Adaptation to Changes in Traffic Load: The persistences
achieved by DRAND and SEEDEX are dependent on topology
alone; neither adapts to traffic load. Although Z-MAC adapts
to load, it does so by deviating from its underlying schedule,
which does not adapt. FPRP can adapt to load by scheduling
a variable number of slots per node; this is done at the
expense of both longer frame lengths and longer run times for
schedule computation. In contrast, ATLAS adapts to traffic
load, responding quickly enough to establish and maintain
multi-hop TCP flows.
3) Continuous Adaptation: Common to the scheduled
schemes mentioned here is the use of a distinct phase for
schedule computation (or neighbour discovery for SEEDEX).
The schedules must be updated in order for the MAC to adapt.
Any fixed period between schedule updates must be selected a
priori; it cannot be adjusted for variations in network mobility.
If schedules are to be updated when needed, a mechanism is
required to trigger the schedule update. This coordination, by
itself, is a challenge in an ad hoc network. In contrast, ATLAS
does not employ a schedule computation (or a neighbour
discovery) phase and adapts continuously to changes in both
topology and traffic load.

VII. D ISCUSSION
In this section we discuss open issues and suggest potential
applications for REACT and ATLAS.
A. Improved Reliable Transport
TCP’s congestion control algorithm is known to suffer cross-layer interactions with binary exponential back-off
(BEB) employed by IEEE 802.11 [9]. BEB is short term
unfair, allowing a single node to capture the channel at the
expense of its neighbours [2], [10] causing high variation in
packet delay and making it difficult for TCP to estimate roundtrip delay. Many modifications have been proposed to improve
TCP performance over wireless networks [17]; common approaches are detection of packet loss (differentiating it from
congestion) and improved estimation of round trip time. An
alternative is to minimize packet loss and control variation
in packet delay at the MAC layer. ATLAS demonstrates a
remarkable control of variation in delay (Fig. 12) enabling
TCP to reliably support 3-, 4-, and 5-hop flows over heavily
loaded networks (Fig. 13). However, TCP throughput still
degrades considerably as the number of hops grows. Potential
areas for future work include the integration of ATLAS into
a cross-layer solution for reliable transport over wireless
networks and the use of REACT to inform TCP’s congestion
window size.
B. Selection of Configurable Parameters
ATLAS has three configurable parameters: pdefault , tlostNbr ,
and pmin . Based on our simulations, [0.01–0.2] is an acceptable
range for pdefault (Fig. 5) and [0.1s–2s] is an acceptable range
for tlostNbr (Figs. 11a, 11b). In [20], pmin =0.1s is found to
be acceptable for a protocol that enforces pmin at all nodes
and at all times. Because ATLAS employs pmin temporarily,
and only when needed, it is less sensitive to the selection of
pmin . Although results show ATLAS to be robust to parameter
selection, tuning may be required in other scenarios or in a
hardware implementation.
C. Dynamic Selection of Auction Capacity
ATLAS targets 100% channel allocation by setting auction
capacities in REACT to one. Although simulation results
show this to be an adequate choice, it is not clear whether
performance can be improved by under- or over-allocating the
channel. Indeed, optimal auction capacities (however optimal
is defined) are dependent on network topology and quality of
the communication channel. We leave a thorough analysis of
auction capacity selection to future work, pointing out here
that REACT adapts continuously, allowing auction capacities
to be adjusted dynamically, if necessary.
D. Potential Applications for REACT
The weighted TLA allocation opens doors for several potential uses. In the simulations of Section VI-F, a bidder’s
weight is set according to the number of flows it services.
It may be desirable to set weights according to queue levels,

13

demand magnitudes, neighbourhood sizes, node betweenness
[8], distance from a point of interest (i.e., an access point or a
common sink), position in a multicast/broadcast tree, or path
hop count. The key observation is that ATLAS maintains flexibility by allowing nodes to define bidder weights arbitrarily
to suit the needs of the network.
While computation of persistences is the primary motivation
for this work, REACT is not limited to this purpose. Consider
the Physical Receivers configuration with node demands set
to one. The resulting allocation is independent of actions
taken by the upper network layers and, therefore, can inform
decisions made by those layers. It can serve as a measure of
potential network congestion—small allocations are assigned
in dense neighbourhoods containing many potentially active
neighbours. The routing protocol can use the allocation to
discover alternate routes around congestion.
An intriguing application is the implementation of differentiated service at the MAC layer. IEEE 802.11e [12] enhances
the distributed coordination function by implementing four
access categories; an instance of the back-off algorithm is run
per access category, each with its own queue. The probability of transmission of each access category is manipulated
independently through selection of contention window size
and inter-frame space. This permits higher priority traffic to
capture the channel from lower priority traffic.
Similar results can be achieved by four instances of REACT,
each computing the allocation for a single access category.
Prioritization is achieved through dynamic coordination of the
four auction capacities at each node. A potential strategy sets
the capacity for each access category equal to one minus the
allocation to higher priority access categories. As a result,
higher priority auctions are permitted to starve lower priority
auctions of capacity, effectively distributing channel access to
high priority traffic. Alternatively, auction capacities can be
selected to ensure a minimum or maximum percentage of the
channel is offered to an access category.
A network can run multiple instances of REACT. For
example, an instance of the Physical Receivers configuration
with all demands set to one can be run concurrently with
four instances configured to support differentiated service.
Alternatively, multiple instances of REACT can be used to
allocate more than one set of resources concurrently.
E. Assumptions Made by ATLAS
Two key assumptions are made by ATLAS in its computation of the TLA allocation using REACT: (1) The offers and
claims received by a node are accurate. (2) The offers and
claims of a node are eventually received by all neighbouring
nodes. The first assumption is reasonable, provided received
packets are checked for errors by the link layer. The second assumption is almost certainly invalid; asymmetric communication, interference beyond the range of transmission, and signal
fading are common in wireless communication and can prevent
the delivery of offers and claims. Under realistic conditions,
REACT may not converge on the TLA allocation, risking overallocation of the channel. In practice, auctions can adjust their
capacities to mitigate the over-allocation. Every node knows

the persistences of its neighbours (from bidder claims) and
can compute the expectation for collisions on the channel.
Significant deviations above this expectation can trigger the
auction to lower its capacity. An evaluation in a testbed of real
radios is necessary to understand the sensitivity to anomalies
on the wireless channel and the effectiveness of adjusting
auction capacities to accommodate channel conditions.
The evaluation of ATLAS in Section VI assumes both slot
and frame synchronization; ATLAS does not require either.
The computation of the TLA allocation by REACT does not
rely on a frame structure and the expected performance of the
random schedules is not affected by loss of frame synchronization. Even without slot synchronization, REACT can compute
the TLA allocation; however, loss of slot synchronization
may reduce channel capacity by 50% (see Aloha vs. slotted
Aloha in [28]). ATLAS can accommodate the lower channel
capacity by reducing auction capacity. This technique may
allow ATLAS to be run on commodity IEEE 802.11 hardware
[29] that lacks native support for slot synchronization. This is
a subject of our current research.
F. Enhancing Existing MAC Protocols
We have used REACT to compute persistences to be employed within ATLAS, a slotted MAC protocol. Alternatively,
REACT can be run on top of the IEEE 802.11 MAC by
embedding claims and offers in the headers of existing control
and data messages. The TLA allocation can be used to inform
the selection of contention window sizes, eliminating the need
for (and negative side effects of) binary exponential back
off. We are currently working to integrate REACT into IEEE
802.11. Another alternative (and more ambitious) approach is
to implement TLA persistences in a topology-dependent MAC
that computes conflict-free schedules. Only a few topologydependent schemes allow a node to reserve more than one
slot in a frame (i.e., [14], [30]), and those do not define how
many slots a node should reserve. The TLA allocation can
establish a permissible number of slots to be reserved by each
node, given the current topology and traffic load.
VIII. C ONCLUSION
We have proposed REACT, a distributed auction that
converges continuously on the TLA allocation, adapting to
changes in both topology and traffic load. The utility of REACT is demonstrated through integration into ATLAS which
we simulate under a wide variety of network scenarios. The
results presented suggest that REACT can effectively inform
the selection of transmitter persistences, and that ATLAS can
provide robust, reliable, and scalable services. The application
of REACT is not restricted to the computation of transmitter
persistences. It has the potential to inform routing and admission control decisions, to enable differentiation of service at
the MAC layer, and even to allocate other node resources.
In this context, the REACT algorithm provides a potential
solution to the immediate challenge of medium access control,
but also shows promise as a tool for use in network protocol
design in general.

14

ACKNOWLEDGEMENT
The authors appreciate the useful comments provided by the
anonymous reviewers.
R EFERENCES
[1] RFC 1323: TCP Extentions for High Performance, 1992.
[2] V. Bharghavan, A. Demers, S. Shenker, and L. Zhang. MACAW:
A medium access protocol for wireless LANs. In Proceedings of
the ACM Conference on Communications Architectures, Protocols and
Applications (SIGCOMM’94), pages 212–225, 1994.
[3] I. Chlamtac and A. Faragó. Making transmission schedules immune
to topology changes in multi-hop packet radio networks. IEEE/ACM
Transactions on Networking, 2(1):23–29, 1994.
[4] I. Chlamtac, A. Faragó, A. D. Myers, V. R. Syrotiuk, and G. Záruba.
ADAPT: A dynamically self-adjusting media access control protocol for
ad hoc networks. In Proceedings of the IEEE Global Telecommunications Conference (GLOBECOM’99), pages 11–15, 1999.
[5] I. Chlamtac and S. S. Pinter. Distributed nodes organization algorithm
for channel access in a multihop dynamic radio network. IEEE
Transactions on Computers, C-36(6):728–737, June 1987.
[6] C. J. Colbourn and V. R. Syrotiuk. Scheduled persistence for medium
access control in sensor networks. In Proceedings from the First
IEEE International Conference on Mobile Ad hoc and Sensor Systems
(MASS’04), pages 264–273, 2004.
[7] S. Even, O. Goldreich, S. Moran, and P. Tong. On the NP-completeness
of certain network testing problems. Networks, 14(1):1–24, 1984.
[8] L. C. Freeman. A set of measures of centrality based on betweenness.
Sociometry, 40(1):35–41, 1977.
[9] M. Gerla, R. Bagrodia, L. Zhang, K. Tang, and L. Wang. TCP over wireless multi-hop protocols: Simulation and experiments. In Proceedings of
the 1999 IEEE International Conference on Communication (ICC’99),
pages 1089–1094, 1999.
[10] J. Hastad, T. Leighton, and B. Rogoff. Analysis of backoff protocols
for multiple access channels. In Proceedings of the 19th annual ACM
Symposium on Theory of Computing (STOC’87), pages 740–744, 1987.
[11] IEEE. IEEE 802.11, Wireless LAN medium access control (MAC) and
physical layer (PHY) specifications, 1997.
[12] IEEE. IEEE 802.11e, Enhancements: QoS, including packet bursting,
2007.
[13] J. Boleng, N. Bauer, T. Camp, and W. Navidi. Random Waypoint Steady
State Mobility Generator (mobgen-ss). http://toilers.mines.edu/.
[14] G. Jakllari, M. Neufeld, and R. Ramanathan. A framework for frameless
TDMA using slot chains. In Proceedings of the 9th IEEE International
Conference on Mobile Ad hoc and Sensor Systems (MASS’12), 2012.
[15] J. Ju and V. O. K. Li. An optimal topology-transparent scheduling
method in multihop packet radio networks. IEEE/ACM Transactions on
Networking, 6(3):298–305, 1998.
[16] D. Koutsonikolas, J. Dyaberi, P. Garimella, S. Fahmy, and Y. C. Hu.
On TCP throughput and window size in a multihop wireless network
testbed. In Proceedings of the 2nd ACM International Workshop on
Wireless network testbeds, experimental evaluation and characterization
(WiNTECH’07), 2007.
[17] K. Leung and V. O. K. Li. Transmission control protocol (TCP) in
wireless networks: Issues, approaches, and challenges. IEEE Communications Surveys & Tutorials, 8:64–79, 2006.
[18] J. Lutz, C. J. Colbourn, and V. R. Syrotiuk. Apples and oranges:
Comparing schedule- and contention-based medium access control. In
Proceedings of the 13th ACM International Conference on Modeling,
Analysis and Simulation of Wireless and Mobile Systems (MSWiM’10),
pages 319–326, 2010.
[19] J. Lutz, C. J. Colbourn, and V. R. Syrotiuk. Variable weight sequences
for adaptive scheduled access in MANETs. In Proceedings of Sequences
and their Applications (SETA’12), pages 53–64, 2012.
[20] J. Lutz, C. J. Colbourn, and V. R. Syrotiuk. Topological persistence
for medium access control. IEEE Transactions on Mobile Computing,
12(8):1598–1612, 2013.
[21] The Network Simulator ns-2. http://www.isi.edu/nsnam/ns/.
[22] M. Pióro and D. Medhi. Routing, Flow, and Capacity Design in
Communication and Computer Networks. Elsevier Inc., 2004.
[23] R. Ramanathan. A unified framework and algorithm for (T/F/C)DMA
channel assignment in wireless networks. In Proceedings of the 16th
Annual Joint Conference of the IEEE Computer and Communications
Societies (INFOCOM’97), pages 900–907, 1997.

[24] I. Rhee, A. Warrier, M. Aia, J. Min, and M. L. Sichitiu. Z-MAC:
A hybrid MAC for wireless sensor networks. IEEE Transactions on
Networking, 16(3):511–524, 2008.
[25] I. Rhee, A. Warrier, J. Min, and L. Xu. DRAND: Distributed randomized
TDMA scheduling for wireless ad-hoc networks. IEEE Transactions on
Mobile Computing, 8(10):1384–1396, 2009.
[26] R. Rozovsky and P. R. Kumar. SEEDEX: A MAC protocol for ad hoc
networks. In Proceedings of the 2nd ACM International Symposium
on Mobile Ad Hoc Networking and Computing (MOBIHOC’01), pages
67–75, 2001.
[27] V. R. Syrotiuk, C. J. Colbourn, and S. Yellamraju. Rateless forward error
correction for topology-transparent scheduling. IEEE/ACM Transactions
on Networking, 16(2):464–472, 2008.
[28] A. S. Tanenbaum. Computer Networks. McGraw Hill, fourth edition,
2003.
[29] I. Tinnirello, G. Bianchi, P. Gallo, D. Garlisi, F. Giuliano, and
F. Gringoli. Wireless MAC processors: Programming MAC protocols
on commodity hardware. In Proceedings of the 31st Annual Joint
Conference of the IEEE Computer and Communications Societies (INFOCOM’12), pages 1269–1277, 2012.
[30] C. Zhu and M. S. Corson. A five-phase reservation protocol (FPRP) for
mobile ad hoc networks. Wireless Networks, 7(4):371–384, 2001.

Jonathan Lutz earned his B.S. in Electrical Engineering from Arizona State University, Tempe, Arizona, in 2000 and his M.S. in Computer Engineering
from the University of Waterloo, Waterloo, Canada,
in 2003. He is currently working on his Ph.D. in
Computer Science at Arizona State University. His
research interests include medium access control in
mobile ad hoc networks.

Charles J. Colbourn earned his Ph.D. in 1980 from
the University of Toronto, and is a Professor of
Computer Science and Engineering at Arizona State
University. He is the author of The Combinatorics
of Network Reliability (Oxford), Triple Systems (Oxford), and 320 refereed journal papers focussing on
combinatorial designs and graphs with applications
in networking, computing, and communications. In
2004, he was awarded the Euler Medal for Lifetime
Research Achievement by the Institute for Combinatorics and its Applications.

Violet R. Syrotiuk earned her Ph.D. in Computer
Science from the University of Waterloo (Canada).
She is an Associate Professor of Computer Science and Engineering at Arizona State University.
Her research has been supported by grants from
NSF, ONR, and DSTO, and contracts with LANL,
Raytheon, General Dynamics, and ATC. She serves
on the editorial boards of Computer Networks and
Computer Communications, as well as on the technical program and organizing committees of several
major conferences sponsored by ACM and IEEE.

J Comb Optim (2007) 14: 229–248
DOI 10.1007/s10878-007-9058-4

Transport schemes for topology-transparent scheduling
Violet R. Syrotiuk · Zhiqiang Zhang ·
Charles J. Colbourn

Published online: 31 March 2007
© Springer Science+Business Media, LLC 2007

Abstract Transport protocols provide reliable, end-to-end communication between
a source and a destination in a network. The Transmission Control Protocol (TCP)
uses backward error correction, where the destination explicitly returns feedback to
the source. Forward error correction (FEC) can also be used for transport; here the
source includes enough redundancy in the encoding symbols to allow the destination
to decode the message. In this paper, we compare the performance of two transport schemes, TCP and LT, a scheme based on rateless FEC codes, in a wireless ad
hoc network when topology-transparent scheduling is used for channel access. These
schedules are derived from cover-free families, a type of combinatorial design. They
provide a mechanism to guarantee collision-free communication between any two
nodes provided that each of the N nodes of the network has at most a specified number D of active (transmitting) neighbours. We find that LT outperforms TCP in more
strenuous network conditions.
Keywords Transport protocols · Forward error correction · Topology-transparent
scheduling
1 Introduction
Unlike a cellular network, a mobile ad hoc network (MANET) is a collection of mobile wireless nodes that self-organize without the aid of any centralized control or
To Frank Hwang on the occasion of his sixty-fifth birthday.
V.R. Syrotiuk () · Z. Zhang · C.J. Colbourn
Department of Computer Science and Engineering, Arizona State University, Tempe,
AZ 85287-8809, USA
e-mail: syrotiuk@asu.edu
Z. Zhang
e-mail: zhiqiang.zhang@asu.edu
C.J. Colbourn
e-mail: colbourn@asu.edu

230

J Comb Optim (2007) 14: 229–248

fixed infrastructure such as basestations. Since the radio transmission range of each
node is limited, it may be necessary to forward a packet over multiple hops in order
for it to reach its destination. Applications that may benefit from such technology
include rescue and/or emergency operations after a disaster that destroys existing
infrastructure, special operations during law-enforcement activities, and tactical missions in a hostile and/or unknown territory.
The network architecture has long been organized as a series of layers each built
on the one below it. The aim is to reduce protocol complexity by defining the responsibilities of each layer. This philosophy extends to the design of wireless networks. In
this work we focus on two layers in the network architecture: the medium access control (MAC) layer and the transport layer. The role of the MAC protocol is to control
access to the shared broadcast channel, providing reliable single-hop communication.
The challenge for MAC protocols is to maximize spatial reuse by exploiting the opportunity for concurrent transmissions by nodes that are sufficiently far apart. The
role of the transport protocol is to provide reliable end-to-end communication between a source and a destination. For transport protocols the challenge is to provide
reliability as network topology and network conditions change.
Most MAC protocols use either contention or scheduling. Contention based approaches, such as IEEE 802.11 (IEEE Standards Committee 1996), are prevalent in
MANETs due to their simplicity and lack of synchronization requirements. While
such protocols achieve high throughput with a reasonable expected delay, in the
worst-case the delay is very poor. As the interest in delay sensitive applications involving multimedia grows, guarantees on delay become crucial.
For scheduled access, topology-dependent and topology-transparent strategies
have been developed for MANETs. In a topology-dependent strategy, the protocol alternates between a contention phase and an allocation phase. In the contention phase,
nodes collect neighbour information from which schedules are computed for use in
the allocation phase (see Chlamtac and Pinter 1987; Zhu and Corson 1998 as examples).
In a topology-transparent strategy, neighbour information is not used. These
schedules are derived from cover-free families, a type of combinatorial design. The
protocols construct schedules that depend on two design parameters: N , the number
of nodes in the network, and D, the maximum active node degree. If the bound on
D is satisfied, the schedule guarantees at least one collision-free transmission to each
neighbour (Chlamtac and Faragó 1994; Ju and Li 1998). The identity of the neighbours is not relevant, merely their number – hence the schedules are independent of
the detailed network topology.
Most transport protocols are based on either backward error correction (BEC) or
forward error correction (FEC). With BEC, the destination explicitly returns feedback to the source, either as a positive or a negative acknowledgment. Standard techniques include stop-and-wait where the window size is one, and go back N and selective repeat for larger windows. These techniques may require the source to wait an
entire frame for receipt of the feedback, even if both transmitter and receiver have at
most D neighbours. In the pathological case that the transmitter is densely surrounded
by neighbours while the receiver is not, acknowledgment can cause collisions at the
transmitter and result in total loss; specifically, when the receiver is within the bound
D but the transmitter is not, loss of acknowledgment may result in stalling for many

J Comb Optim (2007) 14: 229–248

231

frames. Further, these techniques require window, buffer, and timer management, not
to mention that packets suffering collision need retransmission.
With FEC the source includes enough redundancy in the encoding symbols to
allow the destination to decode the message. Most FEC schemes require knowledge
of the loss rate on the channel. Traditional erasure codes are block codes with a
fixed rate. Specifically, some number σ of input symbols are used to generate f − σ
redundant symbols for a total of f encoding symbols. The rate of the code is σ/f .
Reed-Solomon and Tornado codes are erasure codes that have been used for reliable communications. Reed-Solomon codes are efficient for relatively small values
of σ and f since σ (f − σ )q/2 symbol operations are needed to produce the f encoding symbols, where q is the size of the finite field used (Bloemer et al. 1995;
Rizzo 1997); a similar number is needed for decoding. Though faster encoding and
decoding algorithms are known, in practice, an effective implementation of these algorithms does not exist.
Tornado codes use a cascading sequence of bipartite graphs between several layers
of symbols. The input symbols are at the first layer and redundant symbols are at each
subsequent layer. In practice, this requires either prior construction of the same graph
structure at both the encoder and decoder, or that the graph structure is communicated
to the decoder. In either case, the pre-processing overhead is quite extensive. Furthermore, a different graph structure is required for each packet length further increasing
the pre-processing involved. This is a large drawback of Tornado codes.
Determining a suitable rate for the code in practice is not easy. If the rate is chosen
conservatively to account both for collisions and for communication errors, as well as
allowing for the maximum number of permitted active neighbours, many additional
packets are sent containing redundant information when the design assumptions are
pessimistic. Too low a rate decreases throughput, while too high a rate fails to deliver
enough information to decode. Worse yet, adapting at the transmitter to a more suitable rate requires an agreement between transmitter and receiver to change the FEC
encoding in use.
In this paper, we compare the performance of two transport schemes in a MANET
when topology-transparent scheduling is used for channel access. The first scheme
uses the Transmission Control Protocol (TCP), the prevalent transport protocol used
in networks today, whether wired or wireless. It is based on BEC and, the version we
use—Tahoe, includes a number of improvements to aid the handling of congestion.
The second scheme called LT, is based on Luby Transform (LT) codes, a rateless
FEC code. Unlike rated codes, LT codes accommodate variable packet loss making
them suitable for transport in wireless networks. For a sequence of scenarios with
increasing interference we draw the following conclusions: LT remains stable under
high packet loss rates whereas TCP becomes unstable; TCP achieves higher message
throughput than LT at low loss rates and when acknowledgments do not suffer collisions; both protocols are more sensitive to collisions among data packets between
flows than to collisions among a data packet and an acknowledgment.
The rest of this paper is organized as follows. We first describe the role of various combinatorial structures in topology-transparent scheduling in Sect. 2. We then
overview the LT and the TCP Tahoe transport schemes in Sect. 3. In Sect. 4 we discuss the simulation set-up and present the simulation results. Section 5 provides a
summary and conclusions.

232

J Comb Optim (2007) 14: 229–248

2 Combinatorial designs and topology-transparent scheduling
Combinatorial designs arise in many applications in networking (Colbourn et al.
1999). In (Syrotiuk et al. 2003) the existing topology-transparent MAC protocols are
generalized by observing that the application requires a cover-free family and that the
orthogonal arrays used work for that reason. Here, we overview some combinatorial
structures that are equivalent to cover-free families.
2.1 The network model
We model an ad hoc network by a graph G = (V , E) where the vertex set V represents the nodes, and the edge set E represents the communication links; N = |V |.
Each node is equipped with an omnidirectional antenna with transmission modelled
by a circle of radius r. There is an edge (vi , vj ) ∈ E between nodes vi and vj if
the nodes are within the transmission range r of one another. The degree d(vi ) of a
vertex vi corresponds to its neighbourhood size. The maximum node degree of the
network G is D = maxvi ∈V d(vi ). This is an upper bound on the number of active
(transmitting) nodes in a neighbourhood.
The transceiver at each node is half-duplex. As a result, it is not possible for a node
to both transmit and receive concurrently. This introduces well known problems such
as the hidden terminal problem. This problem occurs when the destination vj of a
transmitting node vi suffers a collision because of an interfering transmission from
another node vk not in the transmission range of vi .
Two or more overlapping transmissions to a receiver result in a collision. In other
words, among the overlapping packets none is received correctly, regardless of signal
strength; i.e., no “capture effect” is modelled.
Time is divided into discrete units called slots and slots are grouped into frames.
A schedule Si for a node vi ∈ V consists of a binary vector s0 s1 . . . sn−1 with one
element for each slot. Typically, each node in the network is assigned a schedule
that it uses in a cyclically repeated way for transmission. If sj = 1 then node i may
transmit in slot j , otherwise it is silent (and could receive).
2.2 Cover-free families
In designing a topology-transparent transmission schedule with parameters N and D
we are interested in the following combinatorial property. For each node, we must
guarantee that if a node vi has at most D neighbours its schedule Si guarantees a
collision-free transmission to each neighbour.
Let us treat each schedule Si as a subset Ti on {0, 1, . . . , n − 1}, i.e., Ti is the
characteristic set of Si . Now the combinatorial problem asks for each node vi to be
assigned a subset Ti with the property that the union of D or fewer other subsets
cannot contain Ti . Expressed mathematically, if D is a set of at most D of the sets
{Tj }, and Ti ∈ D, then
 
T ⊇ Ti .
T ∈D

This is precisely a D cover-free family.

J Comb Optim (2007) 14: 229–248

233

As we showed in (Syrotiuk et al. 2003), existing constructions for topologytransparent schedules correspond to orthogonal arrays, and hence give cover-free
families. Since this is essential to the provision of topology-transparent schemes of
sufficient variety and number for practical applications, we outline this connection in
more detail.
2.2.1 Orthogonal arrays
The theory of orthogonal arrays relates combinatorics, finite fields, geometry and
error-correcting codes; they have been studied extensively (Hedayat et al. 1999).
An orthogonal array of size N , with degree k, of order s, and strength t, denoted
OA(N, k, s, t), is a k × N array with entries from a set of s ≥ 2 symbols, having
the property that in every t × N submatrix, every t × 1 column vector appears the
same number λ = N
s t times. The parameter λ is the index of the orthogonal array. An
OA(N, k, s, t) is also denoted by OAλ (t, k, s); in this notation, which we employ, if
t is omitted it is taken to be 2, and if λ is omitted it is taken to be 1.
A transversal design of order n, blocksize k, and index λ, denoted TDλ (t, k, n), is
a triple (V , G, B), where
•
•
•
•
•

V is a set of kn elements;
G is a partition of V into k classes (the groups), each of size n;
B is a collection of k-subsets of V (the blocks);
every block intersects every group in exactly one element;
every unordered t-tuple of elements from V either contains two elements of the
same group or is contained in exactly λ blocks.

When t = 2 it is often omitted in the notation. When λ = 1, the notation TD(k, n) is
used.
A transversal design TDλ (t, k, v) is equivalent to an OAλ (t, k, v). To see this,
given such an orthogonal array, form a one-to-one mapping τ from the (row, symbol)
pairs of the array to a set V of size kv. Then for every column γ of the array form
a block containing the images under τ of the pairs (ρ, σ ) when entry (ρ, γ ) of the
array equals σ . The resulting set of blocks forms a transversal design in which each
group consists of the images of all pairs arising from the same row of the array.
For example, Table 1 shows an OA(3, 3). Using the mapping τ defined by
τ : (ρ, σ ) → 3ρ + σ we produce nine blocks: {0, 3, 6}, {0, 4, 8}, {0, 5, 7}, {1, 4, 7},
{1, 5, 6}, {1, 3, 8}, {2, 5, 8}, {2, 3, 7}, {2, 4, 6}. These form the blocks of a TD(3, 3)
with groups {0, 1, 2}, {3, 4, 5}, and {6, 7, 8}.
There are three representations of these systems of blocks. We have just seen the
set system representation. By forming the λv t × k incidence matrix of these sets, with
rows indexed by sets and columns by elements, we obtain a matrix representation.
Each column is the characteristic vector of one of the sets; conversely each set is the
support of one of the columns. Table 2 shows the incidence matrix of the OA(3, 3) in
Table 1 OA1 (2, 3, 3) =
OA(3,3)

0

0

0

1

1

1

2

2

2

0

1

2

1

2

0

2

0

1

0

2

1

1

0

2

2

1

0

234
Table 2 Incidence matrix of
OA(3, 3)

J Comb Optim (2007) 14: 229–248
1

1

1

0

0

0

0

0

0

0

0

0

1

1

1

0

0

0

0

0

0

0

0

0

1

1

1

1

0

0

0

0

1

0

1

0

0

1

0

1

0

0

0

0

1

0

0

1

0

1

0

1

0

0

1

0

0

0

1

0

0

0

1

0

0

1

1

0

0

0

1

0

0

1

0

0

0

1

1

0

0

Table 1. Finally, considering the binary code whose codewords are the columns (of
length λv t ) in this matrix, we obtain a code representation. We use all three representations interchangeably.
Our interest is in orthogonal arrays of index one. The property of interest is the
following: Consider the union of any m blocks arising from an OA1 (t, k, v). Then
any other block contains at least k − (t − 1)m elements not contained in this union.
In particular, when m ≤ k−1
t−1 , no block is covered by the union of m others.
Given three integers t, k, v such that 2 ≤ t < k < v, a Steiner system S(t, k, v) is
a v-set V together with a family B of k-subsets of V (blocks) with the property that
every t-subset of V is contained in exactly one block. Once again, the union of any
k−1
t−1 blocks cannot contain another. Set systems with this property have been explored
in their own right.
Let x = [x0 x1 . . . xn−1 ]T and y = [y0 y1 . . . yn−1 ]T be two binary n-dimensional
vectors. The bit-by-bit Boolean sum is the superposition sum, denoted by x ∨ y =
[x0 ∨ y0 x1 ∨ y1 . . . xn−1 ∨ yn−1 ]T . A vector x is contained in y, if x ∨ y = y.
A v × b binary matrix M is a superimposed code of order d if the superposition
sum of any d columns of M does not contain any other column of M. The columns
of Table 2 form the codewords of a superimposed code of order 2.
A superimposed code of order d is equivalent to a d cover-free family (D’yachkov
et al. 2002) and also to a d disjunct matrix (Du and Hwang 2000). As a result, there
is also an equivalence between the notation used for superimposed codes (sets of
vectors), cover-free families (characteristic sets), and disjunct matrices (matrices).
Both initial constructions for topology-transparent schedules (Chlamtac and
Faragó 1994; Ju and Li 1998) use orthogonal arrays OA1 (t, p, p) constructed over
the finite field, although neither use this vernacular. In (Syrotiuk et al. 2003) the existing topology-transparent MAC protocols are generalized by observing that the application requires a cover-free family. This relaxation of the combinatorial constraint
from specific orthogonal arrays to cover-free families opens a number of avenues
(Colbourn and Syrotiuk 2005). In particular, if every node is to have the same number of transmission opportunities, the cover-free family must be uniform, i.e. every
set has the same cardinality. Then the largest number of nodes for a given frame
length is supported by a Steiner system (Colbourn et al. 2003). This is a celebrated
result of Erdös, Frankl, and Füredi (Erdös et al. 1985) (see also Ruszinkó 1994;
Stinson et al. 2000 and Theorem 7.3.9 in Du and Hwang 2000).
Cover-free families provide a means to construct schedules in a much more general
manner than was previously known. A study on the robustness of the schedules to

J Comb Optim (2007) 14: 229–248

235

the degree constraint (Colbourn et al. 2004), extensions to slot synchronized and
asynchronous networks (Chu et al. 2004, 2006a, 2006b), and extensions to schedules
with a third state (sleep) for energy efficiency (Dukes et al. 2006, 2007) also exist.

3 Transport protocols
The goal of the transport layer is to provide efficient, reliable, and cost-effective endto-end communication between a source and a destination. We overview a transport
scheme based on forward and on backward error correction. In Sect. 4 we study the
performance of topology-transparent scheduling using each transport scheme.
3.1 LT coding for transport
Recently, Luby Transform (LT) codes (Luby 2002) have been developed in order to
solve some problems associated with Reed-Solomon and Tornado codes, namely the
inefficiency of encoding and decoding, and the inability to accommodate variable
packet loss. In contrast, the LT process is capable of generating a potentially infinite
number of equally useful symbols from a given input, giving the codes immunity
to tolerate arbitrary losses in the channel. This makes LT codes the basis for a very
effective transport scheme in wireless channels.
3.1.1 The LT process
The parameters that characterize the LT process are:
•
•
•
•

The size  of each block or encoding symbol.
The degree α of the encoding symbol.
The number of blocks b into which a message of M bytes is divided.
The number of encoding symbols needed to completely recover the data, denoted
by (b + δ).

A message of size M bytes is fragmented into b blocks each of length  bytes;
these blocks are numbered serially. A degree α is chosen at random from a soliton
distribution. Now α distinct blocks are chosen from the original data uniformly at
random. These blocks are called neighbours of each other.1 The value of the encoding
symbol is the exclusive-or (modulo 2 sum) of the α neighbours.
Unlike classical backward error correction schemes, in the LT transport scheme,
the need for hop-by-hop acknowledgments is eliminated. Successive encoding symbols are transmitted by the source until it receives an acknowledgment from the ultimate destination of the flow.
A destination that wishes to reconstruct the data transmitted by the source need
only collect enough of these encoding symbols. In practice, 7% more than the original
data is needed to reconstruct an exact copy of data by the receiver (Digital Fountain
2004). Figure 1 shows that for zero loss, 7% overhead is achieved when b = 10 000.
It does not matter which encoding symbols are received, or the order in which they

236

J Comb Optim (2007) 14: 229–248

Fig. 1 Decoding overhead versus the number of blocks b in a message

are received. All encoding symbols are of equal value in reconstructing the original
data.
Given an ensemble of encoding symbols and some representation of their associated degrees and sets of neighbours, the decoder recovers the input symbols as follows. All input symbols are initially uncovered. In the first step, all encoding symbols
with one neighbour are released to cover their unique neighbour. The set of covered
input symbols that have not yet been processed is called the ripple, and thus at this
point all covered input symbols are in the ripple.
At each subsequent step one input symbol in the ripple is processed: it is removed
as a neighbour from all encoding symbols that have it as a neighbour and all such
encoding symbols that subsequently have exactly one remaining neighbour are released to cover their remaining neighbour. Some of these neighbours may have been
previously uncovered, causing the ripple to grow, while others of these neighbours
may have already been in the ripple, causing no growth in the ripple. The process
ends when the ripple is empty.
In the example in Fig. 2, the original data consists of eight input symbols (blocks)
and there are eight received encoding symbols. Only the encoding symbol B has
α = 1 and so it covers input symbol 2, i.e., the value of B is the value of input symbol
(block) 2. Then the value of the recovered input is added into the value (bitwise modulo 2) of the other encoding symbols to which it is connected; in this example, to the
encoding symbols D and E. If 2 ⊕ B indicates that input symbol 2 is recovered as the
current value of encoding symbol B, and if the notation D ⊕ 2 denotes that the current value of symbol 2 is added (bitwise modulo 2) into the current value of encoding
symbol D, then the entire recovery process for this example can be expressed by the
1 The terminology of neighbour and degree used in the LT process is different from its use in networking.

J Comb Optim (2007) 14: 229–248

237

Fig. 2 A sequence of encoding
symbols for the given input data

following sequence of operations: 2 ⊕ B, D ⊕ 2, E ⊕ 2, 8 ⊕ D, F ⊕ 8, G ⊕ 8, H ⊕
8, 4 ⊕ F, H ⊕ 4, 3 ⊕ H, C ⊕ 3, 7 ⊕ C, G ⊕ 7, 5 ⊕ G, A ⊕ 5, 1 ⊕ A, E ⊕ 1, 6 ⊕ E.
3.1.2 LT degree distribution
The probability distribution of the degree of the encoding symbols is a critical part of
the design to ensure complete recovery of the original data from the fewest number of
encoding symbols. The encoding symbols must have a highly variable degree. This
variability ensures that the recovery process succeeds. An ideal distribution is such
that there is exactly one encoding symbol with degree one. The soliton distribution
has this property (Luby 2002).
Each encoding symbol has a degree chosen independently from the degree distribution. On average each symbol has the same expected value in recovering the original
data. Furthermore, the chance of two symbols choosing the same degree α and the
same set of α blocks from the original data is infinitesimally small. This ensures that
each encoding symbol is different from the others in content with high probability.
Finally, if the original data consists of b input symbols then each symbol can be
generated, independently of all other encoding symbols, on average by O(log(b/λ))
symbol √
operations, and the b original input symbols can be recovered from any
b + O( b · log2 (b/λ)) encoding symbols with probability 1 + λ by on average
O(b · log(b/λ)) symbol operations (Luby 2002). The maximum number
of encod√
ing symbols needed for complete recovery of data is equal to b + O( b · log2 (b/λ))
(Luby 2002).
The generation and recovery speeds of the LT process are fast because the efficiency of the process is directly proportional to the average degree of the distribution
times the length of the original data. The average degree of the distribution is a small
constant independent of the length of original data.
3.2 The transmission control protocol (TCP)
The Transmission Control Protocol (TCP) is a connection-oriented end-to-end reliable transport protocol defined in Internet RFC 793 (Postel 1981). TCP assumes it
can obtain a simple, potentially unreliable, datagram service from the lower level
protocols (Postel 1981).
Reliability is ensured by a sliding-window acknowledgment and retransmission
mechanism. All data sent by TCP must be acknowledged by the receiver at the other
end of the connection. TCP maintains a variable-sized window of data that is allowed
to exist unacknowledged in the network at any given time. If this limit is reached, no
data is sent until an acknowledgment is received. If no data has been acknowledged

238

J Comb Optim (2007) 14: 229–248

in a certain amount of time, as detected by the expiration of the retransmission time
out (RTO) timer, TCP assumes that the data is lost, and retransmits all of the data in
the window.
3.2.1 TCP Tahoe
TCP Tahoe grew out of a number of congestion-related improvements suggested by
Jacobson (1988) including slow-start, better round trip time (RTT) variance estimation, exponential retransmit timer back-off, and dynamic congestion window sizing.
Early implementations of TCP stressed a network by sending too much data from
the start. The slow-start mode for TCP exponentially increases the size of a congestion window. This allows TCP to determine the bandwidth and delay statistics of a
connection while allowing the network to adjust to the increase in load.
The modified RTO estimation algorithm takes RTT variance into account instead
of using a constant value. The new RTO estimator is capable of adapting to much
greater loads.
Quite often, TCP implementations would worsen network congestion due to multiple, successive retransmissions. The RTO estimator is only updated upon receipt
of an acknowledgment; if data is continually lost due to high network loading, the
data is retransmitted at constant intervals. A strategy that handles multiple retransmits with an exponential back-off of the RTO timer for each successive retransmit
was developed.
TCP Tahoe offers a means of combating congestion by dynamically altering the
size of the sliding window. The algorithm follows three simple rules: (1) If the RTO
expires, set the congestion window size to half of its current size. (2) Increase the
congestion window size by 1 for each acknowledgment. (3) Send the minimum of
the window advertised by the receiver and the congestion window.

4 Simulation study
For our study, we use the ns-2 (VINT 1995) network simulator. We consider six
scenarios each involving 4 nodes positioned in an area of 1000 × 800 m. The scenarios are designed to explore increasingly complex interactions of flows with each
other.
Nodes are connected to their peers via a shared 2 Mbps interface. Two flows F1
and F2 are established, one from a source T1 to its destination R1 , and the other from
T2 to R2 . Transmission schedules come from the OA(3,3) in Table 1. A frame is
kv = 9 slots with 3 slots assigned for transmission; it can support a maximum active
node degree of D = 2.
In the LT transport scheme, each encoding symbol is transmitted exactly once.
When TCP is used, packet retransmissions are made. Since each node has 3 transmission slots per frame, we consider one and two retransmissions of each packet by
the MAC protocol. This is because if the bound on D is satisfied, the schedule guarantees at least one collision-free transmission to each neighbour by the end of the
frame (Chlamtac and Faragó 1994; Ju and Li 1998).

J Comb Optim (2007) 14: 229–248

239

Table 3 Parameters of the simulation
Parameter

Value

Parameter

Value

Simulator

ns-2, v. 2.26

Propagation model

Two-ray ground reflection

Transmission range

250 m

Carrier sensing range

550 m

Simulation area

1000 m × 800 m

Channel bandwidth

2 Mbps

Number of nodes

9

Routing protocol

DSR (Johnson and Maltz 1996)

v

3

Parameters of ns-2

Parameters of the orthogonal array
k

3

Parameters of LT codes
Slot length (bytes)

1100

Slot length (time)

0.004400 s

c

0.15

δ

0.05

 (and b)

1000

MAC retransmissions

0

Version

Tahoe

Window size

20

Slot length (bytes)

1132

Slot length (time)

0.004528 s

Packet size

1000 bytes

Acknowledgment

40 bytes

ACK model

one ACK per packet

MAC retransmissions

1, 2

Parameters of TCP

The message M is 1 Mbyte; since  = 1000, each message is made up of a thousand blocks. In the LT transport scheme, once the receiver has decoded the message,
it sends an acknowledgment to the transmitter, i.e., an acknowledgment is sent on
a per message basis. For TCP, acknowledgments are made on a per packet basis.
(A packet is large enough to hold one block of the message plus the header for the
transport scheme.) Once a source receives an acknowledgment for the message, it
advances to the next message in the queue. The simulation runs for a fixed number
(5000) seconds of simulation time.
These and additional simulation parameters are provided in Table 3.
This simulation study explores the trade-offs between the two transport schemes.
We measure:
• message throughput, the total number of messages delivered to the destination in
the simulation time,
• message delay, the difference in the time a message is delivered to the destination
and the time it is first sent by the source, averaged over all messages received, and
the
• overhead per message, the total number of bytes transmitted in order to deliver a
message from the source to the destination; this includes data packets, retransmissions (if any), and acknowledgments.
Figure 3 shows the first two scenarios considered. The positioning of the nodes
is identical in both scenarios; the nodes are far enough apart that the flows do not

240

J Comb Optim (2007) 14: 229–248

Fig. 3 a Scenario 0, no
interference; b Scenario 1,
schedules of T1 and R1 intersect
in slot 3

(a)

(b)
interfere and are able to run concurrently.2 In scenario 0, the schedules assigned to
a transmitter and its receiver do not intersect. This represents the best case for each
transport protocol since data from the transmitter never collides with any acknowledgments from the receiver. TCP returns more acknowledgments than LT so TCP
should perform the best in this scenario. The difference between the two scenarios is
only in the schedule assigned to T1 ; it changes from {2, 5, 8} in scenario 0 to {2, 3, 7}
in scenario 1. Now, the schedules of T1 and R1 intersect in slot 3, introducing the
chance that a data packet transmitted by T1 may collide with an acknowledgment
from R1 .
Figure 4(a) shows the throughput of the flow F1 in scenario 0. Indeed, the throughput with TCP is better than LT until the loss rate is about 17%. Then with only one
retransmission throughput degrades sharply, approaching zero when the loss rate is
45%. When TCP uses two retransmissions the throughput remains better than LT
until the loss rate is 30%, with a sharp decline for increasing losses. The delay in
Fig. 4(b) shows the instability in TCP more clearly. TCP using one retransmission is
unstable by 30% loss while with two retransmissions is becoming unstable by 45%
loss rate. LT exhibits throughput that is linear with the loss rate and is stable for the
loss rates considered.
As Fig. 5(a) shows, when the data and acknowledgments can collide the throughput of TCP immediately suffers. In fact, it is never better than LT, dropping to zero
with increasing loss. As in scenario 0 the drop is faster with one retransmission than
with two since this induces more timeouts by TCP. Figure 5(b) shows that the instability occurs at a lower loss rate than in scenario 0. TCP using one retransmission
is unstable by 20% loss rate while with two retransmissions it becomes unstable by
40% loss rate.
2 In the simulation, nodes within carrier sensing range—and not the transmission range—interfere with

one another; this is commonly modelled as about twice the transmission range.

J Comb Optim (2007) 14: 229–248

241

Fig. 4 a Throughput and
b delay vs. loss rate of flow F1
for scenario 0

(a)

(b)

The throughput of LT in scenario 1 is nearly identical to that in scenario 0. This
is because acknowledgments are sent on a per message rather than on a per packet
basis. That is, for each message, LT codes sends 1 acknowledgment while TCP sends
1000! Thus the throughput of LT is not affected by the occasional collision of acknowledgment with data. As before, LT is stable for the loss rates considered.
In Fig. 6 we compare the overhead per message in scenarios 0 and 1 for flow F1 .
Since LT performs essentially the same in both scenarios, the overhead is also the
same in each. In scenario 0, TCP has lower overhead than LT until a loss rate of
just over 35%. This is due to TCP timing out and transmitting far fewer packets. In
scenario 1, the overhead of TCP is higher than LT as a result of the large number of
collisions between data and acknowledgments.
Figure 7 shows the next two scenarios considered. While the nodes are positioned
identically the roles of T1 and R1 in scenario 2 are interchanged in scenario 3. In scenario 2, the receiver R1 and the transmitter T2 interfere since their schedules {0, 3, 6}
and {1, 3, 8} intersect in slot 3; hence T1 may experience collisions in slot 3 since T2
may interfere with an acknowledgment by R1 . In scenario 3, the transmitters T1 and

242

J Comb Optim (2007) 14: 229–248

Fig. 5 a Throughput and
b delay vs. loss rate of flow F1
for scenario 1

(a)

(b)
T2 interfere since their schedules {2, 5, 8} and {1, 3, 8} intersect in slot 8; hence the
receiver R1 may experience collisions in slot 8. T2 may interfere with a transmission
of a data packet by T1 to R1 . There is an empty intersection of schedules between
nodes of the same flow. With these scenarios we explore the impact of interference
between a transmitter of one flow with a receiver of another flow and between two
transmitters.
We measure the throughput of flow F1 in scenarios 2 and 3. This is plotted in
Fig. 8. The throughput of LT is not affected when a R1 interferes with T2 but it
does suffer marginally when T1 interferes with the data packets of T2 . The reason
that the throughput is slightly worse than in scenario 0 is because when the flow
intersects in a slot the data also suffers collision; in scenario 3, the acknowledgments
occasionally suffer collision so the overhead per message increases slightly with a
resulting decrease in throughput.
It is at first surprising that throughput of TCP can exceed that of LT considering
the results of scenario 1. In scenario 2, the receiver R1 and transmitter T2 interfere.
This has the net effect of collisions of acknowledgments in flow F1 . The packets
that are transmitted by T1 receive acknowledgment from R1 and hence throughput is

J Comb Optim (2007) 14: 229–248

243

Fig. 6 Overhead per message
vs. loss rate of flow F1 for
scenario (a) 0; (b) 1

(a)

(b)

Fig. 7 a Scenario 2, R1 and T2
interfere in slot 3 at T1 ;
b Scenario 3, T1 and T2
interfere in slot 8 at R1

(a)

(b)

higher than LT for loss rates less than 13% for one retransmission and less than 25%
for two retransmissions. It then rapidly degrades in both cases.
For scenario 3, whenever the data packets of T1 collide with the data packets of
T2 it negatively impacts the throughput of flow F1 . Hence the overall throughput
of scenario 3 is lower than that of scenario 2. Collisions among data packets seem

244

J Comb Optim (2007) 14: 229–248

Fig. 8 Throughput vs. loss rate
for flow F1 for scenario (a) 2;
(b) 3

(a)

(b)
to impact delay in a more negative way than collisions among acknowledgments.
Figure 9 shows that LT is stable while TCP is unstable.
The last two scenarios considered have the most interference. Scenario 4 in
Fig. 10(a) shows that T2 interferes with both endpoints of flow F1 . While the schedules of T1 and R1 do not intersect with each other, the schedule {1, 3, 8} of T2 intersects with the transmitter T1 in slot 8, and with the receiver R1 in slot 3. In scenario 5
(Fig. 10(b)) flows F1 and F2 do not self-interfere. However, T1 intersects with T2 in
slot 8 and with R2 in slot 2. Similarly, R1 intersects with T1 in slot 3 and with R2 in
slot 6. Hence transmitters interfere with each other and with the receivers of the other
flow.
We expect scenario 4 to have worse performance than either scenarios 2 or 3.
As Fig. 11(a) shows, for LT this does not seem to be the case. Its performance
is affected more by collisions with the receiver than with the transmitter, so the
performance closely matches that of scenario 3. TCP suffers more than LT in scenario 4. The only point at which throughput matches the earlier scenarios is for
zero loss rate. For one retransmission, throughput quickly degrades, dropping below that of LT when the loss rate is 7%. When TCP makes two retransmissions

J Comb Optim (2007) 14: 229–248

245

Fig. 9 Delay vs. loss rate for
flow F1 for scenario (a) 2; (b) 3

(a)

(b)

its throughput never exceeds LT. This is the first time in which throughput with
two retransmissions exceeds throughput with one retransmission for TCP. (The
only other time this happens is in scenario 5.) There is a trade-off observed between interference and with retransmissions helping a packet reach its destination.
Scenario 5 shows some interesting behaviour. In Fig. 11(b), the throughput of
TCP never exceeds that of LT. The performance of LT is slightly worse than in scenario 4. Here again TCP with 2 retransmissions exceeds TCP with one retransmission when the loss rate is about 12%. However it has a unusual increase at lower
loss rates. We conjecture that the system is more heavily loaded at low loss rates
because it has more collisions to resolve. This conjecture is supported by the increased delay for TCP with two retransmissions (Fig. 12(b)). As the loss rate increases, this has the effect of decreasing collisions with the result of throughput
increasing. After 12% loss, the additional retransmission is beneficial to throughput.

246

J Comb Optim (2007) 14: 229–248

Fig. 10 a Scenario 4, T2
interferes with both T1 and R1 ;
b Scenario 5, F1 interferes with
F2

(a)

(b)
Fig. 11 Throughput vs. loss
rate for flow F1 for scenario
(a) 4; (b) 5

(a)

(b)
5 Summary and conclusions
In this paper we compared the performance of two transport schemes, TCP and LT,
a scheme based on rateless FEC codes, in a wireless ad hoc network when topology-

J Comb Optim (2007) 14: 229–248

247

Fig. 12 Delay vs. loss rate for
flow F1 for scenario (a) 4; (b) 5

(a)

(b)
transparent scheduling is used for channel access. These schedules are derived from
cover-free families, a type of combinatorial design. We find that LT outperforms TCP
in more strenuous network conditions. For a sequence of scenarios with increasing
interference we draw the following conclusions: LT remains stable under high packet
loss rates whereas TCP becomes unstable; TCP achieves higher message throughput
than LT at low loss rates and when acknowledgments do not suffer collisions; both
protocols are more sensitive to collisions among data packets between flows than to
collisions among a data packet and an acknowledgment.
Acknowledgements Thanks to Minghao Cui for implementing the LT encoding and decoding algorithm in (Luby 2002). The research of Violet R. Syrotiuk and Zhiqiang Zhang is supported in part by
National Science Foundation grant ANI-0240524. Any opinions, findings, conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of NSF.

References
Bloemer J, Kalfane M, Karpinski M, Karp R, Luby M, Zuckerman D (1995) An XOR-based erasureresilient coding scheme. Technical report TR-95-048, ICSI, August 1995
Chlamtac I, Faragó A (1994) Making transmission schedules immune to topology changes in multi-hop
packet radio networks. IEEE/ACM Trans Netw 2(1):23–29
Chlamtac I, Pinter S (1987) Distributed node organization algorithm for channel access in a multi-hop
packet radio network. IEEE Trans Comput 36(6):728–737

248

J Comb Optim (2007) 14: 229–248

Chu W, Colbourn CJ, Syrotiuk VR (2004) Topology transparent scheduling, synchronization and maximum delay. In: Proceedings of the 18th international parallel and distributed processing symposium
(IPDPS’04), April 2004, pp 223–228
Chu W, Colbourn CJ, Syrotiuk VR (2006a) Slot synchronized topology-transparent scheduling for sensor
networks. Comput Commun 29(4):421–428
Chu W, Colbourn CJ, Syrotiuk VR (2006b) The effects of synchronization on topology-transparent
scheduling. Wirel Netw 12:681–690
Colbourn CJ, Syrotiuk VR (2005) Cover-free families and topology-transparency. Bayreuther Math Schr
73:86–106
Colbourn CJ, Dinitz JH, Stinson DR (1999) Applications of combinatorial designs to communications,
cryptography, and networking. In: Lamb JD, Preece DA (eds) Surveys in Combinatorics. Cambridge
University Press, Cambridge, pp 37–100
Colbourn CJ, Syrotiuk VR, Ling ACH (2003) Steiner systems for topology-transparent access control in
MANETs. In: Proceedings of the second international conference on ad hoc networks and wireless
(Ad hoc Now’03), October 2003, pp 247–258
Colbourn CJ, Ling ACH, Syrotiuk VR (2004) Cover-free families and topology-transparent scheduling for
MANETs. Des Codes Cryptogr 32(1–3):65–96
Digital Fountain (2004) Breakthrough reliable transport technology for data and live streaming delivery
over imperfect networks. Technology licensing white paper. Available at http://www.digitalfountain.
com
Du DZ, Hwang FK (2000) Combinatorial group testing and its applications. 2nd edn. World Scientific,
Singapore
Dukes PJ, Colbourn CJ, Syrotiuk VR (2006) Topology-transparent schedules for energy limited ad hoc
networks. In: Proceedings of the IEEE international workshop on foundations and algorithms for
wireless networking (FAWN’06), March 2006, pp 85–90
Dukes PJ, Colbourn CJ, Syrotiuk VR (2007) Directed complete bipartite graph decompositions: indirect
constructions. Discret Math (to appear)
D’yachkov A, Vilenkin P, Macula A, Torney D (2002) Families of finite sets in which no intersection of 
sets is covered by the union of s others. J Comb Theory Ser A 99:195–218
Erdös P, Frankl P, Füredi Z (1985) Families of finite sets in which no set is covered by the union of r
others. Israel J Math 51:79–89
Hedayat AS, Sloane NJA, Stufken J (1999) Orthogonal arrays, theory and applications. Springer, Berlin
IEEE Standards Committee (1996) Wireless LAN medium access control (MAC) and physical layer (PHY)
specifications. In: IEEE 802.11 standard. IEEE, New York, ISBN 1-55937-935-9
Jacobson V (1988) Congestion avoidance and control. In: Proceedings SIGCOMM, August 1988, pp 314–
329
Johnson D, Maltz D (1996) Dynamic source routing in ad hoc wireless networks. In: Imelinsky T, Korth H
(eds) Mobile computing. Kluwer Academic, Dordrecht, pp 153–181
Ju J-H, Li VOK (1998) An optimal topology-transparent scheduling method in multihop packet radio
networks. IEEE/ACM Trans Netw 6(3):298–306
Luby MG (2002) LT codes. In: Proceedings of the 43rd symposium on foundations of computer science
(FOCS’02), November 2002, pp 271–280
Postel JB (1981) RFC 793: Transmission control protocol. ftp://ds.internic.net/rfc/rfc793.txt. September
1981
Rizzo L (1997) Effective erasure codes for reliable computer communication protocols. Comput Commun
Rev 27(2):24–36
Ruszinkó M (1994) On the upper bound of the size of the r-cover-free families. J Comb Theory Ser A
66:302–310
Stinson DR, Wei R, Zhu L (2000) Some new bounds for cover-free families. J Comb Theory Ser A 90:224–
234
Syrotiuk VR, Colbourn CJ, Ling ACH (2003) Topology-transparent scheduling for MANETs using orthogonal arrays. In: Proceedings of the DIALM-POMC joint workshop on foundations of mobile
computing, September 2003, pp 43–49
The Virtual InterNetwork Testbed (VINT) Project (1995) The network simulator—ns-2. http://www.isi.
edu/nsnam/vint/index.html
Zhu C, Corson S (1998) A five-phase reservation protocol (FPRP) for mobile ad hoc networks. In: Proceedings of 17th annual joint conference of the IEEE computer and communication societies (Infocom’98),
March–April 1998, pp 315–321

Fair Variable Transmission Power Control
Minghao Cui and Violet R. Syrotiuk
Computer Science & Engineering, Arizona State University
e-mail: {minghao.cui,syrotiuk}@asu.edu

Abstract—Despite its success in saving energy and increasing
spatial reuse, the use of variable transmission power control in
wireless multihop networks has consequences to fairness. We
study a variant of the hidden terminal problem resulting from
link asymmetries, and its impact on expected node throughput.
We give a model relating the transmission power level and backoff
window size to throughput. Based on the analysis, we propose a
localized algorithm to set the contention window size of a medium
access control protocol according to the transmission power level.
In simulation our protocol achieves the highest fairness index
among several approaches.

I. I NTRODUCTION

in networks where nodes use VTPC. We hypothesize that this
asymmetry can lead to unfairness in node throughput.

Fig. 1.

In contrast to the prevalent use of a common transmission
power by each node in a wireless multihop network, we consider the use of variable transmission power control (VTPC).
In VTPC, the transceiver in each node may be tuned on a
per-packet basis to one of a number of discrete power levels,
with each power level naturally corresponding to a unique
transmission range.
Gomez et al. [1] study and analyze the impact of using
VTPC on the physical network connectivity, network capacity,
and energy savings in wireless multihop networks. These
results, and the existence of commercial wireless cards that
support VTPC (see, e.g., [3]), motivate the need to design
protocols that leverage variable transmission power control.
VTPC has been applied in the medium access control
(MAC) protocol of wireless networks to decrease power
consumption [4], [5] and to increase spectrum reuse [6], [7],
[8], [9]. It has also been applied to reduce the probability
of collisions [10], [11], [12] and as a spatial backoff scheme
[13]. Despite these successful applications of VTPC, coping
with link asymmetries introduces new challenges.
One asymmetry may occur if a sender transmits with a
higher transmission power level than its receiver. In this case,
there is a chance that the receiver cannot reply successfully.
This problem is easily solved by including the transmission
power level as an extra field in the packet header.
A more difficult asymmetry to solve occurs between high
and low power senders. Consider Figure 1 with nodes A,
B and C; dotted and solid circles represent the transmission
range of high and low transmission powers levels, respectively.
If A transmits at low power while B transmits at high power,
A is within the transmission range of B, but not vice versa.
If a CSMA/CA style handshake is initiated by A to C at
low power, B may be a hidden terminal to A. While the
handshake solves the hidden terminal problem when the same
transmission power level is used by all nodes, it is insufficient

B may be hidden to A when asymmetric power is used.

A scenario is set up to test our hypothesis. Figure 2(a) shows
nodes A, B, C, and D positioned at coordinates (50, 50),
(50, 100), (290, 50), and (290, 250), respectively. Two flows
are introduced, one from A to B, the other from C to D,
using a transmission power level with a range corresponding
to 100 m and 250 m, respectively. In this scenario, nodes C
and D are hidden terminals to nodes A and B.

(a) Scenario
Fig. 2.

(b) Starvation of flow 1

A scenario showing unfairness from asymmetric links.

Using this scenario, we run a simulation in ns-2 [14]
using IEEE 802.11 as the MAC protocol, except with the
assigned the transmission power levels. Figure 2(b) shows the
throughput for each of the two flows for ten different runs.
In each run, flow 1 achieves less than half the throughput of
flow 2. Since C cannot receive packets transmitted by A at
low power, C may also transmit even when A is transmitting.
On the other hand, when C transmits at high power, A must
refrain from transmission. Therefore, C acquires access to the
channel more often than A. In general, nodes transmitting
with high transmission power acquire disproportionately high
access to the channel than nodes transmitting at low power,
causing unfairness in the node throughput.

683
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

To address this unfairness, we use the contention window
size to counteract the advantage nodes transmitting at high
power have in channel access. The idea is that if low power
transmitters use a smaller contention window size this may
correct the balance in the throughput loss caused by high
power hidden terminals. We set up an analytical model for
throughput under the simplified assumption of uniform node
distribution and derive a relation between transmission power
and contention window size. Based on our analysis, we
propose a MAC protocol that sets the contention window size
to achieve fair node throughput. Simulation results show that
our protocol achieves a significantly higher fairness index over
several other approaches.
II. R ELATED W ORK
IEEE 802.11 uses the binary exponential backoff (BEB)
algorithm [4]; it is well known that BEB is unfair [15],
[16] since it favours the last node that was successful in
transmission. This exacerbates fairness in heavy traffic loads
[17]. Many algorithms have been proposed to make IEEE
802.11 fair, many of which relate to the backoff algorithm.
One solution is the multiplicative increase linear decrease
(MILD) algorithm [18]. In MILD, the contention window size
is multiplied by 1.5 on a collision and is decreased by 1 on a
successful transmission. Similar approaches include the both
exponential increase and decrease [19], linear/multiplicative
increase and linear decrease [20], and both multiplicative
increase and decrease [21]. In [22], [23] local information
about fairness is exchanged between neighbours to achieve a
globally fair state. These methods suffer from the overhead
required to communicate the fairness state. There are also
other proposed methods for improving the fairness by applying
signal rate [24] and traffic flow priority [25].
While the variant of the hidden terminal problem arising
from asymmetric links has been identified [12], [13], [26], the
associated fairness problem has not received much attention.
In [26], a “SHUSH” signal is used to inform potential hidden
terminals to keep silent. In this solution, spatial reuse is
sacrificed to alleviate the problems due to asymmetric links.
Similar to our approach, in [12] the contention window size is
a linear function of the transmission distance and the backoff
window; no analysis is provided to support the function choice.
III. A M ODEL FOR T HROUGHPUT IN VTPC N ETWORKS
A. Modelling Throughput on Probability of Success
For simplicity, we consider a transmission frame that consists of a two-way (Data-ACK) handshake. If the data packet
and the ACK are both received successfully, then the transmission is successful.
Let Psucc denote the probability of a node having a successful transmission in the current transmission frame. We use this
probability as a measure of node throughput because Psucc
represents the expected throughput of a node over time. Let:
Ptr : The probability of transmission; this represents the
probability that a node initiates a transmission at the
beginning of the current transmission frame.

Ri :

The range corresponding to transmission power level
i; Rmax is the maximum transmission range.
D:
The node density.
Pact : The probability of a node in the network being active,
i.e., it has a packet queued for transmission.

Let us assume that the current transmission range of a source
node s is Rs . In order for a packet to be transmitted correctly
from s to t, three conditions must be satisfied: (1) The source s
is attempting to transmit in the current transmission frame, i.e.,
its backoff timer expires before this frame starts. Furthermore,
carrier sensing indicates an idle channel. (2) During the
transmission of the data packet, for each transmission power
level i, each node within a distance of Ri of t must refrain
from transmission if its current transmission range is greater
than or equal to Ri . This condition ensures that t does not
experience a collision. (3) During the transmission frame,
potential hidden terminals to s must refrain from transmission
for the duration of the transmission. Here, potential hidden
terminals are those nodes outside of transmission range of s,
but their own transmissions can reach s.
The probability that the first condition holds is
Ptr =

1
2Pidle
× Pidle =
backoff timer value
CWs

(1)

where CWs is the contention window size of node s, Pidle is
the probability that the carrier sensing indicates the channel
is idle. The value of the backoff timer is a random number in
the range [0, CWs ).
For the second condition, given any node in t’s neighbourhood, the average probability of this node remaining
silent during the transmission of a data packet is given as
(1 − CW2avg )Tdata , where CWavg is the average contention
window size of the neighbouring nodes, assuming that the
transmission time of the forward packet is equal to Tdata
number of mini-slots.
Assuming that the nodes in the network are uniformly
distributed, the probability that the second condition holds is
n

Tdata  i=1 DπPact Ri2 PRi
2
Pcond2 =
1−
(2)
CWavg
where PRi is the probability of a node using a transmission
range of Ri , and n is the number of transmission levels.
For the third condition, given any node in s’s neighbourhood, the average probability of this node remaining silent
during the transmission of the entire transmission frame is
(1 − CW2avg )T where T is the number of mini-slots in a
transmission frame.
The probability of the third condition holding is

Pcond3

=

1−

2
CWavg

T ×Nhidden
(3)

where Nhidden is the number of hidden terminals to node s.

684
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

B. Node Throughput Fairness
In order for the expected node throughput to remain the
same among nodes independent of their transmission power
levels, the value of Psucc should be the same for all the nodes.
In the expression of Psucc , Pcond2 is constant for all the power
levels. Thus, Psucc can be rewritten as
T ×Nhidden

2
2
Psucc =
× 1−
×C
(4)
CWs
CWavg
where C is a constant.
Since CW2avg is very small and T × Nhidden is some integer,
we can approximate
T ×Nhidden

2
2T × Nhidden
1−
1−
(5)
CWavg
CWavg
and thereby approximate the probability of success as,
Psucc



Hs

=

2
× Hs × C, where
CWs
2T × Nhidden
1−
.
CWavg

(6)
(7)

In a network where nodes are uniformly distributed, the
nodes using higher power observe a smaller number of hidden
terminals Nhidden . The lower a transmission power a node
uses, the larger the number of hidden terminals it may have.
In order to obtain equal values of Psucc , the contention window
size of node s depends on the number of the hidden terminals
Nhidden according to Equation (6).

addition, since the distance between H and s is greater than the
transmission range of transmission power level i, the minimum
required power for s to reach H is greater than transmission
power level i. Thus, all the hidden terminals of s at power
level i are in the neighbour table and their minimum power
entry is greater than transmission power level i. Accordingly,
we can prove that all the nodes in the neighbour table with
minimum power entry greater than transmission power level i
are hidden terminals to s at transmission power level i.
Given the neighbour table, Hs can be computed for each
transmission power level i. CWs is proportional to Hs with an
average contention window size of CWavg . We now incorporate our analysis into a fair MAC protocol for a network using
VTPC. The neighbour table is implemented at the MAC layer
for each node. When a node s has a packet to transmit, Hs is
computed according to the transmission power level selected;
the size of the contention window of s is computed according
to Equation (6), i.e., Hs /CWs is constant1 . Pseudocode for
the transmit and receive procedures of our fair MAC protocol
is given in Figures 3 and 4, respectively.
while there is data to transmit from s to t do
compute Hs using the neighbour table
set the contention window size such that the ratio
Hs /CWs is constant
4:
continue with the CSMA/CA transmit procedure
5: end while
1:
2:
3:

Fig. 3.

Transmit procedure for a fair MAC protocol in VTPC networks.

IV. A FAIR MAC P ROTOCOL FOR VTPC N ETWORKS
Equation (7) defines Hs in terms of CWavg and Nhidden .
In order to calculate CWavg and Nhidden , each node must: (1)
Include the current transmission power and contention window
size in the header of each outgoing packet. (2) Maintain a
neighbour table. Each row contains three entries: the node
identifier, its contention window size, and the minimum power
required for the nodes to reach each other (estimated from
signal strength and transmission power). (3) Update the table
every time a packet is received or overheard.
When a transmitter s needs to estimate a value for Hs ,
the variable CWavg is estimated by averaging the values in
column two of the neighbour table. If s uses power level i,
Nhidden is calculated by counting the number of nodes in the
table with minimum power entry greater than power level i.
Definition A hidden terminal of node s at transmission power
level i is a node H such that H is out of the transmission range
of node s when s is using transmission power level i, and s
is within the transmission range of node H.
Theorem 4.1: The number of nodes in the neighbour table
of node s with minimum power entry greater than transmission
power level i is equal to the number of hidden terminals of s
at transmission power level i.
Proof: By definition, a hidden terminal H at transmission
power level i of node s, satisfies two conditions. As a result,
node s has an entry for node H in its neighbour table. In

if a packet is received or overheard from node i then
update the entry for node i in the neighbour table
3: end if
4: continue with the CSMA/CA receive procedure
1:
2:

Fig. 4.

Receive procedure for a fair MAC protocol in VTPC networks.

V. S IMULATION S TUDY
In this section we run simulations to validate the analysis
in §III and evaluate the fairness of the MAC protocol that
emerged in §IV; we use the network simulator ns-2 version
2.26 [14]. For each of the scenarios, ten replicates are run.
We compare three approaches to achieve fairness in node
throughput: (1) SAME: The same contention window (CW)
size is used for all the transmission power levels. This approach simulates the traditional VTPC, which suffers unfairness from asymmetric links. (2) LINEAR: The contention
window size is a linear function of the distance between
the transmitter and the next-hop receiver. This approach is
proposed by Chu [12]. (3) FAIR: The contention window size
is a function of the transmission power level.
1 The absolute value of this ratio is not critical to the fairness of our
algorithm as long as this ratio remains the same for all the nodes. However
it may afftect the total throughput in the whole network. Finding an optimal
value of this ratio to maximize the total throughput is not trivial, and is omitted
due to space constraints. In the simulation, we use a ratio of 0.004.

685
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

We use a data channel rate of 11 M bps with each data
packet 500 bytes in size. We want each flow in the network to
be saturated so the channel is used at its full capacity. The data
arrival rate at each flow is 11 M bps. To focus our investigation
on the unfairness caused by asymmetric links, all the flows in
the network are one-hop flows as in [12]. The transmission
power levels are so chosen to model the Lucent WaveLAN
DSSS radio. These and other simulation parameters are:
(a) Min/Max ratio
Data packet size, traffic type
Channel data rate, arrival rate
Simulation time , antenna
Carrier sense range
High transmission power
Low transmission power

500 bytes, UDP
11 M bps, 11 M bps
200 s, omni-directional
approximately 2 × transmission range
0.2818 W (250 m)
7.214E-3 W (100 m)

We measure: (1) The total throughput of each flow: the
total data received in bytes. (2) Min/Max throughput ratio:
the ratio of the minimum throughput among all flows to
the maximum throughput among all the flows; this is one
way of evaluating
n (3) Jain’s fairness index [27]:
n the fairness.
fairness = ( i=1 xi )2 /n i=1 x2i where 0 ≤ fairness ≤ 1, n
is the total number of flows with each flow as x1 , x2 , . . . xn .
Equally distributed throughput achieves a fairness index of 1.
A. A Simple Two Flow Scenario
The first scenario we investigate is the one in Figure 2(a).
Figure 5 shows the average throughput for each flow for each
of the approaches. With SAME, since node C is outside the
transmission range of nodes A and B, and the two flows
use the same contention window size, flow 2 dominates the
channel bandwidth. Using Chu’s (LINEAR) approach [12],
the throughput of flow 1 is greatly improved by using a
smaller contention window size. However, the function has
overcompensated for the asymmetry as flow 1 now dominates
the channel. Using the FAIR transmission approach we get
nearly balanced channel usage between the two flows.

Fig. 5.

The average throughput for each flow.

Figures 6 shows the min/max throughput ratio and Jain’s
fairness index for throughput, respectively, for each flow for
each approach. The closer the min/max and Jain’s index is to 1,
the more balanced are the flows in the network. The min/max
ratio for FAIR achieves more than 0.95 while for SAME it
is only around 0.5. The ratio for LINEAR is even lower than
SAME, suggesting that using a linear function of distance for
the contention window size is worse for fairness than using a
uniform contention window size. According to Jain’s fairness
index, FAIR achieves the best throughput fairness.

Fig. 6.

(b) Jain’s fairness index

Fairness metrics for throughput (scenario 1).

B. A Scenario with Background Traffic
We now study the more complex scenario in Figure 7. To
eliminate unfairness caused by the location and topology, the
scenario is highly symmetric with 36 nodes organized in a
6 × 6 grid in an area of 500 × 500 m2 . These nodes generate
background traffic with a flow from each node to one of its
nearest neighbours. The transmission power level for each of
these nodes is randomly assigned.

Fig. 7.

A more complex scenario with background traffic.

Eight additional nodes (shaded) are introduced into the
center of the network and four disjoint flows are established. It
is these four flows from which data is collected. Flows 1 and 2
use low transmission power with a corresponding transmission
range of 100 m while flow 3 and 4 use high transmission power
with a corresponding transmission range of 250 m. The nodes
of flows 3 and 4 are hidden terminals to flow 1 and 2.
Figure 8 shows the average throughput for each flow. Again,
FAIR exhibits the best fairness among all approaches. In
SAME, flows 1 and 2 suffer the most as flows 3 and 4
may interrupt their transmission. In addition, the background
traffic exaggerates the asymmetry. In LINEAR, flow 1 and
2 use a small contention window but overcompensate and
the asymmetry is reversed. In FAIR, the asymmetry between
the low and the high power transmission is compensated
correctly by contention window size. The throughput for all
flows are well balanced. While LINEAR achieves the highest
total throughput for all flows, FAIR achieves the best fairness
while maintaining a high total throughput.
Figure 9 plots the min/max throughput ratio and Jain’s
fairness index for throughput for each of the flows. In this more

686
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

Fig. 8.

The average throughput for each flow.

complex scenario, FAIR outperforms the other approaches in
all fairness measures. The LINEAR approach overcompensates
low power nodes, resulting in nodes that are too aggressive in
attempting to access the channel. While this approach may
increase the total channel utilization, it does not improve
the fairness. The FAIR approach exhibits the best throughput
fairness while achieving a total channel utilization higher than
the SAME approach.

(a) Min/Max ratio
Fig. 9.

(b) Jain’s fairness index

Fairness metrics for throughput (scenario 2).

VI. C ONCLUSIONS AND F UTURE W ORK
In this paper we modelled and analyzed the problem of fairness in wireless ad hoc networks using variable transmission
power control. We use the contention window size to balance
the asymmetry between nodes using high transmission power
and those using low transmission power. A localized fair MAC
protocol is designed based on this idea. Simulations show
that our protocol can achieve high throughput fairness among
flows with different transmission power, while retaining high
total channel utilization compared to other protocols. Future
directions may include: (1) The data rate may be another
variable that affects throughput fairness. (2) We focus our
study on the unfairness caused by asymmetric links of high
power flows to low power flows, and focus on one-hop flows.
We should also consider multihop flows, and interactions with
other layers of the network architecture.
ACKNOWLEDGEMENT
This work is supported in part by NSF grant ANI-0240524.
R EFERENCES
[1] J. Gomez and A. T. Campbell, “A case for variable-range transmission
power control in wireless multihop networks,” in Proceedings of IEEE
Infocom, vol. 2, March 2004, pp. 1425–1436.
[2] “Data sheet: Cisco aironet 350 series client adapters,”
http://www.cisco.com/en/US/products/hw/wireless/index.html.

[3] “WaveLAN/PCMCIA card user’s guide (version 4.0),” NCR Corporation, http://www.info.ncr.com/eDownload.cfm?itemid=982740002.
[4] P. Karn, “MACA — a new channel access method for packet radio,” in
Proceedings of ARRL/CRRL, September 1990, pp. 134–140.
[5] E.-S. Jung and N. H. Vaidya, “A power control MAC protocol for ad
hoc networks,” in Proceedings of ACM Mobicom, September 2002, pp.
36–47.
[6] J. P. Monks, V. Bharghavan, and W.-M. Hwu, “A power controlled
multiple access protocol for wireless packet networks,” in Proceedings
of IEEE Infocom, April 2001, pp. 219–228.
[7] A. Muqattash and M. Krunz, “Power controlled dual channel (PCDC)
medium access protocol for wireless ad hoc networks,” in Proceedings
of Infocom, 2003, pp. 470–480.
[8] ——, “A single-channel solution for transmission power control in
wireless ad hoc networks,” in Proceedings of Mobihoc, May 2004, pp.
210–221.
[9] S. Wu, Y. Tseng, and J. Sheu, “Intelligent medium access for mobile
ad hoc networks with busy tones and power control,” IEEE Journal on
Selected Area in Communications, vol. 18, no. 9, pp. 1647–1657, 2000.
[10] J. Fuemmeler, N. H. Vaidya, and V. V. Veeravalli, “Selecting transmit
powers and carrier sense thresholds for csma protocols,” University of
Illinois, Urbana-Champaign, Tech. Rep., October 2004.
[11] X. Yang and N. H. Vaidya, “On physical carrier sensing in wireless ad
hoc networks,” in Proceedings of IEEE Infocom, vol. 4, March 2005,
pp. 2525 – 2535.
[12] B. Chu, “Improving IEEE 802.11 performance with power control and
distance based contention window selection,” Master’s thesis, University
of Illinois, Urbana-Champaign, 2005.
[13] C. J. Colbourn, M. Cui, V. R. Syrotiuk, and E. L. Lloyd, “A power
control MAC protocol for ad hoc networks,” in Proceedings of MedHocNet’06, June 2006.
[14] “The network simulator — ns-2,” University of California, Berkeley,
http://www.isi.edu/nsname/ns/.
[15] C. E. Koksal, H. Kassab, and H. Balakrishnan, “An analysis of shortterm fairness in wireless media access protocols,” SIGMETRICS Perform. Eval. Rev., vol. 28, no. 1, pp. 118–119, 2000.
[16] H. S. Chhaya and S. Gupta, “Performance modeling of asynchronous
data transfer methods of IEEE 802.11 MAC protocol,” Wireless Networks, vol. 3, no. 3, pp. 217–234, 1997.
[17] C. L. Barrett, M. V. Marathe, D. C. Engelhart, and A. Sivasubramaniam,
“Analyzing the short-term fairness of IEEE 802.11 in wireless multi-hop
radio networks,” in Proceedings of IEEE MASCOTS, 2002, pp. 137–144.
[18] V. Bharghavan, A. Demers, S. Shenker, and L. Zhang, “MACAW: a media access protocol for wireless LAN’s,” in Proceedings of SIGCOMM,
1994, pp. 212–225.
[19] N. Song, B. Kwak, J. Song, and M. E. Miller, “Enhancement of
IEEE 802.11 distributed coordination function with exponential increase
exponential decrease backoff algorithm,” in Proceedings of IEEE VTC,
April 2003, pp. 2775–2778.
[20] J. Deng, P. K. Varshney, and Z. J. Haas, “A new backoff algorithm for
the IEEE 802.11 distributed coordination function,” in Proceedings of
CNDS, January 2004.
[21] H. Wu, S. Cheng, Y. Peng, K. Long, and J. Ma, “IEEE 802.11
distributed coordination function (DCF): Analysis and enhancement,”
in Proceedings of IEEE ICC, 2002, pp. 605–609.
[22] Z. Haas and J. Deng, “On optimizing the backoff interval for random access schemes,” IEEE Transactions on Communications, vol. 51, no. 12,
pp. 2081–2090, 2003.
[23] B. Bensaou, Y. Wang, and C. Ko, “Fair medium access in 802.11 based
wireless ad-hoc networks,” in Proceedings of ACM Mobihoc, 2000, pp.
99–106.
[24] T. Pagtzis, P. Kirstein, and S. Hailes, “Operational and fairness issues
with connection-less traffic over IEEE 802.11b,” in Proceedings of IEEE
ICC, 2001, pp. 176 – 185.
[25] D. Qiao and K. Shin, “Achieving efficient channel utilization and
weighted fairness for data communications in IEEE 802.11 WLAN
under the DCF,” in Proceedings IEEE IWQoS, 2002, pp. 227–36.
[26] A. Sheth and R. Han, “SHUSH: Reactive transmit power control for
wireless MAC protocols,” in Proceedings IEEE WICON, 2005, pp. 18–
25.
[27] R. Jain, D. Chiu, and W. Hawe, “A quantitative measure of fairness
and discrimination for resource allocation in shared computer systems,”
September 1984, DEC Research Report TR-301.

687
1930-529X/07/$25.00 © 2007 IEEE
This full text paper was peer reviewed at the direction of IEEE Communications Society subject matter experts for publication in the IEEE GLOBECOM 2007 proceedings.

Dynamic Source Routing for Ad Hoc Networks
Using the Global Positioning System
Stefan0 Basagni

Imrich Chlamtac

Violet R. Syrotiuk

Center for Advanced Telecommunications Systems and Services (CATSS)
Erik Jonsson School of Engineering and Computer Science
The University of Texas at Dallas
P.O. Box 830688, Mail Station E C 3.1
Richardson, Texas 75083-0688
e-mail: {basagni, chlamtac, syrotiuk}Qutdallas .edu
Abstract- This paper proposes a new routing protocol
for ad hoc networks built -around the source routing technique combined with the location (e.g., GPS coordinates)
of nodes obtained by an energy and distance smart dissemination mechanism. The key new observation used is that
the location information provides each node with a snapshot of the topology of the complete network from which a
source route may be computed locally rather than through
route discovery. The resulting protocol has reduced delay,
and is more bandwidth and energy efficient, than both traditional (proactive and reactive) ad hoc routing protocols,
as well as location based routing protocols.

I . INTRODUCTION
Routing a packet from a source to a destination in an

ad hoc network, i.e., a wireless network in which all the
nodes are free to move randomly and organize themselves
arbitrarily, is a challenging problem. The main source of
the challenge comes from the fact that there are no base
stations in these networks, and therefore the nodes themselves must also function as switches, forwarding packets
to their destination while coping with the dynamically
changing network topology.
Depending on how a route is determined, existing routing protocols for ad hoc networks fall into two main categories. In proactive protocols, a route between the source
node S and the destination node D is immediately available because each node maintains a routing table giving the node that is the “next hop” on the route to D .
Maintaining these routing tables requires each node to
exchange routing tables with its neighborhood whenever
a topology change is detected, and then recompute the
routes based on the updated information. Protocols in
which a route dzscovery phase precedes the transmission
of a data packet are called reactive. In a reactive protocol,
the route is determined only when needed. In addition to
incurring delay due to the route discovery process, there is
no guarantee that the route discovered is usable because
of node mobility.
In both categories of protocols, the information on the
route between S and D is given in terms of the topology
This work was supported in part by the Army Research Office
(DARPA) under contract No. DAAG55-97-1-0312

0-7803-5668-3/99/$10.00 0 1999 IEEE.

301

of the network, meaning the route is given as a sequence
of nodes. The route is explicitly specified in reactive protocols, whereas in proactive protocols it corresponds to a
sequence of next hop table lookups at each node along the
route. Since in ad hoc networks the topology may change
rapidly and unpredictably, this implies that a large part of
the network’s limited bandwidth and, consequently, each
node’s limited energy, has to be used either for updating
or gathering routing information.
In an attempt to overcome the drawbacks derived from
the dependency between the routes and the topology of
the network, routing protocols have recently been proposed in which each node stores information about the
(geographic) location of each other node [l],[5]. In these
solutions the source node S can compute the (geographic)
area in which D is expected to be found and send the
packet to all nodes in D’s direction. Both these solutions
assume that each node is aware of its current location
through the use of, for example, Global Positioning System (GPS) receivers available at each node.
The routing protocol described in this paper combines
the advantages of reactive protocols, such as the Dynamic
Source Routing (DSR) protocol presented in [4], with the
improved performance that is typical of the location based
solutions. As in the DSR protocol, when the source node
S of a data packet goes to transmit the packet to D, it
includes the complete route the packet is to follow in the
packet header ( %ource routing”). Each intermediate node
on the designated route will forward the packet to the next
node on the route itself until D, if possible, is reached.
Using the location dissemination mechanism described
in our previous work [l],we maintain at each node a location table that contains for each other node it’s location
given as GPS coordinates. The key new observation used
is that the location table may not only be used to determine the direction of a given node from the source, but it
also provides a snapshot of the entire network topology.
Given a bound on a node’s transmission radius, i.e., the
distance at which its transmissions can be received, each
node not only knows the positions of all nodes, but can
also compute the neighbors of each node at the time it

sent its last location update. Thus, the route to the destination may be computed locally without the need for a
route discovery phase and its associated delay.
Specifically, when a new data packet is ready to be sent
from S to D:

S constructs from it’s location table a representation
of the topology of the network, i.e., a graph representing the node connectivity;
S locally computes a route to D (e.g., the shortest
path, or the best path according to some routing criteria), and then, if a route physically exists between
S and D,
S transmits the packet, that includes the route the
packet is to follow, to the first node on the computed
route to D.
Through the use of simulation, we show that the average delay of routing a packet between any two nodes is
always less than the average delay of the solutions mentioned above. The reduced delay occurs since we eliminate the overhead of reactive protocols. Specifically, no
route discovery phase is ever needed and no route maintenance needs to be performed (reporting of broken links,
i.e., edges that become unusable in the graph). There
are several reasons why our solution is more bandwidth
and energy efficient. Compared to location based routing
methods, in our solution, a data packet is sent along a single route instead of to all the nodes in the direction of D.
Therefore, fewer copies of the same packet are traveling
through the network. As well, the location information
that is disseminated is very small in terms of the number
of bytes transmitted when compared with routing tables
exchanged by proactive protocols. These properties make
our protocol suitable for ad hoc networks with a higher
packet arrival rate, where previous solutions become unstable.
The remainder of this paper is organized as follows.
Section I1 explains how a location table is maintained at
each node using an energy and distance smart dissemination mechanism, and-how a graph representing the network topology can be constructed from the contents of the
location table. Section I11 describes the new routing protocol that combines the source routing technique with the
graph obtained from the location table information. The
simulation results showing the advantages of this combined approach are presented in Section IV. Finally, our
conclusions are found in Section V.

11. G P S BASEDTOPOLOGY
REPRESENTATION

As in other location based routing protocols, we assume that each node is aware of its own (geographical)
location. Using a Global Positioning System (GPS) receiver, a node can receive GPS broadcasts and compute
its three-dimensional coordinates (latitude, longitude, and

altitude), velocity, and even the current “global” time,
with extremely high precision.
In order for the nodes in an ad hoc network to become
location aware, i.e., each node is aware of the location
of all other nodes, each node floods the network with a
location packet containing its current location. Upon reception of a location packet from a node B , a node A
updates its location table that stores, for each other node,
B’s location. In order to meet the requirements of ad hoc
networks, our dissemination mechanism is tailored to minimize bandwidth and energy usage. This is achieved by
transmitting the small, constant size location packets at
a frequency, and for a distance, that is locally optimized
by each node depending on its velocity. The accuracy of
our dissemination mechanism, as well as its effectiveness
in supporting location based routing in ad hoc networks,
has been studied and presented in [2] and [l],respectively.
Given the location table, and a bound on the transmission radius of each nodel, it is straightforward to compute
which nodes are in the transmission range of each other
node in the network. In graph theoretic terms, this means
to construct from the location table the undirected graph
G = (V,E ) representing the network topology (i.e., where
nodes are positioned and how they are connected), where
V is the set of network nodes, and E is the set of bidirectional radio links. An edge ( A , B ) E E between two
nodes A and B means that the nodes A and B are in the
transmission range of one another. Such a graph represents a “snapshot”of the network topology. Note that G
can be constructed efficiently, in time polynomial in n,
the number of the nodes of the network, and thus it only
imposes a negligible overhead for a node.
USINGG P S
111. DYNAMIC
SOURCEROUTING
Source routing is a routing technique that has been
used in a number of contexts in wired networks (see, e.g.,
[3], [ 6 ] )as well as in wireless networks. The basic idea
of source routing is that the sender (or “source”) of the
packet determines the complete sequence of nodes through
which to forward the packet. The source then explicitly
lists this route in the packet header, specifying each forwarding “hop” by the identifier of the next node to which
to transmit the packet on its way to the destination.
In the Dynamic Source Routing (DSR) protocol [4] for
ad hoc networks, due t o the rapidly changing network
topology, a route discovery is used to dynamically discover a route to any other node in the network in an “on
demand” fashion. This is achieved by the source broadcasting a route request packet specifying the intended destination. On reception of a route request by a node that is
not the intended destination, if this node has not already
‘The transmission radius of a given node may also be included in
the location packet without affecting t h e efficiency of t h e dissemination mechanism.

3 02

,

processed this packet before (to prevent looping and stop
the flood associated with the route request), it will append its identifier onto the route in the packet header
and re-broadcast the packet. If the receiver of the route
request packet is the intended destination, then it returns
a route reply packet to the initiator of the route discovery,
following the newly constructed path in the reverse order.
In DSR, each node also maintains a route cache which
is checked prior to initiating a route discovery in the case
a route to the destination has previously been discovered
and is still considered usable. Aggressive caching techniques, promiscuous learning of routes, and route maintenance (monitoring of the status of a source route while in
use) are all used in order to reduce the overhead and delay
associated with route discovery and improve the efficiency
of the routes used.
We propose a dynamic source routing technique for ad
hoc networks combined with network location awareness.
Every time a node has a packet to transmit] it computes
from its location table obtained through the dissemination mechanism, the graph G representing the “current”
network topology. Then, it applies to G, locally, a (centralized) algorithm for the determination of a minimum
cost path to the destination. We associate a cost of 1 with
each edge of the graph. Thus, the total cost represents
the total number of transmissions (hops) a packet must
take to reach the destination. Therefore, a minimum cost
path minimizes the overall transmission time, the related
energy consumption and the overall needed bandwidth.
Once the source route is computed, the packet is processed in a manner similar to any source routing protocol. Namely, the obtained source route is included in the
header of the packet, and the packet is transmitted in a
hop-by-hop fashion to those nodes on the path.
Our resulting routing protocol is simple and easy to
implement] relying only on a bandwidth and energy efficient dissemination mechanism, rather than on the route
request and reply control packets required by DSR. As
well, our protocol does not require any complex route
caching schemes, nor any route maintenance to be performed, without which DSR would not be a competitive
routing protocol.
IV. SIMULATION
RESULTS
In this paper, we have simulated our dynamic source
routing protocol that is combined with the location of
nodes (henceforth, we will refer to our protocol as DSRGPS) and compared it to a simplified version of the Dynamic Source Routing (DSR) protocol [4]. Specifically
in DSR-GPS, when a packet arrives at a source node S
with destination D , S computes the graph G representing the network topology, and then uses a breadth first
search on G to find the shortest path to D (to minimize
the number of transmissions). In DSR, the source node S

initiates a route discovery to D by broadcasting a route
request packet and waiting for the associated route reply. S buffers the packet while waiting for the route reply
and can process other control and data packets during
its wait. Route caching and route maintenance was not
implemented in order to compare the performance of the
two different forms of route discovery. After obtaining a
source route, both DSR-GPS and DSR process the packet
in the same manner.
We have developed a discrete event simulator of an
ad hoc network, implemented in C++, and modeled the
DSR-GPS and DSR routing protocols in the network.2
Each of the n = 30 nodes of the ad hoc network can
freely move around in a 1000 x 1000 meter region (modeled as a grid) according to the following “inertia” mobility model. (To ease the modeling, the node movements
are discretized to grid units with a grid unit equal to 1
meter.) Each time a node moves, it determines its direction randomly, by choosing between its current direction (with 75% probability, i.e., it has a certain inertia
to keep moving in its current direction) and uniformly
among all other directions (with 25% probability). The
node then moves in the chosen direction according to its
current speed. When a node reaches a grid boundary, it
bounces back into the region with an angle determined by
the incoming direction.
Each node has a fixed transmission range of 350 meters since we found that this value results in high network
connectivity, i.e. after network topology changes, the network was connected in more than 95% of the cases.
Each node is modeled by a store-and-forward queue,
with buffer space that is adequate for packets that are
awaiting transmission. Each link is modeled by a FCFS
queue with service time as the packet transmission time
characterized by a bandwidth of 1 Mbps. Control packets (location packets in DSR-GPS, and route request and
reply packets in DSR) and data packets share the same
transmission channel. The control traffic has higher priority than data traffic and is always processed first. Thus,
the control traffic may be affected by the network load,
and the transmission of data packets may be slowed down
by the transmission of control packets.
Each control (location) packet in DSR-GPS contains time-stamped, node identified, position coordinates.
These packets are generated every time a node moves (i.e.,
at a frequency that is a function of the node velocity; see
also [2]). Each control packet in DSR contains a source
and destination identifier, a source route, and a unique
identifier. In both protocols, data packets contain a payload that is 1K in size, as well as the source, destination,
and source route in the packet header.
A data packet was considered to be successfully routed
2Currently, our study is limited t o network-layer details, thus no
link- or physical-layer are modeled.

303

if the source route discovered, and included in the packet
header, could be followed in a hop-by-hop manner all the
way from the source to the destination. If, because of
a change in the network topology the next hop was unreachable (i.e., no longer in transmission range) then the
packet was considered t o be unsuccessfully routed. For
DSR-GPS a routing failure could also occur if the source
and destination were in different components in the topology graph G (i.e., no path existed between S and D in the
graph). In DSR, a routing failure could occur if the route
reply was never returned in response to a request. This is
detected by having the buffered data packet time out. In
both DSR-GPS and DSR, if the source route could not be
obtained, the packet was simply dropped. In our simulations, data packet arrivals are distributed exponentially
with a mean of 100ms.
Figure 1 shows the percentage of successfully routed
packets in DSR-GPS and DSR for nodes whose velocity
varies from 6m/s t o 20m/s, i.e., from around 20 km/h to
around 70 km/h. In DSR-GPS the routing success is always more than 99% due to accuracy of the dissemination
mechanism and the fact that the local source route computation is performed with constant delay at the node.
The routing success of DSR decreases with increasing
node velocity since the source route becomes more vulnerable to failure with increasing network mobility.

98
96

11

tt

Node Velocity (I&)

Fig. 1. Percentage of successful routing as a function of node mobility.

The delay experienced by a data packet was computed
by subtracting the arrival time of the packet at the source
node S from the time of its delivery at the destination
node D. Since a source route must be obtained before the
data packet can be transmitted, this delay measure also
includes the delay incurred by the route discovery (a constant time in DSR-GPS, and a variable time in DSR). The
global average delay was computed by simply averaging
the delay for each successfully routed data packet. Figure 2 shows the global average delay of successfully routed
data packets in DSR-GPS and DSR again for nodes whose

velocity varies from 6m/s to 20m/s. The global average
delay for DSR-GPS is roughly 40ms for all node speeds
whereas the delay for DSR ranged from 10 t o 50ms higher.
This is, in part, due to no attempt being made to build
or return the shortest source route during route discovery.
As a result, significantly longer routes than that obtained
by the shortest path algorithm resulted, with the associated transmission delay for each hop in evidence in the
delay.
I

80

-

,_.'..'....
..'....
I

I

I

I

I

"""-g;; -

........__.

30 I
6

I

I

8

IO

I

12

I

14.

i

I

I

I

16

18

20

Node Velocity ( d s )

Fig. 2. Global average delay as a function of node mobility.

All the simulations ran for a time long enough to achieve
a confidence level of 95% with a precision within 5%.

v.

CONCLUSIONS A N D FUTURE
RESEARCH

In this paper we have described how network location
awareness, obtained through GPS receivers and the efficient dissemination of location information, can be combined with source routing to obtain a new routing protocol
(DSR-GPS) for ad hoc networks. The route discovery is
performed locally at the source when a data packet arrives. The source first computes a graph that represents
the the network topology using its location table, and then
computes the shortest path t o the destination on the resulting graph as the source route. This route is then included in the packet header, with the route followed in a
hop-by-hop manner as in all source routing techniques.
Through the use of simulation, we have shown that the
global average delay of routing a packet between any two
nodes in DSR-GPS is always less than the global average
delay of a simplified DSR, a source routing protocol for
ad hoc networks, for varied network speeds. The reduced
delay occurs since the overhead associated with the route
discovery, implemented by flooding the network with a
route request, followed by a route reply that follows the
discovered path in reverse, is eliminated. The success rate
of routing is also higher in DSR-GPS than in DSR since
the likelihood that the source route discovered is usable is
reduced by the delay of the route discovery process itself
and node mobility.

3 04

Our solution more bandwidth and energy efficient since
in DSR-GPS we disseminate very small, constant size location packets compared to control packets bearing variable length source routes in DSR. When compared to location based routing methods, DSR-GPS is also more bandwidth and energy efficient since a data packet is sent along
a single route instead of to all the nodes in the direction
of the destination.
Finally, variations and optimizations of the basic DSRGPS protocol can be studied t o further improve its performance in case of route failure due to node movement.
Here, we can apply techniques similar to those found in reactive approaches, namely, route caching, route recomputation at intermediate nodes, and route repair-all done
as local computations. The resulting protocol should be
compared to to DSR with similar enhancements.

REFERENCES
S. Basagni, I. Chlamtac,V. R. Syrotiuk, and B. A. Woodward,
“A distance routing effect algorithm for mobility (DREAM),”
in Proceedings of the Fourth Annual A C M / I E E E International Conference on Mobile Computing and Networking, MobiCom’98, (Dallas, T X ) , pp. 76-84, October 25-30, 1998.
S. Basagni, I. Chlamtac, and V. R. Syrotiuk, “Geographic messaging in wireless ad hoc networks,” in Proceedings of the IEEE
49th Annual International Vehicular Technology Conference,
(Houston, T X ) , May 16-20’1999.
R. C. Dixon and D. A. P i t t , “Addressing, bridging, and source
routing,” in I E E E Network.2, no.1, pp. 25-32, January 1988.
D. Johnson and D. A. Maltz, “Dynamic source routing in ad
hoc wireless networks,” in Mobile Computing (T. Imielinski
and H. F. Korth, eds.), ch. 5, pp. 153-181, Dordrecht, T h e
Netherlands: Kluwer Academic Publishers, February 1996.
KO,Y.-B., and N. H. Vaidya, “Location-aidedrouting (LAR) in
mobile ad hoc networks.” In Proceedings of the Fourth Annual

A CM/IEEE International Conference on Mobile Computing
and Networking (Dallas, T X , October 25-30 1998), pp. 66-75.
R. Perlman, “Interconnections: bridges and routers,” AddisonWesley, Reading, Massachusetts, 1992.

305

2016
2016
IEEE
IEEE
Ninth
International
International
Conference
Conference
on Software
on Software
Testing,
Testing,
Verification
Verification
andand
Validation
Validation
Workshops
Workshops

Coverage, Location, Detection, and Measurement
(Invited Paper)
Charles J. Colbourn and Violet R. Syrotiuk
School of Computing, Informatics, and Decision Systems Engineering
Arizona State University
Tempe, Arizona 85287-8809
Email: {colbourn,syrotiuk}@asu.edu

Abstract—Complex engineered systems arise throughout computing, communications, and networking. Many factors, each
having a ﬁnite number of levels, impact the behaviour of the
system either singly or in interaction with one another. Testing or
evaluating such a system involves formulating a set of tests; when
executed, responses or outcomes from the tests are analyzed. A
single round of testing is conducted.
To witness the effect of an interaction, some test must cover
it; this does not sufﬁce in general to locate the interaction or
to measure its effect. When there are few factors or many
tests, experimental designs can measure (and hence locate) the
interactions. When there are many factors and few tests, can
we locate the interaction(s)? Can we efﬁciently detect them?
Combinatorial arrays, locating and detecting arrays, are introduced to address such location and detection in the context of
combinatorial testing.
Locating and detecting arrays are contrasted with covering
arrays and with experimental designs. An application to a 75
factor protocol stack for ﬁle transfer is given to demonstrate their
practical use. Finally, their place in the literature of combinatorial
testing is discussed and some directions are outlined.

size, can be set to a large number of possible levels; in such
cases a small representative set of admissible levels is selected.
(It can be challenging to ensure that the levels selected are
indeed representative, but we do not address that here.) Levels
for some factors (such as node speed) occur in a numerical
sequence, while for others (such as signal propagation) there
is no natural ordering on the levels. In the scenario outlined,
twenty-eight factors have 2 levels each; nine have 3; six have
4; three have 5; ten have 6; ﬁve have 7; four have 8; one has
9; and eight have 10.
A test for the system is the speciﬁcation of an admissible
level for each of the 75 factors; when executed, a response
is produced. A response may be a numerical value such as a
measure or throughput or delay, or it may be a binary pass/fail
response to indicate acceptable/unacceptable behaviour. This
may involve, for example, ensuring that no execution time
errors occur; or may require that throughput meet some
prespeciﬁed threshold. An experiment to evaluate the system
consists of the design of a set of tests (a test suite), the
execution of these tests to determine responses, and an analysis
of the responses.
To unify the treatment, when responses are pass/fail, we
can classify a ‘fail’ response as signiﬁcant; when responses
are numerical, we can classify a response as signiﬁcant when
it is signiﬁcantly different from the mean. Four natural goals
of experimentation arise:
1) Determine whether or not there exists a cause for a
signiﬁcant response.
2) Uniquely identify the causes of signiﬁcant responses.
3) Efﬁciently ﬁnd the causes of signiﬁcant responses.
4) Measure the effects of causes on the responses.
This leads in turn to the question: What can cause a signiﬁcant response? We suppose that the causes relate to the levels
chosen for the factors identiﬁed; the ﬁle transfer system has
339 (factor,level) choices. Yet system operation depends not
only on the levels of the factors chosen, but also on interactions
among them (see [2], for example). In the absence of further
information, interactions of any number of choices may result
in a signiﬁcant response, so each of the four tasks appears to
require that all interactions be examined. In the ﬁle transfer
system, however, there are more than 1043 interactions, and
such exhaustive testing is evidently infeasible.
Signiﬁcant responses have been found to result from interactions of relatively few factors; for example in software testing,

I. I NTRODUCTION
Complex engineered systems arise throughout computing,
communications, and networking. We recall a scenario discussed in [1] in order to develop the questions that we address.
Reliable ﬁle transfer in a wireless network can be supported
by a suite of existing protocols. The File Transfer Protocol
(FTP) employs the Transport Control Protocol (TCP) at the
transport layer, which in turn employs the Internet Protocol
(IP) at the network layer. IP requires a routing protocol,
for which one can use the Ad Hoc On-Demand Distance
Vector (AODV) protocol. These protocols are supported by
a physical communication medium, in this case speciﬁed by
IEEE 802.11b direct sequence spread spectrum (DSSS). Once
all of these selections are made, determining whether the
resulting protocol stack operates as expected, and optimizing
its performance, are natural goals.
Assessing the operation of this protocol stack necessitates
specifying an environment in which it operates. This is more
easily done in simulation than in a physical system, so we
specify an environment using the Network Simulator ns-2,
which provides mobility, energy, error, and propagation models.
Despite being a substantial simpliﬁcation, the entire system
(the protocol stack and the environmental models) has 75
factors that can be controlled. Some factors, such as packet
978-1-5090-3674-5/16
/16
$31.00 © 2016 IEEE
$31.00 © 2016 IEEE
DOI 10.1109/ICSTW.2016.38

19

examining interactions of six or fewer choices has proved
effective [3]; more generally, the statistical design and analysis
of experiments relies on a sparsity of effects assumption [4]
that the response is determined by interactions among small
sets of choices. In the ﬁle transfer system, there are 57,759
interactions of two choices, and 6,365,469 interactions of three
choices.
One might therefore hope to address our questions when
causes involve a small number of (factor,level) choices. Of
course one could argue that most of the interactions that
remain could be eliminated from consideration by a careful
examination of the system; indeed it may happen that levels
of factors, or factors themselves, can be seen to be inconsequential and hence removed. In our view, this is putting the
cart before the horse. It is not reasonable to expect someone
to know what are not the causes in order to ﬁnd the causes!

tests, while modelling interactions of two choices necessitates
more than 50,000.
In statistical design of experiments, two routes are popular
to deal with this explosion in the number of tests. Supersaturated designs [9] focus on single (factor,level) options
(“main effects”) and employ a number of tests that is in
general insufﬁcient to estimate all main effects; under the
assumption that at most some fraction of the main effects cause
a signiﬁcant response, fewer tests can be required. Supersaturated designs do not address the impact of interactions, and
hence are most useful whenever any interactions impacting
response signiﬁcantly involves main effects that also impact
the response. In our applications, we view the assumption that
interactions are reﬂected in the main effects as suspect.
A second popular route treats interactions, but abandons
the effort to treat them independently. D-Optimal designs (see
[4]) attempt, within a speciﬁed number of tests, to make the
effects of the possible interactions as independent as possible
by maximizing a determinant-based measure. In a sense, they
thereby strive to make the tests as representative as possible
of the space of all possible tests within the constraint on the
number of tests. Although D-optimal designs explicitly address
interactions, the criterion for optimality does not ensure even
coverage of the interactions. In [10], [11], it is shown that
adding a coverage criterion in constructing a D-optimal design,
one can ensure that signiﬁcant interactions are not totally
missed in testing.
Neither supersaturated designs nor D-optimal designs ensure that even a single interaction causing a signiﬁcant response can be determined; yet the alternative of providing
sufﬁcient tests to build a complete linear model is unattractive.

A. Coverage
To see the result of an interaction that may cause a signiﬁcant response, some test must include it. Indeed when the
presence of a speciﬁc interaction in a test ensures a signiﬁcant
response, our ﬁrst task simply asks that each interaction of
interest appear in at least one test. This is the province of
combinatorial testing [3], [5]–[7]. Ten tests sufﬁce to cover
all 339 individual choices in the ﬁle transfer system, while
149 sufﬁce to cover all 57,759 interactions of two choices.
(The latter was found using a post-optimization strategy [8].)
This provides an economical means to determine whether
the system has any interaction of two choices resulting in a
signiﬁcant response.
Although the presence of causes of signiﬁcant responses can
be observed, the interactions themselves forming the causes
remain unknown in general. However, typically one wants to
know the causes, not simply know that some are present. How
can one ﬁnd the causes?

C. The Issue at Hand
Coverage does not sufﬁce to ﬁnd the causes of signiﬁcant
responses, but merely to indicate their presence or absence.
To be clear, combinatorial test suites have been used for fault
characterization, for example in [12], to ﬁnd a subspace in
which the faults must reside, but here we ask for a complete
identiﬁcation of the fault(s) without further testing. Measurement sufﬁces to characterize causes of signiﬁcant responses,
but at an unacceptably large cost in our application. Hence the
issue at hand is whether we can effectively answer the second
and third questions posed earlier: From the responses, can we
ﬁnd the causes of signiﬁcant response? And can we ﬁnd them
efﬁciently?
In Section II we develop a combinatorial framework for
addressing these questions. Then in Section III we return to
the ﬁle transfer system to examine the application of this
framework, and examine a further application to data from a
network testbed. In Section IV we discuss the relation between
location and test suite diversity. Finally in Section V we pose
some questions for the combinatorial testing community.

B. Measurement
In order to locate the causes of signiﬁcant responses,
one could attempt to determine the effect of each relevant
interaction on the response. The usual setting here is for
numerical responses; a system model is developed that is a
function of the chosen options. (See [4].) In a linear model,
the response is characterized as a linear function of the options.
The coefﬁcients in the linear model measure the importance
of the interaction to the response, and hence interactions that
cause a signiﬁcant change in response can be determined.
Knowing the mean response, the effect of one value of a
factor can be determined from the effects of the remaining
values of the same factor. But when a factor has s values,
the complete determination of a linear model requires that the
measurement of interactions for s − 1 levels of a factor with s
levels be independent of every other (more precisely, that they
be linearly independent). Consequently the number of tests to
be conducted can be no smaller than the number of interactions
whose effect is to be measured. In the ﬁle transfer system, even
modelling the effects of single options necessitates at least 265

II. L OCATING AND D ETECTING A RRAYS
In order to introduce test suites for determining causes
of signiﬁcant responses, we develop a formal combinatorial

20

TABLE I
C OVERING ARRAYS
Array
Covering Arrays:
MCA(N ; t, k, (s1 , . . . , sk ))
CA(N ; t, k, v)

Deﬁnition
ρA (T ) = ∅ for all T ∈ It
ρA (T ) = ∅ for all T ∈ It and v = s1 = · · · = sk

framework, following [13]. For this purpose, we adopt the
simpler terminology of pass/fail responses for tests. There are
k factors F1 , . . . , Fk . Each factor Fi has a set of si possible
values (levels) Si = {vi1 , . . . , visi }. A test is an assignment of
a level from Si to Fi for each i with 1 ≤ i ≤ k. A test, when
executed, can pass or fail. For any t-subset I ⊆ {1, . . . , k}
and levels σi ∈ Si for i ∈ I, the set {(i, σi ) : i ∈ I} is
a t-way interaction, or an interaction
  of strength t. Thus a
test on k factors contains (covers) kt interactions of strength
t. A test suite is a collection of tests; the outcomes are the
corresponding set of pass/fail results. A fault is evidenced
by a failure outcome for a test, the result of one or more
faulty interactions covered in the test. Tests are executed
without reference to responses of other tests, so that testing is
nonadaptive.
We employ a matrix representation. An array A with N
rows, k columns, and symbols in the ith column chosen from
an alphabet Si of size si is denoted as an N × k array of
symbol type (s1 , . . . , sk ). A t-way interaction in A is a choice
of a set I of t columns, and the selection of a level σi ∈ Si
for i ∈ I, represented as T = {(i, σi ) : i ∈ I}. For such
an array A = (axy ) and interaction T , deﬁne ρA (T ) = {r :
ari = σi for each i ∈ I}, the set of rows of A in which the
interaction
is covered. For a set of interactions T , ρA (T ) =

ρ
(T
).
A
T ∈T
Let It be the set of all t-way interactions for an array
of symbol type (s1 , . . . , sk ), and let It be the set of all
interactions of strength at most t. Consider an interaction
T ∈ It of strength less than t. Any interaction T  of strength
t that contains T necessarily has ρA (T  ) ⊆ ρA (T ); a subset
T  of interactions in It is independent if there do not exist
T, T  ∈ T  with T ⊂ T  .
An array A is a covering array for a set T of interactions
when, for every T ∈ T , we have ρA (T ) = ∅; see Table I.
It is a mixed covering array when factors may have different
numbers of levels, and uniform when all factors have the same
number.

TABLE II
C OVERING ARRAY AND RESPONSES .

Tests

1
2
3
4
5
6

1
0
1
0
1
0
1

2
1
0
1
0
0
1

Factors
3 4
1
1
1
0
0
0
0
1
0
0
0
1

5
1
0
0
1
1
0

Response
Fail
Pass
Fail
Pass
Pass
Pass

run is not faulty. Similarly, for factors 2, 3, 4, and 5 set to
zero, one, zero, and zero, respectively. This is indicated by a
check-mark (). Repeating for each one-way interaction for
each successful test, no single (factor, level) error accounts for
the faults; see Table III(b).
TABLE III
L OCATING FAULTS DUE TO MAIN EFFECTS .
(a) Test 2
Factors
0
1
1

2

3

4

5


(b) All
Factors
1
2
3
4
5

Tests
0






1






TABLE IV
L OCATING FAULTS DUE TO 2- WAY INTERACTIONS .
Factors
1, 2
1, 3
1, 4
1, 5
2, 3
2, 4
2, 5
3, 4
3, 5
4, 5

A. Coverage is not enough

(a) Test 2
00 01
10














11


Factors
1, 2
1, 3
1, 4
1, 5
2, 3
2, 4
2, 5
3, 4
3, 5
4, 5

(b) All Tests
00 01

















10










11








Therefore, to explain the responses we turn to 2-way interactions. Because the second test passes, all 2-way interactions in
it are known not to be faulty; Table IV(a) records the results.
Repeating for each 2-way interaction in a test that passes,
those interactions not found to pass in this way in Table IV(b)
form a set of candidate faults. In this example, there are
nine interactions in the set of candidate faults. The 2-way
interaction {(1, 0), (2, 1)} has ρ({(1, 0), (2, 1)}) = {1, 3}, and
it is the only 2-way interaction for which this holds. Hence if

To illustrate the need for further requirements, we employ an
example from [1]. For the CA(6;2,5,2) in Table II, a response
for each test is listed in the adjacent column.
Can we explain these responses? First, we try to locate faults
due to main effects (i.e., the individual factors or one-way
interactions). The second test passes, so all (factor, level) pairs
in it are known not to be faulty. Therefore in Table III(a), that
considers only the second test, when factor 1 is set to one, the

21

TABLE V
A RRAYS FOR DETERMINING FAULTS
Array
Locating Arrays:
(d, t)-LA(N ; k, (s1 , . . . , sk ))
(d, t)-LA(N ; k, (s1 , . . . , sk ))
(d, t)-LA(N ; k, (s1 , . . . , sk ))
(d, t)-LA(N ; k, (s1 , . . . , sk ))
Detecting Arrays:
(d, t)-DA(N ; k, (s1 , . . . , sk ))
(d, t)-DA(N ; k, (s1 , . . . , sk ))

Deﬁnition
ρA (T1 ) = ρA (T2 ) ⇔ T1 = T2 whenever T1 , T2
and |T2 | = d
ρA (T1 ) = ρA (T2 ) ⇔ T1 = T2 whenever T1 , T2
and |T2 | ≤ d
ρA (T1 ) = ρA (T2 ) ⇔ T1 = T2 whenever T1 , T2
|T2 | = d, and T1 and T2 are independent
ρA (T1 ) = ρA (T2 ) ⇔ T1 = T2 whenever T1 , T2
|T2 | ≤ d, and T1 and T2 are independent

⊆ It , |T1 | = d,
⊆ It , |T1 | ≤ d,
⊆ It , |T1 | = d,
⊆ It , |T1 | ≤ d,

ρA (T ) ⊆ ρA (T ) ⇔ T ∈ T whenever T ∈ It , T ⊆ It , and
|T | ≤ d
ρA (T ) ⊆ ρA (T ) ⇔ T ∈ T whenever T ∈ It , T ⊆ It , |T | ≤ d,
and T ∪ {T } is independent

there is a single fault, it must be {(1, 0), (2, 1)}, and we have
located the fault.
Our success for one response is not sufﬁcient, however.
Because ρ({(1, 0), (2, 1)}) = {1} = ρ({(2, 1), (3, 1)}), if only
run 1 fails, there are at least two equally plausible explanations
using only a single two-way interaction. Thus the ability to
locate is more than simply coverage!

numbers of levels, deﬁned in Table V. When all factors have
the same number of levels v, we replace (s1 , . . . , sk ) with v
in the notation.
Using a locating array A ensures that there is at most one T
for which ρA (T ) is a speciﬁed set of failed tests, assuming that
the permitted number of interactions each having the permitted
strength are faulty. How does one recover T from ρA (T )? A
simple heuristic is to observe that every interaction appearing
in a test that passes cannot be faulty. Although many (typically
most) interactions are determined not to cause faults in this
way, it may nevertheless happen that the effect of an interaction T remains undetected in the presence of a set T of faulty
interactions. This happens precisely when ρA (T ) ⊆ ρA (T )
but T ∈ T . Unfortunately, determining whether or not this
occurs is NP-hard [14]. However, using detecting arrays, faulty
interactions can be found by simply listing all interactions that
appear only within failed tests. Hence they ensure efﬁcient
determination of faulty interactions.

B. Locating and detecting
Although interactions are believed to cause faults, the speciﬁc interactions causing faults are not known. First suppose
that faults, if present, are caused by interactions of strength at
most t (a sparsity of effects assumption). Even when interactions causing faults are independent, it may not be possible to
uniquely determine T given ρA (T ). For example, if factor f
has levels v1 , . . . , vs and each of {(f, vi ) : 1 ≤ i ≤ s} causes
a fault, then all tests fail, and there is no way to determine
which interactions cause faults. Moreover, there are
t


τ =1+
[
sij − 1]

We argue that locating and detecting arrays properly belong
to combinatorial testing. Indeed they are covering arrays, but
they provide information about the location of faults, not just
their presence. Despite their fault location capability, as for
covering arrays the number of tests grows logarithmically in
the number of factors when the strength and the maximum
number of levels are ﬁxed; for locating and detecting arrays,
one needs to assume in addition that the number of faulty
interactions is ﬁxed to obtain the logarithmic growth [13]. One
might therefore expect that they have been extensively studied,
in the same way as covering arrays.

0<i1 <···<it <k j=1

mutually independent t-way interactions. If any set of t-way
interactions can be the causes of the faults, one would need
to distinguish among all 2τ possible sets, requiring at least τ
tests. In this case, we encounter again the need for a number of
tests linearly related to the number of interactions, as we found
for measurement earlier. At ﬁrst, this suggests that a substantial
reduction in the number of tests requires one to abandon the
determination of the interactions causing faults. If we suppose,
however, that d interactions cause faults and want
  to determine
which, then we need only distinguish among τd sets, not 2τ .
To formulate arrays for testing, we therefore assume limits
on both the number of interactions causing faults and their
strengths. Of course, we must presume not just the sparsity of
effects to limit the strengths of interactions considered, but also
sparsity in the number of interactions that yield a signiﬁcant
response.
As in [13], this leads to a variety of arrays A for testing a
system with N tests and k factors having (s1 , . . . , sk ) as the

Despite this expectation, the literature on detecting and
locating arrays is in its beginning stages. Martı́nez et al. [15]
develop adaptive analogues and establish feasibility conditions
for a locating array to exist. In [16] and [17] the minimum
number of rows in a locating array is determined when the
number of factors is quite small. In [18] the minimum number
of rows for (1, 1)-, (1, 1)-, (1, 1)-, and (1, 1)-locating arrays is
determined precisely when all factors have the same number of
levels. In [19], [20] partial results are given for (1, 1)-detecting

22

arrays (there called “Sperner partition systems”). In [13] a
construction for locating arrays from higher strength covering
arrays is provided. in [21] three recursive constructions for
locating arrays of strength two are developed, patterned on
recursive constructions for covering arrays.
It can safely be said that at the present time, producing a
locating or detecting array with few tests for a speciﬁc set
of parameters is challenging. In the ﬁle transfer application,
for example, a (1,2)-locating array for the 75 factors was
produced having 421 tests. We have seen that a covering
array for this system exists with 149 tests, but it does not
support location even for a single 2-way interaction. The
construction method used in [1] resorts to combining tests
from three different covering arrays of strength two, obtained
by randomly permuting both symbols and columns in a single
covering array. In this way, every 2-way interaction is covered
by at least three tests. Despite this, the resulting array fails to
distinguish a small number of 2-way interactions, and three
tests were added manually to form a locating array. In the
result, tests were eliminated when their removal did not result
in a 2-way interaction being covered fewer than three times
or in two 2-way interactions being indistinguishable. Thus
a locating array with 421 tests was crafted from tools for
covering arrays, using simple heuristics. This is, of course,
not what is needed in general; it poses a challenge to extend
tools for combinatorial testing to support location of a small
number of interactions of interest.

environment employed has random variation injected, and
there is no guarantee that all factors affecting the response
can be controlled. Then what accounts for the success in
building a suitable screening model? In part, the explanation
is that the ﬁle transfer application, despite having a number
of signiﬁcant interactions, does exhibit a substantial numerical
variation in their effects. However, we also crafted the locating
array to avoid confusing the effect of one interaction with that
of another. As mentioned, we ensured that each interaction
is covered in at least three tests; this mitigates the effect
of random noise to an extent. Nevertheless, noise remains a
possible concern.
Suppose that for two interactions T1 and T2 , ρA (T1 ) \
ρA (T2 ) contains exactly one test. Then substantial noise on
this single test could result in the inability to witness the difference of effects between the two interactions. Consequently,
although the deﬁnition of (1,2)-locating arrays requires only
that ρA (T1 ) and ρA (T2 ) be different, effects of noise can be
further mitigated by increasing (insofar as is possible) the
size of the symmetric difference between ρA (T1 ) and ρA (T2 ).
In plain terms, this asks that the sets of rows containing
different interactions be as different as possible. A further
part of the explanation for the locating array’s success in the
ﬁle transfer application is that among the many (1,2)-locating
arrays generated, we chose one for which the symmetric
differences are the largest.
A number of objections could be raised. Perhaps we were
just lucky in the choice of locating array to use. To address
this, a second (1,2)-locating array was constructed by the
same method, and the analysis repeated. In [1], substantial
agreement is found in the results; in particular, the incremental selection of signiﬁcant interactions again succeeded.
Perhaps a randomly chosen array with 421 tests would provide
comparable results. Although true, a randomly chosen array
on 421 tests is expected to fail even to cover about 74
interactions. This is a small fraction of all interactions, but
the consequences of failure to cover one signiﬁcant interaction
are severe. Furthermore, even if we have the good fortune to
select a covering array at random, distinguishing interactions
may be impossible. Perhaps a design to measure just the main
effects would provide a better model. In the model produced
in [1], four of the twelve most signiﬁcant terms correspond to
2-way interactions; none would be guaranteed to be seen in a
main effects model.
A further objection appears to be the most telling: Perhaps
the ﬁle transfer application itself is a toy example, despite
having many factors and levels. The system is modelled in a
simulator. Despite efforts to improve the ﬁdelity of the simulation, effects could be artifacts of the simulation environment.
More recently in [22] we have employed a wireless testbed
environment, examining the effects of 24 operating system and
communication parameters on an application to transmit voice.
Two quite different responses, mean opinion score for the
voice quality and radiation exposure, were measured. Although
the system is smaller in terms of number of factors, responses
in this system are measured physical responses, not simulated

III. A PPLICATIONS
Now we return to the ﬁle transfer application. Surely more
than one main effect or 2-way interaction has a signiﬁcant
effect on the response. Yet we have developed a (1,2)-locating
array for experimental evaluation. How can this make sense?
We have ensured coverage of relevant interactions, so the
evidence of their impact should be present in the responses.
But here we have more information, because the responses are
not pass/fail, but are instead numerical. Thus two interactions,
both signiﬁcant, can differ numerically in their effects on
the response. If one has a signiﬁcantly larger effect on the
response than does the other, we can locate the ﬁrst and
estimate its effect on the response. Then without running a new
experiment, we can adjust the responses to remove the effect
of the interaction identiﬁed. This provides a new (residual)
set of responses with which to identify a further interaction.
In this way, we repeatedly choose an interaction whose effect
on the responses is most signiﬁcant, and remove its (estimated)
effect, until no more signiﬁcant interactions are present. This
is a strategy sometimes called a “heavy hitters” approach; by
adjusting the determination of signiﬁcance of responses, one
can incrementally ﬁnd many signiﬁcant interactions.
The details of the approach appear in [1], so we do not
repeat them here. Despite the small number of tests for
an experiment with many factors and levels, the method
enables the construction of a useful screening model that is
validated by a statistically design experiment on the subset
of the factors identiﬁed by screening. Even the simulation

23

interaction that is covered more than once appears to reduce τ diversity for τ > t. Conversely, increasing τ -diversity appears
to serve as a useful surrogate for enhancing the combinatorial
ability to locate.
While diversity focusses on making tests as different as
possible, locating arrays focus on distinguishing among the
sets of tests in which interactions appear. The relationship
between these two related but different objectives merits study.

ones. As in the earlier study, a (1,2)-locating array was
generated, this time having 109 tests. Each test run requires
initialization of 40 receiver nodes in the testbed, a warm-up
phase, and a data collection phase; and during the experiment,
the testbed is fully allocated and unavailable for other uses.
Hence keeping the number of tests to a minimum is mandatory.
Locating arrays again succeed in building a suitable screening
model, validated through a subsequent experiment on the same
testbed.
We do not claim that either experiment proves that locating arrays always succeed, even when all interactions of
signiﬁcance involve few factors. They do, however, indicate
that locating arrays can serve to determine speciﬁc signiﬁcant
interactions, and that when responses are numerical an iterative
strategy can succeed in ﬁnding many interactions one at a time.

V. N EXT STEPS
Our primary objective is to pose questions for the research
community in combinatorial testing. We have shown that,
beyond just certifying the presence or absence of faults, a
combinatorial framework exists for locating and detecting
faults nonadaptively. Moreover, the ability to locate even a
single signiﬁcant interaction can be used incrementally to ﬁnd
many. We have also seen that, although locating interactions
certainly involves coverage and appears to involve diversity,
the construction of locating and detecting arrays is in its
infancy. To conclude we therefore consider possible next steps.
Naturally we expect that the practical concerns in the
construction of covering arrays, particularly constraints, must
be addressed for location and detection as well. But we focus
on the basic scenario here.

IV. D IVERSITY
We have seen that in order to locate signiﬁcant interactions,
it is not sufﬁcient to cover them (although it is necessary). The
sets of tests in which interactions are covered must be different
in order to distinguish the effects of the interactions. This
objective does not appear to have been addressed explicitly
in the combinatorial testing methods for software. However,
we believe that it relates closely to objectives that have been
extensively studied. We discuss the connections next.
A covering array for a speciﬁed strength t may fail to cover
all τ -way interactions for τ > t. Consequently, Dalal and
Mallows [23] suggest employing test suites with high diversity.
The τ -diversity of an N × k array is the ratio of the number
of (distinct) τ -way interactions that are covered to
 the total
number of τ -way interactions covered in tests, N τk . Larger
τ -diversity can result from reducing the number of tests, or
by covering as many τ -way interactions as possible in the
available number of tests. Increasing the τ -diversity improves
the cost-effectiveness of covering interactions.
Chen et al. [24] discuss the connection between “adaptive
random testing” and diversity. They argue that this and related
measures of diversity enhance the ability to ﬁnd faults, and that
such test suites can be effectively generated using a one-testat-a-time strategy making decisions based on test distances.
Hartman and Raskin [25] suggest ensuring coverage of t-way
interactions, while maximizing τ -diversity for τ > t. These
observations are borne out in [26], where the rate of fault
detection (in a simpliﬁed abstract model) is shown to improve
with higher diversity.
Large diversity still targets determining the presence of
faults, not identiﬁcation of speciﬁc faults. Nevertheless, locating arrays indirectly address diversity. To see this, consider two t-way interactions T1 = {(fi1 , νi1 ), · · · (fit , νit )}
and T2 = {(fj1 , vj1 ), · · · (fjt , vjt )}. They are consistent if
whenever ia = jb , we have νia = vjb (i.e., they can appear
together in a test). When consistent, T = T1 ∪ T2 is a τ -way
interaction for t < τ ≤ 2t. Now suppose that ρ(T1 ) = ρ(T2 ),
so that the array is not (1, t)-locating. Then ρ(T1 ) = ρ(T ).
It follows that among the τ -way interactions consistent with
T1 , only one is covered. Hence, inability to locate a t-way

A. One-test-at-a-time methods
For covering arrays, AETG [27] popularized techniques that
add one test at a time, greedily selecting a test to (attempt
to) maximize the number of newly covered interactions; such
methods can lead to a number of tests that is logarithmic in
the number of factors [28]. The adaptation of such methods to
locating arrays appears to be promising, because once two
interactions appear in different rows in a partial array, no
additional row can change this fact. Nevertheless, a greedy selection must now be concerned with both covering uncovered
interactions and with ensuring that interactions are covered in
different sets of tests. Effective ways to combine these two
objectives are needed.
B. One-factor-at-a-time methods
For large systems, one-test-at-a-time methods involve tracking a very large number of interactions. For this reason, onefactor-at-a-time methods have been widely used. IPO [29]
introduced such methods, which form the basis of the ACTS
system (see [3]). Again here, vertical and horizontal growth
would need to address coverage in differing sets of tests. The
issue is (perhaps) complicated by the introduction of new
interactions as new factors are added; if information about
the tests in which all interactions appear must be maintained,
then the storage advantage over the one-test-at-a-time method
disappears. Can this be overcome?
C. Post-optimization
In [8] a technique is developed for reducing the number of
tests in an existing covering array by exploiting redundancy in
the coverage. A naive application of this approach to locating

24

arrays results in failure to distinguish sets of tests in which
interactions appear, and hence the post-optimization method as
it stands is ineffective for locating arrays. Nevertheless local
modiﬁcations of a locating array can sometimes be made so
as to ensure that a test becomes unnecessary. What is needed
is not only a strategy for ﬁnding such modiﬁcations, but also
a demonstration that they work in practice (if indeed they do).

[6] A. Hartman, “Software and hardware testing using combinatorial covering suites,” in Interdisciplinary Applications of Graph Theory, Combinatorics, and Algorithms, M. C. Golumbic and I. B.-A. Hartman, Eds.
Norwell, MA: Springer, 2005, pp. 237–266.
[7] C. Nie and H. Leung, “A survey of combinatorial testing,” ACM
Computing Surveys, vol. 43, no. 2, p. #11, 2011.
[8] P. Nayeri, C. J. Colbourn, and G. Konjevod, “Randomized postoptimization of covering arrays,” European Journal of Combinatorics, vol. 34,
pp. 91–103, 2013.
[9] C.-S. Cheng and B. Tang, “Upper bounds on the number of columns
in supersaturated designs,” Biometrika, vol. 88, no. 4, pp. 1169–1174,
2001.
[10] D. S. Hoskins, C. J. Colbourn, and D. C. Montgomery, “D-optimal
designs with interaction coverage,” Journal of Statistical Theory and
Practice, vol. 3, pp. 817–830, 2009.
[11] D. S. Hoskins, C. J. Colbourn, and M. Kulahci, “Sub D-optimal designs
for screening experiments,” Amer. J. Math. Manag. Sci., vol. 28, pp.
359–383, 2008.
[12] C. Yilmaz, M. B. Cohen, and A. Porter, “Covering arrays for efﬁcient
fault characterization in complex conﬁguration spaces,” IEEE Transactions on Software Engineering, vol. 31, pp. 20–34, 2006.
[13] C. J. Colbourn and D. W. McClary, “Locating and detecting arrays for
interaction faults,” Journal of Combinatorial Optimization, vol. 15, pp.
17–48, 2008.
[14] B. K. Natarajan, “Sparse approximate solutions to linear systems,” SIAM
J. Comput., vol. 24, pp. 227–234, 1995.
[15] C. Martı́nez, L. Moura, D. Panario, and B. Stevens, “Locating errors
using ELAs, covering arrays, and adaptive testing algorithms,” SIAM J.
Discrete Math., vol. 23, pp. 1776–1799, 2009/10.
[16] C. Shi, Y. Tang, and J. Yin, “Optimal locating arrays for at most two
faults,” Sci. China Math., vol. 55, no. 1, pp. 197–206, 2012.
[17] Y. Tang, C. J. Colbourn, and J. Yin, “Optimality and constructions of
locating arrays,” J. Stat. Theory Pract., vol. 6, no. 1, pp. 20–29, 2012.
[18] C. J. Colbourn, B. Fan, and D. Horsley, “Disjoint spread systems and
fault location,” submitted, 2016.
[19] K. Meagher, L. Moura, and B. Stevens, “A Sperner-type theorem for
set-partition systems,” Electron. J. Combin., vol. 12, pp. Note 20, 6 pp.
(electronic), 2005.
[20] P. C. Li and K. Meagher, “Sperner partition systems,” J. Combin. Des.,
vol. 21, no. 7, pp. 267–279, 2013.
[21] C. J. Colbourn and B. Fan, “Locating one pairwise interaction: Three
recursive constructions,” J. Algebra Combinatorics Discrete Structures
and Applications, 2016.
[22] R. Compton, M. T. Mehari, C. J. Colbourn, E. De Poorter, and V. R.
Syrotiuk, “Screening interacting factors in a wireless network testbed
using locating arrays,” in IEEE INFOCOM International Workshop
on Computer and Networking Experimental Research Using Testbeds
(CNERT), 2016.
[23] S. R. Dalal and C. L. Mallows, “Factor-covering designs for testing
software,” Technometrics, vol. 40, pp. 234–243, 1998.
[24] T. Y. Chen, F.-C. Kuo, R. G. Merkel, and T. Tse, “Adaptive random
testing: The art of test case diversity,” Journal of Systems and Software,
vol. 83, no. 1, pp. 60–66, 2010.
[25] A. Hartman and L. Raskin, “Problems and algorithms for covering
arrays,” Discrete Math., vol. 284, pp. 149–156, 2004.
[26] C. Nie, H. Wu, X. Niu, F. Kuo, H. K. N. Leung, and C. J. Colbourn,
“Combinatorial testing, random testing, and adaptive random testing
for detecting interaction triggered failures,” Information & Software
Technology, vol. 62, pp. 198–213, 2015.
[27] D. M. Cohen, S. R. Dalal, M. L. Fredman, and G. C. Patton, “The AETG
system: An approach to testing based on combinatorial design,” IEEE
Transactions on Software Engineering, vol. 23, pp. 437–44, 1997.
[28] R. C. Bryce and C. J. Colbourn, “A density-based greedy algorithm
for higher strength covering arrays,” Software Testing, Veriﬁcation, and
Reliability, vol. 19, pp. 37–53, 2009.
[29] K. C. Tai and L. Yu, “A test generation strategy for pairwise testing,”
IEEE Transactions on Software Engineering, vol. 28, pp. 109–111, 2002.
[30] J. Torres-Jimenez and E. Rodriguez-Tello, “New upper bounds for binary
covering arrays using simulated annealing,” Information Sciences, vol.
185, no. 1, pp. 137–152, 2012.

D. Metaheuristic search
When more extensive computation is possible, metaheuristic
search techniques such as simulated annealing (for example,
[30]) have proved to be very effective for covering arrays.
Their adaptation for locating and detecting arrays appears to be
relatively straightforward; the primary issue is how to measure
the proximity of an array to the locating array desired, because
the array may fail for lack of coverage, or because of the
inability to distinguish interactions. We expect that simulated
annealing can address these concerns well.
E. Experimental design
We expect that locating and detecting arrays can serve
as a bridge between combinatorial testing and the statistical
design of experiments. The measurement of an interaction
depends upon how it is confounded with other interactions [4],
while observing the effect of the interaction at all depends on
its coverage. Locating and detecting arrays ensure coverage;
they also ensure that no two interactions are completely confounded. Hence they address both combinatorial and statistical
objectives. It appears natural to strengthen this bridge, by
exploiting combinatorial properties of experimental designs in
reﬁning the goals of combinatorial testing.
F. Of things not said
Most readers will have little difﬁculty enumerating many
topics that we could have mentioned but did not. Both theoretical issues in the construction of locating and detecting arrays,
and further practical assessments of their uses (and abuses),
could range in many directions. We have not been exhaustive,
but we hope that the community in combinatorial testing will
ﬁnd productive ideas for future work in the combinatorial
framework for location.
ACKNOWLEDGMENT
This material is based in part upon work supported by the
National Science Foundation under Grant No. 1421058.
R EFERENCES
[1] A. N. Aldaco, C. J. Colbourn, and V. R. Syrotiuk, “Locating arrays: A
new experimental design for screening complex engineered systems,”
SIGOPS Oper. Syst. Rev., vol. 49, no. 1, pp. 31–40, Jan. 2015.
[2] K. Vadde and V. R. Syrotiuk, “Factor interaction on service delivery
in mobile and ad hoc networks,” IEEE Journal on Selected Areas in
Communications, vol. 22, pp. 1335–1346, 2004.
[3] D. R. Kuhn, R. Kacker, and Y. Lei, Introduction to Combinatorial
Testing. CRC Press, 2013.
[4] D. C. Montgomery, Design and Analysis of Experiments, 8th ed. John
Wiley and Sons, Inc., 2012.
[5] M. Grindal, J. Offutt, and S. F. Andler, “Combination testing strategies
– a survey,” Software Testing, Veriﬁcation, and Reliability, vol. 5, pp.
167–199, 2005.

25

Mobile Networks and Applications 7, 493–502, 2002
 2002 Kluwer Academic Publishers. Manufactured in The Netherlands.

An Adaptive Generalized Transmission Protocol for Ad Hoc
Networks
ANDREW D. MYERS, GERGELY V. ZÁRUBA and VIOLET R. SYROTIUK
Department of Computer Science, The University of Texas at Dallas, Richardson, TX 75083, USA

Abstract. Wireless networking and group communication in combination allows groups of dispersed mobile users to collaborate. This paper
presents AGENT, a medium access control (MAC) protocol that unifies point-to-point and multi-point transmission services to facilitate
group communication in ad hoc networks. Analysis and experiments performed in a simulated ad hoc network demonstrate that AGENT
exhibits reliable and stable performance with high spatial bandwidth reuse. Moreover, variation in the proportion of point-to-point and
multi-point traffic is shown to have little impact on the overall performance of AGENT. Comparison with the other tested MAC protocols
reveals that the performance of AGENT is superior, achieving higher channel utilization and lower access delay.
Keywords: medium access control (MAC), mobile ad hoc networks (MANETs), unified unicast/broadcast primitives

1. Introduction
Wireless technology presents users with instantaneous communication and ubiquitous computing capabilities regardless
of their current location. In contrast to a cellular network,
an ad hoc network consists of a group of nodes that collectively form a multi-hop wireless network. Ad hoc nodes directly exchange packets across shared communication channels without the aid of any communications infrastructure.
Due to the limitations of wireless transmission, packet exchanges between distant nodes must be relayed through intermediate nodes in a hop-by-hop fashion. Consequently, an
ad hoc network must display a high level of self-organization
and adapt to fluctuations in network connectivity. These characteristics enable ad hoc networks to support the rapid deployment of temporary communication and information access solutions.
In the most general sense, multi-point (or group) communication involves multiple participants exchanging information. Some examples include the exchange of audio and video
streams during a video conferencing session, and the sharing
of text and graphics in many computer-supported collaborative work (CSCW) applications. Effective group communication allows users to collaboratively interact in natural and
intuitive ways. This type of interaction is essential to many
of the proposed applications of ad hoc networks, such as battlefield coordination and disaster relief [16], that involve the
close cooperation of large numbers of users.
Most recent research efforts have focused on developing
network and transport layer protocols for group communication in ad hoc networks [1,3,7,8]. However, such multi-hop
transmission services ultimately rely on effective, single-hop
packet transmissions that are controlled by the medium access control (MAC) layer. For example, most routing protocols typically require broadcast transmission services to exchange connectivity or location information; multicast transmission services allow a multicast routing protocol to forward

a packet along a tree or mesh; and virtual circuit services and
single source-destination routing is more efficiently supported
by unicast transmission services. In practice, high-layer protocols use a combination of these single-hop services. Thus,
a MAC protocol that effectively supports this suite of singlehop transmission services is required.
This paper introduces AGENT, an adaptive MAC protocol
for ad hoc networks that provides a unified set of effective
single-hop transmission services. AGENT employs a hybrid
design that combines an allocation and contention based protocol. The allocation protocol gives each node guaranteed
access to the channel, providing access delay bounds and preventing instability. The contention protocol allows nodes to
claim idle slots, thus obtaining spatial bandwidth reuse. The
protocol features efficient support for unicast, multicast, and
broadcast packet transmissions, and incorporates prioritized
channel access to ensure cooperation between the allocation
and contention components.
The rest of this paper is organized as follows. Section 2
presents a brief overview of MAC protocols that emphasizes
point-to-point and multi-point transmission service support.
In section 3, we motivate the need for a protocol offering
these services and describe the operation our AGENT protocol. Analysis of AGENT is presented in section 4, where
we examine its performance and reliability. We then evaluate
the performance of AGENT in a simulated ad hoc network
and compare it to other MAC protocols in section 5. Finally,
we summarize our conclusions and outline future research in
section 6.
2. Previous work
The carrier sense multiple access (CSMA) protocol was one
of the earliest contention protocol designs for ad hoc networks
[14]. Developed by Kleinrock and Tobagi, CSMA addresses
the half-duplex nature of wireless communication by having

494

nodes first listen for channel activity before transmitting their
packets. However, CSMA suffers from hidden terminal interference since a node is unable to determine the status of the
channel at its destinations. This leads to more frequent packet
collisions, reducing the performance of the protocol.
To address this problem, Karn introduced a collisionavoidance mechanism involving a request-to-send/clear-tosend (RTS/CTS) control packet exchange between a source
node and its intended destination [10]. Before transmitting its
packet, a source node transmits a RTS expecting a CTS response. If the RTS is successfully received, the destination
responds with a CTS; otherwise it remains silent. Furthermore, each RTS/CTS control packet contains the length of
time needed to transmit the packet. Thus, any node that overhears this handshake refrains from accessing the channel for
the specified duration. Once the CTS is received, the source
node is free to transmit its packet.
Over the years, many variations and combinations of these
two basic techniques have been proposed, including the commercially available IEEE 802.11 standard [17]. However,
many of these contention protocols are subject to instability,
i.e., throughput breakdown, at high traffic loads. Furthermore,
the point-to-point nature of the collision-avoidance mechanism limits its effectiveness in supporting reliable multi-point
transmissions. In practice, multi-point packets are typically
transmitted using CSMA-style channel access, with similar
reception probabilities. This can be made more reliable by
using a “repeated unicast” scheme, i.e., sending a copy of a
packet to each addressed neighbor. However, our analysis and
simulation results demonstrate the inefficiency of such a technique [6].
The time division multiple access (TDMA) protocol was
one of the earliest allocation protocol designs for ad hoc networks. In this case, time is divided into fixed size slots which
are then organized into a synchronous frame. Each node is assigned one unique slot per frame in which it is given exclusive
access to the channel, thus unicast, multicast and broadcast
packets are easily accommodated. The length of a TDMA
frame is proportional to N, where N is the number of nodes
in the network. Shorter frame lengths can be achieved via
more complex slot assignments or dynamic slot assignments.
In [4], Chlamtac and Faragó realized a static frame length
that scaled logarithmically with N and quadratically with the
maximum node degree. In [15], Zhu and Corson dynamically determine the frame length according to the local network topology. A static frame length bounds access delay, yet
transmission concurrency is limited by global network parameters that are typically unknown and time varying. While
dynamic slot assignment schemes can overcome these limitations, the need for a contention protocol to reorganize transmission schedules can lead to instability.
One of the first hybrid MAC protocols was developed by
Sharp, Grindrod, and Camm in [12]. The protocol features
a combination of both TDMA and CSMA channel access
schemes. Each node is permanently assigned a certain number of TDMA slots in which it has priority to access the channel. If a slot is not used by the assigned node, other nodes

A.D. MYERS ET AL.

may attempt channel access at a random instant after the start
of the slot. To alleviate hidden terminal interference, nodes
are not permitted to access time slots allocated to nodes exactly two hops away from them. The main disadvantage of
this protocol is that nearly half of each idle slot is lost accommodating randomization. Furthermore, reliable multicast or
broadcast cannot be assured in an idle slot.
The collision avoidance time allocation (CATA) protocol,
developed by Tang and Garcia-Luna-Aceves in [13], directly
addresses the hidden terminal problem in [12] by replacing
CSMA with a collision-avoidance mechanism. It also features support for both point-to-point and multi-point packet
transmissions, as well as on-demand slot reservations. However, in CATA there are no permanent slot assignments, and
access to each slot is resolved through contention. Consequently, instability can arise in situations where network load
and node connectivity are high, as shown in section 5.
To summarize, each of the above protocols are not well
suited to support efficient group communication in ad hoc networks. They either lack the reliable multi-point transmission
services needed by higher layer protocols, inefficiently use
the bandwidth resources, or suffer from protocol instability.
Our AGENT protocol addresses each of these shortcomings.

3. An adaptive generalized transmission protocol
(AGENT)
3.1. Model and notation
We represent an ad hoc network as an undirected graph G =
(V , E), where V is the set of |V | = N nodes and E is the
set of bidirectional, wireless links. We assume that the network can be embedded in a two-dimensional convex area A.
For two nodes i and j , dist(i, j ) is a function that returns
the Euclidean distance separating them, and link(i, j ) is a
logical function that returns true if dist(i, j )  r, where r
is the transmission range of each node, and false otherwise.
H  (i) = {k ∈ V |link(i, k)} is the set of one-hop neighbors of
node i. We assume that communication is perfectly synchronized, half-duplex, and that the simultaneous arrival of two or
more packets at a node results in a collision, i.e., no capture.
3.2. Motivation for AGENT
We first explore the difference in concurrency that arises in
the network between point-to-point and multi-point transmissions. For a source node s to successfully unicast a packet to
a destination d, all nodes in H  (d) − {s} must not transmit
concurrently to prevent collision 
at d. For s to successfully
broadcast a packet, all nodes in d∈H  (s) H  (d) − {s} must
not transmit concurrently. Spatial bandwidth reuse, and therefore MAC protocol performance, is directly dependent on the
number of nodes that must not transmit concurrently, i.e., the
neighborhood size, in a given transmission attempt. Thus, we
begin by approximating average neighborhood sizes.

AN ADAPTIVE GENERALIZED TRANSMISSION PROTOCOL

495

Geometrically, the probability that two nodes are neighbors is πr 2 /A. Thus, the average number of nodes in a onehop neighborhood, η , is approximated by
πr 2 N
.
(1)
A
For any two such connected nodes, the cumulative distribution function of the distance x separating them is given by
F (x) = x 2 /r 2 , where 0  x  r. The probability distribution function is f (x) = F (x) d/dx = 2x/r 2 , and the
expected value of x is E[f (x)] = 2/(3r).
The radius of the average two-hop neighborhood is approximately 2/(3r) more than the expected value of x. Thus,
the probability that a node resides in this area is 16πr 2 /(9A),
and the average number of nodes in a two-hop neighborhood,
η , is approximated by
η =

16 
16πr 2 N
=
η.
(2)
9A
9
In order to express the tradeoff between unicast and broadcast, let us consider a saturated network where each node has
a packet to send in every slot. The probability of a successful
transmission, psucc , is then τ (1 − τ )1−η , where τ is the probability that a node transmits in a slot and η is the neighborhood
size. Through differentiation we find that psucc is maximized
when τ = 1/η. Thus,


1 1−η
1
1−
.
(3)
psucc =
η
η
η =

The inverse of (3) yields the average time needed for a
successful transmission, i.e., the average access delay. Those
situations where a single broadcast is more effective than repeated unicast occur when
η Du − Db  0,

(4)

where Du and Db denote the respective average access delay
of unicast and broadcast. We find that broadcast is more effective than repeated unicast when η  16/9. Thus, except
for extremely sparse networks, unicast MAC protocols cannot
effectively support multi-point communication; yet broadcast
is not effective for unicast transmissions due to reduced concurrency. Therefore, a MAC protocol that effectively supports
both point-to-point and multi-point traffic in a unified manner
is justified.
3.3. AGENT protocol description
Underlying AGENT is a TDMA allocation protocol in which
node i is assigned a unique slot si , 1  si  N, in a frame
of length N. This guarantees each node access to the channel
once per frame, bounding delay under high loads and dense
connectivity. To take advantage of the potential for spatial
bandwidth reuse, AGENT uses signalling similar to that used
in collision-avoidance protocols. In order to facilitate transmission concurrency, each TDMA slot is subdivided into a
priority, contention and transmission interval (see figure 1).
The priority interval is used to signal nodes about activity in

an assigned slot; the contention interval gives nodes an opportunity to use a slot provided that transmission will not interfere with that of the slot owner; and the transmission interval
is used to transmit a unicast, multicast, or broadcast packet.
To gain access to the transmission interval of a slot s, a
source node i first transmits a RTS control packet. The RTS
is either sent at the beginning of the priority interval, if s = si ,
or at the beginning of the contention interval, otherwise. Reception of a RTS in the priority interval elicits a CTS response
from a destination. Notice that in the case of a multi-point
packet, there will be a collision of responses at i. This is not
a concern, since the purpose of these CTS responses is to inform the neighbors of each destination of i’s intention to use
its assigned slot. On the other hand, reception of a RTS in the
contention interval will generate a CTS response only when
it is associated with a unicast packet. Any node that detects
a collision among RTS control packets will reply with a notclear-to-send (NCTS) control packet.
Once the initial control signalling is finished, a node can
determine its eligibility to transmit its packet p in the transmission interval. If s = si , then source node i is granted
permission to transmit p without restriction. Otherwise, the
following rules must be applied:
1. If any control signalling is detected in the priority interval,
then i must withhold the transmission of p to avoid conflict
with the owner of s.
2. If a NCTS response is received in the contention interval,
then multiple source nodes are contending for s, and i must
withhold the transmission of p to avoid collision.
3. If p is a unicast packet and a corresponding CTS is received, then i may transmit p.
4. If p is a multi-point packet and no signalling response is
received in the contention interval, then i may transmit p.
Any failure to transmit p in an unassigned slot is resolved
by a backoff algorithm that is based on the exponential backoff scheme developed in [9]. Using local network feedback,
a node decreases τ by a factor of 1/c when it detects a failed
transmission attempt in a slot. A failed transmission attempt
occurs when a negative control response is received, e.g., a
NCTS response, or a collision is detected in the contention
interval. On the other hand, τ is increased by a factor of c
when a slot remains idle. In [9], c = 2 was shown to yield
optimal results.
For example, consider the five node network of figure 2.
The current slot is assigned to node 3, which has a multicast
packet addressed to nodes 1 and 2, and node 4 has a unicast
packet addressed to node 5. Then 3 sends a RTS at the beginning of the priority interval (figure 2(a)) to which 1 and
2 respond with a CTS (figure 2(b)). Node 4 sends a RTS at
the start of the contention interval (figure 2(c)), and 5 sends
a CTS response (figure 2(d)). At this point, 3 is free to send
its multicast packet in the transmission interval, since this is
its assigned slot. However, 4 must refrain from sending its
unicast packet, since it detected the RTS of 3 (see figure 2(a))
in the priority interval.

496

A.D. MYERS ET AL.

Figure 1. Frame and slot structure of the AGENT protocol.

(a)

(c)

(b)

(d)
Figure 2. Example of AGENT signalling.

Notice that the concurrent transmissions of nodes 3 and 4
would not cause any interference at any destination node in
the above scenario. This increased concurrency can be accommodated by amending the first rule to read: “If any CTS
control signalling is detected in the priority interval, i must
withhold the transmission of p to avoid conflict with the
owner of s”.
We can further enhance the protocol by eliminating unnecessary control signalling. Specifically, a node that is attempting to send a packet in an unassigned slot can immediately
evaluate the amended rule at the end of the priority interval.
If it evaluates to true, then there is no reason to send a RTS in
the contention interval. This will reduce the number of control packets sent, and increase energy savings.
One further amendment is needed to handle special cases
involving multi-point packets. For example, if the roles of
nodes 4 and 5 are switched in figure 2, then following scenario arises. Node 5 is unable to determine whether 3 is using
its assigned slot, and will send a RTS in the contention inter-

val. According to AGENT, the proper response of 4 is a CTS,
only this would lead to a collision at 4 in the transmission interval. If 4 does not send a CTS, then 5 would not send its
unicast packet. However, with a multi-point packet, 5 would
still attempt packet transmission. To avoid this ambiguity, a
NCTS response is needed. Thus, the node sending a RTS in
the priority interval also sends a jamming RTS (JAM) at the
start of the contention interval. This will cause a collision
with any incoming RTS control packets, and elicit the proper
NCTS response.
Figure 3 presents the specification of the AGENT protocol in pseudocode. For ease of presentation we assume each
destination is in range of the source node. Each node maintains a queue of packets to transmit and a transmission probability (τ ). Each packet header contains a source and destination identifier and a type field which is unicast, multicast, or broadcast. The destination contains one or more
node addresses (for unicast and multicast, respectively) or a
broadcast address. Nodes execute Send(packet, interval) and

AN ADAPTIVE GENERALIZED TRANSMISSION PROTOCOL

AGENT() {
for each slot s do {
if queue 
= empty then {
if s = assigned then {
Send(RTS, priority);
Send(JAM, contention);
Send(PKT, transmission);
}
else if Recv(RTS, priority) = success and
RTS.dest
}
= this_node then {
Send(CTS, priority);
Recv(pkt, transmission);
}
else if Recv(CTS, priority) = idle then {
if Contend(τ ) then {
Send(RTS, contention);
case RTS.type
unicast:
if Recv(CTS, contention) = success then
Send(pkt, transmission);
else τ ← τ/2;
multicast, broadcast:
if Recv(NCTS, contention) = idle then
Send(pkt, transmission);
else τ ← τ/2;
end case
}
else Passsive();
}
}
else Passive();
}
} /* end AGENT() */
Passive() {
if Recv(RTS, priority) = success and
RTS.dest = this_node then {
Send(CTS, priority);
if Recv(RTS, contention) = collision then
Send(NCTS, contention);
Recv(pkt, transmission);
}
else {
status ← Recv(RTS, contention);
case status
success:
if RTS.type = unicast and
RTS.dest = this_node then {
Send(CTS, contention);
Recv(pkt, transmission);
}
else Recv(pkt, transmission);
collision :
Send(NCTS, contention);
τ ← τ/2;
idle:
τ ← 2τ ;
end case
}
}/* end Passive() */
Figure 3. AGENT specification.

Recv(packet, interval) to transmit and receive packets in the
specified interval, i.e., priority, contention, or transmission.
Recv also sets a return code of success, collision, or idle to
indicate whether the packet reception was successful or not,
or that the channel was idle during the interval, respectively.

497

The statement Contend(τ ) returns true if the node may attempt transmission in an unassigned slot, and false otherwise.

4. Analyses of AGENT
4.1. Performance analysis
In this section, we present an approximate analytical framework for evaluating the performance of AGENT. To simplify
our presentation, we assume that the network topology is static and that the traffic load distribution is homogeneous.
With AGENT, there are two cases that need to be analyzed.
For a given node, a slot is either assigned or unassigned. Let ϕ
be the probability that a node has a packet to transmit, and let
η denote the neighborhood size. The probability that a node
transmits its packet in its assigned slot is ϕ/N, since there is
a 1/N probability that a slot is assigned. A node may also
attempt to transmit in an unassigned slot. The probability that
a node contends for an unassigned slot can be expressed as
τ (1 − ϕ/N)η , where 0  τ  1 is the probability that a node
transmits in a slot. Then the probability that its contention is
successful, ϑ, is



 

ϕ η η−1
ϕ η
ϑ =η 1−τ 1−
τ 1−
.
(5)
N
N
By combining the probabilities associated with the assigned
and unassigned slots, we can approximate a node’s average
throughput as Tnode = ϕ/N + ϑ.
Using differentiation, we find that the maximum average throughput of a node occurs when the parameter τ of
(5) equals 1/(η(1 − ϕ/N)η ), yielding an approximate upper bound on the throughput performance of a node using the
AGENT protocol:


1 η−1
ϕ
Tnode =
+ 1−
.
(6)
N
η
By substituting (1) and (2) for η, we obtain the respective pure
unicast and pure broadcast average throughput performance.
4.2. Reliability analysis
There are a few scenarios in which all of the destinations do
not receive a multi-point packet transmission. These scenarios are not unique to AGENT as similar situations arise in
other MAC protocols [13,15]. The source of the problem is
the combination of half-duplex communication and the lack
of a positive control response for multi-point transmissions.
Since AGENT guarantees each node collision-free transmission in its assigned slot, these failure scenarios arise only
when nodes contend in an unassigned slot. Referring back
to figure 2, assume that nodes 3 and 4 simultaneously send a
RTS for broadcast in the contention interval. Since nodes 3
and 4 are transmitting, they cannot directly detect the collision. Furthermore, nodes 1, 2 and 5 each receive a RTS, and
therefore do not respond. Consequently, both nodes 3 and 4

498

A.D. MYERS ET AL.

incorrectly conclude that there is no contention for the unassigned slot, and broadcast their packets in the transmission
interval. Clearly, neither 3 nor 4 receives the other’s broadcast packet.
AGENT fails in the above scenario because there is no
“witness” to the RTS collision. To calculate the likelihood
of such a failure, we compute the probability that there are no
witnesses of a RTS collision between two neighboring nodes i
and j .
Let I be the area of intersection between the transmission
radii of i and j when dist(i, j ) = 2/(3r). Let γ represent
the probability that a node k resides in I . Using the circle
intersection formulas, we find that E[γ ] ≈ 2.24r 2/A. Let
P (κ) be the probability that there are exactly κ contending
nodes in I :


N −2
P (κ) =
(γ τ )κ (1 − γ )N−2−κ .
κ
Then AGENT fails when there are 0, 1, 2, . . . , or N − 2
such contending nodes in I . Therefore, the probability that
a broadcast fails to be received by all neighbors, Pfail , is
Pfail < eγ (2−N)

N−2

κ=1

κ
1
(N − 2)γ τ .
κ!

(7)

Notice that as the number of nodes N is increased, Pfail decreases rapidly. In [6], our analysis has shown that Pfail remains less than 4%.
5. Performance evaluation
The primary goal of our simulation experiments is to collect
baseline performance measures of AGENT. We also compare
these results with that of other existing MAC protocols within
the same simulation framework. Due to limited space, we restrict our evaluation to include the CATA protocol [13], chosen for its similar design and features.
5.1. Simulation model
Using a discrete event simulator, we model an ad hoc network consisting of 100 mobile nodes operating in a twodimensional plane that measures 10 km per side. Each node
is equipped with a simulated radio device that transmitted at
a rate of 1 Mbps to a distance of 1 km. All communication
occurs on a single perfect channel, i.e., no channel noise, with
a free-space propagation model.
Node movement is simulated using the mobility model defined in [11]. With this model, a node’s movement is characterized by three parameters: λ, µ, σ 2 , where λ is the average
time traveled in a single direction with a constant speed; µ is
the average speed; and σ 2 is the speed variance. In our simulations we use 60−1 s, 5 m/s, 8.33 m/s to correspond with
pedestrian movement characteristics.
Network traffic is introduced according to a Poisson arrival process with a mean arrival rate of λ packets per second, which are uniformly distributed among the nodes. Each

packet is 512 bytes in length, and is either a unicast or broadcast packet. This represents a worst-case traffic scenario since
the interaction between these two traffic types is the most
volatile. The control packets are 32 bytes in length. We arbitrarily select two different traffic scenarios – one consisting
of a 80% unicast and 20% broadcast (80/20) traffic mixture,
and the other consisting of a 60% unicast and 40% broadcast
(60/40) traffic mixture.
Since we are only interested in MAC layer performance,
no specific transport, network, or data link protocols are introduced. To accommodate packet addressing, we assume that
each node has perfect knowledge of its neighbors.
5.2. CATA implementation
CATA allows nodes to compete for synchronous time slots,
and supports point-to-point and multi-point packet transmissions. It also features slot reservations that maintains
collision-free access for extended periods of time. Since
multi-point communication is the focus of this paper, this feature was disabled. The contention and reservation scheme
is based on a RTS/CTS handshake, and slots are organized
into a synchronous frame. We use a static frame length equal
to the number of nodes. Each time slot is subdivided into
five mini-slots. The first four mini-slots (CMS1–CMS4) are
used to secure and reserve time slots through the exchange of
short control packets. The last mini-slot (DMS) is used for
the transmission of a data packet. Unlike AGENT, nodes do
not have a dedicated slot.
For a given source node s and time slot t, CATA operates as
follows. Regardless of the packet type, s must first determine
whether or not the current slot has been previously reserved.
To reserve a slot, all nodes that received data in slot t in the
preceding frame send a slot reservation (SR) packet in CMS1.
In addition, each source node that wishes to maintain a reservation sends a RTS and not-to-send (NTS) packets in CMS2
and CMS4, respectively.
If no SR packet is detected in CMS1, then source node s
contends for slot t by sending its own RTS in CMS2. Reception of a unicast RTS causes a node to respond with a CTS in
CMS3, and s can transmit its data packet in the DMS. Reception of a multicast or broadcast RTS in CMS2 causes a node
to remain silent during CMS3 and CMS4; otherwise it sends a
NTS in CMS4 to indicate a potential problem for multi-point
transmissions. Detection of a clear channel in CMS4 allows
source node s to transmit a multi-point packet in the DMS.
Any unsuccessful slot contention is handled by a backoff algorithm; since no specific algorithm was specified in [13], we
use a binary exponential backoff algorithm.
5.3. Simulation results
In this set of experiments, we measure how effectively each
protocol utilizes the channel capacity and the average access
delay for both unicast and broadcast packets. The results are
presented in figures 4–15. Each data point represents the statistical average of several simulation trials, and lies within a

AN ADAPTIVE GENERALIZED TRANSMISSION PROTOCOL

499

Figure 6. CATA utilization (80/20).
Figure 4. AGENT utilization (80/20).

Figure 5. AGENT utilization (60/40).

90% confidence interval. Each graph shows the associated
performance metric as a function of the average node degree (η ), and traffic arrival rate (λ), measured in packets per
second.
5.3.1. Channel utilization
Figures 4 and 5 depict the channel utilization of AGENT with
a 80/20 and 60/40 traffic mixture, respectively. The potential
for concurrent transmission (i.e., spatial bandwidth reuse) is
inversely proportional to the network connectivity. When the
average node degree is less than 20, we find that the channel
utilization of AGENT exceeds the channel capacity, reaching a maximum of 700% (i.e., an average of seven concurrent
packet transmissions are occurring in each slot). This demonstrates that the contention-based component protocol is capable of spatially reusing TDMA slots, resulting in increased
bandwidth efficiency. As network connectivity is increased,
the contention level for each slot rises, and channel utilization begins to drop. However, the underlying TDMA protocol
prevents instability under high traffic loads and network connectivity. Thus, AGENT operates at near channel capacity
under such conditions.

Figure 7. CATA utilization (60/40).

Comparing figures 4 and 5 we find that there is a slight
degradation in channel utilization when the proportion of
broadcast traffic is increased. This is expected since the number of nodes involved (i.e., remaining silent) in a broadcast is
greater than in a unicast transmission. However, the lack of
significant performance degradation indicates the absence of
bias among unicast and broadcast packet transmissions. This
fact is emphasized when we examine the associated access
delays.
Figures 6 and 7 depict the channel utilization of CATA
with a 80/20 and 60/40 traffic mixture, respectively. In figure 6, we find the utilization of CATA comparable to AGENT
when the network connectivity is sparse (η  10). As before, the contention protocol is successful in spatially reusing
the available time slots, leading to a channel utilization that
exceeds capacity. However, the absence of permanent slot
assignments forces all channel access to be decided through
contention. Rising contention levels naturally increase the
number of unsuccessful slot contentions that must be resolved by the backoff algorithm. This introduces additional
packet delay, and reduces the number of packets sent in each
slot. Consequently, the channel utilization of CATA begins

500

A.D. MYERS ET AL.

Figure 10. Average unicast access delay of CATA (80/20).
Figure 8. Average unicast access delay of AGENT (80/20).

Figure 11. Average broadcast access delay of CATA (80/20).
Figure 9. Average broadcast access delay of AGENT (80/20).

to quickly deteriorate as η is increased, and eventually drops
well below full capacity.
Comparing figures 6 and 7 we see that there is a more
pronounced performance degradation when the proportion of
broadcast traffic is increased. The maximum utilization is
700% in figure 6, and reduced to 600% in figure 7. Examining the protocol, we find that the responses for unicast and
broadcast RTS control packets are sent at different times. It is
then possible to receive a positive unicast response followed
by a negative broadcast response. For example, referring back
to the network in figure 2, let node 1 transmit a broadcast RTS
and node 3 a unicast RTS to 4 in CMS2. Then 3 will receive a
CTS in CMS3 while 1 receives a NTS in CMS4. In this case,
the unicast succeeds and the broadcast fails. This preferential
treatment of unicast increases the delay of broadcast packets.
Consequently, increasing the amount of broadcast traffic reduces the overall channel utilization.
5.3.2. Access delay
Figures 8 and 9 depict the respective average unicast and
broadcast access delay of AGENT with a 80/20 traffic mixture, from which we see no significant difference in the delay
experienced by unicast and broadcast packets. This confirms
that AGENT has no bias towards either packet type. Further-

more, the maximum delay associated with either packet type
remains asymptotically bounded by 1000 ms, which corresponds to the frame length used. The same results are evident in figures 12 and 13 which show the respective average
unicast and broadcast access delay of AGENT with a 60/40
traffic mixture.
Figures 10 and 11 depict the respective average unicast and
broadcast access delay of CATA with a 80/20 traffic mixture.
We see that the average broadcast access delay is up to 4 times
higher than its unicast delay, clear evidence of CATA’s partiality towards unicast transmissions. As the proportion of broadcast traffic is increased (see figures 14 and 15) we find the
unicast delay relatively unchanged, while the broadcast delay
actually decreases. With a 60/40 traffic mixture, there is less
opportunity to favor unicast packets, and thus broadcast packets are successfully transmitted with increased frequency. The
irregularity present in the CATA access delay curves indicate
a high degree of delay variation. Large delay variations typically lead to increased packet jitter which negatively impact
the performance quality of multimedia applications.
In comparison to AGENT, there is a significant increase in
the average access delay of CATA for both packet types. With
unicast traffic, the average access delay of CATA ranges from
a few milliseconds to nearly 3 s. This wide delay range limits
the ability of high level services to estimate link/path qual-

AN ADAPTIVE GENERALIZED TRANSMISSION PROTOCOL

501

Figure 14. Average unicast access delay of CATA (60/40).
Figure 12. Average unicast access delay of AGENT (60/40).

Figure 13. Average broadcast access delay of AGENT (60/40).

ity. With broadcast traffic, the delay range is even wider with
a maximum exceeding 10 s. This can also negatively impact
the performance of higher layer services. For example, proactive routing protocols typically use broadcast transmissions to
periodically exchange updated connectivity information. The
introduction of large broadcast delays reduces the frequency
of these updates, diminishing the effectiveness of the routing
protocol to find valid paths.
With AGENT, the access delay of both unicast and broadcast traffic is bounded. Consequently, worst case end-to-end
delay can easily be computed for unicast traffic, and the use
of broadcast for periodic information exchange is much less
volatile. However, the use of an allocation protocol introduces
synchronization and timing issues that were not studied in this
performance evaluation. Many of these timing issues can be
alleviated through the application of global timing services,
such as the Global Positioning System (GPS). This requires
additional hardware to be added to each node, resulting in an
increase per unit cost and reduced battery life.
6. Conclusions
This paper presented AGENT, an adaptive, generalized transmission protocol for ad hoc networks that offers a unified

Figure 15. Average broadcast access delay of CATA (60/40).

set of effective single-hop transmission services. AGENT
features a hybrid design that combines a TDMA allocation
protocol and a contention protocol that employs a collisionavoidance dialogue. The allocation component provides access delay bounds, while the contention component increases
spatial bandwidth reuse. We provided an approximate analytical framework in which we examined the performance of
AGENT with respect to point-to-point and multi-point traffic.
We also analyzed the reliability of AGENT, and showed that
the probability of multi-point failure is very low. Finally, we
evaluated the performance of AGENT in a simulated ad hoc
environment. Our results illustrate the effective operation of a
hybrid design, and show significant improvement over similar
MAC designs.
Although the current hybrid design of the AGENT protocol performs well, its application is somewhat limited. The
use of TDMA means that the delay bound is directly proportional to the network size. For larger networks consisting
of thousands of nodes, the current AGENT protocol may no
longer be a feasible alternative. Moreover, the network size is
typically unknown and time varying. Our future research efforts will focus on overcoming these limitations through the
use of other, more scalable, protocol combinations.

502

Acknowledgements
The authors would like to thank the anonymous reviewers for
their insightful comments that greatly improved the quality of
this paper.
References
[1] S. Basagni, I. Chlamtac and V.R. Syrotiuk, Geographic messaging in
wireless ad hoc networks, in: Proc. IEEE VTC’99, Vol. 3 (May 1999)
pp. 1957–1961.
[2] D. Bertsekas and R. Gallager, Data Networks (Prentice Hall, 1992).
[3] C. Chiang, M. Gerla and L. Zhang, Adaptive shared tree multicast in
mobile wireless networks, in: Proc. IEEE GLOBECOM’98, Vol. 3 (November 1998) pp. 1817–1822.
[4] I. Chlamtac and A. Faragó, Making transmission schedules immune
to topology changes in multi-hop packet radio networks, IEEE/ACM
Transactions on Networking 2(1) (February 1994) 23–29.
[5] I. Chlamtac, A. Faragó, A.D. Myers, V.R. Syrotiuk and G. Záruba,
ADAPT: A dynamically self-adjusting media access control protocol
for ad hoc networks, in: Proc. IEEE GLOBECOM’99, Vol. 1a (December 1999) pp. 11–15.
[6] I. Chlamtac, A.D. Myers, V.R. Syrotiuk and G. Záruba, An adaptive
media access control (MAC) protocol for reliable broadcast in wireless
networks, in: Proc. IEEE ICC’00 (June 2000).
[7] C. Diot, W. Dubbous and J. Crowcroft, Multipoint communication:
A survey of protocols, functions and mechanisms, IEEE Journal on
Selected Areas in Communications 15(3) (April 1997) 277–290.
[8] J.J. Garcia-Luna-Aceves and E. Madruga, A multicast routing protocol for ad-hoc networks, in: Proc. IEEE INFOCOM’99, Vol. 2 (March
1999) pp. 784–792.
[9] D. Jeong and W. Jeon, Performance of an exponential backoff scheme
for the slotted-ALOHA protocol in local wireless environment, IEEE
Transactions on Vehicular Technology 44(3) (August 1995) 470–479.
[10] P. Karn, MACA – A new channel access protocol for packet radio, in:
Proc. ARRL/CRRL Amateur Radio 9th Computer Networking Conference (September 1990).
[11] B. McDonald and T. Znati, A path availability model for wireless adhoc networks, in: Proc. IEEE WCNC’99, Vol. 1 (September 1999)
pp. 35–40.
[12] B.A. Sharp, E.A. Grindrond and D.A. Camm, Hybrid TDMA/CSMA
protocol for self managing packet radio networks, in: Proc. IEEE
ICUPC’95 (November 1995) pp. 929–933.
[13] Z. Tang and J.J. Garcia-Luna-Aceves, A protocol for topologydependent transmission scheduling in wireless networks, in: Proc.
IEEE WCNC’99, Vol. 3 (September 1999) pp. 1333–1337.
[14] F. Tobagi and L. Kleinrock, Packet switching in radio channels. I. Carrier sense multiple access models and their throughput delay characteristics, IEEE Transactions on Communications COM-23(12) (December
1975) 1400–1416.
[15] C. Zhu and S. Corson, A five-phase reservation protocol (FPRP) for
mobile ad hoc networks, in: Proc. INFOCOM’98, Vol. 1 (March 1998)
pp. 322–331.

A.D. MYERS ET AL.

[16] DARPA/ITO Global Mobile Information Systems Principle Investigator
Meeting, Richardson, TX (February 1999).
[17] Wireless Medium Access Control and Physical Layer WG, IEEE Draft
Standard P802.11, Wireless LAN, IEEE Standards Department, D3
(January 1996).
Andrew D. Myers received the B.S. (with honors)
and M.S. degrees in computer science from the Erik
Jonsson School of Engineering and Computer Science at the University of Texas at Dallas (UTD) in
1997 and 1999, respectively. In 1997, he joined
the Center for Advanced Telecommunications Systems and Services where he developed and tested signaling protocols for the DARPA sponsored GloMo
Project. He is currently pursuing a Ph.D. degree in
computer science at UTD, and is a senior Research
Assistant at the Center. Current interests include communication protocols,
routing algorithms, and applications for ad hoc and sensor networks.
E-mail: amyers@utdallas.edu

Gergely V. Záruba received the M.S. degree in computer engineering in 1997 from the Technical University of Budapest, Department of Telecommunications and Telematics, with excellent classification.
Since 1997 he is pursuing research towards a Ph.D.
degree. From 1995 to 1998 he was a member of
Hungary’s leading telecom research laboratory, the
High Speed Networks Laboratory at the Technical
University of Budapest. In 1998 he joined the Center for Advanced Telecommunications Systems and
Services (CATSS) at the University of Texas at Dallas, where he is currently
pursuing research on communication protocols for wireless networks as a
Research Assistant. His research interests include MAC protocol issues in ad
hoc networks, admission control in wireless networks, and Bluetooth scatternet formation problems.
E-mail: zaruba@utdallas.edu

Violet R. Syrotiuk received the Ph.D. degree in
computer science from the University of Waterloo
(Canada) in 1992. She joined the University of Texas
at Dallas in 1994 and is currently an Assistant Professor of Computer Science. In 1997, she joined
the Center for Advanced Telecommunications Systems and Services where she was co-PI and Technical Manager of a DARPA sponsored GloMo Project.
She served on the organizing committee of the First
Annual MobiHoc Workshop held in August 2000.
Dr. Syrotiuk’s current research interests include medium access and network
layer protocols for wireless mobile multi-hop networks, network simulation,
and distributed algorithms and systems.
E-mail: syrotiuk@utdallas.edu

Ad Hoc Networks 5 (2007) 1233–1250
www.elsevier.com/locate/adhoc

A carrier sense multiple access protocol with power
backoﬀ (CSMA/PB) q
Charles J. Colbourn a, Minghao Cui
a

a,*

, Errol L. Lloyd b, Violet R. Syrotiuk

a

Department of Computer Science and Engineering, Arizona State University, Tempe, AZ 85287-8809, USA
b
Department of Computer and Information Sciences, University of Delaware, Newark, DE 19716, USA
Available online 15 March 2007

Abstract
In this paper, we exploit space as a new dimension in collision resolution for a carrier sense multiple access (CSMA)
protocol. Most contention-based medium access control protocols resolve collisions by backing oﬀ in time. We introduce
power backoﬀ (PB), the use of transmission power control to resolve collisions by backing oﬀ in space, and incorporate it
into a CSMA protocol as CSMA/PB. Through analysis and simulation, we show that collision resolution using power
backoﬀ can be remarkably successful. Simulation results show that CSMA/PB outperforms IEEE 802.11 in both static
and mobile ad hoc network scenarios. CSMA/PB improves end-to-end throughput and uses less energy. The resulting
gains in throughput per unit energy can be substantial.
 2007 Elsevier B.V. All rights reserved.
Keywords: Carrier sense multiple access; Collision resolution; Spatial backoﬀ

1. Introduction
Recently, Gomez and Campbell [1,2] investigated
the impact of variable-range power control on the
physical network connectivity, the network capacity, and the energy savings of wireless multi-hop
networks. Inspired by their challenge to develop
protocols that exploit power control we propose a
q
Prepared through collaborative participation in the Communications and Networks Consortium sponsored by the US Army
Research Laboratory under the Collaborative Technology Alliance Program, Cooperative Agreement DAAD19-01-2-0011. The
US Government is authorized to reproduce and distribute
reprints for Government purposes not withstanding any copyright notation thereon.
*
Corresponding author.
E-mail address: Minghao.Cui@asu.edu (M. Cui).

medium access control (MAC) protocol for mobile
ad hoc networks adding the dimension of space to
collision resolution.
Traditional contention-based MAC protocols
resolve collisions by backing oﬀ in time. A transmitter increases its contention window size when the
channel is already in use or the previous transmission attempt fails. The transmitter then waits for a
period related to the window size in the hope that
contention is reduced. In contrast, we consider a
transmitter that backs oﬀ in space—it reduces its
transmission power. This is analogous to increasing
the size of the contention window in temporal backoﬀ; in a smaller transmission range, the interference
and contention are likely to be reduced.
To see why backing oﬀ in space may be as (or
more) eﬀective than backing oﬀ in time, consider a

1570-8705/$ - see front matter  2007 Elsevier B.V. All rights reserved.
doi:10.1016/j.adhoc.2007.02.017

1234

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

network in which the nodes are uniformly distributed throughout some geographic area. If a node
has a transmission range of r, then the physical area
of the interference is proportional to r2. If the network traﬃc is also uniformly distributed among
nodes, then the magnitude of the contention at each
node is also proportional to r2. Since the contention
increases in proportion to the square of the transmission range, the reduction of the transmission
range by half, for example, results in a four fold
decrease in the contention. Consider a path from a
source to a destination; the length (number of hops)
of this path is inversely proportional to r. So overall,
the contention along this path is now proportional
to r2r1 = r. This suggests that a low transmission
range yields low overall contention along a path,
and therefore higher spatial reuse and higher network throughput.
Spatial backoﬀ may also reduce energy consumption. Imagine a single (unicast) transmission; suppose we have one wireless node as transmitter,
and several others within its transmission range.
Potentially all of the nodes in range can receive
the transmission. One transmission occurs at the
transmitter and one reception occurs at each of its
neighbours, with no discrimination as to whether
it is the desired destination. Thus the total energy
consumed in this single transmission is Ptx + kPrx,
where Ptx [Prx] is the energy consumed for one
transmission [reception], and k is the number of
neighbours within transmission range of the transmitter. In spatial backoﬀ where the transmission
range is reduced, the number of neighbours that
receive the transmission is also reduced, i.e., k is
smaller. Therefore, the total energy consumed in
the whole system is reduced.
One may conclude that a small transmission
range is always desired in a wireless network, but
this is not true. The discussion is based on the
assumption that the nodes in the network are uniformly distributed and the traﬃc ﬂows are also uniformly distributed among all the nodes; this may
not be the case. A smaller transmission range may
not allow the desired destination to be reached in
one hop. It may therefore increase the number of
hops between a source and destination pair, thus
increasing the number of transmissions made by
intermediate nodes and associated packet queuing.
Furthermore, a problem for all protocols that use
power control is how to cope with asymmetric links.
Consider Fig. 1 with two nodes A and B where dotted and solid circles represent the range of their high

Fig. 1. B may be hidden to A when asymmetric power used.

and low transmission powers, respectively. If A
transmits at low power while B transmits at high
power, A is within the transmission range of B,
but the converse is not true. If a handshake is initiated from A to C at low transmission power, B may
be a hidden terminal to A. The handshake that
solves the hidden terminal problem when a common
transmission power level is used by all nodes is
insuﬃcient in systems where nodes use variablerange transmissions. Hence, whether a low transmit
power is desirable may depend on several factors.
We call our approach to backing oﬀ in space
power backoﬀ (PB) and incorporate it into a CSMA
protocol as CSMA/PB. A CSMA/CA protocol,
such as IEEE 802.11, may spend a signiﬁcant
amount of time to deliver an individual packet.
The contention window starts at a size of 32, and
through the binary exponential backoﬀ algorithm
may reach a maximum size of 1024. Indeed, if the
contention window is at its maximum size and the
packet is still not delivered, the protocol retries a
constant number of times at this size before ﬁnally
giving up on the packet. In comparison, CSMA/
PB backs oﬀ through a ﬁxed number of transmission power levels, sensing the carrier at each level.
This can be achieved relatively quickly in time, in
fact, so much so that it is premature to give up on
the packet if the channel is sensed busy at the minimum transmission range; hence, a retry strategy is
required. While power backoﬀ alone is eﬀective,
even a naı̈ve combination of spatial backoﬀ with
temporal backoﬀ proves to be better than CSMA/
CA. We propose three ways of combining backoﬀ
in space with backoﬀ in time. We compare the performance of each variant with IEEE 802.11 under
the same conditions for a variety of static and
mobile ad hoc network scenarios. In all scenarios,

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

the throughput per unit energy of CSMA/PB
exceeds that of IEEE 802.11, often quite substantially.
The rest of this paper is organized as follows. We
summarize related work in Section 2. The basic
CSMA/PB protocol is introduced and evaluated in
Section 3. Section 4 describes three variants of combined spatial and temporal backoﬀ, assessing the
eﬀectiveness of each variant in Section 5. Section 6
analyzes the probability of successful transmission
of temporal and spatial backoﬀ strategies. Finally,
we present conclusions and directions for future
work in Section 7.
2. Related work
The analysis of temporal backoﬀ algorithms has
been the subject of intense research. There is no simple answer to the question of which is the best algorithm. For example, despite its wide usage in IEEE
802.11, it is well known that binary exponential
backoﬀ results in a provably unstable protocol (inﬁnitely growing queues) under certain modelling
assumptions [3]. The existence of stable protocols
in this setting also depends on the type of feedback
available from the channel and on how the user
population is modelled. For acknowledgment-based
protocols, Kelly [4] showed that a large class of
backoﬀ algorithms, including polynomial backoﬀ,
is unstable in the inﬁnite user population model.
In contrast, for a ﬁnite user population, any
super-linear polynomial backoﬀ algorithm has been
proved stable, while binary exponential backoﬀ is
unstable above a certain arrival rate [5].
Several approaches to medium access control add
the dimension of space to transmission. One idea is
to use multiple channels with the same aggregate
channel capacity thereby spacing out transmissions
over channels and not just over time. Nasipuri
et al. [6] propose a multichannel MAC protocol
using ‘‘soft reservation’’ of the channels. Each node
keeps its own channel usage history and preferentially selects a channel used in the past to reduce
the contention and collision probability for the
same channel among neighbours. In [7] the protocol
is extended to select the best channel according to
the signal-power on multiple channels so as to distribute the interference on multiple channels evenly.
So and Vaidya [8] propose a multichannel MAC
that enables nodes to dynamically negotiate channels in order for multiple communications to take
place in the same region. Each node maintains a pre-

1235

ferred channel list (PCL) that indicates the preference of each channel. The protocol requires a
window preceding data packet exchange, during
which nodes that want to transmit exchange their
PCL information on a common channel and agree
on the channel selected by one round of handshake.
Multichannel protocols, while requiring that the
transceiver is tunable, and the carrier can be sensed
on all channels, have improved the overall throughput of CSMA.
Another idea using space for transmission is to
use a form of frequency hopping over multiple
channels. In hop reservation multiple access
(HRMA), Tang and Garcia-Luna-Aceves [9] use a
handshake to perform channel reservation for slow
frequency hopping spread spectrum networks. All
nodes listen using a common frequency hopping
sequence. To send data, nodes exchange control
packets on the current frequency. If the handshake
is successful, they use the same frequency for communication. Other nodes continue hopping and
the communicating pair synchronizes with the
sequence after the transmission has completed.
Tzamaloukas et al. [10] use a similar approach
except that the receiver initiates the collision
avoidance instead of the sender. Protocols using frequency hopping cannot be applied to systems using
forms of direct sequence spread spectrum, e.g., code
division multiple access (CDMA) systems, where a
signal is spread over a wide bandwidth.
Transmission power control may be applied at
the MAC layer to decrease power consumption.
Karn [11] incorporated a new ﬁeld in the IEEE
802.11 handshake to allow a transmitter to specify
its transmission power level in the request-to-send
(RTS) packet, and the receiver to set the desired
transmission power level in the clear-to-send (CTS)
packet. The receiver determines the transmission
power level based on the required signal-to-noise
ratio. The data and acknowledgment (ACK) packets
are then transmitted at the power level indicated in
the CTS packet. Jung et al. [12] analyze the performance of this scheme and improve it by periodically
increasing the transmission power level of the data
packet to the maximum power to ensure proper
reception of ACK packet. These schemes reduce
power consumption at the price of throughput since
the RTS/CTS exchange occurs at the highest transmission power level; therefore, the concurrency
achieved is at best the same as IEEE 802.11.
Transmission power control may also be applied
to increase spectrum reuse. Increasing concurrent

1236

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

transmissions around the receiver is the goal of
[13–16]; most protocols use an additional control
channel. Monks et al. [13] propose the power control
multiple access (PCMA) protocol, where an RTS/
CTS-like handshake is used to establish a connection between the transmitter and receiver, but not
for silencing neighbours. Instead, a control channel
is used for carrier sensing. The receiver periodically
sends a busy pulse on the control channel. A potential transmitter listens to the busy tone to determine
an upper bound on its transmission power so as to
not add too much noise to the existing reception.
Wu et al. [16] combine busy tones and power
control. They also use a separate control and data
channel together with two busy tone channels,
BTt and BTr, for transmission and reception,
respectively. The receiver sends a busy tone BTr
at maximum power. A neighbour can then estimate
the channel gain based on the strength of the busy
tone and determine whether it is allowed to transmit if its transmission would not add more than a
ﬁxed amount of noise; this is similar to [13]. In
addition, the transmitter saves energy by sending
the data packets and busy tone BTt at reduced
power based on the power level of the received
CTS. However, neither [13] nor [16] consider additional noise added by future transmitters to the
ongoing reception. Muqattash and Krunz [14]
propose the power controlled dual channel (PCDC)
protocol in which the RTS/CTS packets are transmitted on the control channel, each extended by
an additional byte. Using the new byte, the RTS
packet indicates the power level used. The receiver
determines the channel gain based on the RTS
packet it receives and computes a required power
level for the transmitter, allowing for a number of
future interfering transmissions to take place in its
neighbourhood, and puts it in the new byte of
CTS packet.
In [15], Muqattash et al. devise the power controlled MAC (POWMAC) protocol to eﬀectively
utilize power control on a single channel. However,
several aspects of the protocol change with respect
to the earlier work in [14]. An access window precedes data transmission, during which other neighbouring nodes within the interference range can
exchange RTS/CTS if the interference introduced
by the new transmission to the on-going communication is below a ﬁxed signal-to-noise ratio; this
provides the possibility of concurrent transmission.
Although the use of power control at the MAC
layer can increase the channel throughput, most of

the protocols need additional hardware, incur overhead, and impose restrictions.
Strongly related to the use of power control to
increase spectrum reuse is the use of power control
to prevent collisions. Fuemmeler et al. [17] argue
that, for CSMA protocols, the product of the transmission power and carrier sense threshold should
remain constant. By incorporating this collision prevention condition into a protocol, spatial reuse is
improved. In Chu [18], the contention window of
IEEE 802.11 is a function of the distance from the
transmitter to its next hop destination. A smaller
window is used for nodes closer together since the
contention in the transmission range required to
reach the destination is likely to be reduced.
Recently, Yang et al. [19] examined the possibility
of increasing system performance by reducing the
carrier sense range, while taking into account the
MAC overhead. The performance improvement
results from the higher level of spatial reuse than
is possible with a reduced carrier sense range. In
their conclusions Yang et al. [19] suggest as future
work adjusting contention based on node access
behaviour, even using the term ‘‘spatial backoﬀ’’.
Power control is also utilized by network layer
protocols. Among the ﬁrst routing protocols to
use power control is power-aware routing (PARO)
[20]. It minimizes the transmission power needed
to forward packets between wireless nodes in ad
hoc networks. In the common power (COMPOW)
protocol [21] all the nodes converge to a universal
power level selected to be the minimum power level
that keeps the network connected and the power
consumption minimal. However, if the nodes in
the network are not uniformly distributed signiﬁcant energy is wasted. The clustered power (CLUSTERPOW) protocol [22] handles this problem by
running several routing agents, each corresponding
to a diﬀerent power level, in every node. Every node
forwards a packet to a destination using the smallest
power level to reach the destination. The drawback
for this protocol is the overhead to maintain all the
routing tables.
Further, there are well-known interactions
among protocols (see [23] and references therein).
Indeed with power control these interactions are
likely to be more tightly coupled. Interesting questions relate to which protocol should be responsible
for selecting the transmission power level. Techniques such as those suggested in Vadde et al. [24]
to optimize interactions may apply, but these questions are out-of-scope of this paper.

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

3. Carrier sense multiple access with power backoﬀ
(CSMA/PB)
In this section we introduce the basic form of our
carrier sense multiple access with power backoﬀ
(CSMA/PB) protocol, and provide a simulationbased evaluation of throughput and energy consumption. We begin by describing fundamental
assumptions about the network and CSMA
protocols.
3.1. Fundamental assumptions
Throughout the remainder of this paper, we
assume that each node of the network is identically
equipped with an omni-directional antenna and a
half-duplex transceiver operating on a single channel; thus, when a packet is transmitted, it is received
by all (non-transmitting) nodes within the transmission range of the transmitter. We further assume
that the radio transceiver in each node can be tuned
to a number of discrete power levels, with each
power level naturally corresponding to a unique
transmission range. The minimum and maximum
power levels are denoted by Pmin and Pmax respectively. In addition, we assume that the tuning of a
transceiver to a particular transmit power level
can be accomplished on a per-packet basis and that
tuning to a particular power level does not involve
any signiﬁcant cost.
Most CSMA protocols assume that the links are
bidirectional (i.e., symmetric). That is, communication is possible between nodes i and j if and only if
the transmission power levels of i and j are high
enough that j can receive from i, and i can receive
from j. If nodes are all transmitting at the same
power level, then this is a natural assumption,
though even then unidirectional links may exist
due to noise, interference, etc. When using power
control (and in contrast to the situation with typical
existing CSMA protocols) nodes often transmit at
diﬀering power levels, and unidirectional links may
occur. This asymmetry is addressed in the CSMA/
PB protocol design by adjusting transmission powers as necessary to avoid unidirectional links whenever it is reasonable to do so.
3.2. The basic CSMA/PB protocol
Using CSMA/PB, the transmission of each data
packet follows a four-way handshake with some
added elements related to power control. To

1237

describe the protocol, we consider a node s that
transmits a series of data packets. Let pi be the
power level utilized by s in transmitting the ith data
packet.
Suppose there are n transmission power levels,
Pmax = n and Pmin = 1. Initially, the transmission
power level of s is set to the maximum power level
(i.e., p1
Pmax). To transmit the ith data packet,
s ﬁrst senses the channel; if the channel is busy,
the node updates the network allocation vector
(NAV) as in IEEE 802.11. If the channel is free, s
transmits an RTS at power level pi. That RTS
includes the power level pi being used to transmit
the packet. Following that transmission there are
two cases:
(i) If s subsequently receives the corresponding
CTS, then the ith data packet is transmitted
at power level pi. If the transmission is successful, then s receives an ACK.
(ii) If s does not receive a CTS, then the RTS may
have been involved in a collision. In this case,
the current transmission power level (pi) of s is
reduced and s sends a new RTS at a reduced
power level if the channel is free.
The diﬀerence between our power backoﬀ and
temporal backoﬀ is that when a backoﬀ is needed,
temporal backoﬀ increases the contention window
size and waits for a period related to the window
size. Power backoﬀ reduces the transmission power
level. Both actions reduce contention, the ﬁrst in the
temporal domain, the second in the spatial domain.
The complete basic CSMA/PB transmitter and
receiver protocols appear in Figs. 2 and 3, respectively.
Similar to Karn [11], the power level pi is
included in the RTS. This is to avoid problems arising from unidirectional links that may result when
the transmitter and receiver use diﬀerent transmission power levels. By embedding the power level pi
in the RTS sent by s, when node r receives that
RTS, it can set the transmission power level for
sending the CTS packet to the level embedded in
the RTS packet that it received. Likewise, r will
use that same power level for the ACK packet that
ends a successful transmission.
An important issue in CSMA/PB is determining
the appropriate transmission power level for the
next packet (packet i + 1) in the series after a successful packet exchange. In IEEE 802.11, the contention window is reset to its minimum size after

1238

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

of packet i + 1. If that destination is the same as that
of packet i, then the transmission power level pi is
retained as the value of pi+1. If the destination is different, then the value of pi+1 is initialized to Pmax.
As in IEEE 802.11, when a neighbour z of s or r
overhears an RTS or a CTS packet associated with
the transmissions of s or of r, then node z sets its
NAV for the duration of the data-ACK transmission.
One potential diﬃculty with the CSMA/PB
protocol is that a node may be ‘‘unlucky’’ and
always sense a busy channel. In this case, the node
repeatedly decrements its transmission power level,
eventually setting its transmission power to the minimum possible level. A retry strategy is followed,
with the node able to reach a MAXRETRY number
of attempted transmissions before the packet is
dropped. In the basic CSMA/PB, the contention window (CW) is ﬁxed at 32 (the minimum in IEEE
802.11) and is never changed in the protocol. The
only purpose of this contention window is to introduce a small amount of jitter in the retry in case
nodes become synchronized.
3.3. Evaluation of the basic CSMA/PB

Fig. 2. Basic CSMA/PB transmitter protocol.

We evaluate the basic CSMA/PB protocol using
n = 3 transmission power levels, comparing its
performance to IEEE 802.11, in the ns-2 network
simulator version 2.26 [25]. Table 1 shows some
important simulation parameters. The carrier sense
threshold and receive threshold are set to the default
values in ns-2 and are constant. There are existing
power control schemes that use carrier sense threshold tuning algorithms (e.g. [19]) or even disable the
physical carrier sensing (e.g. [26]), however according to recent work by Kim et al. [27] tuning transmission power yields higher network capacity than
Table 1
Simulation parameters

Fig. 3. Basic CSMA/PB receiver protocol.

each successful four-way handshake. In CSMA/PB,
the value of pi+1 depends on the next hop destination

Data packet size
Transport protocol
Traﬃc arrival rate
Channel data rate
Simulation time
Antenna
Carrier sense threshold
Receive threshold

1000 bytes
UDP
0.5 Mbps
1 Mbps
200 s
Omni-directional
1.559E11 W
3.652E10 W

Transmission power level 3
Transmission power level 2
Transmission power level 1

0.2818 W (250 m)
7.214E3 W (100 m)
8.5872E4 W (40 m)

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

tuning carrier sense threshold. In this paper, we vary
the transmission power variable and hold the carrier
sensing threshold constant. Since the packet reception model in ns-2 is simplistic [28], the simulation
results of ns-2 can be optimistic. Multiple runs of
simulations with randomly generated seeds have
been performed to ensure a 95% conﬁdence for all
the data points with intervals of less than 5% that
plotted.
The network scenario consists of a 250 · 500 m
rectangle with 50 nodes, each moving according to
the (steady-state initialized) random way-point
mobility model at 2 m/s with a 2 s pause time [29].
We randomly select four nodes to generate two
ﬂows for a low traﬃc case, and 10 nodes to generate
ﬁve ﬂows for a high traﬃc case.
We compare the protocols using two metrics: the
total throughput (the total amount of data delivered
by all the ﬂows in the network) and the throughput
per unit energy (the total throughput divided by
the total amount of energy spent by all the nodes
in the network).

1239

Fig. 4 shows disappointing total throughput for
basic CSMA/PB compared to IEEE 802.11 in both
the low and the high traﬃc scenarios. More promising however, are the results in Fig. 5, showing comparable throughput per unit of energy of the two
protocols. While IEEE 802.11 may spend a signiﬁcant amount of time to deliver an individual packet,
CSMA/PB backs oﬀ in space relatively quickly in
time and may give up on a packet prematurely.
These observations suggest that the throughput of
CSMA/PB may improve if we revisit the element
of time in our backoﬀ strategy.
4. Extending CSMA/PB: combining spatial and
temporal backoﬀ
While spatial backoﬀ alone is promising, better
adaptation in some scenarios is required. For example, in a dense network with a large number of
active transmitters, most of the transmitters back
oﬀ to the minimum transmission power level. There
is no action that can be taken by basic CSMA/PB to
alleviate continued contention. This scenario motivates combining spatial backoﬀ with temporal
backoﬀ.
4.1. Spatial followed by temporal backoﬀ

Fig. 4. Total throughput for IEEE 802.11 and basic CSMA/PB
for a low and a high traﬃc scenario.

Fig. 5. Throughput per unit of energy for IEEE 802.11 and basic
CSMA/PB for a low and a high traﬃc scenario.

One way to combine spatial backoﬀ with temporal backoﬀ is to follow one approach by the other.
Fig. 6 shows a transmitter with n = 3 transmission
power levels, ﬁrst backing oﬀ in space. Once the
minimum power level is reached, the transmitter
then backs oﬀ in time using binary exponential
backoﬀ. The size of the contention window doubles,
permitting nodes to use the time dimension once the
space dimension is exhausted. Retransmissions
always occur at the minimum power level. Spatial
followed by temporal backoﬀ is accomplished by
replacing line 26 in Fig. 2 with the statements in
Fig. 7. The contention window is reset (line 7 in

Fig. 6. Spatial followed by temporal backoﬀ.

1240

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

overheard packet and its current transmission
power level.
4.3. Alternating temporal and spatial backoﬀ
Fig. 7. To implement spatial followed by temporal backoﬀ
replace line 26 in Fig. 2 by these statements.

Fig. 2) to the minimum size whenever a new packet
arrives.

4.2. Alternating spatial and temporal backoﬀ
Another way to combine spatial backoﬀ with
temporal backoﬀ is to alternate approaches. Fig. 8
illustrates backing oﬀ in space followed by backing
oﬀ in time. When the minimum transmission power
level is reached, the size of the contention window is
doubled. Spatial backoﬀ is then run using the larger
contention window. This alternating sequence may
be repeated until the contention window reaches
its maximum size. Spatial backoﬀ alternating with
temporal backoﬀ is accomplished by replacing line
26 in Fig. 2 with the statements in Fig. 9.
In this combined approach asymmetric links are
more likely to arise. This is because each step of
backoﬀ can involve a change in the transmission
power level. A copy mechanism may be used to alleviate this problem. In this variant of the protocol,
whenever a node overhears a transmission, it sets
its transmission power level to the minimum of the

Of course, backoﬀ could instead occur in the
temporal domain ﬁrst. This is illustrated in
Fig. 10. In order for such an approach to be practical, the maximum contention window size CWmax is
reduced to 256 from 1024 used in IEEE 802.11. As
before, replacing line 26 in Fig. 2 by the statements
in Fig. 11 implements the alternation of temporal
and spatial backoﬀ.
4.4. Discussion
Of these three approaches to combining spatial
and temporal backoﬀ, in an active and dense network, the ﬁrst approach aggressively reduces the
transmission power to the minimum level. If sources
and destinations of ﬂows are far apart, this encourages longer paths with short hops to be utilized.
When alternating approaches to backoﬀ, asymmetric links are more likely to arise when backing
oﬀ in the spatial domain ﬁrst. Nodes using high
transmission power levels have an advantage in
gaining access to the channel over nodes using low
transmission power levels because high power nodes
may be hidden to low power nodes (recall Fig. 1).
Starting the alternation by backing oﬀ in time is
the most conservative combination, essentially

Fig. 8. Alternating spatial and temporal backoﬀ.

Fig. 10. Alternating temporal and spatial backoﬀ.

Fig. 9. To implement alternating spatial and temporal backoﬀ
replace line 26 in Fig. 2 by these statements.

Fig. 11. To implement alternating temporal and spatial backoﬀ
replace line 26 in Fig. 2 by these statements.

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

running IEEE 802.11 at each of the n transmission
power levels.
5. Evaluation of the extensions of CSMA/PB
We evaluate the three extensions of CSMA/PB
presented in Section 4, comparing their performance
to IEEE 802.11 in the ns-2 network simulator [25].
The simulation parameters used are the same as
used in the evaluation of basic CSMA/PB (see Table
1); n = 3 transmission power levels are assumed.
The variants of CSMA/PB use: spatial followed
by temporal backoﬀ (‘‘direct’’); alternating spatial
and temporal backoﬀ (‘‘power ﬁrst’’); alternating
temporal and spatial backoﬀ (‘‘time ﬁrst’’); and
‘‘power ﬁrst’’ with a copy mechanism (PFwC) to
alleviate asymmetric links.
5.1. Power-aware routing
If the routing protocol does not take into account
variation in transmission power levels it will use
unnecessary paths when the transmission power is
high and have no path to use when the transmission
power is low. Therefore, routing must be poweraware.
Let w(vi, vj) denote the transmission power
needed for node vi to transmit in one hop to vj; this
is inﬁnity if no such power level exists. Then for
each s–t ﬂow and each transmission power level q,
1 6 q 6 n, a path s = v0, v1 P
. . . vk = t is found such
k1
that w(v0, v1) 6 q and q þ j¼1 wðvj ; vjþ1 Þ is minimized. Fig. 12 illustrates the idea of the poweraware routing protocol.
A two-dimensional routing table T[1. . (N 
1), 1 . . n] at each node contains entries for each of
the other N  1 destinations at each of the n power
levels. T[t, q] speciﬁes the next-hop node on the path

Fig. 12. Idea of power-aware routing: The cost of the ﬁrst hop
depends on the transmission power level. Total power consumption is then minimized.

1241

to t at transmission power level q; if the path weight
is inﬁnity then there is no path whose ﬁrst hop is at
power q. If n = 1 (as in IEEE 802.11), then the computed path is a minimum hop-count path.
In this power-aware routing protocol, if node vi
receives a packet to forward towards destination t,
the next hop node vi+1 depends on the transmission
power level q used by vi. Node vi selects vi+1 = T[t, q]
as the next hop node. The value of q is determined
by CSMA/PB. If CSMA/PB changes the transmission power level then this may change the next
hop node through which the packet is routed.
We illustrate the operation of the routing protocol using the sample network in Fig. 13. Assume
that there are n = 3 transmission power levels. The
cost of a link using transmission power level i is
equal to i for i = 1, . . ., 3. For simplicity, assume
that there are no other links except those shown in
the ﬁgure.
Suppose that we want to route a packet from
node A to node E. For the intermediate transmission power level (q = 2), the candidate next-hop
nodes with ﬁrst-hop less than or equal to transmission power level 2 are nodes B and C. Via node B,
the minimum weight path is ABE with
w(A, B) + w(B, E) = 2 + 3 = 5. Via node C, the minimum weight path is ACE with w(A, C) + w(C, E) =
2 + 3 = 5. Therefore the next-hop node for destination E using transmission power level 2 is C (B is
equally good in this small example). A route from
node A to node E using the highest transmission
power level has candidate next-hop nodes of B, C,
and D, among which the minimum cost path is
ADE with w(A, D) + w(D, E) = 3 + 2 = 5. Thus,
the entry in the routing table for node A is
T[E, 3] = D. Table 2 shows the complete routing
table for node A.

Fig. 13. A sample network to illustrate the idealized power-aware
routing protocol.

1242

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

Table 2
Routing table for node A for the sample network of Fig. 13
Destination
node

Next hop at
q=1

Next hop at
q=2

Next hop at
q=3

B
C
D
E

B
B
B
B

B
C
C
C

B
C
D
D

It is possible that for some source s and destination t, there is no next-hop node for a given transmission power level q. In this case, the entry T[t, q]
in the routing table at s is set to inﬁnity. In our
implementation, CSMA/PB skips these transmission power levels as no next-hop node is available.
Our implementation of the power-aware routing
protocol is centralized. It was designed to explore
the potential of a MAC protocol that utilizes transmission power control. The design of a distributed
power-aware routing protocol for this purpose is
out-of-scope of this paper.
In the following several subsections we compare
the performance of CSMA/PB and IEEE 802.11
under increasingly complex network topologies.
5.2. Static chain topology

6, and 10, respectively. The second scenario has
two multi-hop ﬂows from nodes 1 and 2 to nodes
9 and 10, respectively.
Fig. 15 plots throughput in the single-hop ﬂow
scenario. All variants of CSMA/PB outperform
IEEE 802.11 except ‘‘time ﬁrst’’ which decreases
transmission power too slowly to exploit the potential for spatial reuse. In this scenario, all three ﬂows
can transmit simultaneously if the lowest transmission power is used. The ‘‘power ﬁrst with copy’’ performs the best, as the nodes reach the lowest
transmission power level quickly. The copy mechanism accelerates this decrease since once a node
successfully transmits at minimum power, the overhearing neighbours copy this power level. The
‘‘direct’’ protocol does not use the copy mechanism
and therefore takes slightly longer for all the nodes
to reach the minimum transmission power.
Fig. 16 shows larger absolute diﬀerences in
throughput per unit energy. Here, signiﬁcant gains
can be seen; even ‘‘time ﬁrst’’ is 30% higher than
IEEE 802.11. Table 3 shows the number of packets
transmitted at each power level in each of the ﬁve
protocols. The packets transmitted at lower transmission power levels yield signiﬁcant gains in energy
and throughput per unit energy.

We ﬁrst consider two scenarios for a static chain
topology where ten nodes are arranged in a line 30m
apart (see Fig. 14). The ﬁrst scenario has three single-hop ﬂows from nodes 1, 5, and 9 to nodes 2,

Fig. 14. Chain topology with single-hop and multi-hop ﬂows.

Fig. 16. Throughput/energy in chain topology with single-hop
ﬂows.

Table 3
Number of packets transmitted at each transmission power level,
chain topology, single-hop ﬂows

Fig. 15. Throughput in chain topology with single-hop ﬂows.

Protocol

0.2818 W
(250 m)

7.214E3 W
(100 m)

8.5872E4 W
(40 m)

IEEE 802.11
Direct
Power ﬁrst
Power ﬁrst
with copy
Time ﬁrst

81,102
8
12,274
12

0
11,388
55,139
78

0
113,381
56,604
124,876

65,838

18,179

5051

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

1243

Table 4
Number of packets transmitted at each transmission power level,
chain topology, multi-hop ﬂows
Protocol

0.2818 W
(250 m)

7.214E3 W
(100 m)

8.5872E4 W
(40 m)

IEEE 802.11
Direct
Power ﬁrst
Power ﬁrst
with copy
Time ﬁrst

79,635
22,636
39,425
23,535

0
8186
21,237
20,204

0
66,445
34,363
60,051

36,908

27,033

22,023

Fig. 17. Throughput in chain topology with multi-hop ﬂows.

Fig. 17 shows the throughput achieved in the
chain topology with multi-hop ﬂows. All variants
of CSMA/PB suﬀer because the multi-hop ﬂows
compete with each other. Nodes using higher transmission power levels gain access to the channel over
nodes using lower transmission power. In ‘‘power
ﬁrst’’ and ‘‘time ﬁrst,’’ nodes can use high transmission power more frequently than the other two
CSMA/PB protocols, thus their throughput is
higher. However, as expected, they also consume
more energy.
Despite this, Fig. 18 shows that all variants of
CSMA/PB obtain higher throughput per unit
energy than IEEE 802.11. Table 4 shows the number of packets transmitted at each power level.
‘‘Direct’’ and ‘‘power ﬁrst with copy’’ consume the
least energy; while their throughput suﬀers from
taking short hops to the destination they achieve
better throughput per unit energy.

and a single inter-group ﬂow between a pair of
nodes 200m apart (see Fig. 19).
Fig. 20 shows throughput for the static cluster
topology. All variants of CSMA/PB except ‘‘time
ﬁrst’’ obtain higher throughput than IEEE 802.11.
With spatial backoﬀ, concurrency within clusters
leads to higher throughput. Fig. 21 shows that
‘‘direct’’ and ‘‘power ﬁrst with copy’’ obtain the
highest throughput per unit energy. These values
are dramatically higher than those for 802.11. Table
5 shows the number of packets transmitted at each
transmission power level for this topology.

5.3. Static cluster topology
Next we consider a static cluster topology in
which there are two groups of ﬁve nodes, each with
two intra-group ﬂows between nodes 30m apart,

Fig. 19. Static cluster topology.

Fig. 18. Throughput/energy in chain topology with multi-hop
ﬂows.

Fig. 20. Throughput in static cluster topology.

1244

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

Fig. 21. Throughput/energy in a static cluster topology.

Fig. 23. Throughput in a MANET with multi-hop ﬂows.

Table 5
Number of packets transmitted at each transmission power level,
static cluster topology

802.11 there is no concurrency among the ﬁve ﬂows,
while in CSMA/PB the ﬂows can run concurrently.
Among the CSMA/PB variants, ‘‘direct’’ suﬀers the
most since in this protocol nodes tend to back oﬀ to
minimum power very often, increasing the number
of hops along the path. The same is true of ‘‘power
ﬁrst with copy’’ and ‘‘time ﬁrst,’’ except that they
are less aggressive in backing oﬀ in power, so each
obtains a slight increase in throughput. The
throughput for ‘‘power ﬁrst’’ is unexpectedly high.
While this variant of CSMA/PB can suﬀer from a
large number of asymmetric links, this seems to be
an advantage when the network is busy and all of
the ﬂows are multi-hop. At any given time retries
from nodes with high transmission power levels
are more likely to succeed because they literally
over-power nodes with low transmission power.
Compared to IEEE 802.11, there are fewer nodes
transmitting at high power, and thus there are fewer
nodes competing for the channel. Furthermore,
since in ‘‘power ﬁrst’’, a node’s contention window
increases only after a round of power backoﬀ, the
average contention window size is expected to
increase slower than IEEE 802.11. These observations likely explain why ‘‘power ﬁrst’’ outperforms
IEEE 802.11. The throughput per unit energy of
all variants of CSMA/PB dramatically outperform
IEEE 802.11 in the mobile scenario (see Fig. 24).
Table 6 shows the number of packets transmitted
at each power level.

Protocol

0.2818 W
(250 m)

7.214E3 W
(100 m)

8.5872E4 W
(40 m)

IEEE 802.11
Direct
Power ﬁrst
Power ﬁrst
with copy
Time ﬁrst

83351
796
11,433
1361

0
57,583
99,412
102,804

0
83,528
16,040
29,629

22,560

84,014

15,726

5.4. Mobile ad hoc network
In this scenario we consider a mobile ad hoc network (MANET) with 60 nodes in a 500 · 250 m
area. There are 50 nodes, each moving according
to the (steady-state initialized) random way-point
mobility model at 2 m/s with a 2 s pause time [29].
Between the remaining ten nodes, we establish ﬁve
ﬂows, one from each of ﬁve ﬁxed sources positioned
evenly along the left-hand edge of the rectangular
area to destinations positioned directly across on
the right-hand side of the area (see Fig. 22).
Fig. 23 shows the throughput in this scenario. All
variants of CSMA/PB obtain higher throughput
than IEEE 802.11. This is no surprise since in IEEE

5.5. Summary

Fig. 22. Multi-hop ﬂows in a mobile ad hoc network.

The simulation results in this section demonstrate
convincingly the eﬀectiveness of using the dimension
of space in the backoﬀ strategy. The power backoﬀ
protocols show excellent throughput per unit energy
when compared to IEEE 802.11. The ‘‘direct’’ and
‘‘power ﬁrst with copy’’ are aggressive protocols.

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

1245

6. Probability of success: temporal versus spatial
backoﬀ strategies
In this section we analyze the probability of successful transmission using a temporal backoﬀ strategy and also a spatial backoﬀ strategy.
6.1. Temporal and spatial backoﬀ strategies

Fig. 24. Throughput/energy in a MANET with multi-hop ﬂows.

Table 6
Number of packets transmitted at each transmission power level,
mobile ad hoc scenario
Protocol

0.2818 W
(250 m)
250 m

7.214E3 W
(100 m)
100 m

8.5872E4 W
(40 m)
40 m

IEEE 802.11
Direct
Power ﬁrst
Power ﬁrst
with copy
Time ﬁrst

73,408
26,716
58,704
55,651

0
57,135
25,842
26,685

0
35,977
4286
6618

41,082

53,807

12,149

In the scenarios examined, they always perform
among the best in throughput per unit of energy
beneﬁtting from the energy saved by utilizing small
transmission power levels. The ‘‘power ﬁrst’’ variant
can suﬀer from creating asymmetric links, however
this seems to be an advantage in some mobile
multi-hop scenarios. The ‘‘time ﬁrst’’ is the most
conservative variant of CSMA/PB. Its performance
is similar to IEEE 802.11 if the channel is not busy.
In a busy and dense multi-hop network, it is among
the best strategies to use.
While power backoﬀ protocols are successful on
improving throughput and throughput per unit of
energy globally, fairness issues arise from using variable power control. From Table 6 we see that in a
general mobile ad hoc network scenario, the number of packets transmitted at a high power level
are more than that transmitted at a low power level,
suggesting that high power transmissions are more
likely to be successful than low power transmissions. This can be explained by the new hidden terminal problems that arise from asymmetric links
(recall Fig. 1). We analyze this problem in more
detail in the next section. In this paper our goal is
to optimize throughput and throughput per unit
of energy without regard to fairness.

The main goal of backoﬀ is to resolve contention
and reduce the probability of collisions. We measure
the eﬀectiveness of temporal backoﬀ and spatial
backoﬀ by Psuccess, the probability of a node having
a successful transmission in the current transmission
frame.
Assuming a CSMA-based protocol, a transmission frame consists of a two-way or a four-way
handshake: RTS-CTS-data-ACK or data-ACK.
For simplicity, we consider a two-way handshake.
If the data and the ACK are both received properly,
the transmission is successful. We use this probability as the metric because the average Psuccess in the
network represents the throughput for the network.
The higher this probability, the higher the network
throughput.
We use the following notation:
Ptransmit. The probability of transmission; this
represents the probability of a node transmitting
at the beginning of the current transmission
frame.
Pidle. The probability that the channel is idle.
Psilent. The probability of a node remaining silent
in the current transmission frame.
Ri. The transmission range corresponding to
transmission power level i; Rmax is the maximum
transmission range.
D. The density of nodes in the network.
Pactive. The probability of nodes in the network
being active, i.e., they have packets (either data
or control packets) queued for transmission.
First we compute Psuccess for a temporal backoﬀ
strategy. In the CSMA protocol, in order for a
packet to be transmitted correctly from the source
node s to the (one-hop) destination node t, two conditions must be satisﬁed:
(i) The source node s transmits in the current
transmission frame, i.e., its backoﬀ timer
expires before this frame starts. This condition
ensures the initiation of the handshake.

1246

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

(ii) The channel is idle around the destination
node t, i.e., none of its neighbours is transmitting. In this case, the data packet is decoded
correctly resulting in an ACK packet as a
response.
All nodes, except t, receiving the data packet sent
by s update their NAV and remain silent. This
allows s to successfully receive the ACK (for simplicity, we do not consider nodes moving into or
out of the transmission range of node s). If these
two conditions are satisﬁed, a handshake is completed successfully. Therefore,
P success ¼ P transmit  P idle :

Fig. 25. Rings of node s (located at the center).

ð1Þ

Assume the current contention window size for
node s is CWs, then
P transmit

1
2
¼
¼
;
backoff timer value CWs

ð2Þ

since the value of the backoﬀ timer is a random
number in the range [0, CWs). The probability that
the neighbours of the destination node t remain
silent is
ðnumber of active neighboursÞ

P idle ¼ P silent

;

s must refrain from transmission for the duration of the transmission if its transmission
range is greater than or equal to Ri. Here,
Ringi is the area at distance greater than Ri1
and less than or equal to Ri. Fig. 25 shows
Ringi for i = 2, 3. Ring1 = R1.

ð3Þ

where the number of active neighbours is given by
D · p · Rmax2 · Pactive. In order to calculate the
probability for neighbours to remain silent, we
assume that the contention window size for neighbours of s is, on average, CWavg. The average
backoﬀ timer value is CWavg/2, therefore P silent ¼
1  CW2avg .
This allows Eq. (1) to be rewritten as

DpR2max P active
2
2
P success ¼
 1
:
ð4Þ
CWs
CWavg
Next, we consider the case where a spatial backoﬀ strategy is employed. Eqs. (1) and (2) still hold.
Let us assume that the current transmission range
of the source node s is Rs. Now, three conditions
must be satisﬁed:
(i) The source node s is transmitting in the current transmission frame.
(ii) For each transmission power level i, each node
within a distance of Ri of the destination node
t must refrain from transmission if its current
transmission range is greater than or equal to Ri.
(iii) For each transmission power level i, where
Ri > Rs, each node in the area Ringi of node

The ﬁrst two conditions ensure that the data
packet transmitted by s is received by t correctly.
The third condition is used to handle the hidden terminal problem that can arise when variable-range
transmission power levels are used (recall Fig. 1
and the associated discussion). The receipt of an
ACK at node s may suﬀer interference from a high
power transmission outside of the range of s. We
must ensure that all nodes in the area described in
condition (3) remain silent.
Similar to Eq. (3), the probability that the second
condition holds is
DpP active

P condition2 ¼ P silent

n
P
i¼1

R2i P Ri

ð5Þ

;

where P Ri is the probability of a node using a transmission range of Ri, and n is the number of transmission ranges available.
For each ring Ringi, the probability for all nodes
in Ringi to refrain from transmission if their transmission range is greater than or equal to Ri, denoted
P idle;Ringi , is
P idle;

Ringi

DpðR2 R2i1 ÞP active P PRi

¼ P silenti

;

ð6Þ

where P PRi is the probability of a node using a
transmission range greaterPthan or equal to Ri. This
n
can be written as P PRi ¼ j¼i P Rj .

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

Combining Eqs. (1), (2), (5), and (6), we have
b

DpP active P R2i P Ri
2
2
i¼1
 1
P success ¼
CWs
CWavg
DpðR2i R2i1 ÞP active P PRi
Y 
2

1
:
CWavg
i;Ri >Rs

0.012

X

ðR2i  R2s ÞP Ri :

ð9Þ

i;Ri >Rs

i¼1

6.2. Discussion
The probability of successful transmission by a
node using temporal backoﬀ and spatial backoﬀ is
given by Eqs. (4) and (8), respectively. In both cases
Pactive and D represent, to some extent, the magnitude of contention in the network. If no backoﬀ
strategy is used, i.e., all contention window sizes
and transmission ranges remain constant, the probability of success decreases as Pactive and D increase.
For temporal backoﬀ, increasing the ﬁrst term CWs
decreases the ﬁrst part of Eq. (4). However, when
0.012

5

Average CW 2
Average CW 25.5
Average CW 26
Average CW 26.5
Average CW 27

Probability of success

0.01

0.008

0.006

0.004

0.002

0
0.5

0.55

0.6

0.65

0.7

0.75

0.8

0.004

0

where the exponential
factor E is
þ
P
Pn
2
2
i;Ri >Rs ðRi  Ri1 Þ P
j¼i P Rj . The second term of E
can be rewritten as i;Ri >Rs ðR2i  R2s ÞP Ri . This allows
the expression for E to be simpliﬁed as
R2i P Ri þ

0.006

Active nodes ratio 50%
Active nodes ratio 60%
Active nodes ratio 70%
Active nodes ratio 80%
Active nodes ratio 90%
Active nodes ratio 100%

0.002

2
i¼1 Ri P Ri

n
X

0.008

ð8Þ
Pn

E¼

Probability of success

0.01

ð7Þ
Rearranging this equation we obtain

DpP active E
2
2
P success ¼
 1
;
CWs
CWavg

1247

0.85

0.9

0.95

1

Active nodes ratio

Fig. 26. Probability of success using temporal backoﬀ varying
the ratio of active nodes.

5

5.5

6

6.5

7

7.5

8

Average CW size(log)

Fig. 27. Probability of success using temporal backoﬀ varying
contention window size.

CWs increases, CWavg for other nodes also
increases, which increases the second part of Eq. (4).
Figs. 26 and 27 plot the probability of success
using temporal backoﬀ under diﬀerent active node
ratios and contention window sizes, respectively.
Here, we assume a density D of 50 nodes in an area
of 500 · 300 m and a transmission range of 250
meters for all nodes. As the active node ratio
increases, the probability of a successful transmission decreases because there is more contention in
the network. The probability of a successful transmission rises as the contention window size
increases when the CW size is low, and then drops
when the CW size is high. This is because when
the contention window size is high, a node transmits
less frequently. There is an optimal CW window size
for each active node ratio. For an active node ratio
of 50%, this value is around 26. When the active
node ratio is 100%, it increases to around 27.2.
Although we assume node density is constant, we
can interchange the active node ratio with the node
density in Figs. 26 and 27. What really aﬀects the
results is the product of these two factors.
For a spatial backoﬀ strategy, assuming the CW
size is constant, the probability of successful transmission depends solely on the value of the exponential factor E in Eq. (8). From Eq. (9), E is a function
of the distribution of transmission power in the network, and the current transmission power. Consider
a network with the same density used in temporal
backoﬀ. Assume there are three transmission power
levels with transmission ranges corresponding to
250, 100, and 40 m. Consider three distributions of
transmission power levels: a high, medium, and

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

low power scenario where 80% of the nodes use high,
medium, or low transmission power, respectively,
with 10% at each of the two remaining transmission
power levels. In all three scenarios, the contention
window size is ﬁxed at 32. Figs. 28–30 show the
probability of successful transmission given each of
these transmission power distributions.
As expected, the probability of a successful transmission decreases as the active node ratio increases.
In all three cases, the nodes transmitting at a high
transmission power level achieve a high probability
of success. This is because these nodes can be hidden
to nodes transmitting at low transmission power

0.06
40 m
100m
250m
Average

0.05

Probability of success

1248

0.04

0.03

0.02

0.01

0
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Active nodes ratio

Fig. 30. Probability of successful transmission in spatial backoﬀ
as a function of the active node ratio; low power scenario.

0.06
40 m
100m
250m
Average

Probability of success

0.05

levels. The average probability of successful transmission increases as the percentage of nodes transmitting at low transmission power level increases.
When the active node ratio is 100%, the average
probability of success for the low power scenario
is around 10 times higher than the high power scenario. The results of the analysis conﬁrm the potential of space as a means to improve the probability
of successful transmission.

0.04

0.03

0.02

0.01

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Active nodes ratio

7. Conclusions

Fig. 28. Probability of successful transmission using spatial
backoﬀ as a function of the active node ratio; high power
scenario.

0.06
40 m
100m
250m
Average

Probability of success

0.05

0.04

0.03

0.02

0.01

0
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Active nodes ratio

Fig. 29. Probability of successful transmission using spatial
backoﬀ as a function of the active node ratio; medium power
scenario.

In this paper, we propose an alternate approach
to collision resolution in a CSMA protocol, namely
the use of power control to resolve collisions by
backing oﬀ in space. In order to improve performance of the basic protocol under dense or active
network conditions, we combine our power backoﬀ
(PB) approach in a CSMA protocol, CSMA/PB,
with temporal backoﬀ. Simulation results for a variety of static and mobile mobile ad hoc network scenarios show that CSMA/PB always outperforms
IEEE 802.11 in throughput per unit energy, often
by a signiﬁcant margin. Analysis conﬁrms the
potential of exploiting the dimension of space in
medium access control.
We caution that these strong results are based on
a centralized power-aware routing strategy that illustrates the potential of power backoﬀ. This suggests
that an investigation of CSMA/PB with a distributed power-aware routing protocol is warranted.
While asymmetric links seem undesirable, the mobile
scenario seems able to take advantage of them. More

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

investigation is needed to understand when and how
asymmetry can be helpful.
Disclaimer
The views and conclusions contained in this document are those of the authors and should not be
interpreted as representing the oﬃcial policies,
either expressed or implied, of the Army Research
Laboratory or the US Government or the National
Science Foundation.
Acknowledgements
We are grateful to the anonymous referees for
their careful reading of and helpful comments for
our paper. The research of V.R. Syrotiuk is supported, in part, by NSF ANI-0240524 and ITR0220001.
References
[1] J.T. Gomez, A. Campbell, A case for variable-range transmission power control in wireless multihop networks, in:
Proceedings of the 23rd Annual Joint Conference of the
IEEE Computer and Communications Societies (Infocom’04), vol. 2, 2004, pp. 1425–1436.
[2] J. Gomez, A.T. Campbell, A case for variable-range transmission power control in wireless multihop networks, IEEE
Transactions on Mobile Computing 6 (1) (2007) 87–99.
[3] D. Aldous, Ultimate stability of exponential backoﬀ protocol for acknowledgment based transmission control of
random access communication channels, IEEE Transactions
on Information Theory 33 (2) (1987) 219–223.
[4] F.P. Kelly, Stochastic models of computer communication
systems, Journal of the Royal Statistical Society (B) 47
(1985) 379–395.
[5] J. Hastad, F.T. Leighton, B. Rogoﬀ, Analysis of backoﬀ
protocols for multiple access channels, in: Proceedings of the
ACM Symposium on the Theory of Computing, 1987, pp.
241–253.
[6] A. Nasipuri, J. Zhuang, S.R. Das, A multichannel CSMA
MAC protocol for multihop wireless networks, in: Proceedings of IEEE Wireless Communications and Networking
Conference (WCNC’99), 1999, pp. 1402–1406.
[7] A. Nasipuri, S.R. Das, Multichannel CSMA with single
power-based channel selection for multihop wireless networks, in: Proceedings of IEEE Vehicular Technology
Conference (VTC’00), 2000, pp. 211–218.
[8] J. So, N.H. Vaidya, Multi-channel MAC for ad hoc
networks: handling multi-channel hidden terminals using a
single transceiver, in: Proceedings of ACM International
Symposium on Mobile Ad Hoc Networking and Computing
(MobiHoc’04), 2004, pp. 222–233.
[9] Z. Tang, J.J. Garcia-Luna-Aceves, Hop-reservation multiple
access (HRMA) for ad-hoc networks, in: Proceedings of the
18th Annual Joint Conference of the IEEE Computer and
Communications Societies (Infocom’99), 1999, pp. 194–201.

1249

[10] A. Tzamaloukas, J.J. Garcia-Luna-Aceves, A receiver-initiated collision-avoidance protocol for multi-channel networks, in: Proceedings of the 20th Annual Joint
Conference of the IEEE Computer and Communications
Societies (Infocom’01), 2001, pp. 189–198.
[11] P. Karn, MACA – a new channel access method for packet
radio, in: Proceedings of the Ninth ARRL/CRRL Amateur
Radio Computer Networking Conference, 1990, pp. 134–
140.
[12] E.-S. Jung, N.H. Vaidya, A power control MAC protocol
for ad hoc networks, in: Proceedings of the Eighth ACM
International conference on Mobile Computing and Networking (Mobicom’02), 2002, pp. 36–47.
[13] J.P. Monks, V. Bharghavan, W.-M. Hwu, A power controlled multiple access protocol for wireless packet networks,
in: Proceedings of the 20th Annual Joint Conference of the
IEEE Computer and Communications Societies (Infocom’01), 2001, pp. 219–228.
[14] A. Muqattash, M. Krunz, Power controlled dual channel
(PCDC) medium access protocol for wireless ad hoc
networks, in: Proceedings of the 22nd Annual Joint Conference of the IEEE Computer and Communications Societies
(Infocom’03), 2003, pp. 470–480.
[15] A. Muqattash, M. Krunz, A single-channel solution for
transmission power control in wireless ad hoc networks, in:
Proceedings of the Fifth ACM International Symposium on
Mobile Ad Hoc Networking and Computing (MobiHoc’04),
2004, pp. 210–221.
[16] S. Wu, Y. Tseng, J. Sheu, Intelligent medium access for
mobile ad hoc networks with busy tones and power control,
IEEE Journal on Selected Area on Communications 18 (9)
(2000) 1647–1657.
[17] J. Fuemmeler, N.H. Vaidya, V.V. Veeravalli, Selecting
Transmit Powers and Carrier Sense Thresholds for CSMA
Protocols, Technical Report, University of Illinois, Urbana–
Champaign, October 2004.
[18] B. Chu, Improving IEEE 802.11 Performance with Power
Control and Distance Based Contention Window Selection,
Master’s Thesis, University of Illinois, Urbana–Champaign,
2005.
[19] X. Yang, N.H. Vaidya, On physical carrier sensing in
wireless ad hoc networks, in: Proceedings of the 24th Annual
Joint conference of the IEEE Computer and Communications Societies (Infocom’05), vol. 4, 2005, pp. 2525–2535.
[20] J. Gomez, A.T. Campbell, M. Naghshineh, C. Bisdikian,
PARO: supporting dynamic power controlled routing in
wireless ad hoc networks, Wireless Networks 9 (5) (2003)
443–460.
[21] S. Narayanaswamy, V. Kawadia, R.S. Sreenivas, P.R.
Kumar, Power control in ad-hoc networks: theory, architecture, algorithm and implementation of the COMPOW
protocol, in: Proceedings of the European Wireless Conference, 2002, pp. 156–162.
[22] V. Kawadia, P.R. Kumar, Power control and clustering in ad
hoc networks, in: Proceedings of the 22nd Annual Joint
conference of the IEEE Computer and Communications
Societies (Infocom’03), 2003, pp. 459–469.
[23] K.K. Vadde, V.R. Syrotiuk, Factor interaction on service
delivery in mobile ad hoc networks, IEEE Journal on
Selected Areas on Communciations 22 (7) (2004) 1335–1346.
[24] K.K. Vadde, V.V. Syrotiuk, D.C. Montgomery, Optimizing
protocol interaction using response surface methodology,

1250

[25]
[26]

[27]

[28]

[29]

C.J. Colbourn et al. / Ad Hoc Networks 5 (2007) 1233–1250

IEEE Transactions on Mobile Computing 5 (6) (2006) 627–
639.
The network simulator – ns-2, University of California,
Berkeley. http://www.isi.edu/nsname/ns/.
M. Cesana, D. Maniezzo, P. Bergamo, M. Gerla, Interference aware (IA) MAC: an enhancement to IEEE 802.11b
DCF, in: Proceedings of the IEEE Vehicular Technology
Conference (VTC-Fall’03), vol. 5, 2003, pp. 2799–2803.
T. Kim, J.C. Hou, H. Lim, Improving spatial reuse through
tuning transmit power, carrier sense threshold, and data rate
in multihop wireless networks, in: Proceedings of the 12th
Annual International conference on Mobile Computing and
Networking (Mobicom’06), 2006, pp. 366–377.
Q. Chen, D. Jiang, V. Taliwal, L. Delgrossi, IEEE 802.11
based vehicular communication simulation design for ns-2,
in: Proceedings of the Third International Workshop on
Vehicular Ad Hoc Networks (VANET’06), 2006, pp. 50–56.
W. Navidi, T.K. Camp, Stationary distributions for the
random waypoint mobility model, IEEE Transactions on
Mobile Computing 3 (1) (2004) 99–108.

Charles J. Colbourn earned his M.Math.
in 1978 from the University of Waterloo,
and his Ph.D. in 1980 from the University of Toronto, both in Computer Science. He has held academic positions at
the University of Saskatchewan, the
University of Waterloo, the University
of Vermont, and is currently a Professor
of Computer Science and Engineering at
Arizona State University. Dr. Colbourn
is the author of The Combinatorics of
Network Reliability (Oxford) and Triple Systems (Oxford). He is
editor-in-chief of the Journal of Combinatorial Designs and
serves on the editorial boards of Networks, Discrete Mathematics, Journal of Combinatorial Theory (A), Designs, Codes and
Cryptography, and others. He edited the standard reference work
The CRC Handbook of Combinatorial Designs. He is the author
of more than 250 refereed journal papers focussing on combinatorial designs and graphs with applications in networking,
computing, and communications. In 2004, he was awarded the
Euler Medal for Lifetime Research Achievement by the Institute
for Combinatorics and its Applications.

Minghao Cui received his B.E. in Computer Science and Engineering from
Harbin Institute of Technology, China,
in 2002, and M.S. in Computer Science
and Engineering from Arizona State
University, in 2004. He is currently a
Ph.D. student in Computer Science and
Engineering at Arizona State University.
His research interests include mobile ad
hoc networks and computing, medium
access control protocols with an emphasis on transmit power control and cooperative transmission.

Errol Lloyd is a Professor of Computer
and Information Sciences at the University of Delaware. Previously he served
as a faculty member at the University of
Pittsburgh and as Program Director for
Computer and Computation Theory at
the National Science Foundation. From
1994 to 1999 he was Chair of the
Department of Computer and Information Sciences at the University of Delaware. Concurrently, from 1997 to 1999
he was Interim Director of the University of Delaware Center for
Applied Science and Engineering in Rehabilitation. Professor
Lloyd received undergraduate degrees in both Computer Science
and Mathematics from Penn State University, and a Ph.D. in
Computer Science from the Massachusetts Institute of Technology. His research expertise is in the design and analysis of algorithms, with a particular concentration on network algorithms. In
1989 Professor Lloyd received an NSF Outstanding Performance
Award, and in 1994 he received the University of Delaware
Faculty Excellence in Teaching Award.

Violet R. Syrotiuk (M’96/ACM’93)
earned her Ph.D. in Computer Science
from the University of Waterloo (Canada) in 1992. She joined Arizona State
University in 2002 and is currently an
Associate Professor of Computer Science
and Engineering. Dr. Syrotiuk’s research
is currently supported by two grants
from NSF, and contracts with Los Alamos National Laboratory and Defence
Science and Technology Organisation
(Australia). She serves on the Editorial Board of Computer
Networks, and on the Technical Program Committee of several
major conferences including Mobicom, Mobihoc, and Infocom.
Her research interests include MAC and higher layer protocols
for multi-hop wireless networks.

Ad Hoc Networks 8 (2010) 767–777

Contents lists available at ScienceDirect

Ad Hoc Networks
journal homepage: www.elsevier.com/locate/adhoc

Time–space backoff for fair node throughput in wireless networks
using power control
Minghao Cui, Violet R. Syrotiuk *
School of Computing, Informatics and Decision Systems Engineering, Arizona State University, P.O. Box 878809, Tempe, Arizona 85287-8809, United States

a r t i c l e

i n f o

Article history:
Received 8 November 2007
Received in revised form 11 January 2010
Accepted 16 February 2010
Available online 21 February 2010
Keywords:
Carrier sense multiple access (CSMA)
Contention resolution
Backoff algorithm
Time–space backoff

a b s t r a c t
Spatial backoff has recently been applied for contention resolution in wireless networks as
an alternative to algorithms that backoff in time, such as the binary exponential backoff
algorithm used in IEEE 802.11. Despite its success in saving energy and increasing spatial
reuse, the use of transmission power control in spatial backoff has negative consequences
to node throughput fairness. In this paper we study a variant of the hidden terminal problem that arises from link asymmetries, and its impact on the expected node throughput.
We give an analytical model that relates throughput to the transmission power level and
backoff window size. Using the model we propose a time–space (TS) backoff algorithm with
the objective of fair node throughput and incorporate it into a carrier sense multiple access
(CSMA) protocol as CSMA/TS. Through simulation we show that CSMA/TS achieves a high
fairness index value while attaining good total throughput in most scenarios.
Ó 2010 Elsevier B.V. All rights reserved.

1. Introduction
Traditional contention-based medium access control
(MAC) protocols resolve collisions using a contention resolution algorithm. The most commonly used algorithm is
binary exponential backoff which backs off in time. A sender increases its contention window size when the channel
is already in use or when the previous transmission attempt fails. With the advent of transmission power control
comes the opportunity to exploit another dimension in
contention resolution: space. Indeed, Colbourn et al. [6]
introduce the power backoff (PB) contention resolution
algorithm and incorporate it into a carrier sense multiple access (CSMA) protocol. In CSMA/PB, a sender reduces its
transmission power when the channel is already in use
or when the previous transmission attempt fails. This is
analogous to the effect of increasing the size of the contention window in temporal backoff; in a smaller transmission
range, both the interference and the contention are likely
to be reduced.
* Corresponding author.
E-mail address: syrotiuk@asu.edu (V.R. Syrotiuk).
1570-8705/$ - see front matter Ó 2010 Elsevier B.V. All rights reserved.
doi:10.1016/j.adhoc.2010.02.007

With the application of transmission power control a
new challenge arises: the wireless links may not be bidirectional. One such link asymmetry may occur between a
sender and its next-hop receiver. If the sender transmits
with a higher transmission power level than the receiver
there is a chance that the receiver cannot reply successfully. Fortunately, this problem is easily solved by including the transmission power level in an extra ﬁeld in the
packet header. When the receiver decodes the packet, it
extracts the transmission power level and uses the same
power level to reply to the sender (see [13,15] for examples of protocols that use this technique).
A more serious asymmetry occurs among high power
senders and low power senders. Consider Fig. 1 with nodes
A, B, and C; the dotted and solid circles represent the idealized transmission range corresponding to transmission at
high and low powers levels, respectively. If A transmits at
low power while B transmits at high power, then A is
within the transmission range of B, but B is not in the
transmission range of A. If a CSMA/CA style four-way handshake is initiated by A to C at low transmission power, A
may be hidden to B. While the handshake addresses the
hidden terminal problem when all nodes use a common

768

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

Fig. 1. Node A may be hidden to B when A transmits with low
transmission power.

Fig. 2. A scenario in which the ﬂow from A to B uses low power for
transmission, while the ﬂow from C to D uses high power for
transmission.

transmission power level, it is insufﬁcient in networks
where nodes use transmission power control. We hypothesize that such asymmetries can lead to unfairness in node
throughput.
A simple experiment is used to test our hypothesis.
Fig. 2 shows the scenario used. Four nodes, A, B, C, and D,
are positioned at (x,y)-coordinates (50, 50), (50, 80),
(200, 50), and (200, 250), respectively. Two ﬂows are introduced, one from A to B, the other from C to D. Nodes A and
B each use a transmission power level with a range corresponding to 40 m, while nodes C and D each use a transmission power level with a range corresponding to
250 m. In this scenario, nodes A and B are hidden terminals
to nodes C and D, i.e., the transmissions between nodes A
and B cannot be sensed, let alone received, by nodes C or D.
We run a simulation of this scenario in the network
simulator ns-2 version 2.26 [21] using IEEE 802.11 as
the MAC protocol, except that the nodes use the transmission power levels described. In each of ten different runs,
the ﬂow from A to B achieves less than half of the throughput of the ﬂow from C to D; the low power ﬂow suffers
starvation because of the high power ﬂow, supporting
our hypothesis. Since node C does not receive the packets
transmitted by node A at low power, C may transmit even

when A is transmitting. On the other hand, when node C
transmits at high power, A overhears it and refrains from
transmission. Therefore node C acquires access to the
channel more often than node A. In general, nodes transmitting with high power acquire disproportionately higher
access to the channel than nodes transmitting with low
power; the unfairness in channel access results in higher
throughput for the nodes transmitting with high power.
To address this problem of throughput unfairness in
nodes utilizing transmission power control we propose to
use the contention window size to counteract the advantage high power nodes have in channel access. We incorporate our contention resolution algorithm, time–space (TS)
backoff, into a CSMA protocol as CSMA/TS. The idea is that
if low power senders use a smaller contention window
size, this corrects the balance in the throughput loss
caused by low power hidden terminals. In our proposed
time–space backoff algorithm, the transmission power
and contention window size are both adjusted in each step
of backoff, to improve node throughput fairness. The question is how to set the contention window size? In order to
answer this question, we set up an analytical model for
throughput and derive a relation between the transmission
power and the contention window size. Based on our analysis, we propose a localized algorithm to set the contention
window size used in CSMA/TS to achieve fair node
throughput. Simulation results show that our protocol
achieves a signiﬁcantly higher fairness index value and attains good total throughput.
The main contributions of this paper are:
(i) We model node throughput as a function of transmission power level and contention window size.
(ii) Using the model, it is evident that to achieve fair
node throughput, the backoff space must be
explored in both the dimension of time and space.
(iii) We propose time–space (TS) backoff and incorporate
it into a CSMA protocol as CSMA/TS.
(iv) We evaluate the node throughput fairness of CSMA/
TS in simulation for several scenarios, some of which
are known to be unfair, and compare it to CSMA protocols using temporal and spatial backoff.
The rest of this paper is organized as follows. Section 2
summarizes the related work on contention resolution
algorithms and transmission power control, emphasizing
fairness. Section 3 presents the model relating node
throughput to the transmission power level and contention window size and interprets results obtained from
the model. Section 4 proposes the time–space (TS) backoff
algorithm with the objective of fair node throughput and
incorporates it into a CSMA protocol as CSMA/TS. Section
5 evaluates the proposed protocol in simulation. Finally,
in Section 6, we draw conclusions and propose future
work.

2. Related work
IEEE 802.11 uses the binary exponential backoff algorithm [15] for contention resolution; it is well-known that

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

this algorithm is short term unfair [4,16] since it favours
the last node that was successful in transmission. This
exacerbates fairness in heavy trafﬁc loads as the unsuccessful nodes are not able to gain access to the channel [1].
Several ideas are proposed by Bharghavan et al. [3] in
the MACAW protocol to remedy this problem under the
assumption of link symmetry. One idea is to share information about contention by adding a ﬁeld in the packet header that contains the current value of the backoff counter;
this produces a more fair allocation of the channel resources but can cause wild oscillations in the backoff window. Therefore the multiplicative increase linear decrease
(MILD) backoff algorithm is proposed to achieve a more
stable estimate of the contention level. In MILD, the contention window size is multiplied by 1.5 on a collision
and is decreased by 1 on a successful transmission. Another observation is that synchronization information
about contention periods should also be propagated, suggesting that contention for the channel should be initiated
by the receiver not just by the sender. With these features,
MACAW is able to cope with non-homogeneous contention
and achieve a fairer distribution of throughput.
Similar approaches to MILD include using both exponential increase and decrease of the contention window
in [25], linear/multiplicative increase and linear decrease
in [8], and both multiplicative increase and decrease in
[29]; in most of this work, the focus is on throughput
rather than on fairness.
In [2,11], local information about fairness is exchanged
between neighbours to achieve a globally fair state in the
network. These methods suffer from the overhead required
to communicate the state information. There are also
methods proposed for improving the fairness by applying
signal rate [22] and trafﬁc ﬂow priority [23].
While the variant of the hidden terminal problem arising from asymmetric links has been identiﬁed previously
[5,24], the associated fairness problem has not received
much attention. In [24], a ‘‘SHUSH” signal is used to inform
potential hidden terminals to keep silent. In this solution,
spatial reuse is sacriﬁced to alleviate the problems due to
asymmetric links. Similar to our approach, Chu [5] sets
the contention window size as a function of the transmission power. The function used is linear in the transmission
distance and the backoff window but no analysis is provided to support this choice.
Gomez and Campbell [10] study and analyze the effect
of using transmission power control on the physical network connectivity, the network capacity, and the energy
savings in wireless multi-hop networks. One of the conclusions of their work is that when nodes use transmission
power control a higher network capacity can be achieved
than when nodes use a common transmission power.
These results, and the existence of commercial wireless
cards that support it (e.g., the Cisco Aironet 350 series
and the WaveLan PCMCIA card [7,28]), motivate the need
to design protocols that leverage transmission power
control.
One motivation to use transmission power control is to
decrease power consumption at the MAC layer. Karn [15]
incorporated a new ﬁeld in the IEEE 802.11 handshake to
allow a sender to specify its transmission power level in

769

the request-to-send (RTS) packet, and the receiver to set
the desired transmission power level in the clear-to-send
(CTS) packet. The receiver determines the transmission
power level based on the required signal-to-noise ratio.
The data and acknowledgment (ACK) packets are then
transmitted at the power level indicated in the CTS packet.
Jung and Vaidya [13] analyze the performance of this
scheme and improve it by periodically increasing the
transmission power level of the data packet to the maximum power to ensure proper reception of the ACK packet.
These schemes reduce power consumption at the price of
throughput since the RTS-CTS exchange occurs at the highest transmission power level; therefore, the concurrency
achieved is at best the same as IEEE 802.11.
Transmission power control may also increase spectrum reuse. In [17,18,30], the goal is to increase concurrent
transmissions around the receiver. These protocols use
separate control and data channels. The sender or the receiver estimate the channel gain from a busy tone on the
control channel and determine the transmission power to
use. In [19], Muqattash and Krunz devise the power controlled MAC protocol to effectively utilize power control
on a single channel. An access window precedes data
transmission, during which neighbouring nodes within
the interference range exchange RTS-CTS if the interference introduced by the new transmission to the on-going
communication is below a ﬁxed signal-to-noise ratio; this
provides the possibility of concurrent transmission.
In addition to obtaining the potential beneﬁts of transmission power control, we also seek to address one of its
detriments: link asymmetries leading to unfairness in
channel access and consequently to unfairness in node
throughput.

3. An analytical model for node throughput
In this section we model the expected node throughput
in wireless networks using transmission power control,
relating throughput to the transmission power level and
the contention window size.
3.1. Modelling throughput as probability of success
We assume a CSMA/CA-style MAC protocol in which a
transmission frame consists of a four-way (RTS-CTS-DataACK) or a two-way (Data-ACK) handshake. For simplicity,
we consider a two-way handshake in this analysis. If the
forward (data) packet and the backward (ACK) packet are
both received successfully, then the transmission frame is
successful.
We assume that each node is capable of tuning its
transmission power to n discrete levels. We use n = 3 corresponding to the number of transmission power levels
on the WaveLan PCMCIA card [28]; we model this card in
our simulation in Section 5.
Let us deﬁne the following notation:
Psucc: The probability of a node having a successful
transmission in the current transmission frame. We
use this probability as a measure of node throughput

770

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

because Psucc represents the expected throughput of a
node over time.
Ri: The transmission range corresponding to transmission at power level i.
D: The node density.
Pact: The probability of a node in the network being
active, i.e., that it has either a data or a control packet
queued for transmission.
For fair node throughput, the expected probability of
successful transmission Psucc should be the same for each
active node.
Suppose that the current transmission range of a source
node s is Rj. In a CSMA/CA-style protocol, in order for a
packet to be transmitted correctly from s to its next-hop
destination node t, s must have access to the channel and
t must not experience a collision. More speciﬁcally, the following three conditions must be satisﬁed:
(i) The source node s is transmitting in the current
transmission frame, i.e., its backoff timer expires
before this frame starts ensuring s initiates the
handshake.
(ii) During the course of the transmission of the forward
packet, no other node in t’s neighbourhood is transmitting. This is true if, for each transmission power
level i, each node within a distance of Ri of t refrains
from transmission if its current transmission range
is greater than or equal to Ri. This condition ensures
that node t does not experience a collision.
(iii) During the course of the entire transmission frame,
all nodes for which s is a hidden terminal must
refrain from transmitting, i.e., for each transmission
power level i, where Ri > Rj, each node in the area
Ringi of node s must refrain from transmission for
the duration of the transmission if its transmission

range is greater than or equal to Ri. Here, Ringi is
the area at distance greater than Ri1 and less than
or equal to Ri. Fig. 3 shows Ring i for 1 6 i 6 3.
The ﬁrst two conditions ensure that the forward packet
is transmitted by s and is received by t. The third condition
is used to address the hidden terminal problem that can
arise when transmission power control is used. The receipt
of the backward packet at node s may suffer interference
from a high power transmission outside of the range of s.
We must ensure that all nodes in the area described in
the third condition remain silent for s to receive the backward packet successfully.
Let us use Pcond(i) to represent the probability of condition i,1 6 i 6 3. The probability that the ﬁrst condition
holds is:

Pcondð1Þ ¼

1
backoff timer

¼

v alue

lnðCW s Þ
CW s

ð1Þ

where CWs is the contention window size of node s. The value of the backoff timer is a random integer in the range
[0,CWs).
For the second condition, given any node in destination
t’s neighbourhood, the average probability of this node
remaining silent during the transmission of the forward
packet is:

Psilent ¼ 1 

lnðCW av g Þ
;
CW av g

ð2Þ

where CWavg is the average contention window size of t’s
neighbouring nodes.
Assuming that the nodes in the network are uniformly
distributed, the probability that the second condition holds
is:
n
P

DPact pR2i P R

i¼1
Pcondð2Þ ¼ Psilent

i

ð3Þ

;

where P Ri is the probability of a node using a transmission
power level i with corresponding range of Ri, and n is the
number of transmission levels available.
For the third condition, let Nhidden denote the number of
nodes that have s as a hidden terminal:
N

hidden
Pcondð3Þ ¼ Psilent
:

ð4Þ

For each ring Ringi, the probability of all nodes refraining from transmission if their transmission ranges are
greater than or equal to Ri, denoted by PRingi , is:
DpðR2 R2 ÞP act P PR
i
PRingi ¼ Psilent i i1
;

ð5Þ

where PPRi is the probability of a node using a transmission
range greater than or equal to Ri. This probability can be
written as:

PPRi ¼

n
X

P Rj :

ð6Þ

j¼i

Putting these pieces together, the probability that the
third condition holds is:
Fig. 3. The rings of node s where s is located at the center. Ri is the
transmission range corresponding to transmission power level i, and Ringi
is the area at distance greater than Ri1 and less than or equal to
Ri, 1 < i 6 3; Ring1 = R1.

Pcondð3Þ ¼

Y
i;Ri >Rs

DpðR2 R2i1 ÞP act P PR

Psilenti

i

;

ð7Þ

771

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

and

0.12

Nhidden ¼

X



Dp R2i  R2i1 Pact PPRi :

ð8Þ

0.1

i;Ri >Rj

Psucc ¼ Pcondð1Þ  Pcondð2Þ  Pcondð3Þ
n
P
DpP act
R2i PR
i
lnðCW s Þ
N hidden
i¼1
¼
 Psilent
 Psilent
:
CW s

ð9Þ

0.08
Psucc ( x C)

Therefore, the probability that a transmission frame is successful is:

40m
100m
250m

0.06

0.04

0.02

3.2. Node throughput fairness
0

In order for the expected node throughput to be the
same for active nodes independent of their transmission
power levels, the value of Psucc should be the same for all
active nodes. In the expression of Psucc in Eq. (9), Pcond(2)
is same for all the power levels. Thus, Psucc can be rewritten
as:

Psucc ¼

lnðCW s Þ
N hidden
 Psilent
 C;
CW s

ð10Þ

for some constant C.
Furthermore, since Nhidden is an integer, we can
approximate
N

hidden
Psilent
’1

lnðCW av g Þ  Nhidden
;
CW av g

ð11Þ

and therefore approximate the probability of success as

Psucc ’



lnðCW s Þ
lnðCW av g Þ  Nhidden
 1
 C:
CW s
CW av g

ð12Þ

In a wireless network, a node using higher transmission
power is less likely to be a hidden terminal, i.e., Nhidden is
smaller. The lower the transmission power a node uses,
the larger is the chance that the node is a hidden terminal.
In order to obtain equal values of Psucc, the contention window size of a node should depend on Nhidden (see Eq. (8)).
3.2.1. Optimizing fairness for ﬁxed topologies
We note that the analysis presented in Section 3.1 could
be modiﬁed to ﬁnd the optimal transmission power and
backoff window size for a given network topology. While
the analysis assumes that the nodes are uniformly distributed, it could be modiﬁed to ﬁnd the transmission power
level (or the transmission power setting, if continuous
rather than discrete transmission power control is assumed) and the contention window size such that Psucc is
the same for all nodes in any given ﬁxed topology. This
could be of interest in networks where the topology is usually ﬁxed, e.g., wireless mesh networks.
3.3. Numerical results
We plot Psucc as a function of the contention window
size under the following conditions: The network has 50
wireless nodes randomly deployed in a 500  500 m2 area
(i.e., D = 0.0002). We assume that Pact = 1, i.e., all nodes are
saturated with outgoing trafﬁc. We further assume each

5

5.5

6

6.5

7

7.5

8

8.5

9

9.5

10

x

Contention Window Size (2 )

Fig. 4. Expected Psucc as a function of k where CWs = 2k.

node may use one of n = 3 transmission power levels:
P3 = 0.2818 W, P2 = 7.214e3 W, and P1 = 8.5872e4 W
corresponding to transmission ranges of 250 m, 100 m,
and 40 m, respectively. Each node randomly chooses its
next-hop destination and its transmission power level,
i.e., each node has the same probability to transmit at each
transmission power level, namely 13.
For each transmission power level, Fig. 4 plots the expected probability of success Psucc as a function of the size
of the contention window CWs (see Eqs. (8) and (12)).
When power control is not used (i.e., the transmission
range is always 250 m), the expected throughput decreases
as the contention window size increases. This explains the
unfairness observed in the binary exponential backoff
algorithm, since it favours nodes with recent success by
resetting the contention window to the minimum size: this
decrease in the contention window size increases the probability of future transmission for these nodes.
In general, nodes transmitting with higher transmission
power have higher expected throughput. For example,
when the contention window size is 25, the expected
throughput for a transmission at high power is nearly three
times as large as that for a transmission at low power. In
order to obtain fair node throughput, nodes using a higher
transmission power must also use a larger contention window. In the next section, we propose a new time–space
backoff contention resolution algorithm based on this
observation.

4. Carrier sense multiple access with time–space
backoff (CSMA/TS)
4.1. Time, space, and time–space backoff
Fig. 5 is a representation of the backoff space. The x- and
y-axes represent two-dimensions of the backoff space,
time and space, respectively. Binary exponential backoff
is an example of a contention resolution algorithm that
backs off in time; it only explores the backoff space in
the x (time) dimension from left to right. The basic power
backoff algorithm [6] is an example of a contention

772

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

Fig. 5. Time, space, and time–space backoff.

resolution algorithm that backs off in space; it explores the
backoff space in the y (space) dimension, top-down. While
variants of CSMA/PB are proposed that combine the
dimensions of time and space, their objective is to maximize throughput without regard to fairness.
Temporal backoff favours those nodes with a small contention window while spatial backoff favours those nodes
with a high transmission power. To offset the unfairness
in each backoff algorithm, time–space (TS) backoff explores
the backoff space across the back diagonal, from the upper
right (high transmission power with large contention window) to the lower left (small transmission power with
small contention window).
4.2. The CSMA/TS protocol
In CSMA/TS, the transmission of each data packet follows a four-way handshake. Each packet includes an extra
ﬁeld to indicate the transmission power level used. To describe the protocol, we consider a node s that transmits a
series of data packets to node t. Let pi be the power level
utilized by s in transmitting the ith data packet and let
cwi be its contention window size.
Algorithm 1 (CSMA/TS transmitter protocol at s).
1: if there is a DATA packet from s to t then
2: if packet i has destination different from i-1 then
Pmax
3:
pi
4:
cwi
CWmax
5: else
pi1
6:
pi
7:
cwi
cwi1
8: end if
9: totalRetry
0
10: retry
0
11: success
false
12: while not success and
totalRetry < MAX_TOTAL_RETRY do
13:
set a backoff timer for random period in [0,cwi)
14:
while the backoff timer is not expired do
15:
if a transmission is sensed then
16:
pause backoff timer
17:
run receiver protocol to completion
18:
resume backoff timer

19:
end if
20:
end while
21:
send RTS using power level pi
22:
if a CTS is received then
23:
send DATA using power level pi
24:
if an ACK is received
25:
success
true
26:
end if
27:
end if
28:
totalRetry
totalRetry + 1
29:
retry
retry + 1
30:
if retry P MAX_RETRY
31:
pi = MAX(pi-1,Pmin)
32:
cwi = MAX(cwi/2,CWmin)
33:
retry
0
34:
end if
35: end while
36: if not success then
37:
discard packet and report failure
38: end if
39: end if

Algorithm 2 (CSMA/TS receiver protocol at t).
1: if the RTS received is intended for t then
2: send CTS with transmission power pi and
contention window size cwi used by the RTS
3: else if DATA received is for t then
4: send ACK with transmission power pi and
contention window size cwi used for the DATA
5: else
6: set the NAV for this packet and keep silent
7: end if

We assume that each node is capable of tuning its
Pn and Pmin
transmission power to n discrete levels, Pmax
P1, and that the minimum contention window size is
CWmin. We set the maximum contention window size to
2n1CWmin so that there are as many contention
CWmax
window sizes as power levels. In this way, we have a simple one-to-one mapping between transmission power level
and contention window size.
Initially the transmission power level for the ﬁrst packPmax, and the contention
et of s is set to the maximum, p1
CWmax. In genwindow size is set to the maximum, cw1
eral, to transmit data packet i, s ﬁrst senses the channel. If
the channel is busy, the node updates the network allocation vector (NAV) as in IEEE 802.11. If the channel is free,
s transmits an RTS at power level pi which includes pi in
the packet. Following that transmission, if s subsequently
receives the corresponding CTS, then the data packet is
transmitted at power level pi. If the transmission is successful, then s receives an ACK. If s does not receive a CTS
then the RTS may have been involved in a collision. In this
case, both the transmission power level and the contention
window size for packet i of s are reduced. s retransmits an
RTS at a reduced power level using the reduced contention
window if the channel is free.

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

If the destination of the next packet i + 1 is the same as
packet i, then the transmission power level pi and
contention window size cwi are retained for packet i + 1;
otherwise, each is reinitialized.
As in IEEE 802.11 and CSMA/PB, a node may attempt
MAX_TOTAL_RETRY number of transmissions before the
packet is dropped. To avoid backing off too often and the
transmission power being updated too frequently, we use
another shorter retry count MAX_RETRY. A node may only
backoff in time and space when MAX_RETRY number of attempted transmissions have been tried in the current
backoff step.
Algorithms 1 and 2 give the pseudocode for the CSMA/
TS transmitter and receiver protocols, respectively.
5. Simulation study
We now evaluate the effectiveness and node throughput fairness of CSMA/TS. We compare CSMA/TS to the IEEE
802.11 protocol which uses temporal backoff, and to the
basic CSMA/PB protocol [6] which uses spatial backoff; this
gives us a baseline comparison to a ‘‘pure” backoff algorithm of each type.
As before, we use the network simulator ns-2 version
2.26 [21] for our simulations. We use a data channel rate
of 1 Mbps with each data packet being 1000 bytes in size.
Each ﬂow in the network is saturated so that the channel
is used at its full capacity.
We simulate the WaveLan PCMCIA card [28]. It has n = 3
transmission power levels: 0.2818 W,7.214e3 W, and
8.5872e4 W corresponding to a transmission range of
approximately 250 m, 100 m, and 40 m, respectively. We
use a minimum contention window size of 32. Table 1
gives these and other simulation parameters.
We measure the following metrics:
(i) The total throughput, i.e., the total data received at
all the destinations in bytes.
Table 1
Simulation parameters.
Simulation time
Number of replicates

200 s
5

Trafﬁc type
Data packet size
Trafﬁc arrival rate
Channel data rate
Antenna

UDP
1000 bytes
0.5 Mbps
1 Mbps
Omni-directional

CWmin
CWmax = 22Pmin

32
128

P3 = Pmax
P2
P1 = Pmin

0.2818 W
7.214E-3 W
8.5872E-4 W

Transmission range at P3
Transmission range at P2
Transmission range at P1

250 m
100 m
40 m

Carrier sensing range at P3
Carrier sensing range at P2
Carrier sensing range at P1

550 m
220 m
88 m

MAX_TOTAL_RETRY
MAX_RETRY

7
2

773

(ii) Jain’s fairness index (JFI) for total throughput [12]:

P
N
JFI ¼

i¼1 xi

N

2

PN

2
i¼1 xi

ð13Þ

where N is the total number of ﬂows, and the throughput of each ﬂow is x1,x2, . . . xN. Using this fairness index,
0 6 JFI 6 1; equally distributed throughput achieves a
fairness index of one.
If the routing protocol does not take into account variation in transmission power levels it will use unnecessary
paths when the transmission power is high and have no
path to use when the transmission power is low. Therefore,
when transmission power control is used at the MAC layer,
routing must also be power-aware.
For consistency, we use the same power-aware routing
protocol used in the evaluation of CSMA/PB [6]. In this
routing protocol, a node chooses its next-hop destination
depending on the transmission power level selected.
Let pow(ti,tj) denote the transmission power needed for
node ti to transmit in one hop to tj; this is inﬁnity if no such
power level exists. Then for each s–d ﬂow and each transmission power level q, 1 6 q 6 n, a path s = t0t1 . . . tk = d is
P
found such that pow(t0,t1) 6 q and q þ k1
j¼1 powðt j ; t jþ1 Þ is
minimized. In this power-aware routing protocol, if node
ti receives a packet to forward towards destination d, the
next-hop node ti+1 depends on the transmission power level q used by ti. The value of q is determined by the poweraware MAC protocol. For example, if CSMA/TS decreases
the transmission power level then this may change the
next-hop node through which the packet is routed. If there
is only one transmission power level in use, such as in IEEE
802.11, then this routing protocol degrades to one that
ﬁnds a path minimizing the hop count.
In the next several subsections we compare the performance of CSMA/TS to IEEE 802.11 and CSMA/PB under
increasingly complex network topologies. All results are
averaged over a minimum of ﬁve replicates of the
simulation.
5.1. The static two ﬂow scenario
The ﬁrst network scenario we study is the static two
ﬂow scenario in Fig. 2 we used to motivate the problem

Fig. 6. The total throughput for ﬂow 1 (A–B) and ﬂow 2 (C–D) in the
scenario in Fig. 2.

774

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

of throughput unfairness in Section 1. Fig. 6 shows the total
throughput for each ﬂow using the binary exponential
backoff (time), power backoff (space), and time–space
backoff algorithms for contention resolution in CSMA.
The larger the difference between the two ﬂows the more
is the unfairness in throughput.
Spatial backoff is the most unfair among the three algorithms. In this scenario, the nodes in ﬂow 2 (C and D) can
communicate only at high power. Flow 1 (the ﬂow from
A to B) attempts transmission at high power and then
backs off in space to the lowest transmission power level.
As a result, both nodes A and B are hidden terminals to
nodes C and D. The consequence is that the throughput
of the ﬂow 1 is about 44% of ﬂow 2. This is essentially
the same as the results described in Section 1.
In temporal backoff both ﬂows always use maximum
transmission power and backoff in time. The throughput
of ﬂow 1 is about 64% of ﬂow 2. Here, once a ﬂow gains access to the medium it is likely to keep it because of the
short term unfairness of the binary exponential backoff
algorithm.
The combination of backing off in both time and space
is the best in terms of fairness in this scenario. In CSMA/
TS, ﬂow 1 achieves about 93% of the total throughput of
ﬂow 2; it effectively uses the contention window to counteract the hidden terminal problems introduced by the use
of transmission power control. These results are supported
by the value of Jain’s fairness index for each backoff algorithm in Table 2 where the more equally distributed the
throughput the closer the fairness index is to one.
It is worth mentioning that while CSMA/TS achieves the
best node throughput fairness, its total throughput is not
the best (about 80% that of temporal backoff and about
91% of spatial backoff). Often, there is a trade-off between
fairness and total throughput; this trade-off is not unique
to our study [3,26,27,31]. Indeed, in the next subsection
we show that there are scenarios when the trade-off is
impossible to avoid.

5.2. Classic unfair scenarios
We now study several classic scenarios long known to
be unfair when the binary exponential backoff algorithm
is used for collision resolution.

Fig. 7. The classic ﬂow-in-the-middle scenario. The nodes in ﬂows 1 and
3 can sense transmissions from the nodes in the middle ﬂow but not of
each other.

The best throughput that can be achieved in this scenario is when ﬂows 1 and 3 are active concurrently resulting in two units of throughput. However, this shuts out
ﬂow 2 completely because its source (node C) senses the
transmissions from both ﬂows 1 and 3. If the middle ﬂow
was able to capture the medium and transmit, its transmission would be sensed by nodes A and E (the sources
of ﬂows 1 and 3, respectively), and it would become the
only active ﬂow resulting in 1 unit of throughput. Hence
whenever ﬂow 2 transmits, it necessarily reduces the
throughput.
Recall, that we have deﬁned fairness as each source
having equal probability of success to transmit. In the
ﬂow-in-the-middle scenario, the best throughput that a
fair protocol can achieve is 32 units: half of the time the
two outside ﬂows transmit resulting in 2 units of throughput, while the other half of the time the middle ﬂow transmits resulting in 1 unit of throughput. This scenario is just
one example that shows to achieve fairness, throughput
may suffer.
Fig. 8 plots the total throughput for each ﬂow in the
ﬂow-in-the-middle scenario for each of the three backoff
algorithms. When the temporal backoff algorithm is used,
the middle ﬂow receives no throughput while the outer
ﬂows receive nearly identical throughput. The cause is
the lack of transmission opportunities for the middle ﬂow:
The senders A and E are not coordinated so C senses the
channel as busy all the time because the transmissions of
A and E overlap randomly at C. In this scenario, spatial
backoff behaves the same as temporal backoff because
both ﬂows 1 and 3 attempt at transmission at high power,
succeed, and then continues to use high power for subsequent packets leaving the middle ﬂow no opportunities
to access the channel.

5.2.1. The ﬂow-in-the-middle scenario
One well-known unfair scenario is the ﬂow-in-the-middle scenario [3,9,26,27,31] illustrated in Fig. 7. Here, there
are six nodes arranged in two rows parallel to each other.
There are three ﬂows, the ﬁrst from A to B, the second (or
middle) ﬂow from C to D, and the third from E to F.

Table 2
JFI for each backoff algorithm in the static two ﬂow scenario.
Jain’s fairness index
Time backoff
Space backoff
Time–space backoff

0.953
0.867
0.999

Fig. 8. The total throughput for each ﬂow in the ﬂow-in-the-middle
scenario.

775

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777
Table 3
JFI for each algorithm in the ﬂow-in-the-middle scenario.
Jain’s fairness index
Time backoff
Space backoff
Time–space backoff

0.667
0.667
0.855

As Table 3 reports, Jain’s fairness index is higher for
time–space backoff than the other two backoff algorithms.
While the middle ﬂow is able to access the channel it only
obtains about 32% the throughput of ﬂows 1 and 3, and this
comes at the expense of decreasing the total throughput by
37% compared to temporal or spatial backoff. The total
throughput is about 12% lower than what is expected in
the ideal case, and the middle ﬂow is not obtaining equal
32
access to the channel as the outer ﬂows. We set CSmin
2n1CWmin giving a one-to-one mapping beand CWmax
tween transmission power level and contention window
size. Perhaps better fairness and also better throughput
could be obtained through more careful tuning of this
mapping.
5.2.2. The exposed terminal scenario
Fig. 9 shows another well-known unfair scenario: the
exposed terminal scenario [3,9,14,27,31]. In this scenario,
the receiver of ﬂow 1 (node B) can sense the sender of ﬂow
2 (node C) when it transmits at high power; the two senders (nodes A and C) are not in the transmission range of
each other. However both ﬂows can communicate concurrently at low power; this is the best case.
Fig. 10 shows that, under saturated conditions, ﬂow 1
achieves only about 4% of the throughput of ﬂow 2 when
a temporal backoff algorithm is used, and even less (about
1%) of the throughput of ﬂow 2 when spatial backoff is
used. In both cases, ﬂow 1 rarely is successful because node
B senses the channel as busy most of the time and is unable
to respond to an RTS from node A, even when it is sent at
low transmission power.

In this scenario, information asymmetry is the root cause
of the behaviour; the senders perceive an asymmetric view
of the channel state [3,9,14]. The disparity is due to A not
being aware of ﬂow 2 because it does not sense any of its
packets. On the other hand, C can sense the control packets
sent by node B at high transmission power, and is therefore
aware of ﬂow 1. While C knows when to start contending
for the channel, A has to discover a time without any coordination of ﬂow 2. This results in A attempting to transmit
many times without any response from B. As a result, the
probability of ﬂow 1 capturing the channel is much lower
than that of ﬂow 2.
With the time–space backoff algorithm, ﬂow 2 achieves
about 65% of the total throughput it achieved with temporal and spatial backoff. While ﬂow 1 achieves from 9 to 25
times the throughput it achieved with the other backoff
algorithms, it is about 62% of the throughput of ﬂow 2.
As Table 4 shows, the fairness index achieved by time–
space backoff in this scenario is a great improvement over
the other two backoff algorithms. While the smaller backoff window at low transmission power improves the access
of ﬂow 1 to the channel, the information asymmetry problem is not solved entirely. All of the backoff algorithms
would likely beneﬁt from sharing information about contention and synchronization, perhaps by the receiver, similar to the ideas proposed in MACAW [3].

5.3. A mobile ad hoc scenario
We now study a mobile scenario with 50 nodes deployed in an area of 500  500 m2. Each node moves
according to the steady-state initialized random way-point
Table 4
JFI for each algorithm in the exposed terminal scenario.
Jain’s fairness index
Time backoff
Space backoff
Time–space backoff

0.543
0.516
0.948

6

x 10

Fig. 9. The classic exposed terminal scenario.

18

Total Throughput (bytes)

16
14
12
10
8
6
4
2
0

Fig. 10. The total throughput for each ﬂow in the exposed terminal
scenario.

Time Backoff
Space Backoff
Time−Space

5

10

15
Number of Source Nodes

20

25

Fig. 11. The total throughput as a function of number of ﬂows in a mobile
ad hoc network scenario.

776

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

mobility model [20] at 2 m/s and a pause time of 2 s. We
randomly select the source and destination nodes of each
UDP ﬂow, using a trafﬁc generation rate of 0.5 Mbps.
Figs. 11 and 12 show the total throughput and Jain’s
fairness index for throughput, respectively, as a function
of the number of ﬂows.
Fig. 11 shows that as the number of ﬂows increases, the
total throughput decreases. This is because the network is
saturated. As the number of transmitting nodes increases,
the contention in the network increases with a corresponding decrease in throughput. The total throughput
for temporal backoff is the best among the three schemes.
However, Fig. 12 shows that with an increase in the number of ﬂows in the network, Jain’s fairness index decreases.
CSMA/TS achieves the highest fairness index, while the
spatial backoff algorithm suffers from hidden terminals
due to the use of transmission power control. IEEE
802.11 also achieves good fairness, as the nodes in the network are moving randomly without discrimination.

1

Jain‘s Index −− Throughput

0.9

0.8

0.7

0.6

0.5
Time Backoff
Space Backoff
Time−Space

0.4

5

10

15
Number of Source Nodes

20

25

Fig. 12. Jain’s fairness index for total throughput in a mobile ad hoc
network scenario.

5

x 10

Throughput per Unit of Energy (bytes/joule)

5
4.5
4

One beneﬁt of using transmission power control is that
it may decrease power consumption. Fig. 13 plots the total
throughput per unit of energy. As expected, spatial backoff
saves energy by using lower transmission power. The temporal backoff scheme uses a ﬁxed (maximum) transmission power, therefore it consumes the most energy.
CSMA/TS combines the advantages of each of spatial and
temporal backoff achieving good total throughput and energy efﬁciency.
6. Conclusions and future work
In this paper, we model the node throughput as a
function of transmission power level and contention window size. Using the model, we determine that to achieve
node throughput fairness, the backoff space must be explored in both the dimensions of time and space. Consequently, we propose the time–space (TS) backoff
algorithm for contention resolution and incorporate it
into a CSMA protocol as CSMA/TS. We evaluate the node
throughput fairness of CSMA/TS in simulation and compare it to CSMA protocols using temporal and spatial
backoff. The simulation results show that our approach
can achieve higher node throughput fairness, even in scenarios well-known to be unfair, while attaining good total
throughput. This suggests that controlling the contention
window size together with transmission power appears to
be a promising approach to achieve improved node
throughput fairness.
In some scenarios we show that to be fair, throughput is
necessarily reduced. While the prototypical time–space
backoff demonstrates improved fairness, both the fairness
and throughput it achieves are in need of further improvement. An in-depth study of the mapping between transmission power level and contention window size is
needed. As well, it appears that all of the backoff algorithms could beneﬁt from more information sharing (i.e.,
cooperation) by overhearing nodes to improve both fairness and throughput.
Future work should also consider interactions with
other layers of the network architecture. As well, we assume that the transmission power may only be tuned to
a number of discrete levels; we may also consider the
transmission power tuned over a continuous range. Using
the model to optimize the transmission power and the
contention window size for a ﬁxed topology is a problem
of practical interest in wireless mesh networks.

3.5
3

Acknowledgments

2.5
2
1.5
1
0.5
0

Time Backoff
Space Backoff
Time−Space

5

10

15
20
Number of Source Nodes

25

Fig. 13. Total throughput per unit of energy in a mobile ad hoc network
scenario.

We thank Charles J. Colbourn and Errol L. Lloyd for useful discussions. We also thank the anonymous referees
whose suggestions have greatly improved the selection of
experimental results and our presentation.
This work was supported, in part, by National Science
Foundation Grant ANI-0240524 and Los Alamos National
Laboratory contract 13638-001-05. Any opinions, ﬁndings,
conclusions, or recommendations expressed in this paper
are those of the authors and do not necessarily reﬂect the
views of NSF or LANL.

M. Cui, V.R. Syrotiuk / Ad Hoc Networks 8 (2010) 767–777

References
[1] C.L. Barrett, M.V. Marathe, D.C. Engelhart, A. Sivasubramaniam,
Analyzing the short-term fairness of IEEE 802.11 in wireless multihop radio networks, in: Proceedings of the 10th IEEE International
Symposium on Modeling, Analysis, and Simulation of Computer and
Telecommunications Systems, MASCOTS’02, Washington, DC, USA,
2002.
[2] B. Bensaou, Y. Wang, C. Ko, Fair medium access in 802.11 based
wireless ad-hoc networks, in: Proceedings of the 1st ACM
International Symposium on Mobile Ad Hoc Networking and
Computing, Mobihoc’00, 2000.
[3] V. Bharghavan, A. Demers, S. Shenker, L. Zhang, MACAW: a media
access protocol for wireless LAN’s, in: Proceedings of the Conference
on Communications Architectures, Protocols and Applications,
SIGCOMM’94, 1994.
[4] H.S. Chhaya, S. Gupta, Performance modeling of asynchronous data
transfer methods of IEEE 802.11 MAC protocol, Wireless Networks 3
(3) (1997) 217–234.
[5] B. Chu, Improving IEEE 802.11 performance with power control and
distance based contention window selection, Master’s thesis,
University of Illinois, Urbana-Champaign, 2005.
[6] C.J. Colbourn, M. Cui, E.L. Lloyd, V.R. Syrotiuk, A carrier sense
multiple access protocol with power backoff, CSMA/PB, Ad Hoc
Networks 5 (8) (2007) 1233–1250.
[7] Data sheet: Cisco aironet 350 series client adapters. <http://
www.cisco.com/en/US/products/hw/wireless/index.html>.
[8] J. Deng, P.K. Varshney, Z.J. Haas, A new backoff algorithm for the IEEE
802.11 distributed coordination function, in: Proceedings of
Communication Networks and Distributed Systems Modeling and
Simulation, CNDS ’04, 2004.
[9] M. Garetto, T. Salonidis, E.W. Knightly, Modeling per-ﬂow
throughput and capturing starvation in CSMA multi-hop wireless
networks, in: Proceedings the 25th IEEE International Conference on
Computer Communications, Infocom’06, 2006.
[10] J. Gomez, A.T. Campbell, A case for variable-range transmission
power control in wireless multi-hop networks, in: Proceedings the
23rd Annual Joint Conference of the IEEE Computer and
Communications Societies, Infocom’04, vol. 2, 2004.
[11] Z. Haas, J. Deng, On optimizing the backoff interval for random
access schemes, IEEE Transactions on Communications 51 (12)
(2003) 2081–2090.
[12] R. Jain, D. Chiu, W. Hawe, A quantitative measure of fairness and
discrimination for resource allocation in shared computer systems,
DEC Research Report TR-301, September 1984.
[13] E.-S. Jung, N.H. Vaidya, A power control MAC protocol for ad hoc
networks, in: Proceedings of the 8th ACM International Conference
on Mobile Computing and Networking, Mobicom’02, 2002.
[14] V. Kanodia, C. Li, S. Sabharwal, B. Sadeghi, E. Knightly, Ordered
packet scheduling in wireless ad hoc networks: mechanisms and
performance analysis, in: Proceedings of the 3rd ACM Symposium
on Mobile Ad Hoc Networking and Computing, Mobihoc’02, 2002.
[15] P. Karn, MACA – a new channel access method for packet radio, in:
Proceedings of the 9th ARRL/CRRL Amateur Radio Computer
Networking Conference, 1990.
[16] C.E. Koksal, H. Kassab, H. Balakrishnan, An analysis of short-term
fairness in wireless media access protocols, SIGMETRICS
Performance Evaluation Review 28 (1) (2000) 118–119.
[17] J.P. Monks, V. Bharghavan, W.-M. Hwu, A power controlled multiple
access protocol for wireless packet networks, in: Proceedings of 20th
Annual Joint Conference of the IEEE Computer and Communications
Societies, Infocom’01, 2001.
[18] A. Muqattash, M. Krunz, Power controlled dual channel (PCDC)
medium access protocol for wireless ad hoc networks, in:
Proceedings of the 22nd Annual Joint Conference of the IEEE
Computer and Communications Societies, Infocom’03, 2003.
[19] A. Muqattash, M. Krunz, A single-channel solution for transmission
power control in wireless ad hoc networks, in: Proceedings of the
5th ACM International Symposium on Mobile Ad Hoc Networking
and Computing, Mobihoc’04, 2004.
[20] W. Navidi, T.K. Camp, Stationary distributions for the random
waypoint mobility model, IEEE Transactions on Mobile Computing
3 (1) (2004) 99–108.
[21] The network simulator – ns-2. <http://www.isi.edu/nsname/ns/>.

777

[22] T. Pagtzis, P. Kirstein, S. Hailes, Operational and fairness issues with
connection-less trafﬁc over IEEE 802.11 b, in: Proceedings of IEEE
International Conference on Communications, ICC’01, 2001.
[23] D. Qiao, K. Shin, Achieving efﬁcient channel utilization and weighted
fairness for data communications in IEEE 802.11 WLAN under the
DCF, in: IEEE International Workshop on QoS, 2002.
[24] A. Sheth, R. Han, SHUSH: reactive transmit power control for
wireless MAC protocols, in: Proceedings of the 1st IEEE
International Conference on the Wireless Internet, WICON’05, 2005.
[25] N. Song, B. Kwak, J. Song, M.E. Miller, Enhancement of IEEE 802.11
distributed coordination function with exponential increase
exponential decrease backoff algorithm, in: Proceedings of the
57th IEEE Semiannual Vehicular Technology Conference, VTC’03Spring, 2003.
[26] X. Wang, K. Kar, Throughput modelling and fairness issues in CSMA/
CA based ad hoc networks, in: Proceedings the 24th Annual Joint
Conference of the IEEE Computer and Communications Societies,
Infocom’05, 2005.
[27] Y. Wang, J.J. Garcia-Luna-Aceves, Channel sharing of competing
ﬂows in ad hoc networks, in: Proceedings of the 8th IEEE
International Symposium on Computers and Communications,
ISCC’03, 2003.
[28] WaveLAN/PCMCIA card user’s guide (version 4.0). <http://
www.info.ncr.com/eDownload.cfm?itemid=982740002>.
[29] H. Wu, S. Cheng, Y. Peng, K. Long, J. Ma, IEEE 802.11 distributed
coordination function (DCF): analysis and enhancement, in:
Proceedings
of
the
IEEE
International
Conference
on
Communications, ICC’02, 2002.
[30] S. Wu, Y. Tseng, J. Sheu, Intelligent medium access for mobile ad hoc
networks with busy tones and power control, IEEE Journal on
Selected Area in Communications 18 (9) (2000) 1647–1657.
[31] K. Xu, M. Gerla, L. Qi, Y. Shu, Enhancing TCP fairness in ad hoc
wireless networks using neighborhood RED, in: Proceedings of the
9th ACM International Conference on Mobile Computing and
Networking, Mobicom’03, 2003.

Minghao Cui received his B.E. degree in
Computer Science and Engineering from Harbin Institute of Technology, China, in 2002,
and the M.S. and Ph.D. degrees in Computer
Science and Engineering from Arizona State
University in 2004 and 2007, respectively. His
research interests include mobile ad hoc networks and computing, network layer protocols, and medium access control protocols
with an emphasis on optimization, energy
efﬁciency, security, and quality of service.

Violet R. Syrotiuk (SM’96/ACM’93) earned
her Ph.D. in Computer Science from the University of Waterloo (Canada) in 1992. She
joined Arizona State University in 2002 and is
currently an Associate Professor of Computer
Science and Engineering. Dr. Syrotiuk’s
research has been supported by grants from
NSF, ONR, DoD, DSTO (Australia) and contracts with Los Alamos National Laboratory,
General Dynamics, Raytheon, and ATC. She
serves on the editorial boards of Computer
Networks, Computer Communications and
the International Journal of Communication Systems, and on the technical
program committees of several major ACM and IEEE sponsored conferences. Her research interests include modelling, run-time optimization
for adaptation in protocols for multi-hop wireless networks and cognitive
radio ad hoc networks.

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 22, NO. 7, SEPTEMBER 2004

1335

Factor Interaction on Service Delivery in
Mobile Ad Hoc Networks
Kiran K. Vadde, Student Member, IEEE, and Violet R. Syrotiuk, Member, IEEE

Abstract—Delay sensitive applications are driving the need for
the support of quality-of-service (QoS) in mobile ad hoc networks.
In this paper, we use statistical design of experiments to study the
impact of factors and their interaction on the service delivered.
We consider the factors of QoS architecture, routing protocol,
medium access control protocol, offered load, and mobility, at
mixed levels. Real-time throughput, total throughput, and average
delay are used as the measures of service delivery. A statistical
analysis of the data collected by simulation using analysis of variance techniques is performed. This allows us to identify both main
effects and interactions of factors that best explain the response
variables. For average delay several factors of the experiment
interact. For both forms of throughput, the impact of the routing
protocol is not apparent except as it interacts with other factors,
and the factor interactions are not as extensive as for delay. Thus,
for all response variables the factors cannot be studied in isolation.
As well, the analysis provides a means for a system architect to
determine the level to set the factors to optimize a specific service
delivery metric, or combination of metrics.
Index Terms—Design of experiments, factor interactions, mobile
ad hoc networks (MANETs), service delivery.

I. INTRODUCTION

M

OBILE ad hoc networks (MANETs) are designed for
rapid deployment in battlefield or emergency situations
since they do not rely on the presence of any fixed communications infrastructure. Often, the ability to carry voice communication between the troops or the rescue workers in the
field is the most important requirement of the network. This requirement, along with the development of other real-time applications, has motivated research to support quality-of-service
(QoS) in MANETs.
The problem of supporting QoS in MANETs, i.e., providing
resources such as bandwidth and buffer space to real-time flows
to satisfy their rate, delay, or jitter requirements, is a challenging
problem. In a MANET, the network has no centralized control
and each node is capable of functioning as a router. Node mobility, as well as time-varying wireless channel characteristics,
cause frequent changes in node connectivity. These dynamics,
together with distributed control, contribute to the difficulty of
estimating resources in order to support QoS.
Much of the research on QoS in MANETs has advanced along
two fronts. Along one front, QoS architectures such as Swan
Manuscript received October 1, 2003; revised March 15, 2004. This paper
was supported in part by the National Science Foundation (NSF) under Grant
ANI-0240524.
The authors are with the Computer Science and Engineering Department, Arizona State University, Tempe, AZ 85287-8809 USA (e-mail: kvadde@asu.edu;
syrotiuk@asu.edu).
Digital Object Identifier 10.1109/JSAC.2004.829351

[1] and Insignia [2] have developed. These architectures use
mechanisms such as rate, flow, and admission control, and the
rerouting of flows to regulate best-effort traffic in order to satisfy the QoS needs of real-time traffic. Studies have found that
lighter weight stateless QoS architectures such as Swan more
easily cope with the network dynamics and are, therefore, more
appropriate for MANETs [1].
Along the other front, QoS-awareness is introduced into individual protocols. For example, QoS-aware routing protocols
select paths based on metrics such as delay or bandwidth rather
than path length [3], [4]. QoS-awareness in the medium access
control (MAC) protocol provides differentiated channel access
to packets of different traffic classes [5]–[7]. The performance
of such QoS-aware protocols has also been studied, though most
often in isolation rather than in concert with other protocols.
Our interest is to determine the significant factors, and moreover the interaction of factors, on service delivery in MANETs.
In particular, our goal is to start to close the loop on these two
research fronts, examining both QoS architectures together with
individually QoS-aware protocols. To help study such complex
interactions, we use statistical design of experiments [8]. While
this methodology is well known and used for factor interaction
studies in other disciplines, ranging from social sciences to industrial engineering, to our knowledge Barrett et al. [9], [10]
are the first to have used it to study factor interactions in networking, specifically between routing and MAC protocols.
Of course, not only the question of which factors and factor
interactions affect observed performance, but also the question
of how these factors and their interactions work to cause the
observed performance requires an answer. Design of experiments provides answers for the former question; addressing the
latter question is equally important, as understanding how factors and their interactions work is likely to be critical for effective cross-layer protocol designs. In this paper, we focus on
identifying both main effects and interactions of factors on service delivery.
There are two aspects to any experimental problem: the design of the experiment, and the statistical analysis of the data.
In the design, we select five factors of mixed levels that represent a useful subset of possible factors to consider in order to
bound our study. The factors we consider are: 1) QoS architecture; 2) routing protocol; 3) MAC protocol; 4) offered load; and
5) node mobility. We select real-time throughput (throughput of
real-time flows only), total throughput (throughput of real-time
and best-effort flows), and average real-time packet delay as our
measures of service delivery (or response variables). We then
perform a statistical analysis of the data collected from experiments run in the ns-2 network simulator [11] using analysis of

0733-8716/04$20.00 © 2004 IEEE

1336

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 22, NO. 7, SEPTEMBER 2004

variance (ANOVA) techniques in the Design-Expert software [12]. This allows us to identify both the main effects and
interactions of factors that best explain the response variables in
our study. Our results show that for delay, several factors in our
experiment interact. For real-time and total throughput, the impact of the routing protocol is not apparent except as it interacts
with other factors of the experiment. The number of factors required to model the data are not as extensive as for delay. These
results indicate that factors cannot be studied in isolation.
As well, the analysis provides a means for a system architect
to determine the level to set the factors to optimize a specific
service delivery metric, or combination of metrics. Among the
factors and factor levels considered, to optimize all three metrics simultaneously requires the dynamic source routing (DSR)
routing protocol running over the enhanced distributed coordination function (EDCF) MAC protocol in the Swan architecture
at slow speed with minimal best-effort traffic. Results for each
metric optimized individually are also presented. In general,
such an analysis may help network designers decide which combination of protocols is most likely to produce the desired performance under the anticipated conditions, ultimately leading to
better service for the users of the network.
The rest of this paper is organized as follows. Section II
describes some of the related work on protocol interaction.
Section III presents the factors and the levels considered in
the design of our experiment and addresses why they were
selected. In Section IV we discuss other parameters of our
simulation study, as well as present and interpret the simulation
results for mobile scenarios with varying load, as well as
fixed load scenarios with varying mobility using the standard
factor-at-a-time approach. Section V presents the statistical
analysis of the simulation results. This includes an effects table
and an analysis of variance table for each response variable,
as well as interaction graphs that illustrate what happens when
factors are varied together rather than one at a time. We relate
these results to the simulation results of Section IV. Finally,
in Section VI, we summarize our findings, discuss future
directions, and conclude.
II. PROTOCOL INTERACTION STUDIES
Since the popularity of the layered design philosophy of networks, there has been a keen interest in identifying which protocols and their interactions affect performance, and how. This
interest has percolated up into MANETs as they have matured.
Many simulation studies of the performance of MANET
routing protocols run over different MAC protocols have been
conducted [13]–[15]. One conclusion of [15] is that the table
driven routing protocols are not affected by the selection of
MAC protocol. On the other hand, the amount of control
traffic generated by a reactive routing protocol is dependent
on the underlying MAC protocol. In particular, throughput
is affected if a routing protocol generates a large number of
unicast compared with broadcast packets since there is more
overhead in transmitting a unicast packet (broadcast is typically
an unreliable primitive).
In Tang et al. [16], MAC layer mechanisms are isolated
to determine the effect of each on network performance.

The mechanisms considered include: carrier sensing, packet
sensing, carrier sensing with collision avoidance, handshake
control packets, and link-level acknowledgments (ACKs). In
general, the handshake mechanism is found to provide better
sharing of the channel since it is a form of coordination among
nodes. ACKs help avoid unnecessary retransmissions, and this
tends to increase throughput.
Koksal et al. [17] examine how short-term unfairness of a
MAC protocol can degrade the performance of transport and
application protocols.
Several studies have examined the interaction of routing
failures on transmission control protocol (TCP) performance
[18]–[21]. In the DSR protocol [22], routing failures can result
from the propagation of stale routes from the cache. In TCP,
if the source is not aware of a route failure it continues to
transmit packets, leading to packet loss. Since packet loss is
interpreted as congestion, TCP invokes a congestion recovery
algorithm when the route is reestablished. This “slow start”
mechanism reduces the transmission unnecessarily and results
in performance degradation in the network.
There are several feedback-based schemes proposed in
which the failure point notifies the source of route failures
and/or reestablishments; see [19], as an example. Such notification allows a node to distinguish route failures from congestion
and apply a different solution for each problem. Fixing retransmission timeout intervals has also been applied to distinguish
between failure and congestion [23].
A large amount of the work on protocol interaction has consisted of simulation studies; there has been little in the way of
formal methodology. One of the first comprehensive studies that
attempts to characterize the interaction between the MAC and
routing protocols in MANETs using more rigorous techniques
is by Barrett et al. [9]. They use statistical design of experiments
to study whether factors interact with each other in a significant way. Statistically, interaction between two factors exists
when the effect of a factor on a response variable is modified
by another factor in a significant way. Starting with a saturated
model, backward elimination is applied. This method checks
each -way factor interaction term for significance using analysis of variance techniques and eliminates it if it is found to be
insignificant. In this way, the smallest model that explains the
simulation data is found.
Another formal methodology, by Scaglione et al. [24], uses
an approach based on source codes, combined with suitable
routing algorithms and the reencoding of data at intermediate
relay nodes, to capture the interdependencies between routing
and data compression. This model is used to show that the
amount of data generated by a sensor network is below its
transport capacity.
Syrotiuk et al. [25] propose modeling protocol interactions
as optimization problems. In one example, an inverse shortest
path problem is set up to model the impact of congestion on
routing. Solving an inverse shortest path problem consists of
finding weights associated with the links of a network that are
as close as possible to the a priori estimated values, and that
are compatible with the observations of the shortest paths used
for routing in the network. This provides a way to compute the
contribution of delay and packet loss to the link weight.

VADDE AND SYROTIUK: FACTOR INTERACTION ON SERVICE DELIVERY

III. DESIGN OF EXPERIMENTS
Following the lead of Barrett et al. [9], [10], we use statistical
design of experiments (DOE) for our study. For completeness,
we define some of the terminology of statistical DOE.
• Factor: A variable in an experiment believed to have some
effect on the observed value of a response variable. If the
domain of possible values for the factor is discrete, it is
called a categorical factor.
• Levels of a factor: The set of discrete values assigned to
a factor.
• Response variable: A variable in the system whose performance is of interest.
• Interaction: The failure of one factor to produce the same
effect on the response variable at different levels of another
factor [8].
In order to apply DOE, the first step is to identify the factors
and the level of each factor for our experiments. In order to
bound our study, we consider the following five factors:
1) QoS architecture;
2) routing protocol;
3) MAC protocol;
4) offered load;
5) node mobility.
The first three (categorical) factors correspond to three layers
of the protocol stack in a MANET architecture. The QoS architecture is an end-to-end protocol that uses mechanisms such as
rate, flow, and admission control, and the rerouting of flows to
regulate best-effort traffic in support of real-time traffic. Traditionally, there is a spectrum of architectures in support of QoS,
ranging from stateless (differentiated services) to stateful (integrated services). For MANETs, an example of a stateless approach is Swan, while Insignia is an example of a stateful approach.
In Swan [1], individual nodes along the route from a source
to a destination do not maintain any state information regarding
the admitted real-time flows. In Swan, admission control is performed at the source node only. The source decides whether to
admit or reject a real-time flow based on the available bandwidth
along the path to the destination node. Intermediate nodes regulate their best-effort traffic to meet the QoS needs of real-time
flows routed through them. The delay at the MAC layer is used
to determine the rate at which to regulate the best-effort traffic.
In Insignia [2], intermediate nodes in addition to the source
perform admission control. This requires QoS state information to be maintained on admitted flows. Insignia performs flow
adaptation and restoration to meet the QoS needs of real-time
flows in order to match them to the available resources; this is
achieved using in-band signaling.
For the factor of QoS architecture, we therefore, consider
three levels: a stateless QoS architecture (Swan), a stateful QoS
architecture (Insignia), and a “classic” QoS architecture with no
provisions for QoS.
The problem of routing is fundamental in MANETs since
each node is capable of functioning as a router, forwarding
packets in addition to being a source, or destination of packets.
While the research in routing protocols has been very active,
two routing protocols, the DSR protocol, and the ad hoc

1337

on-demand distance vector (AODV) routing protocol, have
competed vigorously in numerous studies.
DSR [22] is an on-demand routing protocol that allows nodes
to dynamically discover a source route to any destination in the
network. In source routing, the source is responsible for computing the route for a packet. When a node wishes to communicate with another node, it employs route discovery to flood a
route request (RREQ), through the network, in search of a route
to the destination. When the RREQ reaches the destination or
a node that is aware of a route to the destination, forwarding
stops. A route reply (RREP) packet is sent back to the source on
the reverse path, including a full source route to the destination.
This source route is included in the header of each data packet
and enables stateless forwarding. The route maintenance mechanism monitors the status of source routes in use, detects link
failures and repairs routes with broken links.
AODV [26] is also an on-demand protocol. Similar to traditional distance vector protocols, AODV maintains routing tables
with one entry per destination. AODV builds routes using RREQ
and RREP control packets similar to the route discovery mechanism in DSR. A node receiving the RREQ packet may send
a RREP if it is either the destination or if it has a route to the
destination with corresponding sequence number greater than
or equal to that contained in the RREQ. Otherwise, it rebroadcasts the RREP. As a RREP propagates back to the source, each
node sets up a forward path entry to the destination in its routing
table. Once the source node receives the RREP it may begin to
forward data packets to the destination.
For the factor of routing protocol, we consider two levels:
AODV and DSR. A side effect of the ubiquity of these protocols
is that the source code of each is now very stable.
The MAC protocol is fundamental in all networks whose
basis is a broadcast channel. The MAC protocol is directly
responsible for controlling access to the communication resources. The distributed coordination function (DCF) of the
IEEE 802.11 [27] protocol is the dominant MAC protocol in
MANETs due to its simplicity and lack of synchronization
requirements. It is a carrier sense multiple-access protocol with
collision avoidance (CSMA/CA).
It is well known that IEEE 802.11 is ineffective for differentiated services [28]. EDCF [5], for EDCF, classifies traffic flows
based on their priority. The traffic from each class has a distinct
queue and also a corresponding backoff window. The backoff
counter for each of the transmission queues is run separately and
the data packets of the queue whose backoff counter expires first
are transmitted. If more than one backoff counter expires, data
packets of the queue with the highest priority are transmitted.
For the factor of MAC protocol, we consider two levels: IEEE
802.11 and its QoS-aware extension, EDCF.
The remaining two factors are quantitative. For the factor of
offered load, we consider four levels that correspond to the introduction of an increasing number of interfering best-effort TCP
flows. These flows are initiated between random source and destination node pairs, above and beyond the six real-time flows
established. The number of interfering best-effort flows range
from zero to six in increments of two.

1338

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 22, NO. 7, SEPTEMBER 2004

TABLE I
FACTORS, AND LEVELS OF EACH FACTOR

Finally, for the factor of node mobility, we consider five
levels. Node speed is varied from 10 to 50 m/s in increments of
ten.
Given that we have five factors, with three, two, two, four,
and five levels, respectively, this results in a total of
experiments to carry out for a full factorial design.
(Of course, multiple simulation runs are made for each point;
see Section IV for more details.) Table I summarizes the factors
and levels of each factor.
We reiterate that design of experiments only provides information about the main effects and interactions of factors that are
significant for a certain response variable; it does not fully explain how the main effects and their interactions work to cause
the observed response. Our goal in this paper is to take the first
step of identifying the main effects and interactions of factors
affecting service delivery.
IV. SIMULATION STUDY
A. Simulation Scenarios
We use the network simulator ns-2 [11] to run our experiments due to the extensive support for MANETs. We generate
scenarios in a manner consistent with earlier QoS architecture
studies [1], [2], in which we consider 30 nodes, connected to
their peers via a shared 11 Mb/s interface, distributed over a
1500
300 m area. One difference is that we distribute the
nodes according to the stationary distribution of the random
waypoint mobility model [29], [30]. Thus, from the start of the
simulation, the distribution of the nodes is stationary and it remains stationary for the duration of the simulation. This ensures
higher confidence in the validity of the results. These and additional simulation parameters are provided in Table II.
Fig. 1 shows a snapshot of nodes in the simulation area of one
scenario. We performed simulations with different scenarios and
took the average of six runs for each point; the confidence interval of the results is 95%. Real-time traffic is modeled using
six voice traffic flows of 32 kb/s. The interarrival time of the
real-time packets is 0.1 s. The maximum number of packets
generated for each real-time flow is 2500. The source and destination pairs
of these real-time flows are: (3,18), (17,20),
(0,6), (9,15), (16,26), and (4,14). These pairs are selected to
create multihop paths that traverse the network. These flows
start at simulation times 5, 15, 15, 40, 40, and 15 s, respectively.
The offered load on the network is varied by increasing the
number of best-effort flows. These best-effort flows are modeled
as TCP connections (we use TCP Reno complete with retransmissions and window adjustment) between random source and
destination pairs. An example of six best-effort flows that were
created in a simulation run is: (19,25), (8,29), (11,22), (15,4),
(1,5), (22,14), all initiated at simulation time 40.

For the EDCF MAC protocol, we consider three priority
classes for the traffic: voice, video, and data. The backoff
window size for each class, respectively, is [5,200], [15,600],
and [31,1023].
The measures of service delivery that we collect in each simulation run are the following.
• Average delay: The average end-to-end delay experienced
by a packet between its initiation at the source and its receipt at the destination. This value includes queueing delays, as well as channel access delays. We report the average delay of real-time packets since only the real-time
traffic is delay sensitive.
• Real-time throughput: The number of real-time packets
received per unit time, expressed in bytes per second (each
real-time packet is 512 bytes long). Delay-sensitive applications, such as voice, typically require an end-to-end
delay of 400 ms for acceptable quality. Any real-time
packet received whose delay is greater than 400 ms is not
included in this real-time throughput calculation.
• Total throughput: The combined throughput of real-time
and best-effort traffic. The real-time traffic is assumed to
meet the delay requirement to be included. Best-effort
traffic does not have to meet a delay requirement, hence,
every best-effort packet received at its destination is included. The reason this metric is of interest is to determine
the extent to which the bandwidth unused by real-time
traffic is utilized by the best-effort traffic.
Among other metrics, we also computed the packet delivery
ratio, defined as the ratio of the number of packets received at the
destination to the number of packets sent by the source node. We
found that for all experiments, the performance trend is similar
to the real-time throughput. Hence, we do not present results for
packet delivery ratio separately.
First, we present some typical factor-at-a-time graphs
showing how the response variable is affected by varying a
single factor with all other factors held constant. A disadvantage
of this type of approach is that it fails to consider any possible
interaction between the factors. In Section V, we present a
statistical analysis of the simulation results including an effects
table and an analysis of variance table for each response variable. As well, we present some interaction graphs that illustrate
what happens when factors are varied together rather than one
at a time. We will see that this analysis of the data is far more
informative for identifying the main effects and interactions of
factors that are significant for a given response variable.
B. Results for Fixed Mobility Rate, Varying Load
In this section, we present only a representative subset of the
experimental results for a fixed mobility rate and varying load.
One approach to identify factor interactions is to plot the results
from the perspective of different factors. In these results, the
average speed of the nodes is fixed at 50 m/s and we vary the
offered best-effort load from zero up to six flows in increments
of two.
Briefly, from Figs. 2–4, DSR shows much wider variation in
throughput both in Swan and in Insignia than does AODV for
increasing offered load. In fact, the performance of DSR is more
sensitive to the MAC protocol than the architecture.

VADDE AND SYROTIUK: FACTOR INTERACTION ON SERVICE DELIVERY

1339

TABLE II
SIMULATION PARAMETERS

Fig. 1.

Initial simulation topology.

(a)

(b)

Fig. 2. QoS architecture real-time throughput. (a) Swan. (b) Insignia.

Swan is the most effective architecture of the three studied
to support QoS; this concurs with the results in [1]. DSR over
EDCF performs the best independent of architecture. Similarly,

for AODV run over IEEE 802.11. Hence, the interaction with
the architecture seems less important than the interaction with
the MAC protocol.

1340

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 22, NO. 7, SEPTEMBER 2004

(a)

(b)

Fig. 3. Routing protocol real-time throughput. (a) AODV. (b) DSR.

(a)

(b)

Fig. 4. MAC real-time throughput. (a) EDCF. (b) IEEE 802.11.

C. Results for Fixed Load, Varying Mobility
In this section, we again present only a representative subset
of results. This time, we fix the number of interfering TCP besteffort flows at the maximum, i.e., six, and we vary the speed of
the nodes from 10 to 50 m/s in increments of 10 m/s.
Figs. 5–7 plot real-time throughput from the perspective
of different factors. With respect to mobility on real-time
throughput, IEEE 802.11 copes better than EDCF. Swan reacts
well to mobility when compared with Insignia. However, with
the routing protocol, there is no clear winner; its performance
depends completely on the underlying MAC protocol. As with
increasing load, when AODV runs over IEEE 802.11 and DSR
runs over EDCF both cope well with increasing node speed.
V. STATISTICAL ANALYSIS OF THE EXPERIMENTS
In this section, we present an analysis of variance for the
full factorial model. The following tables were obtained from

Design-Expert, a software package that aids in designing
experiments and in identifying factor interactions. The input to
Design-Expert is the factors, the levels of each factor, and
experimental results (in our case simulation runs) for each response variable. The software performs a statistical analysis of
the input data and presents the factor interactions and significant
factors affecting a given response variable.
We present the statistical analysis of the simulation results in
three formats:
• Effects Table: The most interesting column of the effects
table is the percentage contribution of the main effects and
interactions of factors to the total observed variability of
a particular response variable. This table helps identify
the most important factors affecting a particular response
variable. The greater the contribution of a factor, the larger
its effect on the response variable.
• ANOVA Table: An ANOVA table shows the analysis of
variance between means of different groups, and tests if

VADDE AND SYROTIUK: FACTOR INTERACTION ON SERVICE DELIVERY

(a)

1341

(b)

Fig. 5. QoS architecture real-time throughput. (a) Swan. (b) Insignia.

(a)

(b)

Fig. 6. Routing protocol real-time throughput. (a) AODV. (b) DSR.

the means of the groups formed by values of the independent variable or combination of multiple independent variables are different enough not to have occurred by chance.
If the means of the groups do not differ significantly, then
the independent variables do not have an effect on the dependent variable.
• Interaction Graph: An interaction graph shows how a
change in the level of one factor affects the other factor
with respect to the response variable.
In the following, “A” denotes the QoS architecture, “R” denotes the routing protocol, “M” denotes the MAC protocol, “L”
denotes offered load, and “S” denotes node speed.
A. Response Variable of Average Delay
Table III shows the effects table for the response variable of
average delay. The last column in the table shows the contribution of main effects and interactions of factors to the average

delay as a percentage. As we have five factors in our experiments, we have up to five-way interactions. The entries in the
table in bold represent significant interactions.
As Table III shows, the contribution of the five-way and all
four-way interactions is negligible. All three-way interactions,
except for ARM, contribute very little to the overall average
delay. The interaction between the QoS architecture, the routing
protocol, and the MAC protocol (ARM) accounts for over 3% of
the observed average delay; this is not very significant compared
with other interaction terms.
Of the two-way interactions, the routing and the MAC
protocol (RM) interaction accounts for nearly 40% of the
average delay value—the RM interaction drives this model.
Among other two-way interactions, the QoS architecture and
the routing protocol (AR) interaction, and the QoS architecture
and MAC (AM) protocol interaction together account for just
over 8% of the average delay. All other two-way interactions
do not contribute significantly.

1342

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 22, NO. 7, SEPTEMBER 2004

(a)

(b)

Fig. 7. MAC real-time throughput (a) EDCF. (b) IEEE 802.11.
TABLE III
EFFECTS TABLE FOR AVERAGE DELAY

TABLE IV
ANOVA TABLE FOR AVERAGE DELAY

Among the main effects, the MAC (M) protocol contributes
almost 27%, suggesting the importance of the MAC protocol
in obtaining an acceptable delay. Also, the routing protocol (R)
contributes nearly 9% to the delay, but when it is coupled with
the MAC protocol, its contribution (RM) increases to 40%. This
shows the relative importance of the routing protocol by itself
and in combination with a MAC protocol. These results emphasize that the performance of a protocol has to be studied in conjunction with other protocols and not in isolation.

In summary, nine main effects and interactions of factors are
significant, accounting for over 97% of contribution to average
delay. Two of the terms drive the model, M and RM together
account for over 66% of the average delay response.
A caveat in the interpretation of the effects table is that the
table only shows the relative importance of factors for a particular response variable based on the factors and the levels of each
factor considered. If the levels for each factor are changed, e.g.,
if we consider different MAC protocols, we may observe a different effects table for average delay, as protocols differ in their
operation and interaction.
Next, we present the ANOVA table for the response variable
of average delay. We only choose for presentation those factors
that contribute at least 1% to the response (the nine significant
factors from the effects table).
In Table IV, the model F-value of 350.09 implies that the
model of the data is significant. There is only a 0.01% chance
that a model F-value this large could occur due to noise. The
R-squared value gives the percentage of the response explained
by the factors in the ANOVA table, and corresponds to the effects table. Our goal is to find the minimum set of factors that
contribute maximally to the overall value of the response variable. The F-value shows that of the nine significant terms, the

VADDE AND SYROTIUK: FACTOR INTERACTION ON SERVICE DELIVERY

Fig. 8.

Interaction graph for A and R on average delay.

1343

Fig. 10. Interaction graph for R and M on average delay.

Fig. 10 shows the interaction graph for the routing protocol
and the MAC protocol on average delay. The MAC protocol has
little impact on the average delay in AODV, while for DSR the
impact is very large. It is not obvious why this is the case as both
AODV and DSR are reactive routing protocols; this deserves
more study. One possibility may include the ways that time-outs
in the routing and MAC protocols interact.
B. Response Variable of Real-Time Throughput

Fig. 9.

Interaction graph for A and M on average delay.

MAC protocol (M), and the routing and MAC protocol interaction (RM), dominate for delay. This suggests that in order
to improve the performance of the system for average delay, a
cross-layer protocol design should focus on the RM interaction.
While all main effects are significant for the response variable
of average delay, the MAC protocol (M) is critical. This corresponds well with the simulation results on average delay, and is
consistent with the results of Barrett et al. [9], [10]. The MAC
protocol controls access to the communication resources so its
importance to delay follows.
Figs. 8–10 show the interaction graphs for average delay. The
axis of the graph shows the average delay on a log scale.
As Fig. 8 shows, there is little variation in the average delay
response with a change in the routing protocol for Swan. In contrast, the routing protocol has a large impact on delay in both
the Insignia and the classic architecture. One reason for this behavior might be that since Swan shapes traffic, it is able to influence the delay for real-time packets, so the routing protocol
over which it operates makes little difference. Further evident is
that the performance of AODV is relatively independent of QoS
architecture, while the same is not true of DSR.
Fig. 9 shows the interaction graph for the QoS architecture
and the MAC protocol on average delay. Similar to its interaction with the routing protocol, there is little variation in the
delay for Swan with changing MAC protocol and more for Insignia and the classic architecture. Comparing Figs. 8 and 9, we
see that the routing protocol used with the architecture is more
significant than the MAC protocol for minimum delay.

From Table V, we see that only seven terms are needed to
account for 98% of the response of real-time throughput, fewer
terms than for average delay. None of the five-way or four-way
interaction terms are significant. Of the three-way interaction
terms, only RMS contributes just over 1% to the real-time
throughput. There are two relatively significant two-way interaction terms: AM and RM, contributing over 12% and 26%,
respectively. Both the architecture and the routing protocol
interact with the MAC protocol factor. Of the main effects,
several points stand out. Notably, the routing protocol is not
significant by itself; only in its interaction with the MAC
protocol does it play a role in throughput. In fact, the MAC
protocol is the dominant effect for real-time throughput.
Table VI confirms that the model of the data is driven by M
and RM. (Again, the model F-value of 287.22 implies the model
is significant with only a 0.01% chance that a value this large
could be due to noise.) The results in Section IV do show that the
real-time throughput achieved by both DSR and AODV in the
best cases is similar, but that their best performance is strongly
correlated to the MAC protocol over which they are run. The
statistical results strongly support this conclusion.
Figs. 11 and 12 show the interaction graphs for real-time
throughput. In particular, Fig. 12 strongly illustrates the interaction between RM for this response variable.
C. Response Variable of Total Throughput
As Table VII shows, only five terms are required to explain
96% of the response variable of total throughput, fewer than the
number required for either response of real-time throughput and
average delay. There are no significant five-, four-, or three-way
interaction terms. Of the two-way interaction terms, only AM
and RM are significant, but both very minimally. Of the main
effects, A and L contribute a little more than AM and RM. The
QoS architecture (A) contributes 21% to real-time throughput,

1344

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 22, NO. 7, SEPTEMBER 2004

TABLE V
EFFECTS TABLE FOR REAL-TIME THROUGHPUT

TABLE VI
ANOVA TABLE FOR REAL-TIME THROUGHPUT

as it is concerned with real-time flows. For total throughput, the
QoS architecture (A) contributes only 2.7%, due to its absence
of role in improving the throughput of the best-effort flows. The
routing protocol also contributes less to both responses of realtime and total throughput than to average delay.
Overwhelming, is the contribution of the MAC protocol
alone—88% to the response of total throughput. The ANOVA
results in Table VIII reinforce that the MAC protocol drives the
model of the data. (The model F-value is significant.) Figs. 13
and 14 show the interaction graphs for total throughput. Different from real-time throughput, for total throughput, EDCF
is the MAC protocol of choice, regardless of routing protocol
or QoS architecture.
D. DOE for Network Management
In addition to the statistical analysis of data, the DesignExpert software allows a system architect to determine the

Fig. 11.

Interaction graph for A and M on real-time throughput.

Fig. 12.

Interaction graph for R and M on real-time throughput.
TABLE VII
EFFECTS TABLE FOR TOTAL THROUGHPUT

VADDE AND SYROTIUK: FACTOR INTERACTION ON SERVICE DELIVERY

TABLE VIII
ANOVA TABLE FOR TOTAL THROUGHPUT

Fig. 13.

Interaction graph for R and M on total throughput.

1345

VI. CONCLUSION, FUTURE WORK
In this paper, we used statistical design of experiments to
study the impact of factors and their interaction on the service
delivery in a MANET. We considered the factors of QoS architecture (A), routing protocol (R), medium access control protocol (M), offered load (L), and node mobility (S) in our paper.
The response variables used to measure the service delivered
were real-time throughput, total throughput, and average delay.
The statistical analysis of the data collected by simulation using
analysis of variance techniques provides a powerful tool to support the simulation results, permitting the identification of the
main effects and interaction of factors that best explain the response variables. We have found that for average delay the MAC
protocol (M) and its interaction with the routing protocol (RM)
are the most significant. For both forms of throughput, the impact of the routing protocol is not apparent except as it interacts
with other factors, and the factor interactions are not as extensive
as for delay. It is clear that factors cannot be studied in isolation
for any of the metrics considered. As well, the analysis provides
a means for a system architect to determine the level to set the
factors to optimize a specific service delivery metric, or combination of metrics.
Our future work will extend the experiment to consider the
additional levels of the MAC and routing factors. In particular,
we plan to consider other QoS-aware MAC protocols, specifically scheduled protocols and hybrids, as well as QoS-aware
routing protocols, and study the impact on service delivery in
MANETs. Moreover, we intend to also investigate the question of how the factors interact using regression models or modeling approaches as in [25]. This may be critical for effective
cross-layer protocol designs.
ACKNOWLEDGMENT

Fig. 14.

Interaction graph for A and M on total throughput.

level to set the factors to optimize a specific response, or combination of responses. In the context of our study, this corresponds
to optimizing a specific service delivery metric, or combination
of metrics.
For the factors and levels of factors that we considered, to
optimize the metrics of average delay, real-time throughput,
and total throughput concurrently requires the DSR routing
protocol running over the EDCF MAC protocol in the Swan
architecture at slow speed with minimal best-effort traffic. It
turns out that to minimize average delay alone, the same factors
and levels are used. However, if the goal is to maximize the
real-time throughput, then this is achieved by AODV running
over IEEE 802.11 in Swan, with nodes moving at 40 m/s with
two best-effort flows. This may be verified by the simulation
results in Section IV. If instead the goal is to maximize the total
throughput, then this is achieved by DSR running over EDCF in
Swan, with nodes moving at 10 m/s with two best-effort flows.

The authors are very fortunate to have met D. Montgomery as
a result of this work. His enthusiasm is infectious, and his experience and expertise with DOE have significantly improved their
paper, especially in interpreting their results in Section V. The
authors grateful to the anonymous reviewers, in particular for
one in-depth review that helped them better focus their presentation. They thank the Toilers at the Colorado School of Mines
for ns-2 code for steady-state initialization, and the COMET
group at Columbia University for ns-2 code for Swan and Insignia. Last, but not least, the authors thank C. Polisetty for his
help with the Design-Expert software.
REFERENCES
[1] A. Gahng-Seop, A. Campbell, A. Veres, and L. Sun, “SWAN: Service
differentiation in stateless wireless ad hoc networks,” in Proc. 21st Annu.
Joint Conf. IEEE Computer Communication Societies (INFOCOM’02),
June 2002, pp. 457–466.
[2] S. Leo, G. Ahn, X. Zhang, and A. Campbell, “INSIGNIA: An IP-based
quality of service framework for mobile ad hoc networks,” J. Parallel
Distrib. Comput., vol. 60, no. 4, pp. 374–406, Apr. 2000.
[3] S. Chen and K. Nahrstedt, “Distributed quality-of-service routing
in ad-hoc networks,” IEEE J. Select. Areas Commun., vol. 17, pp.
1488–1505, Aug. 1999.
[4] C. Zhu and M. Corson, “QoS routing for mobile ad hoc networks,” in
Proc. 21st Annu. Joint Conf. IEEE Computer Communication Societies
(INFOCOM’02), June 2002, pp. 958–967.

1346

IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, VOL. 22, NO. 7, SEPTEMBER 2004

[5] M. Benveniste, G. Chesson, M. Hoeben, A. Singla, H. Teunissen, and M.
Wentink, “Enhanced distributed coordination function (EDCF),” IEEE
Working Document 802.11-01/131r1, Mar. 2001.
[6] L. Romdhani, N. Qiang, and T. Turletti, “Adaptive EDCF: enhanced
service differentiation for IEEE 802.11 wireless ad hoc networks,” in
Proc. IEEE Wireless Communications Networking Conf. (WCNC’03),
Mar. 2003, pp. 1373–1378.
[7] J. Sobrinho and A. Krishnakumar, “Quality-of-service in ad hoc carrier sense multiple access wireless networks,” IEEE J Select. Areas
Commun., vol. 17, pp. 1353–1368, Aug. 1999.
[8] D. Montgomery, Design and Analysis of Experiments. New York:
Wiley, 2001.
[9] C. Barrett, A. Marathe, M. Marathe, and M. Drozda, “Characterizing the
interaction between routing and MAC protocols in ad-hoc networks,”
in Proc. 3rd ACM Int. Symp. Mobile Ad Hoc Networking Computing
(MobiHoc’02), 2002, pp. 92–103.
[10] C. Barrett, M. Drozda, A. Marathe, and M. Marathe, “Analyzing interaction between network protocols, topology, and traffic in wireless radio
networks,” in Proc. IEEE Wireless Communications Networking Conf.
(WCNC’03), Mar. 2003, pp. 1760–1766.
[11] The Network Simulator—ns-2. Univ. California, Berkeley. [Online].
Available: http://www.isi.edu. nsname.ns/
[12] Design-Expert Software. Stat Ease, Inc. [Online]. Available: http://
www.statease.com
[13] S. Das, C. Perkins, and E. Royer, “Performance comparison of two
on-demand routing protocols for ad hoc networks,” in Proc. 19th
Annu. Joint Conf. IEEE Computer Communications Societies (INFOCOM’00), Mar. 2000, pp. 3–12.
[14] C. Perkins, E. Royer, S. Das, and M. Marina, “Performance comparison
of two on-demand routing protocols for ad hoc networks,” IEEE Pers.
Commun. Mag., vol. 8, pp. 16–28, Feb. 2001.
[15] E. Royer, S.-J. Lee, and C. Perkins, “The effects of MAC protocols on ad
hoc network communications,” in Proc. IEEE Wireless Communications
Networking Conf. (WCNC’00), Sept. 2000, pp. 543–548.
[16] K. Tang, M. Correa, and M. Gerla, “Effects of ad hoc MAC layer
medium access mechanisms under TCP,” Mobile Networks Applicat.
(MONET), vol. 6, no. 4, pp. 317–329, 2001.
[17] C. Koksal, H. Kassab, and H. Balakrishnan, “An analysis of short-term
fairness in wireless media access protocols,” in Proc. 2000 ACM Int.
Conf. Measurement Modeling Computer Systems (SIGMETRICS’00),
June 2000, pp. 118–119.
[18] A. Ahuja, S. Agarwal, J. Singh, and R. Shorey, “Performance of TCP
over different routing protocols in mobile ad-hoc networks,” in Proc.
IEEE Vehicular Technology Conf. (VTC’00), vol. 3, Tokyo, Japan, 2000,
pp. 2315–2319.
[19] K. Chandran, S. Raghunathan, S. Venkatesan, and R. Prakash, “A
feedback-based scheme for improving TCP performance in ad hoc
networks,” IEEE Pers. Commun. Mag., vol. 8, pp. 34–39, Feb. 2001.
[20] G. Holland and N. Vaidya, “Impact of routing and link layers on TCP
performance in mobile ad hoc networks,” in Proc. IEEE Wireless
Communications Networking Conf. (WCNC’99), vol. 3, June 1999, pp.
1323–1327.
[21]
, “Analysis of TCP performance over mobile ad hoc networks,” in
Proc. 5th ACM Conf. Mobile Networking Computing (MobiCom’99),
1999, pp. 219–230.
[22] D. Johnson and D. Maltz, “Dynamic source routing in ad hoc wireless networks,” in Mobile Computing, T. Imelinsky and H. Korth,
Eds. Norwell, MA: Kluwer, 1996, ch. 5, pp. 153–181.
[23] T. Dyer and R. Boppana, “Comparison of TCP performance over three
routing protocols for mobile ad hoc networks,” in Proc. 2001 ACM Int.
Symp. Mobile Ad Hoc Networking Computing (MobiHoc’01), Oct. 2001,
pp. 56–64.

[24] A. Scaglione and S. Servetto, “On the interdependence of routing and
data compression in multi-hop sensor networks,” in Proc. 8th ACM Int.
Conf. Mobile Computing Networking (MobiCom’02), Sept. 2002, pp.
140–147.
[25] V. Syrotiuk and A. Bikki, “Modeling cross-layer interaction using inverse optimization,” in Ad Hoc Networking, S. Basagni, M. Conti, S.
Giordano, and I. Stojmenovic, Eds. New York: Wiley, 2004, ch. 15,
pp. 411–426.
[26] C. Perkins and E. Royer, “Ad hoc on-demand distance vector routing,”
in Proc. 2nd IEEE Workshop Mobile Computing Systems Applications,
Feb. 1999, pp. 90–100.
[27] W-LAN medium access control and physical layer specifications, IEEE
Standard 802.11, 1999.
[28] S. Choi, J. Prado, N. Shankar, and S. Mangold, “IEEE 802.11e contention-based channel access (EDCF) performance evaluation,” in Proc.
IEEE Int. Conf. Communications (ICC’03), May 2003, pp. 1151–1156.
[29] W. Navidi and T. Camp, “Improving the accuracy of random way-point
simulations through steady-state initialization,” Colorado School of
Mines, Tech. Rep. MCS-03-08, June 2003.
[30] J. Yoon, M. Liu, and B. Noble, “Sound mobility models,” in Proc. 9th
Annu. Int. Conf. Mobile Computing Networking (MobiCom’03), Sept.
2003, pp. 205–216.

Kiran K. Vadde (S’04) received the M.Sc. degree
in information systems from the Birla Institute of
Technology and Science (BITS), Pilani, India, in
May 2000 and the M.S. degree in computer science
from Arizona State University (ASU), Tempe, in
December 2002. He is currently working toward
the Ph.D. degree in the Computer Science and
Engineering Department, ASU.
His research interests are in the areas of ad hoc networks, cross-layer interaction, routing and MAC protocols, quality-of-service, and wireless networks.

Violet R. Syrotiuk (M’99) received the Ph.D. degree
in computer science from the University of Waterloo,
Waterloo, ON, Canada, in 1992.
She joined Arizona State University, Tempe, in
2002 and is currently an Assistant Professor of
Computer Science and Engineering. Her research
is currently supported by three grants from NSF,
and a DARPA Connectionless Networks subcontract
from General Dynamics Decision Systems. She
serves on the Editorial Board of Computer Networks.
Her research interests include mobile ad hoc and
sensor networks, in particular MAC protocols with an emphasis on adaptation,
topology-transparency, and energy efficiency, dynamic spectrum utilization,
mobile network models, and protocol interaction and cross-layer design.
Dr. Syrotiuk serves on the Technical Program Committee of several major
conferences including MOBICOM and INFOCOM. She is a member of the Association for Computing Machinery (ACM).

Apples and Oranges: Comparing Schedule- and
Contention-based Medium Access Control
Jonathan Lutz, Charles J. Colbourn, and Violet R. Syrotiuk
CIDSE, Arizona State University, Tempe, AZ

85287-8809

{jlutz,colbourn,syrotiuk}@asu.edu

ABSTRACT

whether they are contention-based or schedule-based. Nodes
in contention-based protocols such as Aloha [1], MACAW [2],
and IEEE 802.11 [5] transmit messages whenever there is one
to send. If unsuccessful, an attempt to retransmit is made
again at a later time. In contrast, schedule-based protocols
rely on predetermined schedules to coordinate access to the
common channel. A primitive example of scheduled allocation is found in Time Division Multiple Access (TDMA)
where time is divided into frames, then into slots; each node
is assigned a unique transmission slot in a frame.
The pros and cons of contention-based and schedule-based
MAC protocols appear to complement one another. Contention-based schemes are agile but fail to bound maximum delay
or allocate channel capacity fairly between neighbouring
nodes [2]. On the other hand, scheduled protocols exhibit
stable delay characteristics and, in some cases, provide a
maximum delay guarantee [3]. But, unlike contention-based
allocation, they adapt slowly, if at all, to changing network
conditions. A sensible goal is to combine the strengths of
each type of protocol, the adaptability of contention-based
schemes and the stable delay characteristics of schedulebased schemes. A necessary step towards this goal is to
develop techniques for making an unbiased comparison of
the methods with respect to network performance metrics,
and this is our focus here.
There are four principal contributions in this paper. First,
we provide simulation results corroborating the analytical
claims made in [4] regarding variation in delay for the ppersistence and (k, v)-scheduled MAC protocols. Second, a
framework is defined in which the persistence of any MAC
protocol can be measured. The framework is used to compare
the persistence levels found in IEEE 802.11 and scheduled
p-persistence. To the best of our knowledge this is the
first of such comparisons. Third, because persistence values
achieved by scheduled p-persistence and IEEE 802.11 are less
than “ideal,” we develop a method by which fair persistence
values are identified on a per-node basis. The ideal levels are
defined and then used as a standard by which to evaluate
the persistence of IEEE 802.11. Finally, the ideal persistence
levels are used in conjunction with a p-persistence variant
called scheduled vector-persistence. Simulation results of this
MAC protocol reveal a marked reduction in packet drop rate
and improved system throughput when compared to IEEE
802.11 and scheduled p-persistence.
The paper is organized as follows. Preliminary definitions
are given in §2. §3 presents results on throughput, delay,
and drop rate of scheduled p-persistence and IEEE 802.11
to highlight the differences in the schedule- and contention-

Comparison of schedule and contention based MAC protocols
is made difficult by their fundamental differences in approach
to medium access control. This paper provides a way in
which to analyze and compare MAC protocols regardless of
their underlying allocation strategy. To that end a framework is developed in which the persistence of any protocol,
contention- or schedule-based, can be measured. The framework is used to measure and compare the persistence levels
of two prototypical contention- and schedule-based MACs,
IEEE 802.11 and Scheduled p-Persistence. An ideal persistence that provides lexicographically max-min fair access
to the channel is characterized, and used as a bandwidth
allocation scheme. In addition to reducing the unfairness,
simulations employing the ideal persistence values show increased throughput and decreased delay and drop rate when
compared to either Scheduled p-Persistence or IEEE 802.11.

Categories and Subject Descriptors
C.2 [Computer-Communication Networks]: Network
Architecture and Design

General Terms
Algorithms, Design, Performance

1.

INTRODUCTION

The Medium Access Control (MAC) sublayer plays an integral role in the protocol stack of any wireless network. The
broadcast nature of this medium requires that the communication channel be shared by adjacent nodes whose channel
accesses must be coordinated to avoid collisions. This coordination proves difficult even in stationary or centrally
organized networks. The problem is further complicated
when mobility and lack of hierarchy arise; both attributes
commonly found in mobile ad hoc networks (MANETs).
Generally speaking, MAC protocols can be categorized by
their underlying channel allocation mechanism, specifically

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
MSWiM’10, October 17–21, 2010, Bodrum, Turkey.
Copyright 2010 ACM 978-1-4503-0274-6/10/10 ...$10.00.

319

based approaches. The idea of the persistence of IEEE 802.11
is introduced in §4 and then analyzed in §5 after defining ideal
persistence. Results arising from simulations of scheduled
vector-persistence using ideal persistence levels are presented
in §6. Finally in §7, our work suggests that there is much to
be gained from the structure inherent in a schedule-based
MAC protocol, motivating future work.

2.

time of the transceiver is not modelled. Our focus is on
MAC layer behaviour. Network/MAC layer interactions are
avoided by incorporating omniscient routing by which the
ns-2 general operations director (“god” object) selects the
next hop destination by running Dijkstra’s shortest-path
algorithm [10].
Unless otherwise specified, the following configuration is
used for all simulations discussed in this paper. Nodes are
configured with omni-directional wireless antennas with physical parameters chosen to match those of the 914 M Hz Lucent
WaveLAN DSS unicast radios. Both the transmission and
carrier sense ranges of the radios are set to 250 meters. Interface queues are configured as drop tail queues with a
maximum length of 50. The data rate for all transmissions
is set to 11 M bps. UDP provides network layer services and
traffic is created by Constant Bit Rate (CBR) generators
provided with the base installation of ns-2. Randomization is enabled for the CBR generators but the long term
mean packet generation rate is held constant through the
end of each simulation. Source and sink nodes for multi-hop
CBR flows are randomly selected at the start of each simulation and the payload size for all generated packets is set
to 900 bytes. All topologies consist of 50 nodes randomly
placed in a 1500 × 300 meter2 area. Simulations discussed in
this section were run for 320 seconds and with two replicates
each while the simulations discussed in Sections 4, 5, and 6
run for 100 seconds with four replicates each.
The maximum packet retry count for IEEE 802.11 is
capped at seven for RTS, CTS, and short data packets and
reduced to four for all other larger packets. The minimum
and maximum contention window sizes are set to 32 and 1024
slots respectively with the slot length set to 20 microseconds.
The retry count for p-Persistence and Scheduled p-Persistence
is set to 10. Network mobility follows the Random Waypoint
Steady State mobility model and mobility scripts are generated using Toiler’s mobility generator [6]. A new mobility
script is generated from scratch for every simulation.

PRELIMINARIES

In [4], the p-persistence and (k, v)-scheduled MAC protocols are compared and contrasted. In both cases, time is
divided into slots long enough to support a single packet
transmission. When running a p-persistence MAC, a node
transmits in the current slot with probability p and defers
to the next slot with probability q = 1 − p. The decision
to transmit is made without regard to past transmission
attempts. For the (k, v)-scheduled MAC protocol, slots are
organized into frames of length v in which k of the v slots
are selected to hold transmissions. A node running a (k, v)scheduled MAC transmits during the k selected transmission
slots and refrains during all others. In both protocols, nodes
only transmit if they have a packet to send.
The (k, v)-scheduled MAC represents a family of scheduled
protocols whose effective persistence is equal to p = k/v.
Slots can either be selected at random or in some deterministic fashion [4]. In this paper we employ a specific
(k, v)-scheduled MAC protocol, scheduled p-persistence, in
which each node selects a new set of k transmission slots
uniformly at random from all kv possible sets. A new set of
transmission slots is selected at the start of each frame.
Strengths of scheduled p-persistence include that it minimizes both variation in time between transmission slots and
variation in delay.
In contrast to both the p-persistence and scheduled ppersistence protocols, IEEE 802.11 does not set a predefined
persistence level. Rather, it attempts to adapt to surrounding network conditions by backing off when contention is
detected in the network. IEEE 802.11 uses the binary exponential back-off (BEB) mechanism first proposed for use in
wireless networks in [7]. At a high level, in this protocol, a
node selects a random transmission time within the current
contention window. The contention window is doubled in
length following each unsuccessful transmission attempt and
reset to a minimum value after each successful transmission.
The primary design strength of IEEE 802.11 is the ability
to adapt using this simple back-off mechanism. Adaptation
allows the protocol to increase its per-node bandwidth utilization in lightly loaded portions of a network while, at the
same time, backing off in other more heavily loaded regions.

3.

3.1

Scheduled p-Persistence Delay Variation
We define delay for a packet at the MAC layer to be the
elapsed time from when the packet is queued for transmission
at the source node’s MAC layer to the time at which the
packet is successfully received by the next hop destination’s
MAC layer. The structure imposed by the frame in scheduled
(k, v)-persistence constrains the time between consecutive
transmission attempts [4]. Indeed, the time between transmission slots is never larger than v−k slots. In contrast, there
is no worst case bound for pure p-persistence. In general,
when p = k/v is fixed and v increases, the maximum time
that could arise between transmission slots also increases;
p-persistence can be viewed as the limiting behaviour.
To demonstrate this, a series of ns-2 simulations of a
network running the scheduled p-persistence MAC protocol
with a persistence of 0.1 for frame lengths of 10 (1 out of
10) and 100 (10 out of 100) slots is employed. Figure 1
shows a scatter plot of delay for both frame lengths alongside
delay from pure p-persistence. The distribution of expected
delay is nearly identical regardless of MAC protocol or frame
length. Variation in delay, on the other hand, increases with
frame length. Because it has an effective frame length of
infinity, the p-persistence MAC exhibits the highest variation
in delay.

PERFORMANCE COMPARISON

We now explore performance characteristics of scheduleand contention-based MAC protocols. Scheduled p-persistence
is used as a representative for the family of schedule-based
protocols, and IEEE 802.11 is used for the family of contention-based protocols. The results are obtained from ns-2 [8]
simulations of MANETs. Implementations of p-persistence
and scheduled p-persistence were integrated into a custom
ns-2 build. Both slotted protocols implement per packet
acknowledgments similar to those of IEEE 802.11 with the important difference that the slot length is sized to fit both the
data and the acknowledgment in a single slot; the turnaround

320

(a) IEEE 802.11.

Figure 1: Delays for scheduled p-persistence with
frame lengths 10 and 100, and for 0.1-persistence.
Expected delay is on the x-axis and variance in delay
on the y-axis.

3.2

Instantaneous Delay Traces

One of the more striking differences between the slotted
protocols and IEEE 802.11 is demonstrated by the delay
traces shown in Figure 2. Figures 2(a) and 2(b) plot MAC
delay as a function of simulation time for five randomly
selected nodes from the 50 nodes in the network. For both
simulations, the network was loaded with 50 traffic flows
each generating 80 packets per second. From the perspective
of the MAC layer, the flows appear to be elastic because the
persistence levels assigned to the nodes are lower than the
rate at which the CBR generators create packets. Scheduled
p-persistence was run with p = 0.1 and a frame length of 20
slots.
The traces of Figure 2(a) suggest that MAC layer delay in
an IEEE 802.11 network varies widely over time and between
nodes. In fact, the spikes in delay shown in Figure 2(a) are
truncated with the magnitudes of several approaching 1.6
seconds. This should not come as a surprise since nodes
running the IEEE 802.11 MAC protocol adapt their back-off
windows (adjusting the expected time between transmissions)
in response to perceived network conditions. Nodes running
scheduled p-persistence do not adapt, but rather continue
to transmit with the same persistence regardless of network
topology or traffic congestion.

3.3

(b) Scheduled p-persistence with frame length
of 20 and p = 0.1.

Figure 2: Instantaneous delay traces for five randomly selected nodes.

simulations, we divide time into one second intervals over
which throughput is computed for each node. These measurements are then used as the sample set for average and
standard deviation computations. Figure 4 shows system
wide average and standard deviation in throughput for both
scheduled p-persistence (p = 0.1 and a frame length of 20)
and IEEE 802.11.
IEEE 802.11 shows a slightly higher average throughput
but with much higher variation. Scheduled p-persistence
appears to perform well in this particular scenario with competitive overall throughput and limited variation. However,
one should not be misled by this single data point. The value
p = 0.1 happens to be a reasonable choice for this specific
network loading. A different choice for p or a change in network load could significantly change the overall throughput
achieved by the scheduled p-persistence protocol.

System Wide Delay

While the delay traces give a general indicator, they focus
on the performance characteristics of a few specific points
in the network and fail to describe system wide behaviour.
Figure 3 reports average MAC delay for both scheduled ppersistence (p = 0.1 and a frame length of 20) and IEEE
802.11. The error bars mark the standard deviation for the
sample set containing all MAC layer delay times associated
with successful MAC transmissions. While there is no significant difference between expected delays for the two protocols,
the variation in delay (communicated by the error bars) is
much larger for IEEE 802.11.

3.4

3.5

MAC Layer Drop Rate

The lower variation in throughput and delay achieved by
scheduled p-persistence comes at the cost of increased drop
rates; see Figure 5. The rate at which packets are dropped
by scheduled p-persistence is more than double that of IEEE
802.11. This is a direct consequence of adaptation in IEEE
802.11. The longer timeout period in IEEE 802.11 reduces
the likelihood that a packet is dropped.
The delay results for scheduled p-persistence (Figure 3)
must be understood in the context of the higher drop rates in

MAC Layer Throughput

Another important metric is MAC layer throughput, defined as the rate (in packets per second) at which a node
successfully transmits to its neighbours. Throughput is measured at a given node by counting the successful transmissions
performed by the node within a fixed period of time. In our

321

Figure 3: System wide delay.

Figure 5: System wide drop rate.
spends transmitting. In other words, persistence is
Time Spent Transmitting
.
(1)
Total Time
It is then possible to consider the persistence of any MAC
protocol, without the notion of a protocol “slot,” including
IEEE 802.11.
One further modification to the definition of persistence
is required to avoid bias caused by nodes sitting idle with
an empty transmission queue. Nodes in an idle state have
nothing to send and consequently do not access the channel.
Inactivity due to an empty transmission queue should not
influence persistence measurements. In order to eliminate
bias due to idle nodes, the Total Time in Equation (1) is
revised to be the total time during which a packet is queued
for transmission. Persistence is then equal to
p=

Figure 4: System wide throughput.

Figure 5. Every dropped packet spends the maximum possible time queued for transmission before finally being dropped.
Since the delay statistics do not include measurements associated with dropped messages, they can be misleading
when treated in isolation. Drop statistics must always be
considered in the proper context.

4.

p=

Time Spent Transmitting
.
Total Time while not Idle

(2)

Under the persistence of Equation (1) or (2), the maximum
achievable persistence of any protocol is less than one. The
limitations of the physical layer alone, such as receive and
transmit switching times, make 100% channel utilization
impossible. Possibly more significant is the overhead of
the MAC protocol itself. At a minimum, slotted protocols
must oversize the length of each transmission slot to allow for
network clock drift. The slot length may need to be increased
further if the protocol is expected to sense the channel before
transmitting. Even in IEEE 802.11 MAC, DCF Inter Frame
Space (DIFS) and Short Inter Frame Space (SIFS) result in
unused transmission capacity.

THE PERSISTENCE OF IEEE 802.11

For the scheduled p-persistence MAC, we define the persistence of a node to be the probability with which it transmits
during a single slot. Since IEEE 802.11 does not divide time
into transmission slots, this definition is not directly applicable. Yet, under a slightly more general framework, it is
possible to define persistence for both scheduled p-persistence
and IEEE 802.11 in a way that allows for a meaningful comparison between protocols. In this section we present such a
framework and use it to measure node persistence in simulations of both protocols.
The persistence value p defines the number of expected
transmission attempts made during a fixed number of slots (a
fundamental point made in [4]). For example, we can expect
100p transmission attempts within any 100 contiguous slots.
From this point of view, persistence is

4.1

Challenges in Measuring Persistence

As with all metrics, measurements must be performed
on single, well defined events. For persistence, the lowest
level measurement is the instantaneous persistence of a single
packet transmission defined as
pinst =

Transmit Time
.
MAC Latency + Transmit Time

(3)

where Transmit Time is the time required to transmit the
packet and MAC Latency is the time the packet spent queued
for transmission at the MAC layer. In our simulations all
packets are equally sized making the numerator of Equation
(3) a constant. All variation in the metric is driven by
changes in the denominator. In order to average these ratios,
one would normally employ a geometric mean. Because the

# Transmission Attempts
.
p=
# Transmission Slots
When network packets are of equal size and the slot length is
appropriately selected to contain the transmission of a single
packet, persistence also defines the percentage of time a node

322

numerator is a constant, we instead compute the average
and standard deviation for the inverse persistence values
using the computationally easier arithmetic mean. Average
persistence is then taken to be the inverse of the average of
the inverse persistence values.

4.2

persistence values. Figure 7(b) agrees with the expectation
that average persistence of IEEE 802.11 decreases as network
load increases.

Persistence Results

Traces of persistence in scheduled p-persistence and IEEE
802.11 are shown in Figures 6(a) and 6(b), respectively.
Scheduled p-persistence is configured with p = 0.1 and a
frame length of 20. The persistence data points in the traces
are estimated by counting transmissions over 0.1 second intervals. As expected, the measured persistence of nodes
running scheduled p-persistence remains stable and relatively
unchanged while the persistence of IEEE 802.11 changes
dramatically throughout the simulation. This does not come
as a surprise since IEEE 802.11 is constantly adjusting the
size of its contention window at each node.
(a) Scheduled p-persistence with frame length of
20 and p = 0.1.

(a) Scheduled p-persistence with frame length
of 20 and p = 0.1.
(b) IEEE 802.11.

Figure 7: Average Latency and Persistence.

The method used to collect the persistence results in Figures 6 and 7 has a significant weakness. The measurements
only take into account persistence due to data packets. The
control packets, such as RTS, CTS, and ACK in IEEE 802.11,
along with the ACKs of scheduled p-persistence are ignored.
This inaccuracy limits the ability to make precise claims
regarding the persistence of either protocol. Nevertheless,
the current implementation is sufficient to demonstrate the
volatility of IEEE 802.11 persistence.

(b) IEEE 802.11.

Figure 6: Persistence traces for five randomly selected nodes.

5.

Figures 7(a) and 7(b) plot the average and standard deviation for the observed MAC latencies (magnitudes keyed on
the left). Scheduled p-persistence is configured with a persistence of 0.1 and a frame length of 20. The error bars indicate
the deviation from its expected value. Hence using Equation
(3) they also provide a general idea of how persistence varies
as well. The bars in both figures give the average persistence
associated with each network scenario (magnitudes keyed
on the right). Figure 7(a) demonstrates the accuracy of our
measurements with nearly identical theoretical and measured

Upon considering the wide variation in persistence manifested by IEEE 802.11 and the inflexible transmission rate of
Scheduled p-Persistence, it is not clear how either protocol
selects its persistence level appropriately. Does there exist an
ideal persistence against which the effective persistences of
Scheduled p-Persistence and IEEE 802.11 can be compared?
Of course, the notion of an “ideal” persistence must be defined in terms of a concrete goal such as maximum network
throughput or fair bandwidth allocation.
Persistence represents a claim on channel resources, while
fairness measures the appropriateness of that claim in the

323

WHAT IS THE IDEAL PERSISTENCE?

context of all claims made. Therefore we concern ourselves
with fairness rather than, say, total throughput, to determine
the suitability of persistence levels. Of the many definitions
of fairness we use lexicographic max-min fairness [9], which
places importance on the perspective of each individual user.

5.1

the reception capacity of each node to 1 and scale the allocation and demand magnitudes accordingly. The demand
magnitudes and bandwidth allocations then identify both
fractions of channel capacity and fractions of maximum channel consumption. In other words, W and S define persistence
levels (see Equation (1) in §4). W contains desired persistence levels per demand and S contains persistence levels
realizing a fair allocation of bandwidth. Table 1 summarizes
a mapping of the general max-min fairness problem to the
specific problem of fairness at the wireless MAC layer.

General Definition of Fairness

For our purposes, fairness is defined as follows. Consider a
set R of N resources numbered 1 to N , with capacity vector
C = (c1 , . . . , cN ), and a set D of M demands numbered 1
to M , with magnitudes W = (w1 , . . . , wM ). Each demand
i ∈ D requires service from a subset of the resources, say
Ri ⊆ R, as defined by the M × N incidence matrix T = [ti,j ],
ti,j ∈ {0, 1}. In this matrix, ti,j = 1 if demand i ∈ D
requires resource j ∈ R and ti,j = 0 otherwise. Since the
demand utilizes capacity equally and simultaneously for each
resource in Ri the useful allocation assigned to demand i is
limited by the smallest capacity available in any resource in
Ri . The fair solution is represented as an allocation vector
S = (s1 , . . . , sM ) specifying an allocation of resources among
the M demands.
An n-vector x = (x1 , x2 , . . . , xn ) sorted in non-decreasing
order (x1 ≤ x2 ≤ . . . ≤ xn ) is lexicographically greater than
another n-vector y = (y1 , y2 , . . . , yn ) sorted in non-decreasing
order (y1 ≤ y2 ≤ . . . ≤ yn ) if an index k, 1 ≤ k ≤ n
exists, such that xi = yi for 1 ≤ i < k and xk > yk . For
example, the vector (3, 3, 3, 3) is lexicographically greater
than both (1, 10, 1000, 1001) and (2, 3, 4, 5) but not (3, 3, 3, 4)
or (4, 5, 6, 7). A precise definition of lexicographic max-min
fairness is given next; see also [9].

Table 1: Mapping the General Max-min Fair Problem to Fairness at the Wireless MAC

Definition 1. A capacity allocation vector S = (s1 , . . . , sM )
is lexicographically max-min fair if the vector is lexicographically maximal when sorted in non-decreasing order subject
to constraints
si ≤ wi ,
X

si · ti,j ≤ cj ,

Wireless MAC

Demands (D)

All nodes in the network.

Resources (R)

All nodes in the network.

Magnitudes
(W )

Maximum percentage of bandwidth
each node can potentially utilize (i.e.,
a node’s desired persistence level).

Capacities (C)

Maximum reception capacity. All capacities are identical and equal to the
maximum transmission capacity. For
simplicity, they are normalized to one.

Incidence Matrix (T )

Defines the set of nodes within range
of each node (i.e., defines single hop
neighbourhoods in the network).

Allocation Vector (S)

Defines fair persistence levels for all
nodes in the network.

∀i ∈ D, and

5.3

∀ j ∈ R.

The ideal, or max-min fair, persistence levels of Definition
1 can help to analyze MAC layer unfairness. A node is acting
unfairly if its actual persistence level exceeds that of the its
ideal (or fair) allocation. The amount by which a node’s
persistence exceeds the ideal is the magnitude of unfairness
exhibited by the node.
Figure 8 depicts unfairness observed in IEEE 802.11. The
data points identify the average unfairness measured at all
nodes with error bars marking standard deviations. The sample set used to compute the average and standard deviation
is comprised of per node measurements performed once every
one-tenth of a second. Each data point is based on actual and
ideal persistence levels estimated over the previous one-tenth
of a second.
Average unfairness is depressed by the many nodes who do
not use their fair share of bandwidth and, as a result, report
zero unfairness. The problem of unfairness is better demonstrated by the maximum unfairness metric which identifies
the expected maximum unfairness occurring in the network
at any given time. Figure 8 shows how, for a reasonably
loaded network (number of flows not less than 14), one can
expect at least one node in the network to exceed its fair
persistence level by 0.3 transmissions per transmission opportunity. Considering that the average neighbourhood size
is approximately 22 (bandwidth should be shared 22 ways),
this excess in persistence constitutes a severe unfairness in
the network.

i∈D

Conceptually, a demand allocation is considered lexicographically max-min fair if (1) each demand is assigned as
much capacity as any other (limited by the demand magnitudes and capacity available at all bottleneck resources) and
(2) unallocated resources are divided in a lexicographically
max-min fair fashion among remaining demands who have
not experienced a bottleneck and have not been completely
satisfied. The solution S can be determined using a dynamic
program [9].

5.2

General
Problem

Fairness in Wireless Communication

Here the general fairness problem is applied specifically
to wireless channel access. The reception capacity of each
node is a network resource to be shared among neighbouring
nodes. When a node transmits, it consumes a portion of
the reception capacity of all its neighbours. In this way, a
node plays the role of a resource as well as a demand. The
incidence matrix T identifies nodes within transmission range
of each other. Element ti,j is set to 1 if node j is within
transmission range of node i and set to 0 otherwise.
In a homogeneous network in which all nodes are equipped
with the same radio configured for the same transmission
and reception rate we can, without loss of generality, scale

324

Unfairness in IEEE 802.11

(a) IEEE 802.11.
Figure 8: IEEE 802.11 unfairness (excess persistence
relative to ideal persistence).

5.4

Over Allocation of Network Resources

When nodes deviate from the their ideal persistence levels,
they risk more than just unfairness. They run the danger
of over allocating network bandwidth and guaranteeing contention in the network. Unfairness results when one node
consumes bandwidth at the expense of another. In this
scenario, at least the bandwidth is successfully utilized. In
the case of over allocation, bandwidth is lost to contention
and cannot be used by another node in the neighbourhood.
If over allocation is severe, we can expect increased delay,
degraded throughput, and an exacerbated drop rate.
Figure 9(a) shows how allocation of network resources
increases along with overall network load in an IEEE 802.11
network. At 50 flows, the network is completely saturated.
Yet, IEEE 802.11 succeeds in preventing severe overallocation
of network bandwidth. At its worst, the average allocation
is only slightly greater than the channel capacity. By way of
contrast, the over allocation of scheduled p-persistence for
different values of p and a frame length of 1000 is shown in
Figure 9(b). Even for a seemingly moderate persistence of
0.1, an average allocation of twice the channel capacity is
seen.

6.

(b) Scheduled p-persistence with frame length of
1000.

Figure 9: Average allocation of bandwidth over all
neighborhoods in the network.

mance of scheduled vector-persistence when configured with
fair persistence values is compared with both 0.1-persistence
and IEEE 802.11 in Figure 10. Scheduled p-persistence is
configured with p = 0.1 while scheduled vector-persistence
uses fair persistence values. Both scheduled protocols use
a frame length of 1000 slots. The simulations were run on
multiple, randomly defined, static wireless topologies, fully
loaded with an elastic demand on each node.
Figure 10(a) reports average delay and standard deviation
in delay for all three protocols. The results show the average
delay of scheduled vector-persistence to be very near those
of both scheduled 0.1-persistence and IEEE 802.11. The
variation in delay appears to have increased slightly with
respect to scheduled 0.1-persistence, but recall that dropped
packets impact delay statistics.
Figure 10(b) shows average and standard deviation in
throughput for the three protocols. The expected throughput
for scheduled vector-persistence is higher than both scheduled
0.1-persistence and IEEE 802.11, apparently as a result of
more efficient use of network bandwidth.
The most striking advantage of scheduled vector persistence is the dramatic reduction in drop rate shown in Figure
10(c). The ideal persistence levels implemented by the protocol increase the likelihood that each message is delivered
before it is dropped. In light of the low drop rates seen
in scheduled vector-persistence, its corresponding expected
delay is impressive. A drop rate near zero ensures that nearly

SCHEDULED VECTOR-PERSISTENCE

One of the primary limitations of p-persistence, and by extension scheduled p-persistence, is the use of a single networkwide persistence value. There is no single ideal persistence
level for any but the most simplistic networks. The persistence appropriate for one neighbourhood may be entirely
inappropriate for another. A scheduled scheme that defines
the persistence of each node individually stands to improve
network performance over any protocol with a single network
wide persistence. If the per node persistence values are set to
the ideal levels of §5, it is reasonable to expect improvements
in network performance.
We explore this using scheduled vector-persistence. This
MAC protocol behaves identically to scheduled p-persistence
with the exception that each node is configured with its
own independent persistence level. Time is still divided into
frames, and each node still randomly selects the appropriate
number of transmission slots in the frame. Since each node
can be configured with its own persistence, it is possible to use
the ideal persistence levels (computed off-line using a centralized algorithm) as a channel allocation strategy. The perfor-

325

of a MAC protocol, comparisons of contention-based and
scheduled schemes with respect to persistence, and resulting
throughput, delay, and drop rate metrics, have been performed. These in turn led to a fair method to determine
persistence levels for each node, at least in a centralized
environment. Once nodes are equipped with these ‘ideal’
persistence levels, simulations indicate that improvements in
throughput and in fairness can be accompanied by a reduction in delay, variance in delay, and drop rate, when compared
to both IEEE 802.11 and the Scheduled p-Persistence MAC.
Our current experiments suppose that a persistence level
meeting lexicographic max-min fairness is available at each
node, and in these simulation studies such persistence levels
are computed centrally. The next steps are to compute maxmin fair persistence levels in a fully distributed manner, and
to update them to reflect the dynamic nature of the topology
and the traffic demands. Both pose challenging questions.
However, the performance of Scheduled Vector-Persistence
with respect to each of the metrics examined suggests that a
scheduled scheme that can determine and maintain suitable
persistence levels could resolve some of the concerns with
contention-based schemes.

(a) Average delay.

8.

[1] N. Abramson. The ALOHA system - Another
alternative for computer communications. In
Proceedings of the Fall Joint Computer Conference,
pages 281–285, 1970.
[2] V. Bharghavan, A. Demers, S. Shenker, and L. Zhang.
MACAW: A medium access protocol for wireless LANs.
In Proceedings of the ACM Conference on
Communications Architectures, Protocols and
Applications (SIGCOMM’94), pages 212–225, London,
UK, 1994.
[3] I. Chlamtac and A. Faragó. Making transmission
schedules immune to topology changes in multi-hop
packet radio networks. IEEE/ACM Transactions on
Networking, 2(1):23–29, February 1994.
[4] C. J. Colbourn and V. R. Syrotiuk. Scheduled
persistence for medium access control in sensor
networks. In Proceedings from the First IEEE
International Conference on Mobile Ad-hoc and Sensor
Systems (MASS’04), pages 264–273, Fort Lauderdale,
Florida, USA, October 2004.
[5] IEEE. IEEE 802.11, Wireless LAN medium access
control (MAC) and physical layer (PHY) specifications,
1997.
[6] J. Boleng, N. Bauer, T. Camp, and W. Navidi.
Random Waypoint Steady State Mobility Generator
(mobgen-ss). http://toilers.mines.edu/.
[7] P. Karn. MACA - a new channel access method for
packet radio. In Proceedings from the ARRL/CRRL
Amateur Radio 9th Computer Networking Conference,
pages 134–140, 1990.
[8] The Network Simulator ns-2.
http://www.isi.edu/nsnam/ns/.
[9] M. Pióro and D. Medhi. Routing, Flow, and Capacity
Design in Communication and Computer Networks.
Elsevier Inc., 2004.
[10] A. S. Tanenbaum. Computer Networks. McGraw Hill,
fourth edition, 2003.

(b) Average throughput.

(c) Average drop rate.

Figure 10: Comparing scheduled vector-persistence
to scheduled 0.1-persistence and IEEE 802.11. Both
scheduled protocols use a frame length of 1000 slots.
all packets is accounted for in the average delay. This is not
true for the other two protocols with their higher drop rates
and artificially lowered average delay.

7.

REFERENCES

CONCLUSIONS AND FUTURE WORK

Unfairness and high variance in delay have imposed limits
on the capabilities of contention-based medium access control protocols, while scheduled schemes have suffered from
the difficulties of determining suitable transmission rates,
particularly to adapt to changing network conditions. By
developing a general technique for measuring the persistence

326

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 5,

NO. 6,

JUNE 2006

627

Optimizing Protocol Interaction Using
Response Surface Methodology
Kiran K. Vadde, Student Member, IEEE, Violet R. Syrotiuk, Member, IEEE, and
Douglas C. Montgomery
Abstract—Response surface methodology (RSM) is a collection of statistical design and numerical optimization techniques
traditionally used to optimize industrial processes. In this paper, we demonstrate that the methodology can be successfully applied to
the domain of networking. Specifically, we obtain increased throughput with a significant decrease in delay in a ns-2 simulation model
of a mobile ad hoc network (MANET) by using RSM to optimize protocol interaction found by factor screening. Whether the
experimentation is with a stochastic simulation model or a physical system, such as a MANET or a wireless sensor network test-bed,
RSM provides a general and practical methodology to screen factors and robustly and jointly optimize responses.
Index Terms—Statistical methods, experimental design, wireless networks, algorithm/protocol analysis.

æ
1

INTRODUCTION

A

mobile ad hoc network (MANET) is a self-organizing
collection of mobile wireless nodes without any supporting infrastructure. Applications that may benefit from
such technology include rescue and/or emergency operations after a disaster that destroys existing infrastructure,
special operations during law-enforcement activities, and
tactical missions in a hostile and/or unknown territory. Even
commercial gatherings, such as conferences or on-demand,
interactive classrooms, may leverage MANET research.
The layered network architecture design philosophy
continues to dominate in wireless networks, MANETs
included. As a result, tremendous research activity has
focused on optimizing the performance of protocols at
individual layers of the protocol stack. Further gains in
network performance are limited by such improvements;
they are expected to come from optimizing protocol interactions [1]. There are many instances known of protocols in
adjacent (and even nonadjacent) layers interacting with each
other and solutions proposed to address specific negative
interactions. The interaction of the TCP transport mechanism
with congestion is one example [2]. Similarly, the parameter
settings within a protocol can interact and impact performance. No general methodology for identifying and optimizing interactions among and within protocols has emerged. To
address these problems, we propose the use of response
surface methodology (RSM).
RSM evolved from the basic experimental design
techniques developed in the 1920s by R.A. Fisher and
moved experimental design from the agricultural and life

. K.K. Vadde and V.R. Syrotiuk are with the Computer Science and
Engineering Department, Arizona State University, PO Box 878809,
Tempe, AZ 85287-8809. E-mail: {kvadde, syrotiuk}@asu.edu.
. D.C. Montgomery is with the Industrial Engineering Department, Arizona
State University, PO Box 875906, Tempe, AZ 85287-5906.
E-mail: doug.montgomery@asu.edu.
Manuscript received 28 Feb. 2005; revised 13 Aug. 2005; accepted 19 Aug.
2005; published online 17 Apr. 2006.
For information on obtaining reprints of this article, please send e-mail to:
tmc@computer.org, and reference IEEECS Log Number TMC-0047-0205.
1536-1233/06/$20.00 ß 2006 IEEE

sciences to the industrial world. Box and Wilson [3]
pioneered RSM and over the last 50 years it has found
extensive application in product and process characterization, design, and development. Myers and Montgomery [4]
provide a widely used text on RSM. Myers et al. [5] give an
excellent retrospective on RSM, providing a detailed survey
of the literature along with current research directions. RSM
can be applied to data gathered from experimentation with
a stochastic simulation model or a physical system. This
makes the techniques of RSM attractive for application to
MANETs, since high-fidelity simulation models exist (in,
e.g., ns-2, OpNet, QualNet) and MANET and wireless
sensor network test-beds are emerging. RSM provides a
practical methodology to apply to optimize the performance of such systems.
Response surface methodology (RSM) is a collection of
mathematical and statistical techniques used to model and
analyze problems in which a response is influenced by
several variables and the objective is to optimize this
response. RSM is a structured, sequential procedure
involving factor screening, region seeking, characterization,
and optimization. Factor screening is used to identify the
input variables (or factors) that are most influential on the
output variable (or response). Region seeking moves the
operating ranges of the factors toward a region that is
expected to be near the optimum. Once a stationary point is
found, the response surface is characterized, i.e., determined to be a maximum, a minimum, or a saddle-point.
Optimization solves the regression models to identify the
factor values that optimize the response. With RSM, joint
responses may be considered.
In this paper, we study the interactions between the
IEEE 802.11 [6] medium access control (MAC) protocol and
the Ad hoc On demand Distance Vector (AODV) [7] routing
protocol in a MANET. Both the MAC and the routing
protocols are fundamental to the operation of a MANET
since spatial reuse of the broadcast channel requires multihop routing without centralized control. We use statistical
analysis to identify how different factors considered for our
Published by the IEEE CS, CASS, ComSoc, IES, & SPS

628

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 5,

NO. 6,

JUNE 2006

TABLE 1
Two-Level Factorial Design with Three Factors

Fig. 1. Two-level factorial design with three factors and with a center
point.

study impact the network response variables selected and
then apply RSM to determine values for the factors to
improve the intended responses. Specifically, we obtain
increased throughput with a significant decrease in delay in
a ns-2 simulation model of a MANET by using RSM to
optimize the MAC-routing protocol interaction at the price
of a small increase in the control packet overhead and
energy utilized.
The rest of the paper is organized as follows: We start
with an overview of RSM in Section 2; this section can be
skipped by those familiar with RSM. Our experimental setup and the application of RSM addressing the robustness of
the optimization are presented in Sections 3 and 4,
respectively. A discussion of factor dynamics is presented
in Section 5. The use of RSM in practice is discussed in
Section 6. Work related to protocol interaction studies and
RSM is found in Section 7. Finally, conclusions and further
work are described in Section 8.

2

OVERVIEW

OF

RSM

Design of experiments (DoE) is used for factor screening [8];
this identifies the factors that contribute most to the
response variables for further experimentation. A response
variable y can be modeled as a function of the factors
xi ; 1  i  k, as shown in (1):
y ¼ fðxi Þ; i ¼ 1; . . . ; k:

ð1Þ

The goal of RSM is to approximate the function f. This may
be a linear or quadratic function, or involve higher order
terms of the factors. Optimization is then performed on this
function to set appropriate values for the factors optimizing
the responses. The different values to which a factor can be
set constitute the levels of the factor.
An initial model relating responses to factors is obtained
using factorial experimental designs. A factorial design
consists of experiments with a combination of factors
specified at different levels. A two-level factorial design
varies the factors at two different levels. Such designs are
the most suitable in the initial stages of experimentation,
where the goal is to determine the minimum number of

factors that account for the maximum response. Table 1
shows an example two-level factorial design with one center
run. In this example, there are three factors, x1 , x2 , and x3 ,
each with two levels. þ1 and 1 denote the upper and
lower level of a factor, respectively. Fig. 1 shows how the
combinations of factors can be visualized as eight corners of
a cube. Center runs, i.e., runs at the point ð0; 0; 0Þ, are added
to check for curvature. If present, this indicates inadequacy
of a linear model. Factor screening culminates in the
identification of the most important factors and a simple
linear model, as given in (2), relating the response variables
and the design factors:
y ¼ 0 þ

k
X

i xi þ :

ð2Þ

i¼1

In (2),  i denotes the coefficients of the regression model
and  denotes a random error stemming from the
inaccuracy of the model. The regression coefficients are
estimated using the least-squares method. F-tests are used to
determine the accuracy of the model and R2 estimates the
extent to which the model describes the data, i.e., it
determines the total variation in the data explained by the
factors in percentage form. Together, these measures make
up an analysis of variance (ANOVA) table.
After checking for the validity of the model, the firstorder model is used to determine the direction in which the
factors are varied to improve the measured response. The
sign of the coefficient determines the direction to move in
each factor. The magnitude of the movement is determined
from the coefficient itself. This exploration in the factor
space, shown in Fig. 2 to increase the response by gradient
search, is termed the method of steepest ascent.1 In the figure,
X1 and X2 denote the factors and Y denotes the response
being measured. Based on the regression equations obtained from the current region of experimentation, the
direction in which the response Y is increasing is chosen.
Observations are made along the steps; the method halts
when the response starts to decrease. A new two-level
factorial experiment is performed by taking the point of
maximum response as the center point, and an analysis is
conducted to check for curvature.
If the first-order model is insignificant as a result of
curvature, a second-order model is used to fit the data. This
is achieved by expanding the initial factorial design with
1. If the objective is to minimize the response the method is known as
steepest descent.

VADDE ET AL.: OPTIMIZING PROTOCOL INTERACTION USING RESPONSE SURFACE METHODOLOGY

629

Fig. 3. The factorial design expanded with axial points forms a central
composite design (CCD).
Fig. 2. Illustration of steepest ascent.

axial points to form a central composite design (CCD). Fig. 3
shows the experimental design with the addition of axial
points. This design allows for efficient estimation of the
terms in the model:
y ¼ 0 þ

3
X
i¼1

i xi þ

3
X

ii x2i þ

i¼1

3 X
X

ij xi xj þ :

ð3Þ

i<j¼2

pﬃﬃﬃ
The axial distance is from 1.0 to k, where
pﬃﬃﬃ k is the number
of factors. When the axial distance is k the CCD design is
called a spherical design; this improves the predictive ability
of the response surface model [4].
The second-order equation, (3), is used to determine the
point of optimum response using canonical analysis [3].
Confirmatory experiments are run at the new point to verify
the system behavior.

3

EXPERIMENTAL SET-UP

For our study, we use the ns-2 [9] network simulator due to
its extensive support for MANETs. We consider 25 mobile
nodes moving in an area of 1; 000  1; 000 meters. Node
movement follows the random way point (RWP) mobility
model. We distribute the nodes according to the stationary
distribution to improve confidence in the validity of the
results [10]. The nodes move with a uniform speed of 10 m/s.
Nodes are connected to their peers via a shared 11 Mbps
interface. A CBR voice flow generating 10 pkts/sec is
established from a source to a destination. These and
additional simulation parameters are provided in Table 2.

For our study, we focus on the interaction between the
MAC and the routing protocol. We instantiate AODV as the
routing protocol [7] and IEEE 802.11 [6] as the MAC protocol
because both simulation models and test-beds using each
protocol exist [11], [12].
AODV is a reactive routing protocol based on the classic
distance vector approach. AODV sends a route request
(RREQ) control packet to find a route from a source to a
destination. An intermediate node replies to a RREQ if it
already has a route to the destination. Otherwise, it
forwards the RREQ. Once the destination receives the
RREQ it uses a route reply (RREP) control packet to respond.
Intermediate nodes maintain routing table entries in the
forward and in the reverse direction to help route packets
after the route formation is complete and to cope with
changes in topology. AODV uses timers to maintain route
state. The advantage of such a soft-state approach is that it
does not require explicit control messages for route
deletion; this reduces control packet overhead [13].
An intermediate node uses a route error (RERR) control
packet to inform the source about a link failure it detects. A
link failure is detected either by exchanging HELLO packets
frequently with the neigbour nodes or by feedback from the
MAC protocol regarding the link status. In our study, we
use link feedback from the MAC protocol to detect route
failure as it provides a form of interaction between the MAC
and routing protocol.
The distributed coordination function of the IEEE 802.11
[6] is a CSMA/CA (carrier sense multiple access with
collision avoidance) MAC protocol. It uses request-to-send
(RTS) and clear-to-send (CTS) control packets to coordinate

TABLE 2
Simulation Parameters

630

IEEE TRANSACTIONS ON MOBILE COMPUTING,

access to the broadcast channel, and binary exponential
back-off to try to prevent packet collisions.

VOL. 5,

NO. 6,

JUNE 2006

TABLE 3
The Factors and Levels of Each Factor

3.1 Factors
The first step in factor screening is to identify potential
factors affecting the responses being measured. We consider the following factors of AODV and IEEE 802.11 in our
study [14]:
ACTIVE_ROUTE_TIMEOUT: The source and intermediate nodes in AODV use this timer to
maintain route information regarding the next hop.
The value set for this timer determines the life-time
of a routing table entry. The timer is refreshed each
time a packet arrives for the destination corresponding to that entry. If the timer expires, the routing
table entry is deleted.
. MAX_ROUTEREQ_WAIT_TIMEOUT: If a node
does not receive a route reply after RREQ_RETRIES
number of attempts, it waits for this timer to expire
before attempting to initiate another round of route
requests. This timer is used to restrict the RREQ rate.
. MAX_RETRANSMISSIONS: In the IEEE 802.11
MAC protocol, the number of times a packet is
retransmitted before the MAC protocol reports a link
failure to the routing protocol is given by MAX_RETRANSMISSIONS. AODV uses this feedback from
the MAC layer to determine and respond to link
failures. If the MAC protocol declares a link failure
too quickly, it may lead to unnecessary route
discovery and control packet overhead.
We select these factors for our study because node
movement necessitates frequent route formation, route
repair, and rerouting. The values of these factors determine
the route formation dynamics which, in turn, affect the
quality of the communication between nodes.
Some guidelines for AODV timer values are provided in
[15]. Chin et al. [11] applied these guidelines in a MANET
test-bed; however, they were found ineffective to achieve
good network performance and, in the end, trial-and-error
was used. We show that RSM provides a formal methodology to optimize values for these factors and later evaluate
the effectiveness of these values by a performance comparison with the default values.
.

3.2 Response Variables
We measure the network performance in terms of the
following response variables:
.

.

Average throughput. The number of bytes received
at the destination node per second (bytes/sec); this is
a quantitative measure of the network performance.
In order to support high quality voice communication, a voice packet must reach the destination
within 400 ms. In calculating the average throughput, we consider only those packets that have an
end-to-end delay less than or equal to 400 ms; those
having a delay greater are discarded.
Average packet delay. The average time taken for a
packet to reach the destination from a source in
seconds. This is a qualitative metric of the network
performance.

4

OPTIMIZATION USING RSM

4.1 Factor Screening
Table 3 shows the factors and the levels of each factor
considered. The lower and upper end of the range is given
by ½1; þ1. The values for the levels are based on the
default settings of the AODV software distribution used in
the ns-2 simulator (version 2.26). ns-2 uses default values
of 10.5 for the factors ACTIVE_ROUTE_TIMEOUT ðAÞ and
MAX_ROUTEREQ_WAIT_TIMEOUT ðBÞ and 10 for factor
MAX_RETRANSMISSIONS ðCÞ [9]; these values are used
for center runs.
Given the three factors of interest, we perform a
23 factorial screening experiment to identify the percentage
contributions of each factor. We repeated each experiment
20 times with different mobility scenarios. Given that we
have 23 factor combinations and five additional points
(center and axial points), we performed a total of 13  20 ¼
260 experiments for factor screening. We use the DesignExpert software [16] to perform the statistical analysis and
optimization. Table 4 shows the effects table for the screening experiment.2 Terms shown in bold are the statistically
significant terms found from the ANOVA analysis (see
Table 5).
As Table 4 shows, all the factors contribute to the
response variables of delay and throughput. However, the
interactions between the factors are not prominent for the
levels used in the screening experiment. The contribution
not accounted for any of the factors or their interactions is
included in the error. Lower values of error indicate that the
factors have significant contributions to the response
variables. The error values for delay and throughput are
27.71 percent and 11.22 percent, indicating that the factors
considered contribute significantly to the responses.
Factor B, i.e., the MAX_ROUTEREQ_WAIT_TIMEOUT
timer, contributes the most to both delay and throughput.
Table 5 shows the analysis of variance (ANOVA) for
average throughput. ANOVA shows the important factors
contributing to the response variables and their statistical
significance through the F-test. If the value in the last
column of the table is less than 0.05 (95 percent significance
level), the factor is statistically significant (these are shown
in bold). An indication of curvature implies that a linear
equation cannot fit the data. Table 5 shows that curvature is
not significant for the factor ranges considered. So, we can
2. An effects table shows the relative contribution of the factors to the
response variables as a percentage.

VADDE ET AL.: OPTIMIZING PROTOCOL INTERACTION USING RESPONSE SURFACE METHODOLOGY

TABLE 4
Effects Table for Screening Experiments

TABLE 6
Step Movements of Factors in Steepest Ascent

use the data from this screening experiment to fit a linear
equation to average throughput. The R2 value indicates the
proportion of the variability in the data explained by the
ANOVA analysis: 0  R2  1, with larger values being
more desirable.
From the statistical analysis, it is clear that factors B
(MAX_ROUTEREQ_WAIT_TIMEOUT) and C (MAX_RETRANSMISSIONS) are the most significant factors for
average throughput. Regression analysis using the least
squares estimation method on the values of the response
obtained from various combination of the factors yields the
following equation for average throughput:
Average Throughput ¼ 4016:56  14:30A
 101:41B  35:21C:

ð4Þ

The least squares method chooses the coefficients so that
the sum of squares of the errors are minimized. See [8] for a
detailed overview on the estimation method.
For our study, we are interested in maximizing the
throughput with the constraint that packet delays are less
than 400 ms. Hence, we first use the regression equation for
throughput for region exploration. Later, we add the delay
equation for simultaneous optimization of average throughput and delay in the optimization phase.
TABLE 5
ANOVA for Average Throughput

631

4.2 Region Seeking and Characterization
The regression equation for average throughput is used to
explore the factor ranges following the direction in which
throughput is improved. As the signs for all three factors
are negative in (4), we decrease the value for each factor.
The magnitude of the decrease in factor values is
determined from the factor coefficients.
Based on (4) factor B, i.e., the MAX_ROUTEREQ_
WAIT_TIMEOUT, has the largest effect on throughput, so
we move the other factors relative to the movement of B.
The relative movement of factor A is obtained by dividing
its coefficient by the coefficient of factor B. For each
decrease of 1 unit of B, factor A is decreased by 0.14 units
(14:30  101:41) and, similarly, factor C is decreased by
0.35 units (35:21  101:41).
Step size is an important parameter that may impact the
values obtained after optimization. If the step size is large,
we may step over the optimum point and settle for a less
than optimum value. Through sample experiments, we
found that factor B must be changed by at least 0.75 seconds
to observe a change in the throughput, hence, we use 0.75 as
the step size for B.
Table 6 shows the steps from the center points of the
three factors. Since the timer values and the number of
retransmissions must be positive, the method iterates
14 steps. We try to move as far as possible from the origin
within the restrictions set. For factor C, i.e., MAX_ROUTEREQ_WAIT_TIMEOUT, the integer closest to the floating
point value is assigned.
Fig. 4 shows the steepest ascent graph for average
throughput for increasing steps from the origin. As the
figure shows, the throughput varies as we move away from
the origin. The maximum throughput is obtained at step 14.
We use the values at this step for the next experiment. That
is, after steepest ascent, we use the maximum value as the
new starting point for exploration. In this case, we take
factor values at step 14 and use 0:75 seconds for the timers

632

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 5,

NO. 6,

JUNE 2006

TABLE 7
Factors and Levels after Steepest Ascent

impact the response variable most are the variables of the x
and y-axes of the response surface graph.4 The stationary
point, i.e., the point at which the response has the best
performance, is a saddle-point for average throughput and
a minimum for average delay.
Fig. 4. Steepest ascent graph for average throughput.

and 1 for retransmissions as the new ranges for exploration. Table 7 shows the new region of experimentation.3
As in the earlier situation, five center runs are used to
estimate the curvature. Table 8 shows the ANOVA for the
new region of experimentation. The probability value
shows that the interaction between factors B and C is
significant. This time the curvature term is significant
(shown in bold), meaning a linear model is no longer
sufficient to reflect the relation between the factors and the
average throughput. Therefore, in the next step a quadratic
model is fit to the response variables.
Recall from Section 2 that, to fit a quadratic equation, we
expand the experimental design with axial points to form a
central
composite design. The axial distance is from 1.0 to
pﬃﬃﬃ
k, where k is the number of factors. Since we have
three factors
pﬃﬃﬃ in our experiment, we choose the axial distance
to be 3 ¼ 1:68 for our CCD design. Table 9 shows the
factor values at the axial points.
Table 10 shows the ANOVA for average throughput and
average delay with the CCD design. The table shows that
the quadratic terms are significant for both average
throughput and average delay. The fitted second-order
response functions are given in (5) and (6):

4.3 Optimization
To optimize the response variables, we formulate and solve
the problem as a constrained optimization problem. The
objective is to maximize throughput while maintaining the
average delay less than or equal to 400 ms. The DesignExpert software package [16] solves this problem using a
direct search procedure. Once the optimization problem is
solved, Design-Expert provides the values for the factors
that maximize the throughput with the desired delay. The
optimal value for the ACTIVE_ROUTE_TIMEOUT (A) is
9.88 seconds, 0.05 seconds for the MAX_ROUTEREQ_
WAIT_TIMEOUT (B), and 6 for the maximum number of
retransmissions MAX_RETRANSMISSIONS (C). Recall that
the default values of the factors are 10.5 seconds, 10.5 seconds, and 10, respectively (from Table 3): The optimized
value of factor B is dramatically different from the default.
We next examine the impact of these optimized factors on
the network performance.

Given the significant terms and the regression equations
for the response variables, their response surfaces are
explored. A response surface graph shows how a response
variable varies with respect to the significant factors. To
help visualize the shape of the surface, contours (projections
of the surface) are plotted. Fig. 5a and Fig. 5b show the
three-dimensional response surface graphs and corresponding contours for average throughput and average delay
with respect to the design factors. The two factors that

4.4 Performance Evaluation
To validate the results, a performance evaluation using the
factor values obtained through optimization is compared to
the performance using the default factor values in ns-2 for
a completely different set of simulation scenarios. Fig. 6a
and Fig. 6b show the performance comparison with respect
to average throughput and average delay, respectively. In
the figure, the x-axis is the run number and the y-axis is the
average value of the measured response. The lines connect
the moving averages of the responses with successive runs.
As Fig. 6a and Fig. 6b show, the average delay is
significantly lower (about 90 percent less) and the average
throughput is higher (about 8 percent more) with the
optimized factor values than those with the default factor
values. With the default values, the average packet delay is
about 0.22 seconds. However, with the optimized values,
average packet delay is about 0.018 seconds. The optimized
values allow the network to find more opportunities to form
routes than with the default values, thereby increasing the
throughput and minimizing the packet delay.
Next, we evaluate the control packet overhead and
energy consumption, as these responses are related to the

3. The levels of factor B have 0.05 added so that the 1 timeout value is
nonzero.

4. For throughput, (5) shows that factor C has no impact, while, for
delay, (6) shows that A has no impact.

Average Throughput ¼ 4277:89 þ 4:51A  14:06B
þ 14:32A2  18:18B2  9:32B3 ;
Average Delay ¼0:023 þ 0:020B  0:00245C
þ 0:014B2  0:00378BC:

ð5Þ

ð6Þ

VADDE ET AL.: OPTIMIZING PROTOCOL INTERACTION USING RESPONSE SURFACE METHODOLOGY

TABLE 8
ANOVA for Average Throughput for the
New Region of Experimentation

timer values; Fig. 7a and Fig. 7b show this performance
comparison. All nodes have an initial energy of 200 joules;
the presented energy consumption is the average of the
energy spent by all the nodes at the end of the simulation.
As Fig. 7a shows, the control packet overhead is
somewhat higher with the optimized values since the
network is more responsive to link failures. The default
values miss some opportunities to form routes; as a result,
both the control packet overhead and throughput is lower.
Since nodes send more control packets with the optimized
values, their energy consumption is slightly higher than
with the default values.

4.5 Robustness
The optimal values obtained through RSM depend on the
network parameters and the traffic conditions. Changes in
network parameters, e.g., node density or node speed,
affects the results; this, in turn, changes the optimal values
for the factors. Also, depending on the network parameters,
factors at other layers may turn out to be important.
To further understand the impact of network parameters
on the optimal factor values, we conducted experiments

633

TABLE 9
Factors Levels at Axial Points

with varied node speeds and node densities. Specifically,
we conducted experiments with node speeds 10 m/s and
15 m/s, and with 25 and 40 nodes, with all other simulation
parameters unchanged. Table 11 shows these results.
Table 12 shows the performance improvement in delay
and throughput with these settings. In all the cases, the
performance obtained with the optimized factors is higher
than that achieved with the default ns-2 values.
Our study considered one voice flow from a random
source to a random destination. We evaluate the robustness
of the factor values to the network conditions by adding
additional flows. Table 13 shows these results; even with
additional flows, the optimized factor values obtained from
RSM achieve much better results than the default values.
The observed performance improvement in average delay
and throughput with additional flows is consistent; adding
additional flows did not degrade the performance. Hence,
the factor values obtained from RSM are robust to slight
changes in the network conditions.

4.6 AODV Protocol Behavior
As the performance evaluation shows, AODV performs
better using the RSM values than with the default values.
To understand this improvement in performance, we
further analyze the behavior of AODV. We study the
number of route requests, route validity time, and route
formation delays. These are the protocol operations that
change with the change in the timer values. We generate a
new scenario with the same simulation parameters as in
Table 2, i.e., 25 nodes moving with average speed of 10 m/s.

TABLE 10
ANOVA for Average Throughput and Average Delay

634

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 5,

NO. 6,

JUNE 2006

Fig. 5. Response surface graphs for (a) average throughput and (b) average delay.

Fig. 6. Performance comparison (a) average throughput and (b) average delay.

Fig. 8a shows the cumulative route existence period with
respect to the simulation time. This shows the period of
time that any route from the source to the destination
existed. When the timers are set to the optimized values
route duration is longer. As a result, packets from the
source to the destination are not delayed en route,
decreasing the average packet delay. This also allows more
packets to be sent from the source to the destination,
increasing the throughput. Route existence time is related to
the route formation delay; Fig. 8b shows that the route
formation delay is higher with the default timer values.
Fig. 9 shows the number of route request packets
generated with respect to the simulation time. AODV with
the optimized values generates comparatively more RREQs;
whenever a route breaks, it aggressively tries to reform the
route. This explains the longer route existence times, the

lower route formation delays, and the higher control
overhead with the RSM values.
Timers for route request generation are in place to limit
flooding in the network. The time a node should wait before
sending the next round of RREQs should not be fixed
without knowing the current network conditions. If there is
no other flow in the network, then a source node can be more
aggressive in finding the route. A network design engineer
can select different sets of constraints and objectives and
apply RSM to obtain the desired performance.

5

FACTOR DYNAMICS

One important aspect of RSM is factor identification, i.e.,
determining the potential factors in the system believed to
have an impact on the responses. Domain knowledge is a

VADDE ET AL.: OPTIMIZING PROTOCOL INTERACTION USING RESPONSE SURFACE METHODOLOGY

635

Fig. 7. Performance comparison (a) average control packet overhead and (b) average energy consumed.

key ingredient to applying RSM. It helps in determining the
initial ranges of factors for factorial designs and also in
determining the step size during steepest ascent.
There can be many factors that potentially influence the
response of interest. The set of factors affecting a response
may not be the same across different network settings. As
the network settings change, the set of factors impacting the
responses may also change. One way to express this is by
using weights on factors. A weight of one is used when the
factor affects the response; a weight of zero indicates that
the factor has no affect on the response. Assuming all the
factors have an initial weight of one, based on the network
parameters, the weights of some or all of the factors may
change.
We illustrate our point using the same experimental
setting in the earlier sections (see Table 2) with a change in
the number of nodes. We increase the number of nodes
from 25 to 50 and then to 60. We use the same factors and
levels as shown in Table 3. The effects table for the response
of average delay with the change in number of nodes is
shown in Table 14. We provide the effects table for the case
when the number of nodes is 25 for comparison.
Table 14 shows that the percentage contribution of the
factors and their interactions have changed significantly. In
the 25 node setting, factor B is very significant, contributing
around 63 percent to delay. However, in the 50 and 60 node
setting, factor B has no significance. Also, all two-way
factor interactions are very significant in the 50 node setting,
TABLE 11
Optimal Factor Values for Differing
Node Speeds and Node Densities

whereas they are not significant in the 25 node and 60 node
setting.
When the number of nodes in the network is increased to
50 or 60, if a route needs to be formed or repaired, there are
more opportunities to form routes, since more nodes try to
find or repair routes. This effectively increases the probability that a successful route is formed within the specified
wait time, avoiding the need for repeating route requests.
Hence, the timer, i.e., factor B, never reaches the expiration
time, so changing its value does not impact the average
packet delay. This shows the importance of understanding
the details of the protocols themselves to identify the
behavior that causes such a shift in factor importance. This
knowledge can further be used to change the set of factors
and/or change the initial factor ranges for experimentation.
We demonstrated the application of RSM with the
assumption that average network speed and node densities
are known and that they do not deviate significantly from
the average values. However, in some applications, the
dynamic nature of MANETs may violate these assumptions. In such cases, RSM has to be applied dynamically to
adapt to the current network conditions. This requires
network feedback and model checking to determine when
to change the estimated regression model to capture the
current network conditions. We are currently working in
this direction to optimize the factors on-the-fly; this
involves research on statistical process control.

6

RSM

IN

PRACTICE

The factors involved in an experiment can be either
quantitative or qualitative. A quantitative factor is one
whose levels can be associated with points on a numerical
scale (e.g., node speed). A qualitative factor is one for which
the levels cannot be arranged in order of magnitude. RSM
cannot be applied to qualitative factors. While RSM has
been applied to optimizing an interaction between protocols
in this paper, it could be applied equally well to optimizing
interactions among parameters of a protocol. Extensive
presentations of RSM are in Myers and Montgomery [4].

636

IEEE TRANSACTIONS ON MOBILE COMPUTING,

VOL. 5,

NO. 6,

JUNE 2006

TABLE 12
Performance Comparison with Varied Network Settings

Process knowledge is required to select the design factors,
choose the ranges over which these factors are varied, and
how many levels of each to use. Usually, process knowledge is a combination of practical experience and theoretical understanding. It is important to investigate all factors
that may be of importance, especially in the early stages of
experimentation. Thought must be given to how factors are
controlled at the desired values and how they are
measured.
Usually, it is unnecessary to run all possible combinations of factor levels. A fractional factorial experiment is a
variation of the basic factorial design in which only a subset
of the runs are made. These are used extensively in
industrial research and development and for process
improvement. Robust parameter designs are used to reduce
process variation by choosing levels of controllable factors
that make the system insensitive (or robust) to changes in a
set of uncontrollable factors that represent most of the
sources of variability. See Montgomery [8] for an overview
of these, and other, techniques.

7

RELATED WORK

Many simulation studies have been undertaken to identify
interactions between the MAC and routing protocols in
MANETs (see [17] for a summary). However, these studies
do not take advantage of statistical techniques to design the
experiment. Not only can this potentially greatly reduce the
number of runs in the experiment, but by changing factors
together, factor interactions can be identified. It also paves
the way for optimization.
Statistically designed experiments have been used to
characterize and optimize systems since the 1920s. There
TABLE 13
Robustness to Additional Flows

have been extensive applications of designed experiments
in fields as diverse as agricultural field trials and design of
mechanical systems. Designed experiments, particularly
RSM, have been widely used to study simulation models of
systems in situations where direct experimentation with the
system is inconvenient or impossible. For examples and
discussion, see Myers et al. [18], Hood and Welch [19], and
Myers and Montgomery [4].
More recently, DoE has been applied to ad hoc networks
too. Perkins et al. [20] study the impact of the factors of node
speed, pause time, network size, number of traffic sources,
and routing protocol on average throughput, routing overhead, and power consumption. The conclusion is that the
number of traffic sources has the most impact, followed by
network size and, then, node speed. Barrett et al. [1] study
whether routing and MAC protocols interact with each
other in a significant way under different network loads and
node mobility models. Based on the ANOVA, no single
combination of routing and MAC protocol was found to
dominate other combinations over all mobility models.
Vadde and Syrotiuk [17] used similar techniques to study
the impact of QoS architectures, routing protocols, and
MAC protocols on service delivery in MANETs, using
interaction graphs to visualize the two-way interactions
between factors. All of these studies examine interactions
and effects at the protocol level.
While such studies provide information about high-level
protocol interactions, they do not immediately allow us to
exploit the interaction to improve the network performance.
This requires an in-depth look at the interaction. Bai et al.
[21] use the notion of building blocks to identify similarities
and differences between the AODV and DSR routing
protocols. They conclude that, although AODV and DSR
have similar blocks, the differences in the parameter values
of these blocks lead to the difference in their performance.
Another method to determine values for the factors is by
successive trial-and-error until reasonable performance is
obtained. A test condition is selected, values for the factors
are set, and the performance is measured. Based on the
observed test performance, the values are changed and
performance is measured again. This process usually
proceeds one parameter at a time and is repeated until
satisfactory improvement is observed. To the best of our
knowledge, this is how the factors for major routing and
MAC protocols have been set in simulation models [15] and
in MANET test-beds [11].

VADDE ET AL.: OPTIMIZING PROTOCOL INTERACTION USING RESPONSE SURFACE METHODOLOGY

637

Fig. 8. Performance comparison (a) route existence time and (b) route formation delay.

Recently, there has been tremendous interest in building
test-beds. Some of the related work in this direction is an
implementation of AODV by Royer and Perkins [12], of DSR
by Maltz et al. [22], [23], of ODMRP [24], and of ABR by Toh
and Delawar [25]. These implementations specifically focus
on the effects of various network settings on the protocol
performance. Protocol performance in terms of control
packet overhead, average delay and average throughput is
measured by changing network factors such as node
mobility and number of hops one at a time.
Cui et al. [26], [27] have studied cross-layer optimization
using analytical modeling. In [26], modulation and multiaccess schemes are jointly optimized leading to the development of a variable length TDMA scheme with adaptive
modulation to minimize the delay in data collection for
sensor networks. In [27], the work is extended to include the
routing protocol. Then, joint optimization is performed to
determine whether to transmit data over a single-hop or

over multile hops under energy constraints. Analytical
modeling requires simplification of the system under study
to be able to derive a model for the problem. Also, network
variability in terms of node mobility and channel conditions
make it hard to model a system analytically.

8

CONCLUSIONS

Response surface methodology and design of experiments
encompass techniques to identify the significance of factors
and factor interactions to optimize their values for improved
system performance. In this paper, we have demonstrated
that the methodology can be successfully applied to the
domain of networking. We use design of experiments for
factor screening—to identify significant timers in the
AODV routing protocol and the number of retries before
declaring link failure in the MAC protocol affecting
MANET performance. We then apply RSM to optimize the
values for the significant factors to improve the average
packet delay and the average throughput. We demonstrate
TABLE 14
Effects Table Comparison for Delay

Fig. 9. Number of cumulative route requests generated.

638

IEEE TRANSACTIONS ON MOBILE COMPUTING,

the effectiveness of RSM by comparing the performance of
the optimized values with the default values. A significant
decrease in average packet delay and an increase in
throughput is obtained using the RSM optimized values at
the cost of a small increase in control packet overhead and
energy utilization. Our research not only adds to the
knowledge of how different parameters of protocols affect
the network performance but also helps to optimize them to
achieve the desired performance. While we have applied
RSM to data gathered from experimentation with a
stochastic simulation model, it may also be applied to data
gathered from a physical system. Demonstrating the
effectiveness of RSM in an ad hoc network test-bed is part
of our ongoing work. Whether it is a simulation based or a
real test-bed, RSM can be used to characterize and improve a
system. In addition, RSM can also aid in analytical modeling
to determine which parameters to include in a theoretical
model of a system.
RSM can be used to optimize factor values as long as the
network is uniform with respect to link failures and
network traffic. A network with a wide variability in
topology and network conditions needs a mechanism to
adjust these values dynamically. One way to set the values
dynamically is to use feedback on the current network
conditions and run the optimization on-the-fly. In our
current research, we are investigating discrete and continuous approaches to statistical process control for adaptation
to changing network conditions.

ACKNOWLEDGMENTS
This research was supported in part by US National Science
Foundation grant ANI-0240524. Any opinions, findings,
conclusions, or recommendations expressed in this paper
are those of the authors and do not necessarily reflect the
views of the US National Science Foundation.

REFERENCES
[1]

[2]
[3]
[4]
[5]

[6]
[7]
[8]
[9]

C.L. Barrett, A. Marathe, M.V. Marathe, and M. Drozda,
“Characterizing the Interaction between Routing and Mac Protocols in Ad-Hoc Networks,” Proc. Third ACM Int’l Symp. Mobile
Ad Hoc Networking and Computing (MobiHoc ’02), pp. 92-103, 2002.
G. Holland and N. Vaidya, “Analysis of TCP Performance over
Mobile Ad Hoc Networks,” Proc. Fifth ACM Conf. Mobile
Networking and Computing (MobiCom’99), pp. 219-230, Aug. 1999.
G.E.P. Box and K.B. Wilson, “On the Experimental Attainment of
Optimum Conditions,” J. Royal Statistical Soc., Series B, pp. 1-45,
1951.
R.H. Myers and D.C. Montgomery, Response Surface Methodology.
John Wiley & Sons, Inc., 2002.
R.H. Myers, D.C. Montgomery, G.G. Vining, C.M. Borror, and
S.M. Kowalski, “Response Surface Methodology: A Retrospective
and Literature Survey,” J. Quality Technology, vol. 36, no. 1, pp. 5377, Jan. 2004.
“IEEE Standard 802.11: W-LAN Medium Access Control &
Physical Layer Specifications,” Dec. 1999.
C.E. Perkins and E.M. Royer, “Ad Hoc On-Demand Distance
Vector Routing,” Proc. Second IEEE Workshop Mobile Computing
Systems and Applications, pp. 90-100, Feb. 1999.
D.C. Montgomery, Design and Analysis of Experiments. John Wiley
& Sons, Inc., 2005.
“The Network Simulator—ns-2,” Univ. of California, Berkeley,
http://www.isi.edu/nsnam/ns/, Mar. 2006.

VOL. 5,

NO. 6,

JUNE 2006

[10] W. Navidi and T. Camp, “Stationary Distributions for the Random
Waypoint Mobility Model,” IEEE Trans. Mobile Computing, vol. 3,
no. 1, pp. 99-108, Jan. 2004.
[11] K.W. Chin, J. Judge, A. Williams, and R. Kermode, “Implementation Experience with Manet Routing Protocols,” ACM Computer
Comm. Rev., vol. 32, pp. 49-59, Nov. 2002.
[12] E.M. Royer and C.E. Perkins, “An Implementation Study of the
AODV Routing Protocol,” Proc. IEEE Wireless Comm. and
Networking Conf. (WCNC), vol. 3, pp. 23-28, Sept. 2000.
[13] S. Lee, G. Ahn, X. Zhang, and A. Campbell, “INSIGNIA: An IPBased Quality of Service Framework for Mobile Ad Hoc Networks,” J. Parallel and Distributed Computing (JPDCS), vol. 60, no. 4,
pp. 374-406, Apr. 2000.
[14] K.K. Vadde and V.R. Syrotiuk, “Factor Interaction on Service
Delivery in Mobile Ad Hoc Networks,” IEEE J. Selected Areas in
Comm., vol. 22, no. 7, pp. 1335-1346, Sept. 2004.
[15] C.E. Perkins, E.M. Royer, and S.R. Das, “Ad Hoc on Demand
Distance Vector (AODV) Routing,” IETF Draft, Oct. 2003.
[16] “Design-Expert Software,” Stat Ease Inc., http://www.statease.
com, Mar. 2006.
[17] K.K. Vadde and V.R. Syrotiuk, “On Timers of Routing Protocols in
Manets,” Proc. Third Int’l Conf. Ad Hoc Networks and Wireless
(AdHoc Now ’04), pp. 330-335, July 2004.
[18] R.H. Myers, A.J. Khuri, and W.H. Carter, “Response Surface
Methodology: 1966-1988,” Technometrics, vol. 31, pp. 137-157, May
1989.
[19] S.J. Hood and P.D. Welch, “Response Surface Methodology and
Its Application in Simulation,” Proc. Winter Simulation Conf.,
pp. 115-122, 1993.
[20] D. Perkins, H. Hughes, and C.B. Owen, “Factors Affecting the
Performance of Ad Hoc Networks,” Proc. IEEE Int’l Conf. Comm.,
vol. 5, pp. 2048-2052, 2002.
[21] F. Bai, N. Sadagopan, and A. Helmy, “BRICS: A Building-Block
Approach for Analyzing Routing Protocols in Ad Hoc Networks
—A Case Study of Reactive Routing Protocols,” Proc. Int’l Conf.
Comm. (ICC’04), vol. 6, pp. 3618-3622, June 2004.
[22] D.A. Maltz, J. Broch, and D.B. Johnson, “Experiences Designing
and Building a Multi-Hop Wireless Ad-Hoc Network Testbed,”
Technical Report CMU-CS-99-11, Carnegie Mellon Univ., Mar.
1999.
[23] D.A. Maltz, J. Broch, and D.B. Johnson, “Lessons from a Full-Scale
Multihop Wireless Ad Hoc Network Testbed,” IEEE Personal
Comm. Magazine, vol. 8, no. 1, pp. 8-15, Feb. 2001.
[24] S.H. Bae, S.-J. Lee, and M. Gerla, “Unicast Performance Analysis
of the ODMRP in a Mobile Ad-Hoc Network Testbed,” Proc. IEEE
Conf. Computer Comm. and Networks (ICCCN ’00), pp. 148-153, Oct.
2000.
[25] C.K. Toh and M. Delawar, “Implementation and Evaluation of an
Adaptive Routing Protocol for Infra-Structureless Mobile Networks,” Proc. IEEE Int’l Conf. Computer Comm. and Networks, pp. 1618, Oct. 2000.
[26] S. Cui, A.J. Goldsmith, and A. Bahai, “Joint Modulation and
Multiple Access Optimization under Energy Constraints,” Proc.
IEEE Global Telecomm. Conf., vol. 1, pp. 151-155, Dec. 2004.
[27] S. Cui, R. Madan, A.J. Goldsmith, and S. Lall, “Joint Routing,
MAC, and Link Layer Optimization in Sensor Networks with
Energy Constraints,” Proc. IEEE Conf. Comm. (ICC ’05), May 2005.
Kiran K. Vadde received the MS degree in
computer science from Arizona State University
(ASU) in December 2002 and the MSc degree in
information systems from the Birla Institute of
Technology and Science (BITS), Pilani, India, in
May 2000. He received the PhD degree in
computer science from ASU in 2005. His
research interests are in the areas of ad hoc
networks, cross layer interaction, routing and
MAC protocols, quality of service, and wireless
networks. He is a student member of the IEEE.

VADDE ET AL.: OPTIMIZING PROTOCOL INTERACTION USING RESPONSE SURFACE METHODOLOGY

Violet R. Syrotiuk received the PhD degree in
computer science from the University of Waterloo (Canada) in 1992. She joined Arizona State
University in 2002 and is currently an assistant
professor of computer science and engineering.
Dr. Syrotiuk’s research is currently supported by
three grants from the US National Science
Foundation and a contract with Los Alamos
National Laboratories and Defence Science and
Technology Organisation in Australia. She
serves on the editorial board of Computer Networks and on the
technical program committee of several major conferences, including
MobiCom and Infocom. Her research interests include mobile ad hoc
and sensor networks, in particular, MAC protocols with an emphasis on
adaptation, topology-transparency, and energy efficiency, dynamic
spectrum utilization, mobile network models, and protocol interaction
and cross-layer design. She is a member of the ACM, the IEEE, and the
IEEE Computer Society.

639

Douglas C. Montgomery is the ASU Foundation Professor of Engineering and Professor of
Statistics at Arizona State University. He has
held faculty appointments at the Georgia Institute of Technology as a professor of industrial
and systems engineering and at the University of
Washington, where he held the John M. Fluke
chair in engineering. His research interests are
in industrial statistics and applications of operations research. He is the author of 15 books and
more than 175 technical papers. He is a recipient of the Shewhart
Medal, the Brumbaugh Award, the Hunter Award, and the Shewell
Award (twice) from the American Society for Quality Control. He is also a
recipient of the Ellis R. Ott Award. He is the one of the chief editors of
Quality & Reliability Engineering International, a former editor of the
Journal of Quality Technology, and a member of several other editorial
boards. Professor Montgomery is a fellow of the American Statistical
Association, the American Society for Quality Control, the Royal
Statistical Society, and the Institute of Industrial Engineers, and is also
an elected member of the International Statistical Institute.

. For more information on this or any other computing topic,
please visit our Digital Library at www.computer.org/publications/dlib.

464

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 16, NO. 2, APRIL 2008

Rateless Forward Error Correction for
Topology-Transparent Scheduling
Violet R. Syrotiuk, Member, IEEE, Charles J. Colbourn, and Sruthi Yellamraju

Abstract—Topology-transparent scheduling for mobile wireless
ad hoc networks has been treated as a theoretical curiosity. This
paper makes two contributions towards its practical deployment:
1) We generalize the combinatorial requirement on the schedules
and show that the solution is a cover-free family. As a result, a much
wider number and variety of constructions for schedules exist to
match network conditions. 2) In simulation, we closely match the
theoretical bound on expected throughput. The bound was derived
assuming acknowledgments are available immediately. We use
rateless forward error correction (RFEC) as an acknowledgment
scheme with minimal computational overhead. Since the wireless
medium is inherently unreliable, RFEC also offers some measure
of automatic adaptation to channel load. These contributions
renew interest in topology-transparent scheduling when delay is
a principal objective.
Index Terms—Mobile ad hoc networks, rateless forward error
correction, topology-transparent scheduling.

I. INTRODUCTION

A

mobile ad hoc network (MANET) is a collection of mobile wireless nodes that establish communication without
any centralized control or fixed infrastructure. Since the radio
transmission range of each node is limited, a packet may be forwarded over multiple hops to reach its destination. This limitation also introduces the potential for spatial channel reuse. Most
medium access control (MAC) protocols attempt to exploit this
potential in order to minimize delay and maximize throughput
on a per hop basis.
Scheduled approaches to channel access provide deterministic rather than probabilistic delay guarantees. This is important
for applications sensitive to maximum delay. Furthermore, the
control overhead and carrier sensing associated with contention
MAC protocols can be considerable in terms of time and energy
[1]. The challenge with scheduling is to achieve a reasonable
throughput objective.
Two approaches have emerged to exploit spatial reuse in
response to topology changes. Topology-dependent protocols alternate between a contention phase in which neighbor
information is collected, and a scheduled phase in which

Manuscript received June 6, 2004; revised December 7, 2005, July 9,
2006, and October 22, 2006; approved by IEEE/ACM TRANSACTIONS ON
NETWORKING Editor M. Zukerman. This work was supported in part by
the National Science Foundation (NSF) under Grant ANI-0105985 and by
the Army Research Office (ARO) under Grant DAAD 19-01-1-0406. Any
opinions, findings, conclusions, or recommendations expressed are those of the
authors and do not necessarily reflect the views of NSF or ARO.
The authors are with the Department of Computer Science and Engineering,
Arizona State University, Tempe, AZ 85287-8809 USA (e-mail: syrotiuk@asu.
edu; colbourn@asu.edu).
Digital Object Identifier 10.1109/TNET.2007.899018

nodes follow a schedule constructed using the neighbor information (see, as examples, [2], [3]). In contrast, the idea in
topology-transparent protocols is to design schedules that are
independent of the detailed network topology. Specifically, the
schedules do not depend on the identity of a node’s neighbors,
but rather on how many of them are transmitting. Even if a
node’s neighbors change its schedule does not; if the number
of neighbors does not exceed the designed bound then the
schedule still succeeds.
The existing topology-transparent protocols depend on two
parameters: , the number of nodes in the network, and , the
maximum node degree. Chlamtac et al. [4] gave a construction
based on Galois fields and finite geometries using the algebraic
property that polynomials of bounded degree cannot have many
roots in common; informally, their intersection is small. The
schedules derived from the polynomials share the same intersection property and do not overlap in too many slots. In their
scheme if a node has at most neighbors, there is at least one
collision-free slot to each neighbor within a frame. Their focus
was on parameters to minimize schedule length.
Ju et al. [5] argued that the parameters satisfying the condition on delay do not maximize the minimum throughput. They
showed it is possible to achieve higher minimum throughput at
the expense of longer frame length. Intuitively, while Chlamtac
et al. strive to get one free slot to each neighbor per frame, Ju et
al. aim to get many slots to the same neighbor per frame. There
are complex trade-offs between the design parameters and the
delay and throughput characteristics of the resulting schedules
[6].
Since its introduction, topology-transparent scheduling has
remained a theoretical curiosity. The reasons for this relate to
the following assumptions: 1) Suitable design parameters and
can be selected. 2) Given and , a construction for schedules exists. 3) A method for frame synchronization exists. 4) A
method to distribute schedules to nodes exists. 5) The neighborhood bound is not exceeded. 6) Feedback on the outcome of a
slot is available at the end of that slot; for unicast, this is required
by the transmitter to decide whether to retransmit the packet.
While it is arguable whether the assumptions (1)–(5) are
strong or weak, the assumption in (6)—which underlies the
analysis in both [4] and [5]—is wrong for a MANET. Only the
receiver, and not the transmitter, can determine the outcome of
a transmission. Hence if the transmitter is to know the outcome,
it must gain this knowledge from the receiver.
In this paper, we make two contributions towards the practical deployment of topology-transparent scheduling: 1) We
generalize the combinatorial requirement on topology-transparent schedules and establish that the solution is a well known
object called a cover-free family. Thus a wealth of combinatorial tools is available for schedule construction. 2) We

1063-6692/$25.00 © 2008 IEEE

SYROTIUK et al.: RATELESS FORWARD ERROR CORRECTION FOR TOPOLOGY-TRANSPARENT SCHEDULING

demonstrate, via simulation for both static and mobile ad hoc
networks, that the expected throughput using rateless forward
error correction (RFEC) closely matches the theoretical bound
that assumes immediate feedback availability. Thus unicast can
be effectively implemented with low computational overhead.
We use LT coding [7], a RFEC scheme that does not require
knowledge of the loss rate on the channel. It permits fast
encoding and decoding algorithms; decoding is successful in
recovering the original message once an amount of data only
marginally larger than the original data is received. For our
purposes, any scheme offering these features would suffice.
In fact, there are a number of schemes that could be used; see
Richardson and Urbanke [8] for a thorough discussion of low
density parity check (LDPC) codes. In particular, in cases with
bit flips or low loss rates, coding schemes other than LT, such
as Raptor codes [9], may be more suitable. In our context, it is
assumed that bit errors are corrected by the protocols independently of collisions. Moreover collisions, which are the only
cause of erasures, are frequent events. Hence while LT may not
be the best selection it is anticipated to be a reasonable choice.
Naturally, better schemes would only improve the performance
of RFEC.
The rest of this paper is organized as follows. Section II defines a cover-free family and examines orthogonal arrays as
an important class of this family. We also derive the bound
on expected throughput. Section III discusses acknowledgment
schemes including RFEC for this purpose and overviews the LT
process. Section IV describes an experiment that makes a direct comparison between the proposed RFEC scheme and the
ideal scheme in which the transmitter is omniscient, in the sense
that it receives acknowledgments instantaneously. Comparisons
for achieved delay and throughput are presented. Section V addresses the greatest challenge for scheduling in dynamic environments, namely adaptation to changing network conditions.
Finally in Section VI, we examine the potential use of topologytransparent schemes in light of the practical acknowledgment
scheme developed and discuss remaining limitations.
II. COMBINATORIAL REQUIREMENTS
A. The Network Model
where the vertex
We model a MANET by a graph
represents the nodes, and the edge
set
set represents the communication links.
Each node is equipped with an omnidirectional antenna with
transmission range modeled by a circle of radius . There is an
between and if the distance separating
edge
them is less than or equal to . If is adjacent to then they
.
are neighbors of each other. The degree of is denoted
.
The maximum node degree of is
The transceiver at each node is half-duplex; it cannot transmit
and receive at the same time. We assume that two or more overlapping transmissions to a receiver result in a collision with none
of the overlapping packets correctly received; even the identities
of the colliding transmitters cannot be ascertained. On a link,
loss due to collision is the only reason for loss that we consider,
in keeping with [4], [5].
Time is divided into discrete slots. A schedule (or frame)
for node is a binary vector with one element corresponding

TABLE I
ORTHOGONAL ARRAY

465

OA(2; 4; 4)

to a state for each slot in the frame. A node with schedule
may transmit in slot whenever
and
; otherwise the node is silent and could
receive.
B. Cover-Free Families
In designing a topology-transparent transmission schedule
with parameters
and
we are interested in the following
combinatorial property. For each node, we must guarantee that
if a node has at most neighbors its schedule guarantees
a collision-free transmission to each neighbor.
Let us treat each schedule as a subset on
is the characteristic set of . Now the combinatorial
with
problem asks for each node to be assigned a subset
the property that the union of or fewer other subsets cannot
contain . Expressed mathematically, if is a set of at most
of the sets
, and
, then
.
This is precisely a cover-free family. These are equivalent
to disjunct matrices [10] and to superimposed codes of order
[11]. As a result, there is also an equivalence between the notation used for cover-free families (characteristic sets), disjunct
matrices (matrices), and superimposed codes (sets of vectors).
Such combinatorial designs arise in many other applications in
networking (see [12] for some examples).
As we showed in [13], existing constructions for topologytransparent schedules correspond to orthogonal arrays, giving
cover-free families. Since this is essential to the provision of
topology-transparent schemes of sufficient variety and number
for practical applications, we outline this connection in more
detail.
1) Orthogonal Arrays: Let be a set of symbols. A
array with entries from is an orthogonal array with levels
, if every
and strength , for some in the range
subarray of contains each -tuple based on exactly once as
.
a column. We denote such an array by
. Each
Table I shows an example from [14] of an
column (codeword) intersects every other in fewer than positions. Select any column . Since any of the other columns can
positions, any collection of other
intersect it in at most
differs from all of these in
columns has the property that
positions. Provided this difference is posat least
therefore contains at least one symbol appearing in a
itive,
position not occurring in any of the columns in the same position. The importance of this intersection property in terms of
scheduling is that at least one collision-free slot to each neighbor
exists when a node has at most neighbors. Thus, as long as the
number of neighbors is bounded by , the delay to reach each
neighbor is bounded, even when each neighbor is transmitting.
Evidently, the orthogonal array gives a cover-free family.
2) Constructing Schedules Using OAs: A large number of
techniques are known for constructing orthogonal arrays, usually classified by the essential ideas that underlie them. Both [4]
and [5] implicitly use the classical construction based on Galois

466

Fig. 1. Schedule corresponding to codeword 1230 from

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 16, NO. 2, APRIL 2008

OA(2; 4; 4).

fields and finite geometries though neither observed that what
they were constructing was an orthogonal array.
of the OA gives rise to a transmission
Each codeword
schedule . Specifically, each symbol in gives rise to a bithen the th element of
nary subframe of length . If
vector made
the subframe is set to one. The schedule is a
. Fig. 1
up of the concatenated subframes
shows an example of a schedule constructed from the codeword
symbols. The utility of the resulting transmission
1230 on
schedules does not depend on the construction of the orthogonal
array. We just exploit its combinatorial properties.
3) Properties of OAs: There is a substantial body of knowledge on the existence of orthogonal arrays [14], [15]. Among the
exclassical results in the area is that whenever an
exists. Also, if an
exists then
ists, an
. This is interesting because the pubthere is an
s in their conlished schemes [4], [5] both employ
struction. This result gives rise to an orthogonal array with codefrom which schedules of length
words of length
are constructed, immediately enhancing the guarantee on minimum throughput of Ju et al. [5].
s when is a prime
Both [4] and [5] employ
,
power. They therefore restrict attention to the case when
they do not obtain the
and indeed by not permitting that
best delay guarantees. The restriction of to prime powers is
also not required, as orthogonal arrays exist for these cases.
In the same way that allowing different parameters for orthogonal arrays permits more flexibility in the corresponding schedules, relaxing the parameters further and asking for a cover-free
family allows even more flexibility.
4) Steiner Systems: Cover-free families have frequently been
studied with the objective of maximizing the number of sets in
the family. For scheduling, this corresponds to maximizing the
number of nodes so this is certainly a parameter of interest.
There is a celebrated result of Erdös et al. [16] that established bounds on the size of a cover-free family (see also [10],
[17], [18]). They established that the extreme size, if achievable, is realized by a Steiner system. Hence in terms of scheduling, Steiner systems achieve the shortest frame length of all
cover-free families. Thus, they provide the best solution to our
problem in terms of frame length.
While a substantial amount is known about the existence of
Steiner systems, in general their existence is not settled [15]. As
with orthogonal arrays, there are constructions from finite fields
and finite geometries.
C. Theoretical Bound on Expected Throughput
We summarize our derivation on the expected throughput of a
strength two orthogonal array [13]. It is a function of the number
of transmitters among the neighbors of a node, which we assume
are chosen uniformly at random.

Consider a situation with source and next-hop destination
. Let be a schedule for and
be the schedules
of the other neighbors of (here, we assume the worst case, that
be the schedule for ,
all neighbors are transmitting). Let
and assume that is also transmitting.
The probability of successful transmission within a frame is
the probability that has a slot that does not appear in
. Expected throughput is simply the expected number
of such slots. We employ an ordinary generating function to
enumerate and classify the selections of neighbors. A formal
indicates the
variable is used as an indicator so that
indicates absence.
presence of one of the objects and
expresses that exactly of the objects in question are
Then
present. The conciseness of generating function representations
indicates
is that similar terms can be collected, so that
that exactly situations arise in which exactly of the objects
in question are present. In our case, the indicator marks the
let
presence of a neighbor. For an

where
denotes the number of ways for a given codeword
to select other codewords whose union intersects
in precisely specific positions. We call this the -covering function.
If we can calculate the -covering functions, then

is the probability that if a node has neighbors, then it retains
). If
at least one free slot (calculated as
entries are covered then
are free. There are
ways to
so with neighchoose the covered. The frame length is
bors, expected throughput is

Theorem 2.1 ([13]): For an
, the -covering
for covered slots in a frame is
function

III. ACKNOWLEDGMENT SCHEMES
To approach the theoretical bound for expected throughput
of topology-transparent scheduling in practice an acknowledgment scheme is required. Without an acknowledgment, a node
must transmit the same packet in each of its assigned slots to
guarantee reception to a specific neighbor. This is because while
the schedule guarantees a collision-free slot to each neighbor by
the end of the frame, it is not known which of its slots is successful to a specific neighbor; this depends on the schedules of
the nodes currently in its neighborhood.

SYROTIUK et al.: RATELESS FORWARD ERROR CORRECTION FOR TOPOLOGY-TRANSPARENT SCHEDULING

With backward error correction, the destination explicitly returns feedback to the source. These techniques may require the
source to wait an entire frame for receipt of the feedback, even
if both transmitter and receiver have at most neighbors. In the
pathological case that the transmitter is densely surrounded by
neighbors while the receiver is not, acknowledgment can cause
collisions at the transmitter and result in total loss; this may result in stalling for many frames. Further, these techniques require window, buffer, and timer management, not to mention
that packets suffering collision need retransmission.
With forward error correction (FEC), the source includes
enough redundancy in the encoded packets to allow the destination to decode the message. Most FEC schemes require knowledge of the loss rate on the channel. Determining a suitable rate
for the code in practice is not easy. If the rate is chosen conservatively to account both for collisions and for communication errors, as well as allowing for the maximum number of permitted
active neighbors, many additional packets are sent containing
redundant information. Too low a rate decreases throughput,
while too high a rate fails to deliver enough information to decode. Worse yet, adapting to a more suitable rate requires an
agreement between transmitter and receiver to change the encoding in use.
A. Rateless Forward Error Correction for Acknowledgment
Rateless FEC overcomes numerous concerns with acknowledgment in topology-transparent schemes. Among the rateless
FEC codes currently available, we use Luby Transform (LT)
codes [7]. The LT process is capable of generating a potentially infinite number of equally useful symbols from a given
input, giving the codes immunity to tolerate arbitrary losses in
the channel. This makes LT codes an effective coding technique
for wireless channels.
1) The LT Process: The parameters that characterize the LT
process are: 1) the size of each block or encoding symbol; 2)
the degree of the encoding symbol; 3) the number of blocks
into which a message of
bytes is divided; and 4) the number
of encoding symbols needed to completely recover the message,
.
denoted by
bytes is fragmented into
A message of size
blocks; these blocks are numbered sequentially. A degree is
chosen at random from a soliton distribution. Now distinct
blocks are chosen from the message uniformly at random. The
value of the encoding symbol is the exclusive-or (modulo 2 sum)
of these blocks.
In practice, 5% more than the original message data is needed
to reconstruct an exact copy of it by the receiver [19]. It does
not matter which of the encoding symbols are received, or in
what order they are received. All the encoding symbols are of
equal value in reconstructing the message. Indeed, although not
our primary concern here, the reception of symbols need not
be by any agreed upon route, or by a single route at all. We do
not explore the possible advantages in terms of simultaneous
multi-path routing.
Fig. 2 helps illustrate the decoding process. The original message consists of eight blocks and there are eight received enhas
and so it covers block
coding symbols. Only
2, i.e., the value of is the value of block 2. Then the value
of the recovered input is added into the value (bitwise modulo

467

Fig. 2. A message with 8 blocks and an ensemble of encoding symbols [19].

2) of the other encoding symbols to which it is connected; in
indithis example, to the encoding symbols and . If
cates that block 2 is recovered as the current value of encoding
denotes that the current
symbol B, and if the notation
value of symbol 2 is added (bitwise modulo 2) into the current value of symbol , then the entire recovery process for this
example can be expressed by the following sequence of operations:
.
2) The Soliton Distribution: The probability distribution of
the degree of the encoding symbols is a critical part of the design to ensure complete recovery of the original message from
the fewest encoding symbols. An ideal distribution is such that
there is exactly one encoding symbol with degree one. One such
distribution that has this property is the soliton distribution [7].
.
This distribution has an average degree logarithmic in
be a specified failure probability for the process.
Let
If the message consists of blocks then: 1) each block can be
generated, independently of all other encoding symbols, on avsymbol operations, and 2) the blocks
erage in
encoding
can be recovered from any
in
symbol opersymbols with probability
ations on average [7]. The maximum number of encoding symbols needed for complete recovery of the message is bounded
[7].
by
The generation and recovery speeds of the LT process are fast;
indeed the efficiency of the process is directly proportional to
the average degree of the distribution multiplied by the length
of the message. The average degree of the distribution is a very
small constant independent of the length of message.
3) The LT Coding Acknowledgment Scheme: We exploit the
principle of LT codes in designing an acknowledgment scheme
for topology-transparent scheduling because of its efficiency
and tolerance to arbitrarily large losses on the wireless channel.
There is trade-off between delay and the number of encoding
is
symbols generated that is impacted by where the message
decoded. One choice is to decode on a hop-by-hop basis; this
can impact end-to-end delay negatively. Another choice is to
decode at selected intermediate nodes along the path. This may
be appropriate if the path length is long and the loss rate is high.
Interestingly, regardless of where decoding occurs, nodes can
decode and forward encoding symbols at the same time since
the forwarded symbols are still useful to nodes further down the
path. Furthermore, once any node has successfully decoded the
message it can act as the message source, i.e., acknowledgments
no longer need to return to the original source.
A third choice is to decode at the ultimate destination of the
flow. While this choice may generate the most encoding symbols from the source we choose it for two reasons: 1) This eliminates the need for link layer acknowledgments. Rather than

468

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 16, NO. 2, APRIL 2008

acknowledge every individual packet, the destination acknowledges packets at one time – the message . 2) Our decision
is generous for delay. By deciding to acknowledge end-to-end,
we consider the worst case; every other choice uses less overhead. As the results show, even under this punative assumption
the method is effective.
This describes acknowledgment for unicast; of course reliable
multicast or broadcast would require acknowledgments from
each destination, but each could employ the same stream of encoding packets from the transmitter, despite the fact that each
might receive a different subset of them successfully. To perform an evaluation, we focus on the unicast situation.

TABLE II
SIMULATION PARAMETERS

IV. EXPERIMENTAL SET-UP AND RESULTS
In this section, simulations are described to compare
topology-transparent scheduling using an RFEC based acknowledgment scheme with the performance using omniscient
acknowledgment (OMN). At least in simulation, the transmitter
can be omniscient about the outcome of its transmissions. This
has been colloquially referred to as magic acknowledgment.
For our purposes, while it cannot be implemented in practice,
it gives us an ideal situation with which any real acknowledgment scheme can be compared to assess the overhead due to
acknowledgments.
A. Performance Metrics
The performance of topology-transparent scheduling using
schedules generated from an orthogonal array
is
measured by two metrics, throughput and delay. We define
throughput as the average number of successful transmissions
by a node in a frame. In the best case a node can have as many
, at least
as successes. If the degree of the node is at most
one success is guaranteed. The delay incurred at the MAC layer
is defined as the amount of time taken on average for a packet
to reach its next-hop destination; this includes queueing delays.
B. Simulation Set-Up
The OMN and RFEC acknowledgment schemes were implemented using network simulator ns-2 version 2.26 [20]. A total
nodes were distributed over a 300 1500 m simuof
lation area, connected to their peers via a shared 11 Mbps wireless interface. was chosen to be 289, since the schedules were
with a frame length of
for
designed from an
various ; this can support at most 289 nodes. A rectangular
simulation area was selected in order to force a longer network
diameter. The steady state initialized random waypoint mobility
model was used in initializing the topology and controlling the
movement patterns of the nodes; this ensures higher confidence
in the results [21], [22].
Simulations were run for various numbers (2, 4, 8, 12, and
30) of source-destination pairs, for static and mobile scenarios,
for
. Different values
using an
of were chosen to illustrate the relation among the number of
neighbors, throughput, delay and the frame length. For the mobile case the nodes move at a constant speed of 20 m/s. Table II
gives these and other simulation parameters.
of each CBR flow is selected
The source and destination
. For each message
, the source genat random with
erates encoding symbols according to the LT process described

in Section III-A1 as payload in a packet. The packet header includes the message identifier , and a representation of the degree and the blocks making up the encoding symbol. An intermediate node only forwards the packet to the destination – it
does not decode the packet. If a packet is lost due to collision it is
not retransmitted, it is dropped. Only the destination of the flow
decodes using the LT decoding algorithm [7]. When it recovers
and routes
the message transmits an acknowledgment for
it to the source . Since acknowledgments can suffer collision,
they are retransmitted periodically by the destination until re. Upon
ceives an encoding symbol for the next message
, the source advances to
receiving an acknowledgment for
. All packets are routed using the Dythe next message
namic Source Routing (DSR) protocol [23] which is responsible
for the route set-up and maintenance as topology changes.
C. Simulation Results
We first simulate the topology-transparent scheme using omniscient acknowledgments. The results agree with the analytical results presented in Section II-C. Then, we present the simulation results obtained for the RFEC based acknowledgment
scheme.
1) OMN Acknowledgment Scheme: Fig. 3 shows the number
of successes of a node on average for various frame lengths
, load, mobility and neighborhood conditions.
As increases, the number of chances a node has to transmit
increases. Thus with a longer frame nodes can tolerate more
neighbors. This can be observed in Fig. 3(a) as the number of
, 10 and 12 drop faster
neighbors increase, the curves for
. The dashed lines in Fig. 3(a) show the curves
than for
for
for the analytical results presented earlier. At first it appears that OMN has done better than the theoretical analysis would lead us to expect. However, in order to
produce these curves, the average number of active neighbors
is determined from the simulation, and the dashed curve then
corresponds to throughput under the assumption that every node
has the average number of neighbors. The difference is therefore
accounted for by the fact that a variation in the actual number
of active neighbors improves the throughput over requiring each
node to have exactly the average.
Fig. 3(a) examines a static scenario; the drop in the
throughput is smaller than in the mobile scenario in Fig. 3(b).

SYROTIUK et al.: RATELESS FORWARD ERROR CORRECTION FOR TOPOLOGY-TRANSPARENT SCHEDULING

OA ; k;

;k

; ; ;

Fig. 3. Throughput for
(2
17)
= 3 10 12 17, with an omniscient
acknowledgment scheme. (a) Static scenario. (b) Mobile scenario.

With node mobility, the throughput is generally lower however
the guarantee is still met. Fig. 3 also shows that it is possible to
a frame has only
use very short frames (with
slots for 289 nodes), and yet have a reasonable chance of
success even when the actual number of neighbors exceeds the
design parameters.
We compared the average MAC delay per node for static
and mobile scenarios to the delay obtained using TDMA for
the same set of scenarios. The frame lengths for schedules
and 17 are 0.018618,
using orthogonal arrays for
0.062929, 0.07559 and 0.107241 seconds, respectively. These
values are obtained by calculating the slot length (thereby frame
length) for a 512 byte data packet transmitted on a 11 Mbps
channel. The average MAC delay using orthogonal arrays is
less than its frame length as a node may get multiple successes
in every frame. In TDMA, on the other hand, the number of
slots is equal to the number of nodes. Hence the frame length
of TDMA is same as the frame length for the

469

case, i.e., 0.107241 seconds. Every node just gets one chance
to transmit in a frame, and thus the average MAC delay for
TDMA is always its frame length. This is very large compared
to the average MAC delay obtained using orthogonal arrays.
What is striking is that even with many neighbors, delay under
the topology-transparent scheme is a significant improvement
over TDMA.
In a mobile scenario, this could be optimistic since packets
could encounter additional delay due to loss of packets during
route changes. Despite the mobility, the average MAC delay of
orthogonal arrays is far less (nearly 10 times smaller) than when
using TDMA.
Fig. 4 shows the delay obtained using
for
and 17 in static and mobile scenarios, when acknowledgment is OMN. As the number of neighbors increases, the
delay also increases. This is due to the increased probability of
collision. For higher values of , the delay is also expected to be
larger because of the longer frames. However, increasing may
reduce the probability of collision and hence the observed effect
on delay may be seen either as an increase or a decrease. In addition, delay increases with mobility as shown in Fig. 4(b). For
, in the static
the same number of neighbors, say 40 for
case the average delay is approximately 0.008 s; in the mobile
case it is approximately 0.011 s.
2) RFEC Acknowledgment Scheme: Here, we explore the
impact of RFEC, specifically LT coding, as an acknowledgment
scheme. Simulations were run for the same set of scenarios as
the protocol using omniscient acknowledgments.
Fig. 5 shows the throughput of the protocol using RFEC. The
penalty on the performance due to LT codes is not very significant. The throughput guarantees are still met, but at the price
of a small increase in delay. The dashed lines here show the
analytical results of the original protocol; again, these are for
the situation when every node has a number of active neighbors
equal to the average. The throughput obtained using RFEC is
very close to the results projected using mathematical analysis.
Fig. 5(b) shows the results obtained for a mobile scenario.
Comparing Figs. 3(b) and 5(b), we conclude that the introduction of LT codes into the existing scheduling scheme does not
affect the throughput adversely.
for
We compared the delay obtained by
and under varying load and mobility conditions to
the delay obtained using TDMA. Even after the introduction of
LT codes, the delay obtained using orthogonal arrays is almost
10 times smaller than the delay obtained using TDMA. Indeed
the overhead due to the LT coding is quite small. This is true
even for mobile scenarios.
Fig. 6 shows the delay with RFEC acknowledgment scheme.
Fig. 6(a) shows the sharp increase in MAC delay with the increase in the number of active neighbors. This rise is particu, where the delay is aplarly pronounced in the curve for
proaching the frame length. The tolerance towards larger neighborhood sizes is better for larger values of , but at the cost of
increased delays. However, delays obtained with the OMN and
the RFEC acknowledgment schemes are almost the same. This
can be observed from Figs. 4(a) and 6(a).
Fig. 6(b) shows the delay obtained using RFEC for the same
set of traffic conditions but for a mobile scenario. In this case

470

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 16, NO. 2, APRIL 2008

OA ; k;

;k

; ; ; ;

Fig. 4. Average MAC delay for
(2
17)
= 3 10 12 17 with an omniscience acknowledgment scheme. (a) Static scenario. (b) Mobile scenario.

too, although there is a small increase in delay attributable
to LT coding, the difference between the values obtained for
delay with the OMN and the RFEC schemes is negligible. See
Figs. 4(b) and 6(b).
V. ADAPTATION TO NETWORK DYNAMICS
Most of the analysis for topology-transparent scheduling has
focused on a single frame; while this is a reasonable view for
studying minimum throughput, it ignores what happens when
the design parameter is exceeded. Ju et al. [5] argue that by
selecting a larger frame length, their choice is (relatively) insensitive to the degree limitation; essentially they “over-engineer” the system to permit more neighbors than the design criteria stipulate. Nevertheless, their scheme can fail totally when
the number of neighbors exceeds the capacity of their chosen
scheme, despite its continued operation for some number of
neighbors larger than the stipulated number.
Chlamtac et al. [24] propose a different solution, interleaving
or “threading” different schemes each supporting a different degree limitation; however, this incurs a dramatic slowdown in the

OA ;k;

k

; ; ; ;

Fig. 5. Throughput for
(2
17), for
= 3 10 12 17 with an RFEC
acknowledgment scheme. (a) Static scenario. (b) Mobile scenario.

initial scheme and hence a substantial penalty is paid whether or
not the degree limit is exceeded. What is needed is a scheme that,
if the degree limitation might be exceeded, degrades gracefully
rather than failing completely (as in [5]) or imposing a large
slowdown factor (as in [4]). Ju and Li’s approach fails to provide a guarantee when the number of neighbors is too large. This
in itself is reasonable. However, their scheme repeatedly uses
the same frame schedule in each subsequent frame. Thus loss
of transmission opportunity within one frame is extended to all
subsequent frames unless and until transmitting nodes move or
cease transmission. Of course, this does not impact the expected
throughput. But when the degree limit is exceeded, it can result
in a denial of service to some nodes.
Our results demonstrate, however, that expected throughput
can remain quite acceptable when the degree limitation is exceeded [6]. In general, we must ensure that a situation resulting
in catastrophic collisions in one frame is not automatically repeated in the next frame by simply repeating the schedule. Two

SYROTIUK et al.: RATELESS FORWARD ERROR CORRECTION FOR TOPOLOGY-TRANSPARENT SCHEDULING

471

, and making random distributions of the codewords to be
used in successive frames, repeatedly.
In this way, denial of service can be held to any specified
probability tolerance, while ensuring that when the degree limit
is met, there is provably no denial of service.
VI. CONCLUSION

OA ; k;

k

; ; ;

Fig. 6. Average MAC delay for
(2
17), for
= 3 10 12 17, using
RFEC acknowledgment scheme. (a) Static scenario (b) Mobile scenario.

methods suggest themselves. The first is to allow nodes to remain silent throughout a frame despite having a pending transmission, i.e., “backing off” when it is detected that the degree
limit is exceeded. When the degree limit is satisfied, such a
scheme ensures nonzero minimum throughput; when exceeded,
the scheme employs contention.
A second method is suggested by the results on expected
throughput. If the number of neighbors exceeds the degree
limit, the expected throughput tells us the likelihood that we
fail. The combinatorial properties of the scheme explain why
we could fail: our neighbors interfere with each of our transmission slots. So while minimum throughput tells us that we
could fail, expected throughput tells us how likely we are to be
unlucky enough to have neighbors that cause us to fail. Now
we cannot choose our neighbors, but we can do something
equivalent. By distributing codewords to nodes at random in
each frame, the expectation within one frame does not depend
on the outcome of another (unlike [4], [5] where it is the
same outcome). Obviously this poses insurmountable practical
problems, so we propose selecting a fixed number of frames

Topology-transparent scheduling has suffered from many
drawbacks. In this paper, we have established that the combinatorial construction of such schemes can be done much more
generally than previously suggested. The combinatorial characterization leads not only to more general construction schemes
but also to analytic results suggesting that topology-transparent
schemes retain strong throughput and delay performance even
when in an environment with neighborhoods larger than anticipated.
The fundamental problem, from the beginning, has been to
develop a realistic acknowledgment model that realizes the performance indicated by a theory based on omniscient acknowledgment (OMN) and in which collision is the only cause of erasures. Rateless forward error correction (RFEC) has been proposed here as a solution, and a practical implementation using
LT codes described. We emphasize that LT codes is just one of
a number of schemes that could be used.
To validate this solution, experiments have been conducted
using topology-transparent schedules based on orthogonal arrays, to compare OMN and RFEC, and to explore the analytical
model developed earlier. The computational results are compelling, showing that RFEC has no observable negative effect
on throughput, and only a small impact on delay.
The simulation results examine the case of unicast traffic
when every packet follows a single route. The technique opens
the door for a true multicast and reliable broadcast, and in these
cases RFEC appears to be not just the best, but perhaps the
only, currently viable acknowledgment scheme. Moreover, the
ability to deliver packets of a message by different routes could
support deployment in an environment of very high mobility.
Beyond that, RFEC can also treat losses from channel errors
other than collision.
After the presentation here, it may seem that topology-transparent scheduling solves all problems, but that is surely not
the case. We have argued that the schemes are very robust
to changes in the number of neighbors. Indeed when the
neighborhood size is large, our experiments indicate that both
throughput and delay remain good. When the neighborhood is
too small, RFEC takes advantage of the additional transmission
opportunities, hence providing a limited form of adaptation
to channel load. This remains a limitation, however. A fully
adaptive scheme such as IEEE 802.11 need not be designed for
an optimal environment, but the topology-transparent schemes
discussed here must. Notwithstanding the robustness of the
scheme to changes in environment, its adaptation is limited by
the schedules assigned. Depending on the particular scenario,
this may or may not be significant. For example, in the injection
of a broadcast, 802.11 is faced with a spike in the traffic load,
and hence can encounter unnecessary collisions before adapting
to the increase. Topology-transparent schemes, on the other
hand, profit from the scheduled nature to inject the additional
load in a less dramatic manner.

472

IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 16, NO. 2, APRIL 2008

It is reasonable to expect, from the results we have presented,
that adaptive contention-based approaches typically still exhibit
better throughput characteristics; however when quality of service, in particular delay, is a primary concern, RFEC makes
topology-transparent scheduling competitive.

ACKNOWLEDGMENT
The authors are grateful to the anonymous referees whose
helpful comments have greatly improved the focus and presentation of this paper. Thanks also to Wensong Chu for helpful
discussions and to Minghao Cui for the implementation of the
LT process.

REFERENCES
[1] A. Woo and D. E. Culler, “A transmission control scheme for media
access in sensor networks,” in Proc. MobiCom’01, Jul. 2001, pp.
221–235.
[2] I. Chlamtac and S. S. Pinter, “Distributed node organization algorithm
for channel access in a multihop dynamic radio network,” IEEE Trans.
Comput., vol. 36, pp. 728–737, Jun. 1987.
[3] C. Zhu and S. Corson, “A five-phase reservation protocol FPRP for mobile ad hoc networks,” in Proc. IEEE INFOCOM, 1998, pp. 322–331.
[4] I. Chlamtac and A. Faragó, “Making transmission schedules immune
to topology changes in multi-hop packet radio networks,” IEEE/ACM
Trans. Networking, vol. 2, no. 1, pp. 23–29, Feb. 1994.
[5] J.-H. Ju and V. O. K. Li, “An optimal topology-transparent scheduling
method in multihop packet radio networks,” IEEE/ACM Trans. Networking, vol. 6, no. 3, pp. 298–306, Jun. 1998.
[6] C. J. Colbourn, A. C. H. Ling, and V. R. Syrotiuk, “Cover-free families
and topology-transparent scheduling for MANETs,” Designs, Codes,
and Cryptography, vol. 32, no. 1–3, pp. 35–65, May 2004.
[7] M. G. Luby, “LT codes,” in Proc. 43rd Symp. Foundations of Computer
Science (FOCS’02), Nov. 2002, pp. 271–280.
[8] T. Richardson and R. Urbanke, Modern Coding Theory. New York:
Cambridge Univ. Press, 2005.
[9] A. Shokrollahi, “Raptor codes,” IEEE Trans. Inf. Theory, vol. 52, no.
6, pp. 2551–2567, 2006.
[10] D.-Z. Du and F. K. Hwang, Combinatorial Group Testing and Its Applications, ser. Series on Applied Mathematics, 2nd ed. Singapore:
World Scientific, 2000, vol. 12.
[11] A. D’yachkov, V. Rykov, and A. M. Rashad, “Superimposed distance codes,” Problems Control and Information Theory, vol. 18, pp.
237–250, 1989.
[12] C. J. Colbourn, J. H. Dinitz, and D. R. Stinson, “Applications of combinatorial designs to communications, cryptography, and networking,”
in Surveys in Combinatorics, ser. Lecture Note Series 267, J. D. Lamb
and D. A. Preece, Eds. London, U.K.: London Mathematical Society,
1999, pp. 37–100.
[13] V. R. Syrotiuk, C. J. Colbourn, and A. C. H. Ling, “Topology-transparent scheduling for MANETs using orthogonal arrays,” in Proc.
DIAL-M/POMC Joint Workshop on Foundations of Mobile Computing,
Sep. 2003, pp. 43–49.
[14] A. S. Hedayat, N. J. A. Sloane, and J. Stufken, Orthogonal Arrays,
Theory and Applications. New York: Springer-Verlag, 1999.
[15] C. J. Colbourn and J. H. Dinitz, Eds., Handbook of Combinatorial Designs, 2nd ed. Boca Raton, FL: CRC Press, 2007.
[16] P. Erdös, P. Frankl, and Z. Füredi, “Families of finite sets in which no
set is covered by the union of r others,” Israel J. Math., vol. 51, pp.
79–89, 1985.
[17] M. Ruszinkó, “On the upper bound of the size of the r -cover-free families,” J. Combinatorial Theory, ser. A, vol. 66, pp. 302–310, 1994.
[18] D. R. Stinson, R. Wei, and L. Zhu, “Some new bounds for cover-free
families,” J. Combinatorial Theory, ser. A, vol. 90, pp. 224–234, 2000.

[19] “Breakthrough reliable transport technology for data and live streaming
delivery over imperfect networks,” Digital Fountain, Technology
Licensing White Paper, 2004 [Online]. Available: www.digitalfountain.com
[20] The network simulator: ns-2. Univ. California, Berkeley [Online].
Available: www.isi.edu/nsname/ns/
[21] W. Navidi, T. Camp, and N. Bauer, “Improving the accuracy of random
waypoint simulations through steady-state initialization,” in Proc. 15th
Int. Conf. Modeling and Simulation (MS’04), Mar. 2004, pp. 319–326.
[22] J. Yoon, M. Liu, and B. Noble, “Sound mobility models,” in Proc. Mobicom’03, Sep. 2003, pp. 205–216.
[23] D. B. Johnson, D. A. Maltz, and J. Broch, “DSR: The dynamic source
routing protocol for multi-hop wireless ad hoc networks,” in Ad Hoc
Networking, C. E. Perkins, Ed. Reading, MA: Addison-Wesley,
2001, ch. 5, pp. 139–172.
[24] I. Chlamtac, A. Faragó, and H. Zhang, “Time-spread multiple-access
(TSMA) protocols for multihop mobile radio networks,” IEEE/ACM
Trans. Networking, vol. 5, no. 6, pp. 804–812, Dec. 1997.

Violet R. Syrotiuk (M’96) received the Ph.D. degree
in computer science from the University of Waterloo,
Waterloo, ON, Canada, in 1992.
She joined Arizona State University, Tempe, in
2002, and is currently an Associate Professor of
computer science and engineering. Her research is
currently supported by two grants from NSF, and
contracts with Los Alamos National Laboratory
and Defence Science and Technology Organisation
(Australia). Her research interests include MAC
and higher layer protocols for multi-hop wireless
networks.
Dr. Syrotiuk serves on the Editorial Board of Computer Networks, and on
the Technical Program Committee of several major conferences including Mobicom, Mobihoc, and Infocom. She is a member of the ACM.

Charles J. Colbourn received the M.Math. degree
from the University of Waterloo, Waterloo, ON,
Canada, in 1978, and the Ph.D. degree from the
University of Toronto, Toronto, ON, Canada, in
1980, both in computer science.
He has held academic positions at the University
of Saskatchewan, the University of Waterloo, and the
University of Vermont, and is currently a Professor of
computer science and engineering at Arizona State
University, Tempe. He is the author of The Combinatorics of Network Reliability (Oxford) and Triple
Systems (Oxford). He is editor-in-chief of the Journal of Combinatorial Designs
and serves on the editorial boards of Networks; Discrete Mathematics; Journal
of Combinatorial Theory (A), Designs, Codes and Cryptography; and others.
He edited the standard reference work The CRC Handbook of Combinatorial
Designs. He is the author of more than 250 refereed journal papers focusing on
combinatorial designs and graphs with applications in networking, computing,
and communications.
In 2004, Dr. Colbourn was awarded the Euler Medal for Lifetime Research
Achievement by the Institute for Combinatorics and its Applications.

Sruthi Yellamraju received the B.E. degree in computer science from Osmania University, Hyderabad,
India, in 2001, and the M.S. degree in computer science from Arizona State University, Tempe, in 2004.
Her research interests include mobile ad hoc
networks, and medium access control protocols with
emphasis on topology transparency and quality of
service.

On-Demand Location Aware Multicast (OLAM) for Ad Hoc
Networks*
Stefan0 Basagni Imrich Chlamtac Violet R. Syrotiuk Rodeen Talebi
Center for Advanced Telecommunications Systems and Services (CATSS)
Erik Jonsson School of Engineering and Computer Science
The University of Texas at Dallas
{basagni,chlamtac,syrotiuk,rodeen}@utdallas.edu
Abstract- This paper introduces OLAM, a novel Ondemand Location Aware Multicast protocol for ad hoc
networks. The protocol assumes that, through the use
of positioning system devices, such as Global Positioning System (GPS) devices, each node knows its own position and the current (global) time, and it is able to efficiently distribute these measures, including its current
transmission radius, to all other nodes. As the measures are received, each node updates its local snapshot
of the complete network topology. When a packet is to
be multicast to a group, a heuristic is then used to locally compute the Steiner (i.e., multicast) tree for the addressed multicast group based on the snapshot rather
than maintaining the tree in a distributed manner. The
resulting Steiner tree is then optimally encoded by using
its unique Prifer sequence and included along with the
packet, extending the length of the header by no more
than the header of packets in source routing (unicast)
techniques. All local computations are executed using
efficient (i.e., polynomial time) algorithms. The protocol
has been simulated in ad hoc networks with 30 and 60
nodes and with different multicast group sizes. We show
that OLAM delivers packets to all the nodes in a destination group in more than 85% of the cases. Furthermore, compared to flooding, OLAM achieves improvements of up to 50% on multicast completion delay.

I.

INTRODUCTION

Among the basic network operations, multicast refers to
forms of communication with multiple participants (generally more than two). In this paper we consider the special
case of one-to-many communication (source multicast),
wherein the same packet is sent from one node (the source)
concurrently to a specified subset of nodes of the network
(the multicast group).
We consider networks in which all nodes can be mobile, called mobile multi-hop radio networks (or ad hoc networks). Unlike cellular networks, in which a mobile node
* This work was supported in part by the Army Research Office
(DARPA) under contract No. DAAG55-97-1-03 12.

0-7803-6596-8/00/$10.000 2000 IEEE

communicates by radio one hop through a fixed base station interconnected by a wired backbone network, ad hoc
networks have no fixed infrastructureand may need to communicate by radio for multiple hops. In this latter case, each
node relies on its neighbors to forward packets to destinations not directly in its transmission range, thus also acting
as a router.
Many existing protocols for multicast are based on
shared multicast routing trees, both in wireline and in ad
hoc networks (see, e.g., [ l , 2, 31). However, these solutions, which include the recent “multicast mesh” solution
proposed in [4], the on-demand multicast presented in [SI,
and the multicast operation of the AODV routing protocol
[ 6 ] ,all have a high dependence on the existence and correct operation of an underlying ad hoc routing protocol.
Other solutions, instead, depend on a hierarchical organization of the ad hoc network (e.g., clustering), as in the
algorithm proposed in [7].Thus, whether based on ad hoc
routing or clustering, these multicast protocols expend great
effort to distributively maintain the “multicast routing structure,” and this can heavily affect the overall multicast performance.
In this paper we propose a new multicast protocol for
ad hoc networks which neither assumes any ad hoc routing
scheme, nor builds and maintains any distributeddata structure. The proposed protocol is based on the expectation that
nodes of ad hoc networks will be equipped with positioning
system devices, such as Global Positioning System (GPS)
devices (possibly integrated,,with some inertial positioning
devices, to permit use indoors) whose commercial availability is as common as any other peripheral device. Through
the use of GPS, each node is aware not only of its threedimensional position (latitude, longitude and altitude), but
also of its current velocity and the current global time.
Using a dissemination mechanism specifically tuned to
the system requirements of ad hoc networks such as the one
introduced and described in [ 8 ] and [9], a node’s GPS measures and current transmission radius are continually distributed throughout the network as the node moves. On
receipt of such a “GPS packet,” a snapshot of the “cur-

1323

rent” network topology can be maintained locally as an
undirected graph G in which two nodes are neighbors if
their distance is less than the minimum of their transmission radii.
When a source node S receives a packet to multicast to
a group M, S uses a heuristic to locally compute a multicast
tree (called also a Steiner tree, in graph theoretic terms) for
G and M rooted at S. The source node S then transmits
the packet, that includes a coded representation of the paths
(i.e., the tree) the packet is to follow, to each of its child
nodes. Each child node is the root of a subtree and will
forward the packet to each of its children until finally the
path is exhausted, at which point the multicast is complete.
We show that, by using efficient algorithms for the local
computation of the multicast tree, and by optimally coding the tree through its unique Priifer sequence [lo], our
On-demand Location-Aware Multicast (OLAM) protocol
achieves the following desirable properties:
1. OLAM is easy to implement, relying only on a bandwidth and energy efficient dissemination mechanism, rather
than underlying routing or clustering protocols. As well,
since the computations are performed locally, no complex
coherent distributed data structure (such as a distributed
multicast tree) needs to be maintained among the nodes.
2. The local computation of the multicast tree does not impose a significant overhead to the multicast, since a polynomial time (i.e., computationally efficient) approximation
algorithm can be used to compute a Steiner tree in the network topology graph. Furthermore, the local complexity of
OLAM is linked to the best (possibly yet to come!) algorithm for computing a Steiner tree in a network graph. As
well, no packet looping can occur since the tree is computed
locally.
3. Due to optimal coding through a tree’s unique Prtifer
sequence, there is no overhead associated with transmitting
the encoded tree along with a data packet, with respect to
ad hoc source routing solutions (like the on-demand DSR
presented in [ 1l]), since a tree can be uniquely encoded by
a sequence whose length is at most the length of the longest
route between two nodes.
4. OLAM does not impose restrictions on the number of
multicast groups, on the number of nodes in each group
and on the number of groups with which each node can be
affiliated.
5. “Dynamic multicast,” i.e., the possibility for a node to
change Goidleave) groups, is easily and efficiently supported in OLAM by sending the identifier of a node’s new
group along with its GPS measures.
The effectiveness of OLAM in successfully completing
multicast is demonstrated through the use of simulation.
The obtained results show that in ad hoc networks with 30
and 60 nodes moving at a velocity from 6 to 20 m/s, independently of the size of the multicast groups, all the nodes
in the addressed group receive the packet in more than 85%

of the time (this percentage is actually > 97% in the case of
networks with 30 nodes). In the remaining 15% (3%)of the
cases, always more than 80% of the nodes in the addressed
multicast group receive the packet, leaving only less than
20% of the nodes in the group not receiving the packet.
Furthermore, in both cases (30 and 60 nodes), the delay
associated with the completion of the multicast (computed
as the difference between the arrival time of the packet at
the last node of the destination group that received it and
the time it was sent at the source) is up to 50% better than
the delay associated with the multicast obtained by simply
flooding the packet through the network.
The rest of the paper is organized as follows. Section I1
explains how a graph representing the network topology
can be constructed from the GPS measures. Section I11 describes the multicast protocol in detail, while Section IV
demonstrates the effectiveness of our protocol in delivering
a packet to all nodes of the addressed group. Section V
presents conclusions and future work.

11.

OBTAINING

NETWORKTOPOLOGY
FROM
GPS MEASURES

The OLAM protocol assumes that each node is aware of its
own geographical position which can be easily obtained by
equipping a node with a Global Positioning System (GPS)
receiver. Such devices allow the nodes to receive GPS
broadcasts and compute their three-dimensional position
(latitude, longitude, and altitude), velocity and time (from
now on, together with a node’s transmission radius, called
GPS measures) with a precision to within 100 meters horizontal, 156 meters vertical, and 340 nanoseconds time.
Since nodes in an ad hoc network lack a fixed infrastructure, every node in the network is responsible for disseminating its GPS measures to all the other nodes. This is
obtained by flooding the network with a packet containing
its GPS measures. This dissemination mechanism is especially tailored to meet the requirements of ad hoc networks,
where the minimization of bandwidth and energy usage are
important goals. Its accuracy in disseminating GPS measures, as well as the effectiveness in supporting routing in
ad hoc networks, has been studied and presented in [9] and
[8], respectively.
Through the use of the dissemination mechanism, each
node knows the geographic position and the transmission
radius of each other node at the time those measures were
transmitted. Thus, a node can compute which nodes are
in the transmission range of each node in the network, i.e.,
it can easily obtain a snapshot of the entire network topology: where all the nodes are located, and to whom they
are (bidirectionally) linked. In graph theoretic terms, this
means to construct from the “GPS packets” the undirected
graph G = (V, E) of the network topology, where V is the
set of network nodes, and E is the set of bidirectional radio links. (A link e in E between two nodes A and B in
V means that the nodes A and B are in the transmission

1324

range of one another.) This local network topology graph
G can be easily maintained in an on-line fashion: every
time a GPS packet is received, G is modified accordingly (if
needed). The (time) complexity of this update operation is
clearly linear in n, the number of the nodes in the network,
thus imposing a negligible overhead on the node. Given
the adaptation to mobility of the dissemination mechanism
used [9], the network topology graph at each node provides
quite a faithful snapshot of’the “current” network topology,
and can be effectively used to compute the routes to the
nodes in a given multicast group.

111. ON-DEMAND
MULTICAST IN AD HOC
NETWORKS

1. Constructing a minimum cost multicast tree, also called a
Steiner tree, for the nodes of a given group in a generic network is a well known NP-hard optimization problem (see,
among many others, [12]). This means that exact algorithms for generating the tree of minimum cost to all the
nodes in a given group requires computational time that
detrimentally affects the delivery of the packet to the group.
Therefore, many heuristic algorithms have been proposed
that allow the construction of a Steiner tree in a time which
is polynomial in n, the number of nodes in the network,
and m the number of bidirectional links. Furthermore, for
many of these algorithms it is possible to prove an error
ratio with respect to an optimal solution which is at most
2where h is the number of nodes in the addressed
group, thus guaranteeing a bounded distance from the best
possible solution. (Extensive overviews of these heuristics
can be found in, e.g., [ 121 and [ 131.)
The OLAM protocol imposes no limitations on the
choice of the algorithm for the local computation of a
Steiner tree. Thus, the efficiency of our solution is connected to the best possible heuristic for computing Steiner
trees. In any case, a solution is obtained in polynomial time,
i.e., efficiently, and it is provably “not far” from an optimal
(minimum cost) solution.
As an example, suppose that the multicast source node
6 receives a packet to multicast to the group M =
{4,5,6,10,12,14}.
The left half of Figure 1 shows G, the
network topology graph that represents a snapshot of the
network topology as seen by node 6 at the time it receives
the packet to multicast. (The square vertices represent the
nodes in M . ) Node 6 computes a multicast tree for G and
M , rooted at 6 . The algorithm selected for this example
(and for the simulation in the next section) is a minimum
spanning tree based heuristic that produces a multicast tree
in a time proportional to m n log n. The details of the
algorithm can be found in [ 141, and are summed up in [ 121.
The right half of Figure 1 shows the resulting Steiner tree.
Note that a multicast tree always has group members as
leaves.
2. Any finite tree with j nodes (and j - 1 links) can be optimally encoded as a sequence of j - 2 integers (the node
identifiers) using a Priifer sequence (see, e.g., [lo]). A
Priifer sequence uniquely characterizes a tree, in the sense
that there is a one-to-one correspondence between the set
of all finite trees and their Priifer sequences.2 More importantly, the encoding and decoding of a tree are obtainable
in time which is polynomial in j, the size of the tree. In
our case, we use Priifer sequences for the computed Steiner
tree with j 5 n nodes. We notice that this encoding is as
efficient as specifying the longest source route needed for

i,

We assume that the n nodes of the network are partitioned
into k multicast groups. Multicast can then be defined as the
sending of a packet from one node, the multicast source, to
all the nodes of a specific group.’
Every time a node has to multicast a packet to the nodes
of a specific group, it applies a heuristic algorithm for the
determination of a minimum cost multicast tree (i.e., the
acyclic subgraph of G that spans all the nodes in the addressed group and that minimizes the total cost associated
with the links) to its local network topology graph G. For
our purposes, the cost associated with each link of an ad hoc
network is 1. Thus, the total cost represents the total number of transmissions (hops) a packet takes to reach all the
nodes in the multicast group. Therefore, a minimum cost
multicast tree minimizes the overall transmission time, the
related energy consumption and the overall needed bandwidth.
Once the multicast tree is computed, a packet is processed in a manner similar to any source routing protocol.
Namely, the obtained tree is included in the header of the
data packet, and the packet is transmitted in a hop-by-hop
fashion to all and only the nodes in the tree (provided that
each of these nodes is reachable).
The resulting multicast is thus on-demand, since the
multicast tree is computed only when needed, and no distributed data structure (i.e., a tree, or any other structure) is
built and maintained in order to multicast a packet.
Two main problems have to be addressed in order to
implement the described multicast protocol in ad hoc networks:
1. How to efficiently compute the multicast tree, so that
only negligible overhead is associated with the sending of a
multicast packet?, and
2. How to code a multicast tree so that the corresponding
header of the multicast packet does not significantly affect
the transmission time of the packet itself?
In the remaining part of this section we describe how
these problems can be solved efficientlv.
For the sake of presentation, we consider here that each node belongs
to only one multicast group. The proposed multicast protocol also supports
“multi-group” multicast, i.e., a node may belong to any number of groups.

+

A detailed description of how to generate the Priifer sequence of a
tree, and vice versa, is beyond the scope of this paper. To better understand

the example, it is enough to know that the Priifer sequence of a tree encodes
in the sequence only interior, i.e., non-leaf, nodes. Further details can be
found in [IO],

1325

3
6

,,

!

I

5

4

,

,’

!

’

’

,

14

IO

‘\

\

IO

Figure 1: The network topology according node 6 (left), and a Steiner tree for M, rooted at 6 (right).

routing in ad hoc networks according to on-demand protocols such as the DSR protocol [ 1 11. Thus, from the perspective of header size of a data packet, the proposed multicast
needs as much space as an on-demand routing protocol. As
a consequence, the encoded Steiner tree incurs very little
overhead along with the transmission of the packet and, as
for routing, it reduces with each hop subsequently taken by
the packet.
In our example, node 6 encodes the Steiner tree
with 8 nodes (Figure 1, right) as the Priifer sequence
{6,5,8,5,5,2} of length 6, and broadcasts the encoding
along with the packet, that carries also the group identifier
(in our case, M). According to the Priifer decoding algorithm, since node 4 is not in the sequence and belongs to
M, it realizes that it is a leaf node, and thus it receives the
packet, but does not forward it any further. Node 7 is not
in the Priifer sequence, and since it does not belong to M it
is not involved in the forwarding of the packet and simply
discards the packet (node 7 receives the packet because we
assume a broadcast type of transmission at the MAC layer,
i.e., all the current neighbors of a node v eventually receive
a packet transmitted by v). Node 5 is in M and so receives
the packet, and since it is also in the Priifer sequence, it
realizes that it is an interior node. Thus, it decodes the multicast tree, and forwards the packet with the encoding of its
corresponding subtree ({8,5,5,2} of length 6 - 2 = 4).
The process continues until all leaf nodes, if possible, are
reached.

IV.

SIMULATIONS
RESULTS

We have simulated the OLAM protocol to demonstrate its
effectiveness in delivering multicast packets. A simulator
of an ad hoc network, implemented in C++, was used to
count the number of “successful multicasts,” namely, the
number of multicasts that deliver the packet to all the nodes
in the addressed group. If some node of the group (even
one) does not receive the packet, the multicast is considered unsuccessful. In this latter case, we have measured the

percentage of the nodes of the addressed group that have
received the p a ~ k e t . ~
The TI. nodes of the ad hoc network can freely move
around in a rectangular region (modeled as a grid) according to the following mobility model. (To ease the modeling,
the node movements are discretized to grid units with a grid
unit = 1meter.) Each time it moves, a node determines its
direction randomly, by choosing between its current direction (with 75% probability) and uniformly among all other
directions (with 25% probability). The node then moves in
the chosen direction according to its current speed. When
a node hits a grid boundary, it bounces back into the region
with an angle determined by the incoming direction.
Each node has a fixed transmission range of 350m (we
found this value resulted in good network connectivity, i.e.,
more than 98% of the time, after network topology changes,
the network was connected). Each node is modeled by a
store-and-forward queuing station, and is characterized by
parameters such as buffer space which is assumed to be
adequate for packets that are awaiting transmission. Each
link is modeled by a FCFS queue with service time as the
packet transmission time characterized by a bandwidth of 1
Mbitsh. Control packets containing the GPS measures and
multicast (data) packets share the same transmission channel (which implies that the accuracy of the dissemination
mechanism may be affected by the network load, and that
the transmission of multicasts may be slowed down by the
transmission of the GPS measures).
Each control packet contains time-stamped, node identified, position coordinates and the current transmission radius of a node, which in the current experiments is considered the same for each node. These packets are generated
every time a node moves (i.e., at a frequency that is a function of the node velocity; see also [9]).
Multicast packets contain a payload that is 1024 bytes
Currently, our study is limited to network-layer details, thus no linkor physical-layer are modeled.

1326

in size, the identifier of the source node and that of the addressed group, as well as the encoded Steiner tree. For each
packet, the source node and the destination group are chosen randomly and uniformly among all the nodes of the network. In our simulations we have considered a “heavy” network load: the multicast packets arrivals are distributed exponentially with a mean of lOms for networks with n = 30
nodes and 50ms in networks with n = 60 nodes. (This corresponds to an average of 3 packetstnode per second when
n = 30 and 1 packetfnode every 3 seconds.)
Figure 2 (a) refers to an ad hoc network with n = 30
nodes in a 1000m x lOOOm grid. It shows the percentage
of successful multicasts for nodes whose velocity varies
from 6 d s to 2 0 d s , i.e., from around 20 km/h to around
70 kmJh. For multicast group sizes between E and f (here
only
= 3, 9 = 5 and 3 = 10 are plotted), all the nodes
of the addressed multicast groups received the packet more
than 97% of the time (i.e., more than 97% of the multicasts
were successful). Furthermore, of the unsuccessful multicasts, more than 85% of the nodes received the packet.
Thus, even though the multicast packet failed to reach all
the nodes in the addressed group, only a few nodes (less
than 15%) did not receive the packet.
Our second set of simulations concerned networks with
n = 60 nodes in a lOOOm x2600m.” The percentage of
successful multicasts for the various velocities and groups
with sizes $ = 6, = 10 and = 20 is shown in Figure 2 (b). In this case, more than 85% of the multicasts are
successful, and, in the case of unsuccessful multicast, more
than 80% of the nodes in a group receive the packet.
Figure 2 (a) shows that in small ad hoc networks OLAM
is basically insensitive to both velocity and network load.
The same is true for networks with up to 60 nodes with
velocity up to 14 d s (in this case more than 93% of the
multicast are successful; see Figure 2 (b)).

fi

Different from previously proposed multicast protocols,
OLAM does not assume, construct or maintain any distributed data structure, nor does it use an ad hoc routing
or clustering protocol as a basis. Thus, node and network
resources can be effectively used for the transmission of the
multicast packets. The protocol is executed locally at each
node, where a multicast tree is computed in polynomial
time on the current network topology graph. The resulting
tree is then optimally encoded and transmitted along with
the packet with the same “space” overhead in the packet
header as ad hoc source routing.
Simulation results show that our protocol is effective in
delivering multicast packets in networks up to 60 nodes,
with high network loads and regardless of the nodes’ velocity and group sizes. The behavior of OLAM has to be
investigated when the size of the network grows. In this
case, it is expected that both the dissemination mechanism
and the protocol should be optimized for scalability. In particular, our research will be directed towards implementing
the dissemination mechanism so that a GPS measure is not
flooded throughout the possibly huge network, but instead
only to those nodes that are mostly affected by the movements of the sending node, i.e., the “closer nodes” (see also
[8]). We intend also to investigate the use of tree-caching
and/or tree recomputation at intermediate nodes to improve
the number of successful multicasts when the multicast tree
is very large.

In both cases (networks with 30 and 60 nodes) we have
also compared our protocol with global flooding, the simplest multicast protocol that, as OLAM, does not assume
the construction and maintenance of any underlying distributed data structure. As expected, simulations show that
OLAM improves on the average delay of (successful) multicast completion up to 51% (see Table l below, where /MI
indicates the group size).
All the simulations run for a time long enough to achieve a
confidence level of 95% with a precision within 5%.

v.

CONCLUSIONS AND

FUTURE
RESEARCH

In this paper we have described how, using location awareness through GPS devices and efficient dissemination of
GPS measures, an On-demand Location-Aware Multicast
(OLAM) protocol can be designed for ad hoc networks.
As in the case with 30 nodes, this values for the grid size and the
selected transmission radius guarantee that after movements occur the network is connected.

1327

REFERENCES
(1) T. Ballardie, P. Francis, and J. Crowcroft. Core based
trees (cbt): An architecture for scalable inter-domain
multicast routing. In Proceedings of the ACM SIGCOMM’93, Communications Architectures, Protocols
and Applications. Also Computer Communication Review, ~01.23,no.4, Oct. 1993, pages 85-95, San Francisco, CA, 13-17 September 1993.

(2) S. M. Corson and S . G. Batsell. A reservationbased multicast (RBM) routing protocol for mobile
networks: Initial route construction phase. Wireless
Networks, 1(4):427450,1995.
(3) C.-C. Chiang, M. Gerla, and L. Zhang. Adaptive
shared tree multicast in mobile wireless networks. In
Proceedings of Globecom’98, IEEE Global Telecommunications Conference, Sydney, Australia, November 8-12 1998.
(4) J. J. Garcia-Luna-Aceves and E. L. Madruga. The
core-assisted mesh protocol. IEEE Journal on Selected Areas In Communications, Special Issue on
Wireless Ad Hoc Networks, 17(8):1380-1394, August
1999.
( 5 ) C.-C. Chiang and M. Gerla. On-demand multicast in

mobile wireless networks. In Proceedings of IEEE
ICNP’98, Austin, TX,1998.

loo

E

loo I

I

99

-

98.5

8

98

Group size: 6
Group size: 10
Group size: 20

98

99.5

Y

!,

I

E

96

.z-2

94

3

a

-

I

92
90

8

a

v1

88

91.5

86

I
6

8

10

12

14

16

6

20

18

8

10

12

14

16

18

20

Node Velocity ( d s )

Node Velocity ( d s )

Figure 2: Average percentage of successful multicasts in networks with (a) 30 nodes and (b) 60 nodes.
NodeVelocity(m/s):
n=30,IMI = 3
n=30,(MI = 5
n=30,IMI=10
.

I

I

n = 6 0 , I M I = 10
n=60,IMI = 2 0

I

6

I

I

51
45

I

8
51
47

I 10 I 12 I 14 I

16

I 18 I 20

I

50
45

I

51
46

I

I

49
42

I

36

33 I 3 5

33

29

25

50
44
24

23
20

21
18

1

22

I

19

21
18

24
20

24
18

24
20

1

50
45

I

51
44
25
24
20

Table 1: OLAM delay improvement with respect to flooding (%).

(6) E. M. Royer and C. E. Perkins. Multicast using ad-hoc
on-demand distance vector routing. In Proceedings of
the Fifth Annual ACM/IEEE International Conference
on Mobile Computing and Networking, MobiCom’99,
Seattle, WA, 15-20 August 1999.
(7) C.-C. Chiang and M. Gerla. Routing and multicast
in mobile wireless networks. In Proceedings of 1997
IEEE 6th International Conference on Universal Person Communications Record. Bridging the Way to the
21st Century, ICUPC’97, volume 2, pages 557-561,
San Diego, CA, 12-16 October 1997.
(8) S . Basagni, I. Chlamtac, V. R. Syrotiuk, and B. A.
Woodward. A distance routing effect algorithm for
mobility (DREAM). In Proceedings of the Fourth Annual ACM/IEEE International Conference on Mobile
Computing and Networking, MobiCom’98, pages 7684, Dallas, TX, October 25-30 1998.

(9) S. Basagni, I. Chlamtac, and V. R. Syrotiuk. Geographic messaging in wireless ad hoc networks. In
Proceedings of the IEEE 49th Annual International
Vehicular Technology Conference, volume 3, pages
1957-1961, Houston, TX, May 16-20 1999.

(10) E. M. Palmer. Graphical Evolutions: An Introduction
to the Theory of Random Graphs. Wiley-Interscience
Series in Discrete Mathematics. John Wiley & Sons,
New York, 1985.
(11) D. Johnson and D. A. Maltz. Dynamic source routing in ad hoc wireless networks. In T. Imielinski and
H. E Korth, editors, Mobile Computing, chapter 5 ,
pages 153-1 8 1. Kluwer Academic Publishers, Dordrecht, The Netherlands, February 1996.
(12) E K. Hwang, D. S . Richards, and P. Winter. The
Steiner Tree Problem. Number 53 in Annals of Discrete Matematics. North-Holland, The Netherlands,
1992.
(13) K. Makki, N Pissinou, and 0. Frieder. Efficient solutions to multicast routing in communication networks. Mobile Networks and Applications (MONET),
1(2):221-232,1996.
(14) H. Takahashi and A. Matsuyama. An approximate solution for the steiner problem in graphs. Math. Jap.,
24:573-577, 1980.

1328

Topology Transparent Scheduling, Synchronization, and Maximum Delay
Wensong Chu
Charles J. Colbourn
Violet R. Syrotiuk
Department of Computer Science and Engineering
Arizona State University
Tempe, AZ 85287-8809
wensong.chu,colbourn,syrotiuk@asu.edu
Abstract
Topology transparent scheduling for medium access control is an attractive technique for mobile ad hoc networks
(MANETs) and sensor networks. The transmission schedule for each node is ﬁxed and guarantees a bounded delay independent of which nodes are its neighbours, as long
as the network is not too dense. Constructions of and performance criteria for topology transparent schedules have
been extensively studied however, to date, frame synchronization is assumed. Synchronization is a difﬁcult problem
for MANETs and sensor networks. We study the relationships among topology transparent schedules, synchronization, and maximum delay. Frame synchronization, slot synchronization, and asynchronous transmission are the three
synchronization models for this study. For each synchronization model, the ﬁrst question is:
1. Do topology transparent schedules exist?
If the answer to this question is yes, then two further
questions are natural:
2. How to construct topology transparent schedules?
3. What is the least maximum delay?
For frame and slot synchronization these three questions
are answered in earlier work. In this paper, we give answers
for these three basic questions for asynchronous networks.

1 Introduction
A mobile ad hoc network (MANET) is a collection of
mobile wireless nodes that self-organize without any centralized control or any fixed infrastructure. A sensor network is collection of sensor nodes that may be used to communicate what is sensed continuously, or to detect specific
events. Since the position of the sensor nodes may not be

known in advance, there is a need for the network to coordinate in a distributed manner, similar to the self-organizing
capabilities of a MANET.
Since the nodes in both a MANET and a sensor network
communicate over a shared broadcast channel, a medium
access control (MAC) protocol is responsible for controlling access to the communication resources. As a result, the
MAC protocol is essential component of the network.
There are several differences between sensor networks
and MANETs [13]. In particular, the number of sensor
nodes deployed in a sensor network is expected to be several orders of magnitude higher than the number of nodes
in a typical MANET. While sensor nodes may be more
densely deployed, they are also limited in power, computational capability, and memory capacity. Since sensor nodes
are prone to failure, destruction, and energy depletion, the
topology of the network changes frequently for these reasons rather than from node mobility. Sensor nodes may
not have global identifiers because of the amount of overhead assigning such identifiers for a large numbers of sensors. Furthermore, the network tends to operate as a collective structure, addressed by attribute, rather than supporting
many independent point-to-point flows. Traffic tends to be
variable and highly correlated.
Despite these differences, the type of MAC protocol can
be categorized as either contention or organized. In a contention protocol, nodes share the channel in a manner that
can lead to conflicts. The use of the distributed coordination
function (DCF) of IEEE 802.11 is prevalent in MANETs
due to its simplicity and lack of synchronization requirements [1]. While such contention based protocols achieve
high throughput with a reasonable expected delay, in the
worst-case the delay is very poor. For sensor networks, the
overhead of the control packets in the handshake can be
considerable (as high as 40% [16]) since data packets are
not very large. In addition, the channel must be monitored
continuously throughout the handshake, which is expensive for the low radio ranges of interest in sensor networks,
where transmission and reception have an energy cost of

Proceedings of the 18th International Parallel and Distributed Processing Symposium (IPDPS’04)

0-7695-2132-0/04/$17.00 (C) 2004 IEEE

the same order of magnitude. As the interest in delay sensitive (e.g., voice, video) applications and energy-awareness
grows organized approaches to medium access control are
more attractive.
Of the approaches to organized access, topologydependent and topology-transparent strategies have been
developed for MANETs. In a topology-dependent strategy, the protocol alternates between a contention phase and
an allocation phase. In the contention phase, nodes collect
neighbour information from which schedules are computed
for use in the allocation phase (see [4, 17] as examples).
Recently, such a protocol has also been proposed for use in
sensor networks [14]. All topology-dependent schemes are
sensitive to the frequency with which the contention phase
is run, and may suffer instability if the changes in traffic or
topology occur too rapidly.
In a topology-transparent strategy, neighbour information is not used. The existing protocols construct schedules that depend on two design parameters: , the number of nodes in the network, and
 , the maximum active node degree. If the bound on
 is satisfied, the
schedule guarantees at least one collision-free transmission
to each neighbour [3, 11]. In [15] the existing topologytransparent MAC protocols were generalized by observing
that their schedules correspond to an orthogonal array. The
largest number of nodes for a given frame length is supported by a Steiner system [8]. Both orthogonal arrays and
Steiner systems are special cases of combinatorial objects
called cover-free families [7]. Combinatorial designs arise
in many other applications in networking.
Almost all of the approaches to organized access have assumed that the nodes are synchronized on frame (schedule)
boundaries. In this paper we investigate three synchronization models (frame synchronized, slot synchronized, and
asynchronous) and examine their impact on the existence
of topology-transparent schedules and delay. Our contribution is for the asynchronous model, where we show that
topology-transparent schedules exist for this model, however the cost is that the delay doubles over the slot synchronization. These results are derived from properties of
superimposed codes, a form of combinatorial design.
The rest of this paper is organized as follows. In section 2, we give our assumptions and describe our network
model. As well, we define three synchronization models
(frame and slot synchronized, and asynchronous). The notion of a -robust schedule is also defined for each synchronization model. Section 3 defines the notions of superimposed codes and cyclic superimposed codes and their correspondence with frame- and slot-synchronized schedules.
We also summarize results on existence and constructions
of such schedules. The main results of this paper are given
in section 4. Here, we explore the existence of -robust
asynchronous schedules and discuss the tradeoff between









synchronization and delay. Finally, in section 5, a summary
of the results and conclusion are provided.

2 Models of synchronization
Following [3], we formally model a network of nodes
by an undirected graph
 , where is the set of
nodes (vertices) and is the set of links (edges). The size
of is the total number of nodes in the network, denoted
. Let   
with 
be two nodes
by
(vertices). There exists an edge      if and only if
 is within the range of transmission of  and vice versa.
Then  and  are neighbours of each other.
The degree   of a node is the number of neighbours
of the node . The maximum degree in the network is





  

  

 












	






  
¾ 

Time is slotted and slots are grouped into frames. A frame
 
  where
is the
is represented as
length of the frame.
A schedule or slot assignment of a node  is given
by a subset    and    means that node can
transmit in the th slot of a frame. Thus   consists of the
slots in which node can transmit.
We make two assumptions about channel access. A node
transmitting in a given slot cannot be receiving a packet in
the same slot; that is, communication is half-duplex. A node
cannot receive more than one packet in one slot. If more
than one packet is transmitted to a node in a given slot, then
a collision occurs and all transmissions to the node are considered unsuccessful.
We also make the following assumptions:






     




 





 





1. Channel noise is not considered. The only event that
causes packet loss is a collision.
2. The acknowledgement from the destination node is
available immediately at the end of transmitting slot.
This form of acknowledgement was assumed in [3, 11]
in order to simplify analysis.
3. Each node maintains a local timer to ensure that the
length of a slot is fixed for all nodes of the network.
Each packet is transmitted at the beginning of a slot.
Three different models of synchronization are studied:
1. A network is slot synchronized if there exists a good
method to allow all nodes to align on a slot boundary.
2. A network is frame synchronized if it is slot synchronized and there is a good method to allow all nodes to
start and end frames at the same slot periodically.

Proceedings of the 18th International Parallel and Distributed Processing Symposium (IPDPS’04)

0-7695-2132-0/04/$17.00 (C) 2004 IEEE

3. A network is asynchronous if it is neither frame nor
slot synchronized.
We discuss schedules in the context of different synchronization models and compare the corresponding performance. We begin with formal definitions of schedules
under different synchronization models.
  be a network with frame synchroLet
nization (FS) and  be a positive integer. A  -robust FSis a schedule satisfying the following two
schedule of
conditions:
1. For each node  and for each neighbour  of  there
½ ¾  	 	 	     , such
are at least  slots 
that     and also   ¼   for each
neighbour ¼ of , ¼   . This condition ensures that
each node has  conflict free slots for transmission to
each of its neighbours in every frame.
2. The schedule is only based on two global network parameters 
 and  .

  be a slot synchronized (respectively
Let
asynchronous) network with 
 nodes, and maximum degree  . Let  be an integer with   . A slot assignment  of the node  is a  -robust SS-schedule (respectively AS-schedule) if the following conditions are satisfied:
1. For each node  and for each neighbour  of  , the
node  has at least  collision-free slots in each frame
for transmitting packets to the node , no matter at
what slot (at what time, respectively) it starts.
2. The schedule is only based on two global network parameters 
 and  .
The requirements for  -robust AS-schedules are stronger
than the ones for SS-schedules. Without slot synchronization, two slots from different nodes can overlap.
As expected, frame length increases as the degree of
synchronization weakens. The shortest frames are obtained when communication is frame synchronized. Longer
frames are needed to permit slot synchronization, and
longer frames yet in the asynchronous model.

3 Schedules via superimposed codes
Let 
½  ¾  	 	 	    and 
 
½  
¾ 	 	 	  
 
be two   binary -dimensional vectors. The bit-by-bit
Boolean sum is the superposition sum and denoted by

  
 ½  
½  ¾  
¾  	 	 	    
  	
In addition,  is contained in 
 if   
 
 .

Let  be a    binary matrix. Let  and  be two
positive integers.  is a  -robust superimposed code of
order , denoted by    -SC, if for any  columns
of  , and one designated column  among them, there
exist at least  rows that intersect  in a one and with the
other  columns with all zeros.
Superimposed codes with 
 were introduced by
Kautz and Singleton [12] in 1964 and have been studied
as an application of combinatorial group testing in communications. Cover-free families and disjunct matrices are
equivalent combinatorial objects studied in other contexts.
Refer to [9] for a comprehensive treatment on combinatorial
group testing.
For systems with slot synchronization, we need codes
with the cyclic automorphism group. In [5], we propose a
coding scheme, cyclic superimposed codes, for which we
need some notation.
¼  ½  	 	 	  ½  be a binary vector with
Let 
length . Let

    ·½  	 	 	   ½ ¼  	 	 	   ½ 
be the  th cyclic shift of . Since the vector has length ,
we have   . Let
 

 

	 

 
      
be the set of all possible cyclic shifts of .
Any binary vector of length  can be represented as a
subset of , the integers modulo . This subset
  
 
is called the support of . Corresponding to 	 , we have
its subset representation

    
      
where   
  
 . It is not difficult
to see that 	  and   are different representations of the
same object, the cyclic orbit of the vector  under action of
, or just the cyclic orbit of .
½  ¾  	 	 	    be a    binary matrix,
Let 
where  ,      is a column vector of length  . Then
 is a cyclic    -SC if
1. Any two distinct columns  and 	 with    are
cyclically distinct: 	    	 	  .
2. For any choices of ½  	 	 	   with  
 	  , the
matrix ½  ¾  	 	 	    is a    -SC.
Example 3.1 The following matrix  is the transpose of
a cyclic    -SC. No matter how you cyclically shift
each row of  , the result is always a    -SC.

Proceedings of the 18th International Parallel and Distributed Processing Symposium (IPDPS’04)

0-7695-2132-0/04/$17.00 (C) 2004 IEEE

      
     
     
     
     







If we represent each row of the above matrix by its support,
we have

 
 
 
 






 
 
 
 

If we adjoin all cyclic shifts of each row of  and form a
   	 matrix, then its transpose is a 
	    -SC.
In [5], a unified model for  -robust FS- and SS-schedules
is presented.
Theorem 3.1 ([5]) Let   
   be a network with
  nodes, and maximum degree   . If there exists
a 
 	 
  -SC with 	   and 
    , then there
exists a  -robust FS-schedule for the network  with frame
length  .

 

Weakening from frame synchronization to slot synchronization with the same parameters (assuming the prime
power  is actually a prime 
), the frame length (maximum
delay) is enlarged by a factor around 
. An interesting question is the existence of  -robust AS-schedules and the tradeoff between synchronization and delay. This is the main
topic of the next section.

4

-robust AS-schedules

Slot synchronization is stronger than no synchronization, and hence any  -robust AS-schedule is a  -robust SSschedule. We first look at the constructions for cyclic superimposed codes. One efficient method is via optical orthogonal codes (OOCs). An (    ) optical orthogonal code (OOC)  is a family of 
  sequences of length
 and weight  that satisfies the following two properties,
where 
 denotes addition modulo :
1. Auto-correlation property:


for any  
 

 .


 

 

The existence of  -robust SS-schedules was proved in
[5] via cyclic superimposed codes; constructions of cyclic
SCs are also presented in the same paper.
Theorem 3.3 ([5]) Let   
   be a network with
  nodes, and maximum degree   . If there exists
a cyclic 
 	 
  -SC with 
    and   	, then
there exists a  -robust SS-schedule for each node in  with
frame length  .

 

Theorem 3.4 ([5]) For any given global network parameters  and   , and for any positive integer  , there exist a prime 
 and positive integer , such that there exists a
cyclic 

 	 
 
       -SC, i.e., a  -robust SS-schedule
with   
 ,        , and frame length 
 	 
.

 	

 

 

 



and every integer  ,

 

2. Cross-correlation property:



The main constructions for  -robust FS-schedules in [3,
8, 11, 15] can be summarized as follows:
Theorem 3.2 ([11]) For given global network parameters
 and   , and for every positive integer  , there exist a prime power  and positive integer , such that there
exists a 
        -SC, i.e., a  -robust FS-schedule
with     ,       , and frame length  .







 

 	

 

 ,
for any    
   and every integer  .

 







Example 4.1 The codewords of a 
  





 

 

 

with

-OOC are:

  
   

The weight
ones.



  because each codeword has three

Theorem 4.1 ([5]) Let   be an integer. If there exists a

    -OOC with 	 codewords and  	    , then
there exists a cyclic 
 	 
  -SC with 
   
  .
Lemma 4.1 ([2]) For any prime power  , there exists an
optimal 
 	 
 OOC with one codeword.
The following is a general recursive construction that
only requires a certain prime factorization of integers.
Theorem 4.2 ([6]) Suppose there exists an 
   
OOC with  codewords. Let   
½ 
¾

 be a positive integer, where the 

 ’s with     are primes not
less than  . Then there exists an 
    OOC with

  codewords.

Proceedings of the 18th International Parallel and Distributed Processing Symposium (IPDPS’04)

0-7695-2132-0/04/$17.00 (C) 2004 IEEE

Theorem 4.3 For every prime and every positive integer
, there exists a  ¿     -OOC  with the following parity property: Let  and  be two different codewords
of  . For any   ¾¿ ¾ , if there exists two elements 
and  in 	
  with     modulo  ¿  , then
there exists no pair of elements  and  in 	
   such that
     .
Proof. By Lemma 4.1, there exists a ¾
   OOC with a single codeword. Take the support of this
codeword and multiply each element by . Then we
get a  ¾
   -OOC with a single codeword.
This codeword has the following property: the difference
of any two elements in the support is an even number.
    -OOC
Apply Theorem 4.2 to get a  ¿
 with the property that the difference of any pair of
elements from any two supports of codewords is even (refer
to the proof of the basic construction in [6]). Since all
possible differences are even, the parity property holds.
Now we claim the existence of a 
 -robust AS-schedule.
Theorem 4.4 For any given global network parameters 
and  , and for any positive integer 
 , there exist a
prime and positive integer , such that there exists a 
 robust AS-schedule with   ,      , and
frame length  ¿  .
Proof. We have proved that there exists a  ¿     OOC with the parity property by Theorem 4.3; by Theorem
4.1, there exists a cyclic  ¿        
 -SC. Therefore there exists a 
 -robust SS-schedule with  
and
     .
To prove the theorem, first we show that the parity property is sufficient to make a 
 -robust SS-schedule a 
 -robust
AS-schedule. For any two different codewords of  , say 
and  , we have   	
   	
    . We need to
show that if the slots of  and  are not perfectly aligned,
the intersection number  does not increase. Now  increases if and only if two elements  and  in 	
  are 
apart and two elements  and  in 	
   are    apart.
This is exactly the parity property in Theorem 4.3.
Then the rest of proof is to show that for any  , 
and 
 , we always can find and  such that there exists the
desired schedule.
Given  and 
 , the function   with











is a strictly increasing function with respect
 to prime . In

addition, the function 
  with 
   ÐÒ
ÐÒ  is a strictly
decreasing function with respect to prime . Thus the set





  






	



 





is an infinite subset of all natural numbers. Let  be the

minimal element of this set and   
 ÐÒ
ÐÒ  . Then we
construct the claimed OOC according to Theorem 4.3.
Based on this constructive proof, the following algorithm
finds appropriate parameters for the superimposed code:
Algorithm 4.1 L:=0;
repeat

if   for some prime


compute   
 ÐÒ
ÐÒ   and 	   
if   	, then
Output  and
EXIT
end if
end if
end
Construct a cyclic  ¿     
  and      
END Algorithm

 




 
-SC, where

Weakening from slot synchronization to asynchronous
communication once again enlarges the frame length, in this
case by a factor of two.

5 Conclusions
With respect to different types of synchronization (frame
synchronization, slot synchronization and asynchronous
transmission), we have answered the questions of existence of topology-transparent schedules and how to construct them.
To conclude this paper, we provide a comparison among
these three synchronization schemes. We consider an example. Let      be a network with  is ranging
from 		 to 			 and   
. Choosing   

employs the distributed topology control algorithm in [10].
Figure 1 shows a comparison of the maximum delays. The
lowest delay as expected is when frames are synchronized.
A substantial loss in the delay guarantee results when synchronization is on slot boundaries; the figure illustrates the
further doubling when no synchronization of any kind is assumed.
From frame synchronization to slot synchronization, we
lost performance in a significant way. Thus the main concern is performance. Some interesting questions related to
performance are:

Proceedings of the 18th International Parallel and Distributed Processing Symposium (IPDPS’04)

0-7695-2132-0/04/$17.00 (C) 2004 IEEE

14000
1−robust AS−schedule

L: Maximal Delay with g=1, Dmax=6

12000

10000

8000
1−robust SS−schedule
6000

4000

2000
1−robust FS−schedule
0
100

200

300

400

500
600
700
N: Number of Total Nodes

800

900

1000

Figure 1. Maximum delay for each synchronization model.

1. If the upper bound of
 is violated, i.e., for some
nodes, there are more than
 neighbours, the guarantee of a -robust schedule is lost. How does one handle such a situation? This is studied in [8, 15].



2. If the actual number of neighbours is far less than
, how to be adaptive to the traffic and make use
of available bandwidth?
3. How does one handle acknowledgements in a realistic
manner?
The second and third questions are topics of our current
research on this subject. Simple strategies such as piggybacking acknowledgments on message traffic enables one
to achieve a finite bound for delay, but better solutions are
possible.

Acknowledgements
The work of Charles J. Colbourn was supported in part
by ARO grant DAAD 19-01-1-0406. The work of Violet R.
Syrotiuk was supported in part by NSF grant ANI-0105985.

References
[1] IEEE Standard 802.11: Wireless LAN Medium Access Control and Physical Layer Specifications. December 1999.
[2] R. C. Bose. An Affine Analogue of Singer’s Theorem. Indian Mathematical Society, 6:1–5, 1942.
[3] I. Chlamtac and A. Faragó. Making Transmission Schedules Immune to Topology Changes in Multi-hop Packet Radio Networks. IEEE/ACM Transactions on Networking,
2(1):23–29, February 1994.

[4] I. Chlamtac and S. S. Pinter. Distributed Node Organization Algorithm for Channel Access in a Multihop Dynamic
Radio Network. IEEE Transactions on Computers, 36:728–
737, 1987.
[5] W. Chu, C. J. Colbourn, and V. R. Syrotiuk. Slot Synchronized Topology-Transparent Scheduling for Sensor Networks. Submitted, 2003.
[6] W. Chu and S. W. Golomb. A New Recursive Construction
for Optical Orthogonal Codes. IEEE Transactions on Information Theory, 49(11):3072–3076, November 2003.
[7] C. J. Colbourn, A. C. H. Ling, and V. R. Syrotiuk. CoverFree Families and Topology-Transparent Scheduling for
MANETs. Designs, Codes, and Cryptography, to appear.
[8] C. J. Colbourn, V. R. Syrotiuk, and A. C. H. Ling.
Steiner Systems for Topology-Transparent Access Control
in MANETs. Proceedings of the Second International Conference on Ad hoc Networks and Wireless (Ad hoc Now’03),
pages 247–258, October 2003.
[9] D. Z. Du and F. K. Hwang. Combinatorial Group Testing
and Its Applications. World Scientific, second edition, 2000.
[10] L. Hu.
Topology Control for Multihop Packet Radio Networks. IEEE Transactions on Communications,
41(10):1471–1481, October 1993.
[11] J.-H. Ju and V. O. K. Li. An Optimal Topology-Transparent
Scheduling Method in Multihop Packet Radio Networks.
IEEE/ACM Transactions on Networking, 6(3):298–306,
June 1998.
[12] W. H. Kautz and R. C. Singleton. Nonrandom Binary Superimposed Codes. IEEE Transaction on Information Theory,
10:363–377, October 1964.
[13] C. E. Perkins, editor. Ad Hoc Networks. Addison-Wesley,
Inc., Reading, MA, 2000.
[14] V. Rajendran, K. Obraczka, and J. J. Garcia-Luna-Aceves.
Energy-Efficient, Collision-Free Medium Access Control
for Wireless Sensor Networks. Proceedings of the First
ACM International Conference on Embedded Networked
Sensor Systems (SenSys’03), pages 181–192, November
2003.
[15] V. R. Syrotiuk, C. J. Colbourn, and A. C. H. Ling. TopologyTransparent Scheduling for MANETs using Orthogonal Arrays. Proceedings of the DIALM-POMC Joint Workshop on
Foundations of Mobile Computing, pages 43–49, September
2003.
[16] A. Woo and D. E. Culler. A Transmission Control Scheme
for Media Access in Sensor Networks. Proceedings of the
Seventh Annual International Conference on Mobile Computing and Networking (MobiCom’01), pages 221–235, July
2001.
[17] C. Zhu and M. S. Corson. A Five-Phase Reservation Protocol (FPRP) for Mobile Ad Hoc Networks. Proceedings of
the Seventeenth Annual Joint Conference of the IEEE Computer and Communications Societies (Infocom’98), pages
322–331, 1998.

Proceedings of the 18th International Parallel and Distributed Processing Symposium (IPDPS’04)

0-7695-2132-0/04/$17.00 (C) 2004 IEEE

Quantifying Factors Affecting Quality of
Service in Mobile Ad Hoc Networks
Kiran K. Vadde
Violet R. Syrotiuk
Computer Science & Engineering
Arizona State University
P.O. Box 878809
Tempe, AZ 85287-8809
kvadde@asu.edu
syrotiuk@asu.edu
Support for quality of service (QoS) is increasingly important in mobile ad hoc networks (MANETs)
with the emergence of delay-sensitive applications. This article quantifies the impact of factors and
their interactions on the performance of real-time flows through statistical analysis of data gathered in
simulation. The factors considered include QoS architecture, routing protocol, medium access control
(MAC) protocol, mobility model, and offered load.The QoS architectures considered include stateless
(Swan), stateful (Insignia), and no support for QoS. For routing, proactive (OLSR) and reactive (DSR,
AODV) protocols are considered. The IEEE 802.11 distributed coordination function (DCF) and its
QoS-aware extension enhanced DCF (EDCF) are the MAC protocols considered. The authors find
that the stateless architecture of Swan better supports QoS than the stateful approach of Insignia or
the classic architecture in the two mobility models considered.
Keywords: Quality of service (QoS), mobile ad hoc networks (MANETs), factor interaction, statistical
analysis

1. Introduction
Research to support quality of service (QoS) in mobile ad
hoc networks (MANETs) has largely been motivated by
the need to support voice communication. This is the primary application in battlefield and in emergency situations,
where MANETs are best deployed. What makes supporting QoS in MANETs a challenge is that the network operates without any centralized control or fixed infrastructure.
Frequent changes in the network topology result from node
mobility and from the time-varying characteristics of the
wireless channel. Such network dynamics add to the difficulty of supporting QoS (i.e., estimating and provisioning
resources to real-time flows to satisfy their rate, delay, or
jitter requirements).
Similar to the differentiated and integrated service architectures for wired networks, QoS architectures have
emerged for MANETs [1, 2]. These architectures make
use of techniques such as admission and flow control,
traffic shaping, and others to regulate best-effort traffic to
satisfy the QoS needs of real-time traffic. Individual protocols are made QoS aware by differentiating real-time and
best-effort packets and/or flows. For example, a QoS-aware

SIMULATION, Vol. 81, Issue 8, August 2005 547-560
© 2005 The Society for Modeling and Simulation International
DOI: 10.1177/0037549705060236

|
|
|
|
|

routing protocol selects paths based on metrics such as delay, bandwidth, or load balancing rather than hop count
[3, 4], and a QoS-aware medium access control (MAC)
protocol provides packets of different traffic classes with
differentiated channel access. Improving cross-layer protocol interactions has been critical for improved network
performance [5, 6].
Since there are very few MANET testbeds, simulation
has provided a valuable tool to model MANETs and network architectures with high fidelity and to measure their
performance. Initially, simulation was used to measure the
performance of various protocols run individually in different network settings. For example, Royer, Lee, and Perkins
[7] compare the performance of the Wireless Routing Protocol (WRP), the Fisheye State Routing (FSR), and the
Adhoc On-Demand Distance Vector (AODV) routing protocol over the Carrier Sense with MultipleAccess (CSMA),
Multiple Access with Collision Avoidance (MACA), Floor
Acquisition Multiple Access (FAMA), and IEEE 802.11
MAC protocols, varying the pause time of the random waypoint mobility model. Their results show that performance
of WRP and FSR did not change significantly with the
MAC protocol, while AODV outperformed other routing
protocols when run over IEEE 802.11.
Perkins et al. [8] compare the performance of the Dynamic Source Routing (DSR) and AODV routing protocols
running over the IEEE 802.11 MAC protocol for different network loads, network sizes, and pause times in the

Vadde and Syrotiuk

random waypoint mobility model. Their results show that
the performance of DSR and AODV varies based on
the simulation parameters. For a large number of traffic
sources, the performance of AODV exceeds that of DSR.
While such studies help us understand how a protocol performs in different settings, they provide little information on how or to what extent protocols interact. Bai,
Sadagopan, and Helmy [9] went a step further. They used
simulation to study the impact of mobility models on the
AODV, DSR, and Destination-Sequenced Distance Vector
(DSDV) routing protocols. Their results show that the performance of all three protocols changes significantly with
the underlying mobility model. The difference in performance is attributed to the underlying graph properties of
the mobility model. Of particular interest is the decomposition of the routing protocols into “building blocks” to
gain more insight into how mobility creates performance
variations across the protocols.
At about the same time, Barrett et al. [10] used more rigorous techniques to characterize the interaction between
the MAC and routing protocols in MANETs. They used
statistical design of experiments (DOE) [11] to determine
whether factors interact with each other in a significant
way. This is a well-known methodology used for factor interaction studies in many disciplines ranging from social
sciences to industrial engineering. Statistically, interaction
between two factors exists when the effect of a factor on
a response variable is modified by another factor in a significant way. Starting with a saturated model, they applied
backward elimination. This method checks each k-way factor interaction for significance using analysis of variance
(ANOVA) techniques and eliminates it if it is found to be
insignificant. In this way, the smallest model that explains
the simulation data is found. We applied DOE to quantify
cross-layer protocol interactions affecting service delivery
in MANETs [12].
There are two aspects to any experimental problem: the
design of the experiment and the statistical analysis of the
data. In this article, we select five factors of mixed levels
that represent a useful subset of possible factors to consider
in order to bound our study. The factors we consider are
(1) QoS architecture, (2) routing protocol, (3) MAC protocol, (4) mobility model, and (5) offered load. We select
average real-time packet delay, jitter, real-time throughput
(throughput of real-time flows only), and total throughput (throughput of real-time and best-effort flows) as our
responses. We then perform a statistical analysis of the
data collected from experiments run in the ns-2 network
simulator [13] using ANOVA techniques in Design-Expert
[14]. This allows us to quantify the main effects and interactions of factors that best explain the response variables
in our study.
Our results show that the QoS architecture does contribute to the response variables. Swan in general performs
better than Insignia and classic architectures. However, the
combination of the MAC protocol with which it performs
best is dependent on the routing protocol over which it
548 SIMULATION Volume 81, Number 8

operates. With DSR and Optimized Link State Routing
(OLSR), Swan with the enhanced distributed coordination
function (EDCF) has the best performance with respect
to average delay and real-time throughput. However, with
AODV, Swan over IEEE 802.11 has the best performance.
This is due to the differences in interactions between the
routing and MAC protocols. EDCF performs poorly in the
presence of congestion, and this negatively affects AODV,
causing higher overall average delays.
Of course, not only the question of which factors and
factor interactions affect observed performance but also the
question of how these factors and their interactions work
to cause the observed performance require an answer. Design of experiments provides answers for the former question; addressing the latter question is equally important, as
understanding how factors and their interactions work is
likely to be critical for effective cross-layer protocol designs. In this article, we focus on quantifying both main
effects and interactions of factors on responses.
This article is organized as follows. In section 2, we
briefly explain the simulation models used. In section 3,
we describe the network responses measured and present
as well as interpret the simulation results. A statistical analysis of the simulation results, quantifying the factors and
their interactions, is presented in section 4. The interaction
of the protocols within the architecture leaves substantial
research questions, which we elaborate on in section 5,
after summarizing our findings.
2. Simulation Models
We use the network simulator ns-2 version 2.26 [13] installed on a Pentium IV 2.4-GHz processor with 2 GB
RAM running Linux. It is a discrete event simulator implemented in C++. The Monarch group [15] integrated
extensions into the ns-2 simulator to support wireless
communications between mobile nodes. Specifically, these
extensions include radio propagation models, a channel
model, and node movement and location update—all essential to modeling MANETs.
To apply DOE, the first step is to identify the factors
and the level of each factor for our experiments. To bound
our study, we consider the following five factors:
1. QoS architecture,
2. routing protocol,
3. MAC protocol,
4. mobility model, and
5. offered load.
2.1 QoS Architecture Models
In support of QoS, a spectrum of architectures has been
proposed, ranging from stateless (differentiated services)

QUANTIFYING FACTORS AFFECTING QUALITY OF SERVICE IN MANETS

to stateful (integrated services). For MANETs, an example of a stateless approach is Swan, while Insignia is an
example of a stateful approach.
In Swan [1], individual nodes along the route from a
source to a destination do not maintain any state information regarding the admitted real-time flows. In Swan,
admission control is performed only at the source node to
decide whether to admit or reject a real-time flow based
on the available bandwidth in its neighborhood. Intermediate nodes regulate their best-effort traffic to meet the QoS
needs of real-time flows routed through them. The channel access delay, a local measure of congestion, is used
to determine the rate at which to regulate the best-effort
traffic.
Intermediate nodes, not just the source, perform admission control and maintain the QoS state on flows admitted in Insignia [2]. Insignia performs flow adaptation and
restoration to meet the QoS needs of real-time flows and to
match them to the available resources; this is achieved using in-band signaling. Insignia is therefore a heavy-weight
QoS architecture in terms of memory, computation, and
communication when compared to Swan.
For the factor of QoS architecture, we consider three
levels: Swan, Insignia, and “classic” with no provisions
for QoS.
2.2 Routing Protocol Models
The problem of routing is fundamental in MANETs since
each node is capable of functioning as a router, forwarding packets in addition to being a source or destination of
packets. We consider both proactive and reactive protocols
in our study; all have advanced to the next stage of standardization by the Internet Engineering Task Force (IETF)
MANET working group [16].
In DSR [17], the source is responsible for computing
the route for a packet. When a node wishes to communicate with another node, it floods a route request (RREQ)
through the network to discover a route to the destination.
When the RREQ reaches the destination or a node that
is aware of a route to the destination, forwarding stops.
A route reply (RREP) packet is sent back to the source
on the reverse path, with the full source route to the destination embedded. This source route is included in the
header of each data packet, enabling stateless forwarding.
The route maintenance mechanism monitors the status of
source routes in use, detects link failures, and repairs routes
with broken links. Nodes operating in promiscuous mode
listen to ongoing traffic and cache overheard routes; these
may help reduce the scope of the RREQ flood.
AODV [18] is similar to traditional distance vector protocols in that it maintains routing tables with one entry per
destination. AODV builds routes using RREQ and RREP
control packets similar to the route discovery mechanism
in DSR. The main difference is that as a RREP propagates
back to the source, each node sets up a forward path entry
to the destination in its routing table. Once the source node

receives the RREP, it may begin to forward data packets to
the destination.
While DSR and AODV are reactive routing protocols,
the OLSR protocol [19] is proactive; it builds/maintains
routes to all nodes on a continuous basis rather than on
an as-needed basis. OLSR makes use of multipoint relays (MPRs). An MPR is a subset of neighbors that reach
the two-hop neighborhood, allowing efficient flooding of
control messages. MPRs exchange link state information
to form routes. Sequence numbers are used to guarantee
loop-free routes, and timers are maintained to refresh route
entries.
For the factor of the routing protocol, we consider three
levels: AODV, DSR, and OLSR.
2.3 MAC Protocol Models
The MAC protocol is fundamental in all networks whose
basis is a broadcast channel. The MAC protocol is directly
responsible for controlling access to the communication
resources.
The IEEE 802.11 DCF [20] protocol is the dominant
MAC protocol in MANETs due to its simplicity and lack of
synchronization requirements. It is a carrier-sense multiple
access with collision avoidance (CSMA/CA) protocol. It
is well established that IEEE 802.11 is ineffective for QoS
since it does not perform packet differentiation [21].
There are several approaches to extend IEEE 802.11 to
support traffic classes. In EDCF [22], traffic flows are classified based on their priority. The traffic from each class
has a distinct queue and also a different backoff window.
The backoff window is used to regulate nodes in accessing
the channel. The backoff counter for each of the transmission queues is run separately, and the data packets of the
queue whose backoff counter expires first are transmitted.
If more than one backoff counter expires, data packets of
the queue with the highest priority are transmitted.
We consider IEEE 802.11 DCF and its QoS-aware extension, EDCF, as the two levels of the MAC protocol. In
EDCF, the backoff window size for voice and data packets,
respectively, is [15, 31] and [31, 1023]. The backoff window for control packets is [7, 15]; these packets have higher
priority than the voice or data packets to ensure that broken
routes are repaired quickly to minimize service disruption
to the established flows.
2.4 Mobility Models
A mobility model governs node movement in the simulation area. Although not considered in our study, some
simulators also include terrain models (e.g., such as
TIREM [23]) and the effects of buildings and foliage on
propagation.
We consider two mobility models for individual nodes
in a flat, unobstructed area in our study: the grid and the random waypoint (RWP) models. In the grid mobility model,
the simulation area is divided into grid squares, and nodes
Volume 81, Number 8

SIMULATION

549

Vadde and Syrotiuk

(a)

(b)

Figure 1. Mobility models: (a) grid and (b) random waypoint

are allowed to move only along the grid lines. When a node
reaches an intersection, it decides to move in the same direction with a given probability; otherwise, it changes direction. This simulates movement in a city where there is
an underlying grid structure formed by streets and avenues.
An example of such movement is shown in Figure 1(a). In
the figure, a black circle denotes a mobile node, and the
arrow indicates the direction of its movement.
In the random waypoint (RWP) mobility model, a node
selects a destination at random and moves toward it with a
fixed speed. Once it reaches the destination, it pauses for a
time determined by a simulation parameter. The algorithm
then repeats. This models individuals moving from place
to place performing an activity at each destination. An example of nodes moving according to the RWP mobility
model is given in Figure 1(b).

Real-time traffic is modeled using three voice traffic flows
of 64 Kbps. The network load is varied by increasing the
number of best-effort flows. These best-effort flows are
modeled as TCP connections between the same source and
destination pairs as the real-time flows. This is done to
ensure that the TCP (best-effort) flows follow the same
route as the real-time flows to better observe the service
differentiation.

Nodes are connected to their peers via a shared 11-Mbps
interface. The transmission range of each node is 250 m.
All the nodes in the simulation model, including source
and destination nodes, move at the speed of 2 m/sec, which
corresponds to the speed of an individual walking. For experiments using the RWP mobility model, we distribute the
nodes according to the stationary distribution to improve
confidence of the validity of the results [24]. Nodes move
continuously (i.e., they do not pause). For the grid mobility model, a 10 × 10 grid overlays the simulation area.
Nodes are initially placed randomly on the grid. Nodes
move along the grids in the x or y direction and bounce
back if they approach the simulation area boundary. At a
grid intersection, nodes continue to move along in the same
direction with a probability of 0.5 and change direction to
the left or right with a probability of 0.25 each. This ensures
that nodes move along the grid in both x and y directions.
Each experiment runs for 200 seconds. The voice traffic
is initiated 5 seconds into the simulation between node
pairs (3, 18), (17, 20), and (0, 6), while the best-effort
flows begin after 40 seconds to ensure that the sourcedestination routes have been established and used by each
flow. The maximum number of packets generated by each
flow is 2500 to ensure that voice traffic and TCP data traffic
exist for the duration of the simulation. The size of realtime packets is 512 bytes, while best-effort packets are 128
bytes in size.

2.6 Factor Summary

3. Simulation Results

Table 1 summarizes the factors considered in our simulation. Running an experiment with every factor set to
every possible level (a full factorial design) results in
3 × 3 × 2 × 2 × 4 = 144 different experiments. We repeat
each experiment with 10 different seeds and take the average of these 10 runs. The size of the confidence interval is
20% of the plotted value in the worst case 95% of the time.

In this section, we present our simulation results. We collect
the following responses from our experiments.

2.5 Offered Load

2.7 Scenario Generation
Following scenario generation in earlier simulation studies
[1, 2], 50 nodes are distributed over a 1000 × 1000-m area.
550 SIMULATION Volume 81, Number 8

• (Real-time) average delay: The average end-to-end delay
experienced by a packet between its initiation at the source
and its receipt at the destination. This value includes queuing delays as well as channel access delays. We report the
average delay of real-time packets since only the real-time
traffic is delay sensitive.
• Jitter: The average interarrival time between real-time
packet receipts at the destination node. Jitter is a measure
of transmission quality; low jitter corresponds to a better
quality transmission.

QUANTIFYING FACTORS AFFECTING QUALITY OF SERVICE IN MANETS

Table 1. Factors and their levels
Factor

Levels of Factors

Quality-of-service architecture
Routing protocol

Swan, Insignia, Classic
Adhoc On-Demand Distance Vector (AODV), Dynamic Source Routing (DSR), Optimized Link
State Routing (OLSR)
IEEE 802.11, enhanced distributed coordination function (EDCF)
Grid, random waypoint
0, 3, 6, 9 additional best-effort flows

Medium access control (MAC) protocol
Mobility model
Offered load

• Real-time throughput: The number of real-time packets received per unit time, expressed in bytes/sec. Voice
requires an end-to-end delay of 400 msec for acceptable quality. Any real-time packet received whose delay
is greater than 400 msec is not included in this real-time
throughput calculation.
• Total throughput: The combined throughput of real-time
and best-effort traffic. The real-time traffic is assumed to
meet the delay requirement to be included, while every
best-effort packet received at its destination is included.
This metric determines the effectiveness of protocols in
using the unused bandwidth by real-time traffic for delivering best-effort traffic.

We present our results within the context of a mobility
model. Sections 3.1 and 3.2 present the results for the RWP
and grid mobility models, respectively. To make the results
less cluttered, we present the results for each routing protocol separately. To improve the readability of the graphs,
when IEEE 802.11 [EDCF] is used as the MAC protocol,
solid [dashed] lines are used.
3.1 Fixed Mobility Model: Random Waypoint
3.1.1 DSR in RWP
Figures 2 and 3 show the results of experiments in which
DSR is fixed as the routing protocol. Figure 2(a) shows
the average delay of real-time packets. The Swan QoS architecture over EDCF has the smallest delay among all
network architectures. Real-time packets are differentiated
from the best-effort packets both by the QoS architecture
and the MAC protocol, giving the best performance for
real-time packets.
Insignia over 802.11 has the worst performance because
the flow adaptation and restoration performed increase the
control packet overhead. This causes congestion in the network, leading to increased delay for the real-time packets. However, when Insignia is paired with EDCF as the
MAC protocol, it decreases the average delay for the realtime packets since service differentiation is provided by
the EDCF protocol. Insignia over EDCF performs worse
than the classic architecture over EDCF because of the flow
adaptation and restoration overhead.
When no QoS architecture is used, EDCF performs better than 802.11 because EDCF has a smaller backoff window size for real-time packets compared to that for best-

effort data packets. In 802.11, there is a single queue and
no service differentiation; hence, real-time packets suffer
larger delays.
Swan over 802.11 performs better than 802.11 alone as
Swan regulates the best-effort packets to reduce the delays for real-time packets. The number of route requests
made by DSR is quite low due to the aggressive route
caching, which also decreases the route repair time. Swan
over 802.11 performs better than EDCF in the classic architecture; this suggests that admission control is more helpful than packet differentiation at the MAC level. However,
having both admission control as part of QoS architecture
and packet differentiation at the MAC level is best of all,
as seen from the lowest delay for Swan over EDCF.
Figure 2(b) shows the real-time packet jitter. Swan over
EDCF has the lowest jitter, and 802.11 in the classic architecture has the highest jitter. The classic architecture over
EDCF has higher jitter than Swan over EDCF at low traffic
loads (i.e., at 0 and 3 best-effort flows). At higher traffic
loads (i.e., 6 and 9 best-effort flows), both have the same
jitter. Insignia over 802.11 has higher delay (see Fig. 2(a)),
but it has lower jitter than the classic architecture over
802.11 as it tries to make sure that the real-time flows have
the required bandwidth along the chosen route. Insignia
over EDCF has lower jitter than Insignia over 802.11 since
service differentiation with flow adaptation allows realtime packets to arrive at the destination faster, thereby decreasing the jitter.
Figure 3(a) compares the throughput of the real-time
flows. Swan over EDCF performs the best, and the classic
architecture over 802.11 performs the worst; this follows
from the results on delay discussed above. At the lowest
traffic load (i.e., where there are only real-time flows and
no TCP flows), all network architectures have almost the
same performance. The reason for this is that when there
are no best-effort flows, there is no traffic regulation in
Swan, and there is also no real service differentiation at
the MAC layer.
Figure 3(b) shows the total throughput. The x-axis in
this figure has only three points in contrast to the previous
figure with four data points. The total throughput when
there are no TCP flows is the same as the real-time throughput with zero TCP flows, which is shown in Figure 3(a);
hence, this point is not included. Swan over EDCF has the
best total throughput, and Insignia over 802.11 and the
Volume 81, Number 8

SIMULATION

551

Vadde and Syrotiuk

2.5

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

0.125

0.12

2

1.5

0.11

1

0.105

0.5

0.1

0
0

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

0.115
Avg jitter (secs)

Avg Real−time packets Delay (in secs)

3

3

6

0.095
0

9

# TCP flows

3

6

9

# TCP flows

Figure 2. Dynamic Source Routing (DSR) in the random waypoint (RWP) mobility model: average real-time packet (a) delay and
(b) jitter

5500

4500

8000
Total throughput (bytes/sec)

5000
Real−time flows throughput (bytes/sec)

9000

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

4000
3500
3000
2500

7000

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

6000

5000

4000

2000
3000

1500
1000
0

3

6
# TCP flows

9

2000
3

6
# TCP flows

9

Figure 3. Dynamic Source Routing (DSR) in the random waypoint (RWP) mobility model: (a) real-time throughput and (b) total
throughput

classic architecture over 802.11 have the worst performance. The reasoning given for the delay comparison applies here, too.
3.1.2 AODV in RWP
Figure 5 shows results with AODV fixed as the routing
protocol. As Figure 5(a) shows, the best performance is
obtained when AODV is run with Swan over 802.11; Insignia over EDCF has the worst performance. Of surprise
is that network architectures using EDCF have higher delays than those using 802.11. Intuitively, EDCF with its
service differentiation should perform better than 802.11
without service differentiation.
552 SIMULATION Volume 81, Number 8

The routing protocol plays an important role in the effectiveness of service differentiation at the MAC layer. AODV
generates substantially more (seven times) control packets than DSR, as Figure 4 shows. The reason for this is
the way RREQs propagate in AODV and DSR, as well
as the caching mechanism used in DSR. DSR uses aggressive caching to maintain route information, whereasAODV
does not perform caching. When the nodes move at slower
speeds (as used in our simulation), the routes cached remain valid most of the time, and DSR does not perform
network-wide flooding; hence, it generates fewer control
packets. In contrast, AODV performs an expanding ring
search to find routes, and since it does not use caching,

QUANTIFYING FACTORS AFFECTING QUALITY OF SERVICE IN MANETS

Total number of control packets generated

14000

12000

10000

8000

6000

4000

2000

AODV
DSR

0
0

3

6

9

# TCP flows

Figure 4. Number of control packets generated by the routing protocol

5500

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

Real−time flows throughput (bytes/sec)

Avg Real−time packets Delay (in secs)

1.5

1

0.5

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

5000

4500

4000

3500

3000

2500

0
0

3

6
# TCP flows

9

2000
0

3

6

9

# TCP flows

Figure 5. Adhoc On-Demand Distance Vector (AODV) in the random waypoint (RWP) mobility model: average real-time (a) delay
and (b) throughput

route requests can propagate deep into the network. Bai,
Sadagopan, and Helmy [9] observed the same results.
When the number of control packets generated by the
routing protocol is high, congestion occurs, leading to
higher contention for the channel by the MAC protocol.
With EDCF, collisions of the control packets cause a ripple
effect of collisions with the real-time packets. EDCF uses
a fixed contention window of [15, 31] for real-time packets; with each collision, EDCF selects a backoff time from
this small interval for packet retries. Since nodes choose
from a small backoff interval, at high congestion, there are
many retransmissions, leading to larger queuing delays and
dropped packets. This is the reason for larger delays of network architectures using EDCF.

Figure 5(b) shows the real-time throughput achieved.
As the figure shows, Swan over 802.11 has the best performance. Swan over EDCF performs poorly compared to
Swan over 802.11, as explained earlier. Network architectures using EDCF (except for those with Swan) perform
better than those using 802.11 for real-time throughput.
This is due to the absence of a strong interaction between
Insignia and EDCF, as well as between the classic architecture and EDCF. The reason why the classic architecture
over EDCF has higher real-time throughput than when run
over IEEE 802.11 (despite the fact that EDCF responds
poorly to congestion) is that once congestion eases, EDCF
delivers more packets than IEEE 802.11.
Volume 81, Number 8

SIMULATION

553

Vadde and Syrotiuk

Avg Real−time packets Delay (in secs)

4.5
4

3800

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

3600
Real−time flows throughput (bytes/sec)

5

3.5
3
2.5
2
1.5
1
0.5
0
0

3400
3200
3000
2800
2600
2400
2200
2000

3

6

9

1800
0

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF
3

# TCP flows

6

9

# TCP flows

Figure 6. Optimized Link State Routing (OLSR) in the random waypoint (RWP) mobility model: average real-time (a) delay and
(b) throughput

Jitter and total throughput follow a trend similar to realtime packet delay and real-time throughput, respectively;
hence, they are not shown separately.
3.1.3 OLSR in RWP
Figure 6 shows results when OLSR is fixed as the routing protocol. Figure 6(a) shows the average delay of realtime packets. Swan over EDCF achieves the shortest delay
among all combinations. As with DSR, in OLSR, real-time
packets are differentiated from the best-effort packets both
by the QoS architecture and the MAC protocol, giving the
best performance for real-time packets. Insignia with IEEE
802.11 has the highest average real-time packet delay.
An interesting observation is that all combinations with
EDCF perform better than those with IEEE 802.11 as the
MAC protocol. This is in contrast with the average delay
results of AODV and DSR protocols (see Figs. 2 and 5),
where some combinations with IEEE 802.11 performed
better than those with EDCF. The reason for this is that
both AODV and DSR are reactive protocols forming strong
interactions with the underlying MAC protocol. The efficiency of AODV and DSR depends on how the MAC protocol delivers the control packets and on how it interacts
with the routing decisions. Since OLSR is proactive, the
effect of the MAC protocol is limited to the data packet
delays at the MAC layer and does not affect the route formation delays. EDCF, being a QoS-aware MAC protocol,
contributes to lower delays compared to IEEE 802.11.
Figure 6(b) shows the real-time throughput performance of OLSR. As the figure shows, Swan over EDCF has
the best performance, and it is closely followed by classic
over EDCF. With interfering best-effort traffic (i.e., 3, 6,
and 9 TCP flows), the performance of Insignia over IEEE
554 SIMULATION Volume 81, Number 8

802.11 degrades quickly and has the worst performance.
However, when there are no interfering TCP flows, independent of the MAC protocol, Insignia performs better than
the Swan and classic architectures. This is due to Insignia
having fewer packet drops at different queues in the protocol stack than the Swan and classic architectures, allowing
it to deliver more packets. The combinations with EDCF
outperformed those with IEEE 802.11; this is consistent
with the average delay results (see Fig. 6(a)).
OLSR has higher average packet delays and lower
throughput than AODV and DSR, as seen from the higher
scale for delay and lower scale for throughput. This is not
surprising as OLSR has higher control packet overhead
from frequent HELLO message exchange and MPR selection/relay messages. These results are consistent with
those reported in Choi and Ko [25].
3.2 Fixed Mobility Model: Grid
In this section, we present simulation results with the nodes
moving according to the grid mobility model. As before, to
improve readability, we present the results with the routing
protocol fixed, and we use solid [dashed] lines when IEEE
802.11 [EDCF] is used as the MAC protocol.
3.2.1 DSR in Grid
Figure 7(a) shows the average delay of real-time packets when DSR is fixed as the routing protocol. Swan with
802.11 has the lowest delay compared with the other combinations. The classic architecture over 802.11 and Insignia
over 802.11 have the worst performance. Insignia and the
classic architecture over EDCF perform better than over
802.11. When there are no interfering TCP flows, Swan

4.5

0.18

4

0.17

3.5

0.16

3

0.15
Avg jitter (secs)

Avg Real−time packets Delay (in secs)

QUANTIFYING FACTORS AFFECTING QUALITY OF SERVICE IN MANETS

2.5
2
1.5

0.14
0.13
0.12

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

1
0.5
0
0

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

3

6
# TCP flows

0.11
0.1

9

0.09
0

3

6

9

# TCP flows

Figure 7. Dynamic Source Routing (DSR) in the grid mobility model: average real-time (a) delay and (b) jitter

over EDCF performs better than Swan over IEEE 802.11.
However, as the number of TCP flows increases, the performance reverses; this is counterintuitive. Recall that Swan
over EDCF performs better than Swan over 802.11 at all
traffic loads for DSR in the RWP mobility model (see
Fig. 2(a)). The reason for the anomaly is that the packet
delays of EDCF are higher in the grid mobility model than
in the RWP mobility model. Figure 8 shows the difference
in average packet delays for DSR under both mobility models. Both EDCF and IEEE 802.11 have higher delays when
nodes move according to the grid mobility model than the
RWP mobility model. For EDCF, the rate of increase in
the packet delay with the number of TCP flows is higher
in the grid mobility model than in the RWP model.
Swan estimates the bandwidth available using MAC delays, which, in turn, is used to admit and regulate realtime flows. Since EDCF has high packet delays in the
grid mobility model, Swan responds by regulating the realtime flows, degrading their priority to best effort. Consequently, real-time packets suffer large queuing delays, resulting in increased average delay. As already established,
EDCF performs poorly with high contention. On the other
hand, IEEE 802.11, with its larger backoff interval, responds to the contention by increasing the backoff interval
with each failure, which can ease the contention. Although
Swan running over IEEE 802.11 does observe higher delays with contention, it quickly restores the real-time flows
once the contention has eased, leading to lower average
delays. When the network is congested, EDCF is aggressive, sending real-time packets faster; therefore, it suffers
a longer contention period than IEEE 802.11, degrading
the quality of the real-time flows.
Figure 7(b) compares the average real-time packet jitter.
It follows almost the same trend as the average real-time
packet delays; the difference in performance of Swan over

EDCF and Swan over IEEE 802.11 is minimal. Figure 9(a)
shows the real-time throughput; Swan over EDCF performs the best when there is no interfering best-effort TCP
traffic. However, as the number of TCP flows increases, its
performance falls. On the other hand, Swan over 802.11
performs better than Swan over EDCF with an increasing
number of TCP flows. Again, the reason for this is due
to congestion and the relatively small backoff interval in
EDCF.
In Figure 9(b), we see that the classic architecture
over 802.11 has the highest total throughput followed
by Insignia over 802.11. Since EDCF handles congestion poorly, packet delivery is delayed, which increases
the number of queued packets. Since buffer space at the
MAC layer is limited, packets are dropped. This decreases
the total number of packets sent from the source to the
destination. So the network architectures with EDCF have
less total throughput. Swan over 802.11 has the least total throughput due to the traffic regulation performed by
Swan. This limits the number of best-effort TCP packets sent from the source to the destination, resulting in
lower total throughput. Insignia over 802.11 has lower total throughput than the classic architecture over 802.11
because Insignia manages only the real-time flows, leading to higher real-time throughput but suffering lower total
throughput.
3.2.2 AODV in Grid
The network performance when the routing protocol is
fixed as AODV is shown in Figure 10. Swan over IEEE
802.11 has the lowest average delay. The average delay
with Swan over EDCF and the classic architecture over
EDCF is poor when compared with Swan over 802.11.
With DSR, the performance of Swan over EDCF deteriorated only at high traffic loads (i.e., 3, 6, and 9 TCP
Volume 81, Number 8

SIMULATION

555

Vadde and Syrotiuk

Avg Real−time packets Delay (in secs)

3.5

3

2.5

2

1.5

1
Plain 802.11 RWP
Plain EDCF RWP
Plain 802.11 Grid
Plain EDCF Grid

0.5

0
0

3

6

9

# TCP flows

Figure 8. Comparison of Dynamic Source Routing (DSR) packet delays

5000

4000

14000
Total throughput (bytes/sec)

4500
Real−time flows throughput (bytes/sec)

16000

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

3500
3000
2500
2000

10000

8000

6000

4000

1500
1000
0

12000

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

3

6

9

2000
3

# TCP flows

6
# TCP flows

9

Figure 9. Dynamic Source Routing (DSR) in the grid mobility model: (a) real-time throughput and (b) total throughput

flows) (see Fig. 7(a)), but with AODV, the performance of
Swan over EDCF is always worse than Swan over IEEE
802.11. The reason is that even at lower traffic loads,AODV
generates more control packets than DSR, increasing the
congestion in the network. As observed in section 3.2.1,
EDCF performs poorly with congestion, which further affects Swan, leading to higher delay and lower throughput.
Average real-time packet jitter follows a trend similar
to the average real-time packet delay, and total throughput
follows a trend similar to the DSR total throughput (see
Fig. 9(b)); hence, these results are not shown separately.
3.2.3 OLSR in Grid
Figure 11 shows the average delay for OLSR. As the figure shows, the delay is much higher in the grid mobility
556 SIMULATION Volume 81, Number 8

model. With increasing network load, the average delay
increases rapidly and is almost double that of the random
waypoint model. OLSR uses MPRs to disseminate packets, and node movements along grid positions cause OLSR
to recompute more often leading to higher packet delays.
The performance of real-time throughput, jitter, and total
throughput have similar characteristics and are not shown
separately.
3.3 Discussion
To summarize the simulation results, withAODV and DSR,
the performance of Swan over EDCF depends on the performance of EDCF at the MAC layer. When EDCF experiences low MAC delays, Swan over EDCF improves the
QoS provided to the real-time flows. However, if EDCF

QUANTIFYING FACTORS AFFECTING QUALITY OF SERVICE IN MANETS

Avg Real−time packets Delay (in secs)

1.6
1.4

5000

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

1.2
1
0.8
0.6
0.4

4000
3500
3000
2500
2000
1500

0.2
0
0

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

4500
Real−time flows throughput (bytes/sec)

1.8

3

6

9

1000
0

3

# TCP flows

6

9

# TCP flows

Figure 10. Adhoc On-Demand Distance Vector (AODV) in grid mobility model: average real-time (a) delay and (b) throughput

8

Avg Real−time packets Delay (in secs)

7
6

Plain 802.11
Plain EDCF
Swan with 802.11
Insignia with 802.11
Swan with EDCF
Insignia with EDCF

5
4
3
2
1
0
0

3

6

9

# TCP flows

Figure 11. Optimized Link State Routing (OLSR) in the grid mobility model: average real-time delay

suffers increasing MAC delays due to congestion, Swan
over EDCF degrades in performance. The performance of
EDCF depends on the underlying mobility model and the
number of control packets generated by the routing protocol, as these control packets contend with the real-time
data packets. If the control packet overhead is high, EDCF
performs poorly and vice versa. However, with OLSR, the
effect of the MAC protocol is limited to the packet delays
and does not affect the routing protocol in terms of route
formation delays. The performance of the routing protocols
depends primarily on the underlying mobility model.
Although IEEE 802.11 has higher delays than EDCF as
a result of a single packet queue, an adaptive (and larger)
backoff interval responds better to congestion. Hence, at
high traffic loads, Swan over IEEE 802.11 performs bet-

ter than the classic architecture over EDCF and Swan over
EDCF in the grid mobility model. Although Swan is affected by IEEE 802.11 MAC delays at the point of congestion, it quickly restores the real-time flows to their original
priority once congestion has eased.
With the RWP mobility model, DSR has low control
packet overhead, leading to good performance of EDCF,
which in turn helps Swan perform well. AODV has higher
control packet overhead and a corresponding decrease in
the performance of EDCF and Swan. With the grid mobility model, both DSR and AODV have high control packet
overhead, again resulting in poor performance of EDCF
and Swan. This increase in control packet overhead is attributed to the restricted movement of the mobile nodes in
the simulation area.
Volume 81, Number 8

SIMULATION

557

Vadde and Syrotiuk

Insignia has higher overhead than Swan as it is a stateful QoS architecture. Insignia makes sure that real-time
flows have the required bandwidth along the selected route
but does not regulate the best-effort traffic. As a result,
with each burst in best-effort traffic, it has to find alternate paths with the required bandwidth for real-time flows,
which leads to higher delays than when no QoS architecture is present. However, since Insignia adapts and restores
real-time flows, it has higher real-time throughput than the
classic architecture in general. Also, Insignia with DSR as
the routing protocol has better jitter characteristics than the
classic architecture in both mobility models.
4. Statistical Analysis
To quantify the contributions of each factor to the QoS provided, we perform a statistical analysis of the simulation
results. Statistical analysis helps identify the most important factors affecting a response variable. This analysis can
guide a network designer to direct efforts to the important
factors and factor interactions to further improve the QoS
support provided. The analysis is presented using an effects
table and an interaction graph. An effects table shows the
contributions of the factors to the response variable measured as a percentage. This helps quantify the importance
of each factor on the response variables. The percent contribution is calculated by adding up the total sum of squares
and then taking each term’s sum of squares and dividing
by the total. Sum of squares is the measurement of deviation from the mean. An interaction graph shows the factor
interactions visually in the form of a graph.
As we did for the simulation results in section 3, we
perform the statistical analysis for a fixed mobility model.
Table 2 shows the contribution of each factor to average real-time packet delay, average real-time packet jitter,
real-time throughput (RT Tput), and total throughput (Total Tput). In the following tables, “Q” represents the QoS
architecture, “R” represents the routing protocol, “M” represents the MAC protocol, and “L” represents the offered
load in terms of the number of best-effort TCP flows. Twoway and higher factor interaction terms are also present.
Terms that contribute at least 5% to the response are considered significant and are shown in bold.
As Table 2 shows, the routing protocol (R) and offered
load (L) contribute the most to the average delay for the
grid mobility model and for the RWP model. The two-way
interaction between R and L is significant in both of the
mobility models. For average real-time jitter, the routing
protocol (R), QoS architecture (Q), and offered load individually contribute in the grid mobility model. The twoway interactions QR (i.e., QoS architecture and routing
protocol), QM (i.e., QoS architecture and MAC protocol),
and RL (i.e., routing protocol and offered load) also contribute. In the random waypoint mobility model, the same
terms contribute, although with varying contributions, except for RL interaction, which is insignificant.
558 SIMULATION Volume 81, Number 8

For real-time throughput, in both the grid and the RWP
mobility models, offered load has the most significant contribution. The routing protocol also contributes in both mobility models. The two-way interactions are not very significant for the real-time throughput response for the grid
mobility model, but RL makes a significant contribution
in the RWP mobility model. For total throughput, for the
grid mobility model, the offered load is most significant.
For the RWP mobility model, offered load is the single
most important factor, contributing almost 77% to the response. The routing protocol and the interaction between
the routing protocol and offered load also contribute.
The effects table (Table 2) shows that the contributions
of the protocols to the QoS provided changes depending
on the mobility model. Across both mobility models, for
all response variables, offered load plays a significant role.
With an increase in offered load, protocols at all layers of
the network architecture need to coordinate to meet the
QoS requirements of the real-time flows (recall EDCF and
Swan).
Table 2 provides high-level information about the important factors affecting network performance; we saw that
the percentage contribution of offered load is very high. In
general, we know that not only are individual protocols
important, but so is their interaction—however, this is not
too prominent in the effects table, as load takes most of
the contribution. To better understand the protocol interactions, we performed a statistical analysis after fixing the
offered load at the highest level (i.e., 9 flows). Table 3
shows the percentage contribution of protocols and their
interaction for this case.
Now, for both mobility models and for almost all response variables, all protocols have high individual contribution. The two-way interactions of the MAC protocol
with the QoS architecture and the routing protocol are very
significant. This validates the conclusions we made from
the simulation results. As we saw in the simulation results,
EDCF is heavily affected by the routing protocol being
used, which in turn affects the QoS architecture.
Figure 12 shows the interaction between the QoS architecture and the MAC protocol on real-time throughput
for the DSR routing protocol, with nodes moving according to the grid mobility model. (An interaction graph is
not a graph in the usual sense; see Montgomery [11].) As
the figure shows, Swan over EDCF has lower real-time
throughput than Swan over IEEE 802.11. Insignia and the
classic QoS architecture have higher real-time throughput
when run over EDCF than when run over IEEE 802.11. We
do not include the other two-way interaction graphs due to
the lack of space.
5. Conclusions and Future Work
Providing QoS in MANETs is challenging due to wide
variations in network resources caused by node mobility
and the wireless medium. In this article, we analyzed the

QUANTIFYING FACTORS AFFECTING QUALITY OF SERVICE IN MANETS

Table 2. Effects table for delay, jitter, real-time throughput, and total throughput for each mobility model
Grid Mobility Model
Source

Random Waypoint Mobility Model

Real-Time
Throughput

Delay

Jitter

Q
R
M
L

3.30
21.16
3.67
44.22

6.67
11.38
3.90
34.42

4.15
5.31
2.96
74.75

QR
QM
QL
RM
RL
ML

0.45
1.89
1.39
3.02
16.44
1.34

11.40
8.03
2.61
2.13
6.04
3.94

0.29
2.24
1.37
0.39
0.46
0.43

Total
Throughput

Real-Time
Throughput

Total
Throughput

Delay

Jitter

2.81
4.72
1.24
69.55

4.87
10.81
2.46
51.86

5.58
32.79
0.00
13.24

3.37
8.32
1.00
64.56

0.00
8.87
0.92
76.90

0.46
4.50
3.31
1.90
2.95
1.17

0.47
1.69
2.12
8.03
10.94
0.99

17.22
5.88
0.81
3.60
1.88
1.39

0.91
0.86
1.84
4.63
11.51
0.00

0.32
0.40
1.44
0.63
8.81
0.18

Table 3. Effects table for fixed load of nine TCP flows for each mobility model
Grid Mobility Model
Source
Q
R
M
QR
QM
RM

Random Waypoint Mobility Model

Real-Time
Throughput

Delay

Jitter

6.86
72.30
7.60

15.33
17.33
18.22

25.92
33.10
18.83

1.39
3.90
7.31

12.95
21.72
1.57

2.52
15.42
3.15

Total
Throughput

Real-Time
Throughput

Total
Throughput

Delay

Jitter

5.04
45.47
7.80

11.82
51.09
6.93

4.24
67.45
2.20

19.26
34.65
4.79

9.98
58.34
13.58

8.84
19.41
10.70

1.58
5.77
21.21

11.78
3.34
1.89

2.39
6.21
29.30

6.31
0.12
9.95

Avg Real−time flow throughput (bytes/sec)

5300

5200

5100
802.11
EDCF

5000

4900

4800

4700

4600

Swan

Insignia
QoS architecture

Classic

Figure 12. Interaction graph for real-time throughput for Dynamic Source Routing (DSR) in the grid mobility model

impact of five factors (QoS architecture, routing protocol,
MAC protocol, offered load, and mobility model) on the
QoS responses of real-time packet delay, jitter, real-time
throughput, and total throughput. The performance of the
MAC protocols (IEEE 802.11 and EDCF) is not the same
across mobility models (grid and random waypoint) and
routing protocols (AODV, DSR, and OLSR). Through sta-

tistical analysis, a strong interaction between the MAC protocol and the QoS architectures, the MAC protocol and the
routing protocols, and the MAC protocol and offered load
is found. These interactions were quantified using statistical analysis and validate the simulation results. Our study
helps network designers choose the network architecture
most likely to produce the desired performance under the
Volume 81, Number 8

SIMULATION

559

Vadde and Syrotiuk

anticipated conditions, ultimately leading to better
performance.
In our future work, we plan to extend our study to
include additional factors. In addition, we plan to apply
response surface methodology (RSM) to optimize factors
robustly.
6. Acknowledgments
We are grateful for the useful comments from the anonymous referees that have improved our article. We thank
Tracy Camp at the Colorado School of Mines for ns-2
code for steady-state initialization, as well as the COMET
group at Columbia University for ns-2 code for Swan and
Insignia. This research was supported in part by NSF grant
ANI-0240524.
7. References
[1] Gahng-Seop, A., A. Campbell, A. Veres, and L. Sun. 2002. SWAN:
Service differentiation in stateless wireless ad hoc networks. In
Proceedings of the Twenty-First Annual Joint Conference of the
IEEE Computer and Communication Societies (INFOCOM’02),
June, pp. 457-66.
[2] Lee, S., G. Ahn, X. Zhang, and A. Campbell. 2000. INSIGNIA: An IPbased quality of service framework for mobile ad hoc networks.
Journal of Parallel and Distributed Computing 60 (4): 374-406.
[3] Chen, S., and K. Nahrstedt. 1999. Distributed quality-of-service routing in ad-hoc networks. IEEE Journal on Selected Areas in Communications 17 (8): 1488-1505.
[4] Zhu, C., and M. Corson. 2002. QoS routing for mobile ad hoc networks. In Proceedings of the Twenty-First Annual Joint Conference of the IEEE Computer and Communication Societies (INFOCOM’02), June, pp. 958-67.
[5] Cui, S., A. J. Goldsmith, and A. Bahai. 2004. Joint modulation and
multiple access optimization under energy constraints. In Proceedings of the IEEE Global Telecommunications Conference,
vol. 1, December, pp. 151-5.
[6] Cui, S., R. Madan, A. J. Goldsmith, and S. Lall. 2005. Joint routing, MAC, and link layer optimization in sensor networks with
energy constraints. In Proceedings of the IEEE Conference on
Communications, May, vol. 2, pp. 725-9.
[7] Royer, E., S.-J. Lee, and C. Perkins. 2000. The effects of MAC protocols on ad hoc network communications. In Proceedings of
the IEEE Wireless Communications and Networking Conference
(WCNC’00), September, pp. 543-48.
[8] Perkins, C., E. Royer, S. Das, and M. Marina. 2001. Performance
comparison of two on-demand routing protocols for ad hoc networks. IEEE Personal Communications Magazine 8 (1): 16-28.
[9] Bai, F., N. Sadagopan, and A. Helmy. 2003. IMPORTANT: A framework to systematically analyze the impact of mobility on performance of routing protocols for adhoc networks. In Proceedings of the Twenty-Second Annual Joint Conference of the IEEE
Computer and Communications Societies (INFOCOM’03), vol. 2,
pp. 825-35.
[10] Barrett, C., A. Marathe, M. V. Marathe, and M. Drozda. 2002. Characterizing the interaction between routing and MAC protocols in
ad-hoc networks. In Proceedings of the Third ACM International
Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc’02), pp. 92-103.
[11] Montgomery, D. 2005. Design and analysis of experiments. New
York: John Wiley.

560 SIMULATION Volume 81, Number 8

[12] Vadde, K., and V. Syrotiuk. 2004. Factor interaction on service delivery in mobile ad hoc networks. IEEE Journal on Selected Areas
in Communications 22 (7): 1335-46.
[13] The network simulator—ns-2 (version 2.26), University of California, Berkeley. http://www.isi.edu/nsname/ns/
[14] Design Expert software, State Ease Inc. http://www.statease.com
[15] Wireless and mobility extensions to ns-2, Carnegie Mellon University. http://www.monarch.cs.cmu.edu/cmu-ns.html
[16] Internet Engineering Task Force (IETF) MANET Working Group.
IETF draft. http://www.ietf.org/html.charters/manet-charter.html
[17] Johnson, D., and D. Maltz. 1996. Mobile computing. Amsterdam:
Kluwer Academic.
[18] Perkins, C., and E. Royer. 1999. Ad hoc on-demand distance vector
routing. In Proceedings of the Second IEEE Workshop on Mobile
Computing Systems and Applications, February, pp. 90-100.
[19] Clausen, T., P. Jacquet, A. Laouiti, P. Muhlethaler, and Q. L. Viennot.
2001. Optimized link state routing protocol. In Proceedings of the
IEEE International Multitopic Conference (INMIC’04), December, pp. 62-8.
[20] IEEE. 1999. IEEE standard 802.11: W-LAN medium access control
& physical layer specifications. IEEE.
[21] Choi, S., J. Prado, N. Shankar, and S. Mangold. 2003. IEEE 802.11e
contention-based channel access (EDCF) performance evaluation. In Proceedings of the IEEE International Conference on
Communications (ICC’03), May, pp. 1151-6.
[22] Benveniste, M., G. Chessan, M. Hoeben, A. Singla, H. Teunissen,
and M. Wentink. 2001. Enhanced distributed coordination function (EDCF). Working document 802.11-01/131r1, IEEE.
[23] NTIS. n.d. Master propagation system (MPS11) user’s manual.
Washington, DC: U.S. Department of Commerce, NTIS.
[24] Navidi, W., and T. Camp. January-March 2004. Stationary Distributions for the Random Waypoint Mobility Model, IEEE Transactions on Mobile Computing, 3 (1): 99-108.
[25] Choi, J.-M., andY.-B. Ko. 2004.A performance evaluation for ad hoc
routing protocols in realistic military scenarios. In Proceedings
of the Ninth International Conference on Cellular and Intelligent
Communications (CIC’04), October.

Kiran K. Vadde earned his Ph.D. in computer science from Arizona State University (ASU) in 2005. He obtained an M.S. in
computer science from ASU in December 2002 and an M.Sc. in
information systems in May 2000 from the Birla Institute of Technology and Science (BITS), Pilani, India. His research interests
are in the areas of ad hoc networks, cross-layer interaction, routing and MAC protocols, quality of service, and wireless networks.
Violet R. Syrotiuk earned her Ph.D. in computer science from
the University of Waterloo (Canada) in 1992. She joined Arizona
State University in 2002 and is currently an assistant professor of
computer science and engineering. Her research is currently supported by three grants from the National Science Foundation and
a DARPA Connectionless Networks subcontract from General
Dynamics Decision Systems. She serves on the editorial board of
Computer Networks and on the Technical Program Committee
of several major conferences, including MobiCom and Infocom.
Her research interests include mobile ad hoc and sensor networks, particularly MAC protocols, with an emphasis on adaptation, topology-transparency, energy efficiency, dynamic spectrum
utilization, mobile network models, and protocol interaction and
cross-layer design. She is a member of the ACM and the IEEE.

